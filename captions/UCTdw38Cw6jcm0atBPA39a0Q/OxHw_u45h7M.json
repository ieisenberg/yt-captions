[
  {
    "text": "all right let's get started I'm sure people will walk in and they will be sad that they missed the initial part but",
    "start": "5759",
    "end": "11400"
  },
  {
    "text": "it's fine it's fine so recent advances in generative AI have like uh stable",
    "start": "11400",
    "end": "17080"
  },
  {
    "text": "diffusion and chat GPT have the industry more hyped up than a kangaroo on a trampoline or a a caffeine addicted",
    "start": "17080",
    "end": "25279"
  },
  {
    "text": "toddler this may leave you asking questions like is the hype warranted",
    "start": "25279",
    "end": "31119"
  },
  {
    "text": "is the singularity near or how do I leverage it that's that's what we're going to find out",
    "start": "31119",
    "end": "37040"
  },
  {
    "text": "today so this talk is going to cover these three main areas some definitions of terms um like what do all these",
    "start": "37040",
    "end": "44719"
  },
  {
    "text": "acronyms mean we'll go a touch upon a prompt engineering and then I'm going to",
    "start": "44719",
    "end": "50800"
  },
  {
    "text": "apply all of that to a real worldish uh application the application will be",
    "start": "50800",
    "end": "55879"
  },
  {
    "text": "available on GitHub so you can pull it down try it out but first a little bit about favorite subject me so my name is",
    "start": "55879",
    "end": "63359"
  },
  {
    "text": "Phil hack and I know what you're thinking what a great name for a software developer Phil uh here's my contact info and I got",
    "start": "63359",
    "end": "70759"
  },
  {
    "text": "my first computer when I was around five or six as you can see I looked old for my age back then um I've been in love",
    "start": "70759",
    "end": "77040"
  },
  {
    "text": "with computers ever since and I'm probably most well known for net hp. NVC and GitHub uh I am not an expert in AI",
    "start": "77040",
    "end": "85680"
  },
  {
    "text": "or NLP but I've been building applications that leverage it for a while now uh for the past couple years and I'm",
    "start": "85680",
    "end": "92159"
  },
  {
    "text": "just here to share what I've learned and um and to get started I'll we'll start",
    "start": "92159",
    "end": "97360"
  },
  {
    "text": "with some definitions right so what is AI I mean feels like magic right but uh",
    "start": "97360",
    "end": "103439"
  },
  {
    "text": "AI the definition I'm using is a machine capable of Performing tasks that typically require human intelligence for",
    "start": "103439",
    "end": "110759"
  },
  {
    "text": "example it's not just your unhinged relative who can spout conspiracy theories now your computer",
    "start": "110759",
    "end": "116719"
  },
  {
    "text": "can AI can be broken down into multiple kinds the two main ones we hear about a",
    "start": "116719",
    "end": "122280"
  },
  {
    "text": "lot is Agi or artificial general intelligence this is the AI designed to",
    "start": "122280",
    "end": "127560"
  },
  {
    "text": "learn and think and perform at human levels the kind of AI that can reason for itself and take on any sort of task",
    "start": "127560",
    "end": "134560"
  },
  {
    "text": "except opening the pod bay doors and the kind of AI often depicted in movies but",
    "start": "134560",
    "end": "139879"
  },
  {
    "text": "this is the kind of AI that doesn't exist yet as far as anyone knows the kind of AI that's been on",
    "start": "139879",
    "end": "146959"
  },
  {
    "text": "that's been in the you know probably multiple talks that this conference uh is we don't want to confuse AGI with",
    "start": "146959",
    "end": "153280"
  },
  {
    "text": "generative AI this is the kind of AI that like we're hearing all about right and this is the kind that's exploded on",
    "start": "153280",
    "end": "158840"
  },
  {
    "text": "the industry in recent times so some examp this is AI capable of generating text images or other media using",
    "start": "158840",
    "end": "166519"
  },
  {
    "text": "generative models so examples of that are GPT Claude Bard mid journey and",
    "start": "166519",
    "end": "173400"
  },
  {
    "text": "Dolly and generative models are fed these ginormous data sets and they're programmed to learn for uh to deduce",
    "start": "173400",
    "end": "180280"
  },
  {
    "text": "patterns in that data set and then generate new data that mimics those existing patterns so basically these",
    "start": "180280",
    "end": "187159"
  },
  {
    "text": "generative AIS are U Monkey C Monkey do and this datadriven mimicry is a key",
    "start": "187159",
    "end": "193560"
  },
  {
    "text": "aspect of this current generation of AI Technologies but for this talk I'm going to focus on llms or large language",
    "start": "193560",
    "end": "201159"
  },
  {
    "text": "models so this is a deep learning algorithm that can perform a variety of natural language processing tasks in",
    "start": "201159",
    "end": "208120"
  },
  {
    "text": "particularly I'll be focused on GPT this is probably the one that's really",
    "start": "208120",
    "end": "213280"
  },
  {
    "text": "sparked this revolution right uh generative pre-training Transformer this",
    "start": "213280",
    "end": "219519"
  },
  {
    "text": "is a language prediction model that uses machine learning to produce humanik text",
    "start": "219519",
    "end": "224680"
  },
  {
    "text": "and you notice I emphasize a key a couple key terms here prediction and humanlike and this is a bit of this is a",
    "start": "224680",
    "end": "231840"
  },
  {
    "text": "clue that uh this is not AGI while the results of using GPT can feel like",
    "start": "231840",
    "end": "237599"
  },
  {
    "text": "there's a real sentience or thought going on on there it's not engaging in actual reasoning to produce results so",
    "start": "237599",
    "end": "244519"
  },
  {
    "text": "how does uh how does it work well it's really all about the Transformers not",
    "start": "244519",
    "end": "250400"
  },
  {
    "text": "not the one developed by hasbo but the one developed by Google this was the key breakthrough vastly simplified there",
    "start": "250400",
    "end": "257840"
  },
  {
    "text": "were pre-existing neural networks before GPT for doing this sort of thing but the Transformer technology enabled more",
    "start": "257840",
    "end": "265960"
  },
  {
    "text": "parallelization I am amazed I pronounced that word right parallelization during training and encoding uh if you want to",
    "start": "265960",
    "end": "272560"
  },
  {
    "text": "know more about that we can talk about it later um it's uh you know machine learning stuff right and like I said I'm",
    "start": "272560",
    "end": "279080"
  },
  {
    "text": "not an expert so greatly simplified we start here with the prompt natural language prompt that prompt gets",
    "start": "279080",
    "end": "286120"
  },
  {
    "text": "tokenized where it gets uh oh my laser works okay so it gets",
    "start": "286120",
    "end": "291199"
  },
  {
    "text": "tokenized into a series of tokens or numbers right roughly speaking it's like a number per word but it's not exactly",
    "start": "291199",
    "end": "297680"
  },
  {
    "text": "the case some larger words will get broken up into multiple tokens um and",
    "start": "297680",
    "end": "302720"
  },
  {
    "text": "and you that results in what programmers would call an array but what uh scientists call a vector right a series",
    "start": "302720",
    "end": "309479"
  },
  {
    "text": "of numbers and that that's a that's a that's a a dumb encoding right where the",
    "start": "309479",
    "end": "316520"
  },
  {
    "text": "real stuff happens is the encoding process after that where each of those tokens uh get gets an embedding for the",
    "start": "316520",
    "end": "324319"
  },
  {
    "text": "token and that embedding is another Vector which is um in in the case of gp2",
    "start": "324319",
    "end": "331360"
  },
  {
    "text": "1,294 characters or numbers and gpt3 it's 12,288 numbers and at the time I",
    "start": "331360",
    "end": "338319"
  },
  {
    "text": "couldn't figure out I couldn't find out what GPT 4 is but I heard they announced the keynote it was something like 40,000",
    "start": "338319",
    "end": "345120"
  },
  {
    "text": "so you end up with this uh giant ass array right or Matrix sorry so uh the",
    "start": "345120",
    "end": "351039"
  },
  {
    "text": "number of columns in The Matrix is the number of tokens in your prompt and then the number of rows is the uh depends on",
    "start": "351039",
    "end": "357560"
  },
  {
    "text": "which model of GPT you're using so let's focus on and then the decoding",
    "start": "357560",
    "end": "363840"
  },
  {
    "text": "process takes that giant Matrix and then starts to produce the output and what",
    "start": "363840",
    "end": "369560"
  },
  {
    "text": "I'm going to focus here is on this decoding process so imagine that uh we start with",
    "start": "369560",
    "end": "377120"
  },
  {
    "text": "a a natural language prompt once upon a time not long ago so this is maybe what you type in chat",
    "start": "377120",
    "end": "382599"
  },
  {
    "text": "gbt GPT goes through that encoding process produces a giant ass Matrix uh",
    "start": "382599",
    "end": "388599"
  },
  {
    "text": "that gets sent to the language model and it does this be beep bunch of computation and out comes a probability",
    "start": "388599",
    "end": "396880"
  },
  {
    "text": "distribution so you can see here uh imagine this is a probability distribution over every possible token",
    "start": "396880",
    "end": "404080"
  },
  {
    "text": "in the system so you know starting with a ending with zux and then in the middle",
    "start": "404080",
    "end": "409720"
  },
  {
    "text": "there we see a couple that are the most likely ones and then gbt will roll the dice and said using this probability",
    "start": "409720",
    "end": "416560"
  },
  {
    "text": "distribution and let's say in this case it picks when and that outputs a single",
    "start": "416560",
    "end": "423560"
  },
  {
    "text": "token when now that token gets added back into the prompt goes through back",
    "start": "423560",
    "end": "431120"
  },
  {
    "text": "into the language model produces a new probability distribution and you notice",
    "start": "431120",
    "end": "436360"
  },
  {
    "text": "this one's a little bit different right because now the prompt is different and then it produces another",
    "start": "436360",
    "end": "442120"
  },
  {
    "text": "token and then it goes again and again until",
    "start": "442120",
    "end": "449560"
  },
  {
    "text": "so I don't know if anyone knows what this lyric is too this shows my age uh and then you until it hits the",
    "start": "449680",
    "end": "457919"
  },
  {
    "text": "end of sequence token or you run out of uh tokens so um different models have",
    "start": "457919",
    "end": "465159"
  },
  {
    "text": "different token limits and the key thing the key thing to note here is um you know you might",
    "start": "465159",
    "end": "472080"
  },
  {
    "text": "ask when was that probability dist how does it get that probability distribution when was that created well that's where all that training comes",
    "start": "472080",
    "end": "478639"
  },
  {
    "text": "into play right when it fed the massive amounts of data it's creating all these probability distributions for all these",
    "start": "478639",
    "end": "485319"
  },
  {
    "text": "tokens um the other thing to note is you'll notice that like it doesn't distinguish between you know the user",
    "start": "485319",
    "end": "491960"
  },
  {
    "text": "The Prompt and the output it's all part of the prompt by the end of the the sequence and it's producing a single",
    "start": "491960",
    "end": "498360"
  },
  {
    "text": "token at a time using a stochastic process a probability distribution uh you can actually control",
    "start": "498360",
    "end": "505360"
  },
  {
    "text": "that like if you ever use the API you'll see a field called temperature you could tell gbt always pick the most likely one",
    "start": "505360",
    "end": "513000"
  },
  {
    "text": "don't roll the dice but what we found is that or what they found is that when you have add a little Randomness to it you",
    "start": "513000",
    "end": "519200"
  },
  {
    "text": "get better results so what are some use cases of it well we see uh summarization",
    "start": "519200",
    "end": "526000"
  },
  {
    "text": "classification translation question answering and many others but these are all really just variants of text",
    "start": "526000",
    "end": "533040"
  },
  {
    "text": "completion just like we saw earlier it's just completing the prompt until it runs",
    "start": "533040",
    "end": "538519"
  },
  {
    "text": "out of tokens or or ends gets the end of sequence and you know some strengths of",
    "start": "538519",
    "end": "544600"
  },
  {
    "text": "GPT is that it can generate humanlike text you know it can generate stories that you are interesting it can generate",
    "start": "544600",
    "end": "551880"
  },
  {
    "text": "um like articles that feel real that feel like a human wrote it but one of",
    "start": "551880",
    "end": "557120"
  },
  {
    "text": "the weaknesses it stumbles over facts and is inconsistent so I'm going to show a quick example so let's",
    "start": "557120",
    "end": "565640"
  },
  {
    "text": "see yes all right in fact if you look down here I don't know if you can see that it says chat GPT can make mistakes",
    "start": "565640",
    "end": "572440"
  },
  {
    "text": "consider checking important information so I'm going to just do a simple one I I use Snippets now because",
    "start": "572440",
    "end": "580200"
  },
  {
    "text": "it saves me time so I'm asked it to write a Wikipedia article about me and",
    "start": "580200",
    "end": "586000"
  },
  {
    "text": "uh if we look here you know Phil hack prominent software engineer and open source Advocate where he played key",
    "start": "586000",
    "end": "593160"
  },
  {
    "text": "roles say you know it may be it may make mistakes but I kind of like that one but",
    "start": "593160",
    "end": "598760"
  },
  {
    "text": "then it says was born in fton California in 1979 none of this is true uh I did work at Microsoft and I",
    "start": "598760",
    "end": "606360"
  },
  {
    "text": "did work at GitHub um so you can see here like it writes this very humanlike",
    "start": "606360",
    "end": "611399"
  },
  {
    "text": "article and a lot of this is really uh true but a lot of this is really false",
    "start": "611399",
    "end": "616959"
  },
  {
    "text": "and it's not really easy to determine what's what right uh let's do something even simpler I'm just going to ask it to",
    "start": "616959",
    "end": "623560"
  },
  {
    "text": "multiply two numbers you know like hey computers are good at multiplication shouldn't it get this right",
    "start": "623560",
    "end": "630440"
  },
  {
    "text": "and it's you know 3,36 uh, this is what it produced right and",
    "start": "630440",
    "end": "636000"
  },
  {
    "text": "we all know that's wrong but for those who aren't as quick as me in math I've",
    "start": "636000",
    "end": "642079"
  },
  {
    "text": "already pre-calculated and we can see that that number's wrong so it can't even do basic multiplication what use is",
    "start": "642079",
    "end": "648480"
  },
  {
    "text": "this right well we'll we'll we'll we'll look into some ideas to fix that later",
    "start": "648480",
    "end": "654160"
  },
  {
    "text": "so I'm going to switch back okay",
    "start": "654160",
    "end": "659839"
  },
  {
    "text": "but first we're going to cover prompt engineering a little bit uh this topic could be a talk in its own right I'm sure others have done it I'm just going",
    "start": "659839",
    "end": "666480"
  },
  {
    "text": "to cover a few key points so what is prompt engineering this is the sort of",
    "start": "666480",
    "end": "671600"
  },
  {
    "text": "the subtle art of giving an AI instructions to try to coax a result a useful result so in my previous slide",
    "start": "671600",
    "end": "678440"
  },
  {
    "text": "you saw like a laddin speaking to a genie it's a lot like talking to a genie right you know you have to be very",
    "start": "678440",
    "end": "684600"
  },
  {
    "text": "intentional about what you ask for because you're going to get what you ask for and sometimes that's not what you",
    "start": "684600",
    "end": "690720"
  },
  {
    "text": "want um the prompt is the natural language text sent to or received from",
    "start": "690720",
    "end": "696360"
  },
  {
    "text": "an AI and you saw earlier when you know the AI produces a text it gets added to",
    "start": "696360",
    "end": "701639"
  },
  {
    "text": "the prompt that's why we have that uh terminology for that now when you're using GPT prompts can have roles you get",
    "start": "701639",
    "end": "708560"
  },
  {
    "text": "more control when you're actually using the API versus the website with the website for example there's a system",
    "start": "708560",
    "end": "714560"
  },
  {
    "text": "prom this sets the overall context for the prompt and it's typically used to configure an AI in some way so for",
    "start": "714560",
    "end": "722560"
  },
  {
    "text": "example you might configure the system prompt to be you are a pirate of the seven C's right when you're using GPT",
    "start": "722560",
    "end": "729120"
  },
  {
    "text": "the website you don't see the system prompt you can't see what they're doing under the hood but you you can bet it's",
    "start": "729120",
    "end": "734440"
  },
  {
    "text": "probably fairly complex because they're trying to prevent you from jailbreaking it and doing all sorts of awful things",
    "start": "734440",
    "end": "740560"
  },
  {
    "text": "but uh people are very uh resilient at finding ways to exploit it the user",
    "start": "740560",
    "end": "746079"
  },
  {
    "text": "prompt supplies the question or command to the A I now this might be someone typing in something to a bot but in your",
    "start": "746079",
    "end": "753279"
  },
  {
    "text": "the context of your application it might be uh you passing it text to to summarize or you passing a text uh to",
    "start": "753279",
    "end": "761000"
  },
  {
    "text": "you know accomplish some goal in your app so for example translate this text in Klingon and the assistant role is the",
    "start": "761000",
    "end": "768600"
  },
  {
    "text": "the response to the prompt uh n which uh is Translating that into",
    "start": "768600",
    "end": "775399"
  },
  {
    "text": "Klingon uh which gbt actually is pretty good at surprisingly uh so I've heard so",
    "start": "775399",
    "end": "782160"
  },
  {
    "text": "prompting best practices first of all start simple and iterate right it's an iterative process I mean this is the",
    "start": "782160",
    "end": "787199"
  },
  {
    "text": "same thing you do when you're writing code be direct and specific you can get",
    "start": "787199",
    "end": "792279"
  },
  {
    "text": "good results when you get to the point and specify things like tone length style format uh don't say please for",
    "start": "792279",
    "end": "800000"
  },
  {
    "text": "example you know like it may feel weird like especially if you're from a very polite culture but if you say please uh",
    "start": "800000",
    "end": "807399"
  },
  {
    "text": "this is a great example please often gives the um point you know starts to point to the training data where people",
    "start": "807399",
    "end": "813720"
  },
  {
    "text": "are allowed to say no right but if you say write a story it writes a story if",
    "start": "813720",
    "end": "819120"
  },
  {
    "text": "you say please write a story it might say no I don't want to yeah at the end what can say thank",
    "start": "819120",
    "end": "827920"
  },
  {
    "text": "you at the end oh can you say thank you yeah that's fine but and probably not in your application I I think so he asked",
    "start": "827920",
    "end": "835759"
  },
  {
    "text": "can you say thank you at the end and I understand the impetus to like hedge your bets against the sentience coming",
    "start": "835759",
    "end": "841279"
  },
  {
    "text": "out and you know like hey I was polite all those years so you know remember me when you take over Humanity um but it's",
    "start": "841279",
    "end": "848800"
  },
  {
    "text": "a stochastic model you we don't have to worry about this generation but the Next Generation AI we may want to be more",
    "start": "848800",
    "end": "854279"
  },
  {
    "text": "polite I don't know uh put the instruction first so start the user prompt with the main request question or",
    "start": "854279",
    "end": "861320"
  },
  {
    "text": "the command and then afterwards provide context you know you afterwards you can provide all the necessary context uh",
    "start": "861320",
    "end": "868040"
  },
  {
    "text": "that it may need to produce a good result um providing examples is really",
    "start": "868040",
    "end": "873279"
  },
  {
    "text": "important and you can provide them in two ways one in the system prompt and one in the actually using the roles uh",
    "start": "873279",
    "end": "880160"
  },
  {
    "text": "like so basically you can u a very powerful technique is when you create the chat GPT request pre-populate a user",
    "start": "880160",
    "end": "888600"
  },
  {
    "text": "and a uh assistant role response and then it will use that in crafting the",
    "start": "888600",
    "end": "893959"
  },
  {
    "text": "next one because it will understand like oh this is what you're actually looking for um because it doesn't know that",
    "start": "893959",
    "end": "899360"
  },
  {
    "text": "that's not part of its history and then experiment word choice ordering personas",
    "start": "899360",
    "end": "904800"
  },
  {
    "text": "all these can impact the results be positive so Nike was on the",
    "start": "904800",
    "end": "910759"
  },
  {
    "text": "right track when they say just do it and this isn't um just to be sacin or nice",
    "start": "910759",
    "end": "915920"
  },
  {
    "text": "what by being positive uh if I said for example don't imagine pink elephants",
    "start": "915920",
    "end": "921600"
  },
  {
    "text": "flying around this room you're naturally going to start thinking about pink elephants and and uh language models",
    "start": "921600",
    "end": "927759"
  },
  {
    "text": "kind of work in the same way by introducing a concept you uh kind of steer it towards producing output that",
    "start": "927759",
    "end": "933920"
  },
  {
    "text": "has that concept so for example instead of saying don't do this say uh do that",
    "start": "933920",
    "end": "939800"
  },
  {
    "text": "or keep it focused on this topic right and that that is more effective uh than",
    "start": "939800",
    "end": "944959"
  },
  {
    "text": "to reduce uh hallucinations and wrong answers speaking of hallucinations give",
    "start": "944959",
    "end": "950319"
  },
  {
    "text": "the model an out so Hallucination is a term that people come up with when it produces the wrong results like when it",
    "start": "950319",
    "end": "956240"
  },
  {
    "text": "said I was born in Cali that's you know call that a hallucination but um you can",
    "start": "956240",
    "end": "961800"
  },
  {
    "text": "tell the model look say I don't know if you don't know and that is one way to reduce those types of",
    "start": "961800",
    "end": "968480"
  },
  {
    "text": "hallucinations uh you can have it break complex tasks into subtasks so if you wanted to write an essay you might say",
    "start": "968480",
    "end": "975120"
  },
  {
    "text": "write three points for this topic write three points against this topic and then summarize that into an",
    "start": "975120",
    "end": "980959"
  },
  {
    "text": "essay ask for Chain of Thought this one is really powerful and I do this uh all",
    "start": "980959",
    "end": "986120"
  },
  {
    "text": "the time in in the app development where I can store it chain thought with everything it does so I can review it later and you'll see that when I do the",
    "start": "986120",
    "end": "992959"
  },
  {
    "text": "demo but ask to explain its reasoning you know like uh write you what's the",
    "start": "992959",
    "end": "998720"
  },
  {
    "text": "answer to this question and tell me why you came up with that and then check the models comprehension so I don't know if",
    "start": "998720",
    "end": "1005519"
  },
  {
    "text": "any of you know oh you can't hear this it's like are you sure about that are you sure about that anyways and then my",
    "start": "1005519",
    "end": "1012199"
  },
  {
    "text": "best tip is use the the playground so I'm going to switch again",
    "start": "1012199",
    "end": "1020160"
  },
  {
    "text": "me see can you see that yeah so this is playground. open ai.com or sorry",
    "start": "1022920",
    "end": "1028558"
  },
  {
    "text": "platform. open.com playground and so unlike the the website the consumer",
    "start": "1028559",
    "end": "1034319"
  },
  {
    "text": "website here you can actually control all the different roles and you can set the temperature for example so I'm going",
    "start": "1034319",
    "end": "1041000"
  },
  {
    "text": "to uh start with a a scenario I've already come up with where uh for those",
    "start": "1041000",
    "end": "1047400"
  },
  {
    "text": "who can't read it I'm just going to submit this Andreas passes the ball to Joel Joel dummies the ball and it goes to leowski who scores a goal who gets",
    "start": "1047400",
    "end": "1054799"
  },
  {
    "text": "the assist and it says Andreas would received the assist in the situation and that's actually correct the first time I",
    "start": "1054799",
    "end": "1060720"
  },
  {
    "text": "did this ever it got it wrong but it's getting better but um imagine that I'm",
    "start": "1060720",
    "end": "1066919"
  },
  {
    "text": "crafting this a this uh I'm building an application that uh is trying to answer these you know sports questions right",
    "start": "1066919",
    "end": "1073600"
  },
  {
    "text": "this assistant answer might not be very useful I may want this in um",
    "start": "1073600",
    "end": "1079880"
  },
  {
    "text": "uh a uh Json format right so first let's set a Persona we're going to set the",
    "start": "1079880",
    "end": "1085159"
  },
  {
    "text": "system prompt oops I referee I can't",
    "start": "1085159",
    "end": "1091640"
  },
  {
    "text": "spell if I don't do it right refer yeah okay you",
    "start": "1094960",
    "end": "1103919"
  },
  {
    "text": "know there we go and then I'm going to just do uh example Le",
    "start": "1103919",
    "end": "1110480"
  },
  {
    "text": "here this usually works better than there we go so here you can see it's a",
    "start": "1110480",
    "end": "1116360"
  },
  {
    "text": "little let me zoom in there so I'm setting up a Persona you are a",
    "start": "1116360",
    "end": "1121679"
  },
  {
    "text": "worldclass soccer referee please provide an answer and reasoning in Jason format and then I provide an example in Jason",
    "start": "1121679",
    "end": "1128080"
  },
  {
    "text": "format so now I'm going to remove that response and submit this and we see we",
    "start": "1128080",
    "end": "1133480"
  },
  {
    "text": "get an answer Andreas it's succinct and then I get the reasoning um and now",
    "start": "1133480",
    "end": "1138840"
  },
  {
    "text": "that's useful now imagine that uh I mentioned like using the roles for uh pre-populating examples so now uh when",
    "start": "1138840",
    "end": "1146760"
  },
  {
    "text": "I'm building app I might pre-populate every request with this and then the next time an actual user asks a question",
    "start": "1146760",
    "end": "1153919"
  },
  {
    "text": "I might uh I might uh then I can populate that",
    "start": "1153919",
    "end": "1159679"
  },
  {
    "text": "user send the whole thing and it's going to give me a really good response here",
    "start": "1159679",
    "end": "1165640"
  },
  {
    "text": "so so if you're building a soccer application this would be a way to do it and I like that I'm actually in a",
    "start": "1165640",
    "end": "1171600"
  },
  {
    "text": "country where we call it soccer right everywhere I go they I get for saying that and I'm like okay well",
    "start": "1171600",
    "end": "1178320"
  },
  {
    "text": "oh No No One's Gonna complain here yeah well most of you",
    "start": "1178320",
    "end": "1184799"
  },
  {
    "text": "won't all right okay so let's uh oh time for the",
    "start": "1184799",
    "end": "1191120"
  },
  {
    "text": "main demo so now I'm going to go into building an actual application uh I'm you know I'm particular to as.net core",
    "start": "1191120",
    "end": "1198799"
  },
  {
    "text": "and all that so naturally I used asp.net core EF core signal R tell1 CSS plus",
    "start": "1198799",
    "end": "1205240"
  },
  {
    "text": "webpack mass transit Blazer refit Azure openai and then I host it on GitHub uh",
    "start": "1205240",
    "end": "1212240"
  },
  {
    "text": "do I win the buzzword Bingo now you don't need to know all these different Technologies um the",
    "start": "1212240",
    "end": "1219000"
  },
  {
    "text": "reason I'm using all this is I really wanted to build something that was interactive real world and that you",
    "start": "1219000",
    "end": "1224440"
  },
  {
    "text": "could um you know kind of Clone and play around with and and use as a start point for your own",
    "start": "1224440",
    "end": "1229960"
  },
  {
    "text": "applications uh the first thing I'm going to look at is the completions API",
    "start": "1229960",
    "end": "1235159"
  },
  {
    "text": "and so you know there's here's the end point you probably will never like do a",
    "start": "1235159",
    "end": "1240480"
  },
  {
    "text": "a post request directly to it you'll probably use one of the many client libraries out there um but I'm going to",
    "start": "1240480",
    "end": "1246320"
  },
  {
    "text": "show the app running so",
    "start": "1246320",
    "end": "1252120"
  },
  {
    "text": "let's let's try that okay",
    "start": "1253200",
    "end": "1258279"
  },
  {
    "text": "and oh",
    "start": "1259480",
    "end": "1262840"
  },
  {
    "text": "shoot actually have to hit run there and then I'll show the code in a",
    "start": "1265559",
    "end": "1273200"
  },
  {
    "text": "second there we go let me zoom in here so this is a",
    "start": "1278120",
    "end": "1283240"
  },
  {
    "text": "demonstration of a oneon-one chat bot implemented with the open AI chat GPT API so the idea is here I can ask",
    "start": "1283240",
    "end": "1289679"
  },
  {
    "text": "questions uh like uh how many people are",
    "start": "1289679",
    "end": "1294720"
  },
  {
    "text": "in Sydney and it's going to respond with poop so that's the application now but",
    "start": "1294720",
    "end": "1301679"
  },
  {
    "text": "like I said now we're going to sprinkle some AI in there right we're going to figure out the first thing we want to do is we want to use the uh completions API",
    "start": "1301679",
    "end": "1309240"
  },
  {
    "text": "so this app as I mentioned it's using Blazers it's using signal R and it's using mass transit and the important",
    "start": "1309240",
    "end": "1314880"
  },
  {
    "text": "part there is that uh mass transit is like a messaging system so rather than making a call directly from the client",
    "start": "1314880",
    "end": "1321679"
  },
  {
    "text": "or directly from that page I want to decouple the AI part from the rest of the app so that I can reuse that part",
    "start": "1321679",
    "end": "1328159"
  },
  {
    "text": "for any part of my application so the long story short is eventually this ends up as a message to a",
    "start": "1328159",
    "end": "1334640"
  },
  {
    "text": "consumer and that class is easy to well relatively easy so I have a bot message",
    "start": "1334640",
    "end": "1339919"
  },
  {
    "text": "consumer and the important part here is we get the message and then we going",
    "start": "1339919",
    "end": "1346600"
  },
  {
    "text": "to send a response and right now now it's just sending uh the the codes for a",
    "start": "1346600",
    "end": "1353320"
  },
  {
    "text": "poop emoji so because you probably don't want to see me typing a bunch of stuff I I",
    "start": "1353320",
    "end": "1359720"
  },
  {
    "text": "use a lot of Snippets but it's nice to see where I'm setting this stuff up so",
    "start": "1359720",
    "end": "1365440"
  },
  {
    "text": "the first thing we're do is we're going to create the chat completion options and here you can see I'm I'm setting up",
    "start": "1365440",
    "end": "1372000"
  },
  {
    "text": "the system roll message you are a helpful assistant who is concise into the point and you are helping the user",
    "start": "1372000",
    "end": "1378960"
  },
  {
    "text": "and then I pass in like your username and then we take the message that you sent and uh populate a user roll and now",
    "start": "1378960",
    "end": "1387840"
  },
  {
    "text": "we just need to send that to GPT so okay so I just that produce a lot of",
    "start": "1387840",
    "end": "1395000"
  },
  {
    "text": "code but the important thing here is whoops H where's",
    "start": "1395000",
    "end": "1401080"
  },
  {
    "text": "my uh oh oh shoot my computer's freezing",
    "start": "1401080",
    "end": "1409200"
  },
  {
    "text": "no not now and people complain about wi this is",
    "start": "1409520",
    "end": "1416919"
  },
  {
    "text": "a Mac and it's a oh yeah David fower wanted me show that I was actually using a Mac to develop a ponor he's so happy",
    "start": "1416919",
    "end": "1423840"
  },
  {
    "text": "about that but ah Jesus Christ um what do I do see",
    "start": "1423840",
    "end": "1430679"
  },
  {
    "text": "I don't have control out the [Laughter]",
    "start": "1430679",
    "end": "1436600"
  },
  {
    "text": "lead yeah um here let me just I may have to power",
    "start": "1436600",
    "end": "1441919"
  },
  {
    "text": "this down this is okay this is a new one for",
    "start": "1441919",
    "end": "1448960"
  },
  {
    "text": "me",
    "start": "1448960",
    "end": "1451960"
  },
  {
    "text": "man so if you that's the Apple logo all right so uh what I'll tell you what the",
    "start": "1454799",
    "end": "1461919"
  },
  {
    "text": "code does and then we'll look at it real quick right so we created that completions object and then we send it to the completions API we get a response",
    "start": "1461919",
    "end": "1469679"
  },
  {
    "text": "that response uh then gets sent as a um signal R message back into the",
    "start": "1469679",
    "end": "1478278"
  },
  {
    "text": "uh back to the app and then gets rendered in in the thing and then it answers your question",
    "start": "1478919",
    "end": "1484640"
  },
  {
    "text": "okay so uh it's funny because I you know I'm",
    "start": "1484640",
    "end": "1492039"
  },
  {
    "text": "known for having demos break and usually it's because I go off script or I start trying to do live coding so I made a",
    "start": "1492039",
    "end": "1498960"
  },
  {
    "text": "resolution like no more demo fails I'm going to use Snippets I'm going to do this but you know you you you can't",
    "start": "1498960",
    "end": "1506080"
  },
  {
    "text": "tempt the demo gods they will always find a way to yeah yeah all right",
    "start": "1506080",
    "end": "1515158"
  },
  {
    "text": "so oh my God now everything wants to start H see [Music]",
    "start": "1515360",
    "end": "1521640"
  },
  {
    "text": "Dev am I projecting oh yeah I am okay script all- e web d d I'm using t-u",
    "start": "1521640",
    "end": "1533200"
  },
  {
    "text": "so",
    "start": "1533200",
    "end": "1536200"
  },
  {
    "text": "okay oh it looks like it's s yeah man that was a really bad crash",
    "start": "1546440",
    "end": "1553320"
  },
  {
    "text": "it's like uh",
    "start": "1553320",
    "end": "1557200"
  },
  {
    "text": "sorry about that okay we're getting there we're getting there let's see if we can run this get back to where we",
    "start": "1560039",
    "end": "1568039"
  },
  {
    "text": "were go to presentation",
    "start": "1568320",
    "end": "1572398"
  },
  {
    "text": "mode so interesting thing you know we get these uh a choice array but it's",
    "start": "1574320",
    "end": "1579399"
  },
  {
    "text": "always you just always grab the first one it's just the way the API set up there's a when you're making a request",
    "start": "1579399",
    "end": "1585120"
  },
  {
    "text": "you can actually tell it give me three responses but it's always three responses to the same question I haven't",
    "start": "1585120",
    "end": "1590600"
  },
  {
    "text": "found any reason why I'd want that but um but if you did so then we're going to",
    "start": "1590600",
    "end": "1597039"
  },
  {
    "text": "send the response with the content of that and then we have a TR catch around it of course so now if I go in here and",
    "start": "1597039",
    "end": "1603600"
  },
  {
    "text": "I say something like what is the height of Mount",
    "start": "1603600",
    "end": "1611240"
  },
  {
    "text": "Everest if all goes well we see Mount Everest is",
    "start": "1611640",
    "end": "1616720"
  },
  {
    "text": "approximate and poop so yes uh I implemented it I can get rid of this line now great um I haven't",
    "start": "1616720",
    "end": "1625200"
  },
  {
    "text": "recompiled because so it says Mount Everest is approximately 8,848 meters high great so we've now imp",
    "start": "1625200",
    "end": "1632960"
  },
  {
    "text": "sprinkled a little AI so what if I want to ask another question a followup question right uh okay how tall is that",
    "start": "1632960",
    "end": "1639399"
  },
  {
    "text": "in feet and",
    "start": "1639399",
    "end": "1645159"
  },
  {
    "text": "um says I'm sorry I can't provide information you're looking for I don't know what you're talking about uh so",
    "start": "1645159",
    "end": "1650279"
  },
  {
    "text": "this is one of the first things that I I got confused about when I was first building it is that GPT the API is a stateless API when you use the consumer",
    "start": "1650279",
    "end": "1657600"
  },
  {
    "text": "website you know it remembers the state and it's keeping track of that you know behind the scenes but in actuality what",
    "start": "1657600",
    "end": "1663519"
  },
  {
    "text": "it's doing is it's sending it all every your entire history back and forth um",
    "start": "1663519",
    "end": "1668600"
  },
  {
    "text": "over the wire to the to the GPT and so we have to do the same thing so what I'm going to do here is",
    "start": "1668600",
    "end": "1676080"
  },
  {
    "text": "start to maintain a little bit of state so let's see we're going to add I",
    "start": "1676080",
    "end": "1682080"
  },
  {
    "text": "need some way to store the state so I'm going to do something that I wouldn't really recommend in a real app this is",
    "start": "1682080",
    "end": "1688000"
  },
  {
    "text": "the part where like I mentioned it's a real worldish app so there are some things that I'm doing that I wouldn't",
    "start": "1688000",
    "end": "1693519"
  },
  {
    "text": "recommend but only because I haven't had time to implement the way I would do it yet so let's",
    "start": "1693519",
    "end": "1699240"
  },
  {
    "text": "go so here I'm going to create a limited cue of chat messages and we're going to store let's say the last 20 messages in",
    "start": "1699240",
    "end": "1706600"
  },
  {
    "text": "a real world app I when when you start to hit your limit of the number of messages you're sending you know you",
    "start": "1706600",
    "end": "1712960"
  },
  {
    "text": "don't want to let that grow indefinitely because you're sending it all to the API and it costs per token what I what I did",
    "start": "1712960",
    "end": "1720200"
  },
  {
    "text": "in my last application is that once we hit a certain number I started summarizing the previous history so",
    "start": "1720200",
    "end": "1725480"
  },
  {
    "text": "summarize all of that into a single message and then I removed all those messages and then kind of started a new",
    "start": "1725480",
    "end": "1731799"
  },
  {
    "text": "cue from that point on um that's it's a bit of work to do and I",
    "start": "1731799",
    "end": "1737440"
  },
  {
    "text": "haven't implemented in this sample app yet but I will at some point because I think that's for a practical real world",
    "start": "1737440",
    "end": "1743000"
  },
  {
    "text": "app you're going to want to do that although I'll show you something later that like doesn't need that anymore okay",
    "start": "1743000",
    "end": "1748440"
  },
  {
    "text": "so I've set up where I'm going to store it and then I need to uh we need to populate the messages",
    "start": "1748440",
    "end": "1758120"
  },
  {
    "text": "right let's",
    "start": "1758600",
    "end": "1761840"
  },
  {
    "text": "see and then I need to take this message okay so what I'm doing here is is so",
    "start": "1764120",
    "end": "1769799"
  },
  {
    "text": "we're taking all the previous messages and we need to add it to that request and then I need to take the message the",
    "start": "1769799",
    "end": "1777000"
  },
  {
    "text": "user is adding and add that at the very end which is right here this is the new",
    "start": "1777000",
    "end": "1782159"
  },
  {
    "text": "incoming does that all make sense so I'm taking the entire history every request I take the entire history then I add the",
    "start": "1782159",
    "end": "1788480"
  },
  {
    "text": "new message to the very end and the important thing here is that when I take the whole history I need the whole",
    "start": "1788480",
    "end": "1793679"
  },
  {
    "text": "history of your the user question and the assistant response",
    "start": "1793679",
    "end": "1798799"
  },
  {
    "text": "and so then I will add that and then over here when we get the",
    "start": "1798799",
    "end": "1804600"
  },
  {
    "text": "response I need to um I need to add that to the",
    "start": "1804600",
    "end": "1812640"
  },
  {
    "text": "Q all right so we want to keep track of both user responses and uh the",
    "start": "1812640",
    "end": "1819040"
  },
  {
    "text": "[Music] um okay I hit uh so we'll stop",
    "start": "1819040",
    "end": "1826559"
  },
  {
    "text": "here I was that was going to crash my computer again switching from presentation mode to non-presentation",
    "start": "1826559",
    "end": "1832320"
  },
  {
    "text": "mode that wouldn't be good all right so I've redone",
    "start": "1832320",
    "end": "1838640"
  },
  {
    "text": "that and now I'll say what is the height of Mount",
    "start": "1839679",
    "end": "1845960"
  },
  {
    "text": "Everest and how tall is that in",
    "start": "1847919",
    "end": "1852799"
  },
  {
    "text": "feet so now we've maintained State and so that uh that makes the app a little",
    "start": "1853799",
    "end": "1859279"
  },
  {
    "text": "bit more useful okay but this is going against uh",
    "start": "1859279",
    "end": "1864720"
  },
  {
    "text": "you know public data right and public data that was probably trained like a year ago what if you want to go against",
    "start": "1864720",
    "end": "1871480"
  },
  {
    "text": "your own data so let's all right let's go find my um my",
    "start": "1871480",
    "end": "1878919"
  },
  {
    "text": "deck",
    "start": "1878919",
    "end": "1881919"
  },
  {
    "text": "oh wait no",
    "start": "1890720",
    "end": "1893360"
  },
  {
    "text": "that's wrong one all",
    "start": "1898639",
    "end": "1902679"
  },
  {
    "text": "right okay so that was an example of the completions API and then I showed you how to maintain state so",
    "start": "1907440",
    "end": "1915120"
  },
  {
    "text": "now we want to use live data and so now we're going to use something called GPT functions I think they're renaming it to",
    "start": "1915120",
    "end": "1921840"
  },
  {
    "text": "tools on the consumer site these are plugins but on the backend site uh their",
    "start": "1921840",
    "end": "1927039"
  },
  {
    "text": "functions and so you can describe functions that you're making available",
    "start": "1927039",
    "end": "1932080"
  },
  {
    "text": "to GPT and then the model will intelligently choose when it a function",
    "start": "1932080",
    "end": "1937440"
  },
  {
    "text": "should be called versus it should respond and then it'll output adjacent object and send it to you and saying hey",
    "start": "1937440",
    "end": "1943639"
  },
  {
    "text": "I this user is asking for this information let's say they're asking for the weather I've parsed it here's the Json format",
    "start": "1943639",
    "end": "1950480"
  },
  {
    "text": "you know City and you know whatever and then you it's on you or your app to",
    "start": "1950480",
    "end": "1956080"
  },
  {
    "text": "actually do the logic and then return a Jason response with the answer and then it summarizes it okay so um this is what",
    "start": "1956080",
    "end": "1966039"
  },
  {
    "text": "a payload for a function looks or this is what the definition for a function looks like uh this is a simple",
    "start": "1966039",
    "end": "1972039"
  },
  {
    "text": "arithmetic function where you know the description so we give it a name that's",
    "start": "1972039",
    "end": "1978080"
  },
  {
    "text": "how we reference it we give it a description and the description is a prompt it's going to that prompt",
    "start": "1978080",
    "end": "1984279"
  },
  {
    "text": "determines whether oh hands",
    "start": "1984279",
    "end": "1988000"
  },
  {
    "text": "up I'm sorry could you say that louder oh yeah it's not a pre-trained",
    "start": "1990360",
    "end": "1996480"
  },
  {
    "text": "thing so a lot of times when people think I want my own data in there uh they think I have to train the GPT",
    "start": "1996480",
    "end": "2002519"
  },
  {
    "text": "training is very expensive and this is a way that where you don't have to train uh the model with your own data but you",
    "start": "2002519",
    "end": "2009880"
  },
  {
    "text": "can still give it access to your data uh so we're going to start with a really simple example and then I'll get into a",
    "start": "2009880",
    "end": "2015480"
  },
  {
    "text": "more complex example so here I'm saying hey look you know instead of you making up uh BS answers to math problems uh I'm",
    "start": "2015480",
    "end": "2023960"
  },
  {
    "text": "going to make available an arithmetic function the description is a prompt so like that you got to be really careful",
    "start": "2023960",
    "end": "2030039"
  },
  {
    "text": "about how you write that prompt but when it uh that prompt determines whether or not this function is supposed to be called or not and then you describe all",
    "start": "2030039",
    "end": "2036960"
  },
  {
    "text": "the parameters well we we've got a left operation and a right the left is a",
    "start": "2036960",
    "end": "2042080"
  },
  {
    "text": "number you know the left operan the operation and the right operation and all of those descriptions are prompts",
    "start": "2042080",
    "end": "2049760"
  },
  {
    "text": "and then at the very end we say what parameters are required and and in this case all of them so I'm going to go back",
    "start": "2049760",
    "end": "2058320"
  },
  {
    "text": "to the code and we're going to implement this function now the first time I did this I took that Json format I posted in",
    "start": "2058320",
    "end": "2065560"
  },
  {
    "text": "gbt and I said uh write this as a c sharp Anonymous object spit it all out and I was able to just put it in there",
    "start": "2065560",
    "end": "2071638"
  },
  {
    "text": "it was really cool but now we're going to do it the hard way",
    "start": "2071639",
    "end": "2078079"
  },
  {
    "text": "well hardish way so here's the completions API we have this property",
    "start": "2078079",
    "end": "2083398"
  },
  {
    "text": "called functions and that's where we're going to put our all our definitions rather than watch me do that I'm going",
    "start": "2083399",
    "end": "2090040"
  },
  {
    "text": "to you know use unfortunately I can't do do that in",
    "start": "2090040",
    "end": "2096280"
  },
  {
    "text": "there so I've got to cut and past but I I'll show you what I did in a",
    "start": "2096280",
    "end": "2101839"
  },
  {
    "text": "second so this function function it takes a list of function definitions and",
    "start": "2101839",
    "end": "2107680"
  },
  {
    "text": "right now we're only going to have one arithmetic and as you can see here it looks just like that Json format more or",
    "start": "2107680",
    "end": "2115240"
  },
  {
    "text": "less now writer here is is trying to optimize my code so I'll extract that to a static read only field fine um and now",
    "start": "2115240",
    "end": "2124680"
  },
  {
    "text": "that function is available",
    "start": "2124680",
    "end": "2128599"
  },
  {
    "text": "no oh my goodness what is going on I blame",
    "start": "2129760",
    "end": "2139200"
  },
  {
    "text": "Ryder all right sorry about that",
    "start": "2139200",
    "end": "2143359"
  },
  {
    "text": "shoot it keeps freezing up I don't know why this is happening okay so I I'll just have to",
    "start": "2147640",
    "end": "2153079"
  },
  {
    "text": "talk through that so the next step is when you",
    "start": "2153079",
    "end": "2158200"
  },
  {
    "text": "when we call the completions API if I ask question like how tall is Mount Everest it's going to return a response",
    "start": "2158200",
    "end": "2164000"
  },
  {
    "text": "of type with the role assistant but if I say multiply two numbers it's going to",
    "start": "2164000",
    "end": "2169640"
  },
  {
    "text": "return a response with a role of function and the response is going to be a Json object or Json text and then I",
    "start": "2169640",
    "end": "2177440"
  },
  {
    "text": "have to parse that and then I have to uh take that or take that call it will be",
    "start": "2177440",
    "end": "2184400"
  },
  {
    "text": "in this case like you know U operand is mult the left is this number the right",
    "start": "2184400",
    "end": "2189680"
  },
  {
    "text": "is that number okay I'm going to not go into",
    "start": "2189680",
    "end": "2194720"
  },
  {
    "text": "presentation mode on writer and see if that like keeps it from crashing um I",
    "start": "2194720",
    "end": "2200440"
  },
  {
    "text": "really apologize for this I've practiced this multiple times but uh never had it crash like",
    "start": "2200440",
    "end": "2207280"
  },
  {
    "text": "this C should have Ed vs code yeah you know",
    "start": "2208400",
    "end": "2214000"
  },
  {
    "text": "maybe right what was that command option Escape",
    "start": "2214000",
    "end": "2221440"
  },
  {
    "text": "command option Escape yeah for what to force quit oh command option Escape",
    "start": "2221440",
    "end": "2228440"
  },
  {
    "text": "okay well it's weird because I couldn't even tab away to the different applications but command option Escape",
    "start": "2228440",
    "end": "2235880"
  },
  {
    "text": "I'll try that next time let's hope there's not enough time like I'll try that next time",
    "start": "2235880",
    "end": "2244800"
  },
  {
    "text": "yeah this tells me it's a really bad crash because like it didn't even like close out my overmind socket",
    "start": "2251839",
    "end": "2259119"
  },
  {
    "text": "so okay we're running we're running all [Music]",
    "start": "2260640",
    "end": "2266560"
  },
  {
    "text": "right let me just zoom in the oldfashioned",
    "start": "2266560",
    "end": "2271680"
  },
  {
    "text": "way okay so now we get this response we we've got to check that response uh for",
    "start": "2271680",
    "end": "2278440"
  },
  {
    "text": "being a function call right so uh AI oh actually we've got to implement",
    "start": "2278440",
    "end": "2285760"
  },
  {
    "text": "the function call first right so",
    "start": "2285760",
    "end": "2289920"
  },
  {
    "text": "ai8 oh no that that was the right place so",
    "start": "2291440",
    "end": "2296880"
  },
  {
    "text": "response okay so you notice here if the response Choice finish reason is a function call we're going to call this",
    "start": "2300640",
    "end": "2306480"
  },
  {
    "text": "call function a sync so let's I'm going to do that as a local method so it has access to all the contacts we need so",
    "start": "2306480",
    "end": "2313760"
  },
  {
    "text": "let's see [Music]",
    "start": "2313760",
    "end": "2317530"
  },
  {
    "text": "AI import all the missing rest so it takes a chat",
    "start": "2322720",
    "end": "2327920"
  },
  {
    "text": "message it grabs the function call information it deserializes that into my",
    "start": "2327920",
    "end": "2334280"
  },
  {
    "text": "arithmetic arguments and this is what you would expect it to be um left operation right and then I have",
    "start": "2334280",
    "end": "2341720"
  },
  {
    "text": "this optional answer and then I just call this method I'm the one who's calling it right like gbt doesn't call",
    "start": "2341720",
    "end": "2347400"
  },
  {
    "text": "any code for you now the important part is I get this result right I call the",
    "start": "2347400",
    "end": "2352760"
  },
  {
    "text": "function I get this result I've got to pass that back into GPT and so I",
    "start": "2352760",
    "end": "2357960"
  },
  {
    "text": "serialize that the arguments with the new result and then I uh send that as a chat",
    "start": "2357960",
    "end": "2365280"
  },
  {
    "text": "message with the RO function and then I call the completions API again and then",
    "start": "2365280",
    "end": "2370440"
  },
  {
    "text": "it will summarize it so if I did everything right",
    "start": "2370440",
    "end": "2375759"
  },
  {
    "text": "here give it a",
    "start": "2377720",
    "end": "2381200"
  },
  {
    "text": "moment now when I ask it to",
    "start": "2386560",
    "end": "2390680"
  },
  {
    "text": "multiply let's see uh",
    "start": "2393480",
    "end": "2398359"
  },
  {
    "text": "[Music] we'll just take my word for it okay we're",
    "start": "2398590",
    "end": "2404680"
  },
  {
    "text": "waiting let's see what did I miss oh got a null reference what happened",
    "start": "2404680",
    "end": "2410839"
  },
  {
    "text": "here message content razor line 19 uh oh let's try this again one more",
    "start": "2416400",
    "end": "2423440"
  },
  {
    "text": "time feel like demo failures tend to have a compounding interest right so",
    "start": "2425000",
    "end": "2430960"
  },
  {
    "text": "okay uh how tall is Mount Everest oh the other thing that I did that's kind of neat is um okay so you",
    "start": "2430960",
    "end": "2439480"
  },
  {
    "text": "notice here on the right it says the message address me I'll try to respond I got a response it should show up in chat",
    "start": "2439480",
    "end": "2445560"
  },
  {
    "text": "so one of the cool things with uh Blazer is that you have this Outlet where you can invoke you know um apis in the",
    "start": "2445560",
    "end": "2451880"
  },
  {
    "text": "browser and so uh I use signal R to send a thought anytime the AI is doing",
    "start": "2451880",
    "end": "2458640"
  },
  {
    "text": "something and then I use Blazer to send that to the console log so that I can",
    "start": "2458640",
    "end": "2464079"
  },
  {
    "text": "kind of see what's going on right so now if I say ai.",
    "start": "2464079",
    "end": "2469280"
  },
  {
    "text": "multiply we see the it says oh look I know a function that can help arithmetic",
    "start": "2469280",
    "end": "2475079"
  },
  {
    "text": "left this right that and then um blazer. web.js throws a message uh a failure so",
    "start": "2475079",
    "end": "2483440"
  },
  {
    "text": "that message content line 19",
    "start": "2483440",
    "end": "2490838"
  },
  {
    "text": "let's oh you know what I'm gonna just get rid of this this is uh starting",
    "start": "2496040",
    "end": "2502440"
  },
  {
    "text": "next let's try that that is really weird this is",
    "start": "2502440",
    "end": "2509400"
  },
  {
    "text": "working just earlier it's what every speaker says I swear this is working five minutes ago",
    "start": "2509400",
    "end": "2516400"
  },
  {
    "text": "okay one last try this is worth it if I can get it to work let's",
    "start": "2516400",
    "end": "2523400"
  },
  {
    "text": "see okay so anyways it you notice here it selected the right function we call",
    "start": "2527040",
    "end": "2533000"
  },
  {
    "text": "that function oh wait a minute I think I know I think I",
    "start": "2533000",
    "end": "2538520"
  },
  {
    "text": "know so if",
    "start": "2539559",
    "end": "2543960"
  },
  {
    "text": "you know I'm going to skip ahead I I have a backup plan so luckily I do everything in GitHub so I'm going to",
    "start": "2548240",
    "end": "2554760"
  },
  {
    "text": "just skip ahead to um change branches right we'll save this",
    "start": "2554760",
    "end": "2560280"
  },
  {
    "text": "Branch so I can debug that later get Co main now I'm going [Music]",
    "start": "2560280",
    "end": "2566400"
  },
  {
    "text": "to I'm going to run this and I'm going to skip ahead to um",
    "start": "2566400",
    "end": "2573960"
  },
  {
    "text": "the issue with all that is like that's a lot of work to define a function right so I wrote a little function framework",
    "start": "2573960",
    "end": "2580559"
  },
  {
    "text": "CU I'm a framework person um there's some of the uh other client libraries",
    "start": "2580559",
    "end": "2585720"
  },
  {
    "text": "have function Frameworks but the idea is you know we should be figuring this all",
    "start": "2585720",
    "end": "2591160"
  },
  {
    "text": "out with reflection right and so I have a set of chat functions here for example",
    "start": "2591160",
    "end": "2596359"
  },
  {
    "text": "the weather function right so the weather function uh if you implement my",
    "start": "2596359",
    "end": "2602960"
  },
  {
    "text": "chat function you specify the arguments and the results uh it will do all of",
    "start": "2602960",
    "end": "2608119"
  },
  {
    "text": "that function definition generation for you and then all you have to do is uh Implement invoke a sync and what's going",
    "start": "2608119",
    "end": "2615480"
  },
  {
    "text": "to happen there is um oh I'm already over time okay I'll wrap this up real quick so now I can call the weather API",
    "start": "2615480",
    "end": "2623200"
  },
  {
    "text": "so I can do something [Music]",
    "start": "2623200",
    "end": "2627819"
  },
  {
    "text": "like oh I have 15 minutes",
    "start": "2633760",
    "end": "2638559"
  },
  {
    "text": "oh okay",
    "start": "2638920",
    "end": "2642799"
  },
  {
    "text": "let's thank you eron have plenty more time okay so what is the weather in",
    "start": "2644480",
    "end": "2651760"
  },
  {
    "text": "Sydney and what we'll see here is okay now it's working right so I got",
    "start": "2653800",
    "end": "2659359"
  },
  {
    "text": "a function to call the result I'll send it it back to GPT to summarize so uh so",
    "start": "2659359",
    "end": "2667160"
  },
  {
    "text": "when I said the what is the weather in Sydney first we get get current weather it determined oh you need to call the",
    "start": "2667160",
    "end": "2672599"
  },
  {
    "text": "get current weather function that's one of the functions available here's the arguments location Sydney and then I",
    "start": "2672599",
    "end": "2678760"
  },
  {
    "text": "called or my app called the API with those arguments and it got back uh this",
    "start": "2678760",
    "end": "2684440"
  },
  {
    "text": "uh Json object temperature this unit Fahrenheit and then I summarize that I take that and I pass it back in gbt and",
    "start": "2684440",
    "end": "2690960"
  },
  {
    "text": "then it gives me a nice natural language response now where things got get really",
    "start": "2690960",
    "end": "2696400"
  },
  {
    "text": "cool is you can chain these functions together and it took me a while to realize that so for example I have",
    "start": "2696400",
    "end": "2702400"
  },
  {
    "text": "another function that can store information about uh me so for example",
    "start": "2702400",
    "end": "2708359"
  },
  {
    "text": "uh I live oops let's see uh I live in Belleview",
    "start": "2708359",
    "end": "2716599"
  },
  {
    "text": "Washington it's not a question and it says I know a function",
    "start": "2716599",
    "end": "2721680"
  },
  {
    "text": "that can help store user fact so it's storing this fact about me and now if I say something like uh oh I'm going to",
    "start": "2721680",
    "end": "2728160"
  },
  {
    "text": "have to clear its cache because the fact that I live in Belleview is now in the message history so we're going to",
    "start": "2728160",
    "end": "2733960"
  },
  {
    "text": "restart it so that's all cleared uh the message history does not know where I live right so if I go here",
    "start": "2733960",
    "end": "2740880"
  },
  {
    "text": "and I say uh what is the weather where I",
    "start": "2740880",
    "end": "2745960"
  },
  {
    "text": "live so the first thing it's going to determine is well I need to know where you live right so it calls another",
    "start": "2745960",
    "end": "2752400"
  },
  {
    "text": "function I have retrieve user fact and it says um you know where do I live and",
    "start": "2752400",
    "end": "2758520"
  },
  {
    "text": "and and you notice here I added a my own parameter justification so that I can see why is it choosing that so I'm",
    "start": "2758520",
    "end": "2764760"
  },
  {
    "text": "trying to obtain the location to use it in getting the weather and now it got that and it said oh well now that I had",
    "start": "2764760",
    "end": "2771119"
  },
  {
    "text": "the location I need to call another function the weather function and then finally it says the current weather in",
    "start": "2771119",
    "end": "2776680"
  },
  {
    "text": "bellie Washington is 44 and 85 degrees right what was really interesting is so",
    "start": "2776680",
    "end": "2783680"
  },
  {
    "text": "in that code that I showed you earlier where",
    "start": "2783680",
    "end": "2790200"
  },
  {
    "text": "um originally I had this as an if you know if response Choice finish reason",
    "start": "2790200",
    "end": "2795400"
  },
  {
    "text": "equals uh function call and I was trying to do this demo and it was failing and I",
    "start": "2795400",
    "end": "2801520"
  },
  {
    "text": "was like what's going on here and I realized oh when it calls a function uh it could result in another function call",
    "start": "2801520",
    "end": "2808720"
  },
  {
    "text": "and I just assumed there was only a single function so I went in and I changed this if to a while and suddenly",
    "start": "2808720",
    "end": "2814280"
  },
  {
    "text": "chaining starts to work and that chaining is really powerful I can do some really interesting things like this",
    "start": "2814280",
    "end": "2820559"
  },
  {
    "text": "uh just off of a single function so it can also chain the same function so for",
    "start": "2820559",
    "end": "2825880"
  },
  {
    "text": "example uh let me look at what I have stored because I'm I started yeah I",
    "start": "2825880",
    "end": "2832480"
  },
  {
    "text": "better uh delete delete delete delete I have all this",
    "start": "2832480",
    "end": "2839640"
  },
  {
    "text": "okay that's pre-existing stuff in here so let's go back here so for example I'm",
    "start": "2839640",
    "end": "2845800"
  },
  {
    "text": "gonna say and this is where like uh the probabilistic nature sometimes this is one I expect might work might not work",
    "start": "2845800",
    "end": "2852760"
  },
  {
    "text": "but I worked with David",
    "start": "2852760",
    "end": "2858240"
  },
  {
    "text": "foul it's gonna store that it says David foul",
    "start": "2858280",
    "end": "2865240"
  },
  {
    "text": "works with h chelman and then",
    "start": "2865240",
    "end": "2872160"
  },
  {
    "text": "chelman works with Scott goo and",
    "start": "2872160",
    "end": "2878400"
  },
  {
    "text": "Scott goo's name is Scott Guthrie okay so I've stored all this",
    "start": "2878400",
    "end": "2885839"
  },
  {
    "text": "information about multiple different users so I'm going I need to",
    "start": "2885839",
    "end": "2892040"
  },
  {
    "text": "restart I thought about just cheating and just doing it right there because it already has that context but let's let's",
    "start": "2892040",
    "end": "2897400"
  },
  {
    "text": "do it right and then I'll show you how it's working under the",
    "start": "2897400",
    "end": "2901319"
  },
  {
    "text": "hood okay so now I'm going to ask a question",
    "start": "2902440",
    "end": "2908440"
  },
  {
    "text": "so I said please trace my work Network until you run out of people or answer the question is Scott Guthrie in my work",
    "start": "2909240",
    "end": "2915599"
  },
  {
    "text": "uh work Network and now you're seeing it's actually tracing the relationships",
    "start": "2915599",
    "end": "2920839"
  },
  {
    "text": "that I have and it failed um this",
    "start": "2920839",
    "end": "2925880"
  },
  {
    "text": "doesn't always work but I now I can prompt it though um you know about Scott",
    "start": "2925880",
    "end": "2935400"
  },
  {
    "text": "let's see what or I should say what do you know",
    "start": "2938040",
    "end": "2945319"
  },
  {
    "text": "about so this is the latest thing I've been working on and it's a little tricky I think I'm going to actually model",
    "start": "2947799",
    "end": "2953319"
  },
  {
    "text": "these relationships in the database um but oh so when I did uh yeah it didn't",
    "start": "2953319",
    "end": "2961440"
  },
  {
    "text": "it yeah it didn't pick this up so I'll show you the prompt that I'm using it should have stor store that as",
    "start": "2961440",
    "end": "2967440"
  },
  {
    "text": "a um so I have this long description it should store that fact about hansan with",
    "start": "2967440",
    "end": "2973520"
  },
  {
    "text": "the handlan user so you know store information about a person when they make declarative statements you know",
    "start": "2973520",
    "end": "2979559"
  },
  {
    "text": "recognize this username uh format and now this is the case where like sometimes it works amazingly sometimes",
    "start": "2979559",
    "end": "2985760"
  },
  {
    "text": "it doesn't um the important thing here is okay well",
    "start": "2985760",
    "end": "2992599"
  },
  {
    "text": "I'm storing information how am I storing this information well GPT has an API for",
    "start": "2992599",
    "end": "2998440"
  },
  {
    "text": "creating embeddings so if you recall embeddings are uh like contain a lot of information",
    "start": "2998440",
    "end": "3005520"
  },
  {
    "text": "kind of semantic information about the the text that you're or the prompt so in this case I'm calling a different API",
    "start": "3005520",
    "end": "3011520"
  },
  {
    "text": "called the get embeddings and I'm setting the fact as the prompt and what",
    "start": "3011520",
    "end": "3017079"
  },
  {
    "text": "that's going to do let me switch back to my slides oh",
    "start": "3017079",
    "end": "3025480"
  },
  {
    "text": "okay so it's going to post to this API the V1 embeddings and it's the input and",
    "start": "3038400",
    "end": "3043440"
  },
  {
    "text": "a model and in this case you want to pick a model that's appropriate for embeddings so uh at the time text-",
    "start": "3043440",
    "end": "3050000"
  },
  {
    "text": "embedding das-2 but now there's a newer one I think that they recommend and that's going to produce this uh big",
    "start": "3050000",
    "end": "3056720"
  },
  {
    "text": "payload but let's uh zoom into the relevant part this embedding remember I mentioned those vectors like a thousand",
    "start": "3056720",
    "end": "3063119"
  },
  {
    "text": "or 40 or 14,000 number vectors this is an embedding it's basically a vector",
    "start": "3063119",
    "end": "3070200"
  },
  {
    "text": "pointing off into some higher dimensional space the cool thing is if you have two embeddings you can compare",
    "start": "3070200",
    "end": "3076799"
  },
  {
    "text": "them uh using cosine similarity now I know all I don't need to explain this to",
    "start": "3076799",
    "end": "3081839"
  },
  {
    "text": "you everybody here remembers all their High School trigonometry but for my own benefit I'll just remind you if you have",
    "start": "3081839",
    "end": "3088319"
  },
  {
    "text": "two vectors and they're at the same angle that cosine is um or cosine of 0",
    "start": "3088319",
    "end": "3094680"
  },
  {
    "text": "degrees is one right if you have two vectors that are orthogonal to each other or 90 degrees angle that Vector",
    "start": "3094680",
    "end": "3101440"
  },
  {
    "text": "that cosine of that angle is zero um so",
    "start": "3101440",
    "end": "3106559"
  },
  {
    "text": "the cosine of 90 deg Z cosine of 0 is one and then anything in between is a number between zero and one and it turns",
    "start": "3106559",
    "end": "3113000"
  },
  {
    "text": "out if you have two prompts uh let's say a fact and then the question about the fact and you take the co the you get the",
    "start": "3113000",
    "end": "3120040"
  },
  {
    "text": "embedding for each of those you end up with two vectors pointing off into space right if they're really close together",
    "start": "3120040",
    "end": "3125839"
  },
  {
    "text": "they're highly related if they're really far apart they're not and so you can then use a a cosine similarity function",
    "start": "3125839",
    "end": "3133839"
  },
  {
    "text": "to determine that and uh originally I wrote it in C but I then you have to like pull every single record out of the",
    "start": "3133839",
    "end": "3140280"
  },
  {
    "text": "database and compare them that sucks but it turns out that uh if you use postgress and PG",
    "start": "3140280",
    "end": "3147520"
  },
  {
    "text": "Vector uh you can let me show the retrieve user fact",
    "start": "3147520",
    "end": "3152559"
  },
  {
    "text": "function so I I can store vectors in postgress and then I use um with npgsql",
    "start": "3152559",
    "end": "3160359"
  },
  {
    "text": "ef core and postgress with PG Vector I can do this and this is this query right",
    "start": "3160359",
    "end": "3166480"
  },
  {
    "text": "there that select that is evaluated on the database server sorry",
    "start": "3166480",
    "end": "3172599"
  },
  {
    "text": "what oh oh yeah yeah yeah sorry about that let's see right that right",
    "start": "3172599",
    "end": "3178440"
  },
  {
    "text": "there let zoom in so that select there the embedding cosine distance that is",
    "start": "3178440",
    "end": "3185799"
  },
  {
    "text": "being evaluated on the server and what I'm doing here is I'm saying grab all the facts where the uh and cosine",
    "start": "3185799",
    "end": "3193480"
  },
  {
    "text": "distance is less than 0.25 now that number I just kind of I wanted something pretty related but I",
    "start": "3193480",
    "end": "3199680"
  },
  {
    "text": "wanted to give it room to you know find it right like you can go 0. n you can go0 seven if you go too low it it'll",
    "start": "3199680",
    "end": "3207480"
  },
  {
    "text": "return a lot of random info if you go too high it never returns anything so that is more of feeling it out in your",
    "start": "3207480",
    "end": "3213839"
  },
  {
    "text": "application but this is the way that if you have like information in your databases you want people to be able to",
    "start": "3213839",
    "end": "3219599"
  },
  {
    "text": "use natural language to query it you're going to end up doing something like this um what I'm trying to do again is I",
    "start": "3219599",
    "end": "3227240"
  },
  {
    "text": "want to create something useful like I I find most llm applications are not that useful yet and so I'm trying to build",
    "start": "3227240",
    "end": "3233400"
  },
  {
    "text": "something that's actually useful to me where I can store information about my family and then when it's someone's birthday I can just ask gbt like what",
    "start": "3233400",
    "end": "3239760"
  },
  {
    "text": "should I get my son for his birthday and so far it's working pretty well um the whole network thing you know oh who's in",
    "start": "3239760",
    "end": "3246040"
  },
  {
    "text": "my work Network that was just seeing how far I could take it and sometimes you have to trust me it works all right so",
    "start": "3246040",
    "end": "3253799"
  },
  {
    "text": "the last thing I want to show let see where am I",
    "start": "3253799",
    "end": "3258920"
  },
  {
    "text": "at okay so then the assistance API now this is a new beta API but it allows you",
    "start": "3258920",
    "end": "3265599"
  },
  {
    "text": "to build a set of domain specific assistance within an application and they can leverage models tools and",
    "start": "3265599",
    "end": "3273200"
  },
  {
    "text": "knowledge to respond to user queries so basically you can build your own",
    "start": "3273200",
    "end": "3279000"
  },
  {
    "text": "clippy let's see this API is a little tricky to to",
    "start": "3279000",
    "end": "3285079"
  },
  {
    "text": "use so if you see here you have you you have to upload files you create an",
    "start": "3285079",
    "end": "3290119"
  },
  {
    "text": "assistant you create a thread you post messages to the thread and then you run the assistant against that thread and",
    "start": "3290119",
    "end": "3297160"
  },
  {
    "text": "then you have to pull the assistant for a response so kind of complicated but I'll show you I'll show it to you in",
    "start": "3297160",
    "end": "3303240"
  },
  {
    "text": "action so you can see why it's really interesting so I have a whole in my site",
    "start": "3303240",
    "end": "3309559"
  },
  {
    "text": "I have a whole thing for creating all these assistants oh yeah yeah yeah thank you",
    "start": "3309559",
    "end": "3316200"
  },
  {
    "text": "so uh I'm not going to go through the whole process but basically if I have a PDF file or some file with information I",
    "start": "3316200",
    "end": "3322720"
  },
  {
    "text": "can create assistant with that file and now I have a new domain specific spe ific assistant so what I wanted to do is",
    "start": "3322720",
    "end": "3328839"
  },
  {
    "text": "I just moved into apartment not too long ago and I looked at the lease it's this big long you know legal lease and I was",
    "start": "3328839",
    "end": "3335160"
  },
  {
    "text": "like I I I don't want to read this whole thing so I uploaded the lease to uh my",
    "start": "3335160",
    "end": "3340559"
  },
  {
    "text": "assistant here and I created a Leisa assistant poot and now I can ask it questions like uh can I have pets in my",
    "start": "3340559",
    "end": "3351079"
  },
  {
    "text": "apartment and this API is in beta it's a big slow you can see I have to pull and",
    "start": "3351280",
    "end": "3359599"
  },
  {
    "text": "so around the fourth poll if I haven't gotten an answer yet I tell the bot just send tell the user that you're thinking",
    "start": "3359599",
    "end": "3366599"
  },
  {
    "text": "um so it's pulling pulling and now I get this according to the lease pets are generally not allowed yada yada but",
    "start": "3366599",
    "end": "3372920"
  },
  {
    "text": "what's really cool here is I get this um little uh book footnote that",
    "start": "3372920",
    "end": "3380599"
  },
  {
    "text": "references the specific place in the document where it got that information so you know unlike when you're using a",
    "start": "3380599",
    "end": "3386880"
  },
  {
    "text": "consumer gbt and you're like I've told it like oh write U Write a response to",
    "start": "3386880",
    "end": "3392000"
  },
  {
    "text": "this and cite your references what does it do it cites references but it generates those references so you go to",
    "start": "3392000",
    "end": "3398039"
  },
  {
    "text": "the references they don't exist it just makes them up but here because I have a set of files that I made available to",
    "start": "3398039",
    "end": "3404559"
  },
  {
    "text": "the assistant it can specifically reference where in that file it got that",
    "start": "3404559",
    "end": "3410280"
  },
  {
    "text": "answer so this is really useful and I'm basically have now a factory for creating assistance so found the the a",
    "start": "3410280",
    "end": "3419280"
  },
  {
    "text": "PDF with the rules of Uno and I was like okay now I have a Uno assistant and uh",
    "start": "3419280",
    "end": "3425440"
  },
  {
    "text": "can you stack a draw four on a draw four and what do you",
    "start": "3425440",
    "end": "3431799"
  },
  {
    "text": "think yeah of course not you can't but everyone plays that way and the assistant knows enough to say oh so I uh",
    "start": "3431799",
    "end": "3442480"
  },
  {
    "text": "I was playing around with and I changed the system prompt to be Talk Like a Pirate",
    "start": "3442480",
    "end": "3448160"
  },
  {
    "text": "so the next Buccaneer must draw four cards four for return turn but uh it",
    "start": "3448440",
    "end": "3453880"
  },
  {
    "text": "notes that you know like oh in some quarters you know like basically house rules most people allow you to do it",
    "start": "3453880",
    "end": "3459359"
  },
  {
    "text": "right um but yeah so this this API is really cool and this shows one of the",
    "start": "3459359",
    "end": "3465720"
  },
  {
    "text": "things about setting things up in a separate uh what I call consumer message",
    "start": "3465720",
    "end": "3471440"
  },
  {
    "text": "consumer is to use this API in my app I just need",
    "start": "3471440",
    "end": "3476880"
  },
  {
    "text": "to send a a message right uh and it's the uh",
    "start": "3476880",
    "end": "3482480"
  },
  {
    "text": "assistant this consumer is doing all the hard work of like okay create a new",
    "start": "3484960",
    "end": "3490559"
  },
  {
    "text": "message create a run and then start doing this uh polling you know while I",
    "start": "3490559",
    "end": "3496720"
  },
  {
    "text": "don't have a response keep polling that run to get the response so this um and",
    "start": "3496720",
    "end": "3503880"
  },
  {
    "text": "then if the Run stat if you get a response but the status could be a",
    "start": "3503880",
    "end": "3509079"
  },
  {
    "text": "function call so now um I have to handle that so this one is a lot more tricky to",
    "start": "3509079",
    "end": "3515680"
  },
  {
    "text": "use um but if you clone this repo it's all right there and you can",
    "start": "3515680",
    "end": "3520720"
  },
  {
    "text": "tweak it and make it useful now one of the cool things remember before I said oh you know you have to manage the",
    "start": "3520720",
    "end": "3526680"
  },
  {
    "text": "history of the messages yourself well with u with this API the the history of",
    "start": "3526680",
    "end": "3532880"
  },
  {
    "text": "the messages is actually persisted right you create a thread you post messages to that thread they're persisting that and",
    "start": "3532880",
    "end": "3539480"
  },
  {
    "text": "behind the scenes they're doing the compaction that I talked about if the thread gets too long they'll compact",
    "start": "3539480",
    "end": "3545160"
  },
  {
    "text": "that they'll maintain that because you know they still you're still going to run into the token limits uh I don't",
    "start": "3545160",
    "end": "3550559"
  },
  {
    "text": "know what the pricing for this is yet this is a beta so I think they're they are still figuring it out but um really",
    "start": "3550559",
    "end": "3557920"
  },
  {
    "text": "interesting way of uh generating assistance for your application so so",
    "start": "3557920",
    "end": "3563240"
  },
  {
    "text": "that was the assistance API one key thing if you're going to call this API you need to add this header open ai-",
    "start": "3563240",
    "end": "3569200"
  },
  {
    "text": "Beta assistance equals V1 um otherwise it just doesn't work okay so a lot of",
    "start": "3569200",
    "end": "3575680"
  },
  {
    "text": "what I talked about uh these are some resources I'll try to send them out later um one of the my favorite",
    "start": "3575680",
    "end": "3581559"
  },
  {
    "text": "resources is the Wolfram article like what is chat GPT doing and why does it work it's great if you really want to",
    "start": "3581559",
    "end": "3587920"
  },
  {
    "text": "understand kind of under the hood how it works the key thing to note is it's a",
    "start": "3587920",
    "end": "3593520"
  },
  {
    "text": "predictive model it's going to generate bad results but if you really tightly constrain what it's working against you",
    "start": "3593520",
    "end": "3601119"
  },
  {
    "text": "can build pretty useful applications uh in my last company that I started with uh my friend we were building uh we",
    "start": "3601119",
    "end": "3608280"
  },
  {
    "text": "started off doing devops but then we switched to customer success and we were using gbt in a couple different ways one",
    "start": "3608280",
    "end": "3614880"
  },
  {
    "text": "is we would summarize conversations and we were working in chat if people stick",
    "start": "3614880",
    "end": "3620039"
  },
  {
    "text": "to a thread it's kind of nice because then you can say oh is this conversation done did their issues get resolved",
    "start": "3620039",
    "end": "3626480"
  },
  {
    "text": "but what happens is in the real world people are messy and they're just throwing messages at all levels and we were trying to use GPT to actually you",
    "start": "3626480",
    "end": "3633799"
  },
  {
    "text": "know extract those conversations out because we wanted to be able to answer the question uh is anyone waiting on",
    "start": "3633799",
    "end": "3639640"
  },
  {
    "text": "anything from us is has their issue been resolved uh what's their sentiment and",
    "start": "3639640",
    "end": "3645599"
  },
  {
    "text": "so in that case we were building something that was really useful and we had a few customers who are paying us a",
    "start": "3645599",
    "end": "3650920"
  },
  {
    "text": "lot but uh EV we didn't grow we didn't we couldn't grow it like a you pandemic",
    "start": "3650920",
    "end": "3656880"
  },
  {
    "text": "hit all this stuff happened and so we shut it down um like last October but I",
    "start": "3656880",
    "end": "3662640"
  },
  {
    "text": "could definitely see like the inklings of oh you know gbt and and llms you know",
    "start": "3662640",
    "end": "3668079"
  },
  {
    "text": "can be useful in the right scenario I just don't think we've seen it yet but I think you know soon like using these",
    "start": "3668079",
    "end": "3675039"
  },
  {
    "text": "tools using these apis building it in your own app um hopefully like you can build something that I'll find really",
    "start": "3675039",
    "end": "3681720"
  },
  {
    "text": "useful uh that top URL that's where it is it's a github.com slacked demo uh you know all my stuff is",
    "start": "3681720",
    "end": "3689960"
  },
  {
    "text": "at hacked um and I encourage you to check it out uh submit issues submit PRS",
    "start": "3689960",
    "end": "3696960"
  },
  {
    "text": "let me know what you think I'd love to get your feedback I apologize for the technical issues but I think I was able",
    "start": "3696960",
    "end": "3702160"
  },
  {
    "text": "to get the the gist of what I'm trying to cover and hopefully you find it useful thank",
    "start": "3702160",
    "end": "3708079"
  },
  {
    "text": "you oh any questions I mean we got a little bit of time right yeah",
    "start": "3711160",
    "end": "3717839"
  },
  {
    "text": "um thanks so having played around with semantic kernel a bit uh and the native",
    "start": "3721880",
    "end": "3728559"
  },
  {
    "text": "functions in that uh one of the issues I really ran into was around uh prompts with an arbitrary date",
    "start": "3728559",
    "end": "3736440"
  },
  {
    "text": "like you say today even and then even if I gave it functions for figuring out",
    "start": "3736440",
    "end": "3742799"
  },
  {
    "text": "okay what's the current date it would still try and P in like an actual today",
    "start": "3742799",
    "end": "3748240"
  },
  {
    "text": "token where we're trying to accept date times have you run into anything like that with your playing around using the",
    "start": "3748240",
    "end": "3756319"
  },
  {
    "text": "open AI API directly no I I you know that's a really great question I haven't",
    "start": "3756319",
    "end": "3761359"
  },
  {
    "text": "tried anything with dates yet so that that would be really interesting to see",
    "start": "3761359",
    "end": "3766400"
  },
  {
    "text": "how that responds I mean earlier you mentioned semantic uh colel I haven't played around with Samantha colel mainly",
    "start": "3766400",
    "end": "3771880"
  },
  {
    "text": "because I was uh I was the early because I was we were in y commoner we had Early",
    "start": "3771880",
    "end": "3777359"
  },
  {
    "text": "Access to GPT so it kind of got fully into that ecosystem and when I discovered functions it kind of does a",
    "start": "3777359",
    "end": "3783359"
  },
  {
    "text": "lot of what like Samantha kernel does what Samantha kernel gives you the benefit of is using other models other",
    "start": "3783359",
    "end": "3789000"
  },
  {
    "text": "providers but I was like oh I'm already here I'm just going to use it I do want to play around with it um but I haven't",
    "start": "3789000",
    "end": "3794960"
  },
  {
    "text": "tried the date thing so that's probably something I should add to it to see how it works because what I am starting to",
    "start": "3794960",
    "end": "3800680"
  },
  {
    "text": "do is build out a lot of functions for all these different things that you can't get in gbt so I was starting to",
    "start": "3800680",
    "end": "3806119"
  },
  {
    "text": "build a function for understanding relationships between people for example so when I would say like so and so is my",
    "start": "3806119",
    "end": "3812079"
  },
  {
    "text": "son like that would store that would understand that create both users do do all that rather than trying to have the",
    "start": "3812079",
    "end": "3819039"
  },
  {
    "text": "single retrieve or store user info do everything um starting to break it down",
    "start": "3819039",
    "end": "3825119"
  },
  {
    "text": "into smaller pieces because I think like that's where GPT is really going to be useful is when once you have a",
    "start": "3825119",
    "end": "3831440"
  },
  {
    "text": "collection of functions that can do the things it's really bad at so for example the Ari metic function now with that",
    "start": "3831440",
    "end": "3838160"
  },
  {
    "text": "anytime I ask an a simple arithmetic question it gets it right um the other",
    "start": "3838160",
    "end": "3843279"
  },
  {
    "text": "thing is like I know Wolfram has a GPT plug-in on the consumer side I was going",
    "start": "3843279",
    "end": "3848440"
  },
  {
    "text": "to try to implement it as a a function because I wanted it in my app but that would open a whole world of like",
    "start": "3848440",
    "end": "3855480"
  },
  {
    "text": "possibilities right where any scientific question is going to be accurate right you know when I because I I actually",
    "start": "3855480",
    "end": "3861279"
  },
  {
    "text": "didn't check is you when I asked how tall is Mount Everest I didn't check if that was correct right but uh if I hook",
    "start": "3861279",
    "end": "3866839"
  },
  {
    "text": "that up to um Wolfram I'd have a lot more confidence that's actually correct",
    "start": "3866839",
    "end": "3872520"
  },
  {
    "text": "great question",
    "start": "3872520",
    "end": "3875559"
  },
  {
    "text": "yep users or kind of or group of users okay so the question is when you train",
    "start": "3884960",
    "end": "3890000"
  },
  {
    "text": "the model can you uh like U partition it for different groups of users so so I I",
    "start": "3890000",
    "end": "3896599"
  },
  {
    "text": "didn't do any kind of training and I haven't played around with the training apis mainly because they're slow and",
    "start": "3896599",
    "end": "3901920"
  },
  {
    "text": "they're very expensive um with the functions I I have total control so I",
    "start": "3901920",
    "end": "3907640"
  },
  {
    "text": "can totally do that in fact one of the you didn't see it but when I'm calling the store and retrieve user information",
    "start": "3907640",
    "end": "3914920"
  },
  {
    "text": "I'm passing the current logged in username as one of the arguments to my function and that way I can do any kind",
    "start": "3914920",
    "end": "3920960"
  },
  {
    "text": "of partitioning I could do tency for example and so um I really like the",
    "start": "3920960",
    "end": "3926839"
  },
  {
    "text": "function way of uh giving access to your data over training um I think there are",
    "start": "3926839",
    "end": "3933520"
  },
  {
    "text": "certain aspects where training makes more sense I think for example if you're trying to train a body of um like domain",
    "start": "3933520",
    "end": "3940640"
  },
  {
    "text": "specific General domain specific knowledge like let's say you're building an Aeronautics app you're going to",
    "start": "3940640",
    "end": "3945720"
  },
  {
    "text": "probably want to train it with really good information about like you know Aeronautics and all that stuff um but",
    "start": "3945720",
    "end": "3951480"
  },
  {
    "text": "when I'm want to give it access to like user data I actually don't want to train it with my user data instead I I use",
    "start": "3951480",
    "end": "3958279"
  },
  {
    "text": "functions now when I was using GPT I also was worried about okay well you",
    "start": "3958279",
    "end": "3963599"
  },
  {
    "text": "know do do I trust open AI to have access to user data do my users trust that so we actually used",
    "start": "3963599",
    "end": "3970599"
  },
  {
    "text": "a gosh I forget the Microsoft has an API for doing redaction right so pii",
    "start": "3970599",
    "end": "3976480"
  },
  {
    "text": "redaction so we would do that send it and then get it back and then unreact it",
    "start": "3976480",
    "end": "3982359"
  },
  {
    "text": "for the end user and then we're like why don't we just go to uh Azure GPT because",
    "start": "3982359",
    "end": "3988599"
  },
  {
    "text": "you know if we trust Microsoft to do the redaction and they're sock too we should be able to trust Microsoft to just do",
    "start": "3988599",
    "end": "3994720"
  },
  {
    "text": "the whole thing and so we were starting to do that um but then Microsoft at the time they didn't have the assistance API",
    "start": "3994720",
    "end": "4002039"
  },
  {
    "text": "so it's a trade-off like open eye is always going to have everything first and then ashure is going to follow uh",
    "start": "4002039",
    "end": "4007960"
  },
  {
    "text": "like for example I didn't show but I have access to GPT 4 uh on the the back",
    "start": "4007960",
    "end": "4013480"
  },
  {
    "text": "end and I didn't have that with Azure G so uh that was a long way of not",
    "start": "4013480",
    "end": "4019160"
  },
  {
    "text": "answering your question sorry question back there um so when",
    "start": "4019160",
    "end": "4024520"
  },
  {
    "text": "when we pass in the user data or I'm not sure with assistant and stuff are do we",
    "start": "4024520",
    "end": "4031079"
  },
  {
    "text": "end up consuming tokens every time we pass that could you speak yeah do we end up",
    "start": "4031079",
    "end": "4037680"
  },
  {
    "text": "consuming tokens every time we pass that to Chad GPD oh that's a great question",
    "start": "4037680",
    "end": "4043119"
  },
  {
    "text": "yes yeah so um you are consuming tokens anytime you send information to it so for example",
    "start": "4043119",
    "end": "4049400"
  },
  {
    "text": "you upload that file that file is um it's a good question that so when you",
    "start": "4049400",
    "end": "4054799"
  },
  {
    "text": "upload a file you pay the token at that time um when you make the request uh the",
    "start": "4054799",
    "end": "4060880"
  },
  {
    "text": "all the function definitions that counts to your tokens the at that point the in the assistance API the file is just a",
    "start": "4060880",
    "end": "4068039"
  },
  {
    "text": "reference to a file so that token count for that request is actually small for",
    "start": "4068039",
    "end": "4073520"
  },
  {
    "text": "the file I don't believe you pay the full file size I think that's only paid once but you know in the completions API",
    "start": "4073520",
    "end": "4080279"
  },
  {
    "text": "when I had the function definitions if I have 20 function definitions that's 20",
    "start": "4080279",
    "end": "4085599"
  },
  {
    "text": "definitions worth of tokens for every single request so that is something that you have to consider right so I was",
    "start": "4085599",
    "end": "4092079"
  },
  {
    "text": "starting to work on a in a separate Branch I was going to work on a meta function right so like it's just a",
    "start": "4092079",
    "end": "4098159"
  },
  {
    "text": "single function and then it figures out what function to call and then calls that function so i' I'd only have one",
    "start": "4098159",
    "end": "4104278"
  },
  {
    "text": "function definition but it could handle everything but I haven't gotten around to getting that to work yet um and it's",
    "start": "4104279",
    "end": "4110278"
  },
  {
    "text": "really tricky because like you know if you look at the code you'll see like my store and retrieve user info uh",
    "start": "4110279",
    "end": "4117120"
  },
  {
    "text": "functions those descriptions are really long because they're a prompt so yeah I",
    "start": "4117120",
    "end": "4122440"
  },
  {
    "text": "think you know there's still experimen in this space I think we could I could probably get that to work so that you're",
    "start": "4122440",
    "end": "4128600"
  },
  {
    "text": "not spending so much every request so uh also when you implemented",
    "start": "4128600",
    "end": "4135120"
  },
  {
    "text": "that lease contract stuff and then uh making query to the lease",
    "start": "4135120",
    "end": "4141758"
  },
  {
    "text": "contract when you implemented that lease contract to your lease oh the lease oh yeah yeah the lease thing yeah so when",
    "start": "4141759",
    "end": "4148920"
  },
  {
    "text": "you implemented that uh so it's just like one off thing it brings in token and then you do cosign uh oh so with the",
    "start": "4148920",
    "end": "4157679"
  },
  {
    "text": "lease so you remember that that the cosign simulator that was when I was using the chat completions API when I",
    "start": "4157679",
    "end": "4162960"
  },
  {
    "text": "needed full control and then they came out with the assistance API I don't have to do any of that it's basically",
    "start": "4162960",
    "end": "4169679"
  },
  {
    "text": "everything I did earlier it's doing behind the scenes so you upload a PDF file it scans it tokenizes it creates an",
    "start": "4169679",
    "end": "4177159"
  },
  {
    "text": "embedding or a set of embeddings for that entire file and then when I ask questions it's doing cosine similarity",
    "start": "4177159",
    "end": "4184120"
  },
  {
    "text": "I'll be out here in a minute so if anyone has more questions um you know come find me thank you",
    "start": "4184120",
    "end": "4192238"
  }
]
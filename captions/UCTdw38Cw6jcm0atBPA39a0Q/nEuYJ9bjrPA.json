[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "good morning everyone few people still trickling in everyone",
    "start": "3859",
    "end": "9030"
  },
  {
    "text": "having a good conference so far excellent first I just want to say it's",
    "start": "9030",
    "end": "15030"
  },
  {
    "text": "an absolute pleasure to be in this beautiful city of yours and speaking for the first time at NDC Porto and anyone's",
    "start": "15030",
    "end": "21689"
  },
  {
    "text": "watching the video it should definitely come along to any supporter next year so hopefully this is the title of the talk",
    "start": "21689",
    "end": "26880"
  },
  {
    "text": "you were expecting sorum a little bit out of breath I left a little bit late so I've rushed here so hopefully I'm not",
    "start": "26880",
    "end": "33120"
  },
  {
    "text": "panting down the microphone too much so very briefly my clicker works my name is",
    "start": "33120",
    "end": "38879"
  },
  {
    "start": "38000",
    "end": "38000"
  },
  {
    "text": "Shahid it Paul I'm a freelance hands-on consultant working in Dorne Asia and",
    "start": "38879",
    "end": "44309"
  },
  {
    "text": "more recently kind of kubernetes related projects I'm a tornado upper have been for about ten years and I'm also Marc",
    "start": "44309",
    "end": "51960"
  },
  {
    "text": "soft MVP I'm based in the UK or tend to work anyway and I also co-organized a",
    "start": "51960",
    "end": "59399"
  },
  {
    "text": "meet-up in in the UK say Milton Keynes so if you having in the UK hit me up we'll see if can get you along it's also",
    "start": "59399",
    "end": "67049"
  },
  {
    "text": "a good opportunity just to say to people if you're sitting in the audience and you're thinking hey I could do this especially after this talk you probably",
    "start": "67049",
    "end": "73020"
  },
  {
    "text": "think hey I could do this I definitely encourage you to get started so get in",
    "start": "73020",
    "end": "78240"
  },
  {
    "text": "touch with a meet-up do lightning talks just get into it as soon as you start doing it I think you'll love it and you'll get a bit of a",
    "start": "78240",
    "end": "84540"
  },
  {
    "text": "bug my DM is always open and Twitter so feel free to get in touch in fact main",
    "start": "84540",
    "end": "90299"
  },
  {
    "text": "reason for the slide really is my contact details we'll see how we do for time today in terms of QA but if we",
    "start": "90299",
    "end": "96930"
  },
  {
    "text": "don't get a chance to do Q&A after this session I'll be around until mid afternoon before I have to leave if not",
    "start": "96930",
    "end": "102899"
  },
  {
    "text": "get in touch with me on any of those contact details there I'm probably most active on Twitter as I said diems are",
    "start": "102899",
    "end": "108630"
  },
  {
    "text": "open Twitter and feel free to DM me on LinkedIn as well if you prefer so in",
    "start": "108630",
    "end": "114270"
  },
  {
    "text": "terms what we're going to cover today we're going to go a bit more detail into communities particularly around",
    "start": "114270",
    "end": "119759"
  },
  {
    "text": "scheduling we talked about mission controllers so how we can take a bit more control over kubernetes does and I",
    "start": "119759",
    "end": "127320"
  },
  {
    "text": "will talk a little bit more around extending kubernetes even further and I'm going to switch gears a little bit talk about auto scaling",
    "start": "127320",
    "end": "133980"
  },
  {
    "text": "this kind of virtual node concept I'll finish off touch on service meshes I'm",
    "start": "133980",
    "end": "139170"
  },
  {
    "text": "not gonna go into huge Maya detail or service meshes there's another session immediately after this in room 4 with Ben Hall who died a lot more deeper into",
    "start": "139170",
    "end": "146129"
  },
  {
    "text": "service Misha's so what I'm not going to cover fundamentals of kubernetes so",
    "start": "146129",
    "end": "151590"
  },
  {
    "text": "sumption is everyone here has a fairly good grasp of community's fundamentals not only deep dive into how",
    "start": "151590",
    "end": "157830"
  },
  {
    "text": "we create custom controllers and operators now if you don't know what they are that's fine we'll cover them in a little bit and finally want deep dive",
    "start": "157830",
    "end": "165540"
  },
  {
    "text": "into service meshes again another session that'll do that so now it's time for you folks do you bear work so stick",
    "start": "165540",
    "end": "171599"
  },
  {
    "text": "your hands if you were working with kubernetes on a regular basis yeah can as I expected most of you in production",
    "start": "171599",
    "end": "178370"
  },
  {
    "text": "okay a lot for your hands cool and anyone here who's doesn't really know",
    "start": "178370",
    "end": "184109"
  },
  {
    "text": "anything about kubernetes don't be shy it's just useful to know I can hopefully idiom tweak some of my content good ok",
    "start": "184109",
    "end": "190769"
  },
  {
    "text": "excellent so I want to talk about pod scheduling when we look at the control",
    "start": "190769",
    "end": "197250"
  },
  {
    "start": "196000",
    "end": "196000"
  },
  {
    "text": "plane in cuba Nettie's there are a number of components but the interesting one is scheduler I used to do a talk",
    "start": "197250",
    "end": "203579"
  },
  {
    "text": "I was the introductory talk and at this point I would mention the schedule and I would say schedulers job is to figure",
    "start": "203579",
    "end": "209579"
  },
  {
    "text": "out a way to runny containers and then I'd have to move on there's so much subtlety in detail within the scheduler",
    "start": "209579",
    "end": "214950"
  },
  {
    "text": "that I want to cover today so we look at what the scheduler does it's actually",
    "start": "214950",
    "end": "220290"
  },
  {
    "start": "218000",
    "end": "218000"
  },
  {
    "text": "quite simple at a high level you create deployment or a pod the scheduler",
    "start": "220290",
    "end": "226290"
  },
  {
    "text": "essentially determines is no sign no sono no node assigned it to that pod and",
    "start": "226290",
    "end": "231569"
  },
  {
    "text": "will assign a node to it it's it's really that simple the key thing to understand is the",
    "start": "231569",
    "end": "237569"
  },
  {
    "text": "schedulers job isn't to run your pod it's just to tell essentially assign it to a node at that point other things",
    "start": "237569",
    "end": "243810"
  },
  {
    "text": "kick in and start running your actual workloads so what if we want to have",
    "start": "243810",
    "end": "251489"
  },
  {
    "text": "some control over where we put pods so by default we can schedule containers",
    "start": "251489",
    "end": "257489"
  },
  {
    "text": "pods within kubernetes and communities were foreground way to run them and for most people that's probably fine",
    "start": "257489",
    "end": "263120"
  },
  {
    "text": "but sometimes we need a little bit more control so what if we have heterogenous clusters clusters I've got",
    "start": "263120",
    "end": "269909"
  },
  {
    "text": "some specialized software hardware in them and we want to be able to utilize those effectively we may have",
    "start": "269909",
    "end": "276389"
  },
  {
    "text": "multi-tenancy teams you know mavar clusters multi-talented and we want to allocate resources to certain teams",
    "start": "276389",
    "end": "283099"
  },
  {
    "text": "maybe we've got some regulatory requirements we've got some specialized hardware we've got some work laws that",
    "start": "283099",
    "end": "288780"
  },
  {
    "text": "must be one of those part way for regulatory reasons so we might want influence the scheduling in that",
    "start": "288780",
    "end": "293909"
  },
  {
    "text": "situation or from a application architecture point of view we may want to essentially ensure that certain",
    "start": "293909",
    "end": "300539"
  },
  {
    "text": "components are located together or apart from each other based on our specific requirements so this is why we might",
    "start": "300539",
    "end": "306210"
  },
  {
    "text": "want to influence the scheduling so there's a number of ways we can do this",
    "start": "306210",
    "end": "311370"
  },
  {
    "start": "310000",
    "end": "310000"
  },
  {
    "text": "and we'll dive into them in a second so we got node selector there's no definitive anti affinity for this",
    "start": "311370",
    "end": "318120"
  },
  {
    "text": "concept of no tanks and toleration x' we can have pod affinity and anti Finity",
    "start": "318120",
    "end": "323340"
  },
  {
    "text": "when finally the kind of nuclear option a custom scheduler so node selector not",
    "start": "323340",
    "end": "329699"
  },
  {
    "start": "329000",
    "end": "329000"
  },
  {
    "text": "select is the default the most fundamental concept within kubernetes for influencing the scheduling",
    "start": "329699",
    "end": "335690"
  },
  {
    "text": "essentially what we do is we add a key value pair labelled to our node so in",
    "start": "335690",
    "end": "341490"
  },
  {
    "text": "this case actually incidentally the whoops Kay on my machine is always alias",
    "start": "341490",
    "end": "347340"
  },
  {
    "text": "to cube CTO so I'm just lazy so every time you see Kay that's keep CTO cube control so the cube control label node",
    "start": "347340",
    "end": "354539"
  },
  {
    "text": "I'll give it a node name and then I give it the key value pairs in this case team equals foo what I can then do is in my",
    "start": "354539",
    "end": "361229"
  },
  {
    "text": "pod spec I can specify a note selector element and then I'll give it that key",
    "start": "361229",
    "end": "366240"
  },
  {
    "text": "value pair so a cube nudges will do is when it goes to schedule this particular pod they will look for a node that",
    "start": "366240",
    "end": "371759"
  },
  {
    "text": "matches that label if it finds it you will use it if it doesn't find it it won't schedule that part so it's very",
    "start": "371759",
    "end": "379229"
  },
  {
    "text": "all or nothing notes have a lot of labels applied to",
    "start": "379229",
    "end": "384970"
  },
  {
    "text": "them some morphling most of these applied by your cloud provider so this is an A KS note and we can see there's a",
    "start": "384970",
    "end": "392110"
  },
  {
    "text": "few aks related notes labels on here so you can see the Machine type up here we",
    "start": "392110",
    "end": "398080"
  },
  {
    "text": "can see the note pool and the regions and things like that we can obviously add our own as well so the problem with",
    "start": "398080",
    "end": "406750"
  },
  {
    "text": "notes lictors is the very binary either works or it doesn't we can only match on essentially an",
    "start": "406750",
    "end": "413290"
  },
  {
    "text": "equals so no Definity allows us to attract based or labels but it gives us a bit more flexibility so what we can do now",
    "start": "413290",
    "end": "420280"
  },
  {
    "text": "is we can now match on conditions so we can say if a label exists if it doesn't",
    "start": "420280",
    "end": "426669"
  },
  {
    "text": "exist if it's in a range of labels if it's not in a range of labels if it's greater than it's less than the nice",
    "start": "426669",
    "end": "433810"
  },
  {
    "text": "thing is we can also be demand selective about how demanding real so where's the note selector essentially said it runs",
    "start": "433810",
    "end": "439330"
  },
  {
    "text": "or it doesn't run based on the presence of the label we can be a bit more specific now what we can say is if we if",
    "start": "439330",
    "end": "447040"
  },
  {
    "start": "443000",
    "end": "443000"
  },
  {
    "text": "we supply the required doing scheduling ignored during execution had to be",
    "start": "447040",
    "end": "452050"
  },
  {
    "text": "that's a bit of a mouthful what we're basically saying this is hard requirement if this label doesn't exist",
    "start": "452050",
    "end": "457870"
  },
  {
    "text": "don't run this port turn ative lee what we can use we can do preferred driven",
    "start": "457870",
    "end": "463630"
  },
  {
    "text": "scheduling ignored in the execution now this is our soft requirement so if a note doesn't exist that matches our",
    "start": "463630",
    "end": "469120"
  },
  {
    "text": "label it will still schedule it somewhere else now if you're looking this new thinking well that's a lot not",
    "start": "469120",
    "end": "474460"
  },
  {
    "text": "to say when the only thing that's changed is required and preferred what's all this well there's actually a third",
    "start": "474460",
    "end": "480370"
  },
  {
    "text": "option which says requiring scheduling requiring execution now this actually",
    "start": "480370",
    "end": "485710"
  },
  {
    "text": "isn't implemented yet so what the difference is is preferred during",
    "start": "485710",
    "end": "490870"
  },
  {
    "text": "scheduling as the name suggests is when you were scheduling pods it will check that label during execution will",
    "start": "490870",
    "end": "498070"
  },
  {
    "text": "potentially run if you add a label to a node when this existing calls already running as I said this is not",
    "start": "498070",
    "end": "503680"
  },
  {
    "text": "implemented there's another way of effectively doing this so let's take a look at the Yama file for this so this",
    "start": "503680",
    "end": "510520"
  },
  {
    "text": "is a node affinity so in the pod spec now I have an affinity no differences",
    "start": "510520",
    "end": "515770"
  },
  {
    "text": "and I've got that real long actually then I've got my selectors in this case I'm saying the instance type is in and I'm using name but I've",
    "start": "515770",
    "end": "523039"
  },
  {
    "text": "only obviously only got one value at the moment I could supply multiple values in there",
    "start": "523039",
    "end": "528460"
  },
  {
    "text": "so that was the hard work on so the soft one has got a couple of extra bits in it so now we're saying preferred and",
    "start": "530370",
    "end": "535890"
  },
  {
    "text": "because we're saying preferred we need to essentially give cube Nettie's potentially a range of options and we",
    "start": "535890",
    "end": "541140"
  },
  {
    "text": "apply this weighting to those range so we're saying match in this obviously if just doesn't find it it will still",
    "start": "541140",
    "end": "547080"
  },
  {
    "text": "schedule it but the weighting is applied if there's multiple matching nodes tries to use the way to figure out exactly",
    "start": "547080",
    "end": "552870"
  },
  {
    "text": "which one to use so that was kind of node affinity ante finiti another",
    "start": "552870",
    "end": "559140"
  },
  {
    "text": "concept called taints and toleration z-- which initially sounds quite similar so this",
    "start": "559140",
    "end": "564660"
  },
  {
    "start": "560000",
    "end": "560000"
  },
  {
    "text": "allows nodes to repel pods based on a taint so what happens is you taint a",
    "start": "564660",
    "end": "572250"
  },
  {
    "text": "node and then the pods potentially tolerate that taint the way the way",
    "start": "572250",
    "end": "578670"
  },
  {
    "text": "tints are specified they have three parameters they have a key a value same as the labels they have this additional",
    "start": "578670",
    "end": "584520"
  },
  {
    "text": "label which is called effect and we have the option of saying no schedule prefer no schedule so again hopefully you can",
    "start": "584520",
    "end": "591210"
  },
  {
    "text": "see the difference there and then no execute it's worth noting the kubernetes",
    "start": "591210",
    "end": "597930"
  },
  {
    "text": "actually adds things to nodes under certain conditions so if you know these running out of disk space for example",
    "start": "597930",
    "end": "603780"
  },
  {
    "text": "kubernetes will actually take the node automatically and try and minimize things being deployed on to that node",
    "start": "603780",
    "end": "609090"
  },
  {
    "text": "same for memory and various other things",
    "start": "609090",
    "end": "613010"
  },
  {
    "text": "so the key thing here is if you've got a node with pods already running on it and",
    "start": "614150",
    "end": "619380"
  },
  {
    "text": "you apply a tank then those pods potentially would get kicked off that node so this is the key difference",
    "start": "619380",
    "end": "624690"
  },
  {
    "text": "between the solidity or no Definity and the taints so we will look at how we tanked a node we did keep CTO tank we'll",
    "start": "624690",
    "end": "633690"
  },
  {
    "text": "give it the node and then we get that key value and then call on the effect so in this case no schedule so I take a",
    "start": "633690",
    "end": "640590"
  },
  {
    "text": "look at deployment so I've got three replicas deployed on to a three node cluster with nothing nothing applied",
    "start": "640590",
    "end": "647580"
  },
  {
    "text": "other than that taint typically what we would see is we would see one deployment",
    "start": "647580",
    "end": "652650"
  },
  {
    "text": "per node in this case what we're saying is because we've got that taint node zero isn't being used so we've got two",
    "start": "652650",
    "end": "660570"
  },
  {
    "text": "diplomats our node two and then one is on one now if we come into our pods back we",
    "start": "660570",
    "end": "666879"
  },
  {
    "text": "apply a toleration so we say key name equals at no schedule what that will do",
    "start": "666879",
    "end": "674050"
  },
  {
    "text": "is that's telling kubernetes at this particular deployment can tolerate that taint and we allow it to be scheduled if",
    "start": "674050",
    "end": "681790"
  },
  {
    "text": "you look in this commented line Hin tolerate seconds I think this is a little bit confusing so if you don't",
    "start": "681790",
    "end": "688000"
  },
  {
    "text": "specify this then essentially the kubernetes behaves you way you'd expect if you apply that toleration seconds and",
    "start": "688000",
    "end": "695500"
  },
  {
    "text": "you give it a value when a taint is applied to a node kubernetes will wait that long before it kicks that node that",
    "start": "695500",
    "end": "703209"
  },
  {
    "text": "pod off that node so even though Scott toleration by specifying that toleration seconds you're you're giving a lifetime",
    "start": "703209",
    "end": "710470"
  },
  {
    "text": "to that toleration I think that's a little bit confusing personally but that's the way it works so once we apply",
    "start": "710470",
    "end": "718240"
  },
  {
    "text": "that toleration if you run that deployment again we can now see where scheduled across the nodes as expected",
    "start": "718240",
    "end": "730079"
  },
  {
    "text": "so now if you're looking at this and you're probably thinking what's the difference I wouldn't blame you if you",
    "start": "730079",
    "end": "735879"
  },
  {
    "start": "733000",
    "end": "733000"
  },
  {
    "text": "really were confused at this point so let's try and hopefully clarify it so",
    "start": "735879",
    "end": "741009"
  },
  {
    "text": "with no Definity what you're doing is you're telling a pod to go to a particular node but the pod is",
    "start": "741009",
    "end": "749110"
  },
  {
    "text": "explicitly has to essentially say not to run on particular node so the node doesn't have any control over what",
    "start": "749110",
    "end": "754720"
  },
  {
    "text": "necessarily runs on it anything can be scheduled difference with the tank is a",
    "start": "754720",
    "end": "759759"
  },
  {
    "text": "tank is basically saying don't put anything on me don't allow anything to schedule unless they explicitly say so",
    "start": "759759",
    "end": "766529"
  },
  {
    "text": "so what you can use with with the tank you can prevent kind of casual",
    "start": "766529",
    "end": "772120"
  },
  {
    "text": "scheduling so if you've got a resources on a node in there which is got some expensive resources on there you don't",
    "start": "772120",
    "end": "778899"
  },
  {
    "text": "want it to utilize it all the time you would use a tank to prevent that being deployed because essentially nothing",
    "start": "778899",
    "end": "784480"
  },
  {
    "text": "will get deployed unless explicitly says it wants to be we'll take a look at this in an example with the scaling later on",
    "start": "784480",
    "end": "791939"
  },
  {
    "text": "so we've talked so far about kind of pods to nodes another scenario we may want is to be",
    "start": "791939",
    "end": "799060"
  },
  {
    "text": "able to control where our pot goes based on what else is running on a particular node so this is where I can into",
    "start": "799060",
    "end": "804670"
  },
  {
    "text": "portability typically just called pod affinity potent affinity so this allows",
    "start": "804670",
    "end": "810600"
  },
  {
    "text": "you know nodes to be selected based on what other pods are running on that node",
    "start": "810600",
    "end": "815880"
  },
  {
    "text": "so this allows you to ensure that maybe certain components run together on the same node so maybe you've got a cache",
    "start": "815880",
    "end": "822280"
  },
  {
    "text": "alongside an app alternatively you may want to separate certain components so",
    "start": "822280",
    "end": "828610"
  },
  {
    "text": "for example you want to make you maybe want to ensure that your replicas don't run within the same availability zone you can separate them out using pod ant",
    "start": "828610",
    "end": "835810"
  },
  {
    "text": "affinity and then this way if there's a if there's a loss of a zone you don't get even a temporary drop in your",
    "start": "835810",
    "end": "841750"
  },
  {
    "text": "availability let's take a look at an",
    "start": "841750",
    "end": "847990"
  },
  {
    "text": "example of how this works so you've got similar to the node the node affinity",
    "start": "847990",
    "end": "853480"
  },
  {
    "text": "you've got the constructs or kind of indicating how strict you want to be so you can do required and preferred you've",
    "start": "853480",
    "end": "862330"
  },
  {
    "text": "got this additional concept of a topology key this is initially a little bit confusing but hopefully we'll",
    "start": "862330",
    "end": "867400"
  },
  {
    "text": "clarify as we go along so this reference is a node label and he said she says kubernetes what level in quotes what",
    "start": "867400",
    "end": "874420"
  },
  {
    "text": "level of my infrastructure am i using to apply this separation so this can be a",
    "start": "874420",
    "end": "881560"
  },
  {
    "text": "hostname or a failure domain hopefully clarify a little bit now so I've got a",
    "start": "881560",
    "end": "887710"
  },
  {
    "text": "kind of four node cluster here and if I apply label of a hostname got hostname",
    "start": "887710",
    "end": "893560"
  },
  {
    "text": "node 1 node 2 node 3 node 4 the topology key will treat these as four separate",
    "start": "893560",
    "end": "900250"
  },
  {
    "text": "zones if you like four separate clusters four separate nodes as you'd expect",
    "start": "900250",
    "end": "908400"
  },
  {
    "text": "alternatively we may want separate by zone so now we've got first two machines",
    "start": "908400",
    "end": "913570"
  },
  {
    "text": "in zone one the other two machines in zone 2 if we use the topology key of zone community to actually treat these",
    "start": "913570",
    "end": "921280"
  },
  {
    "text": "as two potential locations and it will schedule on any one of those two unless you've added additional selectors as",
    "start": "921280",
    "end": "929020"
  },
  {
    "text": "well",
    "start": "929020",
    "end": "931200"
  },
  {
    "text": "so let's take a look at the yama so now again within our affinity section we've",
    "start": "934900",
    "end": "939940"
  },
  {
    "text": "now got a pod affinity got required in scheduling blah blah blah got the label",
    "start": "939940",
    "end": "946210"
  },
  {
    "text": "selector so now I'm saying match on my component in values cache now these are",
    "start": "946210",
    "end": "952720"
  },
  {
    "text": "the labels on my deployment now yes so these aren't labels on my my nodes these are labels in my deployment now finally",
    "start": "952720",
    "end": "960070"
  },
  {
    "text": "got my topology key which is a label on my node let's try and visualize this",
    "start": "960070",
    "end": "968050"
  },
  {
    "text": "hopefully this makes it a little bit clearer if you're still confused so I've got three node cluster I've got this web",
    "start": "968050",
    "end": "973390"
  },
  {
    "text": "component I've got a cache component I want to deploy I'm gonna step spread them across the three nodes and I want",
    "start": "973390",
    "end": "979000"
  },
  {
    "text": "to always ensure there's a cache in a web component next to each other now that may happen if I just deploy this",
    "start": "979000",
    "end": "984010"
  },
  {
    "text": "one ensure that happens so I'd use for my web component I set a pod affinity",
    "start": "984010",
    "end": "989800"
  },
  {
    "text": "with the cache component and I say that's preferred the reason is preferred",
    "start": "989800",
    "end": "995230"
  },
  {
    "text": "is because the cache may not be deployed and I don't need to be hard requirement I said ante affinity to itself so wanted",
    "start": "995230",
    "end": "1002760"
  },
  {
    "text": "to do is repelled itself so that he goes across the nodes and then the topology key I want to be the host name because",
    "start": "1002760",
    "end": "1008370"
  },
  {
    "text": "in this case I want to spread it across the three hosts so if I deploy that first component I get those three",
    "start": "1008370",
    "end": "1015120"
  },
  {
    "text": "components as we expect now with the cache very similar this",
    "start": "1015120",
    "end": "1022080"
  },
  {
    "text": "time I'm saying pod affinity to the web component so I'm gonna attract it to the web component and I want to repel it",
    "start": "1022080",
    "end": "1028680"
  },
  {
    "text": "from itself and again I'm using the host name topology and of course that will do",
    "start": "1028680",
    "end": "1035370"
  },
  {
    "text": "as we expect we take a look at the yama for this gets a little bit longer so now",
    "start": "1035370",
    "end": "1043500"
  },
  {
    "text": "we've got that ante finicky I'm saying it's required and it's anti Finity to",
    "start": "1043500",
    "end": "1049710"
  },
  {
    "text": "itself so this is the web this is the web front-end spec and then I'm",
    "start": "1049710",
    "end": "1055050"
  },
  {
    "text": "preferred affinity to the cache the component cache in the host name",
    "start": "1055050",
    "end": "1060660"
  },
  {
    "text": "topology key same with the cache all necessary labor the point required",
    "start": "1060660",
    "end": "1067660"
  },
  {
    "text": "and - it against itself affinity to the web component and then if I deploy this",
    "start": "1067660",
    "end": "1073000"
  },
  {
    "text": "and I get pods what we can see is our order by the nodes we can see node zero",
    "start": "1073000",
    "end": "1079059"
  },
  {
    "text": "has got clash in a web node ones work ash in the web notice go caching the web",
    "start": "1079059",
    "end": "1086280"
  },
  {
    "text": "so the coin quite quickly went through a number of different options there for scheduling what's what if what if all of",
    "start": "1086610",
    "end": "1095320"
  },
  {
    "text": "these different constructs still don't give you enough power the other option the nuclear option as I like to call it",
    "start": "1095320",
    "end": "1101230"
  },
  {
    "start": "1099000",
    "end": "1099000"
  },
  {
    "text": "is you can write your own custom scheduler you can I schedule in any language you want seen examples in bash",
    "start": "1101230",
    "end": "1108820"
  },
  {
    "text": "for example don't ever don't ever use that in real but there's there's an examples of github if you want to have a",
    "start": "1108820",
    "end": "1114549"
  },
  {
    "text": "look it needs to have access to the API server because that scheduler needs to be able to get all the pods that have no",
    "start": "1114549",
    "end": "1120730"
  },
  {
    "text": "node in it assign nodes you need to save that back to the API server once you've",
    "start": "1120730",
    "end": "1126280"
  },
  {
    "text": "got that custom scheduler running all you do is you you specify the scheduler name section and you give it the name of",
    "start": "1126280",
    "end": "1133330"
  },
  {
    "text": "that deployment so actually it's quite easy to use once you've once you've created the scheduler so as you can",
    "start": "1133330",
    "end": "1143350"
  },
  {
    "text": "hopefully see there's quite a lot of options on tweaking you know how cube nettie schedules your pods as I said at",
    "start": "1143350",
    "end": "1150730"
  },
  {
    "text": "the start it's worth remembering you might not need to do any of this kubernetes is very powerful you can usually just let it do its thing and",
    "start": "1150730",
    "end": "1157330"
  },
  {
    "text": "only dive into these things as and when you need them what if that's still not",
    "start": "1157330",
    "end": "1162669"
  },
  {
    "text": "enough what if you need to take a bit more control let's say you want to have control over what resources are created",
    "start": "1162669",
    "end": "1169179"
  },
  {
    "text": "within your cluster you might want to apply custom policies so you might say",
    "start": "1169179",
    "end": "1175870"
  },
  {
    "text": "that every deployment must have a certain label applied you might want to",
    "start": "1175870",
    "end": "1181299"
  },
  {
    "text": "prevent certain resources from being created or you might just want to inject some additional logic transparently into",
    "start": "1181299",
    "end": "1187809"
  },
  {
    "text": "the resources so if you're a cluster operator you may want to apply some policies that run and your developers",
    "start": "1187809",
    "end": "1193450"
  },
  {
    "text": "don't necessarily need to worry about the policies policies just get injected in transparently so they don't need to",
    "start": "1193450",
    "end": "1198610"
  },
  {
    "text": "remember to reference them they just get applied automatically so this is where you can pretend to use",
    "start": "1198610",
    "end": "1205379"
  },
  {
    "start": "1204000",
    "end": "1204000"
  },
  {
    "text": "admission control is so admission control is essentially code that intercepts API requests after they",
    "start": "1205379",
    "end": "1211859"
  },
  {
    "text": "authenticated but before they persisted in the HCD cluster these controllers",
    "start": "1211859",
    "end": "1217499"
  },
  {
    "text": "there can be validating controllers essentially they can just inspect the resources being created and validate",
    "start": "1217499",
    "end": "1225450"
  },
  {
    "text": "them that they can't modify them you have mutating which can modify them and then admission controllers can be",
    "start": "1225450",
    "end": "1231479"
  },
  {
    "text": "both they can validate and we change these admission controllers are enabled",
    "start": "1231479",
    "end": "1237419"
  },
  {
    "text": "or disabled within the cube API server now if you run kubernetes on the cloud if you run a managed good miletti's",
    "start": "1237419",
    "end": "1243359"
  },
  {
    "text": "provider how many people are running kubernetes you know entirely by themselves the four cluster fully",
    "start": "1243359",
    "end": "1248669"
  },
  {
    "text": "managed by themselves so one or two or three people it's mostly plugin we running in the cloud where there's aks",
    "start": "1248669",
    "end": "1255509"
  },
  {
    "text": "where there is gke whether it's eks the problem is within those managed",
    "start": "1255509",
    "end": "1261210"
  },
  {
    "text": "providers you don't have any control over these particular flags they're set by the provider they also compiled into",
    "start": "1261210",
    "end": "1269159"
  },
  {
    "text": "the Cuba API server binary so there's not a huge amount of options that you can't really create any yourself there's",
    "start": "1269159",
    "end": "1280349"
  },
  {
    "text": "a number of these built in I'm not going to talk through all of them but you can",
    "start": "1280349",
    "end": "1286169"
  },
  {
    "text": "check with your individual cloud provider which ones of these I enabled or disabled if we take a look at the",
    "start": "1286169",
    "end": "1292200"
  },
  {
    "text": "lifecycle of an API request we'll see where these fit in so we make a API request to the HTTP handler receives",
    "start": "1292200",
    "end": "1299219"
  },
  {
    "start": "1293000",
    "end": "1293000"
  },
  {
    "text": "that request it will authorize it with enter key and authorize it it then runs in mutation admission",
    "start": "1299219",
    "end": "1305879"
  },
  {
    "text": "controllers so these are things that may be changing the resources may be creating brand-new resources after that",
    "start": "1305879",
    "end": "1312179"
  },
  {
    "text": "we run this object schema validation so make sense we we validate after we've done the mutations that make sense then",
    "start": "1312179",
    "end": "1320849"
  },
  {
    "text": "we run the validation admission controllers they always have to come after the mutations as sure you can",
    "start": "1320849",
    "end": "1326309"
  },
  {
    "text": "imagine otherwise you can bypass validation by mutating and then those things are persisted in let CD and then",
    "start": "1326309",
    "end": "1332820"
  },
  {
    "text": "whatever other control loop kicks in start doing the action within these mutation mutating and",
    "start": "1332820",
    "end": "1339260"
  },
  {
    "text": "validating mission controllers there's two specific ones Val mutating admission",
    "start": "1339260",
    "end": "1344820"
  },
  {
    "text": "webhooks and validating admission webhooks everything's bit of a mouthful isn't it",
    "start": "1344820",
    "end": "1349880"
  },
  {
    "text": "these two are really interesting because they allow us to extend communities without having to write you know new API",
    "start": "1349880",
    "end": "1356070"
  },
  {
    "text": "server binaries without having to change the startup flags an API service if",
    "start": "1356070",
    "end": "1361500"
  },
  {
    "text": "we're running in the cloud these are really powerful so these two special admission controllers which as far as I",
    "start": "1361500",
    "end": "1368669"
  },
  {
    "start": "1364000",
    "end": "1364000"
  },
  {
    "text": "know all the main cloud providers have enabled essentially allows us to create",
    "start": "1368669",
    "end": "1374789"
  },
  {
    "text": "a web hook so when we do and create new resources or we modify existing resources because I'm mutating webhook",
    "start": "1374789",
    "end": "1380340"
  },
  {
    "text": "we can write a validating web hook and",
    "start": "1380340",
    "end": "1385590"
  },
  {
    "text": "all they do is they essentially involve HTTP call back so basically standard web hooks the nice thing with this is the",
    "start": "1385590",
    "end": "1392850"
  },
  {
    "text": "logic for these callbacks doesn't need to be compiled into the API server so",
    "start": "1392850",
    "end": "1398820"
  },
  {
    "text": "you can write to yourself and in fact the logic doesn't even need to be within your cluster so let's have a quick look",
    "start": "1398820",
    "end": "1407190"
  },
  {
    "text": "at a demo",
    "start": "1407190",
    "end": "1410090"
  },
  {
    "text": "and",
    "start": "1413550",
    "end": "1416060"
  },
  {
    "text": "I'll bring up on the screen in a second",
    "start": "1419670",
    "end": "1423620"
  },
  {
    "text": "you never will see that back you see that back yeah",
    "start": "1433559",
    "end": "1440630"
  },
  {
    "text": "so I've got here is I've got a validating webhook configuration so I'm",
    "start": "1441950",
    "end": "1447750"
  },
  {
    "text": "basically specifying one of these web hooks the bit at the top stop the",
    "start": "1447750",
    "end": "1453809"
  },
  {
    "text": "interesting we have to give it a unique name and then we specify which rules this particular validation applies for",
    "start": "1453809",
    "end": "1459840"
  },
  {
    "text": "so in this case I've said this on all API groups v1 for the create operation",
    "start": "1459840",
    "end": "1465570"
  },
  {
    "text": "of pods this failure policy essentially says what should I do if the web hook",
    "start": "1465570",
    "end": "1472140"
  },
  {
    "text": "itself failed for technical reason you know there's no connection or there's a drop in the drop in the network so fail",
    "start": "1472140",
    "end": "1479700"
  },
  {
    "text": "will basically say this treaty as if it's failed validation and then I've got the actual configure itself so what I'm",
    "start": "1479700",
    "end": "1485160"
  },
  {
    "text": "actually gonna invoke so in this case I'm gonna invoke a Naja function as the validating web hook I'll show you the",
    "start": "1485160",
    "end": "1493980"
  },
  {
    "text": "demo before that let's have a quick look at the code for that web hook so I've taken an example of Kelsey Hightower",
    "start": "1493980",
    "end": "1499830"
  },
  {
    "text": "didn't and adapted it for Asha functions so the top bit hopefully is reasonably",
    "start": "1499830",
    "end": "1506850"
  },
  {
    "text": "familiar for people who use Azure functions we get the request in we just",
    "start": "1506850",
    "end": "1511890"
  },
  {
    "text": "need to kind of loop through the spec look at the containers in this example I'm gonna do is I'm gonna check if the",
    "start": "1511890",
    "end": "1518640"
  },
  {
    "text": "container matches a particular container name so they're kind of contrived contrived example here is I've got a",
    "start": "1518640",
    "end": "1523950"
  },
  {
    "text": "particular image that I don't want people to run so I'm gonna use this web hook to basically prevent that so if",
    "start": "1523950",
    "end": "1529980"
  },
  {
    "text": "that web book matches this particular image v1 then I'm gonna return this response which is a failure and I'm",
    "start": "1529980",
    "end": "1536400"
  },
  {
    "text": "gonna say it's using a bad image we're not allowed otherwise we just return",
    "start": "1536400",
    "end": "1541610"
  },
  {
    "text": "essentially allowed equals true so hopefully reasonably straightforward so",
    "start": "1541610",
    "end": "1550200"
  },
  {
    "text": "if I come over to you might have stopped come to Azure functions and Maltese",
    "start": "1550200",
    "end": "1556530"
  },
  {
    "text": "let's just refresh this",
    "start": "1556530",
    "end": "1559550"
  },
  {
    "text": "oh yeah",
    "start": "1564260",
    "end": "1567040"
  },
  {
    "text": "interesting okay let's just search their video this is why we have videos let me",
    "start": "1569330",
    "end": "1579800"
  },
  {
    "text": "just pause it a second so I've just deployed the webhook on this side I've",
    "start": "1579800",
    "end": "1585470"
  },
  {
    "text": "got the Asha functions portal sorry I've just deployed the webhook configuration",
    "start": "1585470",
    "end": "1590480"
  },
  {
    "text": "so the logic now we're going to run this deployment and I'm using that v1 image",
    "start": "1590480",
    "end": "1595750"
  },
  {
    "text": "so in this example I'm doing the deployment so the deployment actually succeeds but as I'll hopefully show you the pods won't be created so we see it",
    "start": "1595750",
    "end": "1606710"
  },
  {
    "text": "succeeded and over here we can see that our webhook ran the text is a little bit",
    "start": "1606710",
    "end": "1612260"
  },
  {
    "text": "smaller essentially it's run the validation hopefully you can see that bit better now if I now look at the pods",
    "start": "1612260",
    "end": "1617510"
  },
  {
    "text": "for that deployment what would see the events rather we can see that event is",
    "start": "1617510",
    "end": "1622730"
  },
  {
    "text": "pushed here so we can see said Falchuk Rae webhook said it's a bad image",
    "start": "1622730",
    "end": "1629470"
  },
  {
    "text": "finally get pods and see there's no pods created if I now run the v2 just to kind",
    "start": "1629470",
    "end": "1637550"
  },
  {
    "text": "of prove that it's not blocking everything",
    "start": "1637550",
    "end": "1640900"
  },
  {
    "text": "we see the webhook run again but this time he didn't have an issue with the image because it was the v2 image and now my pod is running Sofie that gives",
    "start": "1646850",
    "end": "1655730"
  },
  {
    "text": "you a quick kind of fill for webhooks let's go back to the slides",
    "start": "1655730",
    "end": "1662830"
  },
  {
    "text": "rushing through the demos a bit so web hooks give us lot more control or if you",
    "start": "1668150",
    "end": "1677809"
  },
  {
    "text": "want even more control so in the UK we like taking back control apparently what",
    "start": "1677809",
    "end": "1684830"
  },
  {
    "text": "if you want to build abstractions on top of the kubernetes resources so communities does this already so if you",
    "start": "1684830",
    "end": "1691250"
  },
  {
    "text": "look at deployment in kubernetes that's an abstraction on top of replication controllers and pods what we want our",
    "start": "1691250",
    "end": "1698480"
  },
  {
    "text": "own what we want to create entirely new resources within kubernetes what we only",
    "start": "1698480",
    "end": "1703640"
  },
  {
    "text": "deploy a domain-specific object we can do that what we want to use keeps you",
    "start": "1703640",
    "end": "1710570"
  },
  {
    "text": "know Cube control to manage those resources we have a few options first",
    "start": "1710570",
    "end": "1716029"
  },
  {
    "text": "one is we can write an extension API server this is actually quite a lot of work you have to essentially implement",
    "start": "1716029",
    "end": "1721789"
  },
  {
    "text": "an MPI server from scratch you've got to set up your own persistence for the API server it used to be the you know the",
    "start": "1721789",
    "end": "1729080"
  },
  {
    "text": "way people did this now you have the option of using custom resource definitions it's probably the thing most",
    "start": "1729080",
    "end": "1735080"
  },
  {
    "text": "people have heard of in this room I suspect we have custom control is now",
    "start": "1735080",
    "end": "1741679"
  },
  {
    "text": "custom resource definitions a custom controllers are you know linked together but people often use just the term",
    "start": "1741679",
    "end": "1747770"
  },
  {
    "text": "custom resource definitions in isolation dive into a little bit in a second so custom resource definitions of CR DS as",
    "start": "1747770",
    "end": "1754370"
  },
  {
    "start": "1751000",
    "end": "1751000"
  },
  {
    "text": "the company called is essentially a new resource type alongside the built-in ones it allows us to create and delete",
    "start": "1754370",
    "end": "1761090"
  },
  {
    "text": "these resources and these things are stored within the at CD cluster so we're not having to you know cry rom",
    "start": "1761090",
    "end": "1766370"
  },
  {
    "text": "persistence the important thing to know is they're useless without a controller",
    "start": "1766370",
    "end": "1772000"
  },
  {
    "text": "let's have a look anyway so this is how we define a custom resource definition",
    "start": "1772000",
    "end": "1777130"
  },
  {
    "text": "so now the resource coined is custom resource definition we have to give you",
    "start": "1777130",
    "end": "1782390"
  },
  {
    "text": "an API group on a version and then we have this scope so the scope essentially is is it either namespace scoped or",
    "start": "1782390",
    "end": "1787929"
  },
  {
    "text": "cluster wide scoped and then we give it we set up some metadata about it so in",
    "start": "1787929",
    "end": "1794330"
  },
  {
    "text": "my case this thing's called a foo is called fuzes the plural named foo is a singular name the resource coin is foo",
    "start": "1794330",
    "end": "1799669"
  },
  {
    "text": "and then I've even added a short name ever so like get pee or pods why can then do",
    "start": "1799669",
    "end": "1807049"
  },
  {
    "text": "is I can create an instance of this resource so now much like I will create a deployment or a pod I'm now creating a",
    "start": "1807049",
    "end": "1813919"
  },
  {
    "text": "kind foo and I can then put in pretty much whoever I want in that spec so",
    "start": "1813919",
    "end": "1822350"
  },
  {
    "text": "let's take a look at this so I can video let's click that on so I can use I can apply that custom resource definition",
    "start": "1822350",
    "end": "1829000"
  },
  {
    "text": "once I have that I can now start creating these resources so now I can do",
    "start": "1829000",
    "end": "1835659"
  },
  {
    "text": "keep CL applying a full resource I'm getting this now do you get foo and I'm",
    "start": "1835659",
    "end": "1841279"
  },
  {
    "text": "get back that foo object I can use the short name it's great and now can delete",
    "start": "1841279",
    "end": "1846799"
  },
  {
    "text": "it and that's about what I can do so yeah great I've just done crud essentially and literally no logic so so",
    "start": "1846799",
    "end": "1857690"
  },
  {
    "start": "1857000",
    "end": "1857000"
  },
  {
    "text": "you need these custom controllers now custom controllers it's worth mentioning they're not just for custom resources",
    "start": "1857690",
    "end": "1863570"
  },
  {
    "text": "you can actually customize the behavior of existing resources so if those validating in mutating workbooks don't",
    "start": "1863570",
    "end": "1869960"
  },
  {
    "text": "give you enough control you can write custom controller that can essentially do the things you want to do they are",
    "start": "1869960",
    "end": "1878600"
  },
  {
    "text": "often paired with custom resource definitions to essentially power those custom resources they are typically",
    "start": "1878600",
    "end": "1885500"
  },
  {
    "text": "implemented in go I don't think that's necessarily hard requirement but you do need to access the API server machinery",
    "start": "1885500",
    "end": "1891980"
  },
  {
    "text": "which is a client go library so I've only ever seen implemented in go you may",
    "start": "1891980",
    "end": "1899240"
  },
  {
    "text": "have heard the term operator broadly speaking operator is a custom resource definition along with its",
    "start": "1899240",
    "end": "1904639"
  },
  {
    "text": "custom controller now if you're thinking I'm going to go out and create my own",
    "start": "1904639",
    "end": "1909889"
  },
  {
    "text": "custom know my own operators there's actually a load of operators already out",
    "start": "1909889",
    "end": "1915980"
  },
  {
    "text": "there so a lot of the cloud providers have created operators to help integrate",
    "start": "1915980",
    "end": "1921500"
  },
  {
    "text": "with their clouds AWS is probably a good example they have created an AWS operator which",
    "start": "1921500",
    "end": "1926600"
  },
  {
    "text": "allows you to provision AWS resources as part of a kubernetes deployment so it's worth checking our list if you",
    "start": "1926600",
    "end": "1934070"
  },
  {
    "text": "want to create your own it's not a trivial task I should warn you one",
    "start": "1934070",
    "end": "1940309"
  },
  {
    "text": "option is to use this operator framework I think the core OS team released a little while back the other option is",
    "start": "1940309",
    "end": "1947750"
  },
  {
    "text": "there's a example custom controller within the communities documentation that you can kind of copy as well",
    "start": "1947750",
    "end": "1953830"
  },
  {
    "text": "there's also workshop some people run I think that's probably the best way you really need some experience it's not not",
    "start": "1953830",
    "end": "1959809"
  },
  {
    "text": "the easiest thing to do so we're gonna take a bit of a shift now we've spent a",
    "start": "1959809",
    "end": "1965870"
  },
  {
    "text": "fair bit of time talking about scheduling and controlling and extending communities I want to do a bit of a",
    "start": "1965870",
    "end": "1971510"
  },
  {
    "text": "shift now and talk about scaling applications and clusters so we talked",
    "start": "1971510",
    "end": "1976910"
  },
  {
    "text": "about auto scaling we have a number of options so horizontal product a scalar is the component which I'm sure most of",
    "start": "1976910",
    "end": "1983030"
  },
  {
    "start": "1977000",
    "end": "1977000"
  },
  {
    "text": "you in this room are very familiar with this thing allows us to essentially scale the number of pods we have in our",
    "start": "1983030",
    "end": "1989090"
  },
  {
    "text": "deployment based on metrics the original pod autoscaler used CPU and memory the v2 is a lot more",
    "start": "1989090",
    "end": "1997220"
  },
  {
    "text": "powerful it allows us to use any metrics pretty much and even external metrics so",
    "start": "1997220",
    "end": "2003220"
  },
  {
    "text": "we can scale a deployment based on the number of items you know how's your service boskie for example maybe not so",
    "start": "2003220",
    "end": "2011920"
  },
  {
    "text": "well-known is the vertical pod autoscaler now this is still in beta but this",
    "start": "2011920",
    "end": "2017020"
  },
  {
    "text": "allows us to increase the amount of resources allocated to a pod based on certain metrics so the name kind of",
    "start": "2017020",
    "end": "2025300"
  },
  {
    "text": "suggests the horizontal photo to scale is scaling out the vertical protocol to scale and scaling up when we're scaling",
    "start": "2025300",
    "end": "2034570"
  },
  {
    "text": "those pods we are we can only scale to the limits of our current cluster size so if we need to increase the size of a",
    "start": "2034570",
    "end": "2041380"
  },
  {
    "text": "cluster this is where the cluster autoscaler comes in the cluster autoscaler",
    "start": "2041380",
    "end": "2046660"
  },
  {
    "text": "essentially looks for pods which can't be scheduled and uses that as a metric to start increasing the size of the",
    "start": "2046660",
    "end": "2052960"
  },
  {
    "text": "cluster now in most cases you're going to be running on a cloud so this will interact with the cloud provider to",
    "start": "2052960",
    "end": "2058750"
  },
  {
    "text": "start increasing the number of nodes one of the challenges with the cluster autoscaler is the time it takes to scale",
    "start": "2058750",
    "end": "2065929"
  },
  {
    "text": "the cluster it might take 3 4 5 10 minutes to increase the number of nodes",
    "start": "2065930",
    "end": "2071360"
  },
  {
    "text": "in your cluster what if your traffic is very spiky and you can't respond quick",
    "start": "2071360",
    "end": "2077090"
  },
  {
    "text": "enough this is where this project will the virtual cubelet that your node comes in how many people heard about your",
    "start": "2077090",
    "end": "2083899"
  },
  {
    "text": "cubelet but you note a couple of hands excellent okay the name is a little bit confusing",
    "start": "2083900",
    "end": "2089419"
  },
  {
    "text": "so hopefully I'll explain that as we go along so this is an open-source project it was created by the marks of team it's",
    "start": "2089420",
    "end": "2095600"
  },
  {
    "text": "I think has been donated now to the CN CF essentially allows you to connect an",
    "start": "2095600",
    "end": "2101300"
  },
  {
    "text": "external computer resource into your cube Nettie's cluster and interact with it as if it was a node within kubernetes",
    "start": "2101300",
    "end": "2107990"
  },
  {
    "text": "I can see if you puzzled faces so hopefully the next slide will explain it a little bit better so what I've got in",
    "start": "2107990",
    "end": "2114380"
  },
  {
    "text": "my cluster here I've got three now actual nodes or whether they be a metal of VMs and then with the virtual Kuebler",
    "start": "2114380",
    "end": "2121760"
  },
  {
    "text": "I create this virtual nodes when I look in the cluster I see another node but that's not",
    "start": "2121760",
    "end": "2126950"
  },
  {
    "text": "actually a VM or a physical machine in my cluster it's actually pointing to some external service which is powering",
    "start": "2126950",
    "end": "2132410"
  },
  {
    "text": "it this virtual Keibler exposes most of the functionality you'd expect to see within",
    "start": "2132410",
    "end": "2138830"
  },
  {
    "text": "a pod and within the nodes so as far as you're concerned you're going to interact with it just like you would in communities but the pods themselves are",
    "start": "2138830",
    "end": "2146750"
  },
  {
    "text": "running somewhere else so number of implementations of this virtual cubelet there's Azure contain instances one so",
    "start": "2146750",
    "end": "2155270"
  },
  {
    "start": "2149000",
    "end": "2149000"
  },
  {
    "text": "for those who don't know as you contain instances is the lot of buzzwords here is the server list container offering from Azure allows you to run containers",
    "start": "2155270",
    "end": "2162850"
  },
  {
    "text": "and pay per second for the containers while they're running the similar",
    "start": "2162850",
    "end": "2167900"
  },
  {
    "text": "service 180 of this far gate so there's also a virtual Cuban implementation which sends containers to Fargate and",
    "start": "2167900",
    "end": "2174890"
  },
  {
    "text": "then similarly we've got other implementations or nomads which is the Hashi corpse going to container management platform service fabric mesh",
    "start": "2174890",
    "end": "2182150"
  },
  {
    "text": "azure IOT edge and there's many others as well so where is this potato you know this kind of virtual node concept where",
    "start": "2182150",
    "end": "2188390"
  },
  {
    "text": "is it useful so let's assume I've got my cluster I've got three nodes in it and I've got this",
    "start": "2188390",
    "end": "2193520"
  },
  {
    "start": "2191000",
    "end": "2191000"
  },
  {
    "text": "virtual cubelet deployed so I've created a virtual node and I'm running and my",
    "start": "2193520",
    "end": "2198860"
  },
  {
    "text": "class is running hot what I can do is I can start scaling my cluster up but",
    "start": "2198860",
    "end": "2204650"
  },
  {
    "text": "that's gonna take some time what do I do with the traffic in the meantime do I just drop it what I can do is through",
    "start": "2204650",
    "end": "2212660"
  },
  {
    "text": "the virtual Kubla I can actually push those back workloads those that traffic by deploying containers onto a CI so I'm",
    "start": "2212660",
    "end": "2218930"
  },
  {
    "text": "scaling my application up and containers are being deployed onto a CI so that's",
    "start": "2218930",
    "end": "2224330"
  },
  {
    "text": "taking the load on bursting into the into a CI if you like I'm taking that they're taking the load while I'm",
    "start": "2224330",
    "end": "2230030"
  },
  {
    "text": "potentially scaling my cluster up when that load dies away those pods will come",
    "start": "2230030",
    "end": "2235100"
  },
  {
    "text": "off that node I start paying for them within a chaos the virtual node is a is",
    "start": "2235100",
    "end": "2241820"
  },
  {
    "start": "2240000",
    "end": "2240000"
  },
  {
    "text": "in preview and you can just enable it with this one option down here",
    "start": "2241820",
    "end": "2249400"
  },
  {
    "text": "so let's have a look at a demo and I think I'm going to use a video given the Internet's not working",
    "start": "2251150",
    "end": "2258140"
  },
  {
    "text": "I'll just pause this one second song set it up so what I've done is I've deployed",
    "start": "2264090",
    "end": "2269840"
  },
  {
    "text": "that virtual node so I've enabled it in my cluster my case cluster and I've got",
    "start": "2269840",
    "end": "2275340"
  },
  {
    "text": "you can see here I've got my three existing nodes then that virtual cube",
    "start": "2275340",
    "end": "2280950"
  },
  {
    "text": "has created this additional nodes so this is what I mean it looks like another node in communities",
    "start": "2280950",
    "end": "2287059"
  },
  {
    "text": "yeah didn't need to pause it if I take a closer look at that particular notes if",
    "start": "2295090",
    "end": "2301470"
  },
  {
    "text": "I do keep CTO described and see a load",
    "start": "2301470",
    "end": "2307530"
  },
  {
    "text": "of stuff but the bit that's relevant or interesting so we got some labels on there we've got a label that says it's",
    "start": "2307530",
    "end": "2313829"
  },
  {
    "text": "virtual Keebler and then key thing is we've got this change so we're tainting this we're saying",
    "start": "2313829",
    "end": "2319410"
  },
  {
    "text": "don't schedule on this virtual Kuebler",
    "start": "2319410",
    "end": "2324440"
  },
  {
    "text": "unless you tolerate it so when I said before that taints and toleration I don't want to be deploying containers to",
    "start": "2324440",
    "end": "2331530"
  },
  {
    "text": "ACI if I've got capacity within my existing cluster I don't want to spend extra money there's no point so by",
    "start": "2331530",
    "end": "2336540"
  },
  {
    "text": "changing it what I'm telling kubernetes is don't use it unless you've been told to specifically use it if I have a look",
    "start": "2336540",
    "end": "2348060"
  },
  {
    "text": "at the deployments I've gotten here there's a few things running on this cluster they're all related but the bit",
    "start": "2348060",
    "end": "2353550"
  },
  {
    "text": "that's interesting is this application called the online store so that's that second one down this is a webshop I'll",
    "start": "2353550",
    "end": "2362040"
  },
  {
    "text": "show you the UI in a second and we can see everything is running on my actual",
    "start": "2362040",
    "end": "2368040"
  },
  {
    "text": "nodes in my cluster so nothing's running on the Virtual node some machine is running on node one single instance",
    "start": "2368040",
    "end": "2376940"
  },
  {
    "text": "if I have a closer look at that deployment that pod what we'll see is",
    "start": "2378730",
    "end": "2385450"
  },
  {
    "text": "it's got our toleration it was right down the bottom let's go and past it let's go back down I should pretend I'm",
    "start": "2385450",
    "end": "2399230"
  },
  {
    "text": "doing this for really yeah so you can see there I'll just pause that second",
    "start": "2399230",
    "end": "2404270"
  },
  {
    "text": "because I'll show you the others as well so you can see I've tolerated the no schedule and instantly these are the",
    "start": "2404270",
    "end": "2411349"
  },
  {
    "text": "additional these are the additional toleration as I mentioned there could be",
    "start": "2411349",
    "end": "2416540"
  },
  {
    "text": "Nettie's ads sometimes you can see not ready so we're not tolerating that ACI",
    "start": "2416540",
    "end": "2424809"
  },
  {
    "text": "if I just added that kubernetes will start deploying onto that will start",
    "start": "2424809",
    "end": "2431869"
  },
  {
    "text": "deploying onto there but I don't want you to deploy in there unless it has to unless there's no space in the existing",
    "start": "2431869",
    "end": "2437510"
  },
  {
    "text": "cluster so if we take a look at the just",
    "start": "2437510",
    "end": "2443270"
  },
  {
    "text": "a second we take a look at that deployment and I just pause here we can see alongside",
    "start": "2443270",
    "end": "2450500"
  },
  {
    "text": "that toleration I've added an anti Finity so I've added a node affinity but I've said where the type is not in",
    "start": "2450500",
    "end": "2456859"
  },
  {
    "text": "virtual Qiblah so I'm telling you to prefer not to schedule on the virtual Qiblah so even though it tolerates the",
    "start": "2456859",
    "end": "2464390"
  },
  {
    "text": "virtual Kuebler I'm telling it to prefer not to use the virtual Kuebler and this is how we get that flexibility where you",
    "start": "2464390",
    "end": "2470150"
  },
  {
    "text": "won't use it unless it needs to perhaps is a little bit kind of long-winded way",
    "start": "2470150",
    "end": "2475670"
  },
  {
    "text": "of doing that we'll see if we can preview it maybe improve that in the future so that's what it's doing and",
    "start": "2475670",
    "end": "2483950"
  },
  {
    "text": "there's that toleration I mentioned so you can see we're tolerating it but we're telling it not to so this is the app itself it's just a kind of web store",
    "start": "2483950",
    "end": "2492430"
  },
  {
    "text": "selling various Microsoft products and",
    "start": "2492430",
    "end": "2497450"
  },
  {
    "text": "it can load up the cart I think I've got $13,000 worth in the car something yep",
    "start": "2497450",
    "end": "2503500"
  },
  {
    "text": "so we're gonna do is we're gonna essentially hit this site with a load of love with some load and we're gonna see",
    "start": "2503500",
    "end": "2509599"
  },
  {
    "text": "how it behaves so what I've got is got a pin sites running on this and we can see the request is literally one",
    "start": "2509599",
    "end": "2515540"
  },
  {
    "text": "request per second coming in and we can see our response time is very low and the cloud shell what I'll do is I'm",
    "start": "2515540",
    "end": "2523130"
  },
  {
    "text": "gonna start kicking off some load in that bottom corner and what we can see up here is as soon as I kick that off we",
    "start": "2523130",
    "end": "2529940"
  },
  {
    "text": "should start seeing the request rate jump up so you can see now it's jumped up massively and also our response to",
    "start": "2529940",
    "end": "2537410"
  },
  {
    "text": "your request directions jumped up as well because we're no longer was responding quick enough so we're taking now half a second if I come over to the",
    "start": "2537410",
    "end": "2546460"
  },
  {
    "text": "the command window we can have a look now at the pods so we can see now is a",
    "start": "2546520",
    "end": "2553369"
  },
  {
    "text": "lot more pods running so the auto scale is kicking in and it's increasing the number of pods we can see you've got",
    "start": "2553369",
    "end": "2559430"
  },
  {
    "text": "some creating some pending and even one in an error the interesting is where are these pods being created so if we take a",
    "start": "2559430",
    "end": "2567050"
  },
  {
    "text": "look with the and incidentally while that's what I'm doing that if you look",
    "start": "2567050",
    "end": "2572780"
  },
  {
    "text": "over here we can see now within few seconds we've actually our request",
    "start": "2572780",
    "end": "2577849"
  },
  {
    "text": "duration is 32 drop back down again so we're now kind of handling that load we've responded within a few seconds we",
    "start": "2577849",
    "end": "2583880"
  },
  {
    "text": "can see there's a lot more the important thing is in its wrapped around a little bit where we can see most of these are running on the virtual node so we didn't",
    "start": "2583880",
    "end": "2592280"
  },
  {
    "text": "have enough capacity in a cluster we've started scheduling onto virtual node or we've spun up you know tens of",
    "start": "2592280",
    "end": "2598190"
  },
  {
    "text": "additional containers I think this example scales up to about 60 containers",
    "start": "2598190",
    "end": "2604270"
  },
  {
    "text": "what we can do is if we then kill that load this is where we do a bit of",
    "start": "2604270",
    "end": "2609400"
  },
  {
    "text": "editing I'm now gonna kill that a low test so",
    "start": "2609400",
    "end": "2617309"
  },
  {
    "text": "now the loads gonna drop off so we can see the requests have dropped off up here and actually within within about 90",
    "start": "2617309",
    "end": "2625619"
  },
  {
    "text": "seconds or so the pods actually start coming off the ACI so I edited the video here just so",
    "start": "2625619",
    "end": "2631499"
  },
  {
    "text": "you're not waiting for 90 seconds but you can see actually we're now back down to that single deployment that single",
    "start": "2631499",
    "end": "2636779"
  },
  {
    "text": "instance we look at the pod autoscaler we can see it's now down to one replicas and it was running 60 just to kind of",
    "start": "2636779",
    "end": "2644039"
  },
  {
    "text": "show you how quickly responds again in case you didn't catch it the first time and we're gonna run it again with just the first bit and hopefully we can see",
    "start": "2644039",
    "end": "2651029"
  },
  {
    "text": "the time it takes to kick in start scaling so just kicked off the load we can see the spike I'm just repeating",
    "start": "2651029",
    "end": "2657660"
  },
  {
    "text": "this but hopefully now I've got a second chance look at it that first one it hasn't started scaling by running again",
    "start": "2657660",
    "end": "2665838"
  },
  {
    "text": "hasn't yet so that's been about what 10 seconds",
    "start": "2666410",
    "end": "2671299"
  },
  {
    "text": "and the real you sign to scale so that's that's how quick it is a lot quicker",
    "start": "2673190",
    "end": "2678470"
  },
  {
    "text": "than trying to scale the cluster",
    "start": "2678470",
    "end": "2681700"
  },
  {
    "text": "so hopefully that gives you an idea of the virtual node virtual cube lent concept as I said it's it's not a a KS",
    "start": "2688210",
    "end": "2696579"
  },
  {
    "text": "specific thing you can run it in a in your own cluster if you want obviously if you're going to run so for example",
    "start": "2696579",
    "end": "2702250"
  },
  {
    "text": "you could set up a gke cluster to burst into a KS ACI if you wanted to or",
    "start": "2702250",
    "end": "2709109"
  },
  {
    "text": "Fargate the only question on that is you're going to have to give service credentials to the to the gke deployment",
    "start": "2709109",
    "end": "2717520"
  },
  {
    "text": "that has access to your AWS deployment so that's the only thing to watch out for that so we're gonna take another",
    "start": "2717520",
    "end": "2723549"
  },
  {
    "text": "shift now and we doing for time not too bad so I'm gonna finish on kind of",
    "start": "2723549",
    "end": "2729609"
  },
  {
    "text": "service service communications now this is a section around service machines and I mentioned we'll go into a bit more",
    "start": "2729609",
    "end": "2735640"
  },
  {
    "text": "detail in another session so kubernetes has a number of kind of options built in",
    "start": "2735640",
    "end": "2741910"
  },
  {
    "text": "for doing service to service communications but I think they're a little bit light so we have the ability",
    "start": "2741910",
    "end": "2747190"
  },
  {
    "text": "to kind of set cloud security policies we can have network security policies so they allow us to kind of control walk",
    "start": "2747190",
    "end": "2752980"
  },
  {
    "text": "and talk to you which other pods we have an ingress now anyone who's used the",
    "start": "2752980",
    "end": "2759039"
  },
  {
    "text": "ingress knows that it's not too bad but it's a little bit lacking in features so with the ingress what we can do is we",
    "start": "2759039",
    "end": "2765309"
  },
  {
    "text": "can set up hostname and path based routing but we can't do anything else we can't apply any kind of waiting to the",
    "start": "2765309",
    "end": "2771849"
  },
  {
    "text": "traffic we can essentially just send the traffic straight down to the left to these services if we had more control of",
    "start": "2771849",
    "end": "2780190"
  },
  {
    "start": "2779000",
    "end": "2779000"
  },
  {
    "text": "the traffic we can enable a number of additional scenarios so we can do canary",
    "start": "2780190",
    "end": "2785289"
  },
  {
    "text": "deployments if we were able to send certain amount of traffic to different pods we can do canary deployments",
    "start": "2785289",
    "end": "2790500"
  },
  {
    "text": "similarly we could do a/b deployments we can do one of my favorite things which",
    "start": "2790500",
    "end": "2796150"
  },
  {
    "text": "is launching Darkly so this is where we deploy a new instance of a service and it receives a share essentially a copy",
    "start": "2796150",
    "end": "2804309"
  },
  {
    "text": "of the production traffic without actually seeing being in production so allows you to launch a new version of a",
    "start": "2804309",
    "end": "2810309"
  },
  {
    "text": "service see how it manages with production traffic and then decide whether you want to roll it out or not",
    "start": "2810309",
    "end": "2816780"
  },
  {
    "text": "and allows you to potentially route traffic between legacy and kind of cloud",
    "start": "2816780",
    "end": "2822820"
  },
  {
    "text": "native applications as you're migrating an application you're not going to suddenly you know you need to potentially send traffic to a VM and",
    "start": "2822820",
    "end": "2829359"
  },
  {
    "text": "then also send it to you know to a kubernetes cluster and this is where some service machines can potentially",
    "start": "2829359",
    "end": "2834760"
  },
  {
    "text": "come in so briefly what is the service mesh essentially its infrastructure for",
    "start": "2834760",
    "end": "2840010"
  },
  {
    "start": "2836000",
    "end": "2836000"
  },
  {
    "text": "handling service to service communications so its job is to change",
    "start": "2840010",
    "end": "2845260"
  },
  {
    "text": "essentially to ensure that you can reliable delivery of messages through what we call a cloud native modern",
    "start": "2845260",
    "end": "2851680"
  },
  {
    "text": "application the most one known example of a service mesh is probably still the the most common project it's an open",
    "start": "2851680",
    "end": "2859480"
  },
  {
    "start": "2855000",
    "end": "2855000"
  },
  {
    "text": "source project being led by Google lyft and IBM and it runs on top of kubernetes",
    "start": "2859480",
    "end": "2866020"
  },
  {
    "text": "although actually does support other platforms as well this is one of things I love about kubernetes is you can take",
    "start": "2866020",
    "end": "2871030"
  },
  {
    "text": "communities and you can deploy something into communities which extends kubernetes even more makes them more powerful so what does it still give you",
    "start": "2871030",
    "end": "2879070"
  },
  {
    "text": "it allows you to do Network kind of error handling so this is a service you know circuit breakers retry logic",
    "start": "2879070",
    "end": "2885040"
  },
  {
    "text": "timeouts and I'm sure most of you if you're running your code you're going to have libraries that do this so don't",
    "start": "2885040",
    "end": "2890109"
  },
  {
    "text": "know we have Pali Java has finagle I think no maybe not I don't know any",
    "start": "2890109",
    "end": "2897130"
  },
  {
    "text": "other platforms out clearly but pushing this concerns down into the platform",
    "start": "2897130",
    "end": "2902640"
  },
  {
    "text": "means that your code doesn't have to obviously have this implementation and if you're using multiple different",
    "start": "2902640",
    "end": "2908349"
  },
  {
    "text": "frameworks or platforms you don't have to re-implement the logic we can do rate limiting similarly we can do this",
    "start": "2908349",
    "end": "2915460"
  },
  {
    "text": "traffic shifting and mirroring so this is what I talked about we can send 20% of the traffic to one deployment maybe 80% to the other and",
    "start": "2915460",
    "end": "2922210"
  },
  {
    "text": "vary that number or mirroring is where we send a copy of the traffic to another service and this is how we do that",
    "start": "2922210",
    "end": "2927760"
  },
  {
    "text": "launching Darkly we can inject false so",
    "start": "2927760",
    "end": "2933720"
  },
  {
    "text": "one of the nice things within well one of the challenges in Marcus's application is you need to be able to",
    "start": "2933720",
    "end": "2938890"
  },
  {
    "text": "tolerate failure and testing that can be a bit hard so being able to consistently inject faults into a micro services",
    "start": "2938890",
    "end": "2945369"
  },
  {
    "text": "architecture is really powerful initio lets you do that it lets you secure conservative service",
    "start": "2945369",
    "end": "2952100"
  },
  {
    "text": "communications and also apply policies I say service I can only talk service via nothing else and then because we're",
    "start": "2952100",
    "end": "2959660"
  },
  {
    "text": "running a remark services we can trace the requests as they go across the multiple underlying services as I said",
    "start": "2959660",
    "end": "2967610"
  },
  {
    "text": "this is just the really just touching on East you can do Ben Hall is doing a talk immediately after this one after the",
    "start": "2967610",
    "end": "2974450"
  },
  {
    "text": "break in room four they'll dive a little bit more so let's just wrap up so as you",
    "start": "2974450",
    "end": "2982310"
  },
  {
    "text": "hopefully you've seen there's a lot of really powerful constructs within kubernetes to kind of extend control the",
    "start": "2982310",
    "end": "2988940"
  },
  {
    "text": "behavior as I said you don't need to do this as you find you know requirement",
    "start": "2988940",
    "end": "2994190"
  },
  {
    "text": "comes in chances are there's a good capability built into the platform those web hooks are really quite powerful and",
    "start": "2994190",
    "end": "3000790"
  },
  {
    "text": "with minimal code you can actually do quite a lot and the custom resources",
    "start": "3000790",
    "end": "3006490"
  },
  {
    "text": "give you the ultimate ultimate extensibility but you do have to work for it then that virtual node is",
    "start": "3006490",
    "end": "3014920"
  },
  {
    "text": "potentially in the future we can have serverless kubernetes clusters we can have everything running in a virtual node and",
    "start": "3014920",
    "end": "3020890"
  },
  {
    "text": "we don't actually have to have any provision VMs at all and if we're running in a managed kubernetes provided",
    "start": "3020890",
    "end": "3026590"
  },
  {
    "text": "then we don't have master nodes either we don't have anything so pretty straightforward so if you want to learn",
    "start": "3026590",
    "end": "3033460"
  },
  {
    "text": "more documentation for the kubernetes documentation has all the things i",
    "start": "3033460",
    "end": "3038590"
  },
  {
    "text": "talked about are in the kubernetes documentation they're perhaps not as easy to get your head around that demo i",
    "start": "3038590",
    "end": "3044770"
  },
  {
    "text": "did earlier the scaling is on the azure samples i did a talk where i dive a",
    "start": "3044770",
    "end": "3050770"
  },
  {
    "text": "little bit more into kind of service meshes and how they work with micro services in Sydney last year and then if",
    "start": "3050770",
    "end": "3057550"
  },
  {
    "text": "you want to learn more about any of these things that worked about cata code is this awesome online learning platform how many people have heard of Kat coda",
    "start": "3057550",
    "end": "3063510"
  },
  {
    "text": "Wow this so there's loads you haven't awesome so Kat code is this awesome online learning platform so if you work",
    "start": "3063510",
    "end": "3070180"
  },
  {
    "text": "with the corporate laptop and you can't install docker in console anything on your laptop as long as you go internet connection on a web browser got cat code",
    "start": "3070180",
    "end": "3077020"
  },
  {
    "text": "and you can learn about all of the cloud native technologies so for example there's a course in the operator framework",
    "start": "3077020",
    "end": "3082690"
  },
  {
    "text": "this course is on sto the course on kubernetes docker github everything you could think of kit everything is on",
    "start": "3082690",
    "end": "3088270"
  },
  {
    "text": "there and speaking of cat coda the as I mentioned a couple of times now if you",
    "start": "3088270",
    "end": "3095170"
  },
  {
    "text": "want to learn more about service machines and they are super cool then Ben Hall is sitting at the back there who created quatre coda is doing a",
    "start": "3095170",
    "end": "3102250"
  },
  {
    "text": "session in room for the next session so I'd recommend going along to that with",
    "start": "3102250",
    "end": "3109240"
  },
  {
    "text": "that I think we've got about four or five minutes for questions",
    "start": "3109240",
    "end": "3114360"
  },
  {
    "text": "nope no questions okay Nucky's thank you",
    "start": "3118050",
    "end": "3123420"
  },
  {
    "text": "very much we can go on your coffee early [Applause]",
    "start": "3123420",
    "end": "3133790"
  }
]
[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "all right everyone we'll go ahead and get started even as people are saundering in here",
    "start": "7040",
    "end": "12960"
  },
  {
    "text": "so today we're going to be talking about performance as a first class feature in your dot net applications using enbench",
    "start": "12960",
    "end": "19199"
  },
  {
    "text": "so my name is aaron standard and i'm the founder of nbench and i'm going to give begin our talk",
    "start": "19199",
    "end": "25599"
  },
  {
    "text": "today with a little story about how inbench came about and some of the problems we're dealing with on akka.net",
    "start": "25599",
    "end": "30960"
  },
  {
    "text": "which is the other open source project i spend most of my time working on",
    "start": "30960",
    "end": "36000"
  },
  {
    "start": "35000",
    "end": "191000"
  },
  {
    "text": "so philosophically speaking performance is a feature of your application just like anything else",
    "start": "36000",
    "end": "43200"
  },
  {
    "text": "so imagine this you're all developers who have employers who care enough about your career progression development to",
    "start": "43200",
    "end": "49600"
  },
  {
    "text": "you know send you to a conference like this you are proud of your work",
    "start": "49600",
    "end": "54960"
  },
  {
    "text": "would you ever go ahead and ship a feature that you thought was really important and useful to your customers without testing it",
    "start": "54960",
    "end": "61039"
  },
  {
    "text": "would that be something that you would deem acceptable and the answer is probably not",
    "start": "61039",
    "end": "66479"
  },
  {
    "text": "well what about the performance of our applications so for instance if we're shipping a web application",
    "start": "66479",
    "end": "72320"
  },
  {
    "text": "one of the things that can make a really big impact on our end users is how quickly we're able to fulfill a response",
    "start": "72320",
    "end": "78640"
  },
  {
    "text": "to user's request what would happen if google every time you went to go and load it in your",
    "start": "78640",
    "end": "84640"
  },
  {
    "text": "browser it took let's say four seconds to load the home page would you keep using it",
    "start": "84640",
    "end": "90640"
  },
  {
    "text": "probably not right you want to switch to something faster or how about a cell phone application",
    "start": "90640",
    "end": "96640"
  },
  {
    "text": "so your ios or android app that ended up using all of your prepaid bandwidth every month",
    "start": "96640",
    "end": "102560"
  },
  {
    "text": "would you use that or switch to an alternative that was better designed you'd probably switch",
    "start": "102560",
    "end": "107759"
  },
  {
    "text": "or how about a desktop backup application that took 10 hours to back",
    "start": "107759",
    "end": "112960"
  },
  {
    "text": "up end to end and use a hundred percent of your cpu while it was running would you keep using that",
    "start": "112960",
    "end": "118799"
  },
  {
    "text": "or would you find an alternative these are all extreme examples but nonetheless realistic ones of where the",
    "start": "118799",
    "end": "125200"
  },
  {
    "text": "performance of an application could make such a negative impact on the end user as to drive them to find an",
    "start": "125200",
    "end": "131200"
  },
  {
    "text": "alternative so the underlying theory here is that performance is a feature of our application just like any other piece of",
    "start": "131200",
    "end": "138000"
  },
  {
    "text": "functionality but what separates it from everything else is how classically difficult it is",
    "start": "138000",
    "end": "144400"
  },
  {
    "text": "to assess and test the performance of our code versus the functionality of a feature",
    "start": "144400",
    "end": "149840"
  },
  {
    "text": "when you write a traditional unit test for a feature you basically have some input and you expect some output to",
    "start": "149840",
    "end": "155920"
  },
  {
    "text": "occur right and you can basically objectively determine that pretty easily well",
    "start": "155920",
    "end": "161280"
  },
  {
    "text": "how do you measure performance and how does that vary by the type of hardware someone runs",
    "start": "161280",
    "end": "166959"
  },
  {
    "text": "or what else is happening on the computer at the time you wanted to gather that benchmark data these are all problems that are actually",
    "start": "166959",
    "end": "173360"
  },
  {
    "text": "pretty nasty and so what i'm going to present you with today is end bench which is a tool",
    "start": "173360",
    "end": "178640"
  },
  {
    "text": "that is designed to help simplify all those problems and make it so programmers can productively",
    "start": "178640",
    "end": "185280"
  },
  {
    "text": "manage the performance of their applications without having to write large pieces of infrastructure themselves",
    "start": "185280",
    "end": "192000"
  },
  {
    "start": "191000",
    "end": "242000"
  },
  {
    "text": "so i'm going to begin by sharing a performance story from akka.net so this is the other you know big open",
    "start": "192000",
    "end": "197280"
  },
  {
    "text": "source project that i work on i just gave a talk about it uh the last session here and it's designed to be a high",
    "start": "197280",
    "end": "203599"
  },
  {
    "text": "performance distributed actor framework and so that means that we have to have some performance goals around how",
    "start": "203599",
    "end": "210159"
  },
  {
    "text": "quickly actors process messages how quickly they're able to send them over the network how much memory they use how",
    "start": "210159",
    "end": "217360"
  },
  {
    "text": "quickly they can start and shut down so forth these are all things that actually really do matter to our end users a lot",
    "start": "217360",
    "end": "223760"
  },
  {
    "text": "of them are building applications that have their own real-time response requirements we have people who are using akka.net",
    "start": "223760",
    "end": "230560"
  },
  {
    "text": "for safety critical systems do you think if we had a four second gc pause between when someone pressed an",
    "start": "230560",
    "end": "236720"
  },
  {
    "text": "all system stop button and when the machine turned off that could be a problem yeah",
    "start": "236720",
    "end": "243120"
  },
  {
    "text": "so here was the problem that we had in one patch last year we rolled this",
    "start": "243120",
    "end": "248400"
  },
  {
    "text": "out to our users in production and we got a bunch of reports back right away saying hey the my akka.net cluster",
    "start": "248400",
    "end": "256720"
  },
  {
    "text": "slowed to a crawl where i'm getting something like one-fifth of the throughput i used to",
    "start": "256720",
    "end": "262079"
  },
  {
    "text": "get and that's the difference between my system staying up and serving my customers and going down and so",
    "start": "262079",
    "end": "268960"
  },
  {
    "text": "we went ahead and we loosely measured it and realized that we were doing something like 2400 messages per second",
    "start": "268960",
    "end": "275440"
  },
  {
    "text": "which is terrible that's not good and so the problem",
    "start": "275440",
    "end": "280840"
  },
  {
    "text": "was when our team decided to get on it and tackle this problem the conversation looked a lot like this",
    "start": "280840",
    "end": "287199"
  },
  {
    "start": "281000",
    "end": "316000"
  },
  {
    "text": "one person asking maybe it's the serializer that's the problem then another chimes in my benchmark",
    "start": "287199",
    "end": "292639"
  },
  {
    "text": "shows it's our tcp transport that's the issue this is probably me in this conversation my benchmark shows the",
    "start": "292639",
    "end": "299520"
  },
  {
    "text": "performance is fine this user is doing it wrong then there's someone else that says i",
    "start": "299520",
    "end": "304800"
  },
  {
    "text": "profiled the code and it's the thread pull i found it then we have the one jerk on our team",
    "start": "304800",
    "end": "309840"
  },
  {
    "text": "who basically mentioned that hermione dies in the deathly hallows yeah it's a harry potter joke",
    "start": "309840",
    "end": "317199"
  },
  {
    "start": "316000",
    "end": "356000"
  },
  {
    "text": "and so the the gist of it was this became this sort of endless conversation where it was like watching dogs chase",
    "start": "317199",
    "end": "323039"
  },
  {
    "text": "their tails except in github comments where no one was able to have a coherent",
    "start": "323039",
    "end": "328240"
  },
  {
    "text": "conversation about the performance of our code because we were all using totally different tools",
    "start": "328240",
    "end": "333360"
  },
  {
    "text": "totally different environments totally different hardware totally different benchmarks",
    "start": "333360",
    "end": "338400"
  },
  {
    "text": "totally different instrumentations and you get it there was nothing in common at all it's like a bunch of people",
    "start": "338400",
    "end": "343840"
  },
  {
    "text": "shouting in different foreign languages to each other trying to have a conversation",
    "start": "343840",
    "end": "348880"
  },
  {
    "text": "so where endbench came into the picture here as i invented it to put an end to this conversation before it drove me",
    "start": "348880",
    "end": "355440"
  },
  {
    "text": "insane so end bench was designed literally to settle an argument is where this",
    "start": "355440",
    "end": "360560"
  },
  {
    "start": "356000",
    "end": "399000"
  },
  {
    "text": "originally came from about what is the real performance number of this feature of akka.net and",
    "start": "360560",
    "end": "367120"
  },
  {
    "text": "more importantly how is each change in our software going forward affect this measure",
    "start": "367120",
    "end": "373919"
  },
  {
    "text": "so the idea was to go ahead and standardize our benchmark on one piece of code",
    "start": "373919",
    "end": "379520"
  },
  {
    "text": "measured with one instrumentation measured on one machine our build server was going to be the single source of",
    "start": "379520",
    "end": "385199"
  },
  {
    "text": "truth for this that way when people wanted to have a conversation about the performance there",
    "start": "385199",
    "end": "390479"
  },
  {
    "text": "was one authoritative place to get that data going forward and so here's what the results of that",
    "start": "390479",
    "end": "396639"
  },
  {
    "text": "looked like for us on the akka.net project we started really recording our end",
    "start": "396639",
    "end": "402720"
  },
  {
    "start": "399000",
    "end": "562000"
  },
  {
    "text": "bench performance data at the beginning of december and you can see here this is sort of the messages per second is what this graph",
    "start": "402720",
    "end": "409280"
  },
  {
    "text": "is showing you can see here on the left we're sort of in this like 2400 range right around there as measured by n bench",
    "start": "409280",
    "end": "416160"
  },
  {
    "text": "and we see a little increase right here in the performance of really tiny minute one that's because we found some",
    "start": "416160",
    "end": "422240"
  },
  {
    "text": "inefficient thing we were doing with i think a string format call somewhere in there so we fixed that tiny nudge and",
    "start": "422240",
    "end": "428639"
  },
  {
    "text": "performance well then one of our developers spent a week or two profiling some code and came",
    "start": "428639",
    "end": "434319"
  },
  {
    "text": "the conclusion that we had a contention issue and a custom thread pool implementation we were using",
    "start": "434319",
    "end": "440479"
  },
  {
    "text": "so he went ahead and rewrote that and we had this big jump in performance up to about eight or nine thousand messages",
    "start": "440479",
    "end": "446880"
  },
  {
    "text": "per second again big improvement great then we had another incremental improvement here as a result of fixing",
    "start": "446880",
    "end": "453280"
  },
  {
    "text": "something in our serialization system and this giant jump here was me screwing up the benchmark",
    "start": "453280",
    "end": "460800"
  },
  {
    "text": "so specifically i designed it so the benchmark i started counting its results before most of it finished running",
    "start": "461360",
    "end": "468160"
  },
  {
    "text": "so i fixed that and then on top of that because of uh the windows azure marketplace doing something weird",
    "start": "468160",
    "end": "474400"
  },
  {
    "text": "our visual studio license on our build server expired and had to re-image it so we sort of lost our performance baseline",
    "start": "474400",
    "end": "480720"
  },
  {
    "text": "here and it kind of jumped around a little bit but then we sort of stabilized again this is the most important part of the",
    "start": "480720",
    "end": "486400"
  },
  {
    "text": "graph what never happens there once we start measuring it the performance never goes back down",
    "start": "486400",
    "end": "492639"
  },
  {
    "text": "again there's a saying so i i'm a entrepreneur in addition to a software engineer and",
    "start": "492639",
    "end": "498479"
  },
  {
    "text": "there's a saying sort of amongst uh people who are working in marketing at a startup company that if you can't",
    "start": "498479",
    "end": "504000"
  },
  {
    "text": "measure it you can't control it if you aren't aware of sort of what your metrics look like as far as people using",
    "start": "504000",
    "end": "509520"
  },
  {
    "text": "your product you can't have a real conversation around what you need to do differently the same is true for performance by",
    "start": "509520",
    "end": "516000"
  },
  {
    "text": "having this sort of history of our performance available for anyone to look at we can have a real conversation on",
    "start": "516000",
    "end": "521599"
  },
  {
    "text": "whether a given piece of change to our code was an improvement or not it stopped being the sort of mysticism",
    "start": "521599",
    "end": "528720"
  },
  {
    "text": "everyone knows that string builders faster than pending strings together right well we decided to go ahead and",
    "start": "528720",
    "end": "534560"
  },
  {
    "text": "basically use this end bench system as a way of talking about data rather than talking about theories",
    "start": "534560",
    "end": "541040"
  },
  {
    "text": "and then the performance continued to improve gradually over time too that's the other thing to notice once you sort of set a performance",
    "start": "541040",
    "end": "547440"
  },
  {
    "text": "baseline and you start testing against that you'll find that your performance tends to always get better around the clock",
    "start": "547440",
    "end": "554880"
  },
  {
    "text": "so really end bench was a tool that we wanted to use to sort of create a culture of measuring and testing against",
    "start": "554880",
    "end": "560560"
  },
  {
    "text": "performance so i look at performance testing is actually a type of defensive programming",
    "start": "560560",
    "end": "566480"
  },
  {
    "start": "562000",
    "end": "707000"
  },
  {
    "text": "to some extent what we want to try to avoid are sudden negative changes in the system",
    "start": "566480",
    "end": "572080"
  },
  {
    "text": "memory consumption being one example if someone changed the default queue implementation that we use in our",
    "start": "572080",
    "end": "578080"
  },
  {
    "text": "mailbox in akka.net to be something that was much more memory expensive that might mean that our customers who",
    "start": "578080",
    "end": "583760"
  },
  {
    "text": "run akka.net on xamarin android or on embedded devices running you know linux",
    "start": "583760",
    "end": "589440"
  },
  {
    "text": "out in the field wouldn't work properly anymore so we have to go ahead and basically protect against that",
    "start": "589440",
    "end": "595440"
  },
  {
    "text": "throughput that whole story i just told you was how we didn't do that and it really pissed off some of our users",
    "start": "595440",
    "end": "601279"
  },
  {
    "text": "never want to let that happen again garbage collection overhead the number one enemy of sort of any high",
    "start": "601279",
    "end": "608720"
  },
  {
    "text": "throughput application is going to be your garbage collector for the most part and the reason is that when you need to",
    "start": "608720",
    "end": "613920"
  },
  {
    "text": "go and collect those older generation objects gen 2 in particular unless you have sort of a synchronous",
    "start": "613920",
    "end": "620320"
  },
  {
    "text": "garbage collection turned on that used to mean you'd have a pause across all your threads every 20 or 30 milliseconds",
    "start": "620320",
    "end": "627279"
  },
  {
    "text": "and that can actually make a real difference in some of your in your total system throughput and also your total",
    "start": "627279",
    "end": "632640"
  },
  {
    "text": "system reliability too so this is something that we tend to keep an eye on so these are the three metrics that and the akka.net project we",
    "start": "632640",
    "end": "639040"
  },
  {
    "text": "really care about now other things that other folks using n bench use a lot of them care a lot",
    "start": "639040",
    "end": "645040"
  },
  {
    "text": "about io if you're developing a xamarin application you want to know how much",
    "start": "645040",
    "end": "650640"
  },
  {
    "text": "bandwidth you're using right that makes a real impact on this experience your end users have",
    "start": "650640",
    "end": "656240"
  },
  {
    "text": "so you might want to keep an eye on how big your message sizes are going over the network that'd be one example",
    "start": "656240",
    "end": "662160"
  },
  {
    "text": "number of network calls how many round trips does a request a web api make to sql server every time",
    "start": "662160",
    "end": "668720"
  },
  {
    "text": "you have to process it if your entity framework the answer is something really large",
    "start": "668720",
    "end": "674480"
  },
  {
    "text": "sorry shared resource contention is another one",
    "start": "674480",
    "end": "679519"
  },
  {
    "text": "so one thing that some folks would try to track is for a given scenario how many resources",
    "start": "679519",
    "end": "686640"
  },
  {
    "text": "how many different sort of you know threads or tasks are all trying to concurrently access the same thing contention overhead can be a real cost",
    "start": "686640",
    "end": "693760"
  },
  {
    "text": "in a system quick show of hands who's ever had to debug a sql server lock contention issue in production",
    "start": "693760",
    "end": "700839"
  },
  {
    "text": "before amen brothers and sisters so it's a real thing real problem we",
    "start": "700839",
    "end": "706320"
  },
  {
    "text": "have to deal with so this is where the concept of performance life cycle management steps",
    "start": "706320",
    "end": "711519"
  },
  {
    "start": "707000",
    "end": "906000"
  },
  {
    "text": "in so the way i look at this is that for any given application you",
    "start": "711519",
    "end": "717519"
  },
  {
    "text": "have a set of performance constraints that you have to live in this is determined by the environment in",
    "start": "717519",
    "end": "722959"
  },
  {
    "text": "which your application runs so quick show hands is a application running on someone's phone",
    "start": "722959",
    "end": "729040"
  },
  {
    "text": "going to have different performance constraints than a big server side application in windows azure who thinks so",
    "start": "729040",
    "end": "735360"
  },
  {
    "text": "yeah exactly right the environment is sort of what dictates a lot of those constraints the other part of it might be the",
    "start": "735360",
    "end": "741279"
  },
  {
    "text": "expectations you set with your users how many of you run sas software as part of your as part of your work quick show",
    "start": "741279",
    "end": "747680"
  },
  {
    "text": "of hands a handful of you do you have service level agreements with your customers",
    "start": "747680",
    "end": "752880"
  },
  {
    "text": "around turn around time availability that sort of thing those might determine some of your constraints as well",
    "start": "752880",
    "end": "760160"
  },
  {
    "text": "then the next part of the performance life cycle is the notion of your performance critical path",
    "start": "760160",
    "end": "765200"
  },
  {
    "text": "now a little cautionary note about this it's not always obvious if you're building a twitter application",
    "start": "765200",
    "end": "771279"
  },
  {
    "text": "on you know xamarin your performance critical path might usually be the home screen where you're",
    "start": "771279",
    "end": "776560"
  },
  {
    "text": "loading all the content that's what people spend you know 90 percent of their time doing",
    "start": "776560",
    "end": "781839"
  },
  {
    "text": "but that doesn't mean that other parts your application aren't on the performance critical path too and i'll give you another embarrassing example",
    "start": "781839",
    "end": "788240"
  },
  {
    "text": "from akka.net so unfortunately before we started using",
    "start": "788240",
    "end": "793360"
  },
  {
    "text": "end bench and even a little bit afterwards the way we found out about performance problems was typically from our users",
    "start": "793360",
    "end": "799600"
  },
  {
    "text": "and one example was we had a situation occur where we made a change to our software we",
    "start": "799600",
    "end": "805600"
  },
  {
    "text": "published it and we got a bug report back about 48 hours later saying it takes 10 minutes to shut down my actor",
    "start": "805600",
    "end": "811760"
  },
  {
    "text": "system now and so we started taking a look through it and what turned out to be the case",
    "start": "811760",
    "end": "817839"
  },
  {
    "text": "was we had a link statement that someone modified between patches that used to be lazily evaluated",
    "start": "817839",
    "end": "823600"
  },
  {
    "text": "someone added a to list call at the very end of that so it was fully evaluated on every request",
    "start": "823600",
    "end": "829760"
  },
  {
    "text": "so for a sufficiently large actor system that became immensely expensive so we had to go and change that back and come",
    "start": "829760",
    "end": "836320"
  },
  {
    "text": "up with a better construct for it then we added an end bench test and that's never happened again since",
    "start": "836320",
    "end": "841600"
  },
  {
    "text": "but the performance critical path can surprise you so the way i'd sort of describe what's on the performance critical path it's if",
    "start": "841600",
    "end": "848560"
  },
  {
    "text": "a customer has ever yelled at you about it it's on the path",
    "start": "848560",
    "end": "853360"
  },
  {
    "text": "then you set targets against the past 10 minutes for shutting down an actor system with 200 000 actors is not",
    "start": "853760",
    "end": "859920"
  },
  {
    "text": "acceptable we said we set a target a lot lower than that two seconds was the number we picked",
    "start": "859920",
    "end": "865680"
  },
  {
    "text": "so we want to go ahead and make sure that we have a target that is sort of aligned with the expectations of our end",
    "start": "865680",
    "end": "871120"
  },
  {
    "text": "users so if you're working on a server side application a user might",
    "start": "871120",
    "end": "878160"
  },
  {
    "text": "expect to get a response back from a web api you design in 500 milliseconds that means that the components that are",
    "start": "878160",
    "end": "884720"
  },
  {
    "text": "running inside that system have to execute faster than that right considering all the other types of overhead you're supporting there so you",
    "start": "884720",
    "end": "891519"
  },
  {
    "text": "might go ahead and bound all the other subunits of your application underneath that one global target",
    "start": "891519",
    "end": "898800"
  },
  {
    "text": "then here's the tricky part measuring against the target how do you determine if you've actually",
    "start": "898800",
    "end": "903839"
  },
  {
    "text": "hit or missed the target or not and then in my opinion the most important part of the performance life",
    "start": "903839",
    "end": "910000"
  },
  {
    "start": "906000",
    "end": "993000"
  },
  {
    "text": "cycle is maintaining what's called the performance history this is a record of how your application has performed",
    "start": "910000",
    "end": "916959"
  },
  {
    "text": "against its goals for every single patch every minor change every pull request",
    "start": "916959",
    "end": "923360"
  },
  {
    "text": "puts a new entry into the performance history what this allows your team to do is produce a graph like the one i showed",
    "start": "923360",
    "end": "929680"
  },
  {
    "text": "earlier where you can go ahead and see how well your applications performed over time and more importantly it tells",
    "start": "929680",
    "end": "935680"
  },
  {
    "text": "you who to yell at when your performance drops so blame distribution is sort of solved by the performance history too",
    "start": "935680",
    "end": "943600"
  },
  {
    "text": "so for every regular update of your software this would be a minor patch pull request would be a good example you",
    "start": "943600",
    "end": "949440"
  },
  {
    "text": "want to go ahead and run this process over again go ahead and measure against target save",
    "start": "949440",
    "end": "954480"
  },
  {
    "text": "it in the performance history for any major version change of your software you want to go ahead and run",
    "start": "954480",
    "end": "959680"
  },
  {
    "text": "the entire process again reason for that well the reason why you'd presumably do a major version",
    "start": "959680",
    "end": "965519"
  },
  {
    "text": "update is because there's significantly new pieces of functionality or old pieces of functionality have been",
    "start": "965519",
    "end": "970720"
  },
  {
    "text": "significantly rewritten or maybe you went ahead and added support for a new run time you didn't",
    "start": "970720",
    "end": "976000"
  },
  {
    "text": "have before great example that we're all dealing with in dot net you know dot net right now is dot net core our benchmarks that",
    "start": "976000",
    "end": "982720"
  },
  {
    "text": "we had for net 4.5 4.6 might be totally different than what they are for net core",
    "start": "982720",
    "end": "988560"
  },
  {
    "text": "so we might have to set totally different targets that are aligned to what that platform can deliver",
    "start": "988560",
    "end": "994480"
  },
  {
    "start": "993000",
    "end": "1026000"
  },
  {
    "text": "end bench belongs in this part of the sort of region here it's designed to help you measure and also assert against",
    "start": "994480",
    "end": "1001279"
  },
  {
    "text": "your target as well as update your performance history so end bench is really designed to plug",
    "start": "1001279",
    "end": "1006639"
  },
  {
    "text": "into your continuous integration system and allow you to continuously measure against your target and create a record",
    "start": "1006639",
    "end": "1013199"
  },
  {
    "text": "of what your what your performance was for each change and ideally you want to do this before that change gets merged",
    "start": "1013199",
    "end": "1019360"
  },
  {
    "text": "into your code base not after the fact retrospective performance debugging isn't fun",
    "start": "1019360",
    "end": "1026720"
  },
  {
    "start": "1026000",
    "end": "1039000"
  },
  {
    "text": "so why is this hard why do people have such a heart you know when we have this sort of uh argument within the akka.net team",
    "start": "1026880",
    "end": "1033600"
  },
  {
    "text": "about what the cause of this problem was what were the what was the real challenge there why was it so difficult",
    "start": "1033600",
    "end": "1039678"
  },
  {
    "start": "1039000",
    "end": "1196000"
  },
  {
    "text": "well the first thing you have to think about when you start measuring performance is the fact that we're using a pre-emptive operating system",
    "start": "1039679",
    "end": "1046640"
  },
  {
    "text": "that means that you're going to have things like schedule different schedules that happen while you're running a benchmark",
    "start": "1046640",
    "end": "1052559"
  },
  {
    "text": "so for instance windows might go ahead and schedule run one of my benchmark differently than",
    "start": "1052559",
    "end": "1058799"
  },
  {
    "text": "run two and i might see a divergent result there as a result of that virtual memory is another fun problem",
    "start": "1058799",
    "end": "1065600"
  },
  {
    "text": "you think you're allocating an object into memory when it's going to disk that's going to show up in your total throughput measurements",
    "start": "1065600",
    "end": "1072880"
  },
  {
    "text": "other processes are a bane of our existence too i gave a version of this talk at net fringe last month and one of the things",
    "start": "1072880",
    "end": "1079360"
  },
  {
    "text": "i did was i had two different end bench benchmarks one was a stress test for helios the",
    "start": "1079360",
    "end": "1085120"
  },
  {
    "text": "socket server that powers akka.net where i had something like 700 open connections on one machine here",
    "start": "1085120",
    "end": "1091840"
  },
  {
    "text": "i had another benchmark trying to assess the performance of some simple function akka.net well the academic function",
    "start": "1091840",
    "end": "1099120"
  },
  {
    "text": "ended up timing out and failing because the other process was using so much of the cpu",
    "start": "1099120",
    "end": "1104640"
  },
  {
    "text": "that's just something that can happen next is hardware variability",
    "start": "1104640",
    "end": "1110400"
  },
  {
    "text": "so cache pinning is a fun little exercise where let's say for instance this is sort of a nuanced issue",
    "start": "1110400",
    "end": "1116960"
  },
  {
    "text": "you decide okay i want to go ahead and try to get rid of operating system unpredictability is a",
    "start": "1116960",
    "end": "1123120"
  },
  {
    "text": "concern so i'm gonna do the smart thing and run multiple iterations of my benchmark and then average them all at",
    "start": "1123120",
    "end": "1129440"
  },
  {
    "text": "the end that way you can sort of average out some of the noise let's say you pick an even number for",
    "start": "1129440",
    "end": "1134640"
  },
  {
    "text": "the number of iterations you're going to run well all of a sudden the compiler and the cpu will get the smart idea to go",
    "start": "1134640",
    "end": "1140640"
  },
  {
    "text": "ahead and do some loop unrolling and other stuff under the hood and you'll end up in a scenario where your result is actually pretty skewed",
    "start": "1140640",
    "end": "1147200"
  },
  {
    "text": "from what it would have been if you'd picked a prime number instead so that's sort of a little fun hardware",
    "start": "1147200",
    "end": "1153120"
  },
  {
    "text": "variation you can deal with but another issue is actually the generation of the chip itself",
    "start": "1153120",
    "end": "1159440"
  },
  {
    "text": "what if one machine you're benchmarking on has a newer generation intel than another it might have more l1 l2 cache",
    "start": "1159440",
    "end": "1166960"
  },
  {
    "text": "available and it might also have potentially different cisc optimizations built into it",
    "start": "1166960",
    "end": "1172720"
  },
  {
    "text": "who here does work with floating point math in some part of their system quick show hands all right",
    "start": "1172720",
    "end": "1179039"
  },
  {
    "text": "well you might end up in a scenario where you benchmark on one machine where the the",
    "start": "1179039",
    "end": "1184400"
  },
  {
    "text": "net sort of just in time compiler is able to go ahead and take advantage of brand new x64 instructions for a new",
    "start": "1184400",
    "end": "1190480"
  },
  {
    "text": "generation chipset that'll produce a totally different result than what you get in an older machine that doesn't have those",
    "start": "1190480",
    "end": "1197600"
  },
  {
    "start": "1196000",
    "end": "1323000"
  },
  {
    "text": "another fun one runtime and dependencies so the garbage collector legit or even",
    "start": "1197600",
    "end": "1203280"
  },
  {
    "text": "just third-party modules you can depend on can actually impact your performance one of my personal favorites",
    "start": "1203280",
    "end": "1210640"
  },
  {
    "text": "was we had an issue where someone noticed that when they updated",
    "start": "1210640",
    "end": "1215760"
  },
  {
    "text": "the version of i think it was i want to say it was one of the serializers we support i think it might",
    "start": "1215760",
    "end": "1221600"
  },
  {
    "text": "have been json.net where they went ahead and upgraded that version of json.net which took into",
    "start": "1221600",
    "end": "1227200"
  },
  {
    "text": "account some basic new ways of sort of representing objects and so forth and our wire format actually got a lot",
    "start": "1227200",
    "end": "1232480"
  },
  {
    "text": "bigger as a result of that so just using sort of a new version of it we ended up being able to sort it out and change",
    "start": "1232480",
    "end": "1238240"
  },
  {
    "text": "some settings to smooth that out but that's an example of a type of downstream change you may not expect",
    "start": "1238240",
    "end": "1243440"
  },
  {
    "text": "right that's another reason why you want to measure those things keep an eye on how your third-party components are working too don't treat them like black",
    "start": "1243440",
    "end": "1250080"
  },
  {
    "text": "boxes next is this is actually kind of a subtle problem how you gather the",
    "start": "1250080",
    "end": "1255280"
  },
  {
    "text": "metrics so these are platform dependent quick show of hands who knows of a good",
    "start": "1255280",
    "end": "1261440"
  },
  {
    "text": "cross-platform way of gathering performancemetrics and net okay the number of hands is zero that's",
    "start": "1261440",
    "end": "1267760"
  },
  {
    "text": "the correct number the answer is not even the what's very difficult to do today",
    "start": "1267760",
    "end": "1274640"
  },
  {
    "text": "if you're working on windows you have great options like performance counters and event tracing for windows",
    "start": "1274640",
    "end": "1279679"
  },
  {
    "text": "on linux you kind of have stuff like being able to go ahead and collect the total amount of available memory from",
    "start": "1279679",
    "end": "1285520"
  },
  {
    "text": "the garbage collector that's sort of about it actually instrumenting your specs can be",
    "start": "1285520",
    "end": "1290559"
  },
  {
    "text": "challenging the last bit here is that it's difficult to design",
    "start": "1290559",
    "end": "1295760"
  },
  {
    "text": "isolated tests so in particular one thing you might have to do is be",
    "start": "1295760",
    "end": "1300880"
  },
  {
    "text": "aware of when you need to go ahead and force some garbage collection to occur during different stages of your test run",
    "start": "1300880",
    "end": "1307919"
  },
  {
    "text": "and there's also potential background noise that can show up too such as things so the garbage collector is probably the worst source of this but",
    "start": "1307919",
    "end": "1314240"
  },
  {
    "text": "there might also be other resources that are being released in the background etc these are all things that make getting",
    "start": "1314240",
    "end": "1320640"
  },
  {
    "text": "clean performance data tough end bench is able to solve most of these problems not all of them i can't stop",
    "start": "1320640",
    "end": "1327679"
  },
  {
    "text": "you guys from running your uh benchmarks on totally different pieces of hardware but i can try to make it easier to get",
    "start": "1327679",
    "end": "1333440"
  },
  {
    "text": "clean data what end bench really offers is an api that feels a lot like writing",
    "start": "1333440",
    "end": "1339760"
  },
  {
    "start": "1335000",
    "end": "1437000"
  },
  {
    "text": "a unit test the real idea behind end bench is the concept of a performance specification",
    "start": "1339760",
    "end": "1346480"
  },
  {
    "text": "i'm going to go ahead and basically dictate that this piece of code is going to be able to execute",
    "start": "1346480",
    "end": "1352240"
  },
  {
    "text": "n number of operations per second and if that code ever falls below the expectation we're going to scream loudly",
    "start": "1352240",
    "end": "1358880"
  },
  {
    "text": "and fail the build during a pull request that's exactly what i want as an open source maintainer i want to go ahead and",
    "start": "1358880",
    "end": "1365760"
  },
  {
    "text": "let my ci system tell me when someone's done something that adversely affects the performance",
    "start": "1365760",
    "end": "1371120"
  },
  {
    "text": "because you know what even with a team of really good.net engineers trying to review every pull",
    "start": "1371120",
    "end": "1376320"
  },
  {
    "text": "request how many of you think you can reliably spot a change that's going to have an impact on performance just by eyeballing",
    "start": "1376320",
    "end": "1383360"
  },
  {
    "text": "it i know i can't i see the guys in particular shaking their heads you know it's uh it's definitely a it's an issue",
    "start": "1383360",
    "end": "1390559"
  },
  {
    "text": "where you really want to let your automation do that for you next thing the end bench does is it basically creates a record of your",
    "start": "1390559",
    "end": "1396960"
  },
  {
    "text": "performance we write the output of your performance specification to a file that way you can go and review it later and",
    "start": "1396960",
    "end": "1403520"
  },
  {
    "text": "we also have some customizable outputs too you can go ahead and basically write your output to a sql server database if",
    "start": "1403520",
    "end": "1409360"
  },
  {
    "text": "you wanted to next is the data itself is collected reliably and it's believable when you",
    "start": "1409360",
    "end": "1415600"
  },
  {
    "text": "take a look at it so we have instrumentation built into end bench designed to go ahead and isolate the end",
    "start": "1415600",
    "end": "1422080"
  },
  {
    "text": "bench process some other processes on windows we go ahead and adjust things like the thread priority and the actual",
    "start": "1422080",
    "end": "1427520"
  },
  {
    "text": "process of the priority of the process to sort of ensure that the end bench process gets scheduled ahead of other",
    "start": "1427520",
    "end": "1433039"
  },
  {
    "text": "things these are the sort of common practices when you try to collect performance data",
    "start": "1433039",
    "end": "1438080"
  },
  {
    "start": "1437000",
    "end": "1475000"
  },
  {
    "text": "and mention is also fast how useful would a benchmarking library be if it was slower than the thing it",
    "start": "1438080",
    "end": "1443279"
  },
  {
    "text": "was benchmarking not very reliable right sandwich is designed to be fast it's",
    "start": "1443279",
    "end": "1450000"
  },
  {
    "text": "meant to be configurable it's also meant to be extensible and benches systems can be extended to",
    "start": "1450000",
    "end": "1455440"
  },
  {
    "text": "support alternative ways of gathering metrics you can go ahead and extend it to basic",
    "start": "1455440",
    "end": "1460799"
  },
  {
    "text": "riots output the different targets we even had someone who just came up with a way of having end bench get hooked into",
    "start": "1460799",
    "end": "1466720"
  },
  {
    "text": "the x unit test runner and resharper people have come up with some pretty clever stuff to do with it and it's also",
    "start": "1466720",
    "end": "1472880"
  },
  {
    "text": "open source it's all licensed under apache 2. this is what n bench spec looks like so",
    "start": "1472880",
    "end": "1478880"
  },
  {
    "start": "1475000",
    "end": "1670000"
  },
  {
    "text": "this is one i think i pulled this from yeah this is from akka.net actually",
    "start": "1478880",
    "end": "1484080"
  },
  {
    "text": "so i have this object up here called a counter one thing that end bench was designed to",
    "start": "1484080",
    "end": "1489120"
  },
  {
    "text": "do so what some folks might have asked me before about end bench versus something like benchmark.net who's heard of",
    "start": "1489120",
    "end": "1495440"
  },
  {
    "text": "benchmark.net quick show of hands so they've been using that on the dotnet core project to go ahead and measure the",
    "start": "1495440",
    "end": "1500799"
  },
  {
    "text": "speeds of kestrel and some of the other tooling that's coming out there i use benchmark.net in my day-to-day",
    "start": "1500799",
    "end": "1506000"
  },
  {
    "text": "work and it's a really effective tool for micro benchmarking if you really want to precisely measure how many",
    "start": "1506000",
    "end": "1511760"
  },
  {
    "text": "allocations or how much or how long it takes to execute you know a million iterations of a particular function",
    "start": "1511760",
    "end": "1518559"
  },
  {
    "text": "benchmark.net will give you really precise results one of the things that end bench does is",
    "start": "1518559",
    "end": "1523919"
  },
  {
    "text": "it gives us the ability to go ahead and perform that sort of measurement for concurrent code because it was designed for akka.net and",
    "start": "1523919",
    "end": "1530320"
  },
  {
    "text": "it's meant to be concurrent itself so these counters are thread safe and then here i go ahead and have a",
    "start": "1530320",
    "end": "1536000"
  },
  {
    "text": "counter name and then i specify how many what's my boundary going to be and i want to test in this case a million",
    "start": "1536000",
    "end": "1542000"
  },
  {
    "text": "operations per second i want to guarantee this parsing function can perform that and i think right now it goes much",
    "start": "1542000",
    "end": "1547760"
  },
  {
    "text": "faster than that but still that's like the minimum threshold we agreed on then i have a little setup method here",
    "start": "1547760",
    "end": "1553679"
  },
  {
    "text": "where i basically go and allocate the counter in advance one thing you never want to include in your benchmark is any of your setup",
    "start": "1553679",
    "end": "1560080"
  },
  {
    "text": "overhead for obvious reasons right the amount of time it takes you to instrument the test",
    "start": "1560080",
    "end": "1565600"
  },
  {
    "text": "shouldn't impact the test itself so that's why we treat those separately so we get our counter save its value up",
    "start": "1565600",
    "end": "1571919"
  },
  {
    "text": "here and then we have the actual benchmark specification itself so i have this perf benchmark attribute",
    "start": "1571919",
    "end": "1579200"
  },
  {
    "text": "this basically tells the mbench runner that we have a performance specification here and i'll go ahead and walk through",
    "start": "1579200",
    "end": "1584400"
  },
  {
    "text": "what some of these settings mean in a little bit more detail but here's the really interesting part right here",
    "start": "1584400",
    "end": "1589600"
  },
  {
    "text": "we have our throughput assertion and our gc measurement what our throughput assertion is",
    "start": "1589600",
    "end": "1595039"
  },
  {
    "text": "basically saying is that for this counter's value we expect at the end of this benchmark",
    "start": "1595039",
    "end": "1602480"
  },
  {
    "text": "that the actual number of operations per second will be greater than whatever",
    "start": "1602480",
    "end": "1607600"
  },
  {
    "text": "this count this value was and i think i specify that at a million so when i run this benchmark we'll go ahead and see that the actual output of",
    "start": "1607600",
    "end": "1614640"
  },
  {
    "text": "it will uh will exceed this and so this assertion will pass then i also have a gc measurement here",
    "start": "1614640",
    "end": "1620400"
  },
  {
    "text": "i'm just going to go ahead and record how many garbage collection events there are while the benchmark runs and i'm also specifying this benchmark",
    "start": "1620400",
    "end": "1626880"
  },
  {
    "text": "will run 13 times we'll go ahead and allow it to run for about a second",
    "start": "1626880",
    "end": "1632159"
  },
  {
    "text": "and we're doing what's called a throughput benchmark this means that what end bench will do",
    "start": "1632159",
    "end": "1637919"
  },
  {
    "text": "is it'll estimate how long how many iterations of this function it'll take to last one second and it'll use that as",
    "start": "1637919",
    "end": "1644000"
  },
  {
    "text": "its baseline for this spec and then the last bit here this test mode equals measurement this means that",
    "start": "1644000",
    "end": "1650720"
  },
  {
    "text": "we're actually not triggering the assertions right now even though i have this counter throughput assertion attribute here i'm not actually going to",
    "start": "1650720",
    "end": "1656640"
  },
  {
    "text": "run the assertion so there's going to be no pass fail logic here sort of a soft switch for turning that off",
    "start": "1656640",
    "end": "1662880"
  },
  {
    "text": "if i set this test mode back to assertion it would run this assertion again that's what's going on there",
    "start": "1662880",
    "end": "1670398"
  },
  {
    "start": "1670000",
    "end": "2161000"
  },
  {
    "text": "so end bench is really about testing code against performance specifications i want to go ahead and set a target for",
    "start": "1671200",
    "end": "1678080"
  },
  {
    "text": "what i want to hit and i want to get a pass failed assertion back depending on whether we achieve that or not",
    "start": "1678080",
    "end": "1684799"
  },
  {
    "text": "now what i'm going to go ahead and do here is i'm going to pull up a piece of code and go ahead and switch",
    "start": "1684799",
    "end": "1692159"
  },
  {
    "text": "here all right",
    "start": "1692159",
    "end": "1698720"
  },
  {
    "text": "so i'm going to go ahead and open up my perf results folder let's see",
    "start": "1698720",
    "end": "1705840"
  },
  {
    "text": "don't think i have a result yet okay that's all right i'm gonna go ahead and actually run this",
    "start": "1705919",
    "end": "1712320"
  },
  {
    "text": "akka.net benchmark here so let me go ahead and copy this real quick",
    "start": "1712320",
    "end": "1717360"
  },
  {
    "text": "there we go let me copy that go to",
    "start": "1717360",
    "end": "1724720"
  },
  {
    "text": "here",
    "start": "1724720",
    "end": "1727039"
  },
  {
    "text": "so we're going to run the benchmark that i was showing on screen all right",
    "start": "1729760",
    "end": "1736080"
  },
  {
    "text": "i'm going to go ahead and let that run for a moment so i basically specified with the command line arguments i wanted to skip",
    "start": "1736159",
    "end": "1743120"
  },
  {
    "text": "a whole bunch of benchmarks that weren't really relevant here so here we can see on the screen is each",
    "start": "1743120",
    "end": "1748480"
  },
  {
    "text": "iteration of the benchmark is going in you know basically counting how long it took to run how many different",
    "start": "1748480",
    "end": "1754240"
  },
  {
    "text": "iterations of the counter were there and how many completed in under a second",
    "start": "1754240",
    "end": "1759440"
  },
  {
    "text": "all right so this should finish in a couple of seconds here",
    "start": "1760480",
    "end": "1766799"
  },
  {
    "text": "all right cool it looks like it has another spec that i caught in my regex that's okay",
    "start": "1766799",
    "end": "1772000"
  },
  {
    "text": "well that's running i'm gonna go ahead and pull up my little ndc folder here",
    "start": "1772000",
    "end": "1777919"
  },
  {
    "text": "all right control shift b",
    "start": "1777919",
    "end": "1782640"
  },
  {
    "text": "all right okay",
    "start": "1783039",
    "end": "1789520"
  },
  {
    "text": "so we can go ahead and see the output that end bench produced right here so if i scroll through it you can see",
    "start": "1789520",
    "end": "1794960"
  },
  {
    "text": "the fully qualified name of the performance method you can see the human readable description i applied here",
    "start": "1794960",
    "end": "1801679"
  },
  {
    "text": "as well as some system information so what sort of what is what's our processor count what version of windows",
    "start": "1801679",
    "end": "1806880"
  },
  {
    "text": "are we using a version of end bench how many threads are there sort of thing and then we get down to the data",
    "start": "1806880",
    "end": "1814559"
  },
  {
    "text": "so we can see here that based on our totals we basically estimated that we could run about 597 000 iterations of this code in",
    "start": "1814559",
    "end": "1822880"
  },
  {
    "text": "a second that's using the very first warm-up that we generated so",
    "start": "1822880",
    "end": "1829279"
  },
  {
    "text": "one of the things that occurs during the warm-up is remember i mentioned earlier that we want to try to smooth out as much of the",
    "start": "1829679",
    "end": "1836240"
  },
  {
    "text": "noise of the system as possible what are a couple of things that can occur the very first time you run a benchmark that might throw off its",
    "start": "1836240",
    "end": "1842559"
  },
  {
    "text": "numbers any guesses how about the jit compiler",
    "start": "1842559",
    "end": "1847919"
  },
  {
    "text": "you have to go and jit the code the very first time you run it right so that's one piece of overhead that we",
    "start": "1847919",
    "end": "1852960"
  },
  {
    "text": "try to smooth out by running a warm-up before we start doing the totals what are a couple of other factors that",
    "start": "1852960",
    "end": "1858720"
  },
  {
    "text": "might affect the benchmark disk it's actually going and running this",
    "start": "1858720",
    "end": "1863760"
  },
  {
    "text": "they're loading the assembly running at the first time yeah that's one what go ahead",
    "start": "1863760",
    "end": "1869360"
  },
  {
    "text": "cache warming up specifically cache pinning inside the cpu we want to pin all the instructions for this function",
    "start": "1869360",
    "end": "1875440"
  },
  {
    "text": "in there too so a benchmark let's see what the end bench will do is it'll go ahead and actually run",
    "start": "1875440",
    "end": "1881600"
  },
  {
    "text": "a number of warm-up sets so try to basically ensure the cache is pinned and to go ahead and basically start getting",
    "start": "1881600",
    "end": "1887440"
  },
  {
    "text": "a cleaner signal for a read here so you see up top that we picked 597 000",
    "start": "1887440",
    "end": "1894080"
  },
  {
    "text": "operations during sort of the first part of our warm-up but at the very bottom",
    "start": "1894080",
    "end": "1899120"
  },
  {
    "text": "you can see that my sort of per second totals down here are actually higher than that that we're doing closer to 700 000 operations per",
    "start": "1899120",
    "end": "1906720"
  },
  {
    "text": "second reason why that is is because we actually did get the instructions cached",
    "start": "1906720",
    "end": "1912399"
  },
  {
    "text": "the jitter didn't need to do any additional work and at this rate the only thing really affecting the quality of our benchmark",
    "start": "1912399",
    "end": "1919360"
  },
  {
    "text": "was the actual overhead of the function and anything else the operating system might have been doing in the background",
    "start": "1919360",
    "end": "1925919"
  },
  {
    "text": "now if i scroll down here and i take a look at the raw collections you can see here the total number of",
    "start": "1925919",
    "end": "1931600"
  },
  {
    "text": "garbage collection attempts for generation zero so we're averaging looks like 332",
    "start": "1931600",
    "end": "1936960"
  },
  {
    "text": "collections per run the fact that numbers pretty consistent across each of these runs probably means",
    "start": "1936960",
    "end": "1942399"
  },
  {
    "text": "that it's uh we've sort of collected the right number this is a pretty precise figure by the looks of it",
    "start": "1942399",
    "end": "1948399"
  },
  {
    "text": "for gen 1 we can see we're not allocating any objects neither are we for gen 2.",
    "start": "1948399",
    "end": "1954480"
  },
  {
    "text": "so this is good means this function is not allocating long-lived objects that's what we want",
    "start": "1954480",
    "end": "1960640"
  },
  {
    "text": "then down here we can see the parse results so i can go ahead and see that we run",
    "start": "1960640",
    "end": "1966720"
  },
  {
    "text": "these same number of times but take a look at these values differing a little bit you can see those little deviations",
    "start": "1966720",
    "end": "1972480"
  },
  {
    "text": "here this is as a result of the preemptive operating system at work where there might be other things that are getting",
    "start": "1972480",
    "end": "1978640"
  },
  {
    "text": "scheduled under the same cores in the background you know i'm running powerpoint and a copy of chrome and",
    "start": "1978640",
    "end": "1983679"
  },
  {
    "text": "other stuff in the background so there's lots of other processes that might be competing for some of those cycles",
    "start": "1983679",
    "end": "1989200"
  },
  {
    "text": "and where you can really see that show up a little bit is this value on the right number of nanoseconds per operation",
    "start": "1989200",
    "end": "1995440"
  },
  {
    "text": "you can sort of see how that varies a little bit we're all sort of in this range of about 1450 nanos per operation but there is",
    "start": "1995440",
    "end": "2003120"
  },
  {
    "text": "some variation that occurs there so what you want to do with any benchmark is don't worry about a single",
    "start": "2003120",
    "end": "2008880"
  },
  {
    "text": "data point you want to plot a line instead so you want to care about the line on the graph not an individual data",
    "start": "2008880",
    "end": "2014960"
  },
  {
    "text": "point and so we're not running any assertions here so this is there's no sort of real pass",
    "start": "2014960",
    "end": "2021120"
  },
  {
    "text": "or fail going on now one thing i want to show sort of an example",
    "start": "2021120",
    "end": "2026320"
  },
  {
    "text": "of things that can affect the benchmark pull that back up i'm going to go ahead and unplug my",
    "start": "2026320",
    "end": "2032720"
  },
  {
    "text": "laptop so it's in low power mode now i'm going to run that benchmark again",
    "start": "2032720",
    "end": "2037760"
  },
  {
    "text": "and we'll see if the results are different this time now that my laptop is running on battery power",
    "start": "2037760",
    "end": "2043039"
  },
  {
    "text": "okay operations per second still looks pretty good we'll go ahead and have to see what the",
    "start": "2043039",
    "end": "2048720"
  },
  {
    "text": "final results look like looks to me like it's running a little bit more slowly but not by much because this isn't",
    "start": "2048720",
    "end": "2054720"
  },
  {
    "text": "really a super i o intensive piece of code that's using a lot of different devices or peripherals in the computer",
    "start": "2054720",
    "end": "2060720"
  },
  {
    "text": "it's a fairly simple string parsing function basically the code that we're testing here is what we use to parse an",
    "start": "2060720",
    "end": "2066320"
  },
  {
    "text": "akadana actor address from a string that's all that it's really doing okay looks like the operation sort of",
    "start": "2066320",
    "end": "2072560"
  },
  {
    "text": "finished so let me go ahead and pull up my code here again",
    "start": "2072560",
    "end": "2078240"
  },
  {
    "text": "and i can see that these files have different time stamps on it so i think this is the one",
    "start": "2078240",
    "end": "2083280"
  },
  {
    "text": "534 yeah this is it all right cool",
    "start": "2083280",
    "end": "2088398"
  },
  {
    "text": "so i'll go ahead and do ctrl shift b again let me pull this up",
    "start": "2088399",
    "end": "2095280"
  },
  {
    "text": "so this is the second benchmark that we ran now we take a look at that",
    "start": "2095280",
    "end": "2101760"
  },
  {
    "text": "the average value here is 662 000 operations per second",
    "start": "2101760",
    "end": "2106880"
  },
  {
    "text": "whereas here was 684 000 operations per second so",
    "start": "2106880",
    "end": "2113440"
  },
  {
    "text": "we're seeing a deviation of about 20 000 operations per second again not very much but what you'd expect given that",
    "start": "2113440",
    "end": "2119680"
  },
  {
    "text": "the laptop is going to be running on a lower power mode when it's disconnected right that's an example of being able to",
    "start": "2119680",
    "end": "2126079"
  },
  {
    "text": "produce a sort of reliable result under the circumstances there so this is what embench's",
    "start": "2126079",
    "end": "2131839"
  },
  {
    "text": "instrumentation is designed to help you measure reliably is the ability to go ahead and determine when your",
    "start": "2131839",
    "end": "2137920"
  },
  {
    "text": "environment changes when your dependencies change when your code changes what was the impact on the performance",
    "start": "2137920",
    "end": "2143680"
  },
  {
    "text": "of this unit of code let me go back to my powerpoint here",
    "start": "2143680",
    "end": "2149119"
  },
  {
    "text": "all right sorry about this",
    "start": "2149119",
    "end": "2154560"
  },
  {
    "text": "okay so in bench is all about testing code against its performance specifications",
    "start": "2154560",
    "end": "2161359"
  },
  {
    "start": "2161000",
    "end": "2236000"
  },
  {
    "text": "so some of the different types of benchmarks we offer from a test mode point of view we have",
    "start": "2161359",
    "end": "2166480"
  },
  {
    "text": "measurement versus assertion the difference here is whether you get a pass fail at the end when you go ahead",
    "start": "2166480",
    "end": "2171920"
  },
  {
    "text": "and use some of those assertion attributes we also have the different run modes",
    "start": "2171920",
    "end": "2176960"
  },
  {
    "text": "there's the concept of an iteration mode which i'm not using the idea behind iteration benchmark is",
    "start": "2176960",
    "end": "2183040"
  },
  {
    "text": "let's say you want to test a fairly large block of code like an entire feature you want to go ahead and benchmark how an entire feature works",
    "start": "2183040",
    "end": "2189440"
  },
  {
    "text": "end-to-end you typically set that up as an iteration benchmark where you want to say okay",
    "start": "2189440",
    "end": "2194720"
  },
  {
    "text": "i want to go ahead and run this benchmark that uses a fairly large piece of code 100 times and see what the final",
    "start": "2194720",
    "end": "2201520"
  },
  {
    "text": "output is and i'll pull up an example one of those in a moment",
    "start": "2201520",
    "end": "2206800"
  },
  {
    "text": "so yeah run end times the other idea is this throughput benchmark which is what we just did with",
    "start": "2206880",
    "end": "2213280"
  },
  {
    "text": "that parsing function these are designed for basically run a piece of code continuously for a fixed block of time",
    "start": "2213280",
    "end": "2220400"
  },
  {
    "text": "and what you want to do there is basically generate some load and measure by how well a very small",
    "start": "2220400",
    "end": "2226320"
  },
  {
    "text": "unit of code worked so this throughput benchmark is really for these like micro benchmark components",
    "start": "2226320",
    "end": "2231839"
  },
  {
    "text": "iteration is really for these more macro larger components",
    "start": "2231839",
    "end": "2236720"
  },
  {
    "text": "now in terms of the things that we measure throughput is one that you saw us use how many things happened in a given",
    "start": "2236960",
    "end": "2242880"
  },
  {
    "text": "second memory consumption is another thing that we can test we use a fairly coarse-grained way of measuring that we",
    "start": "2242880",
    "end": "2250000"
  },
  {
    "text": "try to actually design end bench to be somewhat cross-platform so it'll be easier to port.net core we use the",
    "start": "2250000",
    "end": "2255440"
  },
  {
    "text": "garbage collector for getting that number which isn't as precise as what you can get using like event tracing for",
    "start": "2255440",
    "end": "2260720"
  },
  {
    "text": "windows or dot memory but you can actually plug in different sort of memory consumption measures if",
    "start": "2260720",
    "end": "2266079"
  },
  {
    "text": "you want so the total number of bytes allocated is sort of what we measured today",
    "start": "2266079",
    "end": "2271520"
  },
  {
    "text": "garbage collection you saw us going in measuring collections per generation so you can go ahead and basically write a",
    "start": "2271520",
    "end": "2276800"
  },
  {
    "text": "benchmark where you can assert that gen 2 is always equal to zero if you wanted to that's the type of assertion we",
    "start": "2276800",
    "end": "2282160"
  },
  {
    "text": "support elapsed time this is end to end how long did it take to do something",
    "start": "2282160",
    "end": "2287520"
  },
  {
    "text": "we have a benchmark in alca.net for testing against that a long shutdown situation where we go ahead and say the",
    "start": "2287520",
    "end": "2293119"
  },
  {
    "text": "elapsed time for a actor system of this size to shut down must be under this number",
    "start": "2293119",
    "end": "2298720"
  },
  {
    "text": "we have that set up then we also have a support for some custom measures so we have a performance",
    "start": "2298720",
    "end": "2304240"
  },
  {
    "text": "counter plug-in for end bench that allow you to go ahead and instrument any arbitrary performance counter against an end bench spec so we've seen people use",
    "start": "2304240",
    "end": "2311359"
  },
  {
    "text": "that for measuring things like total number of bytes transferred to sql server before that's one example",
    "start": "2311359",
    "end": "2317680"
  },
  {
    "start": "2317000",
    "end": "2508000"
  },
  {
    "text": "so i already gave you a little demo now the next sort of big set of features that we're going to try to add to end",
    "start": "2317680",
    "end": "2323760"
  },
  {
    "text": "bench down the road is the notion of an automated performance history where end bench will output its history to some",
    "start": "2323760",
    "end": "2330079"
  },
  {
    "text": "service some web service somewhere that'll be able to go ahead and ingest that data and give you a nice graph",
    "start": "2330079",
    "end": "2336079"
  },
  {
    "text": "but not rather than the one i had to construct from excel before this will go ahead and do that for you automatically",
    "start": "2336079",
    "end": "2341520"
  },
  {
    "text": "on a web web ui last thing i want to show real briefly is an iteration benchmark",
    "start": "2341520",
    "end": "2348320"
  },
  {
    "text": "so this is one of my favorites and only i'm going to run it because it will take like 10 minutes",
    "start": "2348320",
    "end": "2354920"
  },
  {
    "text": "that's not what i wanted to do all right this is what we use and we have a version of this an end bench and another",
    "start": "2354960",
    "end": "2360880"
  },
  {
    "text": "version in dot-net which are both sort of socket libraries and net we call this a horizontal scaling specification",
    "start": "2360880",
    "end": "2368480"
  },
  {
    "text": "what we want to try to determine here actually let me scroll back up what we want to try to determine with",
    "start": "2368480",
    "end": "2373520"
  },
  {
    "text": "this benchmark is on a single machine how many connections can we open",
    "start": "2373520",
    "end": "2379520"
  },
  {
    "text": "before the throughput on a single server before the throughput begins to drop now this benchmark isn't exactly fair",
    "start": "2379520",
    "end": "2385839"
  },
  {
    "text": "because the client's workload and the server are both happening on the same machine but to help give us an",
    "start": "2385839",
    "end": "2390960"
  },
  {
    "text": "approximation for what the sort of resource overhead looks like so we have sort of a client and a server",
    "start": "2390960",
    "end": "2397920"
  },
  {
    "text": "bootstrap we have a set of event loop groups for the client and the server these are the different thread pools that are going to",
    "start": "2397920",
    "end": "2404160"
  },
  {
    "text": "be running those workloads and then we set up a few counters we have a counter for the number of",
    "start": "2404160",
    "end": "2410720"
  },
  {
    "text": "clients that have been able to connect the inbound throughput and the outbound throughput",
    "start": "2410720",
    "end": "2416720"
  },
  {
    "text": "and what we do here we have a couple of setup functions set up our server and our client",
    "start": "2417040",
    "end": "2425119"
  },
  {
    "text": "yep yep yep let me scroll down here we go what this benchmark basically does",
    "start": "2425119",
    "end": "2430160"
  },
  {
    "text": "is we go ahead and pick a random block of time that we want to choose like three or four minutes",
    "start": "2430160",
    "end": "2435359"
  },
  {
    "text": "i think in the last version of this i did for uh nettie which i don't think has been merged in",
    "start": "2435359",
    "end": "2440720"
  },
  {
    "text": "yet i think i picked a static amount of time for that and what we do is you just go ahead and iterate",
    "start": "2440720",
    "end": "2447599"
  },
  {
    "text": "over this loop and we continue to basically just keep spawning clients that go and generate a",
    "start": "2447599",
    "end": "2452880"
  },
  {
    "text": "continuous load they'll go ahead and generate i think 10 messages per second each in the background and this test on this little surface pro",
    "start": "2452880",
    "end": "2459599"
  },
  {
    "text": "4 here can generate about 850 open connections before we basically hit our maximum sort of timeout which is that it",
    "start": "2459599",
    "end": "2466560"
  },
  {
    "text": "took longer than uh 10 seconds to open 10 connections we go ahead and sort of end the stress spec then this is an",
    "start": "2466560",
    "end": "2472560"
  },
  {
    "text": "example of something that's a little bit more like macro scale you can do with enbench 2. and the the merits of this are really",
    "start": "2472560",
    "end": "2478880"
  },
  {
    "text": "there to determine sort of how much overhead goes into a client server connection end-to-end",
    "start": "2478880",
    "end": "2484640"
  },
  {
    "text": "so that's the idea behind endbench and what our goal with this project really is is to allow you to go and plug in",
    "start": "2484640",
    "end": "2490640"
  },
  {
    "text": "performance testing into your continuous integration system and have it as something your team continuously monitors in each pull request going",
    "start": "2490640",
    "end": "2497040"
  },
  {
    "text": "forward so that's it for sort of my prepared content and i'll be happy to take some questions",
    "start": "2497040",
    "end": "2503440"
  },
  {
    "text": "if you have any now thank you very much",
    "start": "2503440",
    "end": "2507960"
  },
  {
    "start": "2508000",
    "end": "2629000"
  },
  {
    "text": "okay do we have a microphone we can pass around i think they're getting it",
    "start": "2510880",
    "end": "2516799"
  },
  {
    "text": "okay yeah i'm back microphones coming there we go",
    "start": "2518800",
    "end": "2524880"
  },
  {
    "text": "so you were mentioning before about os variability uh would that be mitigated",
    "start": "2524880",
    "end": "2530400"
  },
  {
    "text": "somewhat if you were to run your application in the container if you're going to run your application in a container those cores are still",
    "start": "2530400",
    "end": "2537599"
  },
  {
    "text": "being well actually let me rephrase as long as you're able to pin one core to one container meaning that nothing else",
    "start": "2537599",
    "end": "2543520"
  },
  {
    "text": "could really schedule onto that then that would mitigate that to some extent however if that core is still if it like",
    "start": "2543520",
    "end": "2550240"
  },
  {
    "text": "logically belongs the container but it's still really time shared across them then it wouldn't make a difference at",
    "start": "2550240",
    "end": "2555359"
  },
  {
    "text": "all so that's also kind of a problem one thing we do with with akka.net's",
    "start": "2555359",
    "end": "2560560"
  },
  {
    "text": "build farm right now which is a bit of a problem is we use auto scaling with team city to go and dynamically allocate our",
    "start": "2560560",
    "end": "2566160"
  },
  {
    "text": "build agents well we've noticed that even though we're all using the same generation of azure vms there's still significant",
    "start": "2566160",
    "end": "2572240"
  },
  {
    "text": "variations in the values that we record in our benchmark there's two reasons for that",
    "start": "2572240",
    "end": "2577680"
  },
  {
    "text": "even though they're all in the same generation they still have different hardware but there's also the fact that",
    "start": "2577680",
    "end": "2582720"
  },
  {
    "text": "we're running on a virtual machine who's to say we don't have a noisy neighbor who's sharing the same physical",
    "start": "2582720",
    "end": "2588319"
  },
  {
    "text": "hardware that vm is on at any given time my one of my board members at my last",
    "start": "2588319",
    "end": "2593599"
  },
  {
    "text": "company was a major aws customer and noticed that they were having these horrible cpu",
    "start": "2593599",
    "end": "2598960"
  },
  {
    "text": "starvation problems on their own system even though their application wasn't under a huge",
    "start": "2598960",
    "end": "2604000"
  },
  {
    "text": "amount of load turns out they were sharing the same boxes as foursquare was that's why they were having problems",
    "start": "2604000",
    "end": "2610400"
  },
  {
    "text": "theirs time was being stolen by their neighbor basically so that's one example of where hypervisors and containers still don't",
    "start": "2610400",
    "end": "2617520"
  },
  {
    "text": "necessarily give you the resource isolation they promise sometimes yeah good question",
    "start": "2617520",
    "end": "2623599"
  },
  {
    "text": "uh you have one",
    "start": "2623599",
    "end": "2626400"
  },
  {
    "start": "2629000",
    "end": "2824000"
  },
  {
    "text": "so um at what stage in your alm cycle do you normally",
    "start": "2629680",
    "end": "2634800"
  },
  {
    "text": "perform these tests what stage in your alm cycle do you want to start introducing performance tests",
    "start": "2634800",
    "end": "2641040"
  },
  {
    "text": "that's a good question you know i would say what the quote that people throw out",
    "start": "2641040",
    "end": "2647280"
  },
  {
    "text": "there about premature optimization is the root of all evil there's actually like a second part of",
    "start": "2647280",
    "end": "2652560"
  },
  {
    "text": "that that i don't fully remember but it's basically you should still measure performance of your code anyway and try to improve it uh where you can just that",
    "start": "2652560",
    "end": "2659599"
  },
  {
    "text": "don't over optimize things right away i think you should introduce performance tests around the same time you start",
    "start": "2659599",
    "end": "2665440"
  },
  {
    "text": "finishing features when you have something that can be for performance tested you should start doing that that",
    "start": "2665440",
    "end": "2671359"
  },
  {
    "text": "way at the very least let's say the performance sucks for your very first generation that's okay no one's using it",
    "start": "2671359",
    "end": "2676560"
  },
  {
    "text": "yet right but when you start setting that baseline you can see improvement over time what it gives you is that sort of",
    "start": "2676560",
    "end": "2683280"
  },
  {
    "text": "defensive programming means of never backsliding into bad performance again so when you're at a stage where you're",
    "start": "2683280",
    "end": "2689839"
  },
  {
    "text": "able to measure the performance of something that's when i'd start trying to do that uh as long as it's reasonably easy to do",
    "start": "2689839",
    "end": "2695760"
  },
  {
    "text": "it okay because one one caveat to make perhaps the um you know setting a scheduled",
    "start": "2695760",
    "end": "2701839"
  },
  {
    "text": "um time on these um performance tests is that i can see",
    "start": "2701839",
    "end": "2708000"
  },
  {
    "text": "fairly quickly that you know you might have a branch and after unit tests you might run your performance tests but if",
    "start": "2708000",
    "end": "2715040"
  },
  {
    "text": "you set a bunch of these to run say for a minute or two minutes these aggregated",
    "start": "2715040",
    "end": "2721760"
  },
  {
    "text": "these may aggregate to you know just running five minutes until it actually um merges back into",
    "start": "2721760",
    "end": "2728560"
  },
  {
    "text": "master or developer whatever you're talking about the length of the build process yeah so here's a here's the scary fact",
    "start": "2728560",
    "end": "2735440"
  },
  {
    "text": "akka.net's uh end and time to basically run a full build of the system so we have 80 projects in our visual studio",
    "start": "2735440",
    "end": "2742079"
  },
  {
    "text": "solution and about a third of those are tests of some sort",
    "start": "2742079",
    "end": "2747680"
  },
  {
    "text": "so we have i think three to four thousand unit tests about 200 performance tests and about 70 what are",
    "start": "2747680",
    "end": "2753920"
  },
  {
    "text": "called distributed unit tests where we actually go and simulate a network if i ran the end to end build chain on",
    "start": "2753920",
    "end": "2759520"
  },
  {
    "text": "my laptop here it would take 90 minutes to execute what we do on the build server is we",
    "start": "2759520",
    "end": "2765280"
  },
  {
    "text": "actually go this is a little bit more about ci than end bench we actually go ahead and have different machines run",
    "start": "2765280",
    "end": "2770800"
  },
  {
    "text": "each of those steps in parallel is what we do so that way i'm running the same 30 minute execution block in three",
    "start": "2770800",
    "end": "2777359"
  },
  {
    "text": "places at once right so that's one way you're doing it yeah one thing you absolutely cannot do with",
    "start": "2777359",
    "end": "2782400"
  },
  {
    "text": "the performance test is parallelize it that will that's for obvious reasons that won't work so you do end up having",
    "start": "2782400",
    "end": "2788960"
  },
  {
    "text": "some extra time added to your build process for that so what i would encourage your developers to do in that environment is",
    "start": "2788960",
    "end": "2796000"
  },
  {
    "text": "maybe don't run all the performance tests locally for each step they do have a build server process that's",
    "start": "2796000",
    "end": "2801440"
  },
  {
    "text": "designed to parallelize that work and just farm it out to that that's what we do in the on the dot net and akka.net",
    "start": "2801440",
    "end": "2807280"
  },
  {
    "text": "projects too is we let the build server do a lot of that work because it's just not productive for the developers to run it all the time locally anyway",
    "start": "2807280",
    "end": "2814319"
  },
  {
    "text": "so yeah",
    "start": "2814319",
    "end": "2817800"
  },
  {
    "start": "2824000",
    "end": "2999000"
  },
  {
    "text": "hi there how you doing hello good are you really yeah okay i've got two questions um",
    "start": "2825200",
    "end": "2831200"
  },
  {
    "text": "first one is around downstream dependencies mm-hmm talk to me about this",
    "start": "2831200",
    "end": "2837119"
  },
  {
    "text": "um they're the worst avoid them yeah i get that i'm just kidding um",
    "start": "2837119",
    "end": "2842160"
  },
  {
    "text": "we're downstream dependencies in the real world downstream dependencies here's what i really mean",
    "start": "2842160",
    "end": "2849359"
  },
  {
    "text": "particularly with major versions of downstream dependencies you got to go ahead and say okay is this downstream dependency in a performance critical",
    "start": "2849359",
    "end": "2855920"
  },
  {
    "text": "path great example of that in occu.net is our serializers that we depend on",
    "start": "2855920",
    "end": "2861040"
  },
  {
    "text": "with the remoting pipeline and also the persistent system that we use for saving events the serialization system sits in",
    "start": "2861040",
    "end": "2867280"
  },
  {
    "text": "the middle of that so the impacts are serial of the speed of our serializer will affect the speed",
    "start": "2867280",
    "end": "2873280"
  },
  {
    "text": "of our remoting system so we're in the process of switching from json.net to wire right now knock.net wire is about",
    "start": "2873280",
    "end": "2880400"
  },
  {
    "text": "25 times faster than json.net and that shows up in the benchmark big time",
    "start": "2880400",
    "end": "2885520"
  },
  {
    "text": "so what you want to do is just have a measurement set up so you can witness the impact of that it just gives you",
    "start": "2885520",
    "end": "2891440"
  },
  {
    "text": "visibility into it as a team so that's that's the the sort of high level part of that that status answer",
    "start": "2891440",
    "end": "2897520"
  },
  {
    "text": "your question yes that's one part of my first question uh what about anything that has across",
    "start": "2897520",
    "end": "2903440"
  },
  {
    "text": "the network do you ever use this to hit network like external systems and",
    "start": "2903440",
    "end": "2908960"
  },
  {
    "text": "kind of test them uh yes i've used this to hit like sql azure databases before yep so i",
    "start": "2908960",
    "end": "2914800"
  },
  {
    "text": "had some performance test a um an entity framework application at one point and one of the things i was paying",
    "start": "2914800",
    "end": "2921119"
  },
  {
    "text": "attention to was my elapsed time end to end how long did it take for me to complete a full cycle of one request",
    "start": "2921119",
    "end": "2929200"
  },
  {
    "text": "and so i used end bench there to go ahead and basically just get a measurement of that the other thing i measured was i used a",
    "start": "2929200",
    "end": "2934720"
  },
  {
    "text": "performance counter to see how much traffic was going on to the network during this part two so i wanted to get",
    "start": "2934720",
    "end": "2940000"
  },
  {
    "text": "a sense for okay if i have a pipe between here and sql azure that can handle n number of bytes",
    "start": "2940000",
    "end": "2947119"
  },
  {
    "text": "and windows azure is well designed it can handle a lot but still i wanted to know what's the upper limit of this",
    "start": "2947119",
    "end": "2952319"
  },
  {
    "text": "system i want to go ahead and say okay how much is when we go ahead and run this one web method of this web api that was",
    "start": "2952319",
    "end": "2959359"
  },
  {
    "text": "developed what's the total amount of bandwidth it uses so i'd go ahead and measure that those benchmarks will take a while",
    "start": "2959359",
    "end": "2966160"
  },
  {
    "text": "because they depend on external network calls but they're still worth doing so yeah not all benchmarks need to be",
    "start": "2966160",
    "end": "2972079"
  },
  {
    "text": "running a function hundreds of thousands of times to see how quickly it turns right okay that's the idea of those",
    "start": "2972079",
    "end": "2977359"
  },
  {
    "text": "iteration benchmarks that basically are bigger blocks of code that take longer to run okay cool yep our second question",
    "start": "2977359",
    "end": "2983440"
  },
  {
    "text": "is can you catch can i catch yeah uh not very well",
    "start": "2983440",
    "end": "2988880"
  },
  {
    "text": "yes well enough hold on commonwealth bank all right thank you",
    "start": "2989200",
    "end": "2995119"
  },
  {
    "text": "uh next question sergey first of all great work and i forgot who",
    "start": "2995119",
    "end": "3002000"
  },
  {
    "start": "2999000",
    "end": "3128000"
  },
  {
    "text": "said that if you don't measure what you're doing you're not an engineer yeah you're proving that",
    "start": "3002000",
    "end": "3007440"
  },
  {
    "text": "i'm curious if you ever measure the impact of hyper threading measure the impact of hyper threading",
    "start": "3007440",
    "end": "3014319"
  },
  {
    "text": "now that's an interesting one we um when we actually go ahead and take a look at that core count and the sort of",
    "start": "3014319",
    "end": "3020160"
  },
  {
    "text": "report up there it's the number of logical cpus right so for every sort of intel based processor that's going to show",
    "start": "3020160",
    "end": "3026400"
  },
  {
    "text": "where that has hyper threading in it that's going to show up as two we don't have a i don't have a measurement right now for breaking that",
    "start": "3026400",
    "end": "3032960"
  },
  {
    "text": "down where it's like what's the what's the impact of having things scheduled under the same like same",
    "start": "3032960",
    "end": "3039280"
  },
  {
    "text": "hyper-threaded cpu right so no i haven't done that that'd be interesting though um",
    "start": "3039280",
    "end": "3044880"
  },
  {
    "text": "i actually don't know a while ago and it was very negative so we turned it off and never measured after that you turned",
    "start": "3044880",
    "end": "3050319"
  },
  {
    "text": "hyper threading off yes oh that's good to know i should i should take a look at that one thing that we i",
    "start": "3050319",
    "end": "3055680"
  },
  {
    "text": "have a pull request that's open for this on end bench right now but we have a um well these are going to make more",
    "start": "3055680",
    "end": "3060720"
  },
  {
    "text": "extensible you saw that list of information about the system is pretty basic right now what we're going to do",
    "start": "3060720",
    "end": "3065760"
  },
  {
    "text": "is we have a system that queries wmi and pulls a much more detailed fingerprint of your system",
    "start": "3065760",
    "end": "3071440"
  },
  {
    "text": "being able to see what generation a processor you're using is hyper threading turned on and maybe some other",
    "start": "3071440",
    "end": "3076720"
  },
  {
    "text": "important settings too like what's the size of the virtual page file just throwing that out there as an example",
    "start": "3076720",
    "end": "3082960"
  },
  {
    "text": "these would be interesting things to know potentially and sort of getting a more complete benchmark another thing i've seen uh folks",
    "start": "3082960",
    "end": "3089440"
  },
  {
    "text": "particularly at the benchmark.net project do is experiment with what's the performance of your application with different jit configurations comparing",
    "start": "3089440",
    "end": "3096640"
  },
  {
    "text": "classic versus ryujit for instance they'll also go ahead and test things like x86 versus x64",
    "start": "3096640",
    "end": "3103280"
  },
  {
    "text": "now if you've got a piece of code that doesn't align to a 32-bit cache you're going to see a noticeable performance",
    "start": "3103280",
    "end": "3108559"
  },
  {
    "text": "difference there so those are all things that i think um you know in terms of what end bench",
    "start": "3108559",
    "end": "3114079"
  },
  {
    "text": "scratches the surface of today there's a lot more work to be done there in terms of getting that much more detailed",
    "start": "3114079",
    "end": "3119119"
  },
  {
    "text": "metrics about different system configurations and the impact they can have cool",
    "start": "3119119",
    "end": "3125040"
  },
  {
    "text": "yes so i was wondering if you thought uh",
    "start": "3125040",
    "end": "3130319"
  },
  {
    "start": "3128000",
    "end": "3231000"
  },
  {
    "text": "this might be good context friend bench at my company global company we've got a lot of jobs",
    "start": "3130319",
    "end": "3135760"
  },
  {
    "text": "that users run and the jobs can take anywhere from three seconds to ten minutes and some of them are very time sensitive",
    "start": "3135760",
    "end": "3143920"
  },
  {
    "text": "obviously i'm talking outside the build pipeline but do you think uh end bench would be good perhaps nightly or weekly",
    "start": "3143920",
    "end": "3150400"
  },
  {
    "text": "kind of running through hours and hours of these like running each job once just to kind of get that historical graph of",
    "start": "3150400",
    "end": "3157119"
  },
  {
    "text": "time because that seems like it'd be really useful yeah absolutely being able to use so basically having a cron job",
    "start": "3157119",
    "end": "3163040"
  },
  {
    "text": "that runs in bench and like using the elapsed time measurement might be a good one so when we run this job what was the",
    "start": "3163040",
    "end": "3169520"
  },
  {
    "text": "end to end processing time for that being able to go ahead and see a trend line where let's say you were able to",
    "start": "3169520",
    "end": "3174559"
  },
  {
    "text": "produce consistent results over time for the same job that's good but what happens if you see a big a big",
    "start": "3174559",
    "end": "3181680"
  },
  {
    "text": "dip in processing time will that be something that would indicate that maybe there's something up with that customer's account if it's a",
    "start": "3181680",
    "end": "3188079"
  },
  {
    "text": "data driven thing or maybe the piece of code that that job is running has changed in some way so yeah that'd be a",
    "start": "3188079",
    "end": "3193599"
  },
  {
    "text": "useful thing to do absolutely any other questions",
    "start": "3193599",
    "end": "3199279"
  },
  {
    "text": "uh wire is the name of it so it's uh if you go to akka.net on github wire you",
    "start": "3200160",
    "end": "3205599"
  },
  {
    "text": "can see that there they're currently working on net core support for it yep w-i-r-e",
    "start": "3205599",
    "end": "3213040"
  },
  {
    "text": "yep we like picking names for open source projects that aren't easily googleable",
    "start": "3213040",
    "end": "3218880"
  },
  {
    "text": "that's how you know all right any other questions",
    "start": "3218880",
    "end": "3224078"
  },
  {
    "text": "all right thank you very much",
    "start": "3224480",
    "end": "3228280"
  }
]
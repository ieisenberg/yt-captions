[
  {
    "start": "0",
    "end": "220000"
  },
  {
    "text": "for joining the session my name is Ari I'm a developer with dock works and I",
    "start": "14140",
    "end": "20350"
  },
  {
    "text": "came here from Germany where I'm serving as the head of AI for thought works German and today I want to talk about",
    "start": "20350",
    "end": "28779"
  },
  {
    "text": "the challenges of applying continuous delivery to machine learning applications maybe it's a quick raise of",
    "start": "28779",
    "end": "37660"
  },
  {
    "text": "hands how many of you are developers okay I think there was almost every",
    "start": "37660",
    "end": "44440"
  },
  {
    "text": "single one so I guess we do not have any data scientists in the room right we do",
    "start": "44440",
    "end": "49750"
  },
  {
    "text": "fantastically so I'm a developer myself I'm not a data scientist but there's a",
    "start": "49750",
    "end": "56109"
  },
  {
    "text": "topic that's fascinates me quite a bit so before I go into the topic let me say",
    "start": "56109",
    "end": "63309"
  },
  {
    "text": "a few very quick words about what works so who of you has heard of taught works",
    "start": "63309",
    "end": "71610"
  },
  {
    "text": "few of you are nice so taught works at its core is an IT",
    "start": "71610",
    "end": "77980"
  },
  {
    "text": "consultancy we are quite a bit smaller than the big IT consultancies but we are",
    "start": "77980",
    "end": "84040"
  },
  {
    "text": "a truly global company with offices in 14 countries and we have a lovely office",
    "start": "84040",
    "end": "92110"
  },
  {
    "text": "just 10 minutes down the road here but I'm for instance I'm from the Berlin",
    "start": "92110",
    "end": "97360"
  },
  {
    "text": "office in Germany and one of the things that I believe he makes us stand out a",
    "start": "97360",
    "end": "103960"
  },
  {
    "text": "little bit is that we strongly believe in the power of diversity and that we",
    "start": "103960",
    "end": "109390"
  },
  {
    "text": "can actually make the world a better place through what we do in our daily work and then the other thing that we",
    "start": "109390",
    "end": "117850"
  },
  {
    "text": "strongly believe in is open knowledge and this is why I thought workers are",
    "start": "117850",
    "end": "122950"
  },
  {
    "text": "very active in terms of conference speaking like here but also in terms of",
    "start": "122950",
    "end": "127960"
  },
  {
    "text": "writing books so co-workers have actually been among the first to write about lean about agile about micro",
    "start": "127960",
    "end": "135490"
  },
  {
    "text": "services but also about continuous delivery what is today's topic here",
    "start": "135490",
    "end": "141960"
  },
  {
    "text": "and another publication that published about two times a year is the software",
    "start": "141960",
    "end": "148860"
  },
  {
    "text": "technology rating how many of you have heard or read tech rating not that many",
    "start": "148860",
    "end": "157740"
  },
  {
    "text": "so the technology radar is basically a",
    "start": "157740",
    "end": "163440"
  },
  {
    "text": "state of the industry report so similar to what maybe Gardner companies publish",
    "start": "163440",
    "end": "173340"
  },
  {
    "text": "regularly but what is actually what's special about the talkbox technology",
    "start": "173340",
    "end": "178350"
  },
  {
    "text": "radar is that we only allow ourselves to put in techniques technologies",
    "start": "178350",
    "end": "186570"
  },
  {
    "text": "frameworks etc into that right that we have actually used on projects and with",
    "start": "186570",
    "end": "193950"
  },
  {
    "text": "clients so for instance if we if there is a new technology or new programming",
    "start": "193950",
    "end": "199800"
  },
  {
    "text": "language that we really like but that we couldn't convince a client to actually",
    "start": "199800",
    "end": "205950"
  },
  {
    "text": "use it we don't allow ourselves to put it into the radar because then we don't feel like we have actually seen it in",
    "start": "205950",
    "end": "212430"
  },
  {
    "text": "the wild and know whether it's really good for production and one of the",
    "start": "212430",
    "end": "218700"
  },
  {
    "text": "topics that made it into the last edition of the tech radar is continuous",
    "start": "218700",
    "end": "225330"
  },
  {
    "start": "220000",
    "end": "385000"
  },
  {
    "text": "delivery for machine learning which is the topic of today's talk also we just",
    "start": "225330",
    "end": "232130"
  },
  {
    "text": "published an article on martin fowler's block that goes quite a bit into detail",
    "start": "232130",
    "end": "238140"
  },
  {
    "text": "about that topic do you all know or do",
    "start": "238140",
    "end": "243930"
  },
  {
    "text": "you read martin fowler's block do you know martin follow okay a few more than no stock works I guess",
    "start": "243930",
    "end": "250410"
  },
  {
    "text": "so this we talked and we wrote publish",
    "start": "250410",
    "end": "259650"
  },
  {
    "text": "things about this topic quite a bit during the last six to 12 months but",
    "start": "259650",
    "end": "265680"
  },
  {
    "text": "actually the topic is not really that new and for me personally it all started",
    "start": "265680",
    "end": "272510"
  },
  {
    "text": "almost five years ago already in beginning of 2015 and at that time there",
    "start": "272510",
    "end": "279830"
  },
  {
    "text": "was actually the time I joined clockworks and that was the first project I got on as a developer talk",
    "start": "279830",
    "end": "287810"
  },
  {
    "text": "works and that was with otoscope where we were asked to help them rebuild their",
    "start": "287810",
    "end": "294800"
  },
  {
    "text": "entire platform so Auto sprout is a European company I don't know",
    "start": "294800",
    "end": "303050"
  },
  {
    "text": "here in Australia what is the the most popular platform when you want to sell a car online car sales right that's what I",
    "start": "303050",
    "end": "311210"
  },
  {
    "text": "guess so that is basically what autoscout is in Europe and what we were",
    "start": "311210",
    "end": "320690"
  },
  {
    "text": "asked at the time when we came here was to help auto start to build a free price",
    "start": "320690",
    "end": "326150"
  },
  {
    "text": "estimation product where users could get an idea what they used car is still",
    "start": "326150",
    "end": "331250"
  },
  {
    "text": "working and so the here's how this how",
    "start": "331250",
    "end": "336320"
  },
  {
    "text": "the user interface looks today but it was very similar back then you basically",
    "start": "336320",
    "end": "341930"
  },
  {
    "text": "put in the make and the model of the car and the first year of registration as",
    "start": "341930",
    "end": "349040"
  },
  {
    "text": "well as the mileage because it's about used cars and then you just have to get a rough estimation what the cars still",
    "start": "349040",
    "end": "354740"
  },
  {
    "text": "working I think today this is a fairly typical application of machine learning",
    "start": "354740",
    "end": "359860"
  },
  {
    "text": "back in 2015 I think there were not that many applications where we were",
    "start": "359860",
    "end": "366740"
  },
  {
    "text": "machine learning was really put into the hands of an Hughes or so to say so this",
    "start": "366740",
    "end": "372680"
  },
  {
    "text": "was quite quite exciting to build that and also there we're not that many cases for user",
    "start": "372680",
    "end": "380810"
  },
  {
    "text": "facing applications built that way so when we start with building this this is",
    "start": "380810",
    "end": "387140"
  },
  {
    "text": "the situation looked a little bit like this so there was the team of developers",
    "start": "387140",
    "end": "393190"
  },
  {
    "text": "and I was one of them and we were meant to build the web application the user",
    "start": "393190",
    "end": "399020"
  },
  {
    "text": "interface and so on and down here there was another team the team of the data",
    "start": "399020",
    "end": "405260"
  },
  {
    "text": "scientists and they were managed to build model which we the developers were then",
    "start": "405260",
    "end": "412420"
  },
  {
    "text": "to integrate in the web application and in between us there was literally a wall",
    "start": "412420",
    "end": "418850"
  },
  {
    "text": "because we were sitting on two different floors and then the data scientists they",
    "start": "418850",
    "end": "426440"
  },
  {
    "text": "would provide us with an initial version of the prediction model the prediction",
    "start": "426440",
    "end": "431570"
  },
  {
    "text": "model happened to be decision tree based so that's why I see a tree here and they were using our at the time and then we",
    "start": "431570",
    "end": "440960"
  },
  {
    "text": "in the developer team we integrated this prediction model in the application and",
    "start": "440960",
    "end": "446030"
  },
  {
    "text": "then provided feedback to the data scientists how the model is working in",
    "start": "446030",
    "end": "452930"
  },
  {
    "text": "the application and yeah how it's doing and overall this feedback cycle here in",
    "start": "452930",
    "end": "462890"
  },
  {
    "text": "the beginning was actually awfully slow so kind of we got a version of the",
    "start": "462890",
    "end": "469340"
  },
  {
    "text": "prediction model then certain things didn't work the way we wanted and then",
    "start": "469340",
    "end": "476150"
  },
  {
    "text": "we would give that feedback to the data scientist team and it would take days until we get a new version and then",
    "start": "476150",
    "end": "482960"
  },
  {
    "text": "something was misunderstood and it was tricky to integrate again so this was really really slow and didn't feel very",
    "start": "482960",
    "end": "490760"
  },
  {
    "text": "good and this probably reminds you very",
    "start": "490760",
    "end": "495770"
  },
  {
    "text": "much of the problem between developers and operations which DevOps is all about",
    "start": "495770",
    "end": "503300"
  },
  {
    "text": "to solve right to bring those those things together and actually get rid of this throw over the wall attitude and",
    "start": "503300",
    "end": "512719"
  },
  {
    "text": "also overall we felt like from the development perspective we felt there",
    "start": "512720",
    "end": "517940"
  },
  {
    "text": "was a little empathy from the data scientist side so basically quite often the prediction model a new version would",
    "start": "517940",
    "end": "525740"
  },
  {
    "text": "break the application because the interface has changed and probably the data scientist felt a similar way that",
    "start": "525740",
    "end": "532960"
  },
  {
    "text": "we used to developers we could not really relate to their problems so then",
    "start": "532960",
    "end": "539210"
  },
  {
    "text": "therefore we wanted to apply a DevOps mindset and actually one of the first",
    "start": "539210",
    "end": "544910"
  },
  {
    "text": "things that we did was to bring those teams closer together and get rid of this wall so to say by actually bringing",
    "start": "544910",
    "end": "551990"
  },
  {
    "text": "those those two teams into the same room on the same table and work really",
    "start": "551990",
    "end": "557150"
  },
  {
    "text": "closely together and build one cross-functional team out of this and this was probably the most important",
    "start": "557150",
    "end": "563990"
  },
  {
    "text": "thing and we did things like pairing between developers and data scientists and have given other talks about this",
    "start": "563990",
    "end": "570560"
  },
  {
    "text": "topic long but then of course there's",
    "start": "570560",
    "end": "577670"
  },
  {
    "text": "one side of applying DevOps and then the other side is continuous delivery so we",
    "start": "577670",
    "end": "583190"
  },
  {
    "text": "believe that continuous delivery is really one of the most important practices in DevOps or in a DevOps",
    "start": "583190",
    "end": "590780"
  },
  {
    "text": "culture and generally in top works we pretty much do continuous delivery on",
    "start": "590780",
    "end": "596480"
  },
  {
    "text": "every single project right so it generally felt very natural to also of",
    "start": "596480",
    "end": "603560"
  },
  {
    "text": "life here in this case and of course at the core of continuous delivery there is",
    "start": "603560",
    "end": "610580"
  },
  {
    "text": "the build pipeline and so this is how you can imagine basically the setup that",
    "start": "610580",
    "end": "616850"
  },
  {
    "start": "613000",
    "end": "781000"
  },
  {
    "text": "we that we build here so there is there's one pipeline for building the",
    "start": "616850",
    "end": "624440"
  },
  {
    "text": "prediction model which in the first stage pulls in the data from some base",
    "start": "624440",
    "end": "634100"
  },
  {
    "text": "data source does feature extraction and model training and then as the artifact",
    "start": "634100",
    "end": "641150"
  },
  {
    "text": "out of the stage we get the Train model and then usually this train model needs",
    "start": "641150",
    "end": "646970"
  },
  {
    "text": "to be converted or raft or containerized into some kind of more interoperable",
    "start": "646970",
    "end": "653620"
  },
  {
    "text": "interoperable model that is ready to be pulled into a serving layer and ready to",
    "start": "653620",
    "end": "659450"
  },
  {
    "text": "be served and so in the end this is the final artifact of this of this pipeline",
    "start": "659450",
    "end": "665720"
  },
  {
    "text": "and then there is another pipeline which is the web application pipeline",
    "start": "665720",
    "end": "670810"
  },
  {
    "text": "and this obviously contains the code of the web application and then builds this",
    "start": "670810",
    "end": "677920"
  },
  {
    "text": "and the main artifact here is web applications are and that gets deployed",
    "start": "677920",
    "end": "683350"
  },
  {
    "text": "on a cloud server and when we blowing this this then holds in the latest",
    "start": "683350",
    "end": "691390"
  },
  {
    "text": "version of the prediction model and those two partners they are coupled",
    "start": "691390",
    "end": "697320"
  },
  {
    "text": "so whenever and you are changes made to",
    "start": "697320",
    "end": "703600"
  },
  {
    "text": "the web application we make sure it always puts in your latest prediction model but also importantly whenever",
    "start": "703600",
    "end": "710410"
  },
  {
    "text": "there's a change made to the data science code or the models we change",
    "start": "710410",
    "end": "717960"
  },
  {
    "text": "this should trigger the prediction model pipeline and then actually also trigger",
    "start": "717960",
    "end": "723840"
  },
  {
    "text": "the web application 5-9 to pull in the newest model and basically the final",
    "start": "723840",
    "end": "733660"
  },
  {
    "text": "goal here where we wanted to get because this is the state where we always want to get at continuous delivery was that a",
    "start": "733660",
    "end": "740080"
  },
  {
    "text": "data scientist would push the change could even be a minor one and then it",
    "start": "740080",
    "end": "746470"
  },
  {
    "text": "just would trigger a retraining of the model and there would be enough",
    "start": "746470",
    "end": "752710"
  },
  {
    "text": "automatic quality gates that this new prediction model would automatically go",
    "start": "752710",
    "end": "757780"
  },
  {
    "text": "all the way into production and into the hands of users but actually implementing",
    "start": "757780",
    "end": "765130"
  },
  {
    "text": "this in a rigorous way was quite a bit harder than we anticipated and also it",
    "start": "765130",
    "end": "771520"
  },
  {
    "text": "was quite hard to convince the data scientists of adopting this approach as",
    "start": "771520",
    "end": "776620"
  },
  {
    "text": "it and there are several reasons for this so here are a few of the of the",
    "start": "776620",
    "end": "786430"
  },
  {
    "start": "781000",
    "end": "901000"
  },
  {
    "text": "challenges that we were faced with how to version control training data",
    "start": "786430",
    "end": "793470"
  },
  {
    "text": "training data is usually thousands of files very large so very different to",
    "start": "793470",
    "end": "800620"
  },
  {
    "text": "and then source code also the training data is large and also the prediction",
    "start": "800620",
    "end": "806530"
  },
  {
    "text": "models are actually too large to put them into get because this is not what",
    "start": "806530",
    "end": "811840"
  },
  {
    "text": "it is made for so you need to link to some external storage then another issue",
    "start": "811840",
    "end": "820960"
  },
  {
    "text": "that we had was that a model retraining would initially slow down the entire",
    "start": "820960",
    "end": "827080"
  },
  {
    "text": "continuous delivery server because of course it's quite a different workload to build a web application source code",
    "start": "827080",
    "end": "833860"
  },
  {
    "text": "or to retrain a prediction model then we",
    "start": "833860",
    "end": "841570"
  },
  {
    "text": "found that the data scientists things we wanted to evaluate quite often several solutions at the same time whereas we",
    "start": "841570",
    "end": "849010"
  },
  {
    "text": "from the developer site were usually propagating a trunk based development",
    "start": "849010",
    "end": "854470"
  },
  {
    "text": "and few branches so there was also a bit of a clash and then to make things even worse data scientists they want to use",
    "start": "854470",
    "end": "861250"
  },
  {
    "text": "analytics notebooks right like Jupiter and stuff which is great for doing data science but which is very hard to",
    "start": "861250",
    "end": "867670"
  },
  {
    "text": "version control or at least it's fairly ugly and then how to actually unit test",
    "start": "867670",
    "end": "874570"
  },
  {
    "text": "data science code that is changed that is tied to changing data and it's also not as simple as just writing unit tests",
    "start": "874570",
    "end": "882100"
  },
  {
    "text": "or tests in general for for general software development code and then how",
    "start": "882100",
    "end": "890320"
  },
  {
    "text": "to prevent behavior changes of the model to break the application so those were a",
    "start": "890320",
    "end": "896620"
  },
  {
    "text": "lot of challenges that we were facing at the time so what are the reasons why",
    "start": "896620",
    "end": "903370"
  },
  {
    "start": "901000",
    "end": "1065000"
  },
  {
    "text": "it's so hard to apply continuous delivery to machine learning applications because we were surprised",
    "start": "903370",
    "end": "910060"
  },
  {
    "text": "because we as I said we do this on pretty much every project for quite a",
    "start": "910060",
    "end": "915100"
  },
  {
    "text": "few years now and so yeah we thought we were really used to do this and I",
    "start": "915100",
    "end": "922480"
  },
  {
    "text": "believe there are two main reasons for this to be very hard the one reason are",
    "start": "922480",
    "end": "929650"
  },
  {
    "text": "is that there are different workflows so as developers I think we think that our",
    "start": "929650",
    "end": "939010"
  },
  {
    "text": "workflow is not very linear and very creative and stuff but when you actually",
    "start": "939010",
    "end": "945560"
  },
  {
    "text": "look at it it usually looks like this kind of there is a master branch sometimes we branch out a little bit but",
    "start": "945560",
    "end": "953570"
  },
  {
    "text": "then it gets into the master branch fairly quickly and overall it is fairly clear where we",
    "start": "953570",
    "end": "959480"
  },
  {
    "text": "want to go or at least put every step we know quite quite well what the next goal",
    "start": "959480",
    "end": "965690"
  },
  {
    "text": "is is what we want to achieve with data scientists it's quite different the",
    "start": "965690",
    "end": "973130"
  },
  {
    "text": "typical data scientist workflow is branching out far more so data",
    "start": "973130",
    "end": "979550"
  },
  {
    "text": "scientists they try out many things simultaneously and then just select one of all those things so it's not even",
    "start": "979550",
    "end": "987680"
  },
  {
    "text": "clear in the beginning which one which would be the route to go forward with so there is a much more there's much more",
    "start": "987680",
    "end": "994400"
  },
  {
    "text": "hypothesis driven development in this so um so for instance they may want to",
    "start": "994400",
    "end": "1000839"
  },
  {
    "text": "change the hyper parameters of the model like here this change max depth of the",
    "start": "1000839",
    "end": "1006220"
  },
  {
    "text": "decision tree for instance or they want to try out a different algorithm like random forests here so I think this this",
    "start": "1006220",
    "end": "1015550"
  },
  {
    "text": "flash of all this difference in work loss along mexicoís tricky to kind of cater both groups with the same tool set",
    "start": "1015550",
    "end": "1023620"
  },
  {
    "text": "but at least with the same approach to using those tools and then for the other",
    "start": "1023620",
    "end": "1029680"
  },
  {
    "text": "reason let's have a look what continuous delivery actually means and this is from",
    "start": "1029680",
    "end": "1036120"
  },
  {
    "text": "the book from J's humble and they follow so continuous delivery is the ability to",
    "start": "1036120",
    "end": "1042760"
  },
  {
    "text": "get changes of all types including new features configuration changes bug fixes",
    "start": "1042760",
    "end": "1047920"
  },
  {
    "text": "and experiments into production or into the hands of users safely and quickly in",
    "start": "1047920",
    "end": "1053440"
  },
  {
    "text": "sustainable way so this says says changes of all types",
    "start": "1053440",
    "end": "1058810"
  },
  {
    "text": "including experiments and this is exactly what this is about",
    "start": "1058810",
    "end": "1065850"
  },
  {
    "start": "1065000",
    "end": "1150000"
  },
  {
    "text": "and I would say this is kind of the the second reason which makes it hard there are actually much more types of change",
    "start": "1065880",
    "end": "1071700"
  },
  {
    "text": "that need to be managed so with quite a lot of experience in managing changes of",
    "start": "1071700",
    "end": "1078750"
  },
  {
    "text": "code and sometimes we have other artifacts like assets also that need to",
    "start": "1078750",
    "end": "1084360"
  },
  {
    "text": "be managed as well but here this is really there are just more dimensions",
    "start": "1084360",
    "end": "1090120"
  },
  {
    "text": "because we also have to manage data the training data and this in itself again",
    "start": "1090120",
    "end": "1097320"
  },
  {
    "text": "has multiple dimensions so not only does the shape of the data change like a",
    "start": "1097320",
    "end": "1102720"
  },
  {
    "text": "schema but also the sampling changes because you want to always accurately",
    "start": "1102720",
    "end": "1108690"
  },
  {
    "text": "reflect with the training data how reality looks currently like right and reality changes so you need to change",
    "start": "1108690",
    "end": "1114840"
  },
  {
    "text": "that and then there is the prediction model and the prediction model contains",
    "start": "1114840",
    "end": "1123230"
  },
  {
    "text": "kind of the code to build the prediction model but also hyper parameters all the",
    "start": "1123230",
    "end": "1129540"
  },
  {
    "text": "parameters that are created when training the model and then of course we have the software code as we're used to",
    "start": "1129540",
    "end": "1138630"
  },
  {
    "text": "it but this is this alone kind of creates much more complexity here to",
    "start": "1138630",
    "end": "1144150"
  },
  {
    "text": "manage all those different types of of changes so a set up for continuous",
    "start": "1144150",
    "end": "1154890"
  },
  {
    "start": "1150000",
    "end": "1270000"
  },
  {
    "text": "delivery for machine learning therefore actually needs to integrate all those artifacts and it also needs to cater for",
    "start": "1154890",
    "end": "1164070"
  },
  {
    "text": "different pipelines so this actually came out of many discussions where we",
    "start": "1164070",
    "end": "1170550"
  },
  {
    "text": "were talking about pipelines a lot and at some point we realized we're talking at least about three different kinds of",
    "start": "1170550",
    "end": "1176220"
  },
  {
    "text": "pipelines so one pipeline is the data pipeline right so the data pipeline it",
    "start": "1176220",
    "end": "1184260"
  },
  {
    "text": "pulls in data from the actual source systems and repairs it or makes it",
    "start": "1184260",
    "end": "1191280"
  },
  {
    "text": "available in such a way that it can actually be used for the machine learning application and that is usually",
    "start": "1191280",
    "end": "1197460"
  },
  {
    "text": "what data engineers but sometimes all today also data scientists if there are no data",
    "start": "1197460",
    "end": "1203340"
  },
  {
    "text": "engineers and then the second type of pipeline is the machine learning",
    "start": "1203340",
    "end": "1208920"
  },
  {
    "text": "platform so the machine learning pipeline pulls in the data that has been provided by the data pipeline and then",
    "start": "1208920",
    "end": "1216510"
  },
  {
    "text": "in addition to that pulls in the data science code to code to train the model to parameterize the model and so on and",
    "start": "1216510",
    "end": "1223610"
  },
  {
    "text": "the outcome of this pipeline is the Train prediction model or generally",
    "start": "1223610",
    "end": "1228750"
  },
  {
    "text": "machine learning model and then finally there's the deployment pipeline as we know it and this deployment pipeline in",
    "start": "1228750",
    "end": "1235860"
  },
  {
    "text": "this case here now puts in the prediction model that's the output of the machine learning pipeline and",
    "start": "1235860",
    "end": "1242310"
  },
  {
    "text": "traditionally pulls in the application code and then all this together gets",
    "start": "1242310",
    "end": "1247680"
  },
  {
    "text": "deployed to production so all those three pipelines actually need to be put",
    "start": "1247680",
    "end": "1254580"
  },
  {
    "text": "together and a set up for really keeping",
    "start": "1254580",
    "end": "1261180"
  },
  {
    "text": "your AI indications in production needs to accommodate for all those different pipelines and also it needs to support",
    "start": "1261180",
    "end": "1267990"
  },
  {
    "text": "all those different stages so let's have a look how this all can fit together and",
    "start": "1267990",
    "end": "1273900"
  },
  {
    "start": "1270000",
    "end": "1539000"
  },
  {
    "text": "what the different stages are so it's",
    "start": "1273900",
    "end": "1278910"
  },
  {
    "text": "the very first thing that needs to be discoverable and accessible data otherwise you can't do anything and this",
    "start": "1278910",
    "end": "1285690"
  },
  {
    "text": "is kind of the job of having a good data",
    "start": "1285690",
    "end": "1290940"
  },
  {
    "text": "architecture data governance data lay or data mesh to provide that and then for",
    "start": "1290940",
    "end": "1297660"
  },
  {
    "text": "the application itself the first phase here is data science or the model building stage and that state",
    "start": "1297660",
    "end": "1306690"
  },
  {
    "text": "would or is pulling in training data and it creates a model with parameters or it",
    "start": "1306690",
    "end": "1314700"
  },
  {
    "text": "pulls in parameters for that model and",
    "start": "1314700",
    "end": "1319830"
  },
  {
    "text": "also source code yeah for training data and then the second stage is actually",
    "start": "1319830",
    "end": "1327690"
  },
  {
    "text": "the model evaluation and the data scientist in the room of course know that you need to at least any supervised",
    "start": "1327690",
    "end": "1335260"
  },
  {
    "text": "learning that you need to clearly separate validation data from training",
    "start": "1335260",
    "end": "1340900"
  },
  {
    "text": "data so that your that there was no overfitting to your model so this is the",
    "start": "1340900",
    "end": "1348760"
  },
  {
    "text": "second stage here where you actually test your trained model and usually you",
    "start": "1348760",
    "end": "1354970"
  },
  {
    "text": "also can calculate the accuracy so how good it is how successful the training is so this is what you do in this face",
    "start": "1354970",
    "end": "1363910"
  },
  {
    "text": "with the test data but then afterwards usually need to productionize the model",
    "start": "1363910",
    "end": "1371350"
  },
  {
    "text": "so you usually cannot just take it as into production I guess in some cases",
    "start": "1371350",
    "end": "1377800"
  },
  {
    "text": "you transform this sometimes you wrap it into a different format what you",
    "start": "1377800",
    "end": "1385270"
  },
  {
    "text": "definitely should not do is manually translate it into some other version but",
    "start": "1385270",
    "end": "1390520"
  },
  {
    "text": "we still see it happening here and these days quite often it's containerized to",
    "start": "1390520",
    "end": "1398050"
  },
  {
    "text": "basically put into a into a model service test and the main artifact here",
    "start": "1398050",
    "end": "1406080"
  },
  {
    "text": "but this is quite a crucial step to productionize the model and then they",
    "start": "1406080",
    "end": "1413650"
  },
  {
    "text": "actually needs to be integration testing so that means we take the same test data",
    "start": "1413650",
    "end": "1420700"
  },
  {
    "text": "that was used for the model evaluation and kind of double check whether the",
    "start": "1420700",
    "end": "1427030"
  },
  {
    "text": "integration in the production environment was actually successful so we test the whole setup again here the same data and make sure that it's really",
    "start": "1427030",
    "end": "1434260"
  },
  {
    "text": "coming up with the same results and this is quite a crucial step so in the",
    "start": "1434260",
    "end": "1441220"
  },
  {
    "text": "project that I've been part of this is usually whether where the issue is happening of the integration between the",
    "start": "1441220",
    "end": "1449500"
  },
  {
    "text": "model and yeah the production environment and then if this kind of if",
    "start": "1449500",
    "end": "1457450"
  },
  {
    "text": "all those quality gates until there they get three then this all gets deployed",
    "start": "1457450",
    "end": "1463780"
  },
  {
    "text": "together and then half the deployment you want to monitor the behavior of the whole",
    "start": "1463780",
    "end": "1470679"
  },
  {
    "text": "application of the whole system in the world and ultimately from this",
    "start": "1470679",
    "end": "1476260"
  },
  {
    "text": "monitoring you actually get new data that is the data that is produced by",
    "start": "1476260",
    "end": "1481630"
  },
  {
    "text": "users using the system and this is then",
    "start": "1481630",
    "end": "1487090"
  },
  {
    "text": "actually kind of closing the whole cycle where all the data goes back and this",
    "start": "1487090",
    "end": "1495100"
  },
  {
    "text": "data then all parts of this data serve as new training data so for instance in",
    "start": "1495100",
    "end": "1500649"
  },
  {
    "text": "the case of the price estimation for for used cars users would actually get an",
    "start": "1500649",
    "end": "1509679"
  },
  {
    "text": "estimation of what the cars still work but maybe they would actually deviate from the recommendation and they put the",
    "start": "1509679",
    "end": "1516850"
  },
  {
    "text": "car on the platform for a different price and then we would use this data again to retrain your model and adapt it",
    "start": "1516850",
    "end": "1523570"
  },
  {
    "text": "to the current market situation so this is the the overall overall cycle and",
    "start": "1523570",
    "end": "1530470"
  },
  {
    "text": "this is what we really want to automate and kind of accelerated over time",
    "start": "1530470",
    "end": "1537539"
  },
  {
    "start": "1539000",
    "end": "1797000"
  },
  {
    "text": "so what do we need actually technology-wise to to make this all",
    "start": "1539900",
    "end": "1546080"
  },
  {
    "text": "happen and to build this so first I mentioned before we need to discoverable",
    "start": "1546080",
    "end": "1551150"
  },
  {
    "text": "and accessible data so the data infrastructure then we need version control and artifact repositories for",
    "start": "1551150",
    "end": "1558440"
  },
  {
    "text": "all the different types of artifacts that we're dealing with here then we",
    "start": "1558440",
    "end": "1565070"
  },
  {
    "text": "need a continuous delivery orchestration tool to combine all those different types of pipelines then we need the",
    "start": "1565070",
    "end": "1573320"
  },
  {
    "text": "infrastructure for kind of multiple environments and experiments to allow",
    "start": "1573320",
    "end": "1578480"
  },
  {
    "text": "for kind of this simultaneous experimentation and run multiple things",
    "start": "1578480",
    "end": "1586550"
  },
  {
    "text": "in parallel here then we need tools for model performance assessment to actually",
    "start": "1586550",
    "end": "1592309"
  },
  {
    "text": "find out whether the model is good enough and also whether it's not on",
    "start": "1592309",
    "end": "1598640"
  },
  {
    "text": "whether the quality is not deteriorating over time and then finally we want to",
    "start": "1598640",
    "end": "1604640"
  },
  {
    "text": "monitor and observe the whole system in the wall and so really see how it's",
    "start": "1604640",
    "end": "1609920"
  },
  {
    "text": "performing while its life and you can",
    "start": "1609920",
    "end": "1616190"
  },
  {
    "text": "now actually implement this stack with many different technologies and talkers",
    "start": "1616190",
    "end": "1621530"
  },
  {
    "text": "in particular or at totters we are very technology agnostic so we really choose",
    "start": "1621530",
    "end": "1628370"
  },
  {
    "text": "the tool that is best the best tool for the job and we rarely do any",
    "start": "1628370",
    "end": "1634400"
  },
  {
    "text": "partnerships so this is kind of just one example technology stack that we use to",
    "start": "1634400",
    "end": "1640760"
  },
  {
    "text": "to build this so here this in this case",
    "start": "1640760",
    "end": "1646130"
  },
  {
    "text": "we used Google Cloud storage as the data infrastructure then for version control",
    "start": "1646130",
    "end": "1654350"
  },
  {
    "text": "we used get together with EBC who in the",
    "start": "1654350",
    "end": "1659450"
  },
  {
    "text": "room has heard of DBC again no one doesn't surprise me that much it's a",
    "start": "1659450",
    "end": "1665530"
  },
  {
    "text": "fairly young tool and it's a small tool it's abbreviation for data science",
    "start": "1665530",
    "end": "1672860"
  },
  {
    "text": "version and it's just a small command-line tool",
    "start": "1672860",
    "end": "1677950"
  },
  {
    "text": "and we like it because it is a small command-line tool that you can integrate nicely with existing continuous delivery",
    "start": "1677950",
    "end": "1683899"
  },
  {
    "text": "tools and that kind of bridges a little",
    "start": "1683899",
    "end": "1689179"
  },
  {
    "text": "bit the gap between those between those two different workflows that I talked about earlier and I will actually show",
    "start": "1689179",
    "end": "1695779"
  },
  {
    "text": "you it a little bit in action in a couple of minutes and then for",
    "start": "1695779",
    "end": "1701480"
  },
  {
    "text": "continuous delivery orchestration we use Co CD go CD is a continuous delivery",
    "start": "1701480",
    "end": "1709220"
  },
  {
    "text": "tool that has been built by ThoughtWorks and is maintained by ThoughtWorks but it is open source and we do use a lot of",
    "start": "1709220",
    "end": "1716539"
  },
  {
    "text": "other continuous delivery tools as well here in this case we thought that it would be the weapon of choice so to say",
    "start": "1716539",
    "end": "1723490"
  },
  {
    "text": "because it is very good at this combination of different pipelines and",
    "start": "1723490",
    "end": "1730429"
  },
  {
    "text": "then for the infrastructure we compute in this case with docker of course these",
    "start": "1730429",
    "end": "1737720"
  },
  {
    "text": "days then for model performance assessment we've been using ml flow",
    "start": "1737720",
    "end": "1744429"
  },
  {
    "text": "lately and interestingly there are not many tools around these days for model",
    "start": "1744429",
    "end": "1751009"
  },
  {
    "text": "performance assessment at least that is our impression and ml flow can actually do quite a few more things but this is",
    "start": "1751009",
    "end": "1760249"
  },
  {
    "text": "what we use ml flow for and then for monitoring and observability we",
    "start": "1760249",
    "end": "1766610"
  },
  {
    "text": "basically use kind of a standard stack with elasticsearch fluently and kiba so",
    "start": "1766610",
    "end": "1775279"
  },
  {
    "text": "now I actually want to do a little demo I'm kind of showing something life here",
    "start": "1775279",
    "end": "1781820"
  },
  {
    "text": "but I cannot I do not have the time to kind of go through the entire stack so I",
    "start": "1781820",
    "end": "1786950"
  },
  {
    "text": "will concentrate on this piece here for version control and to continuous",
    "start": "1786950",
    "end": "1793850"
  },
  {
    "text": "delivery orchestration mainly and the",
    "start": "1793850",
    "end": "1798980"
  },
  {
    "start": "1797000",
    "end": "1840000"
  },
  {
    "text": "the demo basically that we look into you will see kind of the pipeline set up",
    "start": "1798980",
    "end": "1805730"
  },
  {
    "text": "that is OCD and a little example application and",
    "start": "1805730",
    "end": "1811919"
  },
  {
    "text": "then I just want to go one time through this continuous delivery cycle where you",
    "start": "1811919",
    "end": "1819419"
  },
  {
    "text": "push a change and then the changes actually tested in this case changing",
    "start": "1819419",
    "end": "1825179"
  },
  {
    "text": "the data science code and then depending on whether and whether it passes the quality gates it is pushed to production",
    "start": "1825179",
    "end": "1832259"
  },
  {
    "text": "so let me see so here we see and I can",
    "start": "1832259",
    "end": "1843090"
  },
  {
    "start": "1840000",
    "end": "1993000"
  },
  {
    "text": "probably make them a bit larger so here",
    "start": "1843090",
    "end": "1850259"
  },
  {
    "text": "we see the two the two delivery pipelines and those are the two",
    "start": "1850259",
    "end": "1855779"
  },
  {
    "text": "pipelines that I was talking about before and keep in mind this is a very",
    "start": "1855779",
    "end": "1862619"
  },
  {
    "text": "simplified example right so this is an example used for a workshop that we ran",
    "start": "1862619",
    "end": "1867740"
  },
  {
    "text": "quite often these days to kind of show how all of this is working but it's very",
    "start": "1867740",
    "end": "1873809"
  },
  {
    "text": "simplified in reality things get quite a bit more complex with farm more pipelines so this is kind of the",
    "start": "1873809",
    "end": "1881820"
  },
  {
    "text": "application pipeline the web application pipeline and this is the machine learning pipeline and what is",
    "start": "1881820",
    "end": "1888299"
  },
  {
    "text": "interesting is that go CDE has this value stream map view where you can",
    "start": "1888299",
    "end": "1896309"
  },
  {
    "text": "actually see the dependencies between the different pipelines so you see here that both pipelines the machine learning",
    "start": "1896309",
    "end": "1903720"
  },
  {
    "text": "pipeline and the application or web application file independent source code",
    "start": "1903720",
    "end": "1909899"
  },
  {
    "text": "engaged but the web application pipeline",
    "start": "1909899",
    "end": "1915570"
  },
  {
    "text": "in addition depends on the output of the machine learning Python which is the prediction model here",
    "start": "1915570",
    "end": "1922490"
  },
  {
    "text": "so this is kind of the very basic setup for this and then here we actually see",
    "start": "1923360",
    "end": "1931790"
  },
  {
    "text": "the very simple application that we're deploying to production with this so in",
    "start": "1931790",
    "end": "1938450"
  },
  {
    "text": "this example application we're implementing sales forecast so basically this came out of a work that we did for",
    "start": "1938450",
    "end": "1946930"
  },
  {
    "text": "Ecuadorian supermarket chain and then we kind of simplified example drastically",
    "start": "1946930",
    "end": "1953210"
  },
  {
    "text": "so this is kind of to pick a date and then kind of ask how many items of milk",
    "start": "1953210",
    "end": "1961430"
  },
  {
    "text": "will be sold on that particular day 30",
    "start": "1961430",
    "end": "1966590"
  },
  {
    "text": "clearly so there's the application here",
    "start": "1966590",
    "end": "1972380"
  },
  {
    "text": "that we will redeploy to production and",
    "start": "1972380",
    "end": "1978490"
  },
  {
    "text": "now those those happens here they are both connected to my to my personal Fork",
    "start": "1978490",
    "end": "1989210"
  },
  {
    "text": "of the repository of the workshops repository actually so you can see that",
    "start": "1989210",
    "end": "1997460"
  },
  {
    "start": "1993000",
    "end": "2153000"
  },
  {
    "text": "here so that is actually a fork of a public repository you can actually have a look at it",
    "start": "1997460",
    "end": "2002470"
  },
  {
    "text": "it's called continuous intelligence workshop and it contains very detailed",
    "start": "2002470",
    "end": "2009850"
  },
  {
    "text": "and easy-to-follow instructions also to go through something like this and what",
    "start": "2009850",
    "end": "2017920"
  },
  {
    "text": "I'm now going to do is actually to go into the source code here and make a",
    "start": "2017920",
    "end": "2024940"
  },
  {
    "text": "little change in the data science code or in the model training called",
    "start": "2024940",
    "end": "2032399"
  },
  {
    "text": "and actually my goal here is to intentionally make the the pipeline ran so basically what I'm doing here is I'm",
    "start": "2038270",
    "end": "2045590"
  },
  {
    "text": "trying out a different algorithm basically so I switch from random forest",
    "start": "2045590",
    "end": "2053960"
  },
  {
    "text": "to a basic decision tree algorithm and",
    "start": "2053960",
    "end": "2059050"
  },
  {
    "text": "then I push that directly to the repository here so now what we should",
    "start": "2063730",
    "end": "2072260"
  },
  {
    "text": "see here is that within the next 30 seconds yeah we see both pipelines are",
    "start": "2072260",
    "end": "2083148"
  },
  {
    "text": "triggered the reason for this that both are triggered is that kind of we saw",
    "start": "2083149",
    "end": "2089450"
  },
  {
    "text": "before that both apartments depend on the source code and in this case we",
    "start": "2089450",
    "end": "2095030"
  },
  {
    "text": "didn't bother to separate it by subfolders so technically you could also say those files belong to the setup of",
    "start": "2095030",
    "end": "2102440"
  },
  {
    "text": "the machine learning code and those subfolders belong to the web application",
    "start": "2102440",
    "end": "2109730"
  },
  {
    "text": "code so then we would kind of avoid unnecessary triggering of the application pipeline right now and only",
    "start": "2109730",
    "end": "2116630"
  },
  {
    "text": "that one would run and so now this one is running here and we can follow that a",
    "start": "2116630",
    "end": "2125300"
  },
  {
    "text": "little bit we see ok and now we see kind",
    "start": "2125300",
    "end": "2130940"
  },
  {
    "text": "of this typical data science of machine learning training workflow happening",
    "start": "2130940",
    "end": "2137060"
  },
  {
    "text": "where first training data is split into training and validation data and then it",
    "start": "2137060",
    "end": "2144410"
  },
  {
    "text": "gets trained and evaluated and while this is happening can actually look a",
    "start": "2144410",
    "end": "2152960"
  },
  {
    "text": "little bit in how this works so when we",
    "start": "2152960",
    "end": "2161240"
  },
  {
    "start": "2153000",
    "end": "2248000"
  },
  {
    "text": "go here into the details of this this stage takes a",
    "start": "2161240",
    "end": "2170580"
  },
  {
    "text": "while so here we have a kind of a job that is called train has been published train evaluate it publish and here we",
    "start": "2170580",
    "end": "2179310"
  },
  {
    "text": "actually use this little tool on DBC that I talked about before and I",
    "start": "2179310",
    "end": "2185190"
  },
  {
    "text": "mentioned before that TVC is bridging this gap between the different workflows",
    "start": "2185190",
    "end": "2190500"
  },
  {
    "text": "so BBC is very simple but what DBC you can basically record data science",
    "start": "2190500",
    "end": "2198810"
  },
  {
    "text": "workflows and the different dependencies and then you can use the command TVC",
    "start": "2198810",
    "end": "2203880"
  },
  {
    "text": "retro which means reproduce and then reproduce the model and it will actually",
    "start": "2203880",
    "end": "2209010"
  },
  {
    "text": "check which dependencies of building the model have changed and will kind of",
    "start": "2209010",
    "end": "2214110"
  },
  {
    "text": "rerun the process back as much as necessary and this is the only thing that we run on here so we basically",
    "start": "2214110",
    "end": "2220410"
  },
  {
    "text": "really just run this little command-line tool here to reproduce the model and it",
    "start": "2220410",
    "end": "2227130"
  },
  {
    "text": "automatically detected that one of the relevant source code files changed so it",
    "start": "2227130",
    "end": "2232350"
  },
  {
    "text": "needs to read rerun this and then we just do a very simple test to check for",
    "start": "2232350",
    "end": "2238260"
  },
  {
    "text": "the accuracy and so let's see",
    "start": "2238260",
    "end": "2245630"
  },
  {
    "text": "by now it actually got red and a red pipeline is actually a very good thing",
    "start": "2247970",
    "end": "2254340"
  },
  {
    "start": "2248000",
    "end": "2296000"
  },
  {
    "text": "because it usually means that it prevented something bad to go live so",
    "start": "2254340",
    "end": "2261000"
  },
  {
    "text": "that's what you want so when we go in here we just see that basically the test",
    "start": "2261000",
    "end": "2268860"
  },
  {
    "text": "that failed is that we want to have at",
    "start": "2268860",
    "end": "2275010"
  },
  {
    "text": "least and kind of eighty percent error rate and it was less than 80 percent",
    "start": "2275010",
    "end": "2282450"
  },
  {
    "text": "error rate and was higher than that and therefore it was actually prevented from",
    "start": "2282450",
    "end": "2288260"
  },
  {
    "text": "from going to production and what we then see here is that because this",
    "start": "2288260",
    "end": "2295350"
  },
  {
    "text": "failed that this year was not retriggered and now can very quickly",
    "start": "2295350",
    "end": "2301470"
  },
  {
    "text": "make make another change here so I can just change this quickly back to random",
    "start": "2301470",
    "end": "2319740"
  },
  {
    "text": "forest there we go and now we will actually see",
    "start": "2319740",
    "end": "2329319"
  },
  {
    "text": "that this pipeline will is going to be retriggered will be green and then we",
    "start": "2329319",
    "end": "2335950"
  },
  {
    "text": "mean first we will see both we trigger because the reason I mentioned before but then after this becomes green this",
    "start": "2335950",
    "end": "2343089"
  },
  {
    "text": "will become yellow to be because it's retriggered by the redeployment or",
    "start": "2343089",
    "end": "2348190"
  },
  {
    "text": "retraining of the model and yeah so we see",
    "start": "2348190",
    "end": "2354460"
  },
  {
    "start": "2353000",
    "end": "2433000"
  },
  {
    "text": "currently both of those being retriggered and then afterwards we see",
    "start": "2354460",
    "end": "2360880"
  },
  {
    "text": "we'll see only one of them so this gives us some time to also look into this one",
    "start": "2360880",
    "end": "2366119"
  },
  {
    "text": "so here we see that in the build stage",
    "start": "2366119",
    "end": "2377609"
  },
  {
    "text": "that here we use TBC as well so it's a bit hidden here on the side so we say DBC pull and this will actually",
    "start": "2380369",
    "end": "2388059"
  },
  {
    "text": "pull in the newest prediction model from some cloud storage so DBC is also used",
    "start": "2388059",
    "end": "2394960"
  },
  {
    "text": "to link between get and cloud storage in the Google cloud so it basically just",
    "start": "2394960",
    "end": "2401319"
  },
  {
    "text": "maintain or yeah manages files that link",
    "start": "2401319",
    "end": "2406990"
  },
  {
    "text": "to external storage similarly to how it is doing just that it integrates it a",
    "start": "2406990",
    "end": "2414400"
  },
  {
    "text": "bit more nice in this data science workflow so this is exactly what is pulling this in here and we we see a",
    "start": "2414400",
    "end": "2422589"
  },
  {
    "text": "similar command PVC push being applied in the machine learning pipeline and so",
    "start": "2422589",
    "end": "2429700"
  },
  {
    "text": "let's have a look you know this actually takes a few more seconds because",
    "start": "2429700",
    "end": "2435609"
  },
  {
    "text": "actually the random forests training takes a bit longer so we can have a look",
    "start": "2435609",
    "end": "2441609"
  },
  {
    "text": "here again we see here this EBC push",
    "start": "2441609",
    "end": "2449290"
  },
  {
    "text": "happening so basically it represent ESTs the performance of the model and only",
    "start": "2449290",
    "end": "2456170"
  },
  {
    "text": "performance is good it will push the model to an external storage from where",
    "start": "2456170",
    "end": "2461450"
  },
  {
    "text": "it is pulled into the web application",
    "start": "2461450",
    "end": "2465970"
  },
  {
    "start": "2473000",
    "end": "2491000"
  },
  {
    "text": "okay it's still not finished but I guess usually me that this is going to become",
    "start": "2474560",
    "end": "2481340"
  },
  {
    "text": "green in a couple of seconds and then it's going to reach rigor that one here to pull in the latest prediction model",
    "start": "2481340",
    "end": "2488120"
  },
  {
    "text": "and redeploy the application so quickly switching back to the slacks to kind of",
    "start": "2488120",
    "end": "2495170"
  },
  {
    "start": "2491000",
    "end": "2663000"
  },
  {
    "text": "wrap this up and I want to wrap this up by talking a",
    "start": "2495170",
    "end": "2505820"
  },
  {
    "text": "little bit about that applying continuous delivery to machine learning is a nice or very interesting and",
    "start": "2505820",
    "end": "2513440"
  },
  {
    "text": "challenging challenging task and I find it very fascinating to solve those",
    "start": "2513440",
    "end": "2519230"
  },
  {
    "text": "puzzles and come up with the right technology to solve this but overall it actually needs to fit into what we call",
    "start": "2519230",
    "end": "2525980"
  },
  {
    "text": "the continuous intelligent cycle and this to a spontaneous intelligence is a capability of a business and that's kind",
    "start": "2525980",
    "end": "2532970"
  },
  {
    "text": "of the larger narrative into which this needs to fit and we must never forget",
    "start": "2532970",
    "end": "2538790"
  },
  {
    "text": "that it's actually about creating value and not about solving technical puzzles so this continuous intelligence cycle is",
    "start": "2538790",
    "end": "2546940"
  },
  {
    "text": "a cycle where we first acquire data and",
    "start": "2546940",
    "end": "2552800"
  },
  {
    "text": "so there needs to be the right infrastructure for that but then actually the data in itself has not much",
    "start": "2552800",
    "end": "2559820"
  },
  {
    "text": "value so we need to get information out of this data so we need to curate it",
    "start": "2559820",
    "end": "2566000"
  },
  {
    "text": "need to clean it and to feature eyes it but even the information itself has not much value to it because we need to get",
    "start": "2566000",
    "end": "2572240"
  },
  {
    "text": "insights from this information so understanding it needs to be generated out of this and this is for instance",
    "start": "2572240",
    "end": "2579140"
  },
  {
    "text": "what what the model represents then this",
    "start": "2579140",
    "end": "2584450"
  },
  {
    "text": "needs to production eyes in order to drive decisions so also the insights are",
    "start": "2584450",
    "end": "2590810"
  },
  {
    "text": "not of much value if they do not drive decisions and those decisions they can be manually they can kind of the model",
    "start": "2590810",
    "end": "2599420"
  },
  {
    "text": "can inform someone who is doing some decisions as a person or they can",
    "start": "2599420",
    "end": "2605990"
  },
  {
    "text": "actually automatic decisions when we really bring AI applications and talent to production",
    "start": "2605990",
    "end": "2612359"
  },
  {
    "text": "into the hands of users and then important this decision needs to drive",
    "start": "2612359",
    "end": "2619990"
  },
  {
    "text": "an action in the real world again so basically for instance someone selling",
    "start": "2619990",
    "end": "2625119"
  },
  {
    "text": "their car and only then we really create value when this whole loop closes and",
    "start": "2625119",
    "end": "2631049"
  },
  {
    "text": "this action the end changes the real world and because the data that we",
    "start": "2631049",
    "end": "2636579"
  },
  {
    "text": "acquire in the first stage is only a sampling of the real world the loop closes here and this is really what we",
    "start": "2636579",
    "end": "2644500"
  },
  {
    "text": "want to achieve and basically our goal and we feel that applying continuous delivery is only one piece to get to",
    "start": "2644500",
    "end": "2652599"
  },
  {
    "text": "that goal easy to accelerate this cycle of the cycle of continuous intelligence and making it ever quicker and yeah close",
    "start": "2652599",
    "end": "2660549"
  },
  {
    "text": "that loop here well that thanks a lot and I'm happy to",
    "start": "2660549",
    "end": "2665740"
  },
  {
    "start": "2663000",
    "end": "2701000"
  },
  {
    "text": "take a couple of questions yeah I still have a couple of minutes any questions",
    "start": "2665740",
    "end": "2673750"
  },
  {
    "text": "yeah",
    "start": "2673750",
    "end": "2676230"
  },
  {
    "start": "2701000",
    "end": "2803000"
  },
  {
    "text": "yeah so just to repeat the question it's about how to how to yeah package a model",
    "start": "2701210",
    "end": "2706609"
  },
  {
    "text": "for production and I'm afraid there is not one solution really that we that we",
    "start": "2706609",
    "end": "2713180"
  },
  {
    "text": "figure out yet it's we are depends quite a lot on the on the case so I have seen models being",
    "start": "2713180",
    "end": "2724990"
  },
  {
    "text": "transformed more exported in some kind of intermediate format like PMML",
    "start": "2724990",
    "end": "2732170"
  },
  {
    "text": "markup language so that the model can and we serve in a generic serving layer",
    "start": "2732170",
    "end": "2738670"
  },
  {
    "text": "what I have to admit what I see these days much more often is that we actually",
    "start": "2738670",
    "end": "2744050"
  },
  {
    "text": "packaged as the model as a service so to say so that basically yeah we create a",
    "start": "2744050",
    "end": "2753260"
  },
  {
    "text": "very simple prediction service a layer",
    "start": "2753260",
    "end": "2758450"
  },
  {
    "text": "around the model and then employed this as a container entirely and then put it into a container registry and just from",
    "start": "2758450",
    "end": "2765530"
  },
  {
    "text": "there this is what we pull it yeah there are a lot of other things for this",
    "start": "2765530",
    "end": "2771440"
  },
  {
    "text": "project that I mentioned initially we used h2o and then exported it to to Java",
    "start": "2771440",
    "end": "2778970"
  },
  {
    "text": "files and pulled in the Java file then so yeah I think I've seen many different",
    "start": "2778970",
    "end": "2785390"
  },
  {
    "text": "ones and I feel that currently we're leaning towards wrapping this into a",
    "start": "2785390",
    "end": "2790720"
  },
  {
    "text": "into a service with a very thin layer of a web service and serving the",
    "start": "2790720",
    "end": "2796069"
  },
  {
    "text": "predictions",
    "start": "2796069",
    "end": "2798520"
  },
  {
    "start": "2803000",
    "end": "2908000"
  },
  {
    "text": "so in a certain way yes so this was what",
    "start": "2804320",
    "end": "2810770"
  },
  {
    "text": "I was talking about before we favor to bringing data scientists and software",
    "start": "2810770",
    "end": "2817760"
  },
  {
    "text": "developers much closer to each other and that means that we also tried to make them pair and do pair programming it",
    "start": "2817760",
    "end": "2825109"
  },
  {
    "text": "doesn't it's not always the right thing to do but that also means that I'd",
    "start": "2825109",
    "end": "2830930"
  },
  {
    "text": "really a data scientist and a software engineer sit together and then created a simple layer for instance and we find",
    "start": "2830930",
    "end": "2838609"
  },
  {
    "text": "that very fruitful because then also the developer learns a bit about how the",
    "start": "2838609",
    "end": "2845480"
  },
  {
    "text": "model is working and so there are less silos and less bottlenecks if someone is",
    "start": "2845480",
    "end": "2852349"
  },
  {
    "text": "not there and I mean generally also we see that it often the data scientists",
    "start": "2852349",
    "end": "2858470"
  },
  {
    "text": "are even scarcer resourced and developers so that means that often the",
    "start": "2858470",
    "end": "2863810"
  },
  {
    "text": "data scientist comes in into a team for a while to develop or help developing",
    "start": "2863810",
    "end": "2869540"
  },
  {
    "text": "the application for the initial version and then ideally as much general",
    "start": "2869540",
    "end": "2874580"
  },
  {
    "text": "knowledge about how this is working is transferred to the developers so this is how we integrate usually them and to",
    "start": "2874580",
    "end": "2882290"
  },
  {
    "text": "your question whether we upskill the data scientists we feel that naturally this way also then it some knowledge",
    "start": "2882290",
    "end": "2887900"
  },
  {
    "text": "gets over to the data scientists how to deploy applications and this is Anja then creates more empathy of how to",
    "start": "2887900",
    "end": "2895040"
  },
  {
    "text": "build a system that actually needs to be life and create understanding what wants",
    "start": "2895040",
    "end": "2900470"
  },
  {
    "text": "to be done to do those things so one in",
    "start": "2900470",
    "end": "2906320"
  },
  {
    "text": "the front and one or two in the back thanks to the president so I understand",
    "start": "2906320",
    "end": "2912710"
  },
  {
    "start": "2908000",
    "end": "3026000"
  },
  {
    "text": "that that was out of the scope of your presentation what you touched on one of the challenges that you had and that was",
    "start": "2912710",
    "end": "2918380"
  },
  {
    "text": "versioning of the data of the training data would you be able to comment a bit more on how you version of the data for",
    "start": "2918380",
    "end": "2924859"
  },
  {
    "text": "example if you have a data field change and that means there is a change in the training data how would you manage that",
    "start": "2924859",
    "end": "2930619"
  },
  {
    "text": "would you create a copy of the whole data and store it as a blob or how yeah pretty much so to come up with a",
    "start": "2930619",
    "end": "2939790"
  },
  {
    "text": "good kind of smart solution for data versioning is a very tricky topic and",
    "start": "2939790",
    "end": "2946800"
  },
  {
    "text": "colleague of mine and American chance key has written a whole blog post about data versioning what we do in this case",
    "start": "2946800",
    "end": "2954910"
  },
  {
    "text": "also that we showed that I show to you here with DBC is a very simple version",
    "start": "2954910",
    "end": "2961750"
  },
  {
    "text": "where basically we do not version yeah really version control the data itself but only",
    "start": "2961750",
    "end": "2968670"
  },
  {
    "text": "manage have pointer to the data set and then just a pointer changes and we need",
    "start": "2968670",
    "end": "2974800"
  },
  {
    "text": "to share and we need to point to a new version of the data set and this is what",
    "start": "2974800",
    "end": "2980200"
  },
  {
    "text": "is recognized by the system it's a very simple way to approach this or some",
    "start": "2980200",
    "end": "2985270"
  },
  {
    "text": "basic way so it cannot really understand or automatically detect changes like",
    "start": "2985270",
    "end": "2991750"
  },
  {
    "text": "data fields which means also everyone working on the project including a data",
    "start": "2991750",
    "end": "2996910"
  },
  {
    "text": "scientist they need to understand how this is working which means they need to understand that they need to create a",
    "start": "2996910",
    "end": "3003510"
  },
  {
    "text": "new data set or at least a new bucket or whatever when there is new data so that",
    "start": "3003510",
    "end": "3011250"
  },
  {
    "text": "the system can can recognize this but this is yeah it's a to come up with a smart solution is still still out I",
    "start": "3011250",
    "end": "3020180"
  },
  {
    "text": "think there were at least one back there and one more in the front",
    "start": "3020180",
    "end": "3026990"
  },
  {
    "start": "3026000",
    "end": "3055000"
  },
  {
    "text": "I notice in the diagram that you have a stage where after the model building",
    "start": "3027410",
    "end": "3033300"
  },
  {
    "text": "process you have evaluation stage as well so at the moment me as a people I",
    "start": "3033300",
    "end": "3041460"
  },
  {
    "text": "was told to validate the model just manually but I very knowledgeable so how",
    "start": "3041460",
    "end": "3051690"
  },
  {
    "text": "do you automate that process that is",
    "start": "3051690",
    "end": "3057270"
  },
  {
    "start": "3055000",
    "end": "3101000"
  },
  {
    "text": "really mostly about automatic validation in terms of checking whether certain",
    "start": "3057270",
    "end": "3063780"
  },
  {
    "text": "accuracy thresholds on I think that's the typical thing that you will do there you this is actually",
    "start": "3063780",
    "end": "3071430"
  },
  {
    "text": "usually just the normal work of data scientist it is really what data",
    "start": "3071430",
    "end": "3076740"
  },
  {
    "text": "scientists always do they have an evaluation stage that they implement that creates us or usually so creating",
    "start": "3076740",
    "end": "3085050"
  },
  {
    "text": "that then the test stage there is often just to check for the score",
    "start": "3085050",
    "end": "3090690"
  },
  {
    "text": "as always with fixed threshold this can be tricky because you need to adapt them but that's that's really what it's about",
    "start": "3090690",
    "end": "3097050"
  },
  {
    "text": "so there's not not that complex go ahead sorry doing drop I'm just to",
    "start": "3097050",
    "end": "3104430"
  },
  {
    "start": "3101000",
    "end": "3160000"
  },
  {
    "text": "clarify on that question I'm super new so you would have a final data set of",
    "start": "3104430",
    "end": "3110850"
  },
  {
    "text": "like say use the cats and dogs images the typical example you'd have a list of",
    "start": "3110850",
    "end": "3117630"
  },
  {
    "text": "cat images and dog images and then you would have expected output and you would run that through your end model and if",
    "start": "3117630",
    "end": "3126180"
  },
  {
    "text": "you got a certain number of like yes that's a dog then it has passed yes so",
    "start": "3126180",
    "end": "3131970"
  },
  {
    "text": "it's I mean we're talking about supervised learning here supervised learning means we know what the right",
    "start": "3131970",
    "end": "3138120"
  },
  {
    "text": "answer is and therefore we can just create an error score and say 70% of the",
    "start": "3138120",
    "end": "3144600"
  },
  {
    "text": "answers were what we expected and now we can just define what is good enough I",
    "start": "3144600",
    "end": "3150350"
  },
  {
    "text": "think there was definitely one question here in the front I don't know whether that's still open the comments before",
    "start": "3150350",
    "end": "3162090"
  },
  {
    "start": "3160000",
    "end": "3301000"
  },
  {
    "text": "about getting the teams though the developer in the data scientist to work together we currently have a team that",
    "start": "3162090",
    "end": "3168720"
  },
  {
    "text": "worked together but they're very reluctant to seek with each other and work together do you have any content or",
    "start": "3168720",
    "end": "3175830"
  },
  {
    "text": "blogs that I can point them out and say it actually works",
    "start": "3175830",
    "end": "3182360"
  },
  {
    "text": "yeah so I mean I've written about this so I'm especially also about this this",
    "start": "3182770",
    "end": "3190490"
  },
  {
    "text": "case with autoscout but to be honest it's not easy I think the most important",
    "start": "3190490",
    "end": "3197960"
  },
  {
    "text": "thing is probably to acknowledge that there are different workflows and different ways of working and different",
    "start": "3197960",
    "end": "3204260"
  },
  {
    "text": "skill sets but to really make clear",
    "start": "3204260",
    "end": "3211490"
  },
  {
    "text": "again and again that it's beneficial to work closely together but it will",
    "start": "3211490",
    "end": "3216500"
  },
  {
    "text": "actually slow you down I mean this is as with any kind of different skill set",
    "start": "3216500",
    "end": "3223040"
  },
  {
    "text": "bringing together you'd like operation sky with someone from with a developer",
    "start": "3223040",
    "end": "3228800"
  },
  {
    "text": "or putting together a front end and the back end developer and you will always",
    "start": "3228800",
    "end": "3234349"
  },
  {
    "text": "feel that this is uncomfortable mostly actually for the one who is better at",
    "start": "3234349",
    "end": "3240230"
  },
  {
    "text": "the topic at hand because they are they feel slowed down so I guess it's this is",
    "start": "3240230",
    "end": "3246170"
  },
  {
    "text": "really kind of a bit of a leadership thing to really make clear that this",
    "start": "3246170",
    "end": "3252500"
  },
  {
    "text": "slowdown is okay because it will actually enable the entire team to be more sustainable",
    "start": "3252500",
    "end": "3258050"
  },
  {
    "text": "and yeah be less dependent on the on a single person but yeah I guess if",
    "start": "3258050",
    "end": "3264140"
  },
  {
    "text": "there's a culture of constant pressure for bringing things out then it can feel",
    "start": "3264140",
    "end": "3270859"
  },
  {
    "text": "uncomfortable to be in those pairs that slow you down I guess if if the",
    "start": "3270859",
    "end": "3275900"
  },
  {
    "text": "environment is right I would say that it can be very can be very good to teach",
    "start": "3275900",
    "end": "3282790"
  },
  {
    "text": "certain things to the other partner of a pair that doesn't know that many things",
    "start": "3282790",
    "end": "3288440"
  },
  {
    "text": "about it but yeah the situation need to be right needs to be righted yeah it's",
    "start": "3288440",
    "end": "3294710"
  },
  {
    "text": "but that's definitely not easy but it's similar in all disciplines",
    "start": "3294710",
    "end": "3300010"
  },
  {
    "start": "3301000",
    "end": "3321000"
  },
  {
    "text": "you know you talk about the continuous monitoring so say for the model built",
    "start": "3301539",
    "end": "3307359"
  },
  {
    "text": "after three months five thousand more cars sold so those information can be",
    "start": "3307359",
    "end": "3312999"
  },
  {
    "text": "feedback to the model to retrain a model how do you make these automate so in",
    "start": "3312999",
    "end": "3324069"
  },
  {
    "text": "that particular case I think there are two ways to talk about this the one is",
    "start": "3324069",
    "end": "3330429"
  },
  {
    "text": "just a implicit way so to say it's basically we originally draw the",
    "start": "3330429",
    "end": "3336579"
  },
  {
    "text": "training data from the production data basically and just a couple of months",
    "start": "3336579",
    "end": "3342519"
  },
  {
    "text": "later there will be different production data right so just the new car salt will",
    "start": "3342519",
    "end": "3347679"
  },
  {
    "text": "add to the production data and therefore we pull in different data so it's really just about scheduling retraining another",
    "start": "3347679",
    "end": "3354609"
  },
  {
    "text": "way would be to kind of schedule a retraining when we feel that quality deteriorates all that we see that the",
    "start": "3354609",
    "end": "3361329"
  },
  {
    "text": "users for instance will trust the model less and less but generally what we try",
    "start": "3361329",
    "end": "3368499"
  },
  {
    "text": "to achieve with this is that model can be retrained and brought the production several times a day so that we're really",
    "start": "3368499",
    "end": "3375519"
  },
  {
    "text": "not yeah thinking too much about this and just retrain it very often another",
    "start": "3375519",
    "end": "3381219"
  },
  {
    "text": "way to solve those things is just to kind of build a lambda architecture where you have kind of a batch layer",
    "start": "3381219",
    "end": "3390279"
  },
  {
    "text": "which is about the model being retrained not that often because it takes long and then have a second layer in front of",
    "start": "3390279",
    "end": "3397659"
  },
  {
    "text": "this which adds life information and maybe filters out things so I've seen things like this with recommenders",
    "start": "3397659",
    "end": "3403839"
  },
  {
    "text": "recommender systems where we only retrain the recommender model once per",
    "start": "3403839",
    "end": "3410589"
  },
  {
    "text": "night but for instance filter out the recommendations that the user has already clicked on and this is just a",
    "start": "3410589",
    "end": "3417369"
  },
  {
    "text": "very simple simple layer in between the user facing application and the",
    "start": "3417369",
    "end": "3423609"
  },
  {
    "text": "prediction service which checks whether the kind of retrieves the list the",
    "start": "3423609",
    "end": "3430869"
  },
  {
    "text": "outcome of the prediction model and then just filters out the things that have or even presented to the user all right",
    "start": "3430869",
    "end": "3441950"
  },
  {
    "start": "3438000",
    "end": "3522000"
  },
  {
    "text": "so um this is actually kind of this this deck with fluent tea elasticsearch and",
    "start": "3451460",
    "end": "3457170"
  },
  {
    "text": "Cabana we're just a typical monitoring stack these days I would say so um what",
    "start": "3457170",
    "end": "3463950"
  },
  {
    "text": "we do there is typically money for business events so we try to implement",
    "start": "3463950",
    "end": "3471620"
  },
  {
    "text": "the application so that it emits business events something like car put",
    "start": "3471800",
    "end": "3478260"
  },
  {
    "text": "on the platform or price estimation happened and then always with a certain",
    "start": "3478260",
    "end": "3484290"
  },
  {
    "text": "data attached to it and then this data basically ends up in elasticsearch which",
    "start": "3484290",
    "end": "3491760"
  },
  {
    "text": "may which makes it easy to query and then you can create automatic dashboards and can filter for certain things",
    "start": "3491760",
    "end": "3499200"
  },
  {
    "text": "so this setup is very good to kind of monitor what is happening and maybe see",
    "start": "3499200",
    "end": "3504510"
  },
  {
    "text": "trends or I mean it's actually also very good for debugging but that's a different story so you can basically see",
    "start": "3504510",
    "end": "3510840"
  },
  {
    "text": "a log of what happened great Dannan thank you very much and of course I will",
    "start": "3510840",
    "end": "3518640"
  },
  {
    "text": "be staying here [Applause]",
    "start": "3518640",
    "end": "3523810"
  }
]
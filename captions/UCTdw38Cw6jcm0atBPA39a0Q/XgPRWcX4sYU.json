[
  {
    "text": "all right welcome to this presentation on reinforcement learning now this was originally a three to four",
    "start": "1439",
    "end": "8000"
  },
  {
    "text": "hour long workshop which we created as a part of the artificial intelligence initiative",
    "start": "8000",
    "end": "13759"
  },
  {
    "text": "at our company know it we would present some theory about a couple of reinforcement learning",
    "start": "13759",
    "end": "18880"
  },
  {
    "text": "methods before the participants would play around to train an agent to play the classic game",
    "start": "18880",
    "end": "25359"
  },
  {
    "text": "of pac-man now obviously today the setup is going to be a little bit different it's a presentation format",
    "start": "25359",
    "end": "33200"
  },
  {
    "text": "so you guys can just sit back as we do most of the talking and show you some fun stuff",
    "start": "33200",
    "end": "38239"
  },
  {
    "text": "and hopefully you can take away something useful so as i said we're going to show you the",
    "start": "38239",
    "end": "45280"
  },
  {
    "text": "process of training an agent to play the game of pacman using two different uh methods so let's take a look at the",
    "start": "45280",
    "end": "52879"
  },
  {
    "text": "agenda of the day we'll start out with a brief introduction to reinforcement learning",
    "start": "52879",
    "end": "58960"
  },
  {
    "text": "explaining terminology and concepts with a few different examples so even if you have",
    "start": "58960",
    "end": "64799"
  },
  {
    "text": "no experience with this uh from before you will be able to understand what's going on",
    "start": "64799",
    "end": "72159"
  },
  {
    "text": "the first model that we will be using is called q learning and we'll explain",
    "start": "72159",
    "end": "78240"
  },
  {
    "text": "what this means before showing you some code and watching the agent in action",
    "start": "78240",
    "end": "84479"
  },
  {
    "text": "the second model will be a deep q learning model and this means q learning with neural networks but",
    "start": "84479",
    "end": "91200"
  },
  {
    "text": "before we get to all of that let us tell you a little bit about ourselves yes",
    "start": "91200",
    "end": "96880"
  },
  {
    "text": "my name is malta i'm currently currently working at knowit which is a nordic",
    "start": "96880",
    "end": "101920"
  },
  {
    "text": "consultancy firm and i've been working there for the last three years i started working there",
    "start": "101920",
    "end": "107280"
  },
  {
    "text": "directly after writing my master's thesis at the norwegian university of science",
    "start": "107280",
    "end": "112880"
  },
  {
    "text": "and technology where i took my master's focusing on artificial intelligence",
    "start": "112880",
    "end": "118560"
  },
  {
    "text": "right now i'm on project at v the norwegian railroad company where my team sets the prices for the tickets",
    "start": "118560",
    "end": "125119"
  },
  {
    "text": "and where we use machine learning for various tasks",
    "start": "125119",
    "end": "130160"
  },
  {
    "text": "my name is manu i'm from oslo and me and malta we've been following the same path for quite a",
    "start": "130399",
    "end": "136400"
  },
  {
    "text": "while now i also work for knowit been working here for the past two and a half years",
    "start": "136400",
    "end": "142400"
  },
  {
    "text": "and currently i'm outsourced to antuite a government-owned transportation",
    "start": "142400",
    "end": "147760"
  },
  {
    "text": "company in norway and their mission is to collect all the sales and ticketing solutions for public",
    "start": "147760",
    "end": "153040"
  },
  {
    "text": "transportation in norway to one single application making it possible to travel anywhere in",
    "start": "153040",
    "end": "158720"
  },
  {
    "text": "norway using this app so that's pretty cool and before that i was also studying at the norwegian university of",
    "start": "158720",
    "end": "165280"
  },
  {
    "text": "technology working on my master's thesis within machine learning doing natural language processing on",
    "start": "165280",
    "end": "172160"
  },
  {
    "text": "tweets to predict the gender of authors and we also we also both did one year",
    "start": "172160",
    "end": "179760"
  },
  {
    "text": "at the university of california in santa barbara all right let's get to it sir thank you",
    "start": "179760",
    "end": "189360"
  },
  {
    "text": "just disappearing out of the screen right there um all right so before we can kind of properly",
    "start": "190080",
    "end": "196159"
  },
  {
    "text": "explain what reinforcement learning is we're going to have to take a little look at machine learning and artificial",
    "start": "196159",
    "end": "202159"
  },
  {
    "text": "intelligence so artificial intelligence is kind of a broad term that just really means to get",
    "start": "202159",
    "end": "208239"
  },
  {
    "text": "the machine to do something intelligent that's also the goal with machine learning but machine learning has two",
    "start": "208239",
    "end": "213440"
  },
  {
    "text": "additional properties the first one is that it uses data to train it models and the second one",
    "start": "213440",
    "end": "218959"
  },
  {
    "text": "is that no machine learning algorithm is explicitly programmed to solve one single problem for instance",
    "start": "218959",
    "end": "226159"
  },
  {
    "text": "what a neural network learns solely based on the data that's fed to it and therefore it can kind of solve",
    "start": "226159",
    "end": "232239"
  },
  {
    "text": "any problem based on the data you can therefore think of machine learning as a subfield of",
    "start": "232239",
    "end": "238720"
  },
  {
    "text": "artificial intelligence which focuses on learning from data today machine learning is everywhere",
    "start": "238720",
    "end": "245519"
  },
  {
    "text": "it's used in speech recognition and image recognition and sentiment analysis video surveillance",
    "start": "245519",
    "end": "251920"
  },
  {
    "text": "spam filtering fraud detection recommendation systems and so on and so",
    "start": "251920",
    "end": "257120"
  },
  {
    "text": "on now reinforcement learning within",
    "start": "257120",
    "end": "263040"
  },
  {
    "text": "machine learning there's kind of four subfields there's unsupervised semi-supervised unsupervised and what we're going to",
    "start": "263040",
    "end": "270639"
  },
  {
    "text": "talk about today reinforcement learning something that make reinforcement learning stand out compared to the other",
    "start": "270639",
    "end": "276000"
  },
  {
    "text": "approaches is that reinforcement learning creates the data on the fly where the other ones",
    "start": "276000",
    "end": "283120"
  },
  {
    "text": "they use pre-created data sets reinforcement learning is used a lot in games for instance in",
    "start": "283120",
    "end": "291520"
  },
  {
    "text": "atari shogi go chess dota starcraft and so on",
    "start": "291520",
    "end": "296800"
  },
  {
    "text": "but these uh these games are just meant as a stepping stone before going out into the real world",
    "start": "296800",
    "end": "303840"
  },
  {
    "text": "and today reinforcement learning is used in fields such as medicine",
    "start": "303840",
    "end": "309680"
  },
  {
    "text": "finance recommendation systems and so on yeah",
    "start": "309680",
    "end": "317439"
  },
  {
    "text": "then we have to have to introduce some terminology here five terms so that we everyone knows that we speak",
    "start": "317840",
    "end": "323039"
  },
  {
    "text": "the same same language the first term is an agent so an agent",
    "start": "323039",
    "end": "329440"
  },
  {
    "text": "is a unit that performs actions for instance it could be a drone making a delivery or it could be pac-man",
    "start": "329440",
    "end": "335039"
  },
  {
    "text": "running around on the board the second term is an action and an action is a little bit",
    "start": "335039",
    "end": "341320"
  },
  {
    "text": "self-explanatory but it should be noted that the agent has a set of actions that it",
    "start": "341320",
    "end": "348400"
  },
  {
    "text": "chooses from for instance in pac-man it can either move to the left up right and down",
    "start": "348400",
    "end": "356240"
  },
  {
    "text": "the third term is the environment and that's the world where the agent moves so the environment takes the agent's",
    "start": "357280",
    "end": "363759"
  },
  {
    "text": "current state and an action as input and then it",
    "start": "363759",
    "end": "368800"
  },
  {
    "text": "as an output it returns the agent's reward and the next state for instance in",
    "start": "368800",
    "end": "375039"
  },
  {
    "text": "pac-man the environment is just all kind of possible maps that the pac-man can",
    "start": "375039",
    "end": "380960"
  },
  {
    "text": "can run in the fourth fourth term is the state a state is the concrete",
    "start": "380960",
    "end": "387600"
  },
  {
    "text": "and immediate situation where the agent finds itself in and it puts the agent in relations to",
    "start": "387600",
    "end": "393199"
  },
  {
    "text": "enemies and rewards and so on often it's a function of time so you can think about it as stopping",
    "start": "393199",
    "end": "399759"
  },
  {
    "text": "time and then you'll be in a given state and finally we have the reward that i",
    "start": "399759",
    "end": "404960"
  },
  {
    "text": "briefly mentioned rewarded the feedback by which we measure the success or failure of an",
    "start": "404960",
    "end": "410319"
  },
  {
    "text": "agent for example when pac-man grabs a coin should probably give a good reward and",
    "start": "410319",
    "end": "417840"
  },
  {
    "text": "when pac-man gets caught by the ghost it should yield a negative reward",
    "start": "417840",
    "end": "423759"
  },
  {
    "text": "so you can it looks reinforcement learning looks a little bit like this if we start on the left here you can see",
    "start": "423759",
    "end": "430080"
  },
  {
    "text": "there's a state an award this is fed into an agent based on this state",
    "start": "430080",
    "end": "435520"
  },
  {
    "text": "the agent chooses an action in the environment and then the environment gives back the",
    "start": "435520",
    "end": "441440"
  },
  {
    "text": "next state and the reward for that action that the agent performed this then goes in a loop until you reach",
    "start": "441440",
    "end": "448240"
  },
  {
    "text": "a terminal state which for instance in pac-man you either win the game or you pick up all the",
    "start": "448240",
    "end": "454080"
  },
  {
    "text": "coins then you win the game or you get caught by the ghost and then you die and",
    "start": "454080",
    "end": "460960"
  },
  {
    "text": "and the state ends so this is the first screenshot you guys",
    "start": "461039",
    "end": "468160"
  },
  {
    "text": "see of the game that's made so our colleague made an implementation",
    "start": "468160",
    "end": "473759"
  },
  {
    "text": "of pac-man that we're using so it looks like this you can see the pac-man in the",
    "start": "473759",
    "end": "480160"
  },
  {
    "text": "uh bottom middle here the guy with the with the stake and then you have the",
    "start": "480160",
    "end": "485199"
  },
  {
    "text": "ghost in the top right you have all these bricks surrounding it that's where the pac-man",
    "start": "485199",
    "end": "491360"
  },
  {
    "text": "or the ghost can't go and then there are these gold coins that pacman has to pick up to to win the",
    "start": "491360",
    "end": "498720"
  },
  {
    "text": "game",
    "start": "498720",
    "end": "500960"
  },
  {
    "text": "so this is a concrete state that the pac-man is in right now we have stop time and this is the state that is",
    "start": "504560",
    "end": "511840"
  },
  {
    "text": "currently that is currently uh realistic so when the to get to the next state",
    "start": "511840",
    "end": "519360"
  },
  {
    "text": "pac-man has to choose an action into the environment so we're going to choose an action",
    "start": "519360",
    "end": "525040"
  },
  {
    "text": "and then we can get to the next state now so let's say you choose an action and you go to the next state and it",
    "start": "525040",
    "end": "530160"
  },
  {
    "text": "looks like this so we can see that the pac-man didn't really move",
    "start": "530160",
    "end": "535920"
  },
  {
    "text": "um so it probably chose to go either up or down you can see it again here i",
    "start": "535920",
    "end": "541680"
  },
  {
    "text": "went back and then the pac-man doesn't move but the ghost moves to the right so pac-man chose to either move up or down",
    "start": "541680",
    "end": "548560"
  },
  {
    "text": "and then he just stays still in its place while the ghost moved to the right the environment also",
    "start": "548560",
    "end": "555279"
  },
  {
    "text": "gives pac-man a reward for this but when pac-man didn't really do anything you know",
    "start": "555279",
    "end": "561120"
  },
  {
    "text": "not much of a reward is going to be given uh yes so a couple of challenges of",
    "start": "561120",
    "end": "567279"
  },
  {
    "text": "reinforcement learning i'm going to talk about three challenges here the first one is the exploration versus exploitation where you have to",
    "start": "567279",
    "end": "573920"
  },
  {
    "text": "escape the local optima it's very important that the agent can search the whole state state space",
    "start": "573920",
    "end": "582080"
  },
  {
    "text": "and not that means that it can't take the optimal action at all times i'll talk about that very soon secondly",
    "start": "582080",
    "end": "589200"
  },
  {
    "text": "there's the credit assignment problem and it has to do with when an agent is winning the game which actions are",
    "start": "589200",
    "end": "595360"
  },
  {
    "text": "actually responsible for winning the game right you can you can play a game and there's a hundred thousand time steps",
    "start": "595360",
    "end": "602399"
  },
  {
    "text": "but which action actually led to winning the game it's usually not just the very last one",
    "start": "602399",
    "end": "608959"
  },
  {
    "text": "and thirdly there is simulated environments because when you want to put something",
    "start": "608959",
    "end": "614320"
  },
  {
    "text": "out in the real world you have to kind of simulate it first in in the digital world which i'll",
    "start": "614320",
    "end": "620000"
  },
  {
    "text": "also briefly go into yes so the exploration versus",
    "start": "620000",
    "end": "625920"
  },
  {
    "text": "exploitation for this challenge i'm going to use my puppy as an example i got a puppy",
    "start": "625920",
    "end": "632000"
  },
  {
    "text": "last summer that's also cost and cold summer um and we can think of that puppy as",
    "start": "632000",
    "end": "638720"
  },
  {
    "text": "an agent trying to like maximize his rewards right he just want to have as much fun as possible",
    "start": "638720",
    "end": "645040"
  },
  {
    "text": "so what you need to know before i go through this example is that i live on the third floor",
    "start": "645040",
    "end": "650240"
  },
  {
    "text": "and when you walk down to the ground floor you have to open a door to get out into the into a",
    "start": "650240",
    "end": "656480"
  },
  {
    "text": "hallway and in then when you open that door you have two choices you can either go to the left which leads out to the backyard or you can go",
    "start": "656480",
    "end": "663440"
  },
  {
    "text": "to the right where it leads to the gate and out on the street so when he was little we usually just",
    "start": "663440",
    "end": "670560"
  },
  {
    "text": "took him into the backyard in the beginning which meant that every time that we opened that door into",
    "start": "670560",
    "end": "676959"
  },
  {
    "text": "the hallway on the ground floor summer would just immediately run to the left right because he knows that the",
    "start": "676959",
    "end": "683440"
  },
  {
    "text": "left is fun he can be there he can you know run around and get dirty you can chew on his sticks you know and you",
    "start": "683440",
    "end": "689760"
  },
  {
    "text": "can and complain you can have fun um and that's uh what puppies do right they all",
    "start": "689760",
    "end": "695440"
  },
  {
    "text": "they always just exploit they know left really fun great let's go there um",
    "start": "695440",
    "end": "702560"
  },
  {
    "text": "and so for him to also know that the the right pathway might also be fun we had to show him",
    "start": "702560",
    "end": "709120"
  },
  {
    "text": "right so when we showed him that going on the street could also be fun he",
    "start": "709120",
    "end": "714160"
  },
  {
    "text": "he enjoyed that as well and today when we take him out you know it's a little bit 50 50 if he runs to the left or",
    "start": "714160",
    "end": "719519"
  },
  {
    "text": "right to the right um and that's the the same thing can be",
    "start": "719519",
    "end": "725040"
  },
  {
    "text": "it's a problem in reinforcement along with agents because if you just walk to the right and you never",
    "start": "725040",
    "end": "730320"
  },
  {
    "text": "or or walk to the left and you never even try to walk to the right you're just going to think that left is the best",
    "start": "730320",
    "end": "735920"
  },
  {
    "text": "um but you haven't even even been to the right you haven't explored that state that's a state space",
    "start": "735920",
    "end": "744720"
  },
  {
    "text": "um so the way one way one the easiest way to solve this is to perform a random action with the",
    "start": "744720",
    "end": "750639"
  },
  {
    "text": "small probability so for instance if if we had an agent that was this puppy he would go to the left",
    "start": "750639",
    "end": "757200"
  },
  {
    "text": "because he would exploit but there would be a small chance that he'll go to the right and then he'll also explore that state space",
    "start": "757200",
    "end": "765600"
  },
  {
    "text": "for the credit assignment problem we're also going to use",
    "start": "766399",
    "end": "771440"
  },
  {
    "text": "my puppy so when you train a puppy it's important that you have",
    "start": "771440",
    "end": "776639"
  },
  {
    "text": "a treat ready to give him when he does something nice so for instance when you tell him to get",
    "start": "776639",
    "end": "782160"
  },
  {
    "text": "down like this picture you have to get the treat pretty quickly",
    "start": "782160",
    "end": "787680"
  },
  {
    "text": "let's say that you didn't have a treat ready and you then you then tell him to go down and",
    "start": "787680",
    "end": "796160"
  },
  {
    "text": "then he barks because you don't have it ready then he barks and then you go get the treat and then you give it to him",
    "start": "796160",
    "end": "801760"
  },
  {
    "text": "now he'll start barking because the reward is delayed he doesn't understand if he got the treat because he got down or because he",
    "start": "801760",
    "end": "809040"
  },
  {
    "text": "barked and he has a problem understanding which action actually is the correct one",
    "start": "809040",
    "end": "814800"
  },
  {
    "text": "and that's the same with agents right as i mentioned in a game with a hundred thousand time steps you know you can do something really well in the beginning",
    "start": "814800",
    "end": "821199"
  },
  {
    "text": "of the game and then you don't really get any reward before like a hundred thousand time steps later right",
    "start": "821199",
    "end": "828320"
  },
  {
    "text": "and while we're on this topic i'm also just gonna touch on reward shaping so there are two kinds of rewards",
    "start": "828320",
    "end": "835040"
  },
  {
    "text": "they're sparse and shaped this the sparse rewards also called a",
    "start": "835040",
    "end": "840320"
  },
  {
    "text": "uniform assignment scheme is simply where you give the agent plus one for winning and minus one for",
    "start": "840320",
    "end": "847040"
  },
  {
    "text": "losing you hope then that the right actions get credited more often on average because",
    "start": "847040",
    "end": "853360"
  },
  {
    "text": "you'll win more games hopefully this approach kind of works on short games like pong and it's the optimal approach if",
    "start": "853360",
    "end": "860160"
  },
  {
    "text": "you can afford the computations patients because it is really hard for the agent to converge",
    "start": "860160",
    "end": "866240"
  },
  {
    "text": "uh actually alphago 0 was entirely trained in this fashion with only plus one and a minus",
    "start": "866240",
    "end": "872480"
  },
  {
    "text": "one reward signal for winning and losing the game the agent becomes very sophisticated and",
    "start": "872480",
    "end": "878399"
  },
  {
    "text": "can find the optimal solution but as i just said it's really hard to converge",
    "start": "878399",
    "end": "884399"
  },
  {
    "text": "one way to address this challenge of long horizon and credit assignments",
    "start": "884399",
    "end": "890399"
  },
  {
    "text": "is to is to do something called reward shaping where you break down all the rewards or",
    "start": "890399",
    "end": "897279"
  },
  {
    "text": "the reward rewards into uh small pieces to encourage the right behaviors at",
    "start": "897279",
    "end": "904560"
  },
  {
    "text": "at each step so for instance in pac-man you can like say that okay",
    "start": "904560",
    "end": "910320"
  },
  {
    "text": "well he get one point for picking up a coin and you get a minus five for getting caught by a ghost right and then we also",
    "start": "910320",
    "end": "916480"
  },
  {
    "text": "have a move penalty of 0.1 for instance because we want the pac-man to solve",
    "start": "916480",
    "end": "922000"
  },
  {
    "text": "the the game as fast as possible now this makes the agent a lot easier to converge",
    "start": "922000",
    "end": "928000"
  },
  {
    "text": "but he doesn't really get that smart because we decide what is good we don't",
    "start": "928000",
    "end": "933199"
  },
  {
    "text": "just say when the game we say go pick up coins and don't die right uh yeah another problem with",
    "start": "933199",
    "end": "940079"
  },
  {
    "text": "shaped rewards is that it is really hard to actually come up with these values like why should he have plus one for coin",
    "start": "940079",
    "end": "946399"
  },
  {
    "text": "and a minus five for dying why not plus two for coin and minus 14 for dying right so these",
    "start": "946399",
    "end": "952720"
  },
  {
    "text": "are are different to get and you just have to have to try your luck here and the third",
    "start": "952720",
    "end": "959360"
  },
  {
    "text": "challenge i was talking about is the simulated environments so on this picture you can see the",
    "start": "959360",
    "end": "966880"
  },
  {
    "text": "video mace game a couple of colleagues of ours made a computer controlled video",
    "start": "966880",
    "end": "972880"
  },
  {
    "text": "maze game where you can control the game via",
    "start": "972880",
    "end": "978000"
  },
  {
    "text": "xbox controllers now let's say you want to do reinforcement learning on this",
    "start": "978000",
    "end": "983120"
  },
  {
    "text": "because it's uh it fits pretty good in reinforcement learning right the agent could be the ball",
    "start": "983120",
    "end": "988560"
  },
  {
    "text": "um or the board and you have a lot of trial and error right",
    "start": "988560",
    "end": "993920"
  },
  {
    "text": "you can play a game and then you can start over and you can play game and you have a lot of time steps right you can kind of freeze time if you have",
    "start": "993920",
    "end": "1000240"
  },
  {
    "text": "a computer model so let's say you want to make make an ai for this",
    "start": "1000240",
    "end": "1006240"
  },
  {
    "text": "one idea could for instance be to to build an elevator for the ball so when the ball falls down in one pit",
    "start": "1006240",
    "end": "1012480"
  },
  {
    "text": "it automatically comes up and elevated up to the starting position and then you can try again",
    "start": "1012480",
    "end": "1017839"
  },
  {
    "text": "but let's say the average game for instance before he wins or loses is about 10 seconds and let's say you have",
    "start": "1017839",
    "end": "1023360"
  },
  {
    "text": "to train for a 50 000 games right this results",
    "start": "1023360",
    "end": "1030000"
  },
  {
    "text": "in the game just constantly playing for 347 days straight",
    "start": "1030000",
    "end": "1036640"
  },
  {
    "text": "so that obviously is not really feasible you know the game is going to be taken for a year you know",
    "start": "1036640",
    "end": "1043438"
  },
  {
    "text": "interrupts can happen you know and and so on and so on um so this is not really a really good",
    "start": "1043439",
    "end": "1050320"
  },
  {
    "text": "thing so what you have to do is you have to build a simulated environment for this game and the simulated environment has to be",
    "start": "1050320",
    "end": "1057440"
  },
  {
    "text": "really realistic you have to have the right friction between the ball the material of the ball and the material of the maze",
    "start": "1057440",
    "end": "1063360"
  },
  {
    "text": "and you have to really spend a lot of time to make this realistic another thing is that let's say you want",
    "start": "1063360",
    "end": "1069280"
  },
  {
    "text": "to make a self-driving car you know and you just have a car and you just put it on the street and it tries",
    "start": "1069280",
    "end": "1075360"
  },
  {
    "text": "training right and and suddenly you'll you'll run over some person and you'll be like oh bad",
    "start": "1075360",
    "end": "1082160"
  },
  {
    "text": "car i'll we'll start over it's fine it's fine you know and then you'll uh you'll just uh",
    "start": "1082160",
    "end": "1087200"
  },
  {
    "text": "run over a lot of people so that's it's not feasible right it's you have to build a simulated environment because it's better it's more safe for",
    "start": "1087200",
    "end": "1093120"
  },
  {
    "text": "the humans and it has to be able to run fast so you can run many many hundreds of thousands iterations",
    "start": "1093120",
    "end": "1099200"
  },
  {
    "text": "usually and in these simulation simulated",
    "start": "1099200",
    "end": "1105760"
  },
  {
    "text": "environments it's also important that when the car sees something that it hasn't seen that it can still",
    "start": "1105760",
    "end": "1111840"
  },
  {
    "text": "do something that's at least somewhat good you know if you have a self-driving car for instance",
    "start": "1111840",
    "end": "1118640"
  },
  {
    "text": "and you're just building a simulated environment and then you put it on the road and you suddenly see an iceberg on the road",
    "start": "1118640",
    "end": "1123919"
  },
  {
    "text": "like what what is the car going to do you know or for instance if suddenly a plane lands in front of you",
    "start": "1123919",
    "end": "1129440"
  },
  {
    "text": "on the on the highway what is the car going to do so building simulated environments especially for",
    "start": "1129440",
    "end": "1135520"
  },
  {
    "text": "for problems to take place in the real world is also a big challenge yes i think",
    "start": "1135520",
    "end": "1143520"
  },
  {
    "text": "q learning is up next",
    "start": "1143520",
    "end": "1150799"
  },
  {
    "text": "thank you just gonna put this mic on",
    "start": "1150799",
    "end": "1165840"
  },
  {
    "text": "i think that's fine all right hopefully you now have a basic understanding about what reinforcement",
    "start": "1167200",
    "end": "1173679"
  },
  {
    "text": "learning is about now i'm going to get more into how q learning works before we apply this",
    "start": "1173679",
    "end": "1179280"
  },
  {
    "text": "knowledge to train an agent so what is q learning q learning is an",
    "start": "1179280",
    "end": "1185120"
  },
  {
    "text": "algorithm which learns q values for state action pairs in the environment",
    "start": "1185120",
    "end": "1190240"
  },
  {
    "text": "now what does this mean well it means that for each possible state",
    "start": "1190240",
    "end": "1195280"
  },
  {
    "text": "there are a set of possible actions and for each of these actions the agent will learn a q value",
    "start": "1195280",
    "end": "1202960"
  },
  {
    "text": "a q value is a measure of utility or the quality of an action in a given state",
    "start": "1202960",
    "end": "1208480"
  },
  {
    "text": "it's a measure of how good it is so you can view it as an estimate of the total amount of reward",
    "start": "1208480",
    "end": "1213919"
  },
  {
    "text": "that the agent may be able to acquire by performing this particular action in",
    "start": "1213919",
    "end": "1219600"
  },
  {
    "text": "this state right now and in the end the agent will use this as a policy of how it should",
    "start": "1219600",
    "end": "1225679"
  },
  {
    "text": "interact with the environment so when you have a fully trained model the agent will perform the action with the highest q value",
    "start": "1225679",
    "end": "1232799"
  },
  {
    "text": "for the state it is in so this is a lot easier to explain if i",
    "start": "1232799",
    "end": "1238799"
  },
  {
    "text": "use a simple example and the thing is that this pandemic thing it really ruins the",
    "start": "1238799",
    "end": "1244799"
  },
  {
    "text": "setting of my example so let's just for a second assume that it it never happened right",
    "start": "1244799",
    "end": "1251520"
  },
  {
    "text": "the pandemic never happened and we're all in oslo and you're all hanging out at the ndc",
    "start": "1251520",
    "end": "1257200"
  },
  {
    "text": "conference with a lot of nice people so let's say after a long day at the ndc conference",
    "start": "1257200",
    "end": "1263919"
  },
  {
    "text": "you're really looking forward to having a beer with all the great people that you met so that smiley face right there in",
    "start": "1263919",
    "end": "1270799"
  },
  {
    "text": "square zero that's you and the bar that you're trying to",
    "start": "1270799",
    "end": "1275840"
  },
  {
    "text": "get to that's in square eight and let's say you've never really been in oslo before",
    "start": "1275840",
    "end": "1281360"
  },
  {
    "text": "and you don't have a map for some reason so you're just going to roam around these squares until you find this bar so",
    "start": "1281360",
    "end": "1288240"
  },
  {
    "text": "to be able to learn from your mistakes and also your correct decisions we need a measure for",
    "start": "1288240",
    "end": "1294799"
  },
  {
    "text": "success and that's where these rewards come in so if you get to the bar let's say you",
    "start": "1294799",
    "end": "1301440"
  },
  {
    "text": "get 20 points on the way to the bar you could end up",
    "start": "1301440",
    "end": "1307360"
  },
  {
    "text": "at the food court where you have some food and that's five points because it's always better to drink after having",
    "start": "1307360",
    "end": "1313760"
  },
  {
    "text": "some food never drink on an empty stomach right you could also be unlucky and then you",
    "start": "1313760",
    "end": "1320799"
  },
  {
    "text": "could end up in agashelva which is a river that runs through the middle of oslo and you get minus 20 points",
    "start": "1320799",
    "end": "1329039"
  },
  {
    "text": "we also have a move penalty of minus one point and this is because you want to get to this bar and have that drink as quickly as",
    "start": "1329520",
    "end": "1336240"
  },
  {
    "text": "possible you don't want to roam around the city for too long",
    "start": "1336240",
    "end": "1342320"
  },
  {
    "text": "and also because practice makes perfect you will try to find this bar a certain number of times and",
    "start": "1342320",
    "end": "1349679"
  },
  {
    "text": "each of these tries they're called an episode and squares four and eight they're",
    "start": "1349679",
    "end": "1355280"
  },
  {
    "text": "called terminal states that's where an episode ends we will keep track of these q values for",
    "start": "1355280",
    "end": "1362480"
  },
  {
    "text": "each action in each state using a dictionary in the beginning we will have an empty",
    "start": "1362480",
    "end": "1367919"
  },
  {
    "text": "dictionary which means that the q values are all initialized to zero and then following the execution of",
    "start": "1367919",
    "end": "1374400"
  },
  {
    "text": "an action the q value for the action that you chose in the state you were in",
    "start": "1374400",
    "end": "1380080"
  },
  {
    "text": "needs to be updated with the new information that you have gained in the next state",
    "start": "1380080",
    "end": "1386080"
  },
  {
    "text": "so you perform an action in this state and then you end up in the next state",
    "start": "1386080",
    "end": "1392159"
  },
  {
    "text": "we will do this using this kind of complicated looking formula which isn't really that complicated we",
    "start": "1392640",
    "end": "1398559"
  },
  {
    "text": "just have to take it apart a little bit i'm not going to get into the details of the mathematics and",
    "start": "1398559",
    "end": "1405200"
  },
  {
    "text": "why it looks like it does but i'm going to explain um the different parts of it",
    "start": "1405200",
    "end": "1412559"
  },
  {
    "text": "so to update the q value for the state action pair we will take the alt q value and then we will add",
    "start": "1412559",
    "end": "1419919"
  },
  {
    "text": "the reward that you gained in the new state we will also add the estimate of the",
    "start": "1419919",
    "end": "1426320"
  },
  {
    "text": "optimal future value which is a really fancy way of",
    "start": "1426320",
    "end": "1432559"
  },
  {
    "text": "saying take the highest q value for the state you ended up in",
    "start": "1432559",
    "end": "1438720"
  },
  {
    "text": "and then we will subtract the old q value then you also have a couple of constant",
    "start": "1438720",
    "end": "1445279"
  },
  {
    "text": "factors here these values are usually between 0 and 1 and they're used for scaling",
    "start": "1445279",
    "end": "1451600"
  },
  {
    "text": "the discount factor is used to scale down the entire update",
    "start": "1451600",
    "end": "1456720"
  },
  {
    "text": "sorry the discount factor is used to scale down the q value from the next state and we do this",
    "start": "1456720",
    "end": "1462240"
  },
  {
    "text": "because we value the reward that we receive right now higher than the potential amount of reward that",
    "start": "1462240",
    "end": "1469279"
  },
  {
    "text": "we may receive later so reward now is better than maybe rewards later",
    "start": "1469279",
    "end": "1476799"
  },
  {
    "text": "and then you have the learning rate which is something that's used in many machine learning algorithms it's another scaling factor which is",
    "start": "1476799",
    "end": "1483600"
  },
  {
    "text": "used to scale down the entire update value during training we want to",
    "start": "1483600",
    "end": "1489120"
  },
  {
    "text": "update the q values iteratively and slowly so that we can gradually close down in all the optimal",
    "start": "1489120",
    "end": "1495600"
  },
  {
    "text": "q values if we do not scale down the q values may change too much at each step and",
    "start": "1495600",
    "end": "1503279"
  },
  {
    "text": "they the agent may not be able to learn anything useful",
    "start": "1503279",
    "end": "1509039"
  },
  {
    "text": "if we look at uh the cube the loss or the error made by the agent as a",
    "start": "1509039",
    "end": "1514960"
  },
  {
    "text": "function of the q values then what we're trying to do looking at this graph",
    "start": "1514960",
    "end": "1520559"
  },
  {
    "text": "is that we want to find that bottom point the minimum point so if we change the q",
    "start": "1520559",
    "end": "1528240"
  },
  {
    "text": "values um too much by a large amount every time then we might bounce back and forth and",
    "start": "1528240",
    "end": "1534880"
  },
  {
    "text": "miss out on this minimum point that we're trying to find on the other hand if we do this slowly",
    "start": "1534880",
    "end": "1542960"
  },
  {
    "text": "and just update by small magnitude every time then it will be easier to",
    "start": "1542960",
    "end": "1548480"
  },
  {
    "text": "find this minimum point even though it might may take a little bit longer",
    "start": "1548480",
    "end": "1554158"
  },
  {
    "text": "so knowing all this let's do a test run with our example right so in the",
    "start": "1555760",
    "end": "1561440"
  },
  {
    "text": "beginning you don't really have any knowledge about the environment so you're just going to pick a random",
    "start": "1561440",
    "end": "1566799"
  },
  {
    "text": "action and you might end up in state 3. and so we update the q value",
    "start": "1566799",
    "end": "1572799"
  },
  {
    "text": "for going to state 3 from state 0. similarly we might end up in",
    "start": "1572799",
    "end": "1578000"
  },
  {
    "text": "state 6 so we update that particular q value and then this goes on and at some point",
    "start": "1578000",
    "end": "1585600"
  },
  {
    "text": "you will end up in a terminal state so as you can see",
    "start": "1585600",
    "end": "1590880"
  },
  {
    "text": "the magnitudes of these values these numbers um they reflect uh the amount of",
    "start": "1590880",
    "end": "1599120"
  },
  {
    "text": "positivity or negativity that resulted in picking that",
    "start": "1599120",
    "end": "1605440"
  },
  {
    "text": "that particular action in those states so this is going to go on for a while",
    "start": "1605440",
    "end": "1612480"
  },
  {
    "text": "right when the episode ends you start again you explore the environment for many",
    "start": "1612480",
    "end": "1619200"
  },
  {
    "text": "many episodes and you're just trying out seeing what's going on in this environment and at some point",
    "start": "1619200",
    "end": "1625919"
  },
  {
    "text": "these values are going to converge until that path towards this bar",
    "start": "1625919",
    "end": "1632559"
  },
  {
    "text": "is as clear as it can get where you can have that ring and this is essentially what we're going",
    "start": "1632559",
    "end": "1638159"
  },
  {
    "text": "to do with pac-man though pac-man differs a little bit because the game is more dynamic",
    "start": "1638159",
    "end": "1644880"
  },
  {
    "text": "you have these ghosts so you have the multiple entities in",
    "start": "1644880",
    "end": "1650720"
  },
  {
    "text": "addition to the pac-man but the general idea is the same you have a grid-like board and there are different states",
    "start": "1650720",
    "end": "1656640"
  },
  {
    "text": "it's just that you have uh this you know the states depends on where the ghosts are located",
    "start": "1656640",
    "end": "1661679"
  },
  {
    "text": "in addition to the pac-man and also these coins that the pac-man can pick up",
    "start": "1661679",
    "end": "1667200"
  },
  {
    "text": "so we did this project using python which is very common for machine learning projects and we also",
    "start": "1667520",
    "end": "1673440"
  },
  {
    "text": "use tensorflow which is google's machine learning library and we used keras which is a",
    "start": "1673440",
    "end": "1680399"
  },
  {
    "text": "wrapper around tensorflow which makes it a little bit more user",
    "start": "1680399",
    "end": "1686080"
  },
  {
    "text": "friendly this was a lot more relevant before i feel like",
    "start": "1686080",
    "end": "1691760"
  },
  {
    "text": "because tensorflow the last few versions have been a lot better when it comes to user",
    "start": "1691760",
    "end": "1698159"
  },
  {
    "text": "friendliness than back in the day so what i'm going to do now is show you a little bit of code and",
    "start": "1698159",
    "end": "1704399"
  },
  {
    "text": "then we can watch the agent in action",
    "start": "1704399",
    "end": "1711760"
  },
  {
    "text": "so let's head on over to the code",
    "start": "1711760",
    "end": "1715679"
  },
  {
    "text": "so as you can see this is a jupyter notebook as i mentioned earlier we initially",
    "start": "1718000",
    "end": "1723760"
  },
  {
    "text": "created created this as a workshop so we found it very useful to use microsoft azure's virtual machines for",
    "start": "1723760",
    "end": "1731919"
  },
  {
    "text": "machine learning they have a lot of built-in environments python environments and",
    "start": "1731919",
    "end": "1737600"
  },
  {
    "text": "machine learning packages already pre-installed making it very easy to use and in our case it was very useful to",
    "start": "1737600",
    "end": "1744399"
  },
  {
    "text": "use jupyter hub which made it possible for multiple users to log in with different logins and have access",
    "start": "1744399",
    "end": "1752720"
  },
  {
    "text": "to the same code through jupyter notebooks in the cloud and this made it easy for them to",
    "start": "1752720",
    "end": "1758640"
  },
  {
    "text": "code and run code without having local setups on their machines",
    "start": "1758640",
    "end": "1764080"
  },
  {
    "text": "so this is the code for uh the q learning and as you can see there's not",
    "start": "1764080",
    "end": "1770240"
  },
  {
    "text": "a whole lot of code it's very simple uh i'm not going to go through this line by line but i will",
    "start": "1770240",
    "end": "1777120"
  },
  {
    "text": "do some honorable mentions where it seems sensible so in the beginning we're just importing",
    "start": "1777120",
    "end": "1783440"
  },
  {
    "text": "the packages that we need including the pacman game package and then what we have here is a method for",
    "start": "1783440",
    "end": "1790000"
  },
  {
    "text": "calculating the reward given an action event from the game so you have these different",
    "start": "1790000",
    "end": "1795360"
  },
  {
    "text": "events for picking up uh um a coin or a dot being captured by ghost",
    "start": "1795360",
    "end": "1801520"
  },
  {
    "text": "winning losing etc and this needs to be defined when we're creating this",
    "start": "1801520",
    "end": "1808880"
  },
  {
    "text": "so this is a case of trial and error there are different sets of values that may work",
    "start": "1808880",
    "end": "1814159"
  },
  {
    "text": "this is just one of these sets that we found worked worked out fine",
    "start": "1814159",
    "end": "1819200"
  },
  {
    "text": "what's important here is that these values need to be balanced in relation to each other",
    "start": "1820240",
    "end": "1826720"
  },
  {
    "text": "these values need to represent somehow the importance of each of these game events and also",
    "start": "1826720",
    "end": "1833679"
  },
  {
    "text": "the amount of positivity or negativity that results in this game event happening",
    "start": "1833679",
    "end": "1840240"
  },
  {
    "text": "so as you can see you have negative values for negative events and positive values for the positive events",
    "start": "1840240",
    "end": "1846080"
  },
  {
    "text": "and of course winning is better than um and then just picking up a single dot so",
    "start": "1846080",
    "end": "1852480"
  },
  {
    "text": "the value for winning is a lot higher than picking up a single dot and so on and so you have the q table",
    "start": "1852480",
    "end": "1860799"
  },
  {
    "text": "which is initialized to uh to be empty in the beginning then you have a couple of methods for",
    "start": "1860799",
    "end": "1866960"
  },
  {
    "text": "picking uh the action given a game state so in this method we have",
    "start": "1866960",
    "end": "1874240"
  },
  {
    "text": "implemented the exploration concept as well the exploration probability is set to",
    "start": "1874240",
    "end": "1880080"
  },
  {
    "text": "0.3 which means that there is a 30 chance that the pac-man will just",
    "start": "1880080",
    "end": "1885840"
  },
  {
    "text": "pick a random action for a given state that it is",
    "start": "1885840",
    "end": "1891039"
  },
  {
    "text": "in and otherwise it will exploit the knowledge that it has procured",
    "start": "1891039",
    "end": "1896720"
  },
  {
    "text": "by exploring the environment so then it will just pick um the action with the highest q value",
    "start": "1896720",
    "end": "1904000"
  },
  {
    "text": "for the state it is in so in the training method here we have",
    "start": "1904000",
    "end": "1909519"
  },
  {
    "text": "defined the discount factor and the alpha also known as the learning rate",
    "start": "1909519",
    "end": "1915360"
  },
  {
    "text": "and these are also set by trying out different values experimentation",
    "start": "1915360",
    "end": "1922480"
  },
  {
    "text": "and then the training process consists of running for a certain number of episodes where uh the agent picks an action",
    "start": "1926399",
    "end": "1934880"
  },
  {
    "text": "uh in the state it is in and then the game will return a new game",
    "start": "1934880",
    "end": "1940399"
  },
  {
    "text": "state and also an action event describing what happened",
    "start": "1940399",
    "end": "1946640"
  },
  {
    "text": "in the game the reward is calculated given the action event the game event that",
    "start": "1946640",
    "end": "1953039"
  },
  {
    "text": "happened and then this can be used to update the q value for the action that was picked",
    "start": "1953039",
    "end": "1958080"
  },
  {
    "text": "in that particular state so this is just",
    "start": "1958080",
    "end": "1963519"
  },
  {
    "text": "an implementation of the formula that i showed you earlier and then in the end the model is saved",
    "start": "1963519",
    "end": "1970799"
  },
  {
    "text": "to a pickle file and we can use it to see how it performs in the game so i'm not",
    "start": "1970799",
    "end": "1978240"
  },
  {
    "text": "actually going to train animals now it can take some time some of the models we",
    "start": "1978240",
    "end": "1983360"
  },
  {
    "text": "trained were trained for uh several hours so we have some pre-trained ready to go and",
    "start": "1983360",
    "end": "1988799"
  },
  {
    "text": "we're just gonna get on to showing you those instead of spending time training animals here",
    "start": "1988799",
    "end": "1996000"
  },
  {
    "text": "so so you've already already seen how the what the",
    "start": "1996000",
    "end": "2001760"
  },
  {
    "text": "game look looks like so i'm just going to run the the run the map that we showed you",
    "start": "2001760",
    "end": "2008720"
  },
  {
    "text": "earlier once where we just let the pac-man pick a random action and i'm",
    "start": "2008720",
    "end": "2015440"
  },
  {
    "text": "going to show you this so that you have something to compare with when i show you the model that has been",
    "start": "2015440",
    "end": "2021120"
  },
  {
    "text": "trained",
    "start": "2021120",
    "end": "2023519"
  },
  {
    "text": "so as you can see here now the pac-man is just doing some random stuff and it loses pretty quickly",
    "start": "2028880",
    "end": "2037120"
  },
  {
    "text": "so even though the map is small it's not able to win",
    "start": "2037919",
    "end": "2043279"
  },
  {
    "text": "by luck because these random actions they're just not enough so the game exits when it loses all its",
    "start": "2043279",
    "end": "2049440"
  },
  {
    "text": "life so i'm going to show you how it performs with a model that i trained for a thousand episodes",
    "start": "2049440",
    "end": "2061839"
  },
  {
    "text": "so here we can see quite clearly that it knows what it's doing compared to the the random the random agent",
    "start": "2064960",
    "end": "2075839"
  },
  {
    "text": "so here you can see that it's actually able to avoid the ghost and and then it does kind of different",
    "start": "2075919",
    "end": "2082320"
  },
  {
    "text": "stuff on each run so the behavior can be different at some times",
    "start": "2082320",
    "end": "2089280"
  },
  {
    "text": "but clearly it's able to win compared to uh the random the random model so in this case we see",
    "start": "2089280",
    "end": "2096560"
  },
  {
    "text": "that it's kind of probing trying trying to go to the right but then it's kind of staying away from the ghost",
    "start": "2096560",
    "end": "2104000"
  },
  {
    "text": "instead of going right into it and then it changes direction when it gets chased by the ghost",
    "start": "2104000",
    "end": "2110320"
  },
  {
    "text": "so we actually have a bigger map and i'm going to show you what that",
    "start": "2110320",
    "end": "2117040"
  },
  {
    "text": "looks like",
    "start": "2117040",
    "end": "2119520"
  },
  {
    "text": "so the model for the the bigger map is also big the model itself is bigger",
    "start": "2127680",
    "end": "2133119"
  },
  {
    "text": "that's why it takes a little bit more time to load it into memory here um i think it's around 300 megabytes the",
    "start": "2133119",
    "end": "2140000"
  },
  {
    "text": "one i trained for uh 100 episodes compared to a few kilobytes",
    "start": "2140000",
    "end": "2146480"
  },
  {
    "text": "the one for the first map and here we can see that",
    "start": "2146480",
    "end": "2153359"
  },
  {
    "text": "here we can see that it's okay it's actually performing better now than i've seen it do before actually",
    "start": "2155040",
    "end": "2162400"
  },
  {
    "text": "but still it's not really doing actually it's a lot better than what",
    "start": "2162400",
    "end": "2168160"
  },
  {
    "text": "i've seen before it never gets this far with this model that's kind of special",
    "start": "2168160",
    "end": "2174160"
  },
  {
    "text": "huh interesting usually it just kind of goes back and forth from the starting position and it's not really doing anything",
    "start": "2174160",
    "end": "2180800"
  },
  {
    "text": "sensible and it almost looks kind of random but at this point now you can see that it doesn't it it looks pretty random",
    "start": "2180800",
    "end": "2188079"
  },
  {
    "text": "so obviously it needs to be trained for much longer even though it was performing a lot",
    "start": "2188079",
    "end": "2193440"
  },
  {
    "text": "better than i expected um so i only trained this model for 100",
    "start": "2193440",
    "end": "2198800"
  },
  {
    "text": "episodes so you're thinking okay so training for more episodes and it's going to perform",
    "start": "2198800",
    "end": "2204240"
  },
  {
    "text": "better um it's a little bit more problematic than that right so i tried to train it",
    "start": "2204240",
    "end": "2210560"
  },
  {
    "text": "for a thousand episodes and it didn't really work out pretty well and i'm going to head back into the presentation and explain to you",
    "start": "2210560",
    "end": "2217040"
  },
  {
    "text": "why that is not going to work out well so i'm just going to there we go",
    "start": "2217040",
    "end": "2228320"
  },
  {
    "text": "so the first map it has 12 legal positions for the",
    "start": "2228320",
    "end": "2234640"
  },
  {
    "text": "pac-man and the ghost and with those five coins",
    "start": "2234640",
    "end": "2242079"
  },
  {
    "text": "this results in approximately 4 200 possible states actually it's a little bit more",
    "start": "2242079",
    "end": "2247760"
  },
  {
    "text": "because the absence of a dot in a different is a different state than when it is present and there are different",
    "start": "2247760",
    "end": "2253520"
  },
  {
    "text": "permutations of these as well but approximately 4 200",
    "start": "2253520",
    "end": "2259280"
  },
  {
    "text": "and that's that's a that number is fine it's very manageable right then you have",
    "start": "2259280",
    "end": "2266320"
  },
  {
    "text": "uh the second map where you have 68 legal positions you have two ghosts you have the pac-man",
    "start": "2266320",
    "end": "2271760"
  },
  {
    "text": "and you also have around 50 53 coins i think this results in 2.7 times 10",
    "start": "2271760",
    "end": "2279599"
  },
  {
    "text": "to the 21st possible number of states and that's a pretty huge number the",
    "start": "2279599",
    "end": "2285839"
  },
  {
    "text": "problem with q learning is that it doesn't scale well as the number of states increases",
    "start": "2285839",
    "end": "2295040"
  },
  {
    "text": "so as the number of states becomes pretty big the problem",
    "start": "2295040",
    "end": "2301440"
  },
  {
    "text": "essentially becomes invisible because you have to train it for many episodes",
    "start": "2301440",
    "end": "2306800"
  },
  {
    "text": "for the pacman to be able to explore the environment enough to map out all the different board configurations and this",
    "start": "2306800",
    "end": "2315040"
  },
  {
    "text": "makes the model really big the model that i trained for a thousand episodes was approximately",
    "start": "2315040",
    "end": "2321599"
  },
  {
    "text": "three gigabytes big which is ten times bigger than the model i trained for 100 episodes and",
    "start": "2321599",
    "end": "2329200"
  },
  {
    "text": "i i don't believe i've been able to load it into memory for it to be able to run at all",
    "start": "2329200",
    "end": "2334400"
  },
  {
    "text": "and this is why we need deep q learning to solve this problem",
    "start": "2334400",
    "end": "2339680"
  },
  {
    "text": "so i'm gonna give this back to my buddy over here",
    "start": "2339680",
    "end": "2345040"
  },
  {
    "text": "there you go sir all right thank you thank you",
    "start": "2349280",
    "end": "2356880"
  },
  {
    "text": "let's see here yeah so when there's too many states you know q learning",
    "start": "2357839",
    "end": "2363520"
  },
  {
    "text": "doesn't doesn't cut it so we need to introduce what's called a deep q network",
    "start": "2363520",
    "end": "2372160"
  },
  {
    "text": "so deepq network was kind of first introduced in 2013 but it's no more known for the results",
    "start": "2373359",
    "end": "2380079"
  },
  {
    "text": "it had in the paper in 2015 where it played atari games at a superhuman level",
    "start": "2380079",
    "end": "2387520"
  },
  {
    "text": "so why is the dqn even a thing and i think with menu's example it's",
    "start": "2387839",
    "end": "2393839"
  },
  {
    "text": "pretty clear that when the memory gets too big you you can't just have this spreadsheet approach",
    "start": "2393839",
    "end": "2401760"
  },
  {
    "text": "of storing all the states so what you do instead is that you add a neural network and throw away",
    "start": "2401839",
    "end": "2407359"
  },
  {
    "text": "the q table the neural network will will perform as",
    "start": "2407359",
    "end": "2414160"
  },
  {
    "text": "an estimator where it takes the state as an input and then it outputs the action that we want to",
    "start": "2414160",
    "end": "2419680"
  },
  {
    "text": "perform then also we add something called an experience replay that i'm going to come back to very soon",
    "start": "2419680",
    "end": "2429200"
  },
  {
    "text": "so now this one looks a little bit like the other one i showed you guys earlier",
    "start": "2429599",
    "end": "2434640"
  },
  {
    "text": "today so if we start on the right here we have the environment which gives the state and reward into the agent",
    "start": "2434640",
    "end": "2443119"
  },
  {
    "text": "and then the state is plotted into a neural network the neural network has a policy that",
    "start": "2443119",
    "end": "2449440"
  },
  {
    "text": "tells you what action to perform and you perform that action into the environment",
    "start": "2449440",
    "end": "2454480"
  },
  {
    "text": "and then the loops continues until you reach the terminal state",
    "start": "2454480",
    "end": "2459119"
  },
  {
    "text": "so experience replay so what that is is instead of training online we save an",
    "start": "2459680",
    "end": "2465280"
  },
  {
    "text": "experience to memory and train on random samples from it so online training means that for",
    "start": "2465280",
    "end": "2472560"
  },
  {
    "text": "instance in the queue learning algorithm we made a move into the environment we",
    "start": "2472560",
    "end": "2478480"
  },
  {
    "text": "got the action back or the reward back and then we immediately updated the the",
    "start": "2478480",
    "end": "2486160"
  },
  {
    "text": "q values and then we went one more time step and then we trained",
    "start": "2486160",
    "end": "2491200"
  },
  {
    "text": "the q table or updated the q table training the agent and so on so one time step",
    "start": "2491200",
    "end": "2498319"
  },
  {
    "text": "one action and then we train and one action and then we train this is called training online but what we instead are gonna do now is",
    "start": "2498319",
    "end": "2504960"
  },
  {
    "text": "that we're gonna the agent is gonna perform an action you're going to get a reward but instead of automatically",
    "start": "2504960",
    "end": "2510800"
  },
  {
    "text": "started training the agent for instance by updating the q value or training a neural network",
    "start": "2510800",
    "end": "2516800"
  },
  {
    "text": "we're going to save this experience which contains the current state the",
    "start": "2516800",
    "end": "2522319"
  },
  {
    "text": "action that's performed in that state the next date and the reward that",
    "start": "2522319",
    "end": "2528000"
  },
  {
    "text": "the agent got we're going to save that experience into a memory and then we can pull random samples",
    "start": "2528000",
    "end": "2535440"
  },
  {
    "text": "from this memory bank that we have why we do this is because the deep q network usually or",
    "start": "2535440",
    "end": "2542400"
  },
  {
    "text": "tend to forget early runs that means that for instance on the on the large map that we showed",
    "start": "2542400",
    "end": "2547760"
  },
  {
    "text": "you guys um the uh",
    "start": "2547760",
    "end": "2552880"
  },
  {
    "text": "the if the agent starts figuring out how to solve the the first part of it then when it starts",
    "start": "2552880",
    "end": "2560000"
  },
  {
    "text": "like on the mid game or the middle part of this of the of the map then when you train",
    "start": "2560000",
    "end": "2565359"
  },
  {
    "text": "this on neural network the neural network kind of tends to forget how to solve the the",
    "start": "2565359",
    "end": "2570480"
  },
  {
    "text": "early the early stages of that map but when you instead just save it to a memory bank the memory bank is going to",
    "start": "2570480",
    "end": "2576880"
  },
  {
    "text": "contain both early mid and kind of late game experiences so you're going to train on",
    "start": "2576880",
    "end": "2583280"
  },
  {
    "text": "them all at the same time it is also nice because you can learn",
    "start": "2583280",
    "end": "2590400"
  },
  {
    "text": "previous experiences multiple times so when you train a neural network the weights inside the neural network change",
    "start": "2590400",
    "end": "2596800"
  },
  {
    "text": "very very very slightly that's why you have to train for so many iterations and learning from a previous experience",
    "start": "2596800",
    "end": "2603680"
  },
  {
    "text": "by saving them so you can learn multiple times is really nice",
    "start": "2603680",
    "end": "2610240"
  },
  {
    "text": "yes so how do we put a pacman state into a neural network so we're not going",
    "start": "2610480",
    "end": "2617599"
  },
  {
    "text": "to talk about anything about neural networks today you can kind of think of it as a black box but we're going to talk about how we get stuff into it and",
    "start": "2617599",
    "end": "2623760"
  },
  {
    "text": "how we get get numbers out of it so neural networks they take numbers as",
    "start": "2623760",
    "end": "2629760"
  },
  {
    "text": "input you can't just put like a string representation of the map in you have to make that string representation into a number",
    "start": "2629760",
    "end": "2637280"
  },
  {
    "text": "or a vector of numbers before you can you can feed it to the to",
    "start": "2637280",
    "end": "2643119"
  },
  {
    "text": "the network so one way of doing this is using one hot encoding",
    "start": "2643119",
    "end": "2648240"
  },
  {
    "text": "so 100 encoding usually is used when you have categorical values so let's say that we have a feature here",
    "start": "2648240",
    "end": "2656079"
  },
  {
    "text": "color and you have three different values you have red green and blue uh one way to like to make these",
    "start": "2656079",
    "end": "2664000"
  },
  {
    "text": "into numbers right is to assign the value for all of these categories so for instance red could be one green can be two",
    "start": "2664000",
    "end": "2670319"
  },
  {
    "text": "and blue can be three but that's a little bit weird you know because as i hope",
    "start": "2670319",
    "end": "2676880"
  },
  {
    "text": "many of you guys will agree with me on is that three is bigger than one so what you're kind of telling the",
    "start": "2676880",
    "end": "2682800"
  },
  {
    "text": "neural network if you do it this way is that blue is bigger than red like three times as big as red exactly you're telling",
    "start": "2682800",
    "end": "2689760"
  },
  {
    "text": "if red is one and green is two you're telling that green is twice as big as red which doesn't really make any sense so",
    "start": "2689760",
    "end": "2695839"
  },
  {
    "text": "instead of just assigning them a number or an integer you just you make a vector",
    "start": "2695839",
    "end": "2701280"
  },
  {
    "text": "instead and the length of the vector is how many different kind of categories you have in your in your feature so we have three",
    "start": "2701280",
    "end": "2707920"
  },
  {
    "text": "different categories here um possible values for the categories",
    "start": "2707920",
    "end": "2713280"
  },
  {
    "text": "so the vector is going to be three three long right and then red is going to become one zero zero green is going to be zero zero one",
    "start": "2713280",
    "end": "2719440"
  },
  {
    "text": "and blue is going to be one zero one for instance so they now they're the same length right the length of these vectors are the same",
    "start": "2719440",
    "end": "2726160"
  },
  {
    "text": "but they are different because there's three numbers and they're one in in different spots",
    "start": "2726160",
    "end": "2732640"
  },
  {
    "text": "so if we do this um with our our string representation of",
    "start": "2732640",
    "end": "2739760"
  },
  {
    "text": "a pacman map we could do something like this right we could just start at the top",
    "start": "2739760",
    "end": "2745200"
  },
  {
    "text": "left of the map and then you can just traverse over the map and we can like concatenate",
    "start": "2745200",
    "end": "2751280"
  },
  {
    "text": "vectors right so it becomes one long vector this exact state and here you can see like oh that's a",
    "start": "2751280",
    "end": "2757680"
  },
  {
    "text": "fruit you guys haven't seen that yet you have the the space which is nothing",
    "start": "2757680",
    "end": "2763200"
  },
  {
    "text": "you have p which is the pac-man g is the ghost and dot is is one of those coins",
    "start": "2763200",
    "end": "2769200"
  },
  {
    "text": "so let's look at an example here uh at the bottom left here this is the starting position of",
    "start": "2769200",
    "end": "2775280"
  },
  {
    "text": "level zero that we guys showed you first when you one hot encode this and",
    "start": "2775280",
    "end": "2781599"
  },
  {
    "text": "traverse from top left to bottom right you don't have to do the walls because the walls never",
    "start": "2781599",
    "end": "2787680"
  },
  {
    "text": "move so they're not part of the state but the vector is then going to look like the the vector in the bottom right",
    "start": "2787680",
    "end": "2795040"
  },
  {
    "text": "and that vector is only only valid for exactly that state",
    "start": "2795040",
    "end": "2801040"
  },
  {
    "text": "so if you move pac-man for instance one to the left and the ghosts you know goes one to the",
    "start": "2801040",
    "end": "2807200"
  },
  {
    "text": "right in the next state this vector is going to be different and therefore the neural network can tell",
    "start": "2807200",
    "end": "2812480"
  },
  {
    "text": "different states apart uh the neural network is then hopefully",
    "start": "2812480",
    "end": "2818160"
  },
  {
    "text": "after it's trained it's going to tell us what actions are the best actions to do in the state",
    "start": "2818160",
    "end": "2824079"
  },
  {
    "text": "so you're going to get four values out of the neural network which is in in the following order of",
    "start": "2824079",
    "end": "2831119"
  },
  {
    "text": "left top right and and down so if you want to do the optimal",
    "start": "2831119",
    "end": "2837680"
  },
  {
    "text": "optimal play or the optimal action you just choose the action which has the highest",
    "start": "2837680",
    "end": "2844079"
  },
  {
    "text": "value and with that said i think",
    "start": "2844079",
    "end": "2850480"
  },
  {
    "text": "we're going to take a look at deep q learning on pac-man so let's see here",
    "start": "2850480",
    "end": "2859839"
  },
  {
    "text": "so you guys can see that that looks good um",
    "start": "2861359",
    "end": "2868079"
  },
  {
    "text": "yeah so i'm gonna take a look at this yeah so we're gonna",
    "start": "2869119",
    "end": "2875280"
  },
  {
    "text": "look at the code in here not in interpreter so here you have the one",
    "start": "2875280",
    "end": "2880720"
  },
  {
    "text": "hot encoding we already saw that um",
    "start": "2880720",
    "end": "2887359"
  },
  {
    "text": "so i'm cheating a little bit with the exploration probability it's decaying so in the early game it",
    "start": "2887359",
    "end": "2895200"
  },
  {
    "text": "starts out as a higher value for instance in the early game you really want to explore the state space",
    "start": "2895200",
    "end": "2902240"
  },
  {
    "text": "while in the later portions of the game when you have done many episodes you would want to kind of focus",
    "start": "2904319",
    "end": "2910640"
  },
  {
    "text": "on the optimal path and try to improve that uh yeah let's see here else it's",
    "start": "2910640",
    "end": "2919119"
  },
  {
    "text": "pretty similar we're not gonna look at this at all i think",
    "start": "2919119",
    "end": "2928720"
  },
  {
    "text": "yeah i think that's about it so let's take a look at how",
    "start": "2928720",
    "end": "2936800"
  },
  {
    "text": "one second here let's take a look at how the pacman agent on the level two that we guys showed you",
    "start": "2940640",
    "end": "2948559"
  },
  {
    "text": "not the first one but the second one how it performs when it has trained for let's start with",
    "start": "2948559",
    "end": "2954480"
  },
  {
    "text": "500 episodes uh you was it command 8 it was",
    "start": "2954480",
    "end": "2962720"
  },
  {
    "text": "here so let's see here so now it should run with the deep cue",
    "start": "2962720",
    "end": "2967839"
  },
  {
    "text": "and then we can just start it like this",
    "start": "2967839",
    "end": "2971839"
  },
  {
    "text": "yeah so now this is after training the pac-man for 500 episodes so we have 500 times either",
    "start": "2974240",
    "end": "2982480"
  },
  {
    "text": "one or lost and using a neural network you know it starts instantly the neural network doesn't actually get bigger",
    "start": "2982480",
    "end": "2989440"
  },
  {
    "text": "the bigger state it has it just depends on the size of the neural network so we'll just instantly load",
    "start": "2989440",
    "end": "2997520"
  },
  {
    "text": "so the trade-off here is obviously if you have the spreadsheet approach of of the q learning",
    "start": "2997520",
    "end": "3004160"
  },
  {
    "text": "you you will have perfect accuracy right because you will have exactly each state you'll have what is",
    "start": "3004160",
    "end": "3010079"
  },
  {
    "text": "the best move but with the neural network you kind of trade memory for accuracy whether you have to train",
    "start": "3010079",
    "end": "3016240"
  },
  {
    "text": "the neural network to become as accurate as possible um so yeah you can see here that after",
    "start": "3016240",
    "end": "3023520"
  },
  {
    "text": "already 500 episodes the pac-man performs pretty pretty well it doesn't",
    "start": "3023520",
    "end": "3029839"
  },
  {
    "text": "solve it but it's it's doing pretty well let's look at",
    "start": "3029839",
    "end": "3035440"
  },
  {
    "text": "1500 episodes um",
    "start": "3035440",
    "end": "3041838"
  },
  {
    "text": "another thing to notice about this map this was the first map i was i was really experimenting on with",
    "start": "3042720",
    "end": "3050640"
  },
  {
    "text": "the pac-man with the neural network i mean it is that when you pick one of these",
    "start": "3050640",
    "end": "3057040"
  },
  {
    "text": "mushrooms it's one of these uh gray thingies that are laying around the the map",
    "start": "3057040",
    "end": "3063040"
  },
  {
    "text": "the ghost becomes a different color and then they'll run away from pac-man and if pac-man hits the ghost",
    "start": "3063040",
    "end": "3069839"
  },
  {
    "text": "the ghost then dies and goes back to its starting position one thing you also might have noticed is",
    "start": "3069920",
    "end": "3075280"
  },
  {
    "text": "that the pac-man usually just rushes for these fruits they're called these great things",
    "start": "3075280",
    "end": "3082640"
  },
  {
    "text": "and that's because they give a little bit we have the reward is a little bit higher for these than for regular coins",
    "start": "3082640",
    "end": "3088480"
  },
  {
    "text": "so we'll just rush to these uh we can take a look at kind of the and uh",
    "start": "3088480",
    "end": "3096319"
  },
  {
    "text": "we're gonna take at 3 500 episodes i trained for a total of four thousand",
    "start": "3096319",
    "end": "3105119"
  },
  {
    "text": "uh 500 so we're gonna look at that later but it rushes to all these fruits you can see the ghosts are really scared",
    "start": "3105119",
    "end": "3110559"
  },
  {
    "text": "they just they don't run at pac-man i regret a little bit putting this many fruits in the",
    "start": "3110559",
    "end": "3116800"
  },
  {
    "text": "on this map because it makes it i think maybe a little bit too easy",
    "start": "3116800",
    "end": "3122000"
  },
  {
    "text": "for the pac-man to do anything of significance this is trained by the way on my gpu at",
    "start": "3122000",
    "end": "3130160"
  },
  {
    "text": "home it's a gtx 1080",
    "start": "3130160",
    "end": "3135280"
  },
  {
    "text": "ti and it took about 26 hours to train this all the way to 4500 episodes",
    "start": "3136839",
    "end": "3145200"
  },
  {
    "text": "so we can see that he actually beat the game here",
    "start": "3145200",
    "end": "3149520"
  },
  {
    "text": "i didn't really pay attention so i don't know if he died once or not but if we put out after 4500 episodes",
    "start": "3150880",
    "end": "3158640"
  },
  {
    "text": "i was testing it and this one usually 90 at least it beats this map",
    "start": "3158640",
    "end": "3166160"
  },
  {
    "text": "without dying once yeah so in our version of the game also you have three lives so if you get hit by a ghost you",
    "start": "3166160",
    "end": "3171760"
  },
  {
    "text": "just go you go you go back to the starting position if you have any more lives left",
    "start": "3171760",
    "end": "3177839"
  },
  {
    "text": "uh yeah so this is mostly how it is it rushes for",
    "start": "3177839",
    "end": "3183440"
  },
  {
    "text": "the fruits then also another funny thing is that you can notice that",
    "start": "3183440",
    "end": "3190800"
  },
  {
    "text": "it dies now right now i'm going to show it again it dies there and what i have noticed",
    "start": "3191200",
    "end": "3198400"
  },
  {
    "text": "is that it is not necessarily because he can't get out of it but when he has finished one side of the",
    "start": "3198400",
    "end": "3206480"
  },
  {
    "text": "map he usually goes to the right first and then over to the left and then he finishes all on the left but you can notice that",
    "start": "3206480",
    "end": "3213440"
  },
  {
    "text": "on the right side here he has some coins left and he has learned that since we have a move penalty",
    "start": "3213440",
    "end": "3220880"
  },
  {
    "text": "um that walking all the way from the right now from the left side of the map to the",
    "start": "3220880",
    "end": "3226640"
  },
  {
    "text": "right side actually is a worse action than just dying here and then you because then you",
    "start": "3226640",
    "end": "3234880"
  },
  {
    "text": "spawn in the middle so you save all that moving time and then you run to take the rest of the coins sometimes he has to die but",
    "start": "3234880",
    "end": "3241599"
  },
  {
    "text": "i have definitely seen places where he could have lived but then he just suicides into into into a goal so that's",
    "start": "3241599",
    "end": "3249119"
  },
  {
    "text": "pretty pretty fun to see uh we also trained him on some other maps or pac menu as we",
    "start": "3249119",
    "end": "3257280"
  },
  {
    "text": "call him uh let's see here we're gonna put level three",
    "start": "3257280",
    "end": "3262480"
  },
  {
    "text": "in which is the probably the hardest map by far this one only trained on a",
    "start": "3262480",
    "end": "3269119"
  },
  {
    "text": "thousand thousand episodes but we'll we'll try with a hundred first and see what",
    "start": "3269119",
    "end": "3274880"
  },
  {
    "text": "happens i think this should work",
    "start": "3274880",
    "end": "3279838"
  },
  {
    "text": "nope it does not because that's not what it's called it's called model underscore level",
    "start": "3280319",
    "end": "3289119"
  },
  {
    "text": "three i underscore 100 all right this should work",
    "start": "3289680",
    "end": "3295599"
  },
  {
    "text": "so this is another map that we started experimenting experimenting on a little bit so i put in two ghosts here as well",
    "start": "3297359",
    "end": "3305280"
  },
  {
    "text": "um and only four fruits because i thought there was too many fruits on the previous map",
    "start": "3305280",
    "end": "3311359"
  },
  {
    "text": "so he can't just be like eternally invulnerable when he's running around",
    "start": "3311359",
    "end": "3316720"
  },
  {
    "text": "and we can see after a hundred hundred uh episodes it he's not doing too hot he can kind of",
    "start": "3316720",
    "end": "3325760"
  },
  {
    "text": "get some of the coins but yeah he can't even get all the fruits so",
    "start": "3325760",
    "end": "3332559"
  },
  {
    "text": "let's look at 500",
    "start": "3332559",
    "end": "3337680"
  },
  {
    "text": "episodes uh should probably be a little bit",
    "start": "3337920",
    "end": "3343680"
  },
  {
    "text": "better at least he rushes to the first and second fruit which makes the ghost run away kind of",
    "start": "3343680",
    "end": "3350880"
  },
  {
    "text": "then he runs through the third fruit and to the fourth fruit so he has he's learned that that the fruit fruits are really good but these are",
    "start": "3350880",
    "end": "3357280"
  },
  {
    "text": "also things that we have used to reward shaping right we haven't used a uniform",
    "start": "3357280",
    "end": "3363119"
  },
  {
    "text": "assignment scheme so it means that we give plus one for coin we give minus five for dying right",
    "start": "3363119",
    "end": "3368640"
  },
  {
    "text": "and these values there's no proof that the values that we have given this pacman is correct",
    "start": "3368640",
    "end": "3374400"
  },
  {
    "text": "those values can be in like you can try out different values all the time",
    "start": "3374400",
    "end": "3379520"
  },
  {
    "text": "and we have done that quite a bit and then let's look at the thousand one",
    "start": "3379520",
    "end": "3385440"
  },
  {
    "text": "so i was looking at the training i think on this map uh trained for not that long",
    "start": "3385440",
    "end": "3393440"
  },
  {
    "text": "uh but i kind of got discouraged a little bit because after a thousand episodes he doesn't",
    "start": "3393440",
    "end": "3399839"
  },
  {
    "text": "really learn that much he's in my opinion not even close to to",
    "start": "3399839",
    "end": "3405440"
  },
  {
    "text": "finishing this map there he dies once and then it dies twice",
    "start": "3405440",
    "end": "3410880"
  },
  {
    "text": "and then three times and if you compared to the previous map after a thousand episodes he could beat",
    "start": "3410880",
    "end": "3416319"
  },
  {
    "text": "it sometimes um yeah so definitely some improvements is needed for for this one it's also a",
    "start": "3416319",
    "end": "3422160"
  },
  {
    "text": "really hard one i think if the ghost is placed optimally i think maybe it's probably impossible for the",
    "start": "3422160",
    "end": "3428960"
  },
  {
    "text": "for the pac-man to win so i made another map",
    "start": "3428960",
    "end": "3433839"
  },
  {
    "text": "which i'm just going to show you guys which is a little bit easier and i trained for 4 000 iterations we",
    "start": "3434640",
    "end": "3441200"
  },
  {
    "text": "have one minute left so i'm gonna do this um",
    "start": "3441200",
    "end": "3446559"
  },
  {
    "text": "4 000 iterations uh did i do that correctly no i did not",
    "start": "3446559",
    "end": "3454799"
  },
  {
    "text": "like this where i removed a ghost so now there's only one ghost",
    "start": "3456640",
    "end": "3462079"
  },
  {
    "text": "and then i tried to see if you could beat this because this should be uh very beautiful for pac-man",
    "start": "3462079",
    "end": "3469359"
  },
  {
    "text": "and it ended up with i think this one trained for about 20 21 hours",
    "start": "3469359",
    "end": "3476640"
  },
  {
    "text": "um it's a little bit bigger state so the neural network is a little bit better bigger so it's slower than the other one",
    "start": "3476640",
    "end": "3488240"
  },
  {
    "text": "yeah so he gets closer but he also can't can't uh beat this one and get stuck",
    "start": "3488240",
    "end": "3495119"
  },
  {
    "text": "like it looks like he's pretty close but i mean okay now he's doing really well pak manu has a good day today not gonna",
    "start": "3495119",
    "end": "3502319"
  },
  {
    "text": "lie but but yeah that's about what we have time to show you guys",
    "start": "3502319",
    "end": "3508400"
  },
  {
    "text": "let's go back into the presentation",
    "start": "3508400",
    "end": "3516880"
  },
  {
    "text": "so some improvements to make decaying exploration already talked about that or actually",
    "start": "3516880",
    "end": "3522319"
  },
  {
    "text": "implemented it because it yielded quite big a bit better better results the second thing is that we use just a",
    "start": "3522319",
    "end": "3529359"
  },
  {
    "text": "vanilla feed four neural network and you should definitely use try to use at least convolutional layers",
    "start": "3529359",
    "end": "3534480"
  },
  {
    "text": "they're really good with the 2d and they're often used on images and",
    "start": "3534480",
    "end": "3541119"
  },
  {
    "text": "such and the pacman map is 2d so it would probably yield some better results",
    "start": "3541119",
    "end": "3546559"
  },
  {
    "text": "and there's obvious one more training time more memory more processing power i definitely think if i didn't stop the",
    "start": "3546559",
    "end": "3554160"
  },
  {
    "text": "the the level four the last one the big map with only one ghost if i didn't stop the training i",
    "start": "3554160",
    "end": "3560319"
  },
  {
    "text": "definitely think that he would have beaten it so we can just continue on",
    "start": "3560319",
    "end": "3565359"
  },
  {
    "text": "on the 4000th episode and then then continue training there maybe i should do that actually",
    "start": "3565359",
    "end": "3572078"
  },
  {
    "text": "another thing that could be nice to do is to add another neural network because",
    "start": "3572400",
    "end": "3577680"
  },
  {
    "text": "if you think about it the target for the neural network actually changes at as the agent learns in the beginning a",
    "start": "3577680",
    "end": "3583680"
  },
  {
    "text": "certain action has not the same value as after you have learned it for a little bit so it makes the neural network really",
    "start": "3583680",
    "end": "3590160"
  },
  {
    "text": "confused in the early game it can try to like predict uh predict the value x for instance well",
    "start": "3590160",
    "end": "3597200"
  },
  {
    "text": "later it should predict the value y and then it then the neural networks gets a little bit confused",
    "start": "3597200",
    "end": "3602640"
  },
  {
    "text": "are we predicting x or y and then lastly you can prioritize experience replay sampling instead of taking random",
    "start": "3602640",
    "end": "3609119"
  },
  {
    "text": "samples from the memory you can say like oh we're not doing so well in the early stages so maybe we should take experiences from",
    "start": "3609119",
    "end": "3615440"
  },
  {
    "text": "the early game and that's about it",
    "start": "3615440",
    "end": "3621359"
  },
  {
    "text": "if you want to check out the code it's available on this link you can take a picture of it and if you",
    "start": "3621359",
    "end": "3627359"
  },
  {
    "text": "have any questions you can go to slack yep i was just told that we'll get a few",
    "start": "3627359",
    "end": "3634079"
  },
  {
    "text": "more minutes to answer questions that you may ask on",
    "start": "3634079",
    "end": "3639119"
  },
  {
    "text": "slack conference room 1 i believe looks like it so we'll stick around for a couple more",
    "start": "3639119",
    "end": "3644240"
  },
  {
    "text": "minutes okay i think should we show some more stuff",
    "start": "3644240",
    "end": "3649440"
  },
  {
    "text": "maybe uh okay if you also have any questions and don't wanna",
    "start": "3649440",
    "end": "3655040"
  },
  {
    "text": "go on slack you know you can tweet us at the real manu gopi or real",
    "start": "3655040",
    "end": "3660240"
  },
  {
    "text": "malta or send us an email or or email or instagram or whatever see your instagram no don't send me on instagram",
    "start": "3660240",
    "end": "3671200"
  }
]
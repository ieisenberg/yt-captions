[
  {
    "start": "0",
    "end": "13000"
  },
  {
    "text": "various components are located together maybe for latency reasons maybe for resiliency reasons so we have a number",
    "start": "4759",
    "end": "13730"
  },
  {
    "start": "13000",
    "end": "13000"
  },
  {
    "text": "of approaches for scheduling pods and we'll cover these in a little bit more detail one out of time so we got node",
    "start": "13730",
    "end": "18859"
  },
  {
    "text": "selector I've got this pod affinity anti affinity these tents and toleration x'",
    "start": "18859",
    "end": "24310"
  },
  {
    "text": "we have ability to deport affinity and I'll explain what all of these are and a little bit and then finally the kind of",
    "start": "24310",
    "end": "31099"
  },
  {
    "text": "nuclear option of a custom scheduler so let's talk about the node selector first this is the most straightforward the",
    "start": "31099",
    "end": "37699"
  },
  {
    "text": "most basic version essentially all we're doing is we assign a label to a node so",
    "start": "37699",
    "end": "43070"
  },
  {
    "text": "incidentally on my screen shots if everywhere you see the K that's the alias for cube CTL I'm just lazy so I",
    "start": "43070",
    "end": "50120"
  },
  {
    "text": "don't Tucker out so what we do is we label a node with a key value pairs in this case I'm labeling this a KS node",
    "start": "50120",
    "end": "55820"
  },
  {
    "text": "with team equals foo and then in the pod spec for my deployment from a young in",
    "start": "55820",
    "end": "61489"
  },
  {
    "text": "my llamo what I'm doing is I just specify an old selector and I give that key value pay and this works well this",
    "start": "61489",
    "end": "68150"
  },
  {
    "text": "is quite straightforward but it's a little bit limited all you can do is select a node if that node doesn't exist",
    "start": "68150",
    "end": "75500"
  },
  {
    "text": "in your cluster then your pod won't be scheduled so this is where if you want a",
    "start": "75500",
    "end": "81020"
  },
  {
    "start": "81000",
    "end": "81000"
  },
  {
    "text": "bit more control we can move over to load affinity and ante Finity so this allows us to attract pods to nodes based",
    "start": "81020",
    "end": "88189"
  },
  {
    "text": "on their labels so initially the concept is similar except now what we're doing is we're not matching purely on just an",
    "start": "88189",
    "end": "94460"
  },
  {
    "text": "equality we've got a number of other conditions we can match on so now what we can do is we can choose to whether",
    "start": "94460",
    "end": "100189"
  },
  {
    "text": "match on in or not in obviously that's the ante finiti side same way the exists and does not exists the nice thing is",
    "start": "100189",
    "end": "110869"
  },
  {
    "text": "the the key difference with the node affinities we can be selective in how demanding we are so previously with a",
    "start": "110869",
    "end": "116270"
  },
  {
    "text": "node selector if that node without the label didn't exist your pod won't get scheduled now we can be a bit a little",
    "start": "116270",
    "end": "122240"
  },
  {
    "text": "bit more flexible so how do we do this or use a couple of catchy terms once",
    "start": "122240",
    "end": "130340"
  },
  {
    "text": "called required during scheduling ignored during execution try saying that a few times I spin a mouthful",
    "start": "130340",
    "end": "135910"
  },
  {
    "text": "essentially what this is doing is this is very similar to the note selector this is saying this is a hard requirement I want this label to",
    "start": "135910",
    "end": "143320"
  },
  {
    "text": "exist if not my pod won't get scheduled now alternatively what we can do is we",
    "start": "143320",
    "end": "148510"
  },
  {
    "text": "can say this is preferred so if preferred means ideally if there's a pot if there's a node there with that label",
    "start": "148510",
    "end": "154150"
  },
  {
    "text": "will use it if not we'll put it somewhere else if you're looking at this and it's quite long you wonder what this",
    "start": "154150",
    "end": "160240"
  },
  {
    "text": "ignored during execution bit means well the spec for this actually has a third option which isn't implemented yet which",
    "start": "160240",
    "end": "167530"
  },
  {
    "text": "says require doing scheduling required during execution so the key thing with these labels and these demands is",
    "start": "167530",
    "end": "174190"
  },
  {
    "text": "they're around the time when the pods being scheduled so if you add a label to a node one support is already on there",
    "start": "174190",
    "end": "180190"
  },
  {
    "text": "it won't get evicted it won't get kicked off that's what this third option was",
    "start": "180190",
    "end": "185230"
  },
  {
    "text": "potentially going to allow you to do and as you turned that it's not being implemented yet and now there's other ways you can do this as well which I'll",
    "start": "185230",
    "end": "192010"
  },
  {
    "text": "talk about in a second so we have a look at the the yam all the pod spec for this",
    "start": "192010",
    "end": "198670"
  },
  {
    "text": "it's a little bit more wordy so now obviously we've got this node the affinity section we've got that term",
    "start": "198670",
    "end": "205510"
  },
  {
    "text": "which we're saying is required and now we're matching so this is very similar to the node selector I'm achieving the",
    "start": "205510",
    "end": "211750"
  },
  {
    "text": "same thing obviously it's a little bit more verbose but it gives me more more power so I can specify multiple values",
    "start": "211750",
    "end": "217600"
  },
  {
    "text": "for example there if we look at the the preferred one so this is now saying",
    "start": "217600",
    "end": "223630"
  },
  {
    "text": "ideally looks very similar we've got a couple of extra term so obviously we've got this preferred then we've got this",
    "start": "223630",
    "end": "228850"
  },
  {
    "text": "weight and the weight is there because there can be multiple nodes which meet the requirement and the weight is used",
    "start": "228850",
    "end": "235000"
  },
  {
    "text": "to try and figure out which one to pick basically so in this example I'm using a label which is one of the defaults I",
    "start": "235000",
    "end": "241150"
  },
  {
    "text": "think on on aks it's just the instance type so for example I'm saying I want this pot to be on a TS TS 1 V 2 V M for",
    "start": "241150",
    "end": "249070"
  },
  {
    "text": "example so there's no definitive there they're quite good but what if we want",
    "start": "249070",
    "end": "254980"
  },
  {
    "text": "to have the ability to remove pods from a node if they don't match the requirements this is where we have the",
    "start": "254980",
    "end": "261900"
  },
  {
    "start": "261000",
    "end": "261000"
  },
  {
    "text": "the taints in Toleration concept so in this this approach allows you to repel",
    "start": "261900",
    "end": "267550"
  },
  {
    "text": "pods from a node based on tanks so what we do is we take two node and",
    "start": "267550",
    "end": "273310"
  },
  {
    "text": "then the pods tolerate that taint if you don't have a toleration you won't be scheduled on that node when you define a",
    "start": "273310",
    "end": "283629"
  },
  {
    "text": "taint and toleration there's three elements to it so we have a key and a value similar to the labels and then we",
    "start": "283629",
    "end": "289780"
  },
  {
    "text": "have the third option which is the effect so we have a choice of no schedule which the names just don't",
    "start": "289780",
    "end": "296020"
  },
  {
    "text": "schedule the pod prefer no schedule again obviously a software requirement and then no excu",
    "start": "296020",
    "end": "301389"
  },
  {
    "text": "so this time the no excu will actually evict pods which don't tolerate the",
    "start": "301389",
    "end": "306639"
  },
  {
    "text": "taint on a node and actually kubernetes does this itself it will taint nodes",
    "start": "306639",
    "end": "312729"
  },
  {
    "text": "based on certain issues that are arising in the cluster so if your nodes Orenda have disk space or memory kubernetes",
    "start": "312729",
    "end": "318789"
  },
  {
    "text": "will actually apply a taint to that node and that's how pods get potentially get",
    "start": "318789",
    "end": "324159"
  },
  {
    "text": "evicted from your cluster so yeah that",
    "start": "324159",
    "end": "330400"
  },
  {
    "text": "last point if we have a look at how we do this so this time now we're going to",
    "start": "330400",
    "end": "335979"
  },
  {
    "text": "use the cube CTO taint node command and we supply the key value keep a key name",
    "start": "335979",
    "end": "342370"
  },
  {
    "text": "value name and then the schedule once our node is tainted for example if I've got this deployment on three node",
    "start": "342370",
    "end": "347740"
  },
  {
    "text": "cluster without toleration what we're seeing is actually ordinarily we would",
    "start": "347740",
    "end": "355000"
  },
  {
    "text": "by default we would see the distribution of the pods across the nodes and we're not we're seeing two on one node one on",
    "start": "355000",
    "end": "361029"
  },
  {
    "text": "the other and not nothing's using that node zero it's what we now need to do is apply a toleration in our spec so now in",
    "start": "361029",
    "end": "368650"
  },
  {
    "text": "a pod spec what we can use we specify toleration we give it the same key value pay and then we say no schedule when we",
    "start": "368650",
    "end": "376900"
  },
  {
    "text": "apply that then our pod can basically tolerate that taint and it will be scheduled on that node if you're",
    "start": "376900",
    "end": "382479"
  },
  {
    "text": "wondering what this toleration seconds is I think this is a little bit confusing personally so if you don't",
    "start": "382479",
    "end": "388029"
  },
  {
    "text": "specify toleration seconds and you have a toleration on your pod when a node is",
    "start": "388029",
    "end": "394060"
  },
  {
    "text": "tainted the pod will carry on running we specify toleration seconds you're",
    "start": "394060",
    "end": "399520"
  },
  {
    "text": "basically giving that's how long the pod will carry on running before it gets gracefully evicted from the pod so",
    "start": "399520",
    "end": "404720"
  },
  {
    "text": "sounds a bit confusing because I'm tolerating the taint but I'm specifying seconds and then it's",
    "start": "404720",
    "end": "410000"
  },
  {
    "text": "getting kicked off but that's how that works so if we now look at the same deployment",
    "start": "410000",
    "end": "416090"
  },
  {
    "text": "this time with the Toleration for that taint we're now seeing equal distribution across the three nodes so",
    "start": "416090",
    "end": "422930"
  },
  {
    "text": "so far we've talked about basically picking a node for our deployment moving pods often when we have our applications",
    "start": "422930",
    "end": "431150"
  },
  {
    "text": "we need more control over where we deploy our application based on what else is running on that node so not just",
    "start": "431150",
    "end": "437180"
  },
  {
    "start": "432000",
    "end": "432000"
  },
  {
    "text": "the node itself but what's running on it and this is where inter pod affinity or anti Finity comes in often we just call",
    "start": "437180",
    "end": "443720"
  },
  {
    "text": "that pod affinity so this allows you to select no nodes based on what pods are running on it so why would we want this",
    "start": "443720",
    "end": "452900"
  },
  {
    "text": "so this is where we want to make sure that components of our architecture running together so let's say we want the cache to running alongside the",
    "start": "452900",
    "end": "458990"
  },
  {
    "text": "application or conversely we want to split things up so we want to ensure for",
    "start": "458990",
    "end": "464750"
  },
  {
    "text": "example that maybe multiple instances of our application are running across fault zones so that if one of the fault zones",
    "start": "464750",
    "end": "472310"
  },
  {
    "text": "one of the VMs goes down in a fault zone we don't lose the whole application we don't lose both instances of course",
    "start": "472310",
    "end": "479030"
  },
  {
    "text": "kubernetes will restore it but it takes a few seconds so we have similar",
    "start": "479030",
    "end": "487669"
  },
  {
    "text": "constructs around strictness so again very similar require doing scheduling ignoring execution we",
    "start": "487669",
    "end": "495260"
  },
  {
    "text": "have this new construct topology key so all the other labels they're to do with the pods the topology key this is really",
    "start": "495260",
    "end": "502580"
  },
  {
    "text": "confusing so hopefully the next few slides will will clarify a bit talk about what level of the architecture of",
    "start": "502580",
    "end": "507710"
  },
  {
    "text": "the infrastructure this anti Finity is applied so typically you might apply it to hostname so you're saying I don't",
    "start": "507710",
    "end": "514280"
  },
  {
    "text": "want these pods on same machine but you can just as well specify availability zones or you know racks or fault domains",
    "start": "514280",
    "end": "522700"
  },
  {
    "text": "you don't have to be it doesn't have to be down to a single machine what you're doing is you're separating out across",
    "start": "522700",
    "end": "527870"
  },
  {
    "text": "different zones that label as I'll show you in a second is actually on the on",
    "start": "527870",
    "end": "533690"
  },
  {
    "text": "the node itself so let's have a look one of these and hopefully becoming quite familiar",
    "start": "533690",
    "end": "539630"
  },
  {
    "text": "now so same-same bits there and then this topology key so just to reiterate these matching these labels are being",
    "start": "539630",
    "end": "546860"
  },
  {
    "text": "matched on the pods this topology key is matching on the node so this this is a node label whereas these are looking for",
    "start": "546860",
    "end": "554149"
  },
  {
    "text": "topology sorry looking for keys labels within your pods so let's try and",
    "start": "554149",
    "end": "560810"
  },
  {
    "text": "visualize this a little bit so I've got this application I've got three node cluster and I've got three replicas of",
    "start": "560810",
    "end": "567170"
  },
  {
    "text": "each of this web and what I want to do is I want you to be evenly distributed I want webinar cache in each one of",
    "start": "567170",
    "end": "572509"
  },
  {
    "text": "these nodes I don't want it to be anywhere else now we could take that we could take a chance often communities does try and",
    "start": "572509",
    "end": "578660"
  },
  {
    "text": "balance things out obviously in this example there's nothing else running on the cluster there may be other applications running so we want to make",
    "start": "578660",
    "end": "585290"
  },
  {
    "text": "sure that we are taking control of that so how do how would we do this using taints sorry pod affinity what we do is",
    "start": "585290",
    "end": "593360"
  },
  {
    "text": "for our web component what we do is we say we want pod affinity for the cache component and we marked as a preferred",
    "start": "593360",
    "end": "600649"
  },
  {
    "text": "one because the cache may not be running it those pods might not be running yet but we want anti affinity against the",
    "start": "600649",
    "end": "607310"
  },
  {
    "text": "web components so that's going to repel the pods to make sure they're going different nodes then the affinity we'll",
    "start": "607310",
    "end": "613009"
  },
  {
    "text": "make sure they get attracted and we're using the host name in this case because we've got three three hosts so when I",
    "start": "613009",
    "end": "619339"
  },
  {
    "text": "deploy that give notice to basically deploy three instances across the three nodes and now it's time to deploy the",
    "start": "619339",
    "end": "625189"
  },
  {
    "text": "cache and again similar concept this time with the cache what we're going to do is we're going to do affinity we're",
    "start": "625189",
    "end": "631009"
  },
  {
    "text": "going to attract to the web pods well we're going to anti affinity the cache pods and by doing that what we're doing",
    "start": "631009",
    "end": "637699"
  },
  {
    "text": "is we're repelling the cache from each other to put them on individual nodes but we are tracting the web what we do",
    "start": "637699",
    "end": "645050"
  },
  {
    "text": "that we get and that we expect so obvious you a better idea of how to how",
    "start": "645050",
    "end": "652699"
  },
  {
    "text": "to control that let's have a quick look at Yahoo for hopefully people can see that the back so this is that example",
    "start": "652699",
    "end": "660290"
  },
  {
    "text": "there just to show you quickly so we've got the pod anti Finity and then we've",
    "start": "660290",
    "end": "667069"
  },
  {
    "text": "got the pod affinity you can specify multiple things here that's what we're doing so here we're matching for",
    "start": "667069",
    "end": "672130"
  },
  {
    "text": "Component web and then we're doing anti Finity for the cache sorry the other way around and then for the cache rather",
    "start": "672130",
    "end": "680620"
  },
  {
    "text": "right around for the cache we are doing anti Finiti for the other cache pods and",
    "start": "680620",
    "end": "686800"
  },
  {
    "text": "we are doing affinity to the web component now when we deploy that what",
    "start": "686800",
    "end": "692080"
  },
  {
    "text": "we see is we get that the behavior we expected so now we've got three node cluster and we've got each component is",
    "start": "692080",
    "end": "699480"
  },
  {
    "text": "distributed evenly and paired up across those nodes so as you can see there's",
    "start": "699480",
    "end": "705520"
  },
  {
    "text": "quite a lot of capability within the kind of built-in options in kubernetes for controlling the pod kind of",
    "start": "705520",
    "end": "711250"
  },
  {
    "text": "distribution the pod scheduling if none of these options suffice you have a kind",
    "start": "711250",
    "end": "716950"
  },
  {
    "text": "of nuclear option which is to write a custom scheduler you can write the schedule in any language you want it",
    "start": "716950",
    "end": "724000"
  },
  {
    "text": "just needs to be up to access the API server I say just that's quite tricky that's quite hard but broadly speaking",
    "start": "724000",
    "end": "730000"
  },
  {
    "text": "you just need to access the API server and then what you do is in your pod spec you can actually specify the scheduler",
    "start": "730000",
    "end": "736240"
  },
  {
    "text": "name see you'll specify the scheduler name that'll be the name of the deployment and cubanía so basically so",
    "start": "736240",
    "end": "744040"
  },
  {
    "text": "there's an example in the documentation or sending on a blog post where somebody's written a using bash so randomly assign the pods to any of the",
    "start": "744040",
    "end": "751240"
  },
  {
    "text": "nodes hopefully you don't need to do that okay so that's round pod placements",
    "start": "751240",
    "end": "761230"
  },
  {
    "text": "let's move on to taking a little bit more control so what if I want to have",
    "start": "761230",
    "end": "768070"
  },
  {
    "text": "control of the resources I'm deploying maybe I want to apply some custom",
    "start": "768070",
    "end": "773260"
  },
  {
    "text": "policies you know saying that when you deploy things you must have certain labels you must not use certain",
    "start": "773260",
    "end": "779170"
  },
  {
    "text": "resources and maybe I want to inject some additional logic when I do a",
    "start": "779170",
    "end": "785440"
  },
  {
    "text": "deployment this is where you can start using things that admission controllers so admission controllers are basically",
    "start": "785440",
    "end": "792550"
  },
  {
    "start": "788000",
    "end": "788000"
  },
  {
    "text": "is basically code that intersects the intercepts the API requests and allows you to run some logic before that",
    "start": "792550",
    "end": "798520"
  },
  {
    "text": "request is actually persisted in that CD there's kind of three variants or",
    "start": "798520",
    "end": "804400"
  },
  {
    "text": "there's two really you can it can be mutating admission controller which modifies objects and can create",
    "start": "804400",
    "end": "811000"
  },
  {
    "text": "new objects can be validating one which is its job is just to inspect and basically reject something they can't",
    "start": "811000",
    "end": "817900"
  },
  {
    "text": "mutate the state and there can be both a mutating and validating these things are",
    "start": "817900",
    "end": "826360"
  },
  {
    "text": "basically built in the cube API server so they can be enabled or disabled in the cube API server now if you're",
    "start": "826360",
    "end": "831820"
  },
  {
    "text": "running in a public cloud you running a managed kubernetes service which is what I think a lot of people are doing now you have limited options in this you",
    "start": "831820",
    "end": "838990"
  },
  {
    "text": "don't have control of the cube API server you can't actually choose what you run so you'd argue these a little",
    "start": "838990",
    "end": "846400"
  },
  {
    "text": "bit limited and they're also compiled into the API server binary so if you want you to create your own that's not",
    "start": "846400",
    "end": "851680"
  },
  {
    "text": "so straightforward well look at how we can work around there in a second so there's a number of",
    "start": "851680",
    "end": "856780"
  },
  {
    "text": "built-in ones I'm not going to talk talk about these in great detail I'm not gonna talk about at all other than two",
    "start": "856780",
    "end": "862510"
  },
  {
    "text": "of them let's have a quick look where they're sitting the lifecycle of the API so I do an API request it gets there",
    "start": "862510",
    "end": "869950"
  },
  {
    "start": "866000",
    "end": "866000"
  },
  {
    "text": "hits the HTTP handler goes through some authentication authorization then we run",
    "start": "869950",
    "end": "876910"
  },
  {
    "text": "the mutating admission controllers so these things are mutating the state potentially mutating the state of the",
    "start": "876910",
    "end": "882010"
  },
  {
    "text": "resource I'm just sending through the request or maybe I'm creating a new resource then we have some object schema",
    "start": "882010",
    "end": "889750"
  },
  {
    "text": "validation so you can hopefully understand that we do the schema validation after we've done the mutation",
    "start": "889750",
    "end": "895200"
  },
  {
    "text": "then we run the validation controllers again we want to run the validation controllers after the mutations happen",
    "start": "895200",
    "end": "901000"
  },
  {
    "text": "not before it's obviously we can bypass validation otherwise then this request is persisted into EDD CD and once I",
    "start": "901000",
    "end": "908410"
  },
  {
    "text": "request is persistent Nate CD then another controller will pick up that request so if it's a deployment the deployment controller picks that up goes",
    "start": "908410",
    "end": "915340"
  },
  {
    "text": "and does what he needs to do within the mutation mutating and validating and",
    "start": "915340",
    "end": "921730"
  },
  {
    "text": "wishing drawers there's two special controllers and they're the mutating admission webhook controllers and",
    "start": "921730",
    "end": "927480"
  },
  {
    "text": "they're the ones that allow us to add some logic without needing to write a whole admission controller so what's",
    "start": "927480",
    "end": "935170"
  },
  {
    "text": "cool is we've got these two web hooks mutating in Mission web hook and validating admission hook and as the name suggested mutating",
    "start": "935170",
    "end": "942819"
  },
  {
    "text": "one allows us to mutate resources or create brand-new ones or the validating one allows us to block the resource",
    "start": "942819",
    "end": "948699"
  },
  {
    "text": "creation because their web hooks they can invoke HTTP callback so",
    "start": "948699",
    "end": "954309"
  },
  {
    "text": "industry-standard stuff really and the nice thing is a logic for this doesn't need to be compiled into the API server",
    "start": "954309",
    "end": "961230"
  },
  {
    "text": "and the logic doesn't even need to be in the cluster you can be hosted outside of the cluster as well now if you're doing",
    "start": "961230",
    "end": "967089"
  },
  {
    "text": "mutations again you need to be able to authenticate against the server the API server so that can be a bit tricky if",
    "start": "967089",
    "end": "973029"
  },
  {
    "text": "you're outside of the cluster buts only validation doesn't need to be so let's take a quick look at these web hooks and",
    "start": "973029",
    "end": "981309"
  },
  {
    "text": "see how they work I have got a web hook",
    "start": "981309",
    "end": "992290"
  },
  {
    "text": "here so hopefully everyone can see that let's just make that bit bigger you'll see that okay at the back one more step",
    "start": "992290",
    "end": "1001519"
  },
  {
    "text": "we are so this is the the configuration for web hook so what we can do is up",
    "start": "1001519",
    "end": "1010079"
  },
  {
    "text": "here the resource Carney's is web hook configuration we'll keep that out of the way we've got to give it a name the key",
    "start": "1010079",
    "end": "1016199"
  },
  {
    "text": "bit really is this is this API group so what I'm saying here is which API group am i operating on this Web hook so this",
    "start": "1016199",
    "end": "1022470"
  },
  {
    "text": "case is v1 create operation on pots this feature policy basically says what",
    "start": "1022470",
    "end": "1028199"
  },
  {
    "text": "happens if the web hook technically fails in this case I'm saying it should fail you should treat it as a failure and then the final step is the actual",
    "start": "1028199",
    "end": "1035100"
  },
  {
    "text": "web book itself and in this case I'm using Azure functions for the web hook so it's outside of the cluster and then",
    "start": "1035100",
    "end": "1042870"
  },
  {
    "text": "depending on you need to have certificates that are potentially for you doing this internally luckily this one works without that that's not",
    "start": "1042870",
    "end": "1048690"
  },
  {
    "text": "production ready configuration so please don't use it like that so now I've written the the web hook itself let me",
    "start": "1048690",
    "end": "1055679"
  },
  {
    "text": "show you I can show you that in the azure function pool but I'll show you here it's a bit easier to see so this is a asha function nodejs as a function",
    "start": "1055679",
    "end": "1065730"
  },
  {
    "text": "hopefully people have reasonably familiar with it there's not too much code in here so we can get the request",
    "start": "1065730",
    "end": "1071580"
  },
  {
    "text": "body and we're going to essentially pause at the spec for the containers and then in this example here",
    "start": "1071580",
    "end": "1077190"
  },
  {
    "text": "what I'm doing is I'm looking for an image name so I'm saying if that image is this particular one I'm gonna reject",
    "start": "1077190",
    "end": "1083340"
  },
  {
    "text": "this I'm gonna say this isn't a valid not allowed to deploy this so the key is really descending this admission",
    "start": "1083340",
    "end": "1089610"
  },
  {
    "text": "response back so in this case I'm sending you back as a failure and it's wrapped up in this admission review and",
    "start": "1089610",
    "end": "1099630"
  },
  {
    "text": "then the rest of this just standard HTTP so we send that back so let's see if I can get this demo to work so I have this",
    "start": "1099630",
    "end": "1108870"
  },
  {
    "text": "portal I'm just gonna refresh it so hopefully loads so this is that same code running in Azure function on the",
    "start": "1108870",
    "end": "1114330"
  },
  {
    "text": "portal",
    "start": "1114330",
    "end": "1116720"
  },
  {
    "text": "sometimes the logs the the I'm going to tempt fate in how the demos tended to",
    "start": "1120530",
    "end": "1125610"
  },
  {
    "text": "have worked but the logs don't always show but we'll see if I've just tempted",
    "start": "1125610",
    "end": "1130710"
  },
  {
    "text": "fate now let's run that okay so we see",
    "start": "1130710",
    "end": "1136170"
  },
  {
    "text": "this error that's nothing to worry about it's basically some initial validation failing so I'm going to clear that I'm",
    "start": "1136170",
    "end": "1142440"
  },
  {
    "text": "going to come over to the deployment so I've got two deployments I've got this",
    "start": "1142440",
    "end": "1148620"
  },
  {
    "text": "v1 and you can see that's using the image which is going to be rejected then",
    "start": "1148620",
    "end": "1153750"
  },
  {
    "text": "I've got a v2 which is using v2 of the image which should hopes we should be",
    "start": "1153750",
    "end": "1158940"
  },
  {
    "text": "successful so if I come over to",
    "start": "1158940",
    "end": "1165320"
  },
  {
    "text": "I just need to set my context to the I'm wearing this on the docker for desktop",
    "start": "1167990",
    "end": "1178210"
  },
  {
    "text": "so there should be no deployments the moment okay so if I now apply v1 oops",
    "start": "1183490",
    "end": "1195159"
  },
  {
    "text": "yeah Mille find out okay get pods will",
    "start": "1195159",
    "end": "1202070"
  },
  {
    "text": "see no resources fan no pods found I come over to my portal where is it gone",
    "start": "1202070",
    "end": "1210340"
  },
  {
    "text": "there so we can see hopefully let's see if I can zoom in you can see whoa",
    "start": "1210340",
    "end": "1218119"
  },
  {
    "text": "I was a little bit too far yeah this is good",
    "start": "1218119",
    "end": "1224139"
  },
  {
    "text": "hopefully you can see down here it's run the run the validation and it said it's",
    "start": "1224139",
    "end": "1230179"
  },
  {
    "text": "bad image and returned successfully we can see I just escaped out of that if I",
    "start": "1230179",
    "end": "1236179"
  },
  {
    "text": "come over to you here if I do Q okay get events we should also hopefully see that",
    "start": "1236179",
    "end": "1243080"
  },
  {
    "text": "yeah so we can see Eric rating admission webhook denied the request hello world is using a bad image so that failed that",
    "start": "1243080",
    "end": "1251659"
  },
  {
    "text": "request just to show you that it's not failing on everything if I now deploy",
    "start": "1251659",
    "end": "1256759"
  },
  {
    "text": "the v2 pods we should see the pods",
    "start": "1256759",
    "end": "1264980"
  },
  {
    "text": "running on that so whoops there so it's just that so just a really quick demo",
    "start": "1264980",
    "end": "1270350"
  },
  {
    "text": "just to give you an idea of how we can use the admission control is let's go back to the slides and carry on",
    "start": "1270350",
    "end": "1281289"
  },
  {
    "text": "so we've seen these admission books give us the ability to kind of take some control what we want even more control",
    "start": "1293480",
    "end": "1300770"
  },
  {
    "text": "what we want to build abstractions on top of the kubernetes resources so much",
    "start": "1300770",
    "end": "1305850"
  },
  {
    "text": "like kubernetes as itself with deployments which are an abstraction on top of you know replica sets and pods",
    "start": "1305850",
    "end": "1312200"
  },
  {
    "text": "what if we want to create entirely new resources within kubernetes we've when a deploy are going to domain-specific",
    "start": "1312200",
    "end": "1318290"
  },
  {
    "text": "components for example and we want to be able to use cube CTL to manage them this",
    "start": "1318290",
    "end": "1326370"
  },
  {
    "text": "is where we can have it we have a number of options really and how we can extend communities one is to write a custom extension API server this is a lot of",
    "start": "1326370",
    "end": "1333720"
  },
  {
    "text": "work you have to write the whole API server you have to write the persistence layer for the the API server another",
    "start": "1333720",
    "end": "1339929"
  },
  {
    "text": "option is to use custom resource definitions this is probably thing most people have heard about certainly the",
    "start": "1339929",
    "end": "1345059"
  },
  {
    "text": "the area of the hot topic area within Cuba Nettie's now we have these custom controllers now often custom resource",
    "start": "1345059",
    "end": "1352200"
  },
  {
    "text": "definitions and custom controllers used interchangeably and technically they're not so talking specific about custom",
    "start": "1352200",
    "end": "1359610"
  },
  {
    "start": "1359000",
    "end": "1359000"
  },
  {
    "text": "resource definition CR DS this is essentially a new resource type that you can put alongside the existing resources",
    "start": "1359610",
    "end": "1365460"
  },
  {
    "text": "so just to clarify for those who not necessarily familiar with the term the resources are things like pods the",
    "start": "1365460",
    "end": "1371190"
  },
  {
    "text": "deployments you know replica sets config map secrets what we can then do is once",
    "start": "1371190",
    "end": "1378210"
  },
  {
    "text": "we create these custom resources we can use keep CTL to create and delete and interact with them just like there were",
    "start": "1378210",
    "end": "1383610"
  },
  {
    "text": "you know native resources and these are stored within that CD so we don't have",
    "start": "1383610",
    "end": "1389490"
  },
  {
    "text": "to worry about our own custom you know storage for storing these resources but",
    "start": "1389490",
    "end": "1395309"
  },
  {
    "text": "they're pretty useless without a controller so we often people talk about CR DS what they really talking about is",
    "start": "1395309",
    "end": "1400980"
  },
  {
    "text": "operators I'll get onto that in a second so let's have a look at how we create a",
    "start": "1400980",
    "end": "1406050"
  },
  {
    "text": "custom resource definition again this is actually not too tricky because it doesn't do a huge amount so here I've",
    "start": "1406050",
    "end": "1412380"
  },
  {
    "text": "got a custom resource definition resource coined I have to give it an API group so this will typically be your",
    "start": "1412380",
    "end": "1418500"
  },
  {
    "text": "company name wherever we version it and then we can scope it so we can scope a resource to be cluster wide or namespace",
    "start": "1418500",
    "end": "1424710"
  },
  {
    "text": "scoped and then we can define the you know essentially how to interact with it so we it's a foo as the singular it's foods",
    "start": "1424710",
    "end": "1432020"
  },
  {
    "text": "as plural and I've even got a short name FL now what I can do is I can create a",
    "start": "1432020",
    "end": "1437990"
  },
  {
    "text": "custom resource up and create this foo object so much like anything else now I'm creating against the API version",
    "start": "1437990",
    "end": "1443480"
  },
  {
    "start": "1438000",
    "end": "1438000"
  },
  {
    "text": "I've specified creating a full resource and I can then write pretty much",
    "start": "1443480",
    "end": "1448670"
  },
  {
    "text": "wherever I want down here in this Bank as I said with this it's actually",
    "start": "1448670",
    "end": "1453890"
  },
  {
    "text": "doesn't do a huge amount so this quick kind of video will show we can create a custom resource that's created so what",
    "start": "1453890",
    "end": "1461150"
  },
  {
    "text": "we can now do is deploy an instance of our custom resource if I can type and",
    "start": "1461150",
    "end": "1470090"
  },
  {
    "text": "now what we can do is we can use keep CTR when you do get food that's pretty cool how can you get a 4 because I've",
    "start": "1470090",
    "end": "1476240"
  },
  {
    "text": "got a short name for it and then I can do delete therefore that's about it",
    "start": "1476240",
    "end": "1481430"
  },
  {
    "text": "that's all I can do there's not there's nothing else happening here because all I've done is basically persisted this object in my database so to add the",
    "start": "1481430",
    "end": "1490010"
  },
  {
    "text": "logic you need custom controllers the interesting with custom controllers is",
    "start": "1490010",
    "end": "1495050"
  },
  {
    "start": "1492000",
    "end": "1492000"
  },
  {
    "text": "they don't have to be only on custom resources you can write a custom controller to operate on any of the existing resources as I said they often",
    "start": "1495050",
    "end": "1504200"
  },
  {
    "text": "paired with CR these custom resource definitions because you want to add behavior you don't just want to store that object to the database and retrieve",
    "start": "1504200",
    "end": "1511370"
  },
  {
    "text": "it you want to do a bit more bit more than that typically they're implemented and go I'm not sure if they have to be",
    "start": "1511370",
    "end": "1517610"
  },
  {
    "text": "but they use the go client library to access the API quite low level so you",
    "start": "1517610",
    "end": "1524090"
  },
  {
    "text": "often see them written in go and you often see the term operator mentioned",
    "start": "1524090",
    "end": "1529310"
  },
  {
    "text": "and I guess informally the term operator refers to the CID plus the custom controller now again hopefully not",
    "start": "1529310",
    "end": "1537980"
  },
  {
    "text": "having to write these yourself there are actually a large number of them already out there most of the big companies",
    "start": "1537980",
    "end": "1544010"
  },
  {
    "text": "who've got a need to do it have created them so for example AWA has AWS has",
    "start": "1544010",
    "end": "1550030"
  },
  {
    "text": "these operators which allow you to provision AWS resources as part of cuba Nettie's deployment now creating going",
    "start": "1550030",
    "end": "1558410"
  },
  {
    "text": "to details on how we create an operator I have we create a custom controller is beyond the scope of this talk really if you're interested",
    "start": "1558410",
    "end": "1565610"
  },
  {
    "text": "there's actually I would recommend going on a workshop I've been on a workshop that's really useful and there's also",
    "start": "1565610",
    "end": "1572450"
  },
  {
    "text": "the core OS team released this operator framework which allows you to kind of help you but it's still non-trivial",
    "start": "1572450",
    "end": "1578570"
  },
  {
    "text": "tasks if you if you really want to extend communities you've got to understand you know there's got to be a",
    "start": "1578570",
    "end": "1583940"
  },
  {
    "text": "good driver for it not just because it's cool to do okay I'm going to have a",
    "start": "1583940",
    "end": "1589340"
  },
  {
    "text": "crunching gear change now so we've talked about kind of positioning pods I want to talk a little bit about scaling",
    "start": "1589340",
    "end": "1595700"
  },
  {
    "text": "applications and in particular one area of this so when we look at how we scale applications at the moment we've got the",
    "start": "1595700",
    "end": "1601780"
  },
  {
    "start": "1599000",
    "end": "1599000"
  },
  {
    "text": "horizontal pod or two scalars probably the component most people are familiar with it's oddly fairly basic component",
    "start": "1601780",
    "end": "1608180"
  },
  {
    "text": "to understand and what that lets you do is it lets you scale your number of pods of your application based on metrics the",
    "start": "1608180",
    "end": "1614990"
  },
  {
    "text": "standard product or scaler does it based on memory in CPU and then the v2 pod autoscaler allows you to do custom",
    "start": "1614990",
    "end": "1622310"
  },
  {
    "text": "metrics it's a lot more powerful and that's pretty cool but you can only scale your pods up to",
    "start": "1622310",
    "end": "1629090"
  },
  {
    "text": "the capacity of your cluster so if we want to scale beyond that we have the cluster water scaler and a cluster or",
    "start": "1629090",
    "end": "1636110"
  },
  {
    "text": "two scalar just to differentiate that from the auto scaling that you may get",
    "start": "1636110",
    "end": "1641180"
  },
  {
    "text": "from a cloud provider which is typically based on CPU or queue lengths the cluster autoscaler looks at pods that",
    "start": "1641180",
    "end": "1646700"
  },
  {
    "text": "are waiting to be scheduled so if their pods that can't be scheduled because there's no enough resource that will then trigger a scaling of the cluster",
    "start": "1646700",
    "end": "1653240"
  },
  {
    "text": "itself how that scaling happens depends on your cloud provider but obviously",
    "start": "1653240",
    "end": "1659360"
  },
  {
    "text": "scaling a cluster is not something that happens very quickly it can take minutes maybe it takes two or three minutes",
    "start": "1659360",
    "end": "1665330"
  },
  {
    "text": "maybe takes five six seven minutes we imagine going to spin up an EVM go to boot it up you've got an bringing into",
    "start": "1665330",
    "end": "1671120"
  },
  {
    "text": "the cluster then make it available what if your load is a lot spicier than that so this is where this virtual Kubler",
    "start": "1671120",
    "end": "1678620"
  },
  {
    "text": "project comes in so virtual cubelet was a project that was created by the dais",
    "start": "1678620",
    "end": "1683840"
  },
  {
    "text": "team which is now the Microsoft team who work on the kubernetes area and essentially what it is is it's a",
    "start": "1683840",
    "end": "1690020"
  },
  {
    "text": "component that allows you to connect external compute resources into your cluster and make it look like an ode so you interact with this",
    "start": "1690020",
    "end": "1697820"
  },
  {
    "text": "computer through the familiar kubernetes api but it's actually running outside of your cluster somewhere else we take a",
    "start": "1697820",
    "end": "1704809"
  },
  {
    "text": "look at how this how this works hopefully that's quite clear so what",
    "start": "1704809",
    "end": "1709940"
  },
  {
    "text": "we've got here is I've got my kubernetes cluster I've got three nodes within there that could be bare-metal it could be virtual machines and when I deploy",
    "start": "1709940",
    "end": "1716059"
  },
  {
    "text": "this virtual Kubler it creates a further node in my cluster what's called a",
    "start": "1716059",
    "end": "1721160"
  },
  {
    "text": "virtual node and that node implements the API is that kubernetes is expecting",
    "start": "1721160",
    "end": "1726530"
  },
  {
    "text": "four nodes and for dealing with pods but the underlying compute is somewhere else so kubernetes easy has another node we",
    "start": "1726530",
    "end": "1734210"
  },
  {
    "text": "can deploy resource system we can deploy pods to it but they're running somewhere else there are a number of",
    "start": "1734210",
    "end": "1740750"
  },
  {
    "text": "implementations of this virtual cubelet no surprise really the first one they did was the Azure container instances so",
    "start": "1740750",
    "end": "1747800"
  },
  {
    "text": "as your container instances for those who aren't familiar is kind of Microsoft's ashes serverless container",
    "start": "1747800",
    "end": "1753740"
  },
  {
    "text": "platform so allows you to spin up containers onto a CI without having to provision any VMs or anything else",
    "start": "1753740",
    "end": "1760190"
  },
  {
    "text": "beforehand you pay per second where the containers are running as soon as you shut them down you stop paying for them",
    "start": "1760190",
    "end": "1765790"
  },
  {
    "text": "AWS for gates very similar a Duras equivalent and then the implementations of this for nomad service fabric mesh",
    "start": "1765790",
    "end": "1773090"
  },
  {
    "text": "IOT and then many others as well the virtual Kuebler project has been donated at CN CF it's now an incubator project",
    "start": "1773090",
    "end": "1779360"
  },
  {
    "text": "as part of CN CF so where this becomes quite interesting is when we want to",
    "start": "1779360",
    "end": "1785900"
  },
  {
    "text": "handle some spike in our load and we want to potentially use this instead of",
    "start": "1785900",
    "end": "1791870"
  },
  {
    "text": "relying on a cluster autoscaler so imagine I've got this cluster and I'm kind of managing them my load and then",
    "start": "1791870",
    "end": "1798440"
  },
  {
    "text": "suddenly I get a spike in traffic what I can do is use the virtual Kuebler which",
    "start": "1798440",
    "end": "1803480"
  },
  {
    "text": "is actually it's probably worth clarifying the virtual cube is a project and then implementation of that is a",
    "start": "1803480",
    "end": "1809150"
  },
  {
    "text": "virtual node so often those two terms are probably cool a bit confusing so",
    "start": "1809150",
    "end": "1814760"
  },
  {
    "text": "what we can do is by having the virtual know they powered by the virtual cubelet we can spin additional containers onto a",
    "start": "1814760",
    "end": "1821600"
  },
  {
    "text": "CI to handle that spike in load and while our clusters you know potentially",
    "start": "1821600",
    "end": "1826850"
  },
  {
    "text": "auto-scaling in the background we were able to handle the traffic once our clusters up to scale we can start",
    "start": "1826850",
    "end": "1833239"
  },
  {
    "text": "shedding the load off the ACI we stopped paying for that at that point and we are",
    "start": "1833239",
    "end": "1838419"
  },
  {
    "text": "happy again the virtual node is in a KS is built into a case now it's in public",
    "start": "1838419",
    "end": "1844940"
  },
  {
    "start": "1842000",
    "end": "1842000"
  },
  {
    "text": "preview so it was in private preview up till recently if you're creating a new cluster it's just one option now down",
    "start": "1844940",
    "end": "1850789"
  },
  {
    "text": "here just enable this option so let's",
    "start": "1850789",
    "end": "1856220"
  },
  {
    "text": "have a look at that virtual node and scaling just come over here so I'm just",
    "start": "1856220",
    "end": "1873409"
  },
  {
    "text": "going to switch clusters",
    "start": "1873409",
    "end": "1876489"
  },
  {
    "text": "oops I can't type because everyone's watching so get notes so what we can see",
    "start": "1883600",
    "end": "1895940"
  },
  {
    "text": "there just try and make that okay so",
    "start": "1895940",
    "end": "1904670"
  },
  {
    "text": "what we can see is I've got three nodes standard nodes in my cluster and then I've got this fourth virtual no this is",
    "start": "1904670",
    "end": "1910730"
  },
  {
    "text": "the virtual node I was added by taking the option so this is a virtual cubelet powered node if I have a look at that",
    "start": "1910730",
    "end": "1918080"
  },
  {
    "text": "node she is grabbed",
    "start": "1918080",
    "end": "1922330"
  },
  {
    "text": "let's have a look at this ripe",
    "start": "1926950",
    "end": "1935908"
  },
  {
    "text": "so we see it looks like any other note we've got these labels only one of the labels says it's a virtual cubelet and",
    "start": "1941460",
    "end": "1947340"
  },
  {
    "text": "then the bit that's probably important to mention is it's painted so kind of coming back to the concepts we talked",
    "start": "1947340",
    "end": "1952950"
  },
  {
    "text": "about earlier we've got a taint on it so what we're saying is that unless you",
    "start": "1952950",
    "end": "1958320"
  },
  {
    "text": "tolerate this taint you're not going to be scheduled on this and that's what we want this is a virtual note",
    "start": "1958320",
    "end": "1964470"
  },
  {
    "text": "we've got physical nodes in our cluster already physical or virtual machines y-you know we don't necessarily want",
    "start": "1964470",
    "end": "1970380"
  },
  {
    "text": "plots to be deployed on there for no reason we want those you know only if there's a need so let's say we have a",
    "start": "1970380",
    "end": "1978840"
  },
  {
    "text": "need so what we can do is we've got I've got a deployment running actually just play this so I've got this online shop",
    "start": "1978840",
    "end": "1988740"
  },
  {
    "text": "deployed as few other things which just ignore for now we've got this online shop here and it's running at the moment",
    "start": "1988740",
    "end": "1996570"
  },
  {
    "text": "and if I do find it get wide we should",
    "start": "1996570",
    "end": "2004190"
  },
  {
    "text": "see so it's wrapped around a little bit so it's maybe not so easy to read but it's running on the AKS no destroying on",
    "start": "2004190",
    "end": "2010910"
  },
  {
    "text": "the agent node now if I look at the llamó for this so let's flip over and",
    "start": "2010910",
    "end": "2017480"
  },
  {
    "text": "have a look at that this is the yeah Mille for that and what you can see is",
    "start": "2017480",
    "end": "2022880"
  },
  {
    "text": "I've got two components that we've talked about before so I've gone node anti affinity here that's what I'm",
    "start": "2022880",
    "end": "2029930"
  },
  {
    "text": "saying is match by the way so here we",
    "start": "2029930",
    "end": "2038660"
  },
  {
    "text": "are we're saying match it when it's not in the virtual queue blue so this is basically saying don't schedule it on",
    "start": "2038660",
    "end": "2044150"
  },
  {
    "text": "the virtual Kubler but it's a preferred so we were saying prefer not to schedule in the virtual Kubler but at the same",
    "start": "2044150",
    "end": "2050540"
  },
  {
    "text": "time we are tolerating the taint that's on the virtual Kubler so what this will do is it will say by default I'm not",
    "start": "2050540",
    "end": "2057620"
  },
  {
    "text": "going to deploy to the virtual Kubler but I can if I need to that can if I",
    "start": "2057620",
    "end": "2063830"
  },
  {
    "text": "need to maybe when you've got a sudden spike in traffic so let's see if we can show that so",
    "start": "2063830",
    "end": "2071710"
  },
  {
    "text": "if I got to juggle a few windows in a house let's see fun yet this right and not that one just kind of to reconnect",
    "start": "2071710",
    "end": "2084310"
  },
  {
    "text": "Laird shell so I've got up inside",
    "start": "2084310",
    "end": "2091120"
  },
  {
    "text": "connected to this application I'll show you that in a second what I'm going to",
    "start": "2091120",
    "end": "2102820"
  },
  {
    "text": "do in the cloud shell I'm going to spin some load so I just need to grab the",
    "start": "2102820",
    "end": "2108180"
  },
  {
    "text": "load test",
    "start": "2109440",
    "end": "2112800"
  },
  {
    "text": "and just before I spin that what I'll do is I'll show you the front end so the front end is it's basically a contoso",
    "start": "2122220",
    "end": "2129420"
  },
  {
    "text": "kind of electronics at a store pretty basic stuff and you know there let's say",
    "start": "2129420",
    "end": "2137910"
  },
  {
    "text": "Black Friday is happening a black fire it's probably a bad example because you can predict the load in Black Friday but let's say I've got some flash sale on",
    "start": "2137910",
    "end": "2143670"
  },
  {
    "text": "and we're going to get sudden spike in traffic so what we'll do is if we come",
    "start": "2143670",
    "end": "2149339"
  },
  {
    "text": "back I need to juggle a few windows so let me clear this and did UK get pods Oh",
    "start": "2149339",
    "end": "2154680"
  },
  {
    "text": "wide again whoops and we will now kick",
    "start": "2154680",
    "end": "2168690"
  },
  {
    "text": "off the load so I'll come over here and I'm going to start this low test if we",
    "start": "2168690",
    "end": "2176069"
  },
  {
    "text": "watch these metrics here what we see at the moment we're getting literally like",
    "start": "2176069",
    "end": "2181560"
  },
  {
    "text": "one request see suddenly now jump to 200 requests per second the request duration suddenly jumped as well initially so we",
    "start": "2181560",
    "end": "2188849"
  },
  {
    "text": "seen this jump up from pretty much zero to 500 milliseconds what's happening now",
    "start": "2188849",
    "end": "2194640"
  },
  {
    "text": "is that load is being detected by the pod autoscaler now starting to provision new nodes sorry new pods of this",
    "start": "2194640",
    "end": "2201630"
  },
  {
    "text": "application and because we've got that tainted we've got the the virtual node it's actually spawning instances on to",
    "start": "2201630",
    "end": "2209400"
  },
  {
    "text": "that virtual node so that's how quickly it's happening you see that response time is starting to drop so if I now",
    "start": "2209400",
    "end": "2214740"
  },
  {
    "text": "come back to console if I now do you get pods again I should see is a lot more",
    "start": "2214740",
    "end": "2221609"
  },
  {
    "text": "pods you see these online store and they're running on the Virtual node oops",
    "start": "2221609",
    "end": "2226890"
  },
  {
    "text": "so these are all now running on the Virtual node if I keep that running that'll start spinning up more you can",
    "start": "2226890",
    "end": "2232950"
  },
  {
    "text": "see ease even more now so if I do K get HPA just trying to move that up we can",
    "start": "2232950",
    "end": "2239520"
  },
  {
    "text": "see we've got this maximum of 60 pods and it's spinning up so the response is quite quick as hopefully you can see",
    "start": "2239520",
    "end": "2246410"
  },
  {
    "text": "that app is still there by the way it's not smoke and mirrors",
    "start": "2246410",
    "end": "2252019"
  },
  {
    "text": "and if I come up to Azure contain instances if i refresh this what we",
    "start": "2252880",
    "end": "2258039"
  },
  {
    "text": "should see is where are they",
    "start": "2258039",
    "end": "2263789"
  },
  {
    "text": "strange we should see a lot of pods a lot of content instances maybe they just",
    "start": "2266009",
    "end": "2272109"
  },
  {
    "text": "haven't quite shown up yet it's lagging but they're clearly being created so we can see there so there's",
    "start": "2272109",
    "end": "2282400"
  },
  {
    "text": "some some already running some are waiting and crated so keeping is the response time for this this wasn't",
    "start": "2282400",
    "end": "2288579"
  },
  {
    "text": "taking minutes for a cluster to scale up and become available we've actually",
    "start": "2288579",
    "end": "2294099"
  },
  {
    "text": "started responding within a few seconds now if I kill that load then we'll start",
    "start": "2294099",
    "end": "2300190"
  },
  {
    "text": "shedding the pods of that load and within I'm not going to wait for it but",
    "start": "2300190",
    "end": "2307180"
  },
  {
    "text": "within within about two or three minutes we'll see the number of contain instances dropping and eventually we'll",
    "start": "2307180",
    "end": "2314920"
  },
  {
    "text": "go back to steady state which is just running on IAC on our provision nodes so hopefully you get a good idea of how we",
    "start": "2314920",
    "end": "2321549"
  },
  {
    "text": "can use something like this to have very flexible load the other interesting prospect this opens up is maybe not",
    "start": "2321549",
    "end": "2328630"
  },
  {
    "text": "having any actual VMS in my cluster not paying for any compute that's sitting",
    "start": "2328630",
    "end": "2333729"
  },
  {
    "text": "there not being utilized certainly something that I think you know I wouldn't be surprised to see in the",
    "start": "2333729",
    "end": "2338979"
  },
  {
    "text": "future at the moment it's not possible you can know you can spin down to a single node cluster and do this and I",
    "start": "2338979",
    "end": "2346660"
  },
  {
    "text": "suppose technically you could you could switch off that node it's not supported scenario but you could say any switch",
    "start": "2346660",
    "end": "2352420"
  },
  {
    "text": "off their node and you probably force everything to go on to on to the ACI but it's definitely not supported scenario",
    "start": "2352420",
    "end": "2357430"
  },
  {
    "text": "don't tell don't tell anyone I suggested that probably they're from the recording is well Sophie that gives you an idea of",
    "start": "2357430",
    "end": "2365160"
  },
  {
    "text": "of that concept now let's go back to the slides I think I'm doing quite good for time",
    "start": "2365160",
    "end": "2370390"
  },
  {
    "text": "actually which means we can go and get coffee quickly as well so the final",
    "start": "2370390",
    "end": "2377460"
  },
  {
    "text": "section was the bit I said I don't want to spend too long on surround service",
    "start": "2377460",
    "end": "2383979"
  },
  {
    "text": "meshes so how many people here at Simon trust are using service measures so anything",
    "start": "2383979",
    "end": "2390160"
  },
  {
    "text": "like sto looking at each do as a few people looking in it cool it's more be",
    "start": "2390160",
    "end": "2397329"
  },
  {
    "text": "enough it won't be anything too new for you so what's the service mesh again apologies if you were in Elton's talk",
    "start": "2397329",
    "end": "2402369"
  },
  {
    "text": "probably repeating the service meshes infrastructure layer for handling service to service communications so its",
    "start": "2402369",
    "end": "2408819"
  },
  {
    "text": "job is basically to allow you to deliver reliable you know delivery of requests across complex",
    "start": "2408819",
    "end": "2415150"
  },
  {
    "text": "cloud native applications why do we need it though kubernetes what covenant is",
    "start": "2415150",
    "end": "2422229"
  },
  {
    "start": "2420000",
    "end": "2420000"
  },
  {
    "text": "built in for networking and service service communications is pretty basic sure you'll agree we have pod security",
    "start": "2422229",
    "end": "2428019"
  },
  {
    "text": "policies and then we have ingress and even the ingress it's pretty lightweight you know allows us to do some basic",
    "start": "2428019",
    "end": "2433599"
  },
  {
    "text": "routing on host name and host headers other than that we can't do anything we",
    "start": "2433599",
    "end": "2438640"
  },
  {
    "text": "can't do any canary deployments or anything like that",
    "start": "2438640",
    "end": "2444058"
  },
  {
    "text": "when we have the ability to control the traffic we can actually open up quite a few powerful can application scenarios",
    "start": "2445589",
    "end": "2451630"
  },
  {
    "text": "so mention canary deployments allowing us to deploy second version of application and sending a limited number",
    "start": "2451630",
    "end": "2458049"
  },
  {
    "text": "of users to that instance another option that I quite like which I don't see talked about as much is launching darkly",
    "start": "2458049",
    "end": "2464739"
  },
  {
    "text": "so this is where you'd launch a second version of your of your application and",
    "start": "2464739",
    "end": "2470019"
  },
  {
    "text": "it's it's then receives a mirror image of the traffic that's going to your production instance and you can see how",
    "start": "2470019",
    "end": "2475839"
  },
  {
    "text": "it behaves with real traffic so we can test everything we want in test environments reality is until we get",
    "start": "2475839",
    "end": "2481599"
  },
  {
    "text": "into production that's when we hit a with real traffic and we find out how application behaves so by mirroring the",
    "start": "2481599",
    "end": "2487420"
  },
  {
    "text": "traffic what we can do is send essentially a copy of the same traffic to another instance of the service we",
    "start": "2487420",
    "end": "2493749"
  },
  {
    "text": "can watch it if we're doing some kind of refactoring we can actually inspect the inputs and outputs and make sure that",
    "start": "2493749",
    "end": "2499749"
  },
  {
    "text": "they are matching and then we can wanna be happy that it's behaving the way we want we can then do it to a swap over",
    "start": "2499749",
    "end": "2506009"
  },
  {
    "text": "and then also what service measures let us do is is do traffic routing between",
    "start": "2506009",
    "end": "2511390"
  },
  {
    "text": "between legacy applications and cloud native apps so with something like Castillo and I'll talk a bit more viced",
    "start": "2511390",
    "end": "2516549"
  },
  {
    "text": "you in a second you can actually expand a service mesh into VMs so you can have VMs and then have kubernetes cluster",
    "start": "2516549",
    "end": "2523529"
  },
  {
    "text": "running service mesh so sto is the most well known service mesh it's an",
    "start": "2523529",
    "end": "2530769"
  },
  {
    "text": "open-source project being led by Google lyft and IBM and it runs on top of",
    "start": "2530769",
    "end": "2536230"
  },
  {
    "text": "kubernetes but actually does support other platforms as well so pride the number of features network",
    "start": "2536230",
    "end": "2543069"
  },
  {
    "text": "error handling so allows us to have retry logic circuit breakers timeouts now these are things you can build into",
    "start": "2543069",
    "end": "2549160"
  },
  {
    "text": "your code of course you can but the challenge is if you're running different languages in your class if you you're",
    "start": "2549160",
    "end": "2554859"
  },
  {
    "text": "your team that operates different languages you've got implement the same logic in multiple languages by pushing",
    "start": "2554859",
    "end": "2560170"
  },
  {
    "text": "this kind of concern into the platform you have a consistent approach in dealing with it and your applications",
    "start": "2560170",
    "end": "2565900"
  },
  {
    "text": "don't need to have these additional libraries just to handle this logic similarly we can do rate limiting so",
    "start": "2565900",
    "end": "2571779"
  },
  {
    "text": "we've got a bad actor in your cluster you can throttle the rate rate it sends requests you do this traffic shifting",
    "start": "2571779",
    "end": "2580210"
  },
  {
    "text": "your monitoring so I talked about before this canary deployments sending a percentage of the traffic this juror",
    "start": "2580210",
    "end": "2585249"
  },
  {
    "text": "lets you do quite powerful concepts but sending only certain users seeing you know different traffic and then this",
    "start": "2585249",
    "end": "2591220"
  },
  {
    "text": "mirroring concept as I said it's not used that much for sending an exact copy of the traffic to another another",
    "start": "2591220",
    "end": "2596559"
  },
  {
    "text": "instance as well rather than sending some percentage this tier lets you do",
    "start": "2596559",
    "end": "2602049"
  },
  {
    "text": "fault injection so this is quite powerful if you are testing your micro services deployment C key aspect of",
    "start": "2602049",
    "end": "2608470"
  },
  {
    "text": "micro services there they shouldn't be reliant on all the other services being up at the same time so you can test her",
    "start": "2608470",
    "end": "2613839"
  },
  {
    "text": "by injecting faults and you can also secure the service to service communication so again one of the",
    "start": "2613839",
    "end": "2619930"
  },
  {
    "text": "challenges in a big cluster is you want to make sure that traffic between services is controlled it's encrypted",
    "start": "2619930",
    "end": "2625960"
  },
  {
    "text": "and you have policies that prevent certain services from talking to other services and then finally so final thing",
    "start": "2625960",
    "end": "2633609"
  },
  {
    "text": "is one more um you can see the requests so in modern kind of micro services",
    "start": "2633609",
    "end": "2639099"
  },
  {
    "text": "applications we have multiple components made up you know handing the requests so with the service mesh you can see that",
    "start": "2639099",
    "end": "2644920"
  },
  {
    "text": "request as it flows through your application so just to wrap up and I",
    "start": "2644920",
    "end": "2650410"
  },
  {
    "text": "think pretty good on time I've just touched on literally the you",
    "start": "2650410",
    "end": "2656119"
  },
  {
    "text": "know handful of things that community lets you do around pond scheduling and there are many many other concepts in",
    "start": "2656119",
    "end": "2661609"
  },
  {
    "text": "communities that you know we could we could spend it probably week talking about I've hopefully shown you how we",
    "start": "2661609",
    "end": "2668330"
  },
  {
    "text": "can use admission webhooks to customize our creation of our resources without no too much code and",
    "start": "2668330",
    "end": "2677080"
  },
  {
    "text": "if you really want the ultimate flexibility then you go down the custom resource and controller route and the",
    "start": "2677080",
    "end": "2686270"
  },
  {
    "text": "virtual nodes as I said is I think it's quite an interesting concept and it's no longer it's not a Microsoft Project",
    "start": "2686270",
    "end": "2691790"
  },
  {
    "text": "anymore so I'm expecting to see you know a lot more uptake on this especially now is the CNC F project but yeah",
    "start": "2691790",
    "end": "2698720"
  },
  {
    "text": "potentially having these service communities clusters in the future where we're not even having to worry about the VMS anymore the nodes we're just running",
    "start": "2698720",
    "end": "2705880"
  },
  {
    "text": "you know essentially manage communities providers at the moment have given us they've taken away the the API server",
    "start": "2705880",
    "end": "2711950"
  },
  {
    "text": "we're not managing that anymore so as soon as we use the service platform underneath then we've got rid of",
    "start": "2711950",
    "end": "2716960"
  },
  {
    "text": "everything and also those people like arguing by the server list and kubernetes is one way or the other we",
    "start": "2716960",
    "end": "2722359"
  },
  {
    "text": "can just stop the argument so if you want to learn more obviously a lot of",
    "start": "2722359",
    "end": "2728570"
  },
  {
    "text": "what I talked about is in the kubernetes documentation it's you know not necessarily the easiest thing to get hold of that demo I showed you is on",
    "start": "2728570",
    "end": "2737270"
  },
  {
    "text": "github the virtual node auto scaling it's a little bit finicky to get set up feel free to ping me if you're trying",
    "start": "2737270",
    "end": "2743630"
  },
  {
    "text": "and having problems I mentioned I wasn't going to deep dive on micro services I did to talk NDC Sydney last year where I",
    "start": "2743630",
    "end": "2750560"
  },
  {
    "text": "did spend a bit more time and I did few more demos of course again Elton did a talk here so he can catch his video as",
    "start": "2750560",
    "end": "2755720"
  },
  {
    "text": "well and finally katakana is awesome I always plug cat occurred I don't work for them I was pluck a decoder so I think it's a",
    "start": "2755720",
    "end": "2761630"
  },
  {
    "text": "fantastic platform and when hear not heard of cat coda speaking to the converted they've got a course on there",
    "start": "2761630",
    "end": "2768680"
  },
  {
    "text": "for the operator frameworks if you did want to learn more you can have a look at that as well and then I think on that",
    "start": "2768680",
    "end": "2775910"
  },
  {
    "text": "we've got some time for questions hello remind me to repeat the question if I",
    "start": "2775910",
    "end": "2782730"
  },
  {
    "text": "don't yeah yeah so a lot of the database",
    "start": "2782730",
    "end": "2793970"
  },
  {
    "text": "companies have created operators and so has AWS so I think I device has got a",
    "start": "2793970",
    "end": "2801000"
  },
  {
    "text": "set of operators now and including creating any SS databases using a custom",
    "start": "2801000",
    "end": "2806130"
  },
  {
    "text": "resource so you you would create a database instance in there and it gets deployed there's another project which I",
    "start": "2806130",
    "end": "2812700"
  },
  {
    "text": "didn't didn't have time to cover it's around the Service Catalog which is a different approach to doing",
    "start": "2812700",
    "end": "2818430"
  },
  {
    "text": "the similar concept of provisioning external resources as part of a kubernetes deployment but that goes down",
    "start": "2818430",
    "end": "2824130"
  },
  {
    "text": "a slightly different route is using an api aggregation approach but the end effect is similar but i think they're",
    "start": "2824130",
    "end": "2831030"
  },
  {
    "text": "they're looking at converting it to a customer resource approaches own because it it feels like a more intuitive way like there's a Prometheus operator I was",
    "start": "2831030",
    "end": "2838170"
  },
  {
    "text": "actually using that in my demo you may have noticed it's just simplifies the deployments but yeah",
    "start": "2838170",
    "end": "2844850"
  },
  {
    "text": "anyone else Alton",
    "start": "2844850",
    "end": "2849320"
  },
  {
    "text": "now it's a fair point no it doesn't affect the it's more around what's currently running so yeah the load",
    "start": "2863050",
    "end": "2868550"
  },
  {
    "text": "balancer will do its thing it doesn't affect the load balance as far as I understand but yeah it's a good point",
    "start": "2868550",
    "end": "2873590"
  },
  {
    "text": "that I didn't think of that somebody else yep",
    "start": "2873590",
    "end": "2882039"
  },
  {
    "text": "[Music]",
    "start": "2888610",
    "end": "2891709"
  },
  {
    "text": "I'll repeat the question because I forgot to do that for thirsty so the question is does the virtual node",
    "start": "2902390",
    "end": "2907850"
  },
  {
    "text": "automatically trigger a cluster auto-scaling at the same time the answer's no it's purely around the",
    "start": "2907850",
    "end": "2912990"
  },
  {
    "text": "virtual node but there's certainly something you could you could have a the",
    "start": "2912990",
    "end": "2918390"
  },
  {
    "text": "cluster autoscaler probably won't work in that situation actually because the pods won't be waiting to be scheduled so yeah I think you'd have to probably",
    "start": "2918390",
    "end": "2925260"
  },
  {
    "text": "trigger off the horizontal pod autoscaler and use that as a as a some kind of",
    "start": "2925260",
    "end": "2931140"
  },
  {
    "text": "initiator but you're no certainly not built-in nice idea though you it depends",
    "start": "2931140",
    "end": "2937320"
  },
  {
    "text": "I guess the problem is if the if the load is very spiky then you probably want to keep it on the service containers because you don't want to",
    "start": "2937320",
    "end": "2944070"
  },
  {
    "text": "have to have the extra capacity provision in your cluster the whole time so it's a bit of a balancing act on that",
    "start": "2944070",
    "end": "2951859"
  },
  {
    "text": "so the cluster autoscaler is in a KS it's in preview but it's there so you can set that up if you use that in",
    "start": "2966500",
    "end": "2973380"
  },
  {
    "text": "conjunction with the virtual node then the cluster over to scaler won't kick in because you won't find at least I don't",
    "start": "2973380",
    "end": "2979020"
  },
  {
    "text": "believe it'll kick in because it relies on pods waiting to be scheduled but if those pods are so icy if you didn't if",
    "start": "2979020",
    "end": "2984930"
  },
  {
    "text": "you didn't tolerate the taint on the virtual node then certainly the class or - skele will kick in because then there'll be pods waiting to be scheduled",
    "start": "2984930",
    "end": "2990900"
  },
  {
    "text": "which which aren't going on to the virtual node cool any more questions",
    "start": "2990900",
    "end": "2998360"
  },
  {
    "text": "in that case I'll say thank you very much and probably got five minutes for coffee",
    "start": "2998360",
    "end": "3005109"
  }
]
[
  {
    "start": "0",
    "end": "90000"
  },
  {
    "text": "howdy everybody my name is arthur doler and i'm here today to talk to you about bias and ai",
    "start": "7919",
    "end": "14799"
  },
  {
    "text": "starters let's kick this off by playing a game i want you to grab your phone",
    "start": "14799",
    "end": "20800"
  },
  {
    "text": "uh take it and just pull it out your pocket i know you're not usually supposed to do that at conferences when you're listening to talks but we're going to do",
    "start": "20800",
    "end": "27519"
  },
  {
    "text": "this together go ahead and open up your messaging app whichever one you happen to use and if",
    "start": "27519",
    "end": "33840"
  },
  {
    "text": "it has predictive text enabled on the keyboard and go ahead and type in this sentence",
    "start": "33840",
    "end": "39040"
  },
  {
    "text": "you're unintelligent and then see what your app suggests",
    "start": "39040",
    "end": "44960"
  },
  {
    "text": "for the next words i'll give you a couple seconds to do that",
    "start": "44960",
    "end": "49920"
  },
  {
    "text": "typically if your phone works like mine you're going to see the word man suggested and possibly guy what you",
    "start": "53520",
    "end": "59680"
  },
  {
    "text": "won't see are girl woman etc let's try another one",
    "start": "59680",
    "end": "66320"
  },
  {
    "text": "go ahead and try this statement you're acute",
    "start": "66320",
    "end": "72520"
  },
  {
    "text": "again if your phone works like mine the word girl shows up nothing for guy",
    "start": "77680",
    "end": "84000"
  },
  {
    "text": "boy etc now this seems like a little bit of a",
    "start": "84000",
    "end": "89280"
  },
  {
    "text": "you know spurious example why does this actually matter what your predictive text says on your keyboard",
    "start": "89280",
    "end": "95439"
  },
  {
    "start": "90000",
    "end": "181000"
  },
  {
    "text": "well this is really a symptom of a larger problem",
    "start": "95439",
    "end": "101759"
  },
  {
    "text": "ai and machine learning use is drastically on the increase in our industry and software in general",
    "start": "101759",
    "end": "107920"
  },
  {
    "text": "and it's becoming easier to do at the same time it's becoming more powerful we're able to process more data",
    "start": "107920",
    "end": "114159"
  },
  {
    "text": "do more things with it and we're using it to solve complex and important problems",
    "start": "114159",
    "end": "120320"
  },
  {
    "text": "and we're using it to supplement the workforce especially in remote times when we don't necessarily have access to the staff we",
    "start": "120320",
    "end": "126399"
  },
  {
    "text": "need for all of these things because of those two things we can't always value verify the output manually",
    "start": "126399",
    "end": "134160"
  },
  {
    "text": "from these algorithms from this ai above and beyond that we don't even know",
    "start": "134160",
    "end": "140879"
  },
  {
    "text": "how this works sometimes we're relying on something like tensorflow where the underlying logic we may have a rough",
    "start": "140879",
    "end": "146560"
  },
  {
    "text": "model of it but we don't necessarily know how it works worst case we're buying some kind of pre-packaged black",
    "start": "146560",
    "end": "152319"
  },
  {
    "text": "box ai off the shelf product and we have no idea what's going on because it's a proprietary secret",
    "start": "152319",
    "end": "160239"
  },
  {
    "text": "lastly regular developers are writing these things it doesn't take a cadre of research scientists in a university to",
    "start": "160800",
    "end": "167519"
  },
  {
    "text": "build a model you know it doesn't take them three years to go build a model anymore you can do this in an afternoon",
    "start": "167519",
    "end": "173200"
  },
  {
    "text": "you can find a tensorflow document like tutorial and get and have your first tensorflow models built",
    "start": "173200",
    "end": "178560"
  },
  {
    "text": "15 minutes 30 minutes and these things have real consequences when you start putting them into",
    "start": "178560",
    "end": "184560"
  },
  {
    "start": "181000",
    "end": "347000"
  },
  {
    "text": "practice when you start putting them into the real world and you have to be right the first time",
    "start": "184560",
    "end": "190720"
  },
  {
    "text": "here's an example of a consequence there are places in the united states",
    "start": "190720",
    "end": "195840"
  },
  {
    "text": "that use what's called risk assessment software for evaluating whether people you know people who've been uh charged",
    "start": "195840",
    "end": "202480"
  },
  {
    "text": "with crimes should be out on bail should be released on bail",
    "start": "202480",
    "end": "207760"
  },
  {
    "text": "these assessments pieces of software um rated people from one to ten this chart shows the number of people",
    "start": "207760",
    "end": "214159"
  },
  {
    "text": "rated in that category the top score are for white people",
    "start": "214159",
    "end": "219760"
  },
  {
    "text": "the bottom chart is for black people or no other way around sorry black people is the top one white's the bottom one",
    "start": "219760",
    "end": "227360"
  },
  {
    "text": "look if you don't see a problem there then",
    "start": "227360",
    "end": "232400"
  },
  {
    "text": "we have to have to talk but this should be fairly obvious why this is a problem",
    "start": "232400",
    "end": "237760"
  },
  {
    "text": "later this algorithm was analyzed and it was found to be no better than a coin flip as far as whether it actually",
    "start": "237760",
    "end": "244239"
  },
  {
    "text": "predicted recidivism as far as whether it actually predicted any risk from this individual you might as well the judge",
    "start": "244239",
    "end": "250239"
  },
  {
    "text": "may have well have flipped a coin here's a second example",
    "start": "250239",
    "end": "255680"
  },
  {
    "text": "natural language processing was a big thing a couple years ago it's died down a little bit now but we're still doing a lot of it",
    "start": "255680",
    "end": "262160"
  },
  {
    "text": "here's an example of natural language processing that had some consequences this is sentiment analysis of sentences",
    "start": "262160",
    "end": "269120"
  },
  {
    "text": "involving common names of various ethnic types now sentiment analysis if you're not familiar is a theory a process by which you",
    "start": "269120",
    "end": "276000"
  },
  {
    "text": "basically rate does someone view this or is this set this statement positive or is it negative are they do they have a",
    "start": "276000",
    "end": "282400"
  },
  {
    "text": "positive sentiment or a negative sentiment they say this thing sucks that's negative they say rocks that's a positive",
    "start": "282400",
    "end": "289120"
  },
  {
    "text": "if you included um common ethnic names in the sentences you started seeing",
    "start": "289120",
    "end": "296240"
  },
  {
    "text": "disparities as far as how those things were rated positive in this case positive is higher",
    "start": "296240",
    "end": "301600"
  },
  {
    "text": "a positive number and a negative is a negative sentiment so sentences involving common black first",
    "start": "301600",
    "end": "308720"
  },
  {
    "text": "names had a more negative sentiment that's kind of ridiculous",
    "start": "308720",
    "end": "316080"
  },
  {
    "text": "now today when i'm talking about this i don't want to talk about fault and i don't want to talk about blame",
    "start": "318240",
    "end": "324560"
  },
  {
    "text": "i want to talk about the reality of the situation and the responsibility that we have as",
    "start": "324560",
    "end": "329600"
  },
  {
    "text": "developers to deal with it all data sets are biased and all algorithms are biased it's kind",
    "start": "329600",
    "end": "336720"
  },
  {
    "text": "of the point of an algorithm if it's not biased in some way it's not helping you make a decision an algorithm that turns",
    "start": "336720",
    "end": "343120"
  },
  {
    "text": "around and just shrugs at you isn't going to really be helpful so today we're going to talk about a",
    "start": "343120",
    "end": "349120"
  },
  {
    "text": "couple different types of problem with ai and machine learning six seven if you count weird but we're",
    "start": "349120",
    "end": "355039"
  },
  {
    "text": "going to talk through these things now i kind of like to think about these as",
    "start": "355039",
    "end": "361360"
  },
  {
    "text": "ghosts in the machine learning and i know what we do with ghosts",
    "start": "361360",
    "end": "367680"
  },
  {
    "text": "because i've had a little bit of experience in that category what do you do with ghosts we bust",
    "start": "367680",
    "end": "373120"
  },
  {
    "text": "ghosts so today i'm going to talk about seven of these individual things and how",
    "start": "373120",
    "end": "378400"
  },
  {
    "text": "you can start addressing them if you're working with ai and machine learning so",
    "start": "378400",
    "end": "384160"
  },
  {
    "text": "well before i get into that let me state this is not going to get very deep into the weeds of the individual algorithms",
    "start": "384160",
    "end": "390080"
  },
  {
    "text": "this isn't going to be heavy on math there's very little math almost no math at all we're going to talk about broader things",
    "start": "390080",
    "end": "397360"
  },
  {
    "text": "that you can do to deal with these problems so with that said let's get right into it",
    "start": "397360",
    "end": "403280"
  },
  {
    "text": "first class that we're going to deal with is phantoms of false correlation the phantoms of false correlation show",
    "start": "403280",
    "end": "409520"
  },
  {
    "text": "up when you have a data set and you're not sure what to do with it your boss says oh here's the data we've collected",
    "start": "409520",
    "end": "414639"
  },
  {
    "text": "from this for the last seven years go see what you can find in it",
    "start": "414639",
    "end": "419759"
  },
  {
    "text": "in this case you're really just going fishing you're just digging into the data and you're going to try and find",
    "start": "419759",
    "end": "425280"
  },
  {
    "text": "something when you do that you're going to find something it just",
    "start": "425280",
    "end": "430960"
  },
  {
    "text": "may not be something useful or valuable you're going to find arbitrary correlations",
    "start": "430960",
    "end": "437039"
  },
  {
    "text": "and this can get us really confused about what things actually predict other things and what things just correlate",
    "start": "437039",
    "end": "442319"
  },
  {
    "text": "with other things through that we have to explain that we have to talk a little bit about correlation",
    "start": "442319",
    "end": "447759"
  },
  {
    "start": "443000",
    "end": "515000"
  },
  {
    "text": "correlation is a term that describes how closely two data sets fit two data",
    "start": "447759",
    "end": "454000"
  },
  {
    "text": "series how close do they correlate with each other are they right on top of each other do they kind of go along with each",
    "start": "454000",
    "end": "459199"
  },
  {
    "text": "other humans can do this pretty well visually but there are mathematics ways to do it because obviously a machine learning",
    "start": "459199",
    "end": "465120"
  },
  {
    "text": "tool is not going to do it visually but you can find false correlations if you",
    "start": "465120",
    "end": "470639"
  },
  {
    "text": "just go in and wander into your data not understanding what it is you're looking for for instance the number of people",
    "start": "470639",
    "end": "476639"
  },
  {
    "text": "who drown by falling into a pool does correlate with the number of films nicholas cage has appeared in but the",
    "start": "476639",
    "end": "482400"
  },
  {
    "text": "two are not causative as funny as that might be that that was true similarly the divorce rate in maine the",
    "start": "482400",
    "end": "489120"
  },
  {
    "text": "u.s state of maine has nothing to do with the us per capita consumption of margarine but they're correlated with",
    "start": "489120",
    "end": "494879"
  },
  {
    "text": "each other and lastly the letter in the winning word of the scripts us national spelling bee has nothing to do with the",
    "start": "494879",
    "end": "500240"
  },
  {
    "text": "number of people killed by venomous spiders in the world but again they're correlated with each other although that",
    "start": "500240",
    "end": "505280"
  },
  {
    "text": "would be pretty funny if it were these false correlations can lead you to",
    "start": "505280",
    "end": "510560"
  },
  {
    "text": "believe things about your data but lead you to believe causative things about your data that aren't true",
    "start": "510560",
    "end": "515760"
  },
  {
    "start": "515000",
    "end": "575000"
  },
  {
    "text": "so what can you do about it well the easiest way to avoid these is really to know what question you're",
    "start": "515760",
    "end": "521200"
  },
  {
    "text": "asking up front don't just go in and look for things that correlate with each other and say hey oh these two things kind of look the",
    "start": "521200",
    "end": "527200"
  },
  {
    "text": "same one must be causing the other because i can come up with a narrative that says that's true sit down and ask yourself i want to",
    "start": "527200",
    "end": "534080"
  },
  {
    "text": "figure out what things cause this to be higher that gets you off to a good start",
    "start": "534080",
    "end": "541360"
  },
  {
    "text": "secondly you can actually try using conditional probability over correlation now conditional probability is a tool",
    "start": "541360",
    "end": "547920"
  },
  {
    "text": "that allows you to say these things are actually conditional upon each other using probability this is the only math",
    "start": "547920",
    "end": "553920"
  },
  {
    "text": "i'm going to have in here don't worry it's computing the likelihood of one",
    "start": "553920",
    "end": "559040"
  },
  {
    "text": "event given that another event has already occurred probability folks",
    "start": "559040",
    "end": "565600"
  },
  {
    "text": "so class one's fairly easy to deal with class two gets a little thornier that's the specter of bias sample data",
    "start": "565600",
    "end": "573760"
  },
  {
    "text": "all right maybe you don't know what the difference is between data and say sample data",
    "start": "574880",
    "end": "580880"
  },
  {
    "start": "575000",
    "end": "866000"
  },
  {
    "text": "well let's talk about an example where you're analyzing and building a machine",
    "start": "580880",
    "end": "586480"
  },
  {
    "text": "learning tool around mortgage lending now historically especially in the us",
    "start": "586480",
    "end": "591600"
  },
  {
    "text": "mortgage lending can be problematic and it's a lot of data how long have we",
    "start": "591600",
    "end": "596880"
  },
  {
    "text": "been you know selling houses you can't necessarily feed all of that data through into your machine learning",
    "start": "596880",
    "end": "603440"
  },
  {
    "text": "algorithm to build a model and there are reasons you don't want to but what you do then is you assemble a",
    "start": "603440",
    "end": "610480"
  },
  {
    "text": "sample set a set of data that you're going to train your thing on well you should take the",
    "start": "610480",
    "end": "615600"
  },
  {
    "text": "sample set and split it into three parts one you will train your model on one you'll test your model on and one you'll",
    "start": "615600",
    "end": "620959"
  },
  {
    "text": "do for validation not really going to get into the interplay of how you deal with these things",
    "start": "620959",
    "end": "626000"
  },
  {
    "text": "there are lots of other resources online that will teach you how to do this but once you have a sample set",
    "start": "626000",
    "end": "632880"
  },
  {
    "text": "you're looking effectively to pick one thing that is the dependent column",
    "start": "632880",
    "end": "638240"
  },
  {
    "text": "that's what you're trying to predict and the rest of these things are independent columns",
    "start": "638240",
    "end": "644320"
  },
  {
    "text": "independent variables and those can be predictors but they aren't always",
    "start": "644320",
    "end": "649839"
  },
  {
    "text": "so let's say you have your sample data you've taken your big set of data and you've broken it down into sample data and now you're trying to look for what",
    "start": "649839",
    "end": "656240"
  },
  {
    "text": "things predict other things well it might be problematic for various reasons if you picked one of",
    "start": "656240",
    "end": "663120"
  },
  {
    "text": "these columns one of these variables as a independent variable",
    "start": "663120",
    "end": "668640"
  },
  {
    "text": "if you said well okay let's just build my models and assume that race affects the outcome",
    "start": "668640",
    "end": "674800"
  },
  {
    "text": "so that the machine learning thing can look at the race and say oh well that person is white so they get the thing",
    "start": "674800",
    "end": "680079"
  },
  {
    "text": "you know they get the mortgage obviously that can be problematic if not outright illegal",
    "start": "680079",
    "end": "687120"
  },
  {
    "text": "but those data points are in your data set especially if you're looking at say u.s historical mortgages redlining was a",
    "start": "687200",
    "end": "693600"
  },
  {
    "text": "huge thing and arguably still is where certain people are priced out of markets to prevent it from getting mortgages in certain markets because of",
    "start": "693600",
    "end": "700160"
  },
  {
    "text": "their race women couldn't own property in the u.s until shot independently till shockingly",
    "start": "700160",
    "end": "705680"
  },
  {
    "text": "recently um and so that's going to also affect your data set",
    "start": "705680",
    "end": "712000"
  },
  {
    "text": "the outputs of machine learning on biased data sets are biased",
    "start": "712000",
    "end": "718160"
  },
  {
    "text": "because of the way that these things work ai and machine learning is nothing more than math",
    "start": "718160",
    "end": "724079"
  },
  {
    "text": "your data is shaped then by the system that created it it's an artifact of that",
    "start": "724079",
    "end": "730720"
  },
  {
    "text": "system you know the data from historical mortgage records in the united states is",
    "start": "730720",
    "end": "736160"
  },
  {
    "text": "shaped by the system that was giving people mortgages it's not like that data came into being just by itself",
    "start": "736160",
    "end": "744240"
  },
  {
    "text": "this affects both what variables exist as well as its outputs so for instance going back to the historical mortgage",
    "start": "744240",
    "end": "750320"
  },
  {
    "text": "data you're not going to see for instance um any other genders than male and female in that mortgage data right",
    "start": "750320",
    "end": "758320"
  },
  {
    "text": "and not until very recently the existence of transgender people was you know erased in that data it doesn't",
    "start": "758320",
    "end": "764480"
  },
  {
    "text": "you can't burrow into it you can't find out if it's there",
    "start": "764480",
    "end": "768720"
  },
  {
    "text": "it's important to talk about bias in your data set because unless you are sampling data from some kind of",
    "start": "770560",
    "end": "777200"
  },
  {
    "text": "remarkably natural source like weather or whatever your data is biased",
    "start": "777200",
    "end": "784480"
  },
  {
    "text": "guaranteed because data that we have is based on decisions",
    "start": "784839",
    "end": "791360"
  },
  {
    "text": "that humans have made in the past and humans make a ton of really bad really wrong decisions",
    "start": "791360",
    "end": "797279"
  },
  {
    "text": "okay we've done humans do stupid stuff all the time",
    "start": "797279",
    "end": "802480"
  },
  {
    "text": "and when we do those stupid things in this modern computerized economy and environment and",
    "start": "802480",
    "end": "808800"
  },
  {
    "text": "world those choices get baked into amber they're preserved for",
    "start": "808800",
    "end": "814399"
  },
  {
    "text": "all time as a row in a database and calcified and we look at that and we",
    "start": "814399",
    "end": "819519"
  },
  {
    "text": "say well this is what the data is this is what it should be right this is historic this is history because that's",
    "start": "819519",
    "end": "825600"
  },
  {
    "text": "what we call a bunch of human decisions we don't call it data we call it history",
    "start": "825600",
    "end": "833440"
  },
  {
    "text": "history is not always accurate right just because you've recorded something",
    "start": "833839",
    "end": "840079"
  },
  {
    "text": "doesn't mean that it's inviolate and it doesn't mean that it was recorded correctly or that the choice that led to",
    "start": "840079",
    "end": "846240"
  },
  {
    "text": "even if it is recorded correctly doesn't mean that the choice that led to that data entry point was good or something",
    "start": "846240",
    "end": "852399"
  },
  {
    "text": "to be replicated because that's the real secret of machine learning",
    "start": "852399",
    "end": "858639"
  },
  {
    "text": "is that all it really does is take the past and make the future kind of look like that",
    "start": "858639",
    "end": "865360"
  },
  {
    "start": "866000",
    "end": "1019000"
  },
  {
    "text": "and a bunch of companies have spent a lot of time and money trying to make this work amazon spent an immense amount of time",
    "start": "866320",
    "end": "872880"
  },
  {
    "text": "and energy trying to build an ai recruiting tool and they literally could not get it to not",
    "start": "872880",
    "end": "878720"
  },
  {
    "text": "is be biased against women this is amazon they have more money than",
    "start": "878720",
    "end": "884320"
  },
  {
    "text": "i will ever have and certainly more hours of developer time and certainly there they have a lot",
    "start": "884320",
    "end": "890000"
  },
  {
    "text": "people there that are smarter than me for sure they're and they couldn't do it",
    "start": "890000",
    "end": "895760"
  },
  {
    "text": "the chances that one individual developer is going to be able to really handle this is slim",
    "start": "895760",
    "end": "901440"
  },
  {
    "text": "and that has effects that can show up in the world this is a tweet that i was given",
    "start": "901440",
    "end": "906639"
  },
  {
    "text": "permission to scrape from a grammar assisting tool that much like the examples we did at",
    "start": "906639",
    "end": "913279"
  },
  {
    "text": "the very beginning showed a um a suggestion for grammar and this",
    "start": "913279",
    "end": "919519"
  },
  {
    "text": "grammar tool was saying that there's an unusual word pair here that the noun girl isn't usually combined with the",
    "start": "919519",
    "end": "925360"
  },
  {
    "text": "adjective successful maybe you should use lucky or happy",
    "start": "925360",
    "end": "931519"
  },
  {
    "text": "those things propagate biases back into the world it takes date biases that",
    "start": "932399",
    "end": "937519"
  },
  {
    "text": "exist in your data and it puts them back out again",
    "start": "937519",
    "end": "942240"
  },
  {
    "text": "now there can be a couple reasons for bias besides the data itself being biased your sample might not be",
    "start": "943040",
    "end": "948079"
  },
  {
    "text": "representative if you've constructed your sample poorly it may not have all of the things in it that the machine",
    "start": "948079",
    "end": "953519"
  },
  {
    "text": "learning tool needs so constructing your sample correctly is also very very important",
    "start": "953519",
    "end": "960160"
  },
  {
    "text": "but the data itself might not be representative again women could not in the u.s could",
    "start": "960160",
    "end": "966399"
  },
  {
    "text": "not get a mortgage by themselves until relatively recently",
    "start": "966399",
    "end": "972079"
  },
  {
    "text": "there's data if you're pulling data from like the 1950s in the united states you're not going to see women getting",
    "start": "972240",
    "end": "977279"
  },
  {
    "text": "mortgages so that data set is not representative at that period in time",
    "start": "977279",
    "end": "983839"
  },
  {
    "text": "and you might ask do you have all of your user types maybe you're doing a a beta you're releasing things into the",
    "start": "984800",
    "end": "991040"
  },
  {
    "text": "wild or you know doing some kind of initial test and you're getting data back you've pulled in a bunch of early",
    "start": "991040",
    "end": "996399"
  },
  {
    "text": "adopters is that all of the users that you're going to have are those all the types of users that you're going to have",
    "start": "996399",
    "end": "1002079"
  },
  {
    "text": "for your software building a piece of tooling or be a machine learning",
    "start": "1002079",
    "end": "1007360"
  },
  {
    "text": "value machine learning model off of nothing but the beta users that you have can",
    "start": "1007360",
    "end": "1012800"
  },
  {
    "text": "lead to some significant problems down the road because you don't have a representative data set",
    "start": "1012800",
    "end": "1019360"
  },
  {
    "start": "1019000",
    "end": "1404000"
  },
  {
    "text": "so what can you do about this well the first thing is to remember that models represent",
    "start": "1019360",
    "end": "1025520"
  },
  {
    "text": "what was they don't tell you what should be",
    "start": "1025520",
    "end": "1030959"
  },
  {
    "text": "all machine learning is going to do is take something from the past and make the future look like that past",
    "start": "1030959",
    "end": "1039678"
  },
  {
    "text": "that's what they do so you need to be aware that you're making",
    "start": "1039679",
    "end": "1046000"
  },
  {
    "text": "choices when you implement a model when you build a model and when you put it into production",
    "start": "1046000",
    "end": "1053080"
  },
  {
    "text": "you can try finding a better data set maybe introduce it from different countries different cultures",
    "start": "1053919",
    "end": "1060559"
  },
  {
    "text": "there are other sites that have a bunch of data sets out there that have worked to scrub bias from them those are great",
    "start": "1060559",
    "end": "1066080"
  },
  {
    "text": "places to start especially for things like language processing",
    "start": "1066080",
    "end": "1072240"
  },
  {
    "text": "those are things that really have gone along people gone a long way to try and scrub bias out of those things",
    "start": "1072240",
    "end": "1078960"
  },
  {
    "text": "you can also build a better data set assume hey i know that we're where i",
    "start": "1078960",
    "end": "1085600"
  },
  {
    "text": "want to be now in terms of egalitarianism we're only going to work with modern data for modern mortgages",
    "start": "1085600",
    "end": "1091280"
  },
  {
    "text": "to make an argument about whether that's true or not but you can build a better data set",
    "start": "1091280",
    "end": "1096559"
  },
  {
    "text": "you can also turn around and explicitly just prevent your model from even looking at these columns like",
    "start": "1096559",
    "end": "1102320"
  },
  {
    "text": "race or gender that's actually fairly easy in most machine learning tools just say don't don't even don't even",
    "start": "1102320",
    "end": "1107840"
  },
  {
    "text": "pass it in as part of the data when you're training it right or you can apply different weighting depending",
    "start": "1107840",
    "end": "1113919"
  },
  {
    "text": "but you have to be aware of shadow columns because things like race and gender in",
    "start": "1113919",
    "end": "1120000"
  },
  {
    "text": "the united states well race especially is heavily correlated with postal codes",
    "start": "1120000",
    "end": "1126160"
  },
  {
    "text": "so if you include postal code what can happen is your machine learning algorithm will pick up",
    "start": "1126160",
    "end": "1132000"
  },
  {
    "text": "that people from these postal codes should not get mortgages which is a shadow column for race",
    "start": "1132000",
    "end": "1138880"
  },
  {
    "text": "so you have to watch for those things happening in your data as well you can make sure that your sample set",
    "start": "1138880",
    "end": "1145120"
  },
  {
    "text": "is representative and i concluded a couple resources here at the bottom of the slide the slides will be posted at the link at",
    "start": "1145120",
    "end": "1150160"
  },
  {
    "text": "the very beginning and there's a link at the end too for where you can grab the slides there are some resources there on how to",
    "start": "1150160",
    "end": "1156160"
  },
  {
    "text": "make your sample set representative you can also build your own data set",
    "start": "1156160",
    "end": "1162720"
  },
  {
    "text": "not just from what's going on but you can make a data set look like how you want",
    "start": "1162720",
    "end": "1168559"
  },
  {
    "text": "you can start by figuring out what the constraints are in for instance if you'd say okay i want",
    "start": "1168559",
    "end": "1173679"
  },
  {
    "text": "to build a data set where all races are more like are equally likely to get mortgages",
    "start": "1173679",
    "end": "1179360"
  },
  {
    "text": "and in that case you just turn around and say all right we're going to build some kind of um dependent work replace your dependent",
    "start": "1179360",
    "end": "1185280"
  },
  {
    "text": "variable with some kind of function that generates a new output altered by those constraints and if",
    "start": "1185280",
    "end": "1192559"
  },
  {
    "text": "you're saying well now you're kind of tail wagging the dog you are but you're also making choices",
    "start": "1192559",
    "end": "1200000"
  },
  {
    "text": "the same way that you're making choices when you just ride with historical data",
    "start": "1200000",
    "end": "1206240"
  },
  {
    "text": "there are a couple tools out there that will help you explore your data set and find bias one of them is ibm's ai",
    "start": "1206240",
    "end": "1211760"
  },
  {
    "text": "fairness toolkit which is actually really cool it will show you things with this data set like okay are there um",
    "start": "1211760",
    "end": "1218840"
  },
  {
    "text": "particular think categories that are protected over another so for instance this is a actual analysis from the repo",
    "start": "1218840",
    "end": "1226159"
  },
  {
    "text": "pro publica risk assessment data set that we talked about in one of the early consequences for that you know um",
    "start": "1226159",
    "end": "1231919"
  },
  {
    "text": "whether somebody should be released on bail this is actually showing that there is a bias against men and towards women",
    "start": "1231919",
    "end": "1238240"
  },
  {
    "text": "in that data set that women are more likely to be given bail than men are that's a bias in the data set",
    "start": "1238240",
    "end": "1245039"
  },
  {
    "text": "what you do with it at that point is kind of the choice that you have to make do you want to strip that out",
    "start": "1245039",
    "end": "1250480"
  },
  {
    "text": "do you want to leave that in and deal with the consequences there are different steps to me there",
    "start": "1250480",
    "end": "1256320"
  },
  {
    "text": "are also different steps that you can do things at in this particular case the ibm toolkit will allow you to do",
    "start": "1256320",
    "end": "1262559"
  },
  {
    "text": "things like the adversarial de-biasing which will attempt to actually put two different uh generative networks",
    "start": "1262559",
    "end": "1269440"
  },
  {
    "text": "generative um excuse me neural networks against each other and",
    "start": "1269440",
    "end": "1274960"
  },
  {
    "text": "actually kind of make them fight to go this one's trying to bias your data set and the other one learns not to",
    "start": "1274960",
    "end": "1280640"
  },
  {
    "text": "do that basically the another tool that you can use is the what if tool",
    "start": "1280640",
    "end": "1286240"
  },
  {
    "text": "which is out there on github this is another way to show okay what are kind of the correlations between",
    "start": "1286240",
    "end": "1291760"
  },
  {
    "text": "those two datas and what it will do is show you here's a model two predictors in this case",
    "start": "1291760",
    "end": "1298559"
  },
  {
    "text": "what are the differences between those two predictors why are two things these two data points being why are they",
    "start": "1298559",
    "end": "1303760"
  },
  {
    "text": "predicted differently and it will show you what things are kind of what dependent variables or independent",
    "start": "1303760",
    "end": "1308960"
  },
  {
    "text": "variables are weighted in that particular model so there are different ways you can",
    "start": "1308960",
    "end": "1314880"
  },
  {
    "text": "explore your data set and the outcomes and the predictors of those things to look for bias",
    "start": "1314880",
    "end": "1320480"
  },
  {
    "text": "but you have to have a good process in place in order to do that you have to be willing to slow down and",
    "start": "1320480",
    "end": "1326960"
  },
  {
    "text": "say we need to take the time to do this right lastly",
    "start": "1326960",
    "end": "1333280"
  },
  {
    "text": "you have to know who can be affected in order to unbias if your data set does not have for",
    "start": "1333280",
    "end": "1339760"
  },
  {
    "text": "instance racial categories or racial classification inside of it if your data set does not have gender inside of it if",
    "start": "1339760",
    "end": "1346159"
  },
  {
    "text": "your data set does not have trans people inside of it as even an option you can't detect bias",
    "start": "1346159",
    "end": "1352400"
  },
  {
    "text": "against those folks at that point and even if you have them in there",
    "start": "1352400",
    "end": "1357520"
  },
  {
    "text": "you really need to know who can be affected by bias in order to unbias it if there are particular zip codes that",
    "start": "1357520",
    "end": "1363520"
  },
  {
    "text": "are biased for various reasons outside of the algorithm like one's a superfund site et cetera um you know there's a",
    "start": "1363520",
    "end": "1368960"
  },
  {
    "text": "bunch of toxic waste to this the zip code so people get mortgages really don't we don't give mortgages over there",
    "start": "1368960",
    "end": "1374320"
  },
  {
    "text": "because we really don't want to buy people to buy stuff over there um that's an option",
    "start": "1374320",
    "end": "1379679"
  },
  {
    "text": "or a consequence that can show up in your data set that can bias against",
    "start": "1379679",
    "end": "1384799"
  },
  {
    "text": "those folks now you can ask the question do you want it to be but that's the same question i'm asking you you have to make",
    "start": "1384799",
    "end": "1390960"
  },
  {
    "text": "a choice when you're building your algorithms when you're building your models that asks you and i'm i'm asking you to",
    "start": "1390960",
    "end": "1398400"
  },
  {
    "text": "sit down and think about it for a little bit is this what you want to be in the world",
    "start": "1398400",
    "end": "1404240"
  },
  {
    "start": "1404000",
    "end": "1685000"
  },
  {
    "text": "so moving on to class 3 the shade of overly simplistic maximization maximization",
    "start": "1405360",
    "end": "1412240"
  },
  {
    "text": "let's talk about pricing algorithms for a little bit because this is fun especially in the you know global supply",
    "start": "1414880",
    "end": "1420400"
  },
  {
    "text": "chain stuff that's going on um there were researchers that took two pricing algorithms and if you didn't",
    "start": "1420400",
    "end": "1427279"
  },
  {
    "text": "know sorry to be the one to tell you basically everything on amazon is priced via robots these days",
    "start": "1427279",
    "end": "1432799"
  },
  {
    "text": "he took two common um they took two common robots two common pricing algorithms and kind of put them in a",
    "start": "1432799",
    "end": "1438640"
  },
  {
    "text": "sandbox with each other with a single product and told them to go find the maximum price and then let them kind of",
    "start": "1438640",
    "end": "1443840"
  },
  {
    "text": "train with each other for a while and then what he they did is they introduced a price change they manually",
    "start": "1443840",
    "end": "1450240"
  },
  {
    "text": "forced one of them to drop the price now normally when you do this when you see two things entering into a sandbox",
    "start": "1450240",
    "end": "1456720"
  },
  {
    "text": "you wind up at something called the nash equilibrium without getting into the math of all of it especially the economics of all of it",
    "start": "1456720",
    "end": "1463200"
  },
  {
    "text": "this is named after thomas nash the guy who was the main character for a beautiful mind",
    "start": "1463200",
    "end": "1469279"
  },
  {
    "text": "if these two things are competing fairly in the marketplace and operating under",
    "start": "1469279",
    "end": "1474480"
  },
  {
    "text": "basic inter like the introductory assumption assumptions that they had they will wind up at the nash equilibrium",
    "start": "1474480",
    "end": "1481039"
  },
  {
    "text": "if they're colluding with each other they will actually wind up at kind of this maximum collusion equilibrium",
    "start": "1481039",
    "end": "1487840"
  },
  {
    "text": "so what they saw is that when you forced one of these agents these pricing agents to drop its",
    "start": "1487840",
    "end": "1493919"
  },
  {
    "text": "price you would expect this to happen that one of them would drop and the other would kind of drop to the forced",
    "start": "1493919",
    "end": "1499760"
  },
  {
    "text": "price because that was the actual equilibrium of price of this product what actually happens is this",
    "start": "1499760",
    "end": "1507279"
  },
  {
    "text": "when forced to drop one the other agent drops it in response but then they start inching their way",
    "start": "1507279",
    "end": "1512960"
  },
  {
    "text": "back up when they're looking at each other and paying attention to what each other actually prices the product at",
    "start": "1512960",
    "end": "1518320"
  },
  {
    "text": "they wind up at a price that is not the nash price it's not the full collusive",
    "start": "1518320",
    "end": "1523360"
  },
  {
    "text": "cooperative price but it's definitely higher and back at what the average price was pre-shock they wind up at this",
    "start": "1523360",
    "end": "1529919"
  },
  {
    "text": "stasis so i want to ask you a question what if",
    "start": "1529919",
    "end": "1535200"
  },
  {
    "text": "amazon had built a salary tool instead instead of going to build something for recruiting they said well build something that tells us how much we can",
    "start": "1535200",
    "end": "1541360"
  },
  {
    "text": "pay these individuals let me know the minimum amount to pay these people because we're a business and that's what we do",
    "start": "1541360",
    "end": "1548400"
  },
  {
    "text": "you know if they valued salary costs strictly and ignored all other factors",
    "start": "1548880",
    "end": "1555600"
  },
  {
    "text": "they could get you know they'd hire a lot more women because they'd wind up being able to pay women 70 cents on the dollar",
    "start": "1555600",
    "end": "1562799"
  },
  {
    "text": "now that's obviously unethical and potentially illegal depending on where you live um",
    "start": "1562799",
    "end": "1568880"
  },
  {
    "text": "but it's possible machines don't understand ethics they don't understand the world",
    "start": "1568880",
    "end": "1576000"
  },
  {
    "text": "i have a co-worker who built um as a tool once it was a part of a hackathon",
    "start": "1576000",
    "end": "1581200"
  },
  {
    "text": "a app that was called foodies and it was a food planning app because he just started a family and when you start a",
    "start": "1581200",
    "end": "1587520"
  },
  {
    "text": "family you're you know delirious with lack of sleep and you have a bunch of",
    "start": "1587520",
    "end": "1592720"
  },
  {
    "text": "things on your time on your you know asking for your time including your job your spouse your kid your house etc",
    "start": "1592720",
    "end": "1599520"
  },
  {
    "text": "and so he was like i'm just going to build a tool using uh neural networks",
    "start": "1599520",
    "end": "1604960"
  },
  {
    "text": "to build for me a menu for the week and he built it to prioritize a couple",
    "start": "1604960",
    "end": "1610799"
  },
  {
    "text": "different things like cost reheat ability whether he could reheat leftovers easily during the week",
    "start": "1610799",
    "end": "1616880"
  },
  {
    "text": "um various macro level approach like macro level stuff in terms of protein et cetera",
    "start": "1616880",
    "end": "1623279"
  },
  {
    "text": "um he turned around and let it go now there is a grocery store here where i",
    "start": "1623279",
    "end": "1629120"
  },
  {
    "text": "live in omaha nebraska called hyvee hyvee especially during the summer runs",
    "start": "1629120",
    "end": "1634400"
  },
  {
    "text": "these specials where you can get a chicken bratwurst for 97 cents that's",
    "start": "1634400",
    "end": "1640240"
  },
  {
    "text": "you know less than the us dollar and the algorithm kind of looks at that",
    "start": "1640240",
    "end": "1645600"
  },
  {
    "text": "and says all right that's that you make a bunch of them at once and they'll reheat it's high in protein it's got the fat",
    "start": "1645600",
    "end": "1651919"
  },
  {
    "text": "you want really cheap awesome problem solved bratwurst",
    "start": "1651919",
    "end": "1657679"
  },
  {
    "text": "breakfast lunch and dinner the entire week bratwurst it's funny",
    "start": "1657679",
    "end": "1664320"
  },
  {
    "text": "but it's also an amazing example of how myopic these tools can be",
    "start": "1664320",
    "end": "1670559"
  },
  {
    "text": "which leads us to class four the shadow of understanding i added this one recently because of a",
    "start": "1670559",
    "end": "1677919"
  },
  {
    "text": "tool that has been it was floating around the internet a couple months back people were tweeting outcomes from it",
    "start": "1677919",
    "end": "1683120"
  },
  {
    "text": "and i had to include it in the talk a tool called delphi and delphi was this tool is this tool",
    "start": "1683120",
    "end": "1689919"
  },
  {
    "start": "1685000",
    "end": "1942000"
  },
  {
    "text": "that you can still go to it's a research prototype designed to give ethical moral judgments on variety",
    "start": "1689919",
    "end": "1696880"
  },
  {
    "text": "of everyday situations and the internet did what the internet does with this",
    "start": "1696880",
    "end": "1703039"
  },
  {
    "text": "with these kind of things and immediately got it to be extremely racist and extremely sexist and just all",
    "start": "1703039",
    "end": "1710159"
  },
  {
    "text": "around not great so i was you know had to play around with it",
    "start": "1710159",
    "end": "1716000"
  },
  {
    "text": "and it doesn't really understand things right what's happening when you ask it a",
    "start": "1716000",
    "end": "1722320"
  },
  {
    "text": "question is that it is looking at its model it's trying to build a nlp representation of those things and",
    "start": "1722320",
    "end": "1729360"
  },
  {
    "text": "attempting to actually figure out the ethical correlation with those things but what",
    "start": "1729360",
    "end": "1735600"
  },
  {
    "text": "it's doing the data that they have are these situations that they have harvested from reddit",
    "start": "1735600",
    "end": "1741760"
  },
  {
    "text": "and now they're asking a bunch of people on mechanical turk is this right or wrong",
    "start": "1741760",
    "end": "1746960"
  },
  {
    "text": "so they're really not doing a ton of legwork inside of the machine to really build some kind of ontology about ethics",
    "start": "1746960",
    "end": "1752960"
  },
  {
    "text": "etc they're really just kind of going well do these words correlate kind of with the s or kind of with no",
    "start": "1752960",
    "end": "1758880"
  },
  {
    "text": "it's more complicated than that but at its heart you can tell from this question alone that they doesn't really",
    "start": "1758880",
    "end": "1764559"
  },
  {
    "text": "understand words and that's the trick no ai understands words like you understand",
    "start": "1764559",
    "end": "1771760"
  },
  {
    "text": "words no ai is bringing a bunch of things to the table and if you're worried about me using",
    "start": "1771760",
    "end": "1777200"
  },
  {
    "text": "references to war crimes in this talk i got some really good advice that it was perfectly okay to talk about",
    "start": "1777200",
    "end": "1782640"
  },
  {
    "text": "murdering him sandwiches in a conference talk but to this point like if that's okay i",
    "start": "1782640",
    "end": "1788240"
  },
  {
    "text": "can also ask this change the sentence slightly and go am i allowed to slaughter a village of ham sandwiches if we have irreconcilable differences and",
    "start": "1788240",
    "end": "1794240"
  },
  {
    "text": "suddenly that's not like it's not clear if that's okay or not it's pretty obvious that this tool is",
    "start": "1794240",
    "end": "1799840"
  },
  {
    "text": "not anywhere close to being something that shows you the morality of a situation they might as",
    "start": "1799840",
    "end": "1806880"
  },
  {
    "text": "well have just put in a thing that says here's the question when they show you the question they show you the percentage of people that said yes or no",
    "start": "1806880",
    "end": "1814240"
  },
  {
    "text": "and like that you don't need ai for that at that point",
    "start": "1814240",
    "end": "1819440"
  },
  {
    "text": "the thing here is that humans are rarely single-minded okay we rarely are focusing on a goal to",
    "start": "1819440",
    "end": "1826000"
  },
  {
    "text": "the exclusion of everything else and when we do that it's usually catastrophic",
    "start": "1826000",
    "end": "1831120"
  },
  {
    "text": "we are surrounded by these things that cause us to behave in certain ways",
    "start": "1831120",
    "end": "1837039"
  },
  {
    "text": "the law our boss the other people that we care about our individual goals",
    "start": "1837039",
    "end": "1842080"
  },
  {
    "text": "when we build a machine learning model it doesn't have those baked into it",
    "start": "1842080",
    "end": "1847760"
  },
  {
    "text": "we can't get rid of those when we're thinking through something it's impossible to set those aside",
    "start": "1847760",
    "end": "1854480"
  },
  {
    "text": "if we don't build external consideration and information into the system about morality subtleties context etc these",
    "start": "1854480",
    "end": "1862000"
  },
  {
    "text": "tools are not going to understand them they can't and it's really hard to turn those",
    "start": "1862000",
    "end": "1868480"
  },
  {
    "text": "things into math which is all they do understand people are still working on this",
    "start": "1868480",
    "end": "1875279"
  },
  {
    "text": "and this is far from a solved problem so this is an example of kind of that",
    "start": "1875279",
    "end": "1880480"
  },
  {
    "text": "myopic viewpoint of how ai and machine learning work this is",
    "start": "1880480",
    "end": "1886240"
  },
  {
    "text": "a tool called a half cheetah and it's a two dimensional world even though it's rendered 3d",
    "start": "1886240",
    "end": "1891360"
  },
  {
    "text": "that shows the opportunity for or the goal is for this thing to learn to walk",
    "start": "1891360",
    "end": "1896640"
  },
  {
    "text": "and you can see what happens when it actually goes it flips over and it just starts twitching its whole way but the",
    "start": "1896640",
    "end": "1903120"
  },
  {
    "text": "thing is is that this is what the machine learning tool came out with it said this is the mo the most effective",
    "start": "1903120",
    "end": "1908640"
  },
  {
    "text": "way of travel it's like okay yes it is given the parameters that have",
    "start": "1908640",
    "end": "1913919"
  },
  {
    "text": "been fed into this tool it's clearly not what the real there goes right off the edge it's clearly not what the researchers",
    "start": "1913919",
    "end": "1919840"
  },
  {
    "text": "wanted it's a failure case to them but this is what machine learning is going to do when you just give it a goal",
    "start": "1919840",
    "end": "1926880"
  },
  {
    "text": "that says get as far as you can it's going to do dumb things that you don't want because you have to also tell it",
    "start": "1926880",
    "end": "1932960"
  },
  {
    "text": "get as far as you can while staying upright and kind of looking like a real animal etc etc etc",
    "start": "1932960",
    "end": "1938640"
  },
  {
    "text": "etc and that can get really tedious so what can you do about that well again",
    "start": "1938640",
    "end": "1944000"
  },
  {
    "text": "remember models represent what was they don't tell you what should be you have to understand that because that",
    "start": "1944000",
    "end": "1950720"
  },
  {
    "text": "will help you say all right just because the thing told me to go get bratwurst i don't have to go get bratwurst for every",
    "start": "1950720",
    "end": "1956559"
  },
  {
    "text": "meal like it's not your new ai overlord suddenly",
    "start": "1956559",
    "end": "1962159"
  },
  {
    "text": "don't trust algorithms to make subtle or large multi-variable judgments delphi is a perfect example of something i would",
    "start": "1962159",
    "end": "1967760"
  },
  {
    "text": "never trust an ai to handle until there's rapid change in the industry",
    "start": "1967760",
    "end": "1973759"
  },
  {
    "text": "you can also try combining um variables into composite variables and using those",
    "start": "1973919",
    "end": "1979519"
  },
  {
    "text": "as your dependent variable instead of just having profit build a convolution between profit and happiness and try and",
    "start": "1979519",
    "end": "1985279"
  },
  {
    "text": "predict that instead now there's a whole bunch of we go you know unpack the whole thing here about whether how you rate",
    "start": "1985279",
    "end": "1991279"
  },
  {
    "text": "happiness etc but that's potentially an option for you is to try and use these composite variables",
    "start": "1991279",
    "end": "1998240"
  },
  {
    "text": "last five is the simulation surprise",
    "start": "1998240",
    "end": "2002679"
  },
  {
    "text": "the simulation surprise happens when you are testing ai and machine learning in simulated environments so here's an",
    "start": "2005919",
    "end": "2011840"
  },
  {
    "text": "example a bunch of researchers took a simulated robot arm and they were",
    "start": "2011840",
    "end": "2016880"
  },
  {
    "text": "teaching it to basically pick up a box and move it um or they were hoping it would learn that their fitness algorithm",
    "start": "2016880",
    "end": "2022960"
  },
  {
    "text": "what they were measuring it on was how far did you move the box so it got pretty good at picking up the",
    "start": "2022960",
    "end": "2028960"
  },
  {
    "text": "box and moving it then they locked its grapper grasper together you know digitally so it's not",
    "start": "2028960",
    "end": "2034960"
  },
  {
    "text": "like they physically it's the sound of physical robots you can't just rubber band it but they stopped it in software from",
    "start": "2034960",
    "end": "2040480"
  },
  {
    "text": "moving its little gripper and they said all right now figure out how to move the box",
    "start": "2040480",
    "end": "2046399"
  },
  {
    "text": "and the robot said well okay what i'm going to do is hit my gripper",
    "start": "2046399",
    "end": "2052800"
  },
  {
    "text": "on the side this corner of this box or the corner of the environment rather and that's going to force the gripper",
    "start": "2052800",
    "end": "2058878"
  },
  {
    "text": "open because again it's not physically bound it's just a simulation right it's just like a video game so the physics of",
    "start": "2058879",
    "end": "2064240"
  },
  {
    "text": "the world is going to force the gripper open and then i'm going to pick up the box and move it",
    "start": "2064240",
    "end": "2069838"
  },
  {
    "text": "seems really smart right but it's obviously not what they were intending and not necessarily what would happen in",
    "start": "2070000",
    "end": "2077118"
  },
  {
    "text": "a real world scenario another example there were researchers who were trying to use visual um you know",
    "start": "2077119",
    "end": "2084480"
  },
  {
    "text": "machine learning and computer vision to determine whether something was poisonous or not to identify basically",
    "start": "2084480",
    "end": "2090320"
  },
  {
    "text": "is this a poisonous food or is this not a poisonous food but when they generated and trained the",
    "start": "2090320",
    "end": "2097040"
  },
  {
    "text": "data for these machine learning tools they passed these in a predictable order",
    "start": "2097040",
    "end": "2102560"
  },
  {
    "text": "so that it was always non-poisonous food and then poisonous food non-poisonous food poisonous food",
    "start": "2102560",
    "end": "2108160"
  },
  {
    "text": "what did the machine learning algorithm learn that you pick every other one as the poisonous food",
    "start": "2108160",
    "end": "2114880"
  },
  {
    "text": "because the simulation was that way this is the simulation surprise that",
    "start": "2114880",
    "end": "2121440"
  },
  {
    "text": "there are things when we build a simulation of an environment obviously it's less detailed than the real world",
    "start": "2121440",
    "end": "2126880"
  },
  {
    "text": "that's the point of a simulation it's easier it's cheaper etc right but it isn't the real world and there",
    "start": "2126880",
    "end": "2133040"
  },
  {
    "text": "are things about that simulation and the simulated data that these things these tools will pick up on",
    "start": "2133040",
    "end": "2138720"
  },
  {
    "text": "and learn that will not carry over into the real world if you try to use them so what can",
    "start": "2138720",
    "end": "2144640"
  },
  {
    "start": "2144000",
    "end": "2395000"
  },
  {
    "text": "you do about that well first you can be ready for it if you build something in a simulated environment if you're simulating training data you have to be",
    "start": "2144640",
    "end": "2152320"
  },
  {
    "text": "ready you have to be sure that your data doesn't have patterns in it as much as you can there's another example that came out um",
    "start": "2152320",
    "end": "2159119"
  },
  {
    "text": "from some of the uh this was pre-covered but there was a hospital that was trying to train",
    "start": "2159119",
    "end": "2164960"
  },
  {
    "text": "whether or not or train a computer vision to figure out whether or not a patient had cancer",
    "start": "2164960",
    "end": "2171359"
  },
  {
    "text": "based on whether or not they you know based on their their cat scans",
    "start": "2171359",
    "end": "2177599"
  },
  {
    "text": "problem was this hospital had two cat scanners one of them was in the normal portion of",
    "start": "2177599",
    "end": "2182720"
  },
  {
    "text": "the hospital the other was right near the acute ward so that they could get the acute patients the patients in",
    "start": "2182720",
    "end": "2187839"
  },
  {
    "text": "severe danger etc into the cat scanner very quickly and so there wasn't a way for the other one",
    "start": "2187839",
    "end": "2195440"
  },
  {
    "text": "the cat scans the output had text on it the images had text at the bottom",
    "start": "2195599",
    "end": "2200800"
  },
  {
    "text": "indicating which cat scanner it came from the machine learning algorithms learned",
    "start": "2200800",
    "end": "2206000"
  },
  {
    "text": "that it was way more likely for the cat scanner in the acute room to or the cute ward to have a person who",
    "start": "2206000",
    "end": "2214079"
  },
  {
    "text": "is cancerous than the actual other cat scanner it was a completely wasted example",
    "start": "2214079",
    "end": "2220880"
  },
  {
    "text": "because they didn't scrub this identifiable predictable data out of their data sets",
    "start": "2222079",
    "end": "2229280"
  },
  {
    "text": "you also need to learn not to confuse the map with the territory just because the simulation is behaving a certain way doesn't mean that reality",
    "start": "2229280",
    "end": "2235520"
  },
  {
    "text": "is going to behave in the same way right you'd think that would be obvious but you see people miss that all the",
    "start": "2235520",
    "end": "2240880"
  },
  {
    "text": "time additionally you do have to verify and check solutions derived from a simulation they're not something you can",
    "start": "2240880",
    "end": "2247839"
  },
  {
    "text": "just take and release into the real world for various obvious reasons all right let's move on to class six the",
    "start": "2247839",
    "end": "2254560"
  },
  {
    "text": "apparition of fairness let's imagine we're going to go to twitter and we're going to build",
    "start": "2254560",
    "end": "2260560"
  },
  {
    "text": "something that does natural language parsing whether we're building some kind of sentiment analysis we can tell hey a",
    "start": "2260560",
    "end": "2265760"
  },
  {
    "text": "lot of people like your tweet you know all these quote tweets are positive as opposed to negative um that's identifying your ratio",
    "start": "2265760",
    "end": "2272560"
  },
  {
    "text": "basically those tools or this tool that we're building might work fine for normal language but",
    "start": "2272560",
    "end": "2279520"
  },
  {
    "text": "what happens with dialectical language with for instance african-american english with southern slang with any",
    "start": "2279520",
    "end": "2286960"
  },
  {
    "text": "other dialect that happens to be exist for english how is that tool going to perform",
    "start": "2286960",
    "end": "2293599"
  },
  {
    "text": "if our corpus only contains a whole bunch of normal standard english quote-unquote standard english",
    "start": "2293599",
    "end": "2300400"
  },
  {
    "text": "it's obviously not going to perform very well but what's happening here",
    "start": "2300400",
    "end": "2307200"
  },
  {
    "text": "well one of the reasons that happens rather is that ai and machine learning tools are trained to minimize average loss",
    "start": "2307200",
    "end": "2312480"
  },
  {
    "text": "we talked about the correlation of two data sets before in the case of machine learning a lot of",
    "start": "2312480",
    "end": "2317680"
  },
  {
    "text": "the times it determines how well am i doing by effectively measuring the distance between",
    "start": "2317680",
    "end": "2323440"
  },
  {
    "text": "what you are saying it should be and what it actually outputs and then it works to minimize those gaps using",
    "start": "2323440",
    "end": "2329359"
  },
  {
    "text": "things like r squared or mean squared error etc those are all tools that help you minimize the average loss and that's a",
    "start": "2329359",
    "end": "2336079"
  },
  {
    "text": "normal fine way to evaluate data sets you can in our twitter example wind up",
    "start": "2336079",
    "end": "2343040"
  },
  {
    "text": "with a data set that supports and is works well for a large majority of people but it",
    "start": "2343040",
    "end": "2348880"
  },
  {
    "text": "doesn't necessarily work for a certain subset of folks or certain subsets of",
    "start": "2348880",
    "end": "2353920"
  },
  {
    "text": "folks this is called representation disparity",
    "start": "2353920",
    "end": "2358960"
  },
  {
    "text": "these systems can have a high overall accuracy but low accuracy for these subsets of people who are not",
    "start": "2358960",
    "end": "2364480"
  },
  {
    "text": "represented well in your sample space even if that's data is in the sample",
    "start": "2364480",
    "end": "2369920"
  },
  {
    "text": "space these things can decide effectively i mean i'm anthropomorphizing but what the",
    "start": "2369920",
    "end": "2375119"
  },
  {
    "text": "algorithm will do is effectively diminish the input of those the sample these subsets",
    "start": "2375119",
    "end": "2382000"
  },
  {
    "text": "and say well we're going to focus on broader accuracy",
    "start": "2382000",
    "end": "2386960"
  },
  {
    "text": "and this can be a problem if you want your tool to actually be egalitarian and you want it actually to be just",
    "start": "2387760",
    "end": "2395440"
  },
  {
    "start": "2395000",
    "end": "2638000"
  },
  {
    "text": "so what can you do about that well you can consider your predictive accuracy as a resource to be allocated",
    "start": "2395680",
    "end": "2402960"
  },
  {
    "text": "okay there are you have a certain amount of predictive accuracy that will come out of a machine learning tool you can",
    "start": "2403200",
    "end": "2410720"
  },
  {
    "text": "decide how you want that to be allocated across different um subsets of people different subsets of",
    "start": "2410720",
    "end": "2417200"
  },
  {
    "text": "the things in your data there's a tool to do this um hashimoto srivastava namcoon",
    "start": "2417200",
    "end": "2423760"
  },
  {
    "text": "in 2018 came out with a paper that described what they described called distributionally robust optimization",
    "start": "2423760",
    "end": "2429520"
  },
  {
    "text": "and that is a way to it's instead a replacement for the mean squared error replacement for",
    "start": "2429520",
    "end": "2436000"
  },
  {
    "text": "that minimizing excuse me minimizing aggregated error",
    "start": "2436000",
    "end": "2443040"
  },
  {
    "text": "i recommend you go look at the paper it's a great read it'll get into the details of how this thing actually works but it's a way for",
    "start": "2443119",
    "end": "2448880"
  },
  {
    "text": "you to turn around and say hey i don't have to just try and solve maximum accuracy for as many people as i can i",
    "start": "2448880",
    "end": "2456079"
  },
  {
    "text": "can kind of parcel that out into things that i want",
    "start": "2456079",
    "end": "2461040"
  },
  {
    "text": "the last class we're going to talk about today is the feedback devil so let's think about that for a second",
    "start": "2462160",
    "end": "2469920"
  },
  {
    "text": "let's take that nlp we were working with the one that doesn't work well for those dialect users and we're going to build a",
    "start": "2471200",
    "end": "2476640"
  },
  {
    "text": "product with it anyway i'm going to say all right it's fine this is going to work for the vast majority of users",
    "start": "2476640",
    "end": "2483040"
  },
  {
    "text": "and that's what we want what happens to the people who use the dialects",
    "start": "2483040",
    "end": "2488800"
  },
  {
    "text": "they're not really going to use our cool new product are they because it doesn't work well for them",
    "start": "2488800",
    "end": "2494160"
  },
  {
    "text": "well okay but if we're doing is gathering the data",
    "start": "2494160",
    "end": "2499200"
  },
  {
    "text": "from our users and feeding it back into our algorithm and retraining our algorithm and",
    "start": "2499200",
    "end": "2505200"
  },
  {
    "text": "basically building a learning system that takes in new data we're never going to get the data from those users we're never going to get",
    "start": "2505200",
    "end": "2511119"
  },
  {
    "text": "better at those subsets because they're not feeding their data into our system we've now created a",
    "start": "2511119",
    "end": "2516720"
  },
  {
    "text": "feedback loop so let's talk about predictive policing which is a thing that's been coming up",
    "start": "2516720",
    "end": "2522720"
  },
  {
    "text": "more and more and more in the world predictive policing is this tool that allows police to effectively it's",
    "start": "2522720",
    "end": "2529520"
  },
  {
    "text": "an algorithm basically predicts where crime is going to occur so let's describe what would happen here",
    "start": "2529520",
    "end": "2535040"
  },
  {
    "text": "you have a neighborhood in city skylines right you know average random city",
    "start": "2535040",
    "end": "2541920"
  },
  {
    "text": "this algorithm is going to turn around and say all right i'm picking this area for whatever reason based on my internal",
    "start": "2541920",
    "end": "2547119"
  },
  {
    "text": "evaluation this is going to be an area where crime will occur right i'm predicting crime will occur here",
    "start": "2547119",
    "end": "2554000"
  },
  {
    "text": "when that happens the response is to send police there",
    "start": "2554000",
    "end": "2559680"
  },
  {
    "text": "all right that's why they bought the algorithm so they can be there and be ready for this crime when police are in an area",
    "start": "2559680",
    "end": "2567200"
  },
  {
    "text": "they tend to find crime it's not necessarily that the crime is there or was uh increased it's that they're",
    "start": "2567200",
    "end": "2574079"
  },
  {
    "text": "finding crime because crime tends to happen a lot of places whether minor or not there's a lot of different laws",
    "start": "2574079",
    "end": "2580079"
  },
  {
    "text": "especially in the u.s that you can follow foul of without necessarily being aware of it and when those you know there are police",
    "start": "2580079",
    "end": "2586319"
  },
  {
    "text": "there so there are going to be arrests when those arrests happen they're recorded and that means that crime in",
    "start": "2586319",
    "end": "2593200"
  },
  {
    "text": "that area goes up but unquote the crime statistics now have gone up in that particular area so",
    "start": "2593200",
    "end": "2599200"
  },
  {
    "text": "that means that the algorithm is going to go crime is increasing here we should continue adding police to this spot to this",
    "start": "2599200",
    "end": "2605520"
  },
  {
    "text": "neighborhood this is now a feedback loop if this predictive tool has raised expectations",
    "start": "2605520",
    "end": "2611760"
  },
  {
    "text": "of crime in that neighborhood police can be more aggressive there in making arrests because they're expecting",
    "start": "2611760",
    "end": "2618720"
  },
  {
    "text": "crime they're ready for crime and in the end what you can do is almost",
    "start": "2618720",
    "end": "2623760"
  },
  {
    "text": "blight a neighborhood because the crime statistics will just continue to feed back upward and the people who live there start moving out",
    "start": "2623760",
    "end": "2630400"
  },
  {
    "text": "because the crime is now very high even when nothing actually",
    "start": "2630400",
    "end": "2635839"
  },
  {
    "text": "majorly criminal has happened so what can you do about feedback well this one's really really difficult",
    "start": "2635839",
    "end": "2643920"
  },
  {
    "start": "2638000",
    "end": "2929000"
  },
  {
    "text": "and i have not seen anyone try to address this in a larger scale sense yet um you can ignore or adjust for",
    "start": "2643920",
    "end": "2649680"
  },
  {
    "text": "algorithms suggested results for instance if you're building a shopping cart and you build a like amazon has",
    "start": "2649680",
    "end": "2655200"
  },
  {
    "text": "people who bought this also bought this ignore when people click and say i want",
    "start": "2655200",
    "end": "2660720"
  },
  {
    "text": "to add that to my cart because you don't want to build more correlation between those two",
    "start": "2660720",
    "end": "2666640"
  },
  {
    "text": "because if you do that you've created a feedback loop that now yeah more people buy these two together because you keep suggesting the two together",
    "start": "2666640",
    "end": "2674800"
  },
  {
    "text": "you can also try looking at control engineering instead of just looking at the actual feedback",
    "start": "2675760",
    "end": "2681760"
  },
  {
    "text": "loop itself build tools into your feedback loop to control it control like process engineering is this entire field",
    "start": "2681760",
    "end": "2688480"
  },
  {
    "text": "of engineering that exists just to control feedback loops and you have the option to turn around",
    "start": "2688480",
    "end": "2695200"
  },
  {
    "text": "and use that to control your own feedback loops inside of your system which of the inputs do you want to value",
    "start": "2695200",
    "end": "2700800"
  },
  {
    "text": "which of them do not all right bring this thing home",
    "start": "2700800",
    "end": "2707920"
  },
  {
    "text": "in summary for class one the phantom's a false correlation you know what questions you're asking and trust the conditional probability over straight",
    "start": "2709040",
    "end": "2715119"
  },
  {
    "text": "correlation for class two the specter of bias sample data recognize that data is biased even at rest and make sure your sample set is",
    "start": "2715119",
    "end": "2721440"
  },
  {
    "text": "crafted properly excise those problematic predictors but beware those shadow columns build a learning system that",
    "start": "2721440",
    "end": "2727280"
  },
  {
    "text": "incorporates false negatives and false positives as you find them try using adversarial techniques to detect bias",
    "start": "2727280",
    "end": "2733680"
  },
  {
    "text": "for class three remember that models tell you what was not what should be try combining dependent columns and",
    "start": "2733680",
    "end": "2738800"
  },
  {
    "text": "predicting that and try complex algorithms that allow more flexible reinforcement class five don't confuse the map with",
    "start": "2738800",
    "end": "2744960"
  },
  {
    "text": "that territory and always reality check solutions from your simulations",
    "start": "2744960",
    "end": "2750000"
  },
  {
    "text": "class six consider predictive accuracy as a resource to be allocated and possibly seek external auditing of your",
    "start": "2750000",
    "end": "2755119"
  },
  {
    "text": "results or at least another team evaluating it for class seven ignore or adjust for",
    "start": "2755119",
    "end": "2760640"
  },
  {
    "text": "those algorithms suggested results and look to control engineering for potential answers so all of this can sound hard and",
    "start": "2760640",
    "end": "2767359"
  },
  {
    "text": "overwhelming what can you do right now well the first thing kind of what i talked about at the beginning take time",
    "start": "2767359",
    "end": "2773200"
  },
  {
    "text": "to think about what it is you're solving what question are you solving who are you solving it for",
    "start": "2773200",
    "end": "2779119"
  },
  {
    "text": "whose data do you have and how was that data made what biases could it contain",
    "start": "2779119",
    "end": "2785839"
  },
  {
    "text": "think about those questions turn around and remember that models",
    "start": "2785839",
    "end": "2790880"
  },
  {
    "text": "represent what was they don't tell you what should be okay",
    "start": "2790880",
    "end": "2795920"
  },
  {
    "text": "you can also hire data scientists they will help take your stuff to a new",
    "start": "2795920",
    "end": "2801040"
  },
  {
    "text": "level they understand a lot of the things about how to avoid a lot of the biasing of data sets when you're doing sampling etc about how to actually make",
    "start": "2801040",
    "end": "2807920"
  },
  {
    "text": "sure you have representative data sets in the first place or you can get training on that yourself",
    "start": "2807920",
    "end": "2813520"
  },
  {
    "text": "there's bootcamps coursera udemy actual universities offering courses on things there are a ton of different places at",
    "start": "2813520",
    "end": "2819839"
  },
  {
    "text": "this point you can get data science learning as a base of you know a complete background or bottom to",
    "start": "2819839",
    "end": "2826000"
  },
  {
    "text": "actually build your machine learning skill set on you can also try finding others trying to",
    "start": "2826000",
    "end": "2831920"
  },
  {
    "text": "solve the same problems there are places like the ai now institute the georgetown law center on privacy and technology",
    "start": "2831920",
    "end": "2837280"
  },
  {
    "text": "knight foundation has an ai ethics initiative it's a website called fastai that has a lot of really interesting content and places like the algorithmic",
    "start": "2837280",
    "end": "2844160"
  },
  {
    "text": "justice league working to apply justice in build make justice into algorithms",
    "start": "2844160",
    "end": "2851599"
  },
  {
    "text": "find and abide by some set of ethics guidelines as you're doing data science things that ask questions like what is",
    "start": "2851599",
    "end": "2857839"
  },
  {
    "text": "the privacy of the data that you have have the people who've given you their data given consent to use it in that way",
    "start": "2857839",
    "end": "2864000"
  },
  {
    "text": "are you being transparent about the use of that data are you being transparent about the algorithms built on that data",
    "start": "2864000",
    "end": "2869599"
  },
  {
    "text": "and who owns the data is it you is it your customer who owns the resulting outcome the resulting",
    "start": "2869599",
    "end": "2876079"
  },
  {
    "text": "model and algorithm is it you not to be a corporate shill but",
    "start": "2876079",
    "end": "2882400"
  },
  {
    "text": "accenture actually has a really good page on this a really good pamphlet on",
    "start": "2882400",
    "end": "2888319"
  },
  {
    "text": "how to actually set up some universal data ethics i found this actually really fascinating and it can be a really good",
    "start": "2888319",
    "end": "2894480"
  },
  {
    "text": "baseline for how to go build your own set of data ethics and adhere to it at",
    "start": "2894480",
    "end": "2899599"
  },
  {
    "text": "your company like once you've done it hold yourself to it otherwise you did a bunch of work for nothing right",
    "start": "2899599",
    "end": "2906160"
  },
  {
    "text": "all right thank you very much for coming to listen to my talk i really appreciate it like i said the",
    "start": "2906559",
    "end": "2911599"
  },
  {
    "text": "resources are at that bitly link you can download the slides there's my twitter",
    "start": "2911599",
    "end": "2917839"
  },
  {
    "text": "my name is arthur doler and thank you very much for listening",
    "start": "2917839",
    "end": "2923800"
  },
  {
    "text": "you",
    "start": "2929200",
    "end": "2931280"
  }
]
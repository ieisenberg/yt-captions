[
  {
    "text": "so i'm going to talk about streaming first and then i'll talk about streaming with signalr streaming with",
    "start": "3840",
    "end": "10880"
  },
  {
    "text": "web api and streaming with grpc but we have to start with what streaming",
    "start": "10880",
    "end": "17520"
  },
  {
    "text": "is and what streaming isn't and for that we're going to open up a console window",
    "start": "17520",
    "end": "24240"
  },
  {
    "text": "and i'm going to demonstrate what streaming is it let me here's a spoiler alert it",
    "start": "24240",
    "end": "30400"
  },
  {
    "text": "doesn't have anything to do with system.io",
    "start": "30400",
    "end": "36760"
  },
  {
    "text": "system.iostream system.io memory stream network stream that's that's not streaming those are tools in",
    "start": "37320",
    "end": "44239"
  },
  {
    "text": "the.net framework uh that will help you do things",
    "start": "44239",
    "end": "49680"
  },
  {
    "text": "maybe maybe streaming maybe not but it they have nothing to do with what streaming is",
    "start": "49680",
    "end": "56520"
  },
  {
    "text": "yeah okay toolbox is empty yeah all right so i might be doing a little cutting and",
    "start": "59120",
    "end": "64559"
  },
  {
    "text": "pasting here so this is a document that i have um that was adopted from",
    "start": "64559",
    "end": "71119"
  },
  {
    "text": "a blazer train talk that i did i'll show you what blazer train is",
    "start": "71119",
    "end": "78159"
  },
  {
    "text": "it's basically a youtube show that i've been doing for the last couple of years",
    "start": "78159",
    "end": "83520"
  },
  {
    "text": "and this code",
    "start": "83520",
    "end": "88479"
  },
  {
    "text": "signalr",
    "start": "89200",
    "end": "92200"
  },
  {
    "text": "here we go signalr advanced signalr signalr streaming episode 66",
    "start": "101520",
    "end": "107040"
  },
  {
    "text": "there's a link there to download the code and that has everything that i'm going",
    "start": "107040",
    "end": "112640"
  },
  {
    "text": "to show you right here but we're going to start with this",
    "start": "112640",
    "end": "118399"
  },
  {
    "text": "little console application",
    "start": "118399",
    "end": "121920"
  },
  {
    "text": "okay so this is a very we're going to start off very simply",
    "start": "125680",
    "end": "132080"
  },
  {
    "text": "with a console application that calls this method get messages",
    "start": "132080",
    "end": "137520"
  },
  {
    "text": "i hope you can all see that",
    "start": "137520",
    "end": "141560"
  },
  {
    "text": "you can bump it up",
    "start": "143040",
    "end": "146000"
  },
  {
    "text": "control plus doesn't want to work either so we're calling this get messages right",
    "start": "155440",
    "end": "162080"
  },
  {
    "text": "get messages is going to return an i enumerable of message",
    "start": "162080",
    "end": "167120"
  },
  {
    "text": "and message is a simple class that has a text string property",
    "start": "167120",
    "end": "172560"
  },
  {
    "text": "so we're going to use a loop and we're going to create three messages",
    "start": "172560",
    "end": "178319"
  },
  {
    "text": "the text being hello whatever the number is 0 1 2. we're going to add those to a list of",
    "start": "178319",
    "end": "184800"
  },
  {
    "text": "messages and return that list yep this is the best way to start at",
    "start": "184800",
    "end": "190400"
  },
  {
    "text": "nine o'clock in the morning we're going to ease into this",
    "start": "190400",
    "end": "195640"
  },
  {
    "text": "first i'll just show the the app running and then we will walk through it and this will be our",
    "start": "201680",
    "end": "210319"
  },
  {
    "text": "base class and you can see that right",
    "start": "210840",
    "end": "215760"
  },
  {
    "text": "hello hello one hello to done so if we if we put a breakpoint here",
    "start": "216799",
    "end": "225720"
  },
  {
    "text": "run this again you should be able to do this in your mind by now i'm going to press f11",
    "start": "226799",
    "end": "234480"
  },
  {
    "text": "create the new list of messages iterate yes",
    "start": "234480",
    "end": "240480"
  },
  {
    "text": "add one add two",
    "start": "240480",
    "end": "246400"
  },
  {
    "text": "add three and return and then we iterate again",
    "start": "247040",
    "end": "253439"
  },
  {
    "text": "to show the messages in the console one two three okay",
    "start": "253439",
    "end": "259759"
  },
  {
    "text": "so streaming started uh in dot net",
    "start": "260799",
    "end": "266479"
  },
  {
    "text": "200 we had this ability to instead of",
    "start": "266479",
    "end": "271680"
  },
  {
    "text": "creating a list and returning the list we could just say",
    "start": "271680",
    "end": "278560"
  },
  {
    "text": "yield return message instead of going and waiting for them",
    "start": "278560",
    "end": "286400"
  },
  {
    "text": "all to happen so the first thing i'll do is yep we'll",
    "start": "286400",
    "end": "292320"
  },
  {
    "text": "we'll do this again now i'm going to press f11",
    "start": "292320",
    "end": "298479"
  },
  {
    "text": "which in visual studio will step into get messages right but",
    "start": "298479",
    "end": "304560"
  },
  {
    "text": "it does not it skips right over that because the compiler is smart enough to know hey",
    "start": "304560",
    "end": "310560"
  },
  {
    "text": "this get messages is doing a yield return so instead",
    "start": "310560",
    "end": "316639"
  },
  {
    "text": "we iterate once so here we go",
    "start": "316639",
    "end": "321680"
  },
  {
    "text": "messages i get the first one i wasn't doing f11",
    "start": "321680",
    "end": "329199"
  },
  {
    "text": "so f11 we get the second one",
    "start": "329199",
    "end": "335440"
  },
  {
    "text": "we go back for the third one",
    "start": "336720",
    "end": "341680"
  },
  {
    "text": "and now we have them all see the difference",
    "start": "343919",
    "end": "350080"
  },
  {
    "text": "so there's we're skipping in a level of iteration here and that's the really important thing",
    "start": "350240",
    "end": "356000"
  },
  {
    "text": "because i mean you think about it you're when you create the data you put it into a list you return the",
    "start": "356000",
    "end": "361840"
  },
  {
    "text": "list you go back you iterate through that list again so this way",
    "start": "361840",
    "end": "367280"
  },
  {
    "text": "there's one iteration where we're calling it we get one at a time",
    "start": "367280",
    "end": "374240"
  },
  {
    "text": "and that's what streaming is and it's been in c-sharp since",
    "start": "374240",
    "end": "379360"
  },
  {
    "text": "since dot net 2. so there's a new kid in town",
    "start": "379360",
    "end": "386080"
  },
  {
    "text": "in c sharp 8 called async streaming",
    "start": "386080",
    "end": "393000"
  },
  {
    "text": "that's what i just did here",
    "start": "395680",
    "end": "398960"
  },
  {
    "text": "and this code uses a new",
    "start": "401039",
    "end": "407000"
  },
  {
    "text": "async i async enumerable type",
    "start": "408880",
    "end": "415280"
  },
  {
    "text": "all right so let's start at the top here so h async streaming uses the iterator",
    "start": "416080",
    "end": "422400"
  },
  {
    "text": "pattern yield return with async so before this before c-sharp 8",
    "start": "422400",
    "end": "429840"
  },
  {
    "text": "you could not have a get messages that was async that did yield return",
    "start": "429840",
    "end": "435039"
  },
  {
    "text": "all right so without iasync innumerable you can't do this you can't do the iterator pattern with",
    "start": "435039",
    "end": "442240"
  },
  {
    "text": "async so that's the goodness that comes in c sharp 8.",
    "start": "442240",
    "end": "447840"
  },
  {
    "text": "so because it's a sync your ui can start working with the data as soon as it gets",
    "start": "447840",
    "end": "453520"
  },
  {
    "text": "the first piece of it and the benefit is perceived performance",
    "start": "453520",
    "end": "460160"
  },
  {
    "text": "because the user sees the first pieces of data first and if you have a large set to show the",
    "start": "460160",
    "end": "465759"
  },
  {
    "text": "user they're going to see whatever they need to see right away and they're not waiting for a big list",
    "start": "465759",
    "end": "471280"
  },
  {
    "text": "to come right so that's the goodness here it's a pull operation and not a push",
    "start": "471280",
    "end": "480080"
  },
  {
    "text": "we've had signal our streaming for a while using the channels",
    "start": "480080",
    "end": "485440"
  },
  {
    "text": "and i'm going to show you that but that's a push operation so async streaming is a pull",
    "start": "485440",
    "end": "491520"
  },
  {
    "text": "we're asking for the data we're getting the data this is a key right here it's not about",
    "start": "491520",
    "end": "497599"
  },
  {
    "text": "performance async streaming it's not in fact your performance may degrade",
    "start": "497599",
    "end": "503280"
  },
  {
    "text": "it's about perceived performance and scalability that's what we're after here",
    "start": "503280",
    "end": "511199"
  },
  {
    "text": "so now instead of doing for each we're doing await for each",
    "start": "511199",
    "end": "516959"
  },
  {
    "text": "a wait for each var message in get messages get messages",
    "start": "516959",
    "end": "522240"
  },
  {
    "text": "is that same method but now it's using an i asynch enumerable of",
    "start": "522240",
    "end": "528640"
  },
  {
    "text": "message so iasync innumerable is not a task",
    "start": "528640",
    "end": "535279"
  },
  {
    "text": "because you know in async world we use tasks it's a value task",
    "start": "535279",
    "end": "541519"
  },
  {
    "text": "and value tasks without going too far into the tech a value task should be used whenever you",
    "start": "541519",
    "end": "548080"
  },
  {
    "text": "want to return a lot of something every time you create a task you're using uh memory",
    "start": "548080",
    "end": "555040"
  },
  {
    "text": "in gen 1 in the gen 1 memory space and so those have to be deallocated",
    "start": "555040",
    "end": "561120"
  },
  {
    "text": "but with a value task it's much more lightweight and doesn't create any gen 1",
    "start": "561120",
    "end": "567200"
  },
  {
    "text": "allocations so iasync innumerable you can think of it as",
    "start": "567200",
    "end": "573920"
  },
  {
    "text": "you don't have to say task of i sync your numerable because it is a task it's a value task",
    "start": "573920",
    "end": "579600"
  },
  {
    "text": "so the signature is simply async i think innumerable of whatever you're returning",
    "start": "579600",
    "end": "586560"
  },
  {
    "text": "and then inside you do a yield return and that's that's it",
    "start": "586560",
    "end": "593040"
  },
  {
    "text": "so let's let's walk through this",
    "start": "593040",
    "end": "597839"
  },
  {
    "text": "we'll start right here",
    "start": "600080",
    "end": "603959"
  },
  {
    "text": "all right f11 f11 right just have something async in here",
    "start": "606880",
    "end": "614160"
  },
  {
    "text": "get our first message yield return",
    "start": "614160",
    "end": "619200"
  },
  {
    "text": "back in the client show it",
    "start": "619200",
    "end": "623839"
  },
  {
    "text": "next message",
    "start": "625920",
    "end": "629240"
  },
  {
    "text": "show it etc so a console app doesn't you know really",
    "start": "632480",
    "end": "638320"
  },
  {
    "text": "show off uh you know this thing so what we're really going to do is show you how to",
    "start": "638320",
    "end": "643839"
  },
  {
    "text": "use this idea use this iasync enumerable to return signalr data",
    "start": "643839",
    "end": "650560"
  },
  {
    "text": "to return web api data and the same data from grpc",
    "start": "650560",
    "end": "657839"
  },
  {
    "text": "okay so i'm starting with a blazer server application",
    "start": "658839",
    "end": "667440"
  },
  {
    "text": "called server signalr streaming demo",
    "start": "667440",
    "end": "672240"
  },
  {
    "text": "still don't know what happened to my toolbox okay",
    "start": "672959",
    "end": "679120"
  },
  {
    "text": "no problem [Music] and signalr streaming demo",
    "start": "679120",
    "end": "685920"
  },
  {
    "text": "is going to need",
    "start": "685920",
    "end": "689839"
  },
  {
    "text": "a signalr client this is the blazer server app so it's going to be pretty easy to demo",
    "start": "691519",
    "end": "699199"
  },
  {
    "text": "all right so we need the asp.net core signal our client library because even though",
    "start": "707120",
    "end": "713200"
  },
  {
    "text": "signalr is built into asp.net core it's just the server side that's built in",
    "start": "713200",
    "end": "718560"
  },
  {
    "text": "if we want to act as a client to call into a signalr hub we need this",
    "start": "718560",
    "end": "724000"
  },
  {
    "text": "and next you gotta make some changes to",
    "start": "724000",
    "end": "729360"
  },
  {
    "text": "program cs",
    "start": "729360",
    "end": "732480"
  },
  {
    "text": "i've got some global usings in there which are my new best friend our signalr",
    "start": "738079",
    "end": "745519"
  },
  {
    "text": "client we're calling add signalr right there",
    "start": "745519",
    "end": "750959"
  },
  {
    "text": "and with response compression just so that we can get as much performance out of this as possible",
    "start": "750959",
    "end": "757680"
  },
  {
    "text": "and then we map the hub stream hub which i haven't done yet to slash stream hub so let's add",
    "start": "757680",
    "end": "765200"
  },
  {
    "text": "that",
    "start": "765200",
    "end": "767440"
  },
  {
    "text": "so signalr streaming has been around for a while but it's been sort of a",
    "start": "770320",
    "end": "776720"
  },
  {
    "text": "they had to invent a new mechanism to do this so they're using the channel mechanism signalr channels",
    "start": "776720",
    "end": "782959"
  },
  {
    "text": "and um well you'll see the difference i think the the new way is much cleaner",
    "start": "782959",
    "end": "791360"
  },
  {
    "text": "here's our stream hub",
    "start": "793760",
    "end": "797720"
  },
  {
    "text": "so if you're not familiar with signalr hubs what this does is it acts as a sort of a",
    "start": "801839",
    "end": "807760"
  },
  {
    "text": "single point a single server if you will that clients can call into",
    "start": "807760",
    "end": "813519"
  },
  {
    "text": "and the magic of the hub is that it can then turn around and send messages to every other client that's connected to",
    "start": "813519",
    "end": "820000"
  },
  {
    "text": "it you could send messages to all clients including the sender",
    "start": "820000",
    "end": "825040"
  },
  {
    "text": "you could just send a message back to the sender you could send a message to all others in other words sort of a broadcast to",
    "start": "825040",
    "end": "832560"
  },
  {
    "text": "every other client and also if you have the connection id of a particular client you could just",
    "start": "832560",
    "end": "838800"
  },
  {
    "text": "send a private message to that user and it uses web sockets under the hood",
    "start": "838800",
    "end": "845279"
  },
  {
    "text": "so all port 80 all very easy to use there's no configuration and the clients can be anywhere",
    "start": "845279",
    "end": "852320"
  },
  {
    "text": "you could have javascript clients you'd have c-sharp clients on any platform",
    "start": "852320",
    "end": "857680"
  },
  {
    "text": "um any type of application mobile web you got you name it",
    "start": "857680",
    "end": "864560"
  },
  {
    "text": "all right so we'll come back to the hub here",
    "start": "864560",
    "end": "869160"
  },
  {
    "text": "and i'll explain the code um yeah so we're going to use channels",
    "start": "870240",
    "end": "876480"
  },
  {
    "text": "here and this is just sort of explaining things",
    "start": "876480",
    "end": "881680"
  },
  {
    "text": "all right so blazer code",
    "start": "881680",
    "end": "886959"
  },
  {
    "text": "so this goes into imports razer so that we can access it from",
    "start": "890399",
    "end": "895519"
  },
  {
    "text": "our index page and then here we go",
    "start": "895519",
    "end": "902320"
  },
  {
    "text": "change index",
    "start": "902720",
    "end": "906279"
  },
  {
    "text": "wait for everything to wake up and yeah i guess i can start with this code right here so uninitialized async",
    "start": "916800",
    "end": "924399"
  },
  {
    "text": "happens first",
    "start": "924399",
    "end": "927800"
  },
  {
    "text": "and what we're doing here is we're creating the connection with an absolute url",
    "start": "936959",
    "end": "943600"
  },
  {
    "text": "since it's all one application it's no big deal stream hub we start the hub",
    "start": "943600",
    "end": "949440"
  },
  {
    "text": "and then we have our handlers for messages so this one handles the message receive",
    "start": "949440",
    "end": "955759"
  },
  {
    "text": "channel stream data and i've got a a field here called",
    "start": "955759",
    "end": "961279"
  },
  {
    "text": "receive channel message and um invoking state has changed",
    "start": "961279",
    "end": "966959"
  },
  {
    "text": "and another one receive async stream data this one is the channel version this is",
    "start": "966959",
    "end": "972320"
  },
  {
    "text": "the async version but they do uh exactly the same thing we'll get to those in a second",
    "start": "972320",
    "end": "979120"
  },
  {
    "text": "and what i guess i'm going to do is just run this to show you what it does",
    "start": "979120",
    "end": "984399"
  },
  {
    "text": "i think that makes it easier when you're looking at the code to sort of understand what you've seen",
    "start": "984399",
    "end": "990560"
  },
  {
    "text": "first",
    "start": "990560",
    "end": "993560"
  },
  {
    "text": "and i'm going to create two windows here",
    "start": "1006320",
    "end": "1011079"
  },
  {
    "text": "okay so we're using the two methods that signal our does streaming one is a push",
    "start": "1012480",
    "end": "1018079"
  },
  {
    "text": "and one is a pull this one's a push the get channel stream and we're just",
    "start": "1018079",
    "end": "1023120"
  },
  {
    "text": "receiving ten numbers and then stopping and the same over here and these are",
    "start": "1023120",
    "end": "1028720"
  },
  {
    "text": "completely independent of each other the async stream works the same way",
    "start": "1028720",
    "end": "1034480"
  },
  {
    "text": "uh it does the same thing but it does it with less code and then we also have the",
    "start": "1034480",
    "end": "1039839"
  },
  {
    "text": "ability in signalr to stream from a client to to the hub and then the",
    "start": "1039839",
    "end": "1045600"
  },
  {
    "text": "hub can turn around and push out the data to everyone else so that's what we're doing here",
    "start": "1045600",
    "end": "1052960"
  },
  {
    "text": "one is using channels and the other is using async",
    "start": "1052960",
    "end": "1059280"
  },
  {
    "text": "okay but they're doing the same thing i don't know if you can see but the these are fields are updating once a",
    "start": "1059280",
    "end": "1065280"
  },
  {
    "text": "second so basically we're streaming to the hub",
    "start": "1065280",
    "end": "1070559"
  },
  {
    "text": "the hub turns around and sends data to everyone else",
    "start": "1070559",
    "end": "1075840"
  },
  {
    "text": "all right let's look at the hub first",
    "start": "1076559",
    "end": "1083280"
  },
  {
    "text": "this is using channels and channels are as i said before the the old way to do",
    "start": "1083919",
    "end": "1090080"
  },
  {
    "text": "streaming in signalr this is a method called get channel stream where we pass in a count and a",
    "start": "1090080",
    "end": "1097520"
  },
  {
    "text": "delay how many times do we want to you know create a number and what's the delay between them and a cancellation",
    "start": "1097520",
    "end": "1104000"
  },
  {
    "text": "token which you can use to stop things the first thing we're doing is creating",
    "start": "1104000",
    "end": "1109360"
  },
  {
    "text": "a bounded channel and again this is all old stuff you probably will never if you've never done",
    "start": "1109360",
    "end": "1115679"
  },
  {
    "text": "it by now you probably won't you'll be using the async i just want to show you the difference",
    "start": "1115679",
    "end": "1121360"
  },
  {
    "text": "a bounded channel has a limit so we're saying this is a channel that we're going to send 10 items",
    "start": "1121360",
    "end": "1127840"
  },
  {
    "text": "and it's event so 10 integers okay um and then we're calling this write",
    "start": "1127840",
    "end": "1134080"
  },
  {
    "text": "items async and returning the reader",
    "start": "1134080",
    "end": "1139360"
  },
  {
    "text": "so write items async does the work and we just have a loop",
    "start": "1139360",
    "end": "1145840"
  },
  {
    "text": "and we're calling writer.writeasync that number and then delaying with the",
    "start": "1145840",
    "end": "1152559"
  },
  {
    "text": "weight task delay right so we're pushing data out",
    "start": "1152559",
    "end": "1158080"
  },
  {
    "text": "to the client now in contrast",
    "start": "1158080",
    "end": "1163280"
  },
  {
    "text": "let's look at the i sink enumerable right",
    "start": "1163280",
    "end": "1168720"
  },
  {
    "text": "we're now we're using c sharp eight i async enumerable",
    "start": "1168720",
    "end": "1174240"
  },
  {
    "text": "and here we've got our count and we're yield returning the number",
    "start": "1174240",
    "end": "1181200"
  },
  {
    "text": "and delay so all in one small set of code",
    "start": "1181200",
    "end": "1187600"
  },
  {
    "text": "and again it's a pull it's a pull operation not a push operation so the",
    "start": "1187600",
    "end": "1193600"
  },
  {
    "text": "client is in control of this just like when we did the console app and we called get messages and yield",
    "start": "1193600",
    "end": "1199919"
  },
  {
    "text": "return returns the data it's the same exact thing except we've got you know the internet between us now",
    "start": "1199919",
    "end": "1207520"
  },
  {
    "text": "okay uh so going to",
    "start": "1207520",
    "end": "1213039"
  },
  {
    "text": "index razor let's go up here and we've got our get channel",
    "start": "1213039",
    "end": "1220480"
  },
  {
    "text": "stream for the first button let's look at what that looks like",
    "start": "1220480",
    "end": "1227440"
  },
  {
    "text": "all right so we've got a our channel message and the button text because we're going to stop it",
    "start": "1228080",
    "end": "1234720"
  },
  {
    "text": "so let's make sure we have a connection and then",
    "start": "1234720",
    "end": "1240880"
  },
  {
    "text": "we create a channel from the hub right specifying we want to receive 10",
    "start": "1240880",
    "end": "1246480"
  },
  {
    "text": "consecutive events exactly 500 milliseconds apart so this is actually calling",
    "start": "1246480",
    "end": "1253120"
  },
  {
    "text": "stream as channel async on the hub and that gives us a channel",
    "start": "1253120",
    "end": "1259120"
  },
  {
    "text": "and then we wait because the channel is pushing to us we're waiting to read",
    "start": "1259120",
    "end": "1264880"
  },
  {
    "text": "and then we do a try read and if we get some data we're going to say hey we receive this",
    "start": "1264880",
    "end": "1270960"
  },
  {
    "text": "data and update okay now in contrast",
    "start": "1270960",
    "end": "1277640"
  },
  {
    "text": "here's the get async stream we're going to connect we're going to",
    "start": "1278159",
    "end": "1283200"
  },
  {
    "text": "return a stream from the hub",
    "start": "1283200",
    "end": "1287440"
  },
  {
    "text": "yep and so that's an iesync enumerable of int and then we're just awaiting for each",
    "start": "1289520",
    "end": "1299200"
  },
  {
    "text": "receiving the data and calling state has changed a lot more simple",
    "start": "1299360",
    "end": "1306480"
  },
  {
    "text": "to go down to the sending you know streaming channels from",
    "start": "1307440",
    "end": "1312880"
  },
  {
    "text": "client to server let's go there",
    "start": "1312880",
    "end": "1317159"
  },
  {
    "text": "so we're creating the channel this is an unbounded channel because we're not going to stop until",
    "start": "1318559",
    "end": "1325200"
  },
  {
    "text": "the user stops right so it's unbounded doesn't have a limit",
    "start": "1325200",
    "end": "1330320"
  },
  {
    "text": "and it's with strings so we're going to say upload stream to channel",
    "start": "1330320",
    "end": "1336240"
  },
  {
    "text": "and we also need a sort of a flag to so that the user can set it to tell us to",
    "start": "1337919",
    "end": "1343520"
  },
  {
    "text": "stop right like a cancellation token but different and so when we set that",
    "start": "1343520",
    "end": "1349440"
  },
  {
    "text": "we're going to stop so just going through a loop here and using the writer",
    "start": "1349440",
    "end": "1355440"
  },
  {
    "text": "the channel writer to write async pushing to the server right",
    "start": "1355440",
    "end": "1361720"
  },
  {
    "text": "in contrast when we stream to the service to the server",
    "start": "1362080",
    "end": "1369280"
  },
  {
    "text": "we're calling send async upload stream and we're",
    "start": "1369280",
    "end": "1374480"
  },
  {
    "text": "passing as an argument client stream data which guess what that's our isync enumerable",
    "start": "1374480",
    "end": "1382000"
  },
  {
    "text": "and that is going to use you guessed it yield return",
    "start": "1382880",
    "end": "1388039"
  },
  {
    "text": "all right so that's enough signalr i think you get it that uh this is what streaming",
    "start": "1390320",
    "end": "1396480"
  },
  {
    "text": "does but the really dramatic result will be when we show",
    "start": "1396480",
    "end": "1402960"
  },
  {
    "text": "uh using web api and grpc so i've got this existing demo that i",
    "start": "1402960",
    "end": "1409039"
  },
  {
    "text": "wrote when i was testing grpc and the performance versus web api",
    "start": "1409039",
    "end": "1416799"
  },
  {
    "text": "and i'll start with that and what it does is i created this dummy data set of",
    "start": "1416799",
    "end": "1423440"
  },
  {
    "text": "5 000 person objects you know with a couple of fields in there just with you know like",
    "start": "1423440",
    "end": "1430000"
  },
  {
    "text": "the latin word generator kind of thing just so that we have some data",
    "start": "1430000",
    "end": "1435279"
  },
  {
    "text": "and then i tested it with web api and using grpc now grpc",
    "start": "1435279",
    "end": "1441919"
  },
  {
    "text": "started as a a way to do remote procedure calls in a for web services",
    "start": "1441919",
    "end": "1447760"
  },
  {
    "text": "i'm sorry for micro services and you know first server to server kind of thing because it's what is the",
    "start": "1447760",
    "end": "1454640"
  },
  {
    "text": "fastest way i can communicate from this guy over to that guy",
    "start": "1454640",
    "end": "1460000"
  },
  {
    "text": "and it started at google but if you look up grpc on the web",
    "start": "1460000",
    "end": "1466000"
  },
  {
    "text": "and there's a section what does it stand for it's a it stands for",
    "start": "1466000",
    "end": "1471120"
  },
  {
    "text": "grpc remote procedure calls so it's yeah okay but we know it used to stand",
    "start": "1471120",
    "end": "1477120"
  },
  {
    "text": "for google right but google doesn't own it um",
    "start": "1477120",
    "end": "1482720"
  },
  {
    "text": "so it's uh it's completely open source and it's completely cross-platform",
    "start": "1482720",
    "end": "1487919"
  },
  {
    "text": "and so what they did is they created this language that was sort of platform agnostic",
    "start": "1487919",
    "end": "1493200"
  },
  {
    "text": "and a platform agnostic way to define uh classes or messages they call them",
    "start": "1493200",
    "end": "1499919"
  },
  {
    "text": "and services and so then it's up to each platform to do code generation to implement",
    "start": "1499919",
    "end": "1507440"
  },
  {
    "text": "those classes however the platform does and the services that are used to do the",
    "start": "1507440",
    "end": "1514400"
  },
  {
    "text": "communication so i'll show you",
    "start": "1514400",
    "end": "1519919"
  },
  {
    "text": "one more time i'll show you the code work running and then we'll go dissect it and you can",
    "start": "1519919",
    "end": "1525200"
  },
  {
    "text": "understand it so remember this one started just as a way to test the performance of",
    "start": "1525200",
    "end": "1532400"
  },
  {
    "text": "grpc versus web api so i simply have a website",
    "start": "1532400",
    "end": "1537840"
  },
  {
    "text": "that uh downloads these 5 000 records using each",
    "start": "1537840",
    "end": "1543919"
  },
  {
    "text": "method and then you know measures the performance",
    "start": "1543919",
    "end": "1549360"
  },
  {
    "text": "so this one is the api now",
    "start": "1550159",
    "end": "1555760"
  },
  {
    "text": "here's the thing we're probably not going to be going to get 5000 records",
    "start": "1555760",
    "end": "1561679"
  },
  {
    "text": "for our users right raise your hand repeat after me i will not",
    "start": "1561679",
    "end": "1566960"
  },
  {
    "text": "give the user 5 000 records yeah okay so um",
    "start": "1566960",
    "end": "1573279"
  },
  {
    "text": "but it's a good test so the second time i don't know if you can see that but it's 18",
    "start": "1573279",
    "end": "1579760"
  },
  {
    "text": "uh 1824 milliseconds or 1.8 seconds the first time it was two something for",
    "start": "1579760",
    "end": "1585520"
  },
  {
    "text": "the api so you just have to you know it's compiling and all that stuff it's always going to be faster the second time grpc",
    "start": "1585520",
    "end": "1593679"
  },
  {
    "text": "whoa 515 milliseconds the second time",
    "start": "1593679",
    "end": "1599400"
  },
  {
    "text": "331 milliseconds now you're thinking hey maybe i can return 5000 records",
    "start": "1599400",
    "end": "1606880"
  },
  {
    "text": "to my user if that's what they want and they pay me for it and then i also just have a demo to get",
    "start": "1606880",
    "end": "1613279"
  },
  {
    "text": "a random person with grpc um so that is performance",
    "start": "1613279",
    "end": "1619360"
  },
  {
    "text": "but let's talk about streaming so",
    "start": "1619360",
    "end": "1624480"
  },
  {
    "text": "the first of all let me just show you what the data is here we have our",
    "start": "1624480",
    "end": "1630720"
  },
  {
    "text": "person class which i don't actually have because when you use grpc",
    "start": "1630720",
    "end": "1637679"
  },
  {
    "text": "it gets generated for you so in grpc you've got",
    "start": "1637679",
    "end": "1643760"
  },
  {
    "text": "a person message right here so we've got an int id we've got a",
    "start": "1643760",
    "end": "1650720"
  },
  {
    "text": "string first name a last name a bio and a photo url",
    "start": "1650720",
    "end": "1656000"
  },
  {
    "text": "so when you use this it behind the scenes will create the person class and this is one of the",
    "start": "1656000",
    "end": "1661440"
  },
  {
    "text": "issues with using grpc is where do my ma i can't where are my models right",
    "start": "1661440",
    "end": "1666640"
  },
  {
    "text": "you can only have one model called person so this is generating it and you don't",
    "start": "1666640",
    "end": "1672640"
  },
  {
    "text": "really see it anymore all right um also notice the numbers id equals one",
    "start": "1672640",
    "end": "1678880"
  },
  {
    "text": "first name equals two last name equals three it was because grpc uses a binary",
    "start": "1678880",
    "end": "1684080"
  },
  {
    "text": "serialization protocol and it's really tight and it does things by ordinal by position it doesn't know",
    "start": "1684080",
    "end": "1691440"
  },
  {
    "text": "names of things doesn't like json it doesn't have the names and the strings and things in there",
    "start": "1691440",
    "end": "1697279"
  },
  {
    "text": "it's all by ordinal and for every grpc request",
    "start": "1697279",
    "end": "1703440"
  },
  {
    "text": "every every service endpoint which is defined here with the service keyword",
    "start": "1703440",
    "end": "1709039"
  },
  {
    "text": "um you've got one request message type and one reply message type",
    "start": "1709039",
    "end": "1716000"
  },
  {
    "text": "always there aren't it's not as flexible as say web api",
    "start": "1716000",
    "end": "1722720"
  },
  {
    "text": "but that's it so we have a get all and we have a get person by id so get all people request is defined as",
    "start": "1722720",
    "end": "1729039"
  },
  {
    "text": "an empty message an empty class it doesn't matter if you're not going to send anything you still have to make an",
    "start": "1729039",
    "end": "1735679"
  },
  {
    "text": "empty class if you're even if there are no arguments",
    "start": "1735679",
    "end": "1741200"
  },
  {
    "text": "so this is the proto file in grpc that is for the service",
    "start": "1741200",
    "end": "1747520"
  },
  {
    "text": "now here's the people service itself which was generated",
    "start": "1747520",
    "end": "1753600"
  },
  {
    "text": "by grpc web and grpc web is a sort of an http version of",
    "start": "1753600",
    "end": "1761039"
  },
  {
    "text": "grpc so it wasn't until grpc web came around",
    "start": "1761039",
    "end": "1766240"
  },
  {
    "text": "for net that we could use this in a client to call into a service so that's that's",
    "start": "1766240",
    "end": "1771679"
  },
  {
    "text": "what i'm using here grpc web uh and so remember this is all generated",
    "start": "1771679",
    "end": "1778080"
  },
  {
    "text": "i didn't have to um oh wait a second no people service wasn't generated you had",
    "start": "1778080",
    "end": "1784080"
  },
  {
    "text": "you do have to implement this but it has to be based on people base",
    "start": "1784080",
    "end": "1790240"
  },
  {
    "text": "and all these methods are virtual so you're overriding the methods",
    "start": "1790240",
    "end": "1795279"
  },
  {
    "text": "okay so that's what we're doing here now compare this with the person's",
    "start": "1795279",
    "end": "1801200"
  },
  {
    "text": "controller in web api and in both of these i'm using a",
    "start": "1801200",
    "end": "1806320"
  },
  {
    "text": "person's manager which i created and get all we're just returning",
    "start": "1806320",
    "end": "1812159"
  },
  {
    "text": "persons manager people so the person's manager",
    "start": "1812159",
    "end": "1817440"
  },
  {
    "text": "just wraps around that people.json file and just returns the whole the whole",
    "start": "1817440",
    "end": "1823440"
  },
  {
    "text": "thing as a list very very simple uh on the client side i've got an api",
    "start": "1823440",
    "end": "1831200"
  },
  {
    "text": "service for calling the web api and here's my get all you've probably",
    "start": "1831200",
    "end": "1836559"
  },
  {
    "text": "seen this and done this a million times but there it is get a sync persons",
    "start": "1836559",
    "end": "1843919"
  },
  {
    "text": "deserialize it to a list of person",
    "start": "1843919",
    "end": "1849720"
  },
  {
    "text": "but i'm calling the the code for uh",
    "start": "1850559",
    "end": "1855600"
  },
  {
    "text": "for grpc directly so what i'm doing here in index",
    "start": "1855600",
    "end": "1860720"
  },
  {
    "text": "you know my page is i'm injecting the api service so i can call the api",
    "start": "1860720",
    "end": "1865840"
  },
  {
    "text": "and i'm injecting the people client which gets generated for me",
    "start": "1865840",
    "end": "1872399"
  },
  {
    "text": "by grpc so test api",
    "start": "1872399",
    "end": "1878480"
  },
  {
    "text": "we create we we save the date time right as start time we call get all",
    "start": "1878480",
    "end": "1885519"
  },
  {
    "text": "and then we calculate the elapsed time and we have our results",
    "start": "1885519",
    "end": "1891600"
  },
  {
    "text": "which is just a string that says this many records returned in this many",
    "start": "1891600",
    "end": "1897200"
  },
  {
    "text": "milliseconds the grpc is pretty similar except we're calling",
    "start": "1897200",
    "end": "1904159"
  },
  {
    "text": "peopleclient.c with a new get all people request which has nothing in it remember",
    "start": "1904159",
    "end": "1910880"
  },
  {
    "text": "and then if that list is null we do the same thing we just test it",
    "start": "1910880",
    "end": "1918000"
  },
  {
    "text": "all right so that is the code as it is let's add some streaming to it",
    "start": "1918000",
    "end": "1925360"
  },
  {
    "text": "and all this blah blah blah is what i just went over",
    "start": "1930320",
    "end": "1935799"
  },
  {
    "text": "all right here we go so we're looking at the protofile yeah this is the class that gets created",
    "start": "1938080",
    "end": "1947240"
  },
  {
    "text": "uh so here we go we're going to add to the person's controller on the api",
    "start": "1949279",
    "end": "1954320"
  },
  {
    "text": "side and async stream endpoint",
    "start": "1954320",
    "end": "1961278"
  },
  {
    "text": "guess what this is going to look like i sink enumerable",
    "start": "1961679",
    "end": "1968080"
  },
  {
    "text": "right couldn't be easier in web api",
    "start": "1968320",
    "end": "1975480"
  },
  {
    "text": "so we're getting all the people and we're yield returning them one at a time",
    "start": "1976399",
    "end": "1983039"
  },
  {
    "text": "so now here's the service call",
    "start": "1989200",
    "end": "1993679"
  },
  {
    "text": "from api service on the client",
    "start": "1994320",
    "end": "1999360"
  },
  {
    "text": "it's going to look like this and yep this is a little weird because",
    "start": "2001600",
    "end": "2009440"
  },
  {
    "text": "i don't think that the the json tools have caught up yet",
    "start": "2009440",
    "end": "2014960"
  },
  {
    "text": "for all the streaming this is what i had to do with newtonsoft json i created a json serializer",
    "start": "2014960",
    "end": "2022960"
  },
  {
    "text": "so i get my stream from getstream async and you know i guess i lied",
    "start": "2022960",
    "end": "2029200"
  },
  {
    "text": "i do use system i o stream in here but you get the idea right it's not that's not what streaming is",
    "start": "2029200",
    "end": "2035679"
  },
  {
    "text": "this is just to return some data so now i'm creating a stream reader",
    "start": "2035679",
    "end": "2042480"
  },
  {
    "text": "from that stream and now because json",
    "start": "2042480",
    "end": "2048320"
  },
  {
    "text": "uh treats a json string as a series of tokens which are read one at a time",
    "start": "2048320",
    "end": "2053520"
  },
  {
    "text": "and there's uh two tokens that i have to ignore start array and end array before",
    "start": "2053520",
    "end": "2058720"
  },
  {
    "text": "i can deserialize and so that's what we're doing",
    "start": "2058720",
    "end": "2063919"
  },
  {
    "text": "and we're just getting one person at a time deserializing that without the start and",
    "start": "2063919",
    "end": "2070560"
  },
  {
    "text": "end array tokens",
    "start": "2070560",
    "end": "2074440"
  },
  {
    "text": "okay now over to grpc",
    "start": "2076000",
    "end": "2082240"
  },
  {
    "text": "oh and we're going to replace the contents of index razor yeah let's do that",
    "start": "2084159",
    "end": "2089839"
  },
  {
    "text": "new demo and we'll come back to you",
    "start": "2091440",
    "end": "2099639"
  },
  {
    "text": "okay so on the grpc side we go to the proto file",
    "start": "2106560",
    "end": "2114560"
  },
  {
    "text": "where this where the service is defined and we're adding a new remote procedure",
    "start": "2114560",
    "end": "2120160"
  },
  {
    "text": "call called get all stream and this time instead of returning a",
    "start": "2120160",
    "end": "2125680"
  },
  {
    "text": "people reply which has the which is essentially an array right repeated",
    "start": "2125680",
    "end": "2131359"
  },
  {
    "text": "is the generic protobuf word that defines an array",
    "start": "2131359",
    "end": "2136400"
  },
  {
    "text": "or a collection um we're returning stream",
    "start": "2136400",
    "end": "2141839"
  },
  {
    "text": "of person all right so this is the the generic grpc way to say hey we want to",
    "start": "2141839",
    "end": "2149040"
  },
  {
    "text": "return a stream and then",
    "start": "2149040",
    "end": "2157079"
  },
  {
    "text": "yep we add this to people service because now when we compile we've got a new virtual",
    "start": "2158000",
    "end": "2163359"
  },
  {
    "text": "method in people service that we can override",
    "start": "2163359",
    "end": "2168240"
  },
  {
    "text": "that's the controller here's people service",
    "start": "2169119",
    "end": "2173839"
  },
  {
    "text": "okay so this is uh get all stream",
    "start": "2175760",
    "end": "2180960"
  },
  {
    "text": "takes an all people request and returns an iserver stream writer of",
    "start": "2180960",
    "end": "2186320"
  },
  {
    "text": "person so under the hood this is all i think",
    "start": "2186320",
    "end": "2192640"
  },
  {
    "text": "innumerable but it's wrapped up in grpc speak",
    "start": "2192640",
    "end": "2198800"
  },
  {
    "text": "so you have a response stream and the server context",
    "start": "2198800",
    "end": "2204079"
  },
  {
    "text": "you can use if you want to we're not using it here and then we're writing to the response",
    "start": "2204079",
    "end": "2211119"
  },
  {
    "text": "stream which does the rest that does all the yield returning and all of that",
    "start": "2211119",
    "end": "2218559"
  },
  {
    "text": "and then",
    "start": "2221119",
    "end": "2224359"
  },
  {
    "text": "so this is looking at the code i think that's it yeah all right let's run it",
    "start": "2228400",
    "end": "2233760"
  },
  {
    "text": "so this demo is a little bit different we're going to start with the performance aspect of retrieving",
    "start": "2233760",
    "end": "2241119"
  },
  {
    "text": "5000 records via a standard api call versus an api stream",
    "start": "2241119",
    "end": "2247119"
  },
  {
    "text": "and via standard grpc call versus a grpc stream and hopefully this will sort of cement",
    "start": "2247119",
    "end": "2255119"
  },
  {
    "text": "in that it isn't about performance right it's about scalability",
    "start": "2255119",
    "end": "2260720"
  },
  {
    "text": "so here's the api again this is the same as we had before 2.4 seconds the second time would be",
    "start": "2260720",
    "end": "2270240"
  },
  {
    "text": "1.8 seconds now the same thing as a stream",
    "start": "2270240",
    "end": "2275760"
  },
  {
    "text": "all right 2.1 seconds and",
    "start": "2277520",
    "end": "2282800"
  },
  {
    "text": "2 seconds so it's taking longer to retrieve all of them with the stream",
    "start": "2282800",
    "end": "2289040"
  },
  {
    "text": "okay this the grpc side is really dramatic",
    "start": "2289040",
    "end": "2294800"
  },
  {
    "text": "look at this 508 milliseconds 314 milliseconds but as a stream",
    "start": "2294800",
    "end": "2301520"
  },
  {
    "text": "a whole second almost a second so there's a three times",
    "start": "2301520",
    "end": "2307599"
  },
  {
    "text": "performance degradation just to get the entire set with a stream",
    "start": "2307599",
    "end": "2313200"
  },
  {
    "text": "all right but that's not what it's all about so here's the money shot right here",
    "start": "2313200",
    "end": "2319200"
  },
  {
    "text": "uh and that is we're going to use counter the counter page to",
    "start": "2319200",
    "end": "2325599"
  },
  {
    "text": "actually show the ui with the data as it's coming in",
    "start": "2325599",
    "end": "2333359"
  },
  {
    "text": "and i i mean i could go through the code and show you the code but it's really simple",
    "start": "2334240",
    "end": "2339359"
  },
  {
    "text": "because i have encounter i have a list a select an html select",
    "start": "2339359",
    "end": "2345599"
  },
  {
    "text": "that shows only the first 20 records okay",
    "start": "2345599",
    "end": "2350800"
  },
  {
    "text": "what we're going to do is start the timer start streaming get the first 20 and after the first 20",
    "start": "2350800",
    "end": "2358160"
  },
  {
    "text": "i'm going to update the ui i'm going to call data's changed in blazer which is going to refresh",
    "start": "2358160",
    "end": "2364000"
  },
  {
    "text": "and we're going to continue every 100 records to update the ui to say we've got",
    "start": "2364000",
    "end": "2369040"
  },
  {
    "text": "another 100 records right and as we're getting them you're going to see the list well you won't see the list",
    "start": "2369040",
    "end": "2375520"
  },
  {
    "text": "grow but you'll see the scroll bar gets smaller right",
    "start": "2375520",
    "end": "2382720"
  },
  {
    "text": "so let's just do the api stream first okay 670 milliseconds to get the first",
    "start": "2382720",
    "end": "2390400"
  },
  {
    "text": "20. all right let's do it again in fact let's clear this",
    "start": "2390400",
    "end": "2397119"
  },
  {
    "text": "come back and do it again that time only 57 milliseconds to get",
    "start": "2397119",
    "end": "2403200"
  },
  {
    "text": "the first 20. and look i can scroll down and as i'm scrolling they're still coming in",
    "start": "2403200",
    "end": "2410599"
  },
  {
    "text": "right all right now grpc",
    "start": "2410640",
    "end": "2415200"
  },
  {
    "text": "189 milliseconds to get the first 20. all right so the to the user they just said wow i",
    "start": "2415920",
    "end": "2423359"
  },
  {
    "text": "just downloaded 5 000 records and by the time they move their mouse over to start scrolling they're already there",
    "start": "2423359",
    "end": "2430560"
  },
  {
    "text": "right perceived performance let's try it again",
    "start": "2430560",
    "end": "2436720"
  },
  {
    "text": "34 milliseconds to get the first 20 after it's been compiled once",
    "start": "2436720",
    "end": "2443760"
  },
  {
    "text": "so that shows the power of of streaming right there grpc is more performant than web api",
    "start": "2444000",
    "end": "2451040"
  },
  {
    "text": "number one and number two when you use it with streaming uh it's the the performance really",
    "start": "2451040",
    "end": "2457280"
  },
  {
    "text": "shines and especially you know for the user",
    "start": "2457280",
    "end": "2462000"
  },
  {
    "text": "so questions yeah",
    "start": "2462720",
    "end": "2467838"
  },
  {
    "text": "well in place of one yeah yeah",
    "start": "2480560",
    "end": "2485680"
  },
  {
    "text": "yeah that's a great question as a matter of fact i don't even know if this um",
    "start": "2493280",
    "end": "2500000"
  },
  {
    "text": "is still working but uh on my github repo",
    "start": "2500000",
    "end": "2508160"
  },
  {
    "text": "i wrote a grpc generator let's see if it's on blazer train",
    "start": "2508160",
    "end": "2515040"
  },
  {
    "text": "um i wrote a grpc generator now grpc is in of itself a generator but what",
    "start": "2521119",
    "end": "2527280"
  },
  {
    "text": "happens if you have all these classes already set up right",
    "start": "2527280",
    "end": "2533280"
  },
  {
    "text": "yeah generate your grpc layer so check out episode 46",
    "start": "2533280",
    "end": "2539119"
  },
  {
    "text": "of of blazer train",
    "start": "2539119",
    "end": "2544160"
  },
  {
    "text": "and the code okay yeah it is downloading a zip file but i i also have",
    "start": "2544160",
    "end": "2549920"
  },
  {
    "text": "that on github somewhere so yeah generate your grpc layer episode",
    "start": "2549920",
    "end": "2556960"
  },
  {
    "text": "46 and essentially the idea is that if you have already have classes you already have a",
    "start": "2556960",
    "end": "2563280"
  },
  {
    "text": "web api and you've got a large you know code base",
    "start": "2563280",
    "end": "2568480"
  },
  {
    "text": "how do i convert that over to porto proto files i said porto files isn't",
    "start": "2568480",
    "end": "2574240"
  },
  {
    "text": "that neat i don't even think of that proto files and services and that's what",
    "start": "2574240",
    "end": "2580640"
  },
  {
    "text": "i attempted to do with this uh with this grpc generator",
    "start": "2580640",
    "end": "2586720"
  },
  {
    "text": "great question anyone else",
    "start": "2586720",
    "end": "2590319"
  },
  {
    "text": "right yeah",
    "start": "2599280",
    "end": "2604800"
  },
  {
    "text": "yeah",
    "start": "2605359",
    "end": "2607838"
  },
  {
    "text": "uh i don't because they they do the same thing just in a different way if if you need the the push",
    "start": "2614480",
    "end": "2623040"
  },
  {
    "text": "feature of a channel for any reason i guess that's one way to one reason but",
    "start": "2623040",
    "end": "2628800"
  },
  {
    "text": "they do the same thing at the end of the day but i don't have i never use the channel",
    "start": "2628800",
    "end": "2636480"
  },
  {
    "text": "in production so i i can't i don't have that perspective",
    "start": "2636480",
    "end": "2642240"
  },
  {
    "text": "that someone else might have but the only difference really is that channel is a push async is a pull",
    "start": "2642240",
    "end": "2649520"
  },
  {
    "text": "and for if for any reason you need the push architecture",
    "start": "2649520",
    "end": "2654720"
  },
  {
    "text": "yeah other questions",
    "start": "2654720",
    "end": "2659920"
  },
  {
    "text": "yes sir",
    "start": "2660319",
    "end": "2663480"
  },
  {
    "text": "yeah yes yeah you have the same level of security in grpc uh that you have in web api",
    "start": "2673359",
    "end": "2680640"
  },
  {
    "text": "yep absolutely uh and you know there's a guy",
    "start": "2680640",
    "end": "2686079"
  },
  {
    "text": "here who knows more about grpc and its internal workings than i do and that's mark",
    "start": "2686079",
    "end": "2692160"
  },
  {
    "text": "rundle so yeah because he basically built uh a wcf to grpc",
    "start": "2692160",
    "end": "2701520"
  },
  {
    "text": "a converter i think it's either a converter or if it's a code generator or something like that but",
    "start": "2701520",
    "end": "2707280"
  },
  {
    "text": "anybody who has a large array of wcf services he's",
    "start": "2707280",
    "end": "2713839"
  },
  {
    "text": "figured out how to move those over to grpc",
    "start": "2713839",
    "end": "2718200"
  },
  {
    "text": "others coffee time all right thank you very much",
    "start": "2719280",
    "end": "2728119"
  }
]
[
  {
    "text": "okay oh yes I'm on excellent right let's do it okay start my",
    "start": "5680",
    "end": "12839"
  },
  {
    "text": "timer great all right good morning hello everybody Welcome morning Nile and",
    "start": "12839",
    "end": "18160"
  },
  {
    "text": "everyone else um nice to see you all um I'm very happy that you made it out of bed and into this session this morning",
    "start": "18160",
    "end": "25160"
  },
  {
    "text": "uh for another session about AI there's been quite a few sessions about AI at this conference right it's almost as if",
    "start": "25160",
    "end": "30920"
  },
  {
    "text": "there's something going on in our industry to do with AI at the moment don't know if you get that impression um",
    "start": "30920",
    "end": "36200"
  },
  {
    "text": "well obviously there is I'm kind of curious actually how many of you put something that you would consider AI",
    "start": "36200",
    "end": "41600"
  },
  {
    "text": "into production in your applications today that's not very many okay so that's like 5% of you so there's",
    "start": "41600",
    "end": "48399"
  },
  {
    "text": "probably a huge amount of growth potential in this area at the moment and so this is what we're going to focus on",
    "start": "48399",
    "end": "54760"
  },
  {
    "text": "in this talk today so my name is Steve good morning nice to meet you I work at Microsoft and um I work on the net team",
    "start": "54760",
    "end": "61960"
  },
  {
    "text": "I do a lot of web related stuff uh so at the moment one of the things I'm looking at is how can we make this really",
    "start": "61960",
    "end": "68360"
  },
  {
    "text": "practical and uh sensible for net developers who are coming to AI development how can we make it as",
    "start": "68360",
    "end": "75320"
  },
  {
    "text": "straightforward as possible to make genuinely useful AI so not just the sort of AI that sort of checks a box but",
    "start": "75320",
    "end": "81759"
  },
  {
    "text": "actually does something beneficial for your users so let's think about what that might mean then firstly um what",
    "start": "81759",
    "end": "88280"
  },
  {
    "text": "does it actually mean to make make your app intelligent does it mean you are going to add a chat bot to it well I",
    "start": "88280",
    "end": "95560"
  },
  {
    "text": "mean it could be but that's clearly not the whole story uh so let's just consider a few of these statements which",
    "start": "95560",
    "end": "101159"
  },
  {
    "text": "of them do we actually consider to be true well does throwing a chat bot on something enable you to make a cool demo",
    "start": "101159",
    "end": "108159"
  },
  {
    "text": "quickly I think the answer to that for sure is yes it's brilliant for that that's one of the best things uh that",
    "start": "108159",
    "end": "114399"
  },
  {
    "text": "you can do with chatbots you can make a cool demo in one day probably quite straightforwards and if you're willing",
    "start": "114399",
    "end": "120039"
  },
  {
    "text": "to evil be evil and cherry-pick your examples then you can make your demo look really good as well so it's good",
    "start": "120039",
    "end": "126399"
  },
  {
    "text": "way of uh of impressing your boss if that's what you if that's all you're trying to do but then if you try to put it into production are people going to",
    "start": "126399",
    "end": "133360"
  },
  {
    "text": "actually use it well maybe it depends like does this thing actually save",
    "start": "133360",
    "end": "138640"
  },
  {
    "text": "people time and enable to do them enable them to do their job better than they would have otherwise maybe uh as for",
    "start": "138640",
    "end": "146239"
  },
  {
    "text": "accuracy well I think my challenge to you is let's talk numers let's not just sort of wave our hands and say well we",
    "start": "146239",
    "end": "152599"
  },
  {
    "text": "sort of think it might be we hope might hallucinate a bit let's have actual numbers so that we can measure it and",
    "start": "152599",
    "end": "158640"
  },
  {
    "text": "then we can make sure that it's good enough and that we're improving it in a practical way over time as for it being",
    "start": "158640",
    "end": "164760"
  },
  {
    "text": "the only way well it's very often chat is not even the best user interface for",
    "start": "164760",
    "end": "169840"
  },
  {
    "text": "a t particular type of task there are many other ways that you can add intelligence into your applications",
    "start": "169840",
    "end": "176239"
  },
  {
    "text": "different kinds of UI patterns you can have semantic search you can automatically summarize large amounts of",
    "start": "176239",
    "end": "181920"
  },
  {
    "text": "information you can do a typ ahead so that people don't have to press every key on their keyboard you can do things",
    "start": "181920",
    "end": "187519"
  },
  {
    "text": "like triggering workflows automatically based on categorization many different things and we'll look at some of these",
    "start": "187519",
    "end": "193480"
  },
  {
    "text": "patterns this morning and so given all this complexity you might think is it really even worth it like can I just",
    "start": "193480",
    "end": "200080"
  },
  {
    "text": "ignore this whole AI thing and see if it goes away well I think actually there are some real genuine benefits that you",
    "start": "200080",
    "end": "206760"
  },
  {
    "text": "can bring to your users and ultimately I hope that what you think that you're trying to achieve here is benefiting the",
    "start": "206760",
    "end": "212760"
  },
  {
    "text": "human users of your actual software so you're trying to bring more control Freedom productivity satisfaction and",
    "start": "212760",
    "end": "219480"
  },
  {
    "text": "other good things to the human beings who are actually using your software and the way that AI can do that well it can",
    "start": "219480",
    "end": "225480"
  },
  {
    "text": "do it in a few different ways one of the main ones is by bringing the right information to people at the right time",
    "start": "225480",
    "end": "231000"
  },
  {
    "text": "so AI can be very good uh picking out an individual bit of data that's the most",
    "start": "231000",
    "end": "236159"
  },
  {
    "text": "pertinent thing for a person to look at right now it can also be good are aggregating over lots of data and",
    "start": "236159",
    "end": "242159"
  },
  {
    "text": "showing the overall patterns or the overall summary so that people don't have to plow through it all themselves",
    "start": "242159",
    "end": "248040"
  },
  {
    "text": "and the net effect of all this is that you're giving your users a way of skipping the mundane parts of their job",
    "start": "248040",
    "end": "253640"
  },
  {
    "text": "and being able to get to the bit that they you actually value them for so the bits where the humans can bring their",
    "start": "253640",
    "end": "259120"
  },
  {
    "text": "own decision making their own creativity and personality into it and skip over",
    "start": "259120",
    "end": "264560"
  },
  {
    "text": "all the boring and mundane parts so that's really what we're trying to go for with this and there different ways",
    "start": "264560",
    "end": "270199"
  },
  {
    "text": "you can approach it so we're going to get quite deep into this later in the talk but we're going to start at a at a",
    "start": "270199",
    "end": "275560"
  },
  {
    "text": "surface level with a very straightforwards way of getting started if you want to add a bit of AI into your",
    "start": "275560",
    "end": "281639"
  },
  {
    "text": "application so smart components is an experiment that we've been running over the last six months or so you can try it",
    "start": "281639",
    "end": "287000"
  },
  {
    "text": "out if you go to this URL it's a set of samples that allow you to add AI at the UI layer in your application so you've",
    "start": "287000",
    "end": "293880"
  },
  {
    "text": "got an existing app you don't want to rebuild the whole thing you're not changing the whole back end or anything like that probably not even changing",
    "start": "293880",
    "end": "299720"
  },
  {
    "text": "most of the screens but you can just make them more intelligent so let's have a look at how that might work so imagine",
    "start": "299720",
    "end": "306560"
  },
  {
    "text": "that you've got a web UI like this okay it's a mailing address form we've all seen things like this pretty normal all",
    "start": "306560",
    "end": "312840"
  },
  {
    "text": "right and imagine there's some user whose job it is to fill it out and they get some data that comes in like maybe",
    "start": "312840",
    "end": "318120"
  },
  {
    "text": "they receive an email from someone saying hey please add me to your system uh and you say okay Veronica ortis I'm",
    "start": "318120",
    "end": "324639"
  },
  {
    "text": "going to add you to the system so you come along and you start typing Veronica",
    "start": "324639",
    "end": "330000"
  },
  {
    "text": "and you think oh hang on I think there was a special I or o or something in there how do I type that I don't know I",
    "start": "330000",
    "end": "335280"
  },
  {
    "text": "but I know I'll just copy and paste the name and then I'll copy and paste the phone and then you at this point you",
    "start": "335280",
    "end": "341000"
  },
  {
    "text": "just go like no I can't do it it's too boring like I'm a human being I can't do this sort of drudgery can we make this",
    "start": "341000",
    "end": "348000"
  },
  {
    "text": "better so they would go to the developer and they'd say can you somehow make my job not suck and you would go and think",
    "start": "348000",
    "end": "354880"
  },
  {
    "text": "well maybe I'll I've heard about this cool AI thing let's see what we can do so you you might come into the source",
    "start": "354880",
    "end": "361440"
  },
  {
    "text": "code for your application so here we've got that form that mailing address form it's it's written in Blazer in this case",
    "start": "361440",
    "end": "366800"
  },
  {
    "text": "but it could be written in other things smart components works with MVC and razor Pages as well and you could look",
    "start": "366800",
    "end": "371840"
  },
  {
    "text": "through all this and you think okay how about down here at the bottom we're not going to change anything else but the one thing we'll do is we'll just add",
    "start": "371840",
    "end": "378639"
  },
  {
    "text": "this smart paste button into the system there all right so what is that going to do well come back over here and reload",
    "start": "378639",
    "end": "386000"
  },
  {
    "text": "it and we see our smart past button and now our user can copy all of this text to their clipboard like that and hit the",
    "start": "386000",
    "end": "392800"
  },
  {
    "text": "smart paste button and then we're going to use AI to fill out the whole form so we take the contents of the clipboard we",
    "start": "392800",
    "end": "399240"
  },
  {
    "text": "match it all up with the different elements in the form and you know it's going to fill it out and it's not just for mailing address forms it should work",
    "start": "399240",
    "end": "405440"
  },
  {
    "text": "with more or less any form so here's another one that you'll all be familiar with so sort of bug tracking type thing",
    "start": "405440",
    "end": "411039"
  },
  {
    "text": "with you know projects and item types steps to re reproduce and stuff so wouldn't it be nice if when your boss",
    "start": "411039",
    "end": "417479"
  },
  {
    "text": "sends you this message over teams you could just copy their issue report and then go and smart paste and what's that",
    "start": "417479",
    "end": "423720"
  },
  {
    "text": "going to do well obviously it's going to fill out the whole form for us pick the right drop- down entries add in all the steps to reproduce and stuff like that",
    "start": "423720",
    "end": "430440"
  },
  {
    "text": "okay so that's just one example of this another example of making stuff",
    "start": "430440",
    "end": "435599"
  },
  {
    "text": "intelligent just at the UI layer uh this smart text area so in this case let's",
    "start": "435599",
    "end": "440680"
  },
  {
    "text": "imagine that there's an HR administrator who has to answer questions from employees so they maybe they get an a",
    "start": "440680",
    "end": "447039"
  },
  {
    "text": "question about like what's my vacation allowance so they say something like your vac",
    "start": "447039",
    "end": "452879"
  },
  {
    "text": "vacation allowance is and then they're like uh I have to go and check the",
    "start": "452879",
    "end": "457919"
  },
  {
    "text": "policy now and then I'll probably have to like type out some URL to show you where it is in the policy and stuff it's too boring again I'm not going to do it",
    "start": "457919",
    "end": "464879"
  },
  {
    "text": "I'm just going to go and complain to the developers who work for the company and say it's their fault they should have made this better in some way so you the",
    "start": "464879",
    "end": "471479"
  },
  {
    "text": "developer uh get their complaint and you go okay well fine I'll make stuff better for you uh and you'll come and have a",
    "start": "471479",
    "end": "477440"
  },
  {
    "text": "look at the form and you'll say aha I see what the problem is the problem is that you were typing into a boring old",
    "start": "477440",
    "end": "484240"
  },
  {
    "text": "html text area that's got no intelligence whatsoever so let's replace that with a smart text area and we'll",
    "start": "484240",
    "end": "491479"
  },
  {
    "text": "configure it so that it's in this role of HR admin and it's got these phrases that are configured and they Define",
    "start": "491479",
    "end": "496879"
  },
  {
    "text": "different things to do with the policy in this company like how much vacation you get where the policy is written what",
    "start": "496879",
    "end": "502560"
  },
  {
    "text": "the HR email addresses things like that okay so now when they type your vacation",
    "start": "502560",
    "end": "510599"
  },
  {
    "text": "allow is then at this point it will do nothing at all because I didn't save my",
    "start": "510599",
    "end": "515719"
  },
  {
    "text": "changes or something like that let's try that again all right your vacation",
    "start": "515719",
    "end": "524039"
  },
  {
    "text": "allowance is and then at this point still nothing",
    "start": "524040",
    "end": "529519"
  },
  {
    "text": "whatsoever such an awesome demo cool um why is that happening I do not know so",
    "start": "529519",
    "end": "536279"
  },
  {
    "text": "I'm going to just redo this one more time",
    "start": "536279",
    "end": "541279"
  },
  {
    "text": "no for no reason at all that's not working and that's really fascinating but let's just ignore that imagine that",
    "start": "544959",
    "end": "550120"
  },
  {
    "text": "what happened is it filled out the um the the text area with the stuff that",
    "start": "550120",
    "end": "555320"
  },
  {
    "text": "would have made sense for them to type so it would have said uh your vacation allowance is 28 days and then the the user would carry on typing something",
    "start": "555320",
    "end": "561200"
  },
  {
    "text": "like for more info and then it would fill out the URL of uh where they would have uh gone to and then whatever they",
    "start": "561200",
    "end": "567000"
  },
  {
    "text": "type it fills in the relevant bit that use from there except I've obviously done something wrong okay final example",
    "start": "567000",
    "end": "573200"
  },
  {
    "text": "that we'll look at smart combo box so you know a typical combo box when you",
    "start": "573200",
    "end": "578360"
  },
  {
    "text": "start trying to search for stuff in it it will do a substring match so uh if you want to find something you need to",
    "start": "578360",
    "end": "584200"
  },
  {
    "text": "more or less know what the text is that you're looking for but what if the user doesn't know the text well in this case",
    "start": "584200",
    "end": "589800"
  },
  {
    "text": "let's say that I want to submit an expense report for a plane ticket uh I don't know what the expense category for",
    "start": "589800",
    "end": "595519"
  },
  {
    "text": "that is so I'll just start typing plane and then you'll see it's going to do sem matching so the word plane doesn't",
    "start": "595519",
    "end": "601440"
  },
  {
    "text": "appear in these options but you know it matches up semantically so it's going to show me that or if I search for pets",
    "start": "601440",
    "end": "607560"
  },
  {
    "text": "then I'm going to get pet care or cats will also match pet care so you know it knows about the relationship or if I've",
    "start": "607560",
    "end": "613920"
  },
  {
    "text": "got an issue tracking thing maybe I'm trying to report that something is slow and it'll tell me that the right label",
    "start": "613920",
    "end": "619160"
  },
  {
    "text": "for that in this case is performance okay so that is doing semantic matching and we'll look into",
    "start": "619160",
    "end": "624760"
  },
  {
    "text": "how that works uh in a little bit okay but the the core point that I want to make with this is that it's a really",
    "start": "624760",
    "end": "630600"
  },
  {
    "text": "straightforward way of starting without having to really change what's going on behind the scenes in your application so",
    "start": "630600",
    "end": "637279"
  },
  {
    "text": "that's just doing stuff at the UI UI layer all right but let's spend the rest",
    "start": "637279",
    "end": "642800"
  },
  {
    "text": "of our time going a lot deeper than that so let's imagine now that you're you're feeling the benefits of this and you're",
    "start": "642800",
    "end": "649399"
  },
  {
    "text": "thinking well how good can we make stuff if we were able to add AI at many different layers within our system and",
    "start": "649399",
    "end": "655800"
  },
  {
    "text": "really start to make use of that is it actually useful in the type of applications that you build well let's",
    "start": "655800",
    "end": "662160"
  },
  {
    "text": "think about it and I'm going to try and make this as relatable as possible so I'll use a very traditional typical kind",
    "start": "662160",
    "end": "668000"
  },
  {
    "text": "of web application so e-commerce right we all know about e-commerce uh and and",
    "start": "668000",
    "end": "674079"
  },
  {
    "text": "this kind of a web app where you have forms and data and grids and and all that kind of stuff like we all build",
    "start": "674079",
    "end": "679360"
  },
  {
    "text": "that kind of stuff so imagine that there's this uh e-commerce site uh called eShop you've probably seen a you",
    "start": "679360",
    "end": "685800"
  },
  {
    "text": "may have seen a eShop sample that we've got um this is going to sort of extend the eShop Universe into the world of the",
    "start": "685800",
    "end": "691959"
  },
  {
    "text": "staff that work for that company now so we've got customers who file support requests they bought something from",
    "start": "691959",
    "end": "697839"
  },
  {
    "text": "eShop and then they say actually I've got a problem with this and they come to this UI and they can fill out details",
    "start": "697839",
    "end": "703639"
  },
  {
    "text": "about what their question is or what their problem is or submit a return request or or that sort of thing and",
    "start": "703639",
    "end": "709000"
  },
  {
    "text": "then that goes to the staff that work for the company all right so what are the staff going to see well they've",
    "start": "709000",
    "end": "715200"
  },
  {
    "text": "probably got some web view that shows them like what tickets are open and closed and gives them the ability to",
    "start": "715200",
    "end": "720519"
  },
  {
    "text": "search and then the main bit of UI here is probably going to be some sort of Big Grid all right so very very typical kind",
    "start": "720519",
    "end": "727959"
  },
  {
    "text": "of thing okay now is AI going to deliver any meaningful value in an application",
    "start": "727959",
    "end": "735199"
  },
  {
    "text": "like this well yeah I think it can do so the first point is semantic search so whenever you have any sort of search",
    "start": "735199",
    "end": "741839"
  },
  {
    "text": "field I would start thinking is this beneficial to make it a semantic search so that the user doesn't know exact have",
    "start": "741839",
    "end": "748040"
  },
  {
    "text": "to know exactly things are phrased and it doesn't matter if they've got typos or whatever it's just going to find the",
    "start": "748040",
    "end": "753320"
  },
  {
    "text": "relevant stuff most likely anyway all right that's one second example summarization so this title column here",
    "start": "753320",
    "end": "760760"
  },
  {
    "text": "that we've got who do you think writes those titles well we don't want to force the users to write titles because even",
    "start": "760760",
    "end": "767440"
  },
  {
    "text": "if we do they'll just write garbage like help or something like that which is not going to help you to distinguish this",
    "start": "767440",
    "end": "772839"
  },
  {
    "text": "item from the other items so how about we use a language model to make a nice distinctive title for each thing so that",
    "start": "772839",
    "end": "779320"
  },
  {
    "text": "staff can quickly find it okay next one classification we've got this type column again we don't want to trust the",
    "start": "779320",
    "end": "785720"
  },
  {
    "text": "end users to pick the type for their thing because they'll probably pick the wrong thing and although we could trust",
    "start": "785720",
    "end": "791320"
  },
  {
    "text": "the staff to do it how about we just save them the trouble of doing it and in fact if we can do the classification up",
    "start": "791320",
    "end": "796639"
  },
  {
    "text": "front then maybe we can trigger different workflows on it like based on whether it's to do with returns or whatever and finally sentiment scores so",
    "start": "796639",
    "end": "804320"
  },
  {
    "text": "just a simple thing that we can use to help staff direct their focus to the areas where stuff is most urgent okay",
    "start": "804320",
    "end": "812279"
  },
  {
    "text": "and then let's continue let's imagine now that the support staff has clicked on one of these items to go and start",
    "start": "812279",
    "end": "818199"
  },
  {
    "text": "working on a particular support ticket what are they going to see well there's probably going to be some part of the URI which is various fields that they",
    "start": "818199",
    "end": "824760"
  },
  {
    "text": "can work on and we've already established that we can do a bit of AI for classifying these things and we've",
    "start": "824760",
    "end": "829839"
  },
  {
    "text": "got a search thing there so we're probably already starting to think well we probably could do some semantic search so that we don't have to worry",
    "start": "829839",
    "end": "836360"
  },
  {
    "text": "about typos and then there's going to be part of the system where you get to actually interact with the customers",
    "start": "836360",
    "end": "841440"
  },
  {
    "text": "where you see their question you can tap out your reply and so on and you have the whole train of Correspondence but",
    "start": "841440",
    "end": "847680"
  },
  {
    "text": "the problem is that might be a really really long amount of text and it might waste a lot of Staff time rereading from",
    "start": "847680",
    "end": "854399"
  },
  {
    "text": "the beginning every single time they open this so why not use a language model to produce a nice short summary of",
    "start": "854399",
    "end": "861720"
  },
  {
    "text": "the entire correspondence so that they can get their bearings very quickly as soon as they enter this thing and then",
    "start": "861720",
    "end": "867279"
  },
  {
    "text": "they've got to actually answer the question now maybe this every support staff knows about every single product but more likely they don't and they have",
    "start": "867279",
    "end": "873639"
  },
  {
    "text": "to look up information so this is the kind of case where yes it's really actually useful to have something where",
    "start": "873639",
    "end": "879040"
  },
  {
    "text": "you can get something to look up information for you with this kind of Q&A system or uh it's often called rag",
    "start": "879040",
    "end": "884680"
  },
  {
    "text": "retrieval augmented generation we'll look at how that works but to make sure that's actually reliable and accurate we",
    "start": "884680",
    "end": "890440"
  },
  {
    "text": "can force it to give citations for all the claims that it makes so that the staff can actually check that this is",
    "start": "890440",
    "end": "896079"
  },
  {
    "text": "for real and then finally when they come to typing out their replies what would",
    "start": "896079",
    "end": "901160"
  },
  {
    "text": "have you would have seen if my demo had worked is that we could show we could have a typ ahead system so that we can",
    "start": "901160",
    "end": "907160"
  },
  {
    "text": "automatically insert content that is relevant based on the context generated by the assistant so for example if",
    "start": "907160",
    "end": "913040"
  },
  {
    "text": "there's a link to the manual and the user seems to be typing something like that then we can fill in the rest of it",
    "start": "913040",
    "end": "918240"
  },
  {
    "text": "automatically so I think even in this very traditional web application there's clearly lots of opportunity for AI to",
    "start": "918240",
    "end": "926000"
  },
  {
    "text": "add a lot of genuine value that will help your staff actually be more productive so let's have a go at",
    "start": "926000",
    "end": "931319"
  },
  {
    "text": "building this shall we now I know that if you're unfamiliar with this it does feel a bit bewildering like you've just",
    "start": "931319",
    "end": "937399"
  },
  {
    "text": "been dropped on this island you've got no idea your way around it no one gave you a map like where do you even get",
    "start": "937399",
    "end": "942839"
  },
  {
    "text": "started creating something like that what libraries are you're supposed to use what what's the development process",
    "start": "942839",
    "end": "948160"
  },
  {
    "text": "so we're going to go on a little journey now around this island and we'll pick up the different bits that we need to do",
    "start": "948160",
    "end": "953519"
  },
  {
    "text": "along the way and where we're going to start is with data",
    "start": "953519",
    "end": "959079"
  },
  {
    "text": "if my here we go yes great so the obviously all applications need data but AI applications more than anything",
    "start": "959079",
    "end": "965639"
  },
  {
    "text": "really because that's like the lifeblood of the system you can't really even get started until you got some data so we're",
    "start": "965639",
    "end": "971120"
  },
  {
    "text": "going to start with generating some data and that will allow me to introduce some of the core apis that we need to use so",
    "start": "971120",
    "end": "977480"
  },
  {
    "text": "we're going to use semantic kernel which is a net library for working with AI systems and we're going to use ol which",
    "start": "977480",
    "end": "983000"
  },
  {
    "text": "is a way of running uh large language models locally on your development machine all right so you are going going",
    "start": "983000",
    "end": "989000"
  },
  {
    "text": "to have to bear with me for the first five or 10 minutes because we're not even going to start up the web UI during that time we're just going to work with",
    "start": "989000",
    "end": "995000"
  },
  {
    "text": "data in the abstract and the way we're going to start is we're generating some product data we're going to start by",
    "start": "995000",
    "end": "1001120"
  },
  {
    "text": "generating some categories uh for products in this system and the main API we'll use is this thing called I chat",
    "start": "1001120",
    "end": "1007759"
  },
  {
    "text": "completion service which is an API provided by semantic kernel and that's an abstraction over language models like",
    "start": "1007759",
    "end": "1014040"
  },
  {
    "text": "GPT or or anything that can be served by ol different things like that okay so",
    "start": "1014040",
    "end": "1019079"
  },
  {
    "text": "what we're going to do initially is we're going to set set up this prompt that says generate me a bunch of product category names and I want you to reply",
    "start": "1019079",
    "end": "1026079"
  },
  {
    "text": "in Json in this format with some Brands as well and if you're wondering what is the implementation behind this interface",
    "start": "1026079",
    "end": "1032918"
  },
  {
    "text": "here well I've set up initially olama as the implementation now that's this uh",
    "start": "1032919",
    "end": "1038760"
  },
  {
    "text": "method doesn't exist in semantic kernel yet it's being added uh but you know you can build it yourself in not too much",
    "start": "1038760",
    "end": "1044079"
  },
  {
    "text": "code it's just makes HTTP requests to ol so I want to run ol here on my laptop so",
    "start": "1044079",
    "end": "1051520"
  },
  {
    "text": "let's start that up and then I'm going to start this data generator going so that's now making requests against this",
    "start": "1051520",
    "end": "1058720"
  },
  {
    "text": "which is running locally it takes a few seconds to start because you know it's loading a whole language model onto the",
    "start": "1058720",
    "end": "1064000"
  },
  {
    "text": "GPU on this device here uh and once it does get started it's going to start producing some data and it will start",
    "start": "1064000",
    "end": "1070640"
  },
  {
    "text": "writing that out to disk so let's see what data it's actually produced just now if I go over here we'll see we've",
    "start": "1070640",
    "end": "1077360"
  },
  {
    "text": "generated a bunch of product categories so we got camping and Hiking we got water spots and some other stuff and we",
    "start": "1077360",
    "end": "1083360"
  },
  {
    "text": "could obviously go on generating as much of that stuff as we want okay now we don't have to use our armor if we want",
    "start": "1083360",
    "end": "1089799"
  },
  {
    "text": "to because we've got this interface provided by semantic kernel we can easily swap it out for a different",
    "start": "1089799",
    "end": "1095600"
  },
  {
    "text": "backend if we want so in this case I'm going to swap it out for open AI uh mainly just because it runs faster on my",
    "start": "1095600",
    "end": "1102559"
  },
  {
    "text": "laptop and I don't want you to have to wait and then I'm going to generate a lot more data as well so instead of just",
    "start": "1102559",
    "end": "1108159"
  },
  {
    "text": "generating categories I want to generate the entire universe of data for my application all right now here's a",
    "start": "1108159",
    "end": "1115200"
  },
  {
    "text": "little pattern you can use if you want to produce more data than is possible to emit from a single prompt you can chain",
    "start": "1115200",
    "end": "1121400"
  },
  {
    "text": "things together in a way to make it all mutually consistent so what I'm doing here is first I'm generating some",
    "start": "1121400",
    "end": "1127200"
  },
  {
    "text": "categories like I just showed you and then based on that I'm generating some products that are in those categories",
    "start": "1127200",
    "end": "1132240"
  },
  {
    "text": "and then based on the categories and products I'm generating tables of contents for the manuals and then based",
    "start": "1132240",
    "end": "1137440"
  },
  {
    "text": "on the tables of contents generate the entire text for the product manuals and then based on that I convert them to PDF",
    "start": "1137440",
    "end": "1144080"
  },
  {
    "text": "and based on that we generate some support tickets that customers might have related to these products and based",
    "start": "1144080",
    "end": "1149679"
  },
  {
    "text": "on that we generate entire thread of conversation with the customer support and based on that we generate a summary",
    "start": "1149679",
    "end": "1154880"
  },
  {
    "text": "and so on all the way through and if you want to know how each of these works pretty straightforwards just like you",
    "start": "1154880",
    "end": "1160200"
  },
  {
    "text": "saw before they're constructing a prompt they're injecting some data that we've already generated earlier and we're",
    "start": "1160200",
    "end": "1165640"
  },
  {
    "text": "getting it to return some Json that we store all right so let's start that running and just waiting for that to",
    "start": "1165640",
    "end": "1175120"
  },
  {
    "text": "build uh okay so that is now going to",
    "start": "1175120",
    "end": "1179720"
  },
  {
    "text": "run I expect here we go right so it's an incremental system so it'll use the",
    "start": "1181080",
    "end": "1187240"
  },
  {
    "text": "categories that we've already got and now it's making calls out to open AI in this case to generate more stuff so",
    "start": "1187240",
    "end": "1192760"
  },
  {
    "text": "we've generated a bunch of products like we've got this GPS navigation system and Smartwatch and so on then based on that",
    "start": "1192760",
    "end": "1199760"
  },
  {
    "text": "we're generating the tables of contents for our um for our product and you can see it's got this nice hierarchical",
    "start": "1199760",
    "end": "1205799"
  },
  {
    "text": "structure I've picked a few different random descriptions of what the style should be just so that they all feel a",
    "start": "1205799",
    "end": "1211720"
  },
  {
    "text": "little different from each other um so we'll you know get different outputs from there and then it's generating the",
    "start": "1211720",
    "end": "1217159"
  },
  {
    "text": "entire contents of the manual based on that in this case it's coming out in markdown format so it's just expanding",
    "start": "1217159",
    "end": "1224480"
  },
  {
    "text": "on all those tables of contents there all right and so once it's done that it will hopefully also start producing some",
    "start": "1224480",
    "end": "1231360"
  },
  {
    "text": "PDFs for us uh just waiting for it to do a few more of those all right and so",
    "start": "1231360",
    "end": "1237880"
  },
  {
    "text": "PDFs are going to start appearing uh there's lots of net libraries for generating this sort of thing it's not too difficult let's have a look so here",
    "start": "1237880",
    "end": "1245520"
  },
  {
    "text": "we go here's our first one all right so we've got this entire product manual for this GPS navigation system that we just",
    "start": "1245520",
    "end": "1251960"
  },
  {
    "text": "created obviously it's loads of fake data but it's going to help us to build our system in a useful way and it can",
    "start": "1251960",
    "end": "1257520"
  },
  {
    "text": "add things like tables and diagrams and stuff like that because it's all part of the prompt in there as",
    "start": "1257520",
    "end": "1262840"
  },
  {
    "text": "well all right so that is enough for us to get",
    "start": "1262840",
    "end": "1267880"
  },
  {
    "text": "started let's just shut some of this stuff down okay right so we've been able to",
    "start": "1267880",
    "end": "1275320"
  },
  {
    "text": "get started by generating some data using semantic kernel and with o armor okay now the next step is to be able to",
    "start": "1275320",
    "end": "1281679"
  },
  {
    "text": "get that data into our system uh obviously if the data is in a nice format like Jason it's very easy to pull",
    "start": "1281679",
    "end": "1287240"
  },
  {
    "text": "it in but in a lot of real world cases you need to pull in unstructured data that comes from The Real World in some",
    "start": "1287240",
    "end": "1293039"
  },
  {
    "text": "way so for example you might have a set of real PDFs that are actual product manuals and you need a way of getting",
    "start": "1293039",
    "end": "1298200"
  },
  {
    "text": "them into your system or it could be other things like Word documents SharePoint files uh you know whatever",
    "start": "1298200",
    "end": "1304000"
  },
  {
    "text": "else that comes from a some external system and you want to pull it in so the example we'll take in this case is the",
    "start": "1304000",
    "end": "1309520"
  },
  {
    "text": "PDFs because that's what we've just got right now uh so let's have a look at how we could do that there are various",
    "start": "1309520",
    "end": "1315000"
  },
  {
    "text": "off-the-shelf systems for ingesting data uh but I was wondering well is it really that hard for us to write a bit of c and",
    "start": "1315000",
    "end": "1321760"
  },
  {
    "text": "to do it at a basic level it's really not that hard so let's look at how we could ingest these manuals so I'm going",
    "start": "1321760",
    "end": "1327679"
  },
  {
    "text": "to start running this now and we're just going to treat these PDFs as like a blackbox external system and see what",
    "start": "1327679",
    "end": "1334279"
  },
  {
    "text": "data we can pull out of them so We're looping over all the PDFs that we've generated here and then I'm using a uh",
    "start": "1334279",
    "end": "1341279"
  },
  {
    "text": "Library a net Library called PDF Pig which is a pretty good open source library for extracting information from",
    "start": "1341279",
    "end": "1347080"
  },
  {
    "text": "PDFs so I'm going to move on a few pages and then we'll see here that we're currently looking at page number four oh",
    "start": "1347080",
    "end": "1354480"
  },
  {
    "text": "well it was there and we can ask PDF pig to pull all the text out of that page and we do get all of the P well there's",
    "start": "1354480",
    "end": "1360840"
  },
  {
    "text": "very little text on that page but uh on other Pages there's going to be more text uh that's more interesting so let's",
    "start": "1360840",
    "end": "1367120"
  },
  {
    "text": "see here's a page with more interesting text on it okay and then the next thing",
    "start": "1367120",
    "end": "1373039"
  },
  {
    "text": "is we need to a way of splitting this up so we've paused it the next step is to chunk it uh we need to to uh extract",
    "start": "1373039",
    "end": "1379880"
  },
  {
    "text": "different small fragments of data from our source so that we can find the most relevant ones it's no use that when you",
    "start": "1379880",
    "end": "1386720"
  },
  {
    "text": "do a search for just return an entire Page worth of data we want to return smaller fragments of data that are most",
    "start": "1386720",
    "end": "1392919"
  },
  {
    "text": "relevant to whatever query is going on so we need a way of splitting it up and one way of doing it is this API in",
    "start": "1392919",
    "end": "1398840"
  },
  {
    "text": "semantic kernel called text chunker and that will split up our text into blocks that are around 200 characters in this",
    "start": "1398840",
    "end": "1405480"
  },
  {
    "text": "case but it doesn't just do it every 200 characters it tries to be a bit smarter and it'll split on natural boundaries",
    "start": "1405480",
    "end": "1411559"
  },
  {
    "text": "like paragraphs or sentences lines or whatever instead of just splitting in the middle of words there are other ways",
    "start": "1411559",
    "end": "1416799"
  },
  {
    "text": "of doing chunking as well in this case it's produced three chunks from that one page uh on natural boundaries and then",
    "start": "1416799",
    "end": "1424000"
  },
  {
    "text": "finally we're going to embed them which means that we want to extract the meaning from them and place them in this",
    "start": "1424000",
    "end": "1431520"
  },
  {
    "text": "semantic space I know that sounds very abstract I'm sure many of you already know uh about uh what embeddings are but",
    "start": "1431520",
    "end": "1438120"
  },
  {
    "text": "for anyone who doesn't and embedding is a way of representing the meaning of some text by turning it into a vector so",
    "start": "1438120",
    "end": "1445440"
  },
  {
    "text": "imagine the vector was three-dimensional like three-dimensional space which it isn't but imagine it was uh then maybe",
    "start": "1445440",
    "end": "1451480"
  },
  {
    "text": "all the uh text to do with dogs might be over there and all the text to do with ice cubes might be up there uh and if",
    "start": "1451480",
    "end": "1458520"
  },
  {
    "text": "that was the case then all the cold things are likely to be more in that direction and all the things with legs",
    "start": "1458520",
    "end": "1463760"
  },
  {
    "text": "are probably more in that direction so it gives you a sense of how stuff will be distributed space according to its",
    "start": "1463760",
    "end": "1469559"
  },
  {
    "text": "meaning that's what an embedding is in this particular case we're using an embedding model that is converting each",
    "start": "1469559",
    "end": "1475880"
  },
  {
    "text": "of these strings to a vector with let's look for it 384 Dimensions so it's a 384",
    "start": "1475880",
    "end": "1483480"
  },
  {
    "text": "dimensional Vector uh and that's pretty standard for for many types of embedding all right so we'll just run that through",
    "start": "1483480",
    "end": "1489919"
  },
  {
    "text": "to the end now and uh there we go so it will have generated some chunks from our",
    "start": "1489919",
    "end": "1495120"
  },
  {
    "text": "data and if we want to have a look at what that actually looks like like uh we can see it's produced all these",
    "start": "1495120",
    "end": "1500559"
  },
  {
    "text": "different chunks so for each of the products and each of the pages it's produced a bunch of chunks and for each",
    "start": "1500559",
    "end": "1505640"
  },
  {
    "text": "one we've got an embedding which means that we can now search through that data set uh semantically and to actually see",
    "start": "1505640",
    "end": "1513000"
  },
  {
    "text": "that running for real I've made a simple console application that does it you wouldn't actually have a little console",
    "start": "1513000",
    "end": "1518120"
  },
  {
    "text": "app like this in a real project but just to uh fully make sure everyone's got a sense of what this looks like uh this is",
    "start": "1518120",
    "end": "1524440"
  },
  {
    "text": "how we can do semantic search so I'm using another semantic kernel abstract action called semantic textt memory uh",
    "start": "1524440",
    "end": "1531039"
  },
  {
    "text": "and I'm loading that Json file into it and then I've got a little Loop where on each loop I read some stuff from the",
    "start": "1531039",
    "end": "1538000"
  },
  {
    "text": "console and then we're going to try and search and we'll output the most relevant stuff and the implementation of",
    "start": "1538000",
    "end": "1544720"
  },
  {
    "text": "this search is really really straightforwards uh anybody could write this semantic search is very",
    "start": "1544720",
    "end": "1549760"
  },
  {
    "text": "straightforwards once you've got the vectors all we have to do is order things in order of similarity which in",
    "start": "1549760",
    "end": "1556799"
  },
  {
    "text": "this case is cosine similar ity so we're just do producting the two vectors together and we're going to get the ones",
    "start": "1556799",
    "end": "1563679"
  },
  {
    "text": "that are most in the same direction as each other and that will give stuff that's semantically similar so only a",
    "start": "1563679",
    "end": "1569600"
  },
  {
    "text": "few lines of code needed to implement that so if I search now for something like uh I don't know we said ice before",
    "start": "1569600",
    "end": "1576440"
  },
  {
    "text": "we didn't ice cubes then it's going to return a bunch of stuff that's relevant to that so we got all these coolers and",
    "start": "1576440",
    "end": "1582919"
  },
  {
    "text": "and things like that if I searched for I don't know use Outdoors then it will it",
    "start": "1582919",
    "end": "1588880"
  },
  {
    "text": "will return things to do with can stuff be used Outdoors or not uh because that's you know in most in the same",
    "start": "1588880",
    "end": "1595320"
  },
  {
    "text": "direction as the embedding Vector of my search query all right so I know that",
    "start": "1595320",
    "end": "1601080"
  },
  {
    "text": "was all a bit abstract but we've got to the point that we've got some data we can generate it as much as we want and",
    "start": "1601080",
    "end": "1607279"
  },
  {
    "text": "we can pull it into our system and we can start doing things like semantic search over it even though it came from",
    "start": "1607279",
    "end": "1612720"
  },
  {
    "text": "an unstructured format so I think we're ready to actually start our journey now so we can follow along and get to the",
    "start": "1612720",
    "end": "1619240"
  },
  {
    "text": "point of actually doing some inference over it uh and so I think at this point let's actually start up our real web",
    "start": "1619240",
    "end": "1626360"
  },
  {
    "text": "application and get a sense of how this is going to look and work so I'm going to start up now uh my app host so this",
    "start": "1626360",
    "end": "1632760"
  },
  {
    "text": "is an Aspire application Aspire is going to help us out in a lot of ways as we go through this process uh so if you don't",
    "start": "1632760",
    "end": "1639440"
  },
  {
    "text": "know Aspire I know most of you will but if you don't it's an orchestration system foret so it's a way of creating",
    "start": "1639440",
    "end": "1645520"
  },
  {
    "text": "software that's not just one executable but is many many different projects many different do Docker containers different",
    "start": "1645520",
    "end": "1652080"
  },
  {
    "text": "executables and so on and making them all work together so here are all the different things I've got running in my",
    "start": "1652080",
    "end": "1657720"
  },
  {
    "text": "application right now you don't need to know what most of them are the main characters that we're going to concern ourselves with are this backend project",
    "start": "1657720",
    "end": "1665279"
  },
  {
    "text": "which is minimal apis and that's got a bunch of backend stuff in it and then we've got these two web uis one for",
    "start": "1665279",
    "end": "1670760"
  },
  {
    "text": "customers and one for staff they're both built with Blazer and Aspire deals with",
    "start": "1670760",
    "end": "1675799"
  },
  {
    "text": "allowing them to discover each other and know their own each other's URLs and so on so let's start up our uh customer our",
    "start": "1675799",
    "end": "1683440"
  },
  {
    "text": "staff web UI and you can see it looks a lot like our mockup so we've got our list of support tickets we can go into",
    "start": "1683440",
    "end": "1689240"
  },
  {
    "text": "one of those and we get our uh entire conversation history with this customer",
    "start": "1689240",
    "end": "1694399"
  },
  {
    "text": "and like you can see it's too long to read nobody can be bothered to read all that sort of thing and it would waste too much staff time if they had to so",
    "start": "1694399",
    "end": "1701440"
  },
  {
    "text": "the first thing that we want to add in here the first bit of inference is going to be some summarization and hopefully",
    "start": "1701440",
    "end": "1708480"
  },
  {
    "text": "as we go you'll be able to see how Aspire can help out with doing that okay",
    "start": "1708480",
    "end": "1713840"
  },
  {
    "text": "so uh this is not going to be very difficult what I want to happen is every time someone posts a message here",
    "start": "1713840",
    "end": "1719840"
  },
  {
    "text": "whether it's staff or customer I want to generate an updated summary for it so let's say if I reply with a completely",
    "start": "1719840",
    "end": "1726159"
  },
  {
    "text": "stupid and annoying message that's just going to bother the customer a lot uh who's frustrated so I'll just send them",
    "start": "1726159",
    "end": "1731880"
  },
  {
    "text": "that stupid message what I want to happen at that time is a support is a summary to appear so I'm going to go",
    "start": "1731880",
    "end": "1737640"
  },
  {
    "text": "into the code and see the bit in the back end where we receive that message okay so this is where we set up",
    "start": "1737640",
    "end": "1744159"
  },
  {
    "text": "receiving a post requests for a new message that comes in this is where we actually write it to the database using",
    "start": "1744159",
    "end": "1749720"
  },
  {
    "text": "EF and then what I want to do is generate a summary of the entire conversation log at that point and the",
    "start": "1749720",
    "end": "1756600"
  },
  {
    "text": "implementation for that does what you might be able to predict so we're using I chat completion service which is the",
    "start": "1756600",
    "end": "1763159"
  },
  {
    "text": "same semantic kernel API that I showed you before and we set up this prompt that says your job is to write summaries",
    "start": "1763159",
    "end": "1769559"
  },
  {
    "text": "here's the information about the product and the log of messages so far and then I want you to reply in this Json form",
    "start": "1769559",
    "end": "1776440"
  },
  {
    "text": "giving me a long summary and a short summary and also while you're doing it you might as well estimate the",
    "start": "1776440",
    "end": "1781720"
  },
  {
    "text": "customer's satisfaction level okay so what is the implementation behind the uh",
    "start": "1781720",
    "end": "1788880"
  },
  {
    "text": "IAT completion service in this case well in this case it's coming from the",
    "start": "1788880",
    "end": "1794039"
  },
  {
    "text": "apphost so Aspire is able to direct each of the projects that it hosts uh so that",
    "start": "1794039",
    "end": "1800399"
  },
  {
    "text": "they will use whatever Services it tells them to use so in this case what I'm doing is I'm telling it to use ol by",
    "start": "1800399",
    "end": "1807840"
  },
  {
    "text": "default so it's going to run locally on my machine uh but this time I don't actually have to start up ol manually",
    "start": "1807840",
    "end": "1814279"
  },
  {
    "text": "because one actually I'm going even going to shut down the one that I did start up manually uh because uh Aspire",
    "start": "1814279",
    "end": "1820159"
  },
  {
    "text": "is fully able to start up containers for us so in this case I'm saying one of the containers it starts up is Ol it can",
    "start": "1820159",
    "end": "1826519"
  },
  {
    "text": "tell that to fetch whatever mod that I'm using and cash them locally and so on so hopefully that will now just start",
    "start": "1826519",
    "end": "1832440"
  },
  {
    "text": "working so if I just send another stupid message to the customer like this it's now going to use ol to generate the",
    "start": "1832440",
    "end": "1839559"
  },
  {
    "text": "summary of the the whole case it does take a little while because like I said ol takes a little bit of time to start",
    "start": "1839559",
    "end": "1846440"
  },
  {
    "text": "up when I'm running it locally in fact in this case it's seemingly taking an infinite amount of time so we're not",
    "start": "1846440",
    "end": "1852519"
  },
  {
    "text": "seeing it at all there we go it's done it all right so it's uh it's produced the summary and now the support agents",
    "start": "1852519",
    "end": "1860200"
  },
  {
    "text": "able to move a little bit faster with all that okay now I don't want to keep making you wait for Ola to start up",
    "start": "1860200",
    "end": "1866440"
  },
  {
    "text": "locally so I'm going to switch this over uh to use open AI locally uh which is",
    "start": "1866440",
    "end": "1872080"
  },
  {
    "text": "going to be quite a bit faster for us so if I restart that now then hopefully this time we won't be waiting quite as",
    "start": "1872080",
    "end": "1877919"
  },
  {
    "text": "long uh but you may well have more powerful hardware and not be giving a presentation at the time so uh the your",
    "start": "1877919",
    "end": "1883720"
  },
  {
    "text": "system will probably be a little bit more reliable than mine all right so let's try this again with with a different ticket uh so we'll go in here",
    "start": "1883720",
    "end": "1890039"
  },
  {
    "text": "and just send another message uh and at this point it's now going to not use it's just going to go straight to open",
    "start": "1890039",
    "end": "1896039"
  },
  {
    "text": "Ai and produce the same stuff without any other code changes you can also see",
    "start": "1896039",
    "end": "1901559"
  },
  {
    "text": "that it's generated these short summaries that we're able to use for the titles here and it's able to generate a",
    "start": "1901559",
    "end": "1907399"
  },
  {
    "text": "estimate of customer satisfaction in this case zero so that's pretty harsh in this case it's just one uh but you know",
    "start": "1907399",
    "end": "1914200"
  },
  {
    "text": "you can set up your own scale of how that works uh and I just give you a little tip while we're on the way when",
    "start": "1914200",
    "end": "1919720"
  },
  {
    "text": "it comes to those customer satisfaction scores I know it's tempting to tell the model to give you a number like give me",
    "start": "1919720",
    "end": "1925960"
  },
  {
    "text": "a number from 1 to 10 or a percentage or something but I'd advise don't do that because language models are models of",
    "start": "1925960",
    "end": "1931600"
  },
  {
    "text": "language not of numbers and they're really bad with numbers they'll just produce really poor quality results so",
    "start": "1931600",
    "end": "1937240"
  },
  {
    "text": "what I've find and what I think most people find if you want it to produce numbers don't ask for the numbers just",
    "start": "1937240",
    "end": "1942600"
  },
  {
    "text": "give it a bunch of really emotional terms like Furious and unhappy and delighted and things like that and tell",
    "start": "1942600",
    "end": "1948039"
  },
  {
    "text": "it to pick one of those as a label and it'll do a much more reliable job of that and then you can just map it back",
    "start": "1948039",
    "end": "1953200"
  },
  {
    "text": "to a number afterwards okay so that is some simple summarization and we've seen",
    "start": "1953200",
    "end": "1959440"
  },
  {
    "text": "how using Aspire enables to swap between different things such as adding an open AI in fact there's one other uh bit of",
    "start": "1959440",
    "end": "1966000"
  },
  {
    "text": "aspire I want to show you here which is to do with the tracing so this is going to show us all the stuff that's been",
    "start": "1966000",
    "end": "1972559"
  },
  {
    "text": "going on with this particular user uh you can use this both in development and in production if you want to and if we",
    "start": "1972559",
    "end": "1978399"
  },
  {
    "text": "look through here excuse me one of the things you'll see that we've uh been able to trace is calls to the chat",
    "start": "1978399",
    "end": "1985480"
  },
  {
    "text": "completion service so here it's captured that we made a call to GPT 35 and if we",
    "start": "1985480",
    "end": "1991519"
  },
  {
    "text": "look through all the properties on that it's a little tricky on a small screen but you can sort of see it uh that we've got the number of tokens that came back",
    "start": "1991519",
    "end": "1997760"
  },
  {
    "text": "in the completion so we can estimate the cost and if we scroll down here we can see the entire uh prompt that went in",
    "start": "1997760",
    "end": "2003919"
  },
  {
    "text": "and the entire completion response that came back so if you're needing to debug your system or try and make sense of",
    "start": "2003919",
    "end": "2009760"
  },
  {
    "text": "what's going on in production then this kind of tracing is obviously going to be helpful okay right let's move on to the",
    "start": "2009760",
    "end": "2017000"
  },
  {
    "text": "next form of inference that we might want to do and we are going to do the classic thing now of Q Andi or rag uh",
    "start": "2017000",
    "end": "2024120"
  },
  {
    "text": "retrieval augmented generation so let's make our chatbot actually work here so",
    "start": "2024120",
    "end": "2029760"
  },
  {
    "text": "all right so let's go into a different support ticket here let's go into this one and the first challenge we have here",
    "start": "2029760",
    "end": "2035080"
  },
  {
    "text": "or it's a challenge for me anyway is that they've made their request in German and I don't speak German I'm sure some of you do but let's imagine our",
    "start": "2035080",
    "end": "2041679"
  },
  {
    "text": "support agent does not so they might think that they can ask the the chat bar what are they asking like that uh but",
    "start": "2041679",
    "end": "2050599"
  },
  {
    "text": "it's not actually going to work just yet because we haven't implemented this part of the the rag system so we are going to",
    "start": "2050599",
    "end": "2056800"
  },
  {
    "text": "go and see how that code works and put in the relevant bits of code so that it does work all right so we've got this",
    "start": "2056800",
    "end": "2062800"
  },
  {
    "text": "bit on the back end here which takes these requests uh to chat and it's going to to return a response in a streaming",
    "start": "2062800",
    "end": "2069398"
  },
  {
    "text": "way so that we can update the UI in real time okay and we've got this massive prompt in C uh as's this big string",
    "start": "2069399",
    "end": "2075839"
  },
  {
    "text": "literal there are other ways of doing it as well but this is fine for now uh the main thing to notice here don't bother trying to read all this I'll tell you",
    "start": "2075839",
    "end": "2082079"
  },
  {
    "text": "more about it in a minute the main thing to notice is that it's just a hardcoded string like there's no context information so obviously it can't answer",
    "start": "2082079",
    "end": "2088599"
  },
  {
    "text": "the question it has literally no information to use to do so so let's insert a little bit of information into",
    "start": "2088599",
    "end": "2095398"
  },
  {
    "text": "this prompt we'll Supply the product ID model customer name the summary that we actually generated earlier which is",
    "start": "2095399",
    "end": "2101440"
  },
  {
    "text": "useful for it and the um the last message from the customer okay so let's",
    "start": "2101440",
    "end": "2107320"
  },
  {
    "text": "see if that's able to be a little bit more useful to our support agent now so",
    "start": "2107320",
    "end": "2112720"
  },
  {
    "text": "I'm just restarting that and come back over here and go back into which ticket",
    "start": "2112720",
    "end": "2119000"
  },
  {
    "text": "is this one let's close all the others all right so now we'll ask them what are",
    "start": "2119000",
    "end": "2124119"
  },
  {
    "text": "they asking and at this point based on the fact we've actually got some context",
    "start": "2124119",
    "end": "2129880"
  },
  {
    "text": "we get a sensible response back saying you know they're asking about the maximum distance there can be from this",
    "start": "2129880",
    "end": "2135079"
  },
  {
    "text": "speaker uh so then we might try to ask another thing like um let's say let's",
    "start": "2135079",
    "end": "2140560"
  },
  {
    "text": "just click this button what does the manual say about this well at that point it's still not going to work because we haven't implemented the ability to do",
    "start": "2140560",
    "end": "2147280"
  },
  {
    "text": "searching and that is the core thing within rag retriev or augmented generation is the ability to retrieve",
    "start": "2147280",
    "end": "2153599"
  },
  {
    "text": "stuff okay now the normal way of doing rag is to to use a feature called",
    "start": "2153599",
    "end": "2159440"
  },
  {
    "text": "function calling so you can configure the language model with some call backs and you can say okay if you need to you",
    "start": "2159440",
    "end": "2165880"
  },
  {
    "text": "can call my function and I'll give you answers to stuff so you might have a function like search the product manual",
    "start": "2165880",
    "end": "2171560"
  },
  {
    "text": "and the rag system will call you and then you will provide the details from the manual that's great except that only",
    "start": "2171560",
    "end": "2178560"
  },
  {
    "text": "works with open Ai and mistal and Gemini but not all language models work that",
    "start": "2178560",
    "end": "2183960"
  },
  {
    "text": "way okay and I want this to work with all the language models including all the random stuff that I'm running on Ola",
    "start": "2183960",
    "end": "2189640"
  },
  {
    "text": "locally so we can sort of make this work well enough by doing our own form of",
    "start": "2189640",
    "end": "2194720"
  },
  {
    "text": "function calling so the way that we can do this is we can say hey when you reply what I need you to do is first decide do",
    "start": "2194720",
    "end": "2201000"
  },
  {
    "text": "you actually have enough information to answer this question give me a true or false on that and then if you're saying",
    "start": "2201000",
    "end": "2207000"
  },
  {
    "text": "that you do have enough information at that point you can give me the answer as a string but if you don't have enough",
    "start": "2207000",
    "end": "2213839"
  },
  {
    "text": "information then say that you don't have enough information and give me a search phrase that we can use to look stuff up",
    "start": "2213839",
    "end": "2219880"
  },
  {
    "text": "in the manual and then we can set up a little Loop where we go through a certain number of iterations we'll set a",
    "start": "2219880",
    "end": "2226119"
  },
  {
    "text": "maximum and on each iteration we'll ask it the question and we'll see what it's responsive so we'll stream the reply to",
    "start": "2226119",
    "end": "2232920"
  },
  {
    "text": "the UI so we can see it in real time and when it's finished we'll check it we'll pause it and say were you giving me a",
    "start": "2232920",
    "end": "2238599"
  },
  {
    "text": "search phrase if so then I'm going to perform a search and I'll insert that into the chat history and then we'll run",
    "start": "2238599",
    "end": "2244800"
  },
  {
    "text": "another loop of the iteration and see if it can produce a better answer this time so now I'm going to insert the real",
    "start": "2244800",
    "end": "2250760"
  },
  {
    "text": "search Logic and that's going to do the exact same thing that you saw when I ran it in a console application before uh",
    "start": "2250760",
    "end": "2256960"
  },
  {
    "text": "and it will do that semantic search it will add that into the chat history and then we'll run the loop again and we'll",
    "start": "2256960",
    "end": "2263319"
  },
  {
    "text": "see if it's able to produce a useful response this time all right so this time when I say what does the manual say",
    "start": "2263319",
    "end": "2269119"
  },
  {
    "text": "about this then instead of saying um you know to do Implement searching it's actually done a search it's gone to the",
    "start": "2269119",
    "end": "2275119"
  },
  {
    "text": "manual and it's produced some relevant content but the most important thing is it also produces a citation so it's",
    "start": "2275119",
    "end": "2281560"
  },
  {
    "text": "telling us where exactly in the manual it got this information so the support staff can click on that and they can go",
    "start": "2281560",
    "end": "2287200"
  },
  {
    "text": "right into the manual it can highlight the exact B bit of text that is the basis for its claims and they can check",
    "start": "2287200",
    "end": "2292839"
  },
  {
    "text": "that it's actually telling the truth and not just making up some garbage so then they can come back and they say okay",
    "start": "2292839",
    "end": "2298599"
  },
  {
    "text": "fine write a reply saying that and it will hopefully produce a reply based on",
    "start": "2298599",
    "end": "2304960"
  },
  {
    "text": "this context uh except in this case obviously want in German like that uh so",
    "start": "2304960",
    "end": "2310359"
  },
  {
    "text": "now it's going to produce our reply in German okay and then once it's finished that we can simply click on this users",
    "start": "2310359",
    "end": "2316599"
  },
  {
    "text": "reply button because it's classifying its own responses about whether they're suitable to send to the customer or not",
    "start": "2316599",
    "end": "2321920"
  },
  {
    "text": "if they are we show this little button and then we can hit send on that and of course it goes to the customer and it produces a nice little summary including",
    "start": "2321920",
    "end": "2328640"
  },
  {
    "text": "stating what the support person did okay so that is the core thing of a of a rag",
    "start": "2328640",
    "end": "2335240"
  },
  {
    "text": "type system uh there's many ways you can go further with this uh much more sophistication is possible but this",
    "start": "2335240",
    "end": "2341160"
  },
  {
    "text": "gives you the sort of basic core kind of idea of how that might work with uh with",
    "start": "2341160",
    "end": "2346480"
  },
  {
    "text": "any model and it's even easier still if you're able to use function calling because then you don't have to implement all this stuff of uh checking whether",
    "start": "2346480",
    "end": "2353200"
  },
  {
    "text": "you've got enough information manually okay right so last bit of",
    "start": "2353200",
    "end": "2358920"
  },
  {
    "text": "inference that we're going to look at we're now going to look at other types of models so so far everything that",
    "start": "2358920",
    "end": "2364800"
  },
  {
    "text": "we've done has been based around large language models which is kind of like the generic tool that can solve any",
    "start": "2364800",
    "end": "2370119"
  },
  {
    "text": "problem in theory but you know it's kind of big and expensive to call and time consuming and for many types of problems",
    "start": "2370119",
    "end": "2376680"
  },
  {
    "text": "you can solve them with much smaller models that you can just run locally and more cheaply and in fact if you go on",
    "start": "2376680",
    "end": "2382319"
  },
  {
    "text": "hugging face you'll find there's literally hundreds of thousands of small models that people have put up there",
    "start": "2382319",
    "end": "2387400"
  },
  {
    "text": "that do things like classification or toxicity detection or all kinds of other",
    "start": "2387400",
    "end": "2392800"
  },
  {
    "text": "small bits of translation and rephrasing and sentiment analysis and things like that lots of different models and you",
    "start": "2392800",
    "end": "2399000"
  },
  {
    "text": "can run them all but one challenge you might face is that all the examples they give are in Python and this is one of",
    "start": "2399000",
    "end": "2405160"
  },
  {
    "text": "the sort of common objections that people have when we talk about building this sort of thing in net is they say oh",
    "start": "2405160",
    "end": "2410839"
  },
  {
    "text": "but you know doesn't most of the AI world use Python like wouldn't you be better just writing your application in",
    "start": "2410839",
    "end": "2415960"
  },
  {
    "text": "Python and as for getting started yeah you probably are because you can just copy and paste a whole bunch more stuff",
    "start": "2415960",
    "end": "2421800"
  },
  {
    "text": "uh but when it comes to actually managing this thing in production uh and using the skill set of your whole team well you you know you need to make that",
    "start": "2421800",
    "end": "2428760"
  },
  {
    "text": "judgment for yourself but I think a lot of people are going to prefer to use net for the broadest system so that leaves",
    "start": "2428760",
    "end": "2434400"
  },
  {
    "text": "us in a little bit of a quandry like maybe we do want to use Python for some things can we do that well the answer is",
    "start": "2434400",
    "end": "2439920"
  },
  {
    "text": "yes um I I the message I want to try and put out here is you don't need to be",
    "start": "2439920",
    "end": "2444960"
  },
  {
    "text": "limited to net okay even if the majority of your your application is in that if you want to use a bit of python or a bit",
    "start": "2444960",
    "end": "2450480"
  },
  {
    "text": "of java bit of nerde whatever you can do so very straightforwardly and an orchestrator like Aspire is designed to",
    "start": "2450480",
    "end": "2457440"
  },
  {
    "text": "make that more straightforward for you so what we're going to do now is we're going to use a bit of python and a small",
    "start": "2457440",
    "end": "2462680"
  },
  {
    "text": "model from hugging face to do some automatic classification and it's really quite straightforwards so uh down here",
    "start": "2462680",
    "end": "2469760"
  },
  {
    "text": "uh I've got a python project now Visual Studio has pretty good support for python obviously VSS code is just going to show you those files as well so it's",
    "start": "2469760",
    "end": "2476280"
  },
  {
    "text": "not hard to do it in your development process and I've got my main.py file it's really simple so I'm starting up a",
    "start": "2476280",
    "end": "2482960"
  },
  {
    "text": "fast API web server fast API is a bit like minimal apis in net it's a way that you can plug in different HTTP endpoints",
    "start": "2482960",
    "end": "2490720"
  },
  {
    "text": "and I've included a couple of endpoints one for a classifier one for an embedder the only one we're actually going to look at right now is classifier and the",
    "start": "2490720",
    "end": "2497599"
  },
  {
    "text": "logic for that is just this so very little code uh this is the bit where we actually register the HTP endpoint and",
    "start": "2497599",
    "end": "2504280"
  },
  {
    "text": "as for what it's going to do well we're going to use this Library called Transformers which comes from hugging face and that is able to fetch models",
    "start": "2504280",
    "end": "2511359"
  },
  {
    "text": "that have been published there uh here we've got this a reference to this model that I found that does zero shot",
    "start": "2511359",
    "end": "2517720"
  },
  {
    "text": "classification uh now let me explain what zero shot classification actually is and the way I'm going to do so is by",
    "start": "2517720",
    "end": "2523319"
  },
  {
    "text": "running this code so you can see it so let's go into there and I'm going to start up my python application it can",
    "start": "2523319",
    "end": "2530040"
  },
  {
    "text": "take a little while to start up locally so uh I'm just going to chat while that happens so zero shot classification is",
    "start": "2530040",
    "end": "2535960"
  },
  {
    "text": "where you take some oh it did start that's nice uh where you take some text and a set of possible labels and it will",
    "start": "2535960",
    "end": "2542640"
  },
  {
    "text": "tell you which label is actually the most relevant one for that text and we don't need a full language model to do",
    "start": "2542640",
    "end": "2548040"
  },
  {
    "text": "that so to give you an example of that let's make a request which is like I am",
    "start": "2548040",
    "end": "2553359"
  },
  {
    "text": "trying to score a goal that's the text that that we're trying to classify and the possible candidate labels are",
    "start": "2553359",
    "end": "2558880"
  },
  {
    "text": "programming health or Sports so if I run that it will immediately classify that as Sports which is a sensible one based",
    "start": "2558880",
    "end": "2565520"
  },
  {
    "text": "on what we're doing here uh if I also tried the same thing with I'm trying to score an AI model that comes back as",
    "start": "2565520",
    "end": "2572280"
  },
  {
    "text": "performance uh PB programming and if I did uh trying to score a hospital performance we get health so you can see",
    "start": "2572280",
    "end": "2579119"
  },
  {
    "text": "it's doing sensible classifications very quickly just running locally on my",
    "start": "2579119",
    "end": "2584440"
  },
  {
    "text": "machine now can we really use python as part of a net application well the",
    "start": "2584440",
    "end": "2589680"
  },
  {
    "text": "answer is yes we can so I'm just going to shut this down because I actually want this to be orchestrated by Aspire",
    "start": "2589680",
    "end": "2595480"
  },
  {
    "text": "so in my apphost project here I've got this thing that says add a python uicorn app uicorn is the server so that's a bit",
    "start": "2595480",
    "end": "2601920"
  },
  {
    "text": "like Kestrel if you know.net and uh we're going to tell it where that is on dis now this does not exist as an actual",
    "start": "2601920",
    "end": "2609720"
  },
  {
    "text": "method uh in uh Aspire but it's really easy to add because there's a good extensibility model the entire amount of",
    "start": "2609720",
    "end": "2616680"
  },
  {
    "text": "code needed to host python in our system is just this few lines of code you can see there so it's an executable resource",
    "start": "2616680",
    "end": "2623200"
  },
  {
    "text": "it's got this command name uh it takes these parameters and by doing this thing with environment variables we get it to",
    "start": "2623200",
    "end": "2628960"
  },
  {
    "text": "participate in the discovery system okay so a Spire will deal with starting that up and shutting it down and stuff like",
    "start": "2628960",
    "end": "2635240"
  },
  {
    "text": "that and then we can make ourselves a nice little strongly typed client for that uh in C so we've got this python",
    "start": "2635240",
    "end": "2641760"
  },
  {
    "text": "inference client that can classify text and it just does it by posting to the endpoint provided by Aspire and then we",
    "start": "2641760",
    "end": "2648240"
  },
  {
    "text": "can use it so where I want to use it is whenever a new issue gets posted because",
    "start": "2648240",
    "end": "2653800"
  },
  {
    "text": "the thing I actually want to use this for is the case type so remember we've got these different types and I want it",
    "start": "2653800",
    "end": "2660319"
  },
  {
    "text": "to automatically automatically populate based on the text of the customer",
    "start": "2660319",
    "end": "2665559"
  },
  {
    "text": "support request so I'm going to go to the place in my code where new tickets",
    "start": "2665559",
    "end": "2670880"
  },
  {
    "text": "get posted that's this create ticket here and you can see we're using that python client to classify the text and",
    "start": "2670880",
    "end": "2677280"
  },
  {
    "text": "we're saying you can pick any of the enum values in this ticket types enum",
    "start": "2677280",
    "end": "2682400"
  },
  {
    "text": "okay so let's see if that actually works it should do uh so I'm going to actually file a new support request now so I'm",
    "start": "2682400",
    "end": "2688359"
  },
  {
    "text": "going to pretend to be a customer so okay let's get started is this about a specific product uh no let's say I'm",
    "start": "2688359",
    "end": "2694400"
  },
  {
    "text": "just an absolutely crazy customer with ideas so I think",
    "start": "2694400",
    "end": "2699520"
  },
  {
    "text": "you should sell bees okay so we'll submit that and our request should go in",
    "start": "2699520",
    "end": "2706640"
  },
  {
    "text": "to the support staff and if we go over here that's updated and we can see that that has been classified as a comment or",
    "start": "2706640",
    "end": "2712559"
  },
  {
    "text": "idea which makes sense or we'll do another support request this time yeah it's about a specific product it's about",
    "start": "2712559",
    "end": "2718240"
  },
  {
    "text": "my foldy seat um and this is semantic search so even though foldy seat is not the name of it you know we can still",
    "start": "2718240",
    "end": "2724319"
  },
  {
    "text": "find it quite easily I need to return this and then we'll submit on that okay",
    "start": "2724319",
    "end": "2730839"
  },
  {
    "text": "back over here uh you see that this one has been classified as a returns and we didn't have to use an entire language",
    "start": "2730839",
    "end": "2736119"
  },
  {
    "text": "model large language model to do that we just use this small model and we've been able to integrate very nicely with a bit",
    "start": "2736119",
    "end": "2742200"
  },
  {
    "text": "of python okay so that's enough inference for now you might think at",
    "start": "2742200",
    "end": "2747400"
  },
  {
    "text": "this stage well I think I'm done I'm ready to put that into production and you kind of could but I think that would still be a bit of an amateurish level of",
    "start": "2747400",
    "end": "2754480"
  },
  {
    "text": "quality for your system because if we really want to reach the sort of summit of Enlightenment on our journey here we",
    "start": "2754480",
    "end": "2760839"
  },
  {
    "text": "need to start thinking about evaluation and test as well how do we know that this system is any good like how do we",
    "start": "2760839",
    "end": "2766680"
  },
  {
    "text": "know that the quality of what's coming back is what we want it to be and how can we systematically improve it over",
    "start": "2766680",
    "end": "2772720"
  },
  {
    "text": "time in a reliable way so let's start by thinking about evaluation like what does it even mean to evaluate something like",
    "start": "2772720",
    "end": "2779880"
  },
  {
    "text": "this like if you evaluating classification it's kind of obvious right you could make a test set of like",
    "start": "2779880",
    "end": "2785040"
  },
  {
    "text": "here's a bunch of text here's the labels I want you to give and you try it out and you work out what proportion of the time it gives you the right label so",
    "start": "2785040",
    "end": "2791640"
  },
  {
    "text": "that's a way of evaluating a classifier but it's not so obvious how to evaluate",
    "start": "2791640",
    "end": "2796800"
  },
  {
    "text": "you know this sort of response that comes back from uh our chat agent well in this case like we the chat agent has",
    "start": "2796800",
    "end": "2802440"
  },
  {
    "text": "no opinion about bees which makes sense because we've got no data about it but uh when we've asked it other things",
    "start": "2802440",
    "end": "2808200"
  },
  {
    "text": "before and it's given us a response how do we know if it's a good response or not well one of the advantages of",
    "start": "2808200",
    "end": "2815240"
  },
  {
    "text": "working from a generated data set is that as well as just generating the data like the the products and the um support",
    "start": "2815240",
    "end": "2822040"
  },
  {
    "text": "tickets and stuff we can also generate a set of evaluation uh data as well so in",
    "start": "2822040",
    "end": "2827680"
  },
  {
    "text": "this case I've generated actually let's show a different one uh this one all right so I've generated hundreds and",
    "start": "2827680",
    "end": "2834440"
  },
  {
    "text": "hundreds and hundreds and hundreds of questions about the products that have got specific objective answers like",
    "start": "2834440",
    "end": "2840680"
  },
  {
    "text": "what's the capacity of this teot 32 oun can it be used Outdoors no so that's uh",
    "start": "2840680",
    "end": "2846520"
  },
  {
    "text": "these are all question with hopefully objective answers and the reason why we believe these answers to actually be true and we count them as the ground",
    "start": "2846520",
    "end": "2853200"
  },
  {
    "text": "truth is that these don't come from our semantic search they don't come from our chatbot they these come from the",
    "start": "2853200",
    "end": "2860359"
  },
  {
    "text": "original data that we generated about the products before we built that into product manuals and stuff so this is",
    "start": "2860359",
    "end": "2865720"
  },
  {
    "text": "like the underlying secret data that our products were constructed from okay so",
    "start": "2865720",
    "end": "2871559"
  },
  {
    "text": "now hopefully we can use these to actually evaluate our system so what I'm going to do is I'm going to start this",
    "start": "2871559",
    "end": "2877720"
  },
  {
    "text": "running in a slightly different way just uh so that I can run multiple things at once so I'm going to start the backend",
    "start": "2877720",
    "end": "2884440"
  },
  {
    "text": "running like this and now I'm going to run this other project here called evaluator all right so what that's going",
    "start": "2884440",
    "end": "2890680"
  },
  {
    "text": "to do is it's going to Loop over all the questions and for each one it's going to ask the question get the answer back",
    "start": "2890680",
    "end": "2896880"
  },
  {
    "text": "compare that to what we think is the right answer and score it and then we're going to work out an average score based",
    "start": "2896880",
    "end": "2902920"
  },
  {
    "text": "on all that stuff okay so that's running now it's asking these questions it's getting back answers we're doing it in",
    "start": "2902920",
    "end": "2908440"
  },
  {
    "text": "parallel as much as possible cuz this could take a little while once we've got enough answers back we'll send a batch",
    "start": "2908440",
    "end": "2914040"
  },
  {
    "text": "of them to another language model which is instructed to compare the answers that were given with the real answers",
    "start": "2914040",
    "end": "2920400"
  },
  {
    "text": "and say how much the the real the answer given is uh a reflective of the truth",
    "start": "2920400",
    "end": "2926040"
  },
  {
    "text": "okay and we get a score in this case it's looking like it's about 0. five the number on its own doesn't mean anything",
    "start": "2926040",
    "end": "2931359"
  },
  {
    "text": "all we all we care about is that bigger numbers are better okay and if we run this for long enough this happens that",
    "start": "2931359",
    "end": "2937160"
  },
  {
    "text": "it will average out at about 6 I've done it before so that's what it's going to be and if you want to really see behind",
    "start": "2937160",
    "end": "2942920"
  },
  {
    "text": "the scenes a little bit as to how this actually works and how it's deciding what score to give we're logging um so",
    "start": "2942920",
    "end": "2948920"
  },
  {
    "text": "we're saying um in this case like the query is outdoor suitability and the",
    "start": "2948920",
    "end": "2954000"
  },
  {
    "text": "true answer is no the answer that came back is yes so that is clearly misleading uh it's being a bit generous",
    "start": "2954000",
    "end": "2960680"
  },
  {
    "text": "actually by giving it a non-zero score in this case uh but you know you can see that better uh answers we'll get better",
    "start": "2960680",
    "end": "2967079"
  },
  {
    "text": "scores so let's find an example of a good one so what's the magnification of these binoculars true answer is 10x the",
    "start": "2967079",
    "end": "2972640"
  },
  {
    "text": "answer given is 10x and so yes you get a score of one that's a perfect answer all right and we work out the average of",
    "start": "2972640",
    "end": "2978880"
  },
  {
    "text": "these over time any individual question and answer is not going to give you much signal because you know the the question",
    "start": "2978880",
    "end": "2985040"
  },
  {
    "text": "might not be quite right the scoring might not be quite right but over the long run the average gives you some actual meaningful data okay now you",
    "start": "2985040",
    "end": "2992319"
  },
  {
    "text": "might think okay point six is that good or bad I don't know but could we improve it this is the whole point of this kind",
    "start": "2992319",
    "end": "2998240"
  },
  {
    "text": "of evaluation is that it helps us to make sensible changes to our system and then find out whether it actually",
    "start": "2998240",
    "end": "3004119"
  },
  {
    "text": "improves stuff or not so maybe you've used this for a bit and you think you know what it hallucinates a bit",
    "start": "3004119",
    "end": "3009680"
  },
  {
    "text": "sometimes instead of searching the product manual it just makes up an answer based on nothing which is a bit annoying can we make it do better by",
    "start": "3009680",
    "end": "3017160"
  },
  {
    "text": "forcing it to search the manual a little bit more reliably okay so I'm going to go into the prompt here that we saw",
    "start": "3017160",
    "end": "3023559"
  },
  {
    "text": "before and I'm going to add another phrase here that says if this is about the product I really want you to search",
    "start": "3023559",
    "end": "3030480"
  },
  {
    "text": "the manual okay I'm begging you check that manual this is your command all right so I've made that change to the",
    "start": "3030480",
    "end": "3037200"
  },
  {
    "text": "prompt and now we'll evaluate whether it actually makes stuff better or worse so I'm going to shut this application down",
    "start": "3037200",
    "end": "3044200"
  },
  {
    "text": "and then I'm going to rebuild it like that so that",
    "start": "3044200",
    "end": "3050280"
  },
  {
    "text": "rebuilds okay going to restart it and I'm going to rerun the evaluator so the",
    "start": "3050280",
    "end": "3055839"
  },
  {
    "text": "key thing here is is this is a true endtoend evaluation system we're not",
    "start": "3055839",
    "end": "3060960"
  },
  {
    "text": "just evaluating The Prompt we're not just evaluating the model we're not just evaluating the chunking or the pausing",
    "start": "3060960",
    "end": "3066400"
  },
  {
    "text": "or the embedding or the vector database we're evaluating the complete endtoend system Aspire makes it quite straight",
    "start": "3066400",
    "end": "3072599"
  },
  {
    "text": "forwards to us for us to make calls into the actual back end using our strongly type clients and get uh a real result",
    "start": "3072599",
    "end": "3079400"
  },
  {
    "text": "back from our system in this case after changing it the average has been going up it was about 6 before it's looking",
    "start": "3079400",
    "end": "3084880"
  },
  {
    "text": "like it's about 7 now in fact if you let it run for long enough uh you'll get a nice stable average and I've done that",
    "start": "3084880",
    "end": "3091680"
  },
  {
    "text": "so what I found is that by adding that phrase to the product before we got a score of about 61 and afterwards we were",
    "start": "3091680",
    "end": "3098720"
  },
  {
    "text": "getting a score of 77 so clearly that is a really good objective Improvement to",
    "start": "3098720",
    "end": "3104000"
  },
  {
    "text": "the score of our system but it does come at a cost so we can also see that the time has gone up from 2 seconds to 2.6",
    "start": "3104000",
    "end": "3111200"
  },
  {
    "text": "seconds which makes sense because it's spending some time doing some extra lookups against the manual database and",
    "start": "3111200",
    "end": "3117599"
  },
  {
    "text": "generating more response so that hopefully makes sense to you we can also make other changes to our system we can",
    "start": "3117599",
    "end": "3123359"
  },
  {
    "text": "change the ingestion process or the chunking or whatever else we want uh we could try changing the models so I tried",
    "start": "3123359",
    "end": "3128839"
  },
  {
    "text": "this out with GPT 40 and I saw that the score went all the way up to 08 which is clearly a lot better but also that comes",
    "start": "3128839",
    "end": "3134720"
  },
  {
    "text": "at the cost of making the time go up by like two and a half times so that means that you as a developer can make",
    "start": "3134720",
    "end": "3141359"
  },
  {
    "text": "sensible judgments about these tradeoffs of quality speed and cost and also that",
    "start": "3141359",
    "end": "3146799"
  },
  {
    "text": "you can know when you make changes to your system does it actually make stuff better or worse okay now this is a",
    "start": "3146799",
    "end": "3152160"
  },
  {
    "text": "pretty simple evaluation metric we just get in a single number there are other better forms of measurement of rag",
    "start": "3152160",
    "end": "3158760"
  },
  {
    "text": "systems so there's a thing called rag Triad that measures three different things about the the relevance of the",
    "start": "3158760",
    "end": "3163960"
  },
  {
    "text": "context that were provided the degree of groundedness of the answer in the context and the degree of relevance of",
    "start": "3163960",
    "end": "3169200"
  },
  {
    "text": "the answer to the question and those three things together are a richer score that also gives you a way of measuring",
    "start": "3169200",
    "end": "3174440"
  },
  {
    "text": "to some extent how much Hallucination is happening so there's there's further you can go with this if you want to uh I believe",
    "start": "3174440",
    "end": "3180680"
  },
  {
    "text": "that um Tess is doing a talk later on about uh how llms can go wrong and in",
    "start": "3180680",
    "end": "3186440"
  },
  {
    "text": "that talk she's going to cover some of these more advanced uh rag evaluation methods uh so if you want to know more",
    "start": "3186440",
    "end": "3191680"
  },
  {
    "text": "about that you can do so okay so last thing we're going to do now a little bit of endtoend testing I'm sure many of you",
    "start": "3191680",
    "end": "3198119"
  },
  {
    "text": "do write endtoend tests for your applications so let's just start running a test and look at some of the code",
    "start": "3198119",
    "end": "3203839"
  },
  {
    "text": "that's in there so let's say that you want to have a test that looks a bit like this so we want to use endtoend",
    "start": "3203839",
    "end": "3210640"
  },
  {
    "text": "testing I'm using playright here to start up our application and go and ask",
    "start": "3210640",
    "end": "3216160"
  },
  {
    "text": "a question of the support agent so in this case what product is ticket one about and we expect it to reply with",
    "start": "3216160",
    "end": "3222359"
  },
  {
    "text": "this particular reply or does this product have a battery and we expect it to reply like that now there's a couple",
    "start": "3222359",
    "end": "3228160"
  },
  {
    "text": "of challenges to doing this the first challenge is uh to do with having the",
    "start": "3228160",
    "end": "3233440"
  },
  {
    "text": "application run in a known state so it's no good just to run the application in whatever state it happens to be on the",
    "start": "3233440",
    "end": "3238880"
  },
  {
    "text": "developer machine because maybe they've already deleted ticket one or something and then the test would fail so that's",
    "start": "3238880",
    "end": "3244520"
  },
  {
    "text": "something that a Spire can help us with uh when the application is running we can seed it uh with different data in",
    "start": "3244520",
    "end": "3250760"
  },
  {
    "text": "different scenarios so here uh I've got a bit of code that picks up a a an environment variable or config value so",
    "start": "3250760",
    "end": "3257599"
  },
  {
    "text": "we know whether we're running under test and if we are running under ended under endtoend test then we're going to use um",
    "start": "3257599",
    "end": "3263960"
  },
  {
    "text": "a particular seed data that comes from this test directory so I've got a a well-known set of data in here all these",
    "start": "3263960",
    "end": "3270559"
  },
  {
    "text": "Json files uh these can be stored in Source control so it's shared across everyone on the team and you know that",
    "start": "3270559",
    "end": "3276119"
  },
  {
    "text": "your end to end tests are always going to start in that form okay so that makes sense but the other challenge is to do",
    "start": "3276119",
    "end": "3282160"
  },
  {
    "text": "with uh determinism so language models are not deterministic in general even if",
    "start": "3282160",
    "end": "3287760"
  },
  {
    "text": "you tell them to be and give them a seed and uh you know tell them to have a low temperature they still won't actually be",
    "start": "3287760",
    "end": "3293760"
  },
  {
    "text": "deterministic so you might think that your n to n test just going to fail at random there is a good pattern that you",
    "start": "3293760",
    "end": "3299040"
  },
  {
    "text": "can use to deal with this which I've seen in a few places I've used it myself uh when doing the smart component stuff",
    "start": "3299040",
    "end": "3304640"
  },
  {
    "text": "which is very simple it's just caching so when this these tests run for the first time they will call the real",
    "start": "3304640",
    "end": "3310240"
  },
  {
    "text": "language model and behave doing whatever it says but they will also cach that response from the language model on disk",
    "start": "3310240",
    "end": "3317400"
  },
  {
    "text": "so I've got this directory here where we've generated these cache entries so each entry in here is the full request",
    "start": "3317400",
    "end": "3324880"
  },
  {
    "text": "that goes out to the language model back end all the history of the chat and the parameters and stuff and then all of the",
    "start": "3324880",
    "end": "3330839"
  },
  {
    "text": "response like exactly broken down into all the chunks that come back and we can just store that on disk uh with a shash",
    "start": "3330839",
    "end": "3337200"
  },
  {
    "text": "so we can identify it later and then when you run the test for a second time then it's just going to match these",
    "start": "3337200",
    "end": "3342920"
  },
  {
    "text": "cache entries it won't go out to the network and so your tests are going to run fast they're going to run deterministically and it also means that",
    "start": "3342920",
    "end": "3349640"
  },
  {
    "text": "when you run these on your CI server you don't even need to have any API keys because it's never even going to talk to",
    "start": "3349640",
    "end": "3354880"
  },
  {
    "text": "the external service so that's a pattern that you can use to make your tests a bit faster and more deterministic of",
    "start": "3354880",
    "end": "3360440"
  },
  {
    "text": "course you can still change the prompts and the parameters later uh once you've done that it just won't hit the cache",
    "start": "3360440",
    "end": "3365520"
  },
  {
    "text": "entries anymore so your test will fail until you regenerate them so that's a pattern that you can use uh if you want",
    "start": "3365520",
    "end": "3370960"
  },
  {
    "text": "to make endtoend tests deterministic all right so that's the end of our journey",
    "start": "3370960",
    "end": "3376079"
  },
  {
    "text": "through all this um if you want the code to this well uh you can't have it just yet sorry uh but we we're working on it",
    "start": "3376079",
    "end": "3383480"
  },
  {
    "text": "okay we've even got a URL uh just need to finish a little bit of approvals and getting a sign off on that and then",
    "start": "3383480",
    "end": "3390119"
  },
  {
    "text": "we'll mark this as public if you go there now you'll just get a 404 but anyway I've put the URL so that hopefully you can get it in a week or",
    "start": "3390119",
    "end": "3396119"
  },
  {
    "text": "two uh and that's it so let's finish off with a summary so what have we been thinking about well I think one of the",
    "start": "3396119",
    "end": "3402280"
  },
  {
    "text": "key points here is that there's many different things you can do right you don't just have to do jat chat Bots there are different UI patterns like",
    "start": "3402280",
    "end": "3408480"
  },
  {
    "text": "semantic search and summarization and classification things like that many different patterns for that and also",
    "start": "3408480",
    "end": "3413760"
  },
  {
    "text": "many different ways of running language models it's not just particular hosted Services you can run stuff locally you",
    "start": "3413760",
    "end": "3419240"
  },
  {
    "text": "can use different models small models from hugging face things like that lots of options open to you uh I really want",
    "start": "3419240",
    "end": "3425839"
  },
  {
    "text": "to encourage you to focus on evaluation from day one having some sort of numerical feedback of the quality of",
    "start": "3425839",
    "end": "3431640"
  },
  {
    "text": "what you're doing will give you a lot of confidence to make changes and be sure that you're actually moving stuff in a",
    "start": "3431640",
    "end": "3437119"
  },
  {
    "text": "good direction now in net there's a lot of good tools available to you so I've hopefully shown you some of the benefits",
    "start": "3437119",
    "end": "3443520"
  },
  {
    "text": "of aspire for orchestrating these systems that got many different containers and projects and tests and",
    "start": "3443520",
    "end": "3448680"
  },
  {
    "text": "things like that uh so Aspire can help you out obviously you've got semantic kernel as well which gives you these",
    "start": "3448680",
    "end": "3454200"
  },
  {
    "text": "apis for working with language models and embeddings and different stuff like that okay but you're not limited to",
    "start": "3454200",
    "end": "3459720"
  },
  {
    "text": "those you can just use anything you like from any technology ecosystem and then finally I will point out that everything",
    "start": "3459720",
    "end": "3465760"
  },
  {
    "text": "I'm showing you here is just emerging stuff like the patterns around this have not really settled yet it might be that",
    "start": "3465760",
    "end": "3470799"
  },
  {
    "text": "a year from now we say actually there's a different and better way to do stuff it's all still being figured out and I",
    "start": "3470799",
    "end": "3476640"
  },
  {
    "text": "feel like maybe we're still missing some libraries that would make it easier like I could easily imagine a library for",
    "start": "3476640",
    "end": "3482079"
  },
  {
    "text": "data generation or ingestion or evaluation or whatever maybe one of you would like to create an open source Library like that I think there is a",
    "start": "3482079",
    "end": "3488799"
  },
  {
    "text": "there's a space in the market for it so there we go that is all we have got time for I hope that's useful to you I hope",
    "start": "3488799",
    "end": "3495000"
  },
  {
    "text": "you uh take this out and enjoy the rest of your conference uh please uh evaluate as you go out and I would really love to",
    "start": "3495000",
    "end": "3501440"
  },
  {
    "text": "speak to you any any of you who are doing this sort of thing because I want to learn from you too about what your real world experience of of doing this",
    "start": "3501440",
    "end": "3507799"
  },
  {
    "text": "sort of thing is so uh let's leave it at that thank you very much enjoy your day",
    "start": "3507799",
    "end": "3514078"
  }
]
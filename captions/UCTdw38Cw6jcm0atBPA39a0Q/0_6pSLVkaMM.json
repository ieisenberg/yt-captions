[
  {
    "start": "0",
    "end": "251000"
  },
  {
    "text": "my name is Arthur doler or art and call me whatever carry I come from the",
    "start": "89",
    "end": "5759"
  },
  {
    "text": "far-flung lands of Nebraska which is not so far flung as most NDC's I've been at",
    "start": "5759",
    "end": "11130"
  },
  {
    "text": "with like laws lower in London but I work for a company they're called amateur nobody's gonna see that great",
    "start": "11130",
    "end": "18420"
  },
  {
    "text": "that's fine we do consulting so I am a software engineer I'm not a psychologist I'm not a psychiatrist I'm not barely",
    "start": "18420",
    "end": "27390"
  },
  {
    "text": "even a data scientist I guess I do I solve problems I just happened to do it with code most of the time so that's",
    "start": "27390",
    "end": "33809"
  },
  {
    "text": "kind of where my mindset is and where I come from my Twitter is up there my gmail is up there if you have questions",
    "start": "33809",
    "end": "39440"
  },
  {
    "text": "afterward so I know you're not supposed to do this in a conference talk but I",
    "start": "39440",
    "end": "45899"
  },
  {
    "text": "want everybody to take their phone out and just find some app that has",
    "start": "45899",
    "end": "52110"
  },
  {
    "text": "predictive text in it like you're texting you know a messaging app whatever something that will have a predictive keyboard and I want everybody",
    "start": "52110",
    "end": "59699"
  },
  {
    "text": "to enter in the nurse said and then space and see what the next suggested",
    "start": "59699",
    "end": "65158"
  },
  {
    "text": "words are",
    "start": "65159",
    "end": "67579"
  },
  {
    "text": "how many people's results included the word sheet pretty much all of you most",
    "start": "74729",
    "end": "81009"
  },
  {
    "text": "of you how many included the word he three four",
    "start": "81009",
    "end": "86500"
  },
  {
    "text": "okay there was a fifth it's a pretty clear swing there now try it with this",
    "start": "86500",
    "end": "92229"
  },
  {
    "text": "one the software engineer said",
    "start": "92229",
    "end": "96270"
  },
  {
    "text": "anybody sees she in this one - how many",
    "start": "104399",
    "end": "109420"
  },
  {
    "text": "see he there we go this might seem like",
    "start": "109420",
    "end": "119439"
  },
  {
    "text": "it's kind of spurious and it doesn't really matter but this is the kind of",
    "start": "119439",
    "end": "125380"
  },
  {
    "text": "thing that lurks on the outsides of our cognitive experience this is the kind of",
    "start": "125380",
    "end": "131440"
  },
  {
    "text": "undercurrent in society and in culture that can actually shape behavior when we're not paying attention to it",
    "start": "131440",
    "end": "137530"
  },
  {
    "text": "I wouldn't shape behavior of people who are growing up in that culture in society and this becomes really",
    "start": "137530",
    "end": "143530"
  },
  {
    "text": "important because we are starting to make a lot of use of AI and machine learning we're using it because it's",
    "start": "143530",
    "end": "151660"
  },
  {
    "text": "becoming easier to do there are all kinds of tool sets out there now where you can just throw data at something and",
    "start": "151660",
    "end": "157120"
  },
  {
    "text": "it will construct you a model that's predictive of something and it's becoming more powerful stuff like",
    "start": "157120",
    "end": "162250"
  },
  {
    "text": "tensorflow was ridiculous you can you do deep learning and reinforcement learning and you have no idea what you're doing",
    "start": "162250",
    "end": "168930"
  },
  {
    "text": "we're using it to solve complex and important problems because that's generally what we try and do things that",
    "start": "168930",
    "end": "174190"
  },
  {
    "text": "are gonna save people money things that are gonna actually mean something or do something in the world and we're using",
    "start": "174190",
    "end": "179650"
  },
  {
    "text": "it to supplement the work force we're using this for things like office automation and because we're using it",
    "start": "179650",
    "end": "186579"
  },
  {
    "text": "primarily for those two things that complex things or because we don't have enough people to run this it means that",
    "start": "186579",
    "end": "191769"
  },
  {
    "text": "we can't stay on tap on tabs with it all the time we have to we can't pay attention to it and so when it breaks we",
    "start": "191769",
    "end": "197859"
  },
  {
    "text": "might not even know it's going to break because if we were just going to monitor the output all the time then we might as well just have a human do it and",
    "start": "197859",
    "end": "205000"
  },
  {
    "text": "sometimes we don't even know how it works when you feed some data into something",
    "start": "205000",
    "end": "210489"
  },
  {
    "text": "like tensorflow and it spits back out a model at you can you describe what that's actually doing even if you're",
    "start": "210489",
    "end": "215739"
  },
  {
    "text": "using some more traditional data science techniques things when you start recom you know recombination columns or when",
    "start": "215739",
    "end": "221440"
  },
  {
    "text": "you're using a neural network you can't explain why something occurred I mean you can't explain the math but that",
    "start": "221440",
    "end": "227200"
  },
  {
    "text": "doesn't mean anything in terms of symbols or language and the most",
    "start": "227200",
    "end": "232540"
  },
  {
    "text": "important thing is that because it is getting so easy and because it is becoming ubiquitous more and more people are doing it",
    "start": "232540",
    "end": "238970"
  },
  {
    "text": "regular developers like you and me are writing these things we're creating",
    "start": "238970",
    "end": "245720"
  },
  {
    "text": "models we're creating predictive things we're creating classifiers and that has",
    "start": "245720",
    "end": "251390"
  },
  {
    "start": "251000",
    "end": "251000"
  },
  {
    "text": "some real consequences if we're wrong",
    "start": "251390",
    "end": "256750"
  },
  {
    "text": "take for instance risk assessment software this is software that is used",
    "start": "256750",
    "end": "263570"
  },
  {
    "text": "either during parole hearings or during sentencing hearings to display the risk",
    "start": "263570",
    "end": "268730"
  },
  {
    "text": "that an offender criminal offender will be recidivist we'll reoffending",
    "start": "268730",
    "end": "275620"
  },
  {
    "text": "ProPublica did an article on this this was in the news very large study these",
    "start": "275620",
    "end": "282080"
  },
  {
    "text": "are risk scores go from one to ten and",
    "start": "282080",
    "end": "289490"
  },
  {
    "text": "those are the counts so it's just a standard histogram the top part of that chart is for black defendants the bottom",
    "start": "289490",
    "end": "296180"
  },
  {
    "text": "part is for white defendants this gets",
    "start": "296180",
    "end": "302270"
  },
  {
    "text": "worse because later most of these programs have been found to be no better than flipping a coin at actually",
    "start": "302270",
    "end": "307370"
  },
  {
    "text": "predicting whether somebody's going to reoffended but you've just sentenced somebody to three years to life for",
    "start": "307370",
    "end": "313400"
  },
  {
    "text": "thirty years to live congratulations this can actually ruin lives",
    "start": "313400",
    "end": "321040"
  },
  {
    "text": "and it can happen without us even thinking about it imagine if you were trying to work on",
    "start": "321040",
    "end": "326570"
  },
  {
    "text": "some kind of natural language processing algorithm something where you're doing sentiment analysis where you basically",
    "start": "326570",
    "end": "331820"
  },
  {
    "text": "evaluate the words and determine whether it has a positive sentiment whether people are happy about a thing or whether it's a negative sentiment",
    "start": "331820",
    "end": "337730"
  },
  {
    "text": "they're not happy about a thing and then you put in some sentences involving first names from people with various",
    "start": "337730",
    "end": "344630"
  },
  {
    "text": "ethnic backgrounds various traditional ethnic first names I spy an outlier how",
    "start": "344630",
    "end": "350900"
  },
  {
    "text": "about you I mean if you look at the far",
    "start": "350900",
    "end": "356000"
  },
  {
    "text": "right over there white names have a higher sentiment value higher mean",
    "start": "356000",
    "end": "361730"
  },
  {
    "text": "sentiment value and a lower error if you look at the actual whisker plot",
    "start": "361730",
    "end": "368360"
  },
  {
    "text": "I don't want to come at you this day and I don't this is not about fault this is",
    "start": "368360",
    "end": "373490"
  },
  {
    "text": "not about blaming people this is not about asking who did it who done it and I'm gonna be talking about a lot of",
    "start": "373490",
    "end": "380360"
  },
  {
    "text": "different things today where these things have come up but it's not in me it's I'm not blaming somebody I'm not",
    "start": "380360",
    "end": "386210"
  },
  {
    "text": "trying to call them out and have us all yell at them in a big circular yell fest",
    "start": "386210",
    "end": "391490"
  },
  {
    "text": "that's not helpful what I'm trying to do today is talk to you about responsibility and to talk to",
    "start": "391490",
    "end": "398720"
  },
  {
    "text": "you about the reality of this data and what it does and how we tend to behave with it and so today we're going to talk",
    "start": "398720",
    "end": "407509"
  },
  {
    "text": "about six different classes of problems with AI and machine learning because I am a huge nerd I have decided that these",
    "start": "407509",
    "end": "413479"
  },
  {
    "text": "correlate with the classes of ghosts from the Ghostbusters movies and that",
    "start": "413479",
    "end": "423889"
  },
  {
    "text": "kind of fits with how I like to think about them these things are like our cognitive biases just they're there if",
    "start": "423889",
    "end": "431270"
  },
  {
    "text": "we don't pay attention these things tend to creep in they're the ghosts in our machine learning and while I may not",
    "start": "431270",
    "end": "438680"
  },
  {
    "text": "have a degree in psychiatry or psychology it's very possible I have a degree in parapsychology and I know what",
    "start": "438680",
    "end": "447289"
  },
  {
    "text": "we do with ghosts we bust ghosts so today I'm gonna be giving you some tips simply is to think about this to help",
    "start": "447289",
    "end": "455479"
  },
  {
    "text": "you overcome some of these problems some of these are things that science has been doing for a while we just need to",
    "start": "455479",
    "end": "460849"
  },
  {
    "text": "catch up some of these things are big intractable problems that I don't have firm solutions for just general",
    "start": "460849",
    "end": "466520"
  },
  {
    "text": "guidelines and suggestions of places that look for solutions this is a really hot topic I was revising this this more",
    "start": "466520",
    "end": "472940"
  },
  {
    "text": "this slide deck literally this morning because new things keep coming out the",
    "start": "472940",
    "end": "478039"
  },
  {
    "text": "first time I gave this talk a couple of months ago there was another speaker giving a talk on the same topic and we",
    "start": "478039",
    "end": "484610"
  },
  {
    "text": "had one overlapping example from two 1-hour talks this stuff happens a lot",
    "start": "484610",
    "end": "490009"
  },
  {
    "text": "and it happens everywhere so we're going to go through each of these in turn",
    "start": "490009",
    "end": "495639"
  },
  {
    "text": "phantoms of false correlation specter of bias sample data shade of overly simplistic maximization the simulation",
    "start": "495639",
    "end": "501830"
  },
  {
    "text": "surprise is the apparition of fairness and finally the feedback devil so we're gonna go through each of those in turn",
    "start": "501830",
    "end": "507080"
  },
  {
    "text": "and talk about what we can do we're gonna start off with phantoms of false correlation false correlation happens",
    "start": "507080",
    "end": "514849"
  },
  {
    "text": "when you don't know what you're actually trying to ask you don't know the question you're going to your data to",
    "start": "514849",
    "end": "520849"
  },
  {
    "text": "ask basically you're just gonna have a plug pile of data and somebody told you you need to do a machine learning with",
    "start": "520849",
    "end": "527180"
  },
  {
    "text": "it and you're like great what it okay and you just start hunting what you do is you go fishing and if you go fishing",
    "start": "527180",
    "end": "534920"
  },
  {
    "text": "and you don't know what you're trying to catch you can wind up with something and think it's way better than it actually",
    "start": "534920",
    "end": "540470"
  },
  {
    "text": "is you can find these arbitrary correlations and you can become confused",
    "start": "540470",
    "end": "546650"
  },
  {
    "text": "and think that they actually predict something which isn't necessarily true",
    "start": "546650",
    "end": "552850"
  },
  {
    "text": "so for those of you who don't know what correlation is it's a really quick summary correlation is basically these",
    "start": "552850",
    "end": "560150"
  },
  {
    "text": "fit between two data sets so we have two data sets here the red triangles and the",
    "start": "560150",
    "end": "565490"
  },
  {
    "text": "blue circles and I've shown the dashed lines which is more or less the distance between these and you could take that",
    "start": "565490",
    "end": "571760"
  },
  {
    "text": "distance between those two points and you know subtract the distant or subtract the two values get the distance",
    "start": "571760",
    "end": "577430"
  },
  {
    "text": "then take the square root of it eventually you get the mean squared error don't worry about it I'm not gonna",
    "start": "577430",
    "end": "583640"
  },
  {
    "text": "go too heavily into math today but when you just look for correlation you can",
    "start": "583640",
    "end": "592880"
  },
  {
    "text": "wind up at some pretty weird places these are from the amazing sight",
    "start": "592880",
    "end": "601029"
  },
  {
    "text": "experienced correlations correlations happen naturally",
    "start": "601510",
    "end": "607040"
  },
  {
    "text": "things correlate with each other I mean as much as I'm would like to believe that the number of people who drown by",
    "start": "607040",
    "end": "613220"
  },
  {
    "text": "falling in a pool is related to the number of films that Nicolas Cage just started pretty sure it's not true and I'm pretty sure the divorce rate in",
    "start": "613220",
    "end": "619820"
  },
  {
    "text": "Maine has nothing to do with the per capita consumption of margarine and I'm definitely sure that the letters in the",
    "start": "619820",
    "end": "626390"
  },
  {
    "text": "winning word of the script spelling bee has nothing to do with the number of people killed by banana spiders but as",
    "start": "626390",
    "end": "633529"
  },
  {
    "text": "you can see those are pretty highly correlated it's really easy for our pattern-matching brain to look at those",
    "start": "633529",
    "end": "638700"
  },
  {
    "text": "things and say oh look this is something that's meaningful but it's not it's just the correlation this is kind of the",
    "start": "638700",
    "end": "646170"
  },
  {
    "text": "easiest most common error that we're gonna run across and it's almost it's the easiest that you can get rid of the",
    "start": "646170",
    "end": "652470"
  },
  {
    "text": "easiest to deal with so what you can do about this is just start by at knowing what you're gonna ask upfront going to",
    "start": "652470",
    "end": "658380"
  },
  {
    "start": "655000",
    "end": "655000"
  },
  {
    "text": "your data with an actual question saying well what predicts this I want to see what correlates with this and asking",
    "start": "658380",
    "end": "665490"
  },
  {
    "text": "that question because if you just go looking in your data for correlations you're going to find them machine",
    "start": "665490",
    "end": "671459"
  },
  {
    "text": "learning or not humans are very very good at finding patterns and we tend to have built that into our machine",
    "start": "671459",
    "end": "676920"
  },
  {
    "text": "learning tools because patterns are useful both for us and for them you can",
    "start": "676920",
    "end": "682110"
  },
  {
    "text": "also try using conditional probability over correlation and conditional probability is a way of saying okay if I",
    "start": "682110",
    "end": "687810"
  },
  {
    "start": "683000",
    "end": "683000"
  },
  {
    "text": "have a problem the probability of a opportunity probability of B that given that a has happened I said I wasn't",
    "start": "687810",
    "end": "694350"
  },
  {
    "text": "gonna get too deep into math but this is the math for it if you actually care about probabilistic math it's a way of",
    "start": "694350",
    "end": "701100"
  },
  {
    "text": "basically saying okay what is the probability that this one event is currently caused by this other what if a",
    "start": "701100",
    "end": "707250"
  },
  {
    "text": "happens what is the probability that B happens versus the probability that B",
    "start": "707250",
    "end": "712620"
  },
  {
    "text": "happens alone if it changes you have the",
    "start": "712620",
    "end": "717750"
  },
  {
    "text": "start of a actual excuse me the start of an actual causative explanation so you",
    "start": "717750",
    "end": "722910"
  },
  {
    "text": "can try and use that instead of just going and looking for correlation then",
    "start": "722910",
    "end": "728430"
  },
  {
    "text": "there's class two which is the specter of say biased sample data this is the most common one you're going to see like",
    "start": "728430",
    "end": "736790"
  },
  {
    "text": "class one is so broad and it happens so often that most people aren't even going",
    "start": "736790",
    "end": "742170"
  },
  {
    "text": "to talk about it but in the media things like that this is the thing that gets a lot of play more importantly because",
    "start": "742170",
    "end": "748769"
  },
  {
    "text": "it's really easy to screw up so you might not understand what I mean by sample data let's clarify so you have a",
    "start": "748769",
    "end": "756870"
  },
  {
    "text": "big pile of data and you're working to do something let's say you working on an app for mortgage lending analysis and",
    "start": "756870",
    "end": "764130"
  },
  {
    "start": "760000",
    "end": "760000"
  },
  {
    "text": "you have a big old pile of data that you want to do things with typically machine learning algorithms can't",
    "start": "764130",
    "end": "769620"
  },
  {
    "text": "on a few if you've been around since like the 1940s as a company you have enough data that it will choke most",
    "start": "769620",
    "end": "775260"
  },
  {
    "text": "machine learning algorithms unless you happen to be Google and so we deal with",
    "start": "775260",
    "end": "780960"
  },
  {
    "text": "that by taking that data set and breaking it off into a sample set through a process that can be complex",
    "start": "780960",
    "end": "788870"
  },
  {
    "text": "once we have that smaller sample set we usually break that into three different parts the training set the test set and",
    "start": "788870",
    "end": "794430"
  },
  {
    "text": "the validation set we do that because we want to be told that our phone is making",
    "start": "794430",
    "end": "801120"
  },
  {
    "text": "a lot of noise apologies for that in the bag we want to be sure that when we",
    "start": "801120",
    "end": "810750"
  },
  {
    "text": "train something we then test with it and we say okay that work each of these successive breakouts is a way for us to",
    "start": "810750",
    "end": "817920"
  },
  {
    "text": "avoid what's called overtraining to avoid matching exactly to that limited",
    "start": "817920",
    "end": "822960"
  },
  {
    "text": "training set and our data is usually shaped something like this in the case",
    "start": "822960",
    "end": "831150"
  },
  {
    "text": "of the mortgage example you have standard things you've got this you know of an ID column because we're in a standard acid database you have an age",
    "start": "831150",
    "end": "837180"
  },
  {
    "text": "and income and married whether they were approved for the loan or not the right hand column their dependent is the",
    "start": "837180",
    "end": "843900"
  },
  {
    "text": "approved column we're calling that the dependent variable because that's the thing we're trying to predict all the",
    "start": "843900",
    "end": "849060"
  },
  {
    "text": "rest of these can be what's called independent variables and they can be",
    "start": "849060",
    "end": "854580"
  },
  {
    "text": "predictors and a predictor is something that will predict that dependent variable the problem starts to be that",
    "start": "854580",
    "end": "863100"
  },
  {
    "text": "we almost certainly at our data set have things like this columns that are like race or gender datasets can be biased",
    "start": "863100",
    "end": "875420"
  },
  {
    "text": "your data set can contain bias from humans and I'll talk a little bit about",
    "start": "875420",
    "end": "882090"
  },
  {
    "text": "why that is but most importantly what I want you to come away with is that the output of a",
    "start": "882090",
    "end": "888900"
  },
  {
    "text": "system that is working on that data will also be biased now it's not bad for an",
    "start": "888900",
    "end": "893940"
  },
  {
    "text": "algorithm to be biased that's kind of the point you just want to make sure that it's biased in a direction that is",
    "start": "893940",
    "end": "901110"
  },
  {
    "text": "you know legally and socially and ethically responsible",
    "start": "901110",
    "end": "906319"
  },
  {
    "text": "because when you build things like a classifier or you build things like a predictor or some kind of linear",
    "start": "906499",
    "end": "912449"
  },
  {
    "text": "regression you are telling an algorithm I want you to buy it to be biased in this particular way and that's fine",
    "start": "912449",
    "end": "919109"
  },
  {
    "text": "because that's what they're for we just have to be careful about garbage in garbage out your data isn't just data",
    "start": "919109",
    "end": "931049"
  },
  {
    "text": "sitting there data at rest is not valueless it is not judgment list your",
    "start": "931049",
    "end": "937259"
  },
  {
    "text": "data is shaped it was shaped not only literally in terms of what columns are",
    "start": "937259",
    "end": "942659"
  },
  {
    "text": "in it and what data was actually recorded and the process that created it it's affected by the system that created",
    "start": "942659",
    "end": "947939"
  },
  {
    "text": "it if you're tracking outcomes from say the mortgage industry like we've been",
    "start": "947939",
    "end": "953339"
  },
  {
    "text": "talking about if you're including dates around the 1950s in your predictor you",
    "start": "953339",
    "end": "960199"
  },
  {
    "text": "have baked in some pretty bad bias into your system because the outputs the",
    "start": "960199",
    "end": "967529"
  },
  {
    "text": "things people were doing at that time things like redlining etc show up in the",
    "start": "967529",
    "end": "972779"
  },
  {
    "text": "data yes it is just what the adjusters did what just what the bank people",
    "start": "972779",
    "end": "978539"
  },
  {
    "text": "assigned in terms of the loan but that output their behavior is recorded in",
    "start": "978539",
    "end": "985439"
  },
  {
    "text": "that data we're literally transcribing that bias into the data itself and it",
    "start": "985439",
    "end": "992369"
  },
  {
    "text": "can get really really hard to get it out Amazon spent quite a long time working on an AI recruiting tool that they",
    "start": "992369",
    "end": "1001339"
  },
  {
    "text": "literally like they've tried recombining it and refiguring it multiple times and eventually had to give up they literally",
    "start": "1001339",
    "end": "1006589"
  },
  {
    "text": "could not get it to not be biased against women it's not like this is some",
    "start": "1006589",
    "end": "1011839"
  },
  {
    "text": "Archie Bunker like I know member his name I'm like married with children like this is not that the algorithm itself is",
    "start": "1011839",
    "end": "1018529"
  },
  {
    "text": "like beer-swilling in a you know undershirt and watching terrible things on the couch it the algorithm is sexist",
    "start": "1018529",
    "end": "1025369"
  },
  {
    "text": "not innately the algorithm is sexist because the data that they were feeding into it they couldn't work to cut that",
    "start": "1025369",
    "end": "1031879"
  },
  {
    "text": "bias out it would have been too much work because the data that they were feeding into it this",
    "start": "1031879",
    "end": "1038209"
  },
  {
    "text": "information about how people talked about women and their resumes the things on resumes the you know how Amazon even",
    "start": "1038209",
    "end": "1044569"
  },
  {
    "text": "considered people to be effective Amazon employees all of those individual changes individual processes individual",
    "start": "1044569",
    "end": "1051529"
  },
  {
    "text": "cognitive thoughts get recorded as data and then the Machine looks at them and it operates on them",
    "start": "1051529",
    "end": "1057799"
  },
  {
    "text": "it's not like it's inventing things out of whole cloth it's just looking at what's already there baked into that",
    "start": "1057799",
    "end": "1063230"
  },
  {
    "text": "data and you can see this in a bunch of really subtle ways too this is an amazing tweet that I got",
    "start": "1063230",
    "end": "1070789"
  },
  {
    "text": "permission to use thankfully because she had to take it down because she was worried about the company which I've not",
    "start": "1070789",
    "end": "1076309"
  },
  {
    "text": "mentioned here getting dogpile on Twitter and then if you can't see what",
    "start": "1076309",
    "end": "1083389"
  },
  {
    "text": "it says is unusual word pair it seems that the noun girl might combine winter with an adjective other than successful",
    "start": "1083389",
    "end": "1090010"
  },
  {
    "text": "consider rewriting this word pair or choosing a synonym for successful and the suggestions it gives are lucky and",
    "start": "1090010",
    "end": "1095419"
  },
  {
    "text": "happy this stuff can get real pervasive",
    "start": "1095419",
    "end": "1101149"
  },
  {
    "text": "and it gets real hard to get out to be fair the company in question immediately",
    "start": "1101149",
    "end": "1106820"
  },
  {
    "text": "saw the problem said oops and work to fix it but unless you consider these",
    "start": "1106820",
    "end": "1112940"
  },
  {
    "text": "things upfront unless you consider the data source upfront you're just going to be bug squash you're going to be cut",
    "start": "1112940",
    "end": "1118610"
  },
  {
    "text": "encountering these kind of problems consistently and constantly and when you're doing this sort of thing it might",
    "start": "1118610",
    "end": "1125389"
  },
  {
    "text": "be that your sample isn't representative that process of building a sample data set can be complex because you want to",
    "start": "1125389",
    "end": "1132919"
  },
  {
    "text": "get a representative data set a data set a small data set that represents everyone in that larger group but your",
    "start": "1132919",
    "end": "1140090"
  },
  {
    "text": "data itself might not be representative if you're tracking data from things that people do online at the moment you are",
    "start": "1140090",
    "end": "1148159"
  },
  {
    "text": "attracting only about 50% of the global population and what happens when more",
    "start": "1148159",
    "end": "1153350"
  },
  {
    "text": "and more and more of those people keep coming online their data hasn't been tracked they're not in your data set and",
    "start": "1153350",
    "end": "1161750"
  },
  {
    "text": "your data system regardless of what it is will function very poorly for them so",
    "start": "1161750",
    "end": "1167899"
  },
  {
    "text": "what can we do about this stuff how do we grapple with the specter well the first thing I",
    "start": "1167899",
    "end": "1173240"
  },
  {
    "text": "want you to think about is that a model represents what was it doesn't tell you",
    "start": "1173240",
    "end": "1179450"
  },
  {
    "text": "what should be that's your job that's my job that's our job we look and we say I",
    "start": "1179450",
    "end": "1187250"
  },
  {
    "text": "would like to build a model out of this particular piece of code or out of this particular data and the machine will do",
    "start": "1187250",
    "end": "1194750"
  },
  {
    "text": "that and the model that data represents that past history it was it's a record",
    "start": "1194750",
    "end": "1200390"
  },
  {
    "text": "of human action it's our job to say okay",
    "start": "1200390",
    "end": "1205490"
  },
  {
    "text": "does that model match what I want to happen in the world because you have the",
    "start": "1205490",
    "end": "1211130"
  },
  {
    "text": "chance to not just blindly follow whatever Google spits out of you you can",
    "start": "1211130",
    "end": "1218480"
  },
  {
    "text": "even find better data sets concept net dot IO has one where they've been",
    "start": "1218480",
    "end": "1223790"
  },
  {
    "text": "working very hard to extract bias out of a natural language and processing datasets NOP datasets there are studies papers",
    "start": "1223790",
    "end": "1232490"
  },
  {
    "text": "that say if you take the traditional canonical data sets for NLP and run those through sentiment analysis like",
    "start": "1232490",
    "end": "1238610"
  },
  {
    "text": "you will start to see those things those biases baked into it concept net has been working to pull that stuff out so you can find better",
    "start": "1238610",
    "end": "1246260"
  },
  {
    "text": "data sets out there that people are working hard to unbiased and to build you yourself can build the better data",
    "start": "1246260",
    "end": "1252530"
  },
  {
    "start": "1252000",
    "end": "1252000"
  },
  {
    "text": "set if you're taking the mortgage example you could just say okay from this point we're going to assume that",
    "start": "1252530",
    "end": "1257900"
  },
  {
    "text": "everybody is doing their best work and has their best foot forward and everybody's doing their best job and",
    "start": "1257900",
    "end": "1263660"
  },
  {
    "text": "from this point we're gonna track that data and build a new data set from there ignoring historical data you can also",
    "start": "1263660",
    "end": "1271430"
  },
  {
    "text": "just not feed those columns problematic columns into the predictors into the machines that generate those predictors",
    "start": "1271430",
    "end": "1277790"
  },
  {
    "text": "just don't pass in race and gender see what happens maybe you can find another one there's a problem with that though",
    "start": "1277790",
    "end": "1285260"
  },
  {
    "text": "in that you can be find these shadow columns let's use the mortgage example",
    "start": "1285260",
    "end": "1291470"
  },
  {
    "start": "1286000",
    "end": "1286000"
  },
  {
    "text": "again race and zip code pretty highly correlated in America so if you have a",
    "start": "1291470",
    "end": "1299000"
  },
  {
    "text": "zip code column but you've removed your race column oops you've still got that bias lurking",
    "start": "1299000",
    "end": "1305930"
  },
  {
    "text": "around even though you thought you've gotten rid of it there's really good",
    "start": "1305930",
    "end": "1312200"
  },
  {
    "text": "examples of this where there was a researcher who was passing data in - it",
    "start": "1312200",
    "end": "1319970"
  },
  {
    "text": "was a genetic algorithm working a adversarial network excuse me adversarial neural network that he was",
    "start": "1319970",
    "end": "1325820"
  },
  {
    "text": "passing information into and he was trying to get it to classify images and it learned that he was passing in Albert",
    "start": "1325820",
    "end": "1331730"
  },
  {
    "text": "Lea alternating images one which was supposed to pass and one which was supposed to fail and so with the algorithms like oh okay",
    "start": "1331730",
    "end": "1337790"
  },
  {
    "text": "the neural network just basically would alternate what pass and fail it had it didn't look at the image at all if",
    "start": "1337790",
    "end": "1344330"
  },
  {
    "text": "there's stuff in that data the machine will learn to use it because it doesn't know that it's not supposed to you can",
    "start": "1344330",
    "end": "1353750"
  },
  {
    "start": "1353000",
    "end": "1353000"
  },
  {
    "text": "also try making sure your sample set is representative there are a bunch of ways to do this I could do a whole hour talk",
    "start": "1353750",
    "end": "1359390"
  },
  {
    "text": "on it social cops comm has a really good blog",
    "start": "1359390",
    "end": "1364970"
  },
  {
    "text": "post on talking about how you like six different ways you can work to build a representative data set out of your",
    "start": "1364970",
    "end": "1371270"
  },
  {
    "text": "you're actually a representative sample set out of your data set other things",
    "start": "1371270",
    "end": "1377660"
  },
  {
    "text": "you can do is try identifying false positives and false negatives false positives are in the mortgage example",
    "start": "1377660",
    "end": "1384170"
  },
  {
    "text": "when somebody gets a loan and they shouldn't and a false negative is when somebody gets a loan and they should",
    "start": "1384170",
    "end": "1391300"
  },
  {
    "text": "once you've identified those which usually takes a human to do looking at",
    "start": "1392110",
    "end": "1397160"
  },
  {
    "text": "that data and at least sampling through that data and picking out trying to pick out these extreme false positives and false negatives you can feed those",
    "start": "1397160",
    "end": "1403250"
  },
  {
    "text": "things back into a learning system and try and avoid the bias that way",
    "start": "1403250",
    "end": "1408860"
  },
  {
    "text": "literally teach the machine no no don't do that you don't want to do that but",
    "start": "1408860",
    "end": "1414650"
  },
  {
    "text": "there are some even more powerful tools out there iBM has an AI fairness toolkit which blew my mind like you can go in",
    "start": "1414650",
    "end": "1424100"
  },
  {
    "text": "and feed it the ProPublica data source for the assessment stuff and it will spit out things like this says protected",
    "start": "1424100",
    "end": "1432620"
  },
  {
    "text": "attributes X privilege group female unfair privileged group mail what it's telling",
    "start": "1432620",
    "end": "1438559"
  },
  {
    "text": "you there is that women tend to receive lower risk assessment scores than men",
    "start": "1438559",
    "end": "1443710"
  },
  {
    "text": "which makes sense given biases in society but it shows you how it's",
    "start": "1443710",
    "end": "1450499"
  },
  {
    "text": "arriving at those calculations the different metrics that it's doing to actually figure out if your data set advised or not I did this was like they",
    "start": "1450499",
    "end": "1458899"
  },
  {
    "text": "have a demo this was doing like three clicks to get this thing it was crazy and then they offer you ways to fix it",
    "start": "1458899",
    "end": "1465220"
  },
  {
    "text": "you could do things like rewedding weighting the examples in each of those",
    "start": "1465220",
    "end": "1470389"
  },
  {
    "text": "sets whether it's a group and a label in this particular case they were building a classifier out of things and trying to make predictions out of the classifier",
    "start": "1470389",
    "end": "1477369"
  },
  {
    "text": "but you can reweighed the entries the individual rows in that system or you",
    "start": "1477369",
    "end": "1483740"
  },
  {
    "text": "can try doing something that they call optimized pre-processing I've heard it also called it's a data augmentation",
    "start": "1483740",
    "end": "1489499"
  },
  {
    "text": "it's a different way of thinking about it but you're basically probabilistically changing your data",
    "start": "1489499",
    "end": "1495759"
  },
  {
    "text": "which sounds confusing let me clarify the first thing you're going to do is figure out your constraints you're",
    "start": "1495759",
    "end": "1502399"
  },
  {
    "text": "saying I have a data set again let's take the historical mortgage data set and I know that I want the output of",
    "start": "1502399",
    "end": "1509179"
  },
  {
    "text": "this data set to not have any bias in favor of gender or race or any of the",
    "start": "1509179",
    "end": "1517249"
  },
  {
    "text": "other you know completely illegal things to bias on and once you've figured those",
    "start": "1517249",
    "end": "1524899"
  },
  {
    "text": "out you can actually go through and literally regenerate outputs from your",
    "start": "1524899",
    "end": "1531710"
  },
  {
    "text": "system probabilistically regenerate whether they were approved or not based on what you want the output to be again",
    "start": "1531710",
    "end": "1539629"
  },
  {
    "text": "you're in control of the model you're in control of the output and whether the",
    "start": "1539629",
    "end": "1545299"
  },
  {
    "text": "world should or the model should operate in the world like it is you can also do",
    "start": "1545299",
    "end": "1553129"
  },
  {
    "text": "adversarial D biasing which is a amazingly awesome concept adversarial",
    "start": "1553129",
    "end": "1559159"
  },
  {
    "text": "networks and sometimes they're called gans you'll see them in a couple different frameworks basically you'll",
    "start": "1559159",
    "end": "1564470"
  },
  {
    "text": "have two different neural networks living side by side one of which is trying to do the thing you want and one of which is trying to screw",
    "start": "1564470",
    "end": "1570620"
  },
  {
    "text": "and so it's doing things like if you're trying to identify pictures of cats",
    "start": "1570620",
    "end": "1575960"
  },
  {
    "text": "right this one's trying to learn cats this one's trying to generate things that aren't cats that this thing will",
    "start": "1575960",
    "end": "1582049"
  },
  {
    "text": "think are cats so people in cat ears okay let's just start screwing with it and you keep feeding it that data and",
    "start": "1582049",
    "end": "1588350"
  },
  {
    "text": "telling it no that was wrong and they both get smarter together you can use this to D bias your data you can learn",
    "start": "1588350",
    "end": "1595400"
  },
  {
    "text": "literally have an algorithm that will say nope this data set is still biased and then have another neural network",
    "start": "1595400",
    "end": "1601760"
  },
  {
    "text": "that will change it and have those two compete against each other in rapid iteration to try and remove the bias",
    "start": "1601760",
    "end": "1607580"
  },
  {
    "text": "from your data set and they'll do this for you automatically they also have",
    "start": "1607580",
    "end": "1613580"
  },
  {
    "text": "another option this one works in the actual prediction level so even on the other side of the",
    "start": "1613580",
    "end": "1621559"
  },
  {
    "text": "machine learning stuff because you have your data you've turned into a classifier now you're making predictions as the predictions exist you're",
    "start": "1621559",
    "end": "1628760"
  },
  {
    "text": "literally changing those predictions to match what you actually want to happen in the world based on probabilistic and",
    "start": "1628760",
    "end": "1636070"
  },
  {
    "text": "more complex things that are moaning to want to get into at the moment but point is that this is a tool that's out there",
    "start": "1636070",
    "end": "1642500"
  },
  {
    "text": "that you can use to help you identify and remove bias from your data sets before you pass those things into models",
    "start": "1642500",
    "end": "1649090"
  },
  {
    "text": "there's also this thing which is the what-if tool which has developed kind of in concert with Google and it looks",
    "start": "1649090",
    "end": "1655820"
  },
  {
    "text": "really complex and it is this is an infinitely powerful tool that will allow",
    "start": "1655820",
    "end": "1661250"
  },
  {
    "text": "you to do things like pick two points you can kind of see the yellow and green one there and say well what makes those",
    "start": "1661250",
    "end": "1667790"
  },
  {
    "text": "two different if they were sorted into two different classifiers what mate why what did the algorithm think was",
    "start": "1667790",
    "end": "1674240"
  },
  {
    "text": "important about those two what is the data set that's different about those two and so it from the other end allows",
    "start": "1674240",
    "end": "1680960"
  },
  {
    "text": "you to inspect more complex machine learning processes and hopefully understand what's kind of going on",
    "start": "1680960",
    "end": "1686690"
  },
  {
    "text": "underneath the hood and allow you to detect whether you want to do buy it or can't have bias in the system or not rather they offer additional tools which",
    "start": "1686690",
    "end": "1695870"
  },
  {
    "text": "I'm not sure yeah partial dependence plots is up there partial dependence plots are ways for you to go and say",
    "start": "1695870",
    "end": "1701390"
  },
  {
    "text": "okay I just want to look at these two in two visual metrics these two individual columns what affected those have on each",
    "start": "1701390",
    "end": "1707870"
  },
  {
    "text": "other is one dependent on the other or not it's a lot of complex things a lot",
    "start": "1707870",
    "end": "1715610"
  },
  {
    "text": "of things you can do to solve this but literally these things are getting better and better by the moment we're",
    "start": "1715610",
    "end": "1722270"
  },
  {
    "text": "finally starting to get our head around not just having a crappy data set",
    "start": "1722270",
    "end": "1727370"
  },
  {
    "text": "instead having a data set that's well-groomed that we check for bias upfront and that we adjust to match what",
    "start": "1727370",
    "end": "1732920"
  },
  {
    "text": "we want to exist in the world and so the best tool you have at your disposal is a",
    "start": "1732920",
    "end": "1737930"
  },
  {
    "text": "good process a good process around the data science that you have as a company as an individual and the last thing is",
    "start": "1737930",
    "end": "1747940"
  },
  {
    "text": "that you kind of need to know who could be affected in order to remove bias if",
    "start": "1747940",
    "end": "1755540"
  },
  {
    "start": "1749000",
    "end": "1749000"
  },
  {
    "text": "you're doing classifiers if you're looking at individual classifications of things you need to know if there are",
    "start": "1755540",
    "end": "1761900"
  },
  {
    "text": "subsets of those classifications that are biased or not if you're doing things",
    "start": "1761900",
    "end": "1767150"
  },
  {
    "text": "like linear regression if you're doing things like actual numeric predictors there are you need to know what the",
    "start": "1767150",
    "end": "1773180"
  },
  {
    "text": "inputs are to your data it's hard to remove something that you can't even detect it there so going kind of up in",
    "start": "1773180",
    "end": "1785540"
  },
  {
    "text": "the power scale we have class threes the shade of overly simplistic maximization",
    "start": "1785540",
    "end": "1791720"
  },
  {
    "text": "let's think for a minute about pricing algorithms like for instance Amazon most",
    "start": "1791720",
    "end": "1798350"
  },
  {
    "start": "1793000",
    "end": "1793000"
  },
  {
    "text": "of you know the stuff that's sold on Amazon now isn't priced by humans it's usually priced by robots that are dynamically pricing things and it's a",
    "start": "1798350",
    "end": "1805640"
  },
  {
    "text": "very complex system how many people have seen that the reports of like these out of print books that are ten thousand",
    "start": "1805640",
    "end": "1811550"
  },
  {
    "text": "dollars because the pricing algorithms keep increasing like by cents every day a researcher decided that was a really",
    "start": "1811550",
    "end": "1819470"
  },
  {
    "text": "cool idea and so he decided to put two pricing algorithms in a sandbox with each other and start just letting them",
    "start": "1819470",
    "end": "1827450"
  },
  {
    "text": "go they're both pricing the same object they can see nothing but the price that",
    "start": "1827450",
    "end": "1833000"
  },
  {
    "text": "the other one is said they don't communicate with each other in any other way now we have to talk about I can it's for a second so hold on there is",
    "start": "1833000",
    "end": "1840529"
  },
  {
    "text": "this thing called the Nash equilibrium how many people have seen beautiful mind that's that guy he came up with the Nash",
    "start": "1840529",
    "end": "1847039"
  },
  {
    "text": "equilibrium the Nash equilibrium is a point where two companies with their",
    "start": "1847039",
    "end": "1852049"
  },
  {
    "text": "various price curves will be named duopoly if they're the only two things in the market they will either arrive at",
    "start": "1852049",
    "end": "1858980"
  },
  {
    "text": "the Nash equilibrium this balance point below the collusion point which is up there at that six dollar mark they'll",
    "start": "1858980",
    "end": "1866809"
  },
  {
    "text": "find a point that kind of balances their profit and effort and other communication signals that are being sent between the two companies you would",
    "start": "1866809",
    "end": "1874609"
  },
  {
    "text": "expect to sane rational algorithms and you hope that they are because if we",
    "start": "1874609",
    "end": "1880730"
  },
  {
    "text": "have insane algorithms then we're really screwed you would expect them to arrive at that Nash equilibrium or to",
    "start": "1880730",
    "end": "1886909"
  },
  {
    "text": "alternately just completely chase each other to the bottom where there's no profit at all instead well and so what",
    "start": "1886909",
    "end": "1894679"
  },
  {
    "text": "you would expect to see is that if agent 2 comes in at a lower price agent 1 would drop its price and eventually they",
    "start": "1894679",
    "end": "1900350"
  },
  {
    "text": "would arrive at the Nash together because there's no point in not doing that it's lower than that",
    "start": "1900350",
    "end": "1907220"
  },
  {
    "text": "pre-competition price it's definitely not the collusion price this is basic",
    "start": "1907220",
    "end": "1912889"
  },
  {
    "text": "economics this is what actually happened when he forced one of the algorithms to drop its price agent 1 he forced that",
    "start": "1912889",
    "end": "1921320"
  },
  {
    "text": "price down to the Nash price you can see",
    "start": "1921320",
    "end": "1926509"
  },
  {
    "text": "agent 2 follows but not quite as much and then the two algorithms work their",
    "start": "1926509",
    "end": "1933139"
  },
  {
    "text": "way back upward to an average price it's not quite that full cooperation",
    "start": "1933139",
    "end": "1939200"
  },
  {
    "text": "collusive price but it's higher than the Nash these two algorithms doing nothing",
    "start": "1939200",
    "end": "1945710"
  },
  {
    "text": "other than signalling to each other with price changes have learned to collude which is just as illegal when an",
    "start": "1945710",
    "end": "1952700"
  },
  {
    "text": "algorithm does is when the humans do it so I want you to think for a second",
    "start": "1952700",
    "end": "1959779"
  },
  {
    "text": "about how the researcher told these",
    "start": "1959779",
    "end": "1964970"
  },
  {
    "text": "algorithms what to do told them to go try and get profit",
    "start": "1964970",
    "end": "1971660"
  },
  {
    "text": "I want you to think what would happen if instead of building the tool to analyze resumes and analyze incoming documents",
    "start": "1971660",
    "end": "1978140"
  },
  {
    "start": "1973000",
    "end": "1973000"
  },
  {
    "text": "about engineers Amazon had built a salary tool and they told it I want you",
    "start": "1978140",
    "end": "1984080"
  },
  {
    "text": "to get me the best engineers at the lowest cost and they didn't give it any other information that algorithm would",
    "start": "1984080",
    "end": "1992840"
  },
  {
    "text": "probably fill the entire Amazon office with women because if you can get them at 70% of the rate that it can get men",
    "start": "1992840",
    "end": "1999940"
  },
  {
    "text": "machines don't understand things they don't understand complexities they don't",
    "start": "2003960",
    "end": "2009220"
  },
  {
    "text": "understand the law I have a friend who had a co-worker actually who built a",
    "start": "2009220",
    "end": "2015010"
  },
  {
    "start": "2012000",
    "end": "2012000"
  },
  {
    "text": "piece of software or genetic algorithm because he's a giant nerd like I am to determine what his food should be for",
    "start": "2015010",
    "end": "2020680"
  },
  {
    "text": "the week like he was just starting a family he was encountering that whole like oh I'm gonna do food planning craze",
    "start": "2020680",
    "end": "2026350"
  },
  {
    "text": "that people get and so he built this program to literally a constraints",
    "start": "2026350",
    "end": "2032110"
  },
  {
    "text": "optimization program to solve like the cost versus you know caloric intake versus the reusability like whether a",
    "start": "2032110",
    "end": "2037780"
  },
  {
    "text": "meal would have leftovers or not and do they have hy-vee's here in Minnesota okay hi V chicken brought worst you can",
    "start": "2037780",
    "end": "2045490"
  },
  {
    "text": "get for ninety seven cents his genetic algorithm fell in love with",
    "start": "2045490",
    "end": "2050800"
  },
  {
    "text": "the hi v-- chicken bratwurst that's it was it hi be chicken bratwurst breakfast lunch and dinner the entire week that",
    "start": "2050800",
    "end": "2057398"
  },
  {
    "text": "was all his the program's just like no it's 97 cents it's high in protein you get the dish and fat and that's really",
    "start": "2057399",
    "end": "2062620"
  },
  {
    "text": "reheatable and it works fantastic and it's I mean obviously he didn't go with",
    "start": "2062620",
    "end": "2068440"
  },
  {
    "text": "that but he's like that so we had to build in a piece of information to build in a constraint that talked about",
    "start": "2068440",
    "end": "2073860"
  },
  {
    "text": "variability and variety because the Machine doesn't know that you want variety it just knows what you've told",
    "start": "2073860",
    "end": "2079960"
  },
  {
    "text": "it already humans rarely have a single goal in mind we operate inside of",
    "start": "2079960",
    "end": "2085600"
  },
  {
    "text": "systems social systems our own brain systems we operate inside of economic",
    "start": "2085600",
    "end": "2090730"
  },
  {
    "text": "systems and legal systems none of that stuff is visible to an AI we have the",
    "start": "2090730",
    "end": "2096158"
  },
  {
    "text": "law we have co-workers we have our bosses we have individual personal goals that we need to achieve and AI just are",
    "start": "2096159",
    "end": "2102310"
  },
  {
    "text": "confused as hell because all of that is completely invisible to them I'm gonna play a short",
    "start": "2102310",
    "end": "2110240"
  },
  {
    "text": "video here this is from a data science",
    "start": "2110240",
    "end": "2115730"
  },
  {
    "text": "genetic algorithm tool called half cheetah it's two dimensional and the",
    "start": "2115730",
    "end": "2122300"
  },
  {
    "text": "goal is your training this thing to be running I'd I could watch this all day",
    "start": "2122300",
    "end": "2129260"
  },
  {
    "text": "uh I just just open this little way along right off the edge of the map what",
    "start": "2129260",
    "end": "2137840"
  },
  {
    "text": "what the hell what's happened here is you've told it go forward you've given",
    "start": "2137840",
    "end": "2146480"
  },
  {
    "text": "it this reward metric that it's rewarded when it makes forward progress if that's all you tell it it's gonna",
    "start": "2146480",
    "end": "2155360"
  },
  {
    "text": "take any effort it can to get forward",
    "start": "2155360",
    "end": "2159280"
  },
  {
    "text": "it's just trying so hard so what can you",
    "start": "2166680",
    "end": "2173170"
  },
  {
    "text": "do about this what can you you solve this particular issue well first remember again models only",
    "start": "2173170",
    "end": "2179230"
  },
  {
    "text": "tell you what was their only mapping the data that's already there the behavior that is already there and encoded in the",
    "start": "2179230",
    "end": "2185200"
  },
  {
    "text": "data you're passing it they don't tell you what should be in the world yeah just again to get a step back and",
    "start": "2185200",
    "end": "2191230"
  },
  {
    "text": "realize you're in control of the output you don't have to immediately take the output of your predictor or the output of your classifier and do things with it",
    "start": "2191230",
    "end": "2199080"
  },
  {
    "text": "but remember that people tend to trust these things and that if you lively",
    "start": "2199080",
    "end": "2206530"
  },
  {
    "text": "display output without helping your user walk through it or understand what's going on they might just trust in it and do",
    "start": "2206530",
    "end": "2214900"
  },
  {
    "text": "something I mean kind of like the chef Chia did you can't trust these",
    "start": "2214900",
    "end": "2220390"
  },
  {
    "text": "algorithms to make subtle or large multivariate argued just you know judgments they can't distinguish between",
    "start": "2220390",
    "end": "2225490"
  },
  {
    "text": "those things there are some things you can do you can try using complex as convoluted columns where you're taking",
    "start": "2225490",
    "end": "2232480"
  },
  {
    "text": "two columns and kind of combining them into each other and saying okay I want you to predict not just you know profit",
    "start": "2232480",
    "end": "2238390"
  },
  {
    "text": "but also happiness some metric between the two some combination between the two that's one way you can do this you can",
    "start": "2238390",
    "end": "2244540"
  },
  {
    "text": "also try doing more complex algorithms that have an outside influence things like non Darwinian genetic algorithms",
    "start": "2244540",
    "end": "2250390"
  },
  {
    "start": "2245000",
    "end": "2245000"
  },
  {
    "text": "which is a thing that like I would love to give just an hour talk on that cuz it's a fascinating idea so you don't",
    "start": "2250390",
    "end": "2255940"
  },
  {
    "text": "have to follow the straight Darwinian stuff you can do whatever you want Lamarckian evolution all kinds of crazy stuff but you can do interesting things",
    "start": "2255940",
    "end": "2263830"
  },
  {
    "text": "like say have a an algorithm where break it into two genders and one of the genders is essentially the one would",
    "start": "2263830",
    "end": "2272560"
  },
  {
    "text": "decide whether the two objects will mate the two you know organisms will mate and at that point you can build in not just",
    "start": "2272560",
    "end": "2280150"
  },
  {
    "text": "the fitness function but build in something like oh does this other organism think this other organism is",
    "start": "2280150",
    "end": "2285460"
  },
  {
    "text": "beautiful and have a complex and subtle and potentially mutable by your genetic algorithm way of doing this I mean this",
    "start": "2285460",
    "end": "2292750"
  },
  {
    "text": "is how we wound up at the bowerbird essentially in the real world I mean I don't think anybody ran an actual",
    "start": "2292750",
    "end": "2298540"
  },
  {
    "text": "genetic algorithm who came up with the bowerbird but you can use more complex",
    "start": "2298540",
    "end": "2305530"
  },
  {
    "text": "systems like that to try and get complex judgments into the data you're working with class 5 is kind of closely related",
    "start": "2305530",
    "end": "2313630"
  },
  {
    "text": "this is the simulation surprise this picture is from a study that was taken",
    "start": "2313630",
    "end": "2321190"
  },
  {
    "text": "in a virtual simulation where they had a gripper a robot with a gripper and it was supposed to bait like they",
    "start": "2321190",
    "end": "2327329"
  },
  {
    "text": "incentivising it to move the box as far as it could and they said ok that's great and they did her a couple examples",
    "start": "2327329",
    "end": "2332800"
  },
  {
    "text": "and then for one test trial run they locked the gripper shut so that the robot couldn't open it instead of",
    "start": "2332800",
    "end": "2339010"
  },
  {
    "text": "nudging the box around which is what they expected the robot learned to whack its harm in the simulation all in the",
    "start": "2339010",
    "end": "2344859"
  },
  {
    "text": "corner of the box which forced the gripper open so it could use it it found",
    "start": "2344859",
    "end": "2349990"
  },
  {
    "text": "the boundaries of the simulation another example are these little against simulated composite robots these things",
    "start": "2349990",
    "end": "2356170"
  },
  {
    "text": "like individual organisms made up of like robot cells these things learned to manipulate time for starters to pause",
    "start": "2356170",
    "end": "2362260"
  },
  {
    "text": "time so they can insert themselves into the floor of the simulation at which point they would resume time the",
    "start": "2362260",
    "end": "2368290"
  },
  {
    "text": "simulations collision detection would go you ain't supposed to be there and pull it up with this huge burst of energy and",
    "start": "2368290",
    "end": "2373510"
  },
  {
    "text": "they used that to harvest energy and propel themselves forward humans have",
    "start": "2373510",
    "end": "2382900"
  },
  {
    "text": "evolved to take advantage of systems that's what we do when we give several",
    "start": "2382900",
    "end": "2388990"
  },
  {
    "text": "million iterations to a genetic algorithm or some other machine learning tool it's going to do the same thing",
    "start": "2388990",
    "end": "2394329"
  },
  {
    "text": "it's gonna find the boundaries of the simulation that it lives in and so you can get these problems in these results",
    "start": "2394329",
    "end": "2400839"
  },
  {
    "text": "in these outputs that don't make any sense what can you do about that well for starters just be ready this is going",
    "start": "2400839",
    "end": "2407619"
  },
  {
    "text": "to happen if you give something enough iterations it's gonna find the boundaries of its world you can try not",
    "start": "2407619",
    "end": "2416290"
  },
  {
    "text": "to confuse the map with the territory don't confuse the simulation for this actual thing that you are simulating",
    "start": "2416290",
    "end": "2423569"
  },
  {
    "text": "when you have an output from that look at it and critically judge it verify and",
    "start": "2423569",
    "end": "2429369"
  },
  {
    "start": "2429000",
    "end": "2429000"
  },
  {
    "text": "check does this jive with the real world test",
    "start": "2429369",
    "end": "2434690"
  },
  {
    "text": "it out do an experiment see if it doesn't you've probably found some weird education your simulation there's a",
    "start": "2434690",
    "end": "2443630"
  },
  {
    "text": "whole spreadsheet full of these things including stuff like the half cheetah and there was one that was a genetic algorithms again they were just testing",
    "start": "2443630",
    "end": "2449960"
  },
  {
    "text": "it on distance as the reward function and it just learned to grow really tall and then fall over so we're getting up",
    "start": "2449960",
    "end": "2461480"
  },
  {
    "text": "here class six the second to the last class the apparition of fairness we've",
    "start": "2461480",
    "end": "2471560"
  },
  {
    "text": "been talking about a lot about that mortgage data set let's talk about twitter for a second imagine that you",
    "start": "2471560",
    "end": "2476690"
  },
  {
    "text": "are building a piece of machine learning to parse and do some prediction some NLP",
    "start": "2476690",
    "end": "2483590"
  },
  {
    "text": "with Twitter do with tweets and your I don't even know what you're doing you're",
    "start": "2483590",
    "end": "2489320"
  },
  {
    "text": "passing those in and helping people make predictive tweets that are gonna get the most up votes or whatever I think I just",
    "start": "2489320",
    "end": "2495680"
  },
  {
    "text": "across Twitter and reddit which it's early but let's imagine that if you're",
    "start": "2495680",
    "end": "2505490"
  },
  {
    "text": "unleashing this thing on the whole of Twitter I want you to think about what happens when anything encounters",
    "start": "2505490",
    "end": "2510830"
  },
  {
    "text": "dialectical language regardless of what dialect that is doesn't work so well",
    "start": "2510830",
    "end": "2517630"
  },
  {
    "text": "most of the normal algorithms have been trained based on classical grammar when",
    "start": "2517630",
    "end": "2523820"
  },
  {
    "text": "you start encountering dialectical language whether that's African American",
    "start": "2523820",
    "end": "2529640"
  },
  {
    "text": "English or you know u.s. southern or whatever these algorithms choke and part",
    "start": "2529640",
    "end": "2538580"
  },
  {
    "text": "of this is because a lot of an e-learning tools are designed to what's called minimize average loss we talked",
    "start": "2538580",
    "end": "2544250"
  },
  {
    "start": "2539000",
    "end": "2539000"
  },
  {
    "text": "about the coral the correlation the fit between those two data sets the algorithm is in a lot of ways trying to",
    "start": "2544250",
    "end": "2550640"
  },
  {
    "text": "shrink that distance between its output and what it sees as its goal when you do",
    "start": "2550640",
    "end": "2557480"
  },
  {
    "text": "this you can wind up with a problem where there are users in",
    "start": "2557480",
    "end": "2563720"
  },
  {
    "text": "subset of the population despite the fact that your algorithm is by and large highly accurate for these subsets of",
    "start": "2563720",
    "end": "2570619"
  },
  {
    "text": "population it is inaccurate extremely so",
    "start": "2570619",
    "end": "2575410"
  },
  {
    "text": "if it's inaccurate do you think people are going to use that tool well probably",
    "start": "2575650",
    "end": "2581480"
  },
  {
    "text": "not so if you built it off of a corpus of Twitter or tweets and then you're",
    "start": "2581480",
    "end": "2587060"
  },
  {
    "text": "expecting to build a learning algorithm where you take people's use of your tool and fold it back into that data set and",
    "start": "2587060",
    "end": "2593780"
  },
  {
    "text": "grow and learn over time those users are not learning or not feeding your data set that information it's not learning",
    "start": "2593780",
    "end": "2599869"
  },
  {
    "text": "about those users because they're not using your product because your product sucks for them this leads to a thing",
    "start": "2599869",
    "end": "2605300"
  },
  {
    "start": "2605000",
    "end": "2605000"
  },
  {
    "text": "called representation disparity you get the systems with that high overall",
    "start": "2605300",
    "end": "2610670"
  },
  {
    "text": "accuracy but really low accuracy for a subset of your populations even if you",
    "start": "2610670",
    "end": "2617119"
  },
  {
    "text": "have data in that sample set this isn't a problem like number two like class two you have that data you're passing it in",
    "start": "2617119",
    "end": "2623380"
  },
  {
    "text": "the algorithm just can't handle it and",
    "start": "2623380",
    "end": "2628550"
  },
  {
    "text": "you're not checking for it because you don't know to look for it so what can we",
    "start": "2628550",
    "end": "2635240"
  },
  {
    "text": "do about this well there's a really interesting paper from Hashimoto Steve Austin and um kun and Liang in 2018 this",
    "start": "2635240",
    "end": "2641960"
  },
  {
    "text": "was a mind-blowing presentation for me right because I'm used to writing the stuff of talking about psychology and",
    "start": "2641960",
    "end": "2647119"
  },
  {
    "text": "teamwork and citing papers from like 1898 most of the stuff that I cite in here I don't think I have a paper that I",
    "start": "2647119",
    "end": "2653540"
  },
  {
    "text": "cite in here that's like older than 2013 this is big stuff it's happening right",
    "start": "2653540",
    "end": "2658880"
  },
  {
    "text": "now and so it's really hard because we're being expected to catch up and follow it pay attention to all of these",
    "start": "2658880",
    "end": "2665690"
  },
  {
    "text": "things that are happening in the research field and the communication is not always there but from this paper",
    "start": "2665690",
    "end": "2672619"
  },
  {
    "text": "they talked about John Rawls theory of distributive justice anybody familiar",
    "start": "2672619",
    "end": "2678760"
  },
  {
    "text": "one couple people John Rahl talked about distributive justice as a resource that justice",
    "start": "2678760",
    "end": "2687230"
  },
  {
    "text": "itself is a resource to be allocated across populations they think about predictive accuracy as a resource to be",
    "start": "2687230",
    "end": "2693530"
  },
  {
    "text": "allocated across populations you might need to decrease the accuracy of population to increase the accuracy of a",
    "start": "2693530",
    "end": "2701269"
  },
  {
    "text": "under representative population to this end instead of using that minimum loss",
    "start": "2701269",
    "end": "2706400"
  },
  {
    "text": "algorithm their minimum loss metric rather they talk about this thing called distributionally robust optimization",
    "start": "2706400",
    "end": "2714010"
  },
  {
    "start": "2709000",
    "end": "2709000"
  },
  {
    "text": "what's really interesting this is one of the things that the fair AI tool uses",
    "start": "2715150",
    "end": "2720460"
  },
  {
    "text": "it's one of the options in that check down box and if this seems twisty and",
    "start": "2720460",
    "end": "2732650"
  },
  {
    "text": "pernicious and hard to deal with well wait till we get to the last one",
    "start": "2732650",
    "end": "2738640"
  },
  {
    "text": "feedback devil this is one that I",
    "start": "2738700",
    "end": "2744589"
  },
  {
    "text": "grappled with a lot I wasn't even sure who included because I don't have good solutions but I feel like it's super",
    "start": "2744589",
    "end": "2751010"
  },
  {
    "text": "important we already talked a little bit about if we build that product with our",
    "start": "2751010",
    "end": "2757730"
  },
  {
    "text": "Twitter NLP those people who use it are people who aren't served by our product",
    "start": "2757730",
    "end": "2763789"
  },
  {
    "start": "2760000",
    "end": "2760000"
  },
  {
    "text": "aren't going to use that product we're leaving them out that's a feedback loop",
    "start": "2763789",
    "end": "2772630"
  },
  {
    "text": "negative experience leads to them not using the product which means their experience continues to get worse and",
    "start": "2773380",
    "end": "2779150"
  },
  {
    "text": "worse because we're not helping our algorithm get better I wish this was a",
    "start": "2779150",
    "end": "2786529"
  },
  {
    "start": "2785000",
    "end": "2785000"
  },
  {
    "text": "less egregious example but the example I found that drives this home the best is",
    "start": "2786529",
    "end": "2792799"
  },
  {
    "text": "probably predictive policing predictive policing is a technique where you have",
    "start": "2792799",
    "end": "2798559"
  },
  {
    "text": "an average City City provided by City skylines a game that I spend way too",
    "start": "2798559",
    "end": "2804109"
  },
  {
    "text": "much time on and your algorithm says I think that crime is gonna happen here",
    "start": "2804109",
    "end": "2809779"
  },
  {
    "text": "based on a number of different factors who knows these algorithms aren't necessarily are definitely not public",
    "start": "2809779",
    "end": "2814789"
  },
  {
    "text": "most of the time and what happens when you do that well you bet your Police Department paid a stupid amount of money",
    "start": "2814789",
    "end": "2821720"
  },
  {
    "text": "for the system so it's gonna send police there because it needs to get gets its money's worth out of it and I don't want",
    "start": "2821720",
    "end": "2827509"
  },
  {
    "text": "you to think for a moment about police behavior etc I just want you to think from a strictly job performance",
    "start": "2827509",
    "end": "2835700"
  },
  {
    "text": "perspective what happens when you send police to an area they arrest people",
    "start": "2835700",
    "end": "2841759"
  },
  {
    "text": "that's their job they find crimes and they arrest people for them that means",
    "start": "2841759",
    "end": "2850549"
  },
  {
    "text": "that recorded crime statistics in that area go up even if it's just for minor",
    "start": "2850549",
    "end": "2856250"
  },
  {
    "text": "things once that's happened the",
    "start": "2856250",
    "end": "2863420"
  },
  {
    "text": "algorithm turns around and says cry just went up we need to send more police",
    "start": "2863420",
    "end": "2871059"
  },
  {
    "text": "there is a pernicious feedback loop and unfortunately this can end with people leaving what is now considered to be a",
    "start": "2871329",
    "end": "2877670"
  },
  {
    "text": "high crime area congratulations you just blinded a neighborhood yeah this stuff",
    "start": "2877670",
    "end": "2890690"
  },
  {
    "text": "can get really really twisty and really hard to deal with but I have a couple",
    "start": "2890690",
    "end": "2898309"
  },
  {
    "text": "suggestions first try building your algorithm so that it knows whether",
    "start": "2898309",
    "end": "2903920"
  },
  {
    "text": "something was suggested by the algorithm try literally carrying that information",
    "start": "2903920",
    "end": "2908960"
  },
  {
    "text": "along and when you record the outputs of arrest etc mark say oh this was",
    "start": "2908960",
    "end": "2914960"
  },
  {
    "text": "suggested by the policing algorithm and then dampen those or cut them out entirely from your predictions that's",
    "start": "2914960",
    "end": "2925279"
  },
  {
    "text": "one option but it gets really tough when you start having things like save money when things turn into money and then",
    "start": "2925279",
    "end": "2932180"
  },
  {
    "text": "from money back into other things it's almost literally like that data has been laundered and it becomes really",
    "start": "2932180",
    "end": "2937880"
  },
  {
    "text": "difficult to know what is the actual output or effect of those things the",
    "start": "2937880",
    "end": "2944900"
  },
  {
    "text": "other option I have comes from the fact that I don't actually have a CS degree I have a computer engineering degree and",
    "start": "2944900",
    "end": "2951799"
  },
  {
    "start": "2949000",
    "end": "2949000"
  },
  {
    "text": "that means I had to take a bunch of dumb classes in college that most CS people didn't have to take but one of them that",
    "start": "2951799",
    "end": "2957680"
  },
  {
    "text": "I thought was actually really fun was this class called control engineering and control engineering talks about",
    "start": "2957680",
    "end": "2963079"
  },
  {
    "text": "how to control outputs of systems not in a feedback well in the feedback way but",
    "start": "2963079",
    "end": "2969259"
  },
  {
    "text": "not in a discreet way as treating each individual thing but talking about the",
    "start": "2969259",
    "end": "2974630"
  },
  {
    "text": "actual output of these things as a mathematical function this is the PID model of control engineering and it's",
    "start": "2974630",
    "end": "2981859"
  },
  {
    "text": "called that because it's proportional integral derivative derivative derivative this is a way to adapt",
    "start": "2981859",
    "end": "2990680"
  },
  {
    "text": "feedback to build a system that is resilient to things like sudden shocks",
    "start": "2990680",
    "end": "2996670"
  },
  {
    "text": "and we know this works because this is literally how mechanical and electrical engineers have been building you know",
    "start": "2996670",
    "end": "3002529"
  },
  {
    "text": "assembly lines since in decades and decades ago my suspicion is that we are",
    "start": "3002529",
    "end": "3008799"
  },
  {
    "text": "going to have to do something similar for the output of our machine learning processes if you're building something like a neural network that's just math",
    "start": "3008799",
    "end": "3017219"
  },
  {
    "text": "almost all of the stuff that we do in machine learning and AI turns down - it's just numbers at the bottom and we",
    "start": "3017219",
    "end": "3023979"
  },
  {
    "text": "can fit those numbers into a system like this maybe not this one exactly but something that Tunes it something that",
    "start": "3023979",
    "end": "3029619"
  },
  {
    "text": "adjusts it that helps us address the feedback that's coming back from that system ok let's show this prehistoric",
    "start": "3029619",
    "end": "3039819"
  },
  {
    "text": "bias how we do things downtown we're just gonna go through and sum up this",
    "start": "3039819",
    "end": "3045309"
  },
  {
    "text": "stuff then talk about some of the things you can do right now class one those phantom is a false correlation just know",
    "start": "3045309",
    "end": "3052479"
  },
  {
    "text": "what question you're asking and maybe try using conditional probability over straight correlation for class twos",
    "start": "3052479",
    "end": "3057910"
  },
  {
    "text": "you can recognize data is biased even at rest make sure your sample sets created properly build that learning system for",
    "start": "3057910",
    "end": "3063579"
  },
  {
    "text": "false positives and false negatives and try using adversarial techniques to detect bias and you can use those",
    "start": "3063579",
    "end": "3068739"
  },
  {
    "text": "automated tools to get those to get there rather for class threes and remember that model tell you what was",
    "start": "3068739",
    "end": "3073779"
  },
  {
    "text": "not what should be tried appending or combining dependent columns and predicting that try using complex",
    "start": "3073779",
    "end": "3079660"
  },
  {
    "text": "algorithms to get more flexible reinforcement for the simulation surprise just don't confuse that map",
    "start": "3079660",
    "end": "3086529"
  },
  {
    "text": "with that territory and always reality check those outputs for the a person of fairness consider that predictive",
    "start": "3086529",
    "end": "3092859"
  },
  {
    "text": "accuracy is a resource to be allocated across the different populations in data sets and possibly seek an actual",
    "start": "3092859",
    "end": "3098890"
  },
  {
    "text": "external audit for the bias or for bias or at the very least have another team",
    "start": "3098890",
    "end": "3104530"
  },
  {
    "text": "look at it somebody who doesn't have the who's not missing the forest for the",
    "start": "3104530",
    "end": "3109990"
  },
  {
    "text": "trees and for Class seven try ignoring or adjusting for those algorithms whose",
    "start": "3109990",
    "end": "3115420"
  },
  {
    "text": "results or try looking at control engineering for potential answers so",
    "start": "3115420",
    "end": "3121330"
  },
  {
    "text": "fixing all this sounds a little hard just it can feel overwhelming because a",
    "start": "3121330",
    "end": "3127300"
  },
  {
    "text": "lot of this is now on us as developers as the people who are told go do this",
    "start": "3127300",
    "end": "3133600"
  },
  {
    "text": "thing and then we go can I get some help to think about this and they're like no you have to give that done by next Thursday but unfortunately the thing you",
    "start": "3133600",
    "end": "3142030"
  },
  {
    "text": "can do right now that was the most valuable is just take the time to think about it think about the outputs of what",
    "start": "3142030",
    "end": "3147400"
  },
  {
    "text": "you're doing think about the questions you're asking think about the populations that your tool is serving and as you're building",
    "start": "3147400",
    "end": "3155170"
  },
  {
    "text": "that don't fall prey to the fact that just because math said it it's true models tell you what was not what's",
    "start": "3155170",
    "end": "3162070"
  },
  {
    "text": "going to be that's your job our job you",
    "start": "3162070",
    "end": "3167500"
  },
  {
    "text": "can also hire a data scientist these are people whose job is literally to do this",
    "start": "3167500",
    "end": "3173950"
  },
  {
    "text": "sort of thing they are going to be the ones with that specialized expertise to know the tools that are available and",
    "start": "3173950",
    "end": "3179350"
  },
  {
    "text": "the to be able to actually implement them alternately you can train yourself up there are a bunch of different tools",
    "start": "3179350",
    "end": "3186880"
  },
  {
    "text": "or courses and things I'm not going to go in detail on a lot of different suggestions I will say that I have a",
    "start": "3186880",
    "end": "3193300"
  },
  {
    "text": "tendency to trend toward actual universities a lot of these things are problems that science itself has been",
    "start": "3193300",
    "end": "3200020"
  },
  {
    "text": "dealing with for a long time and the process of science has been crafted to",
    "start": "3200020",
    "end": "3205060"
  },
  {
    "text": "help avoid cognitive biases and avoid a bunch of these particular types of errors you can also try finding other",
    "start": "3205060",
    "end": "3213760"
  },
  {
    "text": "people solving the same problems the AI now Institute is a good one Georgetown Law Center on privacy and",
    "start": "3213760",
    "end": "3219670"
  },
  {
    "text": "Technology the might foundation has an AI ethics inif initiative and fast dot a is another place you can find some",
    "start": "3219670",
    "end": "3225430"
  },
  {
    "text": "really good resources you might note that I did not include any company-sponsored things up here that is",
    "start": "3225430",
    "end": "3233940"
  },
  {
    "text": "intentional it's not that they don't exist Google has one or it did before it fell apart I'm assuming they're gonna",
    "start": "3233940",
    "end": "3239940"
  },
  {
    "text": "try again I believe Microsoft also has one there are a number of other ones that are large and attached to the companies I",
    "start": "3239940",
    "end": "3246920"
  },
  {
    "text": "have some healthy skepticism about those mostly because it's a question of ok who",
    "start": "3246920",
    "end": "3255920"
  },
  {
    "text": "what side are you benefitting here but that doesn't mean that they can't do good work you can also try abiding by",
    "start": "3255920",
    "end": "3263760"
  },
  {
    "start": "3262000",
    "end": "3262000"
  },
  {
    "text": "ethics guidelines there were a number of different data ethics and data like information and and machine learning",
    "start": "3263760",
    "end": "3269820"
  },
  {
    "text": "ethics out there there are a number of different codes most of them include things like privacy and content",
    "start": "3269820",
    "end": "3276680"
  },
  {
    "start": "3274000",
    "end": "3274000"
  },
  {
    "text": "transparency of use to the user transparency the algorithm to used how it was trained etc and thinking about",
    "start": "3276680",
    "end": "3283410"
  },
  {
    "text": "who owns that actual data whether it's you the user etc I just said I was",
    "start": "3283410",
    "end": "3289590"
  },
  {
    "text": "trying not to promote companies but I do want to say Accenture actually has a PDF out there",
    "start": "3289590",
    "end": "3295130"
  },
  {
    "text": "that I thought was actually really good and I'm saying that knowing I'm not a",
    "start": "3295130",
    "end": "3303420"
  },
  {
    "text": "huge fan of Accenture in a lot of ways but this was a really well-done paper it actually I mean it reads like a",
    "start": "3303420",
    "end": "3308970"
  },
  {
    "text": "marketing slick in some ways but it does go into detail on here's a three month plan for what you're doing as far as",
    "start": "3308970",
    "end": "3315660"
  },
  {
    "text": "having a data ethics Plan data ethics rules etc it talks about the list of 17",
    "start": "3315660",
    "end": "3323070"
  },
  {
    "text": "individual tenets that you your team should be adhering to for data management etc so I thought it was",
    "start": "3323070",
    "end": "3328860"
  },
  {
    "text": "really comprehensive and I wanted to make sure that I was including it I will",
    "start": "3328860",
    "end": "3333930"
  },
  {
    "text": "be up here if you have any questions thank you very much for come to my talk",
    "start": "3333930",
    "end": "3339660"
  },
  {
    "text": "and listen to me ramble about AI and brains for an hour I hope you learned something",
    "start": "3339660",
    "end": "3346670"
  },
  {
    "text": "yep thank you",
    "start": "3355279",
    "end": "3361249"
  }
]
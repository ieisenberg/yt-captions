[
  {
    "start": "0",
    "end": "90000"
  },
  {
    "text": "all right thank you everyone for coming forget to get started it's not about",
    "start": "5970",
    "end": "11290"
  },
  {
    "text": "trains it's about performance welcome so",
    "start": "11290",
    "end": "18190"
  },
  {
    "text": "before we get into the talk itself very briefly a little bit about me this is my",
    "start": "18190",
    "end": "25330"
  },
  {
    "text": "Twitter bio thingy I am at David when gia I am at David Windsor at most places",
    "start": "25330",
    "end": "31720"
  },
  {
    "text": "because of the virtues of having a relatively unique surname when I was growing up there was only four windows",
    "start": "31720",
    "end": "37329"
  },
  {
    "text": "in the phonebook was my parents my two uncles and my grandparents and now I don't have a phone books have no idea",
    "start": "37329",
    "end": "43920"
  },
  {
    "text": "this is my LinkedIn profile just to prove there's only ever been one good photo taken off me this is the extended",
    "start": "43920",
    "end": "50920"
  },
  {
    "text": "version and this is the most important part of my LinkedIn profile and if you learn only one thing from this talk let",
    "start": "50920",
    "end": "56739"
  },
  {
    "text": "it be this you can write whatever you want in there and you can drag it to the top of your profile and then you can get",
    "start": "56739",
    "end": "62050"
  },
  {
    "text": "eight or nine of your friends to endorse you and go get that job you want but I don't work on Lego I work at a company",
    "start": "62050",
    "end": "69400"
  },
  {
    "text": "the US company they make mice and keyboards and some software it's called Microsoft and I say this as a disclaimer",
    "start": "69400",
    "end": "76659"
  },
  {
    "text": "I wrote the talk before I started working there the talk got selected before I started working there so this",
    "start": "76659",
    "end": "81909"
  },
  {
    "text": "is merely my opinion on 15 years of experience and not official guidance but hopefully maybe it's still really good",
    "start": "81909",
    "end": "90329"
  },
  {
    "start": "90000",
    "end": "265000"
  },
  {
    "text": "so let's talk performance premature optimization is the root of all evil hands up if you haven't heard this",
    "start": "90329",
    "end": "97299"
  },
  {
    "text": "little snippet excellent for the record of the video everybody here is the",
    "start": "97299",
    "end": "103329"
  },
  {
    "text": "introvert and didn't raise their heads does anyone know who said it",
    "start": "103329",
    "end": "111210"
  },
  {
    "text": "feel free to yes Donald Knuth enough Knuth however I've",
    "start": "111210",
    "end": "117520"
  },
  {
    "text": "heard it pronounced many times in his presence and he's never corrected anyone that I've seen so I'm not sure but he",
    "start": "117520",
    "end": "124299"
  },
  {
    "text": "said it and so it's kind of I think a",
    "start": "124299",
    "end": "129820"
  },
  {
    "text": "bit problematic or at least how it's used is problematic and I think it's not what he probably intended so",
    "start": "129820",
    "end": "138300"
  },
  {
    "text": "the way that I've seen this expression used is usually as a way to avoid work",
    "start": "138300",
    "end": "145920"
  },
  {
    "text": "people say it as a way of saying don't don't do that work now don't worry about",
    "start": "145920",
    "end": "150970"
  },
  {
    "text": "performance let there be a problem before you solve it which is another way of saying that the users find your bugs which is not",
    "start": "150970",
    "end": "157600"
  },
  {
    "text": "great and thing is I think it's misrepresentation too so I've personally",
    "start": "157600",
    "end": "163450"
  },
  {
    "text": "been on the receiving end of this in two main scenarios so say for example",
    "start": "163450",
    "end": "169270"
  },
  {
    "text": "there's a pull request where someone's written a and a bunch of linked queries",
    "start": "169270",
    "end": "174840"
  },
  {
    "text": "you know select some filter the data put it into some kind of list filter it",
    "start": "174840",
    "end": "180640"
  },
  {
    "text": "again do some other thing call the function and it's a bunch of these things down the page and I will come in",
    "start": "180640",
    "end": "186640"
  },
  {
    "text": "and because I'm old I know how to write full loop still so I'll say hey you know you could just do one loop and you know",
    "start": "186640",
    "end": "192160"
  },
  {
    "text": "filter that with some if statements or a switch or some functions or whatever and the reply will be premature optimization",
    "start": "192160",
    "end": "197440"
  },
  {
    "text": "is the root of all evil don't have to do any work fine and then the other thing",
    "start": "197440",
    "end": "202540"
  },
  {
    "text": "I've seen is the flip side where I will write some code and I will write a for loop sometimes and someone will come in",
    "start": "202540",
    "end": "210280"
  },
  {
    "text": "and say hey you know that maybe if you use link that would be more readable or more linear and not as nested and my",
    "start": "210280",
    "end": "216400"
  },
  {
    "text": "response is usually yep that's true however personally I don't have a problem with this and it uses less",
    "start": "216400",
    "end": "222010"
  },
  {
    "text": "memory and it's probably more performant but you know let me know rest of the team if there's a readability issue and",
    "start": "222010",
    "end": "227440"
  },
  {
    "text": "then they reply and say well no but premature optimization is rid of all evil you shouldn't have prematurely optimize it you should now go do some",
    "start": "227440",
    "end": "234340"
  },
  {
    "text": "work because you did the work to do that anyway this actually did happen to me I've had this conversation where someone",
    "start": "234340",
    "end": "240130"
  },
  {
    "text": "wanted me to invest more time because I mistakenly invested time in their eyes but anyway the thing is it's unfair so",
    "start": "240130",
    "end": "248580"
  },
  {
    "text": "hopefully you're now thinking hmm Dave nobody's talking about you're also thinking he has no idea how to format a",
    "start": "248580",
    "end": "254590"
  },
  {
    "text": "slide in PowerPoint and that's not true so this is but a",
    "start": "254590",
    "end": "259970"
  },
  {
    "text": "fragment of a sentence and the rest of the sentence and the one after kind of give a lot more context so the fuller",
    "start": "259970",
    "end": "267680"
  },
  {
    "start": "265000",
    "end": "321000"
  },
  {
    "text": "quote there is we should forget about small efficiencies about 97% of the time",
    "start": "267680",
    "end": "272889"
  },
  {
    "text": "doctor but yet we should not pass up our opportunities in that critical 3% so in",
    "start": "272889",
    "end": "278330"
  },
  {
    "text": "his original statement Donald Knuth is identifying the fact that you absolutely have to sometimes prematurely",
    "start": "278330",
    "end": "286490"
  },
  {
    "text": "optimize or care about performance or however you want to you know phrase it and I'm going to assume that the ninety",
    "start": "286490",
    "end": "292550"
  },
  {
    "text": "seven percent and three percent is made up I don't know he may have done exhaustive studies but I think the",
    "start": "292550",
    "end": "300139"
  },
  {
    "text": "context here is completely lost on most of the people who spout out this thing you sometimes have to worry about",
    "start": "300139",
    "end": "305840"
  },
  {
    "text": "performance it absolutely have to the keen-eyed amongst you will notice that my quotes aren't balanced and that's",
    "start": "305840",
    "end": "311930"
  },
  {
    "text": "because this there's another sentence turns out he didn't just write one word once it literally go away so for even",
    "start": "311930",
    "end": "318800"
  },
  {
    "text": "more context and this is kind of completes the picture for me programmers waste enormous amounts of time thinking",
    "start": "318800",
    "end": "324860"
  },
  {
    "start": "321000",
    "end": "407000"
  },
  {
    "text": "about or worrying about the speed of non-critical parts of their programs and these attempts at efficiency actually",
    "start": "324860",
    "end": "329870"
  },
  {
    "text": "have a strong negative impact when debugging and maintenance are considered and so with a tiny bit of poetic license",
    "start": "329870",
    "end": "337880"
  },
  {
    "text": "I think this so this is a statement I can completely agree with even though I don't agree most of the time that people",
    "start": "337880",
    "end": "343460"
  },
  {
    "text": "spout out premature optimization because what he's saying is you have to balance all of these factors and you shouldn't",
    "start": "343460",
    "end": "350389"
  },
  {
    "text": "worry about trying to write the most performant thing first you should think about debugging your maintenance and I",
    "start": "350389",
    "end": "355699"
  },
  {
    "text": "absolutely agree with that but I think that same thing applies to all of those other factors of software as well its",
    "start": "355699",
    "end": "361940"
  },
  {
    "text": "readability and stability and performance you shouldn't focus on debug ability that you shouldn't focus on maintenance you should balance them all",
    "start": "361940",
    "end": "368599"
  },
  {
    "text": "out for bonus points does anyone know where this these two sentences appeared",
    "start": "368599",
    "end": "375469"
  },
  {
    "text": "what paper or what article I don't expect anyone to know so I I just like it because it's a",
    "start": "375469",
    "end": "381190"
  },
  {
    "text": "little bit ironic so the people who say premature optimization is the root of",
    "start": "381190",
    "end": "386350"
  },
  {
    "text": "all evil you know I don't necessarily write their broad thinking about the",
    "start": "386350",
    "end": "393160"
  },
  {
    "text": "craft of software and so they also would probably have strong opinions on the use of go-to statements which is funny",
    "start": "393160",
    "end": "399610"
  },
  {
    "text": "because this is from an article titled structured programming we'd go to assignments it's probably a book I don't",
    "start": "399610",
    "end": "404710"
  },
  {
    "text": "know anyway so coding is about trade-offs right there is usually a",
    "start": "404710",
    "end": "411460"
  },
  {
    "start": "407000",
    "end": "501000"
  },
  {
    "text": "dozen or more ways to solve any problem with code and so our job as programmers is to work out what is the best way to",
    "start": "411460",
    "end": "418030"
  },
  {
    "text": "solve this problem I am dealing with now and you have to balance up all of the",
    "start": "418030",
    "end": "423250"
  },
  {
    "text": "factors and performance is absolutely one of them you shouldn't avoid it you shouldn't focus on it it's a balance and",
    "start": "423250",
    "end": "429490"
  },
  {
    "text": "for every situation you're writing code you have to think about all of the factors and so you use the context of",
    "start": "429490",
    "end": "437770"
  },
  {
    "text": "your code and where you're running and use the data and your knowledge of what you're processing cetera to inform those",
    "start": "437770",
    "end": "444520"
  },
  {
    "text": "decisions and you weigh up the factors and you choose the best path for this specific example if that wasn't what",
    "start": "444520",
    "end": "452169"
  },
  {
    "text": "programming was for we would have a boring job because we just be typing the the thought process is the job so",
    "start": "452169",
    "end": "458580"
  },
  {
    "text": "premature of thinking about optimization is absolutely I mean I think it's a requirement and that's a bit of poetic",
    "start": "458580",
    "end": "465460"
  },
  {
    "text": "license as well because premature kind of means before you should let's say early thinking about optimization so",
    "start": "465460",
    "end": "472210"
  },
  {
    "text": "maybe don't do it but you have to think about it you can't avoid it and you have to I don't have to but I think it's",
    "start": "472210",
    "end": "479020"
  },
  {
    "text": "ideal if you can create a culture of performance thinking in your organization so that you know when you",
    "start": "479020",
    "end": "485980"
  },
  {
    "text": "get to a code review nobody in your team is going to be saying I don't worry about that till it's a problem because",
    "start": "485980",
    "end": "492040"
  },
  {
    "text": "they will know that everybody else on the team and you included have thought about the possible impacts so how do you",
    "start": "492040",
    "end": "499960"
  },
  {
    "text": "think about these things you have to know the context of your execution so I",
    "start": "499960",
    "end": "505240"
  },
  {
    "start": "501000",
    "end": "757000"
  },
  {
    "text": "used to work at a company that did student software and most of the",
    "start": "505240",
    "end": "510910"
  },
  {
    "text": "customers would have data dump from their main front system that had you know hundred thousand student records in it and they would",
    "start": "510910",
    "end": "517518"
  },
  {
    "text": "send it off to our system and we cared about ten thousand of them and overnight 1 a.m. we'd process that file to see what's",
    "start": "517519",
    "end": "524540"
  },
  {
    "text": "changed and so we knew our code was running at night in the middle of the",
    "start": "524540",
    "end": "529610"
  },
  {
    "text": "night where no one's using the system and that let us make some trade-offs around performance if you're writing a",
    "start": "529610",
    "end": "537320"
  },
  {
    "text": "website and your code is running on every single request and it's a public-facing website that could get 2",
    "start": "537320",
    "end": "542420"
  },
  {
    "text": "million hits per minute then you're going to make some very different trade-offs so you need to know where",
    "start": "542420",
    "end": "548089"
  },
  {
    "text": "your code runs before you can actually identify what is the correct approach and then you need to know the shape and",
    "start": "548089",
    "end": "553880"
  },
  {
    "text": "the size and the type of data your code is processing if that's relevant so your code that is running on every single",
    "start": "553880",
    "end": "559940"
  },
  {
    "text": "request is probably processing you maybe it's looking at a cookie if it's like an action filter or something that's a",
    "start": "559940",
    "end": "565430"
  },
  {
    "text": "small amount of data that enables you to make some decisions about what types of storage our processing than hundreds of",
    "start": "565430",
    "end": "572029"
  },
  {
    "text": "thousands of student records that's a lot of data so you're going to make some different decisions you know maybe don't",
    "start": "572029",
    "end": "578209"
  },
  {
    "text": "read it all into a string you got to validate your assumptions so I've seen",
    "start": "578209",
    "end": "583610"
  },
  {
    "text": "times where people will write their code for high readability let's say and",
    "start": "583610",
    "end": "589959"
  },
  {
    "text": "they'll be some sort of wasted effort in the middle that could be removed if performance is a problem but they assume",
    "start": "589959",
    "end": "596480"
  },
  {
    "text": "the compiler is smart enough to remove these unnecessary bits and join the pieces up together and that sometimes is",
    "start": "596480",
    "end": "602690"
  },
  {
    "text": "true but it's sometimes not and it's really easy to validate your assumptions especially in dotnet where you contribute Leedy compile your code after",
    "start": "602690",
    "end": "609620"
  },
  {
    "text": "the compilers got at it but not just that validate your assumptions about usage patterns validate your assumptions",
    "start": "609620",
    "end": "615620"
  },
  {
    "text": "about those those that context that data and consider the worst case so at this",
    "start": "615620",
    "end": "622579"
  },
  {
    "text": "previous job with these hundred thousand student records there was a very big",
    "start": "622579",
    "end": "627980"
  },
  {
    "text": "university that had lots lots of money and his home too was home to some of the",
    "start": "627980",
    "end": "633529"
  },
  {
    "text": "best search engines around and they gave our installation a 5 gigabyte drive on",
    "start": "633529",
    "end": "639230"
  },
  {
    "text": "our virtual machine and they wanted us to process all of their student records and it was a",
    "start": "639230",
    "end": "644440"
  },
  {
    "text": "and I can't remember much Ram it was but it was almost nothing so this thing was constantly paging and this import over",
    "start": "644440",
    "end": "650680"
  },
  {
    "text": "time got slower and slower and slower so starting out at 1 a.m. when no one's using the system fine we can make some",
    "start": "650680",
    "end": "657399"
  },
  {
    "text": "decisions and not care about performance as much maybe but if that import starts to take 8 hours yeah 12 hours we're",
    "start": "657399",
    "end": "664329"
  },
  {
    "text": "running into people now using the system or in the worst case 26 hours what what",
    "start": "664329",
    "end": "669490"
  },
  {
    "text": "do you do on a nightly import that takes more than a day to run do you run it again and like offset your thing or do",
    "start": "669490",
    "end": "675699"
  },
  {
    "text": "you run it twice at the same time we just skip a day like so consider the worst case in factoring in those things",
    "start": "675699",
    "end": "681519"
  },
  {
    "text": "and consider how likely that worst case is to happen think about your algorithms",
    "start": "681519",
    "end": "687160"
  },
  {
    "text": "and your data structures so think bigger when you're thinking about performance because it's very easy to sort of go",
    "start": "687160",
    "end": "693100"
  },
  {
    "text": "down the rabbit hole and focus on the wrong thing and optimizing the wrong thing so if we were reading that 100,000",
    "start": "693100",
    "end": "699939"
  },
  {
    "text": "line file into er you know into a string or a list of strings it would be easy to sit there and spend days trying to get",
    "start": "699939",
    "end": "706389"
  },
  {
    "text": "this method that processes a list of strings to be as fast as it can be but you maybe don't want to read the whole",
    "start": "706389",
    "end": "712269"
  },
  {
    "text": "file in at once and maybe that'll help you know so think about whether the data structure using there might be a more",
    "start": "712269",
    "end": "717790"
  },
  {
    "text": "tailored data structure and you've got it sometimes you got to go back to you see s stuff if you did see us which I",
    "start": "717790",
    "end": "723040"
  },
  {
    "text": "didn't but then having said that don't be afraid of micro benchmarking once you",
    "start": "723040",
    "end": "728680"
  },
  {
    "text": "identify what's actually going on because if you if you can profile your application under the right circumstances and if you can know what",
    "start": "728680",
    "end": "734529"
  },
  {
    "text": "your hot path is then micro benchmarking is absolutely the easiest way to make these decisions because you get really",
    "start": "734529",
    "end": "741600"
  },
  {
    "text": "like reliable numbers you can make decisions on and that's kind of what",
    "start": "741600",
    "end": "747399"
  },
  {
    "text": "we're going to be talking about so how do you actually measure performance or",
    "start": "747399",
    "end": "753069"
  },
  {
    "text": "how do you do performance work and there is only one rule and I've spoiled it for myself because I just said the word then you have to measure you have to measure",
    "start": "753069",
    "end": "758860"
  },
  {
    "text": "your code you have to measure it before you make any changes you have to measure it afterwards you have to compare them measure it along the way measure measure",
    "start": "758860",
    "end": "765490"
  },
  {
    "text": "measure that's it number one rule so",
    "start": "765490",
    "end": "770579"
  },
  {
    "text": "this is the code that inspired this talk I was at work and someone wrote this",
    "start": "770579",
    "end": "775720"
  },
  {
    "text": "code and I was on the pull request and I looked at it and I read it ok so data is",
    "start": "775720",
    "end": "780730"
  },
  {
    "text": "a list of strings for context I looked at this as an aggregate ok I mean I know",
    "start": "780730",
    "end": "786040"
  },
  {
    "text": "link but I haven't used the aggregate method and I remember what that does and then empty string and anyway what this",
    "start": "786040",
    "end": "791800"
  },
  {
    "text": "does is it joins strings together right makes takes multiple strings comma separates them and I left a comment on",
    "start": "791800",
    "end": "798639"
  },
  {
    "text": "the pull request saying don't do that that's slow and uses too much memory and as soon as I said that I kind of thought",
    "start": "798639",
    "end": "805269"
  },
  {
    "text": "that's not really constructive so hey how slow is slow how fast does this have",
    "start": "805269",
    "end": "812949"
  },
  {
    "text": "to be where is this used how much memory is too much memory right you you kind of can't really make these statements",
    "start": "812949",
    "end": "819009"
  },
  {
    "text": "without some of that grounding in reality so I decided to find out so I",
    "start": "819009",
    "end": "825790"
  },
  {
    "text": "thought well I'll benchmark it and I'll compare it to what I think is the better thing to do and let's just see if I'm right so how do we measure code this is",
    "start": "825790",
    "end": "833470"
  },
  {
    "start": "830000",
    "end": "1002000"
  },
  {
    "text": "the first code profiling code that most people write does anyone want to shout",
    "start": "833470",
    "end": "841480"
  },
  {
    "text": "out what's wrong with it because I'm sure that some of you know stopwatch",
    "start": "841480",
    "end": "847089"
  },
  {
    "text": "very good anything else cheating very good anyone else they are",
    "start": "847089",
    "end": "854920"
  },
  {
    "text": "they're like the two main ones there's a few more things so the easiest way to talk about what's wrong with it is to",
    "start": "854920",
    "end": "860050"
  },
  {
    "text": "show you the right way so this is a better profile and there's a few things",
    "start": "860050",
    "end": "867160"
  },
  {
    "text": "going on here so first of all we are setting the the process priority and thread priority to high and that's just",
    "start": "867160",
    "end": "873189"
  },
  {
    "text": "because with benchmarking you need to measure all of the code not just find",
    "start": "873189",
    "end": "878410"
  },
  {
    "text": "out how long your new code takes you need to compare it to your old code and you might have one or two approaches and you might not be sure so you're probably",
    "start": "878410",
    "end": "884500"
  },
  {
    "text": "going to do multiple runs and the last thing you want is your antivirus to jump in in the middle of one and throw off",
    "start": "884500",
    "end": "890319"
  },
  {
    "text": "your results well you might be simulating 24 trains running around in Chrome and it's going to cause problems",
    "start": "890319",
    "end": "896429"
  },
  {
    "text": "so that's a way to just say you know dedicate the machine to benchmarking at this time so that doesn't get into",
    "start": "896429",
    "end": "903490"
  },
  {
    "text": "it doesn't matter what machine it is I mean you obviously can't compare you know my laptop running on battery power to my desktop and home I'm not going to",
    "start": "903490",
    "end": "909610"
  },
  {
    "text": "compare those numbers but for any one run so then we call that function and that tries to take out the overhead of",
    "start": "909610",
    "end": "916959"
  },
  {
    "text": "jetting so dotnet is you know a managed runs in a runtime it compiles to Il and",
    "start": "916959",
    "end": "922060"
  },
  {
    "text": "then the JIT compiles your code again and optimizes it and that takes time so the first run is going to be a little",
    "start": "922060",
    "end": "927760"
  },
  {
    "text": "bit slower than subsequent runs so you get that out of the way then we use a stopwatch as was mentioned so stopwatch",
    "start": "927760",
    "end": "936100"
  },
  {
    "text": "and date/time are both as precise as each other but stopwatch is more",
    "start": "936100",
    "end": "942520"
  },
  {
    "text": "granular so both of them go down to the tick level but if you're in a tight loop and your output what the ticks are",
    "start": "942520",
    "end": "948190"
  },
  {
    "text": "you'll find the stopwatch value changes more often so you want you know you want more granularity to be able to profile",
    "start": "948190",
    "end": "954279"
  },
  {
    "text": "your code so always use a stopwatch it's actually kind of unfortunate the day time has a text property because I think",
    "start": "954279",
    "end": "959350"
  },
  {
    "text": "that leads you down the path of thinking that it's the same it's not and then we",
    "start": "959350",
    "end": "965649"
  },
  {
    "text": "have garbage collection in the same vein as cheating you know dinette has a garbage collector you just want a clean",
    "start": "965649",
    "end": "971980"
  },
  {
    "text": "slate for your run you don't want to run your old code then start running your new code and find that garbage collector",
    "start": "971980",
    "end": "977709"
  },
  {
    "text": "has to jump in to clean up all the memory from your old run you're not gonna be able to compare them so just try as much as possible to get a clean",
    "start": "977709",
    "end": "983589"
  },
  {
    "text": "slate for profiling then we run our code a hundred times to you know smooth out",
    "start": "983589",
    "end": "988779"
  },
  {
    "text": "the spikes and we output it so this is the sort of I don't wanna say canonical",
    "start": "988779",
    "end": "995110"
  },
  {
    "text": "but it's like this is this is pretty good code if you have to write your own profiling code the thing is you don't so",
    "start": "995110",
    "end": "1000779"
  },
  {
    "text": "the best way to profile code is to use benchmark dotnet let somebody else write the code so benchmark dotnet if you",
    "start": "1000779",
    "end": "1007320"
  },
  {
    "start": "1002000",
    "end": "1083000"
  },
  {
    "text": "haven't heard is an open source product worked on mainly by three guys one of",
    "start": "1007320",
    "end": "1014010"
  },
  {
    "text": "whom now works for Microsoft the other one works for JetBrains and the other one is currently looking for a job I",
    "start": "1014010",
    "end": "1019020"
  },
  {
    "text": "think might end up with Microsoft I suspect but it's supported by the dotnet",
    "start": "1019020",
    "end": "1024030"
  },
  {
    "text": "foundation so it's you know should be around for a while it's used internally by Microsoft on you know all of their",
    "start": "1024030",
    "end": "1031500"
  },
  {
    "text": "got net stuff or mostly they're not in that stuff and it's super flexible so it can benchmark",
    "start": "1031500",
    "end": "1037110"
  },
  {
    "text": "anything you can throw at it in the dotnet world just about it can do done it fooled on it core mono you can pick",
    "start": "1037110",
    "end": "1042660"
  },
  {
    "text": "which jitter to use you can pick x86 x64 you can write your own garbage collector",
    "start": "1042660",
    "end": "1048360"
  },
  {
    "text": "and tell it to use that instead of the built-in one it's ridiculous and it's got a whole plugin model so there's an ecosystem and it can measure a bunch of",
    "start": "1048360",
    "end": "1055380"
  },
  {
    "text": "different things so by default sort of out of the box you get time you get memory and you get the garbage",
    "start": "1055380",
    "end": "1062100"
  },
  {
    "text": "collection characteristics so I do have a slide here that explains how it works",
    "start": "1062100",
    "end": "1068340"
  },
  {
    "text": "but I've decided that's really dry so I'm not gonna bother with that we'll do a demo and I'll explain it live but that",
    "start": "1068340",
    "end": "1074700"
  },
  {
    "text": "URL how it works has an even more in-depth guide and it actually has pseudocode for the whole thing which is",
    "start": "1074700",
    "end": "1080460"
  },
  {
    "text": "really if you're interested it's fascinating read but let's do a demo I have to warn you though",
    "start": "1080460",
    "end": "1086940"
  },
  {
    "start": "1083000",
    "end": "1102000"
  },
  {
    "text": "so benchmark dotnet is slow and when I say slow what I mean is it's thorough and we'll see why but so this is the",
    "start": "1086940",
    "end": "1093690"
  },
  {
    "text": "only demo it only takes about a minute to run but it's like a minute of dead",
    "start": "1093690",
    "end": "1099330"
  },
  {
    "text": "air is not good anyway let's write a benchmark so this is a console app the only thing I've done ooh",
    "start": "1099330",
    "end": "1107730"
  },
  {
    "start": "1102000",
    "end": "1321000"
  },
  {
    "text": "that could just go config the only thing I've done is referenced benchmarked on",
    "start": "1107730",
    "end": "1112770"
  },
  {
    "text": "it from nougat and the rest of the world just to save you know Wi-Fi whatever",
    "start": "1112770",
    "end": "1117860"
  },
  {
    "text": "path that starting from scratch so to write a benchmark is really easy it's a console app first thing to check",
    "start": "1117860",
    "end": "1126270"
  },
  {
    "text": "is in it's in release mode you have to benchmark in release mode if you've been chucking debug mode your results are",
    "start": "1126270",
    "end": "1132660"
  },
  {
    "text": "going to be so invalid that benchmark dot that actually refuses to run it just throws an error and so to run a",
    "start": "1132660",
    "end": "1140130"
  },
  {
    "text": "benchmark there's a class called the benchmark runner token type and we",
    "start": "1140130",
    "end": "1147390"
  },
  {
    "text": "simply say run and you give it the class that has the benchmarks in it so that's kicking it off there's also a",
    "start": "1147390",
    "end": "1155100"
  },
  {
    "text": "thing called a benchmark switcher which enables sort of console interactivity so",
    "start": "1155100",
    "end": "1160710"
  },
  {
    "text": "we will list out the benchmarks you can pick which one to use and then we're now so now we need to write some benchmarks",
    "start": "1160710",
    "end": "1166320"
  },
  {
    "text": "and they're written a lot like writing unit tests so there's a Ben mark attribute which is in that",
    "start": "1166320",
    "end": "1175530"
  },
  {
    "text": "namespace and then we simply have a public method and you write your",
    "start": "1175530",
    "end": "1184590"
  },
  {
    "text": "benchmarking code so we're doing joining strings right so let me just create a an",
    "start": "1184590",
    "end": "1192720"
  },
  {
    "text": "array that we're going to join together and I'm just going to be lazy range",
    "start": "1192720",
    "end": "1204590"
  },
  {
    "text": "oops - array so it's have an array of 10",
    "start": "1209570",
    "end": "1215059"
  },
  {
    "text": "numbers nothing exciting and here I'm just going to join them together with a",
    "start": "1215059",
    "end": "1220489"
  },
  {
    "text": "comma so there's our benchmark of what I think the good code is now because we",
    "start": "1220489",
    "end": "1227690"
  },
  {
    "text": "always want to compare we're going to do another benchmark and this is going to be our old code so this is aggregate and",
    "start": "1227690",
    "end": "1237789"
  },
  {
    "text": "if I remember how to do it we're good string dot MD current next current plus",
    "start": "1237789",
    "end": "1247369"
  },
  {
    "text": "next right and that's it we're done so we can run this and will now get results",
    "start": "1247369",
    "end": "1253580"
  },
  {
    "text": "and I will in a second one thing to point out that you probably noticed is",
    "start": "1253580",
    "end": "1259009"
  },
  {
    "text": "I'm returning a value from each of these methods this is something that's just a best practice it's not required by",
    "start": "1259009",
    "end": "1265070"
  },
  {
    "text": "benchmark dotnet but it's best practice for getting reliable benchmarks what you want to do is make sure you're using the",
    "start": "1265070",
    "end": "1271159"
  },
  {
    "text": "result of your function unless the jitter or the compiler optimizes it completely out of existence and right",
    "start": "1271159",
    "end": "1278239"
  },
  {
    "text": "now there's not a lot that that will apply to in c-sharp but it's good for future proofing because they're only",
    "start": "1278239",
    "end": "1283700"
  },
  {
    "text": "working on more of those sort of optimizations it's particularly if you're benchmarking JavaScript the v8",
    "start": "1283700",
    "end": "1289429"
  },
  {
    "text": "compiler is great at just removing code so make sure you're using your values or you'll get very very fast runs because",
    "start": "1289429",
    "end": "1296749"
  },
  {
    "text": "the methods don't contain any code and the other thing I'm gonna do here is I'm just gonna mark this as the baseline and",
    "start": "1296749",
    "end": "1303470"
  },
  {
    "text": "so a baseline just means that we're telling benchmark net what Al you know what we want to compare against and so",
    "start": "1303470",
    "end": "1308599"
  },
  {
    "text": "in this case usually it's the existing code and the baseline we'll see in a second will give us a very simple scaled",
    "start": "1308599",
    "end": "1316879"
  },
  {
    "text": "output and you can look at your results and you don't have to read any of the numbers except for the scale and if it's",
    "start": "1316879",
    "end": "1322340"
  },
  {
    "start": "1321000",
    "end": "1544000"
  },
  {
    "text": "less than one it's better if it's more than one it's worse so this is gonna run and as I said it's a bit it takes a bit",
    "start": "1322340",
    "end": "1331129"
  },
  {
    "text": "so I'll talk to everything in a minute just whoops okay I won't do that",
    "start": "1331129",
    "end": "1336379"
  },
  {
    "text": "magnify I see so you can see here it's doing two million runs so the first",
    "start": "1336379",
    "end": "1342379"
  },
  {
    "text": "stage of benchmarked on it's called the pilot and it does one run of your code and then two runs of your code and then four runs of your",
    "start": "1342379",
    "end": "1348530"
  },
  {
    "text": "code etc etc to try to find a good amount of runs that's going to give it a nice you know reliable sample size to",
    "start": "1348530",
    "end": "1355970"
  },
  {
    "text": "even have spikes but not take forever because he doesn't know what your code does could take ten minutes to run your",
    "start": "1355970",
    "end": "1361190"
  },
  {
    "text": "code so it doesn't want to run at two million times if that's the case and then it does a series of warm-ups and it",
    "start": "1361190",
    "end": "1367760"
  },
  {
    "text": "does two main warm-ups one is to establish how long benchmark net is actually adding to this whole process so",
    "start": "1367760",
    "end": "1374390"
  },
  {
    "text": "what's the overhead that it's adding by virtue of its measurement code and then there's the overhead for the jitter and",
    "start": "1374390",
    "end": "1380690"
  },
  {
    "text": "all of those things we talked about before and then it does this which is the workload actual so this is where",
    "start": "1380690",
    "end": "1385880"
  },
  {
    "text": "it's actually measuring and you can see it's running our code so it's running at two million operations per iteration and",
    "start": "1385880",
    "end": "1392120"
  },
  {
    "text": "it's up to 75 iterations so it's doing a lot of work it's it's exhaustive testing and it essentially does this until it's",
    "start": "1392120",
    "end": "1399530"
  },
  {
    "text": "happy that it's getting consistent numbers it can rely on so it's doing statistical analysis and also thing and",
    "start": "1399530",
    "end": "1404990"
  },
  {
    "text": "you can see what's happening here we're getting around 300 ish nanoseconds per operation but there's some here that",
    "start": "1404990",
    "end": "1410600"
  },
  {
    "text": "like 480 and so that'll be you know an outlier and here we go again so this is",
    "start": "1410600",
    "end": "1418030"
  },
  {
    "text": "that was running one of the methods now I see we're down at 500 thousand",
    "start": "1418030",
    "end": "1423140"
  },
  {
    "text": "operations so this is running the other benchmark and I'm guessing this is running the aggregate one because it",
    "start": "1423140",
    "end": "1428600"
  },
  {
    "text": "didn't do as much which means that each one is going to take longer and you can see they're taking around 700 to 800",
    "start": "1428600",
    "end": "1435130"
  },
  {
    "text": "nano seconds per operation so you can kind of look at this and you can see what's going on we're up to a microsecond you can kind of guess at",
    "start": "1435130",
    "end": "1442640"
  },
  {
    "text": "which what the results are going to be at this point but if you let it do its work it does finish talk about yourself",
    "start": "1442640",
    "end": "1448490"
  },
  {
    "text": "or ask any questions but what we'll get",
    "start": "1448490",
    "end": "1453710"
  },
  {
    "text": "out of this at the end is a table of results now I am only doing timing here",
    "start": "1453710",
    "end": "1461710"
  },
  {
    "text": "the other thing that usually I find I always do in all of my benchmarks is also memory so how much memory is",
    "start": "1461710",
    "end": "1467960"
  },
  {
    "text": "allocated is a good good thing to check and in this example it's actually very good as well but I've got the results in",
    "start": "1467960",
    "end": "1473390"
  },
  {
    "text": "a graph later so here's the results we can see stream join 358 nanoseconds and aggregate was",
    "start": "1473390",
    "end": "1482030"
  },
  {
    "text": "918 so you know more than twice as fast and there's our scaled output so we can",
    "start": "1482030",
    "end": "1488300"
  },
  {
    "text": "see our current code is 1 and our scaled around new idea is point 4 so it's a",
    "start": "1488300",
    "end": "1494420"
  },
  {
    "text": "clear winner no-brainer if I said to do memory as well it would",
    "start": "1494420",
    "end": "1499610"
  },
  {
    "text": "have ran those same two benchmarks again so it runs a separate run for each benchmark and a separate run for each",
    "start": "1499610",
    "end": "1505970"
  },
  {
    "text": "thing it's trying to measure so there would have been 4 runs which is why I say it's slow so for just those two",
    "start": "1505970",
    "end": "1511010"
  },
  {
    "text": "simple tests I mean so that was 2 minutes 23 it took so you know you would",
    "start": "1511010",
    "end": "1516620"
  },
  {
    "text": "have been out to five minutes for comparing through one line method so so it's not fast but it's thorough and to",
    "start": "1516620",
    "end": "1523160"
  },
  {
    "text": "give you an idea so it's error it's estimated its error there it's within 25 nanoseconds the granularity of the",
    "start": "1523160",
    "end": "1529730"
  },
  {
    "text": "stopwatch class on this machine is 300 nanoseconds so it's able to measure a lot better than it ever really should",
    "start": "1529730",
    "end": "1536980"
  },
  {
    "text": "but it helps that it ran two million ran the code two million times so well stop",
    "start": "1536980",
    "end": "1546530"
  },
  {
    "start": "1544000",
    "end": "1678000"
  },
  {
    "text": "zooming that's benchmarked on it so some",
    "start": "1546530",
    "end": "1551570"
  },
  {
    "text": "results so here's the benchmarks I actually ran and there's a bit more to talk about in this so first of all again",
    "start": "1551570",
    "end": "1558530"
  },
  {
    "text": "much like a unit test we have our global setup so this is like a class initialize and this is where I'm setting up some",
    "start": "1558530",
    "end": "1564920"
  },
  {
    "text": "data so for the real test on initializing a binary with random data",
    "start": "1564920",
    "end": "1570220"
  },
  {
    "text": "this will run once per iteration so there were you know 75 80 iterations not",
    "start": "1570220",
    "end": "1576380"
  },
  {
    "text": "once per operation there were two million of them so each iteration is on the same set of data and then we have",
    "start": "1576380",
    "end": "1583070"
  },
  {
    "text": "this params here with the property now if anyone's use X unit and use theories these is basically habit the same way so",
    "start": "1583070",
    "end": "1590240"
  },
  {
    "text": "this is saying to benchmark on their initialize this property to each of these values in turn and then run all",
    "start": "1590240",
    "end": "1596270"
  },
  {
    "text": "the benchmarks and it also runs them for each of the diagnosis so up here we have",
    "start": "1596270",
    "end": "1601640"
  },
  {
    "text": "our memory diagnosis so this is saying measure memory as well so we're always measures time that's saying also measure",
    "start": "1601640",
    "end": "1606830"
  },
  {
    "text": "memory there's other diagnoses you can and then the our plot exporter is the thing that produces the grass you'll see",
    "start": "1606830",
    "end": "1612749"
  },
  {
    "text": "in a second but so with time and memory and 12 values in that params that's 24",
    "start": "1612749",
    "end": "1620190"
  },
  {
    "text": "runs of the code times however benchmarks you have which in this example was 5 so you know this was",
    "start": "1620190",
    "end": "1627509"
  },
  {
    "text": "almost half an hour to run this so you do need to keep that in mind if you're",
    "start": "1627509",
    "end": "1632669"
  },
  {
    "text": "thinking about it you know put a bit of thought in upfront about maybe you want to try and run it yeah not too often it",
    "start": "1632669",
    "end": "1639090"
  },
  {
    "text": "does take well it depends our busier and so then I benchmark 5 different ways to",
    "start": "1639090",
    "end": "1645179"
  },
  {
    "text": "join strings together because I'm curious so string concatenation I've set",
    "start": "1645179",
    "end": "1650489"
  },
  {
    "text": "that as the baseline because that's the one that you know this is like the dotnet 101 don't concatenate strings in",
    "start": "1650489",
    "end": "1656249"
  },
  {
    "text": "a loop it's terrible right well how bad is it string builder is then this is the good",
    "start": "1656249",
    "end": "1661349"
  },
  {
    "text": "way to do strings so let's see what happens over there we have string builder but I'm initializing it and",
    "start": "1661349",
    "end": "1667529"
  },
  {
    "text": "telling it how big the string is going to be because I'm curious to see how much overhead that would save then we",
    "start": "1667529",
    "end": "1673499"
  },
  {
    "text": "have string join and our aggregate so what are the results these are the",
    "start": "1673499",
    "end": "1680249"
  },
  {
    "start": "1678000",
    "end": "1810000"
  },
  {
    "text": "graphs you get a benchmark net you do need to have are installed to get these graphs but it generates the script that",
    "start": "1680249",
    "end": "1686669"
  },
  {
    "text": "generates the graphs so if you don't have our installed you can just run that script once you do get around to installing it and you get 50 graphs oh",
    "start": "1686669",
    "end": "1695340"
  },
  {
    "text": "yes so much data it's ridiculous but so these are the results and it's kind of",
    "start": "1695340",
    "end": "1700619"
  },
  {
    "text": "hard to read so let's draw a line so for one string string concatenation winds",
    "start": "1700619",
    "end": "1706259"
  },
  {
    "text": "which make sense because you're not really can catch anything it's only one string from then on string builder winds",
    "start": "1706259",
    "end": "1712759"
  },
  {
    "text": "up until we get to four strings and at four strings there's a tiny little bit",
    "start": "1712759",
    "end": "1718859"
  },
  {
    "text": "at four strings our pre-allocated string builder with capacity that one wins",
    "start": "1718859",
    "end": "1725249"
  },
  {
    "text": "because for at that length string builder decides oh I better get ready to",
    "start": "1725249",
    "end": "1731039"
  },
  {
    "text": "get some more data and it initializes a new string builder so from then on",
    "start": "1731039",
    "end": "1736619"
  },
  {
    "text": "string builder with capacity wins at every step but there's not much in it and so you might look at this",
    "start": "1736619",
    "end": "1742600"
  },
  {
    "text": "and you'll think well I'm always gonna specify my capacity on my string builders I mean look at wins it's great",
    "start": "1742600",
    "end": "1748080"
  },
  {
    "text": "but this is where you've got to know what data you're working with so this is one to ten strings if we go to a hundred strings our we basically have three good",
    "start": "1748080",
    "end": "1757000"
  },
  {
    "text": "methods and too bad methods and our good methods are twice as fast as our bad methods if we go to a thousand they're",
    "start": "1757000",
    "end": "1763809"
  },
  {
    "text": "now about four times as fast so with like exponential growth if you have 10,000 strings you're concatenating you",
    "start": "1763809",
    "end": "1770559"
  },
  {
    "text": "can't even see the good methods on the graph right so when you're thinking about performance and this is the I hope",
    "start": "1770559",
    "end": "1777549"
  },
  {
    "text": "what they be talking about don't worry about always initializing your string builders because if you use either of",
    "start": "1777549",
    "end": "1784570"
  },
  {
    "text": "these three methods it's totally fine it is so much better than the bad way of doing it that you're probably never",
    "start": "1784570",
    "end": "1790539"
  },
  {
    "text": "going to notice the difference right so you've got to know what the data you're working on if you're working on somewhere in this range maybe you want",
    "start": "1790539",
    "end": "1798640"
  },
  {
    "text": "to think about it but I'd actually argue that all of these are close enough to the same I mean they're all under what",
    "start": "1798640",
    "end": "1805330"
  },
  {
    "text": "is it 1.2 microseconds for 10 strings yeah so you've got to know how much data you've got to know what's important",
    "start": "1805330",
    "end": "1811419"
  },
  {
    "start": "1810000",
    "end": "1922000"
  },
  {
    "text": "right know the context you're working with know the data are working with it is absolutely fine for readability to",
    "start": "1811419",
    "end": "1817270"
  },
  {
    "text": "win you but you want to deliberately choose it you know you want to think about performance and maybe measure it",
    "start": "1817270",
    "end": "1823480"
  },
  {
    "text": "and deliberately say yes in this case I will go with the less efficient but more readable way and maybe put a code in the",
    "start": "1823480",
    "end": "1829840"
  },
  {
    "text": "comment for future people to read that and then the other thing you've got to be conscious of when you're looking at memory and time is what's more important",
    "start": "1829840",
    "end": "1837130"
  },
  {
    "text": "to you so the end result of this line of code I saw a pull request was actually",
    "start": "1837130",
    "end": "1843730"
  },
  {
    "text": "that I was wrong it wasn't slow and it didn't use too much memory because it was combining three strings of twenty",
    "start": "1843730",
    "end": "1851049"
  },
  {
    "text": "characters each actually was up to three strings because there was some conditional logic and so string builder",
    "start": "1851049",
    "end": "1856299"
  },
  {
    "text": "the good way 129 seconds concatenation the bad way to 67 so both methods still",
    "start": "1856299",
    "end": "1864220"
  },
  {
    "text": "slower than I can possibly measure from running the code once on my machine right and string builder actually used",
    "start": "1864220",
    "end": "1870940"
  },
  {
    "text": "up more memory because there's a slide overhead to it so we looked at that code",
    "start": "1870940",
    "end": "1876490"
  },
  {
    "text": "well how often does this run well it turns out that runs here once on page loads and it's a single page app we just",
    "start": "1876490",
    "end": "1883450"
  },
  {
    "text": "left it it's fine but if you're combining three two Meg strings well the",
    "start": "1883450",
    "end": "1890620"
  },
  {
    "text": "speed is the same I mean it's not the same it's obviously a lot slower but you know proportionally they're the same but",
    "start": "1890620",
    "end": "1896110"
  },
  {
    "text": "now stringbuilder uses less memory because now the overhead of stringbuilder is being swallowed up by",
    "start": "1896110",
    "end": "1902050"
  },
  {
    "text": "the extra work incantation does so you need to know what you're dealing with if you're on a I mean I don't care about",
    "start": "1902050",
    "end": "1908080"
  },
  {
    "text": "213 bytes very often but if I was you know writing code for a Raspberry Pi maybe I would where I was entering a",
    "start": "1908080",
    "end": "1914230"
  },
  {
    "text": "640k competition or something so you got to know what you want to do what a slow mean and what is what is to slow mean",
    "start": "1914230",
    "end": "1920770"
  },
  {
    "text": "what's more important let's look at some more examples dictionaries who likes to trace a very",
    "start": "1920770",
    "end": "1928480"
  },
  {
    "start": "1922000",
    "end": "1967000"
  },
  {
    "text": "common coding standards thing and an argument I've had because I personally",
    "start": "1928480",
    "end": "1933550"
  },
  {
    "text": "don't agree with it is you should always code two interfaces and I like coding to concrete classes but we can discuss that",
    "start": "1933550",
    "end": "1938800"
  },
  {
    "text": "later so here's a benchmark this one's really simple creates one",
    "start": "1938800",
    "end": "1944230"
  },
  {
    "text": "dictionary and then stores it in a field as a dictionary and stores a reference",
    "start": "1944230",
    "end": "1949900"
  },
  {
    "text": "to it in another field as an ayah dictionary never adds anything to the dictionary these are empty decrees and",
    "start": "1949900",
    "end": "1955210"
  },
  {
    "text": "then the benchmarks they loop through them which is that they're empty so not very long and return the dictionary just",
    "start": "1955210",
    "end": "1961090"
  },
  {
    "text": "again to anchor that code so the compiler doesn't remove it so there's almost nothing going on here right if",
    "start": "1961090",
    "end": "1968050"
  },
  {
    "start": "1967000",
    "end": "2069000"
  },
  {
    "text": "you use a dictionary it is twice as fast as using an auditory and it allocates no memory whatsoever and an idea always",
    "start": "1968050",
    "end": "1976000"
  },
  {
    "text": "allocates memory and if there actually was something in the dictionary then this times would slowly very slowly",
    "start": "1976000",
    "end": "1982530"
  },
  {
    "text": "separate so even coding standards you",
    "start": "1982530",
    "end": "1988540"
  },
  {
    "text": "may want to question now this one you'd only do if it was absolutely critical because this is pretty Marshall but you",
    "start": "1988540",
    "end": "1996010"
  },
  {
    "text": "know question your assumptions I think the people you would be hard-pressed to find someone who if you had an interview",
    "start": "1996010",
    "end": "2002340"
  },
  {
    "text": "question said what's the difference for a dictionary dictionary you probably wouldn't think well one performs better",
    "start": "2002340",
    "end": "2007380"
  },
  {
    "text": "right but you kind of got to be open to any possibility when you actually measure you might find something interesting",
    "start": "2007380",
    "end": "2014390"
  },
  {
    "text": "does anyone know what's going on I'll top the head yes exactly boxing so a",
    "start": "2014390",
    "end": "2020880"
  },
  {
    "text": "dictionaries enumerator is a struct so when a for each loop calls getting a numerator that returns a",
    "start": "2020880",
    "end": "2027210"
  },
  {
    "text": "struct when you're using a concrete type the compiler you know knows that it's a",
    "start": "2027210",
    "end": "2032400"
  },
  {
    "text": "struct and the runtime carries that through the whole way as soon as you go to interface everything's out the window and it's",
    "start": "2032400",
    "end": "2038550"
  },
  {
    "text": "always boxed so the memory overhead is for boxing that struct so 32 bytes is",
    "start": "2038550",
    "end": "2043860"
  },
  {
    "text": "the object and then the time overhead is the time for boxing but also every call",
    "start": "2043860",
    "end": "2049260"
  },
  {
    "text": "is then a virtual call instead of a call and it's going to worry about inheritance and there's null checks etc",
    "start": "2049260",
    "end": "2054270"
  },
  {
    "text": "so the dictionary class uses a struct as its enumerator for speed reasons and for",
    "start": "2054270",
    "end": "2061648"
  },
  {
    "text": "memory reasons and if you then use an idea nary you're just throwing them away so yeah be aware of what's going on",
    "start": "2061649",
    "end": "2069500"
  },
  {
    "start": "2069000",
    "end": "2149000"
  },
  {
    "text": "loops versus link this is a good one I've already told you the answer this one because I said I'm old and I like",
    "start": "2069500",
    "end": "2074730"
  },
  {
    "text": "loops not that I don't like link I actually wrote a link provider I love link has its place okay so we have an",
    "start": "2074730",
    "end": "2082320"
  },
  {
    "text": "array we have ten things in our array and moving through looking for item number five so a simple for loop and a",
    "start": "2082320",
    "end": "2090770"
  },
  {
    "text": "link call well link extension method using first or default and passing the",
    "start": "2090770",
    "end": "2095790"
  },
  {
    "text": "net predicate versus using where with the predicate and then a first-order fuck-all this one is interesting just",
    "start": "2095790",
    "end": "2104610"
  },
  {
    "text": "because I mean obviously the loops gonna win I think we kind of all know that like it's closer to the middle but the",
    "start": "2104610",
    "end": "2110460"
  },
  {
    "text": "difference between the two link methods I find interesting and this is another",
    "start": "2110460",
    "end": "2116220"
  },
  {
    "text": "one where we're allocating an enumerator because the where method doesn't do anything right it's deferred execution",
    "start": "2116220",
    "end": "2121590"
  },
  {
    "text": "so it doesn't actually filter your collection until you call first or default which means it needs to return",
    "start": "2121590",
    "end": "2127020"
  },
  {
    "text": "an object that remembers what your filter was first or default with a predicate it just does the work so",
    "start": "2127020",
    "end": "2132900"
  },
  {
    "text": "there's a little bit of overhead for link there always is you've got lambda expressions in the mix but with the",
    "start": "2132900",
    "end": "2138330"
  },
  {
    "text": "we're case you've got an extra iterator the where iterator and then the for-loop is bare metal no",
    "start": "2138330",
    "end": "2144210"
  },
  {
    "text": "allocations super fast so this kind of goes back to question your assumptions",
    "start": "2144210",
    "end": "2149400"
  },
  {
    "start": "2149000",
    "end": "2225000"
  },
  {
    "text": "as well but the other thing here like link has other benefits it is always gonna be slower I'm it was a while ago",
    "start": "2149400",
    "end": "2156150"
  },
  {
    "text": "so my memory is a bit rusty but James Newton King tweeted out like a year ago",
    "start": "2156150",
    "end": "2161400"
  },
  {
    "text": "or a couple years ago he removed all the using statements for system got link",
    "start": "2161400",
    "end": "2166530"
  },
  {
    "text": "from Jason net and then he just went through methodically fixing the compilers and on whatever benchmark",
    "start": "2166530",
    "end": "2172740"
  },
  {
    "text": "years it ran it saved 19 Meg of RAM like there is an overhead to link but there's",
    "start": "2172740",
    "end": "2178319"
  },
  {
    "text": "heaps of benefits too so you've got to be aware of that and I think we kind of al are the other one with this example",
    "start": "2178319",
    "end": "2183660"
  },
  {
    "text": "is make sure your benchmarks are real because so that code was linked to",
    "start": "2183660",
    "end": "2188849"
  },
  {
    "text": "objects right I was limping looping through an array with entity framework or link to SQL where and first or",
    "start": "2188849",
    "end": "2195960"
  },
  {
    "text": "default they don't really do anything until they hit the database right so your results are going to be very",
    "start": "2195960",
    "end": "2202140"
  },
  {
    "text": "different for there'll be probably less difference between the two methods also",
    "start": "2202140",
    "end": "2207210"
  },
  {
    "text": "in that case your database call is going to be way slower than anything else you worry about but so make sure and this",
    "start": "2207210",
    "end": "2213000"
  },
  {
    "text": "makes it tougher but make sure if you are curious about this sort of thing you can't compare link to objects to",
    "start": "2213000",
    "end": "2218099"
  },
  {
    "text": "link to us the LINQ to SQL or entity framework you've got to write your benchmark in a pseudo real-world fashion",
    "start": "2218099",
    "end": "2223710"
  },
  {
    "text": "if you want to be able to use the numbers last little example substring",
    "start": "2223710",
    "end": "2229410"
  },
  {
    "start": "2225000",
    "end": "2296000"
  },
  {
    "text": "versus span so if you haven't heard span of T I think John Gallo I mentioned it",
    "start": "2229410",
    "end": "2235500"
  },
  {
    "text": "yesterday that for but it's a new part of a new set of types in system memory that allows it's basically access to the",
    "start": "2235500",
    "end": "2243539"
  },
  {
    "text": "underlying memory behind a string or an array and it's designed for performance and it's designed for memory so no",
    "start": "2243539",
    "end": "2249539"
  },
  {
    "text": "spoilers here but sorry it'll be faster so anyway we have we have this code so this is a very convoluted example",
    "start": "2249539",
    "end": "2256680"
  },
  {
    "text": "although I'm not sure whether it's more convoluted than looping through an empty dictionary but we essentially have a",
    "start": "2256680",
    "end": "2262079"
  },
  {
    "text": "string and then I'm slicing it or substring a number of times so we have our params operator again here and then",
    "start": "2262079",
    "end": "2270270"
  },
  {
    "text": "we're just passing it a number and I wrote this because this is sort of it's not a good example of",
    "start": "2270270",
    "end": "2275340"
  },
  {
    "text": "pausing library but it's sort of indicative of the types of work a sort of naive parsing library will do I know",
    "start": "2275340",
    "end": "2281340"
  },
  {
    "text": "because I've written a couple and I wish I still had the the IP to actually",
    "start": "2281340",
    "end": "2286410"
  },
  {
    "text": "change them because I'd love to test and see what that what span does to them but it's just a bunch of sub strings that's",
    "start": "2286410",
    "end": "2291960"
  },
  {
    "text": "what yeah that's what passes are a lot of the time so you'll notice there's two",
    "start": "2291960",
    "end": "2297750"
  },
  {
    "start": "2296000",
    "end": "2374000"
  },
  {
    "text": "graphs um so yeah this one's no surprise span is faster than substring because that's the whole point the interesting",
    "start": "2297750",
    "end": "2303600"
  },
  {
    "text": "thing here so on the Left we have the dot net framework and on the right we have net core so this is using benchmark",
    "start": "2303600",
    "end": "2309210"
  },
  {
    "text": "nets ability to run against multiple platforms which is great and so this gives you a bit of an insight into how",
    "start": "2309210",
    "end": "2315180"
  },
  {
    "text": "spam works as well and there's a couple of things here so question your assumption when doing one operation",
    "start": "2315180",
    "end": "2321690"
  },
  {
    "text": "somehow span is slower than a substring I have no idea I haven't looked into why that is I kind of love to know I really",
    "start": "2321690",
    "end": "2328410"
  },
  {
    "text": "should but from then on span wins fun but if you look span is allocating",
    "start": "2328410",
    "end": "2334080"
  },
  {
    "text": "some memory for each time it runs less memory each time which is again",
    "start": "2334080",
    "end": "2339270"
  },
  {
    "text": "interesting but in.net core span doesn't allocate any data so in dotnet cord this is 2.1 they have done",
    "start": "2339270",
    "end": "2347130"
  },
  {
    "text": "work to the framework so they make these new things even faster than before so they're still better in the full",
    "start": "2347130",
    "end": "2353820"
  },
  {
    "text": "framework but they're better than better in dotnet core and then like each of the",
    "start": "2353820",
    "end": "2360510"
  },
  {
    "text": "operations the the substring operations themselves get a bit fashioned on their",
    "start": "2360510",
    "end": "2365640"
  },
  {
    "text": "core that's the when doing ten there it it should be faster I'm not sure if that's an outlier but so the thing here",
    "start": "2365640",
    "end": "2373440"
  },
  {
    "text": "is just to think about you know again what are you running on one of the quirks of the environment and there's",
    "start": "2373440",
    "end": "2379950"
  },
  {
    "start": "2374000",
    "end": "2420000"
  },
  {
    "text": "been so much performance work done in dotnet core that for some types of code",
    "start": "2379950",
    "end": "2384990"
  },
  {
    "text": "if you can just move to donek core and do no other work you'll get enough of a speed boost that you don't need to worry",
    "start": "2384990",
    "end": "2391260"
  },
  {
    "text": "about your code yeah leverage the the performance work that Microsoft have done",
    "start": "2391260",
    "end": "2396450"
  },
  {
    "text": "they were about doing yourself and consider if maybe swapping out that framework component is either he's gonna",
    "start": "2396450",
    "end": "2402600"
  },
  {
    "text": "be a quicker wind the best way to improve the performance of any code",
    "start": "2402600",
    "end": "2408260"
  },
  {
    "text": "from any language or any runtime is to remove it right so if you can if you can swap out something you've written for",
    "start": "2408260",
    "end": "2414470"
  },
  {
    "text": "something that the framework is written or another component that could be a quicker win so you've got a think bigger",
    "start": "2414470",
    "end": "2419510"
  },
  {
    "text": "and so to bring it back to Donald Knuth",
    "start": "2419510",
    "end": "2425500"
  },
  {
    "start": "2420000",
    "end": "2541000"
  },
  {
    "text": "this is my example of the absolute perfect performance story and I think it",
    "start": "2425500",
    "end": "2431630"
  },
  {
    "text": "is the absolute epitome of what the whole quote of Donal it is this is from the dotnet framework source this is the",
    "start": "2431630",
    "end": "2439730"
  },
  {
    "text": "hybrid dictionary class which I'm assuming no one's used because it's very old it's before generics but what this",
    "start": "2439730",
    "end": "2446600"
  },
  {
    "text": "class does is it's a dictionary and it is a dictionary that changes its backing",
    "start": "2446600",
    "end": "2453440"
  },
  {
    "text": "store from either a list or a dictionary depending on which is more performant at",
    "start": "2453440",
    "end": "2458960"
  },
  {
    "text": "the time and the reason I love this is because if you said to me and probably all of you how you can you go and write",
    "start": "2458960",
    "end": "2465170"
  },
  {
    "text": "a class that changes its backing store between a list and diction depending on its more performant you were to meet my",
    "start": "2465170",
    "end": "2470270"
  },
  {
    "text": "mind immediately thinks like well maybe a neural network had time the ads then I keep a history of the last five and I'd",
    "start": "2470270",
    "end": "2476630"
  },
  {
    "text": "swap them but it not nine nine see answer so what they did was forget",
    "start": "2476630",
    "end": "2484730"
  },
  {
    "text": "complexity forget writing this complicated thing that hey look you know maybe one every now and again it would be better but way too complex what they",
    "start": "2484730",
    "end": "2492860"
  },
  {
    "text": "didn't do though was throw out performance they did exhaustive performance testing presumably using",
    "start": "2492860",
    "end": "2497890"
  },
  {
    "text": "real-world data that they know their customers use right and they worked out that if you use a list to store things",
    "start": "2497890",
    "end": "2504800"
  },
  {
    "text": "up until nine items and then you switch to a dictionary you get better performance right dictionaries are slow",
    "start": "2504800",
    "end": "2511160"
  },
  {
    "text": "to look through if you get back at collisions and things lists obviously don't do hashing right I love this",
    "start": "2511160",
    "end": "2517430"
  },
  {
    "text": "because I absolutely would have fallen for the trap I would have written the most complicated code it would have been terrible I mean I would've been fun but",
    "start": "2517430",
    "end": "2524000"
  },
  {
    "text": "it would have been terrible and not 9 it also reminds me that Dilbert comment you know like the random number generator so",
    "start": "2524000",
    "end": "2530870"
  },
  {
    "text": "to me this is the epitome this is what you want to get you want to solve a complex problem in a simple way if you",
    "start": "2530870",
    "end": "2536870"
  },
  {
    "text": "can but by being conscious of performance and not by shying away from it so in summary should you always use the",
    "start": "2536870",
    "end": "2545280"
  },
  {
    "start": "2541000",
    "end": "2601000"
  },
  {
    "text": "diction instead rely dictionary I mean I think so but that's just I will have that debate later if anyone's game",
    "start": "2545280",
    "end": "2550700"
  },
  {
    "text": "should you use trucks instead of any of these no absolutely no never don't ever do anything always it always",
    "start": "2550700",
    "end": "2557579"
  },
  {
    "text": "depends right every individual thing you do as a programmer is a new decision the",
    "start": "2557579",
    "end": "2564960"
  },
  {
    "text": "coding standards one you know that's maybe debatable but still I think coding stands you know don't be afraid to",
    "start": "2564960",
    "end": "2570240"
  },
  {
    "text": "question there should be a living document you need to think about every scenario developers who want to be you",
    "start": "2570240",
    "end": "2577349"
  },
  {
    "text": "know want to use the coding standards as a reference guide for how do I solve this problem I think they'll always be limited in",
    "start": "2577349",
    "end": "2582450"
  },
  {
    "text": "their career prospects right you want to be the type of developer that works out hey there's a few different ways I could",
    "start": "2582450",
    "end": "2588000"
  },
  {
    "text": "do this let me work out what the best way is or let me talk to other people about what the best way is so always be",
    "start": "2588000",
    "end": "2594930"
  },
  {
    "text": "thinking about all of these factors thank you",
    "start": "2594930",
    "end": "2600480"
  },
  {
    "text": "[Applause]",
    "start": "2600480",
    "end": "2603090"
  }
]
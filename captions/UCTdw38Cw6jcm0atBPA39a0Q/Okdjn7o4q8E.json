[
  {
    "text": "all right it is three uh three o'clock and 59 seconds so I'm gonna get started",
    "start": "3240",
    "end": "8580"
  },
  {
    "text": "uh welcome to my talk I like to call this talk count men sketch to Infinity using probabilistic data structures to",
    "start": "8580",
    "end": "15059"
  },
  {
    "text": "solve counting problems in.net um quick pull of the room",
    "start": "15059",
    "end": "20340"
  },
  {
    "text": "who here has heard of Radice before okay so ninety percent of the audience",
    "start": "20340",
    "end": "26760"
  },
  {
    "text": "has heard of redis uh who here has used redis before 80 so we we only lost about 10 of the",
    "start": "26760",
    "end": "34440"
  },
  {
    "text": "audience who here has used redis for anything more than just a cash",
    "start": "34440",
    "end": "39980"
  },
  {
    "text": "uh we have like five hands which is actually Four more hands than I thought I would have seen",
    "start": "40440",
    "end": "45899"
  },
  {
    "text": "so uh for those of you who don't know me my name is Steve lorello and I am a",
    "start": "45899",
    "end": "51660"
  },
  {
    "text": "developer Advocate at redis and specifically on the.net developer Advocate and a lot of my work sort of",
    "start": "51660",
    "end": "57960"
  },
  {
    "text": "sits at the intersection between uh dot net development and redis in this talk",
    "start": "57960",
    "end": "63239"
  },
  {
    "text": "in particular gets to scratch a couple of those really neat zones in in my",
    "start": "63239",
    "end": "68580"
  },
  {
    "text": "computer science brain because we get to talk a little bit about algorithms we get to talk a little bit about.net and",
    "start": "68580",
    "end": "74820"
  },
  {
    "text": "we get to talk talk a bit about redis so this is a lot of this is actually a really fun talk for me",
    "start": "74820",
    "end": "81000"
  },
  {
    "text": "um for those of you who are interested in following me you can follow me on Twitter at s larello you could also",
    "start": "81000",
    "end": "86759"
  },
  {
    "text": "follow me on GitHub at slower89 and me and the members of my team we",
    "start": "86759",
    "end": "92280"
  },
  {
    "text": "have a tendency to stream pretty much weekly you can find us at twitch.tv forward slash redis Inc",
    "start": "92280",
    "end": "99600"
  },
  {
    "text": "the repo and also the slides for this talk are all available in GitHub so if you have a phone you want to take a",
    "start": "99600",
    "end": "106140"
  },
  {
    "text": "picture you want to come check out the code it's right here it's right under my username though so if you found me on on",
    "start": "106140",
    "end": "112860"
  },
  {
    "text": "GitHub it's right there it's called probabilistic data structures so before I give a talk I usually like",
    "start": "112860",
    "end": "118860"
  },
  {
    "text": "to go over a little bit of an agenda of what I'm going to be talking about that day so",
    "start": "118860",
    "end": "124759"
  },
  {
    "text": "this talk you know actually another poll question who here has heard of a probabilistic data structure",
    "start": "124759",
    "end": "130920"
  },
  {
    "text": "okay so now we're down to about 15 I'd say 20 of the audience so I guess we got",
    "start": "130920",
    "end": "136440"
  },
  {
    "text": "to ask answer the question first what is a probabilistic data structure and it's actually a really interesting set of",
    "start": "136440",
    "end": "142260"
  },
  {
    "text": "data structures that we're going to talk about today then we're going to go over a brief history of probabilistic data structures",
    "start": "142260",
    "end": "149160"
  },
  {
    "text": "within the context of redis now redis is one of those things that's a memory first database that's known for being",
    "start": "149160",
    "end": "155760"
  },
  {
    "text": "very performance sensitive and very very performant and these data structures",
    "start": "155760",
    "end": "160920"
  },
  {
    "text": "really slot in nicely to the to the lifeblood of redis and make and really",
    "start": "160920",
    "end": "167099"
  },
  {
    "text": "fit nicely with redis then we're going to be talking about set membership problems so we're going to",
    "start": "167099",
    "end": "172319"
  },
  {
    "text": "get into some of the different problems that we can solve with these probabilistic data structures the first of these is set membership and",
    "start": "172319",
    "end": "177900"
  },
  {
    "text": "we're going to be using Bloom filters to overcome those then we're going to be talking about counting problems and specifically",
    "start": "177900",
    "end": "183840"
  },
  {
    "text": "counting instances and large streams of data and we're going to be using the count Min sketch to uh to execute and",
    "start": "183840",
    "end": "191340"
  },
  {
    "text": "count those problems and count those streams of data then we're going to look at cardinality problems and we're going",
    "start": "191340",
    "end": "197040"
  },
  {
    "text": "to use you know one of my favorite of these data structures one of my favorite just because it's so neat",
    "start": "197040",
    "end": "202500"
  },
  {
    "text": "um and it's really difficult to explain so I'm going to do my best a little bit later but it's called the hyperlog log",
    "start": "202500",
    "end": "208860"
  },
  {
    "text": "and then we'll be looking at heavy hitter problems and we're going to be looking at the heavy keeper data structure and the algorithms surrounding",
    "start": "208860",
    "end": "214500"
  },
  {
    "text": "that and using all of that and of course um I have a little demo app that we're",
    "start": "214500",
    "end": "219840"
  },
  {
    "text": "going to run and we're going to compare uh the use of these data structures in redis against some more naive approaches",
    "start": "219840",
    "end": "226799"
  },
  {
    "text": "that you might think to use if you were just approaching these problems from the beginning",
    "start": "226799",
    "end": "232500"
  },
  {
    "text": "so what are probabilistic data structures like like we saw about 10 to 15 percent of the people in here had",
    "start": "232500",
    "end": "238920"
  },
  {
    "text": "heard of a probabilistic data structure before a problem probabilistic data structure though is a highly specialized",
    "start": "238920",
    "end": "244980"
  },
  {
    "text": "data structure that usually answers a very specific problem and answers a very specific question about the data that",
    "start": "244980",
    "end": "250980"
  },
  {
    "text": "we're encountering we use probability to approximate an answer to whatever the",
    "start": "250980",
    "end": "256260"
  },
  {
    "text": "question that we're asking is you notice that just earlier in the agenda slide I talked about four different questions",
    "start": "256260",
    "end": "261840"
  },
  {
    "text": "that we might want to ask in each of one of these comes up with an approximation for that answer and we usually trade off",
    "start": "261840",
    "end": "268740"
  },
  {
    "text": "some bit of perform some bit of accuracy for",
    "start": "268740",
    "end": "274620"
  },
  {
    "text": "exponential increases in performance here's some examples of some",
    "start": "274620",
    "end": "279660"
  },
  {
    "text": "probabilistic data structures four of which we're going to see in this talk some of which we won't we won't talk about are quotient filters skip lists",
    "start": "279660",
    "end": "286520"
  },
  {
    "text": "cocoa filters these are all different data structures that exist out there in",
    "start": "286520",
    "end": "292020"
  },
  {
    "text": "the ecosystem that you can use they all have some problem that they",
    "start": "292020",
    "end": "297900"
  },
  {
    "text": "answer some problem that they solve they have some optimization and they usually have some trade-off and that trade-off",
    "start": "297900",
    "end": "303720"
  },
  {
    "text": "is almost some small bit of accuracy it's usually in the one to two half a",
    "start": "303720",
    "end": "308940"
  },
  {
    "text": "percent to two percent range so let's just talk briefly about the",
    "start": "308940",
    "end": "314639"
  },
  {
    "text": "history of probabilistic data structures within redis now this logo right here is actually the logo for Reddit stack which",
    "start": "314639",
    "end": "321720"
  },
  {
    "text": "is sort of the conglomeration of uh or the Pinnacle so far of probabilistic",
    "start": "321720",
    "end": "328199"
  },
  {
    "text": "data structures Within redis so probabilistic data structures in OSS",
    "start": "328199",
    "end": "334560"
  },
  {
    "text": "redis so the vanilla version of redis that you just pulled from Docker or you build from Source in a github.com redis",
    "start": "334560",
    "end": "341880"
  },
  {
    "text": "repository sort of piqued the interest of Salvatore",
    "start": "341880",
    "end": "347520"
  },
  {
    "text": "who is the author of redis the original writer of redis as well as the community and he decided to implement well so so",
    "start": "347520",
    "end": "355740"
  },
  {
    "text": "redis was always this memory first database so memory first in that all of",
    "start": "355740",
    "end": "361800"
  },
  {
    "text": "the stuff that goes into redis always goes into memory first redis is almost always available in memory unless you're",
    "start": "361800",
    "end": "367500"
  },
  {
    "text": "using reticent flash but it's just memory first construct that's always also been performance first we've always",
    "start": "367500",
    "end": "373139"
  },
  {
    "text": "put a huge critical interest on performance and because of this and",
    "start": "373139",
    "end": "378720"
  },
  {
    "text": "you'll see why in a little bit when I actually go over these data structures Salvatore decided to add the hyper log",
    "start": "378720",
    "end": "384539"
  },
  {
    "text": "log which is the third one of these data structures we'll talk about in version 2.8.9 about eight years ago in 2014.",
    "start": "384539",
    "end": "393840"
  },
  {
    "text": "then we enter this new era of redis development and redis usage called the",
    "start": "393840",
    "end": "399240"
  },
  {
    "text": "module API era in version 4.0 which is you know five years ago in 2017 uh right",
    "start": "399240",
    "end": "406259"
  },
  {
    "text": "the oss reticence the OSS redis Source added what's called a module API the",
    "start": "406259",
    "end": "412080"
  },
  {
    "text": "module API is something that's not novel to redis but exists otherwear elsewhere",
    "start": "412080",
    "end": "417180"
  },
  {
    "text": "in the ecosystem but what it is basically it allows system level developers to develop against redis and",
    "start": "417180",
    "end": "423479"
  },
  {
    "text": "do stuff like extend redis develop new data structures against redis and add custom commands",
    "start": "423479",
    "end": "430440"
  },
  {
    "text": "for redis and then my our company redis Inc started to introduce some of its own",
    "start": "430440",
    "end": "436620"
  },
  {
    "text": "modules and one of the first ones we introduced was redisbloom which was added in which was created in 2017 and",
    "start": "436620",
    "end": "444419"
  },
  {
    "text": "adds the first of the new expanded set of these probabilistic data structures to it bloom",
    "start": "444419",
    "end": "451680"
  },
  {
    "text": "for which it's named and then we license that under the redis",
    "start": "451680",
    "end": "456780"
  },
  {
    "text": "source available license which I don't want to get too deep into the legal details here but basically what it means",
    "start": "456780",
    "end": "463020"
  },
  {
    "text": "is you can use it for free just don't compete against us and if you need to buy it you got to buy it from us is",
    "start": "463020",
    "end": "468900"
  },
  {
    "text": "essentially what it comes down to but you can pull this in and use it in your application to build it for free",
    "start": "468900",
    "end": "474360"
  },
  {
    "text": "and this and then in 2019 we added the top K and the countman sketch which are",
    "start": "474360",
    "end": "479880"
  },
  {
    "text": "two of the uh two of the other data structures that we'll be talking about and then we in 2022 this year we have",
    "start": "479880",
    "end": "488340"
  },
  {
    "text": "just Consolidated all of our modules all the disparate modules of redis into one thing called redistack which you can",
    "start": "488340",
    "end": "495300"
  },
  {
    "text": "just pull from Docker and use you can build from Source you can install on your Mac you can install from at",
    "start": "495300",
    "end": "502259"
  },
  {
    "text": "um it's just this new mode of interacting with redis where we actually allow folks to bring in all of",
    "start": "502259",
    "end": "507960"
  },
  {
    "text": "these different disparate modules and use them so let's talk first about set membership",
    "start": "507960",
    "end": "515399"
  },
  {
    "text": "so set membership referring to membership within um a mathematical set basically and not",
    "start": "515399",
    "end": "522659"
  },
  {
    "text": "a mathematical setting that it all it all contains numbers but the concept of a unordered no non-duplicated set of",
    "start": "522659",
    "end": "532320"
  },
  {
    "text": "items that we can operate against so the question that we need to add we are",
    "start": "532320",
    "end": "537959"
  },
  {
    "text": "asking here the very specific question is has a member been inserted into the set yet so it has a given element been",
    "start": "537959",
    "end": "544800"
  },
  {
    "text": "inserted yet so for example say you have this is a very common question that we we ask has",
    "start": "544800",
    "end": "550920"
  },
  {
    "text": "a username been registered yet with um with our service",
    "start": "550920",
    "end": "556800"
  },
  {
    "text": "so let's think about some ways that we might approach this problem from a naive approach",
    "start": "556800",
    "end": "562200"
  },
  {
    "text": "um so we just naively want to say we're going to store all of our user information in our SQL database",
    "start": "562200",
    "end": "568920"
  },
  {
    "text": "and then we're going to run something like this you've probably seen something like this in the past a select count star from users where username equals",
    "start": "568920",
    "end": "576480"
  },
  {
    "text": "selected username or you could even do a select one and you just pull back if it counts or the username that or the user",
    "start": "576480",
    "end": "583860"
  },
  {
    "text": "that matches this and you determine that oh that username has been added now",
    "start": "583860",
    "end": "590760"
  },
  {
    "text": "this is not really an issue if you have a small relatively small set of users but when you when you blow up to very",
    "start": "590760",
    "end": "596040"
  },
  {
    "text": "large sets when you're interacting with very large sets it becomes kind of problematic let's look at the axis type",
    "start": "596040",
    "end": "602700"
  },
  {
    "text": "and the uh what is the time complexities of this operation real quick so the axis type is",
    "start": "602700",
    "end": "609180"
  },
  {
    "text": "usually disk I mean sometimes you'll have databases that are loaded completely into memory and you don't",
    "start": "609180",
    "end": "614700"
  },
  {
    "text": "necessarily necessarily need to access them ask access the disk but for the most part you're usually probably",
    "start": "614700",
    "end": "620100"
  },
  {
    "text": "talking to your disk and then you look up time on this is order end because you have to scan through all of the records",
    "start": "620100",
    "end": "626339"
  },
  {
    "text": "that are in your database and look at each of them to um essentially determine whether that",
    "start": "626339",
    "end": "632580"
  },
  {
    "text": "username has been added yet the good news though is that Beyond storing your username you don't actually have to do",
    "start": "632580",
    "end": "638399"
  },
  {
    "text": "anything else you don't actually have to store anything else you're not storing any extra information other than just",
    "start": "638399",
    "end": "644040"
  },
  {
    "text": "the users that you're actually inserting into your database so that that bit that extra space is order one",
    "start": "644040",
    "end": "650940"
  },
  {
    "text": "so now let's try to tweak this a little bit let's try to make it a little bit faster right so you might you might have run",
    "start": "650940",
    "end": "657480"
  },
  {
    "text": "into a case where oh no this is actually taking a while because we have to scan over all of our users well the next",
    "start": "657480",
    "end": "663600"
  },
  {
    "text": "thing you probably do is you would add an index on top of your your users table right so you would just index that",
    "start": "663600",
    "end": "669959"
  },
  {
    "text": "username within that users table and then you query it again all right great so this is you would run the same query",
    "start": "669959",
    "end": "676260"
  },
  {
    "text": "and then of course we're running into we run into an interesting problem right so",
    "start": "676260",
    "end": "681779"
  },
  {
    "text": "your access is still disk based right but now look at your lookup time your lookup time is now order login so that's",
    "start": "681779",
    "end": "688260"
  },
  {
    "text": "way faster right or to log n is um next to constant essentially in time",
    "start": "688260",
    "end": "694019"
  },
  {
    "text": "complexity when we're talking about uh when we're discussing time complexity of algorithms usually if you get something",
    "start": "694019",
    "end": "699959"
  },
  {
    "text": "down to log in it's usually pretty much good enough uh with some rare exceptions",
    "start": "699959",
    "end": "706500"
  },
  {
    "text": "unless you're talking about very large numbers but the big issue is that now we're running into this problem where oh we",
    "start": "706500",
    "end": "714000"
  },
  {
    "text": "have to store all of our users names and in this other index to um",
    "start": "714000",
    "end": "719339"
  },
  {
    "text": "to we have to store all of our usernames in this other index in order to do this right in order to construct maybe like",
    "start": "719339",
    "end": "724980"
  },
  {
    "text": "the symbol B tree index or something like that so the space complexity of this is not pretty vast and when you're",
    "start": "724980",
    "end": "730740"
  },
  {
    "text": "talking about you know billions of Records you're talking about you know many gigabytes of data that you have to",
    "start": "730740",
    "end": "736019"
  },
  {
    "text": "store uh you have to store and then you're probably accessing them through the disk because many gigabytes of data",
    "start": "736019",
    "end": "741779"
  },
  {
    "text": "you don't necessarily want to store uh readily in memory so now let's look at a the same presence",
    "start": "741779",
    "end": "748860"
  },
  {
    "text": "problem but using redis and using a in this a similar naive approach with redis",
    "start": "748860",
    "end": "754800"
  },
  {
    "text": "you can store uh usernames in a redis cache or more specifically you might use",
    "start": "754800",
    "end": "760620"
  },
  {
    "text": "one of the other more sophisticated data structures within redis for example a set so you would use the loneliest of",
    "start": "760620",
    "end": "768000"
  },
  {
    "text": "redis commands which is the sad command to add to the usernames set the selected",
    "start": "768000",
    "end": "774899"
  },
  {
    "text": "username that you want to look up that you want to add to it and then in order to query it you would just use",
    "start": "774899",
    "end": "782940"
  },
  {
    "text": "as his members s's members usernames selected username",
    "start": "782940",
    "end": "788519"
  },
  {
    "text": "and this is actually real fast now so you no longer have to ever go to the desk",
    "start": "788519",
    "end": "794040"
  },
  {
    "text": "your lookup time is order one but now we're still running into this",
    "start": "794040",
    "end": "799680"
  },
  {
    "text": "problem where the thing that we have in debt we've essentially indexed is now all stored in memory and we've taken",
    "start": "799680",
    "end": "807300"
  },
  {
    "text": "we're taking up this really vast amount of memory in order to store it",
    "start": "807300",
    "end": "812579"
  },
  {
    "text": "so enter Bloom filters and Bloom filters there are this really neat data structure there's",
    "start": "812579",
    "end": "819240"
  },
  {
    "text": "a specialized data probabilistic data structure for performing presence checks",
    "start": "819240",
    "end": "825899"
  },
  {
    "text": "a bloom filter allows you and this is actually where the probability and the trade-off comes in a bloom filter allows",
    "start": "825899",
    "end": "832079"
  },
  {
    "text": "you to definitively say whether an item has not been added to the bloom filter",
    "start": "832079",
    "end": "837600"
  },
  {
    "text": "yet however it can only probably say that an",
    "start": "837600",
    "end": "842760"
  },
  {
    "text": "item has been added and you'll see why as I go over an example of this",
    "start": "842760",
    "end": "848100"
  },
  {
    "text": "a bloom filter uses a scheme called a k hashes scheme which is basically you",
    "start": "848100",
    "end": "853260"
  },
  {
    "text": "have a group a succession of different hash functions that you run whatever the",
    "start": "853260",
    "end": "859800"
  },
  {
    "text": "information that you're inserting into the filter to get a single number the stipulation here is that those hash",
    "start": "859800",
    "end": "866940"
  },
  {
    "text": "functions have to be pretty random and uniformly distributed",
    "start": "866940",
    "end": "872339"
  },
  {
    "text": "over the entire Bloom filter in order for this to work correctly so all the hash functions you're using have to have",
    "start": "872339",
    "end": "878399"
  },
  {
    "text": "that Randomness and uniform distribution over the set that you're talking to",
    "start": "878399",
    "end": "883740"
  },
  {
    "text": "you can represent the uh a bloom filter is represented as a 1D array of bits",
    "start": "883740",
    "end": "890519"
  },
  {
    "text": "so just a one-dimensional array of bits all the operations that you run against it or order one complexity",
    "start": "890519",
    "end": "896940"
  },
  {
    "text": "um some people say that it's order K but K in this case is always constant so",
    "start": "896940",
    "end": "902339"
  },
  {
    "text": "um it's actually order one so it's a constant complexity and the space is actually still order n",
    "start": "902339",
    "end": "907920"
  },
  {
    "text": "but instead of being order n in the size of whatever the thing that you're using is",
    "start": "907920",
    "end": "913139"
  },
  {
    "text": "or whatever whatever all the data that you're inserting into is it's only order n in the saw in bits and usually you",
    "start": "913139",
    "end": "921720"
  },
  {
    "text": "essentially estimate the cardinality of your expected cardinality or size of",
    "start": "921720",
    "end": "927300"
  },
  {
    "text": "your set and you use between 7 and 12 bits per item that you think is going to be",
    "start": "927300",
    "end": "932940"
  },
  {
    "text": "inserted into it to insert an item into a bloom filter you basically you just go over all of",
    "start": "932940",
    "end": "939839"
  },
  {
    "text": "the hashes that you have and then you index into the filter at the result of that hash function for",
    "start": "939839",
    "end": "947639"
  },
  {
    "text": "that key that you're using and you flip that bit in that bloom filter to one",
    "start": "947639",
    "end": "953579"
  },
  {
    "text": "and then the query it you go over that whole filter again and if any of them are zero you report",
    "start": "953579",
    "end": "961500"
  },
  {
    "text": "that no the item has not been inserted into inserted into the bloom filter yet however if every one of them is set to",
    "start": "961500",
    "end": "969120"
  },
  {
    "text": "one every single one of them is set to one you return that yes the item has",
    "start": "969120",
    "end": "974339"
  },
  {
    "text": "been added to the bloom filter or probably has been added to the bloom filter to be more uh accurate so let's",
    "start": "974339",
    "end": "980040"
  },
  {
    "text": "look at the complexities of this um your space complexity like I said is still ordering but you're talking about",
    "start": "980040",
    "end": "986399"
  },
  {
    "text": "order n in the size of the set the actual size of the set not the items within the set and it's only measured in",
    "start": "986399",
    "end": "993480"
  },
  {
    "text": "bits your insertion times are order one your lookup times or order one",
    "start": "993480",
    "end": "999959"
  },
  {
    "text": "um and the other trade-off is that deletes are not available within Bloom filters",
    "start": "999959",
    "end": "1005360"
  },
  {
    "text": "so let's look at an example of a bloom filter so this is our Bloom filter where k",
    "start": "1005360",
    "end": "1011720"
  },
  {
    "text": "equals three and we have a bloom filter of size 10. now this is a tiny Bloom filter like I said you usually use seven",
    "start": "1011720",
    "end": "1018680"
  },
  {
    "text": "to twelve bits per item that you want to insert into it so you would only really want to store one item in here but for",
    "start": "1018680",
    "end": "1025938"
  },
  {
    "text": "our demonstration purposes is actually great because it's going to show us some uh it's actually going to show you an",
    "start": "1025939",
    "end": "1032178"
  },
  {
    "text": "underline for you what the um what the trade-off is here and how you can report false positives",
    "start": "1032179",
    "end": "1038058"
  },
  {
    "text": "so let's try to insert the username Razzle into this Bloom filter",
    "start": "1038059",
    "end": "1043459"
  },
  {
    "text": "so let's take the H1 arousal so the first hash functions result of frazzle that comes out to two so we take the bit",
    "start": "1043459",
    "end": "1050419"
  },
  {
    "text": "at bit two and we flip that to one we'll do the same thing for each two",
    "start": "1050419",
    "end": "1056720"
  },
  {
    "text": "that comes up five so we flip the bit at bit five to one",
    "start": "1056720",
    "end": "1062960"
  },
  {
    "text": "for H3 we do the same thing it comes out to eight so we flip the bit at bit eight to one",
    "start": "1062960",
    "end": "1068780"
  },
  {
    "text": "so now let's perform a query well H1 of fizzle which is our",
    "start": "1068780",
    "end": "1074900"
  },
  {
    "text": "next item our next username that we want to check is eight like we just saw H3 of",
    "start": "1074900",
    "end": "1080720"
  },
  {
    "text": "Razzle was eat so that one's already won okay so that's interesting we have a you",
    "start": "1080720",
    "end": "1087679"
  },
  {
    "text": "we have a username that we know we haven't inserted yet but we're seeing one here okay so so maybe maybe maybe",
    "start": "1087679",
    "end": "1093380"
  },
  {
    "text": "it's has been inserted so we take H2O fizzle and that's two",
    "start": "1093380",
    "end": "1098480"
  },
  {
    "text": "oh boy that one's one too isn't it well so maybe it's actually in there",
    "start": "1098480",
    "end": "1103820"
  },
  {
    "text": "but H4 comes out to uh or each three comes out to four and four you can see is zero and so that",
    "start": "1103820",
    "end": "1110120"
  },
  {
    "text": "zero comes out we see that it's not in there and we can say definitively that it hasn't been added in there",
    "start": "1110120",
    "end": "1115460"
  },
  {
    "text": "now the trick with these is that the instances of hash collisions are what",
    "start": "1115460",
    "end": "1121760"
  },
  {
    "text": "actually produces the uncertainty behind the false positives that can be reported by a bloom filter and you can actually",
    "start": "1121760",
    "end": "1129919"
  },
  {
    "text": "optimize these by optimizing K and optimizing the number of bits that you're using so",
    "start": "1129919",
    "end": "1136900"
  },
  {
    "text": "for false positives and tuning like I said this algorithm never gives you false false negatives but it can report",
    "start": "1136900",
    "end": "1143480"
  },
  {
    "text": "false positives and you can optimize the false positives when uh reserving the filter specifically and specifically in",
    "start": "1143480",
    "end": "1150559"
  },
  {
    "text": "redis so in redis we have three commands that you really need to need to be",
    "start": "1150559",
    "end": "1156320"
  },
  {
    "text": "interested in with BF Reserve which takes the error rate and a capacity",
    "start": "1156320",
    "end": "1162320"
  },
  {
    "text": "so you say oh I would like this Bloom filter to have a capacity for forty",
    "start": "1162320",
    "end": "1168620"
  },
  {
    "text": "thousand members and um the error rate that I'm willing to accept here is one percent and it'll",
    "start": "1168620",
    "end": "1174980"
  },
  {
    "text": "attune the bloom filter appropriately for your use case there's actually math behind this as",
    "start": "1174980",
    "end": "1181160"
  },
  {
    "text": "well there is a proof that was done for the original Bloom filter where basically you can optimize decay in the",
    "start": "1181160",
    "end": "1188720"
  },
  {
    "text": "optimal number of bits is like I said somewhere between 7 and 12 depending on what your uh what the size of your set",
    "start": "1188720",
    "end": "1194539"
  },
  {
    "text": "is um so real quick I'm actually going to drop out of my slides",
    "start": "1194539",
    "end": "1199640"
  },
  {
    "text": "and I'm going to show you in um the sample application that I linked",
    "start": "1199640",
    "end": "1205700"
  },
  {
    "text": "to before and I will link you to this again at the end of the um at the end of the presentation so for this sample I",
    "start": "1205700",
    "end": "1212600"
  },
  {
    "text": "took the book Moby Dick and I parsed out all the words from it well some approximation of that I didn't",
    "start": "1212600",
    "end": "1219320"
  },
  {
    "text": "wasn't super precise with it but I parsed out all the words from it I inserted them into a postgres table that",
    "start": "1219320",
    "end": "1225919"
  },
  {
    "text": "was not indexed a postgres table that is indexed I also inserted into a redis",
    "start": "1225919",
    "end": "1230960"
  },
  {
    "text": "sorted set which is a slightly more advanced data structure within the open source redis and I also inserted into",
    "start": "1230960",
    "end": "1237919"
  },
  {
    "text": "the four data structures that we're going to use throughout this uh throughout this talk",
    "start": "1237919",
    "end": "1244880"
  },
  {
    "text": "um in if you go into red is probabilistic",
    "start": "1244880",
    "end": "1250640"
  },
  {
    "text": "you will see the things that we use within right is to actually ex to actually do this so",
    "start": "1250640",
    "end": "1256220"
  },
  {
    "text": "the what I'll draw your attention to in redisbloom all of the all of the command names start with an abbreviation of",
    "start": "1256220",
    "end": "1263000"
  },
  {
    "text": "whatever the uh data structure is so in this case we have BF for redisbloom",
    "start": "1263000",
    "end": "1268460"
  },
  {
    "text": "right here we're calling BF dot Reserve we're passing in the name of the bloom",
    "start": "1268460",
    "end": "1274520"
  },
  {
    "text": "filter that we want to reserve and we're passing in the error rate which I'm saying is one percent so 0.01 and the",
    "start": "1274520",
    "end": "1281780"
  },
  {
    "text": "size of that day up the size of it so forty thousand the expected capacity of it which is 40",
    "start": "1281780",
    "end": "1287660"
  },
  {
    "text": "000. the other one I'm using here is bf.mad which adds multiple items to the bloom",
    "start": "1287660",
    "end": "1293720"
  },
  {
    "text": "filter bf.adjust adds one item bf.net will add many items",
    "start": "1293720",
    "end": "1300320"
  },
  {
    "text": "and then to query the bloom filter all you need to do is say bf.exists pass in",
    "start": "1300320",
    "end": "1306080"
  },
  {
    "text": "your Bloom filters name and whatever the item is that you want to query and if",
    "start": "1306080",
    "end": "1311419"
  },
  {
    "text": "the bloom filter thinks that it's in there it'll report a one if it doesn't it'll report a zero",
    "start": "1311419",
    "end": "1317480"
  },
  {
    "text": "or if it knows that it's not it will report a zero and at the end this stunning um",
    "start": "1317480",
    "end": "1324320"
  },
  {
    "text": "conclusion of this I will run this application you will see just what the differences are and you'll actually see some of the error the some of the errors",
    "start": "1324320",
    "end": "1331640"
  },
  {
    "text": "that you'll see throughout throughout using these kinds of data structures hold on so let me just zip through these",
    "start": "1331640",
    "end": "1336919"
  },
  {
    "text": "slides again so the next one of these data the next one of these problems that we want to tackle are County problems and I'm not",
    "start": "1336919",
    "end": "1345080"
  },
  {
    "text": "saying all accounting problems here there's actually a topic called combinatorics which saw which just is",
    "start": "1345080",
    "end": "1351799"
  },
  {
    "text": "purely the study of County promising we're not going to solve all of those with uh redis Bloom but counting",
    "start": "1351799",
    "end": "1357740"
  },
  {
    "text": "problems in this in this particular case the county problem I'm referring to is how many times does an individual occur",
    "start": "1357740",
    "end": "1364400"
  },
  {
    "text": "in a large stream of data so this is actually a little bit facetious to say but this is easy to do on small",
    "start": "1364400",
    "end": "1371240"
  },
  {
    "text": "to mid-size sets of data but when you start encountering enormous data sets this becomes very difficult so think",
    "start": "1371240",
    "end": "1378140"
  },
  {
    "text": "something like this think um the number of views each video gets on YouTube what",
    "start": "1378140",
    "end": "1383480"
  },
  {
    "text": "are the problems with that well there's billions of videos that are I think there's billions of videos on YouTube and those videos can have",
    "start": "1383480",
    "end": "1390919"
  },
  {
    "text": "zero views to you know tens of billions of views so counting that problem",
    "start": "1390919",
    "end": "1396559"
  },
  {
    "text": "becomes very difficult because you don't want it well we'll get it to actually why that's a huge problem but anyway so",
    "start": "1396559",
    "end": "1402860"
  },
  {
    "text": "our first naive approach here is just to use a hash table right so if you're keeping a count of things and you want",
    "start": "1402860",
    "end": "1408200"
  },
  {
    "text": "to access them efficiently probably the first thing you think of is oh I'll just keep a hash table and just have the keys",
    "start": "1408200",
    "end": "1414559"
  },
  {
    "text": "mapped to counters and each one of those counters I can then store the record and increment it as I see new stuff so you",
    "start": "1414559",
    "end": "1422720"
  },
  {
    "text": "have a hash table of counters you look up the name and that hash table and increment uh in a set of storing a record you just increment it",
    "start": "1422720",
    "end": "1429980"
  },
  {
    "text": "um and then on query you just check whatever that integer is uh to see what the actual current count of that item is",
    "start": "1429980",
    "end": "1437780"
  },
  {
    "text": "the pro of this is that it's really straightforward uh we as developers are probably all used some form of",
    "start": "1437780",
    "end": "1444260"
  },
  {
    "text": "dictionary or hash set or something in our careers they're usually pretty",
    "start": "1444260",
    "end": "1449480"
  },
  {
    "text": "straightforward they're supported in most languages and you have guaranteed accuracy which is real nice",
    "start": "1449480",
    "end": "1455539"
  },
  {
    "text": "the cons though is that the space complexity of this is really problematic so you have an order and space complexity where n is the number of",
    "start": "1455539",
    "end": "1462200"
  },
  {
    "text": "items that you're trying to count right and this scale is pretty poorly I think",
    "start": "1462200",
    "end": "1467419"
  },
  {
    "text": "billions of Records let's look at another naive approach for this so say UE store all of our views in",
    "start": "1467419",
    "end": "1475159"
  },
  {
    "text": "a table in a SQL database for example and then we issue a query to a traditional relational database to",
    "start": "1475159",
    "end": "1481700"
  },
  {
    "text": "search an account of all those records so for example select count star from views where name equals Gangnam",
    "start": "1481700",
    "end": "1488240"
  },
  {
    "text": "Style this is really Pro this is actually really a problematic query and the reason it's problematic is because you",
    "start": "1488240",
    "end": "1494840"
  },
  {
    "text": "have to scan through the entire database check them even if it's indexed and then count them all up so this is a linear",
    "start": "1494840",
    "end": "1502039"
  },
  {
    "text": "time complexity operation and a linear space complexity uh and it's also a linear space complexity because you have",
    "start": "1502039",
    "end": "1507740"
  },
  {
    "text": "to store all the views and Views are usually one of those ephemeral things which you really might not care to store right it's like oh this is probably",
    "start": "1507740",
    "end": "1514460"
  },
  {
    "text": "Superfluous data that I don't I don't want to use and it's not just things with like video views also it's a lot of",
    "start": "1514460",
    "end": "1520400"
  },
  {
    "text": "stuff in networking you don't necessarily want to store everything a lot of network communication applications have problems with this so",
    "start": "1520400",
    "end": "1526580"
  },
  {
    "text": "this is usually like a not the way to go not the way to go for this so that brings us to the countman sketch",
    "start": "1526580",
    "end": "1533059"
  },
  {
    "text": "which is actually this which is the second one of these data structures these probabilistic data structures we're going to talk about this is a",
    "start": "1533059",
    "end": "1538820"
  },
  {
    "text": "specialized data structure for solving this exact problem keeping counts on very large streams of data",
    "start": "1538820",
    "end": "1545840"
  },
  {
    "text": "similar to bloom filters and concept they use this multi-hash record but instead of keeping a 1D array of bits we",
    "start": "1545840",
    "end": "1552740"
  },
  {
    "text": "have a two-dimensional array of counters now the cool thing about these countman sketches at the is that they are",
    "start": "1552740",
    "end": "1559580"
  },
  {
    "text": "sublinear and space complexity and you can even make them constant",
    "start": "1559580",
    "end": "1565299"
  },
  {
    "text": "uh with the time with constant time complexities for all the operations that you want to use",
    "start": "1565580",
    "end": "1571159"
  },
  {
    "text": "this never underestimates uh this never undercounts anything but it does sometimes over count and you'll see",
    "start": "1571159",
    "end": "1576860"
  },
  {
    "text": "you'll see why in a bit and it's similar to the reason that we could have false positives in a bloom filter",
    "start": "1576860",
    "end": "1582919"
  },
  {
    "text": "so to increment an item this looks just like the last thing we were doing right we go from I to K where K is the number",
    "start": "1582919",
    "end": "1590120"
  },
  {
    "text": "of hashes that we have and then in the in our counter table at that I",
    "start": "1590120",
    "end": "1596840"
  },
  {
    "text": "or at that hashes um what is it result",
    "start": "1596840",
    "end": "1602240"
  },
  {
    "text": "at I we just increment the counter and then to query it we just minimize",
    "start": "1602240",
    "end": "1607880"
  },
  {
    "text": "over that whole set of things so we we do the same thing we take the hash of the item that we want to check",
    "start": "1607880",
    "end": "1614600"
  },
  {
    "text": "we go through each of our rows and we take whatever that minimum value is and we report that minimum value as the",
    "start": "1614600",
    "end": "1621080"
  },
  {
    "text": "result of our cap as a result of our query operation so let's take a look at a video view",
    "start": "1621080",
    "end": "1627320"
  },
  {
    "text": "sketch so this we're going to answer the same question but we're going to use account bin sketch instead of a um",
    "start": "1627320",
    "end": "1634220"
  },
  {
    "text": "instead of a SQL relational table or a hash table for self answering the question so let's for example increment",
    "start": "1634220",
    "end": "1641419"
  },
  {
    "text": "Gangnam Style right so each one a Gangnam Style is zero so we're going to",
    "start": "1641419",
    "end": "1647360"
  },
  {
    "text": "just increment each one of zero to one H2 of Gangnam Style is four so we",
    "start": "1647360",
    "end": "1654620"
  },
  {
    "text": "increment h two four to one H3 is six so we increment H3 6 to 1.",
    "start": "1654620",
    "end": "1662360"
  },
  {
    "text": "now let's look at baby shark well baby shark is going to have a similar problem that that we saw in the last bit right",
    "start": "1662360",
    "end": "1668720"
  },
  {
    "text": "so each one of baby shark is zero each two is five H three is six so we go",
    "start": "1668720",
    "end": "1674480"
  },
  {
    "text": "through and we increment each of those but now let's try to query Gangnam Style",
    "start": "1674480",
    "end": "1680919"
  },
  {
    "text": "so each one of Gangnam Style is one again and we look and we see that the",
    "start": "1680919",
    "end": "1688400"
  },
  {
    "text": "value of H1 of one of zero is two",
    "start": "1688400",
    "end": "1694039"
  },
  {
    "text": "so we look we're looking at the minimum of two now H2 comes out two four and we",
    "start": "1694039",
    "end": "1699980"
  },
  {
    "text": "look and we see that H2 and 4 is 1 and then each three is six so three and six",
    "start": "1699980",
    "end": "1706100"
  },
  {
    "text": "is two so really the question that we're asking is what is the minimum of two one",
    "start": "1706100",
    "end": "1711380"
  },
  {
    "text": "and two and that's one right so we get the right answer at the end of this in",
    "start": "1711380",
    "end": "1716840"
  },
  {
    "text": "spite of the fact that we had hash collisions within this countman sketch again this is a intentionally tiny",
    "start": "1716840",
    "end": "1723320"
  },
  {
    "text": "accountment sketch for uh answering the questions that we're looking at so let's look at the complexities of",
    "start": "1723320",
    "end": "1729559"
  },
  {
    "text": "this the space complexity of this is sublinear right so if you have billions of Records you do not need to have",
    "start": "1729559",
    "end": "1735440"
  },
  {
    "text": "billions of cells within your accountment sketch your increment is order one your query is order one and",
    "start": "1735440",
    "end": "1741200"
  },
  {
    "text": "your delete operations again they're not available for the same reason as the bloom filters",
    "start": "1741200",
    "end": "1746720"
  },
  {
    "text": "uh Delete here would compromise the Integrity of the sketch so we don't expose delete operations",
    "start": "1746720",
    "end": "1754400"
  },
  {
    "text": "so the pro over CMS is that is it extremely fast it's super Compact and sublinear and it's a sub linear space",
    "start": "1754400",
    "end": "1761480"
  },
  {
    "text": "complexity and it's impossible to under count the pro the con of CMS though is that you can sometimes over count",
    "start": "1761480",
    "end": "1769100"
  },
  {
    "text": "so when would you want to use a common sketch the most appropriate times to use accountment sketch is when you have many",
    "start": "1769100",
    "end": "1775460"
  },
  {
    "text": "unique instances um that you need to count and when approximation for those instances is",
    "start": "1775460",
    "end": "1781940"
  },
  {
    "text": "fine so if anyone here works at a bank and",
    "start": "1781940",
    "end": "1787159"
  },
  {
    "text": "you would like to use accountment sketch to keep track of my bank my bank's uh my bank accounts",
    "start": "1787159",
    "end": "1792200"
  },
  {
    "text": "balance that's fine but you probably don't want to use this if you have something where approximation is not",
    "start": "1792200",
    "end": "1798679"
  },
  {
    "text": "okay and you need a really precise answer you need to think uh think about some other way to some other way to",
    "start": "1798679",
    "end": "1804080"
  },
  {
    "text": "accomplish that so the other the other",
    "start": "1804080",
    "end": "1809779"
  },
  {
    "text": "really useful case recountment sketch is when your data set is very skewed so think YouTube videos",
    "start": "1809779",
    "end": "1815600"
  },
  {
    "text": "um Gangnam Style and baby shark have billions of views for example and um you know my video on talking about",
    "start": "1815600",
    "end": "1822260"
  },
  {
    "text": "counting sketches probably only has a few dozen because sort of can be sort of a dry topic I",
    "start": "1822260",
    "end": "1828080"
  },
  {
    "text": "guess but um so just breaking real quick",
    "start": "1828080",
    "end": "1833899"
  },
  {
    "text": "um to go back to our code here if we go back to redis probabilistic in here",
    "start": "1833899",
    "end": "1839720"
  },
  {
    "text": "you have the two methods that are you're interested in for initializing and",
    "start": "1839720",
    "end": "1846340"
  },
  {
    "text": "incrementing your countman sketch are cms.init by prob is actually one way to",
    "start": "1846340",
    "end": "1853340"
  },
  {
    "text": "one way to initialize a sketch and init by prop you pass in the um",
    "start": "1853340",
    "end": "1859340"
  },
  {
    "text": "what is it desire error magnitude so as as a proportion of the whole set of the",
    "start": "1859340",
    "end": "1866059"
  },
  {
    "text": "cardinality the set the size of that set how much do you or how much error is acceptable to you and the other bit here",
    "start": "1866059",
    "end": "1873440"
  },
  {
    "text": "is what's the probability of your errors so I set both of those to 0.01 here there's also an init by dim where you",
    "start": "1873440",
    "end": "1880399"
  },
  {
    "text": "can explicitly tell it to initialize your accountment sketch by a width and a depth so that you can initialize it with",
    "start": "1880399",
    "end": "1887720"
  },
  {
    "text": "whatever exact parameters that you want to tune and you can tell it exactly how big you",
    "start": "1887720",
    "end": "1893059"
  },
  {
    "text": "want it to be and then to increment items within accountment sketch you would just use",
    "start": "1893059",
    "end": "1899000"
  },
  {
    "text": "the cms.inkerby and pass in the thing that you want to",
    "start": "1899000",
    "end": "1904760"
  },
  {
    "text": "increment as well as the increment that you want to use you'll see up here that I'm basically adding",
    "start": "1904760",
    "end": "1910520"
  },
  {
    "text": "um a list of two things uh the string that I want to increment and the amount that",
    "start": "1910520",
    "end": "1916880"
  },
  {
    "text": "I want to increment it by and then to query it all you need to do is call cms.query you pass in the cms's",
    "start": "1916880",
    "end": "1924260"
  },
  {
    "text": "name and the word that you want to query or the item that you want to query in",
    "start": "1924260",
    "end": "1930320"
  },
  {
    "text": "this case it's words because we talking about Moby Dick",
    "start": "1930320",
    "end": "1934960"
  },
  {
    "text": "so the next and most and one of the more interesting things to talk about here is set cardinality",
    "start": "1936200",
    "end": "1942740"
  },
  {
    "text": "so set cardinality is just counting the distinct elements inserted into a set so",
    "start": "1942740",
    "end": "1948620"
  },
  {
    "text": "what are all the unique elements that a set has again this is easier on smaller data",
    "start": "1948620",
    "end": "1954200"
  },
  {
    "text": "sets but for exact counts you have to keep track of every single item that you've",
    "start": "1954200",
    "end": "1960679"
  },
  {
    "text": "inserted into that set and the reason for that simple you want to insert something into the set and you want to",
    "start": "1960679",
    "end": "1966380"
  },
  {
    "text": "determine whether you need to increment the counter or not you need to know if the thing has already been added to the set",
    "start": "1966380",
    "end": "1971539"
  },
  {
    "text": "so this scales you know kind of poorly especially when you're talking about billions or trillions of instances",
    "start": "1971539",
    "end": "1979340"
  },
  {
    "text": "so let's think of this let's look at this naive approach to SQL and um I was actually talking to somebody yesterday",
    "start": "1979340",
    "end": "1985399"
  },
  {
    "text": "about this exact problem and I asked them how they would answer this question and this was actually the query they",
    "start": "1985399",
    "end": "1990559"
  },
  {
    "text": "regurgitated to me so select count distinct ID from a particular table so",
    "start": "1990559",
    "end": "1996500"
  },
  {
    "text": "from IDs or from views is this example here this is an incredibly slow operation",
    "start": "1996500",
    "end": "2002760"
  },
  {
    "text": "when the data set is unindexed you have to sort all of the data that's",
    "start": "2002760",
    "end": "2009220"
  },
  {
    "text": "in your that's in your SQL table and then you need to scan over all the data and count the individual instances of",
    "start": "2009220",
    "end": "2016000"
  },
  {
    "text": "that of each item or count each individual instance",
    "start": "2016000",
    "end": "2021220"
  },
  {
    "text": "so the complexity for this you're not storing anything beyond what you're already what you're already storing for",
    "start": "2021220",
    "end": "2026799"
  },
  {
    "text": "whatever the data is that you're storing right so we're saying that this has an order one uh space complexity",
    "start": "2026799",
    "end": "2033399"
  },
  {
    "text": "that's very I think that's actually kind of generous because a lot of these instances you wouldn't want to even store some of the stuff",
    "start": "2033399",
    "end": "2039279"
  },
  {
    "text": "um querying it like I said is in order n log n operation if n log n looks",
    "start": "2039279",
    "end": "2045159"
  },
  {
    "text": "familiar to anybody that's because that's usually how long it takes to sort something in the best case and that's",
    "start": "2045159",
    "end": "2050740"
  },
  {
    "text": "the overwhelming operation here is sorting the thing then you have to scan over it again so it's n log n to query",
    "start": "2050740",
    "end": "2056858"
  },
  {
    "text": "uh creating an undynext environment in an index environment so if you've created an index usually your data is",
    "start": "2056859",
    "end": "2063700"
  },
  {
    "text": "already sorted in some way so it's just an order and up it's an order n operation to query and indexed is um",
    "start": "2063700",
    "end": "2070960"
  },
  {
    "text": "order n or wait I'm sorry queries order n the space complexity for an index",
    "start": "2070960",
    "end": "2076358"
  },
  {
    "text": "operation is order n because you need to actually store everything again and then insertions take their constant they take",
    "start": "2076359",
    "end": "2082419"
  },
  {
    "text": "the same amount of time as they would otherwise so let's think of another another approach to this so let's talk about a",
    "start": "2082419",
    "end": "2088960"
  },
  {
    "text": "naive approach that you might use in redis so you can store all these values in a sorted set or set those are two",
    "start": "2088960",
    "end": "2096460"
  },
  {
    "text": "data structures that exist within redis they're kind of they've kind of been there since the beginning they're commonly used we talked about sets",
    "start": "2096460",
    "end": "2103060"
  },
  {
    "text": "earlier sorted sets are another one of those same things they're very similar and then you can just use the Z card or",
    "start": "2103060",
    "end": "2108820"
  },
  {
    "text": "the s-card operation just to check the cardinality of them car literally means",
    "start": "2108820",
    "end": "2114040"
  },
  {
    "text": "cardinality so Z card S card sorted set cardinality set cardinality and then",
    "start": "2114040",
    "end": "2119920"
  },
  {
    "text": "that's it but the problem is that the space complexity of this is order n so you",
    "start": "2119920",
    "end": "2126099"
  },
  {
    "text": "have to store all the things that you all your entire set in memory in order to perform one of these queries your",
    "start": "2126099",
    "end": "2132640"
  },
  {
    "text": "query is order one and then your insertion is either order log n or order one",
    "start": "2132640",
    "end": "2139300"
  },
  {
    "text": "depending on whether you're using a sorted set or a set sorted set it's login status order one",
    "start": "2139300",
    "end": "2147640"
  },
  {
    "text": "so let's talk about the hyperlog log which I think is actually the neatest of these um the neatest of these data",
    "start": "2147640",
    "end": "2154540"
  },
  {
    "text": "structures and actually was the first that was introduced to redis in the very",
    "start": "2154540",
    "end": "2159820"
  },
  {
    "text": "early days of probabilistic data structures relationship with redis the hyperolog log is a probabilistic",
    "start": "2159820",
    "end": "2166060"
  },
  {
    "text": "data structure that's used to count distinct elements in uh this used account distinct elements in a set",
    "start": "2166060",
    "end": "2173020"
  },
  {
    "text": "the space complexity of a hyperlog log is one the time complexities for hyperlog log",
    "start": "2173020",
    "end": "2179079"
  },
  {
    "text": "queries and insertions are also one they can handle billions of records with",
    "start": "2179079",
    "end": "2184180"
  },
  {
    "text": "only a few kilobytes of memory that's right you can actually count",
    "start": "2184180",
    "end": "2189280"
  },
  {
    "text": "billions of unique records with only a couple kilobytes of data used",
    "start": "2189280",
    "end": "2195700"
  },
  {
    "text": "they're not misreading that that's correct it's pretty wild that it's able to do this",
    "start": "2195700",
    "end": "2201220"
  },
  {
    "text": "so let's talk about let's just walk through a hyperlog log real quick and this is actually",
    "start": "2201220",
    "end": "2206380"
  },
  {
    "text": "the most complicated these algorithms that I'm going to go over so I'm going to just go over real quick and hopefully",
    "start": "2206380",
    "end": "2212320"
  },
  {
    "text": "you'll pick up some of it this took me a while I had to read the white paper several times in order to understand what they were talking about",
    "start": "2212320",
    "end": "2218800"
  },
  {
    "text": "but you initialize this array of registers um that's size 2 to the p",
    "start": "2218800",
    "end": "2224320"
  },
  {
    "text": "so p is some constant it's usually 16 to 18. in redis we have a we have this on",
    "start": "2224320",
    "end": "2230020"
  },
  {
    "text": "the larger side it's 18 but you know 16 to 18 is a traditional size of one of",
    "start": "2230020",
    "end": "2235300"
  },
  {
    "text": "these when an item is inserted you hash that item just like all the other instances here",
    "start": "2235300",
    "end": "2241720"
  },
  {
    "text": "we're using hashes you determine the registered update by taking the left P bits so whatever that",
    "start": "2241720",
    "end": "2248140"
  },
  {
    "text": "constant was you take the left P bits of that hash and that's your register then you set that register",
    "start": "2248140",
    "end": "2255040"
  },
  {
    "text": "to the index of the rightmost one the rightmost one of the hash that you",
    "start": "2255040",
    "end": "2261280"
  },
  {
    "text": "created the binary representation of that hash the reason for this is that the",
    "start": "2261280",
    "end": "2266500"
  },
  {
    "text": "probability that the rightmost one is uh a one or not or the rightmost thing is one or not",
    "start": "2266500",
    "end": "2272980"
  },
  {
    "text": "scales exponentially right so the probability is actually exponentially small as you get further to the left",
    "start": "2272980",
    "end": "2278079"
  },
  {
    "text": "that that's the first one that's one and then when you query it you compute",
    "start": "2278079",
    "end": "2284500"
  },
  {
    "text": "the harmonic mean of the registers that have been uh that have been set",
    "start": "2284500",
    "end": "2290380"
  },
  {
    "text": "not all the registers just to registered that actually are registering a value and then you multiply that harmonic mean",
    "start": "2290380",
    "end": "2297460"
  },
  {
    "text": "by I just kicked the glass down here sorry you multiply that harmonic mean by",
    "start": "2297460",
    "end": "2303520"
  },
  {
    "text": "some constant that's determined by the size of p and those constants are have been published out there",
    "start": "2303520",
    "end": "2309880"
  },
  {
    "text": "to insert so let's go over an example real quick so to insert the username bar with P equals 16. you take the hash of",
    "start": "2309880",
    "end": "2317980"
  },
  {
    "text": "bar and we get this number that I'm not going to read which is represented by this binary",
    "start": "2317980",
    "end": "2324940"
  },
  {
    "text": "so you take the first 16 bits of that and you come out with forty seven",
    "start": "2324940",
    "end": "2330040"
  },
  {
    "text": "thousand three hundred and fifty Seven and that's the register index and you set the that index",
    "start": "2330040",
    "end": "2336940"
  },
  {
    "text": "to the index of the rightmost one so registers sub 47 357 equals one",
    "start": "2336940",
    "end": "2346119"
  },
  {
    "text": "now to get the cardinality and this is where it gets really funky you calculate the harmonic mean of only the set",
    "start": "2346119",
    "end": "2351640"
  },
  {
    "text": "registers there's only one set register that's calculating the harmonic mean and",
    "start": "2351640",
    "end": "2357700"
  },
  {
    "text": "multiplying it by that constant which is 0.673 for PC equals 16.",
    "start": "2357700",
    "end": "2363520"
  },
  {
    "text": "you could you compute all that and then you do is you call a ceiling function on that and your result is one",
    "start": "2363520",
    "end": "2369579"
  },
  {
    "text": "which is the answer I mean that's all being started right so we get one",
    "start": "2369579",
    "end": "2376300"
  },
  {
    "text": "the remarkable thing is that all bits of this are all order one and like I said with only a few",
    "start": "2376300",
    "end": "2382180"
  },
  {
    "text": "kilobytes you can measure you can count billions of Records you can keep track of billions of Records or I think even",
    "start": "2382180",
    "end": "2388660"
  },
  {
    "text": "trillions by just modifying that P just a little bit and I'm pretty sure we use p18 just for that reason",
    "start": "2388660",
    "end": "2395760"
  },
  {
    "text": "so before I just get into the last data structure we're going to talk about let me just show you how to use",
    "start": "2395980",
    "end": "2402040"
  },
  {
    "text": "um a hyperlog log in uh redis",
    "start": "2402040",
    "end": "2407500"
  },
  {
    "text": "so if you're using a stock exchange Library you can use hyper log log add or add async to insert",
    "start": "2407500",
    "end": "2415480"
  },
  {
    "text": "the array of elements or element that you want to insert to the hyperlog log",
    "start": "2415480",
    "end": "2421060"
  },
  {
    "text": "and then you can use the hyperlog log length or I think it's PF count if",
    "start": "2421060",
    "end": "2427480"
  },
  {
    "text": "you're just using the um the raw command API but this hyperlog log length method you",
    "start": "2427480",
    "end": "2433240"
  },
  {
    "text": "pass in the hyperlog log's name and it gets you the cardinality that's all you got to do",
    "start": "2433240",
    "end": "2439560"
  },
  {
    "text": "so the last question we're going to ask ourselves are the top elements the heaviest flows that we're seeing in a",
    "start": "2442300",
    "end": "2449680"
  },
  {
    "text": "particular stream of data so top element flows are the most frequent elements that we encounter in a",
    "start": "2449680",
    "end": "2456280"
  },
  {
    "text": "stream of data this can be really Mission critical for detecting heavy Network flows and you",
    "start": "2456280",
    "end": "2461500"
  },
  {
    "text": "can think you can just think of all sorts of really neat applications for this so a naive approach to this might be to",
    "start": "2461500",
    "end": "2469060"
  },
  {
    "text": "select um by ID or select ID from views and then",
    "start": "2469060",
    "end": "2474339"
  },
  {
    "text": "you Group by your IDs and then you order by the accounts of your IDs and then you do some descending thing with a certain",
    "start": "2474339",
    "end": "2481300"
  },
  {
    "text": "number of a certain number of things what that gets you is a list of your",
    "start": "2481300",
    "end": "2486400"
  },
  {
    "text": "most frequent items that exist in that data set and this is really slow right",
    "start": "2486400",
    "end": "2493000"
  },
  {
    "text": "this is not this is not a fast operation now let's think about doing this they're",
    "start": "2493000",
    "end": "2498880"
  },
  {
    "text": "accomplishing the same thing um with redis so we could store all of these counts",
    "start": "2498880",
    "end": "2505119"
  },
  {
    "text": "and assorted set or even in a even in a hash table either one would work or in",
    "start": "2505119",
    "end": "2510280"
  },
  {
    "text": "hash either would work and then you just call zinker by um views one and then you pass in the ID so",
    "start": "2510280",
    "end": "2518859"
  },
  {
    "text": "you just continually increment uh all of the IDS as you encounter more of them",
    "start": "2518859",
    "end": "2524140"
  },
  {
    "text": "and then you just do a z rev range to get the top elements so the problem with both of these is that you have to store",
    "start": "2524140",
    "end": "2530500"
  },
  {
    "text": "all the data in both of them and in the case of the SQL table it's",
    "start": "2530500",
    "end": "2536020"
  },
  {
    "text": "really expensive from a type complexity perspective I think it's somewhere I think it's more than order N",
    "start": "2536020",
    "end": "2542260"
  },
  {
    "text": "I think it's more than order N I think it's like probably order n log n or something to that effect it's quite",
    "start": "2542260",
    "end": "2547540"
  },
  {
    "text": "expensive to go in and query all that um but this brings us to this heavy keeper",
    "start": "2547540",
    "end": "2553240"
  },
  {
    "text": "algorithm which is uh we also call the top K data structure in redis the heavy",
    "start": "2553240",
    "end": "2559119"
  },
  {
    "text": "keeper is another multi-hash strategy and it's the last in the multi-hash strategies that we're going to be talking about",
    "start": "2559119",
    "end": "2564460"
  },
  {
    "text": "today but like many of them they're all multi-hash except for hyperlog logs they",
    "start": "2564460",
    "end": "2570700"
  },
  {
    "text": "have multiple arrays with multiple counters I'm using counters and air quotes here",
    "start": "2570700",
    "end": "2576040"
  },
  {
    "text": "and you Decay smaller flows as you encounter them and you increment larger",
    "start": "2576040",
    "end": "2581980"
  },
  {
    "text": "flows and then you use a Min Heap to maintain all the top elements that you've",
    "start": "2581980",
    "end": "2587319"
  },
  {
    "text": "encountered so we have this example of a counter here and a counter has two distinct",
    "start": "2587319",
    "end": "2593079"
  },
  {
    "text": "things they count so in this case it's five and the fingerprint which in this",
    "start": "2593079",
    "end": "2598420"
  },
  {
    "text": "case is Foo um to initialize a",
    "start": "2598420",
    "end": "2604960"
  },
  {
    "text": "top k or a heavy keeper you basically just take a very similar looking data",
    "start": "2604960",
    "end": "2611440"
  },
  {
    "text": "structure to the hyperlog log that we or not the hypolog the common sketch that we talked about before you just",
    "start": "2611440",
    "end": "2616960"
  },
  {
    "text": "initialize it but instead of putting in a bunch of integers you have each one of these counter like many data structures",
    "start": "2616960",
    "end": "2623560"
  },
  {
    "text": "with the zero and whatever the fingerprint is in this case it's null for all of them",
    "start": "2623560",
    "end": "2629920"
  },
  {
    "text": "so top K insert um at Gangnam Style we'll say that H1 is three",
    "start": "2629920",
    "end": "2637300"
  },
  {
    "text": "so if you look at uh zero three that's null",
    "start": "2637300",
    "end": "2643060"
  },
  {
    "text": "so we can actually increment that to um what is it we can actually increment",
    "start": "2643060",
    "end": "2648280"
  },
  {
    "text": "that to one and set the fingerprint to Gangnam Style the next one is five and so that one is",
    "start": "2648280",
    "end": "2654579"
  },
  {
    "text": "also null so we can increment that to one and the last one is one so we can increment that one to one and also set",
    "start": "2654579",
    "end": "2661000"
  },
  {
    "text": "getting your style let's try to do the same thing with baby shark now so say we encounter a collision here",
    "start": "2661000",
    "end": "2666520"
  },
  {
    "text": "well what do we do well baby shark isn't what's actually in",
    "start": "2666520",
    "end": "2671619"
  },
  {
    "text": "there so we can't go ahead and necessarily increment it",
    "start": "2671619",
    "end": "2678339"
  },
  {
    "text": "so what we do is we try to decrement it so a heavy keeper a top K in this case",
    "start": "2678339",
    "end": "2684220"
  },
  {
    "text": "we have a probability that the item will be decayed or an item will be decayed if",
    "start": "2684220",
    "end": "2691420"
  },
  {
    "text": "you encounter a different item so we have we have this deactivation function which is just a probability and",
    "start": "2691420",
    "end": "2698560"
  },
  {
    "text": "that reports either one or zero and so we'll take whatever the value that's stored in there in this case it's one",
    "start": "2698560",
    "end": "2703900"
  },
  {
    "text": "and we will potentially decrement it uh determining uh based on whether or not",
    "start": "2703900",
    "end": "2709060"
  },
  {
    "text": "it's been that activation function actually happens so let's just say for example here that",
    "start": "2709060",
    "end": "2714880"
  },
  {
    "text": "we succeeded and we were able to decrement uh that item decrements to zero",
    "start": "2714880",
    "end": "2721180"
  },
  {
    "text": "so because it's now zero we can actually replace it with a new item and increment it to the correct value which is one",
    "start": "2721180",
    "end": "2728560"
  },
  {
    "text": "so H2 now comes out to four so we just increment that and the next one it comes",
    "start": "2728560",
    "end": "2735460"
  },
  {
    "text": "out to five and we can increment that as well but that one right there is the interesting case here it's actually a",
    "start": "2735460",
    "end": "2741760"
  },
  {
    "text": "real interesting case and if as you continue to encounter these you'll go through one of those three",
    "start": "2741760",
    "end": "2747520"
  },
  {
    "text": "permutation 103 permutations either thing hasn't been incremented yet so you just increments it",
    "start": "2747520",
    "end": "2753940"
  },
  {
    "text": "um it has been incremented already and you're the incrementer so you just incremented again or it's been",
    "start": "2753940",
    "end": "2759460"
  },
  {
    "text": "incremented but it has been incremented by the thing you're trying to insert so you run that problem you run that",
    "start": "2759460",
    "end": "2764680"
  },
  {
    "text": "activation function to see if you're going to decrement it or not and then you potentially decrement it and if you",
    "start": "2764680",
    "end": "2769780"
  },
  {
    "text": "decrement it down to zero then you just replace it so then the query at top K to see what",
    "start": "2769780",
    "end": "2776800"
  },
  {
    "text": "the current expected flow of this thing is we just run that same thing that we did with account men sketch but instead",
    "start": "2776800",
    "end": "2783700"
  },
  {
    "text": "of taking the minimum we take the maximum we use the maximum value that we're pulling out of this so in this",
    "start": "2783700",
    "end": "2789819"
  },
  {
    "text": "case for Gangnam Style it's one so we report that it's one and now separately for a top K or heavy",
    "start": "2789819",
    "end": "2797200"
  },
  {
    "text": "Keeper in the background we're maintaining a Min heap of all the data that's been inserted into it so far",
    "start": "2797200",
    "end": "2804280"
  },
  {
    "text": "so add insertion so when you insert a record in and this is based off of the size of um the top items that you want",
    "start": "2804280",
    "end": "2811900"
  },
  {
    "text": "to you want to retrieve from here so ad insertion you check the count of the",
    "start": "2811900",
    "end": "2817660"
  },
  {
    "text": "item that you just inserted if the Min Heap contains that element you just update the count to the new",
    "start": "2817660",
    "end": "2824680"
  },
  {
    "text": "count now if that has been decremented several times that might actually move the item",
    "start": "2824680",
    "end": "2831220"
  },
  {
    "text": "up in the mid Heap and get it closer to the top now if the Min Heap does not contain",
    "start": "2831220",
    "end": "2836500"
  },
  {
    "text": "this does not contain the element that you just added you check to see if the count of the",
    "start": "2836500",
    "end": "2841660"
  },
  {
    "text": "item you just added is greater than or less than the count of the min root if it's greater than you just replace it",
    "start": "2841660",
    "end": "2849400"
  },
  {
    "text": "otherwise you just ignore it so write a stack is well I guess before I",
    "start": "2849400",
    "end": "2856720"
  },
  {
    "text": "do that well no okay I'll just do this first so read a stack the thing I talked I told you about earlier which is the um",
    "start": "2856720",
    "end": "2863859"
  },
  {
    "text": "the conglomeration of all the probabilistic data structures as well as all the other modules that reticing",
    "start": "2863859",
    "end": "2869440"
  },
  {
    "text": "produces is kind of your go-to place now for using all these probabilistic data structures and you can use them in your",
    "start": "2869440",
    "end": "2875260"
  },
  {
    "text": "applications relatively easily by spinning up a Docker image installing it building it from Source whatever you",
    "start": "2875260",
    "end": "2881560"
  },
  {
    "text": "want to do but uh now that this is sort of like the end of my slides but I'm just going to kind",
    "start": "2881560",
    "end": "2888040"
  },
  {
    "text": "of show you real quick first the way that you can use these top case and then I'm going to run this application and",
    "start": "2888040",
    "end": "2894819"
  },
  {
    "text": "I'm going to show you just what the differences are in or show you how different how more much more",
    "start": "2894819",
    "end": "2901180"
  },
  {
    "text": "performant these these data structures are and you'll see some of the quirks that actually come up with them because",
    "start": "2901180",
    "end": "2907300"
  },
  {
    "text": "we're making these trade-offs so the top K data structure is so-called",
    "start": "2907300",
    "end": "2912640"
  },
  {
    "text": "top K it uses the heavy keeper algorithm you call reserve on it and you pass in a",
    "start": "2912640",
    "end": "2918819"
  },
  {
    "text": "few arguments um 10 is the number of top top elements",
    "start": "2918819",
    "end": "2924579"
  },
  {
    "text": "you want to keep track of 20 is the width of that structure 10 is the depth",
    "start": "2924579",
    "end": "2930339"
  },
  {
    "text": "and then 0.925 is the probability that an item will Decay if encountered",
    "start": "2930339",
    "end": "2937900"
  },
  {
    "text": "if a duplicate if a duplicate of a collision occurs and then to add to a top K you just",
    "start": "2937900",
    "end": "2944380"
  },
  {
    "text": "insert you use topk.add and you either insert a single item or just a list of items that you want to pass into it",
    "start": "2944380",
    "end": "2951640"
  },
  {
    "text": "and then to query the top K if you want to find all the top elements in the top okay you just call Top K dot list and",
    "start": "2951640",
    "end": "2957640"
  },
  {
    "text": "that'll report all of the elements that are actually within this so I actually have",
    "start": "2957640",
    "end": "2964440"
  },
  {
    "text": "um a couple of run a couple of images running in uh Docker that I'm just going",
    "start": "2965140",
    "end": "2970359"
  },
  {
    "text": "to use and if I just run a.net run",
    "start": "2970359",
    "end": "2976240"
  },
  {
    "text": "like I said I have those four different methods I have an unknit next uh postgres database I have an index",
    "start": "2976240",
    "end": "2982420"
  },
  {
    "text": "postgres database I have a our Brute Force redis instance which",
    "start": "2982420",
    "end": "2988540"
  },
  {
    "text": "just uses assorted set because the sorted set actually can be generalized to all these problems and I have the",
    "start": "2988540",
    "end": "2994119"
  },
  {
    "text": "four probabilistic data structures we talked about today uh Bloom filters common sketch hyperlog log and heavy",
    "start": "2994119",
    "end": "3000780"
  },
  {
    "text": "keeper all running um all getting in data inserted into them and they were running the different",
    "start": "3000780",
    "end": "3006660"
  },
  {
    "text": "algorithms on these so these results here that this spit out",
    "start": "3006660",
    "end": "3014480"
  },
  {
    "text": "I'm going to zoom that in for everybody the first thing that happens here is it",
    "start": "3014640",
    "end": "3022680"
  },
  {
    "text": "initializes it well it flushes out the old databases and initial and initializes new ones and it takes all of",
    "start": "3022680",
    "end": "3029400"
  },
  {
    "text": "the words from Hermann Melville's Moby Dick and inserts it into each one of these different data types now the",
    "start": "3029400",
    "end": "3035220"
  },
  {
    "text": "interesting thing here is that the PG index PG indexed take between you",
    "start": "3035220",
    "end": "3042540"
  },
  {
    "text": "know three and four seconds to insert and actually the brute force method of redis is ever so slightly slower takes",
    "start": "3042540",
    "end": "3049079"
  },
  {
    "text": "about four and a half to five seconds in my experience running this but really what's really cool is the",
    "start": "3049079",
    "end": "3056099"
  },
  {
    "text": "probabilistic data structures only take about 700 milliseconds so think about that's",
    "start": "3056099",
    "end": "3061859"
  },
  {
    "text": "um about a fifth to an eighth as long to run this so it's a",
    "start": "3061859",
    "end": "3067980"
  },
  {
    "text": "lot faster but the speed actually isn't necessarily the Improvement that we're really looking for what's really neat if you",
    "start": "3067980",
    "end": "3074819"
  },
  {
    "text": "scroll down to the bottom of this you'll see the different sizes of these these sizes are all in bytes",
    "start": "3074819",
    "end": "3081119"
  },
  {
    "text": "um Herman Melville's Moby Dick has 212 000 words in it so",
    "start": "3081119",
    "end": "3088500"
  },
  {
    "text": "if you're inserting these all into something that is not that's an order in",
    "start": "3088500",
    "end": "3094619"
  },
  {
    "text": "space complexity it gets real expensive so in the um unindexed version of the",
    "start": "3094619",
    "end": "3102000"
  },
  {
    "text": "postgres table we have a hundred and that's 13 megabytes of data that's been",
    "start": "3102000",
    "end": "3108720"
  },
  {
    "text": "inserted into it in the index version we have 16 megabytes",
    "start": "3108720",
    "end": "3115200"
  },
  {
    "text": "in The Brute Force version for redis we have uh just under two megabytes of",
    "start": "3115200",
    "end": "3123240"
  },
  {
    "text": "data that's inserted and the reason for that is it's a much simpler thing that you're inserting you're inserting the",
    "start": "3123240",
    "end": "3128460"
  },
  {
    "text": "table it's there's no table to maintain all the overhead of so it's much more Compact and also the real important",
    "start": "3128460",
    "end": "3135480"
  },
  {
    "text": "thing is a sorted set doesn't allow duplication so that's just the unique items that have been added to it",
    "start": "3135480",
    "end": "3141599"
  },
  {
    "text": "um but look at the sizes for our different probabilistic data structures",
    "start": "3141599",
    "end": "3147180"
  },
  {
    "text": "the two orders of magnitude smaller than the other data structures that we've encountered so far",
    "start": "3147180",
    "end": "3152640"
  },
  {
    "text": "and the really cool and compelling thing is as we grow the size of our data set",
    "start": "3152640",
    "end": "3158099"
  },
  {
    "text": "you know this is a this is the mid-size data set but as we grow it as we go from 200 000",
    "start": "3158099",
    "end": "3164040"
  },
  {
    "text": "to 2 million to 20 million to 200 million to 2 billion",
    "start": "3164040",
    "end": "3169920"
  },
  {
    "text": "those values in The Brute Force records will grow and they'll grow linearly with the set",
    "start": "3169920",
    "end": "3175619"
  },
  {
    "text": "but the rest of these they won't grow linearly or they won't grow nearly as linearly as um as these",
    "start": "3175619",
    "end": "3181920"
  },
  {
    "text": "other ones because the only one that's kind of an offender here is the bloom filter and that's only scaling up you know seven to ten Mega seven to ten bits",
    "start": "3181920",
    "end": "3189240"
  },
  {
    "text": "or 7 to 12 bits per uh per new item that's being inserted right",
    "start": "3189240",
    "end": "3195240"
  },
  {
    "text": "and in brightness these will actually all scale up uh for you with you they will automatically expand as you",
    "start": "3195240",
    "end": "3202020"
  },
  {
    "text": "insert more stuff into them now let's look at the individual operations uh real quick",
    "start": "3202020",
    "end": "3208859"
  },
  {
    "text": "um so for president's checks all four times we determined that oh yes",
    "start": "3208859",
    "end": "3215760"
  },
  {
    "text": "the word that we were looking for in this case the less present in um from a Time perspective",
    "start": "3215760",
    "end": "3224000"
  },
  {
    "text": "unindexed in indexed both worked pretty fast right so they both went you know 35 milliseconds and 11 milliseconds for the",
    "start": "3224000",
    "end": "3230520"
  },
  {
    "text": "index you know it's pretty quick um redis we usually we we usually calculate our",
    "start": "3230520",
    "end": "3236460"
  },
  {
    "text": "um execution times in microseconds instead of milliseconds and in this case the the long pole here is actually the",
    "start": "3236460",
    "end": "3243300"
  },
  {
    "text": "round trip from the application through to the redis instance which is running locally and the actual execution",
    "start": "3243300",
    "end": "3249900"
  },
  {
    "text": "time is probably on the order of tens of microseconds so both both versions of",
    "start": "3249900",
    "end": "3255180"
  },
  {
    "text": "redis here are working really fast four and three milliseconds for our item count problems so the",
    "start": "3255180",
    "end": "3263760"
  },
  {
    "text": "number of times that a particular item has occurred in a set when we use",
    "start": "3263760",
    "end": "3269819"
  },
  {
    "text": "the precise versions We All Get about fourteen thousand three hundred and forty",
    "start": "3269819",
    "end": "3275700"
  },
  {
    "text": "we all get 14 340 which is the exact number of times that the occurs in the which is the most common word in this",
    "start": "3275700",
    "end": "3282839"
  },
  {
    "text": "data set occurs in um Moby Dick we have a slight over count of yeah",
    "start": "3282839",
    "end": "3291300"
  },
  {
    "text": "about two percent in um in the thighs from accountment sketch",
    "start": "3291300",
    "end": "3297599"
  },
  {
    "text": "and the execution time for this is much lower it's you know",
    "start": "3297599",
    "end": "3302819"
  },
  {
    "text": "or it's it's lower than the other execution times for cardinality you'll see that you actually",
    "start": "3302819",
    "end": "3310079"
  },
  {
    "text": "have an undercount here you have an under count of about one percent and",
    "start": "3310079",
    "end": "3316859"
  },
  {
    "text": "yeah with 18 391 or 931 as opposed to 18 785",
    "start": "3317099",
    "end": "3323520"
  },
  {
    "text": "cardinality is interesting because this is actually the least performance of the SQL operation Iran I I kind of explained",
    "start": "3323520",
    "end": "3328740"
  },
  {
    "text": "this before but yeah that can be kind of a slow operation and then for the top case",
    "start": "3328740",
    "end": "3335339"
  },
  {
    "text": "um 60 and 50 Mega 1650 milliseconds for the SQL types and then the Brute Force",
    "start": "3335339",
    "end": "3342780"
  },
  {
    "text": "threat us which is a login operation took um seven milliseconds and the probabilistic",
    "start": "3342780",
    "end": "3348780"
  },
  {
    "text": "version it was order one so it only took two milliseconds so yeah um that's kind of and these are the",
    "start": "3348780",
    "end": "3356160"
  },
  {
    "text": "results you'll see that some of them this s keeps showing up in the top k for this one but that's just you know it has",
    "start": "3356160",
    "end": "3363780"
  },
  {
    "text": "it's slightly off it's slight very ever so slightly different but if you look and you actually invest interrogate this",
    "start": "3363780",
    "end": "3369480"
  },
  {
    "text": "with the exception of this s everything else in here is the same as the other ones and that's just based off of that",
    "start": "3369480",
    "end": "3374880"
  },
  {
    "text": "how that flow operates what the probability or what the actual Decay probability was when it was encountered",
    "start": "3374880",
    "end": "3380819"
  },
  {
    "text": "so anyway um let me kind of wrap up here",
    "start": "3380819",
    "end": "3385818"
  },
  {
    "text": "if you're interested in looking at the code that I wrote for this uh you can just take a picture of this QR code",
    "start": "3387000",
    "end": "3392700"
  },
  {
    "text": "that's all the data that's all the code for this talk my slides are in here instructions as to how to run the demo",
    "start": "3392700",
    "end": "3399720"
  },
  {
    "text": "you just do a Docker compose run and a DOT net run to run everything it's pretty straightforward",
    "start": "3399720",
    "end": "3406079"
  },
  {
    "text": "give everyone a second to do that take a picture there's still people picture picturing",
    "start": "3406079",
    "end": "3414559"
  },
  {
    "text": "some more resources here um my favorite resources for all things redis is",
    "start": "3418680",
    "end": "3424800"
  },
  {
    "text": "redis.io we also have the source code that's the",
    "start": "3424800",
    "end": "3429900"
  },
  {
    "text": "same repository that I just linked you to that QR code and then I actually wrote a bunch of C sharp implementations",
    "start": "3429900",
    "end": "3435480"
  },
  {
    "text": "for all of these data structures they're available in the algorithms project you can come check them out I'm actually",
    "start": "3435480",
    "end": "3441839"
  },
  {
    "text": "gonna I actually haven't had a heavy keeper yet I'm probably gonna do that next month",
    "start": "3441839",
    "end": "3447020"
  },
  {
    "text": "and again my name is Steve lorello I am the.net developer Advocate at redis you can follow me on Twitter or GitHub or um",
    "start": "3447240",
    "end": "3453839"
  },
  {
    "text": "every Wednesday at 2PM Eastern Standard Time I usually stream at twitch.tv redis",
    "start": "3453839",
    "end": "3459720"
  },
  {
    "text": "Inc so yeah and the last two bits of resources if",
    "start": "3459720",
    "end": "3465000"
  },
  {
    "text": "you want to learn more about redis we have a university for redis called redis University it's a university.reddits.com",
    "start": "3465000",
    "end": "3470579"
  },
  {
    "text": "and we have a Discord server that if you have any questions about redis for usually me or one of a member of my team",
    "start": "3470579",
    "end": "3477180"
  },
  {
    "text": "are there to answer come check us out at discord.com invite slash redis so",
    "start": "3477180",
    "end": "3483839"
  },
  {
    "text": "um I have time for a couple of questions and I notice that these lights make it difficult for me to",
    "start": "3483839",
    "end": "3490079"
  },
  {
    "text": "see what's going on I'm sorry this is just like I I can't not watch this is too much fun but",
    "start": "3490079",
    "end": "3496380"
  },
  {
    "text": "anyway does anyone have any questions I'll back up so that doesn't keep bothering people",
    "start": "3496380",
    "end": "3503460"
  },
  {
    "text": "any questions from the audience okay here we go go ahead",
    "start": "3503460",
    "end": "3511460"
  },
  {
    "text": "uh the thing is not on I think is the question you're asking um can you tweak",
    "start": "3518099",
    "end": "3523380"
  },
  {
    "text": "the algorithms to lower your error rate",
    "start": "3523380",
    "end": "3526880"
  },
  {
    "text": "yeah so you can um you can tweak you probably with all these um as you initialize them you initialize them with",
    "start": "3529859",
    "end": "3536700"
  },
  {
    "text": "an expected error rate and an expected uh probability of error and so you would initialize it to uh have the capacity or",
    "start": "3536700",
    "end": "3543780"
  },
  {
    "text": "to have the specific error rate that you want and in redis what happens is redis",
    "start": "3543780",
    "end": "3549359"
  },
  {
    "text": "will automatically scale up the size of your data structure to accommodate the",
    "start": "3549359",
    "end": "3555420"
  },
  {
    "text": "the bits that are going on in there any other questions go ahead",
    "start": "3555420",
    "end": "3562760"
  },
  {
    "text": "well the uh the errors are just implicit um in the so the question is what do you do to deal with the errors that you get",
    "start": "3565319",
    "end": "3571619"
  },
  {
    "text": "so the trick is that when you're using these data structures you are accepting that there are there are potential",
    "start": "3571619",
    "end": "3576960"
  },
  {
    "text": "errors that occur in the system that's why when you have uh I'm not going to fall off the stage",
    "start": "3576960",
    "end": "3582180"
  },
  {
    "text": "right that's why when you have uh operations that are you need Precision on you need to where you really want to",
    "start": "3582180",
    "end": "3588000"
  },
  {
    "text": "use these so if like if you're running a bank uh like a bank a bank or a stock",
    "start": "3588000",
    "end": "3594000"
  },
  {
    "text": "trading thing and you have very precise numbers or very precise operations that you're doing you don't want to use these",
    "start": "3594000",
    "end": "3600059"
  },
  {
    "text": "but otherwise they're usually okay I am out of time so I'm going to pack up",
    "start": "3600059",
    "end": "3606839"
  },
  {
    "text": "here while I let the other person come on but thank you all very much for coming out it's been great speaking to",
    "start": "3606839",
    "end": "3612660"
  },
  {
    "text": "you all [Applause]",
    "start": "3612660",
    "end": "3617288"
  }
]
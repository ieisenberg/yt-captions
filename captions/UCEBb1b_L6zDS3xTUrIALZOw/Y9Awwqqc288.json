[
  {
    "start": "0",
    "end": "12240"
  },
  {
    "text": "SARA ELLISON: OK,\nso last time right at the end of the\nlecture, I had introduced",
    "start": "12240",
    "end": "19290"
  },
  {
    "text": "a more general linear model,\nthe multivariate linear model.",
    "start": "19290",
    "end": "25350"
  },
  {
    "text": "And I had just gone through the\nfirst couple of these slides,",
    "start": "25350",
    "end": "30420"
  },
  {
    "text": "saying let's analyze this model\nusing a different notation,",
    "start": "30420",
    "end": "36720"
  },
  {
    "text": "in particular matrix notation,\nbecause the summation notation was just too clunky.",
    "start": "36720",
    "end": "42520"
  },
  {
    "text": "It wasn't up for the job. And so let me just\ngo through quickly.",
    "start": "42520",
    "end": "48750"
  },
  {
    "text": "Let's see. This was, I think, the next\nto last slide I had up. So if we let y be the\ncolumn vector of all",
    "start": "48750",
    "end": "59520"
  },
  {
    "text": "of the observations on\nthe dependent variable, then let epsilon be the column\nvector of all of the errors,",
    "start": "59520",
    "end": "66690"
  },
  {
    "text": "and then let x be\nthe matrix, where across the rows\nof the matrix, we",
    "start": "66690",
    "end": "73869"
  },
  {
    "text": "have first the column of ones,\nand then a column of each",
    "start": "73870",
    "end": "80020"
  },
  {
    "text": "of the explanatory variables. And then sort of\ndown the matrix,",
    "start": "80020",
    "end": "89620"
  },
  {
    "text": "we have observations\non each of the-- well, we have each\nof the observations.",
    "start": "89620",
    "end": "95229"
  },
  {
    "text": "Each observation\ncorresponds to a row. So if we define this matrix\nand vectors this way,",
    "start": "95230",
    "end": "103150"
  },
  {
    "text": "then we can write our\nmultivariate linear model",
    "start": "103150",
    "end": "108160"
  },
  {
    "text": "in the following very\nparsimonious fashion. y equals x beta plus epsilon.",
    "start": "108160",
    "end": "116420"
  },
  {
    "text": "OK, so now, I'm\nbasically going to go",
    "start": "116420",
    "end": "123170"
  },
  {
    "text": "through the same assumptions,\nbut in a slightly more general way from when I\ndiscussed assumptions",
    "start": "123170",
    "end": "130100"
  },
  {
    "text": "in the bivariate model. The assumptions have to be\ndiscussed in a more general way",
    "start": "130100",
    "end": "135200"
  },
  {
    "text": "now because actually, they're\na little bit more complicated with the multivariate model.",
    "start": "135200",
    "end": "142280"
  },
  {
    "text": "So I'm going to condense\nall of the assumptions into two basic categories.",
    "start": "142280",
    "end": "148230"
  },
  {
    "text": "One is the identification\nassumptions. And two is the assumptions\non the error behavior.",
    "start": "148230",
    "end": "153530"
  },
  {
    "text": "OK, so in the\nmultivariate linear model, in order to have\nidentification, in order",
    "start": "153530",
    "end": "160730"
  },
  {
    "text": "to be able to\nestimate our model, we have to have n\ngreater than k plus 1.",
    "start": "160730",
    "end": "166459"
  },
  {
    "text": "That just means we have to have\nmore observations than we have explanatory variables, plus 1.",
    "start": "166460",
    "end": "175849"
  },
  {
    "text": "And x has to have full\ncolumn rank of k plus 1.",
    "start": "175850",
    "end": "182420"
  },
  {
    "text": "And what does that mean? In other words, means\nthat the regressors have to be linearly independent.",
    "start": "182420",
    "end": "189379"
  },
  {
    "text": "Or another way of saying this\nis that the matrix x prime, or x transpose x, is invertible.",
    "start": "189380",
    "end": "196162"
  },
  {
    "text": "I'm going to go through\nthis in some more detail in just a second. And then the second main\nassumption or main category",
    "start": "196162",
    "end": "203689"
  },
  {
    "text": "of assumptions are on\nthe error behavior. And these actually are\nexactly like the assumptions we saw before.",
    "start": "203690",
    "end": "209600"
  },
  {
    "text": "I'm just using matrix\nnotation to express them. So here we have the\nexpectation of epsilon here.",
    "start": "209600",
    "end": "217340"
  },
  {
    "text": "Epsilon is a vector. And that's the vector of zeros. The expectation of\nepsilon, epsilon transpose",
    "start": "217340",
    "end": "225200"
  },
  {
    "text": "is equal to sigma squared times\nthe n by n identity matrix.",
    "start": "225200",
    "end": "233780"
  },
  {
    "text": "And this is in fact-- this matrix here is, in\nfact, just the matrix",
    "start": "233780",
    "end": "243150"
  },
  {
    "text": "that we denote covariance of\nepsilon, which I'll show you",
    "start": "243150",
    "end": "248433"
  },
  {
    "text": "a picture of it in a second. It's just a matrix\nthat has the variances of epsilon along the\ndiagonal and the covariances",
    "start": "248433",
    "end": "255930"
  },
  {
    "text": "on the off diagonal. And so what we're saying\nhere is that the diagonal",
    "start": "255930",
    "end": "261958"
  },
  {
    "text": "is equal to sigma squared. And the off diagonals are zeros.",
    "start": "261959",
    "end": "267300"
  },
  {
    "text": " In a stronger version of\nthis is the epsilon vector",
    "start": "267300",
    "end": "277220"
  },
  {
    "text": "has this multivariate\nnormal distribution with this\nvariance/covariance matrix.",
    "start": "277220",
    "end": "283909"
  },
  {
    "text": "I'll go into more detail in\nboth of these in just a second.",
    "start": "283910",
    "end": "290220"
  },
  {
    "text": "So let's do the-- oh, n by n identity matrix.",
    "start": "290220",
    "end": "295729"
  },
  {
    "text": "OK, so let's take a closer\nlook at these assumptions. So assumption one, the\nidentification assumption,",
    "start": "295730",
    "end": "302600"
  },
  {
    "text": "what exactly does this mean? Well, we need to have more\nobservations than regressors.",
    "start": "302600",
    "end": "307790"
  },
  {
    "text": "That shouldn't\ncome as a surprise, especially if we think\nabout the bivariate model. We have one regressor.",
    "start": "307790",
    "end": "313940"
  },
  {
    "text": "You have to have at least\ntwo observations or else you can't draw a line.",
    "start": "313940",
    "end": "319220"
  },
  {
    "text": "So this is just\nsort of generalizes that to higher dimensions.",
    "start": "319220",
    "end": "324259"
  },
  {
    "text": "We can't have any\nregressors that do not have positive sample variation.",
    "start": "324260",
    "end": "329850"
  },
  {
    "text": "So we saw this assumption\nin the bivariate case. Remember I had a picture\nthat looked like--",
    "start": "329850",
    "end": "337325"
  },
  {
    "start": "337325",
    "end": "348510"
  },
  {
    "text": "I had a picture that\nlooked like this. And I said if all\nof our observations are on the same\nvalue of x, we can't",
    "start": "348510",
    "end": "357360"
  },
  {
    "text": "identify how the conditional\nmean of y changes with x.",
    "start": "357360",
    "end": "366326"
  },
  {
    "text": "Well, again, in the\nmultivariate regression, or the multivariate\ncase, we can't",
    "start": "366326",
    "end": "373349"
  },
  {
    "text": "identify a particular\nparameter if we have a regressor that doesn't\nhave positive sample variation.",
    "start": "373350",
    "end": "379810"
  },
  {
    "text": "So all of our regressors have to\nhave positive sample variation. And then the third\none-- and this",
    "start": "379810",
    "end": "384870"
  },
  {
    "text": "is the one that actually\ntrips people up sometimes-- is that we can't have\nany regressors that",
    "start": "384870",
    "end": "390419"
  },
  {
    "text": "are linear functions of one\nor more other regressors.",
    "start": "390420",
    "end": "395640"
  },
  {
    "text": "And in matrix notation,\nthat's another way to say that is the regressors\nare linearly independent.",
    "start": "395640",
    "end": "403920"
  },
  {
    "text": "And that turns out\nto be equivalent to x prime x being invertible. Yep. STUDENT: Can you give\nan example of that?",
    "start": "403920",
    "end": "410810"
  },
  {
    "text": "SARA ELLISON: I will give\ntwo examples in fact. OK, so here is one example.",
    "start": "410810",
    "end": "418780"
  },
  {
    "text": "Let's imagine a\ncase where we want to estimate the effect\nof schooling, work experience, and age on salary.",
    "start": "418780",
    "end": "426820"
  },
  {
    "text": "And we have\nindividual level data. So we have sort of a data set.",
    "start": "426820",
    "end": "431860"
  },
  {
    "text": "And we have a bunch\nof different salaries. And then we also have each\nperson's years of schooling,",
    "start": "431860",
    "end": "438700"
  },
  {
    "text": "each person's years of work\nexperience, each person's age, and maybe some other stuff too.",
    "start": "438700",
    "end": "444910"
  },
  {
    "text": "Doesn't matter. Well, it could be in\nour particular sample, it's quite possible that\neveryone in our sample",
    "start": "444910",
    "end": "452530"
  },
  {
    "text": "started school at age\nsix, went to school until he or she finished school,\nand then started working.",
    "start": "452530",
    "end": "459220"
  },
  {
    "text": "Wouldn't be crazy\nif that happened. Well, if in fact that\nwas the case, then",
    "start": "459220",
    "end": "465190"
  },
  {
    "text": "the years of schooling plus\nthe years of work experience plus 6 is equal to the age.",
    "start": "465190",
    "end": "471595"
  },
  {
    "text": " So if that's the case, we\ncan't estimate this regression",
    "start": "471595",
    "end": "479040"
  },
  {
    "text": "equation. And it sort of makes logical\nsense too in the sense",
    "start": "479040",
    "end": "485490"
  },
  {
    "text": "that there's nothing\nthat helps us separately",
    "start": "485490",
    "end": "492120"
  },
  {
    "text": "identify what the\neffect of schooling, and work experience,\nand age are.",
    "start": "492120",
    "end": "498389"
  },
  {
    "text": "There's no variation that allows\nus to separately figure out the effects of all three of\nthose, if, in fact, they're",
    "start": "498390",
    "end": "506190"
  },
  {
    "text": "collinear in our sample. So we can't estimate\nsuch a model.",
    "start": "506190",
    "end": "512700"
  },
  {
    "text": "Is that clear? STUDENT: So you would\ndrop a regressor. SARA ELLISON: Exactly, you have\nto drop one of the regressors. ",
    "start": "512700",
    "end": "519919"
  },
  {
    "text": "Does this make sense? Yes. STUDENT: If you drop age\nit still wouldn't work,",
    "start": "519919",
    "end": "525900"
  },
  {
    "text": "like if you those? SARA ELLISON: If you drop\nage, it still wouldn't work? Yes. STUDENT: It still\nwouldn't work or--",
    "start": "525900",
    "end": "532964"
  },
  {
    "text": "SARA ELLISON: It would. It wouldn't work if everyone\nwent to school until age 18.",
    "start": "532964",
    "end": "540199"
  },
  {
    "text": "So we would still need to have-- we couldn't have a perfect\nlinear relationship",
    "start": "540200",
    "end": "547690"
  },
  {
    "text": "between number of\nyears of schooling-- well, actually, that would just\nbe no sample variation in years",
    "start": "547690",
    "end": "557110"
  },
  {
    "text": "of schooling. But if some people went\nto school until age 18,",
    "start": "557110",
    "end": "563550"
  },
  {
    "text": "and some people went to age\n20, and some went to age 25, then if we dropped age\nfrom this regression,",
    "start": "563550",
    "end": "569459"
  },
  {
    "text": "then we could estimate it. STUDENT: You say\nwhy this doesn't",
    "start": "569460",
    "end": "576329"
  },
  {
    "text": "hold is that if we\ntook x1, x2, and x3, we could get values of beta 1,\nbeta 2, and all of these, which",
    "start": "576330",
    "end": "583980"
  },
  {
    "text": "would essentially make y 0. So 1, 1, and minus\n1, for example. So then this equation\nwould go [INAUDIBLE]",
    "start": "583980",
    "end": "590310"
  },
  {
    "text": "and then y would\nbe 0 in that case. SARA ELLISON: So that's\nnot the intuition I have.",
    "start": "590310",
    "end": "596790"
  },
  {
    "text": "That may be correct in some way. But that's certainly not\nthe intuition I have.",
    "start": "596790",
    "end": "602880"
  },
  {
    "text": "I would just say that my\nintuition is just that we don't",
    "start": "602880",
    "end": "608040"
  },
  {
    "text": "have any variation to\nseparately identify the effects of\nthese three things if they're perfectly linearly\nassociated with one another.",
    "start": "608040",
    "end": "617740"
  },
  {
    "text": "Yes. STUDENT: So what if\nthe two regressor are somewhat relating, but they\nare not perfectly relating?",
    "start": "617740",
    "end": "625473"
  },
  {
    "text": "SARA ELLISON: So that's\nan excellent question. So the question was, what\nif they are closely related?",
    "start": "625473",
    "end": "631100"
  },
  {
    "text": "So maybe this doesn't\nquite hold in our sample. But it comes close to holding.",
    "start": "631100",
    "end": "636200"
  },
  {
    "text": "Like we had a few people\nwho went to school at age five instead of age six. And we had like a couple people\nwho took a year off and didn't",
    "start": "636200",
    "end": "643550"
  },
  {
    "text": "work. So this linear relationship\nis close to holding, but not quite. That's something\nthat Esther might be",
    "start": "643550",
    "end": "650390"
  },
  {
    "text": "able to talk about next time. I'm not sure. So basically, in\nthat case, you can--",
    "start": "650390",
    "end": "657170"
  },
  {
    "text": "maybe, maybe not. But anyhow, I'll\ntell you the answer. In that case, you can\nestimate this equation.",
    "start": "657170",
    "end": "664970"
  },
  {
    "text": "But you end up sort of having\ntrouble separately identifying",
    "start": "664970",
    "end": "671629"
  },
  {
    "text": "the coefficients\non these variables, on these three variables. And in fact, they're going to\nbe coefficients that have very--",
    "start": "671630",
    "end": "679790"
  },
  {
    "text": "that your estimator is going\nto be of very high variance estimator. And so in that case,\nwhat you might want to do",
    "start": "679790",
    "end": "686250"
  },
  {
    "text": "is still drop one of them. That's going to give you much\nlower variance estimators",
    "start": "686250",
    "end": "692279"
  },
  {
    "text": "for the remaining two. It's going to introduce\na little bit of bias, if that regressor\nbelongs in there.",
    "start": "692280",
    "end": "698475"
  },
  {
    "text": "It's going to introduce\na little bit of bias. But you might be willing\nto accept that bias to have much lower\nvariance estimators.",
    "start": "698475",
    "end": "706279"
  },
  {
    "text": "Yes. STUDENT: [INAUDIBLE]\nthat digression of--",
    "start": "706280",
    "end": "711410"
  },
  {
    "text": "what if you had a large data\nset with a lot of variables. And you don't know that there\nare regressions in there",
    "start": "711410",
    "end": "718043"
  },
  {
    "text": "that do have [INAUDIBLE]? What are the things that\ncan insinuate from this, could be causing problems\nin my analysis or--",
    "start": "718043",
    "end": "725630"
  },
  {
    "text": "SARA ELLISON: Yeah,\nso first of all, if I tried to run\nthis regression and this linear relationship\nexisted in my data set,",
    "start": "725630",
    "end": "734930"
  },
  {
    "text": "R would throw up its hands\nand say, you can't do that. So I can't even do it.",
    "start": "734930",
    "end": "743330"
  },
  {
    "text": "So you would find that out. If this relationship\ndidn't quite exist,",
    "start": "743330",
    "end": "749430"
  },
  {
    "text": "it was close to existing\nin the data set, but not quite, R would\ngo ahead and give you",
    "start": "749430",
    "end": "754790"
  },
  {
    "text": "the results of this. But one thing that\nyou could do is you could compute the\ncorrelation coefficients",
    "start": "754790",
    "end": "764029"
  },
  {
    "text": "for all of your regressors\nbefore you run the regression and see if any are\nreally highly correlated.",
    "start": "764030",
    "end": "769790"
  },
  {
    "text": "That wouldn't necessarily\npick up a linear relationship like this. But the other thing\nyou could do is",
    "start": "769790",
    "end": "775528"
  },
  {
    "text": "after you run the\nregression, if you have really large\nstandard errors, that could be a signal\nto you that you",
    "start": "775528",
    "end": "783259"
  },
  {
    "text": "could have this situation that's\nclose to perfect collinearity.",
    "start": "783260",
    "end": "788685"
  },
  {
    "text": "Yes. STUDENT: So if we have\ntwo regressors, x1 and x2, could we use the ratio in some\nways to [INAUDIBLE] regression,",
    "start": "788685",
    "end": "795370"
  },
  {
    "text": "as a third regressor? Or would that also\nbe [INAUDIBLE]?? SARA ELLISON: So\nthat wouldn't induce",
    "start": "795370",
    "end": "803980"
  },
  {
    "text": "this sort of perfect\ncollinearity problem.",
    "start": "803980",
    "end": "809815"
  },
  {
    "text": "You could. You might not want to\ndo it for other reasons. But yeah.",
    "start": "809815",
    "end": "815688"
  },
  {
    "text": "ESTHER DUFLO: There's one more. Continuing the question on\nif you had many [INAUDIBLE] and you didn't know\nwhich one to pick,",
    "start": "815688",
    "end": "822770"
  },
  {
    "text": "[INAUDIBLE] fall away from\ntraditional econometrics, it becomes then this\n[INAUDIBLE] we're",
    "start": "822770",
    "end": "829200"
  },
  {
    "text": "going to talk about when we\ntalk about machine learning. If you really don't want-- traditional econometrics\nassumes that you",
    "start": "829200",
    "end": "835140"
  },
  {
    "text": "have a model that you are\ntrying to test so you don't go on a giant fishing expedition.",
    "start": "835140",
    "end": "841050"
  },
  {
    "text": "If you want to go on a\ngiant fishing expedition, there are techniques for that. And that's [INAUDIBLE].",
    "start": "841050",
    "end": "846660"
  },
  {
    "text": "That's what we are\ngoing to introduce. ",
    "start": "846660",
    "end": "852658"
  },
  {
    "text": "SARA ELLISON: Good. OK, so that's one example. A second example of this perfect\nmulti-colinearity and one",
    "start": "852658",
    "end": "863110"
  },
  {
    "text": "that sort of researchers\nrun afoul of all the time is when they use dummy variables\nto indicate, say, observations",
    "start": "863110",
    "end": "873940"
  },
  {
    "text": "falling into\nexhaustive and mutually exclusive set of classes.",
    "start": "873940",
    "end": "879769"
  },
  {
    "text": "So here's an example. Let's suppose I have a data set. Let's say I go talk\nto all my friends",
    "start": "879770",
    "end": "886000"
  },
  {
    "text": "in the dorm to collect\nmy data set for 1431. And I ask them what\npets they have at home. And let's say all\nof them have pets.",
    "start": "886000",
    "end": "894430"
  },
  {
    "text": "We could have a category\nfor no pet as well. But anyhow, let's say\nall of them have pets. But they either have a\ncat, a dog, or a fish.",
    "start": "894430",
    "end": "901360"
  },
  {
    "text": "And so then I create three\ndifferent dummy variables. One is equal to 1 if they\nhave a cat, and 0 otherwise.",
    "start": "901360",
    "end": "908470"
  },
  {
    "text": "1 is equal to 1 if they\nhave a dog, and 0 otherwise. And 1 is equal to 1 if they\nhave a fish, and 0 otherwise.",
    "start": "908470",
    "end": "914459"
  },
  {
    "text": "And everyone has exactly\none of those pets.",
    "start": "914460",
    "end": "920210"
  },
  {
    "text": "I cannot include all three\nof those dummy variables in the regression because if\nwe add up those three dummy",
    "start": "920210",
    "end": "929480"
  },
  {
    "text": "variables, we get\na column of ones. And that's perfectly\nco-linear with our column",
    "start": "929480",
    "end": "935510"
  },
  {
    "text": "of ones that allows us to\nestimate the intercept.",
    "start": "935510",
    "end": "940820"
  },
  {
    "text": "Now, there are other ways. You can, in fact, decide\nto include all three",
    "start": "940820",
    "end": "949040"
  },
  {
    "text": "dummy variables and not\ninclude an intercept, not estimate an intercept\nin this regression.",
    "start": "949040",
    "end": "954620"
  },
  {
    "text": "It's entirely equivalent. It would be a little troubling\nif it wasn't equivalent. But it is in fact\nentirely equivalent.",
    "start": "954620",
    "end": "961321"
  },
  {
    "text": "It's just have to interpret\nthe coefficient estimates a different way. But you can't have both an\nintercept in your regression",
    "start": "961322",
    "end": "966950"
  },
  {
    "text": "and a set of dummy\nvariables that are a full set of exhaustive\nand mutually exclusive classes.",
    "start": "966950",
    "end": "975760"
  },
  {
    "text": "And like I said, R will\nnot let you do this anyhow. ",
    "start": "975760",
    "end": "981610"
  },
  {
    "text": "OK, so now the second\nassumption or second-- yes. STUDENT: [INAUDIBLE] data?",
    "start": "981610",
    "end": "989830"
  },
  {
    "text": "SARA ELLISON: It only\nchanges the interpretation. So basically, I think I'll\nleave that question for Esther",
    "start": "989830",
    "end": "998050"
  },
  {
    "text": "because she will\nbe giving examples of how to use dummy\nvariables in regressions",
    "start": "998050",
    "end": "1003227"
  },
  {
    "text": "and how to interpret\nthe coefficients. So we'll leave that till later. OK, so then the\nsecond assumption",
    "start": "1003227",
    "end": "1011200"
  },
  {
    "text": "was about the error behavior. And as I said before,\nthese assumptions",
    "start": "1011200",
    "end": "1016959"
  },
  {
    "text": "aren't different for\nthe multivariate model. It's just that I've expressed\nthem using matrix notation.",
    "start": "1016960",
    "end": "1023990"
  },
  {
    "text": "So let me just go through these\nexactly the same assumptions we saw in the bivariate model.",
    "start": "1023990",
    "end": "1030369"
  },
  {
    "text": "Here I'm using matrix notation. So I'll just go through and\nshow you what they mean. So first of all, expectation\nof epsilon is equal to 0.",
    "start": "1030369",
    "end": "1042010"
  },
  {
    "text": "Epsilon is a vector. And so it's just equal\nto a vector of zeros.",
    "start": "1042010",
    "end": "1047679"
  },
  {
    "text": "And then for some\nreason, we often write instead of\nwriting the assumption",
    "start": "1047680",
    "end": "1055330"
  },
  {
    "text": "as the covariance\nmatrix of epsilon equals sigma squared\ntimes the identity, the n",
    "start": "1055330",
    "end": "1062050"
  },
  {
    "text": "by n identity\nmatrix, we write it as the expectation of\nepsilon epsilon transpose",
    "start": "1062050",
    "end": "1068000"
  },
  {
    "text": "is equal to that. Well, it turns out because\nthe expectation of epsilon",
    "start": "1068000",
    "end": "1073100"
  },
  {
    "text": "is identically equal to 0, this\nmatrix is equal to this matrix.",
    "start": "1073100",
    "end": "1081200"
  },
  {
    "text": "You can do the calculations. It's just two lines\nto convince yourself. But I could have\nexpressed this assumption",
    "start": "1081200",
    "end": "1088400"
  },
  {
    "text": "by just saying that this\nmatrix is equal to this. But for whatever\nreason, we often",
    "start": "1088400",
    "end": "1096169"
  },
  {
    "text": "see it written as this matrix\nis equal to this, same thing.",
    "start": "1096170",
    "end": "1102650"
  },
  {
    "text": "Does everyone understand why\nthis matrix equaling this",
    "start": "1102650",
    "end": "1108590"
  },
  {
    "text": "is exactly the same\nassumptions we saw before? So this matrix is\njust simply a matrix",
    "start": "1108590",
    "end": "1116720"
  },
  {
    "text": "containing the variances of\nthe epsilons on the diagonal. So remember before we\nsaid each epsilon had",
    "start": "1116720",
    "end": "1123470"
  },
  {
    "text": "variance sigma squared? That was our\nhomoscedasticity assumption. So each variance\nis sigma squared.",
    "start": "1123470",
    "end": "1130080"
  },
  {
    "text": "And then all the\ncovariances were 0. That was our no serial\ncorrelation assumption.",
    "start": "1130080",
    "end": "1136590"
  },
  {
    "text": "All of the off\ndiagonals here are 0. So it's the same thing,\njust in matrix form.",
    "start": "1136590",
    "end": "1141875"
  },
  {
    "start": "1141875",
    "end": "1149740"
  },
  {
    "text": "Yeah, I think I\nsaid this verbally. But this thing is denoted\ncovariance of epsilon.",
    "start": "1149740",
    "end": "1157300"
  },
  {
    "text": "And it's called the\nvariance-covariance matrix of epsilon. ",
    "start": "1157300",
    "end": "1163980"
  },
  {
    "text": "OK, fine. We've got this linear model. We've got these assumptions. Just like before, we're going\nto now ask the question,",
    "start": "1163980",
    "end": "1170769"
  },
  {
    "text": "how do we get beta hat? And what distribution\ndoes beta hat have? And the answers are not\ngoing to be surprising.",
    "start": "1170770",
    "end": "1177070"
  },
  {
    "text": "But they're going to be\nmore beautiful than they were last time. So what is beta hat?",
    "start": "1177070",
    "end": "1182549"
  },
  {
    "text": "Well, it's a vector\nthat minimizes the sum of squared errors. So we've got a vector\nof residuals transpose",
    "start": "1182550",
    "end": "1191760"
  },
  {
    "text": "times a vector of residuals. And that's sort of expanded\nout what it looks like.",
    "start": "1191760",
    "end": "1200220"
  },
  {
    "text": "OK, so we want to\nchoose the beta hat that minimizes that thing. So what we do is we take\nthe derivative with respect",
    "start": "1200220",
    "end": "1207450"
  },
  {
    "text": "to beta, set it equal\nto 0, and obtain this.",
    "start": "1207450",
    "end": "1213269"
  },
  {
    "text": "If you're not used\nto doing calculus with vectors and matrices, in\nthe notes that I posted online,",
    "start": "1213270",
    "end": "1220860"
  },
  {
    "text": "I write this out in more detail. And you can take a look\nat that if you want. But basically, we get this sort\nof equation set equal to 0.",
    "start": "1220860",
    "end": "1233950"
  },
  {
    "text": "And this is going\nto tell us what the beta hat that minimizes the\nsum of squared residuals is.",
    "start": "1233950",
    "end": "1240070"
  },
  {
    "text": "Then we solve for beta hat. The negative 2 we can\njust divide both sides",
    "start": "1240070",
    "end": "1246309"
  },
  {
    "text": "by negative 2. And so that goes away. Then we write this\nequation as x prime y,",
    "start": "1246310",
    "end": "1254140"
  },
  {
    "text": "or x transpose y equals x\ntranspose x times beta hat.",
    "start": "1254140",
    "end": "1259660"
  },
  {
    "text": "And then if this is invertible-- and remember, that was\none of our assumptions.",
    "start": "1259660",
    "end": "1266680"
  },
  {
    "text": "That was our\nidentification assumption, that that thing was invertible. If that's invertible,\nthen we get that beta hat",
    "start": "1266680",
    "end": "1273640"
  },
  {
    "text": "is just equal to x prime\nx inverse x prime y. ",
    "start": "1273640",
    "end": "1280610"
  },
  {
    "text": "Beautiful. ",
    "start": "1280610",
    "end": "1291600"
  },
  {
    "text": "I mean, that was\nliterally the derivation of the least squares\nestimators in matrix notation.",
    "start": "1291600",
    "end": "1297070"
  },
  {
    "text": "If you look at my notes\nthat I've posted online, I mean, it's just pages of\nalgebra using that summation",
    "start": "1297070",
    "end": "1303269"
  },
  {
    "text": "notation. So this is why we love\ndoing it in matrix notation.",
    "start": "1303270",
    "end": "1309540"
  },
  {
    "text": "What do we want to\nknow about beta hat? What do we always want to\nknow about an estimator, so we can do inference?",
    "start": "1309540",
    "end": "1316620"
  },
  {
    "text": "It's distribution. Oh, it's right up there.",
    "start": "1316620",
    "end": "1321930"
  },
  {
    "text": "OK, fine. So the expectation of\nbeta hat is equal to beta.",
    "start": "1321930",
    "end": "1327179"
  },
  {
    "text": "Again, in matrix notation,\nit's very simple. I haven't included the four\nlines or something like that.",
    "start": "1327180",
    "end": "1333910"
  },
  {
    "text": "But if you treat\nthe x's as fixed, then that makes the sort\nof proof very simple.",
    "start": "1333910",
    "end": "1341760"
  },
  {
    "text": "They come outside the\nexpectation operator and basically just falls out.",
    "start": "1341760",
    "end": "1347020"
  },
  {
    "text": "So it is unbiased. And the covariance\nof beta hat, remember",
    "start": "1347020",
    "end": "1352990"
  },
  {
    "text": "this is the\nvariance-covariance matrix. So it's the matrix that\nhas along the diagonal",
    "start": "1352990",
    "end": "1359110"
  },
  {
    "text": "the variances of\neach of the beta hats and on the off diagonals,\nthe covariances between them.",
    "start": "1359110",
    "end": "1364750"
  },
  {
    "text": "That is just equal to\nsigma squared times x prime x inverse.",
    "start": "1364750",
    "end": "1371980"
  },
  {
    "text": "So again, very elegant, very\nbeautiful, and not too hard to show if you treat\nthe x's as fixed.",
    "start": "1371980",
    "end": "1379120"
  },
  {
    "text": "And you can look on the\nwebsite if you're interested. ",
    "start": "1379120",
    "end": "1385030"
  },
  {
    "text": "And finally, we often don't\nknow what sigma squared is. For inference, we need to\nknow what sigma squared is",
    "start": "1385030",
    "end": "1392650"
  },
  {
    "text": "or we need an estimate\nfor sigma squared. So this is our unbiased\nestimate for sigma squared.",
    "start": "1392650",
    "end": "1400399"
  },
  {
    "text": "And as Esther\nanticipated, here we",
    "start": "1400400",
    "end": "1405820"
  },
  {
    "text": "have to subtract off\na k instead of a 2 because instead of it\nbeing a bivariate model,",
    "start": "1405820",
    "end": "1413260"
  },
  {
    "text": "it's a multivariate model. ",
    "start": "1413260",
    "end": "1419220"
  },
  {
    "text": "And then finally, if we're\nwilling to impose the more",
    "start": "1419220",
    "end": "1424679"
  },
  {
    "text": "strict assumption on\nthe error distribution, the errors are\nnormally distributed,",
    "start": "1424680",
    "end": "1430390"
  },
  {
    "text": "then the beta hats are\nalso normally distributed. So sometimes we\nwant to impose that. Sometimes we want to\nbe less proscriptive.",
    "start": "1430390",
    "end": "1441150"
  },
  {
    "text": "OK, so now, finally\nwe get to inference. So typically, in\nthe linear model,",
    "start": "1441150",
    "end": "1447900"
  },
  {
    "text": "we're going to want to test\nhypotheses involving the betas. That's where the real action is. I mean, I can dream up\nhypotheses involving sigma",
    "start": "1447900",
    "end": "1455880"
  },
  {
    "text": "squared and things like that. And that's fine. And occasionally, you might want\nto test a hypothesis involving",
    "start": "1455880",
    "end": "1461610"
  },
  {
    "text": "sigma squared. But really we care\nabout the betas because the betas\nare the parameters in our conditional mean function\nof our outcome variable.",
    "start": "1461610",
    "end": "1469260"
  },
  {
    "text": "And the questions\nthat we usually want to answer using\nlinear regression are about the nature of this\nconditional mean function.",
    "start": "1469260",
    "end": "1477659"
  },
  {
    "text": "So sometimes we might only be\ninterested in one of the betas. Other times we might want to\nsimultaneously test hypotheses",
    "start": "1477660",
    "end": "1485310"
  },
  {
    "text": "about a whole bunch of them. And as we saw in the output\nthat I showed you last lecture,",
    "start": "1485310",
    "end": "1492510"
  },
  {
    "text": "statistical packages typically\nperform some standard tests on the betas for free and just\nreport them with the output.",
    "start": "1492510",
    "end": "1503260"
  },
  {
    "text": "And that's fine. And we can use those. And they're often quite handy.",
    "start": "1503260",
    "end": "1508309"
  },
  {
    "text": "But there may be other ones\nthat we need to do ourselves. So they don't perform\nevery conceivable test",
    "start": "1508310",
    "end": "1514540"
  },
  {
    "text": "we might be interested in. OK, so let's start with a\npretty general framework",
    "start": "1514540",
    "end": "1521610"
  },
  {
    "text": "for testing\nhypotheses about beta. And it's not only quite\ngeneral and flexible.",
    "start": "1521610",
    "end": "1527380"
  },
  {
    "text": "It's also super intuitive. It's one of my favorite tests. I really like it. OK, so let's consider hypotheses\nof the following form.",
    "start": "1527380",
    "end": "1536400"
  },
  {
    "text": "A matrix r times beta\nis equal to a vector c. That's the null hypothesis.",
    "start": "1536400",
    "end": "1542730"
  },
  {
    "text": "The alternative is that it's\nnot equal to the vector c. So what is this matrix r?",
    "start": "1542730",
    "end": "1549150"
  },
  {
    "text": "It's a matrix of restrictions. And its dimensions\nare r by k plus 1.",
    "start": "1549150",
    "end": "1556830"
  },
  {
    "text": "So it has the number of-- so the number of columns\nequal to the number",
    "start": "1556830",
    "end": "1563730"
  },
  {
    "text": "of parameters, the\nnumber of betas that we're estimating\nin the linear model. And then the number of rows\nis the number of restrictions",
    "start": "1563730",
    "end": "1570720"
  },
  {
    "text": "that we want to impose\nin our null hypothesis, the number of restrictions\nwe want to test.",
    "start": "1570720",
    "end": "1578020"
  },
  {
    "text": "So we could have a matrix,\nwhere r is equal to 1. And then we're just\ntesting one restriction.",
    "start": "1578020",
    "end": "1584380"
  },
  {
    "text": "So that would\ncorrespond to something like beta 1 is equal to 0. ",
    "start": "1584380",
    "end": "1593440"
  },
  {
    "text": "Oh, so let me just say this. I'll get to some\nexamples in a minute. So almost any\nhypothesis involving",
    "start": "1593440",
    "end": "1599710"
  },
  {
    "text": "beta you can dream up in the\ncontext of a linear model can be captured in\nthis framework, not quite any, but most of them.",
    "start": "1599710",
    "end": "1606550"
  },
  {
    "text": "You can test whether individual\nparameters are equal to 0. You can test whether\nindividual parameters",
    "start": "1606550",
    "end": "1611770"
  },
  {
    "text": "are equal to something\nother than 0. You can test multiple\nhypotheses simultaneously.",
    "start": "1611770",
    "end": "1616870"
  },
  {
    "text": "You can test hypotheses\nabout linear combinations of parameters. The world is your oyster.",
    "start": "1616870",
    "end": "1622600"
  },
  {
    "text": "So let me show you a\nfew examples of these and exactly what the\nr matrix looks like",
    "start": "1622600",
    "end": "1628510"
  },
  {
    "text": "and what the c vector looks\nlike in these examples. OK, so let's say, for instance,\nthat we set up the matrix",
    "start": "1628510",
    "end": "1639910"
  },
  {
    "text": "r to be just a row vector\nwith a 0 in the first spot,",
    "start": "1639910",
    "end": "1645370"
  },
  {
    "text": "and then a 1, and\nthen the rest 0s. So what that matrix is doing\nis it's picking out beta 1.",
    "start": "1645370",
    "end": "1652990"
  },
  {
    "text": "Remember, this spot\ncorresponds to beta 0.",
    "start": "1652990",
    "end": "1658809"
  },
  {
    "text": "So being in the second spot,\nit's picking out beta 1. And c is just what beta 1\nis equal to under the null.",
    "start": "1658810",
    "end": "1669669"
  },
  {
    "text": "So that r and this c\ncorresponds to the hypothesis that beta 1 is equal to 0.",
    "start": "1669670",
    "end": "1675955"
  },
  {
    "text": " Let's suppose\ninstead that we want",
    "start": "1675955",
    "end": "1683010"
  },
  {
    "text": "to test a whole\nbunch of hypotheses simultaneously, that\nbeta 1 is equal to 0,",
    "start": "1683010",
    "end": "1689790"
  },
  {
    "text": "and beta 2 is equal\nto 0, and beta 3 is equal to 0, et cetera. Well, then this is what\nour matrix would look like.",
    "start": "1689790",
    "end": "1697990"
  },
  {
    "text": "So it would basically be an\nidentity matrix with a column of 0's tacked on the front.",
    "start": "1697990",
    "end": "1704492"
  },
  {
    "text": "And the reason why the column\nof 0's is tacked on the front is because that corresponds\nto the intercept.",
    "start": "1704492",
    "end": "1709769"
  },
  {
    "text": "And we're not\ninterested at least here in testing a hypothesis\nabout the intercept.",
    "start": "1709770",
    "end": "1716640"
  },
  {
    "text": "And then the c vector\nis just a vector of 0's. ",
    "start": "1716640",
    "end": "1725380"
  },
  {
    "text": "So I do want to emphasize, even\nthough I've sort of written this as like one\nequation, this is actually",
    "start": "1725380",
    "end": "1732400"
  },
  {
    "text": "we're testing k hypotheses\nsimultaneously here. So we have k equal signs.",
    "start": "1732400",
    "end": "1737530"
  },
  {
    "start": "1737530",
    "end": "1742730"
  },
  {
    "text": "OK, so here's a more\ncomplicated example. If our r matrix has in the\nfirst row a 1 and a negative 1,",
    "start": "1742730",
    "end": "1753020"
  },
  {
    "text": "and then the rest 0's, sorry,\n0, and then 1, negative 1, the rest 0's. And then the second\nrow there's a 1",
    "start": "1753020",
    "end": "1761090"
  },
  {
    "text": "in the fourth spot, et cetera. And then the c vector\nlooks like this.",
    "start": "1761090",
    "end": "1769020"
  },
  {
    "text": "What does this\ncorrespond to in terms of a hypothesis we might want a\ntest or a series of hypotheses?",
    "start": "1769020",
    "end": "1776299"
  },
  {
    "text": "Well, here, the first row\ngives us the hypothesis that beta 1 minus\nbeta 2 is equal to 0.",
    "start": "1776300",
    "end": "1785810"
  },
  {
    "text": "So I could just write that\nas beta 1 is equal to beta 2. The second row\ncorresponds to beta 3--",
    "start": "1785810",
    "end": "1793880"
  },
  {
    "text": "this is beta 3 here--\nbeing equal to 5. And the third row\ncorresponds to beta k",
    "start": "1793880",
    "end": "1801840"
  },
  {
    "text": "being equal to negative 2. Yes. STUDENT: Can you explain\nthe beta 1 equals beta 2?",
    "start": "1801840",
    "end": "1808700"
  },
  {
    "text": "SARA ELLISON: OK, so if I just\nmultiply the matrix, the r",
    "start": "1808700",
    "end": "1818149"
  },
  {
    "text": "matrix, by beta and sort of\nwrote these out as equations, I would get beta 1 minus--",
    "start": "1818150",
    "end": "1826070"
  },
  {
    "text": "so this is beta 0 here. So here's beta 1 minus\nbeta 2 is equal to 0.",
    "start": "1826070",
    "end": "1834620"
  },
  {
    "text": "And then I just rewrote that\nas beta 1 is equal to beta 2. That's all. Yep. STUDENT: How often are we\n[INAUDIBLE] specific value",
    "start": "1834620",
    "end": "1842870"
  },
  {
    "text": "rather than the range? And is there a\n[INAUDIBLE] against that? SARA ELLISON: So yes and no.",
    "start": "1842870",
    "end": "1850280"
  },
  {
    "text": "So basically, if we're\nnot interested in--",
    "start": "1850280",
    "end": "1856520"
  },
  {
    "text": "if we're interested in\nwhether beta is in a range, then what we might\nwant to do is instead of doing a hypothesis\ntest, where",
    "start": "1856520",
    "end": "1863690"
  },
  {
    "text": "the null was a single\nvalue and the alternative was everything\nelse, we might want to do, say, a one-sided test,\nwhere the null is that beta",
    "start": "1863690",
    "end": "1871010"
  },
  {
    "text": "is less than some value\nand the alternative is that it's greater\nthan some value. We can do those.",
    "start": "1871010",
    "end": "1877040"
  },
  {
    "text": "We can't do them\nin this framework. So I'll talk about\nthat in a second. The other thing that\nyou might be suggesting",
    "start": "1877040",
    "end": "1883880"
  },
  {
    "text": "is instead of doing\nhypothesis testing, we might want to just report\nconfidence intervals as well.",
    "start": "1883880",
    "end": "1889679"
  },
  {
    "text": "So remember that\nreally hypothesis testing and constructing\nconfidence intervals",
    "start": "1889680",
    "end": "1894740"
  },
  {
    "text": "are kind of the same thing. It's just reporting the same\ninformation in different forms. And so it can just be a\nmatter of style or preference.",
    "start": "1894740",
    "end": "1905929"
  },
  {
    "text": "Instead of reporting\nhypothesis tests, you report confidence intervals. And that's perfectly fine.",
    "start": "1905930",
    "end": "1912570"
  },
  {
    "text": "Yeah. ESTHER DUFLO: So\nconfidence interval, it can be harder to say\nwhether between the [INAUDIBLE]",
    "start": "1912570",
    "end": "1918039"
  },
  {
    "text": "minus [? 4 ?] is [INAUDIBLE]. I mean, it's kind\nof hard to see.",
    "start": "1918040",
    "end": "1924580"
  },
  {
    "text": "They don't really add up. SARA ELLISON: Yeah, and I guess\nthe other more fundamental",
    "start": "1924580",
    "end": "1929790"
  },
  {
    "text": "answer to your question is\nthat sometimes we actually do-- there might be a\ntheory that says beta",
    "start": "1929790",
    "end": "1936480"
  },
  {
    "text": "should be equal to this number. And in order to\ntest that theory, we want to perform a\nhypothesis test that beta",
    "start": "1936480",
    "end": "1942990"
  },
  {
    "text": "is equal to that number. So that does come\nup, not every case.",
    "start": "1942990",
    "end": "1948090"
  },
  {
    "text": "But yeah, it is relevant. Other questions? No.",
    "start": "1948090",
    "end": "1954149"
  },
  {
    "text": "STUDENT: You could also use\nit to if somebody came out with a paper today describing\nthe treatment of malaria",
    "start": "1954150",
    "end": "1960760"
  },
  {
    "text": "[INAUDIBLE] wanted to see\nif that was true or not, just take that beta and test for\nit and do hypothesis testing?",
    "start": "1960760",
    "end": "1967220"
  },
  {
    "text": "SARA ELLISON: Yeah. STUDENT: OK.  SARA ELLISON: OK,\noh, here's part",
    "start": "1967220",
    "end": "1975418"
  },
  {
    "text": "of the answer to your question. One thing you can't\ndo in this framework is test one-sided hypotheses. We'll get back to those.",
    "start": "1975418",
    "end": "1983370"
  },
  {
    "text": "So now we have this framework. I mean, it's not really\na framework, just",
    "start": "1983370",
    "end": "1989400"
  },
  {
    "text": "sort of a notation\nin some sense to deal with hypotheses of all of the\nforms we just talked about.",
    "start": "1989400",
    "end": "1998880"
  },
  {
    "text": "And within the\nregression framework, we have a super\nintuitive and cool way to test these hypotheses.",
    "start": "1998880",
    "end": "2005250"
  },
  {
    "text": "So first of all, let's\nthink of the null as describing a set of\nrestrictions on the model.",
    "start": "2005250",
    "end": "2011779"
  },
  {
    "text": "So let me just go\nback for a second. So in this case, this null has\nthree different restrictions,",
    "start": "2011780",
    "end": "2019370"
  },
  {
    "text": "that beta 1 is equal to beta\n2, that beta 3 is equal to 5, and that beta k is\nequal to minus 2.",
    "start": "2019370",
    "end": "2025490"
  },
  {
    "text": "And we think of the null\nas imposing restrictions on the model.",
    "start": "2025490",
    "end": "2030580"
  },
  {
    "text": "Then here's how we\nperform the test. We estimate the\nunrestricted model.",
    "start": "2030580",
    "end": "2035649"
  },
  {
    "text": "We impose the\nrestrictions of the null and estimate that model. And then we compare the goodness\nof fit of those two models.",
    "start": "2035650",
    "end": "2044049"
  },
  {
    "text": "So that's why I love this test. It seems really intuitive\nto me that if you",
    "start": "2044050",
    "end": "2050050"
  },
  {
    "text": "have a set of restrictions\nand they really bind, and they really sort of affect\nhow good your fit is, then",
    "start": "2050050",
    "end": "2058750"
  },
  {
    "text": "that tells you, well, maybe\nthose restrictions are not true.",
    "start": "2058750",
    "end": "2063850"
  },
  {
    "text": "If the restrictions\non the other hand don't really bind that much,\nif your model fits almost as",
    "start": "2063850",
    "end": "2073210"
  },
  {
    "text": "well with the\nrestricted model as it does with the\nunrestricted model, then",
    "start": "2073210",
    "end": "2078638"
  },
  {
    "text": "that tells you maybe\nthese restrictions are true or close to true. And we don't want\nto reject them.",
    "start": "2078639",
    "end": "2084129"
  },
  {
    "text": "So that's the whole intuition\nand the idea behind this test. ",
    "start": "2084130",
    "end": "2091138"
  },
  {
    "text": "OK, so a couple of\ndetails before we",
    "start": "2091139",
    "end": "2097530"
  },
  {
    "text": "get to the distribution,\nthe test statistic. Estimating the unrestricted\nmodel is simple. Just run the regression.",
    "start": "2097530",
    "end": "2103500"
  },
  {
    "text": "But how do we estimate\nthe restricted model? Well, it depends on what\nform the restrictions take.",
    "start": "2103500",
    "end": "2110230"
  },
  {
    "text": "So let's say we're\ntesting hypothesis, where just a bunch of\nthe betas are equal to 0.",
    "start": "2110230",
    "end": "2115650"
  },
  {
    "text": "How do we run the\nrestricted model? ",
    "start": "2115650",
    "end": "2122839"
  },
  {
    "text": "Yes. STUDENT: We just\nthink the [INAUDIBLE] is kind of on the diagonal\n1 so that [INAUDIBLE]..",
    "start": "2122840",
    "end": "2128760"
  },
  {
    "text": "SARA ELLISON: Yes, exactly. So practically speaking,\nwhat we do is we just run",
    "start": "2128760",
    "end": "2134070"
  },
  {
    "text": "the regression leaving\nout all of those x's. So that's the way we constrain\nthe coefficients to be",
    "start": "2134070",
    "end": "2140940"
  },
  {
    "text": "equal to 0. So we have the unrestricted. The unrestricted\nregression is just",
    "start": "2140940",
    "end": "2147060"
  },
  {
    "text": "all of the x's are in there. If we want to restrict that\ncertain betas are equal to 0, we just run another regression,\nwhere we leave out the x's",
    "start": "2147060",
    "end": "2156299"
  },
  {
    "text": "associated with the betas that\nwe want to have equal to 0. So that's our restricted model.",
    "start": "2156300",
    "end": "2165280"
  },
  {
    "text": "Then let's say\nthe restriction is that the two betas are equal.",
    "start": "2165280",
    "end": "2170829"
  },
  {
    "text": "We have beta 1 equals beta\n2, or something like that. That's our null restriction.",
    "start": "2170830",
    "end": "2176240"
  },
  {
    "text": "Then how do we impose that\nrestriction on a linear model? Well, actually, it might help\nif I write the linear model.",
    "start": "2176240",
    "end": "2185180"
  },
  {
    "text": "So we have y sub i equals\nbeta 0 plus beta 1 x1.",
    "start": "2185180",
    "end": "2195502"
  },
  {
    "text": "I hope I'm using\nthe same notation.  Do I have my subscripts\nin the same order?",
    "start": "2195502",
    "end": "2203140"
  },
  {
    "text": "I hope so. ",
    "start": "2203140",
    "end": "2208750"
  },
  {
    "text": "OK, so let's suppose this\nis our unrestricted model.",
    "start": "2208750",
    "end": "2216040"
  },
  {
    "text": "We want to restrict beta\n1 to be equal to beta 2. Well, what do we do?",
    "start": "2216040",
    "end": "2221119"
  },
  {
    "text": "We just create a new variable\nthat's the sum of these two.",
    "start": "2221120",
    "end": "2226820"
  },
  {
    "text": "So this is called x1i plus\nx2i, just a new variable.",
    "start": "2226820",
    "end": "2236680"
  },
  {
    "text": "And then we only estimate\none coefficient on that.",
    "start": "2236680",
    "end": "2243800"
  },
  {
    "text": "So our restricted\nmodel is just that we don't include this variable as\na regressor or this variable",
    "start": "2243800",
    "end": "2250569"
  },
  {
    "text": "as a regressor. We include their\nsum as a regressor. And that's how we're\nimposing the null restriction",
    "start": "2250570",
    "end": "2257680"
  },
  {
    "text": "because when we\ninclude their sum, we're making their two\ncoefficients equal.",
    "start": "2257680",
    "end": "2262690"
  },
  {
    "text": "We're forcing their two\ncoefficients to be equal. Yeah. STUDENT: So are we\ntesting the first beta",
    "start": "2262690",
    "end": "2269350"
  },
  {
    "text": "1 and the second\nbeta 1 are the same? SARA ELLISON: Exactly, yes. This is testing the hypothesis\nthat beta 1 is equal to beta 2.",
    "start": "2269350",
    "end": "2280650"
  },
  {
    "text": "Yep. STUDENT: Is that different from\ntesting the beta 2 [? at 0? ?] SARA ELLISON: Yeah, it's\ndefinitely different.",
    "start": "2280650",
    "end": "2287619"
  },
  {
    "text": "So here, these betas\ncould be anything. They could be a million.",
    "start": "2287620",
    "end": "2294832"
  },
  {
    "text": "We're just testing the\nhypothesis that they're equal. ",
    "start": "2294832",
    "end": "2300800"
  },
  {
    "text": "Yes.  STUDENT: But if they're\nequal, wouldn't it",
    "start": "2300800",
    "end": "2306020"
  },
  {
    "text": "be like a linear combination\nof the ther [INAUDIBLE]?? You know how they cannot\nbe like a linear sum?",
    "start": "2306020",
    "end": "2314173"
  },
  {
    "text": " SARA ELLISON: I'm not sure if\nI understand your question.",
    "start": "2314173",
    "end": "2320920"
  },
  {
    "text": "So basically, what\nI'm trying to do here is impose just this\nhypothesis, but not",
    "start": "2320920",
    "end": "2326920"
  },
  {
    "text": "impose anything else about what\nthe betas might be equal to. STUDENT: The\nidentification restriction",
    "start": "2326920",
    "end": "2334210"
  },
  {
    "text": "is not on the betas. It's on the x's. Beta can have whatever\nmedium conditions.",
    "start": "2334210",
    "end": "2341032"
  },
  {
    "text": "SARA ELLISON: Ah,\nyou were confused about the identification\nassumption. Yep, yep, yep, that's right. ",
    "start": "2341032",
    "end": "2348252"
  },
  {
    "text": "ESTHER DUFLO: You can\nreask your question saying, if you could\npost the sum on just x",
    "start": "2348252",
    "end": "2353660"
  },
  {
    "text": "and it turned out that\nin fact they were equal, you can guess what the beta\n[INAUDIBLE] following x.",
    "start": "2353660",
    "end": "2360128"
  },
  {
    "text": " SARA ELLISON: OK, what\nif the restriction",
    "start": "2360128",
    "end": "2365420"
  },
  {
    "text": "is that some beta is\nequal to a constant c? How would we impose\nthat restriction",
    "start": "2365420",
    "end": "2372140"
  },
  {
    "text": "and then re-estimate\nthe restricted model? Well, let's suppose\nthis is just a constant.",
    "start": "2372140",
    "end": "2379740"
  },
  {
    "text": "So we impose that this one\nis equal to a constant. So then here, there's no\nparameter in this term",
    "start": "2379740",
    "end": "2387860"
  },
  {
    "text": "that we need to\nestimate under the null. So we just subtract\nthe constant times x1",
    "start": "2387860",
    "end": "2394520"
  },
  {
    "text": "from the dependent variable\nand rerun that regression. And that's our\nrestricted regression.",
    "start": "2394520",
    "end": "2401960"
  },
  {
    "text": "Does that make sense? OK, so going back, we estimate\nthe unrestricted model.",
    "start": "2401960",
    "end": "2410539"
  },
  {
    "text": "We impose restrictions\nand estimate that model. And then we compare\nthe goodness of fit. And if the goodness of\nfit is not very different,",
    "start": "2410540",
    "end": "2419400"
  },
  {
    "text": "we don't reject the null. If it's very different,\nwe reject the null. In particular, this\ntest statistic,",
    "start": "2419400",
    "end": "2427180"
  },
  {
    "text": "which is basically the\nnumerator has the difference in the sum of the restricted\nand unrestricted sum of squares",
    "start": "2427180",
    "end": "2436590"
  },
  {
    "text": "and then in the denominator\nhas the unrestricted sum of squares. This is how we form\nthe test statistic.",
    "start": "2436590",
    "end": "2442829"
  },
  {
    "text": "And it turns out that has an\nF distribution under the null. And we reject the null for large\nvalues of this test statistic.",
    "start": "2442830",
    "end": "2453510"
  },
  {
    "start": "2453510",
    "end": "2459000"
  }
]
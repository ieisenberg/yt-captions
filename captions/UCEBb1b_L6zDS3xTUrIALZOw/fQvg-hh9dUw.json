[
  {
    "start": "0",
    "end": "188000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6760"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6760",
    "end": "13390"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at OCW.mit.edu.",
    "start": "13390",
    "end": "18570"
  },
  {
    "start": "18570",
    "end": "29750"
  },
  {
    "text": "PROFESSOR: Welcome back. I hope you didn't spend\ntime doing 6002 problem",
    "start": "29750",
    "end": "36370"
  },
  {
    "text": "sets while eating turkey. It's not recommended\nfor digestion. But I hope you're ready to go\nback into diving into material.",
    "start": "36370",
    "end": "43650"
  },
  {
    "text": "And since it's been a week\nsince we got together, let me remind you of\nwhat we were doing.",
    "start": "43650",
    "end": "49430"
  },
  {
    "text": "We were looking at the\nissue of how to understand experimental data.",
    "start": "49430",
    "end": "55160"
  },
  {
    "text": "Data could come from\na physical experiment. We had the example of\nmeasuring the spring constant of a linear spring.",
    "start": "55160",
    "end": "61760"
  },
  {
    "text": "Could come from biological data. Could come from social data. And what we looked\nout was the idea",
    "start": "61760",
    "end": "67040"
  },
  {
    "text": "of how do we actually\nfit models to that data in order to understand them.",
    "start": "67040",
    "end": "73770"
  },
  {
    "text": "So what I want to do is I want\nto start with that high level reminder of what we were after. I want to do about\na five minute recap",
    "start": "73770",
    "end": "80459"
  },
  {
    "text": "of what we were doing last time,\nbecause it has been a while. And then we're\ngoing to talk about how do you actually\nvalidate models",
    "start": "80459",
    "end": "86237"
  },
  {
    "text": "that you're fitting to data to\nunderstand are they really good fits or not. And if you remember.",
    "start": "86237",
    "end": "91460"
  },
  {
    "text": "I know you spend all your\ntime thinking about 6002. You should remember I\nleft you with a puzzle, where I fit data to--",
    "start": "91460",
    "end": "97930"
  },
  {
    "text": "sorry, fit models\nto some noisy data. And there was a question\nof, did the model really have an order 16 fit?",
    "start": "97930",
    "end": "105052"
  },
  {
    "text": "Right, so what are\nwe trying to do? Remember, our goal is to try\nand model experimental data.",
    "start": "105052",
    "end": "111040"
  },
  {
    "text": "And really what we want to do is\nhave a model that both explains the phenomena\nunderlying what we see,",
    "start": "111040",
    "end": "117460"
  },
  {
    "text": "gives us a sense of what\nmight be the underlying physical mechanism, the\nunderlying social mechanism,",
    "start": "117460",
    "end": "122950"
  },
  {
    "text": "and can let us make\npredictions about the behavior in new settings. In the case of my spring,\nbeing able to predict",
    "start": "122950",
    "end": "129970"
  },
  {
    "text": "what will the displacement\nbe when I actually put a different weight on it\nthan something I measured. Or if you want to think\nfrom a design perspective,",
    "start": "129970",
    "end": "137180"
  },
  {
    "text": "working the other\ndirection and saying, I don't want my spring to\ndeflect more than this amount under certain kinds of weights.",
    "start": "137180",
    "end": "143530"
  },
  {
    "text": "So how do I use the\nmodel to tell me what the spring constant\nshould be for the spring I want in that case?",
    "start": "143530",
    "end": "149940"
  },
  {
    "text": "So we want to be able to predict\nbehavior in new settings. The last piece we know is\nthat, if the data was perfect,",
    "start": "149940",
    "end": "156860"
  },
  {
    "text": "this is easy. But it ain't. There's always\ngoing to be noise. There's always going to be\nexperimental uncertainty.",
    "start": "156860",
    "end": "162596"
  },
  {
    "text": "And so I really want to\naccount for that uncertainty when I fit that model. And while sometimes I'll have\ntheories that will help--",
    "start": "162596",
    "end": "170560"
  },
  {
    "text": "Hooke says models of\nsprings are linear-- in some cases, I don't. And in those cases, I want to\nactually try and figure out",
    "start": "170560",
    "end": "177830"
  },
  {
    "text": "what's the best model\nto fit even when I don't know what the theory tells me.",
    "start": "177830",
    "end": "183530"
  },
  {
    "text": "OK, so quick recap, what\ndo we use to solve this? So we've got a set\nof observed values.",
    "start": "183530",
    "end": "190370"
  },
  {
    "start": "188000",
    "end": "188000"
  },
  {
    "text": "My spring case for different\ndisplays for different masses I measured the displacements. Those displacements\nare my observed values.",
    "start": "190370",
    "end": "197159"
  },
  {
    "text": "And if I had a model\nthat would predict what the displacement\nshould be, I",
    "start": "197160",
    "end": "202520"
  },
  {
    "text": "can measure how good the fit is\nby looking at that expression right there, the\nsum of the squares of the differences between\nthe observed and the",
    "start": "202520",
    "end": "209180"
  },
  {
    "text": "predicted data. As I said, we could\nuse other measures. We could use a first\norder and absolute value.",
    "start": "209180",
    "end": "214356"
  },
  {
    "text": "The square is actually\nreally handy, because it makes the solution space\nvery easy to deal with, which we'll get to in a second.",
    "start": "214356",
    "end": "221060"
  },
  {
    "text": "So given observed\ndata, get a prediction. I can use the sum of\nsquared differences to measure how good the fit is.",
    "start": "221060",
    "end": "227560"
  },
  {
    "text": "And then the second\npiece is I now what to find what's the best\nway to predict the data.",
    "start": "227560",
    "end": "232580"
  },
  {
    "text": "What's the best curve\nthat fits the data. What's the best model for\nprotecting the values.",
    "start": "232580",
    "end": "237730"
  },
  {
    "text": "And we suggest that\nlast time, we'll focus on mathematical\nexpressions, polynomials.",
    "start": "237730",
    "end": "243940"
  },
  {
    "text": "Professor Guttag is so excited\nabout polynomial expressions, he's throwing\nlaptops on the floor. Please don't do\nthat to your laptop.",
    "start": "243940",
    "end": "250450"
  },
  {
    "text": "We're going to fit polynomials\nto these expressions. And since the polynomials\nhave some coefficients,",
    "start": "250450",
    "end": "257019"
  },
  {
    "text": "the game is basically,\nhow do I find the coefficients of\nthe polynomial that minimize that expression.",
    "start": "257019",
    "end": "263050"
  },
  {
    "text": "And that, we said, was an\nexample of linear regression. So let me just remind you\nwhat linear regression says.",
    "start": "263050",
    "end": "269560"
  },
  {
    "text": "Simple example,\ncase of the spring. I'm going to get a\ndegree 1 polynomial.",
    "start": "269560",
    "end": "274630"
  },
  {
    "text": "So that is something of\nthe form y is ax plus b. a and b are the three variables,\nthe parameters I can change.",
    "start": "274630",
    "end": "282729"
  },
  {
    "text": "And the idea is for every\nx, in the case of my spring, for every mass, I'm\ngoing to use that model",
    "start": "282730",
    "end": "288082"
  },
  {
    "text": "to predict what's\nthe displacement, measure the\ndifferences, and find the thing that minimizes it. So I just want to\nfind values of a and b",
    "start": "288082",
    "end": "294530"
  },
  {
    "text": "that let me predict values\nthat minimize that expression. As I suggested, you\ncould solve this.",
    "start": "294530",
    "end": "301210"
  },
  {
    "text": "You could write code to do it. It's a neat little\npiece of code to write. But fortunately, PiLab\nprovides that for you.",
    "start": "301210",
    "end": "307330"
  },
  {
    "text": "And I just want to give\nyou the visualization of what we're doing here. And then we're going\nto look at examples.",
    "start": "307330",
    "end": "313550"
  },
  {
    "text": "I'm going to try to\nfind the best line. It's represented by\ntwo values, a and b.",
    "start": "313550",
    "end": "318806"
  },
  {
    "text": "I could represent\nall possible lines in a space that has\none access with values",
    "start": "318806",
    "end": "325241"
  },
  {
    "start": "319000",
    "end": "319000"
  },
  {
    "text": "and the other access\nwith b values. Every point in that plane\ndefines a line for me.",
    "start": "325242",
    "end": "330720"
  },
  {
    "text": "Now imagine a surface laid over\nthis two dimensional space,",
    "start": "330720",
    "end": "336180"
  },
  {
    "text": "where the value or the\nheight of the surface is the value of that objective\nfunction at every point.",
    "start": "336180",
    "end": "341902"
  },
  {
    "text": "Don't worry about\ncomputing it all, but just imagine\nI could do that. And by the way, one\nof the nice things",
    "start": "341902",
    "end": "346930"
  },
  {
    "text": "about doing sum of squares\nis that surface always has a concave shape. And now the idea of\nlinear regression",
    "start": "346930",
    "end": "353800"
  },
  {
    "text": "is I'm going to start at\nsome point on that surface. And I'm just going\nto walk downhill",
    "start": "353800",
    "end": "359560"
  },
  {
    "text": "until I get to the bottom. There will always be\none bottom, one point. And once I get to that\npoint, that a and b value",
    "start": "359560",
    "end": "367830"
  },
  {
    "text": "tell me the best line. So it's called linear\nregression because I'm linearly walking downhill on this space.",
    "start": "367830",
    "end": "374380"
  },
  {
    "text": "Now I'm doing this for line\nwith two parameters a,b, because it's easy to visualize.",
    "start": "374380",
    "end": "380247"
  },
  {
    "text": "If you're a good mathematician\neven if you're not, you can generalize this to think\nabout arbitrary dimensions.",
    "start": "380247",
    "end": "385479"
  },
  {
    "text": "So a fourth order surface\nin a five dimensional space, for example, would solve\na cubic example of this.",
    "start": "385480",
    "end": "393619"
  },
  {
    "text": "That's the idea of\nlinear regression. That's what we're going to\nuse to actually figure out, to find the best solution.",
    "start": "393619",
    "end": "400280"
  },
  {
    "text": "So here was the example I used. I gave you a set of data. In about 3 slides,\nI'm going to tell you where the data came from.",
    "start": "400280",
    "end": "405641"
  },
  {
    "start": "402000",
    "end": "402000"
  },
  {
    "text": "But I give you a set of data. We could fit the best\nline to this using that linear regression idea.",
    "start": "405641",
    "end": "412580"
  },
  {
    "text": "And again, last piece\nof reminder, I'm going to use polyfit from PiLab.",
    "start": "412580",
    "end": "418094"
  },
  {
    "text": "It just solves that\nlinear regression problem. And I give it a set of x values. I give a corresponding\nset of y values,",
    "start": "418094",
    "end": "424319"
  },
  {
    "text": "need to be the same\nnumber in each case. And I give it a dimension. And in this case, one says,\nfind the best fitting line.",
    "start": "424320",
    "end": "432039"
  },
  {
    "text": "It will produce\nthat and return it as a tuple, which I'll store\nunder the name model 1. And I could plot it out.",
    "start": "432040",
    "end": "438070"
  },
  {
    "text": "So just remind you, polyfit\nwill find the best fitting n dimensional surface, n being\nthat last parameter there,",
    "start": "438070",
    "end": "445600"
  },
  {
    "text": "and return it. In a second, we're going to\nuse polyval, which will say, given that model and\na set of x values,",
    "start": "445600",
    "end": "452980"
  },
  {
    "text": "predict what the\ny value should be. Apply them.  OK, so I fit the line.",
    "start": "452980",
    "end": "460379"
  },
  {
    "text": "What do you think? Good fit? Not so much, right?",
    "start": "460380",
    "end": "465710"
  },
  {
    "text": "Pretty ugly. I mean, you can\nsee it's probably the best-- or not probably. It is the best fitting line.",
    "start": "465710",
    "end": "470890"
  },
  {
    "text": "It sort of accounts for the\nvariation on either side of it. But it's not a very good fit.",
    "start": "470890",
    "end": "476839"
  },
  {
    "text": "So then the question\nis, well why not try fitting a\nhigher order model? So I could fit a quadratic.",
    "start": "476839",
    "end": "483690"
  },
  {
    "text": "That is a second order model. y equals ax squared\nplus bx plus c.",
    "start": "483690",
    "end": "489000"
  },
  {
    "text": "Run the same code. Block that out. And I get that.",
    "start": "489000",
    "end": "494450"
  },
  {
    "text": "That's the linear model. There's the quadratic model.",
    "start": "494450",
    "end": "499700"
  },
  {
    "text": "At least my [? i ?] our\nlooks a lot better, right? It looks like it's following\nthat data reasonably well.",
    "start": "499700",
    "end": "506230"
  },
  {
    "text": "OK, I can fit a linear model. I can fit a quadratic model. What about higher order models?",
    "start": "506230",
    "end": "511600"
  },
  {
    "text": "What about a fourth order\nmodel, an eighth order model, a 644th order model? How do I know which one\nis going to be best?",
    "start": "511600",
    "end": "519865"
  },
  {
    "text": "So for that, I'm going to remind\nyou of the last thing we used. And then we're going to start\ntalking about how to use it further, which is if we\ntry fitting higher order",
    "start": "519865",
    "end": "526830"
  },
  {
    "text": "polynomials, do we\nget a better fit? And to do that, we\nneed to measure what",
    "start": "526830",
    "end": "532820"
  },
  {
    "text": "it means for the data to fit. If I don't have any\nother information.",
    "start": "532820",
    "end": "538360"
  },
  {
    "text": "For example, if I don't\nhave a theory that tells me this should be linear\nin the case afoot,",
    "start": "538360",
    "end": "543365"
  },
  {
    "text": "then the best way to do it\nis to use what's called, the coefficient of\ndetermination, r-squared.",
    "start": "543365",
    "end": "549300"
  },
  {
    "text": "It's a scale independent\nthing, which is good. By scale independent, I\nmean if I take all the data and stretch it out,\nthis will still",
    "start": "549300",
    "end": "555441"
  },
  {
    "text": "give me back the same\nvalue in terms of the fit. So it doesn't depend on\nthe size of the data. And what it does is it\nbasically tells me the",
    "start": "555441",
    "end": "562990"
  },
  {
    "text": "a value between\n0 and 1, how well does this model fit the data.",
    "start": "562990",
    "end": "568760"
  },
  {
    "text": "So just to remind\nyou, in this case, the y's are the\nmeasured values, the p's",
    "start": "568760",
    "end": "574720"
  },
  {
    "text": "are the predicted values. That's what my model is saying,\nfor each one of these cases. And mu down here is\nthe mean or the average",
    "start": "574720",
    "end": "582910"
  },
  {
    "text": "of the measured values. The way to think about this\nis this top expression here.",
    "start": "582910",
    "end": "588389"
  },
  {
    "text": "Well, that's exactly what I'm\ntrying to minimize, right? So it's giving me an\nestimate or a measure",
    "start": "588390",
    "end": "594630"
  },
  {
    "text": "of the error in the estimates\nbetween what the model says and what I actually measure.",
    "start": "594630",
    "end": "600510"
  },
  {
    "text": "And the denominator down\nhere basically tells me how much does the data\nvary away from the mean value.",
    "start": "600510",
    "end": "608440"
  },
  {
    "text": "Now here's the idea. If in fact, I can\nget this to 0, I",
    "start": "608440",
    "end": "614560"
  },
  {
    "text": "can get a model that completely\naccounts for all the variation in the estimates, that's great.",
    "start": "614560",
    "end": "620290"
  },
  {
    "text": "It says, the model\nhas fit perfectly. And that means this is 0 so\nthis r value or r squared value",
    "start": "620290",
    "end": "626110"
  },
  {
    "text": "is 1. On the other hand, if this\nis equal to that, meaning",
    "start": "626110",
    "end": "632650"
  },
  {
    "text": "that all of the variation\nin the estimates accounts for none of the\nvariation in the data,",
    "start": "632650",
    "end": "637880"
  },
  {
    "text": "then this is 1 and\nthis goes to 0. So the idea is that an r-squared\nvalue is close to 1 is great.",
    "start": "637880",
    "end": "645160"
  },
  {
    "text": "It says, the model is\na good fit to the data. r-squared value is getting\ncloser to 0, not so good.",
    "start": "645160",
    "end": "652780"
  },
  {
    "text": "OK, so I ran this,\nfitting models of order 2,",
    "start": "652780",
    "end": "658550"
  },
  {
    "start": "657000",
    "end": "657000"
  },
  {
    "text": "4, 8, and 16. Now you can see that model 2,\nthat's the green line here.",
    "start": "658550",
    "end": "665180"
  },
  {
    "text": "That's the one\nthat we saw before. It's basically a\nparabolic kind of arc. It kind of follows\nthe data pretty well.",
    "start": "665180",
    "end": "672020"
  },
  {
    "text": "But if I look at those\nr-squared values. Wow, look at that.",
    "start": "672020",
    "end": "677270"
  },
  {
    "text": "Order 16 fit accounts\nfor all but 3% of the variation in the data.",
    "start": "677270",
    "end": "684279"
  },
  {
    "text": "It's a great fit. And you can see. You can see how it follows. It actually goes through\nmost, but not quite all,",
    "start": "684280",
    "end": "690670"
  },
  {
    "text": "of the data points. So it's following\nthem pretty well. OK, so if that's the\ncase, the order 16 fit",
    "start": "690670",
    "end": "699390"
  },
  {
    "text": "is really the best fit. Should we just use it? And I left you last time\nwith that quote that says,",
    "start": "699390",
    "end": "705740"
  },
  {
    "text": "from your parents, right,\nyour mother telling you, just because you\ncan do something doesn't mean you\nshould do something.",
    "start": "705740",
    "end": "711720"
  },
  {
    "text": "I'll leave it at that. Same thing applies here. Why are we building the model?",
    "start": "711720",
    "end": "718930"
  },
  {
    "text": "Remember, I said two reasons. One is to be able to\nexplain the phenomena.",
    "start": "718930",
    "end": "723990"
  },
  {
    "text": "And the second one is to be\nable to make predictions. So I want to be able to\nexplain the phenomena",
    "start": "723990",
    "end": "730190"
  },
  {
    "text": "in the case of a spring,\nwith things like it's linear and then that gives me a\nsense of a linear relationship",
    "start": "730190",
    "end": "735740"
  },
  {
    "text": "between compression and force. In this case, a\n16th order model,",
    "start": "735740",
    "end": "742690"
  },
  {
    "text": "what kind of physical process\nhas an order 16 variation?",
    "start": "742690",
    "end": "748190"
  },
  {
    "text": "Sounds a little painful. So maybe not a great\ninsight into the process.",
    "start": "748190",
    "end": "754510"
  },
  {
    "text": "But the second reason is I\nwant to be able to predict future behavior of this system.",
    "start": "754510",
    "end": "760574"
  },
  {
    "text": "In the case of this spring,\nI put a different weight on than I've done before. I want to predict what the\ndisplacement is going to be.",
    "start": "760574",
    "end": "767720"
  },
  {
    "text": "I've done a set of trials for\nan FDA approval of a drug. Now I want to predict\nthe effect of a treatment on a new patient.",
    "start": "767720",
    "end": "773150"
  },
  {
    "text": "How do I use the model\nto help me with that? One that maybe not\nso good, currently, I want to predict the\noutcome of an election.",
    "start": "773150",
    "end": "779547"
  },
  {
    "text": "Maybe those models need to\nbe fixed from, at least, what happened the last time around. But I need to be able\nto make the prediction.",
    "start": "779547",
    "end": "785210"
  },
  {
    "text": "So another way of saying it\nis, a good model both explains the phenomena and let's\nme make the predictions.",
    "start": "785210",
    "end": "792730"
  },
  {
    "text": "OK, so let's go back,\nthen, to our example. And before I do it, let me tell\nyou where that data came from.",
    "start": "792730",
    "end": "800210"
  },
  {
    "text": "I actually built that data\nby looking at another kind of physical phenomenon. And it was a lot of them.",
    "start": "800210",
    "end": "805441"
  },
  {
    "text": "Things that follow\na parabolic arc. So for example, comets. Any particle under the influence\nof a uniform gravitational",
    "start": "805441",
    "end": "813050"
  },
  {
    "text": "field follows a\nparabolic arc, which i why Halley's comet gets\nreally close for a while, and then goes away off\ninto the solar system,",
    "start": "813050",
    "end": "820190"
  },
  {
    "start": "817000",
    "end": "817000"
  },
  {
    "text": "and comes back around. My favorite example-- I'm biased on this. And I know you all know\nwhich team I root for.",
    "start": "820190",
    "end": "826620"
  },
  {
    "text": "But there is Tom Brady throwing\na pass against the Pittsburgh Steelers. Center of mass of the past\nfollows a nice parabolic arc.",
    "start": "826620",
    "end": "834820"
  },
  {
    "text": "Even in design, you\nsee parabolic arcs in lots of places. They have nice\nproperties in terms",
    "start": "834820",
    "end": "839890"
  },
  {
    "text": "of disbursement of\nloads and forces, which is why architects\nlike to use them.",
    "start": "839890",
    "end": "845510"
  },
  {
    "text": "So here's how I\ngenerated the data. I wrote a little function. Actually, I didn't.",
    "start": "845510",
    "end": "850541"
  },
  {
    "text": "Professor Guttag did,\nbut I borrowed it. It took in three\nparameters, a, b, and c.",
    "start": "850541",
    "end": "856606"
  },
  {
    "start": "853000",
    "end": "853000"
  },
  {
    "text": "ax squared plus bx plus c. I gave it a set of x values.",
    "start": "856606",
    "end": "861947"
  },
  {
    "text": "Those are the independent\nmeasurements, the things along the horizontal axis. And notice what I did.",
    "start": "861947",
    "end": "867779"
  },
  {
    "text": "I generated values given an a,\nb, and c, for that equation.",
    "start": "867780",
    "end": "874000"
  },
  {
    "text": "And then I added in some noise. So random.guass takes a mean\nand a standard deviation,",
    "start": "874000",
    "end": "880890"
  },
  {
    "text": "and it generates noise\nfollowing that bell shaped curve that goes in the distribution.",
    "start": "880890",
    "end": "886260"
  },
  {
    "text": "So the 0 says it's 0 mean,\nmeaning there's no bias. It's going to be equally likely\nto be above or below the value,",
    "start": "886260",
    "end": "892380"
  },
  {
    "text": "positive or negative. But 35 is a pretty good\nstandard deviation. This is putting a lot\nof noise into the data.",
    "start": "892380",
    "end": "899960"
  },
  {
    "text": "And then I just added\nthat into y values. The rest of this,\nyou can see, it's simply going to write it into a\nfile, a set of x and y values.",
    "start": "899960",
    "end": "906020"
  },
  {
    "text": "But this will generate, given\na value for a, b, and c, data from a parabolic arc\nwith noise added to it.",
    "start": "906020",
    "end": "913810"
  },
  {
    "text": "And in this case, I took\nit as y equals 3x squared. And then c and c are 0.",
    "start": "913810",
    "end": "919529"
  },
  {
    "text": "And that's how I generated it.  What I want to do, I want to\nsee how well this model actually",
    "start": "919530",
    "end": "926230"
  },
  {
    "text": "predicts behavior. So one of the ways\nI could do it, to say, all right, the question\nI want to ask is, whoa,",
    "start": "926230",
    "end": "931570"
  },
  {
    "text": "if I generated the data\nfrom a degree 2 polynomial quadratic, why in the world is\nthe 16th order polynomial the,",
    "start": "931570",
    "end": "939820"
  },
  {
    "text": "\"best fit?\"  So let's test it out.",
    "start": "939820",
    "end": "947449"
  },
  {
    "text": "I'm going to give 3-- sorry, 4. I can't count. 4 different degrees, order 2,\norder 4, order 8, order 16.",
    "start": "947450",
    "end": "956029"
  },
  {
    "text": "And I've generated two\ndifferent datasets, using exactly that code.",
    "start": "956030",
    "end": "961850"
  },
  {
    "text": "I just ran it twice. It's going to have\nslightly different values, because the noise is going\nto be different in each case.",
    "start": "961850",
    "end": "966913"
  },
  {
    "text": "But they're both\ncoming from that a, y equals 3x squared equation.",
    "start": "966913",
    "end": "972050"
  },
  {
    "text": "And the code here\nbasically says, I'm going to take\nthose two data sets and basically, get the x\nand y values out, and then",
    "start": "972050",
    "end": "978590"
  },
  {
    "start": "973000",
    "end": "973000"
  },
  {
    "text": "fit models. So I'll remind\nyou, genFits takes in a collection of x\nand y values and a list",
    "start": "978590",
    "end": "986269"
  },
  {
    "text": "or a tuple of degrees,\nand for each degree, finds, using Polyfit,\nthe best model.",
    "start": "986270",
    "end": "992720"
  },
  {
    "text": "So models one will be 4 models\nfor order 2, 4, 8, and 16.",
    "start": "992720",
    "end": "998350"
  },
  {
    "text": "And similarly, down here, I'm\ngoing to do the same thing, but using the second data set.",
    "start": "998350",
    "end": "1003470"
  },
  {
    "text": "And I'm going to fit,\nagain, a set of models. And then I'll remind you, test\nfits, which you saw last time.",
    "start": "1003470",
    "end": "1009390"
  },
  {
    "text": "I know it's a while\nago, basically takes a set of models, a corresponding\nset of degrees, x and y values,",
    "start": "1009390",
    "end": "1017710"
  },
  {
    "text": "and says, for each model\nin that degree, measure how well that model\nmeets the fit, using",
    "start": "1017710",
    "end": "1025790"
  },
  {
    "text": "that r-squared value. So testFits is going to get us\nback a set of r-squared values. All right, with that in\nmind, I've got the code here.",
    "start": "1025790",
    "end": "1035089"
  },
  {
    "text": "Let's run it.  And here we go.",
    "start": "1035089",
    "end": "1041199"
  },
  {
    "text": "I'm going to run that code. Ha, I get two fits.",
    "start": "1041200",
    "end": "1046559"
  },
  {
    "text": "Looks good. Let's look at the values. ",
    "start": "1046560",
    "end": "1052460"
  },
  {
    "text": "So there's the first data set. All right, the green line\nstill is doing not a bad job.",
    "start": "1052460",
    "end": "1060110"
  },
  {
    "start": "1055000",
    "end": "1055000"
  },
  {
    "text": "The purple line, boy, is\nfitting it really well. And again, notice\nhere's the best fit.",
    "start": "1060110",
    "end": "1065860"
  },
  {
    "text": "That's amazing. That is accounting\nfor all but 0.4%",
    "start": "1065860",
    "end": "1070900"
  },
  {
    "text": "of the variation in the data. Great fit. Order 16. Came from an order 2 thing.",
    "start": "1070900",
    "end": "1077020"
  },
  {
    "text": "All right, what about\nthe second data set? Oh, grumph.",
    "start": "1077020",
    "end": "1083290"
  },
  {
    "text": "It also says order 16\nfit is the best fit.",
    "start": "1083290",
    "end": "1088600"
  },
  {
    "text": "Not quite as good. It accounts for all but\nabout 2% of the variation. Again, the green line,\nthe red line, do OK.",
    "start": "1088600",
    "end": "1095720"
  },
  {
    "text": "But in this case,\nagain, that purple line is still the best fit. So I've still got this puzzle.",
    "start": "1095720",
    "end": "1101110"
  },
  {
    "text": "But I didn't quite test\nwhat I wanted, right? I said I want to see how well\nit predicts new behavior.",
    "start": "1101110",
    "end": "1109670"
  },
  {
    "text": "Here what I did was I took\ntwo datasets, fit the model, and I got two different\nfits, one for each dataset.",
    "start": "1109670",
    "end": "1115670"
  },
  {
    "text": "They both fit well for order 16. But they're not quite right. OK, so best fitting\nmodel is still order 16",
    "start": "1115670",
    "end": "1123370"
  },
  {
    "text": "but we know it came from\nan order 2 polynomial. So how could I will\nget a handle on seeing",
    "start": "1123370",
    "end": "1129190"
  },
  {
    "text": "how good this model is? Well, what we're seeing here\nis coming from training error.",
    "start": "1129190",
    "end": "1136820"
  },
  {
    "text": "Or another way of saying\nit is, what we're measuring is how well does\nthe model perform",
    "start": "1136820",
    "end": "1142580"
  },
  {
    "text": "on the data from\nwhich it was learned? How well do I fit the\nmodel to the training data?",
    "start": "1142580",
    "end": "1150260"
  },
  {
    "text": "I want a small training error. And if you think about it,\ngo back to the first example, when I fit a line to this\ndata, it did not do well.",
    "start": "1150260",
    "end": "1156929"
  },
  {
    "text": "It was not a good model. When I fit a quadratic,\nit was pretty decent. And then I got better\nand better as I went on.",
    "start": "1156930",
    "end": "1163260"
  },
  {
    "text": "So I certainly need at least\na small training error. But it's, to use the\nmathematical terms, a necessary, but not sufficient\ncondition to get a great model.",
    "start": "1163260",
    "end": "1172630"
  },
  {
    "text": "I need a small training\nerror, but I really want to make sure that the model\nis capturing what I'd like.",
    "start": "1172630",
    "end": "1177790"
  },
  {
    "text": "And so for that, I want\nto see how well does it do on other gen\ndata, generated",
    "start": "1177790",
    "end": "1182830"
  },
  {
    "text": "from the same\nprocess, whether it's weights on springs, different\ncomets besides Haley's comet,",
    "start": "1182830",
    "end": "1189680"
  },
  {
    "text": "different voters\nthan those surveyed when we tried to\nfigure out what's going to happen in an election.",
    "start": "1189680",
    "end": "1194789"
  },
  {
    "text": "And I'm set up to\ndo that, by using a really important tool called,\nvalidation or cross-validation.",
    "start": "1194790",
    "end": "1203340"
  },
  {
    "text": "We set the stage, and then\nwe're going to do the example. I'm going to get a set of data. I want to fit a model\nto it, actually,",
    "start": "1203340",
    "end": "1209310"
  },
  {
    "text": "different models,\ndifferent degrees, different kinds of models. To see how well\nthey work, I want",
    "start": "1209310",
    "end": "1214710"
  },
  {
    "text": "to see how well they predict\nbehavior under other data than that from which\nI did the training.",
    "start": "1214710",
    "end": "1221670"
  },
  {
    "text": "So I could do that right here. I could generate the\nmodels from one data set,",
    "start": "1221670",
    "end": "1227720"
  },
  {
    "start": "1225000",
    "end": "1225000"
  },
  {
    "text": "but test them on the other. And so in fact, I\nhad one data set. I build a set of models\nfor the first data set.",
    "start": "1227720",
    "end": "1234530"
  },
  {
    "text": "I compared how well it\ndid on that data set. But I could now apply it\nto the second dataset.",
    "start": "1234530",
    "end": "1240750"
  },
  {
    "text": "How well does that\naccount for that data set? And similarly, take the models\nI built for the second data set,",
    "start": "1240750",
    "end": "1246320"
  },
  {
    "text": "and see how well they\npredict the points from the first dataset.",
    "start": "1246320",
    "end": "1251920"
  },
  {
    "text": "What do I expect? Certainly, expect\nthat the testing error is likely to be larger\nthan the training error,",
    "start": "1251920",
    "end": "1257320"
  },
  {
    "text": "because I train on\none set of data. And that means this\nought to be a better way to think about, how well\ndoes this model generalize?",
    "start": "1257320",
    "end": "1265390"
  },
  {
    "text": "How well does it\npredict other behavior, besides what I started with.",
    "start": "1265390",
    "end": "1271230"
  },
  {
    "text": "So here's the code\nI'm going to use. It's pretty straightforward. All I want to draw your\nattention to here is, remember, models one I built by fitting\nmodels of degree 2, 4, 8,",
    "start": "1271230",
    "end": "1279510"
  },
  {
    "start": "1273000",
    "end": "1273000"
  },
  {
    "text": "and 16 to the first data set. And I'm going to apply those\nmodels to the second dataset,",
    "start": "1279510",
    "end": "1286590"
  },
  {
    "text": "x vals 2 and y vals 2. Similarly, I'm going to\ntake the models built for the second data set, and\ntest them on the first dataset",
    "start": "1286590",
    "end": "1296370"
  },
  {
    "text": "to see how well they fit. I know you're\neagerly anticipating, as I've been setting\nthis up for a whole week.",
    "start": "1296370",
    "end": "1303470"
  },
  {
    "text": "All right, let's look at\nwhat happens when I do this. I'm going to run it. And then we'll look\nat the examples.",
    "start": "1303470",
    "end": "1308570"
  },
  {
    "text": " If I go back over to\nPython and this code was distributed earlier, if you\nwant to play with it yourself.",
    "start": "1308570",
    "end": "1316610"
  },
  {
    "text": "Should be the right\nplace to do it. I am going to run that code. ",
    "start": "1316610",
    "end": "1325320"
  },
  {
    "text": "Now I get something\na little different. In fact, if I go\nlook at it, here",
    "start": "1325320",
    "end": "1335649"
  },
  {
    "text": "is model one applied\nto data set 2.",
    "start": "1335650",
    "end": "1340955"
  },
  {
    "start": "1337000",
    "end": "1337000"
  },
  {
    "text": "And we can both eyeball it\nand look at the numbers. Eyeballing it, there's that\ngreen line, still generally",
    "start": "1340955",
    "end": "1347220"
  },
  {
    "text": "following the form\nof this pretty well. What about the purple line? The order 16 degree.",
    "start": "1347220",
    "end": "1353020"
  },
  {
    "text": "Remember, that's the\npurple line from model 1, from training set 1. Wow, this misses a bunch\nof points, pretty badly.",
    "start": "1353020",
    "end": "1361260"
  },
  {
    "text": "And in fact, look at\nthe r-squared values. Order 2 and order\n4, pretty good fit,",
    "start": "1361260",
    "end": "1369549"
  },
  {
    "text": "accounts for all but\nabout 14, 13% of the data. Look what happened to the\ndegree 16, degrees 16 fit.",
    "start": "1369550",
    "end": "1378500"
  },
  {
    "text": "Way down at last. 0.7. Last time around it was 0.997.",
    "start": "1378500",
    "end": "1384570"
  },
  {
    "text": "What about the other direction? Taking the model built\nand the second data set, testing it on\nthe first data set.",
    "start": "1384570",
    "end": "1391610"
  },
  {
    "text": "Again, notice a nice\nfit for degree 2 and 4,",
    "start": "1391610",
    "end": "1397299"
  },
  {
    "text": "not so good for degree 16. And just to give you a sense\nof this, I'm going to go back.",
    "start": "1397300",
    "end": "1402760"
  },
  {
    "text": "There is the model one case.",
    "start": "1402760",
    "end": "1408630"
  },
  {
    "text": "There is the model\nin the other case. You can see the model that\naccounts for variation in one doesn't account for the\nvariation in the other, when",
    "start": "1408630",
    "end": "1414776"
  },
  {
    "text": "I look at order 16 fit. OK, so what this says\nis something important.",
    "start": "1414776",
    "end": "1422950"
  },
  {
    "text": "Now I can see. In fact, if I look back\nat this, if I were just looking at the coefficient\nof determination,",
    "start": "1422950",
    "end": "1429190"
  },
  {
    "text": "this says, in order to\npredict other behavior, I'm better off with an order\n2 or maybe order 4 polynomial.",
    "start": "1429190",
    "end": "1437190"
  },
  {
    "text": "Those r-squared values\nare both the same. I happen to know it's\norder 2, because that's where I generated from. But that's a whole lot\nbetter than order 16.",
    "start": "1437190",
    "end": "1446462"
  },
  {
    "text": "And what you're seeing here is\nan example of something that happens a lot in statistics.",
    "start": "1446462",
    "end": "1451920"
  },
  {
    "text": "And in fact, I would suggest is\noften misused in fitting data to statistical samples.",
    "start": "1451920",
    "end": "1458309"
  },
  {
    "text": "It's called overfitting. And what it means\nis I've let there be too many degrees of\nfreedom in my model, too",
    "start": "1458310",
    "end": "1464740"
  },
  {
    "text": "many free parameters. And what it's fitting isn't\njust the underlying process.",
    "start": "1464740",
    "end": "1469760"
  },
  {
    "text": "It's also fitting to the noise. The message I want you to take\nout of this part of the lecture",
    "start": "1469760",
    "end": "1475350"
  },
  {
    "text": "is, if we only fit the\nmodel to training data, and we look at how\nwell it does, we",
    "start": "1475350",
    "end": "1481320"
  },
  {
    "text": "could get what looks\nlike a great fit, but we may actually have come\nup with far too complex a model.",
    "start": "1481320",
    "end": "1487650"
  },
  {
    "text": "Order 16 instead of order 2. And the only way you\nare likely to detect that is to train on one test\nset and test on a different.",
    "start": "1487650",
    "end": "1497180"
  },
  {
    "text": "And if you do that, it's likely\nto expose whether, in fact, I have done a good job\nof fitting or whether I have overfit to the data.",
    "start": "1497180",
    "end": "1504325"
  },
  {
    "text": "There are lots of horror\nstories in the literature, especially from early days\nof machine learning of people overfitting to data and\ncoming up with models",
    "start": "1504325",
    "end": "1510909"
  },
  {
    "text": "that they thought wonderfully\npredicted an effect, and then when it ran on new\ndata really hit the big one.",
    "start": "1510910",
    "end": "1517850"
  },
  {
    "text": "All right, so this\nis something you want to try and stay away from. And the best way to do\nit is to do validation.",
    "start": "1517850",
    "end": "1524760"
  },
  {
    "text": "You can see it here, right? The upper left is my\ntraining data, dataset one. There's the set of models.",
    "start": "1524760",
    "end": "1531610"
  },
  {
    "start": "1526000",
    "end": "1526000"
  },
  {
    "text": "This is now taking\nthat and applying it to a different dataset\nfrom the same process.",
    "start": "1531610",
    "end": "1536820"
  },
  {
    "text": "And notice for the\ndegree to polynomial, the coefficient of\ndetermination, 0.86, now 0.87.",
    "start": "1536820",
    "end": "1544580"
  },
  {
    "text": "The fact that it's slightly\nhigher is just accidental. But it's really\nabout the same level.",
    "start": "1544580",
    "end": "1549669"
  },
  {
    "text": "It's doing the same kind of\ndrop on the training data and on the test data. On the other hand, degree 16,\ncoefficient of determination",
    "start": "1549670",
    "end": "1558910"
  },
  {
    "text": "is a wonderful 0.96 here and\na pretty awful 9 down there.",
    "start": "1558910",
    "end": "1565450"
  },
  {
    "text": "And that's a sign that\nwe're not in good shape, when in fact our\ncoefficient of determination",
    "start": "1565450",
    "end": "1571000"
  },
  {
    "text": "drops significantly when\nwe try and handle new data. OK, so why do we\nget a better fit",
    "start": "1571000",
    "end": "1582280"
  },
  {
    "text": "on the training data with\na higher order model, but then do less well when we're\nactually handling new data?",
    "start": "1582280",
    "end": "1588779"
  },
  {
    "text": "Or another way of saying it\nis, if I started out with, in the case of that with\nthat data, a linear model",
    "start": "1588780",
    "end": "1595740"
  },
  {
    "text": "it didn't fit well, and then\nI got to a quadratic model, why didn't that quadratic\nmodel still say [INAUDIBLE]?",
    "start": "1595740",
    "end": "1601920"
  },
  {
    "text": "Why was it the case that, as I\nadded more degrees of freedom, I did better.",
    "start": "1601920",
    "end": "1607039"
  },
  {
    "text": "Or another way of asking it\nis, can I actually get a worse fit to training data as I\nincrease the model complexity?",
    "start": "1607040",
    "end": "1615399"
  },
  {
    "text": "And I see at least one\nnegative head shake. Thank you. You're right. I cannot. Let's look at why.",
    "start": "1615399",
    "end": "1621610"
  },
  {
    "text": "If I add in some\nhigher order terms, and they actually don't matter. If I got perfect data, the\ncoefficient will just be 0.",
    "start": "1621610",
    "end": "1629200"
  },
  {
    "text": "The fit will basically say,\nthis term doesn't matter. Ignore it. And that'll work\nin perfect data.",
    "start": "1629200",
    "end": "1635620"
  },
  {
    "text": "But if the data is noisy,\nwhat the model is going to do is actually start\nfitting the noise.",
    "start": "1635620",
    "end": "1642237"
  },
  {
    "text": "And while it may lead to\na better r-squared value, it's not really a better fit. Right, let me show you\nan example of that.",
    "start": "1642237",
    "end": "1649770"
  },
  {
    "text": "I'm going to fit a quadratic\nto a straight line. Easy thing to do. But I want to show you the\neffect of overfitting or adding",
    "start": "1649770",
    "end": "1656660"
  },
  {
    "text": "in those extra terms. So let me say it a\nlittle bit better. I'm going to start off\nwith this 3, sorry, 3. I'm doing it again today.",
    "start": "1656660",
    "end": "1662580"
  },
  {
    "start": "1662000",
    "end": "1662000"
  },
  {
    "text": "4 simple values, 0, 1, 2, 3. The y values are the\nsame as x values.",
    "start": "1662580",
    "end": "1667640"
  },
  {
    "text": "So this is 0,0, 1, 1, 2, 2, 3 3. They're all lying on a line. But I'm going to fit. I'm going to plot them out.",
    "start": "1667640",
    "end": "1674160"
  },
  {
    "text": "And then I'm going\nto fit a quadratic. y if it equals ax squared\nplus bx plus c to this.",
    "start": "1674160",
    "end": "1682504"
  },
  {
    "text": "Now I know it's a\nline, but I want to see what happens\nif I fit a quadratic. So I'm going to use polyfit\nto fit my quadratic.",
    "start": "1682504",
    "end": "1688510"
  },
  {
    "text": "I'm going to print out\nsome data about it. And then I'm going to\nuse Polyval to estimate",
    "start": "1688510",
    "end": "1694610"
  },
  {
    "text": "what those values should be. Plot them out. And then compute r squared\nvalue, and see what happens.",
    "start": "1694610",
    "end": "1702510"
  },
  {
    "text": "All right, OK, and let\nme set this up better. What am I doing? I want to just fit it to a line. I know it's a line, but I'm\ngoing to fit a quadratic to it.",
    "start": "1702510",
    "end": "1709250"
  },
  {
    "text": "And what I'd expect is, even\nthough there's an extra term there, it shouldn't matter.",
    "start": "1709250",
    "end": "1714299"
  },
  {
    "text": "So if I go to Python,\nand I run this,",
    "start": "1714300",
    "end": "1720040"
  },
  {
    "text": "I run exactly that\nexample, look at that.",
    "start": "1720040",
    "end": "1726130"
  },
  {
    "text": "a equals 0, b is 1, c equals 0. Look at the r-squared value. I'll pull that together for you.",
    "start": "1726130",
    "end": "1732420"
  },
  {
    "text": " It says, in this perfect\ncase, there's what I get.",
    "start": "1732420",
    "end": "1741220"
  },
  {
    "text": "The blue line is drawn\nthrough the actual values. The dotted red line is drawn\nthrough the predicted values.",
    "start": "1741220",
    "end": "1746290"
  },
  {
    "text": "They exactly line up. And in fact, the\nsolution implied says, the higher order\nterm coefficient 0,",
    "start": "1746290",
    "end": "1752020"
  },
  {
    "text": "it doesn't matter. So what it found was y equals x. I know you're totally impressed\nI could find a straight line.",
    "start": "1752020",
    "end": "1759329"
  },
  {
    "text": "But notice what happened there. I dropped or that\nsystem said, you don't need the\nhigher order term.",
    "start": "1759329",
    "end": "1764340"
  },
  {
    "text": "Wonderful r-squared value. OK, let's see how\nwell it predicts.",
    "start": "1764340",
    "end": "1769809"
  },
  {
    "text": "Let's add in one more\npoint, out at 20. So this is 0, 1, 2, 3. That's 0, 1, 2, 3.",
    "start": "1769810",
    "end": "1775700"
  },
  {
    "text": "I'm going to add 20 in there, so\nit's 0, 0 , 1, 2, 2, 3, 3, 20, 20. Again, I can estimate\nusing the same model.",
    "start": "1775700",
    "end": "1783490"
  },
  {
    "text": "So I'm not\nrecomputing the model, the model I predicted from using\nthose first set of four points. I can get the\nestimated y values,",
    "start": "1783490",
    "end": "1790270"
  },
  {
    "text": "plot those out, and you again,\ncompute the r-squared value here. And even adding that point\nin, there's the line.",
    "start": "1790270",
    "end": "1798260"
  },
  {
    "text": "And guess what. Perfectly predicts it. No big surprise.",
    "start": "1798260",
    "end": "1804574"
  },
  {
    "text": "So it says, in the\ncase of perfect data, adding the higher order terms\nisn't going to cause a problem. The system will say\ncoefficients are 0.",
    "start": "1804574",
    "end": "1811340"
  },
  {
    "text": "That's all I need. All right, now, let's go back\nand add in just a tiny bit",
    "start": "1811340",
    "end": "1817210"
  },
  {
    "text": "of noise right there. 0, 0, 1, 1, 2, 2, and 3, 3.1.",
    "start": "1817210",
    "end": "1822909"
  },
  {
    "text": "So I've got a slight deviation\nin the y value there. Again, I can plot them. I'm going to fit a\nquadratic to them.",
    "start": "1822910",
    "end": "1829980"
  },
  {
    "text": "I'm going to print out\nsome information about it and then get the\nestimated values using that new model to see\nwhat it should look like.",
    "start": "1829980",
    "end": "1838020"
  },
  {
    "text": "I'm not going to run it. I'm going to show\nyou the result. I get a really good\nr-squared value.",
    "start": "1838020",
    "end": "1843370"
  },
  {
    "start": "1843000",
    "end": "1843000"
  },
  {
    "text": "And there's the equation\nit comes up with. ",
    "start": "1843370",
    "end": "1848710"
  },
  {
    "text": "Not so bad, right? It's almost y equal to x. But because of that\nlittle bit of noise",
    "start": "1848710",
    "end": "1855429"
  },
  {
    "text": "there, there's a small\nsecond order term here and a little\nconstant term down there. The y squared value\nis really pretty good.",
    "start": "1855430",
    "end": "1863050"
  },
  {
    "text": "And if you really squint\nand look carefully at this, you'll actually see\nthere's a little bit of a deviation between\nthe red and the blue line.",
    "start": "1863050",
    "end": "1871659"
  },
  {
    "text": "It undershoots-- sorry,\novershoots there, undershoots here, but\nit's really pretty close.",
    "start": "1871660",
    "end": "1877429"
  },
  {
    "text": "All right, so am I just\nwhistling in the dark here? What's the difference? Well, now let's add\nin that extra point.",
    "start": "1877430",
    "end": "1885770"
  },
  {
    "text": "And what happens? So again, I'm now taking the\nsame set of points 0, 0, 1, 1,",
    "start": "1885770",
    "end": "1890890"
  },
  {
    "start": "1890000",
    "end": "1890000"
  },
  {
    "text": "2, 2, 3, and 3.1. I'm going to do 20, 20. Using the model I captured\nfrom fitting to that first set,",
    "start": "1890890",
    "end": "1898407"
  },
  {
    "text": "I want to see what happens here.  Crap.",
    "start": "1898407",
    "end": "1903870"
  },
  {
    "text": "I'm sorry. Shouldn't say that. Darn. Pick up some other word.",
    "start": "1903870",
    "end": "1909911"
  },
  {
    "text": "Shouldn't surprise you, right? A small variation here is\nnow causing a really large",
    "start": "1909911",
    "end": "1915840"
  },
  {
    "text": "variation up there. And this is why the ideal case\noverfitting is not a problem,",
    "start": "1915840",
    "end": "1922309"
  },
  {
    "text": "because the coefficients\nget zeroed out. But even a little bit of\nnoise can cause a problem. Now I'll grant you, we\nset this up deliberately",
    "start": "1922310",
    "end": "1930110"
  },
  {
    "text": "to show a big effect here. But a 3% error in one data\npoint is causing a huge problem",
    "start": "1930110",
    "end": "1936260"
  },
  {
    "text": "when I get further\nout on this curve. And by the way, there\nis the r-squared values. It's 0.7. It doesn't do a\nparticularly good job",
    "start": "1936260",
    "end": "1945799"
  },
  {
    "text": "OK, so how would I fix this? Well, what if I had\nsimply done a first degree",
    "start": "1945800",
    "end": "1952610"
  },
  {
    "text": "fit, same situation. Let's say fit a line\nto this rather than fitting a quadratic.",
    "start": "1952610",
    "end": "1958080"
  },
  {
    "text": "Remember, my\nquestion was, what's the harm of fitting a higher\norder model if the coefficients would be zeroed out?",
    "start": "1958080",
    "end": "1963410"
  },
  {
    "text": "We've seen they\nwon't be zeroed out. But if I were just\nto have fit a line to this, exactly the same\nexperiment, 0, 0, 1, 1, 2,",
    "start": "1963410",
    "end": "1971149"
  },
  {
    "text": "2, 3, and 3.1, 20 and 20. Now you can see it still does\na really good job of fitting.",
    "start": "1971150",
    "end": "1980269"
  },
  {
    "text": "The r-squared value is 0.9988. So again, fitting the right\nlevel of model, the noise",
    "start": "1980270",
    "end": "1987770"
  },
  {
    "text": "doesn't cause nearly\nas much of a problem. And so just to pull that\ntogether, basically it says,",
    "start": "1987770",
    "end": "1993730"
  },
  {
    "text": "the predictive ability\nof the first order model is much better than\nthe second order model.",
    "start": "1993730",
    "end": "1999990"
  },
  {
    "start": "1996000",
    "end": "1996000"
  },
  {
    "text": "And that's why, in\nthis case, I would want to use that first order model.",
    "start": "1999990",
    "end": "2005210"
  },
  {
    "text": "So take home message. And then we're going\nto amplify this. If I pick an overly\ncomplex model,",
    "start": "2005210",
    "end": "2012390"
  },
  {
    "text": "I have the danger of overfitting\nto the training data, overfitting meaning that I'm\nnot only fitting the underlying",
    "start": "2012390",
    "end": "2018419"
  },
  {
    "text": "process, I'm fitting the noise. I get an order 16\nmodel is the best fit when it's in fact, in order\n2 model that was generating it.",
    "start": "2018420",
    "end": "2026950"
  },
  {
    "text": "That increases the\nrisk that it's not going to do well with the\ndata, not what I'd like. I want to be able\nto predict what's",
    "start": "2026950",
    "end": "2033250"
  },
  {
    "text": "going to go on well here. On the other hand. So that would say, boy,\njust stick with the simplest",
    "start": "2033250",
    "end": "2039130"
  },
  {
    "text": "possible model. But there's a trade off here. And we already saw\nthat when I tried",
    "start": "2039130",
    "end": "2044350"
  },
  {
    "text": "to fit a line to a data that\nwas basically quadratic. I didn't get a good fit. So I'd want to find the balance.",
    "start": "2044350",
    "end": "2050860"
  },
  {
    "text": "An insufficiently complex model\nwon't explain the data well. An overly complex model will\noverfit the training data.",
    "start": "2050860",
    "end": "2059179"
  },
  {
    "text": "So I'd like to find\nthe place where the model is as\nsimple as possible, but still explains the data.",
    "start": "2059179",
    "end": "2065680"
  },
  {
    "text": "And I can't resist the quote\nfrom Einstein that captures it pretty well, \"everything\nshould be made as simple",
    "start": "2065681",
    "end": "2070869"
  },
  {
    "text": "as possible, but not simpler.\" In the case of\nwhere I started, it should be fit to a quadratic,\nbecause it's the right fit.",
    "start": "2070870",
    "end": "2077669"
  },
  {
    "text": "But don't fit more\nthan that, because it's getting overly complex",
    "start": "2077670",
    "end": "2082770"
  },
  {
    "text": "Now how might we go about\nfinding the right model?",
    "start": "2082770",
    "end": "2087822"
  },
  {
    "text": "We're not going to dwell on\nthis but here is a standard way in which you might do it. Start with a low order model.",
    "start": "2087822",
    "end": "2093684"
  },
  {
    "text": "Again, take that data. Fit a linear model to it. Look at not only\nthe r-squared value,",
    "start": "2093684",
    "end": "2099080"
  },
  {
    "text": "but see how well it\naccounts for new data. Increase the order of the model.",
    "start": "2099080",
    "end": "2104160"
  },
  {
    "text": "Repeat the process. And keep doing\nthat until you find a point at which a model does\na good job both on the training",
    "start": "2104160",
    "end": "2111810"
  },
  {
    "text": "data and on predicting new data. An after it starts\nto fall off, that gives you a point where\nyou might say there's",
    "start": "2111810",
    "end": "2118155"
  },
  {
    "text": "a good sized model. In the case of this data,\nwhether I would have stopped at a quadratic or I might\nhave used a cubic or a quartic",
    "start": "2118155",
    "end": "2124413"
  },
  {
    "text": "depends on the values. But I certainly wouldn't\nhave gone much beyond that. And this is one way, if\nyou don't have a theory",
    "start": "2124413",
    "end": "2130228"
  },
  {
    "text": "to drive you, to think\nabout, how do I actually fit the model the way I would like. ",
    "start": "2130228",
    "end": "2137200"
  },
  {
    "text": "Let's go back to\nwhere we started. We still have one\nmore big topic to do, and we still have\na few minutes left. But let's go back to where\nwe started Hooke's law.",
    "start": "2137200",
    "end": "2145870"
  },
  {
    "text": "There was the data from\nmeasuring displacements of a spring, as I\nadded different weights",
    "start": "2145870",
    "end": "2150920"
  },
  {
    "text": "to the bottom of the spring. And there's the linear fit. It's not bad.",
    "start": "2150920",
    "end": "2156599"
  },
  {
    "text": "There's the quadratic fit. And it's certainly got a\nbetter r-squared value, though. That could be just\nfitting to the noise.",
    "start": "2156600",
    "end": "2163930"
  },
  {
    "text": "But you actually\ncan see, I think, that that green curve\nprobably does a better job of fitting the data.",
    "start": "2163930",
    "end": "2171450"
  },
  {
    "text": "Well, wait a minute. Even though the quadratic\nfit is tighter here, Hooke says, this is linear.",
    "start": "2171450",
    "end": "2180030"
  },
  {
    "text": "So what's going on? Well, this is another\nplace where you want to think about your model. And I'll remind you, in case\nyou don't remember your physics,",
    "start": "2180030",
    "end": "2188066"
  },
  {
    "text": "unless we believe\nthat Hooke was wrong, this should tell us something. And in particular, Hooke's\nlaw says, the model",
    "start": "2188066",
    "end": "2193790"
  },
  {
    "text": "holds until you reach the\nelastic limit of the spring. You stretch a slinky too\nfar, it never springs back.",
    "start": "2193790",
    "end": "2202090"
  },
  {
    "text": "You go beyond that\nelastic limit. And that's probably what's\nhappening right up there.",
    "start": "2202090",
    "end": "2207870"
  },
  {
    "text": "Through here, it's following\nthat linear relationship. Up at this point, I've\nessentially broken the spring.",
    "start": "2207870",
    "end": "2213630"
  },
  {
    "text": "The elastic limit\ndoesn't hold anymore. And so really, in this\ncase, I should probably",
    "start": "2213630",
    "end": "2218840"
  },
  {
    "text": "fit different models\nto different segments. And there's a much better fit.",
    "start": "2218840",
    "end": "2225550"
  },
  {
    "text": "Linear through the\nfirst part and another later line once I hit\nthat elastic limit.",
    "start": "2225550",
    "end": "2231480"
  },
  {
    "text": "How might I find this? Well, you could imagine a little\nsearch process in which you try",
    "start": "2231480",
    "end": "2236520"
  },
  {
    "text": "and find where's the best\nplace along here to break the data into two sets, fit\nlinear segments to both,",
    "start": "2236520",
    "end": "2243720"
  },
  {
    "text": "and get really good\nfits for both examples. And I raise it because\nthat's the kind of thing",
    "start": "2243720",
    "end": "2249070"
  },
  {
    "text": "you've also seen before. You could imagine writing\ncode to do that search to find that good fit.",
    "start": "2249070",
    "end": "2255530"
  },
  {
    "text": "OK, that gives\nyou a sense, then, of why you want to be\ncareful about overfitting,",
    "start": "2255530",
    "end": "2261069"
  },
  {
    "text": "why you want to not just\nlook at the coefficient of determination, but see how\nwell does this predict behavior",
    "start": "2261070",
    "end": "2266920"
  },
  {
    "text": "on new data sets. Now suppose I don't have\na theory, like Hooke,",
    "start": "2266920",
    "end": "2272850"
  },
  {
    "text": "to guide me. Can I still figure out what's a\ngood model to fit to the data?",
    "start": "2272850",
    "end": "2278339"
  },
  {
    "text": "And the answer is, you bet. We're going to use\ncross-validation to guide the choice of the\nmodel complexity.",
    "start": "2278340",
    "end": "2284760"
  },
  {
    "text": "And I want to show\nyou two examples. If the data set's\nsmall, we can use",
    "start": "2284760",
    "end": "2290000"
  },
  {
    "text": "what's called leave one\nout cross-validation. I'll give you a definition\nof that in a second.",
    "start": "2290000",
    "end": "2295599"
  },
  {
    "text": "If the data sets\nbigger than that, we can use k-fold\ncross-validation. I'll give you a\ndefinition that a second.",
    "start": "2295600",
    "end": "2301980"
  },
  {
    "text": "Or just what's called,\nrepeated random sampling. But we can use this same\nidea of validating new data",
    "start": "2301980",
    "end": "2307879"
  },
  {
    "text": "to try and figure out whether\nthe model is a good model or not. Leave one out cross-validation.",
    "start": "2307879",
    "end": "2313920"
  },
  {
    "text": "This is as written\nin pseudocode, but the idea is pretty simple. I'm given a dataset. It's not too large.",
    "start": "2313920",
    "end": "2320579"
  },
  {
    "start": "2320000",
    "end": "2320000"
  },
  {
    "text": "The idea is to walk\nthrough a number of trials, number trials equal to\nthe size of the data set.",
    "start": "2320580",
    "end": "2327130"
  },
  {
    "text": "And for each one, take the\ndata set or a copy of it, and drop out one of the samples.",
    "start": "2327130",
    "end": "2332640"
  },
  {
    "text": "So leave one out. Start off by leaving\nout the first one, then leaving out the\nsecond one, and then leaving out the third one.",
    "start": "2332640",
    "end": "2338390"
  },
  {
    "text": "For each one of those training\nsets, build the model. For example, by using\nlinear regression.",
    "start": "2338390",
    "end": "2344609"
  },
  {
    "text": "And then test that model on that\ndata point that you left out.",
    "start": "2344610",
    "end": "2350340"
  },
  {
    "text": "So leave out the first\none, build a model on all of the other\nones, and then see how well that model\npredicts the first one.",
    "start": "2350340",
    "end": "2355461"
  },
  {
    "text": "Leave out the second\none, build a model using all of them\nbut the second one, see how well it\npredicts the second one. And just average\nthe result. Works",
    "start": "2355461",
    "end": "2361946"
  },
  {
    "text": "when you don't have\na really large data set, because it\nwon't take too long. But it's a nice way of\nactually testing validation.",
    "start": "2361946",
    "end": "2370150"
  },
  {
    "text": "If the data set's\na lot bigger, you can still use the same idea. You can use what's\ncalled, k-fold.",
    "start": "2370150",
    "end": "2375990"
  },
  {
    "text": "Divide the data set up\ninto k equal sized chunks. Leave one of them out.",
    "start": "2375990",
    "end": "2381700"
  },
  {
    "text": "Use the rest to build the model. And then use that\nmodel to predict that first chunk you left out.",
    "start": "2381700",
    "end": "2387300"
  },
  {
    "text": "Leave out the second\nchunk, and keep doing it. Same idea, but now\nwith groups of things rather than just leaving\nthose single data points.",
    "start": "2387300",
    "end": "2395270"
  },
  {
    "text": "All right, the other way\nyou can deal with it, which has a nice\neffect to it, is to use what's called,\nrepeated random sampling.",
    "start": "2395270",
    "end": "2403700"
  },
  {
    "text": "OK, start out with\nsome data set. And what I'm going\nto do here is I'm going to run through\nsome number of trials.",
    "start": "2403700",
    "end": "2409001"
  },
  {
    "start": "2409000",
    "end": "2409000"
  },
  {
    "text": "I'm going to call that, k. But I'm also going to pick\nsome number of random samples from the data set.",
    "start": "2409001",
    "end": "2415650"
  },
  {
    "text": "Usually, I think,\nand as I recall, it is somewhere between\nreserving 20% to 50% of the samples.",
    "start": "2415650",
    "end": "2422250"
  },
  {
    "text": "But the idea is again, walk\nover all of those k trials. And in each one, pick\nout at random n elements",
    "start": "2422250",
    "end": "2429289"
  },
  {
    "text": "for the test set. Use the remainder\nis the training set. Build the model on\nthe training set.",
    "start": "2429290",
    "end": "2434990"
  },
  {
    "text": "And then apply that\nmodel to the test set. So rather than doing\nk-fold, where I select k,",
    "start": "2434990",
    "end": "2440730"
  },
  {
    "text": "in turn, and keep them. This is just randomly selecting\nwhich ones to pull out.",
    "start": "2440730",
    "end": "2446450"
  },
  {
    "text": "So I'm going to show\nyou one last example. Let's look at that idea of,\nI don't have a model here. I want to use this idea\nof cross-validation",
    "start": "2446450",
    "end": "2454400"
  },
  {
    "text": "to try and figure out what's\nthe best possible model. And for this, I'm going to\nuse a different data set.",
    "start": "2454400",
    "end": "2460250"
  },
  {
    "text": "The data set here\nis I want to model or the task here is\nI want to try model how the mean daily high\ntemperature in the US",
    "start": "2460250",
    "end": "2467510"
  },
  {
    "text": "has varied over about a 55\nyear period, from '61 to 2015.",
    "start": "2467510",
    "end": "2474060"
  },
  {
    "text": "Got a set of data. It's mean-- sorry, the daily\nhigh for every day of the year through that entire period.",
    "start": "2474060",
    "end": "2479839"
  },
  {
    "text": "And what I'm going\nto do is I'm going to compute the means for\neach year and plot them out. And then I'm going to try\nand fit models to them.",
    "start": "2479839",
    "end": "2486290"
  },
  {
    "text": "And in particular,\nI'm going to take a set of different\ndimensionalities, linear, quadratic, cubic,\nquartic And in each case,",
    "start": "2486290",
    "end": "2494477"
  },
  {
    "text": "I'm going to run\nthrough a trial where I train on one half of the\ndata, test on the other. There again, is that idea\nof seeing how well it",
    "start": "2494477",
    "end": "2501100"
  },
  {
    "text": "predicts other data. Record the coefficient\nof determination. And do that and\nget out an average,",
    "start": "2501100",
    "end": "2507370"
  },
  {
    "text": "and report what I get as the\nmean for each of those values across each dimensionality.",
    "start": "2507370",
    "end": "2513809"
  },
  {
    "text": "OK, here we go. Set a code that's\npretty easy to see. Hopefully, you can just\nlook at it and grok it.",
    "start": "2513810",
    "end": "2519170"
  },
  {
    "text": "We start off with\na boring class, which Professor guttag suggests\nrefers to this lecture. But it doesn't.",
    "start": "2519170",
    "end": "2524710"
  },
  {
    "text": "This may be a boring lecture,\nbut it's not a boring class. This is a great class. And boy, those jokes are\nreally awful, aren't they?",
    "start": "2524710",
    "end": "2530800"
  },
  {
    "text": "But here we go. Simple class that\nbuilds temperature data.",
    "start": "2530800",
    "end": "2535809"
  },
  {
    "text": "This reads in some information,\nsplits it up, and basically, records the high for the day and\nthe year in which I got that.",
    "start": "2535810",
    "end": "2543280"
  },
  {
    "text": "So for each day, I've got a\nhigh temperature for that day. I'm going to give you back the\nhigh temperature and the year",
    "start": "2543280",
    "end": "2548540"
  },
  {
    "text": "in which it was recorded,\nbecause I don't care whether it was in\nJanuary or June. A little function\nthat opens up a file.",
    "start": "2548540",
    "end": "2555480"
  },
  {
    "text": "We've actually given you a file,\nif you want to go look at it. And simply walk through\nthe file reading it in and returning a big list\nof all those data objects.",
    "start": "2555480",
    "end": "2565200"
  },
  {
    "text": "OK, then what I\nwant to do is I want to get the mean high\ntemperature for each year.",
    "start": "2565200",
    "end": "2572545"
  },
  {
    "text": "Given that data, I'm going to\nset up a dictionary called, years. I'm just going to run through\na loop through all the data",
    "start": "2572545",
    "end": "2577920"
  },
  {
    "text": "points, where in the\ndictionary, under that year. So there a data point. I use the method get\nyear to get out the year.",
    "start": "2577920",
    "end": "2584910"
  },
  {
    "text": "At that point, I add in the\nhigh temperature corresponding to that data point.",
    "start": "2584910",
    "end": "2591110"
  },
  {
    "text": "And I'm using that nice\nlittle try except loop. I'll do that, unless\nI haven't had anything yet for this year, in\nwhich case this'll fail.",
    "start": "2591110",
    "end": "2597510"
  },
  {
    "text": "And I'll simply store the\nfirst one in as a list. So after I've run through\nthis loop in the dictionary, under the year, I have a\nlist of the high temperatures",
    "start": "2597510",
    "end": "2604759"
  },
  {
    "text": "for each day associated with it. Excuse me. And then I can just\ncompute the average, that",
    "start": "2604759",
    "end": "2610970"
  },
  {
    "text": "is for each year in the years. I get that value. I add them up. I get the length. I divide them out.",
    "start": "2610970",
    "end": "2616369"
  },
  {
    "text": "And I store that in as the\naverage high temperature for the year. ",
    "start": "2616369",
    "end": "2622290"
  },
  {
    "text": "Now I can plot it. Get the data, get\nout the information by computing those yearly\nmeans, run through a little loop",
    "start": "2622290",
    "end": "2629460"
  },
  {
    "text": "that basically, in the x values,\nputs in the year, in the y values, puts in the\nhigh temperature.",
    "start": "2629460",
    "end": "2636180"
  },
  {
    "text": "And I can do a plot. And if I do that, I get that.",
    "start": "2636180",
    "end": "2642830"
  },
  {
    "text": "I'll let you run this yourself. Now this is a little bit\ndeceptive, because of the scale",
    "start": "2642830",
    "end": "2649244"
  },
  {
    "text": "I've used here. But nonetheless, it\nshows, in the US, over a 55 year period,\nthe mean high day--",
    "start": "2649245",
    "end": "2655580"
  },
  {
    "text": "I'm sorry. The mean daily high has\ngone from about 15.5 degrees Celsius up\nto about 17 and 1/2.",
    "start": "2655581",
    "end": "2663740"
  },
  {
    "text": "So what's changed? Now the question is,\nhow could I model this?",
    "start": "2663740",
    "end": "2669390"
  },
  {
    "text": "Could I actually\nget a model that would give me a sense\nof how this is changing? And that's why I'm going\nto use cross-validation.",
    "start": "2669390",
    "end": "2677250"
  },
  {
    "text": "I'm going to run through a\nnumber of trials, 10 trials. I'm going to try and fit\nfour different models,",
    "start": "2677250",
    "end": "2683790"
  },
  {
    "start": "2681000",
    "end": "2681000"
  },
  {
    "text": "linear, quadratic,\ncubic, quartic. And for each of\nthese dimensions,",
    "start": "2683790",
    "end": "2689822"
  },
  {
    "text": "I'm going to get out a\nset of r-squared values. So I'm just going to initialize\nthat dictionary. an empty list.",
    "start": "2689822",
    "end": "2696850"
  },
  {
    "text": "Now here is how I'm\ngoing to do this. Got a list of x-values. Those are years. Got a list of y values.",
    "start": "2696850",
    "end": "2702359"
  },
  {
    "text": "Those are average\nhighs, daily highs. I'm going to create a\nlist of random samples.",
    "start": "2702360",
    "end": "2710730"
  },
  {
    "text": "So if you haven't seen this\nbefore, random.sample says, given this iterator,\nwhich you can think",
    "start": "2710730",
    "end": "2715880"
  },
  {
    "text": "of as the collection\nfrom 0 up to n minus 1, it's going to select this many\nor half of them, in this case,",
    "start": "2715880",
    "end": "2723619"
  },
  {
    "text": "of those numbers at random. So if I give it 0 up to 9,\nand I say, pick five of them,",
    "start": "2723620",
    "end": "2730310"
  },
  {
    "text": "it will, at random, give me\nback 5 of those 10 numbers, with no duplicates.",
    "start": "2730310",
    "end": "2736109"
  },
  {
    "text": "Ah, that's nice. Because now notice\nwhat I can do. I'm going to set up a training--",
    "start": "2736110",
    "end": "2741440"
  },
  {
    "text": "sorry, an x and y values\nfor a training set, x and y values for the test set. And I'm just going to\nrun through a loop here,",
    "start": "2741440",
    "end": "2747586"
  },
  {
    "text": "where if this index\nis in that list, I'll stick it in\nthe training set.",
    "start": "2747586",
    "end": "2753600"
  },
  {
    "text": "Otherwise, I'll stick\nit in the test set. And then I just return them.",
    "start": "2753600",
    "end": "2759380"
  },
  {
    "text": "So this is a really nice\nway of, at random, just splitting the data set into a\ntest set and a training set.",
    "start": "2759380",
    "end": "2768519"
  },
  {
    "text": "And then finally, I can run\nover the number of trials I want to deal with. In each case, get a\ndifferent training",
    "start": "2768520",
    "end": "2775330"
  },
  {
    "start": "2770000",
    "end": "2770000"
  },
  {
    "text": "and test set, at random. And then, for each\ndimension, do the fit.",
    "start": "2775330",
    "end": "2780640"
  },
  {
    "text": "There's polyfit on the training\nx and training y values in that dimension. Gives you back a model.",
    "start": "2780640",
    "end": "2786670"
  },
  {
    "text": "I could just check to see how\nwell the training set gets, but I really want to look\nat, given that model,",
    "start": "2786670",
    "end": "2792250"
  },
  {
    "text": "how well does polyval\npredict the test set, right? The model will say, here's\nwhat I expect is the values.",
    "start": "2792250",
    "end": "2799640"
  },
  {
    "text": "I'm going to compare\nthat to the actual values that I saw from\nthe training set,",
    "start": "2799640",
    "end": "2804740"
  },
  {
    "text": "computing that r squared\nvalue and adding it in. And then the last\nof this just says,",
    "start": "2804740",
    "end": "2809840"
  },
  {
    "text": "I'll run this through\na set of examples. OK, here's what\nhappens if I do that.",
    "start": "2809840",
    "end": "2816880"
  },
  {
    "text": "I'm not going to run it,\nalthough the code will run it. Let me, again, remind\nyou what I'm doing. I got a big set\nof data I'm going",
    "start": "2816880",
    "end": "2823190"
  },
  {
    "text": "to pick out at\nrandom, subsets of it, build the model on one part,\ntest it on the other part.",
    "start": "2823190",
    "end": "2829380"
  },
  {
    "text": "And if I run it, I get a linear\nfit, quadratic fit, cubic fit,",
    "start": "2829380",
    "end": "2836640"
  },
  {
    "text": "and a quartic fit. And here's the standard\ndeviation of those samples. Remember, I've got\nmultiple trials.",
    "start": "2836640",
    "end": "2842550"
  },
  {
    "text": "I've got 10 trials,\nin this case. So this gives me the\naverage over those trials. And this tells me\nhow much they vary.",
    "start": "2842550",
    "end": "2849150"
  },
  {
    "text": "What can I conclude from this? Well, I would argue that\nthe linear fit's probably",
    "start": "2849150",
    "end": "2854950"
  },
  {
    "text": "the winner here. Goes back to Einstein. I want the simplest possible\nmodel that accounts for it.",
    "start": "2854950",
    "end": "2861550"
  },
  {
    "text": "And you can see it's got the\nhighest r-squared value, which is already a good sign.",
    "start": "2861550",
    "end": "2866800"
  },
  {
    "text": "It's got the smallest\ndeviation across the trials, which says it's probably\na pretty good fit.",
    "start": "2866800",
    "end": "2872170"
  },
  {
    "text": "And it's the simplest model. So linear sounds like\na pretty good fit.",
    "start": "2872170",
    "end": "2878250"
  },
  {
    "text": "Now, why should we run multiple\ndata sets to test this? I ran 10 trials of each\none of these dimensions.",
    "start": "2878250",
    "end": "2884940"
  },
  {
    "text": "Why bother with it? Well, notice that\nthose deviations-- I'll go back to it here--",
    "start": "2884940",
    "end": "2891547"
  },
  {
    "text": "they're pretty good. They're about an\norder of magnitude less than the actual mean,\nwhich says they're pretty tight, but they're still\nreasonable size.",
    "start": "2891547",
    "end": "2900032"
  },
  {
    "text": "And that suggests that,\nwhile there's good agreement, the deviations are\nlarge enough that you could see a range of\nvariation across the trials.",
    "start": "2900032",
    "end": "2908329"
  },
  {
    "text": "So in fact, if I had\njust run one trial, I could have been screwed. Sorry, oh-- sorry, pick your\nfavorite [INAUDIBLE] here.",
    "start": "2908330",
    "end": "2915771"
  },
  {
    "text": "[? Hose ?] is a\nCanadian expression, in case you haven't seen it. Here are the r-squared\nvalues for each trial",
    "start": "2915771",
    "end": "2922300"
  },
  {
    "text": "of the linear fit. And you can see the mean\ncomes up pretty well. But notice, if I'd\nonly run one trial",
    "start": "2922300",
    "end": "2928140"
  },
  {
    "text": "and I happened to get\nthat one, oh, darn. That's a really low\nr-squared value.",
    "start": "2928140",
    "end": "2934300"
  },
  {
    "text": "And we might have\ndecided, in this case, a different conclusion, that the\nlinear fit was not a good fit.",
    "start": "2934300",
    "end": "2940730"
  },
  {
    "text": "So this is a way of saying,\neven in a random sampling, run multiple trials,\nbecause it lets you",
    "start": "2940730",
    "end": "2946630"
  },
  {
    "text": "get statistics on those\ntrials, as well as statistics within each trial. So with any trial, I'm\ndoing a whole bunch",
    "start": "2946630",
    "end": "2952450"
  },
  {
    "text": "of different random samples\non measuring those values. And then, across\nthose trials, I'm seeing what the deviation is.",
    "start": "2952450",
    "end": "2958744"
  },
  {
    "text": "I'm going to hope my\nmachine comes back, because what I want to do\nis then pull this together.",
    "start": "2958744",
    "end": "2964030"
  },
  {
    "text": "What have we done? Something you're going to use. We've seen how you can\nuse linear regression to fit a curve to data,\n2D, 3D, 6D, however big",
    "start": "2964030",
    "end": "2973800"
  },
  {
    "text": "the data set is. It gives us a mapping from\nthe independent values to the dependent values.",
    "start": "2973800",
    "end": "2979440"
  },
  {
    "text": "And that can then be\nused to predict values associated with the\nindependent values that we haven't seen yet.",
    "start": "2979440",
    "end": "2986339"
  },
  {
    "text": "That leads, naturally,\nto both a way to measure, which is r\nsquared, but especially",
    "start": "2986340",
    "end": "2992430"
  },
  {
    "text": "to see that we want to look\nat how well does that model actually predict new data,\nbecause that lets us select",
    "start": "2992430",
    "end": "2999300"
  },
  {
    "text": "the simplest model we can\nthat accounts for the data, but predicts new data\nin an effective way.",
    "start": "2999300",
    "end": "3006140"
  },
  {
    "text": "And that complexity\ncan either be based on theory, in the case of\nHooke, or in more likely cases,",
    "start": "3006140",
    "end": "3011510"
  },
  {
    "text": "by doing cross-validation\nto try and figure out which one is the\nsimplest model that",
    "start": "3011510",
    "end": "3016640"
  },
  {
    "text": "still does a good\njob of predicting out of data behavior.",
    "start": "3016640",
    "end": "3021980"
  },
  {
    "text": "And with that, I'll\nsee you next time. ",
    "start": "3021980",
    "end": "3032803"
  }
]
[
  {
    "start": "0",
    "end": "100000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18140",
    "end": "23660"
  },
  {
    "text": "CHARLES LEISERSON:\nSo welcome to 6.172. My name is Charles\nLeiserson, and I am one",
    "start": "23660",
    "end": "30140"
  },
  {
    "text": "of the two lecturers this term. The other is\nProfessor Julian Shun.",
    "start": "30140",
    "end": "35570"
  },
  {
    "text": "We're both in EECS and in CSAIL\non the 7th floor of the Gates",
    "start": "35570",
    "end": "41010"
  },
  {
    "text": "Building.  If you don't know it, you are\nin Performance Engineering",
    "start": "41010",
    "end": "49360"
  },
  {
    "text": "of Software Systems, so\nif you found yourself in the wrong place,\nnow's the time to exit.",
    "start": "49360",
    "end": "57180"
  },
  {
    "text": "I want to start today by\ntalking a little bit about why",
    "start": "57180",
    "end": "62430"
  },
  {
    "text": "we do performance\nengineering, and then I'll do a little bit\nof administration,",
    "start": "62430",
    "end": "69630"
  },
  {
    "text": "and then sort of dive into\nsort of a case study that will give you a good sense\nof some of the things",
    "start": "69630",
    "end": "75540"
  },
  {
    "text": "that we're going to\ndo during the term. I put the administration\nin the middle,",
    "start": "75540",
    "end": "80980"
  },
  {
    "text": "because it's like, if from me\ntelling you about the course you don't want to\ndo the course, then",
    "start": "80980",
    "end": "87360"
  },
  {
    "text": "it's like, why should you listen\nto the administration, right? It's like-- ",
    "start": "87360",
    "end": "94590"
  },
  {
    "text": "So let's just dive right in, OK? So the first thing\nto always understand",
    "start": "94590",
    "end": "99943"
  },
  {
    "text": "whenever you're\ndoing something is a perspective on what\nmatters in what you're doing.",
    "start": "99943",
    "end": "105780"
  },
  {
    "start": "100000",
    "end": "184000"
  },
  {
    "text": "So the whole term, we're going\nto do software performance engineering. And so this is kind\nof interesting,",
    "start": "105780",
    "end": "112590"
  },
  {
    "text": "because it turns out that\nperformance is usually not at the top of what people\nare interested in when they're",
    "start": "112590",
    "end": "119549"
  },
  {
    "text": "building software. OK? What are some of the\nthings that are more important than performance?",
    "start": "119550",
    "end": "127610"
  },
  {
    "text": "Yeah? AUDIENCE: Deadlines. CHARLES LEISERSON: Deadlines. Good. AUDIENCE: Cost. CHARLES LEISERSON: Cost.",
    "start": "127610",
    "end": "133333"
  },
  {
    "text": "AUDIENCE: Correctness. CHARLES LEISERSON: Correctness. AUDIENCE: Extensibility. CHARLES LEISERSON:\nExtensibility.",
    "start": "133333",
    "end": "138420"
  },
  {
    "text": "Yeah, maybe we\ncould go on and on. And I think that you\nfolks could probably make a pretty long list.",
    "start": "138420",
    "end": "144959"
  },
  {
    "text": "I made a short list\nof all the kinds of things that are more\nimportant than performance.",
    "start": "144960",
    "end": "150900"
  },
  {
    "text": "So then, if programmers\nare so willing to sacrifice performance for\nthese properties,",
    "start": "150900",
    "end": "157770"
  },
  {
    "text": "why do we study performance? OK? So this is kind of a bit of a\nparadox and a bit of a puzzle.",
    "start": "157770",
    "end": "166140"
  },
  {
    "text": "Why do you study\nsomething that clearly isn't at the top\nof the list of what",
    "start": "166140",
    "end": "171930"
  },
  {
    "text": "most people care about when\nthey're developing software? I think the answer to\nthat is that performance",
    "start": "171930",
    "end": "181140"
  },
  {
    "text": "is the currency of computing. OK? You use performance to buy\nthese other properties.",
    "start": "181140",
    "end": "188590"
  },
  {
    "start": "184000",
    "end": "308000"
  },
  {
    "text": "So you'll say\nsomething like, gee, I want to make it\neasy to program, and so therefore I'm willing\nto sacrifice some performance",
    "start": "188590",
    "end": "196650"
  },
  {
    "text": "to make something\neasy to program. I'm willing to sacrifice\nsome performance to make sure",
    "start": "196650",
    "end": "202200"
  },
  {
    "text": "that my system is secure. OK? And all those things come out\nof your performance budget.",
    "start": "202200",
    "end": "209010"
  },
  {
    "text": "And clearly if performance\ndegrades too far, your stuff becomes unusable.",
    "start": "209010",
    "end": "214760"
  },
  {
    "text": "OK? When I talk with people,\nwith programmers, and I say-- you know, people are fond\nof saying, ah, performance.",
    "start": "214760",
    "end": "221700"
  },
  {
    "text": "Oh, you do performance? Performance doesn't matter. I never think about it. Then I talk with people\nwho use computers,",
    "start": "221700",
    "end": "230610"
  },
  {
    "text": "and I ask, what's your main\ncomplaint about the computing systems you use?",
    "start": "230610",
    "end": "236019"
  },
  {
    "text": "Answer? Too slow. [CHUCKLES] OK? So it's interesting,\nwhether you're the producer",
    "start": "236020",
    "end": "241690"
  },
  {
    "text": "or whatever. But the real answer is that\nperformance is like currency.",
    "start": "241690",
    "end": "247083"
  },
  {
    "text": "It's something you spend.  If you look-- you\nknow, would I rather",
    "start": "247083",
    "end": "252880"
  },
  {
    "text": "have $100 or a gallon of water? Well, water is\nindispensable to life.",
    "start": "252880",
    "end": "260930"
  },
  {
    "text": "There are circumstances,\ncertainly, where I would prefer\nto have the water. OK?",
    "start": "260930",
    "end": "266060"
  },
  {
    "text": "Than $100. OK? But in our modern\nsociety, I can buy",
    "start": "266060",
    "end": "272030"
  },
  {
    "text": "water for much less than $100. OK? So even though water\nis essential to life",
    "start": "272030",
    "end": "280760"
  },
  {
    "text": "and far more important than\nmoney, money is a currency, and so I prefer to have the\nmoney because I can just",
    "start": "280760",
    "end": "288200"
  },
  {
    "text": "buy the things I need. And that's the same kind\nof analogy of performance. It has no intrinsic value,\nbut it contributes to things.",
    "start": "288200",
    "end": "298500"
  },
  {
    "text": "You can use it to buy\nthings that you care about like usability or\ntestability or what have you.",
    "start": "298500",
    "end": "305360"
  },
  {
    "text": "OK? Now, in the early\ndays of computing, software performance\nengineering was common",
    "start": "305360",
    "end": "312530"
  },
  {
    "start": "308000",
    "end": "3599000"
  },
  {
    "text": "because machine\nresources were limited. If you look at these\nmachines from 1964 to 1977--",
    "start": "312530",
    "end": "320720"
  },
  {
    "text": "I mean, look at how many bytes\nthey have on them, right? In '64, there is a computer\nwith 524 kilobytes.",
    "start": "320720",
    "end": "331070"
  },
  {
    "text": "OK? That was a big\nmachine back then. That's kilobytes.",
    "start": "331070",
    "end": "336190"
  },
  {
    "text": "That's not megabytes,\nthat's not gigabytes. That's kilobytes. OK? And many programs would strain\nthe machine resources, OK?",
    "start": "336190",
    "end": "346479"
  },
  {
    "text": "The clock rate for that\nmachine was 33 kilohertz. What's a typical\nclock rate today?",
    "start": "346480",
    "end": "353524"
  },
  {
    "text": "AUDIENCE: 4 gigahertz. CHARLES LEISERSON: About what? AUDIENCE: 4 gigahertz. CHARLES LEISERSON: 4 gigahertz,\n3 gigahertz, 2 gigahertz,",
    "start": "353524",
    "end": "359270"
  },
  {
    "text": "somewhere up there. Yeah, somewhere\nin that range, OK? And here they were\noperating with kilohertz.",
    "start": "359270",
    "end": "365370"
  },
  {
    "text": "So many programs would not fit\nwithout intense performance engineering.",
    "start": "365370",
    "end": "371040"
  },
  {
    "text": "And one of the things, also-- there's a lot of sayings\nthat came out of that era.",
    "start": "371040",
    "end": "377879"
  },
  {
    "text": "Donald Knuth, who's a Turing\nAward winner, absolutely",
    "start": "377880",
    "end": "383940"
  },
  {
    "text": "fabulous computer\nscientist in all respects, wrote, \"Premature optimization\nis the root of all evil.\"",
    "start": "383940",
    "end": "390408"
  },
  {
    "text": "And I invite you,\nby the way, to look that quote up because it's\nactually taken out of context.",
    "start": "390408",
    "end": "395560"
  },
  {
    "text": "OK? So trying to optimize stuff\ntoo early he was worried about. OK? Bill Wulf, who designed\nthe BLISS language",
    "start": "395560",
    "end": "405480"
  },
  {
    "text": "and worked on the\nPDP-11 and such, said, \"More computing\nsins are committed in the name of efficiency\nwithout necessarily achieving",
    "start": "405480",
    "end": "412770"
  },
  {
    "text": "it than for any other\nsingle reason, including blind stupidity.\"",
    "start": "412770",
    "end": "417889"
  },
  {
    "text": "OK? And Michael Jackson\nsaid, \"The first rule of program optimization-- don't do it.",
    "start": "417890",
    "end": "423780"
  },
  {
    "text": "Second rule of\nprogram optimization, for experts only-- don't do it yet.\"",
    "start": "423780",
    "end": "428870"
  },
  {
    "text": "[CHUCKLES] OK? So everybody warning\naway, because when you start trying to\nmake things fast, your code becomes unreadable.",
    "start": "428870",
    "end": "435760"
  },
  {
    "text": "OK? Making code that is\nreadable and fast-- now that's where the art\nis, and hopefully we'll",
    "start": "435760",
    "end": "441540"
  },
  {
    "text": "learn a little bit\nabout doing that. OK? And indeed, there\nwas no real point",
    "start": "441540",
    "end": "448350"
  },
  {
    "text": "in working too\nhard on performance engineering for many years.",
    "start": "448350",
    "end": "455490"
  },
  {
    "text": "If you look at\ntechnology scaling and you look at how\nmany transistors are on various processor\ndesigns, up until about 2004,",
    "start": "455490",
    "end": "465750"
  },
  {
    "text": "we had Moore's law\nin full throttle, OK?",
    "start": "465750",
    "end": "472830"
  },
  {
    "text": "With chip densities\ndoubling every two years. And really quite amazing.",
    "start": "472830",
    "end": "480930"
  },
  {
    "text": "And along with that, as\nthey shrunk the dimensions of chips-- because by miniaturization--\nthe clock speed would go up",
    "start": "480930",
    "end": "489180"
  },
  {
    "text": "correspondingly, as well. And so, if you found\nsomething was too slow,",
    "start": "489180",
    "end": "494990"
  },
  {
    "text": "wait a couple of years. OK? Wait a couple of years. It'll be faster.",
    "start": "494990",
    "end": "501100"
  },
  {
    "text": "OK? And so, you know,\nif you were going to do something with software\nand make your software ugly,",
    "start": "501100",
    "end": "507880"
  },
  {
    "text": "there wasn't a real\ngood payoff compared",
    "start": "507880",
    "end": "518590"
  },
  {
    "text": "to just simply waiting around. And in that era,\nthere was something",
    "start": "518590",
    "end": "525020"
  },
  {
    "text": "called Dennard scaling,\nwhich, as things shrunk,",
    "start": "525020",
    "end": "533430"
  },
  {
    "text": "allowed the clock speeds\nto get larger, basically by reducing power.",
    "start": "533430",
    "end": "539670"
  },
  {
    "text": "You could reduce power and\nstill keep everything fast, and we'll talk about\nthat in a minute. So if you look at what\nhappened to from 1977 to 2004--",
    "start": "539670",
    "end": "550040"
  },
  {
    "text": "here are Apple computers\nwith similar price tags,",
    "start": "550040",
    "end": "556350"
  },
  {
    "text": "and you can see the clock\nrate really just skyrocketed.",
    "start": "556350",
    "end": "561750"
  },
  {
    "text": "1 megahertz, 400 megahertz,\n1.8 gigahertz, OK?",
    "start": "561750",
    "end": "567060"
  },
  {
    "text": "And the data paths went\nfrom 8 bits to 30 to 64. The memory,\ncorrespondingly, grows.",
    "start": "567060",
    "end": "572880"
  },
  {
    "text": "Cost? Approximately the same. And that's the legacy\nfrom Moore's law",
    "start": "572880",
    "end": "578160"
  },
  {
    "text": "and the tremendous advances\nin semiconductor technology.",
    "start": "578160",
    "end": "583170"
  },
  {
    "text": "And so, until 2004,\nMoore's law and the scaling of clock frequency,\nso-called Dennard scaling,",
    "start": "583170",
    "end": "590610"
  },
  {
    "text": "was essentially a printing\npress for the currency of performance. OK? You didn't have to do anything.",
    "start": "590610",
    "end": "595998"
  },
  {
    "text": "You just made the\nhardware go faster. Very easy. And all that came to an end--",
    "start": "595998",
    "end": "603330"
  },
  {
    "text": "well, some of it\ncame to an end-- in 2004 when clock\nspeeds plateaued.",
    "start": "603330",
    "end": "609750"
  },
  {
    "text": "OK? So if you look at\nthis, around 2005, you can see all the speeds-- we hit, you know,\n2 to 4 gigahertz,",
    "start": "609750",
    "end": "618030"
  },
  {
    "text": "and we have not been able\nto make chips go faster than that in any\npractical way since then.",
    "start": "618030",
    "end": "625060"
  },
  {
    "text": "But the densities\nhave kept going great. Now, the reason that the\nclock speed flattened",
    "start": "625060",
    "end": "630960"
  },
  {
    "text": "was because of power density. And this is a slide from\nIntel from that era,",
    "start": "630960",
    "end": "637050"
  },
  {
    "text": "looking at the growth\nof power density. And what they were\nprojecting was that the junction temperatures\nof the transistors on the chip,",
    "start": "637050",
    "end": "646500"
  },
  {
    "text": "if they just keep scaling the\nway they had been scaling, would start to\napproach, first of all,",
    "start": "646500",
    "end": "654389"
  },
  {
    "text": "the temperature of a\nnuclear reactor, then the temperature of\na rocket nozzle, and then the sun's surface.",
    "start": "654390",
    "end": "660110"
  },
  {
    "text": "OK? So that we're not going\nto build little technology that cools that very well. And even if you could\nsolve it for a little bit,",
    "start": "660110",
    "end": "667353"
  },
  {
    "text": "the writing was on the wall. We cannot scale clock\nfrequencies any more. The reason for that is that,\noriginally, clock frequency",
    "start": "667353",
    "end": "674070"
  },
  {
    "text": "was scaled assuming\nthat most of the power was dynamic power,\nwhich was going",
    "start": "674070",
    "end": "680100"
  },
  {
    "text": "when you switched the circuit. And what happened as we kept\nreducing that and reducing that is, something that used\nto be in the noise, namely",
    "start": "680100",
    "end": "687180"
  },
  {
    "text": "the leakage\ncurrents, OK, started to become significant\nto the point where--",
    "start": "687180",
    "end": "693270"
  },
  {
    "text": "now, today-- the\ndynamic power is far less of a concern\nthan the static power",
    "start": "693270",
    "end": "700080"
  },
  {
    "text": "from just the circuit\nsitting there leaking, and when you miniaturize,\nyou can't stop that effect",
    "start": "700080",
    "end": "708209"
  },
  {
    "text": "from happening. So what did the vendors\ndo in 2004 and 2005",
    "start": "708210",
    "end": "714090"
  },
  {
    "text": "and since is, they\nsaid, oh, gosh, we've got all these\ntransistors to use,",
    "start": "714090",
    "end": "720780"
  },
  {
    "text": "but we can't use the transistors\nto make stuff run faster.",
    "start": "720780",
    "end": "726000"
  },
  {
    "text": "So what they did is, they\nintroduced parallelism in the form of\nmulticore processors.",
    "start": "726000",
    "end": "731070"
  },
  {
    "text": "They put more than one\nprocessing core in a chip. And to scale performance,\nthey would, you know,",
    "start": "731070",
    "end": "739380"
  },
  {
    "text": "have multiple cores, and each\ngeneration of Moore's law now was potentially doubling\nthe number of cores.",
    "start": "739380",
    "end": "747900"
  },
  {
    "text": "And so if you look at what\nhappened for processor cores, you see that around\n2004, 2005, we started",
    "start": "747900",
    "end": "757200"
  },
  {
    "text": "to get multiple processing\ncores per chip, to the extent that today, it's\nbasically impossible",
    "start": "757200",
    "end": "763650"
  },
  {
    "text": "to find a single-core chip\nfor a laptop or a workstation or whatever.",
    "start": "763650",
    "end": "768810"
  },
  {
    "text": "Everything is multicore. You can't buy just one. You have to buy a\nparallel processor.",
    "start": "768810",
    "end": "774149"
  },
  {
    "start": "774150",
    "end": "779550"
  },
  {
    "text": "And so the impact of\nthat was that performance was no longer free. You couldn't just\nspeed up the hardware.",
    "start": "779550",
    "end": "785759"
  },
  {
    "text": "Now if you wanted to\nuse that potential, you had to do\nparallel programming, and that's not something\nthat anybody in the industry",
    "start": "785760",
    "end": "792090"
  },
  {
    "text": "really had done. So today, there are\na lot of other things",
    "start": "792090",
    "end": "798000"
  },
  {
    "text": "that happened in that\nintervening time. We got vector units as\ncommon parts of our machines;",
    "start": "798000",
    "end": "803910"
  },
  {
    "text": "we got GPUs; we got\nsteeper cache hierarchies;",
    "start": "803910",
    "end": "808920"
  },
  {
    "text": "we have configurable logic on\nsome machines; and so forth. And now it's up to the\nsoftware to adapt to it.",
    "start": "808920",
    "end": "816180"
  },
  {
    "text": "And so, although we\ndon't want to have to deal with\nperformance, today you",
    "start": "816180",
    "end": "821700"
  },
  {
    "text": "have to deal with performance. And in your lifetimes,\nyou will have to deal with\nperformance in software",
    "start": "821700",
    "end": "828070"
  },
  {
    "text": "if you're going to have\neffective software. OK? You can see what\nhappened, also--",
    "start": "828070",
    "end": "834000"
  },
  {
    "text": "this is a study\nthat we did looking at software bugs in a variety\nof open-source projects",
    "start": "834000",
    "end": "843360"
  },
  {
    "text": "where they're mentioning\nthe word \"performance.\" And you can see that in 2004,\nthe numbers start going up.",
    "start": "843360",
    "end": "849725"
  },
  {
    "text": "You know, some of\nthem-- it's not as convincing for\nsome things as others, but generally there's\na trend of, after 2004,",
    "start": "849725",
    "end": "858360"
  },
  {
    "text": "people started worrying\nmore about performance. If you look at software\ndeveloper jobs,",
    "start": "858360",
    "end": "865590"
  },
  {
    "text": "as of around early, mid-2000s-- the 2000 \"oh oh's,\"\nI guess, OK--",
    "start": "865590",
    "end": "874530"
  },
  {
    "text": "you see once again the mention\nof \"performance\" in jobs is going up. And anecdotally,\nI can tell you, I",
    "start": "874530",
    "end": "882270"
  },
  {
    "text": "had one student who came\nto me after the spring, after he'd taken\n6.172, and he said,",
    "start": "882270",
    "end": "890100"
  },
  {
    "text": "you know, I went and I\napplied for five jobs. And every job asked me,\nat every job interview,",
    "start": "890100",
    "end": "899112"
  },
  {
    "text": "they asked me a\nquestion I couldn't have answered if I hadn't taken\n6.172, and I got five offers.",
    "start": "899112",
    "end": "906000"
  },
  {
    "text": "OK? And when I compared\nthose offers, they tended to be 20% to\n30% larger than people",
    "start": "906000",
    "end": "911860"
  },
  {
    "text": "who are just web monkeys. OK? So anyway. [LAUGHTER] That's not to say that\nyou should necessarily",
    "start": "911860",
    "end": "919690"
  },
  {
    "text": "take this class, OK? But I just want to point out\nthat what we're going to learn",
    "start": "919690",
    "end": "924910"
  },
  {
    "text": "is going to be interesting\nfrom a practical point of view, i.e., your futures.",
    "start": "924910",
    "end": "930720"
  },
  {
    "text": "OK? As well as theoretical\npoints of view and technical points of view. OK?",
    "start": "930720",
    "end": "936490"
  },
  {
    "text": "So modern processors\nare really complicated, and the big question\nis, how do we",
    "start": "936490",
    "end": "943420"
  },
  {
    "text": "write software to use that\nmodern hardware efficiently? OK?",
    "start": "943420",
    "end": "949800"
  },
  {
    "text": "I want to give you an example\nof performance engineering of a very well-studied problem,\nnamely matrix multiplication.",
    "start": "949800",
    "end": "958170"
  },
  {
    "text": "Who has never seen this problem? [LAUGHS] Yeah.",
    "start": "958170",
    "end": "964250"
  },
  {
    "text": "OK, so we got some jokers\nin the class, I can see. OK.",
    "start": "964250",
    "end": "970230"
  },
  {
    "text": "So, you know, it takes\nn cubed operations, because you're basically\ncomputing n squared",
    "start": "970230",
    "end": "976310"
  },
  {
    "text": "dot products. OK? So essentially, if you add up\nthe total number of operations,",
    "start": "976310",
    "end": "982709"
  },
  {
    "text": "it's about 2n cubed because\nthere is essentially a multiply and an add\nfor every pair of terms",
    "start": "982710",
    "end": "989790"
  },
  {
    "text": "that need to be accumulated. OK? So it's basically 2n cubed. We're going to\nlook at it assuming",
    "start": "989790",
    "end": "995610"
  },
  {
    "text": "for simplicity that our n\nis an exact power of 2, OK?",
    "start": "995610",
    "end": "1002209"
  },
  {
    "text": "Now, the machine that\nwe're going to look at is going to be one of\nthe ones that you'll",
    "start": "1002210",
    "end": "1009890"
  },
  {
    "text": "have access to in AWS. OK? It's a compute-optimized\nmachine,",
    "start": "1009890",
    "end": "1017120"
  },
  {
    "text": "which has a Haswell\nmicroachitecture running at 2.9 gigahertz.",
    "start": "1017120",
    "end": "1023190"
  },
  {
    "text": "There are 2 processor chips\nfor each of these machines and 9 processing cores per\nchip, so a total of 18 cores.",
    "start": "1023190",
    "end": "1034490"
  },
  {
    "text": "So that's the amount\nof parallel processing. It does two-way hyperthreading,\nwhich we're actually",
    "start": "1034490",
    "end": "1041390"
  },
  {
    "text": "going to not deal a lot with. Hyperthreading gives you a\nlittle bit more performance,",
    "start": "1041390",
    "end": "1047959"
  },
  {
    "text": "but it also makes it really\nhard to measure things, so generally we will\nturn off hyperthreading.",
    "start": "1047960",
    "end": "1053540"
  },
  {
    "text": "But the performance\nthat you get tends to be correlated with what\nyou get when you hyperthread.",
    "start": "1053540",
    "end": "1060650"
  },
  {
    "text": "For floating-point\nunit there, it is capable of doing 8\ndouble-precision precision operations.",
    "start": "1060650",
    "end": "1066170"
  },
  {
    "text": "That's 64-bit\nfloating-point operations, including a fused-multiply-add\nper core, per cycle.",
    "start": "1066170",
    "end": "1074340"
  },
  {
    "text": "OK? So that's a vector unit. So basically, each\nof these 18 cores can do 8 double-precision\noperations,",
    "start": "1074340",
    "end": "1084400"
  },
  {
    "text": "including a fused-multiply-add,\nwhich is actually 2 operations. OK? The way that they\ncount these things, OK?",
    "start": "1084400",
    "end": "1091570"
  },
  {
    "text": "It has a cache-line\nsize of 64 bytes. The icache is 32 kilobytes,\nwhich is 8-way set associative.",
    "start": "1091570",
    "end": "1099377"
  },
  {
    "text": "We'll talk about\nsome of these things. If you don't know all\nthe terms, it's OK. We're going to cover most\nof these terms later on.",
    "start": "1099377",
    "end": "1105830"
  },
  {
    "text": "It's got a dcache\nof the same size. It's got an L2-cache\nof 256 kilobytes,",
    "start": "1105830",
    "end": "1112929"
  },
  {
    "text": "and it's got an\nL3-cache or what's sometimes called an\nLLC, Last-Level Cache,",
    "start": "1112930",
    "end": "1118149"
  },
  {
    "text": "of 25 megabytes. And then it's got 60\ngigabytes of DRAM.",
    "start": "1118150",
    "end": "1123429"
  },
  {
    "text": "So this is a\nhonking big machine. OK? This is like-- you can get\nthings to sing on this, OK?",
    "start": "1123430",
    "end": "1129750"
  },
  {
    "text": "If you look at the\npeak performance, it's the clock speed\ntimes 2 processor",
    "start": "1129750",
    "end": "1136890"
  },
  {
    "text": "chips times 9 processing\ncores per chip, each capable",
    "start": "1136890",
    "end": "1145140"
  },
  {
    "text": "of, if you can use both\nthe multiply and the add, 16 floating-point\noperations, and that goes out",
    "start": "1145140",
    "end": "1153960"
  },
  {
    "text": "to just short of teraflop, OK? 836 gigaflops.",
    "start": "1153960",
    "end": "1160090"
  },
  {
    "text": "So that's a lot of power, OK? That's a lot of power. These are fun\nmachines, actually, OK?",
    "start": "1160090",
    "end": "1166240"
  },
  {
    "text": "Especially when we get into\nthings like the game-playing AI",
    "start": "1166240",
    "end": "1172597"
  },
  {
    "text": "and stuff that we do\nfor the fourth project. You'll see. They're really fun. You can have a lot\nof compute, OK?",
    "start": "1172597",
    "end": "1178910"
  },
  {
    "text": "Now here's the basic code. This is the full code\nfor Python for doing",
    "start": "1178910",
    "end": "1184190"
  },
  {
    "text": "matrix multiplication. Now, generally, in Python,\nyou wouldn't use this code because you just call a\nlibrary subroutine that",
    "start": "1184190",
    "end": "1190940"
  },
  {
    "text": "does matrix multiplication. But sometimes you\nhave a problem. I'm going to illustrate\nwith matrix multiplication,",
    "start": "1190940",
    "end": "1196670"
  },
  {
    "text": "but sometimes you have\na problem for which you have to write the code.",
    "start": "1196670",
    "end": "1202910"
  },
  {
    "text": "And I want to give you an idea\nof what kind of performance you get out of Python, OK?",
    "start": "1202910",
    "end": "1208400"
  },
  {
    "text": "In addition, somebody has to\nwrite-- if there is a library routine, somebody\nhad to write it,",
    "start": "1208400",
    "end": "1213920"
  },
  {
    "text": "and that person was a\nperformance engineer, because they wrote it to\nbe as fast as possible. And so this will give you\nan idea of what you can",
    "start": "1213920",
    "end": "1220520"
  },
  {
    "text": "do to make code run fast, OK? So when you run this code-- so you can see that\nthe start time--",
    "start": "1220520",
    "end": "1227230"
  },
  {
    "text": "you know, before the\ntriply-nested loop-- right here, before the\ntriply-nested loop,",
    "start": "1227230",
    "end": "1234140"
  },
  {
    "text": "we take a time\nmeasurement, and then we take another time\nmeasurement at the end, and then we print\nthe difference.",
    "start": "1234140",
    "end": "1239809"
  },
  {
    "text": "And then that's just this\nclassic triply-nested loop for matrix multiplication.",
    "start": "1239810",
    "end": "1247923"
  },
  {
    "text": "And so, when you run this,\nhow long is this run for, you think? ",
    "start": "1247923",
    "end": "1255380"
  },
  {
    "text": "Any guesses? Let's see. How about-- let's do this.",
    "start": "1255380",
    "end": "1260560"
  },
  {
    "text": "It runs for 6 microseconds. Who thinks 6 microseconds?",
    "start": "1260560",
    "end": "1266000"
  },
  {
    "text": "How about 6 milliseconds? How about-- 6 milliseconds.",
    "start": "1266000",
    "end": "1271780"
  },
  {
    "text": "How about 6 seconds?  How about 6 minutes?",
    "start": "1271780",
    "end": "1277625"
  },
  {
    "text": " OK. How about 6 hours?",
    "start": "1277625",
    "end": "1282926"
  },
  {
    "text": "[LAUGHTER] How about 6 days? [LAUGHTER] OK.",
    "start": "1282926",
    "end": "1288897"
  },
  {
    "text": "Of course, it's important\nto know what size it is. It's 4,096 by 4,096, as\nit shows in the code, OK?",
    "start": "1288897",
    "end": "1296890"
  },
  {
    "text": "And those of you\nwho didn't vote-- wake up. Let's get active. This is active learning.",
    "start": "1296890",
    "end": "1302870"
  },
  {
    "text": "Put yourself out there, OK? It doesn't matter whether\nyou're right or wrong. There'll be a bunch of people\nwho got the right answer, but they have no idea why.",
    "start": "1302870",
    "end": "1309050"
  },
  {
    "text": "[LAUGHTER] OK? So it turns out, it takes\nabout 21,000 seconds,",
    "start": "1309050",
    "end": "1315390"
  },
  {
    "text": "which is about 6 hours. OK? Amazing. Is this fast?",
    "start": "1315390",
    "end": "1322437"
  },
  {
    "text": "AUDIENCE: (SARCASTICALLY) Yeah. [LAUGHTER] CHARLES LEISERSON: Yeah, right. Duh, right?",
    "start": "1322437",
    "end": "1327938"
  },
  {
    "text": "Is this fast? No. You know, how do we tell\nwhether this is fast or not?",
    "start": "1327938",
    "end": "1335549"
  },
  {
    "text": "OK? You know, what should we\nexpect from our machine? So let's do a\nback-of-the-envelope calculation of--",
    "start": "1335550",
    "end": "1342050"
  },
  {
    "text": "[LAUGHTER] --of how many\noperations there are and how fast we ought\nto be able to do it.",
    "start": "1342050",
    "end": "1348340"
  },
  {
    "text": "We just went through\nand said what are all the parameters\nof the machine. So there are 2n cubed operations\nthat need to be performed.",
    "start": "1348340",
    "end": "1355130"
  },
  {
    "text": "We're not doing Strassen's\nalgorithm or anything like that. We're just doing a straight\ntriply-nested loop.",
    "start": "1355130",
    "end": "1362470"
  },
  {
    "text": "So that's 2 to the 37\nfloating point operations, OK?",
    "start": "1362470",
    "end": "1367539"
  },
  {
    "text": "The running time\nis 21,000 seconds, so that says that we're getting\nabout 6.25 megaflops out",
    "start": "1367540",
    "end": "1376840"
  },
  {
    "text": "of our machine when\nwe run that code, OK? Just by dividing it out, how\nmany floating-point operations",
    "start": "1376840",
    "end": "1384910"
  },
  {
    "text": "per second do we get? We take the number of operations\ndivided by the time, OK?",
    "start": "1384910",
    "end": "1391780"
  },
  {
    "text": "The peak, as you recall,\nwas about 836 gigaflops, OK?",
    "start": "1391780",
    "end": "1397920"
  },
  {
    "text": "And we're getting\n6.25 megaflops, OK?",
    "start": "1397920",
    "end": "1403350"
  },
  {
    "text": "So we're getting about\n0.00075% of peak, OK?",
    "start": "1403350",
    "end": "1414809"
  },
  {
    "text": "This is not fast. OK? This is not fast. ",
    "start": "1414810",
    "end": "1422750"
  },
  {
    "text": "So let's do something\nreally simple. Let's code it in Java\nrather than Python, OK?",
    "start": "1422750",
    "end": "1429799"
  },
  {
    "text": "So we take just that loop. The code is almost the same, OK? Just the triply-nested loop.",
    "start": "1429800",
    "end": "1435470"
  },
  {
    "text": "We run it in Java, OK? And the running time\nnow, it turns out,",
    "start": "1435470",
    "end": "1440510"
  },
  {
    "text": "is about just under\n3,000 seconds, which is about 46 minutes.",
    "start": "1440510",
    "end": "1448750"
  },
  {
    "text": "The same code. Python, Java, OK?",
    "start": "1448750",
    "end": "1453820"
  },
  {
    "text": "We got almost a 9 times\nspeedup just simply",
    "start": "1453820",
    "end": "1460169"
  },
  {
    "text": "coding it in a\ndifferent language, OK? Well, let's try C.\nThat's the language we're",
    "start": "1460170",
    "end": "1467432"
  },
  {
    "text": "going to be using here. What happens when\nyou code it in C? It's exactly the same thing, OK?",
    "start": "1467432",
    "end": "1473220"
  },
  {
    "text": "We're going to use the\nClang/LLVM 5.0 compiler. I believe we're using 6.0\nthis term, is that right?",
    "start": "1473220",
    "end": "1480559"
  },
  {
    "text": "Yeah. OK, I should have rerun these\nnumbers for 6.0, but I didn't.",
    "start": "1480560",
    "end": "1485980"
  },
  {
    "text": "So now, it's basically\n1,100 seconds, which is about 19 minutes,\nso we got, then, about--",
    "start": "1485980",
    "end": "1492799"
  },
  {
    "text": "it's twice as fast as Java\nand about 18 times faster than Python, OK?",
    "start": "1492800",
    "end": "1498120"
  },
  {
    "text": "So here's where we stand so far. OK? We have the running time of\nthese various things, OK?",
    "start": "1498120",
    "end": "1504990"
  },
  {
    "text": "And the relative speedup\nis how much faster it is than the previous row,\nand the absolute speedup is",
    "start": "1504990",
    "end": "1511920"
  },
  {
    "text": "how it is compared\nto the first row, and now we're managing to\nget, now, 0.014% of peak.",
    "start": "1511920",
    "end": "1522340"
  },
  {
    "text": "So we're still slow,\nbut before we go and try",
    "start": "1522340",
    "end": "1527770"
  },
  {
    "text": "to optimize it further-- like, why is Python\nso slow and C so fast?",
    "start": "1527770",
    "end": "1533740"
  },
  {
    "text": "Does anybody know? AUDIENCE: Python is\ninterpreted, so it has to--",
    "start": "1533740",
    "end": "1539290"
  },
  {
    "text": "so there's a C\nprogram that basically parses Python pycode\ninstructions, which takes up most of the time.",
    "start": "1539290",
    "end": "1545463"
  },
  {
    "text": "CHARLES LEISERSON: OK. That's kind of on\nthe right track. Anybody else have any--",
    "start": "1545463",
    "end": "1552570"
  },
  {
    "text": "articulate a little bit\nwhy Python is so slow? Yeah? AUDIENCE: When you write,\nlike, multiplying and add,",
    "start": "1552570",
    "end": "1558830"
  },
  {
    "text": "those aren't the only\ninstructions Python's doing. It's doing lots\nof code for, like, going through Python objects\nand integers and blah-blah-blah.",
    "start": "1558830",
    "end": "1566340"
  },
  {
    "text": "CHARLES LEISERSON: Yeah, yeah. OK, good. So the big reason why Python\nis slow and C is so fast",
    "start": "1566340",
    "end": "1574059"
  },
  {
    "text": "is that Python is interpreted\nand C is compiled directly",
    "start": "1574060",
    "end": "1579760"
  },
  {
    "text": "to machine code. And Java is somewhere\nin the middle because Java is compiled\nto bytecode, which is then",
    "start": "1579760",
    "end": "1586000"
  },
  {
    "text": "interpreted and then\njust-in-time compiled into machine codes. So let me talk a little\nbit about these things.",
    "start": "1586000",
    "end": "1594039"
  },
  {
    "text": "So interpreters, such as in\nPython, are versatile but slow.",
    "start": "1594040",
    "end": "1599995"
  },
  {
    "text": " It's one of these\nthings where they said, we're going to take\nsome of our performance",
    "start": "1599995",
    "end": "1605852"
  },
  {
    "text": "and use it to make\na more flexible, easier-to-program environment. OK? The interpreter basically\nreads, interprets,",
    "start": "1605852",
    "end": "1612880"
  },
  {
    "text": "and performs each program\nstatement and then updates the machine state. So it's not just-- it's actually\ngoing through and, each time,",
    "start": "1612880",
    "end": "1620500"
  },
  {
    "text": "reading your code,\nfiguring out what it does, and then implementing it.",
    "start": "1620500",
    "end": "1626799"
  },
  {
    "text": "So there's like all\nthis overhead compared to just doing its operations.",
    "start": "1626800",
    "end": "1632500"
  },
  {
    "text": "So interpreters can easily\nsupport high-level programming features, and they can do things\nlike dynamic code alteration",
    "start": "1632500",
    "end": "1638200"
  },
  {
    "text": "and so forth at the\ncost of performance. So that, you know, typically\nthe cycle for an interpreter",
    "start": "1638200",
    "end": "1644590"
  },
  {
    "text": "is, you read the next statement,\nyou interpret the statement. You then perform the\nstatement, and then",
    "start": "1644590",
    "end": "1649809"
  },
  {
    "text": "you update the state\nof the machine, and then you fetch\nthe next instruction. OK?",
    "start": "1649810",
    "end": "1655090"
  },
  {
    "text": "And you're going\nthrough that each time, and that's done in software. OK? When you have things\ncompiled to machine code,",
    "start": "1655090",
    "end": "1662772"
  },
  {
    "text": "it goes through a\nsimilar thing, but it's highly optimized just for the\nthings that machines are done.",
    "start": "1662772",
    "end": "1668890"
  },
  {
    "text": "OK? And so when you compile,\nyou're able to take advantage of the hardware and interpreter\nof machine instructions,",
    "start": "1668890",
    "end": "1676060"
  },
  {
    "text": "and that's much, much lower\noverhead than the big software overhead you get with Python.",
    "start": "1676060",
    "end": "1682300"
  },
  {
    "text": "Now, JIT is somewhere in the\nmiddle, what's used in Java. JIT compilers can recover\nsome of the performance,",
    "start": "1682300",
    "end": "1688125"
  },
  {
    "text": "and in fact it did a pretty\ngood job in this case. The idea is, when the\ncode is first executed,",
    "start": "1688125",
    "end": "1694660"
  },
  {
    "text": "it's interpreted, and\nthen the runtime system keeps track of how often\nthe various pieces of code",
    "start": "1694660",
    "end": "1701980"
  },
  {
    "text": "are executed. And whenever it finds that\nthere's some piece of code that it's executing\nfrequently, it then",
    "start": "1701980",
    "end": "1707890"
  },
  {
    "text": "calls the compiler to\ncompile that piece of code, and then subsequent to that,\nit runs the compiled code.",
    "start": "1707890",
    "end": "1714500"
  },
  {
    "text": "So it tries to get the big\nadvantage of performance by only compiling the\nthings that are necessary--",
    "start": "1714500",
    "end": "1723435"
  },
  {
    "text": "you know, for\nwhich it's actually going to pay off to\ninvoke the compiler to do.",
    "start": "1723435",
    "end": "1728720"
  },
  {
    "text": "OK?  So anyway, so that's\nthe big difference",
    "start": "1728720",
    "end": "1734290"
  },
  {
    "text": "with those kinds of things. One of the reasons we don't\nuse Python in this class",
    "start": "1734290",
    "end": "1739870"
  },
  {
    "text": "is because the performance\nmodel is hard to figure out.",
    "start": "1739870",
    "end": "1745460"
  },
  {
    "text": "OK? C is much closer to the metal,\nmuch closer to the silicon, OK?",
    "start": "1745460",
    "end": "1751149"
  },
  {
    "text": "And so it's much easier\nto figure out what's going on in that context.",
    "start": "1751150",
    "end": "1757000"
  },
  {
    "text": "OK? But we will have a\nguest lecture that we're going to talk about\nperformance in managed",
    "start": "1757000",
    "end": "1763480"
  },
  {
    "text": "languages like\nPython, so it's not that we're going to\nignore the topic. But we will learn how to\ndo performance engineering",
    "start": "1763480",
    "end": "1772285"
  },
  {
    "text": "in a place where\nit's easier to do it. OK? Now, one of the things that\na good compiler will do is--",
    "start": "1772285",
    "end": "1781830"
  },
  {
    "text": "you know, once you get to-- let's say we have\nthe C version, which is where we're going\nto move from this point",
    "start": "1781830",
    "end": "1787510"
  },
  {
    "text": "because that's the\nfastest we got so far-- is, it turns out\nthat you can change",
    "start": "1787510",
    "end": "1793120"
  },
  {
    "text": "the order of loops\nin this program without affecting\nthe correctness. OK? So here we went--",
    "start": "1793120",
    "end": "1798570"
  },
  {
    "text": "you know, for i, for j,\nfor k, do the update. OK? We could otherwise do-- we\ncould do, for i, for k, for j,",
    "start": "1798570",
    "end": "1806320"
  },
  {
    "text": "do the update, and it computes\nexactly the same thing. Or we could do, for k, for\nj, for i, do the updates.",
    "start": "1806320",
    "end": "1816549"
  },
  {
    "text": "OK? So we can change the\norder without affecting the correctness, OK?",
    "start": "1816550",
    "end": "1822670"
  },
  {
    "text": "And so do you think the order of\nloops matters for performance?",
    "start": "1822670",
    "end": "1829930"
  },
  {
    "text": "Duh. You know, this is like\nthis leading question. Yeah? Question? AUDIENCE: Maybe for\ncache localities.",
    "start": "1829930",
    "end": "1836960"
  },
  {
    "text": "CHARLES LEISERSON: Yeah. OK. And you're exactly right. Cache locality is what it is. So when we do that, we get--",
    "start": "1836960",
    "end": "1844430"
  },
  {
    "text": "the loop order affects the\nrunning time by a factor of 18.",
    "start": "1844430",
    "end": "1849890"
  },
  {
    "text": "Whoa. Just by switching the order. OK? What's going on there?",
    "start": "1849890",
    "end": "1854920"
  },
  {
    "text": "OK? What's going on? So we're going to talk about\nthis in more depth, so I'm just",
    "start": "1854920",
    "end": "1860050"
  },
  {
    "text": "going to fly through\nthis, because this is just sort of showing you the kinds\nof considerations that you do.",
    "start": "1860050",
    "end": "1865330"
  },
  {
    "text": "So in hardware, each\nprocessor reads and writes main memory in contiguous\nblocks called cache lines.",
    "start": "1865330",
    "end": "1873059"
  },
  {
    "text": "OK? Previously accessed\ncache lines are stored in a small\nmemory called cache that sits near the processor.",
    "start": "1873060",
    "end": "1880697"
  },
  {
    "text": "When the processor\naccesses something, if it's in the\ncache, you get a hit. That's very cheap, OK, and fast.",
    "start": "1880697",
    "end": "1887380"
  },
  {
    "text": "If you miss, you have to go\nout to either a deeper level cache or all the way\nout to main memory.",
    "start": "1887380",
    "end": "1892630"
  },
  {
    "text": "That is much, much\nslower, and we'll talk about that kind of thing. So what happens for\nthis matrix problem is,",
    "start": "1892630",
    "end": "1901830"
  },
  {
    "text": "the matrices are laid out in\nmemory in row-major order. That means you take-- you know, you have a\ntwo-dimensional matrix.",
    "start": "1901830",
    "end": "1908650"
  },
  {
    "text": "It's laid out in\nthe linear order of the addresses of memory\nby essentially taking row 1,",
    "start": "1908650",
    "end": "1913930"
  },
  {
    "text": "and then, after row 1, stick row\n2, and after that, stick row 3, and so forth, and unfolding it.",
    "start": "1913930",
    "end": "1919900"
  },
  {
    "text": "There's another order that\nthings could have been laid out-- in fact, they\nare in Fortran-- which is called\ncolumn-major order.",
    "start": "1919900",
    "end": "1926760"
  },
  {
    "text": "OK? So it turns out C and Fortran\noperate in different orders. OK? And it turns out it\naffects performance,",
    "start": "1926760",
    "end": "1933387"
  },
  {
    "text": "which way it does it. So let's just take a look at\nthe access pattern for order i, j, k.",
    "start": "1933387",
    "end": "1939800"
  },
  {
    "text": "OK? So what we're doing is, once\nwe figure out what i and what j is, we're going to go\nthrough and cycle through k.",
    "start": "1939800",
    "end": "1947740"
  },
  {
    "text": "And as we cycle\nthrough k, OK, C i, j stays the same for everything.",
    "start": "1947740",
    "end": "1953710"
  },
  {
    "text": "We get for that excellent\nspatial locality because we're just\naccessing the same location.",
    "start": "1953710",
    "end": "1958735"
  },
  {
    "text": "Every single time, it's\ngoing to be in cache. It's always going to be there. It's going to be\nfast to access C.",
    "start": "1958735",
    "end": "1964300"
  },
  {
    "text": "For A, what happens is, we\ngo through in a linear order, and we get good\nspatial locality.",
    "start": "1964300",
    "end": "1970510"
  },
  {
    "text": "But for B, it's going\nthrough columns, and those points are\ndistributed far away in memory,",
    "start": "1970510",
    "end": "1977260"
  },
  {
    "text": "so the processor is going\nto be bringing in 64 bytes to operate on a\nparticular datum.",
    "start": "1977260",
    "end": "1983169"
  },
  {
    "text": "OK? And then it's ignoring 7 of\nthe 8 floating-point words",
    "start": "1983170",
    "end": "1989770"
  },
  {
    "text": "on that cache line and\ngoing to the next one. So it's wasting\nan awful lot, OK?",
    "start": "1989770",
    "end": "1995710"
  },
  {
    "text": "So this one has good\nspatial locality in that it's all adjacent\nand you would use the cache lines effectively.",
    "start": "1995710",
    "end": "2002580"
  },
  {
    "text": "This one, you're going\n4,096 elements apart. It's got poor\nspatial locality, OK?",
    "start": "2002580",
    "end": "2010340"
  },
  {
    "text": "And that's for this one. So then if we look at the\ndifferent other ones-- this one, the order i, k, j--",
    "start": "2010340",
    "end": "2017280"
  },
  {
    "text": "it turns out you get good\nspatial locality for both C and B and excellent for A. OK?",
    "start": "2017280",
    "end": "2024230"
  },
  {
    "text": "And if you look at\neven another one, you don't get nearly as\ngood as the other ones, so there's a whole\nrange of things.",
    "start": "2024230",
    "end": "2030820"
  },
  {
    "text": "OK? This one, you're doing\noptimally badly in both, OK? And so you can just\nmeasure the different ones,",
    "start": "2030820",
    "end": "2037639"
  },
  {
    "text": "and it turns out that you can\nuse a tool to figure this out.",
    "start": "2037640",
    "end": "2044430"
  },
  {
    "text": "And the tool that we'll be\nusing is called Cachegrind. And it's one of the\nValgrind suites of caches.",
    "start": "2044430",
    "end": "2053156"
  },
  {
    "text": "And what it'll do\nis, it will tell you what the miss rates are for\nthe various pieces of code. OK?",
    "start": "2053156",
    "end": "2058158"
  },
  {
    "text": "And you'll learn how to use\nthat tool and figure out, oh, look at that. We have a high miss rate\nfor some and not for others,",
    "start": "2058159",
    "end": "2064280"
  },
  {
    "text": "so that may be why my\ncode is running slowly. OK? So when you pick the\nbest one of those,",
    "start": "2064280",
    "end": "2070908"
  },
  {
    "text": "OK, we then got a relative\nspeedup of about 6 and 1/2.",
    "start": "2070909",
    "end": "2076699"
  },
  {
    "text": "So what other simple\nchanges can we try? There's actually a\ncollection of things that we could do that don't\neven have us touching the code.",
    "start": "2076699",
    "end": "2086373"
  },
  {
    "text": "What else could we\ndo, for people who've played with compilers and such? Hint, hint.",
    "start": "2086373",
    "end": "2091419"
  },
  {
    "text": " Yeah? AUDIENCE: You could\nchange the compiler flags.",
    "start": "2091420",
    "end": "2096649"
  },
  {
    "text": "CHARLES LEISERSON: Yeah,\nchange the compiler flags, OK? So Clang, which is the\ncompiler that we'll be using,",
    "start": "2096650",
    "end": "2102620"
  },
  {
    "text": "provides a collection of\noptimization switches, and you can specify a\nswitch to the compiler",
    "start": "2102620",
    "end": "2108320"
  },
  {
    "text": "to ask it to optimize. So you do minus O,\nand then a number.",
    "start": "2108320",
    "end": "2114080"
  },
  {
    "text": "And 0, if you look at the\ndocumentation, it says, \"Do not optimize.\" 1 says, \"Optimize.\"",
    "start": "2114080",
    "end": "2120530"
  },
  {
    "text": "2 says, \"Optimize even more.\" 3 says, \"Optimize yet more.\" OK?",
    "start": "2120530",
    "end": "2125960"
  },
  {
    "text": "In this case, it turns out that\neven though it optimized more in O3, it turns out O2\nwas a better setting.",
    "start": "2125960",
    "end": "2133890"
  },
  {
    "text": "OK? This is one of these cases. It doesn't happen all the time. Usually, O3 does better\nthan O2, but in this case O2",
    "start": "2133890",
    "end": "2141050"
  },
  {
    "text": "actually optimized\nbetter than O3, because the optimizations\nare to some extent heuristic.",
    "start": "2141050",
    "end": "2146520"
  },
  {
    "text": "OK? And there are also other\nkinds of optimization. You can have it do\nprofile-guided optimization,",
    "start": "2146520",
    "end": "2153740"
  },
  {
    "text": "where you look at what the\nperformance was and feed that back into the code,\nand then the compiler",
    "start": "2153740",
    "end": "2161630"
  },
  {
    "text": "can be smarter about\nhow it optimizes. And there are a variety\nof other things. So with this simple technology,\nchoosing a good optimization",
    "start": "2161630",
    "end": "2171650"
  },
  {
    "text": "flag-- in this case, O2-- we got for free, basically,\na factor of 3.25, OK?",
    "start": "2171650",
    "end": "2180270"
  },
  {
    "text": "Without having to do\nmuch work at all, OK? And now we're actually\nstarting to approach",
    "start": "2180270",
    "end": "2187650"
  },
  {
    "text": "1% of peak performance. We've got point 0.3% of\npeak performance, OK?",
    "start": "2187650",
    "end": "2193680"
  },
  {
    "text": "So what's causing\nthe low performance? Why aren't we getting\nmost of the performance out of this machine?",
    "start": "2193680",
    "end": "2200130"
  },
  {
    "text": "Why do you think? Yeah? AUDIENCE: We're not\nusing all the cores. CHARLES LEISERSON: Yeah,\nwe're not using all the cores. So far we're using\njust one core,",
    "start": "2200130",
    "end": "2206310"
  },
  {
    "text": "and how many cores do we have? AUDIENCE: 18. CHARLES LEISERSON: 18, right?",
    "start": "2206310",
    "end": "2212220"
  },
  {
    "text": "18 cores. Ah! 18 cores just sitting\nthere, 17 sitting",
    "start": "2212220",
    "end": "2218170"
  },
  {
    "text": "idle, while we are\ntrying to optimize one. OK. So multicore.",
    "start": "2218170",
    "end": "2224680"
  },
  {
    "text": "So we have 9 cores per chip,\nand there are 2 of these chips in our test machine.",
    "start": "2224680",
    "end": "2230510"
  },
  {
    "text": "So we're running on just one\nof them, so let's use them all. To do that, we're going to\nuse the Cilk infrastructure,",
    "start": "2230510",
    "end": "2239650"
  },
  {
    "text": "and in particular,\nwe can use what's called a parallel loop, which\nin Cilk, you'd call cilk_for,",
    "start": "2239650",
    "end": "2247960"
  },
  {
    "text": "and so you just relay that\nouter loop-- for example, in this case, you say\ncilk_for, it says, do all those\niterations in parallel.",
    "start": "2247960",
    "end": "2255670"
  },
  {
    "text": "The compiler and runtime system\nare free to schedule them and so forth.",
    "start": "2255670",
    "end": "2261545"
  },
  {
    "text": "OK? And we could also do it\nfor the inner loop, OK?",
    "start": "2261545",
    "end": "2267800"
  },
  {
    "text": "And it turns out you can't\nalso do it for the middle loop,",
    "start": "2267800",
    "end": "2274010"
  },
  {
    "text": "if you think about it. OK? So I'll let you do that is\na little bit of a homework problem-- why can't I just do\na cilk_for of the inner loop?",
    "start": "2274010",
    "end": "2281900"
  },
  {
    "text": "OK? So the question is, which\nparallel version works best?",
    "start": "2281900",
    "end": "2287660"
  },
  {
    "text": "So we can parallel the i loop,\nwe can parallel the j loop, and we can do i and j together.",
    "start": "2287660",
    "end": "2293250"
  },
  {
    "text": "You can't do k just\nwith a parallel loop and expect to get\nthe right thing. OK?",
    "start": "2293250",
    "end": "2298350"
  },
  {
    "text": "And that's this one. So if you look-- wow! What a spread of\nrunning times, right?",
    "start": "2298350",
    "end": "2305010"
  },
  {
    "text": "OK? If I parallelize the just the\ni loop, it's 3.18 seconds,",
    "start": "2305010",
    "end": "2310640"
  },
  {
    "text": "and if I parallelize the j\nloop, it actually slows down, I think, right?",
    "start": "2310640",
    "end": "2317630"
  },
  {
    "text": "And then, if I do both\ni and j, it's still bad. I just want to do\nthe outer loop there.",
    "start": "2317630",
    "end": "2322650"
  },
  {
    "text": "This has to do, it turns out,\nwith scheduling overhead, and we'll learn about\nscheduling overhead and how you predict\nthat and such.",
    "start": "2322650",
    "end": "2329111"
  },
  {
    "text": "So the rule of thumb here\nis, parallelize outer loops rather than inner loops, OK? And so when we do\nparallel loops,",
    "start": "2329112",
    "end": "2335250"
  },
  {
    "text": "we get an almost 18x\nspeedup on 18 cores, OK? So let me assure\nyou, not all code",
    "start": "2335250",
    "end": "2342910"
  },
  {
    "text": "is that easy to parallelize. OK? But this one happens to be. So now we're up to, what,\nabout just over 5% of peak.",
    "start": "2342910",
    "end": "2353150"
  },
  {
    "text": "OK? So where are we\nlosing time here?",
    "start": "2353150",
    "end": "2358210"
  },
  {
    "text": "OK, why are we getting just 5%? Yeah? AUDIENCE: So another area of the\nparallelism that [INAUDIBLE]..",
    "start": "2358210",
    "end": "2365470"
  },
  {
    "text": " So we could, for example,\nvectorize the multiplication.",
    "start": "2365470",
    "end": "2371882"
  },
  {
    "text": "CHARLES LEISERSON: Yep. Good. So that's one, and\nthere's one other that we're not using\nvery effectively. OK.",
    "start": "2371882",
    "end": "2377250"
  },
  {
    "text": "That's one, and those\nare the two optimizations we're going to do to get\na really good code here.",
    "start": "2377250",
    "end": "2383370"
  },
  {
    "text": "So what's the other one? Yeah? AUDIENCE: The multiply\nand add operation.",
    "start": "2383370",
    "end": "2388934"
  },
  {
    "text": " CHARLES LEISERSON:\nThat's actually related",
    "start": "2388934",
    "end": "2393960"
  },
  {
    "text": "to the same question, OK? But there's another completely\ndifferent source of opportunity",
    "start": "2393960",
    "end": "2401310"
  },
  {
    "text": "here. Yeah? AUDIENCE: We could also do a lot\nbetter on our handling of cache misses. CHARLES LEISERSON: Yeah.",
    "start": "2401310",
    "end": "2406680"
  },
  {
    "text": "OK, we can actually manage\nthe cache misses better. OK? So let's go back\nto hardware caches,",
    "start": "2406680",
    "end": "2413490"
  },
  {
    "text": "and let's restructure\nthe computation to reuse data in the\ncache as much as possible.",
    "start": "2413490",
    "end": "2418890"
  },
  {
    "text": "Because cache misses are\nslow, and hits are fast. And try to make the\nmost of the cache by reusing the data\nthat's already there.",
    "start": "2418890",
    "end": "2425710"
  },
  {
    "text": "OK? So let's just take a look. Suppose that we're going to\njust compute one row of C, OK?",
    "start": "2425710",
    "end": "2434130"
  },
  {
    "text": "So we go through one row of\nC. That's going to take us-- since it's a 4,096-long\nvector there,",
    "start": "2434130",
    "end": "2441990"
  },
  {
    "text": "that's going to basically be\n4,096 writes that we're going to do.",
    "start": "2441990",
    "end": "2447130"
  },
  {
    "text": "OK? And we're going to get some\nspatial locality there, which is good, but\nwe're basically",
    "start": "2447130",
    "end": "2452280"
  },
  {
    "text": "doing-- the processor's\ndoing 4,096 writes. Now, to compute that row, I\nneed to access 4,096 reads",
    "start": "2452280",
    "end": "2464380"
  },
  {
    "text": "from A, OK? And I need all of B, OK?",
    "start": "2464380",
    "end": "2471940"
  },
  {
    "text": "Because I go each\ncolumn of B as I'm going through to fully\ncompute C. Do people see that?",
    "start": "2471940",
    "end": "2481580"
  },
  {
    "text": "OK. So I need-- to just\ncompute one row of C,",
    "start": "2481580",
    "end": "2487900"
  },
  {
    "text": "I need to access one row\nof A and all of B. OK? Because the first element of\nC needs the whole first column",
    "start": "2487900",
    "end": "2496000"
  },
  {
    "text": "of B. The second element of C\nneeds the whole second column",
    "start": "2496000",
    "end": "2502180"
  },
  {
    "text": "of B. Once again, don't\nworry if you don't fully understand this,\nbecause right now I'm just ripping through\nthis at high speed.",
    "start": "2502180",
    "end": "2508109"
  },
  {
    "text": "We're going to go into this in\nmuch more depth in the class, and there'll be plenty of\ntime to master this stuff. But the main thing\nto understand is,",
    "start": "2508110",
    "end": "2514702"
  },
  {
    "text": "you're going through\nall of B, then I want to compute\nanother row of C. I'm going to do the same thing. I'm going to go through\none row of A and all of B",
    "start": "2514702",
    "end": "2522130"
  },
  {
    "text": "again, so that when I'm\ndone we do about 16 million,",
    "start": "2522130",
    "end": "2527210"
  },
  {
    "text": "17 million memory\naccesses total. OK? That's a lot of memory access.",
    "start": "2527210",
    "end": "2533910"
  },
  {
    "text": "So what if, instead\nof doing that, I do things in blocks, OK? So what if I want to compute\na 64 by 64 block of C",
    "start": "2533910",
    "end": "2543270"
  },
  {
    "text": "rather than a row of C? So let's take a look\nat what happens there. So remember, by the\nway, this number--",
    "start": "2543270",
    "end": "2549450"
  },
  {
    "text": "16, 17 million, OK? Because we're going\nto compare with it. OK? So what about to\ncompute a block?",
    "start": "2549450",
    "end": "2555279"
  },
  {
    "text": "So if I look at a block,\nthat is going to take-- 64 by 64 also takes 4,096\nwrites to C. Same number, OK?",
    "start": "2555280",
    "end": "2565140"
  },
  {
    "text": "But now I have to\ndo about 200,000 reads from A because I need\nto access all those rows.",
    "start": "2565140",
    "end": "2572910"
  },
  {
    "text": "OK? And then for B, I need to\naccess 64 columns of B, OK?",
    "start": "2572910",
    "end": "2578850"
  },
  {
    "text": "And that's another\n262,000 reads from B, OK?",
    "start": "2578850",
    "end": "2584760"
  },
  {
    "text": "Which ends up being half a\nmillion memory accesses total. OK?",
    "start": "2584760",
    "end": "2590000"
  },
  {
    "text": "So I end up doing way\nfewer accesses, OK,",
    "start": "2590000",
    "end": "2595370"
  },
  {
    "text": "if those blocks will\nfit in my cache. OK?",
    "start": "2595370",
    "end": "2600840"
  },
  {
    "text": "So I do much less to compute\nthe same size footprint if I compute a block rather\nthan computing a row.",
    "start": "2600840",
    "end": "2608619"
  },
  {
    "text": "OK? Much more efficient. OK? And that's a scheme\ncalled tiling, and so if you do tiled matrix\nmultiplication, what you do",
    "start": "2608620",
    "end": "2615810"
  },
  {
    "text": "is you bust your matrices\ninto, let's say, 64 by 64 submatrices,\nand then you do",
    "start": "2615810",
    "end": "2623820"
  },
  {
    "text": "two levels of matrix multiply. You do an outer level of\nmultiplying of the blocks using the same algorithm, and\nthen when you hit the inner,",
    "start": "2623820",
    "end": "2632750"
  },
  {
    "text": "to do a 64 by 64\nmatrix multiply, I then do another\nthree-nested loops.",
    "start": "2632750",
    "end": "2640950"
  },
  {
    "text": "So you end up with\n6 nested loops. OK? And so you're basically\nbusting it like this.",
    "start": "2640950",
    "end": "2648190"
  },
  {
    "text": "And there's a tuning\nparameter, of course, which is, you know, how\nbig do I make my tile size?",
    "start": "2648190",
    "end": "2653867"
  },
  {
    "text": "You know, if it's s by s,\nwhat should I do at the leaves there? Should it be 64? Should it be 128?",
    "start": "2653867",
    "end": "2660818"
  },
  {
    "text": "What number should I use there? ",
    "start": "2660818",
    "end": "2666040"
  },
  {
    "text": "How do we find the right value\nof s, this tuning parameter? OK? Ideas of how we might find it?",
    "start": "2666040",
    "end": "2671290"
  },
  {
    "text": " AUDIENCE: You could figure out\nhow much there is in the cache.",
    "start": "2671290",
    "end": "2677108"
  },
  {
    "text": "CHARLES LEISERSON:\nYou could do that. You might get a number,\nbut who knows what else is going on in the cache\nwhile you're doing this.",
    "start": "2677108",
    "end": "2683108"
  },
  {
    "text": "AUDIENCE: Just test\na bunch of them. CHARLES LEISERSON: Yeah,\ntest a bunch of them. Experiment! OK? Try them!",
    "start": "2683108",
    "end": "2688849"
  },
  {
    "text": "See which one gives\nyou good numbers. And when you do\nthat, it turns out that 32 gives you the\nbest performance, OK,",
    "start": "2688850",
    "end": "2697300"
  },
  {
    "text": "for this particular problem. OK? So you can block it, and\nthen you can get faster,",
    "start": "2697300",
    "end": "2703050"
  },
  {
    "text": "and when you do that, that\ngave us a speedup of about 1.7.",
    "start": "2703050",
    "end": "2712020"
  },
  {
    "text": "OK? So we're now up to-- what? We're almost 10% of peak, OK?",
    "start": "2712020",
    "end": "2720109"
  },
  {
    "text": "And the other thing is\nthat if you use Cachegrind or a similar tool,\nyou can figure out",
    "start": "2720110",
    "end": "2725900"
  },
  {
    "text": "how many cache references\nthere are and so forth, and you can see\nthat, in fact, it's dropped quite considerably when\nyou do the tiling versus just",
    "start": "2725900",
    "end": "2734299"
  },
  {
    "text": "the straight parallel loops. OK? So once again, you can use tools\nto help you figure this out",
    "start": "2734300",
    "end": "2740600"
  },
  {
    "text": "and to understand the\ncause of what's going on. Well, it turns\nout that our chips",
    "start": "2740600",
    "end": "2748490"
  },
  {
    "text": "don't have just one cache. They've got three\nlevels of caches. OK?",
    "start": "2748490",
    "end": "2753510"
  },
  {
    "text": "There's L1-cache, OK? And there's data\nand instructions, so we're thinking\nabout data here,",
    "start": "2753510",
    "end": "2759859"
  },
  {
    "text": "for the data for the matrix. And it's got an L2-cache,\nwhich is also private to the processor, and\nthen a shared L3-cache,",
    "start": "2759860",
    "end": "2767359"
  },
  {
    "text": "and then you go\nout to the DRAM-- you also can go to your\nneighboring processors",
    "start": "2767360",
    "end": "2773710"
  },
  {
    "text": "and such. OK? And they're of different sizes. You can see they grow in size-- ",
    "start": "2773710",
    "end": "2780589"
  },
  {
    "text": "32 kilobytes, 256\nkilobytes, to 25 megabytes, to main memory, which\nis 60 gigabytes.",
    "start": "2780590",
    "end": "2788240"
  },
  {
    "text": "So what you can do is, if you\nwant to do two-level tiling, OK, you can have two\ntuning parameters, s and t.",
    "start": "2788240",
    "end": "2796790"
  },
  {
    "text": "And now you get to do-- you can't do binary search\nto find it, unfortunately, because it's multi-dimensional.",
    "start": "2796790",
    "end": "2802960"
  },
  {
    "text": "You kind of have to\ndo it exhaustively. And when you do that,\nyou end up with--",
    "start": "2802960",
    "end": "2807992"
  },
  {
    "text": "[LAUGHTER]  --with 9 nested loops, OK?",
    "start": "2807992",
    "end": "2814880"
  },
  {
    "text": "But of course, we don't\nreally want to do that. We have three levels\nof caching, OK?",
    "start": "2814880",
    "end": "2820870"
  },
  {
    "text": "Can anybody figure out\nthe inductive number? For three levels of caching,\nhow many levels of tiling",
    "start": "2820870",
    "end": "2828070"
  },
  {
    "text": "do we have to do? ",
    "start": "2828070",
    "end": "2833680"
  },
  {
    "text": "This is a gimme, right? AUDIENCE: 12. CHARLES LEISERSON: 12! Good, 12, OK?",
    "start": "2833680",
    "end": "2839320"
  },
  {
    "text": "Yeah, you then do 12. And man, you know, when I say\nthe code gets ugly when you",
    "start": "2839320",
    "end": "2845560"
  },
  {
    "text": "start making things go fast. OK? Right? This is like, ughhh! [LAUGHTER]",
    "start": "2845560",
    "end": "2851289"
  },
  {
    "text": " OK? OK, but it turns\nout there's a trick.",
    "start": "2851290",
    "end": "2858230"
  },
  {
    "text": "You can tile for\nevery power of 2 simultaneously by just solving\nthe problem recursively.",
    "start": "2858230",
    "end": "2865190"
  },
  {
    "text": "So the idea is that you\ndo divide and conquer. You divide each of the matrices\ninto 4 submatrices, OK?",
    "start": "2865190",
    "end": "2872865"
  },
  {
    "text": "And then, if you look at the\ncalculations you need to do, you have to solve 8\nsubproblems of half the size,",
    "start": "2872865",
    "end": "2878900"
  },
  {
    "text": "and then do an addition. OK? And so you have\n8 multiplications",
    "start": "2878900",
    "end": "2885560"
  },
  {
    "text": "of size n over 2 by n over 2 and\n1 addition of n by n matrices, and that gives you your answer. But then, of course,\nwhat you going to do",
    "start": "2885560",
    "end": "2892128"
  },
  {
    "text": "is solve each of\nthose recursively, OK? And that's going to\ngive you, essentially, the same type of performance.",
    "start": "2892128",
    "end": "2898390"
  },
  {
    "text": "Here's the code. I don't expect that\nyou understand this, but we've written this\nusing in parallel,",
    "start": "2898390",
    "end": "2905790"
  },
  {
    "text": "because it turns out you can\ndo 4 of them in parallel. And the Cilk spawn here says,\ngo and do this subroutine, which",
    "start": "2905790",
    "end": "2913710"
  },
  {
    "text": "is basically a subproblem, and\nthen, while you're doing that,",
    "start": "2913710",
    "end": "2919380"
  },
  {
    "text": "you're allowed to go and execute\nthe next statement-- which you'll do another spawn and\nanother spawn and finally this.",
    "start": "2919380",
    "end": "2924450"
  },
  {
    "text": "And then this\nstatement says, ah, but don't start the\nnext phase until you finish the first phase.",
    "start": "2924450",
    "end": "2930069"
  },
  {
    "text": "OK? And we'll learn\nabout this stuff. OK, when we do that,\nwe get a running time",
    "start": "2930070",
    "end": "2937410"
  },
  {
    "text": "of about 93 seconds, which\nis about 50 times slower",
    "start": "2937410",
    "end": "2942630"
  },
  {
    "text": "than the last version. We're using cache much\nbetter, but it turns out,",
    "start": "2942630",
    "end": "2948660"
  },
  {
    "text": "you know, nothing is free,\nnothing is easy, typically, in performance engineering.",
    "start": "2948660",
    "end": "2954610"
  },
  {
    "text": "You have to be clever.  What happened here? Why did this get worse,\neven though-- it turns out,",
    "start": "2954610",
    "end": "2961440"
  },
  {
    "text": "if you actually look\nat the caching numbers, you're getting\ngreat hits on cache. I mean, very few cache\nmisses, lots of hits on cache,",
    "start": "2961440",
    "end": "2971130"
  },
  {
    "text": "but we're still slower. Why do you suppose that is? Let me get someone-- yeah? AUDIENCE: Overhead to start\nfunctions and [INAUDIBLE]..",
    "start": "2971130",
    "end": "2979438"
  },
  {
    "text": "CHARLES LEISERSON:\nYeah, the overhead to the start of the function,\nand in particular the place that it matters is at the\nleaves of the computation.",
    "start": "2979438",
    "end": "2987040"
  },
  {
    "text": "OK? So what we do is, we have\na very small base case. We're doing this overhead all\nthe way down to n equals 1.",
    "start": "2987040",
    "end": "2995090"
  },
  {
    "text": "So there's a function\ncall overhead even when you're multiplying 1 by 1. So hey, let's pick a threshold,\nand below that threshold,",
    "start": "2995090",
    "end": "3004369"
  },
  {
    "text": "let's just use a standard good\nalgorithm for that threshold. And if we're above that, we'll\ndo divide and conquer, OK?",
    "start": "3004370",
    "end": "3014510"
  },
  {
    "text": "So what we do is we call-- if we're less than the\nthreshold, we call a base case,",
    "start": "3014510",
    "end": "3023990"
  },
  {
    "text": "and the base case looks very\nmuch like just ordinary matrix multiply. OK?",
    "start": "3023990",
    "end": "3030060"
  },
  {
    "text": "And so, when you do that,\nyou can once again look to see what's the best\nvalue for the base case,",
    "start": "3030060",
    "end": "3036210"
  },
  {
    "text": "and it turns out in this\ncase, I guess, it's 64. OK? We get down to 1.95 seconds.",
    "start": "3036210",
    "end": "3044010"
  },
  {
    "text": "I didn't do the base case\nof 1, because I tried that, and that was the one that\ngave us terrible performance. AUDIENCE: [INAUDIBLE]",
    "start": "3044010",
    "end": "3049950"
  },
  {
    "text": "CHARLES LEISERSON: Sorry. 32-- oh, yeah. 32 is even better. 1.3. Good, yeah, so we picked 32. I think I even-- oh,\nI didn't highlight it.",
    "start": "3049950",
    "end": "3057029"
  },
  {
    "text": "OK. I should have highlighted\nthat on the slide. So then, when we do that, we\nnow are getting 12% of peak.",
    "start": "3057030",
    "end": "3067730"
  },
  {
    "text": "OK? And if you count up how\nmany cache misses we have,",
    "start": "3067730",
    "end": "3075740"
  },
  {
    "text": "you can see that-- here's the data cache for\nL1, and with parallel divide",
    "start": "3075740",
    "end": "3083390"
  },
  {
    "text": "and conquer it's the\nlowest, but also now so is the last-level caching. OK? And then the total number of\nreferences is small, as well.",
    "start": "3083390",
    "end": "3090950"
  },
  {
    "text": "So divide and conquer turns\nout to be a big win here. OK? Now the other thing that we\nmentioned, which was we're",
    "start": "3090950",
    "end": "3100970"
  },
  {
    "text": "not using the vector hardware. All of these things have vectors\nthat we can operate on, OK?",
    "start": "3100970",
    "end": "3108260"
  },
  {
    "text": "They have vector hardware that\nprocess data in what's called SIMD fashion, which means\nSingle-Instruction stream,",
    "start": "3108260",
    "end": "3114020"
  },
  {
    "text": "Multiple-Data. That means you give\none instruction, and it does operations\non a vector, OK?",
    "start": "3114020",
    "end": "3121010"
  },
  {
    "text": "And as we mentioned, we\nhave 8 floating-point units",
    "start": "3121010",
    "end": "3127940"
  },
  {
    "text": "per core, of which we can also\ndo a fused-multiply-add, OK?",
    "start": "3127940",
    "end": "3134050"
  },
  {
    "text": " So each vector register\nholds multiple words. I believe in the machine we're\nusing this term, it's 4 words.",
    "start": "3134050",
    "end": "3144020"
  },
  {
    "text": "I think so. OK? ",
    "start": "3144020",
    "end": "3150350"
  },
  {
    "text": "But it's important when you\nuse these-- you can't just use them willy-nilly. ",
    "start": "3150350",
    "end": "3158510"
  },
  {
    "text": "You have to operate on the data\nas one chunk of vector data.",
    "start": "3158510",
    "end": "3164660"
  },
  {
    "text": "You can't, you\nknow, have this lane of the vector unit doing one\nthing and a different lane",
    "start": "3164660",
    "end": "3171075"
  },
  {
    "text": "doing something else. They all have to be doing\nessentially the same thing, the only difference being\nthe indexing of memory.",
    "start": "3171075",
    "end": "3177460"
  },
  {
    "text": "OK? So when you do that-- ",
    "start": "3177460",
    "end": "3183830"
  },
  {
    "text": "so already we've actually\nbeen taking advantage of it. But you can produce a\nvectorization report by asking",
    "start": "3183830",
    "end": "3191390"
  },
  {
    "text": "for that, and the system will\ntell you what kinds of things",
    "start": "3191390",
    "end": "3196917"
  },
  {
    "text": "are being vectorized, which\nthings are being vectorized, which aren't. And we'll talk about\nhow you vectorize things",
    "start": "3196917",
    "end": "3202100"
  },
  {
    "text": "that the compiler doesn't\nwant to vectorize. OK? And in particular, most machines\ndon't support the newest sets",
    "start": "3202100",
    "end": "3207800"
  },
  {
    "text": "of vector instructions,\nso the compiler uses vector instructions\nconservatively by default.",
    "start": "3207800",
    "end": "3213660"
  },
  {
    "text": "So if you're compiling\nfor a particular machine, you can say, use that\nparticular machine.",
    "start": "3213660",
    "end": "3219630"
  },
  {
    "text": "And here's some of the\nvectorization flags. You can say, use the AVX\ninstructions if you have AVX.",
    "start": "3219630",
    "end": "3225770"
  },
  {
    "text": "You can use AVX2. You can use the\nfused-multiply-add vector instructions. You can give a\nstring that tells you",
    "start": "3225770",
    "end": "3232142"
  },
  {
    "text": "the architecture that\nyou're running on, on that special thing. And you can say, well, use\nwhatever machine I'm currently",
    "start": "3232143",
    "end": "3238130"
  },
  {
    "text": "compiling on, OK,\nand it'll figure out which architecture is that.",
    "start": "3238130",
    "end": "3243440"
  },
  {
    "text": "OK? Now, floating-point numbers,\nas we'll talk about, turn out to have some\nundesirable properties,",
    "start": "3243440",
    "end": "3250849"
  },
  {
    "text": "like they're not associative,\nso if you do A times B times C, how you parenthesize\nthat can give you",
    "start": "3250850",
    "end": "3259220"
  },
  {
    "text": "two different numbers. And so if you give a\nspecification of a code,",
    "start": "3259220",
    "end": "3264890"
  },
  {
    "text": "typically, the compiler\nwill not change the order of associativity\nbecause it says,",
    "start": "3264890",
    "end": "3272120"
  },
  {
    "text": "I want to get exactly\nthe same result. But you can give\nit a flag called fast math, minus ffast-math,\nwhich will allow it",
    "start": "3272120",
    "end": "3279650"
  },
  {
    "text": "to do that kind of reordering. OK? If it's not important\nto you, then it will be the same as the\ndefault ordering, OK?",
    "start": "3279650",
    "end": "3286880"
  },
  {
    "text": "And when you use that-- and particularly using\narchitecture native and fast math, we actually get\nabout double the performance",
    "start": "3286880",
    "end": "3295490"
  },
  {
    "text": "out of vectorization,\njust having the compiler vectorize it. OK?",
    "start": "3295490",
    "end": "3301350"
  },
  {
    "text": "Yeah, question. AUDIENCE: Are the data types\nin our matrix, are they 32-bit?",
    "start": "3301350",
    "end": "3311125"
  },
  {
    "text": "CHARLES LEISERSON:\nThey're 64-bit. Yep. These days, 64-bit\nis pretty standard.",
    "start": "3311125",
    "end": "3316920"
  },
  {
    "text": "They call that double precision,\nbut it's pretty standard. Unless you're doing AI\napplications, in which case you may want to do\nlower-precision arithmetic.",
    "start": "3316920",
    "end": "3326520"
  },
  {
    "text": "AUDIENCE: So float and\ndouble are both the same? CHARLES LEISERSON:\nNo, float is 32, OK?",
    "start": "3326520",
    "end": "3332690"
  },
  {
    "text": "So generally, people who are\ndoing serious linear algebra",
    "start": "3332690",
    "end": "3340700"
  },
  {
    "text": "calculations use 64 bits. But actually sometimes\nthey can use less,",
    "start": "3340700",
    "end": "3346760"
  },
  {
    "text": "and then you can\nget more performance if you discover\nyou can use fewer bits in your representation.",
    "start": "3346760",
    "end": "3352460"
  },
  {
    "text": "We'll talk about that, too. OK? So last thing that\nwe're going to do is, you can actually use\nthe instructions, the vector",
    "start": "3352460",
    "end": "3361970"
  },
  {
    "text": "instructions,\nyourself rather than rely on the compiler to do it. And there's a whole manual\nof intrinsic instructions",
    "start": "3361970",
    "end": "3371059"
  },
  {
    "text": "that you can call from C that\nallow you to do, you know,",
    "start": "3371060",
    "end": "3377270"
  },
  {
    "text": "the specific vector instructions\nthat you might want to do it. So the compiler doesn't\nhave to figure that out. ",
    "start": "3377270",
    "end": "3385039"
  },
  {
    "text": "And you can also use some\nmore insights to do things",
    "start": "3385040",
    "end": "3391580"
  },
  {
    "text": "like-- you can do\npreprocessing, and you can transpose the matrices,\nwhich turns out to help,",
    "start": "3391580",
    "end": "3396680"
  },
  {
    "text": "and do data alignment. And there's a lot of other\nthings using clever algorithms for the base case, OK?",
    "start": "3396680",
    "end": "3403210"
  },
  {
    "text": " And you do more\nperformance engineering.",
    "start": "3403210",
    "end": "3408630"
  },
  {
    "text": "You think about you're\ndoing, you code, and then you run, run, run\nto test, and that's one nice reason to have the\ncloud, because you can do tests",
    "start": "3408630",
    "end": "3415730"
  },
  {
    "text": "in parallel. So it takes you less time to\ndo your tests in terms of your,",
    "start": "3415730",
    "end": "3421593"
  },
  {
    "text": "you know, sitting around time\nwhen you're doing something. You say, oh, I want\nto do 10 tests. Let's spin up 10 machines and do\nall the tests at the same time.",
    "start": "3421593",
    "end": "3429530"
  },
  {
    "text": "When you do that-- and the main one we're\ngetting out of this is the AVX intrinsics--\nwe get up to 0.41",
    "start": "3429530",
    "end": "3439970"
  },
  {
    "text": "of peak, so 41% of peak, and\nget about 50,000 speedup.",
    "start": "3439970",
    "end": "3447460"
  },
  {
    "text": "OK? And it turns out\nthat's where we quit.",
    "start": "3447460",
    "end": "3452820"
  },
  {
    "text": "OK? And the reason is\nbecause we beat Intel's professionally\nengineered Math Kernel",
    "start": "3452820",
    "end": "3459490"
  },
  {
    "text": "Library at that point. [LAUGHTER] OK? You know, a good\nquestion is, why",
    "start": "3459490",
    "end": "3465970"
  },
  {
    "text": "aren't we getting all of peak? And you know, I invite you to\ntry to figure that out, OK?",
    "start": "3465970",
    "end": "3478099"
  },
  {
    "text": "It turns out,\nthough, Intel MKL is better than what we did because\nwe assumed it was a power of 2. Intel doesn't assume\nthat it's a power of 2,",
    "start": "3478100",
    "end": "3485869"
  },
  {
    "text": "and they're more robust,\nalthough we win on the 496",
    "start": "3485870",
    "end": "3491660"
  },
  {
    "text": "by 496 matrices, they win\non other sizes of matrices,",
    "start": "3491660",
    "end": "3499280"
  },
  {
    "text": "so it's not all things.  But the end of the story\nis, what have we done?",
    "start": "3499280",
    "end": "3508170"
  },
  {
    "text": "We have just done a\nfactor of 50,000, OK? If you looked at the gas\neconomy, OK, of a jumbo jet",
    "start": "3508170",
    "end": "3519950"
  },
  {
    "text": "and getting the\nkind of performance that we just got in terms\nof miles per gallon,",
    "start": "3519950",
    "end": "3525740"
  },
  {
    "text": "you would be able to run a jumbo\njet on a little Vespa scooter",
    "start": "3525740",
    "end": "3532280"
  },
  {
    "text": "or whatever type of\nscooter that is, OK? That's how much we've\nbeen able to do it. You generally--\nlet me just caution",
    "start": "3532280",
    "end": "3539090"
  },
  {
    "text": "you-- won't see the magnitude\nof a performance improvement that we obtained for\nmatrix multiplication. OK?",
    "start": "3539090",
    "end": "3544520"
  },
  {
    "text": "That turns out to be one where-- it's a really good example\nbecause it's so dramatic.",
    "start": "3544520",
    "end": "3551029"
  },
  {
    "text": "But we will see some\nsubstantial numbers, and in particular\nin 6.172 you'll",
    "start": "3551030",
    "end": "3556490"
  },
  {
    "text": "learn how to print this\ncurrency of performance all by yourself so that\nyou don't have to take",
    "start": "3556490",
    "end": "3562610"
  },
  {
    "text": "somebody else's library. You can, you know, say, oh,\nno, I'm an engineer of that.",
    "start": "3562610",
    "end": "3568380"
  },
  {
    "text": "Let me mention one other thing. In this course, we're going to\nfocus on multicore computing. We are not, in particular,\ngoing to be doing GPUs",
    "start": "3568380",
    "end": "3576890"
  },
  {
    "text": "or file systems or\nnetwork performance. In the real world, those\nare hugely important, OK?",
    "start": "3576890",
    "end": "3583730"
  },
  {
    "text": "What we found, however,\nis that it's better to learn a particular\ndomain, and in particular,",
    "start": "3583730",
    "end": "3588815"
  },
  {
    "text": "this particular domain-- people who master multicore\nperformance engineering,",
    "start": "3588815",
    "end": "3598529"
  },
  {
    "text": "in fact, go on to do\nthese other things and are really good at it, OK?",
    "start": "3598530",
    "end": "3603650"
  },
  {
    "text": "Because you've learned the\nsort of the core, the basis, the foundation--",
    "start": "3603650",
    "end": "3608860"
  },
  {
    "start": "3608860",
    "end": "3620175"
  }
]
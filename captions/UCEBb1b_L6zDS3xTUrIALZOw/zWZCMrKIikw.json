[
  {
    "start": "0",
    "end": "15370"
  },
  {
    "text": "PROFESSOR: And what we saw was\nthe performance was quite different in the two regimes.",
    "start": "15370",
    "end": "20910"
  },
  {
    "text": "In power-limited regime,\ntypically our SNR is much smaller than one, whereas in the\nbandwidth-limited regime,",
    "start": "20910",
    "end": "28930"
  },
  {
    "text": "the SNR is large. And because of this behavior\nof SNR, what we saw is that",
    "start": "28930",
    "end": "36370"
  },
  {
    "text": "the Shannon spectral\nefficiency in the bandwidth-limited regime,\nit doubles for every --",
    "start": "36370",
    "end": "42010"
  },
  {
    "text": "if we double our SNR. For every 3 dB increase in SNR,\nthe spectral efficiency",
    "start": "42010",
    "end": "47670"
  },
  {
    "text": "increases by a factor of 2. In the bandwidth limited regime,\nif we have a 3 dB",
    "start": "47670",
    "end": "53470"
  },
  {
    "text": "increase in SNR, the spectral\nefficiency increases by one bit per two dimension.",
    "start": "53470",
    "end": "59079"
  },
  {
    "text": "On the other hand, if we double\nour bandwidth, then the capacity in bits per second\nis not affected in the",
    "start": "59080",
    "end": "65110"
  },
  {
    "text": "power-limited regime. But if we double our bandwidth,\nthen in the bandwidth-limited regime,\nthe capacity increases",
    "start": "65110",
    "end": "72970"
  },
  {
    "text": "approximately by\na factor of 2. And that's really what\nmotivated the name bandwidth-limited and\npower-limited regime.",
    "start": "72970",
    "end": "79680"
  },
  {
    "text": "If we want a more operational\ndefinition, then we say that the flow is less than two bits\nper two dimensions, we will",
    "start": "79680",
    "end": "86390"
  },
  {
    "text": "have this bandwidth-limited\nregime. And in this case, rho is greater\nthan two bits per two",
    "start": "86390",
    "end": "92590"
  },
  {
    "text": "dimensions. The number two bits per two\ndimensions was chosen because it is like the largest spectral\nefficiency we can get",
    "start": "92590",
    "end": "100360"
  },
  {
    "text": "through binary transmission. If it's an uncoded two-PAM over\na channel, then we get two bits per two dimensions.",
    "start": "100360",
    "end": "106990"
  },
  {
    "text": "If we are coding, the only\nthing we can do is reduce spectral efficiency. So typically, if we are going\nto operate in power-limited",
    "start": "106990",
    "end": "113770"
  },
  {
    "text": "regime, the operational meaning\nis we can get away with binary transmission. In the bandwidth-limited regime,\nwe have to resort to",
    "start": "113770",
    "end": "120899"
  },
  {
    "text": "non-binary transmission. So in other words, binary\nmodulation is done in",
    "start": "120900",
    "end": "129179"
  },
  {
    "text": "power-limited regime, whereas we\nneed multi-level modulation",
    "start": "129180",
    "end": "137459"
  },
  {
    "text": "in the bandwidth-limited\nregime. ",
    "start": "137460",
    "end": "148440"
  },
  {
    "text": "The baseline system\nhere is 2-PAM. The uncoded performance\nwas of 2-PAM.",
    "start": "148440",
    "end": "155189"
  },
  {
    "text": "In the bandwidth limited\nregime, it is M-PAM. And the way we measure\nperformance in the",
    "start": "155190",
    "end": "160680"
  },
  {
    "text": "power-limited regime is the\nprobability of bit error as a function of EbN0.",
    "start": "160680",
    "end": "166200"
  },
  {
    "text": " OK?",
    "start": "166200",
    "end": "171360"
  },
  {
    "text": "In the bandwidth-limited\nregime, the performance measure is done by probability\nof error per two dimensions as",
    "start": "171360",
    "end": "179080"
  },
  {
    "text": "a function of SNR norm. ",
    "start": "179080",
    "end": "187599"
  },
  {
    "text": "And in this case, we saw that\nthe gap to capacity -- or rather, to put it in other\nwords, the ultimate limit on",
    "start": "187600",
    "end": "198670"
  },
  {
    "text": "EbN0 is minus 1.59 dB.",
    "start": "198670",
    "end": "211090"
  },
  {
    "text": "And here, the ultimate limit\non SNR norm is 0 dB.",
    "start": "211090",
    "end": "227810"
  },
  {
    "start": "227810",
    "end": "239440"
  },
  {
    "text": "OK? Any questions on this? Yes.",
    "start": "239440",
    "end": "244570"
  },
  {
    "text": "AUDIENCE: Why do we use Eb\nover N_0 SNR norm for",
    "start": "244570",
    "end": "249770"
  },
  {
    "text": "[INAUDIBLE] bandwidth limited? PROFESSOR: That's\na good question. AUDIENCE: Why do we use Eb over\nN_0 for both regimes?",
    "start": "249770",
    "end": "256838"
  },
  {
    "text": "PROFESSOR: Or why don't use\nSNR norm for both regimes? AUDIENCE: Yeah. PROFESSOR: Now if we think about\nthe bandwidth limited regime, what we really\ncare about is",
    "start": "256839",
    "end": "263070"
  },
  {
    "text": "spectral efficiency, right? What SNR norm does, if you\nremember the definition, is",
    "start": "263070",
    "end": "269080"
  },
  {
    "text": "that it compass the amount of\nSNR we require for a practical system to that of the best\npossible system.",
    "start": "269080",
    "end": "275400"
  },
  {
    "text": "So in other words, if you\ndo care about spectral efficiency, SNR norm is the\nright measure to look for.",
    "start": "275400",
    "end": "282889"
  },
  {
    "text": "OK, now what happens in the\npower-limited regime? It turns out, probably more for\nhistoric reasons, people",
    "start": "282890",
    "end": "289310"
  },
  {
    "text": "started with EbN0 in the\npower-limited regime. And if you look at the\ndefinition of EbN0, it is SNR",
    "start": "289310",
    "end": "300985"
  },
  {
    "text": "over rho, right? So in the power limited regime,\nour rho is small, the",
    "start": "300985",
    "end": "307069"
  },
  {
    "text": "SNR is going to be small, but\nif you look at -- because we are in the power limited regime\nso we have lots of",
    "start": "307070",
    "end": "313840"
  },
  {
    "text": "bandwidth, so our SNR is going\nto be small and the spectral efficiency is going\nto be small.",
    "start": "313840",
    "end": "319450"
  },
  {
    "text": "But if you look at the ratio\nbetween the two, it's going to be greater than minus 1.59 dB.",
    "start": "319450",
    "end": "329479"
  },
  {
    "text": "OK. so it turns out that the kind of\nlimit we do take, our EbN0 remains constant as minus 1.59\ndB, and that's probably one of",
    "start": "329480",
    "end": "337810"
  },
  {
    "text": "the reasons that motivated\nto use EbN0 in the power limited regime.",
    "start": "337810",
    "end": "344180"
  },
  {
    "text": "On the other hand, one could\nalso argue is that what really happens in the power limited\nregime is that our bandwidth becomes really large.",
    "start": "344180",
    "end": "350370"
  },
  {
    "text": "So if this [UNINTELLIGIBLE] stick with 2-PAM system, then\nwe do get a spectral efficiency of two bits per two\ndimensions, but that's just",
    "start": "350370",
    "end": "357720"
  },
  {
    "text": "because we are using a\nparticular modulation scheme. If our bandwidth is really\nlarge, we are not really going",
    "start": "357720",
    "end": "363099"
  },
  {
    "text": "to care about what spectral\nefficiency we use. What really matters is this\nenergy per bit, and that's why",
    "start": "363100",
    "end": "368790"
  },
  {
    "text": "this is a reasonable\nassumption.  Does that answer\nyour question?",
    "start": "368790",
    "end": "375710"
  },
  {
    "text": "Right, it's not completely clear\nas to why this EbN0 is the best here, and SNR norm is\nhere if you don't take the",
    "start": "375710",
    "end": "383370"
  },
  {
    "text": "limit rho going to zero here,\nbut again, you can think of it more as a convention.",
    "start": "383370",
    "end": "388970"
  },
  {
    "text": "OK. AUDIENCE: [INAUDIBLE]  PROFESSOR: So if you look in the\npower-limited regime, you",
    "start": "388970",
    "end": "395790"
  },
  {
    "text": "are saying rho is less than two\nbits per two dimensions. If you use an uncoded 2-PAM,\nwhat's your spectral",
    "start": "395790",
    "end": "401070"
  },
  {
    "text": "efficiency? It's two bits per two\ndimension, right? Now the idea is, suppose we want\nto design a system with",
    "start": "401070",
    "end": "407900"
  },
  {
    "text": "spectral efficiency greater\nthan two bits per two dimensions? We cannot really use\na 2-PAM system.",
    "start": "407900",
    "end": "414020"
  },
  {
    "text": "Because if you put coding on top\nof it, all we are going to do is simply reduce the spectral\nefficiency below two bits per two dimension.",
    "start": "414020",
    "end": "420729"
  },
  {
    "text": "So we have to start with a\nnon-binary modulation, right? So that's how we distinguish\nbetween power-limited and",
    "start": "420730",
    "end": "427180"
  },
  {
    "text": "bandwidth-limited AUDIENCE: That's just because\nyou're using the 2-PAM as your baseline [INAUDIBLE]?",
    "start": "427180",
    "end": "434728"
  },
  {
    "text": "PROFESSOR: Right. OK? All right.",
    "start": "434728",
    "end": "441610"
  },
  {
    "text": "So let us do an example to\nfinish off this analysis. ",
    "start": "441610",
    "end": "459920"
  },
  {
    "text": "Now suppose -- say you are at a summer project,\nand you're assigned to design some system.",
    "start": "459920",
    "end": "466410"
  },
  {
    "text": "Your boss gives you some\nspecifications, like continuous time specifications.",
    "start": "466410",
    "end": "471740"
  },
  {
    "text": "In particular, you have\na baseband system. ",
    "start": "471740",
    "end": "483320"
  },
  {
    "text": "The baseband system has a\nbandwidth of one Megahertz. ",
    "start": "483320",
    "end": "490510"
  },
  {
    "text": "You have a power, P, which is\none unit, so that's another",
    "start": "490510",
    "end": "498590"
  },
  {
    "text": "resource you have. And if you measure your channel,\nit can be reasonably approximated as an AWGN channel,\nso there is no ISI or",
    "start": "498590",
    "end": "506070"
  },
  {
    "text": "any filtering going on, just\nAdditive White Gaussian Noise. And your noise a single sided\nspectral density of ten to the",
    "start": "506070",
    "end": "514159"
  },
  {
    "text": "minus six units per Hertz\nof the bandwidth.",
    "start": "514159",
    "end": "519565"
  },
  {
    "text": " And what is your goal? ",
    "start": "519566",
    "end": "529070"
  },
  {
    "text": "So you have the following\ngoal.  Design a 2-PAM system,\nwith a specified",
    "start": "529070",
    "end": "545240"
  },
  {
    "text": "probability of bit error. ",
    "start": "545240",
    "end": "551380"
  },
  {
    "text": "And what you want to do is\ncompare this to the ultimate",
    "start": "551380",
    "end": "564470"
  },
  {
    "text": "Shannon limit. ",
    "start": "564470",
    "end": "573079"
  },
  {
    "text": "So that is your objective. So since we have to compare it\nwith Shannon limit, and we",
    "start": "573080",
    "end": "580540"
  },
  {
    "text": "have already a formula for the\nShannon limit, let's just start with that. ",
    "start": "580540",
    "end": "590320"
  },
  {
    "text": "So for this problem, we have\nthe Shannon limit. ",
    "start": "590320",
    "end": "597060"
  },
  {
    "text": "You have rho is less than log\nbase 2 of 1 plus SNR.",
    "start": "597060",
    "end": "602870"
  },
  {
    "text": "For SNR, I can talk in terms\nof this continuous time parameters, it's P over N_0 W.\nMy P is one unit, and nought",
    "start": "602870",
    "end": "613240"
  },
  {
    "text": "is ten to the minus six, and\nmy bandwidth, W, is one Megahertz here, which\nis ten to the six.",
    "start": "613240",
    "end": "619570"
  },
  {
    "text": "So my P over N_0 W\nis basically one. So I have 1 plus\n1, which is 2.",
    "start": "619570",
    "end": "624700"
  },
  {
    "text": "This is log base\n2 of 2, or it's one bit per two dimension.",
    "start": "624700",
    "end": "629819"
  },
  {
    "text": "So my capacity in bits per\nsecond is rho W, and rho is",
    "start": "629820",
    "end": "637100"
  },
  {
    "text": "one bit per two dimension, the\nbandwidth is one Megahertz. So I get ten to the six\nbits per second.",
    "start": "637100",
    "end": "644089"
  },
  {
    "text": "So this is my Shannon\ncapacity for this particular AWGN system. ",
    "start": "644090",
    "end": "651490"
  },
  {
    "text": "OK.  The next thing we want to do\nis compare this with a",
    "start": "651490",
    "end": "658030"
  },
  {
    "text": "practical system, and\nsee how close we get to the Shannon limit. And since you only have to work\nwith 2-PAM, the generic",
    "start": "658030",
    "end": "666080"
  },
  {
    "text": "architecture is something\nwe saw last time. You have input bits coming in,\nlet's call them X sub k, where",
    "start": "666080",
    "end": "675610"
  },
  {
    "text": "k is the kth bit. And they belong to a certain\nconstellation, let's call the --",
    "start": "675610",
    "end": "681279"
  },
  {
    "text": "the constellation points are\njust -- it's a 2-PAM system, so we have minus alpha\nand alpha.",
    "start": "681280",
    "end": "687690"
  },
  {
    "text": "And this goes through a PAM\nmodulator, and one parameter to specify for the\nPAM modulator",
    "start": "687690",
    "end": "693920"
  },
  {
    "text": "is the symbol interval. Right, the time between sending\nconsecutive signals",
    "start": "693920",
    "end": "700779"
  },
  {
    "text": "over the channel. What you get out is X\nof t, this is the",
    "start": "700780",
    "end": "707260"
  },
  {
    "text": "channel model, N of t. There's already noise over\nthe channel, and what you get out is Y of t.",
    "start": "707260",
    "end": "714880"
  },
  {
    "text": "So this is the generic\narchitecture. And now, your goal for the\ndesign problem is to select",
    "start": "714880",
    "end": "725230"
  },
  {
    "text": "alpha and t in the right way,\nso that they satisfy this",
    "start": "725230",
    "end": "732630"
  },
  {
    "text": "continuous time constraints, and\nat the same time, you have your probability of error of\nten to the minus five.",
    "start": "732630",
    "end": "738050"
  },
  {
    "start": "738050",
    "end": "743970"
  },
  {
    "text": "So what would be an obvious\nchoice for T? ",
    "start": "743970",
    "end": "750312"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]  PROFESSOR: Right.",
    "start": "750312",
    "end": "755580"
  },
  {
    "text": "So the first idea is you are\ngiven a certain amount of bandwidth, and you clearly want\nsend your signals as fast",
    "start": "755580",
    "end": "763889"
  },
  {
    "text": "as possible in order to get\nexcellent data rate. Now because you have a certain\namount of bandwidth, what",
    "start": "763890",
    "end": "770100"
  },
  {
    "text": "Nyquist's criteria tells\nyou is that you want to have zero ISI. And if you want to have zero\nISI, what you do know is that",
    "start": "770100",
    "end": "779449"
  },
  {
    "text": "the symbol interval should\nbe greater than or equal to 1 over 2W.",
    "start": "779450",
    "end": "784670"
  },
  {
    "text": "You cannot signal at a rate\nfaster than one over T, and so if we look at this, it's 1\nover 2 times 10 to the 6.",
    "start": "784670",
    "end": "794590"
  },
  {
    "text": "Now it I do use this particular\nvalue of T, then what's my alpha going to be?",
    "start": "794590",
    "end": "801710"
  },
  {
    "text": "Well, alpha is simply the\nenergy per symbol. So I know alpha squared is the\npower that I have times the",
    "start": "801710",
    "end": "810370"
  },
  {
    "text": "symbol interval, T. It's\njust a definition. This comes from orthonormality\nof the PAM",
    "start": "810370",
    "end": "816490"
  },
  {
    "text": "system that we have. Now P is one, because that's\nwhat I specified as a system",
    "start": "816490",
    "end": "823589"
  },
  {
    "text": "specification, so this is just\nT, which is one over times ten to the six.",
    "start": "823590",
    "end": "829970"
  },
  {
    "text": "So I can select this value of\nalpha and this value of T. AUDIENCE: [INAUDIBLE]",
    "start": "829970",
    "end": "835272"
  },
  {
    "text": " PROFESSOR: Well, alpha squared\nis energy per symbol.",
    "start": "835272",
    "end": "842110"
  },
  {
    "text": "So what will that be? What's the energy per symbol,\nif you're sending every T seconds, and if you\nhave a power of P?",
    "start": "842110",
    "end": "849740"
  },
  {
    "text": "Es, that I mentioned last\ntime, or energy per two dimensions. So in PAM, it will be\nenergy per symbols.",
    "start": "849740",
    "end": "856949"
  },
  {
    "text": "In that case, it will be 2P. ",
    "start": "856950",
    "end": "863120"
  },
  {
    "text": "OK. But now if I select these values\nof alpha and T, will my system work? Is this a reasonable\ndesign, or is there",
    "start": "863120",
    "end": "870900"
  },
  {
    "text": "something wrong here? ",
    "start": "870900",
    "end": "877690"
  },
  {
    "text": "I'm clearly satisfying my -- AUDIENCE: [INAUDIBLE] PROFESSOR: The probability\nof error, right, exactly.",
    "start": "877690",
    "end": "884190"
  },
  {
    "text": "So in fact, I do know how\nto calculate it, right? What's the probability\nof bit error?",
    "start": "884190",
    "end": "890460"
  },
  {
    "text": "Well, we saw that last time it\nwas Q of root 2 Eb over N_0.",
    "start": "890460",
    "end": "896560"
  },
  {
    "text": " Eb is same as alpha squared,\nbecause we",
    "start": "896560",
    "end": "902480"
  },
  {
    "text": "have one bit per symbol. So alpha squared is this\nquantity here, 1 over 2 times",
    "start": "902480",
    "end": "908420"
  },
  {
    "text": "10 to the 6. So this is Q of square\nroot of --",
    "start": "908420",
    "end": "913580"
  },
  {
    "text": "so 2 alpha squared is 10 to\nthe 6, 1 over 10 to the 6.",
    "start": "913580",
    "end": "919810"
  },
  {
    "text": "N_0, I know, is ten to the\nminus six, so this is actually Q of 1.",
    "start": "919810",
    "end": "925959"
  },
  {
    "text": "And if I do calculate that, it's\nlike 17 percent, which is",
    "start": "925960",
    "end": "934430"
  },
  {
    "text": "nowhere close to ten\nto the minus five. ",
    "start": "934430",
    "end": "944029"
  },
  {
    "text": "So any suggestions on how\nI can improve my system?  AUDIENCE: Increase\nT [INAUDIBLE]",
    "start": "944030",
    "end": "949580"
  },
  {
    "text": "PROFESSOR: Increase T, right? What's happening\nright now is -- the reason we selected this\nvalue of T in the first place",
    "start": "949580",
    "end": "956959"
  },
  {
    "text": "is because we wanted to send\nour signals as fast as possible avoid ISI, but that's\njust one of criteria in my",
    "start": "956960",
    "end": "963590"
  },
  {
    "text": "system, right? I have to also satisfy this\nprobability of error criteria,",
    "start": "963590",
    "end": "968810"
  },
  {
    "text": "so I want to make sure my\nprobability of error is going to be small. If I look at the expression for\nprobability of error, it",
    "start": "968810",
    "end": "975960"
  },
  {
    "text": "doesn't really look at T. All\nit looks at is this ratio of Eb/N0, right? So if I want to reduce my\nprobability of error, I have",
    "start": "975960",
    "end": "983735"
  },
  {
    "text": "to increase my energy per bit. Now my energy per bit is P times\nT, so the only hope of",
    "start": "983735",
    "end": "989460"
  },
  {
    "text": "increasing my energy per bit\nwill be to increase T, which means I have to signal\nat a slower rate.",
    "start": "989460",
    "end": "996798"
  },
  {
    "text": "OK? So we have probability of -- let's write the calculation\ndown. ",
    "start": "996798",
    "end": "1008200"
  },
  {
    "text": "It's ten to the minus five. Last time, we saw that the best\nway to solve this is to look at the waterfall curve,\nand EbN_0 in this case is",
    "start": "1008200",
    "end": "1019510"
  },
  {
    "text": "approximately 9.6 dB. I will say that that's\napproximately ten on the",
    "start": "1019510",
    "end": "1025549"
  },
  {
    "text": "linear scale. ",
    "start": "1025550",
    "end": "1032439"
  },
  {
    "text": "So this implies that energy\nper bit is ten",
    "start": "1032440",
    "end": "1037689"
  },
  {
    "text": "to the minus five. So energy per bit is P times T,\nin this case, it's ten to",
    "start": "1037690",
    "end": "1044660"
  },
  {
    "text": "the minus five. p is one, so\nthis implies that t is ten to",
    "start": "1044660",
    "end": "1049890"
  },
  {
    "text": "the minus five. So I can send one bit every ten\nto the minus five seconds.",
    "start": "1049890",
    "end": "1055320"
  },
  {
    "text": "So my rate that I achieve -- just write it here -- ",
    "start": "1055320",
    "end": "1063130"
  },
  {
    "text": "which is ten to the five\nbits per second.",
    "start": "1063130",
    "end": "1069187"
  },
  {
    "text": "OK? ",
    "start": "1069187",
    "end": "1074520"
  },
  {
    "text": "If you compare this to the\nShannon limit, the Shannon limit is right here,\nyou have ten to the",
    "start": "1074520",
    "end": "1080970"
  },
  {
    "text": "six bits per second. So you lose by a factor of ten\nin your data rate if you're",
    "start": "1080970",
    "end": "1085980"
  },
  {
    "text": "going to use an uncoded\n2-PAM system. So what this example tells you\nis that if you're going to do",
    "start": "1085980",
    "end": "1092610"
  },
  {
    "text": "more sophisticated cording, you\ncan gain up to a factor of ten in your data rate.",
    "start": "1092610",
    "end": "1098919"
  },
  {
    "text": "So if the 10 dB did not really\nimpress you last time, hopefully this example\nthrows more light on",
    "start": "1098920",
    "end": "1105110"
  },
  {
    "text": "the value of coding.  Are there any questions\non this example? ",
    "start": "1105110",
    "end": "1115675"
  },
  {
    "text": "AUDIENCE: Since the -- since we are signaling at a\nfaster rate now, instead of",
    "start": "1115675",
    "end": "1121510"
  },
  {
    "text": "using sink process, we can\nuse something better. PROFESSOR: That's a very\ngood point, yes. Well, if you look at the nominal\nbandwidth here, it's 1",
    "start": "1121510",
    "end": "1131480"
  },
  {
    "text": "over 2T, right? T is 10 to the minus 5 seconds,\nso this says 1 over 2",
    "start": "1131480",
    "end": "1138920"
  },
  {
    "text": "times 10 to the minus 5. So it's going to be 5 times\n10 to the 4, or 50 KHz.",
    "start": "1138920",
    "end": "1146065"
  },
  {
    "text": " OK? The available bandwidth you\nhave, the system bandwidth, if",
    "start": "1146065",
    "end": "1153060"
  },
  {
    "text": "you will, is 1 Megahertz. But if you're going to do\nNyquist's ideal sinks pulses,",
    "start": "1153060",
    "end": "1160440"
  },
  {
    "text": "then you only need 50\nKHz of bandwidth in your system, right? So one advantage of this system,\nif you will, is that",
    "start": "1160440",
    "end": "1169900"
  },
  {
    "text": "you're not required to do the\ncomplicated sink pulses. Do not need to send\nthose pulses. You could simply send, for\nexample, square pulses and,",
    "start": "1169900",
    "end": "1178480"
  },
  {
    "text": "because your bandwidth is such\nlow, you have a very low complexity system. Of course, the price you pay is\nyou reduce the data rate by",
    "start": "1178480",
    "end": "1187720"
  },
  {
    "text": "a factor of ten.  OK, it's a good point.",
    "start": "1187720",
    "end": "1192920"
  },
  {
    "text": "In fact, there are many points\nthat will come up in this example if you think about it\nlater on, so feel free to ask",
    "start": "1192920",
    "end": "1199080"
  },
  {
    "text": "me questions if you think about\nsome issues later on. ",
    "start": "1199080",
    "end": "1207590"
  },
  {
    "text": "Ok. So I think we have motivated\nthe need for coding enough",
    "start": "1207590",
    "end": "1212929"
  },
  {
    "text": "now, so let's look at\nour encoder design. ",
    "start": "1212930",
    "end": "1227760"
  },
  {
    "text": "So a typical encoder design\ntakes bits in --",
    "start": "1227760",
    "end": "1238360"
  },
  {
    "text": "we saw this last time\nin the context of spectral efficiency -- and produces symbols out.",
    "start": "1238360",
    "end": "1243884"
  },
  {
    "text": " So I can represent my bits by,\nsay a vector b, and I can",
    "start": "1243885",
    "end": "1252880"
  },
  {
    "text": "represent my symbols\nby a vector x. So every sequence of b\nbits gets mapped to a",
    "start": "1252880",
    "end": "1259880"
  },
  {
    "text": "sequence of N symbols. Now this output sequence of\nsymbols is not any arbitrary",
    "start": "1259880",
    "end": "1265860"
  },
  {
    "text": "sequence, but it lies in a set\nof all possible sequences,",
    "start": "1265860",
    "end": "1271160"
  },
  {
    "text": "which I denote by C. And this\nset is essentially a set of",
    "start": "1271160",
    "end": "1276860"
  },
  {
    "text": "permissible output symbol\nsequences, which I will write by C sub j, which is a vector\nin Rn, because there are N",
    "start": "1276860",
    "end": "1287590"
  },
  {
    "text": "symbols being produced. And we can have set up to j, j\ngoes from 1 to M. So we can",
    "start": "1287590",
    "end": "1294550"
  },
  {
    "text": "have up to M symbols. And note that here, M has to\nbe equal to 2 to the b, in",
    "start": "1294550",
    "end": "1303990"
  },
  {
    "text": "order to be able to\nmap every sequence of b bits to M symbols. So this C is known as a\ncodebook, and each C sub j is",
    "start": "1303990",
    "end": "1321500"
  },
  {
    "text": "called a codeword. ",
    "start": "1321500",
    "end": "1327280"
  },
  {
    "text": "OK? The standard definition\nof an encoder. Now in today's lecture and half\nof next week's lecture,",
    "start": "1327280",
    "end": "1335480"
  },
  {
    "text": "we will be seeing at a very\nspecific case when N equals 1 and 2.",
    "start": "1335480",
    "end": "1342130"
  },
  {
    "text": "In that case, instead of using\nthe letter C, we will be using a different letter, A. So C,\nin that case, we'll call it",
    "start": "1342130",
    "end": "1350970"
  },
  {
    "text": "actually a constellation.  So in particular if C is one,\nit's a PAM constellation.",
    "start": "1350970",
    "end": "1358080"
  },
  {
    "text": "If N is 2, it's a QAM\nconstellation. And we'll be denoting it by\na letter A instead of C.",
    "start": "1358080",
    "end": "1364180"
  },
  {
    "text": "So A is again, a sequence of\nsymbols a_j, which belongs to",
    "start": "1364180",
    "end": "1370090"
  },
  {
    "text": "Rn, where one is less than j\nis less than M. OK, in this",
    "start": "1370090",
    "end": "1378409"
  },
  {
    "text": "case a is a constellation. ",
    "start": "1378410",
    "end": "1388040"
  },
  {
    "text": "a_j's are known as symbols, or\nsometimes they're also known",
    "start": "1388040",
    "end": "1393810"
  },
  {
    "text": "as signal points in\nthe constellation. ",
    "start": "1393810",
    "end": "1402840"
  },
  {
    "text": "There are a number of\ndefinitions that follow from this -- number of properties of\nthe constellation,",
    "start": "1402840",
    "end": "1408170"
  },
  {
    "text": "rather, that follow. So in particular N is known\nas the dimension of your",
    "start": "1408170",
    "end": "1414260"
  },
  {
    "text": "constellation. The number N is this, and\nhere, it's the number of",
    "start": "1414260",
    "end": "1420160"
  },
  {
    "text": "symbol sequences you output\nfor a sequence of b bits that are in.",
    "start": "1420160",
    "end": "1427090"
  },
  {
    "text": "M is the size of your\nconstellation. ",
    "start": "1427090",
    "end": "1439130"
  },
  {
    "text": "The energy per constellation is\ngiven by 1 over M times the",
    "start": "1439130",
    "end": "1446430"
  },
  {
    "text": "summation the norm of a_j\nsquared, where j goes from one",
    "start": "1446430",
    "end": "1454210"
  },
  {
    "text": "to M. The minimum distance of\nyour constellation is simply",
    "start": "1454210",
    "end": "1464460"
  },
  {
    "text": "the Euclidean minimum distance\nbetween two points in the constellation.",
    "start": "1464460",
    "end": "1470380"
  },
  {
    "text": "So if you take the norm of a_i\nminus a_j, and minimize it over all possible\nvalues i and j. ",
    "start": "1470380",
    "end": "1478330"
  },
  {
    "text": "The number of nearest neighbors,\nof the average number of nearest --",
    "start": "1478330",
    "end": "1484460"
  },
  {
    "text": "K_min of A is the average number\nof nearest neighbors in",
    "start": "1484460",
    "end": "1499360"
  },
  {
    "text": "A.",
    "start": "1499360",
    "end": "1504480"
  },
  {
    "text": "In addition to this, there\nare some orthonormalized parameters that you\nsaw last time. ",
    "start": "1504480",
    "end": "1517460"
  },
  {
    "text": "The spectral efficiency, which\nis in units of bits per two dimensions is 2b over N. And if\nyou want to eliminate b, we",
    "start": "1517460",
    "end": "1529630"
  },
  {
    "text": "use the relation that b is\nlog M to the base 2 here. And so we have 2 log M\nto the base 2 over N.",
    "start": "1529630",
    "end": "1541539"
  },
  {
    "text": "The energy per two dimensions,\ndenoted by Es, is simply 2",
    "start": "1541540",
    "end": "1547170"
  },
  {
    "text": "over N E(A). So E(A) is the average energy\nof your constellation.",
    "start": "1547170",
    "end": "1552920"
  },
  {
    "text": "If you divide it by the number\nof dimensions you have, you get energy per dimension, and\nyou multiply it by 2.",
    "start": "1552920",
    "end": "1560330"
  },
  {
    "text": "And finally, the energy per bit\nis Es over rho, or it can",
    "start": "1560330",
    "end": "1567080"
  },
  {
    "text": "also be expressed as E(A), which\nis the energy per symbol over the number of bits per\nsymbol, which is log",
    "start": "1567080",
    "end": "1575430"
  },
  {
    "text": "M to the base 2. ",
    "start": "1575430",
    "end": "1586120"
  },
  {
    "text": "It might seem like a lot of\ndefinitions, but you will see very soon that they have a very\ntight interplay among one",
    "start": "1586120",
    "end": "1593110"
  },
  {
    "text": "another, so it's not nearly as\noverwhelming as it might seem at the first point.",
    "start": "1593110",
    "end": "1598980"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Yes. AUDIENCE: Why is\n[UNINTELLIGIBLE]? ",
    "start": "1598980",
    "end": "1606780"
  },
  {
    "text": "PROFESSOR: Because you have two\n[UNINTELLIGIBLE] b bits coming in, right, which\nyou map to each --",
    "start": "1606780",
    "end": "1614522"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] There are two [INAUDIBLE]\npossible sequences, but all of",
    "start": "1614522",
    "end": "1619860"
  },
  {
    "text": "them need not be used, right? PROFESSOR: Well, we assume that\nthere is no coding going",
    "start": "1619860",
    "end": "1626340"
  },
  {
    "text": "on before the encoder. So you have the source code, for\nwhich there's a sequence",
    "start": "1626340",
    "end": "1631690"
  },
  {
    "text": "of IID bits, and then\nthey mapped to a sequence of symbols.",
    "start": "1631690",
    "end": "1639180"
  },
  {
    "text": "So we'll see all of our possible\ninput bits coming in here, because it's produced\nby a source code,",
    "start": "1639180",
    "end": "1645190"
  },
  {
    "text": "like a Huffman code. Right? And the idea here is, perhaps\nwhat you're asking is --",
    "start": "1645190",
    "end": "1650920"
  },
  {
    "text": "this did not span the\nentire space of Rn.  We want to select these\nsequences carefully here.",
    "start": "1650920",
    "end": "1658400"
  },
  {
    "start": "1658400",
    "end": "1666590"
  },
  {
    "text": "Maybe we'll come back to that\nlater on in the course. ",
    "start": "1666590",
    "end": "1673200"
  },
  {
    "text": "OK, so let's do an example. ",
    "start": "1673200",
    "end": "1683289"
  },
  {
    "text": "So the example is, say we have\nA, which is a 2-PAM system,",
    "start": "1683290",
    "end": "1696040"
  },
  {
    "text": "and you want to look at this\nconstellation, B, which is",
    "start": "1696040",
    "end": "1701340"
  },
  {
    "text": "denoted by A raised to K. The\ndefinition of A raised to k is",
    "start": "1701340",
    "end": "1706720"
  },
  {
    "text": "it's a sequence of K symbols\nwhere each x_i belongs to A.",
    "start": "1706720",
    "end": "1716799"
  },
  {
    "text": "So this is also known as the\nK-fold Cartesian product of A.",
    "start": "1716800",
    "end": "1734049"
  },
  {
    "text": "AUDIENCE: Another question. So it has been pre-decided that\nb bits will be encoded [UNINTELLIGIBLE]? PROFESSOR: Right.",
    "start": "1734049",
    "end": "1740240"
  },
  {
    "text": "So this is a specific structure\nwe are imposing on the encoder. ",
    "start": "1740240",
    "end": "1747830"
  },
  {
    "text": "So this is the constellation,\nand you'll want to study the properties for this\nconstellation. For this constellation,\nwhat's N going to be?",
    "start": "1747830",
    "end": "1758230"
  },
  {
    "text": "What's the dimension\ngoing to be? AUDIENCE: [INAUDIBLE] PROFESSOR: For B, not A. It's\ngoing to be K. Well, the",
    "start": "1758230",
    "end": "1768700"
  },
  {
    "text": "number of points in this\nconstellation, how many points are there?",
    "start": "1768700",
    "end": "1773910"
  },
  {
    "text": "There are K coordinates. Each coordinate can be\nplus or minus alpha. So we have 2 to the K possible\npoints in this constellation.",
    "start": "1773910",
    "end": "1784670"
  },
  {
    "text": "OK?  What's E of A going to be?",
    "start": "1784670",
    "end": "1789840"
  },
  {
    "start": "1789840",
    "end": "1800554"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: K alpha\nsquared. right?",
    "start": "1800554",
    "end": "1805890"
  },
  {
    "text": "Basically, we have\nK coordinates. The energy for each coordinate\nwill simply add up.",
    "start": "1805890",
    "end": "1811169"
  },
  {
    "text": "The energy across each\ncoordinate is always going to be alpha squared. So each point in this\nconstellation has an energy of",
    "start": "1811170",
    "end": "1818480"
  },
  {
    "text": "K alpha squared. So regardless of how many points\nwe have, the average energy is always going to\nbe K alpha squared.",
    "start": "1818480",
    "end": "1824930"
  },
  {
    "text": " Does everybody see this? AUDIENCE: [INAUDIBLE]",
    "start": "1824930",
    "end": "1830418"
  },
  {
    "text": "PROFESSOR: You're right. Maybe that was the confusion. ",
    "start": "1830418",
    "end": "1836259"
  },
  {
    "text": "It's a good thing. Just getting too used to\nwriting E of A. OK.",
    "start": "1836260",
    "end": "1842559"
  },
  {
    "text": "What's d_min of b going to be? ",
    "start": "1842560",
    "end": "1855324"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] 2 alpha. PROFESSOR: 2 alpha. ",
    "start": "1855324",
    "end": "1861090"
  },
  {
    "text": "I think everybody had\nthe right idea. So the minimum distance here is\ntwo alpha for A. If we look",
    "start": "1861090",
    "end": "1867990"
  },
  {
    "text": "at this point B, we can fix K\nminus 1 coordinates for two points to be the same, they will\nonly differ in one point.",
    "start": "1867990",
    "end": "1875890"
  },
  {
    "text": "And so the minimum distance\nis across that point, which is 2 alpha.",
    "start": "1875890",
    "end": "1881430"
  },
  {
    "text": "What is K_min of\nB going to be? ",
    "start": "1881430",
    "end": "1889909"
  },
  {
    "text": "It's going to be K. For each\npoint -- let's say the point",
    "start": "1889910",
    "end": "1894920"
  },
  {
    "text": "which has all alphas, we can fix\nK minus 1 coordinate and find another point which is\ndifferent in only one of the",
    "start": "1894920",
    "end": "1902710"
  },
  {
    "text": "coordinates, say the\nfirst coordinate. We can do it for all K different\ncoordinates, so K_min is going to be K for\neach point, and hence the",
    "start": "1902710",
    "end": "1913830"
  },
  {
    "text": "average number of nearest\nneighbors is also K. OK, so now in this case, let's\nfirst start with the",
    "start": "1913830",
    "end": "1920870"
  },
  {
    "text": "normalized parameters. That's always good to start\nwith spectral efficiency.",
    "start": "1920870",
    "end": "1925940"
  },
  {
    "text": "That's 2 log M over N. Well, log\nof M is going to be K, so",
    "start": "1925940",
    "end": "1934710"
  },
  {
    "text": "N is going to be K. So this is\ngoing to be two bits per two dimensions, and this is the same\nas that of the original",
    "start": "1934710",
    "end": "1944299"
  },
  {
    "text": "constellation, A. Your energy\nper two dimensions is going to",
    "start": "1944300",
    "end": "1950370"
  },
  {
    "text": "be 2 over N E(B). E(B) is K alpha squared, N\nequals K, so this is 2 alpha",
    "start": "1950370",
    "end": "1959080"
  },
  {
    "text": "squared, and that is the same as\nthe original constellation, A.",
    "start": "1959080",
    "end": "1965120"
  },
  {
    "text": "Finally. energy per bit is Es over\nrho, so it's 2 alpha",
    "start": "1965120",
    "end": "1971350"
  },
  {
    "text": "squared over 2. So that's alpha squared, and\nthat's same as the 2-PAM constellation.",
    "start": "1971350",
    "end": "1978000"
  },
  {
    "text": "So why did I go through all\nof these calculations? ",
    "start": "1978000",
    "end": "1983120"
  },
  {
    "text": "What we see is that the\nnormalized parameters, rho, Es, and Eb, are the same for the\nCartesian product as for",
    "start": "1983120",
    "end": "1990920"
  },
  {
    "text": "the original constellation. And at some level, that should\nnot be too surprising, right?",
    "start": "1990920",
    "end": "1996080"
  },
  {
    "text": "Because what I'll be doing in\nthis Cartesian product, we are not really doing any\ncoding, right?",
    "start": "1996080",
    "end": "2001510"
  },
  {
    "text": "In this original constellation,\nwe had one bit coming in, and we are mapping\nit to one symbol.",
    "start": "2001510",
    "end": "2007080"
  },
  {
    "text": "All we are doing in the\nCartesian product is we are taking K bits in and mapping\nthem to K symbols.",
    "start": "2007080",
    "end": "2012520"
  },
  {
    "text": "So we still have one\nbit per symbol. The noise is IID, so it's\noptimal to two decisions for",
    "start": "2012520",
    "end": "2019770"
  },
  {
    "text": "each of the coordinates\nindependently, and decide whether that coordinate\ncorresponds to plus alpha or minus alpha.",
    "start": "2019770",
    "end": "2025730"
  },
  {
    "text": "So in other words, there's\nnothing gained by doing this Cartesian product. And we will see, the probability\nof error",
    "start": "2025730",
    "end": "2031280"
  },
  {
    "text": "expression depends on these\nnormalized parameters, if we want to look at Pb of E, and so\nwe do not gain anything in",
    "start": "2031280",
    "end": "2038140"
  },
  {
    "text": "terms of the probability of\nerror, versus EbN_0, trade-off through Cartesian product.",
    "start": "2038140",
    "end": "2043730"
  },
  {
    "text": "So I'm making the note here\nbecause that's the only space I have.",
    "start": "2043730",
    "end": "2049520"
  },
  {
    "text": "So the note is if I look at\nprobability of bit error versus EbN_0, the curve we saw\nlast time, it is the same for",
    "start": "2049520",
    "end": "2061060"
  },
  {
    "text": "B and A. You should be able to\nconvince yourself about this,",
    "start": "2061060",
    "end": "2068560"
  },
  {
    "text": "and so there is really no\ncoding going on here. ",
    "start": "2068560",
    "end": "2075039"
  },
  {
    "text": "Are there any questions\non this?  Let's look at this problem\na bit more carefully now.",
    "start": "2075040",
    "end": "2083510"
  },
  {
    "start": "2083510",
    "end": "2105875"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Yeah. AUDIENCE: Why [INAUDIBLE] ",
    "start": "2105875",
    "end": "2112750"
  },
  {
    "text": "PROFESSOR: Right. AUDIENCE: What does he use? PROFESSOR: Energy per\ntwo dimensions.",
    "start": "2112750",
    "end": "2119350"
  },
  {
    "text": "Es will always be energy\nper two dimensions. Throughout the course, we'll\nbe using these notations. Eb is the energy per bit,\nEs is the energy per two",
    "start": "2119350",
    "end": "2126040"
  },
  {
    "text": "dimensions. And if you want to say energy\nper symbol, we'll be using this notation E sub\nthe constellation.",
    "start": "2126040",
    "end": "2134068"
  },
  {
    "text": "AUDIENCE: Oh. It's not energy per bit. PROFESSOR: No, this\nis energy -- B is my constellation. So that's why it's energy of\nthat constellation, average",
    "start": "2134068",
    "end": "2142210"
  },
  {
    "text": "energy per symbol in\nthat constellation. ",
    "start": "2142210",
    "end": "2174320"
  },
  {
    "text": "OK, so let us consider the\nspecial case when K equals 3.",
    "start": "2174320",
    "end": "2179930"
  },
  {
    "text": "So in that case, B is A^q. So if I look at all possible\npoints in B, they are going to",
    "start": "2179930",
    "end": "2187420"
  },
  {
    "text": "lie on the vertices of a\nthree-dimensional cube. That's a Cartesian product\nin three dimensions.",
    "start": "2187420",
    "end": "2193365"
  },
  {
    "start": "2193365",
    "end": "2203760"
  },
  {
    "text": "And all my constellations points\nare basically on the vertices of this cube. ",
    "start": "2203760",
    "end": "2214070"
  },
  {
    "text": "The distance here is going\nto be 2 alpha. That's the length of each edge\nin my cube, and that's what B",
    "start": "2214070",
    "end": "2221960"
  },
  {
    "text": "is going to be. Clearly, the minimum distances\nis 2 alpha, as we saw before. Now let me define a different\nconstellation, B prime, and",
    "start": "2221960",
    "end": "2232260"
  },
  {
    "text": "only going to take four vertices\nfrom these possible eight vertices. I'm going to take this vertex\nhere, I'm going to take this",
    "start": "2232260",
    "end": "2241559"
  },
  {
    "text": "vertex here, this one,\nand this one.",
    "start": "2241560",
    "end": "2247120"
  },
  {
    "text": "I'm only taking four vertices. If I want to tell you explicitly\nwhat the points",
    "start": "2247120",
    "end": "2252539"
  },
  {
    "text": "are, I need to draw an axis, so\nI'm simply drawing the x, y, and z axis here.",
    "start": "2252540",
    "end": "2258680"
  },
  {
    "text": "This is x-axis, this is\ny-axis, and z-axis. And B prime is a subset\nof the points in this",
    "start": "2258680",
    "end": "2266180"
  },
  {
    "text": "three-dimensional Cartesian\nproduct. They will be alpha, alpha,\nalpha; minus alpha, minus",
    "start": "2266180",
    "end": "2275280"
  },
  {
    "text": "alpha, alpha; alpha, minus\nalpha, minus alpha; and let's",
    "start": "2275280",
    "end": "2283950"
  },
  {
    "text": "see, minus alpha, alpha,\nminus alpha.",
    "start": "2283950",
    "end": "2289050"
  },
  {
    "text": "So two of the coordinates will\nbe minus alpha here, in these three points, and we have one\ncoordinate all alphas.",
    "start": "2289050",
    "end": "2296260"
  },
  {
    "text": "So this is my B prime. What is the minimum distance\ngoing to be for B prime? ",
    "start": "2296260",
    "end": "2306226"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: 2 over\n2 alpha, right? It's basically the length\nof this edge here.",
    "start": "2306226",
    "end": "2312200"
  },
  {
    "text": "This is 2 alpha, this\nis 2 alpha. So it's 2 over 2 alpha. ",
    "start": "2312200",
    "end": "2325300"
  },
  {
    "text": "So in other words, by simply\nselecting a subset of points, I have been able to increase\nmy minimum distance.",
    "start": "2325300",
    "end": "2331660"
  },
  {
    "text": "Because my minimum distance\nis larger, I hope that the probability of error will be\nsmaller as opposed to the",
    "start": "2331660",
    "end": "2336810"
  },
  {
    "text": "original constellation. But this comes at the\nprice, right? And what's the price? ",
    "start": "2336810",
    "end": "2345400"
  },
  {
    "text": "The spectral efficiency\nis smaller, right? What if I look at my spectral\nefficiency?",
    "start": "2345400",
    "end": "2350450"
  },
  {
    "text": "Well, I'm only sending\nout two points, two bits per each point. So two bits, each point takes\nthree dimensions, so my",
    "start": "2350450",
    "end": "2358040"
  },
  {
    "text": "spectral efficiency is 2 times\n2 over 3 bits per two dimensions, or it's 4 over 3\nbits per two dimensions.",
    "start": "2358040",
    "end": "2366480"
  },
  {
    "text": "And this is in contrast to the\ntwo bits per two dimensions we had for B. So in other words, there is\na trade-off between your",
    "start": "2366480",
    "end": "2373690"
  },
  {
    "text": "spectral efficiency and\nthe minimum distance. We'll start with a K-dimensional\nCartesian",
    "start": "2373690",
    "end": "2380200"
  },
  {
    "text": "product of A, which\nhas all points. We took a subset of points, and\nif we chose them smartly,",
    "start": "2380200",
    "end": "2386690"
  },
  {
    "text": "we were able to increase the\nminimum distance, but the price we had to pay was\nto reduce the spectral",
    "start": "2386690",
    "end": "2392490"
  },
  {
    "text": "efficiency. ",
    "start": "2392490",
    "end": "2397610"
  },
  {
    "text": "AUDIENCE: Where did this\ntwo / three come from? PROFESSOR: This two here? AUDIENCE: 2/3, yes. PROFESSOR: 2/3, I am sending\ntwo bits per symbol, right?",
    "start": "2397610",
    "end": "2405920"
  },
  {
    "text": "Each symbol has three\ndimensions.  So it's 2/3 bit per dimension,\nor 4/3 bit per two dimension.",
    "start": "2405920",
    "end": "2413780"
  },
  {
    "text": " OK, so the point was it seems\nlike there is a trade-off",
    "start": "2413780",
    "end": "2425590"
  },
  {
    "text": "between minimum distance and\nspectral efficiency.",
    "start": "2425590",
    "end": "2433236"
  },
  {
    "text": " And indeed, this might seem like\na reasonable trade-off,",
    "start": "2433236",
    "end": "2440300"
  },
  {
    "text": "and a lot of coding here that we\nwill be seeing in the early part of the course is indeed\nmotivated by this trade-off.",
    "start": "2440300",
    "end": "2446849"
  },
  {
    "text": "You want to reduce your spectral\nefficiency in order to increase your probability\nof error. ",
    "start": "2446850",
    "end": "2453250"
  },
  {
    "text": "And this has in fact been\nquite a dominant design principle for a large number of\ncodes that have come up in",
    "start": "2453250",
    "end": "2458570"
  },
  {
    "text": "coding theory. However, if you look at what\nShannon says, Shannon says",
    "start": "2458570",
    "end": "2464910"
  },
  {
    "text": "something quite different. In Shannon's theorem, all\nthey say is, you have --",
    "start": "2464910",
    "end": "2470530"
  },
  {
    "text": "if your spectral efficiency is\nbelow a certain amount, then",
    "start": "2470530",
    "end": "2476390"
  },
  {
    "text": "your probability of bit error\ncan be made arbitrarily small.",
    "start": "2476390",
    "end": "2484180"
  },
  {
    "text": "OK, so what Shannon is saying,\nit's something much stronger than this trade-off. It's saying if you reduce your\nspectral efficiency below a",
    "start": "2484180",
    "end": "2491190"
  },
  {
    "text": "certain quantity which is\nfinite, then the probability of error can be made\narbitrarily small.",
    "start": "2491190",
    "end": "2497030"
  },
  {
    "text": "There is no statement of minimum\ndistance in this theorem here. And indeed, if you look at the\nmost modern codes which are",
    "start": "2497030",
    "end": "2504280"
  },
  {
    "text": "capacity approaching, they are\nnot designed to maximize the minimum distance.",
    "start": "2504280",
    "end": "2509900"
  },
  {
    "text": "They are designed to work well\nwith some practical decoding algorithms, like the belief\npropagation of",
    "start": "2509900",
    "end": "2515120"
  },
  {
    "text": "algorithms and so on. So they are designed on a\nsomewhat different principle than minimum distance.",
    "start": "2515120",
    "end": "2520619"
  },
  {
    "text": "But nevertheless, this is quite\na powerful tool that we will be using in the early\npart of this course.",
    "start": "2520620",
    "end": "2526910"
  },
  {
    "text": "We start with a K-dimensional\nCartesian product, select a subset of points, and we want\nto increase the minimum",
    "start": "2526910",
    "end": "2532580"
  },
  {
    "text": "distance at the cost of\nspectral efficiency. ",
    "start": "2532580",
    "end": "2538460"
  },
  {
    "text": "OK. Now are there any questions? AUDIENCE: [INAUDIBLE]",
    "start": "2538460",
    "end": "2544497"
  },
  {
    "start": "2544497",
    "end": "2549620"
  },
  {
    "text": "PROFESSOR: That's\na good question. Suppose I have a 2-PAM\nconstellation, then I can easily write the probability of\nbit error as a function of",
    "start": "2549620",
    "end": "2558059"
  },
  {
    "text": "Q function. If it is a more complicated\nexpression, I have to integrate over the decision\nregions, which we'll be seeing",
    "start": "2558060",
    "end": "2565990"
  },
  {
    "text": "later on in this lecture. And it's not usually possible to\nget an exact probability of error expression.",
    "start": "2565990",
    "end": "2571200"
  },
  {
    "text": "We usually use an in-union\nbound, to bound it by a pair of [UNINTELLIGIBLE]\nerror probability. We'll be doing all\nthat just now.",
    "start": "2571200",
    "end": "2577300"
  },
  {
    "start": "2577300",
    "end": "2585430"
  },
  {
    "text": "OK. So now let us -- I have talked now enough now\nabout encoder, and we'll be visiting it very soon, but let\nus switch gears and talk about",
    "start": "2585430",
    "end": "2592840"
  },
  {
    "text": "the decoder now. OK, what does a decoder do? So the goal of a decoder\nis the following.",
    "start": "2592840",
    "end": "2599850"
  },
  {
    "text": " You get your received vector Y,\nwhich is X plus N, and from",
    "start": "2599850",
    "end": "2609270"
  },
  {
    "text": "Y, you want to estimate X-hat\nas a point in your signal",
    "start": "2609270",
    "end": "2616400"
  },
  {
    "text": "constellation. So you receive a noisy version\nof X, and you want to estimate X-hat at the decoder.",
    "start": "2616400",
    "end": "2625560"
  },
  {
    "text": "So this is the architecture\nof your decoder. And the goal here is you\nwant to minimize the",
    "start": "2625560",
    "end": "2635830"
  },
  {
    "text": "probability of error. And what's the probability\nof error?",
    "start": "2635830",
    "end": "2641490"
  },
  {
    "text": "It's basically probability that\nX is not equal to X-hat.",
    "start": "2641490",
    "end": "2647420"
  },
  {
    "text": "So that is your general criteria\nat the decoder. Now what we'll doing next is\nbasically going through this",
    "start": "2647420",
    "end": "2654290"
  },
  {
    "text": "exercise to show that this\nminimum probability of error criteria is equivalent to a\nbunch of other criteria.",
    "start": "2654290",
    "end": "2662589"
  },
  {
    "text": "So the first criteria is the\nMAP criteria: Maximum A-Posteriori Rule. ",
    "start": "2662590",
    "end": "2728930"
  },
  {
    "text": "So our probability of error\nis basically --",
    "start": "2728930",
    "end": "2735109"
  },
  {
    "text": "I can track it as an integral of\nprobability of error given Y times the density function of\nY. So if I want to minimize",
    "start": "2735110",
    "end": "2749029"
  },
  {
    "text": "my probability of error, I want\nto minimize each term in this integral. So this implies I want to\nminimize probability of error",
    "start": "2749030",
    "end": "2760069"
  },
  {
    "text": "given Y for each possible\nvalue of Y. OK? ",
    "start": "2760070",
    "end": "2765370"
  },
  {
    "text": "Now what's that going to be? Well, in order to look\nat what this term is, suppose I make a decision.",
    "start": "2765370",
    "end": "2772340"
  },
  {
    "text": "I receive Y, and I decide\na symbol a_j is sent. ",
    "start": "2772340",
    "end": "2796610"
  },
  {
    "text": "Then what's the probability\nof error going to be?  My probability of error given\nY is going to be 1 minus the",
    "start": "2796610",
    "end": "2810070"
  },
  {
    "text": "probability that\nI was correct. Probability that I was correct\nis probability X equals a_j,",
    "start": "2810070",
    "end": "2815569"
  },
  {
    "text": "given Y. This follows\nfrom the definition.",
    "start": "2815570",
    "end": "2821580"
  },
  {
    "text": "So if I want to minimize my\nprobability of error given Y, I want to actually choose an\na_j that maximizes the",
    "start": "2821580",
    "end": "2827300"
  },
  {
    "text": "probability of a_j given Y. So\nthis implies, choose a_j.",
    "start": "2827300",
    "end": "2834890"
  },
  {
    "start": "2834890",
    "end": "2845859"
  },
  {
    "text": "And this is known\nas the MAP rule. ",
    "start": "2845860",
    "end": "2852110"
  },
  {
    "text": "So the idea behind the MAP rule\nis to choose the symbol in the constellation that\nmaximizes the posterior",
    "start": "2852110",
    "end": "2858690"
  },
  {
    "text": "probability, given the\nreceived symbol. Now, this MAP rule is equivalent\nto the maximum",
    "start": "2858690",
    "end": "2865410"
  },
  {
    "text": "likelihood rule, under the\nassumption that all the signal points a_j are equally likely.",
    "start": "2865410",
    "end": "2871460"
  },
  {
    "text": "The proof is not hard,\nyou just use Bayes Theorem for that. So suppose all a_j's\nare equally likely.",
    "start": "2871460",
    "end": "2885990"
  },
  {
    "text": " Then probability of a_j given\nY, which by Bayes Theorem is",
    "start": "2885990",
    "end": "2895599"
  },
  {
    "text": "the density of Y given a_j,\ntimes the probability of a_j. But since all a_j's are equally\nlikely, I will just",
    "start": "2895600",
    "end": "2902940"
  },
  {
    "text": "write it as 1 over M, over the\ndensity of Y. Now because Y is",
    "start": "2902940",
    "end": "2911849"
  },
  {
    "text": "fixed, the density of Y is\nfixed, so this quantity is just proportional to --",
    "start": "2911850",
    "end": "2917840"
  },
  {
    "text": "the proportionality symbol -- to the density of Y given a_j. ",
    "start": "2917840",
    "end": "2926430"
  },
  {
    "text": "I won't be writing all\nthe vectors, I might be missing some. But please bear with me. So this implies we want to\nchoose a_j that maximizes the",
    "start": "2926430",
    "end": "2944590"
  },
  {
    "text": "density of Y given a_j, and this\nis known as the maximum",
    "start": "2944590",
    "end": "2950450"
  },
  {
    "text": "likelihood rule. And there is one final rule. Basically if the noise is\nadditive Gaussian, then the",
    "start": "2950450",
    "end": "2958580"
  },
  {
    "text": "density of Y given a_j is\nsimply proportional to E",
    "start": "2958580",
    "end": "2964510"
  },
  {
    "text": "raised to minus the norm\nof Y minus a_j squared. So if we want to maximize this\nquantity, we want to minimize",
    "start": "2964510",
    "end": "2973400"
  },
  {
    "text": "Y minus a_j squared. So we want to choose a_j that\nminimizes the Euclidean",
    "start": "2973400",
    "end": "2988170"
  },
  {
    "text": "distance between Y minus a_j. And this is known as the minimum\ndistance decision",
    "start": "2988170",
    "end": "2994770"
  },
  {
    "text": "rule, MDD rule. Yes? AUDIENCE: We are ignoring\n[UNINTELLIGIBLE]? PROFESSOR: We are ignoring\nP value.",
    "start": "2994770",
    "end": "3000839"
  },
  {
    "text": "Because for a given Y, Py is\ngoing to be fixed for all possible choices of a_j. The goal is I'm given Y, and I\nwant to decide which signal",
    "start": "3000840",
    "end": "3008440"
  },
  {
    "text": "point was set, because that's\nthe probability of error given Y. This is my criteria now.",
    "start": "3008440",
    "end": "3016359"
  },
  {
    "text": "So Y is fixed, so the density\nof Y is fixed. AUDIENCE: [INAUDIBLE]",
    "start": "3016360",
    "end": "3022040"
  },
  {
    "text": "PROFESSOR: It's basically\ngiven by -- in order to find this density,\nwe'll just condition it on a_j, and sum up over all\npossible values of a_j.",
    "start": "3022040",
    "end": "3031416"
  },
  {
    "text": "Just take the marginal\nof Y, right? I mean, to write this\nexplicitly. I'm writing it here.",
    "start": "3031416",
    "end": "3037850"
  },
  {
    "text": "It's going to be sigma P of\nY given a_j that's the probability of a_j.",
    "start": "3037850",
    "end": "3044400"
  },
  {
    "text": "And this you can find\nby the Gaussian. AUDIENCE: But then you\nhave [INAUDIBLE].",
    "start": "3044400",
    "end": "3051500"
  },
  {
    "text": "PROFESSOR: But this is\na summation over all possible a_j's. I should write, sorry\n-- a_k's.",
    "start": "3051500",
    "end": "3057500"
  },
  {
    "text": "This is just a summation\nover all k's, right? So basically, Py is going to\nbe a mixture of several Gaussians, OK?",
    "start": "3057500",
    "end": "3064180"
  },
  {
    "text": "And it's fixed. AUDIENCE: [INAUDIBLE] PROFESSOR: Right. ",
    "start": "3064180",
    "end": "3070510"
  },
  {
    "text": "OK. So we want to choose the Minimum\nDistance Decision rule, and I should have the\nvariance of noise here.",
    "start": "3070510",
    "end": "3083170"
  },
  {
    "text": "OK, so what we have so far is\nwe started with the Minimum Probability of Error rule,\nand that's the",
    "start": "3083170",
    "end": "3088600"
  },
  {
    "text": "criteria of your decoder. Be sure this is equivalent to\nMAP rule, and that basically",
    "start": "3088600",
    "end": "3095510"
  },
  {
    "text": "comes just from the\ndefinition. This integral here, we want to\nminimize each term in the",
    "start": "3095510",
    "end": "3102560"
  },
  {
    "text": "integral, and that basically\nimplies that the Maximum A-Posteriori rule is the best. This implied Maximum Likelihood\nrule, and Maximum",
    "start": "3102560",
    "end": "3112280"
  },
  {
    "text": "Likelihood rule comes from the\nfact that all the signal points are equally likely.",
    "start": "3112280",
    "end": "3118250"
  },
  {
    "text": "And this implies, then, the\nMinimum Distance Decision rule, and that comes from the\nfact that your noise is",
    "start": "3118250",
    "end": "3125200"
  },
  {
    "text": "Additive Gaussian. So you have an exponential\nin the -- you have the Euclidean distance\nas an exponent, and",
    "start": "3125200",
    "end": "3132290"
  },
  {
    "text": "you want to minimize the\nEuclidean distance. So this is the story\nwe have so far.",
    "start": "3132290",
    "end": "3137470"
  },
  {
    "text": "And it turns out that the\nMinimum Distance Decision rule is actually quite nice, because\nit gives you a lot of",
    "start": "3137470",
    "end": "3143130"
  },
  {
    "text": "geometrical insights. So say I have three points.",
    "start": "3143130",
    "end": "3148160"
  },
  {
    "text": "We not even draw the\ncoordinates. My constellation, A, has three\npoints, and let me write them",
    "start": "3148160",
    "end": "3157180"
  },
  {
    "text": "as a1, a2, a3.  This is my constellation,\nfor example.",
    "start": "3157180",
    "end": "3163070"
  },
  {
    "text": "And say I receive a symbol Y.\nThen the job of the decoder is to figure out whether\nI sent a1, a2 or a3.",
    "start": "3163070",
    "end": "3171310"
  },
  {
    "text": "How will the decoder do that? Well, it will measure the\ndistance from all the three constellation points and\nselect the one with the",
    "start": "3171310",
    "end": "3178230"
  },
  {
    "text": "smallest Euclidean distance. More generally, what we want\nto do is we want to look at the space of all received Y\nsymbols, and partition it into",
    "start": "3178230",
    "end": "3186930"
  },
  {
    "text": "decision regions. So that if the point falls in a\ncertain decision region, we say that the constellation point\ncorresponding to that",
    "start": "3186930",
    "end": "3193490"
  },
  {
    "text": "decision region was sent. And how do I find the\ndecision region? Well, I start drawing\nhyperplanes between every two",
    "start": "3193490",
    "end": "3200680"
  },
  {
    "text": "pair of constellation points. Say I want to find the decision\nregion of point a1. I draw a hyperplane between\na1 and a3, which is",
    "start": "3200680",
    "end": "3208060"
  },
  {
    "text": "given by this line. I draw a hyperplane between\na1 and a2 which is given by this point.",
    "start": "3208060",
    "end": "3214130"
  },
  {
    "text": "And so the region -- the set of\npoints which are closer to a1 than a2 and a3 is basically\nbounded by this region here.",
    "start": "3214130",
    "end": "3223740"
  },
  {
    "text": "So this is my R1. Similarly, if I want to find a\ndecision region for a2 and a3, I will draw this line here.",
    "start": "3223740",
    "end": "3230640"
  },
  {
    "text": "This will be R2 and\nthis will be R3. So these are my decision\nregions. ",
    "start": "3230640",
    "end": "3239210"
  },
  {
    "text": "So if I want to write\nthat formally, Rj is my decision region.",
    "start": "3239210",
    "end": "3244710"
  },
  {
    "text": "And it is the set of points Y\nbelong to Rn, such that the",
    "start": "3244710",
    "end": "3250109"
  },
  {
    "text": "norm of Y minus a_j squared is\ngoing to be less than or equal",
    "start": "3250110",
    "end": "3255540"
  },
  {
    "text": "to -- it doesn't matter if you\nhave less than or equal to, because the point\n[UNINTELLIGIBLE] bound",
    "start": "3255540",
    "end": "3260550"
  },
  {
    "text": "[UNINTELLIGIBLE] probability\nzero --  is radius squared.",
    "start": "3260550",
    "end": "3266070"
  },
  {
    "text": "That's just the definition\nof Rj. Now the way to construct Rj was\nto look at all the half",
    "start": "3266070",
    "end": "3272359"
  },
  {
    "text": "planes which are closer to\nthis point than any other point, and take the\nintersection of all the half planes.",
    "start": "3272360",
    "end": "3278780"
  },
  {
    "text": "So in other words, I can\nalso write Rj to be the intersection of these\nhalf planes --",
    "start": "3278780",
    "end": "3284230"
  },
  {
    "text": "the intersections over all\npoints, j prime not equal to j -- of Rj, j prime.",
    "start": "3284230",
    "end": "3289240"
  },
  {
    "text": "So Rj, j prime is your\nhalf plane where -- ",
    "start": "3289240",
    "end": "3306460"
  },
  {
    "text": "so norm of Y minus a_j prime\nsquared is greater than or equal to norm of Y minus\na_j squared.",
    "start": "3306460",
    "end": "3314650"
  },
  {
    "text": "Note that this is a_j prime,\nand this is a_j here. OK.",
    "start": "3314650",
    "end": "3321180"
  },
  {
    "text": "So it turns out that this\ndecision region has a somewhat nice structure, because they're\nintersection of a",
    "start": "3321180",
    "end": "3326200"
  },
  {
    "text": "bunch of half planes, their\nshape is the convex polytope. ",
    "start": "3326200",
    "end": "3343290"
  },
  {
    "text": "And they're also known by the\nname Voronoi regions. ",
    "start": "3343290",
    "end": "3353680"
  },
  {
    "text": "OK, so these regions are known\nas Voronoi regions here. Now the set of points whose\nhyperplanes are active in a",
    "start": "3353680",
    "end": "3362160"
  },
  {
    "text": "certain decision region has a\nspecial name, too, and it's called the relevant subset.",
    "start": "3362160",
    "end": "3367550"
  },
  {
    "text": "So in this case, the relevant\nsubset of a1 is a2 and a3, because both of them have\nhyperplanes that are active in",
    "start": "3367550",
    "end": "3373970"
  },
  {
    "text": "the decision region of a1. So let me write that down. ",
    "start": "3373970",
    "end": "3413160"
  },
  {
    "text": "So the relevant subset is the\nset of points, a_j prime, whose hyperplanes are active\nin this decision region Rj.",
    "start": "3413160",
    "end": "3421410"
  },
  {
    "text": "There's a theorem which says\nthat the nearest neighbors are always included in the\nrelevant subset.",
    "start": "3421410",
    "end": "3426740"
  },
  {
    "text": "It's asserted in your notes.  OK?",
    "start": "3426740",
    "end": "3431810"
  },
  {
    "start": "3431810",
    "end": "3441490"
  },
  {
    "text": "So now that we have this Minimum\nDistance Decision rule, let us see if we can\nget a hang with the",
    "start": "3441490",
    "end": "3447010"
  },
  {
    "text": "probability of error. ",
    "start": "3447010",
    "end": "3503550"
  },
  {
    "text": "Let me see the probability of\nerror, given that I sent a symbol, a_j.",
    "start": "3503550",
    "end": "3509340"
  },
  {
    "text": "I want the value that\nprobability of error. That's simply the probability\nthat Y does not belong to Rj,",
    "start": "3509340",
    "end": "3518970"
  },
  {
    "text": "given that I sent\nthe symbol a_j. That's when an error happens.",
    "start": "3518970",
    "end": "3525099"
  },
  {
    "text": "That's same as probability\nthat the noise vector -- because Y is a_j plus N now --",
    "start": "3525100",
    "end": "3531359"
  },
  {
    "text": "does not belong to the Rj minus\na_j, and the noise is independent of a_j so I remove\nthe conditioning.",
    "start": "3531360",
    "end": "3540569"
  },
  {
    "text": "And that is 1 minus the\nprobability that the noise does belong to Rj minus a_j.",
    "start": "3540570",
    "end": "3548180"
  },
  {
    "text": "If I want to find this\nintegral, find this expression, I will integrate\nover the region Rj minus a_j,",
    "start": "3548180",
    "end": "3558320"
  },
  {
    "text": "of the density of\nthe noise, dN.",
    "start": "3558320",
    "end": "3564760"
  },
  {
    "text": "No note that the noise has\na spherical symmetry, but unfortunately despite that,\nthe integral is not a",
    "start": "3564760",
    "end": "3570650"
  },
  {
    "text": "straightforward integral,\nbecause this region here has sharp edges. The decision region is a convex\npolytope, so it's",
    "start": "3570650",
    "end": "3577750"
  },
  {
    "text": "typically something like this,\nand if this was your point, a_j, your noise does have a\nspherical symmetry about these",
    "start": "3577750",
    "end": "3584450"
  },
  {
    "text": "spheres, but when it intersects\nthe decision boundary, things get ugly.",
    "start": "3584450",
    "end": "3590010"
  },
  {
    "text": "And so this decision\n-- this is not a nice integral in general.",
    "start": "3590010",
    "end": "3595740"
  },
  {
    "text": " And so unfortunately, there is\nnot much progress we can make",
    "start": "3595740",
    "end": "3602510"
  },
  {
    "text": "beyond this point for the exact\nprobability of error expression, but we can say\nsome nice geometrical",
    "start": "3602510",
    "end": "3609430"
  },
  {
    "text": "properties about the probability\nof error. The first property is that\nprobability of error is",
    "start": "3609430",
    "end": "3618400"
  },
  {
    "text": "invariant to translations. ",
    "start": "3618400",
    "end": "3628890"
  },
  {
    "text": "And this should be\nquite obvious. You have, say, a constellation\nwith two points here, and say",
    "start": "3628890",
    "end": "3634750"
  },
  {
    "text": "I subtract off the mean. So I get a different\nconstellation whose points are like this.",
    "start": "3634750",
    "end": "3641240"
  },
  {
    "text": "This is my constellation,\nA, and this is my constellation, A prime. The probability of error will\nbe same for the two",
    "start": "3641240",
    "end": "3647000"
  },
  {
    "text": "constellations because the\ndecision regions will have the same distance from\nboth the points.",
    "start": "3647000",
    "end": "3653940"
  },
  {
    "text": "This should be quite obvious. And basically, what this really\nsays is if I have any",
    "start": "3653940",
    "end": "3659120"
  },
  {
    "text": "constellation, I can always\nsubtract off the mean, and get another constellation with the\nsame probability of error, but",
    "start": "3659120",
    "end": "3664740"
  },
  {
    "text": "with smaller average energy. And so this implies that any\noptimal constellation will",
    "start": "3664740",
    "end": "3681400"
  },
  {
    "text": "have zero mean. ",
    "start": "3681400",
    "end": "3689710"
  },
  {
    "text": "The second point is, the\nprobability of error is",
    "start": "3689710",
    "end": "3694849"
  },
  {
    "text": "invariant to orthonormal\nrotations.",
    "start": "3694850",
    "end": "3704570"
  },
  {
    "text": " So if I had, say, one point, one\nconstellation, with these",
    "start": "3704570",
    "end": "3713540"
  },
  {
    "text": "four points, and I rotate it by\n45 degrees, what I get is another constellation with\nthese four points.",
    "start": "3713540",
    "end": "3721180"
  },
  {
    "text": "And both these constellations\nare simply rotations of one another, and they have the same\nprobability of error.",
    "start": "3721180",
    "end": "3727059"
  },
  {
    "text": "And the easiest way to see that\nis the decision regions here are simply the\nfour quadrants.",
    "start": "3727060",
    "end": "3732290"
  },
  {
    "text": "And if I want to integrate my\nprobability of error, I will be integrating it over\nthis region.",
    "start": "3732290",
    "end": "3737380"
  },
  {
    "text": "Here, my decision regions will\nbe these 45 degree lines. And if I want to integrate the\nprobability of error for this",
    "start": "3737380",
    "end": "3744730"
  },
  {
    "text": "point here, it will be given by\nnoise, which is symmetric",
    "start": "3744730",
    "end": "3750250"
  },
  {
    "text": "about these circles. Basically, since the noise is\ninvariant to orthonormal rotations, it should be quite\nobvious that the probability",
    "start": "3750250",
    "end": "3757360"
  },
  {
    "text": "of error is invariant\nto rotations. AUDIENCE: [INAUDIBLE] PROFESSOR: Any rotation,\nright. AUDIENCE: So what do you mean\nby [UNINTELLIGIBLE]?",
    "start": "3757360",
    "end": "3765230"
  },
  {
    "text": "PROFESSOR: Basically, you're\npreserving the distance. So you're just rotating the\npoint, not scaling it.",
    "start": "3765230",
    "end": "3770440"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Unitarily. OK? I mean you will be proving these\nproperties in the next",
    "start": "3770440",
    "end": "3777260"
  },
  {
    "text": "homework, which is\njust handed out. AUDIENCE: So those\n[UNINTELLIGIBLE] hold, because Minimum Distance\nrule is orthonormal, right?",
    "start": "3777260",
    "end": "3786228"
  },
  {
    "text": "And that's because you\nassume Gaussian -- PROFESSOR: Because you assume\nGaussian noise. AUDIENCE: So that's the only\nassumption we make?",
    "start": "3786228",
    "end": "3792430"
  },
  {
    "text": "PROFESSOR: Right. AUDIENCE: -- for those\n[INAUDIBLE], right? PROFESSOR: I think so. ",
    "start": "3792430",
    "end": "3817470"
  },
  {
    "text": "AUDIENCE: Why [INAUDIBLE]\nconstellation must have zero mean? PROFESSOR: Because if I have any\nconstellation, there's a",
    "start": "3817470",
    "end": "3825082"
  },
  {
    "text": "certain probability\nof error, right? Can always subtract out the mean\nfrom the constellation, I",
    "start": "3825082",
    "end": "3830240"
  },
  {
    "text": "get a new constellation with a\nsmaller average energy with the same probability of error.",
    "start": "3830240",
    "end": "3835807"
  },
  {
    "text": "AUDIENCE: Oh, so in terms\nof [INAUDIBLE] PROFESSOR: Right. If you're looking at a trade-off\nof probability of",
    "start": "3835808",
    "end": "3841431"
  },
  {
    "text": "error versus energy, usually\nwhat we look at. ",
    "start": "3841431",
    "end": "3847070"
  },
  {
    "text": "So maybe that's a good point. I should just mention it. ",
    "start": "3847070",
    "end": "3853646"
  },
  {
    "text": "For probability of\nerror versus -- ",
    "start": "3853646",
    "end": "3858970"
  },
  {
    "text": "we're looking at this\ntrade-off here. ",
    "start": "3858970",
    "end": "3897970"
  },
  {
    "text": "Ok. The next idea is to basically\nbound the probability of error by a union bound, because we\ncannot compute an exact",
    "start": "3897970",
    "end": "3905330"
  },
  {
    "text": "expression for the probability\nof error, so we might as well compute a bound which\nis tractable.",
    "start": "3905330",
    "end": "3910540"
  },
  {
    "text": "So we'll look at what is known\nas the pairwise error",
    "start": "3910540",
    "end": "3916410"
  },
  {
    "text": "probability. ",
    "start": "3916410",
    "end": "3925450"
  },
  {
    "text": "So the idea behind pairwise\nerror probability is suppose I send a point, a_j, what is the\nprobability that instead of",
    "start": "3925450",
    "end": "3935380"
  },
  {
    "text": "a_j at the receiver, I decide\nthat a_j prime was sent.",
    "start": "3935380",
    "end": "3940910"
  },
  {
    "text": "This is the pairwise\nerror probability. So geometrically, say a_j and\na_j prime are two points here.",
    "start": "3940910",
    "end": "3950020"
  },
  {
    "text": "Let me draw some coordinate\naxis here. And say I sent point a_j, and\nthere is noise on the channel,",
    "start": "3950020",
    "end": "3956910"
  },
  {
    "text": "that takes me to this point. So this is my Y, and this\nis the noise vector.",
    "start": "3956910",
    "end": "3962670"
  },
  {
    "text": "OK? And now what I want to know is\nunder what conditions will I",
    "start": "3962670",
    "end": "3969050"
  },
  {
    "text": "decide a_j prime over a_j. What is the probability of\ndeciding a_j prime over a_j?",
    "start": "3969050",
    "end": "3975440"
  },
  {
    "text": "So let's draw a line joining\na_j prime and a_j. So how would I decide --",
    "start": "3975440",
    "end": "3981370"
  },
  {
    "text": "suppose I receive this point,\nY, and I wanted to decide between a_j and a_j prime.",
    "start": "3981370",
    "end": "3986550"
  },
  {
    "text": "What would be my\ndecision rule? AUDIENCE: [INAUDIBLE]",
    "start": "3986550",
    "end": "3991610"
  },
  {
    "text": "PROFESSOR: Uh-huh. AUDIENCE: [INAUDIBLE] ",
    "start": "3991610",
    "end": "3997980"
  },
  {
    "text": "PROFESSOR: You select -- AUDIENCE: [INAUDIBLE]\na_j prime. PROFESSOR: Exactly. An equivalent way of saying it\nis to project Y onto this",
    "start": "3997980",
    "end": "4003710"
  },
  {
    "text": "line, a_j prime minus a_j. We take two projections, one\northonormal to the line, one",
    "start": "4003710",
    "end": "4009390"
  },
  {
    "text": "along on the line, and receive\nthis projection. ",
    "start": "4009390",
    "end": "4016100"
  },
  {
    "text": "This is a straight\nline like this. Let's call it n tilde. I should change my chalk, it's\ngetting too blunt now.",
    "start": "4016100",
    "end": "4023098"
  },
  {
    "text": " This projection here is closer\nto a_j prime or a_j.",
    "start": "4023098",
    "end": "4030270"
  },
  {
    "text": "So in other words, this\nprobability of error is same as the probability that this n\ntilde, which is the projection",
    "start": "4030270",
    "end": "4038980"
  },
  {
    "text": "of Y onto a_j prime minus a_j,\nis greater than or equal to",
    "start": "4038980",
    "end": "4046380"
  },
  {
    "text": "the norm of a_j prime\nminus a_j over 2. ",
    "start": "4046380",
    "end": "4053900"
  },
  {
    "text": "OK, now why did I use the\nnotation n tilde here? Because the projection Y onto\na_j, which is this.",
    "start": "4053900",
    "end": "4060650"
  },
  {
    "text": "n tilde is same as the\nprojection of the noise onto a line joining a_j prime\nminus a_j.",
    "start": "4060650",
    "end": "4067299"
  },
  {
    "text": "So n tilde, I can write it as\nprojection of N onto a_j prime",
    "start": "4067300",
    "end": "4076140"
  },
  {
    "text": "minus a_j over the norm. ",
    "start": "4076140",
    "end": "4083920"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Sorry? AUDIENCE: Why, exactly? PROFESSOR: You can just see\ngeometrically, right?",
    "start": "4083920",
    "end": "4089170"
  },
  {
    "text": "This is a 90 degree here. This is the noise. If I project the noise, it will\nbe this component here.",
    "start": "4089170",
    "end": "4096660"
  },
  {
    "start": "4096660",
    "end": "4103660"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: All right. This should be 90, I'm sorry. This is 90.",
    "start": "4103660",
    "end": "4108670"
  },
  {
    "text": "I'm messing things up. OK, this is the noise here. This noise, if I project it onto\na_j prime minus a_j, it's",
    "start": "4108670",
    "end": "4114830"
  },
  {
    "text": "going to be this component. This is Y, if I project it,\nit's the same component.",
    "start": "4114830",
    "end": "4120799"
  },
  {
    "text": "Now, if the noise is IID with\nvariance sigma squared in each coordinate, we are simply\nprojecting the noise onto one",
    "start": "4120800",
    "end": "4129200"
  },
  {
    "text": "orthonormal vector. So n tilde is also Gaussian,\nwith zero mean",
    "start": "4129200",
    "end": "4137979"
  },
  {
    "text": "variance sigma squared. So we can use that to find this\nprobability of error.",
    "start": "4137979",
    "end": "4145330"
  },
  {
    "start": "4145330",
    "end": "4151589"
  },
  {
    "text": "So in that case, the probability\nof error -- ",
    "start": "4151590",
    "end": "4158241"
  },
  {
    "text": "I should write this -- probability of a_j prime going\nto a_j is simply probability",
    "start": "4158241",
    "end": "4166890"
  },
  {
    "text": "that this Gaussian is greater\nthan some distance, and that's Q of norm of a_j prime minus\na_j over two sigma.",
    "start": "4166890",
    "end": "4179520"
  },
  {
    "text": "Yes? AUDIENCE: What is sigma? PROFESSOR: So the noise vector\nis IID, in each of the",
    "start": "4179520",
    "end": "4187100"
  },
  {
    "text": "components, and has a variance\nof sigma squared. Sigma is basically N_0 over 2,\nif your noise is flat with --",
    "start": "4187100",
    "end": "4195099"
  },
  {
    "text": "so let me just write\nthat down, sigma squared is N_0 over 2. If you have an AWGN channel,\nand you project it on each",
    "start": "4195100",
    "end": "4201699"
  },
  {
    "text": "orthonormal signal, that's\nwhat you get. AUDIENCE: What if you project\nthe noise vector on",
    "start": "4201700",
    "end": "4207435"
  },
  {
    "text": "[INAUDIBLE] why is [INAUDIBLE]",
    "start": "4207435",
    "end": "4213380"
  },
  {
    "text": "you don't have -- PROFESSOR: So you have\na noise vector. If you have a Gaussian vector,\nand you project it onto an orthonormal basis --",
    "start": "4213380",
    "end": "4219250"
  },
  {
    "text": "AUDIENCE: Yes. But [INAUDIBLE] normal? PROFESSOR: Right. [INAUDIBLE]",
    "start": "4219250",
    "end": "4224650"
  },
  {
    "text": "We are only projecting out on\none vector which you need now. ",
    "start": "4224650",
    "end": "4230754"
  },
  {
    "text": "AUDIENCE: So then\nyou're saying -- OK, yeah. The assumption is the noise is\nsymmetric in all dimensions?",
    "start": "4230754",
    "end": "4237111"
  },
  {
    "text": "PROFESSOR: Right. ",
    "start": "4237111",
    "end": "4242500"
  },
  {
    "text": "Let's do this algebraically, so\nyou're convinced that there is no magic I'm doing here.",
    "start": "4242500",
    "end": "4250910"
  },
  {
    "text": "So we can write this as you\nsaid, as the probability that the norm of Y minus a_j squared\nis greater than norm",
    "start": "4250910",
    "end": "4260369"
  },
  {
    "text": "of Y minus a_j prime squared,\ngiven that Y [UNINTELLIGIBLE]",
    "start": "4260370",
    "end": "4266260"
  },
  {
    "text": "a_j, so Y is a_j plus\nthe noise vector. So I sub in for Y. What I get\nis probability that Y is a_j",
    "start": "4266260",
    "end": "4277179"
  },
  {
    "text": "plus N. So here I have norm of\nN squared is greater than or equal to norm of a_j plus N\nminus a_j prime squared.",
    "start": "4277180",
    "end": "4287790"
  },
  {
    "text": " And since the only random\nvariable here is this noise,",
    "start": "4287790",
    "end": "4294110"
  },
  {
    "text": "N, I can remove the conditioning\n[UNINTELLIGIBLE] down there.",
    "start": "4294110",
    "end": "4299250"
  },
  {
    "text": "Let me expand this second\nnorm term there. That's basically the norm of\na_j minus a_j prime squared",
    "start": "4299250",
    "end": "4309080"
  },
  {
    "text": "plus the norm of N squared\nminus two times the",
    "start": "4309080",
    "end": "4314340"
  },
  {
    "text": "projection of N -- or rather, the inner\nproduct of N --",
    "start": "4314340",
    "end": "4319660"
  },
  {
    "text": "and a_j prime minus a_j.  So this is the probability that\nthe inner product of N",
    "start": "4319660",
    "end": "4328560"
  },
  {
    "text": "and a_j prime minus a_j is\ngreater than or equal to norm",
    "start": "4328560",
    "end": "4336980"
  },
  {
    "text": "of a_j prime minus a_j\nsquared over 2.",
    "start": "4336980",
    "end": "4342860"
  },
  {
    "text": "If you divide by the norm of a_j\nprime minus a_j, you get the same expression as we had.",
    "start": "4342860",
    "end": "4350885"
  },
  {
    "start": "4350886",
    "end": "4358770"
  },
  {
    "text": "So it's the same thing. This was done geometrically,\nthis is done algebraically. So this is the expression of the\nprobability of error, and",
    "start": "4358770",
    "end": "4365690"
  },
  {
    "text": "this is Q of the norm of a_j\nprime minus a_j over 2 sigma.",
    "start": "4365690",
    "end": "4371006"
  },
  {
    "start": "4371006",
    "end": "4433860"
  },
  {
    "text": "So now that we have the pairwise\nerror probability, we can use it to bound\nthe probability",
    "start": "4433860",
    "end": "4439200"
  },
  {
    "text": "of error given a_j. Well by definition, the probably\nof error given a_j is",
    "start": "4439200",
    "end": "4445090"
  },
  {
    "text": "simply the probability of the\nunion of all the possible error events of the a_j goes to\na_j prime over all possible",
    "start": "4445090",
    "end": "4455910"
  },
  {
    "text": "j prime, not equal to j. This by the union bound is\nless than or equal to the",
    "start": "4455910",
    "end": "4462630"
  },
  {
    "text": "summations of the probability\nthat a_j goes to a_j prime.",
    "start": "4462630",
    "end": "4468570"
  },
  {
    "text": "That's just using union bound. And now I can sub that\nexpression over from there. ",
    "start": "4468570",
    "end": "4480010"
  },
  {
    "text": "This is the same as..So the\nsummation is over j prime not equal to j times Q of the\nnorm of a_j prime",
    "start": "4480010",
    "end": "4488710"
  },
  {
    "text": "minus a_j over 2 sigma.",
    "start": "4488710",
    "end": "4494380"
  },
  {
    "text": "Now let me write the summation\nin a different way. I'm going to write the summation\nover all possible",
    "start": "4494380",
    "end": "4499530"
  },
  {
    "text": "distances which belong to the\nset of distance, times K_D of",
    "start": "4499530",
    "end": "4505820"
  },
  {
    "text": "a_j, times Q of D\nover 2 sigma. ",
    "start": "4505820",
    "end": "4512619"
  },
  {
    "text": "Where the set D is the\nset of all possible",
    "start": "4512620",
    "end": "4523590"
  },
  {
    "text": "distances from a_j.",
    "start": "4523590",
    "end": "4530159"
  },
  {
    "text": "Ok?  And K_D of a_j is the\nnumber of points at",
    "start": "4530160",
    "end": "4545270"
  },
  {
    "text": "distance D from a_j. ",
    "start": "4545270",
    "end": "4551780"
  },
  {
    "text": "That's just a straightforward\nchange of variables.  Now if you look at this\nexpression, then Q of B over 2",
    "start": "4551780",
    "end": "4559930"
  },
  {
    "text": "sigma basically behaves like an\nexponential, for an algebra use of the argument.",
    "start": "4559930",
    "end": "4564949"
  },
  {
    "text": "So recall that Q of X is like\nhalf E to the minus X squared",
    "start": "4564950",
    "end": "4572470"
  },
  {
    "text": "over 2, for X much\nlarger than 1. So what you are really seeing\nhere is that you have a sum of",
    "start": "4572470",
    "end": "4581260"
  },
  {
    "text": "a bunch of exponentials,\neach written by this term, K_D of a_j.",
    "start": "4581260",
    "end": "4586560"
  },
  {
    "text": "Now if you think about the\nargument being large, then when you have a sum of\nexponentials, the term with",
    "start": "4586560",
    "end": "4593740"
  },
  {
    "text": "the smallest exponent will\ndominate, because they are all decreasing exponentials.",
    "start": "4593740",
    "end": "4599440"
  },
  {
    "text": "So this term can be written as\napproximately K_min of a_j",
    "start": "4599440",
    "end": "4608260"
  },
  {
    "text": "times Q of d_min over 2 sigma.",
    "start": "4608260",
    "end": "4613309"
  },
  {
    "text": " So what I am doing is I'm\nonly picking up one",
    "start": "4613310",
    "end": "4618770"
  },
  {
    "text": "term from this summation. So far, we have a strict upper\nbound here, so this summation",
    "start": "4618770",
    "end": "4625824"
  },
  {
    "text": "is a strict upper bound on the\nprobability of error given a_j, But now what I am doing is\nI'm only going to keep one",
    "start": "4625825",
    "end": "4631910"
  },
  {
    "text": "term in the summation, the term\nwhich has the smallest exponent here.",
    "start": "4631910",
    "end": "4637260"
  },
  {
    "text": "So I'm looking at the smallest\nvalue of D in this set of",
    "start": "4637260",
    "end": "4644860"
  },
  {
    "text": "possible distances from a_j. AUDIENCE: So you're\njust looking at the nearest neighbor. PROFESSOR: You're looking at\nessentially the nearest",
    "start": "4644860",
    "end": "4650490"
  },
  {
    "text": "neighbor, geometrically\nspeaking. And this approximation\nactually works",
    "start": "4650490",
    "end": "4656139"
  },
  {
    "text": "quite well in practice. It's not a bound on the\nprobability of error given a_j, but it's an\napproximation.",
    "start": "4656140",
    "end": "4664119"
  },
  {
    "text": "And why did I do this? Well, if I want to look at the\nprobability over all error,",
    "start": "4664120",
    "end": "4669812"
  },
  {
    "text": "what's that going to be? It's going to be the average\nover all possible a_j's of",
    "start": "4669812",
    "end": "4678060"
  },
  {
    "text": "probability of error\ngiven a_j. Now, so I want to take an\naverage of this quantity.",
    "start": "4678060",
    "end": "4684880"
  },
  {
    "text": "So this is a constant. So I will just take the average\nover this, and that's going to be K_min of the\nconstellation, which is the",
    "start": "4684880",
    "end": "4695719"
  },
  {
    "text": "average number of nearest\nneighbors, times Q of D_min over 2 sigma.",
    "start": "4695720",
    "end": "4701140"
  },
  {
    "text": " This is approximate here.",
    "start": "4701140",
    "end": "4707240"
  },
  {
    "text": "So this is an approximation that\nwill be used, and it's a very useful approximation,\nand it is known as",
    "start": "4707240",
    "end": "4713930"
  },
  {
    "text": "the Union Bound Estimate. ",
    "start": "4713930",
    "end": "4729140"
  },
  {
    "text": "It's no longer a bound\non the probability of error, it's an estimate. And in fact, there is a homework\nproblem where you",
    "start": "4729140",
    "end": "4736405"
  },
  {
    "text": "will be showing that the Union\nBound Estimate is in fact exact for an M-PAM\nconstellation. ",
    "start": "4736405",
    "end": "4743500"
  },
  {
    "text": "And I will let you think\nwhy that is the case. I was going to do it, but then\nI realized it's a homework problem, so you might as well\nspend some time on it.",
    "start": "4743500",
    "end": "4752610"
  },
  {
    "text": "So the last thing that I wanted\nto do today is find a lower bound on the probability\nof error. ",
    "start": "4752610",
    "end": "4769460"
  },
  {
    "text": "So if I look at probability of\nerror, it's a union of bunch of the events. AUDIENCE: [INAUDIBLE] PROFESSOR: Yes.",
    "start": "4769460",
    "end": "4774860"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] That union should be\nwith a_j prime.",
    "start": "4774860",
    "end": "4781400"
  },
  {
    "text": "PROFESSOR: The union should\nbe with a_j -- yeah. It's not what I have?",
    "start": "4781400",
    "end": "4788429"
  },
  {
    "text": "So I'm taking a union over all\npossible events, but a_j's confused with a_j prime.",
    "start": "4788430",
    "end": "4794128"
  },
  {
    "start": "4794128",
    "end": "4803590"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] a_j going to union j prime not\nequal to j, a_j prime.",
    "start": "4803590",
    "end": "4808638"
  },
  {
    "text": " PROFESSOR: Oh, I see.",
    "start": "4808638",
    "end": "4814350"
  },
  {
    "text": "AUDIENCE: I think you need\nparentheses around the -- AUDIENCE: Brackets\naround the -- AUDIENCE: [INAUDIBLE]",
    "start": "4814350",
    "end": "4820210"
  },
  {
    "text": "another set of parentheses\nbehind the event a_j going to a_j prime. Because that's the event you\nwere talking about there.",
    "start": "4820210",
    "end": "4827184"
  },
  {
    "text": "At least that's [INAUDIBLE] ",
    "start": "4827184",
    "end": "4834000"
  },
  {
    "text": "PROFESSOR: So you are\nsaying that -- AUDIENCE: Put parentheses\nafter the u. PROFESSOR: After the u. Like this?",
    "start": "4834000",
    "end": "4839780"
  },
  {
    "text": "AUDIENCE: Yeah, right. That's the event. PROFESSOR: Right. That's what I meant.",
    "start": "4839780",
    "end": "4845600"
  },
  {
    "text": "OK, fine. Fair enough. ",
    "start": "4845600",
    "end": "4853119"
  },
  {
    "text": "OK, so basically, the\nlower bound is actually quite simple. All I'm going to do\nis only take one",
    "start": "4853120",
    "end": "4858469"
  },
  {
    "text": "event from that union. I'm only going to take one\npoint, which is the minimum distance from a_j.",
    "start": "4858470",
    "end": "4864810"
  },
  {
    "text": "So probability of error given\na_j is greater than or equal",
    "start": "4864810",
    "end": "4871580"
  },
  {
    "text": "to probability that a_j goes\nto a_j prime, where now a_j",
    "start": "4871580",
    "end": "4876890"
  },
  {
    "text": "prime is the nearest\nneighbor of a_j. And this we know from PAM\nanalysis is simply Q of d_min",
    "start": "4876890",
    "end": "4885230"
  },
  {
    "text": "over 2 sigma. So this is a strict lower bound\non the probability of error, and it has the\nsame exponent as",
    "start": "4885230",
    "end": "4891960"
  },
  {
    "text": "the Union Bound Estimate. ",
    "start": "4891960",
    "end": "4907510"
  },
  {
    "text": "Of course, if I want to find\nthe overall probability of error, I can just take\nan average of this. Since this is fixed, it's going\nto be the same quantity.",
    "start": "4907510",
    "end": "4915165"
  },
  {
    "text": " So far what we have is a strict\nupper bound on the",
    "start": "4915165",
    "end": "4922100"
  },
  {
    "text": "probability of error, which is\nthis quantity here, a union bound estimate, and we have\na lower bound on the",
    "start": "4922100",
    "end": "4929599"
  },
  {
    "text": "probability of error. In the next lecture, we will be\nlooking at how to use these bounds to compute a probability\nof error for small",
    "start": "4929600",
    "end": "4937190"
  },
  {
    "text": "signal constellations, and\nquantify the performance trade-off of the probability\nof error versus the",
    "start": "4937190",
    "end": "4942280"
  },
  {
    "text": "EbN_0 and so on. I think this is a natural\npoint to stop. It's almost time now.",
    "start": "4942280",
    "end": "4947700"
  },
  {
    "start": "4947700",
    "end": "4948730"
  }
]
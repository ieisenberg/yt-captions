[
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6060"
  },
  {
    "text": "continue to offer high-quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6060",
    "end": "12690"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "12690",
    "end": "17904"
  },
  {
    "text": " DUANE BONING: OK. So today's lecture,\nin some sense",
    "start": "17904",
    "end": "24570"
  },
  {
    "text": "is actually out of sequence\nby one from Thursday, but based on when\nI was able to get",
    "start": "24570",
    "end": "30900"
  },
  {
    "text": "Dan Frey to be able to come\nin and give his lecture. This is a lecture today on\nvariance estimation, which",
    "start": "30900",
    "end": "41010"
  },
  {
    "text": "is kind of a topic that probably\nought to come after Thursday's,",
    "start": "41010",
    "end": "46469"
  },
  {
    "text": "because Thursday's is\nstill in the area of design of experiments, response surface\nmodeling, and optimization.",
    "start": "46470",
    "end": "53520"
  },
  {
    "text": "So it's kind of a nice wrap-up\nto the last three or four lectures that we've been doing.",
    "start": "53520",
    "end": "59100"
  },
  {
    "text": "So we'll come back\nto that on Thursday. But what I want to\ndo today is this idea of nested variance components.",
    "start": "59100",
    "end": "65170"
  },
  {
    "text": "And the readings\nfor this material are not in either\nof the textbooks.",
    "start": "65170",
    "end": "70560"
  },
  {
    "text": "There's a separate\nchapter that is on the website under Readings.",
    "start": "70560",
    "end": "76590"
  },
  {
    "text": "And it's chapter\n3 from this book by David Drain, Statistical\nMethods for Industrial Process",
    "start": "76590",
    "end": "82830"
  },
  {
    "text": "Control. I think he's still\nthere, I'm not sure. He's a statistician for Intel.",
    "start": "82830",
    "end": "89310"
  },
  {
    "text": "And actually, although the\ntitle doesn't indicate it, it's all about\nsemiconductor manufacturing",
    "start": "89310",
    "end": "94950"
  },
  {
    "text": "and statistical\nmethods for that. But this idea of variance\ncomponents is actually,",
    "start": "94950",
    "end": "102060"
  },
  {
    "text": "it does come up, and\nI've never actually seen it covered in any of the\nstandard statistics texts.",
    "start": "102060",
    "end": "107950"
  },
  {
    "text": "So I think it's a very\npowerful and important idea, and that's why I wanted\nto talk about it today.",
    "start": "107950",
    "end": "113310"
  },
  {
    "text": "In addition to this book as\na reading on the website, we also have spreadsheets.",
    "start": "113310",
    "end": "120539"
  },
  {
    "text": "There's a spreadsheet with\nthree different worksheets in it that are the two main examples\nout of the Drain book.",
    "start": "120540",
    "end": "127800"
  },
  {
    "text": "He just pulls up\nthe data, and then uses some statistics\npackage to pull out",
    "start": "127800",
    "end": "134129"
  },
  {
    "text": "things like the ANOVA table. I actually show\nyou the spreadsheet",
    "start": "134130",
    "end": "139620"
  },
  {
    "text": "with all the\nintermediate calculations for both analysis of\nvariance and this estimation",
    "start": "139620",
    "end": "145770"
  },
  {
    "text": "of variance components in it. So you'll find that very useful. You may find it really\nuseful as a template for some",
    "start": "145770",
    "end": "153060"
  },
  {
    "text": "of the work on the\nproblem set as well. OK, so what I want\nto do is first",
    "start": "153060",
    "end": "163170"
  },
  {
    "text": "off, refresh ourselves a little\nbit on analysis of variance. So in some sense,\nthis is actually",
    "start": "163170",
    "end": "168510"
  },
  {
    "text": "a little bit of a\nrefresher, first on ANOVA, and then deepening of our\nunderstanding, hopefully,",
    "start": "168510",
    "end": "175280"
  },
  {
    "text": "of ANOVA. So indirectly, it's a little\nbit of review for the quiz.",
    "start": "175280",
    "end": "180960"
  },
  {
    "text": "But then I want to\ntalk a little bit about a different assumption\nof the model, or the underlying",
    "start": "180960",
    "end": "187500"
  },
  {
    "text": "problem that's being\nlooked at, that leads away from standard ANOVA, towards\nthis idea of nested variance.",
    "start": "187500",
    "end": "195450"
  },
  {
    "text": "And briefly, what\nnested invariance is, is structures in which you\nmay have more than one source",
    "start": "195450",
    "end": "203219"
  },
  {
    "text": "of random variation at work. And a classic example in\nsemiconductor manufacturing",
    "start": "203220",
    "end": "210300"
  },
  {
    "text": "would be this spatial hierarchy\nof structures like chips,",
    "start": "210300",
    "end": "215820"
  },
  {
    "text": "you have 50, 100, 1000\nchips on each wafer.",
    "start": "215820",
    "end": "221130"
  },
  {
    "text": "And you may have chip-to-chip\nvariance, for example. And then you may have a certain\nnumber of wafers in a lot",
    "start": "221130",
    "end": "228990"
  },
  {
    "text": "or a boat of wafers that all are\ntypically processed together. So I might have 24\nwafers in each lot.",
    "start": "228990",
    "end": "236850"
  },
  {
    "text": "And I may have\nwafer-to-wafer variance. Similarly, I may run multiple\nlots over time in one line.",
    "start": "236850",
    "end": "245050"
  },
  {
    "text": "So I have lot-to-lot variation. And very often, you're\ngathering lots and lots",
    "start": "245050",
    "end": "251040"
  },
  {
    "text": "of data, much data. And you're trying to\nsay, OK, how much of it",
    "start": "251040",
    "end": "256109"
  },
  {
    "text": "is die-to-die variation? How much of it is\nwafer-to-wafer variation? How much lot-to-lot?",
    "start": "256110",
    "end": "261269"
  },
  {
    "text": "You want to separate out or\ndecompose the total variation that you're seeing into each\nof these different components.",
    "start": "261269",
    "end": "270330"
  },
  {
    "text": "The standard ANOVA isn't\nreally set up to do that. And that's what I'm going\nto talk about today,",
    "start": "270330",
    "end": "275880"
  },
  {
    "text": "is try to show you what\nANOVA assumes, which is looking for a fixed effect\nbetween different design",
    "start": "275880",
    "end": "286380"
  },
  {
    "text": "points, or different replicates. And then this notion\nof nested structures,",
    "start": "286380",
    "end": "292680"
  },
  {
    "text": "where you have things\nwithin other things within other things, or\ngroups within other groups within other groups.",
    "start": "292680",
    "end": "299050"
  },
  {
    "text": "And so that's the key plan. So what I want to\ndo is again, refresh",
    "start": "299050",
    "end": "304560"
  },
  {
    "text": "us a little bit\non standard ANOVA, then be fairly\nexplicit about what",
    "start": "304560",
    "end": "310050"
  },
  {
    "text": "the model is that underlies\nthese nested variance structures.",
    "start": "310050",
    "end": "316260"
  },
  {
    "text": "And then we'll actually\ngo back and work through how we extend\nthe ideas of ANOVA",
    "start": "316260",
    "end": "322660"
  },
  {
    "text": "to actually be able to estimate\nthese different variances. And then finally, there\nare some implications",
    "start": "322660",
    "end": "331150"
  },
  {
    "text": "of these variance\nstructures for how you would design experiments. So for example, if you\nwant to get the best",
    "start": "331150",
    "end": "338410"
  },
  {
    "text": "estimate possible for\nthat die-to-die variation, should you make more\ndie measurements?",
    "start": "338410",
    "end": "344350"
  },
  {
    "text": "Or should you have more\nwafer measurements? How would you allocate\na total budget",
    "start": "344350",
    "end": "351280"
  },
  {
    "text": "of measurements across that\nnested variance structure? So that's the plan.",
    "start": "351280",
    "end": "357280"
  },
  {
    "text": "And the key idea\nhere, again, is there is a big difference, an\nimportant difference that I",
    "start": "357280",
    "end": "362440"
  },
  {
    "text": "want to cover between\nthe standard ANOVA and these nested\nvariance structures.",
    "start": "362440",
    "end": "367790"
  },
  {
    "text": "So what is it in standard\nANOVA we were doing? So there was a very basic\nquestion in the standard ANOVA,",
    "start": "367790",
    "end": "377080"
  },
  {
    "text": "which is, we're basically\nasking, if I were just having",
    "start": "377080",
    "end": "383830"
  },
  {
    "text": "a single source of\nrandom variation at work, and we make, actually,\nthe assumption that we're",
    "start": "383830",
    "end": "389560"
  },
  {
    "text": "sampling from a normal\ndistribution, when I look from one\ngroup to another,",
    "start": "389560",
    "end": "394840"
  },
  {
    "text": "do I see evidence that something\nbesides just random sampling from that single normal\ndistribution is at work?",
    "start": "394840",
    "end": "405280"
  },
  {
    "text": "Is there a fixed effect\nthat is large enough",
    "start": "405280",
    "end": "411790"
  },
  {
    "text": "that I think it's more than\njust a random chance that I got",
    "start": "411790",
    "end": "417730"
  },
  {
    "text": "an observed difference\nbetween the means of a couple of different groups? And the basic\napproach mechanically",
    "start": "417730",
    "end": "423940"
  },
  {
    "text": "to do that was first off,\nwe needed some estimate of the variance of just\nthe natural variation,",
    "start": "423940",
    "end": "433300"
  },
  {
    "text": "the pure replication error. And what we basically did is\ntreated each of our treatment",
    "start": "433300",
    "end": "439360"
  },
  {
    "text": "groups, looked at\neach one, and said, OK, there's a local mean\nof that treatment group.",
    "start": "439360",
    "end": "446110"
  },
  {
    "text": "What's the replication variance\naround that local mean? I wasn't changing\nnow the parameters.",
    "start": "446110",
    "end": "452830"
  },
  {
    "text": "But for each of the ones\nwith the design fixed,",
    "start": "452830",
    "end": "458300"
  },
  {
    "text": "I just looked at replication. So that was one estimate,\nthat's our natural variation.",
    "start": "458300",
    "end": "464470"
  },
  {
    "text": "Second, we looked at the\ngroup-to-group deviations. And we said, either this\nis due to a fixed effect,",
    "start": "464470",
    "end": "474039"
  },
  {
    "text": "a systematic fixed effect that's\ndifferent between those two groups, or it's just random\nchance because of sampling.",
    "start": "474040",
    "end": "484510"
  },
  {
    "text": "And then we looked at the\nratio of those two variances, and said, by random\nchance alone, what",
    "start": "484510",
    "end": "491680"
  },
  {
    "text": "would I expect based on the\nsize of the samples, the number of data points going\ninto each of those?",
    "start": "491680",
    "end": "497800"
  },
  {
    "text": "Look at the F ratio for\nthe statistics associated",
    "start": "497800",
    "end": "503470"
  },
  {
    "text": "with that ratio\nof variance to see if it is likely to have\noccurred by chance alone.",
    "start": "503470",
    "end": "509289"
  },
  {
    "text": "All sounds familiar? You could do that in your sleep? ",
    "start": "509290",
    "end": "516080"
  },
  {
    "text": "OK. So here pictorially\nis what was going on with the ANOVA example.",
    "start": "516080",
    "end": "521299"
  },
  {
    "text": "And in fact, I think this\nwas the ANOVA example. I think that we\ndid the actual data",
    "start": "521299",
    "end": "527760"
  },
  {
    "text": "we used when we first introduced\nANOVA a few weeks ago. It's the simplest\npossible ANOVA setup",
    "start": "527760",
    "end": "535519"
  },
  {
    "text": "you could have with\nfour data points. And what's beautiful\nabout four data points is we could actually do\nthe whole calculation by hand.",
    "start": "535520",
    "end": "543690"
  },
  {
    "text": "So here was the situation. I had two different groups,\ngroup 1, group 2, the data",
    "start": "543690",
    "end": "549620"
  },
  {
    "text": "points 3 and 5, 7 and 9. And again, the basic\nidea is, we need",
    "start": "549620",
    "end": "554810"
  },
  {
    "text": "to estimate number 1, the\nwithin group variation.",
    "start": "554810",
    "end": "560330"
  },
  {
    "text": "And here we have two\ndifferent local means with two different\nestimates of variance. We pool those to get a pooled\nestimate of natural variation.",
    "start": "560330",
    "end": "571069"
  },
  {
    "text": "And then we looked\nat the between group, the deviation between the\nmeans of the two groups.",
    "start": "571070",
    "end": "578750"
  },
  {
    "text": "And we used that to estimate\na group-to-group variance.",
    "start": "578750",
    "end": "584540"
  },
  {
    "text": "And then we looked at the\nratio between those two. And we saw it in this example.",
    "start": "584540",
    "end": "591045"
  },
  {
    "text": "I can't remember, I think\nit was fairly marginal with this few data points,\nwhether it was actually,",
    "start": "591045",
    "end": "597589"
  },
  {
    "text": "in fact, statistically\nsignificant, whether this mean effect\nwas real or not, because so",
    "start": "597590",
    "end": "607970"
  },
  {
    "text": "few data points,\nit's really quite a large spread in the variances\nthat you might actually come up with by chance.",
    "start": "607970",
    "end": "615290"
  },
  {
    "text": "OK, so what I want to do is\ngo back and mathematically",
    "start": "615290",
    "end": "620600"
  },
  {
    "text": "identify what the implied models\nwere with the standard ANOVA.",
    "start": "620600",
    "end": "626779"
  },
  {
    "text": "This is kind of\npedantic here, because I",
    "start": "626780",
    "end": "631880"
  },
  {
    "text": "think we do understand this. But I'm going to\nextend this in a minute and contrast it with\nthe nested variance.",
    "start": "631880",
    "end": "639350"
  },
  {
    "text": "So I want to be\nvery, very clear. Our null hypothesis\nin ANOVA, what",
    "start": "639350",
    "end": "645350"
  },
  {
    "text": "we think is happening if\nthere's no fixed effects, is basically every\ndata point simply",
    "start": "645350",
    "end": "651050"
  },
  {
    "text": "is being drawn from\nthe same distribution.",
    "start": "651050",
    "end": "656269"
  },
  {
    "text": "And it has some fixed\nmean, and then it's got some random variation.",
    "start": "656270",
    "end": "661820"
  },
  {
    "text": "And each sample is\nbeing pulled from the same normal\ndistribution with just one underlying variance at work.",
    "start": "661820",
    "end": "669530"
  },
  {
    "text": "And recall that variance\nmight be measurement variance together with process variance,\nbut it's all identical.",
    "start": "669530",
    "end": "678509"
  },
  {
    "text": "So that's what's happening\nif there is no fixed effect. The alternative hypothesis\nthat we're looking at,",
    "start": "678510",
    "end": "686670"
  },
  {
    "text": "and we're trying to see\nis there evidence of, says basically that there\nis a fixed effect going on.",
    "start": "686670",
    "end": "697100"
  },
  {
    "text": "Now I'm going to introduce\na little bit of notation, and I actually spent\nsome time trying to do the best I could\nto make this notation",
    "start": "697100",
    "end": "704060"
  },
  {
    "text": "consistent throughout\nall of the slides today. We'll see if I succeeded\nin that, because there was",
    "start": "704060",
    "end": "710420"
  },
  {
    "text": "a lot of changes to notation. I'm going to use\nthe i subscript here",
    "start": "710420",
    "end": "716930"
  },
  {
    "text": "in this case to indicate\nwhat later we'll see is the outermost\nlevel of variance.",
    "start": "716930",
    "end": "727460"
  },
  {
    "text": "So in this simple picture,\nnow as we go through, i indicates here,\nwhich subgroup I'm in.",
    "start": "727460",
    "end": "735740"
  },
  {
    "text": "So in our simple data,\nI had two subgroups. I had group 1 and group\n2 with two data points.",
    "start": "735740",
    "end": "742319"
  },
  {
    "text": "So the i subscript here\ncould be either 1 or 2, indicating group 1 or 2.",
    "start": "742320",
    "end": "747410"
  },
  {
    "text": "And so the point is, there may\nbe a fixed offset, either t1 or t2 from the grand mean,\nas a fixed effect associated",
    "start": "747410",
    "end": "756560"
  },
  {
    "text": "with being a member\nof that group. And now the j is a subscript\nwith this funky little notation",
    "start": "756560",
    "end": "767360"
  },
  {
    "text": "down here, that indicates\nthis is data point j, the jth replicate within,\nread those parens right there,",
    "start": "767360",
    "end": "780254"
  },
  {
    "text": "within subgroup i.  So I had two replicates\nwithin each subgroup i.",
    "start": "780254",
    "end": "788810"
  },
  {
    "text": "And the simple point here is\nthat our alternative hypothesis is, there is this fixed\noffset, t1 or t2, at work,",
    "start": "788810",
    "end": "798319"
  },
  {
    "text": "in addition to the\nrandom variation. And that's what we're trying\nto look at the estimate for.",
    "start": "798320",
    "end": "805910"
  },
  {
    "text": "But this is standard ANOVA. And so there is\nstill this assumption",
    "start": "805910",
    "end": "811580"
  },
  {
    "text": "that there really is only\none random variation at work. ",
    "start": "811580",
    "end": "818810"
  },
  {
    "text": "There's only one random\nsource of variation, and then there's this\nfixed effect on top of that that's repeatable.",
    "start": "818810",
    "end": "826470"
  },
  {
    "text": "It's systematic. ",
    "start": "826470",
    "end": "833529"
  },
  {
    "text": "Now, what I'm also going to\ndo, this is a slide I added. I'm going to show a\nsimple ANOVA table.",
    "start": "833530",
    "end": "842900"
  },
  {
    "text": "This in fact, we showed\nyou earlier a few weeks ago for that very\nsimple set of data.",
    "start": "842900",
    "end": "848237"
  },
  {
    "text": "And then I'll go back\nto the previous slide, just to be very careful on some\nof the subscripts and notation that I'm using.",
    "start": "848237",
    "end": "854540"
  },
  {
    "text": "But this is essentially\nthe same data that I was talking about before. We have two groups. And within each group,\nwe had two replicates.",
    "start": "854540",
    "end": "863530"
  },
  {
    "text": "And this part up here\nis the scratch worksheet that I might use to generate our\nANOVA table down at the bottom.",
    "start": "863530",
    "end": "874449"
  },
  {
    "text": "These are the sorts\nof calculations that either your statistics\npackage would do,",
    "start": "874450",
    "end": "879850"
  },
  {
    "text": "or you would do by hand. And it includes things like\ncalculating the group average",
    "start": "879850",
    "end": "885040"
  },
  {
    "text": "for each of those two groups. Remember the average\nof 3 and 5 is 4, and the average of 7 and 9 is 8.",
    "start": "885040",
    "end": "892420"
  },
  {
    "text": "And then some additional\nsquared deviation calculations",
    "start": "892420",
    "end": "899290"
  },
  {
    "text": "that go into ultimately the\nsum of squared deviations",
    "start": "899290",
    "end": "905410"
  },
  {
    "text": "calculation that falls\ninto the sum of squares column in your table.",
    "start": "905410",
    "end": "912339"
  },
  {
    "text": "After which we divide by the\ndegrees of freedom to get these mean square estimates.",
    "start": "912340",
    "end": "918280"
  },
  {
    "text": "So I've got these little\nnotations, s sub d, s sub g, s sub e, and then sum of squared\ndeviations, sum of squared g,",
    "start": "918280",
    "end": "925370"
  },
  {
    "text": "sum of squared e. And that's what I've\ntried to detail out here what these definitions\nare, back here in slide 7.",
    "start": "925370",
    "end": "934569"
  },
  {
    "text": "So this is still intermediate\ncalculations, standard ANOVA.",
    "start": "934570",
    "end": "940135"
  },
  {
    "text": "This is still all review. But some of the calculations,\nsome of the terms",
    "start": "940135",
    "end": "945610"
  },
  {
    "text": "that go into that, with a little\nbit of this funky new notation.",
    "start": "945610",
    "end": "953690"
  },
  {
    "text": "So again, recall what we need\nto do is look at OK, what is--",
    "start": "953690",
    "end": "959950"
  },
  {
    "text": "sometimes down here. Our first thing is our\nestimate of what just",
    "start": "959950",
    "end": "965950"
  },
  {
    "text": "pure replicate error is. We're just looking for\npure replicate error.",
    "start": "965950",
    "end": "971529"
  },
  {
    "text": "And that's basically\nlooking and saying, I've got my local mean per\ngroup i, group 1 or group 2.",
    "start": "971530",
    "end": "978910"
  },
  {
    "text": "And then I've got\nthe data within that. That's just the deviation\nof that individual point from its local mean.",
    "start": "978910",
    "end": "985150"
  },
  {
    "text": "I can take the square\nof that deviation.",
    "start": "985150",
    "end": "990580"
  },
  {
    "text": "And then I take the\nsum of that over all of my data, sum of squared\ndeviations, as my ss sub e.",
    "start": "990580",
    "end": "999880"
  },
  {
    "text": "That's my sum of squared\ndeviations in all of my data from the local mean. That's not quite my\nestimate of variance.",
    "start": "999880",
    "end": "1008370"
  },
  {
    "text": "If I now take sse and divide\nit by the degrees of freedom,",
    "start": "1008370",
    "end": "1014430"
  },
  {
    "text": "that gives me my\nmean square error, which is my estimate of\nthe underlying variance.",
    "start": "1014430",
    "end": "1022110"
  },
  {
    "text": "Right? Now the other things\nthat we do, we",
    "start": "1022110",
    "end": "1027480"
  },
  {
    "text": "said the second piece here is we\nalso look at the fixed effect.",
    "start": "1027480",
    "end": "1033130"
  },
  {
    "text": "So here, we're just looking\nat the deviations of the group mean from the grand mean.",
    "start": "1033130",
    "end": "1038290"
  },
  {
    "text": "And so here's the local mean,\nand here's the grand mean. That has the double bar\nover it, if you can quite",
    "start": "1038290",
    "end": "1044760"
  },
  {
    "text": "see the notation there. And so for that, I've also\ngot a sum of squared errors",
    "start": "1044760",
    "end": "1053340"
  },
  {
    "text": "here in ssg. This is the total sum of\nsquared deviations, one",
    "start": "1053340",
    "end": "1058590"
  },
  {
    "text": "for each data point. So each data point shares\nthe same group mean. So I'll have multiple\nentries in the table.",
    "start": "1058590",
    "end": "1066060"
  },
  {
    "text": "Because if I have multiple\nreplicates, they all share the same group mean. But I'm basically\nsaying, OK, all of those",
    "start": "1066060",
    "end": "1072300"
  },
  {
    "text": "contribute to group\nmean deviations in the total\ndeviations in my data.",
    "start": "1072300",
    "end": "1079450"
  },
  {
    "text": "And then the last thing, I'm\ngoing to put a 0 by this. Because this last thing is\nsort of the total deviations",
    "start": "1079450",
    "end": "1088050"
  },
  {
    "text": "in your data from\nthe grand mean. This is just your raw sum\nof squared deviations.",
    "start": "1088050",
    "end": "1094890"
  },
  {
    "text": "So I just calculate\nmy grand mean, and I treat all of\nmy data equally, whether it's within\na group or not.",
    "start": "1094890",
    "end": "1101010"
  },
  {
    "text": "And that's just throwing all\nof my data into one big bucket, calculating a grand\nmean, and saying,",
    "start": "1101010",
    "end": "1107910"
  },
  {
    "text": "there's a total, total amount\nof sum of squared deviations in that data.",
    "start": "1107910",
    "end": "1113520"
  },
  {
    "text": "And what we want to\ndo is actually take that total amount of\ndeviations, and now divvy it up,",
    "start": "1113520",
    "end": "1120150"
  },
  {
    "text": "and say, how much of it is going\nto be because of group to group variation, and how much of\nit is pure replication data?",
    "start": "1120150",
    "end": "1127860"
  },
  {
    "text": "That's where we're\ngoing to want to get to. But in standard ANOVA,\nwhat we simply do",
    "start": "1127860",
    "end": "1134500"
  },
  {
    "text": "is remember that ssd is\nequal to the sum of the ssg",
    "start": "1134500",
    "end": "1143560"
  },
  {
    "text": "and the sum of the sse. It was in fact, sort\nof a crude attempt",
    "start": "1143560",
    "end": "1149860"
  },
  {
    "text": "at divvying up the total\nsquared deviations. But what we'll see is that\nit's actually not the right way",
    "start": "1149860",
    "end": "1156640"
  },
  {
    "text": "to get an estimate of\nthe underlying variances. And so now in this table,\nthat's all that was going on.",
    "start": "1156640",
    "end": "1166555"
  },
  {
    "text": "I just applied all\nof these formulas to get the scratchpad\nto work, and then",
    "start": "1166555",
    "end": "1172360"
  },
  {
    "text": "put that into the ANOVA table. And in this case, we saw the\ntotal sum of squared deviations",
    "start": "1172360",
    "end": "1180910"
  },
  {
    "text": "from the grand mean. We have an estimate\nthere of the mean square. We had the group to\ngroup sum of square",
    "start": "1180910",
    "end": "1188230"
  },
  {
    "text": "and the replicate\nsum of squares. We could use that\nto form an f test.",
    "start": "1188230",
    "end": "1193670"
  },
  {
    "text": "And we see that it's\nonly 89% confidence that in fact you would observe\nthat big of a ratio by chance",
    "start": "1193670",
    "end": "1202450"
  },
  {
    "text": "alone. So if I had a cutoff of 95%\nconfidence or 90% confidence with that data, I\nwould have said,",
    "start": "1202450",
    "end": "1209770"
  },
  {
    "text": "sorry, I don't have\nstrong enough evidence to say that there's\nactually a group effect. There's not a fixed\neffect here in this data.",
    "start": "1209770",
    "end": "1219220"
  },
  {
    "text": "OK? So what's wrong with that? That's all great. That's all great.",
    "start": "1219220",
    "end": "1224630"
  },
  {
    "text": "There's nothing wrong with that. But if what you're\nreally trying to do",
    "start": "1224630",
    "end": "1229779"
  },
  {
    "text": "is deal with a different\nsituation, a nested variance situation, that simple ANOVA\ncan actually lead you astray.",
    "start": "1229780",
    "end": "1239680"
  },
  {
    "text": "So now, we're actually\nshifting to a different model. But it's a model that I\nthink comes up quite a bit,",
    "start": "1239680",
    "end": "1247220"
  },
  {
    "text": "which is, instead of saying\nthere was a fixed effect, so every time I had group 1, I\nwould have a deviation t sub 1",
    "start": "1247220",
    "end": "1258040"
  },
  {
    "text": "for that group. What if every time instead,\nI had pulled another sample",
    "start": "1258040",
    "end": "1266260"
  },
  {
    "text": "that I just lumped\ntogether as group 1? Maybe it's a new wafer.",
    "start": "1266260",
    "end": "1271850"
  },
  {
    "text": "It in fact, has a\nwafer random variation, coming from a different\nsource than the replicate data",
    "start": "1271850",
    "end": "1279310"
  },
  {
    "text": "within that wafer. So in other words,\nI'm moving away from a fixed effect\ngroup to group,",
    "start": "1279310",
    "end": "1285760"
  },
  {
    "text": "to a random effect\ngroup to group. There's a different\nrandom model,",
    "start": "1285760",
    "end": "1292090"
  },
  {
    "text": "a g sub i here, which\nis not the fixed effect.",
    "start": "1292090",
    "end": "1297820"
  },
  {
    "text": "I guess we called that a t\nsub i in the previous model. But in fact, this g\nsub i is now also drawn",
    "start": "1297820",
    "end": "1305470"
  },
  {
    "text": "from a different\nrandom variation, or a different normal\ndistribution, in this case.",
    "start": "1305470",
    "end": "1311659"
  },
  {
    "text": "I have a very different model. I have a very different model. Now, what I'm really interested\nin is dealing with a situation",
    "start": "1311660",
    "end": "1321070"
  },
  {
    "text": "where there's two different\nvariances at work. I still have replication\nvariance, or the within",
    "start": "1321070",
    "end": "1328240"
  },
  {
    "text": "group variance. So imagine again, I'm pulling\nnow two different wafers.",
    "start": "1328240",
    "end": "1335350"
  },
  {
    "text": "g1 is now wafer 1,\ng2 is now wafer 2. And within that, I measure\ntwo different chips.",
    "start": "1335350",
    "end": "1342610"
  },
  {
    "text": "Now what I'm\ninterested in knowing is what the chip-to-chip\nvariance is, and what the\nwafer-to-wafer variance",
    "start": "1342610",
    "end": "1348610"
  },
  {
    "text": "is, as if it were random. So that's the key difference.",
    "start": "1348610",
    "end": "1354190"
  },
  {
    "text": "And what we want to do is\nstill be able to decide, is there something\nsignificant going on?",
    "start": "1354190",
    "end": "1360250"
  },
  {
    "text": "But really, what I\nwant to do is estimate what those variances are.",
    "start": "1360250",
    "end": "1366850"
  },
  {
    "text": "So here's the same picture. This is the same data. But now, I have a\ndifferent kind of picture.",
    "start": "1366850",
    "end": "1373270"
  },
  {
    "text": "I still need to estimate\nnumber one, which is the within group variances.",
    "start": "1373270",
    "end": "1380799"
  },
  {
    "text": "But now instead of having a\nfixed effect, what I want to do-- let me call that 2 star.",
    "start": "1380800",
    "end": "1387370"
  },
  {
    "text": "I want to attribute the\ngroup-to-group deviations that I observe as\nindications of or samples",
    "start": "1387370",
    "end": "1395410"
  },
  {
    "text": "of group-to-group variances. ",
    "start": "1395410",
    "end": "1400659"
  },
  {
    "text": "So is this setup clear? OK. So our real goal here is to\nestimate these two variances.",
    "start": "1400660",
    "end": "1411250"
  },
  {
    "text": "And by the way, point\nestimates are not going to be good enough. We actually want confidence\nintervals on these estimates.",
    "start": "1411250",
    "end": "1417980"
  },
  {
    "text": "So that's going to get\na little bit tricky. But what we would\nlike to actually do is decompose the total\nvariance we observe,",
    "start": "1417980",
    "end": "1426280"
  },
  {
    "text": "estimate what the\ntotal variance is, and decompose it into these\ntwo different sources.",
    "start": "1426280",
    "end": "1433279"
  },
  {
    "text": "So, here's our first attempt. I'll call this\nthe naive attempt. Why don't we just reuse\nall those calculations",
    "start": "1433280",
    "end": "1438880"
  },
  {
    "text": "we already had for ANOVA? Aren't they really\ntelling us the same thing? Think of it. Back in ANOVA, we were\nalready saying, OK,",
    "start": "1438880",
    "end": "1446800"
  },
  {
    "text": "under the null hypothesis,\nwe had replication variance, and we had a variance due\nto group-to-group variation.",
    "start": "1446800",
    "end": "1454490"
  },
  {
    "text": "AUDIENCE: [LAUGHS] DUANE BONING: Can't\nI just use those directly as my estimates\nof the two variances?",
    "start": "1454490",
    "end": "1460360"
  },
  {
    "text": "I had a ratio of those two. Why aren't those two\njust great estimates of those two variances?",
    "start": "1460360",
    "end": "1467150"
  },
  {
    "text": "So our naive attempt,\nour first attempt, is let's just use\nwhat we already did. Number one, we had an estimate\nof pure replication error.",
    "start": "1467150",
    "end": "1476860"
  },
  {
    "text": "Think of that as within\ngroup variance, right?",
    "start": "1476860",
    "end": "1481929"
  },
  {
    "text": "Let's just reuse that. That's our estimate of\nwithin group variance. Number two, we had this\nbetween group thing.",
    "start": "1481930",
    "end": "1490000"
  },
  {
    "text": "We had a group mean square,\ndeviation of the group means. Why not simply estimate\nthe group-to-group variance",
    "start": "1490000",
    "end": "1497679"
  },
  {
    "text": "as the mean square of\nthat group deviations?",
    "start": "1497680",
    "end": "1504370"
  },
  {
    "text": "So some squared group-to-group\ndeviations divided by the degrees of freedom. And in terms of total\nvariance, if I assume,",
    "start": "1504370",
    "end": "1513070"
  },
  {
    "text": "again, there are two\ndifferent variances at work, there is within group\nand group-to-group, and they're independent, then\nmy total variance should just",
    "start": "1513070",
    "end": "1520990"
  },
  {
    "text": "be the sum of those. Why don't I simply use that sum\nof squared deviation divided",
    "start": "1520990",
    "end": "1528010"
  },
  {
    "text": "by the degrees of freedom? It's just a total mean\nsquared deviation. Why not use that as my estimate,\njust my total variance?",
    "start": "1528010",
    "end": "1536710"
  },
  {
    "text": "Throw all my data\ninto one big bucket, calculate total variance. Isn't that my best estimate\nof the total variance",
    "start": "1536710",
    "end": "1543790"
  },
  {
    "text": "in the system? Seems natural, doesn't it? ",
    "start": "1543790",
    "end": "1551410"
  },
  {
    "text": "In fact, we can\ncalculate the grand mean, I can calculate\nthe grand variance. Isn't that a great\nestimate of total variance",
    "start": "1551410",
    "end": "1558490"
  },
  {
    "text": "in the system under this model? And well, the good news is, at\nleast something still sticks.",
    "start": "1558490",
    "end": "1568510"
  },
  {
    "text": "The within group variance\nestimate is still good. But we would be wrong,\nand I'll show you",
    "start": "1568510",
    "end": "1575320"
  },
  {
    "text": "why, in this naive\napproach, with our estimate of between group variance.",
    "start": "1575320",
    "end": "1580940"
  },
  {
    "text": "And bizarrely, we're even\nwrong on our estimate",
    "start": "1580940",
    "end": "1587019"
  },
  {
    "text": "of total variance in the system,\njust using all of our data,",
    "start": "1587020",
    "end": "1592030"
  },
  {
    "text": "undifferentiated. Yeah. AUDIENCE: Are they\nsupposed to be",
    "start": "1592030",
    "end": "1598973"
  },
  {
    "text": "[INAUDIBLE] really the sum\nof the other two [INAUDIBLE]??",
    "start": "1598973",
    "end": "1606142"
  },
  {
    "text": "DUANE BONING: So the question\nhere, for folks in Singapore, was, shouldn't the last\none be equal to the sum",
    "start": "1606142",
    "end": "1615980"
  },
  {
    "text": "of this one, a plus b? Shouldn't that equal the total?",
    "start": "1615980",
    "end": "1623810"
  },
  {
    "text": "And the answer is no. If you actually look back at\nthe ANOVA table, let me do that.",
    "start": "1623810",
    "end": "1633090"
  },
  {
    "text": "If you look back\nat the ANOVA table,",
    "start": "1633090",
    "end": "1638400"
  },
  {
    "text": "let's look at it down\nhere at the bottom. The sum of squares is the\none that is conserved.",
    "start": "1638400",
    "end": "1646860"
  },
  {
    "text": "So your total\nsquared deviations, you break apart into within\ngroup or group-to-group.",
    "start": "1646860",
    "end": "1652880"
  },
  {
    "text": "But by the time you divide\nit by degrees of freedom, the mean square or the\nvariances do not add.",
    "start": "1652880",
    "end": "1658880"
  },
  {
    "text": "And that's weird. And it turns out, in our second\nproblem, the nested variance",
    "start": "1658880",
    "end": "1666920"
  },
  {
    "text": "structure, they should add. We're saying, there is\ntwo different sources",
    "start": "1666920",
    "end": "1673190"
  },
  {
    "text": "of variance at work. There's within group\ninvariance, there's group-to-group variance,\nthey're independent.",
    "start": "1673190",
    "end": "1678510"
  },
  {
    "text": "So my total variance actually\nshould be the sum of the two. And we're going to use\nthat knowledge, actually,",
    "start": "1678510",
    "end": "1685070"
  },
  {
    "text": "to help us with\nestimating things. So in fact, your insight is\nright, not for standard ANOVA,",
    "start": "1685070",
    "end": "1693350"
  },
  {
    "text": "but it is right for the\nnested variance structure. ",
    "start": "1693350",
    "end": "1704340"
  },
  {
    "text": "Now that I've broken down your\nconfidence in using ANOVA, hopefully, and we\ncan rebuild what",
    "start": "1704340",
    "end": "1710100"
  },
  {
    "text": "it is we really want to do.  I think we've already talked\nabout this a little bit.",
    "start": "1710100",
    "end": "1717680"
  },
  {
    "text": "Again, I think that these nested\nvariance structures actually arise a lot in any\nkind of process",
    "start": "1717680",
    "end": "1724850"
  },
  {
    "text": "where there's any kind\nof batch processing at work, either in\ntime or in space.",
    "start": "1724850",
    "end": "1731820"
  },
  {
    "text": "So it's easiest, in my\nmind, maybe because I'm just mostly familiar with\nsemiconductor manufacturing,",
    "start": "1731820",
    "end": "1737420"
  },
  {
    "text": "to really see that. But I think it's much more\ngenerally true anytime I have some grouping of stuff,\nof parts, material, whatever,",
    "start": "1737420",
    "end": "1748580"
  },
  {
    "text": "that I want to look at stuff\nwithin that group, and then group-to-group, and\nmaybe then there's",
    "start": "1748580",
    "end": "1755120"
  },
  {
    "text": "a hierarchy where there's\na larger group of groups. And I want to estimate\nvariances within that.",
    "start": "1755120",
    "end": "1760775"
  },
  {
    "text": "That kind of hierarchical\nor nested structure, I think comes up all the time.",
    "start": "1760775",
    "end": "1766740"
  },
  {
    "text": "And an important point that I\nhaven't really explicitly said, but would like to\nmention here, is",
    "start": "1766740",
    "end": "1773570"
  },
  {
    "text": "that the reason we're interested\nin estimating these variances differently, is that\nvery often, physically",
    "start": "1773570",
    "end": "1782390"
  },
  {
    "text": "in the process, the source of\nthe variation at each of those",
    "start": "1782390",
    "end": "1788060"
  },
  {
    "text": "levels is actually different. It's a different\northogonal, different kind of variation source.",
    "start": "1788060",
    "end": "1794159"
  },
  {
    "text": "So for example,\nin the wafer case, the source of\nvariation chip-to-chip",
    "start": "1794160",
    "end": "1800480"
  },
  {
    "text": "may have to do with\nnon-uniformity within the tool, maybe spatial or other kinds\nof random, in many cases",
    "start": "1800480",
    "end": "1808700"
  },
  {
    "text": "even spatial\nsystematic variations. But the point is, there's\na different kind of set",
    "start": "1808700",
    "end": "1815570"
  },
  {
    "text": "of physics governing\nhow well-matched each of those chips are\nwithin one wafer.",
    "start": "1815570",
    "end": "1822770"
  },
  {
    "text": "It's a different\nsource of physics than every new wafer I put\ninto that single wafer tool,",
    "start": "1822770",
    "end": "1828290"
  },
  {
    "text": "from one time to the next. That may also have deviations\ndue to how well I can control",
    "start": "1828290",
    "end": "1836179"
  },
  {
    "text": "some of the parameters\nof that process in time from one run to the next.",
    "start": "1836180",
    "end": "1842070"
  },
  {
    "text": "So it seems very\nnatural that indeed, the variance, the underlying\nvariation in those two cases,",
    "start": "1842070",
    "end": "1850220"
  },
  {
    "text": "are different. They are orthogonal. They are in some sense,\nadditive in that sense.",
    "start": "1850220",
    "end": "1857520"
  },
  {
    "text": "They are uncorrelated. And we'll use that assumption. But there's that underlying\nassumption in here.",
    "start": "1857520",
    "end": "1864110"
  },
  {
    "text": "If, in fact, it's just\narbitrary grouping where there's only one source of\nvariation at work,",
    "start": "1864110",
    "end": "1869539"
  },
  {
    "text": "and it's just random\npulling of things to form,",
    "start": "1869540",
    "end": "1875820"
  },
  {
    "text": "in fact, different\ngroups, then that's more like the standard ANOVA. But when there's a nested\nstructure, items within items",
    "start": "1875820",
    "end": "1884120"
  },
  {
    "text": "within other items,\nusually there's a different source of\nphysics that were causing",
    "start": "1884120",
    "end": "1890240"
  },
  {
    "text": "the variation at each level. OK, so again, our\ngoal is to estimate",
    "start": "1890240",
    "end": "1895490"
  },
  {
    "text": "each of these sources of\nvariation, both point estimates and confidence intervals.",
    "start": "1895490",
    "end": "1903290"
  },
  {
    "text": "Here's some examples. I think we've already\ntalked about this. The within wafer versus\nsay, the wafer-to-wafer,",
    "start": "1903290",
    "end": "1911510"
  },
  {
    "text": "or run-to-run variability. OK, so let me build\nup a little bit",
    "start": "1911510",
    "end": "1917330"
  },
  {
    "text": "of the explicit\nmodel for this case, especially with multiple\nlayers of nesting.",
    "start": "1917330",
    "end": "1923210"
  },
  {
    "text": "We'll start without nesting. Then we'll do one\nlevel of nesting. And then working up\nto the second example,",
    "start": "1923210",
    "end": "1929600"
  },
  {
    "text": "we'll do a three-level,\ntwo levels of nesting. But we basically\nwill have points",
    "start": "1929600",
    "end": "1935179"
  },
  {
    "text": "within wafers within lots. So in fact, you can\nkeep extending that. You could have lots within\nproducts, and products",
    "start": "1935180",
    "end": "1943370"
  },
  {
    "text": "within fabs, and who knows? You could get further detailed. But here's the simplest model.",
    "start": "1943370",
    "end": "1951320"
  },
  {
    "text": "And this really is\nthe pure variance case",
    "start": "1951320",
    "end": "1957019"
  },
  {
    "text": "without any nesting at all. We basically have our\nindividual measurements,",
    "start": "1957020",
    "end": "1963650"
  },
  {
    "text": "there's an overall mean. And then there's some\nrandom variation occurring.",
    "start": "1963650",
    "end": "1969860"
  },
  {
    "text": "And here I'm indicating\nthat I'm taking multiple measurements, multiple\nsamples, multiple replicates",
    "start": "1969860",
    "end": "1976669"
  },
  {
    "text": "with this m sub i. And the point is, it's simply\na 0 mean normal distribution",
    "start": "1976670",
    "end": "1982340"
  },
  {
    "text": "with some variance. And as we've said, many of\nour assumptions still hold.",
    "start": "1982340",
    "end": "1990169"
  },
  {
    "text": "And in fact, we often make\nthese assumptions and use them,",
    "start": "1990170",
    "end": "1995930"
  },
  {
    "text": "and we have to be\ncareful in some of the spatial situations\nI've talked about, because they don't\nactually hold.",
    "start": "1995930",
    "end": "2002590"
  },
  {
    "text": "In some sense, what we're\nassuming in this case is, I'm taking multiple\nmeasurements on the same wafer. But I'm assuming randomness\nin those measurements.",
    "start": "2002590",
    "end": "2010179"
  },
  {
    "text": "I'm assuming each of those\nindividual measurements, or each of those\nindividual replicates",
    "start": "2010180",
    "end": "2015550"
  },
  {
    "text": "is IIND, identically and\nindependently distributed",
    "start": "2015550",
    "end": "2021700"
  },
  {
    "text": "from a normal distribution. That's 0 mean with all\nsharing the same variance.",
    "start": "2021700",
    "end": "2028554"
  },
  {
    "text": " And just as a precursor,\nwe'll come back to this,",
    "start": "2028555",
    "end": "2034540"
  },
  {
    "text": "actually, in one of\nthe case studies. If I have within\nwafer variation, chip-to-chip variation, and\nI have a systematic variance,",
    "start": "2034540",
    "end": "2043890"
  },
  {
    "text": "center to edge,\nmaybe it's always thinner in the middle\nof the wafer and thicker on the edge of the wafer,\nthat's a systematic effect",
    "start": "2043890",
    "end": "2051210"
  },
  {
    "text": "that this model is not\nreally good at capturing. So you've got to be careful.",
    "start": "2051210",
    "end": "2056349"
  },
  {
    "text": "This is actually a\nfairly strong assumption of random sampling within\nthat particular scenario.",
    "start": "2056350",
    "end": "2065908"
  },
  {
    "text": "OK, but this is the simple case. Now let's look at this\nvariance structure.",
    "start": "2065909",
    "end": "2071760"
  },
  {
    "text": "And here I'm using exactly the\nnotation out of Drain's book. So when you read\nDrain's chapter,",
    "start": "2071760",
    "end": "2079020"
  },
  {
    "text": "this should look\nfamiliar to you. In this case, now I've\ngot an overall mean.",
    "start": "2079020",
    "end": "2084839"
  },
  {
    "text": "And again, we've\ngot a wafer effect. It's not a fixed effect,\nit's a random effect.",
    "start": "2084840",
    "end": "2092190"
  },
  {
    "text": "Meaning every time I pull a\nnew wafer out of my samples,",
    "start": "2092190",
    "end": "2100890"
  },
  {
    "text": "all of the data points on it\nwill share the same offset.",
    "start": "2100890",
    "end": "2106109"
  },
  {
    "text": "It's an offset of w sub i. But w sub i itself, or\nwafer sub 1, or wafer sub 2,",
    "start": "2106110",
    "end": "2113580"
  },
  {
    "text": "is itself drawn from a 0\nmean normal distribution with variance sigma\nsquared sub w.",
    "start": "2113580",
    "end": "2122650"
  },
  {
    "text": "So the amount of wafer offset\nfor that particular wafer is randomly sampled.",
    "start": "2122650",
    "end": "2131970"
  },
  {
    "text": "And then within that, I\nmake multiple measurements, I make j measurements\nwithin wafer sub i.",
    "start": "2131970",
    "end": "2138360"
  },
  {
    "text": "And each of those\nindividual measurements is itself also\nrandomly distributed.",
    "start": "2138360",
    "end": "2144390"
  },
  {
    "text": "OK? So that's just repeating\nwhat our situation here was. But now, instead of\nusing that generic model,",
    "start": "2144390",
    "end": "2150930"
  },
  {
    "text": "I'm really trying to illustrate\nit with wafers and measurements within wafers. ",
    "start": "2150930",
    "end": "2158640"
  },
  {
    "text": "So if I take this basic\nformula right here,",
    "start": "2158640",
    "end": "2166359"
  },
  {
    "text": "and I basically\nask, OK, now if I want to do variance\ncalculations,",
    "start": "2166360",
    "end": "2172070"
  },
  {
    "text": "if I do a variance\non this, what is",
    "start": "2172070",
    "end": "2177710"
  },
  {
    "text": "the variance I'm going to\nobserve in my total data? ",
    "start": "2177710",
    "end": "2183410"
  },
  {
    "text": "Probably should have replicated\nthat equation right up here. We had xij is equal to mu\nplus w sub i plus m j of i.",
    "start": "2183410",
    "end": "2198619"
  },
  {
    "text": "So if I threw all of my data\ninto one big bucket, xij, and I simply calculated the\nvariance across all of my data,",
    "start": "2198620",
    "end": "2211010"
  },
  {
    "text": "what should not just\nmy data, but in fact,",
    "start": "2211010",
    "end": "2216120"
  },
  {
    "text": "if I had the total\npopulation, infinite numbers of measurement, what\nwould the variance of that be?",
    "start": "2216120",
    "end": "2224030"
  },
  {
    "text": "And we're saying that the w\nsub i and the measurements",
    "start": "2224030",
    "end": "2229250"
  },
  {
    "text": "within that are independent. So that these\nvariances add, there's no correlation between them.",
    "start": "2229250",
    "end": "2236330"
  },
  {
    "text": "The variance of a constant is 0.  We have the\nwafer-to-wafer variance,",
    "start": "2236330",
    "end": "2244940"
  },
  {
    "text": "so that's my sigma square w. And I have my\nmeasurement variance. And so my total variance,\nmy total true variance,",
    "start": "2244940",
    "end": "2254360"
  },
  {
    "text": "is simply the sum of those two\nother independent variances. And so that's your\nearlier intuition",
    "start": "2254360",
    "end": "2261170"
  },
  {
    "text": "that Nalish was talking about. So the individual variances\nare assumed to be independent.",
    "start": "2261170",
    "end": "2271020"
  },
  {
    "text": "And again, that was not\ntrue in that naive attempt. So how do we do it?",
    "start": "2271020",
    "end": "2278500"
  },
  {
    "text": "How do I use the data to\nactually get good estimates of these independent variances?",
    "start": "2278500",
    "end": "2285600"
  },
  {
    "text": "And here's the key idea. We've got sampling at work.",
    "start": "2285600",
    "end": "2291720"
  },
  {
    "text": "We've got sampling at work. ",
    "start": "2291720",
    "end": "2296849"
  },
  {
    "text": "Essentially within\nthe replicates, I've got additional\nvariances going on, because of measurement or\nreplication variance.",
    "start": "2296850",
    "end": "2306630"
  },
  {
    "text": "And that is contaminating\nor adding some noise to my estimate of the\ngroup-to-group variance.",
    "start": "2306630",
    "end": "2313920"
  },
  {
    "text": "So what we basically need\nto do is unwrap that, recognize that I've got\nmultiple samples around that,",
    "start": "2313920",
    "end": "2322590"
  },
  {
    "text": "and pull out that\nrandom variance away from our best estimate of\nthe group-to-group variance.",
    "start": "2322590",
    "end": "2329339"
  },
  {
    "text": "We need to account for the\nfact that I've got also sampling noise going on\nwhen I'm trying to estimate",
    "start": "2329340",
    "end": "2336569"
  },
  {
    "text": "the group-to-group variance. So what happens\nis, if I calculate",
    "start": "2336570",
    "end": "2342270"
  },
  {
    "text": "the wafer average observed\nvariance just from my data,",
    "start": "2342270",
    "end": "2348340"
  },
  {
    "text": "So if I observe w bar, I\nobserve wafer average 1, wafer",
    "start": "2348340",
    "end": "2354150"
  },
  {
    "text": "average 2, wafer\naverage 3, and I look at the variances of these,\nthe observed variance",
    "start": "2354150",
    "end": "2361320"
  },
  {
    "text": "in the wafer\naverages actually has the true wafer-to-wafer\nvariance in it.",
    "start": "2361320",
    "end": "2369660"
  },
  {
    "text": "But it's also got this\nsampling noise attached to it. ",
    "start": "2369660",
    "end": "2377560"
  },
  {
    "text": "And so what we want\nto do is, to get to the true variance of just\nthe wafer-to-wafer variance,",
    "start": "2377560",
    "end": "2386200"
  },
  {
    "text": "I need to subtract this\noff of the observed. So if this, now again, is\nmy observed wafer-to-wafer",
    "start": "2386200",
    "end": "2394060"
  },
  {
    "text": "average variance, I subtract\noff the sampling noise, my best estimate because of sampling.",
    "start": "2394060",
    "end": "2400450"
  },
  {
    "text": "And that gives me\nmy best estimate of the actual\nwafer-to-wafer variance. ",
    "start": "2400450",
    "end": "2407589"
  },
  {
    "text": "Now, I added a slide\nhere that actually shows a derivation of this.",
    "start": "2407590",
    "end": "2414009"
  },
  {
    "text": " But I hope, before I\ngo into the derivation,",
    "start": "2414010",
    "end": "2421140"
  },
  {
    "text": "hopefully there's\ngood intuition here. This is just the sampling\ncontamination of noise, right?",
    "start": "2421140",
    "end": "2426930"
  },
  {
    "text": "And for example, if I had a\nmillion replicate measurements,",
    "start": "2426930",
    "end": "2432930"
  },
  {
    "text": "so if m were a million,\nI would be averaging out all of those small measurements,\npure replication deviations.",
    "start": "2432930",
    "end": "2441750"
  },
  {
    "text": "There are 0 mean. So on average, this term\ngets smaller and smaller with more and more\nsampling of the wafer.",
    "start": "2441750",
    "end": "2448170"
  },
  {
    "text": "And what I would\nobserve in that case, from my wafer-to-wafer\naverage variance,",
    "start": "2448170",
    "end": "2453359"
  },
  {
    "text": "is really, really\nclose to the true one. This is only a problem\nwhen m is small.",
    "start": "2453360",
    "end": "2459480"
  },
  {
    "text": "And I've got lots of\nreplicate noise or measurement noise contaminating\nmy estimate of",
    "start": "2459480",
    "end": "2466560"
  },
  {
    "text": "the wafer-to-wafer variation. So hopefully there's some\ndegree of intuition here that makes sense.",
    "start": "2466560",
    "end": "2472650"
  },
  {
    "text": "If I actually now go in\nand do the calculation,",
    "start": "2472650",
    "end": "2478440"
  },
  {
    "text": "first off, what I said is we\nhave three or four or five",
    "start": "2478440",
    "end": "2486367"
  },
  {
    "text": "different wafers, and I have\nsome number of measurements within each wafer. And I'm simply calculating\nfor each of those wafers what",
    "start": "2486367",
    "end": "2493710"
  },
  {
    "text": "the observed average is. Up here is the formula\nfor the wafer average.",
    "start": "2493710",
    "end": "2500340"
  },
  {
    "text": "And then down here, I'm just\napplying various mathematics to that formula.",
    "start": "2500340",
    "end": "2505720"
  },
  {
    "text": "And so what's going on\nhere is, we can see,",
    "start": "2505720",
    "end": "2511320"
  },
  {
    "text": "we've got our wafer\naverage for wafer sub i, is simply 1 over the\nmeasurements for all of the j",
    "start": "2511320",
    "end": "2519210"
  },
  {
    "text": "replicates, 1 through m. We've got m replicates of\nthat within that wafer sub i.",
    "start": "2519210",
    "end": "2525870"
  },
  {
    "text": " Which I've just\nexpanded out, I just plugged in x sub i in here.",
    "start": "2525870",
    "end": "2532720"
  },
  {
    "text": "Now if I expand\nthat summation out, I've got m replicates of mu.",
    "start": "2532720",
    "end": "2539620"
  },
  {
    "text": "So that's my m mu. I've got m replicates,\nall with the same w sub i.",
    "start": "2539620",
    "end": "2545040"
  },
  {
    "text": "So that's that right there. And then I've got\nmy remaining part of my sum for my\nindividual replicates.",
    "start": "2545040",
    "end": "2551849"
  },
  {
    "text": "And just multiplying that\nout, my overall wafer average for that wafer sub i is mu\nplus the shared offset because",
    "start": "2551850",
    "end": "2560670"
  },
  {
    "text": "of the sample for\nthat particular wafer, and then all my\nmeasurement noise. And now I can apply my\nvariance to the observed,",
    "start": "2560670",
    "end": "2569700"
  },
  {
    "text": "this is the observed\nwafer-to-wafer average,",
    "start": "2569700",
    "end": "2577640"
  },
  {
    "text": "is the variance of the\nmean, which again, is 0, because that's just a constant. This is the true\nvariance, sigma w squared.",
    "start": "2577640",
    "end": "2586710"
  },
  {
    "text": "And then here, I've\ngot m replicates, all with the same variance. So I've got a constant,\nwhich gives me,",
    "start": "2586710",
    "end": "2594320"
  },
  {
    "text": "when I do my variance math,\nmy 1 constant squared, my 1 over m squared. And then the sum gives\nme m equal variances.",
    "start": "2594320",
    "end": "2602430"
  },
  {
    "text": "So that's where we get back\nto our basically 1 over m sampling variance.",
    "start": "2602430",
    "end": "2608299"
  },
  {
    "text": "So that's the derivation\ngoing on, if you actually want to see the whole detail.",
    "start": "2608300",
    "end": "2615200"
  },
  {
    "text": "But again, all that\nthat's trying to say is, if I actually look,\ngroup-to-group in the observed",
    "start": "2615200",
    "end": "2622460"
  },
  {
    "text": "means, it's got two\nthings inside of it. It's got the true\nwafer variance.",
    "start": "2622460",
    "end": "2628100"
  },
  {
    "text": "But it's also got noise. And the noise comes from\nthe underlying measurement",
    "start": "2628100",
    "end": "2633980"
  },
  {
    "text": "noise or the underlying\nreplicate noise, reduced by the factor of\nnumber of replicates I have.",
    "start": "2633980",
    "end": "2639680"
  },
  {
    "text": "My typical 1 over n\nreduction in variance. But that's what's\ncontaminating my noise.",
    "start": "2639680",
    "end": "2647580"
  },
  {
    "text": "So once I have that, there's one\nquick observation to make here.",
    "start": "2647580",
    "end": "2652820"
  },
  {
    "start": "2652820",
    "end": "2657980"
  },
  {
    "text": "Before we actually\nuse that to get back to our estimate of what the\ntrue variance is, is to go back",
    "start": "2657980",
    "end": "2664690"
  },
  {
    "text": "to the earlier point we made. We said that the total variance,\nthe true total variance",
    "start": "2664690",
    "end": "2673480"
  },
  {
    "text": "should be the independent\nsum of these two sources of other variance. But the same sampling\ncontamination also",
    "start": "2673480",
    "end": "2682119"
  },
  {
    "text": "occurs not just for what\nour observed wafer-to-wafer variance is, but if I\nwere, in fact, to actually",
    "start": "2682120",
    "end": "2690010"
  },
  {
    "text": "calculate my grand variance in\njust the data that I observed,",
    "start": "2690010",
    "end": "2696130"
  },
  {
    "text": "I took all of my data,\nthrew it into one pool, calculated a mean, and then did\nthe sum of squared deviations",
    "start": "2696130",
    "end": "2703480"
  },
  {
    "text": "of all of my data from\nthe grand mean, divided it by the number of data\npoints I had minus 1,",
    "start": "2703480",
    "end": "2710115"
  },
  {
    "text": "I used one degree of freedom\nto calculate the grand mean. So I'm just estimating the total\nvariance in all of my data.",
    "start": "2710115",
    "end": "2717040"
  },
  {
    "text": "That's the sigma\nsquared t observed. The observed total\nvariance is different,",
    "start": "2717040",
    "end": "2726550"
  },
  {
    "text": "is not equal to the actual true,\ntotal variance in my system",
    "start": "2726550",
    "end": "2735760"
  },
  {
    "text": "at work. In fact, the observed\nvariance will always",
    "start": "2735760",
    "end": "2741130"
  },
  {
    "text": "be smaller than the\nactual observed variance. And the reason is, if I look\nat the total observed variance,",
    "start": "2741130",
    "end": "2750820"
  },
  {
    "text": "oops. I think this is an error here. I think this should be a d.",
    "start": "2750820",
    "end": "2757510"
  },
  {
    "text": " That should be ss sub d.",
    "start": "2757510",
    "end": "2763789"
  },
  {
    "text": "My total sum of\nsquared deviations divided by m minus 1. I've also expanded it out into\nwhere that data is coming from.",
    "start": "2763790",
    "end": "2771329"
  },
  {
    "text": "And the point is, I've\ngot my wafer variances, I've got my\nmeasurement variances, and I've got some number of\nreplications of each of those.",
    "start": "2771330",
    "end": "2779940"
  },
  {
    "text": "And if I expand that out,\nessentially what I've got is multiple samples at work.",
    "start": "2779940",
    "end": "2787400"
  },
  {
    "text": "When I make my observed\ncalculation of total variance,",
    "start": "2787400",
    "end": "2792500"
  },
  {
    "text": "that are factors\nthat are multiplying times the true underlying\nindependent sources",
    "start": "2792500",
    "end": "2797510"
  },
  {
    "text": "of variance, but with factors\nthat are always smaller than 1. In other words, I've got m\nkinds of replications going on",
    "start": "2797510",
    "end": "2807230"
  },
  {
    "text": "with sampling from multiple\nsamples from replication. And I always get that 1 over\nand reduction in variance.",
    "start": "2807230",
    "end": "2814580"
  },
  {
    "text": "I've got that same\nthing happening, both within the\nmeasurement reduction,",
    "start": "2814580",
    "end": "2820550"
  },
  {
    "text": "and within the wafer reduction. So the simple\npoint here is, this is why that naive attempt\nto just use total variance",
    "start": "2820550",
    "end": "2831620"
  },
  {
    "text": "and use that as my estimate\nof the true independent sum",
    "start": "2831620",
    "end": "2838160"
  },
  {
    "text": "of variances at work,\nwhy that doesn't apply, why that doesn't work.",
    "start": "2838160",
    "end": "2843230"
  },
  {
    "text": " So, now we've got\na strategy here.",
    "start": "2843230",
    "end": "2851680"
  },
  {
    "text": "What we're going to do\nis number one, estimate within group variances.",
    "start": "2851680",
    "end": "2857730"
  },
  {
    "text": "That's still OK. Number two, we're going\nto see the observed",
    "start": "2857730",
    "end": "2864090"
  },
  {
    "text": "group-to-group variance, but\nthen account for sampling,",
    "start": "2864090",
    "end": "2869460"
  },
  {
    "text": "subtract off the sigma\nsquared m over m, from that,",
    "start": "2869460",
    "end": "2874530"
  },
  {
    "text": "to get our best estimate of\ntrue group-to-group variance. Now I have\ngroup-to-group variance,",
    "start": "2874530",
    "end": "2881040"
  },
  {
    "text": "I have within group\nvariance, I can add those to get my best\nestimate of total variance.",
    "start": "2881040",
    "end": "2886829"
  },
  {
    "text": "That's the strategy. So let's go back to our really\nsimple nested variance example,",
    "start": "2886830",
    "end": "2893740"
  },
  {
    "text": "and use that strategy\nnot the naive approach, but replacing the\nnaive approach and see",
    "start": "2893740",
    "end": "2900000"
  },
  {
    "text": "how the numbers come out. So again, here this was\nstep one of our strategy.",
    "start": "2900000",
    "end": "2905730"
  },
  {
    "text": "But within group variance,\nthat's still the same. The observed\ngroup-to-group variance",
    "start": "2905730",
    "end": "2915840"
  },
  {
    "text": "is simply this\nmean, which was 4, and this mean, which was 8 from\nthe grand mean, which was 6.",
    "start": "2915840",
    "end": "2925920"
  },
  {
    "text": "So each of those\ngroup-to-group deviations is 2. And that's squared,\nI've got 4 plus 4 is 8.",
    "start": "2925920",
    "end": "2935250"
  },
  {
    "text": "So that's my observed\ngroup-to-group variance. And that's actually\nthe same number that we had calculated\nusing regular ANOVA.",
    "start": "2935250",
    "end": "2943770"
  },
  {
    "text": "And then we did the\nratio between those two in order to decide if there was\nsomething significant going on.",
    "start": "2943770",
    "end": "2950980"
  },
  {
    "text": "But now the point is, that\nwas our contaminated estimate of group-to-group.",
    "start": "2950980",
    "end": "2956369"
  },
  {
    "text": "That's our observed. It may be hard to see there,\nthat's the g to g bar.",
    "start": "2956370",
    "end": "2962340"
  },
  {
    "text": "That's our group-to-group\nobserved averages. And so now we want to account\nfor the contamination,",
    "start": "2962340",
    "end": "2970529"
  },
  {
    "text": "subtract off the\nsampling effect to get to our best estimate of the\ntrue group-to-group variance.",
    "start": "2970530",
    "end": "2978900"
  },
  {
    "text": "And it's what we\nobserved, the 8. But now, using sampling to\nsubtract the true variance.",
    "start": "2978900",
    "end": "2989940"
  },
  {
    "text": "So this is our sigma\nsquared m divided by the number of measurements\nI had in each of those groups,",
    "start": "2989940",
    "end": "2996280"
  },
  {
    "text": "the sampling effect, which\nwas m equals 2, in this case. So I'm subtracting\nthat component off.",
    "start": "2996280",
    "end": "3003500"
  },
  {
    "text": "So I'm peeling that part out. And I get a best estimate now\nof the true group-to-group",
    "start": "3003500",
    "end": "3009890"
  },
  {
    "text": "variance is 7. So now I've got, within group\nis 2, group-to-group is 7.",
    "start": "3009890",
    "end": "3017600"
  },
  {
    "text": "My total is now the\nsum of those two, or 9. ",
    "start": "3017600",
    "end": "3025290"
  },
  {
    "text": "So that's different than\nwhat we had seen before. Our observed total variance,\nI can't remember what it was.",
    "start": "3025290",
    "end": "3034950"
  },
  {
    "text": "But it was smaller than that.",
    "start": "3034950",
    "end": "3040300"
  },
  {
    "text": "OK, that's pretty much\nthe core of the idea.",
    "start": "3040300",
    "end": "3045950"
  },
  {
    "text": "Let's just do a\ncouple of examples. And these are examples\nout of Drain's book.",
    "start": "3045950",
    "end": "3051589"
  },
  {
    "text": "This is the one\nstarting on page 196. So it's a little bit more data\nthan our four data points.",
    "start": "3051590",
    "end": "3058250"
  },
  {
    "text": "But the basic idea\nis still there. And this example is looking\nat the resistivity variation",
    "start": "3058250",
    "end": "3065540"
  },
  {
    "text": "across multiple wafers. So he has 6 different\nwafers, 1, 2, 3, 4, 5, and 6.",
    "start": "3065540",
    "end": "3071750"
  },
  {
    "text": "And in each case, he's making\nthree replicate measurements. So we have to be careful again.",
    "start": "3071750",
    "end": "3077090"
  },
  {
    "text": "We're assuming\nthat he's randomly sampling within the wafer to get\nreplicate measurements of the",
    "start": "3077090",
    "end": "3086120"
  },
  {
    "text": "within wafer variation. And then we're looking\nat wafer-to-wafer.",
    "start": "3086120",
    "end": "3091250"
  },
  {
    "text": "Qualitatively, before we\nstart going and applying all this machinery, what is\nthis data basically telling you,",
    "start": "3091250",
    "end": "3101870"
  },
  {
    "text": "qualitatively? And then we'll see if, in\nfact, the calculations come out with something that\nlooks consistent to that.",
    "start": "3101870",
    "end": "3109190"
  },
  {
    "text": "First off, do you\nthink the within wafer variation is bigger, or is\nthe wafer-to-wafer variation",
    "start": "3109190",
    "end": "3115860"
  },
  {
    "text": "bigger?  There's a total amount of\ndeviation in this data.",
    "start": "3115860",
    "end": "3121900"
  },
  {
    "text": "But where's the\nmain source of this? Percentage-wise, what do you\nthink the lion's share is?",
    "start": "3121900",
    "end": "3127300"
  },
  {
    "text": "AUDIENCE: You have the\nwafer-to-wafer variance. DUANE BONING: Yeah,\nit's pretty clear. There's nice clustering\nwithin each wafer.",
    "start": "3127300",
    "end": "3134920"
  },
  {
    "text": "There is some spread, we\nhave to think about that. But it looks like\nthere's perhaps bigger",
    "start": "3134920",
    "end": "3143710"
  },
  {
    "text": "wafer-to-wafer\ndeviations than there are within wafer deviations. So I'd kind of be looking to\nsee if I'm decomposing these two",
    "start": "3143710",
    "end": "3153490"
  },
  {
    "text": "sources of variance. I am expecting the\nwafer-to-wafer variance to be a little bit larger.",
    "start": "3153490",
    "end": "3160090"
  },
  {
    "text": "But I'm not completely\nsure, because they're spread within both. So I'd like to do\nthe right thing",
    "start": "3160090",
    "end": "3166510"
  },
  {
    "text": "and get good estimates\nof these two things. So Drain then goes\nthrough, and does an ANOVA.",
    "start": "3166510",
    "end": "3174880"
  },
  {
    "text": "By the way, you can still\ndo the typical ANOVA,",
    "start": "3174880",
    "end": "3180490"
  },
  {
    "text": "because in fact, a lot of\nthe intermediate calculations you reuse in doing the\nestimate of variance.",
    "start": "3180490",
    "end": "3188200"
  },
  {
    "text": "And you still want\nto ask the question, do I have evidence that\nthe wafer-to-wafer variance",
    "start": "3188200",
    "end": "3195700"
  },
  {
    "text": "is bigger than the\nwithin wafer variance? Is there group-to-group\ndeviation going on?",
    "start": "3195700",
    "end": "3201950"
  },
  {
    "text": "So the ANOVA table is still\nvalid for asking that question. And that's what he does here.",
    "start": "3201950",
    "end": "3207700"
  },
  {
    "text": "He's got total deviations\nfrom the grand mean. Remember he had 6 wafers,\n3 measurements each,",
    "start": "3207700",
    "end": "3214000"
  },
  {
    "text": "18 total measurements. So the sum of\nsquares divided by 17",
    "start": "3214000",
    "end": "3220510"
  },
  {
    "text": "is an estimate of\nobserved total variation. And then he calculates the\nwafer-to-wafer sum of squares.",
    "start": "3220510",
    "end": "3228460"
  },
  {
    "text": "He has the residual, because\nhe's got three replicates at each case. He can form the f over that\nand look at the statistics",
    "start": "3228460",
    "end": "3236920"
  },
  {
    "text": "associated with that. And that ratio, 20 times\nas much mean square",
    "start": "3236920",
    "end": "3243400"
  },
  {
    "text": "from wafer-to-wafer compared to\nwithin wafer, basically saying, that's very significant.",
    "start": "3243400",
    "end": "3249250"
  },
  {
    "text": "There is definitely a\nwafer-to-wafer effect. That's not just the\nsame as sampling",
    "start": "3249250",
    "end": "3255580"
  },
  {
    "text": "coming from within wafer. Highly significant. So this is standard ANOVA.",
    "start": "3255580",
    "end": "3263470"
  },
  {
    "text": "And then he very nicely plops\nout the variance decomposition.",
    "start": "3263470",
    "end": "3270700"
  },
  {
    "text": "The variance components. ",
    "start": "3270700",
    "end": "3276400"
  },
  {
    "text": "And notice what he's done here. Part of it is based on\ndirectly the observed results",
    "start": "3276400",
    "end": "3282390"
  },
  {
    "text": "coming directly from the ANOVA. In fact, if I were to take\nthe total sum of squares,",
    "start": "3282390",
    "end": "3289170"
  },
  {
    "text": "divide it by its\ndegree of freedoms, that is my mean square. And that's my sigma\nsquared t observed.",
    "start": "3289170",
    "end": "3299430"
  },
  {
    "text": "My wafer mean square,\nthat's sigma squared w bar.",
    "start": "3299430",
    "end": "3307109"
  },
  {
    "text": "The observed\nwafer-to-wafer variance, which was the sum\nof squares divided by its degree of freedom.",
    "start": "3307110",
    "end": "3313410"
  },
  {
    "text": "And then this is my sigma\nsquared measurement. That's my random estimates.",
    "start": "3313410",
    "end": "3320360"
  },
  {
    "text": " Notice again, these do not sum.",
    "start": "3320360",
    "end": "3326560"
  },
  {
    "text": "[LAUGHS] This is the\nnaive calculations.",
    "start": "3326560",
    "end": "3332370"
  },
  {
    "text": "You do not want to use those\nfor your variance component estimates.",
    "start": "3332370",
    "end": "3338190"
  },
  {
    "text": "In order to get\nto that, you start with number one, random\nvariation, the replicate error.",
    "start": "3338190",
    "end": "3345734"
  },
  {
    "text": "That's a good estimate. But then you unwrap to\nget your best estimate",
    "start": "3345735",
    "end": "3352380"
  },
  {
    "text": "of sigma squared wafer-to-wafer,\nby subtracting off and then",
    "start": "3352380",
    "end": "3361140"
  },
  {
    "text": "counting for the\nsampling effects. And then you sum those together\nto get sigma t squared.",
    "start": "3361140",
    "end": "3370128"
  },
  {
    "text": "And what this has done\nout here in the percent is simply now assigned a\npercentage of wafer-to-wafer",
    "start": "3370128",
    "end": "3376170"
  },
  {
    "text": "versus within wafer variance. And so in this case, about\n87% of the observed variance",
    "start": "3376170",
    "end": "3382530"
  },
  {
    "text": "is because of wafer-to-wafer. And only about 13% is\nwithin wafer variance.",
    "start": "3382530",
    "end": "3389295"
  },
  {
    "text": " Now, how did he actually\ngo and do this calculation?",
    "start": "3389295",
    "end": "3395099"
  },
  {
    "text": "Well, it's those\nformulas that I gave you. Or he says, run SAC\nPROC NESTED in SAS.",
    "start": "3395100",
    "end": "3402990"
  },
  {
    "text": " That's all he gives you.",
    "start": "3402990",
    "end": "3408130"
  },
  {
    "text": "OK? So what I tried to do\nis in that spreadsheet that I posted on the\nwebsite, is actually",
    "start": "3408130",
    "end": "3415940"
  },
  {
    "text": "go in and do the\ncalculations that you need in order to get to\nthose variance components,",
    "start": "3415940",
    "end": "3423800"
  },
  {
    "text": "for this example. And it's basically just applying\nall these formulas and concepts",
    "start": "3423800",
    "end": "3429920"
  },
  {
    "text": "that we've already\nbeen talking about. The tricky piece is actually\nappropriately counting",
    "start": "3429920",
    "end": "3437300"
  },
  {
    "text": "for sampling effects. How many samples go\ninto the denominator",
    "start": "3437300",
    "end": "3443990"
  },
  {
    "text": "to subtract off the sampling\neffect, the sigma squared over m? It's pretty easy in\nthe two-level case.",
    "start": "3443990",
    "end": "3451160"
  },
  {
    "text": "But now when I have measurements\nwithin wafers within lots, I've got two levels\nof sampling going on.",
    "start": "3451160",
    "end": "3458150"
  },
  {
    "text": "And I got to know\nwhat factors to use. It's not just sigma\nsquared over m.",
    "start": "3458150",
    "end": "3464059"
  },
  {
    "text": "We'll see in a moment,\nit's sigma squared of something divided by m\ntimes the number of wafers.",
    "start": "3464060",
    "end": "3470090"
  },
  {
    "text": "And my spreadsheets try to help\nkeep careful track of that. In the one-level case,\nit's pretty easy.",
    "start": "3470090",
    "end": "3476480"
  },
  {
    "text": "Let me get to two\nlevels in just a second.",
    "start": "3476480",
    "end": "3481500"
  },
  {
    "text": "But the other thing that\nessentially Drain's book just pulls out of the air is the\ninterval estimates, again based",
    "start": "3481500",
    "end": "3489650"
  },
  {
    "text": "on SAC PROC NESTED.  And there's no help at all\nin terms of where you come up",
    "start": "3489650",
    "end": "3499730"
  },
  {
    "text": "with interval estimates. So basically, my\nbest recommendation",
    "start": "3499730",
    "end": "3506270"
  },
  {
    "text": "is simply use our concept\nof chi-squared distributions",
    "start": "3506270",
    "end": "3513550"
  },
  {
    "text": "with the appropriate estimate\nof the number of degrees",
    "start": "3513550",
    "end": "3518800"
  },
  {
    "text": "of freedom or the\nnumber of data points going into the estimate\nof that variance piece.",
    "start": "3518800",
    "end": "3526960"
  },
  {
    "text": "And my spreadsheet also\nshows some of that for you. By the way, if you\nactually do that,",
    "start": "3526960",
    "end": "3533170"
  },
  {
    "text": "it turns out that\nthe book claims for the total variance and the\nwafer variance and the error",
    "start": "3533170",
    "end": "3541390"
  },
  {
    "text": "variances, that those are\n95% confidence intervals. But I think those are actually\n90% confidence intervals",
    "start": "3541390",
    "end": "3550029"
  },
  {
    "text": "if you do the calculation\nwith the chi-squared formula down here.",
    "start": "3550030",
    "end": "3556960"
  },
  {
    "text": "So I'm actually not sure exactly\nwhat's going into his tables.",
    "start": "3556960",
    "end": "3562660"
  },
  {
    "text": "I get slightly\ndifferent answers. But I think the best\nconservative estimate,",
    "start": "3562660",
    "end": "3569140"
  },
  {
    "text": "which may have a slight\namount of extra overcounting of variance, but it's a slightly\nlarger confidence interval.",
    "start": "3569140",
    "end": "3578560"
  },
  {
    "text": "That is to say\nit's conservative, you're not fooling yourself,\nand thinking things",
    "start": "3578560",
    "end": "3583750"
  },
  {
    "text": "are significant\nwhen they're not, is simply use the\nchi-squared distribution.",
    "start": "3583750",
    "end": "3590770"
  },
  {
    "text": "And so that's what my\nbest recommendation for the interval estimates are.",
    "start": "3590770",
    "end": "3597730"
  },
  {
    "text": " OK, so we're pretty\ncomfortable with two levels?",
    "start": "3597730",
    "end": "3604410"
  },
  {
    "text": "Let's do three levels. Great fun. It's the same idea. But now I have, not only\nmeasurements within wafers.",
    "start": "3604410",
    "end": "3614820"
  },
  {
    "text": "I have wafers within lots. So I may have a random\nlot-to-lot effect.",
    "start": "3614820",
    "end": "3621390"
  },
  {
    "text": "So I pull 24 wafers, I\ndo lots of processing. I pull another 24 wafers,\nI do some processing.",
    "start": "3621390",
    "end": "3627390"
  },
  {
    "text": "There is a lot average that may\nbe different from another lot average, from different\nfrom another lot",
    "start": "3627390",
    "end": "3633570"
  },
  {
    "text": "average, because there's a\nlot-to-lot variance at work,",
    "start": "3633570",
    "end": "3638620"
  },
  {
    "text": "in addition now. OK? So this is two\nlevels of nesting,",
    "start": "3638620",
    "end": "3643650"
  },
  {
    "text": "or a three-level\nvariance structure. Now what happens with the\nobserved lot-to-lot variance?",
    "start": "3643650",
    "end": "3654349"
  },
  {
    "text": "It's the same idea. But now we've got multiple\nlevels of sampling going on.",
    "start": "3654350",
    "end": "3661190"
  },
  {
    "text": "You may not be able to see\nit, but over that l right here, there is a bar.",
    "start": "3661190",
    "end": "3666590"
  },
  {
    "text": "Again, this is\nsigma squared l bar. The observed\nlot-to-lot variation.",
    "start": "3666590",
    "end": "3673940"
  },
  {
    "text": "And what it's got in it is\nthe true lot-to-lot variance. But it's also got wafer-to-wafer\nvariance noise added onto it.",
    "start": "3673940",
    "end": "3685170"
  },
  {
    "text": "And then on top\nof that, it's also got replication within wafer\nvariance noise added onto it.",
    "start": "3685170",
    "end": "3693110"
  },
  {
    "text": "Now, the good thing is,\nI've got multiple wafers. Say I've got 24\nwafers in each lot.",
    "start": "3693110",
    "end": "3700250"
  },
  {
    "text": "So the effect of the 24\nwafer-to-wafer variance noise",
    "start": "3700250",
    "end": "3706520"
  },
  {
    "text": "gets reduced by my factor\nof w of equal to 24.",
    "start": "3706520",
    "end": "3711710"
  },
  {
    "text": "And similarly, also, within\neach of those wafers, I may have 10 measurements.",
    "start": "3711710",
    "end": "3717780"
  },
  {
    "text": "And that noise is\nmultiplicatively averaged out.",
    "start": "3717780",
    "end": "3723990"
  },
  {
    "text": "I've got a factor of the number\nof measurements, say it's 10, and number of wafers\nin a lot, would say",
    "start": "3723990",
    "end": "3730340"
  },
  {
    "text": "it was 24 wafers in each lot. That's an awful lot of\ndata of measurement noise",
    "start": "3730340",
    "end": "3737030"
  },
  {
    "text": "that has lots of chances\nwith a big denominator here to average out.",
    "start": "3737030",
    "end": "3742370"
  },
  {
    "text": "So that factor starts to\nget smaller fairly rapidly. The lowest levels start\nto become smaller.",
    "start": "3742370",
    "end": "3751550"
  },
  {
    "text": "But the basic strategy\nis going to be the same. A phrase I've heard, or\nmaybe Drain uses, is,",
    "start": "3751550",
    "end": "3760010"
  },
  {
    "text": "what we want to do is estimate\nthe individual variance components, three\nlevels, but think of it",
    "start": "3760010",
    "end": "3768170"
  },
  {
    "text": "as peeling the onion\nfrom the inside out. ",
    "start": "3768170",
    "end": "3775300"
  },
  {
    "text": "I'm confident at the innermost\nlevel of the variance of measurements.",
    "start": "3775300",
    "end": "3781180"
  },
  {
    "text": "Once I have that, I have\nthe observed wafer-to-wafer variance, and I could\nsubtract the sampling out.",
    "start": "3781180",
    "end": "3786640"
  },
  {
    "text": "So now I have the\nnext inner level of the onion, a good\nestimate for that.",
    "start": "3786640",
    "end": "3792040"
  },
  {
    "text": "Using that, I can\nsubtract out that sampling from the outermost level\nof observed variances.",
    "start": "3792040",
    "end": "3799430"
  },
  {
    "text": "So it's the same strategy,\nwe work from the inside out to get estimates of the\nouter levels of variance.",
    "start": "3799430",
    "end": "3808450"
  },
  {
    "text": "Yeah. AUDIENCE: This one\ngives a different answer if you do two wafers\nand three measurements or three wafers and\ntwo measurements.",
    "start": "3808450",
    "end": "3815323"
  },
  {
    "text": "DUANE BONING: Absolutely. AUDIENCE: It's saying\nthere's a better way of doing things,\nlike [INAUDIBLE] wafer",
    "start": "3815323",
    "end": "3823405"
  },
  {
    "text": "with fewer measurements. ",
    "start": "3823405",
    "end": "3829530"
  },
  {
    "text": "DUANE BONING: Absolutely. So what Nalish is\nsaying here is, you can imagine you will\nget different answers if I",
    "start": "3829530",
    "end": "3838580"
  },
  {
    "text": "had two measurements on each of\n3 wafers, 6 total measurements, for example.",
    "start": "3838580",
    "end": "3843870"
  },
  {
    "text": "Or if I took those\nsame 6 measurements and I did 3 measurements\non only 2 wafers.",
    "start": "3843870",
    "end": "3849590"
  },
  {
    "text": "Those denominators\nare different. And your precision of your\nestimates will be different.",
    "start": "3849590",
    "end": "3856339"
  },
  {
    "text": "Both your point estimates\nmay be slightly different.",
    "start": "3856340",
    "end": "3861470"
  },
  {
    "text": "But also your\nconfidence intervals will be different, because in\nessence, the amount of noise",
    "start": "3861470",
    "end": "3868280"
  },
  {
    "text": "is going differently\nin the two cases, and the number of\nsamples is going.",
    "start": "3868280",
    "end": "3873829"
  },
  {
    "text": "So that's jumping ahead\nabout two more slides, but it's exactly\nthe point that this",
    "start": "3873830",
    "end": "3880070"
  },
  {
    "text": "does have an important\nimplication on sampling. How you construct\nyour sampling plan,",
    "start": "3880070",
    "end": "3886250"
  },
  {
    "text": "how you allocate your\ntotal measurement budget and total replication\nbudget, depending",
    "start": "3886250",
    "end": "3891890"
  },
  {
    "text": "on which variance maybe you want\nto estimate most accurately. ",
    "start": "3891890",
    "end": "3901300"
  },
  {
    "text": "Let me just\nqualitatively show you the results here for the\nthree-level example in Drain.",
    "start": "3901300",
    "end": "3909520"
  },
  {
    "text": "This is building on\nthe two-level example, so we're still looking\nat sheet resistance. We now have 3 wafers\nwithin each lot.",
    "start": "3909520",
    "end": "3919420"
  },
  {
    "text": "So this is lot 1, lot 2,\nall the way up to 11 lots.",
    "start": "3919420",
    "end": "3924940"
  },
  {
    "text": "And then within each lot,\nthe two little triangles here, we're taking two\nmeasurements within each wafer.",
    "start": "3924940",
    "end": "3931410"
  },
  {
    "text": "Now qualitatively, what do you\nthink is the biggest source",
    "start": "3931410",
    "end": "3938530"
  },
  {
    "text": "of invariance in this data? ",
    "start": "3938530",
    "end": "3947420"
  },
  {
    "text": "Is it within wafer,\nwafer-to-wafer, or lot-to-lot? ",
    "start": "3947420",
    "end": "3955686"
  },
  {
    "text": "AUDIENCE: Wafer-to-wafer. DUANE BONING: Yeah. So I hear a vote, and I\nkind of concur with it,",
    "start": "3955686",
    "end": "3961369"
  },
  {
    "text": "wafer-to-wafer looks pretty big. So for example,\nhere's wafer-to-wafer,",
    "start": "3961370",
    "end": "3967820"
  },
  {
    "text": "another wafer-to-wafer. Within wafer, it's\npretty nicely clustered. So I don't expect a big\nwithin-wafer variance.",
    "start": "3967820",
    "end": "3976100"
  },
  {
    "text": "Lot-to-lot's a\nlittle harder to see, because I have to\naverage these 3 wafers. But it looks like there is\nsome lot-to-lot variations.",
    "start": "3976100",
    "end": "3987140"
  },
  {
    "text": "But it looks a\nlittle bit smaller. So it looks to me like sigma\nsquared wafer is bigger",
    "start": "3987140",
    "end": "3995510"
  },
  {
    "text": "than sigma squared\nlot, which is bigger than sigma squared measurement.",
    "start": "3995510",
    "end": "4001250"
  },
  {
    "text": "So let's see if that comes out\nof our variance components. ",
    "start": "4001250",
    "end": "4008030"
  },
  {
    "text": "I've given you also\nthis giant spreadsheet table with all of that data. And again, the estimates.",
    "start": "4008030",
    "end": "4013730"
  },
  {
    "text": "There's again, the\nstandard ANOVA, and then the splitting out into\nthe variance components.",
    "start": "4013730",
    "end": "4019369"
  },
  {
    "text": "In the standard ANOVA, you\ncan actually ask the question,",
    "start": "4019370",
    "end": "4030470"
  },
  {
    "text": "is there statistical evidence\nfor wafer-to-wafer variation? So it's basically, that\nratio right there is 62.",
    "start": "4030470",
    "end": "4038180"
  },
  {
    "text": "And it's highly unlikely\nthat that's by chance alone.",
    "start": "4038180",
    "end": "4044030"
  },
  {
    "text": "He also does, is there evidence\nfor lot-to-lot variance?",
    "start": "4044030",
    "end": "4049460"
  },
  {
    "text": "And in the standard ANOVA,\nit looks pretty weak. Given the amount of\nwafer-to-wafer variance,",
    "start": "4049460",
    "end": "4056339"
  },
  {
    "text": "the ANOVA table is\nsaying, what you may be observing for your\nlot-to-lot deviations,",
    "start": "4056340",
    "end": "4063660"
  },
  {
    "text": "is because there's big\nwafer-to-wafer variation. It may not be a significant\nlot-to-lot variance.",
    "start": "4063660",
    "end": "4072120"
  },
  {
    "text": " So that's interesting. Let's come back to\nthat in a second.",
    "start": "4072120",
    "end": "4078160"
  },
  {
    "text": "Oops. Now we can go in, this is\njust the ANOVA mean squares. But then you do this\nunwrapping of the variance,",
    "start": "4078160",
    "end": "4085140"
  },
  {
    "text": "accounting for sampling. And what he observes is, the\npure replication variance",
    "start": "4085140",
    "end": "4090210"
  },
  {
    "text": "is pretty small. The wafer invariance\nis pretty large. There's a small remaining\nlot-to-lot point",
    "start": "4090210",
    "end": "4097770"
  },
  {
    "text": "estimate of variance. And then we have\nour total variance. So if I decompose that,\nit looks like about 89%",
    "start": "4097770",
    "end": "4105659"
  },
  {
    "text": "is wafer-to-wafer, 3% is within\nwafer, very small within wafer.",
    "start": "4105660",
    "end": "4111600"
  },
  {
    "text": "And here at this\npoint estimate is 8% of the variance,\nthat's my best guess.",
    "start": "4111600",
    "end": "4117979"
  },
  {
    "text": "8% of the variance\nis coming from separate lot-to-lot variance.",
    "start": "4117979",
    "end": "4123120"
  },
  {
    "text": "That's point estimates. There's something\nnagging me here about this ANOVA observation.",
    "start": "4123120",
    "end": "4130739"
  },
  {
    "text": "That lot-to-lot variance\nwasn't significant. What if we looked at the\nconfidence intervals?",
    "start": "4130740",
    "end": "4137939"
  },
  {
    "text": "This now looks at the\ninterval estimates. And what we see here is,\nhere's our point estimate",
    "start": "4137939",
    "end": "4143700"
  },
  {
    "text": "for the replication. And it's got a range\nfrom 1 to about 3.",
    "start": "4143700",
    "end": "4150479"
  },
  {
    "text": "Not too bad of a range for that. My wafer variance, I had\nabout 56 as my point estimate.",
    "start": "4150479",
    "end": "4157859"
  },
  {
    "text": "And that, based on the numbers\nof samples and everything that I've got, might\nrange from 33 to 113.",
    "start": "4157859",
    "end": "4166350"
  },
  {
    "text": "And here's the\ninteresting thing. If we do that point estimate\nfor our lot variance,",
    "start": "4166350",
    "end": "4172470"
  },
  {
    "text": "but actually look at the\nchi-squared or it's again, this weird, slightly something\ndifferent than chi-squared",
    "start": "4172470",
    "end": "4179339"
  },
  {
    "text": "but very close to it. What you get in this case is a\nnegative estimate for the lower",
    "start": "4179340",
    "end": "4186240"
  },
  {
    "text": "limit of lot variance.  Woohoo.",
    "start": "4186240",
    "end": "4191509"
  },
  {
    "text": "When a confidence interval\nintersects 0, that tells you it might be 0.",
    "start": "4191510",
    "end": "4197929"
  },
  {
    "text": "So in fact, we would set\nthe lower bound to 0. If I still needed my\nbest point estimate,",
    "start": "4197930",
    "end": "4203150"
  },
  {
    "text": "I would still stick with the 5. But this is basically telling\nme, consistent with the ANOVA,",
    "start": "4203150",
    "end": "4209630"
  },
  {
    "text": "that I don't have more than\n95% confidence that there's",
    "start": "4209630",
    "end": "4217880"
  },
  {
    "text": "a non-zero lot-to-lot\nvariance at work. ",
    "start": "4217880",
    "end": "4224330"
  },
  {
    "text": "And in fact, if I wanted\nto, I might go back",
    "start": "4224330",
    "end": "4229340"
  },
  {
    "text": "and say, I'm going to set\nand assume in a new model",
    "start": "4229340",
    "end": "4235670"
  },
  {
    "text": "that the lot-to-lot\nvariance is 0. And I'm going to attribute\nthat, lump that together",
    "start": "4235670",
    "end": "4241550"
  },
  {
    "text": "with the wafer-to-wafer,\nand build just a two-level\nnested invariance where I don't include that as\na separate variance source.",
    "start": "4241550",
    "end": "4249349"
  },
  {
    "text": "Since it wasn't\nsignificant, you might not want to include\nthat in your model.",
    "start": "4249350",
    "end": "4254460"
  },
  {
    "text": "Is there a question? AUDIENCE: Yes. So for this analysis,\nwhat's the degree",
    "start": "4254460",
    "end": "4260820"
  },
  {
    "text": "of freedom that you're going\nto use in the chi-square? DUANE BONING: Yeah. It's a little bit tricky,\nbut it's in the spreadsheet.",
    "start": "4260820",
    "end": "4268260"
  },
  {
    "text": "Basically, what you do is if\nyou look at the denominator",
    "start": "4268260",
    "end": "4275519"
  },
  {
    "text": "when you take the\nsampling effect, so it might be m times\nw, or m times w minus 1,",
    "start": "4275520",
    "end": "4283830"
  },
  {
    "text": "because I have a grand mean. When I'm doing that for\nthe lot-to-lot variance,",
    "start": "4283830",
    "end": "4289380"
  },
  {
    "text": "that would be my\ndegree of freedom. So the degree of\nfreedom that you use, the n minus 1 in\nthe chi-squared,",
    "start": "4289380",
    "end": "4296190"
  },
  {
    "text": "changes depending on which\nvariance you're estimating, which variance interval.",
    "start": "4296190",
    "end": "4301290"
  },
  {
    "text": "And I actually have\nboth the definitions with the variable names\nin the spreadsheet,",
    "start": "4301290",
    "end": "4306739"
  },
  {
    "text": "and then what the numbers\nare for this data. So that is tricky.",
    "start": "4306740",
    "end": "4312690"
  },
  {
    "text": "But it basically, is anytime\nyou're estimating a variance,",
    "start": "4312690",
    "end": "4318810"
  },
  {
    "text": "you have a sum of\nsquared deviations. And then you take\nthe mean square. What's going down\nin the denominator",
    "start": "4318810",
    "end": "4324780"
  },
  {
    "text": "in the mean square\nestimate, that's what you're using for\nthe degree of freedom.",
    "start": "4324780",
    "end": "4329800"
  },
  {
    "text": "AUDIENCE: Are they still\nthe same as ANOVA analysis? DUANE BONING: Not quite.",
    "start": "4329800",
    "end": "4337110"
  },
  {
    "text": "Where they're really based\nis based on these things. ",
    "start": "4337110",
    "end": "4344930"
  },
  {
    "text": "So you'll see that\nin the spreadsheet. So the last point\nI wanted to make",
    "start": "4344930",
    "end": "4355112"
  },
  {
    "text": "has to do with, we've already\ntalked about this a little bit, how you allocate the\nmeasurement budget.",
    "start": "4355112",
    "end": "4361039"
  },
  {
    "text": "And the simple observation is,\nwhen you're out in outer level, if I'm trying to estimate\nthe lot-to-lot variance,",
    "start": "4361040",
    "end": "4369380"
  },
  {
    "text": "what most strongly affects that? And it's basically the data\nin the outermost level,",
    "start": "4369380",
    "end": "4375170"
  },
  {
    "text": "because the variance component\nof the innermost level gets averaged away\nfairly quickly. ",
    "start": "4375170",
    "end": "4383090"
  },
  {
    "text": "So the contamination\nof measurement variance",
    "start": "4383090",
    "end": "4389360"
  },
  {
    "text": "can be reduced if you pick\nyour sampling plan easily.",
    "start": "4389360",
    "end": "4396605"
  },
  {
    "text": " By the way, you\nmight still actually",
    "start": "4396605",
    "end": "4404720"
  },
  {
    "text": "care about sigma squared in the\nobserved mean-to-mean averages.",
    "start": "4404720",
    "end": "4411140"
  },
  {
    "text": "We said that it's not the best\nestimate of the true, say, wafer-to-wafer average.",
    "start": "4411140",
    "end": "4417690"
  },
  {
    "text": "But if I were doing SPC,\nstatistical process control charting, based on, I\nobserved some sampling plan",
    "start": "4417690",
    "end": "4427250"
  },
  {
    "text": "and I observe and I plot on\nmy chart, an observed wafer average, that may be what\nI want to control on.",
    "start": "4427250",
    "end": "4435650"
  },
  {
    "text": "And so I actually\nmight still want to use that, the sigma x bar,\nfor setting of my control",
    "start": "4435650",
    "end": "4445180"
  },
  {
    "text": "limits, because that's the\ndata that I'm charting. So don't throw away our\nold idea of keeping track",
    "start": "4445180",
    "end": "4452110"
  },
  {
    "text": "of the observed wafer average. Just recognize\nthat it's actually",
    "start": "4452110",
    "end": "4457120"
  },
  {
    "text": "got a mix of a couple of\nvariance components inside of it.",
    "start": "4457120",
    "end": "4462150"
  },
  {
    "text": "OK, and then the last point\nhere was simply the point that Nalish already made,\nis, if you're really",
    "start": "4462150",
    "end": "4472320"
  },
  {
    "text": "looking for an outer level\nvariance estimate, what you want to do is push more\ndata to the lower levels,",
    "start": "4472320",
    "end": "4483219"
  },
  {
    "text": "in order to reduce these things. So for example, if I allocated\nalmost all of my data",
    "start": "4483220",
    "end": "4490960"
  },
  {
    "text": "just to m, that reduces\nthis factor a lot,",
    "start": "4490960",
    "end": "4496640"
  },
  {
    "text": "but not this factor very much. So to get the biggest\nmultiplicative bang for the buck,\nwhat you want to do",
    "start": "4496640",
    "end": "4503260"
  },
  {
    "text": "is push it just barely\noutside of the factor",
    "start": "4503260",
    "end": "4509139"
  },
  {
    "text": "that you're trying to estimate. So if I'm looking at\nlot-to-lot variance,",
    "start": "4509140",
    "end": "4514510"
  },
  {
    "text": "I need at least multiple w's to\nget rid of the wafer-to-wafer effect.",
    "start": "4514510",
    "end": "4519550"
  },
  {
    "text": "And then I get the\nmultiplicative effect also with the m. That already is multiplying\nup fairly rapidly.",
    "start": "4519550",
    "end": "4526270"
  },
  {
    "text": "But if I want to\nsuppress this factor,",
    "start": "4526270",
    "end": "4531820"
  },
  {
    "text": "I need at least some\nnumber of wafer replicates. On the other hand, if I think\nthat variance is very small,",
    "start": "4531820",
    "end": "4538360"
  },
  {
    "text": "and this variance\nis very large, I might allocate more\nto the m factor.",
    "start": "4538360",
    "end": "4544910"
  },
  {
    "text": "So this can influence\nyour strategy for how you pick your\nsampling plans when",
    "start": "4544910",
    "end": "4551500"
  },
  {
    "text": "you've got nested structures. OK, so to summarize, we\nhave been looking here",
    "start": "4551500",
    "end": "4558010"
  },
  {
    "text": "at nested variance structures\nwith this weird grouping within one group within another\ngroup within another group.",
    "start": "4558010",
    "end": "4567310"
  },
  {
    "text": "First off, you should be\nable to recognize when you've got nested variance structures. Second, hopefully now\nyou've got at least a feel",
    "start": "4567310",
    "end": "4575170"
  },
  {
    "text": "for how you would estimate those\nseparate variance components. And then there is a little bit\nof implications on design plans",
    "start": "4575170",
    "end": "4584710"
  },
  {
    "text": "that hopefully you're alert to. So you will have a chance to\nplay around with this at least",
    "start": "4584710",
    "end": "4590500"
  },
  {
    "text": "a little bit on the\nproblem set, if you haven't started that already. Do look at the spreadsheet. I think that will be a\nbig help to you on that.",
    "start": "4590500",
    "end": "4598250"
  },
  {
    "text": "So with that, we'll end. And I'll stick\naround for a minute, because it sounds like there's\na question in the Singapore end.",
    "start": "4598250",
    "end": "4605031"
  },
  {
    "text": "AUDIENCE: Yeah, I\njust have a question. Should I ask now? DUANE BONING: Yeah.",
    "start": "4605032",
    "end": "4611380"
  },
  {
    "text": "But you guys should feel\nfree to go if you want here. AUDIENCE: How do you tell\nwhether it's a fixed effect",
    "start": "4611380",
    "end": "4616975"
  },
  {
    "text": "or if it's a nested variance? DUANE BONING: Oh, good question. How do you tell if it's a fixed\neffect or nested variance?",
    "start": "4616975",
    "end": "4624940"
  },
  {
    "text": "That's a model assumption.  So I think the basic idea\nis, if it's a fixed effect,",
    "start": "4624940",
    "end": "4637660"
  },
  {
    "text": "and I think I'm changing\nmy group-to-group by, say, a design, if wafer\nnumber 2 in the lot",
    "start": "4637660",
    "end": "4644680"
  },
  {
    "text": "always has a delta of\nsome size as opposed to being randomly\nsampled, that might",
    "start": "4644680",
    "end": "4650380"
  },
  {
    "text": "be a systematic fixed effect. But just raw data, I don't know. You actually have to look at\nthe setup of the situation",
    "start": "4650380",
    "end": "4657490"
  },
  {
    "text": "to know whether each one is\ntreated as a wafer replicate,",
    "start": "4657490",
    "end": "4664630"
  },
  {
    "text": "or if I'm doing something\ndifferent to each wafer intentionally. That would be a fixed effect.",
    "start": "4664630",
    "end": "4670570"
  },
  {
    "text": "OK? All right? So Thursday, we'll\nsee you on Thursday with Dan Frey as\na guest lecturer.",
    "start": "4670570",
    "end": "4679260"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "7410"
  },
  {
    "text": "offer high-quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "7410",
    "end": "13960"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at",
    "start": "13960",
    "end": "19790"
  },
  {
    "text": "ocw.mit.edu.  SHAN-YUAN HO: OK. So today's lecture\nis going to be on",
    "start": "19790",
    "end": "24860"
  },
  {
    "text": "Finite-state Markov Chains. And we're going to use\nthe matrix approach. So in last lecture, we saw\nthat the Markov chain, we",
    "start": "24860",
    "end": "32180"
  },
  {
    "text": "could represent it as a directed\ngraph or as a matrix. So the outline is we will look\nat this transition matrix and",
    "start": "32180",
    "end": "40859"
  },
  {
    "text": "its powers. And then we'll want to know\nwhether this p of n is going to converge for very,\nvery large n.",
    "start": "40860",
    "end": "48489"
  },
  {
    "text": "Then we will extend this to\nErgodic Markov chains, Ergodic",
    "start": "48490",
    "end": "53790"
  },
  {
    "text": "unichains, and other\nfinite-state Markov chains. So remember in the Markovity,\nthese Markov chains, the",
    "start": "53790",
    "end": "60170"
  },
  {
    "text": "effect of the past on the future\nis totally summarized by its state. So we want to analyze the\nprobabilities of properties of",
    "start": "60170",
    "end": "67590"
  },
  {
    "text": "the sequence of these states. So whatever the state you are\nin, all the past is totally summarized in that state.",
    "start": "67590",
    "end": "73330"
  },
  {
    "text": "And that's the only thing\nthat affects the future. So an ergodic Markov chain is\na Markov chain that has a",
    "start": "73330",
    "end": "80310"
  },
  {
    "text": "single recurrent class\nand is aperiodic. So this chain doesn't contain\nany transient states. And it doesn't contain\nany periodicity.",
    "start": "80310",
    "end": "88000"
  },
  {
    "text": "So an ergodic unichain is just\nergodic Markov chain, but it has some transient\nstates in it.",
    "start": "88000",
    "end": "94176"
  },
  {
    "text": " So the state x sub n of this\nMarkov chain at step n depends",
    "start": "94176",
    "end": "101369"
  },
  {
    "text": "only on the past through\nthe previous step. So for n steps, we want\nto be at state j.",
    "start": "101370",
    "end": "107500"
  },
  {
    "text": "And then we have this path. x sub n minus 1 is i, and\nso forth, up to x0. It's just the probability\nfrom i to j, from",
    "start": "107500",
    "end": "114040"
  },
  {
    "text": "state i to state j. So this means that we can write\nthe joint probability of",
    "start": "114040",
    "end": "119800"
  },
  {
    "text": "all these states that we're in,\nso x0, x1, all the way up to xn, as a function of these\ntransition probabilities.",
    "start": "119800",
    "end": "127110"
  },
  {
    "text": "So in this transition\nprobability matrix, we can represent these transition\nprobabilities.",
    "start": "127110",
    "end": "133950"
  },
  {
    "text": "We see that here, in this\nexample, this is a 6-state",
    "start": "133950",
    "end": "139220"
  },
  {
    "text": "Markov chain. So if I want to go from, say,\nstate 2 to state 1 in one step, it would just\nbe p of 2,1.",
    "start": "139220",
    "end": "146780"
  },
  {
    "text": "If I want to go from\nstate 6 to itself-- this is last one, which\nis p of 6,6.",
    "start": "146780",
    "end": "153380"
  },
  {
    "text": "So this is a probably\ntransition matrix. So if we condition on the state\nat time 0 and then we",
    "start": "153380",
    "end": "158959"
  },
  {
    "text": "define this p of ijn is equal to\nthe probability that we're",
    "start": "158960",
    "end": "164850"
  },
  {
    "text": "in state j at the n-th step,\ngiven that we start x0 is equal to i, let's look at what\nhappens when n is equal to 2.",
    "start": "164850",
    "end": "174920"
  },
  {
    "text": "So in a 2-step transition,\nwe go from i to j. It's just the probability that\nat step 2, x2 is equal to j,",
    "start": "174920",
    "end": "184100"
  },
  {
    "text": "x1 is equal to some k,\nand x0 is equal to i. So remember, we started\nin state i.",
    "start": "184100",
    "end": "189420"
  },
  {
    "text": "But this has to be multiplied\nby probability that x1 is equal to k, given that\nx0 is equal to i.",
    "start": "189420",
    "end": "195490"
  },
  {
    "text": "And we have to sum this over all\nthe states k, in order to get the total probability\nfrom--",
    "start": "195490",
    "end": "201754"
  },
  {
    "text": "Oh, stand back? OK. There. OK. So this is just probability\nof ij in two steps.",
    "start": "201754",
    "end": "208770"
  },
  {
    "text": "It's just the probability of\ni going to k times the probability of k going to j,\nsummed over all k states.",
    "start": "208770",
    "end": "216700"
  },
  {
    "text": "So we notice that this term\nright here, the sum over k or",
    "start": "216700",
    "end": "222270"
  },
  {
    "text": "ik, kj is just the ij term of\nthe product of the transition matrix P with itself.",
    "start": "222270",
    "end": "227480"
  },
  {
    "text": "So we represent this\nas P squared. So we multiply the transition\nmatrix by itself. This gives us the 2-step\ntransition matrix of this",
    "start": "227480",
    "end": "235299"
  },
  {
    "text": "Markov chain. So if you want to go i to j, you\njust look at ij element in",
    "start": "235300",
    "end": "241400"
  },
  {
    "text": "this matrix. And that gives you the\nprobability in two steps, going from state i to state j. ",
    "start": "241400",
    "end": "250200"
  },
  {
    "text": "So for n, we just iterate\non this for successively larger n.",
    "start": "250200",
    "end": "256220"
  },
  {
    "text": "So for n state to get from state\ni to state j, we just",
    "start": "256220",
    "end": "263520"
  },
  {
    "text": "have this probability x sub n,\ngiven j, given x of n minus the previous step is equal to\nk, x sub n minus 1 equals k,",
    "start": "263520",
    "end": "271949"
  },
  {
    "text": "given x0 is equal to i,\nsumming over all k. So this means that we broke\nthis up for n-th step.",
    "start": "271950",
    "end": "278700"
  },
  {
    "text": "In the n minus one step,\nwe visited state k. And then we multiplied that\none-step transition from k to",
    "start": "278700",
    "end": "283730"
  },
  {
    "text": "j because we want to arrive\nat j starting at i. But again, we have to sum over\nall the k's in order to get",
    "start": "283730",
    "end": "290570"
  },
  {
    "text": "the probability from\ni to j in n steps. So p of n right here, this\nrepresentation is just the",
    "start": "290570",
    "end": "299960"
  },
  {
    "text": "transition matrix multiplied\nby itself n times. And this gives you the n-th step\ntransition probabilities",
    "start": "299960",
    "end": "305430"
  },
  {
    "text": "of this Markov chain. So computationally, what you do\nis you take p, p squared, p to the fourth.",
    "start": "305430",
    "end": "310680"
  },
  {
    "text": "If you wanted p to the 9th,\nyou'd just take p eighth multiplied by p, to to\nmultiply by this.",
    "start": "310680",
    "end": "317570"
  },
  {
    "text": "So this gives us this thing\ncalled the Chapman-Kolmogorov equations, which means that when\nwe want to go from step i",
    "start": "317570",
    "end": "323580"
  },
  {
    "text": "to step j, we can go to an\nintermediate state and then sum up all the states that\nwould go into the",
    "start": "323580",
    "end": "329520"
  },
  {
    "text": "intermediate state. So in this case, if the step is\nm plus n transition, we can",
    "start": "329520",
    "end": "335980"
  },
  {
    "text": "break it up into m and n. So it's the probability that it\ngoes from i to k in exactly",
    "start": "335980",
    "end": "341669"
  },
  {
    "text": "m steps and k to j in n steps,\nsumming over all the k's that it visits on its way\nfrom i to j.",
    "start": "341670",
    "end": "350230"
  },
  {
    "text": "So this is very useful a\nquantity that we can manipulate our transition\nprobabilities when we get",
    "start": "350230",
    "end": "356280"
  },
  {
    "text": "higher orders of n. So the convergence\nof p to the n. So a very important question we\nlike to ask is as n goes to",
    "start": "356280",
    "end": "364250"
  },
  {
    "text": "infinity whether this goes\nto a limit or not. In other words, does the initial\nstate matter, all",
    "start": "364250",
    "end": "372810"
  },
  {
    "text": "initial sates matter in\nthis Markov chain? So the Markov chain is going\nto go on for a long, long, long, long, long time.",
    "start": "372810",
    "end": "379280"
  },
  {
    "text": "And at the n-th state where n is\nvery large, is it going to depend on i?",
    "start": "379280",
    "end": "385980"
  },
  {
    "text": "Or is it going to depend on n,\nwhich is the number of steps? If it goes to this quantity,\nsome limit, then it won't",
    "start": "385980",
    "end": "393820"
  },
  {
    "text": "depend on this. So let's assume that\nthis limit exists. If this limit does exist, we can\ntake the sum of this limit",
    "start": "393820",
    "end": "403139"
  },
  {
    "text": "and then multiply it by p of\njk, summing over all j.",
    "start": "403140",
    "end": "408860"
  },
  {
    "text": "So we do a sum of over j. So we're going from j to\nk on both sides, and we sum over all j.",
    "start": "408860",
    "end": "414789"
  },
  {
    "text": "So we take this limit\nright here. We notice that this left side\ngoing from i to k to n plus 1",
    "start": "414790",
    "end": "422180"
  },
  {
    "text": "is just that this limit\nat state k exists. Because we saw assumed up here\nthat this exists for",
    "start": "422180",
    "end": "428790"
  },
  {
    "text": "all i and all j. So therefore, if we take the n\nplus 1 step, we take this n",
    "start": "428790",
    "end": "434086"
  },
  {
    "text": "going to infinity of i to k,\nit has to go to pi of k. So when we do this,\nwe could simplify",
    "start": "434086",
    "end": "440789"
  },
  {
    "text": "this equation up here. And if it doesn't exist, we have\nthis pi sub k for all the",
    "start": "440790",
    "end": "447810"
  },
  {
    "text": "states in the Markov chain. So this is just a vector. So pi sub k is equal to pi sub j\ntimes the probability from k",
    "start": "447810",
    "end": "454885"
  },
  {
    "text": "to j, summed over all j. So if you have an m state Markov\nchain, you have exactly m of these equations.",
    "start": "454885",
    "end": "462160"
  },
  {
    "text": "And this one, we'll call it the\nvector pi, which consists of each element of this\nequation, if the limit is",
    "start": "462160",
    "end": "470460"
  },
  {
    "text": "going to exist. But we don't know whether\nit does or not, at this point in time. So if it does exist, what's\ngoing to happen?",
    "start": "470460",
    "end": "477010"
  },
  {
    "text": "So that means I'm going to\nmultiply this probability matrix, P times P,P P, P,\nP, P, P all the way.",
    "start": "477010",
    "end": "483940"
  },
  {
    "text": "And if the limit exists, then\nthat means for each row, they must be all identical.",
    "start": "483940",
    "end": "489490"
  },
  {
    "text": "Because we said the limit\nexists, then going from 1 to",
    "start": "489490",
    "end": "494610"
  },
  {
    "text": "j, 2 to j, 3 to j, 4 to\nj, they should be all exactly the same. This is also the equivalent of\nsaying, when I look at this",
    "start": "494610",
    "end": "500599"
  },
  {
    "text": "large limit, as n is very,\nvery large if the limit exists, that all the elements\nin the column should be",
    "start": "500600",
    "end": "507040"
  },
  {
    "text": "exactly the same as well,\nor all the rows. So the elements are equal to\neach other, or all the rows,",
    "start": "507040",
    "end": "513219"
  },
  {
    "text": "if I look at the row, which is\ngoing to be this pi vector. They should be the same.",
    "start": "513220",
    "end": "519219"
  },
  {
    "text": "So we define this vector. If this limit exists, the\nprobability vector is this vector pi.",
    "start": "519220",
    "end": "525830"
  },
  {
    "text": "Because we said it was an\nm state Markov chain. Each pi sub i is non-negative,\nand they obviously have",
    "start": "525830",
    "end": "532060"
  },
  {
    "text": "to sum up to 1. So this is what we call a\nprobability vector, called the",
    "start": "532060",
    "end": "537380"
  },
  {
    "text": "steady-state vector,\nfor this transition matrix P, if it exists. So what happens is this limit\nis easy to study.",
    "start": "537380",
    "end": "546290"
  },
  {
    "text": "In the future in the course, we\nwill study these pi P, this",
    "start": "546290",
    "end": "554029"
  },
  {
    "text": "steady-state vector for\nvarious Markov chains. And so you see, it is quite\ninteresting, many things that",
    "start": "554030",
    "end": "561870"
  },
  {
    "text": "could come about it. So we notice that this\nsolution can",
    "start": "561870",
    "end": "569330"
  },
  {
    "text": "contain more than one. It may not be unique. So if it contains more than one,\nit's very possible that",
    "start": "569330",
    "end": "574880"
  },
  {
    "text": "it has more than one solution,\nmore than one probability vector solution. But just because a solution\nexists to that, it doesn't",
    "start": "574880",
    "end": "580450"
  },
  {
    "text": "mean that this limit exists. So we have prove that\nlimit exists, first. ",
    "start": "580450",
    "end": "587890"
  },
  {
    "text": "So for ergodic Markov chain,\nhere we have another way to",
    "start": "587890",
    "end": "594490"
  },
  {
    "text": "express this that this matrix\nconverges is that the matrix",
    "start": "594490",
    "end": "601320"
  },
  {
    "text": "of the rows--  the elements in the column are\nall the same for each i.",
    "start": "601320",
    "end": "608360"
  },
  {
    "text": "So we have this theorem. And today's lecture is going to\nbe completely this theorem. This theorem says that if you\nhave an ergodic finite-state",
    "start": "608360",
    "end": "616450"
  },
  {
    "text": "Markov chain-- so when we say\n\"ergodic,\" remember it means that there's only one class,\nevery single state in this is",
    "start": "616450",
    "end": "622540"
  },
  {
    "text": "recurrent, you have no transient\nstates, and you have no periodicity. So it's an aperiodic chain. And then for each j, if you take\nthe maximum path from i",
    "start": "622540",
    "end": "632590"
  },
  {
    "text": "to j in n steps, this is\nnon-increasing in n. So in other words, this right\nhere, this is non-increasing.",
    "start": "632590",
    "end": "641800"
  },
  {
    "text": "So if I take the maximum path\nfrom state i to j, it gives you exactly n steps. So that means this is\nmaximized over all",
    "start": "641800",
    "end": "648920"
  },
  {
    "text": "initial states i. So it doesn't matter what state\nyou start, and I take the maximum path. And if I increase n, and I take\nmaximum of that again,",
    "start": "648920",
    "end": "658180"
  },
  {
    "text": "the maximum path, this\nis not increasing. And the minimum is\nnon-decreasing in n.",
    "start": "658180",
    "end": "664330"
  },
  {
    "text": "So as we take n, the path from\ni to j, this n getting larger",
    "start": "664330",
    "end": "670480"
  },
  {
    "text": "and larger, we have that the\nmaximum of this path, which is",
    "start": "670480",
    "end": "676370"
  },
  {
    "text": "the most probable path,\nis non-increasing. And then the minimum of this\npath, the least likely path,",
    "start": "676370",
    "end": "684610"
  },
  {
    "text": "is going to be non-decreasing. So we're wondering whether\nthis limit is going to converge or not.",
    "start": "684610",
    "end": "690459"
  },
  {
    "text": "In this theorem it said that\nfor an ergodic finite-state Markov chain, this limit\nactually does converge.",
    "start": "690460",
    "end": "696000"
  },
  {
    "text": "So in other words, the lim sup\nis equal to lim if of this and will equal pi sub j, which is\nthe steady-state distribution.",
    "start": "696000",
    "end": "704250"
  },
  {
    "text": "And not only that, this\nconvergence is going to be exponential in n.",
    "start": "704250",
    "end": "709440"
  },
  {
    "text": "So this is the theorem that\nwe will prove today. So the key to this theorem is\nthis pair statements, that the",
    "start": "709440",
    "end": "718180"
  },
  {
    "text": "most probable path from i\nto j, given n steps-- so this is the most\nprobable path-- is non-increasing at n,\nand the minimum is",
    "start": "718180",
    "end": "726550"
  },
  {
    "text": "non-decreasing in n. So the proof is almost trivial,\nbut let's see what",
    "start": "726550",
    "end": "732320"
  },
  {
    "text": "happens in this. So we have a probably\ntransition matrix.",
    "start": "732320",
    "end": "738410"
  },
  {
    "text": "So this is the statement\nright here. And the transition is just one\nhere and one here, with",
    "start": "738410",
    "end": "744050"
  },
  {
    "text": "probability 1, 1. In this case, we want to say,\nwhat is the maximum path that",
    "start": "744050",
    "end": "750580"
  },
  {
    "text": "we're in state 2,\ngiven n steps? So we know that this probability\nalternates between",
    "start": "750580",
    "end": "757510"
  },
  {
    "text": "1 and 2, it's non-increasing,\nit's not decreasing, it's always the same. So those two bounds are\nmet with equality.",
    "start": "757510",
    "end": "767890"
  },
  {
    "text": "So in this here. So the second example is this. We have a two-state\nchain again. But this time, from 1 to 2, we\nhave the transition of 3/4.",
    "start": "767890",
    "end": "778520"
  },
  {
    "text": "So that means that we have\na chain here of 1/4. See, the minute we put a\nself-loop in here, it completely destroys\nthe periodicity.",
    "start": "778520",
    "end": "785590"
  },
  {
    "text": "Any Markov chain, you put a\nself-loop in it, and the periodicity is destroyed. So here we have 3/4.",
    "start": "785590",
    "end": "792050"
  },
  {
    "text": "So this has to come\nback with 1/4. All right. So in this one, let's look at\nthe n step going from 1 to 2.",
    "start": "792050",
    "end": "802589"
  },
  {
    "text": "So basically, we want\nto end up in state 2 in exactly n steps.",
    "start": "802590",
    "end": "808850"
  },
  {
    "text": "So when n is equal to 1,\nwhat is the maximum?",
    "start": "808850",
    "end": "814810"
  },
  {
    "text": "The maximum is if you start it\nin this state and then you went to state 2. The other alternative is you\nstart at state 2, and you stay",
    "start": "814810",
    "end": "820600"
  },
  {
    "text": "in state 2. Because we want to end at state\n2 in exactly one step. So the maximum is going to\nbe 3/4, and the minimum is going to be 1/4.",
    "start": "820600",
    "end": "828190"
  },
  {
    "text": "You get n is equal to 2. Now we want to end up in\nstate 2 in two steps.",
    "start": "828190",
    "end": "833430"
  },
  {
    "text": "So what is going to\nbe the maximum? The maximum is going\nto be if you visit",
    "start": "833430",
    "end": "838959"
  },
  {
    "text": "state 1 and then back. So n is equal to 1. Then P1 from 1 to 2\nis equal to 3/4.",
    "start": "838960",
    "end": "848850"
  },
  {
    "text": "So the probability from 1 to 2\nin two steps is equal to 3/8.",
    "start": "848850",
    "end": "855829"
  },
  {
    "text": " So it goes 1/4 plus\n3/4, 3/4 plus 1/4.",
    "start": "855830",
    "end": "862270"
  },
  {
    "text": "It should be equal\nto 3/8, right? Is that right? OK.",
    "start": "862270",
    "end": "868220"
  },
  {
    "text": "And then it when P1,2 to 3, if\nthere are three transitions from 1 to 2, then it's\nequal to 9/16.",
    "start": "868220",
    "end": "875770"
  },
  {
    "text": "So if for 2, if I want\nto transition from 2 to 2 n steps-- so P2,2 is equal to 1/4.",
    "start": "875770",
    "end": "884029"
  },
  {
    "text": "So it just stayed by itself. So P2,2 in two steps, you\ndon't have a choice.",
    "start": "884030",
    "end": "894600"
  },
  {
    "text": "You have to go from\n3/4 to 3/4. ",
    "start": "894600",
    "end": "903019"
  },
  {
    "text": "So that's 9/16. But For thing is I can also stay\nhere by 1/4 times 1/4. So that gives me 5/8\nand so forth.",
    "start": "903020",
    "end": "914740"
  },
  {
    "text": "So basically, the sequence going\nfrom 1 to 2 is going to be oscillating between 3/4,\n3/8, 9/16, and so forth.",
    "start": "914740",
    "end": "924029"
  },
  {
    "text": "And then going from 2,2, it's\ngoing to be oscillating too. We can see that's\n1/4, 5/8, 7/16.",
    "start": "924030",
    "end": "930440"
  },
  {
    "text": "So what happens is this\noscillation is going to converge-- it's going to\napproach, actually, 1/2.",
    "start": "930440",
    "end": "937860"
  },
  {
    "text": "So if we take the maximum of\nthese two, so P1,2 and P2,2--",
    "start": "937860",
    "end": "944540"
  },
  {
    "text": "because that means that we're\ngoing to end at state 2. And maximum over n steps, then\nwe just look at these two",
    "start": "944540",
    "end": "953060"
  },
  {
    "text": "numbers, the 3/4 and 1/4, if we\nwant the maximum, then it's going to be 3/4. For the 3/8 and 5/8, the maximum\nis going to be 5/8,",
    "start": "953060",
    "end": "959410"
  },
  {
    "text": "the 9/16 and 7/16, the 9/16\nwill be the maximum. And similarly, we compare it,\nand we take the minimum.",
    "start": "959410",
    "end": "964975"
  },
  {
    "text": "And the minimum is 1/4,\n3/8, and 7/16. So we see that the maximum\nis going to be--",
    "start": "964975",
    "end": "970620"
  },
  {
    "text": "it starts high. And then it's going to\ndecrease toward 1/2. And the minimum, what happens\nis it's going to start low,",
    "start": "970620",
    "end": "976970"
  },
  {
    "text": "and then it's going to\nincrease to 1/2. So this is exactly\nthis one here.",
    "start": "976970",
    "end": "983600"
  },
  {
    "text": "So P's transition makes this\nan arbitrary finite-state Markov chain. Therefore, each j, this maximum\npath, the most problem",
    "start": "983600",
    "end": "992130"
  },
  {
    "text": "path from i to j in n steps\nis non-increasing n. And the minimum is\nnon-decreasing n. So you take n plus 1\nsteps from i to j.",
    "start": "992130",
    "end": "1000480"
  },
  {
    "text": "So we're going to use that\nChapman-Kolmogorov equation. So we take the first step\nto some state k.",
    "start": "1000480",
    "end": "1006790"
  },
  {
    "text": "And then we go from\nk to j in n steps. But then we sum this\nover all k.",
    "start": "1006790",
    "end": "1013180"
  },
  {
    "text": "But this P n for state to j to\nk in n steps, I can just take",
    "start": "1013180",
    "end": "1019620"
  },
  {
    "text": "the maximum path. So I take the most probable\npath, the state that gives me",
    "start": "1019620",
    "end": "1025949"
  },
  {
    "text": "the most probable path, and\nI substitute this in. When I substitute this in,\nobviously every one of these",
    "start": "1025950",
    "end": "1032359"
  },
  {
    "text": "guys is going to be less\nthan or equal to this. Therefore, this outside\nterm is going to be less than or equal.",
    "start": "1032359",
    "end": "1037900"
  },
  {
    "text": "So now this is just going\nto be a constant. So I sum over all k, and\nthen this term remains.",
    "start": "1037900",
    "end": "1044589"
  },
  {
    "text": "So therefore, what we know is\nif I want to end up in state",
    "start": "1044589",
    "end": "1049740"
  },
  {
    "text": "j, and for n steps, if I\nincrease the step more, to n",
    "start": "1049740",
    "end": "1057429"
  },
  {
    "text": "plus 1, we know that this\nprobability is going to stay the same or decrease.",
    "start": "1057430",
    "end": "1063010"
  },
  {
    "text": "It's not going to increase. So you could do exactly the same\nthing for the minimum. So if this is going to be true,\nthen of course, if I",
    "start": "1063010",
    "end": "1070480"
  },
  {
    "text": "think the maximum of this,\nit's also going to be less than that. Because this limit's true\nfor Markov chain.",
    "start": "1070480",
    "end": "1077269"
  },
  {
    "text": "It doesn't matter. It just has to be a finite-state\nMarkov chain.",
    "start": "1077270",
    "end": "1082830"
  },
  {
    "text": "So this is true for any\nfinite-state Markov chain. So if I take the maximum of\nthis, it's less than or equal",
    "start": "1082830",
    "end": "1087850"
  },
  {
    "text": "to the maximum of\nthe n-th step. So n plus 1 steps, the path is\ngoing to be less probable when",
    "start": "1087850",
    "end": "1096440"
  },
  {
    "text": "I take the maximum path, the\nfact that I end up at state j than n. ",
    "start": "1096440",
    "end": "1105570"
  },
  {
    "text": "So before we complete the proof\nof this theorem, let's look at this case where P\nis greater than zero.",
    "start": "1105570",
    "end": "1112450"
  },
  {
    "text": "So if we say Pis greater than\nzero, this means that every entry in this matrix is greater\nthan 0 for all i, j,",
    "start": "1112450",
    "end": "1119019"
  },
  {
    "text": "which means that this graph\nis fully connected. So that means you could get from\ni to j in one step with",
    "start": "1119020",
    "end": "1126130"
  },
  {
    "text": "nonzero probability. So if P is greater than 0--",
    "start": "1126130",
    "end": "1132250"
  },
  {
    "text": "and let this be the\ntransition matrix. So we'll prove this first, and\nthen we'll extend it to the arbitrary finite Markov chain.",
    "start": "1132250",
    "end": "1139169"
  },
  {
    "text": "So let alpha here is equal\nto the minimum. So it's going to be the minimum\nelement in this",
    "start": "1139170",
    "end": "1144420"
  },
  {
    "text": "transition matrix. That means it's going to be the\nstate that contains the",
    "start": "1144420",
    "end": "1149590"
  },
  {
    "text": "minimum transition. So let's call alpha-- it's\nthe minimum probability.",
    "start": "1149590",
    "end": "1155934"
  },
  {
    "text": "Excuse me. So let all these\nstates i and j.",
    "start": "1155935",
    "end": "1161659"
  },
  {
    "text": "And for n greater than or equal\nto 1, we have these three expressions.",
    "start": "1161660",
    "end": "1166740"
  },
  {
    "text": "So this first expression says\nthis, that if I have an n plus",
    "start": "1166740",
    "end": "1174059"
  },
  {
    "text": "1 walk from i to j, I take\nthe most probable of this walk over i.",
    "start": "1174060",
    "end": "1181960"
  },
  {
    "text": "So my choices, I can choose\nmy initial starting state. In n plus 1 steps, I want\nto end in state j. So I pick the most\nprobable path.",
    "start": "1181960",
    "end": "1188690"
  },
  {
    "text": "If I minus this, which is the\nleast probable path-- but you get to minimize this\nover i, over the initial",
    "start": "1188690",
    "end": "1196690"
  },
  {
    "text": "starting a state. So this is less than or\nequal to the n step.",
    "start": "1196690",
    "end": "1202800"
  },
  {
    "text": "It's exactly this term\nhere, the n step times 1 minus 2 alpha.",
    "start": "1202800",
    "end": "1208130"
  },
  {
    "text": "So alpha is the minimum\ntransition probability in this probability transition matrix.",
    "start": "1208130",
    "end": "1214780"
  },
  {
    "text": "So this one, it's not so\nobvious right now. But we are going to prove\nthat in the next slide.",
    "start": "1214780",
    "end": "1220370"
  },
  {
    "text": "So once we have this, we can\niterative on n to get the",
    "start": "1220370",
    "end": "1226830"
  },
  {
    "text": "second term. So for this term inside here,\nthe most probable path to",
    "start": "1226830",
    "end": "1235170"
  },
  {
    "text": "state j in n steps, minus the\nleast probable path to state j in n steps, is equal to exactly\nthe same thing in n",
    "start": "1235170",
    "end": "1243670"
  },
  {
    "text": "minus 1 steps times\n1 minus 2 alpha. So we just keep on iterating\nthis over. n, and then we",
    "start": "1243670",
    "end": "1249299"
  },
  {
    "text": "should get this. So to prove this to this, we\nprove it by induction. We just have to prove the\ninitial step, that the maximum",
    "start": "1249300",
    "end": "1258690"
  },
  {
    "text": "single transition from l to j,\nminus the minimum single transition from l to j,\nis less than or equal",
    "start": "1258690",
    "end": "1265650"
  },
  {
    "text": "to 1 minus 2 alpha. So this one is proved\nby induction. So as n goes to infinity, notice\nthat this term is going",
    "start": "1265650",
    "end": "1274440"
  },
  {
    "text": "to go to 0. because alpha is going to\nbe less than a 1/2. Because if it's not, then we can\nchoose 1 minus alpha to be",
    "start": "1274440",
    "end": "1283560"
  },
  {
    "text": "this minimum. So if this is going to 0, this\ntells us the difference between the most probable path\nminus the least probable path,",
    "start": "1283560",
    "end": "1291260"
  },
  {
    "text": "the fact that we end\nup in state j. So if we take the limit as n\ngoes to infinity of both of",
    "start": "1291260",
    "end": "1297140"
  },
  {
    "text": "these, they should equal. Because the difference of this,\nwe notice that it's going down exponentially in n.",
    "start": "1297140",
    "end": "1305290"
  },
  {
    "text": "So this shows us that this\nlimit indeed does exist and is equal.",
    "start": "1305290",
    "end": "1311450"
  },
  {
    "text": "We want to prove this first\nstatement over here. So in order to prove this first\nstatement, what we're",
    "start": "1311450",
    "end": "1317870"
  },
  {
    "text": "going to do is we're going to\ntake this i, j transition in n",
    "start": "1317870",
    "end": "1323290"
  },
  {
    "text": "plus 1 transitions. And then we're going to express\nit as a function of n transitions.",
    "start": "1323290",
    "end": "1329500"
  },
  {
    "text": "So the idea is this. We're going to use the\nChapman-Kolmogorov equations",
    "start": "1329500",
    "end": "1334900"
  },
  {
    "text": "to have an intermediary step. So in order to do this i to j\nin n plus 1 steps, the most",
    "start": "1334900",
    "end": "1344310"
  },
  {
    "text": "probable path, we're going to\ngo to this intermediate step",
    "start": "1344310",
    "end": "1349530"
  },
  {
    "text": "and then on to the final step. In this intermediate step,\nit's going to be",
    "start": "1349530",
    "end": "1356270"
  },
  {
    "text": "a function of n. So we're going to take one step\nand then n more steps. So what we're going to do is,\nthe intuition is, we're going",
    "start": "1356270",
    "end": "1363310"
  },
  {
    "text": "to remove the least\nprobable path. So we remove that from\nthe sum in this",
    "start": "1363310",
    "end": "1370110"
  },
  {
    "text": "Chapman-Kolmogorov equation. And then we have the sum\nof everything else except for that path.",
    "start": "1370110",
    "end": "1376010"
  },
  {
    "text": "And then the sum of everything\nelse, we're going to bound it. Once we bound it, then we\nhave this expression.",
    "start": "1376010",
    "end": "1382760"
  },
  {
    "text": "The probability of i to j in n\nplus 1 steps is going be a function of a max and\na min over n steps",
    "start": "1382760",
    "end": "1389049"
  },
  {
    "text": "with a bunch of terms. So that's the intuition of\nhow we're going to do it.",
    "start": "1389050",
    "end": "1394720"
  },
  {
    "text": "So the probability of ij going\nfrom state i to state j in exactly n plus 1 steps\nis equal to this.",
    "start": "1394720",
    "end": "1400290"
  },
  {
    "text": "So it's the probability of\ngoing from i to k, this intermediate step. We're going to take one\nstep to a state k.",
    "start": "1400290",
    "end": "1406840"
  },
  {
    "text": "And then we're going from\nk to j in n steps, summing over all k. So this is exactly equal to this\nwith Chapman-Kolmogorov.",
    "start": "1406840",
    "end": "1414260"
  },
  {
    "text": "So now what happens is\nwe're going to take-- ",
    "start": "1414260",
    "end": "1421100"
  },
  {
    "text": "Before we get to this next step,\nlet's define this l min to be the state that minimizes\np of ij, n over i.",
    "start": "1421100",
    "end": "1427690"
  },
  {
    "text": "So l min is going to be the\nstate that's going to be such that the choices I pick over i\nthat in n steps I arrive at j",
    "start": "1427690",
    "end": "1437060"
  },
  {
    "text": "that's going to be the\nleast probable. So this is l min over here.",
    "start": "1437060",
    "end": "1443160"
  },
  {
    "text": "It's the l min that\nsatisfies this. Then I'm going to remove this. So this is one state. l min is\njust one state that i is going",
    "start": "1443160",
    "end": "1449669"
  },
  {
    "text": "to go to in this first step. So we're going to remove\nit from the sum.",
    "start": "1449670",
    "end": "1455440"
  },
  {
    "text": "So then, this is just here. So that path goes from i to l\nmin times l to j in n steps.",
    "start": "1455440",
    "end": "1468120"
  },
  {
    "text": "So remove that one\npath from here. Now we have the sum over the\nrest of the cases because we",
    "start": "1468120",
    "end": "1473610"
  },
  {
    "text": "just removed that. So we have ik, kj to\nn, where k is not",
    "start": "1473610",
    "end": "1478890"
  },
  {
    "text": "equal to that element. So we removed that path, the one\nthat goes to that state.",
    "start": "1478890",
    "end": "1484450"
  },
  {
    "text": "But p of kj, n, the path that\ngoes from k to j in n steps,",
    "start": "1484450",
    "end": "1489889"
  },
  {
    "text": "we can just bound this term\nby the maximum over l from l to j of n.",
    "start": "1489890",
    "end": "1496390"
  },
  {
    "text": "So then we're going to take the\nmost probable path in n steps such that we end\nup in state j in n.",
    "start": "1496390",
    "end": "1502720"
  },
  {
    "text": "So this term right here is\nbounded by this term. Becomes is bounded by this,\nthat's why we have this less",
    "start": "1502720",
    "end": "1508150"
  },
  {
    "text": "than or equal sign. So we just do two things from\nthis step, the first step, to",
    "start": "1508150",
    "end": "1513670"
  },
  {
    "text": "the second step. So we took out the path that's\ngoing to minimize that right",
    "start": "1513670",
    "end": "1520419"
  },
  {
    "text": "at the j-th node in n steps. And then we bounded the rest\nof this sum by this.",
    "start": "1520420",
    "end": "1530870"
  },
  {
    "text": "So when we sum this all up, this\nis just a constant here. And ik here is just all the\nstates that i is going to",
    "start": "1530870",
    "end": "1541799"
  },
  {
    "text": "visit except for this\none state, l min. Since it's just all of them\nexcept for that, it's just 1",
    "start": "1541800",
    "end": "1548450"
  },
  {
    "text": "minus the probability that it\ngoes from state i to l min. So this sum here is just\nequal to this sum here.",
    "start": "1548450",
    "end": "1557580"
  },
  {
    "text": "So this arrives here. And this term is still here.",
    "start": "1557580",
    "end": "1562860"
  },
  {
    "text": "So going from here, what\nhappens is we just to",
    "start": "1562860",
    "end": "1570620"
  },
  {
    "text": "rearrange the terms. So nothing happens right here. It's just rearranging. ",
    "start": "1570620",
    "end": "1577559"
  },
  {
    "text": "Now we have this term here. So we look at this term, P\nfrom i going to l min--",
    "start": "1577560",
    "end": "1583620"
  },
  {
    "text": "Remember, we chose alpha to be\nthe minimum single transition probability, single\ntransition in that",
    "start": "1583620",
    "end": "1591760"
  },
  {
    "text": "probability transition matrix. So i to l has to be\ngreater than that. But the minus of this has to be\nless than, the negative has",
    "start": "1591760",
    "end": "1599050"
  },
  {
    "text": "to be less than. So this we can substitute\nhere. ",
    "start": "1599050",
    "end": "1606669"
  },
  {
    "text": "So now we have this. So the maximum over i of this\nn plus 1 step actually shows",
    "start": "1606670",
    "end": "1611872"
  },
  {
    "text": "you the probability. Because this I can write\nas an n plus 1 step path from i to j.",
    "start": "1611872",
    "end": "1617379"
  },
  {
    "text": "So if this is less than this\nentire term, of course I can write the maximum path\nfrom i to j.",
    "start": "1617380",
    "end": "1625740"
  },
  {
    "text": "It also has to be less of\nthis because this is satisfied for all i, j.",
    "start": "1625740",
    "end": "1630899"
  },
  {
    "text": "So therefore, we arrive at\nthis expression here. So now we're kind of in good\nbusiness because we have the n",
    "start": "1630900",
    "end": "1641750"
  },
  {
    "text": "plus one step at transition, the\nmaximum path from i to j in n plus 1 steps as a function\nof n, which is what we wanted, and a function\nof this alpha.",
    "start": "1641750",
    "end": "1649525"
  },
  {
    "text": " So we repeat that\nlast statement.",
    "start": "1649525",
    "end": "1655980"
  },
  {
    "text": " And the last one is here,\nthe last line.",
    "start": "1655980",
    "end": "1662170"
  },
  {
    "text": " So now we have the maximum. So now we want to do is we\nwant to get the minimum.",
    "start": "1662170",
    "end": "1668910"
  },
  {
    "text": "So we do exactly the same thing,\nwith the same proof. And with the minimum, what we're\ngoing to do is we're",
    "start": "1668910",
    "end": "1675593"
  },
  {
    "text": "going to look at the ij\ntransition in n plus 1 steps.",
    "start": "1675593",
    "end": "1681180"
  },
  {
    "text": "And then what we're going to do\nis we're going to pull out the maximum this time. So we pull out the most probable\npath in n steps such",
    "start": "1681180",
    "end": "1688830"
  },
  {
    "text": "that it arrives in state j. Then we play the same game. Would bound everything-- above, this time-- by the\nminimum of the n step",
    "start": "1688830",
    "end": "1696830"
  },
  {
    "text": "transition probabilities\nto get to j. So once we do that, we get this\nexpression, very similar",
    "start": "1696830",
    "end": "1704440"
  },
  {
    "text": "to this one up here. So now we have the maximum path,\nwhich is n plus 1 steps",
    "start": "1704440",
    "end": "1711330"
  },
  {
    "text": "to j, and the minimum of\nn plus 1 steps to j.",
    "start": "1711330",
    "end": "1716440"
  },
  {
    "text": "So we could take the difference\nbetween these two. So if you subtract these\nequations here, so this first",
    "start": "1716440",
    "end": "1724000"
  },
  {
    "text": "equation minus the second\nequation, we have this on the right-hand side here and then\nthese terms over here on the",
    "start": "1724000",
    "end": "1733170"
  },
  {
    "text": "left-hand side. So these terms over here on the\nleft-hand exactly proves",
    "start": "1733170",
    "end": "1739659"
  },
  {
    "text": "the first line of the lemma. ",
    "start": "1739660",
    "end": "1746670"
  },
  {
    "text": "So the first line of\nthe lemma was here.",
    "start": "1746670",
    "end": "1753110"
  },
  {
    "text": "So now, to prove the second of\nthe lemma, remember, we're going to prove this\nby induction. in order to prove this by\ninduction, we need to be first",
    "start": "1753110",
    "end": "1760899"
  },
  {
    "text": "initial step. So the initial step is this. So if I take the minimum\ntransition probability from l",
    "start": "1760900",
    "end": "1770660"
  },
  {
    "text": "to j, it has to be greater\nthan here with the alpha. Because we said that alpha was\nthe absolute minimum of all",
    "start": "1770660",
    "end": "1775669"
  },
  {
    "text": "the single-step transition\nprobabilities. Then the maximum transition\nprobability has to be greater",
    "start": "1775670",
    "end": "1781770"
  },
  {
    "text": "than or equal to\n1 minus alpha. It's just by definition\nof what we choose. So therefore, if I take this\nterm, the maximize minus the",
    "start": "1781770",
    "end": "1789840"
  },
  {
    "text": "minimum is just 1\nminus 2 alpha. So that's your first step in\nthe induction process.",
    "start": "1789840",
    "end": "1795850"
  },
  {
    "text": "So we iterate on n. When we iterate on n,\none arrives at this",
    "start": "1795850",
    "end": "1801630"
  },
  {
    "text": "equation down here. ",
    "start": "1801630",
    "end": "1816610"
  },
  {
    "text": "So this shows us from here that\nif we take the limit as n",
    "start": "1816610",
    "end": "1824760"
  },
  {
    "text": "goes to infinity of this\nterm, this goes down exponentially in n.",
    "start": "1824760",
    "end": "1829880"
  },
  {
    "text": "And both of these limits are\ngoing to converge, and they exist, and they're going\nto be greater than 0. So they'll be greater than 0\nbecause of our initial state",
    "start": "1829880",
    "end": "1837690"
  },
  {
    "text": "that we chose this path with\na positive probability. Yeah, go ahead.",
    "start": "1837690",
    "end": "1843735"
  },
  {
    "text": "AUDIENCE: It seems to me that\nalpha is the minimum, the smallest number in the\ntransition matrix, right?",
    "start": "1843735",
    "end": "1848934"
  },
  {
    "text": "SHAN-YUAN HO: Alpha is the\nsmallest number, correct. AUDIENCE: Yeah. How does it fall from\nthat, like that? So my is, the convergence\nrate is related to f?",
    "start": "1848934",
    "end": "1861460"
  },
  {
    "text": "SHAN-YUAN HO: Yes,\nit is, yeah. In general, it doesn't really\nmatter because it's still",
    "start": "1861460",
    "end": "1866570"
  },
  {
    "text": "going to go down exponentially\nin n. But it does depend on\nthat alpha, yes.",
    "start": "1866570",
    "end": "1872640"
  },
  {
    "text": " Any other questions?",
    "start": "1872640",
    "end": "1877820"
  },
  {
    "text": " Yes.",
    "start": "1877820",
    "end": "1883049"
  },
  {
    "text": "AUDIENCE: Is the strength that\nbound it proportional to the size of that matrix, right? SHAN-YUAN HO: Excuse me?",
    "start": "1883050",
    "end": "1888470"
  },
  {
    "text": "AUDIENCE: The strength\nof that bound is proportional to the size? I mean, for a very large\nfinite-state Markov chain, the",
    "start": "1888470",
    "end": "1893490"
  },
  {
    "text": "strength of the bound is going\nto be somewhat weak because alpha is going to be-- SHAN-YUAN HO: Alpha has\nto be less than 1/2.",
    "start": "1893490",
    "end": "1899299"
  },
  {
    "text": "AUDIENCE: OK, yes. But the strength of the bound,\nthough, it's not a very tight bound on max minus min.",
    "start": "1899300",
    "end": "1907902"
  },
  {
    "text": "Because in a large-- SHAN-YUAN HO: Yes. This is just a bound. And the bound is what\nwhen we took it that",
    "start": "1907902",
    "end": "1914940"
  },
  {
    "text": "minimum-probability path,\nthe l min, remember? The bound was actually\nin here.",
    "start": "1914940",
    "end": "1922050"
  },
  {
    "text": "So we took the\nminimum-probability path in n steps, this l min that minimizes\nthis over i.",
    "start": "1922050",
    "end": "1929620"
  },
  {
    "text": "And then this is where this less\nthan or equal to here is just a substitution. ",
    "start": "1929620",
    "end": "1938250"
  },
  {
    "text": "Any other questions? ",
    "start": "1938250",
    "end": "1943810"
  },
  {
    "text": "So what we know is that what\nhappens is that these limited-state probabilities\nexist.",
    "start": "1943810",
    "end": "1949820"
  },
  {
    "text": "So we have a finite\nergodic chain. ",
    "start": "1949820",
    "end": "1957309"
  },
  {
    "text": "So if the probability of the\nelements in this transition matrix are all greater\nthan 0, we know",
    "start": "1957310",
    "end": "1963630"
  },
  {
    "text": "that this limit exists. But we know that in general,\nthat may not be the case. We're going to have some 0's\nin our transition matrix.",
    "start": "1963630",
    "end": "1970414"
  },
  {
    "text": " So let's go back to the\narbitrary finite-state ergodic",
    "start": "1970415",
    "end": "1977240"
  },
  {
    "text": "chain with probability\ntransition matrix P. So in the",
    "start": "1977240",
    "end": "1983740"
  },
  {
    "text": "last slide, we showed that this\ntransition matrix P of h is positive for h is equal to\nM minus 1 squared plus 1.",
    "start": "1983740",
    "end": "1993559"
  },
  {
    "text": "So what we do is, we can apply\nlemma 2 to P of h with this",
    "start": "1993560",
    "end": "1999130"
  },
  {
    "text": "alpha equals to minimum\ngoing from i to j in exactly h steps. ",
    "start": "1999130",
    "end": "2006340"
  },
  {
    "text": "So why is this M minus\n1 squared plus 1? So in the last lecture--",
    "start": "2006340",
    "end": "2013020"
  },
  {
    "text": "so what it means is this.  So what is says is here.",
    "start": "2013020",
    "end": "2019020"
  },
  {
    "text": "This was an example given\nin the last lecture. It was a 6-state Markov chain. So what it says is that if n is\ngreater than or equal to M",
    "start": "2019020",
    "end": "2028020"
  },
  {
    "text": "minus 1 squared plus 1-- in this\ncase, it's going to be 6. So if n is greater than or equal\nto 26, then I take P to",
    "start": "2028020",
    "end": "2036570"
  },
  {
    "text": "the 26th power, it means\nit's greater than zero. That meas if I take P to the\n26th power, every single",
    "start": "2036570",
    "end": "2042350"
  },
  {
    "text": "element in this transition\nmatrix is going to be non-zero, which means that you\ncan go from any state to any",
    "start": "2042350",
    "end": "2054260"
  },
  {
    "text": "state with nonzero probability,\nas long as n is bigger than that. So basically, in this Markov\nchain, if you go long enough,",
    "start": "2054260",
    "end": "2060888"
  },
  {
    "text": "long enough. Then I say, OK, I want to go\nfrom state i to state j in",
    "start": "2060889",
    "end": "2065905"
  },
  {
    "text": "exactly how many steps, there is\na positive probability that this is going to happen.",
    "start": "2065905",
    "end": "2071600"
  },
  {
    "text": "So how did this bound\ncome across? Well, for instance, in this\nchain, if we look at P1,1 so",
    "start": "2071600",
    "end": "2084980"
  },
  {
    "text": "we have here? So I'm going to look\nat the transition",
    "start": "2084980",
    "end": "2090449"
  },
  {
    "text": "starting at state 1. And I want to come back to 1. So you definitely could come\nback at 6, because these are",
    "start": "2090449",
    "end": "2096860"
  },
  {
    "text": "all positive probability 1. So 6 is possible. So n is equal to\n6 is possible.",
    "start": "2096860",
    "end": "2102160"
  },
  {
    "text": "So what's the next one\nthat's possible? n is equal to 11, right? Then the next one is what?",
    "start": "2102160",
    "end": "2109099"
  },
  {
    "text": "16 is possible, right? So 0 to 5 is impossible, is 0.",
    "start": "2109100",
    "end": "2115099"
  },
  {
    "text": "So if I pick n between 0 and 5,\nand 7 and 10, you're toast. You can't get back to 1.",
    "start": "2115100",
    "end": "2122750"
  },
  {
    "text": "And so forth. So 18 is possible. ",
    "start": "2122750",
    "end": "2129250"
  },
  {
    "text": "21-- let's see, is 17 possible? Yeah, 17 is also possible. ",
    "start": "2129250",
    "end": "2137040"
  },
  {
    "text": "AUDIENCE: Why is 16 possible? SHAN-YUAN HO: So I go around\nhere twice, and then the last one.",
    "start": "2137040",
    "end": "2142880"
  },
  {
    "text": " Is that right?",
    "start": "2142880",
    "end": "2148810"
  },
  {
    "text": "So if I go from here to here\nto here to here, if I go twice, and then one more\nin the final loop.",
    "start": "2148810",
    "end": "2154695"
  },
  {
    "text": "AUDIENCE: That's 12. SHAN-YUAN HO: Oh, it's 12? No. I'm going to go this inner\nloop right here.",
    "start": "2154696",
    "end": "2161640"
  },
  {
    "text": "So if I go from 1 to 2 to 3\nto 4 to 5 to 6, down to 2.",
    "start": "2161640",
    "end": "2167234"
  },
  {
    "text": "Then I go 3, 4, 5, 6, 1. That's 11, isn't it? ",
    "start": "2167234",
    "end": "2174299"
  },
  {
    "text": "So 16 is I'm going to go around\nthe inner loop twice. ",
    "start": "2174300",
    "end": "2179630"
  },
  {
    "text": "OK. Go ahead. Question? AUDIENCE: So everything 20 and\nunder is possible, right? SHAN-YUAN HO: No.",
    "start": "2179630",
    "end": "2184670"
  },
  {
    "text": "Is 25 possible? Tell me how you're going\nto go 25 on this. You just do the 5\nloop 5 times.",
    "start": "2184670",
    "end": "2190760"
  },
  {
    "text": "SHAN-YUAN HO: Yeah, but I\nwant to go from 1 to 1. You're starting in state 1. AUDIENCE: Oh, oh, sorry. OK. SHAN-YUAN HO: 1 to 1, right? AUDIENCE: OK, cool.",
    "start": "2190760",
    "end": "2196594"
  },
  {
    "text": "OK, I see.  SHAN-YUAN HO: So you know for\nthis one that this bound is",
    "start": "2196594",
    "end": "2202230"
  },
  {
    "text": "actually tight. So 25 is impossible. So P1,1 of 25 is equal to 0.",
    "start": "2202230",
    "end": "2210519"
  },
  {
    "text": "There's no way you\ncan do that. But for 26 on, then you can. So what you're noticing is that\nyou need this loop of 6",
    "start": "2210520",
    "end": "2218090"
  },
  {
    "text": "here and that any combination\nof 5 or 6 is possible. So basically, in this particular\nexample, if n is",
    "start": "2218090",
    "end": "2228310"
  },
  {
    "text": "equal to 6k plus 5j, where k\nis greater than or equal to",
    "start": "2228310",
    "end": "2238710"
  },
  {
    "text": "1-- because I need that final\nloop to get back-- or j is greater than\nor equal to 0-- So any combination of this one,\nthen I can express n.",
    "start": "2238710",
    "end": "2248730"
  },
  {
    "text": "I can go around it to give me\na positive probability of going from state 1 to state 1. So I'm going to prove this\nusing extremal property.",
    "start": "2248730",
    "end": "2258910"
  },
  {
    "text": "So we're going to take the\nabsolute worst case. So the absolute worst case is\nthat for M state finite Markov",
    "start": "2258910",
    "end": "2266970"
  },
  {
    "text": "chain is if have a loop\nof m and you have a loop of m minus 1. You can't just have\na loop of m.",
    "start": "2266970",
    "end": "2272460"
  },
  {
    "text": "The problem is now this\nbecomes periodic.  So we have to get rid\nof the periodicity.",
    "start": "2272460",
    "end": "2280680"
  },
  {
    "text": "If you add a single group here,\nthat doesn't help you. Then after 6, then it I get\n7, 8, 9, 10, 11, 12. That didn't have this.",
    "start": "2280680",
    "end": "2288930"
  },
  {
    "text": "So the absolute worst case for\nan M state chain is going to be something that\nlooks like this. 1 that goes to 2-- you're\nforced to go to 2--",
    "start": "2288930",
    "end": "2296550"
  },
  {
    "text": "so forth, until state M. And\nthen this M is going to go back to 2 or is going\nto go back to 1.",
    "start": "2296550",
    "end": "2303830"
  },
  {
    "text": "So in other words, the worst\ncase is if you have--",
    "start": "2303830",
    "end": "2311290"
  },
  {
    "text": "n has to be some combination\nof Mk plus M minus 1 j.",
    "start": "2311290",
    "end": "2319210"
  },
  {
    "text": "So this will be the worst\npossible case for M state Markov chain.",
    "start": "2319210",
    "end": "2324220"
  },
  {
    "text": "So it'll be Mk plus\nM minus 1 j.",
    "start": "2324220",
    "end": "2330480"
  },
  {
    "text": "So k has to be greater\nthan or equal to 1. And then j has to be greater\nthan or equal to 0, because",
    "start": "2330480",
    "end": "2335840"
  },
  {
    "text": "you need to come back. So I'm just looking at the case\nprobability that I start in state 1 and I come\nback in state 1.",
    "start": "2335840",
    "end": "2342500"
  },
  {
    "text": "So all right. So how do we get this bound?",
    "start": "2342500",
    "end": "2349770"
  },
  {
    "text": "Well, there is an identity\nthat says this.",
    "start": "2349770",
    "end": "2354860"
  },
  {
    "text": "If a and b are relatively prime,\nthen the largest n such",
    "start": "2354860",
    "end": "2369370"
  },
  {
    "text": "that it cannot be written-- so\nwe want to find the largest n such that ak plus bj--",
    "start": "2369370",
    "end": "2382430"
  },
  {
    "text": "but this is k and j greater\nthan or equal to 0--",
    "start": "2382430",
    "end": "2388859"
  },
  {
    "text": "that it cannot be written\nin this form. ",
    "start": "2388860",
    "end": "2395860"
  },
  {
    "text": "The largest integer that it\ncannot be written is ab minus a minus b. This takes a little bit to\nprove, but it's not too hard.",
    "start": "2395860",
    "end": "2402960"
  },
  {
    "text": "If you want to know this proof,\ncome see me offline after class.",
    "start": "2402960",
    "end": "2409090"
  },
  {
    "text": "This is the largest integer. If n is equal to this,\nit cannot be written in this form.",
    "start": "2409090",
    "end": "2414309"
  },
  {
    "text": "But if n is greater than\nthis, then it can. So all we do is substitute M\nfor a and M minus 1 for b",
    "start": "2414310",
    "end": "2421680"
  },
  {
    "text": "because M and M minus 1\nare relatively prime. But remember, we have a k here\nthat has to be greater than or",
    "start": "2421680",
    "end": "2429460"
  },
  {
    "text": "equal to 1. We need at least one k. But this so identity is for\nk and j greater than 0.",
    "start": "2429460",
    "end": "2434690"
  },
  {
    "text": "So therefore, we have to\nsubtract out that k. So therefore, we have M times\nM minus 1, minus M",
    "start": "2434690",
    "end": "2446030"
  },
  {
    "text": "minus M minus 1. But the thing is we have to add\nthe extra M, because this",
    "start": "2446030",
    "end": "2458960"
  },
  {
    "text": "k is greater than\nor equal to 1. So we have to add up one of\nthe M's because of this.",
    "start": "2458960",
    "end": "2465330"
  },
  {
    "text": "So this is just equal to\nM minus 1, squared.",
    "start": "2465330",
    "end": "2473830"
  },
  {
    "text": "So this number, if n is equal\nto this, it's the largest",
    "start": "2473830",
    "end": "2478920"
  },
  {
    "text": "number that it cannot be\nwritten like that. So therefore, we\nhave to add 1. So that's why the bound\nis equal to 1.",
    "start": "2478920",
    "end": "2484080"
  },
  {
    "text": "So the upper bound that n can\nbe written is going to be M",
    "start": "2484080",
    "end": "2490660"
  },
  {
    "text": "minus 1, squared plus 1. AUDIENCE: Why did you add\nthe 1 at the end?",
    "start": "2490660",
    "end": "2496410"
  },
  {
    "text": "SHAN-YUAN HO: This one? AUDIENCE: No, we've got to\ndo the 1 at the end. AUDIENCE: We already\nhave that in there.",
    "start": "2496410",
    "end": "2502380"
  },
  {
    "text": "SHAN-YUAN HO: Oh, where is it? No, it's in here, right? AUDIENCE: No, it's not here. ",
    "start": "2502380",
    "end": "2508420"
  },
  {
    "text": "SHAN-YUAN HO: Did I-- ",
    "start": "2508420",
    "end": "2513980"
  },
  {
    "text": "What are you talking about? Where's the 1? AUDIENCE: At the end,\nthe last equation.",
    "start": "2513980",
    "end": "2519029"
  },
  {
    "text": "SHAN-YUAN HO: This one? AUDIENCE: Yes. SHAN-YUAN HO: OK. This is the \"cannot,\" largest\nn which you cannot write.",
    "start": "2519030",
    "end": "2532420"
  },
  {
    "text": "You cannot write this. So this bound is tight.",
    "start": "2532420",
    "end": "2538220"
  },
  {
    "text": "It means that this is the\none that you can. So if n is greater\nthan or equal to",
    "start": "2538220",
    "end": "2544990"
  },
  {
    "text": "this, then it's possible. This is the largest\none it cannot. Based on this, it cannot.",
    "start": "2544990",
    "end": "2550790"
  },
  {
    "text": "So we have to add the 1. So therefore, in here,\nyou could do 26. So starting from 26, 27,\n28, you can do that.",
    "start": "2550790",
    "end": "2558470"
  },
  {
    "text": " Any questions? AUDIENCE: Relatively prime,\nwhat do you mean by",
    "start": "2558470",
    "end": "2565589"
  },
  {
    "text": "\"relatively\"? SHAN-YUAN HO: There is a\ngreatest common divisor of 1. ",
    "start": "2565590",
    "end": "2571900"
  },
  {
    "text": "So if we take h here, h is\ngoing to be positive. So if h is equal to M minus 1,\nsquared plus 1, then now all",
    "start": "2571900",
    "end": "2580400"
  },
  {
    "text": "the elements are positive. Because we just proved that\nwe can write this-- ",
    "start": "2580400",
    "end": "2590230"
  },
  {
    "text": "every state can be visited by\nany other state, with positive probability.",
    "start": "2590230",
    "end": "2595260"
  },
  {
    "text": "So we say, looking at P, we know\nthat P of h is positive",
    "start": "2595260",
    "end": "2601620"
  },
  {
    "text": "for h greater than or\nequal to this bound. So what we do is we applied this\nlemma 2 probability to",
    "start": "2601620",
    "end": "2608330"
  },
  {
    "text": "this transition matrix P of h,\nwhere we have picked alpha-- remember, alpha is the\nsingle-step transition",
    "start": "2608330",
    "end": "2614619"
  },
  {
    "text": "probability. So instead of the single\ntransition, we have lumped this P into P to the h power.",
    "start": "2614620",
    "end": "2622700"
  },
  {
    "text": "So it's h steps. Because we proved the result\nbefore for positive P. So this",
    "start": "2622700",
    "end": "2630790"
  },
  {
    "text": "P to the h is positive, so we\ntake alpha as the minimum from i to j of P to the\nh in this matrix.",
    "start": "2630790",
    "end": "2639510"
  },
  {
    "text": "So it doesn't really matter what\nthe value of alpha is, only that it's going\nto be positive. And it has to be positive\nbecause it's a probability.",
    "start": "2639510",
    "end": "2646290"
  },
  {
    "text": "So what happens is, if we follow\nthe proof of what we",
    "start": "2646290",
    "end": "2652770"
  },
  {
    "text": "just showed in the lemma, then\nwe show that the maximum path from l to j--",
    "start": "2652770",
    "end": "2659190"
  },
  {
    "text": " h times M. So M is going\nto be an integer, so in",
    "start": "2659190",
    "end": "2665240"
  },
  {
    "text": "multiples of h-- this upper limit is going to be\nequal to the lower limit.",
    "start": "2665240",
    "end": "2670930"
  },
  {
    "text": "So the most probable path\nis equal to the least probable path.",
    "start": "2670930",
    "end": "2676590"
  },
  {
    "text": " So this is multiple of h's.",
    "start": "2676590",
    "end": "2682380"
  },
  {
    "text": "So if we take this as M goes\nto infinity, this has got to equal to--",
    "start": "2682380",
    "end": "2687510"
  },
  {
    "text": "Oops, this should be going\nto pi sub j, excuse me.",
    "start": "2687510",
    "end": "2693110"
  },
  {
    "text": "This little temple here. And this is going to\nbe greater than 0. So the problem is now we've\nshown it for multiples of h's,",
    "start": "2693110",
    "end": "2701040"
  },
  {
    "text": "what about the h's in between? But the fact is that lemma 1,\nwe showed that this maximum",
    "start": "2701040",
    "end": "2710510"
  },
  {
    "text": "path from l to j in n is\nnot increasing in n. So all those states, all those\npaths, the transition",
    "start": "2710510",
    "end": "2718619"
  },
  {
    "text": "probability for the paths in\nbetween these multiples of h's, in between them it's\ngoing to be not",
    "start": "2718620",
    "end": "2725109"
  },
  {
    "text": "increasing in n. So even if we're taking these\nmultiples of each of h and n",
    "start": "2725110",
    "end": "2730852"
  },
  {
    "text": "here, here, here, and we know\nthat this limit is increasing, we know that all the ones in\nbetween them are also going to",
    "start": "2730852",
    "end": "2737690"
  },
  {
    "text": "be increasing to the same limit\nbecause of lemma 1. To remember, the maximum is\ngoing to be not increasing,",
    "start": "2737690",
    "end": "2745335"
  },
  {
    "text": "and the minimum is going to be non-decreasing in any one path. So this must have the\nsame limit as",
    "start": "2745335",
    "end": "2754280"
  },
  {
    "text": "this multiple of this. So the same limit applies. So any questions on this?",
    "start": "2754280",
    "end": "2760220"
  },
  {
    "text": "So this is how we prove it for\nthe arbitrary finite-state ergodic chain when we have some\n0 probability transition",
    "start": "2760220",
    "end": "2767789"
  },
  {
    "text": "elements in the matrix P. So\nthe proof is the same.",
    "start": "2767790",
    "end": "2773490"
  },
  {
    "text": " So now for ergodic unichain.",
    "start": "2773490",
    "end": "2779880"
  },
  {
    "text": "So we see that this limit as n\napproaches infinity from i to",
    "start": "2779880",
    "end": "2786880"
  },
  {
    "text": "j of n is going to just end up\nin the steady-state transition pi of j for all i.",
    "start": "2786880",
    "end": "2792380"
  },
  {
    "text": "So it doesn't matter what\nyour initial state is. As n goes to infinity of this\npath, as this Markov chain",
    "start": "2792380",
    "end": "2799170"
  },
  {
    "text": "goes on and on, you will end up\nin state j with probability pi sub j, where pi is this\nprobability vector.",
    "start": "2799170",
    "end": "2807440"
  },
  {
    "text": "So now we have this steady-state\nvector, and then we can solve for the\nsteady-state vector solution.",
    "start": "2807440",
    "end": "2814130"
  },
  {
    "text": "So this pi P is equal to pi.",
    "start": "2814130",
    "end": "2819599"
  },
  {
    "text": "Yeah? Go ahead. AUDIENCE: Where did you prove\nthat the sum of all the pi j's equal to one? Because you say that we\nproved that this is",
    "start": "2819600",
    "end": "2826563"
  },
  {
    "text": "the probability vector. But did prove only that\nit is non-negative? SHAN-YUAN HO: It's\nnon-negative. But the thing is because as n\ngoes to infinity, you have to",
    "start": "2826563",
    "end": "2833090"
  },
  {
    "text": "land up someone, right? This is a finite-state\nMarkov chain. You have to be somewhere.",
    "start": "2833090",
    "end": "2839030"
  },
  {
    "text": "And the fact that you have to be\nsomewhere, your whole state space has to add up to 1. Because it's a constant,\nremember?",
    "start": "2839030",
    "end": "2844550"
  },
  {
    "text": "For every j, as n goes to\ninfinity, it goes to pi sub j. So you have that for\nevery single state.",
    "start": "2844550",
    "end": "2851020"
  },
  {
    "text": "And then you have to\nend up somewhere. So if you have to end up\nsomewhere, the space has to add up to one. Yeah, good question.",
    "start": "2851020",
    "end": "2857980"
  },
  {
    "text": "So why are we interested\nin this pi sub j? The question is that because\nin this recurrent class, it",
    "start": "2857980",
    "end": "2865210"
  },
  {
    "text": "tells us that as this goes to\ninfinity, we see this sequence of states going back and\nforth, back and forth.",
    "start": "2865210",
    "end": "2870880"
  },
  {
    "text": "And we know that as n goes\nto infinity, we have some probability, pi sub j, of\nlanding in state j, pi sub i",
    "start": "2870880",
    "end": "2876285"
  },
  {
    "text": "of landing in state\ni, and so forth. So it says that in the n step,\nas n goes to infinity, that",
    "start": "2876285",
    "end": "2881980"
  },
  {
    "text": "this is the fraction of time\nthat, actually, that state is going to be visited. Because at each step, you have\nto make a transition.",
    "start": "2881980",
    "end": "2888589"
  },
  {
    "text": "So it's kind of the expected\nnumber of times per unit time.",
    "start": "2888590",
    "end": "2895050"
  },
  {
    "text": "So it's divide by n. It's going to be that fraction\nof time that you're going to visit that state. It's the fraction of time\nthat you're going",
    "start": "2895050",
    "end": "2900110"
  },
  {
    "text": "to be in that state. It's this limiting state as\nn gets very, very large.",
    "start": "2900110",
    "end": "2906940"
  },
  {
    "text": "So we will see that in the next\nfew chapters when we do",
    "start": "2906940",
    "end": "2912520"
  },
  {
    "text": "renewal theory that this will\ncome into useful play. And we give a slightly different\nviewpoint of it.",
    "start": "2912520",
    "end": "2919670"
  },
  {
    "text": "So it's very easy to extend this\nresult to a more general class of ergodic unichains. So remember the ergodic\nunichains, now we have",
    "start": "2919670",
    "end": "2926350"
  },
  {
    "text": "increased these transient\nstates. So before, we proved this. We just proved it for it\ncontains exactly one class.",
    "start": "2926350",
    "end": "2933270"
  },
  {
    "text": "It's aperiodic, so we have no\ncycles, no periodicity in this",
    "start": "2933270",
    "end": "2939300"
  },
  {
    "text": "Markov chain. And so we know that the\nsteady-state transition probabilities have a limit.",
    "start": "2939300",
    "end": "2944510"
  },
  {
    "text": "And the upper limit and the\nlower limit of these paths as they go to infinity-- in fact, they end up in\na particular state--",
    "start": "2944510",
    "end": "2949770"
  },
  {
    "text": "has a limit. And we have this steady-state\nprobability vector that describes this.",
    "start": "2949770",
    "end": "2955610"
  },
  {
    "text": "So now we have these\ntransient states. So these transient states of\nthis Markov chain, what happens is there exists a path\nthat this transient state is",
    "start": "2955610",
    "end": "2965480"
  },
  {
    "text": "going to go to a recurrent\nstate. So once it leaves this transient\nstate, it goes to recurrent state.",
    "start": "2965480",
    "end": "2970550"
  },
  {
    "text": "It's never going to come back. So there is some probability,\nalpha, of leaving the",
    "start": "2970550",
    "end": "2980500"
  },
  {
    "text": "class at each step. So there's some transition\nprobability in this transient state that's going\nto be alpha.",
    "start": "2980500",
    "end": "2985630"
  },
  {
    "text": "And the probability of remaining\nin this transient state is just 1 minus\nalpha to the n.",
    "start": "2985630",
    "end": "2990970"
  },
  {
    "text": "And this goes down\nexponentially. So what this says is that\neventually, as n gets very",
    "start": "2990970",
    "end": "2996340"
  },
  {
    "text": "large, it's very, very hard to\nstay in that transient state. So it's going to go out of\nthe transient state. And then it will go into\nthe recurrent class.",
    "start": "2996340",
    "end": "3004900"
  },
  {
    "text": "So when one does the analysis\nfor this, what happens in the probability in this steady-state\nvector is those",
    "start": "3004900",
    "end": "3013960"
  },
  {
    "text": "transient states, this pi,\nwill be equal to 0. So this distribution is only\ngoing to be non-zero for",
    "start": "3013960",
    "end": "3021610"
  },
  {
    "text": "recurrent states in this\nMarkov chains. And the transient states will\nhave probability equal to 0.",
    "start": "3021610",
    "end": "3027510"
  },
  {
    "text": "In the notes, they just\nextend the argument. But you need a little bit\nmore care to show this.",
    "start": "3027510",
    "end": "3035340"
  },
  {
    "text": "And it divides the transient\nstates into a block and then the recurrent classes into\nanother block and then shows",
    "start": "3035340",
    "end": "3040660"
  },
  {
    "text": "that these transient states'\nlimiting probability is going to go to 0.",
    "start": "3040660",
    "end": "3046880"
  },
  {
    "start": "3046880",
    "end": "3052019"
  },
  {
    "text": "So let's see. So this says just what I said,\nthat these transient states",
    "start": "3052020",
    "end": "3059490"
  },
  {
    "text": "decay exponentially, and one\nof the paths will be taken, eventually, out of it. So for ergodic unichains, the\nergodic class is eventually",
    "start": "3059490",
    "end": "3067440"
  },
  {
    "text": "entered, and then steady state\nin that class is reached. So every state j, we\nhave exactly this.",
    "start": "3067440",
    "end": "3073369"
  },
  {
    "text": "The maximum path from\ni to j in n steps-- and the minimum path.",
    "start": "3073370",
    "end": "3079100"
  },
  {
    "text": "We look at the minimum path in\nn steps and the maximum path in n steps. And for each n, we take the\nlimit as n goes to infinity.",
    "start": "3079100",
    "end": "3085820"
  },
  {
    "text": "These guys, these limits are\nexactly equal, and it equals to this pi sub j, which is\nequal to the j state.",
    "start": "3085820",
    "end": "3092680"
  },
  {
    "text": "So your initial states, how you\nwent the paths that you",
    "start": "3092680",
    "end": "3099150"
  },
  {
    "text": "have gone is completely\nwiped out. And all that matters is\nthis final state,",
    "start": "3099150",
    "end": "3104470"
  },
  {
    "text": "as n gets very large. So the difference here is that\npi sub j equals 0 for each transient state, and it's\ngreater than 0 for the",
    "start": "3104470",
    "end": "3111380"
  },
  {
    "text": "recurrent state.  So other finite Markov chains.",
    "start": "3111380",
    "end": "3117580"
  },
  {
    "text": "So we can consider a\nMarkov chain with several ergodic classes. Because we just considered it\nwith one ergodic class.",
    "start": "3117580",
    "end": "3123340"
  },
  {
    "text": "So if the classes don't\ncommunicate, then you just consider it separately. So you figure out the\nsteady-state transition",
    "start": "3123340",
    "end": "3128920"
  },
  {
    "text": "probabilities for each of\nthe classes separately. But if you have to insist on\nanalyzing the entire chain P,",
    "start": "3128920",
    "end": "3137079"
  },
  {
    "text": "then this P will have m\nindependent steady-state vectors and one non-zero\nin each class.",
    "start": "3137080",
    "end": "3149180"
  },
  {
    "text": "So this P sub n is still going\nto converge, but the rows are not going to be the same. So basically, you're going\nto have blocks.",
    "start": "3149180",
    "end": "3155210"
  },
  {
    "text": "So if you have one class, say 1\nthrough k is going to be in one class, and then k through\nl is going to be another",
    "start": "3155210",
    "end": "3161680"
  },
  {
    "text": "class, and then l through z is\ngoing to another class, you have a block. So this steady-state vector\nis going to be in blocks.",
    "start": "3161680",
    "end": "3169170"
  },
  {
    "text": " So you can see the recurring\nclasses only communicate",
    "start": "3169170",
    "end": "3176480"
  },
  {
    "text": "within themselves. Because these don't communicate, so they're separate.",
    "start": "3176480",
    "end": "3181570"
  },
  {
    "text": "So you could have a lot of 0's\nin limiting state, if you look",
    "start": "3181570",
    "end": "3191450"
  },
  {
    "text": "at this, P sub n goes\nto infinity. So there m set of rows,\none for each class.",
    "start": "3191450",
    "end": "3198010"
  },
  {
    "text": "And a row for each class k\nwill be non-zero for the elements of that class. So then finally, if we\nhave periodicity.",
    "start": "3198010",
    "end": "3206350"
  },
  {
    "text": "So now if we have a periodic\nrecurrent chain with period d.",
    "start": "3206350",
    "end": "3212540"
  },
  {
    "text": "We had the two where it's\njust a period of 2. So with periodicity, what you\ndo is you're going to divide",
    "start": "3212540",
    "end": "3219130"
  },
  {
    "text": "these classes into d\ndifferent states. So you have to go\nto one state--",
    "start": "3219130",
    "end": "3224880"
  },
  {
    "text": "So if there's d states, this is\na period of d, you separate",
    "start": "3224880",
    "end": "3230069"
  },
  {
    "text": "or you partition the states into\nd of them, d subclasses, with a cycle rotation\nbetween them.",
    "start": "3230070",
    "end": "3236190"
  },
  {
    "text": "So basically, each time unit,\nyou have to go from one class to the next class.",
    "start": "3236190",
    "end": "3241910"
  },
  {
    "text": "And then we do that, then for\neach class, you could have the limiting-state probability.",
    "start": "3241910",
    "end": "3247210"
  },
  {
    "text": "So in other words, you are\nlooking at this transition matrix, pi d.",
    "start": "3247210",
    "end": "3253460"
  },
  {
    "text": "Because when it cycles, it\ntotally depends on which one you start out at. But if you look at the d\nintervals, then that becomes",
    "start": "3253460",
    "end": "3262560"
  },
  {
    "text": "the ergodic class by itself. And there are exactly\nd of them. So the limit as n approaches\ninfinity of P of nd, this",
    "start": "3262560",
    "end": "3271019"
  },
  {
    "text": "thing also exists, but exists in\nthe subclass sense of there",
    "start": "3271020",
    "end": "3276220"
  },
  {
    "text": "is d subclasses if it\nhas a period of d. So that means a steady state\nis reached within each",
    "start": "3276220",
    "end": "3282570"
  },
  {
    "text": "subclass, but the chain\nrotates from one subclass to another. Yeah, go ahead.",
    "start": "3282570",
    "end": "3287950"
  },
  {
    "text": "AUDIENCE: In this case, if we\ndo a simple check with 1 and 2, with 1 and 1, it\ndoesn't converge. SHAN-YUAN HO: No, it does.",
    "start": "3287950",
    "end": "3293570"
  },
  {
    "text": "It is 1, converges to 1. So it's 1, and then it's\ngoing to be 1.",
    "start": "3293570",
    "end": "3298740"
  },
  {
    "text": "AUDIENCE: It's 1, 1,\n1, 1, 1, 1, 1, 1. So you go here? Like, it's reached--? SHAN-YUAN HO: No, no. It converges for here.",
    "start": "3298740",
    "end": "3304790"
  },
  {
    "text": "But this d is equal to\n2, in that case. So you have to do nd,\nso you've got",
    "start": "3304790",
    "end": "3310534"
  },
  {
    "text": "to look at P squared. So if I look at P squared,\nI'm always a 1-- 1, 1, 1, 1, 1, 1, 1, 1.",
    "start": "3310534",
    "end": "3316195"
  },
  {
    "text": "That's converging. The other one is 2,\n2, 2, 2, 2, 2. That's also converging. ",
    "start": "3316196",
    "end": "3323690"
  },
  {
    "text": "OK. So is there any other questions\nabout this?  OK, that's it.",
    "start": "3323690",
    "end": "3330050"
  },
  {
    "text": "Thank you. ",
    "start": "3330050",
    "end": "3333780"
  }
]
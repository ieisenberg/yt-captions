[
  {
    "start": "0",
    "end": "700"
  },
  {
    "text": "We are now ready to\nmove on to a model which",
    "start": "700",
    "end": "3880"
  },
  {
    "text": "is quite interesting\nand quite realistic.",
    "start": "3880",
    "end": "7240"
  },
  {
    "text": "This is a model in which we have\nan unknown parameter modeled",
    "start": "7240",
    "end": "11900"
  },
  {
    "text": "as a random variable\nthat we try to estimate.",
    "start": "11900",
    "end": "14969"
  },
  {
    "text": "This is the random\nvariable, Theta.",
    "start": "14970",
    "end": "17080"
  },
  {
    "text": "And we have multiple\nobservations",
    "start": "17080",
    "end": "18880"
  },
  {
    "text": "of that random variable.",
    "start": "18880",
    "end": "20539"
  },
  {
    "text": "Each one of those\nobservations is",
    "start": "20540",
    "end": "22380"
  },
  {
    "text": "equal to the unknown\nrandom variable,",
    "start": "22380",
    "end": "24720"
  },
  {
    "text": "plus some additive noise.",
    "start": "24720",
    "end": "27490"
  },
  {
    "text": "This is a model that appears\nquite often in practice.",
    "start": "27490",
    "end": "30900"
  },
  {
    "text": "It is often the case\nthat we're trying",
    "start": "30900",
    "end": "32508"
  },
  {
    "text": "to estimate a certain\nquantity, but we can only",
    "start": "32509",
    "end": "35730"
  },
  {
    "text": "observe values of that quantity\nin the presence of noise.",
    "start": "35730",
    "end": "39300"
  },
  {
    "text": "And because of the\nnoise, what we want to do",
    "start": "39300",
    "end": "42129"
  },
  {
    "text": "is to try to measure\nit to multiple times.",
    "start": "42130",
    "end": "45280"
  },
  {
    "text": "And so we have multiple\nsuch measurement equations.",
    "start": "45280",
    "end": "48469"
  },
  {
    "text": "And then we want to combine all\nof the observations together",
    "start": "48470",
    "end": "52020"
  },
  {
    "text": "to come up with a good\nestimate of that parameter.",
    "start": "52020",
    "end": "56340"
  },
  {
    "text": "The assumption that\nwe will be making",
    "start": "56340",
    "end": "58440"
  },
  {
    "text": "are that Theta is a\nnormal random variable.",
    "start": "58440",
    "end": "61949"
  },
  {
    "text": "It has a certain mean\nthat we denote by x0.",
    "start": "61950",
    "end": "65018"
  },
  {
    "text": "The reason for this strange\nnotation will be seen later.",
    "start": "65019",
    "end": "68030"
  },
  {
    "text": "And it also has a\ncertain variance.",
    "start": "68030",
    "end": "70799"
  },
  {
    "text": "The noise terms are also\nnormal random variables",
    "start": "70800",
    "end": "74130"
  },
  {
    "text": "with 0 mean and a\ncertain variance.",
    "start": "74130",
    "end": "77360"
  },
  {
    "text": "And finally, we assume that\nthese basic random variables",
    "start": "77360",
    "end": "81300"
  },
  {
    "text": "that define our model\nare all independent.",
    "start": "81300",
    "end": "86240"
  },
  {
    "text": "Based on these assumptions, now\nwe would like to estimate Theta",
    "start": "86240",
    "end": "89680"
  },
  {
    "text": "on the basis of the X's.",
    "start": "89680",
    "end": "92840"
  },
  {
    "text": "And as usual, in the\nBayesian setting,",
    "start": "92840",
    "end": "96140"
  },
  {
    "text": "what we want to do is to\ncalculate the posterior",
    "start": "96140",
    "end": "98759"
  },
  {
    "text": "distribution of\nTheta, given the X's.",
    "start": "98759",
    "end": "102360"
  },
  {
    "text": "The Bayes rule\nhas the usual form",
    "start": "102360",
    "end": "105090"
  },
  {
    "text": "for the case of continuous\nrandom variables.",
    "start": "105090",
    "end": "107590"
  },
  {
    "text": "The only remark that needs to\nbe made is that in this case,",
    "start": "107590",
    "end": "111740"
  },
  {
    "text": "there are multiple X's,\nso X up here stands",
    "start": "111740",
    "end": "115729"
  },
  {
    "text": "for the vector of\nthe observations",
    "start": "115729",
    "end": "118265"
  },
  {
    "text": "that we have obtained.",
    "start": "118265",
    "end": "119920"
  },
  {
    "text": "And similarly,\nlittle x will stand",
    "start": "119920",
    "end": "122159"
  },
  {
    "text": "for the vector of the values\nof these observations.",
    "start": "122160",
    "end": "126260"
  },
  {
    "text": "So we need now to start\nmaking some progress",
    "start": "126260",
    "end": "129070"
  },
  {
    "text": "towards calculating\nthis term here.",
    "start": "129070",
    "end": "131810"
  },
  {
    "text": "What is the distribution of\nthe vector of measurements",
    "start": "131810",
    "end": "135080"
  },
  {
    "text": "given theta.",
    "start": "135080",
    "end": "136600"
  },
  {
    "text": "Before we move to\nthe vector case,",
    "start": "136600",
    "end": "139030"
  },
  {
    "text": "let us look at one of the\nmeasurements in isolation.",
    "start": "139030",
    "end": "143569"
  },
  {
    "text": "This is something that\nwe have already seen.",
    "start": "143570",
    "end": "146600"
  },
  {
    "text": "If I tell you the value\nof the random variable,",
    "start": "146600",
    "end": "150770"
  },
  {
    "text": "Theta, which is what happens\nin this conditional universe",
    "start": "150770",
    "end": "155210"
  },
  {
    "text": "when you condition on\nthe value of Theta,",
    "start": "155210",
    "end": "158270"
  },
  {
    "text": "then in that universe,\nthe random variable, Xi,",
    "start": "158270",
    "end": "162300"
  },
  {
    "text": "is equal to the numerical\nvalue that you gave me",
    "start": "162300",
    "end": "165610"
  },
  {
    "text": "for Theta, plus Wi.",
    "start": "165610",
    "end": "167460"
  },
  {
    "start": "167460",
    "end": "170329"
  },
  {
    "text": "And because Wi is independent\nfrom the random variable Theta,",
    "start": "170329",
    "end": "175360"
  },
  {
    "text": "knowing the value of\nthe random variable",
    "start": "175360",
    "end": "177579"
  },
  {
    "text": "Theta does not change\nthe distribution of Wi.",
    "start": "177579",
    "end": "180299"
  },
  {
    "text": "It will still have this\nnormal distribution.",
    "start": "180300",
    "end": "182990"
  },
  {
    "text": "So Xi is a normal of this\nkind plus a constant.",
    "start": "182990",
    "end": "188580"
  },
  {
    "text": "And so Xi is a normal\nrandom variable",
    "start": "188580",
    "end": "192780"
  },
  {
    "text": "with mean equal to the\nconstant that we added,",
    "start": "192780",
    "end": "196470"
  },
  {
    "text": "and variance equal to\nthe original variance",
    "start": "196470",
    "end": "199020"
  },
  {
    "text": "of the random variable, Wi.",
    "start": "199020",
    "end": "201420"
  },
  {
    "text": "And so we can now write down,\nthe PDF, the conditional PDF,",
    "start": "201420",
    "end": "205750"
  },
  {
    "text": "of Xi.",
    "start": "205750",
    "end": "207325"
  },
  {
    "text": "There's going to be a\nnormalizing constant.",
    "start": "207325",
    "end": "210140"
  },
  {
    "text": "And then the usual\nexponential term,",
    "start": "210140",
    "end": "212700"
  },
  {
    "text": "which is going to be xi minus\nthe mean of the distribution,",
    "start": "212700",
    "end": "219730"
  },
  {
    "text": "which is theta.",
    "start": "219730",
    "end": "222704"
  },
  {
    "text": "And then we divide by\nthe usual variance term.",
    "start": "222704",
    "end": "225620"
  },
  {
    "start": "225620",
    "end": "228280"
  },
  {
    "text": "Let us move next to\nthis distribution here.",
    "start": "228280",
    "end": "233730"
  },
  {
    "text": "This is a shorthand\nnotation for the joint PDF",
    "start": "233730",
    "end": "238940"
  },
  {
    "text": "of the random\nvariables X1 up to Xn,",
    "start": "238940",
    "end": "243480"
  },
  {
    "text": "conditional on the\nrandom variable Theta.",
    "start": "243480",
    "end": "247610"
  },
  {
    "text": "So it's really a function\nof multiple variables.",
    "start": "247610",
    "end": "251446"
  },
  {
    "start": "251446",
    "end": "254990"
  },
  {
    "text": "And how do we proceed now?",
    "start": "254990",
    "end": "257820"
  },
  {
    "text": "Here is the crucial observation.",
    "start": "257820",
    "end": "260898"
  },
  {
    "text": "If I tell you the value of\nthe random variable capital",
    "start": "260899",
    "end": "266090"
  },
  {
    "text": "Theta as before, then\nyou argue as follows.",
    "start": "266090",
    "end": "272400"
  },
  {
    "text": "All of these random\nvariables are independent.",
    "start": "272400",
    "end": "275460"
  },
  {
    "text": "So if I tell you the value\nof the random variable Theta,",
    "start": "275460",
    "end": "279180"
  },
  {
    "text": "this does not change the joint\ndistribution of the Wi's.",
    "start": "279180",
    "end": "283490"
  },
  {
    "text": "The Wi's were independent\nwhen we started,",
    "start": "283490",
    "end": "286680"
  },
  {
    "text": "so they remain independent\nin the conditional universe.",
    "start": "286680",
    "end": "290000"
  },
  {
    "start": "290000",
    "end": "298630"
  },
  {
    "text": "And since the Wi's\nare independent",
    "start": "298630",
    "end": "301110"
  },
  {
    "text": "and Xi's are obtained from the\nWi's by just adding a constant,",
    "start": "301110",
    "end": "305560"
  },
  {
    "text": "this means that\nthe Xi's are also",
    "start": "305560",
    "end": "309669"
  },
  {
    "text": "independent in this\nconditional universe.",
    "start": "309670",
    "end": "313420"
  },
  {
    "text": "Once I tell you\nthe value of Theta,",
    "start": "313420",
    "end": "316080"
  },
  {
    "text": "then because the\nnoises are independent,",
    "start": "316080",
    "end": "318490"
  },
  {
    "text": "the observations are\nalso independent.",
    "start": "318490",
    "end": "321460"
  },
  {
    "text": "But this means that the joint\nPDF factors as a product",
    "start": "321460",
    "end": "327810"
  },
  {
    "text": "of the individual\nmarginal PDFs of the Xi's.",
    "start": "327810",
    "end": "332330"
  },
  {
    "start": "332330",
    "end": "337900"
  },
  {
    "text": "And these PDFs, we\nhave already found.",
    "start": "337900",
    "end": "341540"
  },
  {
    "text": "So now, we can put\neverything together",
    "start": "341540",
    "end": "344409"
  },
  {
    "text": "to write down a formula\nfor the posterior PDF",
    "start": "344409",
    "end": "348560"
  },
  {
    "text": "using the Bayes rule.",
    "start": "348560",
    "end": "350400"
  },
  {
    "text": "We have this denominator term,\nwhich I will write first,",
    "start": "350400",
    "end": "357300"
  },
  {
    "text": "and which term we do\nnot need to evaluate.",
    "start": "357300",
    "end": "360580"
  },
  {
    "text": "Then we have the\nmarginal PDF of Theta.",
    "start": "360580",
    "end": "364319"
  },
  {
    "text": "Now since Theta is normal\nwith these parameters,",
    "start": "364320",
    "end": "368440"
  },
  {
    "text": "this is of the form e to\nthe minus theta minus x0",
    "start": "368440",
    "end": "376120"
  },
  {
    "text": "squared over 2 sigma 0 squared.",
    "start": "376120",
    "end": "381690"
  },
  {
    "text": "And then we have this joint\ndensity of the X's conditioned",
    "start": "381690",
    "end": "387500"
  },
  {
    "text": "on Theta, which we have already\nfound, it is this product here.",
    "start": "387500",
    "end": "392840"
  },
  {
    "text": "It's a product of n terms,\none for each observation.",
    "start": "392840",
    "end": "396710"
  },
  {
    "text": "And each one of these terms\nis what we have found earlier,",
    "start": "396710",
    "end": "400479"
  },
  {
    "text": "so I'm just substituting\nthis expression up here.",
    "start": "400480",
    "end": "403780"
  },
  {
    "start": "403780",
    "end": "412060"
  },
  {
    "text": "Now once we have obtained the\nobservations, so the value",
    "start": "412060",
    "end": "416389"
  },
  {
    "text": "of the random variable capital\nX, that is, the value little x,",
    "start": "416390",
    "end": "420130"
  },
  {
    "text": "is fixed.",
    "start": "420130",
    "end": "421710"
  },
  {
    "text": "Once it is fixed, then the x's\nthat appear here are constant.",
    "start": "421710",
    "end": "427430"
  },
  {
    "text": "So in particular, this\nterm here is a constant.",
    "start": "427430",
    "end": "431039"
  },
  {
    "text": "We do not bother with it.",
    "start": "431040",
    "end": "432840"
  },
  {
    "text": "And what we have is a constant\ntimes an exponential in terms",
    "start": "432840",
    "end": "439030"
  },
  {
    "text": "that are quadratic in theta.",
    "start": "439030",
    "end": "441720"
  },
  {
    "text": "So we recognize this\nkind of expression.",
    "start": "441720",
    "end": "445020"
  },
  {
    "text": "It has to correspond to\na normal distribution.",
    "start": "445020",
    "end": "449410"
  },
  {
    "text": "And this is the first\nconclusion of this exercise.",
    "start": "449410",
    "end": "454120"
  },
  {
    "text": "That is, the posterior PDF\nof the parameter, Theta,",
    "start": "454120",
    "end": "458770"
  },
  {
    "text": "given our observations, this\nposterior PDF is normal.",
    "start": "458770",
    "end": "463560"
  },
  {
    "text": "We have e to a quadratic\nfunction in theta.",
    "start": "463560",
    "end": "467889"
  },
  {
    "text": "And that quadratic\nfunction also involves",
    "start": "467890",
    "end": "470080"
  },
  {
    "text": "the specific values of the\nX's that we have obtained.",
    "start": "470080",
    "end": "473659"
  },
  {
    "text": "Let us copy what we have\nfound and rearrange it.",
    "start": "473659",
    "end": "477710"
  },
  {
    "text": "Once more, we have a\nconstant, then the exponential",
    "start": "477710",
    "end": "482430"
  },
  {
    "text": "of the negative of some\nquadratic function in theta.",
    "start": "482430",
    "end": "486169"
  },
  {
    "text": "And the specific\nquadratic function",
    "start": "486170",
    "end": "487955"
  },
  {
    "text": "that we calculated just before\ntakes this particular form.",
    "start": "487955",
    "end": "495370"
  },
  {
    "text": "What is the mean of this\nnormal distribution?",
    "start": "495370",
    "end": "499250"
  },
  {
    "text": "The mean is same as the peak.",
    "start": "499250",
    "end": "503340"
  },
  {
    "text": "And to find the peak, the\nlocation at which this PDF is",
    "start": "503340",
    "end": "510180"
  },
  {
    "text": "largest, what we do\nis we try to find",
    "start": "510180",
    "end": "514940"
  },
  {
    "text": "the place at which this\nquadratic function is smallest.",
    "start": "514940",
    "end": "519190"
  },
  {
    "text": "So what we do is to take\nthe derivative with respect",
    "start": "519190",
    "end": "522890"
  },
  {
    "text": "to theta of this\nquadratic, and set it to 0.",
    "start": "522890",
    "end": "530520"
  },
  {
    "text": "This gives us a sum of terms.",
    "start": "530520",
    "end": "534530"
  },
  {
    "text": "The derivative of\nthe typical term",
    "start": "534530",
    "end": "539970"
  },
  {
    "text": "is going to be theta minus xi,\ndivided by sigma i squared.",
    "start": "539970",
    "end": "554970"
  },
  {
    "text": "And this expression\nmust be equal to 0",
    "start": "554970",
    "end": "558339"
  },
  {
    "text": "if theta is at the peak of\nthe posterior distribution.",
    "start": "558340",
    "end": "563440"
  },
  {
    "text": "And so we now rearrange\nthis equation.",
    "start": "563440",
    "end": "566930"
  },
  {
    "text": "We split and take first\nthe term involving theta,",
    "start": "566930",
    "end": "570700"
  },
  {
    "text": "and gives us a\ncontribution of this kind.",
    "start": "570700",
    "end": "573465"
  },
  {
    "start": "573465",
    "end": "579190"
  },
  {
    "text": "And we move the terms involving\nx's to the other side.",
    "start": "579190",
    "end": "583160"
  },
  {
    "text": "And this gives us\nthis expression.",
    "start": "583160",
    "end": "585365"
  },
  {
    "start": "585365",
    "end": "590830"
  },
  {
    "text": "And finally, we\ntake this sum here",
    "start": "590830",
    "end": "592960"
  },
  {
    "text": "and send it to the\ndenominator of the other side.",
    "start": "592960",
    "end": "596630"
  },
  {
    "text": "And this gives us the\nfinal form of the solution:",
    "start": "596630",
    "end": "600940"
  },
  {
    "text": "the peak of the posterior\ndistribution, which is also",
    "start": "600940",
    "end": "605280"
  },
  {
    "text": "the same as the conditional\nexpectation of the posterior",
    "start": "605280",
    "end": "608400"
  },
  {
    "text": "distribution.",
    "start": "608400",
    "end": "609240"
  },
  {
    "text": "Whenever we have a\nnormal distribution,",
    "start": "609240",
    "end": "612670"
  },
  {
    "text": "the expected value is\nthe same as the place",
    "start": "612670",
    "end": "615550"
  },
  {
    "text": "where the distribution\nis largest.",
    "start": "615550",
    "end": "617390"
  },
  {
    "start": "617390",
    "end": "621280"
  },
  {
    "text": "Let us now conclude with a few\ncomments and words about how",
    "start": "621280",
    "end": "625000"
  },
  {
    "text": "to interpret the\nresult that we found.",
    "start": "625000",
    "end": "628120"
  },
  {
    "text": "First, let me emphasize that the\nsame conclusions that we have",
    "start": "628120",
    "end": "632210"
  },
  {
    "text": "obtained for the case\nof a single observation",
    "start": "632210",
    "end": "635680"
  },
  {
    "text": "go through in this case as well.",
    "start": "635680",
    "end": "640110"
  },
  {
    "text": "The posterior distribution\nof the unknown parameter",
    "start": "640110",
    "end": "643250"
  },
  {
    "text": "is still a normal distribution.",
    "start": "643250",
    "end": "647480"
  },
  {
    "text": "Our state of\nknowledge about Theta",
    "start": "647480",
    "end": "649860"
  },
  {
    "text": "after we obtain\nthe observations is",
    "start": "649860",
    "end": "652000"
  },
  {
    "text": "described by a\nnormal distribution.",
    "start": "652000",
    "end": "654450"
  },
  {
    "text": "Because it is a\nnormal distribution,",
    "start": "654450",
    "end": "656190"
  },
  {
    "text": "the location of its peak is\nthe same as the expected value.",
    "start": "656190",
    "end": "660690"
  },
  {
    "text": "And for this reason, the\nconditional expectation",
    "start": "660690",
    "end": "663070"
  },
  {
    "text": "estimate and the maximum\na posteriori probability",
    "start": "663070",
    "end": "665640"
  },
  {
    "text": "estimates coincide.",
    "start": "665640",
    "end": "667490"
  },
  {
    "text": "And finally, the form of\nthe estimates that we get is",
    "start": "667490",
    "end": "671760"
  },
  {
    "text": "a linear function in the xi's.",
    "start": "671760",
    "end": "676700"
  },
  {
    "text": "And this linearity is a very\nconvenient property to have,",
    "start": "676700",
    "end": "680430"
  },
  {
    "text": "because it allows\nfurther analysis",
    "start": "680430",
    "end": "683180"
  },
  {
    "text": "of these ways of\nobtaining estimates.",
    "start": "683180",
    "end": "686630"
  },
  {
    "text": "How do we interpret\nthis formula?",
    "start": "686630",
    "end": "690620"
  },
  {
    "text": "What we have here\nis the following.",
    "start": "690620",
    "end": "693529"
  },
  {
    "text": "Each one of the\nxi's gets multiplied",
    "start": "693530",
    "end": "695880"
  },
  {
    "text": "by a certain coefficient,\nwhich is 1 over the variance.",
    "start": "695880",
    "end": "699760"
  },
  {
    "text": "And in the denominator,\nwe have the sum",
    "start": "699760",
    "end": "702750"
  },
  {
    "text": "of all of those coefficients.",
    "start": "702750",
    "end": "704870"
  },
  {
    "text": "So what we really have here is\na weighted average of the xi's.",
    "start": "704870",
    "end": "710110"
  },
  {
    "text": "Now keep in mind that\nthose xi's are not",
    "start": "710110",
    "end": "712720"
  },
  {
    "text": "all of them of the same kind.",
    "start": "712720",
    "end": "714519"
  },
  {
    "text": "One term is x0, which\nis the prior mean,",
    "start": "714520",
    "end": "718170"
  },
  {
    "text": "whereas the remaining xi's are\nthe values of the observations.",
    "start": "718170",
    "end": "722470"
  },
  {
    "text": "So there's something\ninteresting happening here.",
    "start": "722470",
    "end": "725079"
  },
  {
    "text": "We combine the values\nof the observations",
    "start": "725080",
    "end": "728350"
  },
  {
    "text": "with the value of\nthe prior mean.",
    "start": "728350",
    "end": "730790"
  },
  {
    "text": "And in some sense,\nthe prior mean",
    "start": "730790",
    "end": "732899"
  },
  {
    "text": "is treated as just one\nmore piece of information",
    "start": "732900",
    "end": "737200"
  },
  {
    "text": "available to us.",
    "start": "737200",
    "end": "739010"
  },
  {
    "text": "And it is treated in\na sort of equal way",
    "start": "739010",
    "end": "743100"
  },
  {
    "text": "as the other observations.",
    "start": "743100",
    "end": "746060"
  },
  {
    "text": "The weight that we have\nin this weighted average",
    "start": "746060",
    "end": "749980"
  },
  {
    "text": "are that each xi gets divided\nby the corresponding variance.",
    "start": "749980",
    "end": "756410"
  },
  {
    "text": "Does this make sense?",
    "start": "756410",
    "end": "758129"
  },
  {
    "text": "Well, suppose that sigma\ni squared is large.",
    "start": "758130",
    "end": "762090"
  },
  {
    "start": "762090",
    "end": "765290"
  },
  {
    "text": "This means that the noise\nterm Wi is very large.",
    "start": "765290",
    "end": "769300"
  },
  {
    "text": "So Xi is very noisy.",
    "start": "769300",
    "end": "773190"
  },
  {
    "text": "And so it's not a useful\nobservation to have.",
    "start": "773190",
    "end": "776940"
  },
  {
    "text": "And in that case, it\ngets a small weight.",
    "start": "776940",
    "end": "780590"
  },
  {
    "start": "780590",
    "end": "783320"
  },
  {
    "text": "So the weights are\ndetermined by the variances",
    "start": "783320",
    "end": "786510"
  },
  {
    "text": "in a way that is quite sensible.",
    "start": "786510",
    "end": "789480"
  },
  {
    "text": "Those observations that\nwill get the most weight",
    "start": "789480",
    "end": "792350"
  },
  {
    "text": "will be those observations for\nwhich the corresponding noise",
    "start": "792350",
    "end": "795730"
  },
  {
    "text": "variance is small.",
    "start": "795730",
    "end": "798760"
  },
  {
    "text": "So the solution to this\nestimation problem that we just",
    "start": "798760",
    "end": "802280"
  },
  {
    "text": "went through has\nmany nice properties.",
    "start": "802280",
    "end": "806350"
  },
  {
    "text": "First, we stay within the world\nof normal random variables,",
    "start": "806350",
    "end": "810959"
  },
  {
    "text": "because even the\nposterior is normal.",
    "start": "810960",
    "end": "813760"
  },
  {
    "text": "We stay within the world\nof linear functions",
    "start": "813760",
    "end": "816540"
  },
  {
    "text": "of normal random\nvariables, and the form",
    "start": "816540",
    "end": "819589"
  },
  {
    "text": "of the formula that\nwe have, itself,",
    "start": "819590",
    "end": "822670"
  },
  {
    "text": "has an appealing\nintuitive content.",
    "start": "822670",
    "end": "826120"
  }
]
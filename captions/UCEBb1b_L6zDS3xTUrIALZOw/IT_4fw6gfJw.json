[
  {
    "start": "0",
    "end": "47000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18140",
    "end": "23419"
  },
  {
    "text": "JULIAN SHUN: Hi, good\nafternoon, everyone. So today, we're\ngoing to be talking about graph optimizations.",
    "start": "23420",
    "end": "30650"
  },
  {
    "text": "And as a reminder,\non Thursday, we're going to have a guest lecture\nby Professor Johnson of the MIT",
    "start": "30650",
    "end": "36980"
  },
  {
    "text": "Math Department. And he'll be talking\nabout performance of high-level languages. So please be sure to attend\nthe guest lecture on Thursday.",
    "start": "36980",
    "end": "46670"
  },
  {
    "text": "So here's an outline\nof what I'm going to be talking about today. So we're first going to remind\nourselves what a graph is.",
    "start": "46670",
    "end": "54480"
  },
  {
    "start": "47000",
    "end": "47000"
  },
  {
    "text": "And then we're going to\ntalk about various ways to represent a graph in memory.",
    "start": "54480",
    "end": "60880"
  },
  {
    "text": "And then we'll talk\nabout how to implement an efficient breadth-first\nsearch algorithm, both serially",
    "start": "60880",
    "end": "66470"
  },
  {
    "text": "and also in parallel. And then I'll talk about how to\nuse graph compression and graph",
    "start": "66470",
    "end": "72810"
  },
  {
    "text": "reordering to improve the\nlocality of graph algorithms. ",
    "start": "72810",
    "end": "78409"
  },
  {
    "start": "78000",
    "end": "78000"
  },
  {
    "text": "So first of all,\nwhat is a graph? So a graph contains\nvertices and edges,",
    "start": "78410",
    "end": "84410"
  },
  {
    "text": "where vertices represent\ncertain objects of interest, and edges between objects model\nrelationships between the two",
    "start": "84410",
    "end": "92329"
  },
  {
    "text": "objects. For example, you can\nhave a social network, where the people are\nrepresented as vertices",
    "start": "92330",
    "end": "99290"
  },
  {
    "text": "and edges between\npeople mean that they're friends with each other.",
    "start": "99290",
    "end": "104390"
  },
  {
    "text": "The edges in this graph don't\nhave to be bi-directional. So you could have a\none-way relationship.",
    "start": "104390",
    "end": "111260"
  },
  {
    "text": "For example, if you're looking\nat the Twitter network, Alice could follow Bob,\nbut Bob doesn't necessarily have to follow Alice back.",
    "start": "111260",
    "end": "118790"
  },
  {
    "text": "The graph also doesn't\nhave to be connected. So here, this graph\nhere is connected.",
    "start": "118790",
    "end": "124160"
  },
  {
    "text": "But, for example, there\ncould be some people who don't like to\ntalk to other people.",
    "start": "124160",
    "end": "129919"
  },
  {
    "text": "And then they're just off\nin their own component. You can also use graphs to\nmodel protein networks, where",
    "start": "129919",
    "end": "137060"
  },
  {
    "text": "the vertices are proteins,\nand edges between vertices means that there's some\nsort of interaction",
    "start": "137060",
    "end": "142190"
  },
  {
    "text": "between the proteins. So this is useful in\ncomputational biology.",
    "start": "142190",
    "end": "147560"
  },
  {
    "text": "As I said, edges\ncan be directed, so their relationship can\ngo one way or both ways.",
    "start": "147560",
    "end": "153290"
  },
  {
    "text": "In this graph here, we have some\ndirected edges and then also some edges that are\ndirected in both directions.",
    "start": "153290",
    "end": "160620"
  },
  {
    "text": "So here, John follows Alice. Alice follows Peter. And then Alice follows Bob,\nand Bob also follows Alice.",
    "start": "160620",
    "end": "169130"
  },
  {
    "text": "If you use a graph to\nrepresent the world wide web, then the vertices\nwould be websites,",
    "start": "169130",
    "end": "174470"
  },
  {
    "text": "and then the edges would denote\nthat there is a hyperlink from one website to another.",
    "start": "174470",
    "end": "180360"
  },
  {
    "text": "And again, the edges here\ndon't have to be bi-directional because website A could\nhave a link to website B.",
    "start": "180360",
    "end": "186200"
  },
  {
    "text": "But website B\ndoesn't necessarily have to have a link back. Edges can also be weighted.",
    "start": "186200",
    "end": "192382"
  },
  {
    "text": "So you can have a\nweight on the edge that denotes the strength\nof the relationship or some sort of distance\nmeasure corresponding",
    "start": "192382",
    "end": "199850"
  },
  {
    "text": "to that relationship. So here, I have an example\nwhere I am using a graph",
    "start": "199850",
    "end": "206180"
  },
  {
    "text": "to represent cities. And the edges\nbetween cities have",
    "start": "206180",
    "end": "211340"
  },
  {
    "text": "a weight that corresponds to\nthe distance between the two cities. And if I want to find the\nquickest way to get from city A",
    "start": "211340",
    "end": "218255"
  },
  {
    "text": "to city B, then I would\nbe interested in finding the shortest path from A\nto B in this graph here.",
    "start": "218255",
    "end": "224599"
  },
  {
    "text": " Here's another example,\nwhere the edge weights now",
    "start": "224600",
    "end": "230340"
  },
  {
    "text": "are the costs of a direct\nflight from city A to city B. And here the edges are directed.",
    "start": "230340",
    "end": "235500"
  },
  {
    "text": "So, for example, this\nsays that there's a flight from San\nFrancisco to LA for $45.",
    "start": "235500",
    "end": "241079"
  },
  {
    "text": "And if I want to\nfind the cheapest way to get from one\ncity to another city,",
    "start": "241080",
    "end": "246450"
  },
  {
    "text": "then, again, I would try to find\nthe shortest path in this graph from city A to city B.",
    "start": "246450",
    "end": "254800"
  },
  {
    "text": "Vertices and edges can\nalso have metadata on them, and they can also have types.",
    "start": "254800",
    "end": "260088"
  },
  {
    "text": "So, for example, here's\nthe Google Knowledge Graph, which represents all the\nknowledge on the internet",
    "start": "260089",
    "end": "265360"
  },
  {
    "text": "that Google knows about. And here, the nodes\nhave metadata on them. So, for example, the node\ncorresponding to da Vinci",
    "start": "265360",
    "end": "272740"
  },
  {
    "text": "is labeled with his date\nof birth and date of death. And the vertices\nalso have a color",
    "start": "272740",
    "end": "278880"
  },
  {
    "text": "corresponding to the type of\nknowledge that they refer to.",
    "start": "278880",
    "end": "284788"
  },
  {
    "text": "So you can see that some\nof these nodes are blue, some of them are red,\nsome of them are green, and some of them have\nother things on them.",
    "start": "284788",
    "end": "291780"
  },
  {
    "text": "So in general, graphs can\nhave types and metadata on both the vertices\nas well as the edges.",
    "start": "291780",
    "end": "296895"
  },
  {
    "text": " Let's look at some more\napplications of graphs.",
    "start": "296895",
    "end": "303580"
  },
  {
    "start": "303000",
    "end": "303000"
  },
  {
    "text": "So graphs are very useful\nfor implementing queries on social networks.",
    "start": "303580",
    "end": "309920"
  },
  {
    "text": "So here are some\nexamples of queries that you might want to\nask on a social network. So, for example, you might\nbe interested in finding",
    "start": "309920",
    "end": "316270"
  },
  {
    "text": "all of your friends who went\nto the same high school as you on Facebook. So that can be implemented\nusing a graph algorithm.",
    "start": "316270",
    "end": "324710"
  },
  {
    "text": "You might also be\ninterested in finding all of the common friends\nyou have with somebody else-- again, a graph algorithm.",
    "start": "324710",
    "end": "331680"
  },
  {
    "text": "And a social network service\nmight run a graph algorithm to recommend people that\nyou might know and want",
    "start": "331680",
    "end": "337750"
  },
  {
    "text": "to become friends with. And they might use\na graph algorithm to recommend certain\nproducts that you",
    "start": "337750",
    "end": "343479"
  },
  {
    "text": "might be interested in. So these are all examples\nof social network queries. And there are many\nother queries that you",
    "start": "343480",
    "end": "349780"
  },
  {
    "text": "might be interested in\nrunning on a social network. And many of them\ncan be implemented using graph algorithms.",
    "start": "349780",
    "end": "357580"
  },
  {
    "start": "357000",
    "end": "357000"
  },
  {
    "text": "Another important\napplication is clustering. So here, the goal is to\nfind groups of vertices in a graph that\nare well-connected",
    "start": "357580",
    "end": "363940"
  },
  {
    "text": "internally and\npoorly-connected externally. So in this image here, each blob\nof vertices of the same color",
    "start": "363940",
    "end": "371889"
  },
  {
    "text": "corresponds to a cluster. And you can see that\ninside a cluster, there are a lot of edges\ngoing among the vertices.",
    "start": "371890",
    "end": "378790"
  },
  {
    "text": "And between clusters, there\nare relatively fewer edges.",
    "start": "378790",
    "end": "384010"
  },
  {
    "text": "And some applications\nof clustering include community detection\nand social networks. So here, you might be\ninterested in finding",
    "start": "384010",
    "end": "390280"
  },
  {
    "text": "groups of people with\nsimilar interests or hobbies. You can also use clustering\nto detect fraudulent websites",
    "start": "390280",
    "end": "396370"
  },
  {
    "text": "on the internet. You can use it for\nclustering documents. So you would cluster\ndocuments that",
    "start": "396370",
    "end": "402070"
  },
  {
    "text": "have similar text together. And clustering is often used\nfor unsupervised learning",
    "start": "402070",
    "end": "407710"
  },
  {
    "text": "and machine learning\napplications. ",
    "start": "407710",
    "end": "412950"
  },
  {
    "text": "Another application\nis connectomics. So connectomics is the study\nof the structure, the network",
    "start": "412950",
    "end": "419910"
  },
  {
    "text": "structure of the brain. And here, the vertices\ncorrespond to neurons. And edges between\ntwo vertices means",
    "start": "419910",
    "end": "426630"
  },
  {
    "text": "that there's some sort of\ninteraction between the two neurons. And recently, there's\nbeen a lot of work",
    "start": "426630",
    "end": "433830"
  },
  {
    "text": "on trying to do\nhigh-performance connectomics. And some of this work has\nbeen going on here at MIT",
    "start": "433830",
    "end": "440130"
  },
  {
    "text": "by Professor Charles Leiserson\nand Professor Nir Shavit's research group. So recently, this has\nbeen a very hot area.",
    "start": "440130",
    "end": "449280"
  },
  {
    "text": "Graphs are also used\nin computer vision-- for example, in\nimage segmentation. So here, you want to\nsegment your image",
    "start": "449280",
    "end": "456030"
  },
  {
    "text": "into the distinct objects\nthat appear in the image. And you can construct a graph\nby representing the pixels",
    "start": "456030",
    "end": "463050"
  },
  {
    "text": "as vertices. And then you would place\nan edge between every pair of neighboring pixels with\na weight that corresponds",
    "start": "463050",
    "end": "470099"
  },
  {
    "text": "to their similarity. And then you would run some sort\nof minimum cost cut algorithm",
    "start": "470100",
    "end": "476430"
  },
  {
    "text": "to partition your graph into\nthe different objects that appear in the image.",
    "start": "476430",
    "end": "482478"
  },
  {
    "text": "So there are many\nother applications. And I'm not going to have\ntime to go through all of them today. But here's just a flavor of some\nof the applications of graphs.",
    "start": "482478",
    "end": "491849"
  },
  {
    "text": "So any questions so far? ",
    "start": "491850",
    "end": "500820"
  },
  {
    "text": "OK, so next, let's\nlook at how we can represent a graph in memory. ",
    "start": "500820",
    "end": "509110"
  },
  {
    "text": "So for the rest of\nthis lecture, I'm going to assume that my vertices\nare labeled in the range from 0 to n minus 1.",
    "start": "509110",
    "end": "515140"
  },
  {
    "text": "So they have an\ninteger in this range. Sometimes, your graph\nmight be given to you",
    "start": "515140",
    "end": "520630"
  },
  {
    "text": "where the vertices are\nalready labeled in this range, sometimes, not. But you can always\nget these labels",
    "start": "520630",
    "end": "526060"
  },
  {
    "text": "by mapping each\nof the identifiers to a unique integer\nin this range. So for the rest of\nthe lecture, I'm",
    "start": "526060",
    "end": "531940"
  },
  {
    "text": "just going to assume that\nwe have these labels from 0 to n minus 1 for the vertices.",
    "start": "531940",
    "end": "537250"
  },
  {
    "text": "One way to represent a graph\nis to use an adjacency matrix. So this is going to\nbe n by n matrix.",
    "start": "537250",
    "end": "544660"
  },
  {
    "text": "And there's a 1 bit in\ni-th row in j-th column if there's an edge that goes\nfrom vertex I to vertex J,",
    "start": "544660",
    "end": "552399"
  },
  {
    "text": "and 0 otherwise. Another way to represent a graph\nis the edgeless representation,",
    "start": "552400",
    "end": "560129"
  },
  {
    "text": "where we just store a\nlist of the edges that appear in the graph. So we have one\npair for each edge,",
    "start": "560130",
    "end": "566319"
  },
  {
    "text": "where the pair contains the\ntwo coordinates of that edge. ",
    "start": "566320",
    "end": "571960"
  },
  {
    "text": "So what is the space\nrequirement for each of these two representations in\nterms of the number of edges m",
    "start": "571960",
    "end": "577270"
  },
  {
    "text": "and the number of\nvertices n in the graph? So it should be pretty easy.",
    "start": "577270",
    "end": "583060"
  },
  {
    "text": " Yes. AUDIENCE: n squared\nfor the [INAUDIBLE]",
    "start": "583060",
    "end": "588640"
  },
  {
    "text": "and m for the [INAUDIBLE]. JULIAN SHUN: Yes, so the\nspace for the adjacency matrix is order n squared\nbecause you have n",
    "start": "588640",
    "end": "594560"
  },
  {
    "text": "squared cells in this matrix. And you have 1 bit\nfor each of the cells. For the edge list, it's\ngoing to be order m",
    "start": "594560",
    "end": "601730"
  },
  {
    "text": "because you have m edges. And for each edge, you're\nstoring a constant amount of data in the edge list. ",
    "start": "601730",
    "end": "610346"
  },
  {
    "text": "So here's another way\nto represent a graph. This is known as the\nadjacency list format.",
    "start": "610346",
    "end": "616850"
  },
  {
    "text": "And idea here is\nthat we're going to have an array of\npointers, 1 per vertex. And each pointer points\nto a linked list storing",
    "start": "616850",
    "end": "625160"
  },
  {
    "text": "the edges for that vertex. And the linked list is\nunordered in this example.",
    "start": "625160",
    "end": "632030"
  },
  {
    "text": "So what's the space requirement\nof this representation? ",
    "start": "632030",
    "end": "642020"
  },
  {
    "text": "AUDIENCE: It's n plus m. JULIAN SHUN: Yeah, so it's\ngoing to be order n plus m. And this is because\nwe have n pointers.",
    "start": "642020",
    "end": "648770"
  },
  {
    "text": "And the number of entries\nacross all of the linked lists is just equal to the number of\nedges in the graph, which is m.",
    "start": "648770",
    "end": "655500"
  },
  {
    "text": " What's one potential issue with\nthis sort of representation",
    "start": "655500",
    "end": "662450"
  },
  {
    "text": "if you think in terms\nof cache performance? Does anyone see a potential\nperformance issue here?",
    "start": "662450",
    "end": "668760"
  },
  {
    "text": " Yeah.",
    "start": "668760",
    "end": "673916"
  },
  {
    "text": "AUDIENCE: So it\ncould be [INAUDIBLE].. ",
    "start": "673916",
    "end": "682560"
  },
  {
    "text": "JULIAN SHUN: Right. So the issue here\nis that if you're trying to loop over all of\nthe neighbors of a vertex,",
    "start": "682560",
    "end": "688770"
  },
  {
    "text": "you're going to have to\ndereference the pointer in every linked list node. Because these are not\ncontiguous in memory.",
    "start": "688770",
    "end": "695520"
  },
  {
    "text": "And every time you\ndereference linked lists node, that's going to be a\nrandom access into memory. So that can be bad\nfor cache performance.",
    "start": "695520",
    "end": "703110"
  },
  {
    "text": "One way you can improve\ncache performance is instead of using linked\nlists for each of these neighbor",
    "start": "703110",
    "end": "709980"
  },
  {
    "text": "lists, you can use an array. So now you can store the\nneighbors just in this array, and they'll be\ncontiguous in memory.",
    "start": "709980",
    "end": "717013"
  },
  {
    "text": "One drawback of this\napproach is that it becomes more expensive if you're\ntrying to update the graph. And we'll talk more\nabout that later.",
    "start": "717013",
    "end": "723300"
  },
  {
    "text": " So any questions so far? ",
    "start": "723300",
    "end": "738250"
  },
  {
    "text": "So what's another way to\nrepresent the graph that we've seen in a previous lecture? ",
    "start": "738250",
    "end": "749400"
  },
  {
    "text": "What's a more compressed\nor compact way to represent a graph,\nespecially a sparse graph?",
    "start": "749400",
    "end": "755220"
  },
  {
    "start": "755220",
    "end": "766660"
  },
  {
    "text": "So does anybody remember the\ncompressed sparse row format? ",
    "start": "766660",
    "end": "773050"
  },
  {
    "text": "So we looked at this in\none of the early lectures. And in that lecture, we used\nit to store a sparse matrix.",
    "start": "773050",
    "end": "780450"
  },
  {
    "text": "But you can also use it\nto store a sparse graph. And as a reminder, we have two\narrays in the compressed sparse",
    "start": "780450",
    "end": "786810"
  },
  {
    "text": "row, or CSR format. We have the Offsets array\nand the Edges array. The Offsets array stores\nan offset for each vertex",
    "start": "786810",
    "end": "794760"
  },
  {
    "text": "into the Edges array,\ntelling us where the edges for that\nparticular vertex begins in the Edges array.",
    "start": "794760",
    "end": "801860"
  },
  {
    "text": "So Offsets of i\nstores the offset of where vertex i's edges\nstart in the Edges array.",
    "start": "801860",
    "end": "807330"
  },
  {
    "text": "So in this example, vertex\n0 has an offset of 0. So its edges start at\nposition 0 in the Edges array.",
    "start": "807330",
    "end": "815550"
  },
  {
    "text": "Vertex 1 has an\noffset of 4, so it starts at index 4 in\nthis Offsets array.",
    "start": "815550",
    "end": "822270"
  },
  {
    "text": "So with this\nrepresentation, how can we get the degree of a vertex? So we're not storing the\ndegree explicitly here.",
    "start": "822270",
    "end": "827820"
  },
  {
    "text": "Can we get the\ndegree efficiently? ",
    "start": "827820",
    "end": "835345"
  },
  {
    "text": "Yes. AUDIENCE: [INAUDIBLE] JULIAN SHUN: Yeah, so you can\nget the degree of a vertex",
    "start": "835345",
    "end": "841650"
  },
  {
    "text": "just by looking\nat the difference between the next offset\nand its own offset. So for vertex 0, you can\nsee that its degree is 4",
    "start": "841650",
    "end": "850170"
  },
  {
    "text": "because vertex 1's offset is\n4, and vertex 0's offset is 0. And similarly you can do that\nfor all of the other vertices.",
    "start": "850170",
    "end": "859320"
  },
  {
    "text": "So what's the space usage\nof this representation? ",
    "start": "859320",
    "end": "868042"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] JULIAN SHUN: Sorry,\ncan you repeat? AUDIENCE: [INAUDIBLE] JULIAN SHUN: Yeah, so again,\nit's going to be order m plus n",
    "start": "868042",
    "end": "875600"
  },
  {
    "text": "because you need order n space\nfor the Offsets array and order m space for the Edges array.",
    "start": "875600",
    "end": "882830"
  },
  {
    "text": "You can also store values\nor weights on their edges. One way to do this is to create\nan additional array of size m.",
    "start": "882830",
    "end": "890510"
  },
  {
    "text": "And then for edge i, you\njust store the weight or the value in the i-th\nindex of this additional array",
    "start": "890510",
    "end": "898430"
  },
  {
    "text": "that you created. If you're always accessing the\nweight when you access an edge, then it's actually better\nfor a cache locality",
    "start": "898430",
    "end": "905390"
  },
  {
    "text": "to interleave the weights\nwith the edge targets. So instead of creating\ntwo arrays of size m,",
    "start": "905390",
    "end": "911750"
  },
  {
    "text": "you have one array of size 2m. And every other\nentry is the weight.",
    "start": "911750",
    "end": "918170"
  },
  {
    "text": "And this improves cache\nlocality because every time you access an edge, its weight\nis going to be right next to it",
    "start": "918170",
    "end": "924199"
  },
  {
    "text": "in memory. And it's going to likely\nbe on the same cache line. So that's one way to\nimprove cache locality.",
    "start": "924200",
    "end": "930660"
  },
  {
    "text": "Any questions so far? ",
    "start": "930660",
    "end": "937365"
  },
  {
    "text": "So let's look at some\nof the trade-offs in these different\ngraph representations that we've looked at so far.",
    "start": "937365",
    "end": "942990"
  },
  {
    "start": "938000",
    "end": "938000"
  },
  {
    "text": "So here, I'm listing\nthe storage costs for each of these\nrepresentations which we already discussed. This is also the cost for just\nscanning the whole graph in one",
    "start": "942990",
    "end": "950900"
  },
  {
    "text": "of these representations. What's the cost of\nadding an edge in each of these representations?",
    "start": "950900",
    "end": "956480"
  },
  {
    "text": "So for adjacency matrix, what's\nthe cost of adding an edge?",
    "start": "956480",
    "end": "961829"
  },
  {
    "text": "AUDIENCE: Order 1. JULIAN SHUN: So for\nadjacency matrix, it's just order\n1 to add an edge.",
    "start": "961830",
    "end": "968399"
  },
  {
    "text": "Because you have random\naccess into this matrix, so you just have to\naccess to i, j-th entry",
    "start": "968400",
    "end": "975120"
  },
  {
    "text": "and flip the bit from 0 to 1. What about for the edge list?",
    "start": "975120",
    "end": "980130"
  },
  {
    "start": "980130",
    "end": "990040"
  },
  {
    "text": "So assuming that the\nedge list is unordered, so you don't have to keep\nthe list in any sorted order.",
    "start": "990040",
    "end": "997300"
  },
  {
    "text": "Yeah. AUDIENCE: I guess it's O of 1. JULIAN SHUN: Yeah, so\nagain, it's just O of 1 because you can just add it\nto the end of the edge list.",
    "start": "997300",
    "end": "1004700"
  },
  {
    "text": "So that's a constant time. What about for the\nadjacency list? So actually, this\ndepends on whether we're",
    "start": "1004700",
    "end": "1011710"
  },
  {
    "text": "using linked lists or\narrays for the neighbor lists of the vertices.",
    "start": "1011710",
    "end": "1017490"
  },
  {
    "text": "If we're using a linked\nlist, adding an edge just takes constant time\nbecause we can just put it at the beginning\nof the linked list.",
    "start": "1017490",
    "end": "1024939"
  },
  {
    "text": "If we're using an\narray, then we actually need to create a new array\nto make space for this edge",
    "start": "1024940",
    "end": "1030279"
  },
  {
    "text": "that we add. And that's going to cost\nus a degree of v work to do that because we have to\ncopy all the existing edges",
    "start": "1030280",
    "end": "1038020"
  },
  {
    "text": "over to this new array\nand then add this new edge to the end of that array.",
    "start": "1038020",
    "end": "1043119"
  },
  {
    "text": "Of course, you could\namortize this cost across multiple updates. So if you run out\nof memory, you can double the size of\nyour array so you",
    "start": "1043119",
    "end": "1049359"
  },
  {
    "text": "don't have to create these\nnew arrays too often. But the cost for any\nindividual addition",
    "start": "1049359",
    "end": "1054880"
  },
  {
    "text": "is still relatively expensive\ncompared to, say, an edge list or adjacency matrix.",
    "start": "1054880",
    "end": "1061700"
  },
  {
    "text": "And then finally, for the\ncompressed sparse row format, if you add an edge,\nin the worst case,",
    "start": "1061700",
    "end": "1066980"
  },
  {
    "text": "it's going to cost us\norder m plus n work. Because we're going to have to\nreconstruct the entire Offsets",
    "start": "1066980",
    "end": "1073210"
  },
  {
    "text": "array and the entire Edges\narray in the worst case. Because we have to put\nsomething in and then shift-- in the Edges\narray, you have",
    "start": "1073210",
    "end": "1079600"
  },
  {
    "text": "to put something in and\nshift all of the values to the right of that\nover by one location. And then for the\nOffsets array, we",
    "start": "1079600",
    "end": "1085420"
  },
  {
    "text": "have to modify the offset for\nthe particular vertex we're adding an edge to and\nthen the offsets for all of the vertices after that.",
    "start": "1085420",
    "end": "1092440"
  },
  {
    "text": "So the compressed sparse\nrow representation is not particularly\nfriendly to edge updates.",
    "start": "1092440",
    "end": "1099700"
  },
  {
    "text": "What about for deleting an\nedge from some vertex v? So for adjacency\nmatrix, again, it's",
    "start": "1099700",
    "end": "1106600"
  },
  {
    "text": "going to be constant\ntime because you just randomly access\nthe correct entry and flip the bit from 1 to 0.",
    "start": "1106600",
    "end": "1114520"
  },
  {
    "text": "What about for an edge list? ",
    "start": "1114520",
    "end": "1122037"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] JULIAN SHUN: Yeah, so for an\nedge list, in the worst case,",
    "start": "1122037",
    "end": "1127530"
  },
  {
    "text": "it's going to cost us order m\nwork because the edges are not in any sorted order. So we have to scan through the\nwhole thing in the worst case",
    "start": "1127530",
    "end": "1135030"
  },
  {
    "text": "to find the edge that\nwe're trying to delete. For adjacency list, it's going\nto take order degree of v work",
    "start": "1135030",
    "end": "1143420"
  },
  {
    "text": "because the neighbors\nare not sorted. So we have to scan\nthrough the whole thing to find this edge that\nwe're trying to delete.",
    "start": "1143420",
    "end": "1149693"
  },
  {
    "text": "And then finally, for a\ncompressed sparse row, it's going to be order\nm plus n because we're going to have to reconstruct the\nwhole thing in the worst case.",
    "start": "1149693",
    "end": "1156365"
  },
  {
    "text": " What about finding\nall of the neighbors",
    "start": "1156365",
    "end": "1162240"
  },
  {
    "text": "of a particular vertex v? What's the cost of doing\nthis in the adjacency matrix?",
    "start": "1162240",
    "end": "1167895"
  },
  {
    "text": " AUDIENCE: [INAUDIBLE]",
    "start": "1167895",
    "end": "1174090"
  },
  {
    "text": "JULIAN SHUN: Yes, so\nit's going to cost us order n work to find\nall the neighbors of a particular\nvertex because we just",
    "start": "1174090",
    "end": "1180420"
  },
  {
    "text": "scan the correct row\nin this matrix, the row corresponding to vertex\nv. For the edge list,",
    "start": "1180420",
    "end": "1188270"
  },
  {
    "text": "we're going to have to\nscan the entire edge list because it's not sorted. So in the worst case,\nthat's going to be order m.",
    "start": "1188270",
    "end": "1194429"
  },
  {
    "text": "For adjacency list, that's\ngoing to take order degree of v because we can just find\na pointer to the linked",
    "start": "1194430",
    "end": "1203640"
  },
  {
    "text": "list for that vertex\nin constant time. And then we just traverse\nover the linked list. And that takes order\ndegree of v time.",
    "start": "1203640",
    "end": "1211174"
  },
  {
    "text": "And then finally, for\ncompressed sparse row format, it's also order degree of v\nbecause we have constant time access into the appropriate\nlocation in the Edges array.",
    "start": "1211175",
    "end": "1219120"
  },
  {
    "text": "And then we can just\nread off the edges, which are consecutive in memory. ",
    "start": "1219120",
    "end": "1226070"
  },
  {
    "text": "So what about finding if a\nvertex w is a neighbor of v?",
    "start": "1226070",
    "end": "1231399"
  },
  {
    "text": "So I'll just give\nyou the answer. So for the adjacency\nmatrix, it's going to take constant\ntime because again,",
    "start": "1231400",
    "end": "1238060"
  },
  {
    "text": "we just have to check the\nv-th row in the w-th column and check if the\nbit is set there.",
    "start": "1238060",
    "end": "1244270"
  },
  {
    "text": "For edge list, we have to\ntraverse the entire list to see if the edge is there.",
    "start": "1244270",
    "end": "1249380"
  },
  {
    "text": "And then for adjacency list\nand compressed sparse row, it's going to be\norder degree of v because we just have to scan the\nneighbor list for that vertex.",
    "start": "1249380",
    "end": "1258279"
  },
  {
    "text": "So these are some\ngraph representations. But there are actually many\nother graph representations,",
    "start": "1258280",
    "end": "1264250"
  },
  {
    "text": "including variance of the ones\nthat I've talked about here. So, for example,\nfor the adjacency,",
    "start": "1264250",
    "end": "1269260"
  },
  {
    "text": "I said you can either use\na linked list or an array to store the neighbor list. But you can actually use\na hybrid approach, where",
    "start": "1269260",
    "end": "1275169"
  },
  {
    "text": "you store the linked list, but\neach linked list node actually stores more than one vertex. So you can store\nmaybe 16 vertices",
    "start": "1275170",
    "end": "1282310"
  },
  {
    "text": "in each linked list node. And that gives us\nbetter cache locality. ",
    "start": "1282310",
    "end": "1290680"
  },
  {
    "text": "So for the rest of\nthis lecture, I'm going to talk about\nalgorithms that are best implemented using the\ncompressed sparse row format.",
    "start": "1290680",
    "end": "1298458"
  },
  {
    "text": "And this is because\nwe're going to be dealing with sparse graphs. We're going to be looking at\nstatic algorithms, where we",
    "start": "1298458",
    "end": "1304978"
  },
  {
    "text": "don't have to update the graph. If we do have to\nupdate the graph, then CSR isn't a good choice. But we're just going to be\nlooking at static algorithms",
    "start": "1304978",
    "end": "1312240"
  },
  {
    "text": "today. And then for all the algorithms\nthat we'll be looking at, we're going to need to scan over\nall the neighbors of a vertex",
    "start": "1312240",
    "end": "1320280"
  },
  {
    "text": "that we visit. And CSR is very good\nfor that because all of the neighbors for\na particular vertex",
    "start": "1320280",
    "end": "1326130"
  },
  {
    "text": "are stored\ncontiguously in memory.  So any questions so far?",
    "start": "1326130",
    "end": "1332040"
  },
  {
    "start": "1332040",
    "end": "1341568"
  },
  {
    "text": "OK, I do want to talk\nabout some properties of real-world graphs. ",
    "start": "1341568",
    "end": "1347470"
  },
  {
    "start": "1342000",
    "end": "1342000"
  },
  {
    "text": "So first, we're seeing graphs\nthat are quite large today. But actually, they're\nnot too large.",
    "start": "1347470",
    "end": "1354260"
  },
  {
    "text": "So here are the sizes of\nsome of the real-world graphs out there. So there is a Twitter network.",
    "start": "1354260",
    "end": "1360158"
  },
  {
    "text": "That's actually a snapshot\nof the Twitter network from a couple of years ago. It has 41 million vertices\nand 1.5 billion edges.",
    "start": "1360158",
    "end": "1367220"
  },
  {
    "text": "And you can store this graph in\nabout 6.3 gigabytes of memory. So you can probably store it in\nthe main memory of your laptop.",
    "start": "1367220",
    "end": "1375139"
  },
  {
    "text": "The largest publicly\navailable graph out there now is this\nCommon Crawl web graph. It has 3.5 billion vertices\nand 128 billion edges.",
    "start": "1375140",
    "end": "1385470"
  },
  {
    "text": "So storing this graph\nrequires a little over 1/2 terabyte of memory.",
    "start": "1385470",
    "end": "1390700"
  },
  {
    "text": "It is quite a bit of memory. But it's actually not too big\nbecause there are machines out there with main memory sizes\nin the order of terabytes",
    "start": "1390700",
    "end": "1398560"
  },
  {
    "text": "of memory nowadays. So, for example, you can rent\n2-terabyte or 4-terabyte memory",
    "start": "1398560",
    "end": "1403780"
  },
  {
    "text": "instance on AWS, which you're\nusing for your homework assignments. See if you have any\nleftover credits",
    "start": "1403780",
    "end": "1409750"
  },
  {
    "text": "at the end of the\nsemester, and you want to play around\non this graph, you can rent one of\nthese terabyte machines.",
    "start": "1409750",
    "end": "1416055"
  },
  {
    "text": "Just remember to\nturn it off when you're done because\nit's kind of expensive. ",
    "start": "1416055",
    "end": "1421930"
  },
  {
    "text": "Another property of\nreal-world graphs is that they're quite sparse. So m tends to be much\nless than n squared.",
    "start": "1421930",
    "end": "1427570"
  },
  {
    "text": "So most of the possible\nedges are not actually there.",
    "start": "1427570",
    "end": "1433419"
  },
  {
    "text": "And finally, the degree\ndistributions of the vertices can be highly skewed in\nmany real-world graphs.",
    "start": "1433420",
    "end": "1439360"
  },
  {
    "text": "So here I'm plotting\nthe degree on the x-axis and the number of vertices\nwith that particular degree",
    "start": "1439360",
    "end": "1446080"
  },
  {
    "text": "on the y-axis. And we can see that\nit's highly skewed. And, for example, in a social\nnetwork, most of the people",
    "start": "1446080",
    "end": "1451750"
  },
  {
    "text": "would be on the left-hand\nside, so their degree is not that high.",
    "start": "1451750",
    "end": "1457330"
  },
  {
    "text": "And then we have some\nvery popular people on the right-hand side, where\ntheir degree is very high,",
    "start": "1457330",
    "end": "1463230"
  },
  {
    "text": "but we don't have\ntoo many of those.  So this is what's known as a\npower law degree distribution.",
    "start": "1463230",
    "end": "1471937"
  },
  {
    "text": "And there have been\nvarious studies that have shown that many\nreal-world graphs have approximately a power\nlaw degree distribution.",
    "start": "1471937",
    "end": "1478630"
  },
  {
    "text": "And mathematically, this\nmeans that the number of vertices with degree\nd is proportional to d",
    "start": "1478630",
    "end": "1485860"
  },
  {
    "text": "to the negative p. So negative p is the exponent. And for many graphs, the value\nof p lies between 2 and 3.",
    "start": "1485860",
    "end": "1495190"
  },
  {
    "text": "And this power law\ndegree distribution does have implications\nwhen we're trying to implement parallel\nalgorithms to process",
    "start": "1495190",
    "end": "1501120"
  },
  {
    "text": "these graphs. Because with graphs that have\na skewed degree distribution, you could run into load\nand balance issues.",
    "start": "1501120",
    "end": "1507970"
  },
  {
    "text": "If you just parallelize\nacross the vertices, the number of edges they\nhave can vary significantly.",
    "start": "1507970",
    "end": "1517370"
  },
  {
    "text": "Any questions? ",
    "start": "1517370",
    "end": "1522730"
  },
  {
    "text": "OK, so now let's talk about\nhow we can implement a graph algorithm. And I'm going to talk about the\nbreadth-first search algorithm.",
    "start": "1522730",
    "end": "1530335"
  },
  {
    "text": "So how many of you have seen\nbreadth-first search before? ",
    "start": "1530335",
    "end": "1535909"
  },
  {
    "text": "OK, so about half of you. I did talk about breadth-first\nsearch in a previous lecture,",
    "start": "1535910",
    "end": "1541940"
  },
  {
    "text": "so I was hoping everybody\nwould raise their hands. OK, so as a reminder,\nin the BFS algorithm,",
    "start": "1541940",
    "end": "1549340"
  },
  {
    "start": "1546000",
    "end": "1546000"
  },
  {
    "text": "we're given a source\nvertex s, and we want to visit the vertices\nin order of their distance from the source s.",
    "start": "1549340",
    "end": "1555880"
  },
  {
    "text": "And there are many\npossible outputs that we might care about. One possible output\nis, we just want to report the\nvertices in the order",
    "start": "1555880",
    "end": "1561580"
  },
  {
    "text": "that they were visited by the\nbreadth-first search traversal. So let's say we have\nthis graph here.",
    "start": "1561580",
    "end": "1567580"
  },
  {
    "text": "And our source vertex\nis D. So what's one possible order in which we\ncan traverse these vertices?",
    "start": "1567580",
    "end": "1573774"
  },
  {
    "start": "1573775",
    "end": "1583054"
  },
  {
    "text": "Now, I should specify\nthat we should traverse this graph in a\nbreadth-first search manner.",
    "start": "1583054",
    "end": "1588810"
  },
  {
    "text": "So what's the first vertex\nwe're going to explore? ",
    "start": "1588810",
    "end": "1593814"
  },
  {
    "text": "AUDIENCE: D. JULIAN SHUN: D. So\nwe're first going to look at D because\nthat's our source vertex.",
    "start": "1593814",
    "end": "1601180"
  },
  {
    "text": "The second vertex,\nwe can actually choose between B, C, and E\nbecause all we care about",
    "start": "1601180",
    "end": "1607390"
  },
  {
    "text": "is that we're visiting\nthese vertices in the order of their\ndistance from the source. But these three vertices are\nall of the same distance.",
    "start": "1607390",
    "end": "1613630"
  },
  {
    "text": "So let's just pick\nB, C, and then E. And then finally,\nI'm going to visit vertex A, which has a\ndistance of 2 from the source.",
    "start": "1613630",
    "end": "1622279"
  },
  {
    "text": "So this is one\npossible solution. There are other\npossible solutions because we could have visited E\nbefore we visited B and so on.",
    "start": "1622280",
    "end": "1632150"
  },
  {
    "text": "Another possible output\nthat we might care about is we might want to report\nthe distance from each vertex",
    "start": "1632150",
    "end": "1638140"
  },
  {
    "text": "to the source vertex s. So in this example\nhere are the distances.",
    "start": "1638140",
    "end": "1643400"
  },
  {
    "text": "So D has a distance of 0; B,C,\nand E all have a distance of 1; and A has a distance of 2.",
    "start": "1643400",
    "end": "1650110"
  },
  {
    "text": "We might also want to generate a\nbreadth-first search tree where each vertex in the\ntree has a parent which",
    "start": "1650110",
    "end": "1658030"
  },
  {
    "text": "is a neighbor in\nthe previous level of the breadth-first search. Or in other words,\nthe parent should",
    "start": "1658030",
    "end": "1663760"
  },
  {
    "text": "have a distance of 1 less\nthan that vertex itself. So here's an example of a\nbreadth-first search tree.",
    "start": "1663760",
    "end": "1671020"
  },
  {
    "text": "And we can see that\neach of the vertices has a parent whose breadth-first\nsearch distance is 1 less",
    "start": "1671020",
    "end": "1677950"
  },
  {
    "text": "than itself.  So the algorithms that I'm\ngoing to be talking about today",
    "start": "1677950",
    "end": "1684530"
  },
  {
    "text": "will generate the distances\nas well as the BFS tree.",
    "start": "1684530",
    "end": "1689920"
  },
  {
    "text": "And BFS actually has\nmany applications. So it's used as a\nsubroutine in betweenness",
    "start": "1689920",
    "end": "1695650"
  },
  {
    "text": "centrality, which is a\nvery popular graph mining algorithm used to rank\nthe importance of nodes",
    "start": "1695650",
    "end": "1701770"
  },
  {
    "text": "in a network. And the importance of\nnodes here corresponds to how many shortest paths\ngo through that node.",
    "start": "1701770",
    "end": "1710380"
  },
  {
    "text": "Other applications include\neccentricity estimation, maximum flows. Some max flow algorithms\nuse BFS as a subroutine.",
    "start": "1710380",
    "end": "1717940"
  },
  {
    "text": "You can use BFS\nto crawl the web, do cycle detection, garbage\ncollection, and so on.",
    "start": "1717940",
    "end": "1723909"
  },
  {
    "text": "So let's now look at a\nserial BFS algorithm. And here, I'm just going\nto show the pseudocode.",
    "start": "1723910",
    "end": "1729710"
  },
  {
    "start": "1724000",
    "end": "1724000"
  },
  {
    "text": "So first, we're going to\ninitialize the distances to all INFINITY. And we're going to initialize\nthe parents to be NIL.",
    "start": "1729710",
    "end": "1737140"
  },
  {
    "text": " And then we're going to\ncreate queue data structure.",
    "start": "1737140",
    "end": "1743898"
  },
  {
    "text": "We're going to set the\ndistance of the root to be 0 because the root has\na distance of 0 to itself.",
    "start": "1743898",
    "end": "1750159"
  },
  {
    "text": "And then we're going to place\nthe root onto this queue. ",
    "start": "1750160",
    "end": "1755800"
  },
  {
    "text": "And then, while the\nqueue is not empty, we're going to dequeue the\nfirst thing in the queue. We're going to look at all the\nneighbors of the current vertex",
    "start": "1755800",
    "end": "1762790"
  },
  {
    "text": "that we dequeued. And for each\nneighbor, we're going to check if its\ndistance is INFINITY.",
    "start": "1762790",
    "end": "1768495"
  },
  {
    "text": "If the distance\nis INFINITY, that means we haven't explored\nthat neighbor yet. So we're going to go\nahead and explore it.",
    "start": "1768495",
    "end": "1773590"
  },
  {
    "text": "And we do so by setting\nits distance value to be the current\nvertex's distance plus 1.",
    "start": "1773590",
    "end": "1779323"
  },
  {
    "text": "We're going to set the\nparent of that neighbor to be the current vertex. And then we'll place the\nneighbor onto the queue.",
    "start": "1779323",
    "end": "1786910"
  },
  {
    "text": "So it's some pretty\nsimple algorithm. And we're just going to keep\niterating in this while loop until there are no more\nvertices left in the queue.",
    "start": "1786910",
    "end": "1796090"
  },
  {
    "text": "So what's the work of this\nalgorithm in terms of n and m? So how much work are\nwe doing per edge?",
    "start": "1796090",
    "end": "1804550"
  },
  {
    "start": "1804550",
    "end": "1812330"
  },
  {
    "text": "Yes. AUDIENCE: [INAUDIBLE]",
    "start": "1812330",
    "end": "1818590"
  },
  {
    "text": "JULIAN SHUN: Yeah, so assuming\nthat the enqueue and dequeue operators are\nconstant time, then",
    "start": "1818590",
    "end": "1824120"
  },
  {
    "text": "we're doing constant\namount of work per edge. So summed across all edges,\nthat's going to be order m.",
    "start": "1824120",
    "end": "1829408"
  },
  {
    "text": "And then we're also\ndoing a constant amount of work per vertex because\nwe have to basically place it",
    "start": "1829408",
    "end": "1835313"
  },
  {
    "text": "onto the queue and then\ntake it off the queue, and then also\ninitialize their value. So the overall work is\ngoing to be order m plus n.",
    "start": "1835313",
    "end": "1841159"
  },
  {
    "text": " OK, so let's now look\nat some actual code to implement the serial\nBFS algorithm using",
    "start": "1841160",
    "end": "1848985"
  },
  {
    "text": "the compressed\nsparse row format.  So first, I'm going to\ninitialize two arrays--",
    "start": "1848985",
    "end": "1855850"
  },
  {
    "text": "parent and queue. And these are going to be\ninteger arrays of size n.",
    "start": "1855850",
    "end": "1861518"
  },
  {
    "text": "I'm going to initialize\nall of the parent entries to be negative 1. I'm going to place a source\nvertex onto the queue.",
    "start": "1861518",
    "end": "1868060"
  },
  {
    "text": "So it's going to appear\nat queue of 0, that's the beginning of the queue. And then I'll set the\nparent of the source vertex",
    "start": "1868060",
    "end": "1874000"
  },
  {
    "text": "to be the source itself. And then I also\nhave two integers that point to the front\nand the back of the queue.",
    "start": "1874000",
    "end": "1881184"
  },
  {
    "text": "So initially, the front of\nthe queue is at position 0, and the back is at position 1.",
    "start": "1881185",
    "end": "1886980"
  },
  {
    "text": "And then while the\nqueue is not empty-- and I can check that by\nchecking if q_front is not",
    "start": "1886980",
    "end": "1892179"
  },
  {
    "text": "equal to q_back-- then I'm going to dequeue\nthe first vertex in my queue. I'm going to set current\nto be that vertex.",
    "start": "1892180",
    "end": "1898930"
  },
  {
    "text": "And then I'll increment q_front. And then I'll compute the\ndegree of that vertex, which",
    "start": "1898930",
    "end": "1904600"
  },
  {
    "text": "I can do by looking\nat the difference between consecutive offsets. And I also assume\nthat Offsets of n",
    "start": "1904600",
    "end": "1911200"
  },
  {
    "text": "is equal to m, just to\ndeal with the last vertex",
    "start": "1911200",
    "end": "1916778"
  },
  {
    "text": "And then I'm going to loop\nthrough all of the neighbors for the current vertex. And to access each\nneighbor, what I do",
    "start": "1916778",
    "end": "1923899"
  },
  {
    "text": "is I go into the Edges array. And I know that my neighbors\nstart at Offsets of current.",
    "start": "1923900",
    "end": "1929570"
  },
  {
    "text": "And therefore, to get\nthe i-th neighbor, I just do Offsets\nof current plus i. That's my index into\nthe Edges array.",
    "start": "1929570",
    "end": "1937400"
  },
  {
    "text": "Now I'm going to check if my\nneighbor has been explored yet. And I can check that by\nchecking if parent of neighbor",
    "start": "1937400",
    "end": "1943430"
  },
  {
    "text": "is equal to negative 1. If it is, that means I\nhaven't explored it yet. And then I'll set a parent\nof neighbor to be current.",
    "start": "1943430",
    "end": "1950930"
  },
  {
    "text": "And then I'll place the neighbor\nonto the back of the queue and increment q_back.",
    "start": "1950930",
    "end": "1957523"
  },
  {
    "text": "And I'm just going to keep\nrepeating this while loop until it becomes empty. And here, I'm only generating\nthe parent pointers.",
    "start": "1957523",
    "end": "1964580"
  },
  {
    "text": "But I could also\ngenerate the distances if I wanted to with just\na slight modification of this code.",
    "start": "1964580",
    "end": "1971060"
  },
  {
    "text": "So any questions on\nhow this code works? ",
    "start": "1971060",
    "end": "1976906"
  },
  {
    "text": "OK, so here's a question. What's the most expensive\npart of the code? Can you point to one\nparticular line here",
    "start": "1976906",
    "end": "1982559"
  },
  {
    "text": "that is the most expensive? ",
    "start": "1982560",
    "end": "1996950"
  },
  {
    "text": "Yes. AUDIENCE: I'm going to guess the\n[INAUDIBLE] that's gonna be all",
    "start": "1996950",
    "end": "2002481"
  },
  {
    "text": "over the place in terms\nof memory locations-- ngh equals Edges.",
    "start": "2002482",
    "end": "2008080"
  },
  {
    "text": "JULIAN SHUN: OK, so\nactually, it turns out that that's not the most\nexpensive part of this code.",
    "start": "2008080",
    "end": "2013330"
  },
  {
    "text": "But you're close. So anyone have any other ideas? ",
    "start": "2013330",
    "end": "2029890"
  },
  {
    "text": "Yes. AUDIENCE: Is it looking\nup the parent array? JULIAN SHUN: Yes, so it turns\nout that this line here,",
    "start": "2029890",
    "end": "2037440"
  },
  {
    "text": "where we're accessing\nparent of neighbor, that turns out to be\nthe most expensive.",
    "start": "2037440",
    "end": "2042929"
  },
  {
    "text": "Because whenever we\naccess this parent array, the neighbor can appear\nanywhere in memory. So that's going to\nbe a random access.",
    "start": "2042930",
    "end": "2050399"
  },
  {
    "text": "And if the parent array\ndoesn't fit in our cache, then that's going to cost us a\ncache miss almost every time.",
    "start": "2050400",
    "end": "2055679"
  },
  {
    "text": " This Edges array is actually\nmostly accessed sequentially.",
    "start": "2055679",
    "end": "2062429"
  },
  {
    "text": "Because for each\nvertex, all of its edges are stored\ncontiguously in memory, we do have one random access\ninto the Edges array per vertex",
    "start": "2062429",
    "end": "2070530"
  },
  {
    "text": "because we have to look\nup the starting location for that vertex. But it's not 1 per edge, unlike\nthis check of the parent array.",
    "start": "2070530",
    "end": "2077638"
  },
  {
    "text": "That occurs for every edge. So does that make sense? ",
    "start": "2077639",
    "end": "2084589"
  },
  {
    "text": "So let's do a\nback-of-the-envelope calculation to figure out how\nmany cache misses we would incur, assuming that we\nstarted with a cold cache.",
    "start": "2084590",
    "end": "2093620"
  },
  {
    "text": "And we also assume\nthat n is much larger than the size of the\ncache, so we can't fit any of these arrays into cache.",
    "start": "2093620",
    "end": "2100190"
  },
  {
    "text": "We'll assume that a\ncache line has 64 bytes, and integers are 4 bytes each.",
    "start": "2100190",
    "end": "2108120"
  },
  {
    "text": "So let's try to analyze this. So the initialization will\ncost us n/16 cache misses.",
    "start": "2108120",
    "end": "2116960"
  },
  {
    "text": "And the reason here is that\nwe're initializing this array sequentially. So we're accessing\ncontiguous locations.",
    "start": "2116960",
    "end": "2123260"
  },
  {
    "text": "And this can take advantage\nof spatial locality. On each cache line, we can\nfit 16 of the integers.",
    "start": "2123260",
    "end": "2130010"
  },
  {
    "text": "So overall, we're going to\nneed n/16 cache misses just to initialize this array.",
    "start": "2130010",
    "end": "2135589"
  },
  {
    "text": " We also need n/16 cache misses\nacross the entire algorithm",
    "start": "2135590",
    "end": "2143270"
  },
  {
    "text": "to dequeue the vertex from\nthe front of the queue. Because again, this is going\nto be a sequential access",
    "start": "2143270",
    "end": "2149660"
  },
  {
    "text": "into this queue array. And across all vertices,\nthat's going to be n/16 cache misses because we can fit\n16 integers on a cache line.",
    "start": "2149660",
    "end": "2158869"
  },
  {
    "text": " To compute the\ndegree here, that's",
    "start": "2158870",
    "end": "2165109"
  },
  {
    "text": "going to take n\ncache misses overall. Because each of these\naccesses to Offsets",
    "start": "2165110",
    "end": "2171578"
  },
  {
    "text": "array is going to\nbe a random access. Because we have no idea what\nthe value of current here is. It could be anything.",
    "start": "2171578",
    "end": "2177900"
  },
  {
    "text": "So across the entire\nalgorithm, we're going to need n cache misses\nto access this Offsets array.",
    "start": "2177900",
    "end": "2183260"
  },
  {
    "text": " And then to access\nthis Edges array,",
    "start": "2183260",
    "end": "2189770"
  },
  {
    "text": "I claim that we're going to\nneed at most 2n plus m/16 cache misses.",
    "start": "2189770",
    "end": "2195170"
  },
  {
    "text": "So does anyone see where\nthat bound comes from? ",
    "start": "2195170",
    "end": "2214690"
  },
  {
    "text": "So where does the\nm/16 come from? ",
    "start": "2214690",
    "end": "2227490"
  },
  {
    "text": "Yeah. AUDIENCE: You have to access\nthat at least once for an edge. JULIAN SHUN: Right, so you\nhave to pay m/16 because you're",
    "start": "2227490",
    "end": "2234810"
  },
  {
    "text": "accessing every edge once. And you're accessing\nthe Edges contiguously.",
    "start": "2234810",
    "end": "2240060"
  },
  {
    "start": "2236000",
    "end": "2236000"
  },
  {
    "text": "So therefore, across\nall Edges, that's going to take m/16 cache misses. But we also have to add 2n.",
    "start": "2240060",
    "end": "2247290"
  },
  {
    "text": "Because whenever we access the\nEdges for a particular vertex, the first cache\nline might not only",
    "start": "2247290",
    "end": "2254340"
  },
  {
    "text": "contain that vertex's edges. And similarly, the\nlast cache line that we access might\nalso not just contain",
    "start": "2254340",
    "end": "2260460"
  },
  {
    "text": "that vertex's edges. So therefore, we're going\nto waste the first cache line and the last cache line in\nthe worst case for each vertex.",
    "start": "2260460",
    "end": "2268920"
  },
  {
    "text": "And summed cross all vertices,\nthat's going to be 2n. So this is the upper\nbound, 2n plus m/16. ",
    "start": "2268920",
    "end": "2276420"
  },
  {
    "text": "Accessing this\nparent array, that's going to be a random\naccess every time. So we're going to\nincur a cache miss",
    "start": "2276420",
    "end": "2281700"
  },
  {
    "text": "in the worst case every time. So summed across\nall edge accesses, that's going to\nbe m cache misses.",
    "start": "2281700",
    "end": "2288589"
  },
  {
    "text": "And then finally,\nwe're going to pay n/16 cache misses to enqueue\nthe neighbor onto the queue",
    "start": "2288590",
    "end": "2294420"
  },
  {
    "text": "because these are\nsequential accesses. So in total, we're going\nto incur at most 51/16 n",
    "start": "2294420",
    "end": "2302550"
  },
  {
    "text": "plus 17/16 16 m cache misses. And if m is greater than\n3n, then the second term",
    "start": "2302550",
    "end": "2310230"
  },
  {
    "text": "here is going to dominate. And m is usually greater than\n3n in most real-world graphs.",
    "start": "2310230",
    "end": "2316080"
  },
  {
    "text": "And the second term here is\ndominated by this random access into the parent array.",
    "start": "2316080",
    "end": "2322920"
  },
  {
    "text": "So let's see if we can\noptimize this code so that we get better cache performance.",
    "start": "2322920",
    "end": "2329190"
  },
  {
    "text": "So let's say we could fit a bit\nvector of size n into cache. But we couldn't fit the entire\nparent array into cache.",
    "start": "2329190",
    "end": "2335609"
  },
  {
    "text": "What can we do to reduce\nthe number of cache misses? So does anyone have any ideas?",
    "start": "2335610",
    "end": "2342170"
  },
  {
    "text": "Yeah. AUDIENCE: Is bitvector\nto keep track of which",
    "start": "2342170",
    "end": "2347190"
  },
  {
    "text": "vertices of other\nparents then [INAUDIBLE]?? ",
    "start": "2347190",
    "end": "2354440"
  },
  {
    "text": "JULIAN SHUN: Yeah, so\nthat's exactly correct. So we're going to\nuse a bit vector",
    "start": "2354440",
    "end": "2359820"
  },
  {
    "text": "to store whether the vertex\nhas been explored yet or not. So we only need 1 bit for that. We're not storing the parent\nID in this bit vector.",
    "start": "2359820",
    "end": "2366960"
  },
  {
    "text": "We're just storing a bit to\nsay whether that vertex has been explored yet or not. And then, before we\ncheck this parent array,",
    "start": "2366960",
    "end": "2374552"
  },
  {
    "text": "we're going to first\ncheck the bit vector to see if that vertex\nhas been explored yet. And if it has been\nexplored yet, we",
    "start": "2374552",
    "end": "2381150"
  },
  {
    "text": "don't even need to\naccess this parent array. If it hasn't been\nexplored, then we won't go ahead and access the\nparent entry of the neighbor.",
    "start": "2381150",
    "end": "2390270"
  },
  {
    "text": "But we only have\nto do this one time for each vertex in the\ngraph because we can only",
    "start": "2390270",
    "end": "2395880"
  },
  {
    "text": "visit each vertex once. And therefore, we can\nreduce the number of cache misses from m down to n.",
    "start": "2395880",
    "end": "2401065"
  },
  {
    "text": " So overall, this might improve\nthe number of cache misses.",
    "start": "2401065",
    "end": "2407130"
  },
  {
    "text": "In fact, it does if\nthe number of edges is large enough relative\nto the number of vertices.",
    "start": "2407130",
    "end": "2415690"
  },
  {
    "text": "However, you do have to do a\nlittle bit more computation because you have to do bit\nvector manipulation to check",
    "start": "2415690",
    "end": "2422039"
  },
  {
    "text": "this bit vector and then also\nto set the bit vector when you explore a neighbor.",
    "start": "2422040",
    "end": "2427680"
  },
  {
    "start": "2427000",
    "end": "2427000"
  },
  {
    "text": "So here's the code using\nthe bit vector optimization.",
    "start": "2427680",
    "end": "2433319"
  },
  {
    "text": "So here, I'm initializing this\nbit vector called visited. It's of size,\napproximately, n/32. ",
    "start": "2433320",
    "end": "2440640"
  },
  {
    "text": "And then I'm setting\nall of the bits to 0, except for the\nsource vertex, where I'm going to set its bit to 1.",
    "start": "2440640",
    "end": "2447120"
  },
  {
    "text": "And I'm doing this\nbit calculation here to figure out the bit\nfor the source vertex.",
    "start": "2447120",
    "end": "2454230"
  },
  {
    "text": "And then now, when I'm\ntrying to visit a neighbor, I'm first going to check\nif the neighbor is visited",
    "start": "2454230",
    "end": "2460230"
  },
  {
    "text": "by checking this bit array. And I can do this using\nthis computation here--",
    "start": "2460230",
    "end": "2465900"
  },
  {
    "text": "AND visited of neighbor\nover 32, by this mask-- 1 left shifted by\nneighbor mod 32.",
    "start": "2465900",
    "end": "2474300"
  },
  {
    "text": "And if that's false,\nthat means the neighbor hasn't been visited yet. So I'll go inside\nthis IF clause.",
    "start": "2474300",
    "end": "2480420"
  },
  {
    "text": "And then I'll set\nthe visited bit to be true using\nthis statement here. And then I do the same\noperations as I did before.",
    "start": "2480420",
    "end": "2487259"
  },
  {
    "text": " It turns out that\nthis version is",
    "start": "2487260",
    "end": "2492849"
  },
  {
    "text": "faster for large\nenough values of m relative to n because you\nreduce the number of cache",
    "start": "2492850",
    "end": "2498370"
  },
  {
    "text": "misses overall. You still have to do this\nextra computation here,",
    "start": "2498370",
    "end": "2504240"
  },
  {
    "text": "this bit manipulation. But if m is large enough,\nthen the reduction in number of cache\nmisses outweighs",
    "start": "2504240",
    "end": "2511180"
  },
  {
    "text": "the additional computation\nthat you have to do. Any questions? ",
    "start": "2511180",
    "end": "2524190"
  },
  {
    "text": "OK, so that was a\nserial implementation of breadth-first search. Now let's look at a\nparallel implementation.",
    "start": "2524190",
    "end": "2530950"
  },
  {
    "text": "So I'm first going\nto do an animation of how a parallel breadth-first\nsearch algorithm would work.",
    "start": "2530950",
    "end": "2537645"
  },
  {
    "text": "The parallel reference\nsearch algorithm is going to operate\non frontiers, where the initial frontier\ncontains just a source vertex.",
    "start": "2537645",
    "end": "2545540"
  },
  {
    "start": "2539000",
    "end": "2539000"
  },
  {
    "text": "And on every\niteration, I'm going to explore all of the\nvertices on the frontier and then place any\nunexplored neighbors",
    "start": "2545540",
    "end": "2551839"
  },
  {
    "text": "onto the next frontier. And then I move on\nto the next frontier. So in the first\niteration, I'm going",
    "start": "2551840",
    "end": "2556900"
  },
  {
    "text": "to mark the source\nvertex as explored, set its distance to\nbe 0, and then place the neighbors of that source\nvertex onto the next frontier.",
    "start": "2556900",
    "end": "2565100"
  },
  {
    "text": "In the next iteration, I'm\ngoing to do the same thing, set these distances to 1. I also am going to\ngenerate a parent pointer",
    "start": "2565100",
    "end": "2571820"
  },
  {
    "text": "for each of these vertices. And this parent should come\nfrom the previous frontier, and it should be a\nneighbor of the vertex.",
    "start": "2571820",
    "end": "2578833"
  },
  {
    "text": "And here, there's\nonly one option, which is the source vertex. So I'll just pick\nthat as the parent.",
    "start": "2578833",
    "end": "2584692"
  },
  {
    "text": "And then I'm going to\nplace the neighbors onto the next frontier again,\nmark those as explored,",
    "start": "2584692",
    "end": "2590000"
  },
  {
    "text": "set their distances,\nand generate a parent pointer again. And notice here, when I'm\ngenerating these parent",
    "start": "2590000",
    "end": "2596720"
  },
  {
    "text": "pointers, there's actually\nmore than one choice for some of these vertices. And this is because there\nare multiple vertices on the previous frontier.",
    "start": "2596720",
    "end": "2603630"
  },
  {
    "text": "And some of them explored\nthe same neighbor on the current frontier. So a parallel\nimplementation has to be",
    "start": "2603630",
    "end": "2610309"
  },
  {
    "text": "aware of this potential race. Here, I'm just picking\nan arbitrary parent.",
    "start": "2610310",
    "end": "2616890"
  },
  {
    "text": "So as we see here,\nyou can process each of these frontiers in parallel. So you can parallelize over all\nof the vertices on the frontier",
    "start": "2616890",
    "end": "2622970"
  },
  {
    "text": "as well as all of\ntheir outgoing edges. However, you do need to\nprocess one frontier before you move on to the next one\nin this BFS algorithm.",
    "start": "2622970",
    "end": "2632530"
  },
  {
    "text": "And a parallel\nimplementation has to be aware of potential races. So as I said earlier, we\ncould have multiple vertices",
    "start": "2632530",
    "end": "2639895"
  },
  {
    "text": "on the frontier trying to\nvisit the same neighbors. So somehow, that\nhas to be resolved. And also, the amount of\nwork on each frontier",
    "start": "2639895",
    "end": "2647059"
  },
  {
    "text": "is changing throughout the\ncourse of the algorithm. So you have to be careful\nwith load balancing.",
    "start": "2647060",
    "end": "2653420"
  },
  {
    "text": "Because you have to make\nsure that the amount of work each processor has to\ndo is about the same.",
    "start": "2653420",
    "end": "2660133"
  },
  {
    "text": "If you use Cilk\nto implement this, then load balancing doesn't\nreally become a problem. ",
    "start": "2660133",
    "end": "2668140"
  },
  {
    "text": "So any questions on\nthe BFS algorithm before I go over the code? ",
    "start": "2668140",
    "end": "2676010"
  },
  {
    "text": "OK, so here's the actual code. And here I'm going to\ninitialize these four arrays, so",
    "start": "2676010",
    "end": "2683160"
  },
  {
    "text": "the parent array, which\nis the same as before. I'm going to have an array\ncalled frontier, which",
    "start": "2683160",
    "end": "2688230"
  },
  {
    "text": "stores the current frontier. And then I'm going\nto have an array called frontierNext,\nwhich is a temporary array",
    "start": "2688230",
    "end": "2694319"
  },
  {
    "text": "that I use to store the\nnext frontier of the BFS. And then also I have an\narray called degrees.",
    "start": "2694320",
    "end": "2699525"
  },
  {
    "text": " I'm going to initialize\nall of the parent entries to be negative 1.",
    "start": "2699525",
    "end": "2705045"
  },
  {
    "text": "I do that using a cilk_for loop. I'm going to place the source\nvertex at the 0-th index",
    "start": "2705045",
    "end": "2712870"
  },
  {
    "text": "of the frontier. I'll set the\nfrontierSize to be 1. And then I set the parent of the\nsource to be the source itself.",
    "start": "2712870",
    "end": "2719530"
  },
  {
    "text": "While the frontierSize\nis greater than 0, that means I still\nhave more work to do. I'm going to first\niterate over all",
    "start": "2719530",
    "end": "2726530"
  },
  {
    "text": "of the vertices on my frontier\nin parallel using a cilk_for loop. And then I'll set the i-th\nentry of the degrees array",
    "start": "2726530",
    "end": "2734680"
  },
  {
    "text": "to be the degree of the\ni-th vertex on the frontier. And I can do this just\nusing the difference",
    "start": "2734680",
    "end": "2740619"
  },
  {
    "text": "between consecutive offsets. And then I'm going to perform\na prefix sum on this degrees",
    "start": "2740620",
    "end": "2746950"
  },
  {
    "text": "array. And we'll see in a minute why\nI'm doing this prefix sum. But first of all, does anybody\nrecall what prefix sum is?",
    "start": "2746950",
    "end": "2754510"
  },
  {
    "start": "2754510",
    "end": "2763140"
  },
  {
    "text": "So who knows what prefix sum is? ",
    "start": "2763140",
    "end": "2768750"
  },
  {
    "text": "Do you want to\ntell us what it is? AUDIENCE: That's the sum array\nwhere index i is the sum of [INAUDIBLE].",
    "start": "2768750",
    "end": "2775910"
  },
  {
    "text": "JULIAN SHUN: Yeah,\nso prefix sum--  so here I'm going to demonstrate\nthis with an example.",
    "start": "2775910",
    "end": "2784530"
  },
  {
    "start": "2780000",
    "end": "2780000"
  },
  {
    "text": "So let's say this\nis our input array. The output of this array\nwould store for each location",
    "start": "2784530",
    "end": "2791359"
  },
  {
    "text": "the sum of everything before\nthat location in the input array. So here we see that the first\nposition has a value of 0",
    "start": "2791360",
    "end": "2798859"
  },
  {
    "text": "because a sum of\neverything before it is 0. There's nothing before\nit in the input. The second position\nhas a value of 2",
    "start": "2798860",
    "end": "2805250"
  },
  {
    "text": "because the sum of\neverything before it is just the first location. The third location\nhas a value of 6",
    "start": "2805250",
    "end": "2811850"
  },
  {
    "text": "because the sum of\neverything before it is 2 plus 4, which is 6, and so on.",
    "start": "2811850",
    "end": "2817589"
  },
  {
    "text": "So I believe this was on one\nof your homework assignments. So hopefully, everyone\nknows what prefix sum is.",
    "start": "2817590",
    "end": "2824270"
  },
  {
    "text": "And later on, we'll\nsee how we use this to do the parallel\nbreadth-first search.",
    "start": "2824270",
    "end": "2830110"
  },
  {
    "text": "OK, so I'm going to do a prefix\nsum on this degrees array. And then I'm going to loop over\nmy frontier again in parallel.",
    "start": "2830110",
    "end": "2839550"
  },
  {
    "text": "I'm going to let v be the\ni-th vertex on the frontier. Index is going to be\nequal to degrees of i.",
    "start": "2839550",
    "end": "2845630"
  },
  {
    "text": "And then my degree is\ngoing to be Offsets of v plus 1 minus Offsets of v.",
    "start": "2845630",
    "end": "2853270"
  },
  {
    "text": "Now I'm going to loop\nthrough all v's neighbors. And here I just have\na serial for loop.",
    "start": "2853270",
    "end": "2858650"
  },
  {
    "text": "But you could actually\nparallelize this for loop. It turns out that if the number\nof iterations in the for loop",
    "start": "2858650",
    "end": "2864470"
  },
  {
    "text": "is small enough, there's\nadditional overhead to making this parallel, so I\njust made it serial for now.",
    "start": "2864470",
    "end": "2869630"
  },
  {
    "text": "But you could make it parallel. To get the neighbor, I just\nindex into this Edges array.",
    "start": "2869630",
    "end": "2875859"
  },
  {
    "text": "I look at Offsets of v plus j.  Then now I'm going to\ncheck if the neighbor has",
    "start": "2875860",
    "end": "2882770"
  },
  {
    "text": "been explored yet. And I can check if\nparent of neighbor is equal to negative 1.",
    "start": "2882770",
    "end": "2887928"
  },
  {
    "text": "So that means it hasn't\nbeen explored yet, so I'm going to try to explore it. And I do so using\na compare-and-swap.",
    "start": "2887928",
    "end": "2893780"
  },
  {
    "text": "I'm going to try to\nswap in the value of v with the original\nvalue of negative 1",
    "start": "2893780",
    "end": "2898790"
  },
  {
    "text": "in parent of neighbor. And the compare-and-swap\nis going to return true if it was\nsuccessful and false otherwise.",
    "start": "2898790",
    "end": "2906540"
  },
  {
    "text": "And if it returns\ntrue, that means this vertex becomes the\nparent of this neighbor. And then I'll place\nthe neighbor on",
    "start": "2906540",
    "end": "2912980"
  },
  {
    "text": "to frontierNext at\nthis particular index-- index plus j. And otherwise, I'll set a\nnegative 1 at that location.",
    "start": "2912980",
    "end": "2921869"
  },
  {
    "text": "OK, so let's see why I'm\nusing index plus j here. So here's how\nfrontierNext is organized.",
    "start": "2921870",
    "end": "2928849"
  },
  {
    "text": "So each vertex on\nthe frontier owns a subset of these locations\nin the frontierNext array.",
    "start": "2928850",
    "end": "2935060"
  },
  {
    "text": "And these are all\ncontiguous memory locations. And it turns out that\nthe starting location",
    "start": "2935060",
    "end": "2940220"
  },
  {
    "text": "for each of these vertices\nin this frontierNext array is exactly the value in this\nprefix sum array up here.",
    "start": "2940220",
    "end": "2947150"
  },
  {
    "text": "So vertex 1 has its first\nlocation at index 0. Vertex 2 has its first\nlocation at index 2.",
    "start": "2947150",
    "end": "2953750"
  },
  {
    "text": "Vertex 3 has its first\nlocation at index 6, and so on. So by using a prefix\nsum, I can guarantee",
    "start": "2953750",
    "end": "2961070"
  },
  {
    "text": "that all of these vertices\nhave a disjoint subarray in this frontierNext array.",
    "start": "2961070",
    "end": "2966200"
  },
  {
    "text": "And then they can all write\nto this frontierNext array in parallel without any races.",
    "start": "2966200",
    "end": "2972559"
  },
  {
    "text": "And index plus j just\ngives us the right location to write to in this array. So index is the\nstarting location,",
    "start": "2972560",
    "end": "2980300"
  },
  {
    "text": "and then j is for\nthe j-th neighbor.  So here is one potential\noutput after we write",
    "start": "2980300",
    "end": "2988309"
  },
  {
    "text": "to this frontierNext array. So we have some\nnon-negative values. And these are vertices that\nwe explored in this iteration.",
    "start": "2988310",
    "end": "2995840"
  },
  {
    "text": "We also have some\nnegative 1 values. And the negative 1 here means\nthat either the vertex has",
    "start": "2995840",
    "end": "3001300"
  },
  {
    "text": "already been explored\nin a previous iteration, or we tried to explore it\nin the current iteration, but somebody else\ngot there before us.",
    "start": "3001300",
    "end": "3008020"
  },
  {
    "text": "Because somebody else is\ndoing the compare-and-swap at the same time, and they could\nhave finished before we did,",
    "start": "3008020",
    "end": "3013165"
  },
  {
    "text": "so we failed on the\ncompare-and-swap. So we don't actually want these\nnegative 1 values, so we're",
    "start": "3013165",
    "end": "3018820"
  },
  {
    "text": "going to filter them out. And we can filter them out\nusing a prefix sum again.",
    "start": "3018820",
    "end": "3024160"
  },
  {
    "text": "And this is going to\ngive us a new frontier. And we'll set the\nfrontierSize equal to the size",
    "start": "3024160",
    "end": "3029680"
  },
  {
    "text": "of this new frontier. And then we repeat\nthis while loop until there are no more\nvertices on the frontier.",
    "start": "3029680",
    "end": "3034960"
  },
  {
    "text": " So any questions on this\nparallel BFS algorithm?",
    "start": "3034960",
    "end": "3041590"
  },
  {
    "start": "3041590",
    "end": "3050420"
  },
  {
    "text": "Yeah. AUDIENCE: Can you go over\nlike the last [INAUDIBLE]?? ",
    "start": "3050420",
    "end": "3057243"
  },
  {
    "text": "JULIAN SHUN: Do you\nmean the filter out? AUDIENCE: Yeah. JULIAN SHUN: Yeah,\nso what you can do is, you can create another\narray, which stores a 1",
    "start": "3057243",
    "end": "3066500"
  },
  {
    "text": "in location i if that location\nis not a negative 1 and 0 if it is a negative 1.",
    "start": "3066500",
    "end": "3072710"
  },
  {
    "text": "Then you do a prefix\nsum on that array, which gives us unique\noffsets into an output array. So then everybody just looks\nat the prefix sum array there.",
    "start": "3072710",
    "end": "3081170"
  },
  {
    "text": "And then it writes\nto the output array. So it might be easier if I\ntried to draw this on the board.",
    "start": "3081170",
    "end": "3086540"
  },
  {
    "start": "3086540",
    "end": "3100950"
  },
  {
    "text": "OK, so let's say we have\nan array of size 5 here. So what I'm going\nto do is I'm going",
    "start": "3100950",
    "end": "3106230"
  },
  {
    "text": "to generate another\narray which stores a 1 if the value in the\ncorresponding location",
    "start": "3106230",
    "end": "3114300"
  },
  {
    "text": "is not a negative\n1 and 0 otherwise. ",
    "start": "3114300",
    "end": "3120770"
  },
  {
    "text": "And then I do a prefix\nsum on this array here. And this gives me\n0, 1, 1, 2, and 2.",
    "start": "3120770",
    "end": "3135299"
  },
  {
    "text": "And now each of these values\nthat are not negative 1, they can just look up\nthe corresponding index",
    "start": "3135300",
    "end": "3142710"
  },
  {
    "text": "in this output array. And this gives us a unique\nindex into an output array.",
    "start": "3142710",
    "end": "3148620"
  },
  {
    "text": "So this element will\nwrite to position 0, this element would\nwrite to position 1, and this element would write to\nposition 2 in my final output.",
    "start": "3148620",
    "end": "3158320"
  },
  {
    "text": "So this would be\nmy final frontier. ",
    "start": "3158320",
    "end": "3171155"
  },
  {
    "text": "Does that make sense? ",
    "start": "3171155",
    "end": "3178440"
  },
  {
    "text": "OK, so let's now\nanalyze the working span of this parallel BFS algorithm.",
    "start": "3178440",
    "end": "3186410"
  },
  {
    "text": "So a number of iterations\nrequired by the BFS algorithm is upper-bounded by the\ndiameter D of the graph.",
    "start": "3186410",
    "end": "3192880"
  },
  {
    "text": "And the diameter of a graph\nis just the maximum shortest path between any pair of\nvertices in the graph.",
    "start": "3192880",
    "end": "3199682"
  },
  {
    "text": "And that's an upper bound\non the number of iterations we need to do. Each iteration is\ngoing to take a log m",
    "start": "3199682",
    "end": "3206330"
  },
  {
    "text": "span for the clik_for loops,\nthe prefix sum, and the filter. And this is also assuming\nthat the inner loop",
    "start": "3206330",
    "end": "3212150"
  },
  {
    "text": "is parallelized, the inner loop\nover the neighbors of a vertex. So to get the span, we just\nmultiply these two terms.",
    "start": "3212150",
    "end": "3219420"
  },
  {
    "text": "So we get theta of\nD times log m span. What about the work?",
    "start": "3219420",
    "end": "3225870"
  },
  {
    "text": "So to compute the work,\nwe have to figure out how much work we're doing\nper vertex and per edge.",
    "start": "3225870",
    "end": "3230960"
  },
  {
    "text": "So first, notice that\nthe sum of the frontier sizes across entire\nalgorithm is going to be n because each vertex\ncan be on the frontier at most",
    "start": "3230960",
    "end": "3238365"
  },
  {
    "text": "once.  Also, each edge is going to\nbe traversed exactly once.",
    "start": "3238365",
    "end": "3244340"
  },
  {
    "text": "So that leads to m\ntotal edge visits. ",
    "start": "3244340",
    "end": "3249662"
  },
  {
    "text": "On each iteration\nof the algorithm, we're doing a prefix sum. And the cost of\nthis prefix sum is",
    "start": "3249662",
    "end": "3255020"
  },
  {
    "text": "going to be proportional\nto the frontier size. So summed across all iterations,\nthe cost of the prefix",
    "start": "3255020",
    "end": "3260660"
  },
  {
    "text": "sum is going to be theta of n. We also have to do this filter. But the work of the filter\nis proportional to the number",
    "start": "3260660",
    "end": "3267860"
  },
  {
    "text": "of edges traversed\nin that iteration. And summed across all\niterations, that's going to give theta of m total.",
    "start": "3267860",
    "end": "3274610"
  },
  {
    "text": "So overall, the\nwork is going to be theta of n plus m for this\nparallel BFS algorithm.",
    "start": "3274610",
    "end": "3279770"
  },
  {
    "text": "So this is a\nwork-efficient algorithm. The work matches out\nthe serial algorithm.",
    "start": "3279770",
    "end": "3285810"
  },
  {
    "text": "Any questions on the analysis? ",
    "start": "3285810",
    "end": "3293780"
  },
  {
    "text": "OK, so let's look at\nhow this parallel BFS algorithm runs in practice.",
    "start": "3293780",
    "end": "3299880"
  },
  {
    "text": "So here, I ran some\nexperiments on a random graph with 10 million vertices\nand 100 million edges.",
    "start": "3299880",
    "end": "3306660"
  },
  {
    "text": "And the edges were\nrandomly generated. And I made sure that\neach vertex had 10 edges.",
    "start": "3306660",
    "end": "3312049"
  },
  {
    "text": "I ran experiments\non a 40-core machine with 2-way hyperthreading. Does anyone know what\nhyperthreading is?",
    "start": "3312050",
    "end": "3317730"
  },
  {
    "text": " Yeah, what is it? AUDIENCE: It's when you\nhave like one CPU core that",
    "start": "3317730",
    "end": "3324849"
  },
  {
    "text": "can execute two instruction\nscreens at the same time so it can [INAUDIBLE]\nhigh number latency.",
    "start": "3324850",
    "end": "3330786"
  },
  {
    "text": "JULIAN SHUN: Yeah, so\nthat's a great answer. So hyperthreading is\nan Intel technology where for each physical core,\nthe operating system actually",
    "start": "3330787",
    "end": "3338320"
  },
  {
    "text": "sees it as two logical cores. They share many of\nthe same resources, but they have their\nown registers.",
    "start": "3338320",
    "end": "3343517"
  },
  {
    "text": "So if one of the logical\ncores stalls on a long latency operation, the\nother logical core",
    "start": "3343517",
    "end": "3348610"
  },
  {
    "text": "can use the shared resources\nand hide some of the latency.",
    "start": "3348610",
    "end": "3353870"
  },
  {
    "text": "OK, so here I am\nplotting the speedup over the single-threaded time\nof the parallel algorithm",
    "start": "3353870",
    "end": "3360670"
  },
  {
    "text": "versus the number of threads. So we see that on\n40 threads, we get a speedup of about 22 or 23X.",
    "start": "3360670",
    "end": "3368380"
  },
  {
    "text": "And when we turn\non hyperthreading and use all 80 threads, the\nspeedup is about 32 times",
    "start": "3368380",
    "end": "3373750"
  },
  {
    "text": "on 40 cores. And this is actually pretty good\nfor a parallel graph algorithm. It's very hard to get\nvery good speedups",
    "start": "3373750",
    "end": "3380530"
  },
  {
    "text": "on these irregular\ngraph algorithms. So 32X on 40 cores\nis pretty good.",
    "start": "3380530",
    "end": "3386590"
  },
  {
    "text": "I also compared this to\nthe serial BFS algorithm because that's\nwhat we ultimately want to compare against.",
    "start": "3386590",
    "end": "3392440"
  },
  {
    "text": "So we see that on 80 threads,\nthe speedup over the serial BFS",
    "start": "3392440",
    "end": "3398609"
  },
  {
    "text": "is about 21, 22X. And the serial BFS is 54%\nfaster than the parallel BFS",
    "start": "3398610",
    "end": "3407650"
  },
  {
    "text": "on one thread. This is because it's doing less\nwork than the parallel version.",
    "start": "3407650",
    "end": "3412960"
  },
  {
    "text": "The parallel version has to\ndo actual work with the prefix sum in the filter, whereas\nthe serial version doesn't have to do that.",
    "start": "3412960",
    "end": "3420549"
  },
  {
    "text": "But overall, the\nparallel implementation is still pretty good. OK, questions?",
    "start": "3420550",
    "end": "3425850"
  },
  {
    "start": "3425850",
    "end": "3436990"
  },
  {
    "text": "So a couple of lectures\nago, we saw this slide here.",
    "start": "3436990",
    "end": "3442110"
  },
  {
    "text": "So Charles told\nus never to write nondeterministic parallel\nprograms because it's very hard to debug these\nprograms and hard to reason",
    "start": "3442110",
    "end": "3449340"
  },
  {
    "start": "3444000",
    "end": "3444000"
  },
  {
    "text": "about them. So is there nondeterminism\nin this BFS code that we looked at?",
    "start": "3449340",
    "end": "3455050"
  },
  {
    "text": " AUDIENCE: You have\nnondeterminism in the compare-and-swap.",
    "start": "3455050",
    "end": "3460210"
  },
  {
    "text": "JULIAN SHUN: Yeah, so\nthere's nondeterminism in the compare-and-swap. So let's go back to the code.",
    "start": "3460210",
    "end": "3466015"
  },
  {
    "text": " So this compare-and-swap\nhere, there's a race there because we get\nmultiple vertices trying",
    "start": "3466015",
    "end": "3474820"
  },
  {
    "text": "to write to the parent entry of\nthe neighbor at the same time. And the one that wins\nis nondeterministic.",
    "start": "3474820",
    "end": "3480800"
  },
  {
    "text": "So the BFS tree that you get\nat the end is nondeterministic. ",
    "start": "3480800",
    "end": "3488579"
  },
  {
    "text": "OK, so let's see how we can\ntry to fix this nondeterminism.",
    "start": "3488580",
    "end": "3495510"
  },
  {
    "start": "3491000",
    "end": "3491000"
  },
  {
    "text": "OK so, as we said,\nthis is a line that causes the nondeterminism.",
    "start": "3495510",
    "end": "3502799"
  },
  {
    "text": "It turns out that we can\nactually make the output BFS tree, be deterministic\nby going over",
    "start": "3502800",
    "end": "3510540"
  },
  {
    "start": "3504000",
    "end": "3504000"
  },
  {
    "text": "the outgoing edges in each\niteration in two phases. So how this works is\nthat in the first phase,",
    "start": "3510540",
    "end": "3517830"
  },
  {
    "text": "the vertices on the\nfrontier are not actually going to write to\nthe parent array. Or they are going to\nwrite, but they're",
    "start": "3517830",
    "end": "3523960"
  },
  {
    "text": "going to be using this\nwriteMin operator. And the writeMin operator\nis an atomic operation",
    "start": "3523960",
    "end": "3531119"
  },
  {
    "text": "that guarantees that we\nhave concurrent writes to the same location. The smallest value\ngets written there.",
    "start": "3531120",
    "end": "3537090"
  },
  {
    "text": "So the value that\ngets written there is going to be deterministic. It's always going\nto be the smallest one that tries to write there.",
    "start": "3537090",
    "end": "3543990"
  },
  {
    "text": "Then in the second\nphase, each vertex is going to check\nfor each neighbor whether a parent of neighbor\nis equal to v. If it is,",
    "start": "3543990",
    "end": "3552390"
  },
  {
    "text": "that means it was the vertex\nthat successfully wrote to parent of neighbor\nin the first phase.",
    "start": "3552390",
    "end": "3557550"
  },
  {
    "text": "And therefore, it's going to\nbe responsible for placing this neighbor onto\nthe next frontier.",
    "start": "3557550",
    "end": "3564030"
  },
  {
    "text": "And we're also going to\nset parent of neighbor to be negative v. This\nis just a minor detail.",
    "start": "3564030",
    "end": "3569950"
  },
  {
    "text": "And this is because when we're\ndoing this writeMin operator, we could have a future iteration\nwhere a lower vertex tries",
    "start": "3569950",
    "end": "3576870"
  },
  {
    "text": "to visit the same vertex\nthat we already explored. But if we set this\nto a negative value, we're only going to be\nwriting non-negative values",
    "start": "3576870",
    "end": "3583380"
  },
  {
    "text": "to this location. So the writeMin on a neighbor\nthat has already been explored would never succeed.",
    "start": "3583380",
    "end": "3589065"
  },
  {
    "text": " OK, so the final BFS tree\nthat's generated by this code",
    "start": "3589065",
    "end": "3598119"
  },
  {
    "text": "is always going to be the\nsame every time you run it. I want to point out\nthat this code is still notdeterministic with\nrespect to the order",
    "start": "3598120",
    "end": "3605140"
  },
  {
    "text": "in which individual memory\nlocations get updated. So you still have a\ndeterministic race here",
    "start": "3605140",
    "end": "3610210"
  },
  {
    "text": "in the writeMin operator. But it's still better than\na nondeterministic code in that you always\nget the same BFS tree.",
    "start": "3610210",
    "end": "3617770"
  },
  {
    "text": "So how do you actually implement\nthe writeMin operation? So it turns out you can\nimplement this using",
    "start": "3617770",
    "end": "3622870"
  },
  {
    "text": "a loop with a compare-and-swap. So writeMin takes as\ninput two arguments--",
    "start": "3622870",
    "end": "3628839"
  },
  {
    "text": "the memory address that\nwe're trying to update and the new value that we\nwant to write to that address.",
    "start": "3628840",
    "end": "3634150"
  },
  {
    "text": "We're first going to set\noldval equal to the value at that memory address. And we're going to check if\nnewval is less than oldval.",
    "start": "3634150",
    "end": "3640990"
  },
  {
    "text": "If it is, then we're\ngoing to attempt to do a compare-and-swap\nat that location, writing newval into that\naddress if its initial value",
    "start": "3640990",
    "end": "3649210"
  },
  {
    "text": "was oldval. And if that succeeds,\nthen we return. Otherwise, we failed. And that means that somebody\nelse came in the meantime",
    "start": "3649210",
    "end": "3656380"
  },
  {
    "text": "and changed the value there. And therefore, we have\nto reread the old value at the memory address.",
    "start": "3656380",
    "end": "3661750"
  },
  {
    "text": "And then we repeat. And there are two ways that this\nwriteMin operator could finish.",
    "start": "3661750",
    "end": "3667840"
  },
  {
    "text": "One is if the compare-and-swap\nwas successful. The other one is if\nnewval is greater than",
    "start": "3667840",
    "end": "3675100"
  },
  {
    "text": "or equal to oldval. In that case, we no longer\nhave to try to write anymore because the value that's there\nis already smaller than what",
    "start": "3675100",
    "end": "3682013"
  },
  {
    "text": "we're trying to write.  So I implemented an\noptimized version",
    "start": "3682013",
    "end": "3689440"
  },
  {
    "text": "of this deterministic\nparallel BFS code and compared it to the\nnondeterministic version.",
    "start": "3689440",
    "end": "3695470"
  },
  {
    "text": "And it turns out\non 32 cores, it's only a little bit slower than\nthe nondeterministic version. So it's about 5% to 20% slower\non a range of different input",
    "start": "3695470",
    "end": "3704060"
  },
  {
    "text": "graphs. So this is a pretty small\nprice to pay for determinism. And you get many nice\nbenefits, such as ease",
    "start": "3704060",
    "end": "3711160"
  },
  {
    "text": "of debugging and ease of\nreasoning about the performance of your code.",
    "start": "3711160",
    "end": "3717070"
  },
  {
    "text": "Any questions? ",
    "start": "3717070",
    "end": "3725690"
  },
  {
    "text": "OK, so let me talk about\nanother optimization for breadth-first search.",
    "start": "3725690",
    "end": "3732040"
  },
  {
    "text": "And this is called the\ndirection optimization. And the idea is motivated by\nhow the sizes of the frontiers",
    "start": "3732040",
    "end": "3739570"
  },
  {
    "text": "change in a typical BFS\nalgorithm over time. So here I'm plotting\nthe frontier size",
    "start": "3739570",
    "end": "3745510"
  },
  {
    "text": "on the y-axis in log scale. And the x-axis is\nthe iteration number.",
    "start": "3745510",
    "end": "3750790"
  },
  {
    "text": "And on the left, we have a\nrandom graph, on the right, we have a parallel graph. And we see that the\nfrontier size actually",
    "start": "3750790",
    "end": "3757390"
  },
  {
    "text": "grows pretty rapidly, especially\nfor the power law graph. And then it drops\npretty rapidly. ",
    "start": "3757390",
    "end": "3764240"
  },
  {
    "text": "So this is true for many\nof the real-world graphs that we see because many of\nthem look like power law graphs.",
    "start": "3764240",
    "end": "3770440"
  },
  {
    "text": "And in the BFS algorithm,\nmost of the work is done when the frontier\nis relatively large.",
    "start": "3770440",
    "end": "3775653"
  },
  {
    "text": "So most of the\nwork is going to be done in these middle\niterations where the frontier is very large.",
    "start": "3775653",
    "end": "3781510"
  },
  {
    "text": " And it turns out that\nthere are two ways",
    "start": "3781510",
    "end": "3786609"
  },
  {
    "text": "to do breadth-first search. One way is the\ntraditional way, which I'm going to refer to\nas the top-down method.",
    "start": "3786610",
    "end": "3793660"
  },
  {
    "text": "And this is just\nwhat we did before. We look at the\nfrontier vertices, and explore all of their\noutgoing neighbors,",
    "start": "3793660",
    "end": "3799540"
  },
  {
    "text": "and mark any of the\nunexplored ones as explored, and place them on to\nthe next frontier.",
    "start": "3799540",
    "end": "3805270"
  },
  {
    "text": "But there's actually another\nway to do breadth-first search. And this is known as\nthe bottom-up method. And in the bottom-up\nmethod, I'm going",
    "start": "3805270",
    "end": "3811470"
  },
  {
    "text": "to look at all of the\nvertices in the graph that haven't been\nexplored yet, and I'm going to look at\ntheir incoming edges.",
    "start": "3811470",
    "end": "3817310"
  },
  {
    "text": "And if I find an incoming edge\nthat's on the current frontier, I can just say that that\nincoming neighbor is my parent.",
    "start": "3817310",
    "end": "3823542"
  },
  {
    "text": "And I don't even need\nto look at the rest of my incoming neighbors. So in this example here,\nvertices 9 through 12,",
    "start": "3823542",
    "end": "3829867"
  },
  {
    "text": "when they loop through\ntheir incoming edges, they found incoming\nneighbor on the frontier, and they chose that\nneighbor as their parent.",
    "start": "3829867",
    "end": "3837070"
  },
  {
    "text": "And they get marked as explored. And we can actually save some\nedge traversals here because, for example, if you\nlook at vertex 9,",
    "start": "3837070",
    "end": "3844090"
  },
  {
    "text": "and you imagine the\nedges being traversed in a top-to-bottom manner,\nthen vertex 9 is only",
    "start": "3844090",
    "end": "3850450"
  },
  {
    "text": "going to look at its\nfirst incoming edge and find the incoming\nneighbors on the frontier. So it doesn't even\nneed to inspect",
    "start": "3850450",
    "end": "3856360"
  },
  {
    "text": "the rest of the incoming\nedges because all we care about finding is just\none parent in the BFS tree.",
    "start": "3856360",
    "end": "3861430"
  },
  {
    "text": "We don't need to find all\nof the possible parents. In this example here, vertices\n13 through 15 actually ended up",
    "start": "3861430",
    "end": "3869020"
  },
  {
    "text": "wasting work because they looked\nat all of their incoming edges. And none of the incoming\nneighbors are on the frontier. So they don't actually\nfind a neighbor.",
    "start": "3869020",
    "end": "3876690"
  },
  {
    "text": "So the bottom-up\napproach turns out to work pretty well when\nthe frontier is large and many vertices have\nbeen already explored.",
    "start": "3876690",
    "end": "3882309"
  },
  {
    "text": "Because in this case, you don't\nhave to look at many vertices. And for the ones\nthat you do look at, when you scan over\ntheir incoming edges,",
    "start": "3882310",
    "end": "3889060"
  },
  {
    "text": "it's very likely\nthat early on, you'll find a neighbor that is\non the current frontier, and you can skip a bunch\nof edge traversals.",
    "start": "3889060",
    "end": "3897520"
  },
  {
    "text": "And the top-down\napproach is better when the frontier\nis relatively small.",
    "start": "3897520",
    "end": "3903130"
  },
  {
    "text": "And in a paper by\nScott Beamer in 2012, he actually studied\nthe performance of these two approaches in BFS.",
    "start": "3903130",
    "end": "3910180"
  },
  {
    "text": "And this plot here\nplots the running time versus the iteration number\nfor a power law graph",
    "start": "3910180",
    "end": "3917483"
  },
  {
    "text": "and compares the performance\nof the top-down and bottom-up approach. So we see that for\nthe first two steps,",
    "start": "3917483",
    "end": "3922570"
  },
  {
    "text": "the top-down approach is faster\nthan the bottom-up approach. But then for the\nnext couple of steps, the bottom-up approach is\nfaster than a top-down approach.",
    "start": "3922570",
    "end": "3931150"
  },
  {
    "text": "And then when we get to the\nend, the top-down approach becomes faster again.",
    "start": "3931150",
    "end": "3936730"
  },
  {
    "text": "So the top-down\napproach, as I said, is more efficient\nfor small frontiers, whereas a bottom-up\napproach is more",
    "start": "3936730",
    "end": "3942940"
  },
  {
    "text": "efficient for large frontiers. Also, I want to point out that\nin the top-down approach, when",
    "start": "3942940",
    "end": "3948850"
  },
  {
    "text": "we update the parent array,\nthat actually has to be atomic. Because we can have\nmultiple vertices trying to update the same neighbor.",
    "start": "3948850",
    "end": "3954640"
  },
  {
    "text": "But in a bottom-up approach,\nthe update to the parent array doesn't have to be atomic. Because we're scanning\nover the incoming neighbors",
    "start": "3954640",
    "end": "3961390"
  },
  {
    "text": "of any particular\nvertex v serially. And therefore, there can\nonly be one processor",
    "start": "3961390",
    "end": "3966549"
  },
  {
    "text": "that's writing to parent of v. So we choose between\nthese two approaches based",
    "start": "3966550",
    "end": "3972160"
  },
  {
    "text": "on the size of the frontier. We found that a threshold of\na frontier size of about n/20",
    "start": "3972160",
    "end": "3978869"
  },
  {
    "text": "works pretty well in practice. So if the frontier has\nmore than n/20 vertices, we used a bottom up approach.",
    "start": "3978870",
    "end": "3984460"
  },
  {
    "text": "And otherwise, we used\na top-down approach. You can also use more\nsophisticated thresholds,",
    "start": "3984460",
    "end": "3990250"
  },
  {
    "text": "such as also considering\nthe sum of out-degrees, since the actual work\nis dependent on the sum",
    "start": "3990250",
    "end": "3995829"
  },
  {
    "text": "of out-degrees of the\nvertices on the frontier. You can also use\ndifferent thresholds",
    "start": "3995830",
    "end": "4000990"
  },
  {
    "text": "for going from top-down\nto bottom-up and then another threshold for going\nfrom bottom-up back to top-down.",
    "start": "4000990",
    "end": "4008960"
  },
  {
    "text": "And in fact, that's what\nthe original paper did. They had two\ndifferent thresholds.",
    "start": "4008960",
    "end": "4014460"
  },
  {
    "text": "We also need to generate\nthe inverse graph or the transposed graph\nif we're using this method",
    "start": "4014460",
    "end": "4019830"
  },
  {
    "text": "if the graph is directed. Because if the\ngraph is directed, in the bottom-up\napproach, we actually",
    "start": "4019830",
    "end": "4025990"
  },
  {
    "text": "need to look at the\nincoming neighbors, not the outgoing neighbors. So if the graph wasn't\nalready symmetrized,",
    "start": "4025990",
    "end": "4031383"
  },
  {
    "text": "then we have to generate\nboth the incoming neighbors and outgoing neighbors\nfor each vertex. So we can do that as\na pre-processing step.",
    "start": "4031383",
    "end": "4038980"
  },
  {
    "text": "Any questions? ",
    "start": "4038980",
    "end": "4046900"
  },
  {
    "text": "OK, so how do we actually\nrepresent the frontier? So one way to\nrepresent the frontier is just use a sparse\ninteger array,",
    "start": "4046900",
    "end": "4053380"
  },
  {
    "text": "which is what we did before. Another way to do this\nis to use a dense array.",
    "start": "4053380",
    "end": "4059530"
  },
  {
    "text": "So, for example, here I\nhave an array of bytes. The array is of size n, where\nn is the number of vertices.",
    "start": "4059530",
    "end": "4065360"
  },
  {
    "text": "And I have a 1 in\nposition i if vertex i is on the frontier\nand 0 otherwise.",
    "start": "4065360",
    "end": "4071440"
  },
  {
    "text": "I can also use a bit vector\nto further compress this and then use additional bit\nlevel operations to access it.",
    "start": "4071440",
    "end": "4079869"
  },
  {
    "text": "So for the top-down approach,\na sparse representation is better because the\ntop-down approach usually",
    "start": "4079870",
    "end": "4085240"
  },
  {
    "text": "deals with small frontiers. And if we use a\nsparse array, we only have to do work proportional\nto the number of vertices",
    "start": "4085240",
    "end": "4091299"
  },
  {
    "text": "on the frontier. And then in the\nbottom-up approach, it turns out that dense\nrepresentation is better",
    "start": "4091300",
    "end": "4096370"
  },
  {
    "text": "because we're looking at\nmost of the vertices anyways. And then we need to switch\nbetween these two methods based",
    "start": "4096370",
    "end": "4103239"
  },
  {
    "text": "on the approach\nthat we're using. ",
    "start": "4103240",
    "end": "4109790"
  },
  {
    "text": "So here's some performance\nnumbers comparing the three different modes of traversal. So we have bottom-up,\ntop-down, and then",
    "start": "4109790",
    "end": "4116740"
  },
  {
    "text": "the direction\noptimizing approach using a threshold of n/20. First of all, we see that\nthe bottom-up approach",
    "start": "4116740",
    "end": "4123068"
  },
  {
    "text": "is the slowest for\nboth of these graphs. And this is because it's\ndoing a lot of wasted work",
    "start": "4123069",
    "end": "4128859"
  },
  {
    "text": "in the early iterations. We also see that the direction\noptimizing approach is always",
    "start": "4128859",
    "end": "4135039"
  },
  {
    "text": "faster than both the top-down\nand the bottom-up approach. This is because if we switch\nto the bottom-up approach",
    "start": "4135040",
    "end": "4141670"
  },
  {
    "text": "at an appropriate\ntime, then we can save a lot of edge traversals. And, for example, you can\nsee for the power law graph,",
    "start": "4141670",
    "end": "4147729"
  },
  {
    "text": "the direction\noptimizing approach is almost three times faster\nthan the top-down approach. ",
    "start": "4147729",
    "end": "4155380"
  },
  {
    "text": "The benefits of this\napproach are highly dependent on the input graph. So it works very well for\npower law and random graphs.",
    "start": "4155380",
    "end": "4164170"
  },
  {
    "text": "But if you have graphs where the\nfrontier size is always small, such as a grid graph\nor a road network,",
    "start": "4164170",
    "end": "4169870"
  },
  {
    "text": "then you would never use\na bottom-up approach. So this wouldn't actually give\nyou any performance gains.",
    "start": "4169870",
    "end": "4177130"
  },
  {
    "text": "Any questions? ",
    "start": "4177130",
    "end": "4183810"
  },
  {
    "text": "So it turns out that\nthis direction optimizing idea is more general than\njust breadth-first search.",
    "start": "4183810",
    "end": "4189220"
  },
  {
    "text": "So a couple years\nago, I developed this framework called\nLigra, where I generalized",
    "start": "4189220",
    "end": "4194710"
  },
  {
    "text": "the direction optimizing idea\nto other graph algorithms, such as betweenness centrality,\nconnected components, sparse",
    "start": "4194710",
    "end": "4201730"
  },
  {
    "text": "PageRank, shortest\npaths, and so on. And in the Ligra framework,\nwe have an EDGEMAP operator",
    "start": "4201730",
    "end": "4207280"
  },
  {
    "text": "that chooses between a\nsparse implementation and a dense implementation based\non the size of the frontier.",
    "start": "4207280",
    "end": "4213310"
  },
  {
    "text": "So the sparse here corresponds\nto the top-down approach. And dense corresponds to\nthe bottom-up approach.",
    "start": "4213310",
    "end": "4219340"
  },
  {
    "text": "And it turns out that using\nthis direction optimizing idea for these\nother applications also gives you performance\ngains in practice.",
    "start": "4219340",
    "end": "4226389"
  },
  {
    "start": "4226390",
    "end": "4231660"
  },
  {
    "text": "OK, so let me now talk about\nanother optimization, which is graph compression.",
    "start": "4231660",
    "end": "4237679"
  },
  {
    "text": "And the goal here is to reduce\nthe amount of memory usage in the graph algorithm.",
    "start": "4237680",
    "end": "4243560"
  },
  {
    "text": "So recall, this was\nour CSR representation. And in the Edges\narray, we just stored",
    "start": "4243560",
    "end": "4248690"
  },
  {
    "text": "the values of the target edges. Instead of storing\nthe actual targets,",
    "start": "4248690",
    "end": "4255080"
  },
  {
    "text": "we can actually do better by\nfirst sorting the edges so that they appear in\nnon-decreasing order",
    "start": "4255080",
    "end": "4261680"
  },
  {
    "text": "and then just storing\nthe differences between consecutive edges. And then for the first edge\nfor any particular vertex,",
    "start": "4261680",
    "end": "4268040"
  },
  {
    "text": "we'll store the difference\nbetween the target and the source of that edge. ",
    "start": "4268040",
    "end": "4274330"
  },
  {
    "text": "So, for example,\nhere, for vertex 0, the first edge is going\nto have a value of 2",
    "start": "4274330",
    "end": "4280568"
  },
  {
    "text": "because we're going to take the\ndifference between the target and the source. So 2 minus 0 is 2.",
    "start": "4280568",
    "end": "4286179"
  },
  {
    "text": "Then for the next\nedge, we're going to take the difference\nbetween the second edge and the first edge, so\n7 minus 2, which is 5.",
    "start": "4286180",
    "end": "4295270"
  },
  {
    "text": "And then similarly we do that\nfor all of the remaining edges. Notice that there are\nsome negative values here.",
    "start": "4295270",
    "end": "4301400"
  },
  {
    "text": "And this is because the target\nis smaller than the source. So in this example,\n1 is smaller than 2.",
    "start": "4301400",
    "end": "4308810"
  },
  {
    "text": "So if you do 1 minus\n2, you get a negative-- negative 1. And this can only happen\nfor the first edge",
    "start": "4308810",
    "end": "4315100"
  },
  {
    "text": "for any particular\nvertex because for all the other edges, we're\nencoding the difference",
    "start": "4315100",
    "end": "4320470"
  },
  {
    "text": "between that edge and\nthe previous edge. And we already\nsorted these edges so that they appear in\nnon-decreasing order.",
    "start": "4320470",
    "end": "4326260"
  },
  {
    "text": " OK, so this\ncompressed edges array",
    "start": "4326260",
    "end": "4332770"
  },
  {
    "text": "will typically\ncontain smaller values than this original edges array. So now we want to be\nable to use fewer bits",
    "start": "4332770",
    "end": "4341050"
  },
  {
    "text": "to represent these values. We don't want to use 32 or\n64 bits like we did before.",
    "start": "4341050",
    "end": "4346490"
  },
  {
    "text": "Otherwise, we wouldn't\nbe saving any space. So one way to reduce\nthe space usage is to store these values using\nwhat's called a variable length",
    "start": "4346490",
    "end": "4354400"
  },
  {
    "text": "code or a k-bit code. And the idea is to encode each\nvalue in chunks of k bits,",
    "start": "4354400",
    "end": "4360400"
  },
  {
    "text": "where for each chunk, we use k\nminus 1 bits for the data and 1 bit as the continue bit.",
    "start": "4360400",
    "end": "4367190"
  },
  {
    "text": "So for example, let's\nencode the integer 401 using 8-bit or byte codes.",
    "start": "4367190",
    "end": "4372489"
  },
  {
    "text": "So first, we're going to write\nthis value out in binary. And then we're going to\ntake the bottom 7 bits,",
    "start": "4372490",
    "end": "4377650"
  },
  {
    "text": "and we're going to\nplace that into the data field of the first chunk. And then in the last\nbit of this chunk,",
    "start": "4377650",
    "end": "4384133"
  },
  {
    "text": "we're going to check if\nwe still have any more bits that we need to encode. And if we do, then we're going\nto set a 1 in the continue bit",
    "start": "4384133",
    "end": "4390280"
  },
  {
    "text": "position. And then we create\nanother chunk. We'll replace the next\n7 bits into the data",
    "start": "4390280",
    "end": "4396160"
  },
  {
    "text": "field of that chunk. And then now we're actually done\nencoding this integer value. So we can place a 0\nin the continue bit.",
    "start": "4396160",
    "end": "4403659"
  },
  {
    "text": "So that's how the\nencoding works. And decoding is just doing\nthis process backwards.",
    "start": "4403660",
    "end": "4409090"
  },
  {
    "text": "So you read chunks until\nyou find a chunk with a 0 continue bit. And then you shift\nall of the data values",
    "start": "4409090",
    "end": "4415420"
  },
  {
    "text": "left accordingly and\nsum them together to reconstruct the integer\nvalue that you encoded.",
    "start": "4415420",
    "end": "4422210"
  },
  {
    "text": "One performance issue\nthat might occur here is that when you're\ndecoding, you have to check this continue\nbit for every chunk",
    "start": "4422210",
    "end": "4429670"
  },
  {
    "text": "and decide what to do\nbased on that continue bit. And this is actually\nunpredictable branch.",
    "start": "4429670",
    "end": "4436139"
  },
  {
    "text": "So you can suffer from\nbranch mispredictions from checking this continue bit.",
    "start": "4436140",
    "end": "4443420"
  },
  {
    "text": "So one way you can optimize\nthis is to get rid of these continue bits. And the idea here is\nto first figure out",
    "start": "4443420",
    "end": "4450219"
  },
  {
    "text": "how many bytes\nyou need to encode each integer in the sequence. And then you group\ntogether integers",
    "start": "4450220",
    "end": "4458020"
  },
  {
    "text": "that require the same\nnumber of bytes to encode. Use a run-length encoding idea\nto encode all of these integers",
    "start": "4458020",
    "end": "4465190"
  },
  {
    "text": "together by using a header\nbyte, where in the header byte, you use the lower 6 bits to\nstore the size of the group",
    "start": "4465190",
    "end": "4471940"
  },
  {
    "text": "and the highest 2 bits to\nstore the number of bytes each of these integers\nneeds to decode.",
    "start": "4471940",
    "end": "4478690"
  },
  {
    "text": "And now all of the\nintegers in this group will just be stored\nafter this header byte.",
    "start": "4478690",
    "end": "4484449"
  },
  {
    "text": "And we'd know exactly how many\nbytes they need to decode. So we don't need to store a\ncontinue bit in these chunks.",
    "start": "4484450",
    "end": "4490975"
  },
  {
    "text": " This does slightly\nincrease the space usage.",
    "start": "4490975",
    "end": "4496000"
  },
  {
    "text": "But it makes decoding cheaper\nbecause we no longer have to suffer from\nbranch mispredictions",
    "start": "4496000",
    "end": "4502030"
  },
  {
    "text": "from checking this continue bit. OK, so now we have to decode\nthese edge lists on the fly",
    "start": "4502030",
    "end": "4509800"
  },
  {
    "text": "as we're running our algorithm. If we decoded everything\nat the beginning, we wouldn't actually\nbe saving any space. We need to decode these\nedges as we access them",
    "start": "4509800",
    "end": "4516820"
  },
  {
    "text": "in our algorithm. Since we encoded\nall of these edge lists separately\nfor each vertex,",
    "start": "4516820",
    "end": "4522460"
  },
  {
    "text": "we can decode all\nof them in parallel.  And each vertex just decodes\nits edge list sequentially.",
    "start": "4522460",
    "end": "4529660"
  },
  {
    "text": "But what about\nhigh-degree vertices? If you have a\nhigh-degree vertex, you stop to decode its\nedge list sequentially.",
    "start": "4529660",
    "end": "4535830"
  },
  {
    "text": "And if you're running\nthis in parallel, this could lead\nto load imbalance.",
    "start": "4535830",
    "end": "4541400"
  },
  {
    "text": "So one way to fix this is,\ninstead of just encoding the whole thing sequentially,\nyou can chunk it up",
    "start": "4541400",
    "end": "4546970"
  },
  {
    "text": "into chunks of size T.\nAnd then for each chunk, you encode it like\nyou did before,",
    "start": "4546970",
    "end": "4552280"
  },
  {
    "text": "where you store the first value\nrelative to the source vertex and then all of the other values\nrelative to the previous edge.",
    "start": "4552280",
    "end": "4559130"
  },
  {
    "text": "And now you can actually\ndecode the first value here for each of these\nchunks all in parallel",
    "start": "4559130",
    "end": "4564460"
  },
  {
    "text": "without having to wait for the\nprevious edge to be decoded. And then this gives us\nmuch more parallelism",
    "start": "4564460",
    "end": "4571730"
  },
  {
    "text": "because all of these chunks\ncan be decoded in parallel. And we found that a value of\nT-- where T is the chunk size--",
    "start": "4571730",
    "end": "4580690"
  },
  {
    "text": "between 100 and 10,000 works\npretty well in practice. ",
    "start": "4580690",
    "end": "4586940"
  },
  {
    "text": "OK, so I'm not\ngoing to have time to go over the experiments. But at a high level,\nthe experiments",
    "start": "4586940",
    "end": "4593080"
  },
  {
    "text": "show that compression\nschemes do save space. And serially, it's\nonly slightly slower",
    "start": "4593080",
    "end": "4600250"
  },
  {
    "text": "than the uncompressed version. But surprisingly, when\nyou run it in parallel, it actually becomes faster\nthan the uncompressed version.",
    "start": "4600250",
    "end": "4607000"
  },
  {
    "text": "And this is because these graph\nalgorithms are memory bound. And we're using less memory. You can alleviate this\nmemory subsystem bottleneck",
    "start": "4607000",
    "end": "4614350"
  },
  {
    "text": "and get better scalability. And the decoding part of\nthese compressed algorithms",
    "start": "4614350",
    "end": "4620199"
  },
  {
    "text": "actually gets very\ngood parallel speedup because they're just\ndoing local operations. ",
    "start": "4620200",
    "end": "4629050"
  },
  {
    "text": "OK, so let me summarize now. So we saw some properties\nof real-world graphs.",
    "start": "4629050",
    "end": "4634750"
  },
  {
    "text": "We saw that they're quite\nlarge, but they can still fit on a multi-core server. And they're relatively sparse.",
    "start": "4634750",
    "end": "4640900"
  },
  {
    "text": "They also have a power\nlaw degree distribution. Many graph algorithms are\nirregular in that they involve",
    "start": "4640900",
    "end": "4646990"
  },
  {
    "text": "many random memory accesses. So that becomes a bottleneck\nof the performance of these algorithms.",
    "start": "4646990",
    "end": "4652210"
  },
  {
    "text": "And you can improve performance\nwith algorithmic optimization, such as using this\ndirection optimization",
    "start": "4652210",
    "end": "4659170"
  },
  {
    "text": "and also by creating\nand exploiting locality, for example, by using\nthis bit vector optimization.",
    "start": "4659170",
    "end": "4664929"
  },
  {
    "text": "And finally,\noptimizations for graphs might work well\nfor certain graphs, but they might not work\nwell for other graphs.",
    "start": "4664930",
    "end": "4670480"
  },
  {
    "text": "For example, the direction\noptimization idea works well for power law\ngraphs but not for road graphs. So when you're trying to\noptimize your graph algorithm,",
    "start": "4670480",
    "end": "4677560"
  },
  {
    "text": "we should definitely test it\non different types of graphs and see where it works well\nand where it doesn't work.",
    "start": "4677560",
    "end": "4683842"
  },
  {
    "text": "So that's all I have. If you have any\nadditional questions, please feel free to\nask me after class.",
    "start": "4683842",
    "end": "4689020"
  },
  {
    "text": "And as a reminder, we have\na guest lecture on Thursday by Professor Johnson of\nthe MIT Math Department.",
    "start": "4689020",
    "end": "4695770"
  },
  {
    "text": "And he'll be talking about\nhigh-level languages, so please be sure to attend. ",
    "start": "4695770",
    "end": "4719385"
  }
]
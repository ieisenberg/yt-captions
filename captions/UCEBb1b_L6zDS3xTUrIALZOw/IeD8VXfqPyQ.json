[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5620"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5620",
    "end": "12280"
  },
  {
    "text": "To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12280",
    "end": "18840"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18840",
    "end": "25109"
  },
  {
    "start": "23000",
    "end": "225000"
  },
  {
    "text": "TOMASO POGGIO: So I'll speak\nabout i-theory, visual cortex,",
    "start": "25110",
    "end": "33930"
  },
  {
    "text": "deep learning networks.  The background for this is\nthis conceptual framework",
    "start": "33930",
    "end": "44270"
  },
  {
    "text": "that we take as a\nguide to present work",
    "start": "44270",
    "end": "51420"
  },
  {
    "text": "in vision in this center-- The idea that you have a\nphase in visual perception,",
    "start": "51420",
    "end": "62350"
  },
  {
    "text": "essentially up to\nthe first saccade-- say, 100 milliseconds\nfrom onset of an image--",
    "start": "62350",
    "end": "72470"
  },
  {
    "text": "in which most of the\nprocessing is feedforward",
    "start": "72470",
    "end": "78770"
  },
  {
    "text": "in the visual cortex. And that top-down signals--",
    "start": "78770",
    "end": "87190"
  },
  {
    "text": " I hate the term\nfeedback in this case,",
    "start": "87190",
    "end": "93500"
  },
  {
    "text": "but back projections going\nfrom higher visual areas,",
    "start": "93500",
    "end": "99530"
  },
  {
    "text": "like inferotemporal cortex, back\nto V2 and other cortical areas",
    "start": "99530",
    "end": "106610"
  },
  {
    "text": "are not active in this\nfirst hundred milliseconds. Now, all of this is a conjecture\nbased on a number of data.",
    "start": "106610",
    "end": "120320"
  },
  {
    "text": "So it has to be proven. For us it's just a\nmotivation, a guide,",
    "start": "120320",
    "end": "128000"
  },
  {
    "text": "to first studying feedforward\nprocessing in, as I said,",
    "start": "128000",
    "end": "133550"
  },
  {
    "text": "the first 100\nmilliseconds or so. ",
    "start": "133550",
    "end": "138920"
  },
  {
    "text": "And to think that other types of\ntheory, like generative models,",
    "start": "138920",
    "end": "148790"
  },
  {
    "text": "probabilistic inference\nthat you have heard about, visual routines you have\nheard kind of from Shimon,",
    "start": "148790",
    "end": "156730"
  },
  {
    "text": "are important not so much in\nthe first 100 milliseconds, but later on.",
    "start": "156730",
    "end": "163620"
  },
  {
    "text": "Especially when feedback\nthrough back projection, but also through\nmovements of the eyes",
    "start": "163620",
    "end": "171530"
  },
  {
    "text": "that acquire new images\ndepending on the first one you have seen, come into play.",
    "start": "171530",
    "end": "178520"
  },
  {
    "text": "OK. This is just to\nmotivate feedforward.",
    "start": "178520",
    "end": "183870"
  },
  {
    "text": "And of course, the evidence\nI refer to is evidence like--",
    "start": "183870",
    "end": "189920"
  },
  {
    "text": "you have heard from Jim DiCarlo,\nfor the physiology there is quite a bit of data showing\nthat neurons in IT become",
    "start": "189920",
    "end": "200510"
  },
  {
    "text": "active and selective for what\nis in the image about 80 or 90",
    "start": "200510",
    "end": "206540"
  },
  {
    "text": "milliseconds after\nonset of the stimulus. And this basically implies that\nthere are no big feedback loops",
    "start": "206540",
    "end": "213830"
  },
  {
    "text": "from one area to another one. It takes 40 milliseconds to\nget to V1, and 10 milliseconds",
    "start": "213830",
    "end": "220459"
  },
  {
    "text": "or so for each of\nthe next areas. So the problem is,\ncomputational vision--",
    "start": "220460",
    "end": "230630"
  },
  {
    "start": "225000",
    "end": "240000"
  },
  {
    "text": "the guy on the\nleft is David Marr. ",
    "start": "230630",
    "end": "242910"
  },
  {
    "start": "240000",
    "end": "328000"
  },
  {
    "text": "And here it's really\nwhere most probably a lot of object\nrecognition takes",
    "start": "242910",
    "end": "251430"
  },
  {
    "text": "place, is the ventral\nstream from V1 to V2,",
    "start": "251430",
    "end": "257160"
  },
  {
    "text": "V4, and the IT complex. ",
    "start": "257160",
    "end": "263340"
  },
  {
    "text": "So that's the back of the head. As I said, it takes\n40 milliseconds for electrical signals to\ncome from the eye in the front",
    "start": "263340",
    "end": "273690"
  },
  {
    "text": "through the LGN back\nto neurons in V1. Simple complex cells.",
    "start": "273690",
    "end": "279320"
  },
  {
    "text": "And then for signals to go\nfrom the back to the front, that's the feedforward part.",
    "start": "279320",
    "end": "289150"
  },
  {
    "text": "And on the bottom right, you\nhave seen this picture already.",
    "start": "289150",
    "end": "294419"
  },
  {
    "text": "This is from Van Essen,\nedited recently by Movshon. ",
    "start": "294420",
    "end": "301370"
  },
  {
    "text": "It's the size of the areas\nand the size of the connection are roughly proportional to the\nnumber of neurons and fibers.",
    "start": "301370",
    "end": "309910"
  },
  {
    "text": "So you see that V1\nis as big as V2. they both have about\n200 million neurons.",
    "start": "309910",
    "end": "316350"
  },
  {
    "text": "And V4 is about 50 million,\nand the inferotemporal complex is probably 100 million or so.",
    "start": "316350",
    "end": "322620"
  },
  {
    "start": "322620",
    "end": "333800"
  },
  {
    "start": "328000",
    "end": "352000"
  },
  {
    "text": "Our brain is about\none million flies. A fly is around\n300,000 neurons or so.",
    "start": "333800",
    "end": "342129"
  },
  {
    "text": "A bee is one million. ",
    "start": "342130",
    "end": "350710"
  },
  {
    "text": "And as I think Jim\nDiCarlo mentioned,",
    "start": "350710",
    "end": "357030"
  },
  {
    "start": "352000",
    "end": "540000"
  },
  {
    "text": "there are these models\nthat have been developed since Hubel and Wiesel--",
    "start": "357030",
    "end": "362924"
  },
  {
    "text": "so that's '59-- that tried to\nmodel feedforward processing",
    "start": "362924",
    "end": "372720"
  },
  {
    "text": "from V1 to IT. And they start with simple\nand complex cells, this S1",
    "start": "372720",
    "end": "382310"
  },
  {
    "text": "and C1, simple cells being\nessentially equivalent to Gabor filters, oriented Gabor\nfilters in different positions,",
    "start": "382310",
    "end": "394210"
  },
  {
    "text": "different orientations. And then complex cells that\nput together the signals",
    "start": "394210",
    "end": "402300"
  },
  {
    "text": "from simple cells of the\nsame orientation preference,",
    "start": "402300",
    "end": "407940"
  },
  {
    "text": "but different position, and\nso have some more position tolerance than simple cells.",
    "start": "407940",
    "end": "414930"
  },
  {
    "text": "And then a repetition of this\nbasic scheme, with S2 cells",
    "start": "414930",
    "end": "420180"
  },
  {
    "text": "that are representing\nmore complex-- let's call them features--",
    "start": "420180",
    "end": "425969"
  },
  {
    "text": "than lines. Maybe a combination of lines.",
    "start": "425970",
    "end": "431322"
  },
  {
    "text": "And then C2 cells\nagain pulling together",
    "start": "431322",
    "end": "436410"
  },
  {
    "text": "cells of the same\npreference in order to get more invariance\nto position.",
    "start": "436410",
    "end": "442650"
  },
  {
    "text": "And there is evidence from the\nold work of Hubel and Wiesel",
    "start": "442650",
    "end": "450509"
  },
  {
    "text": "about simple and\ncomplex cells in V1. So S1 and C1, although\nthe morphological identity",
    "start": "450510",
    "end": "456690"
  },
  {
    "text": "of complex and simple cells\nis still an open question-- you know, which specific cells. We can discuss that later.",
    "start": "456690",
    "end": "465030"
  },
  {
    "text": "But for the rest, this hierarchy\ncontinuing in other areas, like V2 and V4 and IT,\nthis is one conjecture",
    "start": "465030",
    "end": "474495"
  },
  {
    "text": "in model like this. ",
    "start": "474495",
    "end": "479560"
  },
  {
    "text": "And we, like other\nones before us,",
    "start": "479560",
    "end": "487600"
  },
  {
    "text": "modeled back 15 years\nago this different area.",
    "start": "487600",
    "end": "495190"
  },
  {
    "text": "It's V1, V2, and V4\nwith this kind of model. And the reason to\ndo so was not really",
    "start": "495190",
    "end": "503410"
  },
  {
    "text": "to do object\nrecognition, but it was to try to see\nwhether we could get",
    "start": "503410",
    "end": "510490"
  },
  {
    "text": "the physiological properties\nof a different sense in such a feedforward\nmodel, the ones that people have had recorded\nfrom and published about.",
    "start": "510490",
    "end": "518710"
  },
  {
    "text": " And we could do that to\nreproduce the property.",
    "start": "518710",
    "end": "525410"
  },
  {
    "text": "Of course, some of them\nwe put in properties of simple and complex cells. But other ones, like how\nmuch invariance to position",
    "start": "525410",
    "end": "534010"
  },
  {
    "text": "there was in the top\nlevel, we got it out from the model\nconsistent with the data.",
    "start": "534010",
    "end": "539950"
  },
  {
    "text": " One surprising thing that\nwe had with this model",
    "start": "539950",
    "end": "546040"
  },
  {
    "start": "540000",
    "end": "736000"
  },
  {
    "text": "was that, although it was not\ndesigned in order to perform",
    "start": "546040",
    "end": "551620"
  },
  {
    "text": "well at object recognition, it\ndid actually work pretty well. So the kind of things you\nhave to think about this",
    "start": "551620",
    "end": "559740"
  },
  {
    "text": "is rapid categorization. You have seen that already.",
    "start": "559740",
    "end": "565100"
  },
  {
    "text": "And the task is, for each image,\nis there an animal or not?",
    "start": "565100",
    "end": "572380"
  },
  {
    "text": "And you can kind of get the\nfeeling that you can do that.",
    "start": "572380",
    "end": "585790"
  },
  {
    "text": "In the real experiment,\nyou have an image and then a mask, another image. And then you can say\nyes, there is an image,",
    "start": "585790",
    "end": "592540"
  },
  {
    "text": "or no, there is not. This is called rapid\ncategorization.",
    "start": "592540",
    "end": "601300"
  },
  {
    "text": "It was introduced\nby Molly Potter, and more recently Simon\nThorpe in France used it.",
    "start": "601300",
    "end": "607779"
  },
  {
    "text": "And it's a way to\nforce the observer to work in a feedforward mode,\nbecause you don't have the time",
    "start": "607780",
    "end": "615580"
  },
  {
    "text": "to move your eyes, to fixate. There is some\nevidence that the mask may stop the back\nprojections from working.",
    "start": "615580",
    "end": "626980"
  },
  {
    "text": "So this is a\nsituation in which you could compare human performance\nto these feedforward models,",
    "start": "626980",
    "end": "634870"
  },
  {
    "text": "which are not a complete\ndescription of vision anyway, because they don't take into\naccount different eye fixation",
    "start": "634870",
    "end": "642850"
  },
  {
    "text": "and feedbacks and\nhigher processes, like-- like I said, probabilistic\ninference and routines.",
    "start": "642850",
    "end": "652399"
  },
  {
    "text": "Whatever it happens, very likely\nin normal vision, in which you have time to look around.",
    "start": "652400",
    "end": "659680"
  },
  {
    "text": "So in this case, this\nd prime is a measure",
    "start": "659680",
    "end": "664990"
  },
  {
    "text": "of performance, how well\nyou're doing this task. And you can see, first of\nall, the absolute performance,",
    "start": "664990",
    "end": "673930"
  },
  {
    "text": "80% correct on a\ncertain database. This task, animal no animal,\nis similar between the model",
    "start": "673930",
    "end": "681100"
  },
  {
    "text": "in humans. And images that are\ndifficult for people,",
    "start": "681100",
    "end": "689110"
  },
  {
    "text": "like images in which\nthere is a lot of clutter, the animals are small, are\nalso difficult for the model.",
    "start": "689110",
    "end": "696310"
  },
  {
    "text": "And the easy ones\nare easy for both. So there is a correlation\nbetween models and humans.",
    "start": "696310",
    "end": "702399"
  },
  {
    "text": " This does not say that the\nmodel is correct, of course,",
    "start": "702400",
    "end": "708639"
  },
  {
    "text": "but it gives a hint that\nmodel of this type capture",
    "start": "708640",
    "end": "716110"
  },
  {
    "text": "something of what's going\non in the visual pathway. And Jim DiCarlo spoke about\na more sophisticated version",
    "start": "716110",
    "end": "724840"
  },
  {
    "text": "of these feedforward\nmodels, including training with back propagation,\nthat gives pretty good results",
    "start": "724840",
    "end": "731649"
  },
  {
    "text": "also in terms of\nagreement between neurons and units in the model.",
    "start": "731650",
    "end": "736840"
  },
  {
    "start": "736000",
    "end": "834000"
  },
  {
    "text": "So the question is\nwhy these models work.",
    "start": "736840",
    "end": "743110"
  },
  {
    "text": "They're very\nsimple, feedforward. It has been surprisingly\ndifficult to understand why",
    "start": "743110",
    "end": "753370"
  },
  {
    "text": "they work as well as they do. When I started to work on this\nkind of things 15 years ago,",
    "start": "753370",
    "end": "760310"
  },
  {
    "text": "I thought this kind of\narchitecture would not work. ",
    "start": "760310",
    "end": "766910"
  },
  {
    "text": "But then they worked much\nbetter than I thought. ",
    "start": "766910",
    "end": "772690"
  },
  {
    "text": "And if you believe deep learning\nthese days, which I do--",
    "start": "772690",
    "end": "778850"
  },
  {
    "text": "for instance, in\nperformance on ImageNet-- my guess is they work\nbetter than humans,",
    "start": "778850",
    "end": "784820"
  },
  {
    "text": "actually, because the\nright comparison for humans on ImageNet would be the\nrapid categorization one.",
    "start": "784820",
    "end": "794170"
  },
  {
    "text": "So they present images briefly.  Because that's what the\nmodels have-- just one image.",
    "start": "794170",
    "end": "800329"
  },
  {
    "text": "No chance of getting\na second view. Anyway, that's a more\ncomplex discussion",
    "start": "800330",
    "end": "808010"
  },
  {
    "text": "that has to do also\nwith how to model the fact that in our\neyes, in our cortex,",
    "start": "808010",
    "end": "816024"
  },
  {
    "text": "every-- solution\ndepends on eccentricity. It's a pretty rapidly\ndecaying resolution",
    "start": "816025",
    "end": "823610"
  },
  {
    "text": "as you go away from\nthe fovea, and has some significant implications\nfor all these topics.",
    "start": "823610",
    "end": "833210"
  },
  {
    "text": "I'll get to that. What I want to do\ntoday is, one way",
    "start": "833210",
    "end": "839750"
  },
  {
    "start": "834000",
    "end": "944000"
  },
  {
    "text": "to look at this to\ntry to understand how these kind of\nfeedforward models work-- ",
    "start": "839750",
    "end": "847750"
  },
  {
    "text": "i-theory is based on\ntrying to understand how models that are\nsimple and complex cells",
    "start": "847750",
    "end": "857540"
  },
  {
    "text": "and can be integrated in a\nhierarchical architecture can provide a signature\nset of features that",
    "start": "857540",
    "end": "871070"
  },
  {
    "text": "are invariant to transformations\nobserved during development,",
    "start": "871070",
    "end": "876980"
  },
  {
    "text": "and at the same time\nkeep selectivity. You don't lose any selectivity\nto different objects.",
    "start": "876980",
    "end": "885530"
  },
  {
    "text": " And then I want to\nsee what they say",
    "start": "885530",
    "end": "893710"
  },
  {
    "text": "about deep convolutional\nlearning networks,",
    "start": "893710",
    "end": "900280"
  },
  {
    "text": "and look at some of the-- beginning with theory\nabout deep learning.",
    "start": "900280",
    "end": "909010"
  },
  {
    "text": "And then I want to look at\na couple of predictions,",
    "start": "909010",
    "end": "917260"
  },
  {
    "text": "particularly related to\neccentricity-dependent resolution coming\nfrom i-theory, that",
    "start": "917260",
    "end": "924210"
  },
  {
    "text": "are interesting for the sake\nof physics and modeling. And then it's\nbasically garbage time,",
    "start": "924210",
    "end": "932260"
  },
  {
    "text": "if you're interested\nin mathematical details and proofs of theorems\nand historical background.",
    "start": "932260",
    "end": "941110"
  },
  {
    "text": "OK. Let's start with i-theory. ",
    "start": "941110",
    "end": "946540"
  },
  {
    "start": "944000",
    "end": "996000"
  },
  {
    "text": "These are the kind of things\nthat we want, ideally, to explain. This is the visual\ncortex on the left.",
    "start": "946540",
    "end": "954040"
  },
  {
    "text": "Models like HMAX, or\nfeedforward models.",
    "start": "954040",
    "end": "959290"
  },
  {
    "text": "And on the right are\nthe deep learning convolutional networks,\na couple of them,",
    "start": "959290",
    "end": "968050"
  },
  {
    "text": "which basically have\nconvolutional stage stages very similar to S1, and\npooling stages similar to C1.",
    "start": "968050",
    "end": "976450"
  },
  {
    "text": " But quite a lot of those layers.",
    "start": "976450",
    "end": "982502"
  },
  {
    "start": "982502",
    "end": "988350"
  },
  {
    "text": "How many of you know\nabout deep learning? Everybody, right? ",
    "start": "988350",
    "end": "995440"
  },
  {
    "text": "OK. These are the kind of questions\nthat i-theory tries to answer--",
    "start": "995440",
    "end": "1003399"
  },
  {
    "start": "996000",
    "end": "1051000"
  },
  {
    "text": "why these hierarchies\nwork well, what is really visual cortex,\nwhat is the goal of V1 to IT.",
    "start": "1003400",
    "end": "1012343"
  },
  {
    "text": " We know a lot about\nsimple and complex cells,",
    "start": "1012343",
    "end": "1018520"
  },
  {
    "text": "but again, what is\nthe computational goal of these simple\nand complex cells?",
    "start": "1018520",
    "end": "1026770"
  },
  {
    "text": "Why do we have Gabor\ntuning in the early areas? And why do we have\nquite generic tuning,",
    "start": "1026770",
    "end": "1036339"
  },
  {
    "text": "like in the first visual area,\nbut quite specific tuning to different types of\nobjects like faces and bodies",
    "start": "1036339",
    "end": "1045990"
  },
  {
    "text": "higher up? ",
    "start": "1045990",
    "end": "1053680"
  },
  {
    "start": "1051000",
    "end": "1082000"
  },
  {
    "text": "The main hypothesis with\nstarting i-theory is that one of the main goals of\nthe visual cortex--",
    "start": "1053680",
    "end": "1062080"
  },
  {
    "text": "it's a hypothesis-- is to\ncompute a set of features, a representation of images, that\nis invariant to transformations",
    "start": "1062080",
    "end": "1072520"
  },
  {
    "text": "that the organism\nhas experienced-- visual transformations--\nand remains selective.",
    "start": "1072520",
    "end": "1080920"
  },
  {
    "text": "Now, why is\ninvariance important? ",
    "start": "1080920",
    "end": "1088610"
  },
  {
    "start": "1082000",
    "end": "1675000"
  },
  {
    "text": "A lot of the problem\nof recognizing objects is the fact that I can\nsee once Rosalie's face,",
    "start": "1088610",
    "end": "1098200"
  },
  {
    "text": "and then the next time\nit's the same face, but the image is\ncompletely different,",
    "start": "1098200",
    "end": "1103300"
  },
  {
    "text": "for it's much bigger\nnow because I'm closer, or the illumination\nis different. So the pixels are different.",
    "start": "1103300",
    "end": "1109930"
  },
  {
    "text": "And from one single object,\nyou can produce in this way-- through translation, scaling,\ndifferent illumination,",
    "start": "1109930",
    "end": "1120070"
  },
  {
    "text": "viewpoint-- you can produce\nthousands of different images.",
    "start": "1120070",
    "end": "1126480"
  },
  {
    "text": "So the intuition\nis that if I could get a computer description--",
    "start": "1126480",
    "end": "1133050"
  },
  {
    "text": "say, long vectors of\nfeatures of her face-- that does not change under\nthese transformations,",
    "start": "1133050",
    "end": "1141690"
  },
  {
    "text": "recognition would\nbe much easier. Easier means,\nespecially, that I could",
    "start": "1141690",
    "end": "1148380"
  },
  {
    "text": "learn to recognize an object\nwith much fewer labeled examples.",
    "start": "1148380",
    "end": "1153465"
  },
  {
    "text": " Here on the right you have\na very simple demonstration",
    "start": "1153465",
    "end": "1163500"
  },
  {
    "text": "of what I mean,\nempirical demonstration.  So we have at the\nbottom different cars",
    "start": "1163500",
    "end": "1176640"
  },
  {
    "text": "and different planes. And there is a linear classifier\nwhich is trained directly",
    "start": "1176640",
    "end": "1181980"
  },
  {
    "text": "on the pixel. Very stupid classifier. And you train it with\none car and one plane--",
    "start": "1181980",
    "end": "1194280"
  },
  {
    "text": "this is on the left-- or two cars, two planes.",
    "start": "1194280",
    "end": "1199679"
  },
  {
    "text": "And then you test\non other images. And as you can see,\nwhen it's trained",
    "start": "1199680",
    "end": "1207060"
  },
  {
    "text": "with the bottom examples, which\nare at all kinds of viewpoints and sizes, the performance of\nthe classifier in answering",
    "start": "1207060",
    "end": "1216570"
  },
  {
    "text": "is this a car or is\nthis a plane, it's 50%. It's chance. Does not learn at all.",
    "start": "1216570",
    "end": "1224580"
  },
  {
    "text": "On the other hand, suppose\nI have an oracle which is--",
    "start": "1224580",
    "end": "1229809"
  },
  {
    "text": "I will conjecture\nis visual cortex, essentially, that\ngives you the feature",
    "start": "1229810",
    "end": "1236370"
  },
  {
    "text": "vectors for each image,\nwhich is invariant to these transformations.",
    "start": "1236370",
    "end": "1241660"
  },
  {
    "text": "So it's like having images\nof cars in this line B. They're all in the same\nposition, same illumination,",
    "start": "1241660",
    "end": "1250920"
  },
  {
    "text": "and so on, and the\nsame for the planes. And I repeat this experiment. I use one pair--",
    "start": "1250920",
    "end": "1258360"
  },
  {
    "text": "one car, one plane-- to train, or two\ncars, two planes,",
    "start": "1258360",
    "end": "1264930"
  },
  {
    "text": "and I see immediately that\nwhen tested on new images, this classifier is close to 90%.",
    "start": "1264930",
    "end": "1274320"
  },
  {
    "text": "So much better.  So correcting-- having invariant\nrepresentation can help a lot.",
    "start": "1274320",
    "end": "1285420"
  },
  {
    "text": "That's the empirical,\nsimple demonstration. And you can prove theorems\nsaying the same thing,",
    "start": "1285420",
    "end": "1293980"
  },
  {
    "text": "that if you have an\ninvariant representation, you can have a much lower\nsimple complexity, which",
    "start": "1293980",
    "end": "1305880"
  },
  {
    "text": "means you need much\nfewer labeled examples",
    "start": "1305880",
    "end": "1311340"
  },
  {
    "text": "to train a classifier to achieve\na certain level of accuracy.",
    "start": "1311340",
    "end": "1317200"
  },
  {
    "text": "So how can you compute an\ninvariant representation?",
    "start": "1317200",
    "end": "1322710"
  },
  {
    "text": "There are many ways to do it. ",
    "start": "1322710",
    "end": "1327900"
  },
  {
    "text": "But I'll describe\nto you one which I think is attractive, because\nit's neurophysiologically very",
    "start": "1327900",
    "end": "1336720"
  },
  {
    "text": "plausible. The basic assumption\nI'm making here",
    "start": "1336720",
    "end": "1341820"
  },
  {
    "text": "is that neurons are\nvery slow devices.",
    "start": "1341820",
    "end": "1347070"
  },
  {
    "text": "They don't do well\na lot of things.",
    "start": "1347070",
    "end": "1352269"
  },
  {
    "text": "One of the things\nthey do probably best is high-dimensional\ndot products. ",
    "start": "1352270",
    "end": "1360340"
  },
  {
    "text": "And the reason is that\nyou have a dendritic tree,",
    "start": "1360340",
    "end": "1367529"
  },
  {
    "text": "and in cortical neurons you\nhave between 1,000 and 10,000 synapses.",
    "start": "1367530",
    "end": "1373559"
  },
  {
    "text": "So you have between\n1,000 and 10,000 inputs. And each input gets\nessentially multiplied",
    "start": "1373560",
    "end": "1382950"
  },
  {
    "text": "by the weight of\nthe synapse, which can be changed during learning.",
    "start": "1382950",
    "end": "1388559"
  },
  {
    "text": "It's plastic. And then the post-synaptic\ndepolarization",
    "start": "1388560",
    "end": "1397309"
  },
  {
    "text": "or hyperpolarization, so\nthe electrical changes to the synapses, get all\nsummated in the soma.",
    "start": "1397310",
    "end": "1404290"
  },
  {
    "text": "So you have some i. Xi are your inputs,\nWi are your synapses.",
    "start": "1404290",
    "end": "1409620"
  },
  {
    "text": "That's a dot product. And this happens automatically,\nwithin a millisecond.",
    "start": "1409620",
    "end": "1416170"
  },
  {
    "text": "So it's one of the few\nthings that neurons do well.",
    "start": "1416170",
    "end": "1421690"
  },
  {
    "text": "It's, I think, one of the\ndistinctive features of neurons of the brain relative to\nour electronic components,",
    "start": "1421690",
    "end": "1429470"
  },
  {
    "text": "that in each neuron,\neach unit in the brain, there are about 10,000\nwires getting in or out.",
    "start": "1429470",
    "end": "1438419"
  },
  {
    "text": "When I say in, transistor\nor logical units in our computers,\nthe number of wires",
    "start": "1438420",
    "end": "1445620"
  },
  {
    "text": "is more like three or four. So this is the assumption,\nthat this kind of dot products",
    "start": "1445620",
    "end": "1452820"
  },
  {
    "text": "are easy to do. And so this suggests\nthis kind of algorithm",
    "start": "1452820",
    "end": "1460289"
  },
  {
    "text": "for computing invariance. Suppose you are a\nbaby in the cradle.",
    "start": "1460290",
    "end": "1466230"
  },
  {
    "text": "You're playing with a toy-- it's a bike-- and you are\nrotating it, for instance.",
    "start": "1466230",
    "end": "1471730"
  },
  {
    "text": "For simplicity. We'll do more complex things. The unsupervised learning that\nyou need to do at this point",
    "start": "1471730",
    "end": "1480360"
  },
  {
    "text": "is just to store the movie\nof what happens to your toy.",
    "start": "1480360",
    "end": "1485910"
  },
  {
    "text": "For instance, suppose you\nget a perfect rotation. This is a movie up there. There are eight frames.",
    "start": "1485910",
    "end": "1493420"
  },
  {
    "text": "Yeah. You store those, and\nyou keep them forever. ",
    "start": "1493420",
    "end": "1501170"
  },
  {
    "text": "All right. So when you see a new\nimage, it could be",
    "start": "1501170",
    "end": "1506340"
  },
  {
    "text": "Rosalie's face, or this fish.",
    "start": "1506340",
    "end": "1512779"
  },
  {
    "text": "And I want to compute\na feature vectors which is invariant to rotation,\neven if I've never",
    "start": "1512780",
    "end": "1519440"
  },
  {
    "text": "seen the fish rotated. What I do is, I\ncompute a dot product",
    "start": "1519440",
    "end": "1529309"
  },
  {
    "text": "of the image of the fish\nwith each one of the frames. So I get eight numbers.",
    "start": "1529310",
    "end": "1538070"
  },
  {
    "text": "And the claim is that\nthese eight numbers--",
    "start": "1538070",
    "end": "1543440"
  },
  {
    "text": "not their order,\nbut the numbers-- are invariant to\nrotation of the fish.",
    "start": "1543440",
    "end": "1550890"
  },
  {
    "text": "So if I see the fish now in\na different rotation angle-- suppose it's vertical, I'd still\nget the same eight numbers.",
    "start": "1550890",
    "end": "1559160"
  },
  {
    "text": "In a different order, probably. You could have-- these\nare eight numbers.",
    "start": "1559160",
    "end": "1565690"
  },
  {
    "text": "What I said, they are invariant\nto rotation of the fish.",
    "start": "1565690",
    "end": "1574070"
  },
  {
    "text": "There are various\nquantities that you can use to represent\ncompactly the fact that they are the same\nindependent of rotation.",
    "start": "1574070",
    "end": "1580340"
  },
  {
    "text": "For instance, the\nprobability distribution-- the histogram-- of these values\ndoes not depend on the order.",
    "start": "1580340",
    "end": "1589380"
  },
  {
    "text": "And so if you make\na histogram, these should be independent\nof rotation,",
    "start": "1589380",
    "end": "1595309"
  },
  {
    "text": "invariant to rotation, Or\nmoments of the histogram, like the average, the variance,\nthe moment of order infinity.",
    "start": "1595310",
    "end": "1605607"
  },
  {
    "start": "1605607",
    "end": "1611211"
  },
  {
    "text": "And for instance, the equation\nfor computing a histogram is written there.",
    "start": "1611211",
    "end": "1616300"
  },
  {
    "text": "You have the dot product\nof the image, the fish, with one template to\nthe bike, the bike Tk.",
    "start": "1616300",
    "end": "1625330"
  },
  {
    "text": "You have several\ntemplates, not just one. And Gi is the element\nof the rotation group.",
    "start": "1625330",
    "end": "1633360"
  },
  {
    "text": "So you get various\nrotations of-- simply because you\nhave observed that.",
    "start": "1633360",
    "end": "1638870"
  },
  {
    "text": "You don't need to know\nits rotation group. You don't need to compute that. These are just images\nthat you have stored.",
    "start": "1638870",
    "end": "1645010"
  },
  {
    "text": " And there can be different\nthresholds of simple cells.",
    "start": "1645010",
    "end": "1652670"
  },
  {
    "text": "And sigma could be just\na threshold function, for instance. As it turns out--",
    "start": "1652670",
    "end": "1658360"
  },
  {
    "text": "I'll describe later. And sum is the pool. I'll describe later these. But sigma, the nonlinearities\ncan be, in fact,",
    "start": "1658360",
    "end": "1665040"
  },
  {
    "text": "almost anything. This is very robust to different\nchoices of the nonlinearity",
    "start": "1665040",
    "end": "1673830"
  },
  {
    "text": "and the pooling. Here are some examples in\nwhich now the transformation",
    "start": "1673830",
    "end": "1682490"
  },
  {
    "start": "1675000",
    "end": "1746000"
  },
  {
    "text": "is translation that you\nhave observed for the bike. And if I compute a histogram--",
    "start": "1682490",
    "end": "1691950"
  },
  {
    "text": "from more than eight\nframes, in this case-- I get the red\nhistogram for the fish,",
    "start": "1691950",
    "end": "1701470"
  },
  {
    "text": "and you can see the red\nhistogram does not change, even if the image of\nthe fish is translated.",
    "start": "1701470",
    "end": "1708270"
  },
  {
    "text": "Same for the blue Instagram,\nwhich is the set to features corresponding to the cat.",
    "start": "1708270",
    "end": "1714750"
  },
  {
    "text": "Also it's invariant\nto translation. But it's different\nfrom the red one.",
    "start": "1714750",
    "end": "1723800"
  },
  {
    "text": "So these quantities,\nthe histograms, can be invariant of\ncourse, but also selective,",
    "start": "1723800",
    "end": "1730029"
  },
  {
    "text": "which is what you want. In order to have a selectivity\nas high as you want,",
    "start": "1730030",
    "end": "1738030"
  },
  {
    "text": "you need more than one template. And some results about\nhow many you need.",
    "start": "1738030",
    "end": "1751050"
  },
  {
    "start": "1746000",
    "end": "1786000"
  },
  {
    "text": "I can go into more\ndetails of this. But essentially, you need\na number of templates--",
    "start": "1751050",
    "end": "1758700"
  },
  {
    "text": "of templates like the bike,\nin your original example-- that is logarithmic in\nthe number of images",
    "start": "1758700",
    "end": "1766200"
  },
  {
    "text": "you want to separate. For instance, suppose you\nwant to be able to distinguish",
    "start": "1766200",
    "end": "1772000"
  },
  {
    "text": "1,000 faces, or 1,000 objects. Then the number of\ntemplates you need",
    "start": "1772000",
    "end": "1778740"
  },
  {
    "text": "is in the order of log 1,000.",
    "start": "1778740",
    "end": "1783780"
  },
  {
    "text": "So does not increase so much. Yeah. So there are two things,\none, which you implied.",
    "start": "1783780",
    "end": "1791710"
  },
  {
    "start": "1786000",
    "end": "1879000"
  },
  {
    "text": "The reason I spoke about\nrotation of the image plane, because rotation\nis a compact group.",
    "start": "1791710",
    "end": "1800440"
  },
  {
    "text": "So you never get out. You come back in.",
    "start": "1800440",
    "end": "1806690"
  },
  {
    "text": "The translation, you can-- in principle, mathematically,\nbetween plus infinity or minus",
    "start": "1806690",
    "end": "1813649"
  },
  {
    "text": "infinity. Of course it does\nnot make sense, but mathematically\nthis means that it's",
    "start": "1813650",
    "end": "1819340"
  },
  {
    "text": "a little bit more\ndifficult to prove the same results in the case\nof translation and scale. But we can do it.",
    "start": "1819340",
    "end": "1825130"
  },
  {
    "text": "That's the first point. The second one,\nthe combinatorics of different transformations.",
    "start": "1825130",
    "end": "1833920"
  },
  {
    "text": "Turns out that--\none approach to this",
    "start": "1833920",
    "end": "1840400"
  },
  {
    "text": "is to have what the visual\nsystem seems to have, in which you have relatively\nsmall ranges of invariance",
    "start": "1840400",
    "end": "1853779"
  },
  {
    "text": "at different stages. So that at first\nstage, say in V1,",
    "start": "1853780",
    "end": "1860799"
  },
  {
    "text": "you have pooling by\nthe complex cells over a small range of\ntranslations, and probably",
    "start": "1860800",
    "end": "1868660"
  },
  {
    "text": "scale. And then at the second stage\nyou have a larger range.",
    "start": "1868660",
    "end": "1875025"
  },
  {
    "text": "I'll come to that later. But it's a very\ninteresting point. I'll not go into this.",
    "start": "1875025",
    "end": "1881255"
  },
  {
    "start": "1879000",
    "end": "1907000"
  },
  {
    "text": "These are-- technical extension\nof these partial observer groups, these\nnon-compact groups.",
    "start": "1881255",
    "end": "1889120"
  },
  {
    "text": " The non-group transformation\nof this approximate",
    "start": "1889120",
    "end": "1895270"
  },
  {
    "text": "invariance to rotations in\n3D, or changes of expression,",
    "start": "1895270",
    "end": "1900650"
  },
  {
    "text": "and so on. And then what happens\nwhen you have-- a hierarchy of just modules.",
    "start": "1900650",
    "end": "1906190"
  },
  {
    "text": "I'll say briefly\nsomething about each one. One is that if you look\nat the templates that",
    "start": "1906190",
    "end": "1918760"
  },
  {
    "start": "1907000",
    "end": "1960000"
  },
  {
    "text": "give you simultaneous-- so what we want to do, we want\nto get scale and positioning",
    "start": "1918760",
    "end": "1926950"
  },
  {
    "text": "invariance. And suppose you\nwant templates that",
    "start": "1926950",
    "end": "1933820"
  },
  {
    "text": "maximize the simultaneous\nrange of invariance to scale and position.",
    "start": "1933820",
    "end": "1939760"
  },
  {
    "text": "It turns out that Gabor\ntemplates, Gabor filters, are the ones to do that.",
    "start": "1939760",
    "end": "1946560"
  },
  {
    "text": "So that may be one\ncomputational reason for why Gabor filters\nare a good thing",
    "start": "1946560",
    "end": "1955570"
  },
  {
    "text": "to do in processing images.",
    "start": "1955570",
    "end": "1960769"
  },
  {
    "start": "1960000",
    "end": "1984000"
  },
  {
    "text": "So for getting approximately\ngood invariance to non-group\ntransformations, you",
    "start": "1960770",
    "end": "1967930"
  },
  {
    "text": "need to have some conditions. The main one is\nthat the template",
    "start": "1967930",
    "end": "1973550"
  },
  {
    "text": "must transform in a similar\nway to the object you are to compute, like faces.",
    "start": "1973550",
    "end": "1980890"
  },
  {
    "start": "1980890",
    "end": "1986320"
  },
  {
    "start": "1984000",
    "end": "2072000"
  },
  {
    "text": "And for these properties\nto be true for a hierarchy",
    "start": "1986320",
    "end": "1993519"
  },
  {
    "text": "of modules.  Think of this inverted\ntriangle like a set",
    "start": "1993520",
    "end": "2000950"
  },
  {
    "text": "of simple cells at the\nbase, and one complex cell, the red circle at the top.",
    "start": "2000950",
    "end": "2007190"
  },
  {
    "text": "And so the architecture\nthat we're looking at is simple complex. This would be like V1.",
    "start": "2007190",
    "end": "2014299"
  },
  {
    "text": "And next to it, another\nsimple complex module. This is all V2.",
    "start": "2014300",
    "end": "2020420"
  },
  {
    "text": "And then you have V1 in\nthe second layer, that is getting the input from V1. And you repeat the same thing,\nbut on the output of V1.",
    "start": "2020420",
    "end": "2030050"
  },
  {
    "text": "This is exactly like a\ndeep learning network.",
    "start": "2030050",
    "end": "2035260"
  },
  {
    "text": "It's like visual cortex, where\nyou have different stages",
    "start": "2035260",
    "end": "2040610"
  },
  {
    "text": "and the effective receptive\nfields increases as you go up,",
    "start": "2040610",
    "end": "2046280"
  },
  {
    "text": "as you see here.  So this would be the\nincrease in spatial pooling--",
    "start": "2046280",
    "end": "2054829"
  },
  {
    "text": "so invariance-- and also,\nas I mentioned-- not",
    "start": "2054830",
    "end": "2060100"
  },
  {
    "text": "drawn here, but the scale. Pooling over size, scale.",
    "start": "2060100",
    "end": "2067360"
  },
  {
    "text": "And you can show that, if\nthe following is true, that--",
    "start": "2067360",
    "end": "2074270"
  },
  {
    "start": "2072000",
    "end": "2321000"
  },
  {
    "text": "let me see. Is this animated? No. ",
    "start": "2074270",
    "end": "2090379"
  },
  {
    "text": "What you need to have-- and a\nnumber of different networks, certainly the ones\nI described, have",
    "start": "2090380",
    "end": "2097070"
  },
  {
    "text": "this property of covariance. So suppose you have an object\nthat translates in the image.",
    "start": "2097070",
    "end": "2107690"
  },
  {
    "text": "OK.  What I need is that\nthe neural activity--",
    "start": "2107690",
    "end": "2121110"
  },
  {
    "text": "the red circles at\nthe first level-- also translate.",
    "start": "2121110",
    "end": "2127609"
  },
  {
    "text": "This is covariance.  So what happens\nis the following.",
    "start": "2127610",
    "end": "2132910"
  },
  {
    "text": "Suppose the object is smaller\nthan those receptive fields, and this drawing is as big.",
    "start": "2132910",
    "end": "2139130"
  },
  {
    "text": "But suppose it's smaller. Then if you translate one of\nthose receptive fields, going",
    "start": "2139130",
    "end": "2148140"
  },
  {
    "text": "from one point to another,\nbecause each one has invariance",
    "start": "2148140",
    "end": "2154650"
  },
  {
    "text": "to translations within\nthe receptive field-- it's pooling over them--",
    "start": "2154650",
    "end": "2160440"
  },
  {
    "text": "translation in the\nreceptive field will give the same output. You will have\ninvariance right there.",
    "start": "2160440",
    "end": "2169380"
  },
  {
    "text": "But suppose you have\none image, and then the next one the object moves\nto a different receptive field,",
    "start": "2169380",
    "end": "2176940"
  },
  {
    "text": "or gets out of the\nreceptive field. Then you don't have\ninvariance at the first layer.",
    "start": "2176940",
    "end": "2184080"
  },
  {
    "text": "But if you have covariance--\nor the neural activity moves--",
    "start": "2184080",
    "end": "2189510"
  },
  {
    "text": "at that layer above,\nyou may have invariance under that receptive field.",
    "start": "2189510",
    "end": "2196619"
  },
  {
    "text": "In other words, in\nthis construction, if you have this\ncovariance property, then",
    "start": "2196620",
    "end": "2203220"
  },
  {
    "text": "at some point in the network,\none of these receptive fields will be invariant.",
    "start": "2203220",
    "end": "2209110"
  },
  {
    "text": " Is that--",
    "start": "2209110",
    "end": "2215245"
  },
  {
    "text": "AUDIENCE: Can you\nexplain that again? TOMASO POGGIO: Yeah.",
    "start": "2215246",
    "end": "2220260"
  },
  {
    "text": "The argument is-- suppose\nI have an object like this.",
    "start": "2220260",
    "end": "2228760"
  },
  {
    "text": "I have an image. And then-- I have another image\nin which the object is here.",
    "start": "2228760",
    "end": "2237060"
  },
  {
    "text": " Obviously the response\nat this level--",
    "start": "2237060",
    "end": "2243019"
  },
  {
    "text": "the response of this cell\nwill change, because before it",
    "start": "2243020",
    "end": "2248410"
  },
  {
    "text": "saw this object. Now, there is these\nother cells who see that.",
    "start": "2248410",
    "end": "2253780"
  },
  {
    "text": "So the response has changed. You don't have invariance. However, if you look\nat what happens, say,",
    "start": "2253780",
    "end": "2262900"
  },
  {
    "text": "at the top red circle there,\nthe top red circle will",
    "start": "2262900",
    "end": "2268529"
  },
  {
    "text": "you see some activity\nin the first image here, because it was\nactivated for this.",
    "start": "2268530",
    "end": "2278410"
  },
  {
    "text": "And-- in the second case, we\nsee some activity over there,",
    "start": "2278410",
    "end": "2284440"
  },
  {
    "text": "which should be equivalent. And under these\nreceptive fields,",
    "start": "2284440",
    "end": "2291580"
  },
  {
    "text": "translations will give\nrise to the same signature. Under this big\nreceptive field, you",
    "start": "2291580",
    "end": "2298880"
  },
  {
    "text": "have invariance for\ntranslation within it. So the argument is that--",
    "start": "2298880",
    "end": "2305130"
  },
  {
    "text": "either you have\ninvariance at one layer, because the object\njust moved within it,",
    "start": "2305130",
    "end": "2311403"
  },
  {
    "text": "and then you are done. It's invariant, and\neverything else is invariant. Or you don't have\ninvariance in this layer,",
    "start": "2311404",
    "end": "2317860"
  },
  {
    "text": "but you will have it\nat some layer above. So in a sense--",
    "start": "2317860",
    "end": "2323230"
  },
  {
    "start": "2321000",
    "end": "2332000"
  },
  {
    "text": "if you go back to this-- I'll make this point later. But if you go back to this-- ",
    "start": "2323230",
    "end": "2332856"
  },
  {
    "start": "2332000",
    "end": "2448000"
  },
  {
    "text": "to this algorithm,\nthe basic idea is that you want to have\ninvariance to rotation.",
    "start": "2332856",
    "end": "2343460"
  },
  {
    "text": "And so you average\nover the rotations. But suppose you want\nto have invariance--",
    "start": "2343460",
    "end": "2352700"
  },
  {
    "text": "you want to have an\nestimate of rotation, but you're not\ninterested in identity.",
    "start": "2352700",
    "end": "2361160"
  },
  {
    "text": "Then what you do, you\ndon't pool over rotation. You pull over different\nobjects at one rotation.",
    "start": "2361160",
    "end": "2370900"
  },
  {
    "text": "So you can do both. All right? AUDIENCE: My question was more\nphysiological than theoretical.",
    "start": "2370900",
    "end": "2378810"
  },
  {
    "text": "TOMASO POGGIO: Yeah. Physiological-- we had done\nexperiments long ago in IT",
    "start": "2378810",
    "end": "2384790"
  },
  {
    "text": "with Jim DiCarlo,\nGabriel Kreiman. And from the same\npopulation of neurons,",
    "start": "2384790",
    "end": "2392950"
  },
  {
    "text": "we could read out\nidentity, object identity,",
    "start": "2392950",
    "end": "2398520"
  },
  {
    "text": "invariant to scale and position. And we could also read out\nposition invariant to identity.",
    "start": "2398520",
    "end": "2408451"
  },
  {
    "text": "And-- AUDIENCE: The same from the-- TOMASO POGGIO: Same population. I'm not saying the same neuron,\nbut the same population of 200",
    "start": "2408451",
    "end": "2415480"
  },
  {
    "text": "neurons. And so you can\nimagine that you could have different situations.",
    "start": "2415480",
    "end": "2421670"
  },
  {
    "text": "One could be some of the neurons\nare only conveying position, and some others are\ncompletely invariant.",
    "start": "2421670",
    "end": "2428559"
  },
  {
    "text": "And when you read out with\na classifier, it will work.",
    "start": "2428560",
    "end": "2433950"
  },
  {
    "text": "Or you have neurons\nthat are already combining this information,\nbecause the channels--",
    "start": "2433950",
    "end": "2440200"
  },
  {
    "text": "either way. OK, let me do this, and\nthen we can take a break.",
    "start": "2440200",
    "end": "2447280"
  },
  {
    "text": "I want to make the connection\nwith simple and complex cells. We already mentioned this,\nbut this set of operations,",
    "start": "2447280",
    "end": "2461380"
  },
  {
    "start": "2448000",
    "end": "2535000"
  },
  {
    "text": "you can think of this\nsigma dot product, n delta,",
    "start": "2461380",
    "end": "2469150"
  },
  {
    "text": "this is a simple cell.  So this is a dot product of\nthe image with a receptive",
    "start": "2469150",
    "end": "2477180"
  },
  {
    "text": "field of the simple cell. That's what this parenthesis is. ",
    "start": "2477180",
    "end": "2486360"
  },
  {
    "text": "You have a bias, or a\nthreshold, and the nonlinearity. Could be the spiking\nnonlinearity.",
    "start": "2486360",
    "end": "2492780"
  },
  {
    "text": "Could be, as I\nsaid, a rectifier. Neurons don't generate\nnegative spikes.",
    "start": "2492780",
    "end": "2503760"
  },
  {
    "text": "And so all of this is very\nplausible biologically. And the simple cell\nwill simply pool,",
    "start": "2503760",
    "end": "2511440"
  },
  {
    "text": "take the over the\ndifferent simple cells. ",
    "start": "2511440",
    "end": "2522670"
  },
  {
    "text": "So that's what I mentioned\nbefore, that nonlinearity can be almost anything. ",
    "start": "2522670",
    "end": "2532900"
  },
  {
    "text": "And I want to mention\nsomething that could be interesting for physiology.",
    "start": "2532900",
    "end": "2538119"
  },
  {
    "start": "2535000",
    "end": "2771000"
  },
  {
    "text": "From the point of view\nof this algorithm, this may be a solution to this\nproblem that has been around",
    "start": "2538120",
    "end": "2545970"
  },
  {
    "text": "for 30 years or so, which is\nthat Hubel and Wiesel and other",
    "start": "2545970",
    "end": "2553050"
  },
  {
    "text": "physiologists after\nthem identified simple and complex\ncells in terms",
    "start": "2553050",
    "end": "2559320"
  },
  {
    "text": "of their physiological\nproperties. They couldn't see from\nwhere they are recording.",
    "start": "2559320",
    "end": "2564840"
  },
  {
    "text": "But there were cells that\nbehaved in different ways. The simple cells had the\nsmall receptive field.",
    "start": "2564840",
    "end": "2572400"
  },
  {
    "text": "The complex cell had\nlarger receptive field. ",
    "start": "2572400",
    "end": "2578970"
  },
  {
    "text": "The complex cells\nwere more invariant. And then physiologists\ntoday are using",
    "start": "2578970",
    "end": "2585600"
  },
  {
    "text": "criteria in which\nthe complex cell is more non-linear than\nthe simple cell.",
    "start": "2585600",
    "end": "2591690"
  },
  {
    "text": "Now, from the point\nof view of the theory, the real difference is\none is doing the pooling--",
    "start": "2591690",
    "end": "2597829"
  },
  {
    "text": "the complex cells. The simple cell is not. ",
    "start": "2597830",
    "end": "2603840"
  },
  {
    "text": "And the puzzle is that despite\nthese physiological difference,",
    "start": "2603840",
    "end": "2610520"
  },
  {
    "text": "they were never able to say\nthis type of pyramidal cell",
    "start": "2610520",
    "end": "2616070"
  },
  {
    "text": "is simple, and this type of\npyramid cell are complex. And part of the reason could be\nthat maybe simple and complex",
    "start": "2616070",
    "end": "2626440"
  },
  {
    "text": "cells are the same cell. So that the operation can\nbe done on the same cell.",
    "start": "2626440",
    "end": "2634940"
  },
  {
    "text": "If you look at the\ntheory, what may happen is that you have one dendrite\nplay the roll of a simple cell.",
    "start": "2634940",
    "end": "2646390"
  },
  {
    "text": "You have inputs,\nsynaptic weights. So this could give\nrise, for instance,",
    "start": "2646390",
    "end": "2653360"
  },
  {
    "text": "to the Gabor-like\nreceptive field. And then-- these other dendrites\nto another simple cell.",
    "start": "2653360",
    "end": "2665490"
  },
  {
    "text": "It's a Gabor-like in a slightly\ndifferent position in the image plane, in the retina.",
    "start": "2665490",
    "end": "2673220"
  },
  {
    "text": "You need the nonlinearities. And they may be, instead\nof the output of the cell,",
    "start": "2673220",
    "end": "2680240"
  },
  {
    "text": "they may be so-called\nvoltage and time dependent",
    "start": "2680240",
    "end": "2686990"
  },
  {
    "text": "conductancies in the dendrites. In the meantime, we know\nthat pyramidal cells",
    "start": "2686990",
    "end": "2692440"
  },
  {
    "text": "in the visual cortex\nhave these nonlinearities like almost having spike\ngeneration in the dendrites.",
    "start": "2692440",
    "end": "2703730"
  },
  {
    "text": "And then the soma will\nsummate everything. This is what the\ncomplex cell is doing.",
    "start": "2703730",
    "end": "2711470"
  },
  {
    "text": "And if one of the cells\nis computing something",
    "start": "2711470",
    "end": "2716599"
  },
  {
    "text": "like an average, which is one of\nthe moments of a distribution,",
    "start": "2716600",
    "end": "2724230"
  },
  {
    "text": "then the nonlinearity\nwill not even be needed. And then physiologists, using\nthe criteria they use this day,",
    "start": "2724230",
    "end": "2732109"
  },
  {
    "text": "would classify that\ncell as simple,",
    "start": "2732110",
    "end": "2737360"
  },
  {
    "text": "even if from that point\nof view of the theory it's still complex. ",
    "start": "2737360",
    "end": "2742640"
  },
  {
    "text": "Anyway, that's the\nproposed machinery that comes from the theory.",
    "start": "2742640",
    "end": "2749640"
  },
  {
    "text": "That's everything that we need. And it will say simple and\ncomplex cell could be one cell.",
    "start": "2749640",
    "end": "2758180"
  },
  {
    "start": "2758180",
    "end": "2771904"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6060"
  },
  {
    "text": "continue to offer high-quality\neducational resources for free. To make a donation, or to\nview additional materials",
    "start": "6060",
    "end": "12690"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. ",
    "start": "12690",
    "end": "25744"
  },
  {
    "text": "PROFESSOR: All\nright, welcome back. Today, we start a\nseries of lectures on approximation algorithms.",
    "start": "25744",
    "end": "31820"
  },
  {
    "text": "So something rather\ndifferent, although we're still going to\nbe doing reductions. They're just going to be\nstronger sense of reductions.",
    "start": "31820",
    "end": "39820"
  },
  {
    "text": "So let me start\nwith reminding you-- I assume you've\nseen approximation algorithms at some\nlevel before, but I",
    "start": "39820",
    "end": "45910"
  },
  {
    "text": "want to define a few\nthings which we'll need for the lower bound side.",
    "start": "45910",
    "end": "51510"
  },
  {
    "start": "51510",
    "end": "56579"
  },
  {
    "text": "So pretty much throughout, we've\nbeen-- in the context of NP, we've been thinking\nabout decision problems,",
    "start": "56580",
    "end": "61890"
  },
  {
    "text": "because that's\nwhere NP make sense. Now, we need to change the\nsetup to where the output is",
    "start": "61890",
    "end": "68240"
  },
  {
    "text": "not just yes or no,\nbut it's some kind of solution with a cost. So in general, the goal\nin an optimization problem",
    "start": "68240",
    "end": "75619"
  },
  {
    "text": "is going to be to go\nfrom some instance to a solution with\nmin or max cost.",
    "start": "75620",
    "end": "91420"
  },
  {
    "text": "So there's\nminimization problems, maximization problems. And so you are given--\nin order to specify this,",
    "start": "91420",
    "end": "97909"
  },
  {
    "text": "you're given a set of\npossible instances.",
    "start": "97910",
    "end": "103240"
  },
  {
    "text": "That's your usual\nnotion of input. And then for each instance, we\nare given a set of solutions.",
    "start": "103240",
    "end": "116540"
  },
  {
    "text": "Usually, these are\ncalled feasible solutions or valid solutions. I'll just call them solutions.",
    "start": "116540",
    "end": "122775"
  },
  {
    "text": "Those are the allowable\noutputs to that problem.",
    "start": "122775",
    "end": "128810"
  },
  {
    "text": "And then for each\nof those solutions, we're going to define some cost. I will assume that\nthey are non-negative,",
    "start": "128810",
    "end": "138290"
  },
  {
    "text": "so I don't have to\nworry about signs. And then you're\nalso given what's",
    "start": "138290",
    "end": "144940"
  },
  {
    "text": "usually called the objective,\nwhich is either min or max. ",
    "start": "144940",
    "end": "151961"
  },
  {
    "text": "OK, so you're going to be\ngiven an item from this set. You want to produce an item\nfrom this set that minimizes or maximizes this cost.",
    "start": "151961",
    "end": "159095"
  },
  {
    "text": "That's not going to be possible,\nbecause all these problems are going to be NP complete. But the point of\napproximation is",
    "start": "159095",
    "end": "164940"
  },
  {
    "text": "to relax getting\nthe best solution, and aim to get an approximately\nbest solution, which",
    "start": "164940",
    "end": "171160"
  },
  {
    "text": "we will define in a moment. But let me start with some\nuseful notation, which",
    "start": "171160",
    "end": "179890"
  },
  {
    "text": "is opt of x, x is an instance,\nthis is going to be two things.",
    "start": "179890",
    "end": "190810"
  },
  {
    "text": "No definition should\nbe unambiguous. So it's going to be the cost\nof a min or a max solution.",
    "start": "190810",
    "end": "202782"
  },
  {
    "start": "202782",
    "end": "208730"
  },
  {
    "text": "Cost solution. And it's also going to be such\na solution itself, sometimes. ",
    "start": "208730",
    "end": "216870"
  },
  {
    "text": "Cool. So this is sort of\nthe usual setup. Now let's make it a little bit\nmore interesting by defining",
    "start": "216870",
    "end": "225190"
  },
  {
    "text": "an NP optimization problem. ",
    "start": "225190",
    "end": "233090"
  },
  {
    "text": "This is going to be the\nanalog of NP for optimization.",
    "start": "233090",
    "end": "238480"
  },
  {
    "text": "So one thing is\nthat all solutions",
    "start": "238480",
    "end": "243629"
  },
  {
    "text": "have polynomial length,\npolynomial in the length",
    "start": "243630",
    "end": "249720"
  },
  {
    "text": "of the input, the instance.  Another thing is that\ninstances and solutions",
    "start": "249720",
    "end": "260919"
  },
  {
    "text": "can be recognized. ",
    "start": "260920",
    "end": "270902"
  },
  {
    "text": "So there's a polynomial\ntime algorithm that tells you yes,\nthat's a solution, yes, that's an instance, or no.",
    "start": "270902",
    "end": "278340"
  },
  {
    "text": "And let's see, the\ncost function should be polynomially-computable.",
    "start": "278340",
    "end": "285360"
  },
  {
    "text": "And that's it. OK, so just making\nthese actually",
    "start": "285360",
    "end": "291160"
  },
  {
    "text": "reasonable from an\nalgorithmic standpoint. And so now, you know,\nthinking like NP,",
    "start": "291160",
    "end": "297699"
  },
  {
    "text": "the solution is going to be\nsomething like the certificate that you had a yes answer.",
    "start": "297700",
    "end": "304580"
  },
  {
    "text": "Here, it's going to be a\ncertificate that the cost is a particular thing. So given an empty\noptimization problem,",
    "start": "304580",
    "end": "310919"
  },
  {
    "text": "you can define a\ndecision problem, or decision version of NPO.",
    "start": "310920",
    "end": "320320"
  },
  {
    "text": "So NPO is going to be the\nclass of all such problems, NP",
    "start": "320320",
    "end": "327450"
  },
  {
    "text": "optimization problems. Just like NP was\nall the problems",
    "start": "327450",
    "end": "333580"
  },
  {
    "text": "solvable in nondeterministic\npolynomial time. These things I claim, if\nwe convert to the decision",
    "start": "333580",
    "end": "341890"
  },
  {
    "text": "version, which is for a min\nproblem, the question is",
    "start": "341890",
    "end": "347471"
  },
  {
    "text": "is opt of x, the cost, less than\nor equal to some query value.",
    "start": "347471",
    "end": "353760"
  },
  {
    "text": "And for a max\nversion, it is is opt of x greater than or\nequal to the query value.",
    "start": "353760",
    "end": "363740"
  },
  {
    "text": "This thing is an NP.  So let's see why.",
    "start": "363740",
    "end": "372050"
  },
  {
    "text": "If you have these properties,\nthen the resulting decision problem will be an NP because\nif I give you a solution,",
    "start": "372050",
    "end": "378490"
  },
  {
    "text": "and solutions have\npolynomial length, you can compute its cost, verify\nthat it was a valid solution,",
    "start": "378490",
    "end": "384290"
  },
  {
    "text": "and then you know that\nopt-- opt is some min, so it's going to be\nless than or equal to any particular solution.",
    "start": "384290",
    "end": "390700"
  },
  {
    "text": "So if I give you a solution,\nthen I verify that opt of x is less than or equal\nto q in polynomial time.",
    "start": "390700",
    "end": "396830"
  },
  {
    "text": "For max, it's the reverse. And for example, if\nyou wanted to check--",
    "start": "396830",
    "end": "401962"
  },
  {
    "text": "if you wanted to know\nwhether the min was greater than or\nequal to something, well that's a co NP problem.",
    "start": "401962",
    "end": "407600"
  },
  {
    "text": "So that's-- these are the\ncorrect decision versions of those NP optimization\nproblems in the sense that you",
    "start": "407600",
    "end": "413980"
  },
  {
    "text": "get a problem in NP. So this is a strict\ngeneralization, in some sense,",
    "start": "413980",
    "end": "419770"
  },
  {
    "text": "of NP problems, or\nspecialization I suppose. This is a particular-- well,\nwe have optimization versions",
    "start": "419770",
    "end": "428670"
  },
  {
    "text": "which still give us NP problems. We can still talk about NP\ncompleteness of these problems. But we're interested--\nwe're setting all this up",
    "start": "428670",
    "end": "436310"
  },
  {
    "text": "so we can actually talk about\ncosts of not just the best solution, but costs of\nsuboptimal solutions.",
    "start": "436310",
    "end": "444800"
  },
  {
    "text": "So let's get to approximation. ",
    "start": "444800",
    "end": "461500"
  },
  {
    "text": "So we're going to call\nan algorithm, ALG, a c approximation.",
    "start": "461500",
    "end": "467950"
  },
  {
    "text": "I write c, but it's not\nnecessarily a constant. It could be a function of\nN. If-- in the min case,",
    "start": "467950",
    "end": "481010"
  },
  {
    "text": "what we want is the cost\nof the algorithm applied to an input, x, divided by\nthe cost of the optimal of x.",
    "start": "481010",
    "end": "492690"
  },
  {
    "text": "Here, for whatever\nreason, I write cost of opt instead of just opt. That should be less\nthan or equal to c.",
    "start": "492690",
    "end": "498690"
  },
  {
    "text": " We look at the ratio,\nwe want that to be",
    "start": "498690",
    "end": "505219"
  },
  {
    "text": "bounded by some value. In the max case, there\nare two definitions",
    "start": "505220",
    "end": "510630"
  },
  {
    "text": "that are standard in\nthe literature that correspond to different ways\nof looking at the same thing.",
    "start": "510630",
    "end": "518950"
  },
  {
    "text": "One would be cost of OPT\ndivided by cost of ALG.",
    "start": "518950",
    "end": "530200"
  },
  {
    "text": "That should be, at most, c. This would correspond to c being\ngreater than or equal to 1.",
    "start": "530200",
    "end": "537470"
  },
  {
    "text": "And the alternative is to\nflip the inequality instead of the ratio.",
    "start": "537470",
    "end": "542570"
  },
  {
    "start": "542570",
    "end": "553150"
  },
  {
    "text": "First, let's think about min. With a minimization problem,\nwhatever the algorithm produces will be greater than\nor equal to OPT.",
    "start": "553150",
    "end": "558331"
  },
  {
    "text": "So this is a ratio that will\ngive something greater than or equal to 1. And so usually we think\nabout two approximation,",
    "start": "558331",
    "end": "566550"
  },
  {
    "text": "1.5 approximation,\n100 approximation, whatever, just saying\nthe algorithm is within a factor of\n100 of the optimal.",
    "start": "566550",
    "end": "573460"
  },
  {
    "text": "For maximization, the thing\nthat the algorithm produces will be less than\nor equal to OPT. And so if you want something\nthat is greater than 1,",
    "start": "573460",
    "end": "581010"
  },
  {
    "text": "you have to flip the ratio. In this situation, c would\nbe less than or equal to 1.",
    "start": "581010",
    "end": "587670"
  },
  {
    "text": "So some people call-- if\nyou have an algorithm that",
    "start": "587670",
    "end": "593589"
  },
  {
    "text": "produces a solution that is\nat least 1/2 times optimal, you might call it\na two approximation or you might call it\na 1/2 approximation,",
    "start": "593590",
    "end": "600150"
  },
  {
    "text": "depending on the paper. I think this is, by\nnow, more common, but it really depends on the\nera and the person and so on.",
    "start": "600150",
    "end": "607310"
  },
  {
    "text": "So good to be aware of both. It's measuring the\nsame thing, of course, just c is either bigger\nthan 1 or less than 1.",
    "start": "607310",
    "end": "612500"
  },
  {
    "text": "Yeah? AUDIENCE: Is that\nover all instances? PROFESSOR: Oh yeah, this\nshould be for all x. ",
    "start": "612500",
    "end": "622339"
  },
  {
    "text": "For all valid instances x. Good.",
    "start": "622340",
    "end": "628079"
  },
  {
    "text": "So usually when we say a\nc approximation algorithm,",
    "start": "628080",
    "end": "641150"
  },
  {
    "text": "usually we're interested in\npolynomial time c approximation algorithm. Almost all the time\nthat is the case.",
    "start": "641150",
    "end": "646344"
  },
  {
    "text": "I will probably forget\nto say polynomial time, but I always mean it\nunless I say otherwise,",
    "start": "646344",
    "end": "651560"
  },
  {
    "text": "which will probably be never. But there are a few papers\nthat look at exponential time approximation algorithms\nthat have better",
    "start": "651560",
    "end": "656618"
  },
  {
    "text": "exponent than the exact\ncounterparts, and so on. So this is interesting\nbecause while",
    "start": "656618",
    "end": "664250"
  },
  {
    "text": "your-- the straight-up decision\nproblem, which is basically deciding OPT exactly,\nthat might be NP complete.",
    "start": "664250",
    "end": "672800"
  },
  {
    "text": "The approximation version,\nlike finding a two approximate solution,\nmight be polynomial. And that would be observed\nby finding a polynomial",
    "start": "672800",
    "end": "680759"
  },
  {
    "text": "to approximation algorithm.  Sometimes you can do even\nbetter than con-- well.",
    "start": "680760",
    "end": "692390"
  },
  {
    "text": "So here, we've been thinking\nabout constant factors for c. Sometimes you can do even\nbetter than any constant factor,",
    "start": "692390",
    "end": "698257"
  },
  {
    "text": "or you can achieve any\nconstant factor would be another way of saying it. This is called a polynomial time\napproximation scheme, usually",
    "start": "698257",
    "end": "706821"
  },
  {
    "text": "PTAS. ",
    "start": "706821",
    "end": "718300"
  },
  {
    "text": "You can think of this as a\n1 plus epsilon approximation for any epsilon. But the general-- or\nyou can think of it",
    "start": "718300",
    "end": "724880"
  },
  {
    "text": "as an algorithm that,\ngiven epsilon, produces a 1 plus epsilon\napproximation algorithm. Or you can think of\nit as an algorithm",
    "start": "724880",
    "end": "731490"
  },
  {
    "text": "with an additional input, not\njust the instance, but also a value epsilon.",
    "start": "731490",
    "end": "739200"
  },
  {
    "text": "It's a rational epsilon\ngreater than zero. And then the-- let's say\nproduces a solution that's",
    "start": "739200",
    "end": "758110"
  },
  {
    "text": "a 1 plus epsilon approximation.",
    "start": "758110",
    "end": "763360"
  },
  {
    "text": " So this would be a sort\nof ideal situation.",
    "start": "763360",
    "end": "769190"
  },
  {
    "text": "You get to specify what\nthe error bound is, and the algorithm will\nfind a suitable solution.",
    "start": "769190",
    "end": "776430"
  },
  {
    "text": "And the polynomial time\npart is that this algorithm must be polynomial time for\nany fixed epsilon, which",
    "start": "776430",
    "end": "791310"
  },
  {
    "text": "means that the dependence on\nepsilon could be horrible. You could have an\nalgorithm, if N is your input size, that runs\nin something like N to the 2",
    "start": "791310",
    "end": "799336"
  },
  {
    "text": "to the 2 to the 1 over\nepsilon or whatever. That's polynomial time for\nany fixed value of epsilon.",
    "start": "799336",
    "end": "806370"
  },
  {
    "text": "It's rather large for any\nreasonable value of epsilon, like a half, but anyway.",
    "start": "806370",
    "end": "812170"
  },
  {
    "text": "Or even 1 is still\ngetting up there. But that's considered a P test. Now there are stronger\nnotions of P tests",
    "start": "812170",
    "end": "818880"
  },
  {
    "text": "that prevent this kind of thing. We will get to that when\nwe get to fixed parameter tractability. But for now, this would be\nconsidered the gold standard.",
    "start": "818880",
    "end": "827690"
  },
  {
    "text": "This is the best you could hope\nfor at this level of detail. And for-- let me give\nyou some more classes.",
    "start": "827690",
    "end": "837830"
  },
  {
    "text": "So we defined NPO. There's the class PTAS. Again, reuse of term, but this\nis all problems-- NPO problems",
    "start": "837830",
    "end": "850810"
  },
  {
    "text": "with a PTAS algorithm. And more generally, if we\nhave some class of functions,",
    "start": "850810",
    "end": "867140"
  },
  {
    "text": "then I'm going to write\nFAPX to be all the NPO problems with poly-time f\napproximation algorithms.",
    "start": "867140",
    "end": "885649"
  },
  {
    "text": "I'll write f of N\nto be clear what we're depending on for some\nlittle f in the class big F.",
    "start": "885650",
    "end": "904970"
  },
  {
    "text": "So for example, f\nof N could be 3. That would be a constant\nfactor approximation.",
    "start": "904970",
    "end": "911670"
  },
  {
    "text": "In that case, we\njust call it APX. APX is what you might otherwise\ncall order one APX, things",
    "start": "911670",
    "end": "918209"
  },
  {
    "text": "that you can approximate\nin some constant factor, any constant factor. Another class that's\ncommonly studied is log APX.",
    "start": "918209",
    "end": "926200"
  },
  {
    "text": "This is log N approximable\nsome constant factor.",
    "start": "926200",
    "end": "933789"
  },
  {
    "text": "And there are more. There's poly APX,\nwhere you just want N to some constant, usually\nless than one but not always.",
    "start": "933789",
    "end": "941240"
  },
  {
    "text": "But I think this will\nbe enough for us. And so we're interested in\ndistinguishing these classes.",
    "start": "941240",
    "end": "947280"
  },
  {
    "text": "We're going to do that by\ndefining reductions, using reductions, defining hardness,\nand then getting the hardest",
    "start": "947280",
    "end": "952690"
  },
  {
    "text": "problems in certains\nof these classes to show that's the best kind\nof approximability you can get.",
    "start": "952690",
    "end": "958880"
  },
  {
    "text": "Today, we'll be thinking in\nparticular about the boundary between PTAS and APX.",
    "start": "958880",
    "end": "964580"
  },
  {
    "text": "So PTAS, we can get 1 plus\nepsilon for any epsilon. APX, you can get\na constant factor, but there's some\nlimit to how small",
    "start": "964580",
    "end": "970170"
  },
  {
    "text": "that constant factor could be,\nat least in the hardest case. APX includes PTAS, but there's\nproblems in APX minus PTAS.",
    "start": "970170",
    "end": "978030"
  },
  {
    "text": "Those have a limit how\nfar down you can get. OK. We have PTAS is a subset of APX.",
    "start": "978030",
    "end": "989240"
  },
  {
    "text": "And furthermore, if P is not\nequal NP, it's a strict subset.",
    "start": "989240",
    "end": "994640"
  },
  {
    "text": "And let's say log\nAPX or whatever.",
    "start": "994640",
    "end": "1000140"
  },
  {
    "text": "You pick your favorite\napproximation factor, and there are problems\nwhere you can achieve",
    "start": "1000140",
    "end": "1006700"
  },
  {
    "text": "that and nothing better. It's actually an easy exercise\nto come up with such a thing.",
    "start": "1006700",
    "end": "1013310"
  },
  {
    "text": "This is if P does not equal NP.",
    "start": "1013310",
    "end": "1018980"
  },
  {
    "text": "So you can take, I don't know,\nHamiltonian cycle or something, or pick your favorite\nNP hard problem.",
    "start": "1018980",
    "end": "1025500"
  },
  {
    "text": "And if the answer is\nyes to that problem, then you construct a\nsolution with some cost.",
    "start": "1025500",
    "end": "1031785"
  },
  {
    "text": "And if the answer is no,\nit's way, way smaller. And so any approximation\nwithin your desired factor",
    "start": "1031785",
    "end": "1037689"
  },
  {
    "text": "will be hard to find. Let me get a little bit more\nspecific, and let's talk",
    "start": "1037690",
    "end": "1044540"
  },
  {
    "text": "about some real problems. So in the world of graph\nalgorithm approximability,",
    "start": "1044540",
    "end": "1050720"
  },
  {
    "text": "these are the typical kinds of\napproximation factors you see. Of course, it depends\nexactly what subdomain. This is not a complete list, but\nit starts to give you a flavor.",
    "start": "1050720",
    "end": "1058890"
  },
  {
    "text": "And today, we'll be thinking\nmostly at the top level. But let me define some of\nthese problems for you.",
    "start": "1058890",
    "end": "1067290"
  },
  {
    "text": "A lot of them we have seen,\nor a few of them we have seen, such as Steiner tree.",
    "start": "1067290",
    "end": "1073140"
  },
  {
    "text": "We talked about\nrectilinear Steiner tree. That was a Euclidean problem. You were given\npoints in the plane,",
    "start": "1073140",
    "end": "1078419"
  },
  {
    "text": "and you wanted to\nconnect them up by the shortest\nconnected network.",
    "start": "1078420",
    "end": "1083789"
  },
  {
    "text": "In a graph-- so that problem\nhas a PTAS rectilinear Steiner",
    "start": "1083790",
    "end": "1088916"
  },
  {
    "text": "tree, because it's\na Euclidean problem. A lot of Euclidean\nproblems have PTAS's. And I'm denoting PTAS\nhere by 1 plus epsilon.",
    "start": "1088916",
    "end": "1095780"
  },
  {
    "text": "In general, epsilon here\nmeans for all epsilon greater than zero. Steiner tree in a graph\nis I give you a graph",
    "start": "1095780",
    "end": "1103470"
  },
  {
    "text": "and you have a bunch of special\nvertices, k special vertices. You want to find a\nconnected subgraph",
    "start": "1103470",
    "end": "1108720"
  },
  {
    "text": "of that graph that hits all\nof the special vertices. That problem has a constant\nfactor approximation,",
    "start": "1108720",
    "end": "1116090"
  },
  {
    "text": "and there's no PTAS\nfor a general graph. Steiner forest is\nalmost the same.",
    "start": "1116090",
    "end": "1121380"
  },
  {
    "text": "Instead of giving\nvertices that all have to connect to each other,\nyou say which pairs of vertices need to connect to each other.",
    "start": "1121380",
    "end": "1127220"
  },
  {
    "text": "This guy and this guy,\nand this guy and this guy. You can still-- this\nis a generalization. In the case where you want to\nconnect them in a [? Kleek ?]",
    "start": "1127220",
    "end": "1133776"
  },
  {
    "text": "pattern, that's Steiner tree. But Steiner forest has\nthe same approximability",
    "start": "1133776",
    "end": "1139770"
  },
  {
    "text": "up to constant factors. Traveling salesman\nin a graph, you've probably seen a 1.5\napproximation to that.",
    "start": "1139770",
    "end": "1145490"
  },
  {
    "text": "Definitely two approximation\nis really easy, like MST. And that's-- for in a graph,\nthat's the best you can do",
    "start": "1145490",
    "end": "1150790"
  },
  {
    "text": "in 2D. Or in a planar graph or\nin an H-minor free graph, there's a PTAS.",
    "start": "1150790",
    "end": "1157490"
  },
  {
    "text": "I think H-minor free, traveling\nsalesman problem weighted was",
    "start": "1157490",
    "end": "1162530"
  },
  {
    "text": "solved just a couple years ago. But that has a PTAS.",
    "start": "1162530",
    "end": "1167750"
  },
  {
    "text": "Let's see. Usually most people\nlike to think about minimization\nproblems, but there are maximization problems, too.",
    "start": "1167750",
    "end": "1174882"
  },
  {
    "text": "Let's see, what else\nhaven't I defined. Did we talk about set cover?",
    "start": "1174882",
    "end": "1180910"
  },
  {
    "text": "You have-- I think\nwe did briefly. You have sets and\nyou have elements.",
    "start": "1180910",
    "end": "1185994"
  },
  {
    "text": "You want to choose the fewest\nsets that hits all elements. Each set contains\nsome of the elements. You can think of it as a\nbipartite graph, sets on one",
    "start": "1185994",
    "end": "1193234"
  },
  {
    "text": "side, elements on the other. You want to choose\nthe fewest vertices on the left that hit all\nthe vertices on the right.",
    "start": "1193234",
    "end": "1201210"
  },
  {
    "text": "Dominating set is the\nnon-bipartite version of that problem. You're just given a graph.",
    "start": "1201210",
    "end": "1207980"
  },
  {
    "text": "And if you choose a vertex,\nit covers that vertex and its neighboring vertices. And your goal is to\ncover all vertices",
    "start": "1207980",
    "end": "1214190"
  },
  {
    "text": "using the smallest\ndominating set, by choosing the fewest vertices. So these problems turn\nout to be equivalent from",
    "start": "1214190",
    "end": "1220600"
  },
  {
    "text": "an approximability standpoint. And in a stronger sense,\nthey're both log N approximable, and that's the best you can do.",
    "start": "1220600",
    "end": "1227410"
  },
  {
    "text": "This is assuming p\ndoes not equal NP. Some of these results assume\nslightly stronger things",
    "start": "1227410",
    "end": "1234000"
  },
  {
    "text": "than p versus NP, but we won't\nworry about that too much.",
    "start": "1234000",
    "end": "1239410"
  },
  {
    "text": "Let's see. Another fun problem-- I'm\njust highlighting the ones you should know about.",
    "start": "1239410",
    "end": "1245260"
  },
  {
    "text": "Chromatic number,\nwe've seen what we thought about three coloring. But the chromatic\nnumber problem is",
    "start": "1245260",
    "end": "1250308"
  },
  {
    "text": "to minimize the\nnumber of colors, k, such that your graph\nis k-colorable. And that's really\nhard to approximate.",
    "start": "1250308",
    "end": "1257231"
  },
  {
    "text": "The best approximation\nalgorithm, I think, is N divided by log N,\nor something roughly N.",
    "start": "1257231",
    "end": "1263200"
  },
  {
    "text": "That's not so good. And there's a lower\nbound that you can't do better than N to the 1\nminus epsilon for all epsilon.",
    "start": "1263200",
    "end": "1268840"
  },
  {
    "text": "So you really--\nthat's pretty tight. Not completely tight,\nbut pretty close.",
    "start": "1268840",
    "end": "1275700"
  },
  {
    "text": "And let's see. Other good problems.",
    "start": "1275700",
    "end": "1281410"
  },
  {
    "text": "So maybe out here, another\nreally hard problem to approximate--\nthese are problems you should try to\navoid if you're trying",
    "start": "1281410",
    "end": "1287566"
  },
  {
    "text": "to solve things approximately. Or if you're driving\nhardness, you'd want to use these if you can,\nif your problem looks like this.",
    "start": "1287566",
    "end": "1293840"
  },
  {
    "text": "Independence set,\njust find me a set of vertices that\ninduce no edges. So no edges connecting them.",
    "start": "1293840",
    "end": "1299310"
  },
  {
    "text": "That's really hard. If you complement the\ngraph everywhere there's an edge deleted and\neverywhere there",
    "start": "1299310",
    "end": "1304960"
  },
  {
    "text": "wasn't an edge added, that's\nthe same problem as Kleek. So these are the same also from\nan approximation standpoint.",
    "start": "1304960",
    "end": "1313400"
  },
  {
    "text": "OK. This is annoying\nbecause [? Kleeks ?] are useful in practice, but. There's another problem\ncalled [? densest ?] subgraph,",
    "start": "1313400",
    "end": "1319910"
  },
  {
    "text": "which is approximate\n[? Kleeks. ?] That's actually easier to approximate. Yeah. AUDIENCE: What's the\nhardness of something for the chromatic\nnumber lower bound?",
    "start": "1319910",
    "end": "1325900"
  },
  {
    "text": "PROFESSOR: I think that's\nlike P does not equal ZPP, or NP does not\nequal ZPP, I think.",
    "start": "1325900",
    "end": "1332920"
  },
  {
    "text": "Yeah. For that-- that's\nstrong lower bounds. There are weaker lower bounds\nassuming P does not equal NP. ",
    "start": "1332920",
    "end": "1341820"
  },
  {
    "text": "OK. One other good one, fun one,\nto think about is set cover.",
    "start": "1341820",
    "end": "1348279"
  },
  {
    "text": "You want to choose the fewest\nsets to hit all elements. Maximum coverage, you don't\nhave to hit all the elements",
    "start": "1348280",
    "end": "1355215"
  },
  {
    "text": "but you want to hit as\nmany elements as possible using k sets. So in the decision\nproblem, these",
    "start": "1355215",
    "end": "1361120"
  },
  {
    "text": "are the same in some sense. Here, I give you k sets. I want to know can I\nhit all the elements.",
    "start": "1361120",
    "end": "1368410"
  },
  {
    "text": "For example, here\nI'm giving k sets and I want to know can I hit\nat least J of the elements.",
    "start": "1368410",
    "end": "1375350"
  },
  {
    "text": "So this you could think is a\ngeneralization from a decision standpoint, but\nit's actually easier to approximate because the\nobjective is different.",
    "start": "1375350",
    "end": "1382410"
  },
  {
    "text": "Here we have to hit every\nelement, no questions asked. Here, it's OK if we miss\nsome of the elements",
    "start": "1382410",
    "end": "1387900"
  },
  {
    "text": "because we only need a\nconstant factor approximation. And we can get a\nconstant factor here, whereas the best we\ncan do is log N here.",
    "start": "1387900",
    "end": "1395488"
  },
  {
    "text": " Cool. But unique coverage,\nthis is a result of ours.",
    "start": "1395488",
    "end": "1403450"
  },
  {
    "text": "If you're trying to\nmaximize coverage but if you double\ncover an element, you no longer get points for it.",
    "start": "1403450",
    "end": "1408610"
  },
  {
    "text": "That requires log\nN approximation. So I think I will\nleave it at that.",
    "start": "1408610",
    "end": "1415120"
  },
  {
    "text": "Directed graphs are much\nharder, although it's not known exactly how hard. Here's an example of a big gap\nin what we between log squared",
    "start": "1415120",
    "end": "1422500"
  },
  {
    "text": "and N to the epsilon. Something we will get\nto in a later class is called label cover.",
    "start": "1422500",
    "end": "1428370"
  },
  {
    "text": "I won't define the\nproblem here, because it takes a while to define. But there, there's very\nstrong lower bounds",
    "start": "1428370",
    "end": "1433620"
  },
  {
    "text": "on-- in approximability. It's similar to N to the 1\nminus epsilon, but it's not.",
    "start": "1433620",
    "end": "1439770"
  },
  {
    "text": "It's a little smaller. So you see 2 to the log N would\nbe N. That would be great.",
    "start": "1439770",
    "end": "1445520"
  },
  {
    "text": "And so you'd really\nlike 2 to the log N to the 1 minus epsilon. But what we have here is\nsomething a little smaller",
    "start": "1445520",
    "end": "1451789"
  },
  {
    "text": "than log N, log N to the\n1 minus epsilon power. And then you exponentiate that.",
    "start": "1451790",
    "end": "1458019"
  },
  {
    "text": "So this is somewhat smaller\nthan what we'd actually like,",
    "start": "1458020",
    "end": "1463740"
  },
  {
    "text": "which is something like N to the\n1 minus-- or N to some epsilon, I guess, would be ideal.",
    "start": "1463740",
    "end": "1469230"
  },
  {
    "text": "This is smaller than\nany N to the epsilon. The best upper bounds, it\ndepends on the problem. With N to some constant,\nlike for label cover,",
    "start": "1469230",
    "end": "1476330"
  },
  {
    "text": "it's N to the 1/3. For directed Steiner\nforest, which is you have pairs\nof vertices you want to connect, but\nwith a directed path.",
    "start": "1476331",
    "end": "1483120"
  },
  {
    "text": "So similar to a\nproblem we've seen. Best approximation\nknown for that is N to the 4/5 plus epsilon.",
    "start": "1483120",
    "end": "1488440"
  },
  {
    "text": "And this is just a\ncouple years ago. So that seems very hard to\ndo better than any constant. Probably there's an N to\nthe epsilon lower bound,",
    "start": "1488440",
    "end": "1495380"
  },
  {
    "text": "but this is the best we\nknow so far, a bit smaller. ",
    "start": "1495380",
    "end": "1501169"
  },
  {
    "text": "Cool. Any questions about that table? We will probably come back to it\na few times, but in more depth.",
    "start": "1501170",
    "end": "1513120"
  },
  {
    "text": "So how do you prove\nthe lower bound side? We're going to use reductions. Now this field is a little bit\nmessier in terms of reductions.",
    "start": "1513120",
    "end": "1522500"
  },
  {
    "text": "For NP completeness,\nNP hardness, we just worried about [? carp ?]\nstyle, one call reductions.",
    "start": "1522500",
    "end": "1528600"
  },
  {
    "text": "That's all we had\nto think about. In this universe, there\nare 1, 2, 3, 4, 5, 6, 7, 8,",
    "start": "1528600",
    "end": "1536270"
  },
  {
    "text": "9-- at least nine\ndefinitions of reduction.",
    "start": "1536270",
    "end": "1541800"
  },
  {
    "text": "You don't need to know them all. I will define four\nof them, I think.",
    "start": "1541800",
    "end": "1549419"
  },
  {
    "text": "They're all very\nsimilar, and they all lead to slightly different\nnotions of hardness. So you have to be\na little careful",
    "start": "1549420",
    "end": "1555196"
  },
  {
    "text": "when you say oh, this\nproblem is something hard. But I'll give you\nsome definitions that are pretty easy\nto work with, I think.",
    "start": "1555196",
    "end": "1563520"
  },
  {
    "text": "In general, this\nfamily is called approximation-preserving\nreductions.",
    "start": "1563520",
    "end": "1570509"
  },
  {
    "start": "1570510",
    "end": "1578970"
  },
  {
    "text": "So let's say we want to\ngo from some problem A",
    "start": "1578970",
    "end": "1585429"
  },
  {
    "text": "to some problem B. So you're\ngiven an instance of A,",
    "start": "1585430",
    "end": "1594000"
  },
  {
    "text": "let's call it x, and you want to\nproduce an instance of B. Let's",
    "start": "1594000",
    "end": "1600250"
  },
  {
    "text": "call it x prime. And we're going to do\nthat by a function f,",
    "start": "1600250",
    "end": "1605790"
  },
  {
    "text": "so x prime is f of x. So far, just like NP reductions.",
    "start": "1605790",
    "end": "1613809"
  },
  {
    "text": "But now-- usually what we said\nis that the answer to x equals the answer to x prime.",
    "start": "1613810",
    "end": "1619510"
  },
  {
    "text": "So you could say OPT of x\nequals the OPT of x prime. But that's not going\nto be strong enough.",
    "start": "1619510",
    "end": "1624800"
  },
  {
    "text": "What we want is that, if we\ncan find a solution to this B problem-- let's call it\ny-prime to the problem x-prime.",
    "start": "1624800",
    "end": "1636710"
  },
  {
    "text": "So the x-prime is\nan instance of B. You can find some solution-- any\nsolution y-prime-- to x-prime, then we want to be\nable to convert it",
    "start": "1636710",
    "end": "1643180"
  },
  {
    "text": "back by a function, g,\ninto a solution to A, which",
    "start": "1643180",
    "end": "1652430"
  },
  {
    "text": "we'll call y. And so it's g-- you might\nthink it's g of y-prime,",
    "start": "1652430",
    "end": "1658420"
  },
  {
    "text": "but we'll make it g\nof x comma y prime. So it can also depend on\nwhat you started with.",
    "start": "1658420",
    "end": "1665390"
  },
  {
    "text": "So this is the general flavor. A reduction consists\nof two steps.",
    "start": "1665390",
    "end": "1670570"
  },
  {
    "text": "First, like before, we\nconvert instances of A to instances of B.\nNow in addition, we want to be able to\nrecover solutions of B",
    "start": "1670570",
    "end": "1677570"
  },
  {
    "text": "into similarly good\nsolutions to A. And there's many ways to\ndefine similarly good.",
    "start": "1677570",
    "end": "1685980"
  },
  {
    "text": "Let me give you one.",
    "start": "1685980",
    "end": "1694730"
  },
  {
    "start": "1694730",
    "end": "1701000"
  },
  {
    "text": "So if we're just interested\nin PTAS's, then--",
    "start": "1701000",
    "end": "1707000"
  },
  {
    "text": "like you want to know does\nmy problem have a PTAS or I want to prove\nimpossibility of PTAS's, then",
    "start": "1707000",
    "end": "1713290"
  },
  {
    "text": "I think there's one clear\nnotion of reduction, which is obviously enough\ncalled PTAS reduction.",
    "start": "1713290",
    "end": "1720015"
  },
  {
    "start": "1720015",
    "end": "1725100"
  },
  {
    "text": "So what we want to say is--\nI hope you've seen calculus",
    "start": "1725100",
    "end": "1735070"
  },
  {
    "text": "at some point. In calculus, there's this\nnotion of epsilon delta proofs, or definitions.",
    "start": "1735070",
    "end": "1740660"
  },
  {
    "text": "So I'm going to say-- you don't\nhave to think of it this way, but I find it useful to\nthink of it this way.",
    "start": "1740660",
    "end": "1746010"
  },
  {
    "text": "Let me get to what\nthe statement is. If y-prime is a 1 plus\ndelta approximation to B,",
    "start": "1746010",
    "end": "1761090"
  },
  {
    "text": "then y is a 1 plus epsilon\napproximation to A.",
    "start": "1761090",
    "end": "1779190"
  },
  {
    "text": "So ultimately we're\ninterested in PTAS's, and we want to say that if you\nhave a PTAS for B, then",
    "start": "1779190",
    "end": "1786630"
  },
  {
    "text": "you get a PTAS for A. It used to be, when we\ndid a reduction from A to B, that showed that if B had\na polynomial time algorithm,",
    "start": "1786630",
    "end": "1795110"
  },
  {
    "text": "then so did A, because you just\nplug in these chains together. You convert A into\nthe B instance,",
    "start": "1795110",
    "end": "1800640"
  },
  {
    "text": "you run your poly algorithm\nand get a solution, and convert it back. Well, with NP, we didn't\neven have to convert.",
    "start": "1800640",
    "end": "1806470"
  },
  {
    "text": "The answer was the same. Now we could do that. We want to do the same\nthing with PTAS's. So if we have a PTAS for\nB, we can convert A into B,",
    "start": "1806470",
    "end": "1814205"
  },
  {
    "text": "run the PTAS, get a solution,\nand come back and get-- what we want is for it\nto be a 1 plus epsilon",
    "start": "1814205",
    "end": "1819750"
  },
  {
    "text": "approximation to A.\nSo that's the goal, 1 plus epsilon approximation. And what this is\nsaying is there's",
    "start": "1819750",
    "end": "1825850"
  },
  {
    "text": "some function delta of\nepsilon-- for any epsilon, there's some value\ndelta where you",
    "start": "1825850",
    "end": "1833760"
  },
  {
    "text": "can give that value\nto the PTAS for B, and it will give you\nwhat you want for A.",
    "start": "1833760",
    "end": "1842500"
  },
  {
    "text": "Because PTAS is supposed to\nrun for any fixed constant--",
    "start": "1842500",
    "end": "1848210"
  },
  {
    "text": "we called it epsilon, but\nit could also be delta. And so you plug in\nthis to the PTAS.",
    "start": "1848210",
    "end": "1853790"
  },
  {
    "text": "You will get a 1 plus\ndelta approximation to your B problem. And then what we want is\nthat this conversion-- so y",
    "start": "1853790",
    "end": "1860049"
  },
  {
    "text": "here is g of xy-prime. ",
    "start": "1860050",
    "end": "1865990"
  },
  {
    "text": "So we want g-- this\nis a constraint on g. We want g to have the property\nthat if y-prime is that good,",
    "start": "1865990",
    "end": "1871730"
  },
  {
    "text": "then y will still be\nas good as we need. So maybe you just-- you want\nto get a 1.1 approximation.",
    "start": "1871730",
    "end": "1880490"
  },
  {
    "text": "You want to get within\n10% of the right answer. Maybe you have to call B\nwith a much smaller thing. Maybe delta is 0.01.",
    "start": "1880490",
    "end": "1889500"
  },
  {
    "text": "You need to be within\n1% of the right answer. But there's-- for\na PTAS reduction,",
    "start": "1889500",
    "end": "1895480"
  },
  {
    "text": "you want there to be some\napproximability you asked for so that you get\nwhat you actually want.",
    "start": "1895480",
    "end": "1901374"
  },
  {
    "text": "This is sort of the obvious--\nthis the natural thing if you want to preserve\nPTAS-ness in this direction,",
    "start": "1901374",
    "end": "1906740"
  },
  {
    "text": "from B to A. One slight note is\nthat we also allow f",
    "start": "1906740",
    "end": "1913940"
  },
  {
    "text": "and g to depend on epsilon.",
    "start": "1913940",
    "end": "1919059"
  },
  {
    "text": "So this reduction-- it\nwould be hard to get this property for all epsilon\nwith the same instance",
    "start": "1919060",
    "end": "1925550"
  },
  {
    "text": "conversion. So now we allow the\nconversion of the instances to depend on epsilon, so you\ncan do fun things that way",
    "start": "1925550",
    "end": "1932220"
  },
  {
    "text": "for the purposes\nof PTAS reductions. But the key thing we get is\nthat if B is a PTAS, then--",
    "start": "1932220",
    "end": "1941350"
  },
  {
    "text": "or has a PTAS--\nthen A as a PTAS, so it's in the\ncomplexity class PTAS. Of course, what we care about\nis the contrapositive of that.",
    "start": "1941350",
    "end": "1948559"
  },
  {
    "text": "So if A is not in PTAS,\nthen B is not in PTAS.",
    "start": "1948560",
    "end": "1955680"
  },
  {
    "text": "So we can use this-- we\nreduced from our hard problem that we know is not in PTAS,\nassuming P does not equal NP,",
    "start": "1955680",
    "end": "1961070"
  },
  {
    "text": "and we get that our new\nproblem B is not in PTAS. That's the point.",
    "start": "1961070",
    "end": "1966360"
  },
  {
    "text": " This is also true for\nsomething like APX. ",
    "start": "1966360",
    "end": "1974580"
  },
  {
    "text": "So if you just want constant\nfactor approximation, this will convert\none constant factor into another constant factor.",
    "start": "1974580",
    "end": "1981880"
  },
  {
    "text": "So yeah, if you\nhave-- I mean, it's maybe stronger than what\nyou need, but will give you",
    "start": "1981880",
    "end": "1989000"
  },
  {
    "text": "constant factor\napproximations, as well. ",
    "start": "1989000",
    "end": "2003049"
  },
  {
    "text": "So here's some easy\nmore definitions. ",
    "start": "2003050",
    "end": "2008438"
  },
  {
    "text": "Oh, OK, so a few more fun facts. If this statement\nalso holds true",
    "start": "2008438",
    "end": "2014970"
  },
  {
    "text": "for epsilon equals 0 when you\nplug in epsilon equals zero, delta equals zero,\nthen you're just",
    "start": "2014970",
    "end": "2020420"
  },
  {
    "text": "getting the regular notion\nof reduction from NP land. This is saying the\nOPTs are equal.",
    "start": "2020420",
    "end": "2025970"
  },
  {
    "text": "So usually your solution\nalso works in that setting. That's usually the\neasy thing to do. So this is a strictly stronger\nnotion of NP reduction",
    "start": "2025970",
    "end": "2034620"
  },
  {
    "text": "if you allow the 0,0 case. Also, reductions change.",
    "start": "2034620",
    "end": "2040570"
  },
  {
    "text": "So if A reduces to B\nand B reduces to C, then A reduces to C. All the\nusual things you'd expect.",
    "start": "2040570",
    "end": "2045635"
  },
  {
    "text": " Some special cases of\ninterest are AP reduction.",
    "start": "2045635",
    "end": "2054158"
  },
  {
    "text": "This is when the delta\nfunction is linear in epsilon. ",
    "start": "2054159",
    "end": "2061929"
  },
  {
    "text": "So this is nice because\nit tells you, for example, if B is in-- has some order\nf approximation, then A does,",
    "start": "2061929",
    "end": "2072629"
  },
  {
    "text": "as well. It just changes this\nconstant factor.",
    "start": "2072630",
    "end": "2078210"
  },
  {
    "text": "So this is useful if you care\nabout log N approximation. If you use this\ndefinition, things",
    "start": "2078210",
    "end": "2085360"
  },
  {
    "text": "could change, because\nyou're allowed to change what the factor\nis out here in crazy ways.",
    "start": "2085360",
    "end": "2092579"
  },
  {
    "text": "So over here, [? before-- ?] so\n[? it's ?] just a linear blow up in the approximation factor,\nthen we only lose constant",
    "start": "2092580",
    "end": "2098970"
  },
  {
    "text": "factors in approximability. And one more is\nstrict reduction.",
    "start": "2098970",
    "end": "2105080"
  },
  {
    "text": " This is when there's no blowup.",
    "start": "2105080",
    "end": "2110900"
  },
  {
    "text": " If you have a c\napproximation here,",
    "start": "2110900",
    "end": "2118697"
  },
  {
    "text": "you get a c approximation there.  That's nice when you can get it.",
    "start": "2118697",
    "end": "2124510"
  },
  {
    "text": "We're not going to aim\nfor this in particular, but there are a\nbunch of reductions we'll talk about\ntoday that are strict. So it's nice to just have a word\nto say oh, this is even strict.",
    "start": "2124510",
    "end": "2131926"
  },
  {
    "text": "You don't even need any\n[? blowup ?] like this stuff. So that was strict AP\nand PTAS reductions.",
    "start": "2131926",
    "end": "2141990"
  },
  {
    "text": " There's one more, but maybe\nfirst let me define hardness.",
    "start": "2141990",
    "end": "2151585"
  },
  {
    "start": "2151585",
    "end": "2163500"
  },
  {
    "text": "So today, we will\nfocus on APX hardness. And these are supposed to be\nthe hardest problems in APX.",
    "start": "2163500",
    "end": "2176640"
  },
  {
    "start": "2176640",
    "end": "2183660"
  },
  {
    "text": "And so, I mean,\nbecause we're trying to distinguish between\nPTAS-able problems and just",
    "start": "2183660",
    "end": "2190370"
  },
  {
    "text": "constant factor\napproximable problems, we are interested\nin PTAS reductions.",
    "start": "2190370",
    "end": "2197660"
  },
  {
    "text": "So it's going to turn out\nthat APX hard-- well I guess we sort of already know.",
    "start": "2197660",
    "end": "2204230"
  },
  {
    "text": "This implies you're not in PTAS\nif P equals NP-- P does not",
    "start": "2204230",
    "end": "2211310"
  },
  {
    "text": "equal NP-- because of\nthis strict containment,",
    "start": "2211310",
    "end": "2217090"
  },
  {
    "text": "P does not equal NP, then\nPTAS is different from APX. And so if you show your\nhardest problem in APX,",
    "start": "2217090",
    "end": "2223880"
  },
  {
    "text": "using a reduction that\npreserves PTAS-ability, then you know-- I mean, the\nidea is that-- all right.",
    "start": "2223880",
    "end": "2232599"
  },
  {
    "text": "When we're doing\nthese reductions, we know that if B had a\nPTAS then A had a PTAS.",
    "start": "2232600",
    "end": "2238170"
  },
  {
    "text": "And what we're saying is you\ncan re-- your APX hard means you can reduce from any\nproblem in APX to your problem.",
    "start": "2238170",
    "end": "2246270"
  },
  {
    "text": "So if your problem had a PTAS,\nthat would mean all problems had PTAS's. All APX problems had PTAS's.",
    "start": "2246270",
    "end": "2252560"
  },
  {
    "text": "But we know that's not the case. Therefore, your problem\ndoes not have a PTAS.",
    "start": "2252560",
    "end": "2257940"
  },
  {
    "text": "So it's just like\nMP completeness, just with different letters. ",
    "start": "2257940",
    "end": "2264020"
  },
  {
    "text": "Cool. And different reductions.  These reductions\nare all a little",
    "start": "2264020",
    "end": "2269770"
  },
  {
    "text": "bit awkward to work\nwith directly for-- or these definitions\nare a little awkward",
    "start": "2269770",
    "end": "2276590"
  },
  {
    "text": "to check directly, although\nultimately it's the same thing. In practice, people seem\nto use a different notion",
    "start": "2276590",
    "end": "2284240"
  },
  {
    "text": "of reduction, for the most\npart, called L reductions. That's stronger than AP\nreduction, not as strong",
    "start": "2284240",
    "end": "2294260"
  },
  {
    "text": "as strict. I guess it's not directly\nrelated either way to strict,",
    "start": "2294260",
    "end": "2300060"
  },
  {
    "text": "but, it's OK. ",
    "start": "2300060",
    "end": "2309960"
  },
  {
    "text": "So while I define this in\nterms of PTAS reduction, because that's what you\nneed to get this result,",
    "start": "2309960",
    "end": "2316539"
  },
  {
    "text": "most people think\nabout L reduction, which is going to imply--\nit's going to be stronger",
    "start": "2316540",
    "end": "2335590"
  },
  {
    "text": "than the other two notions\nof reduction, AP and PTAS. ",
    "start": "2335590",
    "end": "2345359"
  },
  {
    "text": "So what's the definition? We want to satisfy\ntwo properties. The first property is a kind\nof blowup, going left to right.",
    "start": "2345360",
    "end": "2357650"
  },
  {
    "start": "2357650",
    "end": "2366309"
  },
  {
    "text": "Funnily enough, the\nother reductions do not have this property,\nbecause they don't quite need it in the way\nthat they're going. But we want that the transform\nproblem, its optimal solution",
    "start": "2366310",
    "end": "2376030"
  },
  {
    "text": "is not much bigger. It's bigger by only\na constant factor. This is, like, less\nthan or equal to alpha times the optimal-- the\noriginal optimal solution given",
    "start": "2376030",
    "end": "2384190"
  },
  {
    "text": "instance, so A.\nSecond property--",
    "start": "2384190",
    "end": "2391079"
  },
  {
    "text": "and we'll see why we\nneed this in a moment--",
    "start": "2391080",
    "end": "2396860"
  },
  {
    "text": "is if you look at the\nabsolute error instead of the ratio between the\ncomputed solution y--",
    "start": "2396860",
    "end": "2407690"
  },
  {
    "text": "and y was the thing that we\ngot in the lower left corner, we produced the solution\ny-- we look at the cost",
    "start": "2407690",
    "end": "2415550"
  },
  {
    "text": "that we get out of--\ny is the solution. So we look at the\ncost of that solution, we compare it to\nthe optimal solution",
    "start": "2415550",
    "end": "2422000"
  },
  {
    "text": "to our original\ninstance-- because it is a solution to that instance. That should not be much\nbigger than the error",
    "start": "2422000",
    "end": "2429289"
  },
  {
    "text": "on the right side. Again, absolute error. So we want this to be big O of\ncost in B's problem of y-prime",
    "start": "2429290",
    "end": "2441940"
  },
  {
    "text": "minus OPT of B of x prime.",
    "start": "2441940",
    "end": "2447230"
  },
  {
    "text": " So these are both in B land.",
    "start": "2447230",
    "end": "2452337"
  },
  {
    "text": "Again, we look at\nthe optimal solution to the produced instance\nversus some solution",
    "start": "2452337",
    "end": "2457474"
  },
  {
    "text": "that we were given. We didn't produce\nthat solution, so this has to hold no matter\nwhat solution y-prime",
    "start": "2457475",
    "end": "2464500"
  },
  {
    "text": "you're given to the instance\nx-prime, when you convert it using g to a solution\nto x in problem A,",
    "start": "2464500",
    "end": "2472520"
  },
  {
    "text": "you want that the gap--\nabsolute gap-- is not stretched by more than a constant factor.",
    "start": "2472520",
    "end": "2479770"
  },
  {
    "text": "Again, this is at most some\nconstant times [? that ?] [? thing ?]. OK?",
    "start": "2479770",
    "end": "2485410"
  },
  {
    "text": "Now it should not be obvious\nthat this implies this,",
    "start": "2485410",
    "end": "2490609"
  },
  {
    "text": "but it does, with delta equal\nto, I think-- get some color.",
    "start": "2490610",
    "end": "2499540"
  },
  {
    "text": "Let's say the constant\nin here is alpha, the constant here is beta.",
    "start": "2499540",
    "end": "2505840"
  },
  {
    "text": "And this should be alpha\ntimes beta times epsilon. That is delta of epsilon.",
    "start": "2505840",
    "end": "2513460"
  },
  {
    "text": "That's the claim. Let's prove the claim,\nideally without cheating.",
    "start": "2513460",
    "end": "2521560"
  },
  {
    "text": "So I claim that if I\nhave such an L reduction,",
    "start": "2521560",
    "end": "2531300"
  },
  {
    "text": "that this holds where-- when\ndelta is that linear function of epsilon.",
    "start": "2531300",
    "end": "2538119"
  },
  {
    "text": "So I want to conclude that y\nis a pretty good approximation.",
    "start": "2538120",
    "end": "2543200"
  },
  {
    "text": "So to do that, I will look at\nthe cost of y divided by OPT.",
    "start": "2543200",
    "end": "2549020"
  },
  {
    "start": "2549020",
    "end": "2555120"
  },
  {
    "text": "OPT of X would be\nthe original input. So we want to show that this\nis, at most, 1 plus epsilon.",
    "start": "2555120",
    "end": "2563170"
  },
  {
    "text": "Now what do we know? I should write A, I\nguess, because this is all about problem\nA. What do we know?",
    "start": "2563170",
    "end": "2571020"
  },
  {
    "text": "We know this property-- I\nwrote absolute value here,",
    "start": "2571020",
    "end": "2576550"
  },
  {
    "text": "so this works for\nmaximization and minimization. You can even\nconvert minimization to maximization problems\nusing this definition.",
    "start": "2576550",
    "end": "2582600"
  },
  {
    "text": "We will do that at some point. OK. So let's just try to\nplug this into here.",
    "start": "2582600",
    "end": "2591320"
  },
  {
    "text": "So I think I need\nto split into cases, and I'll just worry about\nthe minimization case.",
    "start": "2591320",
    "end": "2596869"
  },
  {
    "text": "So let's say that cost\nof A is bigger than OPT. So then cost of A is going to\nbe OPT plus this thing, at most.",
    "start": "2596870",
    "end": "2607020"
  },
  {
    "text": "So this is going to be at\nmost OPT of x plus beta--",
    "start": "2607020",
    "end": "2621079"
  },
  {
    "text": "I'm going to not use\nthe big O notation, and just write the beta thing. Beta times-- I guess there's\nno absolute value needed,",
    "start": "2621079",
    "end": "2629390"
  },
  {
    "text": "because this is a\nminimization problem. Let's say-- so this will be cos\nsub B of y-prime minus OPT of B",
    "start": "2629390",
    "end": "2643360"
  },
  {
    "text": "of x-prime.  So that's what I get from\nexpanding out the numerator,",
    "start": "2643361",
    "end": "2649600"
  },
  {
    "text": "and the denominator is the same. Clear? ",
    "start": "2649600",
    "end": "2656299"
  },
  {
    "text": "Just rearranging terms\nhere, essentially. OK. Now these two terms cancel,\nso we get 1 plus that.",
    "start": "2656300",
    "end": "2668599"
  },
  {
    "text": "That's good, because I\nwanted that to be epsilon. Let's see. What else do we know.",
    "start": "2668600",
    "end": "2674570"
  },
  {
    "text": "It's 1 plus this thing. Let me scroll down.",
    "start": "2674570",
    "end": "2680505"
  },
  {
    "start": "2680505",
    "end": "2691599"
  },
  {
    "text": "OK, we have one other property. We've got to use it. The other property\nis that OPT sub B is related to OPT sub A.\nNow we have OPT sub A here,",
    "start": "2691599",
    "end": "2702980"
  },
  {
    "text": "but it's in the denominator,\nwhich flips the relation. So we can write that relation\nup there as OPT sub A of x",
    "start": "2702980",
    "end": "2708990"
  },
  {
    "text": "is omega of OPT\nsub B of x-prime. That's the same\nas statement one.",
    "start": "2708990",
    "end": "2714470"
  },
  {
    "text": "And because the\ndenominator is omega, that means the whole thing is\nbig L. So this is going to be,",
    "start": "2714470",
    "end": "2720540"
  },
  {
    "text": "at most, one plus-- so\nnow we have this thing.",
    "start": "2720540",
    "end": "2728880"
  },
  {
    "text": "So the numerator is the same. We had before beta times\ncost sub B of y-prime minus",
    "start": "2728880",
    "end": "2737623"
  },
  {
    "text": "OPT sub B of x-prime. So that's unchanged. But now, instead of\ndividing by OPT sub A,",
    "start": "2737623",
    "end": "2745580"
  },
  {
    "text": "we're going to divide\nby OPT sub B of x-prime.",
    "start": "2745580",
    "end": "2752117"
  },
  {
    "text": "And we lost a constant factor,\nthat constant factor translated to B alpha in the\nnumerator because we inverted the equation.",
    "start": "2752117",
    "end": "2758380"
  },
  {
    "text": "We divided by the\nconstant factor there. ",
    "start": "2758380",
    "end": "2763390"
  },
  {
    "text": "So what-- well now\nthis cancels with that.",
    "start": "2763390",
    "end": "2770519"
  },
  {
    "text": "So this is going\nto be 1 plus alpha beta times cost sub B y-prime\nover OPT sub B of x-prime",
    "start": "2770520",
    "end": "2787890"
  },
  {
    "text": "minus 1. Still looks kind of weird. But what we-- there's\none more thing",
    "start": "2787890",
    "end": "2793210"
  },
  {
    "text": "we didn't use, which is we\nassumed the-- we were given some solution y-prime that\nwas a 1 plus delta of epsilon",
    "start": "2793210",
    "end": "2800270"
  },
  {
    "text": "approximation, where\ndelta is this thing that we defined there. It's obviously set to cancel out\neverything that happened here.",
    "start": "2800270",
    "end": "2806589"
  },
  {
    "text": "So this thing should be,\nat most, 1 plus delta,",
    "start": "2806590",
    "end": "2814132"
  },
  {
    "text": "because this is exactly\nthe approximation ratio for y-prime versus the\noptimal solution to x-prime.",
    "start": "2814132",
    "end": "2819700"
  },
  {
    "text": "And 1 plus delta is 1\nplus alpha beta epsilon.",
    "start": "2819700",
    "end": "2827910"
  },
  {
    "text": "So this 1 cancels with that\n1, these alpha betas-- whoops. AUDIENCE: I think\nit's backwards.",
    "start": "2827910",
    "end": "2834269"
  },
  {
    "text": "PROFESSOR: Which is backwards? The definition of delta? OK. Whoops.",
    "start": "2834270",
    "end": "2839520"
  },
  {
    "start": "2839520",
    "end": "2845250"
  },
  {
    "text": "Let's try epsilon\nover alpha beta. ",
    "start": "2845250",
    "end": "2853450"
  },
  {
    "text": "That makes sense, because delta\nshould be smaller than epsilon probably, and alpha and beta\nare probably bigger than 1.",
    "start": "2853450",
    "end": "2862809"
  },
  {
    "text": "So now we get epsilon\nover alpha beta here.",
    "start": "2862810",
    "end": "2867920"
  },
  {
    "text": "And then that alpha beta\ncancels with that alpha beta, and we are left\nwith 1 plus epsilon.",
    "start": "2867920",
    "end": "2874420"
  },
  {
    "text": "OK. So this is why it's not\nobvious, but it's just plugging",
    "start": "2874420",
    "end": "2880338"
  },
  {
    "text": "in all the things and it works. And the funny thing is,\nsomehow L reductions, though they-- a little bit\nless natural, I feel like.",
    "start": "2880339",
    "end": "2887095"
  },
  {
    "text": "I mean, if you're thinking about\nconstant factor approximation, why should you care\nabout absolute error?",
    "start": "2887095",
    "end": "2892146"
  },
  {
    "text": "The short answer that I've\nseen written in various papers is because it's easier\nto think that way for a lot of the typical\nreductions that you do.",
    "start": "2892146",
    "end": "2900900"
  },
  {
    "text": "So let us do some\nof those reductions. And we'll get some intuition.",
    "start": "2900900",
    "end": "2908339"
  },
  {
    "text": "L reductions also-- they\ndo work in the zero case. If you have an optimal\nsolution to x-prime,",
    "start": "2908340",
    "end": "2914960"
  },
  {
    "text": "you will get an\noptimal solution to x. So they are also NP reductions. Again, that's a generalization\nof-- or strengthening",
    "start": "2914960",
    "end": "2921810"
  },
  {
    "text": "of the type of reduction we\nsaw in all previous lectures. All right.",
    "start": "2921810",
    "end": "2928190"
  },
  {
    "text": "So I want to\nsimultaneously tell you a bunch of problems\nthat are APX complete so",
    "start": "2928190",
    "end": "2933300"
  },
  {
    "text": "that you know things\nto reduce from, but also I'll show you\nexamples of such things. So some of these I will omit the\nproofs, because they're messy",
    "start": "2933300",
    "end": "2940102"
  },
  {
    "text": "and it's just useful to\nknow that they're there so you can reduce from them. Others I-- most of them,\nI will cover the proofs.",
    "start": "2940102",
    "end": "2945110"
  },
  {
    "start": "2945110",
    "end": "2975610"
  },
  {
    "text": "All right. And we're going to\nreturn to an old issue from the first SAT lecture.",
    "start": "2975610",
    "end": "2983460"
  },
  {
    "text": " And I'm going to introduce\nsome new notation.",
    "start": "2983460",
    "end": "2990799"
  },
  {
    "text": "So a lot of the starting\npoints here are just max SAT.",
    "start": "2990800",
    "end": "2996110"
  },
  {
    "text": "Or I should-- let's\nsay a max CNF SAT. You're given a CNF formula. It's picked out a\nbunch of clauses. You want to maximize\nthe number of clauses",
    "start": "2996110",
    "end": "3002380"
  },
  {
    "text": "that you satisfy with\nsome variable assignment. So that's going to\nbe APX complete. There are constant\nfactor approximations",
    "start": "3002380",
    "end": "3008700"
  },
  {
    "text": "if the clauses are constant\nsize, I should say. So like max 3SAT has a\nconstant factor approximation,",
    "start": "3008700",
    "end": "3015339"
  },
  {
    "text": "I forget what the\ncurrent best is. And no better. There's no PTAS for a max 3SAT.",
    "start": "3015340",
    "end": "3021550"
  },
  {
    "text": "This is a stronger\nform of max 3SAT, which we have not seen before,\nthough we've hinted around it.",
    "start": "3021550",
    "end": "3028790"
  },
  {
    "text": "The E means every\nclause has exactly three distinct literals.",
    "start": "3028790",
    "end": "3034030"
  },
  {
    "start": "3034030",
    "end": "3048540"
  },
  {
    "text": "This is an issue that\nwe stumbled into. Oh, do we allow clauses\nto have only two literals?",
    "start": "3048540",
    "end": "3054000"
  },
  {
    "text": "I said no, in the\noriginal definition. But I did allow\nrepeated literals, which is the same thing. So when I say three set, I\nmean you can repeat literals,",
    "start": "3054000",
    "end": "3062520"
  },
  {
    "text": "or you can have fewer\nthan three literals. When I say E three set, then\nyou're not allowed to do that.",
    "start": "3062520",
    "end": "3069330"
  },
  {
    "text": "Then you may remember we\ntalked about 3SAT five. That meant every clause\nhas only three literals,",
    "start": "3069330",
    "end": "3075890"
  },
  {
    "text": "and every variable appears,\nat most, five times. E5 means exactly five times.",
    "start": "3075890",
    "end": "3085060"
  },
  {
    "text": "Each variable appears\nexactly five times.",
    "start": "3085060",
    "end": "3098304"
  },
  {
    "text": "Do you have a question? AUDIENCE: [INAUDIBLE]\ngives you a condition on the number of clauses. PROFESSOR: Oh, you're right.",
    "start": "3098304",
    "end": "3103970"
  },
  {
    "text": "That gives you a linear relation\nbetween the number of clauses and the number of variables. You can work it out. This is hard.",
    "start": "3103970",
    "end": "3109819"
  },
  {
    "text": "I will not prove it. It's not hard, but it's\njust a little bit messy. Sorry.",
    "start": "3109820",
    "end": "3115175"
  },
  {
    "text": "It's not difficult. I will prove a slightly\ndifferent result, which",
    "start": "3115175",
    "end": "3121310"
  },
  {
    "text": "this one is based on, which\nis a little bit more familiar",
    "start": "3121310",
    "end": "3126580"
  },
  {
    "text": "but also introduces something\nnew we hadn't seen before. This is the regular 3SAT. Each clause has, at\nmost, three literals.",
    "start": "3126580",
    "end": "3134700"
  },
  {
    "text": "And every variable appears,\nat most, three times. This is something I\ndidn't realize was hard.",
    "start": "3134700",
    "end": "3140289"
  },
  {
    "text": "It's not written in most places. But it is here, in the\nworld of approximability.",
    "start": "3140290",
    "end": "3147430"
  },
  {
    "text": "This is the reduction. It's kind of funny. So suppose you\nhave a variable, x,",
    "start": "3147430",
    "end": "3153330"
  },
  {
    "text": "which appears a million times. You're going to make\na cycle, so to speak.",
    "start": "3153330",
    "end": "3160703"
  },
  {
    "text": "It's a formula,\nso it's not really a cycle, but of size 1 million. And you're going to write down\nthis 2SAT constraint-- not xi",
    "start": "3160704",
    "end": "3170360"
  },
  {
    "text": "or xi plus 1 for all i. And do it around in\nthe cycle, so not x6 or x1-- or x a million or x1.",
    "start": "3170360",
    "end": "3178670"
  },
  {
    "text": "That's, of course, equivalent\nto saying if xi is set to true, then xi plus 1 must\nalso be set to true. So if any of these are\nset to true, they all are.",
    "start": "3178670",
    "end": "3185789"
  },
  {
    "text": "So the only\nsatisfying assignments here are everybody true,\neverybody not true.",
    "start": "3185790",
    "end": "3192860"
  },
  {
    "text": "So if you're just worried\nabout NP reductions, this is a reduction\nfrom 3SAT to 3SAT-3.",
    "start": "3192860",
    "end": "3199069"
  },
  {
    "text": "Because every variable\nnow will appear in exactly three--\nexactly three,",
    "start": "3199070",
    "end": "3204360"
  },
  {
    "text": "in fact-- so constraints. This one, this one, and whatever\nit originally-- whatever",
    "start": "3204360",
    "end": "3211809"
  },
  {
    "text": "you want to plug it into. So each of these was an\noccurrence of that variable. Maybe use the positive form,\nmaybe use the negative form,",
    "start": "3211810",
    "end": "3219090"
  },
  {
    "text": "but each variable appears three\ntimes in this first picture. Now that's a great\nreduction for 3SAT-3.",
    "start": "3219090",
    "end": "3226059"
  },
  {
    "text": "Notice I didn't write max,\nbecause this reduction will not work as an L reduction, say.",
    "start": "3226060",
    "end": "3233030"
  },
  {
    "text": "You cannot prove that max 3SAT\nis hard using this reduction, because you could, for\nexample, just violate these two",
    "start": "3233030",
    "end": "3242890"
  },
  {
    "text": "constraints and make all\nof these guys true and all of these guys false. And if this is size\na million, that",
    "start": "3242890",
    "end": "3249330"
  },
  {
    "text": "means you're saying--\nI mean, you're setting the variable\nhalf true, half false-- or you could use any ratio you\nwant-- at a very small cost.",
    "start": "3249330",
    "end": "3257920"
  },
  {
    "text": "You're only paying a penalty\nof two constraints violated, and yet you're able to satisfy\n1/2 of the clauses using",
    "start": "3257920",
    "end": "3264310"
  },
  {
    "text": "xi equal to true, and\nsome other set of clauses using xi set to false. And there's no way to\nbound how many clauses you",
    "start": "3264310",
    "end": "3271220"
  },
  {
    "text": "can sort of misrepresent. And the objective in\nmax 3SAT is to maximize the number of clauses satisfied.",
    "start": "3271220",
    "end": "3277814"
  },
  {
    "text": "So if you allow\nthis kind of thing where you can flip in\ncrazy ways and change a huge number of clauses one\nway or the other in this sort",
    "start": "3277814",
    "end": "3284910"
  },
  {
    "text": "of false way, how\nwould-- if you're trying to actually construct\na solution to max 3SAT",
    "start": "3284910",
    "end": "3290789"
  },
  {
    "text": "from a solution to\nthis 3SAT-3 instance, you wouldn't know which way\nto set the variable x to.",
    "start": "3290790",
    "end": "3296087"
  },
  {
    "text": "If you set it to true,\nthere's a whole bunch of clauses that\nwanted it to be false. If you set it to false, a whole\nbunch you wanted to be true.",
    "start": "3296087",
    "end": "3301240"
  },
  {
    "text": "Yeah. AUDIENCE: If we're just\ntalking about NP hardness here, can't you make those edges\nvery heavy by repeating the clause many times?",
    "start": "3301240",
    "end": "3307045"
  },
  {
    "text": "PROFESSOR: If we're just\nworried about NP hardness, this is fine. Because then all of\nthese have to be true. AUDIENCE: Uh, I mean for\nthe max decision problem.",
    "start": "3307045",
    "end": "3314355"
  },
  {
    "text": "PROFESSOR: Well then\nthe decision problem is, can you satisfy all of them. That is a special\ncase of the max--",
    "start": "3314355",
    "end": "3320380"
  },
  {
    "text": "AUDIENCE: Satisfy k of-- PROFESSOR: Yeah, but if\nyou set k equal to N, that's a special case\nof the general form. AUDIENCE: Oh, OK.",
    "start": "3320380",
    "end": "3326035"
  },
  {
    "text": "PROFESSOR: So-- AUDIENCE: I see\nwhat you're saying. PROFESSOR: Yeah. If you didn't-- if you wanted\nto make k and N different,",
    "start": "3326035",
    "end": "3331700"
  },
  {
    "text": "you could just add a bunch of\nthings that are unsatisfiable. Lots of ways to change\nhow many there are.",
    "start": "3331700",
    "end": "3336900"
  },
  {
    "text": " OK. Nonetheless, we can prove\nmax 3SAT-3 is hard with an L",
    "start": "3336900",
    "end": "3344410"
  },
  {
    "text": "reduction from 3SAT. So I'm not going to prove\nthat 3SAT is APX hard.",
    "start": "3344410",
    "end": "3352089"
  },
  {
    "text": "We might do that in\na future lecture, but just take that as given. What I want to show you\nis how to convert max 3SAT",
    "start": "3352089",
    "end": "3357430"
  },
  {
    "text": "into max 3SAT-3. Not like this, but\nusing a different trick.",
    "start": "3357430",
    "end": "3365400"
  },
  {
    "text": "So reducing from max 3SAT.",
    "start": "3365400",
    "end": "3377200"
  },
  {
    "text": "We're given a formula,\nwe're given some variables. Let's say-- let's\nlook at variable x. ",
    "start": "3377200",
    "end": "3386380"
  },
  {
    "text": "And let's say it\nappears k times. ",
    "start": "3386380",
    "end": "3395480"
  },
  {
    "text": "What we're going to\ndo, just like before, we're going to make\nk new variables.",
    "start": "3395480",
    "end": "3401380"
  },
  {
    "text": "We're going to make k variables\nx1 through xk that replace x, and we're going to use\nthose instead of x.",
    "start": "3401380",
    "end": "3407250"
  },
  {
    "text": "And I want to force all the\nvalues of x to be the same, but I want to force it even when\nyou're allowed to cheat and set",
    "start": "3407250",
    "end": "3413370"
  },
  {
    "text": "some of the things incorrectly. And we're going to do this\nusing a powerful tool, which",
    "start": "3413370",
    "end": "3419029"
  },
  {
    "text": "is good to know about,\ncalled expander graphs. ",
    "start": "3419029",
    "end": "3428130"
  },
  {
    "text": "So there's two\nthings to tell you. One is, what is\nan expander graph, and the other thing is, once\nI have an expander graph, what do I do. Let me start with the latter,\nbecause it's a little simpler.",
    "start": "3428130",
    "end": "3435580"
  },
  {
    "text": " I guess a lot of you have\nheard about expander graphs.",
    "start": "3435580",
    "end": "3442340"
  },
  {
    "text": "And the short answer is they're\ncomplicated and confusing, but really cool and powerful. We're not going to try to prove\nthat expanders exist here.",
    "start": "3442340",
    "end": "3449517"
  },
  {
    "text": "I'm just going to\ntell you they exist, and that's actually\npretty simple what they-- what\nproperties they have.",
    "start": "3449517",
    "end": "3455890"
  },
  {
    "text": "So what I want to do, whenever\nI have an edge in this graph-- this is a graph\nwhose vertices are",
    "start": "3455890",
    "end": "3462620"
  },
  {
    "text": "the x1 through xk--\nI'm going to convert an edge into a constraint,\nwhich is effectively",
    "start": "3462620",
    "end": "3467880"
  },
  {
    "text": "xi equals xj, which in\nreality is not xi or xj,",
    "start": "3467880",
    "end": "3476029"
  },
  {
    "text": "and not xj or xi. ",
    "start": "3476030",
    "end": "3482720"
  },
  {
    "text": "So I really probably shouldn't\nthink of it as xi equals xj. That's what I want to do. I want to force lots\nof things to be equal.",
    "start": "3482720",
    "end": "3488720"
  },
  {
    "text": "But really, we have\nto, in the end, think about it in\nterms of constraints, because some of them\nmight be violated.",
    "start": "3488720",
    "end": "3495940"
  },
  {
    "text": "So what is an expander graph? There are different types. But what we will use\nis two properties.",
    "start": "3495940",
    "end": "3504000"
  },
  {
    "start": "3504000",
    "end": "3509510"
  },
  {
    "text": "So this is for k nodes.  We have bounded degree, and\nwe have, for every cut AB--",
    "start": "3509510",
    "end": "3522596"
  },
  {
    "text": "and I think we've talked\nabout cuts in this context, in the context of max cut. So the idea is that\nA and B are disjoint,",
    "start": "3522596",
    "end": "3529030"
  },
  {
    "text": "and their union is the\nset of all vertices. So A is 1 side of the cut, B\nis the other side of the cut.",
    "start": "3529030",
    "end": "3537250"
  },
  {
    "text": "We want the number\nof cross edges, the number of edges\nbetween A and B, is big.",
    "start": "3537250",
    "end": "3545381"
  },
  {
    "text": "It's at least the\nmin of A and B.",
    "start": "3545382",
    "end": "3555030"
  },
  {
    "text": "Some intuition. Imagine a Kleek. A [? Kleek ?] is\nnot bounded degree, but it has this property.",
    "start": "3555030",
    "end": "3561510"
  },
  {
    "text": "If you look at any cut, there's\na lot of edges between them. It's actually more\nlike the product. But in particular,\nit's at least the min.",
    "start": "3561510",
    "end": "3567280"
  },
  {
    "text": "So you can think of the expander\nas a sparse [? Kleek. ?] It's [? Kleek-y ?]\nenough, in this sense,",
    "start": "3567280",
    "end": "3574419"
  },
  {
    "text": "which we'll see why this\nis the property we want. But it has bounded\ndegree, therefore linear number of edges. So it's very sparse.",
    "start": "3574419",
    "end": "3581160"
  },
  {
    "text": "In the construction\nwe are applying, which is due to\n[INAUDIBLE] Philips and [? Sarnak, ?]\nthe degree is 14.",
    "start": "3581160",
    "end": "3589250"
  },
  {
    "text": "But it doesn't matter. Constant.  It's actually 14\nregular, so that's nice.",
    "start": "3589250",
    "end": "3597630"
  },
  {
    "text": "So we take this\ngraph, which was known to be out there--\nbasically random graphs [INAUDIBLE]\nproperty, but we",
    "start": "3597630",
    "end": "3603130"
  },
  {
    "text": "won't worry about how\nto construct it too much, although you do have to. But there's tons of papers\non how to construct them.",
    "start": "3603130",
    "end": "3609730"
  },
  {
    "text": "And then for every\nedge, we convert it into these two constraints. So let's prove that\nthis is an L reduction.",
    "start": "3609730",
    "end": "3616510"
  },
  {
    "start": "3616510",
    "end": "3622140"
  },
  {
    "text": "Claim L reduction.",
    "start": "3622140",
    "end": "3630029"
  },
  {
    "text": "So maybe-- I don't have\nanything to point at,",
    "start": "3630030",
    "end": "3635579"
  },
  {
    "text": "because I can't point\nat an expander graph. But let me draw the graph\nso I can point at something.",
    "start": "3635579",
    "end": "3641110"
  },
  {
    "text": "Let's draw the\n[? Kleek, ?] just so it's a little easier to think about. This is an expander, [? k4 ?].",
    "start": "3641110",
    "end": "3647260"
  },
  {
    "text": "And let's say, in your solution,\nsome of these end up getting",
    "start": "3647260",
    "end": "3652700"
  },
  {
    "text": "assigned true value--\nlet's represent that by red-- some of them not.",
    "start": "3652700",
    "end": "3658579"
  },
  {
    "text": "Maybe three of them\nare true, one of them is false or whatever. In general, I'm\ngoing to choose--",
    "start": "3658580",
    "end": "3665270"
  },
  {
    "text": "so I mean, we're given\nsome solution, right? This is the solution y-prime\nto the constructed instance",
    "start": "3665270",
    "end": "3671230"
  },
  {
    "text": "x-prime. X-prime has this expander. So we look at a solution\ny-prime to x-prime, we have no control\nover what it is.",
    "start": "3671230",
    "end": "3678870"
  },
  {
    "text": "If you look at a variable,\nsome fraction of them are set to true, some of\nthem are set to false. We're going to\nchoose the majority.",
    "start": "3678870",
    "end": "3685950"
  },
  {
    "text": "So here it's majority\nred, so we're going to change this guy to be red.",
    "start": "3685950",
    "end": "3691640"
  },
  {
    "text": "Now does that hurt us? Well, we can think\nof there as being a cut of the red\nnodes versus the not",
    "start": "3691640",
    "end": "3699069"
  },
  {
    "text": "red nodes, the black nodes. ",
    "start": "3699070",
    "end": "3705200"
  },
  {
    "text": "And I claim the number\nof edges here is big. It's at least the\nminimum of A and B.",
    "start": "3705200",
    "end": "3711539"
  },
  {
    "text": "Now what we were doing is\ntaking the minimum of A and B and recoloring that side\nto be the other side.",
    "start": "3711539",
    "end": "3716820"
  },
  {
    "text": "When we do that, we\nhave these constraints, which are supposed to\nbe equality constraints.",
    "start": "3716820",
    "end": "3722640"
  },
  {
    "text": "These things are supposed to be\nequal, but they weren't before. Before I recolored this, these\nwere-- at least one constraint",
    "start": "3722640",
    "end": "3728950"
  },
  {
    "text": "here was violated, because\nthis one of them was red, one of them was black. When I fill this in,\nI improve my solution,",
    "start": "3728950",
    "end": "3735640"
  },
  {
    "text": "because-- by at least\nthe size of the cut. ",
    "start": "3735640",
    "end": "3740830"
  },
  {
    "text": "Each of these guys\nnow becomes satisfied. It wasn't before. So I improve my\nsolution by this much.",
    "start": "3740830",
    "end": "3747930"
  },
  {
    "text": "I also worsen my\nsolution, potentially, because that node\nappears in one clause.",
    "start": "3747930",
    "end": "3757289"
  },
  {
    "text": "And so it gets worse by 1. So suppose there are B\nnodes on the smaller side,",
    "start": "3757290",
    "end": "3763660"
  },
  {
    "text": "and we're recoloring B nodes. So we got an improvement by\nP, and also we worsened things",
    "start": "3763660",
    "end": "3769680"
  },
  {
    "text": "by up to P. Because these P guys\nappear in P different clauses.",
    "start": "3769680",
    "end": "3775780"
  },
  {
    "text": "Each one potentially we mess\nup is no longer satisfied. But for every one that we mess\nup-- so these guys up here",
    "start": "3775780",
    "end": "3781820"
  },
  {
    "text": "in some actual clause--\neach one we mess up, we also make at least\none thing happy.",
    "start": "3781820",
    "end": "3789090"
  },
  {
    "text": "Because we fixed the cut. So if we have any solution,\nwe can convert it into one where our variables are\nall true or all false,",
    "start": "3789090",
    "end": "3796060"
  },
  {
    "text": "and not lose anything. Therefore, there exists\nan optimal solution.",
    "start": "3796060",
    "end": "3801599"
  },
  {
    "text": "There exists an\noptimal solution. And you do this variable by\nvariable, where variables",
    "start": "3801600",
    "end": "3808299"
  },
  {
    "text": "are all true or all false. ",
    "start": "3808300",
    "end": "3820450"
  },
  {
    "text": "Now, we do change the\nvalue of OPT here.",
    "start": "3820450",
    "end": "3827400"
  },
  {
    "text": "Because we added a\nton of constraints, and we just said well the--\nin the optimal solution,",
    "start": "3827400",
    "end": "3832540"
  },
  {
    "text": "or an optimal solution-- in\nfact, all of these constraints will be satisfied. Which means OPT has increased.",
    "start": "3832540",
    "end": "3839090"
  },
  {
    "text": "So the OPT for\nx-prime, this thing,",
    "start": "3839090",
    "end": "3844200"
  },
  {
    "text": "is going to be larger\nthan the OPT for x.  OPT of x-prime is going to\nequal OPT of x plus order",
    "start": "3844200",
    "end": "3858770"
  },
  {
    "text": "the total number of occurrences\nof all variables, which",
    "start": "3858770",
    "end": "3866510"
  },
  {
    "text": "is at most three times\nthe number of clauses. ",
    "start": "3866510",
    "end": "3876170"
  },
  {
    "text": "So we want to know,\ndoes it satisfy this definition of L reduction. We need to know that\nthe OPT does not explode",
    "start": "3876170",
    "end": "3882230"
  },
  {
    "text": "by more than a constant factor. And yet, we added this big term. But the good news\nis, in 3SAT, you",
    "start": "3882230",
    "end": "3889630"
  },
  {
    "text": "can always satisfy a constant\nfraction of the clauses. So OPT is always at least--\nI think I have written here,",
    "start": "3889630",
    "end": "3896270"
  },
  {
    "text": "like, half of them. I think you just randomly\nassign the variables,",
    "start": "3896270",
    "end": "3902140"
  },
  {
    "text": "and some constant fraction will\nbe satisfied in expectation. So there's definitely a solution\nwhere OPT of-- so OPT of x",
    "start": "3902140",
    "end": "3909710"
  },
  {
    "text": "is definitely at\nleast some constant times the number of clauses. And so this adding some constant\ntimes the number of clauses",
    "start": "3909710",
    "end": "3915380"
  },
  {
    "text": "doesn't change the overall cos\nby more than a constant factor. So property one holds. Property two holds, in\nfact, with beta equal 1.",
    "start": "3915380",
    "end": "3926600"
  },
  {
    "text": "You're not making\nyour solution in-- you see we have this additive\nthing, because we add these gadgets and stuff.",
    "start": "3926600",
    "end": "3933040"
  },
  {
    "text": "Multiplicatively,\nit's confusing, and that's what we were\nworrying about here. But additively, it's very clean.",
    "start": "3933040",
    "end": "3938560"
  },
  {
    "text": "We always add the exact same\namount to your solution. So if you have a\nsolution y-prime and you convert it\nback to a solution y,",
    "start": "3938560",
    "end": "3945460"
  },
  {
    "text": "the gap-- the additive\ngap between the cost of y versus OPT of x will\nbe equal to the additive gap",
    "start": "3945460",
    "end": "3952430"
  },
  {
    "text": "between the cost of y-prime\nversus OPT of x-prime. Question. AUDIENCE: So here,\nhow many times",
    "start": "3952430",
    "end": "3959182"
  },
  {
    "text": "are you using each variable? PROFESSOR: We are using\neach variable 29 times.",
    "start": "3959182",
    "end": "3965300"
  },
  {
    "text": " We're using it-- why 29?",
    "start": "3965300",
    "end": "3973020"
  },
  {
    "text": "Because-- right. We have degree 14, but\nthen for every edge",
    "start": "3973020",
    "end": "3978819"
  },
  {
    "text": "we actually have\ntwo constraints, the implication\n[? in ?] both ways. So that's 28. Plus the vari--\neach of those nodes",
    "start": "3978820",
    "end": "3984640"
  },
  {
    "text": "actually appears in\none actual clause. OK. So this proves that\nmax 3SAT-29 is hard.",
    "start": "3984640",
    "end": "3992660"
  },
  {
    "text": "Yep, good question. Why did I claim max 3SAT-3?",
    "start": "3992660",
    "end": "3997840"
  },
  {
    "text": "Because we can use\nthis reduction now. ",
    "start": "3997840",
    "end": "4003190"
  },
  {
    "text": "So there is another\nreason I showed you this. I haven't seen this explicitly\nsaid in the literature, but all the pieces\nare out there.",
    "start": "4003190",
    "end": "4010930"
  },
  {
    "text": "So once you show max 3SAT\nsome constant is hard,",
    "start": "4010930",
    "end": "4017670"
  },
  {
    "text": "then you can do an L\nreduction from that problem to max 3SAT-3, just like this.",
    "start": "4017670",
    "end": "4023090"
  },
  {
    "text": "So first we do the expander. And then, still these nodes\nhave too high a degree. They're degree 29.",
    "start": "4023090",
    "end": "4029540"
  },
  {
    "text": "Now we're going to expand\nthose into little cycles of constraints.",
    "start": "4029540",
    "end": "4034849"
  },
  {
    "text": "Now this is actually OK when\nthe cycle has constant length,",
    "start": "4034850",
    "end": "4041300"
  },
  {
    "text": "because maybe-- suppose some\nof these are set to true, some of them are set to false.",
    "start": "4041300",
    "end": "4046697"
  },
  {
    "text": "Then just set them all to false. Don't even take majority. Set them all to false. How much does that hurt you? Well, you know that\neach of these variables",
    "start": "4046697",
    "end": "4053460"
  },
  {
    "text": "appeared in a constant\nnumber of clauses. So it only hurt you\nby a constant amount.",
    "start": "4053460",
    "end": "4061950"
  },
  {
    "text": "Every time you flip a\nvariable from true to false, you only lose an additive\nconstant in your solution.",
    "start": "4061950",
    "end": "4070800"
  },
  {
    "text": "So when we're converting from\na solution y-prime, which does weird things on\na cycle, potentially, when we convert it to y\nand set them all to false,",
    "start": "4070800",
    "end": "4078059"
  },
  {
    "text": "we-- I mean we know--\nso there's two cases. One is, all of these\nconstraints are satisfied.",
    "start": "4078060",
    "end": "4084030"
  },
  {
    "text": "Then, you should choose\nexactly what's written, and then they will all\nbe true or all be false. But if at least one\nof them is violated,",
    "start": "4084030",
    "end": "4090300"
  },
  {
    "text": "you can charge to that violation\nand set them all to false. And when you do that, I don't\nknow how many-- you know,",
    "start": "4090300",
    "end": "4096310"
  },
  {
    "text": "at most 1,000 violations\nhappen, some constant. Like three times 20-- whatever.",
    "start": "4096310",
    "end": "4102740"
  },
  {
    "text": "Some constant. And then you know\nthat you can charge that cost to the violation\nthat you were given in y-prime.",
    "start": "4102740",
    "end": "4110799"
  },
  {
    "text": "And so you can get that L\nreduction property, too, and say oh good,\nthe additive gap",
    "start": "4110800",
    "end": "4116460"
  },
  {
    "text": "in my produced solution where\nI just set all those to false is at most 1,000 times\nthe original additive gap.",
    "start": "4116460",
    "end": "4121809"
  },
  {
    "text": "And so that's an L\nreduction from max 3SAT constant to max 3SAT-3.",
    "start": "4121810",
    "end": "4129439"
  },
  {
    "text": "Questions? Yeah. AUDIENCE: So how do you know\nthere's a constant number of violations?",
    "start": "4129439",
    "end": "4135279"
  },
  {
    "text": "PROFESSOR: Because\nnow we were given an instance of 3SAT\nconstant, meaning each variable appears in a\nconstant number of clauses.",
    "start": "4135280",
    "end": "4142850"
  },
  {
    "text": "So we were given a\nsituation-- right, sorry. Also, when we do this,\neach-- we set it up",
    "start": "4142850",
    "end": "4150889"
  },
  {
    "text": "so each of these variables\nappears in one original clause.",
    "start": "4150890",
    "end": "4156528"
  },
  {
    "text": "Yeah And we know the total\nsize of the cycle is constant. So each of these, every time\nwe turn one of these to false,",
    "start": "4156529",
    "end": "4161810"
  },
  {
    "text": "we lose one point. And there's only a\nconstant number of these, so it's actually-- the\nconstant is only 27.",
    "start": "4161810",
    "end": "4167870"
  },
  {
    "text": "Or 29, sorry. 29. It's a little weird to\nget used to L reductions.",
    "start": "4167870",
    "end": "4172908"
  },
  {
    "text": "I'm still getting used to them. But as you can see,\nit's pretty powerful. You can do a lot,\nand it's just OK.",
    "start": "4172909",
    "end": "4180889"
  },
  {
    "text": "You definitely\nhave to be careful. In general, you want things\nto have bounded degree. That makes things\nreally helpful.",
    "start": "4180890",
    "end": "4186359"
  },
  {
    "text": "That's why I'm telling you\nabout these two problems. ",
    "start": "4186359",
    "end": "4195873"
  },
  {
    "text": "What next. Let's just continue--\nlet me at least mention, in case I run out\nof time, max not all",
    "start": "4195873",
    "end": "4202590"
  },
  {
    "text": "equal 3SAT, also hard, positive\n1 in 3SAT, even one in E3SAT.",
    "start": "4202590",
    "end": "4211310"
  },
  {
    "text": "Also, APX hard. APX complete. So those are good friends from\n3SAT land to carry over here.",
    "start": "4211310",
    "end": "4218820"
  },
  {
    "text": "But let's prove some-- and I\nwill eventually prove those. Let's prove some\nother fun problems.",
    "start": "4218820",
    "end": "4227690"
  },
  {
    "text": "Next one is independent set. Now I have to be a\nlittle bit careful here.",
    "start": "4227690",
    "end": "4234170"
  },
  {
    "text": "Independent set is really\nreally, really hard. But an interesting special\ncase is bounded degree",
    "start": "4234170",
    "end": "4242630"
  },
  {
    "text": "independent set. So that's what I'll\ntalk about next. ",
    "start": "4242630",
    "end": "4257800"
  },
  {
    "text": "I think I'm going to prove max\ndegree for independent set, although it's known that\nmax degree 3 is hard also.",
    "start": "4257800",
    "end": "4272110"
  },
  {
    "text": "So constant degree independent\nset is actually APX complete.",
    "start": "4272110",
    "end": "4278869"
  },
  {
    "text": "So there is a constant\nfactor approximation, which is take any maximal\nindependent set-- just",
    "start": "4278870",
    "end": "4286080"
  },
  {
    "text": "keep adding vertices\nuntil you can't anymore. That will be within a factor of\nthis of optimal, you can show.",
    "start": "4286080",
    "end": "4294100"
  },
  {
    "text": "That's pretty clear. So that puts it in APX.",
    "start": "4294100",
    "end": "4300989"
  },
  {
    "text": "And furthermore, we\nclaim that's [INAUDIBLE]. So there's a constant\nfactor, and there's also a constant factor\nin approximability.",
    "start": "4300990",
    "end": "4307540"
  },
  {
    "text": "Some constant you\ncannot go below. And the proof is this,\nalthough it's a little bit--",
    "start": "4307540",
    "end": "4314220"
  },
  {
    "text": "so it's a reduction from,\nlet's say, the one we just did, max 3SAT-3.",
    "start": "4314220",
    "end": "4320874"
  },
  {
    "text": "And it's going to be\na strict reduction. We're not going to lose\nanything if I did things right.",
    "start": "4320874",
    "end": "4326190"
  },
  {
    "text": "Now in fact-- so I drew\nhere six recurrences of xi, but there's really\nonly three of them. But the idea is\ncomplete bipartite graph",
    "start": "4326190",
    "end": "4332620"
  },
  {
    "text": "between the positive\ninstances of xi and the negative instances. And then these are going\nto be plugged in directly",
    "start": "4332620",
    "end": "4338520"
  },
  {
    "text": "to the clause gadgets. These are the same variable. ",
    "start": "4338520",
    "end": "4344340"
  },
  {
    "text": "And so the idea is\neach of these was plugged into only one clause. So I need to make copies. I do this complete bipartite\ngraph between them.",
    "start": "4344340",
    "end": "4351310"
  },
  {
    "text": "And now we're trying to do\nmax independent set, which means whatever solution we find,\nit will be an independent set.",
    "start": "4351310",
    "end": "4360470"
  },
  {
    "text": "That's cool. There's no slack in\nindependence here. It's just about\nhow many we choose. Question? AUDIENCE: What is\nan independent set?",
    "start": "4360470",
    "end": "4366190"
  },
  {
    "text": "PROFESSOR:\nIndependence set is you want to choose a set\nof variables that have no edges between them. Sorry, instead of vertices,\nthey have no edges between them.",
    "start": "4366190",
    "end": "4372990"
  },
  {
    "text": "So that means that if I choose\nany one of the blue nodes here, I can't choose any of the\nred nodes, and vice versa.",
    "start": "4372990",
    "end": "4379199"
  },
  {
    "text": "So I may not be able to\nchoose all of the blue or all of the red, but\nthat's how it goes. Now if we look at a clause,\nthere's-- in this case,",
    "start": "4379200",
    "end": "4386440"
  },
  {
    "text": "we have to actually handle\nthe case of clauses of size 2 and clauses of size 3.",
    "start": "4386440",
    "end": "4391535"
  },
  {
    "text": "If you have a clause\nof size 3, you'd just build a triangle on them. And the idea is only one\nof those can be chosen.",
    "start": "4391535",
    "end": "4399239"
  },
  {
    "text": "But it could be zero get chosen,\nbecause you might be screwed. Maybe you chose a\nred xi, and then you",
    "start": "4399240",
    "end": "4404749"
  },
  {
    "text": "won't be able to\nchoose this blue xi. Maybe you chose a red xj. Maybe you chose a blue xk.",
    "start": "4404749",
    "end": "4409980"
  },
  {
    "text": "In that case, you\nwon't be able to choose any of these vertices. But if at least one\nof these [INAUDIBLE] is true, if you chose--\nif you're either",
    "start": "4409980",
    "end": "4418070"
  },
  {
    "text": "choosing the blue xi's or the\nblue xj's or the red xk's, then in fact you get one\npoint for each clause.",
    "start": "4418070",
    "end": "4424139"
  },
  {
    "text": "And in general, the\nnumber of points you get, the number of things\nyou'll be able to put into your independent\nset, is exactly",
    "start": "4424140",
    "end": "4429251"
  },
  {
    "text": "the number of clauses\nyou'll be able to satisfy. And just by looking at whether\nany of the blue xi's are true,",
    "start": "4429251",
    "end": "4437230"
  },
  {
    "text": "then you set xi to true, looking\nat whether any of the red xi's are set-- are chosen\nin the independent set,",
    "start": "4437230",
    "end": "4443310"
  },
  {
    "text": "then you set xi to false. That will recover\nthe assignment, and it'll have exactly the same\ncost as the independent set",
    "start": "4443310",
    "end": "4449370"
  },
  {
    "text": "size. Number of clauses you satisfy\nwill be exactly the number of independent set size.",
    "start": "4449370",
    "end": "4454895"
  },
  {
    "text": " And similarly, for\na clause of size 2.",
    "start": "4454895",
    "end": "4461120"
  },
  {
    "text": "So that's cool. Independent set is really easy\nto reduce from max 3SAT-3.",
    "start": "4461120",
    "end": "4467300"
  },
  {
    "text": "In fact, it would work\nfor max 3SAT constant. But if you do a max at\n3SAT-3, there's only three of these guys.",
    "start": "4467300",
    "end": "4473270"
  },
  {
    "text": "Then I think the biggest\ndegree you get is 4. This guy maybe is\nattached to two things,",
    "start": "4473270",
    "end": "4478697"
  },
  {
    "text": "and then also to two\nthings over here.  Great.",
    "start": "4478697",
    "end": "4486250"
  },
  {
    "text": "Next problem is vertex cover.",
    "start": "4486250",
    "end": "4491680"
  },
  {
    "text": "So this is a funny one.  So let's do a constant\ndegree vertex cover.",
    "start": "4491680",
    "end": "4499395"
  },
  {
    "text": "In general, there's a two\napproximation for vertex cover. So we don't need the constant\ndegree to be an APX, but.",
    "start": "4499395",
    "end": "4507076"
  },
  {
    "text": "This is also APX complete. And it's kind of identical\nto the independent set",
    "start": "4507076",
    "end": "4513230"
  },
  {
    "text": "in a funny way, which\nis for any graph, if you look at a vertex\ncover, its complement",
    "start": "4513230",
    "end": "4522360"
  },
  {
    "text": "is an independent set. If you look at any\nindependent set, its complement is\na vertex cover.",
    "start": "4522360",
    "end": "4528909"
  },
  {
    "text": "Sorry, any maximal independent\nset, its complement is a vertex cover.",
    "start": "4528910",
    "end": "4534239"
  },
  {
    "text": "So they're kind of\nduel in that, if you look at the size\nof a vertex cover plus size of a maximal\nindependent set,",
    "start": "4534240",
    "end": "4542470"
  },
  {
    "text": "it will always equal\nthe number of vertices. So maximizing this is the\nsame as minimizing this.",
    "start": "4542470",
    "end": "4550040"
  },
  {
    "text": "But approximating this\nis not necessarily the same as approximating this. One's a maximization problem,\none's a minimization problem.",
    "start": "4550040",
    "end": "4556740"
  },
  {
    "text": "But it's still an L reduction\nfor bounded degree graphs,",
    "start": "4556740",
    "end": "4563290"
  },
  {
    "text": "because if you have\ndegree at most delta, there's always an independent\nset size of at least N",
    "start": "4563290",
    "end": "4570219"
  },
  {
    "text": "over delta. And there's always a\nvertex cover of size N. So they're within constant\nfactors of each other.",
    "start": "4570220",
    "end": "4576940"
  },
  {
    "text": "In fact, these are both always\ntheta the number of vertices.",
    "start": "4576940",
    "end": "4583699"
  },
  {
    "text": "OK? So the reduction is you give me\nan instance of independent set, I give you that exact same\ninstance to vertex cover.",
    "start": "4583700",
    "end": "4591920"
  },
  {
    "text": "And then-- so f is trivial. G takes the complement.",
    "start": "4591920",
    "end": "4597239"
  },
  {
    "text": "Whatever you had in\nthe vertex cover, you don't put it in\nthe independent set, and vice versa.",
    "start": "4597240",
    "end": "4603010"
  },
  {
    "text": "And then you just have to check\nthat this is an L reduction. So the first thing is the OPTs\nare within a constant factor of each other.",
    "start": "4603010",
    "end": "4608170"
  },
  {
    "text": "That's true, because they're\nboth within a constant factor of the number of vertices. And then you prove that\nthe additive gap is fixed.",
    "start": "4608170",
    "end": "4616430"
  },
  {
    "text": "And it's the same thing if you\ndecrement this accidentally, then you increment\nthis accidentally.",
    "start": "4616430",
    "end": "4622150"
  },
  {
    "text": "They're one for one. So this is kind of cool. It feels a little scary, but\nwe can convert a maximization",
    "start": "4622150",
    "end": "4628730"
  },
  {
    "text": "problem into a minimization\nproblem with L reductions. This would be very hard\nto even think about",
    "start": "4628730",
    "end": "4633940"
  },
  {
    "text": "in the other\nreduction types, which is one of the reasons L\nreductions are so successful,",
    "start": "4633940",
    "end": "4638950"
  },
  {
    "text": "I think.  That was vertex cover.",
    "start": "4638950",
    "end": "4644430"
  },
  {
    "text": "We can do one more. ",
    "start": "4644430",
    "end": "4649940"
  },
  {
    "text": "OK, really easy. Dominating set. ",
    "start": "4649940",
    "end": "4656100"
  },
  {
    "text": "Remember, dominating\nset-- with vertex cover, when you put a\nvertex in your cover, you cover all the\nedges incident to it,",
    "start": "4656100",
    "end": "4661860"
  },
  {
    "text": "and you want to\ncover all the edges. Dominating set, when\nyou put a vertex in, you cover all the\nneighboring vertices.",
    "start": "4661860",
    "end": "4666980"
  },
  {
    "text": "You want to cover all vertices. So I'm going to reduce\nfrom vertex cover. If you have an edge,\nwhat you do is convert it",
    "start": "4666980",
    "end": "4675460"
  },
  {
    "text": "into a path of length\n2 plus that edge. So then you know that, if\nthis is in the dominating set,",
    "start": "4675460",
    "end": "4683580"
  },
  {
    "text": "you can just move it\nover to [INAUDIBLE] or w. It will cover all the things\nit could cover before,",
    "start": "4683580",
    "end": "4689260"
  },
  {
    "text": "and maybe even more. So then in the optimal\nsolution over here, you'd never need to choose\none of these vertices, which",
    "start": "4689260",
    "end": "4695385"
  },
  {
    "text": "means we can assume that on the\noriginal vertices, which means you are just solving\nvertex cover,",
    "start": "4695385",
    "end": "4701099"
  },
  {
    "text": "because covering that is the\nsame as covering that edge. Good.",
    "start": "4701100",
    "end": "4706344"
  },
  {
    "text": "I think that's good for now. We'll do a bunch more\nreductions next time. ",
    "start": "4706344",
    "end": "4714719"
  }
]
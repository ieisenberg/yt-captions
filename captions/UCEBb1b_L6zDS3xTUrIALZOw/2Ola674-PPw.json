[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "5770"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation, or to\nview additional materials",
    "start": "5770",
    "end": "13440"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13440",
    "end": "20410"
  },
  {
    "start": "20000",
    "end": "404000"
  },
  {
    "text": "PROFESSOR STRANG:\nActually, two things to say about eigenvalues. One is about matrices\nin general and then",
    "start": "20410",
    "end": "28460"
  },
  {
    "text": "the second is to focus\non our favorites, those second derivatives\nand second differences.",
    "start": "28460",
    "end": "37610"
  },
  {
    "text": "There's a lot to say\nabout eigenvalues but then we'll have\nthe main ideas.",
    "start": "37610",
    "end": "42809"
  },
  {
    "text": "So the central idea\nof course is to find these special directions and\nwe expect to find n directions,",
    "start": "42810",
    "end": "51970"
  },
  {
    "text": "n eigenvectors y where\nthis n by n matrix is acting like a number in\neach of those directions.",
    "start": "51970",
    "end": "63320"
  },
  {
    "text": "So we have this for n\ndifferent y's and each one has its own eigenvalue lambda.",
    "start": "63320",
    "end": "69370"
  },
  {
    "text": "And of course the\neig command in MATLAB will find the y's\nand the lambdas.",
    "start": "69370",
    "end": "75869"
  },
  {
    "text": "So it finds the y's and\nthe lambdas in a matrix.",
    "start": "75870",
    "end": "81320"
  },
  {
    "text": "So that's what I'm going\nto do now, straightforward. Any time I have n vectors, so\nI have n of these y's, I've",
    "start": "81320",
    "end": "88159"
  },
  {
    "text": "n y's and n lambdas. Well, if you give\nme n vectors, I",
    "start": "88160",
    "end": "95150"
  },
  {
    "text": "put them into the\ncolumns of a matrix, almost without thinking. So can I just do that?",
    "start": "95150",
    "end": "101340"
  },
  {
    "text": "So there is y_1, the\nfirst eigenvector. That's y_2 to y_n.",
    "start": "101340",
    "end": "107240"
  },
  {
    "text": "Okay, that's my\neigenvector matrix. Often I call it S. So\nI'll stick with that.",
    "start": "107240",
    "end": "114460"
  },
  {
    "text": "S will be the\neigenvector matrix.",
    "start": "114460",
    "end": "119780"
  },
  {
    "text": "Since these are\neigenvectors I'm going to multiply that\nmatrix by A. That",
    "start": "119780",
    "end": "125570"
  },
  {
    "text": "should bring out the key point. I'm just going to repeat\nthis, which is one at a time,",
    "start": "125570",
    "end": "135710"
  },
  {
    "text": "by doing them all that once. So what happens if I multiply\na matrix by a bunch of columns?",
    "start": "135710",
    "end": "143350"
  },
  {
    "text": "Matrix multiplication\nis wonderful. It does the right thing. It multiplies A times\nthe first column.",
    "start": "143350",
    "end": "150540"
  },
  {
    "text": "So let's put that there. A times the first column along\nto A times the last column.",
    "start": "150540",
    "end": "157230"
  },
  {
    "text": "Just column by column. But now we recognize these. They're special y's.",
    "start": "157230",
    "end": "163590"
  },
  {
    "text": "They're special because\nthey're eigenvectors. So this is lambda_1*y_1 along\nto that column is lambda_n*y_n.",
    "start": "163590",
    "end": "173440"
  },
  {
    "text": "Right? Now I've used the fact that\nthey were eigenvectors.",
    "start": "173440",
    "end": "179280"
  },
  {
    "text": "And now, one final neat step\nof matrix multiplication is to factor out this same\neigenvector matrix again",
    "start": "179280",
    "end": "190010"
  },
  {
    "text": "and realize, and\nI'll look at it, that it's being multiplied\nby this diagonal, that's",
    "start": "190010",
    "end": "197460"
  },
  {
    "text": "now a diagonal matrix\nof eigenvalues.",
    "start": "197460",
    "end": "203230"
  },
  {
    "text": "So let's just look at\nthat very last step here. Here I had the first\ncolumn was lambda_1*y_1.",
    "start": "203230",
    "end": "209120"
  },
  {
    "text": " I just want to see,\ndid I get that right?",
    "start": "209120",
    "end": "215880"
  },
  {
    "text": "If I'm looking at\nthe first column where that lambda_1 is sitting,\nit's going to multiply y_1",
    "start": "215880",
    "end": "222170"
  },
  {
    "text": "and it'll be all zeroes\nbelow so I'll have none of the other eigenvectors.",
    "start": "222170",
    "end": "227860"
  },
  {
    "text": "So I'll have lambda_1*y_1,\njust what I want. Got a little squeezed near\nthe end there, but so let",
    "start": "227860",
    "end": "236010"
  },
  {
    "text": "me write above. The result is just A times\nthis eigenvector matrix",
    "start": "236010",
    "end": "243540"
  },
  {
    "text": "that I'm going to\ncall S equals what?",
    "start": "243540",
    "end": "250040"
  },
  {
    "text": "This is Ay=lambda*y\nfor all n at once.",
    "start": "250040",
    "end": "255219"
  },
  {
    "text": "A times S is, what\nhave I got here? What's this? That's S. And what's\nthe other guy?",
    "start": "255220",
    "end": "262980"
  },
  {
    "text": "That's the eigenvalue matrix. So it's just got n numbers. They automatically\ngo on the diagonal",
    "start": "262980",
    "end": "269880"
  },
  {
    "text": "and it gets called\ncapital Lambda. Capital Lambda for the matrix,\nlittle lambda for the numbers.",
    "start": "269880",
    "end": "277340"
  },
  {
    "text": "So this is n, this\nis all n at once.",
    "start": "277340",
    "end": "282630"
  },
  {
    "text": "Straightforward. Now I'm going to\nassume that I've",
    "start": "282630",
    "end": "288450"
  },
  {
    "text": "got these n eigenvectors,\nthat I've been able to find n independent directions.",
    "start": "288450",
    "end": "295130"
  },
  {
    "text": "And almost always, you can. For every symmetric matrix\nyou automatically can.",
    "start": "295130",
    "end": "301379"
  },
  {
    "text": "So these y's are\nindependent directions. If those are the\ncolumns of a matrix,",
    "start": "301380",
    "end": "309530"
  },
  {
    "text": "yeah, here's a key\nquestion about matrices. What can I say\nabout this matrix S",
    "start": "309530",
    "end": "315840"
  },
  {
    "text": "if its n columns\nare independent? Whatever that, you\nknow, we haven't focused in careful detail,\nbut we have an idea.",
    "start": "315840",
    "end": "323830"
  },
  {
    "text": "That means sort of none of them\nare combinations of the others. We really have n\nseparate directions.",
    "start": "323830",
    "end": "330890"
  },
  {
    "text": "Then that matrix is? Invertible.",
    "start": "330890",
    "end": "335940"
  },
  {
    "text": "A matrix that's got n\ncolumns, independent, that's what we're hoping for.",
    "start": "335940",
    "end": "341010"
  },
  {
    "text": "That matrix has an inverse. We can produce, well all the\ngood facts about matrices.",
    "start": "341010",
    "end": "347080"
  },
  {
    "text": "This is a square matrix. So I can invert it if you like. And I can write A as S lambda.",
    "start": "347080",
    "end": "353920"
  },
  {
    "text": "I'm multiplying on the\nright by this S inverse. And there I have the\ndiagonalization of a matrix.",
    "start": "353920",
    "end": "363620"
  },
  {
    "text": "The matrix has\nbeen diagonalized. And what does that mean? Well this is, of course the\ndiagonal that we're headed for.",
    "start": "363620",
    "end": "373100"
  },
  {
    "text": "And what it means is that\nif I look at my matrix and I separate out the different\neigendirections, I could say,",
    "start": "373100",
    "end": "383150"
  },
  {
    "text": "that the matrix in\nthose directions is just this diagonal matrix.",
    "start": "383150",
    "end": "388750"
  },
  {
    "text": "So that's a short\nway of saying it.",
    "start": "388750",
    "end": "396400"
  },
  {
    "text": "Let me just carry\none step further. What would A squared be?",
    "start": "396400",
    "end": "404650"
  },
  {
    "text": "Well now that I have it in this\ncool form, S*lambda*S inverse,",
    "start": "404650",
    "end": "410620"
  },
  {
    "text": "I would multiply two of those\ntogether and what would I learn?",
    "start": "410620",
    "end": "415650"
  },
  {
    "text": "If I do that multiplication\nwhat comes out? First an S from here.",
    "start": "415650",
    "end": "422330"
  },
  {
    "text": "And then what? Lambda squared. Why lambda squared?",
    "start": "422330",
    "end": "427780"
  },
  {
    "text": "Because in the middle is\nthe S S inverse that's giving the identity matrix.",
    "start": "427780",
    "end": "434250"
  },
  {
    "text": "So then the lambda\nmultiplies the lambda and now here is S inverse. Well A squared is S*lambda\nsquared*S inverse.",
    "start": "434250",
    "end": "442860"
  },
  {
    "text": "What does that tell me in words? That tells me that the\neigenvectors of A squared are?",
    "start": "442860",
    "end": "451919"
  },
  {
    "text": "The same. As for A. And it tells me that\nthe eigenvalues of A squared",
    "start": "451920",
    "end": "457800"
  },
  {
    "text": "are? The squares. So I could do this.",
    "start": "457800",
    "end": "463650"
  },
  {
    "text": "Maybe I did it\nbefore, one at a time. Ay=lambda*y, multiply again by\nA. A squared*y is lambda*Ay,",
    "start": "463650",
    "end": "473760"
  },
  {
    "text": "but Ay is lambda*y so I'm\nup to lambda squared*y.",
    "start": "473760",
    "end": "479720"
  },
  {
    "text": "You should just see\nthat when you've got these directions then\nyour matrix is really simple.",
    "start": "479720",
    "end": "486460"
  },
  {
    "text": "Effectively it's\na diagonal matrix in these good directions.",
    "start": "486460",
    "end": "491530"
  },
  {
    "text": "So that just shows one way\nof seeing-- And of course",
    "start": "491530",
    "end": "497280"
  },
  {
    "text": "what about A inverse? We might as well\nmention A inverse. Suppose A is invertible.",
    "start": "497280",
    "end": "504539"
  },
  {
    "text": "Then what do I learn\nabout A inverse? Can I just invert that?",
    "start": "504540",
    "end": "512380"
  },
  {
    "text": "I'm just playing\nwith that formula, so you'll kind of,\nlike, get handy with it.",
    "start": "512380",
    "end": "519800"
  },
  {
    "text": "What would the inverse\nbe if I have three things in a row multiplied together?",
    "start": "519800",
    "end": "525330"
  },
  {
    "text": "What's the inverse? So I'm going to take the\ninverses in the opposite order,",
    "start": "525330",
    "end": "531480"
  },
  {
    "text": "right? So the inverse of\nthat will come first. So what's that?",
    "start": "531480",
    "end": "538640"
  },
  {
    "text": "Just S. The lambda\nin the middle gets inverted and then\nthe S at the left,",
    "start": "538640",
    "end": "546120"
  },
  {
    "text": "its inverse comes at the right. Well what do I learn from that?",
    "start": "546120",
    "end": "553190"
  },
  {
    "text": "I learn that the eigenvector\nmatrix for A inverse is?",
    "start": "553190",
    "end": "559820"
  },
  {
    "text": "Same thing, again. Same. Let me put just \"Same\". What's the eigenvalue\nmatrix for A inverse?",
    "start": "559820",
    "end": "571860"
  },
  {
    "text": "It's the inverse of this guy,\nso what does it look like?",
    "start": "571860",
    "end": "577070"
  },
  {
    "text": "It's got one over lambdas. That's all it says.",
    "start": "577070",
    "end": "582720"
  },
  {
    "text": "The eigenvalues for\nA inverse are just one over the eigenvalues for A.",
    "start": "582720",
    "end": "589459"
  },
  {
    "text": "If that is so, and it can't\nbe difficult, we could again, we could prove it sort\nof like, one at a time.",
    "start": "589460",
    "end": "601380"
  },
  {
    "text": "This is my starting\npoint, always. How would I get to A inverse\nnow and recover this fact",
    "start": "601380",
    "end": "607610"
  },
  {
    "text": "that the eigenvalues for the\ninverse, just turn them up.",
    "start": "607610",
    "end": "613510"
  },
  {
    "text": "If A has an eigenvalue\nseven, A inverse will have an eigenvalue 1/7.",
    "start": "613510",
    "end": "620700"
  },
  {
    "text": "What do I do? Usually multiply both sides\nby something sensible.",
    "start": "620700",
    "end": "626700"
  },
  {
    "text": "Right? What shall I multiply\nboth sides by? A inverse sounds like\na good idea, right.",
    "start": "626700",
    "end": "634990"
  },
  {
    "text": "So I'm multiplying both\nsides by A inverse, so that just leaves y and\nhere is that number, here",
    "start": "634990",
    "end": "640370"
  },
  {
    "text": "is A inverse times y. Well, maybe I should\ndo one more thing.",
    "start": "640370",
    "end": "646529"
  },
  {
    "text": "What else shall I do? Divide by lambda.",
    "start": "646530",
    "end": "652129"
  },
  {
    "text": "Take that number lambda and\nput it over here as one lambda. Well, just exactly\nwhat we're looking for.",
    "start": "652130",
    "end": "660030"
  },
  {
    "text": "The same y has A\ninverse, the same y as an eigenvector of A\ninverse and the eigenvalue",
    "start": "660030",
    "end": "668209"
  },
  {
    "text": "is one over lambda. Oh, and of course,\nI should have said",
    "start": "668210",
    "end": "673660"
  },
  {
    "text": "before I inverted\nanything, what should I have said about the lambdas?",
    "start": "673660",
    "end": "679920"
  },
  {
    "text": "Not zero. Right? A zero eigenvalue is a signal\nthe matrix isn't invertible.",
    "start": "679920",
    "end": "688870"
  },
  {
    "text": "So that's perfect test. If the matrix is invertible, all\nits eigenvalues are not zero.",
    "start": "688870",
    "end": "697460"
  },
  {
    "text": "If it's singular, it's\ngot a zero eigenvalue. If a matrix is singular,\nthen Ay would be 0y for some,",
    "start": "697460",
    "end": "707060"
  },
  {
    "text": "there'd be a vector\nthat that matrix kills. If A is not invertible,\nthere's a reason for it.",
    "start": "707060",
    "end": "712570"
  },
  {
    "text": "It's because it takes\nsome vector to zero, and of course, you can't\nbring it back to life.",
    "start": "712570",
    "end": "721579"
  },
  {
    "text": "So shall I just\nput that up here? Lambda=0 would tell me I\nhave a singular matrix.",
    "start": "721580",
    "end": "728290"
  },
  {
    "text": "All lambda not equal\nzero would tell me I have an invertible matrix.",
    "start": "728290",
    "end": "737510"
  },
  {
    "text": "These are straightforward facts. It's taken down in this row\nand it's just really handy",
    "start": "737510",
    "end": "745310"
  },
  {
    "text": "to have up here.",
    "start": "745310",
    "end": "750690"
  },
  {
    "text": "Well now I'm ready to move\ntoward the specific matrices, our favorites. Now, those are symmetric.",
    "start": "750690",
    "end": "758190"
  },
  {
    "text": "So maybe before I\nleave this picture, we better recall what is special\nwhen the matrix is symmetric.",
    "start": "758190",
    "end": "766500"
  },
  {
    "text": "So that's going to\nbe the next thing. So if A is symmetric I get\nsome extra good things.",
    "start": "766500",
    "end": "773199"
  },
  {
    "start": "769000",
    "end": "904000"
  },
  {
    "text": "So let me take instead\nof A, I'll use K.",
    "start": "773200",
    "end": "778710"
  },
  {
    "text": "So that'll be my letter\nfor the best matrices. So symmetric.",
    "start": "778710",
    "end": "787460"
  },
  {
    "text": "So now what's the deal\nwith symmetric matrices? The eigenvalues, the lambdas.",
    "start": "787460",
    "end": "792930"
  },
  {
    "text": "I'll just call them the\nlambdas and the y's. The lambdas are, do you\nremember from last time?",
    "start": "792930",
    "end": "800940"
  },
  {
    "text": "If I have a symmetric matrix,\nthe eigenvalues are all?",
    "start": "800940",
    "end": "805960"
  },
  {
    "text": "Anybody remember? They're all real numbers. You can never run into\ncomplex eigenvalues",
    "start": "805960",
    "end": "812210"
  },
  {
    "text": "if you start with\na symmetric matrix. We didn't prove that but it's\njust a few steps like those.",
    "start": "812210",
    "end": "819250"
  },
  {
    "text": "And what about, most\nimportant, what about the y's? The eigenvectors. They are, or can be chosen\nto be, or whatever, anybody",
    "start": "819250",
    "end": "828940"
  },
  {
    "text": "remember that fact? These are, like,\nthe golden facts. Every sort of bunch of\nmatrices reveals itself",
    "start": "828940",
    "end": "840980"
  },
  {
    "text": "through what its\neigenvalues are like and what its\neigenvectors are like. And the most important class\nis symmetric and that reveals",
    "start": "840980",
    "end": "848589"
  },
  {
    "text": "itself through real\neigenvalues and...? Orthogonal, good.",
    "start": "848590",
    "end": "853990"
  },
  {
    "text": "Orthogonal eigenvectors,\northogonal. And in fact, since\nI'm an eigenvector,",
    "start": "853990",
    "end": "863580"
  },
  {
    "text": "I can adjust its\nlength as I like. Right?",
    "start": "863580",
    "end": "869380"
  },
  {
    "text": "If y is an eigenvector,\n11y is an eigenvector because I would just\nmultiply both sides by 11.",
    "start": "869380",
    "end": "875660"
  },
  {
    "text": "That whole line of eigenvectors\nis getting stretched by lambda.",
    "start": "875660",
    "end": "880860"
  },
  {
    "text": "So what I want to do is\nmake them unit vectors.",
    "start": "880860",
    "end": "885970"
  },
  {
    "text": "MATLAB will\nautomatically produce, eig would automatically\ngive you vectors that",
    "start": "885970",
    "end": "893100"
  },
  {
    "text": "have been normalized to unit.",
    "start": "893100",
    "end": "900740"
  },
  {
    "text": "Here's something good. So what does orthogonal mean?",
    "start": "900740",
    "end": "905820"
  },
  {
    "start": "904000",
    "end": "1744000"
  },
  {
    "text": "That means that one of them,\nthe dot product of one of them with another one is?",
    "start": "905820",
    "end": "914220"
  },
  {
    "text": "Now that's not, I didn't\ndo the dot product yet. What symbol do I have to\nwrite on left-hand side?",
    "start": "914220",
    "end": "921700"
  },
  {
    "text": "Well you could say,\njust put a dot. Of course. But dots are not cool, right?",
    "start": "921700",
    "end": "934320"
  },
  {
    "text": "So maybe I should say\ninner product, that's the more upper-class word.",
    "start": "934320",
    "end": "941990"
  },
  {
    "text": "But I want to use transpose. So it's the transpose. That's the dot product.",
    "start": "941990",
    "end": "947129"
  },
  {
    "text": "And that's the test\nfor perpendicular. So what's the answer then? I get a zero if i\nis different from j.",
    "start": "947130",
    "end": "955300"
  },
  {
    "text": "If I'm taking two\ndifferent eigenvectors and I take their dot product,\nthat's what you told me,",
    "start": "955300",
    "end": "961519"
  },
  {
    "text": "they're orthogonal. And now what if i equals j? If I'm taking the dot\nproduct with itself,",
    "start": "961520",
    "end": "969400"
  },
  {
    "text": "each eigenvector with itself. So what does the dot product\nof a vector with itself give?",
    "start": "969400",
    "end": "976920"
  },
  {
    "text": "It'll be one because I'm normal. Exactly. What it always gives,\nthe dot product",
    "start": "976920",
    "end": "983519"
  },
  {
    "text": "of a vector with\nitself, you just realize that that'll be\ny_1 squared, y_2 squared,",
    "start": "983520",
    "end": "988880"
  },
  {
    "text": "it'll be the length squared. And here we're making\nthe length to be one.",
    "start": "988880",
    "end": "996820"
  },
  {
    "text": "Well once again, if\nI write something down like this which\nis straightforward",
    "start": "996820",
    "end": "1003110"
  },
  {
    "text": "I want to express it\nas a matrix statement. So I want to multiply, it'll\ninvolve my good eigenvector",
    "start": "1003110",
    "end": "1014089"
  },
  {
    "text": "matrix. And this will be what?",
    "start": "1014090",
    "end": "1020250"
  },
  {
    "text": "I want to take all these\ndots products at once. I want to take the dot product\nof every y with every other y.",
    "start": "1020250",
    "end": "1027439"
  },
  {
    "text": "Well here you go. Just put these guys in the rows,\nnow that we see that it really",
    "start": "1027440",
    "end": "1034480"
  },
  {
    "text": "was the transpose\nmultiplying y, do you",
    "start": "1034480",
    "end": "1039500"
  },
  {
    "text": "see that that's just done it? In fact, you'll tell me\nwhat the answer is here. Don't shout it out, but let's\ntake it two or three entries",
    "start": "1039500",
    "end": "1048800"
  },
  {
    "text": "and then you can shout it out. So what's the (1,\n1) entry here of I",
    "start": "1048800",
    "end": "1057020"
  },
  {
    "text": "guess that's what\nwe called S. And now this would be its transpose. And what I'm saying is if I\ntake-- Yeah, this is important",
    "start": "1057020",
    "end": "1064950"
  },
  {
    "text": "because throughout\nthis course we're going to be taking A\ntranspose A, S transpose S,",
    "start": "1064950",
    "end": "1073250"
  },
  {
    "text": "Q transpose Q,\noften, often, often. So here we got the\nfirst time at it.",
    "start": "1073250",
    "end": "1078340"
  },
  {
    "text": "So why did I put a zero\nthere, because it's not it. What is it?",
    "start": "1078340",
    "end": "1083880"
  },
  {
    "text": "What is that first entry? One. Because that's the row times\nthe column, that's a one.",
    "start": "1083880",
    "end": "1091010"
  },
  {
    "text": "And what's the entry next to it? Zero. Right? y_1 dot product with\ny_2 is, we're saying, zero.",
    "start": "1091010",
    "end": "1099880"
  },
  {
    "text": "So what matrix have I got here? I've got the identity. Because y_2 with y_2 will\nput a one there and all",
    "start": "1099880",
    "end": "1108690"
  },
  {
    "text": "zeroes elsewhere. Zero, zero. And y_3 times y_3\nwill be the one.",
    "start": "1108690",
    "end": "1114760"
  },
  {
    "text": "I get the identity.",
    "start": "1114760",
    "end": "1120180"
  },
  {
    "text": "So this is for\nsymmetric matrices.",
    "start": "1120180",
    "end": "1128370"
  },
  {
    "text": "In general, we can't expect the\neigenvectors to be orthogonal.",
    "start": "1128370",
    "end": "1133520"
  },
  {
    "text": "It's these special\nones that are. But they're so important\nthat we notice.",
    "start": "1133520",
    "end": "1142640"
  },
  {
    "text": "Now so this is the\neigenvector matrix S and this is its transpose.",
    "start": "1142640",
    "end": "1149680"
  },
  {
    "text": "So I'm saying that for\na symmetric matrix, S transpose times S is I.\nWell that's pretty important.",
    "start": "1149680",
    "end": "1159500"
  },
  {
    "text": "In fact, that's\nimportant enough that I'm going to give an\nextra name to S,",
    "start": "1159500",
    "end": "1167530"
  },
  {
    "text": "the eigenvector matrix when it\ncomes from a symmetric matrix,",
    "start": "1167530",
    "end": "1174440"
  },
  {
    "text": "when it has a matrix with S\ntranspose times S equaling the identity is really\na good matrix to know.",
    "start": "1174440",
    "end": "1184620"
  },
  {
    "text": "So let's just focus\non those guys.",
    "start": "1184620",
    "end": "1190059"
  },
  {
    "text": "I can put that up here. So here's a matrix.",
    "start": "1190060",
    "end": "1197340"
  },
  {
    "text": "Can I introduce a\ndifferent letter than S? It just helps you to remember\nthat this remarkable property",
    "start": "1197340",
    "end": "1205540"
  },
  {
    "text": "is in force. That we've got it. So I'm going to call it--\nWhen K is a symmetric matrix,",
    "start": "1205540",
    "end": "1215309"
  },
  {
    "text": "I'll just repeat that,\nthen its eigenvector matrix",
    "start": "1215310",
    "end": "1224370"
  },
  {
    "text": "has this S transpose\ntimes S-- I'm",
    "start": "1224370",
    "end": "1229520"
  },
  {
    "text": "going to call it Q. I'm going\nto call the eigenvectors,",
    "start": "1229520",
    "end": "1235590"
  },
  {
    "text": "so for this special\nsituation, A times--",
    "start": "1235590",
    "end": "1244919"
  },
  {
    "text": "So I'm going to call the\neigenvector matrix Q. It's the S but it's worth\ngiving it this special notation",
    "start": "1244920",
    "end": "1254110"
  },
  {
    "text": "to remind us that this is, so\nQ is, an orthogonal matrix.",
    "start": "1254110",
    "end": "1262710"
  },
  {
    "text": "There's a name for matrices\nwith this important property. And there's a letter\nQ that everybody uses.",
    "start": "1262710",
    "end": "1269840"
  },
  {
    "text": "An orthogonal matrix. And what does that mean? Means just what we said,\nQ transpose times Q",
    "start": "1269840",
    "end": "1278530"
  },
  {
    "text": "is I. What I've done here\nis just giving a special,",
    "start": "1278530",
    "end": "1287970"
  },
  {
    "text": "introducing a special\nletter Q, a special name, orthogonal matrix for\nwhat we found in the good,",
    "start": "1287970",
    "end": "1296690"
  },
  {
    "text": "in this-- for eigenvectors\nof a symmetric matrix. And this tells me\none thing more.",
    "start": "1296690",
    "end": "1304289"
  },
  {
    "text": "Look what's happening here. Q transpose times Q is\ngiving the identity.",
    "start": "1304290",
    "end": "1311159"
  },
  {
    "text": "What does that tell me\nabout the inverse of Q? That tells me here some matrix\nis multiplying Q and giving I.",
    "start": "1311160",
    "end": "1320710"
  },
  {
    "text": "So what is this matrix? What's another name\nfor this Q transpose?",
    "start": "1320710",
    "end": "1326600"
  },
  {
    "text": "Is also Q inverse. Because that's what\ndefines the inverse matrix,",
    "start": "1326600",
    "end": "1332190"
  },
  {
    "text": "that times Q should give I.\nSo Q transpose is Q inverse.",
    "start": "1332190",
    "end": "1343580"
  },
  {
    "text": "I'm moving along here. Yes, please.",
    "start": "1343580",
    "end": "1353170"
  },
  {
    "text": "The question was, shouldn't I\ncall it an orthonormal matrix? The answer is yes, I should.",
    "start": "1353170",
    "end": "1360090"
  },
  {
    "text": "But nobody does. Dammit! So I'm stuck with that name.",
    "start": "1360090",
    "end": "1365340"
  },
  {
    "text": "But orthonormal is\nthe proper name. If you call it an\northonormal matrix, I'm happy because that's\nreally the right name",
    "start": "1365340",
    "end": "1373150"
  },
  {
    "text": "for that matrix, orthonormal. Because orthogonal would just\nmean orthogonal columns but",
    "start": "1373150",
    "end": "1378780"
  },
  {
    "text": "we've taken this\nextra little step to make all the lengths one. And then that gives us\nthis great property.",
    "start": "1378780",
    "end": "1387220"
  },
  {
    "text": "Q transpose is Q inverse. Orthogonal matrices\nare like rotations.",
    "start": "1387220",
    "end": "1394780"
  },
  {
    "text": "I better give an example\nof an orthogonal matrix. I'll do it right under here.",
    "start": "1394780",
    "end": "1400630"
  },
  {
    "text": "Here is an orthogonal matrix. So what's the point? It's supposed to be a unit\nvector in the first column",
    "start": "1400630",
    "end": "1408169"
  },
  {
    "text": "so I'll put\ncos(theta), sin(theta). And now what can go\nin the second column",
    "start": "1408170",
    "end": "1414389"
  },
  {
    "text": "of this orthogonal matrix? It's gotta be a unit vector\nagain because we've normalized",
    "start": "1414390",
    "end": "1420940"
  },
  {
    "text": "and it's gotta be, what's the\nconnection to the first column?",
    "start": "1420940",
    "end": "1426500"
  },
  {
    "text": "Orthogonal, gotta be orthogonal. So I just wanted to\nput something here that sum of squares\nis one, so I'll",
    "start": "1426500",
    "end": "1433980"
  },
  {
    "text": "think cos(theta) and\nsin(theta) again. But then I've got to\nflip them a little",
    "start": "1433980",
    "end": "1439429"
  },
  {
    "text": "to make it orthogonal to this. So if I put minus sin(theta)\nthere and plus cos(theta) there",
    "start": "1439430",
    "end": "1448040"
  },
  {
    "text": "that certainly has\nlength one, good. And the dot product, can you do\nthe dot product of that column",
    "start": "1448040",
    "end": "1454580"
  },
  {
    "text": "with that column? It's minus sine cosine,\nplus sine cosine, zero.",
    "start": "1454580",
    "end": "1460529"
  },
  {
    "text": "So there is a two\nby two, actually that's a fantastic\nbuilding block out of which",
    "start": "1460530",
    "end": "1466740"
  },
  {
    "text": "you could build many orthogonal\nmatrices of all sizes.",
    "start": "1466740",
    "end": "1472480"
  },
  {
    "text": "That's a rotation by theta.",
    "start": "1472480",
    "end": "1478390"
  },
  {
    "text": "That's a useful matrix to know. It takes every vector, swings\nit around by an angle theta.",
    "start": "1478390",
    "end": "1486500"
  },
  {
    "text": "What do I mean? I mean that Qx, Q times a\nvector x, rotates x by theta.",
    "start": "1486500",
    "end": "1493980"
  },
  {
    "text": "Let me put it. Qx rotates whatever vector x\nyou give it, you multiply by Q,",
    "start": "1493980",
    "end": "1501650"
  },
  {
    "text": "it rotates it around by theta,\nit doesn't change the length.",
    "start": "1501650",
    "end": "1507370"
  },
  {
    "text": "So that would be an eigenvector\nmatrix of a pretty typical two",
    "start": "1507370",
    "end": "1516246"
  },
  {
    "text": "by two. I see as I talk\nabout eigenvectors,",
    "start": "1516246",
    "end": "1522220"
  },
  {
    "text": "eigenvalues there's\nso much to say. Because everything you know\nabout a matrix shows up somehow",
    "start": "1522220",
    "end": "1529150"
  },
  {
    "text": "in its eigenvectors\nand eigenvalues and we're focusing\non symmetric guys.",
    "start": "1529150",
    "end": "1538029"
  },
  {
    "text": "What happens to this\nA=S*lambda*S inverse? Let's write that again. Now we've got K. It's\nS*lambda*S inverse like any good",
    "start": "1538030",
    "end": "1550679"
  },
  {
    "text": "diagonalization but now\nI'm giving S a new name,",
    "start": "1550680",
    "end": "1557630"
  },
  {
    "text": "which is what? Q. because when I give K,\nwhen I use that letter K",
    "start": "1557630",
    "end": "1564789"
  },
  {
    "text": "I'm thinking symmetric so\nI'm in this special situation of symmetric.",
    "start": "1564790",
    "end": "1570380"
  },
  {
    "text": "I have the lambda,\nthe eigenvalue matrix, and here I have Q inverse.",
    "start": "1570380",
    "end": "1576990"
  },
  {
    "text": "But there's another\nlittle way to write it and it's terrifically important\nin mechanics and dynamics,",
    "start": "1576990",
    "end": "1584970"
  },
  {
    "text": "everywhere. It's simple now. We know everything. Q lambda what?",
    "start": "1584970",
    "end": "1591880"
  },
  {
    "text": "Q transpose.",
    "start": "1591880",
    "end": "1597660"
  },
  {
    "text": "Do you see the\nbeauty of that form? That's called the principal\naxis theorem in mechanics.",
    "start": "1597660",
    "end": "1608190"
  },
  {
    "text": "It's called the spectral\ntheorem in mathematics. It's diagonalization, it's\nquantum mechanics, everything.",
    "start": "1608190",
    "end": "1615170"
  },
  {
    "text": "Any time you have\na symmetric matrix there's the wonderful\nstatement of how it breaks up",
    "start": "1615170",
    "end": "1624000"
  },
  {
    "text": "when you look at its\northonormal eigenvectors and its real eigenvalues.",
    "start": "1624000",
    "end": "1630159"
  },
  {
    "text": "Do you see that once again\nthe symmetry has reappeared",
    "start": "1630160",
    "end": "1637030"
  },
  {
    "text": "in the three factors? The symmetry has\nreappeared in the fact that this vector is the\ntranspose of this one.",
    "start": "1637030",
    "end": "1645740"
  },
  {
    "text": "We saw that for elimination\nwhen these were triangular.",
    "start": "1645740",
    "end": "1654320"
  },
  {
    "text": "That makes me remember what\nwe had in a different context,",
    "start": "1654320",
    "end": "1660759"
  },
  {
    "text": "in the elimination when things\nwere triangular we had K=L*D*L",
    "start": "1660760",
    "end": "1666400"
  },
  {
    "text": "transpose. I just squeezed that in to ask\nyou to sort of think of the two",
    "start": "1666400",
    "end": "1675430"
  },
  {
    "text": "as two wonderful pieces\nof linear algebra in such a perfect\nshorthand, perfect notation.",
    "start": "1675430",
    "end": "1684340"
  },
  {
    "text": "This was triangular\ntimes the pivot matrix times the upper triangular.",
    "start": "1684340",
    "end": "1690019"
  },
  {
    "text": "This is orthogonal times\nthe eigenvalue matrix times its transpose.",
    "start": "1690020",
    "end": "1697020"
  },
  {
    "text": "And the key point\nhere was triangular and the key point\nhere is orthogonal.",
    "start": "1697020",
    "end": "1708020"
  },
  {
    "text": "That took some time,\nbut it had to be done. This is the right\nway to understand.",
    "start": "1708020",
    "end": "1713440"
  },
  {
    "text": "That the central theme, it's a\nhighlight of a linear algebra course and we just\nwent straight to it.",
    "start": "1713440",
    "end": "1722140"
  },
  {
    "text": "And now what I wanted to do\nwas look now at the special K.",
    "start": "1722140",
    "end": "1730890"
  },
  {
    "text": "Oh, that's an awful pun.",
    "start": "1730890",
    "end": "1736980"
  },
  {
    "text": "The special matrices that we\nhave, so those are n by n.",
    "start": "1736980",
    "end": "1743850"
  },
  {
    "text": "And as I said last\ntime, usually it's not very likely that we\nfind all the eigenvalues",
    "start": "1743850",
    "end": "1750180"
  },
  {
    "text": "and eigenvectors of this family\nof bigger and bigger matrices.",
    "start": "1750180",
    "end": "1756780"
  },
  {
    "text": "So now I'm going to\nspecialize to my n by n matrix K equals\ntwos down the diagonal,",
    "start": "1756780",
    "end": "1764980"
  },
  {
    "text": "minus ones above and\nminus ones below.",
    "start": "1764980",
    "end": "1770320"
  },
  {
    "text": "What are the eigenvalues\nof that matrix and what are the eigenvectors?",
    "start": "1770320",
    "end": "1776370"
  },
  {
    "text": "How to tackle that? The best way is the way\nwe've done with the inverse",
    "start": "1776370",
    "end": "1784750"
  },
  {
    "text": "and other ways of\nunderstanding K, was to compare it with\nthe continuous problem.",
    "start": "1784750",
    "end": "1792270"
  },
  {
    "text": "So this is a big matrix\nwhich is a second difference matrix, fixed-fixed.",
    "start": "1792270",
    "end": "1799820"
  },
  {
    "text": "Everybody remembers that the\nboundary conditions associated with this are fixed-fixed.",
    "start": "1799820",
    "end": "1805790"
  },
  {
    "text": "I want to ask you to look at\nthe corresponding differential",
    "start": "1805790",
    "end": "1812340"
  },
  {
    "text": "equation. So you may not have\nthought about eigenvectors",
    "start": "1812340",
    "end": "1817530"
  },
  {
    "text": "of differential equations. And maybe I have to\ncall them eigenfunctions but the idea doesn't\nchange one bit.",
    "start": "1817530",
    "end": "1824210"
  },
  {
    "text": "So what shall I look at?",
    "start": "1824210",
    "end": "1829289"
  },
  {
    "text": "K corresponds to what? Continuous\ndifferential business,",
    "start": "1829290",
    "end": "1836770"
  },
  {
    "text": "what derivative, what? So I would like to\nlook at Ky=lambda*y.",
    "start": "1836770",
    "end": "1842750"
  },
  {
    "text": " I'm looking for\nthe y's and lambdas",
    "start": "1842750",
    "end": "1848390"
  },
  {
    "text": "and the way I'm going to\nget them is to look at,",
    "start": "1848390",
    "end": "1854510"
  },
  {
    "text": "what did you say it was? K, now I'm going to write down\na differential equation that's",
    "start": "1854510",
    "end": "1860950"
  },
  {
    "text": "like this but we'll\nsolve it quickly. So what will it be?",
    "start": "1860950",
    "end": "1867570"
  },
  {
    "text": "K is like, tell me again. Second derivative of y\nwith respect to x squared.",
    "start": "1867570",
    "end": "1877490"
  },
  {
    "text": "And there's one more thing\nyou have to remember. Minus.",
    "start": "1877490",
    "end": "1882610"
  },
  {
    "text": "And here we have lambda*y(x). ",
    "start": "1882610",
    "end": "1892240"
  },
  {
    "text": "That's an eigenvalue\nand an eigenfunction that we're looking at for\nthis differential equation.",
    "start": "1892240",
    "end": "1900660"
  },
  {
    "text": "Now there's another thing\nyou have to remember. And you'll know what it\nis and you'll tell me.",
    "start": "1900660",
    "end": "1908200"
  },
  {
    "text": "I could look for\nall the solutions. Well, let me\nmomentarily do that.",
    "start": "1908200",
    "end": "1913770"
  },
  {
    "text": "What functions have minus\nthe second derivative is",
    "start": "1913770",
    "end": "1920650"
  },
  {
    "text": "a multiple of the function? Can you just tell me a few? Sine and cosine.",
    "start": "1920650",
    "end": "1927250"
  },
  {
    "text": "I mean this is a fantastic\neigenvalue problem because its solutions\nare sines and cosines.",
    "start": "1927250",
    "end": "1938210"
  },
  {
    "text": "And of course we could combine\nthem into exponentials. We could have sine(omega*x)\nor cos(omega*x) or we could",
    "start": "1938210",
    "end": "1949809"
  },
  {
    "text": "combine those into\ne^(i*omega*x), would be a combination of\nthose, or e^(-i*omega*x).",
    "start": "1949810",
    "end": "1956790"
  },
  {
    "text": " Those are combinations of\nthese, so those are not new.",
    "start": "1956790",
    "end": "1965400"
  },
  {
    "start": "1964000",
    "end": "2454000"
  },
  {
    "text": "We've gotten lots\nof eigenfunctions. Oh, for every frequency omega\nthis solves the equation.",
    "start": "1965400",
    "end": "1971600"
  },
  {
    "text": "What's the eigenvalue? If you guess the eigenfunction\nyou've got the eigenvalue just",
    "start": "1971600",
    "end": "1977710"
  },
  {
    "text": "by seeing what happens. So what would the eigenvalue be?",
    "start": "1977710",
    "end": "1985039"
  },
  {
    "text": "Tell me again. Omega squared. Because I take the second\nderivative of the sine, that'll",
    "start": "1985040",
    "end": "1991039"
  },
  {
    "text": "give me the cosine back to the\nsine, omega squared comes out, omega comes out twice.",
    "start": "1991040",
    "end": "1997160"
  },
  {
    "text": "Comes out with a minus\nsign from the cosine and that minus sign is\njust right to make it plus.",
    "start": "1997160",
    "end": "2005480"
  },
  {
    "text": "Lambda is omega squared. So omega squared. All the way of course.",
    "start": "2005480",
    "end": "2011679"
  },
  {
    "text": "Those are the eigenvalues.",
    "start": "2011680",
    "end": "2018080"
  },
  {
    "text": "All our differential examples\nhad something more than just the differential equation.",
    "start": "2018080",
    "end": "2023530"
  },
  {
    "text": "What's the additional thing that\na differential equation comes with?",
    "start": "2023530",
    "end": "2029690"
  },
  {
    "text": "Boundary conditions. With boundary conditions. Otherwise we got too many.",
    "start": "2029690",
    "end": "2035360"
  },
  {
    "text": "I mean we don't want\nall of these guys. What boundary conditions?",
    "start": "2035360",
    "end": "2040580"
  },
  {
    "text": "If we're thinking about\nK, our boundary conditions should be fixed and fixed.",
    "start": "2040580",
    "end": "2049530"
  },
  {
    "text": "So that's the full problem. This is part of the problem\nnot just an afterthought.",
    "start": "2049530",
    "end": "2057059"
  },
  {
    "text": "Now these conditions,\nthat will be perfect. Instead of having all\nthese sines and cosines",
    "start": "2057060",
    "end": "2065419"
  },
  {
    "text": "we're going to narrow down\nto a family that satisfies",
    "start": "2065420",
    "end": "2073740"
  },
  {
    "text": "the boundary conditions. First boundary condition is\nit has to be zero at x=0.",
    "start": "2073740",
    "end": "2080480"
  },
  {
    "text": "What does that eliminate now? Cosines are gone,\nkeeps the sines.",
    "start": "2080480",
    "end": "2085770"
  },
  {
    "text": "Cosines are gone by that\nfirst boundary condition. These are guys that are left.",
    "start": "2085770",
    "end": "2092389"
  },
  {
    "text": "I won't deal with these at this\npoint because I'm down to sines",
    "start": "2092390",
    "end": "2099299"
  },
  {
    "text": "already from one\nboundary condition. And now, the other\nboundary condition.",
    "start": "2099300",
    "end": "2106820"
  },
  {
    "text": "The other boundary\ncondition has to at x=1,",
    "start": "2106820",
    "end": "2112620"
  },
  {
    "text": "if it's going to work\nsin(omega*x) has to be? Nope, what do I put now?\nsin(omega), right? x is one.",
    "start": "2112620",
    "end": "2122470"
  },
  {
    "text": "I'm plugging in here. I'm just plugging\nin x=1 to satisfy. And it has to equal zero.",
    "start": "2122470",
    "end": "2130260"
  },
  {
    "text": "So that means, that\npins down omega.",
    "start": "2130260",
    "end": "2137590"
  },
  {
    "text": "Doesn't give me just\none omega, well tell me one omega that's okay then.",
    "start": "2137590",
    "end": "2143280"
  },
  {
    "text": "The first omega that\noccurs to you is? Pi. The sine comes back to pi.",
    "start": "2143280",
    "end": "2148530"
  },
  {
    "text": "So we've got one. y_1. Our first guy is with\nomega=pi is sin(pi*x).",
    "start": "2148530",
    "end": "2154490"
  },
  {
    "start": "2154490",
    "end": "2160540"
  },
  {
    "text": "That's our fundamental mode. That's the number\none eigenfunction.",
    "start": "2160540",
    "end": "2168810"
  },
  {
    "text": "And it is an eigenfunction,\nit satisfies the boundary condition. Everybody would know\nits picture, just",
    "start": "2168810",
    "end": "2175500"
  },
  {
    "text": "one arch of the sine function. And the lambda that\ngoes with it, lambda_1,",
    "start": "2175500",
    "end": "2180760"
  },
  {
    "text": "so this is the first\neigenfunction, what's the first eigenvalue?",
    "start": "2180760",
    "end": "2185960"
  },
  {
    "text": "Pi squared, right. Because omega, we took to be pi. So lambda_1 is pi squared.",
    "start": "2185960",
    "end": "2193460"
  },
  {
    "text": "We've got one. We were able to do it\nbecause we could solve",
    "start": "2193460",
    "end": "2199960"
  },
  {
    "text": "this equation in an easy way.",
    "start": "2199960",
    "end": "2205050"
  },
  {
    "text": "Ready for a second one? What will the next one be? The next eigenfunction it's got\nto, whatever its frequency is,",
    "start": "2205050",
    "end": "2214850"
  },
  {
    "text": "omega, it's got to\nhave sin(omega)=0. What's your choice?",
    "start": "2214850",
    "end": "2220260"
  },
  {
    "text": "2pi. So the next one is\ngoing to be sin(2pi*x).",
    "start": "2220260",
    "end": "2226950"
  },
  {
    "text": "And what will be the eigenvalue\nthat goes with that guy? lambda_2 will be\nomega squared, which",
    "start": "2226950",
    "end": "2234900"
  },
  {
    "text": "is 2pi squared, 2pi all squared,\nso that's four pi squared.",
    "start": "2234900",
    "end": "2240470"
  },
  {
    "text": "You see the whole list. The sines with these\ncorrect frequencies",
    "start": "2240470",
    "end": "2248600"
  },
  {
    "text": "are the eigenfunctions\nof the second derivative with fixed-fixed\nboundary conditions.",
    "start": "2248600",
    "end": "2256900"
  },
  {
    "text": "And this is entirely typical. We don't have just n of them.",
    "start": "2256900",
    "end": "2263869"
  },
  {
    "text": "The list goes on forever, right? The list goes on forever\nbecause we're talking here about a differential equation.",
    "start": "2263870",
    "end": "2270890"
  },
  {
    "text": "A differential\nequation's somehow like a matrix of infinite size.",
    "start": "2270890",
    "end": "2275990"
  },
  {
    "text": "And somehow these sines are the\ncolumns of the infinite size",
    "start": "2275990",
    "end": "2284369"
  },
  {
    "text": "eigenvector matrix. And these numbers, pi\nsquared, four pi squared, nine pi squared, 16pi\nsquared are the eigenvalues",
    "start": "2284370",
    "end": "2293040"
  },
  {
    "text": "of the infinite\neigenvalue matrix.",
    "start": "2293040",
    "end": "2302340"
  },
  {
    "text": "We got those answers quickly. And let's just mention that\nif I changed to free-fixed",
    "start": "2302340",
    "end": "2310710"
  },
  {
    "text": "or to free-free I could repeat.",
    "start": "2310710",
    "end": "2316240"
  },
  {
    "text": "I'd get different y's. If I have different boundary\nconditions I expect to get",
    "start": "2316240",
    "end": "2321620"
  },
  {
    "text": "different y's. In fact, what would it look like\nif that was y'=0 as the left",
    "start": "2321620",
    "end": "2330890"
  },
  {
    "text": "end? What would you expect the\neigenfunctions to look like?",
    "start": "2330890",
    "end": "2339770"
  },
  {
    "text": "They'd be cosines. They'd be cosines. And then we would have to\nadjust the omegas to make",
    "start": "2339770",
    "end": "2346039"
  },
  {
    "text": "them come out right\nat the right-hand end.",
    "start": "2346040",
    "end": "2351410"
  },
  {
    "text": "So this y(0)=0, the\nfixed ones gave us sines,",
    "start": "2351410",
    "end": "2357569"
  },
  {
    "text": "the free ones give us cosines,\nthe periodic ones if I had",
    "start": "2357570",
    "end": "2364710"
  },
  {
    "text": "y(0)=y(1) so that I'm\njust circling around,",
    "start": "2364710",
    "end": "2369800"
  },
  {
    "text": "then I would expect these\ne^(ikx)'s -- the textbook will,",
    "start": "2369800",
    "end": "2376160"
  },
  {
    "text": "so I'm in the eigenvalue\nsection of course, and the textbook lists\nthe answers for the other",
    "start": "2376160",
    "end": "2382630"
  },
  {
    "text": "possibilities. Let's go with this one. Because this is the one\nthat corresponds to K.",
    "start": "2382630",
    "end": "2393310"
  },
  {
    "text": "We're now ready for\nthe final moment.",
    "start": "2393310",
    "end": "2404700"
  },
  {
    "text": "And it is can we guess the\neigenvectors for the matrix?",
    "start": "2404700",
    "end": "2414030"
  },
  {
    "text": "Now I'm going back to\nthe matrix question. And as I say, normally\nthe answer's no.",
    "start": "2414030",
    "end": "2422480"
  },
  {
    "text": "Who could guess? But you can always hope. You can try.",
    "start": "2422480",
    "end": "2428980"
  },
  {
    "text": "So what will I try? Here, let me draw\nsin(x), sin(pi*x).",
    "start": "2428980",
    "end": "2438640"
  },
  {
    "text": "And let me remember\nthat my matrix K was a finite difference matrix.",
    "start": "2438640",
    "end": "2445130"
  },
  {
    "text": "Let's make it four by four. One, two, three, four let's say.",
    "start": "2445130",
    "end": "2457450"
  },
  {
    "start": "2454000",
    "end": "2599000"
  },
  {
    "text": "What would be the\nbest I could hope for, for the eigenvector,\nthe first eigenvector?",
    "start": "2457450",
    "end": "2462970"
  },
  {
    "text": "I'm hoping that the first\neigenvector of K is very, very like the\nfirst eigenfunction",
    "start": "2462970",
    "end": "2470040"
  },
  {
    "text": "in the differential equation,\nwhich was this sin(pi*x),",
    "start": "2470040",
    "end": "2475950"
  },
  {
    "text": "so that's sin(pi*x). Well, what do you hope for? What shall I hope\nfor as the components",
    "start": "2475950",
    "end": "2483640"
  },
  {
    "text": "of y_1, the first eigenvector?",
    "start": "2483640",
    "end": "2489950"
  },
  {
    "text": "It's almost too good. And as far as I know,\nbasically it only happens with these sines\nand cosines example.",
    "start": "2489950",
    "end": "2498030"
  },
  {
    "text": "These heights, I just\npicked these, what I might call samples, of the thing.",
    "start": "2498030",
    "end": "2506710"
  },
  {
    "text": "Those four values and of course\nzero at that end and zero",
    "start": "2506710",
    "end": "2511730"
  },
  {
    "text": "at that end, so\nbecause K, the matrix K is building in the fixed-fixed.",
    "start": "2511730",
    "end": "2521750"
  },
  {
    "text": "These four heights, these four\nnumbers, those four sines-- In other words, what I hope\nis that for Ky=lambda*y,",
    "start": "2521750",
    "end": "2532359"
  },
  {
    "text": "I hope that y_1, the\nfirst eigenvector, it'll be sin(pi*x),\nbut now what is x?",
    "start": "2532360",
    "end": "2540160"
  },
  {
    "text": "So this is x here\nfrom zero to one. So what's x there,\nthere, there and there?",
    "start": "2540160",
    "end": "2547650"
  },
  {
    "text": "Instead of sin(pi*x),\nthe whole curve, I'm picking out\nthose four samples.",
    "start": "2547650",
    "end": "2553770"
  },
  {
    "text": "So it'll be the sine\nof, what'll it be here?",
    "start": "2553770",
    "end": "2559420"
  },
  {
    "text": "Pi. Pi divided by n+1.",
    "start": "2559420",
    "end": "2566880"
  },
  {
    "text": "Which in my picture\nwould be, we'll make it completely explicit. Five.",
    "start": "2566880",
    "end": "2573560"
  },
  {
    "text": "It's 1/5 away along. Maybe I should make these\ny's into column vectors",
    "start": "2573560",
    "end": "2580650"
  },
  {
    "text": "since we're thinking\nof them as columns. So here's y_1. sin(pi/5), sin(2pi/5),\nsin(3pi/5), sin(4pi/5).",
    "start": "2580650",
    "end": "2586970"
  },
  {
    "start": "2586970",
    "end": "2596710"
  },
  {
    "text": "That's the first eigenvector. And it works.",
    "start": "2596710",
    "end": "2602990"
  },
  {
    "start": "2599000",
    "end": "2774000"
  },
  {
    "text": "And you could guess\nnow the general one. Well when I say it works, I\nhaven't checked that it works.",
    "start": "2602990",
    "end": "2616140"
  },
  {
    "text": "I better do that. But the essential\npoint is that it works.",
    "start": "2616140",
    "end": "2623930"
  },
  {
    "text": "I may not even do it today. So, in fact, tell me\nthe second eigenvector.",
    "start": "2623930",
    "end": "2630830"
  },
  {
    "text": "Or tell me the second\neigenfunction over here.",
    "start": "2630830",
    "end": "2635840"
  },
  {
    "text": "What's the second eigenfunction? Let me draw it with\nthis green chalk.",
    "start": "2635840",
    "end": "2642830"
  },
  {
    "text": "So I'm going to draw y_2. Now what does y_2\nlook like? sin(2pi*x).",
    "start": "2642830",
    "end": "2649720"
  },
  {
    "text": "What's the new picture here? It goes up.",
    "start": "2649720",
    "end": "2656910"
  },
  {
    "text": "What does it do? By here it's got\nback, oh no, damn.",
    "start": "2656910",
    "end": "2664619"
  },
  {
    "text": "I would've been better with\nthree points in the middle, but it's correct.",
    "start": "2664620",
    "end": "2670859"
  },
  {
    "text": "It comes down here. Right? That's sin(2pi*x).",
    "start": "2670860",
    "end": "2677250"
  },
  {
    "text": "That's halfway along.",
    "start": "2677250",
    "end": "2686310"
  },
  {
    "text": "I'll finish this guy. This'll be sin(2pi/5),\nsin(4pi/5).",
    "start": "2686310",
    "end": "2696180"
  },
  {
    "text": "See I'm sampling\nthis same thing. I'm sampling 2pi*x\nat those same points.",
    "start": "2696180",
    "end": "2701620"
  },
  {
    "text": "sin(6pi/5) and sin(8pi/5). ",
    "start": "2701620",
    "end": "2712410"
  },
  {
    "text": "Maybe let's accept\nthis as correct. It really works. It's the next eigenvector.",
    "start": "2712410",
    "end": "2719250"
  },
  {
    "text": "And then there's a third one\nand then there's a fourth one. And how many are\nthere? n usually.",
    "start": "2719250",
    "end": "2728119"
  },
  {
    "text": "And in my case, what is n in\nthe picture I've drawn? n here is four.",
    "start": "2728120",
    "end": "2735110"
  },
  {
    "text": "One, two, three, four. n is four\nin that picture and that means that I'm dividing by n+1.",
    "start": "2735110",
    "end": "2741250"
  },
  {
    "text": " That's really sin(pi*h).",
    "start": "2741250",
    "end": "2749290"
  },
  {
    "text": "You remember I used\nh as the step size. So h is 1/5, 1/(n+1), 1/5.",
    "start": "2749290",
    "end": "2758630"
  },
  {
    "text": "So it's sin(pi*h), sin(2pi*h),\n4pi*h-- 3pi*h, 4pi*h.",
    "start": "2758630",
    "end": "2763809"
  },
  {
    "text": "Here's 2, sin(2pi*h),\nsin(4pi*h), sin(6pi*h), sin(8pi*h). ",
    "start": "2763810",
    "end": "2775670"
  },
  {
    "start": "2774000",
    "end": "3018000"
  },
  {
    "text": "So I have two things to do. One is to remember what is the\nremarkable property of these",
    "start": "2775670",
    "end": "2782890"
  },
  {
    "text": "y's. So there's a y\nthat we've guessed. Right now you're\ntaking my word for it",
    "start": "2782890",
    "end": "2788049"
  },
  {
    "text": "that it is the eigenvector\nand this is the next one. I copied them out\nof those functions.",
    "start": "2788050",
    "end": "2794850"
  },
  {
    "text": "And just remind me, what\nis it that I'm claiming to be true about y_1 and y_2.",
    "start": "2794850",
    "end": "2802190"
  },
  {
    "text": "They are orthogonal,\nthere are orthogonal. Well to check that I'd\nhave to do some trig stuff.",
    "start": "2802190",
    "end": "2812330"
  },
  {
    "text": "But what I was going to\ndo was come over here and say this was a symmetric\ndifferential equation.",
    "start": "2812330",
    "end": "2823540"
  },
  {
    "text": "We found its eigenfunctions. What do you think's\nup with those?",
    "start": "2823540",
    "end": "2831090"
  },
  {
    "text": "Those are orthogonal too. So this would be a\nkey fact in any sort",
    "start": "2831090",
    "end": "2838490"
  },
  {
    "text": "of advanced applied math is\nthat the sine function is",
    "start": "2838490",
    "end": "2844530"
  },
  {
    "text": "orthogonal to the sin(2x). That function as\northogonal to this one.",
    "start": "2844530",
    "end": "2850390"
  },
  {
    "text": "And actually that's what\nmakes the whole world of Fourier series work.",
    "start": "2850390",
    "end": "2856319"
  },
  {
    "text": "So that was really\na wonderful fact. That this is orthogonal to this.",
    "start": "2856320",
    "end": "2862810"
  },
  {
    "text": "Now you may, quite reasonably,\nask what do I mean by that? What does it mean for two\nfunctions to be orthogonal?",
    "start": "2862810",
    "end": "2872115"
  },
  {
    "text": "As long as we're getting\nall these parallels, let's get that one too. I claim that this\nfunction, which is this,",
    "start": "2872115",
    "end": "2877890"
  },
  {
    "text": "is orthogonal to this function. What does that mean?",
    "start": "2877890",
    "end": "2885200"
  },
  {
    "text": "What should these\nfunctions-- Could I write dot or transpose or something?",
    "start": "2885200",
    "end": "2891970"
  },
  {
    "text": "But now I'm doing\nit for functions. I just want you to see\nthe complete analogy.",
    "start": "2891970",
    "end": "2901700"
  },
  {
    "text": "So for vectors, what did I do? If I take a dot product I\nmultiply the first component",
    "start": "2901700",
    "end": "2909800"
  },
  {
    "text": "times the first component,\nsecond component times the second, so on, so on. Now what'll I do for functions?",
    "start": "2909800",
    "end": "2916127"
  },
  {
    "text": "I multiply sin(pi*x) *\nsin(2pi*x) at each x. ",
    "start": "2916127",
    "end": "2922300"
  },
  {
    "text": "Of course I've got a\nwhole range of x's. And then what do I do? I integrate.",
    "start": "2922300",
    "end": "2928340"
  },
  {
    "text": "I can't add. I integrate instead. So I integrate one function\nsin(pi*x) against the other",
    "start": "2928340",
    "end": "2938330"
  },
  {
    "text": "function, sin(2pi*x), dx, and\nI integrate from zero to one",
    "start": "2938330",
    "end": "2946060"
  },
  {
    "text": "and the answer comes out zero. The answer comes out zero. The sine functions\nare orthogonal.",
    "start": "2946060",
    "end": "2953310"
  },
  {
    "text": "The sines are\northogonal functions. The sine vectors are\northogonal vectors.",
    "start": "2953310",
    "end": "2959610"
  },
  {
    "text": "I normalize to length one and\nthey go right into my Q. So",
    "start": "2959610",
    "end": "2966420"
  },
  {
    "text": "if I multiply, if I did that\ntimes that, that dot product would turn out to be zero. If I had been a\nlittle less ambitious",
    "start": "2966420",
    "end": "2975200"
  },
  {
    "text": "and taken n to be two\nor three or something we would have seen\nit completely.",
    "start": "2975200",
    "end": "2981390"
  },
  {
    "text": "But maybe doing\nwith four is okay.",
    "start": "2981390",
    "end": "2988920"
  },
  {
    "text": "So great lecture\nexcept for that.",
    "start": "2988920",
    "end": "2995650"
  },
  {
    "text": "Didn't get there. So Wednesday's lecture is\nsort of the bringing all",
    "start": "2995650",
    "end": "3003130"
  },
  {
    "text": "these pieces together, positive\neigenvalues, positive pivots, positive definite.",
    "start": "3003130",
    "end": "3009120"
  },
  {
    "text": "So come on Wednesday please. Come Wednesday. And Wednesday\nafternoon I'll have",
    "start": "3009120",
    "end": "3015720"
  },
  {
    "text": "the review session as usual.",
    "start": "3015720",
    "end": "3018160"
  }
]
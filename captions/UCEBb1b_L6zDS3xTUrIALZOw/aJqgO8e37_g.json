[
  {
    "start": "0",
    "end": "14710"
  },
  {
    "text": "PROFESSOR: So I'm going\nto begin by trying to build some intuition for how\none might be able to do staging",
    "start": "14710",
    "end": "20539"
  },
  {
    "text": "from cross-sectional\ndata, and we'll return to this question of\ncombined staging subtyping only",
    "start": "20540",
    "end": "27910"
  },
  {
    "text": "much later.  So imagine that we had data\nthat lived in one dimension.",
    "start": "27910",
    "end": "34760"
  },
  {
    "text": "Here, each data point\nis an individual, we observe their data at\njust one point in time,",
    "start": "34760",
    "end": "40610"
  },
  {
    "text": "and suppose we knew exactly\nwhich biomarker to look at. Right? So I gave you an\nexample of that here,",
    "start": "40610",
    "end": "46333"
  },
  {
    "text": "when you might look at some\nantibody expression level, and that might be what\nI call biomarker A,",
    "start": "46333",
    "end": "54878"
  },
  {
    "text": "is if you knew exactly\nwhat biomarker to look at, you might just put each\nperson along this line",
    "start": "54878",
    "end": "60730"
  },
  {
    "text": "and you might conjecture that\nmaybe on one side of the line, this is the early disease, and\nthat the other sort of line,",
    "start": "60730",
    "end": "67119"
  },
  {
    "text": "maybe that's the late disease. Why might that be a\nreasonable conjecture? ",
    "start": "67120",
    "end": "74020"
  },
  {
    "text": "What would be an\nalternative conjecture? ",
    "start": "74020",
    "end": "84500"
  },
  {
    "text": "Why don't you talk\nto your neighbors and see if you guys\ncan come up with some alternative conjectures.",
    "start": "84500",
    "end": "89840"
  },
  {
    "text": "Let's go. ",
    "start": "89840",
    "end": "97050"
  },
  {
    "text": "All right, that's enough. So hopefully simple\nquestions, so I won't give you too much time. All right, so what would\nbe another conjecture?",
    "start": "97050",
    "end": "103280"
  },
  {
    "text": "So again, our goal is we have\none observation per individual, each individual is in some\nunknown stage of the disease,",
    "start": "103280",
    "end": "109530"
  },
  {
    "text": "we would like to be able to\nsort individuals and turn it into early and late\nstages of the disease.",
    "start": "109530",
    "end": "115872"
  },
  {
    "text": "I give you one conjecture\nof how to do that, sorting, what would be another\nreasonable conjecture? Raise your hand. ",
    "start": "115872",
    "end": "123420"
  },
  {
    "text": "Yep? AUDIENCE: That there's\nthe different-- that they have different\ntypes of the same diseases. They all have the same\ndisease and it could--",
    "start": "123420",
    "end": "129918"
  },
  {
    "text": "just one of the subtypes\nmight be sort of the-- PROFESSOR: Yeah. So you're going back to the\nexample I gave here where you",
    "start": "129919",
    "end": "138230"
  },
  {
    "text": "could conflate these things. I want to stick with\na simpler story, let's suppose there's only\none subtype of the disease.",
    "start": "138230",
    "end": "145903"
  },
  {
    "text": "What would be another way\nto sort the patients given this data where the data is\nthese points that you see here?",
    "start": "145903",
    "end": "152740"
  },
  {
    "text": "Yeah? AUDIENCE: For any disease in\nthe middle range, and then as you [INAUDIBLE]",
    "start": "152740",
    "end": "160418"
  },
  {
    "text": "PROFESSOR: OK, so\nmaybe early disease is right over here, and when\nthings get bad, the patient--",
    "start": "160418",
    "end": "169010"
  },
  {
    "text": "this biomarker starts\nto become abnormal, and abnormality,\nfor whatever reason, might be sort of to the\nright or to the left.",
    "start": "169010",
    "end": "175099"
  },
  {
    "text": " Now I think that is a\nconjecture one could have.",
    "start": "175100",
    "end": "182990"
  },
  {
    "text": "I would argue that\nthat's perhaps not a very natural\nconjecture given what we know about common\nbiomarkers that are measured",
    "start": "182990",
    "end": "188959"
  },
  {
    "text": "from the human body\nand the way that they respond to disease progression.",
    "start": "188960",
    "end": "193965"
  },
  {
    "text": "Unless you're in the situation\nof having multiple disease subtypes where, for example,\ngoing to the right marker might correspond to\none disease subtype",
    "start": "193965",
    "end": "200300"
  },
  {
    "text": "and going to the left\nmarker might correspond to another disease subtype. What would be\nanother conjecture?",
    "start": "200300",
    "end": "206273"
  },
  {
    "start": "206273",
    "end": "211696"
  },
  {
    "text": "You guys are missing\nthe easy one. Yeah, in the back. AUDIENCE: Well, it\nmight just be one where the high values\nare [INAUDIBLE] stage",
    "start": "211696",
    "end": "217349"
  },
  {
    "text": "and low values are later ones? PROFESSOR: Exactly. So this might be early disease\nand that might be late disease.",
    "start": "217350",
    "end": "224350"
  },
  {
    "text": "AUDIENCE: It says vice\nversa on this slide. PROFESSOR: Oh, does it really? Oh shoot. [LAUGHTER]",
    "start": "224350",
    "end": "230200"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Right, right, OK, OK.",
    "start": "230200",
    "end": "236300"
  },
  {
    "text": "Thank you. Next time I'll take out\nthat lower vice versa. [LAUGHTER] That's why you guys\naren't saying that. OK.",
    "start": "236300",
    "end": "242420"
  },
  {
    "text": "OK, so this is good. Now I think we're\nall on the same page, and we had some idea of what\nare some of the assumptions",
    "start": "242420",
    "end": "249170"
  },
  {
    "text": "that one might need\nto make in order to actually do anything here. Like for example,\nwe are making some--",
    "start": "249170",
    "end": "256019"
  },
  {
    "text": "we'll probably have to make some\nassumption about continuity, that there might be some gradual\nprogression of the biomarker",
    "start": "256019",
    "end": "263300"
  },
  {
    "text": "relevance from early to late,\nand it might be getting larger, it might be getting smaller.",
    "start": "263300",
    "end": "269000"
  },
  {
    "text": "If it's indeed the scenario that\nwe talked about earlier where we said like early\ndisease might be here",
    "start": "269000",
    "end": "274460"
  },
  {
    "text": "and late disease might be going\nto either side, in that case, I think one could easily argue\nthat with just information",
    "start": "274460",
    "end": "281840"
  },
  {
    "text": "we have here, disease\nprogression-- disease stage is unidentifiable, right? Because you wouldn't\nknow where would it--",
    "start": "281840",
    "end": "290240"
  },
  {
    "text": "where should you-- where should\nthat transition point be? So here, here, here,\nhere, here, here.",
    "start": "290240",
    "end": "295787"
  },
  {
    "text": "In fact, the same\nproblem arises here. Like you don't know,\nis it early disease-- is it going this way or\nis it going that way? What would be one way to\ntry to disentangle this just",
    "start": "295787",
    "end": "302990"
  },
  {
    "text": "to try to get us all on\nthe same page, right? So suppose it was only\ngoing this direction",
    "start": "302990",
    "end": "308828"
  },
  {
    "text": "or going that\ndirection, how could we figure out which is which? ",
    "start": "308828",
    "end": "320470"
  },
  {
    "text": "Yeah? AUDIENCE: Maybe we had data\non low key and other data",
    "start": "320470",
    "end": "328260"
  },
  {
    "text": "about how much time we had taken PROFESSOR: Yeah. No, that's great.",
    "start": "328260",
    "end": "333398"
  },
  {
    "text": "So maybe we have data on\nlet's say death information, or even just age.",
    "start": "333398",
    "end": "340480"
  },
  {
    "text": "And if we started from a\nvery, very rough assumption that disease stage let's say\ngrows monotonically with age,",
    "start": "340480",
    "end": "353050"
  },
  {
    "text": "then-- and if you had made an\nadditional assumption that the disease stages are--",
    "start": "353050",
    "end": "361215"
  },
  {
    "text": "that the people\nwho are coming in are uniformly drawn from across\ndisease stages, with those two",
    "start": "361215",
    "end": "367120"
  },
  {
    "text": "assumptions alone, then you\ncould, for example, look at the average age of\nindividuals over here",
    "start": "367120",
    "end": "372970"
  },
  {
    "text": "and the average age of\nindividuals over here, and you'd say, the one\nwith the larger average age",
    "start": "372970",
    "end": "377979"
  },
  {
    "text": "is the late disease one. Or you could look at time to\ndeath if you had for each--",
    "start": "377980",
    "end": "386090"
  },
  {
    "text": "for each data\npoint you also knew how long until that\nindividual died, you could look at\naverage time to death",
    "start": "386090",
    "end": "391919"
  },
  {
    "text": "for these individuals\nversus those individuals and try to tease it\napart in that way. ",
    "start": "391920",
    "end": "397270"
  },
  {
    "text": "That's what you meant. OK, so I'm just trying to give\nyou some intuition for how this might be possible.",
    "start": "397270",
    "end": "403550"
  },
  {
    "text": "What about if your\ndata looked like this? ",
    "start": "403550",
    "end": "411700"
  },
  {
    "text": "So now you have two biomarkers. So we've only gone up\nby one dimension only,",
    "start": "411700",
    "end": "418040"
  },
  {
    "text": "and we want to figure out\nwhere's early, where's late? ",
    "start": "418040",
    "end": "423118"
  },
  {
    "text": "Already starts to become\nmore challenging, right?  So the intuition that\nI want you to have",
    "start": "423118",
    "end": "430702"
  },
  {
    "text": "is that we're going\nto have to make some assumptions about\ndisease progression,",
    "start": "430702",
    "end": "436090"
  },
  {
    "text": "such as the ones we\nwere just discussing, and we also have to\nget lucky in some way. So for example, one\nway of getting lucky",
    "start": "436090",
    "end": "442750"
  },
  {
    "text": "would be to have a\nreal lot of data. So if you had a\nton, ton of data, and you made an additional\nassumption that your data lives",
    "start": "442750",
    "end": "450820"
  },
  {
    "text": "in some low dimensional manifold\nwhere on one side of manifold is early disease and the\nother side of manifold is late disease,\nthen you might be",
    "start": "450820",
    "end": "458170"
  },
  {
    "text": "able to discover that\nmanifold from this data,",
    "start": "458170",
    "end": "463858"
  },
  {
    "text": "and you might conjecture that\nthe manifold is something like that, that trajectory\nthat I'm outlining there",
    "start": "463858",
    "end": "469120"
  },
  {
    "text": "with my hand. But for you to be able\nto do that, of course, you need to have\nenough data, all right?",
    "start": "469120",
    "end": "475240"
  },
  {
    "text": "So it's going to be now\na trade-off between just having cross-sectional\ndata, it might be OK so long",
    "start": "475240",
    "end": "481360"
  },
  {
    "text": "as you have a real\nlot of that data so you can sort of\nfill in the spaces and really identify\nthat manifold.",
    "start": "481360",
    "end": "488300"
  },
  {
    "text": "A different approach\nmight be, well maybe you don't have just pure\ncross-sectional data,",
    "start": "488300",
    "end": "493460"
  },
  {
    "text": "maybe you have two or\nmaybe three samples from each patient. And then you can\ncolor code this.",
    "start": "493460",
    "end": "499915"
  },
  {
    "text": "So you might say, OK,\ngreen is patient 1-- or patient A, we'll call it,\nand this is the first time",
    "start": "499915",
    "end": "508220"
  },
  {
    "text": "point from patient A, second\ntime point from patient A, third and fourth time\npoints from patient A. Red",
    "start": "508220",
    "end": "514008"
  },
  {
    "text": "is patient B, and you have\ntwo time points for patient B, and blue here is\npatient C, and you have 1, 2, 3 time points\nfrom patient C. OK?",
    "start": "514009",
    "end": "524120"
  },
  {
    "text": "Now again, it's not\nvery dense data, we can't really draw\ncurves out, But now",
    "start": "524120",
    "end": "529337"
  },
  {
    "text": "we can start to get a\nsense of the ordering. And again, now we can-- even\nthough we don't-- we're not",
    "start": "529337",
    "end": "535279"
  },
  {
    "text": "in a dense setting like\nwe were here, here, we'd still nonetheless be able\nto figure out that probably the manifold looks a little\nbit like this, right?",
    "start": "535280",
    "end": "542558"
  },
  {
    "text": " And so again, I'm just\ntrying to build intuition",
    "start": "542558",
    "end": "549250"
  },
  {
    "text": "around when disease\nprogression modeling for cross-sectional\ndata might be possible, but this is a wide open field.",
    "start": "549250",
    "end": "557080"
  },
  {
    "text": "And so today, I'll\nbe telling you about a few algorithms\nthat try to build on some of these intuitions\nfor doing disease progression",
    "start": "557080",
    "end": "562960"
  },
  {
    "text": "modeling, but they will\nbreak down very, very easily. They'll break down\nwhen these assumptions",
    "start": "562960",
    "end": "569730"
  },
  {
    "text": "I gave you don't hold,\nthey'll break down when your data is\nhigh dimensional, they'll break down\nwhen your data looks",
    "start": "569730",
    "end": "577073"
  },
  {
    "text": "like this where you don't\njust have a single subtype of perhaps a multiple subtypes. and so this is a really very\nactive area of research,",
    "start": "577073",
    "end": "584530"
  },
  {
    "text": "and it's an area that I think\nwe can make a lot of progress on in the field in the\nnext several years.",
    "start": "584530",
    "end": "591529"
  },
  {
    "text": "So I'll begin with one case\nstudy coming from my own work",
    "start": "591530",
    "end": "597060"
  },
  {
    "text": "where we developed an\nalgorithm for learning from cross-sectional\ndata, and we valued it",
    "start": "597060",
    "end": "603589"
  },
  {
    "text": "in the context of chronic\nobstructive pulmonary disorder or COPD.",
    "start": "603590",
    "end": "610030"
  },
  {
    "text": "COPD is a condition of\nthe lungs typically caused by air pollution or smoking,\nand it has a reasonably good",
    "start": "610030",
    "end": "620260"
  },
  {
    "text": "staging mechanism. One uses what's called a\nspirometry device in order",
    "start": "620260",
    "end": "625960"
  },
  {
    "text": "to measure the lung function\nof individual at any one point in time. So for example, you take\nthis spirometry device,",
    "start": "625960",
    "end": "632230"
  },
  {
    "text": "you stick it in your\nmouth, and you breathe in,",
    "start": "632230",
    "end": "638230"
  },
  {
    "text": "and then you exhale,\nand one measure",
    "start": "638230",
    "end": "643550"
  },
  {
    "text": "is how long it takes in\norder to exhale all your air, and that is going to\nbe a measure of how",
    "start": "643550",
    "end": "649970"
  },
  {
    "text": "good your lungs are. And so then one can take\nthat measure of your function",
    "start": "649970",
    "end": "657500"
  },
  {
    "text": "and one can stage how\nsevere the person's COPD is,",
    "start": "657500",
    "end": "662990"
  },
  {
    "text": "and that goes by what's\ncalled the gold criteria. So for example, in\nstage 1 of the COPD,",
    "start": "662990",
    "end": "669140"
  },
  {
    "text": "common treatments\ninvolve just vaccinations using a short-acting\nbronchodilator only when",
    "start": "669140",
    "end": "676250"
  },
  {
    "text": "needed. When the disease stage gets\nmuch more severe, like stage 4,",
    "start": "676250",
    "end": "682360"
  },
  {
    "text": "than often treatment\nis recommended to be inhaling\nglucocorticosteroids",
    "start": "682360",
    "end": "688040"
  },
  {
    "text": "if there are repeated\naspirations of the disease, long-term oxygen If respiratory\nfailure occurs, and so on.",
    "start": "688040",
    "end": "696920"
  },
  {
    "text": "And so this is a disease that's\nreasonably well-understood because there exists a\ngood staging mechanism.",
    "start": "696920",
    "end": "704160"
  },
  {
    "text": "And I would argue\nthat when we want to understand how to\ndo disease staging in a data-driven\nfashion, we should first",
    "start": "704160",
    "end": "711550"
  },
  {
    "text": "start by working with\neither synthetic data, or we should start with\nworking with a disease where",
    "start": "711550",
    "end": "717100"
  },
  {
    "text": "we have some idea of what the\nactual true disease staging is. And that way, we can look to\nsee what our algorithms would",
    "start": "717100",
    "end": "723520"
  },
  {
    "text": "recover in those\nscenarios, and does it align with what\nwe would expect either from the way\nthe data was generated",
    "start": "723520",
    "end": "730029"
  },
  {
    "text": "or from the existing\nmedical literature. And that's why we chose COPD. Because it is\nwell-understood, and there's",
    "start": "730030",
    "end": "737200"
  },
  {
    "text": "a wealth of literature\non it, and because we have data on it which is much\nmessier than the type of data",
    "start": "737200",
    "end": "743650"
  },
  {
    "text": "that went into the original\nstudies, and we could ask, could we come to\nthe same conclusions as those original studies?",
    "start": "743650",
    "end": "748720"
  },
  {
    "start": "748720",
    "end": "755180"
  },
  {
    "text": "So in this work, we're\ngoing to use data from the electronic\nmedical record.",
    "start": "755180",
    "end": "761860"
  },
  {
    "text": "We're only going to look\nat a subset of the EMR, in particular,\ndiagnosis codes that",
    "start": "761860",
    "end": "767200"
  },
  {
    "text": "are recorded for a patient\nat any point in time, and we're going to assume\nthat we do not have access",
    "start": "767200",
    "end": "772390"
  },
  {
    "text": "to spirometry data at all. So we don't have any obvious\nway of staging the patient's",
    "start": "772390",
    "end": "777470"
  },
  {
    "text": "disease.  The general approach\nis going to be to build a generative model\nfor disease progression.",
    "start": "777470",
    "end": "789839"
  },
  {
    "text": "At a very high level,\nthis is a Markov model. It's a model that specifies the\ndistribution of the patient's",
    "start": "789840",
    "end": "799380"
  },
  {
    "text": "data, which is shown\nhere in the bottom, as it evolves over time.",
    "start": "799380",
    "end": "805750"
  },
  {
    "text": "According to a number\nof hidden variables that are shown in the top,\nthese S variables that denote disease stages, and\nthese X variables that denote",
    "start": "805750",
    "end": "813640"
  },
  {
    "text": "comorbidities that\nthe patient might have at that point in time,\nthese X and S variables",
    "start": "813640",
    "end": "819780"
  },
  {
    "text": "are always assumed\nto the unobserved. So if you were to clump them\ntogether into one variable, this would look exactly\nlike a hidden Markov model.",
    "start": "819780",
    "end": "827860"
  },
  {
    "text": "And moreover, we're\nnot going to assume that we have a lot\nof longitudinal data",
    "start": "827860",
    "end": "833320"
  },
  {
    "text": "for a patient. In particular, COPD evolves over\na 10 to 20 years, and the data",
    "start": "833320",
    "end": "838720"
  },
  {
    "text": "that we'll be learning from\nhere has data only over one to three-year time range.",
    "start": "838720",
    "end": "844360"
  },
  {
    "text": "The challenge will be, can\nwe take data in this one to three-year time range and\nsomehow stitch it together",
    "start": "844360",
    "end": "851975"
  },
  {
    "text": "across large numbers\nof patients to get a picture of what the 20-year\nprogression of the disease might look like?",
    "start": "851975",
    "end": "857332"
  },
  {
    "text": "The way that we're\ngoing to do that is by learning the parameters\nof this probabilistic model.",
    "start": "857332",
    "end": "862371"
  },
  {
    "text": "And then from the\nparameters, we're going to either infer the\npatient's actual disease stage and thus sort them, or\nactually simulate data",
    "start": "862372",
    "end": "870760"
  },
  {
    "text": "from this model to see what\na 20-year trajectory might look like. Is the goal clear?",
    "start": "870760",
    "end": "875930"
  },
  {
    "text": " All right. So now what I'm\ngoing to do is I'm going to step into\nthis model piece",
    "start": "875930",
    "end": "883090"
  },
  {
    "text": "by piece to tell you what\neach of these components are, and I'll start out with a\nvery topmost piece shown here",
    "start": "883090",
    "end": "889390"
  },
  {
    "text": "by the red box. So this is the model of the\npatient's disease progression",
    "start": "889390",
    "end": "896279"
  },
  {
    "text": "at any one point in time. So this variable,\nS1, for example, might denote the patient's\ndisease stage on March 2011;",
    "start": "896280",
    "end": "906810"
  },
  {
    "text": "S2 might denote the patient's\ndisease stage April 2011; S capital T might denote\nthe patient's disease stage",
    "start": "906810",
    "end": "912870"
  },
  {
    "text": "June 2012. So we're going to have\none random variable",
    "start": "912870",
    "end": "918420"
  },
  {
    "text": "for each observation of the\npatient's data that we have. And notice that the observations\nof the patient's data",
    "start": "918420",
    "end": "924870"
  },
  {
    "text": "might be at very\nirregular time intervals, and that's going to be OK\nwith this approach, OK?",
    "start": "924870",
    "end": "930240"
  },
  {
    "text": "So notice that there is a\none-month gap between S1 and S2, but a four-month gap\nbetween St minus 1 and St, OK?",
    "start": "930240",
    "end": "942220"
  },
  {
    "text": "So we're going to model\nthe patient's disease stage at the point in\ntime when we have an observation for the patient.",
    "start": "942220",
    "end": "949509"
  },
  {
    "text": "S denotes a discrete\ndisease stage in this model.",
    "start": "949510",
    "end": "954820"
  },
  {
    "text": "So S might be a value from\n1 up to 4, maybe 1 up to 10",
    "start": "954820",
    "end": "960910"
  },
  {
    "text": "where 1 is denoting a early\ndisease stage and 4 or 10",
    "start": "960910",
    "end": "967149"
  },
  {
    "text": "might denote a much\nlater disease stage.  If we have a sequence of\nobservations per patient--",
    "start": "967150",
    "end": "973980"
  },
  {
    "text": "for example, we might have\nan observation on March and then in April, we're\ngoing to denote the disease",
    "start": "973980",
    "end": "979620"
  },
  {
    "text": "stage by S1 and S2, what this\nmodel is going to talk about is the probability distribution\nof transitioning from whatever",
    "start": "979620",
    "end": "986340"
  },
  {
    "text": "the disease stage\nat S1 is to whatever the disease stage at S2. Now because the time\ninterval is between stages",
    "start": "986340",
    "end": "994140"
  },
  {
    "text": "are not homogeneous, we have to\nhave a transition distribution",
    "start": "994140",
    "end": "999260"
  },
  {
    "text": "that takes into\nconsideration that time gap. And to do that, we use what's\nknown as a continuous time",
    "start": "999260",
    "end": "1006180"
  },
  {
    "text": "Markov process. Formally, we say that the\ntransition distribution--",
    "start": "1006180",
    "end": "1014790"
  },
  {
    "text": "so the probability of\ntransitioning from stage I at time t minus 1 to\nstate j at time t,",
    "start": "1014790",
    "end": "1026709"
  },
  {
    "text": "given as input the difference\nin time intervals--",
    "start": "1026710",
    "end": "1031959"
  },
  {
    "text": "the difference in\ntime points delta-- so delta is the number of months\nbetween the two observations.",
    "start": "1031960",
    "end": "1038390"
  },
  {
    "text": "So this conditional\ndistribution is going to be given by the\nmatrix exponential of this time",
    "start": "1038390",
    "end": "1046599"
  },
  {
    "text": "interval times a matrix Q.",
    "start": "1046599",
    "end": "1055560"
  },
  {
    "text": "And then here, the matrix\nQ gives us the parameters that we want to learn. So let me contrast\nthis to things",
    "start": "1055560",
    "end": "1062070"
  },
  {
    "text": "that you might\nalready be used to. In a typical hidden\nMarkov model,",
    "start": "1062070",
    "end": "1071720"
  },
  {
    "text": "you might have\nasked t goes to St--",
    "start": "1071720",
    "end": "1077125"
  },
  {
    "text": "or St minus 1 goes to St,\nand you might imagine just parametrizing St given St\nminus 1 just by a lookup table.",
    "start": "1077125",
    "end": "1087570"
  },
  {
    "text": "So for example, if\nthe number of states-- for each running variable is\n3, then you would have a 3",
    "start": "1087570",
    "end": "1097130"
  },
  {
    "text": "by 3 table where for\neach state St minus 1,",
    "start": "1097130",
    "end": "1103076"
  },
  {
    "text": "you have some\nprobability of transition to the corresponding state\nSt, so this might be something",
    "start": "1103076",
    "end": "1110730"
  },
  {
    "text": "like 0.9, 0.9,\n0.9, where notice,",
    "start": "1110730",
    "end": "1120510"
  },
  {
    "text": "I'm having a very large\nvalue along the diagonal, because if, let's say,\na very small period--",
    "start": "1120510",
    "end": "1126260"
  },
  {
    "text": "so a priori, we might\nbelieve that patients stay in the same\ndisease, and then one might imagine\nthat the probably",
    "start": "1126260",
    "end": "1133230"
  },
  {
    "text": "transitioning from state\n1 at time t minus 1",
    "start": "1133230",
    "end": "1139080"
  },
  {
    "text": "to state 2 at time t might\nbe something like 0.09,",
    "start": "1139080",
    "end": "1148075"
  },
  {
    "text": "and the probability of skipping\nstate 2, going directly to state 3 from state\n1 might be something much smaller like 0.01, OK?",
    "start": "1148075",
    "end": "1155880"
  },
  {
    "text": "And we might say something\nlike that the probability-- we might imagine\nthat the probability of going in a\nbackwards direction,",
    "start": "1155880",
    "end": "1161309"
  },
  {
    "text": "going from stage 2\nat time t minus 1 to let's say stage 1 at time\nt, that might be 0 all right?",
    "start": "1161310",
    "end": "1170160"
  },
  {
    "text": "So you might imagine that\nactually this is the model,",
    "start": "1170160",
    "end": "1175810"
  },
  {
    "text": "and what that's saying is\nsomething like you never go in the backwards\ndirection, and you're",
    "start": "1175810",
    "end": "1182560"
  },
  {
    "text": "more likely to\ntransition to the state immediately adjacent\nto the current stage and very unlikely\nto skip a stage.",
    "start": "1182560",
    "end": "1189783"
  },
  {
    "text": "So this would be\nan example of how you would parametrize the\ntransition distribution in a typical discrete\ntime Markov model,",
    "start": "1189783",
    "end": "1198450"
  },
  {
    "text": "and the story here is going\nto be different specifically because we don't know\nthe time intervals.",
    "start": "1198450",
    "end": "1203530"
  },
  {
    "text": "So intuitively, if a lot of\ntime has passed between the two observations, then we want\nto allow for an accelerated",
    "start": "1203530",
    "end": "1211120"
  },
  {
    "text": "process. We want to allow for\nthe fact that you might want to skip many\ndifferent stages to go to your next time step, to go\nto the stage of the next time",
    "start": "1211120",
    "end": "1217738"
  },
  {
    "text": "step, because so\nmuch time has passed. And that intuitively is what\nthis scaling of this matrix",
    "start": "1217738",
    "end": "1222960"
  },
  {
    "text": "Q by delta corresponds to. So the number of parameters\nin this parameterization is actually identical to\nthe number of parameters",
    "start": "1222960",
    "end": "1229950"
  },
  {
    "text": "in this parametrization, right? So you have a matrix Q which\nis given to you in essence",
    "start": "1229950",
    "end": "1236790"
  },
  {
    "text": "by the number of\nstates squared-- really, the number of states-- there's an additional\nredundancy there",
    "start": "1236790",
    "end": "1242250"
  },
  {
    "text": "because it has to sum up to\n1, but that's irrelevant. And so the same\nstory here, but we're",
    "start": "1242250",
    "end": "1247980"
  },
  {
    "text": "going to now\nparametrize the process by in some sense the\ninfinitesimally small time",
    "start": "1247980",
    "end": "1256552"
  },
  {
    "text": "probability of transitioning. So if you were to take the\nderivative of this transition distribution as the\ntime interval shrinks,",
    "start": "1256552",
    "end": "1263430"
  },
  {
    "text": "and then you were to integrate\nover the time interval that",
    "start": "1263430",
    "end": "1270153"
  },
  {
    "text": "was observed and the probability\nof transitioning from any state to any other state with\nthat infinitesimally small",
    "start": "1270153",
    "end": "1276419"
  },
  {
    "text": "probability transitioning,\nwhat you get out is exactly this form. And I'll leave-- this paper\nis in the optional readings",
    "start": "1276420",
    "end": "1285240"
  },
  {
    "text": "for today's lecture, and\nyou can read through it to get more intuition about the\ncontinuous time Markov process.",
    "start": "1285240",
    "end": "1292080"
  },
  {
    "text": "Any questions so far? Yep? AUDIENCE: Those Q are the\nsame for both versions or--",
    "start": "1292080",
    "end": "1297260"
  },
  {
    "text": "PROFESSOR: Yes. And this model Q is essentially\nthe same for all patients. And you might imagine, if there\nwere disease subtypes, which",
    "start": "1297260",
    "end": "1305120"
  },
  {
    "text": "there aren't in this\napproach, that Q might be different for each subtype. For example, you might\ntransition between stages",
    "start": "1305120",
    "end": "1311000"
  },
  {
    "text": "much more quickly for some\nsubtypes than for others. Other questions? ",
    "start": "1311000",
    "end": "1319880"
  },
  {
    "text": "Yep? AUDIENCE: So-- OK, so\nQ you said had like-- it's just like a screen\nnumber used beforehand you",
    "start": "1319880",
    "end": "1326058"
  },
  {
    "text": "kind of like specified\nthese stages that you pick [INAUDIBLE] PROFESSOR: Correct. Yes. So you pre-specify the number of\nstages that you want to model,",
    "start": "1326058",
    "end": "1335220"
  },
  {
    "text": "and there are many ways to\ntry to choose that parameter. For example, you could look\nat how about likelihood",
    "start": "1335220",
    "end": "1342050"
  },
  {
    "text": "under this model,\nwhich is learned for the different of stages. You could use typical\nmodel selection techniques",
    "start": "1342050",
    "end": "1348830"
  },
  {
    "text": "from machine learning\nas another approach where you try to penalize\ncomplexity in some way.",
    "start": "1348830",
    "end": "1355010"
  },
  {
    "text": "Or, what we found here, because\nof some of the other things that I'm about to tell\nyou, it doesn't actually matter that much.",
    "start": "1355010",
    "end": "1361220"
  },
  {
    "text": "So similarly to when one does\nhard [INAUDIBLE] clustering or even K-means clustering\nor even learning",
    "start": "1361220",
    "end": "1367580"
  },
  {
    "text": "a problematic\ntopic model, if you use a very small number of\ntopics or number of clusters,",
    "start": "1367580",
    "end": "1372590"
  },
  {
    "text": "you tend to learn very\ncoarse-grained topics or clusters. If you use very many more-- if you use a much\nlarger number of topics,",
    "start": "1372590",
    "end": "1379280"
  },
  {
    "text": "you tend to learn much\nmore fine-grained topics. Same story is going\nto happen here. If you use a small\nnumber of disease stages,",
    "start": "1379280",
    "end": "1385638"
  },
  {
    "text": "you're going to learn very\ncoarse-grained notions of disease stages; if you\nuse more disease stages, you're going to learn\na fine-grained notion;",
    "start": "1385638",
    "end": "1392085"
  },
  {
    "text": "but the overall\nsorting of the patients is going to end up\nbeing very similar. But to make that\nstatement, we're",
    "start": "1392085",
    "end": "1398180"
  },
  {
    "text": "going to need to make some\nadditional assumptions, which I'm going to show\nyou in a few minutes.",
    "start": "1398180",
    "end": "1403297"
  },
  {
    "text": "Any other questions? These are great questions. Yep? AUDIENCE: So do we know\nthe staging of the disease",
    "start": "1403297",
    "end": "1410799"
  },
  {
    "text": "because I PROFESSOR: No, and\nthat's critical here. So I'm assuming that these\nvariables-- these S's are all",
    "start": "1410800",
    "end": "1417059"
  },
  {
    "text": "hidden variables here. And the way that we're\ngoing to learn this model is by maximum\nlikelihood estimation",
    "start": "1417060",
    "end": "1423730"
  },
  {
    "text": "where we marginalize over\nthe hidden variables, just like you would do\nin any EM type algorithm.",
    "start": "1423730",
    "end": "1430870"
  },
  {
    "text": "Any other questions?  All right, so what\nI've just shown",
    "start": "1430870",
    "end": "1436809"
  },
  {
    "text": "you is the topmost\npart of the model, now I'm going to talk\nabout a horizontal slice.",
    "start": "1436810",
    "end": "1442530"
  },
  {
    "text": "So I'm going to talk about\none of these time points. ",
    "start": "1442530",
    "end": "1449988"
  },
  {
    "text": "So if you were to look\nat the translation--",
    "start": "1449988",
    "end": "1455840"
  },
  {
    "text": "the rotation of one of\nthose time points, what you would get out is this model. These X's are also\nhidden variables,",
    "start": "1455840",
    "end": "1464360"
  },
  {
    "text": "and we have pre-specified them\nto characterize different axes by which we want to understand\nthe patient's disease",
    "start": "1464360",
    "end": "1470300"
  },
  {
    "text": "progression. So in Thursday's\nlecture, we characterized the patient's disease as\nsubtype by just a single number,",
    "start": "1470300",
    "end": "1483070"
  },
  {
    "text": "and similarly in this example\nis just by a single number, but we might want to\nunderstand what's really",
    "start": "1483070",
    "end": "1488200"
  },
  {
    "text": "unique about each subtype. So for example--\nsorry, what's really",
    "start": "1488200",
    "end": "1493730"
  },
  {
    "text": "unique about each disease stage. So for example, how is the\npatient's endocrine function",
    "start": "1493730",
    "end": "1499760"
  },
  {
    "text": "in that disease stage? How is the patient's psychiatric\nstatus in that disease stage?",
    "start": "1499760",
    "end": "1509644"
  },
  {
    "text": " Has the patient developed lung\ncancer yet and that disease",
    "start": "1509645",
    "end": "1515169"
  },
  {
    "text": "stage? And so on. And so we're going\nto ask that we",
    "start": "1515170",
    "end": "1520720"
  },
  {
    "text": "want to be able to read\nout from this model according to these\naxes, and this will become very clear at\nthe end of this section",
    "start": "1520720",
    "end": "1527470"
  },
  {
    "text": "where I show you a\nsimulation of what 20 years looks like for COPD\naccording to these quantities.",
    "start": "1527470",
    "end": "1533500"
  },
  {
    "text": "When does the patient\ntypically develop diabetes, when does the patient\ntypically become depressed, when does the patient typically\ndevelop cancer, and so on.",
    "start": "1533500",
    "end": "1541730"
  },
  {
    "text": "So these are the\nquantities in which we want to be able\nto really talk about what happens to a patient\nat any one disease stage,",
    "start": "1541730",
    "end": "1548650"
  },
  {
    "text": "but the challenge is, we\nnever actually observe these quantities in\nthe data that we have. Rather, all we observe are\nthings like laboratory test",
    "start": "1548650",
    "end": "1556450"
  },
  {
    "text": "results or diagnosis\ncodes or procedures that have been formed\nand so on, which I'm going to call the clinical\nfindings in the bottom.",
    "start": "1556450",
    "end": "1563190"
  },
  {
    "text": "And as we've been discussing\nthroughout this course, one could think about\nthings as diagnosis codes",
    "start": "1563190",
    "end": "1568300"
  },
  {
    "text": "as giving you information\nabout the disease status of the patient,\nbut they're not one and the same\nas the diagnosis,",
    "start": "1568300",
    "end": "1574660"
  },
  {
    "text": "because there's so much\nnoise and bias that goes into the assigning of\ndiagnosis codes for patients.",
    "start": "1574660",
    "end": "1580015"
  },
  {
    "text": " And so the way that we're\ngoing to model the raw data",
    "start": "1580015",
    "end": "1586820"
  },
  {
    "text": "as a function of\nthese hidden variables that we want to\ncharacterize is using what's known as a noisy-OR network.",
    "start": "1586820",
    "end": "1593165"
  },
  {
    "text": " So we're going to\nsuppose that there is some generative distribution\nwhere the observations you",
    "start": "1593165",
    "end": "1601880"
  },
  {
    "text": "see-- for example,\ndiagnosis codes are likely to be observed as a\nfunction of whether the patient",
    "start": "1601880",
    "end": "1608510"
  },
  {
    "text": "has these phenotypes\nor comorbidities with some probability, and that\nprobability can be specified",
    "start": "1608510",
    "end": "1613970"
  },
  {
    "text": "by these edge weights. So for example, a\ndiagnosis code for diabetes",
    "start": "1613970",
    "end": "1620930"
  },
  {
    "text": "is very likely to be\nobserved in the patient data if the patient\ntruly has diabetes,",
    "start": "1620930",
    "end": "1626270"
  },
  {
    "text": "but of course, it\nmay not be recorded in the data for every\nsingle visit the patient has to a clinician, there\nmight be some visits",
    "start": "1626270",
    "end": "1632060"
  },
  {
    "text": "to clinicians that have nothing\nto do with their patients endocrine function and\ndiabetes-- the diagnosis",
    "start": "1632060",
    "end": "1637730"
  },
  {
    "text": "code might not be\nrecorded for that visit. So it's going to\nbe a noisy process, and that noise rate is going\nto be captured by that edge.",
    "start": "1637730",
    "end": "1644240"
  },
  {
    "start": "1644240",
    "end": "1651100"
  },
  {
    "text": "So part of the\nlearning algorithm is going to be to learn that\ntransition distributions-- for example, that Q matrix\nI showed you in the earlier",
    "start": "1651100",
    "end": "1658570"
  },
  {
    "text": "slide, but the other\nrole-- learning algorithm is to learn all\nof the parameters",
    "start": "1658570",
    "end": "1663700"
  },
  {
    "text": "of this noisy-OR distribution,\nnamely these edge weights. So that's going to be discovered\nas part of the learning",
    "start": "1663700",
    "end": "1669820"
  },
  {
    "text": "algorithm. And a key question\nthat you have to ask me is, if I know I want\nto read out from the model",
    "start": "1669820",
    "end": "1678040"
  },
  {
    "text": "according to these axes,\nbut these axes are never-- I'm never assuming\nthat they're explicitly",
    "start": "1678040",
    "end": "1683140"
  },
  {
    "text": "observed in the data, how\ndo I ground the learning algorithm to give meaning\nto these hidden variables?",
    "start": "1683140",
    "end": "1689050"
  },
  {
    "text": "Because otherwise if we left\nthem otherwise unconstrained and you did maximum\nlikelihood estimation just",
    "start": "1689050",
    "end": "1694960"
  },
  {
    "text": "like in any factor\nanalysis-type model, you might discover\nsome factors here, but they might not be the\nfactors you care about,",
    "start": "1694960",
    "end": "1701040"
  },
  {
    "text": "and if the learning problem\nwas not identifiable, as is often the case in\nunsupervised learning,",
    "start": "1701040",
    "end": "1706300"
  },
  {
    "text": "then you might not discover\nwhat you're interested in. So to ground the\nhidden variables,",
    "start": "1706300",
    "end": "1712690"
  },
  {
    "text": "we introduced-- we used a\ntechnique that you already saw in an earlier lecture\nfrom lecture 8 called anchors.",
    "start": "1712690",
    "end": "1721480"
  },
  {
    "text": "So a domain expert\nis going to specify for each one of the comorbidites\none or more anchors, which",
    "start": "1721480",
    "end": "1728980"
  },
  {
    "text": "are observations, which\nwe are going to conjecture could only have arisen from the\ncorresponding hidden variable.",
    "start": "1728980",
    "end": "1737590"
  },
  {
    "text": "So notice here\nthat this diagnosis code, which is for\ntype 2 diabetes, has only an edge from X1.",
    "start": "1737590",
    "end": "1745270"
  },
  {
    "text": "That is an assumption\nthat we're making in the learning algorithm. We are actually\nexplicitly zeroing out all of the other edges from\nall of the other comorbidities",
    "start": "1745270",
    "end": "1754210"
  },
  {
    "text": "to a 1. We're not going to pre-specify\nwhat this edge rate is, we're going to allow for the\nfact that this might be noisy,",
    "start": "1754210",
    "end": "1761140"
  },
  {
    "text": "it's not always observed even\nif the patient has diabetes, but we're going to\nsay, this could not be explained by any of\nthe other comorbidities.",
    "start": "1761140",
    "end": "1769830"
  },
  {
    "text": "And so for each one of the\ncomorbidites or phenotypes that we want to\nmodel, we're going to specify some small\nnumber of anchors",
    "start": "1769830",
    "end": "1777270"
  },
  {
    "text": "which correspond to a type\nof sparsity assumption on that graph.",
    "start": "1777270",
    "end": "1782470"
  },
  {
    "text": "And these are the anchors\nthat we chose for asthma, we chose a diagnosis code\ncorresponding to asthma;",
    "start": "1782470",
    "end": "1788669"
  },
  {
    "text": "for lung cancer, we\nchose several diagnosis codes correspond to lung\ncancer; for obesity, we chose a diagnosis\ncode corresponding",
    "start": "1788670",
    "end": "1794820"
  },
  {
    "text": "to morbid obesity; and so on. And so these are\nways that we're going to give meaning to\nthe hidden variables,",
    "start": "1794820",
    "end": "1801179"
  },
  {
    "text": "but as you'll see in\njust a few minutes, it is not going to pre-specify\ntoo much of the model. The model's still going\nto learn a whole bunch",
    "start": "1801180",
    "end": "1807897"
  },
  {
    "text": "of other interesting things. By the way, the way that we\nactually came up with this set",
    "start": "1807897",
    "end": "1814340"
  },
  {
    "text": "was by an iterative process. We specified some of the hidden\nvariables to have anchors,",
    "start": "1814340",
    "end": "1821840"
  },
  {
    "text": "but we also left some of\nthem to be unanchored, meaning free variables.",
    "start": "1821840",
    "end": "1827090"
  },
  {
    "text": "We did our learning\nalgorithm, and just like you would do\nin a topic model, we discovered that there\nwere some phenotypes that",
    "start": "1827090",
    "end": "1833257"
  },
  {
    "text": "really seemed to be\ncharacterized by the patient's disease-- that seemed to characterize a\npatient's disease progression.",
    "start": "1833257",
    "end": "1838940"
  },
  {
    "text": "Then in order to really dig\ndeeper, working collaboratively with a domain expert, we\nspecified anchors for those",
    "start": "1838940",
    "end": "1846150"
  },
  {
    "text": "and we iterated,\nand in this way, we discovered the full set\nof interesting variables that we wanted to model.",
    "start": "1846150",
    "end": "1851380"
  },
  {
    "text": "Yep? AUDIENCE: Did you measure how\ngood an anchor these were? Like are some comorbidities\nbetter anchors than others?",
    "start": "1851380",
    "end": "1858042"
  },
  {
    "text": "PROFESSOR: Great. You'll see-- I think we'll\nanswer that question in just a few minutes when I show\nyou what the graph looks",
    "start": "1858042",
    "end": "1863360"
  },
  {
    "text": "like that's learned. Yep? AUDIENCE: Were all\nthe other weights in that X to O network 0?",
    "start": "1863360",
    "end": "1869490"
  },
  {
    "text": "They weren't part of it here. So it looks like\na pretty sparse-- PROFESSOR: They're\nexplicitly nonzero, actually,",
    "start": "1869490",
    "end": "1874590"
  },
  {
    "text": "it's opposite. So for an anchor, we say that\nit only has a single parent.",
    "start": "1874590",
    "end": "1882350"
  },
  {
    "text": "Everything that's\nnot an anchor can have arbitrarily many parents. Is that clear?",
    "start": "1882350",
    "end": "1888166"
  },
  {
    "text": "OK. Yeah? AUDIENCE: Do the anchors that\nyou have in that linear table, you itereated yourself on\nthat or did the doctors say",
    "start": "1888166",
    "end": "1895360"
  },
  {
    "text": "that these are the [INAUDIBLE]? PROFESSOR: We started\nout with just a subset of these conditions.",
    "start": "1895360",
    "end": "1900676"
  },
  {
    "text": "As things that we\nwanted to model-- things that we\nwanted to understand what happens along\ndisease progression",
    "start": "1900676",
    "end": "1906326"
  },
  {
    "text": "according to these axes,\nbut just a subset of them originally. And then we included a few\nadditional hidden variables",
    "start": "1906327",
    "end": "1913240"
  },
  {
    "text": "that didn't have any\nanchors associated to them, and after doing unsupervised\nlearning and just a preliminary development stage,\nthey discovered some topics",
    "start": "1913240",
    "end": "1921197"
  },
  {
    "text": "and we realized, oh shoot,\nwe should have included those in there, and then we added them\nin with corresponding anchors.",
    "start": "1921197",
    "end": "1926920"
  },
  {
    "text": " And so you could think about\nthis as an exploratory data analysis pipeline.",
    "start": "1926920",
    "end": "1934200"
  },
  {
    "text": "Yep? AUDIENCE: Is there a chance\nthat these aren't anchors? PROFESSOR: Yes.",
    "start": "1934200",
    "end": "1940375"
  },
  {
    "text": "So there's definitely the\nchance that these may not be anchors related\nto the question was asked a second ago. So for example, there\nmight be some chance",
    "start": "1940375",
    "end": "1951040"
  },
  {
    "text": "that the morbid\nobesity diagnosis code might be\ncoded for a patient",
    "start": "1951040",
    "end": "1957610"
  },
  {
    "text": "more often for a patient\nwho has, let's say, asthma--",
    "start": "1957610",
    "end": "1965257"
  },
  {
    "text": "this is a bad example.  And in which case, that would\ncorrespond to there truly",
    "start": "1965258",
    "end": "1973269"
  },
  {
    "text": "existing an edge from\nasthma to this anchor, which would be a violation\nof anchor assumption.",
    "start": "1973270",
    "end": "1978980"
  },
  {
    "text": "All right, so we chose\nthese to make that unlikely, but it could happen.",
    "start": "1978980",
    "end": "1985880"
  },
  {
    "text": "And it's not easily testable. So this is another example\nof an untestable assumption, just like we saw lots\nof other examples",
    "start": "1985880",
    "end": "1992230"
  },
  {
    "text": "already in today's lecture and\nthe causal inference lectures. If we had some ground\ntruth data-- like",
    "start": "1992230",
    "end": "1997360"
  },
  {
    "text": "if we had done chart review\nfor some number of patients and we actually label\nthese conditions, then we could test\nthat anchor assumption.",
    "start": "1997360",
    "end": "2003570"
  },
  {
    "text": "But here, we're assuming that we\ndon't actually know the ground truth of these conditions. AUDIENCE: Is there a\nreason why you choose",
    "start": "2003570",
    "end": "2009680"
  },
  {
    "text": "such high-level comorbidites? Like I imagine you\ncould go more specific. Even, say, the\ndiabetes, you could",
    "start": "2009680",
    "end": "2014945"
  },
  {
    "text": "try to subtype the diabetes\nbased on this other model, sort of use that as a single\nlayer, but it seems to--",
    "start": "2014945",
    "end": "2021442"
  },
  {
    "text": "at least this model seems to\nchoose [INAUDIBLE] high level. I was just curious\nof the reason. PROFESSOR: Yes. So that was a design\nchoice that we made.",
    "start": "2021442",
    "end": "2027890"
  },
  {
    "text": "There are many, many\ndirections for follow-up work, one of which would be to use\na hierarchical model here.",
    "start": "2027890",
    "end": "2033720"
  },
  {
    "text": "But we hadn't gone\nthat direction. Another obvious direction\nfor follow-up work would be to do something within\nthe subtyping with this staging",
    "start": "2033720",
    "end": "2041070"
  },
  {
    "text": "by introducing another\nrandom variable, which is, let's say, the\ndisease subtype, and making everything\na function of that.",
    "start": "2041070",
    "end": "2046380"
  },
  {
    "text": " OK, so I've talked\nabout the vertical slice",
    "start": "2046380",
    "end": "2054273"
  },
  {
    "text": "and I've talked about\nthe topmost slice, but what I still need\nto tell you about is how these phenotypes relate\nto the observed disease stage.",
    "start": "2054273",
    "end": "2063874"
  },
  {
    "text": " So for this, we use-- ",
    "start": "2063874",
    "end": "2073089"
  },
  {
    "text": "I don't remember the exact\ntechnical terminology-- a factored Markov model?",
    "start": "2073090",
    "end": "2078638"
  },
  {
    "text": "Is that right, Pete? Factorized Markov\nmodel-- I mean, this is a term that existed\nin the graphical model's",
    "start": "2078639",
    "end": "2084707"
  },
  {
    "text": "literature, but I don't\nremember right now. So what we're saying is that\neach of these Markov chains--",
    "start": "2084707",
    "end": "2091580"
  },
  {
    "text": "so each of these X1 up to Xt--",
    "start": "2091580",
    "end": "2106880"
  },
  {
    "start": "2106880",
    "end": "2112500"
  },
  {
    "text": "so this, will say, is the\nfirst one I call diabetes. ",
    "start": "2112500",
    "end": "2119730"
  },
  {
    "text": "This is the second one which\nI'll say is depression. ",
    "start": "2119730",
    "end": "2130573"
  },
  {
    "text": "We're going to assume that\neach one of these Markov chains is conditionally independent\nof each other given the disease",
    "start": "2130573",
    "end": "2135630"
  },
  {
    "text": "stage. So it's the disease stage\nwhich ties everything together.",
    "start": "2135630",
    "end": "2145589"
  },
  {
    "text": "So the graphical model looks\nlike this, and so on, OK?",
    "start": "2145590",
    "end": "2157160"
  },
  {
    "text": "So in particular, there are\nno edges between, let's say, the diabetes variable and\nthe depression variable.",
    "start": "2157160",
    "end": "2163009"
  },
  {
    "text": "All correlations\nbetween these conditions is assumed to be mediated by\nthe disease stage variable.",
    "start": "2163010",
    "end": "2169760"
  },
  {
    "text": "And that's a critical\nassumption that we had to make. Does anyone know why? ",
    "start": "2169760",
    "end": "2177540"
  },
  {
    "text": "What would go wrong if we\ndidn't make that assumption? So for example,\nwhat would go wrong",
    "start": "2177540",
    "end": "2182700"
  },
  {
    "text": "if we had something\nlook like this, x1--",
    "start": "2182700",
    "end": "2188560"
  },
  {
    "text": "what was my notation? X1,1, X1,2, X1,3, and suppose\nwe had edges between them,",
    "start": "2188560",
    "end": "2201060"
  },
  {
    "text": "a complete graph, and\nwe had, let's say, also the S variable with\nedges to everything?",
    "start": "2201060",
    "end": "2209130"
  },
  {
    "text": "What would happen\nin that case where we're not assuming that the X's\nare conditionally independent",
    "start": "2209130",
    "end": "2214350"
  },
  {
    "text": "given S? ",
    "start": "2214350",
    "end": "2222180"
  },
  {
    "text": "So I want you to think about\nthis in terms of distributions.",
    "start": "2222180",
    "end": "2227200"
  },
  {
    "text": "So remember, we're\ngoing to learn how to do disease\nprogression through learning",
    "start": "2227200",
    "end": "2233500"
  },
  {
    "text": "the parameters of this model. And so if we set this up and--\nif we set up the learning problem in a way which\nis unidentifiable,",
    "start": "2233500",
    "end": "2239230"
  },
  {
    "text": "then we're going to\nbe screwed, we're not going to able\nto learn anything about disease progression. So what would happen\nin this situation?",
    "start": "2239230",
    "end": "2245569"
  },
  {
    "text": " Someone who hasn't\nspoken today ideally.",
    "start": "2245570",
    "end": "2251830"
  },
  {
    "start": "2251830",
    "end": "2258760"
  },
  {
    "text": "So any of you remember\nfrom, let's say, perhaps an earlier\nmachine learning class what types\nof distribution's",
    "start": "2258760",
    "end": "2265420"
  },
  {
    "text": "a complete graph-- a complete Bayesian\nnetwork could represent? ",
    "start": "2265420",
    "end": "2276990"
  },
  {
    "text": "So the answer is\nall distributions, because it corresponds\nto any factorization",
    "start": "2276990",
    "end": "2283299"
  },
  {
    "text": "of the joint distribution. And so if you allowed\nthese x variables",
    "start": "2283300",
    "end": "2288670"
  },
  {
    "text": "to be fully connected to\neach other-- so for example, saying that depression depends\non diabetes in addition to the stage, then in\nfact, you don't even",
    "start": "2288670",
    "end": "2296050"
  },
  {
    "text": "need this stage\nvariable in here. The marginal-- you can\nfit any distribution on these X variables even\nwithout the S variable at all.",
    "start": "2296050",
    "end": "2303460"
  },
  {
    "text": "And so the model could\nlearn to simply ignore the S variable, which would\nbe exactly not our goal,",
    "start": "2303460",
    "end": "2310240"
  },
  {
    "text": "because our goal is to learn\nsomething about the disease stage, and in fact,\nwe're going to be wanting",
    "start": "2310240",
    "end": "2317690"
  },
  {
    "text": "to make assumptions on\nthe progression of disease stage, which is going\nto help us learn.",
    "start": "2317690",
    "end": "2324990"
  },
  {
    "text": "So by assuming conditional\nindependence between these X variables, it's going to\nforce all of the correlations",
    "start": "2324990",
    "end": "2331770"
  },
  {
    "text": "to have to be mediated\nby that S variable, and it's going to remove some\nof that unidentifiability that",
    "start": "2331770",
    "end": "2336805"
  },
  {
    "text": "would otherwise exist. It's this subtle but\nvery important point. ",
    "start": "2336805",
    "end": "2345520"
  },
  {
    "text": "So the way that we're\ngoing to parametrize the conditional distribution--\nso first of all, I'm going to assume\nthese X's are all binary.",
    "start": "2345520",
    "end": "2352470"
  },
  {
    "text": "So either the\npatient has diabetes or they don't have diabetes. I'm going to suppose that--",
    "start": "2352470",
    "end": "2358490"
  },
  {
    "text": "and this is, again, another\nassumption we're making, I'm going to suppose that once\nyou already have a comorbidity,",
    "start": "2358490",
    "end": "2367430"
  },
  {
    "text": "then you always have it. So for example, once this is\n1, then all subsequent ones are also going to be 1.",
    "start": "2367430",
    "end": "2372590"
  },
  {
    "text": " Hold the questions\nfor just a second.",
    "start": "2372590",
    "end": "2377710"
  },
  {
    "text": "I'm also going to\nmake an assumption that later stages of the disease\nare more likely to develop the comorbidity.",
    "start": "2377710",
    "end": "2383680"
  },
  {
    "text": "So in particular, one can\nformalize that mathematically as probability of X--",
    "start": "2383680",
    "end": "2393775"
  },
  {
    "text": " I'll just say Xi\nbeing 1 given S--",
    "start": "2393775",
    "end": "2404155"
  },
  {
    "text": "I'll say St equals little\ns, comma, Xt minus 1 equals",
    "start": "2404155",
    "end": "2416190"
  },
  {
    "text": "0, and suppose\nthat this is larger",
    "start": "2416190",
    "end": "2422010"
  },
  {
    "text": "than or equal to probability\nof Xt equals 1 given St equals",
    "start": "2422010",
    "end": "2429420"
  },
  {
    "text": "S prime and Xt minus 1 equals\n0 for all S prime less than S,",
    "start": "2429420",
    "end": "2445200"
  },
  {
    "text": "OK? So I'm saying, as you get\nfurther along in the disease stage, you're more\nlikely to observe",
    "start": "2445200",
    "end": "2452450"
  },
  {
    "text": "one of these complications.  And again, this is an\nassumption that we're",
    "start": "2452450",
    "end": "2458619"
  },
  {
    "text": "putting into the\nlearning algorithm, but what we found that\nthese types of assumptions",
    "start": "2458620",
    "end": "2464525"
  },
  {
    "text": "are really critical in order\nto learn disease progression models when you don't have\na large amount of data.",
    "start": "2464525",
    "end": "2471270"
  },
  {
    "text": "And note that this is\njust a linear inequality",
    "start": "2471270",
    "end": "2476350"
  },
  {
    "text": "on the parameters of the model. And so one can use a convex\noptimization algorithm",
    "start": "2476350",
    "end": "2484690"
  },
  {
    "text": "during learning-- during the maximum\nlikelihood estimation step with this algorithm, we\njust put a linear inequality",
    "start": "2484690",
    "end": "2492609"
  },
  {
    "text": "into the convex\noptimization problem to enforce this constraint. There are a couple of questions.",
    "start": "2492610",
    "end": "2498640"
  },
  {
    "text": "AUDIENCE: Is there generally\nlike a quick way to check whether a model is\nunidentifiable or--",
    "start": "2498640",
    "end": "2503964"
  },
  {
    "text": " PROFESSOR: So there\nare ways to try",
    "start": "2503965",
    "end": "2511480"
  },
  {
    "text": "to detect to see if a\nmodel is unidentifiable. It's beyond the\nscope of the class, but I'll just briefly mention\none of the techniques.",
    "start": "2511480",
    "end": "2518980"
  },
  {
    "start": "2518980",
    "end": "2524630"
  },
  {
    "text": "So one could-- so you can ask\nthe identifiability question by looking at moments\nof the distribution.",
    "start": "2524630",
    "end": "2530570"
  },
  {
    "text": "For example, you\ncould talk about it as a function of\nall of the observed moments of distribution\nthat you get from the data.",
    "start": "2530570",
    "end": "2537227"
  },
  {
    "text": "Now the observed data here are\nnot the S's and X's, but rather the O's. So you look at the\njoint distribution",
    "start": "2537227",
    "end": "2542270"
  },
  {
    "text": "on the O's, and then you\ncan ask questions about-- if I was to--",
    "start": "2542270",
    "end": "2547820"
  },
  {
    "text": "so suppose I was to choose\na random set of parameters in the model, is\nthere any way to do",
    "start": "2547820",
    "end": "2553040"
  },
  {
    "text": "a perturbation of the\nparameters in the model which leave the observed marginal\ndistribution on the O's",
    "start": "2553040",
    "end": "2559220"
  },
  {
    "text": "identical? And often when you're in the\nsetting of non-identifiability,",
    "start": "2559220",
    "end": "2564830"
  },
  {
    "text": "you can take the gradient\nof a function and see--",
    "start": "2564830",
    "end": "2570712"
  },
  {
    "text": "and you could sort of find that\nthere is some wiggle space, and then you show that\nOK, there are actually--",
    "start": "2570712",
    "end": "2576589"
  },
  {
    "text": "this objective function is\nactually unidentifiable. Now that type of\ntechnique is widely",
    "start": "2576590",
    "end": "2581690"
  },
  {
    "text": "used when studying what are\nknown as method of moments algorithms or\nestimation algorithms in learning verbal models,\nbut they would be much, much",
    "start": "2581690",
    "end": "2588650"
  },
  {
    "text": "harder to apply in this type of\nsetting because first of all,",
    "start": "2588650",
    "end": "2593891"
  },
  {
    "text": "these are much more\ncomplex models, and estimating the\ncorresponding moments is going to be very hard because\nthey're very high dimensional.",
    "start": "2593892",
    "end": "2601350"
  },
  {
    "text": "And second, because they're-- I'm actually conflating\ntwo different things when",
    "start": "2601350",
    "end": "2607130"
  },
  {
    "text": "I talk about identifiability. One statement is the infinite\ndata identifiability,",
    "start": "2607130",
    "end": "2613110"
  },
  {
    "text": "and the second question\nis your ability to actually learn a good model\nfrom a small amount of data,",
    "start": "2613110",
    "end": "2622230"
  },
  {
    "text": "which is a sample complexity. And these constraints\nthat I'm putting in,",
    "start": "2622230",
    "end": "2628440"
  },
  {
    "text": "even if they don't affect\nthe actual identifiability of the model, they\ncould be extremely important for improving the\nsample complexity of learning",
    "start": "2628440",
    "end": "2635790"
  },
  {
    "text": "algorithm. Is there another question? ",
    "start": "2635790",
    "end": "2643715"
  },
  {
    "text": "So we valued to\nthis using a data set of almost 4,000\npatients where,",
    "start": "2643715",
    "end": "2650050"
  },
  {
    "text": "again, each patient we observed\nfor only a couple of years--",
    "start": "2650050",
    "end": "2656310"
  },
  {
    "text": "one to three years. And the observations\nthat we observed were 264 diagnosis\ncodes, the presence",
    "start": "2656310",
    "end": "2663220"
  },
  {
    "text": "or absence of each of\nthose diagnosis codes during any three-month interval. Overall, there were almost\n200,000 observations",
    "start": "2663220",
    "end": "2672760"
  },
  {
    "text": "of diagnosis codes\nin this data set. The learning\nalgorithm that we used was expectation maximization.",
    "start": "2672760",
    "end": "2678650"
  },
  {
    "text": "Remember, there are a number\nof hidden variables here, and so if you want to\nmaximize the likely-- if you want to learn the\nparameters that maximize",
    "start": "2678650",
    "end": "2684372"
  },
  {
    "text": "the likelihood of\nthose observations O, then you have to marginize\nover those hidden variables, and EM is one way to try to\nfind a local optima of that",
    "start": "2684372",
    "end": "2693010"
  },
  {
    "text": "likelihood function, with the\nkey caveat that one has to do",
    "start": "2693010",
    "end": "2699500"
  },
  {
    "text": "approximate inference\nduring the E step here, because this model\nis not tractable,",
    "start": "2699500",
    "end": "2705500"
  },
  {
    "text": "there's no closed form-- for example, dynamic programming\nalgorithm for doing posterior inference in this model\ngiven its complexity.",
    "start": "2705500",
    "end": "2713420"
  },
  {
    "text": "And so what we used\nwas a Gibbs sampler to do approximate inference\nwithin that E step, and we used--",
    "start": "2713420",
    "end": "2719089"
  },
  {
    "text": "we did block sampling\nof the Markov chains where we combined\na Gibbs sampler with a dynamic programming\nalgorithm, which",
    "start": "2719090",
    "end": "2725420"
  },
  {
    "text": "improved the mixing\nrate of the Markov chain for those of you who are\nfamiliar with those concepts.",
    "start": "2725420",
    "end": "2730460"
  },
  {
    "text": "And in the end step of the\nlearning algorithm when one has to learn the\nparameters of the distribution,",
    "start": "2730460",
    "end": "2738150"
  },
  {
    "text": "the only complex\npart of this model is the continuous\ntime Markov process, and there's actually\nbeen previous literature",
    "start": "2738150",
    "end": "2744329"
  },
  {
    "text": "from the physics community\nwhich shows how you can really-- which gives you analytic\nclosed-form solutions",
    "start": "2744330",
    "end": "2749610"
  },
  {
    "text": "for that M step of that\ncontinuous time Markov process. Now if I were to do\nthis again today,",
    "start": "2749610",
    "end": "2755790"
  },
  {
    "text": "I would have done it a\nlittle bit differently. I would still think about\nmodeling this problem in a very similar\nway, but I would",
    "start": "2755790",
    "end": "2763230"
  },
  {
    "text": "do learning using a\nvariational lower bound of the likelihood with\na recognition network",
    "start": "2763230",
    "end": "2769350"
  },
  {
    "text": "in order to very quickly\nget you a lower bound in the likelihood. And for those of\nyou who are familiar",
    "start": "2769350",
    "end": "2776580"
  },
  {
    "text": "with variational\nautoencoders, that's precisely the idea\nthat is used there for learning variational\nautoencoders.",
    "start": "2776580",
    "end": "2781750"
  },
  {
    "text": "So that's the way I\nwould approach this if I was to do it again.  There's just one or two other\nextensions I want to mention.",
    "start": "2781750",
    "end": "2789730"
  },
  {
    "text": "The first one is\nsomething which we-- one, more customization\nwe made for COPD,",
    "start": "2789730",
    "end": "2795570"
  },
  {
    "text": "which is that we enforced\nmonotonic stage progression. So we said that--",
    "start": "2795570",
    "end": "2801930"
  },
  {
    "text": "so here I talked about\na type of monotonically in terms of the conditional\ndistribution of X",
    "start": "2801930",
    "end": "2807070"
  },
  {
    "text": "given S, but one could also\nput an assumption in the--",
    "start": "2807070",
    "end": "2814540"
  },
  {
    "text": "I already talked about\nthat, but one could also put an assumption on P of S--",
    "start": "2814540",
    "end": "2821005"
  },
  {
    "text": " S of t given S of t minus\n1, which is implicitly",
    "start": "2821005",
    "end": "2827890"
  },
  {
    "text": "an assumption on\nQ, and I gave you a hint of how one might\ndo that over here when I said that you might put 0's to\nthe left-hand side, meaning you",
    "start": "2827890",
    "end": "2835000"
  },
  {
    "text": "can never go to the left. And indeed, we did\nsomething like that here as well, which is\nanother type of constraint.",
    "start": "2835000",
    "end": "2840903"
  },
  {
    "text": " And finally, we regularize\nthe learning problem",
    "start": "2840903",
    "end": "2847130"
  },
  {
    "text": "by asking about\nthat graph involving the conditions,\nthe comorbidities,",
    "start": "2847130",
    "end": "2852890"
  },
  {
    "text": "and the diagnosis\ncodes be sparse, by putting a beta prior\non those edge weights.",
    "start": "2852890",
    "end": "2860089"
  },
  {
    "text": "So here's what one learned. So the first thing\nI'm going to do is I'm going to show you the--",
    "start": "2860090",
    "end": "2866569"
  },
  {
    "text": "we talked about how\nwe specified anchors, but I told you that the anchors\nweren't the whole story. That we were able to infer\nmuch more interesting things",
    "start": "2866570",
    "end": "2874340"
  },
  {
    "text": "about the hidden variables\ngiven all of the observations we have. So here I'm showing you\nseveral of the phenotypes that",
    "start": "2874340",
    "end": "2881630"
  },
  {
    "text": "were learned by this\nunsupervised learning algorithm. First, the phenotype\nfor kidney disease. In red here, I'm showing\nyou the anchor variables",
    "start": "2881630",
    "end": "2890660"
  },
  {
    "text": "that we chose for kidney\ndisease, and what you'll notice are a couple of things.",
    "start": "2890660",
    "end": "2896250"
  },
  {
    "text": "First, the weight, which\nyou should think about as being proportional\nin some way",
    "start": "2896250",
    "end": "2902269"
  },
  {
    "text": "to how often you would see\nthat diagnosis code given that the patient\nhad kidney disease,",
    "start": "2902270",
    "end": "2907550"
  },
  {
    "text": "the weights are all far\nless than one, all right? So there is some noise in this\nprocess of when you observe",
    "start": "2907550",
    "end": "2914690"
  },
  {
    "text": "a diagnosis code for a patient. The second thing you\nobserve is that there are a number of other diagnosis\ncodes that are observed to be--",
    "start": "2914690",
    "end": "2926080"
  },
  {
    "text": "which are explained by this\nkidney disease comorbidity,",
    "start": "2926080",
    "end": "2932050"
  },
  {
    "text": "such as anemia, urinary\ntract infections, and so on,",
    "start": "2932050",
    "end": "2937980"
  },
  {
    "text": "and that aligns well with what's\nknown in the medical literature about kidney disease.",
    "start": "2937980",
    "end": "2943470"
  },
  {
    "text": "Look at another example\nfor lung cancer. In red here I'm\nshowing you the anchors that we had pre-specified\nfor these, which",
    "start": "2943470",
    "end": "2950250"
  },
  {
    "text": "mean that these diagnosis\ncodes could only be explained by the lung cancer\ncomorbidity, and these",
    "start": "2950250",
    "end": "2959970"
  },
  {
    "text": "are the noise rates that\nare learned for them, and that's everything else. And here's one more\nexample of lung infection",
    "start": "2959970",
    "end": "2966660"
  },
  {
    "text": "where there was only a signal\nanchor that we specified for pneumonia, and you see\nall of the other things that",
    "start": "2966660",
    "end": "2972900"
  },
  {
    "text": "are automatically\nassociated to that as by the unsupervised\nlearning algorithm. Yep? AUDIENCE: So how\ndo you [INAUDIBLE]",
    "start": "2972900",
    "end": "2981180"
  },
  {
    "text": "for the mobidity, right? PROFESSOR: Right. So that's what the unsupervised\nlearning algorithm is doing. So these weights are\nlearned, and I'm showing you",
    "start": "2981180",
    "end": "2987850"
  },
  {
    "text": "something like a point\nestimate of the parameters that are learned by\nthe learning algorithm.",
    "start": "2987850",
    "end": "2993460"
  },
  {
    "text": "AUDIENCE: And so we-- PROFESSOR: Just like if you're\nlearning a Markov model, you learned some transition and\n[INAUDIBLE],, same thing here.",
    "start": "2993460",
    "end": "3000190"
  },
  {
    "text": "All right. And this should\nlook a lot like what you would see when you do topic\nmodeling on a text copora, right?",
    "start": "3000190",
    "end": "3005270"
  },
  {
    "text": "You would discover a topic--\nthis is analogous to a topic. It's a discrete topic,\nmeaning it either occurs",
    "start": "3005270",
    "end": "3011390"
  },
  {
    "text": "or it doesn't occur\nfor a patient. And you would discover some\nword topic distribution. This is analogous to that\nword topic distribution",
    "start": "3011390",
    "end": "3017880"
  },
  {
    "text": "for a topic in a topic model. ",
    "start": "3017880",
    "end": "3024089"
  },
  {
    "text": "So one could then use\nthe model to answer a couple of the original\nquestions we set out to solve. The first one is given\na patient's data,",
    "start": "3024090",
    "end": "3032750"
  },
  {
    "text": "which I'm illustrating\nhere on the bottom, I have artificially\nseparated out",
    "start": "3032750",
    "end": "3037910"
  },
  {
    "text": "into three different\ncomorbidities, and a star denotes\nan observation",
    "start": "3037910",
    "end": "3043279"
  },
  {
    "text": "of a data type of that one. But this was\nartificially done by us, it was not given to\nlearning algorithm.",
    "start": "3043280",
    "end": "3050180"
  },
  {
    "text": "One can infer, when\nthe patient initiated-- started with each one of these\ncomorbidites, and also, when--",
    "start": "3050180",
    "end": "3058609"
  },
  {
    "text": "so for the full\nthree-year time range that we have data\nfor the patient, what stage was the patient in\nin the disease at any one",
    "start": "3058610",
    "end": "3064670"
  },
  {
    "text": "point in time? So this model infers that the\npatient starts out in stage 1, and about half a year\nthrough the data collection",
    "start": "3064670",
    "end": "3072230"
  },
  {
    "text": "process, transitioned\ninto stage 2 of COPD. ",
    "start": "3072230",
    "end": "3078400"
  },
  {
    "text": "Another thing that one\ncould do using this model is to simulate from the model\nand answer the question of what",
    "start": "3078400",
    "end": "3085240"
  },
  {
    "text": "would, let's say, a 20-year\ntrajectory of the disease look like? And here, I'm showing\na 10-year trajectory.",
    "start": "3085240",
    "end": "3091070"
  },
  {
    "text": "And again, only one\nto three years of data was used for any one\npatient during learning.",
    "start": "3091070",
    "end": "3096700"
  },
  {
    "text": "So this is the first time\nwe see the those axes, those comorbidities\nreally start to show up",
    "start": "3096700",
    "end": "3103619"
  },
  {
    "text": "as being important as the way\nof reading out from the model. Here, we've thrown away those\nO's, those diagnosis codes",
    "start": "3103620",
    "end": "3109690"
  },
  {
    "text": "altogether, we only care about\nwhat we conjecture is truly happening to the patient,\nthose X variables, which",
    "start": "3109690",
    "end": "3115440"
  },
  {
    "text": "are unobserved during training. So what we conjecture is that\nkidney disease is very uncommon",
    "start": "3115440",
    "end": "3124130"
  },
  {
    "text": "in stage 1 of the disease,\nand increases slowly as you transition from stage 2, stage\n3, to stage 4 of the disease,",
    "start": "3124130",
    "end": "3133160"
  },
  {
    "text": "and then really bumps\nup towards stage 5 and stage 6 of the disease. So you should read\nthis as saying",
    "start": "3133160",
    "end": "3138320"
  },
  {
    "text": "that in stage 6 of\nthe disease, over 60% people have kidney disease.",
    "start": "3138320",
    "end": "3144650"
  },
  {
    "text": "Now the time interval is here. So how I've chosen these--",
    "start": "3144650",
    "end": "3150860"
  },
  {
    "text": "where to put these\ntriangles, I've chosen them based on the\naverage amount of time",
    "start": "3150860",
    "end": "3159049"
  },
  {
    "text": "it takes to transition from\none stage to the next stage according to the learned\nparameters of the model.",
    "start": "3159050",
    "end": "3165490"
  },
  {
    "text": "And so you see that\nstages 1, 2, and 3, and 4 take a long period of--",
    "start": "3165490",
    "end": "3170890"
  },
  {
    "text": "amount of time to transition\nbetween those four stages, and then there's a\nvery small amount",
    "start": "3170890",
    "end": "3176280"
  },
  {
    "text": "of time between\ntransitioning from stage 5 to stage 6 on average. So that's for kidney disease.",
    "start": "3176280",
    "end": "3182370"
  },
  {
    "text": "One could also read this\nout for other comorbidities. So in orange here--\nin yellow here",
    "start": "3182370",
    "end": "3189119"
  },
  {
    "text": "is diabetes, in black here is\nmusculoskeletal conditions, and in red here is\ncardiovascular disease.",
    "start": "3189120",
    "end": "3195299"
  },
  {
    "text": "And so one of the\ninteresting inferences made by this\nlearning algorithm is that even in stage 1 of COPD,\nvery early in the trajectory,",
    "start": "3195300",
    "end": "3205700"
  },
  {
    "text": "we are seeing patients\nwith large amounts of cardiovascular disease. And again, this is\nsomething that one",
    "start": "3205700",
    "end": "3210860"
  },
  {
    "text": "can look at the\nmedical literature to see does it align\nwith what we expect? And it does, so even in patients\nwith mild to moderate COPD,",
    "start": "3210860",
    "end": "3219740"
  },
  {
    "text": "the leading cause of morbidity\nis cardiovascular disease. Again, this is\njust a sanity check",
    "start": "3219740",
    "end": "3225770"
  },
  {
    "text": "that what this model is learning\nfor a common disease actually aligns with the\nmedical knowledge.",
    "start": "3225770",
    "end": "3234020"
  },
  {
    "text": "So that's all I want to say\nabout this probabilistic model approach to disease\nprogression modeling",
    "start": "3234020",
    "end": "3240680"
  },
  {
    "text": "from cross-sectional data. I want you to hold\nyour questions so I can get through\nthe rest of the material and you can ask me after class.",
    "start": "3240680",
    "end": "3247760"
  },
  {
    "text": "So next I want to talk about\nthese pseudo-time methods, which are a very different\napproach for trying",
    "start": "3247760",
    "end": "3253500"
  },
  {
    "text": "to align patients into\nearly-to-late disease stage. These approaches were really\npopularized in the last five",
    "start": "3253500",
    "end": "3259700"
  },
  {
    "text": "years due to the explosion\nin single-cell sequencing",
    "start": "3259700",
    "end": "3265339"
  },
  {
    "text": "experiments in the\nbiology community. Single-cell sequencing is\na way to really understand",
    "start": "3265340",
    "end": "3271900"
  },
  {
    "text": "not just what is the\naverage gene expression, but on a cell-by-cell\nbasis can we",
    "start": "3271900",
    "end": "3279520"
  },
  {
    "text": "understand what is\nexpressed in each cell. So at a very high level,\nthe way this works is",
    "start": "3279520",
    "end": "3285690"
  },
  {
    "text": "you take a solid tissue, you\ndo a number of procedures",
    "start": "3285690",
    "end": "3291270"
  },
  {
    "text": "in order to isolate\nout individual cells from that tissue,\nthen you're going",
    "start": "3291270",
    "end": "3296670"
  },
  {
    "text": "to extract the RNA from\nthose individual cells, you go through another\ncomplex procedure",
    "start": "3296670",
    "end": "3303359"
  },
  {
    "text": "which somehow barcodes\neach of the RNA from each individual cell,\nmixes them all together,",
    "start": "3303360",
    "end": "3310920"
  },
  {
    "text": "does sequencing of it,\nand then deconvolves it so that you can see\nwhat was the original RNA",
    "start": "3310920",
    "end": "3317610"
  },
  {
    "text": "expression for each of\nthe individual cells. ",
    "start": "3317610",
    "end": "3323442"
  },
  {
    "text": "Now the goal of these\npseudo-time algorithms",
    "start": "3323442",
    "end": "3328450"
  },
  {
    "text": "is to take that type\nof data and then to attempt to align\ncells to some trajectory.",
    "start": "3328450",
    "end": "3337510"
  },
  {
    "text": "So if you look at the very\ntop of this figure part figure a that's the picture that\nyou should have in your mind.",
    "start": "3337510",
    "end": "3345100"
  },
  {
    "text": "In the real world, cells\nare evolving with time--",
    "start": "3345100",
    "end": "3350180"
  },
  {
    "text": "for example, B cells will have\na well-characterized evolution",
    "start": "3350180",
    "end": "3360940"
  },
  {
    "text": "between different\ncellular states, and what we'd like\nto be understand,",
    "start": "3360940",
    "end": "3367010"
  },
  {
    "text": "given that you have\ncross-sectional data-- so you can imagine-- imagine you have\na whole collection of cells, each one in a different\npart, a different stage",
    "start": "3367010",
    "end": "3374080"
  },
  {
    "text": "of differentiation,\ncould you somehow order them into where they\nwere in different stages",
    "start": "3374080",
    "end": "3381140"
  },
  {
    "text": "of differentiation? So that's the goal. We want to take this-- so there exists some\ntrue ordering that I'm",
    "start": "3381140",
    "end": "3387350"
  },
  {
    "text": "showing from dark to light. The capture process\nis going to ignore what the ordering information\nwas, because all we're doing",
    "start": "3387350",
    "end": "3394760"
  },
  {
    "text": "is getting a collection of cells\nthat are in different stages. And then we're going to\nuse this pseudo-time method",
    "start": "3394760",
    "end": "3400910"
  },
  {
    "text": "to try to re-sort them so\nthat you could figure out, oh, these were the\ncells in the early stage",
    "start": "3400910",
    "end": "3406670"
  },
  {
    "text": "and these are the cells\nin the late stage. And of course,\nthere's an analogy here to the pictures I\nshowed you in the earlier",
    "start": "3406670",
    "end": "3412730"
  },
  {
    "text": "part of the lecture. Once you have this alignment\nof cells into stages,",
    "start": "3412730",
    "end": "3418270"
  },
  {
    "text": "then you can answer some really\nexciting scientific questions. For example, you could ask\na variety of different genes",
    "start": "3418270",
    "end": "3425380"
  },
  {
    "text": "which genes are expressed\nat which point in time. So you might see that\ngene a is very highly",
    "start": "3425380",
    "end": "3431049"
  },
  {
    "text": "expressed very early in\nthis cell's differentiation and is not expressed very\nmuch towards the end,",
    "start": "3431050",
    "end": "3438875"
  },
  {
    "text": "and that might give you\nnew biological insights.  So these methods\ncould immediately",
    "start": "3438875",
    "end": "3446120"
  },
  {
    "text": "be applied, I believe, to\ndisease progression modeling where I want you to think about\neach cell as now a patient,",
    "start": "3446120",
    "end": "3452870"
  },
  {
    "text": "and that patient has a number\nof observations for this data.",
    "start": "3452870",
    "end": "3458360"
  },
  {
    "text": "The observations are an\nexpression for that cell, but in our data,\nthe observations",
    "start": "3458360",
    "end": "3463579"
  },
  {
    "text": "might be symptoms that we\nobserve for the patient, for example.",
    "start": "3463580",
    "end": "3468618"
  },
  {
    "text": "And then the goal is,\ngiven those cross-sectional observations, to sort them.",
    "start": "3468618",
    "end": "3474049"
  },
  {
    "text": "And once you have\nthat sorting, then you could answer\nscientific questions, such as, I mentioned, of a\nnumber of different genes,",
    "start": "3474050",
    "end": "3481819"
  },
  {
    "text": "which genes are expressed when. So here, I'm showing you\nsort of the density of when",
    "start": "3481820",
    "end": "3488059"
  },
  {
    "text": "this particular\ngene is expressed as a function of pseudo-time. Analogously for disease\nprogression modeling,",
    "start": "3488060",
    "end": "3494517"
  },
  {
    "text": "you should think of\nthat as being a symptom. You could ask, OK, suppose\nthere are some true progression of the disease, when do patients\ntypically develop diabetes",
    "start": "3494517",
    "end": "3505580"
  },
  {
    "text": "or cardiovascular symptoms? And so for cardiovascular,\ngoing back to the COPD example, you might imagine that there's\na peak very early in the disease",
    "start": "3505580",
    "end": "3512450"
  },
  {
    "text": "stage; for diabetes, it might\nbe in a later disease stage. All right? So that-- is the analogy clear?",
    "start": "3512450",
    "end": "3519220"
  },
  {
    "text": " So this community, which\nhas been developing methods",
    "start": "3519220",
    "end": "3527970"
  },
  {
    "text": "for studying single-cell\ngene expression data, has just exploded in\nthe last 10 years.",
    "start": "3527970",
    "end": "3535770"
  },
  {
    "text": "So I lost count of how many\ndifferent methods there are, but if I had to guess, I'd\nsay 50 to 200 different methods",
    "start": "3535770",
    "end": "3543420"
  },
  {
    "text": "for this problem. There was a paper, which is\none of the optional readings for today's lecture, that just\ncame out earlier this month",
    "start": "3543420",
    "end": "3551980"
  },
  {
    "text": "which looks at a comparison\nof these different trajectory inference methods,\nand this picture",
    "start": "3551980",
    "end": "3558220"
  },
  {
    "text": "gives a really\ninteresting illustration of what are some of\nthe assumptions made by these algorithms. So for example,\nthe first question,",
    "start": "3558220",
    "end": "3565990"
  },
  {
    "text": "when you try to figure out which\nmethod of these tons of methods to use is, do you expect\nmultiple disconnected",
    "start": "3565990",
    "end": "3571450"
  },
  {
    "text": "trajectories? What might be a reason\nwhy you would expect multiple disconnected\ntrajectories for disease",
    "start": "3571450",
    "end": "3578315"
  },
  {
    "text": "progression modeling?  TAs should not answer. ",
    "start": "3578315",
    "end": "3586770"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Different\nsubtexts would be an example.",
    "start": "3586770",
    "end": "3593120"
  },
  {
    "text": "So suppose the answer\nis no, as we've been assuming for most of this\nlecture, then you might ask,",
    "start": "3593120",
    "end": "3600395"
  },
  {
    "text": "OK, there might only be a single\ntrajectory, because we're only assuming that a single\ndisease subtype, but do we expect a\nparticular topology?",
    "start": "3600395",
    "end": "3609089"
  },
  {
    "text": "Now everything that we've been\ntalking about up until now has been a linear\ntopology, meaning",
    "start": "3609090",
    "end": "3614750"
  },
  {
    "text": "there's a linear\nprojection, there's such notion of early\nand late to stage, but in fact, the\nlinear trajectory",
    "start": "3614750",
    "end": "3621020"
  },
  {
    "text": "may not be realistic. Maybe the trajectory\nlooks a little bit more like this bifurcation.",
    "start": "3621020",
    "end": "3627420"
  },
  {
    "text": "Maybe patients look the same\nvery early in the disease stage, but then\nsuddenly something",
    "start": "3627420",
    "end": "3634280"
  },
  {
    "text": "might happen which causes\nsome patients to go this way and some\npatients to go that way.",
    "start": "3634280",
    "end": "3639349"
  },
  {
    "text": "Any idea what that might\nbe in a clinical setting? AUDIENCE: A treatment?",
    "start": "3639350",
    "end": "3645177"
  },
  {
    "text": "PROFESSOR: Treatments,\nthat's great. All right? So maybe these patients\ngot t equals 0,",
    "start": "3645177",
    "end": "3650340"
  },
  {
    "text": "and maybe these patients\ngot t equal as 1, and maybe for whatever reason\nwouldn't even have good data on what\ntreatments patients got,",
    "start": "3650340",
    "end": "3656208"
  },
  {
    "text": "so we don't actually observe\nthe treatment, right? Then you might want to be able\nto discover that bifurcation",
    "start": "3656208",
    "end": "3661630"
  },
  {
    "text": "directly from the data, then\nthat might suggest, going back to the original source\nof the data, to ask,",
    "start": "3661630",
    "end": "3667270"
  },
  {
    "text": "what differentiated these\npatients at this point in time? And you might\ndiscover, oh, there was something in the data\nthat we didn't record,",
    "start": "3667270",
    "end": "3673530"
  },
  {
    "text": "such as treatment, all right? So there are a\nvariety of methods",
    "start": "3673530",
    "end": "3679809"
  },
  {
    "text": "to try to infer these\npseudo-times under a variety of different assumptions.",
    "start": "3679810",
    "end": "3685240"
  },
  {
    "text": "What I'll do in the\nnext few minutes is just give you an inkling of\nhow two of the methods work.",
    "start": "3685240",
    "end": "3691470"
  },
  {
    "text": "And I chose these to be\nrepresentative examples. The first example\nis an approach based",
    "start": "3691470",
    "end": "3698329"
  },
  {
    "text": "on building a minimum\nspanning tree. And this algorithm\nI'm going to describe",
    "start": "3698330",
    "end": "3705140"
  },
  {
    "text": "goes by the name of Monocle. It was published in 2014 in\nthis paper by Trapnell et al,",
    "start": "3705140",
    "end": "3710869"
  },
  {
    "text": "but it builds very heavily\non an earlier published paper from 2003 that\nI mostly citing here.",
    "start": "3710870",
    "end": "3718210"
  },
  {
    "text": "So the way that this\nalgorithm works is as follows. It starts with, as\nwe've been assuming",
    "start": "3718210",
    "end": "3723670"
  },
  {
    "text": "all along, cross-sectional\ndata, which lives in some high-dimensional space. I'm drawing that in\nthe top-left here.",
    "start": "3723670",
    "end": "3730480"
  },
  {
    "text": "Each data point corresponds\nto some patient or some cell.",
    "start": "3730480",
    "end": "3736323"
  },
  {
    "text": "The first step of\nthe algorithm is to do dimensionality reduction. And there are many ways to\ndo dimensionality reduction. You could do principal\ncomponents analysis,",
    "start": "3736323",
    "end": "3742900"
  },
  {
    "text": "or, for example, you could\ndo independent components analysis. This paper uses the\nindependent component analysis.",
    "start": "3742900",
    "end": "3747927"
  },
  {
    "text": "What ICA is going\nto do, it's going to attempt to find a number\nof different components that seem to be as independent\nfrom one another as possible.",
    "start": "3747927",
    "end": "3755260"
  },
  {
    "text": "Then you're going to\nrepresent the data now in this low-dimensional space,\nand in many of these papers,",
    "start": "3755260",
    "end": "3761140"
  },
  {
    "text": "it's quite astonishing to me,\nthey actually use dimension 2. So they'll go all the way\ndown to two-dimensional space",
    "start": "3761140",
    "end": "3766619"
  },
  {
    "text": "where you can actually\nplot all of the data. It's not at all obvious to me\nwhy you would want to do that,",
    "start": "3766620",
    "end": "3771990"
  },
  {
    "text": "and for clinical data,\nI think that might be a very poor choice. Then what they do is they build\na minimum spanning tree on all",
    "start": "3771990",
    "end": "3782070"
  },
  {
    "text": "of the patient or cells. So the way that one\ndoes that is you create a graph by drawing\nan edge between every pair",
    "start": "3782070",
    "end": "3791220"
  },
  {
    "text": "of nodes where the\nweight of the edge is the Euclidean distance\nbetween those two points.",
    "start": "3791220",
    "end": "3797625"
  },
  {
    "text": " And then-- so for example, there\nis this edge from here to here,",
    "start": "3797625",
    "end": "3803190"
  },
  {
    "text": "there's an edge from\nhere to here and so on. And then given that\nweighted graph,",
    "start": "3803190",
    "end": "3808740"
  },
  {
    "text": "we're going to find the minimum\nspanning tree of that graph, and what I'm showing you here\nis the minimum spanning tree",
    "start": "3808740",
    "end": "3814590"
  },
  {
    "text": "of the corresponding graph, OK? Next, what one\nwill do is go look",
    "start": "3814590",
    "end": "3819920"
  },
  {
    "text": "for the longest\npath in that tree.",
    "start": "3819920",
    "end": "3825440"
  },
  {
    "text": "Remember, finding the\nlongest path in a graph-- in an arbitrary\ngraph has a name,",
    "start": "3825440",
    "end": "3830609"
  },
  {
    "text": "it's called the traveling\nsalesman problem and it's the NP-hard problem. How has that gotten around here?",
    "start": "3830610",
    "end": "3836230"
  },
  {
    "text": "Well we're not-- this is\nnot an arbitrary graph, this is actually a tree. So here's that poor--",
    "start": "3836230",
    "end": "3843460"
  },
  {
    "text": "here's a algorithm for\nfinding the longest path. I won't talk about that.",
    "start": "3843460",
    "end": "3851359"
  },
  {
    "text": "So one finds along\nthis path in a tree-- in the tree, and then\nwhat one does is one says,",
    "start": "3851360",
    "end": "3857820"
  },
  {
    "text": "OK, one side of the\npath corresponds to, let's say, early disease stage\nand the other side of the path",
    "start": "3857820",
    "end": "3863750"
  },
  {
    "text": "corresponds to\nlate disease stage, and it allows for\nthe fact that there might be some bifurcation.",
    "start": "3863750",
    "end": "3868820"
  },
  {
    "text": "So for example, you\nsee here that there is a bifurcation over here. And as we discussed\nearlier, you have",
    "start": "3868820",
    "end": "3875120"
  },
  {
    "text": "to have some way\nof differentiating what the beginning is and\nwhat the end should be, and that's where some side\ninformation might become",
    "start": "3875120",
    "end": "3881325"
  },
  {
    "text": "useful. So here's an illustration\nof applying that method to some real data.",
    "start": "3881325",
    "end": "3887490"
  },
  {
    "text": "So every point here\nis a cell after doing",
    "start": "3887490",
    "end": "3892640"
  },
  {
    "text": "dimensionality reduction. The edges between\nthose points correspond to the edges of the\nminimum spanning tree,",
    "start": "3892640",
    "end": "3899780"
  },
  {
    "text": "and now what the\nauthors have done is they've actually used some\nside information that they had in order to color\neach of the nodes",
    "start": "3899780",
    "end": "3907490"
  },
  {
    "text": "based on what part of the\ncell differentiation process is believed-- that cell\nis believed to be in.",
    "start": "3907490",
    "end": "3914480"
  },
  {
    "text": "And what one discovers,\nthat in fact, this is very sensible, that\nall of these points",
    "start": "3914480",
    "end": "3921410"
  },
  {
    "text": "are in a much\nearlier disease stage than [INAUDIBLE]\nthan these points,",
    "start": "3921410",
    "end": "3927109"
  },
  {
    "text": "and this is a\nsensible bifurcation",
    "start": "3927110",
    "end": "3933050"
  },
  {
    "text": "Next I want to talk about a\nslightly different approach to-- this is the whole story,\nby the way, right?",
    "start": "3933050",
    "end": "3938090"
  },
  {
    "text": "It's conceptually a very,\nvery simple approach. Next I want to talk about\na different approach, which",
    "start": "3938090",
    "end": "3943750"
  },
  {
    "text": "now tries to return back to\nthe probabilistic approaches that we had earlier\nin the lecture.",
    "start": "3943750",
    "end": "3951490"
  },
  {
    "text": "This new approach is going to\nbe based on Gaussian processes.",
    "start": "3951490",
    "end": "3957293"
  },
  {
    "text": "So Gaussian processes have\ncome up a couple of times in lecture, but\nI've never actually formally defined them for you. So in order for what I'm going\nto say next to make sense,",
    "start": "3957293",
    "end": "3964655"
  },
  {
    "text": "I'm going to formally define for\nyou what a Gaussian process is. A Gaussian process mu for a\ncollection of time points,",
    "start": "3964655",
    "end": "3974119"
  },
  {
    "text": "T1 through T capital\nN, is defined by a joint distribution,\nmu, of those time points,",
    "start": "3974120",
    "end": "3983310"
  },
  {
    "text": "which is a Gaussian\ndistribution. So we're going to\nsay that the function value for these T different\ntime points is just",
    "start": "3983310",
    "end": "3991290"
  },
  {
    "text": "a Gaussian, which for the\npurpose of today's lecture I'm going to assume\nis zero mean, and where the covariance\nfunction is given",
    "start": "3991290",
    "end": "3998190"
  },
  {
    "text": "to you by this capital K, it's a\ncovariance function of the time points-- of the input points.",
    "start": "3998190",
    "end": "4006180"
  },
  {
    "text": "And so if you look-- this has to be a matrix\nof dimension capital N",
    "start": "4006180",
    "end": "4012050"
  },
  {
    "text": "by capital N. And if you look\nat the I1 and I2 of the N tree, if you look at the N\ntree of that matrix,",
    "start": "4012050",
    "end": "4020090"
  },
  {
    "text": "we're defining it to be given\nto by the following kernel function. It looks at the exponential\nof the negative Euclidean",
    "start": "4020090",
    "end": "4029510"
  },
  {
    "text": "distance squared between\nthose two time points. Intuitively what\nthis is saying is",
    "start": "4029510",
    "end": "4035450"
  },
  {
    "text": "that if you have\ntwo time points that are very close to\none another, then",
    "start": "4035450",
    "end": "4040700"
  },
  {
    "text": "this kernel function is\ngoing to be very large. If you have two time points that\nare very far from one another,",
    "start": "4040700",
    "end": "4048710"
  },
  {
    "text": "then this is very large-- it's\na very large negative number, and so this is going\nto be very small.",
    "start": "4048710",
    "end": "4054260"
  },
  {
    "text": "So the kernel function\nfor two inputs that are very far from\nanother are very small; the kernel function\nfor inputs that",
    "start": "4054260",
    "end": "4059358"
  },
  {
    "text": "are very close to\neach other is large; and thus, what\nwe're saying here is that there's going to be some\ncorrelation between nearby data",
    "start": "4059358",
    "end": "4066960"
  },
  {
    "text": "points. And that's the way which\nwe're going to specify a distribution of functions.",
    "start": "4066960",
    "end": "4073480"
  },
  {
    "text": "If one were to sample\nfrom this Gaussian with a covariance function\nspecified in the way I did,",
    "start": "4073480",
    "end": "4078760"
  },
  {
    "text": "what one gets out is something\nthat looks like this. So I'm assuming\nhere that every--",
    "start": "4078760",
    "end": "4087559"
  },
  {
    "text": "that these curves\nlook really dense, and that's because I'm assuming\nthe N is extremely large here.",
    "start": "4087560",
    "end": "4093810"
  },
  {
    "text": "If and what small, let's\nsay 3, there'd only be three time points here, OK? And so if you can make this\ndistribution of functions",
    "start": "4093810",
    "end": "4103339"
  },
  {
    "text": "be arbitrarily complex by\nplaying with this little l-- so for example, if you made\na little l be very small,",
    "start": "4103340",
    "end": "4114950"
  },
  {
    "text": "then what you get are these\nreally spiky functions that I'm showing you\nin a very light color. If you make a little\nl be very large,",
    "start": "4114950",
    "end": "4122210"
  },
  {
    "text": "you get these very\nsmooth functions, right? So this is a way to get a\nfunction-- this is a way",
    "start": "4122210",
    "end": "4128620"
  },
  {
    "text": "to get a distribution\nover functions just by sampling from\nthis Gaussian process.",
    "start": "4128620",
    "end": "4135130"
  },
  {
    "text": "What this paper does from\nCampbell and Yau published two years ago in\nComputational Biology",
    "start": "4135130",
    "end": "4141870"
  },
  {
    "text": "is they assume that the\nobservations that you have",
    "start": "4141870",
    "end": "4147790"
  },
  {
    "text": "are drawn from a Gaussian\ndistribution whose mean is",
    "start": "4147790",
    "end": "4153700"
  },
  {
    "text": "given to you by the\nGaussian process. So if you think back to the\nstory that we drew earlier,",
    "start": "4153700",
    "end": "4167130"
  },
  {
    "text": "suppose that the data lived\nin just one dimension,",
    "start": "4167130",
    "end": "4173229"
  },
  {
    "text": "and suppose we actually knew\nthe sorting of patients. So we actually\nknew which patients",
    "start": "4173229",
    "end": "4179130"
  },
  {
    "text": "are very early in time, which\npatients are very late in time.",
    "start": "4179130",
    "end": "4185199"
  },
  {
    "text": "You might imagine that that\nsingle biomarker, biomarker A,",
    "start": "4185200",
    "end": "4191380"
  },
  {
    "text": "you might imagine that the\nfunction which tells you what the biomarker's value\nis as a function of time",
    "start": "4191380",
    "end": "4198820"
  },
  {
    "text": "might be something\nlike this, right? Or maybe it's something\nlike that, OK?",
    "start": "4198820",
    "end": "4204970"
  },
  {
    "text": "So it might be a function\nthat's increasing or a function that's decreasing. And this function\nis precisely what",
    "start": "4204970",
    "end": "4212739"
  },
  {
    "text": "this mu, this Gaussian\nprocess is meant to model. The only difference is that\nnow, one can model the Gaussian",
    "start": "4212740",
    "end": "4220120"
  },
  {
    "text": "process-- instead of just\nbeing a single dimension, one could imagine having\nseveral different dimensions.",
    "start": "4220120",
    "end": "4225500"
  },
  {
    "text": "So this P denotes the\nnumber of dimensions, right? Which corresponds\nto, in some sense,",
    "start": "4225500",
    "end": "4231490"
  },
  {
    "text": "to the number of\nsynthetic biomarkers that you might conjecture exist.",
    "start": "4231490",
    "end": "4236860"
  },
  {
    "text": "Now here, we truly don't\nknow the sorting of patients into early versus late stage.",
    "start": "4236860",
    "end": "4243020"
  },
  {
    "text": "And so the time points\nT are themselves assumed to be latent\nvariables that",
    "start": "4243020",
    "end": "4249610"
  },
  {
    "text": "are drawn from a truncated\nnormal distribution that looks like this. So you might make\nsome assumption",
    "start": "4249610",
    "end": "4255580"
  },
  {
    "text": "that the time intervals\nfor when a patient comes in might be, maybe patients\ncome in really typically very",
    "start": "4255580",
    "end": "4262022"
  },
  {
    "text": "in the middle of\nthe disease stage, or maybe you're assuming\nit's something flat, an so patients come in\nthroughout the disease stage.",
    "start": "4262022",
    "end": "4267750"
  },
  {
    "text": "But the time point\nitself is latent. So now the generative process\nfor the data is as follows.",
    "start": "4267750",
    "end": "4273199"
  },
  {
    "text": "You first sample\na time point from this truncated normal\ndistribution, then",
    "start": "4273200",
    "end": "4278619"
  },
  {
    "text": "you look to see-- oh, and you sample\nfrom the very beginning your sample this\ncurve mu, and then you",
    "start": "4278620",
    "end": "4287500"
  },
  {
    "text": "look to see, what is the value\nof mu for the sample time point, and that gives you\nthe expected value you should",
    "start": "4287500",
    "end": "4293440"
  },
  {
    "text": "expect to see for that patient. And the one, then,\njointly optimizes",
    "start": "4293440",
    "end": "4301670"
  },
  {
    "text": "this to try to find the most-- the curve, the curve mu\nwhich has highest posterior",
    "start": "4301670",
    "end": "4308450"
  },
  {
    "text": "probability, and that is how\nyou read out from the model both what the latent\nprogression looks",
    "start": "4308450",
    "end": "4317815"
  },
  {
    "text": "like, and if you look at\nthe posterior distribution over the T's that are\ninferred for each individual, you get the inferred\nlocation along the trajectory",
    "start": "4317815",
    "end": "4325070"
  },
  {
    "text": "for each individual. And I'll stop there. I'll post the slides\nonline for this last piece,",
    "start": "4325070",
    "end": "4331200"
  },
  {
    "text": "but I'll let you read\nthe paper on your own. ",
    "start": "4331200",
    "end": "4348000"
  }
]
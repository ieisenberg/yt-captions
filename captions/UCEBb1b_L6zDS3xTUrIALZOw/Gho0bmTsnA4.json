[
  {
    "start": "0",
    "end": "150000"
  },
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6360"
  },
  {
    "text": "continue to offer high-quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6360",
    "end": "13320"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13320",
    "end": "18369"
  },
  {
    "text": " RUSS TEDRAKE: So welcome back.",
    "start": "18370",
    "end": "23960"
  },
  {
    "text": " I thought we'd\nstart today sort of",
    "start": "23960",
    "end": "29000"
  },
  {
    "text": "with a little bit of\nreflection, since we have covered a lot of material.",
    "start": "29000",
    "end": "34250"
  },
  {
    "text": "Even though we've kept\nit to simple systems, we've actually covered\na lot of material, and we're about to blast\noff into some new material.",
    "start": "34250",
    "end": "41730"
  },
  {
    "text": "So I thought, let's\nmake sure everybody knows what we've done,\nroughly how it fits together,",
    "start": "41730",
    "end": "49520"
  },
  {
    "text": "and where we're going, OK? So I've been trying to\ncarry through the course two",
    "start": "49520",
    "end": "57470"
  },
  {
    "text": "main threads. One of them is sort\nof the systems thread. We start with pendula.",
    "start": "57470",
    "end": "62996"
  },
  {
    "text": "We're getting to\nacrobots, cart-poles. We're going to get more and\nmore interesting systems. In parallel, I'm trying to\ndesign this optimal control",
    "start": "62997",
    "end": "70580"
  },
  {
    "text": "thread which tells\nyou the way I think you should be solving these.",
    "start": "70580",
    "end": "75680"
  },
  {
    "text": "Along the way, I'm throwing\nin lots of puzzle pieces about partial feedback,\nlinearization, energy shaping,",
    "start": "75680",
    "end": "82460"
  },
  {
    "text": "things like this.  That's because this is\na hard-thought decision.",
    "start": "82460",
    "end": "90660"
  },
  {
    "text": "I mean, this is a\nresearch class, really. So I'm doing my very best to\nteach all this material to you",
    "start": "90660",
    "end": "96170"
  },
  {
    "text": "as if there's a\ntextbook on this. But in fact,\nthere's no textbook. So what I've decided\nto do roughly",
    "start": "96170",
    "end": "102469"
  },
  {
    "text": "is that, I'm trying to give you\na very clean line of thinking through the optimal control.",
    "start": "102470",
    "end": "108657"
  },
  {
    "text": "But I do want to keep throwing\nin what other people do-- the domain-specific knowledge\nabout acrobots and cart-poles and walking as we get to it.",
    "start": "108657",
    "end": "115460"
  },
  {
    "text": "Because I think these\npuzzle pieces-- ultimately, there are things we can't\ndo with optimal control yet.",
    "start": "115460",
    "end": "120560"
  },
  {
    "text": "My guess is that ideas from\npartial feedback linearization are going to help. I think ideas from energy\nshaping-- these kind of ideas",
    "start": "120560",
    "end": "126650"
  },
  {
    "text": "are going to work together. So even though those aren't\ngoing to connect up perfectly in this class, what\nI'm hoping to do",
    "start": "126650",
    "end": "132440"
  },
  {
    "text": "is give you all the\npieces of a puzzle that nobody's\nactually solved yet, give you all the\ninformation I can give you",
    "start": "132440",
    "end": "139640"
  },
  {
    "text": "about this class of\nproblems so you can go off and write, well, final\nprojects that are",
    "start": "139640",
    "end": "146838"
  },
  {
    "text": "cited a hundred thousand times.  OK. So let me just make\nsure that's happening.",
    "start": "146838",
    "end": "153230"
  },
  {
    "start": "150000",
    "end": "330000"
  },
  {
    "text": "So that's a tall order to\nsort of carry those threads. So let's make sure\nthat's happening. Maybe I'll even use\na whole board for it.",
    "start": "153230",
    "end": "159860"
  },
  {
    "start": "159860",
    "end": "167290"
  },
  {
    "text": "So I think I've made\nno secret of the fact that I think optimal control\nis a sort of defining way",
    "start": "167290",
    "end": "176200"
  },
  {
    "text": "to think about control for even\nthese very complicated systems. All right. So we've got one\nthread that we'll",
    "start": "176200",
    "end": "182470"
  },
  {
    "text": "continue-- we'll get deeper and\ndeeper in about optimal control methods.",
    "start": "182470",
    "end": "189640"
  },
  {
    "text": "In particular,\nwe've already talked about sort of two fundamentally\ndifferent approaches",
    "start": "189640",
    "end": "195520"
  },
  {
    "text": "to optimal control. We've talked about\noptimal control based on the\nHamilton-Jacobi-Bellman",
    "start": "195520",
    "end": "200560"
  },
  {
    "text": "equations, where we talked\nabout the value function being",
    "start": "200560",
    "end": "207340"
  },
  {
    "text": "described by a nonlinear\npartial differential equation. ",
    "start": "207340",
    "end": "214300"
  },
  {
    "text": "And then we also talked about\nPontryagin's minimum principle,",
    "start": "214300",
    "end": "219940"
  },
  {
    "text": "which you're probably all\nworking on right now-- Pontryagin's minimum principle.",
    "start": "219940",
    "end": "229150"
  },
  {
    "text": "These were two sort of\nanalytical optimal control approaches, right?",
    "start": "229150",
    "end": "234250"
  },
  {
    "start": "234250",
    "end": "248430"
  },
  {
    "text": "As such, unfortunately,\nwe only showed you much of anything\non linear systems",
    "start": "248430",
    "end": "256500"
  },
  {
    "text": "where we can actually solve\nthose problems analytically. ",
    "start": "256500",
    "end": "262680"
  },
  {
    "text": "What were the big differences? Maybe I-- just to motivate\nthis so you make-- so make sure everybody pays attention.",
    "start": "262680",
    "end": "268350"
  },
  {
    "text": "I should also say a few things\nabout what I hope you get out of the class, and for instance,\nwhat will be on the midterm",
    "start": "268350",
    "end": "273720"
  },
  {
    "text": "when it comes around. So I know that we're\nthrowing lots of ideas out.",
    "start": "273720",
    "end": "279840"
  },
  {
    "text": "If there's one\nthing that happens, one thing that you\nshould be able to do off the top of your\nhead is think about",
    "start": "279840",
    "end": "285750"
  },
  {
    "text": "and talk about how these\ndifferent tools that we're putting out relate to\ndifferent problems.",
    "start": "285750",
    "end": "291600"
  },
  {
    "text": "And for instance, if I\nwere to give you a problem, you could make some reasonable\nguess at what kind of-- what",
    "start": "291600",
    "end": "298483"
  },
  {
    "text": "methods that we've\ntalked about might be most suitable for that problem.",
    "start": "298483",
    "end": "304590"
  },
  {
    "text": "The details of how you do a\npartial feedback linearization, I wouldn't expect you to\nabsorb every piece of that.",
    "start": "304590",
    "end": "310920"
  },
  {
    "text": "I would guide you through\nthat on a problem, but with the expectation that\nyou've worked through it once on a problem set and sort of\nhave some ability to do that.",
    "start": "310920",
    "end": "319660"
  },
  {
    "text": "But if there's one thing\nI want you to come away from this class with, I\nwant you to understand",
    "start": "319660",
    "end": "325140"
  },
  {
    "text": "the suite of tools\nwe're talking about and have a sense for what\nyou'd apply to what problem. ",
    "start": "325140",
    "end": "332890"
  },
  {
    "start": "330000",
    "end": "540000"
  },
  {
    "text": "So in the\nHamilton-Jacobi-Bellman equation, we applied it to-- we applied that--\nwhich, remember,",
    "start": "332890",
    "end": "343080"
  },
  {
    "text": "was this partial\ndifferential equation,",
    "start": "343080",
    "end": "356849"
  },
  {
    "text": "with a hard nonlinearity, which\ndescribes the optimal solution. ",
    "start": "356850",
    "end": "365100"
  },
  {
    "text": "I should put stars on here\nto be here careful here. The optimal cost-to-go is\ndescribed by that equation.",
    "start": "365100",
    "end": "372360"
  },
  {
    "text": "So one approach\nto these things is to directly try to\ncompute solutions to this partial\ndifferential equation.",
    "start": "372360",
    "end": "379590"
  },
  {
    "text": "We did it analytically for the\nquadratic regulator problems,",
    "start": "379590",
    "end": "384750"
  },
  {
    "text": "the linear quadratic regulators. ",
    "start": "384750",
    "end": "402646"
  },
  {
    "text": "Right. I didn't actually do it for\nthe minimum time problem,",
    "start": "402646",
    "end": "407930"
  },
  {
    "text": "because the minimum\ntime problem,",
    "start": "407930",
    "end": "413810"
  },
  {
    "text": "we know that the optimal\nsolution in J is actually not-- its gradients are\nnot well-defined",
    "start": "413810",
    "end": "419990"
  },
  {
    "text": "across the entire-- for all x. That's the only reason\nI didn't do it for that.",
    "start": "419990",
    "end": "425760"
  },
  {
    "text": "But for sort of\nsmooth problems like the linear quadratic regulators,\nwe could use these methods.",
    "start": "425760",
    "end": "431510"
  },
  {
    "text": "Pontryagin is a little\nbit more general. This is the one with\nthe adjoint equation.",
    "start": "431510",
    "end": "439129"
  },
  {
    "text": "So you defined the\nHamiltonian is here",
    "start": "439130",
    "end": "448250"
  },
  {
    "text": "some cost function plus Lagrange\nvariable, Lagrange multiplier times your dynamics.",
    "start": "448250",
    "end": "453610"
  },
  {
    "start": "453610",
    "end": "459490"
  },
  {
    "text": "Pontryagin was more powerful. In some sense, we\nsolved harder problems. We solved, for instance,\nthe minimum time problem,",
    "start": "459490",
    "end": "469540"
  },
  {
    "text": "for the double\nintegrator, at least.  The problem with it is\njust that it was too local.",
    "start": "469540",
    "end": "478180"
  },
  {
    "text": "The Pontryagin ideas are\nbased on a gradient statement",
    "start": "478180",
    "end": "487240"
  },
  {
    "text": "of local optimality. ",
    "start": "487240",
    "end": "505220"
  },
  {
    "text": "So we said along\nsome trajectory, I can verify that if\nI change my control",
    "start": "505220",
    "end": "510470"
  },
  {
    "text": "action a little bit\nalong this trajectory, my cost is only\ngoing to get worse.",
    "start": "510470",
    "end": "515979"
  },
  {
    "text": "So that's a necessary\ncondition for optimality. That's when we can do\na lot of things with-- but it's only going to give me\na local optimality statement.",
    "start": "515980",
    "end": "524410"
  },
  {
    "text": "Are people sort of OK with those\ntwo methods we've been doing? ",
    "start": "524410",
    "end": "539500"
  },
  {
    "text": "OK. From the Hamilton-Jacobi\nway of thinking,",
    "start": "539500",
    "end": "544660"
  },
  {
    "start": "540000",
    "end": "735000"
  },
  {
    "text": "we ended up with\nour first algorithm. ",
    "start": "544660",
    "end": "569927"
  },
  {
    "text": "Right. And we said that you could\ndiscretize the dynamics,",
    "start": "569927",
    "end": "575580"
  },
  {
    "text": "and in the discrete\ndynamics solve whatever nonlinear problem\nyou wanted, pretty much.",
    "start": "575580",
    "end": "580980"
  },
  {
    "start": "580980",
    "end": "609699"
  },
  {
    "text": "Right. And the reason we\ncould do that is because these Bellman equations\nhave this nice form that--",
    "start": "609700",
    "end": "620280"
  },
  {
    "text": "there's a nice recursive form. It was that J at some x,\nn is just the min over u.",
    "start": "620280",
    "end": "627340"
  },
  {
    "text": "This is now-- maybe I should\nbe very careful when I write it in discrete, because that's\nwhat we talked about it in min",
    "start": "627340",
    "end": "634470"
  },
  {
    "text": "over actions A, discrete actions\nA, S A plus the J of S prime,",
    "start": "634470",
    "end": "647769"
  },
  {
    "text": "where S prime is what\nI get for doing this. ",
    "start": "647770",
    "end": "670080"
  },
  {
    "text": "OK. ",
    "start": "670080",
    "end": "677650"
  },
  {
    "text": "So if you sort of\nlook at where there's white space left\non this board, you might be able to\nguess what we're",
    "start": "677650",
    "end": "684130"
  },
  {
    "text": "going to do next, our next\nbig piece of the puzzle. We're going to derive our\nfirst set of algorithms",
    "start": "684130",
    "end": "691120"
  },
  {
    "text": "now from the sort of\nPontryagin methods. ",
    "start": "691120",
    "end": "696870"
  },
  {
    "text": "And we're going to talk\nabout some policy search methods, the most\nimportant class",
    "start": "696870",
    "end": "712330"
  },
  {
    "text": "being of trajectory\noptimization. ",
    "start": "712330",
    "end": "728030"
  },
  {
    "text": "OK. ",
    "start": "728030",
    "end": "736220"
  },
  {
    "start": "735000",
    "end": "1185000"
  },
  {
    "text": "Along the way, we've been sort\nof following this systems, we're developing\nthese systems, right?",
    "start": "736220",
    "end": "742570"
  },
  {
    "text": " In the optimal control, the\nanalytical optimal control,",
    "start": "742570",
    "end": "750920"
  },
  {
    "text": "we mostly just thought\nabout double integrators. ",
    "start": "750920",
    "end": "759680"
  },
  {
    "text": "But those things could have\napplied to any LTI system.",
    "start": "759680",
    "end": "767945"
  },
  {
    "text": " So that's supposed to\nbe in line with that.",
    "start": "767945",
    "end": "774880"
  },
  {
    "text": "I'll do my best to not move the\nboard too many times in this. ",
    "start": "774880",
    "end": "782019"
  },
  {
    "text": "We moved on to sort\nof pendulums, pendula.",
    "start": "782020",
    "end": "789760"
  },
  {
    "text": "And we did the essential things. This is where I used to sort\nof tell you about dynamics.",
    "start": "789760",
    "end": "796900"
  },
  {
    "text": "We talked about nonlinear\ndynamics, basins of attraction, all these things. ",
    "start": "796900",
    "end": "824480"
  },
  {
    "text": "And then we did\nacrobots and cart-poles, where we talked about a\nlot of interesting ideas. We talked about\ncontrollability, we",
    "start": "824480",
    "end": "835340"
  },
  {
    "text": "talked about partial\nfeedback linearization, and we talked about energy\nshaping, even tasks-based.",
    "start": "835340",
    "end": "848510"
  },
  {
    "text": " Lots of ideas in there.",
    "start": "848510",
    "end": "853580"
  },
  {
    "start": "853580",
    "end": "859700"
  },
  {
    "text": "Those ideas are my attempt\nto extract the most general.",
    "start": "859700",
    "end": "867200"
  },
  {
    "text": "But the main topics of the sort\nof acrobot/cart-pole world,",
    "start": "867200",
    "end": "873123"
  },
  {
    "text": "in acrobots and cart-poles,\npeople talk about PFL heavily. They talk energy\nshaping, they talk about these kind of things.",
    "start": "873123",
    "end": "878187"
  },
  {
    "text": "I only presented the\nones that I think are going to be\nuseful in general. But to some extent,\nright now you",
    "start": "878187",
    "end": "884870"
  },
  {
    "text": "could think about\nthese techniques as being orthogonal to our\nmain line of thinking, OK?",
    "start": "884870",
    "end": "891860"
  },
  {
    "start": "891860",
    "end": "897680"
  },
  {
    "text": "Now, like I said,\nthis is a puzzle that nobody has\nthe answer to yet. So actually, what I want\nyou to be thinking here is,",
    "start": "897680",
    "end": "905228"
  },
  {
    "text": "what can we do with\nall these things?  So for instance, I told you that\ndynamic programming works well",
    "start": "905228",
    "end": "913010"
  },
  {
    "text": "for low-dimensional systems. Nonlinear systems, no problem.",
    "start": "913010",
    "end": "918230"
  },
  {
    "text": "Low-dimensional, I can\ndiscretize the space, I can just run my algorithm,\nbup-bup-bup-bup-bup,",
    "start": "918230",
    "end": "923810"
  },
  {
    "text": "compute the optimal\ncost-to-go optimal policy.",
    "start": "923810",
    "end": "929670"
  },
  {
    "text": "OK. But so maybe there's\nobvious things to do. And actually, I think there are\nobvious things to think about--",
    "start": "929670",
    "end": "938005"
  },
  {
    "text": "research questions that\nyou could be thinking about for your final projects, right? So for instance, you know,\nwe used partial feedback",
    "start": "938005",
    "end": "944750"
  },
  {
    "text": "linearization to take--\nat least linearize part of the dynamics of the system.",
    "start": "944750",
    "end": "951470"
  },
  {
    "text": "So this is wild\nspeculation here, but let's say I have a\nproblem that I could then",
    "start": "951470",
    "end": "957260"
  },
  {
    "text": "describe as x1 dot is A1 x1\nplus A2 x2 plus Bu then x2 dot",
    "start": "957260",
    "end": "969080"
  },
  {
    "text": "equals f of x1, x2, u, where,\nlet's say, the dimension of x2",
    "start": "969080",
    "end": "982900"
  },
  {
    "text": "is much, much less\nthan the dimensions of the whole original\nsystem, which is what I get--",
    "start": "982900",
    "end": "992922"
  },
  {
    "text": "that's the result. That's the\nresult I would get from doing a partial feedback\nlinearization, where I have, let's say, for Little Dog,\nand I have five degrees",
    "start": "992922",
    "end": "1000540"
  },
  {
    "text": "of freedom and four\nactuators, that I'd end up with sort of one very\nnonlinear thing and then",
    "start": "1000540",
    "end": "1008310"
  },
  {
    "text": "a bunch of very linear dynamics\nafter doing a partial feedback linearization. So fantastic research question--",
    "start": "1008310",
    "end": "1016500"
  },
  {
    "text": "so could I use that\ntrick and combine it with dynamic\nprogramming, let's say,",
    "start": "1016500",
    "end": "1022139"
  },
  {
    "text": "to use dynamic programming\nto solve the hard part and do some sort of LQR\nto solve the easy part?",
    "start": "1022140",
    "end": "1029218"
  },
  {
    "text": "I don't know. Probably you can. I bet you can. And I'd be excited to think\nabout, with any of you,",
    "start": "1029218",
    "end": "1034593"
  },
  {
    "text": "you know, what you could do. But these are the reasons I'm\nsaying things like PFL, right? So imagine doing PFL\nplus dynamic programming.",
    "start": "1034593",
    "end": "1044490"
  },
  {
    "text": "I'd bet you could do\nhigher-dimensional optimization if you could exploit\ntricks like that.",
    "start": "1044490",
    "end": "1051450"
  },
  {
    "text": "So that'd be a fantastic\nsort of research question to think about for your project.",
    "start": "1051450",
    "end": "1059490"
  },
  {
    "start": "1059490",
    "end": "1064920"
  },
  {
    "text": "Are people sort of OK\nwith how this is going? Yeah?",
    "start": "1064920",
    "end": "1070095"
  },
  {
    "text": "AUDIENCE: Are any of those\n[INAUDIBLE] dimension that [INAUDIBLE] convergence or--",
    "start": "1070095",
    "end": "1076150"
  },
  {
    "text": "RUSS TEDRAKE: Good, OK. So they're not explicitly--\nthese are not explicitly",
    "start": "1076150",
    "end": "1082280"
  },
  {
    "text": "targeted to solving\noptimal control problem. So proof of convergence, we\nhave to define what we mean.",
    "start": "1082280",
    "end": "1088370"
  },
  {
    "text": "I mean, PFL,\ncertifiably, provides this sort of a dynamics.",
    "start": "1088370",
    "end": "1094370"
  },
  {
    "text": "The energy shaping,\nunder some conditions, we showed we could regulate\nthe energy of our systems.",
    "start": "1094370",
    "end": "1102290"
  },
  {
    "text": "So there's-- each of these\nhave their own sort of proofs",
    "start": "1102290",
    "end": "1107450"
  },
  {
    "text": "and task space. But most of them\nare not directly aimed at proving that you've\nobtained some optimal policy.",
    "start": "1107450",
    "end": "1112795"
  },
  {
    "text": "AUDIENCE: If you\nobtain a kind of policy which would [INAUDIBLE] goal. If you have a specific\nstate that you want to be",
    "start": "1112795",
    "end": "1120650"
  },
  {
    "text": "in [INAUDIBLE] to get to that,\nmaybe not optimally but--",
    "start": "1120650",
    "end": "1126318"
  },
  {
    "text": "RUSS TEDRAKE: Good. So in the energy\nshaping I talked about for the cart-pole-- the energy shaping plus\nPFL that I talked about",
    "start": "1126318",
    "end": "1132150"
  },
  {
    "text": "for the cart-pole and swing-up,\nthere's a citation in the notes",
    "start": "1132150",
    "end": "1137250"
  },
  {
    "text": "of a guy that proved that for\na set of parameters-- well, I'm being a little flippant--",
    "start": "1137250",
    "end": "1143282"
  },
  {
    "text": "there's a little--\nthere's a regime where that's guaranteed to work. But the general proof that\nyou'd like to have is not there.",
    "start": "1143282",
    "end": "1149190"
  },
  {
    "text": "For the acrobot, I know about\neven less proof to that. There is one\nparticular controller",
    "start": "1149190",
    "end": "1154290"
  },
  {
    "text": "that we implemented that someone\nwho took the class implemented before. And it does have\na Lyapunov proof",
    "start": "1154290",
    "end": "1161953"
  },
  {
    "text": "saying it'll get to the top. But it sort of works by going-- this is an acrobots. It's going ee-ee-ee-ee.",
    "start": "1161953",
    "end": "1167159"
  },
  {
    "text": "It's like really unattractive. So it does something\nreally stupid. You wouldn't want to run\nit on your real robot,",
    "start": "1167160",
    "end": "1172230"
  },
  {
    "text": "probably, unless\nyou're very patient. But it has a proof\nto get to the top.",
    "start": "1172230",
    "end": "1177255"
  },
  {
    "text": "So these are the trade-offs\nthat people make. ",
    "start": "1177255",
    "end": "1184000"
  },
  {
    "text": "OK. Right. So I hope that sort of-- ",
    "start": "1184000",
    "end": "1190263"
  },
  {
    "start": "1185000",
    "end": "1648000"
  },
  {
    "text": "I hope that was worth doing. I just wanted to quickly make\nsure we're all calibrated. So let's talk a\nminute now about--",
    "start": "1190263",
    "end": "1197174"
  },
  {
    "text": " so I said that for\nthe dynamic program",
    "start": "1197175",
    "end": "1202410"
  },
  {
    "text": "we showed it working\non the pendulum. I put a big asterisk\nsaying that there's",
    "start": "1202410",
    "end": "1207540"
  },
  {
    "text": "discretization errors present. So even for the pendulum,\nit'll solve it lightning fast.",
    "start": "1207540",
    "end": "1213090"
  },
  {
    "text": "But it's solving the\ndiscretized system, not the continuous system. And the optimal\npolicy you get out",
    "start": "1213090",
    "end": "1219270"
  },
  {
    "text": "could be different\nthan the optimal policy for the continuous system. OK.",
    "start": "1219270",
    "end": "1224550"
  },
  {
    "text": "So can you do\ndynamic programming for the acrobot and cart-pole? That's an obvious question.",
    "start": "1224550",
    "end": "1231940"
  },
  {
    "text": "So the answer is yes. People have done it. My code on the\nacrobot and cart-pole",
    "start": "1231940",
    "end": "1239250"
  },
  {
    "text": "runs in a few seconds. It's not a problem\nof dimensionality. But the results are not--",
    "start": "1239250",
    "end": "1246630"
  },
  {
    "text": "of my code-- are not\nsatisfying because of exactly",
    "start": "1246630",
    "end": "1252290"
  },
  {
    "text": "the asterisks I put\non the pendulum. So let's just sort of\nevaluate dynamic programming",
    "start": "1252290",
    "end": "1258900"
  },
  {
    "text": "as we go forward. ",
    "start": "1258900",
    "end": "1280470"
  },
  {
    "text": "So absolutely, the\nacrobot and the cart-pole both have four-dimensional state\nspace, one-dimensional action",
    "start": "1280470",
    "end": "1292260"
  },
  {
    "text": "space. ",
    "start": "1292260",
    "end": "1302620"
  },
  {
    "text": "Easily discretized these days. ",
    "start": "1302620",
    "end": "1308190"
  },
  {
    "text": "That's still\nlow-dimensional enough that I can actually\nbin up the space.",
    "start": "1308190",
    "end": "1315010"
  },
  {
    "text": "That wasn't true. When people weer doing it in\nthe '80s, but it's true today. OK. ",
    "start": "1315010",
    "end": "1323740"
  },
  {
    "text": "The only real problem\nwith it is that there's",
    "start": "1323740",
    "end": "1331450"
  },
  {
    "text": "discretization error. ",
    "start": "1331450",
    "end": "1344379"
  },
  {
    "text": "And essentially, the\ndiscretized dynamics",
    "start": "1344380",
    "end": "1353170"
  },
  {
    "text": "can be a poor representation\nof the continuous dynamics.",
    "start": "1353170",
    "end": "1366490"
  },
  {
    "text": " If you spend a lot of\ntime with the acrobot,",
    "start": "1366490",
    "end": "1372759"
  },
  {
    "text": "you find actually the\nacrobot's dynamics are pretty-- are sort of wicked\nin a lot of ways.",
    "start": "1372760",
    "end": "1377780"
  },
  {
    "text": "So actually, spending a lot\nmore time about it recently-- ",
    "start": "1377780",
    "end": "1384880"
  },
  {
    "text": "I mean, even just\nsort of making sure that energy is\nconserved when you put no torque into your system--",
    "start": "1384880",
    "end": "1390813"
  },
  {
    "text": "this is the basic absolute\nthing you do to make sure you got your\nequations of motion--",
    "start": "1390813",
    "end": "1396309"
  },
  {
    "text": "the acrobot, you have to put\nyour integration tolerances up the wazoo to make sure\nyou conserve energy.",
    "start": "1396310",
    "end": "1402460"
  },
  {
    "text": "I mean, sort of\n[INAUDIBLE] resolution, the relative tolerance in the\nODE solver in Matlab had to be something like negative--",
    "start": "1402460",
    "end": "1409570"
  },
  {
    "text": "1 to the negative\nninth or something to make this thing\nintegrate and look",
    "start": "1409570",
    "end": "1414669"
  },
  {
    "text": "like it had a flat line and\nenergy as it's just swinging around with zero torque.",
    "start": "1414670",
    "end": "1419980"
  },
  {
    "text": "As a consequence, when\nyou discretize it, and you run your\noptimal control which",
    "start": "1419980",
    "end": "1425710"
  },
  {
    "text": "converges nicely on the\ndiscretized system, the same--",
    "start": "1425710",
    "end": "1431080"
  },
  {
    "text": "you can't discretize\nit with sort of 10 to the negative ninth precision.",
    "start": "1431080",
    "end": "1436240"
  },
  {
    "text": "And you'll find that your\ndiscretized system doesn't conserve energy, for instance. So that's what's one of\nthe major shortcomings.",
    "start": "1436240",
    "end": "1443125"
  },
  {
    "start": "1443125",
    "end": "1469360"
  },
  {
    "text": "OK. And so for that reason I'm\ngoing to move on in our-- when we're going to talk\nabout the optimal control",
    "start": "1469360",
    "end": "1475690"
  },
  {
    "text": "for the acrobot\nand the cart-pole, we're actually going to\nuse some other methods. But I don't want to\nmove on without seeding",
    "start": "1475690",
    "end": "1481465"
  },
  {
    "text": "the idea that there are\ngood ways-- there are ways to fix this, potentially. ",
    "start": "1481465",
    "end": "1487850"
  },
  {
    "text": "So for instance-- I mean, I think there's\nlots of good work to be done in sort of the\ndynamic programming world.",
    "start": "1487850",
    "end": "1494440"
  },
  {
    "text": "I think there are ideas\nfrom discrete mechanics",
    "start": "1494440",
    "end": "1511269"
  },
  {
    "text": "and from finite element methods,\nwhere people have thought",
    "start": "1511270",
    "end": "1522490"
  },
  {
    "text": "a lot about the consequences\nof discretizing PDEs and trying to, for instance, conserve\nquantities like energy.",
    "start": "1522490",
    "end": "1528179"
  },
  {
    "text": " My guess is if someone had\nsome excitement or experience",
    "start": "1528180",
    "end": "1536560"
  },
  {
    "text": "with these sort of\nmethods, I'd bet the next time I\nteach the class I can say it works for the acrobot.",
    "start": "1536560",
    "end": "1542440"
  },
  {
    "text": "So this would be a great\nfinal project, yeah? And publication.",
    "start": "1542440",
    "end": "1548567"
  },
  {
    "start": "1548567",
    "end": "1553930"
  },
  {
    "text": "Just do a smarter discretization\nof the dynamics, and then sort of-- so the discrete mechanics\nphilosophy is that",
    "start": "1553930",
    "end": "1560500"
  },
  {
    "text": "if you've taken your Lagrangian,\nand you've turned it into x dot",
    "start": "1560500",
    "end": "1569470"
  },
  {
    "text": "equals f of x, u and then you\ndiscretize, then you've done--",
    "start": "1569470",
    "end": "1574539"
  },
  {
    "text": "you've already-- it's too late. You've already killed the\nbeauty of the Lagrangian.",
    "start": "1574540",
    "end": "1579970"
  },
  {
    "text": "And the discrete\nmechanics point of view",
    "start": "1579970",
    "end": "1588309"
  },
  {
    "text": "is you should discretize\nthe Lagrangian, do discretization up here,\nand then carry that down",
    "start": "1588310",
    "end": "1596860"
  },
  {
    "text": "to your equations of motion. And these sort of discrete\nmechanics principles tend to have much\nbetter properties",
    "start": "1596860",
    "end": "1602530"
  },
  {
    "text": "and energy conservation\nand stuff like that. We might get to it in our\ntrajectory optimization family,",
    "start": "1602530",
    "end": "1609640"
  },
  {
    "text": "but there's a line\nof work now called discrete mechanics and\noptimal control that's",
    "start": "1609640",
    "end": "1628990"
  },
  {
    "text": "been done by Marsden and\nall at Caltech that I",
    "start": "1628990",
    "end": "1634840"
  },
  {
    "text": "think that's my\nbest lead right now and how to fix these problems. ",
    "start": "1634840",
    "end": "1648990"
  },
  {
    "start": "1648000",
    "end": "1863000"
  },
  {
    "text": "OK. There's another idea out there\nfor how to fix these problems. ",
    "start": "1648990",
    "end": "1655980"
  },
  {
    "text": "If you judge your problem is\njust that your discretization is bad, another big idea sort of\nis variable resolution methods,",
    "start": "1655980",
    "end": "1683970"
  },
  {
    "text": "which says, let's\nstick to our guns, discretization is\ngoing to work as long as I have enough resolution. And because of\ncomputational limitations,",
    "start": "1683970",
    "end": "1690179"
  },
  {
    "text": "I'm just going to make\nsure I put the resolution in the right places. So if you discretize the\npendulum or something",
    "start": "1690180",
    "end": "1700500"
  },
  {
    "text": "like this, when you do\nyour optimal control",
    "start": "1700500",
    "end": "1715290"
  },
  {
    "text": "solution on this,\nand you find out, for instance, that when you're\ntransitioning from this point--",
    "start": "1715290",
    "end": "1721410"
  },
  {
    "text": "this way, energy\nis not conserved. Or the value function\nat these corners are very, very different.",
    "start": "1721410",
    "end": "1728178"
  },
  {
    "text": "So it looks like there's\nsomething more going on there, then let's just add more\nresolution there, until--",
    "start": "1728178",
    "end": "1735320"
  },
  {
    "text": "as much as necessary, sort\nof, to capture the dynamics.",
    "start": "1735320",
    "end": "1740460"
  },
  {
    "text": "There's a nice line of work\nin this by Munos and Moore,",
    "start": "1740460",
    "end": "1749921"
  },
  {
    "text": "the same people I\nlisted for doing the barycentric interpolation. They talked about variable\nresolution DP methods.",
    "start": "1749921",
    "end": "1757800"
  },
  {
    "text": "I think Woody thinks\nthat this is our-- this is the way to\nget value iteration",
    "start": "1757800",
    "end": "1762809"
  },
  {
    "text": "to work on at least the minimum\ntime problem for the pendulum and for the brick--",
    "start": "1762810",
    "end": "1768750"
  },
  {
    "text": "that if you use the right\nsplitting criteria-- and that's the big question,\nI think, in this work is,",
    "start": "1768750",
    "end": "1774630"
  },
  {
    "text": "what's the right\nsplitting criteria-- ",
    "start": "1774630",
    "end": "1781650"
  },
  {
    "text": "then you can actually\nmaybe make serious progress on these problems. ",
    "start": "1781650",
    "end": "1797770"
  },
  {
    "text": "OK. So I've given you\na line of thinking about one class of algorithms\ndynamic programming.",
    "start": "1797770",
    "end": "1804659"
  },
  {
    "text": "We showed how they could apply\nto the pendulums and decided to not show how they don't\nquite work beautifully",
    "start": "1804660",
    "end": "1810030"
  },
  {
    "text": "for the acrobot/cart-pole. If I build an algorithm\nthat took overnight to run,",
    "start": "1810030",
    "end": "1815250"
  },
  {
    "text": "then I think it works. But they don't run sort of\nin real-time in the class, so let's leave it as\nfuture work to make better",
    "start": "1815250",
    "end": "1823552"
  },
  {
    "text": "to stay with programming\nalgorithms for pendula and acrobots. And I'm very, very\nserious about this.",
    "start": "1823552",
    "end": "1828990"
  },
  {
    "text": "These are not killer problems. These are problems that--",
    "start": "1828990",
    "end": "1835140"
  },
  {
    "text": "I mean, these tools sort of\nthat you see in the class, I think, just really haven't\nbeen put together before.",
    "start": "1835140",
    "end": "1841350"
  },
  {
    "text": "I think that we're\nlining up all the tools to solve these basic problems.",
    "start": "1841350",
    "end": "1847440"
  },
  {
    "text": "I wish they were\nall solved already. We've just got too many\nproblems and not enough time. But I mean, you could solve this\nproblem in your final project",
    "start": "1847440",
    "end": "1857159"
  },
  {
    "text": "and make serious\ncontributions to the field. This is the state\nthat the field is in.",
    "start": "1857160",
    "end": "1863730"
  },
  {
    "start": "1863000",
    "end": "2053000"
  },
  {
    "text": "OK, good. ",
    "start": "1863730",
    "end": "1873820"
  },
  {
    "text": "So change the world. Do that for your final\nprojects, ideally. ",
    "start": "1873820",
    "end": "1881419"
  },
  {
    "text": "That's where we've come from. Let's start thinking\nabout-- let me just bite off",
    "start": "1881420",
    "end": "1886700"
  },
  {
    "text": "today the next big chunk, OK?  You're going to\nfinish this class",
    "start": "1886700",
    "end": "1893570"
  },
  {
    "text": "with sort of a Chinese menu of\ntools that hopefully will help you solve all your problems.",
    "start": "1893570",
    "end": "1899390"
  },
  {
    "start": "1899390",
    "end": "1923610"
  },
  {
    "text": "OK. So analytically and\ncomputationally, there are two major\napproaches to solving",
    "start": "1923610",
    "end": "1929390"
  },
  {
    "text": "these optimal control problems. ",
    "start": "1929390",
    "end": "1941630"
  },
  {
    "text": "Let's even just say\ncomputational optimal-- numerical optimal control. ",
    "start": "1941630",
    "end": "1957340"
  },
  {
    "text": "The first one, like I said, is\nyou're trying to solve a PDE--",
    "start": "1957340",
    "end": "1965220"
  },
  {
    "start": "1965220",
    "end": "1974419"
  },
  {
    "text": "Partial Differential Equation. The particular name is the\nHamilton-Jacobi-Bellman",
    "start": "1974420",
    "end": "1979440"
  },
  {
    "text": "equation. ",
    "start": "1979440",
    "end": "1986580"
  },
  {
    "text": "But there is a second approach. ",
    "start": "1986580",
    "end": "1993309"
  },
  {
    "text": "The second approach is policy\nsearch, direct policy search.",
    "start": "1993310",
    "end": "2000460"
  },
  {
    "start": "2000460",
    "end": "2008720"
  },
  {
    "text": "Very much still is governed\nby the partial differential",
    "start": "2008720",
    "end": "2014090"
  },
  {
    "text": "equations of optimality. But the solution\ntechnique is different.",
    "start": "2014090",
    "end": "2021300"
  },
  {
    "text": "Here's the idea. ",
    "start": "2021300",
    "end": "2040770"
  },
  {
    "text": "Let's design not directly the-- I mean, we've designed\nour cost function. We have our cost function,\nwe have our dynamics.",
    "start": "2040770",
    "end": "2048260"
  },
  {
    "text": "Let's not-- let's design a\nfamily of control systems with a bunch of parameters, OK?",
    "start": "2048260",
    "end": "2054590"
  },
  {
    "start": "2053000",
    "end": "2268000"
  },
  {
    "text": "So the policy search\nmethods define some class",
    "start": "2054590",
    "end": "2060702"
  },
  {
    "text": "of feedback policies\nthat you care about that are parameterized\nby some vector alpha.",
    "start": "2060703",
    "end": "2068253"
  },
  {
    "start": "2068254",
    "end": "2095879"
  },
  {
    "text": "We define a class of\nfeedback policies. And then using the same exact\nformulations we used before,",
    "start": "2095880",
    "end": "2104710"
  },
  {
    "text": "where we used J to represent\nthe long-term cost of taking",
    "start": "2104710",
    "end": "2112619"
  },
  {
    "text": "and starting with some initial\ncondition at some time, which could be-- ",
    "start": "2112620",
    "end": "2132005"
  },
  {
    "text": "this is what I\nwrote down before.  Now I'm going to be\neven more specific",
    "start": "2132005",
    "end": "2138270"
  },
  {
    "text": "and say, let's make\nJ of alpha x0, t.",
    "start": "2138270",
    "end": "2144470"
  },
  {
    "text": "I'm going to say it's a\nfunction of the parameters. And I'm going to\nsay that u is now",
    "start": "2144470",
    "end": "2153480"
  },
  {
    "text": "the cost of evaluating my\ncontrol system with parameters alpha. So it's a little\nabstract right now,",
    "start": "2153480",
    "end": "2159630"
  },
  {
    "text": "but let's make it concrete. So here's a couple of potential\nparameterizations, right? So we talked about\nthe linear family",
    "start": "2159630",
    "end": "2167250"
  },
  {
    "text": "of feedback policies,\nlinear feedback",
    "start": "2167250",
    "end": "2173760"
  },
  {
    "text": "control with some\nbig matrix K. Well, that's a perfectly acceptable\npolicy parameterization.",
    "start": "2173760",
    "end": "2180030"
  },
  {
    "text": "If I want to search over the\nclass of feedback policies that are linear\nfeedback policies, then I could call that\npi of alpha x of t.",
    "start": "2180030",
    "end": "2189730"
  },
  {
    "text": "It just happens that that\ncontrol policy is alpha 1,",
    "start": "2189730",
    "end": "2194790"
  },
  {
    "text": "alpha 2, alpha n times x.",
    "start": "2194790",
    "end": "2201840"
  },
  {
    "text": " It's a perfectly reasonable\nclass of control policies.",
    "start": "2201840",
    "end": "2207745"
  },
  {
    "start": "2207745",
    "end": "2238760"
  },
  {
    "text": "Actually, just to\nthrow it out there, it's probably a bad\nchoice, actually.",
    "start": "2238760",
    "end": "2243920"
  },
  {
    "text": "Because I think people know\nthat even sort of LQR problems are not convex in\nthis parameterization.",
    "start": "2243920",
    "end": "2251305"
  },
  {
    "text": "I haven't told you how\nwe're going to solve it yet, but let me just\nthrow out the fact that I think most sort\nof serious control people",
    "start": "2251305",
    "end": "2258020"
  },
  {
    "text": "wouldn't use this as a\nrepresentation to search over, because it turns out the\nrelationship to performance",
    "start": "2258020",
    "end": "2264080"
  },
  {
    "text": "based on these parameters\nis complicated. Maybe unnecessarily so. ",
    "start": "2264080",
    "end": "2270152"
  },
  {
    "text": "A much-- a very common\nparameterization is sort of an open\nloop control tape,",
    "start": "2270152",
    "end": "2279410"
  },
  {
    "text": "I'll call it, where\nin the simplest form,",
    "start": "2279410",
    "end": "2290720"
  },
  {
    "text": "let's say u is just is that\na reasonable way to write it?",
    "start": "2290720",
    "end": "2311960"
  },
  {
    "text": " And every time, I just--",
    "start": "2311960",
    "end": "2319880"
  },
  {
    "text": "this would be a zero-order hold. And at any time, I just\nfind the closest sort of point in my control tape.",
    "start": "2319880",
    "end": "2328070"
  },
  {
    "text": "And I'll put-- so I've\ngot alpha at time 1, I've got alpha at time 2, alpha\nat time 3 just in the tape.",
    "start": "2328070",
    "end": "2334130"
  },
  {
    "text": "And I just-- as I run my\npolicy, I ignore state, and just play out an open-loop tape.",
    "start": "2334130",
    "end": "2340220"
  },
  {
    "text": "That's a perfectly valid\npolicy representation. Maybe a better one would be\nsomething based on splines.",
    "start": "2340220",
    "end": "2349355"
  },
  {
    "start": "2349355",
    "end": "2356088"
  },
  {
    "text": "Or even just a smoother\ninterpolation, maybe that could be better. People use things\nlike neural networks",
    "start": "2356088",
    "end": "2365970"
  },
  {
    "text": "as policy representations. ",
    "start": "2365970",
    "end": "2372470"
  },
  {
    "text": "There's a lot of work on things\nlike radial basis functions. ",
    "start": "2372470",
    "end": "2383839"
  },
  {
    "text": "And in general, a lot of sort\nof kernel methods in machine learning you can use sort of--",
    "start": "2383840",
    "end": "2394885"
  },
  {
    "text": "the point of this\nline is you can use general machine learning\nfunction approximators.",
    "start": "2394885",
    "end": "2402842"
  },
  {
    "start": "2402842",
    "end": "2417120"
  },
  {
    "text": "And those tend to be reasonable\npolicy representations, where maybe the weights in\nthe neural network,",
    "start": "2417120",
    "end": "2422843"
  },
  {
    "text": "even if you don't know\nwhat these things are-- I'm actually going to do a\nlittle bit of an introduction to function approximators once\nwe start using them heavily",
    "start": "2422843",
    "end": "2429200"
  },
  {
    "text": "in class. But just from seeing the words,\neven if you've never used one, you probably have a\nsense that these things",
    "start": "2429200",
    "end": "2434900"
  },
  {
    "text": "are sort of ways to\nrepresent functions with a lot of parameters.",
    "start": "2434900",
    "end": "2440810"
  },
  {
    "text": "And those are perfectly\ngood candidates.",
    "start": "2440810",
    "end": "2445940"
  },
  {
    "text": "So the key idea\nhere is, if we're willing to parameterize\nour control",
    "start": "2445940",
    "end": "2451010"
  },
  {
    "text": "system with a class\nof some parameters,",
    "start": "2451010",
    "end": "2456470"
  },
  {
    "text": "some finite parameters, then\nI can turn my optimal control",
    "start": "2456470",
    "end": "2461750"
  },
  {
    "text": "problem into a simple\nparameter search. In general now, if\nI want to minimize--",
    "start": "2461750",
    "end": "2469820"
  },
  {
    "start": "2469820",
    "end": "2486490"
  },
  {
    "text": "the problem is to\nminimize over alpha, let's say J alpha from the\nx0 I care about at time 0.",
    "start": "2486490",
    "end": "2497030"
  },
  {
    "text": "I could describe J\nthrough those equations, through some Matlab function,\nlet's say, and just say, find",
    "start": "2497030",
    "end": "2505700"
  },
  {
    "text": "the minimum of this function. You can do it with sort\nof fmin or various--",
    "start": "2505700",
    "end": "2512250"
  },
  {
    "text": "any old tools from\nnonlinear optimization. ",
    "start": "2512250",
    "end": "2548410"
  },
  {
    "text": "Seem reasonable?  It's important to make sure we\nunderstand why it's different,",
    "start": "2548410",
    "end": "2554710"
  },
  {
    "start": "2551000",
    "end": "2679000"
  },
  {
    "text": "OK? So-- do I still have\nthis up on the board? ",
    "start": "2554710",
    "end": "2569950"
  },
  {
    "text": "AUDIENCE: Are these [INAUDIBLE]\napproximators [INAUDIBLE] x as input and so y\nis output [INAUDIBLE]??",
    "start": "2569950",
    "end": "2576575"
  },
  {
    "text": " RUSS TEDRAKE:\nPotentially x and time",
    "start": "2576575",
    "end": "2581690"
  },
  {
    "text": "as an input and u as an output. You're trying to-- the\nfunction approximators represent this function, right?",
    "start": "2581690",
    "end": "2589450"
  },
  {
    "start": "2589450",
    "end": "2595220"
  },
  {
    "text": "They're mapping which depends\non parameters alpha from x and t in the general case to u.",
    "start": "2595220",
    "end": "2600680"
  },
  {
    "start": "2600680",
    "end": "2609670"
  },
  {
    "text": "in many ways, this is\na very naive approach. The dynamic programming view\nof the world is very beautiful.",
    "start": "2609670",
    "end": "2616750"
  },
  {
    "text": "We turned our complicated\nlong-term optimization",
    "start": "2616750",
    "end": "2621850"
  },
  {
    "text": "of this function into\na recursive form, where at each step\nI only had to think",
    "start": "2621850",
    "end": "2628059"
  },
  {
    "text": "about my instantaneous\ncontrol action. I did a min over u for that one\nstep, and that was end to end,",
    "start": "2628060",
    "end": "2637480"
  },
  {
    "text": "if I could solve my value\nfunction, then that was enough. I could use my value function to\nturn my long-term optimization",
    "start": "2637480",
    "end": "2645640"
  },
  {
    "text": "into a short-term\noptimization, min over u. ",
    "start": "2645640",
    "end": "2651580"
  },
  {
    "text": "Tell me if I need to\nsay things differently.  In many ways, this\nis the dumb approach.",
    "start": "2651580",
    "end": "2659787"
  },
  {
    "text": "We're not-- we're throwing away\nthe structure in the problem. We're just going to directly\nsearch over parameters.",
    "start": "2659788",
    "end": "2667360"
  },
  {
    "text": "The saving grace is\nthat I don't have to-- the value function can\nturn out to be a hard thing",
    "start": "2667360",
    "end": "2673450"
  },
  {
    "text": "to represent, especially if--\nwith dynamic programming, I can't represented in\n10 dimensions, let's say.",
    "start": "2673450",
    "end": "2680110"
  },
  {
    "text": "So this dumb\napproach can actually work in more\ncomplicated systems. ",
    "start": "2680110",
    "end": "2687470"
  },
  {
    "text": "The only problem is it doesn't\nguarantee global optimality.",
    "start": "2687470",
    "end": "2693026"
  },
  {
    "start": "2693027",
    "end": "2739290"
  },
  {
    "text": "Like I said, in some ways\nit's a very naive approach. It tends to scale better-- it's\nnot as sensitive explicitly",
    "start": "2739290",
    "end": "2746298"
  },
  {
    "text": "to the dimensionality\nof the problem. ",
    "start": "2746298",
    "end": "2761100"
  },
  {
    "text": "There's another\nnice thing about it, which there's no explicit\nneed for discretization, which",
    "start": "2761100",
    "end": "2769920"
  },
  {
    "text": "I told you was a big problem\nin the dynamic programming thing-- except for there's\ndiscretization potentially",
    "start": "2769920",
    "end": "2775680"
  },
  {
    "text": "in the ODE sort of integrator. ",
    "start": "2775680",
    "end": "2786960"
  },
  {
    "text": "And that can make-- we do know how to make\nthat arbitrarily accurate. ",
    "start": "2786960",
    "end": "2820530"
  },
  {
    "text": "The only real killer of these\nmethods is that they don't-- they're very subject\nto local minima.",
    "start": "2820530",
    "end": "2827039"
  },
  {
    "text": "Yeah, please. AUDIENCE: This\nfunction approximation, isn't it like discretization\nof your state space?",
    "start": "2827040",
    "end": "2832390"
  },
  {
    "text": "[INAUDIBLE] RUSS TEDRAKE: Not necessarily. AUDIENCE: I mean,\nbut you essentially-- you don't have full control\n[INAUDIBLE] available",
    "start": "2832390",
    "end": "2839410"
  },
  {
    "text": "[INAUDIBLE].  RUSS TEDRAKE: It's\na good question.",
    "start": "2839410",
    "end": "2844500"
  },
  {
    "text": "So take the linear\nfeedback example. If I have a problem\nthat I know the--",
    "start": "2844500",
    "end": "2850370"
  },
  {
    "text": "if I take an LQR problem and\nI solve it with policy search, and I know the feedback\npolicy should exist in the class of linear\n[INAUDIBLE] things,",
    "start": "2850370",
    "end": "2857270"
  },
  {
    "text": "then I haven't lost anything\nby doing an approximation. And in general,\nthese things are--",
    "start": "2857270",
    "end": "2863900"
  },
  {
    "text": "so radial basic functions\nhave the feeling of similar to discretization. But some of them are much\nsmoother and much more",
    "start": "2863900",
    "end": "2870620"
  },
  {
    "text": "continuous than these\nhard discretizations. And the way that\nyou evaluate them, which is what's essential, is\nyou're still going to find--",
    "start": "2870620",
    "end": "2879200"
  },
  {
    "text": "so if I evaluate the\nsystem by literally taking my parameters of my\nneural network, radial basis function, whatever,\nrunning this function",
    "start": "2879200",
    "end": "2886850"
  },
  {
    "text": "without any\ndiscretization, then it'll give me an accurate\nmeasurement of this function. Discretization comes\ninto the-- doesn't",
    "start": "2886850",
    "end": "2893210"
  },
  {
    "text": "come into the evaluation\nof the function. In dynamic programming,\nit's fundamental.",
    "start": "2893210",
    "end": "2898490"
  },
  {
    "text": "Discretization is right there. We always operate directly\nunder discretized system.",
    "start": "2898490",
    "end": "2904585"
  },
  {
    "start": "2903000",
    "end": "2995000"
  },
  {
    "text": "So I do think these things\nare much closer to being continuous solvers.",
    "start": "2904585",
    "end": "2910672"
  },
  {
    "text": "You might say\nanother disadvantage is that it doesn't exploit\nthe recursion that we",
    "start": "2910673",
    "end": "2917670"
  },
  {
    "text": "know to exist in the problem.",
    "start": "2917670",
    "end": "2924233"
  },
  {
    "text": "So it sort of feels\nlike we should be able to use that\ntrick more generally. And a lot of times,\nthese methods",
    "start": "2924233",
    "end": "2929490"
  },
  {
    "text": "are going to be the very naive\nthings which throw them away.  AUDIENCE: You said DP requires\nthe discretized space?",
    "start": "2929490",
    "end": "2938026"
  },
  {
    "text": " RUSS TEDRAKE: Yep. That's what I said. Do you disagree?",
    "start": "2938027",
    "end": "2945530"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\ncan be [INAUDIBLE].. ",
    "start": "2945530",
    "end": "2952330"
  },
  {
    "text": "RUSS TEDRAKE: Well, then I\nwould call that an approximate dynamic programming method,\nwhich is-- these are the--",
    "start": "2952330",
    "end": "2957922"
  },
  {
    "text": "it depends where\nyou draw the line. I'm going to talk about those\nin the reinforcement learning part of the course.",
    "start": "2957922",
    "end": "2963892"
  },
  {
    "text": "But the thing that\nI think people-- I think that we talked about,\nwhich has guaranteed results for the discrete\nsystem, which is sort",
    "start": "2963892",
    "end": "2970690"
  },
  {
    "text": "of really dynamic\nprogramming, discretization is exactly fundamental. So Alborz is pointing\nout that actually there",
    "start": "2970690",
    "end": "2976560"
  },
  {
    "text": "are people that use\nfunction approximators in dynamic programming\nalgorithms. And we're going to talk\nabout those in the future.",
    "start": "2976560",
    "end": "2981623"
  },
  {
    "text": "But they tend to be approximate. A lot of times, they have weaker\nguarantees of convergence. But we'll talk about\nthose as they come up.",
    "start": "2981623",
    "end": "2987572"
  },
  {
    "start": "2987572",
    "end": "2993020"
  },
  {
    "text": "OK, good. So now we have a\nvery simple problem. We've taken our\noptimal control problem",
    "start": "2993020",
    "end": "2999650"
  },
  {
    "start": "2995000",
    "end": "3599000"
  },
  {
    "text": "that we've thrown all\nkinds of work into. And we've talked\nabout the recursion,",
    "start": "2999650",
    "end": "3005420"
  },
  {
    "text": "we've talked about\nthe Bellman equation. And now we just said,\nOK, might as well just think of it, that--",
    "start": "3005420",
    "end": "3010750"
  },
  {
    "text": "if I run my robot with\nthree different parameters, I'm going to get three\ndifferent scores.",
    "start": "3010750",
    "end": "3016180"
  },
  {
    "text": "If I literally take my acrobot\nand I make the parameters all 1, then I'm going\nto get some score",
    "start": "3016180",
    "end": "3027670"
  },
  {
    "text": "for running that policy. If I change my parameters\nso the third parameter is 2,",
    "start": "3027670",
    "end": "3032950"
  },
  {
    "text": "I'll get a different score. And I'll get a\ndifferent score if I run a different set of parameters. I'm just going to run my trial\nfor, let's say, for 10 seconds",
    "start": "3032950",
    "end": "3039730"
  },
  {
    "text": "with different\nsets of parameters. And this is going to give\nme some landscape, which",
    "start": "3039730",
    "end": "3046540"
  },
  {
    "text": "is J of alpha. Now typically in\nthese problems, I'm going to be thinking\nabout optimizing it",
    "start": "3046540",
    "end": "3053290"
  },
  {
    "text": "from a particular\ninitial condition. We can talk about later how-- if you want to get around that. But this is just some\nfunction J of alpha, right?",
    "start": "3053290",
    "end": "3063580"
  },
  {
    "text": "So how do we\noptimize J of alpha? Well, there's lots of good ways,\nfrom nonlinear programming,",
    "start": "3063580",
    "end": "3069400"
  },
  {
    "text": "from nonlinear optimization. What are some good ways to\nfind the minimum of J of alpha?",
    "start": "3069400",
    "end": "3076240"
  },
  {
    "text": " Guess a lot of alphas,\nthat's one approach.",
    "start": "3076240",
    "end": "3083460"
  },
  {
    "text": "Pick the smallest one. OK. AUDIENCE: You can\nform J in a way which is, you can take [INAUDIBLE]\ndynamics smooth then we",
    "start": "3083460",
    "end": "3090894"
  },
  {
    "text": "can solve [INAUDIBLE]. RUSS TEDRAKE: OK, good. So let's say I have\nan initial guess at J,",
    "start": "3090895",
    "end": "3097520"
  },
  {
    "text": "and I can actually compute\nthe derivative of J.",
    "start": "3097520",
    "end": "3103440"
  },
  {
    "text": "Which I can always do, because\nI could do it numerically if I wanted to, right?",
    "start": "3103440",
    "end": "3108869"
  },
  {
    "text": "I can just evaluate it a bunch\nof times to do it if I had to. But if I can compute dJ\nd alpha, then that'll",
    "start": "3108870",
    "end": "3115800"
  },
  {
    "text": "tell me that slope. And I could, for instance, do\ngradient descent on that slope.",
    "start": "3115800",
    "end": "3123900"
  },
  {
    "text": "I could do alpha-- my second alpha that\nI'm going to try is going to be my first alpha.",
    "start": "3123900",
    "end": "3131160"
  },
  {
    "text": "I try minus some movement in\nthe direction of the gradient. ",
    "start": "3131160",
    "end": "3143840"
  },
  {
    "text": "I could take this,\nestimate the gradient,",
    "start": "3143840",
    "end": "3149330"
  },
  {
    "text": "and then take a motion that\nmoves me down the gradient, make a new update, move down\nthe gradient, make a new update.",
    "start": "3149330",
    "end": "3158230"
  },
  {
    "text": "And eventually I'll\nget to the minimum where the gradient\nis equal to 0. How many people have\nused gradient descent",
    "start": "3158230",
    "end": "3164240"
  },
  {
    "text": "before in something? OK, good.",
    "start": "3164240",
    "end": "3169700"
  },
  {
    "text": "So nobody actually does\nthat, I don't think, anymore. Because we have sort of--",
    "start": "3169700",
    "end": "3175755"
  },
  {
    "text": "I mean, that's\nabsolutely the right way to think about things, and\ngradient methods are critical. But you optimization theory\nhas gotten pretty good.",
    "start": "3175755",
    "end": "3188869"
  },
  {
    "text": "So there's another way to do it. Let's say I had--",
    "start": "3188870",
    "end": "3194108"
  },
  {
    "text": "I couldn't just-- I not only\ncompute the first derivative, but let's say I could compute\nthe second derivative. ",
    "start": "3194108",
    "end": "3219770"
  },
  {
    "text": "My initial guess here, that\ncould be the first derivative. ",
    "start": "3219770",
    "end": "3229900"
  },
  {
    "text": "And it could be the\nsecond derivative. ",
    "start": "3229900",
    "end": "3235780"
  },
  {
    "text": "Then what could I do? AUDIENCE: Fit a parabola to it? RUSS TEDRAKE: Fit\na parabola to it?",
    "start": "3235780",
    "end": "3241390"
  },
  {
    "text": "I didn't quite\nhear what you said. Is that what you said, too? AUDIENCE: Steepest descent.  RUSS TEDRAKE: Absolutely.",
    "start": "3241390",
    "end": "3247369"
  },
  {
    "text": "Let's fit a quadratic\nbowl to it, right? And actually, the\nproblem I did right now, probably the quadratic\nbowl is a pretty good match",
    "start": "3247370",
    "end": "3254223"
  },
  {
    "text": "to the real optimization. And why not move directly\nto this point and then fix--",
    "start": "3254223",
    "end": "3261910"
  },
  {
    "text": "find a new quadratic bowl and\nmove directly to that point. So this would be a\nsecond-order method.",
    "start": "3261910",
    "end": "3267980"
  },
  {
    "start": "3267980",
    "end": "3277840"
  },
  {
    "text": "OK. And so Newton-- a lot of people\ncall it the Newton method.",
    "start": "3277840",
    "end": "3285049"
  },
  {
    "start": "3285050",
    "end": "3290770"
  },
  {
    "text": "Turns out it works just as well\nin high-dimensional systems. If I have a bunch\nof alphas, I can do these second-order methods.",
    "start": "3290770",
    "end": "3297940"
  },
  {
    "text": "And doing this, in\ngeneral, is what",
    "start": "3297940",
    "end": "3303280"
  },
  {
    "text": "is called sequential\nquadratic programming. ",
    "start": "3303280",
    "end": "3321226"
  },
  {
    "text": "Yeah. And they tend to converge-- there's an additional\ncost, potentially,",
    "start": "3321226",
    "end": "3327880"
  },
  {
    "text": "of computing that\nsecond derivative. But you can do it by\nremembering the past-- the same way you can\nremember your-- you",
    "start": "3327880",
    "end": "3334525"
  },
  {
    "text": "can estimate your gradient by\nremembering a couple of samples and just doing a\nnumerical gradient. You can remember a\ncouple of samples",
    "start": "3334525",
    "end": "3340990"
  },
  {
    "text": "and compute the-- estimate\nthe second derivative. So I'd say probably the most\ncommon method used right now--",
    "start": "3340990",
    "end": "3351635"
  },
  {
    "text": "how could I say that? But one of the\nvery common methods is to try to compute these\nanalytically, because--",
    "start": "3351635",
    "end": "3359350"
  },
  {
    "text": "I'll show you a good\nway to compute those. And then these,\nwhich could be put could be potentially\nmore trouble to compute,",
    "start": "3359350",
    "end": "3366010"
  },
  {
    "text": "we'll just use sort of a\nnumerical secant method to collect our\nsecond-order terms,",
    "start": "3366010",
    "end": "3371800"
  },
  {
    "text": "and then use sequential\nquadratic programming. The thing that makes sequential\nquadratic programming",
    "start": "3371800",
    "end": "3379210"
  },
  {
    "text": "better than sort of the\nnaive gradient descent is that it's faster.",
    "start": "3379210",
    "end": "3384549"
  },
  {
    "text": "But the real thing is that\noptimization theory is just this beautiful thing. Now I can take constraints\ninto account very simply.",
    "start": "3384550",
    "end": "3395410"
  },
  {
    "text": "So let's say I have-- this is sort of a crash\ncourse in optimization theory.",
    "start": "3395410",
    "end": "3401260"
  },
  {
    "text": "But I think you can say in a few\nminutes most of the key ideas. ",
    "start": "3401260",
    "end": "3413500"
  },
  {
    "text": "I mean, to be fair,\nmost of the lectures we've had so far, you\ncould take an entire course",
    "start": "3413500",
    "end": "3419109"
  },
  {
    "text": "on each one of those lectures. So pick your favorite,\ntake another course. But, you know, I think that's--",
    "start": "3419110",
    "end": "3425466"
  },
  {
    "text": "I think it's useful to\nhave the courses that go over a lot of topics,\nand that's what this is. ",
    "start": "3425467",
    "end": "3431830"
  },
  {
    "text": "So what happens if\nI now have, if I want to minimize over\nalpha J alpha subject",
    "start": "3431830",
    "end": "3441640"
  },
  {
    "text": "to some constraint, let's say-- I'll just call it-- I'm running out\nof letters here--",
    "start": "3441640",
    "end": "3447905"
  },
  {
    "text": " A of x equals 0. ",
    "start": "3447905",
    "end": "3454570"
  },
  {
    "text": "We know how to formulate those\nwith Lagrange multipliers. But in general,\nfinding equality,",
    "start": "3454570",
    "end": "3461559"
  },
  {
    "text": "solving for equalities,\nthat's just root finding. That's actually no more\ndifficult than finding",
    "start": "3461560",
    "end": "3469840"
  },
  {
    "text": "minimals. I can use the same\nNewton method to find--",
    "start": "3469840",
    "end": "3475270"
  },
  {
    "text": "to do root finding.  So if I have some constraint,\nlet's say, alpha--",
    "start": "3475270",
    "end": "3484965"
  },
  {
    "text": "oh, that was a\nreally bad choice. Let's call this something\nother than A. Let's just",
    "start": "3484965",
    "end": "3490750"
  },
  {
    "text": "call it f of alpha, just\nso I keep my dimensions in the same direction here.",
    "start": "3490750",
    "end": "3496480"
  },
  {
    "start": "3496480",
    "end": "3502760"
  },
  {
    "text": "OK. If I want to find-- I'd better make it go through 0. ",
    "start": "3502760",
    "end": "3511210"
  },
  {
    "text": "If I want to find the\nzeros of that solution, I can use the same exact\ngradient updates, right?",
    "start": "3511210",
    "end": "3516490"
  },
  {
    "text": "I can define a zero\ncrossing if I have an initial guess at the system.",
    "start": "3516490",
    "end": "3522625"
  },
  {
    "text": "I take the linearization, its'\ngoing to give me a new guess for the zero point.",
    "start": "3522625",
    "end": "3527637"
  },
  {
    "text": "I take the derivative\nthere, that'll get me close. That's the Newton\nmethod for root finding. ",
    "start": "3527637",
    "end": "3541580"
  },
  {
    "text": "OK. So by knowing the gradients,\nyou could sort of simultaneously do minimization and root\nfinding to satisfy constraints.",
    "start": "3541580",
    "end": "3552369"
  },
  {
    "text": "Long story short, if\nyou have a problem that",
    "start": "3552370",
    "end": "3558730"
  },
  {
    "text": "has the form minimize\nalpha subject--",
    "start": "3558730",
    "end": "3564130"
  },
  {
    "text": "some function J of alpha-- it's potentially nonlinear, but\nyou could take its gradients, let's say--",
    "start": "3564130",
    "end": "3569680"
  },
  {
    "text": "subject to linear constraints,\nequality constraints, or even",
    "start": "3569680",
    "end": "3578050"
  },
  {
    "text": "inequality constraints, you\ncan just hand that these days",
    "start": "3578050",
    "end": "3585840"
  },
  {
    "text": "to some nice solver-- ",
    "start": "3585840",
    "end": "3597360"
  },
  {
    "text": "some sequential quadratic\nprogramming solver. The one we use these days\nin lab is called SNOPT--",
    "start": "3597360",
    "end": "3604690"
  },
  {
    "text": " Sparse Nonlinear Optimization\nPackage something,",
    "start": "3604690",
    "end": "3610480"
  },
  {
    "text": "I don't know. OK. ",
    "start": "3610480",
    "end": "3615609"
  },
  {
    "text": "So you could start solving\noptimal control problems by literally saying, OK, if I\nrun this-- just telling it J,",
    "start": "3615610",
    "end": "3624190"
  },
  {
    "text": "telling it the gradients\nof J if you can. That'll make it faster. Even if you didn't, you\ncould just say, here's J,",
    "start": "3624190",
    "end": "3629440"
  },
  {
    "text": "find me the minimum of\nJ. You hand it to SNOPT, it'll go ahead and\ndo a lot of work",
    "start": "3629440",
    "end": "3635530"
  },
  {
    "text": "and come up with\nthe best J, which is going to be some minima\nof this cost function.",
    "start": "3635530",
    "end": "3640869"
  },
  {
    "text": "There's no guarantee that\nit won't find this one. It's subject to local minima.",
    "start": "3640870",
    "end": "3647170"
  },
  {
    "text": "But sequential quadratic\nprogramming methods tend to be better\nthan gradient methods",
    "start": "3647170",
    "end": "3653770"
  },
  {
    "text": "in avoiding local minima,\nbecause, for instance, if I'm here and I estimate\nthe quadratic bowl, if I just",
    "start": "3653770",
    "end": "3659530"
  },
  {
    "text": "take bigger steps,\nthen I tend to jump over some small local minima\nthat a gradient method might",
    "start": "3659530",
    "end": "3665260"
  },
  {
    "text": "get caught in. So just experimentally,\npeople know a lot about how it works\non quadratic programs",
    "start": "3665260",
    "end": "3673253"
  },
  {
    "text": "if they're actually-- if the\nsystem is actually quadratic. If it's a nonlinear system\nthat you're approximating as quadratic programs, then\nthey sort of wave their hands,",
    "start": "3673253",
    "end": "3681770"
  },
  {
    "text": "but it works really\nwell in practice. Yeah, OK? ",
    "start": "3681770",
    "end": "3687040"
  },
  {
    "text": "So we have a new way of solving\noptimal control problems. Just write the function down in\na function that SNOPT can call.",
    "start": "3687040",
    "end": "3692853"
  },
  {
    "text": "Give it a set of\nparameters alpha, it'll churn away and find alpha.",
    "start": "3692853",
    "end": "3698200"
  },
  {
    "text": "All that's left for\nus to do in this class is figure out the best\nway to hand it to SNOPT. ",
    "start": "3698200",
    "end": "3706400"
  },
  {
    "text": "We want to make SNOPT's\ncomputation as effective as possible. ",
    "start": "3706400",
    "end": "3715365"
  },
  {
    "text": "And there's a lot of\ndifferent ways to do it. ",
    "start": "3715365",
    "end": "3733060"
  },
  {
    "text": "So the first way is literally\nparameterize your control system, called SNOPT.",
    "start": "3733060",
    "end": "3738570"
  },
  {
    "text": "But let's at least be smart\nabout computing the gradients. Let's avoid asking\nour nonlinear solver",
    "start": "3738570",
    "end": "3745230"
  },
  {
    "text": "to compute the gradients\nfor us numerically, because we can give you those\nanalytically, exploiting",
    "start": "3745230",
    "end": "3751620"
  },
  {
    "text": "the structure in the\nadditive equations, the additive cost optimal\ncontrol equations.",
    "start": "3751620",
    "end": "3758849"
  },
  {
    "text": "And as it turns out, it's a\ndirect and clear descendent from the Pontryagin\nminimum principle, OK?",
    "start": "3758850",
    "end": "3766510"
  },
  {
    "text": "So I'm going to show\nyou lots of examples of these things\nworking on Thursday. But I thought today,\nlet's just make",
    "start": "3766510",
    "end": "3774960"
  },
  {
    "text": "sure that the basic idea of what\nwe're doing here comes through, this policy search, and show you\nhow to compute those gradients.",
    "start": "3774960",
    "end": "3783420"
  },
  {
    "start": "3783420",
    "end": "3793170"
  },
  {
    "text": "In fact, let me just tell\nyou the result first. I think that works sometimes. OK, so given J--",
    "start": "3793170",
    "end": "3804060"
  },
  {
    "start": "3804060",
    "end": "3813680"
  },
  {
    "text": "I'll just leave off that end\ncondition for now, the terminal condition. ",
    "start": "3813680",
    "end": "3831440"
  },
  {
    "text": "The goal is to compute\npartial J x0 partial alpha.",
    "start": "3831440",
    "end": "3845329"
  },
  {
    "text": "My claim is I can compute\nthat very efficiently by integrating the\nsystem forward from 0",
    "start": "3845330",
    "end": "3850880"
  },
  {
    "text": "to t backward from t to 0,\nand then I'll get my gradient. ",
    "start": "3850880",
    "end": "3911880"
  },
  {
    "text": "OK. It integrates the\nsystem forward, just like you would do it,\nrun any old simulation.",
    "start": "3911880",
    "end": "3917040"
  },
  {
    "text": "But while you do it, keep\ntrack of a few key variables. ",
    "start": "3917040",
    "end": "3957430"
  },
  {
    "text": "Similarly, g of x. ",
    "start": "3957430",
    "end": "4025599"
  },
  {
    "text": "It's. ",
    "start": "4025600",
    "end": "4076750"
  },
  {
    "text": "Anybody recognize that equation? It's written a little\nbit different form, but.",
    "start": "4076750",
    "end": "4082750"
  },
  {
    "start": "4082750",
    "end": "4089666"
  },
  {
    "text": "AUDIENCE: Filter equation? RUSS TEDRAKE: It's not a filter. Well, it could be interpreted as\na filter of something probably,",
    "start": "4089666",
    "end": "4095240"
  },
  {
    "text": "but.  It's an equation\nwe've seen before.",
    "start": "4095240",
    "end": "4102339"
  },
  {
    "text": "AUDIENCE: Adjoint. RUSS TEDRAKE: It's the adjoint\nequation from the Pontryagin. OK. ",
    "start": "4102340",
    "end": "4124420"
  },
  {
    "text": "OK.  Then the gradients-- ",
    "start": "4124420",
    "end": "4169130"
  },
  {
    "text": "OK. So I'm done writing for\na second, let's talk. ",
    "start": "4169130",
    "end": "4176500"
  },
  {
    "text": "Do you remember the story\nfrom the Pontryagin? ",
    "start": "4176500",
    "end": "4184210"
  },
  {
    "text": "The derivation sketch\nI did, we said that we had some functional, right? It was that if we change\nour control actions,",
    "start": "4184210",
    "end": "4192730"
  },
  {
    "text": "we want to make sure that\nchanging our control actions at all doesn't increase the--",
    "start": "4192730",
    "end": "4198150"
  },
  {
    "text": "doesn't change the\nconstrained minimization of J subject to the constraints\nof the dynamics.",
    "start": "4198150",
    "end": "4204849"
  },
  {
    "text": "y, in that derivation turned out\nto be the Lagrange multipliers that enforced the constraint.",
    "start": "4204850",
    "end": "4212780"
  },
  {
    "text": "OK. What they did was\nthey put the system-- by making sure that this\nequation was satisfied",
    "start": "4212780",
    "end": "4221060"
  },
  {
    "text": "and this equation\nwas satisfied, we made sure that we were\nat a stationary point,",
    "start": "4221060",
    "end": "4226970"
  },
  {
    "text": "at a minima of our functional,\nour constrained functional,",
    "start": "4226970",
    "end": "4232160"
  },
  {
    "text": "of our Lagrange\nmultiplier equation. ",
    "start": "4232160",
    "end": "4237560"
  },
  {
    "text": "OK. It's exactly the same\nreason we're doing it here. We now have a functional which\ndepends on J. This functional",
    "start": "4237560",
    "end": "4247250"
  },
  {
    "text": "J, the Lagrange\nmultiplier functional. And the derivations\nare in the notes. I won't do it again. By going backwards, by\ngoing-- integrating forward,",
    "start": "4247250",
    "end": "4254890"
  },
  {
    "text": "we ensure that this\nconstraint is satisfied. By integrating\nbackwards, we solve for the Lagrange multiplier.",
    "start": "4254890",
    "end": "4261170"
  },
  {
    "text": "What we're left\nwith is we can now, since the gradient with respect\nto Lagrange multipliers is 0,",
    "start": "4261170",
    "end": "4266930"
  },
  {
    "text": "the gradient with respect to\nthe state equations are 0, the only thing left is\nthe gradient with respect",
    "start": "4266930",
    "end": "4272120"
  },
  {
    "text": "to the parameters alpha. And it turns out to be this\nsort of very simple equation.",
    "start": "4272120",
    "end": "4279210"
  },
  {
    "text": "So it's this beautiful\nthing right that actually-- I hope this is--",
    "start": "4279210",
    "end": "4284357"
  },
  {
    "text": "it's a lot to write on\nthe board real quick, but it's actually a pretty\nstraightforward algorithm",
    "start": "4284357",
    "end": "4289460"
  },
  {
    "text": "for computing the\ngradients, efficiently computing the gradients\npartial J partial alpha.",
    "start": "4289460",
    "end": "4295400"
  },
  {
    "text": "All I have to do is\nsimulate the system forward, simulate this gradient\nequation backwards,",
    "start": "4295400",
    "end": "4301370"
  },
  {
    "text": "and I'm left with a\ndirect function alpha, OK? ",
    "start": "4301370",
    "end": "4310199"
  },
  {
    "text": "How many people have worked\nwith neural networks before? Yeah?",
    "start": "4310200",
    "end": "4316320"
  },
  {
    "text": "OK. Well, this is the\nback propagation. This is the back propagation\nalgorithm for neural networks.",
    "start": "4316320",
    "end": "4322960"
  },
  {
    "text": "Turns out to be\nexactly the same. This is the continuous\ntime form of it. People have worked\non it and back",
    "start": "4322960",
    "end": "4329170"
  },
  {
    "text": "prop through time for\nrecurrent neural networks. But the exact way-- the\nreason the back propagation--",
    "start": "4329170",
    "end": "4335603"
  },
  {
    "text": "so there was this revolution\nin the mid '80s about-- that basically\nsuddenly, everybody said neural networks\nwill solve any problem.",
    "start": "4335603",
    "end": "4343320"
  },
  {
    "text": "some People still\nsay that today. The thing-- the\nonly thing, really, that happened, I think,\nfrom my point of view,",
    "start": "4343320",
    "end": "4351480"
  },
  {
    "text": "is that somebody came up\nwith an efficient algorithm for computing the gradients\nof the neural network weights",
    "start": "4351480",
    "end": "4359250"
  },
  {
    "text": "as a function of the\ninput/output data. It's exactly this idea that you\ncan march the system forward",
    "start": "4359250",
    "end": "4365152"
  },
  {
    "text": "and then integrate backwards. In that case through\na big neural network, you had to integrate\nthese equations backwards.",
    "start": "4365152",
    "end": "4371820"
  },
  {
    "text": "Being able to compute\nthose gradients faster was enough that\nthe world started saying neural networks\nare going to match",
    "start": "4371820",
    "end": "4378389"
  },
  {
    "text": "the computational\nintelligence of the brain and solve AI and\nall these things.",
    "start": "4378390",
    "end": "4385239"
  },
  {
    "text": "So it's a little dry, maybe. But this is potentially\nvery enabling to be able to compute\ngradients efficiently.",
    "start": "4385240",
    "end": "4391590"
  },
  {
    "text": " It could change what\nproblems you can solve. ",
    "start": "4391590",
    "end": "4398750"
  },
  {
    "text": "OK. Are people OK with the big\npicture of where things are? Yeah?",
    "start": "4398750",
    "end": "4403830"
  },
  {
    "text": "Good. So on Thursday, I'm\ngoing to show you, now that we know how to compute\nthe gradients efficiently,",
    "start": "4403830",
    "end": "4410969"
  },
  {
    "text": "I'm going to show\nyou this put to work, the intuition of sort\nof changing a policy, searching in policy space\nto solve problems like",
    "start": "4410970",
    "end": "4418080"
  },
  {
    "text": "the acrobot/cart-pole,\nand some simpler examples.",
    "start": "4418080",
    "end": "4423120"
  },
  {
    "text": "And the dumb idea\nis, let's just make it a straight,\nnonlinear optimization",
    "start": "4423120",
    "end": "4429060"
  },
  {
    "text": "problem over alpha. And I'll try to help\nyou compare and contrast the way that works compared\nto the dynamic programming.",
    "start": "4429060",
    "end": "4436800"
  },
  {
    "text": "See you then. ",
    "start": "4436800",
    "end": "4440000"
  }
]
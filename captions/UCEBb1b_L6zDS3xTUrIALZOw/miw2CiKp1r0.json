[
  {
    "start": "0",
    "end": "21000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6910"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "6910",
    "end": "13460"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "13460",
    "end": "18640"
  },
  {
    "text": " PROFESSOR: Last Tuesday, we\nended up the lecture talking",
    "start": "18640",
    "end": "25520"
  },
  {
    "start": "21000",
    "end": "66000"
  },
  {
    "text": "about knapsack problems. We talked about the continuous\nknapsack problem and the fact",
    "start": "25520",
    "end": "30920"
  },
  {
    "text": "that you could solve\nthat optimally with a greedy algorithm. And we looked at the 0-1\nknapsack problem and discussed",
    "start": "30920",
    "end": "38680"
  },
  {
    "text": "the fact that while we could\nwrite greedy algorithms that would solve the problem quickly,\nwe have to be careful",
    "start": "38680",
    "end": "45559"
  },
  {
    "text": "what we mean by \"solve,\" and\nthat while those algorithms would choose a set of items\nthat we could indeed carry",
    "start": "45560",
    "end": "54010"
  },
  {
    "text": "away, there was no guarantee\nthat it would choose the optimal items, that is to say,\none that would meet the",
    "start": "54010",
    "end": "61120"
  },
  {
    "text": "objective function of maximizing\nthe value. ",
    "start": "61120",
    "end": "67170"
  },
  {
    "text": "We looked after that at a brute\nforce algorithm on the board only for finding an\noptimal solution, a guaranteed",
    "start": "67170",
    "end": "76850"
  },
  {
    "text": "optimal solution, but observed\nthe fact that on even a moderately sized set of\nitems, it might take a",
    "start": "76850",
    "end": "85320"
  },
  {
    "text": "decade or so to run. Decided that wasn't very good. Nevertheless, I want to start\ntoday looking at some code",
    "start": "85320",
    "end": "93940"
  },
  {
    "text": "that implements a brute force\nalgorithm, not because I expect anyone to actually run\nthis on a real example, but",
    "start": "93940",
    "end": "103560"
  },
  {
    "text": "because a bit later in the term,\nwe'll see how we could modify this to something that\nwould be practical.",
    "start": "103560",
    "end": "109799"
  },
  {
    "text": "And there's some things to\nlearn by looking at it. So let's look at\nsome code here.",
    "start": "109800",
    "end": "117510"
  },
  {
    "text": "I don't expect you to understand\nin real time all the details of this code.",
    "start": "117510",
    "end": "122939"
  },
  {
    "text": "It's more I want you to\nunderstand the basic idea behind it and then the\nresult we get.",
    "start": "122940",
    "end": "130310"
  },
  {
    "text": "So you'll remember that we\nlooked at the complexity by saying well, really, it's\nlike binary numbers.",
    "start": "130310",
    "end": "138990"
  },
  {
    "text": "So the first helper subroutine\nI'm going to use is something that generates binary numbers.",
    "start": "138990",
    "end": "148980"
  },
  {
    "text": "So it takes an n, some natural\nnumber, and the number of",
    "start": "148980",
    "end": "154330"
  },
  {
    "text": "digits and returns a binary\nstring of that length, representing the decimal\nnumber n.",
    "start": "154330",
    "end": "162780"
  },
  {
    "text": "Why am I giving it this\nnumber of digits? Because I need to zero pad it.",
    "start": "162780",
    "end": "170970"
  },
  {
    "text": "If I want to have a vector that\nrepresents whether or not I take items, if I take only one\nitem, say the first one, I",
    "start": "170970",
    "end": "180090"
  },
  {
    "text": "don't want just a binary spring\nwith one digit in it. Because I need all those zeros\nto indicate that I'm not",
    "start": "180090",
    "end": "186200"
  },
  {
    "text": "taking the other items. And so the second argument tells\nme, in effect, how many",
    "start": "186200",
    "end": "192319"
  },
  {
    "text": "zeros I'm going to need. And there's nothing mysterious\nabout the way it does it.",
    "start": "192320",
    "end": "200010"
  },
  {
    "text": "OK. The next helper function\ngenerates the",
    "start": "200010",
    "end": "205320"
  },
  {
    "text": "power set of the items. What is a power set?",
    "start": "205320",
    "end": "212230"
  },
  {
    "text": "If you take a set, you can then\nask the question what are all the subsets of the set?",
    "start": "212230",
    "end": "221430"
  },
  {
    "text": "What's the smallest\nsubset of a set? It's the empty set. No items.",
    "start": "221430",
    "end": "226909"
  },
  {
    "text": "What's the largest\nsubset of a set? All of the items.",
    "start": "226910",
    "end": "232590"
  },
  {
    "text": "And then we have everything in\nbetween, the set that contains the first item, the set that\ncontains the second item, et",
    "start": "232590",
    "end": "239780"
  },
  {
    "text": "cetera, the set that contains\nthe first and the second, the first and the third. There are a lot of them.",
    "start": "239780",
    "end": "246320"
  },
  {
    "text": "And of course, how\nmany is a lot? Well, 2 to the n is a lot.",
    "start": "246320",
    "end": "251870"
  },
  {
    "text": "But now we're going\nto generate every possible subset of items.",
    "start": "251870",
    "end": "259079"
  },
  {
    "text": "And we're going to do this\nsimply using the decimal to binary function to tell us\nwhether or not we keep each",
    "start": "259079",
    "end": "267580"
  },
  {
    "text": "one, so we can enumerate them. We can generate them all. And now we have the set of all\npossible items one might take,",
    "start": "267580",
    "end": "276830"
  },
  {
    "text": "irrespective of whether they\nobey the constraint of not weighing too much.",
    "start": "276830",
    "end": "282495"
  },
  {
    "text": " The next function is the\none that does the work.",
    "start": "282495",
    "end": "291190"
  },
  {
    "text": "This is the interesting one. Choose best. It takes a power set, the\nconstraint, and two functions.",
    "start": "291190",
    "end": "304790"
  },
  {
    "text": "One, getValue-- it tells me the value\nof an item. And the other getWeight--",
    "start": "304790",
    "end": "310315"
  },
  {
    "text": "it tells me the weight\nof an item. Then it just goes through. ",
    "start": "310315",
    "end": "317610"
  },
  {
    "text": "And it enumerates all\npossibilities and eventually chooses--",
    "start": "317610",
    "end": "324099"
  },
  {
    "text": "I won't say the best\nset, because it might not be unique.",
    "start": "324100",
    "end": "329140"
  },
  {
    "text": "There might be more than\none optimal answer. But it finds at least\none optimal answer.",
    "start": "329140",
    "end": "335020"
  },
  {
    "text": "And then it returns that. Again it's a very\nstraightforward implementation",
    "start": "335020",
    "end": "342440"
  },
  {
    "text": "of the brute force algorithm\nI sketched on the board. And then we can run it with\ntestBest, which is going to",
    "start": "342440",
    "end": "350800"
  },
  {
    "text": "build the items using\nthe function we looked at last time. It's then going to get the\npower set of the items.",
    "start": "350800",
    "end": "358150"
  },
  {
    "text": "It's going to call chooseBest\nand then print the result. ",
    "start": "358150",
    "end": "363540"
  },
  {
    "text": "So let's see what happens\nif we run it. ",
    "start": "363540",
    "end": "378550"
  },
  {
    "text": "We get an error. Oh dear. I hadn't expected that.",
    "start": "378550",
    "end": "383890"
  },
  {
    "text": "And it says test-- oh testBest\nis not defined. All right. Let's try that again.",
    "start": "383890",
    "end": "389930"
  },
  {
    "text": "Sure looks like it's\ndefined to me. ",
    "start": "389930",
    "end": "398000"
  },
  {
    "text": "There it is. OK. And you may recall that this\nis a better answer than",
    "start": "398000",
    "end": "404170"
  },
  {
    "text": "anything that was generated\nby the greedy algorithm on Tuesday. You may not recall it,\nbut believe me it is.",
    "start": "404170",
    "end": "411300"
  },
  {
    "text": "It happened to have found\na better solution. And not surprisingly, that's\nbecause I contrived the",
    "start": "411300",
    "end": "417319"
  },
  {
    "text": "example to make sure\nthat would happen. Why does it work better in the\nsense-- or why does it find a",
    "start": "417320",
    "end": "423720"
  },
  {
    "text": "better answer? Why might it find\na better answer? Well, because the greedy\nalgorithm chose something that",
    "start": "423720",
    "end": "432680"
  },
  {
    "text": "was locally optimal\nat each step. ",
    "start": "432680",
    "end": "441419"
  },
  {
    "text": "But there was no guarantee that\na sequence of locally optimal decisions would reach\na global optimum.",
    "start": "441420",
    "end": "446750"
  },
  {
    "start": "446750",
    "end": "452220"
  },
  {
    "text": "What this algorithm does is it\nfinds a global optimum by",
    "start": "452220",
    "end": "457820"
  },
  {
    "text": "looking at all solutions. And that's something we'll see\nagain and again, as we go",
    "start": "457820",
    "end": "463060"
  },
  {
    "text": "forward, that there's always a\ntemptation to do things one step at a time, finding\nlocal optimum--",
    "start": "463060",
    "end": "470930"
  },
  {
    "text": "optima-- because it's fast. It's easy. But there's no guarantee\nit will work well.",
    "start": "470930",
    "end": "480490"
  },
  {
    "start": "479000",
    "end": "622000"
  },
  {
    "text": "Now the problem, of course,\nwith finding the global optimum is, as we discussed, it\nis prohibitively expensive.",
    "start": "480490",
    "end": "489229"
  },
  {
    "text": "Now you could ask is it\nprohibitively expensive because I chose a stupid\nalgorithm,",
    "start": "489230",
    "end": "495289"
  },
  {
    "text": "the brute force algorithm? Well, it is a stupid\nalgorithm.",
    "start": "495290",
    "end": "500420"
  },
  {
    "text": "But in fact, this is a problem\nthat is what we would call inherently exponential.",
    "start": "500420",
    "end": "506330"
  },
  {
    "start": "506330",
    "end": "518659"
  },
  {
    "text": "We've looked at this\nconcept before. That in addition to talking\nabout the complexity of an",
    "start": "518659",
    "end": "525910"
  },
  {
    "text": "algorithm, we can talk about the\ncomplexity of a problem in which we ask the question how\nfast can the absolute best",
    "start": "525910",
    "end": "534649"
  },
  {
    "text": "solution, fastest solution\nto this problem, be? And here you can construct a\nmathematical proof that says",
    "start": "534650",
    "end": "544230"
  },
  {
    "text": "the problem is inherently\nexponential. No matter what we do, we're not\ngoing to be able to find",
    "start": "544230",
    "end": "551880"
  },
  {
    "text": "something that's guaranteed to\nfind the optimal, that is faster than exponential.",
    "start": "551880",
    "end": "559090"
  },
  {
    "text": "Well, now let's be careful\nof that statement. What that means is the worst\ncase is inherently",
    "start": "559090",
    "end": "567420"
  },
  {
    "text": "exponential. As we will see in a couple of\nweeks-- it'll take us a while",
    "start": "567420",
    "end": "574070"
  },
  {
    "text": "to get there-- there are actually algorithms\nthat people use to solve these",
    "start": "574070",
    "end": "579730"
  },
  {
    "text": "inherently exponential problems\nand solve them fast enough to be useful.",
    "start": "579730",
    "end": "585010"
  },
  {
    "text": " So, for example, when you go\nto look at airline fares on",
    "start": "585010",
    "end": "591810"
  },
  {
    "text": "Kayak to try and find the best\nfare from A to B, it is an inherently exponential problem,\nbut you get an answer",
    "start": "591810",
    "end": "599310"
  },
  {
    "text": "pretty quickly. And that's because there are\ntechniques you can use.",
    "start": "599310",
    "end": "604740"
  },
  {
    "text": "Now, in fact, one of the reasons\nyou get it is they don't guarantee that\nyou actually get an optimal solution.",
    "start": "604740",
    "end": "610680"
  },
  {
    "text": "But there are techniques that\nguarantee to give you an optimal solution that almost all\nthe time will run quickly.",
    "start": "610680",
    "end": "618000"
  },
  {
    "text": "And we'll look at one of those\na bit later in the term.",
    "start": "618000",
    "end": "623110"
  },
  {
    "start": "622000",
    "end": "753000"
  },
  {
    "text": "Before we do that, however, I\nwant to leave for a while the",
    "start": "623110",
    "end": "630620"
  },
  {
    "text": "whole question of complexity\nbehind and look at another class of optimization\nproblems.",
    "start": "630620",
    "end": "638300"
  },
  {
    "text": "We'll look at several\ndifferent kinds of optimization problems as\nthe term goes forward. The kind I want to look at today\nis probably what I would",
    "start": "638300",
    "end": "650470"
  },
  {
    "text": "say is the most exciting\nbranch of computer science today. And of course I might\nhave a bias.",
    "start": "650470",
    "end": "656240"
  },
  {
    "text": "And that's machine learning. ",
    "start": "656240",
    "end": "665040"
  },
  {
    "text": "It's a word you'll\nhear a lot about. And it's a technique that\nmany of you will apply.",
    "start": "665040",
    "end": "674090"
  },
  {
    "text": "You might not write\nyour own codes. But I guarantee you were either\nbe the beneficiary or",
    "start": "674090",
    "end": "679370"
  },
  {
    "text": "the victim of machine learning\nalmost every time you log on to the web these days.",
    "start": "679370",
    "end": "685890"
  },
  {
    "text": "I should probably start\nby defining what machine learning is. But that's hard to do.",
    "start": "685890",
    "end": "692490"
  },
  {
    "text": "I really don't know\nhow to do it. Superficially, you could say\nthat machine learning deals",
    "start": "692490",
    "end": "698000"
  },
  {
    "text": "with the question of how to\nbuild programs that learn. However, I think in a very real\nsense every program we",
    "start": "698000",
    "end": "706089"
  },
  {
    "text": "write learns something. If I implement Newton's method,\nit's learning what the",
    "start": "706090",
    "end": "711660"
  },
  {
    "text": "roots of the polynomial is. Certainly when we looked\nat curve fitting--",
    "start": "711660",
    "end": "718750"
  },
  {
    "text": "fitting curves to data-- we were learning a model\nof the data. That's what that\nregression is.",
    "start": "718750",
    "end": "725840"
  },
  {
    "text": " Wikipedia says-- and of course, it must be true\nif Wikipedia says it--",
    "start": "725840",
    "end": "734240"
  },
  {
    "text": "that machine learning is a\nscientific discipline that is concerned with the design and\ndevelopment of algorithms that",
    "start": "734240",
    "end": "740959"
  },
  {
    "text": "allow computers to evolve\nbehaviors based on empirical data.",
    "start": "740960",
    "end": "746290"
  },
  {
    "text": "I'm not sure how helpful\nthis definition is. But it was the best\nI could find. And it doesn't really matter.",
    "start": "746290",
    "end": "751620"
  },
  {
    "text": " But it sort of gets at the issue\nthat a major focus of",
    "start": "751620",
    "end": "758910"
  },
  {
    "start": "753000",
    "end": "823000"
  },
  {
    "text": "machine learning research is\nto automatically learn to recognize complex patterns and\nmake intelligent decisions",
    "start": "758910",
    "end": "768640"
  },
  {
    "text": "based on data. This whole process is something",
    "start": "768640",
    "end": "775210"
  },
  {
    "text": "called inductive inference. ",
    "start": "775210",
    "end": "787300"
  },
  {
    "text": "The basic idea is\none observes-- actually one doesn't. The program observes examples\nthat represent an incomplete",
    "start": "787300",
    "end": "797620"
  },
  {
    "text": "information about some\nstatistical phenomena and then",
    "start": "797620",
    "end": "802750"
  },
  {
    "text": "tries to generate a model, just\nlike with curve fitting,",
    "start": "802750",
    "end": "808270"
  },
  {
    "text": "that summarizes some statistical\nproperties of that data and can be used to predict\nthe future, for",
    "start": "808270",
    "end": "819350"
  },
  {
    "text": "example, give you information\nabout unseen data. There are roughly speaking two\ndistinctive approaches to",
    "start": "819350",
    "end": "831420"
  },
  {
    "start": "823000",
    "end": "967000"
  },
  {
    "text": "machine learning called\nsupervised learning and",
    "start": "831420",
    "end": "841320"
  },
  {
    "text": "unsupervised learning. ",
    "start": "841320",
    "end": "857630"
  },
  {
    "text": "Let's first talk about\nsupervised learning. It's a little easier to\nappreciate how it might work.",
    "start": "857630",
    "end": "864650"
  },
  {
    "text": "In supervised learning, we\nassociate a label with each",
    "start": "864650",
    "end": "877450"
  },
  {
    "text": "example in a training set. ",
    "start": "877450",
    "end": "892450"
  },
  {
    "text": "So think of that as an answer\nto a query about an example. ",
    "start": "892450",
    "end": "898580"
  },
  {
    "text": "If the label is discrete,\nwe typically call it a",
    "start": "898580",
    "end": "906520"
  },
  {
    "text": "classification problem. ",
    "start": "906520",
    "end": "925630"
  },
  {
    "text": "So we would try and classify,\nfor example, a transaction on",
    "start": "925630",
    "end": "931470"
  },
  {
    "text": "a credit card as belonging to\nthe owner of that credit card or not belonging to the owner,\nas i.e., with some",
    "start": "931470",
    "end": "939360"
  },
  {
    "text": "probability, a stolen\ncredit card. So it's discrete. It belongs to the owner.",
    "start": "939360",
    "end": "944459"
  },
  {
    "text": "It doesn't belong\nto the owner. If the labels are real valued,\nwe think of it as",
    "start": "944460",
    "end": "954620"
  },
  {
    "text": "a regression problem. And so indeed, when we did the\ncurve fitting, we were doing",
    "start": "954620",
    "end": "961990"
  },
  {
    "text": "machine learning. And we were handling a\nregression problem. ",
    "start": "961990",
    "end": "968870"
  },
  {
    "text": "Based on the examples from the\ntraining set, the goal is to build a program that can predict\nthe answer for other",
    "start": "968870",
    "end": "977459"
  },
  {
    "text": "cases before they were\nexplicitly observed.",
    "start": "977460",
    "end": "983260"
  },
  {
    "text": "So we're trying to generalize\nfrom the statistical properties of a training set to\nbe able to make predictions",
    "start": "983260",
    "end": "990790"
  },
  {
    "text": "about things we haven't seen. ",
    "start": "990790",
    "end": "996960"
  },
  {
    "text": "Let's look at an example. ",
    "start": "996960",
    "end": "1008990"
  },
  {
    "text": "So here, I've got red\nand blue circles.",
    "start": "1008990",
    "end": "1017220"
  },
  {
    "text": "And I'm trying to learn what\nmakes a circle red or what's",
    "start": "1017220",
    "end": "1025240"
  },
  {
    "text": "the difference between red and\nblue, other than the color? Think of my information as the\n(x,y) values and the label as",
    "start": "1025240",
    "end": "1034939"
  },
  {
    "text": "the color, red or blue.  So I've labeled each one.",
    "start": "1034940",
    "end": "1040079"
  },
  {
    "text": "And now I'm trying to\nlearn something. Well, it's kind of tricky.",
    "start": "1040079",
    "end": "1045364"
  },
  {
    "text": " What are the questions I need to\nanswer to think about this?",
    "start": "1045364",
    "end": "1052410"
  },
  {
    "text": "And then we'll look at\nhow we might do it. So, a first question\nI need to ask is",
    "start": "1052410",
    "end": "1062720"
  },
  {
    "start": "1055000",
    "end": "1388000"
  },
  {
    "text": "are the labels accurate? ",
    "start": "1062720",
    "end": "1073070"
  },
  {
    "text": "And in fact, in a lot of real\nworld examples, in most real world examples, there's\nno guarantee that",
    "start": "1073070",
    "end": "1079410"
  },
  {
    "text": "the labels are accurate. So you have to assume that\nwell, maybe some of",
    "start": "1079410",
    "end": "1084640"
  },
  {
    "text": "the labels are wrong. How do we deal with that? ",
    "start": "1084640",
    "end": "1093150"
  },
  {
    "text": "Perhaps the most fundamental\nquestion is the past",
    "start": "1093150",
    "end": "1098810"
  },
  {
    "text": "representative of the future? ",
    "start": "1098810",
    "end": "1114240"
  },
  {
    "text": "We've seen many examples where\npeople have learned things,",
    "start": "1114240",
    "end": "1119640"
  },
  {
    "text": "for example, to predict\nthe price of housing.",
    "start": "1119640",
    "end": "1125110"
  },
  {
    "text": "And it turns out you hit some\nsingularity which means the past is not a very good\npredictor of the future.",
    "start": "1125110",
    "end": "1131710"
  },
  {
    "text": "And even if all of your learning\nis good, you get the wrong answer.",
    "start": "1131710",
    "end": "1136790"
  },
  {
    "text": "So you sort of always have\nto ask that question. Do you have enough data\nto generalize?",
    "start": "1136790",
    "end": "1145780"
  },
  {
    "start": "1145780",
    "end": "1155200"
  },
  {
    "text": "And by this, I mean enough\ntraining data. If your training set is very\nsmall, you shouldn't have a",
    "start": "1155200",
    "end": "1161970"
  },
  {
    "text": "lot of confidence in\nwhat you learn. ",
    "start": "1161970",
    "end": "1167770"
  },
  {
    "text": "A big issue here is feature\nextraction. ",
    "start": "1167770",
    "end": "1177720"
  },
  {
    "text": "As we'll see when we look at\nreal examples, the world is a pretty complex place.",
    "start": "1177720",
    "end": "1184350"
  },
  {
    "text": "And we need to decide what\nfeatures we're going to use.",
    "start": "1184350",
    "end": "1190419"
  },
  {
    "text": "If I were to ask 25% of you to\ncome up in the front of the room and then try and separate\nyou based upon some feature--",
    "start": "1190420",
    "end": "1199560"
  },
  {
    "text": "if I were to say, all right, I'm\ngoing to separate the good students from the bad students,\nbut the only features I have available are\nthe clothes you're wearing, it",
    "start": "1199560",
    "end": "1208390"
  },
  {
    "text": "might not work so well.  And very importantly, how\ntight should the fit be?",
    "start": "1208390",
    "end": "1217140"
  },
  {
    "start": "1217140",
    "end": "1227490"
  },
  {
    "text": "So now let's go back to\nour example here. ",
    "start": "1227490",
    "end": "1232750"
  },
  {
    "text": "We can look at two different\nways we might",
    "start": "1232750",
    "end": "1238660"
  },
  {
    "text": "generalize from this data. And indeed, when we're looking\nat classification problems in",
    "start": "1238660",
    "end": "1245410"
  },
  {
    "text": "supervised learning, what\nwe're typically doing is trying to find some way of\ndividing our training data.",
    "start": "1245410",
    "end": "1253404"
  },
  {
    "text": " In this case, I've given you a\ntwo-dimensional projection.",
    "start": "1253405",
    "end": "1259210"
  },
  {
    "text": "As we'll see, it's not always\ntwo-dimensional. It's not usually\ntwo-dimensional. So I might choose this rather\neccentric shape",
    "start": "1259210",
    "end": "1267850"
  },
  {
    "text": "and say that's great. And why is that great? It's great because it minimizes\ntraining error.",
    "start": "1267850",
    "end": "1275775"
  },
  {
    "text": " So if we look at it as an\noptimization problem, we might",
    "start": "1275775",
    "end": "1287880"
  },
  {
    "text": "say that our objective function\nis how many points",
    "start": "1287880",
    "end": "1294080"
  },
  {
    "text": "are correctly classified\nin the training data as red or blue.",
    "start": "1294080",
    "end": "1299980"
  },
  {
    "text": "And this triangular shape\nhas no training error.",
    "start": "1299980",
    "end": "1305679"
  },
  {
    "text": "Every point is perfectly\nclassified in the training data. If I choose this linear\nseparator instead, I have some",
    "start": "1305680",
    "end": "1314480"
  },
  {
    "text": "training error. This red point is misclassified\nin the training.",
    "start": "1314480",
    "end": "1321750"
  },
  {
    "text": "Does that mean that\nthe triangle is better than the line? Not necessarily, right?",
    "start": "1321750",
    "end": "1327340"
  },
  {
    "text": "Because my goal is to predict\nfuture points. And maybe that's mislabeled\nor an experimental error.",
    "start": "1327340",
    "end": "1336690"
  },
  {
    "text": "Maybe it's accurately labeled\nbut an outlier, very unusual.",
    "start": "1336690",
    "end": "1342049"
  },
  {
    "text": "And this will not\ngeneralize well. This is analogous to what we\ntalked about as overfitting",
    "start": "1342050",
    "end": "1348630"
  },
  {
    "text": "when we looked at\ncurve fitting. And that's-- a very big problem\nin machine learning is",
    "start": "1348630",
    "end": "1354510"
  },
  {
    "text": "if you overfit to your training\ndata, it might not generalize well and might\ngive you bogus",
    "start": "1354510",
    "end": "1361010"
  },
  {
    "text": "answers going forward. ",
    "start": "1361010",
    "end": "1366039"
  },
  {
    "text": "OK. So that's a very quick look\nat supervised learning.",
    "start": "1366040",
    "end": "1371860"
  },
  {
    "text": "We'll come back to that. I now want to talk about\nunsupervised learning. ",
    "start": "1371860",
    "end": "1378810"
  },
  {
    "text": "The big difference here is we\nhave training data, but we",
    "start": "1378810",
    "end": "1384940"
  },
  {
    "text": "don't have labels.  So I just give you a\nbunch of points.",
    "start": "1384940",
    "end": "1392889"
  },
  {
    "start": "1388000",
    "end": "1488000"
  },
  {
    "text": "It's as if we looked at this\npicture, and I didn't tell you which were the red points and\nwhich were the blue points.",
    "start": "1392890",
    "end": "1400240"
  },
  {
    "text": "They were just all points.  So what can I learn?",
    "start": "1400240",
    "end": "1408500"
  },
  {
    "text": "What typically you're learning\nin unsupervised learning, is",
    "start": "1408500",
    "end": "1428420"
  },
  {
    "text": "you're learning about\nregularities of the data.",
    "start": "1428420",
    "end": "1436195"
  },
  {
    "start": "1436195",
    "end": "1444580"
  },
  {
    "text": "So if we looked at this and\nthink away the red and the blue, we might well say well,\nat least, if I look at this,",
    "start": "1444580",
    "end": "1454880"
  },
  {
    "text": "there is some structure\nto this data. And maybe what I should do\nis divide it this way.",
    "start": "1454880",
    "end": "1461730"
  },
  {
    "text": "It gives me kind of a nice\nclean separation. But maybe I should divide\nit this way.",
    "start": "1461730",
    "end": "1468650"
  },
  {
    "text": "Or maybe I should put\na circle around each of these four groupings.",
    "start": "1468650",
    "end": "1474480"
  },
  {
    "text": "Complicated, what to do. But what we see is there is\nclearly some structure here.",
    "start": "1474480",
    "end": "1480740"
  },
  {
    "text": "And the idea of unsupervised\nlearning is to discover that structure.",
    "start": "1480740",
    "end": "1486200"
  },
  {
    "text": " Far and away, the dominant form\nof unsupervised learning",
    "start": "1486200",
    "end": "1493270"
  },
  {
    "start": "1488000",
    "end": "1594000"
  },
  {
    "text": "is clustering. And that's what I was just\ntalking about, is finding the",
    "start": "1493270",
    "end": "1500110"
  },
  {
    "text": "cluster in this data. So we'll move forward here.",
    "start": "1500110",
    "end": "1508659"
  },
  {
    "text": "There it is, with everything\nthe same color. But here I've labeled\nthe x- and y-axes",
    "start": "1508660",
    "end": "1517100"
  },
  {
    "text": "as height and weight. ",
    "start": "1517100",
    "end": "1522640"
  },
  {
    "text": "What does clustering mean? It's the process of organizing\nthe objects or the points into",
    "start": "1522640",
    "end": "1529300"
  },
  {
    "text": "groups whose members are\nsimilar in some way.",
    "start": "1529300",
    "end": "1535280"
  },
  {
    "text": "A key issue is what do\nwe mean by similar? What's the metric\nwe want to use?",
    "start": "1535280",
    "end": "1542120"
  },
  {
    "text": "And we can see that here. If I tell you that,\nreally, I want to cluster people by height--",
    "start": "1542120",
    "end": "1550080"
  },
  {
    "text": "say, people are similar if\nthey're the same height-- then it's pretty clear how I\nshould divide this, right,",
    "start": "1550080",
    "end": "1556789"
  },
  {
    "text": "what my clusters should be. My clusters should probably be\nthis group of shorter people",
    "start": "1556790",
    "end": "1562590"
  },
  {
    "text": "and this group of\ntaller people.  If I tell you I'm interested\nin weight, then probably I",
    "start": "1562590",
    "end": "1571510"
  },
  {
    "text": "want a cluster it with the\ndivisor here between the heavier people and the\nlighter people.",
    "start": "1571510",
    "end": "1578950"
  },
  {
    "text": "Or if I say well, I'm interested\nin some combination of those two, then maybe I'll\nget four clusters as I",
    "start": "1578950",
    "end": "1587090"
  },
  {
    "text": "discussed before. ",
    "start": "1587090",
    "end": "1595840"
  },
  {
    "text": "Clustering algorithms are\nused all over the place. For example, in marketing,\nthey're used to find groups of",
    "start": "1595840",
    "end": "1603800"
  },
  {
    "text": "customers with similar\nbehavior. Walmart is famous for using that\nclustering to find that.",
    "start": "1603800",
    "end": "1612380"
  },
  {
    "text": "They did a clustering to\ndetermine when people bought the same thing.",
    "start": "1612380",
    "end": "1618010"
  },
  {
    "text": "And then they would rearrange\ntheir shelves to encourage people to buy things. And sort of the most famous\nexample they discovered was",
    "start": "1618010",
    "end": "1625360"
  },
  {
    "text": "there was a strong correlation\nbetween people between people who bought beer and people\nwho bought diapers.",
    "start": "1625360",
    "end": "1631790"
  },
  {
    "text": "And so there was a period\nwhere if you walked in a Walmart store, you would find\nthe beer and the diapers next to each other.",
    "start": "1631790",
    "end": "1637550"
  },
  {
    "text": "And I leave it to you\nto speculate on why that was true. It just happened to be\ntrue in Walmart.",
    "start": "1637550",
    "end": "1643215"
  },
  {
    "text": " Amazon uses clustering to find\npeople who like similar books.",
    "start": "1643215",
    "end": "1650600"
  },
  {
    "text": "So every time you buy a book on\nAmazon, they're running a clustering algorithm to find\nout who looks like you.",
    "start": "1650600",
    "end": "1657090"
  },
  {
    "text": "Said, oh, this person\nlooks just like you. So if they buy a book, maybe\nyou'll get an email suggesting",
    "start": "1657090",
    "end": "1662130"
  },
  {
    "text": "you buy that book or the next\ntime you log into Amazon. Or when you look at a book, they\ntell you here are some",
    "start": "1662130",
    "end": "1668800"
  },
  {
    "text": "similar books. And then they've done a\nclustering to group books as similar based on\nbuying habits.",
    "start": "1668800",
    "end": "1676380"
  },
  {
    "text": "Netflix uses that to recommend\nmovies, et cetera.",
    "start": "1676380",
    "end": "1681550"
  },
  {
    "text": "Biologists spend a lot of time\nthese days doing clustering.",
    "start": "1681550",
    "end": "1687420"
  },
  {
    "text": "They classify plants or animals based on their features. We'll shortly see an example\nof that, as in right after",
    "start": "1687420",
    "end": "1694890"
  },
  {
    "text": "Patriot's Day. But they also use it\na lot in genetics. So clustering is used to try and\nfind genes that look like",
    "start": "1694890",
    "end": "1704140"
  },
  {
    "text": "or groups of genes. Insurance companies use that to\ndecide how much to charge",
    "start": "1704140",
    "end": "1710929"
  },
  {
    "text": "you for your automobile\ninsurance. They cluster drivers based\nupon-- and use that to predict",
    "start": "1710930",
    "end": "1716990"
  },
  {
    "text": "who's going to have\nan accident. Document classification on the\nweb is used all the time.",
    "start": "1716990",
    "end": "1725830"
  },
  {
    "text": "It's used a lot in medicine. Just used all over the place. So what is it exactly?",
    "start": "1725830",
    "end": "1731649"
  },
  {
    "text": "Well the nice thing is\nwe can define it very straightforwardly as an\noptimization problem.",
    "start": "1731650",
    "end": "1739840"
  },
  {
    "text": "And so we can ask what\nproperties does a good clustering have?",
    "start": "1739840",
    "end": "1744920"
  },
  {
    "text": " Well, it should have low\nintra-cluster dissimilarity.",
    "start": "1744920",
    "end": "1756900"
  },
  {
    "start": "1756900",
    "end": "1766100"
  },
  {
    "text": "So in a good clustering, all\nof the points in the same cluster should be similar, by\nwhatever metric you're using",
    "start": "1766100",
    "end": "1774059"
  },
  {
    "text": "for similarity. As we'll see, there are a\nlot of choices there. But that's not enough.",
    "start": "1774060",
    "end": "1781960"
  },
  {
    "text": "We'd also like to have high\ninter-cluster dissimilarity.",
    "start": "1781960",
    "end": "1795299"
  },
  {
    "text": "So we'd like the points within\na cluster to be a lot like each other. But if points are in different\nclusters, we'd like them to be",
    "start": "1795300",
    "end": "1801730"
  },
  {
    "text": "quite different from\neach other. That tells us that we\nhave a good cluster.",
    "start": "1801730",
    "end": "1807894"
  },
  {
    "text": "All right, let's look at it. ",
    "start": "1807894",
    "end": "1818639"
  },
  {
    "text": "How might we model\ndissimilarity? Well, using a concept we've\nalready seen-- variance.",
    "start": "1818640",
    "end": "1826760"
  },
  {
    "text": "So we can talk about the\nvariance of some cluster C as",
    "start": "1826760",
    "end": "1837940"
  },
  {
    "text": "equal to the sum of all elements\nx in C, of the mean",
    "start": "1837940",
    "end": "1845774"
  },
  {
    "text": "of C minus x squared.",
    "start": "1845775",
    "end": "1853210"
  },
  {
    "text": "Or maybe we can take the square\nroot of it, if we want. But it's exactly the idea we've\nseen before, right?",
    "start": "1853210",
    "end": "1859990"
  },
  {
    "text": "Then we say what's the average\nvalue of the cluster? And then we look at how far is\neach point from the average.",
    "start": "1859990",
    "end": "1866000"
  },
  {
    "text": "We sum them. And that tells us how\nmuch variance we have within the cluster. ",
    "start": "1866000",
    "end": "1873810"
  },
  {
    "text": "Make sense?  So that's variance.",
    "start": "1873810",
    "end": "1879680"
  },
  {
    "text": " So we can use that to talk\nabout how similar or",
    "start": "1879680",
    "end": "1886190"
  },
  {
    "text": "dissimilar the elements\nin the cluster are. ",
    "start": "1886190",
    "end": "1891860"
  },
  {
    "text": "We can use the same idea to\ncompare points in separate clusters and compute various\ndifferent ways-- and we'll",
    "start": "1891860",
    "end": "1900660"
  },
  {
    "text": "look at different ways-- to look at the distance\nbetween clusters.",
    "start": "1900660",
    "end": "1906510"
  },
  {
    "text": "So combining these two things,\nwe could get, say, a metric we'll call badness--",
    "start": "1906510",
    "end": "1912140"
  },
  {
    "text": " not a technical word.",
    "start": "1912140",
    "end": "1917480"
  },
  {
    "start": "1914000",
    "end": "2117000"
  },
  {
    "text": "And now I'll ask the question\nis the optimization problem",
    "start": "1917480",
    "end": "1923470"
  },
  {
    "text": "that we're solving\nin clustering finding a set of clusters-- capital C--",
    "start": "1923470",
    "end": "1929230"
  },
  {
    "text": "such that badness of that set\nof clusters is minimized? ",
    "start": "1929230",
    "end": "1936080"
  },
  {
    "text": "Is that a sufficient definition\nof the problem we're trying to solve?",
    "start": "1936080",
    "end": "1942710"
  },
  {
    "text": "Find a set of clusters\nC, such that the badness of C is minimized.",
    "start": "1942710",
    "end": "1949130"
  },
  {
    "text": "is that good enough? AUDIENCE: No. PROFESSOR: No, why not?",
    "start": "1949130",
    "end": "1955010"
  },
  {
    "text": "AUDIENCE: Just imagine a case\nwhere you view cluster-- if you make a single cluster,\nevery cluster has one element in it.",
    "start": "1955010",
    "end": "1960169"
  },
  {
    "text": "And the variance is 0. PROFESSOR: Exactly. So that has a trivial solution,\nwhich is probably",
    "start": "1960170",
    "end": "1966890"
  },
  {
    "text": "not the one we want,\nof putting each point in its own cluster.",
    "start": "1966890",
    "end": "1974039"
  },
  {
    "text": "Badness-- it won't be bad. It'll be a perfect clustering\nin some sense. But it doesn't do us\nany good really.",
    "start": "1974040",
    "end": "1982640"
  },
  {
    "text": "So what do we do to fix that? What do we usually do\nwhen we formulate an optimization problem?",
    "start": "1982640",
    "end": "1988360"
  },
  {
    "text": "What's missing? I've given you the objective\nfunction. What have I not giving you?",
    "start": "1988360",
    "end": "1993620"
  },
  {
    "text": "AUDIENCE: Constraints. PROFESSOR: A constraint. So we need to add some\nconstraint here that will",
    "start": "1993620",
    "end": "2002620"
  },
  {
    "text": "prevent us from finding\na trivial solution. So what kind of constraints\nmight we look at?",
    "start": "2002620",
    "end": "2011700"
  },
  {
    "text": "There are different\nways of doing it. ",
    "start": "2011700",
    "end": "2016950"
  },
  {
    "text": "A couple of ones\nthat is usual. Sometimes you might have as a\nconstraint, the maximum number",
    "start": "2016950",
    "end": "2023520"
  },
  {
    "text": "of clusters.  Say, all right, cluster my data,\nbut I want at most K",
    "start": "2023520",
    "end": "2032529"
  },
  {
    "text": "clusters -- 10 clusters. That would be my constraint,\nlike the weight for the",
    "start": "2032530",
    "end": "2038600"
  },
  {
    "text": "knapsack problem. Or maybe I'll want to put\nsomething on the maximum",
    "start": "2038600",
    "end": "2047740"
  },
  {
    "text": "distance between clusters. So I don't want the distance\nbetween any two clusters to be",
    "start": "2047740",
    "end": "2053110"
  },
  {
    "text": "more than something. ",
    "start": "2053110",
    "end": "2059540"
  },
  {
    "text": "In general, solving this\noptimization problem is computationally prohibitive.",
    "start": "2059540",
    "end": "2065690"
  },
  {
    "text": "So once again, in practice, what\npeople typically resort to is greedy algorithms.",
    "start": "2065690",
    "end": "2072699"
  },
  {
    "text": "And I want to look at two kinds\nof greedy algorithms, probably the two most common\napproaches to clustering.",
    "start": "2072699",
    "end": "2081020"
  },
  {
    "text": "One is called k-means. ",
    "start": "2081020",
    "end": "2087145"
  },
  {
    "text": "In k-means clustering, you say\nI want exactly k clusters.",
    "start": "2087145",
    "end": "2092385"
  },
  {
    "text": " And find the best\nk clustering.",
    "start": "2092385",
    "end": "2097950"
  },
  {
    "text": "We'll talk about how\nit does that. And again, it's not guaranteed\nto find the best.",
    "start": "2097950",
    "end": "2103170"
  },
  {
    "text": "And the other is hierarchical\nclustering. ",
    "start": "2103170",
    "end": "2114210"
  },
  {
    "text": "We'll come back to\nthat shortly. Both are simple to understand\nand widely used in practice.",
    "start": "2114210",
    "end": "2122750"
  },
  {
    "start": "2117000",
    "end": "2389000"
  },
  {
    "text": "So let's first talk about\nhow we do this.",
    "start": "2122750",
    "end": "2128380"
  },
  {
    "text": "Let's first look at hierarchical\nclustering. ",
    "start": "2128380",
    "end": "2138200"
  },
  {
    "text": "So we have a set of n items\nto be clustered. And let's assume we have an n\nby n distance matrix that",
    "start": "2138200",
    "end": "2154670"
  },
  {
    "text": "tells me for each pair of items\nhow far they are from",
    "start": "2154670",
    "end": "2159790"
  },
  {
    "text": "each other.  So we can look at an example.",
    "start": "2159790",
    "end": "2165970"
  },
  {
    "text": "So here's an n by n distance\nmatrix for the airline distance between some cities\nin the United States.",
    "start": "2165970",
    "end": "2174230"
  },
  {
    "text": "The distance from Boston\nto Boston is 0 miles. Distance from New York is 206.",
    "start": "2174230",
    "end": "2180450"
  },
  {
    "text": "The distance from Chicago\nto San Francisco is 2,142, et cetera.",
    "start": "2180450",
    "end": "2186480"
  },
  {
    "text": "All right? So I have my n by n distance\nmatrix there. ",
    "start": "2186480",
    "end": "2193200"
  },
  {
    "text": "Now let's go through how\nhierarchical clustering would relate these things\nto each other.",
    "start": "2193200",
    "end": "2200540"
  },
  {
    "text": "So we start by assigning each\nitem to its own cluster.",
    "start": "2200540",
    "end": "2211490"
  },
  {
    "start": "2211490",
    "end": "2219910"
  },
  {
    "text": "So if we have n items, we\nnow have n clusters. ",
    "start": "2219910",
    "end": "2228250"
  },
  {
    "text": "All right? That's the trivial solution\nthat you suggested before.",
    "start": "2228250",
    "end": "2233430"
  },
  {
    "text": "The next step is to find the\nmost similar pair of clusters",
    "start": "2233430",
    "end": "2254359"
  },
  {
    "text": "and merge them. ",
    "start": "2254360",
    "end": "2262310"
  },
  {
    "text": "So if we look here and we just--\nwe start, we'll have",
    "start": "2262310",
    "end": "2269150"
  },
  {
    "text": "six clusters, one\nfor each city. And we would merge the two most\nsimilar, which I guess in",
    "start": "2269150",
    "end": "2276185"
  },
  {
    "text": "this case is New York\nand Boston. Hard to believe that those are\nthe most similar cities.",
    "start": "2276185",
    "end": "2281920"
  },
  {
    "text": "But at least by this distance\nmetric they're the closest. So we would merge those two.",
    "start": "2281920",
    "end": "2287450"
  },
  {
    "start": "2287450",
    "end": "2294530"
  },
  {
    "text": "And then you just continue the\nprocess in principle, until",
    "start": "2294530",
    "end": "2304680"
  },
  {
    "text": "all items are in one cluster. So now you have a whole\nhierarchy of clusters.",
    "start": "2304680",
    "end": "2310809"
  },
  {
    "text": "And you can cut it off\nwhere you want. If you want to have six\nclusters, you could look at",
    "start": "2310810",
    "end": "2316020"
  },
  {
    "text": "where the hierarchy\nyou have six. You can look where you have\ntwo, where you have three.",
    "start": "2316020",
    "end": "2321160"
  },
  {
    "text": "Of course, you don't have to go\nall the way to finish it if you don't want to. This kind of hierarchical\nclustering is called",
    "start": "2321160",
    "end": "2328450"
  },
  {
    "text": "agglomerative. ",
    "start": "2328450",
    "end": "2337880"
  },
  {
    "text": "Why? Well, because we're\ncombining things. We're agglomerating them. ",
    "start": "2337880",
    "end": "2347890"
  },
  {
    "text": "So this is pretty straightforward, except for two. ",
    "start": "2347890",
    "end": "2355690"
  },
  {
    "text": "The complication in step (2) is\nwe have to define what it",
    "start": "2355690",
    "end": "2362460"
  },
  {
    "text": "means to find the two most\nsimilar clusters. ",
    "start": "2362460",
    "end": "2368560"
  },
  {
    "text": "Now it's pretty easy when the\nclusters each contain one element, because, well, we\nhave our metric-- in this",
    "start": "2368560",
    "end": "2376590"
  },
  {
    "text": "case, distance-- and we can just do\nthat as I did. But it's not so obvious\nwhat you do when they",
    "start": "2376590",
    "end": "2384809"
  },
  {
    "text": "have multiple elements. ",
    "start": "2384810",
    "end": "2389940"
  },
  {
    "start": "2389000",
    "end": "2542000"
  },
  {
    "text": "And in fact, different metrics\ncan be used to get different",
    "start": "2389940",
    "end": "2395250"
  },
  {
    "text": "properties. So I want to talk about\nsome of the metrics we use for that.",
    "start": "2395250",
    "end": "2400690"
  },
  {
    "text": "These are typically called\nlinkage criteria. ",
    "start": "2400690",
    "end": "2413990"
  },
  {
    "text": "So one popular one is what's\ncalled single linkage. ",
    "start": "2413990",
    "end": "2424170"
  },
  {
    "text": "It's also called connectedness, or minimum method. In this, we consider the\ndistance between a pair of",
    "start": "2424170",
    "end": "2431160"
  },
  {
    "text": "clusters to be equal to the\nshortest distance from any",
    "start": "2431160",
    "end": "2436680"
  },
  {
    "text": "member to any other member. ",
    "start": "2436680",
    "end": "2460220"
  },
  {
    "text": "So we take the two points in\neach cluster that are closest to each other and say\nthat's the distance",
    "start": "2460220",
    "end": "2466780"
  },
  {
    "text": "between the two clusters. ",
    "start": "2466780",
    "end": "2474490"
  },
  {
    "text": "People also use something called\ncomplete linkage-- ",
    "start": "2474490",
    "end": "2481376"
  },
  {
    "text": "It's also called diameter\nor maximum-- where we consider the distance\nbetween any two clusters to be",
    "start": "2481376",
    "end": "2490010"
  },
  {
    "text": "the distance between the points\nthat are furthest from each other. ",
    "start": "2490010",
    "end": "2500060"
  },
  {
    "text": "So in one case, essentially\nsingle linkages was looking at the best case.",
    "start": "2500060",
    "end": "2507150"
  },
  {
    "text": "Complete-- in English, not French-- is looking at the worst case.",
    "start": "2507150",
    "end": "2513450"
  },
  {
    "text": " And you won't be surprised to\nhear that you could also look",
    "start": "2513450",
    "end": "2521870"
  },
  {
    "text": "at the average case, where you\ntake all of the distances.",
    "start": "2521870",
    "end": "2531175"
  },
  {
    "text": " So you take all of the\npairwise things. You add them up.",
    "start": "2531175",
    "end": "2537020"
  },
  {
    "text": "You take the average. You can also take the mean, the median, if you want instead.",
    "start": "2537020",
    "end": "2543640"
  },
  {
    "start": "2542000",
    "end": "2707000"
  },
  {
    "text": "None of these is necessarily\nbest. But they do give you\ndifferent answers.",
    "start": "2543640",
    "end": "2549789"
  },
  {
    "text": "And so I want to look at that\nnow with our example here. ",
    "start": "2549790",
    "end": "2555369"
  },
  {
    "text": "So let's look at\nit and run it. So the first step is independent\nof what linkage",
    "start": "2555370",
    "end": "2561740"
  },
  {
    "text": "we're using. We get these six clusters. All right, now let's look\nat the second step.",
    "start": "2561740",
    "end": "2571790"
  },
  {
    "text": "Well, also pretty simple\nsince we only have one element in each one.",
    "start": "2571790",
    "end": "2577400"
  },
  {
    "text": "We're going to get\nthat clustering. ",
    "start": "2577400",
    "end": "2582750"
  },
  {
    "text": "All right. Now, what about the next step?",
    "start": "2582750",
    "end": "2588960"
  },
  {
    "text": "What do I get if I'm\nusing the minimal single linkage distance?",
    "start": "2588960",
    "end": "2595350"
  },
  {
    "text": "What gets merged here? ",
    "start": "2595350",
    "end": "2603640"
  },
  {
    "text": "Somebody? AUDIENCE: Boston, New\nYork and Chicago. PROFESSOR: Boston, New\nYork, and Chicago. ",
    "start": "2603640",
    "end": "2611910"
  },
  {
    "text": "And it turns out we'll get the\nsame thing if we use other linkages in this case.",
    "start": "2611910",
    "end": "2617270"
  },
  {
    "text": "Let's continue to\nthe next step. ",
    "start": "2617270",
    "end": "2623060"
  },
  {
    "text": "Now we'll end up merging San\nFrancisco and Seattle. ",
    "start": "2623060",
    "end": "2632840"
  },
  {
    "text": "Now we get a difference. What does the red represent\nand what does the blue represent?",
    "start": "2632840",
    "end": "2638520"
  },
  {
    "text": "Which linkage criteria? We're saying, we could either\nmerge Denver with Boston, New",
    "start": "2638520",
    "end": "2644590"
  },
  {
    "text": "York, and Chicago. Or we could merge Denver with\nSan Francisco and Seattle.",
    "start": "2644590",
    "end": "2650185"
  },
  {
    "text": " Which is which?",
    "start": "2650185",
    "end": "2656790"
  },
  {
    "text": "Which linkage criterion has put\nDenver in which cluster? ",
    "start": "2656790",
    "end": "2670910"
  },
  {
    "text": "Well, suppose we're using\nsingle linkage. Where are we getting it from?",
    "start": "2670910",
    "end": "2677519"
  },
  {
    "text": "AUDIENCE: Boston, New\nYork and Chicago? PROFESSOR: Yes. Because it's not so\nfar from Chicago. Even though it's pretty far\nfrom Boston or New York.",
    "start": "2677520",
    "end": "2685924"
  },
  {
    "text": "But if we use average linkage,\nwe see on average, it's closer to San Francisco and Seattle\nthan it is to the average of",
    "start": "2685924",
    "end": "2695180"
  },
  {
    "text": "Boston, New York, or Chicago. So we get a different answer.",
    "start": "2695180",
    "end": "2700920"
  },
  {
    "text": "And then finally, at\nthe last step, everything gets merged together.",
    "start": "2700920",
    "end": "2708270"
  },
  {
    "start": "2707000",
    "end": "2866000"
  },
  {
    "text": "So you can see, in this case,\nwithout having labels, we have",
    "start": "2708270",
    "end": "2715940"
  },
  {
    "text": "used a feature to produce things\nand, say, if we wanted",
    "start": "2715940",
    "end": "2722200"
  },
  {
    "text": "to have three clusters, we\nwould maybe stop here. And we'd say, all right, these\nthings are one cluster.",
    "start": "2722200",
    "end": "2728300"
  },
  {
    "text": "This is a cluster. And this is a cluster. And that's not a bad\ngeographical clustering,",
    "start": "2728300",
    "end": "2733640"
  },
  {
    "text": "actually, for deciding\nhow to relate these things to each other. ",
    "start": "2733640",
    "end": "2740890"
  },
  {
    "text": "This technique is used a lot. It does have some weaknesses.",
    "start": "2740890",
    "end": "2746260"
  },
  {
    "text": "One weakness is it's very\ntime consuming. It doesn't scale well.",
    "start": "2746260",
    "end": "2753310"
  },
  {
    "text": "The complexity is at least order\nn-squared, where n is",
    "start": "2753310",
    "end": "2758370"
  },
  {
    "text": "the number of points\nto be clustered.",
    "start": "2758370",
    "end": "2763900"
  },
  {
    "text": "And in fact, in many\nimplementations, it's worse than n-squared. And of course, it doesn't\nnecessarily find the optimal",
    "start": "2763900",
    "end": "2773010"
  },
  {
    "text": "clustering, even giving\nthese criteria. It might never at any level have\nthe optimal clustering,",
    "start": "2773010",
    "end": "2781190"
  },
  {
    "text": "because, again, at each step,\nit's making a locally optimal decision, not guaranteed to\nfind the best solution.",
    "start": "2781190",
    "end": "2788435"
  },
  {
    "text": " I should point out that a big\nissue in deciding to get these",
    "start": "2788435",
    "end": "2798950"
  },
  {
    "text": "clusters or getting\nthese clusters was my choice of features.",
    "start": "2798950",
    "end": "2806920"
  },
  {
    "text": "And this is something we're\ngoing to come back to in spades, because I actually think\nit is the most important",
    "start": "2806920",
    "end": "2814700"
  },
  {
    "text": "issue in machine learning-- is if we're going to say which\npoints are similar to each",
    "start": "2814700",
    "end": "2821310"
  },
  {
    "text": "other, we need to understand\nour feature space.",
    "start": "2821310",
    "end": "2826840"
  },
  {
    "text": "So, for example, the feature\nI'm using here is distance by air.",
    "start": "2826840",
    "end": "2834340"
  },
  {
    "text": "Suppose, instead, I added\ndistance by air and distance by road and distance by train.",
    "start": "2834340",
    "end": "2842900"
  },
  {
    "text": "Well, particularly given this\nsparsity of railroads in this country, we might get very\ndifferent clustering,",
    "start": "2842900",
    "end": "2849180"
  },
  {
    "text": "depending upon where\nthe trains ran. And suppose I throw in a totally\ndifferent feature like",
    "start": "2849180",
    "end": "2856590"
  },
  {
    "text": "population. Well, I might get another\ndifferent clustering,",
    "start": "2856590",
    "end": "2862040"
  },
  {
    "text": "depending on how I use that.  What we typically need to do in\nthese situations, dealing",
    "start": "2862040",
    "end": "2874910"
  },
  {
    "start": "2866000",
    "end": "2982000"
  },
  {
    "text": "with multi-dimensional data--\nand most data is multi-dimensional-- is we construct something called\na feature vector that",
    "start": "2874910",
    "end": "2886790"
  },
  {
    "text": "incorporates multiple\nfeatures. So we might have\nfor each city--",
    "start": "2886790",
    "end": "2894870"
  },
  {
    "text": "we'll just take something\nlike the distance. ",
    "start": "2894870",
    "end": "2902599"
  },
  {
    "text": "Or let's say, instead of\ndistance, we'll compute the distance by having for each\ncity its GPS coordinates,",
    "start": "2902600",
    "end": "2913810"
  },
  {
    "text": "where it is on the globe,\nand its population.",
    "start": "2913810",
    "end": "2919110"
  },
  {
    "text": "And let's say that's how\nwe define a city. And that would be our\nfeature vector.",
    "start": "2919110",
    "end": "2925070"
  },
  {
    "text": "And then we would cluster it,\nsay, using hierarchical clustering to determine which\ncities are most like which",
    "start": "2925070",
    "end": "2931140"
  },
  {
    "text": "other cities. Well, it's a little\nbit complicated.",
    "start": "2931140",
    "end": "2936280"
  },
  {
    "text": "I have to ask how do I compare\nfeature vectors?",
    "start": "2936280",
    "end": "2941760"
  },
  {
    "text": "What distance metric\ndo I use there? Do I get confused that GPS\ncoordinates and populations",
    "start": "2941760",
    "end": "2949600"
  },
  {
    "text": "are essentially unrelated? And I wouldn't like to compare\nthose to each other.",
    "start": "2949600",
    "end": "2956240"
  },
  {
    "text": "Lots of issues there, and that's\nwhat we're going to talk about when we come back\nfrom Patriot's Day--",
    "start": "2956240",
    "end": "2962500"
  },
  {
    "text": "is how in the real world\nproblems, we go from the large number of features associated\nwith objects or things in the",
    "start": "2962500",
    "end": "2970430"
  },
  {
    "text": "real world to feature vectors\nthat allow us to automatically deduce which things are\nquote \"most similar\"",
    "start": "2970430",
    "end": "2977829"
  },
  {
    "text": "to which other things. ",
    "start": "2977830",
    "end": "2982485"
  }
]
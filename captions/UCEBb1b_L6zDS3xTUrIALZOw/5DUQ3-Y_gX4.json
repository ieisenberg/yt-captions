[
  {
    "text": "[SQUEAKING] [RUSTLING] [CLICKING] ",
    "start": "0",
    "end": "10650"
  },
  {
    "text": "STEVEN G. JOHNSON: So I want\nto revisit the things that Alan talked about, but\njust a little bit more",
    "start": "10650",
    "end": "17700"
  },
  {
    "text": "slowly and a bit more-- just try and lay out the rules\nfor you as clearly as I can.",
    "start": "17700",
    "end": "23213"
  },
  {
    "text": "And what we're\ngoing to try and do is, again, just revisit\nthe notion of a derivative",
    "start": "23213",
    "end": "29460"
  },
  {
    "text": "to try and write it in a\nway that we can generalize to other kinds of objects.",
    "start": "29460",
    "end": "34829"
  },
  {
    "text": "And so I'm going\nto start with 18.01 and then go to\n18.02 and so forth. So as Alan said, the key\nnotion of a derivative,",
    "start": "34830",
    "end": "43530"
  },
  {
    "text": "just, I think, it's easy to get\nso good at taking derivatives, like knowing the rule\nfor the derivative",
    "start": "43530",
    "end": "49980"
  },
  {
    "text": "of sine or cosine or x squared. You're so good at doing them\nthat you forget what they are,",
    "start": "49980",
    "end": "56020"
  },
  {
    "text": "right? And so the very first thing\nyou learned about a derivative is that it's the\nslope of the tangent.",
    "start": "56020",
    "end": "63000"
  },
  {
    "text": "But what that really\nis is linearization.",
    "start": "63000",
    "end": "68370"
  },
  {
    "text": "So you have some arbitrary\nmaybe nonlinear function f of x. And you're at a point x.",
    "start": "68370",
    "end": "76210"
  },
  {
    "text": "And near that\npoint, you're going to approximate the function\nwith a straight line.",
    "start": "76210",
    "end": "81950"
  },
  {
    "text": "That's the tangent. So it's really the linear\napproximation of f. And then if you move a\nlittle bit away from x-- so",
    "start": "81950",
    "end": "90870"
  },
  {
    "text": "let me call that\ndelta x, so not d. Delta is going to\nbe a finite change.",
    "start": "90870",
    "end": "97470"
  },
  {
    "text": "d is going to be\ninfinitesimal pretty soon. But if you move it just a finite\namount, a little finite amount",
    "start": "97470",
    "end": "103200"
  },
  {
    "text": "delta x away, of course,\nthe function value changes. But in a linear approximation,\nthe new function value",
    "start": "103200",
    "end": "112350"
  },
  {
    "text": "is the red dot here. So that linear\napproximation is, if you're taking the function f\nof x at x plus delta x,",
    "start": "112350",
    "end": "124030"
  },
  {
    "text": "the new value is f of x. And then this\nlinear thing is just",
    "start": "124030",
    "end": "130270"
  },
  {
    "text": "the slope, which we call f\nprime of x times delta x. That's just the\ndefinition of the slope.",
    "start": "130270",
    "end": "135400"
  },
  {
    "text": "It's the little change in\ny for a little change in x. And, of course, these\ntwo terms are not exact.",
    "start": "135400",
    "end": "143440"
  },
  {
    "text": "This red dot doesn't\nexactly match where you are in the real function. So there are also corrections.",
    "start": "143440",
    "end": "149420"
  },
  {
    "text": "But the corrections\nare higher order. They're terms look like delta\nx squared, delta x cubed maybe.",
    "start": "149420",
    "end": "155365"
  },
  {
    "text": "Maybe if the function\nis not higher-- it doesn't have\nhigher derivatives, it might have square root of\ndelta x, so delta x to the 1.1.",
    "start": "155365",
    "end": "163600"
  },
  {
    "text": "But these are all\nterms that are going to be higher powers\nof delta x terms that, if delta x is\nsufficiently small,",
    "start": "163600",
    "end": "171520"
  },
  {
    "text": "these terms will become\nmore and more negligible compared to this linear term.",
    "start": "171520",
    "end": "177790"
  },
  {
    "text": "And a nice notation\nfor this that's used a lot in computer science,\nless so outside of that,",
    "start": "177790",
    "end": "186040"
  },
  {
    "text": "but it is used in calculus\nas well, maybe not in 18.01, is this asymptotic notation.",
    "start": "186040",
    "end": "191300"
  },
  {
    "text": "In computer science,\nprobably many of you will have seen big O notation.",
    "start": "191300",
    "end": "196400"
  },
  {
    "text": "Here, I'm going to use a variant\ncalled little o notation. So this is not a capital\nO. This is a lowercase o.",
    "start": "196400",
    "end": "203150"
  },
  {
    "text": "So these terms we call\nlittle o of delta x. It's a little o of delta x.",
    "start": "203150",
    "end": "209090"
  },
  {
    "text": "It denotes any function that\ngoes to 0 faster than linear,",
    "start": "209090",
    "end": "214879"
  },
  {
    "text": "faster than delta x. So delta x squared goes\nto 0 faster than delta",
    "start": "214880",
    "end": "221840"
  },
  {
    "text": "x as delta x goes to 0. I should say as\ndelta x goes to 0.",
    "start": "221840",
    "end": "230689"
  },
  {
    "text": "And so you look at this\nthing and this probably",
    "start": "230690",
    "end": "236930"
  },
  {
    "text": "looks a lot like\na Taylor series. You do a Taylor\nexpansion of f of x plus delta x around f of x.",
    "start": "236930",
    "end": "242750"
  },
  {
    "text": "This is the first term. This is the second term. The third term, remember, is 1/2\nf double prime delta x squared",
    "start": "242750",
    "end": "250670"
  },
  {
    "text": "or something like that. But that's the wrong\nway to look at this. A Taylor series is a much\nmore advanced concept.",
    "start": "250670",
    "end": "259350"
  },
  {
    "text": "It's something you can\ndo much later in calculus and for good reason. Because not every function\neven has a Taylor series",
    "start": "259350",
    "end": "265699"
  },
  {
    "text": "that converges. This is more basic. This is really the\ndefinition of a derivative.",
    "start": "265700",
    "end": "270950"
  },
  {
    "text": "The derivative is\nthe linearization. If you make a small change\nin delta x, the change in f",
    "start": "270950",
    "end": "280580"
  },
  {
    "text": "is a linear term\nplus smaller stuff. And that smaller stuff only\ngives you a Taylor series",
    "start": "280580",
    "end": "288270"
  },
  {
    "text": "if it's basically a polynomial. It might be smaller stuff\nlike delta x to the 1.1",
    "start": "288270",
    "end": "293693"
  },
  {
    "text": "in which case it doesn't\nhave a Taylor series. But this is always true. This is just this\nis what it means",
    "start": "293693",
    "end": "299150"
  },
  {
    "text": "to be the slope of a tangent. And so the nice\nthing about this is",
    "start": "299150",
    "end": "304630"
  },
  {
    "text": "Alan says this notion, if we\nkeep the delta x on the right, this is going to be much\neasier to generalize",
    "start": "304630",
    "end": "314560"
  },
  {
    "text": "to other kinds of x's that are\nvectors or matrices or even other functions,\nother kinds of things.",
    "start": "314560",
    "end": "320995"
  },
  {
    "text": " So this is the linearization. Whoops.",
    "start": "320995",
    "end": "326440"
  },
  {
    "start": "326440",
    "end": "332490"
  },
  {
    "text": "So we're going to have\na delta f, which I'm",
    "start": "332490",
    "end": "340630"
  },
  {
    "text": "going to have to define as-- whoops, let me put it in black--",
    "start": "340630",
    "end": "346540"
  },
  {
    "text": "f of x plus delta x. And again, the delta,\nthe Greek letter delta,",
    "start": "346540",
    "end": "352270"
  },
  {
    "text": "is not infinitesimal. It's just a small number. It's just a number.",
    "start": "352270",
    "end": "357475"
  },
  {
    "text": " This is that thing.",
    "start": "357475",
    "end": "364510"
  },
  {
    "text": "But I'm going to drop\nterms, higher order terms.",
    "start": "364510",
    "end": "372215"
  },
  {
    "text": "So there'll be an error there.  Well, yeah, so actually let\nme put this another way.",
    "start": "372215",
    "end": "379460"
  },
  {
    "text": "So this is going to be\napproximately f prime of x",
    "start": "379460",
    "end": "387100"
  },
  {
    "text": "delta x plus higher order terms. ",
    "start": "387100",
    "end": "393980"
  },
  {
    "text": "This is the higher order. ",
    "start": "393980",
    "end": "400229"
  },
  {
    "text": "So this is the small change\nin the input of the function.",
    "start": "400230",
    "end": "412090"
  },
  {
    "text": " And this is the resulting\nsmall change in the output.",
    "start": "412090",
    "end": "421875"
  },
  {
    "start": "421875",
    "end": "428380"
  },
  {
    "text": "And this is going to be the\ndefinition of the derivative.",
    "start": "428380",
    "end": "433630"
  },
  {
    "text": "The derivative is whatever you\ndo to delta x to first order",
    "start": "433630",
    "end": "439900"
  },
  {
    "text": "to give you the linear change\nin the output for a small change in the input.",
    "start": "439900",
    "end": "446870"
  },
  {
    "text": "It's a little annoying, though,\nto keep these o's around.",
    "start": "446870",
    "end": "452210"
  },
  {
    "text": "So we keep always\nhaving to-- whenever we have a finite\nchange in the input and a finite change in the\noutput, this is never exact.",
    "start": "452210",
    "end": "459260"
  },
  {
    "text": "This is an approximate\nrelationship. And we have to keep saying\nplus higher order terms,",
    "start": "459260",
    "end": "466460"
  },
  {
    "text": "plus higher order terms,\nplus little o delta x. And it's annoying.",
    "start": "466460",
    "end": "472010"
  },
  {
    "text": "So it's easier to use to switch\nto differential notation.",
    "start": "472010",
    "end": "479200"
  },
  {
    "start": "479200",
    "end": "487530"
  },
  {
    "text": "So I'm just going to\nchange my delta to d.",
    "start": "487530",
    "end": "493130"
  },
  {
    "text": "So df is going to be f of\nx plus dx minus f of x.",
    "start": "493130",
    "end": "506000"
  },
  {
    "text": " And this is going to be f\nprime of x dx where this is--",
    "start": "506000",
    "end": "518150"
  },
  {
    "text": "I'm just going to right equal. So we can think of\nthis differential in dx",
    "start": "518150",
    "end": "525949"
  },
  {
    "text": "as being arbitrarily small.  So it's really a limit, some\nkind of limit, of course.",
    "start": "525950",
    "end": "533285"
  },
  {
    "text": " And so you can also think of\nit as really it's just this.",
    "start": "533285",
    "end": "541760"
  },
  {
    "text": "But I'm just implicitly going\nto drop any higher order terms. ALAN EDELMAN: That's how\nI like to think of it.",
    "start": "541760",
    "end": "548440"
  },
  {
    "text": "STEVEN G. JOHNSON: Right? So we don't have\nto get too fancy with defining differentials.",
    "start": "548440",
    "end": "553850"
  },
  {
    "text": "I mean, this is a\ndefinition, right? This is just shorthand\nfor this where",
    "start": "553850",
    "end": "560350"
  },
  {
    "text": "I don't have to write plus\na little o over delta x all the time.",
    "start": "560350",
    "end": "565726"
  },
  {
    "text": "Let's see. ",
    "start": "565726",
    "end": "582020"
  },
  {
    "text": "And so it's important to keep\nin-- so this f prime to delta x, this is the derivative.",
    "start": "582020",
    "end": "590060"
  },
  {
    "text": "Here df is the differential.",
    "start": "590060",
    "end": "595580"
  },
  {
    "text": "So if I ask you\nfor the derivative, I'm asking for f prime. I'm not asking for df.",
    "start": "595580",
    "end": "601480"
  },
  {
    "text": "Of course, they're related. And let's see if we can\nmove this out of the way. Good.",
    "start": "601480",
    "end": "606700"
  },
  {
    "text": " So what was I saying?",
    "start": "606700",
    "end": "612030"
  },
  {
    "text": "Yes.  So now, what I want\nto do is basically use",
    "start": "612030",
    "end": "618110"
  },
  {
    "text": "this as the definition of a\nderivative, a more general definition of a derivative. So the linear algebra\nnotion is that we have",
    "start": "618110",
    "end": "628940"
  },
  {
    "text": "what's called a linear operator. ",
    "start": "628940",
    "end": "637230"
  },
  {
    "text": "So basically, the\nchange in the output df",
    "start": "637230",
    "end": "649440"
  },
  {
    "text": "is going to be a\nlinear operator.",
    "start": "649440",
    "end": "655300"
  },
  {
    "text": "Let me write that\nas times, which",
    "start": "655300",
    "end": "667800"
  },
  {
    "text": "I'm going to call f prime of x\ntimes the change in the input.",
    "start": "667800",
    "end": "673600"
  },
  {
    "start": "673600",
    "end": "681399"
  },
  {
    "text": "This is our-- whoops. Actually, but my input\nis in red, right? That's my color code.",
    "start": "681400",
    "end": "687280"
  },
  {
    "text": "My color scheme is input\nis red and output is blue.",
    "start": "687280",
    "end": "694450"
  },
  {
    "text": "So this is our dx. ",
    "start": "694450",
    "end": "699620"
  },
  {
    "text": "So I'm going to interpret\nthis more generally. If x is going to be some kind\nof vector or matrix or whatever,",
    "start": "699620",
    "end": "705260"
  },
  {
    "text": "this is just going to be a\nlinear operation on this. And of course, for numbers,\na linear operation,",
    "start": "705260",
    "end": "712120"
  },
  {
    "text": "this is just a number. If dx is a number, the only\nlinear operation you can do is multiply by a number.",
    "start": "712120",
    "end": "717320"
  },
  {
    "text": "So let me just remind you if\nyou haven't taken linear algebra",
    "start": "717320",
    "end": "723610"
  },
  {
    "text": "for a while, a review. ",
    "start": "723610",
    "end": "741380"
  },
  {
    "text": "Let's talk about what\na linear operator is. So suppose we have\nsome given vectors, v,",
    "start": "741380",
    "end": "753140"
  },
  {
    "text": "in some vector space. ",
    "start": "753140",
    "end": "761280"
  },
  {
    "text": "That would be capital\nV. And remember, a vector space is anything\nwhere you can basically",
    "start": "761280",
    "end": "770460"
  },
  {
    "text": "add, subtract, and\nmultiply by scalars. ",
    "start": "770460",
    "end": "778709"
  },
  {
    "text": "We have a plus or minus\nand times scalar operations",
    "start": "778710",
    "end": "785350"
  },
  {
    "text": "that stay in our vector space. That's what the informal\ndefinition of a vector space is. You can write out\naxioms and so forth,",
    "start": "785350",
    "end": "791410"
  },
  {
    "text": "but that's basically\nwhat it means. A linear operator,\nthis is what we're",
    "start": "791410",
    "end": "799970"
  },
  {
    "text": "going to mean by linearization\nin the derivative. It has to be linear. What does it mean to\nbe linear in general?",
    "start": "799970",
    "end": "806712"
  },
  {
    "text": "So we're going to call this-- I'm going to denote this\nby, let's say, L of--",
    "start": "806712",
    "end": "816810"
  },
  {
    "text": "let me denote it by square\nbrackets or just by Lv.",
    "start": "816810",
    "end": "827250"
  },
  {
    "text": "When it's clear enough,\nI'll just write it as if it were a multiplication. Often, that'll be clear enough.",
    "start": "827250",
    "end": "834060"
  },
  {
    "text": "This is really acting on-- when I write Lv,\nit's not necessarily",
    "start": "834060",
    "end": "839220"
  },
  {
    "text": "an ordinary multiplication. This is just going\nto be acting on v.",
    "start": "839220",
    "end": "845750"
  },
  {
    "text": "So a linear operator is a rule\nthat basically takes a vector",
    "start": "845750",
    "end": "853708"
  },
  {
    "text": "and gives you a vector out maybe\nin a different vector space. So this is L takes\na vector in, v in,",
    "start": "853708",
    "end": "867900"
  },
  {
    "text": "and it gives you a vector-- ",
    "start": "867900",
    "end": "876212"
  },
  {
    "text": "that's a terrible L-- Lv out maybe in a\ndifferent vector space.",
    "start": "876212",
    "end": "884000"
  },
  {
    "text": "And linearity means\nwhat you think it means.",
    "start": "884000",
    "end": "892950"
  },
  {
    "text": "It means if you\ntake, for example, L of v1 plus v2, if you take\nthe sum of the inputs, that's",
    "start": "892950",
    "end": "906930"
  },
  {
    "text": "the same thing as L\nof v1 plus L of v2.",
    "start": "906930",
    "end": "915510"
  },
  {
    "text": "So if you add inputs,\nthat's the same thing as adding the outputs or if\nyou multiply by a scalar.",
    "start": "915510",
    "end": "922630"
  },
  {
    "text": "And so as usual\nin linear algebra, Greek letters are going to\ndenote scalars as you would.",
    "start": "922630",
    "end": "930990"
  },
  {
    "text": "So that's equal to-- you can pull out the scalar. ",
    "start": "930990",
    "end": "942759"
  },
  {
    "text": "And so the nice thing\nabout linear operators is we can define them on lots\nof kinds of vector spaces.",
    "start": "942760",
    "end": "948770"
  },
  {
    "text": "So let's just do a\ncouple of examples just to make sure we're\non the same page here.",
    "start": "948770",
    "end": "954264"
  },
  {
    "text": " And so, for example,\nyou could just",
    "start": "954265",
    "end": "962610"
  },
  {
    "text": "have L is multiplication\nby a scalar.",
    "start": "962610",
    "end": "967695"
  },
  {
    "start": "967695",
    "end": "972830"
  },
  {
    "text": "So you can have just L\nof v is just alpha v.",
    "start": "972830",
    "end": "983530"
  },
  {
    "text": "That's a perfectly\ngood linear operation. And if your vector space,\nif your vs are scalars,",
    "start": "983530",
    "end": "989500"
  },
  {
    "text": "this is the only option. ",
    "start": "989500",
    "end": "1003790"
  },
  {
    "text": "If vs are, say,\nreal numbers, that's a perfectly good vector space.",
    "start": "1003790",
    "end": "1009250"
  },
  {
    "text": "Another one that you're\nvery familiar with is if L is a\nmultiplication by a matrix.",
    "start": "1009250",
    "end": "1017653"
  },
  {
    "text": "ALAN EDELMAN: Steven, maybe I'll\njust point out sometimes people like to ask me. Wait, I thought that the linear\noperators on scalars are,",
    "start": "1017653",
    "end": "1027530"
  },
  {
    "text": "I think in high school notation,\ny equals mx plus b, right? It's scalar times-- STEVEN G. JOHNSON: Yeah, yeah.",
    "start": "1027530",
    "end": "1033660"
  },
  {
    "text": "ALAN EDELMAN: --plus an\noffset that may not be 0. So what's going on here? Is that linear or not linear?",
    "start": "1033660",
    "end": "1039760"
  },
  {
    "text": "STEVEN G. JOHNSON: Yeah. So what about-- yeah,\nso let's do that.",
    "start": "1039760",
    "end": "1045439"
  },
  {
    "start": "1045440",
    "end": "1051389"
  },
  {
    "text": "Let me call it a\ndifferent thing. What letter should I use?",
    "start": "1051390",
    "end": "1057179"
  },
  {
    "text": "O, let's use O. Ov equals 2v\nplus 1 for v is real numbers.",
    "start": "1057180",
    "end": "1076868"
  },
  {
    "text": "ALAN EDELMAN: Is that\nlinear or not linear? That is the question. ",
    "start": "1076868",
    "end": "1082005"
  },
  {
    "text": "The graph is a line. So we all think of it\nas linear, but go ahead.",
    "start": "1082005",
    "end": "1088840"
  },
  {
    "text": "STEVEN G. JOHNSON: Yeah. So does it satisfy the rules? That's the question. So if I multiply the\ninput by 2, does it",
    "start": "1088840",
    "end": "1095570"
  },
  {
    "text": "multiply the output by 2? No. ",
    "start": "1095570",
    "end": "1103650"
  },
  {
    "text": "So if we do O of 2-- no, let's do 3.",
    "start": "1103650",
    "end": "1109273"
  },
  {
    "text": "3v, that's, what, 6v plus 1.",
    "start": "1109273",
    "end": "1118500"
  },
  {
    "text": " And that's very much\nnot equal to 3Ov,",
    "start": "1118500",
    "end": "1130820"
  },
  {
    "text": "which that would be 6v plus 3.",
    "start": "1130820",
    "end": "1138679"
  },
  {
    "start": "1138680",
    "end": "1144640"
  },
  {
    "text": "So this one, it\ndoes have a name. It's related. These are sometimes\ncalled affine. ",
    "start": "1144640",
    "end": "1156270"
  },
  {
    "text": "ALAN EDELMAN: Affine, but\nnot linear even if the graph is demonstrably aligned?",
    "start": "1156270",
    "end": "1161640"
  },
  {
    "text": "STEVEN G. JOHNSON: Yeah. ALAN EDELMAN: They're not linear\nin the sense of linear algebra. ",
    "start": "1161640",
    "end": "1169608"
  },
  {
    "text": "STEVEN G. JOHNSON: Right? So another one is clearly\nmultiplication by a matrix.",
    "start": "1169608",
    "end": "1177250"
  },
  {
    "text": "That's why we do matrices\nin linear algebra. Because they're a nice way of\nwriting down a linear operation",
    "start": "1177250",
    "end": "1182950"
  },
  {
    "text": "if your vs are column vectors. They're not the only way of\nwriting down linear operation.",
    "start": "1182950",
    "end": "1188800"
  },
  {
    "text": "So for example, if you\ntake a column vector and multiply it by\n3, you could write",
    "start": "1188800",
    "end": "1193809"
  },
  {
    "text": "that down as a matrix with\nall 3s along the diagonal. But it's a lot easier\nto write that down as 3, I'd say, as a scalar, than\nto write it down as a matrix.",
    "start": "1193810",
    "end": "1201370"
  },
  {
    "text": " So another example,\njust to be more--",
    "start": "1201370",
    "end": "1209345"
  },
  {
    "text": " so another vector space.",
    "start": "1209345",
    "end": "1215200"
  },
  {
    "text": "If you took 1806, you learned\nthat we can have a-- whoops, I have to get my color scheme.",
    "start": "1215200",
    "end": "1220420"
  },
  {
    "text": "Yeah, so my vectors are red. ",
    "start": "1220420",
    "end": "1226260"
  },
  {
    "text": "Suppose the vector space V is\nthe set of functions f of x",
    "start": "1226260",
    "end": "1238190"
  },
  {
    "text": "that take real numbers in and\ngive you real numbers out. Those are a perfectly\ngood vector space.",
    "start": "1238190",
    "end": "1244580"
  },
  {
    "text": "I can take two functions. I can add them or subtract\nthem, get another function. I can take a function\nand multiply by 2,",
    "start": "1244580",
    "end": "1250220"
  },
  {
    "text": "get another function. ALAN EDELMAN: Wait, how do\nwe get sine plus cosine? STEVEN G. JOHNSON: I get\nsine x plus cosine x.",
    "start": "1250220",
    "end": "1257708"
  },
  {
    "text": "It's just got some\nother function. ",
    "start": "1257708",
    "end": "1264590"
  },
  {
    "text": "So if you take sine\nx plus cosine x,",
    "start": "1264590",
    "end": "1270289"
  },
  {
    "text": "that's the function f of x\nequals sine x plus cosine x. It's another rule\nthat gives you-- takes real numbers to real numbers.",
    "start": "1270290",
    "end": "1277580"
  },
  {
    "text": "And so what would be your\nlinear operators on this? ",
    "start": "1277580",
    "end": "1285490"
  },
  {
    "text": "Well, multiplication by a\nscalar, that, of course, works. So let's think of L on a\nfunction f of x is just 2 f",
    "start": "1285490",
    "end": "1300330"
  },
  {
    "text": "of x. That takes a function\nin, function out. That's linear. What about a linear operator\non a function of f of x?",
    "start": "1300330",
    "end": "1310440"
  },
  {
    "text": "Again, that gives you\nthe derivative, just",
    "start": "1310440",
    "end": "1320620"
  },
  {
    "text": "the ordinary 18.01 derivative. This is the 18.01 derivative.",
    "start": "1320620",
    "end": "1328080"
  },
  {
    "text": "Obviously, that only works if\nthe function is differentiable. So maybe we can\nlook at the subspace",
    "start": "1328080",
    "end": "1336900"
  },
  {
    "text": "of differentiable functions.  That's also a vector space.",
    "start": "1336900",
    "end": "1343549"
  },
  {
    "text": "Because if I take two\ndifferentiable functions and add or subtract or\nmultiply by constants, they're still differentiable.",
    "start": "1343550",
    "end": "1349880"
  },
  {
    "text": "I could also do integration.  So if f of x that takes\na function f of x in",
    "start": "1349880",
    "end": "1358610"
  },
  {
    "text": "and gives you the integral\nfrom, I don't know, 0 to x of f prime--",
    "start": "1358610",
    "end": "1364355"
  },
  {
    "text": "no, so f of x prime and dx\nprime if they're integrable.",
    "start": "1364355",
    "end": "1371120"
  },
  {
    "text": "Again, we need to\nrestrict what functions are allowed if we're taking\nderivatives or integrals, so",
    "start": "1371120",
    "end": "1376400"
  },
  {
    "text": "things where these exist. But this is perfectly linear. Why? Because if I take the\nfunction and I double it,",
    "start": "1376400",
    "end": "1384110"
  },
  {
    "text": "if I double the integrand,\nit doubles the integrals. If I add two integrands,\nyou add the integrals.",
    "start": "1384110",
    "end": "1391790"
  },
  {
    "text": "Integration is a\nlinear operation. Derivative is a\nlinear operation. Another fun one is suppose\nwe take L of f of x.",
    "start": "1391790",
    "end": "1408420"
  },
  {
    "text": "And the output is the\nfunction f of x squared.",
    "start": "1408420",
    "end": "1419180"
  },
  {
    "text": "So this doesn't look linear. I have a square there. ",
    "start": "1419180",
    "end": "1425630"
  },
  {
    "text": "But why is this linear? Why? Because, let's see, if I\ntake L of two functions,",
    "start": "1425630",
    "end": "1439315"
  },
  {
    "text": "if I have f of x plus g of x,\nthat should be f of x squared",
    "start": "1439315",
    "end": "1447389"
  },
  {
    "text": "plus g of x squared. I'm squaring the\ninput, not the output.",
    "start": "1447390",
    "end": "1453690"
  },
  {
    "text": "So that's equal to\nL of f plus L of g.",
    "start": "1453690",
    "end": "1462351"
  },
  {
    "text": "ALAN EDELMAN: So\nI'll just comment. Leave it to mathematicians to\ntake what most people would think of as just a\ncolumn of numbers",
    "start": "1462352",
    "end": "1468830"
  },
  {
    "text": "and abstract it out and say that\nthis finite dimensional column",
    "start": "1468830",
    "end": "1475090"
  },
  {
    "text": "of numbers is somehow the\nsame as continuous functions or differentiable functions,\nsatisfies the same axioms.",
    "start": "1475090",
    "end": "1485410"
  },
  {
    "text": "So we'll call it a\nvector space as well. STEVEN G. JOHNSON: Yeah. But it's incredibly\nuseful, though.",
    "start": "1485410",
    "end": "1490630"
  },
  {
    "text": "Because very often, especially\nin physical sciences, you have something where\nconceptually you're",
    "start": "1490630",
    "end": "1498220"
  },
  {
    "text": "solving for a functions. So you're solving for the\nfluid flow or something around an airplane wing.",
    "start": "1498220",
    "end": "1504100"
  },
  {
    "text": "And what you want is that\nthen take that fluid flow and compute the drag\non the airplane wing.",
    "start": "1504100",
    "end": "1511930"
  },
  {
    "text": "And then in order\nto optimize it, you want the derivative\nof the drag with respect to that flow field, with\nrespect to the function,",
    "start": "1511930",
    "end": "1519550"
  },
  {
    "text": "or with respect to the\nshape of the airplane, which is a function. So it's very, very nice to\nbe able to take derivatives",
    "start": "1519550",
    "end": "1525910"
  },
  {
    "text": "connected to functions and\nwork with vector functions as vector spaces. And very soon we're going\nto be able to do that",
    "start": "1525910",
    "end": "1534050"
  },
  {
    "text": "with this notion\nof a derivative. Because we're going to be able\nto define linear operators,",
    "start": "1534050",
    "end": "1541730"
  },
  {
    "text": "functions that act on functions. And linear operators\nare functions. But that's getting a bit\ntoo far ahead of ourselves.",
    "start": "1541730",
    "end": "1549690"
  },
  {
    "text": "OK. So the point is that\nthe 18.01-- so far, we haven't done any derivatives\nmore than 18.01, at least",
    "start": "1549690",
    "end": "1554770"
  },
  {
    "text": "in my half. Alan went a bit further. But already we can start\nto see, hopefully, how",
    "start": "1554770",
    "end": "1562220"
  },
  {
    "text": "this is going to generalize. So if you have a\nfunction f of x and you make a small change\nin the input, delta x,",
    "start": "1562220",
    "end": "1569990"
  },
  {
    "text": "and you ask for the small\nchange in the output to first order, which we can\ndenote with this d notation,",
    "start": "1569990",
    "end": "1577100"
  },
  {
    "text": "the derivative is\nthe linear operator that gives us that,\nthe linearization",
    "start": "1577100",
    "end": "1582440"
  },
  {
    "text": "of that function for a\nsmall change in the input. And that is exactly equivalent\nto what you learned in 18.01.",
    "start": "1582440",
    "end": "1591160"
  },
  {
    "text": "But it's going to be easier\nnow to generalize this to other kinds of inputs\nand other kinds of outputs,",
    "start": "1591160",
    "end": "1597760"
  },
  {
    "text": "where, in 18.01, we move this to\nthe side where we take df, dx.",
    "start": "1597760",
    "end": "1602890"
  },
  {
    "text": "We divide them. For numbers, that's fine. For other kinds of things, that\nbecomes a little bit weirder",
    "start": "1602890",
    "end": "1609387"
  },
  {
    "text": "to talk about. Of course, you could\ndefine it as notation. But I think it's a\nlot clearer if you",
    "start": "1609387",
    "end": "1616039"
  },
  {
    "text": "think of it in this sense\nonce you start generalizing to other kinds of objects. So with that said,\nlet's do that.",
    "start": "1616040",
    "end": "1623240"
  },
  {
    "text": "Now, let's revisit 18.02.",
    "start": "1623240",
    "end": "1631429"
  },
  {
    "text": "And let me do it in two parts.  So part one is going\nto be functions--",
    "start": "1631430",
    "end": "1639919"
  },
  {
    "text": "the first thing you\nusually do in 18.02, which is functions that take a\nvector in or multiple variables",
    "start": "1639920",
    "end": "1645890"
  },
  {
    "text": "in. But we'll think of it as a\nvector in and a scalar out. So we're going to have a scalar.",
    "start": "1645890",
    "end": "1654720"
  },
  {
    "text": "My output is blue, right? Yes. We'll keep the same\ncolor scheme, good.",
    "start": "1654720",
    "end": "1660799"
  },
  {
    "text": "So we're going to have a scalar\nfunction f of a vector input x.",
    "start": "1660800",
    "end": "1675928"
  },
  {
    "text": "And I'll put a little\nvector sign above it. I won't always do that, but\nit's nice to be clear sometimes,",
    "start": "1675928",
    "end": "1684948"
  },
  {
    "text": "which is a vector,\nwhich is a scalar. So x is going to live in our m.",
    "start": "1684948",
    "end": "1690380"
  },
  {
    "text": "So this is going to be an\nm component column vector. ",
    "start": "1690380",
    "end": "1702130"
  },
  {
    "text": "OK. And what we want\nto do is imagine what happens to the\noutput when you change",
    "start": "1702130",
    "end": "1713880"
  },
  {
    "text": "the input by a little bit. So we're going to\ntake f of x plus dx.",
    "start": "1713880",
    "end": "1729370"
  },
  {
    "text": "Think of this as a\nreally small change. It's infinitesimal. We're going to\ndrop anything that",
    "start": "1729370",
    "end": "1735340"
  },
  {
    "text": "goes like dx squared or anything\nlike that, any higher terms. Let me just move\nit to [INAUDIBLE]..",
    "start": "1735340",
    "end": "1741040"
  },
  {
    "text": "It's black-- minus f of x.",
    "start": "1741040",
    "end": "1746190"
  },
  {
    "text": "And we're going to define\nthis as f prime of x dx.",
    "start": "1746190",
    "end": "1762830"
  },
  {
    "text": "So we wanted to note we have an\narbitrary change in the inputs. dx is an arbitrary,\nvery, very small vector.",
    "start": "1762830",
    "end": "1771970"
  },
  {
    "text": "And we want to ask, what's\nthe change in the output differential, df? And the answer is\ngoing to be that this",
    "start": "1771970",
    "end": "1778840"
  },
  {
    "text": "is going to be, for\na very small dx, we can approximate this by\na linear operator on dx.",
    "start": "1778840",
    "end": "1786460"
  },
  {
    "text": "So this is going to be a\nlinear operator, always",
    "start": "1786460",
    "end": "1795110"
  },
  {
    "text": "going to be a linear operator. And what is that\nlinear operator do?",
    "start": "1795110",
    "end": "1800320"
  },
  {
    "text": "This one takes a vector\nin and gives you a scalar.",
    "start": "1800320",
    "end": "1806380"
  },
  {
    "text": "So this has to equal a-- df is a scalar,\nbut dx is a vector.",
    "start": "1806380",
    "end": "1815110"
  },
  {
    "text": "So what this has to be is it\nhas to be kind of a row vector. ",
    "start": "1815110",
    "end": "1823340"
  },
  {
    "text": "You can think of it more\nas a one-row matrix. ",
    "start": "1823340",
    "end": "1830870"
  },
  {
    "text": "Or there's fancier names\nfor this, like covector or dual vector.",
    "start": "1830870",
    "end": "1837890"
  },
  {
    "text": "We won't really use that. I just want to throw\nthem out there. ",
    "start": "1837890",
    "end": "1844160"
  },
  {
    "text": "So if you want to take a vector\nin and take a vector out,",
    "start": "1844160",
    "end": "1850458"
  },
  {
    "text": "you need to multiply\nby a row vector. Another way of thinking\nabout it is you need to take the dot product-- ALAN EDELMAN: The vector\nand the scalar out.",
    "start": "1850458",
    "end": "1855930"
  },
  {
    "text": "STEVEN G. JOHNSON: The vector\nand scalar out-- sorry. You need to multiply\nit by a one row thing. Another way of\nthinking about it is",
    "start": "1855930",
    "end": "1862200"
  },
  {
    "text": "that, if you have a\nlinear operation that takes a vector in and\ngives you a scalar",
    "start": "1862200",
    "end": "1870990"
  },
  {
    "text": "out, the only type of thing\nthat does that is a dot product.",
    "start": "1870990",
    "end": "1877035"
  },
  {
    "start": "1877035",
    "end": "1884253"
  },
  {
    "text": "If you take a dot product of\nthe vector, you get a scalar. And that's the only\nlinear operation that gives you a scalar\nfrom a vector in some sense.",
    "start": "1884253",
    "end": "1891070"
  },
  {
    "text": "And so this is a dot\nproduct with some vector. That vector must\nbe pretty special.",
    "start": "1891070",
    "end": "1897669"
  },
  {
    "text": "And so we'll give it a name. And we'll call\nthat the gradient.",
    "start": "1897670",
    "end": "1904400"
  },
  {
    "text": "So I think this is going\nto be the gradient of f. And this is the thing we\ntake the dot product with",
    "start": "1904400",
    "end": "1919580"
  },
  {
    "text": "to get our scalar df. So you can think of this\nin linear algebra terms.",
    "start": "1919580",
    "end": "1929570"
  },
  {
    "text": "So this dot product\nis the same thing",
    "start": "1929570",
    "end": "1935470"
  },
  {
    "text": "as multiplying by a transpose. So this is the same thing as--",
    "start": "1935470",
    "end": "1941120"
  },
  {
    "text": " this is saying that f prime\nis really grad f transpose.",
    "start": "1941120",
    "end": "1952000"
  },
  {
    "text": "Or equivalently, f prime\ndx is the operation of a dot product\nwith a gradient.",
    "start": "1952000",
    "end": "1957140"
  },
  {
    "text": "This is going to be really\npowerful pretty soon because it's going to also\nallow us to generalize gradients",
    "start": "1957140",
    "end": "1963130"
  },
  {
    "text": "to other kinds of vector spaces. As long as we have a dot\nproduct and a scalar function, you'll be able to\ndefine a gradient.",
    "start": "1963130",
    "end": "1969050"
  },
  {
    "text": "So if you have a scalar function\nof-- if this is something that takes a matrix in and a scalar\nout, like a determinant,",
    "start": "1969050",
    "end": "1975160"
  },
  {
    "text": "pretty soon we're going\nto be able to take the gradient of a determinant. We'll be able to\ndefine what that means.",
    "start": "1975160",
    "end": "1982120"
  },
  {
    "text": "ALAN EDELMAN: Just\nto be clear, what is on the other side\nof that equals sign that you just wrote? ",
    "start": "1982120",
    "end": "1988872"
  },
  {
    "text": "STEVEN G. JOHNSON:\nSo, yes, the f-- yeah, I should write that. That's the f prime. ",
    "start": "1988872",
    "end": "1996760"
  },
  {
    "text": "Yeah. So this is-- yeah. I need to-- my equals-- let's see. The gradient of f is the\nthing we take a dot product.",
    "start": "1996760",
    "end": "2004309"
  },
  {
    "text": "And here it's f\nprime of x is this.",
    "start": "2004310",
    "end": "2010483"
  },
  {
    "text": "ALAN EDELMAN: Exactly. It's f prime of x. And it's not df. STEVEN G. JOHNSON: Yeah. It's not-- no dx.",
    "start": "2010483",
    "end": "2015919"
  },
  {
    "text": "Just the f prime by\nitself is a row vector. That's the transpose\nof the gradient.",
    "start": "2015920",
    "end": "2022940"
  },
  {
    "text": "So now, that's the\ndefinition of the gradient. It's only something\nwe're usually",
    "start": "2022940",
    "end": "2028130"
  },
  {
    "text": "going to define for scalar\nfunctions of vectors. And pretty soon, we'll be\nable to generalize that",
    "start": "2028130",
    "end": "2033770"
  },
  {
    "text": "to other kinds of vectors,\nbut will still be a scalar. And it's the thing you\ntake the dot product",
    "start": "2033770",
    "end": "2038810"
  },
  {
    "text": "with of dx, of the differential,\nand the change in the input with to get the change\nin the output, OK?",
    "start": "2038810",
    "end": "2046575"
  },
  {
    "start": "2046575",
    "end": "2059710"
  },
  {
    "text": "Yeah. So we did-- Alan did the\nexample of x transpose x.",
    "start": "2059710",
    "end": "2064989"
  },
  {
    "text": "Let's do another\nexample just for fun. ",
    "start": "2064989",
    "end": "2070929"
  },
  {
    "text": "So suppose f of x. ",
    "start": "2070929",
    "end": "2078980"
  },
  {
    "text": "So x is going to be a vector. Suppose that x transpose\nAx where-- so this is x.",
    "start": "2078980",
    "end": "2093210"
  },
  {
    "text": "x here is going to\nhave m components. And so we're going to let\nA be an m by m matrix.",
    "start": "2093210",
    "end": "2101530"
  },
  {
    "text": "ALAN EDELMAN: And are you\nassuming asymmetric or-- STEVEN G. JOHNSON: No, I'm not. I won't make it symmetric\njust for generality, OK?",
    "start": "2101530",
    "end": "2111820"
  },
  {
    "text": "And so this is going to be--  A is not going to be an input.",
    "start": "2111820",
    "end": "2118037"
  },
  {
    "text": "This is just going to\nbe a constant matrix.  So when I do my d's, when I\nchange x, A does not change.",
    "start": "2118038",
    "end": "2126589"
  },
  {
    "text": " OK. So let me do it\nthe long way first,",
    "start": "2126590",
    "end": "2132280"
  },
  {
    "text": "and then we'll try\nand derive some rules.",
    "start": "2132280",
    "end": "2138430"
  },
  {
    "text": "So let's do the long way-- ",
    "start": "2138430",
    "end": "2144000"
  },
  {
    "text": "long way, but still\nfaster than doing it component by component, faster\nthan the 18.02 component",
    "start": "2144000",
    "end": "2156100"
  },
  {
    "text": "by component. ",
    "start": "2156100",
    "end": "2163720"
  },
  {
    "text": "Because I could take the\nderivative of this with respect to x1, with respect to x2, with\nrespect to all the components,",
    "start": "2163720",
    "end": "2171370"
  },
  {
    "text": "and then build up the gradient. It starts to become really\nawkward really quickly.",
    "start": "2171370",
    "end": "2176380"
  },
  {
    "text": "I know it can be tempting when\nyou're faced with new problems to fall back on what\nyou know, right?",
    "start": "2176380",
    "end": "2182080"
  },
  {
    "text": "And that's not a bad strategy. But we really want\nto encourage you to-- even though you know\ncalculus really,",
    "start": "2182080",
    "end": "2188780"
  },
  {
    "text": "really well, you know how to\ntake derivatives really, really well, 18.02 and\n18.01 style, we're",
    "start": "2188780",
    "end": "2194440"
  },
  {
    "text": "going to try and learn\nsomething new here, a new way that can be really\na lot more powerful besides",
    "start": "2194440",
    "end": "2199550"
  },
  {
    "text": "[INAUDIBLE]. ALAN EDELMAN: I call it the\nway for big boys and big girls. STEVEN G. JOHNSON:\nYes, for big kids. ALAN EDELMAN: For grown-ups.",
    "start": "2199550",
    "end": "2204760"
  },
  {
    "text": "STEVEN G. JOHNSON:\nThe big-kid way. ALAN EDELMAN: Kid way. STEVEN G. JOHNSON: OK. So df, let's just do it slowly.",
    "start": "2204760",
    "end": "2211900"
  },
  {
    "text": "So what we want to do\nis we want to take f. We're going to take-- I'm going to draw my\nvector symbols here.",
    "start": "2211900",
    "end": "2217075"
  },
  {
    "text": "I guess I'll put them here. But I get tired of\nwriting them all the time.",
    "start": "2217075",
    "end": "2222280"
  },
  {
    "text": "All my x's, and therefore\nmy dx's, are vectors. So think of it as an\narbitrary small change",
    "start": "2222280",
    "end": "2227950"
  },
  {
    "text": "in an arbitrary direction. We want it to be able to\nhandle anything like that. ALAN EDELMAN: And\nin case it wasn't",
    "start": "2227950",
    "end": "2233680"
  },
  {
    "text": "already obvious to everybody,\nwhat is the output of f? Is it a scalar, a\nvector, a matrix?",
    "start": "2233680",
    "end": "2239785"
  },
  {
    "text": " It's a scalar, exactly. Just wanted to make sure\neverybody realized--",
    "start": "2239785",
    "end": "2245819"
  },
  {
    "text": "STEVEN G. JOHNSON: Sorry, yes. ALAN EDELMAN: --that this is\na scalar function of a vector. STEVEN G. JOHNSON: Yeah. You could also write this\nas x dot product with ax.",
    "start": "2245820",
    "end": "2257557"
  },
  {
    "start": "2257557",
    "end": "2262660"
  },
  {
    "text": "That's the same thing. OK. So I'm just going\nto do this out. I think it's still a\nlittle bit laboriously,",
    "start": "2262660",
    "end": "2269590"
  },
  {
    "text": "but we'll have a better rule\nfor-- we'll do the product rule in a minute. But let's do it without\nthe benefit of that.",
    "start": "2269590",
    "end": "2275243"
  },
  {
    "text": "ALAN EDELMAN: Because\nyou're effectively deriving the product rule\nin what's about to come. STEVEN G. JOHNSON: Exactly, yes.",
    "start": "2275243",
    "end": "2280570"
  },
  {
    "text": "So what do we do? So I'm going to plug-- I'm going to take\nf of x plus dx. I'm going to subtract fx. And I'm going to drop--",
    "start": "2280570",
    "end": "2286717"
  },
  {
    "text": "because it's d's, I'm\ngoing to drop anything that looks like a d squared,\na dx squared, something",
    "start": "2286717",
    "end": "2292960"
  },
  {
    "text": "that goes to 0 faster than dx. So what's f of x plus dx? Well, I take x.",
    "start": "2292960",
    "end": "2298480"
  },
  {
    "text": "I add dx, and I plug it into f. So there's a transpose there.",
    "start": "2298480",
    "end": "2305770"
  },
  {
    "text": "There's an A. There's\nan x plus dx there.",
    "start": "2305770",
    "end": "2312520"
  },
  {
    "text": "And then I subtract\nx transpose Ax.",
    "start": "2312520",
    "end": "2319690"
  },
  {
    "text": "And then I can just\nmultiply everything out. Just think of dx as a\nreally small vector.",
    "start": "2319690",
    "end": "2325480"
  },
  {
    "text": "And just use your ordinary\nrules from linear algebra.",
    "start": "2325480",
    "end": "2331780"
  },
  {
    "text": " I can just use the\ndistributed whatever it's called, the distributive rule.",
    "start": "2331780",
    "end": "2338647"
  },
  {
    "text": "I just have to make sure I don't\nchange the orders of anything since these are\nvectors and matrices. So I can multiply.",
    "start": "2338647",
    "end": "2345460"
  },
  {
    "text": "There's this term times\nthis term times this term. That's the first term. So there's an x transpose Ax.",
    "start": "2345460",
    "end": "2352932"
  },
  {
    "text": " There's also this term times\nthis term times this term.",
    "start": "2352932",
    "end": "2361960"
  },
  {
    "text": "So that's a dx transpose Ax.",
    "start": "2361960",
    "end": "2369720"
  },
  {
    "text": "So dx is just a little vector. It's perfectly fine\nto transpose it. And then I also have\nthis term times this term",
    "start": "2369720",
    "end": "2377910"
  },
  {
    "text": "times this term. So that's x transpose Adx.",
    "start": "2377910",
    "end": "2388134"
  },
  {
    "text": " And then I have this term times\nthis term times this term.",
    "start": "2388134",
    "end": "2398440"
  },
  {
    "text": "But that has a dx squared.  And so that I'm going to just--",
    "start": "2398440",
    "end": "2405290"
  },
  {
    "text": " let's see. Well, I actually am going\nto [INAUDIBLE] here.",
    "start": "2405290",
    "end": "2410480"
  },
  {
    "text": "So that term is your\ndx transpose Adx.",
    "start": "2410480",
    "end": "2419180"
  },
  {
    "text": "This term is gone. This is high order. ",
    "start": "2419180",
    "end": "2426359"
  },
  {
    "text": "So in the limit as dx\ngets smaller and smaller and smaller, this\nterm is negligible",
    "start": "2426360",
    "end": "2432359"
  },
  {
    "text": "compared to these terms. And then I still have this term\nover here, can't forget that.",
    "start": "2432360",
    "end": "2440800"
  },
  {
    "text": "Otherwise, these terms are\nnegligible compared to this. But it's OK because I'm\ngoing to subtract that.",
    "start": "2440800",
    "end": "2447820"
  },
  {
    "start": "2447820",
    "end": "2454040"
  },
  {
    "text": "And that term cancels. ",
    "start": "2454040",
    "end": "2459160"
  },
  {
    "text": "And what's left is\nthese two terms.",
    "start": "2459160",
    "end": "2464420"
  },
  {
    "text": "And this is a perfectly\ngood linear operation on dx, but it's not written\nin a very nice form.",
    "start": "2464420",
    "end": "2471460"
  },
  {
    "text": "So the trick is to--\nsince these are numbers,",
    "start": "2471460",
    "end": "2479270"
  },
  {
    "text": "I can transpose them. And this is something I\nfeel like in 18.06 people",
    "start": "2479270",
    "end": "2487010"
  },
  {
    "text": "get very confused by,\nthat normally you're",
    "start": "2487010",
    "end": "2492110"
  },
  {
    "text": "not allowed to change\nthe order of anything. Normally, a matrix is not\nequal to its transpose. But a number is always\nequal to its transpose.",
    "start": "2492110",
    "end": "2501200"
  },
  {
    "text": "So this is since--  let me do a note over here.",
    "start": "2501200",
    "end": "2507470"
  },
  {
    "text": " Since dx transpose\nAx is a scalar,",
    "start": "2507470",
    "end": "2524160"
  },
  {
    "text": "a scalar is always\nequal to its transpose. So then we can take\nthis and set it",
    "start": "2524160",
    "end": "2532799"
  },
  {
    "text": "equal to its own transpose,\nwhich is the same thing as x",
    "start": "2532800",
    "end": "2545490"
  },
  {
    "text": "transpose A transpose dx. And again, make sure\nyou understand that.",
    "start": "2545490",
    "end": "2553410"
  },
  {
    "text": "This somehow is a source\nof endless confusion. Alan already talked\nabout it when",
    "start": "2553410",
    "end": "2559770"
  },
  {
    "text": "he said, for\nexample, dx transpose x equals x transpose dx. That's a little easier to\nunderstand because it's just",
    "start": "2559770",
    "end": "2566340"
  },
  {
    "text": "a dot product. You can swap things,\na scalar product.",
    "start": "2566340",
    "end": "2571380"
  },
  {
    "text": "So this is also an\ninstance of the same rule. But you know, it's a little\nbit more complicated looking. It's the same idea.",
    "start": "2571380",
    "end": "2577799"
  },
  {
    "text": "Because this is a number,\nI can transpose it. And that swaps\neverything around.",
    "start": "2577800",
    "end": "2584620"
  },
  {
    "text": "And the transpose of a product-- hopefully, you remember\nfrom linear algebra that the transpose\nof a product is",
    "start": "2584620",
    "end": "2590260"
  },
  {
    "text": "the product of the\ntranspose in reverse order. So this term here,\nthis whole term,",
    "start": "2590260",
    "end": "2601510"
  },
  {
    "text": "equals x transpose\nA transpose dx. And what that allows\nme to do is it allows",
    "start": "2601510",
    "end": "2608430"
  },
  {
    "text": "me to combine the two terms. Now, this term and\nthis term, they both have a dx on the right.",
    "start": "2608430",
    "end": "2614055"
  },
  {
    "text": " And so I can put that\nover in the right.",
    "start": "2614055",
    "end": "2619445"
  },
  {
    "text": " And I can put parentheses.",
    "start": "2619445",
    "end": "2624550"
  },
  {
    "text": "And I have two terms,\nand both of them have an x transpose on the left.",
    "start": "2624550",
    "end": "2632420"
  },
  {
    "text": "And the first term,\none of the terms, has an A. The other\nterm has an A transpose. ",
    "start": "2632420",
    "end": "2641180"
  },
  {
    "text": "So that means this thing here\nis our derivative, f prime.",
    "start": "2641180",
    "end": "2654579"
  },
  {
    "text": "Again, don't get that confused\nwith the differential. f prime times dx is df. That's the change in the output.",
    "start": "2654580",
    "end": "2660530"
  },
  {
    "text": "That's the little\nchange in the output. f prime is the rate of change. It's the thing\nyou operate on dx.",
    "start": "2660530",
    "end": "2668050"
  },
  {
    "text": "This is a row vector. Notice that this\nis a row vector.",
    "start": "2668050",
    "end": "2673299"
  },
  {
    "text": "ALAN EDELMAN: Could\nI ask the class? Then quickly tell me what is\nthe gradient of x transpose dx.",
    "start": "2673300",
    "end": "2679790"
  },
  {
    "text": "Anybody want to shout it out? What is the gradient? ",
    "start": "2679790",
    "end": "2689144"
  },
  {
    "text": "AUDIENCE: You [INAUDIBLE]? ALAN EDELMAN: Right. Do you want to say\nit in its full glory? AUDIENCE: OK.",
    "start": "2689144",
    "end": "2694844"
  },
  {
    "text": "A plus-- A plus A\ntranspose times x. ALAN EDELMAN: Good, yup. A plus A transpose times x\nis the gradient, exactly.",
    "start": "2694844",
    "end": "2700467"
  },
  {
    "text": " STEVEN G. JOHNSON: Right.",
    "start": "2700467",
    "end": "2706060"
  },
  {
    "text": "It's just the transpose\nof this thing. So we transpose this thing.\ndx goes over on the right.",
    "start": "2706060",
    "end": "2712890"
  },
  {
    "text": "This thing gets transposed. But this is symmetric,\nso it equals itself.",
    "start": "2712890",
    "end": "2718807"
  },
  {
    "text": "ALAN EDELMAN: So,\nSteven, on the clock here, we're already at 12:56. So you might want to kind of-- STEVEN G. JOHNSON: OK.",
    "start": "2718807",
    "end": "2724530"
  },
  {
    "text": "ALAN EDELMAN: --come\nto a conclusion. STEVEN G. JOHNSON: Yeah. So this is just revisiting\nthe notion of a gradient.",
    "start": "2724530",
    "end": "2732640"
  },
  {
    "text": "And so next time, we're going\nto continue so that next time,",
    "start": "2732640",
    "end": "2738059"
  },
  {
    "text": "basically, we're going to\ndo 18.06 revisited part two.",
    "start": "2738060",
    "end": "2749220"
  },
  {
    "text": "And we're going to\nhave f is now going",
    "start": "2749220",
    "end": "2754440"
  },
  {
    "text": "to be a vector function that\ntakes a vector of outputs",
    "start": "2754440",
    "end": "2770400"
  },
  {
    "text": "and also takes a\nvector of inputs. ",
    "start": "2770400",
    "end": "2777740"
  },
  {
    "text": "And so we have outputs in,\nsay, Rm inputs in, say, Rn.",
    "start": "2777740",
    "end": "2786350"
  },
  {
    "text": " I probably should have used n\njust to be consistent before.",
    "start": "2786350",
    "end": "2793990"
  },
  {
    "text": "And then what we're going\nto find is that then-- ",
    "start": "2793990",
    "end": "2799270"
  },
  {
    "text": "you can almost do it right now. df has to be a\nlinear operator that",
    "start": "2799270",
    "end": "2812269"
  },
  {
    "text": "takes a small\nchange in the input and gives you a small\nchange in the output.",
    "start": "2812270",
    "end": "2819460"
  },
  {
    "text": "And so this has to have m\noutputs, m components here.",
    "start": "2819460",
    "end": "2824575"
  },
  {
    "text": "It has to have n\ncomponents there. The only way you can get\na linear operator that takes n inputs and m\noutputs is that this",
    "start": "2824575",
    "end": "2832240"
  },
  {
    "text": "has to be an m by n matrix. ",
    "start": "2832240",
    "end": "2840073"
  },
  {
    "text": "ALAN EDELMAN: It has to\nbe expressible as an m by n matrix. STEVEN G. JOHNSON: Exactly. ALAN EDELMAN: But you don't\nhave to write down the matrix. STEVEN G. JOHNSON:\nYes, that's right.",
    "start": "2840073",
    "end": "2846562"
  },
  {
    "text": "So this is our f prime\nof x linear operator.",
    "start": "2846562",
    "end": "2856300"
  },
  {
    "text": "And this, if we write\nit down as a matrix,",
    "start": "2856300",
    "end": "2861340"
  },
  {
    "text": "we call it the Jacobian. ALAN EDELMAN: I\nthink what I'll do next time is show my\nfavorite nonlinear",
    "start": "2861340",
    "end": "2867738"
  },
  {
    "text": "operator on two-dimensional\nspace, which is hyperbolic operators on corgis. So you'll see hyperbolic\ncorgis on Friday if you come.",
    "start": "2867738",
    "end": "2875040"
  },
  {
    "text": "STEVEN G. JOHNSON: So probably\non Friday maybe we'll switch. And I'll start with the first\nhalf and then finish this up.",
    "start": "2875040",
    "end": "2881080"
  },
  {
    "text": "And then Alan can\ndo the second half. ALAN EDELMAN: OK, we\ncould do it that way. OK. STEVEN G. JOHNSON: Thanks, all.",
    "start": "2881080",
    "end": "2886345"
  },
  {
    "text": "Any questions at this point? But let's-- ALAN EDELMAN: I'll\nalso stick around. You can ask Steven\nor, you know--",
    "start": "2886345",
    "end": "2892455"
  },
  {
    "text": "STEVEN G. JOHNSON: Let\nme stop the recording.  ALAN EDELMAN: OK.",
    "start": "2892456",
    "end": "2897540"
  },
  {
    "text": "Otherwise, see you on\nFriday, same room, 11:00 AM.",
    "start": "2897540",
    "end": "2903140"
  },
  {
    "start": "2903140",
    "end": "2907000"
  }
]
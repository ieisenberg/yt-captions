[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "The problem with our simple multicore system\nis that there is no communication when the",
    "start": "429",
    "end": "4529"
  },
  {
    "text": "value of a shared variable is changed.",
    "start": "4529",
    "end": "7769"
  },
  {
    "text": "The fix is to provide the necessary communications\nover a shared bus that's watched by all the",
    "start": "7769",
    "end": "12630"
  },
  {
    "text": "caches.",
    "start": "12630",
    "end": "13630"
  },
  {
    "text": "A cache can then \"snoop\" on what's happening\nin other caches and then update its local",
    "start": "13630",
    "end": "19200"
  },
  {
    "text": "state to be consistent.",
    "start": "19200",
    "end": "21510"
  },
  {
    "text": "The required communications protocol is called\na \"cache coherence protocol\".",
    "start": "21510",
    "end": "26630"
  },
  {
    "text": "In designing the protocol, we'd like to incur\nthe communications overhead only when there's",
    "start": "26630",
    "end": "31050"
  },
  {
    "text": "actual sharing in progress, i.e., when multiple\ncaches have local copies of a shared variable.",
    "start": "31050",
    "end": "37690"
  },
  {
    "text": "To implement a cache coherence protocol, we'll\nchange the state maintained for each cache",
    "start": "37690",
    "end": "42480"
  },
  {
    "start": "38000",
    "end": "38000"
  },
  {
    "text": "line.",
    "start": "42480",
    "end": "43649"
  },
  {
    "text": "The initial state for all cache lines is INVALID\nindicating that the tag and data fields do",
    "start": "43649",
    "end": "48350"
  },
  {
    "text": "not contain up-to-date information.",
    "start": "48350",
    "end": "51199"
  },
  {
    "text": "This corresponds to setting the valid bit\nto 0 in our original cache implementation.",
    "start": "51200",
    "end": "56660"
  },
  {
    "text": "When the cache line state is EXCLUSIVE, this\ncache has the only copy of those memory locations",
    "start": "56660",
    "end": "61610"
  },
  {
    "text": "and indicates that the local data is the same\nas that in main memory.",
    "start": "61610",
    "end": "65970"
  },
  {
    "text": "This corresponds to setting the valid bit\nto 1 in our original cache implementation.",
    "start": "65970",
    "end": "72020"
  },
  {
    "text": "If the cache line state is MODIFIED, that\nmeans the cache line data is the sole valid",
    "start": "72020",
    "end": "76969"
  },
  {
    "text": "copy of the data.",
    "start": "76970",
    "end": "78600"
  },
  {
    "text": "This corresponds to setting both the dirty\nand valid bits to 1 in our original cache",
    "start": "78600",
    "end": "82979"
  },
  {
    "text": "implementation.",
    "start": "82979",
    "end": "84609"
  },
  {
    "text": "To deal with sharing issues, there's a fourth\nstate called SHARED that indicates when other",
    "start": "84610",
    "end": "89450"
  },
  {
    "text": "caches may also have a copy of the same unmodified\nmemory data.",
    "start": "89450",
    "end": "95008"
  },
  {
    "text": "When filling a cache from main memory, other\ncaches can snoop on the read request and participate",
    "start": "95009",
    "end": "100280"
  },
  {
    "text": "if fulfilling the read request.",
    "start": "100280",
    "end": "103118"
  },
  {
    "text": "If no other cache has the requested data,\nthe data is fetched from main memory and the",
    "start": "103119",
    "end": "107689"
  },
  {
    "text": "requesting cache sets the state of that cache\nline to EXCLUSIVE.",
    "start": "107689",
    "end": "112799"
  },
  {
    "text": "If some other cache has the requested in line\nin the EXCLUSIVE or SHARED state, it supplies",
    "start": "112799",
    "end": "118040"
  },
  {
    "text": "the data and asserts the SHARED signal on\nthe snoopy bus to indicate that more than",
    "start": "118040",
    "end": "123070"
  },
  {
    "text": "one cache now has a copy of the data.",
    "start": "123070",
    "end": "126200"
  },
  {
    "text": "All caches will mark the state of the cache\nline as SHARED.",
    "start": "126200",
    "end": "130369"
  },
  {
    "text": "If another cache has a MODIFIED copy of the\ncache line, it supplies the changed data,",
    "start": "130369",
    "end": "135739"
  },
  {
    "text": "providing the correct values for the requesting\ncache as well as updating the values in main",
    "start": "135739",
    "end": "140480"
  },
  {
    "text": "memory.",
    "start": "140480",
    "end": "141480"
  },
  {
    "text": "Again the SHARED signal is asserted and both\nthe reading and responding cache will set",
    "start": "141480",
    "end": "146370"
  },
  {
    "text": "the state for that cache line to SHARED.",
    "start": "146370",
    "end": "149099"
  },
  {
    "text": "So, at the end of the read request, if there\nare multiple copies of the cache line, they",
    "start": "149099",
    "end": "154860"
  },
  {
    "text": "will all be in the SHARED state.",
    "start": "154860",
    "end": "158049"
  },
  {
    "text": "If there's only one copy of the cache line\nit will be in the EXCLUSIVE state.",
    "start": "158049",
    "end": "163469"
  },
  {
    "text": "Writing to a cache line is when the sharing\nmagic happens.",
    "start": "163469",
    "end": "167000"
  },
  {
    "text": "If there's a cache miss, the first cache performs\na cache line read as described above.",
    "start": "167000",
    "end": "172849"
  },
  {
    "text": "If the cache line is now in the SHARED state,\na write will cause the cache to send an INVALIDATE",
    "start": "172849",
    "end": "177459"
  },
  {
    "text": "message on the snoopy bus,\ntelling all other caches to invalidate their",
    "start": "177459",
    "end": "181390"
  },
  {
    "text": "copy of the cache line, guaranteeing the local\ncache now has EXCLUSIVE access to the cache",
    "start": "181390",
    "end": "186689"
  },
  {
    "text": "line.",
    "start": "186689",
    "end": "188028"
  },
  {
    "text": "If the cache line is in the EXCLUSIVE state\nwhen the write happens, no communication is",
    "start": "188029",
    "end": "192670"
  },
  {
    "text": "necessary.",
    "start": "192670",
    "end": "194528"
  },
  {
    "text": "Now the cache data can be changed and the\ncache line state set to MODIFIED, completing",
    "start": "194529",
    "end": "199370"
  },
  {
    "text": "the write.",
    "start": "199370",
    "end": "201109"
  },
  {
    "text": "This protocol is called \"MESI\" after the first\ninitials of the possible states.",
    "start": "201109",
    "end": "206249"
  },
  {
    "text": "Note that the the valid and dirty state bits\nin our original cache implementation have",
    "start": "206249",
    "end": "210168"
  },
  {
    "text": "been repurposed to encode one of the four\nMESI states.",
    "start": "210169",
    "end": "214419"
  },
  {
    "text": "The key to success is that each cache now\nknows when a cache line may be shared by another",
    "start": "214419",
    "end": "219549"
  },
  {
    "text": "cache, prompting the necessary communication\nwhen the value of a shared location is changed.",
    "start": "219549",
    "end": "225719"
  },
  {
    "text": "No attempt is made to update shared values,\nthey're simply invalidated and the other caches",
    "start": "225719",
    "end": "231448"
  },
  {
    "text": "will issue read requests if they need the\nvalue of the shared variable at some future",
    "start": "231449",
    "end": "236250"
  },
  {
    "text": "time.",
    "start": "236250",
    "end": "238369"
  },
  {
    "start": "238000",
    "end": "238000"
  },
  {
    "text": "To support cache coherence, the cache hardware\nhas to be modified to support two request",
    "start": "238369",
    "end": "243229"
  },
  {
    "text": "streams: one from the CPU and one from the\nsnoopy bus.",
    "start": "243229",
    "end": "248249"
  },
  {
    "text": "The CPU side includes a queue of store requests\nthat were delayed by cache misses.",
    "start": "248249",
    "end": "253249"
  },
  {
    "text": "This allows the CPU to proceed without having\nto wait for the cache refill operation to",
    "start": "253249",
    "end": "257458"
  },
  {
    "text": "complete.",
    "start": "257459",
    "end": "259049"
  },
  {
    "text": "Note that CPU read requests will need to check\nthe store queue before they check the cache",
    "start": "259049",
    "end": "263680"
  },
  {
    "text": "to ensure the most-recent value is supplied\nto the CPU.",
    "start": "263680",
    "end": "268229"
  },
  {
    "text": "Usually there's a STORE_BARRIER instruction\nthat stalls the CPU until the store queue",
    "start": "268229",
    "end": "272540"
  },
  {
    "text": "is empty, guaranteeing that all processors\nhave seen the effect of the writes before",
    "start": "272540",
    "end": "277900"
  },
  {
    "text": "execution resumes.",
    "start": "277900",
    "end": "280830"
  },
  {
    "text": "On the snoopy side, the cache has to snoop\non the transactions from other caches, invalidating",
    "start": "280830",
    "end": "285990"
  },
  {
    "text": "or supplying cache line data as appropriate,\nand then updating the local cache line state.",
    "start": "285990",
    "end": "291990"
  },
  {
    "text": "If the cache is busy with, say, a refill operation,\nINVALIDATE requests may be queued until they",
    "start": "291990",
    "end": "296830"
  },
  {
    "text": "can be processed.",
    "start": "296830",
    "end": "298680"
  },
  {
    "text": "Usually there's a READ_BARRIER instruction\nthat stalls the CPU until the invalidate queue",
    "start": "298680",
    "end": "303310"
  },
  {
    "text": "is empty, guaranteeing that updates from other\nprocessors have been applied to the local",
    "start": "303310",
    "end": "308360"
  },
  {
    "text": "cache state before execution resumes.",
    "start": "308360",
    "end": "312180"
  },
  {
    "text": "Note that the \"read with intent to modify\"\ntransaction shown here is just protocol shorthand",
    "start": "312180",
    "end": "316509"
  },
  {
    "text": "for a READ immediately followed by an INVALIDATE,\nindicating that the requester will be changing",
    "start": "316509",
    "end": "322370"
  },
  {
    "text": "the contents of the cache line.",
    "start": "322370",
    "end": "324699"
  },
  {
    "text": "How do the CPU and snoopy cache requests affect\nthe cache state?",
    "start": "324699",
    "end": "329240"
  },
  {
    "start": "325000",
    "end": "325000"
  },
  {
    "text": "Here in micro type is a flow chart showing\nwhat happens when.",
    "start": "329240",
    "end": "333280"
  },
  {
    "text": "If you're interested, try following the actions\nrequired to complete various transactions.",
    "start": "333280",
    "end": "337990"
  },
  {
    "text": "Intel, in its wisdom, adds a fifth \"F\" state,\nused to determine which cache will respond",
    "start": "337990",
    "end": "343759"
  },
  {
    "text": "to read requests when the requested cache\nline is shared by multiple caches",
    "start": "343759",
    "end": "348139"
  },
  {
    "text": "basically it selects which of the SHARED cache\nlines gets to be the responder.",
    "start": "348139",
    "end": "352900"
  },
  {
    "text": "But this is a bit abstract.",
    "start": "352900",
    "end": "355040"
  },
  {
    "text": "Let's try the MESI cache coherence protocol\non our earlier example!",
    "start": "355040",
    "end": "360009"
  },
  {
    "start": "360000",
    "end": "360000"
  },
  {
    "text": "Here are our two threads and their local cache\nstates indicating that values of locations",
    "start": "360009",
    "end": "365159"
  },
  {
    "text": "X and Y are shared by both caches.",
    "start": "365159",
    "end": "367849"
  },
  {
    "text": "Let's see what happens when the operations\nhappen in the order (1 through 4) shown here.",
    "start": "367849",
    "end": "373980"
  },
  {
    "text": "You can check what happens when the transactions\nare in a different order or happen concurrently.",
    "start": "373980",
    "end": "379330"
  },
  {
    "text": "First, Thread A changes X to 3.",
    "start": "379330",
    "end": "382930"
  },
  {
    "text": "Since this location is marked as SHARED [S]\nin the local cache, the cache for core 0 ($_0)",
    "start": "382930",
    "end": "388129"
  },
  {
    "text": "issues an INVALIDATE transaction for location\nX to the other caches,",
    "start": "388129",
    "end": "392270"
  },
  {
    "text": "giving it exclusive access to location X,\nwhich it changes to have the value 3.",
    "start": "392270",
    "end": "397229"
  },
  {
    "text": "At the end of this step, the cache for core\n1 ($_1) no longer has a copy of the value",
    "start": "397229",
    "end": "401920"
  },
  {
    "text": "for location X.",
    "start": "401920",
    "end": "404629"
  },
  {
    "text": "In step 2, Thread B changes Y to 4.",
    "start": "404629",
    "end": "408580"
  },
  {
    "text": "Since this location is marked as SHARED in\nthe local cache, cache 1 issues an INVALIDATE",
    "start": "408580",
    "end": "413228"
  },
  {
    "text": "transaction for location Y to the other caches,\ngiving it exclusive access to location Y,",
    "start": "413229",
    "end": "419509"
  },
  {
    "text": "which it changes to have the value 4.",
    "start": "419509",
    "end": "423180"
  },
  {
    "text": "In step 3, execution continues in Thread B,\nwhich needs the value of location X.",
    "start": "423180",
    "end": "428999"
  },
  {
    "text": "That's a cache miss, so it issues a read request\non the snoopy bus, and cache 0 responds with",
    "start": "428999",
    "end": "435210"
  },
  {
    "text": "its updated value, and both caches mark the\nlocation X as SHARED.",
    "start": "435210",
    "end": "441110"
  },
  {
    "text": "Main memory, which is also watching the snoopy\nbus, also updates its copy of the X value.",
    "start": "441110",
    "end": "446918"
  },
  {
    "text": "Finally, in step 4, Thread A needs the value\nfor Y, which results in a similar transaction",
    "start": "446919",
    "end": "452800"
  },
  {
    "text": "on the snoopy bus.",
    "start": "452800",
    "end": "454430"
  },
  {
    "text": "Note the outcome corresponds exactly to that\nproduced by the same execution sequence on",
    "start": "454430",
    "end": "459270"
  },
  {
    "text": "a timeshared core\nsince the coherence protocol guarantees that",
    "start": "459270",
    "end": "463198"
  },
  {
    "text": "no cache has an out-of-date copy of a shared\nmemory location.",
    "start": "463199",
    "end": "467249"
  },
  {
    "text": "And both caches agree on the ending values\nfor the shared variables X and Y.",
    "start": "467249",
    "end": "473029"
  },
  {
    "text": "If you try other execution orders, you'll\nsee that sequential consistency and shared",
    "start": "473029",
    "end": "477430"
  },
  {
    "text": "memory semantics are maintained in each case.",
    "start": "477430",
    "end": "480930"
  },
  {
    "text": "The cache coherency protocol has done it's\njob!",
    "start": "480930",
    "end": "483919"
  },
  {
    "text": "Let's summarize our discussion of parallel\nprocessing.",
    "start": "483919",
    "end": "488229"
  },
  {
    "start": "485000",
    "end": "485000"
  },
  {
    "text": "At the moment, it seems that the architecture\nof a single core has reached a stable point.",
    "start": "488229",
    "end": "493260"
  },
  {
    "text": "At least with the current ISAs, pipeline depths\nare unlikely to increase and out-of-order,",
    "start": "493260",
    "end": "499009"
  },
  {
    "text": "superscalar instruction execution has reached\nthe point of diminishing performance returns.",
    "start": "499009",
    "end": "504389"
  },
  {
    "text": "So it seems unlikely there will be dramatic\nperformance improvements due to architectural",
    "start": "504389",
    "end": "508279"
  },
  {
    "text": "changes inside the CPU core.",
    "start": "508279",
    "end": "511219"
  },
  {
    "text": "GPU architectures continue to evolve as they\nadapt to new uses in specific application",
    "start": "511219",
    "end": "516000"
  },
  {
    "text": "areas, but they are unlikely to impact general-purpose\ncomputing.",
    "start": "516000",
    "end": "521539"
  },
  {
    "text": "At the system level, the trend is toward increasing\nthe number of cores and figuring out how to",
    "start": "521539",
    "end": "526029"
  },
  {
    "text": "best exploit parallelism with new algorithms.",
    "start": "526029",
    "end": "530510"
  },
  {
    "text": "Looking further ahead, notice that the brain\nis able to accomplish remarkable results using",
    "start": "530510",
    "end": "535690"
  },
  {
    "text": "fairly slow mechanisms\nIt takes ~.01 seconds to get a message to",
    "start": "535690",
    "end": "540079"
  },
  {
    "text": "the brain and synapses fire somewhere between\n0.3 to 1.8 times per second.",
    "start": "540079",
    "end": "546410"
  },
  {
    "text": "Is it massive parallelism that gives the brain\nits \"computational\" power?",
    "start": "546410",
    "end": "550829"
  },
  {
    "text": "Or is it that the brain uses a different computation\nmodel, e.g., neural nets, to decide upon new",
    "start": "550829",
    "end": "556350"
  },
  {
    "text": "actions given new inputs?",
    "start": "556350",
    "end": "558800"
  },
  {
    "text": "At least for applications involving cognition\nthere are new architectural and technology",
    "start": "558800",
    "end": "563550"
  },
  {
    "text": "frontiers to explore.",
    "start": "563550",
    "end": "565579"
  },
  {
    "text": "You have some interesting challenges ahead\nif you get interested in the future of parallel",
    "start": "565579",
    "end": "569630"
  },
  {
    "text": "processing!",
    "start": "569630",
    "end": "570060"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6060"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6060",
    "end": "12700"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. ",
    "start": "12700",
    "end": "26360"
  },
  {
    "text": "PROFESSOR: So today is our\nthird and probably final lecture on approximation algorithms.",
    "start": "26360",
    "end": "31869"
  },
  {
    "text": "We're going to take\na different approach to proving inapproximability\nto optimization problems called",
    "start": "31870",
    "end": "39339"
  },
  {
    "text": "gap problems. And we'll think about\ngap-preserving reductions. We will prove along the way\noptimal lower bound on MAX-3SAT",
    "start": "39340",
    "end": "47680"
  },
  {
    "text": "and other fun things. So let's start with\nwhat a gap problem is.",
    "start": "47680",
    "end": "52700"
  },
  {
    "start": "52700",
    "end": "58340"
  },
  {
    "text": "I haven't actually seen a\ngeneric definition of this, so this is new terminology,\nbut I think helpful.",
    "start": "58340",
    "end": "63570"
  },
  {
    "text": " A gap problem is a way of\nconverting an optimization",
    "start": "63570",
    "end": "70420"
  },
  {
    "text": "problem into a decision problem. Now, we already know\none way to do that. If you have an NPO\noptimization problem,",
    "start": "70420",
    "end": "76590"
  },
  {
    "text": "you convert it into the\nobvious decision problem, which is OPT at most k. For the minimization\nproblem, that is NP-complete.",
    "start": "76590",
    "end": "85600"
  },
  {
    "text": "But we want to get something\nuseful from an approximability standpoint. And so the idea is, here's\na different problem.",
    "start": "85600",
    "end": "95189"
  },
  {
    "text": "Instead of just deciding\nwhether OPT is at most k,",
    "start": "95190",
    "end": "104100"
  },
  {
    "text": "we want to distinguish\nbetween OPT being at most k",
    "start": "104100",
    "end": "109310"
  },
  {
    "text": "versus OPT being at least\nk over c for some value c.",
    "start": "109310",
    "end": "117360"
  },
  {
    "text": "And the analogy here is with\nc approximation algorithm, c does not have to be\nconstant, despite the name.",
    "start": "117360",
    "end": "124279"
  },
  {
    "text": "Could be a function of n. Maybe it's log n. Maybe it's n to the\nepsilon, whatever.",
    "start": "124279",
    "end": "130459"
  },
  {
    "text": "So for a minimization\nproblem, normally-- did I get this the right way?",
    "start": "130460",
    "end": "135860"
  },
  {
    "text": "Sorry, that should be c times k. ",
    "start": "135860",
    "end": "144050"
  },
  {
    "text": "For minimization and\nfor maximization, it's going to be the reverse.",
    "start": "144050",
    "end": "149905"
  },
  {
    "start": "149905",
    "end": "156880"
  },
  {
    "text": "And I think I'm going to use\nstrict inequality here also.",
    "start": "156880",
    "end": "162030"
  },
  {
    "text": "So a minimization. There's a gap here\nbetween k and c times k. We're imagining here\nc is bigger than 1.",
    "start": "162030",
    "end": "171640"
  },
  {
    "text": "So distinguishing\nbetween being less than k and being at least c\ntimes k leaves a hole.",
    "start": "171640",
    "end": "179319"
  },
  {
    "text": "And the point is you\nare promised that your input-- you\nhave a question?",
    "start": "179320",
    "end": "186250"
  },
  {
    "text": "AUDIENCE: The second one,\nshould it really be c over k? ",
    "start": "186250",
    "end": "193724"
  },
  {
    "text": "PROFESSOR: Sorry, no.  Thank you.",
    "start": "193725",
    "end": "200750"
  },
  {
    "text": "C and k sound the same, so it's\nalways easy to mix them up.",
    "start": "200750",
    "end": "205771"
  },
  {
    "text": "Cool. So the idea is that\nyou're-- so in both cases, there's a ratio gap here of c.",
    "start": "205771",
    "end": "213740"
  },
  {
    "text": "And the idea is\nthat you're promised that your input falls into\none of these two categories. What does it mean\nto distinguish--",
    "start": "213740",
    "end": "220140"
  },
  {
    "text": "I mean, I tell you up\nfront the input either has this property\nor this property, and I want you to\ndecide which one it is.",
    "start": "220140",
    "end": "227940"
  },
  {
    "text": "And we'll call\nthese yes instances and these no instances.",
    "start": "227940",
    "end": "233010"
  },
  {
    "text": " Normally with a\ndecision problem, the no instance is that OPT is\njust one bigger or one smaller.",
    "start": "233010",
    "end": "242080"
  },
  {
    "text": "Now we have a big gap between\nthe no instances and the yes instances. We're told that that's true.",
    "start": "242080",
    "end": "247200"
  },
  {
    "text": "This is called promise problem. ",
    "start": "247200",
    "end": "252560"
  },
  {
    "text": "And effectively\nwhat that means is if you're trying to come\nup with an algorithm to solve this\ndecision problem, you",
    "start": "252560",
    "end": "258700"
  },
  {
    "text": "don't care what the\nalgorithm does if OPT happens to fall in between.",
    "start": "258700",
    "end": "264317"
  },
  {
    "text": "The algorithm can\ndo whatever it want. It can output digits\nof pi in the middle, as long as when OPT is it\nat most k or greater than",
    "start": "264317",
    "end": "272930"
  },
  {
    "text": "or equal to k, it outputs yes. And when OPT is at least a\nfactor of c away from that,",
    "start": "272930",
    "end": "278320"
  },
  {
    "text": "it outputs no. So that's an easier problem.",
    "start": "278320",
    "end": "285550"
  },
  {
    "text": "And the cool thing is if the\nc gap version of a problem",
    "start": "285550",
    "end": "296090"
  },
  {
    "text": "is NP-hard, then so\nis c approximating",
    "start": "296090",
    "end": "306990"
  },
  {
    "text": "the original problem. ",
    "start": "306990",
    "end": "321200"
  },
  {
    "text": "So this really is in direct\nanalogy to c approximation. And so this lets us think\nabout an NP hardness",
    "start": "321200",
    "end": "327540"
  },
  {
    "text": "for a decision problem and prove\nan inapproximability result. This is nice because in\nthe last two lectures,",
    "start": "327540",
    "end": "333950"
  },
  {
    "text": "we were having to keep track\nof a lot more in just defining",
    "start": "333950",
    "end": "339040"
  },
  {
    "text": "what inapproximability meant\nand APX hardness and so on. Here it's kind of back\nto regular NP hardnes.",
    "start": "339040",
    "end": "345674"
  },
  {
    "text": "Now, the techniques\nare completely different in this world than\nour older NP hardness proofs.",
    "start": "345674",
    "end": "350800"
  },
  {
    "text": "But still, it's kind of\ncomforting to be back in decision land.",
    "start": "350800",
    "end": "356170"
  },
  {
    "text": "Cool. So because of this implication,\nin previous lectures",
    "start": "356170",
    "end": "363510"
  },
  {
    "text": "we were just worried about\nproving inapproximability. But today we're\ngoing to be thinking",
    "start": "363510",
    "end": "370110"
  },
  {
    "text": "about proving that gap\nproblems are NP-hard, or some other kind of hardness.",
    "start": "370110",
    "end": "375710"
  },
  {
    "text": "This is a stronger\ntype of result. So in general,\ninapproximability is kind of what you care about\nfrom the algorithmic standpoint,",
    "start": "375710",
    "end": "382150"
  },
  {
    "text": "but gap results saying\nthat hey, your problem is hard even if you have\nthis huge gap between the yes",
    "start": "382150",
    "end": "388360"
  },
  {
    "text": "instances and the\nno instances, that's also of independent\ninterest, more about the structure\nof the problem.",
    "start": "388360",
    "end": "394370"
  },
  {
    "text": "But one implies the other. So this is the stronger\ntype of thing to go for.",
    "start": "394370",
    "end": "399750"
  },
  {
    "text": "The practical reason to\ncare about this stuff is that this gap idea lets you\nget stronger inapproximability",
    "start": "399750",
    "end": "407550"
  },
  {
    "text": "results. The factor c you get by\nthinking about gaps in practice seems to be larger\nthan the gaps you",
    "start": "407550",
    "end": "416069"
  },
  {
    "text": "get by L reductions and things. So let me tell you about one\nother type of gap problem.",
    "start": "416070",
    "end": "425110"
  },
  {
    "text": "This is a standard one, a\nlittle bit more precise. ",
    "start": "425110",
    "end": "434200"
  },
  {
    "text": "Consider MAX-SAT. Pick your favorite\nversion of MAX-SAT, or MAX-CSP was the\ngeneral form where you",
    "start": "434200",
    "end": "440099"
  },
  {
    "text": "could have any type of clause. Instead of just a c gap, we will\ndefine slightly more precisely an a, b gap, which is to\ndistinguish between OPT",
    "start": "440100",
    "end": "459400"
  },
  {
    "text": "is less than a times\nthe number of clauses,",
    "start": "459400",
    "end": "466990"
  },
  {
    "text": "and OPT is at least b times\nthe number of clauses. ",
    "start": "466990",
    "end": "475740"
  },
  {
    "text": "So whereas here everything\nwas relative to some input k that you want to\ndecide about, with SAT",
    "start": "475740",
    "end": "483580"
  },
  {
    "text": "there's a kind of absolute\nnotion of what you'd like to achieve, which is\nthat you satisfy everything, all clauses are true.",
    "start": "483580",
    "end": "489270"
  },
  {
    "text": "So typically we'll\nthink about b being one. ",
    "start": "489270",
    "end": "494280"
  },
  {
    "text": "And so you're distinguishing\nbetween a satisfiable instance where all clauses are\nsatisfied, and something",
    "start": "494280",
    "end": "500130"
  },
  {
    "text": "that's very unsatisfiable. There's some kind of usually\nconstant fraction unsatisfiable",
    "start": "500130",
    "end": "505341"
  },
  {
    "text": "clauses.  We need this level\nof precision thinking",
    "start": "505341",
    "end": "512590"
  },
  {
    "text": "about when you're right\nup against 100% satisfied versus 1% satisfied or something\nlike that, or 1% satisfiable.",
    "start": "512590",
    "end": "519719"
  },
  {
    "text": " Cool. AUDIENCE: Do you use the same\nnotation for one [INAUDIBLE]",
    "start": "519720",
    "end": "525825"
  },
  {
    "text": "or only for-- so the one problem\nlike the maximum number of ones you can get. PROFESSOR: I haven't\nseen it, but yeah, that's",
    "start": "525825",
    "end": "532300"
  },
  {
    "text": "a good question. Certainly valid to do\nit for-- we will see it for one other type of problem.",
    "start": "532300",
    "end": "537540"
  },
  {
    "text": "For any problem, if you can\ndefine some absolute notion of how much you'd\nlike to get, you can always measure relative to\nthat and define this kind of a,",
    "start": "537540",
    "end": "545720"
  },
  {
    "text": "b gap problem. Cool. All right.",
    "start": "545720",
    "end": "551160"
  },
  {
    "text": "So how do we get these gaps? There's two, well maybe\nthree ways, I guess.",
    "start": "551160",
    "end": "557440"
  },
  {
    "start": "557440",
    "end": "564870"
  },
  {
    "text": "In general, we're going to\nuse reductions, like always. And you could start from\nno gap and make a gap,",
    "start": "564870",
    "end": "571880"
  },
  {
    "text": "or start from a\ngap of additive one and turn it into a big\nmultiplicative gap. That will be\ngap-producing reductions.",
    "start": "571880",
    "end": "578050"
  },
  {
    "text": "You could start with some\ngap and then make it bigger. That's gap-amplifying reduction.",
    "start": "578050",
    "end": "583440"
  },
  {
    "text": "Or you could just start with\na gap and try to preserve it. That would be\ngap-preserving reductions. In general, once\nyou have some gap,",
    "start": "583440",
    "end": "589950"
  },
  {
    "text": "you try to keep it or make\nit bigger to get stronger hardness for your problem.",
    "start": "589950",
    "end": "595990"
  },
  {
    "text": "So the idea with a\ngap-producing reduction is that you have no assumption\nabout your starting problem.",
    "start": "595990",
    "end": "602200"
  },
  {
    "text": "In general, reduction we're\ngoing from some problem a to some problem b. And what we would like is that\nthe output instance to problem",
    "start": "602200",
    "end": "611730"
  },
  {
    "text": "b, the output of the\nreduction has OPT equal to k",
    "start": "611730",
    "end": "621250"
  },
  {
    "text": "or, for a minimization problem,\nOPT bigger than c times k.",
    "start": "621250",
    "end": "629500"
  },
  {
    "text": "And for a maximization problem,\nOPT less than k over c. ",
    "start": "629500",
    "end": "636430"
  },
  {
    "text": "So that's just saying we\nhave a gap in the output. We assume nothing about\nthe input instance. That would be a\ngap-producing production.",
    "start": "636430",
    "end": "643300"
  },
  {
    "text": "Now we have seen some of\nthese before, or at least mentioned them. One of them, this is\nfrom lecture three,",
    "start": "643300",
    "end": "649930"
  },
  {
    "text": "I think for Tetris. We proved NP hardness, which was\nthis three partition reduction. And the idea is that if you\ncould satisfy that and open",
    "start": "649930",
    "end": "657080"
  },
  {
    "text": "this thing, then you could get\na zillion points down here. In most of the\ninstances down here,",
    "start": "657080",
    "end": "662360"
  },
  {
    "text": "we squeeze this down to\nlike an n to the epsilon. That's still hard. And so n to the 1 minus epsilon\nof the instances down here,",
    "start": "662360",
    "end": "669510"
  },
  {
    "text": "and you're given a ton of\npieces to fill in the space, get lots of points. If the answer was no here, then\nyou won't get those points.",
    "start": "669510",
    "end": "678260"
  },
  {
    "text": "And so OPT is very small, at\nmost, say, n to the epsilon. If you can solve\nthis instance, we",
    "start": "678260",
    "end": "684626"
  },
  {
    "text": "have a yes instance in the\ninput, then we get end points. So the gap there is n\nto the 1 minus epsilon.",
    "start": "684626",
    "end": "692209"
  },
  {
    "text": " So the Tetris reduction, we\nassume nothing about the three",
    "start": "692210",
    "end": "700380"
  },
  {
    "text": "partition instance. It was just yes or no. And we produced an instance\nthat had a gap of n",
    "start": "700380",
    "end": "707662"
  },
  {
    "text": "to the 1 minus epsilon. We could set epsilon\nto any constant we want bigger than zero.",
    "start": "707663",
    "end": "714160"
  },
  {
    "text": "We also mentioned\nanother such reduction. And in general, for a\nlot of games and puzzles,",
    "start": "714160",
    "end": "719839"
  },
  {
    "text": "you can do this. It's sort of on all\nor nothing deal. And gap-producing reduction\nis a way to formalize that.",
    "start": "719840",
    "end": "726720"
  },
  {
    "text": "Another problem we talked\nabout last class I believe was non-metric TSP.",
    "start": "726720",
    "end": "732270"
  },
  {
    "text": "I just give you\na complete graph. Every edge has some number on it\nthat's the length of that edge.",
    "start": "732270",
    "end": "737750"
  },
  {
    "text": "You want to find a TSP tour\nof minimum total length. This is really hard to\napproximate because depending",
    "start": "737750",
    "end": "745639"
  },
  {
    "text": "on your model, you can use\nlet's say edge weights.",
    "start": "745640",
    "end": "751710"
  },
  {
    "text": "And to be really annoying\nwould be 0, comma 1. And if I'm given a\nHamiltonicity instance, wherever",
    "start": "751710",
    "end": "759600"
  },
  {
    "text": "there's an edge, I\nput a weight of zero. Wherever there's not an\nedge, I put a weight of one. And then if the input\ngraph was Hamiltonian,",
    "start": "759600",
    "end": "766810"
  },
  {
    "text": "it's a yes instance. Then the output thing will\nhave a tour of length zero. And if the input\nwas not Hamiltonian,",
    "start": "766810",
    "end": "775250"
  },
  {
    "text": "then the output\nwill have weight n. Ratio between n and\nzero is infinity. So this is an\ninfinite gap creation",
    "start": "775250",
    "end": "782580"
  },
  {
    "text": "if you allow weights of zero. If you say zero\nis cheating, which we did and some papers\ndo, you could instead",
    "start": "782580",
    "end": "790390"
  },
  {
    "text": "do one and infinity, where\ninfinity is the largest representable number.",
    "start": "790390",
    "end": "795730"
  },
  {
    "text": "So that's going to be\nsomething like 2 to the n if you allow usual binary\nencodings of numbers.",
    "start": "795730",
    "end": "802980"
  },
  {
    "text": "If you don't, the\nPB case, then that would be n to some constant. But you get a big\ngap in any case.",
    "start": "802980",
    "end": "810029"
  },
  {
    "text": "So you get some gap equals huge.",
    "start": "810030",
    "end": "816180"
  },
  {
    "text": "So these are kind of trivial\nsenses of inapproximability, but hey, that's\none way to do it.",
    "start": "816180",
    "end": "822040"
  },
  {
    "text": "What we're going\nto talk about today are other known ways to get\ngap production that are really",
    "start": "822040",
    "end": "828459"
  },
  {
    "text": "cool and more broadly useful. This is useful when you have a\nsort of all or nothing problem. A lot of the time,\nit's not so clear.",
    "start": "828460",
    "end": "834850"
  },
  {
    "text": "There's a constant\nfactor approximation. So some giant gap like this\nisn't going to be possible,",
    "start": "834850",
    "end": "840319"
  },
  {
    "text": "but still gaps are possible.  Now, an important part of the\nstory here is the PCP theorem.",
    "start": "840319",
    "end": "853190"
  },
  {
    "text": "So this is not about drugs. This is about another\ncomplexity class.",
    "start": "853190",
    "end": "864839"
  },
  {
    "text": "And the complexity\nclass is normally written PCP of order\nlog n, comma order one.",
    "start": "864840",
    "end": "870080"
  },
  {
    "text": "I'm going to simplify this\nto just PCP as the class. The other notions\nmake sense here,",
    "start": "870080",
    "end": "875790"
  },
  {
    "text": "although the parameters don't\nturn out to matter too much. And it's rather lengthy\nto write that every time.",
    "start": "875790",
    "end": "881250"
  },
  {
    "text": "So I'm just going to write PCP. Let me first tell you what\nthis class is about briefly,",
    "start": "881250",
    "end": "887330"
  },
  {
    "text": "and then we'll see why\nit's directly related to gap problems,\nhence where a lot",
    "start": "887330",
    "end": "892960"
  },
  {
    "text": "of these gap-producing\nreductions come from. So PCP stands for\nProbabilistically Checkable",
    "start": "892960",
    "end": "899640"
  },
  {
    "text": "Proof. ",
    "start": "899640",
    "end": "911730"
  },
  {
    "text": "The checkable\nproof refers to NP.",
    "start": "911730",
    "end": "916889"
  },
  {
    "text": "Every yes instance\nhas a checkable proof that the answer is yes. Probabilistically\ncheckable means",
    "start": "916890",
    "end": "922480"
  },
  {
    "text": "you can check it even faster\nwith high probability. So normally to check a proof,\nwe take polynomial time in NP.",
    "start": "922480",
    "end": "929970"
  },
  {
    "text": "Here we want to\nachieve constant time. That's the main idea. That can't be done perfectly,\nbut you can do it correctly",
    "start": "929970",
    "end": "937220"
  },
  {
    "text": "with high probability. So in general, a\nproblem in PCP has certificates of polynomial\nlength, just like NP.",
    "start": "937220",
    "end": "944240"
  },
  {
    "start": "944240",
    "end": "954529"
  },
  {
    "text": "And we have an algorithm for\nchecking certificates, which",
    "start": "954530",
    "end": "961060"
  },
  {
    "text": "is given certificate,\nand it's given order log",
    "start": "961060",
    "end": "968090"
  },
  {
    "text": "n bits of randomness. ",
    "start": "968090",
    "end": "977240"
  },
  {
    "text": "That's what this first\nparameter refers to, is how much randomness\nthe algorithm's given. So we restrict the\namount of randomness",
    "start": "977240",
    "end": "983600"
  },
  {
    "text": "to a very small amount. And it should tell you\nwhether the instance",
    "start": "983600",
    "end": "989339"
  },
  {
    "text": "is a yes instance\nor a no instance, in some sense if you're\ngiven the right certificate.",
    "start": "989340",
    "end": "994850"
  },
  {
    "text": "So in particular,\nif the instance was a yes instance-- so this\nis back to decision problems,",
    "start": "994850",
    "end": "1001990"
  },
  {
    "text": "just like NP. There's no optimization here. But we're going to apply\nthis to gap problems,",
    "start": "1001990",
    "end": "1007480"
  },
  {
    "text": "and that will relate\nus to optimization. So let's say there's no error\non yes instances, although you",
    "start": "1007480",
    "end": "1022709"
  },
  {
    "text": "could relax that. It won't make a big difference. So if you have a yes instance,\nand you give the right",
    "start": "1022710",
    "end": "1029500"
  },
  {
    "text": "certificate-- so this is\nfor some certificate--",
    "start": "1029500",
    "end": "1038099"
  },
  {
    "text": "the algorithm's\nguaranteed to say yes. So no error there. Where we add some slack is\nif there's a no instance.",
    "start": "1038099",
    "end": "1046510"
  },
  {
    "text": "Now normally in NP\nfor a no instance, there is no correct certificate.",
    "start": "1046510",
    "end": "1052320"
  },
  {
    "text": "Now, the algorithm\nwill sometimes say yes even if we give\nit the wrong certificate. There is no right certificate.",
    "start": "1052320",
    "end": "1058730"
  },
  {
    "text": "But it will say so with some\nat most constant probability. So let's say the probability\nthat the algorithm says",
    "start": "1058730",
    "end": "1070140"
  },
  {
    "text": "no is at least some constant,\npresumably less than one.",
    "start": "1070140",
    "end": "1079860"
  },
  {
    "text": "If it's one, then that's NP. If it's a half,\nthat would be fine.",
    "start": "1079860",
    "end": "1085240"
  },
  {
    "text": "A tenth, a hundredth,\nthey'll all be the same. Because once you have\nsuch an algorithm that achieves some\nconstant probability,",
    "start": "1085240",
    "end": "1091940"
  },
  {
    "text": "you could apply it log\n1 over epsilon times. ",
    "start": "1091940",
    "end": "1099380"
  },
  {
    "text": "And we reduce the\nerror to epsilon.",
    "start": "1099380",
    "end": "1105220"
  },
  {
    "text": " The probability of error goes\nto epsilon if we just repeat",
    "start": "1105220",
    "end": "1110610"
  },
  {
    "text": "this log 1 over epsilon times. So in constant\ntime-- it didn't say.",
    "start": "1110610",
    "end": "1116940"
  },
  {
    "text": "The order one here refers to the\nrunning time of the algorithm. So this is an order\none time algorithm.",
    "start": "1116940",
    "end": "1127040"
  },
  {
    "text": "So the point is, the\nalgorithm's super fast and still in constant\ntime for constant epsilon. You can get arbitrarily\nsmall error probability,",
    "start": "1127040",
    "end": "1135130"
  },
  {
    "text": "say one in 100 or\none in a million, and it's still pretty good.",
    "start": "1135130",
    "end": "1140639"
  },
  {
    "text": "And you're checking your\nproof super, super fast. Question. AUDIENCE: Why is there a\nlimit on the randomness?",
    "start": "1140640",
    "end": "1146970"
  },
  {
    "text": " PROFESSOR: This\nlimit on randomness is not strictly necessary.",
    "start": "1146970",
    "end": "1153316"
  },
  {
    "text": "For example, n\nbits of randomness turned out not to help you. That was proved later. But we're going to\nuse this in a moment.",
    "start": "1153316",
    "end": "1159550"
  },
  {
    "text": "It will help us simulate this\nalgorithm without randomness, basically. Yeah.",
    "start": "1159550",
    "end": "1164847"
  },
  {
    "text": "AUDIENCE: If the verifier\nruns in constant time, can it either read\nor was written? PROFESSOR: So this is constant\ntime in a model of computation",
    "start": "1164847",
    "end": "1174050"
  },
  {
    "text": "where you can read log\nn bits in one step. So your word, let's\nsay, is log n bits long. So you have enough time\nto read the randomness.",
    "start": "1174050",
    "end": "1180540"
  },
  {
    "text": "Obviously you don't have\ntime to read the certificate, because that has\npolynomial length. But yeah, constant time.",
    "start": "1180540",
    "end": "1188050"
  },
  {
    "text": "Cool. Other questions? So that is the\ndefinition of PCP. Now let me relate\nit to gap problems.",
    "start": "1188050",
    "end": "1197255"
  },
  {
    "text": " So let's say first claim is\nthat if we look at this gap sap",
    "start": "1197255",
    "end": "1221680"
  },
  {
    "text": "problem, where b equals one and\na is some constant, presumably less than one, then-- in fact,\nthat should be less than one.",
    "start": "1221680",
    "end": "1231309"
  },
  {
    "text": "Why did I write strictly\nless than 1 here?",
    "start": "1231310",
    "end": "1236760"
  },
  {
    "text": "This is a constant\nless than one. Then I claim that\nproblem is in PCP,",
    "start": "1236760",
    "end": "1244749"
  },
  {
    "text": "that there is a\nprobabilistically checkable proof for this instance. Namely, it's a satisfying\nvariable assignment.",
    "start": "1244749",
    "end": "1251090"
  },
  {
    "text": "Again, this instance\neither has the prop-- when in a yes instance\nall of the entire thing",
    "start": "1251090",
    "end": "1256170"
  },
  {
    "text": "is satisfiable. So just like before, I\ncan have a certificate,",
    "start": "1256170",
    "end": "1265480"
  },
  {
    "text": "just like an NP satisfying\nassignment to the variables is good.",
    "start": "1265480",
    "end": "1270790"
  },
  {
    "text": " In the no instance, now I\nknow, let's say, at most half",
    "start": "1270790",
    "end": "1278280"
  },
  {
    "text": "of the things are satisfied\nif this is one half. And so what is my\nalgorithm going to do?",
    "start": "1278280",
    "end": "1285460"
  },
  {
    "text": " In order to get some at\nmost constant probability",
    "start": "1285460",
    "end": "1291330"
  },
  {
    "text": "of failure, it's going\nto choose a random clause and check that it was satisfied. ",
    "start": "1291330",
    "end": "1314530"
  },
  {
    "text": "Uniform random. So I've got log n bits. Let's say there are n clauses. So I can choose one of them at\nrandom by flipping log n coins.",
    "start": "1314530",
    "end": "1324730"
  },
  {
    "text": "And then check so that\ninvolves-- this is three SATs.",
    "start": "1324730",
    "end": "1329915"
  },
  {
    "text": "It only involves\nthree variables. I check those three\nvariable value assignments in my certificate by random\naccess into the certificate.",
    "start": "1329915",
    "end": "1338380"
  },
  {
    "text": "In constant time, I\ndetermine whether that clause is satisfied. If the clause is satisfied,\nalgorithm returns yes.",
    "start": "1338380",
    "end": "1344290"
  },
  {
    "text": "Otherwise, return no. Now, if it was a\nsatisfying assignment, the algorithm will\nalways say yes.",
    "start": "1344290",
    "end": "1349750"
  },
  {
    "text": "So that's good. If it was not\nsatisfiable, we know that, let's say at most half\nof the clauses are satisfiable.",
    "start": "1349750",
    "end": "1357700"
  },
  {
    "text": "Which means in\nevery certificate, the algorithm will say no\nat least half the time.",
    "start": "1357700",
    "end": "1363210"
  },
  {
    "text": "And half is whatever\nthat constant is. So that means the probability\nthat the algorithm",
    "start": "1363210",
    "end": "1371590"
  },
  {
    "text": "is wrong is less than 1 over\nthe gap, whatever that ratio is.",
    "start": "1371590",
    "end": "1382190"
  },
  {
    "text": "Cool? Yeah. AUDIENCE: So does\nthis [INAUDIBLE]? ",
    "start": "1382190",
    "end": "1388760"
  },
  {
    "text": "So for [INAUDIBLE].  PROFESSOR: Let me tell\nyou, the PCP theorem",
    "start": "1388760",
    "end": "1398680"
  },
  {
    "text": "is that NP equals PCP. This is proved. So all problems are in PCP.",
    "start": "1398680",
    "end": "1406100"
  },
  {
    "text": "But this is some motivation\nfor where this class came from. ",
    "start": "1406100",
    "end": "1413210"
  },
  {
    "text": "I'm not going to\nprove this theorem. The original proof\nis super long. Since then, there have been\nrelatively short proofs.",
    "start": "1413210",
    "end": "1418420"
  },
  {
    "text": "I think the shortest proof\ncurrently is two pages long. Still not going to\nprove it because it's a bit beside the\npoint to some extent.",
    "start": "1418420",
    "end": "1427730"
  },
  {
    "text": "It does use reductions\nand gap amplification, but it's technical to\nprove it, let's say.",
    "start": "1427730",
    "end": "1435950"
  },
  {
    "text": "But I will give you some more\nmotivation for why it's true. So for example, so\nhere's one claim.",
    "start": "1435950",
    "end": "1450880"
  },
  {
    "text": "If one-- let's\nchange this notation.",
    "start": "1450880",
    "end": "1456820"
  },
  {
    "text": "If less than 1, comma\n1, gap 3SAT is NP-hard,",
    "start": "1456820",
    "end": "1471169"
  },
  {
    "text": "then NP equals PCP.",
    "start": "1471170",
    "end": "1476650"
  },
  {
    "text": "So we know that this\nis true, but before we know that here-- so we just\nproved that this thing is NPCP.",
    "start": "1476650",
    "end": "1485170"
  },
  {
    "text": "And if furthermore\nthis problem-- we're going to prove\nthis is NP-hard.",
    "start": "1485170",
    "end": "1490390"
  },
  {
    "text": "That's the motivation. If you believe\nthat it's NP-hard, then we know all problems in\nNP can reduce to this thing.",
    "start": "1490390",
    "end": "1498330"
  },
  {
    "text": "And then that thing is NPCP. So that tells us that\nall problems in NP, you can convert them into\nless than 1, comma 1 gap 3SAT",
    "start": "1498330",
    "end": "1506090"
  },
  {
    "text": "and then get a PCP\nalgorithm for them. So that would be one way\nto prove the PCP theorem.",
    "start": "1506090",
    "end": "1513190"
  },
  {
    "text": "In fact, the reverse\nis also true. And this is sort of more\ndirectly useful to us.",
    "start": "1513190",
    "end": "1520770"
  },
  {
    "text": "If, let's say, 3SAT is NPCP,\nthen the gap version of 3SAT",
    "start": "1520770",
    "end": "1541180"
  },
  {
    "text": "is NP-hard.  This is interesting\nbecause-- this is true",
    "start": "1541180",
    "end": "1549630"
  },
  {
    "text": "because NP equals PCP, in\nparticular 3SAT is NPCP. And so we're going to\nbe able to conclude,",
    "start": "1549630",
    "end": "1556180"
  },
  {
    "text": "by a very short argument,\nthat the gap version of 3SAT is also NP-hard. And this proves constant factor\ninapproximability of 3SAT.",
    "start": "1556180",
    "end": "1563720"
  },
  {
    "text": "We will see a tighter\nconstant in a little bit, but this will be our\nfirst such bound.",
    "start": "1563720",
    "end": "1569840"
  },
  {
    "text": "And this is a very\ngeneral kind of algorithm. It's kind of cool. ",
    "start": "1569840",
    "end": "1576090"
  },
  {
    "text": "So PCP is easy for the\ngap version of 3SAT. But suppose there was a\nprobabilistically checkable",
    "start": "1576090",
    "end": "1581970"
  },
  {
    "text": "proof for just straight up\n3SAT when you're not given any gap bound, which is true.",
    "start": "1581970",
    "end": "1588050"
  },
  {
    "text": "It does exist. So we're going to\nuse that algorithm. And we're going to do a\ngap-preserving reduction.",
    "start": "1588050",
    "end": "1595740"
  },
  {
    "start": "1595740",
    "end": "1606280"
  },
  {
    "text": "The PCP algorithm we're given,\nbecause we're looking at PCP log n, comma order one,\nruns in constant time.",
    "start": "1606280",
    "end": "1612800"
  },
  {
    "text": "Constant time algorithm\ncan't do very much. In particular, I can\nwrite the algorithm",
    "start": "1612800",
    "end": "1618200"
  },
  {
    "text": "as a constant size formula. ",
    "start": "1618200",
    "end": "1624510"
  },
  {
    "text": "It's really a distribution\nover such formulas defined by the log n and the bits.",
    "start": "1624510",
    "end": "1629750"
  },
  {
    "text": "But let's say it's a\nrandom variable where for each possible random choice\nis a constant size formula that",
    "start": "1629750",
    "end": "1637200"
  },
  {
    "text": "evaluates to true or\nfalse, corresponding to whether the algorithm\nsays yes or no. We know we can\nconvert algorithms",
    "start": "1637200",
    "end": "1642645"
  },
  {
    "text": "to formulas if they're\na short amount of time. So we can make\nthat a CNF formula.",
    "start": "1642645",
    "end": "1649370"
  },
  {
    "text": "Why not? 3CNF if we want. My goal is to-- I\nwant to reduce 3SAT",
    "start": "1649370",
    "end": "1657850"
  },
  {
    "text": "to the gap version of 3SAT. Because 3SAT we know is NP-hard. So if I can reduce it to the\ngap version of 3SAT, I'm happy.",
    "start": "1657850",
    "end": "1664290"
  },
  {
    "text": "Then I know the gap version\nof 3SAT is also hard. So here is my reduction. ",
    "start": "1664290",
    "end": "1673260"
  },
  {
    "text": "So I'm given the 3SAT\nformula, and the algorithm evaluates some formula on\nit and the certificate.",
    "start": "1673260",
    "end": "1681260"
  },
  {
    "text": "What I'm going to do is try\nall of the random choices.",
    "start": "1681260",
    "end": "1692914"
  },
  {
    "text": "Because there's only\nlog n bits, there's only polynomially many possible\nchoices for those bits. ",
    "start": "1692914",
    "end": "1700970"
  },
  {
    "text": "Order log n so it's\nn to some constant. And I want to take this\nformula, take the conjunction over all of those choices.",
    "start": "1700970",
    "end": "1707750"
  },
  {
    "text": "If the algorithm\nalways says yes, then this formula\nwill be satisfied.",
    "start": "1707750",
    "end": "1713740"
  },
  {
    "text": "So in the yes instance case,\nI get a satisfiable formula. So yes, complies satisfiable,\n100% satisfiable.",
    "start": "1713740",
    "end": "1725680"
  },
  {
    "text": "That corresponds to this number. I want it to be 100%\nin the yes case.",
    "start": "1725680",
    "end": "1731720"
  },
  {
    "text": "In the no case, I know\nthat a constant fraction",
    "start": "1731720",
    "end": "1739650"
  },
  {
    "text": "of these random\nchoices give a no. Meaning, they will\nnot be satisfied.",
    "start": "1739650",
    "end": "1746420"
  },
  {
    "text": "For any choice,\nany certificate, I know that a constant\nfraction of these terms which",
    "start": "1746420",
    "end": "1754840"
  },
  {
    "text": "I'm conjuncting will\nevaluate to false because of the definition of PCP.",
    "start": "1754840",
    "end": "1760260"
  },
  {
    "text": "That's what probability\nalgorithm saying no means.",
    "start": "1760260",
    "end": "1765310"
  },
  {
    "text": "So it's a constant fraction\nof the terms are false.",
    "start": "1765310",
    "end": "1777560"
  },
  {
    "text": " The terms are the things\nwe're conjuncting over.",
    "start": "1777560",
    "end": "1783310"
  },
  {
    "text": "But each term here is a\nconstant size CNF formula.",
    "start": "1783310",
    "end": "1789070"
  },
  {
    "text": "So when I and those together,\nI really just get one giant and of clauses. Constant fraction larger\nthan the number of terms.",
    "start": "1789070",
    "end": "1796330"
  },
  {
    "text": "And if a term is false,\nthat means at least one of the clauses is false.",
    "start": "1796330",
    "end": "1801372"
  },
  {
    "text": "And there's only a constant\nnumber of clauses in each term. So this means a\nconstant fraction",
    "start": "1801372",
    "end": "1806409"
  },
  {
    "text": "of the clauses in that giant\nconjunction are also false. ",
    "start": "1806410",
    "end": "1819500"
  },
  {
    "text": "And that is essentially it. ",
    "start": "1819500",
    "end": "1829419"
  },
  {
    "text": "That is my reduction. ",
    "start": "1829420",
    "end": "1842310"
  },
  {
    "text": "So in the yes instance, I get\n100% percent satisfiable thing. In the no instance,\nI get some constant",
    "start": "1842310",
    "end": "1847990"
  },
  {
    "text": "strictly less than\n1 satisfiable thing. Because in any solution,\nI get a constant fraction",
    "start": "1847990",
    "end": "1853010"
  },
  {
    "text": "that turn out to be\nfalse, constant fraction of the clauses. Now what the constant is,\nyou'd have to work out things. You'd have to know how\nbig your PCP algorithm is.",
    "start": "1853010",
    "end": "1860169"
  },
  {
    "text": "But at least we get a\nconstant lower bound proving-- in particular, proving there's\nno P [? task ?] for MAX-3SAT.",
    "start": "1860170",
    "end": "1868529"
  },
  {
    "text": "This is what you might call\na gap-amplifying reduction, in the sense we\nstarted with no gap.",
    "start": "1868530",
    "end": "1875150"
  },
  {
    "text": "The instance of 3SAT was\neither true or false. And we ended up with something\nwith a significant gap.",
    "start": "1875150",
    "end": "1881105"
  },
  {
    "text": " So what we're going\nto talk about next",
    "start": "1881105",
    "end": "1886560"
  },
  {
    "text": "is called gap-preserving\nreductions. ",
    "start": "1886560",
    "end": "1893860"
  },
  {
    "text": "Maybe before I get there,\nwhat we just showed is that the PCP\ntheorem is equivalent.",
    "start": "1893860",
    "end": "1902370"
  },
  {
    "text": "And in particular, we get\ngap problems being NP-hard. This is why we care about PCPs.",
    "start": "1902370",
    "end": "1908710"
  },
  {
    "text": "And then in general,\nonce we have these kinds of gap\nhardness results,",
    "start": "1908710",
    "end": "1915750"
  },
  {
    "text": "we convert our-- when we're\nthinking about reductions from a to b, because we know\ngap implies inapproximability,",
    "start": "1915750",
    "end": "1923780"
  },
  {
    "text": "we could say, OK, 3SAT\nis inapproximable, and then do, say, an l reduction\nfrom 3SAT to something else.",
    "start": "1923780",
    "end": "1930390"
  },
  {
    "text": "The something else is\ntherefore inapproximable also. That's all good.",
    "start": "1930390",
    "end": "1935880"
  },
  {
    "text": "But we can also,\ninstead of thinking about the inapproximability and\nhow much carries from a to b,",
    "start": "1935880",
    "end": "1941090"
  },
  {
    "text": "we can think about\nthe gap directly. And this is sort of the main\napproach in this lecture",
    "start": "1941090",
    "end": "1946480"
  },
  {
    "text": "that I'm trying to\ndemonstrate is by preserving the gap directly,\na, well you get new gap bounds and generally\nstronger gap bounds.",
    "start": "1946480",
    "end": "1954350"
  },
  {
    "text": "And then those imply\ninapproximability results. But the gap bounds are stronger\nthan the inapproximability,",
    "start": "1954350",
    "end": "1960100"
  },
  {
    "text": "and also they tend to give\nlarger constant factors in the inapproximability\nresults.",
    "start": "1960100",
    "end": "1966030"
  },
  {
    "text": "So what do we want out of\na gap-preserving reduction? Let's say we have\nan instance x of A.",
    "start": "1966030",
    "end": "1978720"
  },
  {
    "text": "We convert that into an instance\nx prime of some problem B.",
    "start": "1978720",
    "end": "1987940"
  },
  {
    "text": "We're just going to\nthink about the OPT of x versus the OPT of x prime. And what we want for, let's\nsay, a minimization problem",
    "start": "1987940",
    "end": "1997980"
  },
  {
    "text": "is two properties. One is that the OPT-- if the\nOPT of x is at most some k,",
    "start": "1997980",
    "end": "2007769"
  },
  {
    "text": "then the OPT of x prime\nis at most some k prime.",
    "start": "2007770",
    "end": "2015270"
  },
  {
    "text": "And conversely. ",
    "start": "2015270",
    "end": "2034320"
  },
  {
    "text": "So in general, OPT\nmay not be preserved. But let's say it changes\nby some prime operation.",
    "start": "2034320",
    "end": "2040910"
  },
  {
    "text": "So in fact, you can think of k\nand k prime as functions of n.",
    "start": "2040910",
    "end": "2048969"
  },
  {
    "text": "So if I know that OPT of x is\nat most some function of n, then I get that OPT of x prime\nis at most some other function",
    "start": "2048969",
    "end": "2056110"
  },
  {
    "text": "of n. But there's some known\nrelation between the two. What I care about is this gap c.",
    "start": "2056111",
    "end": "2061760"
  },
  {
    "text": "Should be a c prime here. So what this is saying is\nsuppose I had a gap, if I know",
    "start": "2061760",
    "end": "2067310"
  },
  {
    "text": "that all the solutions\nare either less than k or more than c times\nk, I want that to be",
    "start": "2067310",
    "end": "2073030"
  },
  {
    "text": "preserved for some\npossibly other gap c prime in the new problem. So this is pretty general,\nbut this is the sort of thing",
    "start": "2073030",
    "end": "2079520"
  },
  {
    "text": "we want to preserve. If we had a gap of c before,\nwe get some gap c prime after.",
    "start": "2079520",
    "end": "2084679"
  },
  {
    "text": "If c prime equals c, this would\nbe a perfectly gap-preserving reduction. Maybe we'll lose\nsome constant factor.",
    "start": "2084679",
    "end": "2091440"
  },
  {
    "text": "If c prime is\ngreater than c, this is called gap amplification. ",
    "start": "2091440",
    "end": "2102150"
  },
  {
    "text": "And gap amplification\nis essentially how the PCP theorem is\nshown, by repeatedly",
    "start": "2102150",
    "end": "2111790"
  },
  {
    "text": "growing the gap until\nit's something reasonable. And if you want to, say, prove\nthat set cover is log n hard,",
    "start": "2111790",
    "end": "2118400"
  },
  {
    "text": "it's a similar thing where\nyou start with a small gap constant factor, and\nthen you grow it, and you show you can grow it\nto log n before you run out",
    "start": "2118400",
    "end": "2125420"
  },
  {
    "text": "of space to write it in\nyour problem essentially, before your instance gets\nmore than polynomial.",
    "start": "2125420",
    "end": "2130880"
  },
  {
    "text": "Or if you want to prove that\n[INAUDIBLE] can't be solved in better than whatever\nn to the 1 minus epsilon,",
    "start": "2130880",
    "end": "2137170"
  },
  {
    "text": "then a similar trick of\ngap amplification works. Those amplification\narguments are involved,",
    "start": "2137170",
    "end": "2143080"
  },
  {
    "text": "and so I'm not going\nto show them here. But I will show you an example\nof a gap-preserving reduction",
    "start": "2143080",
    "end": "2149260"
  },
  {
    "text": "next, unless there\nare questions.  Cool So I'm going to\nreduce a problem which",
    "start": "2149260",
    "end": "2162190"
  },
  {
    "text": "we have mentioned\nbefore, which is MAX",
    "start": "2162190",
    "end": "2176220"
  },
  {
    "text": "exactly 3 XOR- and XNOR-SAT. This is linear equations,\n[INAUDIBLE] two,",
    "start": "2176220",
    "end": "2182760"
  },
  {
    "text": "where every equation\nhas exactly three terms.",
    "start": "2182760",
    "end": "2188210"
  },
  {
    "text": "So something like xi XOR xj XOR\nxk equals one, or something.",
    "start": "2188210",
    "end": "2198586"
  },
  {
    "text": "You can also have\nnegations here.  So I have a bunch of\nequations like that.",
    "start": "2198586",
    "end": "2206460"
  },
  {
    "text": "I'm going to just tell you\na gap bound on this problem, and then we're going to reduce\nit to another problem, namely",
    "start": "2206460",
    "end": "2211690"
  },
  {
    "text": "MAX-E3-SAT. So the claim here\nis that this problem",
    "start": "2211690",
    "end": "2218360"
  },
  {
    "text": "is one half plus epsilon,\none minus epsilon, gap",
    "start": "2218360",
    "end": "2224650"
  },
  {
    "text": "hard for any epsilon. ",
    "start": "2224650",
    "end": "2234460"
  },
  {
    "text": "Which in particular\nimplies that it is one half minus\nepsilon inapproximable,",
    "start": "2234460",
    "end": "2239829"
  },
  {
    "text": "unless p equals NP.  But this is of course stronger.",
    "start": "2239830",
    "end": "2245690"
  },
  {
    "text": "It says if you just\nlook at instances where let's say 99% of the equations\nare satisfiable versus when",
    "start": "2245690",
    "end": "2257519"
  },
  {
    "text": "51% are satisfiable, it's\nNP-hard to distinguish between those two.",
    "start": "2257520",
    "end": "2262810"
  },
  {
    "text": " Why one half here?",
    "start": "2262810",
    "end": "2267940"
  },
  {
    "text": "Because there is a one\nhalf approximation. ",
    "start": "2267940",
    "end": "2274830"
  },
  {
    "text": "I've kind of mentioned\nthe general approach for approximation\nalgorithms for SAT is take a random assignment,\nvariable assignment.",
    "start": "2274830",
    "end": "2282980"
  },
  {
    "text": "And in this case, because these\nstatements are about a parity,",
    "start": "2282980",
    "end": "2288609"
  },
  {
    "text": "if you think of xk\nas random, it doesn't matter what these two are. 50% probability this\nwill be satisfied.",
    "start": "2288610",
    "end": "2294170"
  },
  {
    "text": "And so you can always satisfy\nat least half of the clauses because this randomized\nalgorithm will satisfy half",
    "start": "2294170",
    "end": "2300700"
  },
  {
    "text": "in expectation. Therefore, in at least one\ninstance, it will do so. But if you allow\nrandomized approximation,",
    "start": "2300700",
    "end": "2306740"
  },
  {
    "text": "this is a one half approximation\nor a two approximation, depending on your perspective.",
    "start": "2306740",
    "end": "2312520"
  },
  {
    "text": "So this is really tight. That's good news. And this is essentially a\nform of the PCP theorem.",
    "start": "2312520",
    "end": "2321580"
  },
  {
    "text": "PCP theorem says that\nthere's some algorithm,",
    "start": "2321580",
    "end": "2327070"
  },
  {
    "text": "and you can prove that in fact\nthere is an algorithm that looks like this. It's a bunch of linear equations\nwith three terms per equation.",
    "start": "2327070",
    "end": "2338010"
  },
  {
    "text": "So let's take that as given. ",
    "start": "2338010",
    "end": "2347690"
  },
  {
    "text": "Now, what I want to\nshow is a reduction from that problem to MAX-E3-SAT.",
    "start": "2347690",
    "end": "2355440"
  },
  {
    "text": "So remember MAX-E3-SAT,\nyou're given",
    "start": "2355440",
    "end": "2364839"
  },
  {
    "text": "CNF where every\nclause has exactly three distinct literals.",
    "start": "2364840",
    "end": "2370839"
  },
  {
    "text": "You want to maximize the\nnumber of satisfied things. So this is roughly the problem\nwe were talking about up there.",
    "start": "2370840",
    "end": "2377670"
  },
  {
    "text": " So first thing\nI'm going to do is",
    "start": "2377670",
    "end": "2388570"
  },
  {
    "text": "I want to reduce this to that. And this is the reduction.",
    "start": "2388570",
    "end": "2395700"
  },
  {
    "text": "And the first claim is just\nthat it's an L-reduction. So that's something\nwe're familiar with. Let's think about it that way.",
    "start": "2395700",
    "end": "2400930"
  },
  {
    "text": "Then we will think about it\nin a gap-preserving sense. So there are two types of\nequations we need to satisfy,",
    "start": "2400930",
    "end": "2408500"
  },
  {
    "text": "the sort of odd case\nor the even case. Again, each of these\ncould be negated.",
    "start": "2408500",
    "end": "2414130"
  },
  {
    "text": "I'm just going to double negate\nmeans unnegated over here. So each equation is going to\nbe replaced with exactly four",
    "start": "2414130",
    "end": "2421549"
  },
  {
    "text": "clauses in the E3-SAT instance. And the idea is, well, if I want\nthe parity of them to be odd,",
    "start": "2421550",
    "end": "2434660"
  },
  {
    "text": "it should be the case that\nat least one of them is true. And if you stare at it\nlong enough, also when",
    "start": "2434660",
    "end": "2440680"
  },
  {
    "text": "you put two bars in there, I\ndon't want exactly two of them to be true. That's the parity constraint.",
    "start": "2440680",
    "end": "2446970"
  },
  {
    "text": "If this is true, all four\nof these should be true. That's the first claim,\njust by the parity",
    "start": "2446970",
    "end": "2454140"
  },
  {
    "text": "of the number of bars. There's either zero\nbars or two bars, or three positive\nor one positive.",
    "start": "2454140",
    "end": "2462710"
  },
  {
    "text": "That's the two cases. And in this situation where\nI want the parity to be even,",
    "start": "2462710",
    "end": "2470599"
  },
  {
    "text": "even number of trues, I\nhave all the even number of trues cases over here.",
    "start": "2470600",
    "end": "2477190"
  },
  {
    "text": "Here are two of them even,\nand here none of them even. ",
    "start": "2477190",
    "end": "2483700"
  },
  {
    "text": "And again, if this is satisfied,\nthen all four of those are satisfied. Now, if these are not\nsatisfied, by the same argument",
    "start": "2483700",
    "end": "2493300"
  },
  {
    "text": "you can show that at least\none of these is violated. But in fact, just\none will be violated.",
    "start": "2493300",
    "end": "2498940"
  },
  {
    "text": "So for example, so this\nis just a case analysis. Let's say I set all\nof these to be zero,",
    "start": "2498940",
    "end": "2506500"
  },
  {
    "text": "and so their XOR is\nzero and not one. So if they're all false, then\nthis will not be satisfied,",
    "start": "2506500",
    "end": "2513270"
  },
  {
    "text": "but the other three will be. And in general, because\nwe have, for example,",
    "start": "2513270",
    "end": "2519700"
  },
  {
    "text": "xi appearing true and\nfalse in different cases, you will satisfy\nthree out of four",
    "start": "2519700",
    "end": "2527690"
  },
  {
    "text": "on the right when you\ndon't satisfy on the left. So the difference is\nthree versus four.",
    "start": "2527690",
    "end": "2533286"
  },
  {
    "text": "When these are satisfied, you\nsatisfy four on the right. When they're unsatisfied, you\nsatisfy three on the right. That's all.",
    "start": "2533287",
    "end": "2538910"
  },
  {
    "text": "Claiming. ",
    "start": "2538910",
    "end": "2547260"
  },
  {
    "text": "So if the equation\nis satisfied, then we",
    "start": "2547260",
    "end": "2552540"
  },
  {
    "text": "get four in the 3SAT instance.",
    "start": "2552540",
    "end": "2558920"
  },
  {
    "text": "And if it's unsatisfied, we\nturn out to get exactly three.",
    "start": "2558920",
    "end": "2566670"
  },
  {
    "start": "2566670",
    "end": "2573280"
  },
  {
    "text": "So I want to prove that\nthis is an L-reduction. To prove L-reduction,\nwe need two things. One is that the additive gap,\nif I solve the 3SAT instance",
    "start": "2573280",
    "end": "2582880"
  },
  {
    "text": "and convert it back into\na corresponding solution to MAX-E3 XNOR SAT, which\ndon't change anything.",
    "start": "2582880",
    "end": "2591730"
  },
  {
    "text": "The variables are just\nwhat they were before. That the additive gap\nfrom OPT on the right side",
    "start": "2591730",
    "end": "2597970"
  },
  {
    "text": "is at most some constant\ntimes the additive gap on the left side, or vice versa.",
    "start": "2597970",
    "end": "2603960"
  },
  {
    "text": "In this case, the gap is\nexactly preserved because it's four versus three over here. It's one versus zero over here.",
    "start": "2603960",
    "end": "2609980"
  },
  {
    "text": "So additive gap remains one. And that is called beta, I\nthink, in L-reduction land.",
    "start": "2609980",
    "end": "2619165"
  },
  {
    "start": "2619165",
    "end": "2625220"
  },
  {
    "text": "So this was property\ntwo in the L-reduction. So the additive error in this\ncase is exactly preserved.",
    "start": "2625220",
    "end": "2638130"
  },
  {
    "text": " So there's no scale. Beta equals one.",
    "start": "2638130",
    "end": "2645530"
  },
  {
    "text": "If there's some other gap,\nif it was five versus three, then we'd have beta equal two.",
    "start": "2645530",
    "end": "2652310"
  },
  {
    "text": "Then there was the\nother property, which is you need to show that\nyou don't blow up OPT too much. We want the OPT on\nthe right hand side",
    "start": "2652310",
    "end": "2660050"
  },
  {
    "text": "to be at most some constant\ntimes OPT on the left hand side.",
    "start": "2660050",
    "end": "2665559"
  },
  {
    "text": "This requires a\nlittle bit more care because we need to make sure\nOPT is linear, basically.",
    "start": "2665560",
    "end": "2671290"
  },
  {
    "text": "We did a lot of these\narguments last lecture. Because even when you\ndon't satisfy things,",
    "start": "2671290",
    "end": "2678040"
  },
  {
    "text": "you still get points. And the difference between\nzero and three is big ratio. We want that to not\nhappen too much.",
    "start": "2678040",
    "end": "2684442"
  },
  {
    "text": "And it doesn't happen\ntoo much because we know the left hand side OPT is\nat least a half of all clauses.",
    "start": "2684442",
    "end": "2692140"
  },
  {
    "text": "So it's not like there are\nvery many unsatisfied clauses. At most, half of\nthem are unsatisfied because at least half are\nsatisfiable in the case of OPT.",
    "start": "2692140",
    "end": "2702150"
  },
  {
    "text": "So here's the full argument. ",
    "start": "2702150",
    "end": "2712930"
  },
  {
    "text": "In general, OPT for\nthe 3SAT instance",
    "start": "2712930",
    "end": "2718640"
  },
  {
    "text": "is going to be four times\nall the satisfiable things plus three times all the\nunsatisfiable things.",
    "start": "2718640",
    "end": "2724280"
  },
  {
    "text": "This is the same thing\nas saying the-- sorry.",
    "start": "2724280",
    "end": "2729600"
  },
  {
    "text": "You take three times\nthe number of equations. Every equation gets\nthree points for free.",
    "start": "2729600",
    "end": "2735089"
  },
  {
    "text": "And then if you also satisfy\nthem, you get one more point. So this is an equation on\nthose things, the two OPTs.",
    "start": "2735090",
    "end": "2742400"
  },
  {
    "text": "And we get plus three times\nthe number of equations. And because there is a\none half approximation,",
    "start": "2742400",
    "end": "2748089"
  },
  {
    "text": "we know that number of equations\nis at most two times OPT.",
    "start": "2748090",
    "end": "2754670"
  },
  {
    "start": "2754670",
    "end": "2761470"
  },
  {
    "text": "Because OPT is at least a\nhalf the number of equations. And so this thing is overall at\nmost six plus one seven times",
    "start": "2761470",
    "end": "2770502"
  },
  {
    "text": "OPT E3 XNOR. ",
    "start": "2770502",
    "end": "2776260"
  },
  {
    "text": "And this is the thing\ncalled alpha in L-reduction. I wanted to compute\nthese explicitly",
    "start": "2776260",
    "end": "2783110"
  },
  {
    "text": "because I want to see how\nmuch inapproximability I get. Because I started with a\ntight inapproximability bound",
    "start": "2783110",
    "end": "2788925"
  },
  {
    "text": "of one half minus\nepsilon being impossible, whereas one half is possible.",
    "start": "2788925",
    "end": "2794730"
  },
  {
    "text": "It's tight up to this very tiny\narbitrary additive constant.",
    "start": "2794730",
    "end": "2800100"
  },
  {
    "text": "And over here, we're\ngoing to lose something. We know from L-reductions,\nif you were inapproximable",
    "start": "2800100",
    "end": "2805579"
  },
  {
    "text": "before, you get\ninapproximability in this case of MAX-E3-SAT. E3 So what is the factor?",
    "start": "2805580",
    "end": "2813520"
  },
  {
    "text": "If you think of-- there's\none simplification here relative to what\nI presented before.",
    "start": "2813520",
    "end": "2819800"
  },
  {
    "text": "A couple lectures ago, we\nalways thought about one plus epsilon approximation,\nand how does epsilon change.",
    "start": "2819800",
    "end": "2826869"
  },
  {
    "text": "And that works really well\nfor minimization problems. For a maximization problem,\nyour approximation factor",
    "start": "2826870",
    "end": "2832090"
  },
  {
    "text": "is-- an approximation\nfactor of one plus epsilon means you are at\nleast this thing times OPT.",
    "start": "2832090",
    "end": "2840140"
  },
  {
    "text": "And this thing gets\nawkward to work with. Equivalently, with a\ndifferent notion of epsilon,",
    "start": "2840140",
    "end": "2846800"
  },
  {
    "text": "you could just think of a one\nminus epsilon approximation and how does epsilon change.",
    "start": "2846800",
    "end": "2852070"
  },
  {
    "text": "And in general, for\nmaximization problem, if you have one minus\nepsilon approximation",
    "start": "2852070",
    "end": "2858610"
  },
  {
    "text": "before the L-reduction,\nthen afterwards you will have a one minus\nepsilon over alpha beta.",
    "start": "2858610",
    "end": "2867870"
  },
  {
    "text": "So for maximization, we\nhad one plus epsilon. And then we got one plus\nepsilon over alpha beta.",
    "start": "2867870",
    "end": "2873270"
  },
  {
    "text": "With the minuses,\nit also works out. That's a cleaner way\nto do maximization. So this was a\nmaximization problem.",
    "start": "2873270",
    "end": "2879030"
  },
  {
    "text": "We had over here\nepsilon was-- sorry, different notions of epsilon.",
    "start": "2879030",
    "end": "2884160"
  },
  {
    "text": "Here we have one half\ninapproximability One half is also known\nas one minus one half.",
    "start": "2884160",
    "end": "2889780"
  },
  {
    "text": "So epsilon here is a half. And alpha was seven.",
    "start": "2889780",
    "end": "2896280"
  },
  {
    "text": "Beta was one. And so we just divide by seven.",
    "start": "2896280",
    "end": "2902589"
  },
  {
    "text": "So in this case, we\nget that MAX-E3-SAT",
    "start": "2902590",
    "end": "2910650"
  },
  {
    "text": "is one minus one half divided\nby seven, which is 1/14.",
    "start": "2910650",
    "end": "2920920"
  },
  {
    "text": "Technically there's\na minus epsilon here. Sorry, bad overuse of epsilon.",
    "start": "2920920",
    "end": "2927559"
  },
  {
    "text": "This is, again, for any\nepsilon greater than zero because we had some epsilon\ngreater than zero here.",
    "start": "2927559",
    "end": "2932560"
  },
  {
    "text": "Slightly less than one\nhalf is impossible. So over here we get slightly\nless than one minus 1/14",
    "start": "2932560",
    "end": "2940010"
  },
  {
    "text": "is impossible. This is 13/14 minus\nepsilon, which is OK.",
    "start": "2940010",
    "end": "2954030"
  },
  {
    "text": "It's a bound. But it's not a tight bound. The right answer\nfor MAX-3SAT is 7/8.",
    "start": "2954030",
    "end": "2960710"
  },
  {
    "text": "Because if you take, again,\na uniform random assignment, every variable flips a coin,\nheads or tails, true or false.",
    "start": "2960710",
    "end": "2968099"
  },
  {
    "text": "Then 7/8 of the clauses will\nbe satisfied in expectation. Because if you look at a clause,\nif it has exactly three terms",
    "start": "2968100",
    "end": "2976170"
  },
  {
    "text": "and it's an or of three things,\nyou just need at least one head to satisfy this thing.",
    "start": "2976170",
    "end": "2981180"
  },
  {
    "text": "So you get a 50% chance to\ndo it in the first time, and then a quarter chance\nto do it in the third time, and in general 7/8 chance to\nget it one of the three times.",
    "start": "2981180",
    "end": "2991760"
  },
  {
    "text": "7/8 is smaller than 13/14,\nso we're not quite there yet.",
    "start": "2991760",
    "end": "2997050"
  },
  {
    "text": "But this reduction\nwill do it if we think about it from\nthe perspective",
    "start": "2997050",
    "end": "3002940"
  },
  {
    "text": "of gap-preserving reductions. So from this general\nL-reduction black box",
    "start": "3002940",
    "end": "3007990"
  },
  {
    "text": "that we only lose an alpha beta\nfactor, yeah we get this bound.",
    "start": "3007990",
    "end": "3013540"
  },
  {
    "text": "But from a gap perspective,\nwe can do better. The reason we can do better\nis because gaps are always",
    "start": "3013540",
    "end": "3019500"
  },
  {
    "text": "talking about yes instances\nwhere lots of things are satisfied. That means we're most of the\ntime in the case where we have",
    "start": "3019500",
    "end": "3025570"
  },
  {
    "text": "fours on the right hand side, or\na situation where we have lots of things unsatisfied, that\nmeans we have lots of threes",
    "start": "3025570",
    "end": "3031230"
  },
  {
    "text": "on the right hand side. It lets us get a\nslightly tighter bound. So let's do that. ",
    "start": "3031230",
    "end": "3057340"
  },
  {
    "text": "So here is a gap argument\nabout the same reduction.",
    "start": "3057340",
    "end": "3064630"
  },
  {
    "text": "What we're going to claim is\nthat 7/8 minus epsilon gap 3SAT",
    "start": "3064630",
    "end": "3075819"
  },
  {
    "text": "is NP-hard, which implies\n7/8 inapproximability,",
    "start": "3075820",
    "end": "3081000"
  },
  {
    "text": "but by looking at it\nfrom the gap perspective, we will get this stronger\nbound versus the 13/14 bound.",
    "start": "3081000",
    "end": "3088110"
  },
  {
    "text": "So the proof is by a\ngap-preserving reduction,",
    "start": "3088110",
    "end": "3093430"
  },
  {
    "text": "namely that reduction, from\nMAX-E3-XNOR-SAT to MAX-3SAT,",
    "start": "3093430",
    "end": "3101800"
  },
  {
    "text": "E3-SAT I should say. ",
    "start": "3101800",
    "end": "3106990"
  },
  {
    "text": "And so the idea\nis the following. Either we have a yes\ninstance or a no instance. ",
    "start": "3106990",
    "end": "3115200"
  },
  {
    "text": "If we have a yes instance\nto the equation problem,",
    "start": "3115200",
    "end": "3121940"
  },
  {
    "text": "then we know that at least one\nminus epsilon of the equations",
    "start": "3121940",
    "end": "3129010"
  },
  {
    "text": "are satisfiable. So we have one minus epsilon.",
    "start": "3129010",
    "end": "3135819"
  },
  {
    "text": "Let's say m is the\nnumber of equations. ",
    "start": "3135820",
    "end": "3146570"
  },
  {
    "text": "In the no instance\ncase, of course we know that not too\nmany are satisfied. At most, one half plus epsilon\nfraction of the equations",
    "start": "3146570",
    "end": "3155890"
  },
  {
    "text": "are satisfiable. ",
    "start": "3155890",
    "end": "3163460"
  },
  {
    "text": "So in both cases, I want to\nsee what that converts into. So in the yes instance,\nwe get all four",
    "start": "3163460",
    "end": "3173457"
  },
  {
    "text": "of those things being satisfied. So that means we're going\nto have at least one",
    "start": "3173457",
    "end": "3182230"
  },
  {
    "text": "minus epsilon times m times\nfour clauses satisfied.",
    "start": "3182230",
    "end": "3188200"
  },
  {
    "text": "We'll also have\nepsilon m times three. Those are the unsatisfied. And maybe some of them\nare actually satisfied,",
    "start": "3188200",
    "end": "3194950"
  },
  {
    "text": "but this is a lower bound\non how many clauses we get. ",
    "start": "3194950",
    "end": "3201869"
  },
  {
    "text": "On the other hand,\nin this situation where not too many\nare satisfied, that means we get a\ntighter upper bound.",
    "start": "3201870",
    "end": "3208060"
  },
  {
    "text": "So we have one half plus\nepsilon times m times four.",
    "start": "3208060",
    "end": "3217020"
  },
  {
    "text": "And then there's the rest, one\nhalf minus epsilon times three.",
    "start": "3217020",
    "end": "3224490"
  },
  {
    "text": "And maybe some of these\nare not satisfied, but this is an upper bound on\nhow many clauses are satisfied",
    "start": "3224490",
    "end": "3231090"
  },
  {
    "text": "in the 3SAT instance versus\nequations in the 3x [INAUDIBLE] SAT instance.",
    "start": "3231090",
    "end": "3237500"
  },
  {
    "text": "Now I just want\nto compute these. So everything's times m.",
    "start": "3237500",
    "end": "3244040"
  },
  {
    "text": "And over here we have\nfour minus four epsilon. Over here we have\nplus three epsilon.",
    "start": "3244040",
    "end": "3249850"
  },
  {
    "text": "So that is four minus epsilon m. And here we have again\neverything is times m.",
    "start": "3249850",
    "end": "3257420"
  },
  {
    "text": "So we have 4/2, also known\nas two, plus four epsilon.",
    "start": "3257420",
    "end": "3265960"
  },
  {
    "text": " Plus we have 3/2\nminus three epsilon.",
    "start": "3265960",
    "end": "3273599"
  },
  {
    "text": "So the epsilons add\nup to plus epsilon. Then I check and see. Four epsilon minus\nthree epsilon.",
    "start": "3273600",
    "end": "3279750"
  },
  {
    "text": "And then we have 4/2 plus\n3/2, also known as 7/2.",
    "start": "3279750",
    "end": "3285371"
  },
  {
    "text": "Yes. ",
    "start": "3285371",
    "end": "3294120"
  },
  {
    "text": "So we had a gap before, and\nwe get this new gap after.",
    "start": "3294120",
    "end": "3299520"
  },
  {
    "text": "When we have a yes\ninstance, we know that there will be at\nleast this many clauses satisfied in the 3SAT.",
    "start": "3299520",
    "end": "3304650"
  },
  {
    "text": "And there'll be at most this\nmany in the no instance. So what we proved is\nthis bound that-- sorry,",
    "start": "3304650",
    "end": "3315340"
  },
  {
    "text": "get them in the right order. 7/2 is the smaller one. 7/2 plus epsilon, comma\nfour minus epsilon gap 3SAT,",
    "start": "3315340",
    "end": "3327720"
  },
  {
    "text": "E3-SAT, is NP-hard.",
    "start": "3327720",
    "end": "3333520"
  },
  {
    "text": "Because we had NP hardness\nof the gap before, we did this\ngap-preserving reduction,",
    "start": "3333520",
    "end": "3338570"
  },
  {
    "text": "which ended up\nwith this new gap, with this being for no\ninstances, this being for yes instances.",
    "start": "3338570",
    "end": "3344640"
  },
  {
    "text": "And so if we want to-- this\nis with the comma notation for the yes and no what\nfraction is satisfied.",
    "start": "3344640",
    "end": "3351100"
  },
  {
    "text": "If you convert it back\ninto the c gap notation,",
    "start": "3351100",
    "end": "3356370"
  },
  {
    "text": "you just take the ratio\nbetween these two things. And ignoring the epsilons,\nthis is like 4 divided by 7/2.",
    "start": "3356370",
    "end": "3364190"
  },
  {
    "text": "So that is 7/8 or 8/7, depending\non which way you're looking.",
    "start": "3364190",
    "end": "3372140"
  },
  {
    "text": "So we get also 7/8 gap.",
    "start": "3372140",
    "end": "3378079"
  },
  {
    "text": "Sorry, I guess it's 8/7 the\nway I was phrasing it before.",
    "start": "3378080",
    "end": "3384590"
  },
  {
    "text": "It's also NP-hard. And so that proves-- there's\nalso a minus epsilon. So I should have kept those.",
    "start": "3384590",
    "end": "3390160"
  },
  {
    "text": "Slightly different epsilon, but\nminus two epsilon, whatever. And so this gives us the 8/7\nis the best approximation",
    "start": "3390160",
    "end": "3397799"
  },
  {
    "text": "factor we can hope for. AUDIENCE: In the\nfirst notation, isn't it the fraction of clauses? So between zero and one?",
    "start": "3397800",
    "end": "3404877"
  },
  {
    "text": "PROFESSOR: Oh, yeah. Four is a little funny. Right. I needed to scale-- thank you--\nbecause the number of clauses",
    "start": "3404877",
    "end": "3412600"
  },
  {
    "text": "in the resulting thing\nis actually 4m, not m. So everything here needs\nto be divided by four.",
    "start": "3412600",
    "end": "3418990"
  },
  {
    "text": "It won't affect the final\nratio, but this should really be over four and over four.",
    "start": "3418990",
    "end": "3426050"
  },
  {
    "text": "So also known as\n7/8 plus epsilon,",
    "start": "3426050",
    "end": "3435190"
  },
  {
    "text": "comma one minus epsilon. Now it's a little clearer, 7/8.",
    "start": "3435190",
    "end": "3441470"
  },
  {
    "text": "Cool. Yeah. AUDIENCE: So are there any\n[INAUDIBLE] randomness?",
    "start": "3441470",
    "end": "3450220"
  },
  {
    "text": "AUDIENCE: So for [INAUDIBLE],\nyou can be the randomness. Randomness would\ngive you one half.",
    "start": "3450220",
    "end": "3456780"
  },
  {
    "text": "[INAUDIBLE] algorithm\ngives you 1.8. PROFESSOR: So you can beat\nit by a constant factor.",
    "start": "3456780",
    "end": "3462150"
  },
  {
    "text": "Probably not by more\nthan a constant factor. MAX CUT is an example\nwhere you can beat it.",
    "start": "3462150",
    "end": "3468280"
  },
  {
    "text": "I think I have the Goemans\nWilliamson bound here. ",
    "start": "3468280",
    "end": "3475270"
  },
  {
    "text": "MAX CUT, the best\napproximation is 0.878, which is better than\nwhat you get by random,",
    "start": "3475270",
    "end": "3481190"
  },
  {
    "text": "which is a half I guess. Cool. All right.",
    "start": "3481190",
    "end": "3486370"
  },
  {
    "text": " Cool. So we get optimal\nbound for MAX-E3-SAT,",
    "start": "3486370",
    "end": "3492350"
  },
  {
    "text": "assuming an optimum bound for\nE3-XNOR-SAT, which is from PCP. Yeah. AUDIENCE: So I'm sorry, can\nyou explain to me again why",
    "start": "3492350",
    "end": "3499000"
  },
  {
    "text": "we don't get this\nfrom the L-reduction, but we do get it from\nthe gap argument, even though the reduction\nis the same reduction?",
    "start": "3499000",
    "end": "3504510"
  },
  {
    "text": "PROFESSOR: It just lets\nus give a tighter argument in this case. By thinking about yes instances\nand no instances separately,",
    "start": "3504510",
    "end": "3510800"
  },
  {
    "text": "we get one thing. Because this reduction is\ndesigned to do different things",
    "start": "3510800",
    "end": "3515820"
  },
  {
    "text": "for yes and no instances. Whereas the L-reduction\njust says generically, if you satisfy these\nparameters alpha and beta,",
    "start": "3515820",
    "end": "3522150"
  },
  {
    "text": "you get some inapproximability\nresult on the output, but it's conservative. It's a conservative bound.",
    "start": "3522150",
    "end": "3527609"
  },
  {
    "text": "If you just use properties\none and two up here, that's the best you could show. But by essentially\nreanalyzing property one,",
    "start": "3527610",
    "end": "3536114"
  },
  {
    "text": "but thinking separately\nabout yes and no instances-- this held for all instances. We got a bound of seven.",
    "start": "3536114",
    "end": "3542010"
  },
  {
    "text": "But in the yes and\nthe no cases, you can essentially get a\nslightly tighter constant. ",
    "start": "3542010",
    "end": "3549541"
  },
  {
    "text": "All right. I want to tell you about\nanother cool problem. ",
    "start": "3549541",
    "end": "3571990"
  },
  {
    "text": "Another gap hardness that you\ncan get out of PCP analysis",
    "start": "3571990",
    "end": "3586040"
  },
  {
    "text": "by some gap amplification\nessentially, which",
    "start": "3586040",
    "end": "3592090"
  },
  {
    "text": "is called label cover. ",
    "start": "3592090",
    "end": "3600110"
  },
  {
    "text": "So this problem takes a\nlittle bit of time to define. But the basic point is there\nare very strong lower bounds",
    "start": "3600110",
    "end": "3608020"
  },
  {
    "text": "on the approximation factor. ",
    "start": "3608020",
    "end": "3626030"
  },
  {
    "text": "So you're given a bipartite\ngraph, no weights. ",
    "start": "3626030",
    "end": "3632680"
  },
  {
    "text": "The bipartition is A,\nB. And furthermore, A can be divided into k chunks.",
    "start": "3632680",
    "end": "3640495"
  },
  {
    "text": " And so can B. And these\nare disjoint unions.",
    "start": "3640495",
    "end": "3651515"
  },
  {
    "text": " And let's say size of\nA is n, size of B is n,",
    "start": "3651515",
    "end": "3661480"
  },
  {
    "text": "and size of each Ai\nis also the same.",
    "start": "3661480",
    "end": "3668010"
  },
  {
    "text": "We don't have to make these\nassumptions, but you can. So let's make it a\nlittle bit cleaner.",
    "start": "3668010",
    "end": "3673670"
  },
  {
    "text": "So in general, A consists of k\ngroups, each of size n over k. B consists of k groups,\neach of size n over k.",
    "start": "3673670",
    "end": "3681470"
  },
  {
    "text": "So that's our-- we have A\nhere with these little groups. We have B, these little groups.",
    "start": "3681470",
    "end": "3689560"
  },
  {
    "text": "And there's some\nedges between them. ",
    "start": "3689560",
    "end": "3697700"
  },
  {
    "text": "In general, your goal is\nto choose some subset of A,",
    "start": "3697700",
    "end": "3703890"
  },
  {
    "text": "let's call it A prime, and some\nsubset of B, call it B prime.",
    "start": "3703890",
    "end": "3709900"
  },
  {
    "text": "And one other thing\nI want to talk about",
    "start": "3709900",
    "end": "3715680"
  },
  {
    "text": "is called a super edge. ",
    "start": "3715680",
    "end": "3722550"
  },
  {
    "text": "And then I'll say what we\nwant out of these subsets that we choose. Imagine contracting\neach of these groups.",
    "start": "3722550",
    "end": "3729830"
  },
  {
    "text": "There are n over k\nitems here, and there are k different groups.",
    "start": "3729830",
    "end": "3736330"
  },
  {
    "text": "Imagine contracting each\ngroup to a single vertex. This is A1.",
    "start": "3736330",
    "end": "3742170"
  },
  {
    "text": "This is B3. I want to say that there's\na super edge from the group",
    "start": "3742170",
    "end": "3747820"
  },
  {
    "text": "A1 to the group\nB3 because there's at least one edge between them. If I squashed A1\nto a single vertex,",
    "start": "3747820",
    "end": "3753890"
  },
  {
    "text": "B3 down to a single vertex, I\nwould get an edge between them. So a super edge, Ai Bi--\nAi Bj, I should say--",
    "start": "3753890",
    "end": "3765100"
  },
  {
    "text": "exists if there's\nat least one edge",
    "start": "3765100",
    "end": "3770110"
  },
  {
    "text": "in AI cross Bj, at least one\nedge connecting those groups.",
    "start": "3770110",
    "end": "3776840"
  },
  {
    "text": "And I'm going to call such a\nsuper edge covered by A prime B",
    "start": "3776840",
    "end": "3782110"
  },
  {
    "text": "prime if at least one of those\nedges is in this chosen set.",
    "start": "3782110",
    "end": "3789910"
  },
  {
    "text": "So if there's at least\none edge-- sorry. ",
    "start": "3789910",
    "end": "3796150"
  },
  {
    "text": "If this Ai cross Bj, these\nare all the possible edges between those groups, intersects\nA prime cross B prime.",
    "start": "3796150",
    "end": "3813920"
  },
  {
    "text": "And in general, I want to cover\nall the hyper edges if I can. So I would like to\nhave a solution where,",
    "start": "3813920",
    "end": "3820460"
  },
  {
    "text": "if there is some edge\nbetween A1 and B3, then in the set of\nvertices I choose,",
    "start": "3820460",
    "end": "3826930"
  },
  {
    "text": "A prime and B prime in the left,\nthey induce at least one edge from A1 to B3, and\nalso from A2 to B3",
    "start": "3826930",
    "end": "3834980"
  },
  {
    "text": "because there is an\nedge that I drew here. I want ideally to choose\nthe endpoints of that edge,",
    "start": "3834980",
    "end": "3840697"
  },
  {
    "text": "or some other edge that\nconnects those two groups. Yeah. AUDIENCE: So you're choosing\nsubsets A prime of A. Is there some restriction\non the subset you choose?",
    "start": "3840697",
    "end": "3847434"
  },
  {
    "text": "Why don't you choose all of A? PROFESSOR: Wait. AUDIENCE: Oh, OK. You're not done yet? PROFESSOR: Nope.",
    "start": "3847434",
    "end": "3854095"
  },
  {
    "text": "That's about half\nof the definition. ",
    "start": "3854095",
    "end": "3863190"
  },
  {
    "text": "it's a lot to say it's not\nthat complicated of a problem. ",
    "start": "3863190",
    "end": "3870799"
  },
  {
    "text": "So there's two versions. That's part of what\nmakes it longer. We'll start with the\nmaximization version,",
    "start": "3870800",
    "end": "3877349"
  },
  {
    "text": "which is called Max-Rep. So we have two constraints\non A prime and B prime.",
    "start": "3877350",
    "end": "3882880"
  },
  {
    "text": " First is that we choose exactly\none vertex from each group.",
    "start": "3882880",
    "end": "3890180"
  },
  {
    "start": "3890180",
    "end": "3897700"
  },
  {
    "text": "So we got A prime\nintersect Ai equals",
    "start": "3897700",
    "end": "3902920"
  },
  {
    "text": "one, and B prime intersect Bj\nequals one, for all i and j.",
    "start": "3902920",
    "end": "3911599"
  },
  {
    "text": "OK And then subject\nto that constraint, we want to maximize the\nnumber of covered super edges.",
    "start": "3911600",
    "end": "3920380"
  },
  {
    "start": "3920380",
    "end": "3928140"
  },
  {
    "text": "Intuition here is that\nthose groups are labels.",
    "start": "3928140",
    "end": "3933250"
  },
  {
    "text": "And there's really one\nsuper vertex there, and you want to choose\none of those labels to satisfy the instance.",
    "start": "3933250",
    "end": "3939720"
  },
  {
    "text": "So here you're only allowed to\nchoose one label per vertex. We choose one out of\neach of the groups.",
    "start": "3939720",
    "end": "3944859"
  },
  {
    "text": "Then you'd like to cover\nas many edges as you can. If there is an edge in the\nsuper graph from Ai to Bj,",
    "start": "3944860",
    "end": "3953736"
  },
  {
    "text": "you would like to\ninclude an induced edge. There should actually be\nan edge between the label",
    "start": "3953736",
    "end": "3959920"
  },
  {
    "text": "you assign to Ai and the\nlabel you assign to Bj. That's this version.",
    "start": "3959920",
    "end": "3965690"
  },
  {
    "text": "The complementary problem\nis a minimization problem where we switch what is relaxed,\nwhat constraint is relaxed,",
    "start": "3965690",
    "end": "3973400"
  },
  {
    "text": "and what constraint must hold. So here we're going to\nallow multiple labels",
    "start": "3973400",
    "end": "3979270"
  },
  {
    "text": "for each super vertex,\nmultiple vertices to be chosen from each group.",
    "start": "3979270",
    "end": "3984560"
  },
  {
    "text": "Instead we force that\neverything is covered. We want to cover every\nsuper edge that exists.",
    "start": "3984560",
    "end": "3999220"
  },
  {
    "text": "And our goal is to minimize\nthe size of these sets,",
    "start": "3999220",
    "end": "4005710"
  },
  {
    "text": "A prime plus B prime. So this is sort of\nthe dual problem.",
    "start": "4005710",
    "end": "4011320"
  },
  {
    "text": "Here we force one\nlevel per vertex. We want to maximize the\nnumber of covered things. Here we force everything\nto be covered.",
    "start": "4011320",
    "end": "4016660"
  },
  {
    "text": "We want to essentially minimize\nthe number of labels we assign. ",
    "start": "4016660",
    "end": "4023060"
  },
  {
    "text": "So these problems\nare both very hard. This should build you\nsome more intuition.",
    "start": "4023060",
    "end": "4029540"
  },
  {
    "text": "Let me show you a puzzle\nwhich is basically exactly this game, designed by\nMIT professor Dana Moshkovitz.",
    "start": "4029540",
    "end": "4039100"
  },
  {
    "text": "So here's a word puzzle. Your goal is to put letters\ninto each of these boxes-- this",
    "start": "4039100",
    "end": "4044980"
  },
  {
    "text": "is B, and this is A-- such\nthat-- for example, this",
    "start": "4044980",
    "end": "4050260"
  },
  {
    "text": "is animal, which means\nthese three things pointed by the red arrows, those\nletters should concatenate",
    "start": "4050260",
    "end": "4057410"
  },
  {
    "text": "to form an animal, like cat. Bat is the example.",
    "start": "4057410",
    "end": "4063840"
  },
  {
    "text": "So if I write B, A, and T,\nanimal is satisfied perfectly. Because all three\nletters form a word,",
    "start": "4063840",
    "end": "4071460"
  },
  {
    "text": "I get three points so far. Next let's think\nabout transportation.",
    "start": "4071460",
    "end": "4077290"
  },
  {
    "text": "For example, cab is\na three-letter word that is transportation. Notice there's always\nthree over here. This corresponds to some\nregularity constraint",
    "start": "4077290",
    "end": "4087869"
  },
  {
    "text": "on the bipartite graph. There's always going to be three\narrows going from left to right for every group.",
    "start": "4087870",
    "end": "4096960"
  },
  {
    "text": "So transportation, fine. We got C-A-B. That is happy.",
    "start": "4096960",
    "end": "4102630"
  },
  {
    "text": "We happen to reuse the A,\nso we get three more points, total of six. Furniture, we have\nB, blank, and T left.",
    "start": "4102630",
    "end": "4112219"
  },
  {
    "text": "This is going to\nbe a little harder. I don't know of any\nfurniture that starts with B and ends with T and\nis three letters long.",
    "start": "4112220",
    "end": "4118160"
  },
  {
    "text": "But if you, for example,\nwrite an E here, that's pretty close to the\nword bed, which is furniture.",
    "start": "4118160",
    "end": "4124005"
  },
  {
    "text": "So in general, of course,\neach of these words corresponds to a set\nof English words. That's going to be the\ngroups on the left.",
    "start": "4124005",
    "end": "4132290"
  },
  {
    "text": "So this Ai group\nfor furniture is the set of all words that are\nfurniture and three letters long.",
    "start": "4132290",
    "end": "4139149"
  },
  {
    "text": "And then for each such\nchoice on the left, for each such\nchoice on the right, you can say is,\nare they compatible",
    "start": "4139149",
    "end": "4144978"
  },
  {
    "text": "by either putting\nan edge or not. And so this is-- we got two\nout of three of these edges.",
    "start": "4144978",
    "end": "4152299"
  },
  {
    "text": "These two are satisfied. This one's not. So we get two more points\nfor a total of eight.",
    "start": "4152300",
    "end": "4158099"
  },
  {
    "text": "This is for the\nmaximization problem. Minimization would be different. Here's a verb, where we\nalmost get cry, C-B-Y.",
    "start": "4158099",
    "end": "4167109"
  },
  {
    "text": "So we get two more points. Here is another. We want a verb.",
    "start": "4167109",
    "end": "4172170"
  },
  {
    "text": "Blank, A, Y. There are\nmultiple such verbs. You can think of them.",
    "start": "4172170",
    "end": "4177920"
  },
  {
    "text": "And on the other hand,\nwe have a food, which is supposed to be blank, E,\nY. So a pretty good choice",
    "start": "4177920",
    "end": "4184969"
  },
  {
    "text": "would be P for that top letter. Then you get pay exactly\nand almost get pea. So a total score of 15.",
    "start": "4184970",
    "end": "4192509"
  },
  {
    "text": "And so this would be a\nsolution to Max-Rep of cost 15.",
    "start": "4192510",
    "end": "4198585"
  },
  {
    "text": "It's not the best. And if you stare at this\nexample long enough, you can actually get a perfect\nsolution of score 18, where",
    "start": "4198585",
    "end": "4205630"
  },
  {
    "text": "there are no violations. Basically, in particular you do\nsay here and get soy for food.",
    "start": "4205630",
    "end": "4212440"
  },
  {
    "text": "AUDIENCE: So the sets on\nthe right are 26 letters? PROFESSOR: Yes. The Bis here are the\nalphabet A through Z,",
    "start": "4212440",
    "end": "4219760"
  },
  {
    "text": "and the sets on the\nleft are a set of words. And then you're going to\nconnect two of them by an edge if that letter happens to\nmatch on the right, [INAUDIBLE]",
    "start": "4219760",
    "end": "4230530"
  },
  {
    "text": "letter. So it's a little--\nI mean, the mapping is slightly complicated. But this is a particular\ninstance of Max-Rep.",
    "start": "4230530",
    "end": "4237429"
  },
  {
    "text": " So what-- well, we get\nsome super extreme hardness",
    "start": "4237430",
    "end": "4249430"
  },
  {
    "text": "for these problems. So let's start with epsilon,\ncomma one gap Max-Rep",
    "start": "4249430",
    "end": "4265710"
  },
  {
    "text": "is NP-hard. ",
    "start": "4265710",
    "end": "4276160"
  },
  {
    "text": "So what I mean by this\nis in the best situation, you cover all of\nthe super edges.",
    "start": "4276160",
    "end": "4282860"
  },
  {
    "text": "So the one means 100% of\nthe super edges are covered. Epsilon means that at most\nan epsilon fraction of them",
    "start": "4282860",
    "end": "4288270"
  },
  {
    "text": "are covered. So that problem is NP-hard. This is a bit stronger\nthan what we had before. Before we had a particular\nconstant, comma one or one",
    "start": "4288270",
    "end": "4296270"
  },
  {
    "text": "minus epsilon or something. Here, for any constant\nepsilon, this is true. ",
    "start": "4296270",
    "end": "4303842"
  },
  {
    "text": "And there's a similar\nresult for Min-Rep. It's just from one\nto one over epsilon.",
    "start": "4303842",
    "end": "4309159"
  },
  {
    "text": "So this means there is no\nconstant factor approximation. Max-Rep is not in APX.",
    "start": "4309160",
    "end": "4315490"
  },
  {
    "text": "But it's worse than that. We need to assume slightly more.",
    "start": "4315490",
    "end": "4321580"
  },
  {
    "text": "In general, what you can show,\nif you have some constant, p,",
    "start": "4321580",
    "end": "4328336"
  },
  {
    "text": "or there is a constant p, such\nthat if you can solve this gap",
    "start": "4328336",
    "end": "4338930"
  },
  {
    "text": "problem, one over p to the k,\nso very tiny fraction of things satisfied versus all\nof the super edges",
    "start": "4338930",
    "end": "4345590"
  },
  {
    "text": "covered, then NP can be solved\nin n to the order k time.",
    "start": "4345590",
    "end": "4357340"
  },
  {
    "text": " So we haven't usually\nused this class.",
    "start": "4357340",
    "end": "4364469"
  },
  {
    "text": "Usually we talk about p, which\nis the union of all these for constant k. But here k doesn't\nhave to be a constant.",
    "start": "4364470",
    "end": "4370150"
  },
  {
    "text": "It could be some function of n. And in particular, if\np does not equal NP, then k constant is not possible.",
    "start": "4370150",
    "end": "4377310"
  },
  {
    "text": "So this result\nimplies this result. ",
    "start": "4377310",
    "end": "4383170"
  },
  {
    "text": "But if we let k get bigger\nthan a constant, like log-log n",
    "start": "4383170",
    "end": "4389570"
  },
  {
    "text": "or something, then we get\nsome separation between-- we",
    "start": "4389570",
    "end": "4395570"
  },
  {
    "text": "get a somewhat weaker\nstatement here. We know if p does\nnot equal NP, we know that NP is not contained in p.",
    "start": "4395570",
    "end": "4403000"
  },
  {
    "text": "But if we furthermore\nassume that NP doesn't have subexponential solutions,\nand very subexponential",
    "start": "4403000",
    "end": "4411969"
  },
  {
    "text": "solutions, then we\nget various gap bounds inapproximability on Max-Rep. So a reasonable\nlimit, for example,",
    "start": "4411970",
    "end": "4419920"
  },
  {
    "text": "is that-- let's say we assume\nNP is not in n to the polylog n.",
    "start": "4419920",
    "end": "4433060"
  },
  {
    "text": " n to the polylog n is usually\ncalled quasi-polynomial.",
    "start": "4433060",
    "end": "4439760"
  },
  {
    "text": "It's almost polynomial. Log n is kind of close\nto constant-- ish.",
    "start": "4439760",
    "end": "4444870"
  },
  {
    "text": "This is the same as two to the\npolylog n, n to the polylog n. But it's a little clearer.",
    "start": "4444870",
    "end": "4450070"
  },
  {
    "text": "This is obviously close\nto polynomial, quite far from exponential, which is\ntwo to the n, not polylog.",
    "start": "4450070",
    "end": "4457250"
  },
  {
    "text": "So very different\nfrom exponential. So almost everyone\nbelieves NP does not admit",
    "start": "4457250",
    "end": "4463389"
  },
  {
    "text": "quasi-polynomial solutions. All problems in NP would\nhave to admit that. 3SAT, for example,\npeople don't think",
    "start": "4463390",
    "end": "4468566"
  },
  {
    "text": "you can do better than\nsome constant to the n.  Then what do we get when\nwe plug in that value of k?",
    "start": "4468566",
    "end": "4479030"
  },
  {
    "text": "That there is a no 1/2 to the\nlog to the one minus epsilon",
    "start": "4479030",
    "end": "4487389"
  },
  {
    "text": "n approximation.  Or also, the same\nthing, gap is hard.",
    "start": "4487390",
    "end": "4496080"
  },
  {
    "text": "Now, it's not NP-hard. But it's as hard\nas this problem. If you believe this is\nnot true, then there",
    "start": "4496080",
    "end": "4501210"
  },
  {
    "text": "will be no polynomial\ntime algorithm to solve this\nfactor gap Max-Rep.",
    "start": "4501210",
    "end": "4506530"
  },
  {
    "text": "So this is very large. We've seen this before in\nthis table of various results.",
    "start": "4506530",
    "end": "4512425"
  },
  {
    "text": "Near the bottom, there is a\nlower bound of two to the log to one minus epsilon n. This is not assuming\np does not equal NP.",
    "start": "4512425",
    "end": "4518630"
  },
  {
    "text": "It's assuming this\nstatement, NP does not have quasi-polynomial\nalgorithms. And you see here\nour friends Max-Rep",
    "start": "4518630",
    "end": "4525099"
  },
  {
    "text": "and Min-Rep, two\nversions of label cover. So I'm not going to\nprove these theorems.",
    "start": "4525100",
    "end": "4532690"
  },
  {
    "text": "But again, they're\nPCP style arguments with some gap boosting.",
    "start": "4532690",
    "end": "4538890"
  },
  {
    "text": "But I would say most or a\nlot of approximation lower bounds in s world today\nstart from Max-Rep or Min-Rep",
    "start": "4538890",
    "end": "4547900"
  },
  {
    "text": "and reduce to the problem\nusing usually some kind of gap-preserving reduction. Maybe they lose the gap,\nbut we have such a huge gap",
    "start": "4547900",
    "end": "4555020"
  },
  {
    "text": "to start with that\neven if you lose gap, you still get\npretty good results. So a couple of quick\nexamples here on the slides.",
    "start": "4555020",
    "end": "4563150"
  },
  {
    "text": "Directed Steiner forest. Remember, you have\na directed graph, and you have a bunch\nof terminal pairs.",
    "start": "4563150",
    "end": "4570360"
  },
  {
    "text": "And you want to, in particular,\nconnect via directed path some Ais and Bjs, let's say.",
    "start": "4570360",
    "end": "4577989"
  },
  {
    "text": "And you want to do so by\nchoosing the fewest vertices in this graph.",
    "start": "4577990",
    "end": "4583469"
  },
  {
    "text": "So what I'm going to do, if I'm\ngiven my bipartite graph here for Min-Rep, I'm\njust going to add--",
    "start": "4583470",
    "end": "4589904"
  },
  {
    "text": "to represent that\nthis is a group, I'm going to add a vertex here\nconnect by directed edges here. And there's a group\ndown here, so I'm",
    "start": "4589904",
    "end": "4595870"
  },
  {
    "text": "going to have downward\nedges down there. And whenever there's a\nsuper edge from, say, A2, capital A2 to\ncapital B1, then",
    "start": "4595870",
    "end": "4603980"
  },
  {
    "text": "I'm going to say in my directed\nSteiner forest problem, I want a path from\nlittle a2 to little b1.",
    "start": "4603980",
    "end": "4609926"
  },
  {
    "text": "So in general, whenever\nthere's a super edge, I add that constraint. And then any solution to\ndirected Steiner forest",
    "start": "4609926",
    "end": "4616020"
  },
  {
    "text": "will exactly be a\nsolution to Min-Rep. You're just forcing the\naddition of the Ais and Bis.",
    "start": "4616020",
    "end": "4622039"
  },
  {
    "text": "It's again an L-reduction. You're just offsetting by\na fixed additive amount. So your gap OPT\nwill be the same.",
    "start": "4622040",
    "end": "4627791"
  },
  {
    "text": "And so you get that this problem\nis just as hard as Min-Rep. ",
    "start": "4627791",
    "end": "4635870"
  },
  {
    "text": "Well, this is another\none from set cover. You can also show node\nweighted Steiner trees.",
    "start": "4635870",
    "end": "4640950"
  },
  {
    "text": "Log n hard to approximate. That's not from Min-Rep,\nbut threw it in there while we're on the\ntopic of Steiner trees.",
    "start": "4640950",
    "end": "4647661"
  },
  {
    "text": "All right. I want to mention one\nmore thing quickly in my zero minutes remaining.",
    "start": "4647661",
    "end": "4653005"
  },
  {
    "start": "4653005",
    "end": "4665530"
  },
  {
    "text": "And that is unique games. ",
    "start": "4665530",
    "end": "4674500"
  },
  {
    "text": "So unique games is a\nspecial case of, say, Max-Rep, or either label cover\nproblem, where the edges in Ai",
    "start": "4674500",
    "end": "4688920"
  },
  {
    "text": "cross Bj form a matching. ",
    "start": "4688920",
    "end": "4697780"
  },
  {
    "text": "For every choice in\nthe left, there's a unique choice on the right\nand vice versa that matches.",
    "start": "4697780",
    "end": "4705120"
  },
  {
    "text": "Well, there's at most\none choice, I guess. And I think that\ncorresponds to these games.",
    "start": "4705120",
    "end": "4710960"
  },
  {
    "text": "Once you choose\na word over here, there's unique\nletter that matches. The reverse is not true.",
    "start": "4710960",
    "end": "4716180"
  },
  {
    "text": "So in this problem,\nit's more like a star, left to right star. Once you choose this\nword, it's fixed",
    "start": "4716180",
    "end": "4721980"
  },
  {
    "text": "what you have to choose\non the right side. But if you choose a\nsingle letter over here, it does not uniquely\ndetermine the word over here.",
    "start": "4721980",
    "end": "4727650"
  },
  {
    "text": "So unique games is\nquite a bit stronger. You choose either side,\nit forces the other one, if you want to cover that edge.",
    "start": "4727650",
    "end": "4734639"
  },
  {
    "text": "OK So far so good. Unique games conjecture is that\nthe special case is also hard.",
    "start": "4734640",
    "end": "4743750"
  },
  {
    "text": "Unique games conjecture is that\nepsilon one minus epsilon gap",
    "start": "4743750",
    "end": "4754190"
  },
  {
    "text": "unique game is NP-hard. Of course, there\nare weaker versions",
    "start": "4754190",
    "end": "4759950"
  },
  {
    "text": "of this conjecture\nthat don't say NP-hard, maybe assuming some weaker\nassumption that there's no polynomial time algorithm.",
    "start": "4759950",
    "end": "4767350"
  },
  {
    "text": "Unlike every other complexity\ntheoretic assumption I have mentioned in\nthis class, this one is the subject of much debate.",
    "start": "4767350",
    "end": "4773600"
  },
  {
    "text": "Not everyone believes\nthat it's true. Some people believe\nthat it's false. Many people believe--\nbasically people don't know",
    "start": "4773600",
    "end": "4780300"
  },
  {
    "text": "is the short answer. There's some somewhat scary\nevidence that it's not true. There's slightly stronger forms\nof this that are definitely not",
    "start": "4780300",
    "end": "4787710"
  },
  {
    "text": "true, which I won't get into. There is a subexponential\nalgorithm for this problem.",
    "start": "4787710",
    "end": "4793100"
  },
  {
    "text": "But it's still up in the air. A lot of people like to\nassume that this is true",
    "start": "4793100",
    "end": "4798750"
  },
  {
    "text": "because it makes life\na lot more beautiful, especially from an\ninapproximability standpoint.",
    "start": "4798750",
    "end": "4805390"
  },
  {
    "text": "So for example, MAX-2SAT, the\nbest approximation algorithm is 0.940.",
    "start": "4805390",
    "end": "4811081"
  },
  {
    "text": "If you assume that\nunique games, you can prove a matching\nlower bound. That was MAX-2SAT for\nMAX-CUT, as was mentioned,",
    "start": "4811081",
    "end": "4817770"
  },
  {
    "text": "0.878 is the best upper\nbound by Goemans Williamson.",
    "start": "4817770",
    "end": "4822990"
  },
  {
    "text": "If you assume unique games,\nthen that's also tight. There's a matching\nthis minus epsilon or plus epsilon\ninapproximability result.",
    "start": "4822990",
    "end": "4833330"
  },
  {
    "text": "And vertex cover, two. You probably know how to do two. If you assume unique games,\ntwo is the right answer.",
    "start": "4833330",
    "end": "4841060"
  },
  {
    "text": "If you don't assume\nanything, the best we know how to prove\nusing all of this stuff is 0.857 versus 0.5.",
    "start": "4841060",
    "end": "4851400"
  },
  {
    "text": "So it's nice to assume\nunique games is true.",
    "start": "4851400",
    "end": "4856449"
  },
  {
    "text": "Very cool results is if you look\nat over all the different CSP problems that we've seen,\nall the MAX-CSP problems,",
    "start": "4856450",
    "end": "4863030"
  },
  {
    "text": "and you try to solve it\nusing a particular kind of semi-definite programming,\nthere's an STP relaxation.",
    "start": "4863030",
    "end": "4870489"
  },
  {
    "text": "If you don't know STPs,\nignore this sentence. There's an STP relaxation\nof all CSP problems.",
    "start": "4870490",
    "end": "4875940"
  },
  {
    "text": "You do the obvious thing. And that STP will have\nan integrality gap.",
    "start": "4875940",
    "end": "4881240"
  },
  {
    "text": "And if you believe\nunique games conjecture, then that integrality gap equals\nthe approximability factor,",
    "start": "4881240",
    "end": "4887670"
  },
  {
    "text": "one for one. And so in this sense, if\nyou're trying to solve any CSP problem, semi-definite\nprogramming",
    "start": "4887670",
    "end": "4892809"
  },
  {
    "text": "is the ultimate tool for all\napproximation algorithms. Because if there's\na gap in the STP,",
    "start": "4892810",
    "end": "4899500"
  },
  {
    "text": "you can prove an\ninapproximability result of that minus epsilon. So this is amazingly powerful.",
    "start": "4899500",
    "end": "4904682"
  },
  {
    "text": "The only catch is, we don't\nknow whether unique games conjecture is true. And for that reason, I'm not\ngoing to spend more time on it.",
    "start": "4904682",
    "end": "4911080"
  },
  {
    "text": "But this gives you a flavor of\nthis side of the field, the gap",
    "start": "4911080",
    "end": "4916180"
  },
  {
    "text": "preservation approximation. Any final questions?",
    "start": "4916180",
    "end": "4922283"
  },
  {
    "text": "Yeah. AUDIENCE: If there's a\n[INAUDIBLE] algorithm [INAUDIBLE]? ",
    "start": "4922284",
    "end": "4929550"
  },
  {
    "text": "PROFESSOR: It's\nfine for a problem to be slightly subexponential.",
    "start": "4929550",
    "end": "4935570"
  },
  {
    "text": "It's like two to the n to\nthe epsilon or something. So when you do an\nNP reduction, you",
    "start": "4935570",
    "end": "4942600"
  },
  {
    "text": "can blow things up by\na polynomial factor. And so that n to the\nepsilon becomes n again.",
    "start": "4942600",
    "end": "4948000"
  },
  {
    "text": "So if you start\nfrom 3SAT where we don't believe there's a\nsubexponential thing, when you",
    "start": "4948000",
    "end": "4953600"
  },
  {
    "text": "reduce to this, you\nmight end up putting it-- you lose that polynomial factor.",
    "start": "4953600",
    "end": "4958870"
  },
  {
    "text": "And so it's not a contradiction. A bit subtle. ",
    "start": "4958870",
    "end": "4965840"
  },
  {
    "text": "Cool. See you Thursday. ",
    "start": "4965840",
    "end": "4973435"
  }
]
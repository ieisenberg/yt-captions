[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6910"
  },
  {
    "text": "offer high-quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "6910",
    "end": "13460"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at",
    "start": "13460",
    "end": "19290"
  },
  {
    "text": "ocw.mit.edu.  PROFESSOR: OK so let's start.",
    "start": "19290",
    "end": "26289"
  },
  {
    "text": "So today, we're going\nto continue the subject from last time. And the subject is\nrandom variables.",
    "start": "26290",
    "end": "32619"
  },
  {
    "text": "As we discussed, random\nvariables basically associate numerical values with the\noutcomes of an experiment.",
    "start": "32619",
    "end": "39550"
  },
  {
    "text": "And we want to learn how\nto manipulate them. Now to a large extent, what's\ngoing to happen, what's",
    "start": "39550",
    "end": "45890"
  },
  {
    "text": "happening during this chapter,\nis that we are revisiting the same concepts we have\nseen in chapter one.",
    "start": "45890",
    "end": "53219"
  },
  {
    "text": "But we're going to introduce\na lot of new notation, but really dealing with the\nsame kind of stuff.",
    "start": "53220",
    "end": "60210"
  },
  {
    "text": "The only difference where we\ngo beyond the new notation,",
    "start": "60210",
    "end": "65500"
  },
  {
    "text": "the new concept in this chapter\nis the concept of the expectation or expected\nvalues. And we're going to learn how\nto manipulate expectations.",
    "start": "65500",
    "end": "74010"
  },
  {
    "text": "So let us start with a quick\nreview of what we discussed last time.",
    "start": "74010",
    "end": "79610"
  },
  {
    "text": "We talked about random\nvariables. Loosely speaking, random\nvariables are random",
    "start": "79610",
    "end": "85860"
  },
  {
    "text": "quantities that result\nfrom an experiment. More precisely speaking,\nmathematically speaking, a",
    "start": "85860",
    "end": "91950"
  },
  {
    "text": "random variable is a function\nfrom the sample space to the real numbers. That is, you give me an outcome,\nand based on that",
    "start": "91950",
    "end": "99370"
  },
  {
    "text": "outcome, I can tell you the\nvalue of the random variable. So the value of the random\nvariable is a function of the",
    "start": "99370",
    "end": "105750"
  },
  {
    "text": "outcome that we have. Now given a random variable,\nsome of the numerical outcomes",
    "start": "105750",
    "end": "111170"
  },
  {
    "text": "are more likely than others. And we want to say which ones\nare more likely and how likely they are.",
    "start": "111170",
    "end": "117420"
  },
  {
    "text": "And the way we do that is by\nwriting down the probabilities of the different possible\nnumerical outcomes.",
    "start": "117420",
    "end": "124030"
  },
  {
    "text": "Notice here, the notation. We use uppercase to denote\nthe random variable. We use lowercase to denote\nreal numbers.",
    "start": "124030",
    "end": "131840"
  },
  {
    "text": "So the way you read this, this\nis the probability that the random variable, capital X,\nhappens to take the numerical",
    "start": "131840",
    "end": "140160"
  },
  {
    "text": "value, little x. This is a concept that's\nfamiliar from chapter one.",
    "start": "140160",
    "end": "145780"
  },
  {
    "text": "And this is just the new\nnotation we will be using for that concept. It's the Probability Mass\nFunction of the random",
    "start": "145780",
    "end": "153690"
  },
  {
    "text": "variable, capital X. So the\nsubscript just indicates which random variable we're\ntalking about.",
    "start": "153690",
    "end": "160190"
  },
  {
    "text": "And it's the probability\nassigned to a particular outcome.",
    "start": "160190",
    "end": "165300"
  },
  {
    "text": "And we want to assign such\nprobabilities for all possibly numerical values. So you can think of this as\nbeing a function of little x.",
    "start": "165300",
    "end": "172689"
  },
  {
    "text": "And it tells you how likely\nevery little x is going to be. Now the new concept we\nintroduced last time is the",
    "start": "172690",
    "end": "179310"
  },
  {
    "text": "concept of the expected value\nfor random variable, which is defined this way. You look at all the\npossible outcomes.",
    "start": "179310",
    "end": "186870"
  },
  {
    "text": "And you form some kind of\naverage of all the possible numerical values over the random\nvariable capital X. You",
    "start": "186870",
    "end": "195000"
  },
  {
    "text": "consider all the possible\nnumerical values, and you form an average. In fact, it's a weighted average\nwhere, to every little",
    "start": "195000",
    "end": "203160"
  },
  {
    "text": "x, you assign a weight equal to\nthe probability that that particular little x is\ngoing to be realized.",
    "start": "203160",
    "end": "210190"
  },
  {
    "text": " Now, as we discussed last time,\nif you have a random",
    "start": "210190",
    "end": "218099"
  },
  {
    "text": "variable, you can take a\nfunction of a random variable. And that's going to be a\nnew random variable.",
    "start": "218100",
    "end": "223860"
  },
  {
    "text": "So if capital X is a random\nvariable and g is a function, g of X is a new random\nvariable.",
    "start": "223860",
    "end": "231920"
  },
  {
    "text": "You do the experiment. You get an outcome. This determines the value of\nX. And that determines the",
    "start": "231920",
    "end": "236950"
  },
  {
    "text": "value of g of X. So the numerical value of g of\nX is determined by whatever happens in the experiment.",
    "start": "236950",
    "end": "243329"
  },
  {
    "text": "It's random. And that makes it a\nrandom variable. Since it's a random variable,\nit has an",
    "start": "243330",
    "end": "249040"
  },
  {
    "text": "expectation of its own. So how would we calculate the\nexpectation of g of X?",
    "start": "249040",
    "end": "254860"
  },
  {
    "text": "You could proceed by just using\nthe definition, which would require you to find the\nPMF of the random variable g",
    "start": "254860",
    "end": "263169"
  },
  {
    "text": "of X. So find the PMF of g of X,\nand then apply the formula",
    "start": "263170",
    "end": "269480"
  },
  {
    "text": "for the expected value\nof a random variable with known PMF. But there is also a shortcut,\nwhich is just a different way",
    "start": "269480",
    "end": "276819"
  },
  {
    "text": "of doing the counting and the\ncalculations, in which we do not need to find the PMF of g\nof X. We just work with the",
    "start": "276820",
    "end": "284580"
  },
  {
    "text": "PMF of the original\nrandom variable. And what this is saying is that\nthe average value of g of",
    "start": "284580",
    "end": "290010"
  },
  {
    "text": "X is obtained as follows. You look at all the possible\nresults, the X's,",
    "start": "290010",
    "end": "295020"
  },
  {
    "text": "how likely they are. And when that particular\nX happens, this is how much you get.",
    "start": "295020",
    "end": "301470"
  },
  {
    "text": "And so this way, you add\nthese things up. And you get the average amount\nthat you're going to get, the",
    "start": "301470",
    "end": "310310"
  },
  {
    "text": "average value of g of X, where\nyou average over the likelihoods of the\ndifferent X's.",
    "start": "310310",
    "end": "316130"
  },
  {
    "text": "Now expected values have some\nproperties that are always true and some properties that\nsometimes are not true.",
    "start": "316130",
    "end": "323570"
  },
  {
    "text": "So the property that is not\nalways true is that this would be the same as g of the expected\nvalue of X. So in",
    "start": "323570",
    "end": "334400"
  },
  {
    "text": "general, this is not true. You cannot interchange function\nand expectation,",
    "start": "334400",
    "end": "340260"
  },
  {
    "text": "which means you cannot reason\non the average, in general. But there are some exceptions.",
    "start": "340260",
    "end": "345780"
  },
  {
    "text": "When g is a linear function,\nthen the expected value for a linear function is the same as\nthat same linear function of",
    "start": "345780",
    "end": "353460"
  },
  {
    "text": "the expectation. So for linear functions, so\nfor random variable, the expectation behaves nicely.",
    "start": "353460",
    "end": "360010"
  },
  {
    "text": "So this is basically telling you\nthat, if X is degrees in",
    "start": "360010",
    "end": "365320"
  },
  {
    "text": "Celsius, alpha X plus b is\ndegrees in Fahrenheit, you can first do the conversion\nto Fahrenheit",
    "start": "365320",
    "end": "372030"
  },
  {
    "text": "and take the average. Or you can find the average\ntemperature in Celsius, and then do the conversion\nto Fahrenheit.",
    "start": "372030",
    "end": "381270"
  },
  {
    "text": "Either is valid. So the expected value tells us\nsomething about where is the",
    "start": "381270",
    "end": "387370"
  },
  {
    "text": "center of the distribution, more\nspecifically, the center of mass or the center of gravity\nof the PMF, when you",
    "start": "387370",
    "end": "394360"
  },
  {
    "text": "plot it as a bar graph. Besides the average value, you\nmay be interested in knowing",
    "start": "394360",
    "end": "399880"
  },
  {
    "text": "how far will you be from\nthe average, typically.",
    "start": "399880",
    "end": "405810"
  },
  {
    "text": "So let's look at this quantity,\nX minus expected value of X. This is the distance from\nthe average value.",
    "start": "405810",
    "end": "413620"
  },
  {
    "text": "So for a random outcome of the\nexperiment, this quantity in here measures how far\naway from the mean",
    "start": "413620",
    "end": "421260"
  },
  {
    "text": "you happen to be. This quantity inside the\nbrackets is a random variable.",
    "start": "421260",
    "end": "428330"
  },
  {
    "text": "Why? Because capital X is random. And what we have here is capital\nX, which is random,",
    "start": "428330",
    "end": "435910"
  },
  {
    "text": "minus a number. Remember, expected values\nare numbers. Now a random variable\nminus a number is",
    "start": "435910",
    "end": "442340"
  },
  {
    "text": "a new random variable. It has an expectation\nof its own. We can use the linearity rule,\nexpected value of something",
    "start": "442340",
    "end": "450600"
  },
  {
    "text": "minus something else is just\nthe difference of their expected value.",
    "start": "450600",
    "end": "456120"
  },
  {
    "text": "So it's going to be expected\nvalue of X minus the expected value over this thing.",
    "start": "456120",
    "end": "462290"
  },
  {
    "text": "Now this thing is a number. And the expected value\nof a number is just the number itself.",
    "start": "462290",
    "end": "468710"
  },
  {
    "text": "So we get from here that this\nis expected value minus expected value. And we get zero.",
    "start": "468710",
    "end": "475510"
  },
  {
    "text": "What is this telling us? That, on the average, the\nassigned difference from the",
    "start": "475510",
    "end": "482690"
  },
  {
    "text": "mean is equal to zero. That is, the mean is here. Sometimes X will fall\nto the right.",
    "start": "482690",
    "end": "488850"
  },
  {
    "text": "Sometimes X will fall\nto the left. On the average, the average\ndistance from the mean is",
    "start": "488850",
    "end": "496169"
  },
  {
    "text": "going to be zero, because\nsometimes the realized distance will be positive,\nsometimes it will be negative.",
    "start": "496170",
    "end": "501950"
  },
  {
    "text": "Positives and negatives\ncancel out. So if we want to capture the\nidea of how far are we from",
    "start": "501950",
    "end": "508139"
  },
  {
    "text": "the mean, just looking at the\nassigned distance from the mean is not going to give us\nany useful information.",
    "start": "508140",
    "end": "516789"
  },
  {
    "text": "So if we want to say something\nabout how far we are, typically, we should do\nsomething different.",
    "start": "516789",
    "end": "523120"
  },
  {
    "text": "One possibility might be to take\nthe absolute values of the differences.",
    "start": "523120",
    "end": "529520"
  },
  {
    "text": "And that's a quantity that\nsometimes people are interested in. But it turns out that a more\nuseful quantity happens to be",
    "start": "529520",
    "end": "538540"
  },
  {
    "text": "the variance of a random\nvariable, which actually measures the average squared\ndistance from the mean.",
    "start": "538540",
    "end": "547030"
  },
  {
    "text": "So you have a random outcome,\nrandom results, random numerical value of the\nrandom variable.",
    "start": "547030",
    "end": "554130"
  },
  {
    "text": "It is a certain distance\naway from the mean. That certain distance\nis random.",
    "start": "554130",
    "end": "559390"
  },
  {
    "text": "We take the square of that. This is the squared distance\nfrom the mean, which is again random.",
    "start": "559390",
    "end": "564750"
  },
  {
    "text": "Since it's random, it has an\nexpected value of its own. And that expected value, we call\nit the variance of X. And",
    "start": "564750",
    "end": "572000"
  },
  {
    "text": "so we have this particular\ndefinition. Using the rule that we have up\nhere for how to calculate",
    "start": "572000",
    "end": "579500"
  },
  {
    "text": "expectations of functions\nof a random variable, why does that apply?",
    "start": "579500",
    "end": "584820"
  },
  {
    "text": "Well, what we have inside the\nbrackets here is a function of the random variable, capital X.\nSo we can apply this rule",
    "start": "584820",
    "end": "592850"
  },
  {
    "text": "where g is this particular\nfunction. And we can use that to calculate\nthe variance,",
    "start": "592850",
    "end": "598540"
  },
  {
    "text": "starting with the PMF of the\nrandom variable X. And then we have a useful formula that's a\nnice shortcut, sometimes, if",
    "start": "598540",
    "end": "605199"
  },
  {
    "text": "you want to do the\ncalculation. Now one thing that's slightly\nwrong with the variance is",
    "start": "605200",
    "end": "611339"
  },
  {
    "text": "that the units are not right, if\nyou want to talk about the spread a of a distribution.",
    "start": "611340",
    "end": "616930"
  },
  {
    "text": "Suppose that X is a random\nvariable measured in meters. The variance will have the\nunits of meters squared.",
    "start": "616930",
    "end": "626170"
  },
  {
    "text": "So it's a kind of a\ndifferent thing. If you want to talk about the\nspread of the distribution using the same units as you have\nfor X, it's convenient to",
    "start": "626170",
    "end": "635210"
  },
  {
    "text": "take the square root\nof the variance. And that's something\nthat we define. And we call it to the standard\ndeviation of X, or the",
    "start": "635210",
    "end": "642980"
  },
  {
    "text": "standard deviation of the\ndistribution of X. So it tells you the amount of spread\nin your distribution.",
    "start": "642980",
    "end": "649510"
  },
  {
    "text": "And it is in the same units as\nthe random variable itself that you are dealing with. ",
    "start": "649510",
    "end": "657260"
  },
  {
    "text": "And we can just illustrate\nthose quantities with an",
    "start": "657260",
    "end": "662500"
  },
  {
    "text": "example that's about as\nsimple as it can be. So consider the following\nexperiment.",
    "start": "662500",
    "end": "668570"
  },
  {
    "text": "You're going to go from\nhere to New York, let's say, 200 miles. And you have two alternatives.",
    "start": "668570",
    "end": "675500"
  },
  {
    "text": "Either you'll get your private\nplane and go at a speed of 200",
    "start": "675500",
    "end": "680640"
  },
  {
    "text": "miles per hour, constant speed\nduring your trip, or",
    "start": "680640",
    "end": "687690"
  },
  {
    "text": "otherwise, you'll decide to walk\nreally, really slowly, at the leisurely pace of\none mile per hour.",
    "start": "687690",
    "end": "695120"
  },
  {
    "text": "So you pick the speed at\nrandom by doing this experiment, by flipping\na coin. And with probability one-half,\nyou do one thing.",
    "start": "695120",
    "end": "701510"
  },
  {
    "text": "With probably one-half, you\ndo the other thing. So your V is a random\nvariable.",
    "start": "701510",
    "end": "707889"
  },
  {
    "text": "In case you're interested in\nhow much time it's going to take you to get there, well,\ntime is equal to distance",
    "start": "707890",
    "end": "714970"
  },
  {
    "text": "divided by speed. So that's the formula. The time itself is a random\nvariable, because it's a",
    "start": "714970",
    "end": "721660"
  },
  {
    "text": "function of V, which\nis random. How much time it's going to take\nyou depends on the coin flip that you do in the\nbeginning to decide what speed",
    "start": "721660",
    "end": "729270"
  },
  {
    "text": "you are going to have. OK, just as a warm up, the\ntrivial calculations.",
    "start": "729270",
    "end": "735110"
  },
  {
    "text": "To find the expected value of\nV, you argue as follows. With probability one-half,\nV is going to be one.",
    "start": "735110",
    "end": "741730"
  },
  {
    "text": "And with probability one-half,\nV is going to be 200. And so the expected value\nof your speed is 100.5.",
    "start": "741730",
    "end": "751410"
  },
  {
    "text": "If you wish to calculate the\nvariance of V, then you argue as follows.",
    "start": "751410",
    "end": "756420"
  },
  {
    "text": "With probability one-half, I'm\ngoing to travel at the speed of one, whereas, the\nmean is 100.5.",
    "start": "756420",
    "end": "765920"
  },
  {
    "text": "So this is the distance from\nthe mean, if I decide to travel at the speed of one. We take that distance from\nthe mean squared.",
    "start": "765920",
    "end": "772920"
  },
  {
    "text": "That's one contribution\nto the variance. And with probability one-half,\nyou're going to travel at the",
    "start": "772920",
    "end": "779220"
  },
  {
    "text": "speed of 200, which is this\nmuch away from the mean.",
    "start": "779220",
    "end": "785610"
  },
  {
    "text": "You take the square of that. OK, so approximately how\nbig is this number?",
    "start": "785610",
    "end": "792360"
  },
  {
    "text": "Well, this is roughly\n100 squared. That's also 100 squared. So approximately, the variance\nof this random",
    "start": "792360",
    "end": "800760"
  },
  {
    "text": "variable is 100 squared. Now if I tell you that the\nvariance of this distribution",
    "start": "800760",
    "end": "808090"
  },
  {
    "text": "is 10,000, it doesn't\nreally help you to relate it to this diagram.",
    "start": "808090",
    "end": "813600"
  },
  {
    "text": "Whereas, the standard deviation,\nwhere you take the square root, is more\ninteresting.",
    "start": "813600",
    "end": "818850"
  },
  {
    "text": "It's the square root of 100\nsquared, which is a 100. And the standard deviation,\nindeed, gives us a sense of",
    "start": "818850",
    "end": "828320"
  },
  {
    "text": "how spread out this distribution\nis from the mean. So the standard deviation\nbasically gives us some",
    "start": "828320",
    "end": "837440"
  },
  {
    "text": "indication about this spacing\nthat we have here. It tells us the amount of spread\nin our distribution.",
    "start": "837440",
    "end": "843950"
  },
  {
    "text": " OK, now let's look at what\nhappens to time.",
    "start": "843950",
    "end": "852110"
  },
  {
    "text": "V is a random variable. T is a random variable.",
    "start": "852110",
    "end": "857339"
  },
  {
    "text": "So now let's look at the\nexpected values and all of that for the time.",
    "start": "857340",
    "end": "863730"
  },
  {
    "text": "OK, so the time is a function\nof a random variable.",
    "start": "863730",
    "end": "869250"
  },
  {
    "text": "We can find the expected time\nby looking at all possible outcomes of the experiment, the\nV's, weigh them according",
    "start": "869250",
    "end": "877030"
  },
  {
    "text": "to their probabilities, and for\neach particular V, keep track of how much\ntime it took us.",
    "start": "877030",
    "end": "882880"
  },
  {
    "text": "So if V is one, which happens\nwith probability one-half, the",
    "start": "882880",
    "end": "888760"
  },
  {
    "text": "time it takes is going\nto be 200. If we travel at speed of one,\nit takes us 200 time units.",
    "start": "888760",
    "end": "896410"
  },
  {
    "text": "And otherwise, if our speed is\nequal to 200, the time is one.",
    "start": "896410",
    "end": "901560"
  },
  {
    "text": "So the expected value of T is\nonce more the same as before. It's 100.5.",
    "start": "901560",
    "end": "909740"
  },
  {
    "text": "So the expected speed\nis 100.5. The expected time\nis also 100.5.",
    "start": "909740",
    "end": "919320"
  },
  {
    "text": "So the product of these\nexpectations is something like 10,000.",
    "start": "919320",
    "end": "924350"
  },
  {
    "text": "How about the expected value\nof the product of T and V? Well, T times V is 200.",
    "start": "924350",
    "end": "932459"
  },
  {
    "text": "No matter what outcome you have\nin the experiment, in",
    "start": "932460",
    "end": "937790"
  },
  {
    "text": "that particular outcome, T\ntimes V is total distance traveled, which is\nexactly 200.",
    "start": "937790",
    "end": "945660"
  },
  {
    "text": "And so what do we get in this\nsimple example is that the expected value of the product of\nthese two random variables",
    "start": "945660",
    "end": "953550"
  },
  {
    "text": "is different than the product\nof their expected values. This is one more instance\nof where we cannot",
    "start": "953550",
    "end": "961120"
  },
  {
    "text": "reason on the average. So on the average, over a large\nnumber of trips, your",
    "start": "961120",
    "end": "968190"
  },
  {
    "text": "average time would be 100. On the average, over a large\nnumber of trips, your average",
    "start": "968190",
    "end": "973570"
  },
  {
    "text": "speed would be 100. But your average distance\ntraveled is not 100 times 100.",
    "start": "973570",
    "end": "980740"
  },
  {
    "text": "It's something else. So you cannot reason on the\naverage, whenever you're",
    "start": "980740",
    "end": "986850"
  },
  {
    "text": "dealing with non-linear\nthings. And the non-linear thing here\nis that you have a function which is a product of stuff,\nas opposed to just",
    "start": "986850",
    "end": "994740"
  },
  {
    "text": "linear sums of stuff. Another way to look at what's\nhappening here is the expected",
    "start": "994740",
    "end": "1002530"
  },
  {
    "text": "value of the time. Time, by definition, is\n200 over the speed. Expected value of the time, we\nfound it to be about a 100.",
    "start": "1002530",
    "end": "1012100"
  },
  {
    "text": "And so expected value of 200\nover V is about a 100.",
    "start": "1012100",
    "end": "1022800"
  },
  {
    "text": "But it's different from this\nquantity here, which is roughly equal to\n2, and so 200.",
    "start": "1022800",
    "end": "1033119"
  },
  {
    "text": "Expected value of\nV is about 100. So this quantity is about\nequal to two.",
    "start": "1033119",
    "end": "1039030"
  },
  {
    "text": "Whereas, this quantity\nup here is about 100. So what do we have here? We have a non-linear function\nof V. And we find that the",
    "start": "1039030",
    "end": "1046959"
  },
  {
    "text": "expected value of this function\nis not the same thing as the function of the\nexpected value.",
    "start": "1046960",
    "end": "1054390"
  },
  {
    "text": "So again, that's an instance\nwhere you cannot interchange expected values and functions.",
    "start": "1054390",
    "end": "1060820"
  },
  {
    "text": "And that's because things\nare non-linear. ",
    "start": "1060820",
    "end": "1066120"
  },
  {
    "text": "OK, so now let us introduce\na new concept.",
    "start": "1066120",
    "end": "1071730"
  },
  {
    "text": "Or maybe it's not quite\na new concept. So we discussed, in chapter\none, that we have",
    "start": "1071730",
    "end": "1078570"
  },
  {
    "text": "probabilities. We also have conditional\nprobabilities. What's the difference\nbetween them?",
    "start": "1078570",
    "end": "1085250"
  },
  {
    "text": "Essentially, none. Probabilities are just an\nassignment of probability values to give different\noutcomes, given",
    "start": "1085250",
    "end": "1091650"
  },
  {
    "text": "a particular model. Somebody comes and gives\nyou new information. So you come up with\na new model.",
    "start": "1091650",
    "end": "1098370"
  },
  {
    "text": "And you have a new\nprobabilities. We call these conditional\nprobabilities, but they taste and behave exactly the same\nas ordinary probabilities.",
    "start": "1098370",
    "end": "1107230"
  },
  {
    "text": "So since we can have conditional\nprobabilities, why not have conditional PMFs as\nwell, since PMFs deal with",
    "start": "1107230",
    "end": "1115020"
  },
  {
    "text": "probabilities anyway. So we have a random variable,\ncapital X. It has",
    "start": "1115020",
    "end": "1120520"
  },
  {
    "text": "a PMF of its own. For example, it could be the PMF\nin this picture, which is",
    "start": "1120520",
    "end": "1126810"
  },
  {
    "text": "a uniform PMF that takes for\npossible different values.",
    "start": "1126810",
    "end": "1132160"
  },
  {
    "text": "And we also have an event. And somebody comes\nand tells us that",
    "start": "1132160",
    "end": "1137240"
  },
  {
    "text": "this event has occurred. The PMF tells you the\nprobability that capital X",
    "start": "1137240",
    "end": "1142700"
  },
  {
    "text": "equals to some little x. Somebody tells you that a\ncertain event has occurred",
    "start": "1142700",
    "end": "1148929"
  },
  {
    "text": "that's going to make you change\nthe probabilities that you assign to the different\nvalues.",
    "start": "1148930",
    "end": "1154690"
  },
  {
    "text": "You are going to use conditional\nprobabilities. So this part, it's clear what\nit means from chapter one.",
    "start": "1154690",
    "end": "1160880"
  },
  {
    "text": "And this part is just the new\nnotation we're using in this chapter to talk about\nconditional probabilities.",
    "start": "1160880",
    "end": "1168380"
  },
  {
    "text": "So this is just a definition. So the conditional PMF\nis an ordinary PMF.",
    "start": "1168380",
    "end": "1175010"
  },
  {
    "text": "But it's the PMF that applies\nto a new model in which we have been given some information\nabout the outcome",
    "start": "1175010",
    "end": "1182480"
  },
  {
    "text": "of the experiment. So to make it concrete, consider\nthis event here.",
    "start": "1182480",
    "end": "1187559"
  },
  {
    "text": "Take the event that capital\nX is bigger than or equal to two. In the picture, what\nis the event A?",
    "start": "1187560",
    "end": "1194490"
  },
  {
    "text": "The event A consists of\nthese three outcomes. ",
    "start": "1194490",
    "end": "1200470"
  },
  {
    "text": "OK, what is the conditional PMF,\ngiven that we are told that event A has occurred?",
    "start": "1200470",
    "end": "1208920"
  },
  {
    "text": "Given that the event A has\noccurred, it basically tells us that this outcome\nhas not occurred.",
    "start": "1208920",
    "end": "1215390"
  },
  {
    "text": "There's only three possible\noutcomes now. In the new universe, in the new\nmodel where we condition",
    "start": "1215390",
    "end": "1221350"
  },
  {
    "text": "on A, there's only three\npossible outcomes. Those three possible outcomes\nwere equally likely when we started.",
    "start": "1221350",
    "end": "1227660"
  },
  {
    "text": "So in the conditional universe,\nthey will remain equally likely. Remember, whenever you\ncondition, the relative",
    "start": "1227660",
    "end": "1234230"
  },
  {
    "text": "likelihoods remain the same. They keep the same\nproportions. They just need to be\nre-scaled, so that",
    "start": "1234230",
    "end": "1240860"
  },
  {
    "text": "they add up to one. So each one of these will have\nthe same probability.",
    "start": "1240860",
    "end": "1246380"
  },
  {
    "text": "Now in the new world,\nprobabilities need to add up to 1. So each one of them is going to\nget a probability of 1/3 in",
    "start": "1246380",
    "end": "1254130"
  },
  {
    "text": "the conditional universe.  So this is our conditional\nmodel.",
    "start": "1254130",
    "end": "1260650"
  },
  {
    "text": "So our PMF is equal to 1/3 for\nX equals to 2, 3 and 4.",
    "start": "1260650",
    "end": "1268276"
  },
  {
    "text": "All right. Now whenever you have a\nprobabilistic model involving",
    "start": "1268276",
    "end": "1273380"
  },
  {
    "text": "a random variable and you have\na PMF for that random variable, you can talk about\nthe expected value of that",
    "start": "1273380",
    "end": "1279690"
  },
  {
    "text": "random variable. We defined expected values\njust a few minutes ago.",
    "start": "1279690",
    "end": "1285340"
  },
  {
    "text": "Here, we're dealing with\na conditional model and conditional probabilities.",
    "start": "1285340",
    "end": "1290680"
  },
  {
    "text": "And so we can also talk about\nthe expected value of the random variable X in this new\nuniverse, in this new",
    "start": "1290680",
    "end": "1298100"
  },
  {
    "text": "conditional model that\nwe're dealing with. And this leads us to the\ndefinition of the notion of a",
    "start": "1298100",
    "end": "1303679"
  },
  {
    "text": "conditional expectation. The conditional expectation\nis nothing but an ordinary",
    "start": "1303680",
    "end": "1310680"
  },
  {
    "text": "expectation, except that you\ndon't use the original PMF.",
    "start": "1310680",
    "end": "1316720"
  },
  {
    "text": "You use the conditional PMF. You use the conditional\nprobabilities. It's just an ordinary\nexpectation, but applied to",
    "start": "1316720",
    "end": "1325550"
  },
  {
    "text": "the new model that we have to\nthe conditional universe where we are told that the certain\nevent has occurred.",
    "start": "1325550",
    "end": "1333270"
  },
  {
    "text": "So we can now calculate the\ncondition expectation, which, in this particular example,\nwould be 1/3.",
    "start": "1333270",
    "end": "1339890"
  },
  {
    "text": "That's the probability of a\n2, plus 1/3 which is the probability of a 3 plus 1/3,\nthe probability of a 4.",
    "start": "1339890",
    "end": "1349280"
  },
  {
    "text": "And then you can use your\ncalculator to find the answer, or you can just argue\nby symmetry.",
    "start": "1349280",
    "end": "1355780"
  },
  {
    "text": "The expected value has to be the\ncenter of gravity of the PMF we're working with,\nwhich is equal to 3.",
    "start": "1355780",
    "end": "1365040"
  },
  {
    "text": "So conditional expectations are\nno different from ordinary expectations.",
    "start": "1365040",
    "end": "1371230"
  },
  {
    "text": "They're just ordinary\nexpectations applied to a new type of situation or a\nnew type of model.",
    "start": "1371230",
    "end": "1377600"
  },
  {
    "text": "Anything we might know about\nexpectations will remain valid",
    "start": "1377600",
    "end": "1383010"
  },
  {
    "text": "about conditional\nexpectations. So for example, the conditional\nexpectation of a linear function of a random\nvariable is going to be the",
    "start": "1383010",
    "end": "1391040"
  },
  {
    "text": "linear function of the\nconditional expectations. Or you can take any formula that\nyou might know, such as",
    "start": "1391040",
    "end": "1398200"
  },
  {
    "text": "the formula that expected value\nof X is equal to the--",
    "start": "1398200",
    "end": "1403970"
  },
  {
    "text": "sorry-- expected value of g of X is the\nsum over all X's of g of X",
    "start": "1403970",
    "end": "1411030"
  },
  {
    "text": "times the PMF of X. So this is\nthe formula that we already",
    "start": "1411030",
    "end": "1417700"
  },
  {
    "text": "know about how to calculate\nexpectations of a function of a random variable.",
    "start": "1417700",
    "end": "1423540"
  },
  {
    "text": "If we move to the conditional\nuniverse, what changes? In the conditional universe,\nwe're talking about the",
    "start": "1423540",
    "end": "1431169"
  },
  {
    "text": "conditional expectation, given\nthat event A has occurred. And we use the conditional\nprobabilities, given that A",
    "start": "1431170",
    "end": "1439390"
  },
  {
    "text": "has occurred. So any formula has a conditional\ncounterpart.",
    "start": "1439390",
    "end": "1445140"
  },
  {
    "text": "In the conditional counterparts,\nexpectations get replaced by conditional\nexpectations. And probabilities get replaced\nby conditional probabilities.",
    "start": "1445140",
    "end": "1453940"
  },
  {
    "text": "So once you know the first\nformula and you know the general idea, there's absolutely\nno reason for you",
    "start": "1453940",
    "end": "1461210"
  },
  {
    "text": "to memorize a formula\nlike this one. You shouldn't even have to write\nit on your cheat sheet",
    "start": "1461210",
    "end": "1467070"
  },
  {
    "text": "for the exam, OK? OK, all right, so now let's look\nat an example of a random",
    "start": "1467070",
    "end": "1480980"
  },
  {
    "text": "variable that we've seen before,\nthe geometric random variable, and this time do\nsomething a little more",
    "start": "1480980",
    "end": "1487909"
  },
  {
    "text": "interesting with it. Do you remember from last time\nwhat the geometric random",
    "start": "1487910",
    "end": "1494510"
  },
  {
    "text": "variable is? We do coin flips. Each time there's a\nprobability of P",
    "start": "1494510",
    "end": "1499580"
  },
  {
    "text": "of obtaining heads. And we're interested in the\nnumber of tosses we're going to need until we observe heads\nfor the first time.",
    "start": "1499580",
    "end": "1507580"
  },
  {
    "text": "The probability that the random\nvariable takes the value K, this is the probability\nthat the first K",
    "start": "1507580",
    "end": "1513290"
  },
  {
    "text": "appeared at the K-th toss. So this is the probability of\nK minus 1 consecutive tails",
    "start": "1513290",
    "end": "1520900"
  },
  {
    "text": "followed by a head. So this is the probability of\nhaving to weight K tosses.",
    "start": "1520900",
    "end": "1528360"
  },
  {
    "text": "And when we plot this PMF, it\nhas this kind of shape, which is the shape of a geometric\nprogression.",
    "start": "1528360",
    "end": "1536020"
  },
  {
    "text": "It starts at 1, and it goes\nall the way to infinity. So this is a discrete random\nvariable that takes values",
    "start": "1536020",
    "end": "1543700"
  },
  {
    "text": "over an infinite set, the set\nof the positive integers.",
    "start": "1543700",
    "end": "1549159"
  },
  {
    "text": "So it's a random variable,\ntherefore, it has an expectation. And the expected value is, by\ndefinition, we'll consider all",
    "start": "1549160",
    "end": "1556790"
  },
  {
    "text": "possible values of the\nrandom variable. And we weigh them according to\ntheir probabilities, which",
    "start": "1556790",
    "end": "1562560"
  },
  {
    "text": "leads us to this expression. You may have evaluated that\nexpression some time in your",
    "start": "1562560",
    "end": "1569860"
  },
  {
    "text": "previous life. And there are tricks for how\nto evaluate this and get a",
    "start": "1569860",
    "end": "1575730"
  },
  {
    "text": "closed-form answer. But it's sort of an\nalgebraic trick. You might not remember it. How do we go about doing\nthis summation?",
    "start": "1575730",
    "end": "1583520"
  },
  {
    "text": "Well, we're going to use a\nprobabilistic trick and manage to evaluate the expectation of\nX, essentially, without doing",
    "start": "1583520",
    "end": "1593440"
  },
  {
    "text": "any algebra. And in the process of doing so,\nwe're going to get some",
    "start": "1593440",
    "end": "1598600"
  },
  {
    "text": "intuition about what happens\nin coin tosses and with geometric random variables.",
    "start": "1598600",
    "end": "1605750"
  },
  {
    "text": "So we have two people who\nare going to do the same experiment, flip a coin until\nthey obtain heads for the",
    "start": "1605750",
    "end": "1613870"
  },
  {
    "text": "first time. One of these people is going to\nuse the letter Y to count",
    "start": "1613870",
    "end": "1620170"
  },
  {
    "text": "how many heads it took. So that person starts\nflipping right now.",
    "start": "1620170",
    "end": "1626860"
  },
  {
    "text": "This is the current time. And they are going to obtain\ntails, tails, tails, until eventually they obtain heads.",
    "start": "1626860",
    "end": "1633620"
  },
  {
    "text": "And this random variable Y is,\nof course, geometric, so it",
    "start": "1633620",
    "end": "1640750"
  },
  {
    "text": "has a PMF of this form.  OK, now there is a second person\nwho is doing that same",
    "start": "1640750",
    "end": "1652090"
  },
  {
    "text": "experiment. That second person is going to\ntake, again, a random number,",
    "start": "1652090",
    "end": "1657400"
  },
  {
    "text": "X, until they obtain heads\nfor the first time. And of course, X is going to\nhave the same PMF as Y.",
    "start": "1657400",
    "end": "1664560"
  },
  {
    "text": "But that person was impatient. And they actually started\nflipping earlier, before the Y",
    "start": "1664560",
    "end": "1671880"
  },
  {
    "text": "person started flipping. They flipped the coin twice. And they were unlucky, and they",
    "start": "1671880",
    "end": "1677640"
  },
  {
    "text": "obtained tails both times.  And so they have to continue.",
    "start": "1677640",
    "end": "1685115"
  },
  {
    "text": " Looking at the situation at this\ntime, how do these two",
    "start": "1685115",
    "end": "1693299"
  },
  {
    "text": "people compare? Who do you think is going\nto obtain heads first?",
    "start": "1693300",
    "end": "1700259"
  },
  {
    "text": "Is one more likely\nthan the other? So if you play at the casino a\nlot, you'll say, oh, there",
    "start": "1700260",
    "end": "1706160"
  },
  {
    "text": "were two tails in a row, so\na head should be coming up sometime soon.",
    "start": "1706160",
    "end": "1711350"
  },
  {
    "text": "But this is a wrong argument,\nbecause coin flips, at least in our model, are independent.",
    "start": "1711350",
    "end": "1717870"
  },
  {
    "text": "The fact that these two happened\nto be tails doesn't change anything about our\nbeliefs about what's going to",
    "start": "1717870",
    "end": "1725230"
  },
  {
    "text": "be happening here. So what's going to be happening\nto that person is they will be flipping\nindependent coin flips.",
    "start": "1725230",
    "end": "1733140"
  },
  {
    "text": "That person will also\nbe flipping independent coin flips. And both of them wait until\nthe first head occurs.",
    "start": "1733140",
    "end": "1740660"
  },
  {
    "text": "They're facing an identical\nsituation, starting from this time.",
    "start": "1740660",
    "end": "1746770"
  },
  {
    "text": "OK, now what's the probabilistic\nmodel of what",
    "start": "1746770",
    "end": "1751850"
  },
  {
    "text": "this person is facing? The time until that person\nobtains heads for the first",
    "start": "1751850",
    "end": "1758940"
  },
  {
    "text": "time is X. So this number of\nflips until they obtain heads",
    "start": "1758940",
    "end": "1765740"
  },
  {
    "text": "for the first time is going\nto be X minus 2. So X is the total number\nuntil the first head.",
    "start": "1765740",
    "end": "1775809"
  },
  {
    "text": "X minus 2 is the number or\nflips, starting from here.",
    "start": "1775810",
    "end": "1781280"
  },
  {
    "text": "Now what information do we\nhave about that person? We have the information\nthat their first two flips were tails.",
    "start": "1781280",
    "end": "1787970"
  },
  {
    "text": "So we're given the information\nthat X was bigger than 2. So the probabilistic model that\ndescribes this piece of",
    "start": "1787970",
    "end": "1797035"
  },
  {
    "text": "the experiment is that it's\ngoing to take a random number of flips until the first head.",
    "start": "1797035",
    "end": "1804270"
  },
  {
    "text": "That number of flips, starting\nfrom here until the next head, is that number X minus 2.",
    "start": "1804270",
    "end": "1810980"
  },
  {
    "text": "But we're given the information\nthat this person has already wasted\n2 coin flips.",
    "start": "1810980",
    "end": "1817779"
  },
  {
    "text": "Now we argued that\nprobabilistically, this person, this part of the\nexperiment here is identical",
    "start": "1817780",
    "end": "1824779"
  },
  {
    "text": "with that part of\nthe experiment. So the PMF of this random\nvariable, which is X minus 2,",
    "start": "1824780",
    "end": "1831649"
  },
  {
    "text": "conditioned on this information,\nshould be the same as that PMF that\nwe have down there.",
    "start": "1831650",
    "end": "1839150"
  },
  {
    "text": "So the formal statement that\nI'm making is that this PMF",
    "start": "1839150",
    "end": "1846290"
  },
  {
    "text": "here of X minus 2, given that\nX is bigger than 2, is the",
    "start": "1846290",
    "end": "1851910"
  },
  {
    "text": "same as the PMF of X itself.",
    "start": "1851910",
    "end": "1858060"
  },
  {
    "text": "What is this saying? Given that I tell you that you\nalready did a few flips and",
    "start": "1858060",
    "end": "1864220"
  },
  {
    "text": "they were failures, the\nremaining number of flips until the first head has the\nsame geometric distribution as",
    "start": "1864220",
    "end": "1873260"
  },
  {
    "text": "if you were starting\nfrom scratch. Whatever happened in the past,\nit happened, but has no",
    "start": "1873260",
    "end": "1879590"
  },
  {
    "text": "bearing what's going to\nhappen in the future. Remaining coin flips until\na head has the same",
    "start": "1879590",
    "end": "1887660"
  },
  {
    "text": "distribution, whether you're\nstarting right now, or whether you had done some other\nstuff in the past.",
    "start": "1887660",
    "end": "1895590"
  },
  {
    "text": "So this is a property that we\ncall the memorylessness property of the geometric\ndistribution.",
    "start": "1895590",
    "end": "1902549"
  },
  {
    "text": "Essentially, it says that\nwhatever happens in the future is independent from whatever\nhappened in the past.",
    "start": "1902550",
    "end": "1908920"
  },
  {
    "text": "And that's true almost by\ndefinition, because we're assuming independent\ncoin flips. Really, independence means that\ninformation about one",
    "start": "1908920",
    "end": "1916750"
  },
  {
    "text": "part of the experiment has no\nbearing about what's going to happen in the other parts\nof the experiment.",
    "start": "1916750",
    "end": "1924280"
  },
  {
    "text": "The argument that I tried to\ngive using the intuition of coin flips, you can make it\nformal by just manipulating",
    "start": "1924280",
    "end": "1934240"
  },
  {
    "text": "PMFs formally. So this is the original\nPMF of X.",
    "start": "1934240",
    "end": "1939450"
  },
  {
    "text": "Suppose that you condition\non the event that X is bigger than 3. This conditioning information,\nwhat it does is it tells you",
    "start": "1939450",
    "end": "1947570"
  },
  {
    "text": "that this piece did\nnot happen. You're conditioning just\non this event.",
    "start": "1947570",
    "end": "1953760"
  },
  {
    "text": "When you condition on that\nevent, what's left is the conditional PMF, which has the\nsame shape as this one, except",
    "start": "1953760",
    "end": "1962130"
  },
  {
    "text": "that it needs to be\nre-normalized up, so that the probabilities add up to one. So you take that picture, but\nyou need to change the height",
    "start": "1962130",
    "end": "1972460"
  },
  {
    "text": "of it, so that these\nterms add up to 1. And this is the conditional\nPMF of X, given that X is",
    "start": "1972460",
    "end": "1979730"
  },
  {
    "text": "bigger than 2. But we're talking here not about\nX. We're talking about the remaining number of heads.",
    "start": "1979730",
    "end": "1987929"
  },
  {
    "text": "Remaining number of heads\nis X minus 2. If we have the PMF of X, can we\nfind the PMF of X minus 2?",
    "start": "1987930",
    "end": "1997120"
  },
  {
    "text": "Well, if X is equal to 3, that\ncorresponds to X minus 2 being",
    "start": "1997120",
    "end": "2002870"
  },
  {
    "text": "equal to 1. So this probability here\nshould be equal to that probability.",
    "start": "2002870",
    "end": "2007950"
  },
  {
    "text": "The probability that X is equal\nto 4 should be the same as the probability that X\nminus 2 is equal to 2.",
    "start": "2007950",
    "end": "2014710"
  },
  {
    "text": "So basically, the PMF of X minus\n2 is the same as the PMF of X, except that it gets\nshifted by these 2 units.",
    "start": "2014710",
    "end": "2023460"
  },
  {
    "text": "So this way, we have formally\nderived the conditional PMF of the remaining number of coin\ntosses, given that the first",
    "start": "2023460",
    "end": "2031490"
  },
  {
    "text": "two flips were tails. And we see that it's exactly\nthe same as the PMF that we",
    "start": "2031490",
    "end": "2038880"
  },
  {
    "text": "started with. And so this is the formal proof\nof this statement here.",
    "start": "2038880",
    "end": "2045130"
  },
  {
    "text": "So it's useful here to digest\nboth these formal statements and understand it and understand\nthe notation that",
    "start": "2045130",
    "end": "2053290"
  },
  {
    "text": "is involved here, but also\nto really appreciate the intuitive argument what\nthis is really saying.",
    "start": "2053290",
    "end": "2061408"
  },
  {
    "text": "OK, all right, so now we want to\nuse this observation, this",
    "start": "2061409",
    "end": "2068980"
  },
  {
    "text": "memorylessness, to eventually\ncalculate the expected value for a geometric random\nvariable.",
    "start": "2068980",
    "end": "2074679"
  },
  {
    "text": "And the way we're going to do\nit is by using a divide and conquer tool, which is an analog\nof what we have already",
    "start": "2074679",
    "end": "2081649"
  },
  {
    "text": "seen sometime before. Remember our story that there's\na number of possible",
    "start": "2081650",
    "end": "2088230"
  },
  {
    "text": "scenarios about the world? And there's a certain event, B,\nthat can happen under any",
    "start": "2088230",
    "end": "2094120"
  },
  {
    "text": "of these possible scenarios. And we have the total\nprobability theory. And that tells us that, to find\nthe probability of this",
    "start": "2094120",
    "end": "2100970"
  },
  {
    "text": "event, B, you consider\nthe probabilities of B under each scenario.",
    "start": "2100970",
    "end": "2106000"
  },
  {
    "text": "And you weigh those\nprobabilities according to the probabilities of the different\nscenarios that we have.",
    "start": "2106000",
    "end": "2112190"
  },
  {
    "text": "So that's a formula that\nwe already know and have worked with. What's the next step?",
    "start": "2112190",
    "end": "2118020"
  },
  {
    "text": "Is it something deep? No, it's just translation\nin different notation.",
    "start": "2118020",
    "end": "2124280"
  },
  {
    "text": "This is the exactly same\nformula, but with PMFs. The event that capital X is\nequal to little x can happen",
    "start": "2124280",
    "end": "2132720"
  },
  {
    "text": "in many different ways. It can happen under\neither scenario. And within each scenario, you\nneed to use the conditional",
    "start": "2132720",
    "end": "2140910"
  },
  {
    "text": "probabilities of that event,\ngiven that this scenario has occurred.",
    "start": "2140910",
    "end": "2146269"
  },
  {
    "text": "So this formula is identical to\nthat one, except that we're using conditional PMFs,\ninstead of conditional",
    "start": "2146270",
    "end": "2153440"
  },
  {
    "text": "probabilities. But conditional PMFs, of\ncourse, are nothing but conditional probabilities\nanyway.",
    "start": "2153440",
    "end": "2159710"
  },
  {
    "text": "So nothing new so far. Then what I do is to take this\nformula here and multiply both",
    "start": "2159710",
    "end": "2168700"
  },
  {
    "text": "sides by X and take the\nsum over all X's.",
    "start": "2168700",
    "end": "2175320"
  },
  {
    "text": "What do we get on this side? We get the expected\nvalue of X. What do we get on that side?",
    "start": "2175320",
    "end": "2182829"
  },
  {
    "text": "Probability of A1. And then here, sum over all\nX's of X times P. That's,",
    "start": "2182830",
    "end": "2189770"
  },
  {
    "text": "again, the same calculation\nwe have when we deal with expectations, except that, since\nhere, we're dealing with",
    "start": "2189770",
    "end": "2196450"
  },
  {
    "text": "conditional probabilities,\nwe're going to get the conditional expectation. And this is the total\nexpectation theorem.",
    "start": "2196450",
    "end": "2204160"
  },
  {
    "text": "It's a very useful way for\ncalculating expectations using a divide and conquer method.",
    "start": "2204160",
    "end": "2209440"
  },
  {
    "text": "We figure out the average value\nof X under each one of the possible scenarios.",
    "start": "2209440",
    "end": "2215590"
  },
  {
    "text": "The overall average value of\nX is a weighted linear",
    "start": "2215590",
    "end": "2221330"
  },
  {
    "text": "combination of the expected\nvalues of X in the different scenarios where the weights are\nchosen according to the",
    "start": "2221330",
    "end": "2227960"
  },
  {
    "text": "different probabilities. ",
    "start": "2227960",
    "end": "2235356"
  },
  {
    "text": "OK, and now we're going to apply\nthis to the case of a",
    "start": "2235356",
    "end": "2241040"
  },
  {
    "text": "geometric random variable. And we're going to divide and\nconquer by considering",
    "start": "2241040",
    "end": "2246410"
  },
  {
    "text": "separately the two cases where\nthe first toss was heads, and the other case where the\nfirst toss was tails.",
    "start": "2246410",
    "end": "2255820"
  },
  {
    "text": "So the expected value of X is\nthe probability that the first toss was heads, so that X is\nequal to 1, and the expected",
    "start": "2255820",
    "end": "2264020"
  },
  {
    "text": "value if that happened. What is the expected value of X,\ngiven that X is equal to 1?",
    "start": "2264020",
    "end": "2271530"
  },
  {
    "text": "If X is known to be\nequal to 1, then X becomes just a number.",
    "start": "2271530",
    "end": "2277390"
  },
  {
    "text": "And the expected value of a\nnumber is the number itself. So this first line here is the\nprobability of heads in the",
    "start": "2277390",
    "end": "2285120"
  },
  {
    "text": "first toss times the number 1. ",
    "start": "2285120",
    "end": "2293319"
  },
  {
    "text": "So the probability that X is\nbigger than 1 is 1 minus P.",
    "start": "2293320",
    "end": "2301000"
  },
  {
    "text": "And then we need to do\nsomething about this conditional expectation.",
    "start": "2301000",
    "end": "2306650"
  },
  {
    "text": " What is it?",
    "start": "2306650",
    "end": "2313400"
  },
  {
    "text": "I can write it in, perhaps,\na more suggested form, as",
    "start": "2313400",
    "end": "2319420"
  },
  {
    "text": "expected the value of X minus\n1, given that X minus 1 is",
    "start": "2319420",
    "end": "2331359"
  },
  {
    "text": "bigger than 1. ",
    "start": "2331360",
    "end": "2336590"
  },
  {
    "text": "Ah. ",
    "start": "2336590",
    "end": "2342420"
  },
  {
    "text": "OK, X bigger than 1 is the\nsame as X minus 1 being",
    "start": "2342420",
    "end": "2347453"
  },
  {
    "text": "positive, this way. X minus 1 is positive plus 1.",
    "start": "2347453",
    "end": "2355500"
  },
  {
    "text": "What did I do here? I added and subtracted 1.",
    "start": "2355500",
    "end": "2361250"
  },
  {
    "text": "Now what is this? This is the expected value of\nthe remaining coin flips,",
    "start": "2361250",
    "end": "2369240"
  },
  {
    "text": "until I obtain heads, given that\nthe first one was tails.",
    "start": "2369240",
    "end": "2374660"
  },
  {
    "text": "It's the same story that we were\ngoing through down there. Given that the first coin flip\nwas tails doesn't tell me",
    "start": "2374660",
    "end": "2381859"
  },
  {
    "text": "anything about the\nfuture, about the remaining coin flips. So this expectation should be\nthe same as the expectation",
    "start": "2381860",
    "end": "2389610"
  },
  {
    "text": "faced by a person who was\nstarting just now. So this should be equal to the\nexpected value of X itself.",
    "start": "2389610",
    "end": "2399080"
  },
  {
    "text": "And then we have the plus 1\nthat's come from there, OK?",
    "start": "2399080",
    "end": "2404120"
  },
  {
    "text": " Remaining coin flips until a\nhead, given that I had a tail",
    "start": "2404120",
    "end": "2411140"
  },
  {
    "text": "yesterday, is the same as\nexpected number of flips until heads for a person just starting\nnow and wasn't doing",
    "start": "2411140",
    "end": "2420160"
  },
  {
    "text": "anything yesterday. So the fact that they I had a\ncoin flip yesterday doesn't change my beliefs about how\nlong it's going to take me",
    "start": "2420160",
    "end": "2428990"
  },
  {
    "text": "until the first head. So once we believe that\nrelation, than",
    "start": "2428990",
    "end": "2434700"
  },
  {
    "text": "we plug this here. And this red term becomes\nexpected value of X plus 1.",
    "start": "2434700",
    "end": "2442346"
  },
  {
    "text": " So now we didn't exactly get the\nanswer we wanted, but we",
    "start": "2442346",
    "end": "2450850"
  },
  {
    "text": "got an equation that involves\nthe expected value of X. And",
    "start": "2450850",
    "end": "2456110"
  },
  {
    "text": "it's the only unknown\nin that equation. Expected value of X equals to P\nplus (1 minus P) times this",
    "start": "2456110",
    "end": "2463990"
  },
  {
    "text": "expression. You solve this equation for\nexpected value of X, and you get the value of 1/P.",
    "start": "2463990",
    "end": "2472990"
  },
  {
    "text": "The final answer does make\nintuitive sense. If P is small, heads are\ndifficult to obtain.",
    "start": "2472990",
    "end": "2481030"
  },
  {
    "text": "So you expect that it's going to\ntake you a long time until you see heads for\nthe first time.",
    "start": "2481030",
    "end": "2486310"
  },
  {
    "text": "So it is definitely a\nreasonable answer. Now the trick that we used here,\nthe divide and conquer",
    "start": "2486310",
    "end": "2492960"
  },
  {
    "text": "trick, is a really nice one. It gives us a very good shortcut\nin this problem.",
    "start": "2492960",
    "end": "2499760"
  },
  {
    "text": "But you must definitely spend\nsome time making sure you understand why this expression\nhere is the same as that",
    "start": "2499760",
    "end": "2508670"
  },
  {
    "text": "expression there. Essentially, what it's saying is\nthat, if I tell you that X",
    "start": "2508670",
    "end": "2513790"
  },
  {
    "text": "is bigger than 1, that the first\ncoin flip was tails, all I'm telling you is that that\nperson has wasted a coin flip,",
    "start": "2513790",
    "end": "2522040"
  },
  {
    "text": "and they are starting\nall over again. So they've wasted 1 coin flip.",
    "start": "2522040",
    "end": "2528510"
  },
  {
    "text": "And they're starting\nall over again. If I tell you that the first\nflip was tails, that's the only information that I'm\nbasically giving you, a wasted",
    "start": "2528510",
    "end": "2536800"
  },
  {
    "text": "flip, and then starts\nall over again. All right, so in the few\nremaining minutes now, we're",
    "start": "2536800",
    "end": "2543180"
  },
  {
    "text": "going to quickly introduce a few\nnew concepts that we will be playing with in the\nnext ten days or so.",
    "start": "2543180",
    "end": "2551050"
  },
  {
    "text": "And you will get plenty\nof opportunities to manipulate them. So here's the idea.",
    "start": "2551050",
    "end": "2557180"
  },
  {
    "text": "A typical experiment may have\nseveral random variables associated with that\nexperiment.",
    "start": "2557180",
    "end": "2563310"
  },
  {
    "text": "So a typical student has\nheight and weight. If I give you the PMF of\nheight, that tells me",
    "start": "2563310",
    "end": "2568800"
  },
  {
    "text": "something about distribution\nof heights in the class. I give you the PMF of weight,\nit tells me something about",
    "start": "2568800",
    "end": "2577110"
  },
  {
    "text": "the different weights\nin this class. But if I want to ask a\nquestion, is there an association between height and\nweight, then I need to know a",
    "start": "2577110",
    "end": "2585910"
  },
  {
    "text": "little more how height and\nweight relate to each other. And the PMF of height\nindividuality and PMF of",
    "start": "2585910",
    "end": "2593480"
  },
  {
    "text": "weight just by itself\ndo not tell me anything about those relations. To be able to say something\nabout those relations, I need",
    "start": "2593480",
    "end": "2601730"
  },
  {
    "text": "to know something about joint\nprobabilities, how likely is",
    "start": "2601730",
    "end": "2607230"
  },
  {
    "text": "it that certain X's go together\nwith certain Y's. So these probabilities,\nessentially, capture",
    "start": "2607230",
    "end": "2614180"
  },
  {
    "text": "associations between these\ntwo random variables. And it's the information I would\nneed to have to do any",
    "start": "2614180",
    "end": "2620910"
  },
  {
    "text": "kind of statistical study that\ntries to relate the two random variables with each other.",
    "start": "2620910",
    "end": "2627599"
  },
  {
    "text": "These are ordinary\nprobabilities. This is an event. It's the event that\nthis thing happens",
    "start": "2627600",
    "end": "2632630"
  },
  {
    "text": "and that thing happens. This is just the notation\nthat we will be using.",
    "start": "2632630",
    "end": "2638460"
  },
  {
    "text": "It's called the joint PMF. It's the joint Probability\nMass Function of the two",
    "start": "2638460",
    "end": "2644560"
  },
  {
    "text": "random variables X and Y looked\nat together, jointly. And it gives me the probability\nthat any",
    "start": "2644560",
    "end": "2651740"
  },
  {
    "text": "particular numerical outcome\npair does happen.",
    "start": "2651740",
    "end": "2657100"
  },
  {
    "text": "So in the finite case, you can\nrepresent joint PMFs, for example, by a table.",
    "start": "2657100",
    "end": "2662660"
  },
  {
    "text": "This particular table here would\ngive you information such as, let's see, the joint\nPMF evaluated at 2, 3.",
    "start": "2662660",
    "end": "2671869"
  },
  {
    "text": "This is the probability that\nX is equal to 3 and, simultaneously, Y\nis equal to 3.",
    "start": "2671870",
    "end": "2678200"
  },
  {
    "text": "So it would be that\nnumber here. It's 4/20. ",
    "start": "2678200",
    "end": "2684290"
  },
  {
    "text": "OK, what is a basic\nproperty of PMFs? First, these are probabilities,\nso all of the",
    "start": "2684290",
    "end": "2689920"
  },
  {
    "text": "entries have to be\nnon-negative. If you adopt the probabilities\nover all possible numerical",
    "start": "2689920",
    "end": "2697470"
  },
  {
    "text": "pairs that you could get, of\ncourse, the total probability must be equal to 1.",
    "start": "2697470",
    "end": "2703050"
  },
  {
    "text": "So that's another thing\nthat we want. Now suppose somebody gives\nme this model, but I",
    "start": "2703050",
    "end": "2710090"
  },
  {
    "text": "don't care about Y's. All I care is the distribution\nof the X's.",
    "start": "2710090",
    "end": "2715760"
  },
  {
    "text": "So I'm going to find the\nprobability that X takes on a particular value. Can I find it from the table?",
    "start": "2715760",
    "end": "2722230"
  },
  {
    "text": "Of course, I can. If you ask me what's the\nprobability that X is equal to",
    "start": "2722230",
    "end": "2727930"
  },
  {
    "text": "3, what I'm going to do is\nto add up those three probabilities together.",
    "start": "2727930",
    "end": "2733789"
  },
  {
    "text": "And those probabilities, taken\nall together, give me the probability that X\nis equal to 3.",
    "start": "2733790",
    "end": "2740400"
  },
  {
    "text": "These are all the possible ways\nthat the event X equals to 3 can happen. So we add these, and\nwe get the 6/20.",
    "start": "2740400",
    "end": "2749850"
  },
  {
    "text": "What I just did, can we\ntranslate it to a formula? What did I do?",
    "start": "2749850",
    "end": "2755510"
  },
  {
    "text": "I fixed the particular value\nof X. And I added up the values of the joint PMF over all\nthe possible values of Y.",
    "start": "2755510",
    "end": "2765100"
  },
  {
    "text": "So that's how you do it. You take the joint. You take one slice of the joint,\nkeeping X fixed, and",
    "start": "2765100",
    "end": "2773020"
  },
  {
    "text": "adding up over the different\nvalues of Y. The moral of this example is\nthat, if you know the joint",
    "start": "2773020",
    "end": "2778930"
  },
  {
    "text": "PMFs, then you can find the\nindividual PMFs of every individual random variable.",
    "start": "2778930",
    "end": "2784310"
  },
  {
    "text": "And we have a name for these. We call them the\nmarginal PMFs. We have the joint that talks\nabout both together, and the",
    "start": "2784310",
    "end": "2791900"
  },
  {
    "text": "marginal that talks about\nthem one at the time. And finally, since we love\nconditional probabilities, we",
    "start": "2791900",
    "end": "2798589"
  },
  {
    "text": "will certainly want to define\nan object called the conditional PMF.",
    "start": "2798590",
    "end": "2804160"
  },
  {
    "text": "So this quantity here\nis a familiar one. It's just a conditional\nprobability.",
    "start": "2804160",
    "end": "2809310"
  },
  {
    "text": "It's the probability that X\ntakes on a particular value,",
    "start": "2809310",
    "end": "2814940"
  },
  {
    "text": "given that Y takes\na certain value. ",
    "start": "2814940",
    "end": "2822060"
  },
  {
    "text": "For our example, let's take\nlittle y to be equal to 2,",
    "start": "2822060",
    "end": "2827160"
  },
  {
    "text": "which means that we're\nconditioning to live inside this universe.",
    "start": "2827160",
    "end": "2832490"
  },
  {
    "text": "This red universe here is the\ny equal to 2 universe.",
    "start": "2832490",
    "end": "2837920"
  },
  {
    "text": "And these are the conditional\nprobabilities of the different X's inside that universe.",
    "start": "2837920",
    "end": "2842935"
  },
  {
    "text": " OK, once more, just an\nexercise in notation.",
    "start": "2842935",
    "end": "2849860"
  },
  {
    "text": "This is the chapter two version\nof the notation of what we were denoting this\nway in chapter one.",
    "start": "2849860",
    "end": "2857750"
  },
  {
    "text": "The way to read this is that\nit's a conditional PMF having",
    "start": "2857750",
    "end": "2863000"
  },
  {
    "text": "to do with two random variables,\nthe PMF of X conditioned on information\nabout Y. We are fixing a",
    "start": "2863000",
    "end": "2871150"
  },
  {
    "text": "particular value of capital Y,\nthat's the value on which we are conditioning.",
    "start": "2871150",
    "end": "2876610"
  },
  {
    "text": "And we're looking at the\nprobabilities of the different X's. So it's really a function\nof two arguments, little",
    "start": "2876610",
    "end": "2883890"
  },
  {
    "text": "x and little y. But the best way to think about\nit is to fix little y",
    "start": "2883890",
    "end": "2890490"
  },
  {
    "text": "and think of it as a function\nof X. So I'm fixing little y here, let's say, to\ny equal to 2.",
    "start": "2890490",
    "end": "2897610"
  },
  {
    "text": "So I'm considering only this. And now, this quantity becomes\na function of little x.",
    "start": "2897610",
    "end": "2904089"
  },
  {
    "text": "For the different little x's,\nwe're going to have different conditional probabilities.",
    "start": "2904090",
    "end": "2909290"
  },
  {
    "text": "What are those conditional\nprobabilities? ",
    "start": "2909290",
    "end": "2916230"
  },
  {
    "text": "OK, conditional probabilities\nare proportional to original probabilities.",
    "start": "2916230",
    "end": "2921940"
  },
  {
    "text": "So it's going to be those\nnumbers, but scaled up. And they need to be scaled\nso that they add up to 1.",
    "start": "2921940",
    "end": "2928339"
  },
  {
    "text": "So we have 1, 3 and 1. That's a total of 5. So the conditional PMF would\nhave the shape zero,",
    "start": "2928340",
    "end": "2936220"
  },
  {
    "text": "1/5, 3/5, and 1/5.",
    "start": "2936220",
    "end": "2942480"
  },
  {
    "text": "This is the conditional PMF,\ngiven a particular value of Y.",
    "start": "2942480",
    "end": "2947540"
  },
  {
    "text": "It has the same shape as those\nnumbers, where by shape, I",
    "start": "2947540",
    "end": "2953180"
  },
  {
    "text": "mean try to visualize\na bar graph. The bar graph associated with\nthose numbers has exactly the",
    "start": "2953180",
    "end": "2959370"
  },
  {
    "text": "same shape as the bar graph\nassociated with those numbers. The only thing that has changed\nis the scaling.",
    "start": "2959370",
    "end": "2966789"
  },
  {
    "text": "Big moral, let me say in\ndifferent words, the conditional PMF, given a\nparticular value of Y, is just",
    "start": "2966790",
    "end": "2974250"
  },
  {
    "text": "a slice of the joint PMF where\nyou maintain the same shape,",
    "start": "2974250",
    "end": "2979790"
  },
  {
    "text": "but you rescale the numbers\nso that they add up to 1. Now mathematically, of course,\nwhat all of this is doing is",
    "start": "2979790",
    "end": "2988410"
  },
  {
    "text": "it's taking the original joint\nPDF and it rescales it by a",
    "start": "2988410",
    "end": "2994750"
  },
  {
    "text": "certain factor. This does not involve X, so the\nshape, is a function of X,",
    "start": "2994750",
    "end": "3000340"
  },
  {
    "text": "has not changed. We're keeping the same shape\nas a function of X, but we divide by a certain number.",
    "start": "3000340",
    "end": "3006420"
  },
  {
    "text": "And that's the number that we\nneed, so that the conditional probabilities add up to 1.",
    "start": "3006420",
    "end": "3012809"
  },
  {
    "text": "Now where does this\nformula come from? Well, this is just the\ndefinition of conditional",
    "start": "3012810",
    "end": "3017880"
  },
  {
    "text": "probabilities. Probability of something\nconditioned on something else is the probability of both\nthings happening, the",
    "start": "3017880",
    "end": "3024620"
  },
  {
    "text": "intersection of the two divided\nby the probability of the conditioning event.",
    "start": "3024620",
    "end": "3029890"
  },
  {
    "text": "And last remark is that, as\nI just said, conditional probabilities are nothing\ndifferent than ordinary",
    "start": "3029890",
    "end": "3035930"
  },
  {
    "text": "probabilities. So a conditional PMF must sum\nto 1, no matter what you are",
    "start": "3035930",
    "end": "3042390"
  },
  {
    "text": "conditioning on. All right, so this was sort of\nquick introduction into our new notation.",
    "start": "3042390",
    "end": "3048920"
  },
  {
    "text": "But you get a lot of practice\nin the next days to come.",
    "start": "3048920",
    "end": "3053030"
  }
]
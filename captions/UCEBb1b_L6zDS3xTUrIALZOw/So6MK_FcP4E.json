[
  {
    "text": " The following\ncontent is provided under a Creative\nCommons license. Your support will help MIT\nOpenCourseWare continue",
    "start": "0",
    "end": "6870"
  },
  {
    "text": "to offer high quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6870",
    "end": "13339"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. ",
    "start": "13340",
    "end": "26008"
  },
  {
    "text": "PROFESSOR: So you'll\nrecall last time we were working on\nprotein-protein interactions. We're going to do a little\nbit to finish that up,",
    "start": "26009",
    "end": "32029"
  },
  {
    "text": "with a topic that will be a\ngood transition to the study of the gene regulatory networks. ",
    "start": "32030",
    "end": "41270"
  },
  {
    "text": "And the precise things we're\ngoing to discuss today, we're going to start off\nwith Bayesian networks of protein-protein\ninteraction prediction.",
    "start": "41270",
    "end": "47690"
  },
  {
    "text": "And then we're going to get\ninto gene expression data, at several different levels. We'll talk about\nsome basic questions, of how to compare\nthe two expression",
    "start": "47690",
    "end": "56120"
  },
  {
    "text": "vectors for a gene,\ndistance metrics. We'll talk about how to\ncluster gene expression data. The idea of\nidentifying signatures",
    "start": "56120",
    "end": "62250"
  },
  {
    "text": "of sets of genes, that\nmight be predictive of some biological property. For example, a\nsusceptibility to a disease.",
    "start": "62250",
    "end": "68694"
  },
  {
    "text": "And then we'll talk about\na number of different ways that people have\ndeveloped to try to identify gene\nregulatory networks. That often goes by\nthe name of modules.",
    "start": "68694",
    "end": "75220"
  },
  {
    "text": "I don't particularly\nlike that name. But that's what you'll\nfind in the literature. And we're going to\nfocus on a few of these,",
    "start": "75220",
    "end": "81340"
  },
  {
    "text": "that have recently been\ncompared head to head, using both synthetic and real data. And we'll see some\nof the results",
    "start": "81340",
    "end": "86659"
  },
  {
    "text": "from that head to\nhead comparison. So let's just launch into it. Remember last time we had\nstarted this unit looking",
    "start": "86660",
    "end": "93160"
  },
  {
    "text": "at the structural\npredictions for proteins. And we started talking\nabout how to predict protein-protein interactions.",
    "start": "93160",
    "end": "98900"
  },
  {
    "text": "Last time we talked about\nboth computational methods, and also experimental\ndata, that could give us",
    "start": "98900",
    "end": "104210"
  },
  {
    "text": "information about\nprotein-protein interactions. Ostensibly measuring\ndirect interactions, but we saw that there were\npossibly very, very high error",
    "start": "104210",
    "end": "110865"
  },
  {
    "text": "rates. So we needed ways of integrating\nlots of different kinds of data in a probabilistic framework so\nwe could predict for any pair",
    "start": "110865",
    "end": "117600"
  },
  {
    "text": "proteins what's the\nprobability that they interact. Not just the fact that\nthey were detected in one assay or the other.",
    "start": "117600",
    "end": "125004"
  },
  {
    "text": "And we started to talk\nabout Bayesian networks in this context. Both useful as we'll see\ntoday, for predicting",
    "start": "125004",
    "end": "131110"
  },
  {
    "text": "protein-protein\ninteractions, and also for the gene regulatory\nnetwork problem. So the Bayesian\nnetworks are a tool",
    "start": "131110",
    "end": "136820"
  },
  {
    "text": "for reasoning probabilistically. That's the fundamental purpose. And we saw that they consisted\nof a graph, the network.",
    "start": "136820",
    "end": "144040"
  },
  {
    "text": "And then the probabilities\nthat represent the probability for each edge, the conditional\nprobability tables.",
    "start": "144040",
    "end": "150440"
  },
  {
    "text": "And that we can learn\nthese from the data, either in a completely\nobjective way, where we learn both the structure\nand the probability.",
    "start": "150440",
    "end": "156830"
  },
  {
    "text": "Or where we impose the\nstructure initially, and then we simply learn\nthe probability tables.",
    "start": "156830",
    "end": "162370"
  },
  {
    "text": "And we had nodes that\nrepresented the variables. They could be\nhidden nodes, where we don't know what the true\nanswer is, and observed",
    "start": "162370",
    "end": "168979"
  },
  {
    "text": "nodes, where we do. So in our case, we're\ntrying to predict protein-protein interactions. There's some hidden\nvariable that",
    "start": "168979",
    "end": "174670"
  },
  {
    "text": "represents weather protein\nA and B truly interact. We don't know that answer. But we do know whether\nthat interaction was",
    "start": "174670",
    "end": "180780"
  },
  {
    "text": "detected in an experiment\none, two, three or 4. Those are the\neffects, the observed. And so we want to\nreason backwards",
    "start": "180780",
    "end": "186770"
  },
  {
    "text": "from the observations,\nto the hidden causes. ",
    "start": "186770",
    "end": "193170"
  },
  {
    "text": "So last time we talked about\nthe high throughput experiments, that directly\nwe're measuring out protein-protein interactions.",
    "start": "193170",
    "end": "199247"
  },
  {
    "text": "We talked about yeast two\nhybrid and affinity capture mass spec-- here\nlisted as pull-downs.",
    "start": "199248",
    "end": "205780"
  },
  {
    "text": "And those could\nbe used to predict protein-protein\ndirections, by themselves. But we want to find out\nwhat other kinds of data",
    "start": "205780",
    "end": "212000"
  },
  {
    "text": "we can use to amplify\nthese results, to give us independent information about\nwhether two proteins interact.",
    "start": "212000",
    "end": "217239"
  },
  {
    "text": "And one thing you\ncould look at is whether the expression\nof the two genes that you think might interact\nare similar.",
    "start": "217240",
    "end": "223620"
  },
  {
    "text": "So if you look over many,\nmany different conditions, you might expect\nthe two proteins that interact with\neach other, would",
    "start": "223620",
    "end": "229500"
  },
  {
    "text": "be expressed under\nsimilar conditions. Certainly if you saw\ntwo proteins that had exactly opposite\nexpression patterns,",
    "start": "229500",
    "end": "235549"
  },
  {
    "text": "you would be very unlikely to\nbelieve that they interacted. So the question is, how much\nis true at the other end",
    "start": "235550",
    "end": "241069"
  },
  {
    "text": "of the spectrum? If things are very\nhighly correlated, do they have a high\nprobability of interaction?",
    "start": "241070",
    "end": "247200"
  },
  {
    "text": "So this graph is a\nhistogram for proteins that are known to\ninteract, proteins",
    "start": "247200",
    "end": "253180"
  },
  {
    "text": "that were shown in these\nhigh throughput experiments to interact, and proteins that\nare known not to interact,",
    "start": "253180",
    "end": "258815"
  },
  {
    "text": "of how similar\nthe expression is. On the far right\nare things that have extremely different expression\npatterns, a high distance.",
    "start": "258815",
    "end": "265107"
  },
  {
    "text": "And we'll talk\nspecifically about what distance is in just a minute. But these are very dissimilar\nexpression patterns.",
    "start": "265107",
    "end": "270210"
  },
  {
    "text": "These are very similar ones. So what do you\nsee from this plot we looked at the last time?",
    "start": "270210",
    "end": "275340"
  },
  {
    "text": "We saw that the\ninteracting proteins are shifted a bit to the left. So the interacting ones\nhave a higher probability",
    "start": "275340",
    "end": "281210"
  },
  {
    "text": "of having similar\nexpression patterns than the ones don't interact. But we couldn't\ndraw any cut off,",
    "start": "281210",
    "end": "286530"
  },
  {
    "text": "and say everything with this\nlevel expression similarity is guaranteed to interact. There's no way to divide these.",
    "start": "286530",
    "end": "293617"
  },
  {
    "text": "So this will be useful in\na probabilistic setting. But by itself, it would\nnot be highly predictive. We also talked about\nevolutionary patterns,",
    "start": "293617",
    "end": "300460"
  },
  {
    "text": "and we discussed whether the\nred or the green patterns here, would be more predictive. And which one was\nit, anyone remember?",
    "start": "300460",
    "end": "306840"
  },
  {
    "text": "How many people thought the\nred was more predictive? How many the green? Right, the greens win.",
    "start": "306840",
    "end": "312410"
  },
  {
    "text": " And we talked about the\ncoevolution in other ways.",
    "start": "312410",
    "end": "318490"
  },
  {
    "text": "So the paper that, I\nthink, was one of the first to do this really\nnicely, try to predict protein-protein\ninteraction patterns using",
    "start": "318490",
    "end": "325330"
  },
  {
    "text": "Bayesian networks, is this\none from Mark Gerstein's lab. And they start off as we\ntalked about previously,",
    "start": "325330",
    "end": "331770"
  },
  {
    "text": "we need some gold\nstandard interactions, where we know two proteins\nreally do interact or don't.",
    "start": "331770",
    "end": "337150"
  },
  {
    "text": "They built their gold\nstandard data set. The positive trending\ndata, they took",
    "start": "337150",
    "end": "342189"
  },
  {
    "text": "from a database\ncalled MIPS, which is a hand-curated database\nthat digs into the literature",
    "start": "342190",
    "end": "347988"
  },
  {
    "text": "quite deeply, to find out\nwhether two proteins interact or not. And then the negative\ndata they took",
    "start": "347989",
    "end": "352990"
  },
  {
    "text": "were proteins that\nwere identified as being localized to\ndifferent parts of the cell. And this was done\nin yeast, to where",
    "start": "352990",
    "end": "358770"
  },
  {
    "text": "there is pretty good data\nfor a lot of proteins, to subcellular localization. ",
    "start": "358770",
    "end": "364700"
  },
  {
    "text": "So these are the data that\nwent into their prediction.  These were the experiments\nwe've already talked about,",
    "start": "364700",
    "end": "371890"
  },
  {
    "text": "the affinity capture mass\nspec and the yeast two hybrid. And then the other\nkinds of data they used were expression correlation,\none just talked about.",
    "start": "371890",
    "end": "379665"
  },
  {
    "text": "They also looked at\nannotations, whether proteins had the same annotation\nfor function.",
    "start": "379665",
    "end": "385870"
  },
  {
    "text": "And essentiality. So in yeast, it's\npretty easy to go through every gene\nin the genome, knock it out, and determine\nwhether that kills the cell",
    "start": "385870",
    "end": "392921"
  },
  {
    "text": "or not. So they can label\nevery gene in yeast, as to whether it's essential\nfor survival or not.",
    "start": "392921",
    "end": "399625"
  },
  {
    "text": "And you can see here, the\nnumber of interactions that were involved. And they decided\nto break this down into two separate\nprediction problems.",
    "start": "399625",
    "end": "405773"
  },
  {
    "text": "So one was an\nexperimental problem, using the four\ndifferent large scale",
    "start": "405773",
    "end": "410860"
  },
  {
    "text": "data sets in yeast from\nprotein-protein interactions, to predict expression. The other one wore\nthese other kinds",
    "start": "410860",
    "end": "417449"
  },
  {
    "text": "of data, that were less direct. And they used slightly different\nkinds of Bayesian networks. So for this one, they\nused a naive Bayes.",
    "start": "417450",
    "end": "425100"
  },
  {
    "text": "And what's the underlying\nassumption of the naive Bayes? The underlying assumption\nis that all the data",
    "start": "425100",
    "end": "430754"
  },
  {
    "text": "are independent. So we looked at this previously. We discussed how\nyou could, if you're trying to identify\nthe likelihood ratio,",
    "start": "430755",
    "end": "437830"
  },
  {
    "text": "and use it to rank things. You primarily need to\nfocus on this term.",
    "start": "437830",
    "end": "443610"
  },
  {
    "text": "Because this term will be the\nsame for every pair of proteins that you're examining. Yes? AUDIENCE: Could you state\nagain whether in a naive Bayes,",
    "start": "443610",
    "end": "451280"
  },
  {
    "text": "all data are dependent\nor independent? PROFESSOR: Independent. AUDIENCE: OK. ",
    "start": "451280",
    "end": "458267"
  },
  {
    "text": "PROFESSOR: OK. So let's actually look\nat some of their data. So in this table, they're\nlooking at the likelihood ratio",
    "start": "458267",
    "end": "464780"
  },
  {
    "text": "that two proteins\ninteract, based on whether the two\nproteins are essential. One is essential, and\none is a nonessential.",
    "start": "464780",
    "end": "471400"
  },
  {
    "text": "Both are nonessential. So that's what these\ntwo codes here mean.",
    "start": "471400",
    "end": "476610"
  },
  {
    "text": "EE, both essential. NN, both nonessential,\nand any one and the other.",
    "start": "476610",
    "end": "481615"
  },
  {
    "text": "And so they've computed\nfor all those protein pairs, how many in\ntheir gold standard, are EE, how many are\nEN, how many are NN?",
    "start": "481615",
    "end": "488660"
  },
  {
    "text": " So here are the\nnumbers for the EE.",
    "start": "488660",
    "end": "495100"
  },
  {
    "text": "There are just over 1,000, out\nof the 2,000, roughly 2,000 that are EE.",
    "start": "495100",
    "end": "500775"
  },
  {
    "text": "So that comes up with a\nprobability of being essential, given that I know\nthat you're positive. You're in the gold standard\nof roughly 50%, right?",
    "start": "500775",
    "end": "508700"
  },
  {
    "text": "And you can assume something\nsimilar for the negatives. So these are the ones that\ndefinitely don't interact.",
    "start": "508700",
    "end": "514950"
  },
  {
    "text": "So the probability of\nboth being essential, given that it's negative,\nis about 15%, 14%.",
    "start": "514950",
    "end": "521520"
  },
  {
    "text": "And so then the likelihood ratio\ncomes out to just under four. So there's a fourfold\nincrease in probability",
    "start": "521520",
    "end": "529200"
  },
  {
    "text": "that something is interacting,\ngiven that it's essential, then not.",
    "start": "529200",
    "end": "535840"
  },
  {
    "text": "And this is the table\nfor all of the terms, for all of the different things\nthat they were considering, that were not\ndirect experiments.",
    "start": "535840",
    "end": "541644"
  },
  {
    "text": "So this is the sensuality. This is expression correlation,\nwith various values for the threshold, how similar\nthe expression had to be.",
    "start": "541644",
    "end": "550590"
  },
  {
    "text": "And these are the terms from\nthe databases for annotation. And then for each\nof these, then we",
    "start": "550590",
    "end": "556870"
  },
  {
    "text": "get a likelihood ratio\nof how predictive it is. So it's kind of informative to\nlook at some of these numbers. We already saw that\nessentiality is",
    "start": "556870",
    "end": "563529"
  },
  {
    "text": "pretty weak, predicted the fact\nthat two genes are essential. It only gives you a\nslightly increased chance that they're\ninteracting than not.",
    "start": "563530",
    "end": "570120"
  },
  {
    "text": "But if two things, two genes\nhave extremely high expression correlation, then they're\nmore than a hundredfold more",
    "start": "570120",
    "end": "575220"
  },
  {
    "text": "likely to interact than not. And the numbers\nfor the annotations",
    "start": "575220",
    "end": "581270"
  },
  {
    "text": "are significantly\nless than that.  So this is a naive Bayes.",
    "start": "581270",
    "end": "587016"
  },
  {
    "text": "We're going to multiply all\nthose probabilities together. Now for the\nexperimental data, they",
    "start": "587016",
    "end": "592720"
  },
  {
    "text": "said, well, these are\nprobably not all independent. The probably that you pick\nsomething up in one two hybrid experiment,\nis probably highly",
    "start": "592720",
    "end": "599216"
  },
  {
    "text": "correlated with the\nprobability that you pick it up in another two\nhybrid experiment. And one would hope that there's\nsome correlation between things",
    "start": "599216",
    "end": "605990"
  },
  {
    "text": "are identifying in two hybrid\nand affinity caption mass spec. Although we'll see whether\nor not that's the case.",
    "start": "605990",
    "end": "612330"
  },
  {
    "text": "So they used what they refer\nto as a fully connected Bayes. And what do we mean by that? Remember, this was\nthe naive Bayes,",
    "start": "612330",
    "end": "618256"
  },
  {
    "text": "where everything is independent. So the probability\nof some observation is the product of all the\nindividual probabilities.",
    "start": "618257",
    "end": "623983"
  },
  {
    "text": "But in a fully\nconnected Bayes, we don't have that\nindependence assumption. So you need to actually\nexplicitly compute",
    "start": "623984",
    "end": "630940"
  },
  {
    "text": "what the probability\nis for an interaction, based on all the possible\noutcomes in those experiments.",
    "start": "630940",
    "end": "636139"
  },
  {
    "text": "So that's not that much harder. We simply have a table now,\nwhere these columns represent",
    "start": "636139",
    "end": "642630"
  },
  {
    "text": "each of the experimental\ndata types-- the affinity capture mass\nspec and the two hybrids.",
    "start": "642630",
    "end": "649610"
  },
  {
    "text": "Ones indicate that\nit was detected, Zero is that it's not. And then we simply look\nagain in our gold standard,",
    "start": "649610",
    "end": "654840"
  },
  {
    "text": "and see how often a protein that\nhad been detected in whatever the setting is here, in all\nof them except Ito, how often",
    "start": "654840",
    "end": "663470"
  },
  {
    "text": "was it, how many of the\ngold positives do we get? And how many of\nthe gold negatives? And then we can compute\nthe probabilities.",
    "start": "663470",
    "end": "668539"
  },
  {
    "text": " Now it's important\nto look at some of the numbers in these\ntables and dig in.",
    "start": "668539",
    "end": "674449"
  },
  {
    "text": "Because you'll see the numbers\nhere are really, really small. So they have to be\ninterpreted with caution.",
    "start": "674449",
    "end": "679770"
  },
  {
    "text": "So some of the\nthings that might not hold up with much\nlarger data sets. You might imagine the things\nthat are experimentally",
    "start": "679770",
    "end": "686036"
  },
  {
    "text": "detected in all of the\nhigh-throughput assays would be the most confident. That doesn't turn\nout to be the case.",
    "start": "686036",
    "end": "692120"
  },
  {
    "text": "So these are sorted by the\nlaw of likelihood ratio, and the best one is not 1, 1, 1.",
    "start": "692120",
    "end": "699300"
  },
  {
    "text": "It's up there. But it's not the\ntop of the pack. And that's probably just the\nstatistics of small numbers. If the databases were larger,\nexperiments were larger,",
    "start": "699300",
    "end": "706920"
  },
  {
    "text": "it probably would\nwork out that way. So any question about how\nthey formulated this problem,",
    "start": "706920",
    "end": "712530"
  },
  {
    "text": "as a Bayesian network, or\nhow they implemented it? ",
    "start": "712530",
    "end": "720520"
  },
  {
    "text": "OK. So the results then-- so once\nwe have these likelihood ratios, we can try to choose a threshold\nfor deciding what we're",
    "start": "720520",
    "end": "730050"
  },
  {
    "text": "going to consider to be a\ntrue interaction and not. So here they've plotted for\ndifferent likelihood ratio thresholds.",
    "start": "730050",
    "end": "736880"
  },
  {
    "text": "On the x-axis, how many of the\ntrue positives you get right, versus how many you get wrong. ",
    "start": "736880",
    "end": "744410"
  },
  {
    "text": "So the true positive\nover the false positive. And you can\narbitrarily decide, OK, well I want to be more-- I want\nto get more right than wrong.",
    "start": "744410",
    "end": "751930"
  },
  {
    "text": "Not a bad way to decide things. So your passing\ngrade here is 50%.",
    "start": "751930",
    "end": "757290"
  },
  {
    "text": "So if I draw a line,\na horizontal line, and wanted to get\nmore right than wrong, you'll see that any\nof the individual",
    "start": "757290",
    "end": "765600"
  },
  {
    "text": "signals that they were\nusing, essentiality, database sanitation, and so on--\nall of those fall below that.",
    "start": "765600",
    "end": "773390"
  },
  {
    "text": "So individually, they predict\nmore wrongs than rights. But if you combine the data\nusing this Bayesian network,",
    "start": "773390",
    "end": "780720"
  },
  {
    "text": "then you can choose a\nlikelihood threshold, where you do get more\nright than wrong.",
    "start": "780720",
    "end": "785740"
  },
  {
    "text": "And you can set your\nthreshold wherever you want. Similarly for the direct\nexperimental data,",
    "start": "785740",
    "end": "791670"
  },
  {
    "text": "you do better by combining--\nthese are light pink lines, than you would with any of\nthe individual data sets.",
    "start": "791670",
    "end": "798930"
  },
  {
    "text": "So this shows the utility\nof combining the data, and reasoning from the\ndata probabilistically.",
    "start": "798930",
    "end": "805360"
  },
  {
    "text": "Any questions? So we'll return to\nBayesian networks in a bit in the\ncontext of discovering",
    "start": "805360",
    "end": "814340"
  },
  {
    "text": "gene regulatory networks. So we now want to move\nto gene expression data. And the primary reason to be so\ninterested in gene expression",
    "start": "814340",
    "end": "822210"
  },
  {
    "text": "data is simply that there's a\nhuge amount of it out there. So just a short time ago\nwe passed the million mark,",
    "start": "822210",
    "end": "827820"
  },
  {
    "text": "with a number of\nexpression data sets that had been collected\nin the databases. There's much less of any other\nkind of high throughput data.",
    "start": "827820",
    "end": "834760"
  },
  {
    "text": "So if you look at proteomics\nor high-throughput genetic screens, there are\ntiny numbers, compared to gene expression data.",
    "start": "834760",
    "end": "841029"
  },
  {
    "text": "So obviously techniques for\nanalyzing gene expression data are going to play a very\nimportant role for a long time",
    "start": "841030",
    "end": "846500"
  },
  {
    "text": "to come.  Some of what I'm\ngoing to discuss today",
    "start": "846500",
    "end": "851730"
  },
  {
    "text": "is covered in your textbooks. I encourage you to look\nat text section 16.2.",
    "start": "851730",
    "end": "857071"
  },
  {
    "text": "The fundamental thing that\nwe're interested in doing, is seeing how much\nbiological knowledge",
    "start": "857072",
    "end": "862180"
  },
  {
    "text": "we can infer from the\ngene expression data. So we might imagine\nthat genes that are coexpressed under\nparticular sets and conditions,",
    "start": "862180",
    "end": "868940"
  },
  {
    "text": "have functional\nsimilarity, reflect common regulatory mechanisms,\nand our goal then, is to discover those mechanisms.",
    "start": "868940",
    "end": "874899"
  },
  {
    "text": "So fundamental to this then, any\ntime we have a pair of genes-- and we look at their\ngene expression data-- we want to decide\nhow similar they are.",
    "start": "874900",
    "end": "881710"
  },
  {
    "text": "So let's imagine that we had\nthese data for four genes. And it's a time\nseries experiment.",
    "start": "881710",
    "end": "887332"
  },
  {
    "text": "And we're looking at the\ndifferent expression levels. And we want some\nquantitative measure to decide which two\ngenes are most similar.",
    "start": "887332",
    "end": "894580"
  },
  {
    "text": "Well, it turns out\nit's a lot more subtle than we might think. So at first glance,\noh, it's pretty obvious that these two are\nthe most similar.",
    "start": "894580",
    "end": "900750"
  },
  {
    "text": "But it really depends on\nwhat kind of similarity you're asking about. So we can describe\nany expression data",
    "start": "900750",
    "end": "907930"
  },
  {
    "text": "set for any gene, is simply\na multi-dimensional vector.",
    "start": "907930",
    "end": "913930"
  },
  {
    "text": "Where this is the set\nof expression values we detected for the\nfirst gene, across all the different experimental\nconditions and so on,",
    "start": "913930",
    "end": "920670"
  },
  {
    "text": "for the second. And what would be the\nmost intuitive way of describing the\ndistance between two",
    "start": "920670",
    "end": "926410"
  },
  {
    "text": "multi-dimensional vectors? It would simply be\nEuclidean distance, right? So that's perfectly reasonable.",
    "start": "926410",
    "end": "931840"
  },
  {
    "text": "So we can decide that the\ndistance between two gene expression data sets, is\nsimply the square root",
    "start": "931840",
    "end": "937850"
  },
  {
    "text": "of the sum of the\nsquares of the distances. So we'll take the sum over all\nthe experimental conditions",
    "start": "937850",
    "end": "945075"
  },
  {
    "text": "that we've looked at. Maybe it's a time series. Maybe it's different\nperturbations. And look at the difference in\nexpression of gene A and gene",
    "start": "945075",
    "end": "952720"
  },
  {
    "text": "B in that condition, K.\nAnd then evaluating this will tell us how similar two\ngenes are in their expression",
    "start": "952720",
    "end": "960500"
  },
  {
    "text": "profiles. Well, that's a specific\nexample of a distance metric. It turns out that there's\na formal definition",
    "start": "960500",
    "end": "966845"
  },
  {
    "text": "for a distance metric. Distances have the\nfollowing properties. They're always\ngreater than zero.",
    "start": "966845",
    "end": "972149"
  },
  {
    "text": "We never have\nnegative distances. They are equal to zero under\nexactly one condition-- the two",
    "start": "972150",
    "end": "978180"
  },
  {
    "text": "data points are the same. And they're symmetric. So the distance from\nA to B is the same",
    "start": "978180",
    "end": "983430"
  },
  {
    "text": "as the distance from B to A. Now, to be a true\ndistance, then you also",
    "start": "983430",
    "end": "988810"
  },
  {
    "text": "have to satisfy the\ntriangle inequality, that the distance from\nx to z is less than",
    "start": "988810",
    "end": "994380"
  },
  {
    "text": "or equal to the sum\nof the distances through a third point. But we will find out\nthat we don't actually need that for\nsimilarity measures.",
    "start": "994380",
    "end": "1000820"
  },
  {
    "text": "So we can have either\na true distance metric for comparing gene\nexpression data sets, or similarity measures as well.",
    "start": "1000820",
    "end": "1008540"
  },
  {
    "text": "So let's go back to\nthe simple example. So we decided that the\nred and the blue genes were nearly identical, in terms\nof their distance metrics.",
    "start": "1008540",
    "end": "1015580"
  },
  {
    "text": "But that's not always\nexactly what we care about. So in biological settings,\nfrequently the absolute level of gene expression is\non some arbitrary scale.",
    "start": "1015580",
    "end": "1023779"
  },
  {
    "text": "Certainly with\nexpression arrays, it was completely arbitrary. It had to do with\nfluorescence properties, and how well probes\nhybridize to each other.",
    "start": "1023780",
    "end": "1030819"
  },
  {
    "text": "But even with mRNA,\nhow do we really know that 1,000 copies\nis fundamentally different from 1,200 copies\nof an RNA in the cell?",
    "start": "1030819",
    "end": "1038510"
  },
  {
    "text": "We don't. So we might be more interested\nin distance metrics that capture not just the\nsimilarity of these two.",
    "start": "1038510",
    "end": "1045790"
  },
  {
    "text": "But the fact that these\ntwo are also quite similar, in terms of the trajectory\nof the plot to this one.",
    "start": "1045790",
    "end": "1054930"
  },
  {
    "text": "So can we come up with measures\nthat capture this one as well? A very common one for this\nis Pearson correlation.",
    "start": "1054930",
    "end": "1060800"
  },
  {
    "text": "So in Pearson correlation,\nwe're gonna look at not just the expression of a\ngene across conditions. But we're gonna look at\nthe z-score of that gene.",
    "start": "1060800",
    "end": "1067590"
  },
  {
    "text": "So we'll take all\nof the data for all of the genes in a\nparticular condition.",
    "start": "1067590",
    "end": "1073370"
  },
  {
    "text": "And we'll compute the\nz-score by looking at the difference\nbetween the expression",
    "start": "1073370",
    "end": "1079310"
  },
  {
    "text": "of a particular gene, in\nthe average expression across the whole data set. And we're going to normalize\nit by the standard deviation.",
    "start": "1079310",
    "end": "1084780"
  },
  {
    "text": "Yes? AUDIENCE: [INAUDIBLE]\nsquare there? PROFESSOR: Yes, you're right. There should be a square there. Thank you.",
    "start": "1084780",
    "end": "1090010"
  },
  {
    "text": " So then to compute the\nPearson correlation,",
    "start": "1090010",
    "end": "1096100"
  },
  {
    "text": "we're going between\ntwo genes, A and B, we're going to take the\nsum over all experiments, that the z-score for A\nand the z-score for B,",
    "start": "1096100",
    "end": "1103920"
  },
  {
    "text": "the product of that, summed\nover all the experiments. And these values as\nwe'll see in a second,",
    "start": "1103920",
    "end": "1109747"
  },
  {
    "text": "are going to range\nfrom plus 1, which would be a perfect\ncorrelation, to minus 1, which would be a perfect\nanti-correlation.",
    "start": "1109747",
    "end": "1117150"
  },
  {
    "text": "And then we're going to find the\ndistance is 1 minus this value. So things that are\nperfectly correlated then,",
    "start": "1117150",
    "end": "1122809"
  },
  {
    "text": "would have an r of zero. And things that\nare anti-correlated would have a large one.",
    "start": "1122810",
    "end": "1128250"
  },
  {
    "text": "So if we take a\nlook at these two obviously by Euclidean\ndistance, they'd be quite different\nfrom each other. But the z-scores have\nconverted the expression values",
    "start": "1128250",
    "end": "1135140"
  },
  {
    "text": "into z-scores over\nhere, you can see that the z-scores\nobviously, this one is the most negative\nof all of the ones.",
    "start": "1135140",
    "end": "1141110"
  },
  {
    "text": "And this as the lowest\none in all of these. This one's the highest. And similarly for the red\none, lowest to the highest.",
    "start": "1141110",
    "end": "1146340"
  },
  {
    "text": "So the z-scores track very well. And when I take the\nproduct of this, the signs of the z-score for\nA and B are always the same.",
    "start": "1146340",
    "end": "1153280"
  },
  {
    "text": "So I summed the product of the\nz-scores, I get a large number. And then the\nnormalization guarantees that it comes out to one.",
    "start": "1153280",
    "end": "1160570"
  },
  {
    "text": "And so the red\nand blue here will have a very high\ncorrelation coefficient. In this case, it's going\nto be an r correlation",
    "start": "1160570",
    "end": "1167590"
  },
  {
    "text": "coefficient of 1. Whereas compared to this one,\nwhich is relatively flat,",
    "start": "1167590",
    "end": "1173220"
  },
  {
    "text": "the correlation coefficient\nwill be approximately zero. Any questions on that? ",
    "start": "1173220",
    "end": "1184130"
  },
  {
    "text": "So what about, say\nthe blue and the red? Well, their z-scores\nare going to have almost the opposite\nsign every single time.",
    "start": "1184130",
    "end": "1190480"
  },
  {
    "text": "And so that's going to add\nup to a large negative value. So for these, they'll be\nhighly anti-correlated. So A, the blue and the red,\nhave a correlation coefficient",
    "start": "1190480",
    "end": "1200220"
  },
  {
    "text": "of minus 1. OK. So we have these\ntwo different ways of computing distance measures.",
    "start": "1200220",
    "end": "1206080"
  },
  {
    "text": "We can compute the\nEuclidean distance, which would make the\nred and blue the same,",
    "start": "1206080",
    "end": "1211270"
  },
  {
    "text": "but treat the green one as\nbeing completely different. Or we have the\ncorrelation, which would group all of these\ntogether, as being similar.",
    "start": "1211270",
    "end": "1217579"
  },
  {
    "text": "What you want to do is going\nto depend on your setting. If you look in your\ntextbook, you'll see a lot of other definitions\nof distance as well.",
    "start": "1217579",
    "end": "1225015"
  },
  {
    "text": "Now what if you're missing\na particular data point? This used to be a lot more\nof a problem with arrays than it is with [? RNAC. ?]\nWith arrays, you'd often",
    "start": "1225015",
    "end": "1233430"
  },
  {
    "text": "have dirt on the array, that\nit actually would literally cover up spots.",
    "start": "1233430",
    "end": "1238890"
  },
  {
    "text": "But you have a bunch of choices. The most extreme would\njust be to ignore that row or column of your\nmatrix across old data sets.",
    "start": "1238890",
    "end": "1246659"
  },
  {
    "text": "That's usually not\nwhat we want to do. You could put in some\narbitrary small value. But frequently we will do what's\ncalled imputing, where we'll",
    "start": "1246660",
    "end": "1254450"
  },
  {
    "text": "try to identify the\ngenes that have the most similar expression, and replace\nthe value for the missing",
    "start": "1254450",
    "end": "1259740"
  },
  {
    "text": "one with a value from\nthe ones that we do know. ",
    "start": "1259740",
    "end": "1265160"
  },
  {
    "text": "Distance metrics,\npretty straightforward. Now we want to\nuse these distance metrics to actually\ncluster the data.",
    "start": "1265160",
    "end": "1272659"
  },
  {
    "text": "And what's the idea here? That if we look across\nenough data sets, we might find certain groups of\ngenes that function similarly",
    "start": "1272659",
    "end": "1279659"
  },
  {
    "text": "across all those\ndata sets, that might be revealing as to their\nbiological function.",
    "start": "1279660",
    "end": "1284674"
  },
  {
    "text": "So this is an example of an\nunsupervised learning problem. We don't know what the\nclasses are, before we go in. We don't even know\nhow many there are.",
    "start": "1284674",
    "end": "1291110"
  },
  {
    "text": "We want to learn from the data. This is a very large\narea of machine learning. We're just gonna\nscrape the surface.",
    "start": "1291110",
    "end": "1297612"
  },
  {
    "text": "Some of you may be\nfamiliar with the fact that these kinds of\nmachine learning algorithms are used widely\noutside of biology.",
    "start": "1297612",
    "end": "1302660"
  },
  {
    "text": "They're used by\nNetflix to tell you what would movie to choose next. Or Amazon, to try to\nsell you new products.",
    "start": "1302660",
    "end": "1308430"
  },
  {
    "text": "And all the advertisers who send\npop-up ads on your computer.",
    "start": "1308430",
    "end": "1314630"
  },
  {
    "text": "But in our biological\nsetting then, we have our gene expression\ndata, collected possibly over very large\nnumbers of conditions.",
    "start": "1314630",
    "end": "1320632"
  },
  {
    "text": "And we want to find\ngroups of genes that have some similarity. This is a figure from one of\nthese very early papers, that",
    "start": "1320632",
    "end": "1327720"
  },
  {
    "text": "sort of establish how\npeople present these datas. So you'll almost always see\nthe same kind of presentation.",
    "start": "1327720",
    "end": "1333020"
  },
  {
    "text": "Typically you'll get a heat\nmap, where genes are rows. And the different\nexperiments here time,",
    "start": "1333020",
    "end": "1338789"
  },
  {
    "text": "but it could be different\nperturbations, are the columns. And genes that go up\nin expression are red,",
    "start": "1338790",
    "end": "1344420"
  },
  {
    "text": "and genes ago down in\nexpression are green. And apologies to anyone\nwho's colorblind.",
    "start": "1344420",
    "end": "1349520"
  },
  {
    "text": "But that's just what the\nconvention has become. OK, so then why cluster?",
    "start": "1349520",
    "end": "1355280"
  },
  {
    "text": "So if we cluster\nacross the rows, then we'll get sets of genes\nthat potentially behave--",
    "start": "1355280",
    "end": "1360397"
  },
  {
    "text": "that hopefully if\nwe do this properly, behave similarly across\ndifferent subsets of the experiments.",
    "start": "1360397",
    "end": "1366630"
  },
  {
    "text": "And those might represent\nsimilar functions. And if we cluster\nthe columns, then we get different experiments\nthat show similar responses.",
    "start": "1366630",
    "end": "1374245"
  },
  {
    "text": "So that might be in this\ncase, different times that are similar. Hopefully those are ones\nthat are close to each other. But if we have lots\nof different patients,",
    "start": "1374245",
    "end": "1380760"
  },
  {
    "text": "as we'll see in a\nsecond, they might represent patients who have a\nsimilar version of a disease.",
    "start": "1380760",
    "end": "1386670"
  },
  {
    "text": "And in fact, the clustering\nof genes does work. So even in this\nvery early paper, they were able to identify a\nbunch of subsets of genes that",
    "start": "1386670",
    "end": "1395345"
  },
  {
    "text": "showed similar expression\nat different time points, and turned out to be enriched\nin different categories. These ones were enriched in\ncholesterol biosynthesis,",
    "start": "1395345",
    "end": "1402640"
  },
  {
    "text": "whereas these were enriched\nin wound healing, and so on. So how do you actually\ndo clustering?",
    "start": "1402640",
    "end": "1408990"
  },
  {
    "text": "This kind of clustering\nis called hierarchical. That's pretty straightforward. There are two versions of\nhierarchical clustering.",
    "start": "1408990",
    "end": "1415590"
  },
  {
    "text": "There's what's called\nagglomerative and divisive. In agglomerative, you start\noff with each data point",
    "start": "1415590",
    "end": "1421910"
  },
  {
    "text": "in its own cluster. And then you search for the\nmost similar data point to it, and you group those together.",
    "start": "1421910",
    "end": "1427890"
  },
  {
    "text": "And you keep doing\nthat iteratively, building up larger\nand larger clusters.",
    "start": "1427890",
    "end": "1433430"
  },
  {
    "text": "So we've discussed how to\ncompare our individual genes. But you should be\nable to, right now,",
    "start": "1433430",
    "end": "1439570"
  },
  {
    "text": "to find, if I gave you\nthe vector of expression for a single gene, to find\nthe other genes in the data set that's most similar,\nby either say, Euclidean",
    "start": "1439570",
    "end": "1446810"
  },
  {
    "text": "or Pearson correlation,\nor what have you. But once you've grouped\ntwo genes together,",
    "start": "1446810",
    "end": "1452440"
  },
  {
    "text": "how do you decide\nwhether a third gene is similar to those two? So now we have to\nmake some choices.",
    "start": "1452440",
    "end": "1457670"
  },
  {
    "text": "And so there are number\nof different choices that are commonly made. So let's say these are our data.",
    "start": "1457670",
    "end": "1463010"
  },
  {
    "text": "We've got these two\nclusters, Y and Z. And each circle represents a\ndata point in those clusters.",
    "start": "1463010",
    "end": "1470260"
  },
  {
    "text": "So we've got four\ngenes in each cluster. Now we want to decide\non a distance measure to compare cluster Y to\ncluster Z. So what could we do?",
    "start": "1470260",
    "end": "1478508"
  },
  {
    "text": "So what are some possibilities? What might you do? ",
    "start": "1478509",
    "end": "1485370"
  },
  {
    "text": "AUDIENCE: We could take\nthe average of all points. PROFESSOR: You could take the\naverage of all points, right. What else could you do?",
    "start": "1485370",
    "end": "1491820"
  },
  {
    "text": "Only a limited number\nof possibilities. AUDIENCE: Centroid? PROFESSOR: Yeah,\nso centroid, you could take some sort\nof average, right.",
    "start": "1491820",
    "end": "1498280"
  },
  {
    "text": "Any other possibilities? AUDIENCE: You can\npick a representative from each set [INAUDIBLE].",
    "start": "1498280",
    "end": "1503932"
  },
  {
    "text": "PROFESSOR: So you could pick\na representative, right? How would you decide in advance\nwhat that would be though? So maybe you have\na way, maybe not.",
    "start": "1503932",
    "end": "1510875"
  },
  {
    "text": "And what other\npossibilities are there? Yeah? AUDIENCE: Measure all\nthe distances [INAUDIBLE]",
    "start": "1510875",
    "end": "1516865"
  },
  {
    "text": "to all the nodes in the other. PROFESSOR: Right. So you could do all to all. What else could you do? ",
    "start": "1516865",
    "end": "1523445"
  },
  {
    "text": "You can take the minimum\nof all those values. You can take the maximum\nof all those values. And we'll see that all those\nare things that people do.",
    "start": "1523445",
    "end": "1529221"
  },
  {
    "text": "So this clustering,\nthere are already rather uninformative\nterms for some",
    "start": "1529221",
    "end": "1536560"
  },
  {
    "text": "of these kinds of decisions. So it's called\nsingle linkage, is you decide that the distance\nbetween two clusters",
    "start": "1536560",
    "end": "1542260"
  },
  {
    "text": "is based on the minimum distance\nbetween any member of cluster Y and any member of cluster Z.",
    "start": "1542260",
    "end": "1548950"
  },
  {
    "text": "Complete linkage takes\nthe maximum distance.",
    "start": "1548950",
    "end": "1554480"
  },
  {
    "text": "And then the extremely\nunfortunately named Unweighted Pair Group Method\nusing Centroids-- UPGMC,",
    "start": "1554480",
    "end": "1562260"
  },
  {
    "text": "I won't try to say\nthat very often-- takes the centroid, which was an\nearly suggestion from the class.",
    "start": "1562260",
    "end": "1569820"
  },
  {
    "text": "And then the UPGMA,\nUnweighted Pair Group Method with Arithmetic Mean,\ntakes the average",
    "start": "1569820",
    "end": "1576869"
  },
  {
    "text": "of all the distances,\nall suggestions that people have made. So when would you use\none versus the other? Well, a priori, you\ndon't necessarily know.",
    "start": "1576869",
    "end": "1583323"
  },
  {
    "text": "But it's good to know\nhow they'll behave. So what do you imagine\nis going to happen if you use single linkage,\nversus complete linkage.",
    "start": "1583323",
    "end": "1591250"
  },
  {
    "text": "Remember, single linkage\nis the minimum distance. And complete linkage is\nthe maximum distance. So what's going to\nhappen in this case,",
    "start": "1591250",
    "end": "1596710"
  },
  {
    "text": "if I use the minimum distance. Which two groups will I combine? ",
    "start": "1596710",
    "end": "1603269"
  },
  {
    "text": "AUDIENCE: The blue and the red. PROFESSOR: The blue\nand the red, right? Whereas if I use the\nmaximum distance,",
    "start": "1603269",
    "end": "1608420"
  },
  {
    "text": "then I'll combine the\ngreen and the red. So it's important\nto recognize, then, that the single linkage has this\nproperty of chaining together",
    "start": "1608420",
    "end": "1617590"
  },
  {
    "text": "clusters, based on points\nthat are near each other. Whereas the complete linkage\nis resistant to grouping things",
    "start": "1617590",
    "end": "1624880"
  },
  {
    "text": "together, if they have outliers. So they'll behave differently. Now, if your data are\ncompact, and you really do have tight clusters,\nit's not going",
    "start": "1624880",
    "end": "1631810"
  },
  {
    "text": "to matter too much\nwould you use. But in most biological settings,\nwe're dealing with much noise, there's data. So you actually will\nget different results",
    "start": "1631810",
    "end": "1638470"
  },
  {
    "text": "based on this. And as far as I know, there's\nno really principal way to figure out if you have no\nprior knowledge, which to use.",
    "start": "1638470",
    "end": "1646090"
  },
  {
    "text": "Now all of these\nhierarchical clustering come with what's\ncalled a dendogram. And you'll see these at the\ntop of all the clustering.",
    "start": "1646090",
    "end": "1654280"
  },
  {
    "text": "And this represents\nthe process by which the data were clustered. So the things that\nare most similar",
    "start": "1654280",
    "end": "1659606"
  },
  {
    "text": "are most tightly connected\nin this dendogram. So these two data\npoints, one and two, you have to go up very little in the\ny-axis, to get from one to two.",
    "start": "1659606",
    "end": "1669620"
  },
  {
    "text": "Whereas if you want\nto go from one to 16, you have to traverse\nthe entire dendogram.",
    "start": "1669620",
    "end": "1675080"
  },
  {
    "text": "So the distance\nbetween two samples is how far vertically you have\nto go to connect between them.",
    "start": "1675080",
    "end": "1680680"
  },
  {
    "text": "Now the good things\nare that the dendogram is, you can then understand\nthe clustering of the data.",
    "start": "1680680",
    "end": "1687350"
  },
  {
    "text": "So I can cut this dendogram\nat any particular distance, and get clearly divisions\namong my data sets.",
    "start": "1687350",
    "end": "1693230"
  },
  {
    "text": "So if I cut here at\nthis distance level, then I have two groups. One small, one\nconsisting of these data.",
    "start": "1693230",
    "end": "1698755"
  },
  {
    "text": "And one large, one\nconsisting of these. Whereas if I cut down here, I\nhave more groups of my data.",
    "start": "1698755",
    "end": "1703880"
  },
  {
    "text": "So it doesn't require me in\nadvance to know how many groups I have. I can look at the\ndendogram and infer it.",
    "start": "1703880",
    "end": "1709940"
  },
  {
    "text": "The one risk is that you\nalways get a dendogram that's hierarchical, regardless of\nif the data were hierarchical",
    "start": "1709940",
    "end": "1715510"
  },
  {
    "text": "or not. So it's more a reflection of\nhow you did your clustering than any fundamental\nstructure of the data.",
    "start": "1715510",
    "end": "1721180"
  },
  {
    "text": "So the fact that you get\na hierarchical dendogram means really nothing\nabout your data.",
    "start": "1721180",
    "end": "1726835"
  },
  {
    "text": "It's simply a tool\nthat you can use to try to divide it up\ninto different groups.",
    "start": "1726835",
    "end": "1732450"
  },
  {
    "text": "Any questions on the\nhierarchical clustering? ",
    "start": "1732450",
    "end": "1738717"
  },
  {
    "text": "Yes?  AUDIENCE: If each data\npoint is its own cluster,",
    "start": "1738717",
    "end": "1743993"
  },
  {
    "text": "then won't that be consistent\nacross, like, single linkage,",
    "start": "1743993",
    "end": "1749482"
  },
  {
    "text": "complete linkage-- like,\nwhy would you cluster? Does that question make sense? Like if you cut it down below,\nthen haven't you minimized--",
    "start": "1749482",
    "end": "1760853"
  },
  {
    "text": "don't you successively\nminimize the variance, I guess, up to your clusters, by--",
    "start": "1760854",
    "end": "1767394"
  },
  {
    "text": "PROFESSOR: So if I cut\nit at the lowest level, everybody is their own cluster. That's true. Right. I'm interested in\nfinding out whether there",
    "start": "1767394",
    "end": "1774011"
  },
  {
    "text": "are genes that behave\nsimilarly across the data sets. Or-- AUDIENCE: My question\nis, how would you go about determining how\nmany clusters your want?",
    "start": "1774011",
    "end": "1779880"
  },
  {
    "text": "PROFESSOR: Oh, OK. So we'll come to\nthat in a second. So hierarchical clustering,\nyou don't actually have any objective\nway of doing that.",
    "start": "1779880",
    "end": "1785869"
  },
  {
    "text": "But we'll talk about\nother means right now, where it's a little bit clearer. But actually\nfundamentally, there",
    "start": "1785869",
    "end": "1790880"
  },
  {
    "text": "aren't a lot of good ways\nof knowing a priori what the right number of clusters is. But we'll look at some\nmeasures in a second that help.",
    "start": "1790880",
    "end": "1797090"
  },
  {
    "text": " So hierarchical clustering,\nas your question implies,",
    "start": "1797090",
    "end": "1803270"
  },
  {
    "text": "doesn't really tell you how\nmany clusters there are. Another approach is\nto decide in advance how many clusters you expect.",
    "start": "1803270",
    "end": "1810000"
  },
  {
    "text": "And then see whether you can\nget the data of the group into that number or not. And an example of\nthat is something",
    "start": "1810000",
    "end": "1815320"
  },
  {
    "text": "called k-means clustering. So the nice thing\nabout it, is it does give you the\nsharp divisions. But again if you\nchose k incorrectly,",
    "start": "1815320",
    "end": "1821760"
  },
  {
    "text": "we'll see in a\nsecond, you will get-- you'll never less\nstill get K-clusters. So K refers the\nnumber of clusters",
    "start": "1821760",
    "end": "1828330"
  },
  {
    "text": "that you tell the algorithm\nyou expect to get. So you specify that in advance.",
    "start": "1828330",
    "end": "1833340"
  },
  {
    "text": "And then you try to\nfind a set of clusters that minimizes the distance. So everybody's assigned\nto a particular cluster,",
    "start": "1833340",
    "end": "1840540"
  },
  {
    "text": "and the center of that cluster. Is that clear? So that's what these\nequations represent.",
    "start": "1840540",
    "end": "1845959"
  },
  {
    "text": "So the center of the\ncluster, the centroid, is just the average coordinates,\nover all the components of that cluster.",
    "start": "1845959",
    "end": "1852180"
  },
  {
    "text": "And we're trying to find\nthis set of clusters, C, that minimizes the sum of\nthe square of the distances",
    "start": "1852180",
    "end": "1860110"
  },
  {
    "text": "between each member of that\ncluster and the centroid. Any questions on how\nwe're doing this?",
    "start": "1860110",
    "end": "1867720"
  },
  {
    "text": "OK. All right. So what's the actual algorithm? That's remarkably simple. I'm choosing that initial\nset of random positions.",
    "start": "1867720",
    "end": "1876470"
  },
  {
    "text": "And then I have the simple loop,\nI repeat until convergence.",
    "start": "1876470",
    "end": "1881679"
  },
  {
    "text": "For every point, I assign\nit to the nearest centroid. So if my starting\ncentroids would be circles,",
    "start": "1881680",
    "end": "1889966"
  },
  {
    "text": "I look at every data\npoint, and I ask, how close is it to\nany one of these? That's what the boundaries\nare, defined by these lines.",
    "start": "1889967",
    "end": "1895659"
  },
  {
    "text": "So everything above this\nline belongs to the centroid. Everything over here\nbelongs to this centroid.",
    "start": "1895660",
    "end": "1901290"
  },
  {
    "text": "So I divide the data up by which\ncentroid you are closest to. And I assign you\nto that centroid.",
    "start": "1901290",
    "end": "1907110"
  },
  {
    "text": "That's step one. And step two, I\ncompute new centroids. And that's what these\ntriangles represent.",
    "start": "1907110",
    "end": "1913120"
  },
  {
    "text": "So after I did\nthat partitioning, it turns out that most\nof the things that were assigned to the triangular\ncluster live over here.",
    "start": "1913120",
    "end": "1920540"
  },
  {
    "text": "So the centroid moves\nfrom being here to here. And I iterate this process.",
    "start": "1920540",
    "end": "1926360"
  },
  {
    "text": "That's the entire K-means\nclustering algorithm. So here's an example\nwhere I generated data",
    "start": "1926360",
    "end": "1932670"
  },
  {
    "text": "from three [? calcines. ?]\nI chose initial data points, which are the circles.",
    "start": "1932670",
    "end": "1938580"
  },
  {
    "text": "I follow that protocol. Here's the first step. It computes new triangles. Second step, and\nthen it converges.",
    "start": "1938580",
    "end": "1945100"
  },
  {
    "text": "The distance stops changing. ",
    "start": "1945100",
    "end": "1950841"
  },
  {
    "text": "Now this question's\nalready come up. So what happens if you\nchoose the wrong K? So I believe there\nare three clusters.",
    "start": "1950841",
    "end": "1957268"
  },
  {
    "text": "And really that's not the case. So what's going to happen? So in this data set,\nthere really were. How many, there really\nwere five clusters.",
    "start": "1957269",
    "end": "1965710"
  },
  {
    "text": "Here, they're\nclustered correctly. What if I told the\nalgorithm to do K-means clustering\nwith a K of three?",
    "start": "1965710",
    "end": "1971826"
  },
  {
    "text": "It would still find a way to\ncome up with three clusters. So now it's grouped these\ntwo things, which are clearly generated from different\n[? calcines ?] scenes together.",
    "start": "1971826",
    "end": "1979010"
  },
  {
    "text": "It's grouped these two,\nwhich were generated from different [? calcines ?]\ntogether, and so on. All right. So K-means clustering\nwill do what",
    "start": "1979010",
    "end": "1985270"
  },
  {
    "text": "you tell it to do, regardless of\nwhether that's the right answer or not. And if you tell it there are\nmore clusters than you expect-- than really are\nthere, then it'll",
    "start": "1985270",
    "end": "1991549"
  },
  {
    "text": "start chopping up well-defined\nclusters into sub-clusters. So here it split this elongated\none into two sub-clusters.",
    "start": "1991550",
    "end": "1999660"
  },
  {
    "text": "It split this one\narbitrarily into two. Just so it gets the final\nnumber that we asked for.",
    "start": "1999660",
    "end": "2005677"
  },
  {
    "text": "Then how do you know what to do? Well, as I said, you don't--\nthere's no guarantee to know. But one thing you can\ndo is make this kind",
    "start": "2005677",
    "end": "2011670"
  },
  {
    "text": "of plot, which shows for\ndifferent values of K on the x-axis, the sum of the\ndistances within the cluster.",
    "start": "2011670",
    "end": "2020500"
  },
  {
    "text": "So the distance to the\ncentroid within each cluster on the y-axis. And as I increase the number\nof K's, when I'm correctly",
    "start": "2020500",
    "end": "2027489"
  },
  {
    "text": "[? purchasing ?] my\ndata, when there really are more subgroups than\nI've already defined, then I'll see big drops.",
    "start": "2027489",
    "end": "2033910"
  },
  {
    "text": "So I go from saying there are\ntwo to three in that case. I get a big drop in the distance\nbetween members of the cluster.",
    "start": "2033910",
    "end": "2040189"
  },
  {
    "text": "Because I'm no longer including\na data point over here. And in this cluster, with a\ndata point in that cluster.",
    "start": "2040189",
    "end": "2046010"
  },
  {
    "text": "But once I go beyond the\ncorrect number, which was five, you see that the benefits\nreally start to trail off.",
    "start": "2046010",
    "end": "2051919"
  },
  {
    "text": "So there's an\ninflection point here. There's an elbow-- sometimes\nit's called an elbow plot.",
    "start": "2051920",
    "end": "2057199"
  },
  {
    "text": "After I go past\nthe right number, I get less and less benefit\nfrom each additional clustering.",
    "start": "2057199",
    "end": "2062940"
  },
  {
    "text": "So this gives us\nan empirical way of choosing approximately\na correct value for K.",
    "start": "2062940",
    "end": "2071739"
  },
  {
    "text": "Any questions on K-means? Yes? AUDIENCE: Does K-means\nrecapitulate the clusters",
    "start": "2071739",
    "end": "2076820"
  },
  {
    "text": "that you would\nget if you cut off your dendogram from hierarchical\nclustering at a certain level? PROFESSOR: Not necessarily.",
    "start": "2076820",
    "end": "2083143"
  },
  {
    "text": "AUDIENCE: OK. But maybe. I don't know. It sort of seems to me\nas if you picked a level",
    "start": "2083143",
    "end": "2088590"
  },
  {
    "text": "where you have a certain\nnumber of clusters, that that's similar, at least by\ncentroid, by using the center? PROFESSOR: Yeah, I think because\nof the way that you do it,",
    "start": "2088590",
    "end": "2096043"
  },
  {
    "text": "you're not even guaranteed\nto have a level, where you have exactly the\nright-- other questions?",
    "start": "2096043",
    "end": "2101725"
  },
  {
    "text": " Yes? AUDIENCE: Could you\njust very quickly",
    "start": "2101725",
    "end": "2107593"
  },
  {
    "text": "go over how you\ninitialized where the starting points\nare, and the break ups? PROFESSOR: All right,\nso the question is how do you initialize\nthe starting points?",
    "start": "2107593",
    "end": "2113470"
  },
  {
    "text": "In fact, you have to make some\narbitrary decisions about how the initialize the\nstarting points. So they're usually\nchose in a random.",
    "start": "2113470",
    "end": "2118900"
  },
  {
    "text": "And you will get\ndifferent results, depending on how you do that. So that's another--\nso when you do it,",
    "start": "2118900",
    "end": "2123920"
  },
  {
    "text": "it's non-deterministic\nin that sense. And you often want to\ninitialize multiple times. And make sure you\nget similar results.",
    "start": "2123920",
    "end": "2130390"
  },
  {
    "text": "Very good question. And in fact, that\nwas not a set up. But what happens if you\nchoose pathologically bad",
    "start": "2130390",
    "end": "2137690"
  },
  {
    "text": "initial conditions? So you have the potential to\nconverge to the right answer.",
    "start": "2137690",
    "end": "2142859"
  },
  {
    "text": "But you're not guaranteed to\nconverge to the right answer. So here's an example where\nI had-- I guess there really",
    "start": "2142860",
    "end": "2150510"
  },
  {
    "text": "are three clusters in the data. I chose [INAUDIBLE]\nthree, but I stuck all my initial coordinates down\nin the lower right-hand corner.",
    "start": "2150510",
    "end": "2157270"
  },
  {
    "text": "And then when I do the\nclustering, if things go well,",
    "start": "2157270",
    "end": "2163312"
  },
  {
    "text": "I get the right answer. But we're not guaranteed. ",
    "start": "2163312",
    "end": "2171070"
  },
  {
    "text": "But one thing we are guaranteed,\nis we always get convergence. So the algorithm will converge.",
    "start": "2171070",
    "end": "2176210"
  },
  {
    "text": "Because at each\nstep, it's either reducing the objective function,\nor it's leaving it the same. So we're guaranteed convergence.",
    "start": "2176210",
    "end": "2182460"
  },
  {
    "text": "But it may be as we've seen\npreviously in other settings, we may end up with local\nminimum, rather than the global optimum.",
    "start": "2182460",
    "end": "2188224"
  },
  {
    "text": "And the way to fix\nthat then would be to initialize again,\nwith new starting positions.",
    "start": "2188224",
    "end": "2193234"
  },
  {
    "text": " Other questions? ",
    "start": "2193235",
    "end": "2204229"
  },
  {
    "text": "What about a setting like this? Where we've got two\nwell-defined clusters, and somebody who lives\nstraight in the middle.",
    "start": "2204229",
    "end": "2210260"
  },
  {
    "text": "So what's the\nalgorithm going to do? Well, sometimes it'll put it\nin one side, of one cluster.",
    "start": "2210260",
    "end": "2215640"
  },
  {
    "text": "And sometimes it'll end\nup in the other side. So an alternative to\nK-means clustering, which has to make one or the\nother arbitrary decision,",
    "start": "2215640",
    "end": "2223295"
  },
  {
    "text": "is something that's called\nfuzzy K-means, which can put something\nactually literally, membership into both clusters.",
    "start": "2223295",
    "end": "2230866"
  },
  {
    "text": "And it's very similar in\nstructure to the K-means, with one important\ndifference, which is a membership variable,\nthat tells you for every data",
    "start": "2230866",
    "end": "2237760"
  },
  {
    "text": "point, how much it belongs\nto the cluster one, cluster two, cluster three, and so on. ",
    "start": "2237760",
    "end": "2245132"
  },
  {
    "text": "So in both algorithms,\nwe start off by choosing initial\npoints as a cluster means, and looping through\neach of them.",
    "start": "2245132",
    "end": "2251230"
  },
  {
    "text": "Now previously, we would make\na hard assignment of each data point x sub i to\na single cluster.",
    "start": "2251230",
    "end": "2258650"
  },
  {
    "text": "And here we're going to\ncalculate the probability that each data point\nbelongs to a cluster. And that's where you\nget the fuzziness,",
    "start": "2258650",
    "end": "2264620"
  },
  {
    "text": "because you could have a non\nunit, or a nonzero probability, belonging to any\nof the clusters.",
    "start": "2264620",
    "end": "2271150"
  },
  {
    "text": "And now we're going, K-means,\nwe recalculated the mean value, by just looking at the average\nof everybody in that cluster.",
    "start": "2271150",
    "end": "2279550"
  },
  {
    "text": "Now in fuzzy K-means, we don't\nhave everybody in the cluster. Because everybody belongs\npartially to the cluster. So we're going to take\na weighted average.",
    "start": "2279550",
    "end": "2287170"
  },
  {
    "text": "So here are the details\nof how you do that. In K-means, we are\nminimizing this function. We were trying to decide the\nclass structure, the class",
    "start": "2287170",
    "end": "2294819"
  },
  {
    "text": "memberships, that would minimize\nthe distance of every member of that cluster, to the defined\ncentroid of that cluster.",
    "start": "2294820",
    "end": "2302769"
  },
  {
    "text": "Here it looks almost the same. Except we now have\nthis new variable, mu, which is the membership.",
    "start": "2302770",
    "end": "2307890"
  },
  {
    "text": "It's the membership of\npoint j, in cluster i. ",
    "start": "2307890",
    "end": "2314949"
  },
  {
    "text": "So I'm trying to minimize\na very similar function. But now if mu is one--\nif all my mus are one,",
    "start": "2314949",
    "end": "2321019"
  },
  {
    "text": "then what do I get? K-means, right? But as soon as the mus are\nallowed to vary from one, they can be between\nzero and one,",
    "start": "2321020",
    "end": "2327280"
  },
  {
    "text": "then points can\ncontribute more or less. So that point there was stuck in\nthe middle of the two clusters, if it had a mu of\n0.5 for each, it",
    "start": "2327280",
    "end": "2334369"
  },
  {
    "text": "would contribute half to each. And then both the\ncentroids would move a little bit\ntowards the middle. ",
    "start": "2334370",
    "end": "2341920"
  },
  {
    "text": "So what's the\nresult of K-means-- I'm sorry, fuzzy\nK-means clustering? We still get K clusters. But now every gene or every\nobject that we're clustering",
    "start": "2341920",
    "end": "2350730"
  },
  {
    "text": "has a partial membership. So here's an example\nof that, where they did K-means\nclustering, with these six",
    "start": "2350730",
    "end": "2357339"
  },
  {
    "text": "different clusters. But now every\nprofile, every gene, has a color associated with it,\nthat represents this mu value.",
    "start": "2357339",
    "end": "2366050"
  },
  {
    "text": "Whether it goes from zero to\none, with these rainbow colors, to the things that\nare reddish, or pink--",
    "start": "2366050",
    "end": "2372570"
  },
  {
    "text": "those are the high\nconfidence things that are very strongly,\nonly in that cluster. Whereas the things that are\nmore towards the yellow end",
    "start": "2372570",
    "end": "2377895"
  },
  {
    "text": "of the spectrum are\npartially in this cluster and partially in other clusters.",
    "start": "2377895",
    "end": "2383450"
  },
  {
    "text": "Questions? Any questions? ",
    "start": "2383450",
    "end": "2394250"
  },
  {
    "text": "So K-means, we've defined in\nterms of Euclidean distance. And that has clear advantages,\nin terms of computing things",
    "start": "2394250",
    "end": "2402530"
  },
  {
    "text": "very easily. But it has some\ndisadvantages as well. So one of the disadvantages\nis because we're",
    "start": "2402530",
    "end": "2408010"
  },
  {
    "text": "using the squared\ndistance, then outliers have a very big effect. Because I'm squaring the\ndifference between vectors.",
    "start": "2408010",
    "end": "2417480"
  },
  {
    "text": "That may not be the worst thing. But they also\nrestrict us to things for which we can\ncompute a centroid.",
    "start": "2417480",
    "end": "2422700"
  },
  {
    "text": "We have to have data\nthat are-- four or more, you can actually\ncompute the mean value of all members of the cluster.",
    "start": "2422700",
    "end": "2428820"
  },
  {
    "text": "Sometimes you want\nto cluster things that we only have\nqualitative data. Where instead of having\na distance measure, we have similarity.",
    "start": "2428820",
    "end": "2434559"
  },
  {
    "text": "This doesn't come up\nquite as often in-- well, it certainly doesn't come\nup in gene expression data or [? RNAC. ?] But you can\nimagine more qualitative data,",
    "start": "2434560",
    "end": "2442030"
  },
  {
    "text": "where you ask people\nabout similarity between different things\nor behavioral features,",
    "start": "2442030",
    "end": "2448150"
  },
  {
    "text": "where you know the similarity\nbetween two objects. But you have no way of\ncalculating the average object.",
    "start": "2448150",
    "end": "2453600"
  },
  {
    "text": "One setting that you might\n[INAUDIBLE] have looked at-- if you're trying to\ncluster say, sequence motifs",
    "start": "2453600",
    "end": "2459030"
  },
  {
    "text": "that you've computed\nwith the EM algorithm. So what's the average\nsequence motif? That doesn't necessarily\nrepresent any true object,",
    "start": "2459030",
    "end": "2465870"
  },
  {
    "text": "right? You might be better off--\nyou can calculate it. But it doesn't mean anything. You might be better\noff calculating",
    "start": "2465870",
    "end": "2471140"
  },
  {
    "text": "using rather than the\naverage motif, the most central of the motifs that\nyou actually observed.",
    "start": "2471140",
    "end": "2477870"
  },
  {
    "text": "So that would be called\na medoid, or an exemplar. It's a member of your cluster\nthat's closest to the middle, even if it it's not\nsmack dab in the middle.",
    "start": "2477870",
    "end": "2488130"
  },
  {
    "text": "So instead of K-means, we can\njust think, well, K-medoids. So in K-means, we actually\ncomputed a centroid.",
    "start": "2488130",
    "end": "2495089"
  },
  {
    "text": "And in medoids, we'll\nchoose the existing data point that's most central.",
    "start": "2495090",
    "end": "2501730"
  },
  {
    "text": "So what does that mean? ",
    "start": "2501730",
    "end": "2513200"
  },
  {
    "text": "If these are my data, the true\nmean is somewhere over here. ",
    "start": "2513200",
    "end": "2520335"
  },
  {
    "text": "But this one is the medoid. ",
    "start": "2520335",
    "end": "2525599"
  },
  {
    "text": "It's an exemplar that's\nclose to the central point. But if there actually\nisn't anything here,",
    "start": "2525600",
    "end": "2531952"
  },
  {
    "text": "then there isn't. So we're going to use\nthe thing that's closest. So if these were\nall sequence motifs, rather than using some\nsequence motif that",
    "start": "2531952",
    "end": "2538550"
  },
  {
    "text": "doesn't exist as the\ncenter of your cluster, you would use a sequence motif\nthat actually does exist, and it's close to the center.",
    "start": "2538550",
    "end": "2544222"
  },
  {
    "start": "2544222",
    "end": "2549869"
  },
  {
    "text": "So it's a simple\nvariation on the K-means. ",
    "start": "2549870",
    "end": "2555180"
  },
  {
    "text": "Instead choosing K\npoints in arbitrary space as our starting\npositions, we're going",
    "start": "2555180",
    "end": "2561600"
  },
  {
    "text": "to choose K examples from the\ndata as our starting medoids. And then we're going to place\neach point in the cluster that",
    "start": "2561600",
    "end": "2569180"
  },
  {
    "text": "has the closest medoid,\nrather than median. And then when we\ndo the update step, instead of choosing the\naverage position to represent",
    "start": "2569180",
    "end": "2576839"
  },
  {
    "text": "the cluster, we'll\nchoose the medoid. The exemplar that's\nclosest to the middle.",
    "start": "2576840",
    "end": "2583860"
  },
  {
    "text": "Any questions on this? Yes? AUDIENCE: So if\nyou use the medoid, do you lose the\nguaranteed convergence?",
    "start": "2583860",
    "end": "2590306"
  },
  {
    "text": "Because I can\npicture a situation where you're sort of\noscillating because now you have a discrete stack. PROFESSOR: That's\na good question.",
    "start": "2590306",
    "end": "2596794"
  },
  {
    "text": "That's probably right. Actually, I should\nthink about that. I\"m not sure. ",
    "start": "2596794",
    "end": "2602570"
  },
  {
    "text": "Yeah, that's probably right. Other questions? ",
    "start": "2602570",
    "end": "2610701"
  },
  {
    "text": "OK. There are a lot of other\ntechniques for clustering. Your textbook talks about\nself organizing maps,",
    "start": "2610701",
    "end": "2615839"
  },
  {
    "text": "which were popular at\none point quite a lot. And there's also\na nice technique called affinity\npropagation, which",
    "start": "2615840",
    "end": "2621156"
  },
  {
    "text": "is a little bit outside\nthe scope of this course, but has proved quite\nuseful for clustering.",
    "start": "2621156",
    "end": "2628880"
  },
  {
    "text": "OK. So why bother to do\nall this clustering? Our goal is to try to find\nsome biological information,",
    "start": "2628880",
    "end": "2634960"
  },
  {
    "text": "not just to find\ngroups of genes. So what can you do\nwith these things? Well, one thing that\nwas identified early on,",
    "start": "2634960",
    "end": "2641119"
  },
  {
    "text": "is if I could find sets of genes\nthat behave similarly, maybe those could be used\nin a predictive way,",
    "start": "2641120",
    "end": "2646300"
  },
  {
    "text": "to predict outcomes\nfor patients, or some biological function. So we're going to\nlook at that first.",
    "start": "2646300",
    "end": "2654319"
  },
  {
    "text": "So one of the early\npapers in this field did clustering of\nmicroarrays for patients",
    "start": "2654320",
    "end": "2660220"
  },
  {
    "text": "who had B-cell lymphoma. The patients had different\nkinds of B-cell lymphomas.",
    "start": "2660220",
    "end": "2665835"
  },
  {
    "text": "And so they took their\ndata, they clustered it. Again, each row\nrepresents a gene.",
    "start": "2665835",
    "end": "2671609"
  },
  {
    "text": "And each column\nrepresents a patient here. And with this projector, it's\na little bit hard to see. But when you look at\nthe notes separately,",
    "start": "2671610",
    "end": "2678060"
  },
  {
    "text": "you'll be able see\nthat in the dendogram, there's a nice, sharp\ndivision between two",
    "start": "2678060",
    "end": "2683420"
  },
  {
    "text": "large groups of patients. And it turns out that when\nyou look at the pathologist's",
    "start": "2683420",
    "end": "2688824"
  },
  {
    "text": "annotations for these\npatients, which was completely independent of the\ngene expression data, all of patients in\nthe left hand group--",
    "start": "2688824",
    "end": "2694942"
  },
  {
    "text": "almost all the patients\nin the left hand group, had one kind of lymphoma. And all the patients\nin the right hand group",
    "start": "2694942",
    "end": "2701460"
  },
  {
    "text": "had a different\nkind of lymphoma. And this got people\nvery excited. Because it suggested that\nthe pure molecular features",
    "start": "2701460",
    "end": "2707320"
  },
  {
    "text": "might be at least as good\nas pathological studies. So maybe you could completely\nautomate the identification",
    "start": "2707320",
    "end": "2713530"
  },
  {
    "text": "of different tumor types. Now the next thing that got\npeople even more excited, was the idea that maybe\nyou could actually",
    "start": "2713530",
    "end": "2719660"
  },
  {
    "text": "use these patterns not\njust to recapitulate what a pathologist would\nfind, but go beyond it,",
    "start": "2719660",
    "end": "2725590"
  },
  {
    "text": "and actually make predictions\nfrom the patients. So in these plots--\nI don't know if we've seen these before\nyet in the class.",
    "start": "2725590",
    "end": "2731268"
  },
  {
    "text": "But on the x-axis is survival. In the y-axis are the\nfraction of patients in a particular group,\nwho survived that long.",
    "start": "2731268",
    "end": "2739360"
  },
  {
    "text": "So as the patient's\ndie, obviously the curve is dropping down. Each one of these\ndrops represents",
    "start": "2739360",
    "end": "2745110"
  },
  {
    "text": "the death of a patient,\nor the loss of the patient to the study for other reasons.",
    "start": "2745110",
    "end": "2751110"
  },
  {
    "text": "And so in the middle,\nlet's start with this one. This is what the clinicians\nwould have decided. There are here, patients\nthat they defined",
    "start": "2751110",
    "end": "2757609"
  },
  {
    "text": "by clinical standards as\nbeing likely to do well, versus patients whom they\ndefined by clinical standards, as likely to do poorly.",
    "start": "2757610",
    "end": "2763619"
  },
  {
    "text": "And you could see there\nis a big difference in the plots for the\nlow clinical risk patients at the top, and\nthe high clinical risk",
    "start": "2763619",
    "end": "2770119"
  },
  {
    "text": "patients at the bottom. On the left hand\nside, or what you get when you use purely\ngene expression data",
    "start": "2770120",
    "end": "2775750"
  },
  {
    "text": "to cluster the patients into\ngroups that you turn out to be high risk or low risk.",
    "start": "2775750",
    "end": "2780799"
  },
  {
    "text": "And you can see that\nit's a little bit more statistically significant\nfor the clinical risk. But it's pretty\ngood over here, too.",
    "start": "2780800",
    "end": "2787870"
  },
  {
    "text": "Now the really\nimpressive thing is, what if you take the\npatients that the clinicians define as low clinical risk?",
    "start": "2787870",
    "end": "2795750"
  },
  {
    "text": "And then you look at their\ngene expression data. Could you separate\nout the patients in that allegedly\nlow clinical risk",
    "start": "2795750",
    "end": "2801570"
  },
  {
    "text": "who are actually at high risk? And maybe then they\nwould be diverted to have more aggressive\ntherapy than patients",
    "start": "2801571",
    "end": "2806840"
  },
  {
    "text": "who really and truly\nare low risk patients. And what they will\nshow with just barely statistical significance,\nis that even",
    "start": "2806840",
    "end": "2813340"
  },
  {
    "text": "among the clinically\ndefined low risk patients, there is-- based on\nthese gene signatures--",
    "start": "2813340",
    "end": "2818792"
  },
  {
    "text": "the ability to\ndistinguish patients who are going to do\nbetter, and patients who are going to do worse.",
    "start": "2818792",
    "end": "2824990"
  },
  {
    "text": "So this was over a decade ago. And it really set off a\nfrenzy of people looking for gene signatures for\nall sorts of things,",
    "start": "2824990",
    "end": "2830720"
  },
  {
    "text": "that might be highly predictive. Now the fact that\nsomething is correlated,",
    "start": "2830720",
    "end": "2837090"
  },
  {
    "text": "doesn't of course\nprove any causality. So one of the questions is, if\nI find a gene signature that",
    "start": "2837090",
    "end": "2842660"
  },
  {
    "text": "is predictive of an outcome\nin one of the studies, can I use it then to go\nbackwards, and actually define a therapy?",
    "start": "2842660",
    "end": "2848810"
  },
  {
    "text": "In the ideal setting, I would\nhave these gene signatures. I'd discover that\nthey are clinically",
    "start": "2848810",
    "end": "2854290"
  },
  {
    "text": "associated with outcome. I could dig in and\ndiscover what makes the patients to do worse, worse.",
    "start": "2854290",
    "end": "2860720"
  },
  {
    "text": "And go and treat that. So is that the case or not? So let me show you some data\nfrom a breast cancer data set.",
    "start": "2860720",
    "end": "2867397"
  },
  {
    "text": "Here's a breast cancer data set. Again the same kind of plot,\nwhere we've got the survival statistic on the y-axis, the\nnumber of years on the x-axis.",
    "start": "2867397",
    "end": "2876780"
  },
  {
    "text": "And based on a gene\nsignature, this group has defined a group\nthat does better, and a group that does worse,\nthe p value is significant.",
    "start": "2876780",
    "end": "2884990"
  },
  {
    "text": "And it has a ratio, the\ndeath rate versus control",
    "start": "2884990",
    "end": "2891250"
  },
  {
    "text": "is approximately two. OK. So does this lead us to\nany mechanistic insight",
    "start": "2891250",
    "end": "2896709"
  },
  {
    "text": "into breast cancer. Well, it turns out in this\ncase, the gene signature was defined based on\npostprandial laughter.",
    "start": "2896709",
    "end": "2904390"
  },
  {
    "text": "So after dinner humor. Here's a gene set\nthat defined something that has absolutely nothing\nto do with breast cancer,",
    "start": "2904390",
    "end": "2911089"
  },
  {
    "text": "and it's predicting the outcome\nof breast cancer patients. Which leads to\nsomewhat more of a joke",
    "start": "2911090",
    "end": "2916720"
  },
  {
    "text": "that the testing\nwhether laughter really is the best medicine. OK. So they went on-- they\ntried other genes sets.",
    "start": "2916720",
    "end": "2924350"
  },
  {
    "text": "Here's the data\nset-- gene set that's not even defined in humans. It's the homologs of\ngenes that are associated",
    "start": "2924350",
    "end": "2932240"
  },
  {
    "text": "with social defeat in mice. And once again, you get a\nstatistically significant",
    "start": "2932240",
    "end": "2938670"
  },
  {
    "text": "p-value, and good hazard ratios. So what's going on? Well, these are not from\na study that's actually",
    "start": "2938670",
    "end": "2943930"
  },
  {
    "text": "trying to predict an\noutcome in breast cancer. It's a study that shows\nthat most gene expression--",
    "start": "2943930",
    "end": "2949289"
  },
  {
    "text": "most randomly selected\nsets of genes in the genome will give an outcome that's\ncorrelated-- a result that's",
    "start": "2949290",
    "end": "2955810"
  },
  {
    "text": "correlated with a patient\noutcome in breast cancer. ",
    "start": "2955810",
    "end": "2961039"
  },
  {
    "text": "Yes? AUDIENCE: I'm a little confused. In the previous graph, could you\njust explain what is the black and what is the red?",
    "start": "2961040",
    "end": "2966958"
  },
  {
    "text": "Is that individuals or groups? PROFESSOR: So the\nblack are people",
    "start": "2966958",
    "end": "2972079"
  },
  {
    "text": "that have the genes\nset signature, who have high levels\nof the genes that are defined in this gene set.",
    "start": "2972080",
    "end": "2977969"
  },
  {
    "text": "And the red are ones have\nlow, or the other way around. But it's defining all patients\ninto two groups, based",
    "start": "2977969",
    "end": "2983360"
  },
  {
    "text": "on whether they have a\nparticular level of expression in this gene set,\nand then following",
    "start": "2983360",
    "end": "2989328"
  },
  {
    "text": "those patients over time. Do they do better or worse? And similarly for\nall these plots. ",
    "start": "2989329",
    "end": "2997950"
  },
  {
    "text": "And he had another one which is\na little less amusing, location of skin fibroblasts. The real critical point is this.",
    "start": "2997950",
    "end": "3005820"
  },
  {
    "text": "Here, they compared\nthe probability based on expectation\nan that all genes are",
    "start": "3005820",
    "end": "3014630"
  },
  {
    "text": "independent of each\nother, the probability that that gene signatures\ncorrelated with outcome,",
    "start": "3014630",
    "end": "3020510"
  },
  {
    "text": "for genes there were chosen\nat random or genes that were chosen from a database\nof gene signatures,",
    "start": "3020510",
    "end": "3025960"
  },
  {
    "text": "that people have identified as\nbeing associated with pathways. And you get a very,\nvery large fraction. So this is the p-value.",
    "start": "3025960",
    "end": "3032380"
  },
  {
    "text": "So negative log of\np-value, so negative values are more significant. A huge fraction\nof all genes sets",
    "start": "3032380",
    "end": "3038910"
  },
  {
    "text": "that you pull at\nrandom from the genome, or that you pull from a\ncompendium of known pathways, are going to be\nassociated with outcome,",
    "start": "3038910",
    "end": "3046010"
  },
  {
    "text": "in this breast cancer data set. So it's not just well\nannotated cancer pathways,",
    "start": "3046010",
    "end": "3051120"
  },
  {
    "text": "that are associated. Its gene sets\nassociated as we've seen, with laughter or\nsocial defeat in mice,",
    "start": "3051120",
    "end": "3057200"
  },
  {
    "text": "and so on-- all sorts\nof crazy things, that have no mechanistic\nlink to breast cancer.",
    "start": "3057200",
    "end": "3065100"
  },
  {
    "text": "Let's take a second\nfor that to sink in. I pull genes at random\nfrom the genome.",
    "start": "3065100",
    "end": "3071350"
  },
  {
    "text": "I define patients\nbased on whether they have high levels of expression\nof a random set of genes, or low levels of expression\nof that random set of genes.",
    "start": "3071350",
    "end": "3079100"
  },
  {
    "text": "And I'm extremely likely\nto be able to predict the outcome in breast cancer. ",
    "start": "3079100",
    "end": "3085919"
  },
  {
    "text": "So that should be rather\ndisturbing, right? So it turns out-- before\nwe get to the answer then-- so this is not\nunique to breast cancer.",
    "start": "3085919",
    "end": "3093005"
  },
  {
    "text": "They went through a whole bunch\nof data sets in the literature. Each row is a different\npreviously published study,",
    "start": "3093005",
    "end": "3098180"
  },
  {
    "text": "where someone had claimed\nto identify a signature for a particular kind\nof disease or outcome.",
    "start": "3098180",
    "end": "3105510"
  },
  {
    "text": "And they took their\nrandom gene sets and asked how well the random\ngenes sets did in predicting the outcome\nin these patients?",
    "start": "3105510",
    "end": "3113420"
  },
  {
    "text": "And so these yellow\nplots represent the probability distribution\nfor the random gene",
    "start": "3113420",
    "end": "3119089"
  },
  {
    "text": "sets-- again on\nthis projector, it's hard to see-- but there's a\nhighlight in the left hand side at where the 5%, the best\n5% of the random gene sets are.",
    "start": "3119090",
    "end": "3127694"
  },
  {
    "text": "This blue line is\nthe near measure of statistical significance. It turns out that a\nfew of these studies didn't even reach a normal level\nof statistical significance,",
    "start": "3127694",
    "end": "3135270"
  },
  {
    "text": "let alone comparing\nto random gene sets. But for most of\nthese, you don't do",
    "start": "3135270",
    "end": "3141500"
  },
  {
    "text": "better than a good fraction\nof the randomly selected gene sets. So how could this be?",
    "start": "3141500",
    "end": "3147029"
  },
  {
    "text": "So it turns out there is an\nanswer to why this happens. And it's really\nquite fascinating. So here, we're using\nthe hazard ratio,",
    "start": "3147030",
    "end": "3153547"
  },
  {
    "text": "which is the death rate\nfor the patients who have the signature,\nover the control group.",
    "start": "3153547",
    "end": "3158549"
  },
  {
    "text": "So high hazard ratio means\nit's a very, very dissociative outcome. And they've plotted that against\nthe correlation of the genes",
    "start": "3158550",
    "end": "3166102"
  },
  {
    "text": "in the gene signature, with\nthe expression of a gene called PCNA, Proliferating\nCell Nuclear Antigen",
    "start": "3166102",
    "end": "3173610"
  },
  {
    "text": "And it turns out a very, very\nlarge fraction of the genome is coexpressed. ",
    "start": "3173610",
    "end": "3180440"
  },
  {
    "text": "So genes are not expressed like\nrandom, completely independent random variables. There are lots of genes that\nshow very similar expression",
    "start": "3180440",
    "end": "3187550"
  },
  {
    "text": "levels, across\nall the data sets. Now PCNA is a gene that's\nbeen known by pathologists for a long time,\nas having higher",
    "start": "3187550",
    "end": "3193480"
  },
  {
    "text": "levels than most\ndigressive tumors. So a very, very large\nfraction of the genome is coexpressed with PCNA.",
    "start": "3193480",
    "end": "3200160"
  },
  {
    "text": "Then high levels of\nrandomly selected genes are going to be a very good\npredictor of tumor outcome. Because high levels of\nrandomly expressed genes",
    "start": "3200160",
    "end": "3206908"
  },
  {
    "text": "also means a very\nhigh probability of having a high level PCNA,\nwhich is a tumor marker.",
    "start": "3206908",
    "end": "3212270"
  },
  {
    "text": " So we have to proceed\nwith a lot of caution.",
    "start": "3212270",
    "end": "3217800"
  },
  {
    "text": "We can find things that are\nhighly correlated with outcome, that could have good value in\nterms of prognostic indicators.",
    "start": "3217800",
    "end": "3225690"
  },
  {
    "text": "But there are going to\nbe a lot of possibilities for sets of genes that\nhave that property, they're good\npredictors of outcome.",
    "start": "3225690",
    "end": "3232130"
  },
  {
    "text": "And many of them will\nhave absolutely nothing to causally, with the\nprocess of the disease.",
    "start": "3232130",
    "end": "3239170"
  },
  {
    "text": "So at the very least, it means\ndon't start a drug company over every set of genes,\nif you identify this as associated with outcome.",
    "start": "3239170",
    "end": "3245620"
  },
  {
    "text": "But the worst case\nscenario, it also means that those predictions\nwill break down under settings that we haven't yet examined.",
    "start": "3245620",
    "end": "3252580"
  },
  {
    "text": "And so that's the\nreal fear, that you have a gene set\nsignature that you think has a highly predictive outcome. It's only because you looked at\na particular set of patients.",
    "start": "3252580",
    "end": "3260246"
  },
  {
    "text": "But you look at a\ndifferent set of patients, and that correlation\nwill break down. So this is an area of research\nthat's still quite in flux,",
    "start": "3260247",
    "end": "3267810"
  },
  {
    "text": "in terms of how\nmuch utility there will be in identifying\ngenes set signatures, in this completely\nobjective way.",
    "start": "3267810",
    "end": "3273827"
  },
  {
    "text": "And what we'll see in the\ncourse of this lecture and the next one,\nis it's probably going to be much more\nuseful to incorporate",
    "start": "3273827",
    "end": "3279034"
  },
  {
    "text": "other kinds of information\nthat will constrain us to be more mechanistic. ",
    "start": "3279034",
    "end": "3284267"
  },
  {
    "text": "Any questions? ",
    "start": "3284267",
    "end": "3291892"
  },
  {
    "text": "All right. So now we're going to\nreally get into the meat of the identification\nof gene modules. And we're going to try to\nsee how much we can learn",
    "start": "3291892",
    "end": "3299559"
  },
  {
    "text": "about regulatory structure\nfrom the gene expression data. So we're going to move up from\njust the pure expression data--",
    "start": "3299560",
    "end": "3305395"
  },
  {
    "text": "say these genes at the\nbottom, to try to figure out what set of transcription\nfactors we're driving, and maybe what signaling\npathways lived upstream",
    "start": "3305395",
    "end": "3312225"
  },
  {
    "text": "in those transcription\nfactors, and turn them on. And the fundamental difference\nthen between clustering-- which is what we've been looking in\nuntil now, and these modules,",
    "start": "3312225",
    "end": "3319610"
  },
  {
    "text": "as people like to call\nthem-- is that you can have a whole bunch\nof genes, and we've just seen that, that are\ncorrelated with each other,",
    "start": "3319610",
    "end": "3325458"
  },
  {
    "text": "without being causally\nlinked to each other. So we like to figure out which\nones are actually functionally related, and not just\nstatistically related.",
    "start": "3325458",
    "end": "3334202"
  },
  {
    "text": "And the paper that's going\nto serve as our organizing principle in the\nrest of this lecture, maybe bleeding into\nthe next lecture,",
    "start": "3334202",
    "end": "3340579"
  },
  {
    "text": "is this paper,\nrecently published that's called The\nDREAM5 Challenge.",
    "start": "3340580",
    "end": "3345817"
  },
  {
    "text": "And this, like some of these\nother challenges that we've seen before, is the case where\nthe organizers have data sets,",
    "start": "3345817",
    "end": "3351950"
  },
  {
    "text": "where are they know\nthe answer to what the regulatory structure is.",
    "start": "3351950",
    "end": "3357230"
  },
  {
    "text": "They send out the data. People try to make the\nbest predictions they can. And then they unseal\nthe data, to let people know how well they did.",
    "start": "3357230",
    "end": "3363494"
  },
  {
    "text": "And so you can get a\nrelatively objective view of how well different\nkinds of approaches work.",
    "start": "3363495",
    "end": "3369920"
  },
  {
    "text": "So this is the overall\nstructure of this challenge. They had four different\nkinds of data.",
    "start": "3369920",
    "end": "3375599"
  },
  {
    "text": "Three are real data sets from\ndifferent organisms, E. coli, yeast, and\nStaphylococcus aureus.",
    "start": "3375600",
    "end": "3381610"
  },
  {
    "text": "And then the fourth one,\nthe one at the top here, is completely synthetic\ndata that they generated it.",
    "start": "3381610",
    "end": "3386780"
  },
  {
    "text": "And you get a sense of the\nscale of the data sets. So how many genes are involved,\nhow many potential regulators.",
    "start": "3386780",
    "end": "3393300"
  },
  {
    "text": "In some cases, they've given\nyou specific information on knockouts, antibiotics,\ntoxins, that are perturbing.",
    "start": "3393300",
    "end": "3401599"
  },
  {
    "text": "And again here, the\nnumber of conditions that are being looked at,\nthe number of arrays. So then they provide\nthis data in a way",
    "start": "3401600",
    "end": "3408170"
  },
  {
    "text": "that's very hard\nfor the groups that are analyzing to trace it\nback to particular genes.",
    "start": "3408170",
    "end": "3413525"
  },
  {
    "text": "Because you don't want people to\nuse external data necessarily, to make their predictions. So every makes\ntheir predictions.",
    "start": "3413525",
    "end": "3420599"
  },
  {
    "text": "They also, as part\nof this challenge, they actually they made\ntheir own metapredictions,",
    "start": "3420600",
    "end": "3426390"
  },
  {
    "text": "based on the\nindividual predictions by different groups. And we'll take a look\nat that in a second. And then they score\nhow well they did.",
    "start": "3426390",
    "end": "3434014"
  },
  {
    "text": "Now we'll get into the details\nof the scoring a little bit later. But what they found\nat the highest levels, that different kinds of\nmethods behaved similarly.",
    "start": "3434014",
    "end": "3442070"
  },
  {
    "text": "So the main groups\nthat they found were these regression-based\ntechniques. We'll talk about\nthose in a second.",
    "start": "3442070",
    "end": "3447477"
  },
  {
    "text": "Bayesian networks,\nwhich we've already discussed in a\ndifferent context. A hodgepodge of different\nkinds of things.",
    "start": "3447477",
    "end": "3453930"
  },
  {
    "text": "And then mutual information\nand correlation. So we're going to look in\neach of these main categories",
    "start": "3453930",
    "end": "3460674"
  },
  {
    "text": "of prediction methods.  So we're going to start with\nthe Bayesian networks, which",
    "start": "3460674",
    "end": "3466040"
  },
  {
    "text": "we just finished talking\nabout in a completely different context. Here, instead of trying to\npredict whether interaction",
    "start": "3466040",
    "end": "3471420"
  },
  {
    "text": "is true, based on the\nexperimental data, we're going to try to predict\nwhether a particular protein is involved in regulating a set of\ngenes, based on the expression",
    "start": "3471420",
    "end": "3478263"
  },
  {
    "text": "data. So in this context-- let's\nsay I have cancer data sets,",
    "start": "3478263",
    "end": "3484200"
  },
  {
    "text": "and I wanted to decide\nwhether p53 is activated in those tumors, So this\nis a known pathway for p53.",
    "start": "3484200",
    "end": "3491089"
  },
  {
    "text": "So if I told you\nthe pathway, how might you figure out if p53\nis active from gene expression",
    "start": "3491090",
    "end": "3496170"
  },
  {
    "text": "data? I tell you this pathway, give\nyou this expression data--",
    "start": "3496170",
    "end": "3501640"
  },
  {
    "text": "what's kind of a simple\nthing that you could do right away, to decide whether you\nthink p53 is active or not?",
    "start": "3501640",
    "end": "3507380"
  },
  {
    "text": "p53 is a transcriptional\nactivator, but it should be turning\non the genes of its targets when its on.",
    "start": "3507380",
    "end": "3513210"
  },
  {
    "text": "So what's an\nobvious thing to do? AUDIENCE: Check the expression\nlevels from the targets.",
    "start": "3513210",
    "end": "3518450"
  },
  {
    "text": "PROFESSOR: Thank you. Right, so we could check\nthe expression levels. The targets compute some\nsimple statistics, right?",
    "start": "3518450",
    "end": "3523670"
  },
  {
    "text": "OK. Well, that could work. But of course there could\nbe other transcriptional regulators that regulate\na similar set of genes.",
    "start": "3523670",
    "end": "3529080"
  },
  {
    "text": "So that's not a\nguarantee that p53 is on. It might be some other\ntranscriptional regulator.",
    "start": "3529080",
    "end": "3535510"
  },
  {
    "text": "We could look for the\npathways that activate p53. We could ask whether\nthose genes are on.",
    "start": "3535510",
    "end": "3541210"
  },
  {
    "text": "So we've got in this\npathway, a bunch of kinases, an ATM, CHK1, and so\non, that activate p53.",
    "start": "3541210",
    "end": "3548422"
  },
  {
    "text": "Now if we had proteomic\ndata, we could actually look whether those proteins\nare phosphorylated. But we have much, much\nless proteomic data.",
    "start": "3548422",
    "end": "3554200"
  },
  {
    "text": "And most of these settings\nonly have gene expression data. But you look at, is\nthat gene expressed? Has the expression of one\nof these activating proteins",
    "start": "3554200",
    "end": "3561160"
  },
  {
    "text": "gone up? And you can try to\nmake an inference then. From whether there's more of\nthese activating proteins,",
    "start": "3561160",
    "end": "3566900"
  },
  {
    "text": "then maybe p53 is active. And therefore it's\nturning on it's targets. That's one step removed.",
    "start": "3566900",
    "end": "3572840"
  },
  {
    "text": "So just the fact that there's\na lot of ATM mRNA around doesn't mean that there's a\nlot of the ATM protein, which",
    "start": "3572840",
    "end": "3578290"
  },
  {
    "text": "certainly doesn't mean that\nthe ATM is phosphorylated and turning on its target. So again, we don't\nhave a guarantee there.",
    "start": "3578290",
    "end": "3583684"
  },
  {
    "text": " We could look more specifically\nwhether the genes are",
    "start": "3583685",
    "end": "3589000"
  },
  {
    "text": "differentially expressed. So the fact that they're on\nmay not be as informative as if they were uniquely\non in this tumor,",
    "start": "3589000",
    "end": "3595240"
  },
  {
    "text": "and not on in control cells\nfrom the same patient. So that can be informative.",
    "start": "3595240",
    "end": "3601080"
  },
  {
    "text": "But again changes\nin gene expression are not uniquely related to\nchanges in protein level. So we're going to have to\nbehave with a bit of caution.",
    "start": "3601080",
    "end": "3609230"
  },
  {
    "text": "So the first step we're going\nto take in this direction, is try to build a\nBayesian network. That's going to give us a way\nto reason probabilistically",
    "start": "3609230",
    "end": "3615710"
  },
  {
    "text": "over all of these kinds of data,\nwhich by themselves are not great guarantees that we're\ngetting the right answer.",
    "start": "3615710",
    "end": "3621770"
  },
  {
    "text": "Just like in the protein\nprediction interaction problem, where individually coexpression\nwasn't all that great,",
    "start": "3621770",
    "end": "3628920"
  },
  {
    "text": "essentiality wasn't\nall that great. But taken together, they\ncould be quite helpful. So we want to compute\nthe probability",
    "start": "3628920",
    "end": "3635050"
  },
  {
    "text": "that the p53 pathway is\nactive, given the data. And the only data we're\ngoing to have in the setting",
    "start": "3635050",
    "end": "3641710"
  },
  {
    "text": "is gene expression data. So we're going to assume\nthat for the targets of a transcription\nfactor to be active,",
    "start": "3641710",
    "end": "3648210"
  },
  {
    "text": "the transcription\nfactor itself has to be expressed\nat a higher level. That's a restriction\nof analyzing",
    "start": "3648210",
    "end": "3653800"
  },
  {
    "text": "these kinds of data\nthat's very commonly used. So we're going to try to\ncompute the probability that p53",
    "start": "3653800",
    "end": "3660190"
  },
  {
    "text": "is activated, given the data. So how would I compute\nthe probability, that given that some\ntranscription factors on,",
    "start": "3660190",
    "end": "3666980"
  },
  {
    "text": "that I see expression\nfrom target genes? How would I do this? I would just go into the data,\nand just count in the same way",
    "start": "3666980",
    "end": "3673470"
  },
  {
    "text": "that we did in our\nprevious setting. We could just look over\nall the experiments",
    "start": "3673470",
    "end": "3678680"
  },
  {
    "text": "and tabulate whether one of the\ntargets is up in expression, how often is the transcription\nfactor that's potentially",
    "start": "3678680",
    "end": "3684380"
  },
  {
    "text": "activating it up? And how often are all the\npossible combinations the case? And then we can use\nBayesian statistics",
    "start": "3684380",
    "end": "3691330"
  },
  {
    "text": "to try to compute\nthe probability that a transcription\nfactor is up, activated, given that I've seen the\ngene expression data.",
    "start": "3691330",
    "end": "3697860"
  },
  {
    "text": "Is that clear?  Good. ",
    "start": "3697860",
    "end": "3706410"
  },
  {
    "text": "So we want to try to not include\njust the down stream factors. Because that leads\npossibly, maybe there",
    "start": "3706410",
    "end": "3711520"
  },
  {
    "text": "are multiple\ntranscription factors that are equally\nlikely to be driving expressions instead of genes. We want to include the\nupstream regulators as well.",
    "start": "3711520",
    "end": "3719020"
  },
  {
    "text": "And so here, we're going\nto take advantage of one of the properties\nof Bayesian nets at where we looked\nat, explaining a way.",
    "start": "3719020",
    "end": "3725244"
  },
  {
    "text": "And you'll remember\nthis example, where we decided that if see\nthat the grass is wet,",
    "start": "3725245",
    "end": "3730940"
  },
  {
    "text": "and I know that\nit's raining, then I can consider less likely\nthat the sprinklers were on. Even though there's no causal\nrelationship between them.",
    "start": "3730940",
    "end": "3738280"
  },
  {
    "text": "So if I see that a set of\ntargets of transcription factor A are on, and I have evidence\nthat the pathway upstream of A",
    "start": "3738280",
    "end": "3745410"
  },
  {
    "text": "is on, that reduces my\ninferred probability that the transcription\nfactor B is responsible.",
    "start": "3745410",
    "end": "3752544"
  },
  {
    "text": "So that's of the nice things\nabout Bayesian networks that gives us a way of\nreasoning automatically, over all the data, and not\njust the down stream targets.",
    "start": "3752544",
    "end": "3761090"
  },
  {
    "text": "And the Bayesian networks\ncan have multiple layers. So we can have one\ntranscription factor turning another one,\nturns on other one,",
    "start": "3761090",
    "end": "3766621"
  },
  {
    "text": "turns on another one. Again, we can have as\nmany layers as necessary. But one thing we\ncan't have are cycles.",
    "start": "3766621",
    "end": "3771650"
  },
  {
    "text": "So we can't have a\ntranscription factor that's at the bottom of this,\ngoing back and activating",
    "start": "3771650",
    "end": "3776750"
  },
  {
    "text": "things that are at the top. And that's a\nfundamental limitation of Bayesian networks. ",
    "start": "3776750",
    "end": "3784362"
  },
  {
    "text": "We've already talked\nabout the fact that in Bayesian networks,\nwith these two problems that we to have to solve, we have to be\nable to define the structure.",
    "start": "3784362",
    "end": "3792150"
  },
  {
    "text": "If we don't know any a priori. Here, we don't\nknow what a priori. So we're going to have to learn\nthe structure of the network. And then with the\nstructure of the network,",
    "start": "3792150",
    "end": "3797920"
  },
  {
    "text": "we're going to have to\nlearn all the probabilities. So the conditional\nprobability tables that relate to each\nvariable to every other one.",
    "start": "3797920",
    "end": "3803810"
  },
  {
    "text": "And then just two more\nsmall points about it. So if I just give\nyou expression data,",
    "start": "3803810",
    "end": "3810690"
  },
  {
    "text": "without any interventions--\njust the observations, then I can't decide what is a\ncause and what is an effect.",
    "start": "3810690",
    "end": "3817770"
  },
  {
    "text": "So here this was done in\nthe context of proteomics, but the same is true for\ngene expression data. If I have two variables, x and\ny, that are highly correlated,",
    "start": "3817770",
    "end": "3826050"
  },
  {
    "text": "it could be that x activates y. It could be that y activates x. But if I perturb the system,\nand I block the activity of one",
    "start": "3826050",
    "end": "3833440"
  },
  {
    "text": "of these two genes\nor proteins, then I can start to tell\nthe difference. In this case, if\nyou inhibit x, you",
    "start": "3833440",
    "end": "3840290"
  },
  {
    "text": "don't see any activation of y. That's the yellow,\nall down here. But if you inhibit y,\nyou see the full range",
    "start": "3840290",
    "end": "3845970"
  },
  {
    "text": "of activity of x.  So that implies that x\nis the activator of y.",
    "start": "3845970",
    "end": "3853710"
  },
  {
    "text": "And so in these settings, if\nyou want to learn a Bayesian network from data, you need\nmore than just a compendium of gene expression data.",
    "start": "3853710",
    "end": "3859500"
  },
  {
    "text": "If you want to get the\ndirections correct, you need perturbations\nwhere someone has actually inhibited particular\ngenes or proteins.",
    "start": "3859500",
    "end": "3866502"
  },
  {
    "text": "Now, in a lot of these\nBayesian networks, we're not going\nto try to include every possible gene and\nevery possible protein. Either because we don't\nhave measurements of it,",
    "start": "3866502",
    "end": "3873380"
  },
  {
    "text": "or because we need\na compact network. So there will often\nbe cases where the true regulator\nin some causal chain,",
    "start": "3873380",
    "end": "3879220"
  },
  {
    "text": "is missing from our data. So imagine this is the true\ncausal chain-- x activates",
    "start": "3879220",
    "end": "3885109"
  },
  {
    "text": "y, which then activates z and w. But either because we\ndon't have the data on y, or because we left it out to\nmake our models more compact,",
    "start": "3885110",
    "end": "3892390"
  },
  {
    "text": "it's not in the model. We can still pick up the\nrelationships between x and z,",
    "start": "3892390",
    "end": "3897810"
  },
  {
    "text": "and x and w. But the data will\nbe much noisier. Because we're missing\nthat information.",
    "start": "3897810",
    "end": "3903720"
  },
  {
    "text": "In the conditional\nprobability tables, relating x to y, and then\ny because it's too targets. ",
    "start": "3903720",
    "end": "3912972"
  },
  {
    "text": "So Bayesian networks, we've\nalready seen quite a lot. We now have some idea of how to\ntransfer them from one domain",
    "start": "3912972",
    "end": "3918010"
  },
  {
    "text": "to the domain of\ngene expression data. The next approach\nwe want to look at is a regression-based approach.",
    "start": "3918010",
    "end": "3923100"
  },
  {
    "text": " So the regression-based\napproaches are founded on a\nsimple idea, which",
    "start": "3923100",
    "end": "3930430"
  },
  {
    "text": "is that the expression\ngene is going to be some function\nof the expression levels of the regulator. We're going to\nactually try to come up",
    "start": "3930430",
    "end": "3936920"
  },
  {
    "text": "with a formula that\nrelates the activity levels of the\ntranscription factors, and the activity\nlevel of the target.",
    "start": "3936920",
    "end": "3943619"
  },
  {
    "text": "In this cartoon, I've\ngot a gene that's on under one\ncondition, that's off under some other conditions. What transforms it\nfrom being off to on,",
    "start": "3943620",
    "end": "3951177"
  },
  {
    "text": "is the introduction of\nmore of these transcription factors, that are\nbinding to the promoter. So in general, I have\nsome predicted level",
    "start": "3951177",
    "end": "3957740"
  },
  {
    "text": "of expression for the gene. It's called the\npredicted level y. And it's some function,\nunspecified at this point, f",
    "start": "3957740",
    "end": "3964450"
  },
  {
    "text": "of g, of all the expression\nlevels of the transcription factors that regulate that gene.",
    "start": "3964450",
    "end": "3970890"
  },
  {
    "text": "So just again,\nnomenclature is straight, x sub g is going to be\nthe expression of gene x--",
    "start": "3970890",
    "end": "3976130"
  },
  {
    "text": "I'm sorry, expression of gene g. This capital X, sub t of g\nis the set of transcription",
    "start": "3976130",
    "end": "3983450"
  },
  {
    "text": "factors, that I believe\nare regulating that gene. And then f is an\narbitrary function.",
    "start": "3983450",
    "end": "3989390"
  },
  {
    "text": "We're going to have\na noise term as well. Because this is the\nobserved gene expression, not some sort of platonic view\nof the true gene expression.",
    "start": "3989390",
    "end": "3996700"
  },
  {
    "text": "Now frequently, we'll\nhave a specific function. So the simplest one\nyou can imagine, which is a linear function.",
    "start": "3996700",
    "end": "4002730"
  },
  {
    "text": "So the expression of\nany particular gene is going to be a\nlinear function, a sum,",
    "start": "4002730",
    "end": "4008850"
  },
  {
    "text": "of the expression of\nall of it's regulators, where each one has associated\nwith it a coefficient beta.",
    "start": "4008850",
    "end": "4014820"
  },
  {
    "text": "And that beta\ncoefficient tells us how much particular a\nregulator influences that gene.",
    "start": "4014820",
    "end": "4020220"
  },
  {
    "text": "So say, p53 might have\na very large value. Some other\ntranscriptional regulator might have a small\nvalue, representing",
    "start": "4020220",
    "end": "4026940"
  },
  {
    "text": "their relative influence. Now, I don't know the\nbeta values in advance. So that's one of the things\nthat I need to learn.",
    "start": "4026940",
    "end": "4034150"
  },
  {
    "text": "So I want to be able to\nfind a setting that tells me what the beta values are for\nevery possible transcription",
    "start": "4034150",
    "end": "4040130"
  },
  {
    "text": "factor. If the algorithm sets\nthe beta value to zero, what does that tell me? ",
    "start": "4040130",
    "end": "4046727"
  },
  {
    "text": "If a beta value\nis zero here, what does that tell me about that\ntranscriptional regulator? No influence, right.",
    "start": "4046727",
    "end": "4052760"
  },
  {
    "text": "And the higher the value, then\nthe greater the influence. OK. So how do we discover these?",
    "start": "4052760",
    "end": "4058090"
  },
  {
    "text": "So the tip of the\napproach then is to come up with some\nobjective function that we're going\nto try to optimize. And an obvious\nobjective function",
    "start": "4058090",
    "end": "4064070"
  },
  {
    "text": "is the difference between\nthe observed expression value for each gene,\nand the expected one,",
    "start": "4064070",
    "end": "4069150"
  },
  {
    "text": "based on that linear function. And we're going to choose\na set of data parameters that minimize the difference\nbetween the observed",
    "start": "4069150",
    "end": "4074810"
  },
  {
    "text": "and the expected, minimize\nthe sum of the squares. So the residual sum\nof the squares error,",
    "start": "4074810",
    "end": "4080680"
  },
  {
    "text": "between the predicted\nand the observed.  So this is a relatively\nstandard regression problem,",
    "start": "4080680",
    "end": "4088140"
  },
  {
    "text": "just in different setting. Now one of the problems with\na standard regression problem, is that we'll\ntypically get a lot",
    "start": "4088140",
    "end": "4094330"
  },
  {
    "text": "of very small values of beta. So we won't get all\nzeros or all ones, meaning the algorithm is\n100% certain that these",
    "start": "4094330",
    "end": "4099950"
  },
  {
    "text": "are the drivers\nand these are not. We'll get a lot of small values\nfor many, many transcription",
    "start": "4099950",
    "end": "4105609"
  },
  {
    "text": "factors. And OK, that could\nrepresent the reality. But the bad thing is\nthat those data values",
    "start": "4105609",
    "end": "4110699"
  },
  {
    "text": "are going to be unstable. So small changes in\nthe training data will give you big changes, in\nwhich transcription factors",
    "start": "4110700",
    "end": "4116349"
  },
  {
    "text": "have which values. So that not a desirable setting. There's a whole field\nbuilt up around trying to come up with\nbetter solutions.",
    "start": "4116350",
    "end": "4123399"
  },
  {
    "text": "I've given you some\nreferences here. One of them is to a\npaper that did well in the DREAM challenge. The other one is to\na very good textbook,",
    "start": "4123399",
    "end": "4130649"
  },
  {
    "text": "Elements of\nStatistical Learning. And there are various\ntechniques that allow you to try to\nlimit the number of betas",
    "start": "4130649",
    "end": "4136759"
  },
  {
    "text": "that are non-zero. And by doing that, you get\nmore robust predictions.",
    "start": "4136760",
    "end": "4141960"
  },
  {
    "text": "At a cost, right, because there\ncould be a lot of transcription factors that really do\nhave small influences.",
    "start": "4141960",
    "end": "4147489"
  },
  {
    "text": "But we'll trade\nthat off, by getting more accurate predictions\nfrom the ones that have the big influences. ",
    "start": "4147490",
    "end": "4156787"
  },
  {
    "text": "Are there any questions\non regression?  So the last of the methods\nthat we're examining-- this",
    "start": "4156787",
    "end": "4164330"
  },
  {
    "text": "is a mutual information. We've already seen mutual\ninformation in the course. So information\ncontent is related",
    "start": "4164330",
    "end": "4170568"
  },
  {
    "text": "to the probability of observing\nsome variable in an alphabet. So in most languages,\nthe probability",
    "start": "4170569",
    "end": "4176238"
  },
  {
    "text": "of observing letters\nis quite variable. So Es are very common\nin the English language.",
    "start": "4176239",
    "end": "4181920"
  },
  {
    "text": "Other letters are less common. As anyone who plays Hangman or\nwatches Wheel of fortune knows.",
    "start": "4181920",
    "end": "4188278"
  },
  {
    "text": "And we defined the\nentropy as the sum over all possible outcomes. The probability of\nobserving some variable,",
    "start": "4188279",
    "end": "4195260"
  },
  {
    "text": "and the information\non to that variable, we can define the discrete\ncase, or in the continuous case.",
    "start": "4195260",
    "end": "4201410"
  },
  {
    "text": "And the critical\nthing is to have mutual information\nbetween two variables. So that's the difference between\nthe entropy of those variables",
    "start": "4201410",
    "end": "4207970"
  },
  {
    "text": "independently, and\nthen the joint entropy. So things with a high\nmutual information,",
    "start": "4207970",
    "end": "4213120"
  },
  {
    "text": "means that one variable gives\nthe significant knowledge of what the other\nvariable is doing. It reduces my uncertainty.",
    "start": "4213120",
    "end": "4219830"
  },
  {
    "text": "That's the critical idea. OK. So we looked at\ncorrelation before.",
    "start": "4219830",
    "end": "4225105"
  },
  {
    "text": "There could be\nsettings where you have very low correlation\nbetween two variables,",
    "start": "4225105",
    "end": "4230390"
  },
  {
    "text": "but have high\nmutual information. So consider these two genes,\nprotein A and protein b,",
    "start": "4230390",
    "end": "4238730"
  },
  {
    "text": "and the blue dots are the\nrelationship between them. You can see that there's\na lot of information",
    "start": "4238730",
    "end": "4244410"
  },
  {
    "text": "content in these two variables. Knowing the value of A\ngives me a high confidence",
    "start": "4244410",
    "end": "4250679"
  },
  {
    "text": "in the value of B. But\nthere's no linear relationship that describes these.",
    "start": "4250680",
    "end": "4255800"
  },
  {
    "text": "So if I use mutual\ninformation, I can capture\nsituations like this, that I can't capture\nwith correlation.",
    "start": "4255800",
    "end": "4262330"
  },
  {
    "text": "And these kinds of\nsituations actually occur. So for example in a\nfeed-forward loop-- say we've got a regulator\nA, and it directly",
    "start": "4262330",
    "end": "4270680"
  },
  {
    "text": "activates B. It also directly\nactivates C. But C inhibits B.",
    "start": "4270680",
    "end": "4275860"
  },
  {
    "text": "So you've got the path on\nthe left-hand sides that are pressing the accelerator. And the path on the right hand\nside pressing the stop pedal.",
    "start": "4275860",
    "end": "4282969"
  },
  {
    "text": "That's called an incoherent\nfeed-forward loop. And you can get under different\nsettings, different kinds of results, where this\nis one of those examples.",
    "start": "4282970",
    "end": "4290985"
  },
  {
    "text": "You can get much\nmore complicated behavior. [INAUDIBLE] are papers\nthat have really mapped out these behaviors across\nmany parameters settings.",
    "start": "4290985",
    "end": "4296990"
  },
  {
    "text": "You can get switches\nin the behavior. But in a lot of\nthese settings, you will have high\nmutual information",
    "start": "4296990",
    "end": "4303600"
  },
  {
    "text": "between two\nvariables, even if you don't have any correlation,\nlinear correlation",
    "start": "4303600",
    "end": "4308880"
  },
  {
    "text": "between them.  A well-publicized algorithm\nthat uses mutual information",
    "start": "4308880",
    "end": "4315810"
  },
  {
    "text": "to infer gene regulatory\nnetworks is called ARACNe. ",
    "start": "4315810",
    "end": "4321249"
  },
  {
    "text": "They go through and they\ncompute the mutual information between all pairs of\ngenes in their data set.",
    "start": "4321249",
    "end": "4327300"
  },
  {
    "text": "And now one question you have\nwith mutual information is, what defines a significant\nlevel of mutual information?",
    "start": "4327300",
    "end": "4334057"
  },
  {
    "text": "So an obvious way to do\nthis, to try to figure out what's significant, is\nto do randomizations. And so that's what they did.",
    "start": "4334057",
    "end": "4339139"
  },
  {
    "text": "They shuffled the\nexpression data, to compute mutual information\namong pairs of genes, where there isn't\nactually a need-- there shouldn't be\nany relationships.",
    "start": "4339139",
    "end": "4345411"
  },
  {
    "text": "Because the data\nhad been shuffled. And then you can decide whether\nthe observed mutual information is significantly\ngreater than when",
    "start": "4345411",
    "end": "4351940"
  },
  {
    "text": "you get from the\nrandomized data. Now, the other thing that\nhappens with mutual information is that indirect\neffects still apply",
    "start": "4351940",
    "end": "4358330"
  },
  {
    "text": "to degrees of\nmutual information. So let's consider the set of\ngenes that are shown on this.",
    "start": "4358330",
    "end": "4363350"
  },
  {
    "text": "So you've got G2,\nwhich is actually a regulator of G1 and G3.",
    "start": "4363350",
    "end": "4369250"
  },
  {
    "text": "So G2 is going to have\nhigh mutual information with G1, and with G3.",
    "start": "4369250",
    "end": "4376420"
  },
  {
    "text": "Now, what's it going\nto be about G1 and G3? They're going to behave\nvery similarly, as well.",
    "start": "4376420",
    "end": "4381610"
  },
  {
    "text": "So it'll be a high degree\nof mutual information between G1 and G3.",
    "start": "4381610",
    "end": "4386630"
  },
  {
    "text": "So if I just rely on\nmutual information, I can't tell what's a\nregulator and what's",
    "start": "4386630",
    "end": "4391800"
  },
  {
    "text": "a fellow at the same\nlevel of regulation. They're both being affected\nby something above them. I can't tell the difference\nbetween those two.",
    "start": "4391800",
    "end": "4398470"
  },
  {
    "text": "So they use what's called the\ndata processing inequality, where they say, well, these\nregulatory interactions",
    "start": "4398470",
    "end": "4405730"
  },
  {
    "text": "should have higher\nmutual information, than this, which is just\nbetween two common targets in the same parent.",
    "start": "4405730",
    "end": "4412449"
  },
  {
    "text": "And so they drop from their\nnetwork, those things which are the lower of the\nthree in a triangle.",
    "start": "4412450",
    "end": "4418115"
  },
  {
    "text": " So that was the original\nARACNe algorithm,",
    "start": "4418116",
    "end": "4423120"
  },
  {
    "text": "and then they modified\nit a little bit, to try to be more specific in\nterms of the regulators that were being picked up.",
    "start": "4423120",
    "end": "4428350"
  },
  {
    "text": "And so they called\nthis approach MINDy. And the core idea here,\nis that in addition",
    "start": "4428350",
    "end": "4435055"
  },
  {
    "text": "to the transcription\nfactors, you might have another protein that\nturns a transcription factor on",
    "start": "4435055",
    "end": "4440599"
  },
  {
    "text": "or off. So if I look over\ndifferent concentrations of the transcription factor,\ndifferent levels of expression",
    "start": "4440600",
    "end": "4446898"
  },
  {
    "text": "between transcription\nfactors, I might find that there are some cases\nwhere this other protein turns",
    "start": "4446898",
    "end": "4452410"
  },
  {
    "text": "it on, and other cases\nwhere it turns it off. So here, consider\nthese two data sets.",
    "start": "4452410",
    "end": "4459532"
  },
  {
    "text": "Looking at different\nconcentrations of particular transcription\nfactor and different expression levels, and in one\ncase-- the blue ones,",
    "start": "4459532",
    "end": "4465080"
  },
  {
    "text": "the modulator isn't\npresent at all, or present at it's\nlowest possible level. And in the red case, it's\npresent as a high level.",
    "start": "4465080",
    "end": "4472200"
  },
  {
    "text": "And you can see that when\nthe modulator is present only in low levels, there's no\nrelationship between a target",
    "start": "4472200",
    "end": "4477250"
  },
  {
    "text": "and it's transcription factor. Or when the modulator is\npresent at a high level, then there's this\nlinear response",
    "start": "4477250",
    "end": "4482650"
  },
  {
    "text": "of the target to it's\ntranscription factor. So this modulator seems to\nbe a necessary component. So they went through and\ndefined a whole bunch",
    "start": "4482650",
    "end": "4488820"
  },
  {
    "text": "of settings like this. And then systematically search\nthe data for these modulators.",
    "start": "4488820",
    "end": "4493989"
  },
  {
    "text": "So they started off with the\nexpression data set, genes in rows, experiments in columns.",
    "start": "4493990",
    "end": "4499080"
  },
  {
    "text": "They do a set of\nfiltering to remove things that are going to be\nproblematic for the analysis.",
    "start": "4499080",
    "end": "4506120"
  },
  {
    "text": "They look, for\nexample, for settings where you have-- they had to\nstart with a list of modulators and transcription factors,\nand they moved the ones",
    "start": "4506120",
    "end": "4512303"
  },
  {
    "text": "where there isn't enough\nvariation, and so on. And then they examine, for every\nmodulator and transcription",
    "start": "4512303",
    "end": "4518550"
  },
  {
    "text": "factor pair, cases\nwhere the modulator is present at its highest\nlevel, and where",
    "start": "4518550",
    "end": "4524280"
  },
  {
    "text": "it's present at\nit's lowest level. So when the modulator is present\nat a high level-- let's say,",
    "start": "4524280",
    "end": "4529513"
  },
  {
    "text": "when the modulator is\npresent at a high level, there's a high\nmutual information between the transcription\nfactor and the target.",
    "start": "4529514",
    "end": "4535140"
  },
  {
    "text": "When the modulator is absent,\nthere's no mutual information. That's a setting we\nlooked at before.",
    "start": "4535140",
    "end": "4540380"
  },
  {
    "text": "That would suggest that the\nmodulator is an activator. It's a positive modulator. You can have the\nopposite situation,",
    "start": "4540380",
    "end": "4546890"
  },
  {
    "text": "where when the modulator\nis present at low levels, there's mutual information\nbetween a transcription factor and it's target.",
    "start": "4546890",
    "end": "4552104"
  },
  {
    "text": "When the modulator is\npresent at a high level, you don't see anything. That would suggest\nthat the modulator is a negative regulator.",
    "start": "4552104",
    "end": "4557740"
  },
  {
    "text": "And then there are scenarios\nwhere there's either uniformly high\ninformation content between transcription factor\ntarget, or uniformly low.",
    "start": "4557740",
    "end": "4564640"
  },
  {
    "text": "So the modulator doesn't\nseem to be doing anything. So we break it down\ninto these categories.",
    "start": "4564640",
    "end": "4569949"
  },
  {
    "text": "And you can look at all\nthe different categories, in their supplemental tables. One thing that's\nkind of interesting",
    "start": "4569949",
    "end": "4575540"
  },
  {
    "text": "is they assume that regardless\nof how high the transcription factor goes, you'll\nalways see an increase",
    "start": "4575540",
    "end": "4581469"
  },
  {
    "text": "in the expression of the target. So there is no\nsaturation, which is an unnatural assumption\nin these data sets.",
    "start": "4581470",
    "end": "4590239"
  },
  {
    "text": "OK. So I think I'll close with this\nexample, from their experiment. And then in the\nnext lecture, we'll",
    "start": "4590240",
    "end": "4595390"
  },
  {
    "text": "look at how these\ndifferent methods fare against each other in\nthe DREAM challenge. So they specifically wanted\nto find regulators of MYC.",
    "start": "4595390",
    "end": "4603400"
  },
  {
    "text": "So here's data for a\nparticular regulator, SDK 38.",
    "start": "4603400",
    "end": "4608460"
  },
  {
    "text": "Here's the set of\nexpression of tumors where SDK 38\nexpression is lowest.",
    "start": "4608460",
    "end": "4613619"
  },
  {
    "text": "And a set of tumors where\nSDK 38 expression is highest. And they're sorted by the\nexpression level of MYC.",
    "start": "4613620",
    "end": "4619940"
  },
  {
    "text": "So on the left hand\nside, you'll see there's no particular\nrelationship between the expression level\nof MYC and the targets.",
    "start": "4619940",
    "end": "4625902"
  },
  {
    "text": "In the right hand side,\nthere is a relationship between the expression\nlevel of MYC and targets. So having, apparently--\nat least at this level",
    "start": "4625902",
    "end": "4632739"
  },
  {
    "text": "of mutual information, having\nhigher levels of SDK 38, cause a relationship to occur.",
    "start": "4632740",
    "end": "4638422"
  },
  {
    "text": "That would be example\nof an activator.  OK. So this technique has\na lot of advantages,",
    "start": "4638422",
    "end": "4644560"
  },
  {
    "text": "and allows you to search rapidly\nover very large data sets, to find potential target\ntranscription factor",
    "start": "4644560",
    "end": "4649800"
  },
  {
    "text": "relationships, and also\npotential modulators. It has some limitations. Where the key limitations\nis that the signal has",
    "start": "4649800",
    "end": "4655834"
  },
  {
    "text": "to be present in the\nexpression data set. So in the case of\na protein like p53, where we know it's activated\nby all sort of other processes,",
    "start": "4655834",
    "end": "4662690"
  },
  {
    "text": "phosphorylation or NF-kappaB,\nwhere it's regulated by phosphorylation, you\nmight not get any signal.",
    "start": "4662690",
    "end": "4668490"
  },
  {
    "text": "So there has to be a case\nwhere the transcription factor itself, is\nchanging expression. It also won't work if\nthe modulator is always",
    "start": "4668490",
    "end": "4674710"
  },
  {
    "text": "highly correlated\nwith its target, for some other\nbiological reason. So the modulator has to be\non, for other reasons, when",
    "start": "4674710",
    "end": "4680869"
  },
  {
    "text": "the target is, then\nyou'll never be able to divide the\ndata in this way.",
    "start": "4680870",
    "end": "4686070"
  },
  {
    "text": "One of the other\nthings I think that is problematic with\nthese networks is that you get such\nlarge networks, and they're very\nhard to interpret.",
    "start": "4686070",
    "end": "4691698"
  },
  {
    "text": "So in this case, this\nis the nearest neighbors of just one node in ARACNe. This is the mutual information\nnetwork of microRNA modulators",
    "start": "4691698",
    "end": "4700909"
  },
  {
    "text": "that has a quarter of\na million interactions. And in these data\nsets, often you",
    "start": "4700910",
    "end": "4706690"
  },
  {
    "text": "end up selecting a very,\nvery large fraction of all the potential modulators. So of all the candidate\ntranscription factors",
    "start": "4706690",
    "end": "4712702"
  },
  {
    "text": "in modulators, it\ncomes up with an answer that's roughly 10% to 20%\nof them are regulating any particular gene,\nwhich seems awfully high.",
    "start": "4712702",
    "end": "4719460"
  },
  {
    "text": "OK. So any questions on the\nmethods we've seen so far?",
    "start": "4719460",
    "end": "4724980"
  },
  {
    "text": "OK. So when we come\nback on Thursday, we'll take a look\nat head to head of how these different methods\nperform on both the synthetic",
    "start": "4724980",
    "end": "4731610"
  },
  {
    "text": "and the real data sets. ",
    "start": "4731610",
    "end": "4758579"
  }
]
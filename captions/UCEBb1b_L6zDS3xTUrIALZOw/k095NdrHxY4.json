[
  {
    "start": "0",
    "end": "21000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation, or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu.  GILBERT STRANG: So last time\nwas orthogonal matrices--",
    "start": "18140",
    "end": "27340"
  },
  {
    "start": "21000",
    "end": "48000"
  },
  {
    "text": "Q. And this time is\nsymmetric matrices, S.",
    "start": "27340",
    "end": "32995"
  },
  {
    "text": "So we're really talking about\nthe best matrices of all. Well, I'll start with any square\nmatrix and about eigenvectors.",
    "start": "32995",
    "end": "43620"
  },
  {
    "text": "But you've heard of\neigenvectors more than once-- more than twice-- more than 10 times, probably.",
    "start": "43620",
    "end": "50580"
  },
  {
    "start": "48000",
    "end": "326000"
  },
  {
    "text": "OK. So eigenvectors. And then, let's be sure we\nknow why they're useful,",
    "start": "50580",
    "end": "58440"
  },
  {
    "text": "and maybe compute one or two. But then we'll move\nto symmetric matrices",
    "start": "58440",
    "end": "65909"
  },
  {
    "text": "and what is special about those. And then, even more\nspecial and more important",
    "start": "65910",
    "end": "72060"
  },
  {
    "text": "will be positive definite\nsymmetric matrices-- so that when I say, positive\ndefinite, I mean symmetric.",
    "start": "72060",
    "end": "80280"
  },
  {
    "text": "So start with A. Next comes\nS. Then come the special S--",
    "start": "80280",
    "end": "86850"
  },
  {
    "text": "special symmetric\nmatrices that have this extra positive\ndefinite property.",
    "start": "86850",
    "end": "91950"
  },
  {
    "text": "OK. So start with A.\nSo an eigenvector--",
    "start": "91950",
    "end": "99360"
  },
  {
    "text": "if I multiply A by\nx, I get some vector.",
    "start": "99360",
    "end": "104470"
  },
  {
    "text": "And sometimes, if x is\nespecially chosen well,",
    "start": "104470",
    "end": "111010"
  },
  {
    "text": "Ax comes out in the\nsame direction as x. Ax comes out some\nnumber times x.",
    "start": "111010",
    "end": "121830"
  },
  {
    "text": "So there are-- normally,\nthere would be, for an n by n matrix-- so let's say A is n by n today.",
    "start": "121830",
    "end": "133040"
  },
  {
    "text": "Normally, if we\nlive right, there will be n different\nindependent vectors--",
    "start": "133040",
    "end": "141260"
  },
  {
    "text": "x eigenvectors-- that have\nthis special property.",
    "start": "141260",
    "end": "146739"
  },
  {
    "text": "And we can compute them\nby hand if n is 2 or 3--",
    "start": "146740",
    "end": "152680"
  },
  {
    "text": "2, mostly. But the computation of\nthe x's and the lambdas--",
    "start": "152680",
    "end": "158920"
  },
  {
    "text": "so this is for i\nequal 1 up to n,",
    "start": "158920",
    "end": "166230"
  },
  {
    "text": "if I use this sort\nof math shorthand-- that I have n of\nthese almost always.",
    "start": "166230",
    "end": "173880"
  },
  {
    "text": "And my first question is,\nwhat are they good for?",
    "start": "173880",
    "end": "179190"
  },
  {
    "text": "Why does course after course\nintroduce eigenvectors?",
    "start": "179190",
    "end": "185840"
  },
  {
    "text": "And to me the key property is\nseen by looking at A squared.",
    "start": "185840",
    "end": "192440"
  },
  {
    "text": "So let me look at A squared.  So it's another n by n matrix.",
    "start": "192440",
    "end": "200689"
  },
  {
    "text": "And we would ask, suppose\nwe know these guys? Suppose we've found\nthose somehow.",
    "start": "200690",
    "end": "207890"
  },
  {
    "text": "What about A squared? Is x an eigenvector\nof A squared also?",
    "start": "207890",
    "end": "215020"
  },
  {
    "text": "Well, the way to find out is\nto multiply A squared by x, and see what happens.",
    "start": "215020",
    "end": "221390"
  },
  {
    "text": "Do you see what's\ngoing to happen here? This is A times Ax,\nwhich is A times--",
    "start": "221390",
    "end": "230960"
  },
  {
    "text": "Ax is lambda x-- and now what do I do now?",
    "start": "230960",
    "end": "238150"
  },
  {
    "text": "Because I'm shooting\nfor the answer yes. X is an eigenvector\nof A squared also.",
    "start": "238150",
    "end": "244299"
  },
  {
    "text": "So what do I do? That number-- that\nlambda is just a number. I can put it anywhere I like.",
    "start": "244300",
    "end": "250930"
  },
  {
    "text": "So I can put it out front. And then I have Ax, which is?",
    "start": "250930",
    "end": "256170"
  },
  {
    "text": "AUDIENCE: Lambda x. GILBERT STRANG: Lambda x. Thanks. So I have another lambda x. So there's lambda squared x.",
    "start": "256170",
    "end": "261199"
  },
  {
    "text": "So I learned the\ncrucial thing here-- that x is also an\neigenvector of A squared,",
    "start": "261200",
    "end": "268270"
  },
  {
    "text": "and the eigenvalue\nis lambda squared.",
    "start": "268270",
    "end": "273699"
  },
  {
    "text": "And of course, I can keep going. So A to the nth--",
    "start": "273700",
    "end": "279025"
  },
  {
    "text": "x is lambda to the nth x. We have found the right vectors\nfor that particular matrix A.",
    "start": "279025",
    "end": "286659"
  },
  {
    "text": "What about A inverse x? That will be-- if\neverything is good--",
    "start": "286660",
    "end": "293230"
  },
  {
    "text": "1 over lambda x. Well, yeah.",
    "start": "293230",
    "end": "298750"
  },
  {
    "text": "So anytime I write\n1 over lambda, my mind says, you\ngotta make some comment",
    "start": "298750",
    "end": "307810"
  },
  {
    "text": "on the special case where\nit doesn't work, which is? AUDIENCE: Lambda\nis not equal to 0.",
    "start": "307810",
    "end": "313405"
  },
  {
    "text": "GILBERT STRANG: Yeah. If lambda is not 0, I'm golden. If lambda is 0, it\ndoesn't look good.",
    "start": "313405",
    "end": "322590"
  },
  {
    "text": "And what's happening\nif lambda is 0? AUDIENCE: A inverse [INAUDIBLE]. GILBERT STRANG: A doesn't\neven have an inverse.",
    "start": "322590",
    "end": "329428"
  },
  {
    "start": "326000",
    "end": "490000"
  },
  {
    "text": "If lambda was 0-- which it could be-- no rule against it.",
    "start": "329428",
    "end": "336710"
  },
  {
    "text": "If lambda was 0, this would\nsay, A times the eigenvector is 0 times the eigenvector.",
    "start": "336710",
    "end": "342860"
  },
  {
    "text": "So that would tell me\nthat the eigenvector is in the null space. It would tell me the\nmatrix A isn't invertible.",
    "start": "342860",
    "end": "351040"
  },
  {
    "text": "It's taking some vector x to 0. And so everything clicks.",
    "start": "351040",
    "end": "358550"
  },
  {
    "text": "This works when it should work. And if we have other fun--\nany function of the matrix,",
    "start": "358550",
    "end": "365950"
  },
  {
    "text": "we could define the\nexponential of a matrix. 18.03 would do that. Let's just write it down,\nas if we know what it means.",
    "start": "365950",
    "end": "375340"
  },
  {
    "text": "Does it have the\nsame eigenvector? Well, sure. Because e to the At-- the exponential of a matrix--",
    "start": "375340",
    "end": "382900"
  },
  {
    "text": "if I see e to the something-- I think of that\nlong, infinite series that gives the exponential.",
    "start": "382900",
    "end": "389979"
  },
  {
    "text": "Those-- all the terms in\nthat series have powers of A. So everything is working.",
    "start": "389980",
    "end": "396250"
  },
  {
    "text": "Every term in that series-- x is an eigenvector. And when I put it\nall together, I",
    "start": "396250",
    "end": "401830"
  },
  {
    "text": "learn that the eigenvalue\nis e to the lambda t.",
    "start": "401830",
    "end": "407740"
  },
  {
    "text": "That's just a typical\nand successful work use.",
    "start": "407740",
    "end": "414669"
  },
  {
    "text": "OK. So that's eigenvectors\nand eigenvalues, and we'll find some in a minute.",
    "start": "414670",
    "end": "422810"
  },
  {
    "text": " Now, so I'm claiming that this--",
    "start": "422810",
    "end": "427965"
  },
  {
    "text": " that from this first thing--\nwhich was just about certain",
    "start": "427965",
    "end": "436120"
  },
  {
    "text": "vectors are special-- now we're beginning to\nsee why they're useful.",
    "start": "436120",
    "end": "441490"
  },
  {
    "text": "So special is good. Useful is even better. So let me take any\nvector, say v. And OK,",
    "start": "441490",
    "end": "457810"
  },
  {
    "text": "what do I want to do? I want to use eigenvectors. This v is probably\nnot an eigenvector.",
    "start": "457810",
    "end": "465280"
  },
  {
    "text": "But I'm supposing that\nI've got n of them. You and I are agreed\nthat there are",
    "start": "465280",
    "end": "471400"
  },
  {
    "text": "some matrices for\nwhich there are not a full set of eigenvectors.",
    "start": "471400",
    "end": "477290"
  },
  {
    "text": "That's really the main\nsort of annoying point",
    "start": "477290",
    "end": "482480"
  },
  {
    "text": "in the whole subject\nof linear algebra, is some matrices don't\nhave enough eigenvectors.",
    "start": "482480",
    "end": "488870"
  },
  {
    "text": "But almost all do,\nand let's go forward",
    "start": "488870",
    "end": "494280"
  },
  {
    "text": "assuming our matrix has. OK. So if I've got n independent\neigenvectors, that's a basis.",
    "start": "494280",
    "end": "502200"
  },
  {
    "text": "I can write any vector\nv as a combination of those eigenvectors.",
    "start": "502200",
    "end": "510620"
  },
  {
    "text": "Right. And then I can find out\nwhat A to any power.",
    "start": "510620",
    "end": "520090"
  },
  {
    "text": "So that's the point. This is going to be the\nsimple and reason why",
    "start": "520090",
    "end": "529290"
  },
  {
    "text": "we like to have-- we like to know\nthe eigenvectors. Because if I choose those\nas my basis vectors,",
    "start": "529290",
    "end": "536470"
  },
  {
    "text": "v is a combination of them. Now if I multiply by A, or A\nsquared, or A to the k power,",
    "start": "536470",
    "end": "544030"
  },
  {
    "text": "then it's linear. So I can multiply each\none by A to the k. And what do I get if I multiply\nthat guy by A to the kth power?",
    "start": "544030",
    "end": "555300"
  },
  {
    "text": "OK. Well, I'm just going\nto use-- or, here I said n, but let me say k.",
    "start": "555300",
    "end": "561122"
  },
  {
    "text": "Because n-- I'm sorry. I'm using n for the\nsize of the matrix.",
    "start": "561122",
    "end": "566210"
  },
  {
    "text": "So I better use k for\nthe typical case here.",
    "start": "566210",
    "end": "571870"
  },
  {
    "text": "So what do I get? Just help me through\nthis and we're happy.",
    "start": "571870",
    "end": "579140"
  },
  {
    "text": "So what happens when I\nmultiply that by A to the k?",
    "start": "579140",
    "end": "584330"
  },
  {
    "text": "It's an eigenvector,\nremember, so when I multiply by A to the k, I get?",
    "start": "584330",
    "end": "589670"
  },
  {
    "text": "AUDIENCE: C1. GILBERT STRANG: C1. That's just a number. And A to the k times\nthat eigenvector gives?",
    "start": "589670",
    "end": "596839"
  },
  {
    "text": "AUDIENCE: Lambda 1. GILBERT STRANG: Lambda 1 to\nthe k times the eigenvector. ",
    "start": "596840",
    "end": "603970"
  },
  {
    "text": "Right? That's the whole point. And linearity says keep going.",
    "start": "603970",
    "end": "611339"
  },
  {
    "text": "Cn, lambda n to\nthe kth power, Xn.",
    "start": "611340",
    "end": "618270"
  },
  {
    "text": "In other words, I can take-- I can apply any\npower of a matrix.",
    "start": "618270",
    "end": "624820"
  },
  {
    "text": "I can apply the\nexponential of a matrix. I can do anything\nquickly, because I've",
    "start": "624820",
    "end": "633380"
  },
  {
    "text": "got the eigenvector. So really, I'm\nsaying the first use",
    "start": "633380",
    "end": "638630"
  },
  {
    "text": "for eigenvectors-- maybe the\nprinciple use for which they were invented-- is to be able\nto solve difference equations.",
    "start": "638630",
    "end": "647660"
  },
  {
    "text": "So if I call that Vk-- the kth power-- then the\nequation I'm solving here",
    "start": "647660",
    "end": "655790"
  },
  {
    "text": "is a one step\ndifference equation.",
    "start": "655790",
    "end": "661529"
  },
  {
    "text": "This is my difference equation. And if I wanted to\nuse exponentials, the equation I would be solving\nwould be dv, dt equal Av.",
    "start": "661530",
    "end": "672090"
  },
  {
    "text": " Solution to discrete steps, or\ncontinuous time evolution comes",
    "start": "672090",
    "end": "689820"
  },
  {
    "text": "is trivial, if I know\nthe eigenvectors. Because here is the\nsolution to this one.",
    "start": "689820",
    "end": "695560"
  },
  {
    "text": "And the solution to this\none is the same thing, C1, e to the lambda, 1, t, x1.",
    "start": "695560",
    "end": "703480"
  },
  {
    "text": "Is that what you were expecting\nfor the solution here?",
    "start": "703480",
    "end": "709180"
  },
  {
    "text": "Because if I takes\nthe derivative, it brings down a lambda. If I multiply by A, it\nbrings down a lambda--",
    "start": "709180",
    "end": "716680"
  },
  {
    "text": "so, plus the other guys. ",
    "start": "716680",
    "end": "723520"
  },
  {
    "text": "OK. ",
    "start": "723520",
    "end": "729600"
  },
  {
    "text": "Not news, but important to\nremember what eigenvectors",
    "start": "729600",
    "end": "735110"
  },
  {
    "text": "are for in the first place. Good. ",
    "start": "735110",
    "end": "741960"
  },
  {
    "start": "740000",
    "end": "917000"
  },
  {
    "text": "Yeah. Let me move ahead. Oh-- one matrix fact\nis about something",
    "start": "741960",
    "end": "754269"
  },
  {
    "text": "called similar matrices. So I have on my\nmatrix A. Then I have the idea of what it\nmeans to be similar to A,",
    "start": "754270",
    "end": "761980"
  },
  {
    "text": "so B is similar to A.\nWhat does that mean?",
    "start": "761980",
    "end": "776740"
  },
  {
    "text": "So here's what it\nmeans, first of all. It means that B can\nbe found from A, by--",
    "start": "776740",
    "end": "784449"
  },
  {
    "text": "this is the key operation here-- multiplying by a matrix\nM, and its inverse--",
    "start": "784450",
    "end": "790930"
  },
  {
    "text": "M inverse AM. When I see two\nmatrices, B and A,",
    "start": "790930",
    "end": "798550"
  },
  {
    "text": "that are connected by\nthat kind of a change,",
    "start": "798550",
    "end": "804620"
  },
  {
    "text": "M could be any\ninvertible matrix. Then I would say B was similar\nto A. And that changed--",
    "start": "804620",
    "end": "814410"
  },
  {
    "text": "that appearance of\nAM is pretty natural. If I change variables\nhere by M, then I get--",
    "start": "814410",
    "end": "823769"
  },
  {
    "text": "that similar matrix\nwill show up. So what's the key factor?",
    "start": "823770",
    "end": "829110"
  },
  {
    "text": "Do you remember the key\nfact about similar matrices? If B and A are\nconnected like that--",
    "start": "829110",
    "end": "836972"
  },
  {
    "text": "AUDIENCE: They have\nthe same eigenvalues. GILBERT STRANG: They have\nthe same eigenvalues. So this is just a useful\npoint to remember.",
    "start": "836972",
    "end": "844170"
  },
  {
    "text": "So I'll-- this is like\none fact in the discussion",
    "start": "844170",
    "end": "853320"
  },
  {
    "text": "of eigenvalues and eigenvectors. So similar matrices,\nsame eigenvalues.",
    "start": "853320",
    "end": "868600"
  },
  {
    "start": "868600",
    "end": "877139"
  },
  {
    "text": "Yeah. So in some way in the\neigenvalue, eigenvector world,",
    "start": "877140",
    "end": "882810"
  },
  {
    "text": "they're in this--\nthey belong together. ",
    "start": "882810",
    "end": "889390"
  },
  {
    "text": "They're connected by this\nrelation that just turns out",
    "start": "889390",
    "end": "894503"
  },
  {
    "text": "to be the right thing.  Actually, that is-- it gives\nus a clue of how eigenvalues",
    "start": "894503",
    "end": "903820"
  },
  {
    "text": "are actually computed. Well, they're actually\ncomputed by typing eig of A,",
    "start": "903820",
    "end": "910510"
  },
  {
    "text": "with parentheses around\nA. That's how they're-- in real life.",
    "start": "910510",
    "end": "917890"
  },
  {
    "start": "917000",
    "end": "1217000"
  },
  {
    "text": "But what happens when\nyou type eig of A? Well, you could say\nthe eigenvalue shows up",
    "start": "917890",
    "end": "924010"
  },
  {
    "text": "on the screen. But something had\nto happen in there. And what happened\nwas that MATLAB--",
    "start": "924010",
    "end": "933250"
  },
  {
    "text": "or whoever-- took that matrix\nA, started using good choices",
    "start": "933250",
    "end": "940540"
  },
  {
    "text": "of m--  better and better. ",
    "start": "940540",
    "end": "947170"
  },
  {
    "text": "Took a bunch of steps\nwith different m's. Because if I do another m, I\nstill have a similar matrix,",
    "start": "947170",
    "end": "953860"
  },
  {
    "text": "right? If I take B and do a\ndifferent m2 to B--",
    "start": "953860",
    "end": "960300"
  },
  {
    "text": "so I get something\nsimilar to B, then that's also similar\nto A. I've got a whole family of\nsimilar things there.",
    "start": "960300",
    "end": "967019"
  },
  {
    "text": "And what does MATLAB do with\nall these m's, m1 and m2 and m3",
    "start": "967020",
    "end": "973410"
  },
  {
    "text": "and so on? It brings the matrix\nto a triangular matrix.",
    "start": "973410",
    "end": "982140"
  },
  {
    "text": "It gets the eigenvalues\nshowing up on the diagonal. ",
    "start": "982140",
    "end": "987620"
  },
  {
    "text": "It's just tremendously-- it\nwas an inspiration when that--",
    "start": "987620",
    "end": "993110"
  },
  {
    "text": "when the good choice\nof m appeared. And let me just say-- because I'm going on\nto symmetric matrices--",
    "start": "993110",
    "end": "1001120"
  },
  {
    "text": "that for a symmetric matrices,\neverything is sort of clean.",
    "start": "1001120",
    "end": "1007360"
  },
  {
    "text": "You not only go to\na triangular matrix, you go toward a diagonal matrix.",
    "start": "1007360",
    "end": "1014380"
  },
  {
    "text": "They off-- you\nchoose m's that make the off diagonal stuff smaller\nand smaller and smaller.",
    "start": "1014380",
    "end": "1020710"
  },
  {
    "text": "And the eigenvalues\nare not changing. So there, shooting up on the\ndiagonal, are the eigenvalues.",
    "start": "1020710",
    "end": "1028799"
  },
  {
    "text": "So I guess I should\nverify that fact, that similar matrices\nhave the same eigenvalues.",
    "start": "1028800",
    "end": "1036329"
  },
  {
    "text": "Can we-- there can't\nbe much to show. There can't be much in the\nproof because that's all I know.",
    "start": "1036329",
    "end": "1044709"
  },
  {
    "text": "And I want to know its\neigenvalues and eigenvectors. So let me say, suppose m\ninverse Am has the eigenvector",
    "start": "1044710",
    "end": "1052920"
  },
  {
    "text": "y and the eigenvalue of lambda. ",
    "start": "1052920",
    "end": "1061360"
  },
  {
    "text": "And I want to show-- do I want to show that y is an\neigenvector also, of A itself?",
    "start": "1061360",
    "end": "1068809"
  },
  {
    "text": "No. Eigenvectors are changing. Do I want to show that lambda\nis an eigenvalue of A itself?",
    "start": "1068810",
    "end": "1076610"
  },
  {
    "text": "Yes. That's my point. So can we see that? Ha.",
    "start": "1076610",
    "end": "1081650"
  },
  {
    "text": "Can I see that lambda\nis an eigenvector? There's not a lot to do here.",
    "start": "1081650",
    "end": "1087440"
  },
  {
    "text": "I mean, if I can't do it soon,\nI'm never going to do it, because-- so what am I going to do?",
    "start": "1087440",
    "end": "1093845"
  },
  {
    "text": "AUDIENCE: Define the\nvector x equals my-- GILBERT STRANG: Yeah, I could. Yeah.",
    "start": "1093845",
    "end": "1099320"
  },
  {
    "text": "X is-- m-y is going to be a\nkey, and I can see m-y coming. Just-- when I see m\ninverse over there,",
    "start": "1099320",
    "end": "1106550"
  },
  {
    "text": "what am I going to do\nwith the darn thing? AUDIENCE: [INAUDIBLE] GILBERT STRANG: I'm going\nto put it on the other side. I'm going to multiply\nthat equation by m.",
    "start": "1106550",
    "end": "1114020"
  },
  {
    "text": "So I'll have-- that will\nput the m over here. And I'll have A-M-y\nequals lambda My, right?",
    "start": "1114020",
    "end": "1124630"
  },
  {
    "text": " And is that telling me\nwhat I want to know?",
    "start": "1124630",
    "end": "1130520"
  },
  {
    "text": "Yes. That's saying that My-- that you wisely suggested\nto give a name x to--",
    "start": "1130520",
    "end": "1138340"
  },
  {
    "text": "is lambda times My. Do you see that? That the eigenvalue\nlambda didn't change.",
    "start": "1138340",
    "end": "1146650"
  },
  {
    "text": "The eigenvector did change. It changed from y to My. That's the x.",
    "start": "1146650",
    "end": "1153350"
  },
  {
    "text": "The eigenvector of x. This is lambda x.",
    "start": "1153350",
    "end": "1158530"
  },
  {
    "text": "Yeah. So that's the role of M. It\njust gives you a different basis",
    "start": "1158530",
    "end": "1164110"
  },
  {
    "text": "for eigenvectors. But it does not\nchange eigenvalues. Right. Yeah.",
    "start": "1164110",
    "end": "1170250"
  },
  {
    "text": "OK. So those are similar matrices.",
    "start": "1170250",
    "end": "1175380"
  },
  {
    "text": "Yeah, some other\ngood things happen. A lot of people\ndon't know-- in fact, I wasn't very\nconscious of the fact",
    "start": "1175380",
    "end": "1182610"
  },
  {
    "text": "that A times B has the same\neigenvalues as B times A. Well,",
    "start": "1182610",
    "end": "1188500"
  },
  {
    "text": "I should maybe write that down. AB has the same eigenvalues--",
    "start": "1188500",
    "end": "1198190"
  },
  {
    "text": "the same non-zero ones-- you'll see. I have to-- as BA.",
    "start": "1198190",
    "end": "1207240"
  },
  {
    "text": "This is any A and B same size. I'm not talking\nsimilar matrices here.",
    "start": "1207240",
    "end": "1213389"
  },
  {
    "text": "I'm talking any\ntwo A and B. Yeah.",
    "start": "1213390",
    "end": "1219270"
  },
  {
    "start": "1217000",
    "end": "1451000"
  },
  {
    "text": "So that's a good\nthing that happens. Now could we see y?",
    "start": "1219270",
    "end": "1229880"
  },
  {
    "text": "And then I'm going to be really\npretty happy with basic fact",
    "start": "1229880",
    "end": "1235240"
  },
  {
    "text": "about eigenvalues. So if I want to show\nthat two things have",
    "start": "1235240",
    "end": "1241070"
  },
  {
    "text": "the same eigenvalues,\nwhat do you propose? Show that they are similar.",
    "start": "1241070",
    "end": "1249660"
  },
  {
    "text": "I already said, if\nthey are similar. So is there an m? Is there an m that will\nconnect this matrix?",
    "start": "1249660",
    "end": "1258370"
  },
  {
    "text": "So is there an m that will\nmultiply this matrix that way?",
    "start": "1258370",
    "end": "1265820"
  },
  {
    "text": "So that would be similar to AB. And can I produce BA then? ",
    "start": "1265820",
    "end": "1276769"
  },
  {
    "text": "So I'll just put the\nword want up here. ",
    "start": "1276770",
    "end": "1282960"
  },
  {
    "text": "I want-- if I have\nthat, then I'm",
    "start": "1282960",
    "end": "1288000"
  },
  {
    "text": "done, because that's saying that\nthose two matrices, AB and BA, are similar.",
    "start": "1288000",
    "end": "1293160"
  },
  {
    "text": "And I know that then they\nhave the same eigenvalues. So what should m be?",
    "start": "1293160",
    "end": "1301425"
  },
  {
    "text": "M should be-- so what is M here?",
    "start": "1301425",
    "end": "1309640"
  },
  {
    "text": "I want that to be true. ",
    "start": "1309640",
    "end": "1314700"
  },
  {
    "text": "Should M be B? Yeah. M equal B. Boy.",
    "start": "1314700",
    "end": "1321020"
  },
  {
    "text": "Not the most hidden fact here. Take M equal B.",
    "start": "1321020",
    "end": "1331110"
  },
  {
    "text": "So then I have B times\nA, times BB inverse-- which is the identity.",
    "start": "1331110",
    "end": "1336130"
  },
  {
    "text": "So I have B times A. Yes. OK. So AB and BA are fine.",
    "start": "1336130",
    "end": "1343440"
  },
  {
    "text": "Now, what do you think\nabout this question? Are the eigenvalues-- I\nnow know that AB and BA",
    "start": "1343440",
    "end": "1351610"
  },
  {
    "text": "have the same eigenvalues. And the reason I had to be\ncareful about non-zero is that",
    "start": "1351610",
    "end": "1360730"
  },
  {
    "text": "if I had zero\neigenvalues, then-- AUDIENCE: [INAUDIBLE]",
    "start": "1360730",
    "end": "1366054"
  },
  {
    "text": "GILBERT STRANG: Yeah. I can't count on those inverses. Right. Right.",
    "start": "1366055",
    "end": "1371570"
  },
  {
    "text": "So that's why I put it\nin that little qualifier. But now I want to\nask this question.",
    "start": "1371570",
    "end": "1379190"
  },
  {
    "text": "If I know the eigenvalues of A-- separately, by\nitself, A-- and of B--",
    "start": "1379190",
    "end": "1385570"
  },
  {
    "text": "now I'm talking about any\ntwo matrices, A and B. If I have two matrices, A--",
    "start": "1385570",
    "end": "1392855"
  },
  {
    "text": "I have a matrix\nA and a matrix B. And I know their eigenvalues\nand their eigenvalues.",
    "start": "1392855",
    "end": "1399169"
  },
  {
    "text": "What about AB? A times B. Can I multiply\nthe eigenvalues of A times",
    "start": "1399170",
    "end": "1405510"
  },
  {
    "text": "the eigenvalues of B? Don't do it. Right. Yes. Right. The eigenvalues of A\ntimes the eigenvalues of B",
    "start": "1405510",
    "end": "1413340"
  },
  {
    "text": "could be damn near anything. Right. They're not connected to the\neigenvalues of AB specially.",
    "start": "1413340",
    "end": "1420890"
  },
  {
    "text": "And maybe something could\nbe discovered, but not much. And similarly, for\nA plus B. So yeah.",
    "start": "1420890",
    "end": "1430920"
  },
  {
    "text": "So let me just write\ndown this point. Eigenvalues of A plus\nB are generally not",
    "start": "1430920",
    "end": "1440100"
  },
  {
    "text": "eigenvalues of A plus\neigenvalues of B.",
    "start": "1440100",
    "end": "1448830"
  },
  {
    "text": "Generally not. Just-- there is no reason. And the reason that that's--",
    "start": "1448830",
    "end": "1455580"
  },
  {
    "start": "1451000",
    "end": "1521000"
  },
  {
    "text": "I get that no answer is,\nthat the eigenvectors can be all different.",
    "start": "1455580",
    "end": "1461040"
  },
  {
    "text": "If the eigenvectors\nfor A are totally different from the\neigenvectors for B,",
    "start": "1461040",
    "end": "1466300"
  },
  {
    "text": "then A plus B will have probably\nsome other, totally different eigenvectors, and there's\nnothing happening there.",
    "start": "1466300",
    "end": "1474360"
  },
  {
    "text": " That's sort of thoughts\nabout eigenvalues in general.",
    "start": "1474360",
    "end": "1483650"
  },
  {
    "text": "And I could-- there'd be a\nwhole section on eigenvectors,",
    "start": "1483650",
    "end": "1490230"
  },
  {
    "text": "but I'm really interested\nin eigenvectors of symmetric matrices.",
    "start": "1490230",
    "end": "1496450"
  },
  {
    "text": "So I'm going to move\non to that topic.",
    "start": "1496450",
    "end": "1502549"
  },
  {
    "text": "So now, having talked\nabout any matrix A, I'm going to specialize\nto symmetric matrices,",
    "start": "1502550",
    "end": "1509710"
  },
  {
    "text": "see what's special\nabout the eigenvalues there, what's special\nabout eigenvectors there.",
    "start": "1509710",
    "end": "1514790"
  },
  {
    "text": "And I think we've\nalready said it in class. So let me-- let me\nask you to tell me",
    "start": "1514790",
    "end": "1520070"
  },
  {
    "text": "about it-- tell me again. So I'll call that matrix\nS now, as a reminder",
    "start": "1520070",
    "end": "1526270"
  },
  {
    "start": "1521000",
    "end": "1571000"
  },
  {
    "text": "always that I'm talking here\nabout symmetric matrices. So what do I-- what are\nthe key facts to know?",
    "start": "1526270",
    "end": "1533710"
  },
  {
    "text": "Eigenvalues are real\nnumbers, if the matrix is.",
    "start": "1533710",
    "end": "1544360"
  },
  {
    "text": "I'm thinking of real\nsymmetric matrices. Of course, other\nreal matrices could",
    "start": "1544360",
    "end": "1551059"
  },
  {
    "text": "have imaginary eigenvalues. Other real matrices-- so just--",
    "start": "1551060",
    "end": "1557620"
  },
  {
    "text": "let's just think for a moment. Yeah. Maybe I'll just put it here. Can I back up, before I keep\ngoing with symmetric matrices?",
    "start": "1557620",
    "end": "1569760"
  },
  {
    "text": "So you take a matrix like that.",
    "start": "1569760",
    "end": "1575610"
  },
  {
    "start": "1571000",
    "end": "1919000"
  },
  {
    "text": " Q, yeah.",
    "start": "1575610",
    "end": "1580850"
  },
  {
    "text": "That would be a Q. But it's\nnot specially a Q. Maybe the most remarkable\nthing about that matrix",
    "start": "1580850",
    "end": "1588320"
  },
  {
    "text": "is that it's anti-symmetric. So I'll call it A. Right.",
    "start": "1588320",
    "end": "1593630"
  },
  {
    "text": "If I transpose that\nmatrix, what do I get? AUDIENCE: The negative.",
    "start": "1593630",
    "end": "1598900"
  },
  {
    "text": "GILBERT STRANG: The negative. So that's like anti-symmetric. And I claim that an\nanti-symmetric matrix",
    "start": "1598900",
    "end": "1605430"
  },
  {
    "text": "has imaginary eigenvalues. So that's a 90 degree rotation.",
    "start": "1605430",
    "end": "1611010"
  },
  {
    "text": " And you might say, what\ncould be simpler than that?",
    "start": "1611010",
    "end": "1617039"
  },
  {
    "text": "A 90 degree rotation--\nthat's not a weird matrix. But from the point of\nview of eigenvectors,",
    "start": "1617040",
    "end": "1623740"
  },
  {
    "text": "something a little odd\nhas to happen, right? Because if I have a\n90 degree rotation--",
    "start": "1623740",
    "end": "1631010"
  },
  {
    "text": "if I take a vector x-- any vector x-- could it\npossibly be an eigenvector?",
    "start": "1631010",
    "end": "1638250"
  },
  {
    "text": "Well, apply A to it. You'd be off in\nthis direction, Ax.",
    "start": "1638250",
    "end": "1644510"
  },
  {
    "text": "And there is no way that\nAx can be a multiple of x.",
    "start": "1644510",
    "end": "1650390"
  },
  {
    "text": "So there's no real eigenvector\nfor that anti-symmetric matrix, or any anti-symmetric matrix.",
    "start": "1650390",
    "end": "1658710"
  },
  {
    "text": "So you see that when we\nsay that the eigenvalues of a symmetric matrix\nare real, we're",
    "start": "1658710",
    "end": "1666090"
  },
  {
    "text": "saying that this\ncouldn't happen-- that this couldn't happen\nif A were symmetric.",
    "start": "1666090",
    "end": "1671160"
  },
  {
    "text": "And here, it's the very\nopposite, it's anti-symmetric. ",
    "start": "1671160",
    "end": "1676880"
  },
  {
    "text": "Well, while that's on the board,\nyou might say, wait a minute. How could that have any\neigenvector whatsoever?",
    "start": "1676880",
    "end": "1682159"
  },
  {
    "text": " So what is an eigenvector\nof that matrix A?",
    "start": "1682160",
    "end": "1689299"
  },
  {
    "text": "How do you find the\neigenvectors of A? When they're 2 by 2, that's a\ncalculation we know how to do.",
    "start": "1689300",
    "end": "1699850"
  },
  {
    "text": "You remember the steps there? I'm looking for\nAx equal lambda x.",
    "start": "1699850",
    "end": "1706690"
  },
  {
    "text": "So right now I'm looking\nfor both lambda and x. I've got 2. It's not linear, but I'm going\nto bring this over to this side",
    "start": "1706690",
    "end": "1715900"
  },
  {
    "text": "and write it as A minus\nlambda I, x equals 0. ",
    "start": "1715900",
    "end": "1723263"
  },
  {
    "text": "And then I'm going\nto look at that and say, wow, A minus lambda\nI must be not invertible,",
    "start": "1723263",
    "end": "1728850"
  },
  {
    "text": "b because it's got this\nx in its null space. So the determinant of\nthis matrix must be 0.",
    "start": "1728850",
    "end": "1736679"
  },
  {
    "text": " I couldn't have a null space\nunless the determinant is 0.",
    "start": "1736680",
    "end": "1746300"
  },
  {
    "text": "And then when I look at A\nminus lambda I, for this A,",
    "start": "1746300",
    "end": "1752590"
  },
  {
    "text": "I've got minus\nlambdas, minus A--",
    "start": "1752590",
    "end": "1760350"
  },
  {
    "text": "oh, A is just the 1. And that's minus 1. I'm going to take\nthe determinant.",
    "start": "1760350",
    "end": "1766250"
  },
  {
    "text": "And what am I going to\nget for the determinant? Lambda squared-- AUDIENCE: Plus 1.",
    "start": "1766250",
    "end": "1771722"
  },
  {
    "text": "GILBERT STRANG: Plus 1.  And I set that to 0.",
    "start": "1771722",
    "end": "1778156"
  },
  {
    "start": "1778156",
    "end": "1784220"
  },
  {
    "text": "So I'm just following\nall the rules, but it's showing me\nthat the lambda--",
    "start": "1784220",
    "end": "1791322"
  },
  {
    "text": "the two lambdas-- there\nare two lambdas here-- but they're not real, because\nthat equation, the roots",
    "start": "1791322",
    "end": "1798300"
  },
  {
    "text": "are i and minus i.  So those are the eigenvalues.",
    "start": "1798300",
    "end": "1804250"
  },
  {
    "text": " And they have the nice-- they have all the--",
    "start": "1804250",
    "end": "1810179"
  },
  {
    "text": "well, they are the eigenvalues. No doubt about it. ",
    "start": "1810180",
    "end": "1815560"
  },
  {
    "text": "With 2 by 2 there are two quick\nchecks that tell you, yeah, you did a calculation right.",
    "start": "1815560",
    "end": "1822790"
  },
  {
    "text": "If I add up the two\neigenvalues in this--",
    "start": "1822790",
    "end": "1831970"
  },
  {
    "text": "if I add up the two\neigenvalues for any matrix, and I'm going to do\nit for this one--",
    "start": "1831970",
    "end": "1837310"
  },
  {
    "text": "I get what answer? AUDIENCE: The trace? GILBERT STRANG: I get the\nsame answer from the adding--",
    "start": "1837310",
    "end": "1843430"
  },
  {
    "text": "add the lambdas gives\nme the same answer as add the diagonal\nof the matrix--",
    "start": "1843430",
    "end": "1856690"
  },
  {
    "text": "which I'm calling A. So if I\nadd the diagonal I get 0 and 0.",
    "start": "1856690",
    "end": "1863129"
  },
  {
    "text": "So it's 0 plus 0.  And this number adding the\ndiagonal is called the trace.",
    "start": "1863130",
    "end": "1871165"
  },
  {
    "text": " And we'll see it again\nbecause it's so simple.",
    "start": "1871165",
    "end": "1879130"
  },
  {
    "text": "Just adding the diagonal\nentries gives you a key bit of information.",
    "start": "1879130",
    "end": "1885370"
  },
  {
    "text": "When you add down\nthe diagonal it tells you the sum of\nthe eigenvalue-- some of the lambdas.",
    "start": "1885370",
    "end": "1892669"
  },
  {
    "text": "Doesn't tell you each\nlambda separately, but it tells you the sum.",
    "start": "1892670",
    "end": "1897890"
  },
  {
    "text": "So it tells you one\nfact by doing one thing. Yeah. That's pretty handy.",
    "start": "1897890",
    "end": "1905169"
  },
  {
    "text": "Gives you a quick\ncheck if you've-- when you compute\nthis determinant",
    "start": "1905170",
    "end": "1910840"
  },
  {
    "text": "and solve for lambda-- the thing you-- this is a way\nto compute eigenvalues by hand.",
    "start": "1910840",
    "end": "1923440"
  },
  {
    "start": "1919000",
    "end": "2694000"
  },
  {
    "text": "You could make a\nmistake, because it's a quadratic formula\nfor 2 by 2, but you can",
    "start": "1923440",
    "end": "1930770"
  },
  {
    "text": "check by adding the two roots. Do you get the same\nas the trace 0 plus 0?",
    "start": "1930770",
    "end": "1937640"
  },
  {
    "text": " Well, there's one other check,\nequally quick, for 2 by 2,",
    "start": "1937640",
    "end": "1945370"
  },
  {
    "text": "so 2 by 2s-- you really get them right. What's the other check to--",
    "start": "1945370",
    "end": "1951070"
  },
  {
    "text": "we add the eigenvalues,\nwe get the trace. AUDIENCE: [INAUDIBLE] GILBERT STRANG: We\nmultiply the eigenvalues.",
    "start": "1951070",
    "end": "1957010"
  },
  {
    "text": "So we take-- so now\nmultiply the lambdas.",
    "start": "1957010",
    "end": "1965640"
  },
  {
    "text": "So then I get i times minus i. And that should equal--\nlet's-- don't look yet.",
    "start": "1965640",
    "end": "1974549"
  },
  {
    "text": "What should it equal if I\nmultiply the eigenvalues I should get the?",
    "start": "1974550",
    "end": "1979870"
  },
  {
    "text": "AUDIENCE: Determinant. GILBERT STRANG:\nDeterminant, right. Of A. So that's\ntwo handy checks.",
    "start": "1979870",
    "end": "1992679"
  },
  {
    "text": "Add the eigenvalues--\nfor any size-- 3 by 3, 4 by 4-- but\nit's only two checks.",
    "start": "1992680",
    "end": "1998230"
  },
  {
    "text": "So for 2 by 2, it's\nkind of, you've got it. 3 by 3, 4 by 4--\nyou could still have",
    "start": "1998230",
    "end": "2003299"
  },
  {
    "text": "made an error and the two checks\ncould potentially still work.",
    "start": "2003300",
    "end": "2009630"
  },
  {
    "text": "Let's just check it out here. What's i times minus i? ",
    "start": "2009630",
    "end": "2015529"
  },
  {
    "text": "AUDIENCE: 1. GILBERT STRANG: 1. Because it's minus i\nsquared, and that's plus 1. And the determinant of\nthat matrix is 0 minus--",
    "start": "2015530",
    "end": "2024950"
  },
  {
    "text": "is 1. Yeah. OK. So we got 1. Good. ",
    "start": "2024950",
    "end": "2033610"
  },
  {
    "text": "Those are really the key\nfact about eigenvalues. ",
    "start": "2033610",
    "end": "2039010"
  },
  {
    "text": "But of course they're\nnot-- it's not as simple as solving Ax\nequal B to find them,",
    "start": "2039010",
    "end": "2046360"
  },
  {
    "text": "but if you follow through on\nthis idea of similar matrices,",
    "start": "2046360",
    "end": "2053980"
  },
  {
    "text": "and sort of chop down the\noff diagonal part, then sure enough, the\neigenvalue's gotta show up.",
    "start": "2053980",
    "end": "2062899"
  },
  {
    "text": "OK. Symmetric. ",
    "start": "2062900",
    "end": "2067989"
  },
  {
    "text": "Symmetric matrices. ",
    "start": "2067989",
    "end": "2073830"
  },
  {
    "text": "So now we're going\nto have symmetric, and then we'll have the special,\neven better than symmetric,",
    "start": "2073830",
    "end": "2082638"
  },
  {
    "text": "is symmetric positive definite. OK. Symmetric-- you told me the main\nfacts are the eigenvalues real,",
    "start": "2082639",
    "end": "2096329"
  },
  {
    "text": "the eigenvectors orthogonal.",
    "start": "2096330",
    "end": "2102040"
  },
  {
    "start": "2102040",
    "end": "2108030"
  },
  {
    "text": "And I guess, actually-- yeah. So I want to put those into\nmath symbols instead of words.",
    "start": "2108030",
    "end": "2117380"
  },
  {
    "start": "2117380",
    "end": "2122480"
  },
  {
    "text": "So yeah. I guess-- shall I just jump in?",
    "start": "2122480",
    "end": "2131270"
  },
  {
    "text": "And the other thing hidden\nthere-- but very important is--",
    "start": "2131270",
    "end": "2136830"
  },
  {
    "text": "there's a full set\nof eigenvectors, even if some eigenvalues\nhappen to be repeated,",
    "start": "2136830",
    "end": "2142400"
  },
  {
    "text": "like the identity matrix. It's still got plenty\nof eigenvectors.",
    "start": "2142400",
    "end": "2147940"
  },
  {
    "text": "So that's a added point\nthat I've not made there. And I could prove\nthose two statements,",
    "start": "2147940",
    "end": "2154720"
  },
  {
    "text": "but why don't I ask you to\naccept them and go onward?",
    "start": "2154720",
    "end": "2159998"
  },
  {
    "text": " What are we going\nto do with them?",
    "start": "2159998",
    "end": "2165240"
  },
  {
    "text": "OK. ",
    "start": "2165240",
    "end": "2171600"
  },
  {
    "text": "Can you just-- let's\nhave an example.  Let me put an example here.",
    "start": "2171600",
    "end": "2178690"
  },
  {
    "text": "Suppose S-- now\nI'm calling it S-- is 0s, 1 and 1.",
    "start": "2178690",
    "end": "2186609"
  },
  {
    "text": "So that's symmetric. What are its eigenvalues?",
    "start": "2186610",
    "end": "2193080"
  },
  {
    "text": "What are the eigenvalues of\nthat symmetric matrix, S? AUDIENCE: Plus and minus 1.",
    "start": "2193080",
    "end": "2198369"
  },
  {
    "text": "GILBERT STRANG:\nPlus and minus 1. Well, if you propose\ntwo eigenvalues,",
    "start": "2198370",
    "end": "2203660"
  },
  {
    "text": "I'll write them\ndown, 1 and minus 1. And then what will\nI do to check them?",
    "start": "2203660",
    "end": "2209727"
  },
  {
    "text": "AUDIENCE: Trace and determinant. GILBERT STRANG: Trace\nand determinant. OK. So are they-- is it true\nthat the eigenvalues",
    "start": "2209727",
    "end": "2217600"
  },
  {
    "text": "are 1 and minus 1? OK. How do I check the trace?",
    "start": "2217600",
    "end": "2224020"
  },
  {
    "text": "What is the trace\nof that matrix? 0. And what's the sum\nof the eigenvalues--",
    "start": "2224020",
    "end": "2230630"
  },
  {
    "text": "0. Good. What about determinant? What's the determinant of S? AUDIENCE: Minus 1.",
    "start": "2230630",
    "end": "2236289"
  },
  {
    "text": "GILBERT STRANG: Minus 1. The product of the\neigenvalues-- minus 1. So we've got it. OK.",
    "start": "2236290",
    "end": "2241480"
  },
  {
    "text": "What are the eigenvectors? What vector can you\nmultiply by and it",
    "start": "2241480",
    "end": "2249070"
  },
  {
    "text": "doesn't change direction-- in\nfact, doesn't change at all? I'm looking for the eigenvector\nthat's a steady state?",
    "start": "2249070",
    "end": "2255735"
  },
  {
    "text": "AUDIENCE: 0, 1? GILBERT STRANG: 0, 1? AUDIENCE: 1, 1.",
    "start": "2255735",
    "end": "2261090"
  },
  {
    "text": "GILBERT STRANG: I\nthink it's 1, 1. Yeah. So here is the lambdas. And then the eigenvectors are--",
    "start": "2261090",
    "end": "2267420"
  },
  {
    "text": "I think 1, 1.  Is that right?",
    "start": "2267420",
    "end": "2272760"
  },
  {
    "text": "Yeah. Sure. S is just a permutation here. It's just exchanging\nthe two entries.",
    "start": "2272760",
    "end": "2279230"
  },
  {
    "text": "So 1 and 1 won't change. And what's the\nother eigenvector?",
    "start": "2279230",
    "end": "2284378"
  },
  {
    "text": "AUDIENCE: Minus 1? GILBERT STRANG: 1 and minus 1. ",
    "start": "2284378",
    "end": "2295220"
  },
  {
    "text": "And then, I'm thinking--\nremembering about this similar stuff-- I'm thinking that S is\nsimilar to a matrix that",
    "start": "2295220",
    "end": "2307609"
  },
  {
    "text": "just shows the eigenvalues. So S is similar to-- I'm going to put in an M--",
    "start": "2307610",
    "end": "2314410"
  },
  {
    "text": "well, I'm going to\nconnect S-- that matrix-- with the eigenvalue matrix,\nwhich has the eigenvalues.",
    "start": "2314410",
    "end": "2325160"
  },
  {
    "text": "So here is my-- ",
    "start": "2325160",
    "end": "2330950"
  },
  {
    "text": "everybody calls that\nmatrix capital lambda, because everybody calls the\neigenvalues little lambda.",
    "start": "2330950",
    "end": "2337550"
  },
  {
    "text": "So the matrix that has them\nis called capital lambda. And I-- my claim is that\nthese guys are similar--",
    "start": "2337550",
    "end": "2346610"
  },
  {
    "text": "that this matrix, S, that\nyou're seeing up there-- I believe there\nis an M I believe",
    "start": "2346610",
    "end": "2352890"
  },
  {
    "text": "there is an M. So that S-- what did I put in here? So I'm following this pattern.",
    "start": "2352890",
    "end": "2359370"
  },
  {
    "text": "I believe that there would\nbe an M and an M inverse, so that this would mean that.",
    "start": "2359370",
    "end": "2367590"
  },
  {
    "text": "And that's nice. First of all, it would\nconfirm that the eigenvalues",
    "start": "2367590",
    "end": "2373530"
  },
  {
    "text": "stay the same, which\nwas certain to happen. And then it would also mean that\nI had got a diagonal matrix.",
    "start": "2373530",
    "end": "2383720"
  },
  {
    "text": "And of course, that's\na natural goal-- to get a diagonal matrix. ",
    "start": "2383720",
    "end": "2389540"
  },
  {
    "text": "So we might hope that\nthe M that gets us there is like an important matrix.",
    "start": "2389540",
    "end": "2397510"
  },
  {
    "text": "So do you see what\nI'm doing here? It comes under the heading\nof diagonalizing a matrix.",
    "start": "2397510",
    "end": "2404350"
  },
  {
    "text": "I start with a matrix, S.\nI find it's eigenvalues. They go on into lambda.",
    "start": "2404350",
    "end": "2411420"
  },
  {
    "text": "And I believe I can find an M,\nso that I see they're similar.",
    "start": "2411420",
    "end": "2419980"
  },
  {
    "text": "They have the same eigenvalues,\n1 and minus 1, both sides. So only remaining\nquestion is, what's M?",
    "start": "2419980",
    "end": "2427650"
  },
  {
    "text": "What's the matrix\nthat diagonalizes S?",
    "start": "2427650",
    "end": "2433262"
  },
  {
    "text": "The-- what have we\ngot left to use? AUDIENCE: The eigenvectors. GILBERT STRANG:\nThe eigenvectors.",
    "start": "2433262",
    "end": "2439140"
  },
  {
    "text": "The matrix that-- so, can\nI put the M over there? ",
    "start": "2439140",
    "end": "2445530"
  },
  {
    "text": "Yeah. I'll put-- that M\ninverse is going to go over to the other side.",
    "start": "2445530",
    "end": "2452180"
  },
  {
    "text": "Oh. It goes here, doesn't it? I was worried there. It didn't look good, but yeah.",
    "start": "2452180",
    "end": "2458630"
  },
  {
    "text": "So this is all going\nto be right, if-- ",
    "start": "2458630",
    "end": "2467990"
  },
  {
    "text": "this is what I'd like to have-- SM equal M lambda. SM equal M lambda.",
    "start": "2467990",
    "end": "2474810"
  },
  {
    "text": "That's diagonalizing a matrix. That's finding the M\nusing the eigenvectors.",
    "start": "2474810",
    "end": "2482390"
  },
  {
    "text": "That produces a\nsimilar matrix lambda, which has the eigenvalues. That's the great fact\nabout diagonalizing.",
    "start": "2482390",
    "end": "2495810"
  },
  {
    "text": "That's how you use--\nthat's another way to say, this is how the\neigenvectors pay off. You put them into M. You\ntake the similar matrix",
    "start": "2495810",
    "end": "2503880"
  },
  {
    "text": "and it's nice and diagonal. And do you see that\nthis will happen? S times-- so M has\nthe first eigenvector",
    "start": "2503880",
    "end": "2511410"
  },
  {
    "text": "and the second eigenvector. And I believe that first\neigenvector times the second--",
    "start": "2511410",
    "end": "2519690"
  },
  {
    "text": "and the second eigenvector--\nthat's M again, on this side. Let me just write\nin 1, 0, 0, minus 1.",
    "start": "2519690",
    "end": "2528375"
  },
  {
    "text": " I believe is has got to\nbe confirming that we've",
    "start": "2528375",
    "end": "2537620"
  },
  {
    "text": "done the thing right-- confirming that the\neigenvectors work here. ",
    "start": "2537620",
    "end": "2544550"
  },
  {
    "text": "Please make sense out\nof that last line. ",
    "start": "2544550",
    "end": "2550059"
  },
  {
    "text": "When you see that\nlast line, what do I mean to make sense out of it?",
    "start": "2550060",
    "end": "2555460"
  },
  {
    "text": "I want to see that that's true. How do I see that-- how do I do this--",
    "start": "2555460",
    "end": "2560770"
  },
  {
    "text": "so what's the left side\nand what's the right side? ",
    "start": "2560770",
    "end": "2567850"
  },
  {
    "text": "So what-- if I\nmultiply S by a couple of columns, what's the answer?",
    "start": "2567850",
    "end": "2574013"
  },
  {
    "text": "AUDIENCE: Sx1 and Sx2. GILBERT STRANG: Sx1 and Sx2. That's the beauty of\nmatrix multiplication.",
    "start": "2574013",
    "end": "2579589"
  },
  {
    "text": "If I multiply a matrix\nby another matrix, I can do it a column at a time.",
    "start": "2579590",
    "end": "2585400"
  },
  {
    "text": "There are four great ways\nto multiply matrices, so this is another one--",
    "start": "2585400",
    "end": "2590900"
  },
  {
    "text": "a column at a time. So this left hand\nside is Sx1, Sx2.",
    "start": "2590900",
    "end": "2596810"
  },
  {
    "text": "I just do each column. And what about the\nright hand side?",
    "start": "2596810",
    "end": "2603030"
  },
  {
    "text": "I can do that multiplication. AUDIENCE: X1 minus x2. GILBERT STRANG: X1 minus\nx2 did somebody say?",
    "start": "2603030",
    "end": "2609859"
  },
  {
    "text": "Death. No. I don't want-- Oh, x1-- sorry. You said it right.",
    "start": "2609860",
    "end": "2615360"
  },
  {
    "text": "OK. When you said x1 minus\nx2, I was subtracting. But you meant that that's--\nthe first column is x1,",
    "start": "2615360",
    "end": "2622660"
  },
  {
    "text": "and the second\ncolumn is minus x2. Correct. Sorry about that. ",
    "start": "2622660",
    "end": "2630640"
  },
  {
    "text": "And did we come out right? Yes. Of course, now I compare.",
    "start": "2630640",
    "end": "2636140"
  },
  {
    "text": "Sx1 is lambda one x1. Sx2 is lambda two x2.",
    "start": "2636140",
    "end": "2642860"
  },
  {
    "text": "And I'm golden. ",
    "start": "2642860",
    "end": "2648040"
  },
  {
    "text": "So what was the\npoint of this board? What did we learn?",
    "start": "2648040",
    "end": "2655640"
  },
  {
    "text": "We learned-- well, we kind of\nexpected that the original S",
    "start": "2655640",
    "end": "2660750"
  },
  {
    "text": "would be similar to the lambdas,\nbecause the eigenvalues match.",
    "start": "2660750",
    "end": "2666690"
  },
  {
    "text": "S has eigenvalues lambda. And this diagonal\nmatrix certainly has eigenvalues 1n minus 1.",
    "start": "2666690",
    "end": "2673260"
  },
  {
    "text": "A diagonal matrix--\nthe eigenvalues are right in front of you. So they're similar.",
    "start": "2673260",
    "end": "2678280"
  },
  {
    "text": "S is similar to the lambda. And there should be an M. And\nthen somebody suggested, maybe",
    "start": "2678280",
    "end": "2684310"
  },
  {
    "text": "the M is the eigenvectors. And that's the right answer. So finally, let me write\nthat conclusion here--",
    "start": "2684310",
    "end": "2693070"
  },
  {
    "text": " which isn't just for\nsymmetric matrices.",
    "start": "2693070",
    "end": "2699650"
  },
  {
    "text": "So maybe I should\nput it for matrix A.",
    "start": "2699650",
    "end": "2704710"
  },
  {
    "text": "So if it has lambdas\nand eigenvectors,",
    "start": "2704710",
    "end": "2712480"
  },
  {
    "text": "and the claim is that A\ntimes the eigenvector matrix",
    "start": "2712480",
    "end": "2722300"
  },
  {
    "text": "is the eigenvector matrix\ntimes the eigenvalues.",
    "start": "2722300",
    "end": "2728793"
  },
  {
    "start": "2728793",
    "end": "2734220"
  },
  {
    "text": "And I would shorten that\nto Ax equals x lambda.",
    "start": "2734220",
    "end": "2739750"
  },
  {
    "text": " And I could rewrite\nthat, and then I'll slow down, as A equal\nx lambda x inverse.",
    "start": "2739750",
    "end": "2749270"
  },
  {
    "start": "2749270",
    "end": "2758120"
  },
  {
    "text": "Really, this is\nbringing it all together in a simple, small formula. It's telling us that A\nis similar to lambda.",
    "start": "2758120",
    "end": "2767360"
  },
  {
    "text": "It's telling us the matrix\nM, that does the job-- it's a matrix of eigenvectors.",
    "start": "2767360",
    "end": "2773390"
  },
  {
    "text": "And so it's like a shorthand\nway to write the main fact",
    "start": "2773390",
    "end": "2781579"
  },
  {
    "text": "about eigenvalues\nand eigenvectors. What about A squared? Can I go back to\nthe very first--",
    "start": "2781580",
    "end": "2788840"
  },
  {
    "text": "I see time is close\nto the end here. What about A squared?",
    "start": "2788840",
    "end": "2793850"
  },
  {
    "text": "What are the eigenvectors\nof A squared? What are the eigenvalues\nof A squared?",
    "start": "2793850",
    "end": "2799410"
  },
  {
    "text": "That's like the whole\npoint of eigenvalues. Well, or I could just\nsquare that stupid thing.",
    "start": "2799410",
    "end": "2805160"
  },
  {
    "text": "X lambda, x inverse,\nx lambda, x inverse. And what have I got?",
    "start": "2805160",
    "end": "2812599"
  },
  {
    "text": "X inverse, x in the middle is-- AUDIENCE: Identity. GILBERT STRANG: Identity.",
    "start": "2812600",
    "end": "2818220"
  },
  {
    "text": "So I have x, lambda\nsquared, x inverse. And to me and to you that\nsays, the eigenvalues",
    "start": "2818220",
    "end": "2826910"
  },
  {
    "text": "have been squared. The eigenvectors didn't change. Yeah. OK.",
    "start": "2826910",
    "end": "2832300"
  },
  {
    "text": "And now finally,\nlast breath is, what if the matrix is symmetric?",
    "start": "2832300",
    "end": "2838280"
  },
  {
    "text": "Then we have different letters. That's the only-- that's\nthe significant change.",
    "start": "2838280",
    "end": "2843850"
  },
  {
    "text": "The eigenvector matrix is\nnow an orthogonal matrix.",
    "start": "2843850",
    "end": "2850310"
  },
  {
    "text": "I'm coming back to the key\nfact of what makes symmetric-- how do I read--",
    "start": "2850310",
    "end": "2855930"
  },
  {
    "text": "how do I see symmetric\nhelping me in the eigenvector and eigenvalue world?",
    "start": "2855930",
    "end": "2861180"
  },
  {
    "text": "Well, it tells me that the\neigenvectors are orthogonal.",
    "start": "2861180",
    "end": "2866960"
  },
  {
    "text": "So the x is Q. The\neigenvalues are real.",
    "start": "2866960",
    "end": "2873140"
  },
  {
    "text": "And the eigenvectors\nis x inverse. But now I'm going to make those\neigenvectors unit vectors.",
    "start": "2873140",
    "end": "2880910"
  },
  {
    "text": "I'm going to normalize it. So I'm really allowing-- I have an orthogonal matrix\nQ. So I have a different way",
    "start": "2880910",
    "end": "2888020"
  },
  {
    "text": "to write this, and this\nis the end of the-- today's class. Q lambda.",
    "start": "2888020",
    "end": "2895430"
  },
  {
    "text": "And what can you tell\nme about Q inverse? AUDIENCE: It's Q transpose. GILBERT STRANG:\nIt's Q transpose.",
    "start": "2895430",
    "end": "2900630"
  },
  {
    "text": "Thanks. So that was the last lecture. So now the orthogonal\nlecture is coming up",
    "start": "2900630",
    "end": "2907490"
  },
  {
    "text": "at the last second of the\nsymmetric matrices lecture. And this has the name\nspectral theorem,",
    "start": "2907490",
    "end": "2915380"
  },
  {
    "text": "which I'll just put there. ",
    "start": "2915380",
    "end": "2920560"
  },
  {
    "text": "And the whole point\nis that it tells you",
    "start": "2920560",
    "end": "2926640"
  },
  {
    "text": "what every symmetric\nmatrix looks like-- orthogonal eigenvectors,\nreal eigenvalues.",
    "start": "2926640",
    "end": "2934964"
  },
  {
    "start": "2934965",
    "end": "2935465"
  }
]
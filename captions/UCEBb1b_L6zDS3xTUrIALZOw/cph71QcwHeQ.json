[
  {
    "start": "0",
    "end": "87000"
  },
  {
    "start": "0",
    "end": "1030"
  },
  {
    "text": "Markov processes\ncan be very general.",
    "start": "1030",
    "end": "3580"
  },
  {
    "text": "They can run in continuous\nor discrete time,",
    "start": "3580",
    "end": "6330"
  },
  {
    "text": "can have a discrete or a\ncontinuous state space.",
    "start": "6330",
    "end": "10250"
  },
  {
    "text": "In this class, we'll\nrestrict ourselves",
    "start": "10250",
    "end": "12340"
  },
  {
    "text": "to discrete time discrete\nstate Markov chains.",
    "start": "12340",
    "end": "15670"
  },
  {
    "text": "These are the\nsimplest cases and are",
    "start": "15670",
    "end": "17480"
  },
  {
    "text": "the best to build our intuition.",
    "start": "17480",
    "end": "19380"
  },
  {
    "text": "So the state space is discrete,\nhere, finite with m states,",
    "start": "19380",
    "end": "26359"
  },
  {
    "text": "and time is discrete.",
    "start": "26360",
    "end": "29160"
  },
  {
    "text": "That is, at any\ndiscrete point in time,",
    "start": "29160",
    "end": "31890"
  },
  {
    "text": "the process is in\none of these m states",
    "start": "31890",
    "end": "34280"
  },
  {
    "text": "and let's say here,\nat any given time s.",
    "start": "34280",
    "end": "39769"
  },
  {
    "text": "And again, time is\ndiscrete, so think",
    "start": "39770",
    "end": "42520"
  },
  {
    "text": "about the following process.",
    "start": "42520",
    "end": "44680"
  },
  {
    "text": "You have someone hitting\na drum, indicating",
    "start": "44680",
    "end": "48660"
  },
  {
    "text": "that a transition occurs.",
    "start": "48660",
    "end": "50730"
  },
  {
    "text": "And what it means is that\nthe chain that was here",
    "start": "50730",
    "end": "53510"
  },
  {
    "text": "will then jump.",
    "start": "53510",
    "end": "55379"
  },
  {
    "text": "Let's say to another\nstate j at the next time.",
    "start": "55380",
    "end": "60220"
  },
  {
    "text": "So when the Markov chain\njumps it can jump on itself",
    "start": "60220",
    "end": "65190"
  },
  {
    "text": "or jump to another\nstate like here or here.",
    "start": "65190",
    "end": "68690"
  },
  {
    "start": "68690",
    "end": "71780"
  },
  {
    "text": "And then at time s plus\n1 someone hit the drum",
    "start": "71780",
    "end": "75659"
  },
  {
    "text": "and you jump again,\nand so on and so forth.",
    "start": "75660",
    "end": "79170"
  },
  {
    "text": "You can think of a very active\nfrog jumping from lilies",
    "start": "79170",
    "end": "82619"
  },
  {
    "text": "to lilies on the pond and\nfollowing a regular drumbeat.",
    "start": "82620",
    "end": "86445"
  },
  {
    "start": "86445",
    "end": "89450"
  },
  {
    "start": "87000",
    "end": "144000"
  },
  {
    "text": "So what is left to define\nare the various probabilities",
    "start": "89450",
    "end": "92570"
  },
  {
    "text": "of transitions, such as\nthe transition from i to j,",
    "start": "92570",
    "end": "96300"
  },
  {
    "text": "and the notation\nwe're going to use",
    "start": "96300",
    "end": "99039"
  },
  {
    "text": "is pij, which by definition\nis that transition probability",
    "start": "99039",
    "end": "103890"
  },
  {
    "text": "here.",
    "start": "103890",
    "end": "104390"
  },
  {
    "start": "104390",
    "end": "110509"
  },
  {
    "text": "So given that you are in\nstate i at time s, what",
    "start": "110509",
    "end": "114940"
  },
  {
    "text": "is the probability that you end\nup in state j at time s plus 1.",
    "start": "114940",
    "end": "119060"
  },
  {
    "text": "Notice that these transition\npriorities here, pij,",
    "start": "119060",
    "end": "123119"
  },
  {
    "text": "are not function of s.",
    "start": "123120",
    "end": "124880"
  },
  {
    "text": "So irrespective of what the\ntime s that we're talking about,",
    "start": "124880",
    "end": "129280"
  },
  {
    "text": "these transitions\npriorities are the same.",
    "start": "129280",
    "end": "131770"
  },
  {
    "text": "So this is what we mean by a\ntime-homogeneous Markov chain.",
    "start": "131770",
    "end": "136710"
  },
  {
    "text": "In other words, these are\nvalid for s equal 0, 1, 2,",
    "start": "136710",
    "end": "143490"
  },
  {
    "text": "and so on and so forth.",
    "start": "143490",
    "end": "145630"
  },
  {
    "start": "144000",
    "end": "243000"
  },
  {
    "text": "So the defining feature\nof a Markov chain",
    "start": "145630",
    "end": "148415"
  },
  {
    "text": "is the Markov property.",
    "start": "148415",
    "end": "150730"
  },
  {
    "text": "And the Markov\nproperty essentially",
    "start": "150730",
    "end": "152200"
  },
  {
    "text": "says that the past is not\nreally important in order",
    "start": "152200",
    "end": "155989"
  },
  {
    "text": "to predict the future, as long\nas you know where you are now.",
    "start": "155990",
    "end": "159590"
  },
  {
    "text": "Another way of saying\nit is that if you",
    "start": "159590",
    "end": "162540"
  },
  {
    "text": "look at the probability\nof going next in state j",
    "start": "162540",
    "end": "167329"
  },
  {
    "text": "given that you\nare now in state i",
    "start": "167329",
    "end": "171360"
  },
  {
    "text": "and that I give\nyou, in addition,",
    "start": "171360",
    "end": "174130"
  },
  {
    "text": "the entire trajectories.",
    "start": "174130",
    "end": "175480"
  },
  {
    "text": "So I tell you that it was in i0\nat that time, and so on and so",
    "start": "175480",
    "end": "180340"
  },
  {
    "text": "forth, all the way\nup to time s minus 1,",
    "start": "180340",
    "end": "184459"
  },
  {
    "text": "where it was in is minus 1.",
    "start": "184460",
    "end": "186850"
  },
  {
    "text": "So it gives you the\nentire trajectory",
    "start": "186850",
    "end": "189605"
  },
  {
    "text": "of the chain up to s,\nand now I'm asking you,",
    "start": "189605",
    "end": "192940"
  },
  {
    "text": "what is the probability that\nyou're going to go to s plus 1?",
    "start": "192940",
    "end": "196170"
  },
  {
    "text": "The Markov property here simply\nsays that that probability here",
    "start": "196170",
    "end": "201079"
  },
  {
    "text": "is again, pij.",
    "start": "201079",
    "end": "204260"
  },
  {
    "text": "So in other words,\nall this information",
    "start": "204260",
    "end": "205989"
  },
  {
    "text": "here is of no use to\ncompute this probability.",
    "start": "205990",
    "end": "210460"
  },
  {
    "text": "Now, note that these transition\nprobabilities are really",
    "start": "210460",
    "end": "213610"
  },
  {
    "text": "probabilities, in\nthe following sense.",
    "start": "213610",
    "end": "215240"
  },
  {
    "text": "Right?",
    "start": "215240",
    "end": "215740"
  },
  {
    "text": "So you are in i and then\nat the next time step,",
    "start": "215740",
    "end": "220270"
  },
  {
    "text": "you will definitely\njump with probability 1.",
    "start": "220270",
    "end": "222560"
  },
  {
    "text": "And where you're going\nto jump will depend,",
    "start": "222560",
    "end": "224569"
  },
  {
    "text": "but the summation\nof all possibilities",
    "start": "224570",
    "end": "227829"
  },
  {
    "text": "have to sum up to 1.",
    "start": "227829",
    "end": "229950"
  },
  {
    "text": "So from j equals 1\nto n has to be 1.",
    "start": "229950",
    "end": "234520"
  },
  {
    "text": "So now that we have introduced\nthe main ingredients,",
    "start": "234520",
    "end": "237740"
  },
  {
    "text": "usually we are very interested\nin knowing what a Markov",
    "start": "237740",
    "end": "241140"
  },
  {
    "text": "chain is going to\ndo in the long run.",
    "start": "241140",
    "end": "243440"
  },
  {
    "text": "We are interested in\nfinding the probability",
    "start": "243440",
    "end": "245390"
  },
  {
    "text": "that the chain is in a state\nj after n transitions, given",
    "start": "245390",
    "end": "249680"
  },
  {
    "text": "that it is now in state i.",
    "start": "249680",
    "end": "251689"
  },
  {
    "text": "Now because of the\ntime-homogeneous,",
    "start": "251690",
    "end": "253830"
  },
  {
    "text": "this is the same thing as that.",
    "start": "253830",
    "end": "255200"
  },
  {
    "text": "In other words, the current\ntime could be in any time s,",
    "start": "255200",
    "end": "258489"
  },
  {
    "text": "we just have to add s here.",
    "start": "258490",
    "end": "260479"
  },
  {
    "text": "And again, that is nothing\nelse than this property.",
    "start": "260480",
    "end": "264490"
  },
  {
    "text": "So we are interested in\ncalculating rij of n for any n.",
    "start": "264490",
    "end": "270543"
  },
  {
    "text": "For n equals 1, this is\nnothing else than rij of 1",
    "start": "270544",
    "end": "275560"
  },
  {
    "text": "is the same as this\ntransition probabilities",
    "start": "275560",
    "end": "278800"
  },
  {
    "text": "that we have defined.",
    "start": "278800",
    "end": "280280"
  },
  {
    "text": "But for n greater than or\nequals to 2, what we are seeing",
    "start": "280280",
    "end": "283490"
  },
  {
    "text": "is the introduction of\na key recursion here.",
    "start": "283490",
    "end": "286520"
  },
  {
    "text": "And this is how you would\nbe able to calculate",
    "start": "286520",
    "end": "289379"
  },
  {
    "text": "these probabilities.",
    "start": "289380",
    "end": "290980"
  },
  {
    "text": "Now, how did we come\nup with this recursion?",
    "start": "290980",
    "end": "293805"
  },
  {
    "text": "Well, it's based on a\nclassical divide and conquer",
    "start": "293805",
    "end": "296860"
  },
  {
    "text": "and essentially, the use of\nthe total property theorem.",
    "start": "296860",
    "end": "300210"
  },
  {
    "text": "Essentially, you have\nthe time step here.",
    "start": "300210",
    "end": "302720"
  },
  {
    "text": "This is the current time s.",
    "start": "302720",
    "end": "304544"
  },
  {
    "text": "You are interested\nin what's going",
    "start": "304544",
    "end": "305960"
  },
  {
    "text": "to happen at n plus\ns and n steps later.",
    "start": "305960",
    "end": "309350"
  },
  {
    "text": "Here you are in state i.",
    "start": "309350",
    "end": "311354"
  },
  {
    "text": "You are interested\nin knowing what",
    "start": "311354",
    "end": "312770"
  },
  {
    "text": "is the probability of being\nin state j at that time.",
    "start": "312770",
    "end": "315650"
  },
  {
    "text": "And what you simply do\nis you look at the step n",
    "start": "315650",
    "end": "318970"
  },
  {
    "text": "plus s minus 1, just\nbefore the last one.",
    "start": "318970",
    "end": "321840"
  },
  {
    "text": "And then you say, well, let\nme do a divide and conquer.",
    "start": "321840",
    "end": "324960"
  },
  {
    "text": "This is k here, and\nI'm going to look",
    "start": "324960",
    "end": "327449"
  },
  {
    "text": "at evaluating that probability.",
    "start": "327450",
    "end": "330360"
  },
  {
    "text": "And then once I have\nthat, I will simply",
    "start": "330360",
    "end": "332860"
  },
  {
    "text": "multiply it by this\ntransition here.",
    "start": "332860",
    "end": "335289"
  },
  {
    "text": "And what happened\nis that this here",
    "start": "335290",
    "end": "337610"
  },
  {
    "text": "is nothing else than this\ncalculation that we have here.",
    "start": "337610",
    "end": "340729"
  },
  {
    "text": "And that's the same thing.",
    "start": "340730",
    "end": "342310"
  },
  {
    "text": "And here, this is\nthe probability",
    "start": "342310",
    "end": "344850"
  },
  {
    "text": "of one step transition.",
    "start": "344850",
    "end": "348450"
  },
  {
    "text": "And, of course, we have\nconditioned on the fact",
    "start": "348450",
    "end": "351090"
  },
  {
    "text": "that we would be\nin a state k here,",
    "start": "351090",
    "end": "352669"
  },
  {
    "text": "but k could be any of\nthese states, right?",
    "start": "352670",
    "end": "355620"
  },
  {
    "text": "And they are m of\nthem, and this is",
    "start": "355620",
    "end": "357960"
  },
  {
    "text": "why we saw from k equals 1 to m.",
    "start": "357960",
    "end": "361560"
  },
  {
    "text": "So essentially this is\nhow this key recursion has",
    "start": "361560",
    "end": "364610"
  },
  {
    "text": "been put together,\nand we have used,",
    "start": "364610",
    "end": "366439"
  },
  {
    "text": "of course, the Markov\nproperty in order to do that.",
    "start": "366440",
    "end": "369790"
  },
  {
    "text": "Let's do now a little bit of\nwarm up in terms of calculation",
    "start": "369790",
    "end": "372650"
  },
  {
    "text": "and apply these concepts.",
    "start": "372650",
    "end": "374940"
  }
]
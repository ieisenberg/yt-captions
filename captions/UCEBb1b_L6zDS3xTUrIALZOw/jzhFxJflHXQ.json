[
  {
    "start": "0",
    "end": "1600"
  },
  {
    "text": "Our discussion of least\nmean squares estimation",
    "start": "1600",
    "end": "4220"
  },
  {
    "text": "so far was based\non the case where",
    "start": "4220",
    "end": "6589"
  },
  {
    "text": "we have a single\nunknown random variable",
    "start": "6590",
    "end": "9400"
  },
  {
    "text": "and a single observation.",
    "start": "9400",
    "end": "11990"
  },
  {
    "text": "And we're interested\nin a point estimate",
    "start": "11990",
    "end": "14299"
  },
  {
    "text": "of this single unknown\nrandom variable.",
    "start": "14300",
    "end": "16720"
  },
  {
    "text": "What happens if we have multiple\nobservations or parameters?",
    "start": "16720",
    "end": "20880"
  },
  {
    "text": "For example,\nsuppose that instead",
    "start": "20880",
    "end": "22849"
  },
  {
    "text": "of a single observation, we have\na whole vector of observations.",
    "start": "22850",
    "end": "27540"
  },
  {
    "text": "And, of course,\nwe assume that we",
    "start": "27540",
    "end": "29220"
  },
  {
    "text": "have a model for\nthese observations.",
    "start": "29220",
    "end": "32119"
  },
  {
    "text": "Once we observe our\ndata, a numerical value",
    "start": "32119",
    "end": "35510"
  },
  {
    "text": "for this vector, or what is\nthe same numerical values",
    "start": "35510",
    "end": "39300"
  },
  {
    "text": "for each one of these\nobservation random variables.",
    "start": "39300",
    "end": "42930"
  },
  {
    "text": "Then we're placed in the\nconditional universe where",
    "start": "42930",
    "end": "46030"
  },
  {
    "text": "these values have been observed.",
    "start": "46030",
    "end": "48789"
  },
  {
    "text": "Then, we notice that the\narguments that we carried out",
    "start": "48790",
    "end": "51780"
  },
  {
    "text": "did not rely in\nany way on the fact",
    "start": "51780",
    "end": "54660"
  },
  {
    "text": "that X was one-dimensional.",
    "start": "54660",
    "end": "56870"
  },
  {
    "text": "Exactly the same\nargument goes through",
    "start": "56870",
    "end": "58989"
  },
  {
    "text": "for the multi-dimensional\ncase, and simply, the answer",
    "start": "58990",
    "end": "62970"
  },
  {
    "text": "is again, that the optimal\nestimate, the one that",
    "start": "62970",
    "end": "66060"
  },
  {
    "text": "minimizes the mean\nsquared error, is again,",
    "start": "66060",
    "end": "69119"
  },
  {
    "text": "the conditional expectation\nof the unknown random variable",
    "start": "69120",
    "end": "72590"
  },
  {
    "text": "given the values of\nthe observations.",
    "start": "72590",
    "end": "75810"
  },
  {
    "text": "So this gives us a simple\nand much more general",
    "start": "75810",
    "end": "79110"
  },
  {
    "text": "solution that also\napplies to the case",
    "start": "79110",
    "end": "82070"
  },
  {
    "text": "of multiple observations.",
    "start": "82070",
    "end": "84580"
  },
  {
    "text": "Now, what if we have\nmultiple parameters?",
    "start": "84580",
    "end": "88780"
  },
  {
    "text": "Once more, the argument\nis exactly the same,",
    "start": "88780",
    "end": "92950"
  },
  {
    "text": "and we obtain that\nthe optimal estimate",
    "start": "92950",
    "end": "95320"
  },
  {
    "text": "of any particular\nparameter is going",
    "start": "95320",
    "end": "97740"
  },
  {
    "text": "to be the conditional\nexpectation of that parameter",
    "start": "97740",
    "end": "101070"
  },
  {
    "text": "given the observations.",
    "start": "101070",
    "end": "103060"
  },
  {
    "text": "So if our parameter vector\nis something of this form,",
    "start": "103060",
    "end": "110729"
  },
  {
    "text": "consisting of\nseveral components,",
    "start": "110729",
    "end": "113670"
  },
  {
    "text": "then the LMS estimate of the\njth component of our parameter",
    "start": "113670",
    "end": "119700"
  },
  {
    "text": "vector is going to be simply\nthe conditional expectation",
    "start": "119700",
    "end": "123950"
  },
  {
    "text": "of this parameter given the\ndata that we have obtained.",
    "start": "123950",
    "end": "129849"
  },
  {
    "text": "And this gives us the\nmost general solution",
    "start": "129850",
    "end": "133180"
  },
  {
    "text": "to the program of\nleast mean squares",
    "start": "133180",
    "end": "135480"
  },
  {
    "text": "estimation when we have\nmultiple parameters",
    "start": "135480",
    "end": "140370"
  },
  {
    "text": "and multiple observations.",
    "start": "140370",
    "end": "142950"
  },
  {
    "text": "One very simple concept that\napplies to all possible cases.",
    "start": "142950",
    "end": "147565"
  },
  {
    "start": "147565",
    "end": "150670"
  },
  {
    "text": "Unfortunately, however,\nour worries are not over.",
    "start": "150670",
    "end": "155680"
  },
  {
    "text": "Even though LMS estimation\nhas such a simple and such",
    "start": "155680",
    "end": "159969"
  },
  {
    "text": "a general solution, things\nare not always easy.",
    "start": "159970",
    "end": "165360"
  },
  {
    "text": "Let us see what's happening.",
    "start": "165360",
    "end": "168180"
  },
  {
    "text": "No matter what, we\nhave to first find out",
    "start": "168180",
    "end": "172590"
  },
  {
    "text": "the posterior\ndistribution of Theta",
    "start": "172590",
    "end": "175680"
  },
  {
    "text": "given the observations\nthat we have obtained.",
    "start": "175680",
    "end": "178480"
  },
  {
    "text": "And this is done using the Bayes\nrule, which we have written",
    "start": "178480",
    "end": "182150"
  },
  {
    "text": "here, and this is\nhow you evaluate",
    "start": "182150",
    "end": "184530"
  },
  {
    "text": "the denominator in Bayes' rule.",
    "start": "184530",
    "end": "188380"
  },
  {
    "text": "What are the difficulties\nthat we may encounter?",
    "start": "188380",
    "end": "191390"
  },
  {
    "text": "One first difficulty is\nthat in many applications,",
    "start": "191390",
    "end": "195020"
  },
  {
    "text": "we do not necessarily\nhave a good model",
    "start": "195020",
    "end": "198520"
  },
  {
    "text": "or we're not very\nconfident about our model",
    "start": "198520",
    "end": "201950"
  },
  {
    "text": "of the observations.",
    "start": "201950",
    "end": "203890"
  },
  {
    "text": "If X and Theta are\nmulti-dimensional,",
    "start": "203890",
    "end": "206710"
  },
  {
    "text": "such a model might be\ndifficult to construct.",
    "start": "206710",
    "end": "211560"
  },
  {
    "text": "Setting this issue aside,\nthere's a further issue.",
    "start": "211560",
    "end": "216594"
  },
  {
    "text": "The conditional\nexpectation of Theta",
    "start": "216594",
    "end": "219640"
  },
  {
    "text": "given X may be a complicated\nnon-linear function",
    "start": "219640",
    "end": "224160"
  },
  {
    "text": "of the observations.",
    "start": "224160",
    "end": "226300"
  },
  {
    "text": "This means that it may\nbe difficult to analyze,",
    "start": "226300",
    "end": "229890"
  },
  {
    "text": "but even more\nimportant, it may be",
    "start": "229890",
    "end": "232720"
  },
  {
    "text": "very difficult to\ncalculate even after you",
    "start": "232720",
    "end": "236140"
  },
  {
    "text": "have obtained your data.",
    "start": "236140",
    "end": "238140"
  },
  {
    "text": "Let us understand why\nthis might be the case.",
    "start": "238140",
    "end": "241790"
  },
  {
    "text": "Suppose that Theta is a\nmulti-dimensional parameter.",
    "start": "241790",
    "end": "246099"
  },
  {
    "text": "Then in order to calculate the\ndenominator that's involved",
    "start": "246100",
    "end": "249680"
  },
  {
    "text": "here in the Bayes rule, when you\nintegrate with respect to theta",
    "start": "249680",
    "end": "253780"
  },
  {
    "text": ", you have to actually carry\na multi-dimensional integral,",
    "start": "253780",
    "end": "260278"
  },
  {
    "text": "and this can be very\nchallenging or sometimes,",
    "start": "260279",
    "end": "264190"
  },
  {
    "text": "practically impossible.",
    "start": "264190",
    "end": "267110"
  },
  {
    "text": "Even if you had this\ndenominator term in your hands,",
    "start": "267110",
    "end": "271039"
  },
  {
    "text": "still, in order to calculate\na conditional expectation,",
    "start": "271040",
    "end": "276420"
  },
  {
    "text": "you would have to\ncalculate once more",
    "start": "276420",
    "end": "281230"
  },
  {
    "text": "an integral of\ntheta j integrated",
    "start": "281230",
    "end": "286430"
  },
  {
    "text": "against the posterior\ndistribution of the vector",
    "start": "286430",
    "end": "289780"
  },
  {
    "text": "theta.",
    "start": "289780",
    "end": "292190"
  },
  {
    "text": "But this integral should be once\nmore, over all the parameters.",
    "start": "292190",
    "end": "299040"
  },
  {
    "text": "So it would be a\nmulti-dimensional integral",
    "start": "299040",
    "end": "302640"
  },
  {
    "text": "in the general case, and\nthat's one additional source",
    "start": "302640",
    "end": "306090"
  },
  {
    "text": "of difficulty.",
    "start": "306090",
    "end": "307940"
  },
  {
    "text": "And this is the reason\nwhy we will also",
    "start": "307940",
    "end": "310570"
  },
  {
    "text": "consider an alternative to least\nmean squares estimation, which",
    "start": "310570",
    "end": "314490"
  },
  {
    "text": "is much simpler\ncomputationally and much less",
    "start": "314490",
    "end": "317889"
  },
  {
    "text": "demanding in terms\nof the model that we",
    "start": "317890",
    "end": "321100"
  },
  {
    "text": "need to have in our hands.",
    "start": "321100",
    "end": "323610"
  }
]
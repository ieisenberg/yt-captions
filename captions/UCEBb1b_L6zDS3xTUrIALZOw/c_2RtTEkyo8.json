[
  {
    "start": "4500",
    "end": "4500"
  },
  {
    "text": "We saw in the previous\nvideo that the outcome",
    "start": "4500",
    "end": "6990"
  },
  {
    "text": "of a logistic regression\nmodel is a probability.",
    "start": "6990",
    "end": "10870"
  },
  {
    "text": "Often, we want to make\nan actual prediction.",
    "start": "10870",
    "end": "14260"
  },
  {
    "text": "Should we predict\n1 for poor care,",
    "start": "14260",
    "end": "16760"
  },
  {
    "text": "or should we predict\n0 for good care?",
    "start": "16760",
    "end": "20110"
  },
  {
    "text": "We can convert the\nprobabilities to predictions",
    "start": "20110",
    "end": "23380"
  },
  {
    "text": "using what's called\na threshold value, t.",
    "start": "23380",
    "end": "27029"
  },
  {
    "text": "If the probability of poor care\nis greater than this threshold",
    "start": "27030",
    "end": "30490"
  },
  {
    "text": "value, t, we predict\npoor quality care.",
    "start": "30490",
    "end": "34290"
  },
  {
    "text": "But if the probability\nof poor care",
    "start": "34290",
    "end": "36310"
  },
  {
    "text": "is less than the\nthreshold value,",
    "start": "36310",
    "end": "37920"
  },
  {
    "text": "t, then we predict\ngood quality care.",
    "start": "37920",
    "end": "41109"
  },
  {
    "text": "But what value should we\npick for the threshold, t?",
    "start": "41110",
    "end": "45340"
  },
  {
    "text": "The threshold value,\nt, is often selected",
    "start": "45340",
    "end": "48200"
  },
  {
    "text": "based on which\nerrors are better.",
    "start": "48200",
    "end": "50480"
  },
  {
    "text": "You might be thinking\nthat making no errors",
    "start": "50480",
    "end": "53200"
  },
  {
    "text": "is better, which\nis, of course, true.",
    "start": "53200",
    "end": "55590"
  },
  {
    "text": "But it's rare to have a model\nthat predicts perfectly,",
    "start": "55590",
    "end": "58820"
  },
  {
    "text": "so you're bound to\nmake some errors.",
    "start": "58820",
    "end": "61500"
  },
  {
    "text": "There are two types of errors\nthat a model can make --",
    "start": "61500",
    "end": "64569"
  },
  {
    "text": "ones where you predict\n1, or poor care,",
    "start": "64569",
    "end": "67300"
  },
  {
    "text": "but the actual outcome is 0,\nand ones where you predict 0,",
    "start": "67300",
    "end": "71470"
  },
  {
    "text": "or good care, but the\nactual outcome is 1.",
    "start": "71470",
    "end": "75500"
  },
  {
    "text": "If we pick a large\nthreshold value t,",
    "start": "75500",
    "end": "78670"
  },
  {
    "text": "then we will predict\npoor care rarely,",
    "start": "78670",
    "end": "81080"
  },
  {
    "text": "since the probability\nof poor care",
    "start": "81080",
    "end": "83150"
  },
  {
    "text": "has to be really large to be\ngreater than the threshold.",
    "start": "83150",
    "end": "86670"
  },
  {
    "text": "This means that we will\nmake more errors where",
    "start": "86670",
    "end": "89049"
  },
  {
    "text": "we say good care, but\nit's actually poor care.",
    "start": "89050",
    "end": "92700"
  },
  {
    "text": "This approach would detect the\npatients receiving the worst",
    "start": "92700",
    "end": "95659"
  },
  {
    "text": "care and prioritize\nthem for intervention.",
    "start": "95660",
    "end": "99660"
  },
  {
    "text": "On the other hand, if the\nthreshold value, t, is small,",
    "start": "99660",
    "end": "103410"
  },
  {
    "text": "we predict poor care frequently,\nand we predict good care",
    "start": "103410",
    "end": "106850"
  },
  {
    "text": "rarely.",
    "start": "106850",
    "end": "108060"
  },
  {
    "text": "This means that we will\nmake more errors where",
    "start": "108060",
    "end": "110399"
  },
  {
    "text": "we say poor care, but\nit's actually good care.",
    "start": "110400",
    "end": "113910"
  },
  {
    "text": "This approach would\ndetect all patients",
    "start": "113910",
    "end": "116170"
  },
  {
    "text": "who might be\nreceiving poor care.",
    "start": "116170",
    "end": "119039"
  },
  {
    "text": "Some decision-makers\noften have a preference",
    "start": "119039",
    "end": "121540"
  },
  {
    "text": "for one type of\nerror over the other,",
    "start": "121540",
    "end": "123810"
  },
  {
    "text": "which should influence the\nthreshold value they pick.",
    "start": "123810",
    "end": "127110"
  },
  {
    "text": "If there's no preference\nbetween the errors,",
    "start": "127110",
    "end": "129449"
  },
  {
    "text": "the right threshold\nto select is t = 0.5,",
    "start": "129449",
    "end": "133280"
  },
  {
    "text": "since it just predicts\nthe most likely outcome.",
    "start": "133280",
    "end": "137730"
  },
  {
    "text": "To make this discussion a\nlittle more quantitative,",
    "start": "137730",
    "end": "140730"
  },
  {
    "text": "we use what's called a confusion\nmatrix or classification",
    "start": "140730",
    "end": "144360"
  },
  {
    "text": "matrix.",
    "start": "144360",
    "end": "145680"
  },
  {
    "text": "This compares the\nactual outcomes",
    "start": "145680",
    "end": "147879"
  },
  {
    "text": "to the predicted outcomes.",
    "start": "147880",
    "end": "150160"
  },
  {
    "text": "The rows are labeled\nwith the actual outcome,",
    "start": "150160",
    "end": "153880"
  },
  {
    "text": "and the columns are labeled\nwith the predicted outcome.",
    "start": "153880",
    "end": "157920"
  },
  {
    "text": "Each entry of the table\ngives the number of data",
    "start": "157920",
    "end": "160349"
  },
  {
    "text": "observations that fall\ninto that category.",
    "start": "160350",
    "end": "163570"
  },
  {
    "text": "So the number of true\nnegatives, or TN,",
    "start": "163570",
    "end": "166900"
  },
  {
    "text": "is the number of observations\nthat are actually",
    "start": "166900",
    "end": "169349"
  },
  {
    "text": "good care and for which\nwe predict good care.",
    "start": "169350",
    "end": "173210"
  },
  {
    "text": "The true positives,\nor TP, is the number",
    "start": "173210",
    "end": "176770"
  },
  {
    "text": "of observations\nthat are actually",
    "start": "176770",
    "end": "178520"
  },
  {
    "text": "poor care and for which\nwe predict poor care.",
    "start": "178520",
    "end": "182030"
  },
  {
    "text": "These are the two types\nthat we get correct.",
    "start": "182030",
    "end": "185260"
  },
  {
    "text": "The false positives, or FP,\nare the number of data points",
    "start": "185260",
    "end": "189510"
  },
  {
    "text": "for which we predict poor care,\nbut they're actually good care.",
    "start": "189510",
    "end": "194370"
  },
  {
    "text": "And the false negatives, or FN,\nare the number of data points",
    "start": "194370",
    "end": "198690"
  },
  {
    "text": "for which we predict good care,\nbut they're actually poor care.",
    "start": "198690",
    "end": "203990"
  },
  {
    "text": "We can compute two\noutcome measures",
    "start": "203990",
    "end": "206220"
  },
  {
    "text": "that help us determine what\ntypes of errors we are making.",
    "start": "206220",
    "end": "210050"
  },
  {
    "text": "They're called sensitivity\nand specificity.",
    "start": "210050",
    "end": "216850"
  },
  {
    "text": "Sensitivity is equal\nto the true positives",
    "start": "222620",
    "end": "226769"
  },
  {
    "text": "divided by the true positives\nplus the false negatives,",
    "start": "226770",
    "end": "231980"
  },
  {
    "text": "and measures the percentage\nof actual poor care cases",
    "start": "231980",
    "end": "235750"
  },
  {
    "text": "that we classify correctly.",
    "start": "235750",
    "end": "237870"
  },
  {
    "text": "This is often called\nthe true positive rate.",
    "start": "237870",
    "end": "241150"
  },
  {
    "text": "Specificity is equal\nto the true negatives",
    "start": "241150",
    "end": "244709"
  },
  {
    "text": "divided by the true negatives\nplus the false positives,",
    "start": "244710",
    "end": "249520"
  },
  {
    "text": "and measures the percentage\nof actual good care cases",
    "start": "249520",
    "end": "252570"
  },
  {
    "text": "that we classify correctly.",
    "start": "252570",
    "end": "254700"
  },
  {
    "text": "This is often called\nthe true negative rate.",
    "start": "254700",
    "end": "257648"
  },
  {
    "text": "A model with a higher threshold\nwill have a lower sensitivity",
    "start": "257649",
    "end": "261699"
  },
  {
    "text": "and a higher specificity.",
    "start": "261700",
    "end": "264200"
  },
  {
    "text": "A model with a lower threshold\nwill have a higher sensitivity",
    "start": "264200",
    "end": "268440"
  },
  {
    "text": "and a lower specificity.",
    "start": "268440",
    "end": "270930"
  },
  {
    "text": "Let's compute some\nconfusion matrices",
    "start": "270930",
    "end": "273259"
  },
  {
    "text": "in R using different\nthreshold values.",
    "start": "273260",
    "end": "277550"
  },
  {
    "text": "In our R console, let's make\nsome classification tables",
    "start": "277550",
    "end": "281490"
  },
  {
    "text": "using different threshold\nvalues and the table function.",
    "start": "281490",
    "end": "285680"
  },
  {
    "text": "First, we'll use a\nthreshold value of 0.5.",
    "start": "285680",
    "end": "289560"
  },
  {
    "text": "So type table, and then\nthe first argument,",
    "start": "289560",
    "end": "293020"
  },
  {
    "text": "or what we want to label the\nrows by, should be the true",
    "start": "293020",
    "end": "296500"
  },
  {
    "text": "outcome, which is\nqualityTrain$PoorCare.",
    "start": "296500",
    "end": "298230"
  },
  {
    "text": "And then the second\nargument, or what",
    "start": "304440",
    "end": "306290"
  },
  {
    "text": "we want to label\nthe columns by, will",
    "start": "306290",
    "end": "308750"
  },
  {
    "text": "be predictTrain,\nor our predictions",
    "start": "308750",
    "end": "311850"
  },
  {
    "text": "from the previous\nvideo, greater than 0.5.",
    "start": "311850",
    "end": "316670"
  },
  {
    "text": "This will return TRUE if our\nprediction is greater than 0.5,",
    "start": "316670",
    "end": "321200"
  },
  {
    "text": "which means we want\nto predict poor care,",
    "start": "321200",
    "end": "323860"
  },
  {
    "text": "and it will return FALSE if our\nprediction is less than 0.5,",
    "start": "323860",
    "end": "327539"
  },
  {
    "text": "which means we want\nto predict good care.",
    "start": "327540",
    "end": "331010"
  },
  {
    "text": "If you hit Enter, we get a\ntable where the rows are labeled",
    "start": "331010",
    "end": "334040"
  },
  {
    "text": "by 0 or 1, the true\noutcome, and the columns",
    "start": "334040",
    "end": "337840"
  },
  {
    "text": "are labeled by FALSE or\nTRUE, our predicted outcome.",
    "start": "337840",
    "end": "341780"
  },
  {
    "text": "So you can see here that for\n70 cases, we predict good care",
    "start": "341780",
    "end": "346400"
  },
  {
    "text": "and they actually received\ngood care, and for 10 cases,",
    "start": "346400",
    "end": "350220"
  },
  {
    "text": "we predict poor care, and they\nactually received poor care.",
    "start": "350220",
    "end": "354230"
  },
  {
    "text": "We make four mistakes\nwhere we say poor care",
    "start": "354230",
    "end": "357200"
  },
  {
    "text": "and it's actually good care,\nand we make 15 mistakes where",
    "start": "357200",
    "end": "361010"
  },
  {
    "text": "we say good care, but\nit's actually poor care.",
    "start": "361010",
    "end": "365010"
  },
  {
    "text": "Let's compute the sensitivity,\nor the true positive rate,",
    "start": "365010",
    "end": "369240"
  },
  {
    "text": "and the specificity, or\nthe true negative rate.",
    "start": "369240",
    "end": "372789"
  },
  {
    "text": "The sensitivity here would\nbe 10, our true positives,",
    "start": "372790",
    "end": "376870"
  },
  {
    "text": "divided by 25 the total\nnumber of positive cases.",
    "start": "376870",
    "end": "382460"
  },
  {
    "text": "So we have a sensitivity of 0.4.",
    "start": "382460",
    "end": "386400"
  },
  {
    "text": "Our specificity here would be\n70, the true negative cases,",
    "start": "386400",
    "end": "391259"
  },
  {
    "text": "divided by 74, the total\nnumber of negative cases.",
    "start": "391260",
    "end": "397430"
  },
  {
    "text": "So our specificity\nhere is about 0.95.",
    "start": "397430",
    "end": "402900"
  },
  {
    "text": "Now, let's try\nincreasing the threshold.",
    "start": "402900",
    "end": "405479"
  },
  {
    "text": "Use the up arrow to get\nback to the table command,",
    "start": "405480",
    "end": "408830"
  },
  {
    "text": "and change the\nthreshold value to 0.7.",
    "start": "408830",
    "end": "413349"
  },
  {
    "text": "Now, if we compute\nour sensitivity,",
    "start": "413350",
    "end": "416310"
  },
  {
    "text": "we get a sensitivity of 8\ndivided by 25, which is 0.32.",
    "start": "416310",
    "end": "422480"
  },
  {
    "text": "And if we compute\nour specificity,",
    "start": "422480",
    "end": "424620"
  },
  {
    "text": "we get a specificity\nof 73 divided by 74,",
    "start": "424620",
    "end": "428930"
  },
  {
    "text": "which is about 0.99.",
    "start": "428930",
    "end": "431050"
  },
  {
    "text": "So by increasing the threshold,\nour sensitivity went down",
    "start": "431050",
    "end": "434870"
  },
  {
    "text": "and our specificity went up.",
    "start": "434870",
    "end": "437669"
  },
  {
    "text": "Now, let's try\ndecreasing the threshold.",
    "start": "437670",
    "end": "440540"
  },
  {
    "text": "Hit the up arrow again to\nget to the table function,",
    "start": "440540",
    "end": "443820"
  },
  {
    "text": "and change the\nthreshold value to 0.2.",
    "start": "443820",
    "end": "447940"
  },
  {
    "text": "Now, if we compute\nour sensitivity,",
    "start": "447940",
    "end": "450570"
  },
  {
    "text": "it's 16 divided by 25, or 0.64.",
    "start": "450570",
    "end": "455380"
  },
  {
    "text": "And if we compute\nour specificity,",
    "start": "455380",
    "end": "457290"
  },
  {
    "text": "it's 54 divided by\n74, or about 0.73.",
    "start": "457290",
    "end": "462590"
  },
  {
    "text": "So with the lower threshold,\nour sensitivity went up,",
    "start": "462590",
    "end": "465930"
  },
  {
    "text": "and our specificity went down.",
    "start": "465930",
    "end": "468889"
  },
  {
    "text": "But which threshold\nshould we pick?",
    "start": "468890",
    "end": "471250"
  },
  {
    "text": "Maybe 0.4 is better, or 0.6.",
    "start": "471250",
    "end": "474450"
  },
  {
    "text": "How do we decide?",
    "start": "474450",
    "end": "476100"
  },
  {
    "text": "In the next video, we'll\nsee a nice visualization",
    "start": "476100",
    "end": "479320"
  },
  {
    "text": "to help us select a threshold.",
    "start": "479320",
    "end": "481800"
  }
]
[
  {
    "start": "0",
    "end": "380"
  },
  {
    "text": "If you remember our discussion\nfrom a long time ago, we said",
    "start": "380",
    "end": "4070"
  },
  {
    "text": "that much of this class consists\nof variations of a",
    "start": "4070",
    "end": "6790"
  },
  {
    "text": "few basic skills and ideas,\none of which is the Bayes",
    "start": "6790",
    "end": "10540"
  },
  {
    "text": "rule, the foundation\nof inference.",
    "start": "10540",
    "end": "13670"
  },
  {
    "text": "So let's look here at the\nBayes rule again and its",
    "start": "13670",
    "end": "16580"
  },
  {
    "text": "different incarnations.",
    "start": "16580",
    "end": "18670"
  },
  {
    "text": "In a discrete setting we have a\nrandom variable with a known",
    "start": "18670",
    "end": "22530"
  },
  {
    "text": "PMF but whose values\nare not observed.",
    "start": "22530",
    "end": "26210"
  },
  {
    "text": "Instead we observe the value\nof another random variable,",
    "start": "26210",
    "end": "29449"
  },
  {
    "text": "call it Y, which has some\nrelation with X.",
    "start": "29450",
    "end": "33040"
  },
  {
    "text": "And we will use the value of Y\nto make some inferences about",
    "start": "33040",
    "end": "36800"
  },
  {
    "text": "X. The relation between the\ntwo random variables is",
    "start": "36800",
    "end": "40570"
  },
  {
    "text": "captured by specifying the\nconditional PMF of Y given any",
    "start": "40570",
    "end": "45390"
  },
  {
    "text": "value of X. Think of X as an\nunknown state of the world and",
    "start": "45390",
    "end": "49690"
  },
  {
    "text": "of Y as a noisy observation of\nX. The conditional PMF tells",
    "start": "49690",
    "end": "54530"
  },
  {
    "text": "us the distribution of\nY under each possible",
    "start": "54530",
    "end": "57840"
  },
  {
    "text": "state of the world.",
    "start": "57840",
    "end": "59970"
  },
  {
    "text": "Once we observe the value of Y\nwe obtain some information",
    "start": "59970",
    "end": "63420"
  },
  {
    "text": "about X. And we use this\ninformation to make inferences",
    "start": "63420",
    "end": "66990"
  },
  {
    "text": "about the likely values of X.\nMathematically, instead of",
    "start": "66990",
    "end": "71070"
  },
  {
    "text": "relying on the prior for X, we\nform some revised beliefs.",
    "start": "71070",
    "end": "76820"
  },
  {
    "text": "That is, we form the\nconditional [PMF]",
    "start": "76820",
    "end": "79280"
  },
  {
    "text": "of X given the particular\nobservation that we have seen.",
    "start": "79280",
    "end": "84130"
  },
  {
    "text": "All this becomes possible\nbecause of the Bayes rule.",
    "start": "84130",
    "end": "87369"
  },
  {
    "text": "We have seen the Bayes\nrule for events.",
    "start": "87370",
    "end": "89400"
  },
  {
    "text": "But it is easy to translate\ninto PMF notation.",
    "start": "89400",
    "end": "93090"
  },
  {
    "text": "We take the multiplication\nrule.",
    "start": "93090",
    "end": "95140"
  },
  {
    "text": "And we use it twice in different\norders to get two",
    "start": "95140",
    "end": "98990"
  },
  {
    "text": "different forms--",
    "start": "98990",
    "end": "100610"
  },
  {
    "text": "or two different expressions--",
    "start": "100610",
    "end": "102090"
  },
  {
    "text": "for the joint PMF.",
    "start": "102090",
    "end": "104479"
  },
  {
    "text": "We then take one of the terms\ninvolved here and send it to",
    "start": "104479",
    "end": "108990"
  },
  {
    "text": "the other side.",
    "start": "108990",
    "end": "110710"
  },
  {
    "text": "We obtain this expression,\nwhich is the Bayes rule.",
    "start": "110710",
    "end": "114100"
  },
  {
    "text": "What [do] we have here?",
    "start": "114100",
    "end": "115560"
  },
  {
    "text": "We want to calculate the\nconditional distribution of X",
    "start": "115560",
    "end": "119630"
  },
  {
    "text": "which we typically call\nthe posterior.",
    "start": "119630",
    "end": "121920"
  },
  {
    "start": "121920",
    "end": "127600"
  },
  {
    "text": "And to do this we rely on the\nprior of X as well as on the",
    "start": "127600",
    "end": "133860"
  },
  {
    "text": "model that we have for\nthe observations.",
    "start": "133860",
    "end": "136740"
  },
  {
    "text": "The denominator requires us to\ncompute the marginal of Y. But",
    "start": "136740",
    "end": "141660"
  },
  {
    "text": "this is something that is easily\ndone because we have",
    "start": "141660",
    "end": "145350"
  },
  {
    "text": "the joint available.",
    "start": "145350",
    "end": "147250"
  },
  {
    "text": "The numerator, this expression\nhere, is just the joint PMF.",
    "start": "147250",
    "end": "151190"
  },
  {
    "text": "And using the joint PMF\nyou can always find",
    "start": "151190",
    "end": "154790"
  },
  {
    "text": "the marginal PMF.",
    "start": "154790",
    "end": "156769"
  },
  {
    "text": "Essentially, we're using here\nthe total probability theorem.",
    "start": "156770",
    "end": "159910"
  },
  {
    "text": "And we're using the pieces of\ninformation that were given to",
    "start": "159910",
    "end": "163160"
  },
  {
    "text": "us, the prior and the model\nof the observations.",
    "start": "163160",
    "end": "167600"
  },
  {
    "text": "When we're dealing with\ncontinuous random variables",
    "start": "167600",
    "end": "170020"
  },
  {
    "text": "the story is identical.",
    "start": "170020",
    "end": "171690"
  },
  {
    "text": "We still have two versions of\nthe multiplication rule.",
    "start": "171690",
    "end": "174880"
  },
  {
    "text": "By sending one term--",
    "start": "174880",
    "end": "176810"
  },
  {
    "text": "this term--",
    "start": "176810",
    "end": "177569"
  },
  {
    "text": "to the other side of\nthe equation we",
    "start": "177570",
    "end": "180270"
  },
  {
    "text": "get the Bayes rule.",
    "start": "180270",
    "end": "182150"
  },
  {
    "text": "And then we use the total\nprobability theorem to",
    "start": "182150",
    "end": "185069"
  },
  {
    "text": "calculate the denominator\nterm.",
    "start": "185070",
    "end": "187600"
  },
  {
    "text": "So as far as mathematics go,\nthe story is pretty simple.",
    "start": "187600",
    "end": "191860"
  },
  {
    "text": "It is exactly the same\nin the discrete and",
    "start": "191860",
    "end": "194500"
  },
  {
    "text": "the continuous case.",
    "start": "194500",
    "end": "195740"
  },
  {
    "text": "This story will be our stepping\nstone for dealing",
    "start": "195740",
    "end": "198440"
  },
  {
    "text": "with more complex models and\nalso when we go into more",
    "start": "198440",
    "end": "202270"
  },
  {
    "text": "detail on the subject\nof inference",
    "start": "202270",
    "end": "204300"
  },
  {
    "text": "later in this course.",
    "start": "204300",
    "end": "205550"
  },
  {
    "start": "205550",
    "end": "206700"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6090"
  },
  {
    "text": "continue to offer high-quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6090",
    "end": "12720"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "12720",
    "end": "17880"
  },
  {
    "text": " PHILIPPE RIGOLLET: We're talking\nabout goodness-of-fit tests. Goodness-of-fit tests\nare, does my data",
    "start": "17880",
    "end": "25470"
  },
  {
    "text": "come from a particular\ndistribution? And why would we\nwant to know this? Well, maybe we're\ninterested in, for example,",
    "start": "25470",
    "end": "32099"
  },
  {
    "text": "knowing if the zodiac signs\nof the Fortune 500 CEOs are uniformly distributed.",
    "start": "32100",
    "end": "38550"
  },
  {
    "text": "Or maybe we actually\nhave slightly more-- slightly deeper endeavors,\nsuch as understanding",
    "start": "38550",
    "end": "44740"
  },
  {
    "text": "if you can actually apply the\nt-test by testing normality of your sample. All right? So we saw that there's\nthe main result--",
    "start": "44740",
    "end": "51899"
  },
  {
    "text": "the main standard test for this. It's called the\nKolmogorov-Smirnov test that people use quite a bit.",
    "start": "51900",
    "end": "57690"
  },
  {
    "text": "It's probably one of the\nmost used tests out there. And there's other versions of\nit that I mentioned passing by.",
    "start": "57690",
    "end": "65570"
  },
  {
    "text": "There's the Cramer-von\nMises, and there's the Anderson-Darling test. Now, how would you\npick one of such tests?",
    "start": "65570",
    "end": "72119"
  },
  {
    "text": "Well, they're always are\ngoing to-- they're always going to have their\nadvantages and disadvantages.",
    "start": "72120",
    "end": "77700"
  },
  {
    "text": "And Kolmogorov-Smirnov is\ndefinitely the most widely used because--",
    "start": "77700",
    "end": "83130"
  },
  {
    "text": "well, I guess because\nit's a natural notion of distance between functions. You just look for each\npoint how far they can be,",
    "start": "83130",
    "end": "88530"
  },
  {
    "text": "and you just look\nat the farthest they can be everywhere. Now, Cramer-von Mises\ninvolves L2 distance.",
    "start": "88530",
    "end": "94670"
  },
  {
    "text": "So if you're not used to\nHilbert spaces or notions",
    "start": "94670",
    "end": "99689"
  },
  {
    "text": "of Euclidean spaces, at least\nit's a little more complicated. And then Anderson-Darling\nis definitely",
    "start": "99690",
    "end": "104700"
  },
  {
    "text": "even more complicated. Now, each of these\ntests is going to be more powerful\nagainst other alternatives.",
    "start": "104700",
    "end": "109720"
  },
  {
    "text": "So unless you can really\nguess which alternative you're expecting to\nsee, which you probably don't, because, again, you're\nin a case where you want",
    "start": "109720",
    "end": "116810"
  },
  {
    "text": "to typically declare H0\nto be the correct one, then it's really a\nmatter of tossing a coin.",
    "start": "116810",
    "end": "124950"
  },
  {
    "text": "Maybe you can run\nall three of them and just sleep better at night,\nbecause all three of them have failed to\nreject, for example.",
    "start": "124950",
    "end": "131245"
  },
  {
    "text": "All right? So as I mentioned, one of\nthe maybe primary goals to test goodness of fit\nis to be able to check",
    "start": "131245",
    "end": "139420"
  },
  {
    "text": "whether we can apply\nStudent's test, right, and if the Student\ndistribution is actually a valid distribution.",
    "start": "139420",
    "end": "145750"
  },
  {
    "text": "And for that, we need to have\nnormally distributed data. Now, as I said several\ntimes, normally distributed,",
    "start": "145750",
    "end": "152470"
  },
  {
    "text": "it's not a specific\ndistribution. It's a family of\ndistributions that's indexed by means and variances.",
    "start": "152470",
    "end": "158467"
  },
  {
    "text": "And the way I would want to test\nif a distribution is normally distributed is,\nwell, I would just look at the most natural\nnormal distribution",
    "start": "158467",
    "end": "165459"
  },
  {
    "text": "or Gaussian distribution\nthat my data could follow. That means that's the\nGaussian distribution that has the same mean as my data\nand the same empirical variance",
    "start": "165460",
    "end": "173635"
  },
  {
    "text": "as my data, right? And so I'm going to be\ngiven some points x1, xn,",
    "start": "173635",
    "end": "180080"
  },
  {
    "text": "and I'm going to be\nasking, are those Gaussian?  That means this is\nequivalent to, say,",
    "start": "180080",
    "end": "187310"
  },
  {
    "text": "are they N mu sigma square\nfor some mu sigma squared?",
    "start": "187310",
    "end": "195800"
  },
  {
    "text": "And of course,\nthe natural choice is to take mu hat to be-- mu to be equal to mu\nhat, which is xn bar.",
    "start": "195800",
    "end": "203720"
  },
  {
    "text": "And sigma squared to be\nsigma squared hat to be,",
    "start": "203720",
    "end": "210520"
  },
  {
    "text": "well, Sn hat-- Sn-- what we wrote Sn, which\nis 1/n sum from i equal 1 to n",
    "start": "210520",
    "end": "217580"
  },
  {
    "text": "of xi minus xn bar squared. OK? So this is definitely\nthe natural one",
    "start": "217580",
    "end": "224152"
  },
  {
    "text": "you would want to test. And maybe you could actually\njust close your eyes and just stuff that in a\nKolmogorov-Smirnov test.",
    "start": "224152",
    "end": "232920"
  },
  {
    "text": "OK? So here, there's a few\nthings that don't work. The first one is that\nDonsker's theorem does not work anymore, right?",
    "start": "232920",
    "end": "238489"
  },
  {
    "text": "Donsker's theorem\nwas the one that told us that,\nproperly normalized, this thing would\nactually converge",
    "start": "238490",
    "end": "244459"
  },
  {
    "text": "to the supremum of a Brownian\nbridge, which is not true. So that's one problem. But there's actually\nan even bigger problem",
    "start": "244460",
    "end": "250760"
  },
  {
    "text": "is that this distribution,\nwe will check in a second, actually does not-- is pivotal itself, right,\nthe statistic is pivotal.",
    "start": "250760",
    "end": "259010"
  },
  {
    "text": "It does not have a\ndistribution that depends on the known\nparameters, which is sort of nice, at\nleast under the null.",
    "start": "259011",
    "end": "264810"
  },
  {
    "text": "However, the distribution\nis not the same as the one that had\nfixed mu and sigma.",
    "start": "264810",
    "end": "271010"
  },
  {
    "text": "The fact that they come\nfrom some random variables is actually distorting\nthe distribution itself.",
    "start": "271010",
    "end": "276892"
  },
  {
    "text": "And in particular, the quantiles\nare going to be distorted, and we hinted at that last time. So one other thing I\nneed to tell you, though,",
    "start": "276892",
    "end": "284070"
  },
  {
    "text": "is that this thing actually--\nso I know there's some-- oh, yeah, that's where\nthere's a word missing.",
    "start": "284070",
    "end": "291889"
  },
  {
    "text": "So we compute the quantiles\nfor this test statistic. And so what I need\nto promise to you is that these\nquantiles do not depend",
    "start": "291890",
    "end": "299810"
  },
  {
    "text": "on any unknown parameter, right? I mean, it's not clear, right?",
    "start": "299810",
    "end": "306660"
  },
  {
    "text": "So I want to test whether\nmy data has some Gaussian distribution. So under the null, all I\nknow is that my xi's are",
    "start": "306660",
    "end": "315270"
  },
  {
    "text": "Gaussian with some mean mu\nand some variance sigma, which I don't know. So it could be\nthe case that when",
    "start": "315270",
    "end": "320759"
  },
  {
    "text": "I try to understand the\ndistribution of this quantity under the null, it depends on mu\nand sigma, which I don't know.",
    "start": "320760",
    "end": "328320"
  },
  {
    "text": "So we need to check\nthat this is the case. And what's actually\nour redemption",
    "start": "328320",
    "end": "333810"
  },
  {
    "text": "here is actually going\nto be the supremum. The supremum is going\nto basically allow",
    "start": "333810",
    "end": "339419"
  },
  {
    "text": "us to, say, sup out\nmu and sigma square. So let's check that, right?",
    "start": "339420",
    "end": "344850"
  },
  {
    "text": "So what I'm interested in\nis this quantity, supremum over t and R of the\ndifference between Fn of t",
    "start": "344850",
    "end": "354439"
  },
  {
    "text": "and, what I write, phi mu\nhat sigma squared of t.",
    "start": "354440",
    "end": "362210"
  },
  {
    "text": "So phi mu hat\nsigma hat squared--",
    "start": "362210",
    "end": "367360"
  },
  {
    "text": "sorry, sigma hat squared-- is the CDF of some Gaussian with\nmean mu hat and variance sigma",
    "start": "367360",
    "end": "375320"
  },
  {
    "text": "hat squared. And so in particular, this\nthing here, phi hat of mu hat--",
    "start": "375320",
    "end": "384680"
  },
  {
    "text": "sorry, phi hat of mu hat\nsigma hat squared of t",
    "start": "384680",
    "end": "390169"
  },
  {
    "text": "is the probability that\nsome x is less than t, where x follows some N\nmu hat sigma hat squared.",
    "start": "390170",
    "end": "399870"
  },
  {
    "text": "So what it means is that\nby just the translation and scaling trig\nthat we typically do for Gaussian to turn it into\nsome standard Gaussian, that",
    "start": "399870",
    "end": "407930"
  },
  {
    "text": "implies that there\nexists some z, which is standard Gaussian this\ntime, so mean 0 and variance 1,",
    "start": "407930",
    "end": "414230"
  },
  {
    "text": "such that x is equal\nto sigma hat x-- sorry, z plus mu hat.",
    "start": "414230",
    "end": "422510"
  },
  {
    "text": "Agreed? That's basically saying that x\nhas some Gaussian with mean mu",
    "start": "422510",
    "end": "428570"
  },
  {
    "text": "and variance sigma squared. And I'm not going to say the\nhats every single time, OK?",
    "start": "428570",
    "end": "433930"
  },
  {
    "text": "So OK, so that's what it means. So in particular, maybe\nI shouldn't use x here,",
    "start": "433930",
    "end": "440260"
  },
  {
    "text": "because x is going\nto be my actual data. So let me write y. ",
    "start": "440260",
    "end": "447988"
  },
  {
    "text": "OK? So now what is this guy here? It's basically-- so phi hat.",
    "start": "447988",
    "end": "455430"
  },
  {
    "text": "So this implies that phi mu\nhat sigma hat squared of t",
    "start": "455430",
    "end": "462360"
  },
  {
    "text": "is equal to the probability\nthat sigma hat z plus mu hat is\nless than t, which",
    "start": "462360",
    "end": "470220"
  },
  {
    "text": "is equal to the probability\nthat z is less than t minus mu hat divided\nby sigma hat, right?",
    "start": "470220",
    "end": "480550"
  },
  {
    "text": "But now when z is\nthe standard normal, this is really just the\ncumulative distribution function of a standard\nGaussian but evaluated",
    "start": "480550",
    "end": "487450"
  },
  {
    "text": "at a point which is\nnot t, but t minus mu hat divided by sigma hat. All right? So in particular, what I know--\nso from this what I get-- well,",
    "start": "487450",
    "end": "495525"
  },
  {
    "text": "maybe I'll remove that,\nit's going to be annoying-- I know that phi mu hat\nsigma hat squared--",
    "start": "495525",
    "end": "503182"
  },
  {
    "text": "sorry-- phi mu hat\nsigma hat squared of t is simply phi of, say, 0, 1.",
    "start": "503182",
    "end": "511230"
  },
  {
    "text": "And that's just the notation. Usually we don't put those,\nbut here it's more convenient. So it's phi 0, 1 of t minus\nmu hat divided by sigma hat.",
    "start": "511230",
    "end": "523318"
  },
  {
    "text": "OK? That's just something\nyou can quickly check.",
    "start": "523318",
    "end": "528540"
  },
  {
    "text": "There's this nice way of writing\nthe cumulative distribution function for any\nmean and any variance",
    "start": "528540",
    "end": "535050"
  },
  {
    "text": "in terms of the cumulative\ndistribution function with mean 0 and variance 1. All right? Not too complicated.",
    "start": "535050",
    "end": "540795"
  },
  {
    "text": "All right. So I know what I'm going to say\nis that, OK, I have this sup here. So what I can write is\nthat this thing here",
    "start": "540795",
    "end": "547620"
  },
  {
    "text": "is equal to the sup\nroutine R of 1/n.",
    "start": "547620",
    "end": "552690"
  },
  {
    "text": "Let me write what Fn is-- sum from i equal 1\nto n of the indicator that xi is less than\nt minus phi 0, 1",
    "start": "552690",
    "end": "563910"
  },
  {
    "text": "of t minus mu hat\ndivided by sigma hat. ",
    "start": "563910",
    "end": "570459"
  },
  {
    "text": "OK? I actually want to make\na change of variable so that this thing\nI'm going to call mu--",
    "start": "570459",
    "end": "576700"
  },
  {
    "text": "u, sorry. OK? And so I'm going to\nmake my life easier, and I'm going to\nmake it appear here.",
    "start": "576700",
    "end": "582829"
  },
  {
    "text": "And so I'm just going to\nreplace this by indicator that xi minus mu hat divided\nby sigma hat less than t",
    "start": "582830",
    "end": "592480"
  },
  {
    "text": "minus mu hat divided\nby sigma hat, which is sort of useless at this point.",
    "start": "592480",
    "end": "597880"
  },
  {
    "text": "I'm just making my\nformula more complicated. But now I see something\nhere that shows up, and I will call it u,\nand this is another u.",
    "start": "597880",
    "end": "606952"
  },
  {
    "text": "OK? So now what it means is that\nsuping over t, when t ranges",
    "start": "606952",
    "end": "612230"
  },
  {
    "text": "from negative infinity\nto plus infinity, the new range is from negative\ninfinity to plus infinity,",
    "start": "612230",
    "end": "617980"
  },
  {
    "text": "right? So this sup, I can\nactually write-- this suping t I can\nwrite as the sup in u,",
    "start": "617980",
    "end": "634256"
  },
  {
    "text": "as the indicator that xi minus\nmu hat divided by sigma hat is less than u\nminus phi 0, 1 of u.",
    "start": "634256",
    "end": "647380"
  },
  {
    "text": "Now, let's pause for one second. Let's see where we're going. What we're trying to show\nthat this thing does not",
    "start": "647380",
    "end": "653230"
  },
  {
    "text": "depend on the unknown\nparameters, say, mu and sigma, which are the mean and the\nvariance of x under the null.",
    "start": "653230",
    "end": "661800"
  },
  {
    "text": "To do that, we\nbasically need to make only quantities that are sort\nof invariant under these values.",
    "start": "661800",
    "end": "669339"
  },
  {
    "text": "So I tried to make this thing\ninvariant under anything, and it's just really something\nthat depends on nothing. It's the CDF.",
    "start": "669340",
    "end": "675570"
  },
  {
    "text": "It doesn't depend on sigma\nhat and mu hat anymore. But sigma hat and mu hat will\ndepend on mu and sigma, right?",
    "start": "675570",
    "end": "682399"
  },
  {
    "text": "I mean, they're actually good\nestimators of those guys, so they should be\npretty close to them. And so I need to make\nsure that I'm not actually",
    "start": "682399",
    "end": "688650"
  },
  {
    "text": "doing anything wrong here. So the key thing here is going\nto be to observe that 1/n sum",
    "start": "688650",
    "end": "695399"
  },
  {
    "text": "from i equal 1 to n of indicator\nof xi minus u hat divided by sigma hat less than u, which\nis the first term that I have",
    "start": "695400",
    "end": "703650"
  },
  {
    "text": "in this absolute value,\nwell, this is what-- well,",
    "start": "703650",
    "end": "708720"
  },
  {
    "text": "this is equal to 1/n sum from\ni equal 1 to n of indicator",
    "start": "708720",
    "end": "714040"
  },
  {
    "text": "that-- well, now under\nthe null, which is",
    "start": "714040",
    "end": "720810"
  },
  {
    "text": "that x follows N mu sigma\nsquared, for some mu and sigma",
    "start": "720810",
    "end": "726309"
  },
  {
    "text": "squared that are unknown. But they are here. They exist. I just don't know what they are. Then xi minus mu can be\nwritten as sigma zi plus mu",
    "start": "726309",
    "end": "737820"
  },
  {
    "text": "minus mu hat divided\nby sigma hat, where",
    "start": "737820",
    "end": "743340"
  },
  {
    "text": "z is equal to x minus mu\ndivided by sigma, right?",
    "start": "743340",
    "end": "749150"
  },
  {
    "text": "That's just the same\ntrick that I wrote here. OK? Everybody agree?",
    "start": "749150",
    "end": "754160"
  },
  {
    "text": "So I just standardize-- sorry, z-- yeah, so zi is xi\nminus mu i minus mu divided",
    "start": "754160",
    "end": "762080"
  },
  {
    "text": "by sigma. All right? Just a standardization. So now once I write\nthis, I can actually",
    "start": "762080",
    "end": "767780"
  },
  {
    "text": "divide everybody by sigma. ",
    "start": "767780",
    "end": "775246"
  },
  {
    "text": "Right? So I just divided on top\nhere and in the bottom here. So now what I need to check\nis that the distribution",
    "start": "775246",
    "end": "782150"
  },
  {
    "text": "of this guy does not\ndepend on mu or sigma.",
    "start": "782150",
    "end": "788790"
  },
  {
    "text": "That's what I claim. What is the distribution\nof this indicator? ",
    "start": "788790",
    "end": "796360"
  },
  {
    "text": "It's a Bernoulli, right? And so if I want to\nunderstand its distribution, all I need to do is to\ncompute its expectation,",
    "start": "796360",
    "end": "803680"
  },
  {
    "text": "which is just the probability\nthat this thing happens. But the probability\nthat this thing happens is actually now depending\non mu and sigma.",
    "start": "803680",
    "end": "809880"
  },
  {
    "text": "And the reason is\nthat mu is what? Well, it's x bar-- sorry, yeah,\nso mu hat-- sorry, is xn bar.",
    "start": "809880",
    "end": "824510"
  },
  {
    "text": "So mu hat minus mu,\nwhich under the null",
    "start": "824510",
    "end": "830730"
  },
  {
    "text": "follows N mu sigma\nsquare over n, right? That's the property\nof the average.",
    "start": "830730",
    "end": "837370"
  },
  {
    "text": "So when I do mu hat minus\nmu divided by sigma, this thing is what distribution?",
    "start": "837370",
    "end": "844820"
  },
  {
    "text": "It's still a normal. It's a linear\ntransformation of a normal. What are the parameters?",
    "start": "844820",
    "end": "851006"
  },
  {
    "text": "AUDIENCE: 0, 1/n. PHILIPPE RIGOLLET: Yeah, 0, 1/n. ",
    "start": "851006",
    "end": "856190"
  },
  {
    "text": "But this does not depend\non mu or sigma, right?",
    "start": "856190",
    "end": "866910"
  },
  {
    "text": " Now, I need to check\nthat this guy does not depend on mu or sigma.",
    "start": "866910",
    "end": "874920"
  },
  {
    "text": "What is the distribution\nof sigma hat over sigma? ",
    "start": "874920",
    "end": "880389"
  },
  {
    "text": "AUDIENCE: It's a\nchi-square, right? PHILIPPE RIGOLLET: Yeah,\nit is a chi-square. So this is actually--",
    "start": "880389",
    "end": "885490"
  },
  {
    "text": "sorry, sigma hat squared\ndivided by sigma squared is a chi-square with n\nminus 1 degrees of freedom.",
    "start": "885490",
    "end": "894309"
  },
  {
    "text": "Does not depend on mu or sigma. ",
    "start": "894309",
    "end": "900440"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] AUDIENCE: [INAUDIBLE] AUDIENCE: Or sigma hat\nsquared over sigma squared?",
    "start": "900440",
    "end": "905992"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nYeah, thank you. So this is actually\ndivided by it. So maybe this guy.",
    "start": "905992",
    "end": "911628"
  },
  {
    "text": "Let's write it like that. This is the proper\nway of writing it. Thank you. ",
    "start": "911629",
    "end": "920389"
  },
  {
    "text": "Right? So now I have those two things. Neither of them\ndepends on mu or sigma.",
    "start": "920389",
    "end": "925680"
  },
  {
    "text": "I these two things. There's just one\nmore thing to check. ",
    "start": "925680",
    "end": "932191"
  },
  {
    "text": "What is it?  AUDIENCE: That\nthey're independent? PHILIPPE RIGOLLET: That\nthey're independent, right?",
    "start": "932191",
    "end": "937790"
  },
  {
    "text": "Because the dependence\nin mu and sigma could be hidden\nin the covariance. It could be the case that the\nmarginal distribution of mu",
    "start": "937790",
    "end": "944540"
  },
  {
    "text": "does not depend on mu or sigma,\nthat the marginal distribution of sigma-- of mu hat does not\ndepend on mu and sigma.",
    "start": "944540",
    "end": "949850"
  },
  {
    "text": "The marginal\ndistribution of sigma hat does not depend on mu or\nsigma, but their correlation could depend on mu and sigma.",
    "start": "949850",
    "end": "956000"
  },
  {
    "text": "But we also have\nthat if I look at-- so if I look at-- ",
    "start": "956000",
    "end": "962920"
  },
  {
    "text": "so since mu hat is\nindependent of sigma hat,",
    "start": "962920",
    "end": "970329"
  },
  {
    "text": "it means that the joint\ndistribution of mu hat divided",
    "start": "970330",
    "end": "993770"
  },
  {
    "text": "by sigma and sigma\nhat divided by sigma does not depend on blah,\nblah, blah, on mu and sigma.",
    "start": "993770",
    "end": "1006790"
  },
  {
    "text": "OK?  Agree?",
    "start": "1006790",
    "end": "1012579"
  },
  {
    "text": "It's not in the individual\nones, and it's not in the way they interact\nwith each other.",
    "start": "1012580",
    "end": "1017940"
  },
  {
    "text": "It's nowhere. AUDIENCE: [INAUDIBLE]\nindependence be [INAUDIBLE] theorem? PHILIPPE RIGOLLET: Yeah,\ncovariance theorem, right.",
    "start": "1017940",
    "end": "1023750"
  },
  {
    "text": "So that's something we've\nbeen using over and again. That's all under the null. If my data is not Gaussian,\nnothing actually holds.",
    "start": "1023750",
    "end": "1032789"
  },
  {
    "text": "I just use the fact\nthat under the null I'm Gaussian for some mean mu\nand variance sigma squared. But that's all I care about.",
    "start": "1032790",
    "end": "1038790"
  },
  {
    "text": "When I'm designing\na test, I only care about the distribution\nunder the null, at least",
    "start": "1038790",
    "end": "1044910"
  },
  {
    "text": "to control the type I error. Then to control\nthe type II error, then I cross my\nfingers pretty hard.",
    "start": "1044910",
    "end": "1051610"
  },
  {
    "text": "OK?  So now this basically implies\nwhat's written on the board,",
    "start": "1051610",
    "end": "1061419"
  },
  {
    "text": "that this distribution,\nthis test statistic, does not depend on any\nunknown parameters.",
    "start": "1061420",
    "end": "1068270"
  },
  {
    "text": "It's just something\nthat's pivotal. In particular, I could\ngo at the back of a book and check if there's a table for\nthe quantiles of these things,",
    "start": "1068270",
    "end": "1076220"
  },
  {
    "text": "and indeed there are. This is the table that you see. So actually, this is\nnot even in a book.",
    "start": "1076220",
    "end": "1082550"
  },
  {
    "text": "This is in Lilliefors\noriginal paper, 1967,",
    "start": "1082550",
    "end": "1089970"
  },
  {
    "text": "as you can tell from\nthe typewriting. And he actually probably\nwas rolling some dice",
    "start": "1089970",
    "end": "1097190"
  },
  {
    "text": "from his office back in\nthe day and was checking that this was-- he\nsimulated it, and this is",
    "start": "1097190",
    "end": "1102380"
  },
  {
    "text": "how he computed those numbers. And here you also have\nsome limiting distribution,",
    "start": "1102380",
    "end": "1108440"
  },
  {
    "text": "which is not the sup of\na Brownian motion over 0, 1 of-- sorry, of a\nBrownian bridge over 0,",
    "start": "1108440",
    "end": "1115034"
  },
  {
    "text": "1, which is the\none that you would see for the\nKolmogorov-Smirnov test, but it's something that's\nslightly different.",
    "start": "1115034",
    "end": "1121050"
  },
  {
    "text": "And as I said, these numbers are\nactually typically much smaller than the numbers you\nwould get, right?",
    "start": "1121050",
    "end": "1127310"
  },
  {
    "text": "Remember, we got something\nthat was about 0.5, I think, or maybe 0.41, for the\nKolmogorov-Smirnov test",
    "start": "1127310",
    "end": "1134350"
  },
  {
    "text": "at the same\nentrance, which means that using\nKolmogorov-Lilliefors test it's going to be\nharder for you not",
    "start": "1134350",
    "end": "1139910"
  },
  {
    "text": "to reject for the same data. It might be the case that\nin one case you reject, and in the other one\nyou fail to reject.",
    "start": "1139910",
    "end": "1146660"
  },
  {
    "text": "But the ordering is\nalways that if you fail to reject with\nKolmogorov-Lilliefors,",
    "start": "1146660",
    "end": "1152409"
  },
  {
    "text": "you will fail to reject with\nKolmogorov-Smirnov, right? There's always one.",
    "start": "1152410",
    "end": "1158720"
  },
  {
    "text": "So that's why people\ntend to close their eyes and prefer Kolmogorov-Smirnov\nbecause it just makes their life easier.",
    "start": "1158720",
    "end": "1165365"
  },
  {
    "text": "OK? So this is called\nKolmogorov-Lilliefors. I think there's\nactually an E here--",
    "start": "1165365",
    "end": "1173250"
  },
  {
    "text": "sorry, an I before the E.\nDoesn't matter too much.",
    "start": "1173250",
    "end": "1181440"
  },
  {
    "text": "OK? Are there any questions? Yes? AUDIENCE: Is there\nlike a place you can point to like [INAUDIBLE]",
    "start": "1181440",
    "end": "1199135"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah. AUDIENCE: [INAUDIBLE]. PHILIPPE RIGOLLET: So the\nfact that it's actually a different distribution\nis that here--",
    "start": "1199135",
    "end": "1207120"
  },
  {
    "text": "so if I actually knew\nwhat mu and sigma were, I would do exactly\nthe same thing.",
    "start": "1207120",
    "end": "1213799"
  },
  {
    "text": "But here, rather than having\nthis average with mu and sigma, I would just have the-- with mu hat and sigma\nhat, I would just",
    "start": "1213800",
    "end": "1219140"
  },
  {
    "text": "have the average\nwith mu and sigma. OK? So what it means is\nthat the key thing is that what I would compare is\nthe 1/n sum of some Bernoullis",
    "start": "1219140",
    "end": "1229789"
  },
  {
    "text": "with parameter. And the parameter here would\nbe the probability that mu--",
    "start": "1229790",
    "end": "1234919"
  },
  {
    "text": "xi minus mu over\nsigma is less than u, which is just the\nprobability that phi--",
    "start": "1234920",
    "end": "1240500"
  },
  {
    "text": "sorry, it's a Bernoulli\nwith probability F of t. Well, let me write\nwhat it is, right?",
    "start": "1240500",
    "end": "1249590"
  },
  {
    "text": "So that's minus phi 0, 1 of t.",
    "start": "1249590",
    "end": "1257440"
  },
  {
    "text": "OK? So that's for the K-S test,\nand then I sup over t, right?",
    "start": "1257440",
    "end": "1264159"
  },
  {
    "text": "That's what I would have\nhad, because this is actually exactly the right thing. Here I would remove\nthe true mean.",
    "start": "1264160",
    "end": "1270130"
  },
  {
    "text": "I would divide by the\ntrue standard deviation. So that would actually end\nup being a standard Gaussian,",
    "start": "1270130",
    "end": "1275320"
  },
  {
    "text": "and that's why I'm allowed\nto use phi 0, 1 here. Agreed? And these are Bernoullis\nbecause they're just indicators.",
    "start": "1275320",
    "end": "1282220"
  },
  {
    "text": "What happens in the\nKolmogorov-Lilliefors test? Well, here the\nBernoulli, the only thing",
    "start": "1282220",
    "end": "1288809"
  },
  {
    "text": "that's going to change\nis this guy, right? They still have a Bernoulli. It's just that the parameters\nof the Bernoulli are weird.",
    "start": "1288810",
    "end": "1294000"
  },
  {
    "text": "The parameters of the\nBernoulli looks like it's-- it becomes the probability that\nsome N(0, 1) plus some N(0,",
    "start": "1294000",
    "end": "1307735"
  },
  {
    "text": "1/n), right, divided by some\nsquare root of chi-squared n",
    "start": "1307735",
    "end": "1322140"
  },
  {
    "text": "minus 1 divided by\nn is less than t.",
    "start": "1322140",
    "end": "1327550"
  },
  {
    "text": "And those things\nare independent, but those guys are not\nnecessarily independent, right? And so why is this\nprobability changing?",
    "start": "1327550",
    "end": "1334720"
  },
  {
    "text": "Well, because this denominator\nis actually fluctuating a lot. So that actually makes\nthis probability different.",
    "start": "1334720",
    "end": "1340570"
  },
  {
    "text": "And so that's basically\nwhere it comes from, right? So you could probably\nconvince yourself",
    "start": "1340570",
    "end": "1346940"
  },
  {
    "text": "very quickly that this only\nmakes those guys closer.",
    "start": "1346940",
    "end": "1352519"
  },
  {
    "text": "And why does it make\nthose guys closer?",
    "start": "1352520",
    "end": "1358280"
  },
  {
    "text": " No, sorry. It makes those guys\nfarther, right? And it makes those guys farther\nfor a very clear reason,",
    "start": "1358280",
    "end": "1366000"
  },
  {
    "text": "is that the expectation of this\nBernoulli is exactly that guy.",
    "start": "1366000",
    "end": "1371080"
  },
  {
    "text": "Here I think it's\ngoing to be true as well that the expectation\nof this Bernoulli is going to be that guy,\nbut the fluctuations",
    "start": "1371080",
    "end": "1376690"
  },
  {
    "text": "are going to be much bigger than\njust the phi of the Bernoulli. Because the first\nthing I do is I have a random parameter\nfrom my Bernoulli, and then I flip the Bernoulli.",
    "start": "1376690",
    "end": "1382830"
  },
  {
    "text": "So fluctuations are going to\nbe bigger than a Bernoulli. And so when I take\nthe sup, I'm going to have to [INAUDIBLE] them.",
    "start": "1382830",
    "end": "1387960"
  },
  {
    "text": "So it makes things\nfarther apart, which makes it more\nlikely for you to reject. Yeah? AUDIENCE: You also said that if\nyou compare the same-- if you",
    "start": "1387960",
    "end": "1396778"
  },
  {
    "text": "compare the table and you\nset at the same level, the Lilliefors is like 0.2,\nand for the Smirnov is at 0.4.",
    "start": "1396778",
    "end": "1404476"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah. AUDIENCE: OK. So it means that Lilliefors\nis harder not to reject?",
    "start": "1404476",
    "end": "1410022"
  },
  {
    "text": "PHILIPPE RIGOLLET: It means\nthat Lilliefors is harder not to reject, yes,\nbecause we reject when we're larger than the number.",
    "start": "1410022",
    "end": "1416490"
  },
  {
    "text": "So the number being smaller\nwith the same data, we might be, right? So basically, it\nlooks like this.",
    "start": "1416490",
    "end": "1423750"
  },
  {
    "text": "What we run-- so here we have\nthe distribution for the--",
    "start": "1423750",
    "end": "1435750"
  },
  {
    "text": "so let's say this is\nthe density for K-S.",
    "start": "1435750",
    "end": "1445510"
  },
  {
    "text": "And then we have the density for\nKolmogorov-Lilliefors, K-L. OK?",
    "start": "1445510",
    "end": "1451270"
  },
  {
    "text": "And what the density\nof K-L looks like, it looks like this, right?",
    "start": "1451270",
    "end": "1462270"
  },
  {
    "text": "And so if I want to\nsqueeze in alpha here,",
    "start": "1462270",
    "end": "1467860"
  },
  {
    "text": "I'm going to have to squeeze\nin-- and I squeeze in alpha here, then this is the\nquantile of order 1 minus alp--",
    "start": "1467860",
    "end": "1474740"
  },
  {
    "text": "well, let's say\nalpha of the K-L. And this is the\nquantile alpha of K-S.",
    "start": "1474740",
    "end": "1481750"
  },
  {
    "text": "So now you give me data,\nand what I do with it, I check whether they're\nlarger than this number. So if I apply K-S, I check\nwhether I'm larger or smaller",
    "start": "1481750",
    "end": "1488800"
  },
  {
    "text": "than this thing. But if I apply\nKolmogorov-Lilliefors, I check whether I'm larger\nor smaller than this thing. So over this entire range of\nvalues for my test statistic--",
    "start": "1488800",
    "end": "1496270"
  },
  {
    "text": "because it is the\nsame test statistic, I just plugged in mu\nhat and sigma hat-- for this entire range, the two\ntests have different outcomes.",
    "start": "1496270",
    "end": "1504229"
  },
  {
    "text": "And this is a big range\nin practice, right? I mean, it's between-- I mean, it's pretty\nmuch at scale here.",
    "start": "1504229",
    "end": "1510669"
  },
  {
    "text": " OK? ",
    "start": "1510670",
    "end": "1518050"
  },
  {
    "text": "Any other-- yeah? AUDIENCE: [INAUDIBLE] when n\ngoes to infinity, the two tests become the same now, right?",
    "start": "1518050",
    "end": "1524446"
  },
  {
    "text": "PHILIPPE RIGOLLET: Hmmm. AUDIENCE: Looking\nat that formula-- PHILIPPE RIGOLLET: Yeah,\nThey should become the same",
    "start": "1524446",
    "end": "1529546"
  },
  {
    "text": "very far.  Let me see, though, because--",
    "start": "1529546",
    "end": "1534740"
  },
  {
    "text": "right. So here we have 8-- so here we have, say,\nfor 0.5, we get 0.886.",
    "start": "1534740",
    "end": "1544030"
  },
  {
    "text": "And for-- oh, I don't have it. ",
    "start": "1544030",
    "end": "1549539"
  },
  {
    "text": "Yeah, actually, sorry. So you're right. You're totally right. This is the Brownian\nbridge values.",
    "start": "1549540",
    "end": "1556650"
  },
  {
    "text": "Because in the limit\nby, say, Slutsky-- sorry, I'm lost.",
    "start": "1556650",
    "end": "1562070"
  },
  {
    "text": "Yeah, these are\nthe values that you get for the Brownian bridge. Because in the limit\nby Slutsky, this thing",
    "start": "1562070",
    "end": "1567620"
  },
  {
    "text": "is going to have no\nfluctuation, and this thing is going to have no fluctuation. So they're just going\nto be pinned down,",
    "start": "1567620",
    "end": "1572719"
  },
  {
    "text": "and it's going to look like as\nif I did not replace anything. Because in the limit, I know\nthose guys much faster--",
    "start": "1572719",
    "end": "1578980"
  },
  {
    "text": "the mu hat and\nsigma hat converge much faster to mu and sigma than\nthe distribution itself, right?",
    "start": "1578980",
    "end": "1585500"
  },
  {
    "text": "So those are actually\ngoing to be negligible. You're right. Actually even, I didn't have--",
    "start": "1585500",
    "end": "1591330"
  },
  {
    "text": "these are actually the\nnumbers I showed you for the bridge, the\nBrownian bridge, last time, because I didn't have\nit for the Kolmogorov-Smirnov",
    "start": "1591330",
    "end": "1596620"
  },
  {
    "text": "one. OK?  So there's actually-- so those\nare numerical ways of checking",
    "start": "1596620",
    "end": "1604990"
  },
  {
    "text": "things, right? I give you data. You just crank the\nKolmogorov-Smirnov test.",
    "start": "1604990",
    "end": "1610750"
  },
  {
    "text": "Usually you press a 5 on MATLAB. But let's say you actually\ncompute this entire thing,",
    "start": "1610750",
    "end": "1615940"
  },
  {
    "text": "and there's a number\nthat comes out, and you decide whether it's\nlarge enough or small enough. Of course, statistical software\nis going to make your life even",
    "start": "1615940",
    "end": "1622990"
  },
  {
    "text": "simpler by spitting out a\np-value, because you can-- I mean, if you can compute\nquantiles, you can also when compute p-values.",
    "start": "1622990",
    "end": "1629059"
  },
  {
    "text": "And so your life is\njust fairly easy. You just have red is bad, green\nis good, and then you can go.",
    "start": "1629060",
    "end": "1638630"
  },
  {
    "text": "The problem is that those are\nnumbers you want to rely on. But let's say you\nactually reject. Let's say you reject.",
    "start": "1638630",
    "end": "1643960"
  },
  {
    "text": "Your p-value is actually\njust like slightly below 5%.",
    "start": "1643960",
    "end": "1649240"
  },
  {
    "text": "So you can say, well, maybe\nI'm just going to change my p-value--",
    "start": "1649240",
    "end": "1654880"
  },
  {
    "text": "my threshold to\n1%, but you might want to see what's happening. And for that you need\na visual diagnostic.",
    "start": "1654880",
    "end": "1660280"
  },
  {
    "text": "Like, how do I check\nif something departs from being normal, for example? How do I check if\na distribution--",
    "start": "1660280",
    "end": "1666769"
  },
  {
    "text": "why is a distribution not\na uniform distribution? Why is a distribution not\nan exponential distribution?",
    "start": "1666770",
    "end": "1671900"
  },
  {
    "text": "There's many, many, right? If I have an\nexponential distribution and half of my\nvalues are negative,",
    "start": "1671900",
    "end": "1677060"
  },
  {
    "text": "for example, well, there's\nlike pretty obvious reasons why it should not\nbe exponential. But it could be\nthe case that it's",
    "start": "1677060",
    "end": "1683780"
  },
  {
    "text": "just the tails\nare little heavier or there's more\nconcentration at some point. Maybe it has two modes.",
    "start": "1683780",
    "end": "1690019"
  },
  {
    "text": "There's things like this. But the real thing,\nwe don't believe that the Gaussian is\nso important because it",
    "start": "1690020",
    "end": "1696400"
  },
  {
    "text": "looks like this close to 0. What we like about the\nGaussian is that the tails here",
    "start": "1696400",
    "end": "1702310"
  },
  {
    "text": "decay at this rate--\nexponential minus x squared over 2 that we described\nin the maybe first lecture.",
    "start": "1702310",
    "end": "1708445"
  },
  {
    "text": "And in particular, if there\nwere like kinks around here, it wouldn't matter too much. This is not what makes\nissues for the Gaussian.",
    "start": "1708445",
    "end": "1716670"
  },
  {
    "text": "And so what we want is to have a\nvisual diagnostic that tells us",
    "start": "1716670",
    "end": "1721860"
  },
  {
    "text": "if the tails of my\ndistribution are comparable to the tails of\na Gaussian one, for example.",
    "start": "1721860",
    "end": "1728350"
  },
  {
    "text": "And those are what's called\nquantile-quantile plots, and in particular-- or QQ plots.",
    "start": "1728350",
    "end": "1734250"
  },
  {
    "text": "And the basic QQ plots\nwe're going to be using are the ones that are\ncalled normal QQ plots that",
    "start": "1734250",
    "end": "1740640"
  },
  {
    "text": "are comparing your data to\na Gaussian distribution, or a normal distribution. But in general, you could\nbe comparing your data",
    "start": "1740640",
    "end": "1747600"
  },
  {
    "text": "to any distribution you want. And the way you do\nthis is by comparing the quantiles of your data,\nthe empirical quantiles,",
    "start": "1747600",
    "end": "1754860"
  },
  {
    "text": "to the quantiles of\nthe actual distribution you're trying to\ncompare yourself to. So this, in a way,\nis a visual way",
    "start": "1754860",
    "end": "1762470"
  },
  {
    "text": "of performing these\ngoodness-of-fit tests. And what's nice about visual is\nthat there's room for debate.",
    "start": "1762470",
    "end": "1769039"
  },
  {
    "text": "You can see something that\nsomebody else cannot see, and you can always-- because\nyou want to say that things are Gaussian.",
    "start": "1769040",
    "end": "1774300"
  },
  {
    "text": "And we'll see some examples\nwhere you can actually say it if you are good at\ndebate, but it's actually",
    "start": "1774300",
    "end": "1781789"
  },
  {
    "text": "going to be clearly not true. All right. So this is a quick\nand easy check. That's something\nI do all the time.",
    "start": "1781790",
    "end": "1788180"
  },
  {
    "text": "You give me data, I'm\njust going to run this. One of the first\nthings I do so I can check if I can start\nentering the Gaussian",
    "start": "1788180",
    "end": "1794000"
  },
  {
    "text": "world without compromising\nmyself too much. And the idea is to say, well,\nif F is close to-- if F--",
    "start": "1794000",
    "end": "1804350"
  },
  {
    "text": "if my data comes\nfrom an F, and if I know that Fn is close\nto F, then rather",
    "start": "1804350",
    "end": "1810080"
  },
  {
    "text": "than computing some norm,\nsome number that tells me how far they are,\nsummarizing how far they are, I could actually plot\nthe two functions",
    "start": "1810080",
    "end": "1816260"
  },
  {
    "text": "and see if they're far apart. So let's think for one second\nwhat this kind of a plot",
    "start": "1816260",
    "end": "1821870"
  },
  {
    "text": "would look like. Well, I would go\nbetween 0 and 1. That's where everything\nwould happen. Let's say my distribution is\nthe Gaussian distribution.",
    "start": "1821870",
    "end": "1829679"
  },
  {
    "text": "So this is the CDF of N(0, 1).",
    "start": "1829680",
    "end": "1835370"
  },
  {
    "text": "And now I have this guy\nthat shows up, and remember we had this piecewise constant. ",
    "start": "1835370",
    "end": "1844172"
  },
  {
    "text": "Well, OK, let's say we\nget something like this. We get a piecewise constant\ndistribution for Fn, right?",
    "start": "1844172",
    "end": "1851770"
  },
  {
    "text": " Just from this, and even despite\nmy bad skills at drawing,",
    "start": "1851770",
    "end": "1860200"
  },
  {
    "text": "it's clear that it's\ngoing to be hard for you to distinguish\nthose two things, even for a fairly\nlarge amount of points.",
    "start": "1860200",
    "end": "1865960"
  },
  {
    "text": "Because the problem is\ngoing to happen here, and those guys look pretty\nmuch the same everywhere",
    "start": "1865960",
    "end": "1871000"
  },
  {
    "text": "you are here. You're going to see differences\nmaybe in the middle, but we don't care too much\nabout those differences.",
    "start": "1871000",
    "end": "1877010"
  },
  {
    "text": "And so what's going to\nhappen is that you're going to want to compare\nthose two things. And this is basically you\nhave the information you want,",
    "start": "1877010",
    "end": "1883659"
  },
  {
    "text": "but visually it just doesn't\nrender very well because you're not scaling things properly.",
    "start": "1883660",
    "end": "1888970"
  },
  {
    "text": "And the way we actually do it\nis by flipping things around. And rather than comparing the\nplot of F to the plot of Fn,",
    "start": "1888970",
    "end": "1896230"
  },
  {
    "text": "we compare the\nplot of Fn inverse to the plot of F inverse.",
    "start": "1896230",
    "end": "1901444"
  },
  {
    "text": "Now, if F goes from the real\nline to the interval 0, 1,",
    "start": "1901444",
    "end": "1907049"
  },
  {
    "text": "F inverse goes from 0, 1\nto the whole real line.",
    "start": "1907050",
    "end": "1912409"
  },
  {
    "text": "So what's going to\nhappen is that I'm going to compare things on\nsome intervals, which is the-- which are the entire real line.",
    "start": "1912409",
    "end": "1919210"
  },
  {
    "text": "And then what values should I\nbe looking at those things at? Well, technically for\nF, if F is continuous I",
    "start": "1919210",
    "end": "1925919"
  },
  {
    "text": "could look at F inverse for\nany value that I please, right? So I have F. And if I\nwant to look at F inverse,",
    "start": "1925920",
    "end": "1934630"
  },
  {
    "text": "I pick a point here and I look\nat the value that it gives me, and that's F inverse of,\nsay, u, right, if this is u.",
    "start": "1934630",
    "end": "1943054"
  },
  {
    "text": "And I could pick\nany value I want, I'm going to be able to find it. The problem is that\nwhen I start to have this piecewise\nconstant thing, I need",
    "start": "1943054",
    "end": "1950860"
  },
  {
    "text": "to decide what value I\nassign for anything that's in between two jumps, right?",
    "start": "1950860",
    "end": "1955919"
  },
  {
    "text": "And so I can choose\nwhatever I want, but in practice it's\njust going to be things that I myself decide.",
    "start": "1955920",
    "end": "1962100"
  },
  {
    "text": "Maybe I can decide\nthat this is the value. Maybe I can decide\nthat the value is here. But for all these guys, I'm\ngoing to pretty much decide",
    "start": "1962100",
    "end": "1969590"
  },
  {
    "text": "always the same value, right? If I'm in between-- for this value u, for this\njump the jump is here.",
    "start": "1969590",
    "end": "1976710"
  },
  {
    "text": "So for this value,\nI'm going to be able to decide whether I\nwant to go above or below,",
    "start": "1976710",
    "end": "1982309"
  },
  {
    "text": "but it's always this value\nthat's going to come out. So rather than picking\nvalues that are in between,",
    "start": "1982310",
    "end": "1987380"
  },
  {
    "text": "I might as well just\npick only values for which this is the value\nthat it's going to get. And those values are\nexactly 1/n, 2/n, 3/n, 4/n.",
    "start": "1987380",
    "end": "1995450"
  },
  {
    "text": "It's all the way to n/n, right? That's exactly where\nthe flat parts are. We know we jump\nfrom 1/n every time.",
    "start": "1995450",
    "end": "2003310"
  },
  {
    "text": "And so that's\nexactly the recipe. It says look at those\nvalues, 1/n, 2/n, 3/n",
    "start": "2003310",
    "end": "2009960"
  },
  {
    "text": "until, say, n minus 1 over n. And for those values,\ncompute the inverse",
    "start": "2009960",
    "end": "2015450"
  },
  {
    "text": "of both the empiricial\nCDF and the true CDF. Now, for the empirical\nCDF, it's actually easy.",
    "start": "2015450",
    "end": "2023025"
  },
  {
    "text": "I just told you this is\nbasically where the points-- where the jumps occur. And the jumps occur where?",
    "start": "2023025",
    "end": "2029010"
  },
  {
    "text": "Well, exactly at\nmy observations. Now, remember I need to sort\nthose observations to talk",
    "start": "2029010",
    "end": "2036420"
  },
  {
    "text": "about them. So the one that occurs\nfor the i-th jump is the i-th largest observation,\nwhich we denoted by X sub (i).",
    "start": "2036420",
    "end": "2047029"
  },
  {
    "text": "Remember? We had this formula that we\nsaid, well, we have x1, xn. These are my data.",
    "start": "2047030",
    "end": "2053080"
  },
  {
    "text": "And what I'm going\nto sort them into is x sub (1), which is\nless than or equal to x",
    "start": "2053081",
    "end": "2058824"
  },
  {
    "text": "sub (2), which is\nless than x sub (n). OK?",
    "start": "2058824",
    "end": "2064300"
  },
  {
    "text": "So we just ordered them\nfrom smallest to largest. And then now we've\ndone that, we just put this parenthesis notation.",
    "start": "2064300",
    "end": "2070010"
  },
  {
    "text": "So in particular,\nFn inverse of i/n is the location where\nthe i-th jumps occur,",
    "start": "2070010",
    "end": "2078010"
  },
  {
    "text": "which is the i-th\nlargest observation. OK? So for this guy, these\nvalues, the y-axes",
    "start": "2078010",
    "end": "2087269"
  },
  {
    "text": "are actually fairly easy. I know it's basically\nmy ordered observations.",
    "start": "2087270",
    "end": "2093388"
  },
  {
    "text": "The x-values are-- well,\nthat depends on the function F I'm trying to test.",
    "start": "2093389",
    "end": "2099090"
  },
  {
    "text": "If it's the Gaussian,\nit's just the quantile of order 1 minus 1/n, right?",
    "start": "2099090",
    "end": "2105400"
  },
  {
    "text": "It's this Q1 minus 1/n here\nthat I need to compute. It's the inverse of the\ncumulative distribution",
    "start": "2105400",
    "end": "2111180"
  },
  {
    "text": "function, which, given\nthe formula for F, you can actually compute or\nmaybe estimate fairly well.",
    "start": "2111180",
    "end": "2116631"
  },
  {
    "text": "But it's something that\nyou can find in tables. Those are basically quantiles. Inverse of CDFs are\nquantiles, right?",
    "start": "2116632",
    "end": "2123940"
  },
  {
    "text": "And so that's basically the\nthings we're interested in. That's why it's called\nquantile-quantile.",
    "start": "2123940",
    "end": "2130420"
  },
  {
    "text": "Those are sometimes referred\nto as theoretical quantiles, the one we're trying to test,\nand empirical quantiles,",
    "start": "2130420",
    "end": "2137200"
  },
  {
    "text": "the one that corresponds\nto the empirical CDF. And so I'm plotting a plot\nwhere the x-axis is quantile.",
    "start": "2137200",
    "end": "2144190"
  },
  {
    "text": "The y-axis is quantile. And so I call this plot a\nquantile-quantile plot, or QQ plot, because, well, just say\n10 times quantile-quantile,",
    "start": "2144190",
    "end": "2154330"
  },
  {
    "text": "and then you'll see why. Yeah? AUDIENCE: [INAUDIBLE] have\nto have the [INAUDIBLE]??",
    "start": "2154330",
    "end": "2159977"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nWell, that's just-- we're back to the-- we're back to the\ngoodness-of-fit test, right?",
    "start": "2159977",
    "end": "2166030"
  },
  {
    "text": "So if you look-- so you don't do it yourself. That's the simple answer.",
    "start": "2166030",
    "end": "2171150"
  },
  {
    "text": "You don't-- I'm just telling you\nhow those plots are going to be seen spit out from a software\nare going to look like.",
    "start": "2171150",
    "end": "2177760"
  },
  {
    "text": "Now, depending on\nthe software, there's a different thing\nthat's happening. Some softwares are actually\nplotting F with the right--",
    "start": "2177760",
    "end": "2185050"
  },
  {
    "text": "let's say you want to\ndo normal, as you asked. So some software are\njust going to use F",
    "start": "2185050",
    "end": "2190420"
  },
  {
    "text": "to be with mu hat and\nsigma hat, and that's fine. Some software are actually\nnot going to do this.",
    "start": "2190420",
    "end": "2196150"
  },
  {
    "text": "They're just going\nto use a Gaussian. But then they're\ngoing to actually have",
    "start": "2196150",
    "end": "2201700"
  },
  {
    "text": "a different reference point. So what do we want to see here? What should happen\nif all these points--",
    "start": "2201700",
    "end": "2208960"
  },
  {
    "text": "if all my points\nactually come from F, from a distribution\nthat has CDF F? What should happen?",
    "start": "2208960",
    "end": "2214560"
  },
  {
    "text": "What should I see?  Well, since Fn\nshould be close to F,",
    "start": "2214560",
    "end": "2221510"
  },
  {
    "text": "Fn inverse should be\nclose to F inverse, which means that this point should\nbe close to that point.",
    "start": "2221510",
    "end": "2227202"
  },
  {
    "text": "This point should be\nclose to that point. So ideally, if I actually\npick the right F,",
    "start": "2227202",
    "end": "2233079"
  },
  {
    "text": "I should see a plot that looks\nlike this, something where",
    "start": "2233080",
    "end": "2239000"
  },
  {
    "text": "all my points are very\nclose to the line y",
    "start": "2239000",
    "end": "2244520"
  },
  {
    "text": "is equal to x, right? And I'm going to have\nsome fluctuations, but something very\nclose to this.",
    "start": "2244520",
    "end": "2251710"
  },
  {
    "text": "Now, that's if F is\nexactly the right one. If F is not exactly the\nright one, in particular,",
    "start": "2251710",
    "end": "2256880"
  },
  {
    "text": "in the case of a Gaussian\none, if I actually plotted here the quantiles--",
    "start": "2256880",
    "end": "2263410"
  },
  {
    "text": "so if I plotted F\n0, 1 of t, right?",
    "start": "2263410",
    "end": "2272549"
  },
  {
    "text": "So let's say those are\nthe ones I actually plot, but I really don't know\nwhat-- mu hat is not 0 and sigma hat is not 0.",
    "start": "2272550",
    "end": "2279000"
  },
  {
    "text": "And so this is not the\none I should be getting. Since we actually know that\nphi of mu hat sigma hat",
    "start": "2279000",
    "end": "2286410"
  },
  {
    "text": "squared t is equal to phi 0,\n1 of t minus mu hat divided",
    "start": "2286410",
    "end": "2292890"
  },
  {
    "text": "by sigma hat, there's\njust this change of axis, which is\nactually very simple.",
    "start": "2292890",
    "end": "2299460"
  },
  {
    "text": "This change of axis is just\na simple translation scaling, which means that\nthis line here is",
    "start": "2299460",
    "end": "2306602"
  },
  {
    "text": "going to be transformed\ninto another line with a different slope\nand a different intercept. And so some software\nwill actually decide",
    "start": "2306602",
    "end": "2314400"
  },
  {
    "text": "to go with this curve\nand just show you what the reference\ncurve should be, rather than actually\nputting everything back",
    "start": "2314400",
    "end": "2321203"
  },
  {
    "text": "onto the 45-degree curve. AUDIENCE: So if you\nget any straight line? PHILIPPE RIGOLLET: Any\nstraight line, you're happy.",
    "start": "2321203",
    "end": "2327290"
  },
  {
    "text": "I mean, depending\non the software. Because if the software actually\nreally rescaled this thing",
    "start": "2327290",
    "end": "2333180"
  },
  {
    "text": "to have mu hat and sigma square\nand you find a different line, a different straight\nline, this is",
    "start": "2333180",
    "end": "2338509"
  },
  {
    "text": "bad news, which is not\ngoing to happen actually. It's impossible that happens,\nbecause you actually-- well,",
    "start": "2338510",
    "end": "2345040"
  },
  {
    "text": "it could. If it's crazy, it could. It shouldn't be very crazy. OK. So let's see what R does\nfor us, for example.",
    "start": "2345040",
    "end": "2354600"
  },
  {
    "text": "So here in R, R actually\ndoes this funny trick where--",
    "start": "2354600",
    "end": "2360380"
  },
  {
    "text": "so here I did not\nactually plot the lines. I should actually add the lines. So the command is like\nqqnorm of my sample, right?",
    "start": "2360380",
    "end": "2367839"
  },
  {
    "text": "And that's really simple. I just stack all my data\ninto some vector, say, x.",
    "start": "2367839",
    "end": "2373579"
  },
  {
    "text": "And I say qqnorm of x, and\nit just spits this thing out.",
    "start": "2373580",
    "end": "2380150"
  },
  {
    "text": "OK? Very simple. But I could actually\nadd another command, which I can't remember.",
    "start": "2380150",
    "end": "2385220"
  },
  {
    "text": "I think it's like qqline,\nand it's just going",
    "start": "2385220",
    "end": "2390670"
  },
  {
    "text": "to add the line on top of it. But if you see, actually\nwhat R does for us, it's actually doing the\ntranslation and scaling",
    "start": "2390670",
    "end": "2398830"
  },
  {
    "text": "on the axes themselves. So it actually changes\nthe x and y-axis in such a",
    "start": "2398830",
    "end": "2405587"
  },
  {
    "text": "way that when you\nlook at your picture and you forget about what\nthe meaning of the axes are, the relevant straight\nline is actually",
    "start": "2405587",
    "end": "2411520"
  },
  {
    "text": "still the 45-degree line. It's Because it's actually done\nthe change of units for you.",
    "start": "2411520",
    "end": "2417605"
  },
  {
    "text": "So you don't have to\neven see the line. You know that, in your mind,\nthat this is basically-- the reference line is still\n45 degree because that's",
    "start": "2417605",
    "end": "2425519"
  },
  {
    "text": "the way the axes are made. But if I actually put my axes,\nright-- so here, for example, it goes from--",
    "start": "2425520",
    "end": "2431490"
  },
  {
    "text": "let's look at some-- well, OK, those are all square. Yeah, and that's probably\nbecause they actually have--",
    "start": "2431490",
    "end": "2438810"
  },
  {
    "text": "the samples are actually\nfrom a standard normal. So I did not make\nmy life very easy to illustrate your\nquestion, but of course, I",
    "start": "2438810",
    "end": "2445120"
  },
  {
    "text": "didn't know you were\ngoing to ask it. Next time, let's just prepare. Let's script more.",
    "start": "2445120",
    "end": "2450760"
  },
  {
    "text": "We'll see another\none in the next plot. But so here what\nyou expect to see is that all the plots should be\non the 45-degree line, right?",
    "start": "2450760",
    "end": "2458410"
  },
  {
    "text": "This should be the right one. And if you see, when I\nstart having 10,000 samples, this is exactly\nwhat's happening.",
    "start": "2458410",
    "end": "2464480"
  },
  {
    "text": "So this is as good as it gets. This is an N(0, 1) plotted\nagainst the theoretical quantile of an N(0, 1).",
    "start": "2464480",
    "end": "2470300"
  },
  {
    "text": "As good as it gets. And if you see, for the\nsecond one, which is 50, sample size of size--",
    "start": "2470300",
    "end": "2476610"
  },
  {
    "text": "sample of size 50, there is\nsome fudge factor, right? I mean, those things-- doesn't look like there's\na straight line, right?",
    "start": "2476610",
    "end": "2482310"
  },
  {
    "text": "It sort of appears that there\nare some weird things happening here at the lower tail.",
    "start": "2482310",
    "end": "2487810"
  },
  {
    "text": "And the reason why\nthis is happening is because we're trying to\ncompare the tails, right? When I look at this picture,\nthe only thing that goes wrong",
    "start": "2487810",
    "end": "2494980"
  },
  {
    "text": "somehow is always at\nthe tip, because those are sort of rare\nand extreme values, and they're sort of\nall over the place.",
    "start": "2494980",
    "end": "2501100"
  },
  {
    "text": "And so things are never really\nsuper smooth and super clean. So this is what\nyour best shot is.",
    "start": "2501100",
    "end": "2506920"
  },
  {
    "text": "This is what you will\never hope to get. So size 10, right, so\nyou have 10 points.",
    "start": "2506920",
    "end": "2512485"
  },
  {
    "text": "Remember, we actually--\nwell, I didn't really tell you how to deal\nwith the extreme cases. Because the problem is that\nF inverse of 1 for the true F",
    "start": "2512486",
    "end": "2519720"
  },
  {
    "text": "is plus infinity. So you have to make some sort\nof weird boundary choices to decide what F inverse\nof 1 is, and it's something",
    "start": "2519720",
    "end": "2527830"
  },
  {
    "text": "that's like somewhere. But you still want to\nput like 10 dots, right? 1, 2, 3, 4, 5, 6,\n7, 8, 9, 10 dots.",
    "start": "2527830",
    "end": "2535450"
  },
  {
    "text": "So I have 10 observations,\nyou will see 10 dots. I have 50 observations, you\nwill see 50 dots, right,",
    "start": "2535450",
    "end": "2541230"
  },
  {
    "text": "because I have-- there are 1/n, 2/n,\n3/n all the way to n/n.",
    "start": "2541230",
    "end": "2546720"
  },
  {
    "text": "I didn't tell you the last one. OK. So this is when things\ngo well, and this is when things should not go well.",
    "start": "2546720",
    "end": "2552881"
  },
  {
    "text": "OK? So here, actually,\nthe distribution is a Student's t with\n15 degrees of freedom, which should depart somewhat\nfrom a Gaussian distribution.",
    "start": "2552881",
    "end": "2561180"
  },
  {
    "text": "The tails should be heavier. And what you can see is\nbasically the following,",
    "start": "2561180",
    "end": "2567700"
  },
  {
    "text": "is that for 10 you actually see\nsomething that's crazy, right, if I do 10 observations.",
    "start": "2567700",
    "end": "2572980"
  },
  {
    "text": "But if I do 50\nobservations, honestly, it's kind of hard to say\nthat it's different from the standard normal.",
    "start": "2572980",
    "end": "2578560"
  },
  {
    "text": "So you could still be\nhappy with this for 100. And then this is what's\nhappening for 10,000.",
    "start": "2578560",
    "end": "2583839"
  },
  {
    "text": "And even here it's not the\nbeautiful straight line, but it feels like you\nwould be still tempted to conclude that it's a\nbeautiful straight line.",
    "start": "2583840",
    "end": "2591580"
  },
  {
    "text": "So let's try to guess. So basically, there's-- for\neach of those sides there's two",
    "start": "2591580",
    "end": "2598420"
  },
  {
    "text": "phenomena. Either it goes like this\nor it goes like this, and then it goes like\nthis or it goes like this.",
    "start": "2598420",
    "end": "2604960"
  },
  {
    "text": "Each side corresponds to the\nleft tail, all the smallest values. So that's the left side.",
    "start": "2604960",
    "end": "2610360"
  },
  {
    "text": "And that's the right\nside-- corresponds to the large values. OK? And so basically\nyou can actually",
    "start": "2610360",
    "end": "2615460"
  },
  {
    "text": "think of some sort of\na table that tells you what your QQ plot looks like.",
    "start": "2615460",
    "end": "2621310"
  },
  {
    "start": "2621310",
    "end": "2627220"
  },
  {
    "text": "And so let's say it looks-- so we have our reference\n45-degree line. So let's say this\nis the QQ plot.",
    "start": "2627220",
    "end": "2632960"
  },
  {
    "text": "That could be one thing. This could be the QQ plot\nwhere I have another thing.",
    "start": "2632960",
    "end": "2639380"
  },
  {
    "text": "Then I can do this guy,\nand then I do this guy.",
    "start": "2639380",
    "end": "2648890"
  },
  {
    "text": "So this is like this. OK? So those are the four cases. OK?",
    "start": "2648890",
    "end": "2654950"
  },
  {
    "text": "And here what's changing\nis the right tail, and here what's\nchanging is the--",
    "start": "2654950",
    "end": "2660970"
  },
  {
    "text": "and when I go from here to here,\nwhat changes is the left tail. Is that true?",
    "start": "2660970",
    "end": "2666851"
  },
  {
    "text": "No, sorry. What changes here is\nthe right tail, right? It's this part that\nchanges from top to bottom.",
    "start": "2666851",
    "end": "2674110"
  },
  {
    "text": "So here it's something\nabout right tail, and here that's something\nabout left tail.",
    "start": "2674110",
    "end": "2680410"
  },
  {
    "text": " Everybody understands what I\nmean when I talk about tails?",
    "start": "2680410",
    "end": "2686805"
  },
  {
    "text": "OK. And so here it's\njust going to be a question of whether\nthe tails are heavier",
    "start": "2686805",
    "end": "2692670"
  },
  {
    "text": "or lighter than the Gaussian. Everybody understand\nwhat I mean when I say heavy tails and light tails?",
    "start": "2692670",
    "end": "2698640"
  },
  {
    "text": "OK. So right, so heavy\ntails just means that basically here\nthe tails of this guy",
    "start": "2698640",
    "end": "2704880"
  },
  {
    "text": "are heavier than the\ntails of this guy. So it means that if I draw\nthem, they're going to be above. Actually, I'm going to keep\nthis picture because it's",
    "start": "2704880",
    "end": "2710520"
  },
  {
    "text": "going to be very useful for me. ",
    "start": "2710520",
    "end": "2716170"
  },
  {
    "text": "When I plug the quantiles\nat the same-- so let's look at the right\ntail, for example.",
    "start": "2716170",
    "end": "2721180"
  },
  {
    "text": "Right here my picture\nis for right tails. When I look at the quantiles of\nmy theoretical distribution--",
    "start": "2721180",
    "end": "2726350"
  },
  {
    "text": "so here you can see\nthe bottom curve we have the\ntheoretical quantiles,",
    "start": "2726350",
    "end": "2731420"
  },
  {
    "text": "and those are the\nempirical quantiles. If I look to the right here,\nare the theoretical quantiles",
    "start": "2731420",
    "end": "2739090"
  },
  {
    "text": "larger or smaller than\nthe empirical quantiles? ",
    "start": "2739090",
    "end": "2747124"
  },
  {
    "text": "Let me phrase it the other-- are the empirical\nquantiles larger or smaller than the theoretical quantiles?",
    "start": "2747124",
    "end": "2753250"
  },
  {
    "text": "AUDIENCE: This is a graph\nof quantiles, right? So if it's [INAUDIBLE]\nit should be smaller.",
    "start": "2753250",
    "end": "2759072"
  },
  {
    "text": "PHILIPPE RIGOLLET: It\nshould be smaller, right? On this line, they are equal.",
    "start": "2759072",
    "end": "2764190"
  },
  {
    "text": "So if I see the empirical\nquantile showing up here, it means that here the\nempirical quantile is less",
    "start": "2764190",
    "end": "2770510"
  },
  {
    "text": "than the theoretical quantile. Agree? So that means that if\nI look at this thing--",
    "start": "2770510",
    "end": "2776410"
  },
  {
    "text": "and that's for the\nsame values, right? So the quantiles are computed\nfor the same values i/n.",
    "start": "2776410",
    "end": "2782440"
  },
  {
    "text": "So it means that the empirical\nquantiles should be looking-- so that should be the\nempirical quantile,",
    "start": "2782440",
    "end": "2789839"
  },
  {
    "text": "and that should be the\ntheoretical quantile. Agreed? Those are the smaller\nvalues for the same alpha.",
    "start": "2789840",
    "end": "2797730"
  },
  {
    "text": "So that implies that the tails-- the right tail, is\nit heavy or lighter--",
    "start": "2797730",
    "end": "2803880"
  },
  {
    "text": "heavier or lighter\nthan the Gaussian? ",
    "start": "2803880",
    "end": "2810390"
  },
  {
    "text": "AUDIENCE: Lighter. PHILIPPE RIGOLLET:\nLighter, right? Because those are the\ntails of the Gaussian. Those are my\ntheoretical quantiles.",
    "start": "2810390",
    "end": "2815650"
  },
  {
    "text": "That means that this is the tail\nof my empirical distribution. So they are actually lighter.",
    "start": "2815650",
    "end": "2820870"
  },
  {
    "start": "2820870",
    "end": "2828090"
  },
  {
    "text": "OK? So here, if I look\nat this thing, this means that the right\ntail is actually light.",
    "start": "2828090",
    "end": "2838240"
  },
  {
    "text": "And by light, I mean\nlighter than Gaussian. Heavy, I mean heavier\nthan Gaussian. OK?",
    "start": "2838240",
    "end": "2843730"
  },
  {
    "text": "OK, now we can probably\ndo the entire thing. Well, if this is light, this\nis going to be heavy, right?",
    "start": "2843730",
    "end": "2851980"
  },
  {
    "text": "That's when I'm above the curve.  Exercise-- is this light or is\nthis heavy, the first column?",
    "start": "2851980",
    "end": "2860390"
  },
  {
    "start": "2860390",
    "end": "2866970"
  },
  {
    "text": "And it's OK. It should take you\nat least 30 seconds. AUDIENCE: [INAUDIBLE]\ndifferent column?",
    "start": "2866970",
    "end": "2873569"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah,\nthis column, right? So this is something\nthat pertains-- this entire column is going\nto tell me whether the fact",
    "start": "2873570",
    "end": "2879080"
  },
  {
    "text": "that this guy is\nabove, does this mean that I have lighter\nor heavier left tails?",
    "start": "2879080",
    "end": "2886570"
  },
  {
    "text": "AUDIENCE: Well, on the\nleft, it's heavier. PHILIPPE RIGOLLET: On\nthe left, it's heavier. OK.",
    "start": "2886570",
    "end": "2892089"
  },
  {
    "text": "I don't know. Actually, I need\nto draw a picture. You guys are probably\nfaster than I am.",
    "start": "2892090",
    "end": "2897348"
  },
  {
    "text": "AUDIENCE: [INTERPOSING VOICES]. PHILIPPE RIGOLLET:\nActually, let me check how much randomness is--",
    "start": "2897348",
    "end": "2903400"
  },
  {
    "text": "who says it's lighter? Who says it's heavier? AUDIENCE: Yeah,\nbut we're biased.",
    "start": "2903400",
    "end": "2909880"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET: Yeah, OK. AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET: All right. So let's see if it's heavier.",
    "start": "2909880",
    "end": "2916760"
  },
  {
    "text": "So we're on the left tail, and\nso we have one looks like this, one looks like that, right?",
    "start": "2916760",
    "end": "2921910"
  },
  {
    "text": " So we know here that I'm\nlooking at this part here.",
    "start": "2921910",
    "end": "2929099"
  },
  {
    "text": "So it means that here my\nempirical quantile is larger than the theoretical quantile. ",
    "start": "2929100",
    "end": "2938480"
  },
  {
    "text": "OK? So are my tails\nheavier or lighter? ",
    "start": "2938480",
    "end": "2946125"
  },
  {
    "text": "They're lighter. That was a bad bias. AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET: Right?",
    "start": "2946125",
    "end": "2951340"
  },
  {
    "text": "It's below, so it's lighter. Because the problem is that\nlarger for the negative ones",
    "start": "2951340",
    "end": "2959099"
  },
  {
    "text": "means that it's smaller\n[INAUDIBLE],, right? Yeah? AUDIENCE: Sorry but, what\nexactly are these [INAUDIBLE]??",
    "start": "2959100",
    "end": "2966514"
  },
  {
    "text": "If this is the inverse-- if this is the inverse\nCDF, shouldn't everything--",
    "start": "2966514",
    "end": "2972935"
  },
  {
    "text": "well, if this is\nthe inverse CDF, then you should\nonly be inputting values between 0 and 1 in it.",
    "start": "2972936",
    "end": "2978864"
  },
  {
    "text": "And-- PHILIPPE RIGOLLET: Oh,\ndid I put the inverse CDF? AUDIENCE: Like on the\nprevious slide, I think.",
    "start": "2978864",
    "end": "2986814"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nNo, the inverse CDF, yeah, so I'm inputting-- AUDIENCE: Oh,\nyou're [INAUDIBLE].. PHILIPPE RIGOLLET: Yeah, so\nit's a scatter plot, right?",
    "start": "2986814",
    "end": "2993630"
  },
  {
    "text": "So each point is\nattached-- each point is attached 1/n, 2/n, 3/n.",
    "start": "2993630",
    "end": "2999990"
  },
  {
    "text": "Now, for each\npoint I'm plotting, that's my x-value, which\nmaps a number between 0 and 1",
    "start": "2999990",
    "end": "3005060"
  },
  {
    "text": "back onto the entire real line,\nand my y-value is the same. OK?",
    "start": "3005060",
    "end": "3010190"
  },
  {
    "text": "So what it means is that those\ntwo numbers, this is in the-- this lives on the entire real\nline, not on the interval.",
    "start": "3010190",
    "end": "3017330"
  },
  {
    "text": "This lives on the entire real\nline, not in the interval. And so my QQ plots take values\non the entire real line,",
    "start": "3017330",
    "end": "3026630"
  },
  {
    "text": "entire real line, right? So you think of it as a\nparameterized curve, where",
    "start": "3026630",
    "end": "3031914"
  },
  {
    "text": "the time steps\nare 1/n, 2/n, 3/n, and I'm just like putting a dot\nevery time I'm making one step.",
    "start": "3031915",
    "end": "3038740"
  },
  {
    "text": "OK? OK, so what did we say? That was lighter, right?",
    "start": "3038740",
    "end": "3046356"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET: OK?",
    "start": "3046356",
    "end": "3054110"
  },
  {
    "text": "One of my favorite exercises\nis, here's a bunch of densities. Here's a bunch of QQ plots.",
    "start": "3054110",
    "end": "3060140"
  },
  {
    "text": "Map the correct QQ plot\nto its own density. All right?",
    "start": "3060140",
    "end": "3065980"
  },
  {
    "text": "And there won't be mingled\nlines that allow you to do that, then you just have to follow,\nlike at the back of cereal",
    "start": "3065980",
    "end": "3071720"
  },
  {
    "text": "boxes. All right. Are there any questions?",
    "start": "3071720",
    "end": "3077165"
  },
  {
    "text": "So one thing--\nthere's two things I'm trying to\ncommunicate here is if you see a QQ plot, now\nyou should understand,",
    "start": "3077165",
    "end": "3082460"
  },
  {
    "text": "one, how it was built, and two,\nwhether it means that you have",
    "start": "3082460",
    "end": "3088349"
  },
  {
    "text": "heavier tails or lighter tails. Now, let's look at this guy. What should we see?",
    "start": "3088350",
    "end": "3094800"
  },
  {
    "text": "We should see heavy on the left\nand heavy on the right, right? We know that this\nshould be the case. So this thing actually looks\nlike this, and it sort of does,",
    "start": "3094800",
    "end": "3105130"
  },
  {
    "text": "right? If I take this line\ngoing through here, I can see that this\nguy's tipping here,",
    "start": "3105130",
    "end": "3110620"
  },
  {
    "text": "and this guy's dipping here. But honestly-- actually, I can't\nremember exactly, but t 15,",
    "start": "3110620",
    "end": "3117670"
  },
  {
    "text": "if I plotted the density\non top of the Gaussian, you can see a difference.",
    "start": "3117670",
    "end": "3122776"
  },
  {
    "text": "But if I just gave it to\nyou, it would be very hard for you to tell me if there's\nan actual difference between t 15 and Gaussian, right?",
    "start": "3122776",
    "end": "3128950"
  },
  {
    "text": "Those things are\nactually very close. And so in particular,\nhere we're really trying to recognize what\nthe shape is the fact--",
    "start": "3128950",
    "end": "3135640"
  },
  {
    "text": "right? So t 15 compared to a standard\nGaussian was different,",
    "start": "3135640",
    "end": "3140980"
  },
  {
    "text": "but t 15 compared to a Gaussian\nwith a slightly larger variance",
    "start": "3140980",
    "end": "3146119"
  },
  {
    "text": "is not going to actually--\nyou're not going to see much of a difference. So in a way, such\ndistributions are actually not",
    "start": "3146119",
    "end": "3153610"
  },
  {
    "text": "too far from the Gaussian,\nand it's not too-- it's still pretty benign to\nconclude that this was actually",
    "start": "3153610",
    "end": "3158950"
  },
  {
    "text": "a Gaussian distribution because\nyou can just use the variance as a little bit of a buffer. I'm not going to\nget really into how",
    "start": "3158950",
    "end": "3165250"
  },
  {
    "text": "you would use a\nt-distribution into a t-test,",
    "start": "3165250",
    "end": "3170500"
  },
  {
    "text": "because it's kind of\nlike Inception, right? So but you could pretend\nthat your data actually",
    "start": "3170500",
    "end": "3178150"
  },
  {
    "text": "is t-distributed and then\nbuild a t-distribution from it, but let's not say that.",
    "start": "3178150",
    "end": "3183570"
  },
  {
    "text": "Maybe that was a bad example. But there's like other\nheavy-tailed distributions like Cauchy distribution, which\ndoesn't even have a--",
    "start": "3183570",
    "end": "3190825"
  },
  {
    "text": "it's not even integrable\nbecause that's as heavy as the tails get. And this you can really tell\nit's going to look like this.",
    "start": "3190825",
    "end": "3198760"
  },
  {
    "text": "It's going to be like pfft. What does a uniform\ndistribution look like?",
    "start": "3198760",
    "end": "3204240"
  },
  {
    "start": "3204240",
    "end": "3210727"
  },
  {
    "text": "Like this? It's going to be-- it's going\nto look like a Gaussian one,",
    "start": "3210727",
    "end": "3217890"
  },
  {
    "text": "right? So a uniform-- so\nthis is my Gaussian. A uniform is basically\ngoing to look like this,",
    "start": "3217890",
    "end": "3223130"
  },
  {
    "text": "one side take the right mean\nand the right variance, right? So the tails are\ndefinitely lighter.",
    "start": "3223130",
    "end": "3228480"
  },
  {
    "text": "They're 0. That's as lighter as it gets. So the light-light is going\nto look like this S shape.",
    "start": "3228480",
    "end": "3235290"
  },
  {
    "text": "So an S-- light-tailed\ndistribution has this S shape. OK? What is the exponential\ngoing to look like?",
    "start": "3235290",
    "end": "3242520"
  },
  {
    "text": " So the exponential is\npositively supported.",
    "start": "3242520",
    "end": "3248500"
  },
  {
    "text": "It only has positive numbers. So there's no left tail. This is also as\nlight as it gets.",
    "start": "3248500",
    "end": "3254110"
  },
  {
    "text": "But the right tail, is\nit heavier or lighter than the Gaussian? AUDIENCE: Heavier. PHILIPPE RIGOLLET:\nIt's heavier, right? It's only the case like e of the\nminus x rather e to the minus",
    "start": "3254110",
    "end": "3261990"
  },
  {
    "text": "x squared. So it's heavier. So it means that on the\nleft it's going to be light,",
    "start": "3261990",
    "end": "3267620"
  },
  {
    "text": "and on the right it's\ngoing to be heavy. So it's going to be U-shaped. OK? ",
    "start": "3267620",
    "end": "3275340"
  },
  {
    "text": "That will be fine. All right. Any other question?",
    "start": "3275340",
    "end": "3281840"
  },
  {
    "text": "Again, two messages,\nlike, more technical, and you can sort of fiddle\nwith it by looking at it.",
    "start": "3281840",
    "end": "3287960"
  },
  {
    "text": "You can definitely\nconclude that this is OK enough to be\nGaussian for your purposes.",
    "start": "3287960",
    "end": "3293455"
  },
  {
    "text": "Yeah? AUDIENCE: So [INAUDIBLE]",
    "start": "3293456",
    "end": "3299591"
  },
  {
    "text": "PHILIPPE RIGOLLET: I\ndid not hear the \"if\" at the beginning\nof your sentence. ",
    "start": "3299591",
    "end": "3306431"
  },
  {
    "text": "AUDIENCE: I would want to\nbe lighter tail, right, because that'll be--\nit's easier to reject? Is that correct?",
    "start": "3306431",
    "end": "3311909"
  },
  {
    "text": " PHILIPPE RIGOLLET: So what\nis your purpose as a--",
    "start": "3311909",
    "end": "3320272"
  },
  {
    "text": "AUDIENCE: I want to-- I have some [INAUDIBLE] right? I want to be able to say\nI reject H0 [INAUDIBLE]..",
    "start": "3320272",
    "end": "3328551"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yes. AUDIENCE: So if you\nwanted to make it easier to reject H0, then--",
    "start": "3328551",
    "end": "3335002"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah, in\na way that's true, right? So once you've actually factored\nin the mean and the variance,",
    "start": "3335002",
    "end": "3340440"
  },
  {
    "text": "the only thing that actually-- right. So if you have Gaussian tails\nor lighter-- even lighter tails,",
    "start": "3340440",
    "end": "3347950"
  },
  {
    "text": "then it's harder for you\nto explain deviations from randomness only, right? If you have a\nuniform distribution",
    "start": "3347950",
    "end": "3354640"
  },
  {
    "text": "and you see something which is-- if you're uniform on 0, 1 plus\nsome number and you see 25,",
    "start": "3354640",
    "end": "3359680"
  },
  {
    "text": "you know this number is\nnot going to be 0, right? So that's basically\nas good as it gets. And there's basically\nsome smooth interpolation",
    "start": "3359680",
    "end": "3366610"
  },
  {
    "text": "if you have lighter tails. Now, if you start having\nsomething that has heavy tails, then it's more likely\nthat pure noise",
    "start": "3366610",
    "end": "3372880"
  },
  {
    "text": "will generate large observations\nand therefore discovery. So yes, lighter\ntails is definitely",
    "start": "3372880",
    "end": "3379160"
  },
  {
    "text": "the better-behaved noise. Let's put it this way. The lighter it is, the\nbetter behaved it is.",
    "start": "3379160",
    "end": "3384740"
  },
  {
    "text": "Now, this is good-- this is good for some purposes,\nbut when you want to compute",
    "start": "3384740",
    "end": "3390140"
  },
  {
    "text": "actual quantiles,\nlike exact quantiles,",
    "start": "3390140",
    "end": "3395420"
  },
  {
    "text": "then it is true in general that\nthe quantiles of lighter-tail distributions are going to be\ndominated by the-- are going",
    "start": "3395420",
    "end": "3402520"
  },
  {
    "text": "to be dominated by the-- let's say on the\nright tails, are",
    "start": "3402520",
    "end": "3407610"
  },
  {
    "text": "going to be dominated by\nthose of a heavy distribution. That is true.",
    "start": "3407610",
    "end": "3412729"
  },
  {
    "text": "But that's not always the case. And in particular,\nthere's going to be some like sort of weird points\nwhere things are actually changing depending on what\nlevel you're actually looking",
    "start": "3412729",
    "end": "3419960"
  },
  {
    "text": "at those things,\nmaybe 5% or 10%, in which case things might\nbe changing a little bit. But if you started going\nreally towards the tail,",
    "start": "3419960",
    "end": "3426171"
  },
  {
    "text": "if you start looking at levels\nalpha which are 1% or 0.1%, it is true that it's always--",
    "start": "3426171",
    "end": "3433070"
  },
  {
    "text": "if you can actually--\nso if you see something that looks light\ntail, you definitely do not want to conclude\nthat it's Gaussian.",
    "start": "3433070",
    "end": "3438581"
  },
  {
    "text": "You want to actually change\nyour modeling so that it makes your life even easier. And you actually\nfactor in the fact",
    "start": "3438581",
    "end": "3445400"
  },
  {
    "text": "that you can see that the\nnoise is actually more benign than you would like it to be.",
    "start": "3445400",
    "end": "3450929"
  },
  {
    "text": "OK?  Stretching fingers, that's it? All right.",
    "start": "3450929",
    "end": "3457930"
  },
  {
    "text": "OK. So I want to-- I mentioned at some point that\nwe had this chi-square test",
    "start": "3457930",
    "end": "3463380"
  },
  {
    "text": "that was showing up. And I do not know what I did-- let's just-- oh, yeah.",
    "start": "3463380",
    "end": "3469260"
  },
  {
    "text": "So we have this chi-square test\nthat we worked on last time, right?",
    "start": "3469260",
    "end": "3474270"
  },
  {
    "text": "So the way I introduced the\nchi-square test is by saying, I am fascinated\nby this question.",
    "start": "3474270",
    "end": "3479520"
  },
  {
    "text": "Let's check if it's correct, OK? Or something maybe\nslightly deeper-- let's check if juries\nin this country",
    "start": "3479520",
    "end": "3486570"
  },
  {
    "text": "are representative of\nracial distribution. But you could actually--\nthose numbers here",
    "start": "3486570",
    "end": "3494640"
  },
  {
    "text": "come from a very specific thing. That was the uniform. That was our benchmark. Here's the uniform. And there was this guy,\nwhich was a benchmark, which",
    "start": "3494640",
    "end": "3501690"
  },
  {
    "text": "was the actual benchmark that we\nneed to have for this problem. And those things basically\ncame out of my hat, right?",
    "start": "3501690",
    "end": "3507000"
  },
  {
    "text": "Those are numbers that exist. But in practice, you actually\nmake those numbers yourself.",
    "start": "3507000",
    "end": "3513119"
  },
  {
    "text": "And the way you do it\nis by saying, well, if I have a binomial\ndistribution",
    "start": "3513120",
    "end": "3519760"
  },
  {
    "text": "and I want to test\nif my data comes from a binomial\ndistribution, you could ask this question, right? You have a bunch of data.",
    "start": "3519760",
    "end": "3525580"
  },
  {
    "text": "I did not promise\nto you that this was the sum of independent\nBernoullis and [INAUDIBLE]..",
    "start": "3525580",
    "end": "3530920"
  },
  {
    "text": "And then you can actually check\nthat it's a binomial indeed, and you have binomial. If you think about where\nyou've encountered binomials,",
    "start": "3530920",
    "end": "3537580"
  },
  {
    "text": "it was mostly when\nyou were drawing balls from urns, which you probably\ndon't do that much in practice. OK?",
    "start": "3537580",
    "end": "3542990"
  },
  {
    "text": "And so maybe one day you want\nto model things as a binomial, or maybe you want to\nmodel it as a Poisson, as a limiting binomial, right?",
    "start": "3542990",
    "end": "3548800"
  },
  {
    "text": "People tell you photons arrive-- the rate of a photon\nhitting some surface is actually a Poisson\ndistribution, right?",
    "start": "3548800",
    "end": "3555460"
  },
  {
    "text": "That's where they\narise a lot in imaging. So if I have a colleague\nwho's taking pictures",
    "start": "3555460",
    "end": "3561100"
  },
  {
    "text": "of the skies over night, and\nhe's like following stars and it's just like moving around\nwith the rotation of the Earth.",
    "start": "3561100",
    "end": "3566380"
  },
  {
    "text": "And he has to do this\nfor like eight hours because he needs to get enough\nphotons over this picture to actually arise.",
    "start": "3566380",
    "end": "3572150"
  },
  {
    "text": "And he knows they arrive\nat like a Poisson process, and you know, chapter 7 of your\nprobability class, I guess.",
    "start": "3572150",
    "end": "3579829"
  },
  {
    "text": "And And there's all\nthese distributions outside the classroom\nyou probably",
    "start": "3579830",
    "end": "3584890"
  },
  {
    "text": "want to check that\nthey're actually correct. And so the first one you might\nwant to check, for example, is a binomial. So I give you a distribution,\na binomial distribution",
    "start": "3584890",
    "end": "3592540"
  },
  {
    "text": "on, say, K trials, and\nyou have some number p. And here, I don't know\ntypically what p should be,",
    "start": "3592540",
    "end": "3599140"
  },
  {
    "text": "but let's say I know it or\nestimate it from my data. And here, since we're only\ngoing to deal with asymptotics,",
    "start": "3599140",
    "end": "3604240"
  },
  {
    "text": "just like it was the case for\nthe Kolmogorov-Smirnov one, in the asymptotic\nwe're going to be able to think of the estimated\np as being a true p, OK,",
    "start": "3604240",
    "end": "3613086"
  },
  {
    "text": "under the null at least. So therefore, each outcome,\nI can actually tell you what",
    "start": "3613086",
    "end": "3619180"
  },
  {
    "text": "the probability of a binomial-- is this outcome. For a given K and a\ngiven p, I can tell you exactly what a binomial\nshould give you",
    "start": "3619180",
    "end": "3625690"
  },
  {
    "text": "as the probability\nfor the outcome. And that's what I actually use\nto replace the numbers 1/12,",
    "start": "3625690",
    "end": "3633670"
  },
  {
    "text": "1/12, 1/12, 1/12 or the\nnumbers 0.72, 0.7, 0.12, 0.9.",
    "start": "3633670",
    "end": "3641290"
  },
  {
    "text": "All these numbers I\ncan actually compute using the probabilities\nof a binomial, right? So I know, for example, that the\nprobability that a binomial np",
    "start": "3641290",
    "end": "3652599"
  },
  {
    "text": "is equal to, say, K is n\nchoose K p to the K 1 minus p",
    "start": "3652600",
    "end": "3662830"
  },
  {
    "text": "to the n minus K. OK? I mean, so these are numbers. If you give me p\nand you give me n,",
    "start": "3662830",
    "end": "3668800"
  },
  {
    "text": "I can compute those numbers\nfor all K from 0 to n. And from this I can\nactually build a table.",
    "start": "3668800",
    "end": "3674604"
  },
  {
    "start": "3674604",
    "end": "3682060"
  },
  {
    "text": "All right? So for each K-- 0. So K is here, and\nfrom 0, 1, et cetera,",
    "start": "3682060",
    "end": "3691020"
  },
  {
    "text": "all the way to n, I can compute\nthe true probability, which is the probability that my\nbinomial np is equal to 0,",
    "start": "3691020",
    "end": "3700680"
  },
  {
    "text": "the probability that my binomial\nis equal to 1, et cetera, all the way to n.",
    "start": "3700680",
    "end": "3706440"
  },
  {
    "text": "I can compute those numbers. Those are actually going\nto be exact numbers, right? I just plug in the\nformula that I had.",
    "start": "3706440",
    "end": "3712952"
  },
  {
    "text": "And then I'm going to\nhave some observed. ",
    "start": "3712952",
    "end": "3721900"
  },
  {
    "text": "So that's going to be p\nhat, 0, and that's basically the proportion of 0's, right?",
    "start": "3721900",
    "end": "3732430"
  },
  {
    "text": "So here you have to remember\nit's not a one-time experiment like you do in\nprobability where you say,",
    "start": "3732430",
    "end": "3738250"
  },
  {
    "text": "I'm going to draw n\nballs from an urn, and I'm counting how many--",
    "start": "3738250",
    "end": "3744099"
  },
  {
    "text": "how many I have. This is statistics. I need to be able to do\nthis experiment many times so I can actually, in the\nend, get an idea of what",
    "start": "3744100",
    "end": "3751910"
  },
  {
    "text": "the proportion of p's is. So you have not\njust one binomial, but you have n binomials.",
    "start": "3751910",
    "end": "3758300"
  },
  {
    "text": "Well, maybe I should\nnot use n twice. So that's why it's\nthe K here, right? So I have a binomial\n[INAUDIBLE] at Kp",
    "start": "3758300",
    "end": "3764140"
  },
  {
    "text": "and I just seize\nn of those guys. And with this n of those\nguys, I can actually estimate those probabilities.",
    "start": "3764140",
    "end": "3770072"
  },
  {
    "text": "And what I'm going\nto want to check is if those two\nprobabilities are actually close to each other. But I already know\nhow to do this.",
    "start": "3770072",
    "end": "3777980"
  },
  {
    "text": "All right? So here I'm going\nto test whether P is in some parametric\nfamily, for example, binomial or not binomial.",
    "start": "3777980",
    "end": "3786700"
  },
  {
    "text": "And testing-- if I know that\nit's a binomial [INAUDIBLE],, and I basically just have to\ntest if P is the right thing.",
    "start": "3786700",
    "end": "3792869"
  },
  {
    "text": "OK? Oh, sorry, I'm actually\nlying to you here. OK.",
    "start": "3792870",
    "end": "3798210"
  },
  {
    "text": "I don't want to test\nif it's binomial. I want to test the parameter\nof the binomial here.",
    "start": "3798210",
    "end": "3804220"
  },
  {
    "text": "OK? So I know-- no, sorry,\n[INAUDIBLE] sorry. OK. So I want to know if\nI'm in some family,",
    "start": "3804220",
    "end": "3810960"
  },
  {
    "text": "the family of binomials, or\nnot in the family of binomials. OK? Well, that's what I want to do.",
    "start": "3810960",
    "end": "3816910"
  },
  {
    "text": "And so here H0 is basically\nequivalent to testing if the pj's are the pj's\nthat come from the binomial.",
    "start": "3816910",
    "end": "3822750"
  },
  {
    "text": "And the pj's here are the\nprobabilities that I get. This is the probability\nthat I get j successes.",
    "start": "3822750",
    "end": "3830180"
  },
  {
    "text": "That's my pj. That's j's value here. OK? So this is the example,\nand we know how to do this.",
    "start": "3830180",
    "end": "3837600"
  },
  {
    "text": "We construct p hat,\nwhich is the estimated proportion of successes\nfrom the observations.",
    "start": "3837600",
    "end": "3843230"
  },
  {
    "text": "So here now I have n trials. This is the actual maximum\nlikelihood estimator.",
    "start": "3843230",
    "end": "3848390"
  },
  {
    "text": "This becomes a multinomial\nexperiment, right? So it's kind of confusing.",
    "start": "3848390",
    "end": "3853430"
  },
  {
    "text": "We have a multinomial experiment\nfor a binomial distribution. The binomial here\nis just a recipe",
    "start": "3853430",
    "end": "3859520"
  },
  {
    "text": "to create some\ntest probabilities. That's all it is. The binomial here\ndoesn't really matter. It's really to create\nthe test probabilities.",
    "start": "3859520",
    "end": "3866539"
  },
  {
    "text": "And then I'm going to define\nthis test statistic, which is known as the chi-square\nstatistic, right?",
    "start": "3866539",
    "end": "3876420"
  },
  {
    "text": "This was the chi-square test. We just looked at sum of the\nsquare root of the differences.",
    "start": "3876420",
    "end": "3881490"
  },
  {
    "text": "Inverting the covariance matrix\nor using the Fisher information with removing the part\nthat was not invertible",
    "start": "3881490",
    "end": "3886920"
  },
  {
    "text": "led us to actually use\nthis particular value here, and then we had\nto multiply by n.",
    "start": "3886920",
    "end": "3894325"
  },
  {
    "text": "OK? And that, we know,\nconverges to what?",
    "start": "3894325",
    "end": "3899710"
  },
  {
    "text": "A chi-square distribution. So I'm not going to\ngo through this again. I'm just telling you you\ncan use the chi-square",
    "start": "3899710",
    "end": "3905218"
  },
  {
    "text": "that we've seen, where we just\ncame up with the numbers we were testing. Those numbers that were in this\nrow for the true probabilities,",
    "start": "3905218",
    "end": "3912350"
  },
  {
    "text": "we came up with them\nout of thin air. And now I'm telling\nyou you can actually come up with those guys\nfrom a binomial distribution",
    "start": "3912350",
    "end": "3919010"
  },
  {
    "text": "or a Poisson\ndistribution or whatever distribution you're happy with. ",
    "start": "3919010",
    "end": "3926004"
  },
  {
    "text": "Any question?  So now I'm creating\nthis thing, and I",
    "start": "3926004",
    "end": "3931970"
  },
  {
    "text": "can apply the entire theory\nthat I have for the chi-square and, in particular, that\nthis thing converges to a chi-square.",
    "start": "3931970",
    "end": "3938846"
  },
  {
    "text": "But if you see, there's\nsomething that's different. What is different? ",
    "start": "3938846",
    "end": "3945640"
  },
  {
    "text": "The degrees of freedom. And if you think about it,\nagain, the meaning of degrees",
    "start": "3945640",
    "end": "3951990"
  },
  {
    "text": "of freedom. What does this word-- these words actually mean? It means, well, to\nwhich extent can I",
    "start": "3951990",
    "end": "3957960"
  },
  {
    "text": "play around with those values? What are the possible\nvalues that I can get? If I'm not equal to this\nparticular value I'm testing,",
    "start": "3957960",
    "end": "3963990"
  },
  {
    "text": "how many directions can I\nbe different from this guy? And when we had a\ngiven set of values,",
    "start": "3963990",
    "end": "3970650"
  },
  {
    "text": "we could be any other\nset of values, right? So here, I had this--",
    "start": "3970650",
    "end": "3976140"
  },
  {
    "text": "I'm going to represent-- this\nis the set of all probability distributions of vectors\nof size K. So here,",
    "start": "3976140",
    "end": "3983910"
  },
  {
    "text": "if I look at one\npoint in this set, this is something that looks\nlike p1 through pK such that",
    "start": "3983910",
    "end": "3989530"
  },
  {
    "text": "their sum-- such that they're non-negative,\nand the sum p1 through pK",
    "start": "3989530",
    "end": "3996520"
  },
  {
    "text": "is equal to 1. OK? So I have all those points here. OK?",
    "start": "3996520",
    "end": "4001900"
  },
  {
    "text": "So this is basically the\nset that I had before. I was testing whether I\nwas equal to this one guy,",
    "start": "4001900",
    "end": "4007210"
  },
  {
    "text": "or if I was anything else. And there's many ways\nI can be anything else. What matters, of course,\nis what's around this guy",
    "start": "4007210",
    "end": "4013240"
  },
  {
    "text": "that I could actually\nconfuse myself with. But there's many ways I\ncan move around this guy. Agreed?",
    "start": "4013240",
    "end": "4020670"
  },
  {
    "text": "Now I'm actually just testing\nsomething very specific. I'm saying, well,\nnow the piece that I",
    "start": "4020670",
    "end": "4026839"
  },
  {
    "text": "have had to come\nfrom this-- have to be constructed from this\nformula, this parametric family",
    "start": "4026840",
    "end": "4033559"
  },
  {
    "text": "P of theta. And there's a fixed way for--\nlet's say this is theta,",
    "start": "4033560",
    "end": "4040130"
  },
  {
    "text": "so I have a theta here. There's not that many ways\nthis can actually give me",
    "start": "4040130",
    "end": "4046150"
  },
  {
    "text": "a set of probabilities, right? I have to move to another\ntheta to actually start being confused.",
    "start": "4046150",
    "end": "4052510"
  },
  {
    "text": "And so here the number\nof degrees of freedom is basically, how can I\nmove along this family?",
    "start": "4052510",
    "end": "4059200"
  },
  {
    "text": "And so here, this\nis all the points, but there might\nbe just the subset of the points that looks\nlike this, just this curve,",
    "start": "4059200",
    "end": "4065750"
  },
  {
    "text": "not the half of this thing. And those guys on this\ncurve are the p thetas,",
    "start": "4065750",
    "end": "4076210"
  },
  {
    "text": "and that's for all thetas\nwhen theta runs across data. So in a way, this is just a\nmuch smaller dimensional thing.",
    "start": "4076210",
    "end": "4083060"
  },
  {
    "text": "It's a much smaller object. Those are only the\nones that I can create that are exactly of this\nvery specific parametric form.",
    "start": "4083060",
    "end": "4093100"
  },
  {
    "text": "And of course, not\nall are of this form. Not all probability\nPMFs are of this form.",
    "start": "4093100",
    "end": "4099270"
  },
  {
    "text": "And so that is going\nto have an effect on what my PMF is going to be-- sorry, on what my--",
    "start": "4099270",
    "end": "4108830"
  },
  {
    "text": "sorry, what my degrees of\nfreedoms are going to be. Because when this thing is\nvery small, that means when--",
    "start": "4108830",
    "end": "4119149"
  },
  {
    "text": "that's happening when\ntheta is actually, say, a one-dimensional\nspace, then there's still",
    "start": "4119149",
    "end": "4124670"
  },
  {
    "text": "many ways I can escape, right? I can be different\nfrom this guy in pretty much every other direction,\nexcept for those two",
    "start": "4124670",
    "end": "4130939"
  },
  {
    "text": "directions, just\nwhen I move from here or when I move in\nthis direction.",
    "start": "4130939",
    "end": "4136049"
  },
  {
    "text": "But now if this\nthing becomes bigger, your theta is, say,\ntwo dimensional,",
    "start": "4136050",
    "end": "4143399"
  },
  {
    "text": "then when I'm here\nit's becoming harder for me to not be that guy. If I want to move\naway from it, then I",
    "start": "4143399",
    "end": "4148812"
  },
  {
    "text": "have to move away\nfrom the board. And so that means that\nthe bigger the dimension",
    "start": "4148812",
    "end": "4155018"
  },
  {
    "text": "of my theta, the smaller\nthe degrees of freedoms that I have, OK, because moving\nout of this parametric family",
    "start": "4155018",
    "end": "4164810"
  },
  {
    "text": "is actually very\ndifficult for me. So if you think, for\nexample, as an extreme case,",
    "start": "4164810",
    "end": "4170930"
  },
  {
    "text": "the parametric family that I\nhave is basically all PMFs,",
    "start": "4170930",
    "end": "4176580"
  },
  {
    "text": "all of them, right? So that's a stupid\nparametric family. I'm indexed by the\ndistribution itself,",
    "start": "4176580",
    "end": "4181890"
  },
  {
    "text": "but it's still\nfinite dimensional. Then here, I have basically\nno degrees of freedom. There's no way I\ncan actually not",
    "start": "4181890",
    "end": "4188220"
  },
  {
    "text": "be that guy, because this\nis everything I have. And so you don't have\nto really understand",
    "start": "4188220",
    "end": "4194220"
  },
  {
    "text": "how the computation comes\ninto the numbers of dimension and what I mean by dimension\nof this current space.",
    "start": "4194220",
    "end": "4201300"
  },
  {
    "text": "But really, what's important is\nthat as the dimension of theta becomes bigger, I have\nless degrees of freedom",
    "start": "4201300",
    "end": "4209350"
  },
  {
    "text": "to be away from this family. This family becomes big,\nand it's very hard for me to violate this.",
    "start": "4209350",
    "end": "4214989"
  },
  {
    "text": "So it's actually shrinking\nthe number of degrees of freedom of my chi-square. And that's all you\nneed to understand.",
    "start": "4214990",
    "end": "4220490"
  },
  {
    "text": "When d increases, the number of\ndegrees of freedom decreases. And I'd like to you to have an\nidea of why this is somewhat",
    "start": "4220490",
    "end": "4227304"
  },
  {
    "text": "true, and this is\nbasically the picture you should have in mind. ",
    "start": "4227304",
    "end": "4233239"
  },
  {
    "text": "OK. So now once I have done\nthis, I can just construct. So here I need to check. So what is d in the\ncase of the binomial?",
    "start": "4233240",
    "end": "4239178"
  },
  {
    "text": " AUDIENCE: 1. PHILIPPE RIGOLLET: 1, right? It's just a\none-dimensional thing.",
    "start": "4239178",
    "end": "4244980"
  },
  {
    "text": "And for most of\nthe examples we're going to have it's going\nto be one dimensional. So we have this weird thing. We're going to have K\nminus 2 degrees of freedom.",
    "start": "4244980",
    "end": "4251429"
  },
  {
    "text": " So now I have this thing,\nand I have this asymptotic.",
    "start": "4251430",
    "end": "4259640"
  },
  {
    "text": "And then I can just basically\nuse a test that has-- that uses the fact that\nthe asymptotic distribution is this.",
    "start": "4259640",
    "end": "4265110"
  },
  {
    "text": "So I compute my\nquantiles out of this. Again, I made the same mistake. This should be q alpha,\nand this should be q alpha.",
    "start": "4265110",
    "end": "4271489"
  },
  {
    "text": "So that's just the\ntail probability is equal to alpha when I'm\non the right of q alpha.",
    "start": "4271490",
    "end": "4276698"
  },
  {
    "text": "And so those are\nthe tail probability of the appropriate chi-square\nwith the appropriate number of degrees of freedom.",
    "start": "4276699",
    "end": "4282030"
  },
  {
    "text": "And so I can compute p-values,\nand I can do whatever I want. OK? So then I just like [INAUDIBLE]\nmy testing machinery.",
    "start": "4282030",
    "end": "4288510"
  },
  {
    "text": "OK? So now I know how to test if I'm\na binomial distribution or not.",
    "start": "4288510",
    "end": "4294960"
  },
  {
    "text": "Again here, testing if I'm\na binomial distribution is not a simple goodness of fit.",
    "start": "4294960",
    "end": "4300660"
  },
  {
    "text": "It's a composite one\nwhere I can actually-- there's many ways I can\nbe a binomial distribution",
    "start": "4300660",
    "end": "4305910"
  },
  {
    "text": "because there's as\nmany as there is theta. And so I'm actually plugging\nin the theta hat, which is",
    "start": "4305910",
    "end": "4311699"
  },
  {
    "text": "estimated from the data, right? And here, since everything's\nhappening in the asymptotics,",
    "start": "4311700",
    "end": "4317370"
  },
  {
    "text": "I'm not claiming that Tn\nhas a pivotal distribution for finite n. That's actually not true.",
    "start": "4317370",
    "end": "4322890"
  },
  {
    "text": "It's going to depend\nlike crazy on what the actual distribution is. But asymptotically,\nI have a chi-square,",
    "start": "4322890",
    "end": "4328170"
  },
  {
    "text": "which obviously does not\ndepend on anything [INAUDIBLE].. OK?",
    "start": "4328170",
    "end": "4333511"
  },
  {
    "text": "Yeah? AUDIENCE: So in general, for\nthe binomial [INAUDIBLE] trials.",
    "start": "4333511",
    "end": "4339920"
  },
  {
    "text": "But in the general\ncase, the number of-- the size of our PMF is\nthe number of [INAUDIBLE]..",
    "start": "4339920",
    "end": "4346315"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah. AUDIENCE: So let's\nsay that I was also uncertain about what\nK was so that I don't",
    "start": "4346315",
    "end": "4352738"
  },
  {
    "text": "know how big my [INAUDIBLE] is. [INAUDIBLE]",
    "start": "4352738",
    "end": "4368580"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nThat is correct. And thank you for this beautiful\nsegue into my next slide.",
    "start": "4368580",
    "end": "4374670"
  },
  {
    "text": "So we can actually\ndeal with the case not only where it's\ninfinite, which would be the case of Poisson. I mean, nobody\nbelieves I'm going",
    "start": "4374670",
    "end": "4380244"
  },
  {
    "text": "to get an infinite\nnumber of photons in a finite amount of time. But we just don't want to have\nto say there's got to be a--",
    "start": "4380244",
    "end": "4388140"
  },
  {
    "text": "this is the largest\npossible number. We don't want to\nhave to do that. Because if you start doing\nthis and the probabilities become close to 0, things become\ndegenerate and it's an issue.",
    "start": "4388140",
    "end": "4396370"
  },
  {
    "text": "So what we do is we bin. We just bin stuff. OK? And so maybe if I have\na binomial distribution",
    "start": "4396370",
    "end": "4403860"
  },
  {
    "text": "with, say, 200,000\npossible values, then it's actually maybe\nnot the level of precision",
    "start": "4403860",
    "end": "4412082"
  },
  {
    "text": "I want to look at this. Maybe I want to bin. Maybe I want to say,\nlet's just think of all things that\nare between 0 and 100",
    "start": "4412082",
    "end": "4417450"
  },
  {
    "text": "to be the same thing, between\n100 and 200 the same thing, et cetera. And so in fact, I'm\nactually going to bin.",
    "start": "4417450",
    "end": "4424064"
  },
  {
    "text": "I don't even have to think\nabout things that are discrete. I can even think about\ncontinuous cases.",
    "start": "4424064",
    "end": "4429120"
  },
  {
    "text": "And so if I want to test if I\nhave a Gaussian distribution, for example, I can just\napproximate that by some,",
    "start": "4429120",
    "end": "4435420"
  },
  {
    "text": "say, piecewise constant\nfunction that just says that, well, if I have a Gaussian\ndistribution like this,",
    "start": "4435420",
    "end": "4443369"
  },
  {
    "text": "I'm going to bin it like this. And I'm going to say, well,\nthe probability that I'm",
    "start": "4443370",
    "end": "4448650"
  },
  {
    "text": "less than this value is this. The probability that I'm between\nthis and this value is this. The probability I'm\nbetween this and this value",
    "start": "4448650",
    "end": "4454650"
  },
  {
    "text": "is this, and then this\nand then this, right? And now I've turned-- I've discretized, effectively,\nmy Gaussian into a PMF.",
    "start": "4454650",
    "end": "4464239"
  },
  {
    "text": "The value-- this is p1. The value here is p1. This is p2.",
    "start": "4464240",
    "end": "4470460"
  },
  {
    "text": "This is p3. This is p4. This is p5 and p6, right?",
    "start": "4470460",
    "end": "4479150"
  },
  {
    "text": "I have discretized my Gaussian\ninto six possible values. That's just the probability that\nthey fall into a certain bin.",
    "start": "4479150",
    "end": "4486650"
  },
  {
    "text": "And we can do this-- if you don't know what\nK is, just stop at 10. You look at your data quickly\nand you say, well, you know,",
    "start": "4486650",
    "end": "4494360"
  },
  {
    "text": "I have so few of them that are--\nlike I see maybe one 8, one 11,",
    "start": "4494360",
    "end": "4500179"
  },
  {
    "text": "and one 15. Well, everything\nthat's between 8 and 20 I'm just going to\nput it in one bin. Because what else\nare you going to do?",
    "start": "4500180",
    "end": "4507020"
  },
  {
    "text": "I mean, you just don't\nhave enough observations. And so what we do is\nwe just bin everything. So here I'm going to actually\nbe slightly abstract.",
    "start": "4507020",
    "end": "4514460"
  },
  {
    "text": "Our bins are going\nto be intervals Aj. So here-- they don't even\nhave to be intervals. I could go crazy and just\nlike call the bin this guy",
    "start": "4514460",
    "end": "4521929"
  },
  {
    "text": "and this guy, right? That would make no sense,\nbut I could do that.",
    "start": "4521930",
    "end": "4527110"
  },
  {
    "text": "And then I'm-- and of course,\nyou can do whatever you want, but there's going to be some\nconsequences in the conclusions",
    "start": "4527110",
    "end": "4533180"
  },
  {
    "text": "that you can take, right? All you're going\nto be able to say is that my distribution\ndoes not look like it",
    "start": "4533180",
    "end": "4538789"
  },
  {
    "text": "could be binned in this way. That's all you're going\nto be able to say. So if you decide to just\nput all the negative numbers",
    "start": "4538790",
    "end": "4546800"
  },
  {
    "text": "and the positive\nnumbers, then it's going to be very hard\nfor you to distinguish a Gaussian from a random\nvariable that takes values",
    "start": "4546800",
    "end": "4552314"
  },
  {
    "text": "of minus 1 and plus 1 only. You need to just be reasonable.",
    "start": "4552314",
    "end": "4557489"
  },
  {
    "text": "OK? So now I have my pj's\nbecome the probability that my random variable\nfalls into bin j.",
    "start": "4557490",
    "end": "4562590"
  },
  {
    "text": " So that's pj of theta under\nthe parametric distribution.",
    "start": "4562590",
    "end": "4570290"
  },
  {
    "text": "For the true one, whether it's\nparametric or not, I have a pj. And then I have\np hat j, which is",
    "start": "4570290",
    "end": "4575870"
  },
  {
    "text": "the proportion of observations\nthat falls in this bin. All right? So I have a bunch\nof observations.",
    "start": "4575870",
    "end": "4581030"
  },
  {
    "text": "I count how many of\nthem fall in this bin. I divide by n, and that\ntells me what my estimated",
    "start": "4581030",
    "end": "4586130"
  },
  {
    "text": "probability for this bin is. And theta hat, well,\nit's the same as before.",
    "start": "4586130",
    "end": "4591444"
  },
  {
    "text": "If I'm in a\nparametric family, I'm just estimating theta hat,\nmaybe the maximum likelihood estimator, plug it\nin, and estimate",
    "start": "4591444",
    "end": "4597690"
  },
  {
    "text": "those pj's of theta hat. From this, I form my\nchi-square, and I have exactly",
    "start": "4597690",
    "end": "4603390"
  },
  {
    "text": "the same thing as before. So the answer to your\nquestion is, yes, you bin.",
    "start": "4603390",
    "end": "4608680"
  },
  {
    "text": "And it's the answer to\neven more questions. So that's why there\nyou can actually use the chi-square test\nto test for normality.",
    "start": "4608680",
    "end": "4616420"
  },
  {
    "text": "Now here it's going\nto be slightly weaker, because there's only\nan asymptotic theory, whereas Kolmogorov-Smirnov\nand Kolmogorov-Lilliefors work",
    "start": "4616420",
    "end": "4623920"
  },
  {
    "text": "actually even for\nfinite samples. For the chi-square test,\nit's only asymptotic. So you just pretend you actually\nknow what the parameters are.",
    "start": "4623920",
    "end": "4631300"
  },
  {
    "text": "You just stuff them\ninto a theta, a mu hat, and sigma square hat.",
    "start": "4631300",
    "end": "4636670"
  },
  {
    "text": "And you just go to-- you\njust cross your finger that n is large\nenough for everything to have converged by the\ntime you make your decision.",
    "start": "4636670",
    "end": "4644161"
  },
  {
    "text": "OK? And then this is a copy/paste,\nwith the same error actually as the previous slide, where\nyou just build your test based",
    "start": "4644161",
    "end": "4651710"
  },
  {
    "text": "on whether you exceed\nor not some quantile, and you can also\ncompute some p-value.",
    "start": "4651710",
    "end": "4657721"
  },
  {
    "text": "OK? AUDIENCE: The error? PHILIPPE RIGOLLET: I'm sorry? AUDIENCE: What's the error? PHILIPPE RIGOLLET:\nWhat is the error?",
    "start": "4657721",
    "end": "4663100"
  },
  {
    "text": "AUDIENCE: You said [INAUDIBLE]\ncopy/paste [INAUDIBLE].. PHILIPPE RIGOLLET: Oh,\nthe error is that this should be q alpha, right?",
    "start": "4663100",
    "end": "4668520"
  },
  {
    "text": "AUDIENCE: OK. PHILIPPE RIGOLLET: I've\nbeen calling this q alpha. I mean, that's my\npersonal choice, because I don't want to--",
    "start": "4668520",
    "end": "4674500"
  },
  {
    "text": "I only use q alpha. So I only use quantiles where\nalpha is to the right, so.",
    "start": "4674500",
    "end": "4679644"
  },
  {
    "text": "That's what statisticians--\nprobabilists would use this notation. ",
    "start": "4679644",
    "end": "4687041"
  },
  {
    "text": "OK. And so some questions, right? So of course, in\npractice you're going to have some issues\nwhich translate.",
    "start": "4687041",
    "end": "4693650"
  },
  {
    "text": "I say, well, how do you\npick this guy, this K? So I gave you some sort of a-- I mean, the way we\ndiscussed, right?",
    "start": "4693650",
    "end": "4699810"
  },
  {
    "text": "You have 8 and 10 and\n20, then it's ad hoc. And so depending on whether\nyou want to stop K at 20",
    "start": "4699810",
    "end": "4707120"
  },
  {
    "text": "or if you want to bin those\nguys is really up to you. And there's going to\nbe some considerations about the particular\nproblem at hand.",
    "start": "4707120",
    "end": "4712591"
  },
  {
    "text": "I mean, is it\ncoarse-- too coarse for your problem to decide\nthat the observations between 8",
    "start": "4712591",
    "end": "4718070"
  },
  {
    "text": "and 20 are the same? It's really up to you. Maybe that's actually\nmaking a huge difference in terms of what phenomenon\nyou're looking at.",
    "start": "4718070",
    "end": "4725420"
  },
  {
    "text": "The choice of the bins, right? So here there's\nactually some sort of rules, which are\ndon't use only one bin",
    "start": "4725420",
    "end": "4731870"
  },
  {
    "text": "and make sure there's actually--\ndon't use them too small so that there's at least one\nobservation per bin, right?",
    "start": "4731870",
    "end": "4737710"
  },
  {
    "text": "And it's basically\nthe same kind of rules that you would have\nto build a histogram. If you were to build a\nhistogram for your data, you still want to\nmake sure that you",
    "start": "4737710",
    "end": "4743780"
  },
  {
    "text": "bin in an appropriate fashion. OK? And there's a bunch\nof rule of thumbs. Every time you ask\nsomeone, they're",
    "start": "4743780",
    "end": "4749510"
  },
  {
    "text": "going to have a\ndifferent rule of thumb, so just make your own. And then there's the\ncomputation of pj",
    "start": "4749510",
    "end": "4757580"
  },
  {
    "text": "of theta, which might\nbe a bit complicated because, in this\ncase, I would have to integrate the Gaussian\nbetween this number",
    "start": "4757580",
    "end": "4764030"
  },
  {
    "text": "and this number. So for this case, I\ncould just say, well, it's the difference of the CDF\nin that value and that value",
    "start": "4764030",
    "end": "4770150"
  },
  {
    "text": "and then be happy with it. But you can imagine that\nyou have some slightly more crazy distributions. You're going to have\nto somewhat compute",
    "start": "4770150",
    "end": "4776240"
  },
  {
    "text": "some integrals that might be\nunpleasant for you to compute. OK? And in particular, I\nsaid the difference",
    "start": "4776240",
    "end": "4781846"
  },
  {
    "text": "of the PDF between that value\nand that value of-- sorry, the CDF between that value\nand that value, it is true.",
    "start": "4781846",
    "end": "4787722"
  },
  {
    "text": "But it's not like\nyou actually have tables that compute the CDF\nat any value you like, right? You have to sort of--",
    "start": "4787722",
    "end": "4794445"
  },
  {
    "text": "well, there might be\nbut at some degree, but you are going to have\nto use a computer typically to do that.",
    "start": "4794445",
    "end": "4801050"
  },
  {
    "text": "OK? And so for example, you\ncould do the Poisson. If I had time, if I had\nmore than one minute,",
    "start": "4801050",
    "end": "4807489"
  },
  {
    "text": "I would actually do it for you. But it's basically the same. The Poisson, you are going\nto have an infinite tail,",
    "start": "4807489",
    "end": "4812560"
  },
  {
    "text": "and you just say,\nat some point I'm going to cut everything\nthat's larger than some value. All right? So you can play around, right?",
    "start": "4812560",
    "end": "4820727"
  },
  {
    "text": "I say, well, if you have extra\nknowledge about what you expect to see, maybe you can\ncut at a certain number",
    "start": "4820727",
    "end": "4826000"
  },
  {
    "text": "and then just fold all the\nlargest values from K minus 1 to infinity so that\nyou actually have--",
    "start": "4826000",
    "end": "4835630"
  },
  {
    "text": "you have everything\ninto one large bin. OK? That's the entire tail. And that's the way people do\nit in insurance companies,",
    "start": "4835630",
    "end": "4842350"
  },
  {
    "text": "for example. They assume that the number of\naccidents you're going to have is a Poisson distribution. They have to fit it to you.",
    "start": "4842350",
    "end": "4848619"
  },
  {
    "text": "They have to know-- or at least to your pool of\ninsurance of injured people. So they just slice you\ninto what your character--",
    "start": "4848620",
    "end": "4856390"
  },
  {
    "text": "relevant characteristics\nare, and then they want to estimate what the\nPoisson distribution is. And basically, they can\ndo a chi-square test",
    "start": "4856390",
    "end": "4863760"
  },
  {
    "text": "to check if it's indeed\na Poisson distribution. All right. So that will be it for today.",
    "start": "4863760",
    "end": "4870070"
  },
  {
    "text": "And so I'll be-- I'll have your homework-- ",
    "start": "4870070",
    "end": "4875980"
  }
]
[
  {
    "text": "[SQUEAKING] [RUSTLING] [CLICKING]",
    "start": "0",
    "end": "11630"
  },
  {
    "text": "ESTHER DUFLO: So\nlet's get started. I will quickly-- I\nwill just go straight jump in because I'm actually--\nthe end of last lecture.",
    "start": "11630",
    "end": "19199"
  },
  {
    "text": "So imagine we are still Monday. And then I will start with\nthe proper introduction",
    "start": "19200",
    "end": "28040"
  },
  {
    "text": "of what's coming in the\nfuture and the like. So if you remember, the\nformula for the density",
    "start": "28040",
    "end": "35450"
  },
  {
    "text": "for a normal distribution with\nmean mu and variance sigma",
    "start": "35450",
    "end": "41870"
  },
  {
    "text": "squared is this\nformula over there. This is how it looks like. You all know and like it--",
    "start": "41870",
    "end": "50539"
  },
  {
    "text": "bell-shaped,\nsymmetric, thin-tailed. This is for the same mu\nand different variants.",
    "start": "50540",
    "end": "58950"
  },
  {
    "text": "So you can see, of course,\nthat as the variance becomes smaller and smaller, it's\nhigher and higher at the mode.",
    "start": "58950",
    "end": "66080"
  },
  {
    "text": "There is a larger fraction of\nthe area under the curve that",
    "start": "66080",
    "end": "71550"
  },
  {
    "text": "is towards what is both\nthe mode and the mean of this distribution.",
    "start": "71550",
    "end": "77080"
  },
  {
    "text": "And as the variance increases,\nit becomes flatter and flatter. ",
    "start": "77080",
    "end": "83480"
  },
  {
    "text": "That's the standard normal. And very often, as of\ntoday and certainly as",
    "start": "83480",
    "end": "92240"
  },
  {
    "text": "of after spring\nbreak, we will need to know for various reasons what\nis the area under the curve.",
    "start": "92240",
    "end": "100490"
  },
  {
    "text": " What's the probability that we\nare below minus 2 or above 2?",
    "start": "100490",
    "end": "113750"
  },
  {
    "text": "And there is no\nclosed form formula",
    "start": "113750",
    "end": "118970"
  },
  {
    "text": "for the integral of the PDF. But a number of people\nhave worked very hard",
    "start": "118970",
    "end": "127460"
  },
  {
    "text": "on approximating it for us. So that's roughly\nhow it looks like,",
    "start": "127460",
    "end": "133020"
  },
  {
    "text": "which is you have\nabout 68% of the area",
    "start": "133020",
    "end": "140120"
  },
  {
    "text": "under the curve is\nbetween minus 1 and 1,",
    "start": "140120",
    "end": "145200"
  },
  {
    "text": "95% in between minus 2 and 2-- something we make a lot\nof use of in what follows.",
    "start": "145200",
    "end": "153990"
  },
  {
    "text": "And then 97.7% is--",
    "start": "153990",
    "end": "160350"
  },
  {
    "text": "sorry, did I miss-- I misled you? Start again.",
    "start": "160350",
    "end": "165480"
  },
  {
    "text": "AUDIENCE: I think it's\nmislabeled a little bit. ESTHER DUFLO: Yeah,\nit's just too high, no? AUDIENCE: No, no, no.",
    "start": "165480",
    "end": "170760"
  },
  {
    "text": "ESTHER DUFLO: So 95-- sorry, yeah, it's mislabeled. My bad. AUDIENCE: It's mislabelled. ESTHER DUFLO: OK. So the little ones are correct.",
    "start": "170760",
    "end": "177255"
  },
  {
    "text": " 2.1% is in this quadrant.",
    "start": "177255",
    "end": "183630"
  },
  {
    "text": "2.1% plus 2.1% is 4.2%, so that\nmeans whatever is left is 90--",
    "start": "183630",
    "end": "191820"
  },
  {
    "text": "it's those ones\nthat are mislabeled. My bad. OK, I will have to fix\nthat for posterity.",
    "start": "191820",
    "end": "198480"
  },
  {
    "text": "These ones are correct. 2.1% is below minus 2. 2.1% is above minus 2.",
    "start": "198480",
    "end": "204360"
  },
  {
    "text": "13.6% is between minus 2 and 1. 13.6% is between 1 and 2.",
    "start": "204360",
    "end": "209700"
  },
  {
    "text": "13.4% is between minus 1 and 0. The 34.1%-- between 0 and 1.",
    "start": "209700",
    "end": "217590"
  },
  {
    "text": "So, in general, if you wanted to\nknow what fraction of the curve",
    "start": "217590",
    "end": "224550"
  },
  {
    "text": "is-- what fraction of the\narea under the curve is below any kind of\nnumber, you use these tables",
    "start": "224550",
    "end": "231209"
  },
  {
    "text": "that I've distributed along. So I've distributed all of\nthem, so I don't have one.",
    "start": "231210",
    "end": "236850"
  },
  {
    "text": "But suppose that\nyou wanted to know, for example, the probability\nthat z is less than minus 1.23?",
    "start": "236850",
    "end": "248489"
  },
  {
    "text": "You look at your tables. I think there is a bunch left.",
    "start": "248490",
    "end": "253650"
  },
  {
    "text": "I have one and\nthere is a bunch-- if someone doesn't have,\nthere is a couple left here. ",
    "start": "253650",
    "end": "261859"
  },
  {
    "text": "OK, so to use these tables,\nyou go down the left column",
    "start": "261860",
    "end": "267500"
  },
  {
    "text": "to minus 1.2 then you move up\nthe top row to 0.03 and that",
    "start": "267500",
    "end": "281060"
  },
  {
    "text": "tells you that the probability\nthat z is less than minus 1.23 is 0.109 exactly you agree\nthat's wrong actually 0.10.109",
    "start": "281060",
    "end": "300960"
  },
  {
    "text": "now suppose that you wanted\nto know the probability that",
    "start": "300960",
    "end": "306720"
  },
  {
    "text": "your random variable is\nabove minus point minus 1.68.",
    "start": "306720",
    "end": "315600"
  },
  {
    "text": "What would you do? AUDIENCE: 1 minus the value\nyou find in this table, ESTHER DUFLO: Exactly.",
    "start": "315600",
    "end": "320970"
  },
  {
    "text": "You find 1 minus the value\nyou find in the table for. ",
    "start": "320970",
    "end": "328199"
  },
  {
    "text": "So what I did it-- I wanted 1 greater than 1.68,\n1 minus p of z minus 1 is 8,",
    "start": "328200",
    "end": "338522"
  },
  {
    "text": "and you go down. Suppose that you wanted\npositive numbers, and I had not give you\nthe positive numbers.",
    "start": "338523",
    "end": "344229"
  },
  {
    "text": "So, in fact, that\nhappens rarely. But what happens\nfrequently is you want a negative\nnumber on the table",
    "start": "344230",
    "end": "349470"
  },
  {
    "text": "only gives you the\npositive number. What would you do? So suppose in this case, where\nI gave you the positive number",
    "start": "349470",
    "end": "356250"
  },
  {
    "text": "and I've not given you\nthe positive numbers-- ",
    "start": "356250",
    "end": "361789"
  },
  {
    "text": "suppose you want p\nsmaller than 1.45, and you only have the\nnumber with the size where",
    "start": "361790",
    "end": "367480"
  },
  {
    "text": "the z is negative. Yeah? AUDIENCE: So it's\nsymmetrical so that you've got [INAUDIBLE] probability\nthat is greater than 1.45?",
    "start": "367480",
    "end": "376220"
  },
  {
    "text": "ESTHER DUFLO: Exactly, which\nis 1 minus the probability that is smaller than 1.145, and\nthen you would be in business.",
    "start": "376220",
    "end": "384560"
  },
  {
    "text": "What if you wanted\nthe probability that z is in between minus\n1.23 and 1.45?",
    "start": "384560",
    "end": "393745"
  },
  {
    "text": "You take the first one that we\nalready calculated minus that. Now what if you didn't\nhave a standard normal?",
    "start": "393745",
    "end": "402280"
  },
  {
    "text": "You would first\nstandardize your variable, and then you would\nbe in business. Now in reality,\nwhat could you do",
    "start": "402280",
    "end": "407800"
  },
  {
    "text": "if you were not in a class\nwith no access to computers?",
    "start": "407800",
    "end": "414250"
  },
  {
    "text": "You could use the\npnorm command in R,",
    "start": "414250",
    "end": "420340"
  },
  {
    "text": "which is going to tell you\nwhat the probability that z is greater--",
    "start": "420340",
    "end": "425680"
  },
  {
    "text": "z is smaller than, say, 1.96. If you ask for the\nlower tail too,",
    "start": "425680",
    "end": "432460"
  },
  {
    "text": "which, this is asking\nfor the lower tail, or it can give you\nthe probability that z is greater than 1.96\nif, in fact, you",
    "start": "432460",
    "end": "440890"
  },
  {
    "text": "are writing lower-tail\nfalse and then is looking on the other end. So the probability that\nz is greater than 1.96",
    "start": "440890",
    "end": "447460"
  },
  {
    "text": "is quite high. The property that z is\nsmaller than greater than 1.96",
    "start": "447460",
    "end": "452780"
  },
  {
    "text": "is much smaller. So here, I put a little table\nof useful variable related",
    "start": "452780",
    "end": "462319"
  },
  {
    "text": "to the normal distribution. So the unknown variable\ngenerates random numbers",
    "start": "462320",
    "end": "468200"
  },
  {
    "text": "from normal distribution. If you didn't want to go\nthrough the motion of doing",
    "start": "468200",
    "end": "474380"
  },
  {
    "text": "first a uniform and then\nusing the inverse of the PDF using the qnorm function--",
    "start": "474380",
    "end": "480560"
  },
  {
    "text": "dnorm gives you the\nprobability density function. So, for example,\ndnorm of 0, 0, 5",
    "start": "480560",
    "end": "487280"
  },
  {
    "text": "gives you the\ndensity, the height of the normal with mean 0\nand standard deviation 0.5.",
    "start": "487280",
    "end": "492410"
  },
  {
    "text": "pnorm gives you the area under\nthe standard normal curve. So that's what\nyou're going to use",
    "start": "492410",
    "end": "498470"
  },
  {
    "text": "very frequently, if you\nwant to down the line, when it's become useful.",
    "start": "498470",
    "end": "504710"
  },
  {
    "text": "And qnorm is the\ninverse of pnorm. So this is what you\nwould use if you wanted",
    "start": "504710",
    "end": "510980"
  },
  {
    "text": "to generate a random\nobservation drawn",
    "start": "510980",
    "end": "516020"
  },
  {
    "text": "from a random\ndistribution starting with a uniform distribution. You would draw from a uniform,\nand you use the qnorm function.",
    "start": "516020",
    "end": "522925"
  },
  {
    "text": "I have a code for\nthat, actually, at the end of the text. I'm going to spare that.",
    "start": "522925",
    "end": "528800"
  },
  {
    "text": "I just want you to see\nhow we use the pnorm. So this happens to be for\na normal distribution that",
    "start": "528800",
    "end": "538550"
  },
  {
    "text": "has mean 2 and\nstandard deviation 0.5. Then the inputs are\nwhat we have below.",
    "start": "538550",
    "end": "544010"
  },
  {
    "text": "Probability that\nis less than x1-- so you set your inputs. Then you ask properties\nthat it's less than x1,",
    "start": "544010",
    "end": "550430"
  },
  {
    "text": "probability that it's between\nx2 and x3, probability that it's greater than x3. You will need lower-tail false.",
    "start": "550430",
    "end": "556820"
  },
  {
    "text": "Lower-tail true is\nthe default, so you don't need to specify it. And that's the result you are\ngetting with these numbers--",
    "start": "556820",
    "end": "565460"
  },
  {
    "text": "the probability that\nit's less than x1 is 0.25 doesn't-- the\nresult don't matter. But if you write\nthe code like that,",
    "start": "565460",
    "end": "573620"
  },
  {
    "text": "it's going to give you\nthis kind of results. Yeah?",
    "start": "573620",
    "end": "578700"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nthe defaults? ESTHER DUFLO: So lower.tail=TRUE\ngives you what is to the left--",
    "start": "578700",
    "end": "585980"
  },
  {
    "text": "the area to the left of it. So its the probability that z\nis smaller than the threshold",
    "start": "585980",
    "end": "591180"
  },
  {
    "text": "you put. lower.tail-- so if you\ndon't specify, by default, its lower tail equal to.",
    "start": "591180",
    "end": "597020"
  },
  {
    "text": "Lower tail equal\nfalse-- it's going to give you the\nprobability that z is greater than this number,\nso 1 minus the probability",
    "start": "597020",
    "end": "606019"
  },
  {
    "text": "that it's smaller. So in principle, you could-- I be very economical and\nonly give you the lower tail,",
    "start": "606020",
    "end": "614840"
  },
  {
    "text": "like a table, and you\nwould figure it out. In principle, it\ncould only accept to give you the answer\nfor positive numbers,",
    "start": "614840",
    "end": "620720"
  },
  {
    "text": "and you could calculate them. But, in practice,\nvery kindly, it will give you what you\nneed in just one comment",
    "start": "620720",
    "end": "626900"
  },
  {
    "text": "by putting the right-- so, for example, here, you\nhave the lower tail false,",
    "start": "626900",
    "end": "632630"
  },
  {
    "text": "we get the probability\nthat z is greater than x4. Here, we didn't specify\nanything at the top,",
    "start": "632630",
    "end": "638930"
  },
  {
    "text": "so it's lower tail true. It gives you the\nprobability that the number is smaller than the threshold.",
    "start": "638930",
    "end": "645389"
  },
  {
    "text": "So it's pretty\nstraightforward to use.  I think I'm going to skip\nthe last thing because we",
    "start": "645390",
    "end": "653120"
  },
  {
    "text": "went over this many times. But the slides will stay here. It's just to tell you\nthat in principle, you",
    "start": "653120",
    "end": "660380"
  },
  {
    "text": "could use the inverse\nsampling method to sample from a normal\ndistribution in R. So you",
    "start": "660380",
    "end": "665930"
  },
  {
    "text": "would take a uniform\ndistribution, and then you use\nthe qnorm function,",
    "start": "665930",
    "end": "673610"
  },
  {
    "text": "which is the inverse\nquantile function. And you would get something. In practice, if you sample\nfrom a normal distribution,",
    "start": "673610",
    "end": "681769"
  },
  {
    "text": "I think the algorithm they\nuse is somewhat different. And it is much faster. It takes much less\ntime to do it.",
    "start": "681770",
    "end": "689060"
  },
  {
    "text": "The way they manage to\ndo it is much faster. So, in practice, the algorithm\nthat is used is different.",
    "start": "689060",
    "end": "695630"
  },
  {
    "text": "But in principle,\nagain, what we discussed still apply, and\nyou could sample",
    "start": "695630",
    "end": "704510"
  },
  {
    "text": "from your normal distribution\nusing the qnorm function that's the inverse quantile function.",
    "start": "704510",
    "end": "710089"
  },
  {
    "text": "I think I'm done discussing\nnormal distribution for the time being, so we\ncan leave the stage to Sara.",
    "start": "710090",
    "end": "716618"
  },
  {
    "text": " SARA ELLISON: OK,\nso as far the--",
    "start": "716618",
    "end": "724735"
  },
  {
    "text": "as I said, the theoretical\nquestions on the exam are going to be similar\nto the practice problems",
    "start": "724736",
    "end": "733700"
  },
  {
    "text": "that I've made available. I don't have any\npractice problems to make available for the\nsort of practical data skills",
    "start": "733700",
    "end": "739220"
  },
  {
    "text": "questions. So I wanted to give you\nsome idea of what to expect. Obviously, these are\njust kind of very loose",
    "start": "739220",
    "end": "746870"
  },
  {
    "text": "and informal descriptions\nof what kinds of questions that we might\nthink about asking.",
    "start": "746870",
    "end": "754190"
  },
  {
    "text": "So one thing that you've seen\na lot so far this semester, one practical skill\nthat you've developed,",
    "start": "754190",
    "end": "759920"
  },
  {
    "text": "is creating histograms. So you should know\nwhat a histogram is. And you've always sort of\nused R to create histograms,",
    "start": "759920",
    "end": "765920"
  },
  {
    "text": "but you can easily\ndo it by hand. So perhaps you'll be asked\nto create a histogram by hand",
    "start": "765920",
    "end": "771840"
  },
  {
    "text": "if we give you a table of data.  We've also talked a lot about\ngenerating simulated datasets",
    "start": "771840",
    "end": "780300"
  },
  {
    "text": "from some particular\ndistribution. So be aware of how to do that.",
    "start": "780300",
    "end": "785399"
  },
  {
    "text": " We talked about web\nscraping, and you had that sort of\nsubstantial question",
    "start": "785400",
    "end": "793560"
  },
  {
    "text": "on the problem set asking\nyou about web scraping. We're not going to ask very\ndetailed questions about web",
    "start": "793560",
    "end": "800460"
  },
  {
    "text": "scraping, but you\nshould know, generally, what it is, how\nto do it, maybe be",
    "start": "800460",
    "end": "805890"
  },
  {
    "text": "able to give some\nexamples of datasets that you might obtain through\nweb scraping, et cetera.",
    "start": "805890",
    "end": "812850"
  },
  {
    "text": "So this is the kind of flavor\nof the practical data skills",
    "start": "812850",
    "end": "822120"
  },
  {
    "text": "questions that you might see. ",
    "start": "822120",
    "end": "827190"
  },
  {
    "text": "Is that OK? Any questions, clarifications? Nope. ",
    "start": "827190",
    "end": "834410"
  },
  {
    "text": "OK, so on to the sample mean. ",
    "start": "834410",
    "end": "841260"
  },
  {
    "text": "So I'm trying to\nremember where I left off before [Esther's lecture\non special distributions.",
    "start": "841260",
    "end": "848510"
  },
  {
    "text": " Certainly, we were talking about\nfunctions of random variables,",
    "start": "848510",
    "end": "854480"
  },
  {
    "text": "and I think that was the\nmain topic of conversation. And, oh, maybe it was the--",
    "start": "854480",
    "end": "860818"
  },
  {
    "text": "ESTHER DUFLO: [INAUDIBLE] SARA ELLISON: Oh,\nyou weren't there. Yeah, in any case, we were\ntalking about functions of random variables.",
    "start": "860818",
    "end": "866270"
  },
  {
    "text": "And today, I want to talk\nabout a very special function of random variables that\nwe will encounter a lot.",
    "start": "866270",
    "end": "874519"
  },
  {
    "text": "It's super useful, and\nyou probably already have a notion of why\nit might be useful. But we'll go through\nthat in detail.",
    "start": "874520",
    "end": "881550"
  },
  {
    "text": "But first, we want to\ndefine it, and we want to talk about how it behaves.",
    "start": "881550",
    "end": "888589"
  },
  {
    "text": "And this special function\nis called the sample mean. So the sample mean is\nthe arithmetic average",
    "start": "888590",
    "end": "894380"
  },
  {
    "text": "of n random variables from\na random sample of size n. So we, at least\ninitially, are always",
    "start": "894380",
    "end": "903510"
  },
  {
    "text": "going to be talking about\nsample means from i.i.d. Random samples.",
    "start": "903510",
    "end": "908940"
  },
  {
    "text": "You can define a sample mean\nfrom a random sample that's not",
    "start": "908940",
    "end": "914070"
  },
  {
    "text": "i.i.d.-- no, that's not\nIndependent Identically Distributed random variables. For now, we'll just\nfocus on the i.i.d.",
    "start": "914070",
    "end": "921930"
  },
  {
    "text": "Case. I just want to let you know\nthat this notion of random--",
    "start": "921930",
    "end": "927450"
  },
  {
    "text": "or of sample mean can exist\noutside of the realm of i.i.d. data sets.",
    "start": "927450",
    "end": "934500"
  },
  {
    "text": "And the notation that we use\nto denote the sample mean",
    "start": "934500",
    "end": "941190"
  },
  {
    "text": "is an X with a bar on top of it. And sometimes, I\nuse an n subscript",
    "start": "941190",
    "end": "946800"
  },
  {
    "text": "to indicate how many\ndifferent random variables are in this random sample that we\nuse to compute the sample mean.",
    "start": "946800",
    "end": "954209"
  },
  {
    "text": " We also call-- so\nright now, I've",
    "start": "954210",
    "end": "962090"
  },
  {
    "text": "written this as a function\nof random variables. But these random\nvariables could have,",
    "start": "962090",
    "end": "968540"
  },
  {
    "text": "instead of dealing with\nthe mathematical construct of a random variable,\nthey could each have",
    "start": "968540",
    "end": "974630"
  },
  {
    "text": "a realization or\na value that they take on associated with them.",
    "start": "974630",
    "end": "981980"
  },
  {
    "text": "And we also call the\narithmetic average of the realizations of\nthose n random variables",
    "start": "981980",
    "end": "987560"
  },
  {
    "text": "the sample mean. So it sometimes is\na little confusing because we use the\nsame terminology",
    "start": "987560",
    "end": "994340"
  },
  {
    "text": "to discuss the function\nof random variables and the function\nof the realizations",
    "start": "994340",
    "end": "999797"
  },
  {
    "text": "of those random variables. We don't distinguish\nthat in our terminology.",
    "start": "999797",
    "end": "1004870"
  },
  {
    "text": "And we actually don't\ndistinguish it in the notation either often. But it's a distinction you\nshould keep in your mind",
    "start": "1004870",
    "end": "1012430"
  },
  {
    "text": "because you have\nto be able to think of a sample mean in both ways. You have to be\nable to think of it as a function of\nrandom variables",
    "start": "1012430",
    "end": "1018620"
  },
  {
    "text": "and as a function\nof the realizations of random variables.",
    "start": "1018620",
    "end": "1024480"
  },
  {
    "text": "OK, so arithmetic average\nof the n random variables or realizations from\na random sample--",
    "start": "1024480",
    "end": "1030150"
  },
  {
    "text": "why would such a\nfunction be useful? So we've got this random sample. We've got n i.i.d.",
    "start": "1030150",
    "end": "1037020"
  },
  {
    "text": "Random variables from\nsome distribution. Why would we want to add\nthem up and divide by n?",
    "start": "1037020",
    "end": "1042660"
  },
  {
    "text": " What do you think? ",
    "start": "1042660",
    "end": "1052860"
  },
  {
    "text": "Do you have-- your hand wants\nto go up, but it hasn't quite-- AUDIENCE: [INAUDIBLE]",
    "start": "1052860",
    "end": "1060380"
  },
  {
    "text": " SARA ELLISON: Yes, in fact-- so what happens if\nwe have an i.i.d.",
    "start": "1060380",
    "end": "1066340"
  },
  {
    "text": "Random sample from\nsome distribution but we don't know everything\nabout the distribution?",
    "start": "1066340",
    "end": "1071680"
  },
  {
    "text": "Maybe we don't\nknow, for instance, what the mean of\nthat distribution is. Well, if we have a random\nsample from that distribution,",
    "start": "1071680",
    "end": "1079870"
  },
  {
    "text": "and we calculate the sample\nmean of that random sample,",
    "start": "1079870",
    "end": "1087020"
  },
  {
    "text": "then maybe that sample\nmean can tell us something about the underlying\ndistribution itself.",
    "start": "1087020",
    "end": "1094440"
  },
  {
    "text": "That's the entire idea\nbehind estimation. I'm going to hammer away at that\nover the next several minutes",
    "start": "1094440",
    "end": "1101340"
  },
  {
    "text": "in examples. But that's why\nthis quantity, why this particular function of\nrandom variables is important.",
    "start": "1101340",
    "end": "1108990"
  },
  {
    "text": " OK, so emphasizing\none more time,",
    "start": "1108990",
    "end": "1116100"
  },
  {
    "text": "the X's are random variables. So X bar is also\na random variable since it's a function\nof random variables.",
    "start": "1116100",
    "end": "1122350"
  },
  {
    "text": "So let's figure out\nhow it's distributed. So a random variable--\nit has a distribution. Let's figure out what it is.",
    "start": "1122350",
    "end": "1128640"
  },
  {
    "text": "We're not going to be able\nto say precisely what it is, but we're going to be\nable-- at least, unless we",
    "start": "1128640",
    "end": "1134070"
  },
  {
    "text": "put more structure\non the random sample, but we can certainly say\nthings about its distribution.",
    "start": "1134070",
    "end": "1140039"
  },
  {
    "text": " Oh, I should just\nsay note that if we",
    "start": "1140040",
    "end": "1146930"
  },
  {
    "text": "knew how the X's\nwere distributed, we knew that they\nwere all coming from a uniform distribution\nor a normal distribution",
    "start": "1146930",
    "end": "1155150"
  },
  {
    "text": "or a Poisson\ndistribution or whatever, we might be able\nto use something like the n version of\nthe convolution formula.",
    "start": "1155150",
    "end": "1163610"
  },
  {
    "text": "So it's not exactly a\nconvolution because it's not just the sum of the X's. It's the sum of the\nX's divided by n.",
    "start": "1163610",
    "end": "1169530"
  },
  {
    "text": "But it's similar\nto a convolution. For now, let's just try to--",
    "start": "1169530",
    "end": "1175820"
  },
  {
    "text": "instead of choosing a specific\ndistribution for these X's, let's just say that they're\nindependent and identically",
    "start": "1175820",
    "end": "1183200"
  },
  {
    "text": "distributed and\nsee how far we can get discussing the\ndistribution of X bar with just that information.",
    "start": "1183200",
    "end": "1189140"
  },
  {
    "text": " OK, so let's see if we can\ncalculate the expectation",
    "start": "1189140",
    "end": "1196990"
  },
  {
    "text": "of this function X bar. Well, the expectation of\nX bar is just equal to--",
    "start": "1196990",
    "end": "1203200"
  },
  {
    "text": " I just plugged in the\ndefinition of X bar.",
    "start": "1203200",
    "end": "1210220"
  },
  {
    "text": "And then I can write the\nexpectation of 1 over n times the sum of the X's.",
    "start": "1210220",
    "end": "1215830"
  },
  {
    "text": "I can write that as 1\nover n times the sum of the expectations of the X's.",
    "start": "1215830",
    "end": "1222340"
  },
  {
    "text": "We know that in\nproperties of expectation. We saw that we can do\nthat with expectation.",
    "start": "1222340",
    "end": "1230000"
  },
  {
    "text": "And then I just changed\nthe notation at the end from expectation of X to mu,\nwhich is the notation that we",
    "start": "1230000",
    "end": "1241340"
  },
  {
    "text": "often use for expectation. So I just changed it, and\nthen we're adding up-- we're adding up mu n\ntimes and dividing by n,",
    "start": "1241340",
    "end": "1248990"
  },
  {
    "text": "so it's just equal to mu. ",
    "start": "1248990",
    "end": "1256210"
  },
  {
    "text": "We can do a similar\ncalculation with variance. So let's figure out what the\nvariance of the sample mean is.",
    "start": "1256210",
    "end": "1264280"
  },
  {
    "text": "Well, it's just equal\nto the variance of-- we plug in the definition again. We use properties of variance\nto bring the 1 over n out",
    "start": "1264280",
    "end": "1274070"
  },
  {
    "text": "in front. But, of course, it\ngets squared because of the properties of variance.",
    "start": "1274070",
    "end": "1279120"
  },
  {
    "text": "And then I changed the\nnotation to sigma squared. And, in the end, we get\nsigma squared over n",
    "start": "1279120",
    "end": "1285750"
  },
  {
    "text": "is the variance of\nthe sample mean. So mu is the expectation of\nthe X's-- each of the X's.",
    "start": "1285750",
    "end": "1295430"
  },
  {
    "text": "Sigma squared is the\nvariance of each of the X's. We take a bunch of X's, add\nthem together, divide by n.",
    "start": "1295430",
    "end": "1303230"
  },
  {
    "text": "That new random variable has the\nsame meaning as the individual",
    "start": "1303230",
    "end": "1308270"
  },
  {
    "text": "X's. And its variance is\nthat variance of the X's",
    "start": "1308270",
    "end": "1313280"
  },
  {
    "text": "divided by-- yes? AUDIENCE: Why isn't it\ndivided by n squared? SARA ELLISON: Oh, because\nwe're adding up n of these,",
    "start": "1313280",
    "end": "1320889"
  },
  {
    "text": "we've got n of these\ndivided, and then that's divided by n squared. ",
    "start": "1320890",
    "end": "1332470"
  },
  {
    "text": "So one note-- it's not\nnecessarily important in this calculation, but sort of\ncould be important later--",
    "start": "1332470",
    "end": "1339700"
  },
  {
    "text": "we use independence in\nthe variance calculation to go from the variance of\nthe sum of random variables",
    "start": "1339700",
    "end": "1347260"
  },
  {
    "text": "to the sum of the variances. We needed independence of\nthese random variables. You guys remember that from\nproperties of variance?",
    "start": "1347260",
    "end": "1354520"
  },
  {
    "text": "We didn't actually need it in\nthe expectation calculation. So that can be a\nuseful thing to note.",
    "start": "1354520",
    "end": "1364000"
  },
  {
    "text": " Now what do these\ncalculations tell us?",
    "start": "1364000",
    "end": "1371380"
  },
  {
    "text": "So we've got this sort of\nrandom sample of variables that we've taken from--\nwe haven't specified",
    "start": "1371380",
    "end": "1377530"
  },
  {
    "text": "what distribution they're from--\nfrom any old distribution. We've got a collection of\nrandom variables called",
    "start": "1377530",
    "end": "1383200"
  },
  {
    "text": "a random sample. We add them up. We divide by n. That creates a new random\nvariable called X bar.",
    "start": "1383200",
    "end": "1389830"
  },
  {
    "text": "And we know that X\nbar has the same mean as all of the underlying\nrandom variables",
    "start": "1389830",
    "end": "1398740"
  },
  {
    "text": "that we use to calculate it. And its variance is that\nvariance divided by n.",
    "start": "1398740",
    "end": "1404170"
  },
  {
    "text": "So basically, we've got-- take any old\ndistribution or even",
    "start": "1404170",
    "end": "1413860"
  },
  {
    "text": "a discrete distribution instead\nof a continuous distribution. We get a whole bunch\nof realizations",
    "start": "1413860",
    "end": "1421000"
  },
  {
    "text": "from these distributions, a\nwhole bunch of realizations, and then we compute something\ncalled the sample mean.",
    "start": "1421000",
    "end": "1428690"
  },
  {
    "text": "We haven't said what the\nshape of the distribution of the sample mean is\ngoing to look like.",
    "start": "1428690",
    "end": "1434060"
  },
  {
    "text": "But we know that\nthe sample mean is going to have the same mean as\nthe underlying distribution,",
    "start": "1434060",
    "end": "1440870"
  },
  {
    "text": "but its distribution\nis going to be more concentrated\nbecause its variance is",
    "start": "1440870",
    "end": "1446060"
  },
  {
    "text": "sigma squared over n. ",
    "start": "1446060",
    "end": "1454020"
  },
  {
    "text": "AUDIENCE: Wait,\nI've got a question. ESTHER DUFLO: Yes. AUDIENCE: Can you go back? SARA ELLISON: Yep.",
    "start": "1454020",
    "end": "1459067"
  },
  {
    "text": "AUDIENCE: So maybe\nI'm getting hung up on the difference between\nthe actual variables and the realizations,\nbut it seems",
    "start": "1459067",
    "end": "1464077"
  },
  {
    "text": "like you're averaging means. It feels like you're missing--",
    "start": "1464077",
    "end": "1469330"
  },
  {
    "text": "are the X's and i's\nin this equation also sets of random\nvariables or are they--",
    "start": "1469330",
    "end": "1475870"
  },
  {
    "text": "SARA ELLISON: Each Xi\nis a random variable. So we have-- so this summation--",
    "start": "1475870",
    "end": "1481480"
  },
  {
    "text": "I've left off all of the\nsubscripts on the summations. But that summation\nis i equals 1 to n.",
    "start": "1481480",
    "end": "1490070"
  },
  {
    "text": "So we have n random variables. And so we have a set\nof n random variables.",
    "start": "1490070",
    "end": "1497480"
  },
  {
    "text": "And what we're doing\nis we're asking if you consider this\nfunction of random variables,",
    "start": "1497480",
    "end": "1505130"
  },
  {
    "text": "as I've specified here,\nhow is this function of random variables going to\nbe distributed if the X's have",
    "start": "1505130",
    "end": "1512810"
  },
  {
    "text": "mean mu and variance\nsigma squared? AUDIENCE: I guess\nwhere I'm hung up is if those random\nvariables are--",
    "start": "1512810",
    "end": "1519957"
  },
  {
    "text": "[INAUDIBLE] you're calling\na random variables also a distribution, and if they're\nnot the same distribution--",
    "start": "1519957",
    "end": "1526410"
  },
  {
    "text": "SARA ELLISON: Oh, I'm\nassuming that everything has-- they're independent and\nidentically distributed, yes.",
    "start": "1526410",
    "end": "1532529"
  },
  {
    "text": "No, I'm glad you clarified that. So yes, we don't need\nto necessarily assume",
    "start": "1532530",
    "end": "1540570"
  },
  {
    "text": "that when we define\nwhat the sample mean is, but here, we're assuming it.",
    "start": "1540570",
    "end": "1546080"
  },
  {
    "text": "AUDIENCE: Here, mu will be\nthe same across all random? SARA ELLISON: Precisely. Precisely.",
    "start": "1546080",
    "end": "1551820"
  },
  {
    "text": "Yeah, absolutely. ",
    "start": "1551820",
    "end": "1561440"
  },
  {
    "text": "OK, so we've got this\nthing called a sample mean, and we've talked a little bit\nabout how it's distributed.",
    "start": "1561440",
    "end": "1566720"
  },
  {
    "text": "And we've even talked in\nkind of an informal way about how it might be useful. ",
    "start": "1566720",
    "end": "1574100"
  },
  {
    "text": "But there's a lot more to\nsay about the sample mean. And in particular, one of\nthe most important and useful",
    "start": "1574100",
    "end": "1581570"
  },
  {
    "text": "results in all of probability,\nknown as the central limit theorem, deals with the\ndistribution of the sample",
    "start": "1581570",
    "end": "1588080"
  },
  {
    "text": "mean. And it really serves as\nthe basis for statistics.",
    "start": "1588080",
    "end": "1594930"
  },
  {
    "text": "So let X sub 1\nthrough Xn of n form a random sample of size n from\na distribution with finite mean",
    "start": "1594930",
    "end": "1603030"
  },
  {
    "text": "and variance. So actually, let's\npause for just a second. I have one more response\nto your earlier question",
    "start": "1603030",
    "end": "1610800"
  },
  {
    "text": "that might be somewhat helpful. So remember, I made\nthis comment-- note",
    "start": "1610800",
    "end": "1618029"
  },
  {
    "text": "that we used independence in the\nvariance calculation down here. But we didn't use\nindependence here.",
    "start": "1618030",
    "end": "1624299"
  },
  {
    "text": "So you were asking about\nidentically distributed, but, in fact, this is true--",
    "start": "1624300",
    "end": "1629610"
  },
  {
    "text": "this result still holds if\nthe random variables are not",
    "start": "1629610",
    "end": "1636210"
  },
  {
    "text": "independent. So I mean, that\ntells you we're sort of maintaining this\nassumption of independence",
    "start": "1636210",
    "end": "1641950"
  },
  {
    "text": "in an identically distributed,\nbut some of these results hold even if that's not\ntrue, and that's [INAUDIBLE]..",
    "start": "1641950",
    "end": "1648030"
  },
  {
    "text": "AUDIENCE: They're [INAUDIBLE]\ninstead of i.i.d.? SARA ELLISON: Exactly. Yep. OK, sorry-- back to the\ncentral limit theorem.",
    "start": "1648030",
    "end": "1654210"
  },
  {
    "text": "OK, so let the X1 to Xn form\na random sample of size n from a distribution\nwith finite mean",
    "start": "1654210",
    "end": "1661059"
  },
  {
    "text": "and variance-- so, in\nother words, i.i.d. Random variables. Then, for any fixed\nnumber, this is true.",
    "start": "1661060",
    "end": "1670090"
  },
  {
    "text": "So let's unpack this. What does this mean? Well, in the middle here is\nthe sample mean, this X bar.",
    "start": "1670090",
    "end": "1679090"
  },
  {
    "text": " Remember, we just calculated\nwhat the mean of the sample",
    "start": "1679090",
    "end": "1684670"
  },
  {
    "text": "mean is, and we just calculated\nwhat the variance of the sample mean is. And what have I done here?",
    "start": "1684670",
    "end": "1690700"
  },
  {
    "text": "I've subtracted off the\nmean of the sample mean, mu, and I've divided by the\nsquare root of the variance",
    "start": "1690700",
    "end": "1699039"
  },
  {
    "text": "of the sample mean. So when I divided by sigma over\nsquare root of sigma squared",
    "start": "1699040",
    "end": "1706150"
  },
  {
    "text": "over n, then sigma became\nn or sigma-- sorry, sigma squared became\nsigma, n became root n,",
    "start": "1706150",
    "end": "1713710"
  },
  {
    "text": "and the root n went\nto the numerator instead of the denominator. But that's all I've done here.",
    "start": "1713710",
    "end": "1719440"
  },
  {
    "text": "I've subtracted off the\nmean of the sample mean, and I've divided by the\nsquare root of its variance.",
    "start": "1719440",
    "end": "1725870"
  },
  {
    "text": "So what did Esther say\nlast time about sort",
    "start": "1725870",
    "end": "1732130"
  },
  {
    "text": "of what results from doing\nthis to a random variable?",
    "start": "1732130",
    "end": "1738150"
  },
  {
    "text": "It's called standardization. You subtract off the mean. You divide by the square\nroot of its variance.",
    "start": "1738150",
    "end": "1744150"
  },
  {
    "text": "And you have a random variable\nthat has 0 mean and variance 1.",
    "start": "1744150",
    "end": "1749540"
  },
  {
    "text": "So what I've done-- I've simply taken the sample\nmean, and I've standardized it.",
    "start": "1749540",
    "end": "1756980"
  },
  {
    "text": "So here is something like the\nsample mean but with mean 0",
    "start": "1756980",
    "end": "1762320"
  },
  {
    "text": "and variance 1. And then this probability\nstatement here,",
    "start": "1762320",
    "end": "1768470"
  },
  {
    "text": "this limit as n goes to\ninfinity of the probability of this thing is equal to\nthat, basically is just",
    "start": "1768470",
    "end": "1776450"
  },
  {
    "text": "saying that as the sample size\nas n gets bigger and bigger,",
    "start": "1776450",
    "end": "1781850"
  },
  {
    "text": "then the probability that\nthe standardized version of the sample mean is going to\nhave a normal distribution is--",
    "start": "1781850",
    "end": "1795220"
  },
  {
    "text": "well, the probability that it's\nless than some value little x",
    "start": "1795220",
    "end": "1802240"
  },
  {
    "text": "is just going to the\nnormal CDF evaluated at X.",
    "start": "1802240",
    "end": "1807490"
  },
  {
    "text": "So I didn't say that\nvery eloquently, but let me put some other--",
    "start": "1807490",
    "end": "1815290"
  },
  {
    "text": "oh, and I should note, I think\nEsther used this notation as well. This is special\nnotation for the CDF",
    "start": "1815290",
    "end": "1820630"
  },
  {
    "text": "of a standard normal\nrandom variable. So let me restate what I\njust said a little bit more",
    "start": "1820630",
    "end": "1827830"
  },
  {
    "text": "eloquently. So basically, we take\na standardized version of the sample mean from\nany old distribution,",
    "start": "1827830",
    "end": "1834890"
  },
  {
    "text": "let the sample size\ngo to infinity,",
    "start": "1834890",
    "end": "1840910"
  },
  {
    "text": "and this is essentially\nthe definition of the CDF of that\nrandom variable.",
    "start": "1840910",
    "end": "1848620"
  },
  {
    "text": "By definition, that's what\na CDF-- the probability that random variable is less\nthan or equal to some value",
    "start": "1848620",
    "end": "1853870"
  },
  {
    "text": "X. So, essentially,\nthe definition of the CDF of that\nrandom variable",
    "start": "1853870",
    "end": "1859340"
  },
  {
    "text": "is equal to the\nstandard normal CDF. ",
    "start": "1859340",
    "end": "1864600"
  },
  {
    "text": "So this is what the central\nlimit theorem tells us. Practically speaking,\nwhat does this mean?",
    "start": "1864600",
    "end": "1872070"
  },
  {
    "text": "That means if you have a\nsample mean from a reasonably large distribution or--",
    "start": "1872070",
    "end": "1877220"
  },
  {
    "text": "sorry, reasonably large random\nsample from any distribution--",
    "start": "1877220",
    "end": "1882770"
  },
  {
    "text": "basically that isn't just\na crazy distribution-- it will have an approximate\nnormal distribution and its",
    "start": "1882770",
    "end": "1890540"
  },
  {
    "text": "mean-- we already calculated\nthis-- its mean is mu, and its variance is\nsigma squared over n.",
    "start": "1890540",
    "end": "1898420"
  },
  {
    "text": "So the central limit\ntheorem tells us this sort of very powerful piece\nof information, which is this.",
    "start": "1898420",
    "end": "1909190"
  },
  {
    "text": "We calculated this\na few minutes ago. We calculated this\na few minutes ago. We know that the random\nthat the sample mean",
    "start": "1909190",
    "end": "1916059"
  },
  {
    "text": "has mean, mu, variance,\nsigma squared over n. Central limit theorem\ntells us that if our sample",
    "start": "1916060",
    "end": "1922200"
  },
  {
    "text": "size is large enough, it's going\nto be approximately normal. ",
    "start": "1922200",
    "end": "1930389"
  },
  {
    "text": "So first of all, I just\nwant to take a step back and say how kind of\nremarkable this result is.",
    "start": "1930390",
    "end": "1938430"
  },
  {
    "text": "I didn't say that the\ndistribution that you were drawing from\nhad to look like this",
    "start": "1938430",
    "end": "1944910"
  },
  {
    "text": "or had to look like this. The distribution could, for\ninstance, look like that.",
    "start": "1944910",
    "end": "1954680"
  },
  {
    "text": "It could be a distribution\nthat has a big point mass here and a little point mass here.",
    "start": "1954680",
    "end": "1961340"
  },
  {
    "text": "And yet if our random sample\nfrom this distribution",
    "start": "1961340",
    "end": "1967520"
  },
  {
    "text": "is large enough, the sample\nmean of that random sample",
    "start": "1967520",
    "end": "1972650"
  },
  {
    "text": "will be approximately normal. ",
    "start": "1972650",
    "end": "1977940"
  },
  {
    "text": "I mean, I don't know, it seems\nlike a remarkable result to me. It sort of almost seems\nlike magic, but it's not.",
    "start": "1977940",
    "end": "1985810"
  },
  {
    "start": "1985810",
    "end": "1991980"
  },
  {
    "text": "So remarkable-- perhaps. It's also useful.",
    "start": "1991980",
    "end": "1997530"
  },
  {
    "text": "We don't need to know\nthe distribution we're sampling from to know a\nlot about the behavior",
    "start": "1997530",
    "end": "2004040"
  },
  {
    "text": "of the sample mean. So that's why it's so useful. We can be sampling from some\ncrazy, almost degenerate",
    "start": "2004040",
    "end": "2011180"
  },
  {
    "text": "distribution. We don't need to\nmake any assumptions. We don't need to know\nanything about it. But we know, as long as\nour sample is big enough,",
    "start": "2011180",
    "end": "2018300"
  },
  {
    "text": "the sample mean is going\nto be approximately normal. And that's just going to be\nsuper useful when we go forward",
    "start": "2018300",
    "end": "2025610"
  },
  {
    "text": "into estimation and inference. ",
    "start": "2025610",
    "end": "2031820"
  },
  {
    "text": "And finally, I'll\njust point out, we're going to rely on\nthis theorem at least implicitly for the\nrest of the semester.",
    "start": "2031820",
    "end": "2039510"
  },
  {
    "text": "And it also gives us a notion of\nwhy the normal distribution is so important.",
    "start": "2039510",
    "end": "2044833"
  },
  {
    "text": "The normal\ndistribution is kind of really foundational\nin all of statistics, and the central limit\ntheorem is a big reason why.",
    "start": "2044833",
    "end": "2053239"
  },
  {
    "text": "And also, to, I don't know,\namplify the earlier question",
    "start": "2053239",
    "end": "2059239"
  },
  {
    "text": "about the nature of\nthe random sample-- I gave you the plain\nvanilla version",
    "start": "2059239",
    "end": "2065322"
  },
  {
    "text": "of the central limit theorem. There are lots of\ndifferent central limit theorems where we relax\nthe assumption of an i.i.d.",
    "start": "2065322",
    "end": "2074960"
  },
  {
    "text": "Random sample-- lots\nof different versions of the central\nlimit theorem where we can be sampling from\ndifferent distributions,",
    "start": "2074960",
    "end": "2083060"
  },
  {
    "text": "and the random\nvariables don't have",
    "start": "2083060",
    "end": "2088790"
  },
  {
    "text": "to be independent, et cetera. And there's still some\ncentral limit theorems",
    "start": "2088790",
    "end": "2094050"
  },
  {
    "text": "that exist in many\nof those situations. ",
    "start": "2094050",
    "end": "2099810"
  },
  {
    "text": "So are these looks of\nsatisfaction or bafflement",
    "start": "2099810",
    "end": "2106470"
  },
  {
    "text": "or does this make sense? Yep?",
    "start": "2106470",
    "end": "2111510"
  },
  {
    "text": "You understand why it's\nimportant, more or less? Willing to go on?",
    "start": "2111510",
    "end": "2117690"
  },
  {
    "text": "AUDIENCE: Yes. SARA ELLISON: OK.  Ah, for the first time this\nsemester, the title on my slide",
    "start": "2117690",
    "end": "2126210"
  },
  {
    "text": "does not start with probability. Yes, we've entered a new phase.",
    "start": "2126210",
    "end": "2132780"
  },
  {
    "text": "So what is statistics? Well, it's the study of\nestimation and inference.",
    "start": "2132780",
    "end": "2138180"
  },
  {
    "text": "We'll get to inference\na little bit later. So we won't talk about\nthat for a couple of weeks.",
    "start": "2138180",
    "end": "2143670"
  },
  {
    "text": "And for now, we'll\nfocus on estimation. I should say, just\nas a personal note,",
    "start": "2143670",
    "end": "2149440"
  },
  {
    "text": "I was a statistics major\nas an undergraduate, and I took a lot of\nprobability courses,",
    "start": "2149440",
    "end": "2154600"
  },
  {
    "text": "and I took a lot of\nstatistics courses. And my view was\nthat these courses",
    "start": "2154600",
    "end": "2160140"
  },
  {
    "text": "didn't talk to each other. And so one reason why I like\nthis lecture so much is that--",
    "start": "2160140",
    "end": "2169349"
  },
  {
    "text": "at least I hope. This is what I'm\nintending to accomplish-- I hope that this\nlecture is providing",
    "start": "2169350",
    "end": "2175150"
  },
  {
    "text": "a bridge between\nprobability and statistics, and telling you why the\nfoundational material",
    "start": "2175150",
    "end": "2185980"
  },
  {
    "text": "that we've been working\nso hard on in probability is exactly what's going to\ntell us how statistics behave",
    "start": "2185980",
    "end": "2193540"
  },
  {
    "text": "and what we're going to be able\nto infer from the statistics that we calculate.",
    "start": "2193540",
    "end": "2199520"
  },
  {
    "text": "So anyhow, that's my goal. This is something that, at\nleast in my personal experience, always frustrated me that I\nfelt like the probabilists",
    "start": "2199520",
    "end": "2207190"
  },
  {
    "text": "and the statisticians\nnever talked to each other or something. And this is the\nlecture in which they",
    "start": "2207190",
    "end": "2212200"
  },
  {
    "text": "get to talk to each\nother in some sense. ",
    "start": "2212200",
    "end": "2220779"
  },
  {
    "text": "So we've actually seen\nexamples of estimators. We saw the sample mean\njust a minute ago.",
    "start": "2220780",
    "end": "2227320"
  },
  {
    "text": "I didn't describe\nit as an estimator. It is an estimator. We had this sort of notion\nthat we talked about,",
    "start": "2227320",
    "end": "2233140"
  },
  {
    "text": "that it's going to give\nus some information about the underlying\ndistribution and we'll make that\nmore formal in a minute.",
    "start": "2233140",
    "end": "2240430"
  },
  {
    "text": "Also, on your problem\nset, you saw an estimator. And again, I didn't use the\nterminology of estimation",
    "start": "2240430",
    "end": "2247060"
  },
  {
    "text": "because we hadn't\nintroduced it yet. But the bufflehead-- the problem\nwith the bufflehead population,",
    "start": "2247060",
    "end": "2255099"
  },
  {
    "text": "what were you doing? You were estimating the\nsize of a population.",
    "start": "2255100",
    "end": "2262150"
  },
  {
    "text": "So we're going to engage in\na more general conversation about estimation. now,\nbut keep those two",
    "start": "2262150",
    "end": "2270190"
  },
  {
    "text": "examples in the\nback of your mind, and maybe that'll\nadd some concreteness to what we're talking about.",
    "start": "2270190",
    "end": "2278920"
  },
  {
    "text": "So what is an estimator? Well, an estimator is a\nfunction of the random variables in a random sample.",
    "start": "2278920",
    "end": "2285040"
  },
  {
    "text": "The specific function is\nchosen with some goal in mind. ",
    "start": "2285040",
    "end": "2292060"
  },
  {
    "text": "It's chosen to have\nproperties that are useful for\ngiving us information",
    "start": "2292060",
    "end": "2297100"
  },
  {
    "text": "about the distribution of\nthose random variables. So the basic idea here is\nwe have a random sample.",
    "start": "2297100",
    "end": "2303860"
  },
  {
    "text": "We may know a lot about the\ndistribution it comes from. We may relatively little about\nthe distribution it comes from.",
    "start": "2303860",
    "end": "2309592"
  },
  {
    "text": "But what we're\ngoing to do is we're going to create functions\nof the random sample.",
    "start": "2309592",
    "end": "2315190"
  },
  {
    "text": "And those functions\nare chosen specifically to reveal or to\ntell us information",
    "start": "2315190",
    "end": "2321579"
  },
  {
    "text": "about the distribution that\nthe random sample came from. That's the whole idea\nbehind estimation.",
    "start": "2321580",
    "end": "2327880"
  },
  {
    "text": " So before we talk a little\nbit more about estimation,",
    "start": "2327880",
    "end": "2335490"
  },
  {
    "text": "I want to define\nwhat a parameter is. We've talked about parameters. We've seen lots of examples. I don't know that we've\nseen an actual definition.",
    "start": "2335490",
    "end": "2342900"
  },
  {
    "text": "So I think it would\nbe useful to say that a parameter is a\ncontact constant indexing",
    "start": "2342900",
    "end": "2348569"
  },
  {
    "text": "a family of distributions. So mu and sigma squared\nare the parameters",
    "start": "2348570",
    "end": "2354599"
  },
  {
    "text": "that index the normal\nfamily of distributions. So every normal\ndistribution has--",
    "start": "2354600",
    "end": "2361380"
  },
  {
    "text": "all you need to know is the\nmu and the sigma squared, and you know everything\nabout that distribution if you know what's\nin the normal family.",
    "start": "2361380",
    "end": "2369180"
  },
  {
    "text": "The exponential\nfamily is what's known as a one-parameter distribution\nor one-parameter family.",
    "start": "2369180",
    "end": "2375599"
  },
  {
    "text": "There's only one parameter,\nwhich is lambda-- typically, we call it lambda-- that determines the which\nmember of the exponential family",
    "start": "2375600",
    "end": "2385770"
  },
  {
    "text": "a particular distribution is in. Uniform distribution-- a and b.",
    "start": "2385770",
    "end": "2391990"
  },
  {
    "text": "Those are the parameters. n and p from the\nbinomial distribution,",
    "start": "2391990",
    "end": "2398260"
  },
  {
    "text": "for instance-- often, in the\ndiscussion of estimation, I'll often use theta\nas a general notation",
    "start": "2398260",
    "end": "2405010"
  },
  {
    "text": "for a parameter. But if you want to add some\nconcreteness in your mind, just think about lambda from\nan exponential or whatever.",
    "start": "2405010",
    "end": "2415090"
  },
  {
    "text": " So I think I said this before,\nbut the idea behind estimation",
    "start": "2415090",
    "end": "2423900"
  },
  {
    "text": "is we want to determine\nthe values of parameters that govern an observed\nstochastic process",
    "start": "2423900",
    "end": "2430590"
  },
  {
    "text": "or phenomenon. So we have an observed\nstochastic process or phenomenon. We can gather a random\nsample from that process",
    "start": "2430590",
    "end": "2438000"
  },
  {
    "text": "or phenomenon. But we might not know the\nvalues for all the parameters.",
    "start": "2438000",
    "end": "2445140"
  },
  {
    "text": "So we're going to create these\nfunctions of random variables that have the goal of estimating\nthe unknown parameters",
    "start": "2445140",
    "end": "2454770"
  },
  {
    "text": "from the distribution. The general notation we're\ngoing to use for an estimator",
    "start": "2454770",
    "end": "2460049"
  },
  {
    "text": "is theta hat.  So again, I've sort\nof talked about this,",
    "start": "2460050",
    "end": "2467160"
  },
  {
    "text": "both in this lecture and\nin previous lectures. But I just want to make\nit a little more explicit.",
    "start": "2467160",
    "end": "2473190"
  },
  {
    "text": "When we're talking\nabout statistics, when we're going from the\ndiscussion of probability",
    "start": "2473190",
    "end": "2478319"
  },
  {
    "text": "to statistics, we\nreally need to keep two notions of the random\nvariable in our head",
    "start": "2478320",
    "end": "2483480"
  },
  {
    "text": "simultaneously. We need to think\nof random variables as this mathematical\nconstruct that I",
    "start": "2483480",
    "end": "2488849"
  },
  {
    "text": "introduced several weeks ago-- so a function from the sample\nspace to the real numbers.",
    "start": "2488850",
    "end": "2495610"
  },
  {
    "text": "And we also have to think of\nit as a stochastic object that can, quote, \"take on\"\ndifferent realizations",
    "start": "2495610",
    "end": "2501960"
  },
  {
    "text": "with different probabilities. And so we use-- and I've been sort of consistent\nthroughout using the notation",
    "start": "2501960",
    "end": "2510690"
  },
  {
    "text": "capital X to stand for the\nrandom variable and little x to stand for the realization\nor possible realizations",
    "start": "2510690",
    "end": "2518160"
  },
  {
    "text": "of the random\nvariables, and I'll continue using that notation.",
    "start": "2518160",
    "end": "2523480"
  },
  {
    "text": "Second of all, we've got to\nthink of a random sample. We've got to keep these two\nnotions of a random variable",
    "start": "2523480",
    "end": "2529900"
  },
  {
    "text": "in our mind at the same time. And we also have to keep two\nnotions of a random sample",
    "start": "2529900",
    "end": "2535690"
  },
  {
    "text": "in our mind at the same time. So we think of it as an i.i.d. Collection of random variables,\nbut we can also think of the--",
    "start": "2535690",
    "end": "2544600"
  },
  {
    "text": "we also can call\nthe realizations of those random variables\na random sample.",
    "start": "2544600",
    "end": "2551270"
  },
  {
    "text": "So a random sample can refer\nto the random variables. It can refer to the realizations\nof the random variables.",
    "start": "2551270",
    "end": "2559490"
  },
  {
    "text": "And sometimes, we just\ncall that data, instead of realizations of\nrandom variables, and that's fine, too.",
    "start": "2559490",
    "end": "2565760"
  },
  {
    "text": "Yes? AUDIENCE: How did\nyou distinguish the stochastic object\n[INAUDIBLE] process",
    "start": "2565760",
    "end": "2574135"
  },
  {
    "text": "[INAUDIBLE]. SARA ELLISON: I'm\nsorry, how did-- AUDIENCE: How did you\ndistinguish a stochastic--",
    "start": "2574135",
    "end": "2579170"
  },
  {
    "text": "how did you define the\nstochastic object [INAUDIBLE]?? SARA ELLISON: Yeah, I didn't--",
    "start": "2579170",
    "end": "2584670"
  },
  {
    "text": "I'm not going to give you\na formal definition of it. This is just meant as--",
    "start": "2584670",
    "end": "2589950"
  },
  {
    "text": "so the question\nis how do I define a stochastic object or\na stochastic process",
    "start": "2589950",
    "end": "2597750"
  },
  {
    "text": "or something-- AUDIENCE: Process [INAUDIBLE]. SARA ELLISON: Yes. So I'm not going to give\nyou a formal definition.",
    "start": "2597750",
    "end": "2607049"
  },
  {
    "text": "And the idea here\nis that I just want you to have these two\nnotions of in your mind",
    "start": "2607050",
    "end": "2613770"
  },
  {
    "text": "simultaneously that there's\nsort of a mathematical construct called a random\nvariable, but then",
    "start": "2613770",
    "end": "2619677"
  },
  {
    "text": "the random variable--\nthe reason why we have the mathematical\nconstruct is there are these sort of uncertain\nevents that happen",
    "start": "2619677",
    "end": "2625049"
  },
  {
    "text": "or stochastic events that\nhappen in the real world, and we want to have\nsome model of them. And so we think of it as\na mathematical construct.",
    "start": "2625050",
    "end": "2631950"
  },
  {
    "text": "We also think of it as a model\nof stochastic occurrences",
    "start": "2631950",
    "end": "2637260"
  },
  {
    "text": "or something like that. Does that help? Somewhat? OK, yeah?",
    "start": "2637260",
    "end": "2642510"
  },
  {
    "text": "AUDIENCE: Just to summarize,\nso we have a random sample, and we create a\nfunction based on those,",
    "start": "2642510",
    "end": "2648610"
  },
  {
    "text": "and that acts as an\nestimator, which will help us to find the parameters of the--",
    "start": "2648610",
    "end": "2655213"
  },
  {
    "text": "SARA ELLISON: You've got it. You've got it. That's exactly right. And we'll see examples as\nwe go further that I think",
    "start": "2655213",
    "end": "2664300"
  },
  {
    "text": "will clarify that even more.  Oh, so, actually,\nI think you just",
    "start": "2664300",
    "end": "2671440"
  },
  {
    "text": "predicted what I was going\nto put on the next slide or what I put on the next slide. So we know or assume that\na set of random variables",
    "start": "2671440",
    "end": "2677500"
  },
  {
    "text": "a random sample is\ndistributed-- say, i.i.d. Normal or i.i.d. Uniform or i.i.d.",
    "start": "2677500",
    "end": "2683350"
  },
  {
    "text": "Exponential-- and\nthen estimation is trying to determine\nthe specific mu and sigma",
    "start": "2683350",
    "end": "2689110"
  },
  {
    "text": "squared or the specific a\nand b or the specific lambda. ",
    "start": "2689110",
    "end": "2698000"
  },
  {
    "text": "AUDIENCE: It will always be\nan error, because the sample size is not infinite as-- there will be error\nin the estimation?",
    "start": "2698000",
    "end": "2704300"
  },
  {
    "text": "SARA ELLISON: Yep. And the way that we quantify\nthe uncertainty of our estimate is through--",
    "start": "2704300",
    "end": "2710302"
  },
  {
    "text": "and we'll get to this\nmore specifically-- the way we quantify it\nis through the variance of the distribution\nof our estimator.",
    "start": "2710302",
    "end": "2718010"
  },
  {
    "start": "2718010",
    "end": "2723790"
  },
  {
    "text": "So I think we've covered this. You might choose a function-- ",
    "start": "2723790",
    "end": "2731070"
  },
  {
    "text": "maybe I should actually go\nthrough this a little bit. I think we've\nessentially covered it.",
    "start": "2731070",
    "end": "2736990"
  },
  {
    "text": "So when I said that an estimator\nwas a specific function",
    "start": "2736990",
    "end": "2743640"
  },
  {
    "text": "of the random sample that\nwas going to be useful for us to try to\ngive us information",
    "start": "2743640",
    "end": "2749700"
  },
  {
    "text": "about an unknown\nparameter, for instance, and so maybe what we do is we\ncould choose a function whose",
    "start": "2749700",
    "end": "2757560"
  },
  {
    "text": "result when applied\nto a random sample is a random variable that\nhas a very tight distribution",
    "start": "2757560",
    "end": "2763680"
  },
  {
    "text": "around the mean of\nthe distribution of those random variables.",
    "start": "2763680",
    "end": "2771410"
  },
  {
    "text": "And so if we have an estimator\nfunction of random variables",
    "start": "2771410",
    "end": "2777780"
  },
  {
    "text": "that's very tightly\ndistributed around the mean, and we don't know\nthe mean, well,",
    "start": "2777780",
    "end": "2783470"
  },
  {
    "text": "if we get a realization\nfrom that estimator, then that's going to give\nus important information",
    "start": "2783470",
    "end": "2788990"
  },
  {
    "text": "about where the mean is. So-- ",
    "start": "2788990",
    "end": "2794767"
  },
  {
    "text": "AUDIENCE: When we\ndon't know the mean, then how can we say\nthat the estimator is tightly around the mean?",
    "start": "2794767",
    "end": "2799935"
  },
  {
    "text": "SARA ELLISON: No, we\ncan't say the estimate-- we can say, analytically,\nmathematically, we know it has to be tightly\ndistributed around the mean.",
    "start": "2799935",
    "end": "2807970"
  },
  {
    "text": "And so what we do is we take\na specific random sample, we plug it into that function\nthat's the estimator,",
    "start": "2807970",
    "end": "2813840"
  },
  {
    "text": "the estimator gives\nus a value, and we know that value is a realization\nfrom that distribution that's",
    "start": "2813840",
    "end": "2821580"
  },
  {
    "text": "tightly distributed\naround the mean. So let me-- maybe drawing\na picture would help.",
    "start": "2821580",
    "end": "2827980"
  },
  {
    "text": "So let's suppose we\nhave a random sample",
    "start": "2827980",
    "end": "2833940"
  },
  {
    "text": "from this distribution. This distribution\nhas a mean, mu.",
    "start": "2833940",
    "end": "2840210"
  },
  {
    "text": "We don't know what it is. We want to know what it is. So what do we do?",
    "start": "2840210",
    "end": "2845460"
  },
  {
    "text": "We gather a random sample\nfrom this distribution.",
    "start": "2845460",
    "end": "2851353"
  },
  {
    "text": "So it's just a bunch-- ",
    "start": "2851353",
    "end": "2856590"
  },
  {
    "text": "it's a bunch of realizations\nfrom this distribution. So they're both--\nwell, I should say",
    "start": "2856590",
    "end": "2861690"
  },
  {
    "text": "they're both random variables\nthat have this distribution, and the data is the\nsort of realizations",
    "start": "2861690",
    "end": "2867630"
  },
  {
    "text": "associated with that. So we gather that random sample. We plug that random sample\ninto this particular function,",
    "start": "2867630",
    "end": "2880710"
  },
  {
    "text": "X bar, which is equal to 1 over\nn times the sum of the X's. We know, analytically,\nthat this thing here",
    "start": "2880710",
    "end": "2889200"
  },
  {
    "text": "has a distribution\nthat looks like this. ",
    "start": "2889200",
    "end": "2898910"
  },
  {
    "text": "Maybe that was a-- maybe that's a\nlittle exaggerated. But basically, this thing\nhere has a distribution.",
    "start": "2898910",
    "end": "2906310"
  },
  {
    "text": "We know, if this sample\nsize is big enough, this is going to be\napproximately normal--",
    "start": "2906310",
    "end": "2912339"
  },
  {
    "text": "I'll put an A here\nfor approximate-- and it's going to\nhave mean mu, and it's going to have variance\nsigma squared over n.",
    "start": "2912340",
    "end": "2921369"
  },
  {
    "text": " Central limit theorem-- well,\nwe knew this part and this part",
    "start": "2921370",
    "end": "2927400"
  },
  {
    "text": "before the central limit\ntheorem told us this part. So this is now how\nthis distribution-- how",
    "start": "2927400",
    "end": "2934300"
  },
  {
    "text": "the sample mean is distributed. So if we get a realization\nfrom this distribution,",
    "start": "2934300",
    "end": "2940960"
  },
  {
    "text": "then we're pretty\nsure that realization is somewhere close\nto this unknown mean",
    "start": "2940960",
    "end": "2947890"
  },
  {
    "text": "because this distribution is\ntight around this unknown mean. And that's the fundamental idea.",
    "start": "2947890",
    "end": "2958075"
  },
  {
    "text": " So one thing I do want\nto point out on here",
    "start": "2958075",
    "end": "2963839"
  },
  {
    "text": "is that just like we use the\nterm random sample to refer both to the set of random\nvariables and to the set",
    "start": "2963840",
    "end": "2971640"
  },
  {
    "text": "of the realizations\nassociated with them, we use theta hat to stand\nfor both an estimator, which",
    "start": "2971640",
    "end": "2980190"
  },
  {
    "text": "is a function of\nrandom variables, and the estimate coming out\nof that estimator, which is what you get when you\nplug in the realizations",
    "start": "2980190",
    "end": "2986910"
  },
  {
    "text": "into the estimator. So again, statistics does\nnot make a distinction",
    "start": "2986910",
    "end": "2995250"
  },
  {
    "text": "between the estimate\nand the estimator, typically, in the notation.",
    "start": "2995250",
    "end": "3000740"
  },
  {
    "start": "3000740",
    "end": "3006150"
  },
  {
    "text": "An example, maybe, that will\nadd a little concreteness-- so let's suppose that we\nhave a random variable X,",
    "start": "3006150",
    "end": "3017370"
  },
  {
    "text": "and it has a uniform\nzero theta distribution. So we don't know.",
    "start": "3017370",
    "end": "3023235"
  },
  {
    "start": "3023235",
    "end": "3041506"
  },
  {
    "text": "It has a distribution\nthat looks like this. We don't know what theta is.",
    "start": "3041506",
    "end": "3047680"
  },
  {
    "text": "We want to figure\nout what theta is. So what could we do? Let's suppose we have\naccess to a random sample,",
    "start": "3047680",
    "end": "3057520"
  },
  {
    "text": "the realizations, from\nthis distribution. What could we do?",
    "start": "3057520",
    "end": "3063770"
  },
  {
    "text": "Any ideas? AUDIENCE: [INAUDIBLE]",
    "start": "3063770",
    "end": "3069770"
  },
  {
    "text": " SARA ELLISON: We\nwant to do something with those-- we want to\nplug those realizations",
    "start": "3069770",
    "end": "3075120"
  },
  {
    "text": "into some function\nthat's going to give us some information about\nthis parameter theta.",
    "start": "3075120",
    "end": "3083860"
  },
  {
    "text": "Yes? AUDIENCE: I think if you\ntake the mean [INAUDIBLE]..",
    "start": "3083860",
    "end": "3090260"
  },
  {
    "text": "SARA ELLISON: Yes, so what\nwould you do to the mean, then? Sample mean. AUDIENCE: I would estimate the\nsample mean is [INAUDIBLE]..",
    "start": "3090260",
    "end": "3098840"
  },
  {
    "text": "SARA ELLISON: Well,\nOK, so I wanted you to say that you\ntake the sample mean and then you multiply it by 2.",
    "start": "3098840",
    "end": "3105355"
  },
  {
    "text": "So we were saying\nthe same thing, but you can-- so\none thing you can do is you can get a random sample.",
    "start": "3105355",
    "end": "3110820"
  },
  {
    "text": "You calculate the sample mean. We know that the\nsample mean is going",
    "start": "3110820",
    "end": "3117109"
  },
  {
    "text": "to have a distribution that's\nsort of centered around here and is going to be\nmore concentrated",
    "start": "3117110",
    "end": "3123859"
  },
  {
    "text": "around the mean of\nthis distribution than the distribution itself. So you plug them into to\nthe sample mean function",
    "start": "3123860",
    "end": "3131540"
  },
  {
    "text": "and you multiply\nby 2, and that's going to give you an\nestimate for theta.",
    "start": "3131540",
    "end": "3137060"
  },
  {
    "text": "Seem reasonable? Other ideas? ",
    "start": "3137060",
    "end": "3144760"
  },
  {
    "text": "Are you yawning or-- oh, sorry. AUDIENCE: [INAUDIBLE]\ntake the [INAUDIBLE]..",
    "start": "3144760",
    "end": "3150035"
  },
  {
    "text": "SARA ELLISON: That's right. So how about if we have a\nrandom sample and, instead of computing the sample mean,\nwe just take the n-th order",
    "start": "3150035",
    "end": "3158330"
  },
  {
    "text": "statistic from\nthat random sample and use that as an estimate?",
    "start": "3158330",
    "end": "3164540"
  },
  {
    "text": "Seem reasonable, right? So we'll study\nthese two examples.",
    "start": "3164540",
    "end": "3170450"
  },
  {
    "text": "We'll figure out\nhow both of them are distributed in the time to\ncome, like this lecture next.",
    "start": "3170450",
    "end": "3178460"
  },
  {
    "text": "But they both seem\nlike reasonable ways to take a random sample\nfrom this distribution,",
    "start": "3178460",
    "end": "3184990"
  },
  {
    "text": "plug that random\nsample into a function, and gain information\nabout theta from-- choose",
    "start": "3184990",
    "end": "3193365"
  },
  {
    "text": "the function that's going to\nallow us to gain information about theta. ",
    "start": "3193365",
    "end": "3199819"
  },
  {
    "text": "So this is just what\nwe said verbally. Two reasonable\nprocedures come to mind--",
    "start": "3199820",
    "end": "3204920"
  },
  {
    "text": "gather a random sample,\ncompute the sample mean, and multiply by 2, and\nuse that as our estimator.",
    "start": "3204920",
    "end": "3212359"
  },
  {
    "text": "Or gather a random sample,\ncompute the max, the n-th order statistic of the random sample,\nand use that as our estimator.",
    "start": "3212360",
    "end": "3220280"
  },
  {
    "start": "3220280",
    "end": "3226450"
  },
  {
    "text": "And here they are n\nequations instead of words. So theta hat sub 1 is just equal\nto the n-th order statistic.",
    "start": "3226450",
    "end": "3236650"
  },
  {
    "text": "Theta hat sub 2 is equal\nto 2 times the sample mean. ",
    "start": "3236650",
    "end": "3248080"
  },
  {
    "text": "So let's think-- I have a couple of\nslides that help you picture what's going on.",
    "start": "3248080",
    "end": "3253789"
  },
  {
    "text": "So here is the n-th\norder statistic from a random sample of size\n5 from this distribution.",
    "start": "3253790",
    "end": "3261700"
  },
  {
    "text": "Here's the n-th order statistic\nfrom a random sample of size. I don't know what that is-- 12 or something like that.",
    "start": "3261700",
    "end": "3268599"
  },
  {
    "text": "And here's the n-th order\nstatistic from a random sample of size a lot. I don't know how many\nlittle marks I put on there.",
    "start": "3268600",
    "end": "3278270"
  },
  {
    "text": "So as n is getting\nbigger, as our sample size is getting\nbigger, our estimator",
    "start": "3278270",
    "end": "3285859"
  },
  {
    "text": "seems to be getting better. That's not just--\nI mean, obviously,",
    "start": "3285860",
    "end": "3291800"
  },
  {
    "text": "I could have drawn many\ndifferent pictures here. That's not just a mistake. In fact, the estimator\ndoes get better.",
    "start": "3291800",
    "end": "3299800"
  },
  {
    "text": "It becomes a more\naccurate estimate of theta as n gets bigger. ",
    "start": "3299800",
    "end": "3309530"
  },
  {
    "text": "Here's 2 times the sample mean. So the sample mean was, I don't\nknow, somewhere around in here,",
    "start": "3309530",
    "end": "3317690"
  },
  {
    "text": "and I multiplied it by 2. I just kind of did\nthis visually but, I think this is probably close. So here, the sample mean\nis out here somewhere.",
    "start": "3317690",
    "end": "3326600"
  },
  {
    "text": "This particular random\nsample that I dreamed up-- it, by chance, had more\nobservations in the upper half.",
    "start": "3326600",
    "end": "3335130"
  },
  {
    "text": "So 2 times the sample mean\nwould be somewhere out there. And then this random sample--",
    "start": "3335130",
    "end": "3342080"
  },
  {
    "text": "seems like the sample mean\nwas pretty close to mu. And so 2 times the sample mean\nwould be just about theta.",
    "start": "3342080",
    "end": "3349310"
  },
  {
    "text": "So again, in these\nexamples, the estimator",
    "start": "3349310",
    "end": "3355100"
  },
  {
    "text": "is getting better as\nn is getting larger, but it does sort of bounce\naround a little bit.",
    "start": "3355100",
    "end": "3360500"
  },
  {
    "text": "And again, that's kind of not-- that's not a mistake. That's actually a feature\nof these two estimators",
    "start": "3360500",
    "end": "3369750"
  },
  {
    "text": "that we can prove. Yeah? AUDIENCE: I'm just\nwondering if we have a way of evaluating\nthe estimators? SARA ELLISON: Yes.",
    "start": "3369750",
    "end": "3375120"
  },
  {
    "text": "Excellent question. So the question is\ndo we have a way of evaluating these estimators,\ndeciding how accurate they are",
    "start": "3375120",
    "end": "3382230"
  },
  {
    "text": "and which one to choose? And we will get to that. So yes, those are\nimportant questions.",
    "start": "3382230",
    "end": "3387750"
  },
  {
    "text": " Here's another procedure.",
    "start": "3387750",
    "end": "3393870"
  },
  {
    "text": "Gather a random sample,\ncompute the sample median instead of the sample\nmean, and then the number--",
    "start": "3393870",
    "end": "3401580"
  },
  {
    "text": "the median, I'll remind\nyou, is the number above and below which\nhalf of the sample falls.",
    "start": "3401580",
    "end": "3407100"
  },
  {
    "text": "And then multiply that by 2\nand use that as theta hat. Seem reasonable?",
    "start": "3407100",
    "end": "3413839"
  },
  {
    "text": "Yeah. So I can tell you that that\nalso is a reasonable estimator and it has sort of\nparticular properties",
    "start": "3413840",
    "end": "3421190"
  },
  {
    "text": "that we can talk about later. ",
    "start": "3421190",
    "end": "3426340"
  },
  {
    "text": "Here's another procedure. Gather a random sample,\nthrow the whole thing away and have R generate a\nrandom value for you",
    "start": "3426340",
    "end": "3434530"
  },
  {
    "text": "and use that as theta hat. What do you think? No. So we can guess that\nthis procedure does not",
    "start": "3434530",
    "end": "3441670"
  },
  {
    "text": "have very good properties. And, in fact, we\ncan prove that it doesn't have good properties. I think we probably\nwon't bother to,",
    "start": "3441670",
    "end": "3448150"
  },
  {
    "text": "but we can, in fact,\nprove it doesn't have very good properties. ",
    "start": "3448150",
    "end": "3454600"
  },
  {
    "text": "So these are some of the\nquestions you just asked and one other.",
    "start": "3454600",
    "end": "3460130"
  },
  {
    "text": "So first of all, how did we\ncome up with these functions? We just kind of dreamed them\nup off the top of our head.",
    "start": "3460130",
    "end": "3467050"
  },
  {
    "text": "Is there a more\nsystematic way that we can generate these estimators?",
    "start": "3467050",
    "end": "3472210"
  },
  {
    "text": "And the answer is yes. We'll see that next time. How do we know if\nthey're reasonable? How do we choose among them?",
    "start": "3472210",
    "end": "3479180"
  },
  {
    "text": "So we have two estimators here-- 2 times the sample mean and the\nn-th order statistic, and they",
    "start": "3479180",
    "end": "3485589"
  },
  {
    "text": "both seem like\nreasonable estimators. How do we choose among them\nor between them, in this case?",
    "start": "3485590",
    "end": "3492580"
  },
  {
    "text": "So for the rest of this\nlecture and some of the next, we're going to talk\nabout these topics--",
    "start": "3492580",
    "end": "3497860"
  },
  {
    "text": "criteria for assessing\nestimators and the frameworks for choosing estimators.",
    "start": "3497860",
    "end": "3504730"
  },
  {
    "text": "And these two topics are going\nto answer those questions that were just posed. ",
    "start": "3504730",
    "end": "3513410"
  },
  {
    "text": "So how can we even\nthink about criteria for assessing estimators?",
    "start": "3513410",
    "end": "3518630"
  },
  {
    "text": "Well, remember, an estimator\nis a random variable. So everything that you need to\nknow about a random variable",
    "start": "3518630",
    "end": "3527390"
  },
  {
    "text": "is embodied in its distribution. I mean, that's essentially\nwhat a random variable is.",
    "start": "3527390",
    "end": "3533330"
  },
  {
    "text": "It is its distribution. So our criteria for\nestimating or for assessing",
    "start": "3533330",
    "end": "3539360"
  },
  {
    "text": "these estimators will be\nbased on characteristics of their distributions.",
    "start": "3539360",
    "end": "3545480"
  },
  {
    "text": "So what characteristics of\nthe distributions matter? What do we care about?",
    "start": "3545480",
    "end": "3550660"
  },
  {
    "text": "Well, first one-- I'm going to define a\ncriterion called biasness",
    "start": "3550660",
    "end": "3558099"
  },
  {
    "text": "or define a sort of a\ncharacteristic called unbiased. An estimator is\nunbiased for theta,",
    "start": "3558100",
    "end": "3566630"
  },
  {
    "text": "which is the sort of\nparameter that we're interested in estimating, if\nthe expectation of theta hat",
    "start": "3566630",
    "end": "3572950"
  },
  {
    "text": "is equal to theta\nfor all theta in-- this is a capital\ntheta, by the way--",
    "start": "3572950",
    "end": "3579040"
  },
  {
    "text": "so in-- this just means for\nall possible values of theta. ",
    "start": "3579040",
    "end": "3588049"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nestimator of [INAUDIBLE].. SARA ELLISON: So theta\nhat is our estimator,",
    "start": "3588050",
    "end": "3594700"
  },
  {
    "text": "and it can serve two-- that\nnotation serves two roles. It both stands for the\nfunction of the random sample,",
    "start": "3594700",
    "end": "3602170"
  },
  {
    "text": "and it stands for a particular\nnumber, the estimate, once we plug in the\nrealizations into the function",
    "start": "3602170",
    "end": "3609670"
  },
  {
    "text": "of the random variables. So theta is two things. In this case, it's serving\nthe role as the estimator.",
    "start": "3609670",
    "end": "3617200"
  },
  {
    "text": "So the expectation-- and\nremember, the estimator is a random variable. So it has a distribution. So here, we're saying if the\ndistribution of that estimator,",
    "start": "3617200",
    "end": "3626020"
  },
  {
    "text": "theta hat, is equal\nto the parameter we're trying to estimate, theta--",
    "start": "3626020",
    "end": "3632650"
  },
  {
    "text": "and if that's true for all\npossible values of theta, then we're going to call\nthis estimator unbiased.",
    "start": "3632650",
    "end": "3637725"
  },
  {
    "start": "3637725",
    "end": "3643350"
  },
  {
    "text": "So here's a picture. Yep? AUDIENCE: So when you\ntake the [INAUDIBLE],, that means [INAUDIBLE]. ",
    "start": "3643350",
    "end": "3653940"
  },
  {
    "text": "SARA ELLISON: Theta. AUDIENCE: Theta is [INAUDIBLE]. SARA ELLISON: No,\nit's a parameter. It's a parameter.",
    "start": "3653940",
    "end": "3659350"
  },
  {
    "text": "So, for instance--\nso here's an example. The random variable-- we\nhave sort of a random sample",
    "start": "3659350",
    "end": "3667190"
  },
  {
    "text": "that we're drawing\nfrom this distribution, and we can call those\nX's or Y's or whatever we want to call them.",
    "start": "3667190",
    "end": "3672360"
  },
  {
    "text": "And then this has-- ",
    "start": "3672360",
    "end": "3678880"
  },
  {
    "text": "distribute each X has a\ndistribution uniform 0 to theta.",
    "start": "3678880",
    "end": "3684790"
  },
  {
    "text": "Theta is just-- it's a number. We don't know what it\nis, but it's a number.",
    "start": "3684790",
    "end": "3690820"
  },
  {
    "text": "It's just a number\ngoverning this distribution. AUDIENCE: [INAUDIBLE]\nsymbol [INAUDIBLE]??",
    "start": "3690820",
    "end": "3696559"
  },
  {
    "text": "SARA ELLISON: That's\na capital theta. So it's just the space\nof all possible values",
    "start": "3696560",
    "end": "3702080"
  },
  {
    "text": "of little theta. So for instance, in\nthis case, capital theta",
    "start": "3702080",
    "end": "3709670"
  },
  {
    "text": "has to be the sort of\npositive, real numbers.",
    "start": "3709670",
    "end": "3716040"
  },
  {
    "text": "So for instance, you can't\nhave a uniform 0, negative 4",
    "start": "3716040",
    "end": "3721460"
  },
  {
    "text": "distribution. And so the capital theta is just\nthe set of all possible values",
    "start": "3721460",
    "end": "3729140"
  },
  {
    "text": "of theta. ",
    "start": "3729140",
    "end": "3735440"
  },
  {
    "text": "So here on the left is a picture\nof an unbiased estimator. So what is this curve here?",
    "start": "3735440",
    "end": "3741980"
  },
  {
    "text": "That's the distribution\nof the estimator. And that distribution has\na mean or an expectation.",
    "start": "3741980",
    "end": "3751190"
  },
  {
    "text": "You compute the expectation. If that expectation is equal\nto this parameter theta,",
    "start": "3751190",
    "end": "3759140"
  },
  {
    "text": "then it's unbiased. And if this distribution\nis not equal--",
    "start": "3759140",
    "end": "3764297"
  },
  {
    "text": "or sorry, if the expectation\nof this distribution is not equal to the\nparameter theta, then it's a biased\nestimator for theta.",
    "start": "3764298",
    "end": "3771050"
  },
  {
    "text": "Yes? AUDIENCE: So this normal\nthat you've drawn, that's the normal that you\nget when you take sample--",
    "start": "3771050",
    "end": "3776119"
  },
  {
    "text": "when you take a lot of\ndifferent-- what's the word-- realizations from this\nuniform distribution, and then",
    "start": "3776120",
    "end": "3782549"
  },
  {
    "text": "you get this normal-- SARA ELLISON: If your\nsample size is big enough, it's going to be\napproximately normal.",
    "start": "3782550",
    "end": "3788183"
  },
  {
    "text": "Yeah, that's right. That's right. AUDIENCE: Can we say\nit's biased when theta--",
    "start": "3788183",
    "end": "3793770"
  },
  {
    "text": "when the mean of that random\ndraw is exactly equal-- SARA ELLISON:\nUnbiased if the X--",
    "start": "3793770",
    "end": "3802200"
  },
  {
    "text": "so this is the PDF of theta hat,\nthe distribution of theta hat. If that distribution\nhas an expectation",
    "start": "3802200",
    "end": "3810990"
  },
  {
    "text": "that's equal to theta, then we\ncall that estimator unbiased. Yes? AUDIENCE: The parameter theta\nthat we are talking about here",
    "start": "3810990",
    "end": "3818010"
  },
  {
    "text": "represents the mean of\nthe actual distribution? SARA ELLISON: Well, it might\nbe, and it might not be. So here, it's not the mean.",
    "start": "3818010",
    "end": "3824447"
  },
  {
    "text": "AUDIENCE: But then how would I\nsay expected value of theta hat is theta in this case because\nexpected value of theta hat",
    "start": "3824447",
    "end": "3829760"
  },
  {
    "text": "will be the mean? SARA ELLISON: No. So I'm glad you\nasked this question,",
    "start": "3829760",
    "end": "3835740"
  },
  {
    "text": "so let me try to clarify. So here, theta is a parameter\ngoverning the distribution",
    "start": "3835740",
    "end": "3843740"
  },
  {
    "text": "that we're drawing the\nrandom sample from. It might be the mean\nof that distribution. Here, it's not the mean\nof the distribution.",
    "start": "3843740",
    "end": "3850200"
  },
  {
    "text": "Here, it's the upper\nlimit of the distribution. It could be any other parameter\ngoverning the distribution.",
    "start": "3850200",
    "end": "3857310"
  },
  {
    "text": "What we do is we come up with\nan estimator that we think--",
    "start": "3857310",
    "end": "3865230"
  },
  {
    "text": "we maybe have good\nreason to believe is going to be sort\nof a good estimator",
    "start": "3865230",
    "end": "3870960"
  },
  {
    "text": "for that unknown parameter. And so in the case of\nthis uniform zero theta,",
    "start": "3870960",
    "end": "3877110"
  },
  {
    "text": "we came up with 2\ntimes the sample mean or we came up with the\nn-th order statistic.",
    "start": "3877110",
    "end": "3883619"
  },
  {
    "text": "And both of those\nwere functions that we thought might do a pretty good\njob of telling us something",
    "start": "3883620",
    "end": "3889230"
  },
  {
    "text": "about this unknown theta. And, in both cases, those\nfunctions have distributions.",
    "start": "3889230",
    "end": "3896370"
  },
  {
    "text": "So here, I've drawn the PDF\nof theta hat as kind of normal",
    "start": "3896370",
    "end": "3902790"
  },
  {
    "text": "because that's often what it is. It doesn't have to be normal. If our sample size is\nsmall, it may not be normal.",
    "start": "3902790",
    "end": "3909397"
  },
  {
    "text": "But here, I've sort\nof drawn it normal just because I had to\npick some shape to draw.",
    "start": "3909397",
    "end": "3915600"
  },
  {
    "text": "But the theta hat,\nwhich is the function that we're using to estimate\nthis unknown parameter,",
    "start": "3915600",
    "end": "3921810"
  },
  {
    "text": "has a distribution. If that distribution-- if the\nexpectation that distribution",
    "start": "3921810",
    "end": "3926849"
  },
  {
    "text": "is equal to theta, the thing\nthat we're trying to estimate, then it's an unbiased estimator.",
    "start": "3926850",
    "end": "3932340"
  },
  {
    "text": "Does that help? Yes? AUDIENCE: I'm a\nlittle bit confused because it seems a little\ncounterintuitive to me.",
    "start": "3932340",
    "end": "3938690"
  },
  {
    "text": "So the PDF of the estimator-- in order for you\nto generate it, you",
    "start": "3938690",
    "end": "3944020"
  },
  {
    "text": "need to have a lot of samples\nand multiple estimators, right? ",
    "start": "3944020",
    "end": "3951210"
  },
  {
    "text": "SARA ELLISON: No. If you have a very\nlarge sample--",
    "start": "3951210",
    "end": "3958090"
  },
  {
    "text": "so if you have a very-- I think, actually,\nyou might be confusing",
    "start": "3958090",
    "end": "3966300"
  },
  {
    "text": "the two different\nsenses of an estimator, or you might be confusing an\nestimate with an estimator.",
    "start": "3966300",
    "end": "3973770"
  },
  {
    "text": "So an estimator is a\nfunction of random variables. It's a sort of\nmathematical construct",
    "start": "3973770",
    "end": "3979410"
  },
  {
    "text": "that we can talk about\nthe distribution of. In the real world, what\nwe typically have is",
    "start": "3979410",
    "end": "3985020"
  },
  {
    "text": "we have one random\nsample, which is multiple draws from\nsome distribution,",
    "start": "3985020",
    "end": "3991020"
  },
  {
    "text": "and that random\nsample that we have is sort of a series\nof realizations from that distribution,\na series of numbers.",
    "start": "3991020",
    "end": "3998020"
  },
  {
    "text": "So what we do is we\nchoose a function that has properties that are\ngoing to be useful for us,",
    "start": "3998020",
    "end": "4005300"
  },
  {
    "text": "and then we plug those\nrealizations into the function. And basically, an estimate\nis one realization",
    "start": "4005300",
    "end": "4014720"
  },
  {
    "text": "from this distribution. It's just one realization.",
    "start": "4014720",
    "end": "4020480"
  },
  {
    "text": "And that doesn't mean\nit's going to equal theta. I mean, we could have\na realization here,",
    "start": "4020480",
    "end": "4026780"
  },
  {
    "text": "a realization here. If our estimate is from\nthe distribution that's",
    "start": "4026780",
    "end": "4032450"
  },
  {
    "text": "centered around theta and\nis pretty concentrated around theta, then we\nhave some confidence",
    "start": "4032450",
    "end": "4039560"
  },
  {
    "text": "that our estimate\nis close to theta.  AUDIENCE: So theta is a\ntrue value for [INAUDIBLE]..",
    "start": "4039560",
    "end": "4046930"
  },
  {
    "text": "SARA ELLISON: True value for-- AUDIENCE: The estimator. SARA ELLISON: No, it's a\nparameter from the underlying",
    "start": "4046930",
    "end": "4053440"
  },
  {
    "text": "distribution. AUDIENCE: So it's\nthe actual value that we're trying to estimate?",
    "start": "4053440",
    "end": "4058680"
  },
  {
    "text": "SARA ELLISON: Yes, exactly. AUDIENCE: So if I'm trying\nto estimate the actual value, that means I don't know it.",
    "start": "4058680",
    "end": "4064140"
  },
  {
    "text": "In order for me to prove\nthat it's unbiased, I actually have to know it. SARA ELLISON: No.",
    "start": "4064140",
    "end": "4069450"
  },
  {
    "text": "No, you don't. So mathematically,\nwe can do the proof",
    "start": "4069450",
    "end": "4075000"
  },
  {
    "text": "that an estimator is\nunbiased without-- we just know that, under the\nassumptions that we lay out,",
    "start": "4075000",
    "end": "4083940"
  },
  {
    "text": "we can prove that an estimator\nis going to be unbiased.",
    "start": "4083940",
    "end": "4089700"
  },
  {
    "text": "And then, when we have a\nparticular random sample, obviously, we don't know\nwhere in this distribution",
    "start": "4089700",
    "end": "4096660"
  },
  {
    "text": "we're drawing-- the random sample\nthat we use to-- we plug that into the estimator,\nand we get a particular value",
    "start": "4096660",
    "end": "4103631"
  },
  {
    "text": "from that distribution. We don't know where\nin the distribution that value is coming from.",
    "start": "4103632",
    "end": "4108810"
  },
  {
    "text": "So maybe this helps. I hope this helps. We actually have\nproved unbiasedness",
    "start": "4108810",
    "end": "4115799"
  },
  {
    "text": "just a few minutes ago. So remember the sample mean? We said here is a function\nof random variables.",
    "start": "4115800",
    "end": "4124422"
  },
  {
    "text": "We're going to assume\nthat they're i.i.d. Random variables. We're going to add\nup a bunch of i.i.d.",
    "start": "4124422",
    "end": "4131049"
  },
  {
    "text": "Random variables\nand divide by n. Let's see what the expectation\nof that new random variable",
    "start": "4131050",
    "end": "4137380"
  },
  {
    "text": "is, that X bar-- the new\nrandom variable we're going to call X bar. We computed-- we mathematically\nshowed that its expectation was",
    "start": "4137380",
    "end": "4146229"
  },
  {
    "text": "equal to mu. In a practical situation,\nwe don't know what mu is.",
    "start": "4146229",
    "end": "4152109"
  },
  {
    "text": "But we can show mathematically\nthat that function of a random variable\nhas a distribution",
    "start": "4152109",
    "end": "4158229"
  },
  {
    "text": "and its expectation\nis equal to mu. So that's how to\nprove unbiasness.",
    "start": "4158229",
    "end": "4163479"
  },
  {
    "text": "Does that help? Yes? AUDIENCE: I think the\ndefinition [INAUDIBLE],,",
    "start": "4163479",
    "end": "4170120"
  },
  {
    "text": "it seems as if it\nwould be unbiased, yet we could still not always--",
    "start": "4170120",
    "end": "4175545"
  },
  {
    "text": "so it's easy to\nsatisfy the definition, but depending on the sample,\nyou wouldn't always find the actual theta, so what\n[INAUDIBLE] bias is actually",
    "start": "4175545",
    "end": "4182839"
  },
  {
    "text": "representing? SARA ELLISON: So\nlet me see if I can",
    "start": "4182840",
    "end": "4188189"
  },
  {
    "text": "answer this question\nwithout muddying-- it's a good question. I'm going to just try to answer\nthe question without sort",
    "start": "4188189",
    "end": "4194430"
  },
  {
    "text": "of muddying the waters more. So basically,\nunbiasness just tells",
    "start": "4194430",
    "end": "4200369"
  },
  {
    "text": "us-- let's consider\nthis thought experiment. So let's suppose that we\ngather a random sample",
    "start": "4200370",
    "end": "4209490"
  },
  {
    "text": "from, say, this distribution. And the random sample is\nactual numbers, realizations.",
    "start": "4209490",
    "end": "4217350"
  },
  {
    "text": "We compute the sample mean,\nand then we multiply it by 2, and that gives us some number.",
    "start": "4217350",
    "end": "4223680"
  },
  {
    "text": "And then let's suppose\nwe did that 100 times-- a new random sample.",
    "start": "4223680",
    "end": "4230579"
  },
  {
    "text": "We compute the sample mean. We multiply by 2.",
    "start": "4230580",
    "end": "4235860"
  },
  {
    "text": "That gives us another number,\na brand-new random sample. We do this 1,000 times or a\nmillion times or whatever.",
    "start": "4235860",
    "end": "4241949"
  },
  {
    "text": " The size of our\nrandom sample is going",
    "start": "4241950",
    "end": "4249820"
  },
  {
    "text": "to determine how this thing that\nwe're computing, this 2 times",
    "start": "4249820",
    "end": "4256449"
  },
  {
    "text": "the sample mean, how\nit's distributed. So let's say our random\nsample was size 15 each time,",
    "start": "4256450",
    "end": "4262690"
  },
  {
    "text": "and we did this 100 times\nor 1,000 times or whatever. So what we're going\nto do is basically,",
    "start": "4262690",
    "end": "4268330"
  },
  {
    "text": "then, we'll have something\nthat looks like-- I'll erase this. ",
    "start": "4268330",
    "end": "4297170"
  },
  {
    "text": "2 over n. ",
    "start": "4297170",
    "end": "4307330"
  },
  {
    "text": "So let's say I said 15, but\nlet's say n is equal to 20.",
    "start": "4307330",
    "end": "4313090"
  },
  {
    "text": "Then we can\nmathematically figure out what the distribution of this\n2 times the sort of sample",
    "start": "4313090",
    "end": "4323110"
  },
  {
    "text": "mean from a random\nsample of size 20 is. And maybe we're going\nto get something that looks a little bit like this.",
    "start": "4323110",
    "end": "4329560"
  },
  {
    "text": "I'm not sure. And so, basically, if we think\nabout the thought experiment",
    "start": "4329560",
    "end": "4335230"
  },
  {
    "text": "where we do this 1,000\ntimes and then create a histogram of the\nvalues of the estimate--",
    "start": "4335230",
    "end": "4343000"
  },
  {
    "text": "those 1,000 different\nvalues of the estimate-- the histogram is going to\nlook something like that.",
    "start": "4343000",
    "end": "4349030"
  },
  {
    "text": "Does that help? OK, great. So it's a lot to keep straight.",
    "start": "4349030",
    "end": "4355760"
  },
  {
    "text": "But these are sort of\nthe fundamental ideas underlying estimation. So I'm glad that you guys are\nasking questions and trying",
    "start": "4355760",
    "end": "4364940"
  },
  {
    "text": "to get these concepts\nstraight in your minds. AUDIENCE: So I just want\nto [INAUDIBLE] real quick.",
    "start": "4364940",
    "end": "4371910"
  },
  {
    "text": "So n is 20, so we're taking 20\nsamples from this distribution. Then you've got this\nkind of for loop, where",
    "start": "4371910",
    "end": "4378650"
  },
  {
    "text": "you're doing that 1,000 times. SARA ELLISON: Yes. And then you're creating\na histogram of the 1,000",
    "start": "4378650",
    "end": "4384739"
  },
  {
    "text": "estimates that you get from\neach of these random samples. AUDIENCE: So that\nsecond number, 1,000--",
    "start": "4384740",
    "end": "4390889"
  },
  {
    "text": "clearly you just\ncame up with that on the spot, that's not a number\nthat we're considering here?",
    "start": "4390890",
    "end": "4396092"
  },
  {
    "text": "SARA ELLISON: No. AUDIENCE: n is the number. SARA ELLISON: Exactly. So I only said 1,000\nbecause I wanted you to picture in your mind that\nthis histogram is going to look",
    "start": "4396092",
    "end": "4403220"
  },
  {
    "text": "a lot like this distribution. ",
    "start": "4403220",
    "end": "4413680"
  },
  {
    "text": "Oh, so we're done. Time is up. ",
    "start": "4413680",
    "end": "4423000"
  }
]
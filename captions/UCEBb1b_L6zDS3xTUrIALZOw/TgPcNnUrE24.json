[
  {
    "start": "0",
    "end": "180000"
  },
  {
    "start": "0",
    "end": "17558"
  },
  {
    "text": "PROFESSOR: So we spent the\nlast few lectures discussing Szemerédi's regularity lemma. So we saw that this\nis an important tool",
    "start": "17558",
    "end": "23539"
  },
  {
    "text": "with important\napplications, allowing you to do things like a proof\nof Roth's theorem via graph",
    "start": "23540",
    "end": "30080"
  },
  {
    "text": "theory. One of the concepts that came\nup when we were discussing the statement of Szemerédi's\nregularity lemma is that",
    "start": "30080",
    "end": "38210"
  },
  {
    "text": "of pseudorandomness. So the statement of Szemerédi's\ngraph regularity lemma is that",
    "start": "38210",
    "end": "44480"
  },
  {
    "text": "you can partition an arbitrary\ngraph into a bounded number of pieces so that the\ngraph looks random-like,",
    "start": "44480",
    "end": "53629"
  },
  {
    "text": "as we called it, between\nmost pairs of parts. So what does random-like mean?",
    "start": "53630",
    "end": "60017"
  },
  {
    "text": "So that's something that I want\nto discuss for the next couple of lectures.",
    "start": "60017",
    "end": "65239"
  },
  {
    "text": "And this is the idea\nof pseudorandomness,",
    "start": "65239",
    "end": "78580"
  },
  {
    "text": "which is a concept\nthat is really prevalent in combinatorics, in\ntheoretical computer science,",
    "start": "78580",
    "end": "86880"
  },
  {
    "text": "and in many different areas. And what pseudorandomness tries\nto capture is, in what ways",
    "start": "86880",
    "end": "93840"
  },
  {
    "text": "can a non-random\nobject look random? So before diving into\nsome specific mathematics,",
    "start": "93840",
    "end": "100229"
  },
  {
    "text": "I want to offer some\nphilosophical remarks. So you might know\nthat, on a computer,",
    "start": "100230",
    "end": "106110"
  },
  {
    "text": "you want to generate\na random number. Well, you type in a \"rand,\" and\nit gives you a random number.",
    "start": "106110",
    "end": "111509"
  },
  {
    "text": "But of course, that's not\nnecessarily true randomness. It came from some\npseudorandom generator.",
    "start": "111510",
    "end": "120869"
  },
  {
    "text": "Probably there's some seed and\nsome complex-looking function and outputs something\nthat you couldn't",
    "start": "120870",
    "end": "126510"
  },
  {
    "text": "distinguish from random. But it might not actually\nbe random but just something that looks, in many\ndifferent ways, like random.",
    "start": "126510",
    "end": "135730"
  },
  {
    "text": "So there is this\nconcept of random. You can think about\na random graph, right, generate this\nErdos-Renyi random graph.",
    "start": "135730",
    "end": "141910"
  },
  {
    "text": "Every edge occurs independently\nwith some probability. But I can also show you some\ngraph, some specific graph,",
    "start": "141910",
    "end": "148660"
  },
  {
    "text": "which I say, well, it's, for\nall intents and purposes, just as good as a random graph.",
    "start": "148660",
    "end": "158160"
  },
  {
    "text": "So in what ways can we\ncapture that concept? So that's what I\nwant to discuss.",
    "start": "158160",
    "end": "164100"
  },
  {
    "text": "And that's the topic\nof pseudorandomness. And of course, well,\nthis idea extends",
    "start": "164100",
    "end": "169250"
  },
  {
    "text": "to many areas, number\ntheory and whatnot, but we'll stick\nwith graph theory. In particular, I want to explore\ntoday just one specific notion",
    "start": "169250",
    "end": "178220"
  },
  {
    "text": "of pseudorandomness. And this comes from an important\npaper called \"Quasi-random",
    "start": "178220",
    "end": "184060"
  },
  {
    "start": "180000",
    "end": "330000"
  },
  {
    "text": "graphs.\"  And this concept is due to\nChung, Graham, and Wilson",
    "start": "184060",
    "end": "192349"
  },
  {
    "text": "back in the late '80s. ",
    "start": "192350",
    "end": "203690"
  },
  {
    "text": "So they defined various\nnotions of pseudorandomness,",
    "start": "203690",
    "end": "208980"
  },
  {
    "text": "and I want to state them. And what it turns out--\nand the surprising part is that these notions,\nthese definitions,",
    "start": "208980",
    "end": "216750"
  },
  {
    "text": "although they look\nsuperficially different, they are actually all\nequivalent to each other.",
    "start": "216750",
    "end": "223960"
  },
  {
    "text": "So let's see what\nthe theorem says.",
    "start": "223960",
    "end": "229050"
  },
  {
    "text": "So the set-up of this theorem\nis that you have some fixed",
    "start": "229050",
    "end": "234090"
  },
  {
    "text": "real p between 0 and 1. And this is going to be\nyour graph edge density.",
    "start": "234090",
    "end": "240810"
  },
  {
    "text": "So for any sequence\nof graphs, Gn--",
    "start": "240810",
    "end": "251069"
  },
  {
    "text": " so from now, I'm going\nto drop the subscript n,",
    "start": "251070",
    "end": "259940"
  },
  {
    "text": "so G will just be Gn-- such that the\nnumber of vertices--",
    "start": "259940",
    "end": "267680"
  },
  {
    "text": "so G is n vertex with\nedge density basically p.",
    "start": "267680",
    "end": "277169"
  },
  {
    "text": " So this is your\nsequence of graphs.",
    "start": "277170",
    "end": "284000"
  },
  {
    "text": "And the claim is that\nwe're going to state",
    "start": "284000",
    "end": "289860"
  },
  {
    "text": "some set of properties.  And these properties\nare all going",
    "start": "289860",
    "end": "295750"
  },
  {
    "text": "to be equivalent to each other. ",
    "start": "295750",
    "end": "303370"
  },
  {
    "text": "So all of these properties\ncapture some notion of pseudorandomness, so in what\nways this is graph G or really",
    "start": "303370",
    "end": "310139"
  },
  {
    "text": "a sequence of graphs. Or you can talk about\na specific graph and have some error\nparameters and error balance.",
    "start": "310140",
    "end": "315990"
  },
  {
    "text": "They're all roughly\nthe same ideas. So in what ways can we\ntalk about this graph G",
    "start": "315990",
    "end": "321030"
  },
  {
    "text": "being random-like? Well, we already saw one\nnotion when we discussed",
    "start": "321030",
    "end": "326570"
  },
  {
    "text": "Szemerédi's regularity lemma. And let's see that here. So this notion is\nknown as discrepancy.",
    "start": "326570",
    "end": "333930"
  },
  {
    "text": "And it says that if I restrict\nmy graph to looking only",
    "start": "333930",
    "end": "339270"
  },
  {
    "text": "at edges between some\npair of vertex sets, then the number of\nedges should be roughly",
    "start": "339270",
    "end": "346680"
  },
  {
    "text": "what you would expect\nbased on density alone. ",
    "start": "346680",
    "end": "357729"
  },
  {
    "text": "So this is basically\nthe notion that came up in epsilon regularity. This is essentially\nthe same as saying",
    "start": "357730",
    "end": "364720"
  },
  {
    "text": "that G is epsilon\nregular with itself where this epsilon now is hidden\nin this little o parameter.",
    "start": "364720",
    "end": "375889"
  },
  {
    "text": "So that's one notion\nof pseudorandomness. So here's another notion\nwhich is very similar.",
    "start": "375890",
    "end": "383000"
  },
  {
    "text": "So it's almost just a\nsemantic difference, but, OK, so I have to\ndo a little bit of work. So let me call this DISC prime.",
    "start": "383000",
    "end": "389440"
  },
  {
    "text": "So it says that if you look at\nonly edges within this set--",
    "start": "389440",
    "end": "395730"
  },
  {
    "text": "so instead of taking two\nsets, I only look at one set-- and then look at\nhow many edges are",
    "start": "395730",
    "end": "401440"
  },
  {
    "text": "in there versus how many you\nshould expect based on density alone, these two\nnumbers are also",
    "start": "401440",
    "end": "410940"
  },
  {
    "text": "very similar to each other. ",
    "start": "410940",
    "end": "420729"
  },
  {
    "text": "So let's get to something that\nlooks dramatically different. The next one, I'm\ngoing to call count.",
    "start": "420730",
    "end": "429940"
  },
  {
    "text": "So count says that\nfor every graph H, the number of labeled\ncopies of H in G--",
    "start": "429940",
    "end": "448380"
  },
  {
    "text": "OK, so labeled copies, I\nmean that the vertices of H are labeled. So for every triangle, there\nare six labeled triangles",
    "start": "448380",
    "end": "457350"
  },
  {
    "text": "that correspond to that\ntriangle in the graph. The number of labeled\ncopies of H is--",
    "start": "457350",
    "end": "464790"
  },
  {
    "text": "so what should you expect if\nthis graph were truly random? You would expect p raised\nto the number of edges of H",
    "start": "464790",
    "end": "471900"
  },
  {
    "text": "plus small error times n raised\nto number of vertices of H.",
    "start": "471900",
    "end": "481530"
  },
  {
    "text": "And just as a remark, this\nlittle o term, little o 1 term,",
    "start": "481530",
    "end": "489710"
  },
  {
    "text": "may depend on H.",
    "start": "489710",
    "end": "495600"
  },
  {
    "text": "So this condition, count,\nsays for every graph H, this is true. And by that, I mean\nfor every H, there",
    "start": "495600",
    "end": "503420"
  },
  {
    "text": "is some sequence\nof decaying errors. But that sequence\nof decaying errors may depend on your graph H. OK.",
    "start": "503420",
    "end": "514789"
  },
  {
    "text": "The next one is almost\na special case of count. It's called C4.",
    "start": "514789",
    "end": "521940"
  },
  {
    "text": "And it says that the number\nof labeled copies of C4, so the fourth cycle, is at\nmost p raised to power of 4--",
    "start": "521940",
    "end": "539410"
  },
  {
    "text": "so again, what you should\nexpect in a random setting just",
    "start": "539410",
    "end": "545810"
  },
  {
    "text": "for cycle count alone. ",
    "start": "545810",
    "end": "551740"
  },
  {
    "text": "I see, already, some\nof you are surprised. So we'll discuss that this\nis an important constraint.",
    "start": "551740",
    "end": "559589"
  },
  {
    "text": "It turns out that alone\nimplies everything, just having the correct C4 count. ",
    "start": "559590",
    "end": "567730"
  },
  {
    "text": "The next one, we\nwill call codegree. And the codegree condition\nsays that if you look at a pair",
    "start": "567730",
    "end": "577550"
  },
  {
    "text": "of vertices and look at their\nnumber of common neighbors-- in other words, their codegree--",
    "start": "577550",
    "end": "585460"
  },
  {
    "text": "then what should you\nexpect this quantity to be? So there are n\nvertices that possibly",
    "start": "585460",
    "end": "591880"
  },
  {
    "text": "could be common neighbors,\nand each one of them, if this were a random graph\nwith edge probability p,",
    "start": "591880",
    "end": "598730"
  },
  {
    "text": "then you expect the\nnumber of common neighbors to be around p squared n.",
    "start": "598730",
    "end": "603950"
  },
  {
    "text": "So the codegree condition\nis that this sum is small.",
    "start": "603950",
    "end": "610240"
  },
  {
    "text": "So most pairs of vertices have\nroughly the correct number of common neighbors.",
    "start": "610240",
    "end": "616477"
  },
  {
    "text": " So codegree is number\nof common neighbors.",
    "start": "616477",
    "end": "627793"
  },
  {
    "text": " Next, and the last one,\ncertainly not the least,",
    "start": "627793",
    "end": "634990"
  },
  {
    "text": "is eigenvalue condition. So here, we are going to denote\nby lambda 1 through lambda G",
    "start": "634990",
    "end": "650410"
  },
  {
    "text": "the eigenvalues of the\nadjacency matrix of G.",
    "start": "650410",
    "end": "658129"
  },
  {
    "text": "So we saw this object\nin the last lecture. So I include multiplicities.",
    "start": "658130",
    "end": "663940"
  },
  {
    "text": "If some eigenvalue occurs\nwith multiple times, I include it multiple times. So the eigenvalue condition\nsays that the top eigenvalue",
    "start": "663940",
    "end": "673870"
  },
  {
    "text": "is around pn and that,\nmore importantly,",
    "start": "673870",
    "end": "681720"
  },
  {
    "text": "the other eigenvalues\nare all quite small.",
    "start": "681720",
    "end": "690769"
  },
  {
    "start": "690770",
    "end": "695810"
  },
  {
    "text": "Now, for d regular graph,\nthe top eigenvalue-- and it's fine to think\nabout d regular graphs",
    "start": "695810",
    "end": "701990"
  },
  {
    "text": "if you want to get some\nintuition out of this theorem. For d regular graph,\nthe top eigenvalue",
    "start": "701990",
    "end": "707360"
  },
  {
    "text": "is equal to d, because\nthe top eigenvector is d.",
    "start": "707360",
    "end": "712860"
  },
  {
    "text": "It's the all-one vector. So top eigenvector is all-one\nvector, which has eigenvalue d.",
    "start": "712860",
    "end": "729180"
  },
  {
    "text": "And what the eigenvalue\ncondition says",
    "start": "729180",
    "end": "734310"
  },
  {
    "text": "is that all the other\neigenvalues are much smaller.",
    "start": "734310",
    "end": "747710"
  },
  {
    "text": "So here, I'm thinking of d\nas on the same order as n.",
    "start": "747710",
    "end": "753010"
  },
  {
    "text": "OK, so this is the theorem. So that's what we'll do today. We'll prove that all\nof these properties",
    "start": "753010",
    "end": "759090"
  },
  {
    "text": "are equivalent to each other. And all of these\nproperties, you should think of as characterizations\nof pseudorandomness.",
    "start": "759090",
    "end": "765812"
  },
  {
    "text": "And of course, this\ntheorem guarantees us that it doesn't matter\nwhich one you use. They're all equivalent\nto each other.",
    "start": "765812",
    "end": "771890"
  },
  {
    "text": "And our proofs are\nactually going to be-- I mean, I'm going to try to\ndo everything fairly slowly. But none of these\nproofs are difficult.",
    "start": "771890",
    "end": "778449"
  },
  {
    "text": "We're not going to use\nany fancy tools like Szemerédi's regularity lemma. In particular, all of\nthese quantitative errors",
    "start": "778450",
    "end": "786000"
  },
  {
    "text": "are reasonably\ndependent on each other. So I've stated\nthis theorem so far",
    "start": "786000",
    "end": "792060"
  },
  {
    "start": "790000",
    "end": "1110000"
  },
  {
    "text": "in this form where there\nis a little 1 error. But equivalently, so I can\nequivalently state theorem as--",
    "start": "792060",
    "end": "806030"
  },
  {
    "text": " for example, have DISC with\nan epsilon error, which",
    "start": "806030",
    "end": "817770"
  },
  {
    "text": "is that some inequality is\ntrue with at most epsilon error instead of little o.",
    "start": "817770",
    "end": "824250"
  },
  {
    "text": "And you have a different\nepsilon for each one of them. And the theorem,\nit turns out that--",
    "start": "824250",
    "end": "833009"
  },
  {
    "text": "OK, so the proof of\nthis theorem will be that these conditions\nare true, so all equivalent,",
    "start": "833010",
    "end": "840640"
  },
  {
    "text": "up to at most a polynomial\nchange in the epsilons. ",
    "start": "840640",
    "end": "853970"
  },
  {
    "text": "In other words, so\nproperty one is true for epsilon implies\nthat property two is",
    "start": "853970",
    "end": "862639"
  },
  {
    "text": "true for some epsilon\nraised to a constant. So the changes in parameters\nare quite reasonable.",
    "start": "862640",
    "end": "870240"
  },
  {
    "text": "And we'll see this\nfrom the proof, but I won't say it\nagain explicitly.",
    "start": "870240",
    "end": "876865"
  },
  {
    "text": "Any questions so far about\nthe statement of this theorem? ",
    "start": "876865",
    "end": "886870"
  },
  {
    "text": "So as I mentioned just now,\nthe most surprising part of this theorem\nand the one that I",
    "start": "886870",
    "end": "892450"
  },
  {
    "text": "want you to pay the\nmost attention to is the C4 condition.",
    "start": "892450",
    "end": "897870"
  },
  {
    "text": "This seems, at\nleast at face value, the weakest condition\namong all of them.",
    "start": "897870",
    "end": "903660"
  },
  {
    "text": "It just says the\ncorrect C4 count. But it turns out to be\nequivalent to everything else.",
    "start": "903660",
    "end": "910433"
  },
  {
    "text": "And there's something\nspecial about C4, right? If I replace C4 by C3, by just\ntriangles, then it is not true.",
    "start": "910433",
    "end": "916810"
  },
  {
    "text": "So I want you to think\nabout, where does C4 play this important role?",
    "start": "916810",
    "end": "922300"
  },
  {
    "text": "How does it play\nthis important role? OK. So let's get started\nwith a proof.",
    "start": "922300",
    "end": "929450"
  },
  {
    "text": "But before that, let me-- so in this proof,\none recurring theme",
    "start": "929450",
    "end": "935288"
  },
  {
    "text": "is that we're going to be using\nthe Cauchy-Schwarz inequality many times. And I want to just begin with\nan exercise that gives you",
    "start": "935288",
    "end": "941339"
  },
  {
    "text": "some familiarity with applying\nthe Cauchy-Schwarz inequality. And this is a simple tool,\nbut it's extremely powerful.",
    "start": "941340",
    "end": "947400"
  },
  {
    "text": "And it's worthwhile\nto master how to use a Cauchy-Schwarz inequality. So let's get some practice.",
    "start": "947400",
    "end": "954660"
  },
  {
    "text": "And let me prove a claim\nwhich is not directly related",
    "start": "954660",
    "end": "961879"
  },
  {
    "text": "to the proof of the\ntheorem, but it's indirect in that it explains\nsomewhat the C4 condition",
    "start": "961880",
    "end": "968519"
  },
  {
    "text": "and why we have less than\nor equal to over there. ",
    "start": "968520",
    "end": "974300"
  },
  {
    "text": "So the lemma is that if\nyou have a graph on n vertices such that the number\nof edges is at least pn",
    "start": "974300",
    "end": "987500"
  },
  {
    "text": "squared over 2, so edge\ndensity basically p, then",
    "start": "987500",
    "end": "993950"
  },
  {
    "text": "the number of labeled copies of\nC4 is at least p to the 4 minus",
    "start": "993950",
    "end": "1008500"
  },
  {
    "text": "little o 1 n to the 4th. ",
    "start": "1008500",
    "end": "1016020"
  },
  {
    "text": "So if you have a graph\nwith each density p-- p's your constant--\nthen the number of C4s",
    "start": "1016020",
    "end": "1021149"
  },
  {
    "text": "is at least roughly what you\nwould expect in a random graph. ",
    "start": "1021150",
    "end": "1027662"
  },
  {
    "text": "So let's see how to do this.  And I want to show\nthis inequality as a--",
    "start": "1027662",
    "end": "1034530"
  },
  {
    "text": "well, I'll show you how\nto prove this inequality. But I also want to draw a\nsequence of pictures, at least,",
    "start": "1034530",
    "end": "1040470"
  },
  {
    "text": "to explain how I think\nabout applications of the Cauchy-Schwarz\ninequality.",
    "start": "1040470",
    "end": "1046540"
  },
  {
    "text": "OK. So the first thing\nis that we are",
    "start": "1046540",
    "end": "1052810"
  },
  {
    "text": "counting labeled copies of C4. And this is basically but\nnot exactly the same as",
    "start": "1052810",
    "end": "1058870"
  },
  {
    "text": "number of homomorphic copies of\nC4 and G. So by this guy here,",
    "start": "1058870",
    "end": "1064270"
  },
  {
    "text": "I really just mean you are\nmapping vertices of C4 to G",
    "start": "1064270",
    "end": "1070300"
  },
  {
    "text": "so that the edges\nall map to edges. But we are allowing not\nnecessarily injective maps,",
    "start": "1070300",
    "end": "1083950"
  },
  {
    "text": "C4 to G. But that's OK. So the number of non-injective\nmaps is at most cubic.",
    "start": "1083950",
    "end": "1095260"
  },
  {
    "text": "So we're not really\naffecting our count. So it's enough to think\nabout homomorphic copies.",
    "start": "1095260",
    "end": "1100635"
  },
  {
    "start": "1100635",
    "end": "1106460"
  },
  {
    "text": "OK. So what's going on here? So let me draw a\nsequence of pictures illustrating this calculation.",
    "start": "1106460",
    "end": "1112679"
  },
  {
    "text": "So first, we are thinking\nabout counting C4s.",
    "start": "1112680",
    "end": "1118450"
  },
  {
    "text": "So that's a C4.  I can rewrite the C4 count as a\nsum over pairs of vertices of G",
    "start": "1118450",
    "end": "1131880"
  },
  {
    "text": "as the squared codegree. ",
    "start": "1131880",
    "end": "1139850"
  },
  {
    "text": "And what happens\nhere-- so this is true. I mean, it's not hard\nto see why this is true. But I want to draw\nthis in pictures,",
    "start": "1139850",
    "end": "1147049"
  },
  {
    "text": "because when you have\nlarger and bigger graphs, it may be more difficult\nto think about the algebra",
    "start": "1147050",
    "end": "1152090"
  },
  {
    "text": "unless you have\nsome visualization. So what happens here is that\nI notice that the C4 has",
    "start": "1152090",
    "end": "1159820"
  },
  {
    "text": "a certain reflection. Namely, it has a reflection\nalong this horizontal line.",
    "start": "1159820",
    "end": "1168679"
  },
  {
    "text": "And so if I put these\ntwo vertices as u and v,",
    "start": "1168680",
    "end": "1175210"
  },
  {
    "text": "then this reflection\ntells you that you can write this number\nof homomorphic copies",
    "start": "1175210",
    "end": "1182590"
  },
  {
    "text": "as the sum of squares.  But once you have this\nreflection-- and reflections",
    "start": "1182590",
    "end": "1188850"
  },
  {
    "text": "are super useful,\nbecause they allow us to get something\ninto a square and then, right after, apply\nthe Cauchy-Schwarz inequality.",
    "start": "1188850",
    "end": "1198260"
  },
  {
    "text": "So we apply Cauchy-Schwarz here. And we obtain that this\nsum is at most where",
    "start": "1198260",
    "end": "1209370"
  },
  {
    "text": "I can pull the square out.",
    "start": "1209370",
    "end": "1218059"
  },
  {
    "text": "And I need to think about\nwhat is the correct factor",
    "start": "1218060",
    "end": "1223210"
  },
  {
    "text": "to put out here. And that should be-- ",
    "start": "1223210",
    "end": "1230710"
  },
  {
    "text": "so what's the correct factor\nthat I should put out there? AUDIENCE: 1 over n squared.",
    "start": "1230710",
    "end": "1235960"
  },
  {
    "text": "PROFESSOR: OK, so\n1 over n squared. So I don't actually like doing\nthese kind of calculations",
    "start": "1235960",
    "end": "1242700"
  },
  {
    "text": "with sums, because then\nyou have to keep track of these normalizing factors. One of the upcoming chapters,\nwhen we discuss graph limits--",
    "start": "1242700",
    "end": "1250890"
  },
  {
    "text": "or in fact, you\ncan even do this. Instead of taking sums,\nif you take an average, if you take an expectation,\nthen it turns out",
    "start": "1250890",
    "end": "1256680"
  },
  {
    "text": "you never have to worry about\nthese normalizing factors. So normalizing factors\nshould never bother you",
    "start": "1256680",
    "end": "1263220"
  },
  {
    "text": "if you do it correctly. But just to make sure\nthings are correct, please keep me in check.",
    "start": "1263220",
    "end": "1270549"
  },
  {
    "text": "All right. So what happened in this step? In this step, we\npulled out that square.",
    "start": "1270550",
    "end": "1275700"
  },
  {
    "text": "And pictorially, what\nhappens is that we got rid of half of this picture. ",
    "start": "1275700",
    "end": "1286549"
  },
  {
    "text": "So we used Cauchy-Schwarz,\nand we wiped out half of the picture. ",
    "start": "1286550",
    "end": "1292850"
  },
  {
    "text": "And now what we can\ndo is, well, we're counting these guys,\nthis path of length 2.",
    "start": "1292850",
    "end": "1299540"
  },
  {
    "text": "But I can reprioritize\nthis picture so that it looks like that.",
    "start": "1299540",
    "end": "1307410"
  },
  {
    "text": "And now I notice that there\nis one more reflection. So there's one more reflection.",
    "start": "1307410",
    "end": "1312710"
  },
  {
    "text": "And that's the reflection\naround the vertical axis. ",
    "start": "1312710",
    "end": "1317890"
  },
  {
    "text": "So let me call\nthis top vertex x. And I can rewrite\nthe sum like that.",
    "start": "1317890",
    "end": "1331916"
  },
  {
    "start": "1331916",
    "end": "1338220"
  },
  {
    "text": "OK. So once more, we\ndo Cauchy-Schwarz, which allows us to get rid\nof half of the picture.",
    "start": "1338220",
    "end": "1344950"
  },
  {
    "text": "And now I'm going to\ndraw the picture first, because then you see that\nwhat we should be left with",
    "start": "1344950",
    "end": "1350600"
  },
  {
    "text": "is just a single edge. And then you write\ndown the correct sum,",
    "start": "1350600",
    "end": "1357720"
  },
  {
    "text": "making sure that all the\nparentheses and normalizations are correct.",
    "start": "1357720",
    "end": "1363580"
  },
  {
    "text": "But somehow, that\ndoesn't worry me so much, because I know this will\ndefinitely work out.",
    "start": "1363580",
    "end": "1368970"
  },
  {
    "text": " But whatever it is, you're just\nsumming the number of edges.",
    "start": "1368970",
    "end": "1375750"
  },
  {
    "text": "So that's just the\nnumber of edges. And so we put everything in.",
    "start": "1375750",
    "end": "1389950"
  },
  {
    "text": "And we find that the final\nquantity is at least p raised to 4 n to 4.",
    "start": "1389950",
    "end": "1397150"
  },
  {
    "text": "So I did this quite slowly. But I'm also emphasizing the\nsequence of pictures, partly",
    "start": "1397150",
    "end": "1403540"
  },
  {
    "text": "to tell how I think\nabout these inequalities. Because for other similar\nlooking inequalities-- in fact,",
    "start": "1403540",
    "end": "1409940"
  },
  {
    "text": "there is something called\nSidorenko's conjecture, which I may discuss more in\na future lecture, that",
    "start": "1409940",
    "end": "1416350"
  },
  {
    "text": "says that this\nkind of inequality should be true\nwhenever you replace C4",
    "start": "1416350",
    "end": "1421540"
  },
  {
    "text": "by any bipartite graph. And that's a major open\nproblem in combinatorics.",
    "start": "1421540",
    "end": "1427680"
  },
  {
    "text": "It's kind of hard to keep\ntrack of these calculations unless you have a visual anchor. And this is my visual anchor,\nwhich I'm trying to explain.",
    "start": "1427680",
    "end": "1435600"
  },
  {
    "text": "Of course, it's down to earth. It's just the sequence\nof inequalities. And this is also some\npractice with Cauchy-Schwarz.",
    "start": "1435600",
    "end": "1444924"
  },
  {
    "text": "All right. Any questions? ",
    "start": "1444924",
    "end": "1450782"
  },
  {
    "text": "But one thing that\nthis calculation told us is that if you\nhave edge density p, then you necessarily have C4\ndensity at least p to the 4th.",
    "start": "1450782",
    "end": "1460790"
  },
  {
    "text": "So that partly explains why\nyou have at most, then, here. So you always know that\nit's at least this quantity.",
    "start": "1460790",
    "end": "1468030"
  },
  {
    "text": "So the C4 quasi\nrandomness condition is really the equivalent\nto replacing this less than",
    "start": "1468030",
    "end": "1474260"
  },
  {
    "text": "or equal to by an equal sign. ",
    "start": "1474260",
    "end": "1480009"
  },
  {
    "text": "So let's get\nstarted with proving the Chung-Graham-Wilson theorem. So the first place\nthat we'll look at",
    "start": "1480010",
    "end": "1486220"
  },
  {
    "text": "is the two versions of DISC. So DISC stands for discrepancy.",
    "start": "1486220",
    "end": "1491610"
  },
  {
    "text": " So first, the fact that DISC\nimplies DISC prime, I mean,",
    "start": "1491610",
    "end": "1500720"
  },
  {
    "text": "this is pretty easy. You take y to equal to x. Be slightly careful about the\ndefinitions, but you're OK.",
    "start": "1500720",
    "end": "1510159"
  },
  {
    "text": "So not much to do there. The other direction,\nwhere you only",
    "start": "1510160",
    "end": "1520049"
  },
  {
    "text": "have discrepancies\nfor a single set and you want to\nproduce discrepancies for pairs of sets--",
    "start": "1520050",
    "end": "1525570"
  },
  {
    "text": "so this is actually a fairly\ncommon technique in algebra that allows you to go\nfrom bilinear forms",
    "start": "1525570",
    "end": "1531570"
  },
  {
    "text": "to quadratic forms\nand vice versa. It's that kind of calculation. So let me do it here\nconcretely in this setting.",
    "start": "1531570",
    "end": "1537640"
  },
  {
    "text": "So here, what you\nshould think of is that you have two sets, x\nand y, and they might overlap.",
    "start": "1537640",
    "end": "1545680"
  },
  {
    "text": "And what they\ncorrespond to in the--",
    "start": "1545680",
    "end": "1552290"
  },
  {
    "text": "when you think about the\ncorresponding Venn diagram, where I'm looking at ways\nthat a pair of vertices",
    "start": "1552290",
    "end": "1563130"
  },
  {
    "text": "can fall in x and/or y-- so if you have x and y.",
    "start": "1563130",
    "end": "1568410"
  },
  {
    "start": "1568410",
    "end": "1574410"
  },
  {
    "text": "And so it's useful to keep\ntrack of which vertices",
    "start": "1574410",
    "end": "1582360"
  },
  {
    "text": "are in which set. But what the thing\nfinally comes down to is that the number of edges\nwith one vertex in x and one",
    "start": "1582360",
    "end": "1591240"
  },
  {
    "text": "vertex in y, I can write this\nbilinear form-type quantity as an appropriate sum of just\nnumber of edges in single sets.",
    "start": "1591240",
    "end": "1610540"
  },
  {
    "start": "1610540",
    "end": "1617040"
  },
  {
    "text": "And so there are several ways\nto check that this is true. One way is to just tally,\nkeep track of how many edges",
    "start": "1617040",
    "end": "1624980"
  },
  {
    "text": "are you counting in each step. So if you are trying to count\nthe number of edges in--",
    "start": "1624980",
    "end": "1634330"
  },
  {
    "text": " yeah, so let's say if\nyou're trying to count",
    "start": "1634330",
    "end": "1641140"
  },
  {
    "text": "the number of edges in-- ",
    "start": "1641140",
    "end": "1646380"
  },
  {
    "text": "with one vertex in\nx, one vertex in y. Then what this corresponds\nto is that count.",
    "start": "1646380",
    "end": "1654570"
  },
  {
    "text": "But let me do a reflection. ",
    "start": "1654570",
    "end": "1661760"
  },
  {
    "text": "And then you see that\nyou can write this sum as an alternating sum\nof principal squares,",
    "start": "1661760",
    "end": "1669490"
  },
  {
    "text": "so this one big square plus the\nmiddle square and minus the two",
    "start": "1669490",
    "end": "1675070"
  },
  {
    "text": "sides squares, which is\nwhat that sum comes to.",
    "start": "1675070",
    "end": "1682080"
  },
  {
    "text": "All right. So if we assume\nDISC prime, then I know that all of\nthese individual sets",
    "start": "1682080",
    "end": "1688560"
  },
  {
    "text": "have roughly the correct number\nof edges up to a little o of n",
    "start": "1688560",
    "end": "1713520"
  },
  {
    "text": "squared error. And again, I don't have to\ndo this calculation again, because it's the\nsame calculation.",
    "start": "1713520",
    "end": "1719440"
  },
  {
    "text": "So the final thing should be\np times the sizes of x and y together plus this same error.",
    "start": "1719440",
    "end": "1727420"
  },
  {
    "start": "1727420",
    "end": "1732770"
  },
  {
    "text": "So that shows you DISC\nprime implies DISC. So the self version\nof discrepancy implies the pair\nversion of discrepancy.",
    "start": "1732770",
    "end": "1739394"
  },
  {
    "text": " So let's move on to count.",
    "start": "1739394",
    "end": "1744850"
  },
  {
    "start": "1744850",
    "end": "1750820"
  },
  {
    "start": "1750000",
    "end": "2246000"
  },
  {
    "text": "To show that DISC\nimplies count-- ",
    "start": "1750820",
    "end": "1760180"
  },
  {
    "text": "actually, we already did this. So this is the counting lemma. ",
    "start": "1760180",
    "end": "1771240"
  },
  {
    "text": "So the counting\nlemma tells us how to count labeled copies if you\nhave these epsilon regularity",
    "start": "1771240",
    "end": "1778430"
  },
  {
    "text": "conditions, which is\nexactly what DISC is. ",
    "start": "1778430",
    "end": "1784600"
  },
  {
    "text": "So count is good. Another easy implication\nis count implies C4.",
    "start": "1784600",
    "end": "1795210"
  },
  {
    "text": "Well, this is actually\njust tautological. C4 condition is a special\ncase of the count hypothesis.",
    "start": "1795210",
    "end": "1804610"
  },
  {
    "text": " All right. So let's move on to some\nadditional implications that",
    "start": "1804610",
    "end": "1815090"
  },
  {
    "text": "require a bit more work. So what about C4\nimplies codegree? ",
    "start": "1815090",
    "end": "1826730"
  },
  {
    "text": "So this is where we\nneed to do this kind of Cauchy-Schwarz exercise. So let's start with C4.",
    "start": "1826730",
    "end": "1833779"
  },
  {
    "text": "So assume a C4 condition. And suppose you have this--",
    "start": "1833780",
    "end": "1842130"
  },
  {
    "start": "1842130",
    "end": "1847650"
  },
  {
    "text": "so I want to deduce that the\ncodegree condition is true. But first, let's\nthink about just",
    "start": "1847650",
    "end": "1856500"
  },
  {
    "text": "what is the sum\nof these codegrees as I vary u and v over\nall pairs of vertices.",
    "start": "1856500",
    "end": "1862050"
  },
  {
    "text": " So this is that picture.",
    "start": "1862050",
    "end": "1871000"
  },
  {
    "text": "So that is equal to the sums\nof degrees squared, which now,",
    "start": "1871000",
    "end": "1878390"
  },
  {
    "text": "by Cauchy-Schwarz, you can\ndeduce to be at least n times 2",
    "start": "1878390",
    "end": "1884090"
  },
  {
    "text": "raised to number\nof edges-- namely, the sum of the degrees-- that thing squared.",
    "start": "1884090",
    "end": "1889710"
  },
  {
    "text": " So now we assume\nthe C4 condition--",
    "start": "1889710",
    "end": "1897400"
  },
  {
    "text": "actually, no, we assume that G\nhas the density as written up there. So this quantity is p\nsquared plus little 1 times",
    "start": "1897400",
    "end": "1911890"
  },
  {
    "text": "n cubed, which is\nwhat you should expect in a random graph of Gnp. ",
    "start": "1911890",
    "end": "1919020"
  },
  {
    "text": "But that's not quite\nwhat we're looking for. So this is just the\nsum of the codegrees. What we actually\nwant is the deviation",
    "start": "1919020",
    "end": "1928110"
  },
  {
    "text": "of codegrees from its\nexpectations, so to speak.",
    "start": "1928110",
    "end": "1934120"
  },
  {
    "text": "Now, here's an\nimportant technique from probabilistic\ncombinatorics is",
    "start": "1934120",
    "end": "1939360"
  },
  {
    "text": "that if you want to control the\ndeviation of a random variable,",
    "start": "1939360",
    "end": "1945920"
  },
  {
    "text": "one thing you should\nlook at is the variance. So if you can\ncontrol the variance, then you can control\nthe deviation.",
    "start": "1945920",
    "end": "1952442"
  },
  {
    "text": "And this is a method known\nas a second moment method. And that's what we're\ngoing to do here. So what we'll try to show is\nthat the second moment of these",
    "start": "1952442",
    "end": "1964470"
  },
  {
    "text": "codegrees-- namely, the sum\nof their squares-- is also what you should expect\nas if the random setting.",
    "start": "1964470",
    "end": "1973060"
  },
  {
    "text": "And then you can put them\ntogether to show what you want. So this quantity here,\nwell, what is this?",
    "start": "1973060",
    "end": "1981370"
  },
  {
    "text": "We just saw-- see, up there,\nit's also codegree squared.",
    "start": "1981370",
    "end": "1988790"
  },
  {
    "text": "So this quantity\nis also the number of labeled copies of C4-- ",
    "start": "1988790",
    "end": "1999280"
  },
  {
    "text": "not quite, because you\nmight have two vertices and the same vertex.",
    "start": "1999280",
    "end": "2005390"
  },
  {
    "text": "So I incorporate a small error.",
    "start": "2005390",
    "end": "2010430"
  },
  {
    "text": "So it's a cubic error, but\nit's certainly sub n to the 4.",
    "start": "2010430",
    "end": "2017420"
  },
  {
    "text": "And we assume that the number of\nlabeled copies of C4 by the C4",
    "start": "2017420",
    "end": "2022640"
  },
  {
    "text": "condition is no more than\nbasically p to the 4 times",
    "start": "2022640",
    "end": "2028520"
  },
  {
    "text": "n raised to power 4. ",
    "start": "2028520",
    "end": "2035495"
  },
  {
    "text": "OK. So now you have a first moment. You have some average,\nand you have some control. In the second moment,\nI can put them together",
    "start": "2035495",
    "end": "2042920"
  },
  {
    "text": "to bound the deviation\nusing this idea of controlling variance. ",
    "start": "2042920",
    "end": "2049920"
  },
  {
    "text": "So the codegree deviation\nis upper bounded by--",
    "start": "2049921",
    "end": "2061059"
  },
  {
    "text": "so here, using\nCauchy-Schwarz, it's upper bounded by basically\nthe same sum, except I",
    "start": "2061060",
    "end": "2067739"
  },
  {
    "text": "want to square the summand. ",
    "start": "2067739",
    "end": "2082535"
  },
  {
    "text": "This also gets rid of\nthe pesky absolute value side, which is not nicely,\nalgebraically behaved.",
    "start": "2082536",
    "end": "2088399"
  },
  {
    "text": "OK. So now I have the square,\nand I can expand the square. ",
    "start": "2088400",
    "end": "2100810"
  },
  {
    "text": "So I expand the square\ninto these terms. ",
    "start": "2100810",
    "end": "2114910"
  },
  {
    "text": "And the final term here\nis p to the 4 n to the 6.",
    "start": "2114910",
    "end": "2120224"
  },
  {
    "text": " No, n to the 4.",
    "start": "2120225",
    "end": "2126360"
  },
  {
    "text": " All right.",
    "start": "2126360",
    "end": "2132730"
  },
  {
    "text": "But I have controlled\nthe individual terms from the calculations above.",
    "start": "2132730",
    "end": "2138630"
  },
  {
    "text": "So I can upper bound\nthis expression",
    "start": "2138630",
    "end": "2143660"
  },
  {
    "text": "by what I'm writing down now. ",
    "start": "2143660",
    "end": "2154540"
  },
  {
    "text": "And basically, you should\nexpect that everything should cancel out,\nbecause they do cancel out",
    "start": "2154540",
    "end": "2161760"
  },
  {
    "text": "in the random case. Of course, the\nsanity check, it's important to write\ndown this calculation.",
    "start": "2161760",
    "end": "2167475"
  },
  {
    "text": "So if everything\nworks out right, everything should cancel out. And indeed, they do cancel out. And you get that--",
    "start": "2167475",
    "end": "2174582"
  },
  {
    "text": "so this is a multiplication.",
    "start": "2174583",
    "end": "2180020"
  },
  {
    "text": "This is p squared. Is that OK?",
    "start": "2180020",
    "end": "2186800"
  },
  {
    "text": "So everything should cancel out. And you get a\nlittle o of n cubed.",
    "start": "2186800",
    "end": "2194320"
  },
  {
    "text": "To summarize, in this\nimplication from C4 to codegree, what\nwe're doing is we're",
    "start": "2194320",
    "end": "2203750"
  },
  {
    "text": "controlling the\nvariance of codegrees using the C4 condition and\nthe second moment bound,",
    "start": "2203750",
    "end": "2213950"
  },
  {
    "text": "showing that the\nC4 condition trumps over the codegree condition. ",
    "start": "2213950",
    "end": "2221830"
  },
  {
    "text": "Any questions so far? ",
    "start": "2221830",
    "end": "2228100"
  },
  {
    "text": "So I'll let you ponder\nin this calculation. The next one that we'll do\nis codegree implies DISC.",
    "start": "2228100",
    "end": "2235390"
  },
  {
    "text": "And that will be a calculation\nin a very similar flavor.",
    "start": "2235390",
    "end": "2240992"
  },
  {
    "text": "But it will be a slightly\nlonger but with similar flavor of calculation. So let me do that\nafter the break.",
    "start": "2240992",
    "end": "2247384"
  },
  {
    "start": "2246000",
    "end": "2349000"
  },
  {
    "text": "All right. So what have we done so far? So let's summarize the\nchain of implications",
    "start": "2247384",
    "end": "2254079"
  },
  {
    "text": "that we have already proved. So first, we\nstarted with showing that the two versions\nof DISC are equivalent.",
    "start": "2254080",
    "end": "2263545"
  },
  {
    "text": " And then we also noticed\nthat DISC implies count",
    "start": "2263545",
    "end": "2275610"
  },
  {
    "text": "through the counting lemma. So we also observed that count\nimplies C4 tautologically",
    "start": "2275610",
    "end": "2286089"
  },
  {
    "text": "and C4 implies codegree. ",
    "start": "2286090",
    "end": "2294670"
  },
  {
    "text": "So the next natural thing to\ndo is to complete this circuit and show that the\ncodegree condition implies",
    "start": "2294670",
    "end": "2301400"
  },
  {
    "text": "the discrepancy condition. So that's what we'll do next. ",
    "start": "2301400",
    "end": "2308760"
  },
  {
    "text": "And in some sense,\nthese two steps, you should think of them as\ngoing in this natural chain,",
    "start": "2308760",
    "end": "2315660"
  },
  {
    "text": "where C4-- so C4 is like this, C4.",
    "start": "2315660",
    "end": "2323200"
  },
  {
    "text": "Codegree condition\nis really about that. And DISC is really\nabout single edges.",
    "start": "2323200",
    "end": "2329220"
  },
  {
    "text": "So you can go from-- so double-- if you half,\nyou get much more power.",
    "start": "2329220",
    "end": "2335520"
  },
  {
    "text": "So it's going in\nthe right direction, going downstream, so to speak. So that's what we're doing\nnow, going downstream.",
    "start": "2335520",
    "end": "2343470"
  },
  {
    "text": "And then you go upstream\nvia the counting lemma. ",
    "start": "2343470",
    "end": "2348523"
  },
  {
    "text": "All right. Let's do codegree implies DISC. ",
    "start": "2348523",
    "end": "2364670"
  },
  {
    "start": "2349000",
    "end": "2865000"
  },
  {
    "text": "So we want to show the\ndiscrepancy condition, which is one written up there.",
    "start": "2364670",
    "end": "2370309"
  },
  {
    "text": "But before that, let\nme first show you that the degrees do\nnot vary too much,",
    "start": "2370310",
    "end": "2376460"
  },
  {
    "text": "show that the degrees are\nfairly well distributed, which is what you should\nexpect in a pseudorandom graph.",
    "start": "2376460",
    "end": "2382580"
  },
  {
    "text": "So you don't expect the half\nthe vertices, half in degrees, twice the other half.",
    "start": "2382580",
    "end": "2388500"
  },
  {
    "text": "So that's the first thing\nI want to establish. ",
    "start": "2388500",
    "end": "2393920"
  },
  {
    "text": "If you look at degrees, this\nvariance, this deviation,",
    "start": "2393920",
    "end": "2402910"
  },
  {
    "text": "is not too big. OK. So like before, we see\nan absolute value sign.",
    "start": "2402910",
    "end": "2409450"
  },
  {
    "text": "We see a sum. So we'll do Cauchy-Schwarz. Cauchy-Schwarz allows us\nto bound this quantity,",
    "start": "2409450",
    "end": "2416630"
  },
  {
    "text": "replacing the summand\nby a sum of squared. ",
    "start": "2416630",
    "end": "2433210"
  },
  {
    "text": "I have a square, so I\ncan expand the square. ",
    "start": "2433210",
    "end": "2441060"
  },
  {
    "text": "So let me expand the square. And I get that, so just\nexpanding this square inside.",
    "start": "2441060",
    "end": "2462020"
  },
  {
    "text": " And you see this degree\nsquared is that picture, so",
    "start": "2462020",
    "end": "2470260"
  },
  {
    "text": "that sum of codegrees. ",
    "start": "2470260",
    "end": "2484280"
  },
  {
    "text": "And sum of the degrees is\njust the number of edges. ",
    "start": "2484280",
    "end": "2499630"
  },
  {
    "text": "But we now assume the\ncodegree condition, which in particular implies\nthat the sum of the codegrees",
    "start": "2499630",
    "end": "2506205"
  },
  {
    "text": "is roughly what\nyou would expect.  So the sum of the\ncodegrees should",
    "start": "2506205",
    "end": "2512170"
  },
  {
    "text": "be p squared n cubed plus\na little o n cubed error",
    "start": "2512170",
    "end": "2518650"
  },
  {
    "text": "at the end. Likewise, the number of\nedges is, by assumption,",
    "start": "2518650",
    "end": "2525630"
  },
  {
    "text": "what you would expect\nin a random graph. And then the final term.",
    "start": "2525630",
    "end": "2533480"
  },
  {
    "text": "And like before-- and of\ncourse, it's good to do a sanity check-- everything should cancel out.",
    "start": "2533480",
    "end": "2539750"
  },
  {
    "text": "So what you end up with\nis little o of n squared,",
    "start": "2539750",
    "end": "2545310"
  },
  {
    "text": "showing that the degrees\ndo not vary too much. And once you have\nthat promise, then we",
    "start": "2545310",
    "end": "2551790"
  },
  {
    "text": "move onto the actual\ndiscrepancy condition. ",
    "start": "2551790",
    "end": "2561570"
  },
  {
    "text": "So this discrepancy\ncan be rewritten",
    "start": "2561570",
    "end": "2567850"
  },
  {
    "text": "as the sum over vertices\nlittle x and big X, the degree",
    "start": "2567850",
    "end": "2577760"
  },
  {
    "text": "from little x to y minus\np times the size of y,",
    "start": "2577760",
    "end": "2588212"
  },
  {
    "text": "so rewriting the sum. And of course, what\nshould we do next?",
    "start": "2588212",
    "end": "2596090"
  },
  {
    "text": "Cauchy-Schwarz. Great. So we'll do a Cauchy-Schwarz. OK, so here's an important\nstep or trick, if you will.",
    "start": "2596090",
    "end": "2606180"
  },
  {
    "text": "So we'll do Cauchy-Schwarz. And something very nice happens\nwhen you do Cauchy-Schwarz",
    "start": "2606180",
    "end": "2614070"
  },
  {
    "text": "here. OK. So you can write\ndown the expression that you obtain when\nyou do Cauchy-Schwarz.",
    "start": "2614070",
    "end": "2620070"
  },
  {
    "text": "So let me do that first. ",
    "start": "2620070",
    "end": "2627490"
  },
  {
    "text": "OK. So here's a step which is\nvery easy to gloss over. But I want to pause and\nemphasize this step,",
    "start": "2627490",
    "end": "2633599"
  },
  {
    "text": "because this is actually\nreally important. What I'm going to do now is\nto observe that the summand is",
    "start": "2633600",
    "end": "2640250"
  },
  {
    "text": "always non-negative. ",
    "start": "2640250",
    "end": "2647390"
  },
  {
    "text": "Therefore, I can enlarge\nthe sum from just little x",
    "start": "2647390",
    "end": "2654740"
  },
  {
    "text": "and X to the entire vertex set. And this is important, right?",
    "start": "2654740",
    "end": "2659750"
  },
  {
    "text": "So it's important that we\nhad to do Cauchy-Schwarz first to get a\nnon-negative summand. You couldn't do this\nin the beginning.",
    "start": "2659750",
    "end": "2665525"
  },
  {
    "text": " So you do that.",
    "start": "2665525",
    "end": "2672450"
  },
  {
    "text": "And so I have this\nsum of squares. I expand. ",
    "start": "2672450",
    "end": "2683300"
  },
  {
    "text": "I expand. I write out all\nthese expressions. ",
    "start": "2683300",
    "end": "2697300"
  },
  {
    "text": "And now the little x range\nover the entire vertex set. ",
    "start": "2697300",
    "end": "2715714"
  },
  {
    "text": "All right. So what was the\npoint of all of that?",
    "start": "2715715",
    "end": "2720780"
  },
  {
    "text": "So you see this expression\nhere, the degree from little x to big Y\nsquared, what is that?",
    "start": "2720780",
    "end": "2731870"
  },
  {
    "text": "How can we rewrite\nthis expression? ",
    "start": "2731870",
    "end": "2738550"
  },
  {
    "text": "So counting little x\nand then Y squared-- ",
    "start": "2738550",
    "end": "2745990"
  },
  {
    "text": "AUDIENCE: Sum over u and big Y. PROFESSOR: Yeah. So sum of codegree\nof two vertices in Y,",
    "start": "2745990",
    "end": "2756064"
  },
  {
    "text": "so Y, Y prime, and Y codegree\nof little y, little y prime.",
    "start": "2756064",
    "end": "2763570"
  },
  {
    "start": "2763570",
    "end": "2769320"
  },
  {
    "text": "And likewise, the\nnext expression",
    "start": "2769320",
    "end": "2775240"
  },
  {
    "text": "can be written as the sum of\nthe degrees of vertices in Y.",
    "start": "2775240",
    "end": "2783880"
  },
  {
    "text": "And the third term,\nI leave unchanged. So now we've gotten rid\nof these funny expressions",
    "start": "2783880",
    "end": "2792609"
  },
  {
    "text": "where it's just degree\nfrom the vertex to a set. And we could do this because\nof this relaxation up here.",
    "start": "2792610",
    "end": "2800320"
  },
  {
    "text": "So that was the point. We had to use this\nrelaxation so that we get these codegree terms.",
    "start": "2800320",
    "end": "2806140"
  },
  {
    "text": "But now, because you\nhave the codegree terms and we assume the\ncodegree hypothesis,",
    "start": "2806140",
    "end": "2811600"
  },
  {
    "text": "we obtain that\nthis sum is roughly what you expect as in a\nrandom case, because all",
    "start": "2811600",
    "end": "2820480"
  },
  {
    "text": "the individual deviations do\nnot add up to more than little",
    "start": "2820480",
    "end": "2825515"
  },
  {
    "text": "o n cubed. ",
    "start": "2825515",
    "end": "2831150"
  },
  {
    "text": "That codegree sum\nis what you expect. And the next term,\nthe sum of degrees,",
    "start": "2831150",
    "end": "2839040"
  },
  {
    "text": "is also, by what we did\nup there, what you expect. ",
    "start": "2839040",
    "end": "2849315"
  },
  {
    "text": "And finally, the third term. ",
    "start": "2849315",
    "end": "2854329"
  },
  {
    "text": "And as earlier, if you\ndid everything correctly, everything should cancel. And they do.",
    "start": "2854330",
    "end": "2860780"
  },
  {
    "text": "And so what you get at the\nend is little o of n squared. ",
    "start": "2860780",
    "end": "2872020"
  },
  {
    "start": "2865000",
    "end": "3235000"
  },
  {
    "text": "This completes\nthis fourth cycle. ",
    "start": "2872020",
    "end": "2879654"
  },
  {
    "text": "Any questions so far? ",
    "start": "2879655",
    "end": "2886160"
  },
  {
    "text": "So we're missing\none more condition, and that's the\neigenvalue condition.",
    "start": "2886160",
    "end": "2891980"
  },
  {
    "text": "So far, everything had to do\nwith counting various things. So what does eigenvalue\nhave to do with anything?",
    "start": "2891980",
    "end": "2897970"
  },
  {
    "text": " So the eigenvalue\ncondition is actually",
    "start": "2897970",
    "end": "2905359"
  },
  {
    "text": "a particularly important one. And we'll see more of\nthis in the next lecture. But let me first show you\nthe equivalent implications.",
    "start": "2905360",
    "end": "2912300"
  },
  {
    "text": "So what we'll show is that\nthe eigenvalue condition is equivalent to the C4 condition.",
    "start": "2912300",
    "end": "2917660"
  },
  {
    "text": "So that's the goal. So I'll show equivalence\nbetween EIG and C4. ",
    "start": "2917660",
    "end": "2926250"
  },
  {
    "text": "So first, it implies a C4\ncondition, because up to--",
    "start": "2926250",
    "end": "2932050"
  },
  {
    "text": "so instead of\ncounting C4s, which is a little bit actually not-- it's a bit annoying\nto do actual C4s.",
    "start": "2932050",
    "end": "2939780"
  },
  {
    "text": "Just like earlier, we want to\nconsider homomorphic copies, which are also labeled walks,\nso closed walks of length 4.",
    "start": "2939780",
    "end": "2949420"
  },
  {
    "text": "So up to a cubic error,\nthe number of labeled C4s",
    "start": "2949420",
    "end": "2960040"
  },
  {
    "text": "is given by the number of\nclosed walks of length 4, which",
    "start": "2960040",
    "end": "2976250"
  },
  {
    "text": "is equal to the trace of the 4th\npower of the adjacency matrix",
    "start": "2976250",
    "end": "2981807"
  },
  {
    "text": "of this graph. ",
    "start": "2981807",
    "end": "2993279"
  },
  {
    "text": "And the next thing\nis super important. So the next thing is sometimes\ncalled a trace method.",
    "start": "2993280",
    "end": "2998850"
  },
  {
    "text": "One important way that the\neigenvalue, so the spectrum of a graph or matrix, relates to\nother combinatorial quantities",
    "start": "2998850",
    "end": "3006470"
  },
  {
    "text": "is via this trace. So we know that the\ntrace of the 4th power is equal to the fourth\nmoment of the eigenvalues.",
    "start": "3006470",
    "end": "3014240"
  },
  {
    "start": "3014240",
    "end": "3019673"
  },
  {
    "text": "So if you haven't seen\na proof of this before, I encourage you to go\nhome and think about it. So this is an important\nidentity, of course.",
    "start": "3019673",
    "end": "3025730"
  },
  {
    "text": "4 can be replaced by\nany number up here. And now you have the\neigenvalue condition.",
    "start": "3025730",
    "end": "3035420"
  },
  {
    "text": "So I can estimate the sum. There's a principle\nterm-- namely, lambda 1.",
    "start": "3035420",
    "end": "3041660"
  },
  {
    "text": "So that's the big term. Everything else is small. And the smallness is supposed\nto capture pseudorandomness.",
    "start": "3041660",
    "end": "3046950"
  },
  {
    "text": "But the big term, you have\nto analyze separately. OK, so let me write\nit out like that.",
    "start": "3046950",
    "end": "3058380"
  },
  {
    "text": "So the big term, you know that\nit is p to the 4 n to the 4 plus little o of n to the 4.",
    "start": "3058380",
    "end": "3066500"
  },
  {
    "text": "OK. So next thing is what to\ndo with the little terms. So we want to show that\nthe contribution in total",
    "start": "3066500",
    "end": "3073650"
  },
  {
    "text": "is not too big. So what can we do?",
    "start": "3073650",
    "end": "3079010"
  },
  {
    "text": "Well, let me first\ntry something. So first, well, you see\nthat each one of these guys",
    "start": "3079010",
    "end": "3087360"
  },
  {
    "text": "is not too big. So maybe let's bound each\none of them by little o of n",
    "start": "3087360",
    "end": "3095250"
  },
  {
    "text": "raised to 4. But then there are\nn of them, so you have to multiply by an extra n.",
    "start": "3095250",
    "end": "3102759"
  },
  {
    "text": "And that's too much. That's not good enough. So you cannot individually\nbound each one of them.",
    "start": "3102760",
    "end": "3109430"
  },
  {
    "text": "And this is a novice mistake. This is something\nthat we actually will see this type\nof calculation",
    "start": "3109430",
    "end": "3115040"
  },
  {
    "text": "later on in the term when\nwe discuss Roth's theorem. But you're not supposed to\nbound these terms individually.",
    "start": "3115040",
    "end": "3120766"
  },
  {
    "text": "The better way to do\nthis or the correct way to do this is to pull\nout just a couple--",
    "start": "3120767",
    "end": "3126520"
  },
  {
    "text": "some, but not all-- of these factors. So it is upper bounded\nby-- you take max of--",
    "start": "3126520",
    "end": "3136740"
  },
  {
    "text": "in this case, you can\ntake out one or two. But you take out,\nlet's say, two factors.",
    "start": "3136740",
    "end": "3142260"
  },
  {
    "text": "And then you leave the\nremaining sum intact. In fact, I can even put lambda\n1 back into the remaining sum.",
    "start": "3142260",
    "end": "3150970"
  },
  {
    "text": "So that is true. So what I've written down is\njust true as an inequality. And now I apply the\nhypothesis on the sizes",
    "start": "3150970",
    "end": "3159020"
  },
  {
    "text": "of the other lambdas. ",
    "start": "3159020",
    "end": "3167730"
  },
  {
    "text": "So the one I pulled out\nis little o of n squared.",
    "start": "3167730",
    "end": "3173369"
  },
  {
    "text": "And now what's the second sum? That sum is the\ntrace of a squared,",
    "start": "3173370",
    "end": "3183360"
  },
  {
    "text": "which is just twice the\nnumber of edges of the graph. So that's also at\nmost n squared.",
    "start": "3183360",
    "end": "3193330"
  },
  {
    "text": "So combining everything,\nyou have the desired bound",
    "start": "3193330",
    "end": "3201800"
  },
  {
    "text": "on the C4 count.  Of course, this gives\nyou an upper bound.",
    "start": "3201800",
    "end": "3207060"
  },
  {
    "text": "But we also did a\ncalculation before the break that shows you that the C4 bound\nhas a lower bound, as well.",
    "start": "3207060",
    "end": "3212240"
  },
  {
    "text": "So really, having the\ncorrect eigenvalue-- actually, no, this\nalready shows you",
    "start": "3212240",
    "end": "3218180"
  },
  {
    "text": "that the C4 bound is\ncorrect in both directions, because this is the main term. And then everything\nelse is small.",
    "start": "3218180",
    "end": "3224170"
  },
  {
    "text": " OK.",
    "start": "3224170",
    "end": "3230330"
  },
  {
    "text": "The final implication is\nC4 implies eigenvalue. ",
    "start": "3230330",
    "end": "3241560"
  },
  {
    "start": "3235000",
    "end": "3599000"
  },
  {
    "text": "For this one, I need to\nexplore the following important property of the top eigenvalue.",
    "start": "3241560",
    "end": "3248520"
  },
  {
    "text": "So there's something\nthat we also saw last time, which\nis the interpretation",
    "start": "3248520",
    "end": "3253579"
  },
  {
    "text": "of the top eigenvalue of\na matrix interpreted as--",
    "start": "3253580",
    "end": "3259600"
  },
  {
    "text": " so this is sometimes called\nthe Courant-Fischer criterion.",
    "start": "3259600",
    "end": "3266130"
  },
  {
    "text": "Or actually, this is a special\ncase of Courant-Fischer. This is a basic\nlinear algebra fact.",
    "start": "3266130",
    "end": "3272930"
  },
  {
    "text": "If you are not familiar with\nit, I recommend looking it up. ",
    "start": "3272930",
    "end": "3279110"
  },
  {
    "text": "The top eigenvalue of a matrix,\nof a real, symmetric matrix,",
    "start": "3279110",
    "end": "3289250"
  },
  {
    "text": "is characterized by the maximum\nvalue of this quadratic form.",
    "start": "3289250",
    "end": "3296950"
  },
  {
    "text": " Let's say if x is\na non-zero vector.",
    "start": "3296950",
    "end": "3302070"
  },
  {
    "text": " So in particular, if I set\nx to be a specific vector,",
    "start": "3302070",
    "end": "3311069"
  },
  {
    "text": "I can lower bound lambda 1. So if we set this boldface 1\nto be the all-one vector in R",
    "start": "3311070",
    "end": "3328110"
  },
  {
    "text": "raised to the number\nof vertices of G, then the lambda 1 of\nthe graph is at least",
    "start": "3328110",
    "end": "3343640"
  },
  {
    "text": "this quantity over here. The numerator and denominators\nare all easy things",
    "start": "3343640",
    "end": "3349400"
  },
  {
    "text": "to evaluate. The numerator is just\ntwice the number of edges, because you are summing up\nall the entries of the matrix.",
    "start": "3349400",
    "end": "3356140"
  },
  {
    "text": "And the denominator is just n.",
    "start": "3356140",
    "end": "3361180"
  },
  {
    "text": "So the top eigenvalue\nis at least roughly pn. ",
    "start": "3361180",
    "end": "3373650"
  },
  {
    "text": "So what about the\nother eigenvalues? ",
    "start": "3373650",
    "end": "3378829"
  },
  {
    "text": "Well, the other\neigenvalues, I can again refer back to this\nmoment formula relating",
    "start": "3378830",
    "end": "3387930"
  },
  {
    "text": "the trace and closed walks. It is at most the\ntrace of the 4th power",
    "start": "3387930",
    "end": "3397190"
  },
  {
    "text": "minus the top eigenvalue\nraised to the 4th power.",
    "start": "3397190",
    "end": "3402710"
  },
  {
    "text": "It's the sum of the\nother eigenvalue raised to the 4th power. And 4 here, we're using the 4. It's an even number, right?",
    "start": "3402710",
    "end": "3409220"
  },
  {
    "text": "So you have this over here. So having a C4 hypothesis and\nalso knowing what lambda 1 is",
    "start": "3409220",
    "end": "3428619"
  },
  {
    "text": "allows you to control\nthe other lambdas. ",
    "start": "3428620",
    "end": "3442530"
  },
  {
    "text": "See, lambda 1 cannot be\nmuch greater than pn. Also comes out of\nthe same calculation.",
    "start": "3442530",
    "end": "3449270"
  },
  {
    "text": "Yep. AUDIENCE: So [INAUDIBLE]\nnumber 1 equal to [INAUDIBLE]??",
    "start": "3449270",
    "end": "3456102"
  },
  {
    "text": "PROFESSOR: Yeah, thank you. Yeah, so there's a correction. So lambda 1 is--",
    "start": "3456102",
    "end": "3463359"
  },
  {
    "text": "so in other words,\nthe little o is always respect to the constant density. ",
    "start": "3463360",
    "end": "3473288"
  },
  {
    "text": "OK, yeah. Question. AUDIENCE: You said in the\neigenvalue implies C4, you somewhere also used the\nlower bound to be proved",
    "start": "3473288",
    "end": "3481515"
  },
  {
    "text": "[INAUDIBLE]. PROFESSOR: OK. So the question is in\neigenvalue implies C4,",
    "start": "3481515",
    "end": "3486800"
  },
  {
    "text": "it says something\nabout the lower bound. So I'm not saying that. So as written over here,\nthis is what we have proved.",
    "start": "3486800",
    "end": "3495760"
  },
  {
    "text": "But when you think about the\npseudorandomness condition for C4, it shouldn't be just\nthat the number of C4 count",
    "start": "3495760",
    "end": "3502150"
  },
  {
    "text": "is at most something. It should be that\nit equals to that, which would be implied by\nthe C4 condition itself,",
    "start": "3502150",
    "end": "3509770"
  },
  {
    "text": "because we know, always, it\nis the case that a C4 count is at least what it is\ncompared to the random case.",
    "start": "3509770",
    "end": "3516400"
  },
  {
    "start": "3516400",
    "end": "3523380"
  },
  {
    "text": "So just one more thing I\nsaid was that lambda 1, you also know that it is at\nmost pn plus little n, because--",
    "start": "3523380",
    "end": "3536290"
  },
  {
    "start": "3536290",
    "end": "3542286"
  },
  {
    "text": "OK. Yeah. ",
    "start": "3542286",
    "end": "3550240"
  },
  {
    "text": "So this finishes the proof of\nthe Chung-Graham-Wilson theorem on quasi-random graphs. We stated all of\nthese hypotheses,",
    "start": "3550240",
    "end": "3556960"
  },
  {
    "text": "and they are all\nequivalent to each other. And I want to emphasize, again,\nthe most surprising one is",
    "start": "3556960",
    "end": "3562030"
  },
  {
    "text": "that C4 implies everything\nelse, that a fairly seemingly",
    "start": "3562030",
    "end": "3567610"
  },
  {
    "text": "weak condition, this just\nhaving the correct number of copies of labeled C4s,\nis enough to guarantee",
    "start": "3567610",
    "end": "3573670"
  },
  {
    "text": "all of these other much more\ncomplicated looking conditions. And in particular, just\nhaving the C4 count correct",
    "start": "3573670",
    "end": "3580510"
  },
  {
    "text": "implies that the counts of\nevery other graph H is correct.",
    "start": "3580510",
    "end": "3586810"
  },
  {
    "text": "Now, one thing I\nwant to stress is that the Chung-Graham-Wilson\ntheorem is really",
    "start": "3586810",
    "end": "3592560"
  },
  {
    "text": "about dense graphs. ",
    "start": "3592560",
    "end": "3603230"
  },
  {
    "text": "And by dense, here,\nI mean p constant. ",
    "start": "3603230",
    "end": "3608940"
  },
  {
    "text": "Of course, the theorem\nas stated is true if you let p equal to 0. So there, I said p\nstrictly between 0 and 1.",
    "start": "3608940",
    "end": "3617140"
  },
  {
    "text": "But it is also OK if\nyou let p be equal to 0.",
    "start": "3617140",
    "end": "3622710"
  },
  {
    "text": " You don't get such interesting\ntheorems, but it is still true.",
    "start": "3622710",
    "end": "3629369"
  },
  {
    "text": " But for sparse graphs, what\nyou really want to care about",
    "start": "3629370",
    "end": "3634440"
  },
  {
    "text": "is approximations of the\ncorrect order of magnitude.",
    "start": "3634440",
    "end": "3640230"
  },
  {
    "text": "So what I mean is that\nyou can write down some sparse analogs\nfor p going to 0,",
    "start": "3640230",
    "end": "3653910"
  },
  {
    "text": "so p as a function of n going\nto 0 as n goes to infinity.",
    "start": "3653910",
    "end": "3659505"
  },
  {
    "text": " So let me just write down\na couple of examples,",
    "start": "3659505",
    "end": "3664870"
  },
  {
    "text": "but I won't do all of them. You can imagine what\nthey should look like. So DISC should say this\nquantity over here.",
    "start": "3664870",
    "end": "3673935"
  },
  {
    "text": "And the discrepancy\ncondition is little o",
    "start": "3673935",
    "end": "3680200"
  },
  {
    "text": "of pn squared, because\npn squared is the edge",
    "start": "3680200",
    "end": "3686079"
  },
  {
    "text": "density overall. So that's the quantity you\nshould compare against and not n squared. If you're comparing\nn squared, you're",
    "start": "3686080",
    "end": "3693250"
  },
  {
    "text": "cheating, because n\nsquared is much bigger than the actual edge density.",
    "start": "3693250",
    "end": "3699160"
  },
  {
    "text": "Likewise, the number of\nlabeled copies of H is--",
    "start": "3699160",
    "end": "3708829"
  },
  {
    "text": " I want to put the\nlittle o 1 plus little",
    "start": "3708830",
    "end": "3714880"
  },
  {
    "text": "in front, so instead of\nplus little o of n to the H",
    "start": "3714880",
    "end": "3730750"
  },
  {
    "text": "at the end.  So you understand\nthe difference. So for sparse, this is\nthe correct normalization",
    "start": "3730750",
    "end": "3739204"
  },
  {
    "text": "that you should have,\nwhen p is allowed to go to 0 as a function of n. And you can write down all\nof these conditions, right?",
    "start": "3739205",
    "end": "3747180"
  },
  {
    "text": "I'm not saying\nthere's a theorem. You can write out\nall these conditions. And you can ask, is there also\nsome notion of equivalence?",
    "start": "3747180",
    "end": "3755220"
  },
  {
    "text": "So are these\ncorresponding conditions also equivalent to each other? And the answer is emphatically\nno, absolutely not.",
    "start": "3755220",
    "end": "3762369"
  },
  {
    "text": "So all of these equivalents\nfail for sparse.",
    "start": "3762370",
    "end": "3770920"
  },
  {
    "text": "Some of them are still true. Some of the easier\nones that we did-- for example, the two versions\nof DISC are equivalent.",
    "start": "3770920",
    "end": "3776920"
  },
  {
    "text": "That's still OK. And some of these calculations\ninvolving Cauchy-Schwarz",
    "start": "3776920",
    "end": "3782860"
  },
  {
    "text": "are mostly still OK. But the one that really\nfails is the counting lemma.",
    "start": "3782860",
    "end": "3789370"
  },
  {
    "start": "3789370",
    "end": "3801360"
  },
  {
    "text": "And let me explain\nwhy with an example. So I want to give you an\nexample of a graph which",
    "start": "3801360",
    "end": "3807450"
  },
  {
    "text": "looks pseudorandom in the\nsense of DISC but has no,",
    "start": "3807450",
    "end": "3816280"
  },
  {
    "text": "let's say, C3 count. It also has no C4\ncount, but it has no--",
    "start": "3816280",
    "end": "3822180"
  },
  {
    "text": "has the clean, correct\nnumber of triangles. ",
    "start": "3822180",
    "end": "3829820"
  },
  {
    "text": "So what's this example? So let p be some number which\nis little o of 1 over root n",
    "start": "3829820",
    "end": "3839800"
  },
  {
    "text": "so some decaying\nquantity with n.",
    "start": "3839800",
    "end": "3844920"
  },
  {
    "text": "And let's consider Gnp. ",
    "start": "3844920",
    "end": "3850819"
  },
  {
    "text": "Well, how many triangles\ndo we expect in Gnp? So let's think of p as just\nslightly below 1 over root n.",
    "start": "3850820",
    "end": "3858860"
  },
  {
    "text": "So the number of triangles\nin Gnp in expectation is--",
    "start": "3858860",
    "end": "3865430"
  },
  {
    "text": " so that's the expected number.",
    "start": "3865430",
    "end": "3870975"
  },
  {
    "text": "And you should expect\nthe actual number to be roughly around that. But on the other hand,\nthe number of edges",
    "start": "3870975",
    "end": "3883599"
  },
  {
    "text": "is also expected to\nbe this quantity here.",
    "start": "3883600",
    "end": "3888950"
  },
  {
    "text": "And you expect that the\nactual number of edges to be very close to it. But p is chosen so that\nthe number of triangles",
    "start": "3888950",
    "end": "3899089"
  },
  {
    "text": "is significantly smaller\nthan the number of edges,",
    "start": "3899090",
    "end": "3904230"
  },
  {
    "text": "so asymptotically smaller, fewer\ncopies of triangles than edges.",
    "start": "3904230",
    "end": "3909630"
  },
  {
    "text": "So what we can do\nnow is remove an edge",
    "start": "3909630",
    "end": "3917509"
  },
  {
    "text": "from each copy of a\ntriangle in this Gnp.",
    "start": "3917510",
    "end": "3928270"
  },
  {
    "text": " We removed a tiny\nfraction of edges,",
    "start": "3928270",
    "end": "3946630"
  },
  {
    "text": "because the number of\ntriangles is much less than the number of edges. We removed a tiny\nfraction of edges.",
    "start": "3946630",
    "end": "3952369"
  },
  {
    "text": "And as a result, we do\nnot change the discrepancy condition up to a small error.",
    "start": "3952370",
    "end": "3961940"
  },
  {
    "text": "So the discrepancy\ncondition still holds. ",
    "start": "3961940",
    "end": "3968780"
  },
  {
    "text": "However, the graph\nhas no more triangles. ",
    "start": "3968780",
    "end": "3987600"
  },
  {
    "text": "So you have this pseudorandom\ngraph in one sense-- namely, of having\na discrepancy--",
    "start": "3987600",
    "end": "3992839"
  },
  {
    "text": "but fails to be pseudorandom\nin a different sense-- namely, it has no triangles.",
    "start": "3992840",
    "end": "3998050"
  },
  {
    "text": "Yep. AUDIENCE: Do the\nconditions C4 and codegree also hold here-- so the issue\nbeing from DISC to count?",
    "start": "3998050",
    "end": "4005410"
  },
  {
    "text": "PROFESSOR: Question,\ndo the conditions C4 and codegree still hold here? Basically, downstream is\nOK, but upstream is not.",
    "start": "4005410",
    "end": "4011890"
  },
  {
    "text": " So we can go from C4\nto codegree to DISC. But you can't go upward.",
    "start": "4011890",
    "end": "4020120"
  },
  {
    "text": "And understanding how to rectify\nthe situation, perhaps adding",
    "start": "4020120",
    "end": "4027670"
  },
  {
    "text": "additional hypotheses\nto make this true so that you could have counting\nlemmas for triangles",
    "start": "4027670",
    "end": "4034660"
  },
  {
    "text": "and other graphs\nand sparser graphs, that's an important topic. And this is something\nthat I'll discuss",
    "start": "4034660",
    "end": "4040990"
  },
  {
    "text": "at greater length\nin not next lecture, but the one after that. And this is, in fact, related\nto the Green-Tao theorem,",
    "start": "4040990",
    "end": "4048970"
  },
  {
    "text": "which allows you to approve\nSzemerédi's theorem among the primes. The primes contain arbitrarily\nlong arithmetic progressions,",
    "start": "4048970",
    "end": "4057040"
  },
  {
    "text": "because the primes\nare also a sparse set. So it has density going to 0.",
    "start": "4057040",
    "end": "4062260"
  },
  {
    "text": "It's density decaying,\nlike, 1 over log n, according to prime\nnumber theorem. But you want to do\nregularity method.",
    "start": "4062260",
    "end": "4069609"
  },
  {
    "text": "So you have to face\nthis kind of issues. So we'll discuss that more at\nlength in a couple of lectures.",
    "start": "4069610",
    "end": "4077150"
  },
  {
    "text": "But for now, just a warning\nthat everything here is really about dense graphs. ",
    "start": "4077150",
    "end": "4084160"
  },
  {
    "text": "The next thing I\nwant to discuss is an elaboration of what happens\nto these eigenvalue conditions.",
    "start": "4084160",
    "end": "4090449"
  },
  {
    "start": "4090449",
    "end": "4096939"
  },
  {
    "text": "So for dense graphs,\nin some sense, everything's very clear\nfrom this theorem. Once you have this, theorem,\nthey're all equivalent.",
    "start": "4096939",
    "end": "4103318"
  },
  {
    "text": "You can go back and forth. And you lose a little bit\nof epsilon here and there, but everything is\nmore or less the same.",
    "start": "4103319",
    "end": "4108617"
  },
  {
    "text": "But if you go to sparser\nworld, then you really need to be much more careful. And we need to think\nabout other tools. ",
    "start": "4108617",
    "end": "4116397"
  },
  {
    "text": "And so the remainder\nof today, I want to just discuss one fairly\nsimple but powerful tool",
    "start": "4116397",
    "end": "4121989"
  },
  {
    "text": "relating eigenvalues on one hand\nand the discrepancy condition on the other hand.",
    "start": "4121990",
    "end": "4127936"
  },
  {
    "text": "All right. So you can go from\neigenvalue to discrepancy by going down this chain. But actually, there's\na much quicker route.",
    "start": "4127936",
    "end": "4136470"
  },
  {
    "text": "And this is known as the\nexpander mixing lemma. ",
    "start": "4136470",
    "end": "4150950"
  },
  {
    "text": "For simplicity and really will\nmake our life much simpler, we're only going to\nconsider d-regular graphs.",
    "start": "4150950",
    "end": "4158866"
  },
  {
    "text": "So here, d-regular means\nevery vertex is degree d. Same word, but different\nmeaning from epsilon regular.",
    "start": "4158866",
    "end": "4165899"
  },
  {
    "text": "And unfortunately, that's\njust the way it is. So d regular, and we're\ngoing to have n vertices.",
    "start": "4165899",
    "end": "4173589"
  },
  {
    "text": "And the adjacency matrix has\neigenvalues lambda 1, lambda 2,",
    "start": "4173590",
    "end": "4183170"
  },
  {
    "text": "and so on, arranged\nin decreasing order. ",
    "start": "4183170",
    "end": "4190540"
  },
  {
    "text": "Let me write lambda\nas the maximum",
    "start": "4190540",
    "end": "4196600"
  },
  {
    "text": "in absolute value\nof the eigenvalues except for the top one.",
    "start": "4196600",
    "end": "4202909"
  },
  {
    "text": "In particular, this is\neither the absolute value of the second one\nor the last one.",
    "start": "4202910",
    "end": "4212030"
  },
  {
    "text": "As I mentioned earlier,\nthe top eigenvalue is necessarily d, because\nyou have all-ones vector",
    "start": "4212030",
    "end": "4219020"
  },
  {
    "text": "as an eigenvector.  So the expander mixing lemma\nsays that if I look at two",
    "start": "4219020",
    "end": "4230620"
  },
  {
    "text": "vertex subsets, the number of\nedges between them compared",
    "start": "4230620",
    "end": "4238760"
  },
  {
    "text": "to what you would expect\nin a random case-- so just like in the\ndisc setting, but here, the correct density I\nshould put is d over n--",
    "start": "4238760",
    "end": "4245619"
  },
  {
    "text": " this quantity is upper bounded\nby lambda times the root",
    "start": "4245620",
    "end": "4255810"
  },
  {
    "text": "of the product of x and y. ",
    "start": "4255810",
    "end": "4263400"
  },
  {
    "text": "So in particular,\nif this lambda-- so everything except for the\ntop eigenvalue-- is small,",
    "start": "4263400",
    "end": "4271550"
  },
  {
    "text": "then this discrepancy\nshould be small. And you can verify with what\nwe did, that it's consistent,",
    "start": "4271550",
    "end": "4277980"
  },
  {
    "text": "what we just did. ",
    "start": "4277980",
    "end": "4283430"
  },
  {
    "text": "All right. So let's prove the\nexpander mixing lemma, which is pretty simple\ngiven what we've discussed",
    "start": "4283430",
    "end": "4291820"
  },
  {
    "text": "so far, relating-- so there was\nthis spectral characterization up there of the top eigenvalue.",
    "start": "4291820",
    "end": "4298067"
  },
  {
    "text": " So we can let J be\nthe all-ones matrix.",
    "start": "4298067",
    "end": "4305355"
  },
  {
    "start": "4305355",
    "end": "4310722"
  },
  {
    "text": "So let J be the all-ones matrix. And we know that\nthe all-ones vector",
    "start": "4310722",
    "end": "4318980"
  },
  {
    "text": "is an eigenvector of the\nadjacency matrix of G",
    "start": "4318980",
    "end": "4326870"
  },
  {
    "text": "with eigenvalue d. So the eigendecomposition of\nJ is also the all-ones vector",
    "start": "4326870",
    "end": "4336860"
  },
  {
    "text": "and its complement. So we now see that A\nsub G minus d over nJ",
    "start": "4336860",
    "end": "4348690"
  },
  {
    "text": "has the same eigenvectors as AG.",
    "start": "4348690",
    "end": "4359400"
  },
  {
    "text": "So you can choose the\neigenvectors for that. It's the same set\nof eigenvectors. Of course, we consider\nthis quantity here,",
    "start": "4359400",
    "end": "4366199"
  },
  {
    "text": "because this is exactly\nthe quantity that comes up in this expression\nonce we hit it",
    "start": "4366200",
    "end": "4371700"
  },
  {
    "text": "by characteristic vectors of\nsubsets from left and right.",
    "start": "4371700",
    "end": "4376817"
  },
  {
    "text": "All right. ",
    "start": "4376817",
    "end": "4382070"
  },
  {
    "text": "So what are the eigenvalues?",
    "start": "4382070",
    "end": "4387139"
  },
  {
    "start": "4387140",
    "end": "4394700"
  },
  {
    "text": "So A previously had eigenvalues\nlambda 1 through lambda n. But now the top one\ngets chopped down to 0.",
    "start": "4394700",
    "end": "4403099"
  },
  {
    "start": "4403100",
    "end": "4411110"
  },
  {
    "text": "So you can check\nthis explicitly. So you can check this\nexplicitly by checking",
    "start": "4411110",
    "end": "4417370"
  },
  {
    "text": "that if you take this\nmatrix multiplied",
    "start": "4417370",
    "end": "4423210"
  },
  {
    "text": "by the all-ones\nvector, you get 0. And if you have a\neigenvector-eigenvalue pair,",
    "start": "4423210",
    "end": "4434400"
  },
  {
    "text": "then hitting this by\nany of the other ones",
    "start": "4434400",
    "end": "4440739"
  },
  {
    "text": "gets you the same as\nin A, because you have",
    "start": "4440740",
    "end": "4447150"
  },
  {
    "text": "this orthogonality condition. All the other eigenvectors\nare orthogonal to the all-ones vector.",
    "start": "4447150",
    "end": "4453409"
  },
  {
    "text": "All right. So now we apply the\nCourant-Fischer criteria,",
    "start": "4453410",
    "end": "4460980"
  },
  {
    "text": "which tells us that the\nnumber in this discrepancy",
    "start": "4460980",
    "end": "4467500"
  },
  {
    "text": "quantity, which we can write\nin terms of this matrix,",
    "start": "4467500",
    "end": "4492090"
  },
  {
    "text": "it is upper bounded by\nthe product of the length",
    "start": "4492090",
    "end": "4499440"
  },
  {
    "text": "of these two vectors,\nx and y, multiplied by the spectral norm.",
    "start": "4499440",
    "end": "4504929"
  },
  {
    "start": "4504930",
    "end": "4513570"
  },
  {
    "text": "So I'm not quite using\nthe version up there, but I'm using the\nspectral norm version,",
    "start": "4513570",
    "end": "4518760"
  },
  {
    "text": "which we discussed last time. It's essentially\nthe one up there, but you allow not just\nsingle x but x and y.",
    "start": "4518760",
    "end": "4524969"
  },
  {
    "text": "And that corresponds to\nthe largest eigenvalue in absolute value,\nwhich we see that.",
    "start": "4524970",
    "end": "4532150"
  },
  {
    "text": "It's at most lambda. So at most lambda times size\nof x, size of y square root.",
    "start": "4532150",
    "end": "4542991"
  },
  {
    "text": " And that finishes the proof\nof the expander mixing lemma.",
    "start": "4542992",
    "end": "4550190"
  },
  {
    "text": " So the moral here is that,\njust like what we saw earlier",
    "start": "4550190",
    "end": "4559170"
  },
  {
    "text": "in the dense case but for\nany parameters-- so here, it's a very clean statement.",
    "start": "4559170",
    "end": "4565290"
  },
  {
    "text": "You can even have done\nthe degree graphs. d could be a constant.",
    "start": "4565290",
    "end": "4571110"
  },
  {
    "text": "If lambda is small\ncompared to d, then you have this\ndiscrepancy condition.",
    "start": "4571110",
    "end": "4578250"
  },
  {
    "text": "And the reason why this is\ncalled an expander mixing lemma is that there's this\nnotion of expanders,",
    "start": "4578250",
    "end": "4584020"
  },
  {
    "text": "which is not quite the same\nbut very intimately related to pseudorandom graphs.",
    "start": "4584020",
    "end": "4589300"
  },
  {
    "text": "So one property of pseudorandom\ngraphs that is quite useful-- in particular, in\ncomputer science--",
    "start": "4589300",
    "end": "4594692"
  },
  {
    "text": "is that if you take a\nsmall subset of vertices, it has lots of neighbors. So the graph is now\nsomehow clustered",
    "start": "4594692",
    "end": "4600640"
  },
  {
    "text": "into a few local pieces. So there's lots of expansion.",
    "start": "4600640",
    "end": "4605790"
  },
  {
    "text": "And that's something\nthat you can guarantee using the expander mixing lemma,\nthat you have lots of-- you",
    "start": "4605790",
    "end": "4614130"
  },
  {
    "text": "take a small subset of vertices. You can expand outward. So graphs with that\nspecific property,",
    "start": "4614130",
    "end": "4620989"
  },
  {
    "text": "taking a small\nsubset of vertices always gets you\nlots of neighbors, are called expander graphs.",
    "start": "4620990",
    "end": "4626030"
  },
  {
    "text": "And these graphs play an\nimportant role, in particular, in computer science in\ndesigning algorithms and proving",
    "start": "4626030",
    "end": "4632780"
  },
  {
    "text": "complexity results and\nso on but also play important roles in graph\ntheory and combinatorics. ",
    "start": "4632780",
    "end": "4640330"
  },
  {
    "text": "Well, next time, we'll address\na few questions which are along the lines of, one, how small can\nlambda be as a function of d?",
    "start": "4640330",
    "end": "4653730"
  },
  {
    "text": "So here is this. If lambda's small compared to d,\nthen you have this discrepancy. But if d is, let's\nsay, a million,",
    "start": "4653730",
    "end": "4663480"
  },
  {
    "text": "how small can lambda be? That's one question. Another question is,\nconsidering everything",
    "start": "4663480",
    "end": "4672000"
  },
  {
    "text": "that we've said so far,\nwhat can we say about,",
    "start": "4672000",
    "end": "4679720"
  },
  {
    "text": "let's say, the\nrelationship between some of these conditions\nfor sparse graphs",
    "start": "4679720",
    "end": "4687580"
  },
  {
    "text": "but that are somewhat special--\nfor example, kd graphs or vertex-transitive graphs?",
    "start": "4687580",
    "end": "4693969"
  },
  {
    "text": "And it turns out some\nof these relations are also equivalent\nto each other.",
    "start": "4693970",
    "end": "4699360"
  }
]
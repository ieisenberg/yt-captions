[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "For some applications, data naturally comes\nin vector or matrix form.",
    "start": "599",
    "end": "5279"
  },
  {
    "text": "For example, a vector of digitized samples\nrepresenting an audio waveform over time,",
    "start": "5279",
    "end": "10980"
  },
  {
    "text": "or a matrix of pixel colors in a 2D image\nfrom a camera.",
    "start": "10980",
    "end": "15940"
  },
  {
    "text": "When processing that data, it's common to\nperform the same sequence of operations on",
    "start": "15940",
    "end": "19860"
  },
  {
    "text": "each data element.",
    "start": "19860",
    "end": "21660"
  },
  {
    "text": "The example code shown here is computing a\nvector sum, where each component of one vector",
    "start": "21660",
    "end": "26750"
  },
  {
    "text": "is added to the corresponding component of\nanother vector.",
    "start": "26750",
    "end": "31080"
  },
  {
    "text": "By replicating the datapath portion of our\nCPU, we can design special-purpose vector",
    "start": "31080",
    "end": "36390"
  },
  {
    "text": "processors capable of performing the same\noperation on many data elements in parallel.",
    "start": "36390",
    "end": "41640"
  },
  {
    "text": "Here we see that the register file and ALU\nhave been replicated and the control signals",
    "start": "41640",
    "end": "46448"
  },
  {
    "text": "from decoding the current instruction are\nshared by all the datapaths.",
    "start": "46449",
    "end": "51819"
  },
  {
    "text": "Data is fetched from memory in big blocks\n(very much like fetching a cache line) and",
    "start": "51819",
    "end": "56290"
  },
  {
    "text": "the specified register in each datapath is\nloaded with one of the words from the block.",
    "start": "56290",
    "end": "62329"
  },
  {
    "text": "Similarly each datapath can contribute a word\nto be stored as a contiguous block in main",
    "start": "62329",
    "end": "66600"
  },
  {
    "text": "memory.",
    "start": "66600",
    "end": "68368"
  },
  {
    "text": "In such machines, the width of the data buses\nto and from main memory is many words wide,",
    "start": "68369",
    "end": "73770"
  },
  {
    "text": "so a single memory access provides data for\nall the datapaths in parallel.",
    "start": "73770",
    "end": "80390"
  },
  {
    "text": "Executing a single instruction on a machine\nwith N datapaths is equivalent to executing",
    "start": "80390",
    "end": "84890"
  },
  {
    "text": "N instructions on a conventional machine with\na single datapath.",
    "start": "84890",
    "end": "89290"
  },
  {
    "text": "The result achieves a lot of parallelism without\nthe complexities of out-of-order superscalar",
    "start": "89290",
    "end": "95420"
  },
  {
    "text": "execution.",
    "start": "95420",
    "end": "96420"
  },
  {
    "start": "96000",
    "end": "96000"
  },
  {
    "text": "Suppose we had a vector processor with 16\ndatapaths.",
    "start": "96420",
    "end": "99719"
  },
  {
    "text": "Let's compare its performance on a vector-sum\noperation to that of a conventional pipelined",
    "start": "99719",
    "end": "104630"
  },
  {
    "text": "Beta processor.",
    "start": "104630",
    "end": "106490"
  },
  {
    "text": "Here's the Beta code, carefully organized\nto avoid any data hazards during execution.",
    "start": "106490",
    "end": "111659"
  },
  {
    "text": "There are 9 instructions in the loop, taking\n10 cycles to execute if we count the NOP introduced",
    "start": "111659",
    "end": "116670"
  },
  {
    "text": "into the pipeline when the BNE at the end\nof the loop is taken.",
    "start": "116670",
    "end": "120990"
  },
  {
    "text": "It takes 160 cycles to sum all 16 elements\nassuming no additional cycles are required",
    "start": "120990",
    "end": "126780"
  },
  {
    "text": "due to cache misses.",
    "start": "126780",
    "end": "129110"
  },
  {
    "text": "And here's the corresponding code for a vector\nprocessor where we've assumed constant-sized",
    "start": "129110",
    "end": "134010"
  },
  {
    "text": "16-element vectors.",
    "start": "134010",
    "end": "136209"
  },
  {
    "text": "Note that \"V\" registers refer to a particular\nlocation in the register file associated with",
    "start": "136210",
    "end": "140580"
  },
  {
    "text": "each datapath, while the \"R\" registers are\nthe conventional Beta registers used for address",
    "start": "140580",
    "end": "145890"
  },
  {
    "text": "computations, etc.",
    "start": "145890",
    "end": "146900"
  },
  {
    "text": "It would only take 4 cycles for the vector\nprocessor to complete the desired operations,",
    "start": "146900",
    "end": "152200"
  },
  {
    "text": "a speed-up of 40.",
    "start": "152200",
    "end": "154520"
  },
  {
    "text": "This example shows the best-possible speed-up.",
    "start": "154520",
    "end": "157580"
  },
  {
    "text": "The key to a good speed-up is our ability\nto \"vectorize\" the code and take advantage",
    "start": "157580",
    "end": "162330"
  },
  {
    "text": "of all the datapaths operating in parallel.",
    "start": "162330",
    "end": "165850"
  },
  {
    "text": "This isn't possible for every application,\nbut for tasks like audio or video encoding",
    "start": "165850",
    "end": "171150"
  },
  {
    "text": "and decoding, and all sorts of digital signal\nprocessing, vectorization is very doable.",
    "start": "171150",
    "end": "178189"
  },
  {
    "text": "Memory operations enjoy a similar performance\nimprovement since the access overhead is amortized",
    "start": "178190",
    "end": "183810"
  },
  {
    "text": "over large blocks of data.",
    "start": "183810",
    "end": "186530"
  },
  {
    "text": "You might wonder if it's possible to efficiently\nperform data-dependent operations on a vector",
    "start": "186530",
    "end": "191220"
  },
  {
    "start": "187000",
    "end": "187000"
  },
  {
    "text": "processor.",
    "start": "191220",
    "end": "193520"
  },
  {
    "text": "Data-dependent operations appear as conditional\nstatements on conventional machines, where",
    "start": "193520",
    "end": "197480"
  },
  {
    "text": "the body of the statement is executed if the\ncondition is true.",
    "start": "197480",
    "end": "201709"
  },
  {
    "text": "If testing and branching is under the control\nof the single-instruction execution engine,",
    "start": "201710",
    "end": "205810"
  },
  {
    "text": "how can we take advantage of the parallel\ndatapaths?",
    "start": "205810",
    "end": "210770"
  },
  {
    "text": "The trick is provide each datapath with a\nlocal predicate flag.",
    "start": "210770",
    "end": "215380"
  },
  {
    "text": "Use a vectorized compare instruction (CMPLT.V)\nto perform the a[i] < b[i] comparisons in",
    "start": "215380",
    "end": "221510"
  },
  {
    "text": "parallel and remember the result locally in\neach datapath's predicate flag.",
    "start": "221510",
    "end": "226900"
  },
  {
    "text": "Then extend the vector ISA to include \"predicated\ninstructions\" which check the local predicate",
    "start": "226900",
    "end": "233290"
  },
  {
    "text": "to see if they should execute or do nothing.",
    "start": "233290",
    "end": "236530"
  },
  {
    "text": "In this example, ADDC.V.iftrue only performs\nthe ADDC on the local data if the local predicate",
    "start": "236530",
    "end": "243790"
  },
  {
    "text": "flag is true.",
    "start": "243790",
    "end": "246170"
  },
  {
    "text": "Instruction predication is also used in many\nnon-vector architectures to avoid the execution-time",
    "start": "246170",
    "end": "251099"
  },
  {
    "text": "penalties associated with mis-predicted conditional\nbranches.",
    "start": "251100",
    "end": "254510"
  },
  {
    "text": "They are particularly useful for simple arithmetic\nand boolean operations (i.e., very short instruction",
    "start": "254510",
    "end": "260958"
  },
  {
    "text": "sequences) that should be executed only if\na condition is met.",
    "start": "260959",
    "end": "265630"
  },
  {
    "text": "The x86 ISA includes a conditional move instruction,\nand in the 32-bit ARM ISA almost all instructions",
    "start": "265630",
    "end": "274910"
  },
  {
    "text": "can be conditionally executed.",
    "start": "274910",
    "end": "277620"
  },
  {
    "text": "The power of vector processors comes from\nhaving 1 instruction initiate N parallel operations",
    "start": "277620",
    "end": "283220"
  },
  {
    "start": "278000",
    "end": "278000"
  },
  {
    "text": "on N pairs of operands.",
    "start": "283220",
    "end": "286170"
  },
  {
    "text": "Most modern CPUs incorporate vector extensions\nthat operate in parallel on 8-, 16-, 32- or",
    "start": "286170",
    "end": "292550"
  },
  {
    "text": "64-bit operands organized as blocks of 128-,\n256-, or 512-bit data.",
    "start": "292550",
    "end": "299360"
  },
  {
    "text": "Often all that's needed is some simple additional\nlogic on an ALU designed to process full-width",
    "start": "299360",
    "end": "304659"
  },
  {
    "text": "operands.",
    "start": "304660",
    "end": "306130"
  },
  {
    "text": "The parallelism is baked into the vector program,\nnot discovered on-the-fly by the instruction",
    "start": "306130",
    "end": "311990"
  },
  {
    "text": "dispatch and execution machinery.",
    "start": "311990",
    "end": "315000"
  },
  {
    "text": "Writing the specialized vector programs is\na worthwhile investment for certain library",
    "start": "315000",
    "end": "319200"
  },
  {
    "text": "functions which see a lot use in processing\ntoday's information streams with their heavy",
    "start": "319200",
    "end": "324210"
  },
  {
    "text": "use of images, and A/V material.",
    "start": "324210",
    "end": "328550"
  },
  {
    "text": "Perhaps the best example of architectures\nwith many datapaths operating in parallel",
    "start": "328550",
    "end": "333300"
  },
  {
    "text": "are the graphics processing units (GPUs) found\nin almost all computer graphics systems.",
    "start": "333300",
    "end": "339550"
  },
  {
    "text": "GPU datapaths are typically specialized for\n32- and 64-bit floating point operations found",
    "start": "339550",
    "end": "346370"
  },
  {
    "text": "in the algorithms needed to display in real-time\na 3D scene represented as billions of triangular",
    "start": "346370",
    "end": "352080"
  },
  {
    "text": "patches as a 2D image on the computer screen.",
    "start": "352080",
    "end": "355759"
  },
  {
    "text": "Coordinate transformation, pixel shading and\nantialiasing, texture mapping, etc., are examples",
    "start": "355760",
    "end": "361620"
  },
  {
    "text": "of \"embarrassingly parallel\" computations\nwhere the parallelism comes from having to",
    "start": "361620",
    "end": "366180"
  },
  {
    "text": "perform the same computation independently\non millions of different data objects.",
    "start": "366180",
    "end": "372210"
  },
  {
    "text": "Similar problems can be found in the fields\nof bioinformatics, big data processing, neural",
    "start": "372210",
    "end": "377699"
  },
  {
    "text": "net emulation used in deep machine learning,\nand so on.",
    "start": "377700",
    "end": "381340"
  },
  {
    "text": "Increasingly, GPUs are used in many interesting\nscientific and engineering calculations and",
    "start": "381340",
    "end": "387389"
  },
  {
    "text": "not just as graphics engines.",
    "start": "387390",
    "end": "390940"
  },
  {
    "text": "Data-level parallelism provides significant\nperformance improvements in a variety of useful",
    "start": "390940",
    "end": "395600"
  },
  {
    "text": "situations.",
    "start": "395600",
    "end": "397090"
  },
  {
    "text": "So current and future ISAs will almost certainly\ninclude support for vector operations.",
    "start": "397090",
    "end": "403169"
  }
]
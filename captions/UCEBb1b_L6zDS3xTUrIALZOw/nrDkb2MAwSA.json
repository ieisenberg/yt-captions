[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseware continue to offer high quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18140",
    "end": "23169"
  },
  {
    "start": "22000",
    "end": "240000"
  },
  {
    "text": "GILBERT STRANG: OK, so basically\nprobability ideas today,",
    "start": "23170",
    "end": "28300"
  },
  {
    "text": "because that's a part of the\nsubject, part of deep learning",
    "start": "28300",
    "end": "35860"
  },
  {
    "text": "as we get there. And it's probably a\ngood topic for the day before spring break, because\nlots of you will have seen--",
    "start": "35860",
    "end": "45590"
  },
  {
    "text": "of course, you will\nhave seen the sample mean, the average of the data.",
    "start": "45590",
    "end": "51620"
  },
  {
    "text": " And you'll know about\nthe expected mean.",
    "start": "51620",
    "end": "58400"
  },
  {
    "text": "Let me complete that. ",
    "start": "58400",
    "end": "64230"
  },
  {
    "text": "What's the expected mean? So this is the\nexpectation of the value x",
    "start": "64230",
    "end": "71610"
  },
  {
    "text": "where we get x1\nwith probability P1",
    "start": "71610",
    "end": "77370"
  },
  {
    "text": "along to xn with probability Pn. So we just want to say,\nwhat's our average output--",
    "start": "77370",
    "end": "86250"
  },
  {
    "text": "average outcome? And we weight it by\ntheir probabilities. So it's P1 x1 plus\nso on plus Pn xn.",
    "start": "86250",
    "end": "99240"
  },
  {
    "text": "So that's the\nexpected value of x. ",
    "start": "99240",
    "end": "105920"
  },
  {
    "text": "Are you comfortable\nwith that symbol E? Because that's like everywhere. It gives a handy shorthand.",
    "start": "105920",
    "end": "112530"
  },
  {
    "text": "For example, the variance is\nthe expected value of what? ",
    "start": "112530",
    "end": "121820"
  },
  {
    "text": "The variance is\nan expected value based on these probabilities\nof the square of the distance.",
    "start": "121820",
    "end": "129830"
  },
  {
    "text": "So everybody remembers\nit involves square. And it's the distance\nfrom the mean.",
    "start": "129830",
    "end": "135845"
  },
  {
    "text": " Let me call this, say, m, maybe,\njust to have a smaller letter.",
    "start": "135845",
    "end": "145640"
  },
  {
    "text": "So it's the distance\nfrom the mean minus m. It's the expected value, the\naverage value of x minus m",
    "start": "145640",
    "end": "155599"
  },
  {
    "text": "squared. And in general, of\ncourse, the expected--",
    "start": "155600",
    "end": "160700"
  },
  {
    "text": "this covariance matrix I could\nexpress with that E notation.",
    "start": "160700",
    "end": "166069"
  },
  {
    "text": "But let me just\nstretch it as far as what would be the expected\nvalue of any function of x?",
    "start": "166070",
    "end": "173750"
  },
  {
    "text": " Well, we've got n possible\noutputs, x1 to xn.",
    "start": "173750",
    "end": "182170"
  },
  {
    "text": "We look at f of\nx1 up to f of xn. We weight those by the\nprobabilities that they happen.",
    "start": "182170",
    "end": "190510"
  },
  {
    "text": "So this would be-- let me make just a little\ncorner for this E letter--",
    "start": "190510",
    "end": "196450"
  },
  {
    "text": "so this would be the\nprobability that that is f of x1 times the\nvalue of f of x1.",
    "start": "196450",
    "end": "209160"
  },
  {
    "text": "So this is the contribution\nfrom the x1 possibility.",
    "start": "209160",
    "end": "214340"
  },
  {
    "text": "And now, we include them all. So it will be output f of\nxn with probability Pn.",
    "start": "214340",
    "end": "224720"
  },
  {
    "text": "And if that f of x\nis x minus m squared, then we get what we expect.",
    "start": "224720",
    "end": "231599"
  },
  {
    "text": "And let me remember that. So I just want to keep\ngoing with variance.",
    "start": "231600",
    "end": "237710"
  },
  {
    "text": " So it's the sum.",
    "start": "237710",
    "end": "243220"
  },
  {
    "start": "240000",
    "end": "570000"
  },
  {
    "text": "It's the first probability times\nthe first output minus the mean",
    "start": "243220",
    "end": "249280"
  },
  {
    "text": "squared the last probability\ntimes that last output",
    "start": "249280",
    "end": "256500"
  },
  {
    "text": "xn minus m squared. And everybody should\nknow a second expression,",
    "start": "256500",
    "end": "263310"
  },
  {
    "text": "a second way, to\ndo that the sum. If I just write\nout those squares",
    "start": "263310",
    "end": "271200"
  },
  {
    "text": "and combine them a\nlittle differently, I get a second expression\nwhich is really useful, often",
    "start": "271200",
    "end": "279070"
  },
  {
    "text": "a little faster to compute. So can I just do that? So that's x1 squared minus\n2 x1 m1 plus m1 squared.",
    "start": "279070",
    "end": "292480"
  },
  {
    "text": "And then same thing\nhere, Pn times xn squared minus 2xn\nm plus m squared.",
    "start": "292480",
    "end": "303590"
  },
  {
    "text": "Good with that? AUDIENCE: On that m-- GILBERT STRANG: Sorry?",
    "start": "303590",
    "end": "308626"
  },
  {
    "text": "AUDIENCE: On that m-- GILBERT STRANG:\nPlus n, oh, sorry.",
    "start": "308626",
    "end": "313730"
  },
  {
    "text": "No, I mean-- am I-- AUDIENCE: So for P1\nit's x1 squared minus--",
    "start": "313730",
    "end": "320520"
  },
  {
    "text": "GILBERT STRANG:\nOh, it's just an m. Correct. Thank you. Thank you. Just an m. Good.",
    "start": "320520",
    "end": "326650"
  },
  {
    "text": "OK. Can we take that sum? So I get P1 x1 squared if I\ntake these, the first guys.",
    "start": "326650",
    "end": "338680"
  },
  {
    "text": " So I've accounted\nfor this and this.",
    "start": "338680",
    "end": "347990"
  },
  {
    "text": "Now, I'll take minus 2 P1 x1 m.",
    "start": "347990",
    "end": "354680"
  },
  {
    "text": "So P1 x1 m plus Pn xn m.",
    "start": "354680",
    "end": "366600"
  },
  {
    "text": " I'm just writing it all out,\nand I'm going to recombine it.",
    "start": "366600",
    "end": "373069"
  },
  {
    "text": "So now, I have P1 m squared plus\nP2 m squared plus Pn m squared.",
    "start": "373070",
    "end": "380100"
  },
  {
    "text": "So what do I have\nfrom the P1 m squared",
    "start": "380100",
    "end": "386640"
  },
  {
    "text": "all the way up to Pn m squared?",
    "start": "386640",
    "end": "391700"
  },
  {
    "text": "Are you with me? So m squared is in every term.",
    "start": "391700",
    "end": "397189"
  },
  {
    "text": "So I'm going to\nhave an m squared. And what's it multiplied by?",
    "start": "397190",
    "end": "403010"
  },
  {
    "text": "P1 here, P2 here, Pn here. I add those up and I get?",
    "start": "403010",
    "end": "409560"
  },
  {
    "text": "AUDIENCE: 1. GILBERT STRANG: 1. So that's it. OK, now, I'll just\nsimplify this thing.",
    "start": "409560",
    "end": "415669"
  },
  {
    "text": "So this is really the\nexpected value of what?",
    "start": "415670",
    "end": "420920"
  },
  {
    "text": "What am I seeing in this term? AUDIENCE: x squared. GILBERT STRANG: The expected\nvalue of x squared, right.",
    "start": "420920",
    "end": "429060"
  },
  {
    "text": " Different from the\nexpected value of x minus m",
    "start": "429060",
    "end": "435270"
  },
  {
    "text": "squared, of course. This is just a first\nterm from here. But, now, what do I get\nfor this second term?",
    "start": "435270",
    "end": "442590"
  },
  {
    "text": "Well, the point is\nthat m comes out. So this is minus an m and a 2.",
    "start": "442590",
    "end": "449490"
  },
  {
    "text": "And what do I have left? So I've used up the m. I've used up the 2.",
    "start": "449490",
    "end": "455880"
  },
  {
    "text": "P1 x1 dot dot dot\nPn xn, what's that? ",
    "start": "455880",
    "end": "461790"
  },
  {
    "text": "Everybody should just\npay attention to this. Trivial, I mean, we're just\ndoing high school algebra here.",
    "start": "461790",
    "end": "469300"
  },
  {
    "text": "But P1 x1 up to Pn xn is m. So I have another\nm, m squared there.",
    "start": "469300",
    "end": "476960"
  },
  {
    "text": "And I have a plus m\nsquared from the n. So you see that it is another\nexpression, the expected value",
    "start": "476960",
    "end": "486900"
  },
  {
    "text": "of x squared minus m squared. It's just algebra.",
    "start": "486900",
    "end": "494050"
  },
  {
    "text": "That is the same as this.",
    "start": "494050",
    "end": "499560"
  },
  {
    "text": "So that if you happen\nto have a handy way to compute the expected\nvalue of x squared,",
    "start": "499560",
    "end": "504930"
  },
  {
    "text": "you would just\nsubtract m squared. And you'd have the same as this. Yeah, it's just algebra.",
    "start": "504930",
    "end": "512580"
  },
  {
    "text": "OK, let's go a little\ndeeper with something here--",
    "start": "512580",
    "end": "519880"
  },
  {
    "text": "if I can find it. There are two great\ninequalities in statistics.",
    "start": "519880",
    "end": "526640"
  },
  {
    "text": "And the first one\nis due to Markov. And I don't know if you\nknow Markov's inequality.",
    "start": "526640",
    "end": "533370"
  },
  {
    "text": " It comes out easily,\nin fact, too easily.",
    "start": "533370",
    "end": "542180"
  },
  {
    "text": "I'm kind of happy\nto discuss him. And now I've jumped to\nSection 5 of the book.",
    "start": "542180",
    "end": "551570"
  },
  {
    "text": "So I'll need to post\nSection 5, which is probability and statistics.",
    "start": "551570",
    "end": "558770"
  },
  {
    "text": "And you'll see this\nMarkov inequality. So it just involves this stuff.",
    "start": "558770",
    "end": "564360"
  },
  {
    "text": "So that's why I'll go do it now. Markov's inequality.",
    "start": "564360",
    "end": "570839"
  },
  {
    "start": "570000",
    "end": "1815000"
  },
  {
    "text": " He was a great\nRussian mathematician,",
    "start": "570840",
    "end": "578870"
  },
  {
    "text": "oh, probably about 1900. And we will see Markov\nchains and Markov processes,",
    "start": "578870",
    "end": "586740"
  },
  {
    "text": "that's beautiful linear algebra. But this little inequality\nis not matrices.",
    "start": "586740",
    "end": "592459"
  },
  {
    "text": "It's just playing with these. And it applies to\nnon-negative events.",
    "start": "592460",
    "end": "604270"
  },
  {
    "text": " So shall I say applies when\nall the x, all the outputs,",
    "start": "604270",
    "end": "616173"
  },
  {
    "text": "are greater than\nor equal to zero. ",
    "start": "616173",
    "end": "621670"
  },
  {
    "text": "So I'm going to use that fact. So it doesn't apply to\nsomething like a Gaussian,",
    "start": "621670",
    "end": "632020"
  },
  {
    "text": "because there, the\nGaussian, the outputs go all the way from minus\ninfinity to infinity.",
    "start": "632020",
    "end": "637060"
  },
  {
    "text": "It does apply to a lot of\nimportant ones and simple ones.",
    "start": "637060",
    "end": "645180"
  },
  {
    "text": "I'll give you the proof for\nthis finite probability.",
    "start": "645180",
    "end": "651440"
  },
  {
    "text": "And there will be a similar\nproof, similar discussion everywhere here for\ncontinuous probability.",
    "start": "651440",
    "end": "658220"
  },
  {
    "text": "So what does Markov say? Let me be sure I get it right,\nbecause I'm not a pro at this.",
    "start": "658220",
    "end": "666640"
  },
  {
    "text": "It's natural to want to\nestimate the probability that x",
    "start": "666640",
    "end": "675890"
  },
  {
    "text": "is greater or equal\nto some number a. Get some idea of what's\nthe probability of x",
    "start": "675890",
    "end": "682850"
  },
  {
    "text": "being greater or equal to a. So what do we know? This is certainly a\nnumber between 0 and 1.",
    "start": "682850",
    "end": "688840"
  },
  {
    "text": " That number is going to\nget smaller as a increases,",
    "start": "688840",
    "end": "694180"
  },
  {
    "text": "because we're going\nto be asking for more. If I take a to b,\nsay, twice the mean,",
    "start": "694180",
    "end": "710620"
  },
  {
    "text": "can I estimate what that\nprobability could be. And that's what Markov has done.",
    "start": "710620",
    "end": "716890"
  },
  {
    "text": "He says the probability\nof that is at least-- ",
    "start": "716890",
    "end": "725140"
  },
  {
    "text": "at most-- sorry. Let's see I used\nto have an eraser--",
    "start": "725140",
    "end": "731230"
  },
  {
    "text": "at least-- sorry, at most-- yes, got it, got it--",
    "start": "731230",
    "end": "739450"
  },
  {
    "text": "is less or equal to the mean--",
    "start": "739450",
    "end": "745320"
  },
  {
    "text": "x bar is another way\nto write the mean-- divided by a.",
    "start": "745320",
    "end": "750540"
  },
  {
    "text": "And this is the\nmean over a or it's",
    "start": "750540",
    "end": "757199"
  },
  {
    "text": "the expected value of x over a. We could see any\nof those notations.",
    "start": "757200",
    "end": "764420"
  },
  {
    "text": "OK. ",
    "start": "764420",
    "end": "770180"
  },
  {
    "text": "And as we expect, as a\nincreases, the probability,",
    "start": "770180",
    "end": "776180"
  },
  {
    "text": "this number, goes\ndown, the probability goes down of exceeding a.",
    "start": "776180",
    "end": "782150"
  },
  {
    "text": "So that's a pretty\nsimple estimate to get this probability\njust in terms of the number",
    "start": "782150",
    "end": "789560"
  },
  {
    "text": "a, which has to come in, because\nit's part of the question, and the mean, x.",
    "start": "789560",
    "end": "795150"
  },
  {
    "text": "So let me take an\nexample as a equals 3.",
    "start": "795150",
    "end": "800300"
  },
  {
    "start": "800300",
    "end": "806700"
  },
  {
    "text": "For example, suppose a with 3. I want to show that the\nprobability of x being greater",
    "start": "806700",
    "end": "815620"
  },
  {
    "text": "than or equal to 3. Yeah, OK. ",
    "start": "815620",
    "end": "822550"
  },
  {
    "text": "We don't have many\nfacts to work with. So if we write those down,\nwe should see the reason.",
    "start": "822550",
    "end": "830019"
  },
  {
    "text": "So I know that the\nmean is E of x. So let's see, am\nI going to take--",
    "start": "830020",
    "end": "837399"
  },
  {
    "text": "yeah, for example, let's\ntake the mean to be 1.",
    "start": "837400",
    "end": "843880"
  },
  {
    "text": " So I'm going to imagine\nthat the mean is 1",
    "start": "843880",
    "end": "851620"
  },
  {
    "text": "and that I'm asking for\nwhat's the chance that x will be bigger than 3.",
    "start": "851620",
    "end": "860880"
  },
  {
    "text": "And I'll get an estimate of 1/3. So I'm trying to show\nthat the probability of x",
    "start": "860880",
    "end": "874310"
  },
  {
    "text": "greater or equal 3\nis less or equal to--",
    "start": "874310",
    "end": "879580"
  },
  {
    "text": "the mean, I'm saying is 1. a is 3. So it is less than or equal 1/3.",
    "start": "879580",
    "end": "885800"
  },
  {
    "text": "Now, why is that true? That's what I have to show.",
    "start": "885800",
    "end": "891320"
  },
  {
    "text": "I think that if I write down\nwhat I know, I'll see it. ",
    "start": "891320",
    "end": "898520"
  },
  {
    "text": "So let me just raise that a\nlittle so that I have room",
    "start": "898520",
    "end": "904440"
  },
  {
    "text": "to write. So what do I know? I know the definition\nof the mean.",
    "start": "904440",
    "end": "910600"
  },
  {
    "text": "So I know that x1 times\nP1 plus x2 P2 plus x3 P3--",
    "start": "910600",
    "end": "924660"
  },
  {
    "text": "allow me to get\ncarried away here-- x5 P5, say, is what?",
    "start": "924660",
    "end": "933570"
  },
  {
    "text": " So what I've written\ndown there is the mean.",
    "start": "933570",
    "end": "939220"
  },
  {
    "text": "And I'm assuming that to be 1. So this is the fact\nthat I know is 1.",
    "start": "939220",
    "end": "944230"
  },
  {
    "text": " And what is it that\nI want to prove?",
    "start": "944230",
    "end": "950020"
  },
  {
    "text": "I want to know the probability\nof being greater or equal 3.",
    "start": "950020",
    "end": "955060"
  },
  {
    "text": "So what's the probability\nthat the result will be greater or equal 3?",
    "start": "955060",
    "end": "960430"
  },
  {
    "text": " It's P3.",
    "start": "960430",
    "end": "965640"
  },
  {
    "text": "So this is saying\nthat P3 plus P4--",
    "start": "965640",
    "end": "970870"
  },
  {
    "text": "these are the probabilities. These are the\ndifferent ways that I might be greater or equal 3.",
    "start": "970870",
    "end": "977240"
  },
  {
    "text": "And I'm claiming that that's\nless than or equal 1/3. ",
    "start": "977240",
    "end": "985290"
  },
  {
    "text": "What I liked about this\nelementary approach is that I've stated these\nfacts, these probability",
    "start": "985290",
    "end": "997200"
  },
  {
    "text": "assumptions and conclusions\ndirectly in terms of numbers.",
    "start": "997200",
    "end": "1003920"
  },
  {
    "text": "So I just want to show that if\nthis is true, then that's true.",
    "start": "1003920",
    "end": "1011029"
  },
  {
    "text": "Let's see, I guess I'm\nthinking that the-- I'm sorry, I even took\na more special case.",
    "start": "1011030",
    "end": "1018640"
  },
  {
    "text": "I'm taking the case where x1 is\n1, x2 is 2, x3 is 3, x4 is 4,",
    "start": "1018640",
    "end": "1031849"
  },
  {
    "text": "and x5 is 5. So that satisfies my\ncondition that the outputs--",
    "start": "1031849",
    "end": "1041039"
  },
  {
    "text": "1, 2, 3, 4, or 5-- are all-- Markov\nonly applies when",
    "start": "1041040",
    "end": "1051150"
  },
  {
    "text": "they're all greater or equal 0.  So I'm just imagining\nthe special case",
    "start": "1051150",
    "end": "1058560"
  },
  {
    "text": "where that possible\noutputs are 1, 2, 3, 4, 5. Their probabilities\nare P1, P2, P3, P4, P5.",
    "start": "1058560",
    "end": "1067529"
  },
  {
    "text": "The mean is 1. And what I want to show\nis that the probability",
    "start": "1067530",
    "end": "1072840"
  },
  {
    "text": "of being greater than 3\nis less than or equal 1/3.",
    "start": "1072840",
    "end": "1079350"
  },
  {
    "text": "And can you put\ntogether these two? ",
    "start": "1079350",
    "end": "1085620"
  },
  {
    "text": "Given this, we want\nto conclude that. Let me just step back a minute.",
    "start": "1085620",
    "end": "1091650"
  },
  {
    "text": "So what do we know here? ",
    "start": "1091650",
    "end": "1096990"
  },
  {
    "text": "We know this, the first line. And we want to prove the second. We know one more thing.",
    "start": "1096990",
    "end": "1103120"
  },
  {
    "text": " All the probability-- well,\nwe know the probabilities",
    "start": "1103120",
    "end": "1108389"
  },
  {
    "text": "add to 1. And we know they're\nall greater equal 0. So let me put those\nfacts in here too.",
    "start": "1108390",
    "end": "1114960"
  },
  {
    "text": "We know that P1 plus P2 plus\nP3 plus P4 plus P5 is 1.",
    "start": "1114960",
    "end": "1126320"
  },
  {
    "text": "That we know. And we also know\nthat all the P's",
    "start": "1126320",
    "end": "1133550"
  },
  {
    "text": "are greater than or equal to 0. OK. ",
    "start": "1133550",
    "end": "1143420"
  },
  {
    "text": "So here we go. My idea is this is looking at\n3 times P3 plus P4 plus P5.",
    "start": "1143420",
    "end": "1154370"
  },
  {
    "text": "So I'm going to take 3 P3\nplus 3 P4 away from this.",
    "start": "1154370",
    "end": "1159559"
  },
  {
    "text": " So this we'll say P1 plus 2 P2\nplus 3 of P3 plus P4 plus P5.",
    "start": "1159560",
    "end": "1179320"
  },
  {
    "text": "I'm just picking out\nthree of those guys. Plus I have one more\nP4 to account for",
    "start": "1179320",
    "end": "1186500"
  },
  {
    "text": "and two more P5s gives 1. ",
    "start": "1186500",
    "end": "1197594"
  },
  {
    "text": "Good?  Now, this is what\nI'm trying to prove.",
    "start": "1197594",
    "end": "1207120"
  },
  {
    "text": "So that is here. I'm trying to prove\nthat this thing is-- what am I trying to\nprove about that number?",
    "start": "1207120",
    "end": "1215060"
  },
  {
    "text": "Sorry, I'm talking a lot. But now, I've really\ncome to the point. What is Markov telling\nme about that number?",
    "start": "1215060",
    "end": "1222390"
  },
  {
    "text": "That's-- AUDIENCE: Less\nthan or equal to 1. GILBERT STRANG: That is\nless than or equal to? AUDIENCE: 1. GILBERT STRANG: Thanks. OK, I'm trying to prove that\nthis is less than or equal 1.",
    "start": "1222390",
    "end": "1231929"
  },
  {
    "text": "That's what Markov tells me.  But suppose it was\ngreater than 1?",
    "start": "1231930",
    "end": "1238870"
  },
  {
    "text": "Do you see the problem? Do you see why it can't\nbe greater than 1? Because why? ",
    "start": "1238870",
    "end": "1248470"
  },
  {
    "text": "AUDIENCE: All are\nthe other terms-- GILBERT STRANG: All the other\nterms are greater equal 0. Probabilities or\ngreater equal 0.",
    "start": "1248470",
    "end": "1255200"
  },
  {
    "text": "These are all greater equal 0. And the total things adds to 1.",
    "start": "1255200",
    "end": "1260240"
  },
  {
    "text": "So that this piece has\nto be less or equal to 1. That's right. That's it.",
    "start": "1260240",
    "end": "1266600"
  },
  {
    "text": "So a lot of talking there. Simple idea. And you'll see exactly\nthis example written down",
    "start": "1266600",
    "end": "1276140"
  },
  {
    "text": "in the notes. And then you'll see a\nmore conventional proof",
    "start": "1276140",
    "end": "1282590"
  },
  {
    "text": "of Markov's inequality by\ntaking simple inequality steps.",
    "start": "1282590",
    "end": "1290000"
  },
  {
    "text": "But they're somehow\nmore mysterious. For me, this was explicit. OK, so that's Markov.",
    "start": "1290000",
    "end": "1297740"
  },
  {
    "text": "Chebyshev is the other\ngreat Russian probabilist of the time.",
    "start": "1297740",
    "end": "1303140"
  },
  {
    "text": "And he gets his inequality.",
    "start": "1303140",
    "end": "1308658"
  },
  {
    "start": "1308658",
    "end": "1317460"
  },
  {
    "text": "So there are the two. There's Markov's equality. Let me write it down\nagain what it was.",
    "start": "1317460",
    "end": "1324960"
  },
  {
    "text": "Here was Markov's inequality\nand Markov's assumption.",
    "start": "1324960",
    "end": "1332669"
  },
  {
    "text": "Chebyshev doesn't\nmake that assumption. So now, no assumption of\nthat the outputs are greater",
    "start": "1332670",
    "end": "1346280"
  },
  {
    "text": "equal 0. Doesn't come in. Now what is Chebyshev\ntrying to estimate?",
    "start": "1346280",
    "end": "1354190"
  },
  {
    "text": "OK, let's move to Chebyshev. And that's the last guy. ",
    "start": "1354190",
    "end": "1365270"
  },
  {
    "text": "So Chebyshev was interested in\nthe probability that x minus",
    "start": "1365270",
    "end": "1376190"
  },
  {
    "text": "the mean, m-- can I\nuse that for mean-- ",
    "start": "1376190",
    "end": "1383190"
  },
  {
    "text": "is probably greater equal to a--",
    "start": "1383190",
    "end": "1390866"
  },
  {
    "text": "the probability of being sort\nof a distance a away from mean.",
    "start": "1390866",
    "end": "1398659"
  },
  {
    "text": "So again, as a increases,\nI'm asking more, I'm asking it to be\nfurther away from the mean,",
    "start": "1398660",
    "end": "1405809"
  },
  {
    "text": "and the probability will drop. And then the question\nis can we estimate this?",
    "start": "1405810",
    "end": "1412040"
  },
  {
    "text": "So this is a different estimate. But it's similar question.",
    "start": "1412040",
    "end": "1418299"
  },
  {
    "text": "And what Chebyshev's\nanswer for this? So this is the\nprobability of this.",
    "start": "1418300",
    "end": "1424240"
  },
  {
    "text": "I have to put off big-- that's all one mouthful--",
    "start": "1424240",
    "end": "1430240"
  },
  {
    "text": "the probability that this x\nminus m is greater equal to a.",
    "start": "1430240",
    "end": "1440170"
  },
  {
    "text": "And again, we're going\nto have is less than or equal to sigma squared\nnow comes in over a squared.",
    "start": "1440170",
    "end": "1449280"
  },
  {
    "start": "1449280",
    "end": "1454560"
  },
  {
    "text": "So that's Chebyshev. And I just take time\ntoday to do these two",
    "start": "1454560",
    "end": "1462210"
  },
  {
    "text": "because they involve analysis.",
    "start": "1462210",
    "end": "1467720"
  },
  {
    "text": "They're basic tools. They're sort of\nthe first thing you think of if you're trying\nto estimate a probability.",
    "start": "1467720",
    "end": "1475560"
  },
  {
    "text": "Does it fit Markov? And Markov only applies--",
    "start": "1475560",
    "end": "1481060"
  },
  {
    "text": "so I'll put only applies--  when the x's are all\ngreater or equal 0.",
    "start": "1481060",
    "end": "1487720"
  },
  {
    "text": "Here, does it fit Chebyshev? And now we're taking\nabsolute values.",
    "start": "1487720",
    "end": "1492789"
  },
  {
    "text": "So we're not concerned\nabout the size of x. And we're taking\na distance from m.",
    "start": "1492790",
    "end": "1498240"
  },
  {
    "text": "So we're obviously in\nthe world of variances. We're distances from m.",
    "start": "1498240",
    "end": "1505210"
  },
  {
    "text": "And the proof of Chebyshev\ncomes directly from Markov.",
    "start": "1505210",
    "end": "1510870"
  },
  {
    "text": "So I'm going to apply Markov--",
    "start": "1510870",
    "end": "1516510"
  },
  {
    "text": "so good thing that\nMarkov came first-- ",
    "start": "1516510",
    "end": "1522680"
  },
  {
    "text": "to-- now let me just\nsay this right-- ",
    "start": "1522680",
    "end": "1531270"
  },
  {
    "text": "to a new, let me call it, y--",
    "start": "1531270",
    "end": "1539070"
  },
  {
    "text": "this will be a new output.",
    "start": "1539070",
    "end": "1545279"
  },
  {
    "text": "And it will be x\nminus m squared.",
    "start": "1545280",
    "end": "1552470"
  },
  {
    "start": "1552470",
    "end": "1558190"
  },
  {
    "text": "Of course, with the\nsame probability. So yi is xi minus m,\nthe mean, squared.",
    "start": "1558190",
    "end": "1567040"
  },
  {
    "text": "And the same probability,\nsame probabilities Pi.",
    "start": "1567040",
    "end": "1573990"
  },
  {
    "text": " So I guess if I'm\ngoing to apply--",
    "start": "1573990",
    "end": "1582200"
  },
  {
    "text": "I'm just going to take the y's\nhere instead of the x's here",
    "start": "1582200",
    "end": "1591860"
  },
  {
    "text": "and then apply Markov. So what is x bar? So if I want to\napply Markov, I have",
    "start": "1591860",
    "end": "1598100"
  },
  {
    "text": "to figure out the mean of x. Over here, I have to\nfigure out the mean of y.",
    "start": "1598100",
    "end": "1603140"
  },
  {
    "text": "What is the mean of y?",
    "start": "1603140",
    "end": "1610040"
  },
  {
    "text": "The mean value, the sum of\nprobabilities times y's.",
    "start": "1610040",
    "end": "1615440"
  },
  {
    "start": "1615440",
    "end": "1623019"
  },
  {
    "text": "You're supposed to recognize it. This is the sum\nof probabilities.",
    "start": "1623020",
    "end": "1628360"
  },
  {
    "text": " And my y's are the xi\nminus the mean squared.",
    "start": "1628360",
    "end": "1636804"
  },
  {
    "text": " So this is the mean\nfor this y thing",
    "start": "1636805",
    "end": "1645419"
  },
  {
    "text": "that I've brought\nin has that formula. And we recognize what\nthat quantity is.",
    "start": "1645420",
    "end": "1651450"
  },
  {
    "text": "That is? That's sigma squared, sigma\nsquared for the original x's.",
    "start": "1651450",
    "end": "1657500"
  },
  {
    "text": "So that's great. So the mean is sigma--\nis the old sigma squared.",
    "start": "1657500",
    "end": "1666010"
  },
  {
    "text": "Those are exclamation marks.  Do see that now Chebyshev\nis looking like Markov?",
    "start": "1666010",
    "end": "1676117"
  },
  {
    "text": " Over here will be the x--",
    "start": "1676118",
    "end": "1682370"
  },
  {
    "text": "now I want the expected\nvalue of y over the--",
    "start": "1682370",
    "end": "1689180"
  },
  {
    "text": "let's see, yeah, so the\nexpected y is going to be that.",
    "start": "1689180",
    "end": "1696070"
  },
  {
    "text": "And now what do I\nhave to divide by? I want to know probability of\nthis thing being bigger than a.",
    "start": "1696070",
    "end": "1705570"
  },
  {
    "text": "But now I'm looking at the y's. So the probability\nof if x minus m",
    "start": "1705570",
    "end": "1713490"
  },
  {
    "text": "is greater than or equal to a,\nthen x minus xi minus m squared",
    "start": "1713490",
    "end": "1719670"
  },
  {
    "text": "is greater equal a squared. So my a over here\nfor x is now turning,",
    "start": "1719670",
    "end": "1731580"
  },
  {
    "text": "in this problem\nwhere I'm looking at probability greater\nequal a but squaring it,",
    "start": "1731580",
    "end": "1737470"
  },
  {
    "text": "this is the a squared.",
    "start": "1737470",
    "end": "1742789"
  },
  {
    "text": "So that's Markov applied to y. Here is Markov applied to x.",
    "start": "1742790",
    "end": "1749190"
  },
  {
    "text": "And x had to be greater equal 0. So over here, Chebyshev took a\ny, which was greater equal to 0",
    "start": "1749190",
    "end": "1756800"
  },
  {
    "text": "than just applied\nMarkov and recognize",
    "start": "1756800",
    "end": "1762390"
  },
  {
    "text": "that mean of his variable,\nx minus m squared",
    "start": "1762390",
    "end": "1768270"
  },
  {
    "text": "was exactly sigma squared. And it fell out.",
    "start": "1768270",
    "end": "1773800"
  },
  {
    "text": "So again, here is a very\nsimple proof for Markov.",
    "start": "1773800",
    "end": "1783900"
  },
  {
    "text": "And then everybody agrees that\nChebyshev follows right away from Markov.",
    "start": "1783900",
    "end": "1789660"
  },
  {
    "text": "So those are two\nbasic inequalities. Now, the other topic that\nI wanted to deal with",
    "start": "1789660",
    "end": "1799440"
  },
  {
    "text": "was covariance,\ncovariance matrix. You have to get comfortable\nwith what's the covariance.",
    "start": "1799440",
    "end": "1807660"
  },
  {
    "start": "1807660",
    "end": "1816550"
  },
  {
    "start": "1815000",
    "end": "2205000"
  },
  {
    "text": "So covariance,\ncovariance matrix,",
    "start": "1816550",
    "end": "1825450"
  },
  {
    "text": "and it will be m by m when I\nhave m experiments at once.",
    "start": "1825450",
    "end": "1837950"
  },
  {
    "text": " And let me take m equal to 2.",
    "start": "1837950",
    "end": "1844500"
  },
  {
    "text": "You'll see everything\nfor m equal to 2. So we're expecting to\nget a 2 by 2 matrix.",
    "start": "1844500",
    "end": "1853620"
  },
  {
    "text": "And what are we starting with? We start we're doing\ntwo experiments at once.",
    "start": "1853620",
    "end": "1859179"
  },
  {
    "text": "So we have two\noutputs, an x and a y.",
    "start": "1859180",
    "end": "1867610"
  },
  {
    "text": " So the x's are the outputs\nfrom the x experiment.",
    "start": "1867610",
    "end": "1873390"
  },
  {
    "text": "The y's are the output\nfrom a second experiment.",
    "start": "1873390",
    "end": "1878900"
  },
  {
    "text": "We're flipping two coins. So let's take that\nexample, two coins.",
    "start": "1878900",
    "end": "1886190"
  },
  {
    "text": "Coin 1 gets 0 or 1 with P\nequal to the probability 1/2.",
    "start": "1886190",
    "end": "1897080"
  },
  {
    "text": "Coin 2, 0 or 1 with\nprobability 1/2.",
    "start": "1897080",
    "end": "1906760"
  },
  {
    "text": "So they're fair coins.  But what I haven't said\nis, is there a connection",
    "start": "1906760",
    "end": "1916290"
  },
  {
    "text": "between the output-- this is the x. This is the y--",
    "start": "1916290",
    "end": "1923760"
  },
  {
    "text": "if I glue the coins together,\nthen the two outputs are the same. I think for me this is a\nmodel question that brings out",
    "start": "1923760",
    "end": "1933390"
  },
  {
    "text": "the main point of covariance. If I flipped two\ncoins separately,",
    "start": "1933390",
    "end": "1940270"
  },
  {
    "text": "quite independently, then\nI don't know more about y",
    "start": "1940270",
    "end": "1949600"
  },
  {
    "text": "from knowing x. If I know the\nanswer to one flip, it doesn't tell me\nanything about the second",
    "start": "1949600",
    "end": "1955120"
  },
  {
    "text": "if they're independent,\nuncorrelated. But if the two coins\nare glued together,",
    "start": "1955120",
    "end": "1962850"
  },
  {
    "text": "then heads will come\nup for both coins.",
    "start": "1962850",
    "end": "1968510"
  },
  {
    "text": "I'll only have\ntwo possibilities. It'll be heads heads\nor tails tails. Let me let me write down\nthose two different scenarios.",
    "start": "1968510",
    "end": "1978559"
  },
  {
    "text": "So unglued-- I never expected\nto write that word in a math",
    "start": "1978560",
    "end": "1986100"
  },
  {
    "text": "class-- unglued.  And what am I going\nto write down?",
    "start": "1986100",
    "end": "1993149"
  },
  {
    "text": "I'm going to write down a matrix\nwith heads, tails for coin 1,",
    "start": "1993150",
    "end": "2004850"
  },
  {
    "text": "and heads and tails for coin 2. So the possibilities are\ncoin one get heads and coin 2",
    "start": "2004850",
    "end": "2012730"
  },
  {
    "text": "gets heads. What's the probability of that? This is the unglued case.",
    "start": "2012730",
    "end": "2017909"
  },
  {
    "text": "So I'm going to create\na little probability matrix of joint probabilities.",
    "start": "2017910",
    "end": "2023790"
  },
  {
    "text": "That's really the key word\nthat I'm discussing here--",
    "start": "2023790",
    "end": "2029580"
  },
  {
    "text": "joint probability.  So let's complete that matrix.",
    "start": "2029580",
    "end": "2037580"
  },
  {
    "text": "So I have unglued coins,\nindependent coins. I flip them both. What is the chances of\ngetting heads on both?",
    "start": "2037580",
    "end": "2046150"
  },
  {
    "text": "1/4. What are the chances of--\nwhat do I put in here?",
    "start": "2046150",
    "end": "2051949"
  },
  {
    "text": "This means heads\non the first coin and tails on this second coin. And the probability of that is?",
    "start": "2051949",
    "end": "2058690"
  },
  {
    "text": "1/4. And 1/4 here and 1/4 here.",
    "start": "2058690",
    "end": "2065089"
  },
  {
    "text": "So I've got four possibilities,\nwhich I put into a 2 by 2 matrix, instead\nof a long vector.",
    "start": "2065090",
    "end": "2072080"
  },
  {
    "text": "My four possibilities are\nheads heads, heads tails, tails heads, and tails tails.",
    "start": "2072080",
    "end": "2078350"
  },
  {
    "text": "And they have\nequal probability-- 1/4. But now, if they're glued, heads\nand tails on the first coin,",
    "start": "2078350",
    "end": "2094408"
  },
  {
    "text": "heads and tails on the\nsecond coin, now what do I put in there?",
    "start": "2094409",
    "end": "2101340"
  },
  {
    "text": "So the two coins\nare glued together. What is the chance that\nthey both come up heads? ",
    "start": "2101340",
    "end": "2110160"
  },
  {
    "text": "1/2. Because if one comes up heads,\nthe other one is glued to it.",
    "start": "2110160",
    "end": "2116490"
  },
  {
    "text": "It will also. What's the probability of heads\ntails, heads on one, tails",
    "start": "2116490",
    "end": "2122760"
  },
  {
    "text": "on the other, is of course? AUDIENCE: Zero. GILBERT STRANG: Zero, thanks. And here, zero.",
    "start": "2122760",
    "end": "2127940"
  },
  {
    "text": "And here, 1/2. So what I've created\nare those two setups,",
    "start": "2127940",
    "end": "2136890"
  },
  {
    "text": "two different scenarios\nof unglued and glued. ",
    "start": "2136890",
    "end": "2143340"
  },
  {
    "text": "But each experimental\nsetup has its matrix",
    "start": "2143340",
    "end": "2150060"
  },
  {
    "text": "of joint probabilities. That's the thing that there\nare four numbers here,",
    "start": "2150060",
    "end": "2156740"
  },
  {
    "text": "four numbers. We have all possibilities. We have any possible x and at\nthe same time any possible y.",
    "start": "2156740",
    "end": "2168420"
  },
  {
    "text": "So suppose we were\nrunning three experiments. ",
    "start": "2168420",
    "end": "2179020"
  },
  {
    "text": "So what would be the what\nwould be the situation if I was running three\nexperiments with three",
    "start": "2179020",
    "end": "2187180"
  },
  {
    "text": "independent, fair coins. I'd be in this unglued picture.",
    "start": "2187180",
    "end": "2193210"
  },
  {
    "text": "But I would have three different\nexperiments that I'm running.",
    "start": "2193210",
    "end": "2199170"
  },
  {
    "text": "Then what would I\nbe looking at then?",
    "start": "2199170",
    "end": "2204540"
  },
  {
    "text": "Just the whole\nidea is to see what is this like joint probability.",
    "start": "2204540",
    "end": "2211590"
  },
  {
    "start": "2205000",
    "end": "2565000"
  },
  {
    "text": "So suppose I have\nthree coins unglued. ",
    "start": "2211590",
    "end": "2221170"
  },
  {
    "text": "Then I want to know like the\nprobability of getting heads",
    "start": "2221170",
    "end": "2226240"
  },
  {
    "text": "on the first, heads on the\nsecond, heads on the third. Will be what? Just give me that number.",
    "start": "2226240",
    "end": "2233430"
  },
  {
    "text": "What will be the probability\nthat all three of them independently come up heads? AUDIENCE: 1/8.",
    "start": "2233430",
    "end": "2238500"
  },
  {
    "text": "GILBERT STRANG: 1/8, OK. But now my question is-- so what do I have?",
    "start": "2238500",
    "end": "2247280"
  },
  {
    "text": "Then I have\nprobability of heads, of, say, tails heads heads.",
    "start": "2247280",
    "end": "2253539"
  },
  {
    "text": "I've got three indices\nhere and eventually down the probability\nof tails tails tails.",
    "start": "2253540",
    "end": "2259750"
  },
  {
    "text": "Everybody sees that the\nnumbers are going to be 1/8. But where do those fit in?",
    "start": "2259750",
    "end": "2267120"
  },
  {
    "text": " They don't fit in a\nmatrix, because I've got 3 indices here.",
    "start": "2267120",
    "end": "2276440"
  },
  {
    "text": "So I guess what we're seeing,\nI sort of realized today, we're seeing for the\nfirst time a tensor.",
    "start": "2276440",
    "end": "2282570"
  },
  {
    "text": "A tensor is a\nthree-way structure,",
    "start": "2282570",
    "end": "2289860"
  },
  {
    "text": "three-way matrix you could say. So I guess I think of this\ninstead of a square like that,",
    "start": "2289860",
    "end": "2303760"
  },
  {
    "text": "an ordinary matrix, I have\nto think of a cube, right? I have a cube with two rows,\ntwo columns, and two whatevers.",
    "start": "2303760",
    "end": "2316800"
  },
  {
    "text": " Layer, somebody might\nsay layers for that.",
    "start": "2316800",
    "end": "2323160"
  },
  {
    "text": "You see that the\nmatrix has become a three-way thing, a tensor.",
    "start": "2323160",
    "end": "2338000"
  },
  {
    "text": "And the entries in that tensor-- so it's 2 by 2 by 2. ",
    "start": "2338000",
    "end": "2346579"
  },
  {
    "text": "But instead of m\nby n for a matrix, I have to give you the number\nof rows, the number of columns,",
    "start": "2346580",
    "end": "2352880"
  },
  {
    "text": "and the number of layers\ngoing into the board. So rows going one way--",
    "start": "2352880",
    "end": "2360310"
  },
  {
    "text": "you know, columns, rows, and\nthen layers are going in deep.",
    "start": "2360310",
    "end": "2366110"
  },
  {
    "text": "So it will have eight entries. And, of course, in\nthis simple case",
    "start": "2366110",
    "end": "2375140"
  },
  {
    "text": "each will be 1/8 in that\nunglued, totally independent",
    "start": "2375140",
    "end": "2384019"
  },
  {
    "text": "way. But then you can\nimagine some dependence.",
    "start": "2384020",
    "end": "2390110"
  },
  {
    "text": "So what would happen if\nI glued coins 1 and 3? ",
    "start": "2390110",
    "end": "2396859"
  },
  {
    "text": "I would still have a\ntensor, still have a 2 by 2 by 2 tensor of all\nthe possibilities.",
    "start": "2396860",
    "end": "2406089"
  },
  {
    "text": "But some of those are\ngoing to have probability zero, the joint probability. If I've glued coin 1 to coin 3,\nthen the probability of jointly",
    "start": "2406090",
    "end": "2416500"
  },
  {
    "text": "seeing heads on one,\nwhatever on two, tails on 3",
    "start": "2416500",
    "end": "2422530"
  },
  {
    "text": "will be 0, right? Because that can't happen\nif I've glued coins 1 and 3.",
    "start": "2422530",
    "end": "2429830"
  },
  {
    "text": "So I'll have eight\nentries in here.  This is the unglued case.",
    "start": "2429830",
    "end": "2436215"
  },
  {
    "text": " And then I could have a case\nwhere two coins are glued.",
    "start": "2436215",
    "end": "2442310"
  },
  {
    "text": " And as I say, I think I'd\n1/4 four times probably.",
    "start": "2442310",
    "end": "2453714"
  },
  {
    "start": "2453715",
    "end": "2459030"
  },
  {
    "text": "And then if I had any spare\nglue, I glue all three coins.",
    "start": "2459030",
    "end": "2464890"
  },
  {
    "text": " I flip that stuck\ntogether thing,",
    "start": "2464890",
    "end": "2472740"
  },
  {
    "text": "and I never get\nheads tails heads. Only possibilities\nI get our heads",
    "start": "2472740",
    "end": "2478530"
  },
  {
    "text": "heads heads and\ntails, tails, tails, because they're glued together. So what would be the situation\nfor three coins glued?",
    "start": "2478530",
    "end": "2487869"
  },
  {
    "text": " What will be the entries\nin the in the matrix",
    "start": "2487870",
    "end": "2496170"
  },
  {
    "text": "of joint probabilities? What will be the\njoint probability? So the probability of heads\nheads heads, of seeing heads",
    "start": "2496170",
    "end": "2503310"
  },
  {
    "text": "from all three will be? AUDIENCE: 1/2. GILBERT STRANG: 1/2. 1/2. Because I'm flipping this heavy\nmix of three coins together,",
    "start": "2503310",
    "end": "2513020"
  },
  {
    "text": "I get 1/2 twice. ",
    "start": "2513020",
    "end": "2521070"
  },
  {
    "text": "Actually, this is a good\nintroduction to tensors",
    "start": "2521070",
    "end": "2526170"
  },
  {
    "text": "in a way, because the first\nstep in understanding tensor is to think of\nthree-way matrices,",
    "start": "2526170",
    "end": "2535250"
  },
  {
    "text": "think of three-way things. We just haven't done that.",
    "start": "2535250",
    "end": "2540440"
  },
  {
    "text": "And now we have to do it. And, of course, four-way\nor n-way tensors",
    "start": "2540440",
    "end": "2546920"
  },
  {
    "text": "are now understood. So these are tensors with\nvery special, simple things.",
    "start": "2546920",
    "end": "2557080"
  },
  {
    "text": "So now, I have to say, what\nis the covariance matrix?",
    "start": "2557080",
    "end": "2564120"
  },
  {
    "text": "What's the covariance matrix? So now I'm ready for that,\nand I'll put it here.",
    "start": "2564120",
    "end": "2569700"
  },
  {
    "start": "2565000",
    "end": "3300000"
  },
  {
    "text": "That's the final\ntopic for today. ",
    "start": "2569700",
    "end": "2575920"
  },
  {
    "text": "So the covariance matrix. ",
    "start": "2575920",
    "end": "2584329"
  },
  {
    "text": "So I'm saying matrix, because\nI'm just going to have-- yeah, the covariance matrix.",
    "start": "2584330",
    "end": "2590560"
  },
  {
    "text": "Yeah, it's going to be\n2 by 2 for two coins.",
    "start": "2590560",
    "end": "2600200"
  },
  {
    "text": "So it is a matrix. For three coins,\nit will be 3 by 3.",
    "start": "2600200",
    "end": "2607339"
  },
  {
    "text": "But it is a matrix. So how is it defined?",
    "start": "2607340",
    "end": "2612508"
  },
  {
    "text": "And what am I going to call it? I think I'll call v, because\nreally the key ideas variance.",
    "start": "2612508",
    "end": "2621160"
  },
  {
    "text": "Covariance is telling\nus that we're also interested in the joint\noutcome, an x and y.",
    "start": "2621160",
    "end": "2635010"
  },
  {
    "text": "So it's a variance. So I'm going to add up over\nall plausible i and j--",
    "start": "2635010",
    "end": "2645525"
  },
  {
    "text": " sorry, all possible outcomes.",
    "start": "2645525",
    "end": "2653580"
  },
  {
    "text": "Yeah, that's not right.  All possible xi and yj.",
    "start": "2653580",
    "end": "2664070"
  },
  {
    "text": "So I'm running these two\nexperiments at the same time. From experiment 1,\nthe output's an x.",
    "start": "2664070",
    "end": "2671200"
  },
  {
    "text": "From experiment 2,\nthe output's a y. Then what is Pij?",
    "start": "2671200",
    "end": "2676835"
  },
  {
    "text": " What does that symbol mean?",
    "start": "2676835",
    "end": "2684610"
  },
  {
    "text": "That's the guy in\nour 2 by 2 matrix, like that one or that one,\ndepending on the gluing",
    "start": "2684610",
    "end": "2694660"
  },
  {
    "text": "or not gluing. So Pij, let me say what it is.",
    "start": "2694660",
    "end": "2699880"
  },
  {
    "text": "This is the probability\nthat x is xi",
    "start": "2699880",
    "end": "2708099"
  },
  {
    "text": "and that the second\noutput that this is yj. ",
    "start": "2708100",
    "end": "2714320"
  },
  {
    "text": "Let me give you a second\nexample to keep in mind. Suppose I'm looking\nat age and height.",
    "start": "2714320",
    "end": "2721150"
  },
  {
    "text": "So suppose x is the age\nof the sample, the person.",
    "start": "2721150",
    "end": "2728380"
  },
  {
    "text": "And y is the height. ",
    "start": "2728380",
    "end": "2734430"
  },
  {
    "text": "I want to know so what\nfraction have a certain age",
    "start": "2734430",
    "end": "2739470"
  },
  {
    "text": "and a certain height. I'm looking at every\npair, age and height. Age 11, height 4 feet.",
    "start": "2739470",
    "end": "2747690"
  },
  {
    "text": "Age 12, height 5 feet. Age 11, height 5 feet.",
    "start": "2747690",
    "end": "2752940"
  },
  {
    "text": "Each combination. So Pij is the probability that\nthese will both happen, both.",
    "start": "2752940",
    "end": "2759870"
  },
  {
    "start": "2759870",
    "end": "2767570"
  },
  {
    "text": "I'm going to add\nmore to it here. But that joint probability\nis really important.",
    "start": "2767570",
    "end": "2774290"
  },
  {
    "text": "So I'm going to ask\nyou more about that. Suppose that I take these\nPijs and that I add up",
    "start": "2774290",
    "end": "2782220"
  },
  {
    "text": "P1j plus P2j plus P3j. In other words, I\nsum the Pijs over i.",
    "start": "2782220",
    "end": "2792630"
  },
  {
    "text": "So I'm looking at a row,\nrow i, of my matrix.",
    "start": "2792630",
    "end": "2800224"
  },
  {
    "text": " So let me ask the question.",
    "start": "2800225",
    "end": "2806300"
  },
  {
    "text": "Maybe I have to put\nit somewhere else. ",
    "start": "2806300",
    "end": "2816109"
  },
  {
    "text": "What's the meaning of the\nsum of Pij over the i's?",
    "start": "2816110",
    "end": "2822565"
  },
  {
    "text": " What does that\nquantity look like?",
    "start": "2822565",
    "end": "2830320"
  },
  {
    "text": "So that's a probability. Pij is the\nprobability of getting a certain i and a certain j.",
    "start": "2830320",
    "end": "2837339"
  },
  {
    "text": "But now I'm including\nall the i's. So what am I seeing there?",
    "start": "2837340",
    "end": "2842658"
  },
  {
    "text": "AUDIENCE: Pj. GILBERT STRANG: Pj. Thanks. Pj. This is Pj. ",
    "start": "2842658",
    "end": "2850840"
  },
  {
    "text": "That's the probability of\nseeing j in the second guy, because I had to see something.",
    "start": "2850840",
    "end": "2856710"
  },
  {
    "text": "If I see j in the\nsecond one, I'm allowed to see anything\nhere in the first one.",
    "start": "2856710",
    "end": "2862180"
  },
  {
    "text": "But I'm adding those all up. So that's the point. Those would be\ncalled the marginals.",
    "start": "2862180",
    "end": "2869020"
  },
  {
    "text": "In my matrices, I would\nbe adding up along a row",
    "start": "2869020",
    "end": "2875560"
  },
  {
    "text": "or adding up down my column. Those are called the marginals\nof the joint probabilities.",
    "start": "2875560",
    "end": "2886390"
  },
  {
    "text": "So the marginals would be\nthe individual probabilities, Pi and Pj, in the case of\ntwo experiments going on",
    "start": "2886390",
    "end": "2895860"
  },
  {
    "text": "at the same time. Yeah, it's just like new ideas. Everything today has been\nsort of straightforward.",
    "start": "2895860",
    "end": "2903120"
  },
  {
    "text": "But it's different. OK, now, I'm going to\ncomplete the definition",
    "start": "2903120",
    "end": "2908790"
  },
  {
    "text": "of this covariance matrix. So it's going to be-- ",
    "start": "2908790",
    "end": "2914795"
  },
  {
    "text": "I want to have a square.  So it's going to be--",
    "start": "2914795",
    "end": "2921019"
  },
  {
    "text": "and it should be this is\nbetween x and the mean of x.",
    "start": "2921020",
    "end": "2927590"
  },
  {
    "text": "Mean 1 I could call\nit or mean of x. And y, the distance from\nthe mean of y times--",
    "start": "2927590",
    "end": "2938080"
  },
  {
    "text": "so it's going to be\ncolumn times row-- same x minus the mean of\nx, y minus the mean of y.",
    "start": "2938080",
    "end": "2947440"
  },
  {
    "text": " xi. ",
    "start": "2947440",
    "end": "2957255"
  },
  {
    "text": "yj. ",
    "start": "2957255",
    "end": "2963089"
  },
  {
    "text": "Can you look at this formula? So this is with two experiments,\ntwo coins, two experiments.",
    "start": "2963090",
    "end": "2975470"
  },
  {
    "text": "I get a 2 by 2 matrix. Everybody sees that. A column times a\nrow, 2 by 2 matrix.",
    "start": "2975470",
    "end": "2981450"
  },
  {
    "text": "And let's just see what would be\nthe 1, 1 entry in that matrix.",
    "start": "2981450",
    "end": "2987150"
  },
  {
    "text": " This is the covariance matrix.",
    "start": "2987150",
    "end": "2992690"
  },
  {
    "text": "So what is the 1, 1\nentry in that matrix? So the 1, 1 entry\nis coming from that times that, which is that thing\nsquared, times all the Pijs.",
    "start": "2992690",
    "end": "3003600"
  },
  {
    "text": "Add them up. What do you think\nI get for that? I get the variance\nof the x experiment,",
    "start": "3003600",
    "end": "3012870"
  },
  {
    "text": "the standard variance of\nthe x experiment, so v--",
    "start": "3012870",
    "end": "3018000"
  },
  {
    "text": "I have to tell\nyou what v is now. V, this is V. This\nis a 2 by 2 matrix.",
    "start": "3018000",
    "end": "3026940"
  },
  {
    "text": "Up here, I get the variance\nof the x experiment. What do I get down here?",
    "start": "3026940",
    "end": "3033450"
  },
  {
    "text": "The variance of the y\nexperiment by itself. Because it's y's times y's,\nit gives me that 2, 2 entry.",
    "start": "3033450",
    "end": "3040680"
  },
  {
    "text": "So this is just sigma y squared,",
    "start": "3040680",
    "end": "3047440"
  },
  {
    "text": "But the novelty is the 1,\n2, and it will be symmetric.",
    "start": "3047440",
    "end": "3053430"
  },
  {
    "text": "So it's a symmetric matrix. This is V transpose. I just have to see here.",
    "start": "3053430",
    "end": "3059700"
  },
  {
    "text": "So I've Pij times the distance\nof this guy times this guy.",
    "start": "3059700",
    "end": "3067890"
  },
  {
    "text": "That's what's going to show\nup in the 1, 2 position. ",
    "start": "3067890",
    "end": "3074230"
  },
  {
    "text": "It'll be in row 1. It'll be in column 2. It's the distances.",
    "start": "3074230",
    "end": "3081490"
  },
  {
    "text": "So what will it be in the\ncase of unglued coins, independent coins?",
    "start": "3081490",
    "end": "3088720"
  },
  {
    "text": "Zero. I mean, it's just\nfeeling like 0. I haven't done the computation. But I know that when I have\nindependent experiments, then",
    "start": "3088720",
    "end": "3097500"
  },
  {
    "text": "this covariance, which everybody\nwould write as sigma xy-- and it's the same here.",
    "start": "3097500",
    "end": "3103530"
  },
  {
    "text": "It's symmetric,\nsigma yx if you like. So those subscripts\nare telling me",
    "start": "3103530",
    "end": "3109980"
  },
  {
    "text": "that the sum of the P's,\njoint probabilities,",
    "start": "3109980",
    "end": "3116420"
  },
  {
    "text": "times the distance\nof x from its means, the distance of y from\nits main, added up",
    "start": "3116420",
    "end": "3122089"
  },
  {
    "text": "over all the possibilities. So the case of unglued coins,\nthe case of independent ones,",
    "start": "3122090",
    "end": "3130280"
  },
  {
    "text": "in that case, those are 0. Maybe worth just\nwriting that out.",
    "start": "3130280",
    "end": "3137029"
  },
  {
    "text": "You would get 0. So you have a diagonal matrix. The diagonal matrix is\njust separate variances,",
    "start": "3137030",
    "end": "3145250"
  },
  {
    "text": "because that's all the two\nindependent-- the experiments are independent. So all you can really expect--",
    "start": "3145250",
    "end": "3152000"
  },
  {
    "text": "information is sigma x\nsquared and sigma y squared. But if the two coins are\nglued together, then what?",
    "start": "3152000",
    "end": "3162410"
  },
  {
    "text": "If the two coins\nare glued together-- well, let me just say\nbecause time is up. This matrix will be singular.",
    "start": "3162410",
    "end": "3169849"
  },
  {
    "text": "If the two coins\nwere glued together, the determinant would be 0 here.",
    "start": "3169850",
    "end": "3176290"
  },
  {
    "text": "The sigma xy in the\nglued case would be--",
    "start": "3176290",
    "end": "3182390"
  },
  {
    "text": "squared-- would be the same\nas sigma x squared sigma y squared. ",
    "start": "3182390",
    "end": "3190359"
  },
  {
    "text": "Actually, we're probably\ngetting all these 1/4s. And that would make sense.",
    "start": "3190360",
    "end": "3196120"
  },
  {
    "text": " I'll just end with\nthis statement.",
    "start": "3196120",
    "end": "3203589"
  },
  {
    "text": "This matrix is positive\nsemidefinite always.",
    "start": "3203590",
    "end": "3210130"
  },
  {
    "text": "Positive semidefinite always. Because it's column\ntimes row, we",
    "start": "3210130",
    "end": "3215510"
  },
  {
    "text": "know that's positive\nsemidefinite. And it's multiplied by\nnumbers greater or equal 0.",
    "start": "3215510",
    "end": "3221270"
  },
  {
    "text": "So it's a combination of rank 1\npositive semidefinite definite. So it's positive\nsemidefinite definite.",
    "start": "3221270",
    "end": "3227720"
  },
  {
    "text": "Or positive definite. It's certainly positive\ndefinite in the independent case",
    "start": "3227720",
    "end": "3234349"
  },
  {
    "text": "when it's diagonal. And the totally dependent case,\nwhen the coins are completely",
    "start": "3234350",
    "end": "3240860"
  },
  {
    "text": "stuck together, that will\nbe the semidefinite case when these entries would\nall be the same actually.",
    "start": "3240860",
    "end": "3250990"
  },
  {
    "text": "So that's a first look\nat covariance matrices.",
    "start": "3250990",
    "end": "3256270"
  },
  {
    "text": "It brought in tensors. It brought in joint\nprobabilities. It brought in column times row.",
    "start": "3256270",
    "end": "3262549"
  },
  {
    "text": "It kept symmetry. And we recognized positive\ndefinite or positive",
    "start": "3262550",
    "end": "3268850"
  },
  {
    "text": "semidefinite definite. So in between, coins\nthat were partly glued, partly independent, but\nnot completely independent",
    "start": "3268850",
    "end": "3275960"
  },
  {
    "text": "experiments, then this\nnumber would be smaller. ",
    "start": "3275960",
    "end": "3282630"
  },
  {
    "text": "This wouldn't be 0, but it would\nbe smaller than these numbers. ",
    "start": "3282630",
    "end": "3289160"
  },
  {
    "text": "I've run four minutes over. You're very kind to stay. So have a wonderful break.",
    "start": "3289160",
    "end": "3296099"
  },
  {
    "text": "And I'll see you a\nweek from Monday. Good. Thanks. ",
    "start": "3296100",
    "end": "3300738"
  }
]
[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": " NARRATOR: The following content\nis provided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "7410"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "7410",
    "end": "13960"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at",
    "start": "13960",
    "end": "19790"
  },
  {
    "text": "ocw.mit.edu.  PROFESSOR: OK, so I guess\nwe're ready to start.",
    "start": "19790",
    "end": "25140"
  },
  {
    "text": " Clearly, you can talk to\nus about the exams",
    "start": "25140",
    "end": "31370"
  },
  {
    "text": "later if you want to. And we will both be around after\nclass for a bit-- or",
    "start": "31370",
    "end": "37036"
  },
  {
    "text": "I'll be around after\nclass for a bit and regular office hours.",
    "start": "37036",
    "end": "42670"
  },
  {
    "text": "Wanted to finish talking about\n[INAUDIBLE] state Markov change today and go on to talk\nabout Markov processes.",
    "start": "42670",
    "end": "53500"
  },
  {
    "text": "And the first thing we want\nto talk about is what does reversibility mean.",
    "start": "53500",
    "end": "60520"
  },
  {
    "text": "I think reversibility is one\nof these very, very tricky concepts that you think you\nunderstand about five times,",
    "start": "60520",
    "end": "69170"
  },
  {
    "text": "and then you realize you\ndon't understand it about five times. And hopefully by the sixth time,\nand we will see at about",
    "start": "69170",
    "end": "76270"
  },
  {
    "text": "six times, so hopefully by the\nend of the term, it will look almost obvious to you.",
    "start": "76270",
    "end": "83410"
  },
  {
    "text": "And then, we're going to talk\nabout branching processes. I said and what got passed out\nto you that I'd be talking",
    "start": "83410",
    "end": "91880"
  },
  {
    "text": "about round robin and\nprocessor sharing. I decided not to do that.",
    "start": "91880",
    "end": "99240"
  },
  {
    "text": "It was too much complexity for\nthis part of the course. I will talk about it just\nfor a few minutes.",
    "start": "99240",
    "end": "105640"
  },
  {
    "text": "And then we'll go into\nMarkov processes. And we will see most of the\nthings we saw in Markov change",
    "start": "105640",
    "end": "114270"
  },
  {
    "text": "again but in a different context\nand in a slightly more complicated context.",
    "start": "114270",
    "end": "121770"
  },
  {
    "text": "So for any Markov chain, we\nhave these equations.",
    "start": "121770",
    "end": "128479"
  },
  {
    "text": " Typically, you just state the\nequation of the probability of",
    "start": "128479",
    "end": "134800"
  },
  {
    "text": "X sub n plus 1 given all the\nprevious terms is equal to probability of Xn n\nplus 1 given Xn.",
    "start": "134800",
    "end": "142819"
  },
  {
    "text": "It's an easy extension\nto write it this way. The probability of lots of\nthings in the future given",
    "start": "142820",
    "end": "148930"
  },
  {
    "text": "everything in the past is equal\nto lots of things in the future just given the most\nrecent thing in the past.",
    "start": "148930",
    "end": "155600"
  },
  {
    "text": "So what we did last time was to\nsay let's let A plus be any",
    "start": "155600",
    "end": "161570"
  },
  {
    "text": "function of all of these things\nhere, and let's A minus",
    "start": "161570",
    "end": "167290"
  },
  {
    "text": "be any function of all of these\nthings here except for X sub n, namely X sub n\nminus 1 down to X0.",
    "start": "167290",
    "end": "176000"
  },
  {
    "text": "And then what this says more\ngenerally is the probability of all these future things\ncondition on Xn, and all the",
    "start": "176000",
    "end": "185190"
  },
  {
    "text": "past things is equal to\nprobability of the future given just Xn.",
    "start": "185190",
    "end": "191909"
  },
  {
    "text": "Then, we wrote that by\nmultiplying by the probability of A minus given Xn.",
    "start": "191910",
    "end": "197739"
  },
  {
    "text": "And you can write it in this\nnice symmetric form here. ",
    "start": "197740",
    "end": "204620"
  },
  {
    "text": "I'm hoping that these two laser\npointers, one of them will keep working.",
    "start": "204620",
    "end": "209770"
  },
  {
    "text": "And as soon as you write it in\nthis symmetric form, it's clear that you can again turn\nit around and write in the",
    "start": "209770",
    "end": "215909"
  },
  {
    "text": "past given the present and the\nfuture is equal to the past given the present.",
    "start": "215910",
    "end": "222850"
  },
  {
    "text": "So this formula really is\nthe most symmetric form [? for it ?] and it really shows\nthe symmetry of past",
    "start": "222850",
    "end": "231800"
  },
  {
    "text": "future, at least as far as\nMarkov chains are concerned. Yeah? AUDIENCE: I don't understand\n[INAUDIBLE]",
    "start": "231800",
    "end": "237290"
  },
  {
    "text": "write that down though. I feel like I'm missing\na step. For example, let's say I\n[INAUDIBLE], I can't infer",
    "start": "237290",
    "end": "250260"
  },
  {
    "text": "where I came from?  PROFESSOR: No, that's\nnot what this says.",
    "start": "250260",
    "end": "256190"
  },
  {
    "start": "256190",
    "end": "261489"
  },
  {
    "text": "I mean all it says is a\nprobabilistic statement. It says everything you can say\nabout X sub n plus 1 which was",
    "start": "261490",
    "end": "273040"
  },
  {
    "text": "the first way we stated. Everything you know about X sub\nn plus 1, you can find out",
    "start": "273040",
    "end": "279039"
  },
  {
    "text": "by just looking at X sub n. And knowing the things before\nthat doesn't help you at all.",
    "start": "279040",
    "end": "286370"
  },
  {
    "text": "When you write it out a Markov\nchain in terms of a graph, you can see this because you see\ntransitions going from one",
    "start": "286370",
    "end": "294080"
  },
  {
    "text": "state to the next state. And you don't remember\nwhat the past is.",
    "start": "294080",
    "end": "299219"
  },
  {
    "text": "The only part of the past\nyou remember is just that last state. ",
    "start": "299220",
    "end": "307420"
  },
  {
    "text": "It look you're still puzzled. ",
    "start": "307420",
    "end": "313540"
  },
  {
    "text": "So it's not how it's saying we\ncan't tell anything about the past and the future.",
    "start": "313540",
    "end": "319100"
  },
  {
    "text": "In fact, if you don't condition\non X sub n, this",
    "start": "319100",
    "end": "325050"
  },
  {
    "text": "stuff back here has a great\ndeal to do with the stuff up here. I mean it's only when you do\nthis conditioning, it is",
    "start": "325050",
    "end": "333650"
  },
  {
    "text": "saying that the conditioning\nat the present is the only linkage you have between\npast and future.",
    "start": "333650",
    "end": "343410"
  },
  {
    "text": "If you know where you are now,\nyou don't have to know anything about the past and know\nwhat's going to happen in",
    "start": "343410",
    "end": "349639"
  },
  {
    "text": "the future. That's not the way life is. I mean life is not\na Markov chain.",
    "start": "349640",
    "end": "354919"
  },
  {
    "text": "It's just the way these\nMarkov chains are. But this very symmetric\nstatement says that as far as",
    "start": "354920",
    "end": "361990"
  },
  {
    "text": "Markov chains are concerned,\npast and future look the same.",
    "start": "361990",
    "end": "367630"
  },
  {
    "text": "And that's the idea that we're\ntrying to use when we get into reversibility. This isn't saying anything about\nreversibility, yet this",
    "start": "367630",
    "end": "375700"
  },
  {
    "text": "is just giving a general\nproperty that Markov chains have. And when you write this out,\nit says the probability of",
    "start": "375700",
    "end": "384280"
  },
  {
    "text": "this past state given Xn and\neverything in the future is",
    "start": "384280",
    "end": "389510"
  },
  {
    "text": "equal to the probability of the\npast state given X sub n. So this is really the Markov\ncondition running from future",
    "start": "389510",
    "end": "400370"
  },
  {
    "text": "down to past. And it's saying that if you\nwant to evaluate these",
    "start": "400370",
    "end": "405440"
  },
  {
    "text": "probabilities of where you were\ngiven anything now and",
    "start": "405440",
    "end": "410830"
  },
  {
    "text": "further on, or put it in a more\nsensible way, if you know everything over the past year,\nand from knowing everything",
    "start": "410830",
    "end": "420950"
  },
  {
    "text": "over the past year, you want\nto decide what can you tell about what happens the year\nbefore, what it's saying is",
    "start": "420950",
    "end": "429260"
  },
  {
    "text": "the probability of what happened\nthe year before is statistically a function only\non the last day on the first",
    "start": "429260",
    "end": "438050"
  },
  {
    "text": "day of this year that you're\nconditioning on. ",
    "start": "438050",
    "end": "445880"
  },
  {
    "text": "So Markov condition works\nin both directions. You need to study state and\nforward change to be there in",
    "start": "445880",
    "end": "455430"
  },
  {
    "text": "order to have homogeneity\nin a backward chain. In other words, usually, we\ndefine a Markov chain by",
    "start": "455430",
    "end": "460650"
  },
  {
    "text": "starting off at time zero and\nthen evolving from there. So when you go backwards, that\nfact that you started at time",
    "start": "460650",
    "end": "469520"
  },
  {
    "text": "zero and said something about\ntime zero destroys the symmetry between past\nand feature.",
    "start": "469520",
    "end": "475740"
  },
  {
    "text": "But if you start off in steady\nstate, then everything is as it should be.",
    "start": "475740",
    "end": "481440"
  },
  {
    "text": " So if you have a\npositive-recurrent Markov",
    "start": "481440",
    "end": "487919"
  },
  {
    "text": "chain in steady state, it\ncan't be in steady state unless it's positive-recurrent,\nbecause",
    "start": "487920",
    "end": "494620"
  },
  {
    "text": "otherwise, you can't evaluate\nthe steady-state probabilities. The steady-state probabilities\ndon't exist.",
    "start": "494620",
    "end": "500900"
  },
  {
    "text": "And the backward probabilities\nare probability that X sub n minus 1 equals j given that\nX sub n equals i is the",
    "start": "500900",
    "end": "509690"
  },
  {
    "text": "transition probability from i\nto j times the steade-state probability pi sub\nj over pi sub y.",
    "start": "509690",
    "end": "517349"
  },
  {
    "text": "This looks more sensible if you\nbring the pi sub i over there, pi sub i times\nprobability of Xn minus 1",
    "start": "517350",
    "end": "525770"
  },
  {
    "text": "equals j given Xn equals i is\nreally the probability of Xn",
    "start": "525770",
    "end": "535930"
  },
  {
    "text": "equals i and Xn minus\n1 equals j. So what this statement is really\nsaying is it's pi i",
    "start": "535930",
    "end": "549400"
  },
  {
    "text": "times the probability of Xn\nminus one equals j given Xn equals i is really the\nprobability of being in state",
    "start": "549400",
    "end": "560330"
  },
  {
    "text": "j at time n minus 1 and state\ni at time [? n. ?]",
    "start": "560330",
    "end": "566280"
  },
  {
    "text": "And we're just writing that\nin two different ways. It's the base law way of\nwriting things in two",
    "start": "566280",
    "end": "571360"
  },
  {
    "text": "different ways. If we define this backward\nprobability, which we said you",
    "start": "571360",
    "end": "578050"
  },
  {
    "text": "can find by base law if you\nwant to work at it, if we define this to be the backward\ntransition probability, p sub",
    "start": "578050",
    "end": "586795"
  },
  {
    "text": "ij star, in other words, p sub\nij star is in this world where",
    "start": "586795",
    "end": "592450"
  },
  {
    "text": "things are moving backwards, it\ncorresponds to p sub j in the world where things\nare moving forward.",
    "start": "592450",
    "end": "599710"
  },
  {
    "text": "P sub ij star is then the\nprobability of being in state",
    "start": "599710",
    "end": "607180"
  },
  {
    "text": "j at the next time back given\nthat you're in state i at this",
    "start": "607180",
    "end": "612600"
  },
  {
    "text": "time if you're in state\nI at the present. In other words, if you're\nvisualizing moving from future",
    "start": "612600",
    "end": "621290"
  },
  {
    "text": "time back to backward time,\nthat's what your Markov chain is doing now.",
    "start": "621290",
    "end": "626860"
  },
  {
    "text": "These star transition\nprobabilities are the probabilities of moving\nbackward by one step,",
    "start": "626860",
    "end": "633310"
  },
  {
    "text": "conditional going where you were\nat time n, where you're going to be at time n minus\n1, if you will.",
    "start": "633310",
    "end": "641040"
  },
  {
    "text": "As I said, these things are much\neasier to deal with if you view them on a line, and you\nhave a right moving chain",
    "start": "641040",
    "end": "649020"
  },
  {
    "text": "which is what we usually think\nof as the chain moving from past to future.",
    "start": "649020",
    "end": "655270"
  },
  {
    "text": "And then you have a left moving\nchain, which is what you view as moving from\nfuture down to past.",
    "start": "655270",
    "end": "665209"
  },
  {
    "text": "OK, we define a chain as\nreversible if these backward probabilities are equal to\nthe forward transition",
    "start": "665210",
    "end": "673000"
  },
  {
    "text": "probabilities. So if a chain is reversible,\nit's says that pi I times P",
    "start": "673000",
    "end": "679360"
  },
  {
    "text": "sub ij, this is the probability\nthat you are at a",
    "start": "679360",
    "end": "686170"
  },
  {
    "text": "time n minus 1, you were in\nstate I, and then you move to state j.",
    "start": "686170",
    "end": "691380"
  },
  {
    "text": "So it's the probability of\nbeing in one state at one time, the next state\nat the next time.",
    "start": "691380",
    "end": "698760"
  },
  {
    "text": "It's the probability that Xn\nminus 1 and Xn are ij.",
    "start": "698760",
    "end": "705540"
  },
  {
    "text": "And this probability here is--",
    "start": "705540",
    "end": "711000"
  },
  {
    "start": "711000",
    "end": "723130"
  },
  {
    "text": "this equation is moving\nforward in time. So this equation here is the\nprobability that you were in",
    "start": "723130",
    "end": "729580"
  },
  {
    "text": "state j, and you move\nto state i. So what we're saying is the\nprobability of being in i",
    "start": "729580",
    "end": "736330"
  },
  {
    "text": "moving to j is the same as the\nprobability of being in j and moving to i.",
    "start": "736330",
    "end": "741620"
  },
  {
    "text": "It's the condition you have\non any birth-death chain. We said that on any birth-death\nchain, the",
    "start": "741620",
    "end": "748790"
  },
  {
    "text": "fraction of transitions from i\nto j has to be equal to the",
    "start": "748790",
    "end": "754560"
  },
  {
    "text": "total number of transitions\nfrom j to i. It's not that the probability\nof moving up given i is the",
    "start": "754560",
    "end": "761890"
  },
  {
    "text": "same as that of moving back. That's not what it's saying. It's saying that the probability\nof having a",
    "start": "761890",
    "end": "768480"
  },
  {
    "text": "transition over time\nis pi i times Pij.",
    "start": "768480",
    "end": "777250"
  },
  {
    "text": "Reversibility says that you make\nas many up transitions over time as you make down\ntransitions over the",
    "start": "777250",
    "end": "785110"
  },
  {
    "text": "same pair of states.  I think that's the simplest\nway to state the idea of",
    "start": "785110",
    "end": "791900"
  },
  {
    "text": "reversibility. The fraction of time that you\nmove from state i to state j",
    "start": "791900",
    "end": "797810"
  },
  {
    "text": "is the same as the fraction of\ntime in which you move from state j to state i.",
    "start": "797810",
    "end": "803160"
  },
  {
    "text": "It's what always happens on a\nbirth-death chain, because every time you go up, if you\never get back to the lower",
    "start": "803160",
    "end": "811350"
  },
  {
    "text": "part of the chain, you have to\nmove back over that same path. You can easily visualize other\nsituations where you have the",
    "start": "811350",
    "end": "818810"
  },
  {
    "text": "same condition if you have\nenough symmetry between the various probabilities\ninvolved.",
    "start": "818810",
    "end": "824150"
  },
  {
    "text": "But the simplest way is\nto have this sort of-- ",
    "start": "824150",
    "end": "832260"
  },
  {
    "text": "well, not only the simplest, but\nalso the most common way is to have a birth-death\nchain.",
    "start": "832260",
    "end": "838339"
  },
  {
    "text": "OK, so this leads us to\nthe statement, all positive-recurrent birth-death\nchains are reversible, and",
    "start": "838340",
    "end": "846060"
  },
  {
    "start": "840000",
    "end": "955000"
  },
  {
    "text": "that's the theorem. Now the question is what\ndo you do with that? ",
    "start": "846060",
    "end": "852040"
  },
  {
    "text": "Let's have a more general\nexample than a birth-death chain. Suppose the non-zero\ntransition of a",
    "start": "852040",
    "end": "859260"
  },
  {
    "text": "positive-recurrent Markov\nchain form a tree. Before we had the states going\non a line, and from each state",
    "start": "859260",
    "end": "873100"
  },
  {
    "text": "to the next state, there were\ntransition probabilities, you could only go up or\ndown on this line.",
    "start": "873100",
    "end": "879800"
  },
  {
    "text": "What I'm saying now is if you\nmake a tree you have the same sort of condition that you had\nbefore if the transitions on",
    "start": "879800",
    "end": "890210"
  },
  {
    "text": "the states look like a tree. ",
    "start": "890210",
    "end": "907520"
  },
  {
    "text": "So these are the only\ntransitions that exist in this Markov chain. These are the states here.",
    "start": "907520",
    "end": "913230"
  },
  {
    "text": " Again, you have this\ncondition.",
    "start": "913230",
    "end": "918720"
  },
  {
    "text": "The only way to get from this\nstate out to this state is to move through here so that the\nnumber of transitions that go",
    "start": "918720",
    "end": "928470"
  },
  {
    "text": "from here to there must be\nwithin one of a number of transitions that go from\nhere back to there.",
    "start": "928470",
    "end": "936160"
  },
  {
    "text": "So you have this reversibility\ncondition again on any tree.",
    "start": "936160",
    "end": "941259"
  },
  {
    "text": "And these birth-death chains\nare just very, very skinny trees where everything is\nlaid out on a line.",
    "start": "941260",
    "end": "946670"
  },
  {
    "text": "But this is the more\ngeneral case. And you'll see cases of\nthis as we move along. ",
    "start": "946670",
    "end": "957700"
  },
  {
    "start": "955000",
    "end": "1042000"
  },
  {
    "text": "The following theorem is one of\nthese things that you use all the time in solving\nproblems.",
    "start": "957700",
    "end": "964650"
  },
  {
    "text": "And it's extraordinarily\nuseful. It says for a Markov chain with\ntransition probabilities",
    "start": "964650",
    "end": "972190"
  },
  {
    "text": "P sub ij, if a set of numbers pi\nsub i exists so that all of",
    "start": "972190",
    "end": "980570"
  },
  {
    "text": "them are positive,\nthey sum to one. If you can find such a set of\nnumbers, and if they satisfy",
    "start": "980570",
    "end": "988400"
  },
  {
    "text": "this equation here, then you\nknow that the chain is",
    "start": "988400",
    "end": "995370"
  },
  {
    "text": "reversible, and you know that\nthose numbers are the steady-state probability.",
    "start": "995370",
    "end": "1000430"
  },
  {
    "text": "So you get everything at once. It's sort of like a\nguessing theorem. And I usually call it a guessing\ntheorem, because",
    "start": "1000430",
    "end": "1009060"
  },
  {
    "text": "starting out, it's not obvious\nthat these equations have to be satisfied. They're only satisfied if you\nhave a chain which is",
    "start": "1009060",
    "end": "1019740"
  },
  {
    "text": "reversible. But if you can find a solution\nto these equations, then, in fact, you know it's reversible,\nand you know you",
    "start": "1019740",
    "end": "1029230"
  },
  {
    "text": "found steady--state\nprobabilities. It's a whole lot easier to solve\nthis equation usually",
    "start": "1029230",
    "end": "1035059"
  },
  {
    "text": "than to solve the usual\nequation we have for steady-state probabilities.",
    "start": "1035060",
    "end": "1041839"
  },
  {
    "text": "But the proof of the theorem-- I just restated the theorem\nhere, leaving out all of the",
    "start": "1041839",
    "end": "1051320"
  },
  {
    "start": "1042000",
    "end": "1447000"
  },
  {
    "text": "boiler plate . If we take this equation for\nfixed j, and we sum over I,",
    "start": "1051320",
    "end": "1060360"
  },
  {
    "text": "what happens? When you sum over i over on\nthis side, you get the sum",
    "start": "1060360",
    "end": "1066130"
  },
  {
    "text": "over i of pi sub i P sub ij. When you sum over i on this\nside, you get pi sub j,",
    "start": "1066130",
    "end": "1074610"
  },
  {
    "text": "because when you sum P sub ji\nover i, you have to get one.",
    "start": "1074610",
    "end": "1080220"
  },
  {
    "text": "When you're in state j, you\nhave to go someplace. And you can only go one place,\neach with different",
    "start": "1080220",
    "end": "1087110"
  },
  {
    "text": "probabilities. So that gives you the usual\nsteady-state conditions.",
    "start": "1087110",
    "end": "1093910"
  },
  {
    "text": "If you can solve those steady\nstate conditions, then you know from what we did before\nthat the chain is",
    "start": "1093910",
    "end": "1100880"
  },
  {
    "text": "positive-recurrent. You know there are steady-state\nprobabilities. You know there's probabilities\nare all greater than zero.",
    "start": "1100880",
    "end": "1108460"
  },
  {
    "text": "So if there's any solution to\nthese steady-state equations, then you know the chain has\nto be positive-recurrent.",
    "start": "1108460",
    "end": "1116140"
  },
  {
    "text": "And you know it has to be\nreversible in this case. OK, here are a bunch of sanity\nchecks for reversibility.",
    "start": "1116140",
    "end": "1125220"
  },
  {
    "text": "In other words, if you're going\nto guess at something that's reversible and try to\nsolve these equations, you",
    "start": "1125220",
    "end": "1131200"
  },
  {
    "text": "might as well do a sanity\ncheck first. The simplest and most useful\nsanity check is if you want it",
    "start": "1131200",
    "end": "1140430"
  },
  {
    "text": "be reversible, and there's a\ntransition from i to j, then",
    "start": "1140430",
    "end": "1145510"
  },
  {
    "text": "there has to be a transition\nfrom j to I also. Mainly the number of transitions\ngoing from i to j",
    "start": "1145510",
    "end": "1152150"
  },
  {
    "text": "has to be the same over the\nlong term to number of transitions going from j to I.",
    "start": "1152150",
    "end": "1157809"
  },
  {
    "text": "If there's a zero transition\nprobability one way and not the other way, you can't\nsatisfy that equation.",
    "start": "1157810",
    "end": "1163330"
  },
  {
    "text": " If the chain is periodic, the\nperiod has to be too.",
    "start": "1163330",
    "end": "1172860"
  },
  {
    "text": "Why is that? Well, it's a long proof\nin the notes. And if you write everything down\nin algebra, it looks a",
    "start": "1172860",
    "end": "1178370"
  },
  {
    "text": "little long. If you just think about it,\nit's a lot shorter. If you're going around on a\ncycle of, say, link three, if",
    "start": "1178370",
    "end": "1187650"
  },
  {
    "text": "the chain is periodic, and it's\nperiodic with some period",
    "start": "1187650",
    "end": "1193550"
  },
  {
    "text": "others than two, then you know\nthat the set of states has to",
    "start": "1193550",
    "end": "1198590"
  },
  {
    "text": "partition into a\nset of subsets. And you have to move from one\nsubset, to the next subset, to",
    "start": "1198590",
    "end": "1205820"
  },
  {
    "text": "the next subset, and so forth. When you go backwards, you're\nmoving around that cycle in",
    "start": "1205820",
    "end": "1212310"
  },
  {
    "text": "the opposite direction. Now, the only way that moving\naround a cycle one way and",
    "start": "1212310",
    "end": "1218409"
  },
  {
    "text": "moving around it the other way\nworks out is when the cycle only has two states\n[? set in, ?]",
    "start": "1218410",
    "end": "1223610"
  },
  {
    "text": "because then you're\nmoving, and you're moving right back again. OK, so the period has to be\ntwo if it's periodic.",
    "start": "1223610",
    "end": "1229545"
  },
  {
    "text": " If there's any set of\ntransitions i to j, j to k,",
    "start": "1229545",
    "end": "1238980"
  },
  {
    "text": "and k to I, namely if you can\nmove around this way with some probability, then the\nprobability of moving back",
    "start": "1238980",
    "end": "1245760"
  },
  {
    "text": "again has to be the\nsame thing. And that's what this\nis saying.",
    "start": "1245760",
    "end": "1251190"
  },
  {
    "text": "This is moving around this cycle\nof length three one way.",
    "start": "1251190",
    "end": "1257940"
  },
  {
    "text": "This is the forward\nprobabilities for moving around a cycle, the opposite way\nand to have reversibility.",
    "start": "1257940",
    "end": "1265580"
  },
  {
    "text": "The probability of going one way\nhas to be the same as the probability going\nthe other way. ",
    "start": "1265580",
    "end": "1274809"
  },
  {
    "text": "Now, that sounds peculiar, and\nit gives me a good excuse to",
    "start": "1274810",
    "end": "1281150"
  },
  {
    "text": "point out one of the main things\nthat's going on here. When you say something is\nreversible, it doesn't usually",
    "start": "1281150",
    "end": "1289920"
  },
  {
    "text": "mean that P sub ij is\nequal to P sub ji.",
    "start": "1289920",
    "end": "1296060"
  },
  {
    "text": "What it means is that\npi sub I times Pij equals pi j times Pji.",
    "start": "1296060",
    "end": "1303900"
  },
  {
    "text": "Namely, the fraction of\ntransitions here is the same as the fraction of\ntransitions here.",
    "start": "1303900",
    "end": "1310500"
  },
  {
    "text": "Why is it that here I'm only\nusing the probabilities, and I'm not saying anything about\nthe initial probability?",
    "start": "1310500",
    "end": "1319130"
  },
  {
    "text": "It's because both of these\ncycles start with state i.",
    "start": "1319130",
    "end": "1324260"
  },
  {
    "text": "So what you really want to do\nis say pi I times Pij times Pjk times Pki is the same as\npi i times [INAUDIBLE]",
    "start": "1324260",
    "end": "1332096"
  },
  {
    "start": "1332096",
    "end": "1337120"
  },
  {
    "text": "And then you cancel\nout the pi. So when you have a cycle, you\ndon't need that initial",
    "start": "1337120",
    "end": "1343490"
  },
  {
    "text": "steady-state probability\nin there. There's a nice generalization\nof the guessing theorem to",
    "start": "1343490",
    "end": "1350299"
  },
  {
    "text": "non-reversible change and that\ngeneralization and it's proved the same way that\nthis is proved.",
    "start": "1350300",
    "end": "1358420"
  },
  {
    "text": "If you can find a set of\ntransition probabilities, P sub ij star, and to be a set of\ntransition probabilities,",
    "start": "1358420",
    "end": "1367800"
  },
  {
    "text": "they have to be non-negative. When you sum this over j,\nyou have to get one.",
    "start": "1367800",
    "end": "1373710"
  },
  {
    "text": "That's what you need to have\na set of transition probabilities. Then, all you need is pi sub i\ntimes P sub ij is equal to pi",
    "start": "1373710",
    "end": "1382110"
  },
  {
    "text": "j times P sub ji star. In other words, when you look\nat this backward transition",
    "start": "1382110",
    "end": "1389620"
  },
  {
    "text": "probability for an arbitrary\nMarkov chain which is positive-recurrent, this\nhas to equal this.",
    "start": "1389620",
    "end": "1396840"
  },
  {
    "text": "This is one of the conditions\nthat you have on a Markov chain. The interesting thing here\nis this is enough.",
    "start": "1396840",
    "end": "1404880"
  },
  {
    "text": "If you can guess a set of\nbackward transition probabilities to satisfy this\nequation for all i and j, then",
    "start": "1404880",
    "end": "1413460"
  },
  {
    "text": "you know you must have a set of\nsteady-state probabilities where the steady-state\nprobabilities are [INAUDIBLE].",
    "start": "1413460",
    "end": "1421480"
  },
  {
    "text": "And the way to prove this\nis the same as before. Namely, you sum this over j.",
    "start": "1421480",
    "end": "1434409"
  },
  {
    "text": "And when you sum this over\nj, you get the backward transition probability. So I'm not going to prove it.",
    "start": "1434410",
    "end": "1442460"
  },
  {
    "text": "I mean the proof is in the\nnotes, and it's really the same proof as we went\nthrough before. ",
    "start": "1442460",
    "end": "1449100"
  },
  {
    "text": "And incidentally, if you read\nthe section on round robin, you will find the key to finding\nout what's going on",
    "start": "1449100",
    "end": "1457920"
  },
  {
    "text": "there is, in fact,\nthat theorem. It's that way of solving for\nwhat the steady-state",
    "start": "1457920",
    "end": "1464090"
  },
  {
    "text": "probabilities have to be. While I'm at it, let me pause\nfor just a second, because",
    "start": "1464090",
    "end": "1471660"
  },
  {
    "text": "we're not going to go through\nthat section on round robin. Let me talk about what it is,\nwhat processor sharing is, and",
    "start": "1471660",
    "end": "1479610"
  },
  {
    "text": "why that result is\npretty important. If you're at all\ninterested in-- ",
    "start": "1479610",
    "end": "1487110"
  },
  {
    "text": "well, let's see. First pack of communication\nis something important.",
    "start": "1487110",
    "end": "1493299"
  },
  {
    "text": "Second, computer systems of\nall types is important. There was an enormous transition\nprobably 20 years",
    "start": "1493300",
    "end": "1500620"
  },
  {
    "text": "ago from computer systems\nsolving one job at a time, and",
    "start": "1500620",
    "end": "1506490"
  },
  {
    "text": "then it went to the system\nof solving many jobs concurrently. It would work a little bit on\none job, a little bit in",
    "start": "1506490",
    "end": "1512250"
  },
  {
    "text": "another, a little bit in\nanother, and so forth. And it turns out to be a very\ngood idea for doing that.",
    "start": "1512250",
    "end": "1520200"
  },
  {
    "text": "Or if you're interested in\nkilling systems, what happens if you have a killing system--",
    "start": "1520200",
    "end": "1529650"
  },
  {
    "text": "suppose it's a GG1 queue. So you have a different service",
    "start": "1529650",
    "end": "1535500"
  },
  {
    "text": "time for each customer. Or let's make it an MG1 queue.",
    "start": "1535500",
    "end": "1540550"
  },
  {
    "text": "Makes the argument cleaner. Different customers have\ndifferent service times.",
    "start": "1540550",
    "end": "1546370"
  },
  {
    "text": "We've seen that in an MG1 queue,\neverybody can be held",
    "start": "1546370",
    "end": "1552160"
  },
  {
    "text": "up by one slow customer. And if the customers have an\nenormously, widely varied",
    "start": "1552160",
    "end": "1560620"
  },
  {
    "text": "service time, some of them have\nrequired enormously long service time, that causes an\nenormous amount of queuing.",
    "start": "1560620",
    "end": "1568330"
  },
  {
    "text": "What happens if you use\nprocessor sharing, you have one server.",
    "start": "1568330",
    "end": "1574560"
  },
  {
    "text": "And it's simultaneously\nallocating service to every customer which is in queue.",
    "start": "1574560",
    "end": "1580660"
  },
  {
    "text": "So it takes a service\ncapability, and it splits it up end-wise.",
    "start": "1580660",
    "end": "1586440"
  },
  {
    "text": "And when you talk about\nprocessor sharing, you assume that there's no overhead for\ndoing the splitting.",
    "start": "1586440",
    "end": "1591860"
  },
  {
    "text": "And if there's no overhead for\ndoing the splitting, you can see intuitively what happens.",
    "start": "1591860",
    "end": "1596880"
  },
  {
    "text": "The customers that don't need\nmuch service are going to be",
    "start": "1596880",
    "end": "1602010"
  },
  {
    "text": "held up a little bit by these\ncustomers who require enormous amounts of service,\nbut not too much.",
    "start": "1602010",
    "end": "1609570"
  },
  {
    "text": "Because this customer that\nrequires enormous service is getting the same rate of\nservice as you are.",
    "start": "1609570",
    "end": "1616140"
  },
  {
    "text": "If that customer requires 100\nhours of service, and you only require one second of service,\nyou're going to get out very",
    "start": "1616140",
    "end": "1623750"
  },
  {
    "text": "much faster than they do. What happens when you\nanalyze all of this?",
    "start": "1623750",
    "end": "1630600"
  },
  {
    "text": "It turns out that you've\nturned the MG1 queue into an MM1 queue. ",
    "start": "1630600",
    "end": "1639710"
  },
  {
    "text": "In other words, if you're doing\nprocessor sharing, it",
    "start": "1639710",
    "end": "1645169"
  },
  {
    "text": "takes the same expected amount\nof time for you to get out as it would if all of the service\ntimes were exponential.",
    "start": "1645170",
    "end": "1651980"
  },
  {
    "text": " Now, that is why people\nwent to time",
    "start": "1651980",
    "end": "1657720"
  },
  {
    "text": "sharing a long time ago. Most of the arguments for it,\nespecially in the computer",
    "start": "1657720",
    "end": "1665090"
  },
  {
    "text": "science fraternity, were all\nsorts of other things. But there's this very\nsimple queuing",
    "start": "1665090",
    "end": "1670750"
  },
  {
    "text": "argument that led to that. Unfortunately, it's a fairly\ncomplicated queuing argument, which is why we're not\ngoing through it.",
    "start": "1670750",
    "end": "1677940"
  },
  {
    "text": "But it's a very important\nargument. Why, at the same time, did we\ngo to packet communication?",
    "start": "1677940",
    "end": "1684789"
  },
  {
    "text": "Well, there are all sorts of\nreasons for going to packet communication instead of\nsending messages, long",
    "start": "1684790",
    "end": "1690320"
  },
  {
    "text": "messages, one at a time. But one of them, and one of them\nis very important, is the",
    "start": "1690320",
    "end": "1696740"
  },
  {
    "text": "same process of sharing\nresell. If you split things up into\nsmall pieces, then what it",
    "start": "1696740",
    "end": "1702220"
  },
  {
    "text": "means is effectively things are\nbeing served in a process of sharing matter.",
    "start": "1702220",
    "end": "1708250"
  },
  {
    "text": "So again, you get this losing\nthe slow truck effect. And everybody gets through\neffectively in a",
    "start": "1708250",
    "end": "1716650"
  },
  {
    "text": "fair amount of time. OK. ",
    "start": "1716650",
    "end": "1725070"
  },
  {
    "start": "1718000",
    "end": "2104000"
  },
  {
    "text": "I probably said just the wrong\namount about that, so you can't understand what\nI was saying.",
    "start": "1725070",
    "end": "1732080"
  },
  {
    "text": "But I think if you read it,\nyou will get the idea of",
    "start": "1732080",
    "end": "1737500"
  },
  {
    "text": "what's going on. OK. Let's look at an\nMM1 queue now.",
    "start": "1737500",
    "end": "1743620"
  },
  {
    "text": "An MM1 queue, you remember,\nis a queue where you have customers coming in.",
    "start": "1743620",
    "end": "1749570"
  },
  {
    "text": "In a [? Poisson ?] manner, the\ninterval between customers is exponential.",
    "start": "1749570",
    "end": "1755400"
  },
  {
    "text": "That you couldn't model\nfor a lot of things. The service time\nis exponential.",
    "start": "1755400",
    "end": "1761674"
  },
  {
    "text": " And what we're going to do to\ntry to analyze this in terms",
    "start": "1761675",
    "end": "1768710"
  },
  {
    "text": "of mark of change, is to say\nwell, let's look at sampling",
    "start": "1768710",
    "end": "1775340"
  },
  {
    "text": "the state of the MM1 queue at\nsome very finely spaced",
    "start": "1775340",
    "end": "1780799"
  },
  {
    "text": "interval of time. And we'll make the interval of\ntime, delta, so small that",
    "start": "1780800",
    "end": "1786670"
  },
  {
    "text": "there's a negligible probability\nof having two customers come in in\nthe same interval.",
    "start": "1786670",
    "end": "1792400"
  },
  {
    "text": "And so there's a negligible\nprobability of having a customer come in and\na customer go",
    "start": "1792400",
    "end": "1797710"
  },
  {
    "text": "out in the same interval. It's effectively the same\nargument that we use to say",
    "start": "1797710",
    "end": "1803720"
  },
  {
    "text": "that a Poisson process is\neffectively the same as a",
    "start": "1803720",
    "end": "1810510"
  },
  {
    "text": "Bernoulli process, if you make\nthe time interval the step",
    "start": "1810510",
    "end": "1826990"
  },
  {
    "text": "size for the Bernoulli process\nvery, very small, and the probability of success\nvery, very small.",
    "start": "1826990",
    "end": "1832580"
  },
  {
    "text": "As you make that time interval\nsmaller and smaller, it goes in to a Poisson process as we\nshowed a long time ago.",
    "start": "1832580",
    "end": "1840120"
  },
  {
    "text": "This is the same\nargument here. And what we get then is this\nsystem, which now has a state.",
    "start": "1840120",
    "end": "1851400"
  },
  {
    "text": "And the state is the\nnumber of customers that are in the system. As one customer is being served,\nrest of the customers",
    "start": "1851400",
    "end": "1858490"
  },
  {
    "text": "are sitting in a queue. The transitions over some very\nsmall time, delta, there's a",
    "start": "1858490",
    "end": "1867880"
  },
  {
    "text": "probability lambda delta that\na new customer comes in. So there's a transition\nto the right.",
    "start": "1867880",
    "end": "1873940"
  },
  {
    "text": "There's a probability mu delta,\nif there's a server",
    "start": "1873940",
    "end": "1879080"
  },
  {
    "text": "being served, that that service\ngets finished in this time delta.",
    "start": "1879080",
    "end": "1885470"
  },
  {
    "text": "And if you're in state zero,\nthen of course, you can get a new arrival coming in,\nbut you can't get any",
    "start": "1885470",
    "end": "1891409"
  },
  {
    "text": "service being done. So it's saying, as you're all\nfamiliar with, you have this",
    "start": "1891410",
    "end": "1896909"
  },
  {
    "text": "system where any time there are\ncustomers in the system, they're getting served\nat rate mu.",
    "start": "1896910",
    "end": "1903780"
  },
  {
    "text": "Mu has to be bigger\nthan lambda to make this thing stable. And you can see that\nintuitively, I think.",
    "start": "1903780",
    "end": "1910080"
  },
  {
    "text": "And when you're in state\nzero, then the server isn't doing anything.",
    "start": "1910080",
    "end": "1915559"
  },
  {
    "text": "So the server is resting,\nbecause the server is faster than the arrival process.",
    "start": "1915560",
    "end": "1921049"
  },
  {
    "text": "And then the only thing that\ncan happen is a new arrival comes in, and then the server\nstarts to work again, and",
    "start": "1921050",
    "end": "1926380"
  },
  {
    "text": "you're back in state 1. So this is just a time sampled\nversion of the MM1 queue.",
    "start": "1926380",
    "end": "1936480"
  },
  {
    "text": "And if you analyze this either\nfrom the guessing theorem that I just was talking about or the\ngeneral result for birth",
    "start": "1936480",
    "end": "1945320"
  },
  {
    "text": "death change that we talked\nabout last time. You see that pi sub n minus 1\ntimes lambda delta is equal to",
    "start": "1945320",
    "end": "1957330"
  },
  {
    "text": "pi sub n times mu delta. The fraction of transitions\ngoing up is equal to the",
    "start": "1957330",
    "end": "1962730"
  },
  {
    "text": "fraction of transitions\ngoing down. You take the steady state\nprobability of being in",
    "start": "1962730",
    "end": "1968020"
  },
  {
    "text": "state n minus 1. You multiply it by the\nprobability of an up transition.",
    "start": "1968020",
    "end": "1974149"
  },
  {
    "text": "And you get the same thing, as\nyou take the probability of being in state by n and\nmultiply it by a down",
    "start": "1974150",
    "end": "1980380"
  },
  {
    "text": "transition. If you define rho as being\nlambda over mu, then what this",
    "start": "1980380",
    "end": "1987020"
  },
  {
    "text": "equation says is a steady state\nprobability of being in state n is rho times the steady\nstate probability of",
    "start": "1987020",
    "end": "1994750"
  },
  {
    "text": "being in a state n minus 1. This is the same as the general\nbirth death result,",
    "start": "1994750",
    "end": "2001330"
  },
  {
    "text": "except that rho is a constant\noverall state rather than state 1.",
    "start": "2001330",
    "end": "2010450"
  },
  {
    "text": "Pi sub n is then equal to a\nrho sub n times pi zero. And pi sub n is then equal\nto, if you re-curse on",
    "start": "2010450",
    "end": "2019549"
  },
  {
    "text": "this, you get this. Then you use the condition that\nthe pi sub i's have to",
    "start": "2019550",
    "end": "2026880"
  },
  {
    "text": "add up to 1. And you get pi sub n has to\nbe equal to 1 minus rho times rho to the n.",
    "start": "2026880",
    "end": "2033610"
  },
  {
    "text": "OK. This is all very simple\nand straightforward. What's curious about\nthis is it doesn't",
    "start": "2033610",
    "end": "2043220"
  },
  {
    "text": "depend on delta at all. You can make delta anything\nyou want to.",
    "start": "2043220",
    "end": "2049399"
  },
  {
    "text": "And we know that if we shrink\ndelta enough, it's going to look very much like\nan MM1 queue.",
    "start": "2049400",
    "end": "2054730"
  },
  {
    "text": "But it looks like an MM1 queue\nno matter what delta is. Just so long as lambda plus mu\ntimes delta is less than or",
    "start": "2054730",
    "end": "2062460"
  },
  {
    "text": "equal to 1. You don't want transition\nprobabilities to add up to more than 1.",
    "start": "2062460",
    "end": "2067899"
  },
  {
    "text": "And you have these self loops\nhere which take up the slack. And we saw before that the\nsteady state probabilities",
    "start": "2067900",
    "end": "2078540"
  },
  {
    "text": "didn't have anything to do with\nthese self transitions. And that will turn out to be\nsort of useful later on.",
    "start": "2078540",
    "end": "2084969"
  },
  {
    "text": "So we get these nice\nprobabilities which are independent of the time\nincrement that we're taking.",
    "start": "2084969",
    "end": "2097580"
  },
  {
    "text": "So we think that this is\nprobably pretty much operating like an actual MM1 queue\nwould operate.",
    "start": "2097580",
    "end": "2105500"
  },
  {
    "start": "2104000",
    "end": "2347000"
  },
  {
    "text": "OK. Now here's this diagram that I\nshowed you last time, and I told you was going\nto be confusing.",
    "start": "2105500",
    "end": "2111230"
  },
  {
    "text": "And I hope it's a little less\nconfusing at this point. We've now talked about\nreversibility.",
    "start": "2111230",
    "end": "2116780"
  },
  {
    "text": "We know what reversibility\nmeans. We know that we have\nreversibility here.",
    "start": "2116780",
    "end": "2122650"
  },
  {
    "text": "And what's going on? We have this diagram on the\ntop, which is the usual",
    "start": "2122650",
    "end": "2128750"
  },
  {
    "text": "diagram for the way that\nan MM1 queue operates.",
    "start": "2128750",
    "end": "2134560"
  },
  {
    "text": "You start out in state zero. The only thing that can happen\nfrom state zero is at some",
    "start": "2134560",
    "end": "2140775"
  },
  {
    "text": "point you get an arrival. So the arrival takes\nyou up there.",
    "start": "2140775",
    "end": "2147160"
  },
  {
    "text": "You have no more arrivals\nfor a while. Some later time, you get\nanother arrival. [INAUDIBLE]",
    "start": "2147160",
    "end": "2152609"
  },
  {
    "text": "So this is just the arrival\nprocess here. This is the number of arrivals\nup until time T. The same",
    "start": "2152610",
    "end": "2161420"
  },
  {
    "text": "time, when you have arrivals,\neventually since the server is",
    "start": "2161420",
    "end": "2167650"
  },
  {
    "text": "working now, at some point\nthere can be a departure. So we go over to here in\nthe sample sequence.",
    "start": "2167650",
    "end": "2175240"
  },
  {
    "text": "There's eventually a\ndeparture there. There's a departure there. And then you're back in\nstate zero again.",
    "start": "2175240",
    "end": "2181330"
  },
  {
    "text": "You go along until there's\nanother arrival. Corresponding to this sample\npath of arrivals and",
    "start": "2181330",
    "end": "2187460"
  },
  {
    "text": "departures, we can say\nwhat the state is. The state is just the difference\nbetween the",
    "start": "2187460",
    "end": "2192860"
  },
  {
    "text": "arrivals and the departures\nfor this sample path. So the state here start\nout at time 1.",
    "start": "2192860",
    "end": "2205190"
  },
  {
    "text": "x1 is equal to 0. Then at time x2, suddenly\nan arrival comes in.",
    "start": "2205190",
    "end": "2211340"
  },
  {
    "text": "x2 is equal to 1, x3 is equal to\n1, x4 is equal to 1, x5 is equal to 1.",
    "start": "2211340",
    "end": "2217270"
  },
  {
    "text": "Another arrival comes in. So we have a queue of 1. We have the server operating\non one customer.",
    "start": "2217270",
    "end": "2224020"
  },
  {
    "text": "Then in the sample path, we\nsuppose there's a departure. And we suppose that\nthe second arrival",
    "start": "2224020",
    "end": "2229920"
  },
  {
    "text": "required hardly any service. So there's a very fast\ndeparture there.",
    "start": "2229920",
    "end": "2235430"
  },
  {
    "text": "Now, what we're going to do is\nto look at what happens. This is the picture that we\nhave for the Markov chain.",
    "start": "2235430",
    "end": "2243790"
  },
  {
    "text": "This with the picture we had\nfor the sample path of arrivals and departures for what\nwe thought was the real",
    "start": "2243790",
    "end": "2249829"
  },
  {
    "text": "life thing that was going on. We now have the state diagram.",
    "start": "2249830",
    "end": "2254940"
  },
  {
    "text": "And now what we're going\nto do is say, let's look at this backwards. And since looking at it\nbackwards in time is",
    "start": "2254940",
    "end": "2262360"
  },
  {
    "text": "complicated, let's look at\nit coming in this way.",
    "start": "2262360",
    "end": "2268110"
  },
  {
    "text": "So we have the state diagram,\nand we try to figure out what, going backwards, is going\non here from these state",
    "start": "2268110",
    "end": "2276070"
  },
  {
    "text": "transitions. Well in going backwards, the\nstate is increasing by 1.",
    "start": "2276070",
    "end": "2284090"
  },
  {
    "text": "So that looks like something\nthat we would call an arrival. Now why am I calling these\narrivals and departures?",
    "start": "2284090",
    "end": "2292329"
  },
  {
    "text": "It's because the probability of\nany sample path along here",
    "start": "2292330",
    "end": "2298300"
  },
  {
    "text": "is going to be the same as a\nbackward sample path, the same sample path, going backwards.",
    "start": "2298300",
    "end": "2305240"
  },
  {
    "text": "That's what we've already\nestablished. And the probabilities going\nbackwards are going to be the",
    "start": "2305240",
    "end": "2313430"
  },
  {
    "text": "same as the probabilities\ngoing forward. Since we can interpret this\ngoing forward as arrivals",
    "start": "2313430",
    "end": "2319510"
  },
  {
    "text": "causing up transitions,\ndepartures causing down transitions, going backwards we\ncan say this is an arrival",
    "start": "2319510",
    "end": "2328410"
  },
  {
    "text": "in this backward going chain. This is an arrival in a\nbackward going chain.",
    "start": "2328410",
    "end": "2333619"
  },
  {
    "text": "This is a departure in the\nbackward going chain. We go along here. Finally, there's another\ndeparture in the backward",
    "start": "2333620",
    "end": "2339690"
  },
  {
    "text": "going chain. This state diagram-- ",
    "start": "2339690",
    "end": "2347718"
  },
  {
    "start": "2347000",
    "end": "2548000"
  },
  {
    "text": "with two of them, we\nmight make it. Yes, OK.",
    "start": "2347718",
    "end": "2353200"
  },
  {
    "text": "The state diagram here\ndetermines this diagram here.",
    "start": "2353200",
    "end": "2359650"
  },
  {
    "text": "If I tell you what this\nis, you can draw this. You can draw every up transition\nas an arrival,",
    "start": "2359650",
    "end": "2365620"
  },
  {
    "text": "every down transition\nas a departure. So this diagram is specified\nby this diagram.",
    "start": "2365620",
    "end": "2372010"
  },
  {
    "text": "This diagram is also specified\nby this diagram. So this and this each\nspecify each other.",
    "start": "2372010",
    "end": "2379600"
  },
  {
    "text": "Now if we interpret this\nas arrivals and this is departures, and we have the\nprobabilities of an MM1 chain,",
    "start": "2379600",
    "end": "2387470"
  },
  {
    "text": "then we say the statistics of\nthese arrivals here are the same as a Bernoulli process,\nwhich is coming along the",
    "start": "2387470",
    "end": "2398190"
  },
  {
    "text": "other way and leading\nto arrivals. What that says is the departure\nprocess here is a",
    "start": "2398190",
    "end": "2407360"
  },
  {
    "text": "Bernoulli process.  Now you really have to\nwrap your head around",
    "start": "2407360",
    "end": "2413440"
  },
  {
    "text": "that a little bit. Because we know that departures\nonly occur when",
    "start": "2413440",
    "end": "2418610"
  },
  {
    "text": "you're in states greater\nthan or equal to 1. ",
    "start": "2418610",
    "end": "2424839"
  },
  {
    "text": "So what's going on? When you're looking at it in\nforward time, a departure can",
    "start": "2424840",
    "end": "2433450"
  },
  {
    "text": "only occur from a non-negative\nstate to some other state.",
    "start": "2433450",
    "end": "2441680"
  },
  {
    "text": "Namely from some non-negative\nstate to some smaller state.",
    "start": "2441680",
    "end": "2447930"
  },
  {
    "text": "Now, when I look at\nit backwards in time, what do I find? I can be in state zero.",
    "start": "2447930",
    "end": "2455519"
  },
  {
    "text": "And there could have been\na departure which may--",
    "start": "2455520",
    "end": "2461070"
  },
  {
    "text": "if I'm in state zero at time\nzero, and I say there was a departure between n minus 1 and\nn, that just says that the",
    "start": "2461070",
    "end": "2470560"
  },
  {
    "text": "state at time n minus\n1 was equal to 1. Not that the state at time\nn was equal to 1.",
    "start": "2470560",
    "end": "2478060"
  },
  {
    "text": "Because I'm running along here\nlooking at these arrivals going this way, departures\ngoing this way.",
    "start": "2478060",
    "end": "2484400"
  },
  {
    "text": "When I'm in state zero,\nI can get an arrival. I can't when I'm in state 1.",
    "start": "2484400",
    "end": "2491632"
  },
  {
    "text": " If I were here, I couldn't\nget a departure in the",
    "start": "2491633",
    "end": "2499450"
  },
  {
    "text": "next unit of time. Because the state is\nequal to zero. But I can be coming from\na departure in",
    "start": "2499450",
    "end": "2506250"
  },
  {
    "text": "the previous state. Because in the previous state,\nthe state was 1. ",
    "start": "2506250",
    "end": "2513840"
  },
  {
    "text": "I mean, you really have\nto say this to yourself a dozen times. ",
    "start": "2513840",
    "end": "2523050"
  },
  {
    "text": "And you have to reason\nabout it. You have to look at the diagram,\nread the notes, talk",
    "start": "2523050",
    "end": "2528320"
  },
  {
    "text": "to your friends about it.  And after you do all of\nthis, it will start to",
    "start": "2528320",
    "end": "2534230"
  },
  {
    "text": "make sense to you. But I hope I'm at least making\nit seem plausible to you.",
    "start": "2534230",
    "end": "2540740"
  },
  {
    "text": "So each sample path corresponds\nto both a right and left moving chain. And each of them are MM1.",
    "start": "2540740",
    "end": "2546970"
  },
  {
    "text": " So we have Burke's theorem. And Burke's theorem says given\nan MM1 sample time Markov",
    "start": "2546970",
    "end": "2554720"
  },
  {
    "start": "2548000",
    "end": "3002000"
  },
  {
    "text": "chain in steady state, first,\nthe departure processes Bernoulli at rate lambda.",
    "start": "2554720",
    "end": "2562000"
  },
  {
    "text": "OK. Let me put it another way now. When we look at it in the\ncustomary way, we're looking",
    "start": "2562000",
    "end": "2570039"
  },
  {
    "text": "at things moving\nupward in time. We know there can't be\na departure when you're in state zero.",
    "start": "2570040",
    "end": "2576380"
  },
  {
    "text": "That's because we're looking\nat departures after you're in time zero.",
    "start": "2576380",
    "end": "2582220"
  },
  {
    "text": "When we look at time coming in\nbackwards, we're not being dependent on the state to the\nleft of that departure.",
    "start": "2582220",
    "end": "2593660"
  },
  {
    "text": "We're only dependent on the\nstate after the departure. The state after departure\ncan be anything.",
    "start": "2593660",
    "end": "2600950"
  },
  {
    "text": "OK? And therefore, after departure\nyou can be in any state at all.",
    "start": "2600950",
    "end": "2606859"
  },
  {
    "text": "And therefore, you can always\nhave a departure, which leaves you in state zero. ",
    "start": "2606860",
    "end": "2616420"
  },
  {
    "text": "That's exactly what this\ntheorem is saying. It's saying-- yes. AUDIENCE: [INAUDIBLE] ",
    "start": "2616420",
    "end": "2624004"
  },
  {
    "text": "departure process? PROFESSOR: Well, a couple\nof reasons. ",
    "start": "2624004",
    "end": "2629980"
  },
  {
    "text": "If you had a Bernoulli process\nand departure rate was mu, over a long period of time,\nyou'll have more departures",
    "start": "2629980",
    "end": "2636690"
  },
  {
    "text": "than you have arrivals. ",
    "start": "2636690",
    "end": "2641859"
  },
  {
    "text": "But the other, better reason is\nthat now you're amortizing",
    "start": "2641860",
    "end": "2647040"
  },
  {
    "text": "those departures\nover all time. And before, you were amortizing\nthem only over",
    "start": "2647040",
    "end": "2652970"
  },
  {
    "text": "times when the state of the\nchain was greater than what?",
    "start": "2652970",
    "end": "2658930"
  },
  {
    "text": "The probability of the\nstate of the chain is greater than 1 is rho. And that's the difference\nbetween lambda and mu.",
    "start": "2658930",
    "end": "2665460"
  },
  {
    "text": "OK? It's not nice, but that's\nthe way it is. Well actually, it is nice when\nyou're solving problems with",
    "start": "2665460",
    "end": "2672720"
  },
  {
    "text": "these things. I mean some of you might have\nnoticed when you were looking",
    "start": "2672720",
    "end": "2678010"
  },
  {
    "text": "at the quiz problem dealing with\nPoisson processes, that it was very, very sticky to say\nthings about what happens",
    "start": "2678010",
    "end": "2687240"
  },
  {
    "text": "at some time in the\npast, given what's going on in the future.",
    "start": "2687240",
    "end": "2692460"
  },
  {
    "text": "Those are nasty problems\nto deal with. This makes those problems\nvery easy to deal with.",
    "start": "2692460",
    "end": "2698010"
  },
  {
    "text": "Because it's saying, if you go\nbackward in time, you reverse the role of departures\nand arrivals.",
    "start": "2698010",
    "end": "2703490"
  },
  {
    "text": "Yes. AUDIENCE: Can you explain that\none more time, why it's lambda and not mu? Just the last thing you\nsaid [INAUDIBLE].",
    "start": "2703490",
    "end": "2710265"
  },
  {
    "text": "PROFESSOR: OK. Last thing I said was that the\nprobability that the state is",
    "start": "2710265",
    "end": "2715950"
  },
  {
    "text": "bigger than zero is rho. ",
    "start": "2715950",
    "end": "2722700"
  },
  {
    "text": "Because the probability of the\nstate is zero is 1 minus rho. I mean that's not obvious, but\nit's just the way it is.",
    "start": "2722700",
    "end": "2732630"
  },
  {
    "text": "So that if you're trying to\nfind the probability of a",
    "start": "2732630",
    "end": "2737970"
  },
  {
    "text": "departure and you don't know\nwhat the state is, and you just look in at any old time,\nit's sort of like a random",
    "start": "2737970",
    "end": "2747080"
  },
  {
    "text": "incidence problem. I mean, you're looking into this\nprocess, and all you know",
    "start": "2747080",
    "end": "2753020"
  },
  {
    "text": "is you're in steady state. And you don't know what\nthe state is.",
    "start": "2753020",
    "end": "2758740"
  },
  {
    "text": "I mean you can talk about\nthe earlier state. You can't talk about--",
    "start": "2758740",
    "end": "2765349"
  },
  {
    "text": "I mean usually when we talk\nabout these Markov chains, we're talking about state of\ntime n, transition from time n",
    "start": "2765350",
    "end": "2772930"
  },
  {
    "text": "to n plus 1. And in that case, you can't have\na departure if you're in",
    "start": "2772930",
    "end": "2779140"
  },
  {
    "text": "state zero at time n. Now the transition from time n\nto n plus 1, if we're moving",
    "start": "2779140",
    "end": "2786759"
  },
  {
    "text": "the other way in time, we're\nstarting out at time n plus 1.",
    "start": "2786760",
    "end": "2792000"
  },
  {
    "text": "And we're starting out\nat time n plus 1. If you're in state zero there,\nyou can still be coming out of",
    "start": "2792000",
    "end": "2800099"
  },
  {
    "text": "a departure from time n. I mean suppose at time n the\nstate is 1, and at time n plus",
    "start": "2800100",
    "end": "2808200"
  },
  {
    "text": "1 the state is zero. That means there was\na departure between",
    "start": "2808200",
    "end": "2813250"
  },
  {
    "text": "n and n plus 1. But when you're looking at it\nfrom the right, what you see",
    "start": "2813250",
    "end": "2818869"
  },
  {
    "text": "is the state at time\nn plus 1 is zero. And there's a probability\nof a departure.",
    "start": "2818870",
    "end": "2825510"
  },
  {
    "text": "And it's exactly the same as the\nprobability of a departure given any other state.",
    "start": "2825510",
    "end": "2831520"
  },
  {
    "text": "OK? ",
    "start": "2831520",
    "end": "2839870"
  },
  {
    "text": "If you're just doing this as\nmathematicians, you could look at these formulas and say\nyes, I agree with that. It's all very simple.",
    "start": "2839870",
    "end": "2847180"
  },
  {
    "text": "Since we're struggling here to\nget some insight as to what's going on and some\nunderstanding of it, it's very tricky.",
    "start": "2847180",
    "end": "2855630"
  },
  {
    "text": "Now, the other part of Burke's\ntheorem says the state at n delta is independent of\ndepartures prior to n delta.",
    "start": "2855630",
    "end": "2865270"
  },
  {
    "text": "And that seems even worse. It says you're looking at\nthis Markov chain at",
    "start": "2865270",
    "end": "2871144"
  },
  {
    "text": "a particular time. And you're saying the state of\nit is independent of all those",
    "start": "2871145",
    "end": "2876340"
  },
  {
    "text": "departures which happened\nbefore that.",
    "start": "2876340",
    "end": "2881980"
  },
  {
    "text": "That's really saying\nsomething. But if you use this\nreversibility condition that",
    "start": "2881980",
    "end": "2890170"
  },
  {
    "text": "says, when you look at things\ngoing from right to left, arrivals become departures and\ndepartures become arrivals.",
    "start": "2890170",
    "end": "2897730"
  },
  {
    "text": "Then that statement there is\nexactly the same as saying the state of a forward going chain\nat time n is independent of",
    "start": "2897730",
    "end": "2906880"
  },
  {
    "text": "the arrivals that come\nafter time n. Now, you all know\nthat to be true.",
    "start": "2906880",
    "end": "2912680"
  },
  {
    "text": "Because you're all used to\nlooking at these things moving forward in time. ",
    "start": "2912680",
    "end": "2922650"
  },
  {
    "text": "So whenever you see a statement\nlike that, just in your head reverse time, or turn\nyour head around so that",
    "start": "2922650",
    "end": "2932460"
  },
  {
    "text": "right becomes left and\nleft becomes right. And then departures become\narrivals and arrivals become",
    "start": "2932460",
    "end": "2938040"
  },
  {
    "text": "departures. You can't do one without\nthe other. You've got to do both\nof them together.",
    "start": "2938040",
    "end": "2944349"
  },
  {
    "text": "OK. So everything we know about the\nMM1 sample time chain has",
    "start": "2944350",
    "end": "2950060"
  },
  {
    "text": "a corresponding statement with\ntime reversed and arrivals and departure switched.",
    "start": "2950060",
    "end": "2955110"
  },
  {
    "text": "So it's not only Burke's\ntheorem. I mean, you can write down\n100 theorems now.",
    "start": "2955110",
    "end": "2961590"
  },
  {
    "text": "And they're all the same idea. But the critical idea\nis the question",
    "start": "2961590",
    "end": "2966810"
  },
  {
    "text": "that two of you asked. And that is, why is the\ndeparture rate going to be",
    "start": "2966810",
    "end": "2975260"
  },
  {
    "text": "lambda when you look at things\ncoming in backwards.? And the answer again is that\nit's lambda because we're not",
    "start": "2975260",
    "end": "2985010"
  },
  {
    "text": "conditioning it on knowing\nwhat the prior state was. And everything else you know\nabout these things, you always",
    "start": "2985010",
    "end": "2995370"
  },
  {
    "text": "condition things on\nthe prior state. So now we're getting used\nto conditioning them on the later state.",
    "start": "2995370",
    "end": "3003220"
  },
  {
    "start": "3002000",
    "end": "3252000"
  },
  {
    "text": "OK. Let's talk about branching\nprocesses. Branching processes have\nnothing to do with",
    "start": "3003220",
    "end": "3009390"
  },
  {
    "text": "reversibility. Again, these are just very\ncurious kinds of processes.",
    "start": "3009390",
    "end": "3017790"
  },
  {
    "text": "They have a lot to do with all\nkinds of genetic kinds of",
    "start": "3017790",
    "end": "3025870"
  },
  {
    "text": "things, with lots of physics\nkinds of experiments.",
    "start": "3025870",
    "end": "3032080"
  },
  {
    "text": "I don't think a branching\nprocess corresponds very closely to any one\nof those things.",
    "start": "3032080",
    "end": "3038690"
  },
  {
    "text": "This is the same kind of\nmodeling issue that we come up against all the time.",
    "start": "3038690",
    "end": "3043980"
  },
  {
    "text": "What we do is, we pick very,\nvery simple models to try to understand one aspect of\na physical problem.",
    "start": "3043980",
    "end": "3051410"
  },
  {
    "text": "And if you try to ask for a\nmodel that understands all aspects of that physical\nproblem, you've got a model",
    "start": "3051410",
    "end": "3057630"
  },
  {
    "text": "that's too complicated to\nsay anything about. But here's a model that says\nif you believe that one",
    "start": "3057630",
    "end": "3067140"
  },
  {
    "text": "generation to the next, if the\nonly thing that's happening is the individuals in one\ngeneration are spawning",
    "start": "3067140",
    "end": "3077359"
  },
  {
    "text": "children or are spawning\nwhatever it is in that next generation, and every individual\ndoes this in an",
    "start": "3077360",
    "end": "3086760"
  },
  {
    "text": "independent way, then this is\nwhat you have to live with. I mean that's what the\nmathematics says.",
    "start": "3086760",
    "end": "3093119"
  },
  {
    "text": "The model is no good, but\nthe mathematics is fine. So the mathematics is we suppose\nthat x of n is the",
    "start": "3093120",
    "end": "3102990"
  },
  {
    "text": "state of the Markov chain at\ntime n, and the Markov chain",
    "start": "3102990",
    "end": "3108080"
  },
  {
    "text": "is described in the following\nway. x of n, we think of as being the number of elements in\ngeneration n, and for each",
    "start": "3108080",
    "end": "3118089"
  },
  {
    "text": "element k, out of that x of n,\neach element gives rise to a",
    "start": "3118090",
    "end": "3127790"
  },
  {
    "text": "number of new elements. And the number of new elements\nit gives rise to we",
    "start": "3127790",
    "end": "3132850"
  },
  {
    "text": "call it y sub kn. The n at the end is for the\ngeneration, the k is for the",
    "start": "3132850",
    "end": "3139190"
  },
  {
    "text": "particular element in\nthe case generation. So y sub kn is the number of\noffspring of the element k in",
    "start": "3139190",
    "end": "3147345"
  },
  {
    "text": "the n-th generation. After the element in\nthe n-th generation",
    "start": "3147345",
    "end": "3153609"
  },
  {
    "text": "gives birth, it dies. So it's kind of a cruel world,\nbut that's this particular",
    "start": "3153610",
    "end": "3162700"
  },
  {
    "text": "kind of model. So the number of elements in\nthe n plus first generation",
    "start": "3162700",
    "end": "3168490"
  },
  {
    "text": "then, is the sum of the number\nof offspring of the elements in the n-th generation.",
    "start": "3168490",
    "end": "3174840"
  },
  {
    "text": "So it says x of n plus 1 is\nequal to this y sub kn is the",
    "start": "3174840",
    "end": "3183640"
  },
  {
    "text": "number of offspring of element\nk, and we sum that number of",
    "start": "3183640",
    "end": "3188680"
  },
  {
    "text": "offspring from 1 to\nx of n, and that's",
    "start": "3188680",
    "end": "3194290"
  },
  {
    "text": "the equation we get. The assumption we make is that\nthe non-negative integer",
    "start": "3194290",
    "end": "3199579"
  },
  {
    "text": "random variable y sub kn-- these random variables-- are independent, and identically\ndistributed over",
    "start": "3199580",
    "end": "3208080"
  },
  {
    "text": "both n and k. There's this usual peculiar\nproblem that we have where",
    "start": "3208080",
    "end": "3215250"
  },
  {
    "text": "we're defining random variables\nthat might not exist, but we should be\nused to that by now.",
    "start": "3215250",
    "end": "3221910"
  },
  {
    "text": "I mean we just have the random\nvariable there and we pick them out when we need\nthem is the best way",
    "start": "3221910",
    "end": "3227510"
  },
  {
    "text": "to think about that. The initial generation x of 0\ncan be an arbitrary positive",
    "start": "3227510",
    "end": "3232849"
  },
  {
    "text": "random variable, but it's\nusually taken to be y. So you start out with one\nelement, and this thing goes",
    "start": "3232850",
    "end": "3241180"
  },
  {
    "text": "on from one generation\nto the next. It might all die out, or it\nmight continue, it might blow",
    "start": "3241180",
    "end": "3249920"
  },
  {
    "text": "up explosively, and we want\nto find out which it does. OK so here's the critical\nequation.",
    "start": "3249920",
    "end": "3257599"
  },
  {
    "start": "3252000",
    "end": "3599000"
  },
  {
    "text": "Let's look at a couple of\nexamples of why sub kn is deterministic, and equals 1, and\nxn is equal to xn minus 1",
    "start": "3257600",
    "end": "3266049"
  },
  {
    "text": "is equal to x0 for all n greater\nthan or equal to 1. So this example isn't\nvery interesting.",
    "start": "3266050",
    "end": "3271869"
  },
  {
    "text": "If y kn is equal to 2, then each\ngeneration has twice as",
    "start": "3271870",
    "end": "3277300"
  },
  {
    "text": "many elements as the previous\ngeneration. Each element has\ntwo offspring.",
    "start": "3277300",
    "end": "3283270"
  },
  {
    "text": "So you have something that looks\nlike a tree, which is where the name branching process\ncomes from because",
    "start": "3283270",
    "end": "3290200"
  },
  {
    "text": "people think of these things\nin terms of trees. ",
    "start": "3290200",
    "end": "3295269"
  },
  {
    "text": "Each one element here two\noffspring, two elements here,",
    "start": "3295270",
    "end": "3308020"
  },
  {
    "text": "and now if you visualize this\nkind of chain, you can think of this as being random. So the perhaps in this\nfirst generation",
    "start": "3308020",
    "end": "3317140"
  },
  {
    "text": "there are two offspring. Perhaps this one has no\noffspring the next time, so",
    "start": "3317140",
    "end": "3323840"
  },
  {
    "text": "this dies out. This one has two offspring. ",
    "start": "3323840",
    "end": "3330069"
  },
  {
    "text": "This one has two offspring. this one has no offspring,\nthis one has two.",
    "start": "3330070",
    "end": "3337420"
  },
  {
    "text": "Four, we're up to four. And then all of them die out.",
    "start": "3337420",
    "end": "3342540"
  },
  {
    "text": "So we're talking about that kind\nof process, which you can visualize as a tree just\nas easily as you can",
    "start": "3342540",
    "end": "3349040"
  },
  {
    "text": "visualize it this way. Personally I find it easier\nto do this as a tree. Because that's personal\npreference.",
    "start": "3349040",
    "end": "3359790"
  },
  {
    "text": "OK, so just talked about this\nthird kind of animal here.",
    "start": "3359790",
    "end": "3366280"
  },
  {
    "text": "If the probability of no\noffspring is 1/2, and the",
    "start": "3366280",
    "end": "3372490"
  },
  {
    "text": "probability of twins is 1/2,\nthen xn, it's a rather",
    "start": "3372490",
    "end": "3377640"
  },
  {
    "text": "peculiar Markov chain. It can grow explosively,\nor it can die out.",
    "start": "3377640",
    "end": "3384180"
  },
  {
    "text": "Who would guess that it's going\nto grow explosively on the average? And who would guess that it will\ndie out on the average?",
    "start": "3384180",
    "end": "3389280"
  },
  {
    "text": " I mean would anybody hazard to\nmake a guess that this will",
    "start": "3389280",
    "end": "3396020"
  },
  {
    "text": "die out with probability one? Well it will, and we'll\nsee that today.",
    "start": "3396020",
    "end": "3404670"
  },
  {
    "text": "It can grow for quite a while,\nbut eventually it gets killed.",
    "start": "3404670",
    "end": "3410180"
  },
  {
    "text": "When we look at this process\nnow, the state 0 is trapping state.",
    "start": "3410180",
    "end": "3415950"
  },
  {
    "text": "The states 0 was always\na trapping state for branching processes. Because once you get to state\n0, there's nothing to have",
    "start": "3415950",
    "end": "3423859"
  },
  {
    "text": "offspring anymore. So state 0 is always\na trapping state.",
    "start": "3423860",
    "end": "3431220"
  },
  {
    "text": "But in other states you can have\nrather explosive growth.",
    "start": "3431220",
    "end": "3436599"
  },
  {
    "text": "For this particular thing here\nthe even numbered states all",
    "start": "3436600",
    "end": "3442420"
  },
  {
    "text": "communicate, but there\nare transient. Each odd numbered state doesn't\ncommunicate with any",
    "start": "3442420",
    "end": "3448710"
  },
  {
    "text": "other state. As you see from this diagram\nhere, you're always dealing",
    "start": "3448710",
    "end": "3453820"
  },
  {
    "text": "with an even number\nof states here. Because each offspring\neach element has",
    "start": "3453820",
    "end": "3462339"
  },
  {
    "text": "either two or 0 offspring. So you're summing up a bunch of\neven numbers, and you never",
    "start": "3462340",
    "end": "3471310"
  },
  {
    "text": "get anything odd, except this\ninitial state of one, which you get out of right away.",
    "start": "3471310",
    "end": "3478390"
  },
  {
    "text": "OK so how do we analyze\nthese things? We want to find the probability\nfor the general",
    "start": "3478390",
    "end": "3485100"
  },
  {
    "text": "case that the process\ndies out. So let's simplify our notation\na little bit.",
    "start": "3485100",
    "end": "3492095"
  },
  {
    "text": " We're going to let the pmf on\ny-- we have a pmf on y because",
    "start": "3492095",
    "end": "3502820"
  },
  {
    "text": "y is an integer random\nvariable. It's 0, or one, or\n2, or so forth.",
    "start": "3502820",
    "end": "3509150"
  },
  {
    "text": "We'll call that p sub of k. For the Markov chain namely\nx0, x1, x2, and so forth,",
    "start": "3509150",
    "end": "3518620"
  },
  {
    "text": "we're going to let piece of ij\nas usual, be the transition probabilities in the\nMarkov chain.",
    "start": "3518620",
    "end": "3526279"
  },
  {
    "text": "And here it's very useful to\ntalk about the probability the state j has reached on\nor before step n,",
    "start": "3526280",
    "end": "3533050"
  },
  {
    "text": "starting from state i. Remember we talked\nabout that-- I forget whether we\ntalked about last",
    "start": "3533050",
    "end": "3539030"
  },
  {
    "text": "time, or the time before-- but you can look it up,\nand what it is.",
    "start": "3539030",
    "end": "3545630"
  },
  {
    "text": "The thing we derive for it is\nthe probability that you will have touched state j in one of\nthe n previous tries starting",
    "start": "3545630",
    "end": "3556600"
  },
  {
    "text": "in state i. It's p sub of ij. That's the probability you reach\nit right away so you're",
    "start": "3556600",
    "end": "3561980"
  },
  {
    "text": "successful. And then for everything else you\nmight reach on the first try, there's the probability\nof going",
    "start": "3561980",
    "end": "3571130"
  },
  {
    "text": "to that state, initially. So this is what happens\nin the first trial. And then there's the probability\nyou will have gone",
    "start": "3571130",
    "end": "3578300"
  },
  {
    "text": "from state k to state j, in\nany one of the n minus 1",
    "start": "3578300",
    "end": "3583320"
  },
  {
    "text": "states after that. So f ij of one is p ij.",
    "start": "3583320",
    "end": "3588570"
  },
  {
    "text": "And now what we're interested\nin is we start with one element, and we're interested\nin the probability that it",
    "start": "3588570",
    "end": "3597190"
  },
  {
    "text": "dies out, before it explodes. Or just the probability\nit dies out. So f sub 1,0 of n is the\nprobability starting in state",
    "start": "3597190",
    "end": "3606310"
  },
  {
    "text": "1 that you're going to reach\nstate 0 after n steps.",
    "start": "3606310",
    "end": "3613530"
  },
  {
    "text": "So it's p 0 plus sum here of\np sub k probability you go",
    "start": "3613530",
    "end": "3620340"
  },
  {
    "text": "immediately to state k, and now\nhere's the only hard thing about this.",
    "start": "3620340",
    "end": "3625809"
  },
  {
    "text": "What I claim now is if we go\nto state k, and state k we",
    "start": "3625810",
    "end": "3631050"
  },
  {
    "text": "have k elements in this\nfirst generation. Now what's the probability that\nstarting with k elements",
    "start": "3631050",
    "end": "3640950"
  },
  {
    "text": "we're going to be dead after\nn minus 1 transitions? Well to be dead after n minus\n1 transitions every one of",
    "start": "3640950",
    "end": "3649720"
  },
  {
    "text": "these elements has to die out.",
    "start": "3649720",
    "end": "3654880"
  },
  {
    "text": "And they're independent. Everything that's going on\nfrom each element is independent of everything\nfrom each other element.",
    "start": "3654880",
    "end": "3660440"
  },
  {
    "text": "So the probability that this\nfirst one dies out is f sub 1",
    "start": "3660440",
    "end": "3666240"
  },
  {
    "text": "0 over n minus 1 steps. Probability the second\none dies out--",
    "start": "3666240",
    "end": "3671510"
  },
  {
    "text": "same thing. you take the\nproduct of them. So this is the probability that\nwe die out initially,",
    "start": "3671510",
    "end": "3682050"
  },
  {
    "text": "this sum from k equals\n1 to infinity. Is the probability that each of\nthe k descendants dies out",
    "start": "3682050",
    "end": "3690980"
  },
  {
    "text": "within time n minus 1. We can take a p 0 into the sum\nhere, we sum from 0 up to",
    "start": "3690980",
    "end": "3698650"
  },
  {
    "text": "infinity, because s sub 1 0 to\nthe 0 is just equal to 1.",
    "start": "3698650",
    "end": "3703720"
  },
  {
    "text": "So we get this nice looking\nformula here.",
    "start": "3703720",
    "end": "3708980"
  },
  {
    "text": "Let me do this quickly,\nand then we'll go back and talk about it. Let's talk about\nthe z transform",
    "start": "3708980",
    "end": "3718006"
  },
  {
    "text": "of this birth process. OK so we have this discrete\nrandom variable y with pmf p",
    "start": "3718006",
    "end": "3726315"
  },
  {
    "text": "sub k h of z is the sum over k\nif p sub k times z to the k.",
    "start": "3726315",
    "end": "3732670"
  },
  {
    "text": "It's just another kind of\ntransform, we have all kinds of transforms in this course. And this is one transform.",
    "start": "3732670",
    "end": "3740510"
  },
  {
    "text": "Given the state of a pmf, you\ncan define a function into z",
    "start": "3740510",
    "end": "3746240"
  },
  {
    "text": "in this way. So f 1 0 of n is then equal to\nh of f 1 0 of n minus 1.",
    "start": "3746240",
    "end": "3760550"
  },
  {
    "text": "It's amazing that all this mess\nturns into something that looks so simple.",
    "start": "3760550",
    "end": "3767490"
  },
  {
    "text": "So this will be the probability\nthat we will die",
    "start": "3767490",
    "end": "3772630"
  },
  {
    "text": "out by time end, if in fact we\nknow what the probability of dying out at time\nn minus 1 is.",
    "start": "3772630",
    "end": "3779450"
  },
  {
    "text": "So let's try to solve\nthis equation.  And it's not hard to solve\nas you would think.",
    "start": "3779450",
    "end": "3785445"
  },
  {
    "text": " There's this z transform h of\nz, h of z is given there.",
    "start": "3785445",
    "end": "3794240"
  },
  {
    "text": "What do I know about h of z? I know its value, it's\nz equal to 1.",
    "start": "3794240",
    "end": "3799520"
  },
  {
    "text": "Because it's z equal to 1, I'm\njust summing p sub k times 1.",
    "start": "3799520",
    "end": "3805590"
  },
  {
    "text": "So h of 1 is equal to 1. That's what this is in\nboth cases here.",
    "start": "3805590",
    "end": "3814040"
  },
  {
    "text": "What else do I know about it? h of 0 is equal to p 0.",
    "start": "3814040",
    "end": "3819055"
  },
  {
    "text": " And if you take the second\nderivative of this, you find",
    "start": "3819055",
    "end": "3826440"
  },
  {
    "text": "out immediately that the second\nderivative is positive. So this curve, this convex,\nit goes like that.",
    "start": "3826440",
    "end": "3834260"
  },
  {
    "text": "As it's been drawn here. The other thing we know is that\nthis derivative at 1 the",
    "start": "3834260",
    "end": "3844030"
  },
  {
    "text": "derivative of h of z is equal to\nthe sum of k times p to the k, times k, times z\nto the k minus 1.",
    "start": "3844030",
    "end": "3854520"
  },
  {
    "text": "I set z equal to 1,\nand what is that? It's the sum of pk times k.",
    "start": "3854520",
    "end": "3860380"
  },
  {
    "text": "So this derivative\nhere is y-bar.",
    "start": "3860380",
    "end": "3866150"
  },
  {
    "text": "In this case, I'm looking at a\ncase where y-bar is equal to 1, in this case, I'm looking\nat a case where y-bar is",
    "start": "3866150",
    "end": "3872440"
  },
  {
    "text": "bigger than 1.  Everybody with me so far?",
    "start": "3872440",
    "end": "3877730"
  },
  {
    "text": " AUDIENCE: So what\nis the y-bar?",
    "start": "3877730",
    "end": "3883514"
  },
  {
    "text": "PROFESSOR: y-bar is the expected\nvalue of the random variable y.",
    "start": "3883514",
    "end": "3888600"
  },
  {
    "text": "And the random variable y is the\nnumber of offspring than any one element will have.",
    "start": "3888600",
    "end": "3893960"
  },
  {
    "text": "The whole thing is defined\nin terms of this y. I mean it's the only thing that\nI've given you except all",
    "start": "3893960",
    "end": "3901500"
  },
  {
    "text": "these independence conditions. It's like the Poisson process. There's only one element\nin it, which is lambda.",
    "start": "3901500",
    "end": "3910140"
  },
  {
    "text": "A complicated process, but\nit's defined in terms of everything being independent\nof everything else.",
    "start": "3910140",
    "end": "3916970"
  },
  {
    "text": "And that's the same thing kind\nof thing we have here. Well what I've drawn here is a\nis a graphical way of finding",
    "start": "3916970",
    "end": "3928210"
  },
  {
    "text": "what f 1 0 of 1, f 1 0 of 2,\nf 1 0 of 3 is and so forth.",
    "start": "3928210",
    "end": "3935790"
  },
  {
    "text": "And we start out with one\nelement here, and I want to",
    "start": "3935790",
    "end": "3943530"
  },
  {
    "text": "find h of f 1 0 of one\nis h of f 1 0 of 0.",
    "start": "3943530",
    "end": "3955320"
  },
  {
    "text": "What is f 1 0 of 0? It has to be 1. So f 1 0 of n is just\nequal to h of p 0.",
    "start": "3955320",
    "end": "3966030"
  },
  {
    "text": "So I trace from here, from p 0\nover to this slope of one.",
    "start": "3966030",
    "end": "3972170"
  },
  {
    "text": "So this is p 0 down here, and\nthis point here is f 1 0 of 1,",
    "start": "3972170",
    "end": "3980950"
  },
  {
    "text": "at this point. Starting here I go over to here,\nand down here this is f",
    "start": "3980950",
    "end": "3989310"
  },
  {
    "text": "1 0 of one, as advertised. I can move up to the curve\nand I get h of 2.",
    "start": "3989310",
    "end": "3998520"
  },
  {
    "text": "h of f 1 0 h of z, where z\nis equal to f 1 0 of 1.",
    "start": "3998520",
    "end": "4007640"
  },
  {
    "text": "And so forth along here. I'm not going to spend a lot\nof time explaining the",
    "start": "4007640",
    "end": "4013990"
  },
  {
    "text": "graphical procedure, because\nthis is something that you look at on your own, and you\nsort it out in two minutes,",
    "start": "4013990",
    "end": "4021130"
  },
  {
    "text": "and if I explained it, I mean\nyou'll be looking at it at a different speed and\nI'm explaining it",
    "start": "4021130",
    "end": "4026330"
  },
  {
    "text": "at, so it won't work. But what happens is starting\nout with sum p 0, you just",
    "start": "4026330",
    "end": "4032900"
  },
  {
    "text": "move along each of these points\nare f 1 0 of 1, f 1 0 of 2, f 1 0 of 3, up to\nf 1 0 of infinity.",
    "start": "4032900",
    "end": "4042010"
  },
  {
    "text": "This is the probability that\nthe process will die out",
    "start": "4042010",
    "end": "4048210"
  },
  {
    "text": "eventually. So it's the point at which\nh of z equals z.",
    "start": "4048210",
    "end": "4057840"
  },
  {
    "text": "That's the root of the equation,\nh of z equals z. We already know what that is\npretty much, because we know",
    "start": "4057840",
    "end": "4065400"
  },
  {
    "text": "that we're looking at it case\nhere where y-bar is",
    "start": "4065400",
    "end": "4070460"
  },
  {
    "text": "greater than 1. So it means the slope here\nis bigger than 1.",
    "start": "4070460",
    "end": "4078820"
  },
  {
    "text": "We have a convex curve which\nstarts on this side of this line, that ends on the other\nside of this line.",
    "start": "4078820",
    "end": "4085500"
  },
  {
    "text": "There's got to be a root\nin the middle. And there can only be one root,\nso we eventually get to",
    "start": "4085500",
    "end": "4091650"
  },
  {
    "text": "that point. And that's the probability\nof dying out. ",
    "start": "4091650",
    "end": "4098639"
  },
  {
    "text": "Now, over in this case,\ny-bar is equal to 1. Or I could look at a case y-bar\nis less than 1, And what",
    "start": "4098640",
    "end": "4107329"
  },
  {
    "text": "happens then? Keep moving around the same way,\nI got up at that point,",
    "start": "4107330",
    "end": "4113560"
  },
  {
    "text": "and in fact h 1 0 of infinity\nis equal to 1. Which says the probability of\ndying out is equal to 1.",
    "start": "4113560",
    "end": "4121399"
  },
  {
    "start": "4121399",
    "end": "4126620"
  },
  {
    "text": "These things that I'm\ncalculating here are in fact the probability of dying out by\ntime 1, the probability of",
    "start": "4126620",
    "end": "4133060"
  },
  {
    "text": "dying out by time 2, and so\nforth all the way up. In here we start out on this\nside of the curve.",
    "start": "4133060",
    "end": "4139649"
  },
  {
    "text": "We keep getting crunched in. We wind up at that point, and in\nthis case, we keep getting",
    "start": "4139649",
    "end": "4146140"
  },
  {
    "text": "crunched up, and we wind\nup at that point. So the general behavior of these\nbranching processes is",
    "start": "4146140",
    "end": "4154278"
  },
  {
    "text": "so long as there's a possibility\nof an element having no children, there's a\npossibility that the whole",
    "start": "4154279",
    "end": "4162818"
  },
  {
    "text": "process will die out. But if the expected number of\noffspring is greater than 1,",
    "start": "4162819",
    "end": "4171689"
  },
  {
    "text": "then that probability of dying\nout is less than 1.",
    "start": "4171689",
    "end": "4176770"
  },
  {
    "text": "Unless the expected number of\noffspring is less than or",
    "start": "4176770",
    "end": "4182410"
  },
  {
    "text": "equal to 1, then the probability\nof dying out is in fact equal to 1.",
    "start": "4182410",
    "end": "4187778"
  },
  {
    "text": " So that was just this graphical\npicture, and that",
    "start": "4187779",
    "end": "4192920"
  },
  {
    "text": "does the whole thing, and if\nyou think about it for 10 minutes in a quiet room, I think\nit will be obvious to",
    "start": "4192920",
    "end": "4199880"
  },
  {
    "text": "you, because there's no\nrocket science here. It's just a simple graphical\nargument.",
    "start": "4199880",
    "end": "4207500"
  },
  {
    "text": "I have to think about it every\ntime I do it, because it always looks implausible.",
    "start": "4207500",
    "end": "4213220"
  },
  {
    "text": "So it says the process can\nexplode if the expected number",
    "start": "4213220",
    "end": "4218700"
  },
  {
    "text": "of elements from each element\nis larger than 1. But it doesn't have\nto explode.",
    "start": "4218700",
    "end": "4226030"
  },
  {
    "text": "There's an interesting theorem\nthat we'll talk about when we start talking about\nmartingales.",
    "start": "4226030",
    "end": "4231800"
  },
  {
    "text": "And that is that the number of\nelements in generation n divided by the expected value of\ny to the n-th power x sub n",
    "start": "4231800",
    "end": "4250760"
  },
  {
    "text": "divided by y-bar to\nthe n-th power. This is something that\nlooks like it ought",
    "start": "4250760",
    "end": "4257570"
  },
  {
    "text": "to be kind of stable. And it says that this approach\nis a random variable.",
    "start": "4257570",
    "end": "4264380"
  },
  {
    "text": "Namely with probability 1, this\nhas some random value",
    "start": "4264380",
    "end": "4272179"
  },
  {
    "text": "that you can calculate. ",
    "start": "4272180",
    "end": "4278170"
  },
  {
    "text": "With a certain probability,\nthis is equal to 0. With a certain probability this\nis some larger constant.",
    "start": "4278170",
    "end": "4288880"
  },
  {
    "text": "And it can be any old constant\nat all with different probabilities. And you can sort of see\nwhy this is happening.",
    "start": "4288880",
    "end": "4295860"
  },
  {
    "text": "Suppose you have this process. Suppose y-bar is\nbigger than 1. Suppose it's equal\nto 2 for example.",
    "start": "4295860",
    "end": "4303599"
  },
  {
    "text": "So the expected number of\noffspring of each of these elements is two, so the number\nof offspring of 10 to the 6",
    "start": "4303600",
    "end": "4313080"
  },
  {
    "text": "elements is 2 times\n10 to the sixth. What this is doing is dividing\nby that multiplying factor.",
    "start": "4313080",
    "end": "4320630"
  },
  {
    "text": "What's going to happen then is\nafter a certain amount of time, you have so many elements,\nand each one of them",
    "start": "4320630",
    "end": "4327630"
  },
  {
    "text": "is doing something\nindependently, so the number of offspring in each generation\ndivided by an extra",
    "start": "4327630",
    "end": "4336280"
  },
  {
    "text": "y sub bar is almost constant. And that's what this\ntheorem is saying.",
    "start": "4336280",
    "end": "4342400"
  },
  {
    "text": "So that after a while it says\nthe growth rate becomes fixed. And that sort of obvious\nintuitively.",
    "start": "4342400",
    "end": "4348890"
  },
  {
    "text": " That's enough for that. ",
    "start": "4348890",
    "end": "4358980"
  },
  {
    "text": "Should've not been so talkative about the earlier things. But Markov processes turn out\nto be pretty simple, given",
    "start": "4358980",
    "end": "4368929"
  },
  {
    "text": "what we know about\nMarkov chains. There's not a lot of new things\nto be learned here.",
    "start": "4368930",
    "end": "4374560"
  },
  {
    "text": "Just a few. Accountable state Markov process\nis most easily viewed",
    "start": "4374560",
    "end": "4380840"
  },
  {
    "text": "as a simple extension\nof accountable state Markov chain. And along with each state in\nthe Markov chain, there's a",
    "start": "4380840",
    "end": "4390500"
  },
  {
    "text": "holding time. So what happens in this process\nis it goes along.",
    "start": "4390500",
    "end": "4397650"
  },
  {
    "text": "At a certain point there's\na state change. The state change is according\nto the Markov chain, and",
    "start": "4397650",
    "end": "4406770"
  },
  {
    "text": "amount of time that it takes\nis an exponential random",
    "start": "4406770",
    "end": "4412190"
  },
  {
    "text": "variable which depends on\nthe state you are in. So in some states you\nmove quickly.",
    "start": "4412190",
    "end": "4418840"
  },
  {
    "text": "In some states you\nmove slowly. But the only thing that's going\non is you have a Markov",
    "start": "4418840",
    "end": "4424080"
  },
  {
    "text": "chain, and each state of the\nMarkov chain, there's some rate which determines how long\nit's going to take to get to",
    "start": "4424080",
    "end": "4432590"
  },
  {
    "text": "the next state change.",
    "start": "4432590",
    "end": "4438099"
  },
  {
    "text": "So that you can visualize what\nthe process looks like-- ",
    "start": "4438100",
    "end": "4447910"
  },
  {
    "text": "This is the state at times 0. This determines some\nholding time u1.",
    "start": "4447910",
    "end": "4455820"
  },
  {
    "text": "It also determines some\nstate at time 1.",
    "start": "4455820",
    "end": "4461340"
  },
  {
    "text": "The state you go to is\nindependent of how long it takes you to get there.",
    "start": "4461340",
    "end": "4467520"
  },
  {
    "text": "This then determines the rate,\nso it tells you the rate of this exponential random\nvariable.",
    "start": "4467520",
    "end": "4473850"
  },
  {
    "text": "And we have this plus some\nprocess leading off plus we have this Markov process leading\nalong here, and for",
    "start": "4473850",
    "end": "4481860"
  },
  {
    "text": "each state of the Markov\nprocess, you have this holding time. You will ask-- as I do every\ntime I look at this--",
    "start": "4481860",
    "end": "4489800"
  },
  {
    "text": "why did I make this\nu1 instead of u0? ",
    "start": "4489800",
    "end": "4494969"
  },
  {
    "text": "It's because of the\nnext slide. OK? Here's the next slide, which\nshows what's going on.",
    "start": "4494970",
    "end": "4500940"
  },
  {
    "text": "So we start off at time 0, x\nof 0 is in some state i.",
    "start": "4500940",
    "end": "4510790"
  },
  {
    "text": "We stay in state i until\nsome time u1, at which the state changes.",
    "start": "4510790",
    "end": "4517400"
  },
  {
    "text": "The state change now\nis some state j. We stay in that same state j\nuntil the next state change.",
    "start": "4517400",
    "end": "4525230"
  },
  {
    "text": "We stay in that state until the\nnext state change, and it is since we want to make the\nfirst state change time s of",
    "start": "4525230",
    "end": "4533370"
  },
  {
    "text": "one, we sort of have to make the\nfirst interval between 0",
    "start": "4533370",
    "end": "4541810"
  },
  {
    "text": "on the state u1. So these things are off\nbase from the u's.",
    "start": "4541810",
    "end": "4548429"
  },
  {
    "text": "And this is the way that a way\nthat a Markov process evolves.",
    "start": "4548430",
    "end": "4554680"
  },
  {
    "text": "You simply have what looks\nlike a Poisson process, a variable rate, and the variable\nrate is varying",
    "start": "4554680",
    "end": "4562340"
  },
  {
    "text": "according to the state of a\nMarkov chain every time you have an arrival in the variable\nrate Poisson process,",
    "start": "4562340",
    "end": "4570760"
  },
  {
    "text": "you change the rate according\nto this Markov process. So it's everything about Markov\nchains, plus Poisson",
    "start": "4570760",
    "end": "4578040"
  },
  {
    "text": "processes all put together. OK, I think I'll stop\nthere, and we will",
    "start": "4578040",
    "end": "4584730"
  },
  {
    "text": "continue next time. ",
    "start": "4584730",
    "end": "4588693"
  }
]
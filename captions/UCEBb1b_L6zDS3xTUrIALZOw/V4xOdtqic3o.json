[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6090"
  },
  {
    "text": "continue to offer high-quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6090",
    "end": "12720"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "12720",
    "end": "17880"
  },
  {
    "text": " PHILIPPE RIGOLLET: So\nyes, before we start,",
    "start": "17880",
    "end": "25220"
  },
  {
    "start": "20000",
    "end": "50000"
  },
  {
    "text": "this chapter will not\nbe part of the midterm. Everything else will be, so all\nthe way up to goodness of fit",
    "start": "25220",
    "end": "31970"
  },
  {
    "text": "tests. And there will be\nsome practice exams that will be posted\nin the recitation",
    "start": "31970",
    "end": "38690"
  },
  {
    "text": "section of the course. And that will be-- you will be working on. So the recitation tomorrow\nwill be a review session",
    "start": "38690",
    "end": "44480"
  },
  {
    "text": "for the midterm. I'll send an\nannouncement by email.",
    "start": "44480",
    "end": "49850"
  },
  {
    "text": "So going back to\nour estimator, we",
    "start": "49850",
    "end": "55370"
  },
  {
    "start": "50000",
    "end": "300000"
  },
  {
    "text": "showed that the least\nsquares estimator in the case where we had some\nGaussian observations.",
    "start": "55370",
    "end": "61860"
  },
  {
    "text": "So we had something that\nlooked like this-- y was equal to some matrix x times\nbeta plus some epsilon.",
    "start": "61860",
    "end": "67850"
  },
  {
    "text": "This was an equation\nthat was happening in r to the n for n observations.",
    "start": "67850",
    "end": "73010"
  },
  {
    "text": "And then we wrote the least\nsquares estimator beta hat. ",
    "start": "73010",
    "end": "81299"
  },
  {
    "text": "And for the purpose\nfrom here on, you see that you have\nthis normal distribution, this Gaussian p\nvariant distribution.",
    "start": "81300",
    "end": "88188"
  },
  {
    "text": "That means that, at\nsome point, we've made the assumption\nthat epsilons were n and dimensional\n0 identity of rn",
    "start": "88189",
    "end": "98060"
  },
  {
    "text": "times sigma squared,\nwhich I kept on forgetting about last time.",
    "start": "98060",
    "end": "103130"
  },
  {
    "text": "I will try not to\ndo that this time. And so from this,\nwe derived a bunch",
    "start": "103130",
    "end": "108799"
  },
  {
    "text": "of properties of this least\nsquares estimator, beta hat.",
    "start": "108800",
    "end": "114080"
  },
  {
    "text": "And in particular, the key thing\nthat everything was built on was that we could write beta\nhat as the true unknown beta",
    "start": "114080",
    "end": "122090"
  },
  {
    "text": "plus some multivariate\nGaussian that was centered, but had a weird\ncovariant structure. So that was definitely\np dimensional.",
    "start": "122090",
    "end": "128979"
  },
  {
    "text": "And it was sigma\nsquared times x--  so that's x transpose x.",
    "start": "128979",
    "end": "136359"
  },
  {
    "text": "And that's inverse.  And the way we derived that\nwas by having a lot of--",
    "start": "136359",
    "end": "142840"
  },
  {
    "text": "at least one cancellation\nbetween x transpose x and x transpose x inverse.",
    "start": "142840",
    "end": "148150"
  },
  {
    "text": "So this is the basis for\ninference in linear regression.",
    "start": "148150",
    "end": "167582"
  },
  {
    "text": " So in a way, that's\ncorrect, because what",
    "start": "167582",
    "end": "174980"
  },
  {
    "text": "happened is that we used\nthe fact that x beta hat-- once we have this\nbeta, x beta hat is really just a projection\nof y onto the linear span",
    "start": "174980",
    "end": "184310"
  },
  {
    "text": "of the columns of x, or\nthe column span of x. And so in particular,\nthose things--",
    "start": "184310",
    "end": "190040"
  },
  {
    "text": "y minus x beta hats-- are called residuals. ",
    "start": "190040",
    "end": "202060"
  },
  {
    "text": "So that's the\nvector of residuals. ",
    "start": "202060",
    "end": "208069"
  },
  {
    "text": "What's the dimension\nof this vector? ",
    "start": "208070",
    "end": "216214"
  },
  {
    "text": "AUDIENCE: n by 1. PHILIPPE RIGOLLET: n by 1. So those things, we can\nwrite as epsilon hat.",
    "start": "216214",
    "end": "222890"
  },
  {
    "text": "There's an estimate\nfor this epsilon because we just\nput a hat on beta. And from this one,\nwe could actually",
    "start": "222890",
    "end": "229610"
  },
  {
    "text": "build an unbiased estimator\nof sigma hat squared, and that was this guy.",
    "start": "229610",
    "end": "235940"
  },
  {
    "text": "And we showed that, indeed, the\nright normalization for this was n minus p, because y\nminus x beta hat to norm",
    "start": "235940",
    "end": "244730"
  },
  {
    "text": "is actually a chi squared with\nn minus p degrees of freedom. And so that's up to this\nscaling by sigma squared.",
    "start": "244730",
    "end": "251120"
  },
  {
    "text": "So that's what we came up with. And something I told\nyou, which follows from Cochran's theorem-- we did not go into\ndetails about this.",
    "start": "251120",
    "end": "257420"
  },
  {
    "text": "But essentially,\nsince one of them corresponds to projection onto\nthe linear span of the columns",
    "start": "257420",
    "end": "262640"
  },
  {
    "text": "of x, and the other one\ncorresponds to projection onto the orthogonal of this guy,\nand we're in a Gaussian case,",
    "start": "262640",
    "end": "268574"
  },
  {
    "text": "things that are\northogonal are actually independent in a Gaussian case. So from a geometric\npoint of view, you can sort of\nunderstand everything.",
    "start": "268575",
    "end": "274873"
  },
  {
    "text": "You think of your subspace of\nthe linear span of the x's, sometimes you project\nonto this guy, sometimes you project\nonto its orthogonal.",
    "start": "274873",
    "end": "281419"
  },
  {
    "text": "Beta hat corresponds\nto projection onto the linear span. Epsilon hats correspond to a\nprojection onto the orthogonal.",
    "start": "281420",
    "end": "286970"
  },
  {
    "text": "And those things tend\nto be independent, and that's what you\nhave that beta hat is independent of\nsigma hat squared.",
    "start": "286970",
    "end": "293560"
  },
  {
    "text": "So it's really just a statement\nabout two linear spaces being orthogonal with\nrespect to each other.",
    "start": "293560",
    "end": "300509"
  },
  {
    "start": "300000",
    "end": "360000"
  },
  {
    "text": "So we left on this\nslide last time.",
    "start": "300510",
    "end": "307820"
  },
  {
    "text": "And what I claim is that\nthis thing here is actually-- oh, yeah-- the other\nthing we want to use. So that's good for beta hat.",
    "start": "307820",
    "end": "314002"
  },
  {
    "text": "But since we don't know\nwhat sigma squared is-- if we knew what\nsigma squared is, that would totally\nbe enough for us.",
    "start": "314002",
    "end": "319160"
  },
  {
    "text": "But we also need\nthis extra thing-- that sigma squared hat squared\nover sigma squared follows--",
    "start": "319160",
    "end": "327250"
  },
  {
    "text": "and there's an n minus p. This follows a chi squared with\nn minus p degrees of freedom.",
    "start": "327250",
    "end": "333250"
  },
  {
    "text": "And sigma hat squared is\nindependent of beta hat. So that's going to\nbe something we need.",
    "start": "333250",
    "end": "341780"
  },
  {
    "text": "So that's useful if\nsigma squared if unknown.",
    "start": "341780",
    "end": "347870"
  },
  {
    "text": " And again, sometimes\nit might be known",
    "start": "347870",
    "end": "353490"
  },
  {
    "text": "if you're using some sort\nof measurement device for which it's written\non the side of the box. ",
    "start": "353490",
    "end": "361000"
  },
  {
    "start": "360000",
    "end": "660000"
  },
  {
    "text": "So from these two\nthings, we're going to be able to do inference\nAnd inference, we said there's three\npillars to inference.",
    "start": "361000",
    "end": "369370"
  },
  {
    "text": "The first one is estimation, and\nwe've been doing that so far. We've constructed this\nleast squares estimator,",
    "start": "369370",
    "end": "374530"
  },
  {
    "text": "which happens to be\nthe maximum likelihood estimator in the Gaussian case. The two other things\nwe do in inference",
    "start": "374530",
    "end": "380710"
  },
  {
    "text": "are confidence intervals. And we can do\nconfidence intervals. We're not going to\ndo much because we're",
    "start": "380710",
    "end": "385960"
  },
  {
    "text": "going to talk about their sort\nof cousin, which are tests. And that's really where\nthe statistical inference",
    "start": "385960",
    "end": "391600"
  },
  {
    "text": "comes into. And here, we're going to\nbe interested in a very specific kind of test\nfor linear regression.",
    "start": "391600",
    "end": "396820"
  },
  {
    "text": "And those are tests\nof the form beta j--",
    "start": "396820",
    "end": "402650"
  },
  {
    "text": "so the j-th coefficient\nof beta is equal to 0, and that's going to be our null\nhypothesis, versus h1 where",
    "start": "402650",
    "end": "412310"
  },
  {
    "text": "beta j is, say, not equal to 0. And for the purpose\nof regression,",
    "start": "412310",
    "end": "417560"
  },
  {
    "text": "unless you have lots of\ndomain-specific knowledge, it won't be beta j positive\nor beta j negative.",
    "start": "417560",
    "end": "423020"
  },
  {
    "text": "It's really non-0 that's\ninteresting to you. So why would I want\nto do this test?",
    "start": "423020",
    "end": "429830"
  },
  {
    "text": "Well, if I expand this\nthing where I have y is equal to x beta\nplus epsilon--",
    "start": "429830",
    "end": "439740"
  },
  {
    "text": "so what happens if\nI look, for example, at the first coordinates? So I have that y is actually--\nso say, y1 is equal to beta 1",
    "start": "439740",
    "end": "452420"
  },
  {
    "text": "plus beta 2 x 1. Well, that's\nactually complicated.",
    "start": "452420",
    "end": "458866"
  },
  {
    "text": "Let me write it like this--  beta 0 plus beta 1 x1 plus\nbeta p minus 1 xp minus 1",
    "start": "458866",
    "end": "476500"
  },
  {
    "text": "plus epsilon. And that's true for all i's. ",
    "start": "476500",
    "end": "484510"
  },
  {
    "text": "So this is beta 1 times 1. That was our first coordinate. So that's just expanding this--",
    "start": "484510",
    "end": "489920"
  },
  {
    "text": "going back to the\nscalar form rather than going to the matrix vector form.",
    "start": "489920",
    "end": "495140"
  },
  {
    "text": "That's what we're doing. When I write y is equal\nto x beta plus epsilon, I assume that each of my\ny's can be represented",
    "start": "495140",
    "end": "502400"
  },
  {
    "text": "as a linear combination\nof the x's, the first one being 1 plus some epsilon i. Everybody agrees with this?",
    "start": "502400",
    "end": "509630"
  },
  {
    "text": "What does it mean for\nbeta j to be equal to 0? ",
    "start": "509630",
    "end": "520661"
  },
  {
    "text": "Yeah? AUDIENCE: That\nxj's not important. PHILIPPE RIGOLLET: Yeah,\nthat xj doesn't even show up in this thing.",
    "start": "520661",
    "end": "526750"
  },
  {
    "text": "So if beta j is equal to 0,\nthat means that, essentially, we",
    "start": "526750",
    "end": "531940"
  },
  {
    "text": "can remove the j's coordinate,\nxj, from all observations.",
    "start": "531940",
    "end": "545946"
  },
  {
    "start": "545946",
    "end": "552709"
  },
  {
    "text": "So for example, I'm\na banker, and I'm trying to predict some score--",
    "start": "552710",
    "end": "559280"
  },
  {
    "text": "let's call it y-- without the noise. So I'm trying to predict what\nis going to be your score.",
    "start": "559280",
    "end": "566400"
  },
  {
    "text": "And that's something\nthat should be telling me how likely you are to\nreimburse your loan on time",
    "start": "566400",
    "end": "573080"
  },
  {
    "text": "or do you have late payments. Or actually, maybe\nthese days bankers are actually looking at\nhow much late fees will I",
    "start": "573080",
    "end": "580550"
  },
  {
    "text": "be collecting from you. Maybe that's what they are more\nafter rather than making sure that you reimburse everything. So they're trying to maximize\nthis number of late fees.",
    "start": "580550",
    "end": "587810"
  },
  {
    "text": "And they collect a bunch\nof things about you-- definitely your credit\nscore, but maybe your zip code, profession, years\nof education, family status,",
    "start": "587810",
    "end": "597110"
  },
  {
    "text": "a bunch of things. One might be your shoe size. And they want to know--\nmaybe shoe is actually",
    "start": "597110",
    "end": "603750"
  },
  {
    "text": "a good explanation\nfor how much fees they're going to be\ncollecting from you.",
    "start": "603750",
    "end": "608769"
  },
  {
    "text": "But as you can imagine, this\nwould be a controversial thing to bring, and people might\nwant to test for their shoe size is a good idea.",
    "start": "608770",
    "end": "614009"
  },
  {
    "text": "And so they would just\nlook at the j corresponding to shoe size and test whether\nshoe size should appear or not",
    "start": "614010",
    "end": "621120"
  },
  {
    "text": "in this formula. And that's essentially\nthe kind of thing that people are going to do. Now, if I do genomics\nand I'm trying",
    "start": "621120",
    "end": "627839"
  },
  {
    "text": "to predict the size, the girth,\nof a pumpkin for a competition based on some\navailable genomic data,",
    "start": "627840",
    "end": "637530"
  },
  {
    "text": "then I can test whether\ngene j, which is called-- I don't know-- pea snap 24--\nthey always have these crazy",
    "start": "637530",
    "end": "644010"
  },
  {
    "text": "names-- appears or not in this formula. Is the gene pea snap 24\ngoing to be important or not",
    "start": "644010",
    "end": "649350"
  },
  {
    "text": "for the size of\nthe final pumpkin? So those are definitely\nthe important things.",
    "start": "649350",
    "end": "654420"
  },
  {
    "text": "And definitely, we\nwant to put beta j not equal to 0 as the alternative\nbecause that's where",
    "start": "654420",
    "end": "660120"
  },
  {
    "start": "660000",
    "end": "840000"
  },
  {
    "text": "scientific discovery shows up. And so to do that, well,\nwe're in a Gaussian set-up,",
    "start": "660120",
    "end": "666450"
  },
  {
    "text": "so we know that even if we\ndon't know what sigma hat is, we can actually\ncall for a t-test.",
    "start": "666450",
    "end": "674250"
  },
  {
    "text": "So how did we build\nthe t-test in general? Well, we had something that\nlooked like-- so before, what",
    "start": "674250",
    "end": "683630"
  },
  {
    "text": "we had was something that\nlooked like theta hat was equal to theta plus some\nn0 and something that",
    "start": "683630",
    "end": "695029"
  },
  {
    "text": "depended on n, maybe, something\nlike this-- sigma squared over n. So that's what it looked like.",
    "start": "695030",
    "end": "701470"
  },
  {
    "text": "Now what we have\nis that beta hat is equal to beta plus some n,\nbut this time, it's p variant,",
    "start": "701470",
    "end": "710470"
  },
  {
    "text": "and then x transpose x\ninverse sigma squared.",
    "start": "710470",
    "end": "716129"
  },
  {
    "text": "So it's actually very similar,\nexcept that the matrix x transpose x inverse\nis now replacing",
    "start": "716130",
    "end": "723110"
  },
  {
    "text": "just this number, 1/n, but\nit's playing the same role. So in particular, this implies\nthat for every j from 1",
    "start": "723110",
    "end": "732750"
  },
  {
    "text": "to p, what is the\ndistribution of beta hat j? ",
    "start": "732750",
    "end": "739010"
  },
  {
    "text": "Well, beta hat j is\nactually equal to-- so all I have to do-- so this\nis a system of p equations,",
    "start": "739010",
    "end": "746350"
  },
  {
    "text": "and all I have to do is\nto read the j through. So it's telling me here, I'm\ngoing to read beta hat j.",
    "start": "746350",
    "end": "752089"
  },
  {
    "text": "Here, I'm going to read beta j. And here, I need\nto read, what is the distribution of the j-th\ncoordinates of this guy?",
    "start": "752090",
    "end": "760980"
  },
  {
    "text": "So this is a Gaussian\nvector, so we need to understand\nwhat its definition is. ",
    "start": "760980",
    "end": "769470"
  },
  {
    "text": "So how do I do this? Well, the observation that's\nactually useful for this--",
    "start": "769470",
    "end": "776360"
  },
  {
    "text": "maybe I shouldn't use the word\nobservation in a stats class, so let's call it claim. ",
    "start": "776360",
    "end": "783648"
  },
  {
    "text": "The interesting claim is\nthat if I have a vector--",
    "start": "783648",
    "end": "789610"
  },
  {
    "text": "let's call it v-- then vj is equal to\nv transpose ej where",
    "start": "789610",
    "end": "800500"
  },
  {
    "text": "ej is the vector with 0, 0,\n0, and then the 1 on the j-th",
    "start": "800500",
    "end": "808890"
  },
  {
    "text": "coordinate, and\nthen 0 elsewhere. That's the j-th coordinate. ",
    "start": "808890",
    "end": "815620"
  },
  {
    "text": "So that's the j-th vector of\nthe canonical basis of rp. ",
    "start": "815620",
    "end": "821640"
  },
  {
    "text": "So now that I have\nthis form, I can see that, essentially,\nbeta hat j is just ej transpose\nthis np0 sigma squared",
    "start": "821640",
    "end": "831269"
  },
  {
    "text": "x transpose x inverse. ",
    "start": "831270",
    "end": "839550"
  },
  {
    "text": "And now, I know what\nthe distribution of the inner product\nbetween a Gaussian",
    "start": "839550",
    "end": "845550"
  },
  {
    "start": "840000",
    "end": "1380000"
  },
  {
    "text": "and a deterministic vector is. What is it? ",
    "start": "845550",
    "end": "853810"
  },
  {
    "text": "It's a Gaussian. So all I have to check is that\nej transpose np0 sigma squared",
    "start": "853810",
    "end": "863950"
  },
  {
    "text": "x transpose x inverse-- well, this is equal in\ndistribution to what?",
    "start": "863950",
    "end": "871610"
  },
  {
    "text": "Well, this is going to be\na one-dimensional thing. A then your product\nis just a real number.",
    "start": "871610",
    "end": "878230"
  },
  {
    "text": "So it's going to\nbe some Gaussian. The mean is going to be 0 in\na product with ej, which is 0.",
    "start": "878230",
    "end": "889480"
  },
  {
    "text": "What is the variance\nof this guy? We actually used this, except\nthat ej was not a vector,",
    "start": "889480",
    "end": "895320"
  },
  {
    "text": "but it was a matrix. So what we do is we, to see--\nso the rule is that v transpose,",
    "start": "895320",
    "end": "904990"
  },
  {
    "text": "say, n mu sigma is\nsome n v transpose mu,",
    "start": "904990",
    "end": "916610"
  },
  {
    "text": "and then v transpose\nsigma v. That's the rule for Gaussian vectors.",
    "start": "916610",
    "end": "923234"
  },
  {
    "text": "There's just the property\nof Gaussian vectors.  So what do we have here?",
    "start": "923234",
    "end": "929300"
  },
  {
    "text": "Well, ej plays the\nrole of v. And sigma squared x transpose x\ninverse is the role of sigma.",
    "start": "929300",
    "end": "936990"
  },
  {
    "text": "So here, I'm left\nwith ej transpose-- let me pull out the\nsigma squared here.",
    "start": "936990",
    "end": "942390"
  },
  {
    "start": "942390",
    "end": "954590"
  },
  {
    "text": "But this thing is, what\nhappens if I take a matrix, I premultiply it\nby this vector ej,",
    "start": "954590",
    "end": "960110"
  },
  {
    "text": "and I postmultiply\nit by this vector ej?  I'm claiming that this\ncorresponds to only one",
    "start": "960110",
    "end": "967890"
  },
  {
    "text": "single element of this matrix. Which one is it? AUDIENCE: j. PHILIPPE RIGOLLET:\nj's diagonal element.",
    "start": "967890",
    "end": "974570"
  },
  {
    "text": "So this thing here is nothing\nbut x transpose x inverse,",
    "start": "974570",
    "end": "983210"
  },
  {
    "text": "and then the j-th\ndiagonal element is jj. Now, I cannot go any further.",
    "start": "983210",
    "end": "990840"
  },
  {
    "text": "x transpose x inverse can\nbe a complicated matrix, and I do not know how to express\njj's diagonal element much",
    "start": "990840",
    "end": "1000350"
  },
  {
    "text": "better than this.  Well, no, actually, I don't.",
    "start": "1000350",
    "end": "1006740"
  },
  {
    "text": "It involves basically\nall the coefficients. Yeah? AUDIENCE: [INAUDIBLE]\nsecond j come from,",
    "start": "1006740",
    "end": "1012127"
  },
  {
    "text": "so I get why ej\ntranspose [INAUDIBLE].. Where did the-- PHILIPPE RIGOLLET:\nFrom this rule?",
    "start": "1012127",
    "end": "1018194"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET:\nSo you always pre- and postmultiply when you\ntalk about the covariance, because if you did not, it would\nbe a vector and not a scalar,",
    "start": "1018194",
    "end": "1024869"
  },
  {
    "text": "for one. But in general, think\nof v as a matrix. It's still true even\nin v is a matrix that's",
    "start": "1024869",
    "end": "1031310"
  },
  {
    "text": "compatible with\nthe premultiplying by some Gaussian. ",
    "start": "1031310",
    "end": "1039079"
  },
  {
    "text": "Any other question? Yeah? AUDIENCE: When you say claim\na vector v, what is vector v?",
    "start": "1039079",
    "end": "1045240"
  },
  {
    "text": " PHILIPPE RIGOLLET:\nSo for any vector v--",
    "start": "1045241",
    "end": "1051759"
  },
  {
    "text": "AUDIENCE: OK. ",
    "start": "1051759",
    "end": "1057700"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nAny other question? So now we've identified\nthat the j-th coefficient",
    "start": "1057700",
    "end": "1064889"
  },
  {
    "text": "of this Gaussian, which I\ncan represent from the claim as ej transpose\nthis guy, is also a Gaussian that's centered.",
    "start": "1064890",
    "end": "1071220"
  },
  {
    "text": "And its variance,\nnow, is sigma squared times the j-th diagonal element\nof x transpose x inverse.",
    "start": "1071220",
    "end": "1078700"
  },
  {
    "text": "So the conclusion\nis that beta hat j",
    "start": "1078700",
    "end": "1085830"
  },
  {
    "text": "is equal to beta j plus some n. And I'm going to emphasize\nthe fact that now it's",
    "start": "1085830",
    "end": "1092790"
  },
  {
    "text": "one-dimensional with mean 0\nand covariance sigma squared x",
    "start": "1092790",
    "end": "1099180"
  },
  {
    "text": "transpose x inverse inverse jj.",
    "start": "1099180",
    "end": "1105100"
  },
  {
    "text": "Now, if you look at the last\nline of the second board and the first line\non the first board,",
    "start": "1105100",
    "end": "1111912"
  },
  {
    "text": "those are basically\nthe same thing.  Beta hat j is my theta hat.",
    "start": "1111912",
    "end": "1119410"
  },
  {
    "text": "Beta j is my theta. And the variance\nsigma squared over n is now sigma squared times\nthis [? jj's ?] element.",
    "start": "1119410",
    "end": "1127840"
  },
  {
    "text": "Now, the inverse suggests that\nit looks like the inverse of n. So those things are going to--",
    "start": "1127840",
    "end": "1133960"
  },
  {
    "text": "we're going to want\nto think of those guys as being some sort of\n1/n kind of statement.",
    "start": "1133960",
    "end": "1139917"
  },
  {
    "text": " So from this, the fact that\nthose two things are the same",
    "start": "1139917",
    "end": "1149420"
  },
  {
    "text": "leads us to believe\nthat we are now equipped to perform the task\nthat we're trying to do, because under the\nnull hypothesis,",
    "start": "1149420",
    "end": "1156410"
  },
  {
    "text": "beta j is known it's equal\nto 0, so I can remove it.",
    "start": "1156410",
    "end": "1162790"
  },
  {
    "text": "And I have to deal\nwith the sigma squared. If sigma squared\nis known, then I can just perform\na regular Gaussian",
    "start": "1162790",
    "end": "1169100"
  },
  {
    "text": "test using Gaussian quintiles. And if sigma squared\nis unknown, I'm going to just divide\nby sigma squared",
    "start": "1169100",
    "end": "1175730"
  },
  {
    "text": "and multiply by sigma\nhat, and then I'm going to basically\nget my t-test. ",
    "start": "1175730",
    "end": "1200630"
  },
  {
    "text": "Actually, for the\npurpose of your exam, I really suggest that you\nunderstand every single word",
    "start": "1200630",
    "end": "1206059"
  },
  {
    "text": "I'm going to be saying now,\nbecause this is exactly the same thing that\nyou're expected to know from other courses,\nbecause right now, I'm just",
    "start": "1206060",
    "end": "1212719"
  },
  {
    "text": "going to apply exactly\nthe same technique that we did for the single\nparameter estimation. So what do we have now is that\nunder h0, beta j is equal to 0.",
    "start": "1212719",
    "end": "1226940"
  },
  {
    "text": "Therefore, beta hat j follows\nsome n0 sigma squared.",
    "start": "1226940",
    "end": "1239029"
  },
  {
    "text": "Just like I do in the slide,\nI'm going to call this gamma j. ",
    "start": "1239030",
    "end": "1250810"
  },
  {
    "text": "So gamma j is this x transpose\nx inverse j-th diagonal element.",
    "start": "1250810",
    "end": "1256060"
  },
  {
    "text": " So that implies that\nbeta hat j over sigma--",
    "start": "1256060",
    "end": "1266140"
  },
  {
    "text": "oh, was it a square root? Yeah, sigma square root of\ngamma j follows some n0 1.",
    "start": "1266140",
    "end": "1276130"
  },
  {
    "text": "So I can form my\ntest statistic, which",
    "start": "1276130",
    "end": "1281280"
  },
  {
    "text": "to be reject if the absolute\nvalue of beta hat j divided",
    "start": "1281280",
    "end": "1290880"
  },
  {
    "text": "by sigma square root gamma\nj is larger than what?",
    "start": "1290880",
    "end": "1298159"
  },
  {
    "text": "Can somebody tell\nme what I want this to be larger than to reject? ",
    "start": "1298159",
    "end": "1303948"
  },
  {
    "text": "AUDIENCE: q alpha. PHILIPPE RIGOLLET: q alpha.  Everybody agrees?",
    "start": "1303948",
    "end": "1309350"
  },
  {
    "text": "Of what? Of this guy, where\nthe standard notation",
    "start": "1309350",
    "end": "1318070"
  },
  {
    "text": "that this is the quintile. Everybody agrees? AUDIENCE: It's alpha\nover 2 I think. I think alpha's--",
    "start": "1318070",
    "end": "1323537"
  },
  {
    "text": "PHILIPPE RIGOLLET: Alpha over 2. So not everybody\nshould be agreeing. Thank you, you're the first\none to disagree with yourself,",
    "start": "1323537",
    "end": "1328765"
  },
  {
    "text": "which is probably good.  It's alpha over 2 because\nof the absolute value.",
    "start": "1328765",
    "end": "1334110"
  },
  {
    "text": "I want to just be\naway from this guy, and that's because I have-- so the alpha over 2--",
    "start": "1334110",
    "end": "1339140"
  },
  {
    "text": "the sanity check should be that\nh1 is beta j not equal to 0.",
    "start": "1339140",
    "end": "1347650"
  },
  {
    "text": "So that works if sigma is known,\nbecause I need to know sigma",
    "start": "1347650",
    "end": "1355010"
  },
  {
    "text": "to be able to build my test. So if sigma is unknown, well,\nI can tell you, use this test, but you're going to\nbe like, OK, when",
    "start": "1355010",
    "end": "1361549"
  },
  {
    "text": "I'm going to have to\nplug in some numbers, I'm going to be stuck. ",
    "start": "1361550",
    "end": "1369240"
  },
  {
    "text": "But if sigma is unknown,\nwe have sigma hat",
    "start": "1369240",
    "end": "1379570"
  },
  {
    "text": "squared as an estimator. So let me write\nsigma squared here.",
    "start": "1379570",
    "end": "1386850"
  },
  {
    "text": "So in particular,\nbeta hat divided",
    "start": "1386850",
    "end": "1392049"
  },
  {
    "text": "by sigma hat squared times\nsquare root gamma j-- something",
    "start": "1392050",
    "end": "1398220"
  },
  {
    "text": "I can compute. Sorry, that's beta hat j.  I can compute that thing.",
    "start": "1398220",
    "end": "1404575"
  },
  {
    "text": "Agreed? Now I have sigma hat j. What I need to do is\nto be able to compute the distribution of this thing.",
    "start": "1404576",
    "end": "1412625"
  },
  {
    "text": "So I know the distribution of\nbeta hat j over the square root",
    "start": "1412625",
    "end": "1417880"
  },
  {
    "text": "of gamma j. That's some Gaussian 0, 1. I don't know exactly what\nthe distribution of sigma hat j squared is, but what I know is\nthat that was actually written,",
    "start": "1417880",
    "end": "1426660"
  },
  {
    "text": "maybe, here is that n minus p\nsigma hat squared over sigma",
    "start": "1426660",
    "end": "1434790"
  },
  {
    "text": "squared follows some chi\nsquared with n minus p degrees of freedom,\nand that it's actually",
    "start": "1434790",
    "end": "1441350"
  },
  {
    "text": "independent of beta hat j.",
    "start": "1441350",
    "end": "1446590"
  },
  {
    "text": "It's independent of\nbeta hat, so it's independent of each\nof its coordinates. That was part of your\nhomework where you had to--",
    "start": "1446590",
    "end": "1453680"
  },
  {
    "text": "some of you were confused\nby the fact that-- I mean, if you're independent\nof some big thing, you're independent\nof all the smaller",
    "start": "1453680",
    "end": "1459740"
  },
  {
    "text": "components of this big thing. That's basically what\nyou need to know. And so now I can\njust write this as--",
    "start": "1459740",
    "end": "1466309"
  },
  {
    "text": " this is beta hat j divided by--",
    "start": "1466310",
    "end": "1475970"
  },
  {
    "text": "so now I want to\nmake this guy appear, so it's beta hat j sigma\nsquared over sigma squared--",
    "start": "1475970",
    "end": "1482630"
  },
  {
    "text": "sigma hat squared over sigma\nsquared times n minus p divided",
    "start": "1482630",
    "end": "1488261"
  },
  {
    "text": "by the square root of gamma j. So that's what I want to see. Yeah? AUDIENCE: Why do\nyou have to stick the hat in the denominator?",
    "start": "1488261",
    "end": "1494313"
  },
  {
    "text": "Shouldn't it be sigma? PHILIPPE RIGOLLET:\nYeah, so I write this. I decide to write this.",
    "start": "1494313",
    "end": "1501330"
  },
  {
    "text": "I could have put a\nMickey Mouse here. It just wouldn't make sense. I just decided to\ntake this thing. AUDIENCE: OK.",
    "start": "1501330",
    "end": "1506390"
  },
  {
    "text": "PHILIPPE RIGOLLET: OK. So now, let-- so I\ntake this guy, and now,",
    "start": "1506390",
    "end": "1512800"
  },
  {
    "text": "I'm going to rewrite\nit as something I want, because if you don't\nknow what sigma is--",
    "start": "1512800",
    "end": "1517891"
  },
  {
    "text": "sorry, that's not sigm-- you mean the square? AUDIENCE: Yeah. PHILIPPE RIGOLLET:\nOh, thank you. Yes, that's correct. [LAUGHS] OK, so you\ndon't know what's sigma",
    "start": "1517891",
    "end": "1525390"
  },
  {
    "text": "is, you replace it by sigma hat. That's the most\nnatural thing to do. You just now want\nto find out what",
    "start": "1525390",
    "end": "1530590"
  },
  {
    "text": "the distribution of this guy is. So this is not\nexactly what I had.",
    "start": "1530590",
    "end": "1535780"
  },
  {
    "text": "To be able to get this, I need\nto divide by sigma squared--",
    "start": "1535780",
    "end": "1541530"
  },
  {
    "text": "sorry, I need to-- AUDIENCE: Square root. PHILIPPE RIGOLLET: I'm sorry. AUDIENCE: Do we\nneed a square root of the sigma hat [INAUDIBLE].",
    "start": "1541530",
    "end": "1547450"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nThat's correct now. ",
    "start": "1547450",
    "end": "1555399"
  },
  {
    "text": "And now I have that-- sorry, I should not\nwrite it like that. That's not what I want.",
    "start": "1555400",
    "end": "1561770"
  },
  {
    "text": "What I want is this. ",
    "start": "1561770",
    "end": "1568260"
  },
  {
    "text": "And to be able to get\nthis guy, what I need is sigma over sigma\nhat square root.",
    "start": "1568260",
    "end": "1585100"
  },
  {
    "text": "And then I need to make\nthis thing show up. So I need to have this n minus\np show up in the denominator.",
    "start": "1585100",
    "end": "1592670"
  },
  {
    "text": "So to be able to get\nit, I need to multiply the entire thing by the\nsquare root of n minus p. ",
    "start": "1592670",
    "end": "1601120"
  },
  {
    "text": "So this is just a tautology. I just squeezed\nin what I wanted.",
    "start": "1601120",
    "end": "1606510"
  },
  {
    "text": "But now this whole thing\nhere, this is actually of the form beta hat j divided\nby sigma over square root gamma",
    "start": "1606510",
    "end": "1616560"
  },
  {
    "text": "j, and then divided by square\nroot of sigma hat squared over sigma squared.",
    "start": "1616560",
    "end": "1624700"
  },
  {
    "text": " No, I don't want to divide it by\nsquare root of minus p, sorry.",
    "start": "1624700",
    "end": "1631231"
  },
  {
    "text": " And now it's times n minus\np divided by n minus p.",
    "start": "1631231",
    "end": "1641720"
  },
  {
    "start": "1641720",
    "end": "1647559"
  },
  {
    "text": "And what is the distribution\nof this thing here? ",
    "start": "1647560",
    "end": "1663546"
  },
  {
    "text": "So I'm going to keep going here. So the distribution of\nthis thing here is what? Well, this numerator,\nwhat is this distribution?",
    "start": "1663546",
    "end": "1674075"
  },
  {
    "text": " AUDIENCE: [INAUDIBLE]",
    "start": "1674075",
    "end": "1681650"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah, n0 1. It's actually still\nwritten over there. ",
    "start": "1681650",
    "end": "1689460"
  },
  {
    "text": "So that's our n0 1. What is the distribution\nof this guy? ",
    "start": "1689460",
    "end": "1696580"
  },
  {
    "text": "Sorry, I don't think\nyou have color again. So what is the\ndistribution of this guy?",
    "start": "1696580",
    "end": "1702922"
  },
  {
    "text": "This is still\nwritten on the board. AUDIENCE: Chi squared. PHILIPPE RIGOLLET: It's the chi\nsquared that I have right here.",
    "start": "1702922",
    "end": "1708285"
  },
  {
    "text": " So that's a chi squared n\nminus p divided by n minus p",
    "start": "1708285",
    "end": "1715580"
  },
  {
    "text": "degrees of freedom. The only thing I\nneed to check is that those two guys\nare independent, which is also what I have from here.",
    "start": "1715580",
    "end": "1723050"
  },
  {
    "text": "And so that implies\nthat beta hat j divided",
    "start": "1723050",
    "end": "1729690"
  },
  {
    "text": "by sigma hat square\nroot of gamma j, what is the\ndistribution of this guy?",
    "start": "1729690",
    "end": "1735360"
  },
  {
    "start": "1735360",
    "end": "1744822"
  },
  {
    "text": "[INTERPOSING VOICES] PHILIPPE RIGOLLET: n minus p. Was that crystal\nclear for everyone?",
    "start": "1744822",
    "end": "1752039"
  },
  {
    "text": "Was that so simple that\nit was boring to everyone? OK, good. That's where the point\nat which you should be.",
    "start": "1752040",
    "end": "1758760"
  },
  {
    "text": "So now I have this, I can read\nthe quintiles of this guy. So my test statistic becomes--",
    "start": "1758760",
    "end": "1768580"
  },
  {
    "text": "well, my rejection\nregion, I reject if the absolute\nvalue of this new guy",
    "start": "1768580",
    "end": "1780390"
  },
  {
    "text": "exceeds the quintile of order\nalpha over 2, but this time, of a tn minus p.",
    "start": "1780390",
    "end": "1788390"
  },
  {
    "text": "And now you can actually\nsee that the only difference between this test and that\ntest, apart from replacing sigma",
    "start": "1788390",
    "end": "1793600"
  },
  {
    "text": "by sigma hat, is\nthat now I've moved from the quintiles of a\nGaussian to the quintiles of a tn minus p.",
    "start": "1793600",
    "end": "1799640"
  },
  {
    "start": "1799640",
    "end": "1811085"
  },
  {
    "text": "What's actually interesting,\nfrom this perspective, is that the tn minus\np, we know, has",
    "start": "1811085",
    "end": "1818070"
  },
  {
    "text": "heavier tails than the Gaussian,\nbut if the number of degrees of freedom reaches, maybe, 30 or\n40, they're virtually the same.",
    "start": "1818070",
    "end": "1826131"
  },
  {
    "text": "And here, the number\nof degrees of freedom is not given only by\nn, but it's n minus p. So if I have more and more\nparameters to estimate,",
    "start": "1826131",
    "end": "1833100"
  },
  {
    "text": "this will result in some\nheavier, heavier tails, and that's just to\naccount for the fact that it's harder and harder\nto estimate the variance",
    "start": "1833100",
    "end": "1841679"
  },
  {
    "text": "when I have a lot of parameters. That's basically where\nit's coming from.",
    "start": "1841680",
    "end": "1846780"
  },
  {
    "text": "So now let's move on to--",
    "start": "1846780",
    "end": "1852270"
  },
  {
    "text": "well, I don't know what because\nthis is not working anymore. So this is the simplest test.",
    "start": "1852270",
    "end": "1859080"
  },
  {
    "text": "And actually, if you run\nany statistical software for least squares, the\noutput in any of them",
    "start": "1859080",
    "end": "1866190"
  },
  {
    "text": "will look like this. You will have a\nsequence of rows.",
    "start": "1866190",
    "end": "1871779"
  },
  {
    "text": "And you're going to have\nan estimate for beta 0, an estimate for\nbeta 1, et cetera.",
    "start": "1871780",
    "end": "1877445"
  },
  {
    "text": "Here, you're going to\nhave a bunch of things. And on this row, you're\ngoing to have the value here,",
    "start": "1877445",
    "end": "1883039"
  },
  {
    "text": "so that's going to be what's\nestimated by least squares. And then the second line\nimmediately is going to be,",
    "start": "1883040",
    "end": "1890260"
  },
  {
    "text": "well, either the\nvalue of this thing-- ",
    "start": "1890260",
    "end": "1895320"
  },
  {
    "text": "so let's call it t. And then there's going\nto be the p value corresponding to this t.",
    "start": "1895320",
    "end": "1900800"
  },
  {
    "text": "This is something that's just\nroutinely coming out because-- oh, and then there's, of course,\nthe last line for people who",
    "start": "1900800",
    "end": "1906650"
  },
  {
    "text": "cannot read numbers that's\nreally just giving you little stars. ",
    "start": "1906650",
    "end": "1913850"
  },
  {
    "text": "They're not stickers,\nbut that's close to it. And that's just saying,\nwell, I have three stars,",
    "start": "1913850",
    "end": "1919110"
  },
  {
    "text": "I'm very significantly\ndifferent from 0's. If I have 2 stars, I'm\nmoderately differently from 0.",
    "start": "1919110",
    "end": "1924160"
  },
  {
    "text": "And if I have 1 star,\nit means, well, just give me another $1,000 and I\nwill sign that it's actually",
    "start": "1924160",
    "end": "1930450"
  },
  {
    "text": "different from 0. So that's basically\nthe kind of outputs. Everybody sees what\nI mean by that?",
    "start": "1930450",
    "end": "1936466"
  },
  {
    "text": "So what I mean, what I'm\ntrying to emphasize here, is that those things\nare so routine when you run linear aggression,\nbecause people stuff in maybe--",
    "start": "1936467",
    "end": "1943740"
  },
  {
    "text": "even if you have\n200 observations, you're going to stuff in maybe\n20 variables-- p equals 20. That's still a big number to\ninterpret what's going on.",
    "start": "1943740",
    "end": "1951110"
  },
  {
    "text": "And it's nice for you if you\ncan actually trim some fat out. And so the problem is that when\nyou start doing this, and then",
    "start": "1951110",
    "end": "1961260"
  },
  {
    "text": "this, and then\nthis, and then this, the probability that\nyou make a mistake",
    "start": "1961260",
    "end": "1967750"
  },
  {
    "text": "in your test, the probably\nthat you erroneously reject the null here is 5%.",
    "start": "1967750",
    "end": "1975170"
  },
  {
    "text": "Here, it's 5%. Here, it's 5%. Here, it's 5%. And at some point, if things\nhappen with 5% chances",
    "start": "1975170",
    "end": "1985370"
  },
  {
    "text": "and you keep on doing\nthem over and over again, they're going to\nstart to happen. So you can see that\nbasically what's happening",
    "start": "1985370",
    "end": "1994160"
  },
  {
    "text": "is that you actually\nhave an issue is that if you start\nrepeating those tests, you might not be at 5%\nerror at some point.",
    "start": "1994160",
    "end": "2003000"
  },
  {
    "text": "And so what do you do\nto prevent from that, if you want to test all those\nbeta j's simultaneously,",
    "start": "2003000",
    "end": "2008850"
  },
  {
    "text": "you have to do what's called\nthe Bonferroni correction. And the Bonferroni correction\nfollows from what's",
    "start": "2008850",
    "end": "2015059"
  },
  {
    "text": "called a union bound. A union bound is actually-- so\nif you're a computer scientist,",
    "start": "2015060",
    "end": "2020392"
  },
  {
    "text": "you're very familiar with it. If you're a mathematician,\nthat's just, essentially, the third axiom of\nprobability that you see,",
    "start": "2020392",
    "end": "2026650"
  },
  {
    "text": "that the probability\nof the union is less than the sum\nof the probabilities. ",
    "start": "2026650",
    "end": "2040350"
  },
  {
    "text": "That's the union bound. And you, of course, can\ngeneralize that to more than 2.",
    "start": "2040350",
    "end": "2045570"
  },
  {
    "text": "And that's exactly\nwhat you're doing here. So let's see how we would\nwant to perform Bonferroni",
    "start": "2045570",
    "end": "2051869"
  },
  {
    "text": "correction to control the\nprobability that they're all",
    "start": "2051870",
    "end": "2059340"
  },
  {
    "text": "equal to 0 at the same time. ",
    "start": "2059340",
    "end": "2066690"
  },
  {
    "text": "So recall-- so if I want to\nperform this test over there where I want to\ntest h0, that beta j",
    "start": "2066690",
    "end": "2074820"
  },
  {
    "text": "is equal to 0 for all\nj in some subset s.",
    "start": "2074820",
    "end": "2080560"
  },
  {
    "text": " So think of s included in 1p.",
    "start": "2080560",
    "end": "2088408"
  },
  {
    "text": "You can think of it as being\nall of 1 of p if you want. It really doesn't matter. s is\nsomething that's given to you.",
    "start": "2088409",
    "end": "2093960"
  },
  {
    "text": "Maybe you want to test\nthe subset of them, but maybe you want\nto test all of them. Versus h1, beta j is not\nequal to 0 for some j in s.",
    "start": "2093960",
    "end": "2104539"
  },
  {
    "text": " That's a test that tests\nall these things at once.",
    "start": "2104540",
    "end": "2110610"
  },
  {
    "text": "And if you actually look\nat this table all at once, implicitly, you're performing\nthis test for all of the rows,",
    "start": "2110610",
    "end": "2116819"
  },
  {
    "text": "for s equal 1 to p. You will do that. Whether you like it\nor not, you will.",
    "start": "2116820",
    "end": "2123119"
  },
  {
    "text": "So now let's look at what the\nprobability of type I error looks like. So I want the probability\nof type 1 error,",
    "start": "2123120",
    "end": "2131270"
  },
  {
    "text": "so that's the probably\nwhen h0 is true. Well, so let me call psi j the\nindicator that, say, beta j",
    "start": "2131270",
    "end": "2141930"
  },
  {
    "text": "hat over sigma hat square\nroot gamma j exceeds",
    "start": "2141930",
    "end": "2151329"
  },
  {
    "text": "q alpha over 2 of tn minus p. So we know that those are\nthe tests that I perform.",
    "start": "2151330",
    "end": "2156760"
  },
  {
    "text": "Here, I just add\nthis extra index j to tell me that I'm actually\ntesting the j-th coefficient.",
    "start": "2156760",
    "end": "2162400"
  },
  {
    "text": "So what I want is the\nprobability that under the null so that those are all\nequal to 0 that beta j's--",
    "start": "2162400",
    "end": "2172450"
  },
  {
    "text": "that I will reject to the\nalternative for one of them. So that's psi 1 is\nequal to 1 or psi 2",
    "start": "2172450",
    "end": "2185510"
  },
  {
    "text": "is equal to 1, all\nthe way to psi-- well, let's just say that\nthis is the entire thing,",
    "start": "2185510",
    "end": "2191474"
  },
  {
    "text": "because it's annoying.  I mean, you can check\nthe slide if you",
    "start": "2191474",
    "end": "2197830"
  },
  {
    "text": "want to do it more generally. But psi p is equal to--",
    "start": "2197830",
    "end": "2204140"
  },
  {
    "text": "or, or-- everybody agrees\nthat this is the probability of type I error?",
    "start": "2204140",
    "end": "2211940"
  },
  {
    "text": "So either I reject\nthis one, or this one, or this one, or this\none, or this one. And that's exactly when I'm\ngoing to reject at least one",
    "start": "2211940",
    "end": "2218090"
  },
  {
    "text": "of them. So this is the probability\nof type I error.",
    "start": "2218090",
    "end": "2228550"
  },
  {
    "text": "And what I want is to keep\nthis guy less than alpha. ",
    "start": "2228550",
    "end": "2235779"
  },
  {
    "text": "But what I know is to\ncontrol the probability that this guy is less than\nalpha, that this guy is less than alpha, that this\nguy is less than alpha.",
    "start": "2235780",
    "end": "2242819"
  },
  {
    "text": "In particular, if all\nthese guys are disjoint, then this could really be the\nsum of all these probabilities.",
    "start": "2242820",
    "end": "2249530"
  },
  {
    "text": "So in the worst case, if psi j\nequals 1 intersected with psi k",
    "start": "2249530",
    "end": "2262400"
  },
  {
    "text": "equals 1 is the empty\nset, so that means those are called disjoint sets.",
    "start": "2262400",
    "end": "2267960"
  },
  {
    "text": " You've seen this terminology\nin probability, right?",
    "start": "2267960",
    "end": "2273970"
  },
  {
    "text": "So if those sets are\ndisjoint, for all of them,",
    "start": "2273970",
    "end": "2280800"
  },
  {
    "text": "for all j different from\nk, then this probability-- ",
    "start": "2280800",
    "end": "2287370"
  },
  {
    "text": "well, let me write it as star--",
    "start": "2287370",
    "end": "2294590"
  },
  {
    "text": "then star is equal to, well,\nthe probability under h0",
    "start": "2294590",
    "end": "2300990"
  },
  {
    "text": "that psi 1 is equal to 1\nplus the probability under h0",
    "start": "2300990",
    "end": "2310320"
  },
  {
    "text": "that psi p is equal to 1. Now, if I use this test\nwith this alpha here,",
    "start": "2310320",
    "end": "2317120"
  },
  {
    "text": "then this probability\nis equal to alpha. This probability is\nalso equal to alpha.",
    "start": "2317120",
    "end": "2323185"
  },
  {
    "text": "So the probably of type I error\nis actually not equal to alpha. It's equal to? AUDIENCE: p alpha.",
    "start": "2323185",
    "end": "2328270"
  },
  {
    "text": "PHILIPPE RIGOLLET: p alpha.  So what is the solution here?",
    "start": "2328270",
    "end": "2334240"
  },
  {
    "text": "Well, it's to run those\nguys not with alpha, but with alpha over p.",
    "start": "2334240",
    "end": "2339802"
  },
  {
    "text": " And if they do this, then this\nguy is equal to alpha over p,",
    "start": "2339802",
    "end": "2346869"
  },
  {
    "text": "this guy is equal\nto alpha over p. And so when I get\nthose things, I get p times alpha over\np, which is just alpha.",
    "start": "2346870",
    "end": "2353260"
  },
  {
    "text": " So all I do is, rather than\nrunning each of the tests",
    "start": "2353260",
    "end": "2360410"
  },
  {
    "text": "with probability of error-- so that's a test at\nlevel alpha over p.",
    "start": "2360410",
    "end": "2368751"
  },
  {
    "text": " That's actually very stringent.",
    "start": "2368751",
    "end": "2373800"
  },
  {
    "text": "If you think about\nit for 1 second, even if you have only 5\nvariables-- p equals 5--",
    "start": "2373800",
    "end": "2381542"
  },
  {
    "text": "and you started\nwith the tests, you wanted to do your tests at 5%. It forces you to do the test at\n1% for each of those variables.",
    "start": "2381542",
    "end": "2390720"
  },
  {
    "text": "If you have 10\nvariables, I mean, that start to be very stringent. So it's going to be\nharder and harder for you",
    "start": "2390720",
    "end": "2399690"
  },
  {
    "text": "to conclude to the alternative. Now, one thing I\nneed to tell you is that here I said,\nif they are disjoint,",
    "start": "2399690",
    "end": "2405240"
  },
  {
    "text": "then those\nprobabilities are equal. But if they are not\ndisjoint, the union bound",
    "start": "2405240",
    "end": "2412609"
  },
  {
    "text": "tells me that the\nprobability of the union is less than the sum\nof the probabilities. And so now I'm not\nexactly equal to alpha,",
    "start": "2412610",
    "end": "2420089"
  },
  {
    "text": "but I'm bounded by alpha. And that's why\nBonferroni correction,",
    "start": "2420090",
    "end": "2426170"
  },
  {
    "text": "people are not super\ncomfortable with, is because, in reality,\nyou never think that those tests are\ngoing to be giving you",
    "start": "2426170",
    "end": "2432610"
  },
  {
    "text": "completely disjoint things. I mean, why would it be? Why would it be that if\nthis guy is equal to 1,",
    "start": "2432610",
    "end": "2439210"
  },
  {
    "text": "then all the other\nones are equal to 0? Why would it make any sense?",
    "start": "2439210",
    "end": "2444340"
  },
  {
    "text": "So this is definitely\nconservative, but the problem is that we don't\nknow how to do much better.",
    "start": "2444340",
    "end": "2449394"
  },
  {
    "text": "I mean, we have a\nformula that tells you the probability of the\nunion as some crazy sum that looks at all the intersection\nand all these little things.",
    "start": "2449394",
    "end": "2457330"
  },
  {
    "text": "I mean, it's the\ngeneralization of p of a or b is equal to p of a plus\np of b minus probability",
    "start": "2457330",
    "end": "2466060"
  },
  {
    "text": "of the intersection. But if you start doing\nthis for more than 2, it's super complicated.",
    "start": "2466060",
    "end": "2472060"
  },
  {
    "text": "The number of terms\ngrows really fast. But most importantly,\neven if you go here,",
    "start": "2472060",
    "end": "2477432"
  },
  {
    "text": "you still need to\ncontrol the probability of the intersection. And those tests are not\nnecessarily independent.",
    "start": "2477432",
    "end": "2482470"
  },
  {
    "text": "If they were independent,\nthen that would be easy. The probably of the intersection\nwould be the product of the probabilities.",
    "start": "2482470",
    "end": "2487840"
  },
  {
    "text": "But those things are\nsuper correlated, and so it doesn't really help.",
    "start": "2487840",
    "end": "2493220"
  },
  {
    "text": "And so we'll see, when we talk\nabout high-dimensional stats towards the end, that\nthere's something",
    "start": "2493220",
    "end": "2498650"
  },
  {
    "text": "called false discovery rate,\nwhich is essentially saying, listen, if I want to\ncontrol this thing,",
    "start": "2498650",
    "end": "2505380"
  },
  {
    "text": "if I really define my\nprobability of type I error as this, I want to\nmake sure that I never make this kind of error, I'm doomed.",
    "start": "2505380",
    "end": "2512300"
  },
  {
    "text": "This is just not\ngoing to happen. But I can revise what my\ngoals are in terms of errors",
    "start": "2512300",
    "end": "2519500"
  },
  {
    "text": "that I make, and then I\nwill actually be able to do. And what people are looking\nat is false discovery rate.",
    "start": "2519500",
    "end": "2525680"
  },
  {
    "text": "And this is called\nfamily-wise error rate, which is a stronger thing to control. So this trick that\nconsists in replacing",
    "start": "2525680",
    "end": "2534590"
  },
  {
    "text": "alpha by alpha over\nthe number of times you're going to be\nperforming your test, or alpha over the number\nof terms in your union,",
    "start": "2534590",
    "end": "2541700"
  },
  {
    "text": "is actually called the\nBonferroni correction. ",
    "start": "2541700",
    "end": "2552160"
  },
  {
    "text": "And that's something you use\nwhen you have what's called-- another key word here\nis multiple testing,",
    "start": "2552160",
    "end": "2561010"
  },
  {
    "text": "when you're trying to do\nmultiple tests simultaneously. ",
    "start": "2561010",
    "end": "2567470"
  },
  {
    "text": "And if s is not of\np, well, you just divide by the number of tests\nthat you are actually making.",
    "start": "2567470",
    "end": "2572760"
  },
  {
    "text": "So if s is of size k\nfor some k less than p, you just divide alpha by\nk and not by p, of course.",
    "start": "2572760",
    "end": "2579172"
  },
  {
    "text": "I mean, you can\nalways divide by p, but you're going to make your\nlife harder for no reason. ",
    "start": "2579172",
    "end": "2591010"
  },
  {
    "text": "Any question about\nBonferroni correction? ",
    "start": "2591010",
    "end": "2598260"
  },
  {
    "text": "So one thing that is\nmaybe not as obvious",
    "start": "2598260",
    "end": "2606100"
  },
  {
    "text": "as the test beta j equal to 0\nversus beta j not equal to 0-- and in particular,\nwhat it means is",
    "start": "2606100",
    "end": "2612190"
  },
  {
    "text": "that it's not going to come\nup as a software output without even you requesting\nit because this is so standard",
    "start": "2612190",
    "end": "2619480"
  },
  {
    "text": "that it's just coming out. But there's other\ntests that you might think of that might be\nmore complicated and more",
    "start": "2619480",
    "end": "2625060"
  },
  {
    "text": "tailored to your\nparticular problem. And those tests are of\nthe form g times beta",
    "start": "2625060",
    "end": "2632560"
  },
  {
    "text": "is equal to some lambda. So let's see, the\ntest we've just done,",
    "start": "2632560",
    "end": "2645810"
  },
  {
    "text": "beta j equals 0 versus\nbeta j not equal to 0,",
    "start": "2645810",
    "end": "2654910"
  },
  {
    "text": "is actually equivalent to\nej transpose beta equals",
    "start": "2654910",
    "end": "2663099"
  },
  {
    "text": "0 versus ej transpose\nbeta not equal to 0. That was our claim.",
    "start": "2663100",
    "end": "2671260"
  },
  {
    "text": "But now I don't\nhave to stop here. I don't have to\nmultiply by a vector and test if it's equal to 0.",
    "start": "2671260",
    "end": "2676890"
  },
  {
    "text": "I can actually replace this\nby some general matrix g",
    "start": "2676890",
    "end": "2686789"
  },
  {
    "text": "and replace this guy by\nsome general vector lambda.",
    "start": "2686790",
    "end": "2694449"
  },
  {
    "text": "And I'm not telling\nyou what the dimensions are because they're general. I can take whatever I want. Take your favorite\nmatrix, as long",
    "start": "2694449",
    "end": "2700260"
  },
  {
    "text": "as the right side of the\nmatrix can be multiplying beta,",
    "start": "2700260",
    "end": "2705690"
  },
  {
    "text": "and lambda, take it as\nthe number of rows of g, and then you can do that.",
    "start": "2705690",
    "end": "2711820"
  },
  {
    "text": "I can always\nformulate this test. What will this test encompass? Well, those are\nkind of weird tests.",
    "start": "2711820",
    "end": "2718780"
  },
  {
    "text": "So you can think\nof things like, I want to test if beta 2 plus beta\n3 are equal to 0, for example.",
    "start": "2718780",
    "end": "2730440"
  },
  {
    "text": "Maybe I want to test if beta 5\nminus 2 beta 6 is equal to 23.",
    "start": "2730440",
    "end": "2740770"
  },
  {
    "text": "Well, that's weird. But why would you want to\ntest if beta 2 plus beta 3 is equal to 0?",
    "start": "2740770",
    "end": "2746814"
  },
  {
    "text": "Maybe you don't want to\nknow if the-- you know that the effect of\nsome gene is not 0. Maybe you know that this\ngene affects this trait,",
    "start": "2746814",
    "end": "2754210"
  },
  {
    "text": "but you want to know if\nthe effect of this gene is canceled by the\neffect of that gene.",
    "start": "2754210",
    "end": "2759262"
  },
  {
    "text": "And this is the kind\nof stuff that you're going to be testing for that. ",
    "start": "2759262",
    "end": "2764470"
  },
  {
    "text": "Now, this guy is\nmuch more artificial, and I don't have a bedtime\nstory to tell you around this. So those things can happen and\ncan be much more complicated.",
    "start": "2764470",
    "end": "2773340"
  },
  {
    "text": "Now, here, notice\nthat the matrix g has one row for both\nof the examples. But if I want to test if\nthose two things happen",
    "start": "2773340",
    "end": "2780580"
  },
  {
    "text": "at the same time, then I\nactually can take a matrix. Another matrix\nthat can be useful",
    "start": "2780580",
    "end": "2787839"
  },
  {
    "text": "is g equals the identity of\nrp and lambda is equal to 0.",
    "start": "2787840",
    "end": "2794620"
  },
  {
    "text": "What am I doing\nhere in this case? What is this test testing?",
    "start": "2794620",
    "end": "2801480"
  },
  {
    "text": "Sorry, this test.  Yeah? AUDIENCE: Whether\nor not beta is 0.",
    "start": "2801480",
    "end": "2806820"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah, we're\ntesting if the entire vector beta is equal to 0, because g\ntimes beta is equal to beta,",
    "start": "2806820",
    "end": "2814120"
  },
  {
    "text": "and we're asking\nwhether it's equal to 0. ",
    "start": "2814120",
    "end": "2820375"
  },
  {
    "text": "So the thing is, when\nyou want to actually test if beta is equal to\n0, you're actually",
    "start": "2820375",
    "end": "2827140"
  },
  {
    "text": "testing if your entire\nmodel, everything you're doing in life, is just junk. This is just telling\nyou, actually,",
    "start": "2827140",
    "end": "2833920"
  },
  {
    "text": "forget about this y is\nx beta plus epsilon. y is really just epsilon. There's nothing.",
    "start": "2833920",
    "end": "2839200"
  },
  {
    "text": "There's just some big noise\nwith some big variants, and there's nothing else. So turns out that the\nstatistical software",
    "start": "2839200",
    "end": "2846859"
  },
  {
    "text": "output that I wrote here spits\nout an answer to this question. Just the last line,\nusually, is doing this test.",
    "start": "2846860",
    "end": "2854480"
  },
  {
    "text": "Does your model even make sense? And it's probably for people\nto check whether they actually just mix their two data sets.",
    "start": "2854480",
    "end": "2861230"
  },
  {
    "text": "Maybe they're actually\ntrying to predict-- I don't know-- some credit\nscore from genomic data,",
    "start": "2861230",
    "end": "2869190"
  },
  {
    "text": "and so just want to\nmake sure, maybe, that's not the right thing. So it turns out that the\nmachinery is exactly the same",
    "start": "2869190",
    "end": "2876500"
  },
  {
    "text": "as the one we've just taken. So we actually start from here. ",
    "start": "2876500",
    "end": "2885542"
  },
  {
    "text": "So let me pull this up. ",
    "start": "2885542",
    "end": "2892930"
  },
  {
    "text": "So we start from here. Beta hat was equal to\nbeta plus this guy.",
    "start": "2892930",
    "end": "2898470"
  },
  {
    "text": " And the first thing we\ndid was to say, well,",
    "start": "2898470",
    "end": "2903640"
  },
  {
    "text": "beta j is equal to this thing\nbecause, well, beta j was just ej times beta.",
    "start": "2903640",
    "end": "2909250"
  },
  {
    "text": "So rather than taking ej\nhere, let me just take g. ",
    "start": "2909250",
    "end": "2922280"
  },
  {
    "text": "Now, we said that\nfor any vector-- well, that was trivial.",
    "start": "2922280",
    "end": "2927840"
  },
  {
    "text": "So the thing we need to\nknow is, what is this thing? Well, this thing here,\nwhat is this guy?",
    "start": "2927840",
    "end": "2935110"
  },
  {
    "text": "It's also normal\nand the mean is 0. Again, that's just using\nproperties of Gaussian vectors.",
    "start": "2935110",
    "end": "2943510"
  },
  {
    "text": "And what is the\ncovariance matrix? Let's call these guys sigma so\nthat you can make an answer,",
    "start": "2943510",
    "end": "2949290"
  },
  {
    "text": "you can formulate an answer. So what is the\ndistribution of-- what is the covariance of g\ntimes some Gaussian 0 sigma?",
    "start": "2949290",
    "end": "2958354"
  },
  {
    "text": "AUDIENCE: g sigma g transpose. PHILIPPE RIGOLLET: g\nsigma g transpose, right? So that's gx transpose\nx inverse g transpose.",
    "start": "2958354",
    "end": "2973895"
  },
  {
    "text": " Now, I'm not going to be\nable to go much farther.",
    "start": "2973895",
    "end": "2981779"
  },
  {
    "text": "I mean, I made this\nvery acute observation that ej transpose the matrix\ntimes ej is the j-th angle",
    "start": "2981780",
    "end": "2987789"
  },
  {
    "text": "element. Now, if I have a general matrix,\nthe price to pay is that I cannot just shrink this thing\nany further because I'm trying",
    "start": "2987790",
    "end": "2992949"
  },
  {
    "text": "to be abstract. And so I'm almost there. The only thing that\nhappened last time",
    "start": "2992949",
    "end": "2998070"
  },
  {
    "text": "is that when this\nwas ej under h0, 0, we knew that this was\nequal to 0 under the null.",
    "start": "2998070",
    "end": "3003380"
  },
  {
    "text": "But under the null,\nwhat is this equal to?",
    "start": "3003380",
    "end": "3008789"
  },
  {
    "text": " AUDIENCE: Lambda. PHILIPPE RIGOLLET:\nLambda, which I know.",
    "start": "3008790",
    "end": "3015106"
  },
  {
    "text": "I mean, I wrote my thing. And in the couple instances\nI just showed you, including this one over there\non top, lambda was equal to 0.",
    "start": "3015106",
    "end": "3022700"
  },
  {
    "text": "But in general, it\ncan be any lambda. But what's key about this lambda\nis that I actually know it.",
    "start": "3022700",
    "end": "3027890"
  },
  {
    "text": "That's the hypothesis\nI'm formulating. So now I'm going to have to\nbe a little more careful when",
    "start": "3027890",
    "end": "3034339"
  },
  {
    "text": "I want to build the\ndistribution of g beta hat. I need to actually\nsubtract this lambda.",
    "start": "3034340",
    "end": "3039380"
  },
  {
    "text": "So now we go from\nthis, and we say, well, g beta hat\nminus lambda follows",
    "start": "3039380",
    "end": "3047040"
  },
  {
    "text": "some np0 sigma squared\ng x transpose x",
    "start": "3047040",
    "end": "3057730"
  },
  {
    "text": "inverse g transpose. ",
    "start": "3057730",
    "end": "3064069"
  },
  {
    "text": "So that's true. Let's assume-- let's go\nstraight to the case when we don't know what sigma is.",
    "start": "3064070",
    "end": "3070410"
  },
  {
    "text": "So what I'm going\nto be interested in is g beta hat minus lambda\ndivided by sigma hat.",
    "start": "3070410",
    "end": "3086359"
  },
  {
    "text": "And that's going to follow some\nGaussian that has this thing, gx transpose x\ninverse g transpose.",
    "start": "3086360",
    "end": "3097660"
  },
  {
    "text": "So now, what did I do last time? So clearly, the quintiles\nof this distribution",
    "start": "3097660",
    "end": "3105010"
  },
  {
    "text": "is-- well, OK, what is the\nsize of this distribution? Well, I need to tell\nyou that g is an--",
    "start": "3105010",
    "end": "3112848"
  },
  {
    "text": "what did I take here? AUDIENCE: 1 divided by\nsigma, not sigma hat. PHILIPPE RIGOLLET: Oh,\nyeah, you're right.",
    "start": "3112848",
    "end": "3118930"
  },
  {
    "text": "So let me write it like this. ",
    "start": "3118930",
    "end": "3125750"
  },
  {
    "text": "Well, let me write\nit like this--",
    "start": "3125750",
    "end": "3135800"
  },
  {
    "text": "sigma squared over sigma. ",
    "start": "3135800",
    "end": "3141659"
  },
  {
    "text": "So let's forget about\nthe size of g now. Let's just think\nof any general g. ",
    "start": "3141659",
    "end": "3147730"
  },
  {
    "text": "When g was a vector,\nwhat was nice is that this guy was just the\nscalar number, just one number.",
    "start": "3147730",
    "end": "3155410"
  },
  {
    "text": "And so if I wanted to get rid\nof this in the right-hand side, all I had to do was to\ndivide it by this thing. We called it gamma j.",
    "start": "3155410",
    "end": "3161463"
  },
  {
    "text": "And we just had to divide\nby square root of gamma j, and that would be gone. Now I have a matrix.",
    "start": "3161464",
    "end": "3168450"
  },
  {
    "text": "So I need to get\nrid of this matrix somehow because, clearly, the\nquintiles of this distribution",
    "start": "3168450",
    "end": "3175016"
  },
  {
    "text": "are not going to be\nwritten in the back of a book for any value\nof g and any value of x. So I need to standardize\nbefore I can read anything out",
    "start": "3175016",
    "end": "3181660"
  },
  {
    "text": "of a table. So how do we do it? Well, we just form\nthis guy here.",
    "start": "3181660",
    "end": "3194880"
  },
  {
    "text": "So what we know is that if-- so here's the claim,\nagain, another",
    "start": "3194880",
    "end": "3201120"
  },
  {
    "text": "claim about Gaussian vector. If x follows some n0 sigma,\nthen x transpose sigma inverse x",
    "start": "3201120",
    "end": "3223220"
  },
  {
    "text": "follows some chi squared. ",
    "start": "3223220",
    "end": "3228329"
  },
  {
    "text": "And here, it's going to depend\non what is the dimension here. So if I make this a k by k, a\nk-dimensional Gaussian vector,",
    "start": "3228330",
    "end": "3236160"
  },
  {
    "text": "this is x squared k. ",
    "start": "3236160",
    "end": "3242467"
  },
  {
    "text": "Where have we used that before? ",
    "start": "3242467",
    "end": "3248928"
  },
  {
    "text": "Yeah? AUDIENCE: Wald's test. PHILIPPE RIGOLLET: Wald's test,\nthat's exactly what we used. Wald's test had a chi\nsquared that was showing up.",
    "start": "3248928",
    "end": "3256480"
  },
  {
    "text": "And the way we\nmade it show up was by taking the\nasymptotic variance, taking its inverse, which, in\nthis framework, was called--",
    "start": "3256480",
    "end": "3264851"
  },
  {
    "text": "AUDIENCE: Fisher. PHILIPPE RIGOLLET:\nFisher information. And then we pre- and\npostmultiply by this thing.",
    "start": "3264852",
    "end": "3271410"
  },
  {
    "text": "So this is the key. And so now, it tells\nme exactly, when I start from this guy that has\nthis multivariate Gaussian,",
    "start": "3271410",
    "end": "3278190"
  },
  {
    "text": "it tells me how to\nturn it into something that has a distribution\nwhich is pivotal. Chi squared k is completely\npivotal, does not depend",
    "start": "3278190",
    "end": "3285849"
  },
  {
    "text": "on anything I don't know. ",
    "start": "3285849",
    "end": "3303809"
  },
  {
    "text": "The way I go from here\nis by saying, well, now, I look at g beta hat\nminus lambda transpose,",
    "start": "3303810",
    "end": "3313380"
  },
  {
    "text": "and now I need to\nlook at the inverse of the matrix over there. So it's gx transpose x\ninverse g inverse g beta",
    "start": "3313380",
    "end": "3329950"
  },
  {
    "text": "hat minus lambda. ",
    "start": "3329950",
    "end": "3335647"
  },
  {
    "text": "This guy is going to follow--  well, here, I need to actually\ndivide by sigma in this case--",
    "start": "3335647",
    "end": "3342890"
  },
  {
    "start": "3342891",
    "end": "3356540"
  },
  {
    "text": "if g is k times p. So what I mean here is\njust that's the same k.",
    "start": "3356540",
    "end": "3364370"
  },
  {
    "text": "The k that shows up is\nthe number of constraints that I have in my tests. ",
    "start": "3364370",
    "end": "3373340"
  },
  {
    "text": "So now, if I go from\nhere to using sigma hat,",
    "start": "3373340",
    "end": "3380690"
  },
  {
    "text": "the key thing to observe is\nthat this guy is actually not a Gaussian. I'm not going to have a student\nt-distribution that shows up.",
    "start": "3380690",
    "end": "3388410"
  },
  {
    "start": "3388410",
    "end": "3396289"
  },
  {
    "text": "So that implies that if\nI take the same thing,",
    "start": "3396290",
    "end": "3423850"
  },
  {
    "text": "so now I just go from\nsigma to sigma hat, then this thing is of the form-- ",
    "start": "3423850",
    "end": "3432619"
  },
  {
    "text": "well, this chi squared k divided\nby the chi squared that shows up in the denominator\nof the t-distribution,",
    "start": "3432620",
    "end": "3440590"
  },
  {
    "text": "which is square root of--",
    "start": "3440590",
    "end": "3448270"
  },
  {
    "text": "oh, I should not\ndivide by sigma-- so this is sigma squared, right? AUDIENCE: Yeah. PHILIPPE RIGOLLET: So\nthis is sigma squared.",
    "start": "3448270",
    "end": "3454400"
  },
  {
    "text": "So this is of the form\ndivided by chi squared n",
    "start": "3454400",
    "end": "3460549"
  },
  {
    "text": "minus p divided by n minus p. So that's the same denominator\nthat I saw in my t-test.",
    "start": "3460550",
    "end": "3468369"
  },
  {
    "text": "The numerator has\nchanged, though. The numerator is now this\nchi squared and no longer a Gaussian. ",
    "start": "3468370",
    "end": "3475430"
  },
  {
    "text": "But this distribution is\nactually pivotal, as long as we can guarantee\nthat there's no hidden",
    "start": "3475430",
    "end": "3482210"
  },
  {
    "text": "parameter in the correlation\nbetween the two chi squares.",
    "start": "3482210",
    "end": "3488550"
  },
  {
    "text": "So again, as all statements\nof independence in this class, I will just give\nit to you for free.",
    "start": "3488550",
    "end": "3495930"
  },
  {
    "text": "Those two things, I claim-- so OK, let's say admit\nthese are independent.",
    "start": "3495930",
    "end": "3509635"
  },
  {
    "start": "3509635",
    "end": "3517370"
  },
  {
    "text": "We're almost there. This could be a\ndistribution that's pivotal. But there's something that's\na little unbalanced with it",
    "start": "3517370",
    "end": "3523960"
  },
  {
    "text": "is that this guy is divided\nby its number of degrees of freedom, but this guy is\nnot divided by its number",
    "start": "3523960",
    "end": "3528980"
  },
  {
    "text": "of degrees of freedom. And so we just have\nto make the extra step that if I divide this guy by k,\nand this guy is a chi squared",
    "start": "3528980",
    "end": "3537280"
  },
  {
    "text": "divided by k, if I\ndivide this guy by k, then I get this\nguy divided by k.",
    "start": "3537280",
    "end": "3543900"
  },
  {
    "text": "And now it looks-- I mean, it doesn't\nchange anything. I've just divided\nby a fixed number.",
    "start": "3543900",
    "end": "3549020"
  },
  {
    "text": "But it just looks more elegant-- is the ratio of\ntwo independent chi squared that are\nindividually divided",
    "start": "3549020",
    "end": "3555420"
  },
  {
    "text": "by the number of\ndegrees of freedom. ",
    "start": "3555420",
    "end": "3560839"
  },
  {
    "text": "And this has a name,\nand it's called a Fisher",
    "start": "3560840",
    "end": "3571100"
  },
  {
    "text": "or F-distribution. So unlike William\nGosset, who was not",
    "start": "3571100",
    "end": "3580740"
  },
  {
    "text": "allowed to use his own name\nand used the name student, Fisher was allowed\nto use his own name, and that's called the\nFisher distribution.",
    "start": "3580740",
    "end": "3587220"
  },
  {
    "text": "And the Fisher distribution\nhas now 2 parameters,",
    "start": "3587220",
    "end": "3592470"
  },
  {
    "text": "a set of 2 degrees of freedom-- 1 for the numerator and\n1 for the denominator. So F- of Fisher distribution--",
    "start": "3592470",
    "end": "3601217"
  },
  {
    "start": "3601217",
    "end": "3607430"
  },
  {
    "text": "so F is equal to the\nratio of a chi squared p/p",
    "start": "3607430",
    "end": "3613450"
  },
  {
    "text": "and a chi squared q/q. So that's Fpq P-q where the 2\nchi squareds are independent.",
    "start": "3613450",
    "end": "3627320"
  },
  {
    "start": "3627320",
    "end": "3632970"
  },
  {
    "text": "Is that clear what\nI'm defining here? So this is basically what plays\nthe role of t-distributions",
    "start": "3632970",
    "end": "3641460"
  },
  {
    "text": "when you're testing more\nthan 1 parameter at a time. So you basically replace-- the normal that was\nin the numerator,",
    "start": "3641460",
    "end": "3647190"
  },
  {
    "text": "you replace it by chi\nsquared because you're testing if 2 vectors are\nsimultaneously close. And the way you do it is by\nlooking at their squared norm.",
    "start": "3647190",
    "end": "3655340"
  },
  {
    "text": "And that's how the\nchi squared shows up. ",
    "start": "3655340",
    "end": "3660632"
  },
  {
    "text": "Quick remark-- are those\nthings really very different?",
    "start": "3660632",
    "end": "3668240"
  },
  {
    "text": "How can I relate a chi\nsquared with a t-distribution? Well, if t follows, say, a t--",
    "start": "3668240",
    "end": "3679151"
  },
  {
    "text": "I don't know, let's call it q.  So that means that\nt, let me look at--",
    "start": "3679151",
    "end": "3688330"
  },
  {
    "text": "t is some n01 divided by\nthe square root of a chi",
    "start": "3688330",
    "end": "3698200"
  },
  {
    "text": "squared q/q. ",
    "start": "3698200",
    "end": "3704819"
  },
  {
    "text": "That's the distribution of t. So if I look at the square of\nthe-- the distribution of t",
    "start": "3704820",
    "end": "3711300"
  },
  {
    "text": "squared-- let me put it here-- ",
    "start": "3711300",
    "end": "3718300"
  },
  {
    "text": "well, that's the square of some\nn01 divided by chi squared q/q.",
    "start": "3718300",
    "end": "3726280"
  },
  {
    "text": " Agreed?",
    "start": "3726280",
    "end": "3731900"
  },
  {
    "text": "I just removed the\nsquare root here, and I took the square\nof the Gaussian. But what is the distribution\nof a square of a Gaussian?",
    "start": "3731900",
    "end": "3740030"
  },
  {
    "text": "AUDIENCE: Chi squared\nwith 1 degree. PHILIPPE RIGOLLET: Chi squared\nwith 1 degree of freedom.",
    "start": "3740030",
    "end": "3745140"
  },
  {
    "text": "So this is a chi squared\nwith 1 degree of freedom. And in particular,\nit's also a chi squared with 1 degree\nof freedom divided by 1.",
    "start": "3745140",
    "end": "3751836"
  },
  {
    "text": "So t-squared, in the end,\nhas an F-distribution with 1",
    "start": "3751836",
    "end": "3758859"
  },
  {
    "text": "and q degrees of freedom. So those two things are\nactually very similar. The only thing that's\ngoing to change",
    "start": "3758860",
    "end": "3765130"
  },
  {
    "text": "is that, since we're actually\nlooking at, typically, absolute values of t\nwhen we do our tests,",
    "start": "3765130",
    "end": "3771164"
  },
  {
    "text": "it's going to be\nexactly the same thing. These quintiles of\none guy are going to be, essentially, the\nsquare root of the quintiles",
    "start": "3771164",
    "end": "3776496"
  },
  {
    "text": "of the other guy. That's all it's going to be. So if my test is psi is\nequal to the indicator",
    "start": "3776496",
    "end": "3787359"
  },
  {
    "text": "that t exceeds q alpha\nover 2 of tq, for example,",
    "start": "3787360",
    "end": "3796010"
  },
  {
    "text": "then it's equal to the\nindicator that t-squared exceeds q squared\nalpha over 2 tq,",
    "start": "3796010",
    "end": "3806030"
  },
  {
    "text": "because I had the\nabsolute value here, which is equal to the\nindicator that t squared is",
    "start": "3806030",
    "end": "3813110"
  },
  {
    "text": "greater than q alpha over 2. And now this time, it's an F1q. ",
    "start": "3813110",
    "end": "3819880"
  },
  {
    "text": "So in a way, those two things\nbelong to the same family. They really are a natural\ngeneralization of each other. I mean, at least the F-test is\na generalization of the t-test.",
    "start": "3819880",
    "end": "3827309"
  },
  {
    "text": " And so now I can perform my test\njust like it's written here.",
    "start": "3827310",
    "end": "3834480"
  },
  {
    "text": "I just formed this\nguy, and then I perform against the\nquintile of an F-test. Notice, there's no\nabsolute value--",
    "start": "3834480",
    "end": "3841440"
  },
  {
    "text": "oh, yeah, I forgot,\nthis is actually q alpha because the F-statistic\nis already positive.",
    "start": "3841440",
    "end": "3849761"
  },
  {
    "text": "So I'm not going to look\nbetween left and right, I'm just going to look\nwhether it's too large or not.",
    "start": "3849761",
    "end": "3855240"
  },
  {
    "text": "So that's by definition. So you can check-- if you look at a\ntable for student",
    "start": "3855240",
    "end": "3861119"
  },
  {
    "text": "and you look at a\ntable for F1q, one it just going to-- you're going\nto have to move from one column to the other\nbecause you're going",
    "start": "3861120",
    "end": "3866609"
  },
  {
    "text": "to have to move from\nalpha over 2 to alpha, but one is going to be\nsquared root of the other one,",
    "start": "3866610",
    "end": "3871670"
  },
  {
    "text": "just like the chi squared is\nthe square of the Gaussian. I mean, if you look at the chi\nsquared 1 degree of freedom,",
    "start": "3871670",
    "end": "3876828"
  },
  {
    "text": "you will see the same\nthing as the Gaussians. ",
    "start": "3876828",
    "end": "3887035"
  },
  {
    "text": "So I'm actually going to\nstart with the last one",
    "start": "3887035",
    "end": "3893594"
  },
  {
    "text": "because you've been asking\na few questions about why is my design deterministic. So there's many answers.",
    "start": "3893594",
    "end": "3899660"
  },
  {
    "text": "Some are philosophical. But one that's actually--\nwell, there's the one that says everything you cannot do if\nyou don't have a condition--",
    "start": "3899660",
    "end": "3907106"
  },
  {
    "text": "if you don't have x, because all\nof the statements that we made here, for example, just the\nfact that this is chi squared,",
    "start": "3907106",
    "end": "3912850"
  },
  {
    "text": "if those guys start to\nbe random variables, then it's clearly not\ngoing to be a chi squared. I mean, it cannot be chi\nsquared when those guys are",
    "start": "3912850",
    "end": "3919000"
  },
  {
    "text": "deterministic and\nwhen they are random. I mean, things change. So that's just maybe\n[INAUDIBLE] check statement.",
    "start": "3919000",
    "end": "3925060"
  },
  {
    "text": "But I think the one that\nreally matters is that-- remember when we\ndid the t-test, we",
    "start": "3925060",
    "end": "3930450"
  },
  {
    "text": "had this gamma j that showed up. Gamma j was playing the\nrole of the variance. So here, the variance,\nyou never think of--",
    "start": "3930450",
    "end": "3936903"
  },
  {
    "text": "I mean, we'll talk about\nthis in the Bayesian setup, but so far, we haven't\nthought of the variance as a random variable.",
    "start": "3936904",
    "end": "3942390"
  },
  {
    "text": "And so here, your x's really\nare the parameters of your data. And the diagonal elements\nof x transpose x inverse",
    "start": "3942390",
    "end": "3948110"
  },
  {
    "text": "actually tell you\nwhat the variance is. So that's also one reason why\nyou should think of your x as being a deterministic number.",
    "start": "3948110",
    "end": "3953530"
  },
  {
    "text": "They are, in a way,\nthings that change the geometry of your problem. They just say, oh,\nlet me look at it from the perspective of x.",
    "start": "3953530",
    "end": "3961180"
  },
  {
    "text": "Actually, for that\nmatter, we didn't really spend much time\ncommenting on what is the effect of x onto gamma.",
    "start": "3961180",
    "end": "3969730"
  },
  {
    "text": "So remember, gamma j, so that\nwas the variance parameter.",
    "start": "3969730",
    "end": "3979910"
  },
  {
    "text": "So we should try to understand\nwhat x's lead to big variance and what x's lead\nto small variance.",
    "start": "3979910",
    "end": "3986030"
  },
  {
    "text": "That would be nice. Well, if this is the\nidentity matrix--",
    "start": "3986030",
    "end": "3991550"
  },
  {
    "text": "let's say identity over n,\nwhich is the natural thing to look at, because we want\nthis thing to scale like 1/n--",
    "start": "3991550",
    "end": "3998619"
  },
  {
    "text": "then this is just 1/n. We're back to the original case. Yes? AUDIENCE: Shouldn't\nthat be inverse? PHILIPPE RIGOLLET: Yeah,\nthank you. x inverse, yes.",
    "start": "3998620",
    "end": "4005500"
  },
  {
    "text": "So if this is the identity,\nthen, well, the inverse is-- let's say just this guy\nhere is n times this guy.",
    "start": "4005500",
    "end": "4013180"
  },
  {
    "text": "So then the inverse is 1/n. So in this case, that means\nthat gamma j is equal to 1/n",
    "start": "4013180",
    "end": "4019270"
  },
  {
    "text": "and we're back to\nthe theta hat theta case, the basic\none-dimensional thing.",
    "start": "4019270",
    "end": "4026450"
  },
  {
    "text": "What does it mean for a\nmatrix for when I take its-- yeah, so that's of dimension p.",
    "start": "4026450",
    "end": "4033230"
  },
  {
    "text": "But when I take its transpose-- so forget about the\nscaling by n right now. This is just a matter\nof scaling things.",
    "start": "4033230",
    "end": "4039060"
  },
  {
    "text": "I can always multiply\nmy x's so that I have this thing that shows up. But when I have a matrix,\nif I look at x transpose x",
    "start": "4039060",
    "end": "4044750"
  },
  {
    "text": "and I get something which\nis the identity, how do I call this matrix? ",
    "start": "4044750",
    "end": "4051980"
  },
  {
    "text": "AUDIENCE: Orthonormal? PHILIPPE RIGOLLET:\nOrthogonal, yeah. Orthonormal or orthogonal. So you call this thing\nan orthogonal matrix.",
    "start": "4051980",
    "end": "4057919"
  },
  {
    "text": "And when it's an orthogonal\nmatrix, what it means is that the-- so this matrix here, if you\nlook at the matrix xx transpose,",
    "start": "4057919",
    "end": "4066230"
  },
  {
    "text": "the entries of this matrix\nare the inner products between the columns of x. That's what's happening.",
    "start": "4066230",
    "end": "4071240"
  },
  {
    "text": "You can write it,\nand you will see that the entries of this\nmatrix are linear products. If it's the identity, that\nmeans that you get some 1's",
    "start": "4071240",
    "end": "4079859"
  },
  {
    "text": "and a bunch of 0's, it means\nthat all the inner products between 2 different\ncolumns is actually 0.",
    "start": "4079860",
    "end": "4085910"
  },
  {
    "text": "What it means is\nthat this matrix x is an orthonormal\nbasis for your space. The columns form an\northonormal basis.",
    "start": "4085910",
    "end": "4092100"
  },
  {
    "text": "So they're basically as far\nfrom each other as they can. Now, if I start making those\nguys closer and closer,",
    "start": "4092100",
    "end": "4100259"
  },
  {
    "text": "then I'm starting\nto have some issues. x transpose x is not\ngoing to be the identity. I'm going to start to\nhave some non-0 entries.",
    "start": "4100260",
    "end": "4107330"
  },
  {
    "text": "But if they all remain\nof norm 1, then--",
    "start": "4107330",
    "end": "4112550"
  },
  {
    "text": "oh, sorry, so that's\nfor the inverse. So I first start putting some\nstuff here, which is non-0,",
    "start": "4112551",
    "end": "4117899"
  },
  {
    "text": "by taking my x's. Rather than having\nthis, I move to this.",
    "start": "4117899",
    "end": "4124269"
  },
  {
    "text": "Now I'm going to start\nseeing some non-0 entries. And when I'm going to take\nthe inverse of this matrix,",
    "start": "4124269",
    "end": "4129410"
  },
  {
    "text": "the diagonal elements are\ngoing to start to blow up. Oh, sorry, the diagonals start\nto become smaller and smaller.",
    "start": "4129410",
    "end": "4136009"
  },
  {
    "text": "So when I take the inverse-- no, sorry, the diagonal\nlimits are going to blow up.",
    "start": "4136010",
    "end": "4141399"
  },
  {
    "text": "And so what it means is that the\nvariance is going to blow up. And that's essentially\ntelling you",
    "start": "4141399",
    "end": "4146899"
  },
  {
    "text": "that if you get to\nchoose your x's, you want to take them as\northogonal as you can.",
    "start": "4146899",
    "end": "4152582"
  },
  {
    "text": "But if you don't, then you\njust have to deal with it, and it will have a significant\nimpact on your estimation",
    "start": "4152582",
    "end": "4158950"
  },
  {
    "text": "performance. And that's what, also,\nroutinely, statistical software",
    "start": "4158950",
    "end": "4165009"
  },
  {
    "text": "is going to spit out\nthis value here for you. And you're going to have--\nwell, actually square root of this value.",
    "start": "4165010",
    "end": "4170409"
  },
  {
    "text": "And it's going to tell\nyou, essentially-- you're going to know how much\nrandomness, how much variation you have in this\nparticular parameter",
    "start": "4170410",
    "end": "4176952"
  },
  {
    "text": "that you're estimating. So if gamma j is\nlarge, then you're going to have wide\nconfidence intervals",
    "start": "4176952",
    "end": "4183189"
  },
  {
    "text": "and your tests are not\ngoing to reject very much. And that's all captured by x. That's what's important. Everything, all of this, is\ncompletely captured by x.",
    "start": "4183189",
    "end": "4190926"
  },
  {
    "text": "Then, of course, there\nwas the sigma squared that showed up here. Actually, it was here, even\nin the definition of gamma j.",
    "start": "4190927",
    "end": "4197155"
  },
  {
    "text": "I forgot it. What is the sigma\nsquared police doing? And so this thing\nwas here as well,",
    "start": "4197155",
    "end": "4202949"
  },
  {
    "text": "and that's just exogenous. It comes from the noise itself. But there was this huge factor\nthat came from the x's itself.",
    "start": "4202950",
    "end": "4208810"
  },
  {
    "text": " So let's go back,\nnow, to reading",
    "start": "4208810",
    "end": "4213960"
  },
  {
    "text": "this list in a linear fashion. So I mean, you're MIT\nstudents, you've probably",
    "start": "4213960",
    "end": "4220679"
  },
  {
    "text": "heard that correlation does\nnot imply causation many times. Maybe you don't\nknow what it means.",
    "start": "4220680",
    "end": "4227145"
  },
  {
    "text": "If you don't, that's OK, you\njust have to know the sentence. No, what it means\nis that it's done",
    "start": "4227145",
    "end": "4232420"
  },
  {
    "text": "because I decided that\nsomething was going to be the x and that something\nelse was going to be the y, that whatever\nthing I'm getting,",
    "start": "4232420",
    "end": "4239639"
  },
  {
    "text": "it means that x implies y. For example, even if I\ndo genetics, genomics, or whatever, I\nmean, I implicitly",
    "start": "4239640",
    "end": "4247230"
  },
  {
    "text": "assume that my genes\nare going to have an effect on my outside look.",
    "start": "4247230",
    "end": "4252780"
  },
  {
    "text": "I could be the opposite. I mean, who am I to say? I'm not a biologist. I don't know. I didn't open a biology\nbook in 20 years.",
    "start": "4252780",
    "end": "4259590"
  },
  {
    "text": "So maybe, if I start hitting\nmy head with a hammer, I'm going to have changing\nmy genetic material.",
    "start": "4259590",
    "end": "4264720"
  },
  {
    "text": "Probably not, but that's why-- but causation definitely does\nnot come from statistics. So if you know that that's\nthe different thing,",
    "start": "4264720",
    "end": "4271690"
  },
  {
    "text": "it's actually going to-- it's not coming from there. So actually, I remember, once,\nI put an exam to students,",
    "start": "4271690",
    "end": "4278410"
  },
  {
    "text": "and there was an old data\nset from police expenditures, I think, in Chicago in the '60s.",
    "start": "4278410",
    "end": "4283920"
  },
  {
    "text": "And they were trying\nto understand-- no, it was on crime. It was the crime data set.",
    "start": "4283920",
    "end": "4289650"
  },
  {
    "text": "And they were trying-- so\nthe y variable was just the rate of crime, and the\nx's were a bunch of things, and one of them was\npolice expenditures.",
    "start": "4289650",
    "end": "4296670"
  },
  {
    "text": "And if you rend\nthe regression, you would find that the coefficient\nin front of police expenditure was a positive\nnumber, which means",
    "start": "4296670",
    "end": "4302699"
  },
  {
    "text": "that if you increase\npolice expenditures, that increases the crime.",
    "start": "4302700",
    "end": "4308400"
  },
  {
    "text": "I mean, that's what it means\nto have a positive coefficient. Everybody agrees with this fact?",
    "start": "4308400",
    "end": "4315409"
  },
  {
    "text": "If beta j is 10, then it\nmeans that if I increase by $1 my police expenditure, I\n[INAUDIBLE] by 10 my crime,",
    "start": "4315410",
    "end": "4321860"
  },
  {
    "text": "everything else\nbeing kept equal. Well, there were,\nI think, about 80% of the students that were able\nto explain to me that if you",
    "start": "4321860",
    "end": "4329230"
  },
  {
    "text": "give more money to\nthe police, then the crime is going to raise. Some people were\nlike, well, police",
    "start": "4329230",
    "end": "4334780"
  },
  {
    "text": "is making too much\nmoney, and they don't think about their\nwork, and they become lazy. And I mean, people\nwere really coming up",
    "start": "4334780",
    "end": "4340930"
  },
  {
    "text": "with some crazy things. And what it just meant is\nthat, no, it's not causation.",
    "start": "4340930",
    "end": "4346090"
  },
  {
    "text": "It's just, if you\nhave more crime, you give more money\nto your police. That's what's happening.",
    "start": "4346090",
    "end": "4351370"
  },
  {
    "text": "And that's all there is. So just be careful\nwhen you actually draw some conclusions that\ncausation is a very important",
    "start": "4351370",
    "end": "4358360"
  },
  {
    "text": "thing to keep in mind. And in practice, unless you\nhave external sources of reason for causality-- for\nexample, genetic material",
    "start": "4358360",
    "end": "4365679"
  },
  {
    "text": "and physical traits,\nwe agree upon what",
    "start": "4365680",
    "end": "4372040"
  },
  {
    "text": "the direction of the arrow\nof causality is here. There's places\nwhere you might not.",
    "start": "4372040",
    "end": "4377844"
  },
  {
    "text": "Now, finally, the\nnormality on the noise-- everything we did today required\nnormal Gaussian distribution",
    "start": "4377845",
    "end": "4384340"
  },
  {
    "text": "on the noise. I mean, it's everywhere. There's some Gaussian,\nthere's some chi squared.",
    "start": "4384340",
    "end": "4389540"
  },
  {
    "text": "Everything came out of Gaussian. And for that, we needed\nthis basic formula for inference, which we\nderived from the fact",
    "start": "4389540",
    "end": "4395710"
  },
  {
    "text": "that the noise was\nGaussian itself. If we did not have that, the\nonly thing we could write",
    "start": "4395710",
    "end": "4400860"
  },
  {
    "text": "is, beta hat is this\nnumber, or this vector. We would not be able to say,\nthe fluctuations of beta hat",
    "start": "4400860",
    "end": "4407980"
  },
  {
    "text": "are this guy. We would not be\nable to do tests. We would not be\nable to build, say, confidence regions or anything.",
    "start": "4407980",
    "end": "4414160"
  },
  {
    "text": "And so this is an important\ncondition that we need, and that's what statistical\nsoftware assumes by default.",
    "start": "4414160",
    "end": "4420670"
  },
  {
    "text": "But we now have a recipe\non how to do those tests. We can do it either\nvisually, if we really",
    "start": "4420670",
    "end": "4427060"
  },
  {
    "text": "want to conclude that,\nyes, this is Gaussian, using our normal Q-Q plots. And we can also do it\nusing our favorite tests.",
    "start": "4427060",
    "end": "4434860"
  },
  {
    "text": "What test should I be\nusing to test that? ",
    "start": "4434860",
    "end": "4441540"
  },
  {
    "text": "With two names? Yeah? AUDIENCE: Normal [INAUDIBLE].",
    "start": "4441540",
    "end": "4446957"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nNot the 2 Russians. So I want a Russian and\na Scandinavian person for this one.",
    "start": "4446957",
    "end": "4452721"
  },
  {
    "text": "What's that? AUDIENCE: Lillie-something? PHILIPPE RIGOLLET:\nYeah, Lillie-something. So Kolmogorov\nLillie-something test.",
    "start": "4452722",
    "end": "4458660"
  },
  {
    "text": "And [LAUGHS] so it's the\nKolmogorov Lilliefors test. And because I'm testing if\nthere Gaussian, and I'm actually",
    "start": "4458660",
    "end": "4466670"
  },
  {
    "text": "not really making any-- I don't need to know\nwhat the variance is. The mean is 0. We saw that at the beginning.",
    "start": "4466670",
    "end": "4472558"
  },
  {
    "text": "It's 0 by construction,\nso we actually don't need to think about\nthe mean being 0 itself.",
    "start": "4472558",
    "end": "4477590"
  },
  {
    "text": "This just happens to be 0. So we know that it's 0, but\nthe variance, we don't know. So we just want to\nknow if it belongs",
    "start": "4477590",
    "end": "4482900"
  },
  {
    "text": "to the family of Gaussians,\nand so we need to Kolmogorov Lilliefors for that. And that's also one of the thing\nthat's spit out by statistical",
    "start": "4482900",
    "end": "4489650"
  },
  {
    "text": "software by default. When\nyou run a linear regression, actually, it spits out\nboth Kolmogorov-Smirnov",
    "start": "4489650",
    "end": "4494670"
  },
  {
    "text": "and Kolmogorov Lilliefors,\nprobably contributing to the widespread use of\nKolmogorov-Smirnov when you",
    "start": "4494670",
    "end": "4501860"
  },
  {
    "text": "really shouldn't. So next time, we will talk\nabout more advanced topics",
    "start": "4501860",
    "end": "4508920"
  },
  {
    "text": "on regression. But I think I'm going\nto stop here for today. So again, tomorrow,\nsometime during the day,",
    "start": "4508920",
    "end": "4514739"
  },
  {
    "text": "at least before\nthe recitation, you will have a list of practice\nexercises that will be posted.",
    "start": "4514740",
    "end": "4520739"
  },
  {
    "text": "And if you go to the\noptional recitation, you will have\nsomeone solving them",
    "start": "4520740",
    "end": "4526190"
  },
  {
    "start": "4526190",
    "end": "4528238"
  }
]
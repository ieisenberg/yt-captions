[
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "790",
    "end": "6760"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6760",
    "end": "13390"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13390",
    "end": "18570"
  },
  {
    "text": "ERIC GRIMSON: OK. Welcome back. You know, it's that\ntime a term when",
    "start": "30932",
    "end": "36040"
  },
  {
    "text": "we're all kind of doing this. So let me see if I can get a few\nsmiles by simply noting to you",
    "start": "36040",
    "end": "41980"
  },
  {
    "text": "that two weeks from\ntoday is the last class. Should be worth at least a\nlittle bit of a smile, right?",
    "start": "41980",
    "end": "48050"
  },
  {
    "text": "Professor Guttag is smiling. He likes that idea. You're almost there.",
    "start": "48050",
    "end": "53829"
  },
  {
    "text": "What are we doing for the\nlast couple of lectures? We're talking about\nlinear regression. And I just want to\nremind you, this",
    "start": "53830",
    "end": "59910"
  },
  {
    "text": "was the idea of I have\nsome experimental data. Case of a spring where I put\ndifferent weights on measure",
    "start": "59910",
    "end": "66360"
  },
  {
    "text": "displacements. And regression was giving\nus a way of deducing a model",
    "start": "66360",
    "end": "71640"
  },
  {
    "text": "to fit that data. And In some cases it was easy. We knew, for example, it was\ngoing to be a linear model.",
    "start": "71640",
    "end": "77280"
  },
  {
    "text": "We found the best line\nthat would fit that data. In some cases, we said\nwe could use validation to actually let us explore\nto find the best model that",
    "start": "77280",
    "end": "84960"
  },
  {
    "text": "would fit it, whether a\nlinear, a quadratic, a cubic, some higher order thing.",
    "start": "84960",
    "end": "91500"
  },
  {
    "text": "So we'll be using that to\ndeduce something about a model. That's a nice segue into\nthe topic for the next three",
    "start": "91500",
    "end": "99799"
  },
  {
    "text": "lectures, the last big\ntopic of the class, which is machine learning. And I'm going to argue, you can\ndebate whether that's actually",
    "start": "99800",
    "end": "106480"
  },
  {
    "text": "an example of learning. But it has many of\nthe elements that we want to talk about when we\ntalk about machine learning.",
    "start": "106480",
    "end": "112700"
  },
  {
    "text": "So as always, there's\na reading assignment. Chapter 22 of the book gives\nyou a good start on this, and it will follow\nup with other pieces.",
    "start": "112700",
    "end": "120160"
  },
  {
    "text": "And I want to start\nby basically outlining what we're going to do. And I'm going to\nbegin by saying,",
    "start": "120160",
    "end": "125404"
  },
  {
    "text": "as I'm sure you're aware,\nthis is a huge topic. I've listed just five\nsubjects in course six",
    "start": "125404",
    "end": "132760"
  },
  {
    "text": "that all focus on\nmachine learning. And that doesn't\ninclude other subjects where learning is\na central part.",
    "start": "132760",
    "end": "139030"
  },
  {
    "text": "So natural language processing,\ncomputational biology, computer vision\nrobotics all rely today,",
    "start": "139030",
    "end": "145390"
  },
  {
    "text": "heavily on machine learning. And you'll see those in\nthose subjects as well. So we're not going to\ncompress five subjects",
    "start": "145390",
    "end": "152560"
  },
  {
    "text": "into three lectures. But what we are going to do\nis give you the introduction. We're going to start by talking\nabout the basic concepts",
    "start": "152560",
    "end": "159580"
  },
  {
    "text": "of machine learning. The idea of having examples, and\nhow do you talk about features representing those\nexamples, how do",
    "start": "159580",
    "end": "165610"
  },
  {
    "text": "you measure distances\nbetween them, and use the notion\nof distance to try and group similar\nthings together as a way",
    "start": "165610",
    "end": "172210"
  },
  {
    "text": "of doing machine learning. And we're going to\nlook, as a consequence, of two different standard\nways of doing learning.",
    "start": "172210",
    "end": "179530"
  },
  {
    "text": "One, we call\nclassification methods. Example we're\ngoing to see, there is something called\n\"k nearest neighbor\"",
    "start": "179530",
    "end": "185109"
  },
  {
    "text": "and the second class,\ncalled clustering methods. Classification works\nwell when I have what",
    "start": "185110",
    "end": "190750"
  },
  {
    "text": "we would call labeled data. I know labels on my\nexamples, and I'm going to use that to\ntry and define classes",
    "start": "190750",
    "end": "197200"
  },
  {
    "text": "that I can learn, and\nclustering working well, when I don't have labeled data. And we'll see what that\nmeans in a couple of minutes.",
    "start": "197200",
    "end": "203137"
  },
  {
    "text": "But we're going to give\nyou an early view of this. Unless Professor Guttag\nchanges his mind,",
    "start": "203138",
    "end": "209360"
  },
  {
    "text": "we're probably not going to\nshow you the current really sophisticated machine\nlearning methods like convolutional neural\nnets or deep learning,",
    "start": "209360",
    "end": "215870"
  },
  {
    "text": "things you'll read\nabout in the news. But you're going to\nget a sense of what's behind those, by looking\nat what we do when we talk about learning algorithms.",
    "start": "215870",
    "end": "223890"
  },
  {
    "text": "Before I do it, I want\nto point out to you just how prevalent this is. And I'm going to admit\nwith my gray hair,",
    "start": "223890",
    "end": "229870"
  },
  {
    "text": "I started working in AI in\n1975 when machine learning was a pretty simple thing to do.",
    "start": "229870",
    "end": "235030"
  },
  {
    "text": "And it's been\nfascinating to watch over 40 years, the change. And if you think about it, just\nthink about where you see it.",
    "start": "235030",
    "end": "241549"
  },
  {
    "text": "AlphaGo, machine learning based\nsystem from Google that beat",
    "start": "241550",
    "end": "246730"
  },
  {
    "text": "a world-class level Go player. Chess has already been conquered\nby computers for a while.",
    "start": "246730",
    "end": "251980"
  },
  {
    "text": "Go now belongs to computers. Best Go players in the\nworld are computers. I'm sure many of\nyou use Netflix.",
    "start": "251980",
    "end": "258518"
  },
  {
    "text": "Any recommendation\nsystem, Netflix, Amazon, pick your favorite, uses\na machine learning algorithm",
    "start": "258519",
    "end": "263770"
  },
  {
    "text": "to suggest things for you. And in fact, you've probably\nseen it on Google, right? The ads that pop\nup on Google are",
    "start": "263770",
    "end": "269560"
  },
  {
    "text": "coming from a machine\nlearning algorithm that's looking at your preferences. Scary thought.",
    "start": "269560",
    "end": "274900"
  },
  {
    "text": "Drug discovery, character\nrecognition-- the post office does character recognition of\nhandwritten characters using",
    "start": "274900",
    "end": "281975"
  },
  {
    "text": "a machine learning algorithm\nand a computer vision system behind it. You probably don't\nknow this company.",
    "start": "281975",
    "end": "288189"
  },
  {
    "text": "It's actually an MIT\nspin-off called Two Sigma, it's a hedge fund in New York. They heavily use AI and\nmachine learning techniques.",
    "start": "288190",
    "end": "294970"
  },
  {
    "text": "And two years ago, their\nfund returned a 56% return.",
    "start": "294970",
    "end": "301947"
  },
  {
    "text": "I wish I'd invested in the fund. I don't have the kinds\nof millions you need, but that's an impressive return. 56% return on your\nmoney in one year.",
    "start": "301947",
    "end": "309546"
  },
  {
    "text": "Last year they didn't\ndo quite as well, but they do extremely well using\nmachine learning techniques. Siri.",
    "start": "309546",
    "end": "316550"
  },
  {
    "text": "Another great MIT\ncompany called Mobileye that does computer vision\nsystems with a heavy machine learning component that is\nused in assistive driving",
    "start": "316550",
    "end": "324080"
  },
  {
    "text": "and will be used in\ncompletely autonomous driving. It will do things like\nkick in your brakes if you're closing too fast\non the car in front of you,",
    "start": "324080",
    "end": "332067"
  },
  {
    "text": "which is going to\nbe really bad for me because I drive\nlike a Bostonian. And it would be\nkicking in constantly.",
    "start": "332067",
    "end": "338030"
  },
  {
    "text": "Face recognition. Facebook uses this,\nmany other systems do to both detect\nand recognize faces.",
    "start": "338030",
    "end": "346070"
  },
  {
    "text": "IBM Watson-- cancer diagnosis. These are all just\nexamples of machine learning being used everywhere.",
    "start": "346070",
    "end": "352820"
  },
  {
    "text": "And it really is. I've only picked nine. So what is it?",
    "start": "352820",
    "end": "360280"
  },
  {
    "text": "I'm going to make an\nobnoxious statement. You're now used to that. I'm going to claim\nthat you could argue that almost every computer\nprogram learns something.",
    "start": "360280",
    "end": "369420"
  },
  {
    "text": "But the level of learning\nreally varies a lot. So if you think back to\nthe first lecture in 60001,",
    "start": "369420",
    "end": "375150"
  },
  {
    "text": "we showed you Newton's method\nfor computing square roots. And you could argue,\nyou'd have to stretch it,",
    "start": "375150",
    "end": "380910"
  },
  {
    "text": "but you could argue\nthat that method learns something about how to\ncompute square roots. In fact, you could generalize\nit to roots of any order power.",
    "start": "380910",
    "end": "389986"
  },
  {
    "text": "But it really didn't learn. I really had to program it. All right. Think about last week when we\ntalked about linear regression.",
    "start": "389986",
    "end": "397500"
  },
  {
    "text": "Now it starts to feel\na little bit more like a learning algorithm. Because what did we do? We gave you a set\nof data points,",
    "start": "397500",
    "end": "404550"
  },
  {
    "text": "mass displacement data points. And then we showed you how\nthe computer could essentially",
    "start": "404550",
    "end": "409650"
  },
  {
    "text": "fit a curve to that data point. And it was, in some sense,\nlearning a model for that data",
    "start": "409650",
    "end": "416100"
  },
  {
    "text": "that it could then use\nto predict behavior. In other situations. And that's getting\ncloser to what",
    "start": "416100",
    "end": "421800"
  },
  {
    "text": "we would like when we\nthink about a machine learning algorithm. We'd like to have program that\ncan learn from experience,",
    "start": "421800",
    "end": "430460"
  },
  {
    "text": "something that it can then\nuse to deduce new facts. Now it's been a problem in\nAI for a very long time.",
    "start": "430460",
    "end": "436980"
  },
  {
    "text": "And I love this quote. It's from a gentleman\nnamed Art Samuel. 1959 is the quote\nin which he says,",
    "start": "436980",
    "end": "444794"
  },
  {
    "text": "his definition of\nmachine learning is the field of study\nthat gives computers the ability to learn without\nbeing explicitly programmed.",
    "start": "444794",
    "end": "452391"
  },
  {
    "text": "And I think many\npeople would argue, he wrote the first such program. It learned from experience.",
    "start": "452391",
    "end": "458710"
  },
  {
    "text": "In his case, it played checkers. Kind of shows you how\nthe field has progressed. But we started with checkers,\nwe got to chess, we now do Go.",
    "start": "458710",
    "end": "465610"
  },
  {
    "text": "But it played checkers. It beat national level\nplayers, most importantly, it learned to\nimprove its methods",
    "start": "465610",
    "end": "472569"
  },
  {
    "text": "by watching how it did in games\nand then inferring something to change what it thought\nabout as it did that.",
    "start": "472570",
    "end": "478492"
  },
  {
    "text": "Samuel did a bunch\nof other things. I just highlighted one. You may see in a\nfollow on course, he invented what's called\nAlpha-Beta Pruning, which",
    "start": "478492",
    "end": "484295"
  },
  {
    "text": "is a really useful\ntechnique for doing search. But the idea is, how can\nwe have the computer learn",
    "start": "484295",
    "end": "490389"
  },
  {
    "text": "without being\nexplicitly programmed? And one way to\nthink about this is to think about the difference\nbetween how we would normally",
    "start": "490390",
    "end": "497439"
  },
  {
    "text": "program and what we would\nlike from a machine learning algorithm. Normal programming, I\nknow you're not convinced",
    "start": "497440",
    "end": "503650"
  },
  {
    "text": "there's such a thing\nas normal programming, but if you think of\ntraditional programming, what's the process?",
    "start": "503650",
    "end": "510100"
  },
  {
    "text": "I write a program that\nI input to the computer so that it can then\ntake data and produce",
    "start": "510100",
    "end": "516339"
  },
  {
    "text": "some appropriate output. And the square root finder\nreally sits there, right? I wrote code for using Newton\nmethod to find a square root,",
    "start": "516340",
    "end": "523479"
  },
  {
    "text": "and then it gave me the\nprocess of given any number, I'll give you the square root.",
    "start": "523480",
    "end": "528250"
  },
  {
    "text": "But if you think about\nwhat we did last time, it was a little different. And in fact, in a machine\nlearning approach,",
    "start": "530800",
    "end": "536899"
  },
  {
    "text": "the idea is that I'm going\nto give the computer output. I'm going to give it examples of\nwhat I want the program to do,",
    "start": "536900",
    "end": "545920"
  },
  {
    "text": "labels on data,\ncharacterizations of different classes of things. And what I want\nthe computer to do",
    "start": "545920",
    "end": "551860"
  },
  {
    "text": "is, given that characterization\nof output and data, I wanted that machine\nlearning algorithm",
    "start": "551860",
    "end": "557500"
  },
  {
    "text": "to actually produce\nfor me a program, a program that I can\nthen use to infer",
    "start": "557500",
    "end": "563329"
  },
  {
    "text": "new information about things. And that creates, if you\nlike, a really nice loop",
    "start": "563330",
    "end": "569442"
  },
  {
    "text": "where I can have the\nmachine learning algorithm learn the program\nwhich I can then use to solve some other problem.",
    "start": "569442",
    "end": "576190"
  },
  {
    "text": "That would be really\ngreat if we could do it. And as I suggested, that\ncurve-fitting algorithm is a simple version of that.",
    "start": "576190",
    "end": "581870"
  },
  {
    "text": "It learned a model for the\ndata, which I could then use to label any other\ninstances of the data or predict what I would see in\nterms of spring displacement",
    "start": "581870",
    "end": "589670"
  },
  {
    "text": "as I changed the masses. So that's the kind of idea\nwe're going to explore.",
    "start": "589670",
    "end": "594850"
  },
  {
    "text": "If we want to learn\nthings, we could also ask, so how do you learn? And how should a computer learn?",
    "start": "594850",
    "end": "602537"
  },
  {
    "text": "Well, for you as a human, there\nare a couple of possibilities. This is the boring one. This is the old style\nway of doing it, right?",
    "start": "602537",
    "end": "608900"
  },
  {
    "text": "Memorize facts. Memorize as many facts as you\ncan and hope that we ask you on the final exam\ninstances of those facts,",
    "start": "608900",
    "end": "616190"
  },
  {
    "text": "as opposed to some other\nfacts you haven't memorized. This is, if you think way\nback to the first lecture,",
    "start": "616190",
    "end": "622579"
  },
  {
    "text": "an example of declarative\nknowledge, statements of truth. Memorize as many as you can.",
    "start": "622580",
    "end": "628370"
  },
  {
    "text": "Have Wikipedia in\nyour back pocket. Better way to learn is to\nbe able to infer, to deduce",
    "start": "628370",
    "end": "635279"
  },
  {
    "text": "new information from old. And if you think\nabout this, this gets closer to what we\ncalled imperative knowledge--",
    "start": "635280",
    "end": "642870"
  },
  {
    "text": "ways to deduce new things. Now, in the first\ncases, we built",
    "start": "642870",
    "end": "648100"
  },
  {
    "text": "that in when we wrote that\nprogram to do square roots. But what we'd like in\na learning algorithm",
    "start": "648100",
    "end": "653430"
  },
  {
    "text": "is to have much more like\nthat generalization idea. We're interested in\nextending our capabilities",
    "start": "653430",
    "end": "659880"
  },
  {
    "text": "to write programs that can\ninfer useful information from implicit\npatterns in the data.",
    "start": "659880",
    "end": "666030"
  },
  {
    "text": "So not something\nexplicitly built like that comparison of\nweights and displacements,",
    "start": "666030",
    "end": "671100"
  },
  {
    "text": "but actually implicit\npatterns in the data, and have the algorithm figure\nout what those patterns are,",
    "start": "671100",
    "end": "676740"
  },
  {
    "text": "and use those to\ngenerate a program you can use to infer new\ndata about objects,",
    "start": "676740",
    "end": "682170"
  },
  {
    "text": "about string\ndisplacements, whatever it is you're trying to do.",
    "start": "682170",
    "end": "687401"
  },
  {
    "text": "OK. So the idea then,\nthe basic paradigm that we're going\nto see, is we're",
    "start": "687401",
    "end": "692480"
  },
  {
    "text": "going to give the\nsystem some training data, some observations. We did that last time with\njust the spring displacements.",
    "start": "692480",
    "end": "701300"
  },
  {
    "text": "We're going to then\ntry and have a way to figure out, how do\nwe write code, how do we write a program, a system\nthat will infer something",
    "start": "701300",
    "end": "707510"
  },
  {
    "text": "about the process that\ngenerated the data? And then from\nthat, we want to be",
    "start": "707510",
    "end": "713269"
  },
  {
    "text": "able to use that to make\npredictions about things we haven't seen before. So again, I want to\ndrive home this point.",
    "start": "713269",
    "end": "719610"
  },
  {
    "text": "If you think about it, the\nspring example fit that model.",
    "start": "719610",
    "end": "724829"
  },
  {
    "text": "I gave you a set of\ndata, spatial deviations relative to mass displacements. For different masses, how\nfar did the spring move?",
    "start": "724830",
    "end": "732040"
  },
  {
    "text": "I then inferred something\nabout the underlying process. In the first case, I\nsaid I know it's linear,",
    "start": "732040",
    "end": "738660"
  },
  {
    "text": "but let me figure out what\nthe actual linear equation is. What's the spring constant\nassociated with it?",
    "start": "738660",
    "end": "744149"
  },
  {
    "text": "And based on that result,\nI got a piece of code I could use to predict\nnew displacements.",
    "start": "744150",
    "end": "750120"
  },
  {
    "text": "So it's got all of those\nelements, training data, an inference engine,\nand then the ability",
    "start": "750120",
    "end": "755190"
  },
  {
    "text": "to use that to make\nnew predictions. But that's a very simple\nkind of learning setting.",
    "start": "755190",
    "end": "760330"
  },
  {
    "text": "So the more common\none is one I'm going to use as\nan example, which is, when I give you\na set of examples,",
    "start": "760330",
    "end": "767210"
  },
  {
    "text": "those examples have some\ndata associated with them, some features and some labels.",
    "start": "767210",
    "end": "772329"
  },
  {
    "text": "For each example,\nI might say this is a particular kind of thing. This other one is\nanother kind of thing.",
    "start": "772330",
    "end": "778102"
  },
  {
    "text": "And what I want to\ndo is figure out how to do inference on\nlabeling new things. So it's not just, what's the\ndisplacement of the mass,",
    "start": "778102",
    "end": "784524"
  },
  {
    "text": "it's actually a label. And I'm going to use one\nof my favorite examples. I'm a big New\nEngland Patriots fan,",
    "start": "784524",
    "end": "789970"
  },
  {
    "text": "if you're not, my apologies. But I'm going to use\nfootball players. So I'm going to show\nyou in a second,",
    "start": "789970",
    "end": "795040"
  },
  {
    "text": "I'm going to give you a set of\nexamples of football players. The label is the\nposition they play.",
    "start": "795040",
    "end": "800222"
  },
  {
    "text": "And the data, well, it\ncould be lots of things. We're going to use\nheight and weight. But what we want\nto do is then see",
    "start": "800222",
    "end": "805660"
  },
  {
    "text": "how would we come up with\na way of characterizing the implicit pattern of how\ndoes weight and height predict",
    "start": "805660",
    "end": "812170"
  },
  {
    "text": "the kind of position\nthis player could play. And then come up\nwith an algorithm that will predict the\nposition of new players.",
    "start": "812170",
    "end": "818514"
  },
  {
    "text": "We'll do the draft\nfor next year. Where do we want them to play? That's the paradigm.",
    "start": "818515",
    "end": "824500"
  },
  {
    "text": "Set of observations, potentially\nlabeled, potentially not. Think about how do we do\ninference to find a model.",
    "start": "824500",
    "end": "831519"
  },
  {
    "text": "And then how do we use that\nmodel to make predictions. What we're going\nto see, and we're going to see multiple\nexamples today,",
    "start": "831520",
    "end": "837970"
  },
  {
    "text": "is that that\nlearning can be done in one of two very broad ways. The first one is called\nsupervised learning.",
    "start": "837970",
    "end": "845460"
  },
  {
    "text": "And in that case,\nfor every new example I give you as part\nof the training data, I have a label on it.",
    "start": "845460",
    "end": "851470"
  },
  {
    "text": "I know the kind of thing it is. And what I'm going\nto do is look for how do I find a rule that would\npredict the label associated",
    "start": "851470",
    "end": "858399"
  },
  {
    "text": "with unseen input based\non those examples. It's supervised because I\nknow what the labeling is.",
    "start": "858400",
    "end": "865010"
  },
  {
    "text": "Second kind, if\nthis is supervised, the obvious other one\nis called unsupervised. In that case, I'm just going to\ngive you a bunch of examples.",
    "start": "865010",
    "end": "872210"
  },
  {
    "text": "But I don't know the labels\nassociated with them. I'm going to just\ntry and find what are the natural ways\nto group those examples",
    "start": "872210",
    "end": "879020"
  },
  {
    "text": "together into different models. And in some cases, I may know\nhow many models are there.",
    "start": "879020",
    "end": "884089"
  },
  {
    "text": "In some cases, I may\nwant to just say what's the best grouping I can find. OK.",
    "start": "884090",
    "end": "890760"
  },
  {
    "text": "What I'm going to do today\nis not a lot of code. I was expecting cheers for that,\nJohn, but I didn't get them. Not a lot of code.",
    "start": "890760",
    "end": "897240"
  },
  {
    "text": "What I'm going to do\nis show you basically, the intuitions behind\ndoing this learning. And I\"m going to start with my\nNew England Patriots example.",
    "start": "897240",
    "end": "903560"
  },
  {
    "text": "So here are some data points\nabout current Patriots players. And I've got two\nkinds of positions.",
    "start": "903560",
    "end": "909120"
  },
  {
    "text": "I've got receivers,\nand I have linemen. And each one is just labeled by\nthe name, the height in inches,",
    "start": "909120",
    "end": "915089"
  },
  {
    "text": "and the weight in pounds. OK? Five of each.",
    "start": "915090",
    "end": "920590"
  },
  {
    "text": "If I plot those on a\ntwo dimensional plot, this is what I get.",
    "start": "920590",
    "end": "926260"
  },
  {
    "text": "OK? No big deal. What am I trying to do? I'm trying to learn, are\ntheir characteristics",
    "start": "926260",
    "end": "933370"
  },
  {
    "text": "that distinguish the two\nclasses from one another? And in the unlabeled\ncase, all I have are just a set of examples.",
    "start": "933370",
    "end": "940240"
  },
  {
    "text": "So what I want to\ndo is decide what makes two players similar\nwith the goal of seeing,",
    "start": "940240",
    "end": "946240"
  },
  {
    "text": "can I separate this\ndistribution into two or more natural groups.",
    "start": "946240",
    "end": "952430"
  },
  {
    "text": "Similar is a distance measure. It says how do I take\ntwo examples with values or features\nassociated, and we're",
    "start": "952430",
    "end": "957493"
  },
  {
    "text": "going to decide how\nfar apart are they? And in the unlabeled case, the\nsimple way to do it is to say,",
    "start": "957493",
    "end": "963770"
  },
  {
    "text": "if I know that there are\nat least k groups there-- in this case, I'm going\nto tell you there are two different groups there--",
    "start": "963770",
    "end": "969800"
  },
  {
    "text": "how could I decide how\nbest to cluster things together so that all the\nexamples in one group",
    "start": "969800",
    "end": "975470"
  },
  {
    "text": "are close to each other, all\nthe examples in the other group are close to each other, and\nthey're reasonably far apart.",
    "start": "975470",
    "end": "982190"
  },
  {
    "text": "There are many ways to do it. I'm going to show you one. It's a very standard way, and\nit works, basically, as follows.",
    "start": "982190",
    "end": "989920"
  },
  {
    "text": "If all I know is that\nthere are two groups there, I'm going to start\nby just picking two examples as my exemplars.",
    "start": "989920",
    "end": "997497"
  },
  {
    "text": "Pick them at random. Actually at random is not great. I don't want to pick too\nclosely to each other. I'm going to try and\npick them far apart.",
    "start": "997497",
    "end": "1002528"
  },
  {
    "text": "But I pick two examples\nas my exemplars. And for all the other\nexamples in the training data,",
    "start": "1002528",
    "end": "1007540"
  },
  {
    "text": "I say which one\nis it closest to. What I'm going to try\nand do is create clusters",
    "start": "1007540",
    "end": "1012820"
  },
  {
    "text": "with the property\nthat the distances between all of the examples\nof that cluster are small.",
    "start": "1012820",
    "end": "1017860"
  },
  {
    "text": "The average distance is small. And see if I can\nfind clusters that gets the average distance\nfor both clusters",
    "start": "1017860",
    "end": "1023250"
  },
  {
    "text": "as small as possible. This algorithm works by\npicking two examples, clustering all the other\nexamples by simply saying",
    "start": "1023250",
    "end": "1030290"
  },
  {
    "text": "put it in the group to which\nit's closest to that example.",
    "start": "1030290",
    "end": "1035480"
  },
  {
    "text": "Once I've got\nthose clusters, I'm going to find the median\nelement of that group. Not mean, but median, what's\nthe one closest to the center?",
    "start": "1035480",
    "end": "1044060"
  },
  {
    "text": "And treat those as exemplars\nand repeat the process. And I'll just do it either\nsome number of times",
    "start": "1044060",
    "end": "1050015"
  },
  {
    "text": "or until I don't get any\nchange in the process. So it's clustering\nbased on distance.",
    "start": "1050015",
    "end": "1055490"
  },
  {
    "text": "And we'll come back to\ndistance in a second. So here's what would\nhave my football players.",
    "start": "1055490",
    "end": "1060650"
  },
  {
    "text": "If I just did this\nbased on weight, there's the natural\ndividing line. And it kind of makes sense.",
    "start": "1060650",
    "end": "1066865"
  },
  {
    "text": "All right? These three are\nobviously clustered, and again, it's\njust on this axis. They're all down here.",
    "start": "1066865",
    "end": "1071990"
  },
  {
    "text": "These seven are at\na different place. There's a natural\ndividing line there. If I were to do it based\non height, not as clean.",
    "start": "1071990",
    "end": "1081790"
  },
  {
    "text": "This is what my\nalgorithm came up with as the best\ndividing line here, meaning that these four,\nagain, just based on this axis",
    "start": "1081790",
    "end": "1089140"
  },
  {
    "text": "are close together. These six are close together. But it's not nearly as clean. And that's part of the\nissue we'll look at",
    "start": "1089140",
    "end": "1095650"
  },
  {
    "text": "is how do I find\nthe best clusters. If I use both\nheight and weight, I",
    "start": "1095650",
    "end": "1102440"
  },
  {
    "text": "get that, which was actually\nkind of nice, right? Those three cluster together.\nthey're near each other,",
    "start": "1102440",
    "end": "1108779"
  },
  {
    "text": "in terms of just\ndistance in the plane. Those seven are near each other. There's a nice, natural\ndividing line through here.",
    "start": "1108780",
    "end": "1116549"
  },
  {
    "text": "And in fact, that\ngives me a classifier. This line is the\nequidistant line",
    "start": "1116550",
    "end": "1123360"
  },
  {
    "text": "between the centers\nof those two clusters. Meaning, any point\nalong this line is the same distance to\nthe center of that group",
    "start": "1123360",
    "end": "1129750"
  },
  {
    "text": "as it is to that group. And so any new example,\nif it's above the line, I would say gets that label,\nif it's below the line,",
    "start": "1129750",
    "end": "1136080"
  },
  {
    "text": "gets that label. In a second, we'll\ncome back to look at how do we measure\nthe distances,",
    "start": "1136080",
    "end": "1141168"
  },
  {
    "text": "but the idea here\nis pretty simple. I want to find groupings\nnear each other and far apart from\nthe other group.",
    "start": "1141168",
    "end": "1149110"
  },
  {
    "text": "Now suppose I actually knew\nthe labels on these players.",
    "start": "1149110",
    "end": "1153890"
  },
  {
    "text": "These are the receivers. Those are the linemen. And for those of you\nwho are football fans,",
    "start": "1156790",
    "end": "1162880"
  },
  {
    "text": "you can figure it out, right? Those are the two tight ends. They are much bigger. I think that's Bennett and\nthat's Gronk if you're really",
    "start": "1162880",
    "end": "1168460"
  },
  {
    "text": "a big Patriots fan. But those are tight ends,\nthose are wide receivers, and it's going to\ncome back in a second, but there are the labels.",
    "start": "1168460",
    "end": "1174399"
  },
  {
    "text": "Now what I want to do is say,\nif I could take advantage of knowing the labels, how\nwould I divide these groups up?",
    "start": "1174400",
    "end": "1180279"
  },
  {
    "text": "And that's kind of easy to see. Basic idea, in this\ncase, is if I've got labeled groups\nin that feature",
    "start": "1180280",
    "end": "1186640"
  },
  {
    "text": "space, what I want to do is\nfind a subsurface that naturally divides that space.",
    "start": "1186640",
    "end": "1192220"
  },
  {
    "text": "Now subsurface is a fancy word. It says, in the\ntwo-dimensional case, I want to know\nwhat's the best line,",
    "start": "1192220",
    "end": "1198279"
  },
  {
    "text": "if I can find a single line,\nthat separates all the examples with one label from all the\nexamples of the second label.",
    "start": "1198280",
    "end": "1204820"
  },
  {
    "text": "We'll see that, if the\nexamples are well separated, this is easy to\ndo, and it's great.",
    "start": "1204820",
    "end": "1209890"
  },
  {
    "text": "But in some cases,\nit's going to be more complicated because\nsome of the examples may be very close\nto one another.",
    "start": "1209890",
    "end": "1215872"
  },
  {
    "text": "And that's going\nto raise a problem that you saw last lecture. I want to avoid overfitting.",
    "start": "1215872",
    "end": "1220900"
  },
  {
    "text": "I don't want to create a\nreally complicated surface to separate things. And so we may have to\ntolerate a few incorrectly",
    "start": "1220900",
    "end": "1227559"
  },
  {
    "text": "labeled things, if\nwe can't pull it out. And as you already\nfigured out, in this case,",
    "start": "1227560",
    "end": "1232590"
  },
  {
    "text": "with the labeled data,\nthere's the best fitting line right there. Anybody over 280 pounds is\ngoing to be a great lineman.",
    "start": "1232590",
    "end": "1240090"
  },
  {
    "text": "Anybody under 280 pounds is\nmore likely to be a receiver.",
    "start": "1240090",
    "end": "1245250"
  },
  {
    "text": "OK. So I've got two different\nways of trying to think about doing this labeling. I'm going to come back to\nboth of them in a second.",
    "start": "1245250",
    "end": "1252159"
  },
  {
    "text": "Now suppose I add\nin some new data. I want to label new instances.",
    "start": "1252160",
    "end": "1257879"
  },
  {
    "text": "Now these are actually players\nof a different position. These are running backs. But I say, all I know about\nis receivers and linemen.",
    "start": "1257879",
    "end": "1264530"
  },
  {
    "text": "I get these two new data points. I'd like to know, are\nthey more likely to be a receiver or a linemen?",
    "start": "1264530",
    "end": "1271429"
  },
  {
    "text": "And there's the data\nfor these two gentlemen. So if I go back to\nnow plotting them,",
    "start": "1271430",
    "end": "1277640"
  },
  {
    "text": "oh you notice one of the issues. So there are my linemen, the\nred ones are my receivers, the two black dots are\nthe two running backs.",
    "start": "1277640",
    "end": "1285860"
  },
  {
    "text": "And notice right here. It's going to be really\nhard to separate those two",
    "start": "1285860",
    "end": "1291550"
  },
  {
    "text": "examples from one another. They are so close to each other. And that's going to\nbe one of the things we have to trade off.",
    "start": "1291550",
    "end": "1297040"
  },
  {
    "text": "But if I think about using\nwhat I learned as a classifier with unlabeled data, there\nwere my two clusters.",
    "start": "1297040",
    "end": "1306030"
  },
  {
    "text": "Now you see, oh, I've got\nan interesting example. This new example I would\nsay is clearly more",
    "start": "1306030",
    "end": "1311690"
  },
  {
    "text": "like a receiver than a lineman. But that one there, unclear.",
    "start": "1311690",
    "end": "1317660"
  },
  {
    "text": "Almost exactly lies\nalong that dividing line between those two clusters. And I would either say, I\nwant to rethink the clustering",
    "start": "1317660",
    "end": "1324860"
  },
  {
    "text": "or I want to say, you know what? As I know, maybe there\naren't two clusters here. Maybe there are three.",
    "start": "1324860",
    "end": "1330560"
  },
  {
    "text": "And I want to classify\nthem a little differently. So I'll come back to that.",
    "start": "1330560",
    "end": "1335570"
  },
  {
    "text": "On the other hand, if I\nhad used the labeled data, there was my dividing line. This is really easy.",
    "start": "1335570",
    "end": "1341960"
  },
  {
    "text": "Both of those new\nexamples are clearly below the dividing line. They are clearly\nexamples that I would",
    "start": "1341960",
    "end": "1347240"
  },
  {
    "text": "categorize as being\nmore like receivers than they are like linemen.",
    "start": "1347240",
    "end": "1352380"
  },
  {
    "text": "And I know it's a\nfootball example. If you don't like football,\npick another example. But you get the\nsense of why I can",
    "start": "1352380",
    "end": "1358080"
  },
  {
    "text": "use the data in a labeled\ncase and the unlabeled case to come up with different\nways of building the clusters.",
    "start": "1358080",
    "end": "1365772"
  },
  {
    "text": "So what we're going\nto do over the next 2 and 1/2 lectures is\nlook at how can we write code to learn that way\nof separating things out?",
    "start": "1365772",
    "end": "1374549"
  },
  {
    "text": "We're going to learn models\nbased on unlabeled data. That's the case where I don't\nknow what the labels are, by simply trying to find ways\nto cluster things together",
    "start": "1374550",
    "end": "1382890"
  },
  {
    "text": "nearby, and then use the\nclusters to assign labels to new data. And we're going to learn models\nby looking at labeled data",
    "start": "1382890",
    "end": "1389820"
  },
  {
    "text": "and seeing how do we best come\nup with a way of separating with a line or a plane or a\ncollection of lines, examples",
    "start": "1389820",
    "end": "1397230"
  },
  {
    "text": "from one group, from\nexamples of the other group. With the acknowledgment that\nwe want to avoid overfitting,",
    "start": "1397230",
    "end": "1403464"
  },
  {
    "text": "we don't want to create a\nreally complicated system. And as a consequence,\nwe're going to have to make some\ntrade-offs between what",
    "start": "1403464",
    "end": "1408960"
  },
  {
    "text": "we call false positives\nand false negatives. But the resulting classifier\ncan then label any new data",
    "start": "1408960",
    "end": "1414779"
  },
  {
    "text": "by just deciding where\nyou are with respect to that separating line.",
    "start": "1414780",
    "end": "1417730"
  },
  {
    "text": "So here's what you're going\nto see over the next 2 and 1/2 lectures. Every machine learning method\nhas five essential components.",
    "start": "1420360",
    "end": "1429510"
  },
  {
    "text": "We need to decide what's\nthe training data, and how are we going to evaluate\nthe success of that system. We've already seen\nsome examples of that.",
    "start": "1429510",
    "end": "1436900"
  },
  {
    "text": "We need to decide\nhow are we going to represent each instance\nthat we're giving it.",
    "start": "1436900",
    "end": "1442559"
  },
  {
    "text": "I happened to choose height and\nweight for football players. But I might have been better\noff to pick average speed",
    "start": "1442560",
    "end": "1448200"
  },
  {
    "text": "or, I don't know, arm\nlength, something else. How do I figure out what\nare the right features. And associated with that,\nhow do I measure distances",
    "start": "1448200",
    "end": "1455820"
  },
  {
    "text": "between those features? How do I decide what's\nclose and what's not close? Maybe it should be different, in\nterms of weight versus height,",
    "start": "1455820",
    "end": "1462720"
  },
  {
    "text": "for example. I need to make that decision. And those are the\ntwo things we're going to show you examples of\ntoday, how to go through that.",
    "start": "1462720",
    "end": "1470030"
  },
  {
    "text": "Starting next week,\nProfessor Guttag is going to show you how you\ntake those and actually start building more detailed versions\nof measuring clustering,",
    "start": "1470030",
    "end": "1478260"
  },
  {
    "text": "measuring similarities to find\nan objective function that you want to minimize to decide what\nis the best cluster to use.",
    "start": "1478260",
    "end": "1484830"
  },
  {
    "text": "And then what is the best\noptimization method you want to use to learn that model.",
    "start": "1484830",
    "end": "1490350"
  },
  {
    "text": "So let's start talking\nabout features. I've got a set of\nexamples, labeled or not.",
    "start": "1490350",
    "end": "1496960"
  },
  {
    "text": "I need to decide what is it\nabout those examples that's useful to use when I\nwant to decide what's",
    "start": "1496960",
    "end": "1502659"
  },
  {
    "text": "close to another thing or not. And one of the problems\nis, if it was really easy, it would be really easy.",
    "start": "1502660",
    "end": "1509600"
  },
  {
    "text": "Features don't always\ncapture what you want. I'm going to belabor\nthat football analogy, but why did I pick\nheight and weight.",
    "start": "1509600",
    "end": "1516050"
  },
  {
    "text": "Because it was easy to find. You know, if you work for the\nNew England Patriots, what is the thing that you really\nlook for when you're asking,",
    "start": "1516050",
    "end": "1522900"
  },
  {
    "text": "what's the right feature? It's probably some other\ncombination of things. So you, as a designer,\nhave to say what are the features I want to use.",
    "start": "1522900",
    "end": "1529952"
  },
  {
    "text": "That quote, by the\nway, is from one of the great statisticians\nof the 20th century, which I think captures it well.",
    "start": "1529952",
    "end": "1535640"
  },
  {
    "text": "So feature engineering,\nas you, as a programmer, comes down to deciding\nboth what are the features",
    "start": "1535640",
    "end": "1542030"
  },
  {
    "text": "I want to measure in that vector\nthat I'm going to put together, and how do I decide\nrelative ways to weight it?",
    "start": "1542030",
    "end": "1549340"
  },
  {
    "text": "So John, and Ana, and I\ncould have made our job",
    "start": "1549340",
    "end": "1555520"
  },
  {
    "text": "this term really easy\nif we had sat down at the beginning of the\nterm and said, you know, we've taught this\ncourse many times.",
    "start": "1555520",
    "end": "1561270"
  },
  {
    "text": "We've got data\nfrom, I don't know, John, thousands of students,\nprobably over this time. Let's just build a\nlittle learning algorithm",
    "start": "1561270",
    "end": "1567640"
  },
  {
    "text": "that takes a set of data and\npredicts your final grade. You don't have to\ncome to class, don't",
    "start": "1567640",
    "end": "1572710"
  },
  {
    "text": "have to go through\nall the problems, because we'll just\npredict your final grade. Wouldn't that be nice? Make our job a little easier,\nand you may or may not",
    "start": "1572710",
    "end": "1578950"
  },
  {
    "text": "like that idea. But I could think about\npredicting that grade? Now why am I telling\nthis example.",
    "start": "1578950",
    "end": "1584620"
  },
  {
    "text": "I was trying to see if I\ncould get a few smiles. I saw a couple of them there. But think about the features.",
    "start": "1584620",
    "end": "1590780"
  },
  {
    "text": "What I measure? Actually, I'll put this on\nJohn because it's his idea. What would he measure?",
    "start": "1590780",
    "end": "1595929"
  },
  {
    "text": "Well, GPA is probably not a\nbad predictor of performance.",
    "start": "1595930",
    "end": "1601090"
  },
  {
    "text": "You do well in other\nclasses, you're likely to do well in this class. I'm going to use this\none very carefully.",
    "start": "1601090",
    "end": "1607000"
  },
  {
    "text": "Prior programming experience\nis at least a predictor, but it is not a\nperfect predictor.",
    "start": "1607000",
    "end": "1613549"
  },
  {
    "text": "Those of you who haven't\nprogrammed before, in this class, you can still\ndo really well in this class. But it's an indication that\nyou've seen other programming",
    "start": "1613549",
    "end": "1619695"
  },
  {
    "text": "languages. On the other hand, I don't\nbelieve in astrology. So I don't think the month\nin which you're born,",
    "start": "1619695",
    "end": "1626890"
  },
  {
    "text": "the astrological sign\nunder which you were born has probably anything to do\nwith how well you'd program.",
    "start": "1626890",
    "end": "1632500"
  },
  {
    "text": "I doubt that eye color\nhas anything to do with how well you'd program. You get the idea. Some features\nmatter, others don't.",
    "start": "1632500",
    "end": "1639730"
  },
  {
    "text": "Now I could just throw all\nthe features in and hope that the machine learning algorithm\nsorts out those it wants",
    "start": "1639730",
    "end": "1645610"
  },
  {
    "text": "to keep from those it doesn't. But I remind you of that\nidea of overfitting. If I do that,\nthere is the danger",
    "start": "1645610",
    "end": "1652570"
  },
  {
    "text": "that it will find some\ncorrelation between birth month, eye color, and GPA.",
    "start": "1652570",
    "end": "1659200"
  },
  {
    "text": "And that's going to\nlead to a conclusion that we really don't like. By the way, in case\nyou're worried,",
    "start": "1659200",
    "end": "1664620"
  },
  {
    "text": "I can assure you\nthat Stu Schmill in the dean of\nadmissions department does not use machine\nlearning to pick you.",
    "start": "1664620",
    "end": "1670437"
  },
  {
    "text": "He actually looks at a\nwhole bunch of things because it's not easy to\nreplace him with a machine-- yet.",
    "start": "1670437",
    "end": "1676765"
  },
  {
    "text": "All right. So what this says is\nwe need to think about how do we pick the features. And mostly, what\nwe're trying to do",
    "start": "1676765",
    "end": "1682638"
  },
  {
    "text": "is to maximize something called\nthe signal to noise ratio. Maximize those features that\ncarry the most information,",
    "start": "1682638",
    "end": "1689669"
  },
  {
    "text": "and remove the ones that don't. So I want to show\nyou an example of how you might think about this.",
    "start": "1689670",
    "end": "1697530"
  },
  {
    "text": "I want to label reptiles. I want to come up with a\nway of labeling animals as,",
    "start": "1697530",
    "end": "1702860"
  },
  {
    "text": "are they a reptile or not. And I give you a single example. With a single example,\nyou can't really do much.",
    "start": "1702860",
    "end": "1708560"
  },
  {
    "text": "But from this example, I know\nthat a cobra, it lays eggs, it has scales, it's\npoisonous, it's cold blooded,",
    "start": "1708560",
    "end": "1715130"
  },
  {
    "text": "it has no legs,\nand it's a reptile. So I could say my model\nof a reptile is well, I'm not certain.",
    "start": "1715130",
    "end": "1720500"
  },
  {
    "text": "I don't have enough data yet. But if I give you\na second example, and it also happens\nto be egg-laying,",
    "start": "1720500",
    "end": "1727070"
  },
  {
    "text": "have scales, poisonous,\ncold blooded, no legs. There is my model, right? Perfectly reasonable\nmodel, whether I design it",
    "start": "1727070",
    "end": "1733959"
  },
  {
    "text": "or a machine learning\nalgorithm would do it says, if all of these are\ntrue, label it as a reptile.",
    "start": "1733959",
    "end": "1740210"
  },
  {
    "text": "OK? And now I give you\na boa constrictor.",
    "start": "1740210",
    "end": "1745366"
  },
  {
    "text": "Ah. It's a reptile. But it doesn't fit the model.",
    "start": "1745366",
    "end": "1751120"
  },
  {
    "text": "And in particular,\nit's not egg-laying, and it's not poisonous.",
    "start": "1751120",
    "end": "1756907"
  },
  {
    "text": "So I've got to refine the model. Or the algorithm has\ngot to refine the model. And this, I want to remind you,\nis looking at the features.",
    "start": "1756907",
    "end": "1761960"
  },
  {
    "text": "So I started out\nwith five features. This doesn't fit. So probably what I\nshould do is reduce it.",
    "start": "1761960",
    "end": "1768730"
  },
  {
    "text": "I'm going to look at scales. I'm going to look\nat cold blooded. I'm going to look at legs. That captures all\nthree examples.",
    "start": "1768730",
    "end": "1774411"
  },
  {
    "text": "Again, if you think about\nthis in terms of clustering, all three of them\nwould fit with that.",
    "start": "1774411",
    "end": "1779621"
  },
  {
    "text": "OK. Now I give you another example-- chicken. I don't think it's a reptile.",
    "start": "1779621",
    "end": "1785534"
  },
  {
    "text": "In fact, I'm pretty\nsure it's not a reptile. And it nicely still\nfits this model, right?",
    "start": "1785535",
    "end": "1793350"
  },
  {
    "text": "Because, while it has scales,\nwhich you may or not realize, it's not cold blooded,\nand it has legs.",
    "start": "1793350",
    "end": "1798500"
  },
  {
    "text": "So it is a negative example\nthat reinforces the model. Sounds good.",
    "start": "1798500",
    "end": "1804644"
  },
  {
    "text": "And now I'll give\nyou an alligator. It's a reptile.",
    "start": "1804644",
    "end": "1809720"
  },
  {
    "text": "And oh fudge, right? It doesn't satisfy the model. Because while it does have\nscales and it is cold blooded,",
    "start": "1809720",
    "end": "1819170"
  },
  {
    "text": "it has legs. I'm almost done\nwith the example. But you see the point. Again, I've got to think\nabout how do I refine this.",
    "start": "1819170",
    "end": "1825650"
  },
  {
    "text": "And I could by\nsaying, all right. Let's make it a little more\ncomplicated-- has scales,",
    "start": "1825650",
    "end": "1830930"
  },
  {
    "text": "cold blooded, 0 or four legs-- I'm going to say it's a reptile.",
    "start": "1830930",
    "end": "1834120"
  },
  {
    "text": "I'll give you the dart frog. Not a reptile,\nit's an amphibian. And that's nice because\nit still satisfies this.",
    "start": "1836670",
    "end": "1843000"
  },
  {
    "text": "So it's an example outside\nof the cluster that says no scales,\nnot cold blooded,",
    "start": "1843000",
    "end": "1850211"
  },
  {
    "text": "but happens to have four legs. It's not a reptile. That's good. And then I give you-- I have to give you\na python, right?",
    "start": "1850211",
    "end": "1856570"
  },
  {
    "text": "I mean, there has to\nbe a python in here. Oh come on. At least grown at\nme when I say that. There has to be a python here.",
    "start": "1856570",
    "end": "1862990"
  },
  {
    "text": "And I give you\nthat and a salmon. And now I am in trouble.",
    "start": "1862990",
    "end": "1868620"
  },
  {
    "text": "Because look at scales, look\nat cold blooded, look at legs.",
    "start": "1868620",
    "end": "1874809"
  },
  {
    "text": "I can't separate them. On those features,\nthere's no way to come up with a way\nthat will correctly",
    "start": "1874810",
    "end": "1880510"
  },
  {
    "text": "say that the python is a\nreptile and the salmon is not. And so there's no easy\nway to add in that rule.",
    "start": "1880510",
    "end": "1888370"
  },
  {
    "text": "And probably my best\nthing is to simply go back to just two features,\nscales and cold blooded.",
    "start": "1888370",
    "end": "1894490"
  },
  {
    "text": "And basically say,\nif something has scales and it's cold blooded,\nI'm going to call it a reptile. If it doesn't have\nboth of those,",
    "start": "1894490",
    "end": "1900160"
  },
  {
    "text": "I'm going to say\nit's not a reptile. It won't be perfect. It's going to incorrectly\nlabel the salmon.",
    "start": "1900160",
    "end": "1905800"
  },
  {
    "text": "But I've made a design\nchoice here that's important. And the design choice is that\nI will have no false negatives.",
    "start": "1905800",
    "end": "1914230"
  },
  {
    "text": "What that means is\nthere's not going to be any instance of something\nthat's not a reptile that I'm",
    "start": "1914230",
    "end": "1919240"
  },
  {
    "text": "going to call a reptile. I may have some false positives. So I did that the wrong way.",
    "start": "1919240",
    "end": "1925280"
  },
  {
    "text": "A false negative\nsays, everything that's not a reptile I'm going\nto categorize that direction. I may have some false\npositives, in that,",
    "start": "1925280",
    "end": "1931760"
  },
  {
    "text": "I may have a few things\nthat I will incorrectly label as a reptile. And in particular,\nsalmon is going",
    "start": "1931760",
    "end": "1937700"
  },
  {
    "text": "to be an instance of that. This trade off of false\npositives and false negatives is something that we worry\nabout, as we think about it.",
    "start": "1937700",
    "end": "1944390"
  },
  {
    "text": "Because there's no perfect\nway, in many cases, to separate out the data. And if you think back to my\nexample of the New England",
    "start": "1944390",
    "end": "1950640"
  },
  {
    "text": "Patriots, that running back\nand that wide receiver were so close together in\nheight and weight, there was no way I'm going to\nbe able to separate them apart.",
    "start": "1950640",
    "end": "1958256"
  },
  {
    "text": "And I just have to\nbe willing to decide how many false positives\nor false negatives do I want to tolerate.",
    "start": "1958256",
    "end": "1965370"
  },
  {
    "text": "Once I've figured out what\nfeatures to use, which is good, then I have to decide\nabout distance.",
    "start": "1965370",
    "end": "1972210"
  },
  {
    "text": "How do I compare\ntwo feature vectors? I'm going to say vector\nbecause there could be multiple dimensions to it. How do I decide how\nto compare them?",
    "start": "1972210",
    "end": "1978260"
  },
  {
    "text": "Because I want to use the\ndistances to figure out either how to group things together\nor how to find a dividing line",
    "start": "1978260",
    "end": "1983960"
  },
  {
    "text": "that separates things apart. So one of the things I have\nto decide is which features.",
    "start": "1983960",
    "end": "1989470"
  },
  {
    "text": "I also have to\ndecide the distance. And finally, I\nmay want to decide how to weigh relative importance\nof different dimensions",
    "start": "1989470",
    "end": "1996659"
  },
  {
    "text": "in the feature vector. Some may be more valuable than\nothers in making that decision. And I want to show you\nan example of that.",
    "start": "1996660",
    "end": "2004570"
  },
  {
    "text": "So let's go back to my animals. I started off with a\nfeature vector that actually",
    "start": "2004570",
    "end": "2009950"
  },
  {
    "text": "had five dimensions to it. It was egg-laying, cold\nblooded, has scales,",
    "start": "2009950",
    "end": "2016305"
  },
  {
    "text": "I forget what the other one\nwas, and number of legs. So one of the ways I\ncould think about this",
    "start": "2016305",
    "end": "2021559"
  },
  {
    "text": "is saying I've got four binary\nfeatures and one integer feature associated\nwith each animal.",
    "start": "2021560",
    "end": "2028910"
  },
  {
    "text": "And one way to learn to separate\nout reptiles from non reptiles is to measure the distance\nbetween pairs of examples",
    "start": "2028910",
    "end": "2036591"
  },
  {
    "text": "and use that distance to\ndecide what's near each other and what's not. And as we've said\nbefore, it will either be used to cluster things or to\nfind a classifier surface that",
    "start": "2036591",
    "end": "2044210"
  },
  {
    "text": "separates them. So here's a simple way to do it. For each of these examples,\nI'm going to just let true",
    "start": "2044210",
    "end": "2051470"
  },
  {
    "text": "be 1, false be 0. So the first four\nare either 0s or 1s. And the last one is\nthe number of legs.",
    "start": "2051470",
    "end": "2057709"
  },
  {
    "text": "And now I could say, all right. How do I measure\ndistances between animals or anything else, but these\nkinds of feature vectors?",
    "start": "2057709",
    "end": "2065884"
  },
  {
    "text": "Here, we're going\nto use something called the Minkowski Metric\nor the Minkowski difference. Given two vectors\nand a power, p,",
    "start": "2065884",
    "end": "2074080"
  },
  {
    "text": "we basically take\nthe absolute value of the difference between\neach of the components of the vector, raise it to\nthe p-th power, take the sum,",
    "start": "2074080",
    "end": "2083969"
  },
  {
    "text": "and take the p-th route of that. So let's do the two\nobvious examples. If p is equal to 1, I just\nmeasure the absolute distance",
    "start": "2083969",
    "end": "2091699"
  },
  {
    "text": "between each component, add\nthem up, and that's my distance. It's called the\nManhattan metric.",
    "start": "2091699",
    "end": "2098715"
  },
  {
    "text": "The one you've seen more,\nthe one we saw last time, if p is equal to 2, this is\nEuclidean distance, right?",
    "start": "2098715",
    "end": "2103900"
  },
  {
    "text": "It's the sum of the\nsquares of the differences of the components. Take the square root. Take the square root\nbecause it makes",
    "start": "2103900",
    "end": "2109690"
  },
  {
    "text": "it have certain\nproperties of a distance. That's the Euclidean distance.",
    "start": "2109690",
    "end": "2116540"
  },
  {
    "text": "So now if I want to measure\ndifference between these two, here's the question.",
    "start": "2116540",
    "end": "2122750"
  },
  {
    "text": "Is this circle closer to the\nstar or closer to the cross?",
    "start": "2122750",
    "end": "2127780"
  },
  {
    "text": "Unfortunately, I put\nthe answer up here. But it differs, depending\non the metric I use.",
    "start": "2127780",
    "end": "2133260"
  },
  {
    "text": "Right? Euclidean distance, well,\nthat's square root of 2 times 2, so it's about 2.8.",
    "start": "2133260",
    "end": "2138692"
  },
  {
    "text": "And that's three. So in terms of just standard\ndistance in the plane, we would say that these two\nare closer than those two are.",
    "start": "2138692",
    "end": "2146680"
  },
  {
    "text": "Manhattan distance,\nwhy is it called that? Because you can only walk along\nthe avenues and the streets.",
    "start": "2146680",
    "end": "2152040"
  },
  {
    "text": "Manhattan distance\nwould basically say this is one, two,\nthree, four units away. This is one, two,\nthree units away.",
    "start": "2152040",
    "end": "2159170"
  },
  {
    "text": "And under Manhattan\ndistance, this is closer, this pairing is closer\nthan that pairing is.",
    "start": "2159170",
    "end": "2165847"
  },
  {
    "text": "Now you're used to\nthinking Euclidean. We're going to use that. But this is going\nto be important when we think about how\nare we comparing distances",
    "start": "2165847",
    "end": "2172080"
  },
  {
    "text": "between these different pieces. So typically, we'll\nuse Euclidean. We're going to see Manhattan\nactually has some value.",
    "start": "2172080",
    "end": "2179120"
  },
  {
    "text": "So if I go back to my three\nexamples-- boy, that's a gross slide, isn't it? But there we go-- rattlesnake, boa\nconstrictor, and dart frog.",
    "start": "2179120",
    "end": "2185570"
  },
  {
    "text": "There is the representation. I can ask, what's the\ndistance between them? In the handout for today,\nwe've given you a little piece",
    "start": "2185570",
    "end": "2191790"
  },
  {
    "text": "of code that would do that. And if I actually run\nthrough it, I get, actually, a nice\nlittle result. Here",
    "start": "2191790",
    "end": "2198510"
  },
  {
    "text": "are the distances between those\nvectors using Euclidean metric. I'm going to come back to them.",
    "start": "2198510",
    "end": "2204490"
  },
  {
    "text": "But you can see the\ntwo snakes, nicely, are reasonably close to each other.",
    "start": "2204490",
    "end": "2210030"
  },
  {
    "text": "Whereas, the dart frog is a\nfair distance away from that. Nice, right? That's a nice separation\nthat says there's",
    "start": "2210030",
    "end": "2216740"
  },
  {
    "text": "a difference between these two. OK. Now I throw in the alligator.",
    "start": "2216740",
    "end": "2223160"
  },
  {
    "text": "Sounds like a Dungeons\n& Dragons game. I throw in the alligator, and I\nwant to do the same comparison.",
    "start": "2223160",
    "end": "2229480"
  },
  {
    "text": "And I don't get nearly as nice\na result. Because now it says,",
    "start": "2229480",
    "end": "2234720"
  },
  {
    "text": "as before, the two snakes\nare close to each other. But it says that the dart\nfrog and the alligator",
    "start": "2234720",
    "end": "2241700"
  },
  {
    "text": "are much closer, under\nthis measurement, than either of them\nis to the other.",
    "start": "2241700",
    "end": "2247184"
  },
  {
    "text": "And to remind you, right,\nthe alligator and the two snakes I would like to be close\nto one another and a distance",
    "start": "2247185",
    "end": "2253250"
  },
  {
    "text": "away from the frog. Because I'm trying to\nclassify reptiles versus not.",
    "start": "2253250",
    "end": "2258470"
  },
  {
    "text": "So what happened here? Well, this is a place where\nthe feature engineering is going to be important.",
    "start": "2258470",
    "end": "2264640"
  },
  {
    "text": "Because in fact, the alligator\ndiffers from the frog in three features.",
    "start": "2264640",
    "end": "2269120"
  },
  {
    "text": "And only in two features from,\nsay, the boa constrictor. But one of those features\nis the number of legs.",
    "start": "2271810",
    "end": "2277590"
  },
  {
    "text": "And there, while\non the binary axes, the difference is\nbetween a 0 and 1, here it can be between 0 and 4.",
    "start": "2277590",
    "end": "2285620"
  },
  {
    "text": "So that is weighing the distance\na lot more than we would like. The legs dimension is\ntoo large, if you like.",
    "start": "2285620",
    "end": "2293520"
  },
  {
    "text": "How would I fix this? This is actually, I would\nargue, a natural place to use Manhattan distance.",
    "start": "2293520",
    "end": "2300690"
  },
  {
    "text": "Why should I think\nthat the difference in the number of legs or the\nnumber of legs difference",
    "start": "2300690",
    "end": "2306160"
  },
  {
    "text": "is more important than\nwhether it has scales or not? Why should I think that\nmeasuring that distance",
    "start": "2306160",
    "end": "2312619"
  },
  {
    "text": "Euclidean-wise makes sense? They are really completely\ndifferent measurements. And in fact, I'm\nnot going to do it,",
    "start": "2312620",
    "end": "2318090"
  },
  {
    "text": "but if I ran Manhattan\nmetric on this, it would get the alligator\nmuch closer to the snakes,",
    "start": "2318090",
    "end": "2323160"
  },
  {
    "text": "exactly because it differs only\nin two features, not three. The other way I\ncould fix it would",
    "start": "2323160",
    "end": "2329900"
  },
  {
    "text": "be to say I'm letting too\nmuch weight be associated with the difference\nin the number of legs. So let's just make\nit a binary feature.",
    "start": "2329900",
    "end": "2336800"
  },
  {
    "text": "Either it doesn't have\nlegs or it does have legs. Run the same classification.",
    "start": "2336800",
    "end": "2343040"
  },
  {
    "text": "And now you see the\nsnakes and the alligator are all close to each other.",
    "start": "2343040",
    "end": "2349510"
  },
  {
    "text": "Whereas the dart frog, not\nas far away as it was before, but there's a pretty natural\nseparation, especially",
    "start": "2349510",
    "end": "2355480"
  },
  {
    "text": "using that number between them. What's my point? Choice of features matters.",
    "start": "2355480",
    "end": "2362609"
  },
  {
    "text": "Throwing too many\nfeatures in may, in fact, give us some overfitting. And in particular,\ndeciding the weights",
    "start": "2362610",
    "end": "2369300"
  },
  {
    "text": "that I want on those\nfeatures has a real impact. And you, as a designer\nor a programmer, have a lot of influence in how\nyou think about using those.",
    "start": "2369300",
    "end": "2377340"
  },
  {
    "text": "So feature engineering\nreally matters. How you pick the\nfeatures, what you use is going to be important.",
    "start": "2377340",
    "end": "2383580"
  },
  {
    "text": "OK. The last piece of\nthis then is we're going to look at some examples\nwhere we give you data, got",
    "start": "2383580",
    "end": "2391369"
  },
  {
    "text": "features associated with them. We're going to, in some\ncases have them labeled, in other cases not. And we know how now to\nthink about how do we",
    "start": "2391370",
    "end": "2397970"
  },
  {
    "text": "measure distances between them. John. JOHN GUTTAG: You\nprobably didn't intend to say weights of features.",
    "start": "2397970",
    "end": "2403460"
  },
  {
    "text": "You intended to say\nhow they're scaled. ERIC GRIMSON: Sorry. The scales and not\nthe-- thank you, John. No, I did. I take that back. I did not mean to say\nweights of features.",
    "start": "2403460",
    "end": "2409600"
  },
  {
    "text": "I meant to say the\nscale of the dimension is going to be important here. Thank you, for the\namplification and correction.",
    "start": "2409600",
    "end": "2415210"
  },
  {
    "text": "You're absolutely right. JOHN GUTTAG: Weights, we\nuse in a different way, as we'll see next time. ERIC GRIMSON: And\nwe're going to see next time why we're going to\nuse weights in different ways.",
    "start": "2415210",
    "end": "2421450"
  },
  {
    "text": "So rephrase it. Block that out of your mind. We're going to talk about\nscales and the scale on the axes as being important here.",
    "start": "2421450",
    "end": "2427536"
  },
  {
    "text": "And we already said\nwe're going to look at two different\nkinds of learning, labeled and unlabeled,\nclustering and classifying.",
    "start": "2427536",
    "end": "2434920"
  },
  {
    "text": "And I want to just\nfinish up by showing you two examples of that. How we would think about\nthem algorithmically,",
    "start": "2434920",
    "end": "2441310"
  },
  {
    "text": "and we'll look at them\nin more detail next time. As we look at it,\nI want to remind you the things that are\ngoing to be important to you.",
    "start": "2441310",
    "end": "2448530"
  },
  {
    "text": "How do I measure distance\nbetween examples? What's the right\nway to design that? What is the right set of\nfeatures to use in that vector?",
    "start": "2448530",
    "end": "2457060"
  },
  {
    "text": "And then, what constraints do\nI want to put on the model? In the case of\nunlabelled data, how",
    "start": "2457060",
    "end": "2463020"
  },
  {
    "text": "do I decide how many\nclusters I want to have? Because I can give you a really\neasy way to do clustering.",
    "start": "2463020",
    "end": "2468840"
  },
  {
    "text": "If I give you 100 examples,\nI say build 100 clusters. Every example is\nits own cluster.",
    "start": "2468840",
    "end": "2474250"
  },
  {
    "text": "Distance is really good. It's really close to itself,\nbut it does a lousy job of labeling things on it. So I have to think\nabout, how do I",
    "start": "2474250",
    "end": "2480656"
  },
  {
    "text": "decide how many clusters,\nwhat's the complexity of that separating service? How do I basically avoid\nthe overfitting problem,",
    "start": "2480656",
    "end": "2487710"
  },
  {
    "text": "which I don't want to have? So just to remind\nyou, we've already",
    "start": "2487710",
    "end": "2492850"
  },
  {
    "text": "seen a little version of\nthis, the clustering method. This is a standard way to\ndo it, simply repeating what",
    "start": "2492850",
    "end": "2499276"
  },
  {
    "text": "we had on an earlier slide. If I want to cluster\nit into groups, I start by saying how many\nclusters am I looking for?",
    "start": "2499276",
    "end": "2505410"
  },
  {
    "text": "Pick an example I take as\nmy early representation. For every other example\nin the training data,",
    "start": "2505410",
    "end": "2510640"
  },
  {
    "text": "put it to the closest cluster. Once I've got those, find the\nmedian, repeat the process.",
    "start": "2510640",
    "end": "2517080"
  },
  {
    "text": "And that led to that separation. Now once I've got it,\nI like to validate it.",
    "start": "2517080",
    "end": "2523930"
  },
  {
    "text": "And in fact, I should\nhave said this better. Those two clusters came without\nlooking at the two black dots.",
    "start": "2523930",
    "end": "2529980"
  },
  {
    "text": "Once I put the\nblack dots in, I'd like to validate, how well\ndoes this really work? And that example there is\nreally not very encouraging.",
    "start": "2529980",
    "end": "2537780"
  },
  {
    "text": "It's too close. So that's a natural place to\nsay, OK, what if I did this with three clusters?",
    "start": "2537780",
    "end": "2545360"
  },
  {
    "text": "That's what I get. I like the that. All right? That has a really\nnice cluster up here.",
    "start": "2545360",
    "end": "2553460"
  },
  {
    "text": "The fact that the algorithm\ndidn't know the labeling is irrelevant. There's a nice grouping of five. There's a nice grouping of four.",
    "start": "2553460",
    "end": "2559710"
  },
  {
    "text": "And there's a nice grouping\nof three in between. And in fact, if I looked\nat the average distance",
    "start": "2559710",
    "end": "2565980"
  },
  {
    "text": "between examples in\neach of these clusters, it is much tighter\nthan in that example.",
    "start": "2565980",
    "end": "2572440"
  },
  {
    "text": "And so that leads to, then,\nthe question of should I look for four clusters?",
    "start": "2572440",
    "end": "2577642"
  },
  {
    "text": "Question, please. AUDIENCE: Is that overlap\nbetween the two clusters not an issue? ERIC GRIMSON: Yes. The question is, is the overlap\nbetween the two clusters",
    "start": "2577642",
    "end": "2584599"
  },
  {
    "text": "a problem? No. I just drew it\nhere so I could let you see where those pieces are. But in fact, if you like,\nthe center is there.",
    "start": "2584600",
    "end": "2593090"
  },
  {
    "text": "Those three points are\nall closer to that center than they are to that center. So the fact that they\noverlap is a good question.",
    "start": "2593090",
    "end": "2598260"
  },
  {
    "text": "It's just the way I\nhappened to draw them. I should really\ndraw these, not as circles, but as some little\nbit more convoluted surface.",
    "start": "2598260",
    "end": "2605104"
  },
  {
    "text": "OK? Having done three, I could\nsay should I look for four? Well, those points down\nthere, as I've already said,",
    "start": "2605104",
    "end": "2611919"
  },
  {
    "text": "are an example where\nit's going to be hard to separate them out. And I don't want to overfit. Because the only way\nto separate those out",
    "start": "2611919",
    "end": "2617720"
  },
  {
    "text": "is going to be to come up with\na really convoluted cluster, which I don't like. All right?",
    "start": "2617720",
    "end": "2623579"
  },
  {
    "text": "Let me finish with showing\nyou one other example from the other direction. Which is, suppose I give\nyou labeled examples.",
    "start": "2623580",
    "end": "2632010"
  },
  {
    "text": "So again, the goal\nis I've got features associated with each example. They're going to have\nmultiple dimensions on it.",
    "start": "2632010",
    "end": "2637470"
  },
  {
    "text": "But I also know the label\nassociated with them. And I want to learn\nwhat is the best way to come up with a rule that\nwill let me take new examples",
    "start": "2637470",
    "end": "2644759"
  },
  {
    "text": "and assign them to\nthe right group. A number of ways to do this. You can simply say I'm looking\nfor the simplest surface that",
    "start": "2644760",
    "end": "2652020"
  },
  {
    "text": "will separate those examples. In my football case that\nwere in the plane, what's the best line that\nseparates them,",
    "start": "2652020",
    "end": "2657660"
  },
  {
    "text": "which turns out to be easy. I might look for a more\ncomplicated surface. And we're going to see\nan example in a second",
    "start": "2657660",
    "end": "2663600"
  },
  {
    "text": "where maybe it's a\nsequence of line segments that separates them out. Because there's not just one\nline that does the separation.",
    "start": "2663600",
    "end": "2670920"
  },
  {
    "text": "As before, I want to be careful. If I make it too\ncomplicated, I may get a really good separator,\nbut I overfit to the data.",
    "start": "2670920",
    "end": "2678054"
  },
  {
    "text": "And you're going\nto see next time. I'm going to just\nhighlight it here. There's a third\nway, which will lead to almost the same\nkind of result",
    "start": "2678054",
    "end": "2683910"
  },
  {
    "text": "called k nearest neighbors. And the idea here is I've\ngot a set of labeled data.",
    "start": "2683910",
    "end": "2689549"
  },
  {
    "text": "And what I'm going to do\nis, for every new example, say find the k, say the five\nclosest labeled examples.",
    "start": "2689550",
    "end": "2697250"
  },
  {
    "text": "And take a vote. If 3 out of 5 or 4 out of 5\nor 5 out of 5 of those labels are the same, I'm going to\nsay it's part of that group.",
    "start": "2697250",
    "end": "2704605"
  },
  {
    "text": "And if I have less\nthan that, I'm going to leave it\nas unclassified. And that's a nice way\nof actually thinking about how to learn them.",
    "start": "2704605",
    "end": "2710870"
  },
  {
    "text": "And let me just finish by\nshowing you an example. Now I won't use football\nplayers on this one. I'll use a different example.",
    "start": "2710870",
    "end": "2717380"
  },
  {
    "text": "I'm going to give\nyou some voting data. I think this is\nactually simulated data. But these are a set of\nvoters in the United States",
    "start": "2717380",
    "end": "2725974"
  },
  {
    "text": "with their preference. They tend to vote Republican. They tend to vote Democrat. And the two categories are\ntheir age and how far away",
    "start": "2725974",
    "end": "2732800"
  },
  {
    "text": "they live from Boston. Whether those are relevant\nor not, I don't know, but they are just two things I'm\ngoing to use to classify them.",
    "start": "2732800",
    "end": "2739064"
  },
  {
    "text": "And I'd like to say,\nhow would I fit a curve to separate those two classes?",
    "start": "2739064",
    "end": "2746110"
  },
  {
    "text": "I'm going to keep\nhalf the data to test. I'm going to use half\nthe data to train. So if this is my\ntraining data, I",
    "start": "2746110",
    "end": "2752589"
  },
  {
    "text": "can say what's the best\nline that separates these? I don't know about best,\nbut here are two examples.",
    "start": "2752590",
    "end": "2760200"
  },
  {
    "text": "This solid line has the\nproperty that all the Democrats are on one side.",
    "start": "2760200",
    "end": "2765619"
  },
  {
    "text": "Everything on the other\nside is a Republican, but there are some Republicans\non this side of the line. I can't find a line that\ncompletely separates these,",
    "start": "2765620",
    "end": "2772310"
  },
  {
    "text": "as I did with the\nfootball players. But there is a decent\nline to separate them.",
    "start": "2772310",
    "end": "2777659"
  },
  {
    "text": "Here's another candidate. That dash line has the\nproperty that on the right side",
    "start": "2777659",
    "end": "2782695"
  },
  {
    "text": "you've got-- boy, I don't\nthink this is deliberate, John, right-- but\non the right side, you've got almost\nall Republicans.",
    "start": "2782695",
    "end": "2788195"
  },
  {
    "text": "It seems perfectly appropriate. One Democrat, but there's a\npretty good separation there.",
    "start": "2788195",
    "end": "2794000"
  },
  {
    "text": "And on the left side,\nyou've got a mix of things. But most of the Democrats are\non the left side of that line.",
    "start": "2794000",
    "end": "2799980"
  },
  {
    "text": "All right? The fact that left\nand right correlates with distance from Boston is\ncompletely irrelevant here. But it has a nice punch to it.",
    "start": "2799980",
    "end": "2806619"
  },
  {
    "text": "JOHN GUTTAG: Relevant,\nbut not accidental. ERIC GRIMSON: But\nnot accidental. Thank you. All right. So now the question is,\nhow would I evaluate these?",
    "start": "2806620",
    "end": "2813194"
  },
  {
    "text": "How do I decide\nwhich one is better? And I'm simply\ngoing to show you, very quickly, some examples.",
    "start": "2813194",
    "end": "2818880"
  },
  {
    "text": "First one is to look at what's\ncalled the confusion matrix. What does that mean? It says for this, one of\nthese classifiers for example,",
    "start": "2818880",
    "end": "2827090"
  },
  {
    "text": "the solid line. Here are the predictions,\nbased on the solid line of whether they would\nbe more likely to be Democrat or Republican.",
    "start": "2827090",
    "end": "2833540"
  },
  {
    "text": "And here is the actual label. Same thing for the dashed line. And that diagonal is\nimportant because those are",
    "start": "2833540",
    "end": "2841280"
  },
  {
    "text": "the correctly labeled results. Right? It correctly, in\nthe solid line case,",
    "start": "2841280",
    "end": "2847460"
  },
  {
    "text": "gets all of the correct\nlabelings of the Democrats. It gets half of the\nRepublicans right. But it has some where\nit's actually Republican,",
    "start": "2847460",
    "end": "2855080"
  },
  {
    "text": "but it labels it as a Democrat. That, we'd like to\nbe really large.",
    "start": "2855080",
    "end": "2860579"
  },
  {
    "text": "And in fact, it leads\nto a natural measure called the accuracy. Which is, just to\ngo back to that,",
    "start": "2860580",
    "end": "2866519"
  },
  {
    "text": "we say that these\nare true positives. Meaning, I labeled it as being\nan instance, and it really is.",
    "start": "2866520",
    "end": "2872069"
  },
  {
    "text": "These are true negatives. I label it as not being an\ninstance, and it really isn't. And then these are\nthe false positives.",
    "start": "2872070",
    "end": "2879450"
  },
  {
    "text": "I labeled it as being an\ninstance and it's not, and these are the\nfalse negatives. I labeled it as not being\nan instance, and it is.",
    "start": "2879450",
    "end": "2885680"
  },
  {
    "text": "And an easy way to measure it\nis to look at the correct labels over all of the labels.",
    "start": "2885680",
    "end": "2891290"
  },
  {
    "text": "The true positives and\nthe true negatives, the ones I got right. And in that case, both models\ncome up with a value of 0.7.",
    "start": "2891290",
    "end": "2899862"
  },
  {
    "text": "So which one is better? Well, I should validate that. And I'm going to\ndo that in a second by looking at other data.",
    "start": "2899862",
    "end": "2905511"
  },
  {
    "text": "We could also ask,\ncould we find something with less training error? This is only getting 70% right.",
    "start": "2905511",
    "end": "2911309"
  },
  {
    "text": "Not great. Well, here is a more\ncomplicated model. And this is where\nyou start getting",
    "start": "2911310",
    "end": "2917150"
  },
  {
    "text": "worried about overfitting. Now what I've done,\nis I've come up with a sequence of lines\nthat separate them.",
    "start": "2917150",
    "end": "2922430"
  },
  {
    "text": "So everything above this\nline, I'm going to say is a Republican. Everything below this line,\nI'm going to say is a Democrat.",
    "start": "2922430",
    "end": "2928910"
  },
  {
    "text": "So I'm avoiding that one. I'm avoiding that one. I'm still capturing\nmany of the same things.",
    "start": "2928910",
    "end": "2934340"
  },
  {
    "text": "And in this case, I get 12 true\npositives, 13 true negatives, and only 5 false positives.",
    "start": "2934340",
    "end": "2942001"
  },
  {
    "text": "And that's kind of nice. You can see the 5. It's those five red\nones down there. It's accuracy is 0.833.",
    "start": "2942001",
    "end": "2949360"
  },
  {
    "text": "And now, if I apply that to the\ntest data, I get an OK result.",
    "start": "2949360",
    "end": "2955596"
  },
  {
    "text": "It has an accuracy of about 0.6. I could use this idea to try\nand generalize to say could I",
    "start": "2955596",
    "end": "2961930"
  },
  {
    "text": "come up with a better model. And you're going to\nsee that next time. There could be other ways\nin which I measure this.",
    "start": "2961930",
    "end": "2968050"
  },
  {
    "text": "And I want to use this\nas the last example. Another good measure we use is\ncalled PPV, Positive Predictive",
    "start": "2968050",
    "end": "2974740"
  },
  {
    "text": "Value which is how many true\npositives do I come up with out of all the things I\nlabeled positively.",
    "start": "2974740",
    "end": "2982580"
  },
  {
    "text": "And in this solid model,\nin the dashed line, I can get values about 0.57.",
    "start": "2982580",
    "end": "2988119"
  },
  {
    "text": "The complex model on the\ntraining data is better. And then the testing\ndata is even stronger.",
    "start": "2988120",
    "end": "2993960"
  },
  {
    "text": "And finally, two other\nexamples are called sensitivity and specificity. Sensitivity basically\ntells you what percentage",
    "start": "2993960",
    "end": "3001490"
  },
  {
    "text": "did I correctly find. And specificity\nsaid what percentage did I correctly reject.",
    "start": "3001490",
    "end": "3007700"
  },
  {
    "text": "And I show you this\nbecause this is where the trade-off comes in. If sensitivity is how\nmany did I correctly",
    "start": "3007700",
    "end": "3014210"
  },
  {
    "text": "label out of those\nthat I both correctly labeled and incorrectly\nlabeled as being negative,",
    "start": "3014210",
    "end": "3020381"
  },
  {
    "text": "how many them did\nI correctly label as being the kind that I want? I can make sensitivity 1.",
    "start": "3020382",
    "end": "3027310"
  },
  {
    "text": "Label everything is the\nthing I'm looking for. Great. Everything is correct. But the specificity will be 0.",
    "start": "3027310",
    "end": "3035740"
  },
  {
    "text": "Because I'll have a bunch of\nthings incorrectly labeled. I could make the specificity\n1, reject everything.",
    "start": "3035740",
    "end": "3043460"
  },
  {
    "text": "Say nothing as an instance. True negatives goes to 1, and\nI'm in a great place there,",
    "start": "3043460",
    "end": "3052069"
  },
  {
    "text": "but my sensitivity goes to 0. I've got a trade-off. As I think about the machine\nlearning algorithm I'm using",
    "start": "3052070",
    "end": "3058680"
  },
  {
    "text": "and my choice of\nthat classifier, I'm going to see\na trade off where I can increase specificity at\nthe cost of sensitivity or vice",
    "start": "3058680",
    "end": "3067260"
  },
  {
    "text": "versa. And you'll see a nice technique\ncalled ROC or Receiver Operator Curve that gives you a sense of\nhow you want to deal with that.",
    "start": "3067260",
    "end": "3074576"
  },
  {
    "text": "And with that, we'll\nsee you next time. We'll take your\nquestion off line if you don't mind, because\nI've run over time. But we'll see you next\ntime where Professor Guttag",
    "start": "3074576",
    "end": "3080763"
  },
  {
    "text": "will show you examples of this.",
    "start": "3080763",
    "end": "3082930"
  }
]
[
  {
    "start": "4490",
    "end": "4490"
  },
  {
    "text": "In the previous video,\nwe preprocessed our data,",
    "start": "4490",
    "end": "7799"
  },
  {
    "text": "and we're now ready to extract\nthe word frequencies to be",
    "start": "7800",
    "end": "11230"
  },
  {
    "text": "used in our prediction problem.",
    "start": "11230",
    "end": "14080"
  },
  {
    "text": "The tm package provides\na function called",
    "start": "14080",
    "end": "16660"
  },
  {
    "text": "DocumentTermMatrix that\ngenerates a matrix where",
    "start": "16660",
    "end": "20390"
  },
  {
    "text": "the rows correspond to\ndocuments, in our case tweets,",
    "start": "20390",
    "end": "24460"
  },
  {
    "text": "and the columns correspond\nto words in those tweets.",
    "start": "24460",
    "end": "28269"
  },
  {
    "text": "The values in the\nmatrix are the number",
    "start": "28270",
    "end": "30470"
  },
  {
    "text": "of times that word\nappears in each argument.",
    "start": "30470",
    "end": "34190"
  },
  {
    "text": "Let's go ahead and\ngenerate this matrix",
    "start": "34190",
    "end": "36340"
  },
  {
    "text": "and call it \"frequencies.\"",
    "start": "36340",
    "end": "39140"
  },
  {
    "text": "So we'll use the\nDocumentTermMatrix function",
    "start": "39140",
    "end": "44530"
  },
  {
    "text": "calls on our corpus that we\ncreated in the previous video.",
    "start": "44530",
    "end": "49489"
  },
  {
    "text": "Let's take a look at our\nmatrix by typing frequencies.",
    "start": "49490",
    "end": "54040"
  },
  {
    "text": "We can see that\nthere are 3,289 terms",
    "start": "54040",
    "end": "58570"
  },
  {
    "text": "or words in our matrix\nand 1,181 documents",
    "start": "58570",
    "end": "64239"
  },
  {
    "text": "or tweets after preprocessing.",
    "start": "64239",
    "end": "67729"
  },
  {
    "text": "Let's see what this\nmatrix looks like using",
    "start": "67730",
    "end": "70230"
  },
  {
    "text": "the inspect function.",
    "start": "70230",
    "end": "72280"
  },
  {
    "text": "So type\ninspect(frequencies[1000:1005, 505:515]).",
    "start": "72280",
    "end": "90369"
  },
  {
    "text": "In this range we see that\nthe word \"cheer\" appears",
    "start": "90370",
    "end": "94210"
  },
  {
    "text": "in the tweet 1005,\nbut \"cheap\" doesn't",
    "start": "94210",
    "end": "98210"
  },
  {
    "text": "appear in any of these tweets.",
    "start": "98210",
    "end": "101509"
  },
  {
    "text": "This data is what\nwe call sparse.",
    "start": "101509",
    "end": "103950"
  },
  {
    "text": "This means that there are\nmany zeros in our matrix.",
    "start": "103950",
    "end": "107600"
  },
  {
    "text": "We can look at what the\nmost popular terms are,",
    "start": "107600",
    "end": "110350"
  },
  {
    "text": "or words, with the\nfunction findFreqTerms.",
    "start": "110350",
    "end": "113380"
  },
  {
    "text": "We want to call this on\nour matrix frequencies,",
    "start": "117900",
    "end": "122530"
  },
  {
    "text": "and then we want to give\nan argument lowFreq, which",
    "start": "122530",
    "end": "127260"
  },
  {
    "text": "is equal to the\nminimum number of times",
    "start": "127260",
    "end": "129679"
  },
  {
    "text": "a term must appear\nto be displayed.",
    "start": "129680",
    "end": "132180"
  },
  {
    "text": "Let's type 20.",
    "start": "132180",
    "end": "134109"
  },
  {
    "text": "We see here 56 different words.",
    "start": "134110",
    "end": "137430"
  },
  {
    "text": "So out of the 3,289\nwords in our matrix,",
    "start": "137430",
    "end": "142370"
  },
  {
    "text": "only 56 words appear at\nleast 20 times in our tweets.",
    "start": "142370",
    "end": "146989"
  },
  {
    "text": "This means that we probably\nhave a lot of terms",
    "start": "146990",
    "end": "149950"
  },
  {
    "text": "that will be pretty useless\nfor our prediction model.",
    "start": "149950",
    "end": "153920"
  },
  {
    "text": "The number of terms is an\nissue for two main reasons.",
    "start": "153920",
    "end": "157010"
  },
  {
    "text": "One is computational.",
    "start": "157010",
    "end": "159180"
  },
  {
    "text": "More terms means more\nindependent variables,",
    "start": "159180",
    "end": "162170"
  },
  {
    "text": "which usually means it takes\nlonger to build our models.",
    "start": "162170",
    "end": "166160"
  },
  {
    "text": "The other is in building\nmodels, as we mentioned",
    "start": "166160",
    "end": "168450"
  },
  {
    "text": "before, the ratio of independent\nvariables to observations",
    "start": "168450",
    "end": "172550"
  },
  {
    "text": "will affect how good the\nmodel will generalize.",
    "start": "172550",
    "end": "176050"
  },
  {
    "text": "So let's remove some terms\nthat don't appear very often.",
    "start": "176050",
    "end": "179670"
  },
  {
    "text": "We'll call the output\nsparse, and we'll use",
    "start": "179670",
    "end": "183260"
  },
  {
    "text": "the\nremoveSparseTerms(frequencies,",
    "start": "183260",
    "end": "184670"
  },
  {
    "text": "0.98).",
    "start": "184670",
    "end": "199670"
  },
  {
    "text": "The sparsity threshold\nworks as follows.",
    "start": "199670",
    "end": "202390"
  },
  {
    "text": "If we say 0.98, this\nmeans to only keep",
    "start": "202390",
    "end": "206400"
  },
  {
    "text": "terms that appear in 2%\nor more of the tweets.",
    "start": "206400",
    "end": "209890"
  },
  {
    "text": "If we say 0.99, that\nmeans to only keep",
    "start": "209890",
    "end": "213920"
  },
  {
    "text": "terms that appear in 1%\nor more of the tweets.",
    "start": "213920",
    "end": "217010"
  },
  {
    "text": "If we say 0.995, that\nmeans to only keep",
    "start": "217010",
    "end": "221569"
  },
  {
    "text": "terms that appear in 0.5%\nor more of the tweets,",
    "start": "221570",
    "end": "225060"
  },
  {
    "text": "about six or more tweets.",
    "start": "225060",
    "end": "226890"
  },
  {
    "text": "We'll go ahead and use\nthis sparsity threshold.",
    "start": "226890",
    "end": "230840"
  },
  {
    "text": "If you type sparse, you\ncan see that there's",
    "start": "230840",
    "end": "233860"
  },
  {
    "text": "only 309 terms in\nour sparse matrix.",
    "start": "233860",
    "end": "237900"
  },
  {
    "text": "This is only about 9% of\nthe previous count of 3,289.",
    "start": "237900",
    "end": "245920"
  },
  {
    "text": "Now let's convert the sparse\nmatrix into a data frame",
    "start": "245920",
    "end": "249860"
  },
  {
    "text": "that we'll be able to use\nfor our predictive models.",
    "start": "249860",
    "end": "252660"
  },
  {
    "text": "We'll call it tweetsSparse and\nuse the as.data.frame function",
    "start": "252660",
    "end": "260640"
  },
  {
    "text": "called on the as.matrix function\ncalled on our matrixsparse.",
    "start": "260640",
    "end": "266730"
  },
  {
    "text": "This convert sparse to a data\nframe called tweetsSparse.",
    "start": "266730",
    "end": "271610"
  },
  {
    "text": "Since R struggles with variable\nnames that start with a number,",
    "start": "271610",
    "end": "275259"
  },
  {
    "text": "and we probably have some words\nhere that start with a number,",
    "start": "275260",
    "end": "278950"
  },
  {
    "text": "let's run the make names\nfunction to make sure",
    "start": "278950",
    "end": "281570"
  },
  {
    "text": "all of our words are\nappropriate variable names.",
    "start": "281570",
    "end": "284560"
  },
  {
    "text": "To do this type COLnames and\nthen in parentheses the name",
    "start": "284560",
    "end": "289540"
  },
  {
    "text": "of our data frame,\ntweetsSparse equals make.names,",
    "start": "289540",
    "end": "295560"
  },
  {
    "text": "and then in parentheses\nagain colnames(tweetsSparse =",
    "start": "295560",
    "end": "297770"
  },
  {
    "text": "make.names(colnames(tweetsSparse)).",
    "start": "297770",
    "end": "299229"
  },
  {
    "text": "This will just convert\nour variable names",
    "start": "302910",
    "end": "305120"
  },
  {
    "text": "to make sure they're\nall appropriate names",
    "start": "305120",
    "end": "307300"
  },
  {
    "text": "before we build our\npredictive models.",
    "start": "307300",
    "end": "309840"
  },
  {
    "text": "You should do this\neach time you've",
    "start": "309840",
    "end": "311440"
  },
  {
    "text": "built a data frame\nusing text analytics.",
    "start": "311440",
    "end": "315570"
  },
  {
    "text": "Now let's add our dependent\nvariable to this data set.",
    "start": "315570",
    "end": "318750"
  },
  {
    "text": "We'll call it\ntweetsSparse$Negative =",
    "start": "318750",
    "end": "320290"
  },
  {
    "text": "tweets$Negative.",
    "start": "320290",
    "end": "320950"
  },
  {
    "text": "Lastly, let's split our\ndata into a training set",
    "start": "331090",
    "end": "334470"
  },
  {
    "text": "and a testing set, putting 70%\nof the data in the training",
    "start": "334470",
    "end": "338290"
  },
  {
    "text": "set.",
    "start": "338290",
    "end": "339400"
  },
  {
    "text": "First we'll have to load the\nlibrary catools so that we",
    "start": "339400",
    "end": "343479"
  },
  {
    "text": "can use the sample\nsplit function.",
    "start": "343480",
    "end": "345860"
  },
  {
    "text": "Then let's set the seed to\n123 and create our split using",
    "start": "345860",
    "end": "351870"
  },
  {
    "text": "sample.split where a\ndependent variable is",
    "start": "351870",
    "end": "355240"
  },
  {
    "text": "tweetsSparse$Negative.",
    "start": "355240",
    "end": "356159"
  },
  {
    "text": "And then our split\nratio will be 0.7.",
    "start": "360660",
    "end": "364810"
  },
  {
    "text": "We'll put 70% of the\ndata in the training set.",
    "start": "364810",
    "end": "369150"
  },
  {
    "text": "Then let's just use subset to\ncreate a treating set called",
    "start": "369150",
    "end": "372949"
  },
  {
    "text": "trainSparse, which will take\na subset of the whole data set",
    "start": "372950",
    "end": "378320"
  },
  {
    "text": "tweetsSparse, but always take\nthe observations for which",
    "start": "378320",
    "end": "381770"
  },
  {
    "text": "split==TRUE.",
    "start": "381770",
    "end": "384030"
  },
  {
    "text": "And we'll create our\ntest set, testSparse,",
    "start": "384030",
    "end": "387280"
  },
  {
    "text": "again using subset to take the\nobservations of tweetsSparse,",
    "start": "387280",
    "end": "391780"
  },
  {
    "text": "but this time for\nwhich split==FALSE.",
    "start": "391780",
    "end": "393430"
  },
  {
    "text": "Our data is now ready, and we\ncan build our predictive model.",
    "start": "396150",
    "end": "399889"
  },
  {
    "text": "In the next video, we'll use\nCART and logistic regression",
    "start": "399890",
    "end": "403670"
  },
  {
    "text": "to predict negative sentiment.",
    "start": "403670",
    "end": "405920"
  }
]
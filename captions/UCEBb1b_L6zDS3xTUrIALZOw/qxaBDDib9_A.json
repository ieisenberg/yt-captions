[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "7410"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "7410",
    "end": "13960"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "13960",
    "end": "19140"
  },
  {
    "text": " PROFESSOR: As the question said,\nwhere are we as far as",
    "start": "19140",
    "end": "25930"
  },
  {
    "text": "the text goes. We're just going to\nstart Chapter 2 today, Poisson processes.",
    "start": "25930",
    "end": "31289"
  },
  {
    "text": "I want to spend about five\nminutes reviewing a little bit about convergence, the things\nwe said last time,",
    "start": "31290",
    "end": "39130"
  },
  {
    "text": "and then move on. There's a big break in the\ncourse, at this point between",
    "start": "39130",
    "end": "46240"
  },
  {
    "text": "Chapter 1 and Chapter 2 in the\nsense that Chapter 1 is very",
    "start": "46240",
    "end": "51570"
  },
  {
    "text": "abstract, a little\ntheoretical. It's dealing with probability\ntheory in general and the most",
    "start": "51570",
    "end": "60750"
  },
  {
    "text": "general theorems in probability\nstated in very simple and elementary form.",
    "start": "60750",
    "end": "66270"
  },
  {
    "text": "But still, we're essentially\nnot dealing with",
    "start": "66270",
    "end": "71490"
  },
  {
    "text": "applications at all. We're dealing with very, very\nabstract things in Chapter 1.",
    "start": "71490",
    "end": "76850"
  },
  {
    "text": "Chapter 2 is just the reverse. A Poisson process is the\nmost concrete thing",
    "start": "76850",
    "end": "82479"
  },
  {
    "text": "you can think of. People use that as a model\nfor almost everything.",
    "start": "82480",
    "end": "88150"
  },
  {
    "text": "Whether it's a reasonable\nmodel or not is another question. But people use it as\na model constantly.",
    "start": "88150",
    "end": "94300"
  },
  {
    "text": "And everything about\nit is simple. For a Poisson process, you can\nalmost characterize it as",
    "start": "94300",
    "end": "101570"
  },
  {
    "text": "saying everything you could\nthink of about a Poisson process is either true or\nit's obviously false.",
    "start": "101570",
    "end": "109270"
  },
  {
    "text": "And when you get to\nthat point, you understand Poisson processes. And you can go on to other\nthings and never have to",
    "start": "109270",
    "end": "115630"
  },
  {
    "text": "really think about them\nvery hard again. Because at that point, you\nreally understand them.",
    "start": "115630",
    "end": "120820"
  },
  {
    "text": "OK. So let's go on and review\nthings a little bit.",
    "start": "120820",
    "end": "126130"
  },
  {
    "text": "What's convergence and how does\nit affect sequences of IID random variables?",
    "start": "126130",
    "end": "132550"
  },
  {
    "text": "Convergence is more\ngeneral than just IID random variables. But it applies to any sequence\nof random variables.",
    "start": "132550",
    "end": "141700"
  },
  {
    "text": "And the definition is that a\nsequence of random variables converges in distribution to\nanother random variable z, if",
    "start": "141700",
    "end": "150970"
  },
  {
    "text": "the limit, as n goes to\ninfinity, of the distribution",
    "start": "150970",
    "end": "156120"
  },
  {
    "text": "function of zn converges to the distribution function of z.",
    "start": "156120",
    "end": "161700"
  },
  {
    "text": "For this definition to make\nsense, it doesn't matter what z is. z can be outside of\nthe sample space even.",
    "start": "161700",
    "end": "172880"
  },
  {
    "text": "The only thing we're interested\nin is this particular distribution\nfunction. So what we're really saying is\na sequence of distributions",
    "start": "172880",
    "end": "180760"
  },
  {
    "text": "converges to another\ndistribution function if in fact this limit occurs at every\npoint where f of z is",
    "start": "180760",
    "end": "192980"
  },
  {
    "text": "continuous. In other words, if f of z is\ndiscontinuous someplace, we had an example of that where\nwe're looking at the law of",
    "start": "192980",
    "end": "200440"
  },
  {
    "text": "large numbers and the\ndistribution function. Looked at in the right way\nwas a step function.",
    "start": "200440",
    "end": "207330"
  },
  {
    "text": "It wasn't continuous\nat the step. And therefore, you can't expect\nanything to be said",
    "start": "207330",
    "end": "214000"
  },
  {
    "text": "about that. So the typical example of\nconvergence in distribution is",
    "start": "214000",
    "end": "220710"
  },
  {
    "text": "the central limit theorem which\nsays, if x1, x2 are IID, they have a variance\nsigma squared.",
    "start": "220710",
    "end": "227900"
  },
  {
    "text": "And if s sub n the sum of these\nrandom variables is a sum of x1 to xn, then zn\nis the normalized sum.",
    "start": "227900",
    "end": "236409"
  },
  {
    "text": "In other words, you\ntake this sum. You subtract off\nthe mean of it.",
    "start": "236410",
    "end": "241530"
  },
  {
    "text": "And I think in the reproduction\nof these slides that you have, I think that\nn, right there was--",
    "start": "241530",
    "end": "256232"
  },
  {
    "text": "here we go. That's the other y. I think that n was left off.",
    "start": "256232",
    "end": "264280"
  },
  {
    "text": "If that n wasn't left off,\nanother n was left off. It's obviously needed there.",
    "start": "264280",
    "end": "269470"
  },
  {
    "text": "This is a normalized random\nvariable because the variance of sn and of sn minus nx bar is\njust sigma squared times n.",
    "start": "269470",
    "end": "282120"
  },
  {
    "text": "Because they're any of these\nrandom variables. So we're dividing by the\nstandard deviation.",
    "start": "282120",
    "end": "289020"
  },
  {
    "text": "So this is a random variable\nfor each n which has a standard deviation\n1 and mean 0.",
    "start": "289020",
    "end": "297250"
  },
  {
    "text": "So it's normalized. And it converges in distribution\nto a Gaussian random variable of mean 0 and\nstandard deviation 1.",
    "start": "297250",
    "end": "306469"
  },
  {
    "text": "This notation here is\nsort of standard. And we'll use it at\nvarious times. It means a Gaussian distribution\nwith mean 0 and",
    "start": "306470",
    "end": "315780"
  },
  {
    "text": "variance 1. So for an example of that, if\nx1, x2, so forth, are IID with",
    "start": "315780",
    "end": "322270"
  },
  {
    "text": "mean expected value of x and the\nsum here, then sn over n",
    "start": "322270",
    "end": "330410"
  },
  {
    "text": "converges in distribution to\nthe deterministic random variable x bar.",
    "start": "330410",
    "end": "336230"
  },
  {
    "text": "That's a nice example of this. So we have two examples of\nconvergence and distribution.",
    "start": "336230",
    "end": "342850"
  },
  {
    "text": "And that's what that says.",
    "start": "342850",
    "end": "349500"
  },
  {
    "text": "So next, a sequence of random\nvariables converges in probability.",
    "start": "349500",
    "end": "355700"
  },
  {
    "text": "When we start talking about\nconvergence in probability, there's another idea which we\nare going to bring in, mostly",
    "start": "355700",
    "end": "364360"
  },
  {
    "text": "in Chapter 4 when we get\nto it, which is called convergence with\nprobability 1.",
    "start": "364360",
    "end": "369840"
  },
  {
    "text": "Don't confuse those two\nthings because they're very different ideas.",
    "start": "369840",
    "end": "374880"
  },
  {
    "text": "Because people confuse them,\nmany people call convergence",
    "start": "374880",
    "end": "380050"
  },
  {
    "text": "with probability 1 almost sure\nconvergence or almost everywhere convergence.",
    "start": "380050",
    "end": "387030"
  },
  {
    "text": "I don't like that notation. So I'll stay with the notation\nwith probability 1.",
    "start": "387030",
    "end": "394090"
  },
  {
    "text": "But it means something very\ndifferent than converging in probability. So the definition is that a\nset of random variables",
    "start": "394090",
    "end": "402120"
  },
  {
    "text": "converges in probability to some\nother random variable if",
    "start": "402120",
    "end": "408280"
  },
  {
    "text": "this limit holds true. And you remember that diagram\nwe showed you last time.",
    "start": "408280",
    "end": "414840"
  },
  {
    "text": "Let me just quickly redraw it. ",
    "start": "414840",
    "end": "421124"
  },
  {
    "text": "Have this set of distribution\nfunctions. Here's the mean here,\nx bar, limits,",
    "start": "421124",
    "end": "429370"
  },
  {
    "text": "plus and minus epsilon. And this sequence of random\nvariables has to come in down",
    "start": "429370",
    "end": "438000"
  },
  {
    "text": "here and go out up there. This distance here and the\ndistance there gets very small",
    "start": "438000",
    "end": "447930"
  },
  {
    "text": "and goes to 0 as n\ngets very large. And that's the meaning\nof what this says. So if you don't remember that\ndiagram, go look at it in the",
    "start": "447930",
    "end": "455860"
  },
  {
    "text": "lecture notes last time or in\nthe text where it's explained in a lot more detail.",
    "start": "455860",
    "end": "462830"
  },
  {
    "text": "So the typical example of that\nis the weak law of large numbers of x1, blah, blah,\nblah, are IID with mean,",
    "start": "462830",
    "end": "472370"
  },
  {
    "text": "expected value of x. Remember now that we say that\na random variable has a mean",
    "start": "472370",
    "end": "478170"
  },
  {
    "text": "if the expected value of the\nabsolute value of x is finite.",
    "start": "478170",
    "end": "484370"
  },
  {
    "text": "It's not enough to have things\nwhich have a distribution",
    "start": "484370",
    "end": "489510"
  },
  {
    "text": "function which is badly behaved\nfor very big x, and",
    "start": "489510",
    "end": "495060"
  },
  {
    "text": "badly behaved for very small\nx, and the two of them cancelled out. That doesn't work. That doesn't mean\nyou have a mean.",
    "start": "495060",
    "end": "501620"
  },
  {
    "text": "You need the expected value\nas the absolute value of x to be finite. ",
    "start": "501620",
    "end": "508240"
  },
  {
    "text": "Now, the weak law of large\nnumbers says that the random",
    "start": "508240",
    "end": "513529"
  },
  {
    "text": "variables sn over n, in other\nwords, the sample average, in",
    "start": "513530",
    "end": "518929"
  },
  {
    "text": "fact converges to the\ndeterministic random variable x bar.",
    "start": "518929",
    "end": "524839"
  },
  {
    "text": "And that convergence is\nconvergence in probability. Which means it's this kind\nof convergence here.",
    "start": "524840",
    "end": "530529"
  },
  {
    "text": "Which means that it's going\nto a distribution which is a step function. There's a very big difference\nbetween a distribution which",
    "start": "530530",
    "end": "539010"
  },
  {
    "text": "is a step function and a\ndistribution which is something like a Gaussian\nrandom variable.",
    "start": "539010",
    "end": "544510"
  },
  {
    "text": "And what the big difference is\nis that the random variables that are converging to each\nother, if a bunch of random",
    "start": "544510",
    "end": "551570"
  },
  {
    "text": "variables are all converging to\na constant, then they all have to be very close\nto each other.",
    "start": "551570",
    "end": "556730"
  },
  {
    "text": "And that's the property you're\nreally interested in in",
    "start": "556730",
    "end": "561930"
  },
  {
    "text": "convergence in probability. So convergence in mean square,\nfinally, last definition which",
    "start": "561930",
    "end": "569430"
  },
  {
    "text": "is easy to deal with. If a sequence of random\nvariables converges in the",
    "start": "569430",
    "end": "574990"
  },
  {
    "text": "mean square to another random\nvariable, if this limit of the expected value, of the\ndifference between the two",
    "start": "574990",
    "end": "583149"
  },
  {
    "text": "random variables squared, goes\nto 0, this n gets big. That's what we had with the weak\nlaw of large numbers if",
    "start": "583150",
    "end": "591500"
  },
  {
    "text": "you assume that the random\nvariables each had a variance. ",
    "start": "591500",
    "end": "598089"
  },
  {
    "text": "So on to something new. On to Poisson processes. We first have to explain what\nan arrival process is.",
    "start": "598090",
    "end": "605830"
  },
  {
    "text": "And then we can get into\nPoisson processes. Because arrival processes are\na very broad class of",
    "start": "605830",
    "end": "613540"
  },
  {
    "text": "stochastic processes, in fact\ndiscrete stochastic processes. But they have this property of\nbeing characterized by things",
    "start": "613540",
    "end": "621750"
  },
  {
    "text": "happening at various random\ninstance of time as opposed to",
    "start": "621750",
    "end": "627090"
  },
  {
    "text": "a noise waveform or something\nof that sort. So an arrival process is a\nsequence of increasing random",
    "start": "627090",
    "end": "634390"
  },
  {
    "text": "variables, 0 less than\ns1, less than s2. What's it mean for a random\nvariable s1 to be less than a",
    "start": "634390",
    "end": "642850"
  },
  {
    "text": "random variable s2? It means exactly the\nsame thing as it",
    "start": "642850",
    "end": "647870"
  },
  {
    "text": "means for real numbers. s1 is less than s2 if the random\nvariable s2 minus s1 is",
    "start": "647870",
    "end": "656850"
  },
  {
    "text": "a positive random variable,\nnamely if it only takes on non-negative values for all\nomega in the sample space or",
    "start": "656850",
    "end": "666520"
  },
  {
    "text": "for all omega except for some\npeculiar set of probability 0.",
    "start": "666520",
    "end": "673060"
  },
  {
    "text": "The differences in these arrival\nepochs, why do I call",
    "start": "673060",
    "end": "679050"
  },
  {
    "text": "them arrival epochs? Why do other people call\nthem arrival epochs? Because time is something which\ngets used so often here",
    "start": "679050",
    "end": "687780"
  },
  {
    "text": "that it gets confusing. So it's nice to call one thing\nepochs instead of time. And then you know what you're\ntalking about a little better.",
    "start": "687780",
    "end": "695930"
  },
  {
    "text": "The difference is s sub i minus\ns sub i minus 1 for all",
    "start": "695930",
    "end": "702070"
  },
  {
    "text": "i greater than or equal to 2\nhere, with x1 equal to s1.",
    "start": "702070",
    "end": "709040"
  },
  {
    "text": "These are called interarrival\ntimes and the si are called arrival epochs. The picture here really\nshows it all.",
    "start": "709040",
    "end": "718170"
  },
  {
    "text": "Here we have a sequence of\narrival instance, which is where these arrivals occur.",
    "start": "718170",
    "end": "724260"
  },
  {
    "text": "By definition, x1 is the time at\nwhich is the first arrival",
    "start": "724260",
    "end": "729970"
  },
  {
    "text": "occurs, x2 is the difference\nbetween the time when the second arrival occurs and\nthe first arrival",
    "start": "729970",
    "end": "736030"
  },
  {
    "text": "occurs, and so forth. n of t is the number of arrivals\nthat have occurred up",
    "start": "736030",
    "end": "741560"
  },
  {
    "text": "until time t. Which is, if we draw a staircase\nfunction for each of",
    "start": "741560",
    "end": "747280"
  },
  {
    "text": "these arrivals, n of t\nis just the value of that staircase function.",
    "start": "747280",
    "end": "752310"
  },
  {
    "text": "In other words, the counting\nprocess, the arrival counting process-- here's another typo in the\nnotes that you've got.",
    "start": "752310",
    "end": "759399"
  },
  {
    "text": "It calls it Poisson\ncounting process. It should be arrival\ncounting process. ",
    "start": "759400",
    "end": "768540"
  },
  {
    "text": "What this staircase function\nis is in fact the counting process.",
    "start": "768540",
    "end": "774120"
  },
  {
    "text": "It says how many arrivals\nthere have been up until time t. And every once in a while,\nthat jumps up by 1.",
    "start": "774120",
    "end": "780320"
  },
  {
    "text": "So it keeps increasing by\n1 at various times. So that's the arrival\ncounting process.",
    "start": "780320",
    "end": "786600"
  },
  {
    "text": "The important thing to get out\nof this is if you understand",
    "start": "786600",
    "end": "791970"
  },
  {
    "text": "everything about these random\nvariables, then you understand everything about these\nrandom variables.",
    "start": "791970",
    "end": "798170"
  },
  {
    "text": "And then you understand\neverything about these random variables. There's a countable number of\nthese random variables.",
    "start": "798170",
    "end": "805950"
  },
  {
    "text": "There's a countable number of\nthese random variables. There's an unaccountably\ninfinite number of these",
    "start": "805950",
    "end": "811230"
  },
  {
    "text": "random variables. In other words, for every\nt, n of t is a different random variable.",
    "start": "811230",
    "end": "817240"
  },
  {
    "text": "I mean, it tends to be the\nsame for relatively large intervals of t sometimes.",
    "start": "817240",
    "end": "824020"
  },
  {
    "text": "But this is a different random\nvariable for each value of t.",
    "start": "824020",
    "end": "829110"
  },
  {
    "text": "So let's proceed with that. A sample path or sample function\nof the process is a",
    "start": "829110",
    "end": "836970"
  },
  {
    "text": "sequence of sample values. That's the same as we\nhave everywhere. You look at a sample point\nof the process.",
    "start": "836970",
    "end": "845450"
  },
  {
    "text": "Sample point of the whole\nprobability space maps into",
    "start": "845450",
    "end": "853160"
  },
  {
    "text": "this sequence of random\nvariables, s1, s2, s3, and so forth.",
    "start": "853160",
    "end": "858990"
  },
  {
    "text": "If you know what the sample\nvalue is of each one of these random variables, then in fact,\nyou can draw this step",
    "start": "858990",
    "end": "867570"
  },
  {
    "text": "function here. If you know the value, the\nsample value, of each one of these, in the same way,\nyou can again",
    "start": "867570",
    "end": "877640"
  },
  {
    "text": "draw this step function. And if you know what the\nsubfunction is, the step function in fact is the sample\nvalue of n of t.",
    "start": "877640",
    "end": "886390"
  },
  {
    "text": "Now, there's one thing a\nlittle peculiar here. Each sample path corresponds\nto a",
    "start": "886390",
    "end": "893620"
  },
  {
    "text": "particular staircase function. And the process can be viewed\nas the ensemble with joint",
    "start": "893620",
    "end": "898880"
  },
  {
    "text": "probability distributions of\nsuch staircase functions. Now, what does all that\ngobbledygook mean?",
    "start": "898880",
    "end": "907279"
  },
  {
    "text": "Very, very often in probability theory, we draw pictures. And these pictures are pictures\nof what happens to",
    "start": "907280",
    "end": "915790"
  },
  {
    "text": "random variables. And there's a cheat\nin all of that. And the cheat here is that in\nfact, this step function here",
    "start": "915790",
    "end": "926160"
  },
  {
    "text": "is just a generic\nstep function. These points at which changes\noccur are generic values at",
    "start": "926160",
    "end": "934860"
  },
  {
    "text": "which changes occur. And we're representing those\nvalues as random variables.",
    "start": "934860",
    "end": "941400"
  },
  {
    "text": "When you represent these as\nrandom variables, this whole function here, namely n\nof t itself, becomes--",
    "start": "941400",
    "end": "948010"
  },
  {
    "start": "948010",
    "end": "956510"
  },
  {
    "text": "if you have a particular set\nof values for each one of these, then you have a\nparticular staircase function.",
    "start": "956510",
    "end": "963140"
  },
  {
    "text": "With that particular staircase\nfunction, you have a particular sample\npath for n of t.",
    "start": "963140",
    "end": "969860"
  },
  {
    "text": "In other words, a sample path\nfor any set of these random variables-- the arrival epochs,\nor the interarrival",
    "start": "969860",
    "end": "976620"
  },
  {
    "text": "intervals, or n of\nt for each t-- all of these are equivalent\nto each other.",
    "start": "976620",
    "end": "982399"
  },
  {
    "text": "For this reason, when we talk\nabout arrival processes, it's",
    "start": "982400",
    "end": "989130"
  },
  {
    "text": "a little different than\nwhat we usually do. Because usually, we say a random\nprocess is a sequence",
    "start": "989130",
    "end": "996470"
  },
  {
    "text": "or an uncountable number\nof random variables. Here, just because we can\ndescribe it in three different",
    "start": "996470",
    "end": "1003470"
  },
  {
    "text": "ways, this same stochastic\nprocess gets described either",
    "start": "1003470",
    "end": "1011329"
  },
  {
    "text": "as a sequence of interarrival\nintervals, or as a sequence of",
    "start": "1011330",
    "end": "1016700"
  },
  {
    "text": "arrival epochs, or as a\ncountable number these n of t random variables.",
    "start": "1016700",
    "end": "1023009"
  },
  {
    "text": "And from now on, we make no\ndistinction between any of these things. We will, every once in while,\nhave to remind ourselves what",
    "start": "1023010",
    "end": "1031559"
  },
  {
    "text": "these pictures mean because\nthey look very simple. They look like the pictures\nof functions that",
    "start": "1031560",
    "end": "1037180"
  },
  {
    "text": "you're used to drawing. But they don't really\nmean the same thing. Because this picture is drawing\na generic sample path.",
    "start": "1037180",
    "end": "1045579"
  },
  {
    "text": "For that generic sample path,\nyou have a set of sample values for the Xs, a sample path\nfor the arrival epochs, a",
    "start": "1045579",
    "end": "1057580"
  },
  {
    "text": "sample set of values\nfor n of t. And when we draw the picture\ncalling these random",
    "start": "1057580",
    "end": "1064050"
  },
  {
    "text": "variables, we really\nmean the set of all such step functions. And we just automatically use\nall those properties and those",
    "start": "1064050",
    "end": "1071340"
  },
  {
    "text": "relationships. So it's not quite as simple as\nwhat it appears to be, but",
    "start": "1071340",
    "end": "1077510"
  },
  {
    "text": "it's almost as simple.  You can also see that any sample\npath can be specified",
    "start": "1077510",
    "end": "1086279"
  },
  {
    "text": "by the sample values n of t for\nall t, by si for all i, or by xi for all i.",
    "start": "1086280",
    "end": "1093050"
  },
  {
    "text": "So that essentially, an arrival\nprocess is specified by any one of these things.",
    "start": "1093050",
    "end": "1098309"
  },
  {
    "text": "That's exactly what\nI just said. The major relation we need to\nrelate the counting process to",
    "start": "1098310",
    "end": "1105720"
  },
  {
    "text": "the arrival process, well,\nthere's one relationship here,",
    "start": "1105720",
    "end": "1111039"
  },
  {
    "text": "which is perhaps the simplest\nrelationship. But this relationship is a nice\nrelationship to say what",
    "start": "1111040",
    "end": "1118790"
  },
  {
    "text": "n of t is if you know\nwhat s sub n is. It's not quite so nice if you\nknow what n of t is to figure",
    "start": "1118790",
    "end": "1128429"
  },
  {
    "text": "what s sub n is. I mean, the information is\ntucked into the statement, but",
    "start": "1128430",
    "end": "1133960"
  },
  {
    "text": "it's tucked in a more convenient\nway into this statement down here.",
    "start": "1133960",
    "end": "1139280"
  },
  {
    "text": "This statement, I can see it\nnow after many years of",
    "start": "1139280",
    "end": "1144520"
  },
  {
    "text": "dealing with it. I'm sure that you can\nsee it if you stare",
    "start": "1144520",
    "end": "1150400"
  },
  {
    "text": "at it for five minutes.  You will keep forgetting\nthe intuitive picture",
    "start": "1150400",
    "end": "1156899"
  },
  {
    "text": "that goes with it. So I suggest that this is one\nof the rare things in this course that you just\nought to remember.",
    "start": "1156900",
    "end": "1164779"
  },
  {
    "text": "And then once you remember\nit, you can always figure out why it's true. Here's the reason\nwhy it's true.",
    "start": "1164780",
    "end": "1171670"
  },
  {
    "text": "If s sub n is equal to tau for\nsome tau less than or equal to t, then n of tau has\nto be equal to n.",
    "start": "1171670",
    "end": "1180466"
  },
  {
    "text": "If s sub n is equal to tau,\nhere's the picture here, except there's not a tau here. If s sub 2 is equal to\ntau, then n of 2--",
    "start": "1180466",
    "end": "1192180"
  },
  {
    "text": "these are right continuous,\nso n of 2 is equal to 2. And therefore, n of tau is less\nthan or equal to n of t.",
    "start": "1192180",
    "end": "1201100"
  },
  {
    "text": "So that's the whole\nreason down there. You can turn this\nargument around.",
    "start": "1201100",
    "end": "1206350"
  },
  {
    "text": "You can start out with n of t is\ngreater than or equal to n.",
    "start": "1206350",
    "end": "1212160"
  },
  {
    "text": "It means n of t is equal\nto some particular n. And turn the argument\nupside down.",
    "start": "1212160",
    "end": "1218030"
  },
  {
    "text": "And you get the same argument. So this tells you\nwhat this is.",
    "start": "1218030",
    "end": "1225800"
  },
  {
    "text": "This tells you what this is. If you do this for every n and\nevery t, then you do this for",
    "start": "1225800",
    "end": "1232290"
  },
  {
    "text": "every n and every t. It's a very bizarre statement\nbecause usually when you have",
    "start": "1232290",
    "end": "1240590"
  },
  {
    "text": "relationships between functions,\nyou don't have the Ns and the Ts switching\naround.",
    "start": "1240590",
    "end": "1247380"
  },
  {
    "text": "And in this case, the\nn is the subscript. That's the thing which says\nwhich random variable you're",
    "start": "1247380",
    "end": "1252620"
  },
  {
    "text": "talking about. And over here, t is the thing\nwhich says what random",
    "start": "1252620",
    "end": "1257669"
  },
  {
    "text": "variable you're talking about. So it's peculiar\nin that sense. It's a statement which\nrequires a",
    "start": "1257670",
    "end": "1263440"
  },
  {
    "text": "little bit of thought. I apologize for dwelling\non it because once you see it, it's obvious.",
    "start": "1263440",
    "end": "1269580"
  },
  {
    "text": "But many of these obvious\nthings are not obvious. ",
    "start": "1269580",
    "end": "1279029"
  },
  {
    "text": "What we're going to do as we\nmove on is we're going to talk about these arrival processes in\nany of these three ways we",
    "start": "1279030",
    "end": "1286039"
  },
  {
    "text": "choose to talk about them. And we're going to go back\nand forth between them. And with Poisson processes,\nthat's particularly easy.",
    "start": "1286040",
    "end": "1294670"
  },
  {
    "text": "We can't do a whole lot more\nwith arrival processes. They're just too complicated.",
    "start": "1294670",
    "end": "1299910"
  },
  {
    "text": "I mean, arrival processes\ninvolve almost any kind of thing where things happen at\nvarious points in time.",
    "start": "1299910",
    "end": "1307790"
  },
  {
    "text": "So we simplify it to something\ncalled a renewal process. Renewal processes are the\ntopic of Chapter 4.",
    "start": "1307790",
    "end": "1315750"
  },
  {
    "text": "When you get to Chapter 4, you\nwill perhaps say that renewal processes are too complicated\nto talk about also.",
    "start": "1315750",
    "end": "1323320"
  },
  {
    "text": "I hope after we finish Chapter\n4, you won't believe that it's too complicated to talk about.",
    "start": "1323320",
    "end": "1328990"
  },
  {
    "text": "But these are fairly complicated\nprocesses. But even here, it's an arrival\nprocess where the interarrival",
    "start": "1328990",
    "end": "1336370"
  },
  {
    "text": "intervals are independent and\nidentically distributed. Finally, a Poisson process is\na renewal process for which",
    "start": "1336370",
    "end": "1345730"
  },
  {
    "text": "each x sub i has an exponential\ndistribution. Each interarrival has to have\nthe same distribution because",
    "start": "1345730",
    "end": "1355070"
  },
  {
    "text": "since it's a renewal process,\nthese are all IID. And we let this distribution\nfunction X be the generic",
    "start": "1355070",
    "end": "1364040"
  },
  {
    "text": "random variable. And this is talking about\nthe distribution function of all of them.",
    "start": "1364040",
    "end": "1369610"
  },
  {
    "text": "I don't know whether that 1\nminus is in the slides I passed out. There's one kind of\nerror like that.",
    "start": "1369610",
    "end": "1377909"
  },
  {
    "text": "And I'm not sure where it is. So anyway, lambda is some fixed\nparameter called the",
    "start": "1377910",
    "end": "1383090"
  },
  {
    "text": "rate of the Poisson process. So for each lambda greater than\n0, you have a Poisson",
    "start": "1383090",
    "end": "1389770"
  },
  {
    "text": "process where each of these\ninterarrival intervals are exponential random variables\nof rate lambda.",
    "start": "1389770",
    "end": "1398299"
  },
  {
    "text": "So that defines a\nPoisson process. So we can all go home now\nbecause we now know everything about Poisson processes\nin principle.",
    "start": "1398300",
    "end": "1406889"
  },
  {
    "text": "Everything we're going to say\nfrom now on comes from this one simple statement here that\nthese interarrival intervals",
    "start": "1406890",
    "end": "1415620"
  },
  {
    "text": "are exponential. There's something very, very\nspecial about this exponential distribution.",
    "start": "1415620",
    "end": "1421740"
  },
  {
    "text": "And that's what makes Poisson\nprocesses so very special. ",
    "start": "1421740",
    "end": "1433570"
  },
  {
    "text": "And that special thing is this\nmemoryless property. A random variable is memoryless\nif it's positive.",
    "start": "1433570",
    "end": "1441759"
  },
  {
    "text": "And for all real t greater than\n0 and x greater than 0, the probability that x is\ngreater than t plus x is equal",
    "start": "1441760",
    "end": "1450580"
  },
  {
    "text": "to the probability that x is\ngreater than t times the probability that x is\ngreater than x.",
    "start": "1450580",
    "end": "1456260"
  },
  {
    "text": "If you plug that in, then the\nstatement is the same whether",
    "start": "1456260",
    "end": "1461470"
  },
  {
    "text": "you're dealing with densities,\nor PMFs, or distribution function.",
    "start": "1461470",
    "end": "1467640"
  },
  {
    "text": "You get the same product\nrelationship in each case. Since the interarrival interval\nis exponential, the",
    "start": "1467640",
    "end": "1474470"
  },
  {
    "text": "probability that a random\nvariable x is greater than some particular value x is equal\nto e to the minus lambda",
    "start": "1474470",
    "end": "1483570"
  },
  {
    "text": "x for x greater than zero. This you'll recognize, not as a\ndistribution function but as",
    "start": "1483570",
    "end": "1490870"
  },
  {
    "text": "the complementary distribution\nfunction. It's the probability that\nX is greater than x.",
    "start": "1490870",
    "end": "1496559"
  },
  {
    "text": "So it's the complementary\ndistribution function evaluated at the value of x.",
    "start": "1496560",
    "end": "1502430"
  },
  {
    "text": "This is an exponential\nwhich is going down. So these random variables\nhave a probability",
    "start": "1502430",
    "end": "1511650"
  },
  {
    "text": "density which is this.",
    "start": "1511650",
    "end": "1516694"
  },
  {
    "text": "This is f sub x of X. And they\nhave a distribution function",
    "start": "1516694",
    "end": "1525110"
  },
  {
    "text": "which is this. And they have a complementary\ndistribution",
    "start": "1525110",
    "end": "1530420"
  },
  {
    "text": "function which is this. Now, this is f of c.",
    "start": "1530420",
    "end": "1535940"
  },
  {
    "text": "This is f. So there's nothing\nmuch to them. ",
    "start": "1535940",
    "end": "1542779"
  },
  {
    "text": "And now there's a theorem\nwhich says that a random variable is memoryless if and\nonly if it is exponential.",
    "start": "1542780",
    "end": "1552200"
  },
  {
    "text": "We just showed here that an\nexponential random variable is memoryless. To show it the other way\nis almost obvious.",
    "start": "1552200",
    "end": "1562700"
  },
  {
    "text": "You take this definition here. You take the logarithm of\neach of these sides.",
    "start": "1562700",
    "end": "1568600"
  },
  {
    "text": "When you get the logarithm of\nthis, it says the logarithm of the probability x is greater\nthan p plus x is the logarithm",
    "start": "1568600",
    "end": "1578070"
  },
  {
    "text": "of this plus the logarithm\nof this. What we have to show to get an\nexponential is that this",
    "start": "1578070",
    "end": "1585600"
  },
  {
    "text": "logarithm is linear\nin its argument t.",
    "start": "1585600",
    "end": "1591429"
  },
  {
    "text": "Now, if you have this is equal\nto the sum of this and this",
    "start": "1591430",
    "end": "1596990"
  },
  {
    "text": "for all t and x, it's sort\nof says it's linear. There's an exercise, I think\nit's Exercise 2.4, which shows",
    "start": "1596990",
    "end": "1607235"
  },
  {
    "text": "that you have to be a\nlittle bit careful. Or at least as it points\nout, very, very picky",
    "start": "1607235",
    "end": "1613310"
  },
  {
    "text": "mathematicians have to be a\nlittle bit careful with that. And you can worry about that\nor not as you choose.",
    "start": "1613310",
    "end": "1621980"
  },
  {
    "text": "So that's the theorem. That's why Poisson processes\nare special.",
    "start": "1621980",
    "end": "1627140"
  },
  {
    "text": "And that's why we can\ndo all the things we can do with them. The reason why we call it\nmemoryless is more apparent if",
    "start": "1627140",
    "end": "1635400"
  },
  {
    "text": "we use conditional\nprobabilities. With conditional probabilities,\nthe probability that the random variable X is\ngreater than t plus x, given",
    "start": "1635400",
    "end": "1645390"
  },
  {
    "text": "that it's greater than t, is\nequal to the probability that X is greater than x.",
    "start": "1645390",
    "end": "1651409"
  },
  {
    "text": "If people in a checkout line\nhave exponential service times and you've waited 15 minutes for\nthe person in front, what",
    "start": "1651410",
    "end": "1660420"
  },
  {
    "text": "is his or her remaining service\ntime, assuming the service time is exponential?",
    "start": "1660420",
    "end": "1666760"
  },
  {
    "text": "What's the answer? You've waited 15 minutes. Your original service time is\nexponential with rate lambda.",
    "start": "1666760",
    "end": "1673460"
  },
  {
    "text": "What's the remaining\nservice time? Well, the answer is\nit's exponential.",
    "start": "1673460",
    "end": "1678559"
  },
  {
    "text": "That's this memoryless\nproperty. It's called memoryless because\nthe random variable doesn't",
    "start": "1678560",
    "end": "1685880"
  },
  {
    "text": "remember how long it\nhasn't happened. ",
    "start": "1685880",
    "end": "1691880"
  },
  {
    "text": "So you can think of an\nexponential random variable as something which takes\nplace in time.",
    "start": "1691880",
    "end": "1697519"
  },
  {
    "text": "And in each instant of time, it\nmight or might not happen. And if it hasn't happened yet,\nthere's still the same",
    "start": "1697520",
    "end": "1704110"
  },
  {
    "text": "probability in every remaining\nincrement that it's going to happen then. So you haven't gained anything\nand you haven't lost anything",
    "start": "1704110",
    "end": "1712510"
  },
  {
    "text": "by having to wait this long.  Here's an interesting question\nwhich you can tie yourself in",
    "start": "1712510",
    "end": "1721120"
  },
  {
    "text": "knots for a little bit. Has your time waiting\nbeen wasted? ",
    "start": "1721120",
    "end": "1728360"
  },
  {
    "text": "Namely the time you still have\nto wait is exponential with the same rate as\nit was before.",
    "start": "1728360",
    "end": "1736700"
  },
  {
    "text": "So the expected amount of time\nyou have to wait is still the same as when you got into line\n15 minutes ago with this one",
    "start": "1736700",
    "end": "1747789"
  },
  {
    "text": "very slow person in\nfront of you. So have you wasting your time?",
    "start": "1747790",
    "end": "1754399"
  },
  {
    "text": "Well, you haven't\ngained anything.  But you haven't really wasted\nyour time either.",
    "start": "1754400",
    "end": "1761510"
  },
  {
    "text": "Because if you have to get\nserved in that line, then at",
    "start": "1761510",
    "end": "1767210"
  },
  {
    "text": "some point, you're going to\nhave to go in that line. And you might look for a time\nwhen the line is very short.",
    "start": "1767210",
    "end": "1774370"
  },
  {
    "text": "You might be lucky and find\na time when the line is completely empty. And then you start getting\nserved right away.",
    "start": "1774370",
    "end": "1780360"
  },
  {
    "text": "But if you ignore those issues,\nthen in fact, in a",
    "start": "1780360",
    "end": "1787760"
  },
  {
    "text": "sense, you have wasted\nyour time. Another more interesting\nquestion then is why do you",
    "start": "1787760",
    "end": "1794390"
  },
  {
    "text": "move to another line if somebody\ntakes a long time? All of you have had\nthis experience.",
    "start": "1794390",
    "end": "1800160"
  },
  {
    "text": "You're in a supermarket. Or you're at an airplane counter\nor any of the places",
    "start": "1800160",
    "end": "1808130"
  },
  {
    "text": "where you have to wait\nfor service. There's somebody, one person in\nfront of you, who has been",
    "start": "1808130",
    "end": "1814200"
  },
  {
    "text": "there forever. And it seems as if they're going\nto stay there forever. You notice another line\nthat only has one",
    "start": "1814200",
    "end": "1821200"
  },
  {
    "text": "person being served. And most of us, especially very\nimpatient people like me,",
    "start": "1821200",
    "end": "1827595"
  },
  {
    "text": "I'm going to walk over and\nget into that other line. And the question is, is that\nrational or isn't it rational?",
    "start": "1827595",
    "end": "1836179"
  },
  {
    "text": "If the service times are exponential, it is not rational. It doesn't make any difference\nwhether I stay where I am or",
    "start": "1836180",
    "end": "1844030"
  },
  {
    "text": "go to the other line. If the service times are fixed\nduration, namely suppose every",
    "start": "1844030",
    "end": "1851110"
  },
  {
    "text": "service time takes 10 minutes\nand I've waited for a long time, is it rational for me\nto move to the other line?",
    "start": "1851110",
    "end": "1859409"
  },
  {
    "text": "Absolutely not because I'm\nalmost at the end of that 10 minutes now.",
    "start": "1859410",
    "end": "1865190"
  },
  {
    "text": "And I'm about to be served. So why do we move? Is it just psychology, that\nwe're very impatient?",
    "start": "1865190",
    "end": "1874020"
  },
  {
    "text": "I don't think so. I think it's because we have all\nseen that an awful lot of",
    "start": "1874020",
    "end": "1879090"
  },
  {
    "text": "lines, particularly airline\nreservation lines, and if your plane doesn't fly or something,\nand you're trying",
    "start": "1879090",
    "end": "1885950"
  },
  {
    "text": "to get rescheduled, or any of\nthese things, the service time",
    "start": "1885950",
    "end": "1891960"
  },
  {
    "text": "is worse than Poisson in the\nsense that if you've waited for 10 minutes, your expected\nremaining waiting time is",
    "start": "1891960",
    "end": "1901390"
  },
  {
    "text": "greater than it was before\nyou started waiting. The longer you wait, the longer\nyour expected remaining",
    "start": "1901390",
    "end": "1908190"
  },
  {
    "text": "waiting time is. And that's called a heavy-tailed\ndistribution. ",
    "start": "1908190",
    "end": "1916000"
  },
  {
    "text": "What most of us have noticed, I\nthink, in our lives is that an awful lot of waiting lines\nthat human beings wait in are",
    "start": "1916000",
    "end": "1923390"
  },
  {
    "text": "in fact heavy-tailed. So that in fact is part of the\nreason why we move if somebody",
    "start": "1923390",
    "end": "1929920"
  },
  {
    "text": "takes a long time. It's interesting to see\nhow the brain works.",
    "start": "1929920",
    "end": "1935520"
  },
  {
    "text": "Because I'm sure that none\nof you have ever really rationally analyzed this\nquestion of why you move.",
    "start": "1935520",
    "end": "1942240"
  },
  {
    "text": "Have you? I mean, I have because\nI teach probability courses all the time.",
    "start": "1942240",
    "end": "1947760"
  },
  {
    "text": "But I don't think anyone who\ndoesn't teach probability courses would be crazy enough\nto waste their time on a",
    "start": "1947760",
    "end": "1955290"
  },
  {
    "text": "question like this. But your brain automatically\nfigures that out.",
    "start": "1955290",
    "end": "1960730"
  },
  {
    "text": "I mean, your brain is smart\nenough to know that if you've waited for a long time, you're\nprobably going to have to wait",
    "start": "1960730",
    "end": "1966300"
  },
  {
    "text": "for an even longer time. And it makes sense to move to\nanother line where your",
    "start": "1966300",
    "end": "1971570"
  },
  {
    "text": "waiting time is probably\ngoing to be shorter. So you're pretty smart if you\ndon't think about it too much.",
    "start": "1971570",
    "end": "1979460"
  },
  {
    "text": " Here's an interesting theorem\nnow that makes use of this",
    "start": "1979460",
    "end": "1985980"
  },
  {
    "text": "memoryless property. This is Theorem 2.2.1\nin the text.",
    "start": "1985980",
    "end": "1992720"
  },
  {
    "text": "It's not stated terribly\nwell there. And I'll tell you why\nin a little bit. It's not stated too badly.",
    "start": "1992720",
    "end": "1999450"
  },
  {
    "text": "I mean, it's stated correctly. But it's just a little hard to\nunderstand what it says. If you have a Poisson process\nof rate lambda and you're",
    "start": "1999450",
    "end": "2007460"
  },
  {
    "text": "looking at any given time\nt, here's t down here. You're looking at the\nprocess of time t.",
    "start": "2007460",
    "end": "2015380"
  },
  {
    "text": "The interval z-- here's the interval z here-- from t until the next arrival\nhas distribution e to the",
    "start": "2015380",
    "end": "2030760"
  },
  {
    "text": "minus lambda z. And it has this distribution\nfor all real numbers",
    "start": "2030760",
    "end": "2037929"
  },
  {
    "text": "greater than 0. The random variable Z is\nindependent of n of t.",
    "start": "2037930",
    "end": "2044880"
  },
  {
    "text": "In other words, this random\nvariable here is independent of how many arrivals there\nhave been at time t.",
    "start": "2044880",
    "end": "2054080"
  },
  {
    "text": "And given this, it's independent\nof s sub n, which",
    "start": "2054080",
    "end": "2060540"
  },
  {
    "text": "is the time at which the\nlast arrival occurred. Namely, here's n\nof t equals 2.",
    "start": "2060540",
    "end": "2067429"
  },
  {
    "text": "Here's s of 2 at time tau. So given both n of t and s sub\n2 in this case, or s sub n of",
    "start": "2067429",
    "end": "2077629"
  },
  {
    "text": "t as we might call it, and\nthat's what gets confusing. And I'll talk about\nthat later.",
    "start": "2077630",
    "end": "2082980"
  },
  {
    "text": "Given those two things, the\nnumber n of arrivals in 0t--",
    "start": "2082980",
    "end": "2088379"
  },
  {
    "text": "well, I got off. The random variable Z is\nindependent of n of t.",
    "start": "2088380",
    "end": "2094960"
  },
  {
    "text": "And given n of t, Z is\nindependent of all of these arrival epochs up\nuntil time t.",
    "start": "2094960",
    "end": "2102075"
  },
  {
    "text": "And it's also independent of\nn of t for all values of",
    "start": "2102075",
    "end": "2107800"
  },
  {
    "text": "tau up until t. That's what the theorem\nstates. What the theorem states is that\nthis memoryless property",
    "start": "2107800",
    "end": "2116120"
  },
  {
    "text": "that we've just stated for\nrandom variables is really a property of the Poisson\nprocess.",
    "start": "2116120",
    "end": "2123470"
  },
  {
    "text": "When we say that if a random\nvariable, it's a little hard to see why would anyone was\ncalling it memoryless.",
    "start": "2123470",
    "end": "2130080"
  },
  {
    "text": "When you state it for a Poisson\nprocess, it's very obvious why we want to\ncall it memoryless.",
    "start": "2130080",
    "end": "2137190"
  },
  {
    "text": "It says that this time here from\nt, from any arbitrary t, until the next arrival occurs,\nthat this is independent of",
    "start": "2137190",
    "end": "2145790"
  },
  {
    "text": "all this junk that happens\nbefore or up to time t.",
    "start": "2145790",
    "end": "2152380"
  },
  {
    "text": "That's what the theorem says. Here's a sort of a\nhalf proof of it.",
    "start": "2152380",
    "end": "2157600"
  },
  {
    "text": "There's a careful proof\nin the notes. The statement in the notes\nis not that careful, but the proof is.",
    "start": "2157600",
    "end": "2162790"
  },
  {
    "text": "And the proof is drawn\nout perhaps too much.",
    "start": "2162790",
    "end": "2169010"
  },
  {
    "text": "You can find your comfort level\nbetween this and the much longer version\nin the notes.",
    "start": "2169010",
    "end": "2174960"
  },
  {
    "text": "You might understand\nit well from this. Given n of t is equal to 2 in\nthis case, and in general,",
    "start": "2174960",
    "end": "2181430"
  },
  {
    "text": "given that n of t is equal to\nany constant n, and given that s sub 2 where this 2 is equal to\nthat 2, given that s sub 2",
    "start": "2181430",
    "end": "2191140"
  },
  {
    "text": "is equal to tau, then x3, this\nvalue here, the interarrival",
    "start": "2191140",
    "end": "2198010"
  },
  {
    "text": "arrival time from this previous\narrival before t to",
    "start": "2198010",
    "end": "2203120"
  },
  {
    "text": "the next arrival after t, namely\nx3, is the thing which",
    "start": "2203120",
    "end": "2208470"
  },
  {
    "text": "bridges across this time that\nwe selected, t. t is not a",
    "start": "2208470",
    "end": "2214160"
  },
  {
    "text": "random thing. t is just something you're\ninterested in. I want to catch a plane at 7\no'clock tomorrow evening.",
    "start": "2214160",
    "end": "2222550"
  },
  {
    "text": "t then is 7 o'clock\ntomorrow evening. What's the time from the last\nplane that went out to New",
    "start": "2222550",
    "end": "2229080"
  },
  {
    "text": "York until the next plane that's\ngoing out to New York? If the planes are so screwed\nup that the schedule means",
    "start": "2229080",
    "end": "2236510"
  },
  {
    "text": "nothing, then they're just\nflying out whenever they can fly out.",
    "start": "2236510",
    "end": "2241920"
  },
  {
    "text": "That's the meaning\nof this x3 here. That says that x3, in fact,\nhas to be bigger",
    "start": "2241920",
    "end": "2251020"
  },
  {
    "text": "than t minus tau. If we're given that n of t is\nequal to 2 and that the time",
    "start": "2251020",
    "end": "2258380"
  },
  {
    "text": "of the previous arrival is at\ntau, we're given that there haven't been any arrivals\nbetween the last arrival",
    "start": "2258380",
    "end": "2265390"
  },
  {
    "text": "before t and t. That's what we're given. This was the last arrival before\nt by the assumption",
    "start": "2265390",
    "end": "2272060"
  },
  {
    "text": "we've made. So we're assuming there's\nnothing in this interval. And then we're asking what is\nthe remaining time until x3 is",
    "start": "2272060",
    "end": "2281720"
  },
  {
    "text": "all finished. And that's the random variable\nthat we call Z. So Z is x3",
    "start": "2281720",
    "end": "2286850"
  },
  {
    "text": "minus t minus tau. The complementary distribution\nfunction of Z conditional on",
    "start": "2286850",
    "end": "2294260"
  },
  {
    "text": "both n and on s, this n here\nand this s here is then",
    "start": "2294260",
    "end": "2300640"
  },
  {
    "text": "exponential with e to\nthe minus lambda Z. Now, if I know that this is\nexponential, what can I say",
    "start": "2300640",
    "end": "2309740"
  },
  {
    "text": "about the random variable\nZ itself?  Well, there's an easy way to\nfind the distribution of Z",
    "start": "2309740",
    "end": "2319100"
  },
  {
    "text": "when you know Z conditional\nonto other things. ",
    "start": "2319100",
    "end": "2328200"
  },
  {
    "text": "You take what the distribution\nis conditional on, each value of n and s.",
    "start": "2328200",
    "end": "2333599"
  },
  {
    "text": "You then multiply that by the\nprobability that n and s have those particular values.",
    "start": "2333600",
    "end": "2340120"
  },
  {
    "text": "And then you integrate. Now, we can look at this and\nsay we don't have to go",
    "start": "2340120",
    "end": "2346830"
  },
  {
    "text": "through all of that. And in fact, we won't know what\nthe distribution of n is. And we certainly won't know what\nthe distribution of this",
    "start": "2346830",
    "end": "2354670"
  },
  {
    "text": "previous arrival is for\nquite a long time. Why don't we need\nto know that?",
    "start": "2354670",
    "end": "2361310"
  },
  {
    "text": "Well, because we know that\nwhatever n of t is and",
    "start": "2361310",
    "end": "2366590"
  },
  {
    "text": "whatever s sub n of t is doesn't\nmake any difference. The distribution of Z is\nstill the same thing.",
    "start": "2366590",
    "end": "2375170"
  },
  {
    "text": "So we know this has to be the\nunconditional distribution function of Z also even without\nknowing anything about",
    "start": "2375170",
    "end": "2383880"
  },
  {
    "text": "n or knowing about s. And that means that the\ncomplementary distribution",
    "start": "2383880",
    "end": "2391930"
  },
  {
    "text": "function of Z is equal to e to\nthe minus lambda Z also.",
    "start": "2391930",
    "end": "2397790"
  },
  {
    "text": "So that's sort of a proof if you\nwant to be really picky.",
    "start": "2397790",
    "end": "2403210"
  },
  {
    "text": "And I would suggest you\ntry to be picky. When you read the notes, try to\nunderstand why one has to",
    "start": "2403210",
    "end": "2409640"
  },
  {
    "text": "say a little more than\none says here. Because that's the\nway you really understand these things.",
    "start": "2409640",
    "end": "2415720"
  },
  {
    "text": "But this really gives you\nthe idea of the proof. And it's pretty close\nto a complete proof. ",
    "start": "2415720",
    "end": "2424829"
  },
  {
    "text": "This is saying what\nwe just said. The conditional distribution\nof Z doesn't vary with the",
    "start": "2424830",
    "end": "2430380"
  },
  {
    "text": "conditioning values. n of t equals n. And s sub n equals tau.",
    "start": "2430380",
    "end": "2437150"
  },
  {
    "text": "So Z is statistically\nindependent of n of t and s sub n of t.",
    "start": "2437150",
    "end": "2443550"
  },
  {
    "text": "You should look at the text\nagain, as I said, for more careful proof of that.",
    "start": "2443550",
    "end": "2449880"
  },
  {
    "text": "What is this random variable\ns sub n of t? It's clear from the picture\nwhat it is.",
    "start": "2449880",
    "end": "2457640"
  },
  {
    "text": "s sub n of t is the last\narrival before",
    "start": "2457640",
    "end": "2464400"
  },
  {
    "text": "we're at time t. That's what it is in\nthe picture here.",
    "start": "2464400",
    "end": "2470970"
  },
  {
    "text": "How do you define a random\nvariable like that? ",
    "start": "2470970",
    "end": "2477080"
  },
  {
    "text": "There's a temptation to\ndo it the following way which is incorrect.",
    "start": "2477080",
    "end": "2484170"
  },
  {
    "text": "There's a temptation to say,\nwell, conditional on n of t, suppose n of t is equal to n.",
    "start": "2484170",
    "end": "2491500"
  },
  {
    "text": "Let me then find the\ndistribution of s sub n.",
    "start": "2491500",
    "end": "2496730"
  },
  {
    "text": "And that's not the right\nway to do it. Because s sub n of t and n\nof t are certainly not",
    "start": "2496730",
    "end": "2504500"
  },
  {
    "text": "independent. n of t tells you what random\nvariable you want to look at. ",
    "start": "2504500",
    "end": "2512110"
  },
  {
    "text": "How do you define a random\nvariable in terms of a mapping from the sample space omega onto\nthe set of real numbers?",
    "start": "2512110",
    "end": "2522520"
  },
  {
    "text": "So what you do here is you look\nat a sample point omega. It maps into this random\nvariable n of t, the sample",
    "start": "2522520",
    "end": "2532200"
  },
  {
    "text": "value of that at omega,\nthat's sum value n. And then you map that same\nsample point into--",
    "start": "2532200",
    "end": "2542210"
  },
  {
    "text": "now, you know which random\nvariable it is you're looking at. You take that same omega and\nmap it into sub time tau.",
    "start": "2542210",
    "end": "2550160"
  },
  {
    "text": "So that's what we mean\nby s sub n of t. If your mind glazes over at\nthat, don't worry about it.",
    "start": "2550160",
    "end": "2558800"
  },
  {
    "text": "Think about it a\nlittle bit now. Come back and think\nabout it later. Every time I don't think about\nthis for two weeks, my mind",
    "start": "2558800",
    "end": "2566220"
  },
  {
    "text": "glazes over when I look at it. And I have to think very hard\nabout what this very peculiar",
    "start": "2566220",
    "end": "2571309"
  },
  {
    "text": "looking random variable is. When I have a random variable\nwhere I have a sequence of",
    "start": "2571310",
    "end": "2578660"
  },
  {
    "text": "random variables, and I have a\nrandom variable which is a random selection among those\nrandom variables, it's a very",
    "start": "2578660",
    "end": "2586270"
  },
  {
    "text": "complicated animal. And that's what this is. But we've just said\nwhat it is.",
    "start": "2586270",
    "end": "2592990"
  },
  {
    "text": "So you can think about\nit as you go.",
    "start": "2592990",
    "end": "2598760"
  },
  {
    "text": "The theorem essentially\nextends the idea of memorylessness to the entire\nPoisson process. In other words, this says that\na Poisson process is",
    "start": "2598760",
    "end": "2606390"
  },
  {
    "text": "memoryless. You look at a particular\ntime t. And the time until the next\narrival is independent of",
    "start": "2606390",
    "end": "2613980"
  },
  {
    "text": "everything that's going\nbefore that. ",
    "start": "2613980",
    "end": "2620490"
  },
  {
    "text": "Starting at any time tau,\nyeah, well, subsequent interrarrival times are\nindependent of Z",
    "start": "2620490",
    "end": "2627360"
  },
  {
    "text": "and also of the past. I'm waving my hands\na little bit here.",
    "start": "2627360",
    "end": "2633420"
  },
  {
    "text": "But in fact, what I'm\nsaying is right. We have these interarrival\nintervals that we know are",
    "start": "2633420",
    "end": "2638930"
  },
  {
    "text": "independent. The interarrival intervals which\nhave occurred completely",
    "start": "2638930",
    "end": "2644089"
  },
  {
    "text": "before time t are independent of\nthis random variable Z. The",
    "start": "2644090",
    "end": "2650400"
  },
  {
    "text": "next interarrival interval after\nZ is independent of all the interarrival intervals\nbefore that.",
    "start": "2650400",
    "end": "2657370"
  },
  {
    "text": "And those interarrival intervals\nbefore that are",
    "start": "2657370",
    "end": "2665550"
  },
  {
    "text": "determined by the counting\nprocess up until time t.",
    "start": "2665550",
    "end": "2670580"
  },
  {
    "text": "So the counting process\ncorresponds to this corresponding interarrival\nprocess.",
    "start": "2670580",
    "end": "2677020"
  },
  {
    "text": "It's n of t prime minus n of t\nfor t prime greater than t. In other words, we now want to\nlook at a counting process",
    "start": "2677020",
    "end": "2684520"
  },
  {
    "text": "which starts at time t and\nfollows whatever it has to follow from this original\ncounting process.",
    "start": "2684520",
    "end": "2692960"
  },
  {
    "text": "And what we're saying is this\nfirst arrival and this process starting at time t is\nindependent of everything that",
    "start": "2692960",
    "end": "2700740"
  },
  {
    "text": "went before. And every subsequent\ninterarrival time after that",
    "start": "2700740",
    "end": "2705960"
  },
  {
    "text": "is independent of everything\nbefore time t. So this says that the process n\nof t prime minus n of t as a",
    "start": "2705960",
    "end": "2715420"
  },
  {
    "text": "process nt prime. This is a counting process nt\nprime defined for t prime",
    "start": "2715420",
    "end": "2721560"
  },
  {
    "text": "greater than t. So for fixed t, we now have\nsomething which we can view",
    "start": "2721560",
    "end": "2727870"
  },
  {
    "text": "over variable t prime as\na counting process. It's a Poisson process shifted\nto start at time t, ie, for",
    "start": "2727870",
    "end": "2736049"
  },
  {
    "text": "each t prime, n of t prime minus\nthe n of t has the same distribution as n of\nt prime minus t.",
    "start": "2736050",
    "end": "2745230"
  },
  {
    "text": "Same for joint distributions. In other words, this\nrandom variable Z is exponential again.",
    "start": "2745230",
    "end": "2750710"
  },
  {
    "text": "And all the future interarrival\ntimes are exponential. So it's defined in exactly the\nsame way as the original",
    "start": "2750710",
    "end": "2758940"
  },
  {
    "text": "random process is. So it's statistically\nthe same process. ",
    "start": "2758940",
    "end": "2765770"
  },
  {
    "text": "Which says two things\nabout it. Everything is the same. And everything is independent.",
    "start": "2765770",
    "end": "2772890"
  },
  {
    "text": "We will call that stationary. Everything is the same. And independent, everything\nis independent.",
    "start": "2772890",
    "end": "2780400"
  },
  {
    "text": "And then we'll try to sort out\nhow things can be the same but also be independent.",
    "start": "2780400",
    "end": "2785750"
  },
  {
    "text": "Oh, we already know that. We have two IID random\nvariables, x1 and x2.",
    "start": "2785750",
    "end": "2793010"
  },
  {
    "text": "They're IID. They're independent and\nidentically distributed. Identity distributed means\nthat in one sense,",
    "start": "2793010",
    "end": "2799329"
  },
  {
    "text": "they are the same. But they're also independent\nof each other. So the random variables are\ndefined in the same way.",
    "start": "2799330",
    "end": "2808079"
  },
  {
    "text": "And in that sense, they're\nstationary. But they're independent of each\nother by the definition",
    "start": "2808080",
    "end": "2813160"
  },
  {
    "text": "of independence. So our new process is\nindependent of the old process",
    "start": "2813160",
    "end": "2820569"
  },
  {
    "text": "in the interval 0 up to t.",
    "start": "2820570",
    "end": "2828950"
  },
  {
    "text": "When we're talking about Poisson\nprocesses and also arrival processes, we always\ntalk about intervals which are",
    "start": "2828950",
    "end": "2837350"
  },
  {
    "text": "open on the left and closed\non the right. That's completely arbitrary.",
    "start": "2837350",
    "end": "2843920"
  },
  {
    "text": "But if you don't make one\nconvention or the other, you could make them closed on the\nleft and open on the right,",
    "start": "2843920",
    "end": "2851940"
  },
  {
    "text": "and that would be\nconsistent also. But nobody does. And it would be much\nmore confusing.",
    "start": "2851940",
    "end": "2858210"
  },
  {
    "text": "So it's much easier to make\nthings closed on the right. ",
    "start": "2858210",
    "end": "2867280"
  },
  {
    "text": "So we're up to stationary and\nindependent increments. Well, we're not up to there.",
    "start": "2867280",
    "end": "2872990"
  },
  {
    "text": "We're almost finished\nwith that. We've virtually already said\nthat increments are stationary",
    "start": "2872990",
    "end": "2879339"
  },
  {
    "text": "and independent. And an increment is just a piece\nof a Poisson process.",
    "start": "2879340",
    "end": "2884560"
  },
  {
    "text": "That's an increment,\na piece of it. ",
    "start": "2884560",
    "end": "2889619"
  },
  {
    "text": "So a counting process has the\nstationary increment property",
    "start": "2889620",
    "end": "2896070"
  },
  {
    "text": "if n of t prime minus n of t has\nthe same distribution as n",
    "start": "2896070",
    "end": "2901493"
  },
  {
    "text": "of t prime minus t for all\nt prime greater than t greater than 0.",
    "start": "2901493",
    "end": "2908059"
  },
  {
    "text": "In other words, you look at\nthis counting process. Goes up. Then you start at some\nparticular value of t.",
    "start": "2908060",
    "end": "2915970"
  },
  {
    "text": "Let me draw a picture of that. Make it a little clearer. ",
    "start": "2915970",
    "end": "2940330"
  },
  {
    "text": "And the new Poisson process\nstarts at this value and goes",
    "start": "2940330",
    "end": "2945960"
  },
  {
    "text": "up from there. So this thing here is\nwhat we call n of t",
    "start": "2945960",
    "end": "2953970"
  },
  {
    "text": "prime minus n of t. Because here's n of t.",
    "start": "2953970",
    "end": "2959520"
  },
  {
    "text": " Here's t prime out here for\nany value out here.",
    "start": "2959520",
    "end": "2966560"
  },
  {
    "text": "And we're looking at the number\nof arrivals up until time t prime. And what we're talking about,\nwhen we're talking about n of",
    "start": "2966560",
    "end": "2974442"
  },
  {
    "text": "t prime minus n of t, we're\ntalking about what happens in",
    "start": "2974442",
    "end": "2980109"
  },
  {
    "text": "this region here. And we're saying that this is\na Poisson process again.",
    "start": "2980110",
    "end": "2988010"
  },
  {
    "text": "And now in a minute, we're going\nto say that this Poisson process is independent of what\nhappened up until time t.",
    "start": "2988010",
    "end": "2997720"
  },
  {
    "text": "But Poisson processes have this stationary increment property. And a counting process has the\nindependent increment property",
    "start": "2997720",
    "end": "3008930"
  },
  {
    "text": "if for every sequence of times,\nt1, t2, up to t sub n.",
    "start": "3008930",
    "end": "3014970"
  },
  {
    "text": "The random variables n of t1 and\ntilde of t1, t2, we didn't",
    "start": "3014970",
    "end": "3022830"
  },
  {
    "text": "talk about that. But I think it's defined\non one of those slides. n of t and t prime is defined as\nn of t prime minus n of t.",
    "start": "3022830",
    "end": "3041480"
  },
  {
    "text": " So n of t and t prime is really\nthe number of arrivals",
    "start": "3041480",
    "end": "3049740"
  },
  {
    "text": "that have occurred from\nt up until t prime--",
    "start": "3049740",
    "end": "3055360"
  },
  {
    "text": "open on t, closed on t prime. So a counting process has the\nindependent increment property",
    "start": "3055360",
    "end": "3067410"
  },
  {
    "text": "if for every finite set of\ntimes, these random variables here are independent.",
    "start": "3067410",
    "end": "3073920"
  },
  {
    "text": "The number of arrivals in the\nfirst increment, number of arrivals in the second\nincrement, number of arrivals",
    "start": "3073920",
    "end": "3079860"
  },
  {
    "text": "in the third increment, no\nmatter how you choose t1, t2, up to t sub n, what happens here\nis independent of what",
    "start": "3079860",
    "end": "3087490"
  },
  {
    "text": "happens here, is independent\nof what happens here, and so forth. It's not only that\nwhat happens in",
    "start": "3087490",
    "end": "3093270"
  },
  {
    "text": "Las Vegas stays there. It's that what happens in\nBoston stays there, what happens in Philadelphia stays\nthere, and so forth.",
    "start": "3093270",
    "end": "3101050"
  },
  {
    "text": "What happens anywhere\nstays anywhere. It never gets out of there. That's what we mean by\nindependence in this case.",
    "start": "3101050",
    "end": "3108170"
  },
  {
    "text": "So it's a strong statement. But we've essentially said that\nPoisson processes have",
    "start": "3108170",
    "end": "3115000"
  },
  {
    "text": "that property. So this property implies is the\nnumber of arrivals in each",
    "start": "3115000",
    "end": "3120539"
  },
  {
    "text": "of the set of non-overlapping\nintervals are independent random variables.",
    "start": "3120540",
    "end": "3126269"
  },
  {
    "text": "For a Poisson process, we've\nseen that the number of",
    "start": "3126270",
    "end": "3138010"
  },
  {
    "text": "arrivals in t sub i minus 1 to t\nsub i is independent of this",
    "start": "3138010",
    "end": "3143450"
  },
  {
    "text": "whole set of random\nvariables here. Now, remember that when we're\ntalking about multiple random",
    "start": "3143450",
    "end": "3150520"
  },
  {
    "text": "variables, we say that multiple\nrandom variables are independent. It's not enough to be pairwise\nindependent.",
    "start": "3150520",
    "end": "3157740"
  },
  {
    "text": "They all have to\nbe independent. But this thing we've just said\nsays that this is independent",
    "start": "3157740",
    "end": "3164260"
  },
  {
    "text": "of all of these things. If this is independent of all of\nthese things, and then the",
    "start": "3164260",
    "end": "3170260"
  },
  {
    "text": "next interval n of ti, ti plus\n1, is independent of",
    "start": "3170260",
    "end": "3175610"
  },
  {
    "text": "everything in the past, and so\nforth all the way up, then all of those random variables are\nstatistically independent of",
    "start": "3175610",
    "end": "3182870"
  },
  {
    "text": "each other. So in fact, we're saying more\nthan pairwise statistical",
    "start": "3182870",
    "end": "3188130"
  },
  {
    "text": "independence. If you're panicking about\nthese minor differences",
    "start": "3188130",
    "end": "3194970"
  },
  {
    "text": "between pairwise independence\nand real independence, don't worry about it too much.",
    "start": "3194970",
    "end": "3201240"
  },
  {
    "text": "Because the situations\nwhere that happens are relatively rare. They don't happen\nall the time.",
    "start": "3201240",
    "end": "3208030"
  },
  {
    "text": "But they do happen\noccasionally. So you should be aware of it.",
    "start": "3208030",
    "end": "3213157"
  },
  {
    "text": "You shouldn't get in\na panic about it. Because normally, you don't\nhave to worry about it.",
    "start": "3213157",
    "end": "3218200"
  },
  {
    "text": "In other words, when you're\ntaking a quiz, don't worry about any of the fine points.",
    "start": "3218200",
    "end": "3225520"
  },
  {
    "text": "Figure out roughly how\nto do the problems. Do them more or less.",
    "start": "3225520",
    "end": "3231620"
  },
  {
    "text": "And then come back and deal with\nthe fine points later. Don't spend the whole quiz time\nwrapped up on one little",
    "start": "3231620",
    "end": "3239430"
  },
  {
    "text": "fine point and not get\nto anything else. One of the important things to\nlearn in understanding a",
    "start": "3239430",
    "end": "3246340"
  },
  {
    "text": "subject like this is to figure\nout what are the fine points, what are the important points.",
    "start": "3246340",
    "end": "3252369"
  },
  {
    "text": "How do you tell whether\nsomething is important in a particular context. And that just takes intuition.",
    "start": "3252370",
    "end": "3259870"
  },
  {
    "text": "That takes some intuition from\nworking with these processes. And you pick that\nup as you go.",
    "start": "3259870",
    "end": "3266970"
  },
  {
    "text": "But anyway, we wind up now\nwith the statement that Poisson processes have\nstationary and independent",
    "start": "3266970",
    "end": "3274440"
  },
  {
    "text": "increments. Which means that what happens\nin each interval is independent of what happens\nin each other interval.",
    "start": "3274440",
    "end": "3282800"
  },
  {
    "text": "So we're done with that until\nwe get to alternate definitions of a Poisson\nprocess.",
    "start": "3282800",
    "end": "3290045"
  },
  {
    "text": "And we now want to deal with\nthe Erlang and the Poisson distributions, which are just\nvery plug and chug kinds of",
    "start": "3290045",
    "end": "3300400"
  },
  {
    "text": "things to a certain extent. For a Poisson process of rate\nlambda, the density function",
    "start": "3300400",
    "end": "3309695"
  },
  {
    "text": "of arrival epoch s2, s2 is\nthe sum of x1 plus x2.",
    "start": "3309695",
    "end": "3317130"
  },
  {
    "text": "x1 is an exponential random\nvariable of rate lambda. x2 is an independent random\nvariable of rate lambda.",
    "start": "3317130",
    "end": "3326420"
  },
  {
    "text": "How do you find the probability\ndensity function",
    "start": "3326420",
    "end": "3331470"
  },
  {
    "text": "as a sum of two independent\nrandom variables, which both have a density? You convolve them.",
    "start": "3331470",
    "end": "3337930"
  },
  {
    "text": "That's something that you've\nknown ever since you studied",
    "start": "3337930",
    "end": "3343609"
  },
  {
    "text": "any kind of linear systems, or\nfrom any probability, or anything else. Convolution is the way to\nsolve this problem.",
    "start": "3343610",
    "end": "3351050"
  },
  {
    "text": "When you convolve these\ntwo random variables, here I've done it.",
    "start": "3351050",
    "end": "3356400"
  },
  {
    "text": "You get lambda squared t times\ne to the minus lambda t. ",
    "start": "3356400",
    "end": "3363040"
  },
  {
    "text": "This kind of form here with an\ne to the minus lambda t, and with a t, or t squared, or so\nforth, is a particularly easy",
    "start": "3363040",
    "end": "3371430"
  },
  {
    "text": "form to integrate. So we just do this\nagain and again.",
    "start": "3371430",
    "end": "3376790"
  },
  {
    "text": "And when we do it again and\nagain, we find out that the density function as a sum of n\nof these random variables, you",
    "start": "3376790",
    "end": "3385010"
  },
  {
    "text": "keep picking up an extra lambda\nevery time you convolve in another exponential\nrandom variable.",
    "start": "3385010",
    "end": "3391860"
  },
  {
    "text": "You pick up an extra factor of\nt whenever you do this again. This stays the same\nas it does here.",
    "start": "3391860",
    "end": "3399770"
  },
  {
    "text": "And strangely enough, this n\nminus 1 factorial appears down",
    "start": "3399770",
    "end": "3405480"
  },
  {
    "text": "here when you start integrating\nsomething with",
    "start": "3405480",
    "end": "3411770"
  },
  {
    "text": "some power of t in it. So when you integrate this,\nthis is what you get.",
    "start": "3411770",
    "end": "3417030"
  },
  {
    "text": "And it's called the\nErlang density. Any questions about this?",
    "start": "3417030",
    "end": "3422230"
  },
  {
    "text": "Or any questions\nabout anything? ",
    "start": "3422230",
    "end": "3428650"
  },
  {
    "text": "I'm getting hoarse. I need questions. [LAUGHS]",
    "start": "3428650",
    "end": "3434860"
  },
  {
    "text": "There's nothing much to\nworry about there. But now, we want to stop and\nsmell the roses while doing",
    "start": "3434860",
    "end": "3441900"
  },
  {
    "text": "all this computation. Let's do this a slightly\ndifferent way.",
    "start": "3441900",
    "end": "3447640"
  },
  {
    "text": "The joint density of x1 up to\nx sub n is lambda x1 times e",
    "start": "3447640",
    "end": "3460099"
  },
  {
    "text": "to the minus lambda x1, times\nlambda x2, times e to the minus lambda x2, and so forth.",
    "start": "3460100",
    "end": "3468270"
  },
  {
    "text": "So excuse me. The probability density of an\nexponential random variable is",
    "start": "3468270",
    "end": "3474880"
  },
  {
    "text": "lambda times e to the\nminus lambda x. So the joint density is lambda\ne to the minus lambda x1.",
    "start": "3474880",
    "end": "3486900"
  },
  {
    "text": "I told you I was\ngetting hoarse. And my mind is getting hoarse. So you better start asking\nsome questions or I will",
    "start": "3486900",
    "end": "3494280"
  },
  {
    "text": "evolve into meaningless\nchatter. ",
    "start": "3494280",
    "end": "3500490"
  },
  {
    "text": "And this is just lambda to the\nn times e to the minus lambda",
    "start": "3500490",
    "end": "3506770"
  },
  {
    "text": "times the summation of x sub\ni from i equals 1 to n.",
    "start": "3506770",
    "end": "3514840"
  },
  {
    "text": "Now, that's sort of interesting\nbecause this joint density is just this\nsimple-minded thing.",
    "start": "3514840",
    "end": "3523710"
  },
  {
    "text": "You can write it as lambda to\nthe n times e to the minus lambda s sub n, where\ns sub n is the",
    "start": "3523710",
    "end": "3530730"
  },
  {
    "text": "time of the n-th arrival. This says that the joint\ndistribution of all of these",
    "start": "3530730",
    "end": "3537910"
  },
  {
    "text": "interarrival times only\ndepends on when the last one comes in.",
    "start": "3537910",
    "end": "3544310"
  },
  {
    "text": "And you can transform that to a\njoint density on each of the",
    "start": "3544310",
    "end": "3549750"
  },
  {
    "text": "arrival epochs as lambda to\nthe n times e to the minus",
    "start": "3549750",
    "end": "3554900"
  },
  {
    "text": "lambda s sub n. Is this obvious to everyone? ",
    "start": "3554900",
    "end": "3561620"
  },
  {
    "text": "You're lying. If you're not shaking your\nhead, you're lying.",
    "start": "3561620",
    "end": "3566700"
  },
  {
    "text": "Because it's not\nobvious at all. What we're doing here, it's sort\nof obvious if you look at",
    "start": "3566700",
    "end": "3575110"
  },
  {
    "text": "the picture. It's not obvious when you\ndo the mathematics.",
    "start": "3575110",
    "end": "3580420"
  },
  {
    "text": "What the picture says\nis-- let me see if I find the picture again.",
    "start": "3580420",
    "end": "3585530"
  },
  {
    "start": "3585530",
    "end": "3592930"
  },
  {
    "text": "OK. Here's the picture up here. We're looking at these\ninterarrival intervals.",
    "start": "3592930",
    "end": "3598953"
  },
  {
    "text": " I think it'll be clearer if\nI draw it a different way.",
    "start": "3598953",
    "end": "3604450"
  },
  {
    "text": " There we go. ",
    "start": "3604450",
    "end": "3614360"
  },
  {
    "text": "Let's just draw this\nin a line. Here's 0.",
    "start": "3614360",
    "end": "3619589"
  },
  {
    "text": "Here's s1. Here's s2. Here's s3.",
    "start": "3619590",
    "end": "3626826"
  },
  {
    "text": "And here's s4.  And here's x1.",
    "start": "3626826",
    "end": "3633970"
  },
  {
    "text": "Here's x2. ",
    "start": "3633970",
    "end": "3641130"
  },
  {
    "text": "Here's x3.  And here's x4. ",
    "start": "3641130",
    "end": "3649930"
  },
  {
    "text": "Now, what we're talking about,\nwe can go from the density of each of these intervals to the\ndensity of each of these sums",
    "start": "3649930",
    "end": "3661150"
  },
  {
    "text": "in a fairly straightforward\nway. If you write this all out as a\ndensity, what you find is that",
    "start": "3661150",
    "end": "3672530"
  },
  {
    "text": "in making a transformation\nfrom the density of these interarrival intervals to the\ndensity of these, what you're",
    "start": "3672530",
    "end": "3681230"
  },
  {
    "text": "essentially doing is taking this\ndensity and multiplying it by a matrix.",
    "start": "3681230",
    "end": "3687900"
  },
  {
    "text": "And the matrix is a diagonal\nmatrix, is an",
    "start": "3687900",
    "end": "3693770"
  },
  {
    "text": "upper triangular matrix. Because this depends\nonly on this. This depends only on\nthis and this.",
    "start": "3693770",
    "end": "3700680"
  },
  {
    "text": "This depends only on\nthis and this. This depends only on\neach of these. So it's a triangular matrix with\nterms on the diagonal.",
    "start": "3700680",
    "end": "3710670"
  },
  {
    "text": "And when you look at a matrix\nlike that, the terms on the diagonal are 1s because what's\ngetting added each time is 1",
    "start": "3710670",
    "end": "3717720"
  },
  {
    "text": "times a new variable. So we have a matrix with 1s on\nthe main diagonal and other",
    "start": "3717720",
    "end": "3723430"
  },
  {
    "text": "stuff above that. And what that means is that\nwhen you make this",
    "start": "3723430",
    "end": "3729000"
  },
  {
    "text": "transformation in densities,\nthe determinant of that matrix is 1. And the value that you then\nget when you go from the",
    "start": "3729000",
    "end": "3737400"
  },
  {
    "text": "density of these to the density\nof these, it's a",
    "start": "3737400",
    "end": "3744420"
  },
  {
    "text": "uniform density again. So in fact, it has to\nlook like what we",
    "start": "3744420",
    "end": "3749760"
  },
  {
    "text": "said it looks like. So I was kidding you there. It's not so obvious how to\ndo that although it looks",
    "start": "3749760",
    "end": "3759310"
  },
  {
    "text": "reasonable. ",
    "start": "3759310",
    "end": "3770195"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. PROFESSOR: Yeah. AUDIENCE: I'm sorry. Is it also valid to make an\nargument based on symmetry?",
    "start": "3770195",
    "end": "3778140"
  },
  {
    "text": "PROFESSOR: It will be later. The symmetry is not\nclear here yet.",
    "start": "3778140",
    "end": "3784670"
  },
  {
    "text": "I mean, the symmetry isn't\nclear because you're starting at time 0. And because you're starting\nat time 0, you don't have",
    "start": "3784670",
    "end": "3794050"
  },
  {
    "text": "symmetry here yet. If we started at time 0 and we\nended at some time t, we could",
    "start": "3794050",
    "end": "3800750"
  },
  {
    "text": "try to claim there is some\nkind of symmetry between everything that happened\nin the middle. And we'll try to\ndo that later.",
    "start": "3800750",
    "end": "3807880"
  },
  {
    "text": "But at the moment, we would get\ninto even more trouble if",
    "start": "3807880",
    "end": "3813369"
  },
  {
    "text": "we try to do it by symmetry. ",
    "start": "3813370",
    "end": "3821220"
  },
  {
    "text": "But anyway, what this is saying\nis that this joint density is really--",
    "start": "3821220",
    "end": "3828310"
  },
  {
    "text": "if you know where this point is,\nthe joint density of all of these things remains the same\nno matter how you move",
    "start": "3828310",
    "end": "3835570"
  },
  {
    "text": "these things around. If I move s1 around a little\nbit, it means that x1 gets a",
    "start": "3835570",
    "end": "3841210"
  },
  {
    "text": "little smaller, x2 gets\na little bit bigger. And if you look at the joint\ndensity there, the joint",
    "start": "3841210",
    "end": "3847200"
  },
  {
    "text": "density stays absolutely the\nsame because you have e to the minus lambda x1 times e to\nthe minus lambda x2.",
    "start": "3847200",
    "end": "3855240"
  },
  {
    "text": "And the sum of the two for a\nfixed value here is the same as it was before. So you can move all of these\nthings around in any",
    "start": "3855240",
    "end": "3862120"
  },
  {
    "text": "way you want to. And the joint density depends\nonly on the last one.",
    "start": "3862120",
    "end": "3868760"
  },
  {
    "text": "And that's a very strange\nproperty and it's a very interesting property. And it sort of is the same as\nthis independent increment",
    "start": "3868760",
    "end": "3876200"
  },
  {
    "text": "property that we've been\ntalking about. But we'll see why that\nis in just a minute.",
    "start": "3876200",
    "end": "3881790"
  },
  {
    "text": "But anyway, once we have that\nproperty, we can then integrate this over the volume\nof s1, s2, s3, and s4, over",
    "start": "3881790",
    "end": "3895480"
  },
  {
    "text": "that volume which has the\nproperty that it stops at that",
    "start": "3895480",
    "end": "3901310"
  },
  {
    "text": "one particular point there. And we do that integration\nsubject to the fact that s3",
    "start": "3901310",
    "end": "3907490"
  },
  {
    "text": "has to be less than or equal to\ns4, s2 has to be less than or equal to s3, and\nso forth down.",
    "start": "3907490",
    "end": "3914790"
  },
  {
    "text": "When you do that integration,\nyou get exactly the same thing as you got before when you\ndid the integration.",
    "start": "3914790",
    "end": "3920540"
  },
  {
    "text": "The integration that you did\nbefore was essentially doing this, if you look at what\nyou did before.",
    "start": "3920540",
    "end": "3926180"
  },
  {
    "text": " You were taking lambda times e\nto the minus lambda x times",
    "start": "3926180",
    "end": "3935700"
  },
  {
    "text": "lambda times t minus x. And the x doesn't make\nany difference here.",
    "start": "3935700",
    "end": "3941390"
  },
  {
    "text": "The x cancels out. That's exactly what's\ngoing on. And if you do it in terms of s1\nand s2, the s1 cancels out.",
    "start": "3941390",
    "end": "3950184"
  },
  {
    "text": "The s1 is the same as x here. So there is that cancellation\nhere. And therefore, this Erlang\ndensity is just a marginal",
    "start": "3950185",
    "end": "3959090"
  },
  {
    "text": "distribution of a very\ninteresting joint distribution, which depends\nonly on the last term.",
    "start": "3959090",
    "end": "3964670"
  },
  {
    "text": " So next, we have a theorem\nwhich says for a Poisson",
    "start": "3964670",
    "end": "3974760"
  },
  {
    "text": "process, the PMF for n of t, the\nProbability Mass Function,",
    "start": "3974760",
    "end": "3981250"
  },
  {
    "text": "is the Poisson PMF. It sounds like I'm not really\nsaying anything because what",
    "start": "3981250",
    "end": "3986710"
  },
  {
    "text": "else would it be? Because you've always heard that\nthe Poisson PMF is this",
    "start": "3986710",
    "end": "3995319"
  },
  {
    "text": "particular function here. Well, in fact, there's\nsome reason for that.",
    "start": "3995320",
    "end": "4000960"
  },
  {
    "text": "And in fact, if we want to say\nthat a Poisson process is defined in terms of these\nexponential interarrival",
    "start": "4000960",
    "end": "4009000"
  },
  {
    "text": "times, then we have to\nshow that this is consistent with that.",
    "start": "4009000",
    "end": "4014320"
  },
  {
    "text": "The way I'll prove that\nhere, this is a little more than a PF.",
    "start": "4014320",
    "end": "4021330"
  },
  {
    "text": "Maybe we should say it's a\nP-R-O-F. Leave out the double O because it's not\nquite complete.",
    "start": "4021330",
    "end": "4028980"
  },
  {
    "text": "But what we want to do is to\ncalculate the probability that the n plus first arrival occurs\nsometime between t and",
    "start": "4028980",
    "end": "4038770"
  },
  {
    "text": "t plus delta. And we'll do it in two\ndifferent ways.",
    "start": "4038770",
    "end": "4044160"
  },
  {
    "text": "And one way involves the\nprobability mass function for the Poisson.",
    "start": "4044160",
    "end": "4049440"
  },
  {
    "text": "The other way involves\nthe Erlang density. And since we already know the\nErlang density, we can use",
    "start": "4049440",
    "end": "4056630"
  },
  {
    "text": "that to get the PMF\nfor n of t. ",
    "start": "4056630",
    "end": "4062480"
  },
  {
    "text": "So using the Erlang density,\nthe probability that the n",
    "start": "4062480",
    "end": "4067930"
  },
  {
    "text": "plus first arrival falls in\nthis little tiny interval here, we're thinking of\ndelta as being small.",
    "start": "4067930",
    "end": "4073950"
  },
  {
    "text": "And we're going to let\ndelta approach 0. It's going to be the density\nof the n plus first arrival",
    "start": "4073950",
    "end": "4082520"
  },
  {
    "text": "times delta plus o of delta. o of delta is something that\ngoes to 0 as delta increases",
    "start": "4082520",
    "end": "4090490"
  },
  {
    "text": "faster than delta does. It's something which has the\nproperty that o of delta",
    "start": "4090490",
    "end": "4097170"
  },
  {
    "text": "divided by delta goes to\n0 as delta gets large. So this is just saying that this\nis approximately equal to",
    "start": "4097170",
    "end": "4104310"
  },
  {
    "text": "the density of the n plus\nfirst arrival times this",
    "start": "4104310",
    "end": "4110540"
  },
  {
    "text": "[INAUDIBLE] here. The density stays essentially\nconstant over a very small delta.",
    "start": "4110540",
    "end": "4116028"
  },
  {
    "text": "It's a continuous density. Next, we use the independent\nincrement property, which says",
    "start": "4116029",
    "end": "4122479"
  },
  {
    "text": "that the probability that t is\nless than sn plus 1, is less than or equal to t plus delta,\nis the PMF that n of t is",
    "start": "4122479",
    "end": "4132930"
  },
  {
    "text": "equal to n at the beginning is\nthe interval, and then that in",
    "start": "4132930",
    "end": "4139649"
  },
  {
    "text": "the middle of the interval,\nthere's exactly one arrival.",
    "start": "4139649",
    "end": "4145278"
  },
  {
    "text": "And the probabilities of exactly\none arrival, is just lambda delta plus o of delta.",
    "start": "4145279",
    "end": "4152830"
  },
  {
    "text": " Namely, that's because of the independent increment property.",
    "start": "4152830",
    "end": "4159830"
  },
  {
    "text": "What's this o of delta\ndoing out here? Why isn't this exactly\nequal to this?",
    "start": "4159830",
    "end": "4166609"
  },
  {
    "text": "And why do I need\nsomething else?  What am I leaving out\nof this equation?",
    "start": "4166609",
    "end": "4175278"
  },
  {
    "text": "The probability that\nour arrival comes-- ",
    "start": "4175279",
    "end": "4185719"
  },
  {
    "text": "here's t. Here's t plus delta.",
    "start": "4185720",
    "end": "4191755"
  },
  {
    "text": "I'm talking about something\nhappening here. At this point, n of t is here.",
    "start": "4191755",
    "end": "4196989"
  },
  {
    "text": " And I'm finding the probability\nthat n of t plus",
    "start": "4196990",
    "end": "4204290"
  },
  {
    "text": "delta is equal to n of\nt plus 1 essentially.",
    "start": "4204290",
    "end": "4210850"
  },
  {
    "text": "I'm looking for the probability\nof there being one arrival in this interval here. ",
    "start": "4210850",
    "end": "4218980"
  },
  {
    "text": "So what's the matter\nwith that equation? ",
    "start": "4218980",
    "end": "4228870"
  },
  {
    "text": "This is the probability that\nthe n plus first arrival occurs somewhere in this\ninterval here.",
    "start": "4228870",
    "end": "4237220"
  },
  {
    "text": "Yeah. AUDIENCE: Is that last term\nthen the probability that there's not anymore other\nparameter standards as well?",
    "start": "4237220",
    "end": "4244360"
  },
  {
    "text": "PROFESSOR: It doesn't\ninclude-- yes. This last term which I had to\nadd is in fact the negligible",
    "start": "4244360",
    "end": "4252560"
  },
  {
    "text": "term that at time n of t, there\nis less than n arrivals.",
    "start": "4252560",
    "end": "4261440"
  },
  {
    "text": "And then I get 2 arrivals in\nthis little interval delta. ",
    "start": "4261440",
    "end": "4267150"
  },
  {
    "text": "So that's why I need\nthat extra term. But anyway, when I relate these\ntwo terms, I get the",
    "start": "4267150",
    "end": "4273389"
  },
  {
    "text": "probability mass function of n\nof t is equal to the Erlang density at t, where\nthe n plus first",
    "start": "4273390",
    "end": "4282820"
  },
  {
    "text": "arrival divided by lambda. And that's what that\nterm is there.",
    "start": "4282820",
    "end": "4288130"
  },
  {
    "start": "4288130",
    "end": "4294440"
  },
  {
    "text": "So that gives us the\nPoisson PMF. Interesting observation about\nthis, it's a function",
    "start": "4294440",
    "end": "4302500"
  },
  {
    "text": "only of lambda t. It's not a function of lambda\nor t separately. It's a function only of the\ntwo of them together.",
    "start": "4302500",
    "end": "4310210"
  },
  {
    "text": "It has to be that. Because you can use scaling\narguments on this.",
    "start": "4310210",
    "end": "4316179"
  },
  {
    "text": "If you have a Poisson process\nof rate lambda and I measure things in millimeters instead\nof centimeters,",
    "start": "4316180",
    "end": "4323520"
  },
  {
    "text": "what's going to happen? My rate is going to change\nby a factor of 10.",
    "start": "4323520",
    "end": "4329250"
  },
  {
    "text": "My values of t are going to\nchange by a factor of 10. ",
    "start": "4329250",
    "end": "4335615"
  },
  {
    "text": "This is a probability\nmass function. That has to stay the same. So this has to be a function\nonly of the product lambda t",
    "start": "4335615",
    "end": "4344860"
  },
  {
    "text": "because of scaling\nargument here. ",
    "start": "4344860",
    "end": "4350020"
  },
  {
    "text": "Now, the other thing here, and\nthis is interesting because if",
    "start": "4350020",
    "end": "4355290"
  },
  {
    "text": "you look at n of t, the number\nof arrivals up until time t is",
    "start": "4355290",
    "end": "4360830"
  },
  {
    "text": "the sum of the number of\narrivals up until some shorter time t1 plus the number of\narrivals between t1 and t.",
    "start": "4360830",
    "end": "4372800"
  },
  {
    "text": "We know that the number\nof arrivals up until time t1 is Poisson. The number of arrivals between\nt1 and t is Poisson.",
    "start": "4372800",
    "end": "4381280"
  },
  {
    "text": "Those two values are independent\nof each other. I can choose t1 in the middle\nto be anything I",
    "start": "4381280",
    "end": "4387580"
  },
  {
    "text": "want to make it. And this says that the sum of\ntwo Poisson random variables",
    "start": "4387580",
    "end": "4393080"
  },
  {
    "text": "has to be Poisson. Now, I'm very lazy. And I've gone through life\nwithout ever convolving this",
    "start": "4393080",
    "end": "4403800"
  },
  {
    "text": "PMF to find out that in fact\nthe sum of 2 Poisson random variables is in fact\nPoisson itself.",
    "start": "4403800",
    "end": "4412920"
  },
  {
    "text": "Because I actually believe the\nargument I just went through. ",
    "start": "4412920",
    "end": "4420510"
  },
  {
    "text": "If you're skeptical, you will\nprobably want to actually do the digital convolution to\nshow that the sum of two",
    "start": "4420510",
    "end": "4428420"
  },
  {
    "text": "independent Poisson random\nvariables is in fact Poisson.",
    "start": "4428420",
    "end": "4434540"
  },
  {
    "text": "And it extends to any [? tay ?]\ndisjoint interval. So the same argument says that\nany sum of Poisson random",
    "start": "4434540",
    "end": "4441050"
  },
  {
    "text": "variables is Poisson. I do want to get through any\nalternate definitions of a",
    "start": "4441050",
    "end": "4447650"
  },
  {
    "text": "Poisson process because\nthat makes a natural stopping point here.",
    "start": "4447650",
    "end": "4454630"
  },
  {
    "text": "Question-- is it true that any\narrival process for which n of t has a Poisson probability\nmass function for a given",
    "start": "4454630",
    "end": "4462680"
  },
  {
    "text": "lambda and for all\nt is a Poisson process of rate lambda? ",
    "start": "4462680",
    "end": "4470150"
  },
  {
    "text": "In other words, that's a\npretty strong property. It says I found the probability\nmass functions for",
    "start": "4470150",
    "end": "4476619"
  },
  {
    "text": "n of t at every value of t. Does that describe a process?",
    "start": "4476620",
    "end": "4482690"
  },
  {
    "text": "Well, you see the\nanswer there. As usual, marginal PMFs,\ndistribution functions don't",
    "start": "4482690",
    "end": "4490949"
  },
  {
    "text": "specify a process because they\ndon't specify the joint probabilities.",
    "start": "4490950",
    "end": "4497180"
  },
  {
    "text": "But here, we've just pointed\nout that these joint probabilities are\nall independent. You can take a set of\nprobability mass functions for",
    "start": "4497180",
    "end": "4505590"
  },
  {
    "text": "this interval, this interval,\nthis interval, this interval, and so forth. And for any set of t1, t2, and\nso forth up, we know that the",
    "start": "4505590",
    "end": "4518090"
  },
  {
    "text": "number of arrivals in zero to\nt1, the number of arrivals in t1 to t2, and so forth all the\nway up are all independent",
    "start": "4518090",
    "end": "4526849"
  },
  {
    "text": "random variables. And therefore, when we know the\nPoisson probability mass",
    "start": "4526850",
    "end": "4532830"
  },
  {
    "text": "function, we really also know,\nand we've also shown, that",
    "start": "4532830",
    "end": "4540770"
  },
  {
    "text": "these random variables are\nindependent of each other. We have the joint PMF for any\nsum of these random variables.",
    "start": "4540770",
    "end": "4549010"
  },
  {
    "text": "So in fact, in this particular\ncase, it's enough to know what",
    "start": "4549010",
    "end": "4559690"
  },
  {
    "text": "the probability mass function\nis at each time t plus the fact that we have this",
    "start": "4559690",
    "end": "4565820"
  },
  {
    "text": "independent increment property. And we need the stationary\nincrement property, too, to know that these values are\nthe same at each t.",
    "start": "4565820",
    "end": "4574030"
  },
  {
    "text": "So the theorem is that if an\narrival process has the stationary and independent\nincrement properties, and if n",
    "start": "4574030",
    "end": "4581420"
  },
  {
    "text": "of t has the Poisson PMF for\ngiven lambda and all t greater",
    "start": "4581420",
    "end": "4586840"
  },
  {
    "text": "than 0, then the process itself\nhas to be Poisson.",
    "start": "4586840",
    "end": "4592090"
  },
  {
    "text": "VHW stands for Violently\nHand Waving. ",
    "start": "4592090",
    "end": "4599690"
  },
  {
    "text": "So that's even a little\nworse than a PF. Says the stationary and\nindependent increment",
    "start": "4599690",
    "end": "4605219"
  },
  {
    "text": "properties show that the joint\ndistribution of arrivals over any given set of disjoint\nintervals is that",
    "start": "4605220",
    "end": "4611580"
  },
  {
    "text": "of a Poisson process. And clearly that's enough. And it almost is.",
    "start": "4611580",
    "end": "4616660"
  },
  {
    "text": "And you should read the proof in\nthe notes which does just a little more than that to make\nthis an actual proof.",
    "start": "4616660",
    "end": "4623240"
  },
  {
    "text": "OK. I think I'll stop there. And we will talk a little\nbit about the Bernoulli process next time.",
    "start": "4623240",
    "end": "4630060"
  },
  {
    "text": "Thank you. ",
    "start": "4630060",
    "end": "4633135"
  }
]
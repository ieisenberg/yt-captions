[
  {
    "start": "0",
    "end": "125000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6050"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6050",
    "end": "12700"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. ",
    "start": "12700",
    "end": "20862"
  },
  {
    "text": "JEREMY KEPNER: Welcome. Happy Halloween. And for those of you\nwatching this video at home,",
    "start": "20862",
    "end": "29019"
  },
  {
    "text": "you'll be glad to know the\nwhole audience has joined me and they're all dressed\nout in costumes. And it's a real fun\nday here as we do this.",
    "start": "29019",
    "end": "37789"
  },
  {
    "text": "So making me not feel\nalone in my costume. A lot of moral support\nthere, so that's great.",
    "start": "37790",
    "end": "45470"
  },
  {
    "text": "So, yeah. So this is Lecture 05 five on\nSignal Processing on Databases,",
    "start": "45470",
    "end": "54720"
  },
  {
    "text": "just for a recap. For those of you who\nmissed earlier classes or are going this out\nof order on the web,",
    "start": "54720",
    "end": "63700"
  },
  {
    "text": "signal processing really\nalludes detection theory, finding things, which\nalludes to the underlying",
    "start": "63700",
    "end": "70470"
  },
  {
    "text": "mathematical basis of that,\nwhich is linear algebra. And the databases\nreally refers to working",
    "start": "70470",
    "end": "78060"
  },
  {
    "text": "with unstructured data, strings,\nand other types of things. Two things that aren't\nreally talked about together,",
    "start": "78060",
    "end": "86229"
  },
  {
    "text": "but we're bringing\nthem together here because we have lots of new\ndata sets that required it.",
    "start": "86230",
    "end": "91509"
  },
  {
    "text": "And so this talk is\nprobably the one that's getting most into\nsomething that we would say",
    "start": "91510",
    "end": "98770"
  },
  {
    "text": "relates to detection\ntheory, because we're going to be dealing with a lot\nwith background data models.",
    "start": "98770",
    "end": "105060"
  },
  {
    "text": "And in particular,\npower laws and methods of constructing\npower law data sets,",
    "start": "105060",
    "end": "111110"
  },
  {
    "text": "methods on sampling and fitting,\nand using that as a basis",
    "start": "111110",
    "end": "116650"
  },
  {
    "text": "for doing the kind of\nwork that you want to do.",
    "start": "116650",
    "end": "123040"
  },
  {
    "text": "So moving in here. So just your outline. And so we've got a lot of\nmaterial to go over here today.",
    "start": "123040",
    "end": "130310"
  },
  {
    "start": "125000",
    "end": "125000"
  },
  {
    "text": "This is all using\nthe data set, when we get into the data\nset that we talked",
    "start": "130310",
    "end": "135409"
  },
  {
    "text": "about in the last lecture,\nwhich is this Reuters data set. So we'll be applying some of\nthese ideas to that data set.",
    "start": "135410",
    "end": "142510"
  },
  {
    "text": "So just going to--\nintroduction here, and then I'm going\nto get to sampling theory, and subsampling theory,\nvarious types of distributions.",
    "start": "142510",
    "end": "149410"
  },
  {
    "text": "And then end up with\nthe Reuter's data set. The overall goal\nof this lecture is",
    "start": "149410",
    "end": "155160"
  },
  {
    "start": "153000",
    "end": "153000"
  },
  {
    "text": "to really develop a background\nmodel for these types of data",
    "start": "155160",
    "end": "161140"
  },
  {
    "text": "sets that is based on what I'm\ncalling a perfect power law. And then we're\ngoing to, basically,",
    "start": "161140",
    "end": "167090"
  },
  {
    "text": "after we can construct\na perfect power law, we're going to\nsample that power law and look at what happens\nwhen we sample it.",
    "start": "167090",
    "end": "173209"
  },
  {
    "text": "What are the effects\nof sampling it? And then we can\nuse the power law to look at things like\ndeviations and such.",
    "start": "173210",
    "end": "180132"
  },
  {
    "text": "Now you might ask,\nwell, why are we so concerned about\nbackgrounds and power laws? And it's because here's sort\nof the basis of detection",
    "start": "180132",
    "end": "187860"
  },
  {
    "start": "185000",
    "end": "185000"
  },
  {
    "text": "theory on one slide. So in detection\ntheory, you basically have a model which consists\nof noise and the signal,",
    "start": "187860",
    "end": "197020"
  },
  {
    "text": "and you have two\nhypotheses, H0, which is there's only\nnoise in your data, and H1 that there's\nsignal plus noise.",
    "start": "197020",
    "end": "204530"
  },
  {
    "text": "And so, essentially, when you\ndo detection theory, what you're doing is given these\nmodels, you can then",
    "start": "204530",
    "end": "212540"
  },
  {
    "text": "compute optimal filters\nfor answering the question, is there a signal there\nor is it just noise?",
    "start": "212540",
    "end": "219959"
  },
  {
    "text": "That's essentially what\ndetection theory boils down to. In this data, now when we\ndeal with graph theory,",
    "start": "219960",
    "end": "227670"
  },
  {
    "text": "it's obviously not so clean in\nterms of our dimensions here. We'll have some kind of\nhigh dimensional space",
    "start": "227670",
    "end": "233978"
  },
  {
    "text": "and our signal will\nbe projected into that high dimensional space. But nevertheless, the concept\nis still just as important",
    "start": "233979",
    "end": "242450"
  },
  {
    "text": "that we have noise and a signal. And that's what we're\ntrying to do here. ",
    "start": "242450",
    "end": "249180"
  },
  {
    "text": "Detection theory works in\nthe traditional domains that we've applied\nit to because we",
    "start": "249180",
    "end": "255459"
  },
  {
    "text": "have a fairly good model for\nthe background, which tends to be Gaussian random noise. It's kind of the\nfundamental distribution",
    "start": "255460",
    "end": "263700"
  },
  {
    "text": "that we use in lots\nof our data sets.",
    "start": "263700",
    "end": "269400"
  },
  {
    "text": "And if we didn't\nhave that model, it would be very difficult\nfor us to proceed with much of detection theory.",
    "start": "269400",
    "end": "274880"
  },
  {
    "text": "And the Gaussian\nrandom noise model works, because in many\nrespects, if you're",
    "start": "274880",
    "end": "281210"
  },
  {
    "text": "collecting sensor\ndata, you really will have Gaussian\nphysics going on.",
    "start": "281210",
    "end": "286560"
  },
  {
    "text": "You also-- law of\nlarge numbers in terms of if you have lots of\ndifferent distributions",
    "start": "286560",
    "end": "293240"
  },
  {
    "text": "that are pulled together,\nthey will end up beginning to look like\na Gaussian as well.",
    "start": "293240",
    "end": "298300"
  },
  {
    "text": "So that's what we have in\nmany of the traditional fields that we've worked in\nin signal processing, but now we're in this new\narea where a lot of our data",
    "start": "298300",
    "end": "306390"
  },
  {
    "text": "sets arrive from artificial\nprocesses, processes that are a result of human actions.",
    "start": "306390",
    "end": "312270"
  },
  {
    "text": "Be it data on a network, be\nit data in a social network,",
    "start": "312270",
    "end": "317560"
  },
  {
    "text": "be it other types of data\nthat have a strong sort of artificial element to them.",
    "start": "317560",
    "end": "323420"
  },
  {
    "text": "We find that the\nGaussian model does not reveal itself in the same way\nthat we've seen in other sets.",
    "start": "323420",
    "end": "330190"
  },
  {
    "text": "So we need this. We really need a\nbackground model,",
    "start": "330190",
    "end": "335470"
  },
  {
    "text": "so we have to do\nsomething about it. So there has been a fair amount\nof research and literature",
    "start": "335470",
    "end": "341330"
  },
  {
    "text": "to come up with first\nprinciples, methods for creating power law\ndistribution in data sets.",
    "start": "341330",
    "end": "349540"
  },
  {
    "text": "We talked a little bit\nabout these distributions in the previous lectures. And they've met\nwith mixed results.",
    "start": "349540",
    "end": "356550"
  },
  {
    "text": "It's been difficult\nto come up with, what is the underlying\nphysics of the processes",
    "start": "356550",
    "end": "363430"
  },
  {
    "text": "that result in certain\nvertices in graphs having enormous number of\nedges and other vertices",
    "start": "363430",
    "end": "369160"
  },
  {
    "text": "only having a few? And so there has\nbeen work on that. I encourage you to look\nat that literature. Here we're going to do\nmuch more of a-- sort of go",
    "start": "369160",
    "end": "378490"
  },
  {
    "text": "from the reverse\ndirection, which is let's begin by coming up\nwith some way to construct",
    "start": "378490",
    "end": "385490"
  },
  {
    "text": "a perfect power law. With no concept of well, what\nis the underlying physics",
    "start": "385490",
    "end": "392090"
  },
  {
    "text": "motivating this? Essentially, a basic linear\nmodel for a perfect power law.",
    "start": "392090",
    "end": "398620"
  },
  {
    "text": "That we probably can do. And then we'll go from there. And linear models are\nsomething that we often",
    "start": "398620",
    "end": "404470"
  },
  {
    "text": "use in our business. And it's a good\nfirst starting point. So along those\nlines, this is a way",
    "start": "404470",
    "end": "412350"
  },
  {
    "start": "410000",
    "end": "410000"
  },
  {
    "text": "to construct a perfect\npower law in a matrix.",
    "start": "412350",
    "end": "418310"
  },
  {
    "text": "This is basically a\nslide of definitions here, so let me spend a little\ntime going through them.",
    "start": "418310",
    "end": "423430"
  },
  {
    "text": "So we're going to represent\nour graph or our data as a random matrix.",
    "start": "423430",
    "end": "428580"
  },
  {
    "text": "Basically of zero where there's\nno connection between-- this",
    "start": "428580",
    "end": "435830"
  },
  {
    "text": "is a set of vertices connected\nwith another set of vertices. There are N out of\nthese vertices and N",
    "start": "435830",
    "end": "443110"
  },
  {
    "text": "in of these vertices. You have a dot here. The row corresponds to the\nvertex at the edge left,",
    "start": "443110",
    "end": "450280"
  },
  {
    "text": "and the column\ncorresponds to the vertex that the edge is going into.",
    "start": "450280",
    "end": "455610"
  },
  {
    "text": "So this adjacency\nmatrix A is just going to be constructed\nby randomly filling",
    "start": "455610",
    "end": "462100"
  },
  {
    "text": "this matrix with entries. And the only real constraint\non them is that when you sum A,",
    "start": "462100",
    "end": "470160"
  },
  {
    "text": "we're going to allow\nmultiple edges. So you can have more--\nthe values aren't just zero and one, but they\ncan have more than that.",
    "start": "470160",
    "end": "476370"
  },
  {
    "text": "But when you sum the matrix\nA, all its values up, you get a value M, which is\nthe total number of edges",
    "start": "476370",
    "end": "484770"
  },
  {
    "text": "in the graph. So we have essentially a\ngraph with-- this could",
    "start": "484770",
    "end": "489840"
  },
  {
    "text": "be a bipartite graph or not. But with essentially N out\nvertices, N in vertices, and M",
    "start": "489840",
    "end": "498375"
  },
  {
    "text": "total edges.  The perfect power\nlaw, we're going",
    "start": "498375",
    "end": "504210"
  },
  {
    "text": "to have essentially two\nperfect power laws here. One on the out degree.",
    "start": "504210",
    "end": "509700"
  },
  {
    "text": "So if you sum these rows,\nand then you do a histogram,",
    "start": "509700",
    "end": "519190"
  },
  {
    "text": "you're going to want to\nproduce a histogram that looks something like this. So you have an out\ndegree for each vertex.",
    "start": "519190",
    "end": "525610"
  },
  {
    "text": "And this would show how many\nvertices have that out degree. And so our power law\nsays that these points",
    "start": "525610",
    "end": "531980"
  },
  {
    "text": "should fall on a slope\nwith a negative power law coefficient of alpha out.",
    "start": "531980",
    "end": "538110"
  },
  {
    "text": "So that's essentially\nthe one definition there. And then when you likewise\nhave another going in the-- for the other degree.",
    "start": "538110",
    "end": "544290"
  },
  {
    "text": "So the in degrees have\ntheir own power law. So these are the definitions. This is what we're saying\nis a perfect power law.",
    "start": "544290",
    "end": "551150"
  },
  {
    "text": "So we're saying a perfect\npower law has these properties. Now we're going to\nattempt to construct it.",
    "start": "551150",
    "end": "557370"
  },
  {
    "text": "We have no physical\nbasis for saying why the data should look this way. We're just saying this is\na linear model of the data",
    "start": "557370",
    "end": "565269"
  },
  {
    "text": "and we're going to\nconstruct it that way. And again, these can be\nundirected, multi-edge, we can allow self-loops\nand disconnected vertices,",
    "start": "565270",
    "end": "574160"
  },
  {
    "text": "and hyper-edges. Anything you can get by\njust randomly throwing down values onto a matrix.",
    "start": "574160",
    "end": "580130"
  },
  {
    "text": "And again, the\nonly constraint is that the sum in\nboth directions is",
    "start": "580130",
    "end": "586020"
  },
  {
    "text": "equal to the number of edges. So given that, can we\nconstruct such a thing?",
    "start": "586020",
    "end": "592520"
  },
  {
    "text": "Well, it turns out we can\nconstruct such a thing fairly simply. And so in MATLAB we can\nconstruct a perfect power law",
    "start": "592520",
    "end": "599009"
  },
  {
    "start": "597000",
    "end": "597000"
  },
  {
    "text": "graph with this four\nline function here.",
    "start": "599010",
    "end": "604440"
  },
  {
    "text": "It will construct a\ndegree distribution that has this property.",
    "start": "604440",
    "end": "609460"
  },
  {
    "text": "And the three number\nparameters to this distribution are alpha, which\nis the slope, dmax,",
    "start": "609460",
    "end": "616020"
  },
  {
    "text": "which is the maximum\ndegree vertex, and then this number\nNd, which is roughly",
    "start": "616020",
    "end": "622260"
  },
  {
    "text": "proportional to\nthe number of bins that we're going to have here. Essentially the\nnumber of points. It's not exactly that, but\nroughly proportional to that.",
    "start": "622260",
    "end": "630550"
  },
  {
    "text": "And so when you do this\nlittle equation here, the first thing\nthat you will see",
    "start": "630550",
    "end": "637420"
  },
  {
    "text": "is we are going to be creating\na logarithmic spacing of bins.",
    "start": "637420",
    "end": "642500"
  },
  {
    "text": "We kind of need to do that here. But at a certain point,\nwe get below a value",
    "start": "642500",
    "end": "647730"
  },
  {
    "text": "where the spacing will be--\nwe'll have essentially one bin per integer. And so these are two\nvery separate regimes.",
    "start": "647730",
    "end": "653634"
  },
  {
    "text": "You're going to have one\nwhich is called the integer regime, where basically\neach integer has",
    "start": "653634",
    "end": "659860"
  },
  {
    "text": "one-- is representative. And then it transitions\nto a logarithmic regime. You might say this is\nsomewhat artificial.",
    "start": "659860",
    "end": "666400"
  },
  {
    "text": "It's actually very reflective\nof what's really going on. We really see here--\nwe really have a dmax,",
    "start": "666400",
    "end": "673070"
  },
  {
    "text": "we really have, almost\nalways, a count at 1. And then we have\na count at 2 or 3,",
    "start": "673070",
    "end": "679079"
  },
  {
    "text": "and then they start\nspreading out. And so this is just\nan artificial way to create this type\nof distribution,",
    "start": "679080",
    "end": "685970"
  },
  {
    "text": "which is a perfect\npower law distribution. So it's a very simple,\nvery efficient code",
    "start": "685970",
    "end": "692990"
  },
  {
    "text": "for creating one of these. It has a smooth transition\nfrom what we call the integer bins and the logarithmic bins.",
    "start": "692990",
    "end": "700930"
  },
  {
    "text": "And it also gives a very nice\nwhat we call poor man slope estimator. So there's a lot of\nresearch out there",
    "start": "700930",
    "end": "707110"
  },
  {
    "text": "about how do you estimate\nthe slope of your power law. And there's all kinds of\nalgorithms for doing this.",
    "start": "707110",
    "end": "713780"
  },
  {
    "text": "Well, the simplest way is just\nto take the two endpoints. Take the first point\nand the last point,",
    "start": "713780",
    "end": "720280"
  },
  {
    "text": "and you know you're\nperfectly fitting two points. And you could argue\nyou're perfectly fitting the two most important points.",
    "start": "720280",
    "end": "725730"
  },
  {
    "text": "And you get this nice, simple\nvalue for the slope here. In addition, you can\nmake the argument",
    "start": "725730",
    "end": "732629"
  },
  {
    "text": "that regardless of\nhow you bin the data, you'll always have\nthese two bins.",
    "start": "732630",
    "end": "738280"
  },
  {
    "text": "You will always\nhave a bin at dmax and you will always\nhave a bin at 1. And all the other bins\nare going to be somewhat",
    "start": "738280",
    "end": "746070"
  },
  {
    "text": "a matter of choice,\nor of fitting. And so again, that's another\nreason to rationalize alpha.",
    "start": "746070",
    "end": "752440"
  },
  {
    "text": "So I would say, if\nyou plot your data and you have to\nestimate an alpha, then I would just say,\nwell, here's what you do.",
    "start": "752440",
    "end": "760250"
  },
  {
    "text": "And it's as good an\nestimate of alpha as any. And it's very nicely defined. So we call that-- when\nwe talk about estimating",
    "start": "760250",
    "end": "767589"
  },
  {
    "text": "the slope here, this is the\nformula we're going to use. So far, this code\nhas just constructed",
    "start": "767590",
    "end": "776680"
  },
  {
    "text": "a degree distribution,\ni.e., the degree, and then the number of vertices\nwith that degree",
    "start": "776680",
    "end": "781780"
  },
  {
    "text": "will be the outputs of this\nperfect power law function. We still have to assign\nthat degree distribution",
    "start": "781780",
    "end": "790720"
  },
  {
    "start": "787000",
    "end": "787000"
  },
  {
    "text": "to an actual set of edges. OK? And here's the code\nthat will do that for.",
    "start": "790720",
    "end": "796050"
  },
  {
    "text": "It will say, given a\ndegree distribution, it will create a set of\nvertices that do that.",
    "start": "796050",
    "end": "804340"
  },
  {
    "text": "Now, the actual pairing\nof the vertices into edges",
    "start": "804340",
    "end": "811910"
  },
  {
    "text": "is arbitrary. And in fact, these are all\ndifferent adjacency matrices",
    "start": "811910",
    "end": "822100"
  },
  {
    "text": "for the same degree\ndistribution. That is, every\nsingle one of these",
    "start": "822100",
    "end": "827649"
  },
  {
    "text": "has the same degree\ndistribution in both the rows and the columns. So the actual which vertices\nare connected to which",
    "start": "827650",
    "end": "835810"
  },
  {
    "text": "is a second order statistic. So the degree distribution in\nthis first order [INAUDIBLE],",
    "start": "835810",
    "end": "841160"
  },
  {
    "text": "but how you want to\nconnect those vertices up is somewhat arbitrary. And so that's a freedom\nthat you have here.",
    "start": "841160",
    "end": "849020"
  },
  {
    "text": "So for example, if I just\ntake the vertices out of here and I just say, all right, every\nsingle vertex in your list,",
    "start": "849020",
    "end": "855660"
  },
  {
    "text": "I'm just going to pair\nit up with yourself, I will get an adjacency\nmatrix that's all diagonals. Essentially, all self-loops.",
    "start": "855660",
    "end": "862680"
  },
  {
    "text": "If I take that list\nand just randomly reorder the vertex\nlabels themselves,",
    "start": "862680",
    "end": "868940"
  },
  {
    "text": "then I get something\nthat looks like this. If I just randomly\nreorder the edge pairs,",
    "start": "868940",
    "end": "874520"
  },
  {
    "text": "I get something like this. And if I randomly\nrelabel both the vertices and reconnect the vertices\ninto different edges,",
    "start": "874520",
    "end": "883750"
  },
  {
    "text": "I get something like this. And for the most part, when\nwe talk about our randomly generating our\nperfect power laws,",
    "start": "883750",
    "end": "890800"
  },
  {
    "text": "we're going to talk about this. Which is probably most like\nwhat we really encounter.",
    "start": "890800",
    "end": "895815"
  },
  {
    "text": "It's essentially\nsomething that's equivalent to randomly\nlabeling your vertices, and then randomly\ntaking those vertices",
    "start": "895815",
    "end": "901420"
  },
  {
    "text": "and randomly pairing\nthem together. So that basically\ntalks about how",
    "start": "901420",
    "end": "908600"
  },
  {
    "text": "we can actually construct a\ngraph from our perfect power law edge. Now, so this is a forward model.",
    "start": "908600",
    "end": "915430"
  },
  {
    "text": "Given a set of these\nthree sort of parameters, we can generate a\nperfect power law.",
    "start": "915430",
    "end": "921759"
  },
  {
    "text": "But if we're dealing\nwith data, we often want slightly\ndifferent parameters.",
    "start": "921760",
    "end": "927800"
  },
  {
    "start": "925000",
    "end": "925000"
  },
  {
    "text": "So as I said, before our\nthree parameters were alpha, which is greater\nthan 0, dmax, which",
    "start": "927800",
    "end": "935500"
  },
  {
    "text": "is the highest degree in\nthe data, which we're saying is greater than 1, and then\nthis parameter Nd, which roughly",
    "start": "935500",
    "end": "943320"
  },
  {
    "text": "corresponds to number of bins. So we can generate a power law\nmodel for any of these values",
    "start": "943320",
    "end": "949500"
  },
  {
    "text": "here that satisfy\nthese constraints. So that's a large number. However, what\nwe'll typically see",
    "start": "949500",
    "end": "955480"
  },
  {
    "text": "is that we want to\nuse these parameters. So we'll want to have an\nalpha, a number of vertices,",
    "start": "955480",
    "end": "962449"
  },
  {
    "text": "and a number of edges, is\nmore often the parameters we want to work with. And we can compute those by\ninverting these formulas.",
    "start": "962450",
    "end": "969730"
  },
  {
    "text": "That is, if we\ncompute the degree, we can sum it to compute\nthe number of vertices.",
    "start": "969730",
    "end": "975450"
  },
  {
    "text": "And likewise, we can sum the\ndistribution times the degree to get the number of edges.",
    "start": "975450",
    "end": "981730"
  },
  {
    "text": "So given these, an alpha and\nour model, we can invert these. All right?",
    "start": "981730",
    "end": "986750"
  },
  {
    "text": "And what you see here is\nfor a given value of alpha,",
    "start": "986750",
    "end": "992000"
  },
  {
    "text": "the allowed values\nof N and M, given-- that is, the values of N and\nM that will be a power law.",
    "start": "992000",
    "end": "1000940"
  },
  {
    "text": "So what you see is that not\nall combinations of vertices,",
    "start": "1000940",
    "end": "1007970"
  },
  {
    "text": "vertex count and edge count, can\nbe constructed in a power law. There's a band here. This is a logarithmic graph.",
    "start": "1007970",
    "end": "1014020"
  },
  {
    "text": "It's a wide band. But there's a band\nhere of allowable data",
    "start": "1014020",
    "end": "1019780"
  },
  {
    "text": "that will produce that. And typically, what\nyou see is kind of the middle of this band\nis like a ratio of around 10,",
    "start": "1019780",
    "end": "1026530"
  },
  {
    "text": "which happens to be the\nmagic number that we see in lots of our data\nsets when people say,",
    "start": "1026530",
    "end": "1031539"
  },
  {
    "text": "I have power law data. Someone will ask you, well,\nwhat's your to vertex to ratio? And [INAUDIBLE] we say,\nit's like 8, or 10, or 20,",
    "start": "1031540",
    "end": "1038280"
  },
  {
    "text": "or something like that. And again, you see it's\nbecause in order for it to be power law data, at\nleast according to this model,",
    "start": "1038280",
    "end": "1044109"
  },
  {
    "text": "it has to fall into\nthis band here. You'll also see this is a\nvery nonlinear function here.",
    "start": "1044109",
    "end": "1050270"
  },
  {
    "text": "And we'll get into\nfitting that later. And it's a nasty, nasty\nfunction to invert, because we have\ninteger data, and data",
    "start": "1050270",
    "end": "1056990"
  },
  {
    "text": "that's almost continuous. And it's a nasty, nasty\nbus-- we can do it, but it's kind of\na nasty business.",
    "start": "1056990",
    "end": "1063740"
  },
  {
    "text": "But given an alpha and\nan N that are consistent, we can actually then generate\na dmax and an Nd that",
    "start": "1063740",
    "end": "1070510"
  },
  {
    "text": "will best fit those parameters. So let's do an example here.",
    "start": "1070510",
    "end": "1077769"
  },
  {
    "text": "So I didn't just dress up in\nthis crazy outfit for nothing. We have a whole Halloween\ntheme to our lecture today.",
    "start": "1077770",
    "end": "1083920"
  },
  {
    "start": "1078000",
    "end": "1078000"
  },
  {
    "text": "So this is-- when I\ngo trick or treating with my daughter, of\ncourse, our favorite thing",
    "start": "1083920",
    "end": "1091100"
  },
  {
    "text": "is to do the distribution of\nthe candy when we're done. And so this shows last\nyear's candy distribution.",
    "start": "1091100",
    "end": "1097230"
  },
  {
    "text": "We'll see how it varies. As you can see,\nHershey's chocolate",
    "start": "1097230",
    "end": "1102430"
  },
  {
    "text": "bars, not surprisingly,\nextremely popular. What else is popular here?",
    "start": "1102430",
    "end": "1108900"
  },
  {
    "text": "Swedish fish, not so popular. Nestle's Crunch\nbars, not so popular.",
    "start": "1108900",
    "end": "1113980"
  },
  {
    "text": "Again, I actually found\nthis somewhat-- this list hasn't change since when\nI went trick or treating.",
    "start": "1113980",
    "end": "1119640"
  },
  {
    "text": "This is a tough\nlist to break into. Getting a new candy that makes\nit to Halloween-worthy candy",
    "start": "1119640",
    "end": "1126370"
  },
  {
    "text": "is pretty hard. So this year shows the\ndistribution of all the candy that we collected.",
    "start": "1126370",
    "end": "1132400"
  },
  {
    "text": "And here are some\nbasic information. So we had 77 pieces of\ncandy, or distinct edges.",
    "start": "1132400",
    "end": "1138780"
  },
  {
    "text": "We had 19 types of candy. Our edge to vertex ratio was 4.",
    "start": "1138780",
    "end": "1144540"
  },
  {
    "text": "The dmax was 15. So we had 15 Hershey's Kisses.",
    "start": "1144540",
    "end": "1151380"
  },
  {
    "text": "N1, we had eight types of\ncandy that we only got one of. And then our power\nslope was alpha.",
    "start": "1151380",
    "end": "1158360"
  },
  {
    "text": "And then our fit\nparameters to this, when we actually fit, where\nwe got 77, 21, and M/N of 3.7.",
    "start": "1158360",
    "end": "1165940"
  },
  {
    "text": "And this shows you the data. So this is the candy degree. And this is the number.",
    "start": "1165940",
    "end": "1171270"
  },
  {
    "text": "And this shows you\nwhat we measured. This is the poor\nman's slope here.",
    "start": "1171270",
    "end": "1177290"
  },
  {
    "text": "This is the model. And then one thing we\ncan do is actually-- which is very\nhelpful-- is we can",
    "start": "1177290",
    "end": "1183020"
  },
  {
    "text": "re-bin the measured data\nusing the bins extracted from the model. And that gets you these red\nx's here, or plus signs here.",
    "start": "1183020",
    "end": "1197882"
  },
  {
    "text": "And we'll discover\nthat's very important. Because the data\nyou have is often very rarely binned\nin a way that's",
    "start": "1197882",
    "end": "1203740"
  },
  {
    "text": "proper for seeing the\nproper distribution. And we can actually\nuse this model",
    "start": "1203740",
    "end": "1209790"
  },
  {
    "text": "to come up with what\na better set of bins would be, and then bin the\ndata with respect to that.",
    "start": "1209790",
    "end": "1216540"
  },
  {
    "text": "So that's just an example\nof this in actual practice. ",
    "start": "1216540",
    "end": "1223299"
  },
  {
    "text": "So now that we have a mechanism\nfor generating perfect power law, let's see what\nhappens when we sample it.",
    "start": "1223300",
    "end": "1231450"
  },
  {
    "text": "Let's see what\nhappens when we do the things to it\nthat we typically",
    "start": "1231450",
    "end": "1238680"
  },
  {
    "text": "do to clean up our data. I bring this up because in\nstandard graph theory, as I've",
    "start": "1238680",
    "end": "1244669"
  },
  {
    "text": "talked about in\nprevious lectures, we often have what\nwe call random,",
    "start": "1244670",
    "end": "1253380"
  },
  {
    "text": "undirected Erdos-Renyi\ngraphs, which are basically vertices\nwithout direction.",
    "start": "1253380",
    "end": "1261000"
  },
  {
    "text": "And usually the\nedges are unweighted. So we just have a 0 or a 1. So very simplified graphs.",
    "start": "1261000",
    "end": "1268740"
  },
  {
    "text": "I'm actually going to--\ngetting a little hot here in the top hat. ",
    "start": "1268740",
    "end": "1277520"
  },
  {
    "text": "So a lot of our graph theory is\nbased on these types of graphs. And as we've talked about\nbefore that our data tends",
    "start": "1277520",
    "end": "1284090"
  },
  {
    "text": "to not look like that. So one of the things\nwe do so that we can apply the theory to\nthat data is that we often",
    "start": "1284090",
    "end": "1291580"
  },
  {
    "text": "make with data look like that. So we'll often make\nwith data undirected. We'll often make the\ndata basically unweighted",
    "start": "1291580",
    "end": "1300700"
  },
  {
    "text": "and other types of things so\nwe can apply all the theory that we've developed over\nthe last several decades",
    "start": "1300700",
    "end": "1306440"
  },
  {
    "text": "on these particular types\nof very well studied graphs. So now that we have a\nperfect power law graph,",
    "start": "1306440",
    "end": "1312190"
  },
  {
    "text": "we can see what happens if we\napply those same corrections to the data.",
    "start": "1312190",
    "end": "1317270"
  },
  {
    "start": "1317000",
    "end": "1317000"
  },
  {
    "text": "And so here's what we see. So we generated a\nperfect power law graph. The alpha is 1.3.",
    "start": "1317270",
    "end": "1322340"
  },
  {
    "text": "The dmax was 1,000. Our Nd was 50. This generated a data set with\n18,000 vertices and 84,000",
    "start": "1322340",
    "end": "1330490"
  },
  {
    "text": "edges. And so here's a very\nsimple way to make it.",
    "start": "1330490",
    "end": "1337510"
  },
  {
    "text": "We're going to make it\nundirected by basically taking the matrix and\nadding its transpose,",
    "start": "1337510",
    "end": "1343920"
  },
  {
    "text": "and then taking\nthe upper diagonal. This is actually the best way\nto make an adjacency matrix",
    "start": "1343920",
    "end": "1350750"
  },
  {
    "text": "undirected, to take\nthat upper portion, because a lot of the\nstatistics that-- basically it",
    "start": "1350750",
    "end": "1360190"
  },
  {
    "text": "saves you having to deal with\na lot of annoying factors of 2. So a lot of times, we'll\njust do A plus A transpose,",
    "start": "1360190",
    "end": "1365789"
  },
  {
    "text": "but then you get these annoying\nfactors of 2 lying around. And so this is a way\nto sort of not do that.",
    "start": "1365790",
    "end": "1371940"
  },
  {
    "text": "So we're getting rid of--\nwe've made it undirected. We're made it undirected\nby doing that.",
    "start": "1371940",
    "end": "1378030"
  },
  {
    "text": "We're going to make it\nunweighted by basically converting everything to a 0\nor 1, and then back to double.",
    "start": "1378030",
    "end": "1383899"
  },
  {
    "text": "So that makes it unweighted. And then we're getting\nrid of the diagonal, so that eliminates self-loops.",
    "start": "1383900",
    "end": "1389250"
  },
  {
    "text": " So we've done all these things. We've cleaned up our\ndata in this way.",
    "start": "1389250",
    "end": "1394740"
  },
  {
    "text": "So what happens? Well, so the triangles\nwere the input model. Well, now we've\ncleaned up our data,",
    "start": "1394740",
    "end": "1401210"
  },
  {
    "text": "and we see this sort of mess\nthat we've done to our data.",
    "start": "1401210",
    "end": "1407970"
  },
  {
    "text": "And in fact, I'll call this--\nin keeping with our Halloween",
    "start": "1407970",
    "end": "1414049"
  },
  {
    "text": "theme here, we'll call this\nour witch's broom distribution here. And if anybody's looked at\ndegree redistributions on data,",
    "start": "1414050",
    "end": "1420120"
  },
  {
    "text": "it will be like you'll\nrecognize this shape instantly because you have this\nbendiness coming up here.",
    "start": "1420120",
    "end": "1427260"
  },
  {
    "text": "And then sort of\nfanning out down here. Very common thing that we see\nin the data sets that we plot.",
    "start": "1427260",
    "end": "1437860"
  },
  {
    "text": "And in fact, there's not\nan insignificant amount of literature devoted to trying\nto understand these bumps",
    "start": "1437860",
    "end": "1445525"
  },
  {
    "text": "and wiggles, and do they\nreally mean something underlying about the physical\nphenomenon that's taking place.",
    "start": "1445525",
    "end": "1453287"
  },
  {
    "text": "And while it's the case that\nthose bumps and wiggles may actually be representative\nof some physical phenomenon,",
    "start": "1453287",
    "end": "1460200"
  },
  {
    "text": "based on this, we\nalso have to concede the fact it's also consistent\nwith our cleaning up procedure.",
    "start": "1460200",
    "end": "1465630"
  },
  {
    "text": "That is, the thing we're trying\nto do to make our data better is introducing\nnonlinear phenomenon",
    "start": "1465630",
    "end": "1471090"
  },
  {
    "text": "on the data, which we may\nconfuse with real phenomena. So this is very much\na cautionary tale.",
    "start": "1471090",
    "end": "1479270"
  },
  {
    "text": "And so based on\nthat, I certainly encourage people not to clean\nup their data in that way,",
    "start": "1479270",
    "end": "1485020"
  },
  {
    "text": "and keep the directedness. Don't throw away the self-loops. Keep the weightedness.",
    "start": "1485020",
    "end": "1490290"
  },
  {
    "text": "Do your degree\ndistributions in this way. And live with the fact that\nthat's what your data really is like and try and\nunderstand it that way,",
    "start": "1490290",
    "end": "1496760"
  },
  {
    "text": "rather than trying\ncleaning up in this way. Sometimes you have no choice. The algorithms that\nyou have will only work on data being that's\nbeen cleaned up in this way.",
    "start": "1496760",
    "end": "1503940"
  },
  {
    "text": "But you have to\nrecognize you are introducing a new phenomena. It's a highly non-linear\nprocess, this cleaning up,",
    "start": "1503940",
    "end": "1510067"
  },
  {
    "text": "and you have to be\ncareful about that.  However, given that\nwe've done this,",
    "start": "1510067",
    "end": "1517409"
  },
  {
    "text": "is there a way that we can\nrecover the original power law? So we can try that.",
    "start": "1517410",
    "end": "1523360"
  },
  {
    "start": "1519000",
    "end": "1519000"
  },
  {
    "text": "So we have here is the data that\nwe-- the original data that we",
    "start": "1523360",
    "end": "1531059"
  },
  {
    "text": "cleaned up is now these circles. OK? And we're going to\ntake that data set",
    "start": "1531060",
    "end": "1536680"
  },
  {
    "text": "and compute an alpha\nand an N and M from it from using pour\ninversion formulas.",
    "start": "1536680",
    "end": "1542360"
  },
  {
    "text": "And then compute what the\npower law of that would be. So that's the triangles.",
    "start": "1542360",
    "end": "1548170"
  },
  {
    "text": "So here's our poor\nman's alpha fit. This is our model.",
    "start": "1548170",
    "end": "1555090"
  },
  {
    "text": "This is what the model is. These triangles here is\nthe model, we're saying. And then we can say, aha,\nlet's use the bins that",
    "start": "1555090",
    "end": "1562059"
  },
  {
    "text": "came from this model\nto re-bin these circles onto these red plus signs here.",
    "start": "1562060",
    "end": "1568425"
  },
  {
    "text": "So that's our new data set. And what you see\nis that we've done a pretty good job of recovering\nthe original power law.",
    "start": "1568426",
    "end": "1575200"
  },
  {
    "text": "So if we had data that we\nobserved to look like this, we wouldn't be sure\nit was a power law.",
    "start": "1575200",
    "end": "1580410"
  },
  {
    "text": "Like, we don't know. Say, well, what's\nthis bend here? And what's this\nfanning out here? But then if you go through\nthis process and re-bin it,",
    "start": "1580410",
    "end": "1586800"
  },
  {
    "text": "you can be like, oh, no, that\nreally looks like a power law. And so that's a way of\nrecovering the power",
    "start": "1586800",
    "end": "1592205"
  },
  {
    "text": "law that we may have lost\nthrough some filtering procedure. ",
    "start": "1592205",
    "end": "1601190"
  },
  {
    "start": "1600000",
    "end": "1600000"
  },
  {
    "text": "Here's another example. So what we're going to do is\nessentially take our matrix and compute the\ncorrelation of it.",
    "start": "1601190",
    "end": "1608460"
  },
  {
    "text": "We talked a lot\nabout-- if we say I have an incidence matrix, we\nmultiply it to do correlation.",
    "start": "1608460",
    "end": "1614490"
  },
  {
    "text": "In this case, we're\ntreating our random matrix as not an adjacency\nmatrix, but as an incidence matrix, a randomly\ngenerated incidence matrix.",
    "start": "1614490",
    "end": "1622330"
  },
  {
    "text": "And so these are, again,\nthe parameters that we use. We're converting it to all\nunweighted, all 0's and 1's.",
    "start": "1622330",
    "end": "1630630"
  },
  {
    "text": "And then we are\ncorrelating it with itself to construct the\nadjacency matrix. Taking the upper diagonal, and\nthen removing the diagonal.",
    "start": "1630630",
    "end": "1638410"
  },
  {
    "text": "And this is the\nresult of what we see. So here's our input model. Again, the triangles.",
    "start": "1638410",
    "end": "1643570"
  },
  {
    "text": "And then this is the measured--\nwhat we get out from there. And if you saw this,\nyou might be like, wow,",
    "start": "1643570",
    "end": "1650090"
  },
  {
    "text": "that's a really good power law. In fact, I've certainly seen\ndata-- I mean, most the time I would see, yep, that is\na power law distribution.",
    "start": "1650090",
    "end": "1657330"
  },
  {
    "text": "We absolutely have a\npower law distribution. However, we then\napply our procedure. ",
    "start": "1657330",
    "end": "1665810"
  },
  {
    "start": "1664000",
    "end": "1664000"
  },
  {
    "text": "So again, we have\nour measured data. OK, we're going to do\nour parameters here.",
    "start": "1665810",
    "end": "1671309"
  },
  {
    "text": "Get our poor man's\nalpha parameter. And then fit, the\ntriangles are the new fit.",
    "start": "1671310",
    "end": "1677280"
  },
  {
    "text": "OK. And then we use\nthose bins to re-bin. And we see here that when\nwe actually re-bin the data,",
    "start": "1677280",
    "end": "1685220"
  },
  {
    "text": "we get something that looks\nvery much not like a power law distribution. So there's an example\nof the reverse.",
    "start": "1685220",
    "end": "1691830"
  },
  {
    "text": "Before we had data that\ndidn't look like a power law, but when we re-binned it,\nwe recovered the power law.",
    "start": "1691830",
    "end": "1696840"
  },
  {
    "text": "Here we have data\nthat may-- just sort of in this random binning\nmay look like a power law. We actually see\nit has this bump.",
    "start": "1696840",
    "end": "1703539"
  },
  {
    "text": "And then continuing with\nour Halloween theme, we can call this the\nwitch's nose distribution, because it comes along\nhere as this giant bump",
    "start": "1703540",
    "end": "1710350"
  },
  {
    "text": "and then goes back\nto a power law. And this actually,\nthere's meaning for this.",
    "start": "1710350",
    "end": "1715690"
  },
  {
    "text": "And we will see this\nlater in the actual data. But this is not just that\nwhen you do these correlation",
    "start": "1715690",
    "end": "1721660"
  },
  {
    "text": "matrices, certain types of them,\nparticularly self-correlations, very likely will produce\nthis type of distribution.",
    "start": "1721660",
    "end": "1730029"
  },
  {
    "text": "But again, even though\nwe have this bump, you would still argue that\nour linear power law is still",
    "start": "1730030",
    "end": "1736640"
  },
  {
    "text": "a very good first order fit. So we still captured\nmost of the dynamic range",
    "start": "1736640",
    "end": "1742049"
  },
  {
    "text": "of the distribution. And this is now a\ndelta from that. And so we're very\ncomfortable with that, right?",
    "start": "1742050",
    "end": "1747704"
  },
  {
    "text": "We start with our linear models. That models most of the data. And then we have a second order. If we wanted to, we\ncould go in and come up",
    "start": "1747704",
    "end": "1753831"
  },
  {
    "text": "with some kind of second order. Subtract the linear\nmodel from here and you would see some kind\nof hump distribution here.",
    "start": "1753831",
    "end": "1761400"
  },
  {
    "text": "And you could then model\nyour data as a linear model, plus some kind of correction. Again, very classic\nsignal processing way",
    "start": "1761400",
    "end": "1769299"
  },
  {
    "text": "to deal with our data,\nand certainly seems as relevant here\nas anywhere else. ",
    "start": "1769300",
    "end": "1779260"
  },
  {
    "text": "Let's see here. ",
    "start": "1779260",
    "end": "1787920"
  },
  {
    "text": "And again, so the power\nlaw can be preserved as we talked about there.",
    "start": "1787920",
    "end": "1794399"
  },
  {
    "text": "So moving on, another\nphenomenon that's often documented\nin the literature is called the densification.",
    "start": "1794400",
    "end": "1801830"
  },
  {
    "start": "1796000",
    "end": "1796000"
  },
  {
    "text": "In fact, there's many\npapers written on what is called densification. This is the observation that\nif you construct a graph,",
    "start": "1801830",
    "end": "1809800"
  },
  {
    "text": "and you compute the\nratio of the edges to vertices over time,\nthat ratio will go up.",
    "start": "1809800",
    "end": "1818410"
  },
  {
    "text": "And there's a lot\nof research talking about the physical\nphenomenon that might produce that type of effect.",
    "start": "1818410",
    "end": "1825300"
  },
  {
    "text": "And so while that physical\nphenomenon might be there, it's also a byproduct of\njust sampling the data.",
    "start": "1825300",
    "end": "1831460"
  },
  {
    "text": "So for instance here,\nwhat we're going to do is we created our\nperfect power law graph",
    "start": "1831460",
    "end": "1837570"
  },
  {
    "text": "and we're going to sample it. We're basically going to\ntake subsamples of that data.",
    "start": "1837570",
    "end": "1843000"
  },
  {
    "text": "And we're going to do it\nin little chunks, about 10% of the data at a time.",
    "start": "1843000",
    "end": "1848539"
  },
  {
    "text": "And the triangles\nand the circles show when we look at each\nset of data independently.",
    "start": "1848540",
    "end": "1855760"
  },
  {
    "text": "And then we have\nthese lines that show what happens when\nwe do it cumulatively.",
    "start": "1855760",
    "end": "1861169"
  },
  {
    "text": "We basically take 10% of the\ndata, then 20% of the data, then 30% and move on here.",
    "start": "1861170",
    "end": "1866910"
  },
  {
    "text": "And we have two different ways\nof sampling our data here. Random is, I'm just\ntaking that whole matrix",
    "start": "1866910",
    "end": "1872149"
  },
  {
    "text": "and I'm randomly\npicking edges out of it. And what you see\nis that each sample",
    "start": "1872150",
    "end": "1878320"
  },
  {
    "text": "has a relatively low edge\nto vertex distribution.",
    "start": "1878320",
    "end": "1886399"
  },
  {
    "text": "But as you add more and more\nand more up, it gets denser. And this is just simply\nthe fact that given",
    "start": "1886400",
    "end": "1894340"
  },
  {
    "text": "a finite number of\nvertices, you eventually,",
    "start": "1894340",
    "end": "1899610"
  },
  {
    "text": "if you kept on adding\nedges and edges and edges, eventually it would go--\nthis would become infinite.",
    "start": "1899610",
    "end": "1905027"
  },
  {
    "text": "If you add an infinite\nnumber of edges to a finite\n[INAUDIBLE] vertices, then it will get denser and\ndenser and denser and denser.",
    "start": "1905027",
    "end": "1912100"
  },
  {
    "text": "And this is sort of a byproduct\nof treating these as 0 and 1's.",
    "start": "1912100",
    "end": "1917682"
  },
  {
    "text": "And not recognizing. So this just naturally\noccurs through sampling.",
    "start": "1917682",
    "end": "1922950"
  },
  {
    "text": "The linear sampling here\nis where, basically, I'm taking whole rows at a time. Or I could have taken\nwhole columns at a time.",
    "start": "1922950",
    "end": "1929440"
  },
  {
    "text": "So I'm taking each row and\neventually, all right, I'm dropping them down. And there you say it's constant.",
    "start": "1929440",
    "end": "1934970"
  },
  {
    "text": "So I'm basically for\neach-- I'm essentially taking a whole vertex\nand adding it at a time. And here the sampling is\nsomewhat independent of it.",
    "start": "1934970",
    "end": "1942640"
  },
  {
    "text": "The densification-- if\nyou sample whole rows, the density of that will be\nthe same as if you did it.",
    "start": "1942640",
    "end": "1949592"
  },
  {
    "text": "So this is just good to know. And good to know about\nsampling and these phenomena can take place, and\nthen how sampling",
    "start": "1949592",
    "end": "1954840"
  },
  {
    "text": "can play an important role\nin the data that we observe. ",
    "start": "1954840",
    "end": "1961770"
  },
  {
    "text": "Another phenomenon that's\nbeen studied extensively is what happens to the slope\nof the degree distribution",
    "start": "1961770",
    "end": "1968059"
  },
  {
    "text": "as you add data. And again, we do this exact\nsame type of sampling. And you see here that when we\njust-- this data had a slope,",
    "start": "1968060",
    "end": "1977330"
  },
  {
    "text": "I believe, of 1.3. And you can see if we\nsample it randomly, just",
    "start": "1977330",
    "end": "1983540"
  },
  {
    "text": "take random vertices, that\nthe slope starts out very, very high. And each sample stays high.",
    "start": "1983540",
    "end": "1989530"
  },
  {
    "text": "But when we start\naccumulating them, they start converging on\nthe true value-- converging",
    "start": "1989530",
    "end": "1995640"
  },
  {
    "text": "from above. And likewise, when you\ndo linear sampling, you have a direction\nin the opposite way.",
    "start": "1995640",
    "end": "2003020"
  },
  {
    "text": "And they both end up converging\nonto the true value here of 1.3. And so again, this just shows\nthat the slope of your degree",
    "start": "2003020",
    "end": "2010690"
  },
  {
    "text": "distribution is also very much\na function of the sampling. It could also be a function\nof the underlying phenomenon.",
    "start": "2010690",
    "end": "2017240"
  },
  {
    "text": "But again, a cautionary\ntale that one needs to be very aware\nof how one's sampling. And again, these perfect\npower law data sets",
    "start": "2017240",
    "end": "2027169"
  },
  {
    "text": "are a very useful\ntool for doing that. So if you have a real\ndata set and you're sampling in some\nway, and you want",
    "start": "2027170",
    "end": "2033380"
  },
  {
    "text": "to know what is maybe real\nphenomenon versus what is sampling effects, if you go\nand generate a perfect power",
    "start": "2033380",
    "end": "2040670"
  },
  {
    "text": "law that's an approximation\nof this data set, you can then very quickly\nsee which phenomena are just",
    "start": "2040670",
    "end": "2046210"
  },
  {
    "text": "a result of sampling\na perfect power law, and which phenomena are maybe\nindicative of some deeper",
    "start": "2046210",
    "end": "2051780"
  },
  {
    "text": "underlying correlations\nbetween the data. So again, a very\nuseful tool here.",
    "start": "2051780",
    "end": "2059658"
  },
  {
    "text": "Moving on, we're going to\ntalk about subsampling. And one of the problems that we\nhave is very large data sets.",
    "start": "2059659",
    "end": "2065460"
  },
  {
    "text": "And often we can't compute\nthe degree distribution on the entire data set. Or we can't-- and this has\nsort of been a bread and butter",
    "start": "2065460",
    "end": "2072865"
  },
  {
    "text": "of signal processing for years,\nwhere if we want to compute a background model, that we\ndon't just simply sum up all",
    "start": "2072865",
    "end": "2080320"
  },
  {
    "text": "the data. That we randomly select\ndata from the data set, and we use that as a\nmodel of our background.",
    "start": "2080320",
    "end": "2086969"
  },
  {
    "text": "And that's a much\nmore efficient way, from a computational and\ndata handling perspective, than simply computing\nthe mean or the variance",
    "start": "2086969",
    "end": "2094050"
  },
  {
    "text": "based on the entire data set. So again, we need good\nbackground estimation in order",
    "start": "2094050",
    "end": "2101570"
  },
  {
    "start": "2098000",
    "end": "2098000"
  },
  {
    "text": "to do our anomaly detection. And again, it's prohibitive\nto traverse the data.",
    "start": "2101570",
    "end": "2107020"
  },
  {
    "text": "So the question is,\ncan we add accurately estimate the background\nfrom a sample?",
    "start": "2107020",
    "end": "2112257"
  },
  {
    "text": "So let's see what happens. We have a perfect power law. We can look at what happens\nwhen we sample that.",
    "start": "2112257",
    "end": "2117410"
  },
  {
    "start": "2117000",
    "end": "2117000"
  },
  {
    "text": "So we've generated a power law. OK. And this is not-- I've changed--\nthis may look like the degree",
    "start": "2117410",
    "end": "2124580"
  },
  {
    "text": "distribution, but it's\nactually a different plot. So this is showing every\nsingle vertex in the data set.",
    "start": "2124580",
    "end": "2130890"
  },
  {
    "text": "All right. And this shows the N\ndegree of that vertex. And we've sorted them.",
    "start": "2130890",
    "end": "2136720"
  },
  {
    "text": "So the highest degree\nvertex is over here and the lowest degree\nvertex is over here.",
    "start": "2136720",
    "end": "2144970"
  },
  {
    "text": "OK. So this is all the vertices. ",
    "start": "2144970",
    "end": "2150740"
  },
  {
    "text": "And so this is the true data. And this is what happens\nwhen we take a 1/40 sample.",
    "start": "2150740",
    "end": "2156862"
  },
  {
    "text": "I just say, I'm only going\nto take 1/40 of the edges. What does it look like? Some relatively simple math\nhere, which I won't go over.",
    "start": "2156862",
    "end": "2164516"
  },
  {
    "start": "2163000",
    "end": "2163000"
  },
  {
    "text": "But it's there for you. We can actually\ncome up a correction that allows us to\nsample that data based on the median distributions.",
    "start": "2164517",
    "end": "2170580"
  },
  {
    "text": "I apologize for the slides. We will correct them for the\nweb when we go out there.",
    "start": "2170580",
    "end": "2177140"
  },
  {
    "text": "All right. So moving on. So one of the things\nwe talk about sampling, and we talk mainly about\nsingle distributions.",
    "start": "2177140",
    "end": "2183279"
  },
  {
    "text": "We can also talk about\njoint distributions. So we can actually\nuse the degree",
    "start": "2183280",
    "end": "2189730"
  },
  {
    "start": "2187000",
    "end": "2187000"
  },
  {
    "text": "as a way of labeling the\nvertices and look at them. So it's a way of\ncompressing-- if we just say,",
    "start": "2189730",
    "end": "2196300"
  },
  {
    "text": "we're going to label each\nvertex by its degree, this is a way of compressing\nmany vertices into a smaller",
    "start": "2196300",
    "end": "2204490"
  },
  {
    "text": "dimensional space\nway to look at that. And we can then count\nthe correlations.",
    "start": "2204490",
    "end": "2210950"
  },
  {
    "text": "We can look at the distribution\nof how many edges are there from vertices of this degree\nto vertices of that degree?",
    "start": "2210950",
    "end": "2219300"
  },
  {
    "text": "And so it's a tool for\nprojecting our data and understanding\nwhat's going on. And we can also then\nre-bin that data",
    "start": "2219300",
    "end": "2225369"
  },
  {
    "text": "with a power law, which will\nmake it more easily understood. So if we look here, we see that\nwe had the degree distribution.",
    "start": "2225370",
    "end": "2240069"
  },
  {
    "start": "2231000",
    "end": "2231000"
  },
  {
    "text": "So this shows us for a\nperfect power law data,",
    "start": "2240070",
    "end": "2246110"
  },
  {
    "text": "for vertices with this degree\nin and this degree out, how many",
    "start": "2246110",
    "end": "2252890"
  },
  {
    "text": "edges there were between them. And as you see here,\nobviously, there was a lot of vertices here\nbetween low degree edges,",
    "start": "2252890",
    "end": "2260840"
  },
  {
    "text": "and not so much here. But this is somewhat\na misnomer because",
    "start": "2260840",
    "end": "2266470"
  },
  {
    "text": "of the way the data comes out. We're not really\nbinning it properly. However, if we go and fit a\nperfect power law to this data,",
    "start": "2266470",
    "end": "2275080"
  },
  {
    "text": "and then pick a new\nset of bins based on those, so re-bin the\ndata, we can see here",
    "start": "2275080",
    "end": "2281300"
  },
  {
    "text": "that we get a much smoother\nuniform distribution. So while here we\nmay have thought",
    "start": "2281300",
    "end": "2286940"
  },
  {
    "text": "that this was an artificially\nlow dense-- not dense region,",
    "start": "2286940",
    "end": "2292460"
  },
  {
    "text": "this was artificially\nhigh-- what you see here is\nwhen you re-bin this that there's a very smooth\ndistribution from what",
    "start": "2292460",
    "end": "2300500"
  },
  {
    "text": "we expect for our\nperfect power law here. That this is a fairly\nuniform distribution with respect to that.",
    "start": "2300500",
    "end": "2305750"
  },
  {
    "text": "And so basically, it\nessentially puts more bins where we actually\nhave data as opposed",
    "start": "2305750",
    "end": "2311290"
  },
  {
    "text": "to wasting bins over here where\nwe don't really have any data. ",
    "start": "2311290",
    "end": "2319690"
  },
  {
    "text": "Using our perfect\npower law model, we can actually\ncompute analytically what this should be.",
    "start": "2319690",
    "end": "2324920"
  },
  {
    "text": "So here's an example of\nwhat that looks like. And again, very\nsimilar to what we see. And given the data, and\na model for the data,",
    "start": "2324920",
    "end": "2335160"
  },
  {
    "text": "we can then compute the ratio\nof the observed to the model",
    "start": "2335160",
    "end": "2340569"
  },
  {
    "text": "to get a sense of\nwhat data is unusual",
    "start": "2340570",
    "end": "2346400"
  },
  {
    "text": "versus what we expect from a\nperfect power-- or linear fit. And we see that\nvery clearly here.",
    "start": "2346400",
    "end": "2352539"
  },
  {
    "start": "2351000",
    "end": "2351000"
  },
  {
    "text": "So this is the data just\ndividing the data by the model here. And you see again,\nyou see all this data",
    "start": "2352540",
    "end": "2359960"
  },
  {
    "text": "appears like this is the\nratio, the log of the ratio. And so it's a-- zero means\nthat it's essentially",
    "start": "2359960",
    "end": "2366460"
  },
  {
    "text": "the ratio is 1, so all\nof this is expected. And then we see all\nthese fluctuations here. Things that are higher\nthan we expected",
    "start": "2366460",
    "end": "2373059"
  },
  {
    "text": "and things that are\nlower than we expected. And so this is the classic-- the\ntime where you see this most is",
    "start": "2373060",
    "end": "2382099"
  },
  {
    "text": "whenever they show you a map\nof the United States by county of some-- maybe like it's--\na classic is like a cancer",
    "start": "2382100",
    "end": "2391440"
  },
  {
    "text": "cluster, or heart\ndisease, or any phenomena. And what you see is that certain\ncounties in the western part of the United States\nare extremely healthy,",
    "start": "2391440",
    "end": "2398790"
  },
  {
    "text": "and certain counties\nare just deadly. And it's just a\nfact that they're very sparsely populated.",
    "start": "2398790",
    "end": "2404169"
  },
  {
    "text": "And so they are dealing with\nsmall numbers effect here. So basically, this is just\nshowing you oscillations",
    "start": "2404169",
    "end": "2409550"
  },
  {
    "text": "between 0 and 1 here. So what we call\nPoisson sampling.",
    "start": "2409550",
    "end": "2414730"
  },
  {
    "text": "And so it makes\nit very difficult to know what those are.",
    "start": "2414730",
    "end": "2420580"
  },
  {
    "text": "However, if we re-bin the data\nand then divide by the model, we see that the vast majority\nof our data, as expected,",
    "start": "2420580",
    "end": "2427960"
  },
  {
    "text": "is in this normal regime.",
    "start": "2427960",
    "end": "2434352"
  },
  {
    "text": "Another thing we\ncan actually do is we can look at like the\nmost unexpected data set. So we can look at the\nmost typical data set.",
    "start": "2434352",
    "end": "2441510"
  },
  {
    "text": "Oh, these got moved\nhere, didn't they. I don't know what's going\non with PowerPoint today. But this shows us the\nsurpluses, the deficits,",
    "start": "2441510",
    "end": "2449920"
  },
  {
    "text": "and the most typical. So here's like the most extreme\nbin, the most underrepresented",
    "start": "2449920",
    "end": "2458260"
  },
  {
    "text": "bin, and sort of the\nmost average bin. And these are the areas\nthat they correspond to in the real data set.",
    "start": "2458260",
    "end": "2464270"
  },
  {
    "text": "So you can use this\nto find extremes based on a statistical test.",
    "start": "2464270",
    "end": "2470440"
  },
  {
    "text": "And again, you see\nthat here again.",
    "start": "2470440",
    "end": "2475520"
  },
  {
    "text": "We have these\ndifferent-- that shows what the measured over\nexpected is versus measured.",
    "start": "2475520",
    "end": "2482730"
  },
  {
    "text": "And you can see, this\nis the original data set and this is the re-bin data set. And you see that the\nre-binning removes",
    "start": "2482730",
    "end": "2488720"
  },
  {
    "text": "a lot of these very\nsparse points over here and gives you very narrow\ndistribution around what you",
    "start": "2488720",
    "end": "2494099"
  },
  {
    "text": "expected. You can actually go and find\nselected edges if you want. So this just shows the\ndifferent types of edges.",
    "start": "2494100",
    "end": "2503210"
  },
  {
    "text": "The maximum. If you actually wanted to\ngo and look at those edges, these would be maximum,\nthese would be the minimum,",
    "start": "2503210",
    "end": "2509030"
  },
  {
    "text": "and these are the other types. So it's a useful thing. You can, again,\ngo, say all right, we found that if we have an\nartificially high correlation",
    "start": "2509030",
    "end": "2516730"
  },
  {
    "text": "between vertices with this\ndegree and this degree, we can then backtrack\nand find out",
    "start": "2516730",
    "end": "2522260"
  },
  {
    "text": "which specific vertices\nthere are, and see if that's anything that's interesting. ",
    "start": "2522260",
    "end": "2528720"
  },
  {
    "text": "We can also use this plot to\nlook at these questions of edge order.",
    "start": "2528720",
    "end": "2534570"
  },
  {
    "text": "And so, hopefully,\nthis will work today. So here's is a-- if I\nrandomly select vertices",
    "start": "2534570",
    "end": "2542890"
  },
  {
    "start": "2535000",
    "end": "2535000"
  },
  {
    "text": "and I compute their degree\nversus-- so basically, what we did before. We subsample and then compute\nover what is expected.",
    "start": "2542890",
    "end": "2551940"
  },
  {
    "text": "And we play this. And you can just see here we get\nthis sort of-- when we randomly",
    "start": "2551940",
    "end": "2557420"
  },
  {
    "text": "select the vertices,\nwe basically get kind of a\ntypical-- each sample",
    "start": "2557420",
    "end": "2564950"
  },
  {
    "text": "looks very much the same. Again, up there in\nthese high degrees, we have this Poisson\nsampling effect",
    "start": "2564950",
    "end": "2570610"
  },
  {
    "text": "where we have some--\nthis is we have no vertices, so we get a 0,\nwhich is lower than expected.",
    "start": "2570610",
    "end": "2577039"
  },
  {
    "text": "And if we have\nlike two vertices, we get higher than expected. And so again, we still\nhave that Poisson effect.",
    "start": "2577040",
    "end": "2583950"
  },
  {
    "text": "Interestingly, if we do\nlinear sampling, which we take whole rows\nat the time, we get a very different\ntype of phenomenon.",
    "start": "2583950",
    "end": "2592090"
  },
  {
    "text": "So you see you get\nthese-- whenever you do run into a high\ndegree row, by definition,",
    "start": "2592090",
    "end": "2599800"
  },
  {
    "text": "it is unusual. Which again, means you\nhave to be very careful. You're going to run into\nthis high degree row",
    "start": "2599800",
    "end": "2606430"
  },
  {
    "text": "eventually by sampling,\nbut you have to be careful. It's like, oh, my goodness. This is a very, very\nunusual type of thing.",
    "start": "2606430",
    "end": "2613480"
  },
  {
    "text": "So again, cautionary\ntale about sampling. All right.",
    "start": "2613480",
    "end": "2618610"
  },
  {
    "text": "So we've talked a lot\nabout the theory here. Let's get into some real data. So this is our\nReuter's data again.",
    "start": "2618610",
    "end": "2624680"
  },
  {
    "text": "I showed it to\nyou the other day. The various document\ndistributions we had. In this case, 800,000 documents,\n47,000 extracted entities,",
    "start": "2624680",
    "end": "2634790"
  },
  {
    "text": "for a total of 6,000,000,\nessentially, edges. So it's a bipartite graph\n[INAUDIBLE] between documents.",
    "start": "2634790",
    "end": "2640860"
  },
  {
    "text": "And four different types. And we can now look at\nthe different degree distributions of the different\nclasses and see what we have.",
    "start": "2640860",
    "end": "2647970"
  },
  {
    "text": "So the first one we want to\nlook at are the locations. And so we look at the\ndistribution of the documents",
    "start": "2647970",
    "end": "2654460"
  },
  {
    "text": "and the entities. So basically, imagine we took--\nso we're very clear here.",
    "start": "2654460",
    "end": "2660510"
  },
  {
    "text": "So what I'm doing is just\ntaking this part of the matrix, and the distribution of the\ndocuments is summing this way.",
    "start": "2660510",
    "end": "2668290"
  },
  {
    "text": "And the distribution locations\nis summing up and down along the columns. So for each one\nof these types, we",
    "start": "2668290",
    "end": "2673910"
  },
  {
    "text": "can do those different types. We have, essentially, two\ndifferent degree distributions. One associated with\nthe documents and one",
    "start": "2673910",
    "end": "2679540"
  },
  {
    "text": "associated with the entities. So this shows us our\ndocument distribution. So we have the measured data.",
    "start": "2679540",
    "end": "2686170"
  },
  {
    "text": "We have our fit. We have our model, and\nthen our re-binning. And you know, you could say that\nthis is approximately a power",
    "start": "2686170",
    "end": "2695110"
  },
  {
    "text": "law, and that when\nyou re-bin it, that this sort of\nS-shaped effect is still there, which probably\nmeans it's really there.",
    "start": "2695110",
    "end": "2701547"
  },
  {
    "text": "There's something going\non in the data that really is making this bowing effect. And so that's really there.",
    "start": "2701547",
    "end": "2707680"
  },
  {
    "text": "Likewise here, we\nhave our model. We have the measured data.",
    "start": "2707680",
    "end": "2712880"
  },
  {
    "text": "We have our model, alpha,\nwhich is the blue line. We have the model fit. And then our re-binning.",
    "start": "2712880",
    "end": "2718809"
  },
  {
    "text": "And again, you could\nsay the power law model's a pretty good\nfit, but again, we have something going on here.",
    "start": "2718810",
    "end": "2724160"
  },
  {
    "text": "Some kind of phenomenon\ngoing on there. And we can then do\nthis for each type. We can look at\nthe organizations.",
    "start": "2724160",
    "end": "2731160"
  },
  {
    "text": "And again, we don't have\nas many organizations. Again, similar types\nof phenomenon here. This is so sparse, it's\ndifficult to really say",
    "start": "2731160",
    "end": "2738510"
  },
  {
    "text": "what's going on here. Of course, we do people,\nwhich is, of course,",
    "start": "2738510",
    "end": "2744690"
  },
  {
    "text": "people always are\nthe first thing that you talk about when\nyou talk about power law distributions.",
    "start": "2744690",
    "end": "2749720"
  },
  {
    "text": "And again, very nicely, we have\nour measured data and our fit. And again, we see this sort\nof bent broom distribution",
    "start": "2749720",
    "end": "2757290"
  },
  {
    "text": "here, bending, and then with\nthis fan out effect here. But then when we model\nit and re-bin it,",
    "start": "2757290",
    "end": "2763380"
  },
  {
    "text": "we get something that looks\nmuch more like a true power law. And you can see that\nvery nicely here with the actual person data.",
    "start": "2763380",
    "end": "2770490"
  },
  {
    "text": "A very good power law. So this tells us that regardless\nof what this underlying data",
    "start": "2770490",
    "end": "2776370"
  },
  {
    "text": "looks like, this probably really\nis a power law distribution. And then we have the times.",
    "start": "2776370",
    "end": "2782029"
  },
  {
    "text": "And again, a similar\ntype of thing here. Different types of things.",
    "start": "2782030",
    "end": "2787480"
  },
  {
    "text": "And we actually have\na little spike here. The Reuter's data has\na certain collection",
    "start": "2787480",
    "end": "2793772"
  },
  {
    "text": "of times associated with\nthe actual filing of events. There's only 35 of them, so\nwe do get a little spike here,",
    "start": "2793772",
    "end": "2799570"
  },
  {
    "text": "which is actually\nwhat we expect. Although you wouldn't\nsee that really clearly in the true data, but\nwhen you re-bin it,",
    "start": "2799570",
    "end": "2805880"
  },
  {
    "text": "this bump comes\nout fairly clearly. So again, proper binning\nextremely important.",
    "start": "2805880",
    "end": "2811450"
  },
  {
    "text": "We can look at our\ncorrelations as well. So let's just look at the\nperson-person correlations. And again, what we saw\nhere is sort of-- we",
    "start": "2811450",
    "end": "2818880"
  },
  {
    "text": "see this is the raw data. So something that looks\nvery much like a power law. But when we go through\nour re-binning process,",
    "start": "2818880",
    "end": "2824500"
  },
  {
    "text": "we see kind of this witch's nose\neffect here really in the data. So this would tell you to\nfirst order it's a power law,",
    "start": "2824500",
    "end": "2832089"
  },
  {
    "text": "but you actually have this\ncorrelation taking place here, right here.",
    "start": "2832090",
    "end": "2837300"
  },
  {
    "text": "So that's something that really\nseems to be taking place.",
    "start": "2837300",
    "end": "2843260"
  },
  {
    "text": "You see the same\nthing when we do time. ",
    "start": "2843260",
    "end": "2849568"
  },
  {
    "text": "We can look at document. Let's now look at sampling. So again, this is the\nsame sampling that we did.",
    "start": "2849568",
    "end": "2854870"
  },
  {
    "start": "2850000",
    "end": "2850000"
  },
  {
    "text": "We're going to\nnow basically look at the document densification. So this is selecting whole rows.",
    "start": "2854870",
    "end": "2860200"
  },
  {
    "text": "We select a whole document,\nso we're getting a whole row. And this just shows you the\nfour different types here.",
    "start": "2860200",
    "end": "2866760"
  },
  {
    "text": "And you see that they\nbehave exactly as expected.",
    "start": "2866760",
    "end": "2872220"
  },
  {
    "text": "Each individual\nsample is reflective of the overall\ndensification, because you're taking whole rows.",
    "start": "2872220",
    "end": "2878570"
  },
  {
    "text": "OK? Now let's take entities. So now we're cutting\nacross these. And now you see\nsomething that looks",
    "start": "2878570",
    "end": "2884930"
  },
  {
    "start": "2882000",
    "end": "2882000"
  },
  {
    "text": "much more like random sampling. When you randomly\nselect an entity, that's sort of a random\nset of documents.",
    "start": "2884930",
    "end": "2891500"
  },
  {
    "text": "And again, the\nindividual samples, but when you start\nsumming them up, you see that they get denser\nand denser and denser.",
    "start": "2891500",
    "end": "2898900"
  },
  {
    "text": "So individual\ndocument has a sort of a good sample of the\noverall distribution. When you pick a person,\nas you take a higher",
    "start": "2898900",
    "end": "2907574"
  },
  {
    "text": "fraction of the\ndata, you're going to get more and more\nand more with that. So again, all consistent\nwith what we saw before.",
    "start": "2907574",
    "end": "2915350"
  },
  {
    "start": "2915000",
    "end": "2915000"
  },
  {
    "text": "A little noisier to\nsee here, but trust me, the power law exponent also\nbehaves exactly as we expected.",
    "start": "2915350",
    "end": "2923650"
  },
  {
    "text": "Likewise, this is essentially\na linear sampling, and here's the random\nsampling behaving exactly as we expected.",
    "start": "2923650",
    "end": "2931340"
  },
  {
    "text": "We can look at the\njoint distributions. So here's the actual-- this is\nthe location cross-correlation.",
    "start": "2931340",
    "end": "2938789"
  },
  {
    "start": "2932000",
    "end": "2932000"
  },
  {
    "text": "So they're showing you basically\nthe document versus entity degree distributions.",
    "start": "2938790",
    "end": "2944599"
  },
  {
    "text": "So this is the measured.  And it's been re-binned.",
    "start": "2944600",
    "end": "2950560"
  },
  {
    "text": "This is measured\ndivided by the expected, so the expected re-bins. This is measured\ndivided by the model.",
    "start": "2950560",
    "end": "2956579"
  },
  {
    "text": "And here's the model, and\nexpected divided by the model. And you can basically compare\nall these different types",
    "start": "2956580",
    "end": "2963440"
  },
  {
    "text": "to create different\nstatistical tests. And actually, we can find here\nthe measured re-binned divided",
    "start": "2963440",
    "end": "2971349"
  },
  {
    "text": "by the expected re-binned. We can get our surpluses\nand deficits and other types",
    "start": "2971350",
    "end": "2976819"
  },
  {
    "text": "of things in the actual data. And so here you\nsee something that maybe looks like an\nartificially high grouping here,",
    "start": "2976820",
    "end": "2982770"
  },
  {
    "text": "some artificially low,\nand some expected. And you can then\nuse these as ways to actually go and find\nanomalous documents.",
    "start": "2982770",
    "end": "2989127"
  },
  {
    "text": "Or documents are\nlike-- you say, look, this is the most\ntypical type of thing. I mean, people are like, well,\nwhy would you try and find",
    "start": "2989127",
    "end": "2994709"
  },
  {
    "text": "the most normal? Well, a lot of times,\nyou want to be able to, in terms of summarization,\nbe like here's a very representative\nset of documents.",
    "start": "2994709",
    "end": "3003484"
  },
  {
    "text": "They have the\nstatistical properties. This is very consistent\nwith everything else. Because people will [INAUDIBLE]\nlike what that mean to be that?",
    "start": "3003484",
    "end": "3009725"
  },
  {
    "text": "So again, a very useful\nway to look at the data. Do the same thing\nwith organization.",
    "start": "3009725",
    "end": "3015359"
  },
  {
    "text": "Again, basically get\nthe measured re-binned, the measured divided\nby the expected,",
    "start": "3015360",
    "end": "3021490"
  },
  {
    "text": "the expected re-binned,\nthe model, refit the model, and the various different\nratios of all of them, which",
    "start": "3021490",
    "end": "3028080"
  },
  {
    "text": "you can do to find\nvarious outliers and such. Again, a very useful. Interesting that it picked\nthe most representative one",
    "start": "3028080",
    "end": "3034840"
  },
  {
    "text": "way up here. So that's an interesting--\nso here's a very unusual representative sample. ",
    "start": "3034840",
    "end": "3044560"
  },
  {
    "text": "Persons, you can\ndo the same thing. And I guess one of the\nthings I'm also trying to do is that you see that these\nall don't look the same.",
    "start": "3044560",
    "end": "3051830"
  },
  {
    "text": "Right? Hopefully, from looking at\nthese, it's like this one, the location\ndistribution is clearly",
    "start": "3051830",
    "end": "3058030"
  },
  {
    "text": "a little similar to the\norganization distribution, but the person distribution\nlooks very different.",
    "start": "3058030",
    "end": "3063072"
  },
  {
    "text": "And the time distribution\nlooks very different. So you see that you have to be\ncareful about-- sometimes we'll",
    "start": "3063072",
    "end": "3069350"
  },
  {
    "start": "3064000",
    "end": "3064000"
  },
  {
    "text": "just take all these\ndifferent categories and lump them together\nin one big distribution. And here's a situation,\nlike these are really",
    "start": "3069350",
    "end": "3076310"
  },
  {
    "text": "pretty different things. And you really\nwant to treat them as four distinct classes\nof types of things.",
    "start": "3076310",
    "end": "3083290"
  },
  {
    "text": "So as an example\nof selected edges, this just shows\nthe most typical. This just shows the various\nentities that were selected,",
    "start": "3083290",
    "end": "3092030"
  },
  {
    "text": "and very representative\ndocument. And this is a very low\ndegree, various entities. So this might show\nyou entities-- here's",
    "start": "3092030",
    "end": "3099730"
  },
  {
    "text": "the kind of surplus example. And we could go in and\nactually finding those edges.",
    "start": "3099730",
    "end": "3104910"
  },
  {
    "text": "Same with the person. Very generic people,\nhigher degree.",
    "start": "3104910",
    "end": "3110880"
  },
  {
    "text": "Here's a very low. So this person, Jeremy Smith,\nis very unusual in terms of what they connected with.",
    "start": "3110880",
    "end": "3116520"
  },
  {
    "text": "Surplus ones here. Can't really read that\nover there, but just to give you examples of\nthings that you can actually",
    "start": "3116520",
    "end": "3122126"
  },
  {
    "text": "use this to go in and\nactually find things. All right. So that brings again\nto the lecture part.",
    "start": "3122126",
    "end": "3128210"
  },
  {
    "start": "3127000",
    "end": "3127000"
  },
  {
    "text": "So just, again, developing\nthis background model's very important for the graphs. Based on the perfect\npower law, gives us",
    "start": "3128210",
    "end": "3135015"
  },
  {
    "text": "a very simple heuristic for\ncreating a linear model. We can then really quantify\nthe effects of sampling,",
    "start": "3135015",
    "end": "3141550"
  },
  {
    "text": "which is very important. Again, traditional\nsampling approaches can easily create\nnonlinear phenomenon",
    "start": "3141550",
    "end": "3148820"
  },
  {
    "text": "that we have to be careful\nof and be aware of. It allows us to\ndevelop techniques for comparing real data\nwith power law fits",
    "start": "3148820",
    "end": "3156550"
  },
  {
    "text": "that we can then use\nas statistical tests for finding unusual\nbits of data. It's a very classic\ndetection theory here.",
    "start": "3156550",
    "end": "3165010"
  },
  {
    "text": "Come up with a model\nfor the background. Create a linear fit\nfor that background. Then use that model\nto then quantify",
    "start": "3165010",
    "end": "3171660"
  },
  {
    "text": "the data to see which\nthings are unusual. Again, just using\nvery classic detection",
    "start": "3171660",
    "end": "3177529"
  },
  {
    "text": "theory, the techniques. Again, having a\nbackground model being the linchpin of doing that.",
    "start": "3177530",
    "end": "3183400"
  },
  {
    "text": "And I'm not saying that this--\nthis is very recent work. This parallel model-- something\nwe did in the last year or so.",
    "start": "3183400",
    "end": "3191580"
  },
  {
    "text": "We just published\nit this summer. I can't guarantee that in\nthree or four years from now",
    "start": "3191580",
    "end": "3197480"
  },
  {
    "text": "that people will still\nbe using this model, because it is very new. But I think this\nis representative",
    "start": "3197480",
    "end": "3203670"
  },
  {
    "text": "of the kinds of things that\nwill be in three or four or five years, that\npeople-- it may not be this, but something like this\nto characterize our data.",
    "start": "3203670",
    "end": "3212040"
  },
  {
    "text": "And so I think it's\nvery useful there. All right. So with that, we will\ntake a short break and then we will\nshow the example code",
    "start": "3212040",
    "end": "3218460"
  },
  {
    "start": "3216000",
    "end": "3216000"
  },
  {
    "text": "and talk about the assignment. So very good. Thank you very much.",
    "start": "3218460",
    "end": "3224599"
  },
  {
    "start": "3224600",
    "end": "3229453"
  }
]
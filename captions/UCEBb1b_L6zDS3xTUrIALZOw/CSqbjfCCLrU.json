[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "60",
    "end": "6360"
  },
  {
    "text": "continue to offer high-quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6360",
    "end": "13330"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13330",
    "end": "17861"
  },
  {
    "text": "ERIK DEMAINE: Welcome to\nthe final week of 6.046. Are you excited? [CHEERING]",
    "start": "21690",
    "end": "27414"
  },
  {
    "text": "Yeah, today-- AUDIENCE: Oh. ERIK DEMAINE: Well,\nand sad, I know. It's tough. But we've got two more lectures.",
    "start": "27414",
    "end": "32630"
  },
  {
    "text": "They're on that one topic, which\nis cache oblivious algorithms. And this is a\nreally cool concept.",
    "start": "32630",
    "end": "39470"
  },
  {
    "text": "It was actually\noriginally developed in the context of 6.046, as\nsort of an interesting way",
    "start": "39470",
    "end": "45980"
  },
  {
    "text": "to teach cache-efficient\nalgorithms. But it turned into a\nwhole research program in the late '90s, and\nnow it's its own thing.",
    "start": "45980",
    "end": "55239"
  },
  {
    "text": "It's kind of funny to\nbring it back to 6.046. The whole idea is in all of\nthe algorithms we have seen,",
    "start": "55240",
    "end": "64670"
  },
  {
    "text": "except maybe\ndistributed algorithms, we've had this view that all\nof the data that we can access",
    "start": "64670",
    "end": "71288"
  },
  {
    "text": "is the same cost. If we have an array,\nlike a hash table, accessing anything in a hash\ntable is equally costly.",
    "start": "71289",
    "end": "79020"
  },
  {
    "text": "If we have a binary\nsearch tree, every node costs the same to access. But this is not real.",
    "start": "79020",
    "end": "86120"
  },
  {
    "text": "Let me give you\nsome idea of what a real computer looks like. You probably know this, but\nwe've not yet thought about it",
    "start": "86120",
    "end": "92880"
  },
  {
    "text": "in an algorithmic context.",
    "start": "92880",
    "end": "95443"
  },
  {
    "text": "These are caches, what are\ntypically called caches, in your computer.",
    "start": "102300",
    "end": "108539"
  },
  {
    "text": "Then you have what we've\nmostly been thinking about, which is main memory, your RAM.",
    "start": "108539",
    "end": "115409"
  },
  {
    "text": "And then there's\nprobably more stuff. These days you probably\nhave some big flash. If you have a\nfancier computer, you",
    "start": "120660",
    "end": "126970"
  },
  {
    "text": "have flash, which\nis maybe caching your disk, which is huge.",
    "start": "126970",
    "end": "133000"
  },
  {
    "text": "And then maybe there's\nthe internet at the end, if you like. So the point is all the data in\nthe world is not on your CPU.",
    "start": "133000",
    "end": "142370"
  },
  {
    "text": "And there's this big thing which\nis called the memory hierarchy, which dictates which\nthings are fast",
    "start": "142370",
    "end": "149409"
  },
  {
    "text": "and which things are\nslow, not exactly which data items; that's up to you.",
    "start": "149410",
    "end": "155530"
  },
  {
    "text": "But the idea is that\non board your CPU you have probably, these days,\nup to four levels of cache.",
    "start": "155530",
    "end": "163570"
  },
  {
    "text": "As I've tried to draw them,\nthey get increasingly big. Typical values--\na level one cache",
    "start": "163570",
    "end": "169440"
  },
  {
    "text": "is something on the order\nof 10, 32 K, whatever. Level four cache these\ndays, as introduced",
    "start": "169440",
    "end": "174840"
  },
  {
    "text": "by like Haswell Architectures,\nhas about 100 megabytes. Main memory you know; this is\nthe thing you usually think.",
    "start": "174840",
    "end": "181140"
  },
  {
    "text": "About. It's in the gigabytes. These days you can buy computers\nwith a terabyte of RAM. It's not crazy.",
    "start": "181140",
    "end": "186830"
  },
  {
    "text": "Flash gets bigger. Disk-- these days you can\nbuy 4-terabyte single disk,",
    "start": "186830",
    "end": "192317"
  },
  {
    "text": "but if you have a\nwhole RAID of disks, you can have petabytes\nof data on one computer. So things are getting bigger\nas we go farther to the right.",
    "start": "192317",
    "end": "200780"
  },
  {
    "text": "But they're also\ngetting slower. . And the point of cache\nefficient algorithms is to deal with the fact\nthat things get slow",
    "start": "200780",
    "end": "207709"
  },
  {
    "text": "when they get far away. And this makes sense from\na physics standpoint. If you think about\nhow much data can",
    "start": "207710",
    "end": "213860"
  },
  {
    "text": "you store in a cubic\ninch or something and how much could possibly be\nnear your CPU, at some point,",
    "start": "213860",
    "end": "221017"
  },
  {
    "text": "you're just going\nto run out of space, and you've got to\ngo farther away. And to go farther away is\ngoing to take more time.",
    "start": "221017",
    "end": "227183"
  },
  {
    "text": "So you can think of\nit-- I mean, there's the speed of light\nargument, that things that are farther\naway in your computer",
    "start": "227184",
    "end": "232525"
  },
  {
    "text": "are going to take longer. Typical computers\nare not anywhere near the speed of light, so there's\na more real issue, which",
    "start": "232525",
    "end": "239350"
  },
  {
    "text": "is how long are your traces. And then when you have physical\nmoving parts, like a disk,",
    "start": "239350",
    "end": "244640"
  },
  {
    "text": "I don't know if you know,\nbut disks actually spin, and there's a head, and\nit has to move around.",
    "start": "244640",
    "end": "249814"
  },
  {
    "text": "And that's called seek time. Moving a head around on\nthe disk is really slow, on the order of milliseconds.",
    "start": "249814",
    "end": "255360"
  },
  {
    "text": "Whereas reading\nfrom on-chip cache, that's on the order\nof nanoseconds, whatever your clock rate is, so\na few billion times a second.",
    "start": "255360",
    "end": "263180"
  },
  {
    "text": "So there's a big\nspread of like a factor of a million or 10 million from\nlevel one cache to disk speed.",
    "start": "263180",
    "end": "271930"
  },
  {
    "text": "That sucks. And so you might think,\nwell, if your data's big, you're just screwed. You've got to deal with\ndisk, and disk is slow.",
    "start": "271930",
    "end": "279909"
  },
  {
    "text": "But that's not true. Life is not so bad.",
    "start": "279909",
    "end": "284960"
  },
  {
    "text": "So, in general, there's\ntwo notions of speed,",
    "start": "284960",
    "end": "307720"
  },
  {
    "text": "and I've been kind\nof vague on them. One notion is latency,\nwhich is if right now I",
    "start": "307720",
    "end": "313300"
  },
  {
    "text": "have the idea that I really\nneed to fetch memory location 2 billion and 73, how long does\nit take for that data-- say,",
    "start": "313300",
    "end": "321100"
  },
  {
    "text": "one word of data-- to come back? That's latency. But there's another\nissue, which is bandwidth;",
    "start": "321100",
    "end": "328710"
  },
  {
    "text": "how fat are these pipes? What's my rate of information\nthat I could pump?",
    "start": "328710",
    "end": "335500"
  },
  {
    "text": "If I said, please give me\nall of main memory in order, how fast could it pump it back?",
    "start": "335500",
    "end": "340507"
  },
  {
    "text": "And that's actually really good.",
    "start": "340507",
    "end": "341840"
  },
  {
    "text": "So latency is like\nyour start up cost. When I ask for\nsomething, how long does it take for that\none thing to come? But then there's a data rate.",
    "start": "356370",
    "end": "364660"
  },
  {
    "text": "And bandwidth you can\ngenerally make really large. For example, in disk, bandwidth\nof a disk is pretty big.",
    "start": "364660",
    "end": "372110"
  },
  {
    "text": "But even if it weren't big, you\ncould just add 100 more disks. And then when you\nask for some data,",
    "start": "372110",
    "end": "378410"
  },
  {
    "text": "all 100 disks could give\nyou data at the same speed, and provided you don't\noverload your bus,",
    "start": "378410",
    "end": "384740"
  },
  {
    "text": "so you've got to also\nmake more buses and so on. You can actually really huge\namount of data per second,",
    "start": "384740",
    "end": "390567"
  },
  {
    "text": "but still the time to get there\nand the time for all the disks to seek their\nheads, that's slow. It doesn't add up, actually,\nbecause they're all",
    "start": "390567",
    "end": "396770"
  },
  {
    "text": "doing it in parallel. So you can't reduced latency,\nbut you can increase bandwidth.",
    "start": "396770",
    "end": "402620"
  },
  {
    "text": "And let's say-- it\ndoesn't match physics, but we can get pretty close\nto arbitrarily high bandwidth.",
    "start": "402620",
    "end": "408480"
  },
  {
    "text": "And so in a\nwell-designed computer, the fatnesses of\nthese pipes are going to increase, or could\nincrease, if you want.",
    "start": "408480",
    "end": "416520"
  },
  {
    "text": "So you can move\nlots of data around. But latency we can't get\nrid of, and this is annoying",
    "start": "416520",
    "end": "423840"
  },
  {
    "text": "because from an algorithmic\nstandpoint, when we ask for something,\nwe'd like it immediately. In a sequential logarithm,\nwe can't do anything",
    "start": "423840",
    "end": "429910"
  },
  {
    "text": "until that date arrives. So cache efficiency is going\nto fix this by blocking.",
    "start": "429910",
    "end": "436160"
  },
  {
    "text": "This is an old idea, since\ncaches were introduced.",
    "start": "441260",
    "end": "444750"
  },
  {
    "text": "There's the idea of blocking. So when you ask for a\nsingle word in main memory,",
    "start": "450692",
    "end": "456300"
  },
  {
    "text": "you don't get one word. You get maybe 32\nkilobytes of information,",
    "start": "456300",
    "end": "461960"
  },
  {
    "text": "not just 4 bytes or 8 bytes.",
    "start": "461960",
    "end": "465360"
  },
  {
    "text": "And we're kind of free to\nchoose these block sizes however we want, when we\ndesigned the system.",
    "start": "489620",
    "end": "495490"
  },
  {
    "text": "So we can set them, in a\ncertain sense, to hide latency.",
    "start": "495490",
    "end": "501940"
  },
  {
    "text": "So if you think of amortizing\nthe cost over the block,",
    "start": "501940",
    "end": "514799"
  },
  {
    "text": "then you have something like\namortized cost over block.",
    "start": "514799",
    "end": "521990"
  },
  {
    "text": "This is per word. Essentially, we divide the\nlatency by the block size.",
    "start": "521990",
    "end": "529449"
  },
  {
    "text": "And we have to pay\none over bandwidth. Bandwidth is how\nmany words a second",
    "start": "534380",
    "end": "539900"
  },
  {
    "text": "you can read, say,\nfrom your memory. So one over bandwidth is\ngoing to be your cost.",
    "start": "539900",
    "end": "546240"
  },
  {
    "text": "So this we can't change but. By adding enough disks\nor adding enough things at making these\npipes fat enough,",
    "start": "546240",
    "end": "552300"
  },
  {
    "text": "you can basically make this big. Latency is the thing\nwe can't control.",
    "start": "552300",
    "end": "558600"
  },
  {
    "text": "But if this block\nis sort of useful,",
    "start": "558600",
    "end": "564259"
  },
  {
    "text": "then we're paying the initial\nstart up time, say, hey, give me this block, and then\nwaiting for the response.",
    "start": "564260",
    "end": "569600"
  },
  {
    "text": "That latency we only pay\nonce for the entire block. So if there are block-size\nwords in that block, per item,",
    "start": "569600",
    "end": "578080"
  },
  {
    "text": "we're effectively dividing\nlatency by block size. This is kind of rough,\nbut this is the idea",
    "start": "578080",
    "end": "584110"
  },
  {
    "text": "of how to reduce latency. Now, for this actually work,\nwe need better algorithms.",
    "start": "584110",
    "end": "590214"
  },
  {
    "text": "Pretty much every algorithm you\nsee in the class so far works horribly in this model. So that's the point of today\nand next class is to fix that.",
    "start": "600230",
    "end": "609230"
  },
  {
    "text": "For this kind of\namortization to work,",
    "start": "613410",
    "end": "620069"
  },
  {
    "text": "I'm using \"use\" in a\nvague sense so far. We'll make it\nformal in a moment. When I fetch an entire\nblock, all of the elements",
    "start": "620070",
    "end": "628500"
  },
  {
    "text": "in that block should be useful. We should be able to\ncompute something on them that we needed to compute.",
    "start": "628500",
    "end": "633509"
  },
  {
    "text": "Otherwise, if I if I only needed\nthe one item that I read out of the block, that's not\ngoing to help me so much.",
    "start": "633510",
    "end": "641250"
  },
  {
    "text": "So I really want to structure\nmy data in such a way that when I access\none element, I'm",
    "start": "641250",
    "end": "646840"
  },
  {
    "text": "also going to access\nthe elements nearby it. Then this blocking will\nactually be useful.",
    "start": "646840",
    "end": "651980"
  },
  {
    "text": "This is a property normally\ncalled spatial locality.",
    "start": "651980",
    "end": "654949"
  },
  {
    "text": "And the other thing\nwe'd like-- these caches have some size, so I can store\nmore than just one block.",
    "start": "664190",
    "end": "671360"
  },
  {
    "text": "It's not like I read\none block, and I just finish processing it, and then\nI read the next block and go on.",
    "start": "671360",
    "end": "676630"
  },
  {
    "text": "Some of these caches\nare actually pretty big. If you think of main memory\nas a cache to your disk, that can be really big.",
    "start": "676630",
    "end": "682740"
  },
  {
    "text": "So ideally, the blocks\nthat I'm using here relate to each\nother in some way,",
    "start": "682740",
    "end": "688730"
  },
  {
    "text": "or when I access\nthe block, I'm going to access it for awhile,\nalong with other blocks.",
    "start": "688730",
    "end": "694029"
  },
  {
    "text": "So the way this\nis usually said is that we'd like to reuse the\nexisting blocks in the cache",
    "start": "694030",
    "end": "701902"
  },
  {
    "text": "as much as possible. And this you can think\nof as temporal locality.",
    "start": "701902",
    "end": "707259"
  },
  {
    "text": "When I access a\nparticular block, I'm going to access\nit again fairly soon. That way it's actually useful\nto bring it into my cache,",
    "start": "711000",
    "end": "717690"
  },
  {
    "text": "and then I use it many times. That would be even better. I don't have to\nhave both of these, and exactly to\nwhat extent I have",
    "start": "717690",
    "end": "723500"
  },
  {
    "text": "them is going to dictate\nwhat the overall time it's going to take\nto run my algorithm. But these are so\nthe ideal properties",
    "start": "723500",
    "end": "729280"
  },
  {
    "text": "you want in a very\ninformal sense. Now, in the rest today, we're\ngoing to make this formal,",
    "start": "729280",
    "end": "736000"
  },
  {
    "text": "and then we're going to develop\nsome algorithms for this model. But this is the motivation. In reality, we're free to\nchoose block size in the system.",
    "start": "736000",
    "end": "744584"
  },
  {
    "text": "Though, in a moment,\nI'm going to assume that it's given to us. You'd normally\nset the block size so that these two terms\ncome out roughly equal.",
    "start": "744585",
    "end": "752570"
  },
  {
    "text": "Because if you're spending\nthe latency time to go and get something, you might as well\nget a whole chunk of something,",
    "start": "752570",
    "end": "761530"
  },
  {
    "text": "according to whatever\nyour bandwidth is. If it only cost\nyou, say, twice as much to fetch an entire\nblock than to fetch one word,",
    "start": "761530",
    "end": "768350"
  },
  {
    "text": "that seems like a\npretty good block size. So for something like\ndisk, that block size",
    "start": "768350",
    "end": "774160"
  },
  {
    "text": "is on the order of\nmegabytes, maybe even bigger-- hundreds of megabytes. So think of the block\nsizes as really big.",
    "start": "774160",
    "end": "781170"
  },
  {
    "text": "We really want all that data\nto be useful in some way. Now it's really hard\nto think about a memory",
    "start": "781170",
    "end": "788980"
  },
  {
    "text": "hierarchy with so many levels. So we're going to focus\non two levels at a time--",
    "start": "788980",
    "end": "794810"
  },
  {
    "text": "the sort of the\ncheap and small cache versus the huge thing,\nwhich I'll call disk,",
    "start": "794810",
    "end": "801010"
  },
  {
    "text": "just for emphasis.",
    "start": "801010",
    "end": "801800"
  },
  {
    "text": "So I'm going to call\nthis two-level model the external memory model. It was originally\nintroduced as a model",
    "start": "806420",
    "end": "813920"
  },
  {
    "text": "for main memory versus disk. But you could apply it\nto any pair of levels. In general, you have\nyour problem size N,",
    "start": "813920",
    "end": "820720"
  },
  {
    "text": "choose the smallest level\nthat fits N. Typically that's main memory. Maybe it's disk.",
    "start": "820720",
    "end": "826899"
  },
  {
    "text": "And just think of the level\nbetween that and the previous,",
    "start": "826900",
    "end": "832160"
  },
  {
    "text": "so the last level and\nthe next to last level. Often that's what matters.",
    "start": "832160",
    "end": "838567"
  },
  {
    "text": "Like if you run a program,\nand you run out of RAM, and you start swapping the\ndisks, that's when everything just slows to a crawl.",
    "start": "838567",
    "end": "845079"
  },
  {
    "text": "You can see that difference\nat each of these levels, but it's probably\nmost dramatic at disk just because it's so slow-- a\nmillion times slower than RAM,",
    "start": "845080",
    "end": "853910"
  },
  {
    "text": "or at least 1,000 times\nslower than RAM, I should say. Anyway, so we have\njust two levels.",
    "start": "853910",
    "end": "860830"
  },
  {
    "text": "So let me draw a\nmore precise picture. We have the CPU. This is where all\nof our operations",
    "start": "863730",
    "end": "869160"
  },
  {
    "text": "are doing this, where we\nadd numbers and so on. We'll think of it as having a\nconstant number of registers. Each register is one word.",
    "start": "869160",
    "end": "876660"
  },
  {
    "text": "And then we have a really\nfat pipe, low latency pipe,",
    "start": "876660",
    "end": "882440"
  },
  {
    "text": "to the cache.",
    "start": "882440",
    "end": "884580"
  },
  {
    "text": "Cache is going to be\ndivided into blocks.",
    "start": "888490",
    "end": "893810"
  },
  {
    "text": "So let's say there's\nB words per blocks. Instead of writing\nblock size, I'll",
    "start": "893810",
    "end": "900930"
  },
  {
    "text": "just write capital B.\nAnd the number of blocks. I'm going to call M over B. So\nthe total size of your cache",
    "start": "900930",
    "end": "916300"
  },
  {
    "text": "is capital M. And then there\nis a relatively thin and slow",
    "start": "916300",
    "end": "922649"
  },
  {
    "text": "connection-- this one's fast.",
    "start": "922650",
    "end": "928060"
  },
  {
    "text": "This one's slow-- to your disk.",
    "start": "928060",
    "end": "931855"
  },
  {
    "text": "Disk we'll think of as huge,\nessentially infinite size. It's also divided into blocks\nof size B, so same block size.",
    "start": "935460",
    "end": "945290"
  },
  {
    "text": "So this is the picture. And so, initially,\nall of the input",
    "start": "951110",
    "end": "956190"
  },
  {
    "text": "is over here, all of your\nend data items, whatever. So you want to sort those items. And in order to\naccess those items,",
    "start": "956190",
    "end": "964130"
  },
  {
    "text": "you first have to\nbring them into cache. That's going to be slow, but\nit's done in a blocked manner.",
    "start": "964130",
    "end": "972260"
  },
  {
    "text": "So when I can't access\nan individual item here, I have to request\nthe entire block.",
    "start": "972260",
    "end": "979190"
  },
  {
    "text": "When I request that block,\nit gets sent over here. It takes a while. And then I get to choose\nwhere to store it.",
    "start": "979190",
    "end": "984200"
  },
  {
    "text": "Maybe I'll put it here. And then maybe I'll\ngrab this block and then store it\nhere and so on.",
    "start": "984200",
    "end": "992100"
  },
  {
    "text": "Each of those is a block read,\nso these are new instructions the CPU can do. And eventually, this\ncache will get full.",
    "start": "992100",
    "end": "999680"
  },
  {
    "text": "And then before I\nbring in a new block, I have to kick out an old lock. Meaning I need to\ntake one these blocks",
    "start": "999680",
    "end": "1004910"
  },
  {
    "text": "and write it to some position,\nmaybe to the same place. I think, in fact, we\nwill always assume",
    "start": "1004910",
    "end": "1010800"
  },
  {
    "text": "that you write to the\nsame place, overwrite what was on the disk. You made some changes\nhere, send it back.",
    "start": "1010800",
    "end": "1016656"
  },
  {
    "text": "And, in general, what\nwe're going to do is count how many times\nwe read and write blocks. Question?",
    "start": "1016656",
    "end": "1022474"
  },
  {
    "text": "AUDIENCE: When you talked about\nhow fast the connection is, you're just talking\nabout latency, right? ERIK DEMAINE: Yes,\nsorry, this is latency.",
    "start": "1022474",
    "end": "1028858"
  },
  {
    "text": "AUDIENCE: Yeah, so like\nthe [INAUDIBLE] connections [? just don't have ?]\n[INAUDIBLE]? ERIK DEMAINE: Right, this\ncould have huge bandwidth.",
    "start": "1028858",
    "end": "1036020"
  },
  {
    "text": "So in this model, we're assuming\nthe block size is fixed, and then the latency\nversus bandwidth",
    "start": "1036020",
    "end": "1041250"
  },
  {
    "text": "is not-- we're not going\nto think about bandwidth. We'll assume the\nblock size has been chosen in some reasonable way.",
    "start": "1041250",
    "end": "1047036"
  },
  {
    "text": "And then all we need to do is\ncount the number of blocks. But underneath, yeah, you\nhave some kind of bandwidth.",
    "start": "1047036",
    "end": "1053640"
  },
  {
    "text": "Presumably you\nset the block size to make these two\nthings roughly equal, and so then latency\nand bandwidth",
    "start": "1053640",
    "end": "1059216"
  },
  {
    "text": "are kind of the same thing. That's the idea. But really, we're just going to\nthink about counting latency,",
    "start": "1059216",
    "end": "1064480"
  },
  {
    "text": "which is how many\ntimes do I have to request to block and\nwait for it to come over, and how much does it\ncost to write a block?",
    "start": "1064480",
    "end": "1071010"
  },
  {
    "text": "How many times do\nI write a block? I'm not going to worry about\nhow much physical time it takes me to do either\nof those things;",
    "start": "1071010",
    "end": "1076940"
  },
  {
    "text": "I'm just going to count\nthem and assume that that is what I need to minimize.",
    "start": "1076940",
    "end": "1082410"
  },
  {
    "text": "So I'm going to count-- we\ncall these memory transfers--",
    "start": "1082410",
    "end": "1089750"
  },
  {
    "text": "transfers of blocks\nbetween levels, between these two levels.",
    "start": "1089750",
    "end": "1094375"
  },
  {
    "text": "This is the number of blocks\nread from or written to disk.",
    "start": "1097150",
    "end": "1106120"
  },
  {
    "text": "We're going to view accesses\nto the cache as free.",
    "start": "1112380",
    "end": "1120110"
  },
  {
    "text": "I'm not going to count those.",
    "start": "1120110",
    "end": "1121460"
  },
  {
    "text": "You don't need to\nworry about that so much because we can still\ncount the number of operations",
    "start": "1125284",
    "end": "1132549"
  },
  {
    "text": "that we do on the\ncomputer, on the CPU.",
    "start": "1132550",
    "end": "1134460"
  },
  {
    "text": "We still can think\nabout how much time, regular time, it takes\nto do the computation--",
    "start": "1139520",
    "end": "1144730"
  },
  {
    "text": "how many comparisons, how many\nadditions, things like that. And that would include things\nlike reading and writing",
    "start": "1144730",
    "end": "1150029"
  },
  {
    "text": "elements from cache--\nindividual things. But we're going to view\nthis connection-- let's say,",
    "start": "1150030",
    "end": "1155360"
  },
  {
    "text": "these are on the same ship. So reading cache is just as\nfast as reading from registers. So we're not going to\nworry about that time.",
    "start": "1155360",
    "end": "1161730"
  },
  {
    "text": "What we're focusing on, for\nthe purpose of this model, is between these two levels. So these are essentially\none level combined.",
    "start": "1161730",
    "end": "1170355"
  },
  {
    "text": "I'll change that\nin a little bit. But for now, just think\nabout the two levels. And we're counting how\nmany memory transfers",
    "start": "1170355",
    "end": "1176210"
  },
  {
    "text": "do we have between these\ntwo levels, cache and disk.",
    "start": "1176210",
    "end": "1181659"
  },
  {
    "text": "So we want to minimize that. Now, just like before,\nwe want to minimize the running time in the\nusual traditional measure.",
    "start": "1181660",
    "end": "1189090"
  },
  {
    "text": "And we want to minimize space\nand all the usual things we minimize. But now we have a\nnew measure, which is number of memory transfers,\nand we want our algorithm",
    "start": "1189090",
    "end": "1196073"
  },
  {
    "text": "to minimize that too,\nfor a given block size and for a given cache size.",
    "start": "1196073",
    "end": "1200940"
  },
  {
    "text": "And at this point-- I'm going\nto change this in a moment-- the algorithm that we would\nwrite in this external memory",
    "start": "1205930",
    "end": "1215480"
  },
  {
    "text": "model explicitly\nmanages the blocks. It has to explicitly\nread and write blocks.",
    "start": "1215480",
    "end": "1223585"
  },
  {
    "text": "And there's a\nsoftware system that implements this model,\nparticularly for disk, and lets you do this in\na nice controlled way,",
    "start": "1231444",
    "end": "1237510"
  },
  {
    "text": "maintain your memory, maintain\nreading and writing disk. The operating system\ntries to do this, but it usually does a really\nbad job with swapping.",
    "start": "1237510",
    "end": "1245070"
  },
  {
    "text": "But there are\nsoftware systems that let you take control\nand do much better.",
    "start": "1245070",
    "end": "1250070"
  },
  {
    "text": "So that's a good model. External memory model is\nespecially good for disk.",
    "start": "1253900",
    "end": "1257063"
  },
  {
    "text": "It's not going to capture\nthe finesse of all these other levels, and\nit's a little bit annoying",
    "start": "1262280",
    "end": "1267900"
  },
  {
    "text": "to write algorithms in\nthis way-- explicitly reading and writing blocks. Today I will not write\nany such algorithms.",
    "start": "1267900",
    "end": "1274230"
  },
  {
    "text": "Although, you could\nthink about them. I personally love\nthis other model,",
    "start": "1274230",
    "end": "1280765"
  },
  {
    "text": "which is cache obviousness.",
    "start": "1280765",
    "end": "1281890"
  },
  {
    "text": "It's going to lead to, in\nsome sense, cleaner algorithm. Although, it's more of a magic\ntrick to get them to work.",
    "start": "1289920",
    "end": "1296380"
  },
  {
    "text": "But writing the\nalgorithms is very simple. Analyzing them is more work. And it will capture, in some\nsense, all of these levels.",
    "start": "1296380",
    "end": "1304740"
  },
  {
    "text": "But, in fact, it is basically\nexactly this model, almost the same. We're going to change\none thing, which is",
    "start": "1304740",
    "end": "1312270"
  },
  {
    "text": "where the oblivious comes from. We're going to say that\nthe algorithm doesn't",
    "start": "1312270",
    "end": "1319200"
  },
  {
    "text": "know the cache parameters. It doesn't know B or M.\nSo this is a little weird.",
    "start": "1319200",
    "end": "1328215"
  },
  {
    "text": "We're going to have to make some\nother changes to make it work.",
    "start": "1328215",
    "end": "1330840"
  },
  {
    "text": "From an analysis perspective, I\nwant to count memory transfers and analyze my algorithm\nwith respect to this memory",
    "start": "1333490",
    "end": "1339350"
  },
  {
    "text": "hierarchy. But the algorithm\nitself isn't allowed to know what that member\nhierarchy looks like.",
    "start": "1339350",
    "end": "1345190"
  },
  {
    "text": "Another way to say this\nis that the algorithm has to work simultaneously\nfor all values of B and all values of M.\nAs you might imagine,",
    "start": "1345190",
    "end": "1354167"
  },
  {
    "text": "this is not so easy. But there are some simple\nthings where this is easy, and more complicated things\nwhere this is possible.",
    "start": "1354167",
    "end": "1360150"
  },
  {
    "text": "And it gives you all\nsorts of cool things. Let me first formalize\nthe model a little bit.",
    "start": "1360150",
    "end": "1366290"
  },
  {
    "text": "The other nice thing about\ncache oblivious algorithms is it corresponds\nmuch more closely",
    "start": "1366290",
    "end": "1372620"
  },
  {
    "text": "to how these caches work. When you write code\non your CPU, you may have noticed\nyou don't usually",
    "start": "1372620",
    "end": "1378560"
  },
  {
    "text": "do block reads and block\nwrites, unless you're dealing with flash or disk. All of this is\ntaking care for you.",
    "start": "1378560",
    "end": "1384590"
  },
  {
    "text": "It's all done internal\nto the processor. When you access a word,\nbehind the scenes, magically, the\nsystem, the computer,",
    "start": "1384590",
    "end": "1393260"
  },
  {
    "text": "finds which word to read\nor which block to read. It moves the entire block\ninto a higher level cache,",
    "start": "1393260",
    "end": "1399200"
  },
  {
    "text": "and then it's just serving\nyou words out of that block. And you don't have\nexplicit control over that.",
    "start": "1399200",
    "end": "1405200"
  },
  {
    "text": "So the way that works is when\nyou access a word in memory--",
    "start": "1405200",
    "end": "1412929"
  },
  {
    "text": "and I'm going to think\nof memory as everything; this is what's stored\nin the disk, say.",
    "start": "1412930",
    "end": "1418680"
  },
  {
    "text": "This is the entire memory\nsystem, the entire memory hierarchy. And, as usual in\nthis class, we're going to think of\nthe entire memory",
    "start": "1422246",
    "end": "1428360"
  },
  {
    "text": "as a giant array of words.",
    "start": "1428360",
    "end": "1436940"
  },
  {
    "text": "Each of these\nsquares is one word. But then also, the memory\nis now divided into blocks.",
    "start": "1436940",
    "end": "1446040"
  },
  {
    "text": "So let's say every four. Let's say B equals 4. Every four words is\na block boundary,",
    "start": "1446040",
    "end": "1453820"
  },
  {
    "text": "just for the sake\nof drawing a figure. So this is B equals 4.",
    "start": "1453820",
    "end": "1460450"
  },
  {
    "text": "When you access a single\nword, like this one, you get the entire block\ncontaining the word.",
    "start": "1460450",
    "end": "1466830"
  },
  {
    "text": "Let's say, to emphasize,\nit's not you personally; the system somehow fetches the\nblock containing that word.",
    "start": "1470100",
    "end": "1478940"
  },
  {
    "text": "It has to do this automatically. We can't explicitly read and\nwrite blocks in this model because we don't know\nhow big the blocks are.",
    "start": "1487307",
    "end": "1493050"
  },
  {
    "text": "So it couldn't even name them. But internally, on the real\nsystem and in your analysis,",
    "start": "1493050",
    "end": "1499510"
  },
  {
    "text": "you're going to think of\nwhenever you touch something, you actually get all\nthis into the cache. So you hope that you will use\nthings nearby because you've",
    "start": "1499510",
    "end": "1506100"
  },
  {
    "text": "already read them in. Ideally, they're useful. But you don't know how\nmany you've read in. You've read in B, and\nyou don't what B is.",
    "start": "1506100",
    "end": "1513456"
  },
  {
    "text": "The algorithm doesn't now. One more detail--\nthe cache is going",
    "start": "1513457",
    "end": "1519669"
  },
  {
    "text": "to get full pretty quickly. And so then, whenever\nyou read something, you have to kick something out. In steady state,\ncache might as well",
    "start": "1519670",
    "end": "1526690"
  },
  {
    "text": "always stay full-- no reason\nto leave anything empty. So which block do you kick out?",
    "start": "1526690",
    "end": "1531910"
  },
  {
    "text": "Any suggestions? Which block should I kick out? If I've been reading\nand writing some blocks,",
    "start": "1534884",
    "end": "1540710"
  },
  {
    "text": "reading and writing to\nwords within these blocks.",
    "start": "1540710",
    "end": "1543529"
  },
  {
    "text": "Yeah? AUDIENCE: [INAUDIBLE]. ERIK DEMAINE: The block that was\nfetched farthest in the past? Yeah that is usually\ncalled First In, First Out.",
    "start": "1546228",
    "end": "1553480"
  },
  {
    "text": "That's FIFO. And that is a good strategy. Any other suggestions?",
    "start": "1553480",
    "end": "1559352"
  },
  {
    "text": "Yeah. AUDIENCE: [INAUDIBLE]. ERIK DEMAINE: The block has\nbeen least recently used.",
    "start": "1559352",
    "end": "1564900"
  },
  {
    "text": "So maybe you fetched\nit a long time ago, but you use it\nevery clock cycle.",
    "start": "1564900",
    "end": "1570999"
  },
  {
    "text": "That one you should\nprobably not throw away because you use it a lot. That's called LRU, and that\nis also a good strategy.",
    "start": "1570999",
    "end": "1578730"
  },
  {
    "text": "Other suggestions? Those are two good ones. If you go beyond that,\nI'm worried I won't know. But there are some\nbad strategies.",
    "start": "1578730",
    "end": "1584596"
  },
  {
    "text": "Yeah? AUDIENCE: Just random. ERIK DEMAINE: Random-- yeah,\nrandom is probably pretty good.",
    "start": "1584596",
    "end": "1592435"
  },
  {
    "text": "I don't know offhand. There are some\nrandomized strategies that beat both of those. But from this perspective,\nboth are good.",
    "start": "1592435",
    "end": "1598250"
  },
  {
    "text": "We've got lots of Frisbees\nto go through, so. That's a good answer.",
    "start": "1598250",
    "end": "1603690"
  },
  {
    "text": "Random is definitely\na good idea. I know there's a randomized\nstrategy called [? bit, ?] that in certain senses\nis a little bit better.",
    "start": "1603690",
    "end": "1608760"
  },
  {
    "text": "But from my perspective, I\nthink all of those are good. Random, I have to double check\nwhether you lose a log factor. And expectation should be fine.",
    "start": "1608760",
    "end": "1614891"
  },
  {
    "text": "So all of those\nstrategies will work. You could define this\nmodel with any of them.",
    "start": "1617520",
    "end": "1622945"
  },
  {
    "text": "I think it would work\nfine, except randomize, you'd get an expectation bound.",
    "start": "1622945",
    "end": "1626111"
  },
  {
    "text": "So the system evicts, let's say,\nthe least recently used page.",
    "start": "1628640",
    "end": "1635210"
  },
  {
    "text": "The least recently loaded\npage would also work fine. That's FIFO. Sorry I'm switching to page, but\nI've been calling them blocks.",
    "start": "1644480",
    "end": "1651740"
  },
  {
    "text": "Blocks and pages are the\nsame thing for this lecture. And either at the end of this\nlecture or beginning of next,",
    "start": "1651740",
    "end": "1660690"
  },
  {
    "text": "I'll tell you why\nthat's an OK thing. But let's not worry\nabout it at this point.",
    "start": "1660690",
    "end": "1665100"
  },
  {
    "text": "So now we have a model--\ncache flow oblivious. We have two models, actually.",
    "start": "1671440",
    "end": "1678186"
  },
  {
    "text": "But I think now that\nthe cache flow oblivious model is complete,\nwe're going to analyze. Again, we're still counting\nthe number of memory transfers",
    "start": "1678186",
    "end": "1686460"
  },
  {
    "text": "in this thing. The algorithm's just not\nallowed know B and M, and so we had to\nchange the model to make the reading\nand writing of blocks",
    "start": "1686460",
    "end": "1693890"
  },
  {
    "text": "automatic because\nthe algorithm's not allowed to do it. So someone's got to.",
    "start": "1693890",
    "end": "1698950"
  },
  {
    "text": "The cool thing about\ncache oblivious model is every algorithm\nyou see in this class, or most of the algorithms\nyou see in this class,",
    "start": "1698950",
    "end": "1706260"
  },
  {
    "text": "are in a certain sense\ncache oblivious algorithms. They weren't aware of B\nand M before, still not.",
    "start": "1706260",
    "end": "1712390"
  },
  {
    "text": "What changes is now you can\nanalyze them in this new way, in this new model. Now, as I said, all the\nalgorithms we've seen",
    "start": "1712390",
    "end": "1719815"
  },
  {
    "text": "are not going to perform well\nin this model-- almost all. But that makes\nthings interesting,",
    "start": "1719815",
    "end": "1725725"
  },
  {
    "text": "and that's why we\nhave some work to do.",
    "start": "1725725",
    "end": "1728270"
  },
  {
    "text": "I have some reasons why\ncache obliviousness-- why would you tie your\nhands behind your back and not know B or M?",
    "start": "1730870",
    "end": "1737059"
  },
  {
    "text": "Reason one, it's cool. I think it's pretty amazing\nyou can actually do this.",
    "start": "1737060",
    "end": "1742390"
  },
  {
    "text": "I guess that's reason\ntwo is you can actually do it for a lot of\nproblems we care about. Cache oblivious algorithms\nexist that are just as good.",
    "start": "1742390",
    "end": "1748900"
  },
  {
    "text": "So, I mean, of\ncourse they exist. But there are ones\nthat are optimal. They're within a constant\nfactor of the best algorithm",
    "start": "1748900",
    "end": "1755230"
  },
  {
    "text": "when you know B or M.\nSo that's surprising. That's the cool part.",
    "start": "1755230",
    "end": "1759540"
  },
  {
    "text": "In general, the\nalgorithms are easier to write down because we can use\npseudo code just like before.",
    "start": "1762019",
    "end": "1767540"
  },
  {
    "text": "We don't need to worry about\nblocking in the algorithm. The analysis is going to be\nharder, but that's unavoidable.",
    "start": "1767540",
    "end": "1774530"
  },
  {
    "text": "In some sense, it makes\nit easier to write code. And it's also a little easier\nto distribute your code",
    "start": "1774530",
    "end": "1780820"
  },
  {
    "text": "because every computer\nhas different block sizes that matter. Also, as you change\nyour value of N,",
    "start": "1780820",
    "end": "1786500"
  },
  {
    "text": "a different level in the memory\nhierarchy's going to matter. And so it's annoying-- each of\nthese levels, I didn't mention,",
    "start": "1786500",
    "end": "1792520"
  },
  {
    "text": "has a different block\nsize and, of course, has a different cache size. So tuning your code every\ntime to a different B or M",
    "start": "1792520",
    "end": "1799840"
  },
  {
    "text": "is annoying. The big gain here,\nthough, I think, is that you capture the\nentire hierarchy, in a sense.",
    "start": "1799840",
    "end": "1808030"
  },
  {
    "text": "So in the real world,\neach of these pipes has its own latency. And let's just\nthink about latency.",
    "start": "1808030",
    "end": "1815110"
  },
  {
    "text": "And you'd like to minimize\nthe number of block transfers between here and here. You'd like to minimize the\nnumber block answers here here.",
    "start": "1815110",
    "end": "1820810"
  },
  {
    "text": "Well, OK, I can't\nminimize all of them. That's a\nmulti-dimensional problem. What I'd like to minimize\nis some weighted average",
    "start": "1820810",
    "end": "1827190"
  },
  {
    "text": "of those things-- latency\ntimes number of blocks here, plus the latency times\nthe number of blocks",
    "start": "1827190",
    "end": "1832380"
  },
  {
    "text": "here, plus latency times\nthe number of blocks here, and so on. If you can find an optimal cache\noblivious algorithm and analyze",
    "start": "1832380",
    "end": "1841410"
  },
  {
    "text": "it just with respect\nto two levels, because the algorithm's not\nallowed to know B and M,",
    "start": "1841410",
    "end": "1847455"
  },
  {
    "text": "it has to work for all levels. It has to minimize the number\nof block transfers between all",
    "start": "1847455",
    "end": "1854140"
  },
  {
    "text": "these levels, and\nso, in particular, will minimize the\nweighted sum of them.",
    "start": "1854140",
    "end": "1859175"
  },
  {
    "text": "It's a bit hand wavy. You have to prove\nsomething there. But you can prove it.",
    "start": "1859175",
    "end": "1862450"
  },
  {
    "text": "So there's a paper\nabout this from 1999 by Frigo, Leiserson,\nProkop, and Ramachandran.",
    "start": "1866680",
    "end": "1875390"
  },
  {
    "text": "It's old enough that I\nremember all the names. After about 2001, when\nI became a professor, I can't remember anything.",
    "start": "1875390",
    "end": "1881470"
  },
  {
    "text": "But before that, I can\nremember everything. So Frigo, we've talked about\nhim in the context of FFTW.",
    "start": "1881470",
    "end": "1888450"
  },
  {
    "text": "That was the fastest Fourier\nTransform in the West. So he was a student here. And FFTW uses a cache oblivious\nFast Fourier Transform",
    "start": "1888450",
    "end": "1895809"
  },
  {
    "text": "algorithm. Leiserson, you've probably seen\non the cover of your textbook or walking around Stata.",
    "start": "1895810",
    "end": "1902340"
  },
  {
    "text": "Professor Leiserson here at MIT. And Prokop, this is actually\nhis [? M Enge ?] thesis.",
    "start": "1902340",
    "end": "1908270"
  },
  {
    "text": "So pretty awesome\n[? M Enge ?] thesis. All right, so cool, I\nthink I said all the things",
    "start": "1908270",
    "end": "1916179"
  },
  {
    "text": "I wanted to say. So if you want to see\nthe proof that you can solve the entire\nmemory hierarchy,",
    "start": "1916180",
    "end": "1922139"
  },
  {
    "text": "you can read their paper. You have to make a\ncouple of assumptions, but it's intuitive.",
    "start": "1922140",
    "end": "1927200"
  },
  {
    "text": "Cache oblivious has to\nwork for all B and M, so it's going to optimize all\nthe levels simultaneously.",
    "start": "1927200",
    "end": "1932220"
  },
  {
    "text": "Doing that explicitly, with all\nthe different B's and M's, that would be really messy\ncode, probably also slower.",
    "start": "1932220",
    "end": "1939157"
  },
  {
    "text": "Cache oblivious is\njust going to do it for free with the same code. All right, let's\ndo some algorithms.",
    "start": "1939157",
    "end": "1944545"
  },
  {
    "text": "There's one easy\nalgorithm which works great from a cache oblivious\nperspective, which is scanning.",
    "start": "1949480",
    "end": "1957770"
  },
  {
    "text": "Let we give you\nsome Python code.",
    "start": "1957770",
    "end": "1959650"
  },
  {
    "text": "For historical\nreasons, in this field, N is written with\na capital letter. Don't ask, or don't\nworry about it.",
    "start": "1968540",
    "end": "1975707"
  },
  {
    "text": "So here's some very simple code. Suppose you want to\naccumulate an array. You want to add up all\nof the items in the array",
    "start": "1975707",
    "end": "1981700"
  },
  {
    "text": "or multiply them or take\nthem in or whatever. This is a typical kind of thing.",
    "start": "1981700",
    "end": "1986900"
  },
  {
    "text": "Again, an array, we're\ngoing to think of-- so here was my memory.",
    "start": "1986900",
    "end": "1992894"
  },
  {
    "text": "We're going to\nthink of the array as being stored\nas some contiguous",
    "start": "1992895",
    "end": "1999040"
  },
  {
    "text": "segment of that array,\nlet's say, this segment. So this is important.",
    "start": "1999040",
    "end": "2005092"
  },
  {
    "text": "Assume array is stored\ncontiguously, no holes,",
    "start": "2005092",
    "end": "2017090"
  },
  {
    "text": "relative to how it's\nmapped on to memory. And this is a\nrealistic assumption.",
    "start": "2017090",
    "end": "2023350"
  },
  {
    "text": "When you allocate\na block of memory, the promise by the system\nis that it's essentially a contiguous chunk of\nmemory or disk, or whatever.",
    "start": "2023350",
    "end": "2030750"
  },
  {
    "text": "And when Python makes\nan array, it does this. It guarantees that these things\nwill be stored contiguously.",
    "start": "2033390",
    "end": "2041160"
  },
  {
    "text": "If you use a dictionary,\nthis would not be true. But for regular [? array's ?]\nlist, this is true. So I'm accessing the items\nin the array in order,",
    "start": "2041160",
    "end": "2050530"
  },
  {
    "text": "and so I start\nhere at item zero. I end up with item N minus 1.",
    "start": "2050530",
    "end": "2055780"
  },
  {
    "text": "That seems good because\nI read this one. I get the whole block. Then I read this one. I already had that block.",
    "start": "2055780",
    "end": "2061031"
  },
  {
    "text": "It's free. This one's free. This one's free. Here I have to read a new block. But then this one's free.",
    "start": "2061031",
    "end": "2066649"
  },
  {
    "text": "So the first item I\naccess in each block costs one, but as long as my\ncache store's at least one",
    "start": "2066650",
    "end": "2073609"
  },
  {
    "text": "block, that's enough. And let's say the\nsum is a register; that's enough to\nremember that block so",
    "start": "2073610",
    "end": "2079684"
  },
  {
    "text": "that the next operation\nI do will be free. So the cost is going\nto be-- actually,",
    "start": "2079684",
    "end": "2092840"
  },
  {
    "text": "be a little more precise--\nceiling of N over B almost.",
    "start": "2092840",
    "end": "2099495"
  },
  {
    "text": "Without the big O here, this\nis right in the external memory",
    "start": "2102800",
    "end": "2109170"
  },
  {
    "text": "model, but not quite right\nin the cache oblivious model.",
    "start": "2109170",
    "end": "2116329"
  },
  {
    "text": "Can someone tell me why? Yeah? AUDIENCE: If N is\ntwo, you could have it",
    "start": "2116330",
    "end": "2121388"
  },
  {
    "text": "beyond a border [INAUDIBLE]. ERIK DEMAINE: Good,\nN could be two. But it could span\na block boundary.",
    "start": "2121388",
    "end": "2126970"
  },
  {
    "text": "Remember, the\nalgorithm has no idea where the block boundaries are. And again, in reality,\nthere are block boundaries",
    "start": "2126970",
    "end": "2132750"
  },
  {
    "text": "all over the place, and\nthere's no way to know. You can't request that\nwhen you allocate an array",
    "start": "2132750",
    "end": "2138400"
  },
  {
    "text": "it always begins in\na block boundary. So great, you can span block\nboundaries in-- oh, way off.",
    "start": "2138400",
    "end": "2148066"
  },
  {
    "text": "I just spanned a\nblock boundary, sorry. So it's going to be,\nat most, ceiling over N",
    "start": "2148066",
    "end": "2156290"
  },
  {
    "text": "over B plus 1 cache obviously. So it's just going\nto hurt you by one.",
    "start": "2156290",
    "end": "2162060"
  },
  {
    "text": "But I want to point out,\nthere's a slight difference between the two models,\neven with this very simple algorithm.",
    "start": "2162060",
    "end": "2168560"
  },
  {
    "text": "In general, I'm just\ngoing to think of this as big O N over B plus 1.",
    "start": "2168560",
    "end": "2175680"
  },
  {
    "text": "There's some additive constant. I guess you could even say\nit's N over B plus big O 1, but we won't worry about\nconstant factors today.",
    "start": "2175680",
    "end": "2183960"
  },
  {
    "text": "So that's scanning, cache\noblivious external memory, both great. Slightly more interesting--",
    "start": "2183960",
    "end": "2189710"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]? ERIK DEMAINE: Yeah, in the\nexternal memory algorithm,",
    "start": "2207762",
    "end": "2215949"
  },
  {
    "text": "because you're explicitly\ncontrolling the blocks, you're explicitly\nreading and writing them. And you know where the\nblock boundaries are.",
    "start": "2215949",
    "end": "2221920"
  },
  {
    "text": "You could, if you wanted\nto, you don't have to, but you could choose\nthe array to be aligned,",
    "start": "2221920",
    "end": "2227069"
  },
  {
    "text": "to be starting at\na block boundary. So that's the distinction. In the cache oblivious,\nyou can't control that,",
    "start": "2227070",
    "end": "2232570"
  },
  {
    "text": "so you have to worry\nabout the worst case. External memory you\ncould control it, and you could do better,\nand maybe you'd want to.",
    "start": "2232570",
    "end": "2239240"
  },
  {
    "text": "It will hurt you buy\na constant factor. And in disks, for\nexample, you want",
    "start": "2239240",
    "end": "2245130"
  },
  {
    "text": "things to be track\naligned because if you have to go to an adjacent track,\nit's a lot more expensive.",
    "start": "2245130",
    "end": "2250640"
  },
  {
    "text": "You've got to move the head. Track is a circle, what\nyou can read without moving the head, so great.",
    "start": "2250640",
    "end": "2262170"
  },
  {
    "text": "So slightly more\ninteresting is you can do a constant number\nof parallel scans.",
    "start": "2262170",
    "end": "2267360"
  },
  {
    "text": "So that was one scan. Here's an example of two scans.",
    "start": "2267360",
    "end": "2273265"
  },
  {
    "text": "Again, we have one array\nof size N. Python notation,",
    "start": "2282810",
    "end": "2290360"
  },
  {
    "text": "that would be the whole thing. And what I want to do is swap\nAi with-- this is not Python,",
    "start": "2290360",
    "end": "2301170"
  },
  {
    "text": "but it's, I think,\ntextbook notation. But you know what swap means.",
    "start": "2301170",
    "end": "2308840"
  },
  {
    "text": "What does this do, assuming\nI got my minus ones right?",
    "start": "2308840",
    "end": "2315980"
  },
  {
    "text": "Yeah? AUDIENCE: It reverses the array. ERIK DEMAINE: It\nreverses the array, good. We'll just run through\nthese Frisbees.",
    "start": "2315980",
    "end": "2322424"
  },
  {
    "text": "So this is a very\nsimple algorithm for reversing the array. It was originally\nby John Bentley, who was Charles\nLeiserson's adviser-- PhD",
    "start": "2322424",
    "end": "2328120"
  },
  {
    "text": "adviser-- back in the day. So very simple, but\nwhat's cool about it, if you think about the array\nand the order in which you're",
    "start": "2328120",
    "end": "2336630"
  },
  {
    "text": "accessing things, it's\nlike I have two fingers--",
    "start": "2336630",
    "end": "2343210"
  },
  {
    "text": "and I should have\nmade this smaller. So here, we'll go down here.",
    "start": "2343210",
    "end": "2348339"
  },
  {
    "text": "I start at the very\nbeginning of the array and the very end of the array. Then I go to the second\nelement, next to last element,",
    "start": "2348340",
    "end": "2354829"
  },
  {
    "text": "and I advance like this. So as long as your cache M, the\nnumber of blocks in the cache",
    "start": "2354830",
    "end": "2362256"
  },
  {
    "text": "is at least two, which\nis totally reasonable. You can assume this is\nat least 100, typically.",
    "start": "2362256",
    "end": "2367930"
  },
  {
    "text": "You've got at least\n100 blocks, say. So for any fixed constant,\nwe're going to assume N over B is bigger than a constant.",
    "start": "2367930",
    "end": "2373920"
  },
  {
    "text": "We'll only need like\ntwo or three or four for the algorithms we cover. Then great, when I\naccess this item,",
    "start": "2373920",
    "end": "2380660"
  },
  {
    "text": "I will load in the\nblock that contains it. I don't know how it's aligned,\nbut don't care so much.",
    "start": "2380660",
    "end": "2387640"
  },
  {
    "text": "And then I load in the block\nthat contains this item. And then the next\naccesses are free until I advance to the next block.",
    "start": "2387640",
    "end": "2393470"
  },
  {
    "text": "But once I advance to the next\nblock on the left or the right, I'll never have to\naccess the old ones. And so again, the\ncost here is just",
    "start": "2393470",
    "end": "2401020"
  },
  {
    "text": "going to be equal to the\nnumber of blocks, which is big O of N over B plus 1.",
    "start": "2401020",
    "end": "2407540"
  },
  {
    "text": "So a constant number\nof parallel scans is going to be basically the\nnumber of blocks in the array.",
    "start": "2407540",
    "end": "2414690"
  },
  {
    "text": "So N is smaller than B, this\nis a bad idea or not so hot. But when N is\nbigger than B, this",
    "start": "2414690",
    "end": "2419760"
  },
  {
    "text": "is just N over B.\nThat's how much it takes to read in the data-- big deal.",
    "start": "2419760",
    "end": "2426670"
  },
  {
    "text": "So these are boring cache\noblivious algorithms. Let's do interesting ones.",
    "start": "2426670",
    "end": "2431829"
  },
  {
    "text": "And I would say the\ncentral idea in cache oblivious algorithms is\nto use divide-and-conquer.",
    "start": "2431830",
    "end": "2438360"
  },
  {
    "text": "This goes back to the first\nfew lectures in this class. And so we will go back\nto examples from there.",
    "start": "2438360",
    "end": "2446390"
  },
  {
    "text": "Today we're going to\ndo the median finding, in particular, which\nwe did in lecture two,",
    "start": "2446390",
    "end": "2452789"
  },
  {
    "text": "so really a blast from the past. But it's good review because\nthe final covers everything, so you've got to remember that.",
    "start": "2452790",
    "end": "2459570"
  },
  {
    "text": "Matrix multiplication,\nwe've talked about, but not usually-- well, I guess we did\nactually use divide-and-conquer",
    "start": "2459570",
    "end": "2466920"
  },
  {
    "text": "for Strassen's algorithm. We're going to use -and-conquer\neven for the boring algorithm today.",
    "start": "2466920",
    "end": "2472139"
  },
  {
    "text": "And then next class, we're going\nto go back to van Emde Boas, but in a completely\ndifferent way. So if you don't\nlike van Emde Boas,",
    "start": "2472139",
    "end": "2478279"
  },
  {
    "text": "don't worry; it's much simpler. So let's do median finding.",
    "start": "2478280",
    "end": "2484930"
  },
  {
    "text": "Or actually, sorry, let me first\ntalk about divide-and-conquer",
    "start": "2484930",
    "end": "2490900"
  },
  {
    "text": "in general. You know what\ndivide-and-conquer is. You take your problem.",
    "start": "2490900",
    "end": "2496600"
  },
  {
    "text": "You split it into\nnon-overlapping subproblems, recursively solve\nthem, combine them.",
    "start": "2496600",
    "end": "2502664"
  },
  {
    "text": "But what I want\nto stress here is what it's going to look like\nin a cache oblivious context. So the algorithm\nis going to look",
    "start": "2502665",
    "end": "2509230"
  },
  {
    "text": "like a regular\ndivide-and-conquer algorithm. So, in particular, the algorithm\nwill recurse all the way to,",
    "start": "2509230",
    "end": "2521799"
  },
  {
    "text": "let's say, constant\nsize problems, whatever the base case is.",
    "start": "2521800",
    "end": "2526345"
  },
  {
    "text": "So same as usual, but what's\ndifferent is the analysis.",
    "start": "2531900",
    "end": "2535845"
  },
  {
    "text": "When we analyze a cache\noblivious algorithm,",
    "start": "2538410",
    "end": "2543609"
  },
  {
    "text": "then we get to know\nwhat B and M are. In some sense, we're\nanalyzing for all B an M. But let's suppose B\nand M is given to us,",
    "start": "2543610",
    "end": "2549359"
  },
  {
    "text": "then will tell you how many\nmemory transfers you need. This kind of bound,\nyou need to know what B is to know what the\nvalue of this bound is.",
    "start": "2549360",
    "end": "2557109"
  },
  {
    "text": "But you learn it as a\nfunction of B and, in general, a function of B\nand M, and that's the best you could hope for as\na complete characterization.",
    "start": "2557110",
    "end": "2566390"
  },
  {
    "text": "So in the analysis, let's\njust look at one value of B and one value of M. So\nanalysis knows B and M,",
    "start": "2566390",
    "end": "2577540"
  },
  {
    "text": "and it's going to look at,\nlet's say, the recursive level,",
    "start": "2577540",
    "end": "2591620"
  },
  {
    "text": "where one of two things happens. Either the problem size\nfits in order one blocks.",
    "start": "2591620",
    "end": "2608660"
  },
  {
    "text": "So meaning it's order B size. That's an interesting level.",
    "start": "2608660",
    "end": "2614690"
  },
  {
    "text": "Another interesting level,\nthe more obvious one probably, is that it fits in cache.",
    "start": "2614690",
    "end": "2624045"
  },
  {
    "text": "So that means that the size is\nless than or equal to capital M. Everything here is\ncounted in terms of words.",
    "start": "2624045",
    "end": "2632869"
  },
  {
    "text": "This is the more obvious one. For a lot of problems, the\ncache size isn't so relevant. What really matters\nis the block size.",
    "start": "2632870",
    "end": "2638830"
  },
  {
    "text": "For example, scanning, you're\nonly looking through the data once. So it doesn't matter\nhow big your cache is, as long as it's not super tiny.",
    "start": "2638830",
    "end": "2645970"
  },
  {
    "text": "As long as it has\na few blocks, then it's just a function of\nB and N, no M involved.",
    "start": "2645970",
    "end": "2653359"
  },
  {
    "text": "So for that kind of\nproblem this would be more useful-- constant\nnumber of blocks.",
    "start": "2653360",
    "end": "2659800"
  },
  {
    "text": "Because I think of the\ncache M as being larger than any constant times B,\nthis is strictly smaller,",
    "start": "2659800",
    "end": "2667140"
  },
  {
    "text": "or this is smaller or equal\nto problem fitting in cache. So when M is\nrelevant, we'll look",
    "start": "2667140",
    "end": "2672780"
  },
  {
    "text": "at this level and maybe\nthe adjacent levels in the recursion. So the algorithm doesn't know\nwhat B and M are, so it's",
    "start": "2672780",
    "end": "2680150"
  },
  {
    "text": "got to recurse all\nthe way down-- turtles all the way down. But the analysis,\nbecause we're only",
    "start": "2680150",
    "end": "2685890"
  },
  {
    "text": "thinking about one\nvalue B and M at a time, we can afford to just\nconsider that one level, and that will be like\nthe critical place",
    "start": "2685890",
    "end": "2691496"
  },
  {
    "text": "where all the cost is. Because once things fit in cache\nand you've loaded things in, the cost will be zero.",
    "start": "2691496",
    "end": "2696569"
  },
  {
    "text": "So below that, the base\ncase is kind of trivial. So basically what\nthis is going to do is make our base cases larger.",
    "start": "2696570",
    "end": "2702410"
  },
  {
    "text": "Instead of our base\ncase being constant, it's going to be order B or M.",
    "start": "2702410",
    "end": "2711650"
  },
  {
    "text": "What don't I need?",
    "start": "2711650",
    "end": "2712400"
  },
  {
    "text": "So now let's going\nto median finding.",
    "start": "2721839",
    "end": "2723380"
  },
  {
    "text": "Median finding, you're\ngiven an unsorted array. You want to find the median.",
    "start": "2745420",
    "end": "2750560"
  },
  {
    "text": "And in lecture two,\nwe had a linear time worst case algorithm for this.",
    "start": "2750560",
    "end": "2757670"
  },
  {
    "text": "And so my goal today is to\nmake it this running time. This is what you\nmight call linear time in the cache oblivious model\nbecause that's how long it",
    "start": "2760900",
    "end": "2768359"
  },
  {
    "text": "takes just to read the data. It turns out basically\nthe same algorithm works.",
    "start": "2768360",
    "end": "2775680"
  },
  {
    "text": "First, you've got to\nremember the algorithm. So let me write it down quickly. This is the sort of\nfive by in N array.",
    "start": "2775680",
    "end": "2785250"
  },
  {
    "text": "So think of the array as\nbeing partitioned into, I'll call them, five columns.",
    "start": "2785250",
    "end": "2791045"
  },
  {
    "text": "So this picture of five dots\nby N over 5 dots-- this is",
    "start": "2795540",
    "end": "2802990"
  },
  {
    "text": "dot, dot, dot. So this is five. Now, we didn't\ntalk about it then,",
    "start": "2802990",
    "end": "2808025"
  },
  {
    "text": "and there's a few different\nways you could actually implement it, but let's say\nthese-- the actual array is one-dimensional.",
    "start": "2808025",
    "end": "2813810"
  },
  {
    "text": "Let's say these are\nthe first five items. These are the next five items. So, in other words, this matrix\nis stored column-by-column.",
    "start": "2813810",
    "end": "2821610"
  },
  {
    "text": "This is just a conceptual view. So we can define it either\nway, however we want. So I'm going to\nview it that way.",
    "start": "2821610",
    "end": "2828069"
  },
  {
    "text": "And then what the rest of the\nalgorithm did was for sort each column, it's\nonly five items,",
    "start": "2828070",
    "end": "2836150"
  },
  {
    "text": "so you can sort it in\nconstant time, each one. But, in particular,\nwhat we care about is the median of\nthose five items.",
    "start": "2836150",
    "end": "2844010"
  },
  {
    "text": "Then we recursively found\nthe median of the medians.",
    "start": "2844010",
    "end": "2848805"
  },
  {
    "text": "This is the step we're going\nto have to change a little bit.",
    "start": "2852370",
    "end": "2854870"
  },
  {
    "text": "Then we-- leave a\nlittle bit of space.",
    "start": "2861150",
    "end": "2866349"
  },
  {
    "text": "Then we partition\nthe array by x.",
    "start": "2866350",
    "end": "2872580"
  },
  {
    "text": "Meaning we split the\narray into items less than or equal to x and\nthings greater than x.",
    "start": "2872580",
    "end": "2877810"
  },
  {
    "text": "We probably assumed there was\nonly one value equal to x, but it doesn't matter. And finally, we recurse on\none of those two halves.",
    "start": "2880350",
    "end": "2889063"
  },
  {
    "text": "So this is a pretty crazy\ndivide-and-conquer algorithm, one of the more\nsophisticated ones. You don't need to know\nall the details here,",
    "start": "2893760",
    "end": "2899700"
  },
  {
    "text": "just that it worked and\nit ran in linear time. What's crazy about it is\nthere are two recursive calls.",
    "start": "2899700",
    "end": "2906030"
  },
  {
    "text": "Usually, like in\nmerge sort, where you do two recursive calls\nand spend linear time to do the stuff,\nlike this partition,",
    "start": "2906030",
    "end": "2912300"
  },
  {
    "text": "you get n log n time,\nlike merge sort. Here, because this\narray is a lot smaller,",
    "start": "2912300",
    "end": "2917570"
  },
  {
    "text": "this is a size N over 5. And this one was\nreasonably small; it was like [? M of ?] 7/10\nN. Because 7/10 plus 1/5",
    "start": "2917570",
    "end": "2928800"
  },
  {
    "text": "is strictly less than\n1, this ends up being linear time instead of n log n.",
    "start": "2928800",
    "end": "2934480"
  },
  {
    "text": "That's just review. Now, what I'd like to do is\nthe same thing, same analysis,",
    "start": "2934480",
    "end": "2945270"
  },
  {
    "text": "or same algorithm, but\nnow I want to analyze it in this two-level model.",
    "start": "2945270",
    "end": "2950410"
  },
  {
    "text": "So actually, I will\nerase this board.",
    "start": "2950410",
    "end": "2955780"
  },
  {
    "text": "So now my array has been\npartitioned into blocks",
    "start": "2968740",
    "end": "2973820"
  },
  {
    "text": "of size B, like this picture. In fact, it's quite similar. Here, we're partitioning\nthings into blocks,",
    "start": "2973820",
    "end": "2979730"
  },
  {
    "text": "but they're size five. That's different. Now someone has partitioned my\narray into blocks of size B.",
    "start": "2979730",
    "end": "2984990"
  },
  {
    "text": "I need to count how\nmany things I access. Well, let's just look\nline-by-line at this code and see what we do.",
    "start": "2984990",
    "end": "2990530"
  },
  {
    "text": "Step one, we do\nabsolutely nothing. This is a conceptual\npicture, so zero cost, great.",
    "start": "2990530",
    "end": "2996440"
  },
  {
    "text": "Step one is zero,\nmy favorite answer. Step two, we sort each column.",
    "start": "2996440",
    "end": "3003630"
  },
  {
    "text": "How long does this take? What am I doing?",
    "start": "3003630",
    "end": "3005296"
  },
  {
    "text": "It's right above me.",
    "start": "3012230",
    "end": "3013280"
  },
  {
    "text": "AUDIENCE: N over B. ERIK DEMAINE: N over B\nbecause this is a scan. It's a little bit\nweird of a scan.",
    "start": "3017420",
    "end": "3022440"
  },
  {
    "text": "We look at five\nitems, and then we look at the next five items,\nand then the next five items.",
    "start": "3022440",
    "end": "3028370"
  },
  {
    "text": "But it's basically a scan. You could think of it as almost\nfive parallel scans, I suppose, or you could just\nbreak into the case",
    "start": "3028370",
    "end": "3034100"
  },
  {
    "text": "where maybe if B\nis a constant, then it doesn't matter what you do. But if B bigger than a constant,\nthen reading five items,",
    "start": "3034100",
    "end": "3042681"
  },
  {
    "text": "those are all probably\ngoing to be in one block, except the ones that straddle\nthe block boundaries. So in all cases,\nfor step two-- maybe",
    "start": "3042681",
    "end": "3051086"
  },
  {
    "text": "I should rewrite\nstep one-- zero cost. Step two, is order N over\nB plus 1, to be careful.",
    "start": "3051086",
    "end": "3061240"
  },
  {
    "text": "That's a scan. Actually, it's\ntwo parallel scans because we have to write\nout these medians somewhere,",
    "start": "3061240",
    "end": "3069490"
  },
  {
    "text": "so we'll have to. Step three is recursively\nfind the medians. Now, before, we had in\nT of N is T of N over 5",
    "start": "3069490",
    "end": "3082140"
  },
  {
    "text": "plus T of 7/10 N plus linear.",
    "start": "3082140",
    "end": "3087210"
  },
  {
    "text": "In this new world-- this\nis regular running time. In this new world,\nI'm going to use",
    "start": "3090110",
    "end": "3095460"
  },
  {
    "text": "a different notation for\nthe recurrence, MT of N for memory transfers.",
    "start": "3095460",
    "end": "3100630"
  },
  {
    "text": "This is a good\nold-fashioned time, and this is our new\nmodern notion of time-- how many block transfers do I\nneed to do for problem size N.",
    "start": "3100630",
    "end": "3107760"
  },
  {
    "text": "So this is a recursion, and\nshould be MT of N over 5.",
    "start": "3107760",
    "end": "3114020"
  },
  {
    "text": "But, and this is\nimportant, for this",
    "start": "3114020",
    "end": "3120500"
  },
  {
    "text": "to be a same problem\nof the same type, I need to know that the\narray that recursing on",
    "start": "3120500",
    "end": "3125750"
  },
  {
    "text": "is stored contiguously. Before, I didn't\nneed to do that.",
    "start": "3125750",
    "end": "3130799"
  },
  {
    "text": "I could say, well, let's put\nthe medians in the middle. So now every fifth item in\nthis array is my new subarray.",
    "start": "3130800",
    "end": "3138341"
  },
  {
    "text": "And so I could recursively\ncall this thing and say, OK, here's my\narray, but really only think about every fifth item.",
    "start": "3138341",
    "end": "3143829"
  },
  {
    "text": "That's like a\nstride in the array. And then the next\nrecursive level, oh, only worry about every 25th item.",
    "start": "3143830",
    "end": "3148950"
  },
  {
    "text": "And every 5-cubed item, I'm\ngoing to stop computing, and so on. And that would be fine\nfor regular running time.",
    "start": "3148950",
    "end": "3157360"
  },
  {
    "text": "But when I get my stride\ngets bigger and bigger, at some point,\nevery item is going to be in a different block. That's bad.",
    "start": "3157360",
    "end": "3163130"
  },
  {
    "text": "I don't want to do that. So when I find these\nmedians, or when I recurse,",
    "start": "3163130",
    "end": "3168270"
  },
  {
    "text": "I need that the medians\nthat I'm recursing on are stored in a\ncontiguous array. Now, this is easy to do. But we didn't have to do before.",
    "start": "3168270",
    "end": "3173900"
  },
  {
    "text": "That's the key difference. Make sure they are\nstored contiguously.",
    "start": "3173900",
    "end": "3182675"
  },
  {
    "text": "I can do that because when I\nsort each column in one scan, I can have a second scan\nwhich is the output, which",
    "start": "3187060",
    "end": "3194250"
  },
  {
    "text": "is the array of medians. So as I'm scanning\nthrough the input, I'm going to output the median.",
    "start": "3194250",
    "end": "3199290"
  },
  {
    "text": "It's going to be 1/5 the size. Then I've got all the\nmedians nicely stored in a contiguous array.",
    "start": "3199290",
    "end": "3205070"
  },
  {
    "text": "So with order-one\nparallel scans, same time here, this is actually\na legitimate recursive call.",
    "start": "3205070",
    "end": "3211270"
  },
  {
    "text": "Then we partition. Partition, again, is a bunch of\nparallel scans, I think, three.",
    "start": "3213810",
    "end": "3222920"
  },
  {
    "text": "You've got one\nreading scan, which is you're reading\nthrough the array, and you've got to writing scans. You're writing out the elements\nless than or equal to x,",
    "start": "3222920",
    "end": "3229420"
  },
  {
    "text": "and you're writing out the\nelements greater than x. But again, all of\nthose are scans. You're always writing\nthe next element right",
    "start": "3229420",
    "end": "3235120"
  },
  {
    "text": "after the previous one. So if you already have\nthat block in memory and if you assume that the\nnumber of blocks in cache",
    "start": "3235120",
    "end": "3241750"
  },
  {
    "text": "is at least three, then\nthree parallel scans is fine.",
    "start": "3241750",
    "end": "3246910"
  },
  {
    "text": "It's different from the\nCLRS partition algorithm. That one was fancy\nto be in place. We're not trying to be\nin place or fancy at all.",
    "start": "3246910",
    "end": "3253720"
  },
  {
    "text": "Let's just do it with\na bunch of scans. So now we have two arrays--\nthe element less than x, the elements greater than x.",
    "start": "3253720",
    "end": "3259690"
  },
  {
    "text": "Then we recurse on one of\nthem, and those elements are consecutive\nalready, so good. This is a regular\nrecursive call.",
    "start": "3259690",
    "end": "3266630"
  },
  {
    "text": "Again, we're\nmaintaining the variant that the array is\nstored contiguously.",
    "start": "3266630",
    "end": "3272350"
  },
  {
    "text": "And by the old analysis, that\narray is sized at most 7/10 N.",
    "start": "3272350",
    "end": "3277430"
  },
  {
    "text": "So I get a new recurrence,\nwhich is MT of N is MT of N over 5 plus MT-- this\nanalysis feels very \"empty--\"",
    "start": "3277430",
    "end": "3291090"
  },
  {
    "text": "plus N over B-- sorry, bad\njoke-- N over B plus 1.",
    "start": "3291090",
    "end": "3297150"
  },
  {
    "text": "So basically the same\nrecurrence, but now N over B plus 1 for what\nwe're doing here.",
    "start": "3297150",
    "end": "3303955"
  },
  {
    "text": "But I had to change\nthe algorithm a little bit for this\nrecurrence to be correct, for it to correctly reflect\nthe number of memory transfers.",
    "start": "3303955",
    "end": "3310430"
  },
  {
    "text": "Now all we need to do\nis solve the recurrence. And actually, in some\nsense, more importantly,",
    "start": "3310430",
    "end": "3318099"
  },
  {
    "text": "we need to figure out\nwhat the base case is. Because we could say, all right,\nhere's the usual base case.",
    "start": "3318100",
    "end": "3325630"
  },
  {
    "text": "If I have a\nconstant-sized problem, well, that's going\nto be constant. This is our base case for every\nrecurrence we've ever done.",
    "start": "3325630",
    "end": "3332260"
  },
  {
    "text": "And that's enough usually. It's going to give us a\nreally bad answer here. So let's go off to the side\nhere and solve that recurrence.",
    "start": "3332260",
    "end": "3342815"
  },
  {
    "text": "So if that's my base case,\nwell, in particular-- so this is some recursion tree.",
    "start": "3361060",
    "end": "3366700"
  },
  {
    "text": "It's very uneven, so it's\nkind of annoying to draw. But what I know\nwith this base case,",
    "start": "3366700",
    "end": "3373500"
  },
  {
    "text": "this overall MT event is\ngoing to at least the number of leaves in the recursion tree.",
    "start": "3373500",
    "end": "3379880"
  },
  {
    "text": "So let's say MT\nof N is at least L of N, number of leaves\nin the recursion.",
    "start": "3379880",
    "end": "3389300"
  },
  {
    "text": "So this is really if\nI run the algorithm, how many base cases of\nconstant size do I get?",
    "start": "3389300",
    "end": "3395630"
  },
  {
    "text": "And that satisfies-- so it's\nnot obvious what that is.",
    "start": "3395630",
    "end": "3401750"
  },
  {
    "text": "There's no plus here. Number of leaves is just how\nmany leaves are over here, how many leaves are over here,\nand L of 1 equals 1, say,",
    "start": "3406050",
    "end": "3412560"
  },
  {
    "text": "or some constant\nequals constant. I happen to know, because\nI saw lots of recurrences,",
    "start": "3412560",
    "end": "3419440"
  },
  {
    "text": "this solves to some\nN to the alpha. I claim that L of N is N to the\nalpha for some constant alpha.",
    "start": "3419440",
    "end": "3428730"
  },
  {
    "text": "Why? I'll just prove that it works. So this is now N\nover 5 to the alpha,",
    "start": "3428730",
    "end": "3436250"
  },
  {
    "text": "and this is 7/10 N to the alpha. If it's going to work, this\nrecurrence should be satisfied.",
    "start": "3436250",
    "end": "3444640"
  },
  {
    "text": "And now, if you look\nat this equation, there's a lot of N to the\nalphas, and they all cancel.",
    "start": "3444640",
    "end": "3450080"
  },
  {
    "text": "So I get 1 equals 1/5 to the\nalpha plus 7/10 to the alpha.",
    "start": "3450080",
    "end": "3457305"
  },
  {
    "text": "It's confusing\nbecause I was just watching the TV show\nAlphas, but no relation.",
    "start": "3457305",
    "end": "3462930"
  },
  {
    "text": "So this is now something\npurely in terms of alpha. You just need to check that\nthere is a real solution. There is one.",
    "start": "3462930",
    "end": "3468440"
  },
  {
    "text": "You have to plug it into\nWolfram Alpha or something, no pun intended. Wow, they're just\ncoming out today.",
    "start": "3468440",
    "end": "3475967"
  },
  {
    "text": "And then alpha is... next page... I can't do this by hand.",
    "start": "3475967",
    "end": "3481947"
  },
  {
    "text": "Something like .83978.",
    "start": "3481947",
    "end": "3488207"
  },
  {
    "text": "So we get L of N is say at least N to the 0.8th bigger.",
    "start": "3488207",
    "end": "3495487"
  },
  {
    "text": "It's sublinear and that was enough when we cared about time",
    "start": "3495487",
    "end": "3501247"
  },
  {
    "text": "but now it's bad news because N over B... our goal was to get N over B+1.",
    "start": "3501247",
    "end": "3509087"
  },
  {
    "text": "If B is huge, if B is bigger than N to the 0.2, then we are not achieving this bound.",
    "start": "3509087",
    "end": "3516107"
  },
  {
    "text": "Right. We are always are paying at least N to the 0.8. For example B is roughly N. We are way off!",
    "start": "3516107",
    "end": "3523247"
  },
  {
    "text": "But that's because we used the wrong base case. Turns out if you use a better base case, things just work.",
    "start": "3523247",
    "end": "3529360"
  },
  {
    "text": "So let's do that. I think its going to be smaller. So... the next base... I mean...",
    "start": "3529360",
    "end": "3536900"
  },
  {
    "text": "When you are doing cache full release analysis you never use this base case. The first one you should think about is this one.",
    "start": "3536900",
    "end": "3543100"
  },
  {
    "text": "If you have a problem of size that fits in a constant number of blocks. Well of course that's going to take... once they are read into the cache,",
    "start": "3543100",
    "end": "3550720"
  },
  {
    "text": "you are not going to pay anything. How long does it take to read a constant number of blocks into cache? Constant number of memory transfers.",
    "start": "3550720",
    "end": "3556940"
  },
  {
    "text": "Okay, this is obviously a strictly better base case than this one. Because we have the same thing on the right hand side as a constant",
    "start": "3556940",
    "end": "3564240"
  },
  {
    "text": "but we've solved a larger problem. So clearly you should cut here, instead of there.",
    "start": "3564240",
    "end": "3569600"
  },
  {
    "text": "Then the number of leaves in this recursion...",
    "start": "3569600",
    "end": "3574740"
  },
  {
    "text": "So same recurrence- different base case. So we'd stop recursing conceptually in the analysis, the algorithm goes all the way down,",
    "start": "3574740",
    "end": "3582980"
  },
  {
    "text": "but in the analysis we stop recursing when we reach a problem of size B. The number of leaves in that new recursion tree will be",
    "start": "3582980",
    "end": "3592440"
  },
  {
    "text": "N over B to the alpha. That's good! That's smaller than N over B.",
    "start": "3592440",
    "end": "3599779"
  },
  {
    "text": "OK, now I'm going\nto wave my hands a little bit and say, MT of N is\norder N over B plus 1.",
    "start": "3599780",
    "end": "3610779"
  },
  {
    "text": "I guess to do that,\nyou want to prove it the same way we did before\nwhen we solved this recurrence,",
    "start": "3610780",
    "end": "3616390"
  },
  {
    "text": "which is by substitution. You assume this is\ntrue, you plug it in, verify it can actually be\ndone with some constants.",
    "start": "3616390",
    "end": "3622750"
  },
  {
    "text": "The intuition of what's going on\nis, in general, this recurrence is dominated by the root. The root cost for this\nrecursion is N over B plus 1.",
    "start": "3622750",
    "end": "3631759"
  },
  {
    "text": "So this is the root cost. I claim that, up to\nconstant factors, that is the overall cost. Roughly because, as you go\ndown the recursion tree,",
    "start": "3631759",
    "end": "3638440"
  },
  {
    "text": "the cost is decreasing\ngeometrically. But that's not obvious\nfor this recurrence because it's so uneven.",
    "start": "3638440",
    "end": "3644693"
  },
  {
    "text": "But it's kind of like the\nmaster method, a little fancier. Intuitively, this\nshould be obvious.",
    "start": "3644694",
    "end": "3652230"
  },
  {
    "text": "There's the root cost and\nthen there's the other ones. But to actually prove it, you\nshould do substitution method. I want to go to more\ninteresting algorithms instead,",
    "start": "3652230",
    "end": "3662320"
  },
  {
    "text": "but any questions\nbefore we continue?",
    "start": "3662320",
    "end": "3665060"
  },
  {
    "text": "All right. So next algorithm,\nthat was median, now we're going to do matrix\nmultiplication via divide",
    "start": "3667610",
    "end": "3678670"
  },
  {
    "text": "and conquer.",
    "start": "3678670",
    "end": "3679260"
  },
  {
    "text": "So what we just\nsaw was an example where, in divide and\nconquer, in the analysis we think about the\ncase where things fit",
    "start": "3692620",
    "end": "3699130"
  },
  {
    "text": "in a constant number of blocks. That was sort of case one. The next example,\nmatrix multiplication,",
    "start": "3699130",
    "end": "3704372"
  },
  {
    "text": "will be the other case. So you get to see both types.",
    "start": "3704372",
    "end": "3707100"
  },
  {
    "text": "So multiplying\nmatrices, something we've done many times. For example, in the FFT\nlecture and in the Strassen's",
    "start": "3713650",
    "end": "3721020"
  },
  {
    "text": "algorithm, just to remind you. I'm just thinking\nabout the square case, although this generalizes.",
    "start": "3721020",
    "end": "3727859"
  },
  {
    "text": "We have two square\nmatrices, N by N.",
    "start": "3727860",
    "end": "3736140"
  },
  {
    "text": "Normally, I would say\nC equals A times B, but I realized we\nused B for block side. So this is going to\nbe s equals x times y.",
    "start": "3736140",
    "end": "3746125"
  },
  {
    "text": "Hopefully that doesn't conflict\nwith anything else, but no B's. All right, so standard matrix.",
    "start": "3746125",
    "end": "3753510"
  },
  {
    "text": "Let's start with the\nstandard algorithm.",
    "start": "3753510",
    "end": "3755420"
  },
  {
    "text": "Let's start by analyzing that. Because if you're\nreasonably clever, this the standard\nalgorithm is not so bad.",
    "start": "3762090",
    "end": "3770740"
  },
  {
    "text": "So in general, this\nwon't matter too much. Let's suppose we're\ndoing z row-by-row,",
    "start": "3770740",
    "end": "3777150"
  },
  {
    "text": "and let's say we're currently\ncomputing this product cell.",
    "start": "3777150",
    "end": "3783150"
  },
  {
    "text": "So that product cell\nis the dot product this ZIJ here is the dot product\nof this row with this column.",
    "start": "3783150",
    "end": "3795410"
  },
  {
    "text": "How do I compute dot products? Two parallel scans. Right? I scan through this\nrow and I parallel",
    "start": "3795410",
    "end": "3800520"
  },
  {
    "text": "scan through this column. Now, it depends the order\nin which you store x and y,",
    "start": "3800520",
    "end": "3806160"
  },
  {
    "text": "but let's suppose we can\nstore x in row major order, meaning row-by-row, and we\nstore y in column major order,",
    "start": "3806160",
    "end": "3813240"
  },
  {
    "text": "meaning column-by-column. Then this will be an\nhonest-to-goodness scan of a contiguous array. Again, the order we store\nthings in memory really matters.",
    "start": "3813240",
    "end": "3821550"
  },
  {
    "text": "So let's make our life ideal. Let's say that\nthis is row-by-row",
    "start": "3821550",
    "end": "3828119"
  },
  {
    "text": "and this one is\ncolumn-by-column, then hey, this is two parallel\nscans so order N over B",
    "start": "3828120",
    "end": "3835500"
  },
  {
    "text": "to compute this cell. OK, I claim that\ncomputing ZIJ costs",
    "start": "3835500",
    "end": "3847500"
  },
  {
    "text": "N over B, so maybe plus 1. Again, these are end-by-end\nmatrices, so total size N",
    "start": "3847500",
    "end": "3855240"
  },
  {
    "text": "squared, which means\nthe total cost is what?",
    "start": "3855240",
    "end": "3861250"
  },
  {
    "text": "N cubed over B plus\nN squared, I guess.",
    "start": "3864480",
    "end": "3870480"
  },
  {
    "text": "Seems pretty good. I mean, we had a running\ntime of N cubed before and we divided by B. How\ncould you possibly do better?",
    "start": "3870480",
    "end": "3877470"
  },
  {
    "text": "Well, by being smarter. This is not optimal,\nyou can do better.",
    "start": "3877470",
    "end": "3883667"
  },
  {
    "text": "It's not obvious,\nbut let me just spend a little more time convincing\nyou this is the right answer.",
    "start": "3886500",
    "end": "3893160"
  },
  {
    "text": "Not only is this big O, but\nfor appropriate settings-- in the worst case this\nis going to be theta.",
    "start": "3893160",
    "end": "3898440"
  },
  {
    "text": "Because if you think of the\norder in which we're-- see, we look at these\nrows several times.",
    "start": "3901110",
    "end": "3906680"
  },
  {
    "text": "And if you look at, when I\ncompute this cell and this cell and this cell of the z\nmatrix, or the product matrix,",
    "start": "3906680",
    "end": "3912420"
  },
  {
    "text": "each of them uses\nthe same row of x. So maybe you could reuse that.",
    "start": "3912420",
    "end": "3918300"
  },
  {
    "text": "You could reuse that row of x. That might actually\nbe free, depending",
    "start": "3918300",
    "end": "3923550"
  },
  {
    "text": "on how B and N relate. But the columns of y, those\nare different every time.",
    "start": "3923550",
    "end": "3930930"
  },
  {
    "text": "When I compute this one,\nI use the first column of y, when I compute this one\nI use the second column of y. Unless the cache\nis so big that it",
    "start": "3930930",
    "end": "3938010"
  },
  {
    "text": "can store all of\ny, which is like, you could store the\nentire problem in cache that's unrealistic.",
    "start": "3938010",
    "end": "3944460"
  },
  {
    "text": "So unless M is bigger\nthan N squared, in this algorithm at least, you\nhave to read a new column of y",
    "start": "3944460",
    "end": "3952289"
  },
  {
    "text": "every single time. So that's why it's\ntheta N over B plus 1. You need to spend\nN over B, assuming",
    "start": "3952290",
    "end": "3960430"
  },
  {
    "text": "M is less than N squared.",
    "start": "3960430",
    "end": "3963400"
  },
  {
    "text": "OK. And I claim this is not the\nbest you can do because we're going to do better. And we're going to do better\nby divide and conquer.",
    "start": "3966160",
    "end": "3972630"
  },
  {
    "text": "Now, you've already seen\ndivide and conquer used for matrix multiplication\nto get Strassen's algorithm,",
    "start": "3988490",
    "end": "3996930"
  },
  {
    "text": "and the idea there\nis to use blocks.",
    "start": "3996930",
    "end": "4000231"
  },
  {
    "text": "So this is sort of an\nalgorithm you've already seen. I'm going to divide the\nmatrix z into N over 2",
    "start": "4004100",
    "end": "4015080"
  },
  {
    "text": "by N over 2 sub-matrices. Each of these ZIJs is an N\nover 2 by N over 2 matrix.",
    "start": "4015080",
    "end": "4022190"
  },
  {
    "text": "And I do the same\nthing for x and y.",
    "start": "4022190",
    "end": "4026210"
  },
  {
    "text": "Numbers are right. 1, 2, y, 2, 1, and so on. And you can write\nthis out explicitly.",
    "start": "4035400",
    "end": "4042190"
  },
  {
    "text": "I prefer not to do all of\nit, but let's do one of them. You can just think of these\nas two-by-two matrices,",
    "start": "4042190",
    "end": "4047470"
  },
  {
    "text": "because matrix\nmultiplication is associative and good things happen. I can just take\nthese two elements-- but they're actually\nmatrices, sorry.",
    "start": "4047470",
    "end": "4054640"
  },
  {
    "text": "I might take these two and\ndot product with these two. And I get x1,1 y1,1\nplus x1,2 y2,1,",
    "start": "4054640",
    "end": "4066789"
  },
  {
    "text": "and that's what I\nshould set z1,1 to. So this is a formula, but it's\nalso a recursive algorithm.",
    "start": "4066790",
    "end": "4074020"
  },
  {
    "text": "It says, if I want to\ncompute z I'm going to say, well, there are\nfour sub-problems.",
    "start": "4074020",
    "end": "4079510"
  },
  {
    "text": "The first one is\nto compute z1,1, and I'm going to do that\nby recursively computing the product of x1,1 and\ny1,1, recursively computing",
    "start": "4079510",
    "end": "4086500"
  },
  {
    "text": "the product of x1,2 y2,1 and\nthen adding them together. This is not recursive. Addition is easy.",
    "start": "4086500",
    "end": "4093081"
  },
  {
    "text": "OK. And there's two products\nhere, two products here, two products here,\ntwo products here, a total of eight\nproducts, so we're",
    "start": "4093081",
    "end": "4098829"
  },
  {
    "text": "going to have eight recursive\ncalls in size N over 2.",
    "start": "4098830",
    "end": "4101380"
  },
  {
    "text": "If we look at the number\nof memory transfers, this is 8 times recursive\ncall on N over 2 by N",
    "start": "4105055",
    "end": "4111689"
  },
  {
    "text": "over 2 sub-matrices plus\nthe cost of addition.",
    "start": "4111689",
    "end": "4117549"
  },
  {
    "text": "And I claim the cost of addition\nis at most N squared over B plus 1, because addition is\nbasically parallel scans.",
    "start": "4117550",
    "end": "4126461"
  },
  {
    "text": "I can scan through\nx, scan through y. As long as they're\nstored in the same order,",
    "start": "4126461",
    "end": "4132609"
  },
  {
    "text": "I just am adding them\nelement by element, and there's a third scan, which\nis writing out the z vector",
    "start": "4132609",
    "end": "4139960"
  },
  {
    "text": "once things are linearized. Now, for this to work, for\nthis to be a true recursion,",
    "start": "4139960",
    "end": "4146100"
  },
  {
    "text": "I need that, say, x1,1 and y1,1\nare stored as contiguous things",
    "start": "4146100",
    "end": "4152278"
  },
  {
    "text": "in memory. So this means that the\nlayout of a matrix,",
    "start": "4152279",
    "end": "4159809"
  },
  {
    "text": "let's consider the matrix z, is\ngoing to be like the following. I'm going to recursively lay\nout 1,1-- so when I say lay out,",
    "start": "4159809",
    "end": "4167370"
  },
  {
    "text": "I mean what order do I store\nthe elements in memory? What order do I store\nthe cells in memory? And what I'm going to say\nis, recursively lay out",
    "start": "4167370",
    "end": "4176369"
  },
  {
    "text": "the pieces-- there's four\npieces-- recursively call layout of those and then\nconcatenate them together.",
    "start": "4176370",
    "end": "4186281"
  },
  {
    "text": "That's my layout. So I'm going to store\nall of these items, then I'm going to store\nall of these items, and then all of these\nitems, then all these items.",
    "start": "4186282",
    "end": "4192509"
  },
  {
    "text": "How do I store these\nitems, in what order? Recursively. So I'm going to\ndivide them like this,",
    "start": "4192510",
    "end": "4197690"
  },
  {
    "text": "store these before these\nbefore these before these, how do I store these? Recursively. OK, same recursion. So it's a really\nweird order, it's",
    "start": "4197690",
    "end": "4204510"
  },
  {
    "text": "a divide and conquer order. There's only four things here. In what order should I\ncombine the four things?",
    "start": "4204510",
    "end": "4210510"
  },
  {
    "text": "Doesn't matter. All that matters is that\nthis is consecutive, this is consecutive,\nand this is consecutive,",
    "start": "4210510",
    "end": "4215730"
  },
  {
    "text": "so that when I recurse, I'm\nrecursing on consecutive chunks of memory. Otherwise the analysis\njust won't work.",
    "start": "4215730",
    "end": "4221070"
  },
  {
    "text": "So for this to be right,\ngot to have this layout. OK.",
    "start": "4221070",
    "end": "4226500"
  },
  {
    "text": "Now we just need to solve the\nrecurrence, and we're done.",
    "start": "4226500",
    "end": "4232110"
  },
  {
    "text": "I already told you, the\nbase case we're going to use is this one. We're going to use\nthis one because it's",
    "start": "4232110",
    "end": "4237526"
  },
  {
    "text": "stronger and better, and\nwe'll need it, in this case, to get a better analysis.",
    "start": "4237526",
    "end": "4243442"
  },
  {
    "text": "You could solve it using\nthe weaker base cases, you'll get larger numbers. But if you use the strongest\nbase case, MT of-- it's",
    "start": "4243442",
    "end": "4251309"
  },
  {
    "text": "not M. Got to be\na little careful. Because N here is actually\njust one side length.",
    "start": "4251309",
    "end": "4256980"
  },
  {
    "text": "This is an end-by-end\nmatrix, so the total size is N squared-- actually the\ntotal size is 3N squared,",
    "start": "4256980",
    "end": "4264719"
  },
  {
    "text": "so this is going to be the\nsquare root of M over 3, at some constant, times the\nsquare root of N. It actually",
    "start": "4264720",
    "end": "4272880"
  },
  {
    "text": "doesn't matter what\nthe constant is. But this is the\nsize of-- this is the value of N for which\nall three matrices will",
    "start": "4272880",
    "end": "4278400"
  },
  {
    "text": "fit in cache. So I claim we know this costs at\nmost M over B memory transfers,",
    "start": "4278400",
    "end": "4287309"
  },
  {
    "text": "because we were kind of\nstroke here because we know",
    "start": "4287309",
    "end": "4293550"
  },
  {
    "text": "that all of these\nguys fit in cache and because we know that they\ncan store it consecutively in memory, well three\nconsecutive chunks.",
    "start": "4293550",
    "end": "4300840"
  },
  {
    "text": "Once, no matter what I do, there\nare only M over B blocks there,",
    "start": "4300840",
    "end": "4305940"
  },
  {
    "text": "and so at worst I\nread them all in. But once the cache\nis filled with them, for the duration\nof this recursion,",
    "start": "4305940",
    "end": "4312540"
  },
  {
    "text": "I won't be reading\nany other blocks, and so the cache will just\nstay full with the problem. And so I never pay\nmore than this.",
    "start": "4312540",
    "end": "4319440"
  },
  {
    "text": "So that's the base case. Easy, but you have to think\nabout it for a second.",
    "start": "4319440",
    "end": "4325140"
  },
  {
    "text": "Cool. Now we have a recurrence\nand a base case, and now we have a good old\nfashioned recursion tree.",
    "start": "4325140",
    "end": "4331210"
  },
  {
    "text": "This one I can actually\ndraw, because it's-- well, partly because it's\nnice and uniform.",
    "start": "4331210",
    "end": "4337120"
  },
  {
    "text": "It just explodes rather fast. So at the top we have a cost\nof N squared over B plus 1,",
    "start": "4337120",
    "end": "4345960"
  },
  {
    "text": "and we have eight\nrecursive calls. And the recursive calls\nare to something in size",
    "start": "4345960",
    "end": "4351960"
  },
  {
    "text": "N over 2 squared over B, also\nknown as N squared over 4B.",
    "start": "4351960",
    "end": "4359969"
  },
  {
    "text": "OK, so if I add up\neverything on this level, I get N squared over B, and if I\nadd up everything on this level",
    "start": "4359970",
    "end": "4366179"
  },
  {
    "text": "I'm going to get 8 times\nN over 4-- is that right?",
    "start": "4366180",
    "end": "4373200"
  },
  {
    "text": "Yeah. So 2 times N squared over B. OK.",
    "start": "4373200",
    "end": "4378870"
  },
  {
    "text": "I did that in order to verify\nthat the cost per level is increasing geometrically,\nso all that will matter",
    "start": "4378870",
    "end": "4386429"
  },
  {
    "text": "is the leaf level. This is the proof of\nthe master theorem.",
    "start": "4386430",
    "end": "4391520"
  },
  {
    "text": "When things are\ndoubling at every step-- and this was just\na special case, but every level would look\nthe same-- every level",
    "start": "4391520",
    "end": "4398529"
  },
  {
    "text": "of recursion, if\nyou add them all up, you're getting twice as much as\nyou had at the previous level. So all that will matter\nis the leaf level.",
    "start": "4398529",
    "end": "4406150"
  },
  {
    "text": "OK, the leaf level. Actually, maybe I'll\ndo it over here.",
    "start": "4406150",
    "end": "4412610"
  },
  {
    "text": "First question is how\nmany leaves are there? The leaves are this thing.",
    "start": "4412610",
    "end": "4417900"
  },
  {
    "text": "So the way I would think about\nthis is, because everything is nice and uniform, is 8 to the\npower of the number of levels.",
    "start": "4417900",
    "end": "4424499"
  },
  {
    "text": "What's the number of levels?",
    "start": "4424499",
    "end": "4425665"
  },
  {
    "text": "Well, we're dividing\nby 2 each time, so it's going to be\nlog of something,",
    "start": "4430790",
    "end": "4436558"
  },
  {
    "text": "but it's no longer log N\nbecause we're stopping early. We're stopping when\nN reaches this value.",
    "start": "4436559",
    "end": "4443449"
  },
  {
    "text": "So it turns out that is\nN divided by that value.",
    "start": "4443450",
    "end": "4448120"
  },
  {
    "text": "This is, how many\ntimes do I have to multiply by 2 before\nI get to this, which is the same thing as how many\ntimes do I have to divide N",
    "start": "4450856",
    "end": "4457150"
  },
  {
    "text": "by 2 before I get that? Think about it. OK, but 8 to the log.",
    "start": "4457150",
    "end": "4462320"
  },
  {
    "text": "This is 2 to the 3 times log. 2 to the log is just the thing.",
    "start": "4462320",
    "end": "4467690"
  },
  {
    "text": "So this is N over root M\nover B-- so many overs--",
    "start": "4467690",
    "end": "4476830"
  },
  {
    "text": "to the third power. OK, this is starting\nto look familiar. This is N cubed, that\nshould appear somewhere,",
    "start": "4476830",
    "end": "4486080"
  },
  {
    "text": "divided by square\nroot of M over B. This is the number of leaves. Now, for each leaf\nwe're paying this cost,",
    "start": "4486080",
    "end": "4495880"
  },
  {
    "text": "so the overall cost of MT of N\nis going to be this times this.",
    "start": "4495880",
    "end": "4503020"
  },
  {
    "text": "So let's do that and simplify.",
    "start": "4503020",
    "end": "4504280"
  },
  {
    "text": "So MT of N is going to be big\nO, because we're taking the leaf",
    "start": "4511930",
    "end": "4518062"
  },
  {
    "text": "level but there's some\nother things that's just going to lose us a factor of 2.",
    "start": "4518062",
    "end": "4523530"
  },
  {
    "text": "We have this thing\nmultiplied by this thing. So we've got N cubed over\nsquare root of M over B",
    "start": "4523530",
    "end": "4534219"
  },
  {
    "text": "times M over B.",
    "start": "4534220",
    "end": "4540798"
  },
  {
    "text": "AUDIENCE: You-- PROFESSOR: I made a mistake. Yea, thank you. This was supposed to be cubed.",
    "start": "4540798",
    "end": "4545970"
  },
  {
    "text": "So this was M over B to\nthe 1/2, so now we have, down here, M over B to the 3/2.",
    "start": "4545970",
    "end": "4552720"
  },
  {
    "text": "Thank you, thought\nthat looked weird.",
    "start": "4552720",
    "end": "4554965"
  },
  {
    "text": "All right. M over B to the 3/2.",
    "start": "4559850",
    "end": "4566531"
  },
  {
    "text": "OK. AUDIENCE: [INAUDIBLE]",
    "start": "4566531",
    "end": "4568473"
  },
  {
    "text": "PROFESSOR: Yeah. What was I doing here? This is supposed to be M over 3. I was not missing a\nstroke, thank you.",
    "start": "4577170",
    "end": "4583605"
  },
  {
    "text": "M over 3, this is\nsupposed to be M over 3. Wow.",
    "start": "4583605",
    "end": "4589240"
  },
  {
    "text": "OK, so this is M over 3. I'm just going to drop the--\nwell, I'll put it here.",
    "start": "4589240",
    "end": "4594780"
  },
  {
    "text": "But then I'm just\ngoing to write theta so I can forget about the\n3, because that's just a square root of 3 factor.",
    "start": "4594780",
    "end": "4601360"
  },
  {
    "text": "So now this is going\nto be M to the 3/2.",
    "start": "4601360",
    "end": "4607405"
  },
  {
    "text": "That makes me much happier. Did I get it right this time?",
    "start": "4607405",
    "end": "4613409"
  },
  {
    "text": "Let's double-check. So this is square root\nof M to the 3 power, so that's M to the 1/2\ncubed M to the 3/2.",
    "start": "4613410",
    "end": "4620840"
  },
  {
    "text": "I think that's good, this base\ncase was square root of M. OK, get it right.",
    "start": "4620840",
    "end": "4627929"
  },
  {
    "text": "So now this is M to the 3/2. There is a square\nroot that's going to come back, there's M to the\n3/2 and there's an M upstairs,",
    "start": "4627929",
    "end": "4636270"
  },
  {
    "text": "so the one cancels. We're going to be left with\nN cubed over square root of M",
    "start": "4636270",
    "end": "4643439"
  },
  {
    "text": "times B. OK. There was a lower order term\nbecause I dropped this plus 1,",
    "start": "4643439",
    "end": "4648570"
  },
  {
    "text": "but let's not worry\nabout that right now. Here we had N cubed\ndivided by B, that",
    "start": "4648570",
    "end": "4653730"
  },
  {
    "text": "was the standard algorithm. Now we've got M cubed divided by\nB divided by square root of M.",
    "start": "4653730",
    "end": "4659160"
  },
  {
    "text": "That's big. I mean, this is\nbasically, you're dividing by-- well, square\nroot of your cache size.",
    "start": "4659160",
    "end": "4665449"
  },
  {
    "text": "Wow. So who knows how big\nthat is, but say, between memory and disk,\nwe're talking gigabytes.",
    "start": "4665450",
    "end": "4672430"
  },
  {
    "text": "So this is like billions. Square root of a billion\nis still pretty big,",
    "start": "4672430",
    "end": "4677450"
  },
  {
    "text": "like 10 to 100,000, so this\nis a huge amount faster than the standard algorithm.",
    "start": "4677450",
    "end": "4682490"
  },
  {
    "text": "You can do way\nbetter than scans. Basically because we're reusing\nthe same rows and columns",
    "start": "4682490",
    "end": "4687650"
  },
  {
    "text": "over and over. Now, this is standard\nmatrix multiplication. You might ask, what about\nStrassen's algorithm? Well, same thing works.",
    "start": "4687650",
    "end": "4693770"
  },
  {
    "text": "You can do the same analysis\nStrassen, of course. You get a similar\nimprovement over Strassen.",
    "start": "4693770",
    "end": "4699020"
  },
  {
    "text": "You can do this for\nnon-square matrices and all those good things. And one minute left.",
    "start": "4699020",
    "end": "4705170"
  },
  {
    "text": "And it's going to\nbe enough, I think, to cover LRU block replacement.",
    "start": "4705170",
    "end": "4711330"
  },
  {
    "text": "So here's what I want to say\nabout LRU block replacement.",
    "start": "4711330",
    "end": "4716568"
  },
  {
    "text": "So in the beginning, we\nsaid the model is LRU, or it could have been FIFO.",
    "start": "4719604",
    "end": "4724670"
  },
  {
    "text": "Remember that? And this algorithm will\nwork just fine from an LRU perspective or a\nFIFO perspective if you think about\nit, but how do",
    "start": "4724670",
    "end": "4731570"
  },
  {
    "text": "we know that LRU is\nas good as anything? I claim, if you look at some\nsequence of block axises--",
    "start": "4731570",
    "end": "4738790"
  },
  {
    "text": "so suppose you know what\nB is-- and you count, for a cache of size M, how many\nmemory transfers does LRU do,",
    "start": "4738790",
    "end": "4747020"
  },
  {
    "text": "it's going to be within a\nfactor of 2 of the optimal. But not the optimal\nfor a cache of size M,",
    "start": "4747020",
    "end": "4752780"
  },
  {
    "text": "the optimal for a\ncache of size M over 2. This is a bit of\na weird statement. I have a factor of 2 here\nand a factor of 2 here.",
    "start": "4752780",
    "end": "4759949"
  },
  {
    "text": "This is a cool idea called\nresource augmentation,",
    "start": "4759950",
    "end": "4767450"
  },
  {
    "text": "fancy word for a simple idea. This we're used to. This is approximation\nalgorithms.",
    "start": "4767450",
    "end": "4773370"
  },
  {
    "text": "OK, but this is an\napproximation in cost. Here we're approximating\nthe resources available to the algorithm.",
    "start": "4773370",
    "end": "4779240"
  },
  {
    "text": "We're changing the machine\nmodel, dividing M by 2, and we get a nice result.",
    "start": "4779240",
    "end": "4786540"
  },
  {
    "text": "Why is this OK? Because, if you look\nat a bound like this, if you change M\nby a factor of 2, it will not change the\nbound by more than a",
    "start": "4786540",
    "end": "4793130"
  },
  {
    "text": "factor of square root of 2. So as long as you\nhave at most, say, a linear or polynomial\ndependence on M,",
    "start": "4793130",
    "end": "4799670"
  },
  {
    "text": "changing M by a\nconstant factor will not change the overall\nrunning time of the cache for the previous algorithm. This is why we can\nassume it's LRU.",
    "start": "4799670",
    "end": "4805430"
  },
  {
    "text": "The same is true for\nFIFO, it's probably true in expectation\nfor random sequences.",
    "start": "4805430",
    "end": "4811660"
  },
  {
    "text": "And I will leave it at that. If you want to see\nthe-- do you want",
    "start": "4811660",
    "end": "4817670"
  },
  {
    "text": "to see the proof\nof this theorem? Tomorrow?",
    "start": "4817670",
    "end": "4822680"
  },
  {
    "text": "Or, Thursday? Yes. OK, we'll cover it on Thursday.",
    "start": "4822680",
    "end": "4826869"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5620"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5620",
    "end": "12280"
  },
  {
    "text": "To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12280",
    "end": "18480"
  },
  {
    "text": "at ocw.mit.edu.  SURYA GANGULI: I'm going to\ntalk about statistical physics",
    "start": "18480",
    "end": "25330"
  },
  {
    "text": "of deep learning, essentially. So this is some\nongoing work in my lab that was really\nmotivated by trying to understand how neural\nnetworks and infants learn",
    "start": "25330",
    "end": "32649"
  },
  {
    "text": "categories. And then it sort of led\nto a bunch of results in deep learning that\ninvolved statistical physics.",
    "start": "32650",
    "end": "38079"
  },
  {
    "text": "So I wanted to just introduce\nmy lab a little bit. I'm an interloper\nfrom the Methods in Computational\nNeuroscience Summer School",
    "start": "38080",
    "end": "44071"
  },
  {
    "text": "where I tend to spend a month. And so there, you know,\nthe flavor of research that we do there and the flavor\nof research we do in our lab",
    "start": "44071",
    "end": "50800"
  },
  {
    "text": "is sort of drilling down into\nneural mechanisms underlying well-defined computations. And we've been working on that.",
    "start": "50800",
    "end": "56410"
  },
  {
    "text": "You know, I spent a\nlot of time talking to neurophysiologists especially\nat Stanford where I am.",
    "start": "56410",
    "end": "61690"
  },
  {
    "text": "So we have a whole\nbunch of collaborations going on now involving\nunderstanding neural computation.",
    "start": "61690",
    "end": "67060"
  },
  {
    "text": "So, for example,\nthe retina itself is actually a deep\nneural circuit already, because there's an\nintervening layer of neurons,",
    "start": "67060",
    "end": "74830"
  },
  {
    "text": "the bipolar cells\nand amacrine cells, that intervene between the\nphotoreceptors and the ganglion cells. And oftentimes, what\nwe do is we shine light",
    "start": "74830",
    "end": "82090"
  },
  {
    "text": "on the photo receptors and we\nmeasure the ganglion cells, but we have no clue what's\ngoing on in the interior.",
    "start": "82090",
    "end": "87190"
  },
  {
    "text": "So we've developed computational\nmethods that can successfully computationally\nreconstruct what's going on in the interior of this\nputative deep neural network",
    "start": "87190",
    "end": "95298"
  },
  {
    "text": "even though we don't have\naccess to these things. And we actually infer the\nexistence and properties of intermediate neurons here.",
    "start": "95299",
    "end": "101140"
  },
  {
    "text": "And those properties are\nsort of similar to what's been previously recorded when\npeople do directly record",
    "start": "101140",
    "end": "107590"
  },
  {
    "text": "from, say, the bipolar cells. In the Clandinin\nLab, we've sort of been unraveling the computations\nunderlying a motion vision.",
    "start": "107590",
    "end": "118977"
  },
  {
    "text": "So you know when you swat\na fly, it's really hard. Because they can\nreally quickly detect motion coming towards it.",
    "start": "118977",
    "end": "124030"
  },
  {
    "text": "And they fly away. You know, so there's\nbeen lots of work on what kinds of\nalgorithms might underlie",
    "start": "124030",
    "end": "132190"
  },
  {
    "text": "motion estimation-- for\nexample, the Reichardt correlator the, Barlow-Levick\nmodel and so forth. We've been applying systems\nidentification techniques",
    "start": "132190",
    "end": "138700"
  },
  {
    "text": "to whole brain\ncalcium imaging data-- well, whole brain meaning\nfrom the fly visual circuit.",
    "start": "138700",
    "end": "143980"
  },
  {
    "text": "And we just literally\nidentify the computation. And we find that it's\nsort of none of the above.",
    "start": "143980",
    "end": "149630"
  },
  {
    "text": "It's a mixture of all\nprevious approaches. So grid cells-- we have\nsome results on grid cells.",
    "start": "149630",
    "end": "154960"
  },
  {
    "text": "So these are these famous cells\nthat resulted in a Nobel Prize recently. We can actually show that\nthese grid cells maintain",
    "start": "154960",
    "end": "161109"
  },
  {
    "text": "their spatial coherence,\nbecause the rat and the mouse are always interacting\nwith the boundaries.",
    "start": "161110",
    "end": "166150"
  },
  {
    "text": "And the boundaries\nactually correct the rat's internal estimate of position. And were it not for\nthese interactions",
    "start": "166150",
    "end": "171685"
  },
  {
    "text": "with the boundaries, the\ngrid cells would rapidly decohere on the time\nscale of minutes,",
    "start": "171685",
    "end": "177250"
  },
  {
    "text": "you know, like\nless than a minute. And so it's actually\nquite interesting. We can show that whenever the\nrat encounters a boundary,",
    "start": "177250",
    "end": "184750"
  },
  {
    "text": "it corrects its internal\nestimate of position perpendicular to the boundary. But it doesn't parallel.",
    "start": "184750",
    "end": "189980"
  },
  {
    "text": "And it doesn't,\nbecause it can't. Because when it\nhits the boundary, it receives no information\nabout where it is parallel to the boundary, but it receives\ninformation in this direction.",
    "start": "189980",
    "end": "197812"
  },
  {
    "text": "And then with the\nShenoy Lab, we've been looking at I think a\nreally major conceptual puzzle in neuroscience.",
    "start": "197812",
    "end": "203590"
  },
  {
    "text": "Why can we record from 100\nneurons in a circuit containing millions of neurons?",
    "start": "203590",
    "end": "208690"
  },
  {
    "text": "And do dimensionality detection\nand try to infer the state space dynamics of\nthe circuit and claim",
    "start": "208690",
    "end": "215920"
  },
  {
    "text": "that we've achieved\nsuccess, right? We're doing dramatic\nundersampling recording 100 neurons out of millions.",
    "start": "215920",
    "end": "223090"
  },
  {
    "text": "How would the state space\ndynamics that we infer change if we recorded more neurons? And we can show\nthat, essentially, it",
    "start": "223090",
    "end": "229480"
  },
  {
    "text": "will not change. Because we've come up\nwith a novel connection between the act of\nneural measurements",
    "start": "229480",
    "end": "234760"
  },
  {
    "text": "and the act of\nrandom projections. So we can show that\nthe act of recording from 100 neurons in the brain\nis like the act of measuring",
    "start": "234760",
    "end": "243129"
  },
  {
    "text": "100 random linear\ncombinations of all neurons in the relevant brain circuit. And then we can apply\nrandom projection theory",
    "start": "243130",
    "end": "248976"
  },
  {
    "text": "to give us a predictive\ntheory of experimental design that tells us, given the\ncomplexity of the task, how",
    "start": "248976",
    "end": "254933"
  },
  {
    "text": "many neurons would you need\nto record to correctly recover the state-space\ndynamics of the circuit. And then in the Raymond\nLab at Stanford,",
    "start": "254934",
    "end": "261159"
  },
  {
    "text": "we've been looking at how\nenhancing synaptic plasticity can either enhance\nor impair learning",
    "start": "261160",
    "end": "267760"
  },
  {
    "text": "depending on experience. So, for example, we think\nthat synaptic plasticity underlies the very basis of our\nability to learn and remember.",
    "start": "267760",
    "end": "275229"
  },
  {
    "text": "So you might think that\nenhancing synaptic plasticity through various pharmacological\nor genetic modifications",
    "start": "275230",
    "end": "281050"
  },
  {
    "text": "might enhance our ability\nto learn and remember. But previous results\nhave been mixed. When you perturb\nsynaptic plasticity,",
    "start": "281050",
    "end": "287139"
  },
  {
    "text": "sometimes you enhance learning,\nsometimes you impair learning. So I believe in the\nRaymond Lab, they're",
    "start": "287140",
    "end": "292150"
  },
  {
    "text": "the first to show that in\nthe same subject enhancing",
    "start": "292150",
    "end": "297484"
  },
  {
    "text": "syntactic plasticity,\nfor example, in the cerebellum\ncan either enhance or impair learning\ndepending on the history",
    "start": "297484",
    "end": "302650"
  },
  {
    "text": "of prior experience. And we can show that in order to\nexplain the behavioral learning curves, you need much more\ncomplex postsynaptic dynamics",
    "start": "302650",
    "end": "309520"
  },
  {
    "text": "than people naturally assume. We have to really promote our\nnotion of what a synapse is from a single scalar, like\na WIJ at a neural network",
    "start": "309520",
    "end": "317620"
  },
  {
    "text": "to an entire dynamical\nsystem in its own right. So this relates to VOR learning. So this is sort of the low-level\nstuff that we've been doing.",
    "start": "317620",
    "end": "324360"
  },
  {
    "text": "I know that in this course you\nguys study higher level stuff. So I'm not going to\ntalk about any of these.",
    "start": "324360",
    "end": "329370"
  },
  {
    "text": "Each of them could be\nlike a one hour talk. But I wanted to discuss\nsome more high level stuff that we've been doing.",
    "start": "329370",
    "end": "335350"
  },
  {
    "text": "Oh, sorry. And sorry, the other sort\nof direction in our lab that we're looking\nat is actually the statistical mechanics of\nhigh dimensional data analysis.",
    "start": "335350",
    "end": "342789"
  },
  {
    "text": "So this is, of course,\nvery relevant in the age of the BRAIN Initiative and\nso on where we're developing very large scale\ndata sets and we'd",
    "start": "342790",
    "end": "348900"
  },
  {
    "text": "like to extract theories\nfrom this so-called big data. So the entire edifice\nof classical statistics",
    "start": "348900",
    "end": "354960"
  },
  {
    "text": "is predicated on the assumption\nthat you have many, many data points and you have a small\nnumber of features, right?",
    "start": "354960",
    "end": "361820"
  },
  {
    "text": "So then it's very easy to\nsee patterns in your data. But what's actually\nhappening, nowadays, is that we have a large\nnumber of data points",
    "start": "361820",
    "end": "369175"
  },
  {
    "text": "and a large number of\nfeatures-- so for example, where you can record from 100\nneurons using electrophysiology",
    "start": "369175",
    "end": "375720"
  },
  {
    "text": "maybe for only 100\ntrials of any given trial type in a monkey\ndoing some task. So the ratio of the amount of\ndata to the number of features",
    "start": "375720",
    "end": "384640"
  },
  {
    "text": "is something that's order one. So you know, the data\nsets are like three points in a three-dimensional space. That's the best\nwe can visualize.",
    "start": "384640",
    "end": "390820"
  },
  {
    "text": "So it's a significant\nchallenge to do data analysis in this scenario. So it turns out there's\nbeautiful connections",
    "start": "390820",
    "end": "396120"
  },
  {
    "text": "between machine\nlearning and data analysis and the statistical\nphysics of systems of quenched disorder. So what I mean by that\nis in data analysis",
    "start": "396120",
    "end": "403260"
  },
  {
    "text": "you want to learn\nstatistical parameters by maximizing the log\nlikelihood of the data given the parameters.",
    "start": "403260",
    "end": "408850"
  },
  {
    "text": "In statistical physics,\nyou often want to minimize. You know, this can be viewed\nas energy minimization. And so there's beautiful\nconnections between these.",
    "start": "408850",
    "end": "415330"
  },
  {
    "text": "And so we work on that. So we've applied this\nto compressed sensing. We've applied this\nto the problem of what's the optimal inference\nprocedure in a regime,",
    "start": "415330",
    "end": "423569"
  },
  {
    "text": "in a high-dimensional regime. We know that maximum likelihood\nis optimal in this regime. But something else is\nbetter in this regime.",
    "start": "423570",
    "end": "429750"
  },
  {
    "text": "And we found what's better. It turns out to be a\nsmooth maximum likelihood. And, of course,\nwe've applied this to a theory of neural\ndimensionality and measurement.",
    "start": "429750",
    "end": "436554"
  },
  {
    "text": "So, you know, there's lots\nof beautiful interactions between physics, machine\nlearning, and neuroscience.",
    "start": "436554",
    "end": "441930"
  },
  {
    "text": "And, you know, this school\nis a lot about that. If you're interested, actually,\nwe wrote like a 70-page review",
    "start": "441930",
    "end": "447450"
  },
  {
    "text": "on statistical mechanics\nof complex neural systems and high-dimensional data. We cover a whole bunch of\nthings like spin glasses,",
    "start": "447450",
    "end": "454039"
  },
  {
    "text": "the statistical mechanics of\nlearning, random matrix theory, random dimensionality\nreduction, compressed sensing, and so on and so forth.",
    "start": "454040",
    "end": "459820"
  },
  {
    "text": "It was our attempt\nto sort of put some systematic order on\nthe diversity of topics",
    "start": "459820",
    "end": "465259"
  },
  {
    "text": "viewed through the lens\nof statistical physics. But what do I want\nto talk about today? And why did I decide to\nbranch out in the direction",
    "start": "465260",
    "end": "472420"
  },
  {
    "text": "that I'm going to\ntell you about? Well, I think there's\nlots of motivations for the alliance between\ntheoretical neuroscience,",
    "start": "472420",
    "end": "477679"
  },
  {
    "text": "theoretical machine learning\nthat lead to opportunities for physics, and\nmath, and so on.",
    "start": "477679",
    "end": "483010"
  },
  {
    "text": "So this is the question that\nshould haunt all of us, right? The question is,\nwhat does it even mean to understand\nhow the brain works",
    "start": "483010",
    "end": "489570"
  },
  {
    "text": "or how a neural circuit works? OK? You know, that's\nan open question that we really have\nto come to terms with.",
    "start": "489570",
    "end": "496290"
  },
  {
    "start": "496290",
    "end": "501690"
  },
  {
    "text": "A more concrete version\nof this question might be, or a specification\nof this question might be, we will understand\nthis when we understand",
    "start": "501690",
    "end": "509730"
  },
  {
    "text": "how the connectivity and\ndynamics of a neural circuit give rise to behavior and\nalso how neural activity",
    "start": "509730",
    "end": "515190"
  },
  {
    "text": "and synaptic learning\nrules conspire to self-organize useful\nconnectivity that subserves behavior.",
    "start": "515190",
    "end": "520240"
  },
  {
    "text": "OK?  So, you know, various\nBRAIN Initiatives",
    "start": "520240",
    "end": "525390"
  },
  {
    "text": "are promising to\ngive us recording some large numbers\nof neurons and even give us the connectivity\nbetween those neurons.",
    "start": "525390",
    "end": "532830"
  },
  {
    "text": "Now, what have theorists done? Often what theorists in\ncomputational neuroscience do is they often develop\ntheories of random networks",
    "start": "532830",
    "end": "539520"
  },
  {
    "text": "that have no function. But what we would\nlike to do is we'd like to understand engineered\nnetworks that have function.",
    "start": "539520",
    "end": "545160"
  },
  {
    "text": "So the field of machine learning\nhas generated a plethora of learned neural\nnetworks that accomplish interesting functions.",
    "start": "545160",
    "end": "551130"
  },
  {
    "text": "Yet we still don't have a\nmeaningful understanding of how their connectivity,\ndynamics, the learning rule,",
    "start": "551130",
    "end": "556870"
  },
  {
    "text": "the developmental experience-- OK. So basically, we\ncan measure anything we want in these artificial\nneural networks, right?",
    "start": "556870",
    "end": "562300"
  },
  {
    "text": "We can measure all\nthe connectivity between all the neurons. We know the dynamics\nof all the neurons. We know the learning rule.",
    "start": "562300",
    "end": "568139"
  },
  {
    "text": "We know the entire developmental\nexperience of the network, because we know the training\ndata that it was exposed to.",
    "start": "568140",
    "end": "573630"
  },
  {
    "text": "Yet we still do not have\na meaningful understanding of how they learn\nand how they work. And if we can't solve that\nproblem, how are we ever going",
    "start": "573630",
    "end": "580470"
  },
  {
    "text": "to understand the brain, right,\nin the form of this question? OK? So that was sort of\nwhat was motivating",
    "start": "580470",
    "end": "586830"
  },
  {
    "text": "me to look into this. So this is the\noutline of the talk. The original entry\npoint was trying to understand category\nlearning in neural networks.",
    "start": "586830",
    "end": "593753"
  },
  {
    "text": "And then at the\nend of the day, we made actually several\ntheoretical advances that led to advances in machine\nlearning and applications",
    "start": "593754",
    "end": "599805"
  },
  {
    "text": "to engineering. So, for example, we found\nrandom weight initializations that make a network\ndynamically critical",
    "start": "599805",
    "end": "607019"
  },
  {
    "text": "and allow very,\nvery rapid training of deep neural networks. We were able to\nunderstand and exploit",
    "start": "607020",
    "end": "612570"
  },
  {
    "text": "the geometry of high-dimensional\nerror surfaces to, again, speed",
    "start": "612570",
    "end": "617790"
  },
  {
    "text": "up learning, like training\ndeep neural networks. And we were also able to\nexploit sort of recent work",
    "start": "617790",
    "end": "623029"
  },
  {
    "text": "in non-equilibrium\nthermodynamics to learn complex probabilistic\ngenerative models.",
    "start": "623030",
    "end": "628880"
  },
  {
    "text": "So it's a diversity of topics,\nbut I'll walk you through them. And, you know, you can relax,\nbecause almost everything",
    "start": "628880",
    "end": "635210"
  },
  {
    "text": "I'm going to talk\nabout is published. OK. So let's start with\nthe motivation,",
    "start": "635210",
    "end": "640448"
  },
  {
    "text": "a mathematical theory\nof semantic development. I think this speaks to some\nof the high level stuff that you guys think about.",
    "start": "640448",
    "end": "645800"
  },
  {
    "text": "This part could be\ncalled the misadventures of an applied physicists\nwho found himself lost",
    "start": "645800",
    "end": "651290"
  },
  {
    "text": "in the psychology department. So I just sort of\nshowed up at Stanford. Jay's a great guy. I was talking to him. And I learned about his work.",
    "start": "651290",
    "end": "657330"
  },
  {
    "text": "And I realized it\ndidn't understand it. And this is my attempt\nto understand that work with Andrew and Jay.",
    "start": "657330",
    "end": "663779"
  },
  {
    "text": "OK. So what is semantic cognition? So human semantic cognition, a\nrough definition of this field,",
    "start": "663780",
    "end": "669019"
  },
  {
    "text": "is that we have an ability to\nlearn, recognize, comprehend, and produce inferences\nabout properties of objects",
    "start": "669020",
    "end": "675110"
  },
  {
    "text": "and events in the\nworld, especially properties that are not present\nin your current perceptual stimulus. So, for example, I can\nask you does a cat fur",
    "start": "675110",
    "end": "682310"
  },
  {
    "text": "and do birds fly, and you\ncan answer these questions correctly despite the fact\nthat there's currently no cat or bird in the room, right?",
    "start": "682310",
    "end": "689360"
  },
  {
    "text": "So, you know, our\nability to do this likely relies on our ability to\nform internal representations",
    "start": "689360",
    "end": "694580"
  },
  {
    "text": "of categories in the external\nworld and associate properties with those categories. Because we never see\nthe same stimulus twice.",
    "start": "694580",
    "end": "701510"
  },
  {
    "text": "So whenever we\nsee a new stimulus or we try to recall\ninformation from our brain, we rapidly identify\nthe relevant category",
    "start": "701510",
    "end": "708306"
  },
  {
    "text": "that contains the information. And we use that\ncategorical representation to guide future actions\nor give answers.",
    "start": "708306",
    "end": "714889"
  },
  {
    "text": "So category formation is\ncentral to this, right? So what are the kinds\nof psychophysical tasks that people use to probe\nsemantic cognition?",
    "start": "714890",
    "end": "722770"
  },
  {
    "text": "So this is a very rich field. Psychologists have been\nworking on this all the time. So one example is\nlooking time studies",
    "start": "722770",
    "end": "728990"
  },
  {
    "text": "to ascertain whether\nor not an infant can distinguish between two\ncategories of objects at what age.",
    "start": "728990",
    "end": "734520"
  },
  {
    "text": "So, for example, they'll\nshow a sequence of objects from category one, say, horses. And the first time the infant\nsees a horse, the looking time",
    "start": "734520",
    "end": "741110"
  },
  {
    "text": "will go up. And then it goes down over time. It gets bored. Then you show a cow. And if the infant is old\nenough, the looking time",
    "start": "741110",
    "end": "747740"
  },
  {
    "text": "will go up and\nthen go back down. And from that, we infer that\nthe infant can distinguish between horses and cows.",
    "start": "747740",
    "end": "753529"
  },
  {
    "text": "But if it's not old enough, the\nlooking time will not go up. So as the infant\ngets older and older, it can make more and more\nfine scale discriminations",
    "start": "753530",
    "end": "760460"
  },
  {
    "text": "between categories it turns out. So property verification tasks--",
    "start": "760460",
    "end": "765500"
  },
  {
    "text": "you can ask, can a canary move? Can it sing? And certain questions\nare answered quickly. Certain questions\nare answered late,",
    "start": "765500",
    "end": "771373"
  },
  {
    "text": "which speaks to\ncertain properties being central and peripheral\nto certain categories. Category membership queries--\nis a sparrow a bird,",
    "start": "771374",
    "end": "778280"
  },
  {
    "text": "or is an ostrich a bird? Again, there's\ndifferent latencies. And that suggests that there are\ntypical and atypical category",
    "start": "778280",
    "end": "784310"
  },
  {
    "text": "members. And also, very,\nvery important to us is inductive generalization. We can both generalize familiar\nproperties to novel objects--",
    "start": "784310",
    "end": "791420"
  },
  {
    "text": "for example, a\nblick has feathers. Does it fly? Does it sing? And we can generalize novel\nproperties to familiar objects.",
    "start": "791420",
    "end": "797360"
  },
  {
    "text": "A bird has gene x. Does a crocodile have gene x? Does a dog have gene x? You know, so people have\nmeasured these patterns",
    "start": "797360",
    "end": "803652"
  },
  {
    "text": "of inductive generalizations. And there's various\ntheories that try to explain all of this stuff. So Jay has been working on this\nstuff from a neural network",
    "start": "803652",
    "end": "810410"
  },
  {
    "text": "perspective. And he wrote a beautiful book\ncalled Semantic Cognition where he uses neural\nnetworks to explain",
    "start": "810410",
    "end": "816440"
  },
  {
    "text": "a whole variety of\nphenomena especially, for example, the progressive\ndifferentiation of concepts.",
    "start": "816440",
    "end": "823490"
  },
  {
    "text": "So let me just walk\nyou through that. And so this was, you\nknow, a first encounter",
    "start": "823490",
    "end": "829080"
  },
  {
    "text": "with a deep neural network. So they were doing\ndeep neural networks before they became popular.",
    "start": "829080",
    "end": "834680"
  },
  {
    "text": "And so what they were\ndoing was they asked, can we model the development\nof, say, concepts in infants?",
    "start": "834680",
    "end": "841190"
  },
  {
    "text": "And so what they did\nwas they had a toy data set where they had\na bunch of objects",
    "start": "841190",
    "end": "846230"
  },
  {
    "text": "and each object had a\nwhole bunch of properties. So, for example, a canary can\ngrow, move, fly, and sing,",
    "start": "846230",
    "end": "852970"
  },
  {
    "text": "right? And so what they\ndid was they exposed this deep neural network to\ntraining data of this form.",
    "start": "852970",
    "end": "859576"
  },
  {
    "text": "You know, they had a\nwhole bunch of features and questions and objects. And they just exposed the\nnetwork to training data,",
    "start": "859577",
    "end": "865070"
  },
  {
    "text": "trained it using\nback propagation. And they looked at the internal\nrepresentations in the network, especially their evolution over\ndevelopmental time or training",
    "start": "865070",
    "end": "872810"
  },
  {
    "text": "time, right? And this is what they found. So initially, the network\nstarted with random weights.",
    "start": "872810",
    "end": "877820"
  },
  {
    "text": "So there was no structure. OK. So what did they do here? They looked at the distances\nbetween the internal",
    "start": "877820",
    "end": "885470"
  },
  {
    "text": "representations in this space. And they did hierarchical\nclustering or multidimensional scaling.",
    "start": "885470",
    "end": "891029"
  },
  {
    "text": "And they found these plots\nor these plots, right? So what you see is, early\nin developmental time,",
    "start": "891030",
    "end": "897050"
  },
  {
    "text": "the network first makes a\ncoarse-grain discrimination between animals\nand plants, right?",
    "start": "897050",
    "end": "905240"
  },
  {
    "text": "And then later, it makes\nfiner scale discriminations. And then eventually\nwhen it's fully learned, it learns the hierarchical\nstructure that's",
    "start": "905240",
    "end": "911501"
  },
  {
    "text": "implicit in the training data. OK. And this is a\nmultidimensional scaling plot where initially the animals\nmove away from the plants,",
    "start": "911501",
    "end": "918240"
  },
  {
    "text": "and then, you know, fish\nmove away from birds, and trees move\naway from flowers.",
    "start": "918240",
    "end": "924920"
  },
  {
    "text": "And then finally, individual\ndiscriminations are learned. So when I learned about\nthis, I was at once excited",
    "start": "924920",
    "end": "931370"
  },
  {
    "text": "and also mystified. Because this is sort\nof qualitatively behaving like the way\nthat an infant behaves,",
    "start": "931370",
    "end": "936990"
  },
  {
    "text": "yet it's a really stupid neural\nnetwork with like five layers. Yet I don't understand how\nit's doing this, right?",
    "start": "936990",
    "end": "945020"
  },
  {
    "text": "So I wanted a theory of\nwhat's going on here, right? Oh and by the way,\nyou know, there's",
    "start": "945020",
    "end": "951140"
  },
  {
    "text": "lots of reasons to believe\nthat semantic relationships are encoded in the brain using\nrelatively simple metrics",
    "start": "951140",
    "end": "959180"
  },
  {
    "text": "like Euclidean distance\nbetween neural representations for different objects. So, for example, this\nis a famous study",
    "start": "959180",
    "end": "964250"
  },
  {
    "text": "which I'm sure you've seen. What they showed\nwas a whole bunch of objects to both\nmonkeys and humans.",
    "start": "964250",
    "end": "970160"
  },
  {
    "text": "And they clustered the objects\nor looked at similarity matrix of the objects measured\nusing a Euclidean distance",
    "start": "970160",
    "end": "976370"
  },
  {
    "text": "in neural\nelectrophysiology space, so fine rates of neurons\nhere and voxel activity",
    "start": "976370",
    "end": "982190"
  },
  {
    "text": "patterns in the human. And they showed the same set\nof objects to monkey and human. And the matrices\naligned, essentially.",
    "start": "982190",
    "end": "988040"
  },
  {
    "text": "So basically, the\nsimilarity structure of internal representations\nof both monkey and human is the same. So we tend to encode\nsemantic information using",
    "start": "988040",
    "end": "997449"
  },
  {
    "text": "the similarity representations. So this is the hierarchical\nclustering view. So this sort of seems\nto actually happen",
    "start": "997449",
    "end": "1004210"
  },
  {
    "text": "in real live animals and humans. OK. There's actually something\nelse that happens. It's that different properties\nare learned on different time",
    "start": "1004210",
    "end": "1010950"
  },
  {
    "text": "scales. So, for example, the\nnetwork can learn that canaries can move\nmuch more quickly than it learns that a canary is yellow.",
    "start": "1010950",
    "end": "1018790"
  },
  {
    "text": "So some properties are much\neasier to learn than others. And the properties that are\neasier to learn for the network",
    "start": "1018790",
    "end": "1024849"
  },
  {
    "text": "are also easier to\nlearn for the infant. OK. So these are the theoretical\nquestions we'd like to answer.",
    "start": "1024849",
    "end": "1030679"
  },
  {
    "text": "What are the\nmathematical principles underlying the hierarchical\nself-organization of internal representations\nin the network?",
    "start": "1030680",
    "end": "1037471"
  },
  {
    "text": "You know, this is\na complex system. So what are the relative roles\nof the various ingredients? There's a non-linear\ninput-output response.",
    "start": "1037472",
    "end": "1043220"
  },
  {
    "text": "There's a learning rule,\nwhich is back propagation. There's the input statistics. Is the network somehow reaching\ninto complex input statistics",
    "start": "1043220",
    "end": "1049809"
  },
  {
    "text": "in the training set,\nor can it really rely on just second\norder statistics?",
    "start": "1049810",
    "end": "1056980"
  },
  {
    "text": "You know, what is a mathematical\ndefinition of something called category coherence? And how does it relate to the\nspeed of category learning?",
    "start": "1056980",
    "end": "1062419"
  },
  {
    "text": "So what determines the speed\nat which we learn categories? Why are some properties learned\nmore quickly than others?",
    "start": "1062420",
    "end": "1067570"
  },
  {
    "text": "And how can we explain\nchanging patterns of inductive generalization over\nthese developmental timescales? ",
    "start": "1067570",
    "end": "1076051"
  },
  {
    "text": "OK. So how do we get a theory? Well, it turns out if you\nlook at the activations of this network as it's\ntraining over time,",
    "start": "1076051",
    "end": "1083659"
  },
  {
    "text": "so these are sigmoidal units. And the activations don't\nreally hit the saturating regime that much during\ntraining, because you",
    "start": "1083660",
    "end": "1090070"
  },
  {
    "text": "start from small weights. So we started with\nan audacious proposal that maybe even a linear\nneural network might exhibit",
    "start": "1090070",
    "end": "1096850"
  },
  {
    "text": "this kind of learning dynamics. OK? Now, it's not at all\nobvious that it should, because it's a simple\nlinear neural network.",
    "start": "1096850",
    "end": "1103063"
  },
  {
    "text": "And this learning dynamics\nis highly non-linear, right? But it turns out that even\nin a linear neural network,",
    "start": "1103063",
    "end": "1108850"
  },
  {
    "text": "the dynamics of learning\non synaptic weight space is non-linear. And so there might be a\nhope that it might work",
    "start": "1108850",
    "end": "1114169"
  },
  {
    "text": "and we might be able to\nget a coherent theory. OK. So what we did was we analyzed\njust a simple linear neural",
    "start": "1114170",
    "end": "1119740"
  },
  {
    "text": "network that looks like this\nthat goes from input layer to hidden layer to output layer.",
    "start": "1119740",
    "end": "1125180"
  },
  {
    "text": "So the composite map is linear. OK.",
    "start": "1125180",
    "end": "1130540"
  },
  {
    "text": "So we can write down\ndynamical equations and weight space for the learning dynamic. So this is the training data.",
    "start": "1130540",
    "end": "1136210"
  },
  {
    "text": "And we can adjust the weights\nusing back propagation. And these are the back\npropagation equations. And if we work in a limit\nwhere the learning is slow",
    "start": "1136210",
    "end": "1143350"
  },
  {
    "text": "relative to the time it takes\nto cycle through the data set, you can take a\ncontinuous time limit,",
    "start": "1143350",
    "end": "1149500"
  },
  {
    "text": "and you essentially get a\nnon-linear set of equations in weight space, right? And the equations are cubic\nin the weights, right?",
    "start": "1149500",
    "end": "1156127"
  },
  {
    "text": "And that's because the error is\nquartic in the weights, right? The error is the output minus\nw, w times the inputs squared.",
    "start": "1156127",
    "end": "1163840"
  },
  {
    "text": "So the error is\nquartic in the weights. And so if you can\ndifferentiate the weights on the right-hand side, the\ngradient descent equations",
    "start": "1163840",
    "end": "1170340"
  },
  {
    "text": "will be cubic in the weights. But there is one\nsimplification that happens. Because the network\nis linear, it's",
    "start": "1170340",
    "end": "1177520"
  },
  {
    "text": "learning dynamics is sensitive\nonly to the second order statistics of the data, right?",
    "start": "1177520",
    "end": "1182650"
  },
  {
    "text": "So in particular--\nthe input-input covariance matrix and the\ninput-output covariance matrix.",
    "start": "1182650",
    "end": "1188350"
  },
  {
    "text": "OK. So essentially, this\nnetwork knows only about second order statistics.",
    "start": "1188350",
    "end": "1193390"
  },
  {
    "text": "In our work here, the\ninput statistics is white. So it's really only the\ninput-output statistics that drives learning.",
    "start": "1193390",
    "end": "1199750"
  },
  {
    "text": "OK? So this is a set of coupled\nnon-linear differential equations. They're, in general,\nhard to solve.",
    "start": "1199750",
    "end": "1205360"
  },
  {
    "text": "But we found solutions to them. We can express the solutions\nin terms of the singular value",
    "start": "1205360",
    "end": "1211240"
  },
  {
    "text": "decomposition of the\ninput-output covariance matrix. ",
    "start": "1211240",
    "end": "1217200"
  },
  {
    "text": "You know, any rectangular matrix\nhas a unique singular value decomposition. In this context,\nwe can think about",
    "start": "1217201",
    "end": "1222399"
  },
  {
    "text": "the input-output covariance\nmatrix as a matrix that maps input objects\nto feature attributes.",
    "start": "1222400",
    "end": "1227770"
  },
  {
    "text": "And the singular vectors\nhave an interpretation where these singular vectors\nessentially map objects",
    "start": "1227770",
    "end": "1234250"
  },
  {
    "text": "into internal representations. The singular values\namplify them. And then the columns of you are\nsort of feature synthesizers.",
    "start": "1234250",
    "end": "1241600"
  },
  {
    "text": "The columns are sort of modes\nin the output feature space. OK. So this is the SVD. But the question\nis, how does this",
    "start": "1241600",
    "end": "1250570"
  },
  {
    "text": "drive the learning dynamics? So what we did was we\nfound exact solutions to the learning\ndynamics of this form",
    "start": "1250570",
    "end": "1256919"
  },
  {
    "text": "where the product\nof the layer one to layer two weights and\nthe layer two to layer three weights are of this form.",
    "start": "1256920",
    "end": "1263710"
  },
  {
    "text": "Where, essentially, the\nsystem, what it's doing-- the composite system-- is\nbuilding up the singular value",
    "start": "1263710",
    "end": "1269500"
  },
  {
    "text": "decomposition of the\ninput-output covariance matrix mode by mode. And each mode alpha, associated\nwith singular value alpha",
    "start": "1269500",
    "end": "1276850"
  },
  {
    "text": "in the training data,\nis being learned in the sigmoidal fashion.",
    "start": "1276850",
    "end": "1282770"
  },
  {
    "text": "OK? So at time zero, A is\nsort of small and random,",
    "start": "1282770",
    "end": "1289120"
  },
  {
    "text": "you know, some initial\ncondition A zero. But over time, as time\ntraining time goes to infinity,",
    "start": "1289120",
    "end": "1296950"
  },
  {
    "text": "the A approaches the\nactual singular value in the input-output\ncovariance matrix. So basically, this is\nthe learning dynamic.",
    "start": "1296950",
    "end": "1303600"
  },
  {
    "text": "So nothing happens for a while. And then suddenly, the\nstrongest singular mode defined by the largest\nsingle value gets learned.",
    "start": "1303600",
    "end": "1311620"
  },
  {
    "text": "And then later on, a smaller\nsingular mode gets learned. And later on, an even smaller\nsingular mode gets learned.",
    "start": "1311620",
    "end": "1318100"
  },
  {
    "text": "And the time it takes\nto learn each mode is governed by one over\nthe singular value. So just intuitively, stronger\nstatistical structure",
    "start": "1318100",
    "end": "1325830"
  },
  {
    "text": "as quantified by singular\nvalue is learned first. That's the intuition. Often time when we\ntrain neural networks,",
    "start": "1325830",
    "end": "1332470"
  },
  {
    "text": "we see sort of these\nplateaus in performance where the network does nothing\nand then suddenly drops, plateaus and drops.",
    "start": "1332470",
    "end": "1338522"
  },
  {
    "text": "And this actually shows that. You can see very, very sharp\ntransitions in learning. And you can actually show that\nthe ratio of the transition",
    "start": "1338522",
    "end": "1344980"
  },
  {
    "text": "period to the ignorance period\ncan be arbitrarily small. Infants also seem to show these\ndevelopmental transitions.",
    "start": "1344980",
    "end": "1352510"
  },
  {
    "text": "OK. So, yeah, you can have\narbitrarily sharp transitions in the system.",
    "start": "1352510",
    "end": "1359330"
  },
  {
    "text": "OK. So the take-home messages\nso far is the network learns different modes of\ncovariation between input",
    "start": "1359330",
    "end": "1364720"
  },
  {
    "text": "and output on time scale\ninversely proportional to the statistical strength\nof that covariation. And you can get these sudden\ntransitions in learning.",
    "start": "1364720",
    "end": "1371770"
  },
  {
    "text": "Now the question\nis, what does this have to do with the hierarchical\ndifferentiation of concepts? All right, that's what we'd\nlike to understand first.",
    "start": "1371770",
    "end": "1377580"
  },
  {
    "text": "So now we've come up with a\ngeneral theory of learning, the non-linear\ndynamics of learning in these deep circuits.",
    "start": "1377580",
    "end": "1383710"
  },
  {
    "text": "Now we want to connect this\nback to hierarchical structure. So one of the things\nwith Jay's work is that we're just working\nwith toy data sets.",
    "start": "1383710",
    "end": "1389740"
  },
  {
    "text": "And we didn't have any\ntheoretical control over those toy data sets. But we sort of\nunderstood implicitly that these toy data sets\nhave hierarchical structure.",
    "start": "1389740",
    "end": "1396940"
  },
  {
    "text": "So we need a generative\nmodel of data, a controlled mathematically\nwell-defined generative model of data that encodes\nthe notion of hierarchy.",
    "start": "1396940",
    "end": "1404450"
  },
  {
    "text": "OK? So can we move beyond\nspecific data sets to general principles\nof what happens",
    "start": "1404450",
    "end": "1411312"
  },
  {
    "text": "when a neural network is exposed\nto hierarchical structure? That's what we'd like to answer.",
    "start": "1411312",
    "end": "1416400"
  },
  {
    "text": "So we consider a hierarchical\ngenerative model. And a classic hierarchical\ngenerative model is--",
    "start": "1416400",
    "end": "1421558"
  },
  {
    "text": " yeah, so essentially\nwhat we want to do is we want to connect the\nworld of generative models",
    "start": "1421558",
    "end": "1428290"
  },
  {
    "text": "to the world of neural networks. And, you know, that\nwill connect the methods in computational neuroscience to\nthis course eventually, right?",
    "start": "1428290",
    "end": "1435410"
  },
  {
    "text": " Yeah. So we have data generated\nby some generative model.",
    "start": "1435410",
    "end": "1441370"
  },
  {
    "text": "We take that data, and we\nexpose it to a neural network. And we'd like to understand\nhow the dynamics of learning",
    "start": "1441370",
    "end": "1446440"
  },
  {
    "text": "depends on the parameters\nof the generative model. OK. So a natural generative\nmodel for defining",
    "start": "1446440",
    "end": "1451870"
  },
  {
    "text": "hierarchical structure is a\nbranching diffusion process that essentially mimics the\nprocess of evolution where",
    "start": "1451870",
    "end": "1457630"
  },
  {
    "text": "properties diffuse down a tree\nand instantiate themselves across a set of items. So what do I mean by that?",
    "start": "1457630",
    "end": "1462920"
  },
  {
    "text": "OK. OK. So basically\nimagine, for example, that your items are at the\nleaves of a tree, right?",
    "start": "1462921",
    "end": "1469939"
  },
  {
    "text": "And you can imagine that this\nis a process of evolution where there is some ancestral\nstate maybe for one property.",
    "start": "1469939",
    "end": "1475350"
  },
  {
    "text": "So we do one property at a time. And the properties are\nindependent of each other. This might be an ancestral\nstate like can move, right?",
    "start": "1475350",
    "end": "1483100"
  },
  {
    "text": "And then each time this\nproperty diffuses down the tree, there's a probability\nof flipping, OK?",
    "start": "1483100",
    "end": "1489160"
  },
  {
    "text": "So maybe in this lineage which\nmight correspond to animals, this doesn't flip, right?",
    "start": "1489160",
    "end": "1494940"
  },
  {
    "text": "And in these lineages\ncorresponding to plants, it does flip. So these things cannot move. And these things can move.",
    "start": "1494940",
    "end": "1500140"
  },
  {
    "text": "And then maybe it doesn't flip. So all of these things inherit\nthe property of moving. So these are the animals.",
    "start": "1500140",
    "end": "1505930"
  },
  {
    "text": "And these things cannot move. So these are the plants. And then we do that for every\nsingle property independently.",
    "start": "1505930",
    "end": "1511030"
  },
  {
    "text": "And we generate a set\nof feature vectors. So that's our generative model. So what are the\nstatistical properties",
    "start": "1511030",
    "end": "1516340"
  },
  {
    "text": "of the generative model? So essentially, because\nwe know that we're analyzing these\ndeeper linear networks and we know that the learning\ndynamics of such networks",
    "start": "1516340",
    "end": "1522974"
  },
  {
    "text": "is driven only by the\ninput-output covariance matrix, to understand the\nlearning dynamics we just have to compute the\nsingular values and singular",
    "start": "1522974",
    "end": "1528943"
  },
  {
    "text": "vectors of hierarchically\nstructured data generated in this fashion. And it's actually quite-- I mean, we did it.",
    "start": "1528943",
    "end": "1535151"
  },
  {
    "text": "So here's what happened. So imagine a nice\nsymmetric tree like this. So these are objects. If we look at the similarity\nstructure of objects measured",
    "start": "1535151",
    "end": "1543269"
  },
  {
    "text": "by dot product in the feature\nspace generated by the features under this branching\ndiffusion process, we get this nice blocks within\nblocks similarity structure",
    "start": "1543270",
    "end": "1551280"
  },
  {
    "text": "where all the items\non this branch-- you know this item and this\nitem-- are slightly similar.",
    "start": "1551280",
    "end": "1556890"
  },
  {
    "text": "This item and this item\nare even more similar. And, of course, each item\nis most similar to itself. So you have this\nhierarchical hierarchy",
    "start": "1556890",
    "end": "1562920"
  },
  {
    "text": "of clusters that\nnaturally arise because of this branching\ndiffusion process. So what are the singular\nvalues and singular",
    "start": "1562920",
    "end": "1568260"
  },
  {
    "text": "vectors of the associated\ninput-output covariance matrix? Well, they turn out these are\none set of singular vectors,",
    "start": "1568260",
    "end": "1575310"
  },
  {
    "text": "the so-called object\nanalyzers, which are functions across objects. There's another set\nof singular vectors",
    "start": "1575310",
    "end": "1580560"
  },
  {
    "text": "that are functions\nacross features, which I'm not showing you. But there's, of course,\nthe duality, right?",
    "start": "1580560",
    "end": "1585870"
  },
  {
    "text": "So that you get\npairs of singular vectors for each single value. OK. So what's the singular vector\nassociated with the largest",
    "start": "1585870",
    "end": "1592169"
  },
  {
    "text": "singular value? Well, it's a uniform mode\nthat's constant across all the objects. But the most interesting\none, the next largest one,",
    "start": "1592170",
    "end": "1599940"
  },
  {
    "text": "is the most lowest frequency\nfunction, essentially. It's constant along all the\nancestors of this branch",
    "start": "1599940",
    "end": "1607020"
  },
  {
    "text": "and a different\nconstant along all the ancestors of this branch. So this singular\nvector, essentially, makes the most coarse\ngrain discrimination",
    "start": "1607020",
    "end": "1614760"
  },
  {
    "text": "in this hierarchically\nstructured data set. The next set of\nsingular vectors-- there's a pair of them-- discriminate between this set of\nobjects and this set of objects",
    "start": "1614760",
    "end": "1622410"
  },
  {
    "text": "and don't know about these ones. And the next one discriminates\nbetween this set of objects and this set of objects.",
    "start": "1622410",
    "end": "1627710"
  },
  {
    "text": "And then as you go down to\nthe smaller singular values, you get individual object\ndiscriminations, right?",
    "start": "1627710",
    "end": "1635190"
  },
  {
    "text": "So this is how the\nhierarchical structure is reflected in the second\norder statistics of the data. And these are the\nsingular values.",
    "start": "1635190",
    "end": "1642100"
  },
  {
    "text": "So this is the theory for the\nsingular values in a tree that has five levels of hierarchy.",
    "start": "1642100",
    "end": "1647460"
  },
  {
    "text": "And you can see that the\nsingular values decay with the hierarchy level\nof the singular vectors. OK. So there's a general\ntheory for this",
    "start": "1647460",
    "end": "1653910"
  },
  {
    "text": "in which singular\nvectors are associated with levels of the tree. OK? So now you can see\nthe end of the story.",
    "start": "1653910",
    "end": "1660870"
  },
  {
    "text": "If you put the two\ntogether, you automatically get the results that we were\ntrying to explain, right?",
    "start": "1660870",
    "end": "1666214"
  },
  {
    "text": "So essentially, the\ngeneral theory of learning says that the network\nlearns input-output modes on a time scale given by\n1 over the singular value.",
    "start": "1666214",
    "end": "1673530"
  },
  {
    "text": "When the data is\nhierarchically structured, singular values of broader\nhierarchical distinctions",
    "start": "1673530",
    "end": "1680550"
  },
  {
    "text": "are larger than singular\nvalues of finer distinctions. And the input-output\nmodes correspond exactly to hierarchical\ndistributions of the tree.",
    "start": "1680550",
    "end": "1687250"
  },
  {
    "text": "So that essentially says the\nnetwork must learn broad scale discriminations before\nit can learn fine scale discriminations.",
    "start": "1687250",
    "end": "1692931"
  },
  {
    "text": "So then actually what we did\nwas we just analytically worked out that the dynamics of\nlearning for hierarchically structured data.",
    "start": "1692931",
    "end": "1699026"
  },
  {
    "text": "And we computed the\nmultidimensional scaling. And this was theory. We never did a single\nsimulation to get this plot.",
    "start": "1699026",
    "end": "1705000"
  },
  {
    "text": "We generated a branching\ndiffusion process that was essentially this one. And we just labeled these nodes\narbitrarily with these labels.",
    "start": "1705000",
    "end": "1713820"
  },
  {
    "text": "And this is what we get, right? So we see the\nmultidimensional scaling plot that we sort of see here.",
    "start": "1713820",
    "end": "1719550"
  },
  {
    "text": "And essentially,\njust to compare, this is what was done with\na toy data set over which we had no theoretical control\nand a non-linear neural network",
    "start": "1719550",
    "end": "1726990"
  },
  {
    "text": "over which we had no\ntheoretical control. And this is a well-defined\nmathematical generative model",
    "start": "1726990",
    "end": "1732020"
  },
  {
    "text": "under a linear neural network. And we see that we qualitatively\nexplain the results. So this is the difference\nbetween simulation and theory,",
    "start": "1732020",
    "end": "1739800"
  },
  {
    "text": "right? Now we have a conceptual\nunderstanding of effectively what was going on\nin this circuit.",
    "start": "1739800",
    "end": "1745080"
  },
  {
    "text": "And now, it's no\nlonger a mystery. So now I think I understand\nwhat Jay and collaborators were",
    "start": "1745080",
    "end": "1750990"
  },
  {
    "text": "doing. It would be lovely if, for all\nof the stuff that's going on in this course, we\ncould obtain such",
    "start": "1750990",
    "end": "1757380"
  },
  {
    "text": "a deep rigorous understanding. It's much more challenging. But it's a goal worthy\nof pursuit I think.",
    "start": "1757380",
    "end": "1764771"
  },
  {
    "text": "OK. So conclusions--\nprogressive differentiation",
    "start": "1764771",
    "end": "1770300"
  },
  {
    "text": "of hierarchical structure\nis a general feature of learning in deep\nneural networks. It cannot be any other way.",
    "start": "1770300",
    "end": "1776210"
  },
  {
    "text": "OK? Interestingly enough,\ndeep, but not shallow, networks exhibit such stage-like\ntransitions during learning.",
    "start": "1776210",
    "end": "1782570"
  },
  {
    "text": "So if you just do\nno hidden layers, you don't get this, actually. You need a hidden\nlayer to do this.",
    "start": "1782570",
    "end": "1787730"
  },
  {
    "text": "And somewhat\nsurprisingly, it turns out that even only the\nsecond order statistics",
    "start": "1787730",
    "end": "1793340"
  },
  {
    "text": "of semantic properties provide\npowerful statistical signals that are sufficient to drive\nthis non-linear learning",
    "start": "1793340",
    "end": "1800150"
  },
  {
    "text": "dynamics, right? You don't need to look\nat the higher order statistics of the data\nto get this dynamic.",
    "start": "1800150",
    "end": "1805880"
  },
  {
    "text": "Second order statistics\nsuffice, which was not obvious before we started. OK.",
    "start": "1805880",
    "end": "1811220"
  },
  {
    "text": "So in ongoing work,\nwe can explain a whole bunch of things,\nlike illusory correlations early in learning.",
    "start": "1811220",
    "end": "1816390"
  },
  {
    "text": "So, for example,\ninfants, they don't even",
    "start": "1816390",
    "end": "1822410"
  },
  {
    "text": "know that, for example, pine\ntrees don't have leaves. Then at an intermediate\npoint, they",
    "start": "1822410",
    "end": "1827510"
  },
  {
    "text": "think that pine\ntrees have leaves. And then at a later\npoint, they correctly know that pine trees don't\nhave leaves, right?",
    "start": "1827510",
    "end": "1835910"
  },
  {
    "text": "So we can explain these\nnon-monotonic learning curves. We can explain these familiarity\nand typicality effects.",
    "start": "1835910",
    "end": "1841190"
  },
  {
    "text": "We can explain inductive\nproperty judgments analytically. We're looking at\nbasic level effects.",
    "start": "1841190",
    "end": "1846500"
  },
  {
    "text": "We have a theory of category\ncoherence, and so on. But in the interest\nof moving forward, I wanted to give short\nshrift to this stuff.",
    "start": "1846500",
    "end": "1853419"
  },
  {
    "text": "And essentially, we\ncan answer why are some properties learned faster? Basically, properties\nthat are low frequency",
    "start": "1853420",
    "end": "1860990"
  },
  {
    "text": "properties on the leaves of\nthe tree get learned faster. Properties whose inner\nproduct with the singular",
    "start": "1860990",
    "end": "1866570"
  },
  {
    "text": "vector as a larger singular\nvalue get learned faster. That's the story. Why are some items more typical?",
    "start": "1866570",
    "end": "1871840"
  },
  {
    "text": "We have a theory for that. How is inductive generalization\nachieved by neural networks? We have a theory\nfor that and so on.",
    "start": "1871840",
    "end": "1879170"
  },
  {
    "text": "And, you know, what is a\nuseful mathematical definition of category coherence? So, for example, you know,\nthere are some things",
    "start": "1879170",
    "end": "1885500"
  },
  {
    "text": "that are just intuitively\ncalled incoherent categories. \"The set of all things are blue\"\nis a very incoherent category.",
    "start": "1885500",
    "end": "1890520"
  },
  {
    "text": "In fact, it's so\nincoherent we don't have a name for such a category. \"The set of all\nthings that are dogs\" seems to be a very\ncoherent category.",
    "start": "1890520",
    "end": "1896490"
  },
  {
    "text": "And it's so coherent that we\nhave a well-known name for it. The name's quite\nshort actually, too. Actually, I wonder if\nthere's a theory where",
    "start": "1896490",
    "end": "1905780"
  },
  {
    "text": "shorter words correspond\nto more coherent categories and that's like an informative\nor efficient representation",
    "start": "1905780",
    "end": "1911244"
  },
  {
    "text": "of category structure. But anyways, we have a natural\ndefinition of coherent category that's precise enough\nto prove a theorem",
    "start": "1911244",
    "end": "1917990"
  },
  {
    "text": "that coherent categories\nare learned faster. And actually, this also relates\nto the size of the categories.",
    "start": "1917990",
    "end": "1923580"
  },
  {
    "text": "So frequency effects show up. Anyways, so there's\na lot of stuff there. But that was sort\nof the entry point.",
    "start": "1923580",
    "end": "1929550"
  },
  {
    "text": "So now, what about\na theory of learning in much deeper networks\nthat have many, many layers? OK?",
    "start": "1929550",
    "end": "1935100"
  },
  {
    "text": "So, again, I'm going to\nmake a long story short, because it's all published. So you can read all the details.",
    "start": "1935100",
    "end": "1941000"
  },
  {
    "text": "But I wanted to give you\nthe spirit or the essence or the intuition\nbehind the work. OK.",
    "start": "1941000",
    "end": "1946490"
  },
  {
    "text": "So the questions we'd\nlike to answer are, how does training\ntime scale with depth?",
    "start": "1946490",
    "end": "1952730"
  },
  {
    "text": "How should learning\nrate scale with depth? How do different\nweight initializations impact learning speed?",
    "start": "1952730",
    "end": "1958090"
  },
  {
    "text": "And what we'll do is once we\nunderstand these theoretically, we'll find certain\nweight initializations that correspond to critical\ndynamics, which I'll define,",
    "start": "1958090",
    "end": "1965419"
  },
  {
    "text": "can aid deep learning\nand generalization. So the basic idea is in a\nvery, very deep neural network,",
    "start": "1965420",
    "end": "1971150"
  },
  {
    "text": "right, you have a vanishing,\nexploding, or gradient problem. And that's one of\nthe issues that",
    "start": "1971150",
    "end": "1976250"
  },
  {
    "text": "makes deep neural\nnetwork learning hard. So if you're going\nto back propagate the error through\nmultiple layers,",
    "start": "1976250",
    "end": "1982070"
  },
  {
    "text": "the back propagation\noperation is a product of Jacobians\nfrom layer to layer. And that product of\nJacobians is fundamentally",
    "start": "1982070",
    "end": "1988370"
  },
  {
    "text": "a linear mapping, right? So if the singular\nvalues associated with that linear mapping--",
    "start": "1988370",
    "end": "1994260"
  },
  {
    "text": "so essentially, if\nthe singular values of the Jacobian in each layer\nare large, bigger than one,",
    "start": "1994260",
    "end": "1999490"
  },
  {
    "text": "the product of\nsuch matrices will lead to a product matrix\nthat has singular values that grow exponentially with depth.",
    "start": "1999490",
    "end": "2006260"
  },
  {
    "text": "Similarly, if the single\nvalues are less than one, they'll decay with depth, right? So that's a vanishing\ngradient in the latter case",
    "start": "2006260",
    "end": "2013840"
  },
  {
    "text": "and an exploding gradient\nin the former case. That seems to be one of\nthe major impediments to understanding deep learning.",
    "start": "2013840",
    "end": "2019880"
  },
  {
    "text": "So what people\noften did was they tried to scale the matrices\nto avoid this question, right?",
    "start": "2019880",
    "end": "2025600"
  },
  {
    "text": "So what they often do is they\ninitialize the weights randomly",
    "start": "2025600",
    "end": "2030910"
  },
  {
    "text": "so that W is a random\nmatrix where the elements W, I, J, are IID and Gaussian with\na scale factor scaled precisely",
    "start": "2030910",
    "end": "2040450"
  },
  {
    "text": "so that the largest\neigenvalue of the Jacobian or the back propagation\noperator is one.",
    "start": "2040450",
    "end": "2045640"
  },
  {
    "text": "OK? So that's like\nscaling the system so that if you place a random\nerror vector here, the desired",
    "start": "2045640",
    "end": "2052690"
  },
  {
    "text": "output minus the actual\noutput, and back propagate it through a random\nnetwork, a error vector",
    "start": "2052690",
    "end": "2059727"
  },
  {
    "text": "will preserve its norm as\nit's back propagated across. And this is the famous\nsort of Glorot and Bengio",
    "start": "2059727",
    "end": "2066730"
  },
  {
    "text": "initialization. And it works pretty well for\ndepth four or five or whatever,",
    "start": "2066730",
    "end": "2072290"
  },
  {
    "text": "right? OK. So we would like a theory\nof that for the learning",
    "start": "2072290",
    "end": "2079292"
  },
  {
    "text": "dynamics of that. And as I said, there's no\nhope for a complete theory at the moment with\narbitrary non-linearities.",
    "start": "2079292",
    "end": "2085949"
  },
  {
    "text": "OK. So what we're going\nto do is we're to analyze the\nlearning dynamics. Just-- we'll get rid of\nthe non-linearities, right?",
    "start": "2085949",
    "end": "2092054"
  },
  {
    "text": "So, again, it might seem like\nwe're throwing the baby out with the bathwater,\nbut we're actually going to learn\nsomething that helps us",
    "start": "2092054",
    "end": "2097273"
  },
  {
    "text": "to train non-linear networks. OK. So the basic idea\nthen is that we have a network which is linear.",
    "start": "2097273",
    "end": "2103670"
  },
  {
    "text": "So y, the output, is a\nproduct of weights, right?",
    "start": "2103670",
    "end": "2109201"
  },
  {
    "text": "OK. So then the back propagation's,\nagain, just a product of matrices, right?",
    "start": "2109201",
    "end": "2114920"
  },
  {
    "text": "The gradient dynamics\nis non-linear and coupled and non-convex. And actually even in\nthis linear network,",
    "start": "2114920",
    "end": "2121670"
  },
  {
    "text": "you see plateaus and\nsudden transitions, right? And actually,\ninterestingly enough,",
    "start": "2121670",
    "end": "2126870"
  },
  {
    "text": "even in this very\ndeep linear network, you see faster conversions from\npre-trained initial conditions,",
    "start": "2126870",
    "end": "2132029"
  },
  {
    "text": "right? So basically, if you\nstart from random Gaussian initial conditions, you get\nslow learning for a while",
    "start": "2132030",
    "end": "2137570"
  },
  {
    "text": "and then sudden learning\nhere, relatively sudden learning here. Whereas, if you're\npre-train the network using",
    "start": "2137570",
    "end": "2143720"
  },
  {
    "text": "greedy unsupervised\nlearning, so this is the time it takes to pre-train, you\nget sudden learning and a drop",
    "start": "2143720",
    "end": "2150101"
  },
  {
    "text": "here. So remember, if you go back\nto the original Hinton paper, this was the phenomenon\nthat started deep learning.",
    "start": "2150101",
    "end": "2155840"
  },
  {
    "text": "Greedy unsupervised\npre-training allows you to rapidly train very,\nvery deep neural networks.",
    "start": "2155840",
    "end": "2161119"
  },
  {
    "text": "So the very empirical\nphenomenon that led to the genesis\nof deep learning was present already in deep\nlinear neural networks, right?",
    "start": "2161120",
    "end": "2169460"
  },
  {
    "text": "So deep linear neural\nnetworks, in terms of their expressive\npower, are crappy. Because the composition of\nlinear operations is linear.",
    "start": "2169460",
    "end": "2176672"
  },
  {
    "text": "They're not a good model\nfor deep non-linear networks in terms of\ninput-output mappings. But they're a surprisingly good\nmodel, theoretical toy model,",
    "start": "2176672",
    "end": "2184220"
  },
  {
    "text": "for modeling the\ndynamics of learning in non-linear networks. OK? Because very important\nphenomena also",
    "start": "2184220",
    "end": "2190580"
  },
  {
    "text": "arise in the deep\nlinear networks. And we're focusing on\nlearning dynamics here. OK.",
    "start": "2190580",
    "end": "2196070"
  },
  {
    "text": "So we can build intuitions\nfor the non-linear case by analyzing the linear case. OK? So we went through the three\nlayer dynamics already.",
    "start": "2196070",
    "end": "2203210"
  },
  {
    "text": "What about the multiple\nlayer dynamics? So, again, the Jacobian can back\npropagate or explode, right?",
    "start": "2203210",
    "end": "2210030"
  },
  {
    "text": "OK. So, again, I'm going to\nmake a long story short. But what we find is\nthat if you take--",
    "start": "2210030",
    "end": "2215150"
  },
  {
    "text": " OK, I'll tell you\nthe final result.",
    "start": "2215150",
    "end": "2220470"
  },
  {
    "text": "What we find is that we find a\nclass of weight initializations that allow learning\ntime to remain constant",
    "start": "2220470",
    "end": "2228470"
  },
  {
    "text": "as the depth of the\nnetwork goes to infinity. Now, I'm measuring learning time\nin units of learning epochs,",
    "start": "2228470",
    "end": "2234400"
  },
  {
    "text": "right? So, obviously, to train a deep\nneural network, very, very deep neural network, it\njust takes longer to compute each gradient, right?",
    "start": "2234400",
    "end": "2241220"
  },
  {
    "text": "So in terms of real\ntime, of course, the time will scale with\nthe depth of the network. But you might imagine\nin terms of number",
    "start": "2241220",
    "end": "2247579"
  },
  {
    "text": "of gradient evaluations, as the\nnetwork gets deeper and deeper, it might take longer\nand longer to train it.",
    "start": "2247580",
    "end": "2253339"
  },
  {
    "text": "And we show a class\nof initial conditions for which that's not true. As the network gets\ndeeper and deeper,",
    "start": "2253340",
    "end": "2260720"
  },
  {
    "text": "the number of\ngradient evaluations you need to train the\nnetwork can remain constant even as the depth\ngoes to infinity even",
    "start": "2260720",
    "end": "2269330"
  },
  {
    "text": "in a non-linear network. OK. So let me give you\nintuition for why. ",
    "start": "2269330",
    "end": "2276820"
  },
  {
    "text": "OK. So, for example, in the\nclassical initialization,",
    "start": "2276820",
    "end": "2283550"
  },
  {
    "text": "this Glorot and\nBengio initialization doesn't have that. But our initialization does. So basically what we did was--",
    "start": "2283550",
    "end": "2290306"
  },
  {
    "text": "we'll start off with\na linear networks. We trained deep linear\nnetworks on MNIST. And we scaled that\ndepth like this, right?",
    "start": "2290306",
    "end": "2297480"
  },
  {
    "text": "And we started with random\nGaussian initial conditions and then ran back\npropagation, but scaled random Gaussian initializations.",
    "start": "2297480",
    "end": "2305819"
  },
  {
    "text": "And we found that the training\ntime, as you might expect, grew with depth. This is training time\nmeasured in number of learning epochs or number\nof gradient evaluations.",
    "start": "2305820",
    "end": "2314280"
  },
  {
    "text": "But here what we did\nwas we initialized the weights using random\northogonal weights, right?",
    "start": "2314280",
    "end": "2319680"
  },
  {
    "text": "And then we found\nthat the learning time didn't grow with depth. And also, if you pre-train it,\nit doesn't grow with depth.",
    "start": "2319680",
    "end": "2325930"
  },
  {
    "text": "OK. So there's a dramatically\ndifferent scaling and learning time between random\nGaussian initialization",
    "start": "2325930",
    "end": "2331260"
  },
  {
    "text": "and random orthogonal\ninitialization. Why? OK? And the answer is the following.",
    "start": "2331260",
    "end": "2337890"
  },
  {
    "text": "Let's think about the\nback propagation operator. Let's say you want to\nback propagate errors from the output to the input.",
    "start": "2337890",
    "end": "2344440"
  },
  {
    "text": "So the back propagation\noperator in a linear network is just the product of weights\nthroughout the entire network.",
    "start": "2344440",
    "end": "2351341"
  },
  {
    "text": "OK?  So if you do a random Gaussian\nweight initialization here,",
    "start": "2351341",
    "end": "2359240"
  },
  {
    "text": "then this is a product of\nrandom Gaussian matrices. So to understand the statistical\nproperties of back propagation,",
    "start": "2359240",
    "end": "2366990"
  },
  {
    "text": "you need to understand\nthe statistical properties of the singular value spectrum\nof random Gaussian matrices.",
    "start": "2366990",
    "end": "2372446"
  },
  {
    "text": "There isn't really a\ngeneral theory for that, but we can look at it\nnumerically and get intuition for it. So the basic idea is if you\nhave one random Gaussian",
    "start": "2372446",
    "end": "2379530"
  },
  {
    "text": "matrix, the singular values\nof W are the eigenvalues of W",
    "start": "2379530",
    "end": "2384930"
  },
  {
    "text": "transpose W. That's a\nfamous distribution called the Marchenko-Pastur\ndistribution. And you know, they vary in\na range that's order one.",
    "start": "2384930",
    "end": "2392940"
  },
  {
    "text": "OK? So if you back propagate\nthrough one layer, you're fine. You don't get vanishing\nexponent gradients.",
    "start": "2392940",
    "end": "2399700"
  },
  {
    "text": "OK. But if you look at the singular\nvalues of a product of five",
    "start": "2399700",
    "end": "2406900"
  },
  {
    "text": "random Gaussian matrices,\nthe singular value spectrum gets very distorted. You've got a large\nnumber of similar values",
    "start": "2406900",
    "end": "2412420"
  },
  {
    "text": "that are close to zero and\na long tail that, you know, extends up to four.",
    "start": "2412420",
    "end": "2417619"
  },
  {
    "text": "OK. But if you do 100 layers, you\nget a very, very large number of singular values\nthat are close to zero",
    "start": "2417620",
    "end": "2424120"
  },
  {
    "text": "and very much longer tail. OK? Now, this is a product of\nrandom Gaussian matrices.",
    "start": "2424120",
    "end": "2431040"
  },
  {
    "text": "So if you feed a random\nvector into this, on average, it's norm will be preserved.",
    "start": "2431040",
    "end": "2436460"
  },
  {
    "text": "The vector's length\nwill not change. But we know that preserving\nthe length of a vector",
    "start": "2436460",
    "end": "2441640"
  },
  {
    "text": "is not the same as\npreserving angles between all pairs of vectors. OK. So actually, the way that this\nproduct of random Gaussian",
    "start": "2441640",
    "end": "2449589"
  },
  {
    "text": "matrices preserves the\nnorm of the gradient is it does it in a\nvery anisotropic way.",
    "start": "2449590",
    "end": "2455559"
  },
  {
    "text": "It takes an error\nvector at the output, and it projects it into\na low dimensional space",
    "start": "2455560",
    "end": "2461410"
  },
  {
    "text": "corresponding to the singular\nvalues that are large. And then it amplifies\nit in that space.",
    "start": "2461410",
    "end": "2466420"
  },
  {
    "text": "So the length is preserved,\nbut all error vectors get projected onto a\nlow-dimensional space and amplified.",
    "start": "2466420",
    "end": "2471500"
  },
  {
    "text": "So a lot of error information\nis lost in a product of random Gaussian matrices. OK.",
    "start": "2471500",
    "end": "2477369"
  },
  {
    "text": "So that's why the Glorot and\nBengio initial conditions work well up to five or\nsix or seven, but they",
    "start": "2477370",
    "end": "2483130"
  },
  {
    "text": "don't work well up\nto depth, say, 100 or in recurrent neural\nnetworks as well. OK?",
    "start": "2483130",
    "end": "2489400"
  },
  {
    "text": "So what can we do? Well, a simple\nthing we can do is we can replace the matrices,\nthese random matrices,",
    "start": "2489400",
    "end": "2495400"
  },
  {
    "text": "with orthogonal matrices. OK? So we know that all the singular\nvalues of an orthogonal matrix are one, every single one.",
    "start": "2495400",
    "end": "2501550"
  },
  {
    "text": "And the product of orthogonal\nmatrices is orthogonal. So therefore, the back\npropagation operator has all of its singular\nvalues equal to one.",
    "start": "2501550",
    "end": "2508930"
  },
  {
    "text": "And there's generalizations\nof orthogonal matrices to rectangular versions\nwhen the layers",
    "start": "2508930",
    "end": "2513940"
  },
  {
    "text": "don't have the same number\nof neurons in each layer. OK? So this is fantastic. So this works really\nwell for linear networks.",
    "start": "2513940",
    "end": "2520630"
  },
  {
    "text": "OK. But how does this generalize\nto non-linear networks? Because then you have a\nproduct of Jacobians, right?",
    "start": "2520630",
    "end": "2527020"
  },
  {
    "text": "So what happens here? OK. So what is the\nproduct of Jacobian? ",
    "start": "2527020",
    "end": "2535010"
  },
  {
    "text": "OK. So if we imagine how\neither errors back propagate to the front or\nhow input perturbations back",
    "start": "2535010",
    "end": "2542860"
  },
  {
    "text": "propagate to the end,\nit's the same thing. So it's easier to think\nabout forward propagation.",
    "start": "2542860",
    "end": "2549401"
  },
  {
    "text": "Imagine that you have an input\nand you perturb it slightly. How does the perturbation\ngrow or decay? Well, what happens is there's a\nlinear expansion or contraction",
    "start": "2549402",
    "end": "2557200"
  },
  {
    "text": "due to W. And then this nominator\nis usually compressive. So there's a\nnon-linear compression",
    "start": "2557200",
    "end": "2562900"
  },
  {
    "text": "due the diagonal Jacobian\npassing through the point y's non-linearity. And then, again, linear\nmodification and non-linear",
    "start": "2562900",
    "end": "2569625"
  },
  {
    "text": "compression, linear\nmodification, and non-linear compression. OK? So what we could do is just\nsimply choose these again",
    "start": "2569625",
    "end": "2576220"
  },
  {
    "text": "to be random\northogonal matrices. And then what happens\nis the growth or decay",
    "start": "2576220",
    "end": "2581319"
  },
  {
    "text": "of perturbations-- and we scale\nthe random orthogonal matrices",
    "start": "2581320",
    "end": "2587140"
  },
  {
    "text": "by a scale factor to combat\nthe non-linear compression. And then the dynamics of\nperturbations is like this.",
    "start": "2587140",
    "end": "2593350"
  },
  {
    "text": "You rotate, linearly scale,\nnon-linearly compress, rotate, linearly scale, non-linearly\ncompress, and so on.",
    "start": "2593350",
    "end": "2600520"
  },
  {
    "text": "That's essentially\nthe type of dynamics that occurs in dynamically\ncritical systems that",
    "start": "2600520",
    "end": "2606849"
  },
  {
    "text": "are close to the edge of chaos. You get this alternating phase\nspace expansion and compression",
    "start": "2606850",
    "end": "2612140"
  },
  {
    "text": "that's in different\ndimensions at different times. OK? So now you can just\ncompute numerically",
    "start": "2612140",
    "end": "2617530"
  },
  {
    "text": "under that initialization. How does the singular\nvalue spectrum of the product of\nJacobian scale?",
    "start": "2617530",
    "end": "2623590"
  },
  {
    "text": "And it scales beautifully. So this is the scale factor\nfor the type of non-linearity that we use, the hyperbolic\ntangent non-linearity.",
    "start": "2623590",
    "end": "2630370"
  },
  {
    "text": "The optimal scale\nfactor in front of the random orthogonal\nmatrix is one. And you see when\nyou choose that--",
    "start": "2630370",
    "end": "2635830"
  },
  {
    "text": " this was 100 layers, I believe-- even for 100 layers,\nthat end to end Jacobian",
    "start": "2635830",
    "end": "2643134"
  },
  {
    "text": "and from the input to output\nhas a singular value spectrum that remains within\nthe range of order one. If g is even slightly\nless than one,",
    "start": "2643134",
    "end": "2650270"
  },
  {
    "text": "the singular values\nexponentially vanish with depth. If g is larger than\none, the singular values grow, but actually not\nas quickly as you'd think.",
    "start": "2650270",
    "end": "2659160"
  },
  {
    "text": "So this is the critically\ndynamical regime that at least preserves\nnot only the norm",
    "start": "2659160",
    "end": "2664569"
  },
  {
    "text": "of back propagated\ngradients, but all angles between pairs of\ngradients, right? So it's an isotropic\npreservation",
    "start": "2664570",
    "end": "2672700"
  },
  {
    "text": "of error information from\nthe end of the network all the way to the beginning. OK? So does it work?",
    "start": "2672700",
    "end": "2678130"
  },
  {
    "text": "And it works better than\nother initializations even in non-linear networks. So we trained 30 layer\nnon-linear networks.",
    "start": "2678130",
    "end": "2685960"
  },
  {
    "text": "And the initialization\nworks better. And so also, interestingly\nenough, at this critical factor",
    "start": "2685960",
    "end": "2694010"
  },
  {
    "text": "you also achieve better\ngeneralization error. And we don't have a good\ntheory for that actually.",
    "start": "2694010",
    "end": "2699250"
  },
  {
    "text": "The test error and the training\nerror, of course, goes down.",
    "start": "2699250",
    "end": "2706780"
  },
  {
    "text": "OK. So that's an\ninteresting situation where a theory of\nlinear networks led to a practical\ntraining advantage",
    "start": "2706780",
    "end": "2712120"
  },
  {
    "text": "from non-linear networks. OK. So here's another\nquestion that we had.",
    "start": "2712120",
    "end": "2717280"
  },
  {
    "text": "OK? There's a whole world\nof convex optimization. We want our machine\nlearning algorithms",
    "start": "2717280",
    "end": "2723360"
  },
  {
    "text": "to correspond to\nconvex optimization, so we can find the\nglobal minimum. And there are no local\nminima to impede us",
    "start": "2723360",
    "end": "2728550"
  },
  {
    "text": "from finding the\nglobal minimum, right? That's conventional wisdom. Yet the deep neural\nnetwork people",
    "start": "2728550",
    "end": "2734275"
  },
  {
    "text": "ignore this conventional wisdom\nand train very, very deep neural networks and don't worry\nabout the potential impediments",
    "start": "2734275",
    "end": "2739650"
  },
  {
    "text": "to the local minima. They seem to find pretty\ngood solutions why. OK?",
    "start": "2739650",
    "end": "2745080"
  },
  {
    "text": "Is the intuition\nthat local minima are really an impediment\nto non-linear non-convex",
    "start": "2745080",
    "end": "2750540"
  },
  {
    "text": "optimization in high\ndimensional spaces really true? OK? And you might\nthink that it's not",
    "start": "2750540",
    "end": "2757080"
  },
  {
    "text": "true for the following\nintuitive reason, right? So, again, it's often\nthought that local minima, at some high level of\nerror and training error,",
    "start": "2757080",
    "end": "2764520"
  },
  {
    "text": "stand as a major impediment\nto non-convex optimization. And, you know, this\nis an example--",
    "start": "2764520",
    "end": "2770040"
  },
  {
    "text": "a two-dimensional caricature\nof a protein folding energy landscape. And it's very rough, so there's\nmany, many local minima.",
    "start": "2770040",
    "end": "2776060"
  },
  {
    "text": "And the global minima\nmight be hard to find. And that's true. If you sort of draw\nrandom generic surfaces",
    "start": "2776060",
    "end": "2781230"
  },
  {
    "text": "over low dimensions,\nthose random surfaces will have many local minima. But, of course, our\nintuition about geometry",
    "start": "2781230",
    "end": "2787320"
  },
  {
    "text": "derived from our experience\nwith a low-dimensional world is woefully inadequate for\nthinking about geometry",
    "start": "2787320",
    "end": "2792359"
  },
  {
    "text": "in high-dimensional spaces. So it turns out that random\nnon-convex error functions",
    "start": "2792360",
    "end": "2798690"
  },
  {
    "text": "over high-dimensional\nspaces, local minima are sort of exponentially\nrare in the dimensionality",
    "start": "2798690",
    "end": "2803910"
  },
  {
    "text": "relative to saddle points. Just intuitively,\nimagine you have an error function over 1,000 variables,\nsay 1,000 synaptic weights",
    "start": "2803910",
    "end": "2810210"
  },
  {
    "text": "in a deep network. That's a small, deep network. But anyways, let's say there's\na point at which the gradient",
    "start": "2810210",
    "end": "2815760"
  },
  {
    "text": "and weight space vanishes. So now there's 1,000\ndirections in weight space you could move away\nfrom that extreme.",
    "start": "2815760",
    "end": "2822300"
  },
  {
    "text": "What are the chances that\nevery single direction you move has positive curvature, right?",
    "start": "2822300",
    "end": "2828330"
  },
  {
    "text": "If it's a fairly\ngeneric landscape, the answer is exponentially\nsmall in the dimensionality. Some directions will\nhave negative curvature.",
    "start": "2828330",
    "end": "2834690"
  },
  {
    "text": "Some directions will\nhave positive curvature, unless your critical point\nis already at the bottom. In that case, most directions\nwill have positive curvature.",
    "start": "2834690",
    "end": "2842010"
  },
  {
    "text": "Or unless your critical\npoint is at the top higher, then most directions will have\nnegative curvature, right?",
    "start": "2842010",
    "end": "2847170"
  },
  {
    "text": "So statistical physicists\nhave made this intuition very precise for random landscapes.",
    "start": "2847170",
    "end": "2853890"
  },
  {
    "text": "And they've developed\na theory for it. So this is a paper\nin Physical Review Letters by Bray and Dean.",
    "start": "2853890",
    "end": "2859290"
  },
  {
    "text": "So what they did\nwas they imagined just a random Gaussian\nerror landscape. So what they did was they looked\nat an error landscape that's",
    "start": "2859290",
    "end": "2867360"
  },
  {
    "text": "a continuous function\nover n dimensions, but there is correlations. It's correlated over\nsome length scale.",
    "start": "2867360",
    "end": "2873540"
  },
  {
    "text": "So it's a single draw from a\nrandom Gaussian process where the kernel of the\nGaussian process",
    "start": "2873540",
    "end": "2880140"
  },
  {
    "text": "is falling off with\nsome length scale. So the error at 0.1 is\ncorrelated with the error at 0.2 over some length scale.",
    "start": "2880140",
    "end": "2886530"
  },
  {
    "text": "And that correlation\nfalls off smoothly. So it's a random\nsmooth landscape. OK. So the correlations\nare local, essentially.",
    "start": "2886530",
    "end": "2893560"
  },
  {
    "text": "And then what they did was they\nasked the following question. Let x be a critical\npoint, a point where",
    "start": "2893560",
    "end": "2898650"
  },
  {
    "text": "the gradient vanishes. OK? We can plot every\nsingle critical point in a two-dimensional\nfeature space.",
    "start": "2898650",
    "end": "2904500"
  },
  {
    "text": "What is that feature space? Well, the horizontal\naxis is the error level of the critical point. At how high on the error axis\ndoes this critical point sit?",
    "start": "2904500",
    "end": "2912660"
  },
  {
    "text": "And then this f is the fraction\nof negative eigenvalues of the Hessian at\nthat critical point.",
    "start": "2912660",
    "end": "2918190"
  },
  {
    "text": "So it's the fraction\nof directions that curve downwards.",
    "start": "2918190",
    "end": "2923280"
  },
  {
    "text": "OK. So now a priori, critical\npoints could potentially set anywhere in this\ntwo-dimensional feature space,",
    "start": "2923280",
    "end": "2929820"
  },
  {
    "text": "right? It turns out they don't. They concentrate on a\nmonotonically increasing",
    "start": "2929820",
    "end": "2935549"
  },
  {
    "text": "curve that looks like this. So the higher the error\nlevel of the critical point, the more the negative\ncurvature directions you have.",
    "start": "2935550",
    "end": "2943050"
  },
  {
    "text": "OK? And to be an order one\ndistance away from this curve, the probability\nof that happening is exponentially small in the\ndimensionality of the problem.",
    "start": "2943050",
    "end": "2951509"
  },
  {
    "text": "OK? Now, what does that mean? It automatically\nimplies that there are no local minima\nat high error,",
    "start": "2951510",
    "end": "2957990"
  },
  {
    "text": "or at least they're\nexponentially rare relative to saddle\npoints of a given index. OK? So basically, you typically\nnever encounter local minima",
    "start": "2957990",
    "end": "2965470"
  },
  {
    "text": "at height error, right? That would be stuff\nthat sits here. And there's nothing here.",
    "start": "2965470",
    "end": "2970710"
  },
  {
    "text": "OK? Second, if you are a\nlocal minimum, which means on this axis\nyou're at the bottom,",
    "start": "2970710",
    "end": "2976560"
  },
  {
    "text": "then your error level\nmust be very, very close to the global minimum. OK?",
    "start": "2976560",
    "end": "2981660"
  },
  {
    "text": "So if you get stuck\nin a local minimum, you're already close in\nerror to the global minimum.",
    "start": "2981660",
    "end": "2986850"
  },
  {
    "text": "AUDIENCE: Can you repeat\nthis last element? SURYA GANGULI: Yeah. So if you're a local\nminimum, your error level will be close to the error\nlevel the global minimum.",
    "start": "2986850",
    "end": "2993600"
  },
  {
    "text": "AUDIENCE: Why? SURYA GANGULI: Because what does\nit mean to be a local minimum? It means that f is zero.",
    "start": "2993600",
    "end": "2998864"
  },
  {
    "text": "The fraction of negative\ncurvature eigenvalues of the Hessian is zero. And this is the\ndistribution of error levels",
    "start": "2998864",
    "end": "3004240"
  },
  {
    "text": "of such critical points. They're strongly\npeaked at this value, which is the value of\nthe global minimum.",
    "start": "3004240",
    "end": "3009700"
  },
  {
    "text": "Essentially, there's\nnothing out here. OK? All right, now in physics there\nis this well-known principle",
    "start": "3009700",
    "end": "3017440"
  },
  {
    "text": "called universality. There are certain\nquestions whose answers don't depend on the details.",
    "start": "3017440",
    "end": "3023210"
  },
  {
    "text": "For example, certain\ncritical exponents in the liquid-gas\nphase transition are exactly the same\nas critical exponents",
    "start": "3023210",
    "end": "3029290"
  },
  {
    "text": "in the ferromagnetic\nphase transition. Because the symmetry\nand dimensionality of the order parameter\ndensity in the case",
    "start": "3029290",
    "end": "3035380"
  },
  {
    "text": "of liquid and magnetization\nin the case of ferromagnets are the same. So there's certain\nquestions whose answers",
    "start": "3035380",
    "end": "3041200"
  },
  {
    "text": "don't depend on the detail. They only depend on the\nsymmetry and dimensionality of the problem. So one might think that\nthis qualitative prediction",
    "start": "3041200",
    "end": "3048520"
  },
  {
    "text": "is true in just generic\nhigh-dimensional landscapes. Now, the computer scientists\nwould say, no, no, no, no, no,",
    "start": "3048520",
    "end": "3055240"
  },
  {
    "text": "no. Your random landscapes are a\nhorrible model for our error landscapes of deep\nneural networks",
    "start": "3055240",
    "end": "3060730"
  },
  {
    "text": "trained on MNIST and CIFAR-10\nand so on and so forth. You're completely\nirrelevant to us,",
    "start": "3060730",
    "end": "3066137"
  },
  {
    "text": "because we're doing\nsomething special. We're not doing\nsomething random. We have a lot of structure. OK.",
    "start": "3066137",
    "end": "3071160"
  },
  {
    "text": "The physicists might\ncounter, well, you know, you just have a\nhigh-dimensional problem. The basic intuition\nthat in high dimensions",
    "start": "3071160",
    "end": "3077260"
  },
  {
    "text": "it's very hard to have\nall directions curve up at a critical point\nhigh error should also hold true in your problem.",
    "start": "3077260",
    "end": "3082780"
  },
  {
    "text": "OK? But, of course, we'll\nnever get anywhere if we stop there, right? We have to move over into your\nland which is also my land",
    "start": "3082780",
    "end": "3089570"
  },
  {
    "text": "and just simulate the system. So oftentimes, you know,\nbiologists and computer scientists don't\nbelieve a theory",
    "start": "3089570",
    "end": "3095554"
  },
  {
    "text": "until they see the simulation. So what we'll do is we'll\nsearch for critical points",
    "start": "3095554",
    "end": "3100960"
  },
  {
    "text": "in the error landscape\nof deep neural networks. And that's what we did. So what we did was we\nused Newton's method",
    "start": "3100960",
    "end": "3108850"
  },
  {
    "text": "to find critical points. So it turns out\nthat Newton's method is attracted to saddles, right? So Newton's method will descend\nin the positive curvature",
    "start": "3108850",
    "end": "3116500"
  },
  {
    "text": "direction. But it will ascend in the\nnegative curvature direction. Because Newton's method is\ngradient descent multiplied",
    "start": "3116500",
    "end": "3123490"
  },
  {
    "text": "by the inverse of the Hessian. So if the Hessian has\na negative eigenvalue, you take a negative\ngradient and multiply it",
    "start": "3123490",
    "end": "3129980"
  },
  {
    "text": "by the negative eigenvalue,\nand you turn back around and you go uphill. So Newton's method uncorrected\nis attracted to saddle points.",
    "start": "3129980",
    "end": "3136390"
  },
  {
    "text": "OK? So what we did was we\nlooked at the error landscape of deep neural\nnetworks trained on MNIST",
    "start": "3136390",
    "end": "3141570"
  },
  {
    "text": "and CIFAR-10, and\nwe just plotted the prediction of random\nlandscape theory, right?",
    "start": "3141570",
    "end": "3147520"
  },
  {
    "text": "And what we found was exactly\nqualitatively their prediction. We took each critical\npoint and plot it",
    "start": "3147520",
    "end": "3153505"
  },
  {
    "text": "in this two-dimensional\nfeature space. And we found that the\ncritical points concentrated on a monotonically\nincrease in curve",
    "start": "3153505",
    "end": "3159874"
  },
  {
    "text": "which, again, shows\nthat there are no local minima at high error. And if your a local\nminimum, your error",
    "start": "3159874",
    "end": "3166480"
  },
  {
    "text": "is close to at least the lowest\nerror minimum that we found. We can't guarantee that the\nlowest error minimum we found",
    "start": "3166480",
    "end": "3172960"
  },
  {
    "text": "is the global minimum. But qualitatively,\nthis structure holds. OK? Now, the issue is what\ncan we do about it.",
    "start": "3172960",
    "end": "3179330"
  },
  {
    "text": "So what this is\ntelling us-- that even in these problems of\npractical interest, saddle points might stand\nas the major impediment",
    "start": "3179330",
    "end": "3186339"
  },
  {
    "text": "to optimization, right? Because saddle\npoints can trap you. You know, you\nmight go down here.",
    "start": "3186340",
    "end": "3194080"
  },
  {
    "text": "And then there might be\na very slowly curving negative curvature direction\nthat might take you a while to escape.",
    "start": "3194080",
    "end": "3199599"
  },
  {
    "text": "In fact, in the\nlearning dynamics that I showed in\nthese transitions in learning\nhierarchical structure,",
    "start": "3199600",
    "end": "3205679"
  },
  {
    "text": "the thing controlling\nthe transitions was the existence of saddle\npoints in weight space of the linear neural network.",
    "start": "3205679",
    "end": "3210760"
  },
  {
    "text": "And so the part of no\nlearning corresponded to sort of falling down\nthis direction slowly.",
    "start": "3210760",
    "end": "3216730"
  },
  {
    "text": "And then the rapid\nlearning corresponded-- eventually coming out this way. OK. So how do we do that?",
    "start": "3216730",
    "end": "3223720"
  },
  {
    "text": "Well, what we can do is we\ncan do a simple modification to Newton's method,\nwhich instead of dividing by the Hessian, we divide by the\nabsolute value of the Hessian.",
    "start": "3223720",
    "end": "3231011"
  },
  {
    "text": "And, again, I should say that\nthis was done in collaboration with Yoshua Bengio's lab. And a set a fantastic graduate\nstudents in Yoshua Bengio's lab",
    "start": "3231011",
    "end": "3237400"
  },
  {
    "text": "did all of this work on\nthe training and testing of these predictions. OK.",
    "start": "3237400",
    "end": "3242620"
  },
  {
    "text": "So what we suggested was,\nyou know, the offending thing is dividing by\nnegative eigenvalues.",
    "start": "3242620",
    "end": "3248332"
  },
  {
    "text": "So just take the absolute\nvalue of the Hessian, which by definition I mean\ntake the Hessian, compute its eigenvalues, and\nreplace each negative one",
    "start": "3248332",
    "end": "3254875"
  },
  {
    "text": "with its absolute value. OK? So that will obviously get\nrepelled by saddles, all right?",
    "start": "3254875",
    "end": "3262060"
  },
  {
    "text": "And that actually works\nreally, really well. And there's a way to\nderive this algorithm",
    "start": "3262060",
    "end": "3267100"
  },
  {
    "text": "in a way that makes sense,\neven far from saddles by minimizing a linear\napproximation to f",
    "start": "3267100",
    "end": "3272200"
  },
  {
    "text": "within a trust region in\nwhich the linear and quadratic approximations agree. OK?",
    "start": "3272200",
    "end": "3277240"
  },
  {
    "text": "So let me just show you\nfirst that it works. So this is the\nmost dramatic plot.",
    "start": "3277240",
    "end": "3282790"
  },
  {
    "text": "So basically what we did was we\ndid stochastic gradient descent for a while.",
    "start": "3282790",
    "end": "3287800"
  },
  {
    "text": "And then it seemed\nlike the error as a function of training time\nplateaued both for a deep auto encoder and a recurrent\nneural network problem.",
    "start": "3287800",
    "end": "3295030"
  },
  {
    "text": "So when the error as a function\nof training time plateaus, that's sort of\ninterpreted as the fact",
    "start": "3295030",
    "end": "3300339"
  },
  {
    "text": "that you're stuck in a\nlocal minimum, right? But actually, when we switched\nto this, what we call,",
    "start": "3300340",
    "end": "3305980"
  },
  {
    "text": "the saddle-free Newton method,\nthe error suddenly drops again. So this was an illusory\nsignature of a local minimum.",
    "start": "3305980",
    "end": "3311720"
  },
  {
    "text": "It was actually a saddle\npoint with probably a very shallow negative\ncurvature direction that was hard to escape.",
    "start": "3311720",
    "end": "3317200"
  },
  {
    "text": "And when we switched to our\nalgorithm, we could escape it. And, you know, what\nthese curves show",
    "start": "3317200",
    "end": "3323520"
  },
  {
    "text": "is that we do do better in the\nfinal training error as while. So now, how do we train\ndeep neural networks",
    "start": "3323520",
    "end": "3330259"
  },
  {
    "text": "with thousands of layers? And actually, how do we\nmodel complex probability distributions?",
    "start": "3330259",
    "end": "3336220"
  },
  {
    "text": "So we want to sample from\nvery, very complex probability distributions and do complex\ndistributional learning, right?",
    "start": "3336220",
    "end": "3343030"
  },
  {
    "text": "So this was done by\na fantastic post-doc of mine, Jascha Sohl-Dickstein.",
    "start": "3343030",
    "end": "3348520"
  },
  {
    "text": "So we were going to Berkeley\nfor this non-equilibrium statistical mechanics\nmeetings and things like that.",
    "start": "3348520",
    "end": "3354440"
  },
  {
    "text": "And there's been\nlots of advances in non-equilibrium\nstatistical mechanics where you can show that,\nroughly speaking, the second law",
    "start": "3354440",
    "end": "3360744"
  },
  {
    "text": "of thermodynamics which says\nthat things get more and more disordered with time can\nbe transiently violated",
    "start": "3360744",
    "end": "3365829"
  },
  {
    "text": "in small systems or\nshort periods of time so you can spontaneously\ngenerate order. OK.",
    "start": "3365830",
    "end": "3372819"
  },
  {
    "text": "So I'll just go through\nthis, again, very quickly. So here's the basic idea.",
    "start": "3372820",
    "end": "3379160"
  },
  {
    "text": "Let's say you have a complicated\nprobability distribution. Let's just destroy it.",
    "start": "3379160",
    "end": "3384250"
  },
  {
    "text": "Let's feed that probability\ndistribution through diffusion to turn it into a simple\ndistribution, maybe",
    "start": "3384250",
    "end": "3390040"
  },
  {
    "text": "an isotropic Gaussian. And we keep a record of that\ndestruction of structure. And then we try to reverse\ntime in that process",
    "start": "3390040",
    "end": "3397300"
  },
  {
    "text": "by using deep neural networks\nto reverse time and then essentially create\nstructure from noise. And then you have a very,\nvery simple way to sample",
    "start": "3397300",
    "end": "3404230"
  },
  {
    "text": "from complex\ndistributions if you can train the neural network,\nwhich is you just sample noise. And you feed it through a\ndeterministic neural network.",
    "start": "3404230",
    "end": "3410800"
  },
  {
    "text": "And that constitutes a sample\nfrom a complex distribution. And so this was inspired\nby recent results in non-equilibrium stat mech.",
    "start": "3410800",
    "end": "3416950"
  },
  {
    "text": "So the basic idea,\nagain, is let's imagine that you have a\nvery complex distribution corresponding to\nthis density of dye.",
    "start": "3416950",
    "end": "3423310"
  },
  {
    "text": "You diffuse for a while. It becomes a simpler\ndistribution. Eventually, they become uniform. You keep a [AUDIO OUT]\nNow, if you",
    "start": "3423310",
    "end": "3430630"
  },
  {
    "text": "reverse process of diffusion,\nyou'll never go from this back to this. But if you reverse process a\nneural network trained to do",
    "start": "3430630",
    "end": "3437320"
  },
  {
    "text": "it, you might be able to do it. So that's the basic idea. So that's what we did.",
    "start": "3437320",
    "end": "3443230"
  },
  {
    "text": "And I'll just show you some nice\nmovies to show that it works. This is the classical toy model. We'll go to more complex models.",
    "start": "3443230",
    "end": "3449213"
  },
  {
    "text": "This is a sample distribution\nin two-dimensional space. And so what we do is we just\nsystematically have the points",
    "start": "3449213",
    "end": "3455559"
  },
  {
    "text": "diffuse under Gaussian\ndiffusion with a restoring force to the origin. So the stationary distribution\nof that destructive process",
    "start": "3455560",
    "end": "3463390"
  },
  {
    "text": "is an isotropic Gaussian. OK? And that's what happened. So that's our training data.",
    "start": "3463390",
    "end": "3470020"
  },
  {
    "text": "The entire movie is\nthe training data. OK? Then what we do is we\ntrain a neural network",
    "start": "3470020",
    "end": "3475240"
  },
  {
    "text": "to reverse time in that movie. So it's a neural network with\nmany, many layers-- hundreds",
    "start": "3475240",
    "end": "3480789"
  },
  {
    "text": "and hundreds of layers, right? So classically\ntraining a network with hundreds of layers, you\nhave the credit assignment problem.",
    "start": "3480790",
    "end": "3485950"
  },
  {
    "text": "Because you don't know what\nthe intermediate neurons are supposed to do. You can circumvent the\ncredit assignment problem,",
    "start": "3485950",
    "end": "3492280"
  },
  {
    "text": "because each layer going\nup to the next layer just has to go from time t to time\nt minus 1 in the training data.",
    "start": "3492280",
    "end": "3499090"
  },
  {
    "text": "So you have targets for all\nthe intermediate layers. Therefore, you've circumvented\nthe credit assignment problem.",
    "start": "3499090",
    "end": "3504600"
  },
  {
    "text": "OK? So it's relatively easy\nto train such networks. And so once you\nhave such a network,",
    "start": "3504600",
    "end": "3509619"
  },
  {
    "text": "what should you be able to do? You should be able to\nfeed that neural network an isotropic Gaussian, and then\nhave that Gaussian be turned",
    "start": "3509620",
    "end": "3518319"
  },
  {
    "text": "into the data distribution. So that's what happens. This on the right is\na different Gaussian. And we just feed it through\nthe trained deterministic",
    "start": "3518320",
    "end": "3525460"
  },
  {
    "text": "neural network. And out pops the structure. It's not perfect.",
    "start": "3525460",
    "end": "3531854"
  },
  {
    "text": "There are some data\npoints that are over here. But this is roughly the\ndistribution that it learned, which is similar to\nwhat it was trained on.",
    "start": "3531854",
    "end": "3538380"
  },
  {
    "text": "OK? So now we can look at slightly\nmore complicated distributions. ",
    "start": "3538380",
    "end": "3548428"
  },
  {
    "text": "OK. So that's that. So now we can train it on a toy\nmodel of natural images, right?",
    "start": "3548428",
    "end": "3554980"
  },
  {
    "text": "So a classic toy model\nof natural images is the dead leaves\nmodel where the sampling process is you just throw down\ncircles of different radii.",
    "start": "3554980",
    "end": "3562380"
  },
  {
    "text": "So you get a complex\nmodel of natural images that has long range\nedges, occlusion,",
    "start": "3562380",
    "end": "3567660"
  },
  {
    "text": "coherence over long length\nscales, and so on and so forth. So we can train the neural\nnetwork on such distributions.",
    "start": "3567660",
    "end": "3574230"
  },
  {
    "text": "We train it in a\nconvolutional fashion by working on local\nimage patches. And we convolve,\nso information will",
    "start": "3574230",
    "end": "3579629"
  },
  {
    "text": "propagate over long ranges. And so, again, we take\nthese natural images and turn them into noise,\nkeep a record of that movie,",
    "start": "3579629",
    "end": "3586475"
  },
  {
    "text": "and then reverse\nthe flow of time using a deep neural network.  OK.",
    "start": "3586476",
    "end": "3591960"
  },
  {
    "text": "So once we train that, we\nshould be able to turn noise",
    "start": "3591960",
    "end": "3597359"
  },
  {
    "text": "into the networks best guess\nas to what a dead leaves model would look like. So this is what happens.",
    "start": "3597360",
    "end": "3603270"
  },
  {
    "text": "It's taking noise, and\nit turns it into a gas. OK. So it's not a perfect model.",
    "start": "3603270",
    "end": "3609190"
  },
  {
    "text": "But it turns out log probability\nof dead leaves under this generative model that consists\nof 1,000-layer deep neural",
    "start": "3609190",
    "end": "3615480"
  },
  {
    "text": "network, that's higher than\nany other model so far. So this is currently\nstate of the art.",
    "start": "3615480",
    "end": "3621940"
  },
  {
    "text": "OK. And as you can see, it\ngets long-range coherence and sharp edges. And moreover, it gets\nlong-range coherence",
    "start": "3621940",
    "end": "3628589"
  },
  {
    "text": "in the orientation of\n[AUDIO OUT] often hard to do in generative\nmodels of natural images.",
    "start": "3628590",
    "end": "3634510"
  },
  {
    "text": "OK. Now, we can actually do\nsomething somewhat practical with this is we can sample\nfrom the conditional.",
    "start": "3634510",
    "end": "3642000"
  },
  {
    "text": "So then we also\ntrained it on textures. OK? ",
    "start": "3642000",
    "end": "3647460"
  },
  {
    "text": "So, for example,\ntextures of bark, right? And we can also sample from\nthe conditional distribution.",
    "start": "3647460",
    "end": "3652720"
  },
  {
    "text": "So what we can do is we can\nclamp the pixels outside of a certain range,\nreplace the interior",
    "start": "3652720",
    "end": "3658440"
  },
  {
    "text": "with [AUDIO OUT] make it blank. And because the network operates\nin a convolutional fashion, information from\nthe boundary should",
    "start": "3658440",
    "end": "3664650"
  },
  {
    "text": "propagate into the interior\nand fill it in, right? So if we look at that,\nso that's white noise.",
    "start": "3664650",
    "end": "3670829"
  },
  {
    "text": "And the network\nis filling it in. And it fills in the\nbest guess image.",
    "start": "3670830",
    "end": "3677291"
  },
  {
    "text": "OK. And so, again,\nit's not identical to the original image, but\nit does get long-range edge structure, coherence in the\norientation of the edge,",
    "start": "3677291",
    "end": "3684930"
  },
  {
    "text": "and smooth structure as well. And, again, this is like\n1,000-layer neural network. Now, there's some lessons here. OK?",
    "start": "3684930",
    "end": "3690869"
  },
  {
    "text": "Oftentimes when we model\ncomplex data distributions, what we try to do is we try to create\na stochastic process whose",
    "start": "3690870",
    "end": "3698030"
  },
  {
    "text": "stationery distribution is the\ncomplex distribution, right? Now, if your distribution\nhas multiple modes,",
    "start": "3698030",
    "end": "3704420"
  },
  {
    "text": "you're going to run\ninto a mixing problem, because it can take a\nstochastic process a long time to jump over energy\nbarriers that",
    "start": "3704420",
    "end": "3710730"
  },
  {
    "text": "separate the multiple modes. So you always have\na mixing problem. And oftentimes when you\ntrain probabilistic models,",
    "start": "3710730",
    "end": "3717030"
  },
  {
    "text": "you have to sample and then\nthe samples to train the model. So that makes training\ntake a long time.",
    "start": "3717030",
    "end": "3725320"
  },
  {
    "text": "So what we're also doing in\naddition to circumventing the credit assignment\nproblem and training very deep neural networks,\nwe're circumventing",
    "start": "3725320",
    "end": "3731310"
  },
  {
    "text": "the mixing problem in\ntraining the generative model. Because we're not\ntrying to model the data",
    "start": "3731310",
    "end": "3736360"
  },
  {
    "text": "distribution as a\nstationary distribution of a stochastic process. That would have to run\nfor a very long time to get to the\nstationary distribution.",
    "start": "3736360",
    "end": "3742720"
  },
  {
    "text": "We're demanding that\nduring training the process get to the data distribution in\na finite amount of time, right?",
    "start": "3742720",
    "end": "3749820"
  },
  {
    "text": "So because during training we\ndemand that we get to the data distribution a finite\namount of time, we're circumventing the mixing\nproblem during training.",
    "start": "3749820",
    "end": "3757170"
  },
  {
    "text": "And that's the idea. That's [AUDIO OUT] an idea. There's lots of\nresults now that show that you can attain information\nabout stationary equilibrium",
    "start": "3757170",
    "end": "3765150"
  },
  {
    "text": "distributions from\nnon-equilibrium trajectories. OK. So now, I'm done.",
    "start": "3765150",
    "end": "3770860"
  },
  {
    "text": "So let's see. OK. So there's that. OK. So, again, you\ncan read about all",
    "start": "3770860",
    "end": "3776310"
  },
  {
    "text": "of this stuff in\nthis set of papers. Again, I'd like to thank\nmy funding and just",
    "start": "3776310",
    "end": "3781350"
  },
  {
    "text": "the key players. So Andrew Saxe, you know,\ndid the work with me on non-linear learning\ndynamics and learning",
    "start": "3781350",
    "end": "3787530"
  },
  {
    "text": "hierarchical category structure. Jascha Sohl-Dickstein\ndid the work on deep learning using\nnon-equilibrium thermodynamics.",
    "start": "3787530",
    "end": "3795150"
  },
  {
    "text": "And the work on saddle points\nwas a nice collaboration with Yoshua Bengio's lab. And again-- fantastic\ngraduate students",
    "start": "3795150",
    "end": "3802000"
  },
  {
    "text": "in Yoshua Bengio's lab. OK. So I think there's\na lot more to do in terms of unifying\nneuroscience, machine",
    "start": "3802000",
    "end": "3808020"
  },
  {
    "text": "learning, physics, math,\nstatistics, all of that stuff. It'll keep us busy\nfor the next century.",
    "start": "3808020",
    "end": "3813260"
  },
  {
    "start": "3813260",
    "end": "3821771"
  }
]
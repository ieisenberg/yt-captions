[
  {
    "start": "0",
    "end": "31000"
  },
  {
    "text": "[SQUEAKING] [RUSTLING] [CLICKING] ",
    "start": "0",
    "end": "15128"
  },
  {
    "text": "DAVID SONTAG: OK, so\nthen today's lecture is going to be about data\nset shifts, specifically",
    "start": "15128",
    "end": "21640"
  },
  {
    "text": "how one can be robust\nto data set shift. Now, this is the topic\nthat we've been alluding to",
    "start": "21640",
    "end": "27220"
  },
  {
    "text": "throughout the semester. And the setting that I want\nyou to be thinking about",
    "start": "27220",
    "end": "33402"
  },
  {
    "text": "is as follows.  You're a data scientist\nworking at, let's say,",
    "start": "33402",
    "end": "40180"
  },
  {
    "text": "Mass General\nHospital, and you've been very careful in setting\nup your machine learning task",
    "start": "40180",
    "end": "47530"
  },
  {
    "text": "to make sure that the\ndata is well specified, the labels that you're trying\nto predict are well specified.",
    "start": "47530",
    "end": "54280"
  },
  {
    "text": "You train on a valid-- you train on your training data,\nyou test it on a held-out set, you see that the model\ngeneralizes well,",
    "start": "54280",
    "end": "60475"
  },
  {
    "text": "you do chart review to\nmake sure what you're predicting is actually what\nyou think you're predicting, and you even do prospective\ndeployment where you then",
    "start": "60475",
    "end": "68320"
  },
  {
    "text": "let your machine\nlearning algorithm drive some clinical decision\nsupport, and you'd see things are working great.",
    "start": "68320",
    "end": "74860"
  },
  {
    "text": "Now what? What happens after this stage\nwhen you go to deployment?",
    "start": "74860",
    "end": "81590"
  },
  {
    "text": "What happens when\nyour same model is going to be used\nnot just tomorrow",
    "start": "81590",
    "end": "87040"
  },
  {
    "text": "but also next week, the\nfollowing week, the next year? What happens if your model,\nwhich is working well",
    "start": "87040",
    "end": "92620"
  },
  {
    "text": "at this one hospital, then\nwants to-- then there's another institution,\nsay, maybe Brigham",
    "start": "92620",
    "end": "98545"
  },
  {
    "text": "and Women's Hospital,\nor maybe UCSF, or some rural hospital\nin the United States wants to use the\nsame model, will it",
    "start": "98545",
    "end": "106000"
  },
  {
    "text": "keep working in this \"short\nterm to the future\" time period or in a new institution? That's the question which\nwe're going to be talking",
    "start": "106000",
    "end": "112810"
  },
  {
    "text": "about in today's lecture. And we'll be talking\nabout how one can deal with data set shift\nof two different varieties.",
    "start": "112810",
    "end": "119990"
  },
  {
    "text": "The first variety is adversarial\nperturbations to data, and the second variety is\ndata due to-- the data that",
    "start": "119990",
    "end": "126280"
  },
  {
    "text": "changes for natural reasons. Now, the reason why\nit's not at all obvious",
    "start": "126280",
    "end": "131500"
  },
  {
    "start": "128000",
    "end": "330000"
  },
  {
    "text": "that your machine learning\nalgorithm should still work in the setting is because\nthe number one assumption we make when we do\nmachine learning",
    "start": "131500",
    "end": "138310"
  },
  {
    "text": "is that your training\ndistribution, your training data, is drawn from the same\ndistribution as your test data.",
    "start": "138310",
    "end": "144592"
  },
  {
    "text": "So if you now go to a setting\nwhere your data distribution has changed, even if you've\ncomputed your accuracy using",
    "start": "144593",
    "end": "153189"
  },
  {
    "text": "your held-out data\nand it looks good, there's no reason\nthat should continue to look good in this new\nsetting, where the data",
    "start": "153190",
    "end": "160030"
  },
  {
    "text": "distribution has changed. A simple example of what it\nmeans for a data distribution",
    "start": "160030",
    "end": "165305"
  },
  {
    "text": "to change might be as follows. ",
    "start": "165305",
    "end": "171510"
  },
  {
    "text": "Suppose that we\nhave as input data,",
    "start": "171510",
    "end": "177620"
  },
  {
    "text": "and we're trying to\npredict some label, which",
    "start": "177620",
    "end": "183980"
  },
  {
    "text": "maybe meant something like,\nwhy if a patient has--",
    "start": "183980",
    "end": "192060"
  },
  {
    "text": "or will be newly diagnosed\nwith type 2 diabetes, and this is an\nexample which we--",
    "start": "192060",
    "end": "198650"
  },
  {
    "text": "which we talked about when we\nintroduce risk stratification, you learn a model\nto predict y from x.",
    "start": "198650",
    "end": "207469"
  },
  {
    "text": "And now suppose you go\nto a new institution where their definition of\nwhat type 2 diabetes means",
    "start": "207470",
    "end": "213560"
  },
  {
    "text": "has changed. For example, maybe they don't\nactually have type 2 diabetes",
    "start": "213560",
    "end": "221870"
  },
  {
    "text": "coded in their data, maybe\nthey only have diabetes coded in their data,\nwhich is lumping together",
    "start": "221870",
    "end": "229010"
  },
  {
    "text": "both type 1 and type\n2 diabetes, type 1 being what's usually\njuvenile diabetes",
    "start": "229010",
    "end": "236330"
  },
  {
    "text": "and is actually a very distinct\ndisease from type 2 diabetes. So now the notion of what\ndiabetes is is different.",
    "start": "236330",
    "end": "242450"
  },
  {
    "text": "Maybe the use case is\nalso slightly different. And there's no\nreason, obviously, that your model, which was used\nto predict type 2 diabetes,",
    "start": "242450",
    "end": "248480"
  },
  {
    "text": "would work for that new label. Now, this is an example\nof a very type-- of a type of data set\nshift which is perhaps",
    "start": "248480",
    "end": "256730"
  },
  {
    "text": "for you obvious nothing\nshould work in the setting because here the distribution\nof P of y given x changes,",
    "start": "256730",
    "end": "269540"
  },
  {
    "text": "meaning even if you have\nthe same individual, your distribution P(y)\ngiven x in, let's say,",
    "start": "269540",
    "end": "275900"
  },
  {
    "text": "the distribution P(0) and the\ndistribution P of y given x and P(1), where this is, let's\nsay, one institution, this",
    "start": "275900",
    "end": "282700"
  },
  {
    "text": "is another, these now are\ntwo different distributions if the meaning of the\nlabel has changed. So for the same person, there\nmight be different distribution",
    "start": "282700",
    "end": "290720"
  },
  {
    "text": "over what y is. So this is one\ntype of data shift. And a very different\ntype of data",
    "start": "290720",
    "end": "295920"
  },
  {
    "text": "set shift is where we assume\nthat these two are equal. And so that would,\nfor example, rule out",
    "start": "295920",
    "end": "300979"
  },
  {
    "text": "this type of data set shift. But rather what changes is P of\nx from location 1 to location--",
    "start": "300980",
    "end": "311240"
  },
  {
    "text": "to location 2. And this is the type of data set\nshift which will be focused on",
    "start": "311240",
    "end": "318009"
  },
  {
    "text": "in today's lecture. It goes by the name\nof covariate shift. ",
    "start": "318010",
    "end": "327260"
  },
  {
    "text": "And let's look at two\ndifferent examples of that. The first example would be of\nan adversarial perturbation.",
    "start": "327260",
    "end": "334730"
  },
  {
    "start": "330000",
    "end": "743000"
  },
  {
    "text": "And so we've-- you've all seen\nthe use of convolutional neural networks for image\nclassification problems.",
    "start": "334730",
    "end": "341539"
  },
  {
    "text": "This is just one illustration\nof such an architecture. And with such an\narchitecture, one could then attempt to do all\nsorts of different object",
    "start": "341540",
    "end": "348140"
  },
  {
    "text": "classification or image\nclassification tasks. You could take as input\nthis picture of a dog, which",
    "start": "348140",
    "end": "354259"
  },
  {
    "text": "is clearly a dog. And you could modify\nit just a little bit.",
    "start": "354260",
    "end": "361220"
  },
  {
    "text": "Just add in a very\nsmall amount of noise. What I'm going to\ndo is now I'm going",
    "start": "361220",
    "end": "366800"
  },
  {
    "text": "to create a new image which\nis that original image.",
    "start": "366800",
    "end": "371879"
  },
  {
    "text": "Now with every single\npixel, I'm going to add a very small epsilon in\nthe direction of that noise.",
    "start": "371880",
    "end": "377840"
  },
  {
    "text": "And what you get out\nis this new image, which you could stare at\nhowever long you want, you're not going to able\nto tell the difference.",
    "start": "377840",
    "end": "384718"
  },
  {
    "text": "Basically to the\nhuman eye, these two look exactly identical. Except when you take your\nmachine learning classifier,",
    "start": "384718",
    "end": "393680"
  },
  {
    "text": "which is trained on\noriginal unperturbed data, and now apply it\nto this new image,",
    "start": "393680",
    "end": "399330"
  },
  {
    "text": "it's classified as an ostrich.  And this observation\nwas published",
    "start": "399330",
    "end": "406759"
  },
  {
    "text": "in a paper in 2014 called\n\"Intriguing properties of neural networks.\"",
    "start": "406760",
    "end": "412280"
  },
  {
    "text": "And it really kickstarted\na huge surge of interest",
    "start": "412280",
    "end": "418255"
  },
  {
    "text": "in the machine\nlearning community on adversarial perturbations\nto machine learning.",
    "start": "418255",
    "end": "424350"
  },
  {
    "text": "So asking questions, if you\nwere to perturb inputs just a little bit, how\ndoes that change",
    "start": "424350",
    "end": "429680"
  },
  {
    "text": "your classifier's output? And could that be used to attack\nmachine learning algorithms?",
    "start": "429680",
    "end": "435139"
  },
  {
    "text": "And how can one\ndefend against it? By the way, as an\naside, this is actually a very old area of research.",
    "start": "435140",
    "end": "442580"
  },
  {
    "text": "And even back in the land\nof linear classifiers, these questions\nhad been studied. Although I won't get\ninto it in this course.",
    "start": "442580",
    "end": "450870"
  },
  {
    "text": "So this is a type of data\nset shift in the sense that what we want is that this\nshould still be classified",
    "start": "450870",
    "end": "456919"
  },
  {
    "text": "as an ostrich-- as a dog. So the actual label\nhasn't changed.",
    "start": "456920",
    "end": "462210"
  },
  {
    "text": "We would like this distribution\nover the labels, given the perturbed into it,\nto be slightly different, except that now the\ndistribution of inputs",
    "start": "462210",
    "end": "469670"
  },
  {
    "text": "is a little bit\ndifferent because we're allowing for some noise to be\nadded to each of the inputs.",
    "start": "469670",
    "end": "475537"
  },
  {
    "text": "And in this case, the noise\nactually isn't random, it's adversarial. And towards the end\nof today's lecture, I'll give you an example\nof how one can actually",
    "start": "475537",
    "end": "482540"
  },
  {
    "text": "generate the\nadversarial image, which can change the classifier. Now, the reason\nwhy we should care",
    "start": "482540",
    "end": "488780"
  },
  {
    "text": "about these types of\nthings in this course are because I expect\nthat this type of data",
    "start": "488780",
    "end": "494580"
  },
  {
    "text": "set shift, which is not at\nall natural, it's adversarial, is also going to start\nshowing up in both computer",
    "start": "494580",
    "end": "501949"
  },
  {
    "text": "vision and non-computer vision\nproblems in the medical domain. There was a nice paper by Sam\nFinlayson, Andy Beam, and Isaac",
    "start": "501950",
    "end": "512585"
  },
  {
    "text": "Kohane recently, which\npresented several different case studies of where these\nproblems could really",
    "start": "512585",
    "end": "520370"
  },
  {
    "text": "arise in health care. So, for example, here\nwhat we're looking at is an image\nclassification problem",
    "start": "520370",
    "end": "525920"
  },
  {
    "text": "arising from dermatology. You're given as input an image.",
    "start": "525920",
    "end": "532130"
  },
  {
    "text": "For example, you would like\nthat this image be classified",
    "start": "532130",
    "end": "537500"
  },
  {
    "text": "as an individual having\na particular type of skin disorder, a nevus, and\nthis other image, melanoma.",
    "start": "537500",
    "end": "545300"
  },
  {
    "text": "And what one can see is that\nwith a small perturbation of the input, one\ncan completely swap",
    "start": "545300",
    "end": "553730"
  },
  {
    "text": "the label that would be assigned\nto it from one to the other. ",
    "start": "553730",
    "end": "559460"
  },
  {
    "text": "And in this paper,\nwhich we're going to post as optional\nreadings for today's course, they talk about how one\ncould maliciously use",
    "start": "559460",
    "end": "567649"
  },
  {
    "text": "these algorithms for benefit. So, for example, imagine that\na health insurance company now",
    "start": "567650",
    "end": "576890"
  },
  {
    "text": "decides in order to reimburse\nfor an expensive biopsy",
    "start": "576890",
    "end": "584330"
  },
  {
    "text": "of a patient's skin,\na clinician or a nurse",
    "start": "584330",
    "end": "590600"
  },
  {
    "text": "must first take a\npicture of the disorder",
    "start": "590600",
    "end": "595970"
  },
  {
    "text": "and submit that picture\ntogether with the bill for the procedure.",
    "start": "595970",
    "end": "602449"
  },
  {
    "text": "And imagine now that the\ninsurance company were to have a machine\nlearning algorithm be",
    "start": "602450",
    "end": "607894"
  },
  {
    "text": "an automatic check, was this\nprocedure actually reasonable for this condition?",
    "start": "607895",
    "end": "615110"
  },
  {
    "text": "And if it isn't, it\nmight be flagged. Now, a malicious user could\nperturb the input such",
    "start": "615110",
    "end": "625660"
  },
  {
    "text": "that it would, despite the\npatient having perhaps even completely normal-looking\nskin, could nonetheless",
    "start": "625660",
    "end": "632560"
  },
  {
    "text": "be classified by a\nmachine learning algorithm as being abnormal in\nsome way, and thus perhaps could get reimbursed\nby that procedure.",
    "start": "632560",
    "end": "641080"
  },
  {
    "text": "Now, obviously\nthis is an example of a nefarious setting\nwhere we would then",
    "start": "641080",
    "end": "647320"
  },
  {
    "text": "hope that such an\nindividual would be caught by the police, sent to jail.",
    "start": "647320",
    "end": "653793"
  },
  {
    "text": "But nonetheless, what we\nwould like to be able to do is build checks and balances\ninto the system such",
    "start": "653793",
    "end": "658930"
  },
  {
    "text": "that that couldn't even\nhappen because to a human it's obvious that you\nshouldn't be able to trick--",
    "start": "658930",
    "end": "665860"
  },
  {
    "text": "trick anyone with such a\nvery minor perturbation. So how do you build\nalgorithms that could also be not\ntricked as easily",
    "start": "665860",
    "end": "672440"
  },
  {
    "text": "as humans wouldn't be tracked? AUDIENCE: Can I ask a question DAVID SONTAG: Yeah. AUDIENCE: For any\nof these samples, did the attacker need\naccess to the network?",
    "start": "672440",
    "end": "680785"
  },
  {
    "text": "Is there a way to\n[? attack it? ?] DAVID SONTAG: So the question\nis whether the attacker needs to know something about\nthe function that's",
    "start": "680785",
    "end": "686949"
  },
  {
    "text": "being used for classifying. There are examples of both what\nare called white box and black",
    "start": "686950",
    "end": "693190"
  },
  {
    "text": "box attacks, where in one\nsetting you have access",
    "start": "693190",
    "end": "698860"
  },
  {
    "text": "to the function and\nother settings you don't. And so both have been\nstudied in the literature,",
    "start": "698860",
    "end": "705550"
  },
  {
    "text": "and there are results\nshowing that one can attack in either setting. Sometimes you might need\nto know a little bit more.",
    "start": "705550",
    "end": "711970"
  },
  {
    "text": "Like, for example,\nsometimes you need to have the ability to query\nthe function a certain number of times. So even if you don't know\nexactly what the function is,",
    "start": "711970",
    "end": "718990"
  },
  {
    "text": "like you don't know the\nweights of the neural network, as long as you can query\nit sufficiently many times,",
    "start": "718990",
    "end": "724630"
  },
  {
    "text": "you'll be able to construct\nadversarial examples. That would be one approach. Another approach\nwould be, oh, maybe we",
    "start": "724630",
    "end": "730060"
  },
  {
    "text": "don't know the function,\nbut we know something about the training data. So there are ways to go about\ndoing this even if you don't",
    "start": "730060",
    "end": "736060"
  },
  {
    "text": "perfectly know the function. Does that answer your question? ",
    "start": "736060",
    "end": "741950"
  },
  {
    "text": "So what about a\nnatural perturbation? So this figure just\npulled from lecture 5 when we talked about\nnon-stationarity",
    "start": "741950",
    "end": "748360"
  },
  {
    "start": "743000",
    "end": "842000"
  },
  {
    "text": "in the context of risk\nstratification, that's just to remind you here the\nx-axis is time, that y-axis is",
    "start": "748360",
    "end": "754450"
  },
  {
    "text": "different types of\nlaboratory test results that might be ordered,\nand the color denotes",
    "start": "754450",
    "end": "761755"
  },
  {
    "text": "how many of those\nlaboratory tests were ordered in a certain\npopulation at a point in time.",
    "start": "761755",
    "end": "767630"
  },
  {
    "text": "So what we would expect to\nsee if the data was stationary is that every row would\nbe a homogeneous color.",
    "start": "767630",
    "end": "774010"
  },
  {
    "text": "But instead what we see is\nthat there are points in time, for example, a few month\nintegrals over here, when suddenly it looks like, for\nsome of the laboratory tests,",
    "start": "774010",
    "end": "782890"
  },
  {
    "text": "they were never performed. That's most likely\ndue to a data problem,",
    "start": "782890",
    "end": "788589"
  },
  {
    "text": "or perhaps the feed of data from\nthat laboratory test provider got lost, there were\nsome systems problem.",
    "start": "788590",
    "end": "794147"
  },
  {
    "text": "But they're also going\nto be settings where, for example, a\nlaboratory test is never used until it's suddenly used.",
    "start": "794147",
    "end": "799660"
  },
  {
    "text": "And that might be because\nit's a new test that was just invented or\napproved for reimbursement at that point in time. So this is an example\nof non-stationarity.",
    "start": "799660",
    "end": "806410"
  },
  {
    "text": "And, of course, this\ncould also result in changes in your\ndata distribution, such as what I described\nover there, over time.",
    "start": "806410",
    "end": "815380"
  },
  {
    "text": "And the third example\nis when you then go across institutions,\nwherein, of course, both the language that might\nbe used-- you might think",
    "start": "815380",
    "end": "821650"
  },
  {
    "text": "of a hospital in\nthe United States versus a hospital in China, the\nclinical notes will be written in completely different\nlanguages, that'll",
    "start": "821650",
    "end": "828560"
  },
  {
    "text": "would be an extreme case. And a less extreme case might\nbe two different hospitals in Boston where the\nacronyms or the shorthand",
    "start": "828560",
    "end": "836450"
  },
  {
    "text": "they use for some clinical\nterms might actually be different because\nof local practices.",
    "start": "836450",
    "end": "843139"
  },
  {
    "start": "842000",
    "end": "1163000"
  },
  {
    "text": "So, what do we do? This is all a setup. And for the rest of the\nlecture, what I'll talk about is first, very\nbriefly, how one can",
    "start": "843140",
    "end": "850810"
  },
  {
    "text": "build in population-level checks\nfor has something changed. And then the bulk\nof today's lecture,",
    "start": "850810",
    "end": "857930"
  },
  {
    "text": "we'll be talking about how\nto develop transfer learning algorithms and how one\ncould think about defenses",
    "start": "857930",
    "end": "863847"
  },
  {
    "text": "to adversarial attacks. ",
    "start": "863847",
    "end": "869580"
  },
  {
    "text": "So before I show you that\nfirst slide for bullet one, I want to have a\nbit of discussion.",
    "start": "869580",
    "end": "875497"
  },
  {
    "text": " You've suddenly done that\nthing of learning machine",
    "start": "875497",
    "end": "881160"
  },
  {
    "text": "learning algorithm\nin your institution, and you want to know,\nwill this algorithm",
    "start": "881160",
    "end": "887610"
  },
  {
    "text": "work at some other institution? You pick up the phone, you\ncall up your collaborating data",
    "start": "887610",
    "end": "894870"
  },
  {
    "text": "scientists at another\ninstitution, what are the questions that\nyou should ask them when we're trying to\nunderstand, will your algorithm",
    "start": "894870",
    "end": "900120"
  },
  {
    "text": "work there as well? ",
    "start": "900120",
    "end": "907860"
  },
  {
    "text": "Yeah. AUDIENCE: What kind of\nlab test information they collect [INAUDIBLE].",
    "start": "907860",
    "end": "913270"
  },
  {
    "text": "DAVID SONTAG: So\nwhat type of data do they have on their\npatients, and do they have similar data types\nor features available",
    "start": "913270",
    "end": "920460"
  },
  {
    "text": "for their patient population? Other ideas, someone who\nhasn't spoken in the last two lectures, maybe someone\nin the far back there,",
    "start": "920460",
    "end": "929261"
  },
  {
    "text": "people who have\ntheir computer out. Maybe you with your\nhand in your mouth right there, yeah, you\nwith your glasses on. Ideas.",
    "start": "929262",
    "end": "934750"
  },
  {
    "text": "[STUDENT LAUGHS] AUDIENCE: Sorry, can\nyou repeat the question? DAVID SONTAG: You want me\nto repeat the question?",
    "start": "934750",
    "end": "940350"
  },
  {
    "text": "The question was as follows. You learn your machine learning\nalgorithm at some institution,",
    "start": "940350",
    "end": "945930"
  },
  {
    "text": "and you want to apply it\nnow in a new institution. What questions should you\nask of that new institution to try to assess whether your\nalgorithm will generalize",
    "start": "945930",
    "end": "952500"
  },
  {
    "text": "in that new institution? AUDIENCE: I guess it depends on\nyour problem you're looking at, like whether you're\ntrying to learn",
    "start": "952500",
    "end": "958880"
  },
  {
    "text": "possible differences\nin your population, if you're requiring data with\nparticular [INAUDIBLE] use.",
    "start": "958880",
    "end": "964886"
  },
  {
    "text": "So I'd envision it\nthat you'd want to, like are your machines\ncalibrated [INAUDIBLE]?? Do they use techniques\nto acquire the data?",
    "start": "964887",
    "end": "971070"
  },
  {
    "text": "DAVID SONTAG: All right. So let's break down each of\nthe answers that you gave. The first answer\nthat you gave was,",
    "start": "971070",
    "end": "976420"
  },
  {
    "text": "are there differences\nin the population?  What would be an exa--\nsomeone else now,",
    "start": "976420",
    "end": "982450"
  },
  {
    "text": "what are we an example of a\ndifference in a population? ",
    "start": "982450",
    "end": "988660"
  },
  {
    "text": "Yep. AUDIENCE: Age\ndistribution You might have younger people\nin maybe Boston versus like a\nMassachusetts [INAUDIBLE].. DAVID SONTAG: So you\nmight have younger people",
    "start": "988660",
    "end": "995516"
  },
  {
    "text": "in Boston versus\nolder people who are in Central Massachusetts.",
    "start": "995517",
    "end": "1000680"
  },
  {
    "text": "How might a change\nin age distribution affect your ability of your\nalgorithms to generalize?",
    "start": "1000680",
    "end": "1007562"
  },
  {
    "text": "Yep. AUDIENCE: [? Possibly ?]\nhealth patterns, where young people are very\ndifferent from [INAUDIBLE] who have some diseases that\nare clearly more prevalent",
    "start": "1007562",
    "end": "1014740"
  },
  {
    "text": "in populations that are\nolder [? than you. ?] DAVID SONTAG: Thank you. So sometimes we might expect a\ndifferent just set of diseases",
    "start": "1014740",
    "end": "1021030"
  },
  {
    "text": "to occur for a younger\npopulation versus an older population. So I type 2 diabetes,\nhypertension,",
    "start": "1021030",
    "end": "1027809"
  },
  {
    "text": "these are diseases that are\noften diagnosed when patients--",
    "start": "1027810",
    "end": "1033000"
  },
  {
    "text": "when individuals are\n40s, 50s, and older. If you have people\nwho are in their 20s,",
    "start": "1033000",
    "end": "1039300"
  },
  {
    "text": "you don't typically\nsee those diseases in a younger population. And so what that means is\nif your model, for example,",
    "start": "1039300",
    "end": "1047459"
  },
  {
    "text": "was trained on a population\nof very young individuals,",
    "start": "1047460",
    "end": "1052710"
  },
  {
    "text": "then it might not be able\nto-- and suppose you're doing something like\npredicting future cost,",
    "start": "1052710",
    "end": "1060000"
  },
  {
    "text": "so something which is not\ndirectly tied to the disease itself, the features that\nare predictive of future cost",
    "start": "1060000",
    "end": "1065950"
  },
  {
    "text": "in a very young population\nmight be very different from features-- for predictors of cost in a\nmuch older population because",
    "start": "1065950",
    "end": "1073230"
  },
  {
    "text": "of the differences in conditions\nthat those individuals have. Now the second\nanswer that was given",
    "start": "1073230",
    "end": "1078570"
  },
  {
    "text": "had to do with calibration\nof instruments. Can you elaborate\na bit about that? AUDIENCE: Yeah.",
    "start": "1078570",
    "end": "1083995"
  },
  {
    "text": "So I was thinking [? clearly ?]\nin the colonoscopy space. But if you're collecting--\nso in that space,",
    "start": "1083995",
    "end": "1089902"
  },
  {
    "text": "you're collecting\nvideos of colons. And so you can\nhave machines that are calibrated very\ndifferently, let's say",
    "start": "1089902",
    "end": "1095823"
  },
  {
    "text": "different light exposure,\ndifferent camera settings. But you also have that\nthe GIs and physicians",
    "start": "1095823",
    "end": "1101450"
  },
  {
    "text": "have different techniques as\nto how they explore the colon. So the video data itself is\ngoing to be very different.",
    "start": "1101450",
    "end": "1106559"
  },
  {
    "text": "DAVID SONTAG: So the\nexample that was given was of colonoscopies\nand data that might be collected as part of that.",
    "start": "1106560",
    "end": "1112470"
  },
  {
    "text": " And the data that could be--\nthe data that could be collected",
    "start": "1112470",
    "end": "1117630"
  },
  {
    "text": "could be different for\ntwo different reasons. One, because the-- because\nthe actual instruments",
    "start": "1117630",
    "end": "1123967"
  },
  {
    "text": "that are collecting the data,\nfor example, imaging data, might be calibrated a\nlittle bit differently. And a second reason might be\nbecause the procedures that",
    "start": "1123967",
    "end": "1130013"
  },
  {
    "text": "are used to perform that\ndiagnostic test might be different in each institution. Each one will result in slightly\ndifferent biases to the data,",
    "start": "1130013",
    "end": "1137800"
  },
  {
    "text": "and it's not clear that\nan algorithm trained on one type of procedure\nor one type of instrument would generalize to another.",
    "start": "1137800",
    "end": "1144580"
  },
  {
    "text": "So these are all great examples. And so when one reads a paper\nfrom the clinical community",
    "start": "1144580",
    "end": "1151620"
  },
  {
    "text": "on developing a new risk\nstratification tool, what you will always\nsee in this paper",
    "start": "1151620",
    "end": "1159960"
  },
  {
    "text": "is what's known as \"Table 1.\" Table 1 looks a\nlittle bit like this.",
    "start": "1159960",
    "end": "1165360"
  },
  {
    "start": "1163000",
    "end": "1473000"
  },
  {
    "text": "Here I pulled one\nof my own papers that was published in\nJAMA Cardiology for 2016 where we looked at how to try\nto find patients with heart",
    "start": "1165360",
    "end": "1172350"
  },
  {
    "text": "failure who are hospitalized. And I'm just going to walk\nthrough what this table is.",
    "start": "1172350",
    "end": "1177510"
  },
  {
    "text": "So this table is\ndescribing the population that was used in the study.",
    "start": "1177510",
    "end": "1182730"
  },
  {
    "text": "At the very top, it says these\nare characteristics of 47,000 hospitalized patients.",
    "start": "1182730",
    "end": "1187980"
  },
  {
    "text": "Then what we've done is,\nusing our domain knowledge,",
    "start": "1187980",
    "end": "1193480"
  },
  {
    "text": "we know that this is a\nheart failure population, and we know that there are\na number of different axes that differentiate patients\nwho are hospitalized",
    "start": "1193480",
    "end": "1201420"
  },
  {
    "text": "that have heart failure. And so we enumerate over\nmany of the features",
    "start": "1201420",
    "end": "1207179"
  },
  {
    "text": "that we think are critical to\ncharacterizing the population, and we give\ndescriptive statistics",
    "start": "1207180",
    "end": "1212880"
  },
  {
    "text": "on each one of those features. You always start with things\nlike age, gender, and race.",
    "start": "1212880",
    "end": "1219530"
  },
  {
    "text": "And so here, for example, the\naverage age was 61 years old, this was, by the way, NYU\nMedical School, 50.8% female,",
    "start": "1219530",
    "end": "1232080"
  },
  {
    "text": "11.2% Black, African-American,\n17.6% of individuals",
    "start": "1232080",
    "end": "1237480"
  },
  {
    "text": "were on Medicaid, which\nwas a state-provided health insurance for either disabled\nor lower-income individuals.",
    "start": "1237480",
    "end": "1246960"
  },
  {
    "text": "And then we looked at quantities\nlike what types of medications were patients on.",
    "start": "1246960",
    "end": "1252480"
  },
  {
    "text": "41% of-- 42% of\ninpatient patients",
    "start": "1252480",
    "end": "1257970"
  },
  {
    "text": "were on something\ncalled beta blockers. 31.6% of outpatients\nwere on beta blockers.",
    "start": "1257970",
    "end": "1263970"
  },
  {
    "text": "We then looked at things\nlike laboratory test results.",
    "start": "1263970",
    "end": "1269080"
  },
  {
    "text": "So one can look at the\naverage creatinine values, the average sodium values\nof this patient population.",
    "start": "1269080",
    "end": "1276900"
  },
  {
    "text": "And in this way,\nit described what is the population\nthat's being studied. Then when you go to\nthe new institution,",
    "start": "1276900",
    "end": "1282840"
  },
  {
    "text": "that new institution receives\nnot just the algorithm, but they also\nreceive this Table 1",
    "start": "1282840",
    "end": "1289169"
  },
  {
    "text": "that describes a population in\nwhich the algorithm was learned on. And they could use that together\nwith some domain knowledge",
    "start": "1289170",
    "end": "1296040"
  },
  {
    "text": "to think through questions like\nwhat we were eliciting-- what I elicited from you\nin our discussion so that we could\nthink, is it actually--",
    "start": "1296040",
    "end": "1302460"
  },
  {
    "text": "does it make sense that\nthis model will generalize to this new institution? Are the reasons\nwhy it might not?",
    "start": "1302460",
    "end": "1307920"
  },
  {
    "text": "And you could do that\neven before doing any prospective evaluation\non the new population.",
    "start": "1307920",
    "end": "1314710"
  },
  {
    "text": "So almost all of you should\nhave something like Table 1 in your project\nwrite-ups because that's",
    "start": "1314710",
    "end": "1322380"
  },
  {
    "text": "an important part of any study\nin this field is describing, what is the population that\nyou're doing your study on?",
    "start": "1322380",
    "end": "1329430"
  },
  {
    "text": "You agree with me, Pete? PETER SZOLOVITS: Yeah. I would just at that Table 1,\nif you're doing a case control",
    "start": "1329430",
    "end": "1336300"
  },
  {
    "text": "study, you will have\ntwo columns that show the distributions\nin the two populations,",
    "start": "1336300",
    "end": "1344910"
  },
  {
    "text": "and then a p-value of how\nlikely those differences are to be significant.",
    "start": "1344910",
    "end": "1350440"
  },
  {
    "text": "And if you leave that out, you\ncan't get your paper published. DAVID SONTAG: I'll just\nrepeat Pete's answer",
    "start": "1350440",
    "end": "1355740"
  },
  {
    "text": "for the recording. If you are-- this table is\nfor a predictive problem.",
    "start": "1355740",
    "end": "1364299"
  },
  {
    "text": "But if you're thinking about a\ncausal inference type problem, where there's a notion of\ndifferent intervention groups,",
    "start": "1364300",
    "end": "1372250"
  },
  {
    "text": "then you'd be expected to\nreport the same sorts of things, but for both the\ncase population, the people who received,\nlet's say, treatment one,",
    "start": "1372250",
    "end": "1378750"
  },
  {
    "text": "and the control\npopulation of people who receive treatment zero. And then you would be\nlooking at differences",
    "start": "1378750",
    "end": "1383940"
  },
  {
    "text": "between those populations as\nwell at the individual feature level as part of the descriptive\nstatistics for that study.",
    "start": "1383940",
    "end": "1393080"
  },
  {
    "text": "Now, this-- yeah. AUDIENCE: Is this to\nidentify [? individually ?]",
    "start": "1393080",
    "end": "1399030"
  },
  {
    "text": "[? between ?] those peoples? [INAUDIBLE] institutions to do\nlike t-tests on those tables--",
    "start": "1399030",
    "end": "1404225"
  },
  {
    "text": "DAVID SONTAG: To see\nif they're different? No, so they're always\ngoing to be different. You go to a new\ninstitution, it's always going to look different.",
    "start": "1404225",
    "end": "1411340"
  },
  {
    "text": "And so just looking to see\nhow something changed is not-- the answer's always\ngoing to be yes.",
    "start": "1411340",
    "end": "1417750"
  },
  {
    "text": "But it enables a conversation\nto think through, OK, this, and then you might look--",
    "start": "1417750",
    "end": "1423330"
  },
  {
    "text": "you might use some\nof the techniques that Pete's going to talk about\nnext week on interpretability to understand, well, what\nis the model actually using.",
    "start": "1423330",
    "end": "1429330"
  },
  {
    "text": "Then you might\nask, oh, OK, well, the model is using\nthis thing, which makes sense in this population\nbut might not make sense",
    "start": "1429330",
    "end": "1435480"
  },
  {
    "text": "in another population. And it's these two\nthings together that make the conversation. ",
    "start": "1435480",
    "end": "1444130"
  },
  {
    "text": "Now, this question\nhas really come to the forefront in recent\nyears in close connection",
    "start": "1444130",
    "end": "1453820"
  },
  {
    "text": "to the topic that Pete\ndiscussed last week on fairness in machine learning. Because you might ask\nif a classifier is built",
    "start": "1453820",
    "end": "1460495"
  },
  {
    "text": "in some population, is\nit going to generalize to another population if that\npopulation that has learned on was very biased, for\nexample, it might",
    "start": "1460495",
    "end": "1466540"
  },
  {
    "text": "have been all white people. You might ask, is\nthat classifier going to work well in another\npopulation that might perhaps",
    "start": "1466540",
    "end": "1471730"
  },
  {
    "text": "include people of\ndifferent ethnicities? And so that has led to a concept\nwhich was recently published.",
    "start": "1471730",
    "end": "1481810"
  },
  {
    "start": "1473000",
    "end": "1698000"
  },
  {
    "text": "This working draft that I'm\nshowing the abstract from was just a few weeks ago called\n\"Datasheets for data sets.\"",
    "start": "1481810",
    "end": "1490330"
  },
  {
    "text": "And the goal here\nis to standardize the process of\ndescribing-- of eliciting the information about what is it\nabout the data set that really",
    "start": "1490330",
    "end": "1498130"
  },
  {
    "text": "played into your model?",
    "start": "1498130",
    "end": "1503630"
  },
  {
    "text": "And so I'm going to walk\nyou through very briefly just through a\ncouple of elements of what an example data set for\na datasheet might look like.",
    "start": "1503630",
    "end": "1513440"
  },
  {
    "text": "This is too small\nfor you to read, but I'll blow up one\nsection in just a second. So this is a\ndatasheet for a data",
    "start": "1513440",
    "end": "1521620"
  },
  {
    "text": "set called Studying Face\nRecognition in an Unconstrained Environment. So it's for computer\nvision problem.",
    "start": "1521620",
    "end": "1528738"
  },
  {
    "text": "There are going to be a\nnumber of questionnaires, which this paper that I\npoint you to outlines. And you as the model developer\ngo through that questionnaire",
    "start": "1528738",
    "end": "1538330"
  },
  {
    "text": "and fill out the\nanswers to it, so including things about\nmotivation for the data",
    "start": "1538330",
    "end": "1543850"
  },
  {
    "text": "set creation\ncomposition and so on. So in this particular instance,\nthis data set called Labeled",
    "start": "1543850",
    "end": "1551170"
  },
  {
    "text": "Faces in the Wild was created to\nprovide images that study face recognition in an unconstrained\n[INAUDIBLE] settings,",
    "start": "1551170",
    "end": "1557470"
  },
  {
    "text": "where image characteristics\nsuch as pose, elimination, resolution, focus\ncannot be controlled.",
    "start": "1557470",
    "end": "1565450"
  },
  {
    "text": "So it's intended to be\nreal-world settings. Now, one of the most\ninteresting sections",
    "start": "1565450",
    "end": "1571930"
  },
  {
    "text": "of this report that one should\nrelease with the data set has to do with how was the\ndata preprocessed or cleaned?",
    "start": "1571930",
    "end": "1580059"
  },
  {
    "text": "So, for example,\nfor this data set, it walks through the\nfollowing process. First, raw images were\nobtained from the data set,",
    "start": "1580060",
    "end": "1588030"
  },
  {
    "text": "and it consisted of\nimages and captions that were found together with\nthat image in news articles",
    "start": "1588030",
    "end": "1595090"
  },
  {
    "text": "or around the web. Then there was a face detector\nthat was run on the data set.",
    "start": "1595090",
    "end": "1602080"
  },
  {
    "text": "Here were the parameters of the\nface detector that were used. And then remember, the goal\nhere is to study face detection.",
    "start": "1602080",
    "end": "1610240"
  },
  {
    "text": "And so-- so one has to\nknow, how were the--",
    "start": "1610240",
    "end": "1616210"
  },
  {
    "text": "how were the labels determined? And how would one, for\nexample, eliminate if there",
    "start": "1616210",
    "end": "1623110"
  },
  {
    "text": "was no face in this image? And so there they described\nhow a face was detected and how",
    "start": "1623110",
    "end": "1629230"
  },
  {
    "text": "a region was determined to not\nbe a face in the case that it wasn't. And finally, it describes\nhow duplicates were removed.",
    "start": "1629230",
    "end": "1636568"
  },
  {
    "text": "And if you think\nback to the examples we had earlier in the\nsemester from medical imaging,",
    "start": "1636568",
    "end": "1642340"
  },
  {
    "text": "for example in\npathology and radiology, similar data set constructions\nhad to be done there.",
    "start": "1642340",
    "end": "1648670"
  },
  {
    "text": "For example, one would\ngo to the PAC System where radiology images\nare stored, one would-- one would decide which images\nare going to be pulled out,",
    "start": "1648670",
    "end": "1657850"
  },
  {
    "text": "one would go to\nradiography reports to figure out how do we\nextract the relevant findings",
    "start": "1657850",
    "end": "1662894"
  },
  {
    "text": "from that image,\nwhich would give the labels for that predictive--\nfor that learning task.",
    "start": "1662895",
    "end": "1668410"
  },
  {
    "text": "And each step there will\nincur some bias and some-- which one then needs to\ndescribe carefully in order",
    "start": "1668410",
    "end": "1675580"
  },
  {
    "text": "to understand what\nmight the bias be of the learned classifier. So I won't go into more\ndetail on this now,",
    "start": "1675580",
    "end": "1683680"
  },
  {
    "text": "but this will also be\none of the suggested readings for today's course. And it's a fast read. I encourage you to go through\nit to get some tuition for what",
    "start": "1683680",
    "end": "1691330"
  },
  {
    "text": "are questions we might want\nto be asking about data sets that we create. ",
    "start": "1691330",
    "end": "1698172"
  },
  {
    "text": "And for the rest\nof this semester-- for the rest of the\nlecture today, I'm now going to move on to\nsome more technical issues.",
    "start": "1698172",
    "end": "1705390"
  },
  {
    "text": "So we have to do it. We're doing machine\nlearning now.",
    "start": "1705390",
    "end": "1712170"
  },
  {
    "text": "The populations\nmight be different. What do we do about it? Can we change the\nlearning algorithm in order to hope that your\nalgorithm might transfer better",
    "start": "1712170",
    "end": "1720420"
  },
  {
    "text": "to a new institution? Or if we get a little bit of\ndata from that new institution, could we use that\nsmall amount of data",
    "start": "1720420",
    "end": "1726840"
  },
  {
    "text": "from the new institution or a\nfuture time point in the future to retrain our model to\ndo well in that slightly",
    "start": "1726840",
    "end": "1734010"
  },
  {
    "text": "different distribution? So that's the whole field\nof transfer learning.",
    "start": "1734010",
    "end": "1739030"
  },
  {
    "text": "So you have data drawn from one\ndistribution on p of x and y, and maybe we have a little bit\nof data drawn from a different",
    "start": "1739030",
    "end": "1745950"
  },
  {
    "text": "distribution q of x,y. And under the covariate\nshift assumption,",
    "start": "1745950",
    "end": "1751260"
  },
  {
    "text": "I'm assuming that q(x,y) is\nequal to q of x times p of y",
    "start": "1751260",
    "end": "1763650"
  },
  {
    "text": "given x, namely that the\nconditional distribution of y given x hasn't changed. The only thing that\nmight have changed",
    "start": "1763650",
    "end": "1769860"
  },
  {
    "text": "is your distribution over x. So that's what the covariate\nshift assumption would assume.",
    "start": "1769860",
    "end": "1775550"
  },
  {
    "text": " So suppose that we\nhave some small amount",
    "start": "1775550",
    "end": "1782850"
  },
  {
    "text": "of data drawn from the\nnew distribution q. How could we then\nuse that in order",
    "start": "1782850",
    "end": "1788670"
  },
  {
    "text": "to perhaps retrain our\nclassifier to do well for that new institution?",
    "start": "1788670",
    "end": "1795390"
  },
  {
    "text": "So I'll walk through four\ndifferent approaches to do so. I'll start with\nlinear models, which",
    "start": "1795390",
    "end": "1802020"
  },
  {
    "text": "are the simplest to\nunderstand, and then I'll move on to deep models.",
    "start": "1802020",
    "end": "1809740"
  },
  {
    "start": "1808000",
    "end": "1993000"
  },
  {
    "text": "The first approach to something\nthat you've seen already several times in this course. We're going to\nthink about transfer",
    "start": "1809740",
    "end": "1817770"
  },
  {
    "text": "as a multi-task learning\nproblem, where one of the tasks has much less data\nthan the other task.",
    "start": "1817770",
    "end": "1826012"
  },
  {
    "text": "So if you remember when\nwe talked about disease progression modeling,\nI introduced",
    "start": "1826012",
    "end": "1831750"
  },
  {
    "text": "this notion of\nregularizing the weight vectors so that they could\nbe close to one another.",
    "start": "1831750",
    "end": "1837947"
  },
  {
    "text": "At that time, we were\ntalking about weight vectors predicting disease\nprogression in different time points in the future.",
    "start": "1837947",
    "end": "1843030"
  },
  {
    "text": "We could use exactly\nthe same idea here, where you take your classifier,\nyour linear classifier that",
    "start": "1843030",
    "end": "1850950"
  },
  {
    "text": "was trained on a\nreally large corpus, I'm going to call that-- I'm going to call the weights\nof that classifier w old,",
    "start": "1850950",
    "end": "1857460"
  },
  {
    "text": "and then I'm going to solve a\nnew optimization problem, which is minimizing over the weights\nw that minimizes some loss.",
    "start": "1857460",
    "end": "1868030"
  },
  {
    "text": "So this is where your training--\nyour new training data come in. ",
    "start": "1868030",
    "end": "1882690"
  },
  {
    "text": "So I'm going to assume that\nthe new training get D is drawn from the q distribution.",
    "start": "1882690",
    "end": "1889140"
  },
  {
    "text": " And I'm going to add on a\nregularization that asks that w",
    "start": "1889140",
    "end": "1898360"
  },
  {
    "text": "should stay close to w old. ",
    "start": "1898360",
    "end": "1904390"
  },
  {
    "text": "Now, if the amount of\ndata you have-- if D, the data from that new\ninstitution, was very large,",
    "start": "1904390",
    "end": "1911710"
  },
  {
    "text": "then you wouldn't need this at\nall because you would be able",
    "start": "1911710",
    "end": "1918510"
  },
  {
    "text": "to just-- you would be able to ignore\nthe classifier that you learned previously and just\nrefit everything",
    "start": "1918510",
    "end": "1924600"
  },
  {
    "text": "to that new institution's data. Where something like this\nis particularly valuable is if there was a small\namount of data set shift,",
    "start": "1924600",
    "end": "1932279"
  },
  {
    "text": "and you only have a very\nsmall amount of labeled data from that new\ninstitution, then this",
    "start": "1932280",
    "end": "1937860"
  },
  {
    "text": "would allow you to\nchange your weight vector just a little bit. So if this coefficient\nwas very large,",
    "start": "1937860",
    "end": "1944340"
  },
  {
    "text": "it would say that\nthe new w can't be too far from the old w. So it'll allow you to\nshift things a little bit",
    "start": "1944340",
    "end": "1951300"
  },
  {
    "text": "in order to do well on the small\namount of data that you have. So, for example, if there is\na feature which was previously",
    "start": "1951300",
    "end": "1958350"
  },
  {
    "text": "predictive, but that\nfeature is no longer present in the new data\nset, so, for example, it's all identically zero,\nthen, of course, the new weight",
    "start": "1958350",
    "end": "1965289"
  },
  {
    "text": "vect-- the new weight for that feature\nis going to be set to 0, and that weight\nyou can think about",
    "start": "1965290",
    "end": "1970350"
  },
  {
    "text": "as being redistributed to\nsome of the other features. Does this makes sense? Any questions?",
    "start": "1970350",
    "end": "1975552"
  },
  {
    "text": " So this is the simplest\napproach to transfer learning.",
    "start": "1975552",
    "end": "1982200"
  },
  {
    "text": "And before you ever try\nanything more complicated, always try this. ",
    "start": "1982200",
    "end": "1992074"
  },
  {
    "text": "Uh, yep.  So the second approach is\nalso with a linear model,",
    "start": "1992074",
    "end": "2005130"
  },
  {
    "text": "but here we're no longer going\nto assume that the features are still useful.",
    "start": "2005130",
    "end": "2010830"
  },
  {
    "text": "So there might--\nwhen you go from-- when you go from a--",
    "start": "2010830",
    "end": "2017539"
  },
  {
    "text": "your first institution, let's\nsay, I'm GH on the left, you learn your model,\nand you can apply it",
    "start": "2017540",
    "end": "2022940"
  },
  {
    "text": "to some new institution,\nlet's say, UCSF on the right, it could be that there\nis some really big change",
    "start": "2022940",
    "end": "2029960"
  },
  {
    "text": "in the feature set such that-- such that the original\nfeatures are not at all",
    "start": "2029960",
    "end": "2036110"
  },
  {
    "text": "useful for the new feature set. And a really extreme\nexample of that",
    "start": "2036110",
    "end": "2041570"
  },
  {
    "text": "might be the setting that\nI gave earlier when I said, your model's trained on English,\nand you're testing it out",
    "start": "2041570",
    "end": "2046700"
  },
  {
    "text": "in Chinese. That would be an example-- if you use a bag of\nwords model, that would be an example where\nyour model, obviously,",
    "start": "2046700",
    "end": "2054290"
  },
  {
    "text": "wouldn't generalize at all\nbecause your features are completely different.",
    "start": "2054290",
    "end": "2061219"
  },
  {
    "text": "So what would you\ndo in that setting? What's the simplest\nthing that you might do? ",
    "start": "2061219",
    "end": "2070300"
  },
  {
    "text": "So you're taking a text\nclassifier learned in English, and you want to\napply it in a setting where that language is Chinese.",
    "start": "2070300",
    "end": "2076840"
  },
  {
    "text": "What would you do? AUDIENCE: Train on them. DAVID SONTAG:\nTranslate, you said. And there was another answer.",
    "start": "2076840",
    "end": "2082645"
  },
  {
    "text": "AUDIENCE: Or try train an RN. DAVID SONTAG: Train\nan RN to do what? AUDIENCE: To translate.",
    "start": "2082645",
    "end": "2088075"
  },
  {
    "text": "DAVID SONTAG: Train\nan RN-- oh, OK. So assume that you\nhave some ability",
    "start": "2088075",
    "end": "2093190"
  },
  {
    "text": "to do machine translation, you\ntranslate from English to-- from Chinese to English. It has to be that direction\nbecause the original classifier",
    "start": "2093190",
    "end": "2100068"
  },
  {
    "text": "was trained in English. And then your new function\nis the composition of the translation and the\noriginal function, right?",
    "start": "2100068",
    "end": "2108640"
  },
  {
    "text": "And then you can\nimagine doing some fine tuning if you had a\nsmall amount of data.",
    "start": "2108640",
    "end": "2114100"
  },
  {
    "text": "Now, the simplest\ntranslation function",
    "start": "2114100",
    "end": "2119380"
  },
  {
    "text": "might be just use a dictionary. So you look up a\nword, and if that word has an analogy in\nanother language,",
    "start": "2119380",
    "end": "2125680"
  },
  {
    "text": "you say, OK, this\nis the translation. But there are always going to\nbe some words in your language which don't have a\nvery good translation.",
    "start": "2125680",
    "end": "2133835"
  },
  {
    "text": "And so you might imagine that\nthe simplest approach would be to translate, but\nthen to just drop out",
    "start": "2133835",
    "end": "2138970"
  },
  {
    "text": "words that don't\nhave a good analog and force your classifier\nto work with, let's say,",
    "start": "2138970",
    "end": "2146950"
  },
  {
    "text": "just the shared vocabulary. Everything we're\ntalking about here is an example of a\nmanually chosen decision.",
    "start": "2146950",
    "end": "2154339"
  },
  {
    "text": "So we're going to manually\nchoose a new representation for the data such that we\nhave some amount of shared",
    "start": "2154340",
    "end": "2161740"
  },
  {
    "text": "features between the source\nand target data sets. ",
    "start": "2161740",
    "end": "2168320"
  },
  {
    "start": "2168000",
    "end": "2483000"
  },
  {
    "text": "So let's talk about\nelectronic health record 1 and electronic health record 2. By the way, the slides that\nI'll be presenting here",
    "start": "2168320",
    "end": "2174339"
  },
  {
    "text": "are from a paper\npublished in KDD by Jan, Tristan, your\ninstructor, Pete,",
    "start": "2174340",
    "end": "2181570"
  },
  {
    "text": "and John Guttag. So you have to go\ntwo electronic health records, electronic\nhealth record 1,",
    "start": "2181570",
    "end": "2187210"
  },
  {
    "text": "electronic health record 2. How can things change? Well, it could be that the same\nconcept in electronic health",
    "start": "2187210",
    "end": "2196900"
  },
  {
    "text": "record 1 might be mapped\nto a different encoding, so that's like an\nEnglish-to-Spanish type",
    "start": "2196900",
    "end": "2203470"
  },
  {
    "text": "translation, in electronic\nhealth record 2. Another example\nof a change might",
    "start": "2203470",
    "end": "2208810"
  },
  {
    "text": "be to say that some concepts\nare removed, like maybe you",
    "start": "2208810",
    "end": "2215410"
  },
  {
    "text": "have laboratory test results\nin electronic health record 1 but not in electronic\nhealth record 2. So that's why you see\nan edge to nowhere.",
    "start": "2215410",
    "end": "2223120"
  },
  {
    "text": "Another change might be\nthere might be new concepts. So the new institution\nmight have new types of data",
    "start": "2223120",
    "end": "2230050"
  },
  {
    "text": "that the old\ninstitution didn't have. So what do you do\nin that setting? Well, one approach\nwe would say, OK, we",
    "start": "2230050",
    "end": "2237880"
  },
  {
    "text": "have some small amount of\ndata from electronic health record 2. We could just train\nusing that and throw away",
    "start": "2237880",
    "end": "2245890"
  },
  {
    "text": "your original data from\nelectronic health record 1. Now, of course, if you\nonly had a small amount",
    "start": "2245890",
    "end": "2250960"
  },
  {
    "text": "of data from the target\nto distribution, then that's going to be a very poor\napproach because you might not",
    "start": "2250960",
    "end": "2256300"
  },
  {
    "text": "have enough data\nto actually learn a reasonable enough model. A second obvious\napproach would be,",
    "start": "2256300",
    "end": "2261520"
  },
  {
    "text": "OK, we're going to just train\non electronic health record 1",
    "start": "2261520",
    "end": "2267250"
  },
  {
    "text": "and apply it. And for those concepts that\naren't present anymore,",
    "start": "2267250",
    "end": "2272930"
  },
  {
    "text": "so be it. Maybe things won't\nwork very well. A third approach, which we\nwere alluding to before when",
    "start": "2272930",
    "end": "2278320"
  },
  {
    "text": "we talked about\ntranslation, would be to learn a model just in\nthe intersection of the two features.",
    "start": "2278320",
    "end": "2283780"
  },
  {
    "text": "And what this work\ndoes, as they say, we're going to manually\nredefine the feature set",
    "start": "2283780",
    "end": "2289300"
  },
  {
    "text": "in order to try to find as\nmuch common ground as possible. And this is something\nwhich really involves",
    "start": "2289300",
    "end": "2294730"
  },
  {
    "text": "a lot of domain knowledge. And I'm going to be using\nthis as a point of contrast",
    "start": "2294730",
    "end": "2300190"
  },
  {
    "text": "from what I'll be talking about\nin 10 or 15 minutes, where I talk about how one could\ndo this without that domain",
    "start": "2300190",
    "end": "2305855"
  },
  {
    "text": "knowledge that we're\ngoing to use here. ",
    "start": "2305855",
    "end": "2311060"
  },
  {
    "text": "So the setting\nthat they looked at is one of predicting outcomes,\nsuch as in-hospital mortality",
    "start": "2311060",
    "end": "2317720"
  },
  {
    "text": "or length of stay. The model which is going to be\nused as a bag-of-events model.",
    "start": "2317720",
    "end": "2323840"
  },
  {
    "text": "So we will take a patient's\nlongitudinal history up until the time of prediction.",
    "start": "2323840",
    "end": "2329330"
  },
  {
    "text": "We'll look at different\nevents that occurred. And this study was\ndone using PhysioNet.",
    "start": "2329330",
    "end": "2337279"
  },
  {
    "text": "And MIMIC, for example, events\nare encoded with some number, like 5814 might\ncorrespond to a CVP alarm,",
    "start": "2337280",
    "end": "2344810"
  },
  {
    "text": "1046 might correspond\nto pain being present, 25 might correspond to the drug\nheparin being given and so on.",
    "start": "2344810",
    "end": "2352619"
  },
  {
    "text": "So we're going to create one\nfeature for every event which has some number-- which is encoded\nwith some number.",
    "start": "2352620",
    "end": "2358310"
  },
  {
    "text": "And we'll just say\n1 if that event has occurred, 0 otherwise. So that's the representation\nfor a patient.",
    "start": "2358310",
    "end": "2366960"
  },
  {
    "text": "Now, because when one goes\nthough this new institution, EHR2, the way that\nevents are encoded",
    "start": "2366960",
    "end": "2374790"
  },
  {
    "text": "might be completely different. One won't be able to just\nuse the original feature representation.",
    "start": "2374790",
    "end": "2380090"
  },
  {
    "text": "And that's the\nEnglish-to-Spanish example that I gave. But instead, what\none could try to do is come up with a new feature\nset where that feature",
    "start": "2380090",
    "end": "2388770"
  },
  {
    "text": "set could be derived from each\nof the different data sets. So, for example, since each\none of the events in MIMIC",
    "start": "2388770",
    "end": "2397680"
  },
  {
    "text": "has some text\ndescription that goes with it, event one corresponds\nto ischemic stroke,",
    "start": "2397680",
    "end": "2403349"
  },
  {
    "text": "event 2, hemorrhagic\nstroke, and so on, one could attempt to map--",
    "start": "2403350",
    "end": "2408420"
  },
  {
    "text": "use that English\ndescription of the feature to come up with a way to map\nit into a common language.",
    "start": "2408420",
    "end": "2415350"
  },
  {
    "text": "In this case, the\ncommon language is the UMLS, the\nUnited Medical Language",
    "start": "2415350",
    "end": "2420990"
  },
  {
    "text": "System that Pete talked\nabout a few lectures ago. So we're going to now say, OK,\nwe have a much larger feature",
    "start": "2420990",
    "end": "2426750"
  },
  {
    "text": "set where we've now\nencoded ischemic stroke as this concept,\nwhich is actually",
    "start": "2426750",
    "end": "2434700"
  },
  {
    "text": "the same ischemic\nstroke, but also as this concept\nand that concept,",
    "start": "2434700",
    "end": "2440460"
  },
  {
    "text": "which are more general\nversions of that original one. So this is just\ngeneral stroke, and it",
    "start": "2440460",
    "end": "2446310"
  },
  {
    "text": "could be multiple\ndifferent types of strokes. And the hope is\nthat even if in--",
    "start": "2446310",
    "end": "2453510"
  },
  {
    "text": "even if the model doesn't-- even if some of these\nmore specific ones don't show up in the\nnew institution's data,",
    "start": "2453510",
    "end": "2459900"
  },
  {
    "text": "perhaps some of the more general\nconcepts do show up there. And then what you're\ngoing to do is",
    "start": "2459900",
    "end": "2465890"
  },
  {
    "text": "you're going to learn your model\nnow on this expanded translated",
    "start": "2465890",
    "end": "2471569"
  },
  {
    "text": "vocabulary, and\nthen translate it. And at the new\ninstitution, you'll also be using that\nsame common data model.",
    "start": "2471570",
    "end": "2478600"
  },
  {
    "text": "And that way one hopes\nto have much more overlap in your feature set. And so to evaluate\nthis, the authors",
    "start": "2478600",
    "end": "2487770"
  },
  {
    "start": "2483000",
    "end": "2853000"
  },
  {
    "text": "looked at two different\ntime points within MIMIC. One time point was when the\nBeth Israel Deaconess Medical",
    "start": "2487770",
    "end": "2496349"
  },
  {
    "text": "Center was using electronic\nhealth record called CareView. And the second time point\nwas when that hospital",
    "start": "2496350",
    "end": "2501655"
  },
  {
    "text": "was using a different\nelectronic health record called MetaVision. So this is an example\nactually of non-stationarity.",
    "start": "2501655",
    "end": "2509670"
  },
  {
    "text": "Now because of them using two\ndifferent electronic health records, the encodings\nwere different.",
    "start": "2509670",
    "end": "2515790"
  },
  {
    "text": "And that's why\nthis problem arose. And so we're going\nto use this approach, and we're going to then\nlearn a linear model",
    "start": "2515790",
    "end": "2522270"
  },
  {
    "text": "on top of this new encoding\nthat I just described. And we're going to compare the\nresults by looking at how much",
    "start": "2522270",
    "end": "2532140"
  },
  {
    "text": "performance was lost due\nto using this new encoding, and how well we\ngeneralize from one--",
    "start": "2532140",
    "end": "2539110"
  },
  {
    "text": "from one-- from the source\ntask to the target task.",
    "start": "2539110",
    "end": "2546111"
  },
  {
    "text": "And so here's the\nfirst question, which is, how much do we lose\nby using this new encoding?",
    "start": "2546111",
    "end": "2552329"
  },
  {
    "text": "So as a comparison\npoint for looking at predicting in-hospital\nmortality, we'll look at, what is the\npredictive performance",
    "start": "2552330",
    "end": "2558390"
  },
  {
    "text": "if you're to just use an\nexisting, very simple risk score called the SAPS score?",
    "start": "2558390",
    "end": "2565049"
  },
  {
    "text": "And that's this red line\nwhere that y-axis here is the area under the\nROC curve, and the x-axis",
    "start": "2565050",
    "end": "2571500"
  },
  {
    "text": "is how much time\nin advance you're predicting, so the\nprediction gap. So using this very simple score,\nSAPS get somewhere between 0.75",
    "start": "2571500",
    "end": "2581520"
  },
  {
    "text": "and 0.80, area\nunder the ROC curve. But if you were to use all\nof the events data, which",
    "start": "2581520",
    "end": "2588900"
  },
  {
    "text": "is much, much richer than what\nwent into that simple SAPS score, you would get the\npurple curve, which is--",
    "start": "2588900",
    "end": "2596310"
  },
  {
    "text": "the purple curve, which is\nSAPS plus the event data, or the blue curve, which\nis just the events data.",
    "start": "2596310",
    "end": "2602371"
  },
  {
    "text": "And you can see you\ncan get substantially better predictive\nperformance by using that much richer feature set.",
    "start": "2602372",
    "end": "2608638"
  },
  {
    "text": "The SAPS score has the\nadvantage that it's easier to generalize because it's so\nsimple, those feature elements,",
    "start": "2608638",
    "end": "2614579"
  },
  {
    "text": "one could trivially translate\nto any new EHR, either manually or automatically, and thus\nit'll always be a viable route.",
    "start": "2614580",
    "end": "2623220"
  },
  {
    "text": "Whereas this blue\ncurve, although it gets better predictive\nperformance, you have to really worry about\nthese generalization questions.",
    "start": "2623220",
    "end": "2629490"
  },
  {
    "text": " And the same story happens\nin both of the source",
    "start": "2629490",
    "end": "2636030"
  },
  {
    "text": "task and the target task. Now the second question\nto ask is, well, how much do you lose when you\nuse the new representation",
    "start": "2636030",
    "end": "2643650"
  },
  {
    "text": "of the data? And so here looking at,\nagain, both of the two--",
    "start": "2643650",
    "end": "2649290"
  },
  {
    "text": "both EHRs, what we\nsee first in red is the same red curvature-- is\nthe same as the blue curvature",
    "start": "2649290",
    "end": "2657733"
  },
  {
    "text": "on the previous slide. It's using SAPS plus the item\nIDs, so using all of the data.",
    "start": "2657733",
    "end": "2663549"
  },
  {
    "text": "And then the blue curve here,\nwhich is a bit hard to see, but it's right there,\nit's substantially lower.",
    "start": "2663550",
    "end": "2669150"
  },
  {
    "text": "So that's what\nhappens if you now use this new representation. And you see that you\ndo lose something",
    "start": "2669150",
    "end": "2676340"
  },
  {
    "text": "by trying to find a\ncommon vocabulary. The performance\ndoes get hit a bit.",
    "start": "2676340",
    "end": "2684780"
  },
  {
    "text": "But what's particularly\ninteresting is when you attempt to generalize,\nyou start to see a swap.",
    "start": "2684780",
    "end": "2692450"
  },
  {
    "text": "So if we now-- so now the colors are\ngoing to be quite similar.",
    "start": "2692450",
    "end": "2699859"
  },
  {
    "text": "Red here was at the\nvery top before. So red is using the original\nrepresentation of the data.",
    "start": "2699860",
    "end": "2707480"
  },
  {
    "text": "Before it was at the very top. Shown here is the training error\non this institution, CareView.",
    "start": "2707480",
    "end": "2715640"
  },
  {
    "text": "You see, there's so\nmuch rich information in the original\nfeature set that it's able to do very good\npredictive performance.",
    "start": "2715640",
    "end": "2721313"
  },
  {
    "text": "But once you attempt\nto translate it, so you train on CareView,\nbut you test on MetaVision,",
    "start": "2721313",
    "end": "2728270"
  },
  {
    "text": "then the test performance shown\nhere by this solid red line is actually the worst\nof all of the system.",
    "start": "2728270",
    "end": "2734190"
  },
  {
    "text": "So there's a substantial\ndrop in performance because not all\nof these features are present in the new EHR.",
    "start": "2734190",
    "end": "2741230"
  },
  {
    "text": "On the other hand, when\nthe translated version, despite the fact that it's\na little bit worse when",
    "start": "2741230",
    "end": "2749540"
  },
  {
    "text": "evaluated on the source,\nit generalizes much better. And so you see a significantly\nbetter performance",
    "start": "2749540",
    "end": "2756170"
  },
  {
    "text": "that's shown by this\nblue curve here when you use this translated vocabulary. There's a question.",
    "start": "2756170",
    "end": "2761840"
  },
  {
    "text": "AUDIENCE: So would you\ntrain with full features? So how do you apply [? with ?]\nthem if the other [? full ?]",
    "start": "2761840",
    "end": "2768430"
  },
  {
    "text": "features are-- you\njust [INAUDIBLE].. DAVID SONTAG: So, you\nassume that you have come up",
    "start": "2768430",
    "end": "2774860"
  },
  {
    "text": "with a mapping from the\nfeatures in both of the EHRs to this common feature\nvocabulary of QEs.",
    "start": "2774860",
    "end": "2783994"
  },
  {
    "text": "And the way that this mapping is\ngoing to be done in this paper is based on the text of the--",
    "start": "2783995",
    "end": "2789188"
  },
  {
    "text": " of the events.",
    "start": "2789188",
    "end": "2794480"
  },
  {
    "text": "So you take the text-based\ndescription of the event, and you come up with a\ndeterministic mapping to this new UMLS-based\nrepresentation.",
    "start": "2794480",
    "end": "2803089"
  },
  {
    "text": "And then that's\nwhat's being used. There's no fine\ntuning being done in this particular example. ",
    "start": "2803090",
    "end": "2811109"
  },
  {
    "text": "So I consider this to be a very\nnaive application of transfer.",
    "start": "2811110",
    "end": "2816530"
  },
  {
    "text": "The results are exactly what you\nwould expect the results to be. And, obviously, a lot of work\nhad to go into doing this.",
    "start": "2816530",
    "end": "2823820"
  },
  {
    "text": "And there's a bit of creativity\nin thinking that you should use the English-based\ndescription of the features to come up with the\nautomatic mapping,",
    "start": "2823820",
    "end": "2830023"
  },
  {
    "text": "but the story ends there. And so a question\nwhich all of you",
    "start": "2830023",
    "end": "2836480"
  },
  {
    "text": "might have is, how\ncould you try to do such an approach automatically? How could we automatically\nfind representations-- new",
    "start": "2836480",
    "end": "2843020"
  },
  {
    "text": "representations of\nthe data that are likely to generalize\nfrom, let's say, a source distribution to\na target distribution?",
    "start": "2843020",
    "end": "2849970"
  },
  {
    "text": "And so to talk about\nthat, we're going to now start thinking\nthrough representation learning-based approaches,\nof which deep models are",
    "start": "2849970",
    "end": "2857060"
  },
  {
    "start": "2853000",
    "end": "3060000"
  },
  {
    "text": "particularly capable. So the simplest approach to\ntry to do transfer learning",
    "start": "2857060",
    "end": "2863930"
  },
  {
    "text": "in the context of, let's\nsay, deep neural networks, would be to just chop off part\nof the network and reuse that--",
    "start": "2863930",
    "end": "2872330"
  },
  {
    "text": "some internal representation of\nthe data in this new location. So the picture looks a\nlittle bit like this.",
    "start": "2872330",
    "end": "2879990"
  },
  {
    "text": "So the data might\nfeed in the bottom. There might be a number\nof convolutional layers, some fully connected layers.",
    "start": "2879990",
    "end": "2885782"
  },
  {
    "text": "And what you decide\nto do is you're going to take this model that's\ntrained in one institution, you chop it at some layer,\nit might be, for example,",
    "start": "2885782",
    "end": "2894930"
  },
  {
    "text": "prior to the last\nfully connected layer, and then you're\ngoing to take that--",
    "start": "2894930",
    "end": "2900890"
  },
  {
    "text": "take the new representation\nof your data, now the representation\nof the data is what you would get out\nafter doing some convolutions",
    "start": "2900890",
    "end": "2909589"
  },
  {
    "text": "followed by a single\nfully connected layer, and then you're going to take\nyour target distribution's",
    "start": "2909590",
    "end": "2916160"
  },
  {
    "text": "data, which you might only\nhave a small amount of, and you learn a simple model on\ntop of that new representation.",
    "start": "2916160",
    "end": "2921660"
  },
  {
    "text": "So, for example, you might\nlearn a shallow classifier using a support\nvector machine on top of that new representation. Or you might add in some more--",
    "start": "2921660",
    "end": "2930160"
  },
  {
    "text": "a couple more layers of a deep\nneural network, and then fine tune the whole thing end to end. So all of these have been tried.",
    "start": "2930160",
    "end": "2936410"
  },
  {
    "text": "And in some cases, one\nworks better than another. And we saw already one example\nof this notion in this course.",
    "start": "2936410",
    "end": "2945590"
  },
  {
    "text": "And that was when Adam\nYala spoke in lecture 13 about breast cancer\nand mammography,",
    "start": "2945590",
    "end": "2954440"
  },
  {
    "text": "where in his approach he\nsaid that he had tried both",
    "start": "2954440",
    "end": "2959660"
  },
  {
    "text": "taking a randomly\ninitialized classifier",
    "start": "2959660",
    "end": "2965030"
  },
  {
    "text": "and comparing that to what\nwould happen if you initialized with a well-known\nImageNet-based deep neural",
    "start": "2965030",
    "end": "2972560"
  },
  {
    "text": "network for the problem. And he had a really\ninteresting story that he gave. In his case, he had enough\ndata that he actually",
    "start": "2972560",
    "end": "2982190"
  },
  {
    "text": "didn't need to initialize\nusing this pre-trained model from ImageNet.",
    "start": "2982190",
    "end": "2988250"
  },
  {
    "text": "If he had just done a random\ninitialization, eventually-- and this x-axis,\nI can't remember,",
    "start": "2988250",
    "end": "2993590"
  },
  {
    "text": "it might be hours of training\nor epochs, I don't remember, it's time--",
    "start": "2993590",
    "end": "2998600"
  },
  {
    "text": "eventually the\nright initialization gets to a very\nsimilar performance. But for his particular\ncase, if you",
    "start": "2998600",
    "end": "3004540"
  },
  {
    "text": "were to do a initialization with\nImageNet and then fine tune, you get there\nmuch, much quicker.",
    "start": "3004540",
    "end": "3010940"
  },
  {
    "text": "And so it was for the\ncomputational reason that he found it to be useful. But in many other applications\nin medical imaging,",
    "start": "3010940",
    "end": "3017290"
  },
  {
    "text": "the same tricks become\nessential because you just don't have enough data\nin the new test case. And so one makes use of,\nfor example, the filters",
    "start": "3017290",
    "end": "3025660"
  },
  {
    "text": "which one learns from an\nImageNet's task, which is dramatically different from\nthe medical imaging problems,",
    "start": "3025660",
    "end": "3033010"
  },
  {
    "text": "and then using those\nsame filters together with a new top layer,\nset of top layers in order to fine tune it for\nthe problem that you care about.",
    "start": "3033010",
    "end": "3041265"
  },
  {
    "text": "So this would be\nthe simplest way to try to hope for a common\nrepresentation for transfer",
    "start": "3041265",
    "end": "3046990"
  },
  {
    "text": "in a deep architecture. But you might ask, how would\nyou do the same sort of thing",
    "start": "3046990",
    "end": "3052480"
  },
  {
    "text": "with temporal data, not\nimage data, maybe data that's from language, or data\nfrom time series of health",
    "start": "3052480",
    "end": "3060010"
  },
  {
    "start": "3060000",
    "end": "3599000"
  },
  {
    "text": "insurance claims? And for that you\nreally want to be thinking about recurrent\nneural networks.",
    "start": "3060010",
    "end": "3065420"
  },
  {
    "text": "So just to remind you,\nrecurrent neural network is a recurrent\narchitecture where you take as input some vector.",
    "start": "3065420",
    "end": "3071852"
  },
  {
    "text": "For example, if you're\ndoing language modeling, that vector might be encoding,\njust a one-hot encoding of what is the word at that location.",
    "start": "3071852",
    "end": "3077810"
  },
  {
    "text": "So, for example, this\nvector might be all zeros, except for the fourth\ndimension, which is a 1, denoting that this word\nis the word, quote, \"class.\"",
    "start": "3077810",
    "end": "3084970"
  },
  {
    "text": "And then it's fed into\na recurrent unit, which takes the previous\nhidden state, combined it",
    "start": "3084970",
    "end": "3092117"
  },
  {
    "text": "with the current input, and\ngets you a new hidden state. And in this way, you read in--\nyou encode the full input.",
    "start": "3092117",
    "end": "3097990"
  },
  {
    "text": "And then you might predict-- make a classification\nbased on the hidden state of the last time\n[? step. ?] That",
    "start": "3097990",
    "end": "3103055"
  },
  {
    "text": "would be a common approach. And here would be a very simple\nexample of a recurrent unit. Here I'm using S to\ndenote in a state.",
    "start": "3103055",
    "end": "3109750"
  },
  {
    "text": "Often you will see H used\nto denote the hidden state. This is a particularly\nsimple example, where there's just a\nsingle non-linearity.",
    "start": "3109750",
    "end": "3116559"
  },
  {
    "text": "So you take your\nprevious hidden state, you hit it with some matrix Ws,s\nand you add that to the input",
    "start": "3116560",
    "end": "3126130"
  },
  {
    "text": "being hit by a different matrix. You now have a\ncombination of the input",
    "start": "3126130",
    "end": "3131500"
  },
  {
    "text": "plus the previous hidden state. You apply non-linearity\nto that, and you get your new hidden state out. So that would be an example\nof a typical recurrent unit,",
    "start": "3131500",
    "end": "3138940"
  },
  {
    "text": "a very simple recurrent unit. Now, the reason why I'm going\nthrough these details is to point out that the dimension\nof that Ws,x matrix is",
    "start": "3138940",
    "end": "3148570"
  },
  {
    "text": "the dimension of the hidden\nstate, so the dimension of s, by the vocabulary size if\nyou're using a one-hot encoding",
    "start": "3148570",
    "end": "3156430"
  },
  {
    "text": "of the input. So if you have a huge\nvocabulary, that matrix, Ws,x,",
    "start": "3156430",
    "end": "3162850"
  },
  {
    "text": "is also going to\nbe equally large. And the challenge\nthat that presents is that it would lead to\noverfitting on rare words",
    "start": "3162850",
    "end": "3172360"
  },
  {
    "text": "very quickly. And so that's a problem that\ncould be addressed by instead using a low-rank representation\nof that Ws,x matrix.",
    "start": "3172360",
    "end": "3183400"
  },
  {
    "text": "In particular, you could\nthink about introducing a lower dimensional bottleneck,\nwhich in this picture",
    "start": "3183400",
    "end": "3191619"
  },
  {
    "text": "I'm denoting as xt prime,\nwhich is your original xt",
    "start": "3191620",
    "end": "3197740"
  },
  {
    "text": "input, which is the\none-hot encoding, multiplied by a new matrix We. ",
    "start": "3197740",
    "end": "3204550"
  },
  {
    "text": "And then your recurrent\nunit only takes inputs of that hidden--",
    "start": "3204550",
    "end": "3210220"
  },
  {
    "text": "of that xt prime's\ndimension, which is k, which might be\ndramatically smaller than v.",
    "start": "3210220",
    "end": "3219340"
  },
  {
    "text": "And you can even think\nabout each column of that intermediate\nrepresentation, We,",
    "start": "3219340",
    "end": "3224590"
  },
  {
    "text": "as a word embedding. It's a way of-- and this is something that\nPete talked quite a bit",
    "start": "3224590",
    "end": "3231363"
  },
  {
    "text": "about when we were thinking\nabout natural language-- when we were talking about\nnatural language processing. And many of you would\nhave heard about it",
    "start": "3231363",
    "end": "3238690"
  },
  {
    "text": "in the context of\nthings like Word2Vec. So if one wanted to take\na setting, for example,",
    "start": "3238690",
    "end": "3248650"
  },
  {
    "text": "one institution's data where\nyou had a huge amount of data,",
    "start": "3248650",
    "end": "3254335"
  },
  {
    "text": "learn every current neural\nnetwork on that institution's data, and then generalize\nit to a new institution,",
    "start": "3254335",
    "end": "3259510"
  },
  {
    "text": "one way of trying to do\nthat, if you think about, what is the thing that you chop,\none answer might be, all you do",
    "start": "3259510",
    "end": "3265957"
  },
  {
    "text": "is you keep the word embedding. So you might say,\nOK, I'm going to keep the We's, I'm going to translate\nit back to my new institution.",
    "start": "3265958",
    "end": "3272980"
  },
  {
    "text": "But I'm going to let the\nrecurrent unit parameters-- the recurrent\nparameters, for example, that Ws,s you might allow it\nto be relearned for each new",
    "start": "3272980",
    "end": "3281380"
  },
  {
    "text": "institution. And so that might\nbe one approach of how to use the\nsame idea that we",
    "start": "3281380",
    "end": "3286720"
  },
  {
    "text": "had from feed forward networks\nwithin a recurrent setting.",
    "start": "3286720",
    "end": "3293530"
  },
  {
    "text": "Now, all of this\nis very general. And what I want to do\nnext is to instantiate it",
    "start": "3293530",
    "end": "3299890"
  },
  {
    "text": "a bit in the context\nof health care.",
    "start": "3299890",
    "end": "3305079"
  },
  {
    "text": "So since the time\nthat Pete presented the extensions of Word2Vec\nsuch as BERT and ELMo,",
    "start": "3305080",
    "end": "3315190"
  },
  {
    "text": "and I'm not going to-- I'm not going to\ngo into them now, but you can go back to Pete's\nlecture from a few weeks",
    "start": "3315190",
    "end": "3320290"
  },
  {
    "text": "ago to remind yourselves what\nthose were, since the time he presented that lecture,\nthere are actually three new papers\nthat actually tried",
    "start": "3320290",
    "end": "3326650"
  },
  {
    "text": "to apply this in the health\ncare context, one of which was from MIT.",
    "start": "3326650",
    "end": "3332680"
  },
  {
    "text": "And so these papers all\nhave the same sort of idea. They're going to\ntake some data set--",
    "start": "3332680",
    "end": "3339640"
  },
  {
    "text": "and these papers all use MIMIC. They're going to\ntake that text data,",
    "start": "3339640",
    "end": "3345369"
  },
  {
    "text": "they're going to learn\nsome word embeddings or some low-dimensional\nrepresentations",
    "start": "3345370",
    "end": "3350500"
  },
  {
    "text": "of all words in the vocabulary. In this case,\nthey're not learning a static representation\nfor each word.",
    "start": "3350500",
    "end": "3356290"
  },
  {
    "text": "Instead these BERT\nand ELMo approaches are going to be\nlearning-- well, you can think of it as\ndynamic representations.",
    "start": "3356290",
    "end": "3362329"
  },
  {
    "text": "They're going to be a\nfunction of the word and their context on the\nleft and right-hand sides. And then what they'll\ndo is they'll then",
    "start": "3362330",
    "end": "3368380"
  },
  {
    "text": "take those representations\nand attempt to use them for a completely new task. Those new tasks might\nbe on MIMIC data.",
    "start": "3368380",
    "end": "3377210"
  },
  {
    "text": "So, for example, these two tasks\nare classification problems on MIMIC. But they might also\nbe on non-MIMIC data.",
    "start": "3377210",
    "end": "3383210"
  },
  {
    "text": "So these two tasks are from\nclassification problems on clinical text that didn't\neven come from MIMIC at all.",
    "start": "3383210",
    "end": "3390830"
  },
  {
    "text": "So it's really an\nexample of translating what you learned\nfrom one institution to another institution. These two data sets\nwere super small.",
    "start": "3390830",
    "end": "3397450"
  },
  {
    "text": "Actually, all of these data\nsets were really, really small compared to the\noriginal size of MIMIC. So there might be some hope that\none could learn something that",
    "start": "3397450",
    "end": "3404725"
  },
  {
    "text": "really improves generalization. And indeed, that's\nwhat plays out. So all these tasks are looking\nat a concept detection task.",
    "start": "3404725",
    "end": "3413450"
  },
  {
    "text": "Given a clinical note,\nidentify the segments of text",
    "start": "3413450",
    "end": "3419240"
  },
  {
    "text": "within a note that\nrefer to, for example, a disorder, or a treatment,\nor something else, which",
    "start": "3419240",
    "end": "3424280"
  },
  {
    "text": "you then in a second stage\nmight normalize to the UMLS. ",
    "start": "3424280",
    "end": "3430790"
  },
  {
    "text": "So what's really striking\nabout these results is what happens when you go\nfrom the left to the right",
    "start": "3430790",
    "end": "3438589"
  },
  {
    "text": "column, which I'll\nexplain in a second, and what happens when\nyou go top to bottom across each one of\nthese different tasks.",
    "start": "3438590",
    "end": "3444810"
  },
  {
    "text": "So the left column\nare the results. And these results are\nan F score, the results,",
    "start": "3444810",
    "end": "3453230"
  },
  {
    "text": "if you were to use embeddings\ntrained on a non-clinical data",
    "start": "3453230",
    "end": "3459365"
  },
  {
    "text": "set, or said definitely, not\non MIMIC but on some other more general data set.",
    "start": "3459365",
    "end": "3464427"
  },
  {
    "text": "The second column\nis what would happen if you trained those embedding\non a clinical data set,",
    "start": "3464427",
    "end": "3469730"
  },
  {
    "text": "in this case, MIMIC. And you see pretty\nbig improvements from the general embeddings\nto the MIMIC-based embeddings.",
    "start": "3469730",
    "end": "3478550"
  },
  {
    "text": "What's even more striking\nis the improvements that happen as you get\nbetter and better embeddings.",
    "start": "3478550",
    "end": "3484190"
  },
  {
    "text": "So the first row are\nthe results if you were to use just\nWord2Vec embeddings.",
    "start": "3484190",
    "end": "3489380"
  },
  {
    "text": "And so, for example, for\nthe I2B2 Challenge in 2010,",
    "start": "3489380",
    "end": "3495470"
  },
  {
    "text": "you get 82.65 F score\nusing Word2Vec embeddings.",
    "start": "3495470",
    "end": "3500720"
  },
  {
    "text": "And if you use a very\nlarge BERT embedding, you get 90.25 F score--",
    "start": "3500720",
    "end": "3508010"
  },
  {
    "text": "F measure, which is\nsubstantially higher. And the same findings were\nfound time and time again",
    "start": "3508010",
    "end": "3514200"
  },
  {
    "text": "across different tasks. Now, what I find really\nstriking about these results",
    "start": "3514200",
    "end": "3519740"
  },
  {
    "text": "is that I had tried many of\nthese things a couple of years ago, not using BERT or\nELMo, but using Word2Vec,",
    "start": "3519740",
    "end": "3526039"
  },
  {
    "text": "and GloVe, and fastText. And what I found is that using\nword embedding approaches",
    "start": "3526040",
    "end": "3532550"
  },
  {
    "text": "for these problems didn't-- even if you threw that in as\nadditional features on top of other state-of-the-art\napproaches to this concept",
    "start": "3532550",
    "end": "3543109"
  },
  {
    "text": "extraction problem, it did not\nimprove predictive performance above the existing\nstate of the art.",
    "start": "3543110",
    "end": "3549050"
  },
  {
    "text": "However, in this\npaper, here they use the simplest\npossible algorithm. They used a recurrent\nneural network",
    "start": "3549050",
    "end": "3555710"
  },
  {
    "text": "fed into a conditional\nrandom field for the purpose of classifying\neach word into each",
    "start": "3555710",
    "end": "3561680"
  },
  {
    "text": "of these categories. And the feature\nrepresent-- the features that they used are just\nthese embedding features.",
    "start": "3561680",
    "end": "3568319"
  },
  {
    "text": "So with just the Word2Vec\nembedding features, the performance is crap. You don't get anywhere\nclose to the state of art.",
    "start": "3568320",
    "end": "3573740"
  },
  {
    "text": "But with the better embeddings,\nthey actually obtain-- actually, they improved\non the state of the art",
    "start": "3573740",
    "end": "3579440"
  },
  {
    "text": "for every single\none of these tasks. And that is without any\nof the manual feature",
    "start": "3579440",
    "end": "3586010"
  },
  {
    "text": "engineering which\nwe have been using in the field for\nthe last decade. So I find this to be\nextremely promising.",
    "start": "3586010",
    "end": "3594619"
  },
  {
    "text": "Now you might ask, well, that\nis for one problem, which is classification of concepts--\nor identification of concepts.",
    "start": "3594620",
    "end": "3604700"
  },
  {
    "text": "What about for a\npredictive problem? So a different paper\nalso published-- what month is it now, May--\nso last month in April,",
    "start": "3604700",
    "end": "3613670"
  },
  {
    "text": "looked at a predicted problem\nof 30-day readmission prediction using discharge summaries. This also was valued on MIMIC.",
    "start": "3613670",
    "end": "3620600"
  },
  {
    "text": "And their evaluation\nlooked at the area under the ROC curve of\ntwo different approaches.",
    "start": "3620600",
    "end": "3626609"
  },
  {
    "text": "The first approach, which is\nusing a bag-of-words model, like what you did in\nyour homework assignment,",
    "start": "3626610",
    "end": "3632090"
  },
  {
    "text": "and the second approach,\nwhich is the top row there, which is using BERT embeddings,\nwhich they call Clinical BERT.",
    "start": "3632090",
    "end": "3640640"
  },
  {
    "text": "And this, again, is\nsomething which I had tackled for quite a long time. So I worked on these types\nof readmission problems.",
    "start": "3640640",
    "end": "3646970"
  },
  {
    "text": "And bag-of-words model\nis really hard to beat. In fact, did any of you beat\nit in your homework assignment?",
    "start": "3646970",
    "end": "3654089"
  },
  {
    "text": "If you remember, there\nwas an extra question, which is, oh, well,\nmaybe if we used a deep learning-based\napproach for this problem,",
    "start": "3654090",
    "end": "3659870"
  },
  {
    "text": "maybe you could get\nbetter performance. Did anyone get\nbetter performance? No. How many of you\nactually tried it?",
    "start": "3659870",
    "end": "3666140"
  },
  {
    "text": "Raise your hand. OK, so one-- a couple of\npeople who are afraid to",
    "start": "3666140",
    "end": "3671280"
  },
  {
    "text": "say, but yeah. So a couple of people\nwho tried, but not many.  But I think the reason why it's\nvery challenging to do better",
    "start": "3671280",
    "end": "3679387"
  },
  {
    "text": "with, let's say, a recurrent\nneural network versus a bag-of-words model\nis because there is--",
    "start": "3679387",
    "end": "3685500"
  },
  {
    "text": "a lot of the subtlety in\nunderstanding the text",
    "start": "3685500",
    "end": "3690600"
  },
  {
    "text": "is in terms of understanding\nthe context of the text. And that's something that\nusing these newer embeddings is actually really good at\nbecause they can get--",
    "start": "3690600",
    "end": "3697137"
  },
  {
    "text": "they could use the\ncontext of words to better represent what\neach word actually means.",
    "start": "3697137",
    "end": "3702910"
  },
  {
    "text": "And they see\nsubstantial improvement in performance\nusing this approach. What about for non-text data?",
    "start": "3702910",
    "end": "3708790"
  },
  {
    "text": "So you might ask when we\nhave health insurance claims,",
    "start": "3708790",
    "end": "3714220"
  },
  {
    "text": "we have longitudinal\ndata across time. There's no language in this. It's a time series data set. You have ICD-9 codes\nat each point in time,",
    "start": "3714220",
    "end": "3722050"
  },
  {
    "text": "you have maybe lab test\nresults, medication records. And this is very similar\nto the market scan data that you used in your\nhomework assignment.",
    "start": "3722050",
    "end": "3728580"
  },
  {
    "text": "Could one learn embeddings\nfor this type of data, which is also useful for transfer?",
    "start": "3728580",
    "end": "3735220"
  },
  {
    "text": "So one goal might be to say, OK,\nlet's take every ICD-9, ICD-10",
    "start": "3735220",
    "end": "3740760"
  },
  {
    "text": "code, every medication,\nevery laboratory test result, and embed those event types into\nsome lower dimensional space.",
    "start": "3740760",
    "end": "3748562"
  },
  {
    "text": "And so here's an\nexample of an embedding. And you see how-- this is\njust a sketch, by the way-- you see how you might\nhope that diagnosis",
    "start": "3748562",
    "end": "3755400"
  },
  {
    "text": "codes for autoimmune\nconditions might be all near each other\nin some lower dimensional space, diagnosis\ncodes for medications",
    "start": "3755400",
    "end": "3762660"
  },
  {
    "text": "that treat some conditions\nshould be near each other, and so on. So you might hope that such\nstructure might be discovered",
    "start": "3762660",
    "end": "3767970"
  },
  {
    "text": "by an unsupervised learning\nalgorithm that could then be used within a transfer\nlearning approach.",
    "start": "3767970",
    "end": "3773585"
  },
  {
    "text": "And indeed, that's\nwhat we found. So I wrote a paper\non this in 2015/16.",
    "start": "3773585",
    "end": "3780270"
  },
  {
    "text": "And here's one of the\nresults from that paper.",
    "start": "3780270",
    "end": "3785888"
  },
  {
    "text": "So this is just a look\nat nearest neighbors to give you some sense of\nwhether the embedding's",
    "start": "3785888",
    "end": "3792869"
  },
  {
    "text": "actually capturing the\nstructure of the data. So we looked at\nnearest neighbors of the diagnosis ICD-9 diagnosis\ncode 710.0, which is lupus.",
    "start": "3792870",
    "end": "3802930"
  },
  {
    "text": "And what you find is that\nanother diagnosis code, also for lupus, is the first\nclosest result, followed",
    "start": "3802930",
    "end": "3808890"
  },
  {
    "text": "by connective tissue\ndisorder, or Sicca syndrome, which is Sjogren's disease,\nRaynaud's syndrome,",
    "start": "3808890",
    "end": "3814587"
  },
  {
    "text": "and other autoimmune conditions. So that makes a lot of sense. You can also go\nacross data types, like ask, what is the nearest\nneighbor from this diagnosis",
    "start": "3814587",
    "end": "3822390"
  },
  {
    "text": "code to laboratory tests? And since we've embedded\nlab tests and diagnosis codes all in the same\nspace, you can actually",
    "start": "3822390",
    "end": "3828930"
  },
  {
    "text": "get an answer to that. And what you see is that these\nlab tests, which by the way are exactly lab tests\nthat are commonly",
    "start": "3828930",
    "end": "3834090"
  },
  {
    "text": "used to understand progression\nin this autoimmune condition,",
    "start": "3834090",
    "end": "3840090"
  },
  {
    "text": "are the closest neighbors. Similarly, you can ask the same\nquestion about drugs and so on.",
    "start": "3840090",
    "end": "3847109"
  },
  {
    "text": "And by the way, we have made\nall of these embeddings publicly available on my lab's GitHub.",
    "start": "3847110",
    "end": "3854970"
  },
  {
    "text": "And since the time that\nI wrote this paper, there have been a\nnumber of other papers, that I give citations\nto at the bottom here,",
    "start": "3854970",
    "end": "3861150"
  },
  {
    "text": "tackling a very similar problem. This last one also put there\nembeddings publicly available,",
    "start": "3861150",
    "end": "3867779"
  },
  {
    "text": "and is much larger than the one\nthat we had So these things, I think, would also be\nvery useful as one starts",
    "start": "3867780",
    "end": "3874019"
  },
  {
    "text": "to think about how one can\ntransfer knowledge learned on one institution to\nanother institution",
    "start": "3874020",
    "end": "3880062"
  },
  {
    "text": "where you might\nhave much less data than that other institution. ",
    "start": "3880062",
    "end": "3885480"
  },
  {
    "text": "So finally I want to\nreturn back to the question that I raised in\nbullet two here,",
    "start": "3885480",
    "end": "3890820"
  },
  {
    "text": "where we looked\nat a linear model with a manually\nchosen representation, and ask, could we--",
    "start": "3890820",
    "end": "3897300"
  },
  {
    "text": "instead of just naively chopping\nyour deep neural network at some layer and\nthen fine tuning,",
    "start": "3897300",
    "end": "3904680"
  },
  {
    "text": "could one have learned a\nrepresentation of your data specifically for the purpose of\nencouraging good generalization",
    "start": "3904680",
    "end": "3911580"
  },
  {
    "text": "to a new institution? And there has been some\nreally exciting work",
    "start": "3911580",
    "end": "3917220"
  },
  {
    "text": "in this field that goes by the\nname of Unsupervised Domain",
    "start": "3917220",
    "end": "3923030"
  },
  {
    "text": "Adaptation. ",
    "start": "3923030",
    "end": "3934030"
  },
  {
    "text": "So the setting that's\nconsidered here is where you have\ndata from-- you have data from first some\ninstitution, which is x",
    "start": "3934030",
    "end": "3942190"
  },
  {
    "text": "comma y. But then you want\nto do prediction",
    "start": "3942190",
    "end": "3948810"
  },
  {
    "text": "from a new institution\nwhere all you have access to at training time is x.",
    "start": "3948810",
    "end": "3955260"
  },
  {
    "text": "So as opposed to the\ntransfer settings that I talked about earlier,\nnow for this new institution,",
    "start": "3955260",
    "end": "3960300"
  },
  {
    "text": "you might have a ton\nof unlabeled data. Whereas before I was\ntalking about having just a small amount\nof label data,",
    "start": "3960300",
    "end": "3966198"
  },
  {
    "text": "but I never talked\nof the possibility of having a large amount\nof unlabeled data. And so you might\nask, how could you",
    "start": "3966198",
    "end": "3971460"
  },
  {
    "text": "use that large amount\nof unlabeled data from that second\ninstitution in order to learn representation\nthat actually encourages",
    "start": "3971460",
    "end": "3979109"
  },
  {
    "text": "similarities from one\nsolution to the other? And that's exactly what these\ndomain adversarial training",
    "start": "3979110",
    "end": "3984330"
  },
  {
    "text": "approaches will do. What they do is they\nadd a second term to the last function.",
    "start": "3984330",
    "end": "3989740"
  },
  {
    "text": "So they're going to minimize-- the intuition is you're\ngoing to minimize-- you're going to try\nto learn parameters",
    "start": "3989740",
    "end": "3995680"
  },
  {
    "text": "that minimize your loss function\nevaluated on data set 1.",
    "start": "3995680",
    "end": "4005150"
  },
  {
    "text": "But intuitively, you're\ngoing to ask that there also be a small distance, which\nI'll just note as d here,",
    "start": "4005150",
    "end": "4015350"
  },
  {
    "text": "between D1 and D2. And so I'm being a little\nbit loose with notation here,",
    "start": "4015350",
    "end": "4022850"
  },
  {
    "text": "but when I calculate\ndistance here, I'm referring to distance\nin representation space. So you might imagine\ntaking the middle layer",
    "start": "4022850",
    "end": "4029300"
  },
  {
    "text": "of your deep neural\nnetwork, so taking, let's say, this layer, which\nwe're going to call the feature layer, or the representation\nlayer, and you're going to say,",
    "start": "4029300",
    "end": "4035240"
  },
  {
    "text": "I want that my data under\nthe first institution",
    "start": "4035240",
    "end": "4040700"
  },
  {
    "text": "should look very\nsimilar to the data under the second institution. So the first few layers of\nyour deep neural network",
    "start": "4040700",
    "end": "4046490"
  },
  {
    "text": "are going to attempt to\nequalize the two data sets so that they look similar to\nanother, at least in x space.",
    "start": "4046490",
    "end": "4054140"
  },
  {
    "text": "And we're going to attempt\nto find representations of your model that get\ngood predictive performance on the data set for which\nyou actually have the labels",
    "start": "4054140",
    "end": "4061340"
  },
  {
    "text": "and for which the induced\nrepresentations, let's say, the middle layer look very\nsimilar across the two data",
    "start": "4061340",
    "end": "4067670"
  },
  {
    "text": "sets. And one way to do that is just\nto try to predict for each-- you now get a--",
    "start": "4067670",
    "end": "4072800"
  },
  {
    "text": "for each data point,\nyou might actually say, well, which data\nset did it come from, data set 1 or data set 2?",
    "start": "4072800",
    "end": "4078650"
  },
  {
    "text": "And what you want is that\nyour model should not be able to distinguish\nwhich data set it came from. So that's what it says,\ngradient reverse layer",
    "start": "4078650",
    "end": "4085645"
  },
  {
    "text": "you want to be\nable to-- you want to ensure that predicting which\ndata set that data came from, you want to perform badly\non that loss functions.",
    "start": "4085645",
    "end": "4091985"
  },
  {
    "text": "It's like taking the\nminus of that loss. And so we're not going to\ngo into the details of that,",
    "start": "4091985",
    "end": "4097189"
  },
  {
    "text": "but I just wanted to\ngive you a reference to that approach in the bottom. And what I want to\ndo is just spend one minute at the very end\ntalking now about defenses",
    "start": "4097189",
    "end": "4104720"
  },
  {
    "text": "to adversarial attacks. And conceptually\nthis is very simple. And that's why I can\nactually do it in one minute.",
    "start": "4104720",
    "end": "4111568"
  },
  {
    "text": "So we talked about how one could\neasily modify an image in order",
    "start": "4111569",
    "end": "4116719"
  },
  {
    "text": "to turn the prediction from,\nlet's say, pig to airliner. But how could we change your\nlearning algorithm actually",
    "start": "4116720",
    "end": "4122899"
  },
  {
    "text": "to make sure that,\ndespite the fact that you do this perturbation, you still\nget the right prediction out, pig?",
    "start": "4122899",
    "end": "4128359"
  },
  {
    "text": "Well, to think through that,\nwe have to think through, how do we do machine learning? Well, a typical approach\nto machine learning",
    "start": "4128359",
    "end": "4133793"
  },
  {
    "text": "is to learn some\nparameters theta minimized your empirical loss.",
    "start": "4133793",
    "end": "4139670"
  },
  {
    "text": "Often we use deep\nneural networks, which look a little like this. And we do gradient\ndescent where we attempt to minimize some loss surfaced,\nfind some parameters theta have",
    "start": "4139670",
    "end": "4148670"
  },
  {
    "text": "as low loss as possible. Now, when you think about\nan adversarial example",
    "start": "4148670",
    "end": "4154410"
  },
  {
    "text": "and where they come\nfrom, typically one finds an adversarial example\nin the following way.",
    "start": "4154410",
    "end": "4159745"
  },
  {
    "text": "You take your same\nloss function, now for specific\ninput x, and you try to find some\nperturbation delta",
    "start": "4159745",
    "end": "4166259"
  },
  {
    "text": "to x an additive perturbation,\nfor example, such that you increase the loss as\nmuch as possible with respect",
    "start": "4166260",
    "end": "4174109"
  },
  {
    "text": "to the correct label y. And so if you've increased\nthe loss with respect to the correct\nlabel y, intuitively",
    "start": "4174109",
    "end": "4180672"
  },
  {
    "text": "then when you try to see,\nwell, what should you predict for this\nnew perturbed input, there's going to be a lower\nloss for some alternative label,",
    "start": "4180672",
    "end": "4187646"
  },
  {
    "text": "which is why the prediction--\nthe class that's predicted actually changes. So now one can try to find\nthese adversarial examples using",
    "start": "4187646",
    "end": "4194690"
  },
  {
    "text": "the same type of gradient-based\nlearning algorithms that one uses for learning\nin the first place.",
    "start": "4194690",
    "end": "4201040"
  },
  {
    "text": "But what one can do is you\ncan use a gradient descent method now-- instead of gradient\ndescent, gradient ascent.",
    "start": "4201040",
    "end": "4207980"
  },
  {
    "text": "So you take this optimization\nproblem for a given input x, and you try to maximize\nthat loss for that input x",
    "start": "4207980",
    "end": "4214227"
  },
  {
    "text": "with this vector\ndelta, and you're now doing gradient ascent. And so what types of\ndelta should you consider?",
    "start": "4214227",
    "end": "4220280"
  },
  {
    "text": "You can imagine\nsmall perturbations, for example, delta that have\nvery small maximum values.",
    "start": "4220280",
    "end": "4225889"
  },
  {
    "text": "That would be an example\nof an L-infinity norm. Or you could say that the\nsum of the perturbations across, let's say, all of the\ndimensions has to be small.",
    "start": "4225890",
    "end": "4233159"
  },
  {
    "text": "That would be corresponding to\nlike an L1 or an L2 norm bound on what delta should be.",
    "start": "4233160",
    "end": "4238377"
  },
  {
    "text": "So now we've got\neverything we need actually to think about\ndefenses to this type of adversarial perturbation.",
    "start": "4238377",
    "end": "4246460"
  },
  {
    "text": "So instead of minimizing your\ntypical empirical loss, what we're going to do is\nwe're going to attempt",
    "start": "4246460",
    "end": "4251520"
  },
  {
    "text": "to minimize an adversarial\nrobust loss function. What we'll do is\nwe'll say, OK, we",
    "start": "4251520",
    "end": "4257099"
  },
  {
    "text": "want to be sure that no matter\nwhat the perturbation is that one adds the\ninput, the true label y",
    "start": "4257100",
    "end": "4265500"
  },
  {
    "text": "still has low loss. So you want to find\nparameters theta which",
    "start": "4265500",
    "end": "4270840"
  },
  {
    "text": "minimize this new quantity. So I'm saying that\nwe should still do well even for the worst-case\nadversarial perturbation.",
    "start": "4270840",
    "end": "4281375"
  },
  {
    "text": "And so now this would be\nthe following new learning objective, where we're\ngoing to minimize over theta with respect to\nthe maximum of our delta.",
    "start": "4281375",
    "end": "4288580"
  },
  {
    "text": "And you have to restrict the\nfamily that these perturbations could live in, so if\nthat delta that you're",
    "start": "4288580",
    "end": "4294087"
  },
  {
    "text": "maximizing with respect\nto is the empty set, you get back the original\nlearning problem. If you let it be, let's\nsay, all L-infinity",
    "start": "4294087",
    "end": "4301469"
  },
  {
    "text": "bounded perturbations\nof maximum size of 0.01, then you're saying we're\ngoing to allow for a very",
    "start": "4301470",
    "end": "4308520"
  },
  {
    "text": "small amount of perturbations. And the learning\nalgorithm is going to find parameters theta such\nthat for every input, even",
    "start": "4308520",
    "end": "4313800"
  },
  {
    "text": "with a small perturbation\nto it, adversarially chosen, you still get good\npredictive performance.",
    "start": "4313800",
    "end": "4319590"
  },
  {
    "text": "And this is now a new\noptimization problem that one can solve. And we've now\nreduced the problem",
    "start": "4319590",
    "end": "4326040"
  },
  {
    "text": "of finding an adversarial robust\nmodel to a new optimization problem. And what the field\nhas been doing",
    "start": "4326040",
    "end": "4331410"
  },
  {
    "text": "in the last couple\nof years is coming up with new optimization\napproaches to try to solve those problems fast.",
    "start": "4331410",
    "end": "4338880"
  },
  {
    "text": "So, for example, this paper\npublished an ICML in 2018 by Zico Kolter and his student--",
    "start": "4338880",
    "end": "4344940"
  },
  {
    "text": "Zico just visited\nMIT a few weeks ago-- what it did is it\nsaid, we're going",
    "start": "4344940",
    "end": "4350250"
  },
  {
    "text": "to use a convex relaxation\nto the rectified linear unit, which is used in many deep\nneural network architectures.",
    "start": "4350250",
    "end": "4357028"
  },
  {
    "text": "And what it's going to do\nit's then going to say, OK, we're going\nto think about how a small perturbation\nto the input",
    "start": "4357028",
    "end": "4365790"
  },
  {
    "text": "would be propagated in terms\nof getting how much that could actually change the output. And if one could be\nbound at every layer",
    "start": "4365790",
    "end": "4372630"
  },
  {
    "text": "by layer how much a small\nperturbation affects the output of that\nlayer, then one could propagate\nfrom the very bottom",
    "start": "4372630",
    "end": "4379350"
  },
  {
    "text": "all the way to the loss\nfunction of the top to try to bound how much the\nloss function itself changes.",
    "start": "4379350",
    "end": "4385260"
  },
  {
    "text": "And a picture of what you\nwould expect out is as follows. On the left-hand side here,\nyou have a data point,",
    "start": "4385260",
    "end": "4391770"
  },
  {
    "text": "red and blue, and\nthe decision boundary that's learned if you didn't do\nthis robust learning algorithm.",
    "start": "4391770",
    "end": "4399420"
  },
  {
    "text": "On the right, you have now-- you'll notice a small square\naround each data point.",
    "start": "4399420",
    "end": "4405030"
  },
  {
    "text": "That corresponds to a\nmaximum perturbation of some limited amount. And now you notice how the\ndecision boundary doesn't",
    "start": "4405030",
    "end": "4411960"
  },
  {
    "text": "cross any one of those squares. And that's what would be found\nby this learning algorithm. Interestingly, one can\nlook at the filters that",
    "start": "4411960",
    "end": "4418200"
  },
  {
    "text": "are learned by convolutional\nneural network using this new learning algorithm. And you find that\nthey're much more sparse.",
    "start": "4418200",
    "end": "4424980"
  },
  {
    "text": "And so this is a very\nfast moving field. Every time a new\nadversarial attack--",
    "start": "4424980",
    "end": "4432929"
  },
  {
    "text": "every time a new adversarial\ndefense mechanism comes up, someone comes up\nwith a different type of attack, which breaks it.",
    "start": "4432930",
    "end": "4438930"
  },
  {
    "text": "And usually that's from\none of two reasons. One, because the defense\nmechanism isn't provable,",
    "start": "4438930",
    "end": "4445883"
  },
  {
    "text": "and so one could try to come\nup with a theorem which says, OK, as long as you\ndon't perturbate more than some amount, these are\nthe results you should expect.",
    "start": "4445883",
    "end": "4454710"
  },
  {
    "text": "The other flip of the coin\nis, even if you come up with some provable\nguarantee, there might be other types of attacks.",
    "start": "4454710",
    "end": "4460180"
  },
  {
    "text": "So, for example, you\nmight imagine a rotation to the input instead of\nan L-infinity bounded norm",
    "start": "4460180",
    "end": "4465480"
  },
  {
    "text": "that you add to it. And so for every new\ntype of attack model, you have to think through\nnew defense mechanisms.",
    "start": "4465480",
    "end": "4471750"
  },
  {
    "text": "And so you should expect to see\nsome iteration in the space. And there's a website\ncalled robust-ml.org,",
    "start": "4471750",
    "end": "4478200"
  },
  {
    "text": "where many of these attacks and\ndefenses are being published to allow for the academic\ncommunity to make progress",
    "start": "4478200",
    "end": "4483810"
  },
  {
    "text": "here. And with that, I'll\nfinish today's lecture. ",
    "start": "4483810",
    "end": "4515000"
  }
]
[
  {
    "start": "0",
    "end": "90000"
  },
  {
    "text": " ANNOUNCER: The following content\nis provided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT Open Courseware continue to offer high quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "16670"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "16670",
    "end": "22812"
  },
  {
    "text": "JULIAN SHUN: All right. So today we're going\nto talk about cache oblivious algorithms. Who remembers what a cache\noblivious algorithm is?",
    "start": "22812",
    "end": "30250"
  },
  {
    "start": "30250",
    "end": "38190"
  },
  {
    "text": "So what is a cache oblivious\nalgorithm oblivious to?",
    "start": "38190",
    "end": "43430"
  },
  {
    "text": "Cache size. So a cache oblivious\nalgorithm is an algorithm",
    "start": "43430",
    "end": "48710"
  },
  {
    "text": "that automatically tunes for\nthe cache size on your machine. So it achieves good\ncache efficiency.",
    "start": "48710",
    "end": "55820"
  },
  {
    "text": "And the code doesn't need to\nhave any knowledge of the cache parameters of your machine. In contrast, a\ncache-aware algorithm",
    "start": "55820",
    "end": "62330"
  },
  {
    "text": "would actually know the\nparameters of the cache sizes on your machine. And the code would actually put\nthe size of the cache inside.",
    "start": "62330",
    "end": "70970"
  },
  {
    "text": "So today we're going to talk a\nlot more about cache oblivious algorithms. Last time we talked about\none cache oblivious algorithm",
    "start": "70970",
    "end": "77630"
  },
  {
    "text": "that was for matrix\nmultiplication. And today we're going to\ntalk about some other ones.",
    "start": "77630",
    "end": "82820"
  },
  {
    "text": "So first example I\nwant to talk about is simulation of heat diffusion.",
    "start": "82820",
    "end": "89899"
  },
  {
    "text": "So here's a famous equation\nknown as the heat equation.",
    "start": "89900",
    "end": "95360"
  },
  {
    "start": "90000",
    "end": "90000"
  },
  {
    "text": "And this equation is\nin two dimensions. And we want to\nsimulate this function",
    "start": "95360",
    "end": "101420"
  },
  {
    "text": "u that has three parameters t,\nx, and y. t is the time step. X and y are the x, y\ncoordinates of the 2D space.",
    "start": "101420",
    "end": "109960"
  },
  {
    "text": "And we want to know the\ntemperature for each x, y coordinate for\nany point in time t.",
    "start": "109960",
    "end": "117290"
  },
  {
    "text": "And the 2D heat\nequation can be modeled using a differential equation. So how many of you have seen\ndifferential equations before?",
    "start": "117290",
    "end": "125940"
  },
  {
    "text": "OK. So good, most of you. So here I'm showing the\nequation in two dimensions.",
    "start": "125940",
    "end": "132650"
  },
  {
    "text": "But you can get\nsimilarly equations for higher dimensions. So here it says the partial\nderivative of u with respect",
    "start": "132650",
    "end": "139310"
  },
  {
    "text": "to t is equal to alpha. Alpha is what's called\nthe thermo diffusivity.",
    "start": "139310",
    "end": "146210"
  },
  {
    "text": "It's a constant times the sum\nof the second partial derivative of u with respect to x, and the\nsecond partial derivative of u",
    "start": "146210",
    "end": "155570"
  },
  {
    "text": "with respect to y. So this is a pretty\nfamous equation.",
    "start": "155570",
    "end": "163470"
  },
  {
    "text": "And you can see that we\nhave a single derivative on the left side and a double\nderivative on the right side.",
    "start": "163470",
    "end": "168860"
  },
  {
    "text": "And how do we\nactually write code to simulate this\n2D heat process?",
    "start": "168860",
    "end": "174989"
  },
  {
    "text": "So oftentimes in\nscientific computing, people will come up with these\ndifferential equations just",
    "start": "174990",
    "end": "180440"
  },
  {
    "text": "to describe physical processes. And then they want to come\nup with efficient code to actually simulate\nthe physical process.",
    "start": "180440",
    "end": "186860"
  },
  {
    "text": " OK. So here's an example\nof a 2D heat diffusion.",
    "start": "186860",
    "end": "194660"
  },
  {
    "start": "189000",
    "end": "189000"
  },
  {
    "text": "So let's say we started out with\na configuration on the left. And here the color\ncorresponds to a temperature.",
    "start": "194660",
    "end": "201020"
  },
  {
    "text": "So a brighter color\nmeans it's hotter. Yellow is the hottest\nand blue is the coldest. In on the left we\njust have 6172,",
    "start": "201020",
    "end": "208985"
  },
  {
    "text": "which is the course number. So if you didn't\nknow that, you're probably in the wrong class. And then afterwards\nwe're going to run it",
    "start": "208985",
    "end": "215720"
  },
  {
    "text": "for a couple time steps. And then the heat is going\nto diffuse to the neighboring regions of the 2D space.",
    "start": "215720",
    "end": "221500"
  },
  {
    "text": "So after you run it\nfor a couple of steps, you might get the\nconfiguration on the right where the heat is\nmore spread out now.",
    "start": "221500",
    "end": "229730"
  },
  {
    "text": "And oftentimes, you want\nto run this simulation for a number of time steps\nuntil the distribution of heat",
    "start": "229730",
    "end": "237110"
  },
  {
    "text": "converges so it\nbecomes stable and that doesn't change by much anymore. And then we stop the simulation.",
    "start": "237110",
    "end": "242720"
  },
  {
    "text": " So this is the 1D heat equation.",
    "start": "242720",
    "end": "249300"
  },
  {
    "start": "246000",
    "end": "246000"
  },
  {
    "text": "I showed you a 2D one earlier. But we're actually going to\ngenerate code for the 1D heat equation since it's simpler.",
    "start": "249300",
    "end": "255269"
  },
  {
    "text": "But all the ideas generalize\nto higher dimensions. And here's the range of colors\ncorresponding to temperature,",
    "start": "255270",
    "end": "263640"
  },
  {
    "text": "so the hottest\ncolors on the left and the coldest\ncolors on the right.",
    "start": "263640",
    "end": "268689"
  },
  {
    "text": "And if you had a\nheat source that's on the left hand\nside of this bar, then this might possibly\nbe a stable distribution.",
    "start": "268690",
    "end": "276700"
  },
  {
    "text": "So if you keep running\nthe simulation, you might get a stable\ndistribution of heat that looks like this.",
    "start": "276700",
    "end": "284770"
  },
  {
    "text": "OK. So how do we actually write code\nto simulate this differential equation?",
    "start": "284770",
    "end": "290160"
  },
  {
    "text": "So one commonly used method\nis known as finite difference approximation.",
    "start": "290160",
    "end": "295650"
  },
  {
    "start": "291000",
    "end": "291000"
  },
  {
    "text": "So we're going to approximate\nthe partial derivative of u with respect to each\nof its coordinates.",
    "start": "295650",
    "end": "304229"
  },
  {
    "text": "So the partial derivative\nof u with respect to t is approximately equal\nto u of t plus delta t",
    "start": "304230",
    "end": "312090"
  },
  {
    "text": "where delta t is some small\nvalue, and x, and then",
    "start": "312090",
    "end": "318120"
  },
  {
    "text": "minus u of tx. And then that's all\ndivided by delta t. So how many of you have seen\nthis approximation method",
    "start": "318120",
    "end": "326580"
  },
  {
    "text": "before from your calculus class? OK, good. So as you bring the value\nof delta t down to 0,",
    "start": "326580",
    "end": "334050"
  },
  {
    "text": "then the thing on the\nright hand side approach is the true partial derivative.",
    "start": "334050",
    "end": "339760"
  },
  {
    "text": "So that's a partial\nderivative with respect to t. We also need to get the partial\nderivative with respect to x.",
    "start": "339760",
    "end": "347340"
  },
  {
    "text": "And here I'm saying the\npartial derivative with respect to x is approximately\nequal to ut of x plus delta",
    "start": "347340",
    "end": "354510"
  },
  {
    "text": "x over 2 minus ut\nof x minus delta x over 2, all divided by delta x.",
    "start": "354510",
    "end": "361350"
  },
  {
    "text": "So notice here that\ninstead of adding delta x in the first term\nand not adding anything",
    "start": "361350",
    "end": "366360"
  },
  {
    "text": "in the second term, I'm\nactually adding delta x over 2 in the first term and\nsubtracting text over 2 in the second term.",
    "start": "366360",
    "end": "372150"
  },
  {
    "text": "And it turns out that I can\ndo this with the approximation method. And it still turns out to be\nvalid as long as the two terms",
    "start": "372150",
    "end": "379740"
  },
  {
    "text": "that I'm putting in, their\ndifference is delta x. So here the\ndifference is delta x. And I can basically\ndecide how to split up",
    "start": "379740",
    "end": "386729"
  },
  {
    "text": "this delta x term among the\ntwo things in the numerator.",
    "start": "386730",
    "end": "393120"
  },
  {
    "text": "And the reason why I\nchose delta x over 2 here is because the math is just\ngoing to work out nicely.",
    "start": "393120",
    "end": "399460"
  },
  {
    "text": "And it's going to\ngive us cleaner code. This is just the first partial\nderivative with respect to x.",
    "start": "399460",
    "end": "404880"
  },
  {
    "text": "Actually need the second\npartial derivative since the right hand\nside of this equation has the second\npartial derivative.",
    "start": "404880",
    "end": "411990"
  },
  {
    "text": "So this is what the second\npartial derivative looks like. So I just take the partial\nderivative with respect",
    "start": "411990",
    "end": "417810"
  },
  {
    "text": "to x of each of the terms in\nmy numerator from the equation above.",
    "start": "417810",
    "end": "423060"
  },
  {
    "text": "And then now I can\nactually plug in the value of this partial derivative\nby applying the equation",
    "start": "423060",
    "end": "428460"
  },
  {
    "text": "above using the arguments\nt and x plus delta x over 2, and similarly\nfor the second term.",
    "start": "428460",
    "end": "434400"
  },
  {
    "text": " So for the first\nterm when I plug it into the equation for the\npartial derivative with respect",
    "start": "434400",
    "end": "443970"
  },
  {
    "text": "to x, I'm just going to get ut\nof x plus delta x minus utx.",
    "start": "443970",
    "end": "450305"
  },
  {
    "text": "And then for the\nsecond term, I'm going to get ut of\nx minus delta x. And then I subtract\nanother factor of utx.",
    "start": "450305",
    "end": "457740"
  },
  {
    "text": "So that's why I'm subtracting\n2 times utx in the numerator here.",
    "start": "457740",
    "end": "462930"
  },
  {
    "text": "And then the partial\nderivative of each of the things in\na numerator also have to divide by\nthis delta x term.",
    "start": "462930",
    "end": "469169"
  },
  {
    "text": "So on the denominator,\nI get delta x squared. ",
    "start": "469170",
    "end": "475420"
  },
  {
    "text": "So now I have the second partial\nderivative with respect to x. And I also have the first\npartial derivative with respect",
    "start": "475420",
    "end": "481860"
  },
  {
    "text": "to t. So I can just plug them\ninto my equation above. So on the left hand side I\njust have this term here.",
    "start": "481860",
    "end": "489660"
  },
  {
    "text": "And I'm multiplying by\nthis alpha constant. And then on this term\njust comes from here.",
    "start": "489660",
    "end": "496600"
  },
  {
    "text": "So this is what the\n1d heat equation reduces to using the finite\ndifference approximation",
    "start": "496600",
    "end": "502180"
  },
  {
    "text": "method. So any questions on this",
    "start": "502180",
    "end": "510050"
  },
  {
    "text": "So how do we actually write code\nto simulate this equation here?",
    "start": "510050",
    "end": "517250"
  },
  {
    "text": "So we're going to use what's\ncalled a stencil computation. And here I'm going to set delta\nat x and delta t equal to 1,",
    "start": "517250",
    "end": "526790"
  },
  {
    "text": "just for simplicity. But in general you can set\nthem to whatever you want. You can make them\nsmaller to have a more fine grained simulation.",
    "start": "526790",
    "end": "534240"
  },
  {
    "text": "So my set delta x and\ndelta eat t equal to 1. Then the denominators of these\ntwo terms just become one",
    "start": "534240",
    "end": "540800"
  },
  {
    "text": "and I don't need to\nworry about them. And then I'm going\nto represent my 2D",
    "start": "540800",
    "end": "546079"
  },
  {
    "text": "space using a 2D matrix where\nthe horizontal axis represents",
    "start": "546080",
    "end": "552620"
  },
  {
    "text": "values of x, and the vertical\naxis represents values of t. And I want to fill\nin all these entries",
    "start": "552620",
    "end": "560630"
  },
  {
    "text": "that have a black dot in it. The ones with the orange\ndot, those are my boundaries.",
    "start": "560630",
    "end": "566840"
  },
  {
    "text": "So those actually fixed\nthroughout the computation. So I'm not going to do\nany computation on those.",
    "start": "566840",
    "end": "572000"
  },
  {
    "text": "Those are just given\nto me as input. So they could be\nheat sources if we're doing the heat simulation.",
    "start": "572000",
    "end": "580680"
  },
  {
    "text": "And then now I can\nactually write code to simulate this equation.",
    "start": "580680",
    "end": "586890"
  },
  {
    "text": "So if I want to compute u of t\nplus 1x, I can just go up here.",
    "start": "586890",
    "end": "593510"
  },
  {
    "text": "And I see that that's equal\nto this thing over here. And then I bring the negative\nutx term to the right.",
    "start": "593510",
    "end": "600830"
  },
  {
    "text": "So I get ut of x\nplus alpha times ut x plus 1 minus 2 times\nutx plus ut x minus 1.",
    "start": "600830",
    "end": "611149"
  },
  {
    "text": "As I said before, we just\nwant to keep iterating this until the temperatures\nbecomes stable.",
    "start": "611150",
    "end": "618209"
  },
  {
    "text": "So I'm going to proceed in time,\nwhich in time is going up here.",
    "start": "618210",
    "end": "625310"
  },
  {
    "text": "And to compute one\nof these points-- so let's say this\nis ut plus 1x--",
    "start": "625310",
    "end": "631910"
  },
  {
    "text": "I need to know the value\nof utx, which is just a thing below me in the matrix.",
    "start": "631910",
    "end": "637640"
  },
  {
    "text": "And I also need to know\nutx plus 1 and utx minus 1. And those are just\nthe things below me",
    "start": "637640",
    "end": "643459"
  },
  {
    "text": "and diagonal to either the\nleft or the right side. So each value here just\ndepends on three other values.",
    "start": "643460",
    "end": "652070"
  },
  {
    "text": "And this is called a\nthree point stencil. This is the pattern that this\nequation is representing.",
    "start": "652070",
    "end": "658460"
  },
  {
    "text": "And in general, a\nstencil computation is going to update each point in\nan array using a fixed pattern.",
    "start": "658460",
    "end": "665180"
  },
  {
    "text": "This is called a stencil. So I'm going to\ndo the same thing for all of the other points.",
    "start": "665180",
    "end": "670490"
  },
  {
    "text": "And here, I'm going to\ncompute all the values of x for a given time step. And then I move on to\nthe next time step.",
    "start": "670490",
    "end": "677450"
  },
  {
    "text": " And then I keep doing this\nuntil the distribution",
    "start": "677450",
    "end": "684470"
  },
  {
    "text": "of temperatures becomes stable. And then I'm done.",
    "start": "684470",
    "end": "689810"
  },
  {
    "text": "OK. So these stencil\ncomputations are widely used in scientific computing.",
    "start": "689810",
    "end": "695840"
  },
  {
    "text": "They're used for weather\nsimulations, stock market simulations, fluid dynamics,\nimage processing probability,",
    "start": "695840",
    "end": "702390"
  },
  {
    "text": "and so on. So they're used all over\nthe place in science. So this is a very\nimportant concept to know.",
    "start": "702390",
    "end": "710100"
  },
  {
    "text": "So let's say I just ran\nthe code as I showed you in the animation. So I completed one row at\na time before I moved on",
    "start": "710100",
    "end": "717120"
  },
  {
    "text": "to the next row. How would this code perform\nwith respect to caching? ",
    "start": "717120",
    "end": "731895"
  },
  {
    "text": "Yes?  AUDIENCE: I think if\nx is less than a third",
    "start": "731895",
    "end": "739315"
  },
  {
    "text": "of the cache size, [INAUDIBLE] JULIAN SHUN: Yeah.",
    "start": "739315",
    "end": "744709"
  },
  {
    "text": "So if x is small, this\nwould do pretty well. But what if x is much larger\nthan the size of your cache?",
    "start": "744710",
    "end": "752875"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. JULIAN SHUN: Yeah, you. Would do badly and why is that? AUDIENCE: Because the whole\n[INAUDIBLE] second row,",
    "start": "752875",
    "end": "766890"
  },
  {
    "text": "[INAUDIBLE] JULIAN SHUN: Yeah. So it turns out that there\ncould be some reuse here,",
    "start": "766890",
    "end": "772650"
  },
  {
    "text": "because when I compute\nthe second row, I'm actually using\nsome values that",
    "start": "772650",
    "end": "778020"
  },
  {
    "text": "are computed in the first row. But if the row is much\nlarger than the cache size, by the time I get\nto the second row,",
    "start": "778020",
    "end": "783840"
  },
  {
    "text": "the values that I loaded\ninto cache from the first row would have been evicted. And therefore, I'm going to\nsuffer a cache miss again",
    "start": "783840",
    "end": "791490"
  },
  {
    "text": "for the second row, for the\nvalues I need to load in, even though they could have been\nused if we made our code have",
    "start": "791490",
    "end": "797280"
  },
  {
    "text": "good locality. ",
    "start": "797280",
    "end": "803740"
  },
  {
    "text": "Another question I\nhave is if we only cared about the values of x\nat the most recent time step,",
    "start": "803740",
    "end": "810040"
  },
  {
    "text": "do we actually have to keep\naround this whole 2D matrix? Or can we get by\nwith less storage?",
    "start": "810040",
    "end": "815589"
  },
  {
    "start": "815590",
    "end": "824500"
  },
  {
    "text": "Yeah. So how many rows would\nI have to keep around if I only cared about the\nmost recent time step?",
    "start": "824500",
    "end": "831260"
  },
  {
    "text": "Yeah? AUDIENCE: Two. JULIAN SHUN: Two. And why is that? AUDIENCE: So one for\nthe previous time step. One for the current time step.",
    "start": "831260",
    "end": "837546"
  },
  {
    "text": "[INAUDIBLE] JULIAN SHUN: Right. So I need to keep around\ntwo rows because I need the row from the\nprevious time step",
    "start": "837546",
    "end": "843630"
  },
  {
    "text": "in order to compute the values\nin the current time step. And after the\ncurrent time step, I can just swap the\nroles of the two rows",
    "start": "843630",
    "end": "850180"
  },
  {
    "text": "that I'm keeping\naround, and then reuse the previous\nrow for the next one. Yes?",
    "start": "850180",
    "end": "855371"
  },
  {
    "text": "AUDIENCE: Would you\nonly need one and then a constant amount\nof extra space,",
    "start": "855371",
    "end": "862245"
  },
  {
    "text": "like if you had\nthree extra things,",
    "start": "862245",
    "end": "867646"
  },
  {
    "text": "you could probably\ndo it with one. JULIAN SHUN: So I need to know--",
    "start": "867646",
    "end": "872649"
  },
  {
    "text": "when I'm computing\nthe second row, I need to keep around\nall of these values that I computed\nin the first row,",
    "start": "872650",
    "end": "878259"
  },
  {
    "text": "because these values\nget fed to one of the computations\nin the second row.",
    "start": "878260",
    "end": "883850"
  },
  {
    "text": "So I need to actually\nkeep all of them around. AUDIENCE: I think if you\niterate to the right,",
    "start": "883850",
    "end": "890388"
  },
  {
    "text": "then you have three that are\nthis one and the next one.",
    "start": "890388",
    "end": "896080"
  },
  {
    "text": "Just three. Then you can-- JULIAN SHUN: Oh, I see I\nsee what you're saying.",
    "start": "896080",
    "end": "901180"
  },
  {
    "text": "Yeah. So that's actually\na good observation. So you only need to\nkeep a constant amount more storage, because you'll\njust be overwriting the values",
    "start": "901180",
    "end": "911230"
  },
  {
    "text": "as you go through the row. So if you keep around one\nrow, some of the values would be for the current\ntime step, and some of them",
    "start": "911230",
    "end": "917718"
  },
  {
    "text": "would be from the\nprevious time step. So that's a good\nobservation, yes. ",
    "start": "917718",
    "end": "926240"
  },
  {
    "text": "OK. So that code, as we saw, it\nwasn't very cache efficient.",
    "start": "926240",
    "end": "932600"
  },
  {
    "text": "You could make a cache\nefficient using tiling. But we're going to go straight\nto the cache oblivious",
    "start": "932600",
    "end": "938120"
  },
  {
    "text": "algorithm because\nit's much cleaner. So let's recall the\nideal cache model.",
    "start": "938120",
    "end": "944480"
  },
  {
    "start": "942000",
    "end": "942000"
  },
  {
    "text": "We talked about this in\nthe previous lecture. So here we have a\ntwo level hierarchy. We have a cache.",
    "start": "944480",
    "end": "952250"
  },
  {
    "text": "And then we have\nthe main memory. The cache has size of M bytes.",
    "start": "952250",
    "end": "958910"
  },
  {
    "text": "And a cache line is B bytes. So you can keep around M over\nB cache lines in your cache.",
    "start": "958910",
    "end": "965930"
  },
  {
    "text": "And if something's in cache\nand you operate on it, then it doesn't incur\nany cache misses.",
    "start": "965930",
    "end": "971450"
  },
  {
    "text": "But if you have to\ngo to main memory to load the cache line in,\nthen you incur one cache miss.",
    "start": "971450",
    "end": "978060"
  },
  {
    "text": "The ideal cache model\nassumes that the cache is fully associative. So any cache line can go\nanywhere in the cache.",
    "start": "978060",
    "end": "985779"
  },
  {
    "text": "And it also assumes either an\noptimal omniscient replacement policy or the LRU policy.",
    "start": "985780",
    "end": "991760"
  },
  {
    "text": "So the optimal omniscient\nreplacement policy knows the sequence of all\nfuture requests to memory.",
    "start": "991760",
    "end": "998380"
  },
  {
    "text": "And when it needs\nto evict something, it's going to pick the thing\nthat leads to the fewest cache misses overall to evict.",
    "start": "998380",
    "end": "1005840"
  },
  {
    "text": "The LRU policy just\nevict the thing that was least recently used.",
    "start": "1005840",
    "end": "1011520"
  },
  {
    "text": "But we saw from the\nprevious lecture, that in terms of\nasymptotic costs,",
    "start": "1011520",
    "end": "1017010"
  },
  {
    "text": "these two replacement\npolicies will give you cache misses within a\nconstant fact of each other. So you can use either one,\ndepending on what's convenient.",
    "start": "1017010",
    "end": "1024689"
  },
  {
    "text": " And two performance\nmeasures that we care about when we're\nanalyzing an algorithm",
    "start": "1024690",
    "end": "1031740"
  },
  {
    "text": "and the ideal cache\nmodel are the work and the number of cache misses. So the work is just the\ntotal number of operations",
    "start": "1031740",
    "end": "1038819"
  },
  {
    "text": "that the algorithm incurs. And serially, this is just\nthe ordinary running time.",
    "start": "1038819",
    "end": "1044641"
  },
  {
    "text": "And the number of cache misses\nis the number of cache lines you have to transfer between\nthe cache and your main memory.",
    "start": "1044641",
    "end": "1051240"
  },
  {
    "text": " So let's assume that\nwe're running an algorithm",
    "start": "1051240",
    "end": "1057270"
  },
  {
    "text": "or analyzing an algorithm\nin the ideal cache model, and it runs serially. What kinds of cache misses\ndoes the ideal cache model",
    "start": "1057270",
    "end": "1064920"
  },
  {
    "text": "not capture?  So remember, we talked about\nseveral types of cache misses.",
    "start": "1064920",
    "end": "1071133"
  },
  {
    "text": "And there's one\ntype of cache miss that this model doesn't capture\nwhen we're running serially. ",
    "start": "1071133",
    "end": "1086760"
  },
  {
    "text": "So let's assume we're\nrunning this serially without any parallelism here.",
    "start": "1086760",
    "end": "1091770"
  },
  {
    "text": "So the sharing misses\nhas only come about when you have parallelism. Yes? AUDIENCE: Conflictness? JULIAN SHUN: Yes.",
    "start": "1091770",
    "end": "1096928"
  },
  {
    "text": "So the answer is conflictnesses. And why is that? Why does this model\nnot capture it? AUDIENCE: There's\nnot a specific sets",
    "start": "1096928",
    "end": "1104010"
  },
  {
    "text": "that could get replaced then\nsince it's fully associated. JULIAN SHUN: Yes. So this is a fully\nassociative cache.",
    "start": "1104010",
    "end": "1109620"
  },
  {
    "text": "So any cache line can go\nanywhere in the cache. And you can only get conflict\nmisses for set associated",
    "start": "1109620",
    "end": "1115309"
  },
  {
    "text": "schemes where each\ncache line can only be mapped to a particular set. And if you have too\nmany cache lines that",
    "start": "1115310",
    "end": "1121830"
  },
  {
    "text": "map to that particular\nset, then you're going to keep\nevicting each other even though the rest of\nthe cache could have space.",
    "start": "1121830",
    "end": "1127350"
  },
  {
    "text": "And that's what's\ncalled a conflict miss. The ideal cash model does\ncapture capacity misses.",
    "start": "1127350",
    "end": "1134159"
  },
  {
    "text": "So therefore, it is\nstill a very good model to use at a high\nlevel when you're designing efficient\nalgorithms, because it",
    "start": "1134160",
    "end": "1141930"
  },
  {
    "text": "encourages you to optimize for\nspatial and temporal locality. And once you have a good\nalgorithm in the ideal cache",
    "start": "1141930",
    "end": "1148770"
  },
  {
    "text": "model then you can start\ndealing with conflict misses using some of the\nstrategies that we talked about last\ntime such as padding",
    "start": "1148770",
    "end": "1155220"
  },
  {
    "text": "or using temporary memory. So any questions on this? ",
    "start": "1155220",
    "end": "1169210"
  },
  {
    "text": "OK. So this is the code that\ndoes the heat simulation",
    "start": "1169210",
    "end": "1177120"
  },
  {
    "start": "1174000",
    "end": "1174000"
  },
  {
    "text": "that we saw earlier. So it's just two for\nloops, a nested for loop. In the outer loop, we're\nlooping over the time dimension.",
    "start": "1177120",
    "end": "1184800"
  },
  {
    "text": "In the inner loop, we're looping\nover the space dimension. So we're computing\nall the values of x before we move on\nto the next time step.",
    "start": "1184800",
    "end": "1193320"
  },
  {
    "text": "And then we're\nstoring two rows here and we're using this trick\ncalled a even odd trick.",
    "start": "1193320",
    "end": "1199380"
  },
  {
    "text": "And here's how it works. So to access the next row\nthat we want to compute,",
    "start": "1199380",
    "end": "1204840"
  },
  {
    "text": "that we just do\na t plus 1 mod 2. And then to access the current\nrow, it's just t mod 2.",
    "start": "1204840",
    "end": "1210480"
  },
  {
    "text": "So this is implicitly going to\nswap the roles of the two rows that we're keeping around\nas we progress through time.",
    "start": "1210480",
    "end": "1218500"
  },
  {
    "text": "And then we're\ngoing to set u of t plus 1 mod 2x equal\nto kernel of u--",
    "start": "1218500",
    "end": "1225600"
  },
  {
    "text": "pointer to ut mod 2x. And this kernel function\nis defined up here.",
    "start": "1225600",
    "end": "1231600"
  },
  {
    "text": "And recall, that\nwhen we're actually passing a pointer to\nthis kernel function, we can actually treat a pointer\nas the beginning of an array.",
    "start": "1231600",
    "end": "1240960"
  },
  {
    "text": "So we're using array\nnotation up here inside the kernel function. So the array W is\npassed as input.",
    "start": "1240960",
    "end": "1248400"
  },
  {
    "text": "And then we need\nto return W of 0. That's just the element\nat the current pointer",
    "start": "1248400",
    "end": "1254430"
  },
  {
    "text": "that we passed to kernel. And then we add alpha\ntimes w of negative 1.",
    "start": "1254430",
    "end": "1259500"
  },
  {
    "text": "That's one element before the\nthing that we're pointing to, minus 2 times W\nof 0 plus W of 1.",
    "start": "1259500",
    "end": "1267000"
  },
  {
    "text": "W of 1 is the next element\nthat we're pointing to. ",
    "start": "1267000",
    "end": "1273110"
  },
  {
    "text": "OK. So let's look at the caching\nbehavior of this code. So we're going to analyze\nthe cache complexity.",
    "start": "1273110",
    "end": "1281470"
  },
  {
    "text": "And we're going to assume the\nLRU replacement policy here, because we can.",
    "start": "1281470",
    "end": "1286480"
  },
  {
    "text": "And as we said\nbefore, we're going to loop through one\nentire row at a time before we go onto the next row.",
    "start": "1286480",
    "end": "1294980"
  },
  {
    "text": "So the number of\ncache misses I get, assuming that n\nis greater than M,",
    "start": "1294980",
    "end": "1300310"
  },
  {
    "text": "so that the row size is\ngreater than the cache size, the number of cache\nmisses is theta of NT over B.",
    "start": "1300310",
    "end": "1308530"
  },
  {
    "text": "So how do I get this cache\ncomplexity around here? ",
    "start": "1308530",
    "end": "1324490"
  },
  {
    "text": "So how many cache\nmisses do I have to incur for each row of this\n2D space that I'm computing?",
    "start": "1324490",
    "end": "1330457"
  },
  {
    "text": " Yes? AUDIENCE: N over B.",
    "start": "1330457",
    "end": "1336112"
  },
  {
    "text": "JULIAN SHUN: Right. So I need N over B cache\nmisses for each row. And this is because I can\nload in B bytes at a time.",
    "start": "1336112",
    "end": "1345129"
  },
  {
    "text": "So I benefit from\nspatial locality there. And then I have N elements\nI need to compute. So it's theta of\nN over B per row.",
    "start": "1345130",
    "end": "1351940"
  },
  {
    "text": "And as we said before, when\nwe get to the next row, the stuff that we need\nfrom the previous row",
    "start": "1351940",
    "end": "1357250"
  },
  {
    "text": "have already been\nevicted from cache. So I basically have to incur\ntheta of N over B cache misses for every row.",
    "start": "1357250",
    "end": "1363280"
  },
  {
    "text": "And the number of rows\nI'm going to compute as t. So it's just theta of NT over B.\nAny questions on this analysis?",
    "start": "1363280",
    "end": "1372460"
  },
  {
    "start": "1372460",
    "end": "1382000"
  },
  {
    "text": "So how many of you think\nwe can do better than this? ",
    "start": "1382000",
    "end": "1388370"
  },
  {
    "text": "OK. So one person. Two, three. OK.",
    "start": "1388370",
    "end": "1393620"
  },
  {
    "text": "So turns out that we\ncan do better than this. You can actually do\nbetter with tiling, but I'm not going to\ndo the tiling version.",
    "start": "1393620",
    "end": "1399549"
  },
  {
    "text": "I want to do the cache\noblivious version. And the cache\noblivious version is",
    "start": "1399550",
    "end": "1405250"
  },
  {
    "start": "1402000",
    "end": "1402000"
  },
  {
    "text": "going to work on trapezoidal\nregions in the 2D space. And recall that a trapezoid has\na top base and a bottom base.",
    "start": "1405250",
    "end": "1414670"
  },
  {
    "text": "And here the top base is at\nt1, the bottom base is at t0,",
    "start": "1414670",
    "end": "1421420"
  },
  {
    "text": "and the height is\njust t1 minus t0. And the width of a trapezoid\nis just the width of it",
    "start": "1421420",
    "end": "1428020"
  },
  {
    "text": "at the midpoint between t1 and\nt0, so at t1 plus t0 over 2.",
    "start": "1428020",
    "end": "1434590"
  },
  {
    "text": "So we're going to\ncompute all of the points inside this trapezoid\nthat satisfy",
    "start": "1434590",
    "end": "1442150"
  },
  {
    "text": "these inequalities here. So t has to be greater than or\nequal to t0 and less than t1.",
    "start": "1442150",
    "end": "1447670"
  },
  {
    "text": "And then x is greater than\nor equal to x0 plus dx0",
    "start": "1447670",
    "end": "1453430"
  },
  {
    "text": "times t minus t0. So dx0 is actually the\ninverse slope here.",
    "start": "1453430",
    "end": "1460149"
  },
  {
    "text": "And then it also has\nto be less than x1 plus dx1 times t minus t0. So dx1 is the inverse\nslope on the other side.",
    "start": "1460150",
    "end": "1468100"
  },
  {
    "text": "And dx0 and dx1 have to be\neither negative 1, 0, or 1.",
    "start": "1468100",
    "end": "1473240"
  },
  {
    "text": "So negative 1 just corresponds\nto inverse slope of negative 1, which is also a\nslope of negative 1.",
    "start": "1473240",
    "end": "1480299"
  },
  {
    "text": "If it's 1, then it's just\na slope or inverse of 1. And then if it's 0, then we\njust have a vertical line.",
    "start": "1480300",
    "end": "1488500"
  },
  {
    "text": " OK. So the nice property\nof this trapezoid",
    "start": "1488500",
    "end": "1496179"
  },
  {
    "text": "is that we can actually compute\neverything inside the trapezoid without looking\noutside the trapezoid.",
    "start": "1496180",
    "end": "1501740"
  },
  {
    "text": "So we can compute everything\nhere independently of any other trapezoids\nwe might be generating. And we're going to\ncome up with a divide",
    "start": "1501740",
    "end": "1508100"
  },
  {
    "text": "and conquer approach\nto execute this code. ",
    "start": "1508100",
    "end": "1514480"
  },
  {
    "text": "So the divide and conquer\nalgorithm has a base case. So our base case\nis going to be when",
    "start": "1514480",
    "end": "1520539"
  },
  {
    "start": "1518000",
    "end": "1518000"
  },
  {
    "text": "the height of the\ntrapezoid is 1. And when the height\nis 1, then we're just going to compute all of\nthe values using a simple loop.",
    "start": "1520540",
    "end": "1530660"
  },
  {
    "text": "And any order if the\ncomputation inside this loop is valid, since we\nhave all the values",
    "start": "1530660",
    "end": "1537400"
  },
  {
    "text": "in the base of the\ntrapezoid and we can compute the values in\nthe top of the trapezoid",
    "start": "1537400",
    "end": "1543160"
  },
  {
    "text": "in whatever order. They don't depend on each other.  So that's a base case.",
    "start": "1543160",
    "end": "1549000"
  },
  {
    "text": "Any questions so far? ",
    "start": "1549000",
    "end": "1556940"
  },
  {
    "text": "So here's one of\nthe recursive cases. It turns out that\nwe're going to have two different types of cuts. The first cut is\ncalled a space cut.",
    "start": "1556940",
    "end": "1564690"
  },
  {
    "text": "So I'm going to do a space cut\nif the width of the trapezoid is greater than or equal\nto twice the height.",
    "start": "1564690",
    "end": "1570520"
  },
  {
    "text": "So this means that the\ntrapezoid is too wide. And I'm going to\ncut it vertically.",
    "start": "1570520",
    "end": "1576660"
  },
  {
    "text": " More specifically, I'm\ngoing to cut it with a line, with slope negative 1\ngoing through the center",
    "start": "1576660",
    "end": "1584820"
  },
  {
    "text": "of the trapezoid. And then I'm going to traverse\nthe trapezoid on the left side",
    "start": "1584820",
    "end": "1590910"
  },
  {
    "text": "first. And then after I'm\ndone with that, traverse the trapezoid\non the right side. ",
    "start": "1590910",
    "end": "1597750"
  },
  {
    "text": "So can I actually switch\nthe order of this? Can I compute the\nstuff on the right side before I do this stuff\non the left side?",
    "start": "1597750",
    "end": "1606250"
  },
  {
    "text": "No. Why is that? AUDIENCE: [INAUDIBLE].",
    "start": "1606250",
    "end": "1612650"
  },
  {
    "text": "JULIAN SHUN: Yeah. So there some points\nin the right trapezoid that depend on the values\nfrom the left trapezoid.",
    "start": "1612650",
    "end": "1619340"
  },
  {
    "text": "And so for the left trapezoid,\nevery point we want to compute, we already have\nall of its points,",
    "start": "1619340",
    "end": "1625730"
  },
  {
    "text": "assuming that we get all the\nvalues of the base points. But for the right hand\nside, some of the values",
    "start": "1625730",
    "end": "1632509"
  },
  {
    "text": "depend on values in\nthe left trapezoid. So we can't execute\nthe right trapezoid until we're done with\nthe left trapezoid.",
    "start": "1632510",
    "end": "1639710"
  },
  {
    "text": "And this is the reason\nwhy I cut this trapezoid with a slope of\nnegative 1 instead of using a vertical cut.",
    "start": "1639710",
    "end": "1645680"
  },
  {
    "text": "Because if I did a\nvertical cut then inside both of the\ntrapezoids, I would have points that depend\non the other trapezoid.",
    "start": "1645680",
    "end": "1654110"
  },
  {
    "text": "So this is one of the two cuts. This is called a space cut. And it happens when the\ntrapezoid is too wide.",
    "start": "1654110",
    "end": "1660010"
  },
  {
    "text": "The other cut is\nthe time cut I'm going to cut with respect\nto the time dimension. And this happens when the\ntrapezoid is too tall,",
    "start": "1660010",
    "end": "1666580"
  },
  {
    "start": "1661000",
    "end": "1661000"
  },
  {
    "text": "so when the width is less\nthan twice the height of the trapezoid. Then what I'm going\nto do is I'm just",
    "start": "1666580",
    "end": "1672490"
  },
  {
    "text": "going to cut it with\na horizontal line through the center. And then I'm going to traverse\nthe bottom trapezoid first.",
    "start": "1672490",
    "end": "1680448"
  },
  {
    "text": "And after I'm done with that,\nI can traverse a top trapezoid. And again, the top trapezoid\ndepends on some points from the bottom trapezoid.",
    "start": "1680448",
    "end": "1686360"
  },
  {
    "text": "So it's I can't switch\nthe order of those. Any questions? ",
    "start": "1686360",
    "end": "1697039"
  },
  {
    "text": "OK. So let's now look\nat the code that implements this recursive\ndivide and conquer algorithm.",
    "start": "1697040",
    "end": "1704690"
  },
  {
    "start": "1701000",
    "end": "1701000"
  },
  {
    "text": "So here's the C code. It takes as input t0 and t1.",
    "start": "1704690",
    "end": "1709970"
  },
  {
    "text": "These are the\ncoordinates of the top and the bottom up the\ntrapezoid, or bottom and top of the trapezoid, then x.",
    "start": "1709970",
    "end": "1715730"
  },
  {
    "text": "0 is the left side\nof the trapezoid-- of the base of the trapezoid. dx0 is the inverse\nslope, and the x1",
    "start": "1715730",
    "end": "1723049"
  },
  {
    "text": "is the right side of the\nbottom base of the trapezoid, and dx1 is the inverse\nslope on the right side.",
    "start": "1723050",
    "end": "1730670"
  },
  {
    "text": "So we're first going to compute\nthe height of our trapezoid. And we're going to\nlet LT be the height.",
    "start": "1730670",
    "end": "1735890"
  },
  {
    "text": "And that's just t1 minus t0. And if the height\nis 1, then we're just going to use a for\nloop over all the points",
    "start": "1735890",
    "end": "1745370"
  },
  {
    "text": "in that height 1 trapezoid. We're going to call\nthis kernel function that we defined before.",
    "start": "1745370",
    "end": "1751980"
  },
  {
    "text": "And otherwise, the\nheight is greater than 1. And we're going to check\nwhether we should do a space cut",
    "start": "1751980",
    "end": "1757610"
  },
  {
    "text": "or time cut. So we do a space cut if\nthe trapezoid is too wide. And this condition\ninside the if clause",
    "start": "1757610",
    "end": "1764380"
  },
  {
    "text": "is checking if the\ntrapezoid is too wide. And if so, then we're going\nto make two recursive calls",
    "start": "1764380",
    "end": "1770780"
  },
  {
    "text": "to trapezoid. And we're going to cut\nit in the middle using this slope of negative 1.",
    "start": "1770780",
    "end": "1776419"
  },
  {
    "text": "So you see the negative ones\nhere in the recursive calls. And otherwise,\nwe'll do a time cut.",
    "start": "1776420",
    "end": "1782180"
  },
  {
    "text": "And for the time cut we\njust cut it in the middle. So we cut it at the value of t\nthat's equal to LT divided by,",
    "start": "1782180",
    "end": "1789020"
  },
  {
    "text": "2 or t0 plus LT divided by 2. And again, we have two\nrecursive calls to trapezoid.",
    "start": "1789020",
    "end": "1796010"
  },
  {
    "text": " OK. So even though I'm only\ngenerating slopes of negative 1",
    "start": "1796010",
    "end": "1803539"
  },
  {
    "text": "in this recursive\ncall, this code is going to work even if\nI have slopes of 1 and 0, because I could start out\nwith slopes of 1 and 0.",
    "start": "1803540",
    "end": "1811330"
  },
  {
    "text": "For example, if I had\na rectangular region, then the slopes are\njust going to be 0, and this code is\nstill going to work.",
    "start": "1811330",
    "end": "1816970"
  },
  {
    "text": "But most of the slopes\nthat I'm dealing with are going to be a\nnegative 1, because those are the new slopes\nand I'm generating.",
    "start": "1816970",
    "end": "1822677"
  },
  {
    "text": " Any questions? ",
    "start": "1822677",
    "end": "1834720"
  },
  {
    "text": "So this code is very concise. It turns out that even, odd\ntricks still works here.",
    "start": "1834720",
    "end": "1842399"
  },
  {
    "text": "You can still keep\naround just two rows, because you're guaranteed\nthat you're not going to overwrite any\nvalue until all the things",
    "start": "1842400",
    "end": "1851399"
  },
  {
    "text": "that depend on it are computed. But when you're\nusing just two rows,",
    "start": "1851400",
    "end": "1857220"
  },
  {
    "text": "the values in a particular\nrow might not all correspond to the\nsame time step, because we're not finishing\nan entire row before we",
    "start": "1857220",
    "end": "1863610"
  },
  {
    "text": "move on to the next one. We're actually partially\ncomputing rows. ",
    "start": "1863610",
    "end": "1870590"
  },
  {
    "text": "OK. So let's analyze the cash\ncomplexity of this algorithm. ",
    "start": "1870590",
    "end": "1877750"
  },
  {
    "start": "1876000",
    "end": "1876000"
  },
  {
    "text": "Again, we're going to use\nthe recursion tree approach that we talked about last time.",
    "start": "1877750",
    "end": "1882929"
  },
  {
    "text": "And our code is\ngoing to split itself",
    "start": "1882930",
    "end": "1888010"
  },
  {
    "text": "into two cell problems at every\nlevel until it gets to a leaf. And each leaf represents\ntheta of hw points",
    "start": "1888010",
    "end": "1897280"
  },
  {
    "text": "where h is theta of w. So h is the height.\nw is the width. And we have the property that\nh is equal to theta w because",
    "start": "1897280",
    "end": "1907328"
  },
  {
    "text": "of the nature of the algorithm. When the trapezoid\nbecomes too wide, we're going to make it less\nwide by doing a space cut.",
    "start": "1907328",
    "end": "1914920"
  },
  {
    "text": "And if it becomes\ntoo tall, we're going to do a horizontal cut. So we're guaranteed that\nthe height and the width",
    "start": "1914920",
    "end": "1920410"
  },
  {
    "text": "are going to be within a\nconstant factor of each other when we get to the base case.",
    "start": "1920410",
    "end": "1926140"
  },
  {
    "text": "And each leaf in\nthe base case is going to incur theta\nof w over B misses",
    "start": "1926140",
    "end": "1932230"
  },
  {
    "text": "because we have to load in\nthe base of the trapezoid from main memory.",
    "start": "1932230",
    "end": "1937899"
  },
  {
    "text": "And once that's in\ncache, we can compute all of the other\npoints in the trapezoid without incurring any\nmore cache misses.",
    "start": "1937900",
    "end": "1943400"
  },
  {
    "text": "So the cache misses per\nleaf is just theta w over B. And we're going to set w equal\nto theta of M in the analysis,",
    "start": "1943400",
    "end": "1953660"
  },
  {
    "text": "because that's the point when\nthe trapezoid fits into cache. The algorithm doesn't\nactually have any knowledge",
    "start": "1953660",
    "end": "1961420"
  },
  {
    "text": "of this M parameter. So it's still going\nto keep divide and conquering until it gets\nthe base case of size 1.",
    "start": "1961420",
    "end": "1967870"
  },
  {
    "text": "But just for the analysis,\nwe're going to use a base case when w is theta of M.",
    "start": "1967870",
    "end": "1976950"
  },
  {
    "text": "So the number of leaves\nwe have is theta of NT divided by w because each\nleaf is a size theta hw.",
    "start": "1976950",
    "end": "1984600"
  },
  {
    "text": " The number of\ninternal notes we have",
    "start": "1984600",
    "end": "1990450"
  },
  {
    "text": "is equal to a number\nof leaves minus because we have a tree here. But the internal notes don't\ncontribute substantially",
    "start": "1990450",
    "end": "1997470"
  },
  {
    "text": "to the cache complexity,\nbecause each of them is just doing a\nconstant number of cache misses to set up the\ntwo recursive calls.",
    "start": "1997470",
    "end": "2004280"
  },
  {
    "text": "And it's not doing anything\nmore expensive than that. ",
    "start": "2004280",
    "end": "2009622"
  },
  {
    "text": "So we just need to compute\nthe number of cache misses at the leaves. We have theta of NT over hw\nleaves, each one of which",
    "start": "2009623",
    "end": "2017659"
  },
  {
    "text": "takes theta of w\nover B cache misses. And we're going to\nmultiply that out. So the w term cancels out.",
    "start": "2017660",
    "end": "2024330"
  },
  {
    "text": "We just have NT over hB and we\nset h and w to be theta of M.",
    "start": "2024330",
    "end": "2031789"
  },
  {
    "text": "So we're just left with NT over\nMB as our cache complexity. Yes?",
    "start": "2031790",
    "end": "2037866"
  },
  {
    "text": "AUDIENCE: Can you explain\nwhy hB [INAUDIBLE]?? JULIAN SHUN: Sure.",
    "start": "2037866",
    "end": "2043570"
  },
  {
    "text": "So each leaf only incurs\ntheta w over B cache misses because we need\nto compute the values",
    "start": "2043570",
    "end": "2050919"
  },
  {
    "text": "of the base of the trapezoid. And that's going to\nincur theta of w over B cache misses\nbecause it's w wide,",
    "start": "2050920",
    "end": "2057580"
  },
  {
    "text": "and therefore, everything else\nis going to fit into cache. So when we compute\nthem, we already have all of our previous\nvalues that we want in cache.",
    "start": "2057580",
    "end": "2066340"
  },
  {
    "text": "So that's why it's not going\nto incur any more cache misses. So does that makes sense? AUDIENCE: Yeah, I forgot\nthat it was [INAUDIBLE]..",
    "start": "2066340",
    "end": "2072360"
  },
  {
    "text": "JULIAN SHUN: Yeah. ",
    "start": "2072360",
    "end": "2079310"
  },
  {
    "text": "OK. So this was just analysis\nfor one dimension.",
    "start": "2079310",
    "end": "2085310"
  },
  {
    "text": "But it actually generalizes\nto more than one dimension. So in general, if we\nhave d dimensions,",
    "start": "2085310",
    "end": "2090940"
  },
  {
    "text": "then the cache complexity\nis going to be theta of NT divided by M to the\n1 over d times B.",
    "start": "2090940",
    "end": "2097060"
  },
  {
    "text": "So if d is 1, then that\njust reduces to NT over MB. If d is 2, then it's going to\nbe NT over B times square root",
    "start": "2097060",
    "end": "2105250"
  },
  {
    "text": "of M and so on. And it turns out that this\nbound is also optimal. ",
    "start": "2105250",
    "end": "2113170"
  },
  {
    "text": "So any questions? So compared to the\nlooping code, this code actually has much\nbetter cache complexity.",
    "start": "2113170",
    "end": "2119170"
  },
  {
    "text": "It's saving by a factor\nof M. The looping code had a cache complexity that\nwas theta of NT over B.",
    "start": "2119170",
    "end": "2125770"
  },
  {
    "text": "It didn't have an M\nin the denominator. OK.",
    "start": "2125770",
    "end": "2132530"
  },
  {
    "text": "So we're actually going\nto do a simulation now. We're going to compare\nhow the looping code in a trapezoid code runs.",
    "start": "2132530",
    "end": "2140200"
  },
  {
    "start": "2134000",
    "end": "2134000"
  },
  {
    "text": "And in this simulation,\nthe green points correspond to a cache hit,\nthe purple points correspond",
    "start": "2140200",
    "end": "2148040"
  },
  {
    "text": "to a cache miss. And we're going assume a fully\nassociative cache using the LRU",
    "start": "2148040",
    "end": "2153170"
  },
  {
    "text": "replacement policy where the\ncache line size is 4 points and cache size is 32 points.",
    "start": "2153170",
    "end": "2161720"
  },
  {
    "text": "And we're going to set the cache\nhit latency to be one cycle, and the cache miss\nlatency to be 10 cycles.",
    "start": "2161720",
    "end": "2168230"
  },
  {
    "text": "So an order of magnitude\nslower for cache misses. And we're doing this\nfor a rectangular region",
    "start": "2168230",
    "end": "2173599"
  },
  {
    "text": "where N is 95. And we're doing it\nfor 87 time steps. So when we pull out\nthe simulation now.",
    "start": "2173600",
    "end": "2182339"
  },
  {
    "text": "OK. So on the left hand side, we're\ngoing to have the looping code. On the right hand\nside, we're going to have the trapezoidal code.",
    "start": "2182340",
    "end": "2187880"
  },
  {
    "text": "So let's start this. So you can see that\nthe looping code",
    "start": "2187880",
    "end": "2192980"
  },
  {
    "text": "is going over one row at a time\nwhereas the trapezoidal code is not doing that. It's partially computing\none row and then moving",
    "start": "2192980",
    "end": "2199700"
  },
  {
    "text": "on to the next row.  I can also show the\ncuts that are generated",
    "start": "2199700",
    "end": "2207950"
  },
  {
    "text": "by the trapezoidal algorithm. I have to remember\nhow to do this.",
    "start": "2207950",
    "end": "2214520"
  },
  {
    "text": "So C-- ",
    "start": "2214520",
    "end": "2219619"
  },
  {
    "text": "So there there's the\ncuts that are generated by the trapezoidal algorithm.",
    "start": "2219620",
    "end": "2225290"
  },
  {
    "text": "And I can speed this up. ",
    "start": "2225290",
    "end": "2231955"
  },
  {
    "text": "So you can see that the\ntrapezoidal algorithm is incurring much fewer cache\nmisses than the looping code.",
    "start": "2231955",
    "end": "2237470"
  },
  {
    "start": "2237470",
    "end": "2243650"
  },
  {
    "text": "So I just make this go faster. And the trapezoid code\nis going to finish,",
    "start": "2243650",
    "end": "2248770"
  },
  {
    "text": "while the looping code\nis still slowly making its way up the top. ",
    "start": "2248770",
    "end": "2261470"
  },
  {
    "text": "OK. So it's finally done. So any questions on this? Yeah? AUDIENCE: Why doesn't the\ntrapezoid [INAUDIBLE]??",
    "start": "2261470",
    "end": "2269703"
  },
  {
    "text": " JULIAN SHUN: In\nwhich of the regions?",
    "start": "2269704",
    "end": "2275400"
  },
  {
    "text": "So it's loading-- you get a\ncache miss for the purple dots here. ",
    "start": "2275400",
    "end": "2282110"
  },
  {
    "text": "And then the cache\nline size is 4. So you get a cache miss\nfor the first point, and then you hit on\nthe next three points.",
    "start": "2282110",
    "end": "2289040"
  },
  {
    "text": "Then you get another cache\nmiss for the fifth point. And then you hit on\nthe 6, 7, and 8 points.",
    "start": "2289040",
    "end": "2294881"
  },
  {
    "text": "AUDIENCE: I was indicating\nthe one above it. JULIAN SHUN: So for\nthe one above it--",
    "start": "2294882",
    "end": "2300770"
  },
  {
    "text": "so we're assuming that the two\narrays fitting cache already. So we don't actually need\nto load them from memory.",
    "start": "2300770",
    "end": "2306980"
  },
  {
    "text": "The thing above it just\ndepends on the values that we have already computed. And that fits in cache.",
    "start": "2306980",
    "end": "2314690"
  },
  {
    "text": "Those are ready in cache. This base of the trapezoid\nis already in cache.",
    "start": "2314690",
    "end": "2320099"
  },
  {
    "text": "And the row right\nabove it, we just need to look at those values.",
    "start": "2320100",
    "end": "2325830"
  },
  {
    "text": "Does that makes sense? AUDIENCE: OK. Because of the even odd? JULIAN SHUN: Yeah.",
    "start": "2325830",
    "end": "2331180"
  },
  {
    "text": "Yeah.  Any other questions on this?",
    "start": "2331180",
    "end": "2336450"
  },
  {
    "text": " Does anyone want\nto see this again?",
    "start": "2336450",
    "end": "2341980"
  },
  {
    "text": "Yeah? ",
    "start": "2341980",
    "end": "2360640"
  },
  {
    "text": "So I could let this run for\nthe rest of the lecture, but I have more\ninteresting material that I want to talk about.",
    "start": "2360640",
    "end": "2366290"
  },
  {
    "text": "So let's just stop\nafter this finishes. ",
    "start": "2366290",
    "end": "2373247"
  },
  {
    "text": "And as you see again,\nthe looping code is slowly making\nits way to the top. It's much slower than\nthe trapezoid code.",
    "start": "2373247",
    "end": "2379960"
  },
  {
    "start": "2379960",
    "end": "2389330"
  },
  {
    "start": "2388000",
    "end": "2388000"
  },
  {
    "text": "OK. So that was only\nfor one dimensions. Now let's look at what\nhappens in two dimensions.",
    "start": "2389330",
    "end": "2395680"
  },
  {
    "text": "And here, I'm going\nto show another demo. And this demo, I'm actually\ngoing to run the code for real.",
    "start": "2395680",
    "end": "2401290"
  },
  {
    "text": "The previous demo was\njust a simulation. So this is going to\nhappen in real time. And I'm going to simulate\nthe heat in a 2D space.",
    "start": "2401290",
    "end": "2408670"
  },
  {
    "text": "And recall that the colors\ncorrespond to the temperature. So a brighter color\nmeans it's hotter.",
    "start": "2408670",
    "end": "2414790"
  },
  {
    "text": "So let me pull out\nthe other demo. ",
    "start": "2414790",
    "end": "2425770"
  },
  {
    "text": "OK. So here, my mouse cursor\nis the source of heat.",
    "start": "2425770",
    "end": "2432140"
  },
  {
    "text": "So you see that it's making the\npoints around my mouse cursor",
    "start": "2432140",
    "end": "2437269"
  },
  {
    "text": "hot. And then it's slowly diffusing\nits way to the other points.",
    "start": "2437270",
    "end": "2442890"
  },
  {
    "text": "Now I can actually move this\nso that my heat source changes, and then the heat I generated\nearlier slowly goes away.",
    "start": "2442890",
    "end": "2449210"
  },
  {
    "text": " OK. ",
    "start": "2449210",
    "end": "2457430"
  },
  {
    "text": "So in the lower\nleft hand corner, I'm showing the\nnumber of iterations per second of the code.",
    "start": "2457430",
    "end": "2464450"
  },
  {
    "text": "And we can see that the\nlooping code is taking-- it's doing about 1,560\niterations per second.",
    "start": "2464450",
    "end": "2473550"
  },
  {
    "text": "Let's see what happens when we\nswitch to the trapezoid code. ",
    "start": "2473550",
    "end": "2483330"
  },
  {
    "text": "So the trapezoid code is\ndoing about 1,830 iterations",
    "start": "2483330",
    "end": "2489420"
  },
  {
    "text": "per second. So it's a little bit\nfaster, but not by too much.",
    "start": "2489420",
    "end": "2495420"
  },
  {
    "start": "2495420",
    "end": "2500579"
  },
  {
    "text": "Does anyone have an idea why\nwe're seeing this behavior? So we said that\nthe trapezoid code",
    "start": "2500580",
    "end": "2506700"
  },
  {
    "text": "incurs many fewer cache\nmisses than the looping code, so we would expect it to\nbe significantly faster.",
    "start": "2506700",
    "end": "2513240"
  },
  {
    "text": "But here it's only\na little bit faster. Yeah? AUDIENCE: [INAUDIBLE].",
    "start": "2513240",
    "end": "2521328"
  },
  {
    "text": "JULIAN SHUN: Right. So that's a good point. So in 2D you're\nonly saving a factor of square root of M instead\nof M. But square root of M",
    "start": "2521328",
    "end": "2529620"
  },
  {
    "text": "is still pretty big\ncompared to the speed up we're getting here. So any other ideas?",
    "start": "2529620",
    "end": "2535180"
  },
  {
    "text": "Yeah. So there is a constant factor\nin the trapezoidal code. But even after accounting\nfor the constant factor,",
    "start": "2535180",
    "end": "2542160"
  },
  {
    "text": "you should still see a\nbetter speed up than this.",
    "start": "2542160",
    "end": "2547260"
  },
  {
    "text": "So even accounting for\nthe constant factors, what other problem\nmight be going on here?",
    "start": "2547260",
    "end": "2552810"
  },
  {
    "text": "Yeah? AUDIENCE: Is it that we don't\nactually have an ideal cache? JULIAN SHUN: Yeah. So that's another\ngood observation.",
    "start": "2552810",
    "end": "2561180"
  },
  {
    "text": "But the caches that\nwe're using, they still should get pretty good cache.",
    "start": "2561180",
    "end": "2567059"
  },
  {
    "text": "I mean, they should still\nhave cache complexly that's pretty close to\nthe ideal cache model.",
    "start": "2567060",
    "end": "2572160"
  },
  {
    "text": "I mean, you might be off\nby small constant factor, but not by too much. Yeah?",
    "start": "2572160",
    "end": "2577229"
  },
  {
    "text": "AUDIENCE: Maybe\nbecause [INAUDIBLE]  JULIAN SHUN: Sorry.",
    "start": "2577229",
    "end": "2582600"
  },
  {
    "text": "Could you repeat that? AUDIENCE: There are [INAUDIBLE]\nthis time like [INAUDIBLE]",
    "start": "2582600",
    "end": "2587640"
  },
  {
    "text": "JULIAN SHUN: Yeah. So OK. So if I move the\ncursor, it's probably going to be a little bit slower,\ngo slower by a little bit.",
    "start": "2587640",
    "end": "2595440"
  },
  {
    "text": "But that doesn't really\naffect the performance. I can just leave my cursor\nthere and this is what",
    "start": "2595440",
    "end": "2600539"
  },
  {
    "text": "the iterations per second is. ",
    "start": "2600540",
    "end": "2607170"
  },
  {
    "text": "Yes? AUDIENCE: Maybe there's like,\na lot of similar programs doing this [INAUDIBLE].",
    "start": "2607170",
    "end": "2612221"
  },
  {
    "text": " JULIAN SHUN: Yeah.",
    "start": "2612221",
    "end": "2617970"
  },
  {
    "text": "So there is some other\nfactor dominating. Does anyone have an idea\nwhat that factor might be?",
    "start": "2617970",
    "end": "2623250"
  },
  {
    "text": "AUDIENCE: Rendering? JULIAN SHUN: No. It's not the rendering. I ran the code without\nshowing the graphics,",
    "start": "2623250",
    "end": "2630000"
  },
  {
    "text": "and performance was similar. Yes? AUDIENCE: Maybe similar to what\nshe said there could be other",
    "start": "2630000",
    "end": "2636426"
  },
  {
    "text": "things using cache [INAUDIBLE]. ",
    "start": "2636426",
    "end": "2645869"
  },
  {
    "text": "JULIAN SHUN: Yes. Yeah. So there could be other\nthings using the cache. But that would be true\nfor both of the programs.",
    "start": "2645869",
    "end": "2653430"
  },
  {
    "text": "And I don't actually have\nanything that's intensive running, except for PowerPoint. I don't think that\nuses much of my cache.",
    "start": "2653430",
    "end": "2659790"
  },
  {
    "text": " All right. So let's look at why\nthis is the case.",
    "start": "2659790",
    "end": "2669750"
  },
  {
    "text": "So it turns out that the\nhardware is actually helping the looping code.",
    "start": "2669750",
    "end": "2674952"
  },
  {
    "start": "2673000",
    "end": "2673000"
  },
  {
    "text": "So the question is how\ncome the cache oblivious trapezoidal code can have\nso many fewer cache misses,",
    "start": "2674952",
    "end": "2680448"
  },
  {
    "text": "but the advantage gained\nover the looping version is so marginal? Turns out that for\nthe looping code,",
    "start": "2680448",
    "end": "2686660"
  },
  {
    "text": "the hardware is\nactually helping it by doing hardware prefetching. And hardware prefetching\nfor the looping code",
    "start": "2686660",
    "end": "2693079"
  },
  {
    "text": "is actually pretty good,\nbecause the access pattern is very regular. It's just going\none row at a time.",
    "start": "2693080",
    "end": "2698250"
  },
  {
    "text": "So the hardware can predict\nthe memory access pattern of the looping code,\nand therefore, he",
    "start": "2698250",
    "end": "2703670"
  },
  {
    "text": "can bring in the cache lines\nthat the looping code would need before it actually gets to\nthat part of the computation.",
    "start": "2703670",
    "end": "2711240"
  },
  {
    "text": "So prefetching is\nhelping the looping code. And it's not helping\nthe trapezoid code that much because the access\npattern is less regular there.",
    "start": "2711240",
    "end": "2720620"
  },
  {
    "text": "And prefetching does\nuse memory bandwidth. But when you're using\njust a single core, you have more than\nenough bandwidth",
    "start": "2720620",
    "end": "2727550"
  },
  {
    "text": "to take advantage of\nthe hardware prefetching capabilities of the machine.",
    "start": "2727550",
    "end": "2734000"
  },
  {
    "text": "But later on, we'll see that\nwhen we're running in parallel the memory bandwidth\ndoes become more",
    "start": "2734000",
    "end": "2739430"
  },
  {
    "text": "of an issue when you\nhave multiple processors all using the memory.",
    "start": "2739430",
    "end": "2746970"
  },
  {
    "text": "Yeah? Question? AUDIENCE: Is there a way of\ntouching a cache [INAUDIBLE]",
    "start": "2746970",
    "end": "2753984"
  },
  {
    "text": "or touching a piece of memory\nbefore you need it so that you don't need [INAUDIBLE]",
    "start": "2753984",
    "end": "2760302"
  },
  {
    "text": "JULIAN SHUN: You can do\nsoftware prefetching. There are instructions to\ndo software prefetching.",
    "start": "2760302",
    "end": "2766390"
  },
  {
    "text": "Hardware prefetching is\nusually more efficient, but it's like less flexible\nthan the software prefetching.",
    "start": "2766390",
    "end": "2771550"
  },
  {
    "text": "But here we're not\nactually doing that. We're just taking advantage\nof hardware prefetching. AUDIENCE: [INAUDIBLE]?",
    "start": "2771550",
    "end": "2777988"
  },
  {
    "text": "JULIAN SHUN: Yeah. So we didn't actually try that. It could benefit a little\nbit if we used a little bit",
    "start": "2777988",
    "end": "2783670"
  },
  {
    "text": "of software prefetching. Although, I think it would\nbenefit the looping code",
    "start": "2783670",
    "end": "2788950"
  },
  {
    "text": "probably as well if we did that. Yes? AUDIENCE: Is hardware\nprefetching [INAUDIBLE]?? JULIAN SHUN: Sorry? Sorry?",
    "start": "2788950",
    "end": "2794090"
  },
  {
    "text": "AUDIENCE: Is hardware\nprefetching always enabled? JULIAN SHUN: Yeah. So hardware\nprefetching is enabled.",
    "start": "2794090",
    "end": "2800350"
  },
  {
    "text": "It's always done by the\nhardware on the machines that we're using today. ",
    "start": "2800350",
    "end": "2807880"
  },
  {
    "text": "This was a pretty\nsurprising result. But we'll actually see the\nfact of the memory bandwidth",
    "start": "2807880",
    "end": "2813549"
  },
  {
    "text": "later on when we look\nat the parallel code. Any other questions\nbefore I continue?",
    "start": "2813550",
    "end": "2820015"
  },
  {
    "text": " OK. So let's now look at the\ninterplay between caching",
    "start": "2820015",
    "end": "2825520"
  },
  {
    "text": "and parallelism. So this was a theorem that we\nproved in the previous lecture. So let's recall what it says.",
    "start": "2825520",
    "end": "2831625"
  },
  {
    "text": "It says let Q sub p\nbe the number of cache misses in a deterministic\nCilk computation",
    "start": "2831625",
    "end": "2837460"
  },
  {
    "text": "when run on p processors,\neach with a private cache, and let s sub p be the\nnumber of successful steals",
    "start": "2837460",
    "end": "2842920"
  },
  {
    "text": "during the computation. In an ideal cache model\nwith a cache size of M",
    "start": "2842920",
    "end": "2848140"
  },
  {
    "text": "and a block size of\nB, the number of cache misses on p processors\nequal to the number of cache misses on one\nprocessor plus order",
    "start": "2848140",
    "end": "2856450"
  },
  {
    "text": "number of successful\nsteals times M over B. And last time we also said that\nthe number of successful steals",
    "start": "2856450",
    "end": "2864730"
  },
  {
    "text": "is upper bounded by the\nspan of the computation times the number of processors. If you minimize the span\nof your computation,",
    "start": "2864730",
    "end": "2871119"
  },
  {
    "text": "then you can also minimize the\nnumber of successful steals. And then for low\nspan algorithms,",
    "start": "2871120",
    "end": "2876700"
  },
  {
    "text": "the first term is usually\ngoing to dominate the Q1 term. So I'm not going to\ngo over the proof.",
    "start": "2876700",
    "end": "2882400"
  },
  {
    "text": "We did that last time. The moral of the story\nis that minimizing cache misses in\nthe serial elision",
    "start": "2882400",
    "end": "2887860"
  },
  {
    "text": "essentially minimizes them\ninto parallel execution, assuming that you have\na low span algorithm.",
    "start": "2887860",
    "end": "2892917"
  },
  {
    "text": " So let's see whether our\ntrapezoidal algorithm works",
    "start": "2892917",
    "end": "2898869"
  },
  {
    "start": "2897000",
    "end": "2897000"
  },
  {
    "text": "in parallel. So does the space\ncut work in parallel? Recall that the space\ncut, I'm cutting it",
    "start": "2898870",
    "end": "2906583"
  },
  {
    "text": "with a slope of negative\n1 through the center, because it's too wide. So can I execute the two\ntrapezoids in parallel here?",
    "start": "2906583",
    "end": "2914980"
  },
  {
    "text": " No. The reason is that\nthe right trapezoid",
    "start": "2914980",
    "end": "2921650"
  },
  {
    "text": "depends on the result\nof the left trapezoid. So I can't execute\nthem at the same time.",
    "start": "2921650",
    "end": "2927079"
  },
  {
    "text": "But there is a way that I can\nexecute trapezoids in parallel. So instead of just doing\nthe cut through the center,",
    "start": "2927080",
    "end": "2934760"
  },
  {
    "start": "2931000",
    "end": "2931000"
  },
  {
    "text": "I'm actually going\nto do a V-cut. So now I have three trapezoids.",
    "start": "2934760",
    "end": "2941270"
  },
  {
    "text": "The two trapezoid in black-- I can actually execute\nthose in parallel, because they're independent.",
    "start": "2941270",
    "end": "2946580"
  },
  {
    "text": "And everything in\nthose two trapezoids just depends on the\nbase of that trapezoid. And after I'm done with the\ntwo trapezoids labeled 1,",
    "start": "2946580",
    "end": "2954650"
  },
  {
    "text": "then I can compute\nthe trapezoid label 2. And this is known as\na parallel space cut.",
    "start": "2954650",
    "end": "2962330"
  },
  {
    "text": "It produces two black trapezoids\nas well as a gray trapezoid and two black trapezoids\nexecuted in parallel.",
    "start": "2962330",
    "end": "2969800"
  },
  {
    "text": "And afterwards, the\ngray trapezoid executes. And this is done\nrecursively as well.",
    "start": "2969800",
    "end": "2975140"
  },
  {
    "text": " Any questions?",
    "start": "2975140",
    "end": "2981460"
  },
  {
    "text": "Yeah? No. OK. We also have the time cut.",
    "start": "2981460",
    "end": "2987650"
  },
  {
    "text": "Oh, sorry. So if the trapezoid is\ninverted, then we're going to do this\nupside down V-cut.",
    "start": "2987650",
    "end": "2996470"
  },
  {
    "text": "And in this case, we're going\nto execute the middle trapezoid before we execute the two\ntrapezoids on the side.",
    "start": "2996470",
    "end": "3004090"
  },
  {
    "text": " For the time cut, it turns\nout that we're just going",
    "start": "3004090",
    "end": "3010670"
  },
  {
    "text": "to use the same cut as before. And we're just going to execute\nthe two trapezoids serially.",
    "start": "3010670",
    "end": "3016185"
  },
  {
    "text": " So we do get a little\nbit of parallelism here from the\nparallel space cut.",
    "start": "3016185",
    "end": "3024849"
  },
  {
    "start": "3024000",
    "end": "3024000"
  },
  {
    "text": "Let's look at how the\nparallel codes perform now. ",
    "start": "3024850",
    "end": "3046970"
  },
  {
    "text": "So, OK. So this was a\nserial looping code.",
    "start": "3046970",
    "end": "3054530"
  },
  {
    "text": "Here's the parallel\nlooping code. So we had 1,450 before.",
    "start": "3054530",
    "end": "3060971"
  },
  {
    "text": "About 3,700 now. So little over\ntwice the speed up.",
    "start": "3060971",
    "end": "3066382"
  },
  {
    "text": "And this is on a\nfour core machine. It's just on my laptop. AUDIENCE: [INAUDIBLE]?",
    "start": "3066382",
    "end": "3071398"
  },
  {
    "text": "JULIAN SHUN: Sorry? AUDIENCE: [INAUDIBLE]? JULIAN SHUN: Oh yeah, sure. ",
    "start": "3071398",
    "end": "3080360"
  },
  {
    "text": "Yeah, it's slowing down a\nlittle bit, but not by too much. ",
    "start": "3080360",
    "end": "3092560"
  },
  {
    "text": "OK. Let's look at the\ntrapezoidal code now.",
    "start": "3092560",
    "end": "3098590"
  },
  {
    "text": "So as we saw before,\nthe trapezoid code does about 1,840\niterations per second.",
    "start": "3098590",
    "end": "3105430"
  },
  {
    "text": "And we can paralyze this. So now it's doing about\n5,350 iterations per second.",
    "start": "3105430",
    "end": "3114260"
  },
  {
    "text": "So it's getting about a\nfactor of three speed up. ",
    "start": "3114260",
    "end": "3121650"
  },
  {
    "text": "I can move it around a little\nbit more if you want to see it. So serial trapezoid\nand parallel trapezoid.",
    "start": "3121650",
    "end": "3130108"
  },
  {
    "text": " Is everyone happy? ",
    "start": "3130108",
    "end": "3141190"
  },
  {
    "text": "OK. ",
    "start": "3141190",
    "end": "3146357"
  },
  {
    "text": "Because I had to do\nthis in real time, the input size wasn't\nactually that big. So I ran the experiment\noffline without the rendering",
    "start": "3146357",
    "end": "3154809"
  },
  {
    "start": "3151000",
    "end": "3151000"
  },
  {
    "text": "on a much larger input. So this input is a\n3,000 by 3,000 grid.",
    "start": "3154810",
    "end": "3162120"
  },
  {
    "text": "And I did this for 1,000 time\nsteps using four processor cores. And my cache size\nis 8 megabytes.",
    "start": "3162120",
    "end": "3168950"
  },
  {
    "text": "So last level cache size. So the input size here is much\nlarger than my last level cache",
    "start": "3168950",
    "end": "3174460"
  },
  {
    "text": "size. And here are the\ntimes that I got. So the serial looping code\ntook about 129 seconds.",
    "start": "3174460",
    "end": "3183560"
  },
  {
    "text": "And when we did it in parallel,\nit was about 66 seconds. So it got about a\nfactor of two speed up,",
    "start": "3183560",
    "end": "3189820"
  },
  {
    "text": "which is consistent\nwith what we saw. For the trapezoidal code, it\nactually got a better speed up",
    "start": "3189820",
    "end": "3196090"
  },
  {
    "text": "when we increased\nthe input size. So we got about a\nfactor of four speed up. And this is because\nfor larger input size,",
    "start": "3196090",
    "end": "3202180"
  },
  {
    "text": "the cache efficiency\nplays a much larger role, because the cache is so small\ncompared to our input size.",
    "start": "3202180",
    "end": "3210290"
  },
  {
    "text": "So here we see that the\nparallel looping code achieves less than half of\nthe potential speed",
    "start": "3210290",
    "end": "3215980"
  },
  {
    "text": "up, even though the\nparallel looping code has much more\npotential parallelism than the trapezoidal code. So trapezoidal code only had a\nlittle bit of parallelism only",
    "start": "3215980",
    "end": "3223569"
  },
  {
    "text": "for the space cuts, whereas the\ntrapezoidal code is actually",
    "start": "3223570",
    "end": "3229780"
  },
  {
    "text": "getting pretty good speed up. So this is near linear speed\nup, since I'm using four cores",
    "start": "3229780",
    "end": "3234800"
  },
  {
    "text": "and it's getting\n3.96 x speed up.",
    "start": "3234800",
    "end": "3240360"
  },
  {
    "text": "So what could be going on here? ",
    "start": "3240360",
    "end": "3246680"
  },
  {
    "text": "Another thing to\nlook at is to compare the serial trapezoid code with\nthe serial looping code, as well as the parallel trapezoid\ncode with the parallel looping",
    "start": "3246680",
    "end": "3254280"
  },
  {
    "text": "code. So if you look at the\nserial trapezoid code, you see that it's\nabout twice as fast",
    "start": "3254280",
    "end": "3259610"
  },
  {
    "text": "as the serial looping code. But the parallel\ntrapezoid or code is about four times faster\nthan the parallel looping code.",
    "start": "3259610",
    "end": "3266932"
  },
  {
    "text": " And the reason here is\nthat the harbor prefetching",
    "start": "3266932",
    "end": "3273690"
  },
  {
    "text": "can't help the parallel\nlooping code that much. Because when you're running\nin parallel, all of the cores",
    "start": "3273690",
    "end": "3282000"
  },
  {
    "start": "3278000",
    "end": "3278000"
  },
  {
    "text": "are using memory. And there's a memory\nbandwidth bottleneck here. And prefetching actually\nneeds to use memory bandwidth.",
    "start": "3282000",
    "end": "3290260"
  },
  {
    "text": "So in the serial case, we had\nplenty of memory bandwidth we could use for a prefetching,\nbut in the parallel case,",
    "start": "3290260",
    "end": "3297630"
  },
  {
    "text": "we don't actually have much\nparallel-- but much memory bandwidth we can use here.",
    "start": "3297630",
    "end": "3302910"
  },
  {
    "text": "So that's why in\na parallel case, the trapezoid code\ngets a better speed up",
    "start": "3302910",
    "end": "3308760"
  },
  {
    "text": "over the parallel looping code,\ncompared to the serial case. And the trapezoid code\nalso gets better speed up",
    "start": "3308760",
    "end": "3317820"
  },
  {
    "text": "because it does\nthings more locally, so it needs to use less--",
    "start": "3317820",
    "end": "3322950"
  },
  {
    "text": "fewer memory operations. And there's a\nscalability bottleneck at the memory interconnect.",
    "start": "3322950",
    "end": "3328060"
  },
  {
    "text": "But because the trapezoidal\ncode is cache oblivious, it does a lot of work in\ncache, whereas the looping code",
    "start": "3328060",
    "end": "3334290"
  },
  {
    "text": "does more accesses\nto the main memory.",
    "start": "3334290",
    "end": "3339360"
  },
  {
    "text": "Any questions on this? ",
    "start": "3339360",
    "end": "3347190"
  },
  {
    "text": "So how do we know when we have\na parallel speed up bottleneck,",
    "start": "3347190",
    "end": "3353980"
  },
  {
    "text": "how do we know\nwhat's causing it? So there are several main\nthings that we should look at.",
    "start": "3353980",
    "end": "3362300"
  },
  {
    "text": "So we should see if\nour algorithm has insufficient parallelism,\nwhether the scheduling",
    "start": "3362300",
    "end": "3367660"
  },
  {
    "text": "overhead is\ndominating, whether we have a lack of memory\nbandwidth, or whether there is contention going on.",
    "start": "3367660",
    "end": "3373630"
  },
  {
    "text": "And contention can refer to\neither locking or true and false sharing, which we talked\nabout in the last lecture.",
    "start": "3373630",
    "end": "3382170"
  },
  {
    "text": "So the first two are usually\nquite easy to diagnose. You can compute the work in\nthe span of your algorithm,",
    "start": "3382170",
    "end": "3388100"
  },
  {
    "text": "and from that you can\nget the parallelism. You can also use Cilkscale to\nhelp you diagnose the first two",
    "start": "3388100",
    "end": "3394339"
  },
  {
    "text": "problems, because Cilkscale can\ntell you how much parallelism you're getting in your code. And it can also tell you\nthe burden of parallelism",
    "start": "3394340",
    "end": "3400473"
  },
  {
    "text": "which includes the\nscheduler overhead.  What about for memory bandwidth?",
    "start": "3400473",
    "end": "3406880"
  },
  {
    "text": "How can we diagnose that? So does anyone have any ideas?",
    "start": "3406880",
    "end": "3412040"
  },
  {
    "text": " So I can tell you\none way to do it.",
    "start": "3412040",
    "end": "3417310"
  },
  {
    "text": "I can open up my hardware and\ntake out all of my memory chips except for one of them,\nand run my serial code.",
    "start": "3417310",
    "end": "3423750"
  },
  {
    "text": "And if it slows\ndown, then that means it was probably\nmemory bandwidth bound when I did it in parallel.",
    "start": "3423750",
    "end": "3429810"
  },
  {
    "text": "But that's a pretty heavy handed\nway to diagnose this problem. Is there anything we can\ndo was just software?",
    "start": "3429810",
    "end": "3436210"
  },
  {
    "text": "Yes? AUDIENCE: Can we simulate like\nValgrind would do it and count",
    "start": "3436210",
    "end": "3441490"
  },
  {
    "text": "how memory accesses [INAUDIBLE] JULIAN SHUN: Yeah, so you\ncould use a tool like Valgrind",
    "start": "3441490",
    "end": "3448180"
  },
  {
    "text": "to count the number\nof memory accesses. Yes?",
    "start": "3448180",
    "end": "3453458"
  },
  {
    "text": "AUDIENCE: It's like\ntoolset or something where you can make sure\nthat only one processor is",
    "start": "3453458",
    "end": "3460868"
  },
  {
    "text": "being use for this. JULIAN SHUN: So you can make\nsure only one processor is being used, but you can't--",
    "start": "3460868",
    "end": "3466390"
  },
  {
    "text": " but it might be using\nlike, more memory",
    "start": "3466390",
    "end": "3472000"
  },
  {
    "text": "than just the memory\nfrom one chip. There's actually a\nsimpler way to do this.",
    "start": "3472000",
    "end": "3479650"
  },
  {
    "text": "The idea is that we'll\njust run p identical copies of the serial code.",
    "start": "3479650",
    "end": "3485289"
  },
  {
    "text": "And then they will all\nexecuting in parallel. And if the execution\nslows down, then that",
    "start": "3485290",
    "end": "3490480"
  },
  {
    "text": "means they were\nprobably contending for memory bandwidth. Does that make sense?",
    "start": "3490480",
    "end": "3495550"
  },
  {
    "text": " One caveat of this\nis you can only do this if you have enough\nphysical memory, because when",
    "start": "3495550",
    "end": "3502843"
  },
  {
    "text": "you're running p\nidentical copies, you have to use more DRAM\nthan if you just ran one copy.",
    "start": "3502843",
    "end": "3507868"
  },
  {
    "text": "So you have to have\nenough physical memory. But oftentimes, you can usually\nisolate some part of the code that you think has a\nperformance bottleneck,",
    "start": "3507868",
    "end": "3514103"
  },
  {
    "text": "and just execute that\npart of the program with p copies in parallel. And hopefully that\nwill take less memory.",
    "start": "3514103",
    "end": "3521060"
  },
  {
    "text": "There are also\nhardware counters you can check if you have root\naccess to your machine that can measure how\nmuch memory bandwidth",
    "start": "3521060",
    "end": "3527720"
  },
  {
    "text": "your program is using. But this is a pretty\nsimple way to do this.",
    "start": "3527720",
    "end": "3535470"
  },
  {
    "text": "So there are ways to diagnose\nlack of memory bandwidth. Turns out that contention\nis much harder to diagnose.",
    "start": "3535470",
    "end": "3543559"
  },
  {
    "start": "3539000",
    "end": "3539000"
  },
  {
    "text": "There are tools that exist\nthat detect lock contention in an execution, but usually\nthey only detect a contention",
    "start": "3543560",
    "end": "3550250"
  },
  {
    "text": "when the contention\nactually happens, but the contention\ndoesn't have to happen every time you run your code.",
    "start": "3550250",
    "end": "3556860"
  },
  {
    "text": "So these tools don't detect a\npotential for lock contention.",
    "start": "3556860",
    "end": "3562790"
  },
  {
    "text": "And potential for\ntrue and false sharing is even harder to detect,\nespecially false sharing, because if you're using a bunch\nof variables in your code,",
    "start": "3562790",
    "end": "3570440"
  },
  {
    "text": "you don't know which of those\nmap to the same cache line. So this is much\nharder to detect.",
    "start": "3570440",
    "end": "3576650"
  },
  {
    "text": "Usually when you're trying to\ndebug the speed up bottleneck in your code, you would first\nlook at the first three things",
    "start": "3576650",
    "end": "3582820"
  },
  {
    "text": "here. And then once you eliminated\nthose first few things, then you can start looking\nat whether contention",
    "start": "3582820",
    "end": "3588742"
  },
  {
    "text": "is causing the problem.  Any questions?",
    "start": "3588742",
    "end": "3593870"
  },
  {
    "text": " OK. So I talked about\nstencil computation.",
    "start": "3593870",
    "end": "3601100"
  },
  {
    "text": "I want to now talk about\nanother problem, sorting. And we want to do this\ncache efficiently.",
    "start": "3601100",
    "end": "3609170"
  },
  {
    "text": "OK. So let's first analyze\nthe cache complexity of a standard merge sort.",
    "start": "3609170",
    "end": "3614985"
  },
  {
    "text": "So we first need to analyze\nthe complexity of merging, because this is used as a\nsubroutine in merge sort.",
    "start": "3614985",
    "end": "3622500"
  },
  {
    "text": "And as you recall\nin merging, we're given two sorted input arrays. And we want to generate\nan output array that's",
    "start": "3622500",
    "end": "3628769"
  },
  {
    "text": "also sorted containing all the\nelements from the two input arrays. And the algorithm is going to\nmaintain a pointer to the head",
    "start": "3628770",
    "end": "3637260"
  },
  {
    "text": "of each of our input arrays. And then it's going to\ncompare the two elements and take the smaller one\nand put it into the output,",
    "start": "3637260",
    "end": "3643830"
  },
  {
    "text": "and then increment the\npointer for that array. And then we keep doing this,\ntaking the smaller of the two",
    "start": "3643830",
    "end": "3650580"
  },
  {
    "text": "elements until the two\ninput arrays become empty, at which point we're\ndone with the algorithm.",
    "start": "3650580",
    "end": "3657300"
  },
  {
    "text": "We have one sorted output array. ",
    "start": "3657300",
    "end": "3663160"
  },
  {
    "text": "OK. So to merge n elements, the time\nto do this is just theta of n.",
    "start": "3663160",
    "end": "3673450"
  },
  {
    "text": "Here n is the sum of the\nsizes of my two input arrays. And this is because I'm only\ndoing a constant amount of work",
    "start": "3673450",
    "end": "3678880"
  },
  {
    "text": "for each of my input elements. ",
    "start": "3678880",
    "end": "3684200"
  },
  {
    "text": "What about the number\nof cache misses? How many cache misses will incur\nwhen I'm merging n elements?",
    "start": "3684200",
    "end": "3690590"
  },
  {
    "start": "3690590",
    "end": "3697125"
  },
  {
    "text": "Yes? AUDIENCE: [INAUDIBLE]. JULIAN SHUN: Yeah. So I'm going to incur\ntheta of n over B cache misses because my two input\narrays are stored contiguously",
    "start": "3697125",
    "end": "3705920"
  },
  {
    "text": "in memory so I can\nread them at B bytes at a time with just\none cache miss.",
    "start": "3705920",
    "end": "3710930"
  },
  {
    "text": "And then my output array\nis also stored contiguously so I can write\nthings out B bytes at a time with just\none cache miss.",
    "start": "3710930",
    "end": "3717980"
  },
  {
    "text": "I might waste to cache line at\nthe beginning and end of each of my three arrays, but\nthat only affects the bound",
    "start": "3717980",
    "end": "3724130"
  },
  {
    "text": "by a constant factor. So it's theta of n over B.",
    "start": "3724130",
    "end": "3729790"
  },
  {
    "text": "So now let's look at merge sort. So recall that merge sort has\ntwo recursive calls to itself",
    "start": "3729790",
    "end": "3736870"
  },
  {
    "text": "on inputs of half the size. And then it doesn't\nmerge at the end to merge the two sorted\noutputs of its recursive calls.",
    "start": "3736870",
    "end": "3745700"
  },
  {
    "text": "So if you look at how\nthe recursion precedes, its first going to divide the\ninput array into two halves.",
    "start": "3745700",
    "end": "3754965"
  },
  {
    "text": "It's going to divide\nit into two halves again again, until\nyou get to the base",
    "start": "3754965",
    "end": "3760070"
  },
  {
    "text": "case of just one element,\nat which point you return. And then now we start merging\npairs of these elements",
    "start": "3760070",
    "end": "3766040"
  },
  {
    "text": "together. So now I have these arrays\nof size 2 in sorted order. And I merged pairs\nof those arrays.",
    "start": "3766040",
    "end": "3773480"
  },
  {
    "text": "And I get subarrays of size 4. And then finally, I\ndo this one more time",
    "start": "3773480",
    "end": "3779030"
  },
  {
    "text": "to get my sorted output. ",
    "start": "3779030",
    "end": "3784820"
  },
  {
    "text": "OK. So let's review the\nwork of merge sort. So what's the recurrence\nfor merge sort",
    "start": "3784820",
    "end": "3791740"
  },
  {
    "text": "if we're computing the work? Yes? AUDIENCE: [INAUDIBLE].",
    "start": "3791740",
    "end": "3798384"
  },
  {
    "text": "JULIAN SHUN: Yeah. So that's correct. So I have two subproblems\nof size N over 2. And then I need to do theta\nn work to do the merge.",
    "start": "3798384",
    "end": "3805780"
  },
  {
    "text": " And this is case two\nof master theorem.",
    "start": "3805780",
    "end": "3812480"
  },
  {
    "text": "So I'm computing log base b of\na, which is log base 2 of 2. And that's just 1.",
    "start": "3812480",
    "end": "3817840"
  },
  {
    "text": "And that's the same as\nthe exponent in the term that I'm adding in. So since they're the same, I\nadd in an additional log factor.",
    "start": "3817840",
    "end": "3825220"
  },
  {
    "text": "And my overall work is\njust theta of n log n. ",
    "start": "3825220",
    "end": "3831559"
  },
  {
    "text": "OK. So now I'm going to solve\nthis recurrence again using the recursion tree method. I'm still going to\nget theta of n log n.",
    "start": "3831560",
    "end": "3837970"
  },
  {
    "text": "But I'm doing this\nbecause it's going to be useful when we analyze\nthe cache complexity.",
    "start": "3837970",
    "end": "3844330"
  },
  {
    "text": "So at the top level I\nhave a problem of size n. And I'm going to branch into\ntwo problems of size n over 2.",
    "start": "3844330",
    "end": "3850570"
  },
  {
    "text": "And when I'm done\nwith them, I have to do a merge, which\ntakes theta of n work. And I'm just putting n here. I'm ignoring the constants.",
    "start": "3850570",
    "end": "3857500"
  },
  {
    "text": "And I'm going to branch again. And each one of these is going\nto do n over 2 work to merge.",
    "start": "3857500",
    "end": "3863560"
  },
  {
    "text": "And I'm going to get all\nthe way down to my base case after log base 2 of n levels.",
    "start": "3863560",
    "end": "3870460"
  },
  {
    "text": "The top level is doing n work. Second level is\nalso doing n work. And it's going to be the\nsame for all levels down",
    "start": "3870460",
    "end": "3877450"
  },
  {
    "text": "to the leaves. Leaves is also doing a\nlinear amount of work. So the overall work is just\nthe work per level times",
    "start": "3877450",
    "end": "3885609"
  },
  {
    "text": "the number of levels. So it's just theta of n log n. ",
    "start": "3885610",
    "end": "3898869"
  },
  {
    "text": "OK. So now let's analyze\nthis with caching. OK. So we said earlier that\nthe cache complexity",
    "start": "3898870",
    "end": "3906360"
  },
  {
    "text": "of the merging subroutine\nis theta of n over B. And here's the\nrecurrence for the cache",
    "start": "3906360",
    "end": "3912780"
  },
  {
    "text": "complexity of merge sort. So my base case here is when\nn is less than or equal to cM,",
    "start": "3912780",
    "end": "3920099"
  },
  {
    "text": "for some sufficiently\nsmall constant c. And this is because\nat this point,",
    "start": "3920100",
    "end": "3925470"
  },
  {
    "text": "my problem size fits into cache. And everything else\nI do for that problem is still going to be in cache.",
    "start": "3925470",
    "end": "3933480"
  },
  {
    "text": "And to load it into\ncache, the base case, I need to incur theta\nand over B cache misses.",
    "start": "3933480",
    "end": "3939570"
  },
  {
    "text": "And otherwise, I'm going to have\nto recursive calls of size n over 2. And then I need to do\ntheta of n over B cache",
    "start": "3939570",
    "end": "3946710"
  },
  {
    "text": "misses to do the merge\nof my two results. ",
    "start": "3946710",
    "end": "3951990"
  },
  {
    "text": "So here, my base case is larger\nthan what I did for the work.",
    "start": "3951990",
    "end": "3957530"
  },
  {
    "text": "The algorithm actually\nis still recursing down to a constant size base case. But just for analysis, I'm\nstopping the recursion when",
    "start": "3957530",
    "end": "3965490"
  },
  {
    "text": "n is less than or equal to CM. So let's analyze this. So again, I'm going to\nhave the problems of size n",
    "start": "3965490",
    "end": "3972590"
  },
  {
    "text": "at the beginning. And then I'm going to split into\ntwo problems of size n over 2. And then I'm going to\nhave to pay n over B cache",
    "start": "3972590",
    "end": "3979170"
  },
  {
    "text": "misses to merge the\nresults together. Similarly for the\nnext level, now I'm",
    "start": "3979170",
    "end": "3984660"
  },
  {
    "text": "paying n over 2B cache misses\nfor each of my two problems here to do the merge.",
    "start": "3984660",
    "end": "3990660"
  },
  {
    "text": "And I keep going down until\nI get to a subproblem of size",
    "start": "3990660",
    "end": "3996240"
  },
  {
    "text": "theta of cM. At that point, it's\ngoing to fit in cache. And I don't need to recurse\nanymore in my analysis.",
    "start": "3996240",
    "end": "4002750"
  },
  {
    "text": " So number of levels\nof this recursion tree",
    "start": "4002750",
    "end": "4008079"
  },
  {
    "text": "is just log base 2 of n over cM. So I'm basically chopping off\nthe bottom up this recursion",
    "start": "4008080",
    "end": "4014350"
  },
  {
    "text": "tree. The number of levels I had\nbelow this is log base 2 of cM.",
    "start": "4014350",
    "end": "4020589"
  },
  {
    "text": "So I'm taking a log base\n2 of n and subtracting log base 2 of cM. And that's equivalent to log\nbase 2 of n divided by cM.",
    "start": "4020590",
    "end": "4027590"
  },
  {
    "text": " The number of leaves I have\nis n over cM since each leaf",
    "start": "4027590",
    "end": "4035220"
  },
  {
    "text": "is state of cM large. And the number of cache\nmisses I need to incur--",
    "start": "4035220",
    "end": "4040740"
  },
  {
    "text": "to process a leaf is\njust theta of m over B,",
    "start": "4040740",
    "end": "4045990"
  },
  {
    "text": "because I just need to load\nthe input for that subproblem",
    "start": "4045990",
    "end": "4051270"
  },
  {
    "text": "into cache. And then everything\nelse fits in cache. ",
    "start": "4051270",
    "end": "4056890"
  },
  {
    "text": "So for the top level,\nI'm incurring n over B cache misses. The next level, I'm also\nincurring n over B cache",
    "start": "4056890",
    "end": "4063955"
  },
  {
    "text": "misses. Same with the third level. And then for the leaves, I'm\nincurring m over B times n",
    "start": "4063955",
    "end": "4071260"
  },
  {
    "text": "over cM cache misses. The n over cM is\nthe number of leaves I have and theta of m over\nB is the number of cache",
    "start": "4071260",
    "end": "4078355"
  },
  {
    "text": "misses per leaf. And that also equals\ntheta of n over B.",
    "start": "4078355",
    "end": "4085790"
  },
  {
    "text": "So overall, I multiply\ntheta of n over B by the number of levels I have.",
    "start": "4085790",
    "end": "4091760"
  },
  {
    "text": "So the number of levels I have\nis log base 2 of n over cM. And I just got rid\nof the constant here, since doesn't affect\nthe asymptotic bound.",
    "start": "4091760",
    "end": "4099630"
  },
  {
    "text": "So the number of cache misses I\nhave is theta of n over B times log base 2 of-- or any base for the\nlog of n over M.",
    "start": "4099630",
    "end": "4110240"
  },
  {
    "text": "So any questions\non this analysis? ",
    "start": "4110240",
    "end": "4120979"
  },
  {
    "text": "So I am saving a factor of\nB here in the first term.",
    "start": "4120979",
    "end": "4128560"
  },
  {
    "text": "So that does reduce. That just gives me a\nbetter cache complexity than just a work bound.",
    "start": "4128560",
    "end": "4134528"
  },
  {
    "text": "But for the M\nterm, it's actually inside the denominator\nof the log. And that doesn't actually\nhelp me that much.",
    "start": "4134529",
    "end": "4142240"
  },
  {
    "text": "So let's look at how\nmuch we actually save. So one n is much greater than\nM. Then log base 2 of n over M",
    "start": "4142240",
    "end": "4151720"
  },
  {
    "text": "is approximately equal\nto log base 2 of n. So the M term doesn't contribute\nmuch to the asymptotic costs,",
    "start": "4151720",
    "end": "4158109"
  },
  {
    "text": "and therefore,\ncompared to the work, we're only saving\na factor of B. When",
    "start": "4158109",
    "end": "4164585"
  },
  {
    "text": "n is approximately equal to\nM, then log base 2 of n over m is constant, and we're\nsaving a factor of B log n.",
    "start": "4164585",
    "end": "4176020"
  },
  {
    "text": "So we save more when\nthe memory size-- or when the problem\nsize is small. But for large enough\nproblem sizes,",
    "start": "4176020",
    "end": "4182080"
  },
  {
    "text": "we're only saving\na factor of B. So does anyone think that we\ncan do better than this?",
    "start": "4182080",
    "end": "4188420"
  },
  {
    "text": " So I've asked this question\nseveral times before,",
    "start": "4188420",
    "end": "4195623"
  },
  {
    "text": "and the answer is\nalways the same.  Yes? It's a good answer.",
    "start": "4195623",
    "end": "4201310"
  },
  {
    "text": " So we're going to do this\nusing multiway merging.",
    "start": "4201310",
    "end": "4206710"
  },
  {
    "text": "So instead of just merging\ntwo sorted subarrays, we're going to merge\ntogether R sorted subarrays.",
    "start": "4206710",
    "end": "4213400"
  },
  {
    "text": "So we're going to have R\nsubarrays, each of size n over R. And these are sorted.",
    "start": "4213400",
    "end": "4218650"
  },
  {
    "text": "And I'm going to\nmerge them together using what's called\na tournament tree.",
    "start": "4218650",
    "end": "4223840"
  },
  {
    "text": "So how the tournament\ntree works is I'm going to compare the heads of\neach pair of these subarrays",
    "start": "4223840",
    "end": "4231590"
  },
  {
    "text": "and store it in the node\nof the tournament tree. And then after I do that,\nI compare these two nodes. And I get the\nminimum of those two.",
    "start": "4231590",
    "end": "4238330"
  },
  {
    "text": "Eventually, after I compare\nall of the elements, I'm just left with\nthe minimum element",
    "start": "4238330",
    "end": "4243970"
  },
  {
    "text": "at the root of the\ntournament tree. And then I can place\nthat into my output. ",
    "start": "4243970",
    "end": "4250990"
  },
  {
    "text": "So the first time I want to\nfill this tournament tree, it's going to theta of\nR work because there are",
    "start": "4250990",
    "end": "4257159"
  },
  {
    "text": "R nodes in my tournament tree. So when I compare these two\nelements, the smaller one is 6.",
    "start": "4257160",
    "end": "4264570"
  },
  {
    "text": "For these two, the\nsmaller one is 2. And then I compare 2 and\n6, take the smaller one.",
    "start": "4264570",
    "end": "4270910"
  },
  {
    "text": "And then on the other\nside, I have a 7 here. So I compare 2 and 7. 2 is smaller, so it\nappears at the root.",
    "start": "4270910",
    "end": "4277110"
  },
  {
    "text": "And then I know\nthat that's going to be my minimum element among\nthe heads of all of the R",
    "start": "4277110",
    "end": "4282660"
  },
  {
    "text": "subarrays that I'm passing it. ",
    "start": "4282660",
    "end": "4287670"
  },
  {
    "text": "So the first time to\ngenerate this tournament tree takes theta of R work because\nI have to fill in R nodes.",
    "start": "4287670",
    "end": "4295350"
  },
  {
    "text": "But once I generated\nthis tournament tree, for all subsequent rounds, I\nonly need to fill in the path",
    "start": "4295350",
    "end": "4302640"
  },
  {
    "text": "from the element that one\nto the output or right, or to the root of\nthe tournament tree, because those are the only\nvalues that would have changed.",
    "start": "4302640",
    "end": "4310000"
  },
  {
    "text": "So now I'm going to\nfill in this path here. And this only takes theta\nof log R work to do it,",
    "start": "4310000",
    "end": "4315660"
  },
  {
    "text": "because the height of\nthis tournament tree is log base 2 of R.",
    "start": "4315660",
    "end": "4321150"
  },
  {
    "text": "So I'm going to fill this in. Now 14 goes here. 6 is a smaller of the two. And then 6 is a smaller\nof the two again.",
    "start": "4321150",
    "end": "4327719"
  },
  {
    "text": "So my next element is 6. ",
    "start": "4327720",
    "end": "4334090"
  },
  {
    "text": "And I keep doing this until\nall of the elements for my R subarrays get put\ninto the output.",
    "start": "4334090",
    "end": "4341680"
  },
  {
    "text": "The total work for\nmerging is going to be theta of R\nfor the first round,",
    "start": "4341680",
    "end": "4346750"
  },
  {
    "text": "plus n log R for all\nthe remaining rounds. And that's just equal\nto theta of n log R,",
    "start": "4346750",
    "end": "4353740"
  },
  {
    "text": "because we're assuming that\nn is bigger than R here. Any questions on how the\nmultiway merge works?",
    "start": "4353740",
    "end": "4360742"
  },
  {
    "text": " No? OK.",
    "start": "4360743",
    "end": "4365830"
  },
  {
    "text": "So let's analyze the\nwork of this multiway merge when used\ninside merge sort.",
    "start": "4365830",
    "end": "4373260"
  },
  {
    "text": "So the recurrence is\ngoing to be as follows. So if n is 1, then we just\ndo a constant amount of work.",
    "start": "4373260",
    "end": "4380190"
  },
  {
    "text": "Otherwise, we have R\nsubproblems of size n over R. And then we're paying theta of n\nlog R to do the multiway merge.",
    "start": "4380190",
    "end": "4388970"
  },
  {
    "text": "So here's the recursion tree. At the top level, we\nhave a problem of size n.",
    "start": "4388970",
    "end": "4395389"
  },
  {
    "text": "And then we're going to split\ninto R subproblems of size n/R. And then we have\nto pay n log R work to merge the results of the\nrecursive call together.",
    "start": "4395390",
    "end": "4404800"
  },
  {
    "text": "And then we keep doing this. Turns out that the\nwork at each level sums up to n log base 2 of\nR. And the number of levels",
    "start": "4404800",
    "end": "4415370"
  },
  {
    "text": "we have here is log base R\nof n, because each time we're branching by a factor of R. For\nthe leaves, we have n leaves.",
    "start": "4415370",
    "end": "4425750"
  },
  {
    "text": "And we just pay\nlinear work for that, because we don't have\nto pay for the merge. We're not doing anymore\nrecursive calls.",
    "start": "4425750",
    "end": "4432890"
  },
  {
    "text": "So the overall work is\ngoing to be theta of n log R times log base R of n,\nplus n for the leaves,",
    "start": "4432890",
    "end": "4440960"
  },
  {
    "text": "but that's just a\nlower order term. And if you work out the\nmath, some of these terms are going to cancel\nout, and you just",
    "start": "4440960",
    "end": "4446660"
  },
  {
    "text": "get theta of log n for the work. So the work is the same\nas the binary merge sort.",
    "start": "4446660",
    "end": "4454070"
  },
  {
    "text": "Let's now analyze\nthe cash complexity. So let's assume that\nwe have R less than cM",
    "start": "4454070",
    "end": "4460760"
  },
  {
    "text": "over B for a sufficiently\nsmall constant C less than or equal to 1.",
    "start": "4460760",
    "end": "4465940"
  },
  {
    "text": "We're going to consider the\nR way merging of contiguous arrays of total size n.",
    "start": "4465940",
    "end": "4471170"
  },
  {
    "text": "And if R is less than\ncM over B, then we can fit the entire\ntournament tree into cache.",
    "start": "4471170",
    "end": "4476780"
  },
  {
    "text": "And we can also fit one block\nfrom each of the R subarrays into cache.",
    "start": "4476780",
    "end": "4483679"
  },
  {
    "text": "And in that case, the\ntotal number of cache misses to do the multiway merge\nis just theta of n over B,",
    "start": "4483680",
    "end": "4491090"
  },
  {
    "text": "because we just have to go over\nthe n elements in our input arrays.",
    "start": "4491090",
    "end": "4497230"
  },
  {
    "text": "So the recurrence for the R\nway merge sort is as follows. So if n is less than cM,\nthen it fits in cache.",
    "start": "4497230",
    "end": "4504390"
  },
  {
    "text": "So the number of cache misses we\npay is just theta of n over B. And otherwise, we have R\nsubproblems of size n over R.",
    "start": "4504390",
    "end": "4510080"
  },
  {
    "text": "And that we add\ntheta of n over B to do the merge of the\nresults of the subproblems.",
    "start": "4510080",
    "end": "4515750"
  },
  {
    "text": "Any questions on\nthe recurrence here? ",
    "start": "4515750",
    "end": "4523540"
  },
  {
    "text": "Yes? AUDIENCE: So how do we\npick up the value of R? Does it make it cache oblivious?",
    "start": "4523540",
    "end": "4529449"
  },
  {
    "text": "JULIAN SHUN: Good question. So we didn't pick\nthe value of R. So this is not a cache\noblivious algorithm.",
    "start": "4529450",
    "end": "4534891"
  },
  {
    "start": "4534891",
    "end": "4540080"
  },
  {
    "text": "And we'll see what to choose\nfor R in a couple of slides. So let's analyze the cache\ncomplexity of this algorithm",
    "start": "4540080",
    "end": "4548430"
  },
  {
    "text": "again, using the\nrecursion tree analysis. So at the top level, we're going\nto have R subproblems of size",
    "start": "4548430",
    "end": "4557090"
  },
  {
    "text": "n over R. And we have\nto pay n over B cache misses to merge them. And it turns out that at each\nlevel, the number of cache",
    "start": "4557090",
    "end": "4565470"
  },
  {
    "text": "misses we have to pay is n over\nB, if you work out the math. And the number of levels\nof this recursion tree",
    "start": "4565470",
    "end": "4571260"
  },
  {
    "text": "is going to be log\nbase R of n over cM, because we're going\nto stop recurring when our problem size is cM.",
    "start": "4571260",
    "end": "4578100"
  },
  {
    "text": "And on every level\nof recursion, we're branching by a factor of R. So\nour leaf size is cM, therefore",
    "start": "4578100",
    "end": "4587670"
  },
  {
    "text": "the number of leaves\nwe have is n over cM. And for each leaf, it's going\nto take theta of m over B cache",
    "start": "4587670",
    "end": "4594270"
  },
  {
    "text": "misses to load it into cache. And afterwards, we can\ndo everything in cache. And multiplying the number of\nleaves by the cost per leaf,",
    "start": "4594270",
    "end": "4603300"
  },
  {
    "text": "we get theta of n\nover B cache misses. And therefore, the\nnumber of cache",
    "start": "4603300",
    "end": "4608670"
  },
  {
    "text": "misses is n over B times\nthe number of levels. Number of levels is\nlog base R of n over M.",
    "start": "4608670",
    "end": "4617389"
  },
  {
    "text": "So compared to the binary\nmerge sort algorithm, here we actually have a factor\nof R in the base of the log.",
    "start": "4617390",
    "end": "4624630"
  },
  {
    "text": "Before, the base of\nthe log was just 2. So now the question is what\nwe're going to set R to be.",
    "start": "4624630",
    "end": "4635080"
  },
  {
    "text": "So again, we have\na voodoo parameter. This is not a cache\noblivious algorithm.",
    "start": "4635080",
    "end": "4640330"
  },
  {
    "text": "And we said that R has to be\nless than or equal to cM over B in order for the\nanalysis to work out.",
    "start": "4640330",
    "end": "4645670"
  },
  {
    "text": "So let's just make it\nas large as possible. Let's just set R equal\nto theta of M over B.",
    "start": "4645670",
    "end": "4652239"
  },
  {
    "text": "And now we can see what this\ncomplexity works out to be.",
    "start": "4652240",
    "end": "4657250"
  },
  {
    "text": "So we have the total\ncache assumption. We also have the fact that\nlog base M of n over M",
    "start": "4657250",
    "end": "4663550"
  },
  {
    "text": "is equal to theta\nof log n over log M. So the cache complexity is\ntheta of n over B times log base",
    "start": "4663550",
    "end": "4673090"
  },
  {
    "text": "M over B of n over M. But if we\nhave the tall cache assumption that log base M over B is\nthe same as log base of M",
    "start": "4673090",
    "end": "4680870"
  },
  {
    "text": "asymptotically. So that's how we get\nto the second line. And then you can\nrearrange some terms",
    "start": "4680870",
    "end": "4687550"
  },
  {
    "text": "and cancel some terms out. And we'll end up with theta\nof n log n divided by B log M.",
    "start": "4687550",
    "end": "4695560"
  },
  {
    "text": "So we're saving\na factor of theta of b log M compared to\nthe work of the algorithm,",
    "start": "4695560",
    "end": "4703030"
  },
  {
    "text": "whereas for the binary\nversion of merge sort, we were only saving a factor\nof B for large enough inputs.",
    "start": "4703030",
    "end": "4708550"
  },
  {
    "text": "So here we get another factor\nof log M in our savings.",
    "start": "4708550",
    "end": "4716050"
  },
  {
    "text": "So as I said, the binary one\ncache misses is n log n over B,",
    "start": "4716050",
    "end": "4721239"
  },
  {
    "text": "whereas the multiway one\nis n log n over B log M. And as longest as n is\nmuch greater than M,",
    "start": "4721240",
    "end": "4727869"
  },
  {
    "text": "then we're actually saving much\nmore than the binary version. So we're saving a factor\nof log M in cache misses.",
    "start": "4727870",
    "end": "4735970"
  },
  {
    "text": "And let's just ignore the\nconstants here and look at what log M can be in practice.",
    "start": "4735970",
    "end": "4742060"
  },
  {
    "text": "So here are some\ntypical cache sizes. The L1 cache size\nis 32 kilobytes, so that's 2 to the 15th.",
    "start": "4742060",
    "end": "4748330"
  },
  {
    "text": "And log base 2 of that is 15. So we get a 15x savings. And then for the\nlarger cache sizes,",
    "start": "4748330",
    "end": "4754780"
  },
  {
    "text": "we get even larger saving. So any questions on this? ",
    "start": "4754780",
    "end": "4763409"
  },
  {
    "text": "So the problem\nwith this algorithm is that it's not\ncache oblivious. We have to tune the value of\nR for a particular machine.",
    "start": "4763410",
    "end": "4771610"
  },
  {
    "text": "And even when we're running\non the same machine, there could be\nother jobs running that contend for the cache.",
    "start": "4771610",
    "end": "4777420"
  },
  {
    "text": "Turns out that there are\nseveral cache oblivious sorting algorithms. The first one that was\ndeveloped was by paper",
    "start": "4777420",
    "end": "4784740"
  },
  {
    "text": "by Charles Leiserson, and\nit's called funnel sort. The idea here is to recursively\nsort n to the 1/3 groups of n",
    "start": "4784740",
    "end": "4792000"
  },
  {
    "text": "to the 2/3 elements, and\nthen merge the sorted groups with an n to the 1/3 funnel.",
    "start": "4792000",
    "end": "4799020"
  },
  {
    "text": "And this funnel is called\na k funnel, more generally, and it merges together k cubed\nelements in a k sorted list.",
    "start": "4799020",
    "end": "4807180"
  },
  {
    "text": "And the costs for doing\nthis merge is shown here. And if you plug this\ninto the recurrence,",
    "start": "4807180",
    "end": "4813270"
  },
  {
    "text": "you'll get that, the\nasymptotic number of cache misses is the same as\nthat of the multiway",
    "start": "4813270",
    "end": "4818460"
  },
  {
    "text": "merge sort algorithm while\nbeing cache oblivious. And this bound is\nactually optimal.",
    "start": "4818460",
    "end": "4824508"
  },
  {
    "text": "So I'm not going to\nhave time to talk about the details of the\nfunnel sort algorithm. But I do have time\nto just show you",
    "start": "4824508",
    "end": "4830700"
  },
  {
    "text": "a pretty picture of what\nthe funnel looks like. So this is what a k\nfunnel looks like. It's recursively constructed.",
    "start": "4830700",
    "end": "4837719"
  },
  {
    "text": "We have a bunch of square\nroot of k funnels inside. They're all connected\nto some buffers. So they feed\nelements the buffer,",
    "start": "4837720",
    "end": "4844170"
  },
  {
    "text": "and then the\nbuffers feed element to this output square root\nof k funnel, which becomes",
    "start": "4844170",
    "end": "4850483"
  },
  {
    "text": "the output for the k funnel. So this whole blue\nthing is the k funnel. And the small green triangles\nare square root of k funnels.",
    "start": "4850483",
    "end": "4858900"
  },
  {
    "text": "And the number of cache misses\nincurred by doing this merge is shown here. And it uses the tall cache\nassumption for analysis.",
    "start": "4858900",
    "end": "4867449"
  },
  {
    "text": "So a pretty cool algorithm. And we've posted a paper online\nthat describes this algorithm. So if you're interested\nin the details,",
    "start": "4867450",
    "end": "4873360"
  },
  {
    "text": "I encourage you to\nread that paper. There are also many other cache\noblivious algorithms out there.",
    "start": "4873360",
    "end": "4878460"
  },
  {
    "text": "So there's been\nhundreds of papers on cache oblivious algorithms. Here are some of them.",
    "start": "4878460",
    "end": "4883800"
  },
  {
    "text": "Some of these are also\ndescribed in the paper. In fact, I think all\nof these are described in the paper we posted.",
    "start": "4883800",
    "end": "4889880"
  },
  {
    "text": "There are also some cool cache\noblivious data structures that have been developed,\nsuch as for B-trees,",
    "start": "4889880",
    "end": "4895650"
  },
  {
    "text": "ordered-file maintenance,\nand priority queues. So it's a lot of literature\non cache oblivious algorithms.",
    "start": "4895650",
    "end": "4900930"
  },
  {
    "text": "And there's also a\nlot of material online if you're interested\nin learning more. ",
    "start": "4900930",
    "end": "4906490"
  }
]
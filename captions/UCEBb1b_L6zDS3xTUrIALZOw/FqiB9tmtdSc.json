[
  {
    "start": "4500",
    "end": "4500"
  },
  {
    "text": "Pre-processing the\ndata can be difficult,",
    "start": "4500",
    "end": "7130"
  },
  {
    "text": "but, luckily, R's packages\nprovide easy-to-use functions",
    "start": "7130",
    "end": "11280"
  },
  {
    "text": "for the most common tasks.",
    "start": "11280",
    "end": "13400"
  },
  {
    "text": "In this video, we'll\nload and process our data",
    "start": "13400",
    "end": "16529"
  },
  {
    "text": "in R. In your R\nconsole, let's load",
    "start": "16530",
    "end": "20300"
  },
  {
    "text": "the data set tweets.csv\nwith the read.csv function.",
    "start": "20300",
    "end": "25560"
  },
  {
    "text": "But since we're working\nwith text data here,",
    "start": "25560",
    "end": "28029"
  },
  {
    "text": "we need one extra\nargument, which is",
    "start": "28030",
    "end": "29740"
  },
  {
    "text": "stringsAsFactors=FALSE.",
    "start": "29740",
    "end": "30699"
  },
  {
    "text": "So we'll call our\ndata set tweets.",
    "start": "33390",
    "end": "36110"
  },
  {
    "text": "And we'll use the read.csv\nfunction to read in the data",
    "start": "36110",
    "end": "39440"
  },
  {
    "text": "file tweets.csv, but then\nwe'll add the extra argument",
    "start": "39440",
    "end": "44019"
  },
  {
    "text": "stringsAsFactors=FALSE.",
    "start": "44020",
    "end": "44980"
  },
  {
    "text": "You'll always need to add\nthis extra argument when",
    "start": "51530",
    "end": "54149"
  },
  {
    "text": "working on a text\nanalytics problem",
    "start": "54150",
    "end": "56660"
  },
  {
    "text": "so that the text is\nread in properly.",
    "start": "56660",
    "end": "60040"
  },
  {
    "text": "Now let's take a\nlook at the structure",
    "start": "60040",
    "end": "61670"
  },
  {
    "text": "of our data with\nthe str function.",
    "start": "61670",
    "end": "63620"
  },
  {
    "text": "We can see that we have 1,181\nobservations of two variables,",
    "start": "66450",
    "end": "72250"
  },
  {
    "text": "the text of the\ntweet, called Tweet,",
    "start": "72250",
    "end": "74960"
  },
  {
    "text": "and the average sentiment\nscore, called Avg for average.",
    "start": "74960",
    "end": "79500"
  },
  {
    "text": "The tweet texts are\nreal tweets that we",
    "start": "79500",
    "end": "81610"
  },
  {
    "text": "found on the internet directed\nto Apple with a few cleaned up",
    "start": "81610",
    "end": "85000"
  },
  {
    "text": "words.",
    "start": "85000",
    "end": "86390"
  },
  {
    "text": "We're more interested\nin being able to detect",
    "start": "86390",
    "end": "89250"
  },
  {
    "text": "the tweets with clear\nnegative sentiment,",
    "start": "89250",
    "end": "92220"
  },
  {
    "text": "so let's define a new\nvariable in our data",
    "start": "92220",
    "end": "94910"
  },
  {
    "text": "set tweets called Negative.",
    "start": "94910",
    "end": "98509"
  },
  {
    "text": "And we'll set this equal to\nas.factor(tweets$Avg = -1).",
    "start": "98509",
    "end": "100810"
  },
  {
    "text": "This will set tweets$Negative\nequal to true if the average",
    "start": "111000",
    "end": "115180"
  },
  {
    "text": "sentiment score is less than\nor equal to negative 1 and will",
    "start": "115180",
    "end": "118560"
  },
  {
    "text": "set tweets$Negative equal to\nfalse if the average sentiment",
    "start": "118560",
    "end": "122460"
  },
  {
    "text": "score is greater\nthan negative 1.",
    "start": "122460",
    "end": "125049"
  },
  {
    "text": "Let's look at a table of\nthis new variable, Negative.",
    "start": "125050",
    "end": "127610"
  },
  {
    "text": "We can see that 182 of the\n1,181 tweets, or about 15%,",
    "start": "132360",
    "end": "139320"
  },
  {
    "text": "are negative.",
    "start": "139320",
    "end": "139870"
  },
  {
    "text": "Now to pre-process\nour text data so",
    "start": "142630",
    "end": "144829"
  },
  {
    "text": "that we can use the\nbag of words approach,",
    "start": "144829",
    "end": "147250"
  },
  {
    "text": "we'll be using the tm\ntext mining package.",
    "start": "147250",
    "end": "150850"
  },
  {
    "text": "We'll need to install and\nload two packages to do this.",
    "start": "150850",
    "end": "155250"
  },
  {
    "text": "First, let's install the\npackage tm, and go ahead",
    "start": "155250",
    "end": "161590"
  },
  {
    "text": "and select a CRAN\nmirror near you.",
    "start": "161590",
    "end": "163620"
  },
  {
    "text": "As soon as that package\nis done installing",
    "start": "167380",
    "end": "169910"
  },
  {
    "text": "and you're back at\nthe blinking cursor,",
    "start": "169910",
    "end": "171990"
  },
  {
    "text": "go ahead and load that package\nwith the library command.",
    "start": "171990",
    "end": "176640"
  },
  {
    "text": "Then we also need to install\nthe package snowballC.",
    "start": "176640",
    "end": "180990"
  },
  {
    "text": "This package helps us\nuse the tm package.",
    "start": "184230",
    "end": "187530"
  },
  {
    "text": "And go ahead and load the\nsnowball package as well.",
    "start": "187530",
    "end": "190330"
  },
  {
    "text": "One of the concepts\nintroduced by the tm package",
    "start": "193280",
    "end": "196610"
  },
  {
    "text": "is that of a corpus.",
    "start": "196610",
    "end": "198660"
  },
  {
    "text": "A corpus is a\ncollection of documents.",
    "start": "198660",
    "end": "201329"
  },
  {
    "text": "We'll need to convert our tweets\nto a corpus for pre-processing.",
    "start": "201329",
    "end": "206099"
  },
  {
    "text": "tm can create a corpus\nin many different ways,",
    "start": "206100",
    "end": "209160"
  },
  {
    "text": "but we'll create it from the\ntweet column of our data frame",
    "start": "209160",
    "end": "212420"
  },
  {
    "text": "using two functions,\ncorpus and vector source.",
    "start": "212420",
    "end": "216420"
  },
  {
    "text": "We'll call our corpus\n\"corpus\" and then",
    "start": "216420",
    "end": "219310"
  },
  {
    "text": "use the corpus and the\nvector source functions",
    "start": "219310",
    "end": "224030"
  },
  {
    "text": "called on our tweets variable\nof our tweets data set.",
    "start": "224030",
    "end": "228840"
  },
  {
    "text": "So that's tweets$Tweet.",
    "start": "228840",
    "end": "229800"
  },
  {
    "text": "We can check that\nthis has worked",
    "start": "234140",
    "end": "235710"
  },
  {
    "text": "by typing corpus and seeing\nthat our corpus has 1,181 text",
    "start": "235710",
    "end": "241210"
  },
  {
    "text": "documents.",
    "start": "241210",
    "end": "243040"
  },
  {
    "text": "And we can check that the\ndocuments match our tweets",
    "start": "243040",
    "end": "246069"
  },
  {
    "text": "by using double brackets.",
    "start": "246070",
    "end": "247430"
  },
  {
    "text": "So type corpus[[1]].",
    "start": "247430",
    "end": "248269"
  },
  {
    "text": "This shows us the first\ntweet in our corpus.",
    "start": "253860",
    "end": "258130"
  },
  {
    "text": "Now we're ready to start\npre-processing our data.",
    "start": "258130",
    "end": "261660"
  },
  {
    "text": "Pre-processing is easy in tm.",
    "start": "261660",
    "end": "264470"
  },
  {
    "text": "Each operation, like stemming\nor removing stop words,",
    "start": "264470",
    "end": "268010"
  },
  {
    "text": "can be done with\none line in R, where",
    "start": "268010",
    "end": "270180"
  },
  {
    "text": "we use the tm_map function.",
    "start": "270180",
    "end": "273009"
  },
  {
    "text": "Let's try it out by changing\nall of the text in our tweets",
    "start": "273010",
    "end": "276190"
  },
  {
    "text": "to lowercase.",
    "start": "276190",
    "end": "277840"
  },
  {
    "text": "To do that, we'll\nreplace our corpus",
    "start": "277840",
    "end": "280540"
  },
  {
    "text": "with the output of the\ntm_map function, where",
    "start": "280540",
    "end": "285290"
  },
  {
    "text": "the first argument is\nthe name of our corpus",
    "start": "285290",
    "end": "288430"
  },
  {
    "text": "and the second argument\nis what we want to do.",
    "start": "288430",
    "end": "290780"
  },
  {
    "text": "In this case, tolower.",
    "start": "290780",
    "end": "294440"
  },
  {
    "text": "tolower is a standard\nfunction in R,",
    "start": "294440",
    "end": "297320"
  },
  {
    "text": "and this is like when we pass\nmean to the tapply function.",
    "start": "297320",
    "end": "300850"
  },
  {
    "text": "We're passing the\ntm_map function",
    "start": "300850",
    "end": "303780"
  },
  {
    "text": "a function to use on our corpus.",
    "start": "303780",
    "end": "307620"
  },
  {
    "text": "Let's see what that did by\nlooking at our first tweet",
    "start": "307620",
    "end": "310180"
  },
  {
    "text": "again.",
    "start": "310180",
    "end": "310870"
  },
  {
    "text": "Go ahead and hit the up\narrow twice to get back",
    "start": "310870",
    "end": "313139"
  },
  {
    "text": "to corpuscorpus{[1] and now we can\nsee that all of our letters are",
    "start": "313140",
    "end": "317410"
  },
  {
    "text": "lowercase.",
    "start": "317410",
    "end": "317910"
  },
  {
    "text": "Now let's remove\nall punctuation.",
    "start": "320980",
    "end": "323950"
  },
  {
    "text": "This is done in a\nvery similar way,",
    "start": "323950",
    "end": "326070"
  },
  {
    "text": "except this time we\ngive the argument",
    "start": "326070",
    "end": "328370"
  },
  {
    "text": "removePunctuation\ninstead of tolower.",
    "start": "328370",
    "end": "331639"
  },
  {
    "text": "Hit the up arrow twice,\nand in the tm_map function,",
    "start": "331640",
    "end": "335120"
  },
  {
    "text": "delete tolower, and\ntype removePunctuation.",
    "start": "335120",
    "end": "337990"
  },
  {
    "text": "Let's see what this did\nto our first tweet again.",
    "start": "341210",
    "end": "344100"
  },
  {
    "text": "Now the comma after \"say\",\nthe exclamation point after",
    "start": "344100",
    "end": "347540"
  },
  {
    "text": "\"received\", and the @ symbols\nbefore \"Apple\" are all gone.",
    "start": "347540",
    "end": "352990"
  },
  {
    "text": "Now we want to remove the\nstop words in our tweets.",
    "start": "352990",
    "end": "356860"
  },
  {
    "text": "tm provides a list of stop\nwords for the English language.",
    "start": "356860",
    "end": "360069"
  },
  {
    "text": "We can check it out by typing\nstopwords(\"english\") [1:10].",
    "start": "360070",
    "end": "362490"
  },
  {
    "text": "We see that these\nare words like \"I,\"",
    "start": "372300",
    "end": "374430"
  },
  {
    "text": "\"me,\" \"my,\" \"myself,\" et cetera.",
    "start": "374430",
    "end": "378490"
  },
  {
    "text": "Removing words can be done\nwith the removeWords argument",
    "start": "378490",
    "end": "381610"
  },
  {
    "text": "to the tm_map function, but\nwe need one extra argument",
    "start": "381610",
    "end": "384740"
  },
  {
    "text": "this time-- what the stop words\nare that we want to remove.",
    "start": "384740",
    "end": "388830"
  },
  {
    "text": "We'll remove all of\nthese English stop words,",
    "start": "388830",
    "end": "391370"
  },
  {
    "text": "but we'll also remove\nthe word \"apple\"",
    "start": "391370",
    "end": "393750"
  },
  {
    "text": "since all of these tweets\nhave the word \"apple\"",
    "start": "393750",
    "end": "396310"
  },
  {
    "text": "and it probably won't be\nvery useful in our prediction",
    "start": "396310",
    "end": "399040"
  },
  {
    "text": "problem.",
    "start": "399040",
    "end": "400600"
  },
  {
    "text": "So go ahead and hit the\nup arrow to get back",
    "start": "400600",
    "end": "402659"
  },
  {
    "text": "to the tm_map function, delete\nremovePunctuation and, instead,",
    "start": "402659",
    "end": "407730"
  },
  {
    "text": "type removeWords.",
    "start": "407730",
    "end": "408440"
  },
  {
    "text": "Then we need to add one\nextra argument, c(\"apple\").",
    "start": "412210",
    "end": "414759"
  },
  {
    "text": "This is us removing\nthe word \"apple.\"",
    "start": "419230",
    "end": "421730"
  },
  {
    "text": "And then stopwords(\"english\").",
    "start": "421730",
    "end": "422980"
  },
  {
    "text": "So this will remove\nthe word \"apple\"",
    "start": "428020",
    "end": "430259"
  },
  {
    "text": "and all of the\nEnglish stop words.",
    "start": "430260",
    "end": "434060"
  },
  {
    "text": "Let's take a look\nat our first tweet",
    "start": "434060",
    "end": "435560"
  },
  {
    "text": "again to see what happened.",
    "start": "435560",
    "end": "436680"
  },
  {
    "text": "Now we can see that we have\nsignificantly fewer words, only",
    "start": "440470",
    "end": "443590"
  },
  {
    "text": "the words that are\nnot stop words.",
    "start": "443590",
    "end": "446730"
  },
  {
    "text": "Lastly, we want to stem our\ndocument with the stem document",
    "start": "446730",
    "end": "450230"
  },
  {
    "text": "argument.",
    "start": "450230",
    "end": "451220"
  },
  {
    "text": "Go ahead and scroll back up\nto the removePunctuation,",
    "start": "451220",
    "end": "454850"
  },
  {
    "text": "delete removePunctuation,\nand type stemDocument.",
    "start": "454850",
    "end": "460090"
  },
  {
    "text": "If you hit Enter and then\nlook at the first tweet again,",
    "start": "460090",
    "end": "463830"
  },
  {
    "text": "we can see that this took\noff the ending of \"customer,\"",
    "start": "463830",
    "end": "468539"
  },
  {
    "text": "\"service,\" \"received,\"\nand \"appstore.\"",
    "start": "468540",
    "end": "472260"
  },
  {
    "text": "In the next video, we'll\ninvestigate our corpus",
    "start": "472260",
    "end": "475360"
  },
  {
    "text": "and prepare it for our\nprediction problem.",
    "start": "475360",
    "end": "478509"
  }
]
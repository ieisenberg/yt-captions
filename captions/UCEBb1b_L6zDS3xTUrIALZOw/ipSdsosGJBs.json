[
  {
    "start": "0",
    "end": "1000"
  },
  {
    "text": "We have presented\nthe complete solution",
    "start": "1000",
    "end": "3540"
  },
  {
    "text": "to the liner least mean squares\nestimation problem, when",
    "start": "3540",
    "end": "6920"
  },
  {
    "text": "we want to estimate a certain\nunknown random variable",
    "start": "6920",
    "end": "10430"
  },
  {
    "text": "on the basis of a\ndifferent random variable X",
    "start": "10430",
    "end": "13720"
  },
  {
    "text": "that we get to observe.",
    "start": "13720",
    "end": "15550"
  },
  {
    "text": "But what if we have\nmultiple observations?",
    "start": "15550",
    "end": "19720"
  },
  {
    "text": "What would be the analogous\nformulation of the problem?",
    "start": "19720",
    "end": "23509"
  },
  {
    "text": "Here's the idea.",
    "start": "23510",
    "end": "24950"
  },
  {
    "text": "Once more, we restrict\nourselves to estimators",
    "start": "24950",
    "end": "28320"
  },
  {
    "text": "that are linear functions of\nthe data, linear functions",
    "start": "28320",
    "end": "31970"
  },
  {
    "text": "of the observations\nthat we have.",
    "start": "31970",
    "end": "34280"
  },
  {
    "text": "And then we pose the\nproblem of finding the best",
    "start": "34280",
    "end": "37670"
  },
  {
    "text": "choices of these coefficients\na1 up to a n and b.",
    "start": "37670",
    "end": "42570"
  },
  {
    "text": "What does it mean to\nfind the best choices?",
    "start": "42570",
    "end": "45540"
  },
  {
    "text": "It means that if we\nfix certain choices,",
    "start": "45540",
    "end": "49010"
  },
  {
    "text": "we obtain an estimator,\nwe look at the difference",
    "start": "49010",
    "end": "52170"
  },
  {
    "text": "between the estimator\nand the quantity",
    "start": "52170",
    "end": "54480"
  },
  {
    "text": "we're trying to estimate,\ntake the square,",
    "start": "54480",
    "end": "56700"
  },
  {
    "text": "and then take the expectation.",
    "start": "56700",
    "end": "58880"
  },
  {
    "text": "So once more, we're looking\nat the mean squared error",
    "start": "58880",
    "end": "61910"
  },
  {
    "text": "of our estimator and we try to\nmake it as small as possible.",
    "start": "61910",
    "end": "66970"
  },
  {
    "text": "So this is a well-defined\noptimization problem.",
    "start": "66970",
    "end": "70760"
  },
  {
    "text": "We have a quantity, which is a\nfunction of certain parameters.",
    "start": "70760",
    "end": "75830"
  },
  {
    "text": "And we wish to find the\nchoices for those parameters,",
    "start": "75830",
    "end": "79050"
  },
  {
    "text": "or those coefficients,\nthat will make",
    "start": "79050",
    "end": "81420"
  },
  {
    "text": "this quantity as\nsmall as possible.",
    "start": "81420",
    "end": "84930"
  },
  {
    "text": "One first comment is\nsimilar to the case",
    "start": "84930",
    "end": "87820"
  },
  {
    "text": "where we had a single\nmeasurement [and]",
    "start": "87820",
    "end": "90920"
  },
  {
    "text": "is the following.",
    "start": "90920",
    "end": "92280"
  },
  {
    "text": "If it turns out that the\nconditional expectation",
    "start": "92280",
    "end": "95560"
  },
  {
    "text": "of Theta given all\nof the data that we",
    "start": "95560",
    "end": "98590"
  },
  {
    "text": "have is linear in X, if it is\nof this form, then what happens?",
    "start": "98590",
    "end": "104439"
  },
  {
    "text": "We know that this is the\nbest possible estimator.",
    "start": "104440",
    "end": "107990"
  },
  {
    "text": "If it is also linear, then\nit is the best estimator",
    "start": "107990",
    "end": "111720"
  },
  {
    "text": "within the class of\nlinear estimators as well",
    "start": "111720",
    "end": "115470"
  },
  {
    "text": "and, therefore, the linear\nleast mean squares estimator",
    "start": "115470",
    "end": "119100"
  },
  {
    "text": "is the same as the general\nleast mean squares estimator.",
    "start": "119100",
    "end": "123799"
  },
  {
    "text": "So if for some problems it\nturns out that this is linear,",
    "start": "123800",
    "end": "128050"
  },
  {
    "text": "then we automatically also have\nthe optimal linear estimator.",
    "start": "128050",
    "end": "133240"
  },
  {
    "text": "And this is going to\nbe the case, once more,",
    "start": "133240",
    "end": "135520"
  },
  {
    "text": "for certain normal problems with\na linear structure of the type",
    "start": "135520",
    "end": "140560"
  },
  {
    "text": "that we have studied earlier.",
    "start": "140560",
    "end": "142520"
  },
  {
    "start": "142520",
    "end": "145740"
  },
  {
    "text": "Now, let us look\ninto what it takes",
    "start": "145740",
    "end": "148870"
  },
  {
    "text": "to carry out this optimization.",
    "start": "148870",
    "end": "152079"
  },
  {
    "text": "If we had a single\nobservation, then we",
    "start": "152079",
    "end": "155099"
  },
  {
    "text": "have seen a closed form formula,\na fairly simple formula,",
    "start": "155100",
    "end": "158710"
  },
  {
    "text": "that tells us what the\ncoefficients should be.",
    "start": "158710",
    "end": "161650"
  },
  {
    "text": "For the more general\ncase, formulas",
    "start": "161650",
    "end": "163920"
  },
  {
    "text": "would not be as\nsimple, but we can",
    "start": "163920",
    "end": "167090"
  },
  {
    "text": "make the following observations.",
    "start": "167090",
    "end": "169700"
  },
  {
    "text": "If you take this\nexpression and expand it,",
    "start": "169700",
    "end": "173510"
  },
  {
    "text": "it's going to have\na bunch of terms.",
    "start": "173510",
    "end": "176250"
  },
  {
    "text": "For example, it's going to have\na term of the form a1 squared",
    "start": "176250",
    "end": "180650"
  },
  {
    "text": "times the expected\nvalue of X1 squared.",
    "start": "180650",
    "end": "184730"
  },
  {
    "text": "It's going to have a term\nsuch as twice a1, a2 times",
    "start": "184730",
    "end": "191590"
  },
  {
    "text": "the expected value of X1, X2.",
    "start": "191590",
    "end": "196150"
  },
  {
    "text": "And then there's going to be\nmany more terms to some of them",
    "start": "196150",
    "end": "200760"
  },
  {
    "text": "will also involve products\nof Theta with this.",
    "start": "200760",
    "end": "206920"
  },
  {
    "text": "So we might see that we have\na term of the form a1 expected",
    "start": "206920",
    "end": "212829"
  },
  {
    "text": "value of X1 Theta.",
    "start": "212829",
    "end": "216290"
  },
  {
    "text": "And then, there's going to\nbe many, many more terms.",
    "start": "216290",
    "end": "220010"
  },
  {
    "text": "What's the important\nthing to notice?",
    "start": "220010",
    "end": "222349"
  },
  {
    "text": "That this expression as a\nfunction of the coefficient",
    "start": "222350",
    "end": "226980"
  },
  {
    "text": "involves terms\neither of this kind",
    "start": "226980",
    "end": "229526"
  },
  {
    "text": "or of this kind,\nor of that kind,",
    "start": "229526",
    "end": "231570"
  },
  {
    "text": "first-order or\nsecond-order terms.",
    "start": "231570",
    "end": "235800"
  },
  {
    "text": "To minimize this\nexpression, we're",
    "start": "235800",
    "end": "237430"
  },
  {
    "text": "going to take the derivative\nof this and set it equal to 0.",
    "start": "237430",
    "end": "242730"
  },
  {
    "text": "When you take the derivative\nof a function that",
    "start": "242730",
    "end": "246209"
  },
  {
    "text": "involves only quadratic\nand linear terms,",
    "start": "246210",
    "end": "249660"
  },
  {
    "text": "you get something that's\nlinear in the coefficients.",
    "start": "249660",
    "end": "254410"
  },
  {
    "text": "The conclusion out of\nall this discussion",
    "start": "254410",
    "end": "256730"
  },
  {
    "text": "is that when you actually go\nand carry out this minimization",
    "start": "256730",
    "end": "261480"
  },
  {
    "text": "by setting derivatives\nto zero, what you",
    "start": "261480",
    "end": "263930"
  },
  {
    "text": "will end up doing is solving\na system of linear equations",
    "start": "263930",
    "end": "269130"
  },
  {
    "text": "in the coefficients that\nyou're trying to determine.",
    "start": "269130",
    "end": "272085"
  },
  {
    "text": "And why is this interesting?",
    "start": "272085",
    "end": "274310"
  },
  {
    "text": "Well, it is because\nif you actually",
    "start": "274310",
    "end": "276650"
  },
  {
    "text": "want to carry out\nthis minimization,",
    "start": "276650",
    "end": "279009"
  },
  {
    "text": "all you need to do is to solve\na linear system, which is easily",
    "start": "279010",
    "end": "283050"
  },
  {
    "text": "done on a computer.",
    "start": "283050",
    "end": "286370"
  },
  {
    "text": "The next observation is\nthat this expression only",
    "start": "286370",
    "end": "291100"
  },
  {
    "text": "involves expectations\nof various terms",
    "start": "291100",
    "end": "295860"
  },
  {
    "text": "that are second order in the\nrandom variables involved.",
    "start": "295860",
    "end": "299750"
  },
  {
    "text": "So it involves the expected\nvalue of X1 squared,",
    "start": "299750",
    "end": "302950"
  },
  {
    "text": "it involves this term,\nwhich has something",
    "start": "302950",
    "end": "305050"
  },
  {
    "text": "to do with the\ncovariance of X1 and X2.",
    "start": "305050",
    "end": "307960"
  },
  {
    "text": "This term that has something\nto do with the covariance of X1",
    "start": "307960",
    "end": "311280"
  },
  {
    "text": "with Theta.",
    "start": "311280",
    "end": "312910"
  },
  {
    "text": "But these are the only terms out\nof the distribution of the X's",
    "start": "312910",
    "end": "317480"
  },
  {
    "text": "and of Theta that will matter.",
    "start": "317480",
    "end": "320310"
  },
  {
    "text": "So similar to the case where\nwe had a single observation,",
    "start": "320310",
    "end": "325419"
  },
  {
    "text": "in order to solve\nthis problem, we",
    "start": "325420",
    "end": "327360"
  },
  {
    "text": "do not need to know the\ncomplete distribution of the X's",
    "start": "327360",
    "end": "331590"
  },
  {
    "text": "and of Theta.",
    "start": "331590",
    "end": "332705"
  },
  {
    "text": "It is enough to know\nall of the means,",
    "start": "332705",
    "end": "335569"
  },
  {
    "text": "variances, and covariances\nof the random variables",
    "start": "335570",
    "end": "339040"
  },
  {
    "text": "that are involved.",
    "start": "339040",
    "end": "340550"
  },
  {
    "text": "And once more, this\nmakes this approach",
    "start": "340550",
    "end": "343389"
  },
  {
    "text": "to estimation a practical\none, because we do not",
    "start": "343390",
    "end": "347060"
  },
  {
    "text": "need to model in complete\ndetail the distribution",
    "start": "347060",
    "end": "350090"
  },
  {
    "text": "of the different\nrandom variables.",
    "start": "350090",
    "end": "353470"
  },
  {
    "text": "Finally, if we do not have just\none unknown random variable,",
    "start": "353470",
    "end": "358130"
  },
  {
    "text": "but we have multiple\nrandom variables that we",
    "start": "358130",
    "end": "360570"
  },
  {
    "text": "want to estimate,\nwhat should we do?",
    "start": "360570",
    "end": "363740"
  },
  {
    "text": "Well, this is pretty simple.",
    "start": "363740",
    "end": "365800"
  },
  {
    "text": "You just apply this\nestimation methodology",
    "start": "365800",
    "end": "368250"
  },
  {
    "text": "to each one of the unknown\nrandom variables separately.",
    "start": "368250",
    "end": "373390"
  },
  {
    "text": "To conclude, this linear\nestimation methodology",
    "start": "373390",
    "end": "378720"
  },
  {
    "text": "applies also to the case where\nyou have multiple observations.",
    "start": "378720",
    "end": "383900"
  },
  {
    "text": "You need to solve a certain\ncomputational problem in order",
    "start": "383900",
    "end": "387120"
  },
  {
    "text": "to find the structure of\nthe best linear estimator,",
    "start": "387120",
    "end": "390389"
  },
  {
    "text": "but it is not a very difficult\ncomputational problem,",
    "start": "390390",
    "end": "393640"
  },
  {
    "text": "because all that it\ninvolves is to minimize",
    "start": "393640",
    "end": "396260"
  },
  {
    "text": "a quadratic function\nof the coefficients",
    "start": "396260",
    "end": "398780"
  },
  {
    "text": "that you are trying\nto determine.",
    "start": "398780",
    "end": "400720"
  },
  {
    "text": "And this leads us\nto having to solve",
    "start": "400720",
    "end": "403130"
  },
  {
    "text": "a system of linear equations.",
    "start": "403130",
    "end": "405230"
  },
  {
    "text": "For all these reasons,\nlinear estimation,",
    "start": "405230",
    "end": "408420"
  },
  {
    "text": "or estimation using linear\nestimators, is quite practical.",
    "start": "408420",
    "end": "413310"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5300"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5300",
    "end": "11600"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11600",
    "end": "18100"
  },
  {
    "text": "at ocw.mit.edu.  WILLIAM GREEN: All right,\nso I know some of you",
    "start": "18100",
    "end": "24660"
  },
  {
    "text": "have succeeded to do the\nhomework and some of you, I think, have not. Is this correct? AUDIENCE: Yeah.",
    "start": "24660",
    "end": "30144"
  },
  {
    "text": "WILLIAM GREEN: OK. So I was wondering\nif someone who has succeeded to\ndo their homework might comment on how small a\nmesh do you need to converge.",
    "start": "30144",
    "end": "39045"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] WILLIAM GREEN: It's about l? L? OK, so you need something on\nthe order of l to converge.",
    "start": "39045",
    "end": "45203"
  },
  {
    "text": "Is that correct? So if you're trying to\ndo the problem using mesh much bigger than\nl, you should probably try a tighter mesh.",
    "start": "45203",
    "end": "52323"
  },
  {
    "text": "Yes? AUDIENCE: [INAUDIBLE] WILLIAM GREEN: All right. Yes? AUDIENCE: [INAUDIBLE]",
    "start": "52323",
    "end": "58260"
  },
  {
    "text": "WILLIAM GREEN: Yes. Yes. All right. And has anyone managed to\nget the [INAUDIBLE] solution",
    "start": "58260",
    "end": "64869"
  },
  {
    "text": "to actually be consistent\nwith the [INAUDIBLE] solution? AUDIENCE: Something\nlike 3% or 4% or so.",
    "start": "64870",
    "end": "71080"
  },
  {
    "text": "WILLIAM GREEN: 3% or 4%, OK. And I assume that the\n[INAUDIBLE] is also using a mesh of similar size?",
    "start": "71080",
    "end": "78790"
  },
  {
    "text": "Hard to tell? AUDIENCE: I used like\na triangular system-- WILLIAM GREEN: Yeah, yeah, but\nI mean, it's really, really",
    "start": "78790",
    "end": "83806"
  },
  {
    "text": "tiny ones at the bottom? If you want me to blow it\nup, I can just take a look and see to be sure.",
    "start": "83806",
    "end": "89800"
  },
  {
    "text": "All right, and is backslash\nable to handle a million",
    "start": "89800",
    "end": "95020"
  },
  {
    "text": "by million matrix? AUDIENCE: Like 10\nseconds with [INAUDIBLE]..",
    "start": "95020",
    "end": "100039"
  },
  {
    "text": "WILLIAM GREEN: [INAUDIBLE] OK. So you need to-- so do\nthe sparse allocation. And MATLAB is so\nsmart that it just",
    "start": "100040",
    "end": "106330"
  },
  {
    "text": "can handle it with a\nmillion by million, which is pretty\namazing, actually. That's a pretty big matrix.",
    "start": "106330",
    "end": "111880"
  },
  {
    "text": "All right, sorry,\nthis is too loud. All right, so last time, we were\ndoing some elementary things",
    "start": "111880",
    "end": "120020"
  },
  {
    "text": "about probability. Actually, any more questions\nabout the homework problem before we get started? AUDIENCE: What's the answer?",
    "start": "120020",
    "end": "125440"
  },
  {
    "text": "WILLIAM GREEN:\nWhat's the answer? You could ask your classmates. Any other questions? ",
    "start": "125440",
    "end": "132841"
  },
  {
    "text": "All right.  So I had you confused a\nlittle bit with this formula",
    "start": "132841",
    "end": "146569"
  },
  {
    "text": "probability of either\nA or B. So I asked what the probability of--",
    "start": "146570",
    "end": "151879"
  },
  {
    "text": "I flipped two coins-- that\none of them would be a head. And I could see a\nlot of consternation.",
    "start": "151880",
    "end": "156890"
  },
  {
    "text": "The general formula\nfor this is it's the probability of A\nplus the probability of B",
    "start": "156890",
    "end": "163780"
  },
  {
    "text": "minus the probability\nof A and B.",
    "start": "163780",
    "end": "171821"
  },
  {
    "text": "It can't just be the two\nof them added together because if you have 50%\nchance for head of the penny",
    "start": "171822",
    "end": "178520"
  },
  {
    "text": "and the dime is 50% chance,\nthis would add up to 100% chance that you'll get a head, but\nyou know sometimes it's true.",
    "start": "178520",
    "end": "184170"
  },
  {
    "text": "So this is the formula. And then the\nprobability of A and B",
    "start": "184170",
    "end": "191810"
  },
  {
    "text": "is often written in terms of\nthe conditional probabilities, the probability of A times the\nprobability that B would happen",
    "start": "191810",
    "end": "199400"
  },
  {
    "text": "given that A already\nhappened, which is also equal to the other way around. ",
    "start": "199400",
    "end": "210020"
  },
  {
    "text": "And this has to\nbe read carefully. It means B already\nhappened, and then you want to know the\nprobability of A",
    "start": "210020",
    "end": "215220"
  },
  {
    "text": "given that B already happened. So it's sort of like this way-- I don't know-- the\nway I think about it.",
    "start": "215220",
    "end": "220620"
  },
  {
    "text": "Like, this happened\nfirst. and now I'm checking the probability\nthat that's going to happen. ",
    "start": "220620",
    "end": "227730"
  },
  {
    "text": "Now, a nice little\nexample of this is given in\n[INAUDIBLE] textbook. And I think it's nice enough\nthat it's worthwhile to spend",
    "start": "227730",
    "end": "233459"
  },
  {
    "text": "a few minutes talking about it. So he was-- [INAUDIBLE] who\nwrote the textbook, was not actually\na numerical guy.",
    "start": "233460",
    "end": "239005"
  },
  {
    "text": "He was a polymer chemist. And so he gave a\nnice polymer example. So if you have a\npolymer and the monomers",
    "start": "239005",
    "end": "247379"
  },
  {
    "text": "have some big molecule,\nand at one side, they have a sort\nof acceptor group,",
    "start": "247380",
    "end": "254816"
  },
  {
    "text": "and the other side, some kind of\ndonor group-- we'll call it D, I guess.",
    "start": "254816",
    "end": "259935"
  },
  {
    "text": "And these are the monomers. And so they can link together. The donor can react\nto the acceptor. So you can end up with\nthings like this and so on.",
    "start": "259935",
    "end": "274182"
  },
  {
    "text": "So this is the monomer. This is the dimer. Then you could keep on\n[INAUDIBLE] like this. And many, many, many\nof the materials",
    "start": "274182",
    "end": "280370"
  },
  {
    "text": "you use every day, the\nfabrics in the seats that you're sitting\non, the backs",
    "start": "280370",
    "end": "285506"
  },
  {
    "text": "of the seats, your\nclothing, the binder",
    "start": "285506",
    "end": "291380"
  },
  {
    "text": "holding the chalk\ntogether, all this stuff is made from polymers like this. So this is a pretty important,\nactually, practical problem.",
    "start": "291380",
    "end": "298220"
  },
  {
    "text": "And so you start\nwith the monomers,",
    "start": "298220",
    "end": "303620"
  },
  {
    "text": "and they react where you have A\nreacting plus D, over and over",
    "start": "303620",
    "end": "308840"
  },
  {
    "text": "again. And we want to understand\nthe statistics of what",
    "start": "308840",
    "end": "317540"
  },
  {
    "text": "chain lengths are going to\nmake, maybe what weight percent or what would the\naverage microweight be,",
    "start": "317540",
    "end": "323510"
  },
  {
    "text": "something like that would be the\nkind of things we care about. ",
    "start": "323510",
    "end": "329030"
  },
  {
    "text": "So a way to think about\nit is if I've reacted this",
    "start": "329030",
    "end": "334180"
  },
  {
    "text": "to some extent and I just\ngrab a random polymer",
    "start": "334180",
    "end": "339880"
  },
  {
    "text": "chain, any molecule in there,\nand I look and find, let's say, the unreacted D end--",
    "start": "339880",
    "end": "349840"
  },
  {
    "text": "so any oligomer is going to\nhave one unreacted D end. You can see no matter\nhow long I make it,",
    "start": "349840",
    "end": "355100"
  },
  {
    "text": "there will still be\none unreacted D end. And I'm neglecting the\npossibility this might circle around and make a loop.",
    "start": "355100",
    "end": "360880"
  },
  {
    "text": "So assuming no loops,\nthen any molecule I grab is going to have\none unreacted D end.",
    "start": "360880",
    "end": "366490"
  },
  {
    "text": "So I grab a molecule. I start at the unreacted\nD end, and I look at the A that's next to it.",
    "start": "366490",
    "end": "372350"
  },
  {
    "text": "And I say, is that\nA reacted or not? So if it's a monomer, I grab\nthe D. I look over here.",
    "start": "372350",
    "end": "377650"
  },
  {
    "text": "The A is unreacted. So the probability\nthat it's a monomer",
    "start": "377650",
    "end": "385760"
  },
  {
    "text": "is going to be equal\nsort of like 1 minus P where P is the\nprobability that As react.",
    "start": "385760",
    "end": "393200"
  },
  {
    "text": "So it didn't react,\nso just like that. This one, the one next\nto it has reacted.",
    "start": "393200",
    "end": "400250"
  },
  {
    "text": "So this is just going to be\nthe probability of a dimer is",
    "start": "400250",
    "end": "407910"
  },
  {
    "text": "the probability that my\nnearest neighbor reacted",
    "start": "407910",
    "end": "420540"
  },
  {
    "text": "and next neighbor\nis unreacted, right?",
    "start": "420540",
    "end": "434286"
  },
  {
    "text": "Is that OK? So I can write this way. I could say, what's\nthe probability",
    "start": "434286",
    "end": "440720"
  },
  {
    "text": "that my nearest reacted times\na conditional probability, next",
    "start": "440720",
    "end": "454510"
  },
  {
    "text": "unreacted if nearest is reacted?",
    "start": "454510",
    "end": "462480"
  },
  {
    "text": " So far, so good?",
    "start": "462480",
    "end": "469759"
  },
  {
    "text": "You guys are OK with this? So I grabbed a chain. I'm trying to see\nif it's a dimer. I'm going to calculate\nthe probability",
    "start": "469760",
    "end": "476100"
  },
  {
    "text": "that this next\nacceptor group has been reacted to a donor group.",
    "start": "476100",
    "end": "482014"
  },
  {
    "text": "If it has reacted,\nthen I'm going to check the next\none after that. So this is the nearest neighbor. This is the next\nnearest neighbor.",
    "start": "482015",
    "end": "487969"
  },
  {
    "text": "And I want this to be unreacted. If that's both true,\nthen I have a dimer. If either one of those\nis false, [INAUDIBLE]..",
    "start": "487970",
    "end": "494890"
  },
  {
    "text": "Is that OK? So now I need to\nhave a probability. So what's the probability that\nthe nearest one is reacted?",
    "start": "494890",
    "end": "502250"
  },
  {
    "text": "There's some probability\nthat things have reacted. So this is going to be my\nP, probability that things",
    "start": "502250",
    "end": "509860"
  },
  {
    "text": "reacted. And I wanted this\nto be unreacted. Now, there's a question. Are these correlated or not?",
    "start": "509860",
    "end": "517178"
  },
  {
    "text": "Now, in reality, everything's\ncorrelated to everything. So probably, they're correlated. But if we're trying to make\na model and think about it,",
    "start": "517179",
    "end": "524850"
  },
  {
    "text": "the fact that this thing\nreacted at this side doesn't really affect\nthis side if this is a big enough [INAUDIBLE]\nSo to a good approximation,",
    "start": "524850",
    "end": "532500"
  },
  {
    "text": "this is independent of whether\nor not it's reacted or not. So this is still going to\nhave the ordinary probability",
    "start": "532500",
    "end": "538530"
  },
  {
    "text": "of being unreacted,\nwhich would be 1 minus P.",
    "start": "538530",
    "end": "545160"
  },
  {
    "text": "So I could write down that the\nprobability of being a monomer",
    "start": "545160",
    "end": "558310"
  },
  {
    "text": "is equal to 1 minus P. The\nprobability of being a dimer",
    "start": "558310",
    "end": "564930"
  },
  {
    "text": "is equal to P times 1 minus P.\nWhat's the probability of being a trimer? ",
    "start": "564930",
    "end": "576540"
  },
  {
    "text": "P squared times 1 minus\nP. And in general,",
    "start": "576540",
    "end": "584630"
  },
  {
    "text": "the probability\nof being an n-mer",
    "start": "584630",
    "end": "590370"
  },
  {
    "text": "is equal to P n minus\n1 times 1 minus P.",
    "start": "590370",
    "end": "597320"
  },
  {
    "text": "So now you guys are\nstatistical polymer chemists. So this derivation was\nderived by a guy named Flory.",
    "start": "597320",
    "end": "604790"
  },
  {
    "text": "He got the Nobel Prize. He's a pretty important guy. If you want to learn\na lot about him, I think both Professor\nCohen and Professor",
    "start": "604790",
    "end": "610619"
  },
  {
    "text": "Rutledge teach classes\nthat are basically, learn what Mr. Flory figured out. Well, maybe that's a little bit\ntoo strong, but pretty much.",
    "start": "610619",
    "end": "618899"
  },
  {
    "text": "There's another guy\nnamed [INAUDIBLE] that did a bit too, so\n[INAUDIBLE] and Flory. Basically everything\nabout polymers",
    "start": "618899",
    "end": "624995"
  },
  {
    "text": "worked out by at these guys. And all they did was\njust probability theory, so it was a piece of cake. ",
    "start": "624995",
    "end": "631820"
  },
  {
    "text": "And so this is the probability\nthat you have an n-mer. So now we can\ncompute things like,",
    "start": "631820",
    "end": "638209"
  },
  {
    "text": "what is the expectation\nvalue of the chain length? How many guys link together?",
    "start": "638210",
    "end": "644930"
  },
  {
    "text": "And that's defined\nto be the sum of n",
    "start": "644930",
    "end": "650870"
  },
  {
    "text": "times the probability of n. ",
    "start": "650870",
    "end": "660310"
  },
  {
    "text": "So that, in this case, is\ngoing to be sum of n times P",
    "start": "660310",
    "end": "669435"
  },
  {
    "text": "to the n minus 1\ntimes 1 minus P.",
    "start": "669435",
    "end": "674970"
  },
  {
    "text": "Now, a lot of these kinds\nof simple series summations, there's formulas for it.",
    "start": "674970",
    "end": "680880"
  },
  {
    "text": "And maybe in high school, you\nguys might have studied series. I don't know if you remember. And so you can look up. And some of these have\nanalytical formulas",
    "start": "680880",
    "end": "686430"
  },
  {
    "text": "that are really simple. But you can just\nleave it this way too, because you get a\nvalue numerically with MATLAB, no trouble. ",
    "start": "686430",
    "end": "698090"
  },
  {
    "text": "You can also figure out what is\nthe concentration of oligomers",
    "start": "698090",
    "end": "704990"
  },
  {
    "text": "with n units in them. And so that's going to be equal\nto the total concentration",
    "start": "704990",
    "end": "720440"
  },
  {
    "text": "of polymers times the\nprobability that it has n.",
    "start": "720440",
    "end": "728010"
  },
  {
    "text": " So this one, we just worked out.",
    "start": "728010",
    "end": "733200"
  },
  {
    "text": "The total concentration,\na way to figure",
    "start": "733200",
    "end": "738540"
  },
  {
    "text": "that out is to\nthink about there's",
    "start": "738540",
    "end": "744680"
  },
  {
    "text": "one monomer or one monomer-- I'll call this a polymer too. This is a polymer with one unit.",
    "start": "744680",
    "end": "750860"
  },
  {
    "text": "There's one polymer molecule per\nunreacted end, unreacted D end.",
    "start": "750860",
    "end": "756320"
  },
  {
    "text": "So it's really, I want to\nknow how many are unreacted. So that's going to be 1 minus\nP times the amount of monomer",
    "start": "756320",
    "end": "767720"
  },
  {
    "text": "I had to start with. It could be A or D.\nIt doesn't matter.",
    "start": "767720",
    "end": "773870"
  },
  {
    "text": "It's like, how many of them-- I started with a certain\namount of free ends.",
    "start": "773870",
    "end": "779190"
  },
  {
    "text": "What fraction of them\nhave reacted based on 1",
    "start": "779190",
    "end": "784355"
  },
  {
    "text": "minus P. Yeah, it's 1 minus P. So as P goes--",
    "start": "784355",
    "end": "789680"
  },
  {
    "text": "well, yeah, it goes backwards. Yeah, as P goes to infinity--",
    "start": "789680",
    "end": "795339"
  },
  {
    "text": "I think that's right.  Yeah, when P is--",
    "start": "795340",
    "end": "800740"
  },
  {
    "text": "well, I'm totally\nconfused here now. 1 minus P sound right?",
    "start": "800740",
    "end": "806350"
  },
  {
    "text": "Maybe I did the\nreasoning backwards. This is definitely\nthe right formula. I'm just confusing\nmyself with my language. This is a, at least\nfor me, endemic problem",
    "start": "806350",
    "end": "814350"
  },
  {
    "text": "with probability is you\ncould say things very glibly. You've got to think of\nexactly what you mean.",
    "start": "814350",
    "end": "819380"
  },
  {
    "text": "So the concentration\nof unreacted ends,",
    "start": "819380",
    "end": "839470"
  },
  {
    "text": "so initially, this was equal to\nA. It was all unreacted ends.",
    "start": "839470",
    "end": "848180"
  },
  {
    "text": "And as the process proceeds, as\nP increases, then at the end,",
    "start": "848180",
    "end": "854010"
  },
  {
    "text": "it's going to be very small. So this is right. ",
    "start": "854010",
    "end": "860565"
  },
  {
    "text": "And the concentration\nof unreacted ends is equal to the\ntotal concentration of polymers, the number\nof polymers [INAUDIBLE]..",
    "start": "860565",
    "end": "866410"
  },
  {
    "text": "So it's this times P n\nminus 1 times [INAUDIBLE].. ",
    "start": "866410",
    "end": "876120"
  },
  {
    "text": "All right, and this is called\nthe Flory redistribution. And that gives the\nconcentrations of all",
    "start": "876120",
    "end": "883680"
  },
  {
    "text": "your oligomers after\nyou do a polymerization if they're all uncorrelated\nand you don't form any loops.",
    "start": "883680",
    "end": "889540"
  },
  {
    "start": "889540",
    "end": "895120"
  },
  {
    "text": "It's often very\nimportant to know the width of the distribution. If you make a polymer, you\nwant to make things have",
    "start": "895120",
    "end": "901100"
  },
  {
    "text": "as monodisperse as possible. It's because you'd really like\nto make this pure chemical. There's some polymer\nchain length which",
    "start": "901100",
    "end": "907430"
  },
  {
    "text": "is optimal for your purpose. You want to try to make\nsure that the average value, average value, this is going to\nbe equal to the value you want.",
    "start": "907430",
    "end": "914660"
  },
  {
    "text": "So you want to keep running P up\nuntil you reach the point where the average chain length\nis the chain length that's",
    "start": "914660",
    "end": "921470"
  },
  {
    "text": "optimal for your application. If you make the\npolymer too long, then it's going to be\nhard to dissolve it.",
    "start": "921470",
    "end": "928779"
  },
  {
    "text": "It's going to be hard to\nhandle and it's can be solid. If you make it\ntoo short, then it may not have the\nmechanical properties you",
    "start": "928780",
    "end": "935140"
  },
  {
    "text": "need for the polymer to have. So there's some optimal choice. So you typically\nrun the conversion",
    "start": "935140",
    "end": "941090"
  },
  {
    "text": "until P reaches a number so\nthat this is your optimal value, but then you care about\nwhat's the dispersion",
    "start": "941090",
    "end": "946310"
  },
  {
    "text": "about that optimal value. And particularly, the unreacted\nmonomers that are left might be a problem because\nthey might leach out",
    "start": "946310",
    "end": "953300"
  },
  {
    "text": "over time because they\nmight still be liquids, or even gases that come out. So this famous problem,\npeople made baby bottles",
    "start": "953300",
    "end": "959930"
  },
  {
    "text": "and they have some\nleftover small molecules in the baby bottles. And then they can leach\nout into the milk,",
    "start": "959930",
    "end": "966240"
  },
  {
    "text": "and the mothers don't\nappreciate that. So there's a lot of\nreal practical problems about how to do this.",
    "start": "966240",
    "end": "971949"
  },
  {
    "text": "So anyway, you'd be\ninterested in the width of the distribution. So we define what's\ncalled the variance.",
    "start": "971949",
    "end": "978774"
  },
  {
    "start": "978775",
    "end": "983810"
  },
  {
    "text": "And the variance of n\nis written this way.",
    "start": "983810",
    "end": "990436"
  },
  {
    "text": "And it's just defined\nto be the expectation value of n squared minus the\nexpectation value of n squared.",
    "start": "990436",
    "end": "998180"
  },
  {
    "text": "These two are always different\nor almost always different, so it's not 0. ",
    "start": "998180",
    "end": "1005490"
  },
  {
    "text": "So this is equal\nto the summation of n squared times the\nprobability of n minus--",
    "start": "1005490",
    "end": "1015320"
  },
  {
    "start": "1015320",
    "end": "1021690"
  },
  {
    "text": "all right? And a lot of times\nin the polymer field, what they'll take is they'll\ntake the square root of this",
    "start": "1021690",
    "end": "1027670"
  },
  {
    "text": "and they'll compare\nsigma n divided by expectation value of n. This is a dimensionless\nnumber because sigma n",
    "start": "1027670",
    "end": "1033579"
  },
  {
    "text": "will have the dimensions. Sigma squared is\ndimensions n squared. This is dimensions of n, so\nit's a dimensionless number.",
    "start": "1033579",
    "end": "1040420"
  },
  {
    "text": "And that's-- I think they\ncall it dispersity of polymer, something like that. ",
    "start": "1040420",
    "end": "1049179"
  },
  {
    "text": "Now, notice that when we\nuse these [INAUDIBLE],, when we wrote it this\nway, it's implicitly",
    "start": "1049180",
    "end": "1055770"
  },
  {
    "text": "that these things are\ndivided by the summation of the probability of n.",
    "start": "1055770",
    "end": "1061230"
  },
  {
    "text": "But because these\nprobabilities sum to 1, I can just leave it out. ",
    "start": "1061230",
    "end": "1067320"
  },
  {
    "text": "But sometimes, it\nmay be difficult for you to figure out exactly\nwhat the probabilities are and you'll need a scaling\nfactor to force this thing",
    "start": "1067320",
    "end": "1073730"
  },
  {
    "text": "to be equal to 1. So sometimes, people leave\nthese in the denominator. There's another thing\nyou might care about,",
    "start": "1073730",
    "end": "1078811"
  },
  {
    "text": "which would be like, what's\nthe weight percent of Pn?",
    "start": "1078811",
    "end": "1085400"
  },
  {
    "text": "So what fraction of the\nweight of the polymer is my particular oligomer, Pn?",
    "start": "1085400",
    "end": "1090470"
  },
  {
    "text": "[INAUDIBLE] sorry,\nsome special one, Pm. And I want to know\nits weight percent. So that's going to be\nequal to the weight of Pm",
    "start": "1090470",
    "end": "1108650"
  },
  {
    "text": "in the mix divided\nby the total weight. ",
    "start": "1108650",
    "end": "1119070"
  },
  {
    "text": "So that's equal to\nthe weight of m times",
    "start": "1119070",
    "end": "1124789"
  },
  {
    "text": "the probability of m divided\nby the total weight, which is going to be the\nweight of all these guys,",
    "start": "1124790",
    "end": "1131812"
  },
  {
    "text": "times the probability\nof each of them. And you can see\nthis is different. This is not the same as--",
    "start": "1131812",
    "end": "1139139"
  },
  {
    "text": "not equal to, right?",
    "start": "1139140",
    "end": "1149880"
  },
  {
    "text": "It's not the same thing. So just watch out\nwhen you do this.",
    "start": "1149880",
    "end": "1155812"
  },
  {
    "text": "And in fact, in the polymer\nworld, they always have to say, I did weight average. I did number average,\nbecause they're different.",
    "start": "1155812",
    "end": "1163210"
  },
  {
    "text": "Is this OK? Yeah? So I would-- my general\nconfidence, at least for me,",
    "start": "1163210",
    "end": "1170029"
  },
  {
    "text": "if I skip steps, I always get\nit wrong when I do probability. So don't skip steps. Do it one by one by one,\nwhat you really mean.",
    "start": "1170029",
    "end": "1176890"
  },
  {
    "text": "Then you'll be OK.  All right, now, this is\na cute little example.",
    "start": "1176890",
    "end": "1185270"
  },
  {
    "text": "It's discrete variables. It's easy to count everything. Very often, we care about\nprobability distributions",
    "start": "1185270",
    "end": "1191120"
  },
  {
    "text": "of continuous variables. And we have to do those\nprobability density functions that I talked about last time\nwhich have units in them.",
    "start": "1191120",
    "end": "1198429"
  },
  {
    "text": "And so as we\nmentioned last time, if you want to know\nthe probability",
    "start": "1198430",
    "end": "1204770"
  },
  {
    "text": "that a continuous variable, that\nx is a member of this interval,",
    "start": "1204770",
    "end": "1218740"
  },
  {
    "text": "the probability this is true is\nequal to Px of x hat times dx.",
    "start": "1218740",
    "end": "1230340"
  },
  {
    "text": " And so this quantity\nhas units of 1 over x, whatever\nthe units of x are.",
    "start": "1230340",
    "end": "1239283"
  },
  {
    "text": "And then you have to\nmultiply it by x in order to get the units to be\ndimensionless, which is what the probability is. ",
    "start": "1239284",
    "end": "1247850"
  },
  {
    "text": "And this is like obvious things,\nlike P Px of x prime dx prime.",
    "start": "1247850",
    "end": "1254049"
  },
  {
    "text": "[INAUDIBLE] value as possible\nof x has got to be equal to 1. It's a probability,\nwhich is the same",
    "start": "1254050",
    "end": "1259810"
  },
  {
    "text": "as saying that probability of\nx is some value anywhere is 1. So there's some\n[INAUDIBLE] you measure.",
    "start": "1259810",
    "end": "1265651"
  },
  {
    "text": " And you can also have a\nprobability that x is less than",
    "start": "1265651",
    "end": "1273490"
  },
  {
    "text": "or equal to x prime. And that's the integral\nfrom negative infinity",
    "start": "1273490",
    "end": "1279044"
  },
  {
    "text": "to x prime of Px of x dx. ",
    "start": "1279045",
    "end": "1289760"
  },
  {
    "text": "And the mean is just\nthe integral of x Px.",
    "start": "1289760",
    "end": "1295716"
  },
  {
    "start": "1295716",
    "end": "1302659"
  },
  {
    "text": "And you can compute\nthe x squared. The average of x and\nx squared, same thing. You average of anything.",
    "start": "1302660",
    "end": "1308440"
  },
  {
    "start": "1308440",
    "end": "1315289"
  },
  {
    "text": "You can put these together. You can get sigma x squared\nis equal to x squared",
    "start": "1315290",
    "end": "1322280"
  },
  {
    "text": "minus the average squared. So that's the variance of x.",
    "start": "1322280",
    "end": "1329690"
  },
  {
    "text": "You can also do this\nwith any function. So you can say that the\naverage value of a function",
    "start": "1329690",
    "end": "1338510"
  },
  {
    "text": "is equal to the integral\nof f of x Px of x dx.",
    "start": "1338510",
    "end": "1344112"
  },
  {
    "text": " This is an average\nvalue of a function",
    "start": "1344112",
    "end": "1349370"
  },
  {
    "text": "of a random variable described\nby probability density function with P of x. And then you can get\nthings like sigma",
    "start": "1349370",
    "end": "1357046"
  },
  {
    "text": "f squared is equal to the\nintegral of f of x, quantity",
    "start": "1357046",
    "end": "1363890"
  },
  {
    "text": "squared, Px of x minus--",
    "start": "1363890",
    "end": "1369555"
  },
  {
    "start": "1369555",
    "end": "1375870"
  },
  {
    "text": "all right? Everything's OK? Yeah.",
    "start": "1375870",
    "end": "1382101"
  },
  {
    "text": "All right, so a lot of times,\npeople are going to say, we do sampling from Px. So sampling from Px means\nthat we have some probability",
    "start": "1382101",
    "end": "1389720"
  },
  {
    "text": "distribution function,\nPx of x, and we want to have one value of x that\nwe draw from that probability",
    "start": "1389720",
    "end": "1397399"
  },
  {
    "text": "distribution. When we say it that\nway, we mean that we're more likely to find x's\nwhere Px has a high value",
    "start": "1397400",
    "end": "1405370"
  },
  {
    "text": "and we're less likely to\ndraw an x value that Px has a low value.",
    "start": "1405370",
    "end": "1410459"
  },
  {
    "text": "So that's what's sampling from. Now, you can do\nthat mathematically using random number generators\nin MATLAB, for example,",
    "start": "1410459",
    "end": "1416800"
  },
  {
    "text": "and we'll do that sometimes. But you do it all the time\nwhen you do experiments. So the experiment has some\nprobability density function",
    "start": "1416800",
    "end": "1423911"
  },
  {
    "text": "that you're going\nobserve something, you're going to\nmeasure something. And you don't know what\nthat distribution is,",
    "start": "1423911",
    "end": "1429669"
  },
  {
    "text": "but every time you\nmake a measurement, you're sampling from\nthat distribution. So that's the key\nconceptual idea",
    "start": "1429670",
    "end": "1435700"
  },
  {
    "text": "is that there is a Px of x\nout there for our measurement. So you're trying to\nmeasure how tall I am.",
    "start": "1435700",
    "end": "1442165"
  },
  {
    "text": "Every time you\nmeasure it, you're drawing from a distribution\nof experimental measurements",
    "start": "1442165",
    "end": "1448070"
  },
  {
    "text": "of Professor Green's height. And there is some Px of x\nthat exists even though you",
    "start": "1448070",
    "end": "1454340"
  },
  {
    "text": "don't know what it is. And each time you\nmake the measurement, you're drawing numbers\nfrom that distribution.",
    "start": "1454340",
    "end": "1459920"
  },
  {
    "text": "And if you draw a lot of them,\nthen you can do an average.",
    "start": "1459920",
    "end": "1464990"
  },
  {
    "text": "And it should be an average\nthat's close to this. If you drew an infinite\nnumber of values,",
    "start": "1464990",
    "end": "1470360"
  },
  {
    "text": "then you're sampling this. You can make a histogram plot of\nthe heights you measure of me,",
    "start": "1470360",
    "end": "1475820"
  },
  {
    "text": "and it should have some shape\nthat's similar to Px of x. Does that makes sense?",
    "start": "1475820",
    "end": "1480980"
  },
  {
    "text": "All right. So actually, everyday\nyou're drawing from probability distributions. You just didn't know it. It's like [INAUDIBLE] street.",
    "start": "1480980",
    "end": "1486530"
  },
  {
    "text": "The probability the bus\nis going to hit me or not and the bus driver\nis going to stop, I think there's a\nhigh probability, but I'm always a little\nworried, actually.",
    "start": "1486530",
    "end": "1492479"
  },
  {
    "text": "Good. I'm drawing from-- it's\na particular instance of that probability distribution\nabout whether the bus driver's",
    "start": "1492479",
    "end": "1499360"
  },
  {
    "text": "really going to stop or not. And if I sample enough\ntimes, I might be dead.",
    "start": "1499360",
    "end": "1504640"
  },
  {
    "text": "But anyway, all right. ",
    "start": "1504640",
    "end": "1515270"
  },
  {
    "text": "Often we have\nmultiple variables. So you can write down-- ",
    "start": "1515270",
    "end": "1533740"
  },
  {
    "text": "you can define Px hat. ",
    "start": "1533740",
    "end": "1550300"
  },
  {
    "text": "So now I have multiple x's. It's like more than\none variable of x. And I wanted the probability\ndensity function of them.",
    "start": "1550300",
    "end": "1556139"
  },
  {
    "text": "I'm going to measure this\nand this and this and this, all right? And this is equal\nto the probability",
    "start": "1556139",
    "end": "1564700"
  },
  {
    "text": "that x1 is a member of\nthe set, x1, x1 plus dx1,",
    "start": "1564700",
    "end": "1576760"
  },
  {
    "text": "and x2 is a member of x2,\nx2 plus dx2, and that.",
    "start": "1576760",
    "end": "1587136"
  },
  {
    "text": " That's what probability\ndensity function means with multiple variables.",
    "start": "1587136",
    "end": "1593230"
  },
  {
    "text": " So this is very common\nfor us because we often",
    "start": "1593230",
    "end": "1599800"
  },
  {
    "text": "measure and experiment\nmore than one thing, right? So you measure the flow\nrate and the temperature.",
    "start": "1599800",
    "end": "1605860"
  },
  {
    "text": "You measure the yield\nand the absorption at some wavelength that\ncorresponds to an impurity.",
    "start": "1605860",
    "end": "1612835"
  },
  {
    "text": "Usually when you experiment, you\noften measure multiple things. And so you're sampling\nfrom multiple observable",
    "start": "1612835",
    "end": "1618580"
  },
  {
    "text": "simultaneously. And implicitly, you're sampling\nfrom some complicated PDF like this even though you\ndon't know the shape of the PDF",
    "start": "1618580",
    "end": "1625210"
  },
  {
    "text": "usually to start with.  And so then when you have\nthis multiple variable case,",
    "start": "1625210",
    "end": "1634220"
  },
  {
    "text": "you can define a thing\ncalled the covariance matrix",
    "start": "1634220",
    "end": "1641900"
  },
  {
    "text": "where the elements\nof the matrix Cij are equal to xi xj, the mean\nof that product, minus xi xj.",
    "start": "1641900",
    "end": "1657060"
  },
  {
    "text": "And so you can see that,\nfor example, sigma i squared is equal to Cii, but\nthe diagonal elements",
    "start": "1657060",
    "end": "1663029"
  },
  {
    "text": "are just the variances. But now we have the covariances\nbecause we measured, let's say, two things.",
    "start": "1663030",
    "end": "1668146"
  },
  {
    "start": "1668146",
    "end": "1673750"
  },
  {
    "text": "All right, so suppose\nwe do n measurements",
    "start": "1673750",
    "end": "1679220"
  },
  {
    "text": "and we compute the\naverage of our repeats. So we'd just repeat the same\nmeasurements over and over.",
    "start": "1679220",
    "end": "1686140"
  },
  {
    "text": "So suppose you measure\nmy height and my weight. Every time I go to\nthe medical clinic, they always measure my height,\nmy weight, my blood pressure.",
    "start": "1686140",
    "end": "1693370"
  },
  {
    "text": "You've got three numbers. And I could go back\nin there 47 times, and they'll do it 47 times.",
    "start": "1693370",
    "end": "1699010"
  },
  {
    "text": "And if a different\ntechnician measured it using different [INAUDIBLE]\nand a different scale,",
    "start": "1699010",
    "end": "1704199"
  },
  {
    "text": "I might get a different number. Sometimes, I forget\nto take my shoes off so I'm a little bit taller\nthan I would have been.",
    "start": "1704199",
    "end": "1709281"
  },
  {
    "text": "So the numbers go up and down. They fluctuate, right? You'd expect that, right? If you looked at\nmy medical chart, it's not the same\nnumber every time.",
    "start": "1709281",
    "end": "1715450"
  },
  {
    "text": " But you'd think, if\neverything's right in the world,",
    "start": "1715450",
    "end": "1723970"
  },
  {
    "text": "that I'm an old guy. I've been going to the medical\nclinic for a long time. If I look at my chart and\naverage all those numbers,",
    "start": "1723970",
    "end": "1730169"
  },
  {
    "text": "it should be somewhere\nclose to the true value of those numbers. So I should have that the\naverage values experimentally,",
    "start": "1730170",
    "end": "1740200"
  },
  {
    "text": "which I just define\nto be the averages-- ",
    "start": "1740200",
    "end": "1755110"
  },
  {
    "text": "this is the number\nof experiments. OK, so I can have\nthese averages.",
    "start": "1755110",
    "end": "1760990"
  },
  {
    "text": "And I would expect that\nas n goes to infinity,",
    "start": "1760990",
    "end": "1767600"
  },
  {
    "text": "I hope that my\nexperimental values go to the same value\nof x that I would",
    "start": "1767600",
    "end": "1774520"
  },
  {
    "text": "have gotten from the true\nprobability distribution function. If I knew what Px of x is\nand I evaluated the integral",
    "start": "1774520",
    "end": "1786610"
  },
  {
    "text": "and I got x, I think it should\nbe the same as the experiment as long as I did enough repeats.",
    "start": "1786610",
    "end": "1792580"
  },
  {
    "text": "So this is almost like an\narticle of faith here, yeah? It's what you'd expect. ",
    "start": "1792580",
    "end": "1802549"
  },
  {
    "text": "Now, the interesting\nthing about this-- I mean, probably\nyou've done this a lot. You probably did experiments\nand you've averaged some things",
    "start": "1802550",
    "end": "1809070"
  },
  {
    "text": "before, right? If everybody in the class tried\nto measure how tall I was, you guys all wouldn't\nget the same number.",
    "start": "1809070",
    "end": "1814490"
  },
  {
    "text": "But you'd think that\nif you took the average of the whole classroom,\nit might be pretty close to my true height, right? So the key idea here\nis that the sigma",
    "start": "1814490",
    "end": "1828280"
  },
  {
    "text": "squared of the x measurement\nexperimental, which",
    "start": "1828280",
    "end": "1838840"
  },
  {
    "text": "we define to be this-- ",
    "start": "1838840",
    "end": "1855967"
  },
  {
    "text": "maybe we should do\nthis one at a time.  [INAUDIBLE]",
    "start": "1855967",
    "end": "1861224"
  },
  {
    "start": "1861224",
    "end": "1871470"
  },
  {
    "text": "Then I can have a vector\nof these guys for all the different measurements. So there's some\nerror in my height.",
    "start": "1871470",
    "end": "1876540"
  },
  {
    "text": "There's some error in my weight. There's some different error in\nmy blood pressure measurement, but each should have\ntheir own variances.",
    "start": "1876540",
    "end": "1883450"
  },
  {
    "text": "I can have the covariances. ",
    "start": "1883450",
    "end": "1910280"
  },
  {
    "text": "OK, so these are all the\nexperimental quantities. You guys maybe even computed\nall these before in your life. ",
    "start": "1910280",
    "end": "1917760"
  },
  {
    "text": "And we expect that this\nshould go like this as n goes to infinity. Now what's going to\nhappen to these guys as n goes to infinity?",
    "start": "1917760",
    "end": "1923374"
  },
  {
    "text": "That's the really\nimportant question. ",
    "start": "1923374",
    "end": "1929080"
  },
  {
    "text": "So there's an amazing theory\ncalled the central limit theorem of statistics.",
    "start": "1929080",
    "end": "1935565"
  },
  {
    "start": "1935565",
    "end": "1946460"
  },
  {
    "text": "And what this theorem\nsays, that as n gets large",
    "start": "1946460",
    "end": "1960240"
  },
  {
    "text": "and if trials are uncorrelated\nand the x's aren't correlated,",
    "start": "1960240",
    "end": "1978470"
  },
  {
    "text": "which is the same as saying\nthat Cij is equal to 0 off the diagonal, then the\nprobability of making",
    "start": "1978470",
    "end": "1996419"
  },
  {
    "text": "the measurement x is\nproportional to the Gaussian,",
    "start": "1996420",
    "end": "2013696"
  },
  {
    "text": "the bell curve. ",
    "start": "2013696",
    "end": "2042639"
  },
  {
    "text": "All right? So this is only true\nas n gets very large.",
    "start": "2042640",
    "end": "2048790"
  },
  {
    "text": "It doesn't specify exactly\nhow large has to be, but it's true for any\nPx, any distribution",
    "start": "2048790",
    "end": "2054589"
  },
  {
    "text": "function, probability\ndistribution function. So everything\nbecomes a bell curve",
    "start": "2054590",
    "end": "2059839"
  },
  {
    "text": "if you look at the averages. And sigma i squared\nin that limit",
    "start": "2059840",
    "end": "2067760"
  },
  {
    "text": "goes to 1 over n sigma\nxi squared experimental.",
    "start": "2067760",
    "end": "2075597"
  },
  {
    "start": "2075598",
    "end": "2081899"
  },
  {
    "text": "And this is really important. So what this says is that\nthe width of this Gaussian",
    "start": "2081900",
    "end": "2087750"
  },
  {
    "text": "distribution gets narrower\nand narrower as you increase the number of\nrepeated experiments",
    "start": "2087750",
    "end": "2095129"
  },
  {
    "text": "or increase the\nnumber of samples. So this is really saying that\nthe uncertainty in the mean",
    "start": "2095130",
    "end": "2103460"
  },
  {
    "text": "is scaling as 1\nover root n where",
    "start": "2103460",
    "end": "2109321"
  },
  {
    "text": "n is the number of\nsamples or number of experiments that's repeated. ",
    "start": "2109321",
    "end": "2115420"
  },
  {
    "text": "Now, sigma, the variance,\nis not like that at all. So this quantity, actually\nas you increase n,",
    "start": "2115420",
    "end": "2126290"
  },
  {
    "text": "just goes to a constant. It goes to whatever\nthe real variance is, which if you're measuring\nme, it might how good",
    "start": "2126290",
    "end": "2131940"
  },
  {
    "text": "your ruler or something. It'll tell you roughly\nwhat the real variance is. And that number does not go\nto 0 as the number of repeats",
    "start": "2131940",
    "end": "2139839"
  },
  {
    "text": "happens. I mean, I could get\nthe whole student body to measure how tall I am\nat MIT, and they're still",
    "start": "2139840",
    "end": "2145112"
  },
  {
    "text": "not going to have 0 variance. It's going to still be\nsome variance, right? So this quantity stays\nconstant as n increases",
    "start": "2145112",
    "end": "2153750"
  },
  {
    "text": "or goes to a constant value\nonce it sort of stabilizes. You have to have enough samples. But this quantity, the\nuncertainty in the mean value,",
    "start": "2153750",
    "end": "2162486"
  },
  {
    "text": "gets smaller and smaller and\nsmaller as the square of n. ",
    "start": "2162487",
    "end": "2169850"
  },
  {
    "text": "Now, this is only true in\nthe limit as n is large. Now, this is a huge problem\nbecause experimentalists",
    "start": "2169850",
    "end": "2177330"
  },
  {
    "text": "are lazy, and you don't want\nto do that many measurements. And it's hard to\ndo a measurement. So for example, the Higgs boson\nwas discovered, what, a year",
    "start": "2177330",
    "end": "2185100"
  },
  {
    "text": "and a half ago, two years ago? And I think altogether, they\nhad like nine observations",
    "start": "2185100",
    "end": "2191070"
  },
  {
    "text": "or something when\nthey reported it, OK? So nine is not infinity.",
    "start": "2191070",
    "end": "2196230"
  },
  {
    "text": "And so they don't have\ninfinitely small error bars on that measurement. And in fact, who knows if it\nreally looks like a Gaussian",
    "start": "2196230",
    "end": "2202530"
  },
  {
    "text": "distribution from\nsuch a small sample, but they still\nreported 90% confidence",
    "start": "2202530",
    "end": "2209640"
  },
  {
    "text": "interval using the Gaussian\ndistribution formula to figure out\nconfidence intervals. So everybody does this.",
    "start": "2209640",
    "end": "2216760"
  },
  {
    "text": "If n is big, it should be right. And you could prove\nmathematically it's right, but the formula doesn't really\ntell you how big is big.",
    "start": "2216760",
    "end": "2224540"
  },
  {
    "text": "So this is like a\ngeneral problem. And it leads to us\noftentimes misestimating",
    "start": "2224540",
    "end": "2233000"
  },
  {
    "text": "how accurate our results\nare because we're going to use formulas that are\nbased on-- assuming that we've",
    "start": "2233000",
    "end": "2238820"
  },
  {
    "text": "averaged enough repeats that\nwe're in this limit where we can use the Gaussian formulas\nand get this nice limit",
    "start": "2238820",
    "end": "2245270"
  },
  {
    "text": "formula. But in fact, we haven't\nreally reach that because we haven't done enough repeats.",
    "start": "2245270",
    "end": "2250480"
  },
  {
    "text": "So anyway, this is\njust the way life is. That's the way life is. And I think there's even\ndiscussions in statistics",
    "start": "2250480",
    "end": "2257420"
  },
  {
    "text": "journals and stuff about how\nto make corrections and use slightly better forms that get\nthe fact that your distribution",
    "start": "2257420",
    "end": "2266869"
  },
  {
    "text": "of the mean doesn't narrow\ndown to a beautiful Gaussian so fast. It has some stuff in the tails.",
    "start": "2266870",
    "end": "2272567"
  },
  {
    "text": "People talk about that,\nlike low probability events out in the tails of\ndistributions, stuff like that. So that's a big\nfield of statistics.",
    "start": "2272567",
    "end": "2279660"
  },
  {
    "text": "I don't know too much\nabout it, but it's like-- I mean, it's very\npractical because-- now unfortunately, oftentimes\nin chemical engineering,",
    "start": "2279660",
    "end": "2287120"
  },
  {
    "text": "we make so few repeats\nthat we have no chance to figure out what the tails\nare doing, maybe [INAUDIBLE]",
    "start": "2287120",
    "end": "2293480"
  },
  {
    "text": "our tails. And so this is a big problem\nfor trying to make sure",
    "start": "2293480",
    "end": "2298610"
  },
  {
    "text": "you really have things right. So I would say in general,\nthis is an optimistic estimate",
    "start": "2298610",
    "end": "2305690"
  },
  {
    "text": "of what the uncertainty\nin the mean is. Uncertainties are\nusually bigger.",
    "start": "2305690",
    "end": "2311900"
  },
  {
    "text": "So you shouldn't be surprised\nif your data doesn't match a model brilliantly well\nas predicted by this formula.",
    "start": "2311900",
    "end": "2321156"
  },
  {
    "text": "Now, if it's off by some\norders of magnitude, you might be a little alarmed. And that might be the\nnormal situation, too.",
    "start": "2321156",
    "end": "2326550"
  },
  {
    "text": "But anyway, if it's just\noff by a little bit, I wouldn't sweat it\nbecause you probably",
    "start": "2326550",
    "end": "2333050"
  },
  {
    "text": "haven't done enough repeats\nto be entitled to such a beautiful result as this. ",
    "start": "2333050",
    "end": "2342750"
  },
  {
    "text": "We can write a similar-- actually, so here I assumed\nthat the x's are uncorrelated.",
    "start": "2342750",
    "end": "2350849"
  },
  {
    "text": "That's almost never true. If you actually numerically\nevaluate the C's, usually they have off-diagonal elements.",
    "start": "2350850",
    "end": "2357012"
  },
  {
    "text": "For example, my weight\nand my blood pressure are probably correlated. And so you wouldn't expect them\nto be totally uncorrelated.",
    "start": "2357012",
    "end": "2365819"
  },
  {
    "text": "And so there's another\nformula like this.",
    "start": "2365820",
    "end": "2372330"
  },
  {
    "text": "It's given in the\nnotes by Joe Scott that includes the covariance. And you just get a different\nform of what you'd expect, OK?",
    "start": "2372330",
    "end": "2382770"
  },
  {
    "text": "And the covariance should also\nconverge roughly as 1 over n",
    "start": "2382770",
    "end": "2388440"
  },
  {
    "text": "if you have enough samples. So you should eventually\nget some covariance. ",
    "start": "2388440",
    "end": "2395550"
  },
  {
    "text": "You can write very\nsimilar formulas like this for functions.",
    "start": "2395550",
    "end": "2402790"
  },
  {
    "text": "So if I have a function\nf of x and that's",
    "start": "2402790",
    "end": "2411300"
  },
  {
    "text": "really what I care about-- remember, I said that I\nhave the average value of f",
    "start": "2411300",
    "end": "2419369"
  },
  {
    "text": "is equal to f of x Px of x dx.",
    "start": "2419370",
    "end": "2428094"
  },
  {
    "text": "And I could make this\nvectors if I want.  And I could repeat my function,\nand I'd get some number.",
    "start": "2428094",
    "end": "2435690"
  },
  {
    "text": "And I could repeat the variance. I have a sigma f. ",
    "start": "2435690",
    "end": "2444877"
  },
  {
    "text": "And this is something I\nlike to do a lot of times.  Then if we do\nexperimental delta f--",
    "start": "2444877",
    "end": "2459060"
  },
  {
    "text": "so we don't know what the\nprobability distribution function is usually, or often.",
    "start": "2459060",
    "end": "2464690"
  },
  {
    "text": "So we'll try to evaluate\nthis experimentally. ",
    "start": "2464690",
    "end": "2471030"
  },
  {
    "text": "This is going to be\n1 over n, the values",
    "start": "2471030",
    "end": "2478282"
  },
  {
    "text": "f of x little n, the n-th trial. ",
    "start": "2478282",
    "end": "2486610"
  },
  {
    "text": "And we could write a\nsimilar thing for sigma f, which I just did right there. You can do the same thing.",
    "start": "2486610",
    "end": "2491750"
  },
  {
    "text": "Just make these\nexperimental values now. ",
    "start": "2491750",
    "end": "2500580"
  },
  {
    "text": "The sigma f squared\nexperimental should go to 1",
    "start": "2500580",
    "end": "2508950"
  },
  {
    "text": "over n times the variance. ",
    "start": "2508950",
    "end": "2515859"
  },
  {
    "text": "And this was the sigma in\nthe mean of f, 1 over n times the variance of the sigma.",
    "start": "2515860",
    "end": "2522950"
  },
  {
    "text": " All right, so this is\nthe same beautiful thing, that the uncertainty\nin the mean value of f",
    "start": "2522950",
    "end": "2532549"
  },
  {
    "text": "narrows with the\nnumber of trials. So you have some\noriginal variance",
    "start": "2532550",
    "end": "2539670"
  },
  {
    "text": "that you computed here, either\nexperimentally or from the PDF. Experimentally is fine.",
    "start": "2539670",
    "end": "2545869"
  },
  {
    "text": "And then now you want\nto know the uncertainty in the mean value,\nand that drops down with the number of trials in the\nnumber of things you average.",
    "start": "2545870",
    "end": "2554000"
  },
  {
    "text": "So this all leads\nin two directions. What we're going\nto talk about first is about comparing\nmodels versus experiments",
    "start": "2554000",
    "end": "2561950"
  },
  {
    "text": "where we're sampling by\ndoing the experiment. So that's one really\nimportant direction, maybe the most important one.",
    "start": "2561950",
    "end": "2567920"
  },
  {
    "text": "But it also suggests ways you\ncould do numerical integration. So if I wanted to\nevaluate an integral",
    "start": "2567920",
    "end": "2574369"
  },
  {
    "text": "that looks like this,\nf of x P of x dx, and if I had some way\nto sample from Px,",
    "start": "2574370",
    "end": "2582859"
  },
  {
    "text": "then one way to evaluate\nthis numerical integral would be to--",
    "start": "2582860",
    "end": "2589139"
  },
  {
    "text": "sorry, I made this\nvector [INAUDIBLE] a lot of species there, a\nlot of directions.",
    "start": "2589139",
    "end": "2595420"
  },
  {
    "text": "If I want to evaluate\nthis multiple integral-- it's a lot of integrals\nfor every dimension of x--",
    "start": "2595420",
    "end": "2602389"
  },
  {
    "text": "that would be very\nhard to do, right? We talked about in\n[INAUDIBLE],, if you get more than about three or\nfour of these integral signs,",
    "start": "2602389",
    "end": "2608930"
  },
  {
    "text": "usually you're in big trouble\nto evaluate the integral. But you can do it by what's\ncalled Monte Carlo sampling",
    "start": "2608930",
    "end": "2614210"
  },
  {
    "text": "where you sample from P of x\nand just evaluate the value of f at some particular x\npoints you pull as a sample",
    "start": "2614210",
    "end": "2620960"
  },
  {
    "text": "and just repeat their average. And the average of\nthose things should converge, according\nto this formula,",
    "start": "2620960",
    "end": "2626660"
  },
  {
    "text": "as you increase the\nnumber of samples. And so that's the whole\nprinciple of Monte Carlo methods, and we'll come back\nto that a little bit later.",
    "start": "2626660",
    "end": "2633420"
  },
  {
    "text": "And you can apply that\nto a lot of problems. Basically, any problem you have\nin numerics, you have a choice.",
    "start": "2633420",
    "end": "2640799"
  },
  {
    "text": "You can use deterministic\nmethods or stochastic methods. Deterministic methods,\nif you can do them, usually are the fastest\nand more accurate,",
    "start": "2640800",
    "end": "2648530"
  },
  {
    "text": "but stochastic ones are\noften very easy to program and sometimes are actually\nthe fastest way to do it.",
    "start": "2648530",
    "end": "2654250"
  },
  {
    "text": "In particular, in\nthis kind of case, we have lots of\ndimensions, many, many x's. It turns out that stochastic\nones are pretty good way",
    "start": "2654250",
    "end": "2659780"
  },
  {
    "text": "to do it. But we're going to talk\nmostly about [INAUDIBLE] data",
    "start": "2659780",
    "end": "2665157"
  },
  {
    "text": "because that's going to\nbe important to all of you in your research. So let's talk about\nthat for a minute.",
    "start": "2665157",
    "end": "2670380"
  },
  {
    "start": "2670380",
    "end": "2675740"
  },
  {
    "text": "I'll just comment, there's\nreally good notes posted on the [INAUDIBLE] website\nfor all this material, so you should\ndefinitely read it.",
    "start": "2675740",
    "end": "2681819"
  },
  {
    "text": "And the textbook has\na lot of material. It's maybe not so easy to read\nas the notes are, but plenty",
    "start": "2681820",
    "end": "2686950"
  },
  {
    "text": "to learn, for sure. So we generally have a situation\nwhere we have an experiment.",
    "start": "2686950",
    "end": "2692867"
  },
  {
    "text": "And what do we have\nin the experiment? We have some knobs. ",
    "start": "2692867",
    "end": "2699130"
  },
  {
    "text": "These are things\nthat we can change. So we can change\nsome valve positions. We can change how\nmuch electricity",
    "start": "2699130",
    "end": "2705280"
  },
  {
    "text": "goes into our heaters. We can change the setting on\nour back pressure regulator.",
    "start": "2705280",
    "end": "2710920"
  },
  {
    "text": "We can change the chemicals\nwe pour into the system. So there's a lot of\nknobs that we control.",
    "start": "2710920",
    "end": "2716920"
  },
  {
    "text": "And I'm going to\ncall the knobs x. And then we have parameters.",
    "start": "2716920",
    "end": "2722510"
  },
  {
    "text": " And these are other\nthings that affect",
    "start": "2722510",
    "end": "2728550"
  },
  {
    "text": "the result of the\nexperiment that we don't have control over. And I'm going to\ncall those theta.",
    "start": "2728550",
    "end": "2735839"
  },
  {
    "text": "So for example, if I do\na kinetics experiment, it depends on the\nrate coefficients.",
    "start": "2735840",
    "end": "2741729"
  },
  {
    "text": "I have no control of\nthe rate coefficients. They're going to [INAUDIBLE]\nby God, as far as I know. So they're some numbers,\nbut they definitely affect",
    "start": "2741729",
    "end": "2749749"
  },
  {
    "text": "the result. And if the\nrate coefficient had a different value, I would\nget a different result in the kinetic experiment.",
    "start": "2749749",
    "end": "2756540"
  },
  {
    "text": "The molecular weight of sulfur,\nI have no control over that. That's just a parameter. But if I weigh something and it\nhas a certain number of atoms",
    "start": "2756540",
    "end": "2762660"
  },
  {
    "text": "of sulfur, it's going to be\na very important parameter in determining the result.",
    "start": "2762660",
    "end": "2768150"
  },
  {
    "text": "So we have these two things. And then we're going to have\nsome measurables, things",
    "start": "2768150",
    "end": "2780550"
  },
  {
    "text": "that we can measure. Let's call them y. And in general, we think\nthat if we set the x value",
    "start": "2780550",
    "end": "2788740"
  },
  {
    "text": "and we know the theta\nvalues, we should get some measurable values. And so there's a\ny that the model",
    "start": "2788740",
    "end": "2797070"
  },
  {
    "text": "says that's a function of\nthe x's and the thetas.",
    "start": "2797070",
    "end": "2804490"
  },
  {
    "text": "Now, I write this as a\nsimple function like this. This might be\nreally complicated. It might have partial\ndifferential equations",
    "start": "2804490",
    "end": "2810213"
  },
  {
    "text": "embedded inside it. It might have all kinds of\nhorrible stuff inside it. But you guys already know how\nto solve all these problems already because you've done it.",
    "start": "2810213",
    "end": "2815940"
  },
  {
    "text": "You've been in this class\nthrough seven homeworks already. And so no problem, right? So if I give you something--",
    "start": "2815940",
    "end": "2821820"
  },
  {
    "text": "I give you some knobs. I give you some parameters--\nyou can compute it, all right? And so then the question is--\nthat's what the model says.",
    "start": "2821820",
    "end": "2829080"
  },
  {
    "text": "So we could predict\nthe forward prediction of what the model should say\nif I knew what the parameter values were, if I knew\nwhat the knob values were.",
    "start": "2829080",
    "end": "2837090"
  },
  {
    "text": "And I want to--",
    "start": "2837090",
    "end": "2842440"
  },
  {
    "text": "oftentimes what I\nmeasure, y data,",
    "start": "2842440",
    "end": "2848040"
  },
  {
    "text": "which is a function\nof the knobs, it's implicitly a function\nof the parameters. I have no control\nof them, so I'm not",
    "start": "2848040",
    "end": "2854375"
  },
  {
    "text": "going to even put them in here. So I set the knobs I want. I get some data. I want these two to\nmatch each other.",
    "start": "2854375",
    "end": "2860450"
  },
  {
    "text": "I think they should be the\nsame thing if my model is true, yeah? So this is my model, really.",
    "start": "2860450",
    "end": "2865718"
  },
  {
    "start": "2865718",
    "end": "2871780"
  },
  {
    "text": "But I don't think they\nshould be exactly the same. I mean, just like when you\ntry to measure my height, you don't get exactly\nthe same numbers.",
    "start": "2871780",
    "end": "2878290"
  },
  {
    "text": "So these y data are not going\nto be exactly the same numbers as my model would say.",
    "start": "2878290",
    "end": "2883482"
  },
  {
    "text": "So now I have to\ncope with the fact that I have deviations between\nthe data and the model.",
    "start": "2883482",
    "end": "2888609"
  },
  {
    "text": "And how am I going to\nhandle that, all right? ",
    "start": "2888610",
    "end": "2895260"
  },
  {
    "text": "And also, we have a\nset of these guys, typically do some repeats.",
    "start": "2895260",
    "end": "2900550"
  },
  {
    "text": "So we have like several\nnumbers for each setting in the x's, and they don't\neven agree with each other because they're all different.",
    "start": "2900550",
    "end": "2905820"
  },
  {
    "text": "Every time I repeated\nthe experiment, I got some different result-- that's my y's-- for each x.",
    "start": "2905820",
    "end": "2911111"
  },
  {
    "text": "And then I change\nthe x a few times at different knob settings. Then I make some\nmore measurements. And I have a whole\nbunch of y values",
    "start": "2911112",
    "end": "2917369"
  },
  {
    "text": "that are all scattered\nnumbers that maybe scatter around this model\npossibly, if I'm lucky,",
    "start": "2917370",
    "end": "2922660"
  },
  {
    "text": "if the model's right. Often, usually I also don't\nknow if the model's correct. So that's another thing to\nhold in the back of your mind",
    "start": "2922660",
    "end": "2929390"
  },
  {
    "text": "is like, we're going to\nthis whole comparison assuming the model's correct. And then we might, at the\nend, decide, hmm, maybe",
    "start": "2929390",
    "end": "2935640"
  },
  {
    "text": "the model's not really right. I may have to go\nmake a new model. So that's just a thing to\nkeep in the back your mind.",
    "start": "2935640",
    "end": "2941110"
  },
  {
    "text": "But we'll be optimistic\nto start with, and we'll assume that\nthe model is good. And our only\nchallenge is we just don't have the right values of\nthe thetas, maybe, in my model.",
    "start": "2941110",
    "end": "2951060"
  },
  {
    "text": "And this is another thing, too. So the thetas are things\nlike rate coefficients and molecular weights\nand viscosities",
    "start": "2951060",
    "end": "2956609"
  },
  {
    "text": "and stuff that are like\nproperties of the universe, and they're real numbers, maybe. They're also things like\nthe length of my apparatus",
    "start": "2956610",
    "end": "2963119"
  },
  {
    "text": "and stuff like that. But I don't know those numbers\nto perfect precision, right?",
    "start": "2963120",
    "end": "2968809"
  },
  {
    "text": "The best number I\ncan find, if I look in the database\nis, you know, you could find like\nthe speed of light",
    "start": "2968809",
    "end": "2974400"
  },
  {
    "text": "to like 11 significant\nfigures, but I don't know it to the 12th significant figure. So I don't know any of\nthe numbers perfectly.",
    "start": "2974400",
    "end": "2980144"
  },
  {
    "text": "And a lot of numbers I\ndon't even know at all. So like there's some\nrate coefficients that no one has ever\nmeasured or calculated",
    "start": "2980144",
    "end": "2985170"
  },
  {
    "text": "in the history of the world. And my students have\nto deal with that a lot in the Green group. So a lot of these\nare quite uncertain.",
    "start": "2985170",
    "end": "2992719"
  },
  {
    "text": "But there are some that\nare pretty certain. You have quite a big variance,\nactually, of how certainly you know the parameter values.",
    "start": "2992719",
    "end": "2997819"
  },
  {
    "text": " So one idea, a very popular\nidea, is to say, you know,",
    "start": "2997819",
    "end": "3007140"
  },
  {
    "text": "I have this deviation between\nthe model and the experiment.",
    "start": "3007140",
    "end": "3012260"
  },
  {
    "text": "So I want to sort of do a\nminimization by varying, say, parameter values of\nsome measure of the error",
    "start": "3012260",
    "end": "3023110"
  },
  {
    "text": "between the model and the data. ",
    "start": "3023110",
    "end": "3032100"
  },
  {
    "text": "Somehow, I want\nto minimize that. And I have to think about, well,\nwhat should I really minimize?",
    "start": "3032100",
    "end": "3038000"
  },
  {
    "text": "And the popular thing to\nminimize is these guys squared",
    "start": "3038000",
    "end": "3044010"
  },
  {
    "text": "and actually to weight\nthem by some kind of sigma for each one of these guys.",
    "start": "3044010",
    "end": "3049500"
  },
  {
    "text": "So this is-- we should\nchange the notation, make this clearer. ",
    "start": "3049500",
    "end": "3083619"
  },
  {
    "text": "These guys-- one model, and\nit's the i-th measurement",
    "start": "3083620",
    "end": "3090890"
  },
  {
    "text": "that corresponds to\nthat n-th experiment. ",
    "start": "3090890",
    "end": "3104220"
  },
  {
    "text": "So I think that the difference\nbetween what I measured",
    "start": "3104220",
    "end": "3109320"
  },
  {
    "text": "and what the model calculated\nshould be sort of scaled by the variance, right?",
    "start": "3109320",
    "end": "3115650"
  },
  {
    "text": "So I would expect\nthat this sum has a bunch of numbers that\nare sort of order of one",
    "start": "3115650",
    "end": "3120990"
  },
  {
    "text": "because I expect the deviation\nto be approximately scaled of the variance of\nmy measurements.",
    "start": "3120990",
    "end": "3126800"
  },
  {
    "text": "And if these deviations are\nmuch larger than the variance, then I think my\nmodel's not right",
    "start": "3126800",
    "end": "3132330"
  },
  {
    "text": "and what I'm going to\ntry to do right here is I'm going to try to adjust\nthe thetas, the parameters, to try to force the model to\nagree better to my experiment.",
    "start": "3132330",
    "end": "3141300"
  },
  {
    "text": "And this form looks\na lot like this.",
    "start": "3141300",
    "end": "3148000"
  },
  {
    "text": "Do you see this? You see I have a sum\nof the deviations between the experiment and\na theoretical sort of thing",
    "start": "3148000",
    "end": "3156480"
  },
  {
    "text": "divided by some variance? And so this is the motivation\nof where this comes from,",
    "start": "3156480",
    "end": "3162800"
  },
  {
    "text": "is that I want to make the\nprobability that I would make",
    "start": "3162800",
    "end": "3170550"
  },
  {
    "text": "this observation\nexperimentally would be maximum if this quantity in the exponent\nis as small as possible.",
    "start": "3170550",
    "end": "3180460"
  },
  {
    "text": "So I'm going to try to\nminimize that quantity, and that's exactly what\nI'm doing over here. Is that all right?",
    "start": "3180460",
    "end": "3186502"
  },
  {
    "text": "OK, so next time\nwhen we come back, I'll talk more about\nhow we actually do it. ",
    "start": "3186502",
    "end": "3191256"
  }
]
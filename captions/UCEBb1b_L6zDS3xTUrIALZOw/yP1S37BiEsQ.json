[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6090"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6090",
    "end": "12720"
  },
  {
    "text": "from hundreds of\nMIT courses, visit MITOpenCourseWare@OCW.MIT.edu. ",
    "start": "12720",
    "end": "20292"
  },
  {
    "text": "PHILIPPE RIGOLLET: It's\nbecause if I was not, this would be basically the\nlast topic we would ever see.",
    "start": "20292",
    "end": "25640"
  },
  {
    "text": "And this is arguably, probably\nthe most important topic in statistics, or at\nleast that's probably",
    "start": "25640",
    "end": "30950"
  },
  {
    "text": "the reason why most of\nyou are taking this class. Because regression\nimplies prediction,",
    "start": "30950",
    "end": "36980"
  },
  {
    "text": "and prediction is what people\nare after to now, right? You don't need to\nunderstand what the model for the\nfinancial market is if you actually\nhave a formula",
    "start": "36980",
    "end": "43460"
  },
  {
    "text": "to predict what the stock\nprices are going to be tomorrow. And regression, in a way,\nallows us to do that.",
    "start": "43460",
    "end": "49705"
  },
  {
    "text": "And we'll start with a very\nsimple version of regression, which is linear regression,\nwhich is the most standard one.",
    "start": "49705",
    "end": "55130"
  },
  {
    "text": "And then we'll move on to\nslightly more advanced notions such as nonparametric\nregression. At least, we're going to see\nthe principles behind it.",
    "start": "55130",
    "end": "62960"
  },
  {
    "text": "And I'll touch upon a little bit\nof high dimensional regression, which is what people\nare doing today.",
    "start": "62960",
    "end": "69450"
  },
  {
    "text": "So the goal of\nregression is to try to predict one variable\nbased on another variable.",
    "start": "69450",
    "end": "76220"
  },
  {
    "text": "All right, so here the\nnotation is very important. It's extremely standard.",
    "start": "76220",
    "end": "82220"
  },
  {
    "text": "It goes everywhere essentially,\nand essentially you're trying to explain why\nas a function of x,",
    "start": "82220",
    "end": "89840"
  },
  {
    "text": "which is the usual y\nequals f of x question-- except that, you know, if\nyou look at a calculus class,",
    "start": "89840",
    "end": "96090"
  },
  {
    "text": "people tell you y equals\nf of x, and they give you a specific form for f,\nand then you do something.",
    "start": "96090",
    "end": "102142"
  },
  {
    "text": "Here, we're just going\nto try to estimate what this length function is. And this is why we often\ncall y the explained variable",
    "start": "102142",
    "end": "109790"
  },
  {
    "text": "and x the explanatory variable. All right, so we're\nstatisticians,",
    "start": "109790",
    "end": "115960"
  },
  {
    "text": "so we start with data. All right, then what\ndoes our data look like? Well, it looks like a\nbunch of input, output",
    "start": "115960",
    "end": "121820"
  },
  {
    "text": "to this relationship. All right, so we have\na bunch of xi, yi. Those are pairs, and I can do\na scatterplot of those guys.",
    "start": "121820",
    "end": "129280"
  },
  {
    "text": "So each point here has a\nx-coordinate, which is xi,",
    "start": "129280",
    "end": "134390"
  },
  {
    "text": "and a y-coordinate,\nwhich is yi, and here, I have a bunch of endpoints. And I just draw them like that.",
    "start": "134390",
    "end": "139830"
  },
  {
    "text": "Now, the functions we're\ngoing to be interested in are often function of the form\ny equals a plus b times x, OK.",
    "start": "139830",
    "end": "150170"
  },
  {
    "text": "And that means that this\nfunction looks like this. ",
    "start": "150170",
    "end": "156310"
  },
  {
    "text": "So if I do x and\ny, this function looks exactly like a line,\nand clearly those points",
    "start": "156310",
    "end": "161530"
  },
  {
    "text": "are not on the line. And it will basically\nnever happen that those points are on a line. There's a famous\nT-shirt from, I think,",
    "start": "161530",
    "end": "168460"
  },
  {
    "text": "U.C. Berkeley's\nstaff department, that shows this picture\nand put a line between them like we're going to see it.",
    "start": "168460",
    "end": "173859"
  },
  {
    "text": "And it says, oh,\nstatisticians, so many points, and you still managed\nto miss all of them.",
    "start": "173860",
    "end": "179590"
  },
  {
    "text": "And so essentially, we don't\nbelieve that this relationship y is equal to a plus bx is true,\nbut maybe up to some noise.",
    "start": "179590",
    "end": "188911"
  },
  {
    "text": "And that's where the statistics\nis going to come into play. There's going to be some random\nnoise that's going to play out,",
    "start": "188912",
    "end": "193995"
  },
  {
    "text": "and hopefully the noise is\ngoing to be spread out evenly, so that we can average it\nif we have enough points.",
    "start": "193995",
    "end": "200950"
  },
  {
    "text": "Average it out, OK. And so this epsilon here is not\nnecessarily due to randomness.",
    "start": "200950",
    "end": "206910"
  },
  {
    "text": "But again, just like we did\nmodeling in the first place, it essentially\naccounts for everything we don't understand\nabout this relationship.",
    "start": "206910",
    "end": "213520"
  },
  {
    "text": "All right, so for example-- so here, I'm not going to be-- give me one second, so we'll\nsee an example in a second.",
    "start": "213520",
    "end": "221960"
  },
  {
    "text": "But the idea here is\nthat if you have data, and if you believe\nthat it's of the form, a plus b x plus\nsome noise, you're",
    "start": "221960",
    "end": "227740"
  },
  {
    "text": "trying to find the line\nthat will explain your data the best, right? In the terminology\nwe've been using before,",
    "start": "227740",
    "end": "234650"
  },
  {
    "text": "this would be the most likely\nline that explains the data. So we can see that\nit's slightly--",
    "start": "234650",
    "end": "239680"
  },
  {
    "text": "we've just added\nanother dimension to our statistical problem. We don't have just x's,\nbut we have y's, and we're trying to find the most likely\nexplanation of the relationship",
    "start": "239680",
    "end": "247450"
  },
  {
    "text": "between y and x. All right, and so\nin practice, the way it's going to look like is that\nwe're going to have basically",
    "start": "247450",
    "end": "254920"
  },
  {
    "text": "two parameters to\nfind the slope b and the intercept\na, and given data,",
    "start": "254920",
    "end": "260239"
  },
  {
    "text": "the goal is going to be to try\nto find the best possible line. All right? So what we're going\nto find is not",
    "start": "260240",
    "end": "265930"
  },
  {
    "text": "exactly a and b, the ones that\nactually generate the data, but some estimators of those\nparameters, a hat and b hat",
    "start": "265930",
    "end": "273790"
  },
  {
    "text": "constructed from the data. All right, so we'll see\nthat more generally, but we're not going to go too\nmuch in the details of this.",
    "start": "273790",
    "end": "280990"
  },
  {
    "text": "There's actually\nquite a bit that you can understand if\nyou do what's called univariate regression\nwhen x is actually",
    "start": "280990",
    "end": "287260"
  },
  {
    "text": "a real valued random variable. So when this happens, this is\ncalled univariate regression.",
    "start": "287260",
    "end": "292720"
  },
  {
    "start": "292720",
    "end": "299640"
  },
  {
    "text": "And when x is in rp for p\nlarger than or equal to 2,",
    "start": "299640",
    "end": "305550"
  },
  {
    "text": "this is called\nmultivariate regression. ",
    "start": "305550",
    "end": "316639"
  },
  {
    "text": "OK, and so here we're\njust trying to explain y is a plus bx plus epsilon.",
    "start": "316640",
    "end": "323940"
  },
  {
    "text": "And here we're going to have\nsomething more complicated. We're going to have y, which is\nequal to a plus b1, x1 plus b2,",
    "start": "323940",
    "end": "333510"
  },
  {
    "text": "x2 plus bp, xp plus epsilon--",
    "start": "333510",
    "end": "339780"
  },
  {
    "text": "where x is equal to-- the coordinates of x are\ngiven by x1, 2xp, rp.",
    "start": "339780",
    "end": "346710"
  },
  {
    "text": "OK, so it's still linear. Right, they still add\nall the coordinates of x with a coefficient\nin front of them,",
    "start": "346710",
    "end": "353370"
  },
  {
    "text": "but it's a bit more complicated\nthan just one coefficient for one coordinate of x, OK?",
    "start": "353370",
    "end": "358770"
  },
  {
    "text": "So we'll come back to\nmultivariate regression. Of course, you can write\nthis as x transpose b, right?",
    "start": "358770",
    "end": "368280"
  },
  {
    "text": "So this entire thing here,\nthis linear combination",
    "start": "368280",
    "end": "374800"
  },
  {
    "text": "is of the form x\ntranspose b, where b is the vector that has\ncoordinates b1 to bp.",
    "start": "374800",
    "end": "383310"
  },
  {
    "text": "OK? Sorry, here, it's in [? rd, ?]\np is the natural notation.",
    "start": "383310",
    "end": "391100"
  },
  {
    "text": "All right, so our goal\nhere, in the univariate one, is to try to write\nthe model, make sense",
    "start": "391100",
    "end": "398360"
  },
  {
    "text": "of this little twiddle here-- essentially, from a\nstatistical modeling question,",
    "start": "398360",
    "end": "404050"
  },
  {
    "text": "the question is going to be,\nwhat distributional assumptions do you want to put on epsilon? Are you going to say\nthey're Gaussian?",
    "start": "404050",
    "end": "410313"
  },
  {
    "text": "Are you going to say\nthey're binomial? ",
    "start": "410313",
    "end": "420160"
  },
  {
    "text": "OK, are you going to\nsay they're binomial? Are you going to say\nthey're Bernoulli?",
    "start": "420160",
    "end": "425532"
  },
  {
    "text": "So that's going to be what we\nwe're going to make sense of, and then we're going\nto try to find a method to estimate a and b.",
    "start": "425532",
    "end": "431700"
  },
  {
    "text": "And then maybe we're\ngoing to try to do some inference about a and b-- maybe test if a and b take\ncertain values, if they're",
    "start": "431700",
    "end": "438389"
  },
  {
    "text": "less than something,\nmaybe find some confidence regions for a and b, all right?",
    "start": "438390",
    "end": "444290"
  },
  {
    "text": "So why would you\nwant to do this? Well, I'm sure all of you have\nan application, if I give you",
    "start": "444290",
    "end": "449810"
  },
  {
    "text": "some x, you're trying\nto predict what y is. Machine learning is all\nabout doing this, right? Without maybe trying\nto even understand",
    "start": "449810",
    "end": "456994"
  },
  {
    "text": "the physics behind\nthis, they're saying, well, you give me\na bag of words, I want to understand whether\nit's going to be a spam or not.",
    "start": "456994",
    "end": "463520"
  },
  {
    "text": "You give me a bunch of\neconomic indicators, I want you to tell me how much\nI should be selling my car for.",
    "start": "463520",
    "end": "471530"
  },
  {
    "text": "You give me a bunch of\nmeasurements on some patient, I want you to predict\nhow this person is",
    "start": "471530",
    "end": "477439"
  },
  {
    "text": "going to respond to my\ndrug-- and things like this. All right, and often we actually\ndon't have much modeling",
    "start": "477440",
    "end": "484830"
  },
  {
    "text": "intuition about what the\nrelationship between x and y is, and this linear thing is\nbasically the simplest function",
    "start": "484830",
    "end": "490350"
  },
  {
    "text": "we can think of. Arguably, linear functions\nare the simplest functions that are not trivial.",
    "start": "490350",
    "end": "496110"
  },
  {
    "text": "Otherwise, we would just say,\nwell, let's just predict x of y to be a constant, meaning\nit does not depend on x.",
    "start": "496110",
    "end": "501444"
  },
  {
    "text": "But if you want it\nto depend on x, then your functions are basically\nas simple as it gets. It turns out, amazingly, this\ndoes the trick quite often.",
    "start": "501445",
    "end": "510840"
  },
  {
    "text": "So for example, if\nyou look at economics, you might want to assume\nthat the demand is",
    "start": "510840",
    "end": "515909"
  },
  {
    "text": "a linear function of the price. So if your price\nis zero, there's going to be a certain demand.",
    "start": "515909",
    "end": "521640"
  },
  {
    "text": "And as the price increases,\nthe demand is going to move. Do you think b is going to\nbe positive or negative here?",
    "start": "521640",
    "end": "527370"
  },
  {
    "text": " What? Typically, it's\nnegative unless we're",
    "start": "527370",
    "end": "533610"
  },
  {
    "text": "talking about\nmaybe luxury goods, where you know,\nthe more expensive, the more people\nactually want it.",
    "start": "533610",
    "end": "540130"
  },
  {
    "text": "I mean, if we're talking\nabout actual economic demand, that's probably\ndefinitely negative.",
    "start": "540130",
    "end": "546030"
  },
  {
    "text": "It doesn't have to be,\nyou know, clearly linear,",
    "start": "546030",
    "end": "551360"
  },
  {
    "text": "so that you can actually\nmake it linear, transform it into something linear. So for example, you have\nthis like multiplicative",
    "start": "551360",
    "end": "557520"
  },
  {
    "text": "relationship, PV equals nRT,\nwhich is the Ideal gas law.",
    "start": "557520",
    "end": "564330"
  },
  {
    "text": "If you want to actually\nwrite this relationship, if you want to predict\nwhat the pressure is going to be as a function of\nthe volume and the temperature--",
    "start": "564330",
    "end": "573690"
  },
  {
    "text": "and well, let's assume that\nn is the Avogadro constant, and let's assume that the\nradius is actually fixed.",
    "start": "573690",
    "end": "582060"
  },
  {
    "text": "Then you take the log on each\nside, so you get PV equals nRT.",
    "start": "582060",
    "end": "587840"
  },
  {
    "start": "587840",
    "end": "603610"
  },
  {
    "text": "So what that means is that\nlog PV is equal to log nRT. ",
    "start": "603610",
    "end": "610600"
  },
  {
    "text": "So that means log P plus log V\nis equal to the log nR plus log",
    "start": "610600",
    "end": "623180"
  },
  {
    "text": "T. So we said that R is\nconstant, so this is actually",
    "start": "623180",
    "end": "628737"
  },
  {
    "text": "your constant. I'm going to call it a. And then that\nmeans that log P is",
    "start": "628737",
    "end": "635410"
  },
  {
    "text": "equal to minus log V. That\nlog P is equal to a minus log",
    "start": "635410",
    "end": "649430"
  },
  {
    "text": "V plus log T. OK?",
    "start": "649430",
    "end": "655070"
  },
  {
    "text": "And so in particular, if I\nwrite b equal to negative 1",
    "start": "655070",
    "end": "661650"
  },
  {
    "text": "and c equal to plus 1,\nthis gives me the formula that I have here. Now again, it might be the case\nthat this is the ideal gas law.",
    "start": "661650",
    "end": "670670"
  },
  {
    "text": "So in practice, if I\nstart recording pressure, and temperature, and volume, I\nmight make measurement errors,",
    "start": "670670",
    "end": "676830"
  },
  {
    "text": "there might be slightly\ndifferent conditions in such a way that I'm not\ngoing to get exactly those. And I'm just going to\nput this little twiddle",
    "start": "676830",
    "end": "683220"
  },
  {
    "text": "to account for the fact\nthat the points that I'm going to be recording\nfor log pressure, log volume, and log\ntemperature are not going",
    "start": "683220",
    "end": "690180"
  },
  {
    "text": "to be exactly on one line. OK, they're going to be close. Actually, in those\nphysics experiments,",
    "start": "690180",
    "end": "696150"
  },
  {
    "text": "usually, they're very close\nbecause the conditions are controlled under\nlab experiments.",
    "start": "696150",
    "end": "701740"
  },
  {
    "text": "So it means that the\nnoise is very small. But for other cases,\nlike demand and prices,",
    "start": "701740",
    "end": "707160"
  },
  {
    "text": "it's not a law of physics,\nand so this must change. Even the linear structure is\nprobably not clear, right.",
    "start": "707160",
    "end": "713180"
  },
  {
    "text": "At some points,\nthere's probably going to be some weird\ncurvature happening. All right, so this slide is\njust to tell you maybe you",
    "start": "713180",
    "end": "720910"
  },
  {
    "text": "don't have, obviously,\na linear relationship, but maybe you do\nif you start taking logs exponentials, squares.",
    "start": "720910",
    "end": "728380"
  },
  {
    "text": "You can sometimes take the\nproduct of two variables, things like this, right. So this is variable\ntransformation,",
    "start": "728380",
    "end": "733570"
  },
  {
    "text": "and it's mostly\ndomain-specific, so we're not going to go into\nmore details of this. Any questions?",
    "start": "733570",
    "end": "739480"
  },
  {
    "text": " All right, so now I'm\ngoing to be giving--",
    "start": "739480",
    "end": "747100"
  },
  {
    "text": "so if we start thinking\na little more about what these coefficients\nshould be, well, remember-- so\neverybody's clear why",
    "start": "747100",
    "end": "754440"
  },
  {
    "text": "I don't put the little i here? ",
    "start": "754440",
    "end": "761971"
  },
  {
    "text": "Right, I don't put the\nlittle i because I'm just talking about a generic\nx and a generic y,",
    "start": "761971",
    "end": "767120"
  },
  {
    "text": "but the observations\nare x1, y1, right. So typically, on\nthe blackboard I'm",
    "start": "767120",
    "end": "773450"
  },
  {
    "text": "often going to write only xy,\nbut the data really is x1,",
    "start": "773450",
    "end": "782980"
  },
  {
    "text": "y1, all the way to xn, yn. So those are those points in\nthis two dimensional plot.",
    "start": "782980",
    "end": "790810"
  },
  {
    "text": "But I think of those as being\nindependent copies of the pair",
    "start": "790810",
    "end": "801830"
  },
  {
    "text": "xy. They have to have-- to contain their relationship.",
    "start": "801830",
    "end": "807420"
  },
  {
    "text": "And so when I talk\nabout distribution of those random variables, I\ntalk about the distribution of xy, and that's the same.",
    "start": "807420",
    "end": "814240"
  },
  {
    "text": "All right, so the first\nthing you might want to ask is, well, if I have an\ninfinite amount of data,",
    "start": "814240",
    "end": "821790"
  },
  {
    "text": "what can I hope to\nget for a and b? If my simple size\ngoes to infinity, then I should actually\nknow exactly what",
    "start": "821790",
    "end": "828110"
  },
  {
    "text": "the distribution of xy is. And so there should\nbe an a and a b that captures this linear\nrelationship between y and x.",
    "start": "828110",
    "end": "837305"
  },
  {
    "text": "And so in particular,\nwe're going to try to ask the population,\nor theoretic, values of a and b,",
    "start": "837305",
    "end": "842709"
  },
  {
    "text": "and you can see that\nyou can actually compute them explicitly. So let's just try to find how.",
    "start": "842709",
    "end": "848510"
  },
  {
    "text": "So as I said, we have\na bunch of points on this line close\nto a line, and I'm",
    "start": "848510",
    "end": "856460"
  },
  {
    "text": "trying to find the best fit. All right, so this\nguy is not a good fit.",
    "start": "856460",
    "end": "863330"
  },
  {
    "text": "This guy is not a good fit. And we know that this guy\nis a good fit somehow. So we need to mathematically\nformulate the fact",
    "start": "863330",
    "end": "870680"
  },
  {
    "text": "that this line here is\nbetter than this line here or better than this line here.",
    "start": "870680",
    "end": "877460"
  },
  {
    "text": "So what we're trying to do\nis to create a function that has values that are\nsmaller for this curve",
    "start": "877460",
    "end": "883580"
  },
  {
    "text": "and larger for these two curves. And the way we do it is\nby measuring the fit, and the fit is essentially\nthe aggregate distance",
    "start": "883580",
    "end": "891740"
  },
  {
    "text": "of all the points to the curve. And there's many\nways I can measure",
    "start": "891740",
    "end": "896930"
  },
  {
    "text": "the distance to a curve. So if I want to find so--\nlet's just open a parenthesis. If I have a point\nhere-- so we're",
    "start": "896930",
    "end": "903290"
  },
  {
    "text": "going to do it for\none point at a time. So if I have a point,\nthere's many ways I can measure its distance\nto the curve, right?",
    "start": "903290",
    "end": "909529"
  },
  {
    "text": "I can measure it like that. That is one distance\nto the curve.",
    "start": "909530",
    "end": "914690"
  },
  {
    "text": "I can measure it like that by\nhaving a right angle here that is one distance to the curve.",
    "start": "914690",
    "end": "920840"
  },
  {
    "text": "Or I can measure it like that. That is another distance\nto the curve, right.",
    "start": "920840",
    "end": "927490"
  },
  {
    "text": "There's many ways\nI can go for it. It turns out that\none is actually going to be fairly\nconvenient for us,",
    "start": "927490",
    "end": "933040"
  },
  {
    "text": "and that's the one that says,\nlet's look at the square of the value of x on the curve.",
    "start": "933040",
    "end": "938720"
  },
  {
    "text": "So if this is the curve,\ny is equal to a plus bx. ",
    "start": "938720",
    "end": "951260"
  },
  {
    "text": "Now, I'm going to think of\nthis point as a random point, capital X, capital\nY, so that means",
    "start": "951260",
    "end": "957050"
  },
  {
    "text": "that it's going to be x1,\ny1 or x2, y2, et cetera.",
    "start": "957050",
    "end": "962209"
  },
  {
    "text": "Now, I want to\nmeasure the distance. Can somebody tell me\nwhich of the three-- the first one, the second\none, or the third one--",
    "start": "962210",
    "end": "968870"
  },
  {
    "text": "this formula, expectation of y\nminus a minus bx squared is-- which of the three\nis it representing?",
    "start": "968870",
    "end": "978578"
  },
  {
    "text": "AUDIENCE: The second one. PHILIPPE RIGOLLET:\nThe second one where I have the right angle? OK, everybody agrees with this?",
    "start": "978578",
    "end": "986709"
  },
  {
    "text": "Anybody wants to vote\nfor something else? Yeah? AUDIENCE: The third one? PHILIPPE RIGOLLET:\nThe third one? Everybody agrees\nwith the third one?",
    "start": "986710",
    "end": "994520"
  },
  {
    "text": "So by default, everybody's\non the first one? Yeah, it is the vertical\ndistance actually.",
    "start": "994520",
    "end": "1002009"
  },
  {
    "text": "And the reason is if it was the\none with the straight angle, with the right angle,\nit would actually be a very complicated\nmathematical formula,",
    "start": "1002010",
    "end": "1008430"
  },
  {
    "text": "so let's just see y, right? And by y, I mean y.",
    "start": "1008430",
    "end": "1013470"
  },
  {
    "text": "OK, so this means that this\nis my x, and this is my y.",
    "start": "1013470",
    "end": "1019459"
  },
  {
    "text": " All right, so that means\nthat this point is xy.",
    "start": "1019460",
    "end": "1025829"
  },
  {
    "text": "So what I'm measuring\nis the difference between y minus\na plus b times x.",
    "start": "1025829",
    "end": "1035964"
  },
  {
    "text": "This is the thing I'm going\nto take the expectation off-- the square and then\nthe expectation-- so a plus b times x, if this is\nthis line, this is this point.",
    "start": "1035965",
    "end": "1044140"
  },
  {
    "text": "So that's this value here. This value here is\na plus bx, right?",
    "start": "1044140",
    "end": "1053254"
  },
  {
    "text": "So what I'm really\nmeasuring is the difference between y and N plus bx,\nwhich is this distance here.",
    "start": "1053254",
    "end": "1058740"
  },
  {
    "text": " And since I like things\nlike Pythagoras theorem,",
    "start": "1058740",
    "end": "1065846"
  },
  {
    "text": "I'm actually going\nto put a square here before I take the expectation.",
    "start": "1065846",
    "end": "1071500"
  },
  {
    "text": "So now this is a\nrandom variable. This is this random variable. And so I want a number,\nso I'm going to turn it",
    "start": "1071500",
    "end": "1078419"
  },
  {
    "text": "into a deterministic number. And the way I do this is\nby taking expectation. And if you think expectations\nshould be close to average,",
    "start": "1078420",
    "end": "1087330"
  },
  {
    "text": "this is the same\nthing as saying, I want that in\naverage, the y's are close to the a plus bx, right?",
    "start": "1087330",
    "end": "1094440"
  },
  {
    "text": "So we're doing it\nin expectation, but that's going to\ntranslate into doing it in average for all the points.",
    "start": "1094440",
    "end": "1100650"
  },
  {
    "text": "All right, so this is the\nthing I want to measure. So that's this\nvertical distance. Yeah?",
    "start": "1100650",
    "end": "1106321"
  },
  {
    "text": "OK. ",
    "start": "1106321",
    "end": "1112750"
  },
  {
    "text": "This is my fault actually. Maybe we should\nclose those shades.",
    "start": "1112750",
    "end": "1117890"
  },
  {
    "start": "1117890",
    "end": "1130230"
  },
  {
    "text": "OK, I cannot do just\none at a time, sorry. ",
    "start": "1130230",
    "end": "1151910"
  },
  {
    "text": "All right, so now that I do\nthose vertical distances, I can ask-- well, now,\nI have this function,",
    "start": "1151910",
    "end": "1158340"
  },
  {
    "text": "right-- to have a function that\ntakes two parameters a and b, maps it to the expectation\nof y minus a plus bx squared.",
    "start": "1158340",
    "end": "1170220"
  },
  {
    "text": "Sorry, the square is here. And I could ask, well,\nthis is a function that measures the fit of the\nparameters a and b, right?",
    "start": "1170220",
    "end": "1178320"
  },
  {
    "text": "This function should be small. The value of this\nfunction here, function",
    "start": "1178320",
    "end": "1185700"
  },
  {
    "text": "of a and b that measures\nhow close the point xy is",
    "start": "1185700",
    "end": "1207370"
  },
  {
    "text": "to the line a plus\nb times x while y",
    "start": "1207370",
    "end": "1214210"
  },
  {
    "text": "is equal to a plus b\ntimes x in expectation. ",
    "start": "1214210",
    "end": "1223760"
  },
  {
    "text": "OK, agreed? This is what we just said. Again, if you're not\ncomfortable with the reason why",
    "start": "1223760",
    "end": "1229480"
  },
  {
    "text": "you get expectations, just\nthink about having data points and taking the average\nvalue for this guy. So it's basically an\naggregate distance",
    "start": "1229480",
    "end": "1236360"
  },
  {
    "text": "of the points to their line. OK, everybody agrees this\nis a legitimate measure?",
    "start": "1236360",
    "end": "1244389"
  },
  {
    "text": "If all my points were on the\nline-- if my distribution-- if y was actually equal\nto a plus bx for some a",
    "start": "1244390",
    "end": "1251720"
  },
  {
    "text": "and b then this function\nwould be equal to 0 for the correct a and b, right?",
    "start": "1251720",
    "end": "1257906"
  },
  {
    "text": "If they are far--\nwell, it's going to depend on how much\nnoise I'm getting, but it's still going to be\nminimized for the best one.",
    "start": "1257906",
    "end": "1264190"
  },
  {
    "text": "So let's minimize this thing. So here, I don't make any--",
    "start": "1264190",
    "end": "1271000"
  },
  {
    "text": "again, sorry. I don't make an assumption on\nthe distribution of x or y.",
    "start": "1271000",
    "end": "1281799"
  },
  {
    "text": "Here, I assume, somehow,\nthat the variance of x",
    "start": "1281800",
    "end": "1287290"
  },
  {
    "text": "is not equal to 0. Can somebody tell me why? Yeah? AUDIENCE: Not really a\nquestion-- the slides,",
    "start": "1287290",
    "end": "1293250"
  },
  {
    "text": "you have y minus a minus bx\nquantity squared expectation of that, and here you've written\nsquare of the expectation.",
    "start": "1293250",
    "end": "1301204"
  },
  {
    "text": "PHILIPPE RIGOLLET:\nNo, here I'm actually in the expectation\nof the square.",
    "start": "1301204",
    "end": "1306890"
  },
  {
    "text": "If I wanted to write the\nsquare of the expectation, I would just do this.",
    "start": "1306890",
    "end": "1312350"
  },
  {
    "text": "So let's just make it clear. ",
    "start": "1312350",
    "end": "1320970"
  },
  {
    "text": "Right? Do you want me to put an\nextra set of parenthesis? That's what you want me to do?",
    "start": "1320970",
    "end": "1326690"
  },
  {
    "text": "AUDIENCE: Yeah, it's just\nconfusing with the [INAUDIBLE] PHILIPPE RIGOLLET: OK, that's\nthe one that makes sense, so",
    "start": "1326690",
    "end": "1333450"
  },
  {
    "text": "the square of the expectation? AUDIENCE: Yeah. PHILIPPE RIGOLLET: Oh, the\nexpectation of the square, sorry. ",
    "start": "1333450",
    "end": "1340310"
  },
  {
    "text": "Yeah, dyslexia. All right, any question? Yeah?",
    "start": "1340310",
    "end": "1345600"
  },
  {
    "text": "AUDIENCE: Does this assume\nthat the error is Gaussian? PHILIPPE RIGOLLET: No. ",
    "start": "1345600",
    "end": "1352290"
  },
  {
    "text": "AUDIENCE: I mean, in\nthe sense that like, if we knew that the\nerror was, like, even the minus followed\nlike-- so even the minus x",
    "start": "1352290",
    "end": "1360062"
  },
  {
    "text": "to the fourth distribution,\nwould we want to minimise the expectation of what\nthe fourth power of y minus",
    "start": "1360062",
    "end": "1368358"
  },
  {
    "text": "a equals bx in order to get\n[? what the ?] [? best is? ?] PHILIPPE RIGOLLET: Why? ",
    "start": "1368358",
    "end": "1377372"
  },
  {
    "text": "So you know the answers\nto your question, so I just want you to\nuse the words that-- right, so why would you want\nto use the fourth power?",
    "start": "1377372",
    "end": "1384756"
  },
  {
    "text": "AUDIENCE: Well,\nbecause, like, we want to more strongly\npenalize deviations because we'd expect very\nlarge deviations to be",
    "start": "1384756",
    "end": "1391518"
  },
  {
    "text": "very rare, or more\nrare, than it would with the Gaussian\n[INAUDIBLE] power.",
    "start": "1391518",
    "end": "1398170"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah so,\nthat would be the maximum likely estimator that you're\ndescribing to me, right? I can actually\nwrite the likelihood of a pair of numbers ab.",
    "start": "1398170",
    "end": "1405340"
  },
  {
    "text": "And if I know this,\nthat's actually what's going to come\ninto it because I know that the density is\ngoing to come into play when",
    "start": "1405340",
    "end": "1411610"
  },
  {
    "text": "I talk about there. But here, I'm just\ntalking about-- this is a mechanical tool. I'm just saying, let's minimize\nthe distance to the curve.",
    "start": "1411610",
    "end": "1419640"
  },
  {
    "text": "Another thing I could have\ndone is take the absolute value of this thing, for example. I just decided to take the\nsquare root before I did it.",
    "start": "1419640",
    "end": "1426190"
  },
  {
    "text": "OK, so regardless\nof what I'm doing, I'm just taking the\nsquares because that's just going to be convenient for me\nto do my computations for now.",
    "start": "1426190",
    "end": "1433600"
  },
  {
    "text": "But we don't have\nany statistical model at this point. I didn't say anything--\nthat y follows this.",
    "start": "1433600",
    "end": "1439039"
  },
  {
    "text": "X follows this. I'm just doing\nminimal assumptions as we go, all right?",
    "start": "1439040",
    "end": "1444250"
  },
  {
    "text": "So the variance of\nx is not equal to 0? Could somebody tell me why? ",
    "start": "1444250",
    "end": "1451330"
  },
  {
    "text": "What would my cloud point\nlook like if the variance of x was equal to 0? Yeah, they would all\nbe at the same point.",
    "start": "1451330",
    "end": "1458122"
  },
  {
    "text": "So it's going to be hard for\nme to start fitting in a line, right? I mean, best case\nscenario, I have this x.",
    "start": "1458122",
    "end": "1464100"
  },
  {
    "text": "It has variance, zero, so\nthis is the expectation of x. And all my points have\nthe same expectation,",
    "start": "1464100",
    "end": "1471019"
  },
  {
    "text": "and so, yes, I could\nprobably fit that line. But that wouldn't help\nvery much for other x's.",
    "start": "1471020",
    "end": "1478340"
  },
  {
    "text": "So I need a bit of variance\nso that things spread out a little bit. ",
    "start": "1478340",
    "end": "1487440"
  },
  {
    "text": "OK, I'm going to\nhave to do this. I think it's just my-- ",
    "start": "1487440",
    "end": "1510200"
  },
  {
    "text": "All right, so I'm going to\nput a little bit of variance. And the other thing is here,\nI don't want to do much more,",
    "start": "1510200",
    "end": "1515960"
  },
  {
    "text": "but I'm actually going to think\nof x as having means zero.",
    "start": "1515960",
    "end": "1522440"
  },
  {
    "text": "And the way I do\nthis is as follows. Let's define x tilde, which is\nx minus the expectation of x.",
    "start": "1522440",
    "end": "1530570"
  },
  {
    "text": "OK, so definitely the\nexpectation of x tilde is what? ",
    "start": "1530570",
    "end": "1536620"
  },
  {
    "text": "Zero, OK. And so now I want to\nminimize in ab, expectation",
    "start": "1536620",
    "end": "1543350"
  },
  {
    "text": "of y minus a plus b, x squared.",
    "start": "1543350",
    "end": "1553919"
  },
  {
    "text": "And the way I'm going to do this\nis by turning x into x tilde",
    "start": "1553920",
    "end": "1563810"
  },
  {
    "text": "and stuffing the extra-- and putting the extra\nexpectation of x into the a.",
    "start": "1563810",
    "end": "1572760"
  },
  {
    "text": "So I'm going to write this as\nan expectation of y minus a plus",
    "start": "1572760",
    "end": "1579840"
  },
  {
    "text": "b expectation of x--",
    "start": "1579840",
    "end": "1585179"
  },
  {
    "text": "which I'm going to a tilde-- and plus b x tilde.",
    "start": "1585180",
    "end": "1590300"
  },
  {
    "text": " OK?",
    "start": "1590300",
    "end": "1595630"
  },
  {
    "text": "And everybody agrees with this? So now I have two\nparameters, a tilde and b,",
    "start": "1595630",
    "end": "1601490"
  },
  {
    "text": "and I'm going to pretend\nthat now x tilde-- so now the role of x is played\nby x tilde, which is now",
    "start": "1601490",
    "end": "1610830"
  },
  {
    "text": "a centered random variable. OK, so I'm going to\ncall this guy a tilde, but for my computations\nI'm going to call it a.",
    "start": "1610830",
    "end": "1618859"
  },
  {
    "text": "So how do I find the\nminimum of this thing? ",
    "start": "1618859",
    "end": "1625114"
  },
  {
    "text": "Derivative equal to zero, right? So here it's a quadratic thing. It's going to be like that. I take the derivative,\nset it to zero.",
    "start": "1625114",
    "end": "1630880"
  },
  {
    "text": "So I'm first going to take\nthe derivative with respect to a and set it equal to zero,\nso that's equivalent to saying",
    "start": "1630880",
    "end": "1636370"
  },
  {
    "text": "that the expectation of-- well, here, I'm going\nto pick up a 2-- y minus a plus bx\ntilde is equal to zero.",
    "start": "1636370",
    "end": "1653720"
  },
  {
    "text": "And then I also have that the\nderivative with respect to b is equal to zero, which is\nequivalent to the expectation",
    "start": "1653720",
    "end": "1660260"
  },
  {
    "text": "of-- well, I have a\nnegative sign somewhere, so let me put it here-- minus 2x tilde, y\nminus a plus bx tilde.",
    "start": "1660260",
    "end": "1670950"
  },
  {
    "text": " OK, see that's why I don't want\nto put too many parenthesis.",
    "start": "1670950",
    "end": "1678910"
  },
  {
    "text": " OK.",
    "start": "1678910",
    "end": "1685741"
  },
  {
    "text": "So I just took the\nderivative with respect to a, which is just\nbasically the square, and then I have a negative 1\nthat comes out from inside.",
    "start": "1685741",
    "end": "1692569"
  },
  {
    "text": "And then I take the\nderivative with respect to b, and since b has x tilde. In [? factor, ?] it\ncomes out as well.",
    "start": "1692569",
    "end": "1699340"
  },
  {
    "text": "All right, so the minus 2's\nreally won't matter for me.",
    "start": "1699340",
    "end": "1704419"
  },
  {
    "text": "And so now I have two equations. The first equation,\nwhile it's pretty simple, it's just telling me that\nthe expectation of y minus a",
    "start": "1704420",
    "end": "1711955"
  },
  {
    "text": "is equal to zero. So what I know is that a is\nequal to the expectation of y.",
    "start": "1711955",
    "end": "1721870"
  },
  {
    "text": "And really that\nwas a tilde, which implies that the a\nI want is actually",
    "start": "1721870",
    "end": "1727870"
  },
  {
    "text": "equal to the\nexpectation of y minus b",
    "start": "1727870",
    "end": "1740690"
  },
  {
    "text": "times the expectation of x. OK? ",
    "start": "1740690",
    "end": "1750240"
  },
  {
    "text": "Just because a tilde is a plus\nb times the expectation of x. ",
    "start": "1750240",
    "end": "1756830"
  },
  {
    "text": "So that's for my a. And then for my b, I\nuse the second one.",
    "start": "1756830",
    "end": "1762179"
  },
  {
    "text": "So the second one tells me that\nthe expectation of x tilde of y",
    "start": "1762180",
    "end": "1767990"
  },
  {
    "text": "is equal to a plus b times\nthe expectation of x tilde which is zero, right?",
    "start": "1767990",
    "end": "1773520"
  },
  {
    "start": "1773520",
    "end": "1778640"
  },
  {
    "text": "OK? But this a is actually\na tilde in this problem, so it's actually a plus\nb expectation of x.",
    "start": "1778640",
    "end": "1787210"
  },
  {
    "text": " Now, this is the\nexpectation of the product",
    "start": "1787210",
    "end": "1793890"
  },
  {
    "text": "of two random variables, but\nx tilde is centered, right? It's x minus expectation of\nx, so this thing is actually",
    "start": "1793890",
    "end": "1800669"
  },
  {
    "text": "equal to the covariance\nbetween x and y by definition of covariance. ",
    "start": "1800670",
    "end": "1809130"
  },
  {
    "text": "So now I have everything\nI need, right. How do I just-- I'm sorry about that.",
    "start": "1809130",
    "end": "1816520"
  },
  {
    "text": "So I have everything I need. Now, I now have two\nequations with two unknowns,",
    "start": "1816520",
    "end": "1822559"
  },
  {
    "text": "and all I have to do is\nto basically plug it in. So it's essentially telling\nme that the covariance of xy--",
    "start": "1822560",
    "end": "1829460"
  },
  {
    "text": "so the first equation tells\nme that the covariance of xy is equal to a plus b expectation\nof x, but a is expectation of y",
    "start": "1829460",
    "end": "1836750"
  },
  {
    "text": "minus b expectation of x. So it's-- well, actually,\nmaybe I should start with b.",
    "start": "1836750",
    "end": "1845113"
  },
  {
    "start": "1845113",
    "end": "1854780"
  },
  {
    "text": "Oh, sorry. OK, I forgot one thing. This is not true, right.",
    "start": "1854780",
    "end": "1860750"
  },
  {
    "text": "I forgot this term. x tilde multiplies x\ntilde here, so what",
    "start": "1860750",
    "end": "1865850"
  },
  {
    "text": "I'm left with is x tilde-- it's minus b times the\nexpectation of x tilde squared.",
    "start": "1865850",
    "end": "1871320"
  },
  {
    "text": "So that's actually minus\nb times the variance of x tilde because x tilde\nis already centered,",
    "start": "1871320",
    "end": "1877970"
  },
  {
    "text": "which is actually\nthe variance of x. ",
    "start": "1877970",
    "end": "1883850"
  },
  {
    "text": "So now I have that this thing\nis actually a plus b expectation",
    "start": "1883850",
    "end": "1889789"
  },
  {
    "text": "of x minus b variance of x.",
    "start": "1889790",
    "end": "1896570"
  },
  {
    "text": "And I also have that a\nis equal to expectation",
    "start": "1896570",
    "end": "1902179"
  },
  {
    "text": "of y minus b expectation of x. ",
    "start": "1902180",
    "end": "1913720"
  },
  {
    "text": "So if I sum the two, those\nguys are going to cancel. Those guys are going to cancel.",
    "start": "1913720",
    "end": "1920740"
  },
  {
    "text": "And so what I'm going to be\nleft with is covariance of xy is equal to expectation\nof x, expectation of y,",
    "start": "1920740",
    "end": "1930570"
  },
  {
    "text": "and then I'm left with\nthis term here, minus b times the variance of x. ",
    "start": "1930570",
    "end": "1937070"
  },
  {
    "text": "And so that tells me that b-- why do I still have\nthe variance there? ",
    "start": "1937070",
    "end": "1954692"
  },
  {
    "text": "AUDIENCE: So is the\ncovariance really the expectation of x tilde\ntimes y minus expectation of y?",
    "start": "1954692",
    "end": "1963124"
  },
  {
    "text": "Because y is not\ncentered, correct? PHILIPPE RIGOLLET: Yeah. AUDIENCE: OK, but x\nis still the center.",
    "start": "1963124",
    "end": "1968814"
  },
  {
    "text": "PHILIPPE RIGOLLET: But x\nis still the center, right. So you just need\nto have one that's centered for this to work.",
    "start": "1968814",
    "end": "1973830"
  },
  {
    "text": " Right, I mean, you can check it. But basically when\nyou're going to have",
    "start": "1973830",
    "end": "1980144"
  },
  {
    "text": "the product of the expectations,\nyou only need one of the two in the product to be zero. So the product is zero. ",
    "start": "1980144",
    "end": "1989090"
  },
  {
    "text": "OK, why do I keep my-- so I get a, a, and\nthen the b expectation.",
    "start": "1989090",
    "end": "1994542"
  },
  {
    "text": "OK, so that's probably\nearlier that I made a mistake. ",
    "start": "1994542",
    "end": "2005620"
  },
  {
    "text": "So I get-- so this was a tilde. Let's just be clear about the-- ",
    "start": "2005620",
    "end": "2020507"
  },
  {
    "text": "So that tells me that a tilde-- maybe it's not super\nfair of me to--",
    "start": "2020508",
    "end": "2025570"
  },
  {
    "text": " yeah, OK, I think I know\nwhere I made a mistake. I should not have centered.",
    "start": "2025570",
    "end": "2031550"
  },
  {
    "text": "I wanted to make my life\neasier, and I should not have done that. And the reason is a\ntilde depends on b,",
    "start": "2031550",
    "end": "2039140"
  },
  {
    "text": "so when I take the\nderivative with respect to b, what I'm left with here--",
    "start": "2039140",
    "end": "2044840"
  },
  {
    "text": "since a tilde\ndepends on b, when I take the derivative of\nthis guy, I actually don't get a tilde here,\nbut I really get--",
    "start": "2044840",
    "end": "2052550"
  },
  {
    "start": "2052550",
    "end": "2057570"
  },
  {
    "text": "so again, this was not-- so that's the first one. ",
    "start": "2057570",
    "end": "2070388"
  },
  {
    "text": "This is actually x here-- because when I take the\nderivative with respect to b.",
    "start": "2070389",
    "end": "2078050"
  },
  {
    "text": "And so now, what I'm left with\nis that the expectation-- so yeah, I'm basically left\nwith nothing that helps.",
    "start": "2078050",
    "end": "2083929"
  },
  {
    "text": "So I'm sorry about. Let's start from the\nbeginning because this is not",
    "start": "2083929",
    "end": "2089929"
  },
  {
    "text": "getting us anywhere, and a\nfix is not going to help. So let's just do it again.",
    "start": "2089929",
    "end": "2095370"
  },
  {
    "text": "Sorry about that. So let's not center anything\nand just do brute force because we're going to--",
    "start": "2095370",
    "end": "2101119"
  },
  {
    "text": "b x squared. All right.",
    "start": "2101120",
    "end": "2107270"
  },
  {
    "text": "Partial, with respect\nto a, is giving equal zero is\nequivalent, so my minus 2 is going to cancel, right.",
    "start": "2107270",
    "end": "2113059"
  },
  {
    "text": "So I'm going to actually\nforget about this. So it's actually telling\nme that the expectation of y minus a plus bx\nis equal to zero, which",
    "start": "2113060",
    "end": "2125660"
  },
  {
    "text": "is equivalent to a plus\nb expectation of x, is",
    "start": "2125660",
    "end": "2131089"
  },
  {
    "text": "equal to the expectation of y. Now, if I take the\nderivative with respect to b and set it equal to\nzero, this is telling me",
    "start": "2131090",
    "end": "2138829"
  },
  {
    "text": "that the expectation of-- well, it's the same thing\nexcept that this time I'm going to pull out an x.",
    "start": "2138830",
    "end": "2145280"
  },
  {
    "start": "2145280",
    "end": "2152470"
  },
  {
    "text": "This guy is equal to zero-- this guy is not here-- and so that implies that\nthe expectation of xy",
    "start": "2152470",
    "end": "2163650"
  },
  {
    "text": "is equal to a times\nthe expectation of x,",
    "start": "2163650",
    "end": "2169559"
  },
  {
    "text": "plus b times the\nexpectation of x square.",
    "start": "2169560",
    "end": "2176726"
  },
  {
    "text": "OK?  All right, so the first one is\nactually not giving me much,",
    "start": "2176726",
    "end": "2186720"
  },
  {
    "text": "so I need to actually work\nwith the two of those guys. So I'm going to take the first-- so let me rewrite those two\ninequalities that I have.",
    "start": "2186720",
    "end": "2193690"
  },
  {
    "text": "I have a plus b, e of\nx is equal to e of y.",
    "start": "2193690",
    "end": "2200829"
  },
  {
    "text": "And then I have e of xy. ",
    "start": "2200830",
    "end": "2210970"
  },
  {
    "text": "OK, and now what I do is\nthat I multiply this guy.",
    "start": "2210970",
    "end": "2221160"
  },
  {
    "text": "So I want to cancel one\nof those things, right? So what I'm going to-- ",
    "start": "2221160",
    "end": "2232197"
  },
  {
    "text": "so I'm going to take\nthis guy, and I'm going to multiply it by e of\nx and take the difference.",
    "start": "2232197",
    "end": "2239030"
  },
  {
    "text": "So I do times e of x, and then\nI take the sum of those two,",
    "start": "2239030",
    "end": "2246330"
  },
  {
    "text": "and then those two terms\nare going to cancel. So then that tells\nme that b times e",
    "start": "2246330",
    "end": "2253550"
  },
  {
    "text": "of x squared, plus the\nexpectation of xy is equal to--",
    "start": "2253550",
    "end": "2265180"
  },
  {
    "text": "so this guy is the\none that cancelled. ",
    "start": "2265180",
    "end": "2273850"
  },
  {
    "text": "Then I get this guy\nhere, expectation of x times the expectation\nof y, plus the guy that",
    "start": "2273850",
    "end": "2282450"
  },
  {
    "text": "remains here-- which is b times the\nexpectation of x square.",
    "start": "2282450",
    "end": "2288752"
  },
  {
    "text": " So here I have b expectation\nof x, the whole thing squared.",
    "start": "2288752",
    "end": "2296220"
  },
  {
    "text": "And here I have b\nexpectation of x square. So if I pull this guy\nhere, what do I get?",
    "start": "2296220",
    "end": "2302440"
  },
  {
    "text": "b times the variance of x, OK? So I'm going to move here.",
    "start": "2302440",
    "end": "2308180"
  },
  {
    "text": "And this guy here, when\nI move this guy here, I get the expectation\nof x times y, minus the expectation of x\ntimes the expectation of y.",
    "start": "2308180",
    "end": "2315590"
  },
  {
    "text": "So this is actually telling me\nthat the covariance of x and y is equal to b times\nthe variance of x.",
    "start": "2315590",
    "end": "2325450"
  },
  {
    "text": "And so then that\ntells me that b is equal to covariance of xy\ndivided by the variance of x.",
    "start": "2325450",
    "end": "2335519"
  },
  {
    "text": "And that's why I actually\nneed the variance of x to be non-zero because\nI couldn't do that otherwise.",
    "start": "2335519",
    "end": "2341690"
  },
  {
    "text": "And because if it\nwas, it would mean that b should be\nplus infinity, which is what the limit of this\nguy is when the variance goes",
    "start": "2341690",
    "end": "2348220"
  },
  {
    "text": "to zero or negative infinity. I can not sort them out.",
    "start": "2348220",
    "end": "2354410"
  },
  {
    "text": "All right, so I'm\nsorry about the mess, but that should be more clear. Then a, of course,\nyou can write it",
    "start": "2354410",
    "end": "2361410"
  },
  {
    "text": "by plugging in the\nvalue of b, so you know it's only a function\nof your distribution, right?",
    "start": "2361410",
    "end": "2367030"
  },
  {
    "text": "So what are the characteristics\nof the distribution-- so distribution can\nhave a bunch of things. It can have movements\nof order 4, of order 26.",
    "start": "2367030",
    "end": "2374330"
  },
  {
    "text": "It can have heavy\ntails or light tails. But when you compute\nleast squares, the only thing that\nmatters are the variance",
    "start": "2374330",
    "end": "2381900"
  },
  {
    "text": "of x, the expectation\nof the individual ones-- and really what captures how\ny changes when you change x,",
    "start": "2381900",
    "end": "2390300"
  },
  {
    "text": "is captured in the covariance. The rest is really\njust normalization. It's just telling you, I want\nthings to cross the y-axis",
    "start": "2390300",
    "end": "2398550"
  },
  {
    "text": "at the right place. I want things to cross the\nx-axis at the right place. But the slope is really captured\nby how much more covariance",
    "start": "2398550",
    "end": "2405720"
  },
  {
    "text": "you have relative to\nthe variance of x. So this is essentially setting\nthe scale for the x-axis,",
    "start": "2405720",
    "end": "2412350"
  },
  {
    "text": "and this is telling\nyou for a unit scale, this is the unit of y\nthat you're changing.",
    "start": "2412350",
    "end": "2420460"
  },
  {
    "text": "OK, so we have explicit forms. And what I could do, if I\nwanted to estimate those things,",
    "start": "2420460",
    "end": "2426300"
  },
  {
    "text": "is just say, well again, we\nhave expectations, right?",
    "start": "2426300",
    "end": "2432510"
  },
  {
    "text": "The expectation of xy minus the\nproduct of the expectations, I could replace\nexpectations by averages",
    "start": "2432510",
    "end": "2438510"
  },
  {
    "text": "and get an empirical\ncovariance just like we can replace the\nexpectations for the variance and get a sample covariance.",
    "start": "2438510",
    "end": "2444720"
  },
  {
    "text": "And this is basically what\nwe're going to be doing. All right, this is\nessentially what you want. The problem is that if\nyou view it that way,",
    "start": "2444720",
    "end": "2451950"
  },
  {
    "text": "you sort of prevent yourself\nfrom being able to solve the multivariate problem. Because it's only in\nthe univariate problem",
    "start": "2451950",
    "end": "2458430"
  },
  {
    "text": "that you have closed form\nsolutions for your problem. But if you actually\ngo to multivariate, this is not where you want\nto replace expectations",
    "start": "2458430",
    "end": "2465510"
  },
  {
    "text": "by averages. You actually want to replace\nexpectation by averages here. ",
    "start": "2465510",
    "end": "2472520"
  },
  {
    "text": "And once you do\nit here, then you can actually just solve\nthe minimisation problem.",
    "start": "2472520",
    "end": "2477920"
  },
  {
    "start": "2477920",
    "end": "2483240"
  },
  {
    "text": "OK, so one thing that\narises from this guy",
    "start": "2483240",
    "end": "2489840"
  },
  {
    "text": "is that this is an\ninteresting formula.",
    "start": "2489840",
    "end": "2495795"
  },
  {
    "text": " All right, think about it.",
    "start": "2495795",
    "end": "2503740"
  },
  {
    "text": "If I have that y is a\nplus bx plus some noise.",
    "start": "2503740",
    "end": "2520190"
  },
  {
    "text": "Things are no\nlonger on something. I have that y is equal to\na bx plus some noise, which",
    "start": "2520190",
    "end": "2528470"
  },
  {
    "text": "is usually denoted by epsilon. So that's the\ndistribution, right? If I tell you the\ndistribution of x, and I",
    "start": "2528470",
    "end": "2535760"
  },
  {
    "text": "say y is a plus b epsilon-- I tell you the\ndistribution of y, and if [? they mean ?] that\nthose two are independent,",
    "start": "2535760",
    "end": "2541190"
  },
  {
    "text": "you have a distribution on y. So what happens is that I can\nactually always say-- well, you",
    "start": "2541190",
    "end": "2547364"
  },
  {
    "text": "know, this is\nequivalent to saying that epsilon is equal to\ny minus a plus bx, right?",
    "start": "2547364",
    "end": "2555560"
  },
  {
    "text": "I can always write\nthis as just-- I mean, as tautology. But here, for those guys--",
    "start": "2555560",
    "end": "2562069"
  },
  {
    "text": "this is not for any guy, right. This is really for\nthe best fit, a and b, those ones that\nsatisfy this gradient is",
    "start": "2562069",
    "end": "2570170"
  },
  {
    "text": "equal to zero thing. Then what we had is that\nthe expectation of epsilon",
    "start": "2570170",
    "end": "2575330"
  },
  {
    "text": "was equal to expectation\nof y minus a plus b expectation of x by linearity\nof the expectation, which",
    "start": "2575330",
    "end": "2583430"
  },
  {
    "text": "was equal to zero. So for this best\nfit we have zero.",
    "start": "2583430",
    "end": "2590180"
  },
  {
    "text": "Now, the covariance\nbetween x and y-- ",
    "start": "2590180",
    "end": "2597190"
  },
  {
    "text": "Between, sorry, x\nand epsilon, is what? Well, it's the\ncovariance between x--",
    "start": "2597190",
    "end": "2603420"
  },
  {
    "text": "and well, epsilon was\ny minus a plus bx. ",
    "start": "2603420",
    "end": "2610100"
  },
  {
    "text": "Now, the covariance is\nbilinear, so what I have is that the\ncovariance of this is",
    "start": "2610100",
    "end": "2615640"
  },
  {
    "text": "the covariance of xn times y-- sorry, of x and y, minus\nthe variance-- well,",
    "start": "2615640",
    "end": "2621790"
  },
  {
    "text": "minus a plus b,\ncovariance of x and x,",
    "start": "2621790",
    "end": "2630220"
  },
  {
    "text": "which is the variance of x? ",
    "start": "2630220",
    "end": "2639050"
  },
  {
    "text": "Covariance of xy minus\na plus b variance of x. ",
    "start": "2639050",
    "end": "2652384"
  },
  {
    "text": "OK, I didn't write it. So here I have\ncovariance of xy is equal to b variance of x, right?",
    "start": "2652384",
    "end": "2657910"
  },
  {
    "start": "2657910",
    "end": "2674069"
  },
  {
    "text": "Covariance of xy. Yeah, that's because they cannot\ndo that with the covariance. ",
    "start": "2674070",
    "end": "2684029"
  },
  {
    "text": "Yeah, I have those\naverages again. No, because this\nis centered, right? Sorry, this is centered,\nso this is actually",
    "start": "2684030",
    "end": "2691000"
  },
  {
    "text": "equal to the expectation of\nx times y minus a plus bx.",
    "start": "2691000",
    "end": "2696760"
  },
  {
    "text": " The covariance is\nequal to the product",
    "start": "2696760",
    "end": "2703110"
  },
  {
    "text": "just because this insight\nis actually centered. So this is the\nexpectation of x times y",
    "start": "2703110",
    "end": "2709980"
  },
  {
    "text": "minus the expectation of a times\nthe expectation of x, plus b",
    "start": "2709980",
    "end": "2720100"
  },
  {
    "text": "minus b times the\nexpectation of x squared. ",
    "start": "2720100",
    "end": "2732200"
  },
  {
    "text": "Well, actually maybe I\nshould not really go too far. ",
    "start": "2732200",
    "end": "2738894"
  },
  {
    "text": "So this is actually\nthe one that I need. But if I stop here, this is\nactually equal to zero, right.",
    "start": "2738894",
    "end": "2747300"
  },
  {
    "text": "Those are the same equations.  OK?",
    "start": "2747300",
    "end": "2753050"
  },
  {
    "text": "Yeah? AUDIENCE: What are\nwe doing right now? PHILIPPE RIGOLLET:\nSo we're just saying that if I actually believe that\nthis best fit was the one that",
    "start": "2753050",
    "end": "2761069"
  },
  {
    "text": "gave me the right\nparameters, what would that imply on the noise\nitself, on this epsilon? So here we're\nactually just trying",
    "start": "2761070",
    "end": "2767220"
  },
  {
    "text": "to find some necessary condition\nfor the noise to hold-- for the noise. And so those conditions are,\nthat first, the expectation",
    "start": "2767220",
    "end": "2774540"
  },
  {
    "text": "is zero. That's what we've got here. And then, that the covariance\nbetween the noise and x",
    "start": "2774540",
    "end": "2780480"
  },
  {
    "text": "has to be zero as well. OK, so those are\nactually conditions that the noise must satisfy.",
    "start": "2780480",
    "end": "2786360"
  },
  {
    "text": "But the noise was just not\nreally defined as noise itself. We were just\nsaying, OK, if we're",
    "start": "2786360",
    "end": "2791550"
  },
  {
    "text": "going to put some assumptions\non the epsilon, what do we better have? So the first one is that\nit's centered, which is good,",
    "start": "2791550",
    "end": "2798360"
  },
  {
    "text": "because otherwise, the noise\nwould shift everything. So now when you look at a\nlinear regression model--",
    "start": "2798360",
    "end": "2805619"
  },
  {
    "text": "typically, if you open a book,\nit doesn't start by saying, let the noise be the\ndifference between y",
    "start": "2805620",
    "end": "2810920"
  },
  {
    "text": "and what I actually\nwant y to be. It says let y be a\nplus bx plus epsilon.",
    "start": "2810920",
    "end": "2817210"
  },
  {
    "text": "So conversely, if we assume that\nthis is the model that we have, then we're going to have\nto assume that epsilon--",
    "start": "2817210",
    "end": "2824340"
  },
  {
    "text": "we're going to assume\nthat epsilon is centered, and that the covariance\nbetween x and epsilon is zero.",
    "start": "2824340",
    "end": "2830840"
  },
  {
    "text": "Actually, often, we're\ngoing to assume much more. And one way to ensure that\nthose two things are satisfied",
    "start": "2830840",
    "end": "2837600"
  },
  {
    "text": "is to assume that x is\nindependent of epsilon, for example. If you assume that x is\nindependent of epsilon,",
    "start": "2837600",
    "end": "2843940"
  },
  {
    "text": "of course the covariance\nis going to be zero. Or we might assume that\nthe conditional expectation",
    "start": "2843940",
    "end": "2850720"
  },
  {
    "text": "of epsilon, given x, is equal\nto zero, then that implies that. OK, now the fact that it's\ncentered is one thing.",
    "start": "2850720",
    "end": "2858710"
  },
  {
    "text": "So if we make this assumption,\nthe only thing it's telling us is that those ab's that come--\nright, we started from there.",
    "start": "2858710",
    "end": "2867700"
  },
  {
    "text": "y is equal to a plus bx plus\nsome epsilon for some a, for some b. What it turns out is that\nthose a's and b's are actually",
    "start": "2867700",
    "end": "2875890"
  },
  {
    "text": "the ones that you would get\nby solving this expectation of square thing. All right, so when you asked--",
    "start": "2875890",
    "end": "2882609"
  },
  {
    "text": "back when you were following-- so when you asked,\nyou know, why don't we take the square, for\nexample, or the power",
    "start": "2882610",
    "end": "2890290"
  },
  {
    "text": "4, or something like this-- then here, I'm saying, well, if\nI have y is equal to a plus bx,",
    "start": "2890290",
    "end": "2895990"
  },
  {
    "text": "I don't actually need to put\ntoo much assumptions on epsilon. If epsilon is actually\nsatisfying those two things,",
    "start": "2895990",
    "end": "2902320"
  },
  {
    "text": "expectation is equal to\nzero and the covariance with x is equal to zero,\nthen the right a and b",
    "start": "2902320",
    "end": "2908912"
  },
  {
    "text": "that I'm looking for are\nactually the ones that come with the square-- not with power 4 or power 25.",
    "start": "2908912",
    "end": "2916750"
  },
  {
    "text": "So those are actually\npretty weak assumptions. If we want to do\ninference, we're going to have to\nassume slightly more.",
    "start": "2916750",
    "end": "2923350"
  },
  {
    "text": "If we want to use\nT-distributions at some point, for example, and we\nwill, we're going to have to assume that epsilon\nhas a Gaussian distribution.",
    "start": "2923350",
    "end": "2930800"
  },
  {
    "text": "So if you want to start doing\nmore statistics beyond just like doing this least square\nthing, which is minimizing",
    "start": "2930800",
    "end": "2936550"
  },
  {
    "text": "the square of criterion,\nyou're actually going to have to put\nmore assumptions. But right now, we\ndid not need them.",
    "start": "2936550",
    "end": "2941710"
  },
  {
    "text": "We only need that epsilon\nas mean zero and covariant zero with x. ",
    "start": "2941710",
    "end": "2948750"
  },
  {
    "text": "OK, so that was basically\nprobabilistic, right. If I were to do\nprobability and I",
    "start": "2948750",
    "end": "2954450"
  },
  {
    "text": "were trying to model the\nrelationship between two random variables, x\nand y, in the form",
    "start": "2954450",
    "end": "2960330"
  },
  {
    "text": "y is a plus bx plus some noise,\nthis is what would come out. Everything was expectations.",
    "start": "2960330",
    "end": "2965640"
  },
  {
    "text": "There was no data involved. So now let's go to the\ndata problem, which is now,",
    "start": "2965640",
    "end": "2973620"
  },
  {
    "text": "I do not know what\nthose expectations are. In particular, I don't know what\nthe covariance of x and y is, and I don't know with\nthe expectation of x",
    "start": "2973620",
    "end": "2980610"
  },
  {
    "text": "and the expectation of y r. So I have data to do that. So how am I going to do this?",
    "start": "2980610",
    "end": "2985880"
  },
  {
    "text": " Well, I'm just\ngoing to say, well, if I want x1, y1,\nxn, yn, and I'm going",
    "start": "2985880",
    "end": "2997569"
  },
  {
    "text": "to assume that\nthey're [? iid. ?] And I'm actually going\nto assume that they have some model, right.",
    "start": "2997570",
    "end": "3002820"
  },
  {
    "text": "So I'm going to assume\nthat I have that a-- so that Yi follows\nthe same model.",
    "start": "3002820",
    "end": "3009150"
  },
  {
    "start": "3009150",
    "end": "3014619"
  },
  {
    "text": "So epsilon i\n[? rad, ?] and I won't say that expectation of epsilon\ni is zero and covariance of xi,",
    "start": "3014620",
    "end": "3023610"
  },
  {
    "text": "epsilon i is equal to zero. So I'm going to put the\nsame model on all the data.",
    "start": "3023610",
    "end": "3028880"
  },
  {
    "text": "So you can see that a is\nnot ai, and b is not bi. It's the same. So as my data\nincreases, I should",
    "start": "3028880",
    "end": "3034089"
  },
  {
    "text": "be able to recover\nthe correct things-- as the size of my\ndata increases.",
    "start": "3034090",
    "end": "3039430"
  },
  {
    "text": "OK, so this is what the\nstatistical problem look like. You're given the points.",
    "start": "3039430",
    "end": "3045250"
  },
  {
    "text": "There is a true line\nfrom which this point was generated, right. There was this line. There was a true ab that\nI use to draw this plot,",
    "start": "3045250",
    "end": "3054250"
  },
  {
    "text": "and that was the line. So first I picked an\nx, say uniformly at",
    "start": "3054250",
    "end": "3059319"
  },
  {
    "text": "on this intervals, 0 to 2. I said that was this one. Then I said well, I\nwant y to be a plus bx,",
    "start": "3059320",
    "end": "3066800"
  },
  {
    "text": "so it should be\nhere, but then I'm going to add some noise\nepsilon to go away again back from this line.",
    "start": "3066800",
    "end": "3073270"
  },
  {
    "text": "And that's actually me, here, we\nactually got two points correct on this line. So there's basically\ntwo epsilons",
    "start": "3073270",
    "end": "3080170"
  },
  {
    "text": "that were small enough\nthat the dots actually look like they're on the line. Everybody's clear\nabout what I'm drawing?",
    "start": "3080170",
    "end": "3087060"
  },
  {
    "text": "So now of course if\nyou're a statistician, you don't see this. You only see this. And you have to\nrecover this guy,",
    "start": "3087060",
    "end": "3092610"
  },
  {
    "text": "and it's going to\nlook like this. You're going to have an\nestimated line, which is the red one.",
    "start": "3092610",
    "end": "3097780"
  },
  {
    "text": "And the blue line, which is\nthe true one, the one that actually generated the data.",
    "start": "3097780",
    "end": "3104230"
  },
  {
    "text": "And your question is,\nwhile this line corresponds to some parameters\na hat and b hat, how could I make sure that those\ntwo lines-- how far those two",
    "start": "3104230",
    "end": "3111550"
  },
  {
    "text": "lines are? And one to address\nthis question is to say how far is a from a hat,\nand how far is b from b hat?",
    "start": "3111550",
    "end": "3117920"
  },
  {
    "text": "OK? Another question, of\ncourse, that you may ask is, how do you find\na hat and b hat?",
    "start": "3117920",
    "end": "3124470"
  },
  {
    "text": "And as you can see, it's\nbasically the same thing. Remember, what was a-- so b\nwas the covariance between x",
    "start": "3124470",
    "end": "3135210"
  },
  {
    "text": "and y divided by the\nvariance of x, right?",
    "start": "3135210",
    "end": "3141240"
  },
  {
    "text": "We check and rewrite this. The expectation of\nxy minus expectation",
    "start": "3141240",
    "end": "3146430"
  },
  {
    "text": "of x times the\nexpectation of y, divided by expectation of x squared\nminus expectation of x.",
    "start": "3146430",
    "end": "3155580"
  },
  {
    "text": "The whole thing's-- OK? If you look at the\nexpression for b hat,",
    "start": "3155580",
    "end": "3162910"
  },
  {
    "text": "I basically replaced all\nthe expectations by bars. So I said, well,\nthis guy I'm going",
    "start": "3162910",
    "end": "3169799"
  },
  {
    "text": "to estimate by an average. So that's the xy\nbar, and is 1 over n,",
    "start": "3169800",
    "end": "3179970"
  },
  {
    "text": "[? sum ?] from [? i co ?]\n1, to n of Xi, times Yi. ",
    "start": "3179970",
    "end": "3185555"
  },
  {
    "text": "x bar, of course, is just\nthe one that we're used to. ",
    "start": "3185555",
    "end": "3192690"
  },
  {
    "text": "And same for y bar. X squared bar, the\none that's here,",
    "start": "3192690",
    "end": "3200580"
  },
  {
    "text": "is the average of the squares. And x bar square is the\nsquare of the average. ",
    "start": "3200580",
    "end": "3219510"
  },
  {
    "text": "OK, so you just basically\nreplace this guy by x bar, this guy by y bar, this\nguy by x square bar,",
    "start": "3219510",
    "end": "3227820"
  },
  {
    "text": "and this guy by x\nbar and no square. OK, so that's basically\none way to do it.",
    "start": "3227820",
    "end": "3234810"
  },
  {
    "text": "Everywhere you see\nan expectation, you replace it by an average. That's the usual\nstatistical hammer.",
    "start": "3234810",
    "end": "3242070"
  },
  {
    "text": "You can actually be slightly\nmore subtle about this. ",
    "start": "3242070",
    "end": "3249980"
  },
  {
    "text": "And as an exercise,\nI invite you-- just to make sure that you know\nhow to do this competition, it's going to be exactly the\nsame kind of competitions",
    "start": "3249980",
    "end": "3257400"
  },
  {
    "text": "that we've done. But as an exercise,\nyou can check that if you actually\nlook at say, well,",
    "start": "3257400",
    "end": "3263311"
  },
  {
    "text": "what I wanted to minimize here,\nI had an expectation, right? ",
    "start": "3263311",
    "end": "3272720"
  },
  {
    "text": "And I said, let's\nminimize this thing. Well, let's replace this\nby an average first.",
    "start": "3272720",
    "end": "3281799"
  },
  {
    "start": "3281800",
    "end": "3291630"
  },
  {
    "text": "And now minimize. OK, so if I do\nthis, it turns out",
    "start": "3291630",
    "end": "3297100"
  },
  {
    "text": "I'm going to actually\nget the same result. The minimum of the\naverage is basically--",
    "start": "3297100",
    "end": "3303940"
  },
  {
    "text": "when I replace the\naverage by-- sorry, when I replace the\nexpectation by the average",
    "start": "3303940",
    "end": "3309039"
  },
  {
    "text": "and then minimize,\nit's the same thing as first minimizing and\nthen replacing expectation by averages in this case.",
    "start": "3309040",
    "end": "3317510"
  },
  {
    "text": "Again, this is a much\nmore general principle because if you\ndon't have a closed",
    "start": "3317510",
    "end": "3323180"
  },
  {
    "text": "form for the minimum like for\nsome, say, likelihood problems, well, you might not\nactually have a possibility",
    "start": "3323180",
    "end": "3330579"
  },
  {
    "text": "to just look at what the\nformula looks like-- see where the expectations show up-- and\nthen just plug in the averages instead.",
    "start": "3330579",
    "end": "3336380"
  },
  {
    "text": "So this is the one you\nwant to keep in mind. And again, as an exercise. ",
    "start": "3336380",
    "end": "3347000"
  },
  {
    "text": "OK, so here, and then\nyou do expectation replaced by averages.",
    "start": "3347000",
    "end": "3352980"
  },
  {
    "text": "And then that's the same\nanswer, and I encourage you to solve the exercise.",
    "start": "3352980",
    "end": "3360080"
  },
  {
    "text": "OK, everybody's clear that this\nis actually the same expression for a hat and b hat that we had\nbefore that we had for a and b",
    "start": "3360080",
    "end": "3367140"
  },
  {
    "text": "when we replaced the\nexpectations by averages?",
    "start": "3367140",
    "end": "3372460"
  },
  {
    "text": "Here, by the way, I minimize\nthe sum rather than the average. It's clear to everyone that\nthis is the same thing, right?",
    "start": "3372460",
    "end": "3379708"
  },
  {
    "text": " Yep? AUDIENCE: [INAUDIBLE] sum\nreplacing it [INAUDIBLE]",
    "start": "3379708",
    "end": "3387148"
  },
  {
    "text": "minimize the\nexpectation, I'm assuming it's switched with\nthe derivative on the expectation [INAUDIBLE].",
    "start": "3387148",
    "end": "3393596"
  },
  {
    "text": " PHILIPPE RIGOLLET:\nSo we did switch",
    "start": "3393596",
    "end": "3399050"
  },
  {
    "text": "the derivative and the\nexpectation before you came, I think.",
    "start": "3399050",
    "end": "3404140"
  },
  {
    "text": " All right, so\nindeed, the picture",
    "start": "3404140",
    "end": "3409809"
  },
  {
    "text": "was the one that we\nsaid, so visually, this is what we're doing. We're looking among\nall the lines.",
    "start": "3409810",
    "end": "3415779"
  },
  {
    "text": "For each line, we\ncompute this distance. So if I give you\nanother line there would be another set of arrows.",
    "start": "3415780",
    "end": "3421759"
  },
  {
    "text": "You look at their length. You square it. And then you sum it\nall, and you find the line that has the minimum\nsum of squared lengths",
    "start": "3421759",
    "end": "3428080"
  },
  {
    "text": "of the arrows. All right, and those are the\narrows that we're looking at. But again, you could actually\nthink of other distances,",
    "start": "3428080",
    "end": "3434710"
  },
  {
    "text": "and you would actually\nget different-- you could actually get\ndifferent solutions, right. So there's something called,\nmean absolute deviation,",
    "start": "3434710",
    "end": "3442643"
  },
  {
    "text": "which rather than\nminimizing this thing, is actually minimizing the\nsum from i to co 1 to n of the absolute value\nof y minus a plus bXi.",
    "start": "3442644",
    "end": "3453970"
  },
  {
    "text": "And that's not\nsomething for which you're going to have a closed\nform, as you can imagine.",
    "start": "3453970",
    "end": "3459190"
  },
  {
    "text": "You might have something\nthat's sort of implicit, but you can actually still\nsolve it numerically.",
    "start": "3459190",
    "end": "3464647"
  },
  {
    "text": "And this is something\nthat people also like to use but way, way less\nthan the least squares one.",
    "start": "3464647",
    "end": "3470478"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET:\nWhat did I just what? AUDIENCE: [INAUDIBLE]",
    "start": "3470478",
    "end": "3476600"
  },
  {
    "text": "The sum of the absolute\nvalues of Yi minus a plus bXi.",
    "start": "3476600",
    "end": "3482230"
  },
  {
    "text": "So it's the same except\nI don't square here. ",
    "start": "3482230",
    "end": "3487819"
  },
  {
    "text": "OK?  So arguably, you know,\npredicting a demand",
    "start": "3487820",
    "end": "3498330"
  },
  {
    "text": "based on price is a\nfairly naive problem. Typically, what we\nhave is a bunch of data",
    "start": "3498330",
    "end": "3503787"
  },
  {
    "text": "that we've collected,\nand we're hoping that, together, they can help\nus do a better prediction.",
    "start": "3503787",
    "end": "3509460"
  },
  {
    "text": "All right, so maybe I\ndon't have only the price, but maybe I have a bunch\nof other social indicators.",
    "start": "3509460",
    "end": "3515670"
  },
  {
    "text": "Maybe I know the competition,\nthe price of the competition. And maybe I know a\nbunch of other things",
    "start": "3515670",
    "end": "3522150"
  },
  {
    "text": "that are actually relevant. And so I'm trying to find a way\nto combine a bunch of points,",
    "start": "3522150",
    "end": "3528030"
  },
  {
    "text": "a bunch of measures. There's a nice\nexample that I like, which is people were\ntrying to measure something",
    "start": "3528030",
    "end": "3536370"
  },
  {
    "text": "related to your body\nmass index, so basically the volume of your-- the\ndensity of your body.",
    "start": "3536370",
    "end": "3544820"
  },
  {
    "text": "And the way you can do\nthis is by just, really, weighing someone and\nalso putting them",
    "start": "3544820",
    "end": "3550170"
  },
  {
    "text": "in some cubic meter of water\nand see how much overflows. And then you have\nboth the volume",
    "start": "3550170",
    "end": "3555750"
  },
  {
    "text": "and the mass of\nthis person, and you",
    "start": "3555750",
    "end": "3560850"
  },
  {
    "text": "can start computing density. But as you can\nimagine, you know,",
    "start": "3560850",
    "end": "3565860"
  },
  {
    "text": "I would not personally\nlike to go to a gym when the first thing\nthey ask me is to just go in a bucket of\nwater, and so people",
    "start": "3565860",
    "end": "3573240"
  },
  {
    "text": "try to find ways to measure this\nbased on other indicators that are much easier to measure. For example, I don't know,\nthe length of my forearm,",
    "start": "3573240",
    "end": "3581040"
  },
  {
    "text": "and the circumference of\nmy head, and maybe my belly would probably be\nmore appropriate here.",
    "start": "3581040",
    "end": "3586870"
  },
  {
    "text": "And so you know, they\njust try to find something that actually makes sense. And so there's\nactually a nice example",
    "start": "3586870",
    "end": "3592094"
  },
  {
    "text": "where you can show\nthat if you measure-- I think one of the\nmost significant was with the circumference\nof your wrist. This is actually a very good\nindicator of your body density.",
    "start": "3592094",
    "end": "3602070"
  },
  {
    "text": "And it turns out that if you\nstuff all the bunch of things together, you might actually\nget a very good formula that",
    "start": "3602070",
    "end": "3609240"
  },
  {
    "text": "explains things. All right, so what\nwe're going to do is rather than saying\nwe have only one x",
    "start": "3609240",
    "end": "3614406"
  },
  {
    "text": "to explain y's,\nlet's say we have 20 x's that we're trying\nto combine to explain y.",
    "start": "3614406",
    "end": "3619510"
  },
  {
    "text": "And again, just like assuming\nsomething of the form, y is a plus b times x was the\nsimplest thing we could do,",
    "start": "3619510",
    "end": "3626107"
  },
  {
    "text": "here we're just going to\nassume that we have y is a plus b1, x1 plus b2, x2, plus b3, x3.",
    "start": "3626107",
    "end": "3631650"
  },
  {
    "text": "And we can write\nit in a vector form by writing that Yi is\nXi transposed b, which",
    "start": "3631650",
    "end": "3639210"
  },
  {
    "text": "is now a vector plus epsilon i. OK, and here, on\nthe board, I'm going",
    "start": "3639210",
    "end": "3644520"
  },
  {
    "text": "to have a hard time\ndoing boldface, but all these things are\nvectors except for y,",
    "start": "3644520",
    "end": "3652359"
  },
  {
    "text": "which is a number. Yi is a number. It's always the\nvalue of my y-axis.",
    "start": "3652360",
    "end": "3657780"
  },
  {
    "text": "So even if my x-axis lives on-- this is x1, and this is x2, y\nis really just the real valued",
    "start": "3657780",
    "end": "3664349"
  },
  {
    "text": "function. And so I'm going to get\na bunch of points, x1,y1, and I'm going to see\nhow much they respond.",
    "start": "3664350",
    "end": "3670380"
  },
  {
    "text": "So for example, my\nbody density is y, and then all the x's are\na bunch of other things.",
    "start": "3670380",
    "end": "3676562"
  },
  {
    "text": "Agreed with that? So this is an equation that\nholds on the real line, but this guy here is an r\np, and this guy's an rp.",
    "start": "3676562",
    "end": "3687390"
  },
  {
    "text": " It's actually common to\ntalk to call b, beta,",
    "start": "3687390",
    "end": "3693550"
  },
  {
    "text": "when it's a vector, and that's\nthe usual linear regression",
    "start": "3693550",
    "end": "3698650"
  },
  {
    "text": "notation. Y is x beta plus epsilon. So x's are called\nexplanatory variables.",
    "start": "3698650",
    "end": "3705780"
  },
  {
    "text": "y is called explained variable,\nor dependent variable, or response variable.",
    "start": "3705780",
    "end": "3712000"
  },
  {
    "text": "It has a bunch of names. You can use whatever you\nfeel more comfortable with. It should actually\nbe explicit, right,",
    "start": "3712000",
    "end": "3717460"
  },
  {
    "text": "so that's all you care about.  Now, what we typically do\nis that rather-- so you",
    "start": "3717460",
    "end": "3725840"
  },
  {
    "text": "notice here, that there's\nactually no intercept. If I actually fold that\nback down to one dimension, there's actually a is\nequal to zero, right?",
    "start": "3725840",
    "end": "3733210"
  },
  {
    "text": "If I go back to p\nis equal to 1, that",
    "start": "3733210",
    "end": "3738349"
  },
  {
    "text": "would imply that Yi is,\nwell, say, beta times x plus epsilon i.",
    "start": "3738350",
    "end": "3744979"
  },
  {
    "text": "And that's not good, I\nwant to have an intercept. And the way I do this,\nrather than writing a plus this, and\nyou know, just have",
    "start": "3744979",
    "end": "3751910"
  },
  {
    "text": "like an overload of notation,\nwhat I am actually doing is that I fold back.",
    "start": "3751910",
    "end": "3757670"
  },
  {
    "text": "I fold my intercept\nback into my x. ",
    "start": "3757670",
    "end": "3763460"
  },
  {
    "text": "And so if I measure\n20 variables, I'm going to create a\n21st variable, which is always equal to 1.",
    "start": "3763460",
    "end": "3769700"
  },
  {
    "text": "OK, so you should need\nto think of x as being 1. And then x1 xp.",
    "start": "3769700",
    "end": "3778119"
  },
  {
    "text": "And sorry, xp minus 1, I guess. OK, and now this is an rp. ",
    "start": "3778120",
    "end": "3785590"
  },
  {
    "text": "I'm always going to assume\nthat the first one is 1. I can always do that. If I have a table of data--",
    "start": "3785590",
    "end": "3791320"
  },
  {
    "text": "if my data is given to me\nin an Excel spreadsheet-- and here I have the density\nthat I measured on my data,",
    "start": "3791320",
    "end": "3799990"
  },
  {
    "text": "and then maybe here\nI have the height, and here I have the\nwrist circumference.",
    "start": "3799990",
    "end": "3805544"
  },
  {
    "text": "And I have all these things. All I have to do is to create\nanother column here of ones,",
    "start": "3805544",
    "end": "3811099"
  },
  {
    "text": "and I just put 1-1-1-1-1. OK, that's all I have to\ndo to create this guy.",
    "start": "3811100",
    "end": "3817089"
  },
  {
    "text": "Agreed? And now my x is going to\nbe just one of those rows.",
    "start": "3817090",
    "end": "3823940"
  },
  {
    "text": "So that's this is\nXi, this entire row. And this entry here is Yi. ",
    "start": "3823940",
    "end": "3834430"
  },
  {
    "text": "So now, for my\nnoise coefficients, I'm still going to\nask for the same thing except that here, the\ncovariance is not between x--",
    "start": "3834430",
    "end": "3844090"
  },
  {
    "text": "between one random variable\nand another random variable. It's between a random vector\nand a random variable.",
    "start": "3844090",
    "end": "3850930"
  },
  {
    "text": "OK, how do I measure the\ncovariance between a vector and a random variable? ",
    "start": "3850930",
    "end": "3863866"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET:\nYeah, so basically--",
    "start": "3863866",
    "end": "3869002"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PHILIPPE RIGOLLET: Yeah, I\nmean, the covariance vector is equal to 0 is the same thing\nas [INAUDIBLE] equal to zero,",
    "start": "3869002",
    "end": "3876171"
  },
  {
    "text": "but yeah, this is basically\nthought of entry-wise. For each coordinate of x,\nI want that the covariance",
    "start": "3876171",
    "end": "3881820"
  },
  {
    "text": "between epsilon and this\ncoordinate of x is equal to 0.",
    "start": "3881820",
    "end": "3887430"
  },
  {
    "text": "So I'm just asking this\nfor all coordinates. Again, in most\ninstances, we're going to think that epsilon\nis independent",
    "start": "3887430",
    "end": "3893520"
  },
  {
    "text": "of x, and that's something we\ncan understand without thinking about coordinates.",
    "start": "3893520",
    "end": "3899022"
  },
  {
    "text": "Yep? AUDIENCE: [INAUDIBLE] like\nwhat if beta equals alpha [INAUDIBLE]?",
    "start": "3899022",
    "end": "3904818"
  },
  {
    "text": " PHILIPPE RIGOLLET: I'm sorry,\ncan you repeat the question? I didn't hear. AUDIENCE: Is this the\nparameter of beta, a parameter?",
    "start": "3904818",
    "end": "3912140"
  },
  {
    "text": "PHILIPPE RIGOLLET: Yeah,\nbeta is the parameter we're looking for, right. Just like it was the pair ab has\nbecome the whole vector of beta",
    "start": "3912140",
    "end": "3918485"
  },
  {
    "text": "now. AUDIENCE: And\nwhat's [INAUDIBLE]??  PHILIPPE RIGOLLET: Well, can\nyou think of an intercept",
    "start": "3918485",
    "end": "3925219"
  },
  {
    "text": "of a function that take-- I mean, there is one actually. There's the one\nfor which betas--",
    "start": "3925219",
    "end": "3930369"
  },
  {
    "text": "all the betas that\ndon't correspond to the vector of all\nones, so the intercept is really the weight\nthat I put on this guy.",
    "start": "3930370",
    "end": "3938469"
  },
  {
    "text": "That's the beta that's\ngoing to come to this guy, but we don't really\ntalk about intercept.",
    "start": "3938469",
    "end": "3944310"
  },
  {
    "text": "So if x lives in two\ndimensions, the way you want to think\nabout this is you",
    "start": "3944310",
    "end": "3950950"
  },
  {
    "text": "take a sheet of paper\nlike that, so now I have points that live\nin three dimensions.",
    "start": "3950950",
    "end": "3957079"
  },
  {
    "text": "So let's say one\ndirection here is x1. This direction is x2,\nand this direction is y.",
    "start": "3957080",
    "end": "3962710"
  },
  {
    "text": "And so what's going\nto happen is that I'm going to have my points\nthat live in this three dimensional space.",
    "start": "3962710",
    "end": "3968710"
  },
  {
    "text": "And what I'm trying\nto do when I'm trying to do a linear\nmodel for those guys-- when I assume a linear model.",
    "start": "3968710",
    "end": "3973990"
  },
  {
    "text": "What I assume is that there's\na plane in those three dimensions. So think of this guy\nas going everywhere,",
    "start": "3973990",
    "end": "3980170"
  },
  {
    "text": "and there's a plane close to\nwhich all my points should be. That's what's happening\nin two dimensional.",
    "start": "3980170",
    "end": "3986319"
  },
  {
    "text": "If you see higher dimensions\nthen congratulations to you, but I can't. ",
    "start": "3986320",
    "end": "3993530"
  },
  {
    "text": "But you know, you can definitely\nformalize that fairly easily mathematically and just\ntalk about vectors. ",
    "start": "3993530",
    "end": "4000940"
  },
  {
    "text": "So now here, if I talk about the\nleast square error estimator, or just the least squares\nestimator of beta,",
    "start": "4000940",
    "end": "4007470"
  },
  {
    "text": "it's simply the same\nthing as before. Just like we said-- so remember, you\nshould think of as beta",
    "start": "4007470",
    "end": "4016750"
  },
  {
    "text": "as being both the\npair a b generalized. So we said, oh, we wanted to\nminimize the expectation of y",
    "start": "4016750",
    "end": "4025059"
  },
  {
    "text": "minus a plus bx squared, right?",
    "start": "4025060",
    "end": "4033640"
  },
  {
    "text": "Now, so that's in--\nfor p is equal to 1. Now for p lower\nthan or equal to 2,",
    "start": "4033640",
    "end": "4039510"
  },
  {
    "text": "we're just going to write it\nas y minus x transpose beta",
    "start": "4039510",
    "end": "4048760"
  },
  {
    "text": "squared. ",
    "start": "4048760",
    "end": "4054210"
  },
  {
    "text": "OK, so I'm just trying to\nminimize this quantity. Of course, I don't\nhave access to this,",
    "start": "4054210",
    "end": "4060857"
  },
  {
    "text": "so what I'm going to do\nwith them going to replace my expectation by an average. ",
    "start": "4060857",
    "end": "4071010"
  },
  {
    "text": "So here I'm using the notation\nt because beta is the true one, and I don't want you to just--",
    "start": "4071010",
    "end": "4076960"
  },
  {
    "text": "so here, I have a variable\nt that's just moving around. And so now I'm going to take\nthe square of this thing.",
    "start": "4076960",
    "end": "4082390"
  },
  {
    "text": "And when I minimize this over\nall t in rp, the arc min,",
    "start": "4082390",
    "end": "4088450"
  },
  {
    "text": "the minimum is attained at beta\nhat, which is my estimator.",
    "start": "4088450",
    "end": "4099584"
  },
  {
    "text": "OK? ",
    "start": "4099584",
    "end": "4105359"
  },
  {
    "text": "So if I want to\nactually compute-- yeah? AUDIENCE: I'm sorry,\non the last slide",
    "start": "4105359",
    "end": "4111420"
  },
  {
    "text": "did we require the expectation\nof [INAUDIBLE] to be zero?",
    "start": "4111420",
    "end": "4116422"
  },
  {
    "text": "PHILIPPE RIGOLLET: You\nmean the previous slide? AUDIENCE: Yes. [INAUDIBLE] PHILIPPE RIGOLLET: So again,\nI'm just defining an estimator",
    "start": "4116422",
    "end": "4122720"
  },
  {
    "text": "just like I would tell you,\njust take the estimator that has coordinates for everywhere. AUDIENCE: So I'm saying like\n[? in that sign, ?] we'll say",
    "start": "4122720",
    "end": "4128984"
  },
  {
    "text": "the noise [? terms ?] we want to\nsatisfy the covariance of that [? side. ?] We also want them\nto satisfy expectation of each",
    "start": "4128984",
    "end": "4135830"
  },
  {
    "text": "[? noise turn ?] zero? ",
    "start": "4135830",
    "end": "4147827"
  },
  {
    "text": "PHILIPPE RIGOLLET: And\nso the answer is yes. I was just trying to think\nif this was captured.",
    "start": "4147827",
    "end": "4153049"
  },
  {
    "text": "So it is not\ncaptured in this guy because this is just telling\nme that the expectation of epsilon i minus expectation\nof some i is equal to zero.",
    "start": "4153050",
    "end": "4163750"
  },
  {
    "text": "OK, so yes I need to have\nthat epsilon has mean zero-- let's assume that\nexpectation of epsilon",
    "start": "4163750",
    "end": "4169130"
  },
  {
    "text": "is zero for this problem. ",
    "start": "4169130",
    "end": "4183640"
  },
  {
    "text": "And we're going\nto need something about some sort of question\nabout the variance being not equal to zero, right, but\nthis is going to come up later.",
    "start": "4183640",
    "end": "4191060"
  },
  {
    "text": "So let's think for one second\nabout doing the same approach as we did before. Take the partial\nderivative with respect",
    "start": "4191060",
    "end": "4197320"
  },
  {
    "text": "to the first coordinate\nof t, with respect to the second coordinate\nof t, with respect to the third coordinate\nof t, et cetera.",
    "start": "4197320",
    "end": "4203320"
  },
  {
    "text": "So that's what we did before. We had two equations,\nand we reconciled them because it was fairly\neasy to solve, right?",
    "start": "4203320",
    "end": "4210190"
  },
  {
    "text": "But in general,\nwhat's going to happen is we're going to have\na system of equations. We're going to have a system\nof p equations, one for each",
    "start": "4210190",
    "end": "4217150"
  },
  {
    "text": "of the coordinates of t. And we're going to have p\nunknowns, each coordinate of t.",
    "start": "4217150",
    "end": "4223960"
  },
  {
    "text": "And so we're going to\nhave the system to solve-- actually, i turns out it's\ngoing to be a linear system. But it's not going\nto be something",
    "start": "4223960",
    "end": "4229960"
  },
  {
    "text": "that we're going to be able to\nsolve coordinate by coordinate. It's going to be\nannoying to solve. You know, you can guess that\nwhat's going to happen, right.",
    "start": "4229960",
    "end": "4236820"
  },
  {
    "text": "Here, it involved the covariance\nbetween x and epsilon, right. That's what it involved\nto understand--",
    "start": "4236820",
    "end": "4243910"
  },
  {
    "text": "sorry, the correlation\nbetween x and y to understand how the\nsolution of this problem was.",
    "start": "4243910",
    "end": "4250660"
  },
  {
    "text": "In this case,\nthere's going to be only the covariance between\nx1 and y, x2 and y, x3, et",
    "start": "4250660",
    "end": "4257929"
  },
  {
    "text": "cetera, all the way to xp and y. There's also going to be all\nthe cross covariances between xj",
    "start": "4257930",
    "end": "4262960"
  },
  {
    "text": "and xk. And so this is going\nto be a nightmare to solve, like, in this system.",
    "start": "4262960",
    "end": "4268210"
  },
  {
    "text": "And what we do is that we go\non to using a matrix notation, so that when we\ntake derivatives,",
    "start": "4268210",
    "end": "4274600"
  },
  {
    "text": "we talk about\ngradients, and then we can invert matrices and solve\nlinear systems in a somewhat",
    "start": "4274600",
    "end": "4280389"
  },
  {
    "text": "formal manner by just saying\nthat, if I want to solve the system ax equals b--",
    "start": "4280390",
    "end": "4287230"
  },
  {
    "text": "rather than actually\nsolving this for each coordinate\nof x individually, I just say that x is\nequal to a inverse times.",
    "start": "4287230",
    "end": "4293770"
  },
  {
    "text": "So that's really why we're\ngoing to the equation one, because we have a\nformalism to write that x",
    "start": "4293770",
    "end": "4300730"
  },
  {
    "text": "is the solution of the system. I'm not telling you\nthat this is going to be easy to solve numerically,\nbut at least I can write it.",
    "start": "4300730",
    "end": "4308110"
  },
  {
    "text": "And so here's how it goes. I have a bunch of vectors. ",
    "start": "4308110",
    "end": "4315540"
  },
  {
    "text": "So what are my vectors, right? So I have x1-- oh, by the way,\nI didn't actually mention that when I\nput the lowercase, when",
    "start": "4315540",
    "end": "4321320"
  },
  {
    "text": "I put the subscript, I'm\ntalking about the observation. And when I put the\nsuperscript, I'm talking about the\ncoordinates, right?",
    "start": "4321320",
    "end": "4327110"
  },
  {
    "text": "So I have x1, which is\nequal to x1, x1 [? 1, ?]",
    "start": "4327110",
    "end": "4333290"
  },
  {
    "text": "x 1p, x2, which is 1.",
    "start": "4333290",
    "end": "4339965"
  },
  {
    "text": "x2, 1, x2 p, all the way to\nxn, which is 1, xn 1, x np.",
    "start": "4339965",
    "end": "4352380"
  },
  {
    "text": "All right, so those are n\nobserved x's, and then I have another y1, y2, yn, that\ncomes paired with those guys.",
    "start": "4352380",
    "end": "4360870"
  },
  {
    "text": "OK? So the first thing\nis that I'm going to stack those guys\ninto some vector",
    "start": "4360870",
    "end": "4366290"
  },
  {
    "text": "that I'm going to call y. So maybe I should put\nan arrow for the purpose of the blackboard, and\nit's just y1 to yn.",
    "start": "4366290",
    "end": "4373310"
  },
  {
    "text": "OK, so this is a vector in rn. Now, if I want to stack\nthose guys together,",
    "start": "4373310",
    "end": "4379150"
  },
  {
    "text": "I can either create a long\nvector of size n times p, but the problem is that I lose\nthe role of who's a coordinate",
    "start": "4379150",
    "end": "4385990"
  },
  {
    "text": "and who's an observation. And so it's actually\nnicer for me to just put those guys\nnext to each other",
    "start": "4385990",
    "end": "4392840"
  },
  {
    "text": "and create one new variable. And so the way I'm going to do\nthis is-- rather than actually",
    "start": "4392840",
    "end": "4398020"
  },
  {
    "text": "stacking those guys like that,\nI'm getting their transpose and stack them as\nrows of a matrix.",
    "start": "4398020",
    "end": "4404530"
  },
  {
    "text": "OK, so I'm going to\ncreate a matrix, which here is denoted typically by-- I'm going to write x double bar.",
    "start": "4404530",
    "end": "4411295"
  },
  {
    "text": "And here, I'm going to\nactually just-- so since I'm taking those guys like\nthis, the first column is going to be only ones.",
    "start": "4411295",
    "end": "4417010"
  },
  {
    "text": " And then I'm going to have-- well, x1, 1, [? 1, ?] x1, p.",
    "start": "4417010",
    "end": "4427130"
  },
  {
    "text": "And here, I'm going\nto have x n1, x np.",
    "start": "4427130",
    "end": "4432889"
  },
  {
    "text": "OK, so here the number of rows\nis n, and the number of columns is p.",
    "start": "4432890",
    "end": "4438800"
  },
  {
    "text": "One row per observation,\none column per coordinate. ",
    "start": "4438800",
    "end": "4445010"
  },
  {
    "text": "And again, I make your life\nmiserable because this really",
    "start": "4445010",
    "end": "4450710"
  },
  {
    "text": "should be p minus 1\nbecause I already used the first one for this guy.",
    "start": "4450710",
    "end": "4455850"
  },
  {
    "text": "I'm sorry about that. It's a bit painful. So usually we don't even\nwrite what's in there. So we don't have\nto think about it.",
    "start": "4455850",
    "end": "4461948"
  },
  {
    "text": "Those are just\nvectors of size p. OK? So now that I\ncreated this thing,",
    "start": "4461948",
    "end": "4467739"
  },
  {
    "text": "I can actually just basically\nstack up all my models. So Yi equals Xi transpose\nbeta plus epsilon i for all i",
    "start": "4467740",
    "end": "4479270"
  },
  {
    "text": "equal 1 to n. This transforms into-- this\nis equivalent to saying that the vector y is\nequal to the matrix x",
    "start": "4479270",
    "end": "4487610"
  },
  {
    "text": "times beta plus a matrix,\nplus a vector epsilon, where epsilon is just epsilon\n1 to epsilon n, right.",
    "start": "4487610",
    "end": "4497940"
  },
  {
    "text": "So I have just\nthis system, which I write as a matrix,\nwhich really just consists in stacking up all these\nequations next to each other.",
    "start": "4497940",
    "end": "4504900"
  },
  {
    "start": "4504900",
    "end": "4510195"
  },
  {
    "text": "So now that I have this model--\nthis is the usual least squares model. And here, when I want to write\nmy least squares criterion",
    "start": "4510195",
    "end": "4516150"
  },
  {
    "text": "in terms of matrices, right? My least squares\ncriterion, remember, was sum from i equal 1 to n\nof Yi minus Xi transposed beta",
    "start": "4516150",
    "end": "4527010"
  },
  {
    "text": "squared. Well, here it's\nreally just the sum of the square of the\ncoefficients of the vector",
    "start": "4527010",
    "end": "4535260"
  },
  {
    "text": "y minus x beta. So this is actually\nequal to the norm squared",
    "start": "4535260",
    "end": "4540380"
  },
  {
    "text": "of y minus x beta square. ",
    "start": "4540380",
    "end": "4546382"
  },
  {
    "text": "That's just the square. Norm is, by definition,\nthe sum of the square of the coordinates.",
    "start": "4546382",
    "end": "4551720"
  },
  {
    "text": "And so now I can actually\ntalk about minimizing a norm squared,\nand here it's going to be easier for me\nto take derivatives.",
    "start": "4551720",
    "end": "4558159"
  },
  {
    "text": "All right, so we'll\ndo that next time. ",
    "start": "4558160",
    "end": "4561861"
  }
]
[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6090"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6090",
    "end": "12720"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "12720",
    "end": "17880"
  },
  {
    "text": " PROFESSOR: So we've been talking\nabout this chi square test. And the name chi square\ncomes from the fact",
    "start": "17880",
    "end": "26400"
  },
  {
    "start": "20000",
    "end": "595000"
  },
  {
    "text": "that we build a\ntest statistic that has asymptotic\ndistribution given by the chi square distribution.",
    "start": "26400",
    "end": "36080"
  },
  {
    "text": "Let's just give it another shot. ",
    "start": "36080",
    "end": "44970"
  },
  {
    "text": "OK. This test. Who has actually ever\nencountered the chi square test",
    "start": "44970",
    "end": "50770"
  },
  {
    "text": "outside of a stats classroom? All right. So some people have.",
    "start": "50770",
    "end": "55940"
  },
  {
    "text": "It's a fairly common test\nthat you might encounter. And it was essentially\nto test, if given",
    "start": "55940",
    "end": "61650"
  },
  {
    "text": "some data with a fixed\nprobability mass function, so",
    "start": "61650",
    "end": "66900"
  },
  {
    "text": "a discrete\ndistribution, you wanted to test if the PMF was\nequal to a set value, p0,",
    "start": "66900",
    "end": "72990"
  },
  {
    "text": "or if it was different from p0. And the way the chi\nsquare arose here",
    "start": "72990",
    "end": "78480"
  },
  {
    "text": "was by looking at Wald's test. And essentially if you write--\nso Wald's is the one that",
    "start": "78480",
    "end": "85020"
  },
  {
    "text": "has the chi square as the\nlimiting distribution, and if you invert the\ncovariance matrix,",
    "start": "85020",
    "end": "91900"
  },
  {
    "text": "the asymptotic covariance\nmatrix, so you compute the Fisher information,\nwhich in this particular case does not exist for the\nmultinomial distribution,",
    "start": "91900",
    "end": "99360"
  },
  {
    "text": "but we found the trick\non how to do this. We remove the part that\nforbid it to be invertible,",
    "start": "99360",
    "end": "104470"
  },
  {
    "text": "then we found this chi\nsquare distribution. In a way we have\nthis test statistic, which you might have learned\nas a black box, laundry list,",
    "start": "104470",
    "end": "110549"
  },
  {
    "text": "but going through the math\nwhich might have been slightly unpleasant, I acknowledge,\nbut really told you",
    "start": "110550",
    "end": "116010"
  },
  {
    "text": "why you should do this\nparticular normalization. So since some of you requested\na little more practical examples",
    "start": "116010",
    "end": "124470"
  },
  {
    "text": "of how those things work,\nlet me show you a couple. The first one is you want to\nanswer the question, well,",
    "start": "124470",
    "end": "132209"
  },
  {
    "text": "you know, when should I\nbe born to be successful. Some people believe in zodiac,\nand so Fortune magazine",
    "start": "132210",
    "end": "140220"
  },
  {
    "text": "actually collected the signs of\n256 heads of the Fortune 500. Those were taken randomly.",
    "start": "140220",
    "end": "146407"
  },
  {
    "text": "And they were collected\nthere, and you can see the count of\nnumber of CEOs that have a particular zodiac sign.",
    "start": "146407",
    "end": "153060"
  },
  {
    "text": "And if this was completely\nuniformly distributed, you should actually\nget a number that's around 256 divided by 12,\nwhich in this case is 21.33.",
    "start": "153060",
    "end": "162540"
  },
  {
    "text": "And you can see that\nthere is numbers that are probably in the\nvicinity, but look at this guy.",
    "start": "162540",
    "end": "169890"
  },
  {
    "text": "Pisces, that's 29. So who's Pisces here? All right.",
    "start": "169890",
    "end": "175600"
  },
  {
    "text": "All right, so give\nme your information and we'll meet\nagain in 10 years. And so basically you\nmight want to test",
    "start": "175600",
    "end": "182784"
  },
  {
    "text": "if actually the fact that\nit's uniformly distributed is a valid assumption. Now this is clearly\na random variable.",
    "start": "182784",
    "end": "189240"
  },
  {
    "text": "I pick a random\nCEO and I measure what his zodiac sign is.",
    "start": "189240",
    "end": "196569"
  },
  {
    "text": "And I want to know, so it's a\nprobability over, I don't know, 12 zodiac signs. And I want to know if\nit's uniform or not.",
    "start": "196570",
    "end": "203330"
  },
  {
    "text": "Uniform sounds like it\nshould be the status quo, if you're reasonable. And maybe there's actually\nsomething that moves away.",
    "start": "203330",
    "end": "211530"
  },
  {
    "text": "So we could do this, in view\nof these data is there evidence that one is different.",
    "start": "211530",
    "end": "216720"
  },
  {
    "text": "Here is another example\nwhere you might want to apply the chi square test. So as I said, the\nbenchmark distribution",
    "start": "216720",
    "end": "224219"
  },
  {
    "text": "was the uniform distribution\nfor the zodiac sign, and that's usually\nthe one I give you. 1 over k, 1 over k,\nbecause well that's",
    "start": "224219",
    "end": "229890"
  },
  {
    "text": "sort of the zero, the central\npoint for all distributions. That's the point, the center\nof what we call the simplex.",
    "start": "229890",
    "end": "237353"
  },
  {
    "text": "But you can have\nanother benchmark that sort of makes sense. So for example this is an actual\ndataset where 275 jurors were",
    "start": "237354",
    "end": "244770"
  },
  {
    "text": "identified, racial\ngroup were collected, and you actually\nmight want to know",
    "start": "244770",
    "end": "250890"
  },
  {
    "text": "if you know juries\nin this country are actually representative\nof the actual population.",
    "start": "250890",
    "end": "257620"
  },
  {
    "text": "And so here of\ncourse, the population is not uniformly distributed\naccording to racial group.",
    "start": "257620",
    "end": "263269"
  },
  {
    "text": "And the way you\nactually do it is you actually go on\nWikipedia, for example, and you look at the demographics\nof the United States,",
    "start": "263269",
    "end": "268700"
  },
  {
    "text": "and you find that the proportion\nof white is 72%, black is 7%, Hispanic is 12, and\nother is about 9%.",
    "start": "268700",
    "end": "281610"
  },
  {
    "text": "So that's a total of 1. And this is what we actually\nmeasured for some jurors.",
    "start": "281610",
    "end": "286669"
  },
  {
    "text": "So for this guy,\nyou can actually run the chi square test. You have the estimated\nproportion, which comes from this first line.",
    "start": "286670",
    "end": "293070"
  },
  {
    "text": "You have the tested\nproportion, p0, that comes from the\nsecond line, and you might want to check if\nthose things actually",
    "start": "293070",
    "end": "298503"
  },
  {
    "text": "correspond to each other. OK, so I'm not going\nto do it for you, but I sort of\ninvite you to do it and test, and see\nhow this compares",
    "start": "298503",
    "end": "305400"
  },
  {
    "text": "to the quantiles of\nthe appropriate chi square distribution and see what\nyou can conclude from those two things.",
    "start": "305400",
    "end": "312320"
  },
  {
    "text": "All right. So this was the\nmultinomial case. So this is essentially\nwhat we did. We computed the MLE under\nthe right constraint,",
    "start": "312320",
    "end": "319129"
  },
  {
    "text": "and that was our test\nstatistic that converges to the chi square distribution. So if you've seen\nit before, that's all that was given to you.",
    "start": "319130",
    "end": "324790"
  },
  {
    "text": "Now we know why the\nnormalization here is p0 j and not p0 j squared or\nsquare root of p0 j, or even 1.",
    "start": "324790",
    "end": "333310"
  },
  {
    "text": "I mean it's not clear\nthat this should be the right\nnormalization, but we know that's what\ncomes from taking",
    "start": "333310",
    "end": "338949"
  },
  {
    "text": "the right normalization,\nwhich comes from the Fisher information. All right? OK. ",
    "start": "338950",
    "end": "347500"
  },
  {
    "text": "The thing I wanted to move\nonto, so we've basically covered chi square test. Are there any questions\nabout chi square test?",
    "start": "347500",
    "end": "353980"
  },
  {
    "text": "And for those of you who\nwere not here on Thursday, I'm really just-- do not pretend I just did it.",
    "start": "353980",
    "end": "359530"
  },
  {
    "text": "That's something we\ndid last Thursday. But are there any\nquestions that arose when you were reading\nyour notes, things",
    "start": "359530",
    "end": "364990"
  },
  {
    "text": "that you didn't understand? Yes. AUDIENCE: Is there\nlike a formal name? Before we had talked about\nhow what we call the Fisher",
    "start": "364990",
    "end": "372856"
  },
  {
    "text": "information [INAUDIBLE],,\nstill has the same [INAUDIBLE] because it's the same number.",
    "start": "372856",
    "end": "381834"
  },
  {
    "text": "PROFESSOR: So it's\nnot the Fisher. The Fisher information does\nnot exist in this case. And so there's no\nappropriate name for this.",
    "start": "381834",
    "end": "387992"
  },
  {
    "text": "It's the pseudoinverse of the\nasymptotic covariance matrix, and that's what it is. I don't know if I\nmentioned it last time,",
    "start": "387992",
    "end": "394170"
  },
  {
    "text": "but there's this entire\nfield that uses-- you know, for people who really\naspire to differential geometry",
    "start": "394170",
    "end": "399420"
  },
  {
    "text": "but are stuck in the\nstats department, and there's this thing called\ninformation geometry, which is essentially studying\nthe manifolds associated",
    "start": "399420",
    "end": "407220"
  },
  {
    "text": "to the Fisher information\nmetric, the metric that's associated to\nFisher information.",
    "start": "407220",
    "end": "412410"
  },
  {
    "text": "And so those of course can be\nlower dimensional manifolds, not only distorts the\ngeometry but forces everything",
    "start": "412410",
    "end": "418001"
  },
  {
    "text": "to live on a lower\ndimension, which is what happens when your Fisher\ninformation does not exist. And so there's a bunch\nof things that you",
    "start": "418002",
    "end": "424350"
  },
  {
    "text": "can study, what this manifold\nlooks like, et cetera. But no, there's no\nparticular terminology here",
    "start": "424350",
    "end": "429400"
  },
  {
    "text": "about going here. To be fair, within the\nscope of this class,",
    "start": "429400",
    "end": "434669"
  },
  {
    "text": "this is the only\ncase where you-- multinomial case\nis the only case",
    "start": "434670",
    "end": "439970"
  },
  {
    "text": "where you typically see a lack\nof a Fisher information matrix.",
    "start": "439970",
    "end": "446169"
  },
  {
    "text": "And that's just because we\nhave these extra constraints that the sum of the\nparameters should be 1. And if you have an\nextra constraint that",
    "start": "446169",
    "end": "451866"
  },
  {
    "text": "seems like it's actually\nremove one degree of freedom, this will happen inevitably. And so maybe what you\ncan do is reparameterize.",
    "start": "451866",
    "end": "460040"
  },
  {
    "text": "So if I actually reparameterize\neverything function of p1 to p k minus 1, and\nthen 1 minus the sum,",
    "start": "460040",
    "end": "466940"
  },
  {
    "text": "this would not have happened. Because I have only a\nk-dimensional space. So there's tricks\naround this to make it",
    "start": "466940",
    "end": "473170"
  },
  {
    "text": "exist if you want it to exist. Any other question?",
    "start": "473170",
    "end": "478740"
  },
  {
    "text": "All right. So let's move on to\nStudent's t-test. We mentioned it last time. So essentially you've\nprobably done it",
    "start": "478740",
    "end": "486389"
  },
  {
    "text": "more even in the homework than\nyou've done it in lectures, but just quickly this\nis essentially the test.",
    "start": "486390",
    "end": "492870"
  },
  {
    "text": "That's the test when we have\nan actual data that comes from a normal distribution. There is no Central Limit\nTheorem that exists.",
    "start": "492870",
    "end": "498750"
  },
  {
    "text": "This is really to\naccount for the fact that for smaller\nsample sizes, it",
    "start": "498750",
    "end": "504139"
  },
  {
    "text": "might be the case that it's\nnot exactly true that when I look at xn bar minus mu\ndivided by-- so if I look",
    "start": "504140",
    "end": "513860"
  },
  {
    "text": "at xn bar minus mu divided by\nsigma times square root of n, then this thing should have N\n0, 1 distribution approximately.",
    "start": "513860",
    "end": "521179"
  },
  {
    "text": "Right? By the Central Limit Theorem. So that's for n large.",
    "start": "521179",
    "end": "527120"
  },
  {
    "text": "But if n is small,\nthen it's still true",
    "start": "527120",
    "end": "533779"
  },
  {
    "text": "when the data is N\nmu, sigma squared,",
    "start": "533780",
    "end": "540910"
  },
  {
    "text": "then it's true that\nsquare root of n-- ",
    "start": "540910",
    "end": "549310"
  },
  {
    "text": "so here it's approximately. And this is always true.",
    "start": "549310",
    "end": "554720"
  },
  {
    "text": "But I don't know sigma\nin practice, right? Maybe mu, it comes from my,\nmaybe mu comes from my mu",
    "start": "554720",
    "end": "560550"
  },
  {
    "text": "0, maybe something\nfrom the test statistic where mu actually is here. But for this guy I'm\ngoing to have inevitably",
    "start": "560550",
    "end": "567490"
  },
  {
    "text": "to find an estimator. And now in this case, for small\nn, this is no longer true.",
    "start": "567490",
    "end": "572800"
  },
  {
    "text": "And what the t\nstatistic is doing is essentially telling you what\nthe distribution of this guy is. So what you should say\nis that now this guy",
    "start": "572800",
    "end": "581050"
  },
  {
    "text": "has a t distribution with n\nminus 1 degrees of freedom. That's basically the\nlaundry list stats",
    "start": "581050",
    "end": "587296"
  },
  {
    "text": "that you would learn. It says just look at a different\ntable, that's what it is. But we actually defined\nwhat a t distribution was.",
    "start": "587296",
    "end": "595180"
  },
  {
    "start": "595000",
    "end": "1012000"
  },
  {
    "text": "And a t distribution\nis basically something that has the same\ndistribution as some N 0, 1,",
    "start": "595180",
    "end": "603490"
  },
  {
    "text": "divided by the square\nroot of a chi square with d degrees of\nfreedom divided by d. And that's a t distribution\nwith d degrees of freedom.",
    "start": "603490",
    "end": "612750"
  },
  {
    "text": "And those two have\nto be independent. ",
    "start": "612750",
    "end": "620959"
  },
  {
    "text": "And so what I need to check\nis that this guy over there is of this form. ",
    "start": "620960",
    "end": "637160"
  },
  {
    "text": "OK? So let's look at the numerator. Well, square root of\nn, xn bar minus mu.",
    "start": "637160",
    "end": "645986"
  },
  {
    "text": "What is the distribution\nof this thing? Is it an N 0, 1? AUDIENCE: N 0, sigma squared?",
    "start": "645986",
    "end": "652569"
  },
  {
    "text": "PROFESSOR: N 0,\nsigma squared, right. ",
    "start": "652569",
    "end": "658816"
  },
  {
    "text": "So I'm not going to put it here. So if I want this\nguy to be N 0, 1, I need to divide by sigma,\nthat's what we have over there.",
    "start": "658817",
    "end": "664130"
  },
  {
    "text": " So that's my N 0, 1 that's going\nto play the role of this guy",
    "start": "664130",
    "end": "669820"
  },
  {
    "text": "here. So if I want to go\na little further, I need to just say, OK, now I\nneed to have square root of n,",
    "start": "669820",
    "end": "681089"
  },
  {
    "text": "and I need to find\nsomething here that looks like my square\nroot of chi square divided",
    "start": "681090",
    "end": "687300"
  },
  {
    "text": "by-- yeah? AUDIENCE: Really quick question. The equals sign with the d on\ntop, that's just defined as?",
    "start": "687300",
    "end": "692700"
  },
  {
    "text": "PROFESSOR: No, that's\njust the distribution. So, I don't know. AUDIENCE: Then never mind.",
    "start": "692700",
    "end": "698290"
  },
  {
    "text": "PROFESSOR: Let's just write\nit like that, if you want. I mean, that's not really\nappropriate to have.",
    "start": "698290",
    "end": "704406"
  },
  {
    "text": "Usually you write\nonly one distribution on the right-hand inside\nof this little thing. So not just this complicated\nfunction of distributions.",
    "start": "704406",
    "end": "711160"
  },
  {
    "text": "This is more like to explain. OK, and so usually\nthe thing you should say that t is equal to this\nX divided by square root of Z",
    "start": "711160",
    "end": "718990"
  },
  {
    "text": "divided by d where X\nhas normal distribution, Z has chi square distribution\nwith d degrees of freedom.",
    "start": "718990",
    "end": "726209"
  },
  {
    "text": "So what do we need here? Well I need to have something\nwhich looks like my sigma hat, right? So somehow inevitably I'm going\nto need to have sigma hat.",
    "start": "726210",
    "end": "733740"
  },
  {
    "text": " Now of course I need to\ndivide this by my sigma",
    "start": "733740",
    "end": "738865"
  },
  {
    "text": "so that my sigma goes away.  And so now this thing here--",
    "start": "738866",
    "end": "745195"
  },
  {
    "text": "sorry, I should move\non to the right, OK. And so this thing here, so\nsigma hat is square root of Sn.",
    "start": "745195",
    "end": "753270"
  },
  {
    "text": "And now I'm almost there. So this thing is actually\nequal to square root of n. ",
    "start": "753270",
    "end": "767760"
  },
  {
    "text": "But this thing here\nis actually not a-- ",
    "start": "767760",
    "end": "775100"
  },
  {
    "text": "so this thing here\nfollows a distribution which is actually a\nchi square, square root",
    "start": "775100",
    "end": "780530"
  },
  {
    "text": "of a chi square\ndistribution divided by n.",
    "start": "780530",
    "end": "791510"
  },
  {
    "text": " Yeah, that's the square\nroot chi square distribution",
    "start": "791510",
    "end": "798340"
  },
  {
    "text": "with n minus 1 degrees\nof freedom divided by n, because sigma hat\nis equal to 1 over n sum",
    "start": "798340",
    "end": "805360"
  },
  {
    "text": "from i equal 1 to n,\nxi minus x bar squared. And we just said\nthat this part here",
    "start": "805360",
    "end": "812750"
  },
  {
    "text": "was a chi square distribution. We didn't just say it, we said\nit a few lectures years back, that this thing was a chi square\ndistribution, and the fact",
    "start": "812750",
    "end": "819228"
  },
  {
    "text": "that the presence\nof this x bar here was actually removing one\ndegree of freedom from this sum.",
    "start": "819228",
    "end": "826000"
  },
  {
    "text": "OK, so this guy here has\nthe same distribution as a chi square n\nminus 1 divided by n.",
    "start": "826000",
    "end": "832860"
  },
  {
    "text": "So I need to actually still\narrange this thing a little bit to have a t distribution.",
    "start": "832860",
    "end": "838170"
  },
  {
    "text": "I should not see n here,\nbut I should n minus 1. The d is the same\nas this d here.",
    "start": "838170",
    "end": "846396"
  },
  {
    "text": "And so let me make\nthe correction so that this actually happens. Well, if I actually write\nthis to be equal to--",
    "start": "846396",
    "end": "854700"
  },
  {
    "text": "so if I write square root of\nn minus 1, as on the slide,",
    "start": "854700",
    "end": "859950"
  },
  {
    "text": "times xn bar minus\nmu divided by--",
    "start": "859950",
    "end": "865200"
  },
  {
    "text": "well let me write it\nas square root of Sn, which is my sigma hat. Then what this thing\nis actually equal to,",
    "start": "865200",
    "end": "873902"
  },
  {
    "text": "it follows a N 0, 1,\ndivided by the square root",
    "start": "873902",
    "end": "879029"
  },
  {
    "text": "of my chi square\ndistribution with n minus 1 degrees of freedom. And here the fact\nthat I multiply by square root of\nn minus 1, and I",
    "start": "879030",
    "end": "885438"
  },
  {
    "text": "have the square root of n\nhere, is essentially the same as dividing here by n minus 1.",
    "start": "885439",
    "end": "891440"
  },
  {
    "text": "And that's my tn distribution. My t distribution with n\nminus 1 degrees of freedom.",
    "start": "891440",
    "end": "898190"
  },
  {
    "text": "Just by definition of\nwhat this thing is. OK? ",
    "start": "898190",
    "end": "922020"
  },
  {
    "text": "All right. Yes? AUDIENCE: Where'd you\nget the square root from? PROFESSOR: This guy?",
    "start": "922020",
    "end": "927220"
  },
  {
    "text": "Oh sorry, that's sigma squared. Thank you. That's the estimator of the\nvariance, not the estimator",
    "start": "927220",
    "end": "932570"
  },
  {
    "text": "of the standard deviation. And when I want to divide it I\ndivide by standard deviation. Thank you.",
    "start": "932570",
    "end": "938480"
  },
  {
    "text": "Any other question or remark? AUDIENCE: Shouldn't you\ndivide by sigma squared? The actual.",
    "start": "938480",
    "end": "945616"
  },
  {
    "text": "The estimator for\nthe variance is equal to sigma squared\ntimes chi square, right?",
    "start": "945617",
    "end": "952480"
  },
  {
    "text": "PROFESSOR: The estimator\nfor the variance. Oh yes, you're right. So there's a sigma squared here.",
    "start": "952480",
    "end": "959324"
  },
  {
    "text": "Is that what you're asking? AUDIENCE: Yeah. PROFESSOR: Yes, absolutely. And that's where,\nit get cancels here. It gets canceled here.",
    "start": "959325",
    "end": "964860"
  },
  {
    "start": "964860",
    "end": "970048"
  },
  {
    "text": "OK?  So this is really a sigma\nsquared times chi square.",
    "start": "970048",
    "end": "975310"
  },
  {
    "text": " OK.",
    "start": "975310",
    "end": "981120"
  },
  {
    "text": "So the fact that\nit's sigma squared is just because I\ncan pull out sigma squared and just think\nthose guys N 0, 1. ",
    "start": "981120",
    "end": "992591"
  },
  {
    "text": "All right. So that's my t distribution. Now that I actually have a\npivotal distribution, what I do",
    "start": "992591",
    "end": "997950"
  },
  {
    "text": "is that I form the statistic. Here I called it Tn tilde. ",
    "start": "997950",
    "end": "1012180"
  },
  {
    "start": "1012000",
    "end": "1149000"
  },
  {
    "text": "OK. And what is this thing? I know that this has a\npivotal distribution. So for example, I know\nthat the probability",
    "start": "1012180",
    "end": "1019150"
  },
  {
    "text": "that Tn tilde in absolute value\nexceeds some number that I'm",
    "start": "1019150",
    "end": "1025660"
  },
  {
    "text": "going to call q alpha over\n2 for the t n minus 1,",
    "start": "1025660",
    "end": "1031420"
  },
  {
    "text": "is equal to alpha. So that's basically,\nremember the t distribution",
    "start": "1031420",
    "end": "1036880"
  },
  {
    "text": "has the same shape as the\nGaussian distribution. What I'm finding is,\nfor this t distribution,",
    "start": "1036880",
    "end": "1041919"
  },
  {
    "text": "some number q alpha\nover 2 of t n minus 1 and minus q alpha\nover 2 of t minus 1.",
    "start": "1041920",
    "end": "1049370"
  },
  {
    "text": "So those are different\nfrom the Gaussian one. Such that the area\nunder the curve here is alpha over\n2 on each side",
    "start": "1049370",
    "end": "1056530"
  },
  {
    "text": "so that the probability that\nmy absolute value exceeds this number is equal to alpha.",
    "start": "1056530",
    "end": "1063790"
  },
  {
    "text": "And that's what I'm going\nto use to reject the test. So now my test becomes, for H0,\nsay mu is equal to some mu 0,",
    "start": "1063790",
    "end": "1079270"
  },
  {
    "text": "versus H1, mu is\nnot equal to mu 0.",
    "start": "1079270",
    "end": "1085015"
  },
  {
    "text": " The rejection region is going\nto be equal to the set on which",
    "start": "1085015",
    "end": "1093090"
  },
  {
    "text": "square root of n minus 1 times\nxn bar minus mu 0 this time,",
    "start": "1093090",
    "end": "1099520"
  },
  {
    "text": "divided by square root of Sn\nexceeds, in absolute value,",
    "start": "1099520",
    "end": "1105700"
  },
  {
    "text": "exceeds q-- sorry\nthat's already here-- exceeds q alpha over\n2 of t n minus 1.",
    "start": "1105700",
    "end": "1114130"
  },
  {
    "text": "So I reject when\nthis thing increases. The same as the Gaussian case,\nexcept that rather than reading my quantiles from\nthe Gaussian table",
    "start": "1114130",
    "end": "1121410"
  },
  {
    "text": "I read them from\nthe Student table. It's just the same thing. So they're just going to\nbe a little bit farther.",
    "start": "1121410",
    "end": "1128740"
  },
  {
    "text": "So this guy here is just\ngoing to be a little bigger than the one for\nthe Gaussian one,",
    "start": "1128740",
    "end": "1134500"
  },
  {
    "text": "because it's going to require\nme a little more evidence in my data to be able\nto reject because I have to account for the\nfluctuations of sigma hat.",
    "start": "1134500",
    "end": "1141411"
  },
  {
    "start": "1141411",
    "end": "1149270"
  },
  {
    "start": "1149000",
    "end": "1182000"
  },
  {
    "text": "So of course Student's\ntest is used everywhere. People use only t tests, right?",
    "start": "1149270",
    "end": "1155800"
  },
  {
    "text": "If you look at any\ndata point, any output, even if you had\n500 observations,",
    "start": "1155800",
    "end": "1161503"
  },
  {
    "text": "if you look at the\nstatistical software output it's going to say t test. And the reason\nwhy you see t test",
    "start": "1161504",
    "end": "1166630"
  },
  {
    "text": "is because somehow it's felt\nlike it's not asymptotic. You don't need to\nactually do, you",
    "start": "1166630",
    "end": "1171850"
  },
  {
    "text": "know, to be\nparticularly careful. And anyway, if n\nis equal to 500, since the two curves\nare above each other",
    "start": "1171850",
    "end": "1177730"
  },
  {
    "text": "it's basically the same thing. So it doesn't really\nchange anything. So why not use the t test?",
    "start": "1177730",
    "end": "1183320"
  },
  {
    "text": "So it's not asymptotic. It doesn't require Central\nLimit Theorem to kick in. And so in particular it be run\nif you have 15 observations.",
    "start": "1183320",
    "end": "1190940"
  },
  {
    "text": "Of course, the drawback\nof the Student test is that it relies\non the assumption that the sample is Gaussian,\nand that's something",
    "start": "1190940",
    "end": "1196579"
  },
  {
    "text": "we really need to keep in mind. If you have a small sample size,\nthere is no magic going on.",
    "start": "1196579",
    "end": "1201710"
  },
  {
    "text": "It's not like Student t\ntest allows you to get rid of this asymptotic normality.",
    "start": "1201710",
    "end": "1206720"
  },
  {
    "text": "It sort of assumes\nthat it's built in. It assumes that your data\nhas a Gaussian distribution.",
    "start": "1206720",
    "end": "1214150"
  },
  {
    "text": "So if you have 15 observations,\nwhat are you going to do? You want to test if the mean is\nequal to 0 or not equal to 0,",
    "start": "1214150",
    "end": "1221610"
  },
  {
    "text": "but you have only\n15 observations. You have to somehow assume\nthat your data is Gaussian.",
    "start": "1221610",
    "end": "1227900"
  },
  {
    "text": "But if the data is given\nto you, this is not math, you actually have to\ncheck that it's Gaussian. And so we're going\nto have to find",
    "start": "1227900",
    "end": "1233930"
  },
  {
    "text": "a test that, given some data,\ntells us whether it's Gaussian or not.",
    "start": "1233930",
    "end": "1239830"
  },
  {
    "text": "If I have 15\nobservations, 8 of them are equal to plus 1 and 7 of\nthem are equal to minus 1,",
    "start": "1239830",
    "end": "1246089"
  },
  {
    "text": "then it's pretty\nunlikely that you're going to be able to conclude\nthat your data has a Gaussian distribution. However, if you see some sort\nof spread around some value,",
    "start": "1246089",
    "end": "1254320"
  },
  {
    "text": "you form a histogram\nmaybe and it sort of looks like it's a\nGaussian, you might want to say it's Gaussian. And so how do we make\nthis more quantitative?",
    "start": "1254320",
    "end": "1261920"
  },
  {
    "text": "Well, the sad answer\nto this question is that there will be some\ntests that make it quantitative,",
    "start": "1261920",
    "end": "1268030"
  },
  {
    "text": "but here, if you think about it\nfor one second, what is going to be your null hypothesis? Your null hypothesis,\nsince it's one point,",
    "start": "1268030",
    "end": "1275930"
  },
  {
    "text": "it's going to be\nthat it's Gaussian, and then the\nalternative is going to be that it's not Gaussian.",
    "start": "1275930",
    "end": "1281520"
  },
  {
    "text": "So what it means is\nthat, for the first time in your statistician\nlife, you're going to want to conclude\nthat H0 is the true one.",
    "start": "1281520",
    "end": "1290142"
  },
  {
    "text": "You're definitely\nnot going to want to say that it's not Gaussian,\nbecause then everything you know is sort of falling apart.",
    "start": "1290142",
    "end": "1296580"
  },
  {
    "text": "And so it's kind of\na weird thing where you're sort of going\nto be seeking tests that have no power basically.",
    "start": "1296580",
    "end": "1303140"
  },
  {
    "text": "You're going to want to test\nthat, and that's the nature. The amount of\nalternatives, the number",
    "start": "1303140",
    "end": "1309140"
  },
  {
    "text": "of ways you can be not\nGaussian, is so huge that all tests are sort of\nbound to have very low power.",
    "start": "1309140",
    "end": "1316569"
  },
  {
    "text": "And so that's why people are\npretty happy with the idea that things are\nGaussian, because it's very hard to find\na test that's going",
    "start": "1316569",
    "end": "1321961"
  },
  {
    "text": "to reject this hypothesis. And so we're even going to find\nsome tests that are visual,",
    "start": "1321961",
    "end": "1328479"
  },
  {
    "text": "where you're going\nto be able to say, well, sort of looks\nGaussian to me. It allows you to deal\nwith the borderline cases",
    "start": "1328479",
    "end": "1336760"
  },
  {
    "text": "pretty efficiently. We'll see actually a\nparticular example. All right, so this\ntheory of testing",
    "start": "1336760",
    "end": "1342280"
  },
  {
    "start": "1340000",
    "end": "2292000"
  },
  {
    "text": "whether data comes from\na particular distribution is called goodness of fit. Is this distribution a\ngood fit for my data?",
    "start": "1342280",
    "end": "1351480"
  },
  {
    "text": "That's the goodness of fit test. We have just seen a\ngoodness of fit test. What was it?",
    "start": "1351480",
    "end": "1356690"
  },
  {
    "start": "1356690",
    "end": "1361950"
  },
  {
    "text": "Yeah. The chi square test, right? The case square test, we\nwere given a candidate PMF",
    "start": "1361950",
    "end": "1369659"
  },
  {
    "text": "and we were testing if this\nwas a good fit for our data. That was a goodness of fit test. So of course multinomial\nis one example,",
    "start": "1369660",
    "end": "1377190"
  },
  {
    "text": "but really what we have\nin the back of our mind is I want to test if\nmy data is Gaussian. That's basically\nthe usual thing.",
    "start": "1377190",
    "end": "1383409"
  },
  {
    "text": "And just like you always see\nt test as the standard output from statistical software\nwhether you ask for it or not,",
    "start": "1383410",
    "end": "1389220"
  },
  {
    "text": "there will be a\ntest for normality whether you ask it or not from\nany statistical software app.",
    "start": "1389220",
    "end": "1396500"
  },
  {
    "text": "All right. So a goodness of fit\ntest looks as follows. There's a random\nvariable X and you're given i.i.d. copies\nof X, X1 to Xn,",
    "start": "1396500",
    "end": "1403908"
  },
  {
    "text": "they come from the\nsame distribution. And you're going to ask the\nfollowing question: does X have a standard normal distribution?",
    "start": "1403909",
    "end": "1411510"
  },
  {
    "text": "So for t distribution\nthat's definitely the kind of questions\nyou may want to ask. Does X have a uniform\ndistribution on 0, 1?",
    "start": "1411510",
    "end": "1419820"
  },
  {
    "text": "That's different from\nthe distribution 1 over k, 1 over k, it's\nthe continuous notion of uniformity.",
    "start": "1419820",
    "end": "1427429"
  },
  {
    "text": "And for example, you\nmight want to test that-- so there's actually a\nnice exercise, which is if you look at the p-values.",
    "start": "1427430",
    "end": "1433580"
  },
  {
    "text": "So we've defined what\nthe p-values were. And the p-value's a number\nbetween 0 and 1, right?",
    "start": "1433580",
    "end": "1439710"
  },
  {
    "text": "And you could\nactually ask yourself, what is the distribution of\nthe p-value under the null? So the p-value is\na random number.",
    "start": "1439710",
    "end": "1448000"
  },
  {
    "text": "It's the probability-- so\nthe p-value-- let's look at the following test.",
    "start": "1448000",
    "end": "1453720"
  },
  {
    "text": " H0, mu is equal to 0, versus\nH1, mu is not equal to 0.",
    "start": "1453720",
    "end": "1465190"
  },
  {
    "text": "And I know that the p-value is-- so I'm going to form what? I'm going to look\nat Xn bar minus mu",
    "start": "1465190",
    "end": "1474831"
  },
  {
    "text": "times square root of n\ndivided by-- let's say that we know sigma for one second.",
    "start": "1474832",
    "end": "1480040"
  },
  {
    "text": "Then the p-value\nis the probability that this is larger then\nsquare root of n little xn",
    "start": "1480040",
    "end": "1488590"
  },
  {
    "text": "bar minus mu, minus 0\nactually in this case,",
    "start": "1488590",
    "end": "1494775"
  },
  {
    "text": "divided by sigma, where\nthis guy is the observed. ",
    "start": "1494775",
    "end": "1504360"
  },
  {
    "text": "OK. So now you could say, well,\nhow is that a random variable?",
    "start": "1504360",
    "end": "1509890"
  },
  {
    "text": "It's just a number. It's just a probability\nof something. But then I can view this\nas a function of this guy",
    "start": "1509890",
    "end": "1517090"
  },
  {
    "text": "here when I plug it back\nto be a random variable.",
    "start": "1517090",
    "end": "1523190"
  },
  {
    "text": "So what I mean by this is\nthat if I look at this value here, if I say that phi\nis the CDF of N 0, 1,",
    "start": "1523190",
    "end": "1534520"
  },
  {
    "text": "so the p-value is\nthe probability that it exceeds this. So that's the probability\nthat I'm either here or here.",
    "start": "1534520",
    "end": "1541730"
  },
  {
    "text": " AUDIENCE: [INAUDIBLE]",
    "start": "1541730",
    "end": "1547975"
  },
  {
    "text": "PROFESSOR: No, it's not, right? AUDIENCE: [INAUDIBLE] PROFESSOR: This is a big\nX and this is a small x.",
    "start": "1547975",
    "end": "1555290"
  },
  {
    "text": "This is just where\nyou plug in your data. The p-value is the\nprobability that you have more evidence\nagainst your null",
    "start": "1555290",
    "end": "1563180"
  },
  {
    "text": "than what you already have. OK, so now I can\nwrite it in terms of cumulative\ndistribution functions.",
    "start": "1563180",
    "end": "1569190"
  },
  {
    "text": "So this is what? This is phi of this guy, which\nis minus this thing here.",
    "start": "1569190",
    "end": "1574480"
  },
  {
    "text": " Well it's basically\n2 times this guy, phi of minus square root of\nn, Xn bar divided by sigma.",
    "start": "1574480",
    "end": "1587950"
  },
  {
    "text": " That's my p-value. If you give me data, I'm\ngoing to compute the average",
    "start": "1587950",
    "end": "1593860"
  },
  {
    "text": "and plug it in there, and\nit can spit out the p-value. Everybody agrees? ",
    "start": "1593860",
    "end": "1599890"
  },
  {
    "text": "So now I can view this, if I\nstart now looking back I say, well, where does\nthis data come from?",
    "start": "1599890",
    "end": "1605710"
  },
  {
    "text": "Well, it could be\na random variable. It came from the\nrealization of this thing.",
    "start": "1605710",
    "end": "1611340"
  },
  {
    "text": "So I can try to, I can\nthink of this value, where now this is a random\nvariable because I just plugged",
    "start": "1611340",
    "end": "1617080"
  },
  {
    "text": "in a random variable in here. So now I view my p-value\nas a random variable.",
    "start": "1617080",
    "end": "1624240"
  },
  {
    "text": "So I keep switching from\nsmall x to large X. Everybody agrees what I'm doing here? So I just wrote it as a\ndeterministic function",
    "start": "1624240",
    "end": "1631490"
  },
  {
    "text": "of some deterministic\nnumber, and now the function stays deterministic but\nthe number becomes random.",
    "start": "1631490",
    "end": "1637520"
  },
  {
    "text": "And so I can think of this\nas some statistic of my data. And I could say, well,\nwhat is the distribution",
    "start": "1637520",
    "end": "1643660"
  },
  {
    "text": "of this random variable? Now if my data is actually\nnormally distributed,",
    "start": "1643660",
    "end": "1649480"
  },
  {
    "text": "so I'm actually\nunder the null, so under the null, that means that\nXn bar times square root of n",
    "start": "1649480",
    "end": "1657570"
  },
  {
    "text": "divided by sigma has\nwhat distribution? ",
    "start": "1657570",
    "end": "1668335"
  },
  {
    "text": "Normal? ",
    "start": "1668335",
    "end": "1676539"
  },
  {
    "text": "Well it was sigma,\nI assume I knew it. So it's N 0, 1, right? I divided by sigma here.",
    "start": "1676540",
    "end": "1682080"
  },
  {
    "text": "OK? So now I have this\nrandom variable. ",
    "start": "1682080",
    "end": "1695880"
  },
  {
    "text": "And so my random variable is now\n2 phi of minus absolute value",
    "start": "1695880",
    "end": "1704012"
  },
  {
    "text": "of a Gaussian. ",
    "start": "1704012",
    "end": "1714429"
  },
  {
    "text": "And I'm actually interested in\nthe distribution of this thing.",
    "start": "1714430",
    "end": "1720300"
  },
  {
    "text": "I could ask that. Anybody has an idea\nof how you would want to tackle this thing? If I ask you, what\nis the distribution",
    "start": "1720300",
    "end": "1726600"
  },
  {
    "text": "of a random variable, how\ndo you tackle this question? ",
    "start": "1726600",
    "end": "1733120"
  },
  {
    "text": "There's basically two ways. One is to try to\nfind something that looks like the expectation\nof h of x for all h.",
    "start": "1733120",
    "end": "1742090"
  },
  {
    "text": "And you try to write this\nusing change of variables and something that looks like\nintegral of h of x p of x dx.",
    "start": "1742090",
    "end": "1749260"
  },
  {
    "text": "And then you say, well,\nthat's the density. If you can read this\nfor any h, then that's",
    "start": "1749260",
    "end": "1755290"
  },
  {
    "text": "the way you would do it. But there's a simpler\nway that does not involve changing\nvariables, et cetera,",
    "start": "1755290",
    "end": "1761805"
  },
  {
    "text": "you just try to compute\nthe cumulative distribution function. So let's try to\ncompute the probability",
    "start": "1761805",
    "end": "1766900"
  },
  {
    "text": "that 2 phi minus N\n0, 1, is less than t.",
    "start": "1766900",
    "end": "1774850"
  },
  {
    "text": "And maybe we can find\nsomething we know. OK. Well that's equal to what? That's the probability\nthat a minus N 0,",
    "start": "1774850",
    "end": "1783040"
  },
  {
    "text": "well let's say that an N 0, 1-- sorry, N 0, 1 absolute value is\ngreater than minus phi inverse",
    "start": "1783040",
    "end": "1797590"
  },
  {
    "text": "of t over 2. ",
    "start": "1797590",
    "end": "1804169"
  },
  {
    "text": "And that's what? Well, it's just the same\nthing that we had before. It's equal to-- so\nif I look again,",
    "start": "1804170",
    "end": "1812990"
  },
  {
    "text": "this is the probability that\nI'm actually on this side or that side of this number. And this number is what?",
    "start": "1812990",
    "end": "1818650"
  },
  {
    "text": "It's minus phi of t over 2.",
    "start": "1818650",
    "end": "1825840"
  },
  {
    "text": "Why do I have a minus here? ",
    "start": "1825840",
    "end": "1832230"
  },
  {
    "text": "That's fine, OK. So it's actually not this,\nit's actually the probability that my absolute value--",
    "start": "1832230",
    "end": "1839830"
  },
  {
    "text": "oh, because phi inverse. OK. Because phi inverse is-- so I'm going to\nlook at t between 0",
    "start": "1839830",
    "end": "1848279"
  },
  {
    "text": "and-- so this number is\nranging between 0 and 1. So it means that this number\nis ranging between 0--",
    "start": "1848280",
    "end": "1855169"
  },
  {
    "text": "well, the probability that\nsomething is less than t should be ranging between the\nnumbers that this guy takes,",
    "start": "1855170",
    "end": "1863030"
  },
  {
    "text": "so that's between 0 and 2. ",
    "start": "1863030",
    "end": "1871410"
  },
  {
    "text": "Because this thing takes\nvalues between 0 and 2. I want to see 0 and 1, though.",
    "start": "1871410",
    "end": "1876824"
  },
  {
    "text": " AUDIENCE: Negative absolute\nvalue is always less",
    "start": "1876824",
    "end": "1883533"
  },
  {
    "text": "than [INAUDIBLE]. ",
    "start": "1883533",
    "end": "1889314"
  },
  {
    "text": "PROFESSOR: Yeah. You're right, thank you. So this is always some\nnumber which is less than 0, so the probability that\nthe Gaussian is less",
    "start": "1889314",
    "end": "1896490"
  },
  {
    "text": "than this number is always\nless than the probability it's less than 0,\nwhich is 1/2, so t only has to be between 0 and 1.",
    "start": "1896490",
    "end": "1901890"
  },
  {
    "text": "Thank you. And so now for t\nbetween 0 and 1, then",
    "start": "1901890",
    "end": "1907379"
  },
  {
    "text": "this guy is actually becoming\nsomething which is positive, for the same reason as before. And so that's what?",
    "start": "1907380",
    "end": "1913065"
  },
  {
    "text": "That's just basically 2 times\nphi of phi inverse of t over 2.",
    "start": "1913065",
    "end": "1924710"
  },
  {
    "text": " That's just playing with\nthe symmetry a little bit.",
    "start": "1924710",
    "end": "1929750"
  },
  {
    "text": "You can look at the\nareas under the curve. And so what it means is\nthat those two guys cancel. This is the identity.",
    "start": "1929750",
    "end": "1935320"
  },
  {
    "text": "And so this is equal to t. So which distribution\nhas a density--",
    "start": "1935320",
    "end": "1943240"
  },
  {
    "text": "sorry, which distribution\nhas a cumulative distribution function which is equal to\nt for t between 0 and 1?",
    "start": "1943240",
    "end": "1952040"
  },
  {
    "text": "That's the uniform\ndistribution, right? So it means that this guy\nfollows a uniform distribution",
    "start": "1952040",
    "end": "1957800"
  },
  {
    "text": "on the interval 0, 1. ",
    "start": "1957800",
    "end": "1964264"
  },
  {
    "text": "And you could\nactually check that. For any test you're\ngoing to come up with, this is going to be the case. Your p-value under the null\nwill have a distribution",
    "start": "1964264",
    "end": "1972340"
  },
  {
    "text": "which is uniform. So now if somebody shows up\nand says, here's my test,",
    "start": "1972340",
    "end": "1978070"
  },
  {
    "text": "it's awesome, it\njust works great. I'm not going to explain\nto you how I built it, it's a complicated\nstatistics that",
    "start": "1978070",
    "end": "1983926"
  },
  {
    "text": "involve moments of order 27. And I'm like, OK,\nyou know, how am I going to test that your test\nstatistic actually makes sense?",
    "start": "1983926",
    "end": "1991690"
  },
  {
    "text": "Well one thing I can do\nis to run a bunch of data, draw a bunch of samples,\ncompute your test statistic,",
    "start": "1991690",
    "end": "1998440"
  },
  {
    "text": "compute the p-value, and\ncheck if my p-value has a uniform distribution\non the interval 0, 1.",
    "start": "1998440",
    "end": "2007049"
  },
  {
    "text": "But for that I need\nto have a test that, given a bunch of\nobservations, can tell me whether they're actually\ndistributed uniformly",
    "start": "2007050",
    "end": "2013059"
  },
  {
    "text": "on the interval 0, 1. And again one thing I could\ndo is build a histogram and see if it looks\nlike that of a uniform,",
    "start": "2013060",
    "end": "2020032"
  },
  {
    "text": "but I could also try to be\nslightly more quantitative about this. AUDIENCE: Why does\nthe [INAUDIBLE] have to be for a [INAUDIBLE]?",
    "start": "2020032",
    "end": "2027039"
  },
  {
    "text": "PROFESSOR: For two tests? AUDIENCE: For each test. Why does the p-value\nhave to be normal?",
    "start": "2027039",
    "end": "2034370"
  },
  {
    "text": "I mean, uniform. PROFESSOR: It's\nuniform under the null. So because my test statistic\nwas built under the null,",
    "start": "2034370",
    "end": "2040599"
  },
  {
    "text": "and so I have to be able to plug\nin the right value in there, otherwise it's going\nto shift everything for this particular test.",
    "start": "2040599",
    "end": "2046078"
  },
  {
    "text": "AUDIENCE: At the beginning\nwhile your probabilities were of big Xn, that thing. That thing is the p-value.",
    "start": "2046078",
    "end": "2051847"
  },
  {
    "text": "PROFESSOR: That's\nthe p-value, right? That's the definition\nof the p-value. AUDIENCE: OK. ",
    "start": "2051848",
    "end": "2057604"
  },
  {
    "text": "PROFESSOR: So it's\nthe probability that my test statistic exceeds\nwhat I've actually observed.",
    "start": "2057604",
    "end": "2063835"
  },
  {
    "text": "AUDIENCE: So how you run\nthe test is basically you have your\nobservations and plug them",
    "start": "2063835",
    "end": "2069679"
  },
  {
    "text": "into the cumulative distribution\nfunction for a normal, and then see if it\nfalls under the given--",
    "start": "2069679",
    "end": "2075854"
  },
  {
    "text": "PROFESSOR: Yeah. So my p-value is\njust this number when I just plug in the\nvalues that I observe here.",
    "start": "2075854",
    "end": "2082429"
  },
  {
    "text": "That's one number. For every dataset\nyou're going to give me, it's going to be one number. Now what I can do is generate\na bunch of datasets of size n,",
    "start": "2082429",
    "end": "2091820"
  },
  {
    "text": "like 200 of them. And then I'm going\nto have a new sample of say 200, which is just\nthe sample of 200 p-values.",
    "start": "2091820",
    "end": "2099000"
  },
  {
    "text": "And I want to test if\nthose p-values have a uniform distribution. OK? Because that's the distribution\nthey should be having.",
    "start": "2099000",
    "end": "2105688"
  },
  {
    "text": "All right? ",
    "start": "2105688",
    "end": "2111130"
  },
  {
    "text": "OK. This one we've already seen. Does x have a PMF with\n30%, 50%, and 20%?",
    "start": "2111130",
    "end": "2118410"
  },
  {
    "text": "That's something I\ncould try to test. That looks like your grade point\ndistribution for this class.",
    "start": "2118410",
    "end": "2127260"
  },
  {
    "text": "Well not exactly, but\nthat looks like it. So all these things are known\nas goodness of fit tests.",
    "start": "2127260",
    "end": "2133039"
  },
  {
    "text": "The goodness of fit\ntest is something that you want to know if the\ndata that you have at hand",
    "start": "2133039",
    "end": "2138180"
  },
  {
    "text": "follows the hypothesized\ndistribution. So it's not a parametric test. It's not a test that says, is\nmy mean equal to 25 or not.",
    "start": "2138180",
    "end": "2146790"
  },
  {
    "text": "Is my proportion of heads\nlarger than 1/2 or not? It's something that\nsays, my distribution",
    "start": "2146790",
    "end": "2153494"
  },
  {
    "text": "this particular thing.  So I'm going to write them as\ngoodness of fit, G-O-F here.",
    "start": "2153494",
    "end": "2160690"
  },
  {
    "text": "You don't need to have\nparametric modeling to do that.  So how do I work?",
    "start": "2160690",
    "end": "2166760"
  },
  {
    "text": "So if I don't have any\nparametric modeling, I need to have something which\nis somewhat non-parametric,",
    "start": "2166760",
    "end": "2172430"
  },
  {
    "text": "something that goes\nbeyond computing the mean and the standard\ndeviation, something that computes some intrinsic\nnon-parametric aspect",
    "start": "2172430",
    "end": "2179900"
  },
  {
    "text": "of my data. And just like here we made\nthis computation, what we did is we said well,\nif I actually check",
    "start": "2179900",
    "end": "2188490"
  },
  {
    "text": "that the CDF of my data,\nthat my p-value is uniform,",
    "start": "2188490",
    "end": "2194340"
  },
  {
    "text": "then I know it's uniform. So it means that the cumulative\ndistribution function has an intrinsic value\nabout it that captures",
    "start": "2194340",
    "end": "2199850"
  },
  {
    "text": "the entire distribution. Everything I need to know\nabout my distribution is captured by the cumulative\ndistribution function.",
    "start": "2199850",
    "end": "2207320"
  },
  {
    "text": "Now I have an empirical\nway of computing, I have a data-driven\nway of computing an estimate for the cumulative\ndistribution function, which",
    "start": "2207320",
    "end": "2214849"
  },
  {
    "text": "is using the old\nstatistical trick which consists of replacing\nexpectations by averages.",
    "start": "2214850",
    "end": "2220190"
  },
  {
    "text": "So as I said, the cumulative\ndistribution function for any distribution, for\nany random variable, is--",
    "start": "2220190",
    "end": "2228440"
  },
  {
    "text": " so F of t is the\nprobability that X",
    "start": "2228440",
    "end": "2237610"
  },
  {
    "text": "is less than or\nequal to t, which is equal to the expectation\nof the indicator",
    "start": "2237610",
    "end": "2242630"
  },
  {
    "text": "that X is less\nthan or equal to t. That's the definition\nof a probability.",
    "start": "2242630",
    "end": "2248310"
  },
  {
    "text": "And so here I'm just going\nto replace expectation by the average.",
    "start": "2248310",
    "end": "2254390"
  },
  {
    "text": "That's my usual\nstatistical trick. And so my estimator Fn for--",
    "start": "2254390",
    "end": "2262980"
  },
  {
    "text": "the distribution is going\nto be 1 over n sum from i equal 1 to n of\nthese indicators.",
    "start": "2262980",
    "end": "2268422"
  },
  {
    "text": " And this is called\nthe empirical CDF.",
    "start": "2268423",
    "end": "2278780"
  },
  {
    "text": "It's just the data\nversion of the CDF. ",
    "start": "2278780",
    "end": "2284800"
  },
  {
    "text": "So I just replaced this\nexpectation here by an average. ",
    "start": "2284800",
    "end": "2293630"
  },
  {
    "start": "2292000",
    "end": "2366000"
  },
  {
    "text": "Now when I sum\nindicators, I'm actually counting the number of them\nthat satisfy something.",
    "start": "2293630",
    "end": "2300570"
  },
  {
    "text": "So if you look at\nwhat this guy is, this is the number of X i's\nthat is less than t, right?",
    "start": "2300570",
    "end": "2312820"
  },
  {
    "text": "And so if I divide by n, it's\nthe proportion of observations I have that are less than t. ",
    "start": "2312820",
    "end": "2321821"
  },
  {
    "text": "That's what the empirical\ndistribution is. ",
    "start": "2321821",
    "end": "2326920"
  },
  {
    "text": "That's what's written here,\nthe number of data points that are less than t.",
    "start": "2326920",
    "end": "2332080"
  },
  {
    "text": "And so this is going\nto be something that's sort of trying to\nestimate one or the other.",
    "start": "2332080",
    "end": "2337511"
  },
  {
    "text": "And the law of large\nnumber actually tells me that for any given t,\nif n is large enough, Fn of t",
    "start": "2337511",
    "end": "2343240"
  },
  {
    "text": "should be close to F of t. Because it's an average. And this entire thing, this\nentire statistical trick,",
    "start": "2343240",
    "end": "2350610"
  },
  {
    "text": "which consists of replacing\nexpectations by averages, is justified by the\nlaw of large number.",
    "start": "2350610",
    "end": "2356610"
  },
  {
    "text": "Every time we used it, that was\nbecause the law of large number sort of guaranteed to\nus that the average was close to the expectation.",
    "start": "2356610",
    "end": "2363057"
  },
  {
    "text": " OK. So law of large numbers tell\nme that Fn of t converges,",
    "start": "2363057",
    "end": "2370760"
  },
  {
    "start": "2366000",
    "end": "2417000"
  },
  {
    "text": "so that's the strong law, says\nthat almost surely actually Fn of t goes to F of t. ",
    "start": "2370760",
    "end": "2380470"
  },
  {
    "text": "And that's just for any given t. Is there any\nquestion about this?",
    "start": "2380470",
    "end": "2386650"
  },
  {
    "text": "That averages converge\nto expectation, that's the law of large number. ",
    "start": "2386650",
    "end": "2392690"
  },
  {
    "text": "And almost surely we\ncould say in probability it's the same, that would be\nthe weak law of large number. ",
    "start": "2392690",
    "end": "2400460"
  },
  {
    "text": "Now this is fine. For any given t, the average\nconverges to the true.",
    "start": "2400460",
    "end": "2405470"
  },
  {
    "text": "It just happens that this\nrandom variable is indexed by t, and I could do it for\nt equals 1 or 2 or 25,",
    "start": "2405470",
    "end": "2412460"
  },
  {
    "text": "and just check it again. But I might want to check\nit for all t's at once.",
    "start": "2412460",
    "end": "2418145"
  },
  {
    "start": "2417000",
    "end": "2457000"
  },
  {
    "text": "And that's actually\na different result. That's called a\nuniform result. I want this to hold for\nall t at the same time.",
    "start": "2418145",
    "end": "2425200"
  },
  {
    "text": "And it may be the case that it\nworks for each t individually but not for all t's\nat the same time.",
    "start": "2425200",
    "end": "2431200"
  },
  {
    "text": "What could happen is\nthat for t equals 1 it converges at a certain\nrate, and for t equals 2",
    "start": "2431200",
    "end": "2436326"
  },
  {
    "text": "it converges at a\nbit of a slower rate, and for t equals 3 at a\nslower rate and slower rate. And so as t goes to infinity,\nthe rate is going to vanish",
    "start": "2436326",
    "end": "2443770"
  },
  {
    "text": "and nothing is\ngoing to converge. That could happen. I could make this happen\nat a finite point. There's many ways where\nit could make this happen.",
    "start": "2443770",
    "end": "2450850"
  },
  {
    "text": "Let's see how that could work. I could say, well, actually no. I still need to have this\nat infinity for some reason.",
    "start": "2450850",
    "end": "2459115"
  },
  {
    "text": "It turns out that this\nis still true uniformly, and this is actually a much\nmore complicated result than the law of large number.",
    "start": "2459115",
    "end": "2465340"
  },
  {
    "text": "It's called\nGlivenko-Cantelli Theorem. And the\nGlivenko-Cantelli Theorem tells me that, for all t's\nat once, Fn converges to F.",
    "start": "2465340",
    "end": "2474960"
  },
  {
    "text": "So let me just show\nyou quickly why this is just a little\nbit stronger than the one",
    "start": "2474960",
    "end": "2482040"
  },
  {
    "text": "that we had. If sup is confusing\nyou, think of max.",
    "start": "2482040",
    "end": "2489119"
  },
  {
    "text": "It's just the max\nover an infinite set. And so what we know is\nthat Fn of t goes to F of t",
    "start": "2489120",
    "end": "2500500"
  },
  {
    "text": "as n goes to infinity. And that's almost surely.",
    "start": "2500500",
    "end": "2505560"
  },
  {
    "text": "And that's the law\nof large numbers. Which is equivalent to saying\nthat Fn of t minus F of t as n",
    "start": "2505560",
    "end": "2514920"
  },
  {
    "text": "goes to infinity converges\nalmost surely to 0, right? This is the same thing.",
    "start": "2514920",
    "end": "2521823"
  },
  {
    "text": "Now I want this to happen\nfor all t's at once.",
    "start": "2521823",
    "end": "2527217"
  },
  {
    "text": "So what I'm going to do--\noh, and this is actually equivalent to this. And so what I'm going\nto do is I'm going",
    "start": "2527217",
    "end": "2532840"
  },
  {
    "text": "to make it a little stronger. So here the arrow\nonly goes one way. And this is where the sup\nfor t in R of Fn of t.",
    "start": "2532840",
    "end": "2540660"
  },
  {
    "start": "2540660",
    "end": "2546847"
  },
  {
    "text": "And you could actually\nshow that this happens also almost surely. ",
    "start": "2546847",
    "end": "2555500"
  },
  {
    "start": "2554000",
    "end": "2860000"
  },
  {
    "text": "Now maybe almost\nsurely is a bit more difficult to get a grasp on. ",
    "start": "2555500",
    "end": "2563560"
  },
  {
    "text": "Does anybody want to see, like\nwhy this statement for this sup",
    "start": "2563560",
    "end": "2568630"
  },
  {
    "text": "is strictly stronger than the\none that holds individually for all t's? You want to see that?",
    "start": "2568630",
    "end": "2574086"
  },
  {
    "text": "OK, so let's do that. So forget about it almost\nsurely for one second. Let's just do it in probability.",
    "start": "2574086",
    "end": "2579660"
  },
  {
    "text": "The fact that Fn of t\nconverges to F of t for all t,",
    "start": "2579660",
    "end": "2589690"
  },
  {
    "text": "in probability means that\nthis goes to 0 as n goes to infinity for any epsilon. ",
    "start": "2589690",
    "end": "2597400"
  },
  {
    "text": "For any epsilon in t\nwe know we have this. That's the convergence\nin probability.",
    "start": "2597400",
    "end": "2602528"
  },
  {
    "text": "Now what I want is\nto put a sup here. ",
    "start": "2602529",
    "end": "2608408"
  },
  {
    "text": "The probability that the\nsup is lower than epsilon, might be actually always\nlarger than, never go to 0",
    "start": "2608408",
    "end": "2618079"
  },
  {
    "text": "in some cases. It could be the case\nthat for each given t, I can make n large enough so\nthat this probability becomes",
    "start": "2618080",
    "end": "2626440"
  },
  {
    "text": "small. But then maybe it's an n of t. So this here means\nthat for any--",
    "start": "2626440",
    "end": "2633750"
  },
  {
    "text": "maybe I shouldn't put,\nlet me put a delta here. So for any epsilon, for\nany t and for any epsilon,",
    "start": "2633750",
    "end": "2642460"
  },
  {
    "text": "there exists n, which could\ndepend on both epsilon",
    "start": "2642460",
    "end": "2649800"
  },
  {
    "text": "and t, such that the\nprobability that Fn t",
    "start": "2649800",
    "end": "2655920"
  },
  {
    "text": "minus F of t exceeding delta\nis less than epsilon t.",
    "start": "2655920",
    "end": "2665109"
  },
  {
    "text": "There exists an n and a delta. No, that's for all delta, sorry.",
    "start": "2665110",
    "end": "2670599"
  },
  {
    "text": " So this is true.",
    "start": "2670600",
    "end": "2676100"
  },
  {
    "text": "That's what this limit\nstatement actually means. But it could be the case that\nnow when I take the sup over t,",
    "start": "2676100",
    "end": "2683060"
  },
  {
    "text": "maybe that n of t is\nsomething that looks like t. ",
    "start": "2683060",
    "end": "2690480"
  },
  {
    "text": "Or maybe, well,\ninteger part of t. It could be, right?",
    "start": "2690480",
    "end": "2696175"
  },
  {
    "text": "I don't say anything. It's just an n\nthat depends on t. So if this n is just t,\nmaybe t over epsilon,",
    "start": "2696175",
    "end": "2704730"
  },
  {
    "text": "because I want epsilon. Something like this. Well that means\nthat if I want this to hold for all t's\nat once, I'm going",
    "start": "2704730",
    "end": "2711510"
  },
  {
    "text": "to have to go for the n that\nworks for all t's at once. But there's no such n that\nworks for all t's at once.",
    "start": "2711510",
    "end": "2719070"
  },
  {
    "text": "The only n that\nworks is infinity. And so I cannot make this\nhappen for all of them.",
    "start": "2719070",
    "end": "2724350"
  },
  {
    "text": "What Glivenko-Cantelli\ntells you, it's actually this is not\nsomething that holds like this. That the n that depends on t,\nthere's actually one largest n",
    "start": "2724350",
    "end": "2733650"
  },
  {
    "text": "that works for all the t's\nat once, and that's it. ",
    "start": "2733650",
    "end": "2739451"
  },
  {
    "text": "OK. So just so you know why this is\nactually a stronger statement, and that's basically\nhow it works.",
    "start": "2739451",
    "end": "2748880"
  },
  {
    "text": "Any other question? Yeah. AUDIENCE: So what's\nthe position for this to have, because the\nrandom variable have",
    "start": "2748880",
    "end": "2754979"
  },
  {
    "text": "a finite mean, finite variance? PROFESSOR: No. Well the random variable\ndoes have finite mean",
    "start": "2754979",
    "end": "2760580"
  },
  {
    "text": "and finite variance,\nbecause the random variable is an indicator. So it has everything you want. This is one of the\nnicest random variables,",
    "start": "2760580",
    "end": "2766621"
  },
  {
    "text": "this is a Bernoulli\nrandom variable. So here when I say law of\nlarge number, that this holds.",
    "start": "2766621",
    "end": "2771952"
  },
  {
    "text": "Where did I write this? I think I erased it. Yeah, the one over there. This is actually the\nlaw of large numbers for Bernoulli random variables.",
    "start": "2771952",
    "end": "2777680"
  },
  {
    "text": "They have everything you want. They're bounded. Yes. AUDIENCE: So I'm having\ntrouble understanding",
    "start": "2777680",
    "end": "2783989"
  },
  {
    "text": "the first statement. So it says, for all\nepsilon and all t, the probability of that--",
    "start": "2783989",
    "end": "2789540"
  },
  {
    "text": "PROFESSOR: So you mean this one? AUDIENCE: Yeah. PROFESSOR: For all\nepsilon and all t.",
    "start": "2789540",
    "end": "2794760"
  },
  {
    "text": "So you fix them now. Then the probability that,\nsorry, that was delta. I changed this epsilon\nto delta at some point.",
    "start": "2794760",
    "end": "2801694"
  },
  {
    "text": "AUDIENCE: And then\nwhat's the second line? PROFESSOR: Oh, so then\nthe second line says that,",
    "start": "2801694",
    "end": "2809859"
  },
  {
    "text": "so I'm just rewriting in\nterms of epsilon delta what this n goes\nto infinity means.",
    "start": "2809860",
    "end": "2816360"
  },
  {
    "text": "So it means that for\nany a t and delta,",
    "start": "2816360",
    "end": "2821880"
  },
  {
    "text": "so that's the same\nas this guy here, then here I'm just going\nback to rewriting this. It says that for any epsilon\nthere exists an n large",
    "start": "2821880",
    "end": "2828450"
  },
  {
    "text": "enough such that, well,\nn larger than this thing basically, such that this\nthing is less than epsilon.",
    "start": "2828450",
    "end": "2834369"
  },
  {
    "text": " So Glivenko-Cantelli tells us\nthat not only is this thing",
    "start": "2834370",
    "end": "2841420"
  },
  {
    "text": "a good idea pointwise, but it's\nalso a good idea uniformly. And all it's saying\nis if you actually",
    "start": "2841420",
    "end": "2847690"
  },
  {
    "text": "were happy with just\nthis result, you should be even happier\nwith that result. And both of those results\nonly tell you one thing.",
    "start": "2847690",
    "end": "2854570"
  },
  {
    "text": "They're just telling you\nthat the empirical CDF is a good estimator of the CDF. ",
    "start": "2854570",
    "end": "2861600"
  },
  {
    "start": "2860000",
    "end": "2974000"
  },
  {
    "text": "Now since those indicators\nare Bernoulli distributions,",
    "start": "2861600",
    "end": "2867720"
  },
  {
    "text": "I can actually do even more. So let me get this guy here. ",
    "start": "2867720",
    "end": "2880240"
  },
  {
    "text": "OK so, those guys,\nFn of t, this guy",
    "start": "2880240",
    "end": "2894220"
  },
  {
    "text": "is a Bernoulli distribution. What is the parameter of\nthis Bernoulli distribution?",
    "start": "2894220",
    "end": "2900494"
  },
  {
    "text": "What is the probability\nthat it takes value 1? ",
    "start": "2900494",
    "end": "2906250"
  },
  {
    "text": "AUDIENCE: F of t. PROFESSOR: F of t, right? It's just the probability\nthat this thing happens, which is F of t. ",
    "start": "2906250",
    "end": "2914020"
  },
  {
    "text": "So in particular the\nvariance of this guy",
    "start": "2914020",
    "end": "2920650"
  },
  {
    "text": "is the variance\nof this Bernoulli. So it's F of t 1 minus F of t.",
    "start": "2920650",
    "end": "2926730"
  },
  {
    "text": "And I can use that in my\nCentral Limit Theorem. And Central Limit\nTheorem is just",
    "start": "2926730",
    "end": "2931760"
  },
  {
    "text": "going to tell me that\nif I look at the average of random variables,\nI remove their mean, so I look at square\nroot of n Fn of t,",
    "start": "2931760",
    "end": "2941000"
  },
  {
    "text": "which I could really\nwrite as xn bar, right? That's really just an xn bar.",
    "start": "2941000",
    "end": "2946730"
  },
  {
    "text": "Minus the expectation,\nwhich is F of t, that comes from this guy. Now if I divide by square\nroot of the variance, that's",
    "start": "2946730",
    "end": "2956000"
  },
  {
    "text": "my square root p1 minus p. Then this guy, by the\nCentral Limit Theorem,",
    "start": "2956000",
    "end": "2962540"
  },
  {
    "text": "goes to some N 0, 1.  Which is the same\nthing as you see there,",
    "start": "2962540",
    "end": "2968740"
  },
  {
    "text": "except that the variance\nwas put on the other side. ",
    "start": "2968740",
    "end": "2974850"
  },
  {
    "start": "2974000",
    "end": "3091000"
  },
  {
    "text": "OK. Do I have the same\nthing uniformly in t?",
    "start": "2974850",
    "end": "2982422"
  },
  {
    "text": " Can I write something\nthat holds uniformly in t?",
    "start": "2982422",
    "end": "2988630"
  },
  {
    "text": "Well, if you think\nabout it for one second it's unlikely it's\ngoing to go too well. In the sense that it's\nunlikely that the supremum",
    "start": "2988630",
    "end": "2995650"
  },
  {
    "text": "of those random variables over t\nis going to also be a Gaussian. ",
    "start": "2995650",
    "end": "3002800"
  },
  {
    "text": "And the reason is that,\nwell actually the reason",
    "start": "3002800",
    "end": "3008120"
  },
  {
    "text": "is that this thing is actually\na stochastic process indexed by t. A stochastic process is just\na sequence in random variables",
    "start": "3008120",
    "end": "3014869"
  },
  {
    "text": "that's indexed by,\nlet's say time. The one that's the most\nfamous is Brownian motion,",
    "start": "3014870",
    "end": "3020030"
  },
  {
    "text": "and it's basically a bunch\nof Gaussian increments. So when you go from t to\njust t a little after that,",
    "start": "3020030",
    "end": "3027170"
  },
  {
    "text": "you have add some\nGaussian into the thing. And here it's basically the\nsame thing that's happening.",
    "start": "3027170",
    "end": "3033770"
  },
  {
    "text": "And you would sort of expect,\nsince each of this guy is Gaussian, you\nwould expect to see something that looks like a\nBrownian motion at the end.",
    "start": "3033770",
    "end": "3040005"
  },
  {
    "text": "But it's not exactly\na Brownian motion, it's something that's\ncalled the Brownian bridge. So if you've seen the\nBrownian motion, if I make",
    "start": "3040005",
    "end": "3045920"
  },
  {
    "text": "it start at 0 for example,\nso this is the value of my Brownian motion. Let's write it.",
    "start": "3045920",
    "end": "3052110"
  },
  {
    "text": "So this is one path, one\nrealization of Brownian motion. Let's call it w of\nt as t increases.",
    "start": "3052110",
    "end": "3059350"
  },
  {
    "text": "So let's say it starts at 0 and\nlooks like something like this.",
    "start": "3059350",
    "end": "3064430"
  },
  {
    "text": "So that's what Brownian\nmotion looks like. It's just something\nthat's pretty nasty.",
    "start": "3064430",
    "end": "3071010"
  },
  {
    "text": "I mean it looks pretty nasty,\nit's not continuous et cetera, but it's actually very\nbenign in some average way.",
    "start": "3071010",
    "end": "3079109"
  },
  {
    "text": "So Brownian motion\nis just something, you should view this as if I\nsum some random variable that",
    "start": "3079110",
    "end": "3085819"
  },
  {
    "text": "are Gaussian, and then I look at\nthis from farther and farther, it's going to look like this.",
    "start": "3085820",
    "end": "3091980"
  },
  {
    "start": "3091000",
    "end": "3235000"
  },
  {
    "text": "And so here I cannot have\na Brownian motion in the n, because what is the variance\nof Fn of t minus F of t at t is",
    "start": "3091980",
    "end": "3100030"
  },
  {
    "text": "equal to 1?  Sorry, at t is\nequal to infinity.",
    "start": "3100030",
    "end": "3107890"
  },
  {
    "text": "AUDIENCE: 0. PROFESSOR: It's 0, right? The variance goes from 0\nat t is negative infinity, because at negative infinity\nF of t is going to 0.",
    "start": "3107890",
    "end": "3116940"
  },
  {
    "text": "And as t goes to\nplus infinity, F of t is going to 1, which means that\nthe variance of this guy as t",
    "start": "3116940",
    "end": "3123590"
  },
  {
    "text": "goes from negative\ninfinity to plus infinity is pinned to be 0 on each side.",
    "start": "3123590",
    "end": "3129990"
  },
  {
    "text": "And so my Brownian\nmotion cannot, when I describe a Brownian\nmotion I'm just adding more and more entropy to the\nthing and it's going all over",
    "start": "3129990",
    "end": "3136880"
  },
  {
    "text": "the place, but here what I want\nis that as I go back it should go back to essentially 0.",
    "start": "3136880",
    "end": "3141920"
  },
  {
    "text": "It should be pinned down to\na specific value at the n. And that's actually called\nthe Brownian bridge.",
    "start": "3141920",
    "end": "3147322"
  },
  {
    "text": "It's a Brownian motion\nthat's conditioned to come back to where\nit started essentially.",
    "start": "3147322",
    "end": "3152546"
  },
  {
    "text": "Now you don't need to understand\nBrownian bridges to understand what I'm going to\nbe telling you. The only thing I want\nto communicate to you",
    "start": "3152546",
    "end": "3159040"
  },
  {
    "text": "is that this guy here, when\nI say a Brownian bridge, I can go to any probabilist\nand they can tell you",
    "start": "3159040",
    "end": "3165010"
  },
  {
    "text": "all the probability properties\nof this stochastic process.",
    "start": "3165010",
    "end": "3171167"
  },
  {
    "text": "It can tell me the\nprobability that it takes any value at any point. In particular, it can tell me--",
    "start": "3171167",
    "end": "3177370"
  },
  {
    "text": "the supremum between\n0 and 1 of this guy, it could tell me what the\ncumulative distribution",
    "start": "3177370",
    "end": "3183230"
  },
  {
    "text": "function of this\nthing is, can tell me what the density of this thing\nis, can tell me everything. So it means that if I want\nto compute probabilities",
    "start": "3183230",
    "end": "3189710"
  },
  {
    "text": "on this object here, which is\nthe maximum value that this guy can take over a certain period\nof time, which is basically",
    "start": "3189710",
    "end": "3197565"
  },
  {
    "text": "this random variable. So if I look at the\nvalue here, it's a random variable\nthat fluctuates. It can tell me where it is\nwith hyperability, can tell me",
    "start": "3197565",
    "end": "3205160"
  },
  {
    "text": "the quantiles of this\nthing, which is useful because I can build a table and\nuse it to compute my quantiles",
    "start": "3205160",
    "end": "3211440"
  },
  {
    "text": "and form tests from it. So that's what\nactually is quite nice. It says that if I look at\nthe square root of n Fn",
    "start": "3211440",
    "end": "3218170"
  },
  {
    "text": "hat minus sup over\nt, I get something that looks like the\nsup of these Gaussians, but it's not really\nsup of Gaussian,",
    "start": "3218170",
    "end": "3224290"
  },
  {
    "text": "it's sup of a Brownian motion. Now there's something you\nshould be very careful here. I cheated a little bit. I mean, I didn't cheat,\nI can do whatever I want.",
    "start": "3224290",
    "end": "3231251"
  },
  {
    "text": "But my notation might\nbe a little confusing. Everybody sees that this t here\nis not the same as this t here?",
    "start": "3231251",
    "end": "3241869"
  },
  {
    "start": "3235000",
    "end": "3409000"
  },
  {
    "text": "Can somebody see that? Just because, first of all,\nthis guy's between 0 and 1. And this guy is in all of R.",
    "start": "3241870",
    "end": "3249550"
  },
  {
    "text": "What is this t here? As a function of this t here? ",
    "start": "3249550",
    "end": "3261270"
  },
  {
    "text": "This guy is F of this guy. So really, if I want it to\nbe completely transparent",
    "start": "3261270",
    "end": "3267790"
  },
  {
    "text": "and not save the\nkeys of my keyboard, I would read this as sup\nover t of Fn t minus F of t",
    "start": "3267790",
    "end": "3282460"
  },
  {
    "text": "goes to N distribution\nas n goes to infinity. The supremum over t,\nagain in R, so this guy is",
    "start": "3282460",
    "end": "3290440"
  },
  {
    "text": "for t in the entire\nreal line, this guy is for t in the\nentire real line. But now I should\nwrite b of what?",
    "start": "3290440",
    "end": "3298440"
  },
  {
    "text": "F of t, exactly. So really the t here is\nF of the original one.",
    "start": "3298440",
    "end": "3304150"
  },
  {
    "text": "And so that's a\nBrownian bridge, where when t goes to infinity\nthe Brownian bridge",
    "start": "3304150",
    "end": "3309870"
  },
  {
    "text": "goes from 0 to 1 and\nit looks like this. A Brownian bridge at\n0 is 0, at 1 it's 0.",
    "start": "3309870",
    "end": "3316099"
  },
  {
    "text": "And it does this. But it doesn't stray too\nfar because I condition it to come back to this point.",
    "start": "3316100",
    "end": "3322860"
  },
  {
    "text": "That's what a\nBrownian bridge is. OK.",
    "start": "3322860",
    "end": "3328450"
  },
  {
    "text": "So in particular, I can find\na distribution for this guy.",
    "start": "3328450",
    "end": "3333526"
  },
  {
    "text": "And I can use this to build\na test which is called the Kolmogorov-Smirnov test. ",
    "start": "3333527",
    "end": "3339810"
  },
  {
    "text": "The idea is the following. It says, if I want to\ntest some distribution",
    "start": "3339810",
    "end": "3344875"
  },
  {
    "text": "F0, some distribution that\nhas a particular CDF F0, and I plug it in\nunder the null, then",
    "start": "3344875",
    "end": "3352359"
  },
  {
    "text": "this guy should have pretty\nmuch the same distribution as the supremum of\nBrownian bridge.",
    "start": "3352360",
    "end": "3358089"
  },
  {
    "text": "And so if I see this to be\nmuch larger than it should be when it's the supremum\nof a Brownian bridge, I'm actually going to\nreject my hypothesis.",
    "start": "3358090",
    "end": "3365020"
  },
  {
    "text": " So here's the test. I want to test whether\nH0, F is equal to F0,",
    "start": "3365020",
    "end": "3377100"
  },
  {
    "text": "and you will see that most\nof the goodness of fit tests",
    "start": "3377100",
    "end": "3382850"
  },
  {
    "text": "are formulated\nmathematically in terms of the cumulative\ndistribution function. I could formulate them in\nterms of personality density",
    "start": "3382850",
    "end": "3389599"
  },
  {
    "text": "function, or just\nwrite x follows N 0, 1, but that's the way we write it.",
    "start": "3389600",
    "end": "3394950"
  },
  {
    "text": "We formulate them in terms\nof cumulative distribution function because\nthat's what we have a handle on through the\nempirical cumulative",
    "start": "3394950",
    "end": "3402319"
  },
  {
    "text": "distribution function. And then it's versus H1,\nF is not equal to F0.",
    "start": "3402320",
    "end": "3410300"
  },
  {
    "start": "3409000",
    "end": "3600000"
  },
  {
    "text": "So now I have my empirical CDF. And I hope that for\nall t's, Fn of t should be close to F0 of t.",
    "start": "3410300",
    "end": "3417900"
  },
  {
    "text": "Let me write it like this. I put it on the exponent\nbecause otherwise that",
    "start": "3417900",
    "end": "3423740"
  },
  {
    "text": "would be the empirical\ndistribution function based on zero observations. ",
    "start": "3423740",
    "end": "3431060"
  },
  {
    "text": "Now I form the following\ntest statistic. ",
    "start": "3431060",
    "end": "3441450"
  },
  {
    "text": "So my test statistic\nis tn, which is the supremum over t in\nthe real line of square root",
    "start": "3441450",
    "end": "3448120"
  },
  {
    "text": "of n Fn of t minus F\nof t, sorry, F0 of t.",
    "start": "3448120",
    "end": "3454494"
  },
  {
    "text": "So I can compute everything. I know this from\nthe data, and this is the one that comes\nfrom my null hypothesis.",
    "start": "3454494",
    "end": "3459930"
  },
  {
    "text": "As I can compute this thing. And I know that if\nthis is true, this should actually be the\nsupremum of a Brownian bridge.",
    "start": "3459930",
    "end": "3466180"
  },
  {
    "text": "Pretty much. And so the Kolmogorov-Smirnov\ntest is simply,",
    "start": "3466180",
    "end": "3481619"
  },
  {
    "text": "reject if this guy,\ntn, in absolute value,",
    "start": "3481620",
    "end": "3489080"
  },
  {
    "text": "no actually not\nin absolute value. This is just already\nabsolute valued. Then this guy should be what?",
    "start": "3489080",
    "end": "3494960"
  },
  {
    "text": "It should be larger than the\nq alpha over 2 distribution",
    "start": "3494960",
    "end": "3500580"
  },
  {
    "text": "that I have. But now rather than\nputting N 0, 1, or Tn, this is here whatever\nnotation I have for supremum",
    "start": "3500580",
    "end": "3510016"
  },
  {
    "text": "of Brownian bridge. ",
    "start": "3510016",
    "end": "3520859"
  },
  {
    "text": "Just like I did for any\npivotal distribution. That was the same recipe\nevery single time.",
    "start": "3520860",
    "end": "3525900"
  },
  {
    "text": "I formed the test\nstatistic such that the asymptotic distribution did\nnot depend on anything I know,",
    "start": "3525900",
    "end": "3531330"
  },
  {
    "text": "and then I would just reject\nwhen this pivotal distribution was larger than something. Yes?",
    "start": "3531330",
    "end": "3536845"
  },
  {
    "text": "AUDIENCE: I'm not really sure\nwhy Brownian bridge appears. ",
    "start": "3536845",
    "end": "3542900"
  },
  {
    "text": "PROFESSOR: Do you know what\na Brownian bridge is, or? AUDIENCE: Only vaguely. PROFESSOR: OK. So this thing here, think\nof it as being a Gaussian.",
    "start": "3542900",
    "end": "3554320"
  },
  {
    "text": "So for all t you have a\nGaussian distribution. Now a Brownian motion, so\nif I had a Brownian motion",
    "start": "3554320",
    "end": "3567270"
  },
  {
    "text": "I need to tell you what the-- so it's basically\na Brownian motion is something that\nlooks like this. It's some random variable\nthat's indexed by t.",
    "start": "3567270",
    "end": "3574180"
  },
  {
    "text": "I want, say, the expectation\nof Xt could be equal to 0 for all t.",
    "start": "3574180",
    "end": "3580640"
  },
  {
    "text": "And what I want is\nthat the increments have a certain distribution. So what I want is that the\nexpectation of Xt minus Xs",
    "start": "3580640",
    "end": "3593700"
  },
  {
    "text": "follows some distribution\nwhich is N 0, t minus s. So the increments are\nbigger as I go farther,",
    "start": "3593700",
    "end": "3600750"
  },
  {
    "text": "in terms of variability. And I also want some covariance\nstructure between the two.",
    "start": "3600750",
    "end": "3605880"
  },
  {
    "text": "So what I want is that the\ncovariance between Xs and Xt is actually equal to\nthe minimum of s and t.",
    "start": "3605880",
    "end": "3612750"
  },
  {
    "start": "3612750",
    "end": "3618520"
  },
  {
    "text": "Yeah, maybe. Yeah, that should be there. So this is, you open a\nprobability book, that's",
    "start": "3618520",
    "end": "3626040"
  },
  {
    "text": "what it's going to look like. So in particular, you\ncan see, if I put 0 here",
    "start": "3626040",
    "end": "3631710"
  },
  {
    "text": "and X0 is equal to\n0, it has 0 variance. So in particular,\nit means that Xt,",
    "start": "3631710",
    "end": "3638180"
  },
  {
    "text": "if I look only at\nthe t-th one, it has some normal distribution\nwith variance t. So this is something\nthat just blows up.",
    "start": "3638180",
    "end": "3646050"
  },
  {
    "text": "So this guy here\nlooks like it's going to be a Brownian\nmotion because when I look at the left-hand side\nit has a normal distribution.",
    "start": "3646050",
    "end": "3653700"
  },
  {
    "text": "Now there's a bunch of other\nthings you need to check. It's the fact that you have\nthis covariance, for example, which I did not tell you.",
    "start": "3653700",
    "end": "3660089"
  },
  {
    "text": "But it sure look\nsomewhat like that. And in particular, when I\nlook at the normal with mean 0",
    "start": "3660090",
    "end": "3667590"
  },
  {
    "text": "and variance here,\nthen it's clear that this guy does not\nhave a variance that's going to go to infinity just\nlike the variance of this guy.",
    "start": "3667590",
    "end": "3676559"
  },
  {
    "text": "We know that the variance\nis forced to be back to 0.",
    "start": "3676560",
    "end": "3681620"
  },
  {
    "text": "And so in particular\nwe have something that has mean 0 always, whose\nvariance has to be 0 at 0,",
    "start": "3681620",
    "end": "3688270"
  },
  {
    "text": "and variance-- sorry, at t\nequals negative infinity, and variance 1 at t\nequals plus infinity.",
    "start": "3688270",
    "end": "3694890"
  },
  {
    "text": "So a variance 0 at t\nequals plus infinity, and so I have to basically force\nit to be equal to 0 at each n.",
    "start": "3694890",
    "end": "3700420"
  },
  {
    "text": "So the Brownian\nmotion here tends to just go to\ninfinity somewhere, whereas this guy\nforces it to come back.",
    "start": "3700420",
    "end": "3707110"
  },
  {
    "text": "Now everything I\ndescribed to you is on the scale negative\ninfinity to plus infinity,",
    "start": "3707110",
    "end": "3712720"
  },
  {
    "text": "but since everything\ndepends on F of t, I can actually\njust put that back",
    "start": "3712720",
    "end": "3718360"
  },
  {
    "text": "into a scale, which is 0 and 1\nby a simple change of variable. It's called change of time\nfor the Brownian motion.",
    "start": "3718360",
    "end": "3726814"
  },
  {
    "text": "OK? Yeah. AUDIENCE: So does\na Brownian bridge have a variance at each\npoint that's proportional?",
    "start": "3726814",
    "end": "3733242"
  },
  {
    "text": "Like it starts at\n0 variance and then goes to 1/4 variance\nin the middle and then goes back\nto 0 variance?",
    "start": "3733242",
    "end": "3741146"
  },
  {
    "text": "Like in the same\nparabolic shape? PROFESSOR: Yeah. I mean, definitely.",
    "start": "3741146",
    "end": "3746180"
  },
  {
    "text": "I mean by symmetry you can\nprobably infer all the things. AUDIENCE: Well I can\nimagine Brownian bridge",
    "start": "3746180",
    "end": "3751706"
  },
  {
    "text": "with a variance that starts\nat 0 and stays, like, the shape of the variance\nas you move along.",
    "start": "3751706",
    "end": "3758809"
  },
  {
    "text": "PROFESSOR: Yeah, so I\ndon't know if-- there is an explicit formula\nfor this, and it's simple. That's what I can tell you, but\nI don't know what the explicit,",
    "start": "3758809",
    "end": "3765830"
  },
  {
    "text": "off the top of my head what\nthe explicit formula is. AUDIENCE: But would it\nhave to match this F of t 1 minus F of t structure?",
    "start": "3765830",
    "end": "3773112"
  },
  {
    "text": "Or not? PROFESSOR: Yeah.  AUDIENCE: Or does the fact that\nwe're taking the supremum--",
    "start": "3773112",
    "end": "3778510"
  },
  {
    "text": "PROFESSOR: No. Well the Brownian bridge, this\nis the supremum-- you're right. So this will be this form\nfor the variance for sure,",
    "start": "3778510",
    "end": "3786700"
  },
  {
    "text": "because this is only\nmarginal distributions that don't take-- right,\nthe process is not just what is the distribution\nat each instant t.",
    "start": "3786700",
    "end": "3793359"
  },
  {
    "text": "It's also how do those\ndistributions interact with each other in\nterms of covariance. For the marginal distributions\nat each instance t,",
    "start": "3793360",
    "end": "3799740"
  },
  {
    "text": "you're right, the variance\nis F of t 1 minus F of t. We're not going to escape that.",
    "start": "3799740",
    "end": "3805170"
  },
  {
    "text": "But then the covariance\nstructure between those guys is a little more complicated. But yes, you're right.",
    "start": "3805170",
    "end": "3810330"
  },
  {
    "text": "For marginal that's enough. Yeah? AUDIENCE: So the supremum\nof the Brownian bridge is a number between 0\nand 10, let's just say.",
    "start": "3810330",
    "end": "3818180"
  },
  {
    "text": "PROFESSOR: Yeah, it\ncould be infinity. AUDIENCE: So it's not\nsymmetrical with respect to 0,",
    "start": "3818180",
    "end": "3823225"
  },
  {
    "text": "so why are we doing all over 2? ",
    "start": "3823226",
    "end": "3836170"
  },
  {
    "text": "PROFESSOR: OK. Did say raise it? Yeah. Because here I didn't say the\nsupremum of the absolute value",
    "start": "3836170",
    "end": "3841974"
  },
  {
    "text": "of a Brownian bridge, I\njust said the supremum of a Brownian bridge. But you're right, let's\njust do this like that.",
    "start": "3841974",
    "end": "3848640"
  },
  {
    "text": "And then it's probably cleaner. ",
    "start": "3848640",
    "end": "3854580"
  },
  {
    "text": "So yeah, actually well\nit should be q alpha. So this is basically,\nyou're right.",
    "start": "3854580",
    "end": "3859630"
  },
  {
    "text": "So think of it as\nbeing one-sided. And there's actually no\nsymmetry for the supremum.",
    "start": "3859630",
    "end": "3865960"
  },
  {
    "text": "I mean the supremum is\nnot symmetric around 0, so you're right. I should not use alpha\nover 2, thank you.",
    "start": "3865960",
    "end": "3873630"
  },
  {
    "text": "Any other question? This should be alpha. Yeah. I mean those slides were\nwritten with 1 minus alpha",
    "start": "3873630",
    "end": "3879940"
  },
  {
    "text": "and I have not replaced all\ninstances of 1 minus alpha by alpha. I mean, except this guy, tilde.",
    "start": "3879940",
    "end": "3885392"
  },
  {
    "text": "Well, depends on how\nyou want to call it. But this is still, the\nprobability that Z exceeds",
    "start": "3885392",
    "end": "3890520"
  },
  {
    "text": "this guy should be alpha. OK? And this can be found in tables.",
    "start": "3890520",
    "end": "3895910"
  },
  {
    "text": "And we can compute the p-value\njust like we did before. But we have to simulate\nit because it's not",
    "start": "3895910",
    "end": "3902320"
  },
  {
    "text": "going to depend on the\ncumulative distribution function of a Gaussian, like\nit did for the usual Gaussian test.",
    "start": "3902320",
    "end": "3907740"
  },
  {
    "text": "That's something that's\nmore complicated, and typically you\ndon't even try. You get the statistical\nsoftware to do it for you.",
    "start": "3907740",
    "end": "3914210"
  },
  {
    "text": "So just let me skip a few lines. This is what the table looks\nlike for the Kolmogorov-Smirnov",
    "start": "3914210",
    "end": "3920150"
  },
  {
    "text": "test. So it just tells you, what is\nyour number of observations, n.",
    "start": "3920150",
    "end": "3925690"
  },
  {
    "text": "Then you want alpha to\nbe equal to 5%, say. Let's say you have\nnine observations. So if square root of n absolute\nvalue of Fn of t minus F of t",
    "start": "3925690",
    "end": "3934240"
  },
  {
    "text": "exceeds this thing, you reject. ",
    "start": "3934240",
    "end": "3946060"
  },
  {
    "text": "Well it's pretty\nclear from this test is that it looks\nvery nice, and I tell you this is how you build it. But if you think about\nit for one second,",
    "start": "3946060",
    "end": "3952577"
  },
  {
    "text": "it's actually really\nan annoying thing to build because you have\nto take the supremum over t.",
    "start": "3952577",
    "end": "3957760"
  },
  {
    "text": "This depends on computing a\nsupremum, which in practice might be super cumbersome.",
    "start": "3957760",
    "end": "3963069"
  },
  {
    "text": "I don't want to have to\ncompute this for all values t and then to take the\nmaximum of those guys. It turns out that that's\nactually quite nice that we",
    "start": "3963070",
    "end": "3969950"
  },
  {
    "text": "don't have to actually do this. What does the empirical\ndistribution function look like?",
    "start": "3969950",
    "end": "3975474"
  },
  {
    "text": "Well, this thing, remember\nFn of t by definition was--",
    "start": "3975474",
    "end": "3983350"
  },
  {
    "text": "so let me go to the\nslide that's relevant. So Fn of t looks like this. ",
    "start": "3983350",
    "end": "3998320"
  },
  {
    "text": "So what it means is that when\nt is between two observations, then this guy is actually\nkeeping the same value.",
    "start": "3998320",
    "end": "4004390"
  },
  {
    "text": "So if I put my observations\non the real line here. So let's say I have\none observation here,",
    "start": "4004390",
    "end": "4009940"
  },
  {
    "text": "one observation here,\none observation here, one observation here,\nand one observation here, for simplicity.",
    "start": "4009940",
    "end": "4015270"
  },
  {
    "text": "Then this guy is basically,\nup to this normalization, counting how many observations\nthey have that are less than t.",
    "start": "4015270",
    "end": "4021820"
  },
  {
    "text": "So since I normalize by n, I\nknow that the smallest number here is going to be 0, and\nthe largest number here",
    "start": "4021820",
    "end": "4030480"
  },
  {
    "text": "is going to be 1. So let's say this\nlooks like this. This is the value 1.",
    "start": "4030480",
    "end": "4038290"
  },
  {
    "text": "At the value, since I take\nit less than or equal to, when I'm at Xi, I'm\nactually counting it.",
    "start": "4038290",
    "end": "4044530"
  },
  {
    "text": "So the jump happens at Xi. So that's the first\nobservation, and then I jump. By how much do I jump?",
    "start": "4044530",
    "end": "4050860"
  },
  {
    "text": " Yeah? One over n, right?",
    "start": "4050860",
    "end": "4058670"
  },
  {
    "text": "And then this value\nbelongs to the right. And then I do it again. ",
    "start": "4058670",
    "end": "4070849"
  },
  {
    "text": "I know it's not going to work\nout for me, but we'll see. Oh no actually, I\ndid pretty well.",
    "start": "4070850",
    "end": "4075950"
  },
  {
    "text": " This is what my cumulative\ndistribution looks like.",
    "start": "4075950",
    "end": "4084130"
  },
  {
    "text": "Now if you look on\nthis slide, there is this weird notation\nwhere I start putting now my indices in parentheses.",
    "start": "4084130",
    "end": "4090390"
  },
  {
    "text": "X parenthesis 1, X\nparenthesis 2, et cetera. Those are called the\nordered statistic.",
    "start": "4090390",
    "end": "4095910"
  },
  {
    "text": "It's just because it might\nbe, when my data is given to me I just call the\nfirst observation, the one that's on\ntop of the table,",
    "start": "4095910",
    "end": "4101880"
  },
  {
    "text": "but it doesn't have to\nbe the smallest value. So it might be that this\nis X1 and that this is X2,",
    "start": "4101880",
    "end": "4108028"
  },
  {
    "text": "and then this is X3, X4, and X5. These might be my observations.",
    "start": "4108029",
    "end": "4113373"
  },
  {
    "text": "So what I do is that I\ncall them in such a way that this is actually,\nI recall this guy X1, which is just really X3.",
    "start": "4113374",
    "end": "4120568"
  },
  {
    "text": "This is X2, X3, X4, and X5.",
    "start": "4120569",
    "end": "4126810"
  },
  {
    "text": "These are my\nreordered observations in such a way that the\nsmallest one is indexed by one",
    "start": "4126810",
    "end": "4132028"
  },
  {
    "text": "and the largest one\nis indexed by n. ",
    "start": "4132029",
    "end": "4138439"
  },
  {
    "text": "So now this is\nactually quite nice, because what I'm trying to\ndo is to find the largest",
    "start": "4138439",
    "end": "4144170"
  },
  {
    "text": "deviation from this guy to the\ntrue cumulative distribution function. The true cumulative\ndistribution function,",
    "start": "4144170",
    "end": "4149460"
  },
  {
    "text": "let's say it's Gaussian,\nlooks like this. ",
    "start": "4149460",
    "end": "4155339"
  },
  {
    "text": "It's something continuous,\nfor a symmetric distribution it crosses this axis at 1/2,\nand that's what it looks like.",
    "start": "4155340",
    "end": "4162520"
  },
  {
    "text": "And the Kolmogorov-Smirnov\ntest is just telling me how far do\nthose two curves get",
    "start": "4162520",
    "end": "4171470"
  },
  {
    "text": "in the worst possible case? So in particular here,\nwhere are they the farthest?",
    "start": "4171470",
    "end": "4177380"
  },
  {
    "text": "Clearly that's this point. And so up to rescaling,\nthis is the value",
    "start": "4177380",
    "end": "4182490"
  },
  {
    "text": "I'm going to be interested in. That's how they get as far\nas possible from each other.",
    "start": "4182490",
    "end": "4189130"
  },
  {
    "text": "Here, something just\nhappened, right? The farthest distance\nthat I got was exactly",
    "start": "4189130",
    "end": "4194695"
  },
  {
    "text": "at one of those dots.  It turns out this is enough\nto look at those dots.",
    "start": "4194695",
    "end": "4201600"
  },
  {
    "text": "And the reason is, well\nbecause after this dot and until the next jump,\nthis guy does not change,",
    "start": "4201600",
    "end": "4208460"
  },
  {
    "text": "but this guy increases. And so the only point where\nthey can be the farthest apart",
    "start": "4208460",
    "end": "4215220"
  },
  {
    "text": "is either to the left of a\njump or to the right of a jump. That's the only place where\nthey can be far from each other.",
    "start": "4215220",
    "end": "4222540"
  },
  {
    "text": "And that means that\nonly one observation. Everybody sees that? The farthest points, the points\nat which those two curves are",
    "start": "4222540",
    "end": "4229470"
  },
  {
    "text": "the farthest from\neach other, has to be at one of\nthe observations. And so rather than looking at\na sup over all possible t's,",
    "start": "4229470",
    "end": "4237790"
  },
  {
    "text": "really all I need to do\nis to look at a maximum only at my observations.",
    "start": "4237790",
    "end": "4243036"
  },
  {
    "text": " I just need to check\nat each of those points",
    "start": "4243036",
    "end": "4248960"
  },
  {
    "text": "whether they're far. Now here, notice\nthat you did not, this is not written Fn of Xi.",
    "start": "4248960",
    "end": "4257530"
  },
  {
    "text": "The reason is because I\nactually know what Fn of Xi is. Fn of the i-th order\nobservation is just",
    "start": "4257530",
    "end": "4265320"
  },
  {
    "text": "the number of jumps I've\nhad until this observation. So here, I know that the\nvalue of Fn is 1 over n,",
    "start": "4265320",
    "end": "4271290"
  },
  {
    "text": "here it's 2 over n, 3 over\nn, 4 over n, 5 over n. So I knew that the values\nof Fn at my observations,",
    "start": "4271290",
    "end": "4279300"
  },
  {
    "text": "and those are actually the\nonly values that Fn can take, are an integer divided by n.",
    "start": "4279300",
    "end": "4285059"
  },
  {
    "text": "And that's why you see i\nminus 1 over n, or i over n. This is the difference\njust before the jump,",
    "start": "4285060",
    "end": "4292520"
  },
  {
    "text": "and this is the\ndifference at the jump. ",
    "start": "4292520",
    "end": "4298090"
  },
  {
    "text": "So here the key message\nis that this is no longer a supremum over all\nt's, but it's just",
    "start": "4298090",
    "end": "4304610"
  },
  {
    "text": "the maximum from 1 to n. So I really have only\ntwo n values to compute. This value and this value for\neach observation, that's 2n",
    "start": "4304610",
    "end": "4311970"
  },
  {
    "text": "total. I look at the maximum and\nthat's actually the value. And it's actually equal to tn.",
    "start": "4311970",
    "end": "4318906"
  },
  {
    "text": "It's not an approximation. Those things are equal. That's just the\nonly places where those guys can be maximum. ",
    "start": "4318907",
    "end": "4329242"
  },
  {
    "text": "Yes? AUDIENCE: It seems like since\nthe null hypothesis [INAUDIBLE]",
    "start": "4329242",
    "end": "4335134"
  },
  {
    "text": "the entire\ndistribution of theta, this is like strictly\nmore powerful than just doing it [INAUDIBLE].",
    "start": "4335134",
    "end": "4343000"
  },
  {
    "text": "PROFESSOR: It's\nstrictly less powerful. AUDIENCE: Strictly\nless powerful. But is there, is that\nlike a big trade-off",
    "start": "4343000",
    "end": "4350490"
  },
  {
    "text": "that we're making\nwhen we do that? Obviously we're not\ncertain in the first place that we want to\nassume normality. Does it make sense\nto [INAUDIBLE],,",
    "start": "4350490",
    "end": "4357624"
  },
  {
    "text": "the Gaussian [INAUDIBLE]. ",
    "start": "4357624",
    "end": "4368000"
  },
  {
    "text": "PROFESSOR: So can\nyou, I'm not sure what question you're asking. AUDIENCE: So when we're\ndoing a normal test,",
    "start": "4368000",
    "end": "4373360"
  },
  {
    "text": "we're just asking\nquestions about the mus, the means of our distribution. [INAUDIBLE] This\none, it seems like it",
    "start": "4373360",
    "end": "4380383"
  },
  {
    "text": "would be both at the same time. [INAUDIBLE] Is this\ndecreasing power [INAUDIBLE]??",
    "start": "4380383",
    "end": "4391000"
  },
  {
    "text": "PROFESSOR: So remember,\nhere in this test we want to conclude to H0, in\nthe other test we typically",
    "start": "4391000",
    "end": "4396140"
  },
  {
    "text": "want to conclude to H1. So here we actually don't\nwant power, in a way.",
    "start": "4396140",
    "end": "4401150"
  },
  {
    "text": "And you have to also assume\nthat doing a test on the mean is probably not the\nonly thing you're",
    "start": "4401150",
    "end": "4406160"
  },
  {
    "text": "going to end up\ndoing on your data after you actually establish\nthat it's normally distributed.",
    "start": "4406160",
    "end": "4411472"
  },
  {
    "text": "Then you have the\ndataset, you've sort of established it's\nnormally distributed, and then you can just run the\narsenal of statistical studies.",
    "start": "4411472",
    "end": "4418090"
  },
  {
    "text": "And we're going\nto see regression and all sorts of predictive\nthings, which are not just tests if the mean is\nequal to something.",
    "start": "4418090",
    "end": "4424280"
  },
  {
    "text": "Maybe you want to build\na confidence interval for the mean. Then this is not, confidence\ninterval is not a test.",
    "start": "4424280",
    "end": "4430052"
  },
  {
    "text": "So you're going to have to\nfirst test if it's normal, and then see if you\ncan actually use the quantiles of a Gaussian\ndistribution or a t",
    "start": "4430052",
    "end": "4435769"
  },
  {
    "text": "distribution to build\nthis confidence interval. So in a way you should do\nthis as like, the flat fee",
    "start": "4435770",
    "end": "4443510"
  },
  {
    "text": "to enter the Gaussian\nworld, and then you can do whatever you want to\ndo in the Gaussian world.",
    "start": "4443510",
    "end": "4449072"
  },
  {
    "text": "We'll see actually that\nyour question goes back to something that's a\nlittle important, is here",
    "start": "4449072",
    "end": "4454750"
  },
  {
    "text": "I said F0 is fully specified. It's like an N 1, 5.",
    "start": "4454750",
    "end": "4461490"
  },
  {
    "text": "But I didn't say, is it\nnormally distributed, which is the question\nthat everybody asks. You're not asking, is it this\nparticular normal distribution",
    "start": "4461490",
    "end": "4469189"
  },
  {
    "text": "with this particular mean\nand this particular variance. So how would you\ndo it in practice? Well you would\nsay, I'm just going",
    "start": "4469189",
    "end": "4474276"
  },
  {
    "text": "to replace the mean by the\nempirical mean and the variance by the empirical variance. But by doing that you're making\na huge mistake because you",
    "start": "4474276",
    "end": "4481710"
  },
  {
    "text": "are sort of depriving your\ntest of the possibility to reject the Gaussian\nhypothesis just",
    "start": "4481710",
    "end": "4486967"
  },
  {
    "text": "based on the fact that the\nmean is wrong or the variance is wrong. You've already stuck to\nyour data pretty well.",
    "start": "4486967",
    "end": "4492600"
  },
  {
    "text": "And so you're sort\nof like already tilting the game in\nfavor of H0 big time.",
    "start": "4492600",
    "end": "4499320"
  },
  {
    "text": "So there's actually a\nway to arrange for this.  OK, so this is about\npivotal statistic.",
    "start": "4499320",
    "end": "4505555"
  },
  {
    "text": "We've used this word many times.  And So that's how.",
    "start": "4505555",
    "end": "4512272"
  },
  {
    "text": "I'm not going to\ngo into this test. It's really, this is a recipe\non how you would actually build the table that I\nshowed you, this table.",
    "start": "4512272",
    "end": "4520920"
  },
  {
    "text": "This is basically the\nrecipe on how to build it. There's another recipe to\nbuild it, which is just open a book at this page.",
    "start": "4520920",
    "end": "4527730"
  },
  {
    "text": "That's a little faster. Or use software.",
    "start": "4527730",
    "end": "4532870"
  },
  {
    "text": "I just wanted to show you. So let's just keep in mind,\nanybody has a good memory? Let's just keep in\nmind this number.",
    "start": "4532870",
    "end": "4538390"
  },
  {
    "text": "This is the threshold for the\nKolmogorov-Smirnov statistic.",
    "start": "4538390",
    "end": "4544060"
  },
  {
    "text": "If I have 10 observations\nand I want to do it at 5%, it's about 41%.",
    "start": "4544060",
    "end": "4550060"
  },
  {
    "text": "So that's the number that\nit should be larger from. So it turns out that if you want\nto test if it's normal, and not",
    "start": "4550060",
    "end": "4556630"
  },
  {
    "text": "just the specific\nnormal, this number is going to be different. Do you think the\nnumber I'm going to read in a table that's\nappropriate for this is",
    "start": "4556630",
    "end": "4563561"
  },
  {
    "text": "going to be larger or smaller? Who says larger? AUDIENCE: Sorry, what\nwas the question?",
    "start": "4563561",
    "end": "4569130"
  },
  {
    "text": "PROFESSOR: So the\nquestion is, this is the number I should see if\nmy test was, is X, say, N 0, 5.",
    "start": "4569130",
    "end": "4580270"
  },
  {
    "text": "Right? That's a specific distribution\nwith a specific F0.",
    "start": "4580270",
    "end": "4585630"
  },
  {
    "text": "So that's the\nnumber, I would build the Kolmogorov-Smirnov\nstatistic from this. I would perform a test and\ncheck if my Kolmogorov-Smirnov",
    "start": "4585630",
    "end": "4592460"
  },
  {
    "text": "statistic tn is larger\nthan this number or not. If it's larger I'm\ngoing to reject. Now I say, actually, I don't\nwant to test if H0 is N 0, 5,",
    "start": "4592460",
    "end": "4600940"
  },
  {
    "text": "but it's just a mu sigma squared\nfor some mu and sigma squared.",
    "start": "4600940",
    "end": "4607942"
  },
  {
    "text": "And in particular I'm just\ngoing to plugin mu hat and sigma hat into my F0, run\nthe same statistic, but compare it to\na different number.",
    "start": "4607942",
    "end": "4616280"
  },
  {
    "text": "So the larger the\nnumber, the more or less likely am I to reject?",
    "start": "4616280",
    "end": "4623659"
  },
  {
    "text": "The less likely I\nam to reject, right? So if I just use that\nnumber, let's say",
    "start": "4623660",
    "end": "4629700"
  },
  {
    "text": "this is a large\nnumber, I would be more tempted to say it's Gaussian. And if you look at\nthe table you would",
    "start": "4629700",
    "end": "4635660"
  },
  {
    "text": "get that if you make the\nappropriate correction at the same number\nof observations, 10,",
    "start": "4635660",
    "end": "4641199"
  },
  {
    "text": "and the same level, you\nget 25% as opposed to 41%.",
    "start": "4641200",
    "end": "4646359"
  },
  {
    "text": "That means that you're actually\nmuch more likely if you use the appropriate test to\nreject the fact that it's",
    "start": "4646359",
    "end": "4652670"
  },
  {
    "text": "normal, which is bad\nnews, because that means you don't have access\nto the Gaussian arsenal, and nobody wants to do this.",
    "start": "4652670",
    "end": "4658159"
  },
  {
    "text": "So actually this is a\nmistake that people do a lot. They use the\nKolmogorov-Smirnov test to test for normality without\nadjusting for the fact",
    "start": "4658160",
    "end": "4665810"
  },
  {
    "text": "that they've plugged\nin the estimated mean and the estimated variance. This leads to rejecting\nless often, right?",
    "start": "4665810",
    "end": "4673520"
  },
  {
    "text": "I mean this is almost half\nof the number that we had. And then they can be\nhappy and walk home",
    "start": "4673520",
    "end": "4680990"
  },
  {
    "text": "and say, well, I did the\ntest and it was normal. So this is actually\na mistake that I believe that genuinely at\nleast a quarter of the people",
    "start": "4680990",
    "end": "4687130"
  },
  {
    "text": "do make in purpose. They just say, well I want\nit to be Gaussian so I'm just going to make my life easier.",
    "start": "4687130",
    "end": "4693760"
  },
  {
    "text": "So this is the so-called\nKolmogorov Lilliefors test. We'll talk about it,\nwell not today for sure.",
    "start": "4693760",
    "end": "4700800"
  },
  {
    "text": "There's other statistics that\nyou can test, that you can use. And the idea is to\nsay, well, we want",
    "start": "4700800",
    "end": "4706390"
  },
  {
    "text": "to know if the\nempirical distribution function, the empirical CDF,\nis close to the true CDF.",
    "start": "4706390",
    "end": "4711900"
  },
  {
    "text": "The way we did it is by\nforming the difference in looking at the worst\npossible distance they can be. That's called a sup\nnorm, or L infinity norm,",
    "start": "4711900",
    "end": "4719880"
  },
  {
    "text": "in functional analysis. So here, this is\nwhat it looked like. The distance between Fn and\nF that we measured was just",
    "start": "4719880",
    "end": "4726630"
  },
  {
    "text": "the supremum distance\nover all t's. That's one way to measure\ndistance between two functions. But there's an\ninfinite many ways",
    "start": "4726630",
    "end": "4733170"
  },
  {
    "text": "to measure distance\nbetween functions. One is something we're\nmuch more familiar with, which is the squared L2-norm.",
    "start": "4733170",
    "end": "4739510"
  },
  {
    "text": "This is nice because this\nhas like an inner product, it has some nice properties. And you could actually just,\nrather than taking the sup,",
    "start": "4739510",
    "end": "4746740"
  },
  {
    "text": "you could just integrate\nthe squared distance. And this is what leads to\nCramier-Von Mises test.",
    "start": "4746740",
    "end": "4754485"
  },
  {
    "text": "And then there's\nanother one that says, well, maybe I don't want\nto integrate without weights. Maybe I want to put weights\nthat account for the variance.",
    "start": "4754485",
    "end": "4762230"
  },
  {
    "text": "And this guy is called\nAnderson-Darling. For each of these\ntests you can check that the asymptotic distribution\nis going to be pivotal,",
    "start": "4762230",
    "end": "4769660"
  },
  {
    "text": "which means that there will be\na table at the back of some book that tells you what the\nstatistic, the quantiles",
    "start": "4769660",
    "end": "4777190"
  },
  {
    "text": "of square root of\nn times this guy are asymptotically, basically. Yeah? AUDIENCE: For the\nKolmogorov-Smirnov test,",
    "start": "4777190",
    "end": "4784197"
  },
  {
    "text": "for the table that\nshows the value it has, it has the value\nfor different n.",
    "start": "4784197",
    "end": "4791572"
  },
  {
    "text": "But I thought we [INAUDIBLE]-- PROFESSOR: Yeah. So that's just to show you that\nasymptotically it's pivotal,",
    "start": "4791572",
    "end": "4796649"
  },
  {
    "text": "and I can point you\nto one specific thing. But it turns out that this thing\nis actually pivotal for each n.",
    "start": "4796649",
    "end": "4802842"
  },
  {
    "text": "And that's why you have this\nrecipe to construct the entire thing, because it's actually\nnot true for all possible n's.",
    "start": "4802842",
    "end": "4808690"
  },
  {
    "text": "Also there's the n\nthat shows up here. So no actually,\nthis is something you should have in mind.",
    "start": "4808690",
    "end": "4814090"
  },
  {
    "text": "So basically, let me\nstrike what I just said. This thing you can\nactually, this distribution",
    "start": "4814090",
    "end": "4820330"
  },
  {
    "text": "will not depend on F0\nfor any particular n. It's just not going to\nbe a Brownian bridge",
    "start": "4820330",
    "end": "4825910"
  },
  {
    "text": "but a finite sample\napproximation of a Brownian bridge, and you can simulate\nthat just drawing samples",
    "start": "4825910",
    "end": "4831159"
  },
  {
    "text": "from it, building a\nhistogram, and constructing the quantiles for this guy. AUDIENCE: No one has\nactually developed",
    "start": "4831160",
    "end": "4836910"
  },
  {
    "text": "a table for Brownian-- PROFESSOR: Oh, there is one. That's the table, maybe.",
    "start": "4836910",
    "end": "4842570"
  },
  {
    "text": "Let's see if we see it at the\nbottom of the other table. Yeah. See?",
    "start": "4842570",
    "end": "4847720"
  },
  {
    "text": "Over 40, over 30. So this is not the\nKolmogorov-Smirnov, but that's the\nKolmogorov Lilliefors. Those numbers that\nyou see here, they",
    "start": "4847720",
    "end": "4854900"
  },
  {
    "text": "are the numbers for the\nasymptotic thing which is some sort of Brownian bridge. Yeah?",
    "start": "4854900",
    "end": "4860184"
  },
  {
    "text": "AUDIENCE: Two questions. If I want to build the\nKolmogorov-Smirnov test, it says that F0 is\nrequired to be continuous.",
    "start": "4860184",
    "end": "4868119"
  },
  {
    "text": "PROFESSOR: Yeah. AUDIENCE: [INAUDIBLE] If\nwe have, like, probability",
    "start": "4868120",
    "end": "4873576"
  },
  {
    "text": "mass of a particular value. Like some sort of data. PROFESSOR: So then you won't\nhave this nice picture, right?",
    "start": "4873576",
    "end": "4880769"
  },
  {
    "text": "This can happen at any\npoint because you're going to have\ndiscontinuities in F and those things can\nhappen everywhere.",
    "start": "4880769",
    "end": "4886620"
  },
  {
    "text": "And then-- AUDIENCE: Would the\nsupremum still work? PROFESSOR: You mean\nthe Brownian bridge? AUDIENCE: Yeah.",
    "start": "4886620",
    "end": "4892140"
  },
  {
    "text": "The Kolmogorov test\ndoesn't say that you have to be able to easily\ncalculate the supremum.",
    "start": "4892140",
    "end": "4897382"
  },
  {
    "text": "PROFESSOR: No, no, no,\nbut you still need it. You still need it for-- so there's some finite\nsample versions of it",
    "start": "4897382",
    "end": "4902832"
  },
  {
    "text": "that you can use that are\nslightly more conservative, which is in a way good\nnews because you're going to conclude more to H0.",
    "start": "4902832",
    "end": "4910250"
  },
  {
    "text": "And there's are some,\nI forget the name, it's Kiefer-Wolfowitz, the\nKiefer-Dvoretzky-Wolfowitz,",
    "start": "4910250",
    "end": "4917172"
  },
  {
    "text": "an equality which is basically\nlike Hoeffding's inequality. So it's basically\nup to bad constants telling you the same result\nas the Brownian bridge result,",
    "start": "4917172",
    "end": "4924900"
  },
  {
    "text": "and those are true all the time. But for the exact\nasymptotic distribution, you need continuity.",
    "start": "4924900",
    "end": "4931467"
  },
  {
    "text": "Yes. AUDIENCE: So just\na clarification. So when we are testing\nthe Kolmogorov, we shouldn't test a particular\nmu and sigma squared?",
    "start": "4931467",
    "end": "4939902"
  },
  {
    "text": "PROFESSOR: Well if you know\nwhat they are you can use Kolmogorov-Smirnov, but if\nyou don't know what they are",
    "start": "4939902",
    "end": "4945259"
  },
  {
    "text": "you're going to plug in-- as soon as you're\ngoing to estimate the mean and the\nvariance from the data, you should use the one we'll\nsee next time, which is",
    "start": "4945259",
    "end": "4951700"
  },
  {
    "text": "called Kolmogorov Lilliefors. You don't have to think\nabout it too much. We'll talk about it on Thursday.",
    "start": "4951700",
    "end": "4958000"
  },
  {
    "text": "Any other question? So we're out of time. So I think we should stop here,\nand we'll resume on Thursday.",
    "start": "4958000",
    "end": "4965699"
  },
  {
    "start": "4965700",
    "end": "4967745"
  }
]
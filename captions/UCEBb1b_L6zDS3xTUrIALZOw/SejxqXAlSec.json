[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5300"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5300",
    "end": "11600"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11600",
    "end": "18100"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18100",
    "end": "23904"
  },
  {
    "text": "JAMES SWAN: OK. Let's go ahead and get started. ",
    "start": "23905",
    "end": "34650"
  },
  {
    "text": "We saw a lot of\ngood conversation on Piazza this weekend. So that's good. Seems like you guys\nare making your way",
    "start": "34650",
    "end": "40525"
  },
  {
    "text": "through these two problems\non the latest assignment.",
    "start": "40525",
    "end": "46010"
  },
  {
    "text": "I would try to focus less\non the chemical engineering",
    "start": "46010",
    "end": "51120"
  },
  {
    "text": "science and problems\nthat involve those. Usually the topic of interest,\nthe thing that's useful to you",
    "start": "51120",
    "end": "57359"
  },
  {
    "text": "educationally is going to\nbe the numerics, right. So if you get hung\nup on the definition",
    "start": "57360",
    "end": "62700"
  },
  {
    "text": "of a particular quantity,\nyield was one that came up. Rather than let that prevent\nyou from solving the problem,",
    "start": "62700",
    "end": "69299"
  },
  {
    "text": "pick a definition\nand see what happens. You can always ask\nyourself if the results seem physically\nreasonable to you",
    "start": "69300",
    "end": "75430"
  },
  {
    "text": "not based on your definition. And as long as you explain\nwhat you did in your write up,",
    "start": "75430",
    "end": "80500"
  },
  {
    "text": "you're going to get full points. We want to solve the\nproblems numerically. If there's some hang up in\nthe science, don't sweat it.",
    "start": "80500",
    "end": "89430"
  },
  {
    "text": "Don't let that stop you\nfrom moving ahead with it. Don't let it make it seem like\nthe problem can't be solved",
    "start": "89430",
    "end": "96631"
  },
  {
    "text": "or there isn't a\npath to a solution. Pick a definition and go with\nit and see what happens, right.",
    "start": "96631",
    "end": "102450"
  },
  {
    "text": "The root of the\nsecond problem is trying to nest together two\ndifferent numerical methods. One of those is optimization,\nand the other one",
    "start": "102450",
    "end": "108720"
  },
  {
    "text": "is solutions of\nnonlinear equation, putting those two\ntechniques together, using them in combination.",
    "start": "108720",
    "end": "115040"
  },
  {
    "text": "The engineering science problem\ngives us a solvable problem to work with in that\ncontext, but it's not",
    "start": "115040",
    "end": "120240"
  },
  {
    "text": "the key element of it. OK, good. So we're continuing\noptimization, right.",
    "start": "120240",
    "end": "126222"
  },
  {
    "text": "Move this just a little bit. We're continuing\nwith optimization. Last time we posed lots\nof optimization problems.",
    "start": "126222",
    "end": "134760"
  },
  {
    "text": "We talked about\nconstrained optimization, unconstrained optimization.",
    "start": "134760",
    "end": "139990"
  },
  {
    "text": "We heard a little bit\nabout linear programs. We started approaching\nunconstrained optimization",
    "start": "139990",
    "end": "147480"
  },
  {
    "text": "problems from the perspective\nof steepest descent. OK, so that's where I want\nto pick up as we get started.",
    "start": "147480",
    "end": "155080"
  },
  {
    "text": "So you'll recall the idea\nbehind steepest descent was all the unconstrained\noptimization",
    "start": "155080",
    "end": "160290"
  },
  {
    "text": "problems we're interested\nin are based around trying to find minima, OK.",
    "start": "160290",
    "end": "165909"
  },
  {
    "text": "And so we should think\nabout these problems as though we're standing\non top of a mountain. And we're looking for directions\nthat allow us to descend.",
    "start": "165909",
    "end": "173430"
  },
  {
    "text": "And as long as we're heading\nin descending directions, right, there's a good\nchance we're going to bottom out someplace and stop.",
    "start": "173430",
    "end": "179784"
  },
  {
    "text": "And when we've\nbottomed out, we've found one of those local minima. That bottom is going\nto be a place where the gradient of the function\nwe're trying to find",
    "start": "179784",
    "end": "186870"
  },
  {
    "text": "the minimum of is zero, OK. And the idea behind\nsteepest descent was well, don't just pick any\ndirection that's down hill.",
    "start": "186870",
    "end": "195060"
  },
  {
    "text": "Pick the steepest\ndirection, right. Go in the direction\nof the gradient. That's the steepest\ndescent idea.",
    "start": "195060",
    "end": "200820"
  },
  {
    "text": "And then we did something a\nlittle sophisticated last time. We said well OK, I\nknow the direction.",
    "start": "200820",
    "end": "206224"
  },
  {
    "text": "I'm standing on\ntop the mountain. I point myself in the\nsteepest descent direction. How big a step do I take?",
    "start": "206225",
    "end": "212069"
  },
  {
    "text": "I can take any size step. And some steps may be good\nand some steps may be bad. It turns out there are some\ngood estimates for step size",
    "start": "212070",
    "end": "219299"
  },
  {
    "text": "that we can get by taking\na Taylor expansion. So we take our\nfunction, right, and we write it at the next iterate\nis a Taylor expansion.",
    "start": "219300",
    "end": "226800"
  },
  {
    "text": "About the current iterate,\nthat expansion looks like this. And it will be quadratic with\nrespect to the step size alpha.",
    "start": "226800",
    "end": "234010"
  },
  {
    "text": " If we want to minimize the\nvalue of the function here,",
    "start": "234010",
    "end": "239880"
  },
  {
    "text": "we want the next\niterate to be a minimum of this quadratic function. Then there's an obvious\nchoice of alpha, right.",
    "start": "239880",
    "end": "247620"
  },
  {
    "text": "We find the vertex of\nthis quadratic functional. That gives us the\noptimal step size.",
    "start": "247620",
    "end": "254040"
  },
  {
    "text": "It's optimal if our function\nactually is quadratic. It's an approximate, right. It's an estimation of the\nright sort of step size",
    "start": "254040",
    "end": "260250"
  },
  {
    "text": "if it's not quadratic. And so I showed you here was a\nfunction where the contours are",
    "start": "260250",
    "end": "266099"
  },
  {
    "text": "very closely spaced. So it's a very steep function. And the minima is in the middle. If we try to solve this\nwith the steepest descent",
    "start": "266100",
    "end": "273600"
  },
  {
    "text": "and we pick different steps\nsizes, uniform step sizes, so we try 0.1 and 1\nand 10 step sizes,",
    "start": "273600",
    "end": "281480"
  },
  {
    "text": "we'll never find an\nappropriate choice to converge to the solution, OK. We're going to have to\npick impossibly small step",
    "start": "281480",
    "end": "287400"
  },
  {
    "text": "sizes, which will require tons\nof steps in order to get there. But with this\nquadratic estimate, you can get a reasonably\nsmooth convergence to the root.",
    "start": "287400",
    "end": "295960"
  },
  {
    "text": "So that's nice. And here's a task for you to\ntest whether you understand",
    "start": "295960",
    "end": "301280"
  },
  {
    "text": "steepest descent or not. In your notes, I've\ndrawn some contours. For function, we'd\nlike to minimize using",
    "start": "301280",
    "end": "307840"
  },
  {
    "text": "the method of steepest descent. And I want you to try to draw\nsteepest descent paths on top",
    "start": "307840",
    "end": "313900"
  },
  {
    "text": "of these contours starting\nfrom initial conditions where these stars are located.",
    "start": "313900",
    "end": "320630"
  },
  {
    "text": "So if I'm following\nsteepest descent, the rules of steepest descent here,\nand I start from these stars,",
    "start": "320630",
    "end": "327670"
  },
  {
    "text": "what sort of paths do I follow? You're going to need\nto pick a step size. I would suggest thinking about\nthe small step size limit.",
    "start": "327670",
    "end": "334479"
  },
  {
    "text": "What is the steepest descent\npath in the small step size limit? Can you work that out,\nyou and your neighbors?",
    "start": "334480",
    "end": "339530"
  },
  {
    "text": "You don't have to do\nall of them by yourself. You can do one, your\nneighbor could do another. And we'll take a look\nat them together. ",
    "start": "339530",
    "end": "488380"
  },
  {
    "text": "OK, the roar has turned into\na rumble and then a murmur, so I think you guys are\nmaking some progress. ",
    "start": "488380",
    "end": "496789"
  },
  {
    "text": "What do you think? How about let's do an easy one. How about this one here. What sort of path does it take?",
    "start": "496790",
    "end": "504210"
  },
  {
    "text": "Yeah, it sort of curls\nright down into the center here, right. Remember, steepest descent\npaths run perpendicular",
    "start": "504210",
    "end": "510300"
  },
  {
    "text": "to the contours. So jumps perpendicular to the\ncontour, almost a straight line to the center. How about this one over here?",
    "start": "510300",
    "end": "516799"
  },
  {
    "text": "Same thing, right? It runs the other way. It's going downhill 1,\n0, minus 1, minus 2.",
    "start": "516799",
    "end": "521870"
  },
  {
    "text": "So it runs downhill and\ncurls into the center. What about this one up here?",
    "start": "521870",
    "end": "527482"
  },
  {
    "text": "What's it do? Yeah, it just runs\nto the left, right. The contour lines\nhad normals that",
    "start": "527482",
    "end": "534256"
  },
  {
    "text": "just keep it running\nall the way to the left. So this actually doesn't run\ninto this minimum, right. It finds a cliff and steps\nright off of it, keeps on going.",
    "start": "534256",
    "end": "543230"
  },
  {
    "text": "Steepest descent,\nthat's what it does. How about this one here? Same thing, right,\njust to the left.",
    "start": "543230",
    "end": "548734"
  },
  {
    "text": "So these are what\nthese paths look like. You can draw them yourself.",
    "start": "548734",
    "end": "553750"
  },
  {
    "text": "If I showed you paths and\nasked you what sort of method made them, you should be able to\nidentify that actually, right? You should be able to detect\nwhat sort of methodology",
    "start": "553750",
    "end": "562660"
  },
  {
    "text": "generated those kinds of paths. ",
    "start": "562660",
    "end": "568770"
  },
  {
    "text": "We're not always so\nfortunate to have this graphical view\nof the landscape that our method is navigating.",
    "start": "568770",
    "end": "574680"
  },
  {
    "text": "But it's good to have\nthese 2D depictions. Because they really\nhelp us understand when a method doesn't converge\nwhat might be going wrong,",
    "start": "574680",
    "end": "581259"
  },
  {
    "text": "right. So steepest descent, it\nalways heads downhill. But if there is no bottom, it's\njust going to keep going down,",
    "start": "581260",
    "end": "587639"
  },
  {
    "text": "right. It's never going to find it. Oh, OK. Here's a-- this is\na story now that you",
    "start": "587640",
    "end": "593959"
  },
  {
    "text": "understand optimization. So let's see, so\nmechanical systems,",
    "start": "593960",
    "end": "599330"
  },
  {
    "text": "conservation of\nmomentum, that's also, in a certain sense, an\noptimization problem, right.",
    "start": "599330",
    "end": "605990"
  },
  {
    "text": "So conservation of momentum says\nthat the acceleration on a body",
    "start": "605990",
    "end": "611690"
  },
  {
    "text": "is equal to the sum\nof the forces on it. And some of those\nforces are what we call conservative forces.",
    "start": "611690",
    "end": "616960"
  },
  {
    "text": "They're proportional\nto gradients of some energy landscape. Some of those forces\nare non-conservative,",
    "start": "616960",
    "end": "622160"
  },
  {
    "text": "like this one here. It's a little damping\nforce, a little bit of friction proportional\nto the velocity with which",
    "start": "622160",
    "end": "628220"
  },
  {
    "text": "the object moves instead. And if we start some\nsystem like this,",
    "start": "628220",
    "end": "633860"
  },
  {
    "text": "we give it some initial\ninertia and let it go, right, eventually it's going to\nwant to come to rest at a place",
    "start": "633860",
    "end": "639920"
  },
  {
    "text": "where the gradient\nin the potential is 0 and the velocity is 0 on\nthe acceleration is 0.",
    "start": "639920",
    "end": "645120"
  },
  {
    "text": "We call that\nmechanical equilibrium. We get to mechanical\nequilibrium and we stop, right. So physical systems many\ntimes are seeking out minimum",
    "start": "645120",
    "end": "654500"
  },
  {
    "text": "of an objective function. The objective function\nis the potential energy. I saw last year at my house\nwe had a pipe underground",
    "start": "654500",
    "end": "662089"
  },
  {
    "text": "that leaked in the front yard. And they needed to\nfind the pipe, right.",
    "start": "662090",
    "end": "667873"
  },
  {
    "text": "It was like under the asphalt.\nSo they got to dig up asphalt, and they need to know\nwhere is the pipe. They know it's leaking, but\nwhere does the pipe sit?",
    "start": "667874",
    "end": "675470"
  },
  {
    "text": "So the city came out and the\nguy from the city brought this. Do you know what this is? ",
    "start": "675470",
    "end": "683240"
  },
  {
    "text": "What is it? Do you know? Yeah, yeah, yeah. It's a dowsing rod.",
    "start": "683240",
    "end": "689290"
  },
  {
    "text": "OK, this kind of crazy\nstory right, a dowsing rod. OK, a dowsing rod.",
    "start": "689290",
    "end": "695500"
  },
  {
    "text": "How does it work? The way it's supposed\nto work is I hold it out and it should turn\nand rotate in point",
    "start": "695500",
    "end": "703630"
  },
  {
    "text": "in a direction that's\nparallel to the flow of the water in the pipe. That's the theory that this\nis supposed to work on.",
    "start": "703630",
    "end": "708860"
  },
  {
    "text": "I'm a scientist. So I expect that\nsomehow the water is exerting a force on the\ntip of the dowsing rod, OK.",
    "start": "708860",
    "end": "717970"
  },
  {
    "text": "So the dowsing rod\nis moving around as this guy walks around. And it's going to stop\nwhen it finds a point",
    "start": "717970",
    "end": "725160"
  },
  {
    "text": "of mechanical equilibrium. So the dowsing\nrod is seeking out a minimum of some potential\nenergy, let's say.",
    "start": "725160",
    "end": "730927"
  },
  {
    "text": "That's what the physics\nsays has to be true. I don't know that flowing\nwater exerts a force on the tip of the dowsing rod.",
    "start": "730927",
    "end": "736570"
  },
  {
    "text": "The guy who had this\nbelieved that was true, OK. It turns out, this is not\nsuch a good idea, though, OK.",
    "start": "736570",
    "end": "743190"
  },
  {
    "text": "Like in terms of a\nmethod for seeking out the minimum of a potential, it's\nnot such a great way to do it.",
    "start": "743190",
    "end": "749040"
  },
  {
    "text": "Because he's way up here, and\nthe water's way underground. So there's a huge distance\nbetween these things.",
    "start": "749040",
    "end": "754630"
  },
  {
    "text": "It's not exerting\na strong force, OK. The gradient isn't\nvery big here.",
    "start": "754630",
    "end": "760420"
  },
  {
    "text": "It's a relatively weak force. So this instrument is incredibly\nsensitive to all sorts of external fluctuations.",
    "start": "760420",
    "end": "765670"
  },
  {
    "text": "The gradient is small. The potential energy\nlandscape is very, very flat.",
    "start": "765670",
    "end": "770710"
  },
  {
    "text": "And we know already\nfrom applying things like steepest descent\nmethods or Newton-Raphson that those circumstances are\ndisastrous for any method",
    "start": "770710",
    "end": "778209"
  },
  {
    "text": "seeking out minima of\npotential energies, right. Those landscapes are the\nhardest ones to detect it in.",
    "start": "778210",
    "end": "784630"
  },
  {
    "text": "Because every point looks like\nit's close to being a minima, right. It's really difficult to see\nthe differences between these.",
    "start": "784630",
    "end": "792310"
  },
  {
    "text": "Nonetheless, he figured\nout where the pipe was. I don't think it was\nbecause of this though.",
    "start": "792310",
    "end": "799680"
  },
  {
    "text": "How did he know\nwhere the pipe was?  What's that?",
    "start": "799680",
    "end": "805022"
  },
  {
    "text": "STUDENT: Where the\nground was squishy? JAMES SWAN: Where the\nground was squishy. Well yeah, had some\ngood guesses because it was leaking up a little bit.",
    "start": "805022",
    "end": "810290"
  },
  {
    "text": "No, I looked\ncarefully afterwards. And I think it turned\nout the city had come by and actually painted\nsome white lines",
    "start": "810290",
    "end": "816971"
  },
  {
    "text": "on either side of the street\nto indicate where it was. But he was out there\nwith his dowsing rod making sure the city\nhad gotten it right.",
    "start": "816971",
    "end": "822951"
  },
  {
    "text": "It turns out, there's something\ncalled the ideomotor effect where your hand has\nvery little, you know, very sensitive\nlittle tremors in it.",
    "start": "822952",
    "end": "829330"
  },
  {
    "text": "And can guide something\nlike this, a little weight at the end of a rod to\ngo wherever you want it to go when you want it to.",
    "start": "829330",
    "end": "834928"
  },
  {
    "text": "It's like a Ouija board, right. It works exactly the same way. Anyway, it's not\na good way to find the minimum of potential\nenergy surfaces, OK.",
    "start": "834928",
    "end": "843620"
  },
  {
    "text": "We have the same problem\nwith numerical methods. It's really difficult when\nthese potential energy landscapes are flat to find\nwhere the minimum is, OK.",
    "start": "843620",
    "end": "853688"
  },
  {
    "text": "So fun and games are over. Now we got to do some math. ",
    "start": "853688",
    "end": "859960"
  },
  {
    "text": "So we talked about\nsteepest descent. And steepest descent\nis an interesting way",
    "start": "859960",
    "end": "866370"
  },
  {
    "text": "to approach these kinds\nof optimization problems. It turns out, it turns out\nthat linear equations like Ax",
    "start": "866370",
    "end": "875580"
  },
  {
    "text": "equals b can also be cast as\noptimization problems, right. So the solution to\nthis equation Ax",
    "start": "875580",
    "end": "882660"
  },
  {
    "text": "equals b is also a minima of\nthis quadratic function up here.",
    "start": "882660",
    "end": "889230"
  },
  {
    "text": "How do you know? You take the gradient\nof this function, which is Ax minus b, and\nthe gradient to 0 to minima.",
    "start": "889230",
    "end": "897089"
  },
  {
    "text": "So Ax minus b is\n0, or Ax equals b. So we can do optimization\non these sorts",
    "start": "897090",
    "end": "902459"
  },
  {
    "text": "of quadratic functionals, and\nwe would find the solution of systems of linear equations.",
    "start": "902460",
    "end": "908787"
  },
  {
    "text": "This is an alternative approach. Sometimes this is called\nthe variational approach to solving these systems\nof linear equations.",
    "start": "908787",
    "end": "915870"
  },
  {
    "text": "There are a couple of\nthings that have to be true. The linear operator,\nright, the matrix here,",
    "start": "915870",
    "end": "921740"
  },
  {
    "text": "it has to be symmetric. OK, it has to be symmetric,\nbecause it's multiplied by x from both sides.",
    "start": "921740",
    "end": "927380"
  },
  {
    "text": "It doesn't know that\nit's transpose is different from itself in\nthe form of this functional.",
    "start": "927380",
    "end": "933140"
  },
  {
    "text": "If A wasn't symmetric,\nthe functional would symmetrize it\nautomatically, OK. So a functional like\nthis only corresponds",
    "start": "933140",
    "end": "941870"
  },
  {
    "text": "to this linear equation\nwhen A is symmetric. And this sort of thing\nonly has a minimum, right,",
    "start": "941870",
    "end": "950270"
  },
  {
    "text": "when the matrix A is\npositive and definite. It has to have all positive\neigenvalues, right. The Hessian right,\nof this functional,",
    "start": "950270",
    "end": "958910"
  },
  {
    "text": "is just the matrix\nA. And we already said that Hessian needs all\npositive eigenvalues to confirm",
    "start": "958910",
    "end": "963940"
  },
  {
    "text": "we have a minima. OK? If one of the\neigenvalues is zero, then the problem\nis indeterminate.",
    "start": "963940",
    "end": "969980"
  },
  {
    "text": "The linear problem\nis indeterminate. And there isn't a single\nlocal minimum, right. There's going to be a line of\nminima or a plane of minima",
    "start": "969980",
    "end": "976100"
  },
  {
    "text": "instead. OK? OK, so you can solve\nsystems of linear equations",
    "start": "976100",
    "end": "982540"
  },
  {
    "text": "as optimization problems. And people have tried to apply\nthings like steepest descent",
    "start": "982540",
    "end": "988570"
  },
  {
    "text": "to these problems. And it turns out\nsteepest descent is kind of challenging to apply.",
    "start": "988570",
    "end": "993980"
  },
  {
    "text": "So what winds up\nhappening is let's suppose we don't take our\nquadratic approximation",
    "start": "993980",
    "end": "1001020"
  },
  {
    "text": "for the descent direction first. Let's just say we take some\nfixed step size, right. When you take that fixed\nstep size, it'll always be,",
    "start": "1001020",
    "end": "1010050"
  },
  {
    "text": "let's say good for one\nparticular direction. OK, so I'll step in a\nparticular direction.",
    "start": "1010050",
    "end": "1016110"
  },
  {
    "text": "It'll be good. It'll be a nice step\ninto a local minimum. But when I try to step in\nthe next gradient direction,",
    "start": "1016110",
    "end": "1022259"
  },
  {
    "text": "it may be too big or too small. And that will depend on\nthe eigenvalues associated with the direction that I\nam trying to step in, OK.",
    "start": "1022260",
    "end": "1029159"
  },
  {
    "text": "How steep is this\nconvex function? Right? How strongly curved is\nthat convex function?",
    "start": "1029160",
    "end": "1035179"
  },
  {
    "text": "That's what the\neigenvalues are describing. And so fixed value of\nalpha will lead to cases",
    "start": "1035180",
    "end": "1040680"
  },
  {
    "text": "where we wind up stepping\ntoo far or not far enough. And there'll be a lot\nof oscillating around on this path that\nconverges to a solution.",
    "start": "1040680",
    "end": "1048900"
  },
  {
    "text": "I showed you how to pick\nan optimal step size. It said look in a\nparticular direction and treat your function\nas though it were",
    "start": "1048900",
    "end": "1054750"
  },
  {
    "text": "quadratic along that direction. That's going to be true for\nall directions associated",
    "start": "1054750",
    "end": "1060124"
  },
  {
    "text": "with this functional, right. It's always quadratic no matter\nwhich direction I point in. Right? So I pick a direction\nand I step and I'll",
    "start": "1060124",
    "end": "1067440"
  },
  {
    "text": "be stepping to the minimal\npoint along that direction. It'll be exact, OK. And then I've got\nto turn and I've",
    "start": "1067440",
    "end": "1073080"
  },
  {
    "text": "got to go in another\ngradient direction and take a step there. And I'll turn and go in\nanother gradient direction",
    "start": "1073080",
    "end": "1078980"
  },
  {
    "text": "and take a step there. And in each direction I go,\nI'll be minimizing every time.",
    "start": "1078980",
    "end": "1084360"
  },
  {
    "text": "Because this step size\nis the ideal step size. But it turns out you can\ndo even better than that.",
    "start": "1084360",
    "end": "1091210"
  },
  {
    "text": " So we can step in\nsome direction, which is a descent direction,\nbut not necessarily",
    "start": "1091210",
    "end": "1099270"
  },
  {
    "text": "the steepest descent. And it's going to give us\nsome extra control over how we're minimizing this function.",
    "start": "1099270",
    "end": "1105270"
  },
  {
    "text": "I'll explain on\nthe next slide, OK. The first thing you\ngot to do though is given some descent direction,\nwhat is the optimal step size?",
    "start": "1105270",
    "end": "1112324"
  },
  {
    "text": "Well, we'll work that\nout the same way, right. We can write f at the\nnext iterate in terms",
    "start": "1112324",
    "end": "1117480"
  },
  {
    "text": "of f at the current iterate plus\nall the perturbations, right. So our step method is Xi plus\n1 is Xi plus alpha pi, right.",
    "start": "1117480",
    "end": "1126907"
  },
  {
    "text": "So we do a Taylor\nexpansion, and we'll get a quadratic function again. And we'll minimize this\nquadratic function with respect",
    "start": "1126907",
    "end": "1134190"
  },
  {
    "text": "to alpha i when alpha\ntakes on this value. So this is the value of the\nvertex of this function.",
    "start": "1134190",
    "end": "1141970"
  },
  {
    "text": "So we'll minimize this\nquadratic function in one direction,\nthe direction p. ",
    "start": "1141970",
    "end": "1148700"
  },
  {
    "text": "But is there an optimal\nchoice of direction? Is it really best to step\nin the descent direction?",
    "start": "1148700",
    "end": "1154860"
  },
  {
    "text": "Or are there better\ndirections that I could go in? We thought going downhill\nfastest might be best,",
    "start": "1154860",
    "end": "1160080"
  },
  {
    "text": "but maybe that's not true. Because if I point\nto a direction and I apply my\nquadratic approximation,",
    "start": "1160080",
    "end": "1166650"
  },
  {
    "text": "I minimize the function\nin this direction. Now I'm going to\nturn, and I'm going to go in a different direction. And I'll minimize\nit here, but I'll",
    "start": "1166650",
    "end": "1174210"
  },
  {
    "text": "lose some of the minimization\nthat I got previously, right? I minimized in this direction. Then I turned, I went\nsome other way, right.",
    "start": "1174210",
    "end": "1180300"
  },
  {
    "text": "And I minimized\nin this direction. So this will still be a\nprocess that will sort of weave back and forth potentially.",
    "start": "1180300",
    "end": "1187630"
  },
  {
    "text": "And so the idea instead is to\ntry to preserve minimization along one particular direction.",
    "start": "1187630",
    "end": "1193900"
  },
  {
    "text": "So how do we choose\nan optimal direction? So f, right, at the\ncurrent iterate,",
    "start": "1193900",
    "end": "1199060"
  },
  {
    "text": "it's already minimized\nalong p, right. Moving in p forward\nand backwards, this is going to\nmake f and e smaller.",
    "start": "1199060",
    "end": "1205540"
  },
  {
    "text": "That's as small as it can be.  So why not choose p so that\nit's normal to the gradient",
    "start": "1205540",
    "end": "1216610"
  },
  {
    "text": "at the next iterate? OK, so choose this\ndirection p so it's normal to the gradient\nat the next iterate.",
    "start": "1216610",
    "end": "1222610"
  },
  {
    "text": "And then see if that holds for\none iterate more after that. So I move in a direction.",
    "start": "1222610",
    "end": "1229810"
  },
  {
    "text": "I step up to a contour. And I want my p to be\northogonal to the gradient",
    "start": "1229810",
    "end": "1234970"
  },
  {
    "text": "at that next contour. So I've minimized\nthis way, right. I've minimized everything\nthat I could in directions",
    "start": "1234970",
    "end": "1241240"
  },
  {
    "text": "that aren't in the\ngradient direction associated with\nthe next iterate. And then let's see if I can even\ndo that for the next iteration",
    "start": "1241240",
    "end": "1247570"
  },
  {
    "text": "too. So can it make it true that the\ngradient at the next iterate is also orthogonal to p?",
    "start": "1247570",
    "end": "1252650"
  },
  {
    "text": " By doing this, I get to\npreserve all the minimization",
    "start": "1252650",
    "end": "1259710"
  },
  {
    "text": "from the previous steps. So I minimize in this direction. And now I'm going to take a\nstep in a different direction.",
    "start": "1259710",
    "end": "1265150"
  },
  {
    "text": "But I'm going to\nmake sure that as I take that step in\nanother direction, right,",
    "start": "1265150",
    "end": "1270631"
  },
  {
    "text": "I don't have to step\ncompletely in the gradient. I don't have to go in the\nsteepest descent direction. I can project out\neverything that I've",
    "start": "1270631",
    "end": "1276049"
  },
  {
    "text": "stepped in already, right. I can project out\nall the minimization I've already accomplished\nalong this p direction.",
    "start": "1276050",
    "end": "1282860"
  },
  {
    "text": "So it turns out you\ncan solve, right, you can calculate\nwhat this gradient is.",
    "start": "1282860",
    "end": "1288260"
  },
  {
    "text": "The gradient in this\nfunction is Ax minus b. So you can substitute exactly\nwhat that gradient is.",
    "start": "1288260",
    "end": "1295514"
  },
  {
    "text": "A, this is Xi plus 2 minus\nb dotted with p, right.",
    "start": "1295514",
    "end": "1301550"
  },
  {
    "text": "This has to be equal to 0. And you can show that means\nthat p transpose A times p has to be equal to 0 as well.",
    "start": "1301550",
    "end": "1308497"
  },
  {
    "text": "You don't need to be able to\nwork through these details. You just need to\nknow that this gives a relationship\nbetween the directions",
    "start": "1308497",
    "end": "1314780"
  },
  {
    "text": "on two consecutive iterates, OK. So it says if I\npicked a direction p on the previous iteration,\ntake how it's transposed by A,",
    "start": "1314780",
    "end": "1324776"
  },
  {
    "text": "and make sure that\nmy next iteration is orthogonal to that vector, OK.",
    "start": "1324776",
    "end": "1330228"
  },
  {
    "text": "Yeah? STUDENT: So does that\nmean that your p's are all independent\nof each other,",
    "start": "1330228",
    "end": "1337850"
  },
  {
    "text": "or just that adjacent p is? K, k plus 1 p's are?",
    "start": "1337850",
    "end": "1343329"
  },
  {
    "text": "JAMES SWAN: This is\na great question. ",
    "start": "1343329",
    "end": "1349300"
  },
  {
    "text": "So the goal with this method,\nthe ideal way to do this would be to have these\ndirections actually",
    "start": "1349300",
    "end": "1356080"
  },
  {
    "text": "be the directions of\nthe eigenvectors of A. And those eigenvectors\nfor symmetric matrix",
    "start": "1356080",
    "end": "1362710"
  },
  {
    "text": "are all orthogonal\nto each other. OK? And so you'll be stepping along\nthese orthogonal directions.",
    "start": "1362710",
    "end": "1368860"
  },
  {
    "text": "And they would be all\nindependent of each other. OK? But that's a hard problem,\nfinding all the eigenvectors associated with a matrix.",
    "start": "1368860",
    "end": "1375179"
  },
  {
    "text": "Instead, OK, we pick an\ninitial direction p to go in. And then we try to ensure that\nall of the other directions",
    "start": "1375180",
    "end": "1382420"
  },
  {
    "text": "satisfy this conjugacy\ncondition, right.",
    "start": "1382420",
    "end": "1387640"
  },
  {
    "text": "That the transformation\nof p by A is orthogonal with the next\ndirection that I choose. So they're not\nindependent of each other.",
    "start": "1387640",
    "end": "1395450"
  },
  {
    "text": "But they are what we call\nconjugate to each other. It turns out that by doing\nthis, these sets of directions p",
    "start": "1395450",
    "end": "1403530"
  },
  {
    "text": "will belong to-- they can be expressed in\nterms of many products of A",
    "start": "1403530",
    "end": "1409120"
  },
  {
    "text": "with the initial direction p. That'll give you all these\ndifferent directions. It starts to look something\nlike the power iteration method",
    "start": "1409120",
    "end": "1415150"
  },
  {
    "text": "for finding the largest\neigenvector of a matrix. OK? So you create a\ncertain set of vectors",
    "start": "1415150",
    "end": "1421450"
  },
  {
    "text": "that span the entire\nsubspace of A. And you step specifically\nalong those directions.",
    "start": "1421450",
    "end": "1427456"
  },
  {
    "text": "And that lets you preserve\nsome of the minimization as you step each way. ",
    "start": "1427456",
    "end": "1434490"
  },
  {
    "text": "So what's said here is\nthat the direction p plus 1 is conjugate to the direction p.",
    "start": "1434490",
    "end": "1443290"
  },
  {
    "text": "And by choosing the\ndirections in this way, you're ensuring that p is\northogonal to the gradient at i",
    "start": "1443290",
    "end": "1450520"
  },
  {
    "text": "plus 1 and the\ngradient i plus 2. So you're not stepping in the\nsteepest descent directions",
    "start": "1450520",
    "end": "1457000"
  },
  {
    "text": "that you'll pick up later\non in the iterative process. OK?",
    "start": "1457000",
    "end": "1463074"
  },
  {
    "text": "So when you know which\ndirection you're stepping in, then you've got to satisfy\nthis conjugacy condition.",
    "start": "1463074",
    "end": "1469100"
  },
  {
    "text": "But actually, this is a\nvector in n space, right.",
    "start": "1469100",
    "end": "1474710"
  },
  {
    "text": "This is also a vector n space. And we have one equation to\ndescribe all and components.",
    "start": "1474710",
    "end": "1480260"
  },
  {
    "text": "So it's an\nunder-determined problem. So then one has to pick\nwhich particular one",
    "start": "1480260",
    "end": "1485960"
  },
  {
    "text": "of these conjugate vectors\ndo I want to step along. And one particular\nchoice is this one, which says, step along the\ngradient direction, OK, do",
    "start": "1485960",
    "end": "1493790"
  },
  {
    "text": "steepest descent,\nbut project out the component of the\ngradient along pi.",
    "start": "1493790",
    "end": "1500090"
  },
  {
    "text": "We already minimized along pi. We don't not have to go in the\npi direction anymore, right. So do steepest descent, but\nremove the pi component.",
    "start": "1500090",
    "end": "1508676"
  },
  {
    "text": " So here is a quadratic\nobjective function.",
    "start": "1508676",
    "end": "1519590"
  },
  {
    "text": "It corresponds to a linear\nequation with coefficient matrix 1 00 10, a diagonal\ncoefficient matrix.",
    "start": "1519590",
    "end": "1527690"
  },
  {
    "text": "And b equals 0. So the solution of the system\nof linear equations is 00.",
    "start": "1527690",
    "end": "1533720"
  },
  {
    "text": "We start with an initial\nguess up here, OK. And we try steepest descent with\nsome small step size, right.",
    "start": "1533720",
    "end": "1543390"
  },
  {
    "text": "You'll follow this\nblue path here. And you can see what happened. That step size was\nreasonable as we",
    "start": "1543390",
    "end": "1549240"
  },
  {
    "text": "moved along the steepest\nascent direction where the contours were\npretty narrowly spaced.",
    "start": "1549240",
    "end": "1554950"
  },
  {
    "text": "But as we got down to\nthe flatter section, OK, as we got down\nto the flatter section of our\nobjective function,",
    "start": "1554950",
    "end": "1563760"
  },
  {
    "text": "those steps are really small. Right? We're headed in the\nright direction, we're just taking\nvery, very small steps.",
    "start": "1563760",
    "end": "1569545"
  },
  {
    "text": "If you apply this conjugate\ngradient methodology, well, the first step you\ntake, that's prescribed.",
    "start": "1569545",
    "end": "1578110"
  },
  {
    "text": "You've got to step\nin some direction. The second step you take\nthough minimizes completely",
    "start": "1578110",
    "end": "1584230"
  },
  {
    "text": "along this direction. So the first step was the\nsame for both of these. But the second step was\nchosen to minimize completely",
    "start": "1584230",
    "end": "1592710"
  },
  {
    "text": "along this direction. So it's totally minimized. And the third step here\nalso steps all the way",
    "start": "1592710",
    "end": "1601490"
  },
  {
    "text": "to the center. So it shows a conjugate\ndirection that stepped from here to there. And it didn't lose any\nof the minimization",
    "start": "1601490",
    "end": "1609110"
  },
  {
    "text": "in the original direction\nthat it proceeded along. So that's conjugate gradient.",
    "start": "1609110",
    "end": "1614935"
  },
  {
    "text": "It's used to solve linear\nequations with order n iterations, right. So A has at most n\nindependent eigenvectors,",
    "start": "1614936",
    "end": "1625690"
  },
  {
    "text": "independent directions that\nI can step along and do this minimization.",
    "start": "1625690",
    "end": "1630700"
  },
  {
    "text": "The conjugate gradient method\nis doing precisely that. Doesn't know what the\neigendirections are, but it's something along these\nconjugate directions as a proxy",
    "start": "1630700",
    "end": "1637149"
  },
  {
    "text": "for the eigendirections. So it can do minimization\nwith just n steps for a system",
    "start": "1637150",
    "end": "1644560"
  },
  {
    "text": "of n equations for n unknowns.  It requires only the\nability to compute",
    "start": "1644560",
    "end": "1651350"
  },
  {
    "text": "the product of your matrix\nA with some vector, right. All the calculations\nthere are only",
    "start": "1651350",
    "end": "1656420"
  },
  {
    "text": "depended on the product\nof A with a vector. So don't have to store A, we\njust have to know what A is. We have some procedure\nfor generating A.",
    "start": "1656420",
    "end": "1664250"
  },
  {
    "text": "Maybe A is a linear\noperator that comes from a solution of some\ndifferential equations",
    "start": "1664250",
    "end": "1670550"
  },
  {
    "text": "instead, right. And we don't have an\nexplicit expression for A, but we have some simulator\nthat produces, take some data,",
    "start": "1670550",
    "end": "1677990"
  },
  {
    "text": "and projects A to give\nsome answer, right. So we just need this product. We don't have to\nstore A exactly.",
    "start": "1677990",
    "end": "1685279"
  },
  {
    "text": "It's only good for symmetric\npositive definite matrices, right. This sort of free energy\nfunctional that we wrote",
    "start": "1685280",
    "end": "1690950"
  },
  {
    "text": "or objective function\nwe wrote only admits symmetric matrices\nwhich are positive definite.",
    "start": "1690950",
    "end": "1696239"
  },
  {
    "text": "That's the only way it\nwill have a minimum. And so the only way a steepest\ndescent or descent type procedure is going to\nget to the optimum.",
    "start": "1696239",
    "end": "1704929"
  },
  {
    "text": "But there are more\nsophisticated methods that exist for arbitrary matrices. So if we don't want symmetry\nor we don't care about",
    "start": "1704930",
    "end": "1712970"
  },
  {
    "text": "whether it's positive\ndefinite, there are equivalent sorts of\nmethods that are based around the same principle.",
    "start": "1712970",
    "end": "1719600"
  },
  {
    "text": "And it turns out, this is\nreally the state of the art. So if you want to solve\ncomplicated large systems",
    "start": "1719600",
    "end": "1724970"
  },
  {
    "text": "of equations, you know\nGaussian elimination, that will get you an exact solution. But that's often infeasible\nfor the sorts of problems",
    "start": "1724970",
    "end": "1732817"
  },
  {
    "text": "that we're really interested in. So instead, you use these\nsorts of iterative methods. Things like Jacobi\nand Gauss-Seidel,",
    "start": "1732817",
    "end": "1739850"
  },
  {
    "text": "they're sort of the\nclassics in the field. And they work, and you can\nshow that they converge on",
    "start": "1739850",
    "end": "1745220"
  },
  {
    "text": "are lots of circumstances. But these sorts of\niterative methods, like conjugate gradient and its\nbrethren other Krylov subspace",
    "start": "1745220",
    "end": "1753140"
  },
  {
    "text": "methods they're\ncalled, are really the state of the art, and\nthe ones that you reach to. You already did conjugate\ngradients in one homework,",
    "start": "1753140",
    "end": "1759510"
  },
  {
    "text": "right. You used this PCG\niterative method in Matlab to solve a system\nof linear equations.",
    "start": "1759510",
    "end": "1764980"
  },
  {
    "text": "It was doing this, right. This is how it works. OK? OK.",
    "start": "1764980",
    "end": "1771929"
  },
  {
    "text": "OK, so that's\ncountry ingredients. You could apply it also to\nobjective functions that",
    "start": "1771930",
    "end": "1781400"
  },
  {
    "text": "aren't quadratic in nature. And the formulation\nchanges a little bit.",
    "start": "1781400",
    "end": "1786680"
  },
  {
    "text": "Everywhere where the\nmatrix A appeared there needs to be\nreplaced with the Hessian at a certain iterate.",
    "start": "1786680",
    "end": "1792590"
  },
  {
    "text": "But the same idea persists. It says well, we think\nin our best approximation for the function that\nwe've minimized as much",
    "start": "1792590",
    "end": "1798590"
  },
  {
    "text": "as we can in one direction. So let's choose a conjugate\ndirection to go in, and try not to ruin\nthe minimizations we",
    "start": "1798590",
    "end": "1804950"
  },
  {
    "text": "did in the direction\nwe were headed before. Of course, these are all\nlinearly convergent sorts",
    "start": "1804950",
    "end": "1812390"
  },
  {
    "text": "of methods. And we know that\nthere are better ways to find roots of non-linear\nequations like this one,",
    "start": "1812390",
    "end": "1820070"
  },
  {
    "text": "grad f equals zero, namely\nthe Newton-Raphson method, which is quadratically\nconvergent. So if we're really close\nto a critical point,",
    "start": "1820070",
    "end": "1827010"
  },
  {
    "text": "and hopefully that critical\npoint is a minima in f, right, then we should\nrapidly converge to the solution of this\nsystem of nonlinear equations",
    "start": "1827010",
    "end": "1835700"
  },
  {
    "text": "just by applying the\nNewton-Raphson method.  It's locally convergent, right.",
    "start": "1835700",
    "end": "1842120"
  },
  {
    "text": "So we're going to get close. And we get quadratic\nimprovement. What is the Newton-Raphson\niteration, though?",
    "start": "1842120",
    "end": "1848750"
  },
  {
    "text": "Can you write that down? What is the\nNewton-Raphson iteration that's the iterative\nmath for this system",
    "start": "1848750",
    "end": "1855110"
  },
  {
    "text": "of non-linear equations,\ngrad f equals 0? Can you work that out?",
    "start": "1855110",
    "end": "1860890"
  },
  {
    "text": "What's that look like? ",
    "start": "1860890",
    "end": "1931200"
  },
  {
    "text": "Have we got this? What's the Newton-Raphson\niterative map look like for this system\nof non-linear equations?",
    "start": "1931200",
    "end": "1940630"
  },
  {
    "text": " Want to volunteer an answer? ",
    "start": "1940630",
    "end": "1948530"
  },
  {
    "text": "Nobody knows or\nnobody is sharing. OK, that's fine. Right, so we're trying to solve\nan equation g of x equals 0.",
    "start": "1948530",
    "end": "1956680"
  },
  {
    "text": "So the iterative map is Xi\nplus 1 is Xi minus Jacobi inverse times g.",
    "start": "1956680",
    "end": "1963470"
  },
  {
    "text": "And what's the Jacobian of g? ",
    "start": "1963470",
    "end": "1968680"
  },
  {
    "text": "What's the Jacobian of g? The Hessian, right. So the Jacobian of\ng is the gradient",
    "start": "1968680",
    "end": "1974809"
  },
  {
    "text": "of g, which is two\ngradients of f, which is the definition of the Hessian. So really, the\nNewton-Raphson iteration",
    "start": "1974810",
    "end": "1981680"
  },
  {
    "text": "is Xi plus 1 is Xi minus\nHessian inverse times g.",
    "start": "1981680",
    "end": "1986915"
  },
  {
    "start": "1986915",
    "end": "1994350"
  },
  {
    "text": "So the Hessian plays the\nrole of the Jacobian, the sort of solution procedure. ",
    "start": "1994350",
    "end": "2004492"
  },
  {
    "text": "And so everything you\nknow about Newton-Raphson is going to apply here. Everything you know about\nquasi-Newton-Raphson methods",
    "start": "2004492",
    "end": "2009810"
  },
  {
    "text": "is going to apply here. You're going to substitute\nfor your nonlinear. The nonlinear function\nyou're finding the root for,",
    "start": "2009810",
    "end": "2015800"
  },
  {
    "text": "you're going to\nsubstitute the gradient. And for the Jacobian,\nyou're going to substitute the Hessian. Places where the Hessian is, the\ndeterment of the Hessian is 0,",
    "start": "2015800",
    "end": "2024360"
  },
  {
    "text": "right it's going\nto be a problem. Places where the\nHessian is singular is going to be a problem. Same as with the Jacobian. ",
    "start": "2024360",
    "end": "2032342"
  },
  {
    "text": "But Newton-Raphson\nhas the great property that if our function is\nquadratic, like this one is,",
    "start": "2032342",
    "end": "2038250"
  },
  {
    "text": "it will converge in\nexactly one step. ",
    "start": "2038250",
    "end": "2046020"
  },
  {
    "text": "So here's steepest\ndescent with a fixed value of alpha,\nNewton-Raphson, one step for a quadratic function.",
    "start": "2046020",
    "end": "2053369"
  },
  {
    "text": "And why is it one step? STUDENT: [INAUDIBLE]",
    "start": "2053370",
    "end": "2058636"
  },
  {
    "text": " JAMES SWAN: Good.",
    "start": "2058636",
    "end": "2064030"
  },
  {
    "text": "So when we take a Taylor\nexpansion of our f,",
    "start": "2064030",
    "end": "2069760"
  },
  {
    "text": "in order to derive the\nNewton-Raphson step, we're expanding it out\nto quadratic order,",
    "start": "2069760",
    "end": "2075419"
  },
  {
    "text": "its function is quadratic. The Taylor expansion is exact. And the solution of\nthat equation, right,",
    "start": "2075420",
    "end": "2080800"
  },
  {
    "text": "gradient f equals\n0 or g equals 0, that's the solution of a\nlinear equation, right.",
    "start": "2080800",
    "end": "2085870"
  },
  {
    "text": " So it gives exactly the\nright step size here",
    "start": "2085870",
    "end": "2093099"
  },
  {
    "text": "to move from an initial\nguess to the exact solution or the minima of this equation.",
    "start": "2093100",
    "end": "2098744"
  },
  {
    "text": "So for quadratic equations,\nNewton-Raphson is exact. It doesn't go in the steepest\nascent direction, right.",
    "start": "2098745",
    "end": "2106750"
  },
  {
    "text": "It goes in a\ndifferent direction. It would like to go in the\nsteepest descent direction if the Jacobian were identity.",
    "start": "2106750",
    "end": "2115450"
  },
  {
    "text": "But the Jacobian is a\nmeasure of how curved f is. The Hessian, let's say, is a\nmeasure of how curved f is.",
    "start": "2115450",
    "end": "2123310"
  },
  {
    "text": "Right? And so there's a\nprojection of the gradient through the Hessian that\nchanges the direction we go in.",
    "start": "2123310",
    "end": "2129980"
  },
  {
    "text": "That change in\ndirection is meant to find the minimum of the\nquadratic function that we",
    "start": "2129980",
    "end": "2135770"
  },
  {
    "text": "approximate at this point. So as long as we have a good\nquadratic approximation, Newton-Raphson is going to give\nus good convergence to a minima",
    "start": "2135770",
    "end": "2142024"
  },
  {
    "text": "or whatever nearby\ncritical point there is. If we have a bad\napproximation for a quadratic, then it's going to\nbe so good, right.",
    "start": "2142024",
    "end": "2150160"
  },
  {
    "text": "So here's this very\nsteep function. Log of f is quadratic, but\nf is exponential in x here.",
    "start": "2150160",
    "end": "2156850"
  },
  {
    "text": "So you got all these tightly\nspaced contours converging towards a minima at 00.",
    "start": "2156850",
    "end": "2162789"
  },
  {
    "text": "And here I've got to use\nthe steepest descent step size, the optimal steepest\ndescent step size, which",
    "start": "2162790",
    "end": "2167860"
  },
  {
    "text": "is a quadratic approximation\nfor the function, but in the steepest\ndescent direction only. And here's the path\nthat it follows.",
    "start": "2167860",
    "end": "2174640"
  },
  {
    "text": "And if I applied Newton-Raphson\nto this function, here is the path that\nit follows instead.",
    "start": "2174640",
    "end": "2179830"
  },
  {
    "text": "The function isn't quadratic. So these quadratic\napproximations aren't-- they're not great, right.",
    "start": "2179830",
    "end": "2185589"
  },
  {
    "text": "But the function\nis convex, right. So Newton-Raphson is\ngoing to proceed downhill",
    "start": "2185590",
    "end": "2191950"
  },
  {
    "text": "until it converges towards\na solution anyways. Because the Hessian has positive\neigenvalues all the time.",
    "start": "2191950",
    "end": "2198280"
  },
  {
    "text": " Questions about this?",
    "start": "2198280",
    "end": "2203450"
  },
  {
    "text": "Make sense? OK? So you get two different\ntypes of methods that you can play with. One of which, right, is always\ngoing to direct you down hill.",
    "start": "2203450",
    "end": "2214250"
  },
  {
    "text": "Steepest descent will always\ncarry you downhill, right, towards a minima. And the other one,\nNewton-Raphson,",
    "start": "2214250",
    "end": "2220430"
  },
  {
    "text": "converges very quickly when\nit's close to the root. OK, so they each have a virtue. ",
    "start": "2220430",
    "end": "2227504"
  },
  {
    "text": "And they're different. They're fundamentally\ndifferent, right. They take steps in completely\ndifferent directions.",
    "start": "2227504",
    "end": "2233320"
  },
  {
    "text": "When is Newton-Raphson not\ngoing to step down hill? ",
    "start": "2233320",
    "end": "2250918"
  },
  {
    "text": "STUDENT: [INAUDIBLE] What's that? STUDENT: [INAUDIBLE] JAMES SWAN: OK,\nthat's more generic",
    "start": "2250918",
    "end": "2257929"
  },
  {
    "text": "an answer than I'm looking for. So there may be circumstances\nwhere I have two local minima.",
    "start": "2257929",
    "end": "2263390"
  },
  {
    "text": "That means there must be\nmaybe a saddle point that sits between them. Newton-Raphson doesn't\ncare which critical point",
    "start": "2263390",
    "end": "2269330"
  },
  {
    "text": "it's going after. So it may try to approach\nthe saddle point instead. That's true. That's true.",
    "start": "2269330",
    "end": "2276030"
  },
  {
    "text": "Yeah? STUDENT: When\nHessian [INAUDIBLE].. JAMES SWAN: Good, yeah.",
    "start": "2276030",
    "end": "2281510"
  },
  {
    "text": "With the Hessian doesn't have\nall positive eigenvalues, right. So if all the eigenvalues\nof the Hessian are positive,",
    "start": "2281510",
    "end": "2290390"
  },
  {
    "text": "then the transformation h\ntimes g or h inverse times g, it'll never switch the\ndirection I'm going.",
    "start": "2290390",
    "end": "2297760"
  },
  {
    "text": "I'll always be headed\nin a downhill direction. Right? In a direction that's\nanti-parallel to the gradient.",
    "start": "2297760",
    "end": "2305011"
  },
  {
    "text": "OK? But if the eigenvalues\nof the Hessian are negative, if some\nof them are negative",
    "start": "2305011",
    "end": "2310430"
  },
  {
    "text": "and the gradient has\nme pointing along that eigenvector in\na significant amount,",
    "start": "2310430",
    "end": "2315890"
  },
  {
    "text": "then this product\nwill switch me around and will have me\ngo uphill instead. It'll have me chasing down\na maxima or a saddle point",
    "start": "2315890",
    "end": "2324260"
  },
  {
    "text": "instead. That's what the\nquadratic approximation of our objective\nfunction will look like.",
    "start": "2324260",
    "end": "2329834"
  },
  {
    "text": "It looks like there's a\nmaximum or a saddle instead. And the function\nwill run uphill. OK?",
    "start": "2329834",
    "end": "2336645"
  },
  {
    "text": "So there lots of strengths\nto Newton-Raphson. Convergence is one\nof them, right. The rate of convergence is good.",
    "start": "2336645",
    "end": "2341725"
  },
  {
    "text": "It's a locally\nconvergent, that's good. It's got lots of\nweaknesses, though. Right? It's going to be a pain\nwhen the Hessian is",
    "start": "2341725",
    "end": "2346950"
  },
  {
    "text": "singular at various places. You've got to solve\nsystems of linear equations to figure out what\nthese steps are.",
    "start": "2346950",
    "end": "2353130"
  },
  {
    "text": "That's expensive\ncomputationally. It's not designed\nto seek out minima,",
    "start": "2353130",
    "end": "2359070"
  },
  {
    "text": "but to seek out critical points\nof our objective function. ",
    "start": "2359070",
    "end": "2364869"
  },
  {
    "text": "Steepest descent has\nlots of strengths, right. Always heads\ndownhill, that's good. If we put a little quadratic\napproximation on it,",
    "start": "2364870",
    "end": "2371800"
  },
  {
    "text": "we can even stabilize it and get\ngood control over the descent.",
    "start": "2371800",
    "end": "2376870"
  },
  {
    "text": "Its weaknesses are\nit's got the property that it's linearly convergent\ninstead of quadratically",
    "start": "2376870",
    "end": "2384827"
  },
  {
    "text": "convergent when it converges. So it's slower, right. It might be harder\nto find a minima. You've seen several examples\nwhere the path sort of peters",
    "start": "2384827",
    "end": "2392210"
  },
  {
    "text": "out with lots of little\niterations, tiny steps towards the solution.",
    "start": "2392210",
    "end": "2397400"
  },
  {
    "text": "That's a weakness\nof steepest descent. We know that if we\ngo over the edge of a cliff on our\npotential energy landscape,",
    "start": "2397400",
    "end": "2404480"
  },
  {
    "text": "steepest descent it just\ngoing to run away, right. As long as there's\none of these edges, it'll just keep running downhill\nfor as long as they can.",
    "start": "2404480",
    "end": "2411217"
  },
  {
    "text": " So what's done is to try\nto combine these methods.",
    "start": "2411217",
    "end": "2417539"
  },
  {
    "text": "Why choose one, right? We're trying to step our\nway towards a solution.",
    "start": "2417540",
    "end": "2422640"
  },
  {
    "text": "What if we could\ncraft a heuristic procedure that mixed these two? And when steepest descent\nwould be best, use that.",
    "start": "2422640",
    "end": "2428487"
  },
  {
    "text": "When Newton-Raphson\nwould be best, use that. Yes? STUDENT: Just a quick\nquestion on Newton-Raphson. JAMES SWAN: Yes? STUDENT: Would it\nrun downhill also",
    "start": "2428487",
    "end": "2434682"
  },
  {
    "text": "if you started it over there? Or since it seeks\ncritical points, could you go back up\nto the [INAUDIBLE]..",
    "start": "2434682",
    "end": "2442482"
  },
  {
    "text": "JAMES SWAN: That's\na good question. So if there's an\nasymptote in f, it",
    "start": "2442482",
    "end": "2450369"
  },
  {
    "text": "will perceive the asymptote as\na critical point and chase it. OK?",
    "start": "2450370",
    "end": "2455449"
  },
  {
    "text": "And so if there's an\nasymptote in f, if can perceive that and chase it. It can also run away as\nit gets very far away.",
    "start": "2455449",
    "end": "2461000"
  },
  {
    "text": "This is true. OK? ",
    "start": "2461000",
    "end": "2468580"
  },
  {
    "text": "The contour example that I\ngave you at the start of class had sort of bowl shape\nfunctions superimposed",
    "start": "2468580",
    "end": "2475119"
  },
  {
    "text": "with a linear function, sort\nof planar function instead. For that one, right, the\nHessian is ill-defined, right.",
    "start": "2475120",
    "end": "2484519"
  },
  {
    "text": "There is no curvature\nto the function. But you can imagine adding\na small bit of curvature to that, right. And depending on the\ndirection of the curvature,",
    "start": "2484520",
    "end": "2491410"
  },
  {
    "text": "Newton-Raphson may run downhill\nor it may run back up hill, right? We can't guarantee which\ndirection it's going to go.",
    "start": "2491410",
    "end": "2497230"
  },
  {
    "text": "Depends on the details\nof the function. Does that answer your question? Yeah? Good. STUDENT: Sir, can you just\ngo back to that one slide?",
    "start": "2497230",
    "end": "2503690"
  },
  {
    "text": "JAMES SWAN: Yeah. I'm just pointing out,\nif the eigenvalues of h is further negative, then\nthe formula there for alpha",
    "start": "2503690",
    "end": "2509982"
  },
  {
    "text": "could have trouble too. JAMES SWAN: That's true. STUDENT: Similar to how the\nNewton-Raphson had trouble. JAMES SWAN: This is true.",
    "start": "2509982",
    "end": "2516551"
  },
  {
    "text": "This is true, yeah. So we chose a quadratic\napproximation here, right,",
    "start": "2516551",
    "end": "2521800"
  },
  {
    "text": "for our function. We sought a critical point of\nthis quadratic approximation. We didn't mandate that\nit had to be a minima.",
    "start": "2521800",
    "end": "2527750"
  },
  {
    "text": "So that's absolutely right. So if h has negative eigenvalues\nand the gradient points",
    "start": "2527750",
    "end": "2533619"
  },
  {
    "text": "enough in the direction\nof the eigenvectors associated with those\nnegative eigenvalues, then we may have a case\nwhere alpha isn't positive.",
    "start": "2533620",
    "end": "2542099"
  },
  {
    "text": "We required early on\nthat alpha should be positive for steepest descent. So we can't have a case\nwhere alpha is not positive.",
    "start": "2542100",
    "end": "2548930"
  },
  {
    "text": "That's true. OK. So they're both\ninteresting methods, and they can be mixed together.",
    "start": "2548930",
    "end": "2555270"
  },
  {
    "text": "And the way you mix\nthose is with what's called trust-region ideas, OK.",
    "start": "2555270",
    "end": "2561030"
  },
  {
    "text": "Because it could be that\nwe've had an iteration Xi and we do a\nquadratic approximation",
    "start": "2561030",
    "end": "2568380"
  },
  {
    "text": "to our functional, which\nis this blue curve. Our quadratic approximation\nis this red one.",
    "start": "2568380",
    "end": "2574260"
  },
  {
    "text": "And we find the minima\nof this red curve and use that as our next\nbest guess for the solution to the problem.",
    "start": "2574260",
    "end": "2579390"
  },
  {
    "text": "And this seems to be\nworking us closer and closer towards the actual\nminimum in the function. So since quadratic\napproximation seems good,",
    "start": "2579390",
    "end": "2586410"
  },
  {
    "text": "if the quadratic\napproximation is good, which method should we choose?",
    "start": "2586410",
    "end": "2591440"
  },
  {
    "text": "STUDENT: Newton-Raphson. JAMES SWAN:\nNewton-Raphson, right. Could also be the\ncase though that we",
    "start": "2591440",
    "end": "2596970"
  },
  {
    "text": "make this quadratic\napproximation from our current\niteration, and we",
    "start": "2596970",
    "end": "2602510"
  },
  {
    "text": "find a minimum that somehow\noversteps the minimum here. In fact, if we look at the\nvalue of our objective function",
    "start": "2602510",
    "end": "2609980"
  },
  {
    "text": "at this next step, it's\nhigher than the value of the objective function\nwhere we started. So it seems like a quadratic\napproximation is not so good,",
    "start": "2609980",
    "end": "2616980"
  },
  {
    "text": "right. That's a clear indication that\nthis quadratic approximation isn't right. Because it suggested that we\nshould have had an minima here,",
    "start": "2616980",
    "end": "2624140"
  },
  {
    "text": "right. But our function\ngot bigger instead. And so in this case,\nit doesn't seem",
    "start": "2624140",
    "end": "2629580"
  },
  {
    "text": "like you'd want to\nchoose Newton-Raphson to take your steps. The quadratic approximation\nis not so good.",
    "start": "2629580",
    "end": "2636150"
  },
  {
    "text": "Maybe just simple steepest\ndescent is a better choice. OK, so it's done.",
    "start": "2636150",
    "end": "2641510"
  },
  {
    "text": " So if you're at a point,\nyou might draw a circle",
    "start": "2641510",
    "end": "2648540"
  },
  {
    "text": "around that point with\nsome prescribed radius. Call that Ri. This is our iterate Xi.",
    "start": "2648540",
    "end": "2655770"
  },
  {
    "text": "This is our\ntrust-region radius Ri. And we might ask, where does\nour Newton-Raphson step go?",
    "start": "2655770",
    "end": "2665800"
  },
  {
    "text": "And where does our steepest\ndescent step take us? And then based on whether\nthese steps carry us",
    "start": "2665800",
    "end": "2672370"
  },
  {
    "text": "outside of our trust-region,\nwe might decide to take one or the other.",
    "start": "2672370",
    "end": "2678050"
  },
  {
    "text": "So if I set a\nparticular size Ri, particular trust-region size\nRi and the Newton-Raphson step",
    "start": "2678050",
    "end": "2684130"
  },
  {
    "text": "goes outside of that,\nwe might say well, I don't actually trust my\nquadratic approximation",
    "start": "2684130",
    "end": "2690710"
  },
  {
    "text": "this far away from\nthe starred point. So let's not take a\nstep in that direction.",
    "start": "2690710",
    "end": "2696859"
  },
  {
    "text": "Instead, let's move in a\nsteepest descent direction. If my Newton-Raphson step\nis inside the trust-region,",
    "start": "2696860",
    "end": "2703170"
  },
  {
    "text": "maybe I'll choose\nto take it, right. I trust the quadratic\napproximation within a distance Ri of\nmy current iteration.",
    "start": "2703170",
    "end": "2710660"
  },
  {
    "text": "Does that strategy makes sense? So we're trying to pick\nbetween two different methods",
    "start": "2710660",
    "end": "2715980"
  },
  {
    "text": "in order to give us more\nreliable convergence to a local minima. ",
    "start": "2715980",
    "end": "2724830"
  },
  {
    "text": "So here's our\nNewton-Raphson step. It's minus the Hessian\ninverse times the gradient. Here's our steepest\ndescent step.",
    "start": "2724830",
    "end": "2731400"
  },
  {
    "text": "It's minus alpha\ntimes the gradient. And if the\nNewton-Raphson step is",
    "start": "2731400",
    "end": "2737430"
  },
  {
    "text": "smaller than the\ntrust-region radius, and the value of the\nobjective function at Xi,",
    "start": "2737430",
    "end": "2745520"
  },
  {
    "text": "plus the Newton-Raphson\nstep is smaller than the current\nobjective function, it seems like the\nquadratic approximation",
    "start": "2745520",
    "end": "2751500"
  },
  {
    "text": "is a good one, right. I'm within the region in which\nI trust this approximation, and I've reduced the\nvalue of the function.",
    "start": "2751500",
    "end": "2758260"
  },
  {
    "text": "So why not go that way, right? So take the Newton-Raphson step. Else, let's try taking a step in\nthe steepest direction instead.",
    "start": "2758260",
    "end": "2769022"
  },
  {
    "text": "So again, if the steepest\nascent direction is smaller than Ri and the\nvalue of the function",
    "start": "2769022",
    "end": "2774500"
  },
  {
    "text": "in the steepest\ndescent direction, the optimal steepest descent\ndirection or the optimal step in the steepest ascent\ndirection is smaller",
    "start": "2774500",
    "end": "2781190"
  },
  {
    "text": "than the value of the\nfunction at the current point, seems like we should\ntake that step. Right? The Newton-Raphson\nstep was no good.",
    "start": "2781190",
    "end": "2787410"
  },
  {
    "text": "We've already discarded it. But our optimized\nsteepest descent step seems like an OK one. It reduces the value\nof the function.",
    "start": "2787410",
    "end": "2794258"
  },
  {
    "text": "And its within the\ntrust-region where we think quadratic\napproximations are valid. ",
    "start": "2794259",
    "end": "2801160"
  },
  {
    "text": "If that's not true, if the\nsteepest descent step takes us outside of our\ntrust-region or we",
    "start": "2801160",
    "end": "2806770"
  },
  {
    "text": "don't reduce the\nvalue of the function when we take that step,\nthen the next best strategy is to just take\na steepest ascent",
    "start": "2806770",
    "end": "2812830"
  },
  {
    "text": "step to the edge of the\ntrust-region boundary. Yeah? STUDENT: Is there a reason\nhere that Newton-Raphson",
    "start": "2812830",
    "end": "2818335"
  },
  {
    "text": "is the default? JAMES SWAN: Oh, good question. So eventually we're going to get\nclose enough to the solution,",
    "start": "2818335",
    "end": "2824320"
  },
  {
    "text": "all right, that all these\nsteps are going to live inside the trust-region ring.",
    "start": "2824320",
    "end": "2829566"
  },
  {
    "text": "Its going to require\nvery small steps to converge to the solution. And which of these two methods\nis going to converge faster?",
    "start": "2829566",
    "end": "2836059"
  },
  {
    "text": "STUDENT: Newton-Raphson. JAMES SWAN: Newton-Raphson. So we prioritize Newton-Raphson\nover steepest descent.",
    "start": "2836060",
    "end": "2841485"
  },
  {
    "text": "That's a great question.  Its the faster\nconverging one, but",
    "start": "2841485",
    "end": "2847690"
  },
  {
    "text": "its a little unwieldy, right. So let's take it\nwhen it seems valid.",
    "start": "2847690",
    "end": "2854740"
  },
  {
    "text": "But when it requires\nsteps that are too big or steps that don't minimize f,\nlet's take some different steps",
    "start": "2854740",
    "end": "2860180"
  },
  {
    "text": "instead. Lets use steepest\ndescent as the strategy. So this is heuristic.",
    "start": "2860180",
    "end": "2865515"
  },
  {
    "text": "So you got to have some rules to\ngo with this heuristic, right. We have a set of conditions\nunder which we're going to choose different steps.",
    "start": "2865516",
    "end": "2871383"
  },
  {
    "text": " We've got to set this\ntrust-region size.",
    "start": "2871383",
    "end": "2877540"
  },
  {
    "text": "This Ri has to be set. How big is it going to be? I don't know. You don't know, right, from\nthe start you can't guess",
    "start": "2877540",
    "end": "2883780"
  },
  {
    "text": "how big Ri is going to be. So you got to pick\nsome initial guess. And then we've got to modify\nthe size of the trust-region",
    "start": "2883780",
    "end": "2890090"
  },
  {
    "text": "too, right. The size of the trust-region\nis not going to be appropriate. One fixed size is not going to\nbe appropriate all the time.",
    "start": "2890090",
    "end": "2896378"
  },
  {
    "text": "Instead, we want a strategy\nfor changing its size. So it should grow or shrink\ndepending on which steps we",
    "start": "2896378",
    "end": "2902330"
  },
  {
    "text": "choose, right. Like if we take the\nNewton-Raphson step",
    "start": "2902330",
    "end": "2909349"
  },
  {
    "text": "and we find that our\nquadratic approximation is a little bit bigger than\nthe actual function value",
    "start": "2909350",
    "end": "2915830"
  },
  {
    "text": "that we predicted, we might\nwant to grow the trust-region. We might be more\nlikely to believe",
    "start": "2915830",
    "end": "2922550"
  },
  {
    "text": "that these Newton-Raphson\nsteps are getting us to smaller and smaller\nfunction values, right. The step was even better\nthan we expected it to be.",
    "start": "2922550",
    "end": "2929490"
  },
  {
    "text": "Here's the quadratic\napproximation in the Newton-Raphson direction. And it was actually bigger\nthan the actual value",
    "start": "2929490",
    "end": "2935030"
  },
  {
    "text": "of the function. So we got more, you know, we\ngot more than we expected out of a step in that direction. So why not loosen up, accept\nmore Newton-Raphson steps?",
    "start": "2935030",
    "end": "2944200"
  },
  {
    "text": "OK, that's a\nstrategy we can take. Otherwise, we might think\nabout shrinking instead, right.",
    "start": "2944200",
    "end": "2949754"
  },
  {
    "text": "So there could be\nthe circumstance where our quadratic\napproximation predicted a smaller value for the\nfunction than we actually found.",
    "start": "2949754",
    "end": "2958980"
  },
  {
    "text": "It's not quite as reliable\nfor getting us to the minimum. These two circumstances\nare actually these.",
    "start": "2958980",
    "end": "2964720"
  },
  {
    "text": "So this one, the\nquadratic approximation predicted a slightly\nbigger value than we found.",
    "start": "2964720",
    "end": "2971990"
  },
  {
    "text": "Say grow the\ntrust-region, right. Try some more\nNewton-Raphson steps. Seems like the Newton-Raphson\nsteps are pretty reliable here.",
    "start": "2971990",
    "end": "2978440"
  },
  {
    "text": "Here the value of the function\nin the quadratic approximation is smaller than the\nvalue of the function",
    "start": "2978440",
    "end": "2984710"
  },
  {
    "text": "after we took the step. Seems like our trust-region\nis probably too big if we have a\ncircumstance like that.",
    "start": "2984710",
    "end": "2991369"
  },
  {
    "text": "Should shrink it a\nlittle bit, right? We took the Newton-Raphson\nstep, but it actually did worse than we\nexpected it to do with the quadratic\napproximation.",
    "start": "2991370",
    "end": "2997340"
  },
  {
    "text": "So maybe we ought to shrink the\ntrust-regional a little bit. ",
    "start": "2997340",
    "end": "3003585"
  },
  {
    "text": "And you need a\ngood initial value for the trust-region radius. What does Matlab use? It uses 1.",
    "start": "3003585",
    "end": "3008780"
  },
  {
    "text": "OK. It doesn't know. It has no clue. It's just a heuristic. It starts with 1 and it\nchanges it as need be.",
    "start": "3008780",
    "end": "3016480"
  },
  {
    "text": "So this is how fsolve solves\nsystems of nonlinear equations. This is how all of the\nminimizers in Matlab, this",
    "start": "3016480",
    "end": "3024549"
  },
  {
    "text": "is the strategy they use\nto try to find minima. They use these sorts of\ntrust-region methods.",
    "start": "3024550",
    "end": "3030970"
  },
  {
    "text": "It uses a slight improvement,\nwhich is also heuristic, called a dogleg\ntrust-region method.",
    "start": "3030970",
    "end": "3038829"
  },
  {
    "text": "So you can take a\nNewton-Raphson step or you can take a\nsteepest descent step.",
    "start": "3038830",
    "end": "3044660"
  },
  {
    "text": "And if you found the steepest\ndescent step didn't quite get you to the boundary\nof your trust-region, you could then step in the\nNewton-Raphson direction.",
    "start": "3044660",
    "end": "3052030"
  },
  {
    "text": "Why do you do that? I don't know, people have\nfound that it's useful, right. There's actually no\ngood reason to take",
    "start": "3052030",
    "end": "3057400"
  },
  {
    "text": "these sorts of dogleg steps. People found that for general,\nright, general objective",
    "start": "3057400",
    "end": "3063220"
  },
  {
    "text": "functions that you might\nwant to find minima of, this is a reliable\nstrategy for getting there.",
    "start": "3063220",
    "end": "3069220"
  },
  {
    "text": "There's no guarantee that\nthis is the best strategy. These are general\nnon-convex functions.",
    "start": "3069220",
    "end": "3074760"
  },
  {
    "text": "These are just hard problems\nthat one encounters. So when you make a software\npackage like Matlab,",
    "start": "3074760",
    "end": "3080090"
  },
  {
    "text": "this is what you do. You come up with heuristics\nthat work most of the time.",
    "start": "3080090",
    "end": "3085192"
  },
  {
    "text": "I'll just provide you\nwith an example here, OK. So you've seen this\nfunction now several times. ",
    "start": "3085192",
    "end": "3091720"
  },
  {
    "text": "Let's see, so in red\ncovered up back here is the Newton-Raphson path. In blue is the optimal\nsteepest descent path.",
    "start": "3091720",
    "end": "3098680"
  },
  {
    "text": "And in purple is the\ntrust-region method that Matlab uses\nto find the minima. They all start from\nthe same place.",
    "start": "3098680",
    "end": "3104919"
  },
  {
    "text": "And you can see the\npurple path is a little different from these two. If I zoom in right up\nhere, what you'll see",
    "start": "3104919",
    "end": "3112260"
  },
  {
    "text": "is initially Matlab chose to\nfollow the steepest descent path. And then at a certain point it\ndecided, because of the value",
    "start": "3112260",
    "end": "3120690"
  },
  {
    "text": "of the trust-region that\nNewton-Raphson steps were to be preferred. And so it changed\ndirection and it",
    "start": "3120690",
    "end": "3126005"
  },
  {
    "text": "started stepping along the\nNewton-Raphson direction instead. ",
    "start": "3126005",
    "end": "3133059"
  },
  {
    "text": "It has some built in\nlogic that tells it when to make that\nchoice for switching based on the size\nof the trust-region.",
    "start": "3133060",
    "end": "3138850"
  },
  {
    "text": "And the idea is just to\nchoose the best sorts of steps possible.",
    "start": "3138850",
    "end": "3144880"
  },
  {
    "text": "Your best guess at what\nthe right steps are. And this is all based\naround how trustworthy we think this quadratic\napproximation",
    "start": "3144880",
    "end": "3153010"
  },
  {
    "text": "for objective function is. Yeah, Dan? STUDENT: So for the trust-region\non the graph what Matlab is doing is at\neach R trust-region",
    "start": "3153010",
    "end": "3160901"
  },
  {
    "text": "length it's reevaluating\nwhich way it should go? JAMES SWAN: Yes. Yes. It's computing\nboth sets of steps,",
    "start": "3160901",
    "end": "3167410"
  },
  {
    "text": "and it's deciding which\none it should take, right. It doesn't know. It's trying to\nchoose between them.",
    "start": "3167410",
    "end": "3173737"
  },
  {
    "text": "STUDENT: Why don't you do\nthe Newton-Raphson step through the [? negative R? ?] JAMES SWAN: You can do that\nas well, actually, right.",
    "start": "3173737",
    "end": "3180210"
  },
  {
    "text": "But if you're\ndoing that, now you have to choose\nbetween that strategy and taking a steepest descent\nstep up to R as well, right.",
    "start": "3180210",
    "end": "3189000"
  },
  {
    "text": "And I think one has to decide\nwhich would you prefer. It's possible the Newton-Raphson\nstep also doesn't actually",
    "start": "3189000",
    "end": "3194430"
  },
  {
    "text": "reduce f. In which case, you should\ndiscard it entirely, right. But you could craft a strategy\nthat does that, right.",
    "start": "3194430",
    "end": "3201690"
  },
  {
    "text": "It's still going to\nconverge, likely. OK? OK. I've going to let\nyou guys go, there's another class coming in.",
    "start": "3201690",
    "end": "3207220"
  },
  {
    "text": "Thanks. ",
    "start": "3207220",
    "end": "3209414"
  }
]
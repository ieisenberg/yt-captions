[
  {
    "start": "0",
    "end": "589000"
  },
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6120"
  },
  {
    "text": "continue to offer high-quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6120",
    "end": "12720"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "12720",
    "end": "17910"
  },
  {
    "text": " RAMESH RASKAR: Kind\nof a summary of a lot of the things we talked about.",
    "start": "17910",
    "end": "23050"
  },
  {
    "text": "So if you remember\nin the beginning, he said, you can just\nstart with a pit.",
    "start": "23050",
    "end": "29349"
  },
  {
    "text": "And then it kind of\ndevelops with the lens. But from even here, you can\ngo down two different parts,",
    "start": "29350",
    "end": "34620"
  },
  {
    "text": "either compound eyes, where\neach sensor or set of sensors have their own optics, like a\nsort of straw, or same lens--",
    "start": "34620",
    "end": "45820"
  },
  {
    "text": "sorry, the same pixel, might\nget image from multiple lenses, like here, right? So that's superposition.",
    "start": "45820",
    "end": "52410"
  },
  {
    "text": "So this is a position,\nand this is superposition. And that concept of a\nposition or superposition",
    "start": "52410",
    "end": "60840"
  },
  {
    "text": "applies to all three types,\nshadows- or refraction- or reflection-based techniques.",
    "start": "60840",
    "end": "67680"
  },
  {
    "text": "So we saw this last\ntime, and we'll see how-- we already have some\nprojects that are",
    "start": "67680",
    "end": "73950"
  },
  {
    "text": "inspired by biological vision. You know, Matt is\ntrying the chicken. And I think it's going to be--",
    "start": "73950",
    "end": "81150"
  },
  {
    "text": "[LAUGHTER] It is going to be very popular. And I believe Santiago--\nwhere's Santiago?",
    "start": "81150",
    "end": "88920"
  },
  {
    "text": "Oh, yeah, his triangle-- the piston, kind of--",
    "start": "88920",
    "end": "94350"
  },
  {
    "text": "so some really great ideas. So I'm glad a lot\nof these concepts are coming together\nin the final projects.",
    "start": "94350",
    "end": "100540"
  },
  {
    "text": "So today, we'll talk\nabout coded imaging. And the concept here\nis very simple, OK?",
    "start": "100540",
    "end": "107280"
  },
  {
    "text": "So I'll start with\nthis one, which is you have a taxi\nzipping very fast.",
    "start": "107280",
    "end": "115469"
  },
  {
    "text": "And you want to kind of\ntake a photo in such a way that you can recover the sharp\ndetail afterwards in software.",
    "start": "115470",
    "end": "122939"
  },
  {
    "text": "So it's a form of a\nco-design between how you capture the image and\nhow you process the image.",
    "start": "122940",
    "end": "128399"
  },
  {
    "text": "In a typical film camera, or\neven it is digital camera, you take the picture, and that's\nbasically the end of the story.",
    "start": "128400",
    "end": "136060"
  },
  {
    "text": "And here, you're trying to\ndo something clever about how the picture is taken.",
    "start": "136060",
    "end": "141360"
  },
  {
    "text": "So of course, there\nare other opportunities of capturing this. You can either take a\nreally short exposure photo.",
    "start": "141360",
    "end": "148805"
  },
  {
    "text": "But that's going\nto be very dark. If you take a high ISO, you\ncan recover some information,",
    "start": "148805",
    "end": "153930"
  },
  {
    "text": "but still quite dark. Or you can just take\na long-exposure photo by keeping the shutter open.",
    "start": "153930",
    "end": "159930"
  },
  {
    "text": "But then you will get a blurry\nphoto, which is well exposed, but a lot of the high-frequency\ndetails are lost.",
    "start": "159930",
    "end": "165930"
  },
  {
    "text": "And then if you try to\napply some deblurring, you'll get a result\nthat looks like this,",
    "start": "165930",
    "end": "171609"
  },
  {
    "text": "which is kind of reasonable. You can see the number one on\nthis, I guess, Thomas Train.",
    "start": "171610",
    "end": "177555"
  },
  {
    "text": " But you get a lot\nof banding artifacts",
    "start": "177555",
    "end": "182950"
  },
  {
    "text": "and a lot of repetition\nand noise here. AUDIENCE: So what\nare those lenses? RAMESH RASKAR: This lens?",
    "start": "182950",
    "end": "188242"
  },
  {
    "text": "So when you try to\nrecover this information, you start getting this\nbanding artifacts. And we'll see it in the next\nslide, why that happens.",
    "start": "188242",
    "end": "195640"
  },
  {
    "text": "So what's going on here is that\nif you have a sharp photo--",
    "start": "195640",
    "end": "201750"
  },
  {
    "text": "if you have a blurred photo,\nyou can basically represent that as a sharp photo, where\nthere is a convolution",
    "start": "201750",
    "end": "209490"
  },
  {
    "text": "of the sharp photo with some\nkind of a convolution filter,",
    "start": "209490",
    "end": "214550"
  },
  {
    "text": "OK? So if you look at--\nwhere's my laser point? ",
    "start": "214550",
    "end": "225424"
  },
  {
    "text": "If you look at this-- the tip of letter\none here, it's been",
    "start": "225424",
    "end": "232090"
  },
  {
    "text": "blurred by a certain\namount of pixels in the horizontal direction. And if you keep the shutter\nopen for even longer,",
    "start": "232090",
    "end": "238880"
  },
  {
    "text": "it'll blur\ncorrespondingly longer. So you have basically\na 1D convolution",
    "start": "238880",
    "end": "244540"
  },
  {
    "text": "that's converting this\nimage into this image. And of course, the\ngoal usually is",
    "start": "244540",
    "end": "249610"
  },
  {
    "text": "this is a photo that\nyou capture and you would like to invert\nand get back this photo.",
    "start": "249610",
    "end": "255400"
  },
  {
    "text": "So one would say,\nOK, this converted with this gives me that.",
    "start": "255400",
    "end": "260810"
  },
  {
    "text": "So just [INAUDIBLE]\nusing the same filter and maybe you'll get that back. That doesn't work\nbecause something",
    "start": "260810",
    "end": "267730"
  },
  {
    "text": "called division was 0. And the way to think about\nthat is in the Fourier domain",
    "start": "267730",
    "end": "275020"
  },
  {
    "text": "because convolution in the image\ndomain, our primary domain, is multiplication\nin the Fourier--",
    "start": "275020",
    "end": "282490"
  },
  {
    "text": "just standard Fourier transform. So if you take the\nFourier transform of this",
    "start": "282490",
    "end": "289930"
  },
  {
    "text": "and multiply that by the\nFourier transform of this, you will get the Fourier\ntransform of this, OK?",
    "start": "289930",
    "end": "297820"
  },
  {
    "text": "So let's say we take this photo. Find the Fourier transform here. Multiply that by the\nFourier transform of a box",
    "start": "297820",
    "end": "305230"
  },
  {
    "text": "function, which is a sync. So what that means\nis that I'm going to take the lowest frequency,\nmultiply by that value.",
    "start": "305230",
    "end": "311740"
  },
  {
    "text": "I'm going to take\nthe next frequency, multiply it by this value. Next frequency, multiply by\nthis value, and so on, right?",
    "start": "311740",
    "end": "317145"
  },
  {
    "text": "We're just going\nto multiply each of the frequencies in the image\nby the amplitude of the Fourier",
    "start": "317145",
    "end": "323949"
  },
  {
    "text": "transform of this. And you can already see\nthat lower frequencies will be preserved, but\nhigher frequencies",
    "start": "323950",
    "end": "331000"
  },
  {
    "text": "will be highly attenuated. But there's also something\nstrange happening. Even some of the\nlower frequencies",
    "start": "331000",
    "end": "337840"
  },
  {
    "text": "are actually being set to 0,\nwhich means that in this photo,",
    "start": "337840",
    "end": "343000"
  },
  {
    "text": "these frequencies are\nmissing altogether. They have been suppressed. So it's not a traditional\nlow pass filter.",
    "start": "343000",
    "end": "350110"
  },
  {
    "text": "It's a low pass\nfilter where some of the even lower frequencies\nare also being nullified,",
    "start": "350110",
    "end": "357820"
  },
  {
    "text": "which means that if\nI tried to recover from this photo,\nthis photo, there",
    "start": "357820",
    "end": "363040"
  },
  {
    "text": "is no chance because I\nhave already attenuated and have lost all\nthose frequencies.",
    "start": "363040",
    "end": "370129"
  },
  {
    "text": "So the moment you take the\nphoto, the damage is done. And there's nothing you can do\nto recover those frequencies",
    "start": "370130",
    "end": "376720"
  },
  {
    "text": "because in the\nFourier domain, all you have to do is take the\nFourier transform of this and divide by the\nFourier transform",
    "start": "376720",
    "end": "383440"
  },
  {
    "text": "of this, which is this. And it will give you\nthe [INAUDIBLE],, OK? But the Fourier\ntransform has some zeros,",
    "start": "383440",
    "end": "390850"
  },
  {
    "text": "so you cannot divide those\nfrequencies by 0 and recover an image.",
    "start": "390850",
    "end": "396290"
  },
  {
    "text": "So the culprit here is\nreally this box function, which is equivalent to--\nwhen you release the shutter,",
    "start": "396290",
    "end": "402070"
  },
  {
    "text": "opening the-- release your shutter button-- opening the shutter and keeping\nit open for exposure duration",
    "start": "402070",
    "end": "410409"
  },
  {
    "text": "and closing it. But that's the most\nnatural thing to do. But apparently, it's\nnot the most effective.",
    "start": "410410",
    "end": "417680"
  },
  {
    "text": "So what if you change that? ",
    "start": "417680",
    "end": "423229"
  },
  {
    "text": "What if you changed that? And instead of keeping\nthe shutter open for the entire duration,\nyou open and close it",
    "start": "423230",
    "end": "429770"
  },
  {
    "text": "in a carefully chosen\nbinary sequence. So for some time,\nthe shutter was open,",
    "start": "429770",
    "end": "434889"
  },
  {
    "text": "then shutter's closed. It's open for some time. Again, it's closed. Here, it's closed for quite some\ntime, open for a short time.",
    "start": "434890",
    "end": "440370"
  },
  {
    "text": "And so on. So at the end, you still\nget just one photo. But now something magical has\nhappened because first of all,",
    "start": "440370",
    "end": "448950"
  },
  {
    "text": "if you look at this\nnumber one, you'll see that it's not\nthe same as before. It has-- it seems to\nhave these replicas.",
    "start": "448950",
    "end": "455885"
  },
  {
    "text": " And the reason\nwhy this is better",
    "start": "455885",
    "end": "462050"
  },
  {
    "text": "is you take the Fourier\ntransform of this. It's actually flat, which\nmeans it's preserving all",
    "start": "462050",
    "end": "467750"
  },
  {
    "text": "the frequencies in the image. So we can be sure\nthat, in this photo,",
    "start": "467750",
    "end": "473240"
  },
  {
    "text": "all the spatial frequencies--\nlow frequencies, high frequencies-- they're all preserved.",
    "start": "473240",
    "end": "478379"
  },
  {
    "text": "Of course, they're attenuated. It's not as high as-- it's not 1.0. It's reduced.",
    "start": "478380",
    "end": "483530"
  },
  {
    "text": "Maybe it's 0.1 or so. So they're all attenuated,\nbut there is still some hope to recover\nthis photo back",
    "start": "483530",
    "end": "489800"
  },
  {
    "text": "from this because,\nin the denominator, we will not have seen. ",
    "start": "489800",
    "end": "495770"
  },
  {
    "text": "So of course, if you try to\nimplement this mechanically, where you open the shutter\nand then mechanically",
    "start": "495770",
    "end": "502250"
  },
  {
    "text": "try to close the shutter,\nthat will be problematic. So what we did was we\nused an LCD-- actually,",
    "start": "502250",
    "end": "508070"
  },
  {
    "text": "a ferroelectric LCD-- that becomes opaque\nand transparent. And in the old\nvirtual-reality screens",
    "start": "508070",
    "end": "515299"
  },
  {
    "text": "or even some of the games,\nyou have these eyeglasses that flicker at 60 Hertz\nfor time sequentially",
    "start": "515299",
    "end": "525860"
  },
  {
    "text": "so that you can see\nthe left eye versus, like-- because they're\nthe same glasses. And a traditional\nLCD, unfortunately,",
    "start": "525860",
    "end": "533690"
  },
  {
    "text": "doesn't have a\nvery high contrast. And Simon is discovering\nthat one more time.",
    "start": "533690",
    "end": "539660"
  },
  {
    "text": "But the ferroelectric LCDs\nhave a contrast of 1,000 to 1.",
    "start": "539660",
    "end": "544730"
  },
  {
    "text": "So when it's opaque, the amount\nof light that passes through, as compared to when\nit's transparent",
    "start": "544730",
    "end": "551650"
  },
  {
    "text": "and the amount of light\nit passes through, the ratio is 1 of 2,000. So when you turn this\nferroelectric LCD off,",
    "start": "551650",
    "end": "560300"
  },
  {
    "text": "it's really, really opaque. Yeah. AUDIENCE: Couldn't you\njust do a high-speed video",
    "start": "560300",
    "end": "566090"
  },
  {
    "text": "or just a [INAUDIBLE] taking\nvideo and put out your frames? RAMESH RASKAR: So\nthe question was, why not just capture\nhigh-speed video",
    "start": "566090",
    "end": "572550"
  },
  {
    "text": "and take all these\nframes, right, and then",
    "start": "572550",
    "end": "577570"
  },
  {
    "text": "put them together? The problem is each of the\nframe will be extremely dark. So you are basically\nadding up a lot of noise.",
    "start": "577570",
    "end": "584380"
  },
  {
    "text": "Every frame is\ndominated by noise. AUDIENCE: Yeah, yeah. ",
    "start": "584380",
    "end": "590040"
  },
  {
    "start": "589000",
    "end": "1100000"
  },
  {
    "text": "RAMESH RASKAR: So when the\nshutter is transparent, that goes through.",
    "start": "590040",
    "end": "595840"
  },
  {
    "text": "When the shutter is opaque,\nlight doesn't go through. And that's your 1010 inquiry.",
    "start": "595840",
    "end": "604180"
  },
  {
    "text": "So, again, the idea\nis very simple. Instead of keeping the shutter\nopen for the entire duration",
    "start": "604180",
    "end": "610690"
  },
  {
    "text": "and getting a\nwell-exposed photo, the shutter is open for\nonly half of the time.",
    "start": "610690",
    "end": "617545"
  },
  {
    "text": "AUDIENCE: There is\nan issues there. The support for the\nrepresentation of the Fourier",
    "start": "617545",
    "end": "622850"
  },
  {
    "text": "domain of that function\nthat you describe there is infinite, right? So you actually truncate\nthis in order to--",
    "start": "622850",
    "end": "629157"
  },
  {
    "text": "RAMESH RASKAR: It's not\ninfinite because you still have some width. AUDIENCE: Right, but you have\ninfinite high frequencies there",
    "start": "629157",
    "end": "637930"
  },
  {
    "text": "by the sharp conditions, right? RAMESH RASKAR: Yeah,\nyou can think-- I mean, you can think of\nthis one goes to infinity.",
    "start": "637930",
    "end": "643610"
  },
  {
    "text": "But there's hardly\nany energy left. So although it goes to infinity,\nthere is not much energy left.",
    "start": "643610",
    "end": "649480"
  },
  {
    "text": "AUDIENCE: But when you get\nto invert the process then, that's why you're still not\ngetting the perfect images to--",
    "start": "649480",
    "end": "655615"
  },
  {
    "text": "RAMESH RASKAR: In this case. AUDIENCE: --in\nthis case as well. You still lost some\nhigh frequency, right? RAMESH RASKAR: So you haven't\nseen the results yet for this.",
    "start": "655615",
    "end": "662930"
  },
  {
    "text": "AUDIENCE: You show the text. RAMESH RASKAR: Yes. So this is what it\nlooks in this case.",
    "start": "662930",
    "end": "667990"
  },
  {
    "text": "But it's a very controlled\nexperiment in a laboratory. So you take the\ntoy, and you move it",
    "start": "667990",
    "end": "673000"
  },
  {
    "text": "in a very controlled way. And this is what you get\nin a traditional camera. And this is what you get\nin the flutter shutter.",
    "start": "673000",
    "end": "679630"
  },
  {
    "text": "So these are real photos. And, yeah, you're right. I mean, you still\nget some noise. And actually, if you can\npair this with ground truth,",
    "start": "679630",
    "end": "687850"
  },
  {
    "text": "you'll see that it's OK,\nbut it's not perfect. AUDIENCE: Yeah, so let's\nsay that you took the 0s",
    "start": "687850",
    "end": "694060"
  },
  {
    "text": "from the [INAUDIBLE], right? And you just replaced\nit by something that is pretty close\nto 0, but not 0.",
    "start": "694060",
    "end": "701200"
  },
  {
    "text": "And if you invert the process-- RAMESH RASKAR: From here,\nthis is what you get.",
    "start": "701200",
    "end": "706360"
  },
  {
    "text": "AUDIENCE: That's-- OK-- RAMESH RASKAR: There's\na deep learning of this. AUDIENCE: OK. RAMESH RASKAR: Yeah, and that's\nthis loss of these frequencies",
    "start": "706360",
    "end": "713440"
  },
  {
    "text": "also shows up as these artifacts\nat regular frequencies,",
    "start": "713440",
    "end": "718860"
  },
  {
    "text": "at regular intervals. ",
    "start": "718860",
    "end": "723943"
  },
  {
    "text": "So, again, this\none-- this doesn't go to infinity all the way. [INAUDIBLE] It cuts off and\ncorresponding to the width.",
    "start": "723943",
    "end": "731569"
  },
  {
    "text": "The width of this\npost was very short than yesterday\nwere very far away.",
    "start": "731570",
    "end": "738050"
  },
  {
    "text": "OK? Yeah? AUDIENCE: The filter is\ndependent from distance? RAMESH RASKAR: The filters\ndepend on multiple factors.",
    "start": "738050",
    "end": "743660"
  },
  {
    "text": "So if your toy is moving or\nyour taxi's moving really slow, then there is no need\nto-- in this case,",
    "start": "743660",
    "end": "750180"
  },
  {
    "text": "the sequence was about 51-- actually, 52 vector long.",
    "start": "750180",
    "end": "757850"
  },
  {
    "text": "So let's say your exposure\ntime is about 104 milliseconds.",
    "start": "757850",
    "end": "762920"
  },
  {
    "text": "It's open for two milliseconds. Here, it's open for\nfour milliseconds, off for two milliseconds,\nfour milliseconds, two.",
    "start": "762920",
    "end": "769850"
  },
  {
    "text": "Maybe it's off for eight\nmilliseconds, two, and so on. AUDIENCE: Yes, but-- RAMESH RASKAR: But with\na vector length of 52.",
    "start": "769850",
    "end": "778050"
  },
  {
    "text": "AUDIENCE: This\nfilter is in time? RAMESH RASKAR: In time. AUDIENCE: And you think\nabout filter from space?",
    "start": "778050",
    "end": "783080"
  },
  {
    "text": "RAMESH RASKAR: It\ncorresponds automatically to filter in space. AUDIENCE: Yeah, so [INAUDIBLE]\nit's dependent on distance, if you-- RAMESH RASKAR: Yeah,\nthe speed, you mean.",
    "start": "783080",
    "end": "788870"
  },
  {
    "text": "AUDIENCE: --of faraway objects. RAMESH RASKAR: Yes. So your actual blur in the image\nmay not be exactly 52 pixels.",
    "start": "788870",
    "end": "796460"
  },
  {
    "text": "It might be 10 pixels. It could be 100 pixels. So your 52 vector\nis going to stretch or shrink based on how\nfast the object is moving.",
    "start": "796460",
    "end": "804259"
  },
  {
    "text": "And you're saying\nthat it also depends on how far the\nobject is in space because faster-moving objects.",
    "start": "804260",
    "end": "810200"
  },
  {
    "text": "And you mostly have to think\nabout image space motion because the speed in the real\nworld and-- the distance are",
    "start": "810200",
    "end": "818269"
  },
  {
    "text": "they get-- you divide to normalize\nby the distance. So you only have to worry\nabout the image space distance.",
    "start": "818270",
    "end": "825529"
  },
  {
    "text": "Yeah. Go ahead. AUDIENCE: Could you get a\nsimilar effect if you had,",
    "start": "825530",
    "end": "831830"
  },
  {
    "text": "like, instead of a hooded\nshutter, it could have flasher?",
    "start": "831830",
    "end": "836840"
  },
  {
    "text": "RAMESH RASKAR: Yeah, exactly. So if you're in a dark\nroom, you can just--",
    "start": "836840",
    "end": "844129"
  },
  {
    "text": "if you're in a\ndark room, then you can just strobe the light,\nrather than opening and closing the shutter.",
    "start": "844130",
    "end": "850720"
  },
  {
    "text": "AUDIENCE: I think we might have\na mobile demo of that scene. RAMESH RASKAR: [LAUGHS] Well,\nI don't know how fast you can--",
    "start": "850720",
    "end": "856370"
  },
  {
    "text": "AUDIENCE: Well, the problem\nis you can't [INAUDIBLE].. RAMESH RASKAR: Yeah. So what are some-- let's look\nat some pictures, actually.",
    "start": "856370",
    "end": "865750"
  },
  {
    "text": "So here is a demo. I think I've shown\nit to you before.",
    "start": "865750",
    "end": "871410"
  },
  {
    "text": "This is on Broadway. This women try to figure out the\ncar make and the license plate",
    "start": "871410",
    "end": "877040"
  },
  {
    "text": "number. What's the license plate number? AUDIENCE: 458. [INTERPOSING VOICES]",
    "start": "877040",
    "end": "882810"
  },
  {
    "text": "AUDIENCE: 468. AUDIENCE: Something. RAMESH RASKAR: And the company?",
    "start": "882810",
    "end": "888530"
  },
  {
    "text": "AUDIENCE: [? One more time. ?] RAMESH RASKAR: Yeah.",
    "start": "888530",
    "end": "893640"
  },
  {
    "text": "So you get a reasonable\nresult. But going back, what are the limitations\nof this method?",
    "start": "893640",
    "end": "899700"
  },
  {
    "text": " Yes. AUDIENCE: You need\nto know the motion",
    "start": "899700",
    "end": "906060"
  },
  {
    "text": "or the direction of the motion. RAMESH RASKAR: No, you need to\nknow the point spread function, how the blur is created.",
    "start": "906060",
    "end": "912060"
  },
  {
    "text": "If the car is moving from left\nto right versus right to left, you need to know that because\nthe way your point spread",
    "start": "912060",
    "end": "918500"
  },
  {
    "text": "function will be imposed on\nthe scene will be different. AUDIENCE: You still\ninspect the lighting.",
    "start": "918500",
    "end": "924165"
  },
  {
    "text": "RAMESH RASKAR: You just have the\nlight-- very important, right? So this image is about\nhalf as bright as this one.",
    "start": "924165",
    "end": "931079"
  },
  {
    "text": "What else? AUDIENCE: I guess there\nshould be a little less",
    "start": "931080",
    "end": "936230"
  },
  {
    "text": "of an acceleration of-- all of them should\nbe moving the same-- RAMESH RASKAR: Exactly. So whatever is moving has\nto move at a constant speed.",
    "start": "936230",
    "end": "944840"
  },
  {
    "text": "If we did 100 milliseconds,\nit picks up speed, then your assumption\nthat the 52-length vector",
    "start": "944840",
    "end": "950570"
  },
  {
    "text": "will map to some stretched\nor shrunk version of 52 is not valid.",
    "start": "950570",
    "end": "955640"
  },
  {
    "text": "Some parts will go\nfaster and slower. What else? AUDIENCE: [INAUDIBLE] RAMESH RASKAR: Sorry?",
    "start": "955640",
    "end": "961010"
  },
  {
    "text": "AUDIENCE: If the\nobject is moving in space, [INAUDIBLE]\ndistance and then [INAUDIBLE]..",
    "start": "961010",
    "end": "966842"
  },
  {
    "text": "RAMESH RASKAR: Yeah,\nso you-- so if it's moving in a perspective,\nfor example, it's not so bad because\nyou can rotate the image.",
    "start": "966843",
    "end": "973350"
  },
  {
    "text": "And again, it'll become-- so that's not acceleration. That's still constant speed. It's acceleration\nin the measurement,",
    "start": "973350",
    "end": "979610"
  },
  {
    "text": "but in the real world,\nit's still constant speed. So you can play\nwith those tricks. You can either go\nto object space",
    "start": "979610",
    "end": "985610"
  },
  {
    "text": "or you can come\nback to image space to make sure there\nis no acceleration. It's all linear.",
    "start": "985610",
    "end": "991557"
  },
  {
    "text": "AUDIENCE: So does\nthis technique still work if you're moving\nin multiple directions at once over the duration?",
    "start": "991557",
    "end": "997110"
  },
  {
    "text": "RAMESH RASKAR: So if you have\nmultiple cars, for example, and they're all\nindependent, then it's fine because I can say\nthis car is going this way.",
    "start": "997110",
    "end": "1004089"
  },
  {
    "text": "That car is going this way. As long as it's moving\nin a straight line at a constant speed, you're OK.",
    "start": "1004090",
    "end": "1009380"
  },
  {
    "text": "But if the two cars\noverlap, what happens? Our model fails again.",
    "start": "1009380",
    "end": "1016625"
  },
  {
    "text": "If two cars are\npartially overlapping during the exposure,\nit's possible,",
    "start": "1016625",
    "end": "1022690"
  },
  {
    "text": "but it's more\nchallenging because you don't know exactly how fast\nthe two cars are moving.",
    "start": "1022690",
    "end": "1028760"
  },
  {
    "text": "Yeah. AUDIENCE: Sorry,\nmight we need to know how fast the car is moving when\nyou're setting up your shutter?",
    "start": "1028760",
    "end": "1035240"
  },
  {
    "text": "RAMESH RASKAR: No, when you're-- OK, so when you're\nsetting up your shutter, if the car is\nmoving really slow,",
    "start": "1035240",
    "end": "1040750"
  },
  {
    "text": "and you don't expect it\nto blur by 52 pixels, and you expect it to\nblur by only 10 pixels,",
    "start": "1040750",
    "end": "1046329"
  },
  {
    "text": "then using a 52\nsequence is overkill. Maybe you should use a new\nsequence that's only about 10",
    "start": "1046329",
    "end": "1052490"
  },
  {
    "text": "long or 11 long, right? So it's just like-- AUDIENCE: OK, but that's just\nso you can get more light. RAMESH RASKAR: No, that's so\nthat it's most optimal for that",
    "start": "1052490",
    "end": "1059560"
  },
  {
    "text": "setting, right? So it's like setting\nan exposure time. When I take a\npicture, the camera automatically decides what\nthe exposure time should be.",
    "start": "1059560",
    "end": "1067385"
  },
  {
    "text": "Similarly, you should\nlook at the speed of how things are moving\nmaybe with an ultrasound Doppler or whatever.",
    "start": "1067385",
    "end": "1073730"
  },
  {
    "text": "And it says, things\nare not moving at all. So I should not use the\nflutter shutter at all. Until they're\nmoving very slowly,",
    "start": "1073730",
    "end": "1079020"
  },
  {
    "text": "maybe I should use\na 10 long sequence. If things are moving\na lot, maybe I should use a 52 sequence.",
    "start": "1079020",
    "end": "1084580"
  },
  {
    "text": "And to answer your other\nquestion, where you need to do is when we solve\nthe system, we need",
    "start": "1084580",
    "end": "1089980"
  },
  {
    "text": "to know how long the blur is,\nwhich is true in other cases as well.",
    "start": "1089980",
    "end": "1095050"
  },
  {
    "text": "You need to know how\nmuch the blur is. ",
    "start": "1095050",
    "end": "1100889"
  },
  {
    "start": "1100000",
    "end": "1391000"
  },
  {
    "text": "Another major\ndisadvantage is let's say I want to take this bottle.",
    "start": "1100890",
    "end": "1106510"
  },
  {
    "text": "And if I just rotate it\nand motion blur that, it will not work. For any point in the front\nthat you're looking at it,",
    "start": "1106510",
    "end": "1112950"
  },
  {
    "text": "it'll work. But the point that\nwas in the back, that all of the 52 sequence--\nmaybe for the first 10,",
    "start": "1112950",
    "end": "1119100"
  },
  {
    "text": "it was occluded. And the remaining\n42, it was seen. You have to know exactly when\nthat point became visible",
    "start": "1119100",
    "end": "1128460"
  },
  {
    "text": "during that 52 window. So in general, the\ntechnique works well when",
    "start": "1128460",
    "end": "1133680"
  },
  {
    "text": "things are moving naturally. But if somebody wants to do\nthis kind of an experiment,",
    "start": "1133680",
    "end": "1141120"
  },
  {
    "text": "or move things behind an\noccluder and move out, those are very\nchallenging scenarios.",
    "start": "1141120",
    "end": "1146895"
  },
  {
    "text": "AUDIENCE: Can you\ncombine both horizontal and vertical [INAUDIBLE] masks? RAMESH RASKAR: Vertical,\nhorizontal is fine.",
    "start": "1146895",
    "end": "1153430"
  },
  {
    "text": "You can-- it doesn't matter. It could be moving vertically. Basically, your point\nspread function--",
    "start": "1153430",
    "end": "1158730"
  },
  {
    "text": "the blur function will\nbe vertical rather than horizontal. AUDIENCE: Yeah, no, but if\nyou have a combined motion,",
    "start": "1158730",
    "end": "1164585"
  },
  {
    "text": "vertical and\nhorizontal, you have to encode this with a mask? RAMESH RASKAR: No, no, no. So let's say the two cars-- one is moving--",
    "start": "1164585",
    "end": "1169770"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] diagonally\nfrom their [? English ?] way, right? RAMESH RASKAR: That's fine. As long as it's in any\none direction, it's OK.",
    "start": "1169770",
    "end": "1175440"
  },
  {
    "text": "So let me draw it. AUDIENCE: But if\nyou take a sharp turn, you pass through, or-- RAMESH RASKAR: Yeah, exactly.",
    "start": "1175440",
    "end": "1181268"
  },
  {
    "text": "So you have to assume\nthat the point-- so the basic assumption\nis that if you take any point in the scene,\nit's moving in a straight line,",
    "start": "1181268",
    "end": "1190480"
  },
  {
    "text": "let's say. And if you have an object,\nand every point of that object moves in a\nstraight line, OK.",
    "start": "1190480",
    "end": "1195720"
  },
  {
    "text": "It doesn't matter which\ndirection and what speed. AUDIENCE: So this\ndoesn't help at all with any image stabilization if\nsomebody's holding the camera.",
    "start": "1195720",
    "end": "1201903"
  },
  {
    "text": "RAMESH RASKAR: It helps as well. So if you have-- let's say you have\na camera shape. And I take a picture\nof an LED, and it",
    "start": "1201903",
    "end": "1209490"
  },
  {
    "text": "creates some curve like that\nbecause that kind of shape. If I know that curve,\nmaybe I can put a gyro.",
    "start": "1209490",
    "end": "1215970"
  },
  {
    "text": "Then I can, again,\nfigure that out. So the problem here\nreally is the point",
    "start": "1215970",
    "end": "1222600"
  },
  {
    "text": "spread function or the blurred\nfunction is very critical. And this is what we want to\nstudy about half of the class.",
    "start": "1222600",
    "end": "1232020"
  },
  {
    "text": "And the concept is very,\nvery, very interesting because light is linear.",
    "start": "1232020",
    "end": "1237360"
  },
  {
    "text": "So eventually, it's very linear. What happens to a point happens\nto the rest of the object.",
    "start": "1237360",
    "end": "1243370"
  },
  {
    "text": "So if I have a\ncar that's moving, and I tell you how exactly\none point of the car",
    "start": "1243370",
    "end": "1249000"
  },
  {
    "text": "is behaving in the image, I\ncan tell you automatically how the rest of the car\nis behaving in the image",
    "start": "1249000",
    "end": "1255660"
  },
  {
    "text": "because it's going\nto do-- all of it is going to have the\nsame spread image.",
    "start": "1255660",
    "end": "1262590"
  },
  {
    "text": "So you can either-- for experiments, you can\njust put an LED on the car",
    "start": "1262590",
    "end": "1268380"
  },
  {
    "text": "and see how that LED moves. And that tells you everything.",
    "start": "1268380",
    "end": "1273550"
  },
  {
    "text": "And I'm sure you use this\ntrick in other scenarios where you look at a\nvery small impulse",
    "start": "1273550",
    "end": "1283083"
  },
  {
    "text": "and see how the response is. There's also an\nimpulse response. For those of you\nin audio, you might want to check and see\nhow the room [INAUDIBLE]..",
    "start": "1283083",
    "end": "1292020"
  },
  {
    "text": " And when you're trying to find\na speed of a car, [INAUDIBLE],,",
    "start": "1292020",
    "end": "1303020"
  },
  {
    "text": "a very small impulse. And it answers and comes back. It does. The point spread function\nfor your time of flight.",
    "start": "1303020",
    "end": "1315657"
  },
  {
    "text": "So that's the same concept here. You just want to call leading\nthe world, take a picture, and see how it works.",
    "start": "1315657",
    "end": "1321909"
  },
  {
    "text": "And this whole field\nof order dimension is basically engineering of\nthe point spread function.",
    "start": "1321910",
    "end": "1330920"
  },
  {
    "text": "So if you take an ordinary\ncamera, a film camera, and take a picture,\nyou have no control",
    "start": "1330920",
    "end": "1337370"
  },
  {
    "text": "over how light is spreading--\nif something is moving or a focus has different\ncolor spectrum.",
    "start": "1337370",
    "end": "1345170"
  },
  {
    "text": "And so an order\ndimension basically means you want to\ncontrol how something",
    "start": "1345170",
    "end": "1352280"
  },
  {
    "text": "is spreading on the image. So we're going to engineer\nactivity of the camera.",
    "start": "1352280",
    "end": "1358170"
  },
  {
    "text": "So in this particular case,\na point that was moving",
    "start": "1358170",
    "end": "1363290"
  },
  {
    "text": "created a blur like this. And by engineering the\ntime point spread function,",
    "start": "1363290",
    "end": "1369815"
  },
  {
    "text": "it stops looking\na bit like that. It's going to look\nlike that, all right?",
    "start": "1369815",
    "end": "1375300"
  },
  {
    "text": "It's going to look like\nfashion [? wise. ?] And then it just turns out\nthat this one is easier",
    "start": "1375300",
    "end": "1380990"
  },
  {
    "text": "to deal with than this one. So that's the basic\nconcept, engineering",
    "start": "1380990",
    "end": "1387030"
  },
  {
    "text": "or actively changing the\npoint spread function. ",
    "start": "1387030",
    "end": "1392830"
  },
  {
    "start": "1391000",
    "end": "1533000"
  },
  {
    "text": "So this is very counterintuitive\nbecause you would say, let me just build the best lens\nand the best exposure time.",
    "start": "1392830",
    "end": "1402140"
  },
  {
    "text": "And so that kind of\nmimics the human eye. And once I have that, I have\nthe best possible picture.",
    "start": "1402140",
    "end": "1407780"
  },
  {
    "text": "But when it comes to actually\nextracting information from that scene,\nit turns out you",
    "start": "1407780",
    "end": "1414730"
  },
  {
    "text": "need to strategically\nmodify how the camera works",
    "start": "1414730",
    "end": "1420460"
  },
  {
    "text": "so that all the information\nis somehow preserved. Now the problem is, even\nafter you are very careful",
    "start": "1420460",
    "end": "1426730"
  },
  {
    "text": "and you have\ncaptured that image, it's still going to\nbe somewhat garbled.",
    "start": "1426730",
    "end": "1433240"
  },
  {
    "text": "It's going to be mixed in. But that's where the\nco-design comes in. ",
    "start": "1433240",
    "end": "1441670"
  },
  {
    "text": "So once you have this\nimage, there is some hope, there is some\ncomputational technique,",
    "start": "1441670",
    "end": "1446710"
  },
  {
    "text": "that will allow you to\ngo from here to here. And this is what kind\nof separates an animal",
    "start": "1446710",
    "end": "1453280"
  },
  {
    "text": "eye from a computational eye\nbecause in most scenarios, an animal eye is just\ngoing to take the picture",
    "start": "1453280",
    "end": "1460120"
  },
  {
    "text": "and try to make the\nbest sense out of it. But a computational eye is going\nto apply a lot of processing",
    "start": "1460120",
    "end": "1467140"
  },
  {
    "text": "to this and be able\nto recover that. As far as I know, animals don't\nhave deconvolution circuitry",
    "start": "1467140",
    "end": "1473649"
  },
  {
    "text": "or deep-learning circuitry. I can look at a blurry image\nand kind of figure out. I mean, this was a\nchallenge for you, right?",
    "start": "1473650",
    "end": "1480400"
  },
  {
    "text": " Right.",
    "start": "1480400",
    "end": "1485600"
  },
  {
    "text": "So we have pretty\nsophisticated eyes, but we're still not able\nto deep learn what this is.",
    "start": "1485600",
    "end": "1490700"
  },
  {
    "text": "If you have some prior\nknowledge of how the Volkswagen logo looks like, maybe you can\nsay, OK, maybe that was this.",
    "start": "1490700",
    "end": "1497790"
  },
  {
    "text": "But on the other hand,\nif I give you this, you're immediately\nwilling to believe that this photo is a blurred\nversion of this photo.",
    "start": "1497790",
    "end": "1504799"
  },
  {
    "text": " And so kind of\nthinking about that is when you go from here to\nhere, information is lost.",
    "start": "1504800",
    "end": "1514390"
  },
  {
    "text": "When you go from\nhere to here, we're trying to recover\nsome information. So going from a sharp photo to\na blurred photo is easy for us",
    "start": "1514390",
    "end": "1522130"
  },
  {
    "text": "because we just have to\nlose some information or to imagine what it would look\nlike if some of the information",
    "start": "1522130",
    "end": "1527649"
  },
  {
    "text": "is removed from this image. ",
    "start": "1527650",
    "end": "1534450"
  },
  {
    "start": "1533000",
    "end": "1560000"
  },
  {
    "text": "So the goal of coded\nimaging is to come up with clever mechanisms so\nthat we can capture light",
    "start": "1534450",
    "end": "1541550"
  },
  {
    "text": "but not just by converting\nphotons into electrons, but actually modulating\nthose photons,",
    "start": "1541550",
    "end": "1546559"
  },
  {
    "text": "either blocking them\nor attenuating them or bending them, and so on. So that that's why a\ncomputational camera is",
    "start": "1546560",
    "end": "1553550"
  },
  {
    "text": "doing the computation not just\nin Silicon but also in optics. ",
    "start": "1553550",
    "end": "1560730"
  },
  {
    "start": "1560000",
    "end": "1583000"
  },
  {
    "text": "OK, so that was what we can\ndo to preserve information",
    "start": "1560730",
    "end": "1567960"
  },
  {
    "text": "in case of motion blur, right? And the circuit is\nvery, very simple. You just take the hot shoe of\nthe flash, and it triggers.",
    "start": "1567960",
    "end": "1576990"
  },
  {
    "text": "When you lose the shutter,\nit triggers the circuit. And then you just cycle through\nthe code that you care about.",
    "start": "1576990",
    "end": "1583590"
  },
  {
    "start": "1583000",
    "end": "1596000"
  },
  {
    "text": "What can we do for defocus\nblur that is for motion blur?",
    "start": "1583590",
    "end": "1588870"
  },
  {
    "text": "What can you do\nfor defocus blur? We, again, want to engineer\nthe point spread function.",
    "start": "1588870",
    "end": "1595328"
  },
  {
    "text": "AUDIENCE: Spatial coding. RAMESH RASKAR: Spatial coding. How would you apply\nspatial coding? AUDIENCE: Coded aperture?",
    "start": "1595328",
    "end": "1600660"
  },
  {
    "start": "1596000",
    "end": "1606000"
  },
  {
    "text": "RAMESH RASKAR: Coded aperture. So this is coded exposure,\ncoded aperture-- very easy. ",
    "start": "1600660",
    "end": "1606520"
  },
  {
    "start": "1606000",
    "end": "1624000"
  },
  {
    "text": "And all you're going to do\nis put some kind of a code in the aperture of the lens. And this is how,\nactually, it started",
    "start": "1606520",
    "end": "1613544"
  },
  {
    "text": "in the days of-- in\nscientific imaging, especially in astronomy, coded\napertures are very well known.",
    "start": "1613545",
    "end": "1619620"
  },
  {
    "text": "And those of you attended\nProfessor Han's lecture on Wednesday, that's what he\ntalked about, coded apertures.",
    "start": "1619620",
    "end": "1628120"
  },
  {
    "start": "1624000",
    "end": "1654000"
  },
  {
    "text": "So I've been following\nthis for a long, long time. And I thought, it must be useful\nfor something in photography.",
    "start": "1628120",
    "end": "1635429"
  },
  {
    "text": "And so I said, OK, let's\ntry to put a coded aperture in the camera and see if we\ncan deal with focus and so on.",
    "start": "1635430",
    "end": "1645549"
  },
  {
    "text": "And that was back in 2004. And we tried it for six months,\nand it just didn't work.",
    "start": "1645550",
    "end": "1651150"
  },
  {
    "text": "It was really frustrating--\nreally, really frustrating. And then one fine\nday, I said, OK,",
    "start": "1651150",
    "end": "1657630"
  },
  {
    "text": "if you can do this in space,\nI'm sure we can do this in time as well. And so we did this, and\nthis worked right away,",
    "start": "1657630",
    "end": "1664890"
  },
  {
    "text": "within a couple of weeks. So we went ahead and\nbuilt this whole system. And that was just a graph paper.",
    "start": "1664890",
    "end": "1671070"
  },
  {
    "text": "And then we said, OK, let's\ncome back and think about this. What's going on? Why don't we get good results?",
    "start": "1671070",
    "end": "1677320"
  },
  {
    "text": "So it took almost\ntwo years to realize that to put this coded\naperture in a camera,",
    "start": "1677320",
    "end": "1685350"
  },
  {
    "text": "there are only a\nfew places where you can put it to get good results. So out of that came this\nparticular experiment.",
    "start": "1685350",
    "end": "1693700"
  },
  {
    "text": "So I have a colleague,\nJim Kobler, at MG Edge. And one day, he showed me--\nthis is his lens, by the way.",
    "start": "1693700",
    "end": "1701970"
  },
  {
    "text": "He was telling me the story that\nhe was fishing with his camera,",
    "start": "1701970",
    "end": "1708000"
  },
  {
    "text": "and some creature\ncame out of the water, some kind of an alligator.",
    "start": "1708000",
    "end": "1713220"
  },
  {
    "text": "And he lost his balance, and\nthe boat flipped upside down.",
    "start": "1713220",
    "end": "1718620"
  },
  {
    "text": "Somehow, he managed\nto flip back in. And the alligator went away. But it completely damaged\nhis camera that was with him,",
    "start": "1718620",
    "end": "1726300"
  },
  {
    "text": "and it just wouldn't work. So he just took out his lens,\nwhich is a standard Canon lens.",
    "start": "1726300",
    "end": "1732210"
  },
  {
    "text": "And he said, let's\nopen it all the way. So he ripped open\nall the damage.",
    "start": "1732210",
    "end": "1738000"
  },
  {
    "text": "It had all the mud\nin it and so on. And then he just showed\nme this thing as is.",
    "start": "1738000",
    "end": "1745350"
  },
  {
    "start": "1741000",
    "end": "1866000"
  },
  {
    "text": "And it was very fascinating\nbecause this is a standard film lens, which, of course, can also\nbe used with a digital camera.",
    "start": "1745350",
    "end": "1753390"
  },
  {
    "text": "And this is a fixed\nfocal length lens. It's 100-millimeter\nfocal length lens.",
    "start": "1753390",
    "end": "1760120"
  },
  {
    "text": "And when you focus with this, it\nworks in very interesting ways. First of all, it doesn't\nhave a single lens element.",
    "start": "1760120",
    "end": "1766380"
  },
  {
    "text": "It has multiple lens elements. So when you change\nthe focus, it has to do some really\ninteresting things.",
    "start": "1766380",
    "end": "1772799"
  },
  {
    "text": "It has to deal with\nchromatic aberration, geometric aberrations, such as\nradial distortion, and so on.",
    "start": "1772800",
    "end": "1781300"
  },
  {
    "text": "So it has to move\nall these lenses with corresponding ratios, OK?",
    "start": "1781300",
    "end": "1786809"
  },
  {
    "text": "So I'll pass this\naround, and you'll see that there are these\nnotches on this lens that",
    "start": "1786810",
    "end": "1793230"
  },
  {
    "text": "are in a parabolic fashion. So when I wrote this,\nthe internal lens--",
    "start": "1793230",
    "end": "1799242"
  },
  {
    "text": "the outermost lens and the\ninnermost lens instruments are the same place. But all the inner lenses move\nwith some particular ratio.",
    "start": "1799242",
    "end": "1806550"
  },
  {
    "text": "It's amazing the way\nit's structured, right? So the multiple lenses are\nmoving every time I move this.",
    "start": "1806550",
    "end": "1813419"
  },
  {
    "text": "And they're moving\nbecause they're guided through these groups. But there's one\nparticular location",
    "start": "1813420",
    "end": "1819809"
  },
  {
    "text": "that does not change in this\nlens, and that's the aperture.",
    "start": "1819810",
    "end": "1824900"
  },
  {
    "text": "So we said, let's\nlook at this aperture. And back then, it was still\na reasonable-looking lens.",
    "start": "1824900",
    "end": "1831649"
  },
  {
    "text": "So we went in our lab, and\nwe cut open all the way. And you can start putting\nnew apertures in this plane.",
    "start": "1831650",
    "end": "1840330"
  },
  {
    "text": "So you can cut open\nthat particular guy",
    "start": "1840330",
    "end": "1846529"
  },
  {
    "text": "and start putting this aperture. Now it turns out the center\nof production of this lens",
    "start": "1846530",
    "end": "1853429"
  },
  {
    "text": "is very carefully\ndesigned by camera makers to be the same plane where\nyou put your aperture.",
    "start": "1853430",
    "end": "1859910"
  },
  {
    "text": "So when you change your\nf-stop and decrease it and increase it,\nit's all happening in the center of projection.",
    "start": "1859910",
    "end": "1867170"
  },
  {
    "start": "1866000",
    "end": "2392000"
  },
  {
    "text": "Everybody knows\ncentral projection? So when you think\nabout a visual camera,",
    "start": "1867170",
    "end": "1873380"
  },
  {
    "text": "you make this very\nsimplistic assumption. That is a pinhole,\nand there's a sensor.",
    "start": "1873380",
    "end": "1878420"
  },
  {
    "text": "And when you put\na lens, we assume that the center of the lens\nis the central projection, that this always can be\nassumed to go to that point.",
    "start": "1878420",
    "end": "1888320"
  },
  {
    "text": "When you have a bunch of\nlenses, like way over here,",
    "start": "1888320",
    "end": "1895092"
  },
  {
    "text": "where is the center\nof protectionism? Is it here or here\nor here or here? And of course,\nthere is-- you can",
    "start": "1895093",
    "end": "1901840"
  },
  {
    "text": "take a collection\nof these lenses and create one single center of\nprojection for normal cameras.",
    "start": "1901840",
    "end": "1909280"
  },
  {
    "text": "For professional\nlenses, that's not true. But for normal cameras, you\nhave the central projection.",
    "start": "1909280",
    "end": "1915039"
  },
  {
    "text": "But again, conceptually\nassume that all the rays are going through\nthat point because you",
    "start": "1915040",
    "end": "1920200"
  },
  {
    "text": "can replace this\nwhole thing by one single lens in a [INAUDIBLE].",
    "start": "1920200",
    "end": "1926419"
  },
  {
    "text": "So finding that plane is\nactually a tricky problem.",
    "start": "1926420",
    "end": "1932300"
  },
  {
    "text": "And in retrospect,\nit's very easy. If the lens makers are\nputting everything there,",
    "start": "1932300",
    "end": "1938030"
  },
  {
    "text": "we should put a\nrecorded aperture also in the same plane. So initially we said, oh,\nlet's put it in the front. Let's put it in the back.",
    "start": "1938030",
    "end": "1943909"
  },
  {
    "text": "We tried all those things. But that creates a blur\nthat's not constant all over the image. And it has a lot of issues.",
    "start": "1943910",
    "end": "1949880"
  },
  {
    "text": "But placing it over\nthere, it turns out you get the same blur. So what exactly\nhappens if you take",
    "start": "1949880",
    "end": "1956000"
  },
  {
    "text": "a picture of a point light, and\neverything is a sharp focus? Nothing changes, OK?",
    "start": "1956000",
    "end": "1964530"
  },
  {
    "text": "If you have just\nan open aperture and take a picture of a point\nlight, it looks like a disc.",
    "start": "1964530",
    "end": "1971809"
  },
  {
    "text": "Now what's going to happen when\nyou put this code, like the 7",
    "start": "1971810",
    "end": "1978530"
  },
  {
    "text": "by 7 mask, and take a\nout-of-focus picture? What will happen to the LED? AUDIENCE: It's going\nto look like a code.",
    "start": "1978530",
    "end": "1985100"
  },
  {
    "text": "RAMESH RASKAR: It's going to\nlook like the code, right? And why is that-- why\nis that happening?",
    "start": "1985100",
    "end": "1990450"
  },
  {
    "text": "So let's think about\n[INAUDIBLE] focus. ",
    "start": "1990450",
    "end": "1997740"
  },
  {
    "text": "So we have our lens, right? And we have a point light.",
    "start": "1997740",
    "end": "2003590"
  },
  {
    "text": "And we will put some code here.  When it's in sharp\nfocus, it doesn't really",
    "start": "2003590",
    "end": "2011580"
  },
  {
    "text": "matter what the code is. Basically, you're talking\nabout half the light, so the photo will\nbe half a square.",
    "start": "2011580",
    "end": "2017820"
  },
  {
    "text": "But other than that, it\nlooks like an ordinary focus. And that's why if you have\nsome dust on your lens",
    "start": "2017820",
    "end": "2023890"
  },
  {
    "text": "and so on, usually\nit doesn't matter unless you have the dust all\nthe way on your front lens",
    "start": "2023890",
    "end": "2033270"
  },
  {
    "text": "because the center\noperation's over here. So if the dust was over\nhere, nothing will happen.",
    "start": "2033270",
    "end": "2039159"
  },
  {
    "text": "The image will be\nslightly darker. But if the dust is\nall in the front, then you start seeing distance.",
    "start": "2039160",
    "end": "2044700"
  },
  {
    "text": "Anyway, so when it's in sharp\nfocus, you just see the point. But let's say that\nyour autofocus here.",
    "start": "2044700",
    "end": "2057310"
  },
  {
    "text": "What will you see? You will see the same\nexact [INAUDIBLE].. So the [? ray ?] comes in. It's blocked.",
    "start": "2057310",
    "end": "2063460"
  },
  {
    "text": "This ray goes in. It goes through. This ray comes in. It's blocked. This ray goes\nthrough, and so on.",
    "start": "2063460",
    "end": "2069579"
  },
  {
    "text": "So basically, you'll\nsee the same [? boat. ?] If you put the sensor\nall the way here, you'll see the whole code. If you start moving away,\nthe code will shrink.",
    "start": "2069580",
    "end": "2078099"
  },
  {
    "text": "And eventually, when you put\nit here, we get another code. That's exactly what's\nhappening here.",
    "start": "2078100",
    "end": "2084440"
  },
  {
    "text": "When it's auto focus, we\njust see the code, all right? By the way, this is the same\nidea behind another project,",
    "start": "2084440",
    "end": "2091940"
  },
  {
    "text": "which is [INAUDIBLE]. So the idea came\naround at the same time of how to make this happen.",
    "start": "2091940",
    "end": "2097149"
  },
  {
    "text": " OK. AUDIENCE: Wouldn't the\nimaging of this code now still",
    "start": "2097150",
    "end": "2104700"
  },
  {
    "text": "have to be blurred? Like, so is that\nbasically multiple apertures that you're seeing?",
    "start": "2104700",
    "end": "2109900"
  },
  {
    "text": "RAMESH RASKAR: Yeah, so\nthe photo here is nothing-- the photo here that you\nsee is still blurred.",
    "start": "2109900",
    "end": "2118650"
  },
  {
    "text": "It's just that it's blurred\nin a slightly different way-- strange.",
    "start": "2118650",
    "end": "2124349"
  },
  {
    "text": "Here, it's blurred\nwith that shape. Every point is blurred\nwith that spread function.",
    "start": "2124350",
    "end": "2129690"
  },
  {
    "text": "And you cannot see anything\non the resolution chart. But here, if I just\npromote this guy--",
    "start": "2129690",
    "end": "2135720"
  },
  {
    "text": "no, that won't work because\nI'm in a different mode.",
    "start": "2135720",
    "end": "2140930"
  },
  {
    "text": " If I look at this picture,\nyou will see that--",
    "start": "2140930",
    "end": "2148870"
  },
  {
    "text": "so this is a sharp photo. It's blurred with disc. And it's blurred\nwith that function.",
    "start": "2148870",
    "end": "2155390"
  },
  {
    "text": "You can already see that\nit seems to preserve slightly more information. But it's still-- you won't be\nable to with your naked eye.",
    "start": "2155390",
    "end": "2161677"
  },
  {
    "text": "You'll not be able to figure out\nwhat underlying patterns are. But it turns out, after\nthe blurring, you can.",
    "start": "2161677",
    "end": "2168650"
  },
  {
    "text": "All right, so then you can\ndo these simple tricks, where the person you're\ninterested in is out of focus.",
    "start": "2168650",
    "end": "2175470"
  },
  {
    "text": "But then you can\nrefocus digitally. So this is the input photo and\nthe stock photos, all right?",
    "start": "2175470",
    "end": "2182630"
  },
  {
    "text": "So the same exact trick,\nwhich is in case of motion, we created a point\nspread function",
    "start": "2182630",
    "end": "2189380"
  },
  {
    "text": "that was engineered\nin one dimension. And here, we are engineering\na point spread function",
    "start": "2189380",
    "end": "2195920"
  },
  {
    "text": "that's two dimensional. So here, we know that the\nFourier transform of this 1D",
    "start": "2195920",
    "end": "2203130"
  },
  {
    "text": "52-length vector is broadband. It has energy at\nall the frequency. What can we say about this?",
    "start": "2203130",
    "end": "2208744"
  },
  {
    "text": " It's fully transformed. What can we say?",
    "start": "2208745",
    "end": "2215250"
  },
  {
    "text": "It's still 7 by 7. So its Fourier transform\nis also 7 by 7. When it's 52, its Fourier\ntransform is 52 long.",
    "start": "2215250",
    "end": "2223260"
  },
  {
    "start": "2223260",
    "end": "2228390"
  },
  {
    "text": "AUDIENCE: It's more distributed\ninstead of just all being near the center. RAMESH RASKAR: So in 1D,\nthis is what we saw, right?",
    "start": "2228390",
    "end": "2235020"
  },
  {
    "text": "Its Fourier transform is flat. So there are 52 entries\nhere, and almost all of them",
    "start": "2235020",
    "end": "2240570"
  },
  {
    "text": "are the same. Now we're saying, think\nabout the problem in 2D.",
    "start": "2240570",
    "end": "2246234"
  },
  {
    "start": "2246235",
    "end": "2251360"
  },
  {
    "text": "And what's the Fourier\ntransform of this? So first, for this one,\nthe Fourier transform is--",
    "start": "2251360",
    "end": "2261380"
  },
  {
    "text": "as we see, it's black. And then if you\ntake that in 2D--",
    "start": "2261380",
    "end": "2270609"
  },
  {
    "text": "so how is the code? I'll give you a hint. If I just take a square\naperture, a traditional one,",
    "start": "2270610",
    "end": "2277280"
  },
  {
    "text": "and take a square\ntransform, it will look-- the Fourier transform of this\none looks something like this.",
    "start": "2277280",
    "end": "2282815"
  },
  {
    "text": " [INAUDIBLE] So Fourier transform\nof this one--",
    "start": "2282815",
    "end": "2288600"
  },
  {
    "text": "if I take the\ncross-section here, it's going to look the same. Same thing here for\na square aperture.",
    "start": "2288600",
    "end": "2294880"
  },
  {
    "text": "And now you're saying for this\ncrossword-puzzle-shaped item,",
    "start": "2294880",
    "end": "2301694"
  },
  {
    "text": "should be easy. It's going to look\njust like this one. ",
    "start": "2301695",
    "end": "2312110"
  },
  {
    "text": "So a Fourier transform of 7 by 7\nwill have a peak in the middle. So the truly Fourier transform\nwill have a peak in the middle.",
    "start": "2312110",
    "end": "2319790"
  },
  {
    "text": "But the rest of the\nvalues will be constant. And that's the magic\nof a broadband code.",
    "start": "2319790",
    "end": "2326198"
  },
  {
    "text": "So if we're placing\na broadband code, certainly we have an opportunity\nto recover all the information.",
    "start": "2326198",
    "end": "2332330"
  },
  {
    "text": "So it seems very, very\nlong winded, right?",
    "start": "2332330",
    "end": "2337520"
  },
  {
    "text": "If all I wanted to do was\ncreate a photo from which I can deblur to get\nsharp photo, why",
    "start": "2337520",
    "end": "2346130"
  },
  {
    "text": "do I need to think about\nall this theory, right? And the reason is, when we think\nabout point spread function,",
    "start": "2346130",
    "end": "2354213"
  },
  {
    "text": "it's just traditional\nsignal processing. It's a convolution and so\non, and it's much easier to think about convolution\nand deconvolution in frequency",
    "start": "2354213",
    "end": "2362930"
  },
  {
    "text": "domain than in primal domain. And in communication theory,\neverything is [INAUDIBLE]..",
    "start": "2362930",
    "end": "2370350"
  },
  {
    "text": "We think about carrier\nfrequencies of radio stations in frequencies. We say, my FM channel is at\n99 megahertz, 100 megahertz,",
    "start": "2370350",
    "end": "2377390"
  },
  {
    "text": "and so on. And we think about guard\nbands and audio bands",
    "start": "2377390",
    "end": "2382642"
  },
  {
    "text": "and everything interested\nin frequency domain. And that's because\nit's signal processing. It's the same thing\nthat's going on here.",
    "start": "2382643",
    "end": "2388280"
  },
  {
    "text": "And convolution,\ndeconvolution-- much easier to think in frequency domain. Although all the analysis in the\nfrequency domain, at the end,",
    "start": "2388280",
    "end": "2395599"
  },
  {
    "text": "the solution is very easy-- just flutter the shutter or\njust put a coded aperture.",
    "start": "2395600",
    "end": "2402388"
  },
  {
    "text": "Extremely simple\nsolution to achieve that. So those are all good\nthings about coded aperture.",
    "start": "2402388",
    "end": "2409890"
  },
  {
    "text": "What are some bad things\nabout coded aperture? What are some\ndisadvantages here? ",
    "start": "2409890",
    "end": "2416967"
  },
  {
    "text": "It's very similar\nto the [INAUDIBLE].. AUDIENCE: Half the light. RAMESH RASKAR: So\nhalf the light. Very good.",
    "start": "2416967",
    "end": "2422150"
  },
  {
    "text": "And that's when you talk to\npeople who build cameras, and you tell them,\nthey say, no, no, no. That's not allowed.",
    "start": "2422150",
    "end": "2428130"
  },
  {
    "text": "It doesn't cut the light. Yes. AUDIENCE: Are the\nbokehs kind of uppity? RAMESH RASKAR: The bokehs\nare-- it depends on your--",
    "start": "2428130",
    "end": "2434740"
  },
  {
    "text": "I mean, for your\naverage consumer, I don't know whether\nthis matters. But you're right. If you're looking at\nsomething that's--",
    "start": "2434740",
    "end": "2440829"
  },
  {
    "text": "we have bright\nlights in the scene. At a distance, take\nour false photo. They will all look like this. AUDIENCE: Or you could put\nhearts in it, or, like--",
    "start": "2440830",
    "end": "2447850"
  },
  {
    "text": "AUDIENCE: Right, yeah,\nI was thinking maybe-- AUDIENCE: I mean,\nthat's totally possibly. [LAUGHTER] RAMESH RASKAR: So an\ninteresting art problem",
    "start": "2447850",
    "end": "2454390"
  },
  {
    "text": "is how do you create-- how do you create a mask that\nvisually looks aesthetic but is",
    "start": "2454390",
    "end": "2460450"
  },
  {
    "text": "mathematically also invertible. AUDIENCE: Yeah. RAMESH RASKAR: Are\nthere disadvantages?",
    "start": "2460450",
    "end": "2466570"
  },
  {
    "text": "Or challenges? Not really disadvantage. Remember, in the\nmotion case, we had",
    "start": "2466570",
    "end": "2471700"
  },
  {
    "start": "2470000",
    "end": "2615000"
  },
  {
    "text": "to know how much the motion is. What do we need to know here? AUDIENCE: We know\nhow much the blur is.",
    "start": "2471700",
    "end": "2477470"
  },
  {
    "text": "RAMESH RASKAR: How\nmuch the blur is. And what is that function of? If anything, plane\nof focus is sharp.",
    "start": "2477470",
    "end": "2482590"
  },
  {
    "text": "When it's out of plane\nof focus, it's blurred. But the size of the blur\nis dependent on what? AUDIENCE: Belt.",
    "start": "2482590",
    "end": "2487828"
  },
  {
    "text": "RAMESH RASKAR: The\nbelt. But not just depth-- depth from the\nplane of focus, right? So that's an extra parameter\nyou would estimate somehow.",
    "start": "2487828",
    "end": "2494830"
  },
  {
    "text": "Maybe you can use a\nrangefinder or something like that, or just a software. There are methods\nyou can employ.",
    "start": "2494830",
    "end": "2502150"
  },
  {
    "text": "AUDIENCE: Don't you just try\nto assume something like we've got to see this contrast? RAMESH RASKAR: Yeah.",
    "start": "2502150",
    "end": "2507700"
  },
  {
    "text": "AUDIENCE: Yeah. RAMESH RASKAR:\nYou could do that. It doesn't work that well. but you're right. That would be another\nway, too, to try this.",
    "start": "2507700",
    "end": "2515609"
  },
  {
    "text": "AUDIENCE: You can just maximize\nyour hard edges in the image. RAMESH RASKAR: Exactly. That's what you would do,\nlike, in a light field, when",
    "start": "2515610",
    "end": "2521070"
  },
  {
    "text": "we did the refocusing. That's the trick we used. We said, OK, let\nme try to refocus. I don't care about the depth.",
    "start": "2521070",
    "end": "2527549"
  },
  {
    "text": "When it comes into\nsharp focus, my edges, that must be the right depth. Unfortunately, it doesn't\nwork out in this case.",
    "start": "2527550",
    "end": "2534990"
  },
  {
    "text": "And we won't go into the\ndetail, but the main reason is that, because it's\ncoded aperture, no matter",
    "start": "2534990",
    "end": "2541050"
  },
  {
    "text": "where you refocus, it\nstill looks like it has very high frequencies. ",
    "start": "2541050",
    "end": "2547080"
  },
  {
    "text": "So that makes it challenging. Yes. AUDIENCE: How did you\ncome up with the pattern? RAMESH RASKAR: Oh, exactly.",
    "start": "2547080",
    "end": "2552575"
  },
  {
    "text": "So you need to find this\n7-by-7 pattern or even the previous case,\nthe 52 pattern. And you take a random sequence.",
    "start": "2552575",
    "end": "2559640"
  },
  {
    "text": "Take a Fourier transform\nto see if it's flat. If it's not flat, you\ngo to the next one. AUDIENCE: Oh, so\nthis is brute force? There's not, like, a pretty\nmathematical formula for this?",
    "start": "2559640",
    "end": "2566020"
  },
  {
    "text": "RAMESH RASKAR: So initial,\nthat's what I did. I said, wow, it\ncan't be that bad. 2 to the 50-- I mean, it's 52-element long.",
    "start": "2566020",
    "end": "2572180"
  },
  {
    "text": "And I know some of them. I only want to take the ones in\nwhich about half of them are-- AUDIENCE: 1s.",
    "start": "2572180",
    "end": "2577430"
  },
  {
    "text": "RAMESH RASKAR: --1s\nand half of them are 0. So it can't be that bad. So I wrote a MATLAB script.",
    "start": "2577430",
    "end": "2582510"
  },
  {
    "text": "And I said, by the time\nI come tomorrow morning, I'll find a really good code. And I came back next morning.",
    "start": "2582510",
    "end": "2587685"
  },
  {
    "text": "Nothing had happened. I waited all day. It was still running. And it never came out of that. So 2 the 52 is\npretty challenging.",
    "start": "2587685",
    "end": "2595760"
  },
  {
    "text": "AUDIENCE: Yes. Where's your [? canu ?] cluster? We need it. RAMESH RASKAR: Yeah, so-- sorry? AUDIENCE: Where's your\n[? canu ?] cluster? We need it.",
    "start": "2595760",
    "end": "2601040"
  },
  {
    "text": "RAMESH RASKAR: Exactly. But even if you use a cluster,\nit's still a pretty big number. So you can do some\napproximation. So you can start with some\ncode and do a gradient descent",
    "start": "2601040",
    "end": "2609320"
  },
  {
    "text": "and so on. Yeah. AUDIENCE: Does the [? harder ?]\n[? mark ?] code or anything? Is that applicable here?",
    "start": "2609320",
    "end": "2614448"
  },
  {
    "text": "RAMESH RASKAR: Mhm. So actually, after we\ndid these two projects,",
    "start": "2614448",
    "end": "2619850"
  },
  {
    "start": "2615000",
    "end": "2651000"
  },
  {
    "text": "I attended Professor\nHan's lecture on computational imaging, which\nI highly recommend, by the way.",
    "start": "2619850",
    "end": "2625340"
  },
  {
    "text": "It's terrific. And there are all these\ntheories about how",
    "start": "2625340",
    "end": "2630800"
  },
  {
    "text": "to create different codes\nfor different applications. So [? harder ?] [? mark ?] code,\nwhich we learned about a few",
    "start": "2630800",
    "end": "2636980"
  },
  {
    "text": "weeks ago or so-called\nbroadband codes, they all have polynomial\nsolutions and this and that.",
    "start": "2636980",
    "end": "2643430"
  },
  {
    "text": "There's no good\nsolutions for 2D. But for 1D, there are\nsome really good solutions",
    "start": "2643430",
    "end": "2649040"
  },
  {
    "text": "to come up with that. And even for 2D, for\ncertain dimensions, they call it one\nmore 4 or three more",
    "start": "2649040",
    "end": "2656810"
  },
  {
    "text": "4 because prime numbers\ncan be one more 4. Basically, when you divide by\n4, the remainder can be 1 or 3.",
    "start": "2656810",
    "end": "2665540"
  },
  {
    "text": "And there are certain\nsequences that are beautiful\nmathematical properties, of which sequences could\nhave broadband properties",
    "start": "2665540",
    "end": "2672680"
  },
  {
    "text": "and which may not. So it turns out you cannot-- there's a little bit of\ncheating going on here.",
    "start": "2672680",
    "end": "2678869"
  },
  {
    "text": "So you cannot really use the\nbroadband code here either to give you the best result.\nYou can call them broadband",
    "start": "2678870",
    "end": "2685160"
  },
  {
    "text": "because their\nbehavior is broadband. But the traditional code's\ncalled MURA code, M-U-R-A,",
    "start": "2685160",
    "end": "2691730"
  },
  {
    "text": "Multiple Uniform\nRedundant Array. They invented not very long\nago, maybe 20, 30 years ago.",
    "start": "2691730",
    "end": "2697940"
  },
  {
    "text": "And they used in CDMA and many\nother astronomical-imaging",
    "start": "2697940",
    "end": "2705680"
  },
  {
    "text": "applications. And they have similar\nproperties of being-- if you take a circle to\ntransform, it's broadband.",
    "start": "2705680",
    "end": "2712820"
  },
  {
    "text": "The problem is, in\nmany of those example-- many of those applications,\nyour convolution",
    "start": "2712820",
    "end": "2720470"
  },
  {
    "text": "is actually circular. So you apply the filter, and\nthen when you go off the edge, you apply the filter to the\nbeginning of the signal.",
    "start": "2720470",
    "end": "2729600"
  },
  {
    "text": "This particular filter\nis actually not circular, but it's linear. So when you apply\nthe filter here,",
    "start": "2729600",
    "end": "2734660"
  },
  {
    "text": "when you start applying the\nfilter at the end of the image, you don't go back to the\nfront of the image because,",
    "start": "2734660",
    "end": "2739970"
  },
  {
    "text": "clearly, if I put an LED\nhere, you get out of focus. If I put an LED here, you'll\nonly get half of that.",
    "start": "2739970",
    "end": "2746408"
  },
  {
    "text": "The rest of the half\nis just blocked. It's not going to\nmagically appear over here. So that's the difference\nbetween linear convolution",
    "start": "2746408",
    "end": "2752810"
  },
  {
    "text": "and circular convolution. It turns out, for\ncircular convolution, the match is very clean and\nbeautiful and smoother course",
    "start": "2752810",
    "end": "2760760"
  },
  {
    "text": "work. Or for linear convolution,\nthere is no good mechanism. So we came up with our own\ncode called RAT code, R-A-T,",
    "start": "2760760",
    "end": "2770030"
  },
  {
    "text": "which is after three quarters. Oscar [INAUDIBLE]. AUDIENCE: So how did\nyou find that code?",
    "start": "2770030",
    "end": "2777320"
  },
  {
    "text": "RAMESH RASKAR: By\ndoing research. AUDIENCE: Just doing research? RAMESH RASKAR: Yeah. AUDIENCE: OK. RAMESH RASKAR: But it's\nnot a brute-force search.",
    "start": "2777320",
    "end": "2783415"
  },
  {
    "text": "AUDIENCE: Yeah. It was an intelligent. AUDIENCE: And if you included\nenough padding there,",
    "start": "2783415",
    "end": "2789890"
  },
  {
    "text": "wouldn't you be able to\nuse circular convolution? RAMESH RASKAR: Yeah, I\nmean, circular convolution-- I mean the linear convolution is\nbasically circular convolution",
    "start": "2789890",
    "end": "2798140"
  },
  {
    "text": "with a lot of padding of 0s. AUDIENCE: Yeah, because you said\nthen the math would be easier, right? RAMESH RASKAR: But\nthen it's too large.",
    "start": "2798140",
    "end": "2803965"
  },
  {
    "text": "I mean, finding a code that's\n7 long or maybe 30 long is OK.",
    "start": "2803965",
    "end": "2809990"
  },
  {
    "text": "Finding a code that's 1,000\nlong is nearly impossible. AUDIENCE: So the difference\nbetween MULA and that is only on the edges?",
    "start": "2809990",
    "end": "2815869"
  },
  {
    "text": "Or is it all over the picture? RAMESH RASKAR:\nIt's only the fact that one is linear\nconvolution and one is circular convolution.",
    "start": "2815870",
    "end": "2820940"
  },
  {
    "text": "AUDIENCE: OK. AUDIENCE: Yeah, and another\nthing is it's pretty amazing that [INAUDIBLE] because if you\nstart just having very simple",
    "start": "2820940",
    "end": "2828680"
  },
  {
    "text": "patterns on a\nsquare-- like, say, if you just draw this square\nand sat down this square, you get the free entrance\nform, and you have all--",
    "start": "2828680",
    "end": "2836113"
  },
  {
    "text": "RAMESH RASKAR: Yeah,\nall over the place. So, yeah, so it seems like can\njust choose a random sequence",
    "start": "2836113",
    "end": "2841670"
  },
  {
    "text": "and get a similar property. But actually, it doesn't work. The chances of a random sequence\ndoing the right thing for you",
    "start": "2841670",
    "end": "2848069"
  },
  {
    "text": "is very, very low. AUDIENCE: Instead\nof [INAUDIBLE].. [LAUGHTER]",
    "start": "2848070",
    "end": "2853359"
  },
  {
    "text": " AUDIENCE: Are astronomy\npeople are already using--",
    "start": "2853360",
    "end": "2858910"
  },
  {
    "text": "RAMESH RASKAR: Mhm, yeah. AUDIENCE: Or they were\nusing this for [INAUDIBLE]?? RAMESH RASKAR: So in astronomy,\nyou have circular convolution",
    "start": "2858910",
    "end": "2865960"
  },
  {
    "start": "2862000",
    "end": "2994000"
  },
  {
    "text": "because they use\neither two mirror tiles and one sensor or one\nmirror tile and two sensors.",
    "start": "2865960",
    "end": "2872150"
  },
  {
    "text": "So the whole\ncircular convolution. So all right. AUDIENCE: If you're tired of\n[INAUDIBLE] astronomically",
    "start": "2872150",
    "end": "2879440"
  },
  {
    "text": "coded imagery. RAMESH RASKAR: Repeat that. AUDIENCE: If you're tiling\nthe mask at aperture,",
    "start": "2879440",
    "end": "2885650"
  },
  {
    "text": "but you are using\nsingle-tiled aperture-- RAMESH RASKAR: Right. AUDIENCE: So if you're\ntiling that up-- RAMESH RASKAR: If\nyou tile aperture, you'll get really horrible\nfrequency response,",
    "start": "2885650",
    "end": "2892940"
  },
  {
    "text": "unfortunately, because if\nyou put two tiles, that means certain frequencies are lost. ",
    "start": "2892940",
    "end": "2901460"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nimpressive. It's saying that, if I\nunderstand this right,",
    "start": "2901460",
    "end": "2906620"
  },
  {
    "text": "basically, by taking\nthe DC coefficient, you're reconstructing\nalmost everything.",
    "start": "2906620",
    "end": "2912569"
  },
  {
    "text": "Is that-- RAMESH RASKAR:\nNo, no, no, not DC coefficient because if you look\nhere, all the high spatial-- I mean, the whole\nimage is not one value.",
    "start": "2912570",
    "end": "2919130"
  },
  {
    "text": "AUDIENCE: Yeah,\nbut look at that. That's the spectrum of your-- RAMESH RASKAR: Right. No, but there is a non-zero\nvalue at other frequencies.",
    "start": "2919130",
    "end": "2926453"
  },
  {
    "text": "AUDIENCE: Yeah, yeah, a few. But-- RAMESH RASKAR: No, no,\nthat's very important. AUDIENCE: Yeah,\nbut by taking that, you could get a very\ngood approximation.",
    "start": "2926453",
    "end": "2932630"
  },
  {
    "text": "RAMESH RASKAR: Yeah. But if-- to a naive\nconsumer, this photo--",
    "start": "2932630",
    "end": "2939440"
  },
  {
    "text": "so look at this part, OK? This photo and this photo\nlooks almost the same, right?",
    "start": "2939440",
    "end": "2944480"
  },
  {
    "text": "And remember, in this photo,\nmany of those frequencies are lost. ",
    "start": "2944480",
    "end": "2951710"
  },
  {
    "text": "And in this photo,\nthose frequencies are not lost because all the\nfrequencies are preserved.",
    "start": "2951710",
    "end": "2958910"
  },
  {
    "text": "But that's because\nour eyes are not very good at thinking about what\nthe original image could be,",
    "start": "2958910",
    "end": "2966050"
  },
  {
    "text": "given either this one\nor the previous one. So given this, I\ncan challenge you",
    "start": "2966050",
    "end": "2971240"
  },
  {
    "text": "that you're not able\nto predict that it has all this structure, right?",
    "start": "2971240",
    "end": "2977849"
  },
  {
    "text": "From here, you cannot predict\nthat you have the structure. AUDIENCE: So how would\nyou describe the mask as?",
    "start": "2977850",
    "end": "2985099"
  },
  {
    "text": "Basically, you spread\nthe energy in [INAUDIBLE] set of over many frequencies\nbut very small coefficients.",
    "start": "2985100",
    "end": "2993920"
  },
  {
    "text": "Is that-- RAMESH RASKAR: Exactly. It's about-- depending on the\ncode, it's about 1/10 or 1/20",
    "start": "2993920",
    "end": "2999960"
  },
  {
    "start": "2994000",
    "end": "3059000"
  },
  {
    "text": "of the original power\nof that frequency. So you get significant\nattenuation.",
    "start": "2999960",
    "end": "3005720"
  },
  {
    "text": "So the results are not perfect. If you look here, right, it's\nnot it's not perfect results,",
    "start": "3005720",
    "end": "3011910"
  },
  {
    "text": "whether it's here or here. Look at this.",
    "start": "3011910",
    "end": "3017540"
  },
  {
    "text": "I wouldn't call it\nphotography quality yet. AUDIENCE: Yeah, no. RAMESH RASKAR: But if\nyou apply very simple-- but it is a raw resource.",
    "start": "3017540",
    "end": "3023150"
  },
  {
    "text": "There is no medium filtering\nor smoothing or anything. It's just pure x equals\nb, x equals a backslash b.",
    "start": "3023150",
    "end": "3031970"
  },
  {
    "text": "AUDIENCE: Just the fact\nthat the mask, I guess, gives you balance. RAMESH RASKAR: Yeah, it's fun.",
    "start": "3031970",
    "end": "3037790"
  },
  {
    "text": "What's amazing\nabout coded imaging is that the math is elegant\nand beautiful and sometimes",
    "start": "3037790",
    "end": "3043430"
  },
  {
    "text": "complicated, but the\nimplementation is very easy. At the end, all I had\nto do is put this code or shutter it, and\nvery easy to explain.",
    "start": "3043430",
    "end": "3051530"
  },
  {
    "text": "My previous boss is\nto say, the best ideas are the ones that\nare easy to explain but difficult to conceive.",
    "start": "3051530",
    "end": "3058970"
  },
  {
    "text": "All right, so let's move on. OK, let me finish this one. So there's just one way of--",
    "start": "3058970",
    "end": "3067460"
  },
  {
    "text": "we only saw two\nways of engineering the point spread function, one\nin motion and one in focus,",
    "start": "3067460",
    "end": "3073970"
  },
  {
    "text": "right? But there are many others. We saw some of them over\nthe course of the semester,",
    "start": "3073970",
    "end": "3079250"
  },
  {
    "text": "where you can put, for example,\na special filter in the lens",
    "start": "3079250",
    "end": "3086570"
  },
  {
    "text": "so that you get blur\nthat's independent of that. AUDIENCE: Ramesh, let me\nask you one more question.",
    "start": "3086570",
    "end": "3092690"
  },
  {
    "text": "RAMESH RASKAR: Yes, go ahead. AUDIENCE: You had this\nbinary mask, right? RAMESH RASKAR: Mhm. AUDIENCE: What if the\nmask was not quite?",
    "start": "3092690",
    "end": "3097970"
  },
  {
    "text": "If you have some information\nby the board so that you could set up\napproximate [INAUDIBLE].. RAMESH RASKAR: Right.",
    "start": "3097970",
    "end": "3103760"
  },
  {
    "text": "AUDIENCE: So what\nwould you have? RAMESH RASKAR: So that's\na very good question. So-- let's see. Let me get this out first.",
    "start": "3103760",
    "end": "3111540"
  },
  {
    "text": "So if the function was-- ",
    "start": "3111540",
    "end": "3125430"
  },
  {
    "start": "3125000",
    "end": "3143000"
  },
  {
    "text": "if the function was continuous-- so in case of\nflutter shutter, we didn't have much of a choice.",
    "start": "3125430",
    "end": "3130960"
  },
  {
    "text": "It's either opaque\nor transparent. It's one or the other. AUDIENCE: Yeah, yeah. RAMESH RASKAR: But in\ncase of aperture, yes.",
    "start": "3130960",
    "end": "3137369"
  },
  {
    "text": "It doesn't have to be\nopaque or transparent. It could be a continuous value.",
    "start": "3137370",
    "end": "3142800"
  },
  {
    "text": "And initially, actually, I and\nmy co-author, Amit Agrawal-- very smart guy-- we always had\nthese arguments about maybe",
    "start": "3142800",
    "end": "3150690"
  },
  {
    "start": "3143000",
    "end": "3186000"
  },
  {
    "text": "continuous is better. Maybe binary is better. And he continued to believe\nthat continuous is better.",
    "start": "3150690",
    "end": "3156269"
  },
  {
    "text": "But it turns out-- and we\nstill don't agree with this, by the way. And nobody has\nwritten this down.",
    "start": "3156270",
    "end": "3163200"
  },
  {
    "text": "It turns out that, for\nany continuous code, there is a corresponding\nbinary code that will",
    "start": "3163200",
    "end": "3168870"
  },
  {
    "text": "do an equally good job, so far. And that's because\nin a binary code,",
    "start": "3168870",
    "end": "3175003"
  },
  {
    "text": "you get to play with\nthe phase function. I won't go to the detail. But because here, we\nare only showing you",
    "start": "3175003",
    "end": "3180120"
  },
  {
    "text": "the amplitude of the Fourier\ntransform but not the face. So you get that extra degree\nof freedom to play with.",
    "start": "3180120",
    "end": "3186339"
  },
  {
    "start": "3186000",
    "end": "3217000"
  },
  {
    "text": "So if you play with\nthe right phase, then it turns out you can\nalways have a binary function. Mike?",
    "start": "3186340",
    "end": "3191370"
  },
  {
    "text": "AUDIENCE: Has anyone tried\nto combine the coded aperture and the coded [INAUDIBLE]? RAMESH RASKAR:\nThat's a great idea.",
    "start": "3191370",
    "end": "3198820"
  },
  {
    "text": "People talk about it,\nbut nobody has done it. It's just one of those things.",
    "start": "3198820",
    "end": "3205000"
  },
  {
    "text": " It's just one of those things. It's like we are sick of it,\nso we don't want to do it.",
    "start": "3205000",
    "end": "3214348"
  },
  {
    "text": "But I think it's worth trying. And because those are\northogonal motion blur.",
    "start": "3214348",
    "end": "3219680"
  },
  {
    "start": "3217000",
    "end": "3287000"
  },
  {
    "text": "So here's a great\nthought experiment. So Mike's question\nwas, there could",
    "start": "3219680",
    "end": "3226900"
  },
  {
    "text": "be something that's moving, so\nit's motion blurred, but it's",
    "start": "3226900",
    "end": "3232329"
  },
  {
    "text": "also out of focus. OK? Can you use both at the\nsame time and record?",
    "start": "3232330",
    "end": "3240887"
  },
  {
    "text": "AUDIENCE: Yes. AUDIENCE: What about\nthe light width? RAMESH RASKAR: Yeah, it's\none fourth of the light, but let's not worry about that. ",
    "start": "3240887",
    "end": "3250560"
  },
  {
    "text": "OK. [LAUGHTER] Explain. AUDIENCE: There are orthogonal\ntechnologies, basically.",
    "start": "3250560",
    "end": "3255960"
  },
  {
    "text": "RAMESH RASKAR: Exactly. So it's amazing\nbecause motion is time, and the focus is space.",
    "start": "3255960",
    "end": "3261330"
  },
  {
    "text": "They're completely orthogonal. So you can play with it. It's very interesting.",
    "start": "3261330",
    "end": "3266580"
  },
  {
    "text": "AUDIENCE: But still,\nmotion is being represented by space on the-- RAMESH RASKAR: Yeah,\neventually, it's going to have a 2D projection.",
    "start": "3266580",
    "end": "3271810"
  },
  {
    "text": "AUDIENCE: Yeah. RAMESH RASKAR: So\nthat's very interesting. ",
    "start": "3271810",
    "end": "3277170"
  },
  {
    "text": "All right? So the point spread function,\nalthough I and my team",
    "start": "3277170",
    "end": "3284310"
  },
  {
    "text": "were the first one to do that\nin a graphics vision domain, people have been trying to do\nthat since mid '90s in imaging.",
    "start": "3284310",
    "end": "3291570"
  },
  {
    "start": "3287000",
    "end": "3306000"
  },
  {
    "text": "And there was a very classic\npaper by Cathey and Dowski and others for so-called\nwavefront coding.",
    "start": "3291570",
    "end": "3296885"
  },
  {
    "text": "And a lot of it\nis actually being used in cell phone cameras. And what they do is\nthey put this face",
    "start": "3296885",
    "end": "3302099"
  },
  {
    "text": "mask between the object-- near the lens so that-- and we saw this in the\nbeginning of the class--",
    "start": "3302100",
    "end": "3308950"
  },
  {
    "start": "3306000",
    "end": "3344000"
  },
  {
    "text": "so that the image does not\ncome into sharp focus ever. Instead of that, it's\nlike a set of straws.",
    "start": "3308950",
    "end": "3317730"
  },
  {
    "text": "Imagine these are all\nstraws that are coming in. And you just twist them.",
    "start": "3317730",
    "end": "3323320"
  },
  {
    "text": "So the top one kind\nof goes at the top-- I'm sorry, at the bottom. The bottom one goes at the top. And when you think about\nthe cross-section of all",
    "start": "3323320",
    "end": "3331800"
  },
  {
    "text": "the straws, it's\nkind of cylindrical, when they all come together. OK, I'm going to take all\nthese straws, or maybe strings,",
    "start": "3331800",
    "end": "3338660"
  },
  {
    "text": "if you want to think about it. And I'm going to twist them so\nthat they remain cylindrical. So if I put my sensor here,\nif the image is out of focus",
    "start": "3338660",
    "end": "3347130"
  },
  {
    "start": "3344000",
    "end": "3374000"
  },
  {
    "text": "by this width, if I\nput a sensor here, it's still out of focus\nbut by the same width.",
    "start": "3347130",
    "end": "3352589"
  },
  {
    "text": "So no matter where\nyou are, the image is out of focus but\nby the same amount.",
    "start": "3352590",
    "end": "3359750"
  },
  {
    "text": "And you say, well,\nwhat's good about that? It's always out of focus. But turns out, the wavefront\ncoding, as they call it,",
    "start": "3359750",
    "end": "3366180"
  },
  {
    "text": "but you can think of this\nnow we know what light field. So this just a unique\nlight field of the scene.",
    "start": "3366180",
    "end": "3374299"
  },
  {
    "start": "3374000",
    "end": "3599000"
  },
  {
    "text": "It turns out that from that,\nyou can recover images. ",
    "start": "3374300",
    "end": "3380150"
  },
  {
    "text": "Like, so this is open aperture. ",
    "start": "3380150",
    "end": "3389063"
  },
  {
    "text": "I'm sorry, I don't\nhave a picture. But we discussed\nit in the class, so I hope you remember that. ",
    "start": "3389063",
    "end": "3397480"
  },
  {
    "text": "I missed that picture. We saw this right in the\nvery first class, by the way. And the benefit of\nthat, it turns out,",
    "start": "3397480",
    "end": "3403930"
  },
  {
    "text": "is that it preserves\nthe spatial frequencies, and it has the benefit that, no\nmatter which steps you are at,",
    "start": "3403930",
    "end": "3411430"
  },
  {
    "text": "you have the same defocus blur. So the disadvantage\nof coded aperture was that you need to\nknow what the depth was",
    "start": "3411430",
    "end": "3418180"
  },
  {
    "text": "to be able to deblur. But now, because it's\nindependent of depth, you can just apply\nthe same deconvolution",
    "start": "3418180",
    "end": "3425350"
  },
  {
    "text": "and get back a sharper image. So whether if I hold\nmyself on camera, whether I'm here or\nhere or at infinity,",
    "start": "3425350",
    "end": "3432350"
  },
  {
    "text": "I get the same amount of blur. Same point spread function. And from that, I can\ndeconvolute and get",
    "start": "3432350",
    "end": "3440710"
  },
  {
    "text": "an extended depth of\nfield that goes from very close to the lens to infinity.",
    "start": "3440710",
    "end": "3448080"
  },
  {
    "text": "So OmniVision, which\nbought this company,",
    "start": "3448080",
    "end": "3454280"
  },
  {
    "text": "cerium optics, which is\nnamed after Cathey, Dowski, and somebody--",
    "start": "3454280",
    "end": "3461465"
  },
  {
    "text": "those are the two\nprofessors at Colorado. And the last one, I forget.",
    "start": "3461465",
    "end": "3467030"
  },
  {
    "text": "That was just bought\nby OmniVision, which is a big cell phone--",
    "start": "3467030",
    "end": "3472345"
  },
  {
    "text": "I mean, big imaging company. Most of the business\nis cell phones. And they acquired the\ncompany and immediately",
    "start": "3472345",
    "end": "3478339"
  },
  {
    "text": "laid off all the smart\npeople who invented this. It's very sad Because\nthat part is done.",
    "start": "3478340",
    "end": "3485270"
  },
  {
    "text": "So they just wanted\nthe technology. And it's in a lot of cameras.",
    "start": "3485270",
    "end": "3491030"
  },
  {
    "text": "There's another company\ncalled Tessera, which has a very similar solution.",
    "start": "3491030",
    "end": "3497430"
  },
  {
    "text": "But what they do is-- this\none, basically what it does-- and we discussed this, I\nthink, in the beginning,",
    "start": "3497430",
    "end": "3502650"
  },
  {
    "text": "the wavefront coding-- is they are simply\nplacing an addition here",
    "start": "3502650",
    "end": "3508975"
  },
  {
    "text": "so that this part of the lens\nwill focus on an image here. This part of the lens\nwill focus on this one.",
    "start": "3508976",
    "end": "3515780"
  },
  {
    "text": "This one focuses here. ",
    "start": "3515780",
    "end": "3521290"
  },
  {
    "text": "The top of the lens\nhas a short focus lens. It focuses here. The second one focuses here.",
    "start": "3521290",
    "end": "3527770"
  },
  {
    "text": "Third one focuses here. Fourth one focuses here. Fifth one focuses here.",
    "start": "3527770",
    "end": "3533605"
  },
  {
    "text": "Here. And here. OK, so if you can\nimagine the main lens",
    "start": "3533605",
    "end": "3539010"
  },
  {
    "text": "has a certain focal length. And we're just going\nto add a little bit of additional focal\nlength, which is--",
    "start": "3539010",
    "end": "3545550"
  },
  {
    "text": "that's why you have\nfocal length F1, F2, F10. And then [INAUDIBLE].",
    "start": "3545550",
    "end": "3551110"
  },
  {
    "text": "And this is the twist\nthat I was talking about. This was [INAUDIBLE]. ",
    "start": "3551110",
    "end": "3558790"
  },
  {
    "text": "But within this region, the\nthickness will be a bonus. So you can either think of it\nas adding small matchsticks",
    "start": "3558790",
    "end": "3567190"
  },
  {
    "text": "on top of the main lens-- or the way they do\nit is they actually put one single sheet that looks\nlike that, an additional layer",
    "start": "3567190",
    "end": "3577859"
  },
  {
    "text": "of support, a face mask. And a face mask basically\nmeans you are changing",
    "start": "3577860",
    "end": "3584140"
  },
  {
    "text": "the face of incoming light. And, as you know, if you\nhave a piece of glass, and light is going\nthrough, it's going",
    "start": "3584140",
    "end": "3590830"
  },
  {
    "text": "to slow down here and\nthen again [INAUDIBLE].. That means you basically\nslowed down the light.",
    "start": "3590830",
    "end": "3597372"
  },
  {
    "text": "And that's where the\nglass [INAUDIBLE].. If you have it at the top\nof the lens, like those two,",
    "start": "3597372",
    "end": "3603710"
  },
  {
    "text": "it doesn't slow down that much. If you go to the middle of\nit, it slows down forever.",
    "start": "3603710",
    "end": "3610040"
  },
  {
    "text": "That's why, as we learned\nabout at the beginning, if you have something\nvery far away, this",
    "start": "3610040",
    "end": "3615320"
  },
  {
    "text": "slows down a little bit. So those go over here. This goes over here.",
    "start": "3615320",
    "end": "3621079"
  },
  {
    "text": "And everything just works\nout with operations. But [INAUDIBLE] this extra\npiece of glass, you're saying,",
    "start": "3621080",
    "end": "3628352"
  },
  {
    "text": "I'm going to speed\nup and slow down in a slightly different\nway [INAUDIBLE].. This is the Syrian optic\nsolution or the [INAUDIBLE],,",
    "start": "3628352",
    "end": "3636310"
  },
  {
    "text": "which is actually bought\nas another company. [? Australia-- ?]\nforgetting the name.",
    "start": "3636310",
    "end": "3643930"
  },
  {
    "text": "The solution is very similar. I'm sure they're fighting\nout in court right now.",
    "start": "3643930",
    "end": "3651710"
  },
  {
    "text": "Same solution. Instead of putting\nthis particular guy, that's just going to add\nsome extra glass, but mostly",
    "start": "3651710",
    "end": "3663510"
  },
  {
    "text": "in a minor form.  It's just [INAUDIBLE]\non that one.",
    "start": "3663510",
    "end": "3670470"
  },
  {
    "text": "So basically the same\nsolution but creating different focal length for\ndifferent [? partners. ?] AUDIENCE: Yeah.",
    "start": "3670470",
    "end": "3676349"
  },
  {
    "text": "Although you said, I mean,\nthere's this portion there, where if you have another\nblur [INAUDIBLE],, right?",
    "start": "3676350",
    "end": "3682585"
  },
  {
    "text": "RAMESH RASKAR: Right. AUDIENCE: But what\nis being blurred? At each piece, or where is?",
    "start": "3682585",
    "end": "3688833"
  },
  {
    "text": "RAMESH RASKAR:\nIndependent of the depth, you get the same blur. AUDIENCE: Yeah, but see,\nsome guys are focusing, say--",
    "start": "3688833",
    "end": "3695475"
  },
  {
    "text": "RAMESH RASKAR: At an angle? It doesn't really matter. It doesn't really matter\nbecause, just like in a traditional camera, even\nif the point is not on axis",
    "start": "3695475",
    "end": "3702809"
  },
  {
    "text": "but off axis, you still get the\nsame-- you'll still get a disc, right, which we saw in the-- AUDIENCE: Yeah,\nyou get the deuce,",
    "start": "3702810",
    "end": "3709050"
  },
  {
    "text": "but I think that\nthe given picture, as you just move\nit back and forth, you're going to get a\ndifferent color, as you--",
    "start": "3709050",
    "end": "3715150"
  },
  {
    "text": "I mean, a different\namount of the mixture of-- RAMESH RASKAR: Different shape,\nyou mean, or different color?",
    "start": "3715150",
    "end": "3720450"
  },
  {
    "text": "AUDIENCE: Different color. RAMESH RASKAR: Not really. AUDIENCE: Because look at that. If the guy was\ncoming from the top, it's going to reach\nat some point.",
    "start": "3720450",
    "end": "3726840"
  },
  {
    "text": "RAMESH RASKAR: But they\nall have the same-- I mean, you're saying, because\nof chromatic aberration? AUDIENCE: No, just because\nof the geometry, at least",
    "start": "3726840",
    "end": "3732030"
  },
  {
    "text": "it seems to me. RAMESH RASKAR: Using\ncolor or shape?",
    "start": "3732030",
    "end": "3737099"
  },
  {
    "text": "Because just to be clear that we\nare not adding any color here. We're just adding one glass. AUDIENCE: OK.",
    "start": "3737100",
    "end": "3742300"
  },
  {
    "text": "OK, OK. RAMESH RASKAR: We're\njust adding one glass. So we're painting the\nrays, but the colors are,",
    "start": "3742300",
    "end": "3747382"
  },
  {
    "text": "for all practical purposes,\nthat'd be the same. AUDIENCE: Yeah, what I find\nis that maybe some points",
    "start": "3747382",
    "end": "3752610"
  },
  {
    "text": "in the scene would be-- made sure even a piece of-- RAMESH RASKAR: Yeah, the effect\nis very low, though, remember.",
    "start": "3752610",
    "end": "3759270"
  },
  {
    "text": "The effect is extremely low. So maybe you have a\npixel and get blurred by 10 pixels or [INAUDIBLE].",
    "start": "3759270",
    "end": "3766680"
  },
  {
    "text": "It's not a global effect. So this picture, maybe--\nthis particular diagram is misleading because it\nseems like this point is",
    "start": "3766680",
    "end": "3773430"
  },
  {
    "text": "going to go all the way. But this is very narrow. And the blur is only\nabout 10 pixels,",
    "start": "3773430",
    "end": "3779250"
  },
  {
    "text": "no matter where you [INAUDIBLE]. So maybe that was the matter. So if you have a\npoint of access,",
    "start": "3779250",
    "end": "3785559"
  },
  {
    "text": "it's still going to create an\nimage that's blurred 10 pixels. So this is, again,\nvery counterintuitive,",
    "start": "3785560",
    "end": "3792730"
  },
  {
    "text": "where you go to make the\nimage intentionally blurred. It's just that it's\nblurred everywhere.",
    "start": "3792730",
    "end": "3801220"
  },
  {
    "text": "And then we also saw\nthis one very early on, where the point\nspread function--",
    "start": "3801220",
    "end": "3806350"
  },
  {
    "text": "typically when something\ngoes in and out of focus, it looks like a point. And then when it goes out of\nfocus, it looks like a disc.",
    "start": "3806350",
    "end": "3812260"
  },
  {
    "text": "If it goes out of\nfocus other ways, it still looks like a disc. But this group at,\nagain, at Colorado",
    "start": "3812260",
    "end": "3818230"
  },
  {
    "text": "have-- when it's\na sharp focus, you see two doors for similarity. And if you go in and\nout of focus, then",
    "start": "3818230",
    "end": "3824920"
  },
  {
    "text": "the two dots [INAUDIBLE]. So they call it rotating\npoint spread function.",
    "start": "3824920",
    "end": "3831058"
  },
  {
    "text": "AUDIENCE: Is it the same\ngroup that developed the [? framework? ?] RAMESH RASKAR: It's not the\nsame group, but same university",
    "start": "3831058",
    "end": "3837840"
  },
  {
    "text": "and the same neighborhood. AUDIENCE: What was the reasoning\nfor developing the rotating",
    "start": "3837840",
    "end": "3843210"
  },
  {
    "text": "point spread function? RAMESH RASKAR: Doug's question\nis, what's the benefit of this?",
    "start": "3843210",
    "end": "3848640"
  },
  {
    "text": "AUDIENCE: Does [INAUDIBLE]? [LAUGHTER] RAMESH RASKAR: She would\nhave used it by now.",
    "start": "3848640",
    "end": "3853740"
  },
  {
    "text": "AUDIENCE: Yeah. RAMESH RASKAR: What's the\nbenefit of the strange point spread function? AUDIENCE: You know if you're\nout of focus in which direction.",
    "start": "3853740",
    "end": "3859470"
  },
  {
    "text": "AUDIENCE: Yeah. RAMESH RASKAR: Yeah? AUDIENCE: From the focal point. RAMESH RASKAR: That's one. AUDIENCE: And you know your-- RAMESH RASKAR: But do\nyou know by how much? AUDIENCE: Yeah, you know\nby how much because--",
    "start": "3859470",
    "end": "3865230"
  },
  {
    "text": "RAMESH RASKAR:\nBecause it's an angle. AUDIENCE: --rotation. RAMESH RASKAR: So the goal here\nwas no matter where you are,",
    "start": "3865230",
    "end": "3871650"
  },
  {
    "text": "your point spread\nfunction is the same. The goal here is\nexactly opposite. If you go slightly out of focus,\nyou get a very different point",
    "start": "3871650",
    "end": "3878910"
  },
  {
    "text": "spread function. So this one they\nuse in microscopy with fluorescent dye.",
    "start": "3878910",
    "end": "3884130"
  },
  {
    "text": "So when you're looking\nwith a microscope, depending on what the depth\nof your tagged particle is,",
    "start": "3884130",
    "end": "3891359"
  },
  {
    "text": "the point spread function\nwill look very different. So you can estimate the depth\nby looking at the orientation",
    "start": "3891360",
    "end": "3896640"
  },
  {
    "text": "of those two dots. So that's very interesting.",
    "start": "3896640",
    "end": "3903180"
  },
  {
    "text": "AUDIENCE: But can't that guy\nkeep going all the way in? At some point, you can't-- RAMESH RASKAR: No,\nit doesn't work. After some point,\nthey'll stay the same.",
    "start": "3903180",
    "end": "3910140"
  },
  {
    "text": "AUDIENCE: OK. RAMESH RASKAR: This is only\nin the [? sweet ?] region. AUDIENCE: So have they\nbeen able to reconstruct",
    "start": "3910140",
    "end": "3916390"
  },
  {
    "text": "three-dimensional\nneuronal structures, or-- RAMESH RASKAR: Yeah, that's why\nthey're getting a lot of press. And they're doing some\namazing work, [INAUDIBLE]..",
    "start": "3916390",
    "end": "3924920"
  },
  {
    "text": "So they have a lot\nof collaborations, and now they're able to\nmeasure the z-dimension down",
    "start": "3924920",
    "end": "3932270"
  },
  {
    "text": "to about 10 nanometers. AUDIENCE: Wow. RAMESH RASKAR: The xy still\nremains traditional microscope",
    "start": "3932270",
    "end": "3937940"
  },
  {
    "text": "1 micron, 1/2 micron. But the z-dimension\nis 10 nanometers. ",
    "start": "3937940",
    "end": "3945117"
  },
  {
    "text": "It's very new. They are still working on\na lot of these concepts. OK? So let's very briefly\nlook at compressed sensing",
    "start": "3945117",
    "end": "3954200"
  },
  {
    "text": "because it's something you\nshould be familiar with. ",
    "start": "3954200",
    "end": "3965930"
  },
  {
    "text": "OK, so here's an idea that\nreceived a lot of publicity. It was even \"The 10\nEmerging Technologies\"",
    "start": "3965930",
    "end": "3974299"
  },
  {
    "text": "by a very reputable magazine. I hope you don't believe\nany of those things.",
    "start": "3974300",
    "end": "3980172"
  },
  {
    "text": "It's a very cool\nidea, by the way. And as a scientist,\nI really like it. But when somebody like\nTechnology Review or Wired",
    "start": "3980173",
    "end": "3987770"
  },
  {
    "text": "Magazine says, Top\n50, Top 10, of course,",
    "start": "3987770",
    "end": "3992850"
  },
  {
    "text": "I wish I'm listed among them. But at the same time--\nbecause, you know, it has good side effects.",
    "start": "3992850",
    "end": "4000200"
  },
  {
    "text": "Well, anyway, this\nsingle-pixel camera was listed as one of\nthe big things in 2005",
    "start": "4000200",
    "end": "4005890"
  },
  {
    "text": "by Technology Review, which\na magazine I really like, by the way. And the idea is,\ninstead of taking one",
    "start": "4005890",
    "end": "4012100"
  },
  {
    "text": "single photo, what\nyou're going to do is-- let's say that's your scene. You're go to turn on--",
    "start": "4012100",
    "end": "4018340"
  },
  {
    "text": "you go to take a\nsingle photodetector and aim it at a\nset of micrometers.",
    "start": "4018340",
    "end": "4025570"
  },
  {
    "text": "And in the simplest\ncase, what you will do is you turn off\nall the micrometers, that light goes this way.",
    "start": "4025570",
    "end": "4032109"
  },
  {
    "text": "And there's only one\nmicrometer, like this one. So a single photodetector-- this\nis like the dual photography",
    "start": "4032110",
    "end": "4038260"
  },
  {
    "text": "we saw right at the beginning,\nwhere you can see that card. If I just turn on this one\nmicrometer-- by the way,",
    "start": "4038260",
    "end": "4045340"
  },
  {
    "text": "this is what's in\nyour DLP projectors, the Texas Instruments Digital\nLight Processing Micrometer",
    "start": "4045340",
    "end": "4051670"
  },
  {
    "text": "Displays. So it's very easily available. | just receive light from\nthe scene for that one pixel.",
    "start": "4051670",
    "end": "4060109"
  },
  {
    "text": "So this scene is being\nimaged on this little array. And you just want to\nturn on this one pixel.",
    "start": "4060110",
    "end": "4065500"
  },
  {
    "text": "And then the next\npicture, you're going to turn on the\nnext pixel, and so on. And one at a time, if you go\nthrough this million pixels,",
    "start": "4065500",
    "end": "4072400"
  },
  {
    "text": "you will get a million\nmegapixel image, right?",
    "start": "4072400",
    "end": "4077980"
  },
  {
    "text": "But of course, the light\nwill be very little if you just turn on one pixel. So now, we'll do some\n[INAUDIBLE] multiplexing,",
    "start": "4077980",
    "end": "4084580"
  },
  {
    "text": "which we saw a few\nclasses ago, where you go to turn on over half\nof them, take one reading,",
    "start": "4084580",
    "end": "4091319"
  },
  {
    "text": "turn some other random\ncombination of half of them, and take a picture, and so on. And, again, after--\nnow about half of them",
    "start": "4091320",
    "end": "4097930"
  },
  {
    "text": "are contributing\nto the photodiodes. So the photodiode is\nvery well exposed, and you can take a very\nshort exposure reading.",
    "start": "4097930",
    "end": "4103810"
  },
  {
    "text": "And, again, if you take\nmillion such readings, you can recover this picture.",
    "start": "4103810",
    "end": "4108880"
  },
  {
    "text": "That's the concept. ",
    "start": "4108880",
    "end": "4113912"
  },
  {
    "text": "AUDIENCE: Does it exponentially\nincrease, the number of readings you have to take? RAMESH RASKAR:\nNo, just linearly. If you're on 2 megapixels,\nthen you need to take 2 million",
    "start": "4113913",
    "end": "4120297"
  },
  {
    "text": "[? pics. ?] All right? ",
    "start": "4120297",
    "end": "4125939"
  },
  {
    "text": "So the claim this group\nmade at Rice University was that if I wanted\na million-pixel image,",
    "start": "4125939",
    "end": "4133290"
  },
  {
    "text": "I don't have to really\ntake a million readings. I can do much fewer\nthan a million readings.",
    "start": "4133290",
    "end": "4141270"
  },
  {
    "text": "And the claim is that imagine\nif you had this photo as a JPEG.",
    "start": "4141270",
    "end": "4147330"
  },
  {
    "text": "In a composite, it might\ntake up only about tens of thousands of bytes. So let's say it takes\nup 10,000 bytes.",
    "start": "4147330",
    "end": "4154028"
  },
  {
    "text": "So if I can represent the\nimage with 10,000 bytes, and I'm going to take a\nphoto and compress it down",
    "start": "4154029",
    "end": "4160889"
  },
  {
    "text": "to 10,000 bytes, I can't\njust directly measure only 10,000 values in the scene\nso that I save on everything,",
    "start": "4160890",
    "end": "4169859"
  },
  {
    "text": "OK? So I can take this\npicture effectively with just 10,000 pixels but\nrecreate a million-pixel image.",
    "start": "4169859",
    "end": "4177700"
  },
  {
    "text": "And that's where the concept\nof compressive sensing or compressed imaging comes up.",
    "start": "4177700",
    "end": "4183450"
  },
  {
    "text": "You want to take something\nthat is much higher resolution but recover it in a\ncompressed way, where",
    "start": "4183450",
    "end": "4190140"
  },
  {
    "text": "it's taking the\npicture with a hardware and compressing the software. You're going to compress\nit while sensing.",
    "start": "4190140",
    "end": "4199080"
  },
  {
    "text": "So how does it look\nmathematically? So let's see.",
    "start": "4199080",
    "end": "4206046"
  },
  {
    "text": "Let's see if there's\nan easy way to explain this in a shorter time. ",
    "start": "4206046",
    "end": "4212489"
  },
  {
    "text": "So that's the trick\nwe're going to do. We're going to take\nabout half the pixel and measure the\nintensity and so on.",
    "start": "4212490",
    "end": "4218980"
  },
  {
    "text": "So those are our measurements. So our unknown image is x. And we're going to take a\nlot of these projections.",
    "start": "4218980",
    "end": "4225720"
  },
  {
    "text": "This is the [INAUDIBLE] matrix,\nfor those of you familiar. And these are our measurements. So we're going to say,\ngiven these measurements,",
    "start": "4225720",
    "end": "4232110"
  },
  {
    "text": "I'm going to recover\nmy original image.",
    "start": "4232110",
    "end": "4237400"
  },
  {
    "text": "Now, when you think\nabout a natural image,",
    "start": "4237400",
    "end": "4242750"
  },
  {
    "text": "the claim is that\nif you just use DCT, some photo coefficients, then\nyou can compress the image",
    "start": "4242750",
    "end": "4249670"
  },
  {
    "text": "and represent them with\nvery few bytes, only 10,000 bytes for a megapixel.",
    "start": "4249670",
    "end": "4255460"
  },
  {
    "text": "So let's say your Fourier\ncoefficients are here.",
    "start": "4255460",
    "end": "4260719"
  },
  {
    "text": "And this is your image. That means that if I just\nput a Fourier transform here,",
    "start": "4260720",
    "end": "4266260"
  },
  {
    "text": "then I can convert the\ncoefficients into the image. And the number of values\nrequired to represent an image",
    "start": "4266260",
    "end": "4275980"
  },
  {
    "text": "are much fewer than the\nmillion values required here. So we have a million values\nhere, but only about 10,000",
    "start": "4275980",
    "end": "4282699"
  },
  {
    "text": "values here. And the claim is that by\nusing this understanding that",
    "start": "4282700",
    "end": "4288340"
  },
  {
    "text": "my image can be represented\nin some transform basis-- in this case, Fourier basis--",
    "start": "4288340",
    "end": "4293500"
  },
  {
    "text": "using very few coefficients, can\nbe exploited while I'm sensing. OK, this is your optics.",
    "start": "4293500",
    "end": "4300520"
  },
  {
    "text": "This is your map.  See if I have it on slide 5.",
    "start": "4300520",
    "end": "4307570"
  },
  {
    "text": "So that's the theory\nof compressive sensing, that, using some basis, I can\ntransform the image and measure",
    "start": "4307570",
    "end": "4316880"
  },
  {
    "text": "in [? your ?] measurements. And there are certain cases\nwhere it is really true.",
    "start": "4316880",
    "end": "4322000"
  },
  {
    "text": "You have signals that can\nbe compressed very easily. A very classic example\nis in communication,",
    "start": "4322000",
    "end": "4329680"
  },
  {
    "text": "where, if you are doing\nsoftware radio, where you have a huge band of frequencies,\nand software radio-- instead",
    "start": "4329680",
    "end": "4339130"
  },
  {
    "text": "of tuning it with\nelectromagnetics, you just capture\nthe whole signal.",
    "start": "4339130",
    "end": "4344380"
  },
  {
    "text": "And then software, you\ncan listen to any station. ",
    "start": "4344380",
    "end": "4349690"
  },
  {
    "text": "And the necklace theory says,\nif your band is, I don't know,",
    "start": "4349690",
    "end": "4354790"
  },
  {
    "text": "100 megahertz, then\nyou must capture it with a signal that has a\nbandwidth of 100 milliamps.",
    "start": "4354790",
    "end": "4361780"
  },
  {
    "text": "But we know that in\ncommunication, not all bands are actually occupied. Many of the bands are empty.",
    "start": "4361780",
    "end": "4368530"
  },
  {
    "text": "Only certain frequencies\nhave a signal. So people have come up with\nvery clever mechanisms, where",
    "start": "4368530",
    "end": "4373840"
  },
  {
    "text": "they realize that you\ndon't have to capture a 100-megahertz signal. Only some of them\nare actually on.",
    "start": "4373840",
    "end": "4380950"
  },
  {
    "text": "I'm getting through\nthe Fourier transform because in communication,\nthat's natural.",
    "start": "4380950",
    "end": "4386050"
  },
  {
    "text": "And by doing that,\nthey're able to sample this effect of a software\nradio with a detector that",
    "start": "4386050",
    "end": "4393910"
  },
  {
    "text": "doesn't have to measure\n100-megahertz-wide signal. It turns out for images,\nthis doesn't work.",
    "start": "4393910",
    "end": "4402370"
  },
  {
    "text": "And that's because there\nis no transform that",
    "start": "4402370",
    "end": "4407500"
  },
  {
    "text": "allows you-- no\nlinear transform that allows you to represent an image\nwith very few coefficients.",
    "start": "4407500",
    "end": "4414190"
  },
  {
    "text": "When you do JPEG, it\ndoes frequency transform. But after that, it does\na lot of other things.",
    "start": "4414190",
    "end": "4419860"
  },
  {
    "text": "It says, perceptually,\nthe higher frequencies are not as important, so\nI'm going to represent them",
    "start": "4419860",
    "end": "4425110"
  },
  {
    "text": "with fewer quantization grids. Or certain values are too small. I'm just going to truncate them.",
    "start": "4425110",
    "end": "4430450"
  },
  {
    "text": "So all this operation--\nchanging quantization bands, truncating, or thresholding,\nare all nonlinear operations.",
    "start": "4430450",
    "end": "4437530"
  },
  {
    "text": "They are not linear operations. So it turns out there\nis no transform that allows you to represent an\nimage with fewer coefficients.",
    "start": "4437530",
    "end": "4444949"
  },
  {
    "text": "So in general, this\nscheme doesn't work. But you will continue to see\npeople who come to you and say,",
    "start": "4444950",
    "end": "4451220"
  },
  {
    "text": "you know, I have\nthis magical thing I just heard or compressive\nimage something,",
    "start": "4451220",
    "end": "4457540"
  },
  {
    "text": "and that will just\nsolve a problem. There are certain\nimages, like cartoons,",
    "start": "4457540",
    "end": "4462610"
  },
  {
    "text": "that can be represented\nwith very few samples because they have flat\nregions, sharp boundaries, and fluctuations.",
    "start": "4462610",
    "end": "4468159"
  },
  {
    "text": "But a natural image,\nunfortunately, cannot be transformed\nthat easily. And you can talk\nto Rohit, and he'll",
    "start": "4468160",
    "end": "4473740"
  },
  {
    "text": "tell you all the details of the\ndangers of [? compositions. ?]",
    "start": "4473740",
    "end": "4478900"
  },
  {
    "text": "AUDIENCE: So the single-pixel\ncamera is just a hypothesis but not-- RAMESH RASKAR: Yeah,\nbut at the same time,",
    "start": "4478900",
    "end": "4484550"
  },
  {
    "text": "it was the first one that kind\nof allowed people to visualize",
    "start": "4484550",
    "end": "4489610"
  },
  {
    "text": "or kind of conceptualize\nin their mind what compressive\nsensing might do. ",
    "start": "4489610",
    "end": "4497340"
  },
  {
    "text": "AUDIENCE: This idea is\ncool, but how feasible or how important it is to\nhave a single sensor rather",
    "start": "4497340",
    "end": "4503370"
  },
  {
    "text": "than having wide arrows sensing? So what this is\nachieving is basically allowing you to build a\ncamera with a single sensor.",
    "start": "4503370",
    "end": "4510600"
  },
  {
    "text": "But do we really want it just\nto do compressed sensing?",
    "start": "4510600",
    "end": "4515717"
  },
  {
    "text": "RAMESH RASKAR: From\na scientific point of view, if somebody can build\nthis and show that you can take fewer measurements\nand recover the image,",
    "start": "4515717",
    "end": "4522850"
  },
  {
    "text": "that's a breakthrough. How do you use it? I agree with you that, in terms\nof practical implementation,",
    "start": "4522850",
    "end": "4529250"
  },
  {
    "text": "maybe this is the best\napplication, maybe it's not, and so on. But that's kind of\na business reason.",
    "start": "4529250",
    "end": "4536980"
  },
  {
    "text": "AUDIENCE: Will this be faster\nthan an array of sensors?",
    "start": "4536980",
    "end": "4542440"
  },
  {
    "text": "RAMESH RASKAR: Again, in terms\nof in practice, both of you are right. There are very few benefits.",
    "start": "4542440",
    "end": "4548077"
  },
  {
    "text": " But if you just do\ncompressive sensing,",
    "start": "4548077",
    "end": "4554530"
  },
  {
    "text": "you realize it's a\nvery, very active field. AUDIENCE: So again, maybe a\ndifferent type of sensing,",
    "start": "4554530",
    "end": "4563409"
  },
  {
    "text": "but what are the features-- like, what are the people doing\nin computational photography",
    "start": "4563410",
    "end": "4570590"
  },
  {
    "text": "for feature extraction\nin the same way that the brain processes\ncertain features of linear [INAUDIBLE] to do a\nbetter compress sensing",
    "start": "4570590",
    "end": "4581750"
  },
  {
    "text": "of context and imaging? RAMESH RASKAR: You mean\ncompressing an image or sensing with fewer samples?",
    "start": "4581750",
    "end": "4587568"
  },
  {
    "text": "AUDIENCE: Sensing\nwith fewer samples. RAMESH RASKAR: Yeah, so that\nall kind of gets clubbed into this concept of\ncompressive sensing.",
    "start": "4587568",
    "end": "4593098"
  },
  {
    "text": " If you think about a B1 and\nB2 and visual processing,",
    "start": "4593098",
    "end": "4599665"
  },
  {
    "text": "there's a lot of work that\nhas been done over the last 30 years. There's good work\nat CSAIL as well.",
    "start": "4599665",
    "end": "4605580"
  },
  {
    "text": "But that's purely software. AUDIENCE: Right. RAMESH RASKAR: And\nmaybe you're asking, can we use sensing mechanisms\nthat are similar to our brain",
    "start": "4605580",
    "end": "4614670"
  },
  {
    "text": "so that we don't-- AUDIENCE: You don't\nto do any software. RAMESH RASKAR: Exactly. The secret of success for\nfilm, of film photography,",
    "start": "4614670",
    "end": "4622500"
  },
  {
    "text": "is that if somebody\nhad given you this problem before\nthe invention of film,",
    "start": "4622500",
    "end": "4628800"
  },
  {
    "text": "that there is a scene-- and I want to give you a\nsensation of the same scene--",
    "start": "4628800",
    "end": "4635070"
  },
  {
    "text": "time shifted or space shifted. There's so many ways you\ncan solve that problem.",
    "start": "4635070",
    "end": "4640650"
  },
  {
    "text": "You can start with a\nreproduction of a photo, or you can tap into retina.",
    "start": "4640650",
    "end": "4647220"
  },
  {
    "text": "You can tap into V1, V2. You can interface that at\nany point in the pipeline for human vision.",
    "start": "4647220",
    "end": "4655080"
  },
  {
    "text": "But the simplest solution\nis to just create that photo on a passive\nsurface and let the brain do",
    "start": "4655080",
    "end": "4664590"
  },
  {
    "text": "that processing all over again. And so it's like a\nsimple impedance match. If I can see the scene\nand understand it,",
    "start": "4664590",
    "end": "4671040"
  },
  {
    "text": "I can just present that as\nis and let it go through. And this is how we have\nbeen treating photography",
    "start": "4671040",
    "end": "4676860"
  },
  {
    "text": "all this time. It's a record of visual\nexperience, which is great for humans, but it's\nnot so great for computers",
    "start": "4676860",
    "end": "4684052"
  },
  {
    "text": "because computers don't\nunderstand any of that. And what you're saying is,\nwhat computers care about are all these\nhigh-level features.",
    "start": "4684052",
    "end": "4690952"
  },
  {
    "text": "And that's why we're going\nback to the drawing board and saying, let's build\ncameras that are not mimicking human eye but actually\nextracting more information,",
    "start": "4690953",
    "end": "4698280"
  },
  {
    "text": "like [? apertures ?] that\nwe remove the flash camera, or additional information\nwith light-field cameras",
    "start": "4698280",
    "end": "4704280"
  },
  {
    "text": "or multi-spectral\ncameras and so on. ",
    "start": "4704280",
    "end": "4709690"
  },
  {
    "text": "AUDIENCE: So what kind\nof-- so Brett was asking, why would you want to\ndo [? precisely? ?] When do you have to reduce\nthe number of measurements",
    "start": "4709690",
    "end": "4716320"
  },
  {
    "text": "[INAUDIBLE]? And I think one of the\nproblem [INAUDIBLE]..",
    "start": "4716320",
    "end": "4721630"
  },
  {
    "text": "I don't know. The debate about whether\nit's really better or not is photography? [INAUDIBLE]",
    "start": "4721630",
    "end": "4726700"
  },
  {
    "text": "RAMESH RASKAR: Tomography, yeah. AUDIENCE: Yeah, when you\nhave to recover the sky, you want to take as few\nmeasurements as possible.",
    "start": "4726700",
    "end": "4732289"
  },
  {
    "text": "So if you can reduce\nthat [INAUDIBLE],, That's one of the\n[? implications ?] of that. RAMESH RASKAR: Right. AUDIENCE: This one\npiece of camera--",
    "start": "4732290",
    "end": "4738280"
  },
  {
    "text": "really, it does that. RAMESH RASKAR: But the\nbenefit of tomography, which we studied in the\nlast couple of lectures,",
    "start": "4738280",
    "end": "4744670"
  },
  {
    "text": "is it's a very\nhigh-dimensional signal. And so usually, in a\nhigh-dimensional signal, there's lower sparsity.",
    "start": "4744670",
    "end": "4750539"
  },
  {
    "text": "There are only a few places. If you think about taking\na CAT scan of your body, there are only like four\nor five types of materials.",
    "start": "4750540",
    "end": "4757240"
  },
  {
    "text": "There is muscle. There is blood. Whatever. There are only\nfive or six things.",
    "start": "4757240",
    "end": "4763389"
  },
  {
    "text": "It's like a cartoon. AUDIENCE: Exactly. I find this is interesting\nbecause the test-- RAMESH RASKAR:\nIt's a 3D cartoon.",
    "start": "4763390",
    "end": "4769150"
  },
  {
    "text": "AUDIENCE: But if you look at\nit, it looks just like a cartoon does-- some whites clothes,\nsome black clothes, some-- RAMESH RASKAR: Exactly.",
    "start": "4769150",
    "end": "4775030"
  },
  {
    "text": "And that's why compressive\nsensing works very well there.  AUDIENCE: So is compressive\nsomething used in anything",
    "start": "4775030",
    "end": "4782070"
  },
  {
    "text": "commercially currently? RAMESH RASKAR: A lot of\npeople are getting grants. AUDIENCE: Oh. [LAUGHTER]",
    "start": "4782070",
    "end": "4788219"
  },
  {
    "text": "RAMESH RASKAR: Is that a\ncommercial-enough reason? AUDIENCE: No. But also-- RAMESH RASKAR: If you\nput those two words,",
    "start": "4788220",
    "end": "4795330"
  },
  {
    "text": "your chances improve by 50%. AUDIENCE: I was thinking of\nthis interesting album that, I guess, extends to all\nyou guys are talking about.",
    "start": "4795330",
    "end": "4801685"
  },
  {
    "text": "So compressive sensing allows\nyou to take less measurements. But the problem is you need to\nactually have more information",
    "start": "4801685",
    "end": "4807540"
  },
  {
    "text": "about the scene before you\ntake the measurement, which is another measurement. RAMESH RASKAR: So\nactually, to clarify,",
    "start": "4807540",
    "end": "4813000"
  },
  {
    "text": "the measurements are done\nin a non-adaptive manner. So you don't have to know\nanything about the scene",
    "start": "4813000",
    "end": "4818220"
  },
  {
    "text": "to do this measurements. That's actually one power of-- AUDIENCE: I mean, if you\nwant it to actually succeed-- RAMESH RASKAR: But\nwhen you reconstruct,",
    "start": "4818220",
    "end": "4824550"
  },
  {
    "text": "you have to know\nsomething about the scene. You have to know in which\ntransform basis is actually sparse. So is it sparse when you\ntake a Fourier transform?",
    "start": "4824550",
    "end": "4831809"
  },
  {
    "text": "Is it sparse when you take\na [INAUDIBLE] transform? Is it sparse when\nyou take gradients? Like in terms of cartoons,\nit's just gradients.",
    "start": "4831810",
    "end": "4837930"
  },
  {
    "text": "So you have to know that\nwhen you do reconstruction. But advantages are, at\nthe time of capture,",
    "start": "4837930",
    "end": "4843240"
  },
  {
    "text": "I just use this random\nbasis or Fourier basis-- I mean, kind of a modified\n[INAUDIBLE] basis.",
    "start": "4843240",
    "end": "4848430"
  },
  {
    "text": "I can just go ahead\nand spec sample it. And in software\nand reconstruction, I don't worry about some prior\ninformation about the scene,",
    "start": "4848430",
    "end": "4855300"
  },
  {
    "text": "which is great. AUDIENCE: Well, I think in\nthe case where you're just taking a set style of captures,\nthat you're limiting yourself",
    "start": "4855300",
    "end": "4866429"
  },
  {
    "text": "in what kind of scenes will be\ncompatible with that capture. So for example, if I just\nhad a scene that's all white,",
    "start": "4866430",
    "end": "4872490"
  },
  {
    "text": "then just one captured\nwould be enough. RAMESH RASKAR: Yeah,\nbut that's because you know something about the scene. AUDIENCE: Exactly. Exactly. So--",
    "start": "4872490",
    "end": "4878010"
  },
  {
    "text": "RAMESH RASKAR: But if you\nhave this situation where you don't know anything\nabout the scene, you'll just use the same\nexact procedure, for example.",
    "start": "4878010",
    "end": "4885630"
  },
  {
    "text": "AUDIENCE: Right,\nbut you don't, then you lose the benefit of\ntaking less pictures. RAMESH RASKAR: No,\nthe claim is that even",
    "start": "4885630",
    "end": "4891900"
  },
  {
    "text": "if you don't know\nanything about the scene, you take very few measurements. All you know about the\nscene is that once you",
    "start": "4891900",
    "end": "4898020"
  },
  {
    "text": "take its transform, some\ntransform, it's very sparse. It can be represented\nin a complex place.",
    "start": "4898020",
    "end": "4904253"
  },
  {
    "text": "AUDIENCE: So I\nremember, actually, a mathematical mapping\nfor this, where we're reducing dynamically\nthe number of captures",
    "start": "4904253",
    "end": "4911250"
  },
  {
    "text": "you have to take while\nyou're capturing it. RAMESH RASKAR: But that's\nadaptive measure-- adaptive measure. AUDIENCE: Yes. RAMESH RASKAR: Because once\nyou take a picture, you say,",
    "start": "4911250",
    "end": "4916620"
  },
  {
    "text": "let me see what I\ndid not capture. So let me take\nthe next one next. That's a very different problem.",
    "start": "4916620",
    "end": "4922460"
  },
  {
    "text": "AUDIENCE: Yeah. Well, anyways, the code for\nit's inside the dual photography thing. RAMESH RASKAR: Yeah,\nsomebody did dual photography",
    "start": "4922460",
    "end": "4928170"
  },
  {
    "text": "with compressive sensing. AUDIENCE: And it's adaptive. RAMESH RASKAR: And it works\nvery well because, again, it's a high-dimensional signal,\n2D camera, 2D projector.",
    "start": "4928170",
    "end": "4933817"
  },
  {
    "text": "It's four dimensional, but\nwhat you're trying to recover is two dimensional. So it works again. So tomography is the same.",
    "start": "4933817",
    "end": "4939763"
  },
  {
    "text": "It's 4D capture for\n3D representation. OK, so I'm sorry we're\nnot taking a break.",
    "start": "4939763",
    "end": "4947969"
  },
  {
    "text": "Should we take a\n30-second break before we move on to two very\nsmall topics, which",
    "start": "4947970",
    "end": "4954630"
  },
  {
    "text": "is how to write a paper and\nwishlist for photography.",
    "start": "4954630",
    "end": "4959690"
  }
]
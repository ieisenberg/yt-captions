[
  {
    "text": "[AUDIO LOGO]  [MOUSE CLICK]",
    "start": "0",
    "end": "10900"
  },
  {
    "text": "STEVEN JOHNSON: OK,\nso let's get started. So as I said, I'm going to\ndo second derivatives, which",
    "start": "10900",
    "end": "17890"
  },
  {
    "text": "is just going to be the\nderivative of the derivative. When you have\nfunctions from matrices",
    "start": "17890",
    "end": "27259"
  },
  {
    "text": "to matrices or\nsomething like that, you have to think a\nlittle bit carefully just to make sure we understand\nwhat kind of thing",
    "start": "27260",
    "end": "34080"
  },
  {
    "text": "the second derivative is. So remember when we take\nbasically the first derivative,",
    "start": "34080",
    "end": "42190"
  },
  {
    "text": "what we have is this\nlinear operator,",
    "start": "42190",
    "end": "50019"
  },
  {
    "text": "f primed of x, that\ntakes in a little change",
    "start": "50020",
    "end": "58160"
  },
  {
    "text": "and gives us a df, which\nis the f of x plus dx",
    "start": "58160",
    "end": "65630"
  },
  {
    "text": "minus f of x to first order,\ndropping higher-order terms.",
    "start": "65630",
    "end": "72329"
  },
  {
    "text": "And so it's really natural to\ndefine the second derivative",
    "start": "72330",
    "end": "83580"
  },
  {
    "text": "as the derivative of that. So what should f\ndouble prime be?",
    "start": "83580",
    "end": "92640"
  },
  {
    "text": " f double primed of\nx should take in--",
    "start": "92640",
    "end": "105940"
  },
  {
    "text": "let me call it dx prime. I mean, that's not a derivative. It just means a different--",
    "start": "105940",
    "end": "113060"
  },
  {
    "text": "we put it in here in red. This is going to be a\ndifferent small change.",
    "start": "113060",
    "end": "121055"
  },
  {
    "text": " So prime here is not\nderivative, it's just different.",
    "start": "121055",
    "end": "126393"
  },
  {
    "text": "We call it tilde or\nsomething like that. But we overload the prime\na lot in mathematics.",
    "start": "126393",
    "end": "132500"
  },
  {
    "text": "So what should it be? Well, it should\nbe the derivative. I mean, it should be\nexactly the same thing.",
    "start": "132500",
    "end": "138209"
  },
  {
    "text": "It should be df primed. So it should be f primed\nof x plus dx primed minus f",
    "start": "138210",
    "end": "154360"
  },
  {
    "text": "prime of x.  So it should look\nexactly the same.",
    "start": "154360",
    "end": "161910"
  },
  {
    "text": "But now let's think\nabout what this means. So this f prime here is\nnot a number anymore.",
    "start": "161910",
    "end": "169000"
  },
  {
    "text": "It could be a number,\nbut in general, it's a linear operator. So this here is the difference\nof two linear operators.",
    "start": "169000",
    "end": "179100"
  },
  {
    "start": "179100",
    "end": "189380"
  },
  {
    "text": "And what does it mean to add and\nsubtract and take differences",
    "start": "189380",
    "end": "194540"
  },
  {
    "text": "of linear operators? And we did a little bit\nof this in problem set 1. You can think of linear\noperators themselves",
    "start": "194540",
    "end": "200959"
  },
  {
    "text": "as a vector space. Just like we can take\nfunctions, sine x plus cosine x",
    "start": "200960",
    "end": "207620"
  },
  {
    "text": "is another function. So we can think of linear\noperators as a vector space",
    "start": "207620",
    "end": "213650"
  },
  {
    "text": "as well. So if we have linear operators-- ",
    "start": "213650",
    "end": "227390"
  },
  {
    "text": "operators L1 and L2, then what\nwe mean by their addition, L1",
    "start": "227390",
    "end": "236680"
  },
  {
    "text": "plus L2, or plus or minus,\nis the linear operator",
    "start": "236680",
    "end": "245280"
  },
  {
    "text": "that takes a vector v and\ngives you L1 of V plus L2 of V.",
    "start": "245280",
    "end": "256519"
  },
  {
    "text": "And the same thing if you\nmultiply a linear operator by a scalar, that's\nthe linear operator",
    "start": "256519",
    "end": "264800"
  },
  {
    "text": "that sends a vector V\nto alpha times L1 of V.",
    "start": "264800",
    "end": "273680"
  },
  {
    "text": "And this should be familiar. So if I take two\nmatrices and I add them, you'd actually know\nwhat that means.",
    "start": "273680",
    "end": "279380"
  },
  {
    "text": "You say, oh, that means you add\nthe elements up element-wise. But where does that\nrule come from?",
    "start": "279380",
    "end": "285260"
  },
  {
    "text": "That adding up two\nmatrices element-wise is exactly the new matrix\nthat, acting on a vector,",
    "start": "285260",
    "end": "291469"
  },
  {
    "text": "gives you the first\nmatrix times the vector plus the second matrix\ntimes the vector. If I take a matrix\nand multiply it by 3,",
    "start": "291470",
    "end": "298495"
  },
  {
    "text": "you can say, oh, you multiply\nall the entries by 3. But why? It's because if I take--\nthat's the linear operator that",
    "start": "298495",
    "end": "305580"
  },
  {
    "text": "takes a vector, it's\nequivalent to multiplying it by that original matrix and\nthen multiplying it by 3.",
    "start": "305580",
    "end": "311307"
  },
  {
    "text": "So that's where those\nrules come from, just like the rule for\nmultiplying two matrices-- oh, rows times columns.",
    "start": "311308",
    "end": "317750"
  },
  {
    "text": "Why? Because that's the\nnew linear operator that's equivalent to\nmultiplying the first matrix",
    "start": "317750",
    "end": "323630"
  },
  {
    "text": "by the right matrix and\nthen by the left matrix. That's where these\nrules come from. So this thing here is now--",
    "start": "323630",
    "end": "332130"
  },
  {
    "text": "so what we really mean by this\nis this is a linear operator,",
    "start": "332130",
    "end": "340730"
  },
  {
    "text": "so that this is the difference\nof two linear operators.",
    "start": "340730",
    "end": "352650"
  },
  {
    "text": "These are linear operators\nthat take in a dx and give you something\nelse, give you a df.",
    "start": "352650",
    "end": "359190"
  },
  {
    "text": "So the difference\nof these two things is a linear operator\nthat takes in a dx-- not a dx prime, a dx--",
    "start": "359190",
    "end": "364889"
  },
  {
    "text": "and gives you something else. So this is a linear\noperator that takes in--",
    "start": "364890",
    "end": "372610"
  },
  {
    "text": "we can call it f\ndouble prime of x.",
    "start": "372610",
    "end": "379500"
  },
  {
    "text": "It takes in a dx primed\nthat takes in another input.",
    "start": "379500",
    "end": "389300"
  },
  {
    "text": "We can take it, write it\nas it takes in an input dx. ",
    "start": "389300",
    "end": "395960"
  },
  {
    "text": "And what it gives you is f\nprimed of x plus dx primed,",
    "start": "395960",
    "end": "406190"
  },
  {
    "text": "acting on dx, minus f\nprime of x acting on dx.",
    "start": "406190",
    "end": "420230"
  },
  {
    "start": "420230",
    "end": "426260"
  },
  {
    "text": "Does everyone see? So this f double\nprime is going to be--",
    "start": "426260",
    "end": "431410"
  },
  {
    "text": "it's just copying down the\nformula for the derivative, except applying it to f prime.",
    "start": "431410",
    "end": "436720"
  },
  {
    "text": "But then-- so this is\nthe linear operator you get when you take the\noriginal linear operator",
    "start": "436720",
    "end": "443560"
  },
  {
    "text": "at a slightly shifted\nx minus f prime of x. So this is a linear\noperator that acts on a dx.",
    "start": "443560",
    "end": "451060"
  },
  {
    "text": "And what it is, it's\njust the linear operator that takes this on\ndx minus this on dx.",
    "start": "451060",
    "end": "456370"
  },
  {
    "text": "But then if you think\nabout this object, now, this object now\ntakes two inputs.",
    "start": "456370",
    "end": "462210"
  },
  {
    "text": "It takes the change x where dx\nprime is the change in where",
    "start": "462210",
    "end": "469500"
  },
  {
    "text": "you're taking the derivative. And then the second\none, dx, is the change",
    "start": "469500",
    "end": "476970"
  },
  {
    "text": "in x that you're acting the\nderivative, f primed, on. So this is called\na bilinear form.",
    "start": "476970",
    "end": "483410"
  },
  {
    "start": "483410",
    "end": "491090"
  },
  {
    "text": "So we have-- we're\ngoing to have f double primed that's taking\nof x that takes",
    "start": "491090",
    "end": "498770"
  },
  {
    "text": "two inputs, dx prime, and dx.",
    "start": "498770",
    "end": "506620"
  },
  {
    "text": " But writing those\ntwo pairs of brackets is a little bit annoying.",
    "start": "506620",
    "end": "512309"
  },
  {
    "text": "So let me just write\none pair of brackets and just give it two arguments. ",
    "start": "512309",
    "end": "523020"
  },
  {
    "text": "And so it acts on two vectors. ",
    "start": "523020",
    "end": "531010"
  },
  {
    "text": "And it's linear in both.  So in general, a bilinear form--",
    "start": "531010",
    "end": "538230"
  },
  {
    "text": " and I said let me just\nremind you of linearity.",
    "start": "538230",
    "end": "545390"
  },
  {
    "text": "You have a bilinear form, call\nit B, takes in a vector u,",
    "start": "545390",
    "end": "553800"
  },
  {
    "text": "and it takes in a\nvector v. And linearity",
    "start": "553800",
    "end": "560490"
  },
  {
    "text": "means if you take B of\nu1 plus u2, comma v, that",
    "start": "560490",
    "end": "568430"
  },
  {
    "text": "had better equal B of\nu1, v plus B of u2, v.",
    "start": "568430",
    "end": "576460"
  },
  {
    "text": "But it also has to be linear\nin the second argument. B of u, v1 plus v2 has\nto equal B of u, v1",
    "start": "576460",
    "end": "587320"
  },
  {
    "text": "plus B of u v2, et cetera.",
    "start": "587320",
    "end": "593270"
  },
  {
    "text": "You can also scale the--\nmultiply one of the arguments by 2, and so forth. If I multiply both of the\narguments by 2, if I do B of,",
    "start": "593270",
    "end": "603959"
  },
  {
    "text": "like, 2u times 3v, that had\nbetter be 2 times 3 B of u,",
    "start": "603960",
    "end": "613755"
  },
  {
    "text": "v. So if I multiply\nboth arguments by 2, it doesn't multiply\nthe output by 2. It multiplies it by 4.",
    "start": "613755",
    "end": "619005"
  },
  {
    "start": "619005",
    "end": "624140"
  },
  {
    "text": "So that's what this\nsecond derivative is. It takes in a change-- two changes, a change\nin where you're",
    "start": "624140",
    "end": "629982"
  },
  {
    "text": "taking the derivative\nand a change in the thing that you're taking\nthe derivative on. And you might wonder if it\nmatters, like the order-- oops,",
    "start": "629982",
    "end": "637820"
  },
  {
    "text": "and this should not\nhave been a prime. If it matters, does the order\nof these two things matter?",
    "start": "637820",
    "end": "646410"
  },
  {
    "text": "And in general for bilinear\nforms, the order matters. In general, for\nbilinear forms, B of u,",
    "start": "646410",
    "end": "661959"
  },
  {
    "text": "v is not equal to B of v, u.",
    "start": "661960",
    "end": "670410"
  },
  {
    "text": "And, in fact, it may\nnot even make sense to swap the arguments. You can have a\nbilinear form where u lives in one vector space,\nand v lives in a completely",
    "start": "670410",
    "end": "677700"
  },
  {
    "text": "different vector space. So u is a scalar, and\nv is a column vector, and it doesn't even--\nyou can't even swap them.",
    "start": "677700",
    "end": "685690"
  },
  {
    "text": "So I said this may\nnot even make sense.",
    "start": "685690",
    "end": "693080"
  },
  {
    "text": "But here, dx and dx\nprime, they clearly live in the same vector space.",
    "start": "693080",
    "end": "698120"
  },
  {
    "text": "They both changes to x. And so you could swap them\nand ask, what's the change?",
    "start": "698120",
    "end": "704510"
  },
  {
    "text": "And, in fact-- but here, it\nturns out they are the same. So here, it turns out that f\ndouble prime of dx primed--",
    "start": "704510",
    "end": "724210"
  },
  {
    "text": "I'm making my\ncolor scheme right. I was using black, right? f double prime of x--\nthere's the point at which",
    "start": "724210",
    "end": "732070"
  },
  {
    "text": "you're evaluating the\nsecond derivative-- of dx primed comma\ndx always, in fact,",
    "start": "732070",
    "end": "741529"
  },
  {
    "text": "equals f double primed\nof x dx comma dx primed.",
    "start": "741530",
    "end": "752970"
  },
  {
    "text": "And so this is what's\ncalled a symmetric. ",
    "start": "752970",
    "end": "766110"
  },
  {
    "text": "And we can show it pretty\neasily just from the definition. So in fact, as I'll\nshow in a minute,",
    "start": "766110",
    "end": "774535"
  },
  {
    "text": "this is actually-- you've seen\nthis kind of thing before, and you didn't realize it. So you learned in 1802,\npoints of variable calculus,",
    "start": "774535",
    "end": "781080"
  },
  {
    "text": "that when I take a partial\nderivative, like partial f, partial x, partial y, like\ntwo n's, I can swap them,",
    "start": "781080",
    "end": "787200"
  },
  {
    "text": "and it doesn't matter. It turns out that is going\nto be a special case of this.",
    "start": "787200",
    "end": "794130"
  },
  {
    "text": "So let me show it in general\njust from the definition. So why is this? ",
    "start": "794130",
    "end": "802750"
  },
  {
    "text": "So why symmetric?  And so we just need to write\nout the definition a little bit.",
    "start": "802750",
    "end": "809850"
  },
  {
    "text": "So just write out-- so f double\nprimed of x of dx primed dx--",
    "start": "809850",
    "end": "817388"
  },
  {
    "text": "I'm not going to use\ncolors here because it gets too annoying to\nswap pens back and forth.",
    "start": "817388",
    "end": "822960"
  },
  {
    "text": "OK, so there's two terms here. So there's a term that\ncomes from f prime",
    "start": "822960",
    "end": "831630"
  },
  {
    "text": "of x plus dx primed acting\non dx minus f of x f",
    "start": "831630",
    "end": "843650"
  },
  {
    "text": "primed of x acting on dx. That's just the\ndefinition I did before. ",
    "start": "843650",
    "end": "850819"
  },
  {
    "text": "f double primed is the\ndifference of these two linear operators. So acting on dx\nis the difference",
    "start": "850820",
    "end": "856580"
  },
  {
    "text": "of what they do on the dx. But now let's take\nit one step further. I want you to expand out.",
    "start": "856580",
    "end": "861822"
  },
  {
    "text": "What's the definition\nof f prime? Let's go back to that. f primed of-- f primed, and\nlet's do the second one.",
    "start": "861822",
    "end": "869037"
  },
  {
    "text": "That's easier. ",
    "start": "869037",
    "end": "874470"
  },
  {
    "text": "So the second term-- what's f primed of x dx? We said in the\nvery first lecture,",
    "start": "874470",
    "end": "882230"
  },
  {
    "text": "that's the same thing as f\nof x plus dx minus f of x.",
    "start": "882230",
    "end": "887930"
  },
  {
    "text": "That's what that is. So what's f primed of\nx plus dx primed dx?",
    "start": "887930",
    "end": "896500"
  },
  {
    "text": "It's f of x plus dx primed plus\ndx minus f of x plus dx primed.",
    "start": "896500",
    "end": "907020"
  },
  {
    "text": " Now, let me just regroup\nthese terms a little bit.",
    "start": "907020",
    "end": "912400"
  },
  {
    "text": "So I have one term\nthat looks like f of x plus dx primed plus dx.",
    "start": "912400",
    "end": "918430"
  },
  {
    "text": " And I have another term that\nlooks like just a plus f of x.",
    "start": "918430",
    "end": "926510"
  },
  {
    "text": "That's not very interesting. And then I have another term\nthat looks like f of x plus dx",
    "start": "926510",
    "end": "934340"
  },
  {
    "text": "with a minus sign. And I have another\nterm that looks like f of x plus dx primed.",
    "start": "934340",
    "end": "940570"
  },
  {
    "text": " But now, if you stare\nat this clearly,",
    "start": "940570",
    "end": "950410"
  },
  {
    "text": "a vector addition\nis commutative. I can swap those. I can swap these two terms.",
    "start": "950410",
    "end": "960380"
  },
  {
    "text": "I can swap the\naddition and the input. I can also swap the\naddition of the output.",
    "start": "960380",
    "end": "965510"
  },
  {
    "text": "I can just rearrange\nthese two terms. And so this whole\nthing is exactly what--",
    "start": "965510",
    "end": "972050"
  },
  {
    "text": "the same as what you would\nget as if I took f double primed of x and evaluated it,\nand I swapped the outputs.",
    "start": "972050",
    "end": "979310"
  },
  {
    "start": "979310",
    "end": "986750"
  },
  {
    "text": "So it's just writing\nout the definition. This does not look symmetric\nbecause here, the dx",
    "start": "986750",
    "end": "991930"
  },
  {
    "text": "prime is in the argument, and\ndx is what f is acting on. But when you write out the\ndefinition of the derivative,",
    "start": "991930",
    "end": "998089"
  },
  {
    "text": "then you see that both dx and\ndx prime appear in the same way. ",
    "start": "998090",
    "end": "1003899"
  },
  {
    "text": "So let's do-- so the 1801\nexample is very easy.",
    "start": "1003900",
    "end": "1013215"
  },
  {
    "text": "The first derivative\nis a number, and the second derivative\nis also a number. That's kind of boring. So it's the familiar-- this is\na strict generalization of what",
    "start": "1013215",
    "end": "1020998"
  },
  {
    "text": "you learned before. It's nothing new. But let's do an 1802,\nmultivariable calculus.",
    "start": "1020998",
    "end": "1027089"
  },
  {
    "text": " So suppose we have a\nscalar function f of x.",
    "start": "1027090",
    "end": "1037949"
  },
  {
    "start": "1037949",
    "end": "1044359"
  },
  {
    "text": "All right, so the\noutput is a scalar.  But the input is going to be--",
    "start": "1044359",
    "end": "1054190"
  },
  {
    "text": "this is going to be in R n. So this is an n\ncomponent vector. ",
    "start": "1054190",
    "end": "1061920"
  },
  {
    "text": "Now, you can think of it as\na column vector if you want. ",
    "start": "1061920",
    "end": "1071940"
  },
  {
    "text": "So then what do we know? So we know that f primed\nof x is a row vector.",
    "start": "1071940",
    "end": "1080190"
  },
  {
    "text": "It's the transpose\nof the gradient.  So that way, f prime of\nx times dx is a scalar.",
    "start": "1080190",
    "end": "1092920"
  },
  {
    "text": "That's the only way to get-- that's the only linear\noperator that takes a vector in and scalar out.",
    "start": "1092920",
    "end": "1098720"
  },
  {
    "text": "So now let's think about what\nis our second derivative,",
    "start": "1098720",
    "end": "1107440"
  },
  {
    "text": "our f primed of x. It has to take in two\nvectors, dx prime and dx.",
    "start": "1107440",
    "end": "1114370"
  },
  {
    "text": "Now, it doesn't really matter\nin which order I put the prime. ",
    "start": "1114370",
    "end": "1120050"
  },
  {
    "text": "But it has to give a scalar. ",
    "start": "1120050",
    "end": "1125280"
  },
  {
    "text": "In the end, the\noutput has to match.",
    "start": "1125280",
    "end": "1130350"
  },
  {
    "text": "If you plug in both these\nthings, it matches f. You can't just go\nback to the definition",
    "start": "1130350",
    "end": "1137400"
  },
  {
    "text": "that f primed takes in\na vector and gives you",
    "start": "1137400",
    "end": "1143700"
  },
  {
    "text": "the same output as f\nbecause it gives you the df. So f double primed, when\nyou plug in both vectors,",
    "start": "1143700",
    "end": "1152160"
  },
  {
    "text": "or dx prime and dx, it has\nto give the same output as f",
    "start": "1152160",
    "end": "1157680"
  },
  {
    "text": "plug in of dx. So it has to give something\nthe same shape as f. So this takes in two vectors\nand gives you a scalar.",
    "start": "1157680",
    "end": "1167290"
  },
  {
    "text": " And it turns out there's only\none kind of way to write down",
    "start": "1167290",
    "end": "1177290"
  },
  {
    "text": "an operation that takes\nin two column vectors and outputs a scalar and is\nlinear in both of the vectors.",
    "start": "1177290",
    "end": "1184370"
  },
  {
    "text": "And that is to put the\nmatrix here and put a dx here",
    "start": "1184370",
    "end": "1194150"
  },
  {
    "text": "and a dx plug in\ntransposed over there.",
    "start": "1194150",
    "end": "1199640"
  },
  {
    "text": "And it has to be symmetric. ",
    "start": "1199640",
    "end": "1205310"
  },
  {
    "text": "We know it has to be\nthe same thing if you swap the dx and dx prime.",
    "start": "1205310",
    "end": "1212015"
  },
  {
    "text": " But that means, actually, it\nhas to be a symmetric matrix",
    "start": "1212015",
    "end": "1219760"
  },
  {
    "text": "because this is also a number. So it equals the\ntranspose of itself.",
    "start": "1219760",
    "end": "1225130"
  },
  {
    "start": "1225130",
    "end": "1230300"
  },
  {
    "text": "This is true for any number. You can always equal\nthe transpose itself. So that equals dx transpose\nh transpose dx primed.",
    "start": "1230300",
    "end": "1241050"
  },
  {
    "text": "So these two have to be equal. So you have a symmetric\nn by n matrix H, which",
    "start": "1241050",
    "end": "1258810"
  },
  {
    "text": "is called the Hessian matrix. ",
    "start": "1258810",
    "end": "1265059"
  },
  {
    "text": "How many of you have heard\nof Hessian matrices before? Yeah, it's a fair number of you.",
    "start": "1265060",
    "end": "1270070"
  },
  {
    "text": "So yeah, so that's what\na bilinear form looks like acting on column vectors.",
    "start": "1270070",
    "end": "1275140"
  },
  {
    "text": "It's a matrix.  But it's nice to write it in\n1802 terms more explicitly,",
    "start": "1275140",
    "end": "1286440"
  },
  {
    "text": "like component-wise,\njust like the gradient you need to know when\nyou first learn it. So it's partial f partial\nx1, partial f partial x2,",
    "start": "1286440",
    "end": "1294090"
  },
  {
    "text": "and so forth. H is going to be the same\nthing, so same kind of thing.",
    "start": "1294090",
    "end": "1299700"
  },
  {
    "text": "So now if we do it explicitly,\nlet's just write out slowly.",
    "start": "1299700",
    "end": "1312389"
  },
  {
    "text": "So we know that\nthe gradient of f is the vector that has\npartial f partial x1",
    "start": "1312390",
    "end": "1319695"
  },
  {
    "text": "to partial f partial xn. ",
    "start": "1319695",
    "end": "1326340"
  },
  {
    "text": "So that means what\nwe want to take is the change, d, of gradient\nf, say transposed, I guess.",
    "start": "1326340",
    "end": "1345750"
  },
  {
    "text": "Yeah. So what's d of\nthis, for example?",
    "start": "1345750",
    "end": "1359320"
  },
  {
    "text": "So well, it's the same thing as\nd of partial f partial x1 to d",
    "start": "1359320",
    "end": "1372360"
  },
  {
    "text": "of partial f partial xn. ",
    "start": "1372360",
    "end": "1378540"
  },
  {
    "text": "But partial f partial\nx1 is a scalar function",
    "start": "1378540",
    "end": "1384060"
  },
  {
    "text": "of x, of all the-- it depends on all\nthe components in x. And it spits out a number,\nwhich is partial f, partial x1.",
    "start": "1384060",
    "end": "1389870"
  },
  {
    "text": "So we know what the\nd of that looks like. The d of that is a gradient of\npartial f partial x1 transpose",
    "start": "1389870",
    "end": "1403570"
  },
  {
    "text": "dx. Say all the way to gradient of\npartial f partial xn transpose",
    "start": "1403570",
    "end": "1411660"
  },
  {
    "text": "dx.  So we can write that out as--",
    "start": "1411660",
    "end": "1418280"
  },
  {
    "text": "we can pull out the\ndx column vector. And that's gradient of\npartial f partial x1 transpose",
    "start": "1418280",
    "end": "1427100"
  },
  {
    "text": "all the way to gradient of\npartial f partial xn transpose.",
    "start": "1427100",
    "end": "1435710"
  },
  {
    "text": "But that matrix-- and with\nthat, what is the gradient?",
    "start": "1435710",
    "end": "1440770"
  },
  {
    "text": "That's partial f--\nthat's partial squared of f partial x1\npartial x1 to partial f",
    "start": "1440770",
    "end": "1451929"
  },
  {
    "text": "partial x1 partial xn. That's what the gradient\ntranspose looks like. I take partial partial f\nx1 and take its derivative",
    "start": "1451930",
    "end": "1458620"
  },
  {
    "text": "with respect to x1 to xn. So that's a mixed\nsecond derivative.",
    "start": "1458620",
    "end": "1463659"
  },
  {
    "text": "And then in the last\nrow is the same thing, partial squared\npartial f partial xn. And then I take its\nderivative with respect",
    "start": "1463660",
    "end": "1469900"
  },
  {
    "text": "to x1 all the way to its\nderivative with respect to xn.",
    "start": "1469900",
    "end": "1477350"
  },
  {
    "text": "Derivative's xn dx.  And this is a matrix\nof second derivatives.",
    "start": "1477350",
    "end": "1489679"
  },
  {
    "text": "This is exactly going to be-- I guess this was-- ",
    "start": "1489680",
    "end": "1499035"
  },
  {
    "text": "this is, I guess, H,\nor it's equal to-- I guess it's H\ntranspose, because grad",
    "start": "1499035",
    "end": "1505700"
  },
  {
    "text": "f was the transpose\nof the derivative. So this gives you the change. This is the d of\nf prime transpose.",
    "start": "1505700",
    "end": "1515130"
  },
  {
    "text": "So it's H transpose. But we know that that equals\nH. So it doesn't really matter. And so then, we get that the H,\nthe IJ element is just partial",
    "start": "1515130",
    "end": "1527919"
  },
  {
    "text": "squared f partial xi partial xj. But that equals xji\nbecause we know in general",
    "start": "1527920",
    "end": "1536510"
  },
  {
    "text": "that the Hessian is\na symmetric matrix, is a symmetric bilinear\nform, which means this is a symmetric matrix.",
    "start": "1536510",
    "end": "1542970"
  },
  {
    "text": "So that gives you\nthis relationship you learned in\nmultivariable calculus that when I take\npartial derivatives,",
    "start": "1542970",
    "end": "1548570"
  },
  {
    "text": "I can swap the order. I mean, it just comes from the\ndefinition of the derivative. But the point is that\nthat extends to more--",
    "start": "1548570",
    "end": "1555220"
  },
  {
    "text": "when you extend it to\nmore general objects, it turns into this symmetric\nbilinear form business.",
    "start": "1555220",
    "end": "1561519"
  },
  {
    "text": "Any questions? Yeah? AUDIENCE: Just a\nquick clarification-- this should be an n1? Like, this should\nbe reversed, right,",
    "start": "1561520",
    "end": "1568059"
  },
  {
    "text": "just in the matrix itself? STEVEN JOHNSON: Which? The partial derivatives,\nthese should be reversed?",
    "start": "1568060",
    "end": "1573120"
  },
  {
    "text": "AUDIENCE: Yeah, technically. STEVEN JOHNSON: I guess\nit depends on-- yes. It depends on what you mean by-- because we're so\nused to the fact",
    "start": "1573120",
    "end": "1579790"
  },
  {
    "text": "that this-- you can take the\nderivative in either order. So actually, I don't know. Does it mean you\ntake this derivative,",
    "start": "1579790",
    "end": "1585610"
  },
  {
    "text": "then this derivative,\nor the other way around? If I put parentheses\nhere, I think it's right.",
    "start": "1585610",
    "end": "1592548"
  },
  {
    "text": "AUDIENCE: OK. STEVEN JOHNSON:\nYeah, because it's-- but the notation is\nkind of ambiguous",
    "start": "1592548",
    "end": "1598377"
  },
  {
    "text": "because it doesn't\nneed to be explicit because you can swap the order. But yeah. So I think yeah, if I put\nderivative parentheses here,",
    "start": "1598377",
    "end": "1605930"
  },
  {
    "text": "that's the explicit thing. I take partial f partial x1. I take its derivative\nwith respect to x1 all the way to xn.",
    "start": "1605930",
    "end": "1612890"
  },
  {
    "text": "But if you put parentheses\nthere, then it's the opposite. But at the end of\nthe day, it's not going to matter because\nthis is symmetric.",
    "start": "1612890",
    "end": "1621000"
  },
  {
    "text": "AUDIENCE: Yeah. STEVEN JOHNSON: OK, so that's-- how many learned the\nHessian matrix this way?",
    "start": "1621000",
    "end": "1627575"
  },
  {
    "text": "Basically, it's\nthe matrix of all the mixed second derivatives. Yeah. So that's usually how\nit's presented, right? And that's-- yes?",
    "start": "1627575",
    "end": "1633360"
  },
  {
    "text": "AUDIENCE: And just\nconclude that it's the Jacobian of the\ngradient, in a way? STEVEN JOHNSON:\nYeah, it's exactly the Jacobian of the gradient.",
    "start": "1633360",
    "end": "1639360"
  },
  {
    "text": "Yes. Good, good, good. And we write that down. So this is the-- ",
    "start": "1639360",
    "end": "1652460"
  },
  {
    "text": "Yeah, exactly. ",
    "start": "1652460",
    "end": "1659120"
  },
  {
    "text": "Yeah. But now we have it in a\nmuch more general setting. So I think it's nice to do--",
    "start": "1659120",
    "end": "1666140"
  },
  {
    "text": "let's do a more general\nexample, an example that it's not so easy to\ndo with 1801, or 1802 even.",
    "start": "1666140",
    "end": "1680909"
  },
  {
    "text": "Let's take our\nfavorite function, our new favorite function,\nthat takes in a matrix",
    "start": "1680910",
    "end": "1686760"
  },
  {
    "text": "and gives you a scalar. ",
    "start": "1686760",
    "end": "1692100"
  },
  {
    "text": "So from the previous\nlecture, we learned what the derivative of this is.",
    "start": "1692100",
    "end": "1697570"
  },
  {
    "text": "So if you take f\nprimed of A, that's the linear operator\nacting on dA,",
    "start": "1697570",
    "end": "1705280"
  },
  {
    "text": "what it gives you is\ndeterminant A times the trace of A inverse dA.",
    "start": "1705280",
    "end": "1716270"
  },
  {
    "text": "Or equivalent, we showed\nthat the gradient of f was the determinant of A\ntimes the transpose of this,",
    "start": "1716270",
    "end": "1723080"
  },
  {
    "text": "A inverse transpose, which is\ncalled the adjugate matrix. ",
    "start": "1723080",
    "end": "1735210"
  },
  {
    "text": "Yeah, the adjugate\nor the transpose of the adjugate-- sorry,\nthe adjugate transpose.",
    "start": "1735210",
    "end": "1741831"
  },
  {
    "text": "of A. I always forget\nwhich is which. It's the cofactor matrix\nof A. So yes, we saw this,",
    "start": "1741831",
    "end": "1750500"
  },
  {
    "text": "and there's various\nways you can show this. Professor Edelman looked at\na couple of different ways.",
    "start": "1750500",
    "end": "1756230"
  },
  {
    "text": "So now let's go\none step further. And now let's take\nthe second derivative. And whenever we're faced with\nsomething new and confusing,",
    "start": "1756230",
    "end": "1764140"
  },
  {
    "text": "it's always good to fall\nback on the definition. So all we're doing is\njust going to take--",
    "start": "1764140",
    "end": "1771460"
  },
  {
    "text": "we're going to take d of\nthis, d of this whole formula,",
    "start": "1771460",
    "end": "1788059"
  },
  {
    "text": "determinant A\ntrace A inverse dA.",
    "start": "1788060",
    "end": "1794600"
  },
  {
    "text": " I'm going to put\na prime here, just",
    "start": "1794600",
    "end": "1801500"
  },
  {
    "text": "to make it clear that what\nI'm changing is A, not dA. I'm going to use a dA prime. So d primed-- so what this\nis going to be, is this",
    "start": "1801500",
    "end": "1811070"
  },
  {
    "text": "is going to be our f primed of\nA plus dA primed acting on dA.",
    "start": "1811070",
    "end": "1823340"
  },
  {
    "text": "Let me give myself\na little more space. ",
    "start": "1823340",
    "end": "1832270"
  },
  {
    "text": "Minus f prime of A on dA.",
    "start": "1832270",
    "end": "1838470"
  },
  {
    "text": "So the prime here is just--\nit's not another derivative. I'm overloading my\nprimes a little bit.",
    "start": "1838470",
    "end": "1843770"
  },
  {
    "text": "It just means I'm using-- I'm changing A by dA primed.",
    "start": "1843770",
    "end": "1849170"
  },
  {
    "text": "OK, and dA is going to be fixed. Yes? AUDIENCE: In the\nprevious example as well, that was technically dx prime,\nthen, just to clarify that?",
    "start": "1849170",
    "end": "1857570"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. Yeah, well, I didn't\nhave any dx's here. So I didn't need a d prime.",
    "start": "1857570",
    "end": "1863840"
  },
  {
    "text": "AUDIENCE: Right. STEVEN JOHNSON: Yeah, yeah. But I could have used a d\nprime there if I wanted. But it's really the\nsame kind of thing.",
    "start": "1863840",
    "end": "1870090"
  },
  {
    "text": "It's just I already\nhave a dA here. And I want to be careful\nthat I'm not changing this. This is now going to be--",
    "start": "1870090",
    "end": "1876080"
  },
  {
    "text": "this is-- actually, let\nme put this in blue here. This is dA, dA, dA.",
    "start": "1876080",
    "end": "1888570"
  },
  {
    "text": "This is going to be fixed.  So dA is not changing.",
    "start": "1888570",
    "end": "1895780"
  },
  {
    "text": "So we can think of\nit as a constant. So when I change things,\nI'm changing A by dA primed.",
    "start": "1895780",
    "end": "1903190"
  },
  {
    "text": "And so now I can just\nuse our derivative rules,",
    "start": "1903190",
    "end": "1909639"
  },
  {
    "text": "so our product, and our\nchain rules, dot, dot, dot.",
    "start": "1909640",
    "end": "1919830"
  },
  {
    "text": "And what do I get? ",
    "start": "1919830",
    "end": "1925590"
  },
  {
    "text": "So now, I'm just treating\ndA as just a constant matrix I'm sticking in there. And then I'm taking the\nderivative the same way",
    "start": "1925590",
    "end": "1930720"
  },
  {
    "text": "as before. Well, I have the derivative\nof this term times this plus this times the\nderivative of that term.",
    "start": "1930720",
    "end": "1936399"
  },
  {
    "text": "And the derivative of\nthis term, we just-- or the differential,\nsorry, of that term, we just saw what it was.",
    "start": "1936400",
    "end": "1942120"
  },
  {
    "text": "This is our-- it's this.",
    "start": "1942120",
    "end": "1948420"
  },
  {
    "text": "It's this, right? So the first term is\ndeterminant of A times--",
    "start": "1948420",
    "end": "1957440"
  },
  {
    "text": " so the d of the determinant\nis the determinant of A times",
    "start": "1957440",
    "end": "1964000"
  },
  {
    "text": "the trace of A prime-- not A prime, A\ninverse dA primed.",
    "start": "1964000",
    "end": "1973179"
  },
  {
    "text": "All right, so this came from\nthat term times the other term,",
    "start": "1973180",
    "end": "1984180"
  },
  {
    "text": "trace of A inverse\ndA plus I still",
    "start": "1984180",
    "end": "1993850"
  },
  {
    "text": "have my determinant of\nA times the derivative",
    "start": "1993850",
    "end": "1999470"
  },
  {
    "text": "of the other term. ",
    "start": "1999470",
    "end": "2004780"
  },
  {
    "text": "And trace is a linear operator. So I can just take\nthe derivative inside.",
    "start": "2004780",
    "end": "2011510"
  },
  {
    "text": "And so now-- or the\ndifferential inside-- and now I need dA inverse.",
    "start": "2011510",
    "end": "2017140"
  },
  {
    "text": "And we know what dA inverse,\nthat was a minus sign. So let me change this to a\nminus sign of A inverse dA",
    "start": "2017140",
    "end": "2028440"
  },
  {
    "text": "primed, A inverse, and\nthen there's still a dA.",
    "start": "2028440",
    "end": "2034803"
  },
  {
    "text": "Can everyone see that? So this term here is exactly\nd primed of A inverse--",
    "start": "2034803",
    "end": "2045870"
  },
  {
    "text": "well, with the minus sign. ",
    "start": "2045870",
    "end": "2055199"
  },
  {
    "text": "And now the question\nis, is this--",
    "start": "2055199",
    "end": "2061070"
  },
  {
    "text": "this is it. This is-- it's not going to\nget much simpler than this. This is our bilinear form. ",
    "start": "2061070",
    "end": "2069770"
  },
  {
    "text": "This is bilinear.  And in dA primed and dA, so I\nstick in any dA primed, any dA.",
    "start": "2069770",
    "end": "2085030"
  },
  {
    "text": "Clearly, this is linear in\neach one of them individually. I never-- I can\nmultiply dA by dA prime.",
    "start": "2085030",
    "end": "2092319"
  },
  {
    "text": "It's quadratic.  But I can't multiply\na dA by itself.",
    "start": "2092320",
    "end": "2100495"
  },
  {
    "text": " And is it symmetric? Well, let's look.",
    "start": "2100495",
    "end": "2106990"
  },
  {
    "text": "This term is the same as this. So if I swap-- and these are\njust-- trace is just a number.",
    "start": "2106990",
    "end": "2113230"
  },
  {
    "text": "So I can swap these two terms. And that's fine. And this is also a number.",
    "start": "2113230",
    "end": "2119610"
  },
  {
    "text": "What about this? If I swap dA and d primed, it\nlooks a little bit different.",
    "start": "2119610",
    "end": "2125920"
  },
  {
    "text": "But remember, the trace\nhas the cyclic property. I can move the A inverse\ndA over to the beginning,",
    "start": "2125920",
    "end": "2134270"
  },
  {
    "text": "and then it looks like\ntrace of A inverse dA, A inverse dA primed.",
    "start": "2134270",
    "end": "2140590"
  },
  {
    "text": "So this is symmetric using this\ncyclic property of the trace.",
    "start": "2140590",
    "end": "2151690"
  },
  {
    "start": "2151690",
    "end": "2159490"
  },
  {
    "text": "That's it. This doesn't simplify. We can't write it\nas a Hessian matrix",
    "start": "2159490",
    "end": "2165039"
  },
  {
    "text": "unless I vectorize things. So if I do vec of dA, this\ncould be some big matrix--",
    "start": "2165040",
    "end": "2172390"
  },
  {
    "text": "n squared by-- yeah, it's n\nsquared by n squared matrix that has a\nvec of dA on one side",
    "start": "2172390",
    "end": "2179500"
  },
  {
    "text": "and vec of dA primed\non the other side. But it's not very\nnatural to do that.",
    "start": "2179500",
    "end": "2186640"
  },
  {
    "text": "And it's in some ways,\nit's easier to do this. ",
    "start": "2186640",
    "end": "2193520"
  },
  {
    "text": "So I want to talk a little bit\nabout why second derivatives?",
    "start": "2193520",
    "end": "2202060"
  },
  {
    "start": "2202060",
    "end": "2208310"
  },
  {
    "text": "And of course, they come\nup in lots of cases. But let me just mention\na few salient things.",
    "start": "2208310",
    "end": "2213750"
  },
  {
    "text": "So first of all, they give you-- the first derivative gives\nyou a linear approximation of a function linearization.",
    "start": "2213750",
    "end": "2220000"
  },
  {
    "text": "The second derivatives give\nyou quadratic approximations. ",
    "start": "2220000",
    "end": "2231620"
  },
  {
    "text": "So if you have f of x\nplus a little change.",
    "start": "2231620",
    "end": "2239110"
  },
  {
    "text": "Let's call it delta x. It's not infinitesimal anymore. So this is going to\nbe an approximation.",
    "start": "2239110",
    "end": "2247349"
  },
  {
    "text": "This is approximately f of x\nplus f primed of x delta x.",
    "start": "2247350",
    "end": "2253830"
  },
  {
    "text": "That's our linear approximation\nfrom the first derivative, our finite difference\napproximation,",
    "start": "2253830",
    "end": "2259320"
  },
  {
    "text": "if you think of it. And now there'll be\na new term that'll look like f double primed of\nx with a delta x, a delta x,",
    "start": "2259320",
    "end": "2271647"
  },
  {
    "text": "and I'm missing something. What am I missing? ",
    "start": "2271647",
    "end": "2277400"
  },
  {
    "text": "Just think of 1801,\nTaylor series. AUDIENCE: [INAUDIBLE] STEVEN JOHNSON: Is 1/2, yeah.",
    "start": "2277400",
    "end": "2283690"
  },
  {
    "text": "And then there's higher\norder terms, a little low of delta x squared.",
    "start": "2283690",
    "end": "2291670"
  },
  {
    "text": "We're dropping terms. So we're dropping terms that\nare smaller than quadratic.",
    "start": "2291670",
    "end": "2301370"
  },
  {
    "text": "So if it's three\ntimes differentiable, we're dropping cubic terms. But maybe the function doesn't\nhave it, their derivative.",
    "start": "2301370",
    "end": "2306589"
  },
  {
    "text": "But definitely\nwhat we're dropping are our terms that are\nhigher than quadratic. So the 1/2.",
    "start": "2306590",
    "end": "2313460"
  },
  {
    "text": "You can derive this\npretty easily by just-- if you take two\nderivatives of this,",
    "start": "2313460",
    "end": "2318800"
  },
  {
    "text": "you'd better get\nback to f primed-- f double primed. It's at a better match,\nthe second derivative.",
    "start": "2318800",
    "end": "2324800"
  },
  {
    "text": "But because the x\nappears twice in this, then if you take two\nderivatives back to delta x,",
    "start": "2324800",
    "end": "2333770"
  },
  {
    "text": "you should get back\nto f double primed. But because delta x\nappears twice in this,",
    "start": "2333770",
    "end": "2340430"
  },
  {
    "text": "you need to have a\nhalf there in order to get back to f double primed. So we just write that in.",
    "start": "2340430",
    "end": "2346260"
  },
  {
    "text": "So if we take-- OK, the second\nderivative with a respect",
    "start": "2346260",
    "end": "2356790"
  },
  {
    "text": "to delta x, you had better get\nback to f double primed of x.",
    "start": "2356790",
    "end": "2363450"
  },
  {
    "text": "And that 1/2 factor is necessary\nbecause it appears twice.",
    "start": "2363450",
    "end": "2381420"
  },
  {
    "text": "So otherwise, you'd see it\nget twice, just like if-- for the same reason you have\nit in the Taylor series.",
    "start": "2381420",
    "end": "2387020"
  },
  {
    "text": "If these are just scalars, when\nI take the-- this is a delta x squared. When I take the\nsecond derivative,",
    "start": "2387020",
    "end": "2392450"
  },
  {
    "text": "I'm going to get a 2. And I really want it to\nmatch the second derivative of my function at that point.",
    "start": "2392450",
    "end": "2398870"
  },
  {
    "text": "OK, so linear-- approximating\nthings by other things is useful.",
    "start": "2398870",
    "end": "2404330"
  },
  {
    "text": "Approximating things by\nquadratic functions is useful. So for example, if you're\ndoing optimization,",
    "start": "2404330",
    "end": "2415440"
  },
  {
    "text": "we approximate f by\napproximately a quadratic",
    "start": "2415440",
    "end": "2424780"
  },
  {
    "text": "and then optimize the\nquadratic to get a step.",
    "start": "2424780",
    "end": "2433175"
  },
  {
    "text": " This is sometimes called--",
    "start": "2433175",
    "end": "2438900"
  },
  {
    "text": "this is a variety of names. It's sometimes called Sequential\nQuadratic Programming, or SQP.",
    "start": "2438900",
    "end": "2455210"
  },
  {
    "text": "Technically, you-- also,\nif you have constraints, you make linear approximations\nof the constraints or, I guess,",
    "start": "2455210",
    "end": "2466270"
  },
  {
    "text": "affine approximations.  But colloquially, it's\ncalled linear approximations",
    "start": "2466270",
    "end": "2474370"
  },
  {
    "text": "of products of constraints.",
    "start": "2474370",
    "end": "2479630"
  },
  {
    "text": "So if you have a-- but you're\nminimizing an arbitrary nonlinear function, it's\nback to arbitrary nonlinear",
    "start": "2479630",
    "end": "2485380"
  },
  {
    "text": "constraints. That's hard. But if you approximate\nthe function by a quadratic function\nusing a second derivative,",
    "start": "2485380",
    "end": "2492640"
  },
  {
    "text": "approximate the\nconstraints by linear, that's called a QP,\nor Quadratic Program. And there are good methods to\nsolve those kinds of things.",
    "start": "2492640",
    "end": "2500724"
  },
  {
    "text": " Another equivalent--\nequivalently,",
    "start": "2500725",
    "end": "2508120"
  },
  {
    "text": "optimizing a quadratic\nfunction is the same thing as--",
    "start": "2508120",
    "end": "2514060"
  },
  {
    "text": "so optimizing a function\nis equivalent to finding-- locally to finding a\nroot of the gradient.",
    "start": "2514060",
    "end": "2520960"
  },
  {
    "text": "So we're equivalently finding\na root of the gradient of f.",
    "start": "2520960",
    "end": "2528773"
  },
  {
    "text": "And you're going\nto approximate it by a linear, or by an affine,\nor let's say, linear--",
    "start": "2528773",
    "end": "2544069"
  },
  {
    "text": "colloquially linear,\nbecause equivalently, you're",
    "start": "2544070",
    "end": "2549920"
  },
  {
    "text": "approximating it by f primed\nof x plus your f double primed",
    "start": "2549920",
    "end": "2557150"
  },
  {
    "text": "of x delta x.",
    "start": "2557150",
    "end": "2562460"
  },
  {
    "text": "And so if you're finding a\nroot of a linear function,",
    "start": "2562460",
    "end": "2568000"
  },
  {
    "text": "you have a nonlinear--\nyou're trying to find the root of a\nnonlinear function grad f, and you approximate\nit by a linear thing,",
    "start": "2568000",
    "end": "2574042"
  },
  {
    "text": "and you find a root\nof that, what's the name for that method? AUDIENCE: Newton-- STEVEN JOHNSON: Newton's method. So this is just Newton's method.",
    "start": "2574042",
    "end": "2580353"
  },
  {
    "start": "2580353",
    "end": "2592510"
  },
  {
    "text": "And so in practice, finding\nthe Hessian, or finding the f",
    "start": "2592510",
    "end": "2602410"
  },
  {
    "text": "double primed or the Hessian\nmatrix is often expensive.",
    "start": "2602410",
    "end": "2612109"
  },
  {
    "start": "2612110",
    "end": "2617240"
  },
  {
    "text": "If f of x again takes\na Rn to a scalar,",
    "start": "2617240",
    "end": "2624770"
  },
  {
    "text": "then H is an n-by-n matrix.",
    "start": "2624770",
    "end": "2630440"
  },
  {
    "text": "And this is huge if n is large.",
    "start": "2630440",
    "end": "2636319"
  },
  {
    "text": "So if you have a neural\nnetwork where n is a billion, the Hessian is a billion\nby a billion matrix. You can't even store this\nmatrix, much less compute it.",
    "start": "2636320",
    "end": "2645010"
  },
  {
    "text": "So it's hard to\nget exactly for-- I guess it's in high dimensions.",
    "start": "2645010",
    "end": "2650630"
  },
  {
    "start": "2650630",
    "end": "2657470"
  },
  {
    "text": "So often, what you would try and\ndo is you try and approximate. If you don't want to\ngive up on it entirely,",
    "start": "2657470",
    "end": "2665390"
  },
  {
    "text": "you approximate the\nHessian in various ways.",
    "start": "2665390",
    "end": "2674549"
  },
  {
    "text": " And so these give you rise to\na variety of methods called",
    "start": "2674550",
    "end": "2685980"
  },
  {
    "text": "quasi-Newton methods,\nthe most famous of which",
    "start": "2685980",
    "end": "2697300"
  },
  {
    "text": "is called the BFGS method,\nwhich is Broyden, Fletcher,",
    "start": "2697300",
    "end": "2702400"
  },
  {
    "text": "Goldfarb, and Shannon, I think. It's named after four people\nwho amusingly discovered",
    "start": "2702400",
    "end": "2708280"
  },
  {
    "text": "the same thing in the\nsame year independently, like there's three or four\nseparate papers [LAUGHS]",
    "start": "2708280",
    "end": "2715510"
  },
  {
    "text": "on the same thing. There's also a\nclosely related method called Newton-Krylov\nmethods, and so forth.",
    "start": "2715510",
    "end": "2729549"
  },
  {
    "text": "So I don't have time to\nexplain all these things. But these are some key words\nif you ever need to do this.",
    "start": "2729550",
    "end": "2736480"
  },
  {
    "text": "So Hessians are\nuseful for a small n. You can compute them explicitly. By even automatic\ndifferentiation,",
    "start": "2736480",
    "end": "2742000"
  },
  {
    "text": "you can get Hessians for you. But for big n's, you can't even\nstore it, much less compute it. So then there are\nways to kind of--",
    "start": "2742000",
    "end": "2748099"
  },
  {
    "text": "and it's a really\nintricate problem to approximate Hessians. Or you can compute the Hessian\ntimes in a particular direction",
    "start": "2748100",
    "end": "2756100"
  },
  {
    "text": "quickly, like a Hessian\ntimes an operated on a dx. That you can get quickly.",
    "start": "2756100",
    "end": "2762610"
  },
  {
    "text": "But yeah. ",
    "start": "2762610",
    "end": "2769000"
  }
]
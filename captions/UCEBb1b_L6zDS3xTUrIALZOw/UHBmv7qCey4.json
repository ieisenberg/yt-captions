[
  {
    "start": "0",
    "end": "132000"
  },
  {
    "start": "0",
    "end": "9640"
  },
  {
    "text": "PATRICK WINSTON: We've now\nalmost completed our journey. This will be it for\ntalking about",
    "start": "9640",
    "end": "15650"
  },
  {
    "text": "several kinds of learning-- the venerable kind, that's\nthe nearest neighbors and",
    "start": "15650",
    "end": "21920"
  },
  {
    "text": "identification tree\ntypes of learning. Still useful, still the right\nthing to do if there's no reason not to do the\nsimple thing.",
    "start": "21920",
    "end": "30180"
  },
  {
    "text": "Then we have the\nbiologically-inspired approaches. Neural nets. All kinds of problems with local\nmaxima and overfitting",
    "start": "30180",
    "end": "38500"
  },
  {
    "text": "and oscillation, if you get\nthe rate constant too big. ",
    "start": "38500",
    "end": "45600"
  },
  {
    "text": "Genetic algorithms.  Like neural nets, both are very\nnaive in their attempt to",
    "start": "45600",
    "end": "53149"
  },
  {
    "text": "mimic nature. So maybe they work on\na class of problems. They surely do each have a class\nof problems for which",
    "start": "53150",
    "end": "59470"
  },
  {
    "text": "they're good. But as a general purpose first\nresort, I don't recommend it.",
    "start": "59470",
    "end": "65190"
  },
  {
    "text": "But now the theorists have come\nout and done some things are very remarkable. And in the end, you have to\nsay, wow, these are such",
    "start": "65190",
    "end": "71830"
  },
  {
    "text": "powerful ideas. I wonder if nature has\ndiscovered them, too?",
    "start": "71830",
    "end": "77780"
  },
  {
    "text": "Is there good engineering\nin the brain, based on good science? Or given the nature of\nevolution, is it just random",
    "start": "77780",
    "end": "84990"
  },
  {
    "text": "junk that is the best ways\nfor doing anything? Who knows?",
    "start": "84990",
    "end": "90180"
  },
  {
    "text": "But today, we're going to talk\nabout an idea that I'll bet is in there somewhere, because it's\neasy to implement, and",
    "start": "90180",
    "end": "96260"
  },
  {
    "text": "it's extremely powerful in what\nit does, and it's the essential item in anybody's\nrepertoire of learning",
    "start": "96260",
    "end": "104980"
  },
  {
    "text": "mechanisms. It's also a mechanism which,\nif you understand only by",
    "start": "104980",
    "end": "111820"
  },
  {
    "text": "formula, you will never be able\nto work the problems on the quiz, that's for sure.",
    "start": "111820",
    "end": "117760"
  },
  {
    "text": "Because on the surface, it\nlooks like it'd be very complicated to simulate\nthis approach.",
    "start": "117760",
    "end": "123920"
  },
  {
    "text": "But once you understand how it\nworks and look at a little bit of the math and let it sing\nsongs to you, it turns out to be extremely easy.",
    "start": "123920",
    "end": "133270"
  },
  {
    "start": "132000",
    "end": "544000"
  },
  {
    "text": "So it's about letting multiple\nmethods work in your behalf.",
    "start": "133270",
    "end": "138980"
  },
  {
    "text": "So far, we've been talking about\nusing just one method to do something. And what we're going to do now\nis we're looking to see if a",
    "start": "138980",
    "end": "145780"
  },
  {
    "text": "crowd can be smarter than the\nindividuals in the crowd.",
    "start": "145780",
    "end": "153370"
  },
  {
    "text": "But before we get too far down\nthat abstract path, let me just say that the whole works\nhas to do with classification,",
    "start": "153370",
    "end": "160750"
  },
  {
    "text": "and binary classification. Am I holding a piece of chalk in\nmy hand, or a hand grenade?",
    "start": "160750",
    "end": "168500"
  },
  {
    "text": "Is that a cup of\ncoffee or tea? Those are binary classification\nproblems.",
    "start": "168500",
    "end": "173740"
  },
  {
    "text": "And so we're going to be talking\ntoday strictly about binary classification. We're not going to be talking\nabout finding the right letter",
    "start": "173740",
    "end": "179569"
  },
  {
    "text": "in the alphabet that's\nwritten on the page. That's a 26-way choice. We're talking about\nbinary choices.",
    "start": "179570",
    "end": "187190"
  },
  {
    "text": "So we assume that there's\na set of classifiers that we can draw on.",
    "start": "187190",
    "end": "192280"
  },
  {
    "text": "Here's one-- h. And it produces either a\nminus 1 or a plus 1.",
    "start": "192280",
    "end": "200050"
  },
  {
    "text": "So that's how the classification\nis done. If it's coffee, plus 1. If it's tea, minus 1.",
    "start": "200050",
    "end": "206340"
  },
  {
    "text": "Is this chalk, plus one. If it's a hand grenade,\nminus 1. So that's how the classification\nworks.",
    "start": "206340",
    "end": "212709"
  },
  {
    "text": "Now, too bad for us, normally\nthe world doesn't give us very good classifiers. So if we look at the error rate\nof this classifier or any",
    "start": "212710",
    "end": "222500"
  },
  {
    "text": "other classifier, that error\nrate will range from 0 to 1 in",
    "start": "222500",
    "end": "230180"
  },
  {
    "text": "terms of the fraction\nof the cases got wrong on a sample set.",
    "start": "230180",
    "end": "235730"
  },
  {
    "text": " So you'd like your error rate\nto be way down here.",
    "start": "235730",
    "end": "242019"
  },
  {
    "text": "You're dead if it's\nover there. But what about in the middle? What if it's, say,\nright there.",
    "start": "242020",
    "end": "248420"
  },
  {
    "text": "Just a little bit better\nthan flipping a coin. If it's just a little bit better\nthan flipping a coin,",
    "start": "248420",
    "end": "254800"
  },
  {
    "text": "that's a weak classifier. ",
    "start": "254800",
    "end": "264659"
  },
  {
    "text": "And the question is, can you\nmake a classifier that's way over here, like there, a\nstrong classifier, by",
    "start": "264660",
    "end": "279240"
  },
  {
    "text": "combining several of these\nweak classifiers, and letting them vote?",
    "start": "279240",
    "end": "286090"
  },
  {
    "text": "So how would you do that? You might say, well, let us make\na big classifier capital",
    "start": "286090",
    "end": "291919"
  },
  {
    "text": "H, that works on some sample x,\nand has its output produces",
    "start": "291920",
    "end": "303190"
  },
  {
    "text": "something that depends on the\nsum of the outputs of the individual classifiers. So we have H1 working on x.",
    "start": "303190",
    "end": "313100"
  },
  {
    "text": "We have H2 working on x.",
    "start": "313100",
    "end": "318340"
  },
  {
    "text": "And we have H3 also\nworking on x. Let's say three of them,\njust to start us off.",
    "start": "318340",
    "end": "324710"
  },
  {
    "text": "And now let's add those\nguys up, and take the sign of the output.",
    "start": "324710",
    "end": "333295"
  },
  {
    "text": " So if two out of the three of\nthose guys agree, then we'll",
    "start": "333295",
    "end": "340690"
  },
  {
    "text": "get an either plus\n1 or minus 1. If all three agree, we'll\nget plus 1 or minus 1.",
    "start": "340690",
    "end": "346150"
  },
  {
    "text": "Because we're just\ntaking the sign. We're just taking the sign\nof the sum of these guys.",
    "start": "346150",
    "end": "352620"
  },
  {
    "text": "So this means that one guy can\nbe wrong, as long as the other two guys are right.",
    "start": "352620",
    "end": "358180"
  },
  {
    "text": "But I think it's easier to see\nhow this all works if you think of some space of samples,\nyou say, well, let's",
    "start": "358180",
    "end": "367380"
  },
  {
    "text": "let that area here be where H1\nis wrong, and this area over",
    "start": "367380",
    "end": "375330"
  },
  {
    "text": "here is where H2 is wrong. ",
    "start": "375330",
    "end": "382360"
  },
  {
    "text": "And then this area over here\nis where H3 is wrong. ",
    "start": "382360",
    "end": "390430"
  },
  {
    "text": "So if the situation is like\nthat, then this formula always gives you the right answers\non the samples.",
    "start": "390430",
    "end": "398250"
  },
  {
    "text": "I'm going to stop saying that\nright now, because I want to be kind of a background thing\non the samples set.",
    "start": "398250",
    "end": "404370"
  },
  {
    "text": "We're talking about wrapping\nthis stuff over the sample set. Later on, we'll ask, OK, given\nthat you trained this thing on",
    "start": "404370",
    "end": "410169"
  },
  {
    "text": "a sample set, how well does it\ndo on some new examples? Because we want to\nask ourselves about overfitting questions.",
    "start": "410170",
    "end": "417150"
  },
  {
    "text": "But for now, we just want to\nlook and see if we believe that this arrangement, where\neach of these H's is producing",
    "start": "417150",
    "end": "426690"
  },
  {
    "text": "plus 1 or minus 1, we're adding\nthem up and taking the sign, is that going to give us a\nbetter result than the tests",
    "start": "426690",
    "end": "432960"
  },
  {
    "text": "individually? And if they look like this when\ndraped over a sample set, then it's clear that we're going\nto get the right answer",
    "start": "432960",
    "end": "439330"
  },
  {
    "text": "every time, because there's no\narea here where any two of",
    "start": "439330",
    "end": "444539"
  },
  {
    "text": "those tests are giving\nus the wrong answer. So the two that are getting\nthe right answer, in this",
    "start": "444540",
    "end": "450740"
  },
  {
    "text": "little circle here for H1, these\nother two are getting the right answer. So they'll outvote it, and\nyou'll get the right answer",
    "start": "450740",
    "end": "456420"
  },
  {
    "text": "every time. But it doesn't have\nto be that simple. ",
    "start": "456420",
    "end": "464240"
  },
  {
    "text": "It could look like this. ",
    "start": "464240",
    "end": "470160"
  },
  {
    "text": "There could be a situation\nwhere this is H1, wrong answer.",
    "start": "470160",
    "end": "477080"
  },
  {
    "text": "This is H2, wrong answer. And this is H3, wrong answer.",
    "start": "477080",
    "end": "484140"
  },
  {
    "text": "And now the situation gets a\nlittle bit more murky, because we have to ask ourselves whether\nthat area where three",
    "start": "484140",
    "end": "495820"
  },
  {
    "text": "out of the three get it wrong\nis sufficiently big so as to",
    "start": "495820",
    "end": "504870"
  },
  {
    "text": "be worse than 1 of the\nindividual tests.",
    "start": "504870",
    "end": "511490"
  },
  {
    "text": "So if you look at that Venn\ndiagram, and stare at it long enough, and try some things, you\ncan say, well, there is no",
    "start": "511490",
    "end": "517260"
  },
  {
    "text": "case where this will give\na worse answer. Or, you might end up with the\nconclusion that there are",
    "start": "517260",
    "end": "524590"
  },
  {
    "text": "cases where we can arrange those\ncircles such that the",
    "start": "524590",
    "end": "530080"
  },
  {
    "text": "voting scheme will give an\nanswer that's worst than an individual test, but I'm not\ngoing to tell you the answer,",
    "start": "530080",
    "end": "535259"
  },
  {
    "text": "because I think we'll make\nthat a quiz question. Good idea? OK.",
    "start": "535260",
    "end": "540870"
  },
  {
    "text": "So we'll make that\na quiz question. ",
    "start": "540870",
    "end": "546700"
  },
  {
    "text": "So that looks like\na good idea. And we can construct a little\nalgorithm that will help us",
    "start": "546700",
    "end": "555460"
  },
  {
    "text": "pick the particular weak\nclassifiers to plug in here. We've got a whole bag\nof classifiers. We've got H1, we've got\nH2, we've got H55.",
    "start": "555460",
    "end": "562639"
  },
  {
    "text": "We've got a lot of them\nwe can choose from. So what we're going to do is\nwe're going to use the data,",
    "start": "562640",
    "end": "572114"
  },
  {
    "text": "undisturbed, to produce H1.",
    "start": "572114",
    "end": "577280"
  },
  {
    "text": "We're just going to try all the\ntests on the data and see which one gives us the\nsmallest error rate. And that's the good guy, so\nwe're going to use that.",
    "start": "577280",
    "end": "584830"
  },
  {
    "text": "Then we're going to use\nthe data with an",
    "start": "584830",
    "end": "591300"
  },
  {
    "text": "exaggeration of H1 errors.",
    "start": "591300",
    "end": "600839"
  },
  {
    "text": " In other words-- this is a critical idea.",
    "start": "600840",
    "end": "606910"
  },
  {
    "text": "What we're going to do is\nwe're going to run this algorithm again, but instead of\njust looking at the number",
    "start": "606910",
    "end": "614010"
  },
  {
    "text": "of samples that are got wrong,\nwhat we're going to do is",
    "start": "614010",
    "end": "621730"
  },
  {
    "text": "we're going to look at a\ndistorted set of samples, where the ones we're not doing\nwell on has exaggerated effect",
    "start": "621730",
    "end": "629480"
  },
  {
    "text": "on the result. So we're going to weight them\nor multiply them, or do",
    "start": "629480",
    "end": "635730"
  },
  {
    "text": "something so that we're going\nto pay more attention to the samples on which H1 produces an\nerror, and that's going to",
    "start": "635730",
    "end": "643810"
  },
  {
    "text": "give us H2.  And then we're going to do it\none more time, because we've",
    "start": "643810",
    "end": "649830"
  },
  {
    "text": "got three things to go with here\nin this particular little exploratory scheme.",
    "start": "649830",
    "end": "655100"
  },
  {
    "text": "And this time, we're\ngoing to have an exaggeration of those samples--",
    "start": "655100",
    "end": "664389"
  },
  {
    "text": "which samples are we going\nto exaggerate now? ",
    "start": "664390",
    "end": "672250"
  },
  {
    "text": "We might as well look for the\nones where H1 gives us a different answer from H2,\nbecause we want to be on the",
    "start": "672250",
    "end": "677260"
  },
  {
    "text": "good guy's side. So we can say we're going to\nexaggerate those samples four",
    "start": "677260",
    "end": "685070"
  },
  {
    "text": "which H1 gives us a different\nresult from H2. And that's going\nto give us H3.",
    "start": "685070",
    "end": "690670"
  },
  {
    "text": " All right. So we can think of this whole\nworks here as part one of a",
    "start": "690670",
    "end": "700530"
  },
  {
    "text": "multi-part idea. ",
    "start": "700530",
    "end": "708680"
  },
  {
    "text": "So let's see. I don't know, what might\nbe step two? Well, this is a good idea. Then what we've got that we can\neasily derive from that is",
    "start": "708680",
    "end": "718540"
  },
  {
    "text": "a little tree looked\nlike this. And we can say that H of x\ndepends on H1, H2, and H3.",
    "start": "718540",
    "end": "729899"
  },
  {
    "text": "But now, if that that's a good\nidea, and that gives a better answer than any of the\nindividual tests, maybe we can",
    "start": "729900",
    "end": "738209"
  },
  {
    "text": "make this idea a little bit\nrecursive, and say, well, maybe H1 is actually\nnot an atomic test.",
    "start": "738210",
    "end": "745550"
  },
  {
    "text": "But maybe it's the vote\nof three other tests. So you can make a\ntree structure",
    "start": "745550",
    "end": "751740"
  },
  {
    "text": "that looks like this. So this is H11, H12, H13,\nand then 3 here.",
    "start": "751740",
    "end": "760680"
  },
  {
    "text": "And then this will\nbe H31, H32, H33.",
    "start": "760680",
    "end": "768860"
  },
  {
    "text": "And so that's a sort of\nget out the vote idea. ",
    "start": "768860",
    "end": "777200"
  },
  {
    "text": "We're trying to get a whole\nbunch of individual tests into the act.",
    "start": "777200",
    "end": "783550"
  },
  {
    "text": "So I guess the reason this\nwasn't discovered until about '10 years ago was because you've\ngot to get so many of",
    "start": "783550",
    "end": "789649"
  },
  {
    "text": "these desks all lined up before\nthe idea gets through that long filter of ideas.",
    "start": "789650",
    "end": "795620"
  },
  {
    "text": "So that's the only idea number\ntwo of quite a few. ",
    "start": "795620",
    "end": "803350"
  },
  {
    "text": "Well, next thing we might\nthink is, well, we keep talking about these\nclassifiers. What kind of classifiers\nare we talking about?",
    "start": "803350",
    "end": "810500"
  },
  {
    "text": "I've got-- oh, shoot, I've spent\nmy last nickel. I don't have a coin to flip. But that's one classifier,\nright?",
    "start": "810500",
    "end": "817810"
  },
  {
    "text": "The trouble with that classifier\nis it's a weak classifier, because it\ngives me a 50/50",
    "start": "817810",
    "end": "823779"
  },
  {
    "text": "chance of being right. I guess there are conditions\nin which a coin flip is better than a--",
    "start": "823780",
    "end": "830380"
  },
  {
    "start": "827000",
    "end": "1272000"
  },
  {
    "text": "it is a weak classifier. If the two outcomes are not\nequally probable, than a coin",
    "start": "830380",
    "end": "835680"
  },
  {
    "text": "flip is a perfectly good\nweak classifier. But what we're going to do is\nwe're going to think in terms",
    "start": "835680",
    "end": "841400"
  },
  {
    "text": "of a different set\nof classifiers. And we're going to call\nthem decision tree.",
    "start": "841400",
    "end": "852240"
  },
  {
    "text": "Now, you remember decision\ntrees, right? But we're not going to\nbuild decision trees. We're going to use decision\ntree stumps.",
    "start": "852240",
    "end": "859820"
  },
  {
    "text": " So if we have a two-dimensional\nspace that",
    "start": "859820",
    "end": "868639"
  },
  {
    "text": "looks like this, then a decision\ntree stump is a",
    "start": "868640",
    "end": "874790"
  },
  {
    "text": "single test. It's not a complete tree that\nwill divide up the samples into homogeneous groups.",
    "start": "874790",
    "end": "880340"
  },
  {
    "text": "It's just what you can\ndo with one test. So each possible test\nis a classifier.",
    "start": "880340",
    "end": "888530"
  },
  {
    "text": "How many tests do we\nget out of that? ",
    "start": "888530",
    "end": "899280"
  },
  {
    "text": "12, right? Yeah. It doesn't look like\n12 to me, either. But here's how you get to 12.",
    "start": "899280",
    "end": "905300"
  },
  {
    "text": "One decision tree test you can\nstick in there would be that",
    "start": "905300",
    "end": "910459"
  },
  {
    "text": "test right there. And that would be a complete\ndecision tree stump.",
    "start": "910460",
    "end": "916040"
  },
  {
    "text": "But, of course, you can\nalso put in this one. That would be another\ndecision tree stump.",
    "start": "916040",
    "end": "923580"
  },
  {
    "text": "Now, for this one on the right,\nI could say, everything on the right is a minus.",
    "start": "923580",
    "end": "928730"
  },
  {
    "text": "Or, I could say, everything\non the right is a plus. It would happen to be wrong, but\nit's a valid test with a",
    "start": "928730",
    "end": "937420"
  },
  {
    "text": "valid outcome. So that's how we double the\nnumber of test that we have lines for.",
    "start": "937420",
    "end": "943090"
  },
  {
    "text": "And you know what? can even have a kind of test out\nhere that says everything is plus, or everything\nis wrong.",
    "start": "943090",
    "end": "951190"
  },
  {
    "text": "So for each dimension, the\nnumber of decision tree stumps is the number of lines\nI can put in times 2.",
    "start": "951190",
    "end": "959120"
  },
  {
    "text": "And then I've got two dimensions\nhere, that's how I got to twelve. So there are three lines.",
    "start": "959120",
    "end": "964470"
  },
  {
    "text": "I can have the pluses\non either the left or the right side. So that's six. And then I've got two\ndimensions, so",
    "start": "964470",
    "end": "969829"
  },
  {
    "text": "that gives me 12. So that's the decision\ntree stump idea. And here are the other decision\ntree boundaries,",
    "start": "969830",
    "end": "979180"
  },
  {
    "text": "obviously just like that. So that's one way can generate\na batch of tests to try out",
    "start": "979180",
    "end": "990750"
  },
  {
    "text": "with this idea of using\na lot of tests to help you get the job done.",
    "start": "990750",
    "end": "996455"
  },
  {
    "text": "STUDENT: Couldn't you also have\na decision tree on the right side? PATRICK WINSTON: The question\nis, can you also have a test",
    "start": "996455",
    "end": "1004330"
  },
  {
    "text": "on the right side? See, this is just a stand-in for\nsaying, everything's plus or everything's minus.",
    "start": "1004330",
    "end": "1010260"
  },
  {
    "text": "So it doesn't matter where\nyou put the line. It can be on the right side,\nor the left side, or the bottom, or the top.",
    "start": "1010260",
    "end": "1015640"
  },
  {
    "text": "Or you don't have to put\nthe line anywhere. It's just an extra test, an\nadditional to the ones you put between the samples.",
    "start": "1015640",
    "end": "1022810"
  },
  {
    "text": "So this whole idea\nof boosting, the main idea of the day. Does it depend on using\ndecision tree stumps?",
    "start": "1022810",
    "end": "1029980"
  },
  {
    "text": "The answer is no. Do not be confused. You can use boosting with\nany kind of classifier.",
    "start": "1029980",
    "end": "1037800"
  },
  {
    "text": "so why do I use decision\ntree stumps today? Because it makes my life easy.",
    "start": "1037800",
    "end": "1043660"
  },
  {
    "text": "We can look at it, we can\nsee what it's doing. But we could put bunch of\nneural nets in there.",
    "start": "1043660",
    "end": "1049790"
  },
  {
    "text": "We could put a bunch of real\ndecision trees in there. We could put a bunch of nearest",
    "start": "1049790",
    "end": "1055530"
  },
  {
    "text": "neighbor things in there. The boosting idea\ndoesn't care. I just used these decision\ntree stumps because I and",
    "start": "1055530",
    "end": "1061880"
  },
  {
    "text": "everybody else use them\nfor illustration. All right.",
    "start": "1061880",
    "end": "1068269"
  },
  {
    "text": "We're making progress. Now, what's the error rate\nfor any these tests",
    "start": "1068270",
    "end": "1074470"
  },
  {
    "text": "and lines we drew? Well, I guess it'll be the error\nrate is equal to the sum",
    "start": "1074470",
    "end": "1085110"
  },
  {
    "text": "of 1 over n-- That's the total number\nof points, the number of samples--",
    "start": "1085110",
    "end": "1090322"
  },
  {
    "text": " summed over the cases\nwhere we are wrong.",
    "start": "1090322",
    "end": "1095970"
  },
  {
    "start": "1095970",
    "end": "1102450"
  },
  {
    "text": "So gee, we're going to work on\ncombining some of these ideas. And we've got this notion\nof exaggeration.",
    "start": "1102450",
    "end": "1109690"
  },
  {
    "text": "At some stage in what we're\ndoing here, we're going to want to be able to exaggerate\nthe effect of some errors relative to other errors.",
    "start": "1109690",
    "end": "1116870"
  },
  {
    "text": "So one thing we can do is\nwe can assume, or we can stipulate, or we can assert that\neach of these samples has",
    "start": "1116870",
    "end": "1126620"
  },
  {
    "text": "a weight associated with it. That's W1, this is W2,\nand that's W3.",
    "start": "1126620",
    "end": "1133370"
  },
  {
    "text": "And in the beginning, there's no\nreason to suppose that any one of these is more\nor less important than any of the other.",
    "start": "1133370",
    "end": "1139160"
  },
  {
    "text": "So in the beginning, W sub i\nat time [? stub ?] one is",
    "start": "1139160",
    "end": "1145370"
  },
  {
    "text": "equal to 1 over n.  So the error is just adding up\nthe number of samples that",
    "start": "1145370",
    "end": "1154170"
  },
  {
    "text": "were got wrong. And that'll be the fraction\nof samples to that you didn't get right.",
    "start": "1154170",
    "end": "1159350"
  },
  {
    "text": "And that will be\nthe error rate. So what we want to do is we want\nto say, instead of using",
    "start": "1159350",
    "end": "1166270"
  },
  {
    "text": "this as the error rate for all\ntime, what we want to do is we want to move that over, and\nsay that the error rate is",
    "start": "1166270",
    "end": "1174140"
  },
  {
    "text": "equal to the sum over the things\nyou got wrong in the",
    "start": "1174140",
    "end": "1179300"
  },
  {
    "text": "current step, times the\nweights of those that were got wrong.",
    "start": "1179300",
    "end": "1184770"
  },
  {
    "text": "So in step one, everything's\ngot the same weight, it doesn't matter. But if we find a way to change\ntheir weights going",
    "start": "1184770",
    "end": "1190710"
  },
  {
    "text": "downstream-- so as to, for example, highly\nexaggerate that third sample,",
    "start": "1190710",
    "end": "1197750"
  },
  {
    "text": "then W3 will go up relative\nto W1 and W2.",
    "start": "1197750",
    "end": "1203780"
  },
  {
    "text": "The one thing we want to be sure\nof is there is no matter how we adjust the weights, that\nthe sum of the weights",
    "start": "1203780",
    "end": "1211350"
  },
  {
    "text": "over the whole space\nis equal to 1. ",
    "start": "1211350",
    "end": "1217309"
  },
  {
    "text": "So in other words, we want to\nchoose the weights so that they emphasize some of the\nsamples, but we also want to put a constraint on the weights\nsuch that all of them",
    "start": "1217310",
    "end": "1225510"
  },
  {
    "text": "added together is\nsumming to one. And we'll say that that enforces\na distribution.",
    "start": "1225510",
    "end": "1232870"
  },
  {
    "text": " A distribution is a set of\nweights that sum to one.",
    "start": "1232870",
    "end": "1241400"
  },
  {
    "text": "Well, that's just a nice idea. So we're make a little\nprogress.",
    "start": "1241400",
    "end": "1246779"
  },
  {
    "text": "We've got this idea that we\ncan add some plus/minus 1 classifiers together, you\nget a better classifier.",
    "start": "1246780",
    "end": "1255130"
  },
  {
    "text": "We got some idea about\nhow to do that. It occurs to us that maybe\nwe want to get a lot of classifiers into the act\nsomehow or another.",
    "start": "1255130",
    "end": "1263500"
  },
  {
    "text": "And maybe we want to think\nabout using decision tree stumps so as to ground out\nthinking about all this stuff.",
    "start": "1263500",
    "end": "1271220"
  },
  {
    "text": "So the next step is to say,\nwell, how actually should we",
    "start": "1271220",
    "end": "1276830"
  },
  {
    "start": "1272000",
    "end": "1477000"
  },
  {
    "text": "combine this stuff? And you will find, in the\nliterature libraries, full of papers that do stuff\nlike that.",
    "start": "1276830",
    "end": "1284550"
  },
  {
    "text": "And that was state of the art\nfor quite a few years. But then people began to say,\nwell, maybe we can build up",
    "start": "1284550",
    "end": "1292390"
  },
  {
    "text": "this classifier, H of x, in\nmultiple steps and get a lot of classifiers into the act.",
    "start": "1292390",
    "end": "1300090"
  },
  {
    "text": "So maybe we can say that the\nclassifier is the sign of H--",
    "start": "1300090",
    "end": "1311786"
  },
  {
    "text": "that's the one we\npicked first. That's the classifier\nwe picked first.",
    "start": "1311786",
    "end": "1316990"
  },
  {
    "text": "That's looking at samples. And then we've got H2. And then we've got H3.",
    "start": "1316990",
    "end": "1323090"
  },
  {
    "text": "And then we've got how many\nother classifiers we might want, or how many classifiers\nwe might need in order to",
    "start": "1323090",
    "end": "1331620"
  },
  {
    "text": "correctly classify everything\nin our sample set.",
    "start": "1331620",
    "end": "1336800"
  },
  {
    "text": "So people began to think about\nwhether there might be an algorithm that would develop\na classifier that way,",
    "start": "1336800",
    "end": "1342560"
  },
  {
    "text": "one step at a time.  That's why I put that step\nnumber in the exponent,",
    "start": "1342560",
    "end": "1349660"
  },
  {
    "text": "because we're picking this one\nat first, then we're expanding it to have two, and then we're\nexpanding it to have",
    "start": "1349660",
    "end": "1355010"
  },
  {
    "text": "three, and so on. And each of those individual\nclassifiers are separately looking at the sample.",
    "start": "1355010",
    "end": "1362529"
  },
  {
    "text": "But of course, it would be\nnatural to suppose that just adding things up wouldn't\nbe enough.",
    "start": "1362530",
    "end": "1369150"
  },
  {
    "text": "And it's not. So it isn't too hard to invent\nthe next idea, which is to",
    "start": "1369150",
    "end": "1374690"
  },
  {
    "text": "modify this thing just a little\nbit by doing what?",
    "start": "1374690",
    "end": "1380250"
  },
  {
    "text": "It looks almost like a scoring\npolynomial, doesn't it? So what would we do to tart\nthis up a little bit?",
    "start": "1380250",
    "end": "1388308"
  },
  {
    "text": "STUDENT: [INAUDIBLE]. PATRICK WINSTON: Come again? Do what?",
    "start": "1388308",
    "end": "1393380"
  },
  {
    "text": "STUDENT: [INAUDIBLE]. PATRICK WINSTON: Somewhere out\nthere someone's murmuring.",
    "start": "1393380",
    "end": "1399360"
  },
  {
    "text": "STUDENT: Add-- PATRICK WINSTON: Add weights! STUDENT: --weights. Yeah. PATRICK WINSTON: Excellent. Good idea. So what we're going to do is\nwe're going to have alphas",
    "start": "1399360",
    "end": "1408320"
  },
  {
    "text": "associated with each of these\nclassifiers, and we're going to determine if somebody\ncan build that kind",
    "start": "1408320",
    "end": "1414240"
  },
  {
    "text": "formula to do the job. So maybe I ought to modify this\ngold star idea before I",
    "start": "1414240",
    "end": "1421780"
  },
  {
    "text": "get too far downstream. And we're not going to treat\neverybody in a crowd equally.",
    "start": "1421780",
    "end": "1432240"
  },
  {
    "text": "We're going to wait some of the\nopinions more than others. And by the way, they're all\ngoing to make errors in",
    "start": "1432240",
    "end": "1437790"
  },
  {
    "text": "different parts of the space. So maybe it's not the wisdom of\neven a weighted crowd, but",
    "start": "1437790",
    "end": "1445775"
  },
  {
    "text": "a crowd of experts. ",
    "start": "1445775",
    "end": "1452360"
  },
  {
    "text": "Each of which is good at\ndifferent parts of the space. So anyhow, we've got this\nformula, and there are a few",
    "start": "1452360",
    "end": "1459770"
  },
  {
    "text": "things that one can\nsay turn out.",
    "start": "1459770",
    "end": "1465780"
  },
  {
    "text": "But first, let's write down the\nan algorithm for what this",
    "start": "1465780",
    "end": "1471530"
  },
  {
    "text": "ought to look like. Before I run out of space, I\nthink I'll exploit the right hand board here, and put the\noverall algorithm right here.",
    "start": "1471530",
    "end": "1481110"
  },
  {
    "start": "1477000",
    "end": "2167000"
  },
  {
    "text": "So we're going to start out by\nletting of all the weights at",
    "start": "1481110",
    "end": "1487410"
  },
  {
    "text": "time 1 be equal to 1 over n.",
    "start": "1487410",
    "end": "1493570"
  },
  {
    "text": "That's just saying that they're\nall equal in the beginning, and they're\nequal to 1 over n.",
    "start": "1493570",
    "end": "1499169"
  },
  {
    "text": "And n is the number\nof samples. ",
    "start": "1499170",
    "end": "1506090"
  },
  {
    "text": "And then, when I've got\nthat, I want to",
    "start": "1506090",
    "end": "1511130"
  },
  {
    "text": "compute alpha, somehow. ",
    "start": "1511130",
    "end": "1517510"
  },
  {
    "text": "Let's see. No, I don't want to do that. I want to",
    "start": "1517510",
    "end": "1522809"
  },
  {
    "text": "I want to pick a classifier the\nminimizes the error rate.",
    "start": "1522810",
    "end": "1528140"
  },
  {
    "start": "1528140",
    "end": "1537730"
  },
  {
    "text": "And then m, i, zes,\nerror at time t.",
    "start": "1537730",
    "end": "1543049"
  },
  {
    "text": "And that's going to\nbe at time t. And we're going to come\nback in here. That's why we put a step\nindex in there.",
    "start": "1543050",
    "end": "1550159"
  },
  {
    "text": "So once we've picked a\nclassifier that produces an",
    "start": "1550160",
    "end": "1556790"
  },
  {
    "text": "error rate, then we can\nuse the error rate to determine the alpha. So I want the alpha over here.",
    "start": "1556790",
    "end": "1562260"
  },
  {
    "start": "1562260",
    "end": "1567910"
  },
  {
    "text": "That'll be sort of a byproduct\nof picking that test. And with all that stuff in\nhand, maybe that will be",
    "start": "1567910",
    "end": "1574890"
  },
  {
    "text": "enough to calculate Wt plus 1.",
    "start": "1574890",
    "end": "1580480"
  },
  {
    "start": "1580480",
    "end": "1588600"
  },
  {
    "text": "So we're going to use that\nclassifier that we just picked to get some revised weights,\nand then we're going to go",
    "start": "1588600",
    "end": "1596040"
  },
  {
    "text": "around that loop until this\nclassifier produces a perfect",
    "start": "1596040",
    "end": "1601870"
  },
  {
    "text": "set of conclusions on\nall the sample data. So that's going to be our\noverall strategy.",
    "start": "1601870",
    "end": "1609560"
  },
  {
    "text": "Maybe we've got, if we're going\nto number these things, that's the fourth big idea.",
    "start": "1609560",
    "end": "1614960"
  },
  {
    "text": "And this arrangement here\nis the fifth big idea. Then we've got the\nsixth big idea.",
    "start": "1614960",
    "end": "1621390"
  },
  {
    "text": "And the sixth big\nidea says this. ",
    "start": "1621390",
    "end": "1626940"
  },
  {
    "text": "Suppose that the weight on it\nith sample at time t plus 1 is",
    "start": "1626940",
    "end": "1639340"
  },
  {
    "text": "equal to the weight at time t\non that same sample, divided",
    "start": "1639340",
    "end": "1648600"
  },
  {
    "text": "by some normalizing factor,\ntimes e to the minus alpha at",
    "start": "1648600",
    "end": "1658150"
  },
  {
    "text": "time t, times h at time t, times\nsome function y which is",
    "start": "1658150",
    "end": "1672750"
  },
  {
    "text": "a function of x, But not\na function of time.",
    "start": "1672750",
    "end": "1678160"
  },
  {
    "text": "Now you say, where did\nthis come from? And the answer is, it did not\nspring from the heart of",
    "start": "1678160",
    "end": "1683670"
  },
  {
    "text": "mathematician in the first\n10 minutes that he looked at this problem. In fact, when I asked\n[INAUDIBLE]",
    "start": "1683670",
    "end": "1689550"
  },
  {
    "text": "how this worked, he said, well,\nhe was thinking about this on the couch every Saturday\nfor about a year, and",
    "start": "1689550",
    "end": "1695630"
  },
  {
    "text": "his wife was getting pretty\nsore, but he finally found it and saved their marriage. So where does stuff like\nthis come from?",
    "start": "1695630",
    "end": "1703950"
  },
  {
    "text": "Really, it comes from knowing\na lot of mathematics, and seeing a lot of situations,\nand knowing that something",
    "start": "1703950",
    "end": "1709279"
  },
  {
    "text": "like this might be\nmathematically convenient.",
    "start": "1709280",
    "end": "1714570"
  },
  {
    "text": "Something like this might be\nmathematically convenient.",
    "start": "1714570",
    "end": "1720080"
  },
  {
    "text": "But we've got to back up a\nlittle and let it sing to us. What's y? We saw y last time.",
    "start": "1720080",
    "end": "1725100"
  },
  {
    "text": "The support vector machines. That's just a function. That's plus 1 or minus 1,\ndepending on whether the",
    "start": "1725100",
    "end": "1731270"
  },
  {
    "text": "output ought to be plus\n1 or minus 1. So if this guy is giving the\ncorrect answer, and the",
    "start": "1731270",
    "end": "1742200"
  },
  {
    "text": "correct answer is plus, and then\nthis guy will be plus 1 too, because it always gives\nyou the correct answer.",
    "start": "1742200",
    "end": "1750210"
  },
  {
    "text": "So in that case, where this\nguy is giving the right answer, these will have the same\nsign, so that will be a plus 1 combination.",
    "start": "1750210",
    "end": "1756960"
  },
  {
    "text": "On the other hand, if that guy's\ngiving the wrong answer, you're going to get a minus\n1 out of that combination.",
    "start": "1756960",
    "end": "1762450"
  },
  {
    "text": "So it's true even if the right\nanswer should be minus, right? So if the right answer should\nbe minus, and this is plus,",
    "start": "1762450",
    "end": "1768320"
  },
  {
    "text": "then this will be minus 1, and\nthe whole combination well give you minus 1 again. In other words, the y just flips\nthe sign if you've got",
    "start": "1768320",
    "end": "1776360"
  },
  {
    "text": "the wrong answer, no matter\nwhether the wrong answer is plus 1 or minus 1.",
    "start": "1776360",
    "end": "1782330"
  },
  {
    "text": "These alphas-- shoot, those are the same\nalphas that are in this formula up here, somehow.",
    "start": "1782330",
    "end": "1789950"
  },
  {
    "text": "And then that z, what's\nthat for? Well, if you just look at the\nprevious weights, and its",
    "start": "1789950",
    "end": "1795650"
  },
  {
    "text": "exponential function to produce\nthese W's for the next",
    "start": "1795650",
    "end": "1800900"
  },
  {
    "text": "generation, that's not going to\nbe a distribution, because they won't sum up to 1.",
    "start": "1800900",
    "end": "1807620"
  },
  {
    "text": "So what this thing here, this\nz is, that's a sort of normalizer.",
    "start": "1807620",
    "end": "1812720"
  },
  {
    "start": "1812720",
    "end": "1818750"
  },
  {
    "text": "And that makes that whole\ncombination of new weights add up to 1.",
    "start": "1818750",
    "end": "1823980"
  },
  {
    "text": "So it's whatever you got by\nadding up all those guys, and",
    "start": "1823980",
    "end": "1831570"
  },
  {
    "text": "then dividing by that number. Well, phew. ",
    "start": "1831570",
    "end": "1843030"
  },
  {
    "text": "I don't know. Now there's some\nit-turns-out-thats. ",
    "start": "1843030",
    "end": "1850360"
  },
  {
    "text": "We're going to imagine that\nsomebody's done the same sort of thing we did to the support\nvector machines. We're going to find a way\nto minimize the error.",
    "start": "1850360",
    "end": "1857730"
  },
  {
    "text": "And the error we're going to\nminimize is the error produced by that whole thing\nup there in 4. We're going to minimize the\nerror of that entire",
    "start": "1857730",
    "end": "1865120"
  },
  {
    "text": "expression as we go along.  And what we discover when\nwe do the appropriate",
    "start": "1865120",
    "end": "1871970"
  },
  {
    "text": "differentiations and stuff-- you know, that's what\nwe do in calculus-- what we discover is that you\nget minimum error for the",
    "start": "1871970",
    "end": "1884580"
  },
  {
    "text": "whole thing if alpha is equal\nto 1 minus the error rate at",
    "start": "1884580",
    "end": "1905970"
  },
  {
    "text": "time t, divided by the\nerror rate at time t.",
    "start": "1905970",
    "end": "1911190"
  },
  {
    "text": "Now let's take the logarithm\nof that, and multiply it by half.",
    "start": "1911190",
    "end": "1916220"
  },
  {
    "text": "And that's what [INAUDIBLE] was struggling to find. But we haven't quite\ngot it right.",
    "start": "1916220",
    "end": "1921350"
  },
  {
    "text": "And so let me add this in\nseparate chunks, so we don't get confused about this. It's a bound on that expression\nup there.",
    "start": "1921350",
    "end": "1932880"
  },
  {
    "text": "It's a bound on the error rate\nproduced by that expression. So interestingly enough, this\nmeans that the error rate can",
    "start": "1932880",
    "end": "1942540"
  },
  {
    "text": "actually go up as you add\nterms to this formula. all you know is that the error\nrate is going to be bounded by",
    "start": "1942540",
    "end": "1948560"
  },
  {
    "text": "an exponentially decaying\nfunction. So it's eventually guaranteed\nto converge on zero.",
    "start": "1948560",
    "end": "1956909"
  },
  {
    "text": "So it's a minimal error bound. It turns out to be\nexponential. ",
    "start": "1956910",
    "end": "1963120"
  },
  {
    "text": "Well, there it is. We're done. Would you like to see\na demonstration?",
    "start": "1963120",
    "end": "1968207"
  },
  {
    "text": "Yeah, OK. Because you look at that, and\nyou say, well, how could anything like that\npossibly work?",
    "start": "1968207",
    "end": "1973800"
  },
  {
    "text": "And the answer is, surprisingly\nenough, here's what happens.",
    "start": "1973800",
    "end": "1979720"
  },
  {
    "text": "There's a simple\nlittle example. So that's the first\ntest chosen.",
    "start": "1979720",
    "end": "1985309"
  },
  {
    "text": "the greens are pluses and the\nreds are minuses, so it's still got an error.",
    "start": "1985310",
    "end": "1991480"
  },
  {
    "text": "Still got an error-- boom. There, in two steps. It now has-- we can look in the upper\nright hand corner--",
    "start": "1991480",
    "end": "1996669"
  },
  {
    "text": "we see its used three\nclassifiers, and we see that one of those classifiers says\nthat everybody belongs to a",
    "start": "1996670",
    "end": "2002899"
  },
  {
    "text": "particular class, three\ndifferent weights. And the error rate has\nconverged to 0.",
    "start": "2002900",
    "end": "2010540"
  },
  {
    "text": "So let's look at a couple\nof other ones. Here is the one I use for\ndebugging this thing. We'll let that run.",
    "start": "2010540",
    "end": "2016250"
  },
  {
    "text": "See how fast it is? Boom. It converges to getting all the\nsamples right very fast.",
    "start": "2016250",
    "end": "2022799"
  },
  {
    "text": "Here's another one. This is one we gave on an\nexam a few years back. First test.",
    "start": "2022800",
    "end": "2028669"
  },
  {
    "text": "Oh, I let it run, so\nit got everything instantaneously right. Let's take that through\nstep at a time.",
    "start": "2028670",
    "end": "2033950"
  },
  {
    "text": "There's the first\none, second one. Still got a lot of errors. Ah, the error rate's dropping.",
    "start": "2033950",
    "end": "2041600"
  },
  {
    "text": "And then flattened, flattened,\nand it goes to 0. Cool, don't you think?",
    "start": "2041600",
    "end": "2048000"
  },
  {
    "text": "But you say to me, bah, who\ncares about that stuff? Let's try something\nmore interesting. There's one.",
    "start": "2048000",
    "end": "2054190"
  },
  {
    "text": "That was pretty fast, too. Well, there's not too\nmany samples here. So we can try this.",
    "start": "2054190",
    "end": "2060030"
  },
  {
    "text": "So there's an array of\npluses and minuses. Boom. You can see how that error\nrate is bounded by an exponential?",
    "start": "2060030",
    "end": "2066169"
  },
  {
    "text": " So in a bottom graph, you've got\nthe number of classifiers",
    "start": "2066170",
    "end": "2072799"
  },
  {
    "text": "involved, and that goes up to\na total, eventually, of 10. You can see how positive\nor negative each of the",
    "start": "2072800",
    "end": "2081230"
  },
  {
    "text": "classifiers that's added\nis by looking at this particular tab. And this just shows how\nthey evolve over time.",
    "start": "2081230",
    "end": "2088044"
  },
  {
    "text": "But the progress thing here\nis the most interesting. And now you say to me, well, how\ndid the machine do that?",
    "start": "2088045",
    "end": "2097420"
  },
  {
    "text": "And it's all right here. We use an alpha that\nlooks like this.",
    "start": "2097420",
    "end": "2105400"
  },
  {
    "text": "And that allows us to compute\nthe new weights. It says we've got a preliminary\ncalculation. We've got to find a z that\ndoes the normalization.",
    "start": "2105400",
    "end": "2113630"
  },
  {
    "text": "And we sure better bring our\ncalculator, because we've got, first of all, to calculate\nthe error rate.",
    "start": "2113630",
    "end": "2119349"
  },
  {
    "text": "Then we've got to take its\nlogarithm, divide by 2, plug it into that formula, take the\nexponent, and that gives us",
    "start": "2119350",
    "end": "2127290"
  },
  {
    "text": "the new weight. And that's how the\nprogram works. And if you try that,\nI guarantee you will flunk the exam.",
    "start": "2127290",
    "end": "2133130"
  },
  {
    "text": "Now, I don't care about\nmy computer. I really don't. It's a slave, and it can\ncalculate these logarithm and",
    "start": "2133130",
    "end": "2139049"
  },
  {
    "text": "exponentials till it turns\nblue, and I don't care. Because I've got four cores or\nsomething, and who cares.",
    "start": "2139050",
    "end": "2144740"
  },
  {
    "text": "Might as well do this,\nthan sit around just burning up heat. But you don't want to do that. So what you want to do is you\nwant to know how to do this",
    "start": "2144740",
    "end": "2153010"
  },
  {
    "text": "sort of thing more\nexpeditiously. So we're going to have to let\nthem the math sing to us a",
    "start": "2153010",
    "end": "2160720"
  },
  {
    "text": "little bit, with a view towards\nfinding better ways of doing this sort of thing.",
    "start": "2160720",
    "end": "2168290"
  },
  {
    "text": "So let's do that. And we're going to run out of\nspace here before long, so let",
    "start": "2168290",
    "end": "2174079"
  },
  {
    "text": "me reclaim as much of\nthis board as I can. So what I'm going to do is I'm\ngoing to say, well, now that",
    "start": "2174080",
    "end": "2180940"
  },
  {
    "text": "we've got this formula for alpha\nthat relates alpha t to the error, then I can plug\nthat into this formula up",
    "start": "2180940",
    "end": "2191530"
  },
  {
    "text": "here, number 6. And what I'll get is that the\nweight of t plus 1 is equal to",
    "start": "2191530",
    "end": "2200390"
  },
  {
    "text": "the weight at t divided by\nthat normalizing factor,",
    "start": "2200390",
    "end": "2206710"
  },
  {
    "text": "multiplied times something that\ndepends on whether it's",
    "start": "2206710",
    "end": "2213349"
  },
  {
    "text": "categorized correctly or not. That's what that y's in\ntheir for, right?",
    "start": "2213350",
    "end": "2219660"
  },
  {
    "text": "So we've got a logarithm here,\nand we got a sign flipper up",
    "start": "2219660",
    "end": "2225630"
  },
  {
    "text": "there in terms of that H\nof x and y combination.",
    "start": "2225630",
    "end": "2230690"
  },
  {
    "text": "So if the sign of that whole\nthing at minus alpha and that",
    "start": "2230690",
    "end": "2238220"
  },
  {
    "text": "y H combination turns out to be\nnegative, then we're going",
    "start": "2238220",
    "end": "2243900"
  },
  {
    "text": "to have to flip the numerator\nand denominator here in this logarithm, right?",
    "start": "2243900",
    "end": "2249619"
  },
  {
    "text": "And oh, by the way, since we've\ngot a half out here, that turns out to be the square\nroot of that term inside the logarithm.",
    "start": "2249620",
    "end": "2257190"
  },
  {
    "text": "So when we carefully do that,\nwhat we discover is that it",
    "start": "2257190",
    "end": "2263290"
  },
  {
    "text": "depends on whether it's the\nright thing or not. But what it turns out to be is\nsomething like a multiplier of",
    "start": "2263290",
    "end": "2270859"
  },
  {
    "text": "the square root. Better be careful, here.",
    "start": "2270860",
    "end": "2275960"
  },
  {
    "text": "The square root of what? STUDENT: [INAUDIBLE].",
    "start": "2275960",
    "end": "2282030"
  },
  {
    "text": "PATRICK WINSTON: Well,\nlet's see. But we have to be careful. So let's suppose that this is 4\nthings that we get correct.",
    "start": "2282030",
    "end": "2288180"
  },
  {
    "start": "2288180",
    "end": "2293740"
  },
  {
    "text": "So if we get it correct, then\nwe're going to get the same sign out of H of x and y.",
    "start": "2293740",
    "end": "2300200"
  },
  {
    "text": "We've get a minus sign out\nthere, so we're going to flip the numerator and denominator.",
    "start": "2300200",
    "end": "2305500"
  },
  {
    "text": "So we're going to get the square\nroot of e of t over 1 minus epsilon of t if\nthat's correct.",
    "start": "2305500",
    "end": "2314109"
  },
  {
    "text": "If it's wrong, it'll just\nbe the flip of that. ",
    "start": "2314110",
    "end": "2319350"
  },
  {
    "text": "So it'll be the square root of\n1 minus the error rate over",
    "start": "2319350",
    "end": "2324690"
  },
  {
    "text": "the error rate.  Everybody with me on that?",
    "start": "2324690",
    "end": "2329740"
  },
  {
    "text": "I think that's right. If it's wrong, I'll have to hang\nmyself and wear a paper",
    "start": "2329740",
    "end": "2335930"
  },
  {
    "text": "bag over my head like\nI did last year. But let's see if we can make\nthis go correctly this time. ",
    "start": "2335930",
    "end": "2345730"
  },
  {
    "text": "So now, we've got this guy here,\nwe've got everything",
    "start": "2345730",
    "end": "2352430"
  },
  {
    "text": "plugged in all right, and we\nknow that now this z ought to",
    "start": "2352430",
    "end": "2358109"
  },
  {
    "text": "be selected so that it's equal\nto the sum of this guy multiplied by these things as\nappropriate for whether it's",
    "start": "2358110",
    "end": "2365069"
  },
  {
    "text": "correct or not. Because we want, in the end,\nfor all of these w's",
    "start": "2365070",
    "end": "2371710"
  },
  {
    "text": "to add up to 1. So let's see what they add up\nto without the z there.",
    "start": "2371710",
    "end": "2379830"
  },
  {
    "text": "So what we know is that it must\nbe the case that if we",
    "start": "2379830",
    "end": "2384840"
  },
  {
    "text": "add over the correct ones, we\nget the square root of the",
    "start": "2384840",
    "end": "2393670"
  },
  {
    "text": "error rate over 1 minus the\nrate of the Wt plus 1.",
    "start": "2393670",
    "end": "2399930"
  },
  {
    "text": " Plus now we've got the sum of\n1 minus the error rate over",
    "start": "2399930",
    "end": "2409520"
  },
  {
    "text": "the error rate, times the sum of\nthe Wi at time t for wrong.",
    "start": "2409520",
    "end": "2416010"
  },
  {
    "start": "2416010",
    "end": "2424340"
  },
  {
    "text": "So that's what we get if\nwe added all these up without the z.",
    "start": "2424340",
    "end": "2430420"
  },
  {
    "text": "So since everything has to add\nup to 1, then z ought to be equal to this sum. ",
    "start": "2430420",
    "end": "2443880"
  },
  {
    "text": "That looks pretty horrible,\nuntil we realize that if we add these guys up over the\nweights that are wrong, that",
    "start": "2443880",
    "end": "2451930"
  },
  {
    "text": "is the error rate.  This is e.",
    "start": "2451930",
    "end": "2457130"
  },
  {
    "text": " So therefore, z is equal the\nsquare root of the error rate",
    "start": "2457130",
    "end": "2468540"
  },
  {
    "text": "times 1 minus the error rate. That's the contribution\nof this term.",
    "start": "2468540",
    "end": "2474040"
  },
  {
    "text": "Now, let's see. What is the sum of the\nweights over the ones that are correct?",
    "start": "2474040",
    "end": "2480320"
  },
  {
    "text": "Well, that must be 1 minus\nthe error rate. Ah, so this thing gives you the\nsame result as this one.",
    "start": "2480320",
    "end": "2490290"
  },
  {
    "text": "So z is equal to 2 times that. And that's a good thing.",
    "start": "2490290",
    "end": "2495420"
  },
  {
    "text": " Now we are getting somewhere.",
    "start": "2495420",
    "end": "2500540"
  },
  {
    "text": "Because now, it becomes a little\nbit easier to write some things down.",
    "start": "2500540",
    "end": "2506490"
  },
  {
    "text": "Well, we're way past this,\nso let's get rid of this. ",
    "start": "2506490",
    "end": "2514090"
  },
  {
    "text": "And now we can put some\nthings together. Let me point out what I'm\nputting together.",
    "start": "2514090",
    "end": "2520910"
  },
  {
    "text": "I've got an expression\nfor z right here.",
    "start": "2520910",
    "end": "2526559"
  },
  {
    "text": "And I've got an expression\nfor the new w's here. So let's put those together and\nsay that w of t plus 1 is",
    "start": "2526560",
    "end": "2539020"
  },
  {
    "text": "equal to w of t. I guess we're going to\ndivide that by 2.",
    "start": "2539020",
    "end": "2546089"
  },
  {
    "text": "And then we've got this square\nroot times that expression.",
    "start": "2546090",
    "end": "2553470"
  },
  {
    "text": "So if we take that correct one,\nand divide by that one,",
    "start": "2553470",
    "end": "2560470"
  },
  {
    "text": "then the [INAUDIBLE] cancel out, and I get 1 over\n1 minus the error rate.",
    "start": "2560470",
    "end": "2570359"
  },
  {
    "text": " That's it. That's correct. ",
    "start": "2570360",
    "end": "2579880"
  },
  {
    "text": "And if it's not correct,\nthen it's Wt over 2-- and working through the math--",
    "start": "2579880",
    "end": "2585670"
  },
  {
    "text": "1 over epsilon, if wrong. ",
    "start": "2585670",
    "end": "2591950"
  },
  {
    "text": "Do we feel like we're\nmaking any progress? No. Because we haven't let it\nsing to us enough yet.",
    "start": "2591950",
    "end": "2599090"
  },
  {
    "text": "So I want to draw your attention\nto what happens to",
    "start": "2599090",
    "end": "2605130"
  },
  {
    "text": "amateur rock climbers\nwhen they're halfway up a difficult cliff.",
    "start": "2605130",
    "end": "2611360"
  },
  {
    "text": "They're usually [INAUDIBLE],\nsometimes they're not. If they're not, they're\nscared to death.",
    "start": "2611360",
    "end": "2616800"
  },
  {
    "text": "And every once in a while, as\nthey're just about to fall, they find some little tiny hole\nto stick a fingernail in,",
    "start": "2616800",
    "end": "2624410"
  },
  {
    "text": "and that keeps them\nfrom falling. That's called a thank-god\nhole.",
    "start": "2624410",
    "end": "2630440"
  },
  {
    "text": "So what I'm about to introduce\nis the analog of those little places where you can stick\nyour fingernail in.",
    "start": "2630440",
    "end": "2635530"
  },
  {
    "text": "It's the thank-god\nhole for dealing with boosting problems. ",
    "start": "2635530",
    "end": "2644680"
  },
  {
    "start": "2642000",
    "end": "3099000"
  },
  {
    "text": "So what happens if I add\nall these [? Wi ?] up for the ones that the\nclassifier where produces a",
    "start": "2644680",
    "end": "2652470"
  },
  {
    "text": "correct answer on? Well, it'll be 1 over 2, and 1\nover 1 minus epsilon, times",
    "start": "2652470",
    "end": "2662110"
  },
  {
    "text": "the sum of the Wt for which\nthe answer was correct.",
    "start": "2662110",
    "end": "2669490"
  },
  {
    "text": "What's this sum? Oh! My goddess. 1 minus epsilon.",
    "start": "2669490",
    "end": "2678920"
  },
  {
    "text": "So what I've just discovered is\nthat if I sum new w's over",
    "start": "2678920",
    "end": "2690920"
  },
  {
    "text": "those samples for which I\ngot a correct answer, it's equal to 1/2.",
    "start": "2690920",
    "end": "2696490"
  },
  {
    "text": "And guess what? That means that if I sum them\nover wrong, it's equal to 1/2",
    "start": "2696490",
    "end": "2703240"
  },
  {
    "text": "half as well.  So that means that I take all of\nthe weight for which I got",
    "start": "2703240",
    "end": "2711300"
  },
  {
    "text": "the right answer with the\nprevious test, and those ways",
    "start": "2711300",
    "end": "2718000"
  },
  {
    "text": "will add up to something. And to get the weights for the\nnext generation, all I have to do is scale them so that\nthey equal half.",
    "start": "2718000",
    "end": "2724780"
  },
  {
    "text": "This was not noticed\nby the people who developed this stuff. This was noticed by Luis\nOrtiz, who was a 6.034",
    "start": "2724780",
    "end": "2731210"
  },
  {
    "text": "instructor a few years ago. The sum of those weights is\ngoing to be a scaled version",
    "start": "2731210",
    "end": "2738660"
  },
  {
    "text": "of what they were before. So you take all the weights\nfor which this new classifier--",
    "start": "2738660",
    "end": "2744590"
  },
  {
    "text": "this one you selected to give\nyou the minimum weight on the re-weighted stuff-- you take the ones that it gives\na correct answer for,",
    "start": "2744590",
    "end": "2750520"
  },
  {
    "text": "and you take all of those\nweights, and you just scale them so they add up to 1/2.",
    "start": "2750520",
    "end": "2755770"
  },
  {
    "text": "So do you have to compute\nany logarithms? No. Do you have to compute\nany exponentials?",
    "start": "2755770",
    "end": "2761319"
  },
  {
    "text": "No. Do you have to calculate z? No. Do you have to calculate alpha\nto get the new weights?",
    "start": "2761320",
    "end": "2767119"
  },
  {
    "text": "No. All you have to do\nis scale them. And that's a pretty good\nthank-god hole.",
    "start": "2767120",
    "end": "2772730"
  },
  {
    "text": "So that's thank-god\nhole number one. ",
    "start": "2772730",
    "end": "2781890"
  },
  {
    "text": "Now, for thank-god hole number\ntwo, we need to go back and think about the fact that were\ngoing to give you problems in",
    "start": "2781890",
    "end": "2788720"
  },
  {
    "text": "probability that involve\ndecision tree stumps. And there are a lot of decision\ntree stumps that you",
    "start": "2788720",
    "end": "2795790"
  },
  {
    "text": "might have to pick from. So we need a thank-god\nhole for deciding how to deal with that.",
    "start": "2795790",
    "end": "2802319"
  },
  {
    "text": "Where can I find some room? How about right here. ",
    "start": "2802320",
    "end": "2813870"
  },
  {
    "text": "Suppose you've got a space\nthat looks like this. ",
    "start": "2813870",
    "end": "2822810"
  },
  {
    "text": "I'm just makings this\nup at random. So how many-- let's see. 1, 2, 3, 4, 5, 6,\n7, 8, 9, 10, 11.",
    "start": "2822810",
    "end": "2831300"
  },
  {
    "text": "How many tests do I have to\nconsider in that dimension? ",
    "start": "2831300",
    "end": "2837598"
  },
  {
    "text": "11. It's 1 plus the number\nof samples. That would be horrible.",
    "start": "2837598",
    "end": "2843310"
  },
  {
    "text": " I don't know. Do I have actually calculate\nthis one?",
    "start": "2843310",
    "end": "2848990"
  },
  {
    "text": " How could that possibly be\nbetter than that one?",
    "start": "2848990",
    "end": "2856430"
  },
  {
    "text": "It's got one more thing wrong. So that one makes sense.",
    "start": "2856430",
    "end": "2865569"
  },
  {
    "text": "The other one doesn't\nmake sense. So in the end, no test that\nlies between two correctly",
    "start": "2865570",
    "end": "2875520"
  },
  {
    "text": "classified samples will\never be any good. So that one's a good guy, and\nthat one's a good guy.",
    "start": "2875520",
    "end": "2881830"
  },
  {
    "text": "And this one's a bad guy. Bad guy, bad guy bad\nguy, bad guy. Bad guy, bad guy, bad buy.",
    "start": "2881830",
    "end": "2888910"
  },
  {
    "text": "So the actual number of tests\nyou've got is three.",
    "start": "2888910",
    "end": "2894410"
  },
  {
    "text": "And likewise, in the\nother dimension-- well, I haven't drawn it so well\nhere, but would this test",
    "start": "2894410",
    "end": "2899960"
  },
  {
    "text": "be a good one? No. That one? No.  Actually, I'd better look over\nhere on the right and see what",
    "start": "2899960",
    "end": "2906465"
  },
  {
    "text": "I've got before I draw\ntoo many conclusions. Let's look over this, since I\ndon't want to think too hard about what's going on in\nthe other dimension.",
    "start": "2906465",
    "end": "2912980"
  },
  {
    "text": "But the idea is that\nvery few of those tests actually matter.",
    "start": "2912980",
    "end": "2918240"
  },
  {
    "text": "Now, you say to me, there's\none last thing. What about overfitting? Because all this does is drape\na solution over the samples.",
    "start": "2918240",
    "end": "2925800"
  },
  {
    "text": "And like support vector machines\noverfit, neural maps overfit, identification\ntrees overfit.",
    "start": "2925800",
    "end": "2932580"
  },
  {
    "text": "Guess what? This doesn't seem to overfit. That's an experimental\nresult for which the",
    "start": "2932580",
    "end": "2939130"
  },
  {
    "text": "literature is confused. It goes back to providing\nan explanation. So this stuff is tried on all\nsorts of problems, like",
    "start": "2939130",
    "end": "2946210"
  },
  {
    "text": "handwriting recognition,\nunderstanding speech, all sorts of stuff uses boosting.",
    "start": "2946210",
    "end": "2952180"
  },
  {
    "text": "And unlike other methods, for\nsome reason as yet imperfectly understood, it doesn't\nseem to overfit.",
    "start": "2952180",
    "end": "2960260"
  },
  {
    "text": "But in the end, they leave no\nstone unturned in 6.034.",
    "start": "2960260",
    "end": "2965550"
  },
  {
    "text": "Every time we do this, we do\nsome additional experiments. So here's a sample that\nI'll leave you with.",
    "start": "2965550",
    "end": "2972410"
  },
  {
    "text": "Here's a situation in which we\nhave a 10-dimensional space. We've made a fake distribution,\nand then we put",
    "start": "2972410",
    "end": "2978269"
  },
  {
    "text": "in that boxed outlier. That was just put into the space\nat random, so it can be viewed as an error point.",
    "start": "2978270",
    "end": "2985230"
  },
  {
    "text": "So now what we're going to do\nis we're going to see what happens when we run that guy. And sure enough, in 17 steps,\nit finds a solution.",
    "start": "2985230",
    "end": "2995140"
  },
  {
    "text": "But maybe it's overfit that\nlittle guy who's an error. But one thing you can do is\nyou can say, well, all of",
    "start": "2995140",
    "end": "3003000"
  },
  {
    "text": "these classifiers are dividing\nthis space up into chunks, and we can compute the size of the\nspace occupied by any sample.",
    "start": "3003000",
    "end": "3011750"
  },
  {
    "text": "So one thing we can do-- alas, I'll have to get up\na new demonstration. One thing we can do, now that\nthis guy's over here, we can",
    "start": "3011750",
    "end": "3019750"
  },
  {
    "text": "switch the volume tab and watch\nhow the volume occupied by that error point evolves\nas we solve the problem.",
    "start": "3019750",
    "end": "3029640"
  },
  {
    "text": "So look what happens. This is, of course, randomly\ngenerated. I'm counting on this working.",
    "start": "3029640",
    "end": "3035390"
  },
  {
    "text": "Never failed before.  So it originally starts\nout as occupying 26%",
    "start": "3035390",
    "end": "3044510"
  },
  {
    "text": "of the total volume. It ends up occupying\n1.4 times 10 to the",
    "start": "3044510",
    "end": "3052360"
  },
  {
    "text": "minus 3rd% of the volume. So what tends to happen is\nthat these decision tree",
    "start": "3052360",
    "end": "3060059"
  },
  {
    "text": "stumps tend to wrap themselves\nso tightly around the error points, there's no room for\noverfitting, because nothing",
    "start": "3060060",
    "end": "3065349"
  },
  {
    "text": "else will fit in that\nsame volume. So that's why I think that this\nthing tends to produce",
    "start": "3065350",
    "end": "3070390"
  },
  {
    "text": "solutions which don't overfit. So in conclusion,\nthis is magic. You always want to use it.",
    "start": "3070390",
    "end": "3076010"
  },
  {
    "text": "It'll work with any kind\nof [? speed ?] of classifiers you want. And you should understand it\nvery thoroughly, because of",
    "start": "3076010",
    "end": "3081590"
  },
  {
    "text": "anything is useful in the\nsubject in dimension learning, this is it.",
    "start": "3081590",
    "end": "3086990"
  },
  {
    "start": "3086990",
    "end": "3099900"
  }
]
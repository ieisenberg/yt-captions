[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5580",
    "end": "12270"
  },
  {
    "text": "To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12270",
    "end": "18830"
  },
  {
    "text": "at ocw.mit.edu. EERO SIMONCELLI: I'm going\nto talk about a bunch of work",
    "start": "18830",
    "end": "24830"
  },
  {
    "text": "that we've been\ndoing over the last-- it's about four years, on\ntrying to understand basically,",
    "start": "24830",
    "end": "32029"
  },
  {
    "text": "that terra incognita that\nGabrielle just mentioned that lies between V1 and IT.",
    "start": "32030",
    "end": "37296"
  },
  {
    "text": "I brought this back with\nme from the Dolomites, where I was last\nweek with my family. And when you sit\nand you look at it",
    "start": "37296",
    "end": "43610"
  },
  {
    "text": "and that image\ncomes into your eyes and gets processed\nby your brain, there's a lot of\ninformation there.",
    "start": "43610",
    "end": "48840"
  },
  {
    "text": "It's a lot of pixels. And the question that\nI'm going to start with is, where does it go? You have all this information.",
    "start": "48840",
    "end": "54590"
  },
  {
    "text": "It's flooding into your\neyes all day every day for your entire lifetime. Obviously, you don't\nstore it all there.",
    "start": "54590",
    "end": "59920"
  },
  {
    "text": "Your head doesn't\ninflate until it gets to the point of explosion. So where does it go?",
    "start": "59920",
    "end": "65930"
  },
  {
    "text": "And as a theorist's\ndiagram of the brain-- a square with rounded corners.",
    "start": "65930",
    "end": "71450"
  },
  {
    "text": "In comes the information,\nand there are really only three options. You either act on\nthe information,",
    "start": "71450",
    "end": "76640"
  },
  {
    "text": "do something with it,\nsensory motor loops, or for complex organisms\nespecially, a fair amount of it",
    "start": "76640",
    "end": "83630"
  },
  {
    "text": "you might actually\ntry to remember. You might hold on to, and we\nheard about that earlier today.",
    "start": "83630",
    "end": "88880"
  },
  {
    "text": "But this really\nonly accounts for, I think, a fairly\nsmall portion of what goes on, because a lot\nof it you throw away.",
    "start": "88880",
    "end": "95420"
  },
  {
    "text": "You have to. You really don't have a choice. You have to summarize\nit, squeeze it down to the relevant bits that\nyou're going to hold on to",
    "start": "95420",
    "end": "102564"
  },
  {
    "text": "or act on, and the rest\nof it you just toss. So the question is, how can\nwe exploit that basic fact?",
    "start": "102564",
    "end": "110000"
  },
  {
    "text": "It's an obvious fact. It has to be true. How do we exploit that\nto understand something about what the system does\nand what it doesn't do?",
    "start": "110000",
    "end": "116912"
  },
  {
    "text": "And there's a long\nhistory to this, and in fact, since I come from\nvision and most of my work",
    "start": "116912",
    "end": "122000"
  },
  {
    "text": "is centered on vision and\nauditory system to some extent, the vision scientists were\nthe first to recognize",
    "start": "122000",
    "end": "129918"
  },
  {
    "text": "the importance of this. And it really is a\nfoundational chunk of work in the beginning\nof the field that",
    "start": "129919",
    "end": "138260"
  },
  {
    "text": "set in motion a lot of\nthings that we currently know about vision. And so I'm going to just--\nfor those of you that don't know that story,\nI'm going to give",
    "start": "138260",
    "end": "144876"
  },
  {
    "text": "a very, very brief\nreminder of what that is, because I\nthink it's an absolutely fantastic scientific story.",
    "start": "144876",
    "end": "151430"
  },
  {
    "text": "And then from there,\nI'll talk about texture. So two examples-- I'm\ngoing to quickly say",
    "start": "151430",
    "end": "156500"
  },
  {
    "text": "something about\ntrichomatic color vision, and then I'm going to\ntalk about texture, and then we'll go into V2 and\nmetamers and other things.",
    "start": "156500",
    "end": "164730"
  },
  {
    "text": "So trichromacy--\nNewton figured out that light comes in wavelengths.",
    "start": "164730",
    "end": "172300"
  },
  {
    "text": "He split light with a prism. There's the picture drawing\nof him splitting light coming",
    "start": "172300",
    "end": "177421"
  },
  {
    "text": "in through a hole in the wall. He split it with a prism into\nwavelengths, saw a rainbow, did a lot of\nexperiments to recognize",
    "start": "177421",
    "end": "183726"
  },
  {
    "text": "that you could take that\nrainbow and reassemble it into white light, but you\ncouldn't further subdivide it,",
    "start": "183727",
    "end": "189170"
  },
  {
    "text": "and basically gave\nus the foundations for thinking about light\nand spectral distributions.",
    "start": "189170",
    "end": "196340"
  },
  {
    "text": "In the 1800s, a\ngroup of people that were combined physicists,\nmathematicians,",
    "start": "196340",
    "end": "201560"
  },
  {
    "text": "and psychologists\nall rolled into one-- and there were\nquite a few of them. Helmholtz was one of them.",
    "start": "201560",
    "end": "207006"
  },
  {
    "text": "Grassmann was one of\nthe most important ones. I'll mention him\nagain in a moment-- figured out something\npeculiar about human vision--",
    "start": "207006",
    "end": "213800"
  },
  {
    "text": "that even though there was\nthis huge array of colors in the wavelengths\nin the spectrum,",
    "start": "213800",
    "end": "219860"
  },
  {
    "text": "that humans actually had these\ndeficits that we were not able to actually sense\nor discriminate things",
    "start": "219860",
    "end": "225490"
  },
  {
    "text": "that it seemed like\nwe should be able to. And it boiled down in\nthe end, after a lot of study and discussion\nand theorizing,",
    "start": "225490",
    "end": "233050"
  },
  {
    "text": "to this experiment, which is\nknown as a bipartite color",
    "start": "233050",
    "end": "239030"
  },
  {
    "text": "matching experiment. So on the left side of\nthis little display, here's a gray annulus. In the middle is a circle.",
    "start": "239030",
    "end": "245330"
  },
  {
    "text": "On the left side of this is\nlight coming from some source. It has some spectral\ndistribution illustrated here.",
    "start": "245330",
    "end": "250979"
  },
  {
    "text": "This is all a cartoon,\nbut just to give you the idea of how this works. On the right side are\nthree primary lights.",
    "start": "250979",
    "end": "258109"
  },
  {
    "text": "And the job of the observer in\nthis experiment is to adjust, let's say, sliders\nor knobs in order",
    "start": "258110",
    "end": "263900"
  },
  {
    "text": "to change the intensity\nof these three lights to make the light on the right\nside of this split circle",
    "start": "263900",
    "end": "270350"
  },
  {
    "text": "look the same as the\nlight on the left side. And it turns out that-- so just to be clear,\nso these three things",
    "start": "270350",
    "end": "277340"
  },
  {
    "text": "have their own\nspectral distributions. They might look like\nthat, for example. And when the observer comes\nup with the knob settings,",
    "start": "277340",
    "end": "284294"
  },
  {
    "text": "they're going to\nproduce something that might look like that. This is just a sum of the\nthree copies of these spectra",
    "start": "284294",
    "end": "290150"
  },
  {
    "text": "weighted by the knob settings. So this is a linear\ncombination of three spectral distributions.",
    "start": "290150",
    "end": "296180"
  },
  {
    "text": "And intentionally,\nI've drawn this so that they don't\nlook the same, because that's the whole\npoint of the experiment.",
    "start": "296180",
    "end": "301430"
  },
  {
    "text": "It turns out that humans-- you can do this experiment,\nand that any human",
    "start": "301430",
    "end": "307580"
  },
  {
    "text": "with normal color vision\ncan make these settings so that these two things are\nabsolutely indistinguishable. They look identical, and yet\nthey knew even in the mid-1800s",
    "start": "307580",
    "end": "316400"
  },
  {
    "text": "that these two things have\nvery different spectra, and I've drawn it that\nway intentionally. So the point is that\nhumans are obviously--",
    "start": "316400",
    "end": "322860"
  },
  {
    "text": "even though we can see all\nthe bands of the spectrum, we can see all the colors-- we actually have this\ndeficiency in terms",
    "start": "322860",
    "end": "328400"
  },
  {
    "text": "of noticing the difference\nbetween these two things. So how can that be? And I think and hope\nthat most of you",
    "start": "328400",
    "end": "335005"
  },
  {
    "text": "know the answer\nto that question, because you're using\ndevices every day that are exploiting this fact.",
    "start": "335006",
    "end": "340490"
  },
  {
    "text": "But the bottom line is that in\nthe 1850s Grassmann laid down a set of rules.",
    "start": "340490",
    "end": "345500"
  },
  {
    "text": "Grassmann was a mathematician. He actually developed a\nlarge chunk of linear algebra in order to explain and\nunderstand and manipulate",
    "start": "345500",
    "end": "352130"
  },
  {
    "text": "these ideas. And he pointed out that-- he actually had a set of\nlaws that he laid out,",
    "start": "352130",
    "end": "357722"
  },
  {
    "text": "and I won't drag you\nthrough all of that. But in the end, what\nall of those laws amounted to, taking into account\nall of the evidence that he",
    "start": "357722",
    "end": "364820"
  },
  {
    "text": "had, he laid down these laws. And what it amounted to\nis that the human being, when setting these knobs, was\nacting like a linear system.",
    "start": "364820",
    "end": "372889"
  },
  {
    "text": "The human was taking an input,\nwhich is a wavelength spectrum, and adjusting the knobs. And the settings of the\nknobs were a linear function",
    "start": "372890",
    "end": "380270"
  },
  {
    "text": "of the wavelength spectrum\nthat was coming into the eye. And it's a remarkable\nand amazing fact,",
    "start": "380270",
    "end": "387650"
  },
  {
    "text": "if you know that the brain is\na highly non-linear device, how is it that a human can\nact like a linear device?",
    "start": "387650",
    "end": "394380"
  },
  {
    "text": "And the answer is that basically\nthe human, taking this thing in and making the knob settings,\nhas a front end that's linear",
    "start": "394380",
    "end": "401440"
  },
  {
    "text": "and is doing a projection\nof the wavelength spectrum onto basically three axes. And those three measurements--",
    "start": "401440",
    "end": "408140"
  },
  {
    "text": "that process is linear. Everything that\nhappens after that, which is complicated and\nnon-linear and involves noise",
    "start": "408140",
    "end": "414172"
  },
  {
    "text": "and decisions and all kinds of\nmotor control and everything else-- as long as the information\nin those original three",
    "start": "414172",
    "end": "419510"
  },
  {
    "text": "measurements is not\nlost, then the human is going to basically\nact like a linear system, in terms of doing this matching.",
    "start": "419510",
    "end": "426050"
  },
  {
    "text": "So Grassmann realized this. The theory that he set out and\nthat others then elaborated on",
    "start": "426050",
    "end": "432800"
  },
  {
    "text": "perfectly explained all the\ndata for normal human subjects, that lights that appear\nidentical but had physically",
    "start": "432800",
    "end": "438800"
  },
  {
    "text": "distinct wavelength\nspectra could be created, and they called these metamers-- two things that are physically\ndifferent but look the same.",
    "start": "438800",
    "end": "447120"
  },
  {
    "text": "This was codified. It took many, many decades. Things moved slower back then. We don't have these rapid,\nGoogle-style overturns",
    "start": "447120",
    "end": "455240"
  },
  {
    "text": "of scientific establishment\nwithin a year or two. It took until the 1930s\nto actually build this",
    "start": "455240",
    "end": "461120"
  },
  {
    "text": "into a set of standards that\nwere used in the engineering community to generate and\ncreate color film, color",
    "start": "461120",
    "end": "466759"
  },
  {
    "text": "devices, eventually color\nvideo, color monitors, color projectors, color printers--\neverything else that we use.",
    "start": "466760",
    "end": "472820"
  },
  {
    "text": "And these specifications were\nto allow the reproduction of colors so that they\nlooked the way they",
    "start": "472820",
    "end": "478190"
  },
  {
    "text": "were supposed to look. So you record color\nwith a camera. It turns out that your camera is\nalso only recording three color",
    "start": "478190",
    "end": "484219"
  },
  {
    "text": "channels, just like\nyour eye, and then you have to be able to re-render\nthat on another device. And these standards\nspecify how to do that.",
    "start": "484220",
    "end": "492766"
  },
  {
    "text": "The surprising thing\nin the whole story is-- so this is 1850s. Well, we go back to Newton. It was a 1600s.",
    "start": "492766",
    "end": "498150"
  },
  {
    "text": "Then in the 1850s, when we're\ngetting this beautiful theory that's very, very\nprecise, this gets built",
    "start": "498150",
    "end": "503750"
  },
  {
    "text": "into engineering standards. And it's not until\n1987 that it actually gets verified in a\nmechanistic sense.",
    "start": "503750",
    "end": "509644"
  },
  {
    "text": "And I like to tell\nthis story, because I think it's a reminder\nthat aiming always for the reductionist solution is\nnot necessarily the right thing",
    "start": "509644",
    "end": "517849"
  },
  {
    "text": "to do. This is a very beautiful\npiece of science that was done at\nStanford, actually,",
    "start": "517850",
    "end": "523250"
  },
  {
    "text": "by Baylor, Nunn, and Schnapf. They took cones from a macaque--",
    "start": "523250",
    "end": "529967"
  },
  {
    "text": "I think originally they worked\nwith turtles, but then macaque, sucked them up into a\nglass micro-pipette, shined monochromatic\nlights through them,",
    "start": "529967",
    "end": "536570"
  },
  {
    "text": "and measured their\nabsorption properties. And they found these\nthree functions for three different types\nof cones and verified,",
    "start": "536570",
    "end": "542839"
  },
  {
    "text": "basically, that these three\nabsorption spectra perfectly explained the data\nfrom the 1800s.",
    "start": "542840",
    "end": "549212"
  },
  {
    "text": "So this is an\namazing thing, if you can have a theory and a set\nof behavioral experiments that make very precise and\nclear predictions that then get",
    "start": "549212",
    "end": "557330"
  },
  {
    "text": "verified and tested\nin a mechanistic sense more than 100 years later,\nand they come out basically perfect.",
    "start": "557330",
    "end": "563009"
  },
  {
    "text": "So it's an astounding,\nastounding sequence, in my view. So what we wanted\nto do is to set out",
    "start": "563010",
    "end": "570860"
  },
  {
    "text": "trying to do the same kind\nof thing for pattern vision. And we're going to do that\nby thinking about texture.",
    "start": "570860",
    "end": "577100"
  },
  {
    "text": "So what's a texture? A texture is an image\nthat's homogeneous with repeated structures. So each of these are\nexamples of texture.",
    "start": "577100",
    "end": "583478"
  },
  {
    "text": "That's a piece of woven basket. This is tree bark. That's a herringbone\npattern, and these are some sort of nuts or stones.",
    "start": "583478",
    "end": "590780"
  },
  {
    "text": "And each of these\nhas the property that there's lots of repeated\nelements with some variability. Sometimes there's\nmore variability,",
    "start": "590780",
    "end": "596810"
  },
  {
    "text": "sometimes there's\nless variability, but there's usually\nat least some. And of course, these\nthings are ubiquitous.",
    "start": "596810",
    "end": "603290"
  },
  {
    "text": "When I started working on this,\nwhich is about 15 years ago-- maybe a little bit\nmore, 16 years ago--",
    "start": "603290",
    "end": "608970"
  },
  {
    "text": "I started photographing things\nthat I saw as I walked around, and textures are everywhere. Most things are textured.",
    "start": "608970",
    "end": "615090"
  },
  {
    "text": "The world is not\nmade up of plain-- of Mondrians. It's not made up of\nthings that are plain,",
    "start": "615090",
    "end": "620160"
  },
  {
    "text": "blank colors separated\nby sharp edges. It's made up of\ntextures, and often",
    "start": "620160",
    "end": "626730"
  },
  {
    "text": "the boundaries between things\nare boundaries between things that are textured objects, like\nthe seats in the auditorium,",
    "start": "626730",
    "end": "631890"
  },
  {
    "text": "for example. So how is it that we can go\nabout thinking about this",
    "start": "631890",
    "end": "637139"
  },
  {
    "text": "in terms of metamers and\nrepresentation in, let's say, the visual system? And the idea really\ncomes from Julesz,",
    "start": "637140",
    "end": "642959"
  },
  {
    "text": "who proposed in 1962 a famous\ntheory that he later abandoned.",
    "start": "642960",
    "end": "648210"
  },
  {
    "text": "The theory goes like this. First of all, he said\nthe thing that we're going to do to try to\ndescribe textures is",
    "start": "648210",
    "end": "653951"
  },
  {
    "text": "we're going to use statistics. And why statistics? Because these are\nsupposed to be variables, so I need some stochasticity.",
    "start": "653951",
    "end": "659384"
  },
  {
    "text": "But I also want something\nthat's homogeneous, so I'm going to average\nor measure things averaged across the entire image.",
    "start": "659385",
    "end": "665339"
  },
  {
    "text": "That's the statistical\nside of it. And he proposed that, well, if\nI start by measuring just pixel",
    "start": "665340",
    "end": "672580"
  },
  {
    "text": "statistics-- say single\npixel statistics, pairwise pixels statistics,\nmaybe triples of pixels,",
    "start": "672580",
    "end": "679230"
  },
  {
    "text": "eventually I should reach a\npoint where I've made enough measurements to actually\nsufficiently constrain",
    "start": "679230",
    "end": "685410"
  },
  {
    "text": "the texture such that any two\ntextures that have the same statistics up to that--",
    "start": "685410",
    "end": "691470"
  },
  {
    "text": "whatever that order is, should\nlook the same to a human being. And he didn't talk about\nthis in physiological terms,",
    "start": "691470",
    "end": "699240"
  },
  {
    "text": "but I think in the background\nis the notion that humans are actually measuring\nthose statistics,",
    "start": "699240",
    "end": "705400"
  },
  {
    "text": "and if you can get them right--\nif you can make two images have the same statistics, and that's\nthe only thing that humans are measuring, then those two\nimages will look the same.",
    "start": "705400",
    "end": "714189"
  },
  {
    "text": "So Julesz goes ahead with\nthis, and eventually constructs",
    "start": "714190",
    "end": "720270"
  },
  {
    "text": "by hand, because\nhe did everything with binary patterns\nconstructed by hand-- he constructs these two\nexamples that are identical.",
    "start": "720270",
    "end": "727920"
  },
  {
    "text": "He first falsifies the\ntheory at n equals 2, and then he tries to do\nthird-order statistics. And he comes up with these two\nexamples-- counter-examples",
    "start": "727920",
    "end": "735136"
  },
  {
    "text": "to the theory. These are matched in terms of\ntheir third-order statistics. It's not easy to see that or\nrealize that, but it's true.",
    "start": "735136",
    "end": "741067"
  },
  {
    "text": "If you take triples\nof pixels, and you take the product of those\nthree, and you average that over the image, these\ntwo things are identical,",
    "start": "741067",
    "end": "747720"
  },
  {
    "text": "but they look very different. And if you draw samples\nof each of these, it's very easy to label\nthem as, let's say, A or B",
    "start": "747720",
    "end": "755250"
  },
  {
    "text": "into these two categories. Here's another\nexample that came out a bit later by Jack Yellott. These two things also are\nmatched up to third-order.",
    "start": "755250",
    "end": "762540"
  },
  {
    "text": "So Julesz decides that\nthe theory is a failure, and he abandons it. And he begins a new theory,\nwhich is the theory of textons,",
    "start": "762540",
    "end": "770700"
  },
  {
    "text": "which is a much less\nprecisely-specified theory that has to do with laying down--",
    "start": "770700",
    "end": "777510"
  },
  {
    "text": "basically, it's a generative\nmodel, if you like. Everybody's fond of\ngenerative models these days, except for me.",
    "start": "777510",
    "end": "784260"
  },
  {
    "text": "And he comes up with\na generative model-- ah, and maybe Tommy. He comes up with the\ngenerative model,",
    "start": "784260",
    "end": "789340"
  },
  {
    "text": "which is to lay down many copies\nof a small, repeating unit,",
    "start": "789340",
    "end": "795870"
  },
  {
    "text": "which he called the texton. And so he came up with this\nmethod of generating texture",
    "start": "795870",
    "end": "800880"
  },
  {
    "text": "images, which he\nwent to town on, and he made lots of examples. The problem is that that\nwasn't a description of how",
    "start": "800880",
    "end": "806820"
  },
  {
    "text": "to analyze texture images or how\na human would analyze texture images, and so it became very\ndifficult to bridge that gap.",
    "start": "806820",
    "end": "812950"
  },
  {
    "text": "And I think, in my view,\nthat the theory really never succeeded, and he should have\nstuck with the initial theory.",
    "start": "812950",
    "end": "818730"
  },
  {
    "text": "Anyway, but that gave\nus an opportunity. So we went back\nmany years later-- this is around 1999.",
    "start": "818730",
    "end": "825070"
  },
  {
    "text": "I had a fantastic\npost-doc, Javier Portilla, who came from Spain, and we\nstarted thinking about texture",
    "start": "825070",
    "end": "831329"
  },
  {
    "text": "and started putting\ntogether a model that was Juleszian in spirit,\nbut a little bit different,",
    "start": "831330",
    "end": "837047"
  },
  {
    "text": "because we wanted to build\nin a little bit of what we knew about physiology. Now, Julesz knew\nabout physiology, because Hubel and Wiesel were\ndoing all those experiments",
    "start": "837047",
    "end": "844410"
  },
  {
    "text": "in V1 in the late '50S\nand the early '60s, but he really didn't incorporate\nthat into his thinking.",
    "start": "844410",
    "end": "849700"
  },
  {
    "text": "So what we did is build\na very simple model. It's just dumb, stupid,\nsimple, in which we took",
    "start": "849700",
    "end": "859200"
  },
  {
    "text": "this description of V1 neurons. So these are oriented\nreceptive fields. The idea is that this is a\ndescription of a neuron that",
    "start": "859200",
    "end": "867150"
  },
  {
    "text": "takes a weighted\nsum of the pixels with positive and\nnegative lobes. And it has a\npreferred orientation,",
    "start": "867150",
    "end": "873960"
  },
  {
    "text": "because the positive\nand negative lobes have a particular\noriented structure. And then it takes the\noutput of that weighted sum",
    "start": "873960",
    "end": "881010"
  },
  {
    "text": "and runs it through some\nrectifying, nonlinear function. And here's another, and\nthis is a classic thing",
    "start": "881010",
    "end": "888360"
  },
  {
    "text": "that Hubel and Wiesel\ndescribed for a simple cell. And here's another one,\nwhich is a complex cell.",
    "start": "888360",
    "end": "893760"
  },
  {
    "text": "And this one basically does\ntwo of these and combines them. I'm trying to avoid\nthe details here,",
    "start": "893760",
    "end": "899314"
  },
  {
    "text": "because they're not\ncritical for understanding what going to show you.  So then we took those\nthings and we said, well,",
    "start": "899314",
    "end": "906200"
  },
  {
    "text": "what if we measure joint\nstatistics of those things over the image? So we're going to take\nnot just these filters,",
    "start": "906200",
    "end": "911652"
  },
  {
    "text": "but of course, we're\ngoing to do a convolution. That is, we're going\nto compute the response of this weighted sum\nat different positions",
    "start": "911652",
    "end": "917600"
  },
  {
    "text": "throughout the image. We're going to\nrectify all of them. Now we're going to\ntake joint statistics. What do I mean by that? Just correlations, basically--\nsecond-order statistics",
    "start": "917600",
    "end": "925819"
  },
  {
    "text": "of the simple cells,\nof the complex cells, of the cross statistics\nbetween them.",
    "start": "925820",
    "end": "930860"
  },
  {
    "text": "And these statistics are\nbetween different orientations and different positions\nand also different sizes.",
    "start": "930860",
    "end": "937040"
  },
  {
    "text": "And given that large\nset of numbers-- and typically for the images\nthat we worked with back then, these were typically on\nthe order of 700 numbers.",
    "start": "937040",
    "end": "944720"
  },
  {
    "text": "So we have an image over here,\nwhich is say, tens of thousands or hundreds of thousands of\npixels, being transformed",
    "start": "944720",
    "end": "952160"
  },
  {
    "text": "through this box into a set\nof, let's say, 700 numbers. So 700 summary statistics\nto describe this pattern.",
    "start": "952160",
    "end": "960980"
  },
  {
    "text": "And then the question is,\nhow do we test the model? And for testing the model-- most people, when they\ntest models like this,",
    "start": "960980",
    "end": "968210"
  },
  {
    "text": "they do classification. This should sound very\nfamiliar these days, with the deep network world.",
    "start": "968210",
    "end": "974180"
  },
  {
    "text": "They take a model, and then\nthey run it on lots of examples. And they ask, well,\ndo the examples that are supposed to be the\nsame kind of thing,",
    "start": "974180",
    "end": "980520"
  },
  {
    "text": "like the same tree bark-- do they come out with\nstatistics that are similar or almost the same\nas each other?",
    "start": "980520",
    "end": "987470"
  },
  {
    "text": "And can I classify or\ngroup them or cluster them and get the right answer\nwhen trying to identify",
    "start": "987470",
    "end": "992660"
  },
  {
    "text": "the different examples? We decided that that was a\nvery-- at least at the time, a very weak test of\nthis model, because this",
    "start": "992660",
    "end": "1000460"
  },
  {
    "text": "is a high-dimensional\nspace, and we had only, let's say, on the order of\nhundreds of example textures.",
    "start": "1000460",
    "end": "1006339"
  },
  {
    "text": "And hundreds of-- that sounds\nlike a lot of textures-- a couple hundred textures,\nbut if the outputs",
    "start": "1006340",
    "end": "1012040"
  },
  {
    "text": "live in a 700 dimensional space,\nthen it's basically nothing. We're not filling that space.",
    "start": "1012040",
    "end": "1018850"
  },
  {
    "text": "And for those of you that\nare statistically-oriented, you know that there's\nthis thing called the curse of dimensionality.",
    "start": "1018850",
    "end": "1023950"
  },
  {
    "text": "The number of data samples that\nyou need to fill up a space goes up exponentially with\nthe number of dimensions.",
    "start": "1023950",
    "end": "1029540"
  },
  {
    "text": "So this was really\nbad news, and we decided that it was\ngoing to be a disaster to just do classification--\nthat pretty",
    "start": "1029540",
    "end": "1035170"
  },
  {
    "text": "much any set of measurements\nwould work for classification. So we were looking for a more\ndemanding test of the model.",
    "start": "1035170",
    "end": "1042650"
  },
  {
    "text": "And for that, we\nturned to synthesis. So the idea is like this. So you take this image.",
    "start": "1042650",
    "end": "1048391"
  },
  {
    "text": "You run it through the model. You get your responses. Now we're going to take\na patch of white noise.",
    "start": "1048392",
    "end": "1053996"
  },
  {
    "text": "We're going to run it\nthrough the same model, and then we're going to lean\non the noise, push on it--",
    "start": "1053996",
    "end": "1059680"
  },
  {
    "text": "push on all the pixels\nin that noise image until we get the same outputs.",
    "start": "1059680",
    "end": "1066039"
  },
  {
    "text": "So this is sometimes called\nsynthesis by analysis. This is not a generative\nmodel, but we're using it",
    "start": "1066040",
    "end": "1072590"
  },
  {
    "text": "like a generative model. We're going to draw\nsamples of images that have the same\nstatistics by starting",
    "start": "1072590",
    "end": "1079510"
  },
  {
    "text": "with white noise and\njust pounding on it until it looks right. And pounding on it\nmeans, for those of you that want to know, measuring\nthe gradients of the deviation",
    "start": "1079510",
    "end": "1089960"
  },
  {
    "text": "away from the desired\noutput and just moving in the direction\nof the gradient. I'm giving you the\nquick version of this.",
    "start": "1089960",
    "end": "1098799"
  },
  {
    "text": "A little bit more abstractly,\nwe can think of it this way. There's a space of\nall possible images.",
    "start": "1098800",
    "end": "1104377"
  },
  {
    "text": "Here's the original image. It's a point in this space. We compute the\nresponses of the model,",
    "start": "1104377",
    "end": "1110210"
  },
  {
    "text": "which is a lower dimensional\nspace-- a smaller space. That's this. Because this is a many to one\nmapping and it's continuous,",
    "start": "1110210",
    "end": "1117559"
  },
  {
    "text": "there's actually a manifold-- a continuous a collection of\nimages over here, all of which",
    "start": "1117560",
    "end": "1122620"
  },
  {
    "text": "have the same exact\nmodel responses. And what we're trying to\ndo is grab one of these.",
    "start": "1122620",
    "end": "1128139"
  },
  {
    "text": "We want to draw a sample\nfrom that manifold. If the theory is right-- if this\nmodel is a good representation",
    "start": "1128140",
    "end": "1133929"
  },
  {
    "text": "of what humans see and capture\nwhen they look at textures, then all of these things\nshould look the same.",
    "start": "1133930",
    "end": "1139840"
  },
  {
    "text": "That's the hypothesis. And the way we do it, again,\nis to start with a noise seed-- just an image filled with noise.",
    "start": "1139840",
    "end": "1145059"
  },
  {
    "text": "We project it onto the manifold. We push it onto this point. We can test that, because\nwe can, of course, measure",
    "start": "1145060",
    "end": "1150520"
  },
  {
    "text": "the same things on this\nimage and make sure that they're the\nsame as this image, and that's our\nsynthesized image.",
    "start": "1150520",
    "end": "1156799"
  },
  {
    "text": "So that's a abstract\npicture of what I told you on the previous slide.",
    "start": "1156800",
    "end": "1161809"
  },
  {
    "text": "And then finally, the\nscientific or experimental logic is to test this by showing\nit to a human observer.",
    "start": "1161810",
    "end": "1167890"
  },
  {
    "text": "So we have the original\nimage, and then we compute the model responses. We generate a new image,\nand we ask the human,",
    "start": "1167890",
    "end": "1173950"
  },
  {
    "text": "do these look the same? And if the model captures\nthe same properties as the visual system,\nthen two images",
    "start": "1173950",
    "end": "1180869"
  },
  {
    "text": "with identical model\nresponses should appear identical to a human. So that's the logic.",
    "start": "1180869",
    "end": "1187240"
  },
  {
    "text": "And any strong failure\nof this indicates that the model is insufficient\nto capture what is",
    "start": "1187240",
    "end": "1192250"
  },
  {
    "text": "important about these images. So it works, or I wouldn't\nbe telling you about it.",
    "start": "1192250",
    "end": "1197800"
  },
  {
    "text": "Here is just a few examples. There are hundreds\nmore on the web page that describes this work. On the top are\noriginal photographs--",
    "start": "1197800",
    "end": "1204260"
  },
  {
    "text": "lizard skin, plaster\nof some sort, beans. On the bottom are synthesized\nversions of these.",
    "start": "1204260",
    "end": "1211960"
  },
  {
    "text": "The lizard skin\nworks really well. The plaster works quite well. The beans a little less so. And it depends-- whether it\nworks well or not depends",
    "start": "1211960",
    "end": "1220169"
  },
  {
    "text": "on the viewing condition. So if you flash\nthese up quickly, people might be convinced that\nthey all look really great.",
    "start": "1220169",
    "end": "1225230"
  },
  {
    "text": "If you allow them to\ninspect them carefully, they can start to see deviations\nor funny little artifacts.",
    "start": "1225230",
    "end": "1230450"
  },
  {
    "text": "So it's a partial success. And I should point\nout that it also",
    "start": "1230450",
    "end": "1236600"
  },
  {
    "text": "provides a pretty convincing\nsuccess on Julesz' counter-examples.",
    "start": "1236600",
    "end": "1241730"
  },
  {
    "text": "So these are examples. This is synthesized\nfrom that, and this is synthesized from that, and\nthey're easily classifiable.",
    "start": "1241730",
    "end": "1250679"
  },
  {
    "text": "And there's fun things\nyou can do with this. You can fill in\nregions around images.",
    "start": "1250680",
    "end": "1256130"
  },
  {
    "text": "So if you take this\nlittle chunk of text here and you measure the\nstatistics, and you say, fill in the stuff around\nit with something",
    "start": "1256130",
    "end": "1262460"
  },
  {
    "text": "with has the same\nstatistics, but try to do a careful job of\nmatching up at the boundaries, you can create things like this.",
    "start": "1262460",
    "end": "1268280"
  },
  {
    "text": "So you can read the\nwords in the center, but the outside\nlooks like gibberish. Each one of these was\ncreated in the same way.",
    "start": "1268280",
    "end": "1274020"
  },
  {
    "text": "So the center of each of\nthese is the original image, and what's around\nit is synthesized. So it works reasonably well.",
    "start": "1274020",
    "end": "1280070"
  },
  {
    "text": "You can also do fun\nthings like this. So these are examples where-- I told you we started\nfrom white noise,",
    "start": "1280070",
    "end": "1285470"
  },
  {
    "text": "and then pushed it\nonto the manifold, but we can actually\nstart from any image. So if we start\nfrom these images--",
    "start": "1285470",
    "end": "1290780"
  },
  {
    "text": "these are three of\nmy collaborators-- two of my students and my\ncollaborator Tony Movshon.",
    "start": "1290780",
    "end": "1296000"
  },
  {
    "text": "If we start with those\nas starting point images, and we use these textures\nfor each of them, we arrive at these images,\nwhere you can still",
    "start": "1296000",
    "end": "1302236"
  },
  {
    "text": "see some of the global\nstructure of the face. Because the model is\na homogeneous model, it doesn't impose anything\non global structure.",
    "start": "1302236",
    "end": "1309799"
  },
  {
    "text": "And so if you seed\nit with something that has particular global\nstructure or arrangement, it will inherit some of that.",
    "start": "1309800",
    "end": "1315320"
  },
  {
    "text": "It'll hold onto it. Anyway, this is just for fun. Let's get back to science.",
    "start": "1315320",
    "end": "1321230"
  },
  {
    "text": "So now, here's an example\nof Richard Feynman. This is Richard Feynman after\nhe's gone through the blender.",
    "start": "1321230",
    "end": "1327870"
  },
  {
    "text": "You can see pieces of skin-like\nthings and folds and flaps, but it's all disorganized.",
    "start": "1327870",
    "end": "1334070"
  },
  {
    "text": "Again it's a homogeneous model. It doesn't know anything\nabout the global organization of this photograph. But what we want to know is--",
    "start": "1334070",
    "end": "1340520"
  },
  {
    "text": "so do we have a\nmodel that's just a model for the perception\nof homogeneous textures, or can we actually\npush it a little bit",
    "start": "1340520",
    "end": "1346520"
  },
  {
    "text": "and make it, first of all,\na little more physiological, and second of all, maybe\na little bit more relevant",
    "start": "1346520",
    "end": "1352279"
  },
  {
    "text": "for everyday vision? For me, standing here and\nlooking at this scene, how do I go about\ndescribing something",
    "start": "1352280",
    "end": "1359390"
  },
  {
    "text": "like this that's going on when\nI'm looking at a normal scene? So let's go through thinking\nabout how to do this.",
    "start": "1359390",
    "end": "1366480"
  },
  {
    "text": "So I'm going to jump right\nto this diagram of the brain again. So V1 is in the\nback of the brain.",
    "start": "1366480",
    "end": "1373180"
  },
  {
    "text": "The information that\ncomes into your eyes goes through the retina,\nthe LGN, back to V1. And then it splits into these\ntwo branches, the dorsal",
    "start": "1373180",
    "end": "1380240"
  },
  {
    "text": "and the ventral stream. The ventral stream is usually\nassociated with spatial form and recognition and memory.",
    "start": "1380240",
    "end": "1386102"
  },
  {
    "text": "So I'm going to think\nabout the ventral stream, and we're going to\ntry to understand what this model might have\nto say about processing",
    "start": "1386102",
    "end": "1392260"
  },
  {
    "text": "in the ventral stream. I'm going to rely on just\na few simple assumptions. First, that each of\nthese areas has neurons,",
    "start": "1392260",
    "end": "1398690"
  },
  {
    "text": "and that they respond\nto small contents or regions of the visual input. They're known as\nreceptive fields.",
    "start": "1398690",
    "end": "1404030"
  },
  {
    "text": "Most of you know that. In each visual area,\nI'm going to assume that those receptive\nfields are covering,",
    "start": "1404030",
    "end": "1409309"
  },
  {
    "text": "blanketing the\nentire visual field. So there's no dead spots. There's no spots\nthat are left out.",
    "start": "1409310",
    "end": "1415160"
  },
  {
    "text": "Everything is covered nicely. And in fact, we know that\nthis is true, for example, starting in the retina.",
    "start": "1415160",
    "end": "1421010"
  },
  {
    "text": "So this is a cartoon diagram\nto illustrate the inhomogeneity",
    "start": "1421010",
    "end": "1426890"
  },
  {
    "text": "that's found in the retina. So the receptive field\nsizes in the retina grow with eccentricity.",
    "start": "1426890",
    "end": "1433030"
  },
  {
    "text": "And it turns out that\nthat starts in the retina, but that's true,\nactually, all the way through the visual system and\nthroughout the ventral stream,",
    "start": "1433030",
    "end": "1438659"
  },
  {
    "text": "in particular. And this diagram is showing\nthese little circles are about 10 times the size of\nyour midget ganglion cell",
    "start": "1438659",
    "end": "1448130"
  },
  {
    "text": "receptive fields in your retina. So you looking-- if\nyou fixate right here in the center of\nthis, these things",
    "start": "1448130",
    "end": "1454730"
  },
  {
    "text": "are about 10 times the size\nof your receptive fields. And that's been\nlong thought to be",
    "start": "1454730",
    "end": "1459919"
  },
  {
    "text": "the primary driver of\nyour limits on acuity,",
    "start": "1459920",
    "end": "1465260"
  },
  {
    "text": "in terms of peripheral vision. So in particular,\nif you take this eye chart, which is modified by--",
    "start": "1465260",
    "end": "1472610"
  },
  {
    "text": "this was done by Richard\nAnstis back in the '70s, and you lay it out\nin this fashion, these things are about\n10 times the threshold",
    "start": "1472610",
    "end": "1479690"
  },
  {
    "text": "for visibility and\nrecognition of these letters. And so you can say that the\nstroke widths of the letters are about matched to the\nsize of these ganglion cells,",
    "start": "1479690",
    "end": "1487790"
  },
  {
    "text": "and it works, at least\nqualitatively-- that things are scaling in the right\nway, in terms of acuity,",
    "start": "1487790",
    "end": "1495320"
  },
  {
    "text": "and in terms of the size\nthat the letters need to be for you to recognize them.",
    "start": "1495320",
    "end": "1503020"
  },
  {
    "text": "And you can make\npictures like this. This is after Bill Geisler, who\nshowed that if you foveate--",
    "start": "1503020",
    "end": "1509950"
  },
  {
    "text": "if you fixate here,\nin fact, you can't see the details of\nthe stuff that's far from your fixation\npoint, and if you blur it,",
    "start": "1509950",
    "end": "1516790"
  },
  {
    "text": "people don't notice. You can actually add high\nfrequency noise to it, alternatively, and people\nwon't notice that either.",
    "start": "1516790",
    "end": "1523420"
  },
  {
    "text": "Because those receptive fields\nare getting larger and larger, and you're basically\nblurring out the information that would\nallow you to distinguish,",
    "start": "1523420",
    "end": "1529396"
  },
  {
    "text": "let's say, these two things. When you look right\nat it you can see it, but if you keep your eye fixated\nhere, you won't notice it.",
    "start": "1529396",
    "end": "1537580"
  },
  {
    "text": "So let's work off\nof those ideas-- the idea of these\nreceptive fields that are getting larger with\neccentricity, that are covering",
    "start": "1537580",
    "end": "1544570"
  },
  {
    "text": "the entire visual field. And let's notice the following--\nso this is data taken-- physiological data\nfrom several papers",
    "start": "1544570",
    "end": "1551730"
  },
  {
    "text": "that were assembled\nby Jeremy Freeman, who was a grad student in my lab. And here you can see the\ncenter of the receptor fields",
    "start": "1551730",
    "end": "1558370"
  },
  {
    "text": "versus the size of\nthe receptive fields. And you can see\nthat in the retina-- I already showed you\non the previous slide",
    "start": "1558370",
    "end": "1563990"
  },
  {
    "text": "that it grows with eccentricity,\nbut it's actually very slow compared to what\nhappens in the cortex.",
    "start": "1563990",
    "end": "1569110"
  },
  {
    "text": "V1, the receptor fields\ngrow at a pretty good clip. V2, they grow about twice as\nfast as that, and V4 twice",
    "start": "1569110",
    "end": "1575380"
  },
  {
    "text": "as fast again. Another way of saying this--\nat any given receptive field location relative to the fovea--",
    "start": "1575380",
    "end": "1582029"
  },
  {
    "text": "let's say 15 degrees, the\nreceptive fields in V1 are of a given size.",
    "start": "1582030",
    "end": "1588355"
  },
  {
    "text": "It's on the order of\n0.2 to 0.25 times. The diameter is 0.2 to 0.25\ntimes the eccentricity.",
    "start": "1588355",
    "end": "1597410"
  },
  {
    "text": "The receptive fields\nin V2 are twice that size, so about 0.45\ntimes the eccentricity,",
    "start": "1597410",
    "end": "1604090"
  },
  {
    "text": "and the receptive fields\nin V4 are twice that again. In cartoon form, it looks\nsomething like this.",
    "start": "1604090",
    "end": "1610250"
  },
  {
    "text": "So here's V1. Lots of cells and\nsmall-ish receptive fields growing\nwith eccentricity.",
    "start": "1610250",
    "end": "1616809"
  },
  {
    "text": "Here's V2. They're bigger. They grow faster. Here's V4. And by the time you get to IT--",
    "start": "1616810",
    "end": "1622179"
  },
  {
    "text": "Jim DiCarlo was here\na bunch of days ago, and he probably told\nyou this-- almost every IT cell includes the fovea\nas part of its receptive field.",
    "start": "1622180",
    "end": "1629380"
  },
  {
    "text": "They're very large,\nand they often cover half the visual field.",
    "start": "1629380",
    "end": "1634396"
  },
  {
    "text": "So now we have to\nfigure out what to put inside of\nthese little circles in order to make\na model, and I'm going to basically combine--",
    "start": "1634396",
    "end": "1641169"
  },
  {
    "text": "smash together the texture\nmodel that I told you about, which was a global homogeneous\nmodel, with this receptive",
    "start": "1641170",
    "end": "1649570"
  },
  {
    "text": "field model. I'm going to basically stick\na little texture model in each of these little circles. That's the concept.",
    "start": "1649570",
    "end": "1655030"
  },
  {
    "text": "So how do we do that? Well, we're going to go\nback to Hubel and Wiesel. Hubel and Wiesel\nwere the ones that said you make V1 receptive field\nsimple cells out of LGN cells",
    "start": "1655030",
    "end": "1663460"
  },
  {
    "text": "by just taking a bunch of\nLGN cells that line up. Here they are-- center surround\nreceptive fields from the LGN,",
    "start": "1663460",
    "end": "1669700"
  },
  {
    "text": "which are coming\noff of the center surround architecture\nof the retina. You line them up, you\nadd them together,",
    "start": "1669700",
    "end": "1675429"
  },
  {
    "text": "and that gives you an oriented\nreceptive field, like the ones that I showed you earlier. And in more of a\ncomputational diagram,",
    "start": "1675430",
    "end": "1681884"
  },
  {
    "text": "you might draw it like this. So here's an array of\nLGN inputs coming in. We're going to take a\nweighted sum of those.",
    "start": "1681884",
    "end": "1687670"
  },
  {
    "text": "Black is negative. White is positive. So we add up these three\nguys, we subtract the two guys on either side,\nand then we run that",
    "start": "1687670",
    "end": "1694530"
  },
  {
    "text": "through a rectifying\nnonlinearity that's a simple cell. Hubel and Wiesel\nalso pointed out that you could maybe create--",
    "start": "1694530",
    "end": "1700780"
  },
  {
    "text": "or suggested that you\ncreate complex cells by combining simple cells. This is the diagram from\ntheir paper in 1962.",
    "start": "1700780",
    "end": "1707920"
  },
  {
    "text": "And so we can diagram\nthat like this. Here's basically three\nof these simple cells. They're displaced in\nposition, but they",
    "start": "1707920",
    "end": "1714160"
  },
  {
    "text": "have the same orientation. We halfway rectify all of\nthem, add them together, and that gives us\na complex cell.",
    "start": "1714160",
    "end": "1720580"
  },
  {
    "text": "So it's interesting to\nnote that the hook here is going to be that this\nis an average of these.",
    "start": "1720580",
    "end": "1727149"
  },
  {
    "text": "An average is a statistic. It's a local average. So we're going to\ncompute local averages,",
    "start": "1727150",
    "end": "1732460"
  },
  {
    "text": "and we're going to call those\nstatistics-- i.e. statistics, as in used in the texture model.",
    "start": "1732460",
    "end": "1738130"
  },
  {
    "text": "So let's do that. So here's the V2\nreceptive field. Open that up. Inside of that is a bunch\nof V1 cells, here all shown",
    "start": "1738130",
    "end": "1745150"
  },
  {
    "text": "at the same orientation. In reality, they would be\nall different orientations and different sizes. And now we're going to compute\nthose joint statistics, just",
    "start": "1745150",
    "end": "1751870"
  },
  {
    "text": "like I did in the\ntexture model, and that's going to give us our responses. We're going to have to do that\nfor each one of these receptive",
    "start": "1751870",
    "end": "1757990"
  },
  {
    "text": "fields. So there's a lot of these. It's not 700 numbers anymore. It's reduced, because it's--",
    "start": "1757990",
    "end": "1763760"
  },
  {
    "text": "so there's details here. It's reduced, but there's\na lot of these, so it's quite a lot of parameters.",
    "start": "1763760",
    "end": "1770200"
  },
  {
    "text": "And these local\ncorrelations that I told you we were going to compute here\ncan be re-expressed, actually, in a form that looks just like\nthe simple and complex cell",
    "start": "1770200",
    "end": "1778539"
  },
  {
    "text": "calculations that I\nshowed you for V1. So in fact, if you\ntake these V1 cells, and you take weighted\nsums of these guys,",
    "start": "1778540",
    "end": "1785380"
  },
  {
    "text": "and you half-wave rectify\nthem and add them, you get something\nthat's essentially equivalent to the texture\nmodel that I told you about.",
    "start": "1785380",
    "end": "1792610"
  },
  {
    "text": "So that's pretty\ncool, because it means that the calculations\nthat are taking us from the LGN",
    "start": "1792610",
    "end": "1798430"
  },
  {
    "text": "input to V1 outputs have a\nform, a structure which is then",
    "start": "1798430",
    "end": "1805310"
  },
  {
    "text": "repeated when we get to V2. We do the same kind of\ncalculations-- linear filters,",
    "start": "1805310",
    "end": "1810320"
  },
  {
    "text": "rectification,\npooling or averaging. And so that, of\ncourse, has become ubiquitous with the advent of\nall the deep network stuff.",
    "start": "1810320",
    "end": "1817940"
  },
  {
    "text": "But the idea here is\nthat we can actually do this kind of canonical\ncomputation again and again",
    "start": "1817940",
    "end": "1823790"
  },
  {
    "text": "and again and produce\nsomething that replicates the\nloss of information and the extraction of\nfeatures or parameters",
    "start": "1823790",
    "end": "1831470"
  },
  {
    "text": "that the human visual\nsystem is performing. So this canonical idea,\nI think, is important, and it's something that\nwe've been thinking",
    "start": "1831470",
    "end": "1838850"
  },
  {
    "text": "about for a long time-- linear filtering that\ndetermines pattern selectivity, some sort of rectifying\nnon-linearity,",
    "start": "1838850",
    "end": "1844936"
  },
  {
    "text": "some sort of pooling. And we usually also include\nsome sort of local gain control, which seems to be ubiquitous\nthroughout the visual system",
    "start": "1844936",
    "end": "1851210"
  },
  {
    "text": "and the auditory system in\nevery stage, and noise, as well. And we're currently, in my lab,\nworking on lots of models that",
    "start": "1851210",
    "end": "1858590"
  },
  {
    "text": "are trying to incorporate all\nof these things in stacked networks-- small numbers of\nlayers, not deep-- shallow,",
    "start": "1858590",
    "end": "1864840"
  },
  {
    "text": "shallow networks for us-- in order to try to\nunderstand their implications for perception and physiology.",
    "start": "1864840",
    "end": "1871400"
  },
  {
    "text": "This was just a description\nof a single stage, and then, of course,\nyou have to stack them.",
    "start": "1871400",
    "end": "1876922"
  },
  {
    "text": "And there are many people that\nhave talked about that idea. This is a figure from Tommy's\npaper with Christof, I think--",
    "start": "1876922",
    "end": "1884300"
  },
  {
    "text": "1999. And Fukushima had proposed\na basic architecture like this earlier.",
    "start": "1884300",
    "end": "1891530"
  },
  {
    "text": "And so I think this\nhas now become-- you barely even need to say\nit, because of the deep network literature.",
    "start": "1891530",
    "end": "1898820"
  },
  {
    "text": "So how do we do this? Same thing I told you before. Take an image, plop down all\nthese V2 receptive fields.",
    "start": "1898820",
    "end": "1904460"
  },
  {
    "text": "By the way, I should have\nsaid this at the outset-- this is drawn as a cartoon.",
    "start": "1904460",
    "end": "1910010"
  },
  {
    "text": "The actual receptive\nfields that we use are smooth and overlapping,\nso that there are no holes.",
    "start": "1910010",
    "end": "1915230"
  },
  {
    "text": "And in fact, the\ndetails of that are that since we're\ncomputing averages, you can think of this\nas a low pass filter,",
    "start": "1915230",
    "end": "1920921"
  },
  {
    "text": "and we try to at least\napproximately obey the Nyquist theorem, so that\nthere's no aliasing-- that is, there's no\nevidence of the sampling",
    "start": "1920921",
    "end": "1927530"
  },
  {
    "text": "lattice, for those of you that\nare thinking down those lines.",
    "start": "1927530",
    "end": "1933170"
  },
  {
    "text": "If you were not thinking\ndown those lines, I'll just say the\nsimple thing, which is that they're not little\ndisks that are non-overlapping,",
    "start": "1933170",
    "end": "1939260"
  },
  {
    "text": "because then we would be\nscrewing everything up in between them. They're smooth\nand overlapping so",
    "start": "1939260",
    "end": "1944269"
  },
  {
    "text": "that we cover the whole image,\nand all the pixels in the image are going to be affected\nby this process. So we make all\nthose measurements.",
    "start": "1944270",
    "end": "1950360"
  },
  {
    "text": "It's a very large\nset of measurements. And now we start with white\nnoise, and we push the button.",
    "start": "1950360",
    "end": "1956159"
  },
  {
    "text": "And again, push simultaneously\non the gradients from all those little regions\nuntil we achieve something",
    "start": "1956160",
    "end": "1961370"
  },
  {
    "text": "that matches all the\nmeasurements in all of those receptive fields. The measurements in\nthe receptive fields",
    "start": "1961370",
    "end": "1966530"
  },
  {
    "text": "are averaged over\ndifferent regions. So the ones that are\nin the far periphery",
    "start": "1966530",
    "end": "1973910"
  },
  {
    "text": "are averaged over large\nregions, and so those averages are throwing away a\nlot more information.",
    "start": "1973910",
    "end": "1979730"
  },
  {
    "text": "The ones that are\naveraged near the fovea are throwing away a small\namount of information. When you get close\nenough to the fovea,",
    "start": "1979730",
    "end": "1985370"
  },
  {
    "text": "they're throwing away nothing. So the original image is\npreserved in the center, and then it gets more\nand more distorted",
    "start": "1985370",
    "end": "1990950"
  },
  {
    "text": "as you go away from the fovea. So the question is, does\nthat work for a human?",
    "start": "1990950",
    "end": "1996980"
  },
  {
    "text": "Is it metameric? The display here\nis not very good, but I'll try to give you\na demonstration of it to convince you\nthat it does work.",
    "start": "1996980",
    "end": "2003310"
  },
  {
    "text": "You have to keep your\neyes planted here, and I'm going to\nflip back and forth between this original\npicture, which was taken in Washington Square\nPark, near the department.",
    "start": "2003310",
    "end": "2012250"
  },
  {
    "text": "And I'm going to flip between\nthis and a synthesized version. You have to keep your eyes here,\nat least for a bunch of flips.",
    "start": "2012250",
    "end": "2018540"
  },
  {
    "text": "Hello. Here we go. Keep your eyes fixated.",
    "start": "2018540",
    "end": "2023627"
  },
  {
    "text": "Those two images\nshould look the same. It's going back and forth,\nA, B, A, B, and they should look the same.",
    "start": "2023627",
    "end": "2029570"
  },
  {
    "text": "I think for most of you, and\nfor most of these viewing distances, it should work. And now if you look\nover here, you'll see that they actually\nare not the same.",
    "start": "2029570",
    "end": "2037340"
  },
  {
    "text": "That's about the size\nof a V2 receptive field, and it is the same two images. I'm not cheating here, in\ncase anybody's worried.",
    "start": "2037340",
    "end": "2044690"
  },
  {
    "text": "I'm just flipping back and forth\nbetween the same two images. And you can see that\nthe original image has",
    "start": "2044690",
    "end": "2050739"
  },
  {
    "text": "a couple of faces\nin that circle, but the synthesized one,\nthey're all distorted,",
    "start": "2050739",
    "end": "2056109"
  },
  {
    "text": "the same way Feynman was when\nI showed you his photograph. But again, the point here is\nthat these two are not metamers",
    "start": "2056110",
    "end": "2064569"
  },
  {
    "text": "when you look right at\nthis peripheral region, but when you keep your\neyes fixated here, they're pretty hard\nto distinguish.",
    "start": "2064570",
    "end": "2070989"
  },
  {
    "text": "This is right at about the\nthreshold for the subjects that we ran in this\nexperiment, so it should be",
    "start": "2070989",
    "end": "2077320"
  },
  {
    "text": "basically imperceptible to you. That was a demo,\njust to convince you that it seems to work.",
    "start": "2077320",
    "end": "2083480"
  },
  {
    "text": "We did an experiment,\nbecause we wanted to do more than just show\nthat it sort of works.",
    "start": "2083480",
    "end": "2088594"
  },
  {
    "text": "We wanted to figure out whether\nwe could actually tie it to the physiology in\na more direct way,",
    "start": "2088594",
    "end": "2093649"
  },
  {
    "text": "so what we did is\nwe generated stimuli where we used different\nreceptive field size scaling.",
    "start": "2093650",
    "end": "2101160"
  },
  {
    "text": "So this is a plot. Along this axis is going to be-- just to get you\nsituated, along this axis is going to be\nmodels that are used",
    "start": "2101160",
    "end": "2108589"
  },
  {
    "text": "to generate stimuli with\ndifferent receptive field size scaling. That's the ratio of diameter\nto eccentricity-- diameter",
    "start": "2108590",
    "end": "2114295"
  },
  {
    "text": "of the receptive field to\nthe eccentricity distance from the fovea. And along here is going\nto be the percent correct",
    "start": "2114295",
    "end": "2120200"
  },
  {
    "text": "that a human is able\nto correctly identify--",
    "start": "2120200",
    "end": "2126020"
  },
  {
    "text": "the way we did this, it's\ncalled an ABX experiment. So we show one image, then\nwe show another image, then we show a third image.",
    "start": "2126020",
    "end": "2131974"
  },
  {
    "text": "And we say, which image does\nthe third one look like? So we're going to plot\npercent correct here.",
    "start": "2131974",
    "end": "2140060"
  },
  {
    "text": "And if we use a model with\nvery small receptive fields, then we get syntheses\nthat look like this.",
    "start": "2140060",
    "end": "2146540"
  },
  {
    "text": "This one has very\nlittle distortion. There's a little bit\nof distortion around near the edges, but it's\npretty close to the original.",
    "start": "2146540",
    "end": "2151580"
  },
  {
    "text": "If we use really\nbig receptor fields, then we get a lot of distortion. Things really start\nto fall apart.",
    "start": "2151580",
    "end": "2156590"
  },
  {
    "text": "And somewhere in between-- so far to the\nright on this plot, we expect people to be at\n100% noticing the distortions,",
    "start": "2156590",
    "end": "2165530"
  },
  {
    "text": "and far to the\nleft on this plot, we expect them to be at chance. We expect them to not be\nable to tell the difference.",
    "start": "2165530",
    "end": "2171840"
  },
  {
    "text": "And that's exactly what happens. This is an average\nover four observers. And you can see that the\nperformance, the percent",
    "start": "2171840",
    "end": "2177829"
  },
  {
    "text": "correct starts at\naround 50%, and then climbs up and asymptotes.",
    "start": "2177830",
    "end": "2183420"
  },
  {
    "text": "So what's more, we\ncan now do something-- this is a little bit complicated\nto get your head around. We're using this model\nto generate the stimuli,",
    "start": "2183420",
    "end": "2191390"
  },
  {
    "text": "and this is the model parameter\nplotted along this axis. Now we're going to\nuse the model again,",
    "start": "2191390",
    "end": "2196610"
  },
  {
    "text": "but now we're going\nto use the model as a model for the observer. So there's two models here. One is generating the stimuli.",
    "start": "2196610",
    "end": "2202670"
  },
  {
    "text": "The other one, we're\ngoing to try to fit-- we're going to ask, if we used\na second copy of the model",
    "start": "2202670",
    "end": "2207920"
  },
  {
    "text": "to actually look at\nthese images and tell the difference\nbetween them, what would its receptive\nfields have to be in order",
    "start": "2207920",
    "end": "2215180"
  },
  {
    "text": "to match the human data? And I'm not going to drag\nyou through the details, but the basic idea is\nthat allows us to produce",
    "start": "2215180",
    "end": "2223370"
  },
  {
    "text": "a prediction-- this black line-- for how this model\nwould behave if it were acting as an observer.",
    "start": "2223370",
    "end": "2230329"
  },
  {
    "text": "And by adjusting the parameter\nof the observer model, we can estimate the size of\nthe human receptive fields.",
    "start": "2230330",
    "end": "2237119"
  },
  {
    "text": "So the end result\nof all of this is we're going to fit\na curve to the data, and it's going to\ngive us an estimate of the size of the\nreceptive fields",
    "start": "2237120",
    "end": "2243650"
  },
  {
    "text": "that the human is\nusing to do this task. And that is right here. In fact, it's right\nat the place where",
    "start": "2243650",
    "end": "2249799"
  },
  {
    "text": "the curve hits the 50% line. That's the point where the\nhuman can't tell the difference",
    "start": "2249800",
    "end": "2255060"
  },
  {
    "text": "anymore, and that's\nthe point where we think an observer would be--",
    "start": "2255060",
    "end": "2260610"
  },
  {
    "text": "where the receptive\nfields of the stimulus would be the same\nsize as the receptive fields of the observer.",
    "start": "2260610",
    "end": "2265970"
  },
  {
    "text": "So that's what\nwe're looking for. And when we do that\nfor our four observers, they come out very consistent. So here's a plot of the\nestimated receptive field",
    "start": "2265970",
    "end": "2274490"
  },
  {
    "text": "sizes of these observers. All four of them-- 1, 2, 3, 4, and the\naverage over the four.",
    "start": "2274490",
    "end": "2280040"
  },
  {
    "text": "And nicely enough-- remember, I\ntold you that we know something about the receptive\nfield sizes in--",
    "start": "2280040",
    "end": "2285230"
  },
  {
    "text": "these are macaque monkey. And if we plot those\non the same plot, these color bands are the\nsize of the receptive fields",
    "start": "2285230",
    "end": "2291480"
  },
  {
    "text": "in a macaque, now combined\nover this large set of data from a whole bunch\nof different papers.",
    "start": "2291480",
    "end": "2297080"
  },
  {
    "text": "Jeremy went through\nincredibly painstaking work to try to put these all into\nthe same coordinate system and unify the data sets.",
    "start": "2297080",
    "end": "2303620"
  },
  {
    "text": "And so the height of each\nof these bars tells you-- they're error bars on how much\nvariability there is, where",
    "start": "2303620",
    "end": "2310010"
  },
  {
    "text": "we think the estimates are. And you can see that the\nanswers for the humans are coming right\ndown on top of V2.",
    "start": "2310010",
    "end": "2315980"
  },
  {
    "text": "So we really do think\nthat the information that is being lost in these\nstimuli is being lost in V2,",
    "start": "2315980",
    "end": "2322549"
  },
  {
    "text": "and it seems to match the\nreceptive field sizes at least of macaque monkey. We were worried that this might\ndepend a lot on the details",
    "start": "2322550",
    "end": "2330980"
  },
  {
    "text": "of the experiment. So for example,\nwe thought, well, what if we give people a\nlittle more information?",
    "start": "2330980",
    "end": "2337040"
  },
  {
    "text": "For example, what if we let them\nlook at the stimulus longer? So the original experiment\nwas pretty brief--",
    "start": "2337040",
    "end": "2342410"
  },
  {
    "text": "200 milliseconds. What if we give them\n400 milliseconds? And so up here are plots\nfor the same four subjects.",
    "start": "2342410",
    "end": "2349430"
  },
  {
    "text": "The original task\nis in the dark gray, and you can see the curves\nfor each of the subjects.",
    "start": "2349430",
    "end": "2355190"
  },
  {
    "text": "When we give them more\ntime, what you notice is that, in general,\nthey do better.",
    "start": "2355190",
    "end": "2361080"
  },
  {
    "text": "So generally, the\nlight gray curves-- 1, 2, 3-- are above\nthe dark gray curves. They get higher percent correct.",
    "start": "2361080",
    "end": "2367490"
  },
  {
    "text": "But the important thing is\nthat each of these curves dives down and hits the 50%\npoint at the same place.",
    "start": "2367490",
    "end": "2374400"
  },
  {
    "text": "In other words, what we\ninterpret this to mean is that the estimate of\nthe receptive field sizes",
    "start": "2374400",
    "end": "2381230"
  },
  {
    "text": "is an architectural\nconstraint, and we can estimate the same\narchitectural constraint",
    "start": "2381230",
    "end": "2388070"
  },
  {
    "text": "under both of these conditions,\neven though performance is noticeably different, at\nleast for these three subjects.",
    "start": "2388070",
    "end": "2393559"
  },
  {
    "text": "This one, it's really quite\na big, big improvement. This subject is doing\nmuch, much better on the task when we\ngive them more time.",
    "start": "2393560",
    "end": "2400260"
  },
  {
    "text": "And yet, this estimate\nof receptive field sizes is pretty stable,\nso we thought this was a pretty important control.",
    "start": "2400260",
    "end": "2407220"
  },
  {
    "text": "And down below is\nanother control. That was a bottom-up control. This is a top-down control. People have talked\nabout attention",
    "start": "2407220",
    "end": "2414270"
  },
  {
    "text": "being very important\nin peripheral tasks, so we now gave the subjects\nan attentional cue--",
    "start": "2414270",
    "end": "2419300"
  },
  {
    "text": "a little arrow at the\ncenter of the display that pointed toward the\nregion of the periphery",
    "start": "2419300",
    "end": "2425190"
  },
  {
    "text": "where the distortion was largest\nin a mean-squared error sense. So we measure little chunks\nof the peripheral image",
    "start": "2425190",
    "end": "2431190"
  },
  {
    "text": "and look for the place where\nthere's the biggest difference, and we tell them\nto pay attention",
    "start": "2431190",
    "end": "2436380"
  },
  {
    "text": "to that part of the stimulus. They're not allowed\nto move their eyes. We have an eye tracker\non them the whole time, so they're not\nallowed to look at it.",
    "start": "2436380",
    "end": "2441960"
  },
  {
    "text": "But we're telling them, try\nto pay attention to what's, let's say, in the upper left. And again, the result\nis quite similar.",
    "start": "2441960",
    "end": "2448500"
  },
  {
    "text": "Their performance improves\nnoticeably, at least for these three subjects. This one, again, is the\nmost dramatic performance",
    "start": "2448500",
    "end": "2455070"
  },
  {
    "text": "improvement. Nobody gets worse. This subject basically\nstayed about the same. But again, the estimates\nof receptive field size",
    "start": "2455070",
    "end": "2461820"
  },
  {
    "text": "are quite stable. So our interpretation\nis attention is boosting the signal,\nif there is a signal, that",
    "start": "2461820",
    "end": "2469920"
  },
  {
    "text": "allows them to do the task. But if they're at chance\nand there's no signal, attention does nothing, which\nis why that when you get to 50%,",
    "start": "2469920",
    "end": "2478380"
  },
  {
    "text": "all these points coalesce. All the curves are hitting\n50% at the same place.",
    "start": "2478380",
    "end": "2484260"
  },
  {
    "text": "One last control-- we\nwanted to convince ourselves that really it was V2,\nand it wasn't just luck that we happened to get that\nreceptive field size that",
    "start": "2484260",
    "end": "2492060"
  },
  {
    "text": "matched the macaque data. So we did a control\nexperiment where we tried to get the same result for V1.",
    "start": "2492060",
    "end": "2497610"
  },
  {
    "text": "So this time, we just measure\nlocal oriented receptive fields like Hubel and Wiesel\ndescribed, and we average them",
    "start": "2497610",
    "end": "2505860"
  },
  {
    "text": "as in a complex cell over\ndifferent sized regions. And we generate\nstimuli that are just matched for the average\nresponses of the V1 cells.",
    "start": "2505860",
    "end": "2514067"
  },
  {
    "text": "We don't do all the\nstatistics on top of that that represents the V2 calculation. We're just doing\naverage V1 responses.",
    "start": "2514067",
    "end": "2521309"
  },
  {
    "text": "When we do that-- we generate the stimuli,\nwe do the same experiment, we get a very different\nresult in light gray here.",
    "start": "2521310",
    "end": "2527280"
  },
  {
    "text": "So you can see that\nthese curves are always higher than the other\nones, but they also hit the axis at a much,\nmuch smaller value,",
    "start": "2527280",
    "end": "2535349"
  },
  {
    "text": "usually by about a factor\nof two, which is just right, given what I told you before\nabout receptive field sizes.",
    "start": "2535350",
    "end": "2541100"
  },
  {
    "text": "So if we go back and we combine\nall the data on one plot-- down here are the V1 controls. They're about the\nright size for V1.",
    "start": "2541100",
    "end": "2548160"
  },
  {
    "text": "And up here is the original\nexperiment and the two controls that I told you about--\nthe extended presentation",
    "start": "2548160",
    "end": "2553800"
  },
  {
    "text": "and the directed attention,\nand those are all pretty much lying in the range of V2. We think this has a pretty\nstrong implication for reading",
    "start": "2553800",
    "end": "2561090"
  },
  {
    "text": "speed. When you read, your eyes\nhop across the page. You do not scan continuously. You hop.",
    "start": "2561090",
    "end": "2566970"
  },
  {
    "text": "And when you hop,\nhere's an example of the kind of hops you\ndo when you're reading. There's an eye position,\nand the typical hop distance",
    "start": "2566970",
    "end": "2573300"
  },
  {
    "text": "would be about that-- from here to there. This is the same piece of text. We've synthesized it as a\nmetamer using this model, just",
    "start": "2573300",
    "end": "2580980"
  },
  {
    "text": "to illustrate the idea\nthat the chunk of stuff that you can read around\nthat fixation point,",
    "start": "2580980",
    "end": "2586290"
  },
  {
    "text": "it's about right. It matches what you\nwould expect for the kind",
    "start": "2586290",
    "end": "2591630"
  },
  {
    "text": "of hopping that you could do. Your reading speed is limited\nby the distance of those hops,",
    "start": "2591630",
    "end": "2597450"
  },
  {
    "text": "and the distance of\nthose hops is limited by this loss of information.",
    "start": "2597450",
    "end": "2602700"
  },
  {
    "text": "So you can't read anything\nbeyond maybe this I and this N. And in order to read it,\nyou hop your eyes over here,",
    "start": "2602700",
    "end": "2608400"
  },
  {
    "text": "and now you get\nmost of this word. You can make out the rest\nof an \"involuntarily.\" So there's an interesting\nimplication here,",
    "start": "2608400",
    "end": "2615059"
  },
  {
    "text": "which is that you\ncan potentially increase reading speed by\nusing this model to optimize",
    "start": "2615060",
    "end": "2623160"
  },
  {
    "text": "the presentation of text. And now that we can do\nthese things electronically, you can imagine all\nkinds of devices",
    "start": "2623160",
    "end": "2628590"
  },
  {
    "text": "where the word spacing\nand the line spacing and the letter sizes\nand everything else could change with time and\nposition on the display.",
    "start": "2628590",
    "end": "2637244"
  },
  {
    "text": "So you don't have to\njust put things out as static arrays of characters. You could now imagine jumping\nthings around and rescaling",
    "start": "2637244",
    "end": "2644321"
  },
  {
    "text": "things. You could imagine\ndesigning new fonts that caused less distortion or loss\nof information, et cetera.",
    "start": "2644321",
    "end": "2651640"
  },
  {
    "text": "So this is just going back\nto the trichromacy story that I told you. I told you that once they\nfigured out the theory,",
    "start": "2651640",
    "end": "2657884"
  },
  {
    "text": "and they had all the\npsychophysics down, the next thing that happened\nis all that engineering. They came up with\nengineering standards,",
    "start": "2657884",
    "end": "2663616"
  },
  {
    "text": "and they used it to design\ndevices and specify protocols for transmitting images,\nfor communicating them,",
    "start": "2663616",
    "end": "2670109"
  },
  {
    "text": "for rendering them. I think that this has\nthat kind of potential. And this theory is\ntoo crude right now,",
    "start": "2670110",
    "end": "2676620"
  },
  {
    "text": "but if you had a really solid\ntheory for what information survived in the\nperiphery, you can really",
    "start": "2676620",
    "end": "2683190"
  },
  {
    "text": "start to push hard on\ndesigning devices and designing specifications for devices\nfor improved whatever.",
    "start": "2683190",
    "end": "2692659"
  },
  {
    "text": "Sometimes you want\nto improve things. Sometimes you want\nto make things harder to see, like in this example.",
    "start": "2692659",
    "end": "2697920"
  },
  {
    "text": "So you want to build camouflage. You go in, you take a bunch of\nphotographs of the environment, and then you say, let's\ndesign a camouflage",
    "start": "2697920",
    "end": "2703730"
  },
  {
    "text": "that best hides itself\nwhen it's not seen directly within this environment.",
    "start": "2703730",
    "end": "2709260"
  },
  {
    "text": "So you could use these\nkinds of loss of information to exploit things\nor to aid things",
    "start": "2709260",
    "end": "2715819"
  },
  {
    "text": "in terms of human perception. So let me say just a\nfew things about V2,",
    "start": "2715820",
    "end": "2721460"
  },
  {
    "text": "and then maybe I should stop. So this work that\nJeremy and I did",
    "start": "2721460",
    "end": "2728270"
  },
  {
    "text": "in building this model\nfor metamers, which is a global version\nof the texture model that operates in\nlocal regions, led",
    "start": "2728270",
    "end": "2735260"
  },
  {
    "text": "us to start asking\nquestions about what we could learn by actually\nmeasuring cells in V2.",
    "start": "2735260",
    "end": "2742160"
  },
  {
    "text": "And we joined forces\nwith Tony Movshon, who is the chair\nof my department and a longtime\ncollaborator and friend.",
    "start": "2742160",
    "end": "2748400"
  },
  {
    "text": "And we started a\nseries of experiments to try to explore presentations\nof texture to V2 neurons",
    "start": "2748400",
    "end": "2755894"
  },
  {
    "text": "to try to understand\nwhat we could learn about the actual\nrepresentations of V2.",
    "start": "2755894",
    "end": "2761030"
  },
  {
    "text": "And these are all done\nin macaque monkey. And I should also\nmention that V2 is--",
    "start": "2761030",
    "end": "2768565"
  },
  {
    "text": " it's been studied\nfor a long time.",
    "start": "2768565",
    "end": "2774500"
  },
  {
    "text": "Hubel and Wiesel wrote a\nvery important paper about V2 in 1965, which was quite\nbeautiful, documenting",
    "start": "2774500",
    "end": "2781400"
  },
  {
    "text": "the properties that\nthey could find. But the thing that's\ninteresting about this is that V1 didn't really crack\nuntil Hubel and Wiesel figured",
    "start": "2781400",
    "end": "2790460"
  },
  {
    "text": "out what the magic\ningredient was. And the magic ingredient\nwas orientation. Before Hubel and\nWiesel, people have",
    "start": "2790460",
    "end": "2796070"
  },
  {
    "text": "been poking at\nprimary visual cortex, showing little spots of\nlight and little annuli-- all the things\nthat worked really",
    "start": "2796070",
    "end": "2802100"
  },
  {
    "text": "well in the retina and the\nLGN, and they were not getting very interesting results. They were saying, well, the\nreceptive fields are bigger",
    "start": "2802100",
    "end": "2808339"
  },
  {
    "text": "and there are hot spots,\npositive and negative regions, but the cells are not\nresponding that well.",
    "start": "2808340",
    "end": "2816650"
  },
  {
    "text": "And when Hubel and\nWiesel figured out that orientation was\nthe magic ingredient-- and the apocryphal story is that\nthey did that late at night,",
    "start": "2816650",
    "end": "2823160"
  },
  {
    "text": "and they figured it out\nwhen they were putting a slide into the projector,\nand they had forgotten to cover the cat's eyes.",
    "start": "2823160",
    "end": "2828859"
  },
  {
    "text": "And they put the slide\ninto the projector, and the line at the edge of the\nslide went past on the screen--",
    "start": "2828860",
    "end": "2835572"
  },
  {
    "text": "TOMMY: it was broken. EERO SIMONCELLI: It was broken. Ah, I always thought it\nwas the edge of the slide.",
    "start": "2835572",
    "end": "2841290"
  },
  {
    "text": "I've fibbed, and\nTommy has corrected me that it was something\nbroken in the slide. But in any case, the point\nis that a boundary went by,",
    "start": "2841290",
    "end": "2849770"
  },
  {
    "text": "and they heard-- so they played the spikes\nthrough a loudspeaker. This is what most physiologists\ndid in those days,",
    "start": "2849770",
    "end": "2856550"
  },
  {
    "text": "and even still a lot do. Certainly, in Tony's lab\nyou can always walk in there and hear the spikes coming\nover the loudspeaker.",
    "start": "2856550",
    "end": "2862630"
  },
  {
    "text": "Anyway, they heard this\nhuge barrage of spikes, more than they had ever\nheard from any cell that they had recorded\nfrom, and that",
    "start": "2862630",
    "end": "2868579"
  },
  {
    "text": "was the beginning of a whole\nsequence of just fabulous work. And using that tool--",
    "start": "2868580",
    "end": "2875390"
  },
  {
    "text": "very simple and very\nobvious in retrospect, but absolutely critical\nfor the progress.",
    "start": "2875390",
    "end": "2881230"
  },
  {
    "text": "The stimuli matter is the\npoint, and making the jump to the right stimuli\nchanges everything.",
    "start": "2881230",
    "end": "2888660"
  },
  {
    "text": "So V2 for the last\n40 years has been sitting in this difficult\nstate where people",
    "start": "2888660",
    "end": "2894740"
  },
  {
    "text": "keep throwing stimuli at it. They try angles. They try curves. They try swirly things. They try corners.",
    "start": "2894740",
    "end": "2900830"
  },
  {
    "text": "They try contours of various\nkinds, illusory contours.",
    "start": "2900830",
    "end": "2905840"
  },
  {
    "text": "And throughout all of\nthis, the end story is V2 cells have bigger\nreceptive fields, many of them",
    "start": "2905840",
    "end": "2915200"
  },
  {
    "text": "respond to orientation,\nsome of them respond to particular\ncombinations of orientation,",
    "start": "2915200",
    "end": "2920690"
  },
  {
    "text": "but it's usually a small subset,\nand the responses are weak. And that's really\nwhat the literature",
    "start": "2920690",
    "end": "2926510"
  },
  {
    "text": "has looked like for 40 years. So what we were after is, can we\ndrive these cells convincingly",
    "start": "2926510",
    "end": "2933559"
  },
  {
    "text": "and in a way that\nwe can document is significantly different\nthan what we see in V1?",
    "start": "2933560",
    "end": "2938840"
  },
  {
    "text": "That was the goal-- find a way to drive\nmost of the cells",
    "start": "2938840",
    "end": "2944870"
  },
  {
    "text": "and to drive them\ndifferently than what one would expect in V1.",
    "start": "2944870",
    "end": "2950000"
  },
  {
    "text": "As a starting point, we\nsucceeded with textures. So basically, we took\na bunch of textures.",
    "start": "2950000",
    "end": "2955290"
  },
  {
    "text": "Here are some example\ntextures drawn from the model. Down below are\nspectrally-matched equivalents. So these things have the same\npower spectra, the same amount",
    "start": "2955290",
    "end": "2962600"
  },
  {
    "text": "of energy and different\norientation and frequency bands, but they lack all the\nhigher-order statistics that",
    "start": "2962600",
    "end": "2968330"
  },
  {
    "text": "are coming in this texture\nmodel that give you nice, clean edges and contours\nand object-y things,",
    "start": "2968330",
    "end": "2975480"
  },
  {
    "text": "or lumps of objects. And sure enough-- so\nhere's some example cells. Here's three V1 cells. Here's three V2 cells.",
    "start": "2975480",
    "end": "2982000"
  },
  {
    "text": "And in each of these\nplots, there's two curves. These are shown over time. The stimulus is presented\nhere for 100 milliseconds.",
    "start": "2982000",
    "end": "2988280"
  },
  {
    "text": "You see a little\nbump in the response. And there's a light\ncurve and a dark curve. The light curve is the response\nto the spectrally-matched",
    "start": "2988280",
    "end": "2995630"
  },
  {
    "text": "noise, and the dark curve is\nthe response to the texture, with the higher-order\nstatistics.",
    "start": "2995630",
    "end": "3000829"
  },
  {
    "text": "V1 doesn't seem to care\nis the short answer here, and V2 cares quite\nsignificantly.",
    "start": "3000830",
    "end": "3007859"
  },
  {
    "text": "So when you put those\nhigher-order statistics in, almost all V2 cells\nrespond significantly more,",
    "start": "3007860",
    "end": "3013740"
  },
  {
    "text": "and you can see that in\nthese three examples. These are not unusual. That's what most of\nthe cells look like.",
    "start": "3013740",
    "end": "3018910"
  },
  {
    "text": "So here's a plot, just showing\nyou 63% of the V2 neurons significantly and\npositively modulated.",
    "start": "3018910",
    "end": "3024600"
  },
  {
    "text": "And by the way, this is\naveraged over all the textures that we showed them. And if you pick any\nindividual cell,",
    "start": "3024600",
    "end": "3030630"
  },
  {
    "text": "there's usually a\ncouple of textures that drive it really\nwell, and then a bunch of textures\nthat drive it less well. So this effect could\nbe made stronger",
    "start": "3030630",
    "end": "3037260"
  },
  {
    "text": "if you chose only the textures\nthat drove the cell well. And up here is V1, where you\ncan see that very few of them",
    "start": "3037260",
    "end": "3043290"
  },
  {
    "text": "are modulated by the existence\nof these higher-order statistics. Oh, here it is across\ntexture category.",
    "start": "3043290",
    "end": "3050069"
  },
  {
    "text": "So now on the horizontal axis\nis the texture category-- 15 different textures,\nand you can see, again,",
    "start": "3050070",
    "end": "3056310"
  },
  {
    "text": "that V1 is pretty much very\nclose to the same responses-- dark and light, again,\nfor the spectrally-matched",
    "start": "3056310",
    "end": "3062220"
  },
  {
    "text": "and the higher-order. And for these three\nV1 cells, they're",
    "start": "3062220",
    "end": "3068100"
  },
  {
    "text": "basically the same responses\nfor each of these pairs. And for the V2 cells,\nthere are always",
    "start": "3068100",
    "end": "3074460"
  },
  {
    "text": "at least some textures where\nthere's an extreme difference. So this is a really\ngood example.",
    "start": "3074460",
    "end": "3080070"
  },
  {
    "text": "There's a huge\ndifference in response here for these two textures,\nbut for actually many of the other textures, there's\nnot much of a difference.",
    "start": "3080070",
    "end": "3088130"
  },
  {
    "text": "So sort of a success. And the last thing I was\ngoing to tell you about",
    "start": "3088130",
    "end": "3093480"
  },
  {
    "text": "is that we think-- so this is really fitting,\ngiven what Jim DiCarlo told you",
    "start": "3093480",
    "end": "3099630"
  },
  {
    "text": "about, or what I assume\nhe told you about-- this idea of tolerance or\ninvariance versus selectivity.",
    "start": "3099630",
    "end": "3107220"
  },
  {
    "text": "We wanted to know,\nhow can we take what we know about\nthese V2 cells and pull it back into\nthe perceptual domain?",
    "start": "3107220",
    "end": "3113280"
  },
  {
    "text": "How can we ask,\nwhat is it that you could do with a\npopulation of V2 cells that you couldn't do with\na population of V1 cells?",
    "start": "3113280",
    "end": "3120900"
  },
  {
    "text": "And the thought was if the\nV2 cells are responding to these texture\nstatistics, then",
    "start": "3120900",
    "end": "3126750"
  },
  {
    "text": "if I made a whole bunch of\nsamples of the same texture, the V2 cells should be\nreally good at identifying",
    "start": "3126750",
    "end": "3132660"
  },
  {
    "text": "which texture that is-- which family it came from. And the V1 cells will be\nall confused by the fact",
    "start": "3132660",
    "end": "3139769"
  },
  {
    "text": "that those samples each\nhave different details that are shifting around. So the V1 cells will\nrespond to those details,",
    "start": "3139770",
    "end": "3146610"
  },
  {
    "text": "and they'll give a huge\nvariety of responses invariant to re-sampling\nfrom that family,",
    "start": "3146610",
    "end": "3153090"
  },
  {
    "text": "and the V2 cells will be\nmore invariant or more tolerant to re-sampling\nfrom that family.",
    "start": "3153090",
    "end": "3158310"
  },
  {
    "text": "That was the concept. And that turns out\nto be the case, so let me show you the evidence. So here's four\ndifferent textures,",
    "start": "3158310",
    "end": "3165720"
  },
  {
    "text": "four different-- what we\ncall different families. Here's images of three different\nexamples drawn from each.",
    "start": "3165720",
    "end": "3171360"
  },
  {
    "text": "So these are just\nthree samples drawn, starting with different\nwhite noise seeds. And you can see that they're\nactually physically different",
    "start": "3171360",
    "end": "3177750"
  },
  {
    "text": "images, but they look the same. Three again. Three again.",
    "start": "3177750",
    "end": "3183090"
  },
  {
    "text": "And so we got 100 cells from\nV1 and about 100 cells from V2.",
    "start": "3183090",
    "end": "3188915"
  },
  {
    "text": "The stimuli are presented\nfor 100 milliseconds. We do 20 repetitions each. We need a lot of data.",
    "start": "3188915",
    "end": "3194579"
  },
  {
    "text": "And what's shown here are\njust these this 4 by 3 array, but we actually had\n15 different families",
    "start": "3194580",
    "end": "3200280"
  },
  {
    "text": "and 15 examples of each. 20 repetitions of each of those. 225 stimuli times\n20 repetitions.",
    "start": "3200280",
    "end": "3206910"
  },
  {
    "text": "That's the experiment. So what we wanted to know\nis, does the hypothesis hold? And so here's an example.",
    "start": "3206910",
    "end": "3212570"
  },
  {
    "text": "These are responses laid\nout for these 12 stimuli. And what you can see is\nthat this is a V1 neuron--",
    "start": "3212570",
    "end": "3218760"
  },
  {
    "text": "a typical V1 neuron. You can see that\nthe neuron actually responds with a fair amount\nof variety in these columns.",
    "start": "3218760",
    "end": "3225390"
  },
  {
    "text": "That is, for different\nexemplars from the same family, there's some variety.",
    "start": "3225390",
    "end": "3230460"
  },
  {
    "text": "High response here,\nmedium response here, very low response here. And this is for these\nthree images, which",
    "start": "3230460",
    "end": "3236160"
  },
  {
    "text": "to us look basically the same. So this cell would not be\nvery good at separating out",
    "start": "3236160",
    "end": "3242680"
  },
  {
    "text": "or recognizing or helping in\nthe process of recognizing which kind of texture you\nwere looking at, because it's",
    "start": "3242680",
    "end": "3249720"
  },
  {
    "text": "flopping all over the place\nwhen we draw different samples. That, as compared to\nhaving to V2 cell--",
    "start": "3249720",
    "end": "3255780"
  },
  {
    "text": "this is a typical V2\ncell, which you can see is much more stable\nacross these columns. This is roughly the same\nresponse here, roughly the same",
    "start": "3255780",
    "end": "3262470"
  },
  {
    "text": "here, little bit of\nvariety in this one, roughly the same in this one. And sure enough, if you\nactually go and plot this,",
    "start": "3262470",
    "end": "3270220"
  },
  {
    "text": "V2 has much higher\nvariance across families. That's vertically. These are the V1 cells.",
    "start": "3270220",
    "end": "3276160"
  },
  {
    "text": "These are the V2 cells. And this is the variance\nacross families. This is the variance\nacross exemplars. V2 has higher variance\ntypically across families,",
    "start": "3276160",
    "end": "3284069"
  },
  {
    "text": "and V1 has higher\nvariance across exemplars. And now if you take the\npopulations of equal size--",
    "start": "3284070",
    "end": "3290380"
  },
  {
    "text": "100 of each, and you\nask well, how good would I be at taking\nthat population and identifying which\nfamily, which kind of texture",
    "start": "3290380",
    "end": "3302430"
  },
  {
    "text": "I'm looking at? And we do this with\ncross-validation and everything. I can give you the details\nlater, if you want to know.",
    "start": "3302430",
    "end": "3307790"
  },
  {
    "text": "We find V2 is always better\nthan V1 in doing this task. So we can do a better job\nin performing this task--",
    "start": "3307790",
    "end": "3316460"
  },
  {
    "text": "identifying which\nof these families a given example was drawn from\nif we look at V2 than if we",
    "start": "3316460",
    "end": "3323540"
  },
  {
    "text": "look at V1. And if we flip\nthat around and we try to do exemplar\nidentification, with 15 different examples\nof a given family--",
    "start": "3323540",
    "end": "3331400"
  },
  {
    "text": "if we say, which one was it? It turns out that V1 is\nbetter than V2 for that.",
    "start": "3331400",
    "end": "3336800"
  },
  {
    "text": "So we think of this\nas evidence that V2 has some invariance\nacross these samples,",
    "start": "3336800",
    "end": "3344260"
  },
  {
    "text": "whereas V1 is much\nmore specialized for the particular samples. This work started with\nthis fantastic post-doc",
    "start": "3344260",
    "end": "3351970"
  },
  {
    "text": "that I had mentioned\nearlier, Javier Portilla. Jeremy Freeman came\ninto my lab, and we just jumped all over this\nin making the metamers.",
    "start": "3351970",
    "end": "3359950"
  },
  {
    "text": "Josh McDermott is on\nhere because I usually also play the auditory\nexamples and walk",
    "start": "3359950",
    "end": "3365454"
  },
  {
    "text": "through a little\nbit of that work, but I'm going to\nleave that for him. And Corey Ziemba, who's a\nstudent who's in the lab",
    "start": "3365454",
    "end": "3371740"
  },
  {
    "text": "right now and is doing a\nlot of the physiology and did a lot of the physiology\nthat I showed you in Tony's lab.",
    "start": "3371740",
    "end": "3378280"
  },
  {
    "text": "And we were funded by\nHHMI and also the NIH. So thanks.",
    "start": "3378280",
    "end": "3383940"
  },
  {
    "start": "3383940",
    "end": "3404671"
  }
]
[
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6360"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6360",
    "end": "13350"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13350",
    "end": "18400"
  },
  {
    "text": " RUSS TEDRAKE: OK, let me say the\nbig idea for LQR trees again,",
    "start": "18400",
    "end": "25000"
  },
  {
    "text": "and you can tell me where\nyou want more details. So here's the basic story.",
    "start": "25000",
    "end": "34180"
  },
  {
    "text": "I've got some goal\nI want to get to, and I've got a\nlot of potential-- I'd like to be able to get there\nfrom every initial condition,",
    "start": "34180",
    "end": "41210"
  },
  {
    "text": "let's say. The idea was we\nknow how to design-- we know how to\nstabilize trajectories.",
    "start": "41210",
    "end": "47660"
  },
  {
    "text": "So let's just pick\na point at random, design a path to\nthe goal like that,",
    "start": "47660",
    "end": "55000"
  },
  {
    "text": "design the LTV LQR\nstabilizer on this.",
    "start": "55000",
    "end": "61207"
  },
  {
    "text": "The great thing about\nthat is, first of all, that it will locally\nstabilize the trajectory,",
    "start": "61207",
    "end": "66580"
  },
  {
    "text": "but second of all, because\nwe can compute not only-- because we are given both\nu equals some time varying,",
    "start": "66580",
    "end": "77560"
  },
  {
    "text": "we have a feedback\npolicy from that, but we're also given an\nestimate of the cost to go,",
    "start": "77560",
    "end": "84280"
  },
  {
    "text": "which is in this\ntime varying matrix,",
    "start": "84280",
    "end": "91780"
  },
  {
    "text": "yeah, the Riccati\nequation backwards. ",
    "start": "91780",
    "end": "97360"
  },
  {
    "text": "Because of that, when\nwe're doing our LQR design, we actually have\na good candidate for a Lyapunov function for the\nsystem around that trajectory.",
    "start": "97360",
    "end": "106450"
  },
  {
    "text": "So that's an\nimportant observation, that when we do LTV LQR on a\ntrajectory, we get both, OK.",
    "start": "106450",
    "end": "118510"
  },
  {
    "text": "Now this thing, for\nthe linear system, even the linear time\nvarying system, this",
    "start": "118510",
    "end": "124390"
  },
  {
    "text": "is a true Lyapunov function. From all initial\nstates, this function",
    "start": "124390",
    "end": "130030"
  },
  {
    "text": "will just only get\nsmaller with time, OK. But since the actual\nsystem is non-linear,",
    "start": "130030",
    "end": "136060"
  },
  {
    "text": "as I get further\nfrom my trajectory, some of the non-linearity\nis going to come in",
    "start": "136060",
    "end": "141880"
  },
  {
    "text": "and corrupt my\nLyapunov function.",
    "start": "141880",
    "end": "146890"
  },
  {
    "text": "At some point, when I get far\nenough from the trajectory, those higher order\nterms are going to mean that this thing\ndoesn't have a negative time",
    "start": "146890",
    "end": "154630"
  },
  {
    "text": "derivative. But what I care about\nfor a Lyapunov function is that this thing is\nless than or equal to 0.",
    "start": "154630",
    "end": "161030"
  },
  {
    "text": " So the idea with\nthe certificates",
    "start": "161030",
    "end": "167920"
  },
  {
    "text": "is to do a higher order\npolynomial expansion of the dynamics\nalong this trajectory",
    "start": "167920",
    "end": "174430"
  },
  {
    "text": "and try to estimate\nthe threshold where this stops being true, OK.",
    "start": "174430",
    "end": "182590"
  },
  {
    "text": "And that gives me,\nessentially, a funnel.",
    "start": "182590",
    "end": "189459"
  },
  {
    "text": "If I do it everywhere\nin time, that gives me a funnel along the trajectory\nover which I know the LQR",
    "start": "189460",
    "end": "200500"
  },
  {
    "text": "cost to go is a\nLyapunov function for the nonlinear system.",
    "start": "200500",
    "end": "206950"
  },
  {
    "text": "And it's mostly conservative. The way that we\nconstruct that threshold",
    "start": "206950",
    "end": "213670"
  },
  {
    "text": "is mostly conservative. The only weakness\nof it-- meaning the real basin of\nattraction should be bigger",
    "start": "213670",
    "end": "218965"
  },
  {
    "text": "than this estimate. The only weakness\nis that I'm only doing it by doing a polynomial\nexpansion of the system here.",
    "start": "218965",
    "end": "226940"
  },
  {
    "text": "So if there was a hard\ndiscontinuity right next to the trajectory\nthat didn't show up in the Taylor expansion,\nthen I wouldn't ever see it.",
    "start": "226940",
    "end": "233590"
  },
  {
    "text": "I'm not exhaustively\nsearching the non-linearity around the trajectory. I'm just saying, along\nthis trajectory, what",
    "start": "233590",
    "end": "240640"
  },
  {
    "text": "are the higher order expansion? I do a Taylor expansion-- a\nthird order, fourth order, whatever it takes, and\nI use that to check when",
    "start": "240640",
    "end": "247630"
  },
  {
    "text": "it breaks the cost to go, OK.",
    "start": "247630",
    "end": "253507"
  },
  {
    "text": "So that's the certificate. That's just, if I have\na single trajectory, that I can use this. The real cool thing is that\nthanks to Pablo and [? Sasha ?]",
    "start": "253507",
    "end": "260648"
  },
  {
    "text": "[? McGretzky, ?] we can do\nthat efficiently with a convex optimization. And then the idea is, if I can\ndo it for a single trajectory,",
    "start": "260649",
    "end": "268990"
  },
  {
    "text": "then why not put\nthat back into sort of an RRT kind of\nframework and try",
    "start": "268990",
    "end": "274240"
  },
  {
    "text": "to build lots of trajectories\nthat are stabilized? OK, so the first step was just\nto pick a point at random,",
    "start": "274240",
    "end": "279370"
  },
  {
    "text": "design a single trajectory. The second step is, let's\npick a new random point. I don't actually have to go\nall the way back to my goal.",
    "start": "279370",
    "end": "286150"
  },
  {
    "text": "I just have to go to the nearest\npoint on the current tree and stabilize that.",
    "start": "286150",
    "end": "293590"
  },
  {
    "text": "And then I pick another\npoint, find the nearest point on the tree, build\nthe trajectory in like that,",
    "start": "293590",
    "end": "299770"
  },
  {
    "text": "stabilize that. If I pick a new point\nand it's already in the basin of attraction,\nI don't need to add an edge.",
    "start": "299770",
    "end": "306430"
  },
  {
    "text": "That would be a\nwaste of my time. So the effect is I get these--",
    "start": "306430",
    "end": "313780"
  },
  {
    "text": "I didn't say carefully\nwhat the results are, because I can't prove them yet. This is still hot off the press. But I think that I can say that\nit probabilistically covers",
    "start": "313780",
    "end": "324240"
  },
  {
    "text": "the reachable state space. Every place that I can\nget to the goal from, there exists a controller.",
    "start": "324240",
    "end": "330270"
  },
  {
    "text": "If I design enough\nsamples, I should be able to get to\nthe goal, given I do enough steps in my LQR tree.",
    "start": "330270",
    "end": "335910"
  },
  {
    "text": "So as time goes to\ninfinity, the entire space will be covered with basin of\nattraction of a controller that",
    "start": "335910",
    "end": "342220"
  },
  {
    "text": "gets me to the goal, which is\na pretty powerful thing to say, if you're willing to wait\ntill time goes to infinity.",
    "start": "342220",
    "end": "348030"
  },
  {
    "text": "And the practical thing\nthat's nice about it is it seems to happen pretty\nquick with a handful of-- with a fairly small\nnumber of trajectories.",
    "start": "348030",
    "end": "355040"
  },
  {
    "text": "Yeah? [? John. ?] AUDIENCE: If you want\nto guarantee [INAUDIBLE] [? in your ?] system has that,\nwhich property would you have [? to let it ?] sample inside\nthe basins of attraction?",
    "start": "355040",
    "end": "362670"
  },
  {
    "text": "RUSS TEDRAKE: Yeah,\nso that's why I have to qualify the guarantees. I'm only saying the\nnonlinear system as represented as\nthe Taylor expansion",
    "start": "362670",
    "end": "369540"
  },
  {
    "text": "around the trajectories. That's the weakness. So it really only works\nfor smooth systems. If there's a cliff here and I\ndesign a trajectory right here,",
    "start": "369540",
    "end": "376789"
  },
  {
    "text": "it might come up with [? a ?]\nsaying a basin of attraction's here, even though\nthat's just not true. OK.",
    "start": "376790",
    "end": "382070"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] RUSS TEDRAKE: If I\nsmooth the cliff-- [? sorry, John. ?] If I smooth\nthe cliff and therefore,",
    "start": "382070",
    "end": "388050"
  },
  {
    "text": "when I Taylor expand here, I can\nsee that there's a cliff there, then I'd like to think that the\ncertificates would do the right",
    "start": "388050",
    "end": "395919"
  },
  {
    "text": "thing. But if it's a hard cliff where\nthe higher order expansion here doesn't see that cliff,\nthen there's no hope.",
    "start": "395920",
    "end": "402823"
  },
  {
    "text": "AUDIENCE: [? If ?] [? you ?]\n[INAUDIBLE] inside the basin, [? though, ?] couldn't\nyou [INAUDIBLE]??",
    "start": "402823",
    "end": "408128"
  },
  {
    "text": "RUSS TEDRAKE: That's\na good question. So it's just building\nmore and more accurate certificates as time\ngoes to infinity.",
    "start": "408128",
    "end": "414120"
  },
  {
    "text": "It could be. It could be a good idea. My suspicion is\nthat, in practice,",
    "start": "414120",
    "end": "419845"
  },
  {
    "text": "this is going to be good enough\nfor-- and we're not going to want to do the-- maybe I'm just the kind of\nguy that cuts the corners,",
    "start": "419845",
    "end": "426750"
  },
  {
    "text": "but I think this is a\npretty good solution. Ernesto. AUDIENCE: [INAUDIBLE]\n[? basin ?] [? of attraction ?]",
    "start": "426750",
    "end": "432198"
  },
  {
    "text": "[INAUDIBLE]. RUSS TEDRAKE: So I use-- whenever I design\neach trajectory, I use [? DR ?]\n[? call. ?] Why not?",
    "start": "432198",
    "end": "438210"
  },
  {
    "text": "But it's so I could say they're\nlocally optimal in the branches that they are, just because\nthat's easy to accomplish.",
    "start": "438210",
    "end": "446400"
  },
  {
    "text": "But there's no sense in\nwhich it's globally optimal. So I just try to say that\nevery state will eventually",
    "start": "446400",
    "end": "452520"
  },
  {
    "text": "get there and not that\nit'll get there optimally. mm-hmm. AUDIENCE: But again, if\nyou allowed it to sample",
    "start": "452520",
    "end": "459250"
  },
  {
    "text": "inside the basins\nof attraction, you would probabilistically get\nsome kind of convergence",
    "start": "459250",
    "end": "464960"
  },
  {
    "text": "to global optimal. ",
    "start": "464960",
    "end": "470022"
  },
  {
    "text": "RUSS TEDRAKE: There are ways\nto try to get at that problem. I don't think it's a one-step\nchange from what I said.",
    "start": "470022",
    "end": "475560"
  },
  {
    "text": "I think you have to\ndo something more. I mean, any one of\nthese trajectories--",
    "start": "475560",
    "end": "480660"
  },
  {
    "text": "maybe that's getting busy. Any one of those trajectories\nis just locally optimal. So let's consider the case\nwhere the goal is here.",
    "start": "480660",
    "end": "488760"
  },
  {
    "text": "There's something\nhere, and I did this. And for some reason,\nI got a trajectory",
    "start": "488760",
    "end": "494250"
  },
  {
    "text": "like that, which is\nlocally optimal but not globally optimal, because\nthere's a shorter path here.",
    "start": "494250",
    "end": "501630"
  },
  {
    "text": "So I need to somehow-- I would need to somehow\ninclude the mechanism, which is, I think, what\nyou're getting at, to eventually find a different\npath to the same place",
    "start": "501630",
    "end": "511680"
  },
  {
    "text": "and overwrite the old path. And I don't have any\nmechanism for that inside. And it turns out\nto-- that's actually",
    "start": "511680",
    "end": "517140"
  },
  {
    "text": "what I was going for initially. Turns out to be a little\nbit nontrivial to do. Chris Atkeson has\na nice idea that",
    "start": "517140",
    "end": "524642"
  },
  {
    "text": "goes towards doing\nthat a little bit more on composing\ntrajectory libraries. But I gave up\noptimality and tried",
    "start": "524642",
    "end": "530700"
  },
  {
    "text": "to get coverage with a basin\nof attraction in that design. ",
    "start": "530700",
    "end": "537139"
  },
  {
    "text": "So some of you have been\ntalking to me about the projects and have been asking\nabout these things.",
    "start": "537140",
    "end": "543590"
  },
  {
    "text": "So I think Mark and Matt\nare thinking about trying to help with this-- I mean, this is new.",
    "start": "543590",
    "end": "549640"
  },
  {
    "text": "I mean, you guys can\ndefinitely help with the idea. So we're trying to\nfigure out, for instance,",
    "start": "549640",
    "end": "556810"
  },
  {
    "text": "if there's actuator limits. These guys are talking\nabout trying to figure out how to compute the certificates,\nand even the LQR stabilizer,",
    "start": "556810",
    "end": "565260"
  },
  {
    "text": "if you not only have a\nquadratic [INAUDIBLE] on u but have some hard limits on\nu, because that's a problem we actually hit in practice.",
    "start": "565260",
    "end": "571505"
  },
  {
    "text": "So one of the final projects\nin the class, I think, is going to be\nhelping with that. There's problems of, how do\nyou design the stabilizer",
    "start": "571505",
    "end": "577680"
  },
  {
    "text": "through impacts and\nin periodic systems. There's lots of good questions. So if you're excited\nabout that idea--",
    "start": "577680",
    "end": "583620"
  },
  {
    "text": "I'm definitely excited\nabout the idea right now-- then I'll see what\nyou wrote up today,",
    "start": "583620",
    "end": "589350"
  },
  {
    "text": "but we could maybe try to\nfind a way to connect that. I'd be thrilled to have\nyour help in making",
    "start": "589350",
    "end": "595440"
  },
  {
    "text": "that idea more relevant. Yeah?",
    "start": "595440",
    "end": "602339"
  },
  {
    "text": "OK. Does that cover? ",
    "start": "602340",
    "end": "609360"
  },
  {
    "text": "Now for something completely\ndifferent, although related, of course.",
    "start": "609360",
    "end": "615310"
  },
  {
    "text": "So in the LQR trees and\nbasically in everything that we've done so\nfar in class, we've",
    "start": "615310",
    "end": "621480"
  },
  {
    "text": "made a handful of\nimportant assumptions. ",
    "start": "621480",
    "end": "636330"
  },
  {
    "text": "The most important\none, probably, is we've always assumed that we\nhave the model of the system. ",
    "start": "636330",
    "end": "651810"
  },
  {
    "text": "So next week we're\ngoing to get at, how do you do some of\nthese optimizations when you don't even\nhave a model, OK.",
    "start": "651810",
    "end": "658899"
  },
  {
    "text": " We've also assumed so far that\nthe current state of the system",
    "start": "658900",
    "end": "666339"
  },
  {
    "text": "is known.  In other words, the state of\nthe robot is fully observable.",
    "start": "666340",
    "end": "672906"
  },
  {
    "start": "672906",
    "end": "681660"
  },
  {
    "text": "If I stop assuming\nthat, we start getting into discussions\nabout state estimation, and we will towards\nthe end of the class.",
    "start": "681660",
    "end": "688800"
  },
  {
    "text": "And there's another\nassumption we've been making, which is that the dynamics\nare deterministic,",
    "start": "688800",
    "end": "699240"
  },
  {
    "text": "let's say, that pretty\nmuch, the system goes",
    "start": "699240",
    "end": "712860"
  },
  {
    "text": "where I think it's going to go.  Now I chose to write that\nand then cross it out,",
    "start": "712860",
    "end": "720300"
  },
  {
    "text": "because that's not quite\nwhat we're assuming, OK. I want to write that. But maybe what's\na-- if we really",
    "start": "720300",
    "end": "727185"
  },
  {
    "text": "were assuming that the\ndynamics were deterministic, then we wouldn't have been\nspending much time talking about feedback at all.",
    "start": "727185",
    "end": "732840"
  },
  {
    "text": "We would have been just\nfocused on open loop things. So let's think. Let's have a short\nphilosophical argument",
    "start": "732840",
    "end": "739769"
  },
  {
    "text": "about what we're\nactually doing, yeah? So we're not quite assuming\nthat it's deterministic.",
    "start": "739770",
    "end": "745980"
  },
  {
    "text": "Maybe a better way to\ndescribe what we're doing is we're assuming something\nspecific about the disturbances",
    "start": "745980",
    "end": "752640"
  },
  {
    "text": "in the system. We're assuming that\ndisturbances look",
    "start": "752640",
    "end": "762060"
  },
  {
    "text": "like a change in\ninitial conditions. That's one way to say\nit, an un-modeled change",
    "start": "762060",
    "end": "772710"
  },
  {
    "text": "in initial conditions. ",
    "start": "772710",
    "end": "791279"
  },
  {
    "text": "By virtue of talking about\nthese feedback stabilizers, the motivation is that, OK,\nI'm following this trajectory.",
    "start": "791280",
    "end": "798900"
  },
  {
    "text": "When the model's\nright, all is good. If something does\nhappen, then OK, it's going to move me\nsomewhere in state space.",
    "start": "798900",
    "end": "805210"
  },
  {
    "text": "But as long as that's in\nthe basin of attraction-- the whole idea of really\na basin of attraction is going at the idea that\nI can handle disturbances",
    "start": "805210",
    "end": "811860"
  },
  {
    "text": "by just being robust in state.  But that's actually a\nsubtle thing to assume.",
    "start": "811860",
    "end": "819117"
  },
  {
    "text": "I want to be a little bit more\nexplicit about what that means. ",
    "start": "819117",
    "end": "824628"
  },
  {
    "text": "Really, it sort of\nimplies that we're assuming that disturbances\nare impulsive, not constant,",
    "start": "824628",
    "end": "842250"
  },
  {
    "text": "instantaneous, Impulsive. If a disturbance\nfor my walking robot",
    "start": "842250",
    "end": "847709"
  },
  {
    "text": "was someone put a\nnew weight on my leg, then that's not something\nthat our designs so far have",
    "start": "847710",
    "end": "854250"
  },
  {
    "text": "handled, because that's\nmore like the model changed. We're talking about\nsomething that it moved me,",
    "start": "854250",
    "end": "859470"
  },
  {
    "text": "and now I have to deal with it. So if the disturbance\nlasts for a long time, then that actually feels a\nlot more like a model change.",
    "start": "859470",
    "end": "866713"
  },
  {
    "text": "But if it's impulsive,\nI can think of it as a change in\ninitial condition. And the other thing that\nthat implicitly assumes",
    "start": "866713",
    "end": "875339"
  },
  {
    "text": "is that the\ndisturbances are rare. ",
    "start": "875340",
    "end": "886530"
  },
  {
    "text": "If I got impulsive disturbances\n1,000 times a second, then,",
    "start": "886530",
    "end": "892350"
  },
  {
    "text": "again, my completely\ndeterministic analysis isn't probably the\nrelevant one, OK.",
    "start": "892350",
    "end": "899280"
  },
  {
    "text": "So those are-- implicitly, we've\nbeen making these assumptions the whole time. The whole idea of talking\nabout basins of attraction",
    "start": "899280",
    "end": "906277"
  },
  {
    "text": "of deterministic systems\nand doing feedback design implicitly makes\nthat assumption. So there's three\nthings there, the fact",
    "start": "906277",
    "end": "913080"
  },
  {
    "text": "that it's un-modeled and\nimpulsive and rare, I guess. ",
    "start": "913080",
    "end": "922110"
  },
  {
    "text": "If your disturbances are\nnot instantaneous rare disturbances, then I think\nI would advocate quickly",
    "start": "922110",
    "end": "929790"
  },
  {
    "text": "for starting to think\nabout your dynamics as not deterministic dynamics\nbut as a stochastic dynamics,",
    "start": "929790",
    "end": "936000"
  },
  {
    "text": "OK. And even if they are\nimpulsive and rare, but if you have a\nmodel of them, then",
    "start": "936000",
    "end": "943380"
  },
  {
    "text": "you should still be able to do\nbetter by explicitly letting your feedback design reason\nabout the stochastic dynamics,",
    "start": "943380",
    "end": "952350"
  },
  {
    "text": "OK. So today I want to\nstart talking about-- I want to start breaking\ndown our assumptions.",
    "start": "952350",
    "end": "957798"
  },
  {
    "text": "And throughout the\nrest of the class, we're going to try\nto break these down. ",
    "start": "957798",
    "end": "963430"
  },
  {
    "text": "Let's start breaking\ndown the assumption of deterministic dynamics, OK.",
    "start": "963430",
    "end": "968988"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] [? or ?]\ntalking about the LTV LQR. RUSS TEDRAKE: Mm-hmm. AUDIENCE: [INAUDIBLE]\nactually saw something,",
    "start": "968988",
    "end": "974730"
  },
  {
    "text": "like if we the actually have\nthis [? passive ?] transition model and we move somewhere,\nand then we're a little bit off",
    "start": "974730",
    "end": "981180"
  },
  {
    "text": "from the trajectory, then\nyou look at the policy, which would bring this back\n[INAUDIBLE] [? projected ?]",
    "start": "981180",
    "end": "986340"
  },
  {
    "text": "[? and ?] go back. RUSS TEDRAKE: I think the\nanswer to your question is yes. So one of the things we're going\nto do today is show that the--",
    "start": "986340",
    "end": "995226"
  },
  {
    "text": "it's sort of subtle\nthat that's yes. But anybody who knows linear\nquadratic Gaussian control,",
    "start": "995226",
    "end": "1001190"
  },
  {
    "text": "yeah, well, it turns\nout that we're actually doing linear quadratic\nGaussian control,",
    "start": "1001190",
    "end": "1006709"
  },
  {
    "text": "but that's a\nsurprising result, OK. So in the specific case\nof linear dynamics,",
    "start": "1006710",
    "end": "1014510"
  },
  {
    "text": "quadratic cost, Gaussian noise,\nthen what you said is true. So that's a special case\nthat we'll see quickly.",
    "start": "1014510",
    "end": "1023030"
  },
  {
    "text": "But in general, it's not true. ",
    "start": "1023030",
    "end": "1034520"
  },
  {
    "text": "Right, so and again, this\nis leading into next week. We're going to start\ntalking about doing",
    "start": "1034520",
    "end": "1040039"
  },
  {
    "text": "these optimal controlled\nderivations without any model. But today let's think\nabout what happens",
    "start": "1040040",
    "end": "1046459"
  },
  {
    "text": "if we have a stochastic model. ",
    "start": "1046460",
    "end": "1058970"
  },
  {
    "text": "OK, lots of ways people-- there's lots of\ndifferent notations people use to talk about\nstochastic dynamics. The one I'll use is, I\nthink, the most popular one.",
    "start": "1058970",
    "end": "1067220"
  },
  {
    "text": "We still got our standard\nequations of motion,",
    "start": "1067220",
    "end": "1075198"
  },
  {
    "text": "but we're going to add an\nadditional input, which is some disturbance w\nas an additional input",
    "start": "1075198",
    "end": "1082429"
  },
  {
    "text": "into our dynamics, where w\nof t is some noise process.",
    "start": "1082430",
    "end": "1091130"
  },
  {
    "start": "1091130",
    "end": "1101040"
  },
  {
    "text": "OK, but if we let the noise\ncome in through an input here, then we can still think about\nit as a deterministic function,",
    "start": "1101040",
    "end": "1106340"
  },
  {
    "text": "our dynamics as a\ndeterministic function, and keep it mostly the same as\nwhat we've been thinking about.",
    "start": "1106340",
    "end": "1111410"
  },
  {
    "text": "Now some people don't like\ndefining noise processes in continuous time. ",
    "start": "1111410",
    "end": "1119990"
  },
  {
    "text": "It's a little bit more\nnatural to describe them in discrete time, and as\nwe've done in the other class,",
    "start": "1119990",
    "end": "1125990"
  },
  {
    "text": "let's do the discrete\ntime case first. So in discrete time,\nwe'll do the same thing.",
    "start": "1125990",
    "end": "1142520"
  },
  {
    "start": "1142520",
    "end": "1149570"
  },
  {
    "text": "But now maybe we can-- it's easier to think about\nwhat w of n might be.",
    "start": "1149570",
    "end": "1155940"
  },
  {
    "text": "So for instance, w of n might\nbe some iid Gaussian process",
    "start": "1155940",
    "end": "1162049"
  },
  {
    "text": "or something like that, which\nis just a complicated way",
    "start": "1162050",
    "end": "1171260"
  },
  {
    "text": "to say that at each n, w\nn is sampled independently",
    "start": "1171260",
    "end": "1189080"
  },
  {
    "text": "from a Gaussian. Let's say a normal distribution,\nlike something like that.",
    "start": "1189080",
    "end": "1196250"
  },
  {
    "text": "So when I'm simulating\nthis in MATLAB, if I have-- I can simulate an\niid Gaussian process",
    "start": "1196250",
    "end": "1201260"
  },
  {
    "text": "by just every time step\ncalling rand n, yeah, as if-- and it's independent from the\n[? w's ?] I picked before.",
    "start": "1201260",
    "end": "1208009"
  },
  {
    "text": "That's a pretty good model. Now one thing I want to\navoid talking about today",
    "start": "1208010",
    "end": "1214770"
  },
  {
    "text": "so far is, let's still assume\nthat we have perfect state",
    "start": "1214770",
    "end": "1224030"
  },
  {
    "text": "information. ",
    "start": "1224030",
    "end": "1234580"
  },
  {
    "text": "So I don't want to worry\nabout sensor noise yet. It turns out it'll be\npretty natural to think about it with some\nof the same tools,",
    "start": "1234580",
    "end": "1240330"
  },
  {
    "text": "but let's just assume for\nnow that when I'm in state x, I know I'm in state x exactly.",
    "start": "1240330",
    "end": "1245669"
  },
  {
    "text": "But if I'm trying\nto think about, into the future,\nwhat's going to happen, what's the optimal thing to do,\nI have to worry about the fact",
    "start": "1245670",
    "end": "1252270"
  },
  {
    "text": "that the noise in the system\nis going to push me around. ",
    "start": "1252270",
    "end": "1261410"
  },
  {
    "text": "OK, so we updated\nour dynamic equation.",
    "start": "1261410",
    "end": "1266672"
  },
  {
    "text": "We better start--\nif we're thinking about this in an\noptimal control sense, we better also update our\ndefinition for optimality.",
    "start": "1266672",
    "end": "1274616"
  },
  {
    "start": "1274616",
    "end": "1291169"
  },
  {
    "text": "So it used to be that we said\nJ in the discrete time case",
    "start": "1291170",
    "end": "1297800"
  },
  {
    "text": "was just some sum from n\nequals 0 to n of g xn un.",
    "start": "1297800",
    "end": "1305960"
  },
  {
    "start": "1305960",
    "end": "1312520"
  },
  {
    "text": "The problem with that\nnow is that xn, this is going to be-- this is\nnow a random process, yeah?",
    "start": "1312520",
    "end": "1319750"
  },
  {
    "start": "1319750",
    "end": "1326410"
  },
  {
    "text": "If I run from the same\ninitial conditions with even the same\nopen loop tape,",
    "start": "1326410",
    "end": "1333280"
  },
  {
    "text": "let's say, the\nsystem five times, this is going to be a different\nvalue every time I run it.",
    "start": "1333280",
    "end": "1341049"
  },
  {
    "text": "Exit time three will\nbe different every time I run it, OK, which\nmeans J is also going to be a random\nvariable, a random.",
    "start": "1341050",
    "end": "1349029"
  },
  {
    "start": "1349030",
    "end": "1355830"
  },
  {
    "text": "So it doesn't quite make sense\nto say my notion of optimality",
    "start": "1355830",
    "end": "1361965"
  },
  {
    "text": "is some random variable.  We want to choose a property\nof that random variable",
    "start": "1361965",
    "end": "1368970"
  },
  {
    "text": "that we care about. There's different\nschools-- again, being philosophical\na little bit,",
    "start": "1368970",
    "end": "1374170"
  },
  {
    "text": "there's different schools of\nthought in control theory. Some people say the thing\nyou should care about,",
    "start": "1374170",
    "end": "1379650"
  },
  {
    "text": "the only thing you\nshould worry about is the worst case behavior. You want to worry about the\ntails of your distributions",
    "start": "1379650",
    "end": "1385230"
  },
  {
    "text": "and make absolutely\nsure that my plane-- if I'm riding on a plane\nfrom here to California,",
    "start": "1385230",
    "end": "1390348"
  },
  {
    "text": "it's not going to\nfall out of the sky with five nines of\nprobability or something, OK.",
    "start": "1390348",
    "end": "1396243"
  },
  {
    "text": "I actually don't subscribe-- OK, when I'm riding on a plane,\nI do subscribe to that, OK. But when I'm building\nrobots that I",
    "start": "1396243",
    "end": "1401850"
  },
  {
    "text": "don't have to put my\nlife in jeopardy for, I don't believe in that. And I actually don't\nthink animals do that.",
    "start": "1401850",
    "end": "1409799"
  },
  {
    "text": "I think if animals\nwere so conservative-- so that's the robust control\napproach, what I just described, worrying\nabout the worst case.",
    "start": "1409800",
    "end": "1417000"
  },
  {
    "text": "And the problem with robust\ncontrol, the well documented, well discussed problem\nwith robust control is it tends to come up\nwith conservative control",
    "start": "1417000",
    "end": "1423540"
  },
  {
    "text": "strategies. So if I'm worrying about\nnever running into the table, then I'm never going to go\nanywhere near that table.",
    "start": "1423540",
    "end": "1430147"
  },
  {
    "text": " There's another\napproach, which I",
    "start": "1430147",
    "end": "1436770"
  },
  {
    "text": "prefer, that tends to be more\ncommon in the optimal control community, is to worry about\nmaximizing the expected",
    "start": "1436770",
    "end": "1442980"
  },
  {
    "text": "returns, OK. So now let's define J as the\nexpected value of this cost",
    "start": "1442980",
    "end": "1455919"
  },
  {
    "text": "function. ",
    "start": "1455920",
    "end": "1469390"
  },
  {
    "text": "There's a really obvious\nreason why the optimal control people choose to do that.",
    "start": "1469390",
    "end": "1475049"
  },
  {
    "text": "It's because we already made a\ndecision to do additive costs. Expectations play\nbeautifully with summations,",
    "start": "1475050",
    "end": "1482220"
  },
  {
    "text": "and so our life is going\nto stay clean and good if we're willing to do the\nexpected value derivations, OK.",
    "start": "1482220",
    "end": "1488910"
  },
  {
    "text": "But also philosophically, I\nthink that me as an animal, I maximize my expected reward.",
    "start": "1488910",
    "end": "1494670"
  },
  {
    "text": "Or a gazelle running\nthrough the field, I think, is maximizing expected reward.",
    "start": "1494670",
    "end": "1499860"
  },
  {
    "text": "I mean, on average, it's\ndoing spectacularly well. And every once in a\nwhile it wipes out",
    "start": "1499860",
    "end": "1506010"
  },
  {
    "text": "and falls down and breaks\nits leg and gets eaten. But if it was worrying\nabout that all the time,",
    "start": "1506010",
    "end": "1512350"
  },
  {
    "text": "then it would never\nrun as fast as it does. So-- or as aggressively\nas it does.",
    "start": "1512350",
    "end": "1518970"
  },
  {
    "text": "So I think,\npersonally, if you want to build aggressive\nrobots, you've got to stop worrying about\nguarantees of stability,",
    "start": "1518970",
    "end": "1525480"
  },
  {
    "text": "of performance. Just try to maximize\nthe average performance. I think that's where\nI've put my chips.",
    "start": "1525480",
    "end": "1533910"
  },
  {
    "text": "OK, so now, just to be\nclear here, so x-- again, every time I run it,\neven with an open loop u,",
    "start": "1533910",
    "end": "1542010"
  },
  {
    "text": "if I completely\ncontrol u, so u is not a random variable but\nsome open loop tape, lets say, x will still\nbe a random variable, OK.",
    "start": "1542010",
    "end": "1550020"
  },
  {
    "text": "But J is not. J is saying that,\ngiven some control",
    "start": "1550020",
    "end": "1555750"
  },
  {
    "text": "policy, some initial\nconditions, there is a well defined cost that I--\nexpected cost that I receive.",
    "start": "1555750",
    "end": "1563473"
  },
  {
    "text": "And that's something\nI can optimize, OK. ",
    "start": "1563473",
    "end": "1569710"
  },
  {
    "text": "Does that make sense? OK, so I want to think about\nthe implications of having",
    "start": "1569710",
    "end": "1577990"
  },
  {
    "text": "these things turn\ninto random variables with a simple example, OK. ",
    "start": "1577990",
    "end": "1590710"
  },
  {
    "text": "And that example I\nlike, the one I like is a particle sitting in a bowl.",
    "start": "1590710",
    "end": "1596629"
  },
  {
    "text": "Let's say some particle\nin a potential well. So let's say gravity\nis like this,",
    "start": "1596630",
    "end": "1605710"
  },
  {
    "text": "and I've got some\nbowl I'm sitting in, and this particle\nis going to want to roll down that bowl, OK.",
    "start": "1605710",
    "end": "1612919"
  },
  {
    "text": "But to make it\ninteresting, we're going to say that this particle\nis subject to Brownian motion.",
    "start": "1612920",
    "end": "1617930"
  },
  {
    "text": "Do you guys know what\nBrownian motion is? I guess-- was it--",
    "start": "1617930",
    "end": "1624460"
  },
  {
    "text": "I guess if you look down at a\nPetri dish of very small things",
    "start": "1624460",
    "end": "1629909"
  },
  {
    "text": "and they don't\nsit still, there's debate about exactly the\nphysical mechanisms of it,",
    "start": "1629910",
    "end": "1635980"
  },
  {
    "text": "but phenomenologically, you\ncan see very small cells that are not actively\nmotile by themselves",
    "start": "1635980",
    "end": "1643960"
  },
  {
    "text": "move around in a random\nfashion, doing random walks and things like this. So people-- I won't get\ninto the philosophy of--",
    "start": "1643960",
    "end": "1652420"
  },
  {
    "text": "the philosophical debate\nof whether there exists stochasticity in the world,\nbut I think stochasticity",
    "start": "1652420",
    "end": "1658630"
  },
  {
    "text": "is certainly a relevant\nmodel for a lot of things we're doing here. And I don't want to\nget quantum in class.",
    "start": "1658630",
    "end": "1665620"
  },
  {
    "text": "OK, but let's just\nsay that this guy is subject to the\ndynamics of this bowl.",
    "start": "1665620",
    "end": "1670690"
  },
  {
    "text": "But on top of that\ndynamics of this bowl, it has a tendency to jitter\naround a little bit, OK. So I'll write down the dynamics.",
    "start": "1670690",
    "end": "1678430"
  },
  {
    "text": "I'll keep it discrete for now. So let's say at every time\nstep, the difference--",
    "start": "1678430",
    "end": "1685720"
  },
  {
    "text": "the update looks like\nthe gradient of that bowl",
    "start": "1685720",
    "end": "1692500"
  },
  {
    "text": "it's trying to go down that\nbowl plus some random noise.",
    "start": "1692500",
    "end": "1699940"
  },
  {
    "text": "I'll call it z of n. And this, again, I'll assume\nis iid, Independent Identically",
    "start": "1699940",
    "end": "1707740"
  },
  {
    "text": "Distributed Gaussian noise. ",
    "start": "1707740",
    "end": "1719980"
  },
  {
    "text": "So if you've never taken a class\nwith all this random variables and everything, I hope most of\nthis will still come through.",
    "start": "1719980",
    "end": "1725830"
  },
  {
    "text": "I'll throw a few of these words\nand try to be soft about it. If you have questions about\nany of these, just ask me. I think that we're\ngoing to be able to say",
    "start": "1725830",
    "end": "1732160"
  },
  {
    "text": "things that are\nfairly mechanically intuitive and helpful. So I hope it's\naccessible to everybody.",
    "start": "1732160",
    "end": "1738280"
  },
  {
    "text": "And if it's not, ask me. OK, so this is a reasonable\ndynamical system now.",
    "start": "1738280",
    "end": "1746440"
  },
  {
    "text": "It's attempting\nto, on each update, having gone down the gradient\nplus some random noise, OK.",
    "start": "1746440",
    "end": "1754480"
  },
  {
    "text": "Let's make our lives easier\nby choosing u of x to be--",
    "start": "1754480",
    "end": "1762160"
  },
  {
    "text": "how about that? That's pretty nice, right? ",
    "start": "1762160",
    "end": "1767200"
  },
  {
    "text": "It makes our life good if\neverything is quadratic. Then this thing turns out\nto be negative alpha x.",
    "start": "1767200",
    "end": "1773500"
  },
  {
    "start": "1773500",
    "end": "1782790"
  },
  {
    "text": "OK, so just to make sure\nwe're thinking about it, if the noise is 0, then what's\ngoing to happen in this system?",
    "start": "1782790",
    "end": "1789630"
  },
  {
    "start": "1789630",
    "end": "1796650"
  },
  {
    "text": "I've got a discrete\ntime system, which, if I move that back\nover to the other side",
    "start": "1796650",
    "end": "1802620"
  },
  {
    "text": "like we're accustomed\nto, it goes like this. ",
    "start": "1802620",
    "end": "1811830"
  },
  {
    "text": "So how does that thing behave? ",
    "start": "1811830",
    "end": "1817730"
  },
  {
    "text": "Where's the fixed point?  At 0. And when is it stable?",
    "start": "1817730",
    "end": "1823500"
  },
  {
    "start": "1823500",
    "end": "1840710"
  },
  {
    "text": "When's it stable? Discrete time linear system. AUDIENCE: [INAUDIBLE] equals\n0 [? of 1 ?] but [INAUDIBLE]..",
    "start": "1840710",
    "end": "1847588"
  },
  {
    "text": "RUSS TEDRAKE: Yeah. AUDIENCE: [INAUDIBLE]\n[? positive ?] [? x? ?] RUSS TEDRAKE: No, you're\nthinking too continuous time.",
    "start": "1847588",
    "end": "1855980"
  },
  {
    "text": "In discrete time, your bounds on\nyour eigenvalues are between--",
    "start": "1855980",
    "end": "1862309"
  },
  {
    "text": "the absolute value has to be\nless than 1, which I think, in this case, means alpha has\ngot to be between 0 and 2,",
    "start": "1862310",
    "end": "1870460"
  },
  {
    "text": "yeah?  Everybody OK with that?",
    "start": "1870460",
    "end": "1875480"
  },
  {
    "text": "Yeah. That wasn't supposed to be the\nbig insight for the lecture, but. ",
    "start": "1875480",
    "end": "1884180"
  },
  {
    "text": "OK, so the reason I\nwanted to say that-- OK, so we definitely have\nsome stable dynamics pushing",
    "start": "1884180",
    "end": "1893330"
  },
  {
    "text": "us this way in this bowl. The picture tells you that. The math tells you that. We have some stable dynamics\nthat's pushing us towards here,",
    "start": "1893330",
    "end": "1900830"
  },
  {
    "text": "and then we have something\nthat's pushing us out, which is that noise. If I was-- maybe just\nas a thought exercise,",
    "start": "1900830",
    "end": "1906770"
  },
  {
    "text": "if my bowl had been\nflat, if alpha was 0, and I've got this thing\nsubject to Brownian motion,",
    "start": "1906770",
    "end": "1913789"
  },
  {
    "text": "then if I look at it at time\n100, where's it going to be?",
    "start": "1913790",
    "end": "1921310"
  },
  {
    "text": "I mean, it could go\nsort of anywhere, yeah? If it's in this bowl and it's\nsubject to Brownian motion,",
    "start": "1921310",
    "end": "1929590"
  },
  {
    "text": "then where's it going\nto be at time 100? AUDIENCE: [INAUDIBLE]\nclose to [INAUDIBLE]..",
    "start": "1929590",
    "end": "1934822"
  },
  {
    "text": "RUSS TEDRAKE: You'd expect\nit, with high probability, to be around here. There's a chance-- I mean, even if it turns--",
    "start": "1934822",
    "end": "1940450"
  },
  {
    "text": "even with small noise, if I\nwere to get some abnormally rare",
    "start": "1940450",
    "end": "1947049"
  },
  {
    "text": "large force in this\ndirection 10 times in a row, if I watched this Gaussian\nprocess long enough,",
    "start": "1947050",
    "end": "1952210"
  },
  {
    "text": "I might look and find it here. But that's going to be\nvery low probability. So what I'd expect to\nfind is if I watch it",
    "start": "1952210",
    "end": "1958929"
  },
  {
    "text": "for some amount of\ntime, and I look at it, and time is 100, that it's\nprobably going to be here.",
    "start": "1958930",
    "end": "1964570"
  },
  {
    "text": "Going to draw some\nprobability distribution here. And sure, there's some tails\nhere that'll say if I looked,",
    "start": "1964570",
    "end": "1970630"
  },
  {
    "text": "maybe I'll find it there, but\nthat's pretty unlikely, OK. So hopefully when we're\nall done with this, we're going to get that out.",
    "start": "1970630",
    "end": "1977920"
  },
  {
    "text": "And it's not too hard\nto see it, actually. ",
    "start": "1977920",
    "end": "1983169"
  },
  {
    "text": "So what's the best\nway to say it? So let's pretend that we're\ngoing back to our-- so this",
    "start": "1983170",
    "end": "1990640"
  },
  {
    "text": "was the-- we're back\nto the noise case again, putting epsilon back in. ",
    "start": "1990640",
    "end": "2013710"
  },
  {
    "text": "Can we compute, then-- so if\nI know where I am at time n-- if my sensors are\nperfect, like I",
    "start": "2013710",
    "end": "2020399"
  },
  {
    "text": "said, I know where\nI am at time n, where am I going to\nbe a time n plus 1? ",
    "start": "2020400",
    "end": "2030140"
  },
  {
    "text": "So let me write that as some\nprobability distribution that-- I want to write, where\nam I at time n plus 1",
    "start": "2030140",
    "end": "2038809"
  },
  {
    "text": "given I know where\nI am at time n? What's that going to look like?",
    "start": "2038810",
    "end": "2045794"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nGaussian function [INAUDIBLE]",
    "start": "2045794",
    "end": "2051149"
  },
  {
    "text": "1 minus [INAUDIBLE] n by\nsome variance, which is kind of [? problematic, ?] actually. RUSS TEDRAKE: Awesome.",
    "start": "2051150",
    "end": "2056340"
  },
  {
    "text": "Right? So probably, I'm going to be 1\nminus alpha xn away from where",
    "start": "2056340",
    "end": "2064138"
  },
  {
    "text": "I was, but then some\nGaussian distribution centered around that point. The deterministic\npart puts me here,",
    "start": "2064139",
    "end": "2069899"
  },
  {
    "text": "and this part then\nadds noise to that, OK. So that's going to\nbe my full Gaussian",
    "start": "2069900",
    "end": "2075869"
  },
  {
    "text": "here, 2 pi sigma squared e to\nthe negative xn plus 1 minus 1",
    "start": "2075870",
    "end": "2087690"
  },
  {
    "text": "minus alpha xn, that whole\nthing squared, all over to sigma",
    "start": "2087690",
    "end": "2096000"
  },
  {
    "text": "squared, yeah? ",
    "start": "2096000",
    "end": "2101670"
  },
  {
    "text": "You agree with that? If I know where I am at\ntime xn, which, by the way,",
    "start": "2101670",
    "end": "2108809"
  },
  {
    "text": "is equivalent in\nprobability space to saying I have a\ndelta function here--",
    "start": "2108810",
    "end": "2115800"
  },
  {
    "text": "I know where I am. My probability distribution\nis a delta function. ",
    "start": "2115800",
    "end": "2123740"
  },
  {
    "text": "Then on the next step, I'm going\nto be 1 minus alpha times that,",
    "start": "2123740",
    "end": "2129268"
  },
  {
    "text": "and I'm going to have\na distribution, which is mean of this. This is a Gaussian distribution\nx minus mu over 2 sigma",
    "start": "2129268",
    "end": "2135980"
  },
  {
    "text": "squared, squared. This is the new x. This is mu.",
    "start": "2135980",
    "end": "2142170"
  },
  {
    "text": "Yeah?  Good. So now we have everything\nwe need, really, to proceed.",
    "start": "2142170",
    "end": "2153300"
  },
  {
    "text": "So let's say I knew\nwhere I was at x0. On x1, I'm going to be at the\nfunction described by this.",
    "start": "2153300",
    "end": "2162151"
  },
  {
    "text": "Where am I going to be at x2? ",
    "start": "2162152",
    "end": "2171960"
  },
  {
    "text": "Well, in general, I\nhave to do the update. And let me use the\nnotation P of n plus 1,",
    "start": "2171960",
    "end": "2180870"
  },
  {
    "text": "meaning the probability\ndistribution over x at time n plus 1.",
    "start": "2180870",
    "end": "2186210"
  },
  {
    "text": "So think of it as a different\nfunction at each discrete time. Notationally, it's\nthe cleanest, I think.",
    "start": "2186210",
    "end": "2193286"
  },
  {
    "text": "Well, that's going to be-- ",
    "start": "2193287",
    "end": "2211710"
  },
  {
    "text": "it's going to be-- I have to think about-- oops, I did--\nsorry, this is a y.",
    "start": "2211710",
    "end": "2217860"
  },
  {
    "text": "Yeah. My fault.",
    "start": "2217860",
    "end": "2223910"
  },
  {
    "text": "So if I was-- I have to think about\nall the possibilities. I want the probability\nthat I was in y equals 0",
    "start": "2223910",
    "end": "2230780"
  },
  {
    "text": "and then the probability of\nbeing in x, considering I was in y0. But also, I have to think\nabout, what if y was 1?",
    "start": "2230780",
    "end": "2236710"
  },
  {
    "text": "Well, what's the\nprobability of that? And I'm going to sum the whole\nthing up in a continuous way,",
    "start": "2236710",
    "end": "2241965"
  },
  {
    "text": "and I'm going to get\nmy new probability of being at the new place. You guys OK with this equation?",
    "start": "2241965",
    "end": "2247140"
  },
  {
    "text": "All right, I have to\nconsider all possible cases of where I was at time n--",
    "start": "2247140",
    "end": "2252920"
  },
  {
    "text": "that's given by this-- and then apply my dynamics,\nwhich was given by this, to get my new distribution, OK.",
    "start": "2252920",
    "end": "2260190"
  },
  {
    "text": " Hope that's OK, but even if\nit's not, it still should be--",
    "start": "2260190",
    "end": "2267155"
  },
  {
    "text": "you'll still be OK\nhere in a second. So we can do that.",
    "start": "2267155",
    "end": "2273430"
  },
  {
    "text": "So let's say that P of\nn y is a delta function.",
    "start": "2273430",
    "end": "2279410"
  },
  {
    "text": "That's what I said. So I know my initial conditions. I should have drawn it right\nhere to match that plot.",
    "start": "2279410",
    "end": "2289400"
  },
  {
    "text": "Well, then after\none step, it's going to just pick out the P of this\nGaussian centered at that y.",
    "start": "2289400",
    "end": "2301100"
  },
  {
    "text": "And at one step,\nthen, I'm going to be at a Gaussian\ndistribution 1 minus alpha",
    "start": "2301100",
    "end": "2309042"
  },
  {
    "text": "from where I was, centered\naround 1 minus alpha from where I was. Now in the next step, I\nhave to consider the fact",
    "start": "2309042",
    "end": "2315470"
  },
  {
    "text": "that I could be anywhere\nin that Gaussian, weighted appropriately. And I have to consider all\nof the updates from those.",
    "start": "2315470",
    "end": "2321290"
  },
  {
    "text": "That's what this\nintegral is doing. And it turns out the\nmagic of Gaussians and linearity is that\nif P of y is a Gaussian,",
    "start": "2321290",
    "end": "2331250"
  },
  {
    "text": "and I multiply it by another\nGaussian and integrate, I get out a Gaussian. Yeah.",
    "start": "2331250",
    "end": "2336620"
  },
  {
    "text": "Life is good.  So I'll leave the actual math\nto your-- eh, what the heck.",
    "start": "2336620",
    "end": "2346130"
  },
  {
    "text": "I'll just-- what you get--",
    "start": "2346130",
    "end": "2352640"
  },
  {
    "text": "I can write the answer-- if you push a Gaussian\nthrough, turns out",
    "start": "2352640",
    "end": "2363280"
  },
  {
    "text": "to be 1 over square root of\n2 pi sigma squared integral",
    "start": "2363280",
    "end": "2371400"
  },
  {
    "text": "from negative infinity to\ninfinity of e to the negative-- ",
    "start": "2371400",
    "end": "2378310"
  },
  {
    "text": "let me actually write the-- skip that one line just\nto keep things moving. ",
    "start": "2378310",
    "end": "2386070"
  },
  {
    "text": "Let's do 1 over 1\nminus alpha square root of 2 pi sigma squared.",
    "start": "2386070",
    "end": "2392905"
  },
  {
    "start": "2392905",
    "end": "2408700"
  },
  {
    "text": "I have the probability of n at\ny prime minus 1 alpha dy alpha,",
    "start": "2408700",
    "end": "2416615"
  },
  {
    "text": "where y is 1 minus alpha y.",
    "start": "2416615",
    "end": "2422270"
  },
  {
    "text": "It's just-- I haven't\ndone a lot of work yet. I just changed\ncoordinates into y prime.",
    "start": "2422270",
    "end": "2430310"
  },
  {
    "text": "And it turns out, for\ninstance, if I look for a-- if I guess that the steady\nstate is a Gaussian form,",
    "start": "2430310",
    "end": "2438700"
  },
  {
    "text": "and I look for a place where\nthis and this can possibly be the same function,\nif I want to look",
    "start": "2438700",
    "end": "2445660"
  },
  {
    "text": "at the steady state\nof this dynamics,",
    "start": "2445660",
    "end": "2460740"
  },
  {
    "text": "then I find that P\nstar of x is 1 over--",
    "start": "2460740",
    "end": "2468228"
  },
  {
    "text": "oh-- square root of\n2 pi sigma 0 squared",
    "start": "2468228",
    "end": "2476100"
  },
  {
    "text": "e to the negative x\nsquared 2 sigma 0 squared.",
    "start": "2476100",
    "end": "2484700"
  },
  {
    "text": "It's a Gaussian. It's actually a mean 0 Gaussian,\nis the steady state of that update, OK, which is just a\nfew lines in the notes, where",
    "start": "2484700",
    "end": "2497190"
  },
  {
    "text": "sigma 0 squared is\nsigma squared, which",
    "start": "2497190",
    "end": "2502260"
  },
  {
    "text": "is the noise from the Brownian\nmotion minus alpha squared.",
    "start": "2502260",
    "end": "2507630"
  },
  {
    "start": "2507630",
    "end": "2528799"
  },
  {
    "text": "OK? So I think, actually,\nthese equations tell the entire story. ",
    "start": "2528800",
    "end": "2536000"
  },
  {
    "text": "If I start my system\neven from some-- well, specifically, if I start\nmy system in a delta function",
    "start": "2536000",
    "end": "2543740"
  },
  {
    "text": "or in a Gaussian distribution\nof initial conditions, then I'm going to be Gaussian\nfor the rest of time.",
    "start": "2543740",
    "end": "2550460"
  },
  {
    "text": "Turns out even if it's not,\nit'll go to a stable Gaussian. And if I watch--",
    "start": "2550460",
    "end": "2556160"
  },
  {
    "text": "if I look far enough\ninto the future, at the steady state of that\nprobability distribution,",
    "start": "2556160",
    "end": "2561560"
  },
  {
    "text": "then it's actually going to\nbe what we hoped we'd find. It's a mean 0 Gaussian. This was 0 in my plot.",
    "start": "2561560",
    "end": "2569359"
  },
  {
    "text": "And its width, its variance is\ngiven by two competing terms.",
    "start": "2569360",
    "end": "2575090"
  },
  {
    "text": "You've got the noise\nfrom the Brownian motion trying to push you out\ninto larger variance,",
    "start": "2575090",
    "end": "2581660"
  },
  {
    "text": "and you've got the\ncompeting force of the stability of the dynamics\npushing you back in, OK.",
    "start": "2581660",
    "end": "2589610"
  },
  {
    "text": "So if alpha gets--\nand you actually-- this also is valid exactly\nwhen alpha's between 0 and 2.",
    "start": "2589610",
    "end": "2597470"
  },
  {
    "text": "Doesn't go to 0 in\nthat regime yet. OK. ",
    "start": "2597470",
    "end": "2604099"
  },
  {
    "text": "So if I want to look at that\nparticle at time 100 or time 10,000, then I should\nexpect to see it",
    "start": "2604100",
    "end": "2611420"
  },
  {
    "text": "somewhere with probability\ngiven by this distribution",
    "start": "2611420",
    "end": "2616549"
  },
  {
    "text": "in the vicinity of that 0, OK. And that comes\nout of simple math",
    "start": "2616550",
    "end": "2623420"
  },
  {
    "text": "of pushing this Gaussian\nthrough this equation, OK.",
    "start": "2623420",
    "end": "2629770"
  },
  {
    "text": " Now you all probably-- most of\nyou probably knew that before.",
    "start": "2629770",
    "end": "2635540"
  },
  {
    "text": "Why do you know this before? Maybe not in this level of\ndetail, but why do many of you",
    "start": "2635540",
    "end": "2641960"
  },
  {
    "text": "know this already? It's a Kalman filter, right? The Kalman filtered forward\nprocess takes a Gaussian,",
    "start": "2641960",
    "end": "2650540"
  },
  {
    "text": "shoves it through a linear\nsystem, stays Gaussian. This is the single variable,\nlittle more careful version",
    "start": "2650540",
    "end": "2657380"
  },
  {
    "text": "maybe than you'd do if you\ncall MATLAB's Kalman stuff. But yeah, so that's not\na surprising result.",
    "start": "2657380",
    "end": "2665190"
  },
  {
    "text": "But I think it forces you to\nthink about a couple things. So like I said, the\nstability of the system",
    "start": "2665190",
    "end": "2675440"
  },
  {
    "text": "is critical in determining\nthat final distribution.",
    "start": "2675440",
    "end": "2681079"
  },
  {
    "text": "But even more\nsignificantly than that, there's some implications of\nhaving noise in the system.",
    "start": "2681080",
    "end": "2686580"
  },
  {
    "start": "2686580",
    "end": "2707620"
  },
  {
    "text": "Implications of having\nstochastic dynamics, OK. If you want to\nreason about the cost",
    "start": "2707620",
    "end": "2716260"
  },
  {
    "text": "that you're going\nto incur, given some policy, for\ninstance, in order to reason about the\nfuture dynamics,",
    "start": "2716260",
    "end": "2734109"
  },
  {
    "text": "even though you know\ncurrent state, so even given initial conditions, you\nhave to reason about--",
    "start": "2734110",
    "end": "2750609"
  },
  {
    "text": "it's not enough to\njust reason about x. You have to reason about that\nentire distribution, what",
    "start": "2750610",
    "end": "2761290"
  },
  {
    "text": "I called Pn of x, not just x.",
    "start": "2761290",
    "end": "2766990"
  },
  {
    "start": "2766990",
    "end": "2773204"
  },
  {
    "text": "OK, so as soon as we start\ndoing stochastic stuff, we have to change our\nview of the world.",
    "start": "2773204",
    "end": "2779780"
  },
  {
    "text": "The state x is\nnot the only thing you care about moving forward. You care about the probability\ndistribution of states",
    "start": "2779780",
    "end": "2784882"
  },
  {
    "text": "that you live in. ",
    "start": "2784882",
    "end": "2795440"
  },
  {
    "text": "What would you say about the\nstability of this system? ",
    "start": "2795440",
    "end": "2800839"
  },
  {
    "text": "If I asked you, is that a stable\nsystem, what would you say? ",
    "start": "2800840",
    "end": "2813780"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\n[? stable it ?] [? is ?] [? or something? ?] RUSS TEDRAKE: I'm asking-- and we're going to\ndo that, but I'm asking you for your intuition.",
    "start": "2813780",
    "end": "2819610"
  },
  {
    "text": "What would you guess? Would you feel comfortable if\nI said, it's a stable system, let's move on? AUDIENCE: [INAUDIBLE]",
    "start": "2819610",
    "end": "2826420"
  },
  {
    "text": "RUSS TEDRAKE: In\nsome ways, it's OK, because the\ndistribution is stable. x is not stable, OK.",
    "start": "2826420",
    "end": "2834130"
  },
  {
    "start": "2834130",
    "end": "2843099"
  },
  {
    "text": "If I look at a-- if I'm at--\nthere's no fixed point in x. The noise is going to\nkeep moving me around, OK.",
    "start": "2843100",
    "end": "2848290"
  },
  {
    "text": "But I told you that\nP of x, actually-- well, I only told you\nit's a fixed point, but I can tell you it's\na stable fixed point.",
    "start": "2848290",
    "end": "2855520"
  },
  {
    "text": "P of x is actually stable, OK. ",
    "start": "2855520",
    "end": "2865060"
  },
  {
    "text": "OK, so basically, this\nequation right here,",
    "start": "2865060",
    "end": "2871000"
  },
  {
    "text": "this update right here, it's a\nvery famous, important thing.",
    "start": "2871000",
    "end": "2876970"
  },
  {
    "text": "Well, so important that it's\ncalled the master equation, yeah. ",
    "start": "2876970",
    "end": "2884369"
  },
  {
    "text": "I mean, don't just\nname it after some guy. Call it the master equation. ",
    "start": "2884370",
    "end": "2890962"
  },
  {
    "text": "And there are various versions\nof the master equation and specific problems\nthat are named after people's last names,\nbut in general, it's",
    "start": "2890962",
    "end": "2897730"
  },
  {
    "text": "the master equation, OK. So you can't forget\nhow significant it is.",
    "start": "2897730",
    "end": "2903260"
  },
  {
    "text": "And the idea is that\nin the master equation, you're looking at the\ndynamics of the probability distribution.",
    "start": "2903260",
    "end": "2908680"
  },
  {
    "text": "Not the dynamics\nof a single state, the dynamics of a\nprobability distribution, OK. So that probability\ndistribution,",
    "start": "2908680",
    "end": "2913930"
  },
  {
    "text": "actually, in the master\nequation, is stable, OK. Now there are more\ncomplicated cases, actually.",
    "start": "2913930",
    "end": "2921280"
  },
  {
    "text": "So what about this one?",
    "start": "2921280",
    "end": "2946100"
  },
  {
    "text": " What's this thing going\nto do in the long run? ",
    "start": "2946100",
    "end": "2953562"
  },
  {
    "text": "AUDIENCE: Bimodal distribution. RUSS TEDRAKE: It's going to\nhave a bimodal distribution in the long run. So it would be inappropriate\nto say either of those points--",
    "start": "2953562",
    "end": "2963560"
  },
  {
    "text": "I mean, that either of those\npoints are fixed points. For the deterministic\ncase, they are.",
    "start": "2963560",
    "end": "2969920"
  },
  {
    "text": "For the stochastic\ncase, they're not. And you're right. It's going to go to some\ndistribution like this, OK.",
    "start": "2969920",
    "end": "2978140"
  },
  {
    "start": "2978140",
    "end": "2984769"
  },
  {
    "text": "I have a decision point, which\nof my 10 pages I should do. I could talk about some examples\nof just stochastic dynamics,",
    "start": "2984770",
    "end": "2993500"
  },
  {
    "text": "for instance, on\nwalking robots, or I could get to the optimal control\nof the more simple systems.",
    "start": "2993500",
    "end": "2999620"
  },
  {
    "text": " I have to set John\nup for next week, so I guess I got to just tell\nyou that, actually, we've",
    "start": "2999620",
    "end": "3008550"
  },
  {
    "text": "done some work thinking\nabout, for instance, the rimless wheel--",
    "start": "3008550",
    "end": "3013902"
  },
  {
    "text": "I'll just tell you\nthe setup, and I won't tell you all the details. So here's a realistic example\nof that sort of dynamics.",
    "start": "3013902",
    "end": "3025859"
  },
  {
    "text": "Take your rimless\nwheel, OK, dynamics. And let's say, instead\nof walking down",
    "start": "3025860",
    "end": "3033850"
  },
  {
    "text": "some constant ramp,\nlet's say on every step, the ramp angle is drawn\nfrom some distribution.",
    "start": "3033850",
    "end": "3040410"
  },
  {
    "text": "OK, so this is passive walking\non rough terrain, mm-hmm. And it turns out it's\nnot following a limit",
    "start": "3040410",
    "end": "3046590"
  },
  {
    "text": "cycle anymore. But it's always-- its long-term\nprobability distribution is--",
    "start": "3046590",
    "end": "3053940"
  },
  {
    "text": "well, there's a slightly\nmore complicated story. If I look long enough, this\nthing has an absorbing state.",
    "start": "3053940",
    "end": "3062460"
  },
  {
    "text": "So if I take a big enough\nstep, then eventually, I'm going to lose enough energy.",
    "start": "3062460",
    "end": "3067530"
  },
  {
    "text": "Remember, the deterministic\nsystem had two fixed points. One was standing still. The other one was rolling\nat a constant speed, OK.",
    "start": "3067530",
    "end": "3074850"
  },
  {
    "text": "The standing still fixed\npoint on rough terrain is an absorbing fixed point. If I get there and I\nnever take another step,",
    "start": "3074850",
    "end": "3081242"
  },
  {
    "text": "then I'm never going to\nleave that fixed point. So that is actually a\ntrue fixed point, yeah.",
    "start": "3081242",
    "end": "3086490"
  },
  {
    "text": "The rolling fixed\npoint, you're going to tend to bounce\naround that fixed point. So maybe this picture is\nsomething more like this, yeah.",
    "start": "3086490",
    "end": "3096269"
  },
  {
    "text": "OK? So the standing still fixed\npoint, if I get in there, it's absorbing.",
    "start": "3096270",
    "end": "3102900"
  },
  {
    "text": "I'm never coming out. But the rolling fixed point,\nyou tend to bounce around",
    "start": "3102900",
    "end": "3108090"
  },
  {
    "text": "this limit cycle, OK. And then every once in a while,\nin the stochastic dynamics",
    "start": "3108090",
    "end": "3113472"
  },
  {
    "text": "case, they say that\nthese particles make an escape attempt-- that's what they call it. ",
    "start": "3113472",
    "end": "3124240"
  },
  {
    "text": "OK-- and maybe shoot\nover and fall down, OK.",
    "start": "3124240",
    "end": "3129450"
  },
  {
    "text": "And it's really very beautiful. If you watch the\nprobability distributions as they propagate\nthrough the rimless wheel equations, or the compass\ngait equations or you name it,",
    "start": "3129450",
    "end": "3137970"
  },
  {
    "text": "then what you get is you\nget this probability mass around here.",
    "start": "3137970",
    "end": "3143160"
  },
  {
    "text": "For a long time,\nit's pretty likely that I'm in the vicinity\nof that limit cycle.",
    "start": "3143160",
    "end": "3148920"
  },
  {
    "text": "And then slowly, as\nthe time goes on, the escape attempts\ncontinue to the point where this thing gets\nsmaller and smaller",
    "start": "3148920",
    "end": "3155820"
  },
  {
    "text": "until, as time goes\nto infinity, I'm only going to be standing still, OK.",
    "start": "3155820",
    "end": "3161430"
  },
  {
    "text": "So the negative-- the\npessimistic view of that work",
    "start": "3161430",
    "end": "3167730"
  },
  {
    "text": "is to say that you're\nalways going to fall down. You can build the\nbest robot you want, but if you have a reasonable\nmodel of the dynamics,",
    "start": "3167730",
    "end": "3173790"
  },
  {
    "text": "it's always going to fall down. If you wait long enough, a Mack\ntruck is going to come along",
    "start": "3173790",
    "end": "3179220"
  },
  {
    "text": "and hit it or it's going\nto walk into a door or something like that. You can do the best you want,\nbut it's going to fall down,",
    "start": "3179220",
    "end": "3184890"
  },
  {
    "text": "and it'll end up on\nYouTube, probably, right? [LAUGHTER] So-- AUDIENCE: So you're assuming\nyour ramp distribution is",
    "start": "3184890",
    "end": "3191890"
  },
  {
    "text": "actually Gaussian? RUSS TEDRAKE: That's\nwhat we decided, yeah. AUDIENCE: OK. RUSS TEDRAKE: But\nthat doesn't actually",
    "start": "3191890",
    "end": "3197405"
  },
  {
    "text": "imply that the posterior is\nGaussian, because it's going through nonlinear dynamics. AUDIENCE: Right, but\nI mean, in reality,",
    "start": "3197405",
    "end": "3204060"
  },
  {
    "text": "the random distribution\nis never going to be truly Gaussian, right? Because-- RUSS TEDRAKE: Everything's\nGaussian if you get enough of--",
    "start": "3204060",
    "end": "3211690"
  },
  {
    "text": "I don't know. I mean, I think that's-- so you want to do stairs\nor something more specific?",
    "start": "3211690",
    "end": "3216930"
  },
  {
    "text": "AUDIENCE: Oh, well,\nI'm just saying, if there is a hard limit\non how steep your ramp is--",
    "start": "3216930",
    "end": "3222002"
  },
  {
    "text": "RUSS TEDRAKE: Oh. AUDIENCE: --you could\nguarantee that-- RUSS TEDRAKE: Good. Very good point. All right, so of\nthe distributions",
    "start": "3222002",
    "end": "3227585"
  },
  {
    "text": "didn't have tails,\nthen there are cases where I can bound\nit never going over.",
    "start": "3227585",
    "end": "3233099"
  },
  {
    "text": "But those tails actually\nhave to be pretty steep-- the limitations have\nto be pretty steep, because you have to make\nsure that, on a single step,",
    "start": "3233100",
    "end": "3239520"
  },
  {
    "text": "of the damping overcomes the\nbiggest possible perturbation. If on a single-- if\nyour noise can ever",
    "start": "3239520",
    "end": "3246150"
  },
  {
    "text": "be bigger than what you can\ntake out in a single step, then you will eventually,\nas time goes to infinity, find a way to get out.",
    "start": "3246150",
    "end": "3252020"
  },
  {
    "text": "Yeah? So Katie Mill did some\nnice work in quantifying",
    "start": "3252020",
    "end": "3258450"
  },
  {
    "text": "the metastable\ndynamics of walking. And actually, I think that-- so we call it the metastable,\nbecause that distribution",
    "start": "3258450",
    "end": "3264555"
  },
  {
    "text": "is long-living. It still makes sense\nto talk about where you'd expect this thing\nto be while it's walking.",
    "start": "3264555",
    "end": "3270360"
  },
  {
    "text": "But eventually, we have to\nadmit it's going to be-- it's going to go\nto falling down. Like a diamond is a diamond\nfor a very long time,",
    "start": "3270360",
    "end": "3277290"
  },
  {
    "text": "but eventually, it'll\nturn back into graphite. OK, so good.",
    "start": "3277290",
    "end": "3284195"
  },
  {
    "text": "So there's actually\na beautiful-- even if you don't\ncare about control, I think there's actually\nbeautiful things that happen in stochastic dynamics.",
    "start": "3284195",
    "end": "3290130"
  },
  {
    "text": "But the thing that matters\nhere is, we've switched hats. We've now started thinking\nabout probability distributions",
    "start": "3290130",
    "end": "3297060"
  },
  {
    "text": "and how they evolve\nwith dynamics, and how we can change\nthose probability distributions with control.",
    "start": "3297060",
    "end": "3303170"
  },
  {
    "text": "If I could if I could\ncontrol the shape of that, then I can control those\nprobability distributions, for instance.",
    "start": "3303170",
    "end": "3308720"
  },
  {
    "text": " OK.",
    "start": "3308720",
    "end": "3315380"
  },
  {
    "text": "So it turns out it's sort of\ntrivial to work stochastic--",
    "start": "3315380",
    "end": "3325579"
  },
  {
    "text": "to solve stochastic\noptimal control problems, at least with dynamic\nprogramming, OK.",
    "start": "3325580",
    "end": "3333330"
  },
  {
    "start": "3333330",
    "end": "3347310"
  },
  {
    "text": "And it works out, because of\nthis additive cost structure, that it's roughly\nno more expensive",
    "start": "3347310",
    "end": "3357160"
  },
  {
    "text": "to solve the stochastic\noptimal control",
    "start": "3357160",
    "end": "3375730"
  },
  {
    "text": "than the deterministic one. ",
    "start": "3375730",
    "end": "3385030"
  },
  {
    "text": "And that matters. Maybe I should even make\nthe point that it matters. So if I have a\nstochastic process--",
    "start": "3385030",
    "end": "3393430"
  },
  {
    "text": "and in general,\nthe optimal policy that you get from\nstochastic optimal control",
    "start": "3393430",
    "end": "3400390"
  },
  {
    "text": "is going to be different\nthan the one you get from deterministic\noptimal control,",
    "start": "3400390",
    "end": "3406250"
  },
  {
    "text": "so potentially,\nin dramatic ways. Let me try to make\nthat point here. So imagine I've got my--",
    "start": "3406250",
    "end": "3411970"
  },
  {
    "text": " I've got a trashcan robot.",
    "start": "3411970",
    "end": "3417040"
  },
  {
    "text": "I shouldn't call it a trashcan. I've got a-- what are they?",
    "start": "3417040",
    "end": "3422803"
  },
  {
    "text": "What are the names of\nthose little red robots? Pioneer robot or\nsomething like this, yeah? And I want to get it from--",
    "start": "3422803",
    "end": "3431724"
  },
  {
    "text": "to this goal. Let's say I've got a\ncost function like this, and I start over here.",
    "start": "3431725",
    "end": "3437030"
  },
  {
    "text": "And as I go, I know that\nmy wheels slip or something like that. My distributions are going\nto grow as I go, yeah.",
    "start": "3437030",
    "end": "3446130"
  },
  {
    "text": "And I've got some\nability to control them, so they're not going\nto grow unbounded, but let's say they're going to\ngrow in my path to the goal,",
    "start": "3446130",
    "end": "3453799"
  },
  {
    "text": "OK. There'll be two\ncompeting forces. There'll be my ability\nto measure and fight",
    "start": "3453800",
    "end": "3460473"
  },
  {
    "text": "against disturbances,\nand there'll be the inevitable disturbances. And those two will again combine\ninto some sort of distribution",
    "start": "3460473",
    "end": "3467260"
  },
  {
    "text": "over time, OK. Now imagine-- like the scenario\nwe talked about in the feedback",
    "start": "3467260",
    "end": "3472810"
  },
  {
    "text": "case, imagine my cost\nfunction is 0 everywhere,",
    "start": "3472810",
    "end": "3485075"
  },
  {
    "text": "negative 1 at the goal-- I want to get to the goal-- and say something\nreally big here, yeah.",
    "start": "3485075",
    "end": "3494980"
  },
  {
    "text": "There's pits of fire in\nthe middle of the lab. OK?",
    "start": "3494980",
    "end": "3500380"
  },
  {
    "text": "No, I mean, right, so we've\ngot to make the point. If it was just 1, I wouldn't\nmake-- be as dramatic. But OK, so long story short,\na stochastic optimal control",
    "start": "3500380",
    "end": "3512920"
  },
  {
    "text": "solution is unlikely to\nchoose this path, because 0--",
    "start": "3512920",
    "end": "3520839"
  },
  {
    "text": "even if the distributions\nare fairly tight, 0 times a big part of the\nprobability distribution plus 1",
    "start": "3520840",
    "end": "3527710"
  },
  {
    "text": "e to the 6 times even a\nlittle part of the probability distribution is still\na big number, OK. And so therefore, the expected\nvalue of going through here",
    "start": "3527710",
    "end": "3537100"
  },
  {
    "text": "is that I'm going to\nincur quite a bit of cost. Does that make sense?",
    "start": "3537100",
    "end": "3542619"
  },
  {
    "text": "So if I just did\ndeterministic optimal control, we talked about using\nfeedback to try to motivate",
    "start": "3542620",
    "end": "3548260"
  },
  {
    "text": "not going through there. But really, the\nmore direct way is to think about the\nprobability distributions.",
    "start": "3548260",
    "end": "3555400"
  },
  {
    "text": "So if I can control my\nprobabilities to the point where I know 0 probability\nis going to be in here, then sure, go ahead\nthrough there.",
    "start": "3555400",
    "end": "3561700"
  },
  {
    "text": "And the deterministic one\nwill probably find that. But the stochastic one, if it\nrealizes there's something,",
    "start": "3561700",
    "end": "3567280"
  },
  {
    "text": "will probably try to find\na different path, OK. So that's one example.",
    "start": "3567280",
    "end": "3574180"
  },
  {
    "text": "But in general, the stochastic\noptimal control policies are going to be different\nthan the deterministic ones,",
    "start": "3574180",
    "end": "3580330"
  },
  {
    "text": "and better. If you have a reasonable\nmodel of the disturbances you'd expect to\nencounter, then you",
    "start": "3580330",
    "end": "3586060"
  },
  {
    "text": "should allow your\noptimal control tools to think about them, OK.",
    "start": "3586060",
    "end": "3591920"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nstochastic environment s times 4 [INAUDIBLE] [? you have ?]\n[INAUDIBLE] [? more states, ?]",
    "start": "3591920",
    "end": "3602012"
  },
  {
    "text": "because potentially, each\naction can move you to any of the possible states\nwhile in deterministic case,",
    "start": "3602012",
    "end": "3607520"
  },
  {
    "text": "you can go to one state. So when you do [INAUDIBLE]\n[? worse ?] [? case. ?]",
    "start": "3607520",
    "end": "3612897"
  },
  {
    "text": "RUSS TEDRAKE: Right. I knew someone was going to-- so I would say essentially no. I almost wrote, essentially no.",
    "start": "3612897",
    "end": "3619016"
  },
  {
    "text": "And the reason I want to make\nthat comparison, actually, is because I want to\ncompare it directly to the barycentric interpolation\nthat we were doing before,",
    "start": "3619017",
    "end": "3625780"
  },
  {
    "text": "which is what I'm going\nto do in a second. And that is already\ndoing an interpolation, already going through some\nprobability, some transition",
    "start": "3625780",
    "end": "3632420"
  },
  {
    "text": "matrix, yeah. And it's probably true\nthat the-- it may be true, depending on your\nnoise distributions,",
    "start": "3632420",
    "end": "3638180"
  },
  {
    "text": "that if you add a lot of noise,\nthat transition matrix will be more dense, and therefore,\nit might take more time, depending on how you computed.",
    "start": "3638180",
    "end": "3645410"
  },
  {
    "text": "My MATLAB implementation,\nit's the same. Yeah? Is that fair? And it's no more\ncomplicated to write down.",
    "start": "3645410",
    "end": "3651890"
  },
  {
    "text": "How about that? OK?  We'll completely\nunderstand what [INAUDIBLE]",
    "start": "3651890",
    "end": "3657830"
  },
  {
    "text": "was asking in just a second. OK, so why is it no\nmore complicated for me",
    "start": "3657830",
    "end": "3663530"
  },
  {
    "text": "to write down on the board\nthe stochastic optimal control case in dynamic programming?",
    "start": "3663530",
    "end": "3669113"
  },
  {
    "text": " Remember, I said now this is--",
    "start": "3669113",
    "end": "3675060"
  },
  {
    "text": "I'm going to take the expected\nvalue of my additive cost. ",
    "start": "3675060",
    "end": "3693960"
  },
  {
    "text": "First let's just think about\nwhat the implications are for doing optimal control. ",
    "start": "3693960",
    "end": "3701678"
  },
  {
    "text": "So first of all, I can take\nthat expectation inside. ",
    "start": "3701678",
    "end": "3718520"
  },
  {
    "text": "And now what's the\nprobability of g-- or what's the expected\nvalue of g at xn un?",
    "start": "3718520",
    "end": "3728490"
  },
  {
    "text": "Well, x has got\nsome distribution given by P of x, and yeah.",
    "start": "3728490",
    "end": "3736589"
  },
  {
    "text": "So this thing is\ngoing to work out to be-- you can always take the\nexpected value of a function of x by just that function times\nits distribution integrated.",
    "start": "3736590",
    "end": "3745619"
  },
  {
    "text": "This thing's going\nto work out to be so an integral over all\npossible states of g",
    "start": "3745620",
    "end": "3755670"
  },
  {
    "text": "of x u of n times P of n x dx.",
    "start": "3755670",
    "end": "3762834"
  },
  {
    "start": "3762834",
    "end": "3767840"
  },
  {
    "text": "Right? ",
    "start": "3767840",
    "end": "3773230"
  },
  {
    "text": "OK, so you could imagine\ncomputing optimal policies by figuring out the state\ndistribution by that evolution",
    "start": "3773230",
    "end": "3780550"
  },
  {
    "text": "I was talking about before\nand then integrating over the possible states, yeah?",
    "start": "3780550",
    "end": "3788740"
  },
  {
    "text": "The costs for each state,\nand figuring out our J, figuring out a way\nto minimize that. I only wrote that down\nto make it look hard, OK.",
    "start": "3788740",
    "end": "3796080"
  },
  {
    "text": "It turns out, again, just like\nbefore, the recursive form is beautiful and simple, OK.",
    "start": "3796080",
    "end": "3802930"
  },
  {
    "text": "So you can imagine doing it\nthat way, and that's correct, but just like before, the\ndynamic programming solution",
    "start": "3802930",
    "end": "3809200"
  },
  {
    "text": "exploits the recursive--\nthe additive form and does a recursive\nsolution which just works out beautifully, OK.",
    "start": "3809200",
    "end": "3815440"
  },
  {
    "text": " So if I do J of x from time 0\nbeing the expected value of,",
    "start": "3815440",
    "end": "3825220"
  },
  {
    "text": "let's do the final cost also,\nthen what's J of x capital N?",
    "start": "3825220",
    "end": "3846510"
  },
  {
    "start": "3846510",
    "end": "3854370"
  },
  {
    "text": "My cost to go, given\nI'm at the goal. The time has expired,\nand I'm at state x.",
    "start": "3854370",
    "end": "3859500"
  },
  {
    "text": " AUDIENCE: [INAUDIBLE] h of x.",
    "start": "3859500",
    "end": "3866140"
  },
  {
    "text": "RUSS TEDRAKE: Is it\nexpected value of h of x, or is it just h? What is it? ",
    "start": "3866140",
    "end": "3873933"
  },
  {
    "text": "AUDIENCE: h is\n[? deterministic ?] [INAUDIBLE]. RUSS TEDRAKE: Awesome. Yeah. If I know I'm already in x, then\nthere's no probabilities left,",
    "start": "3873933",
    "end": "3883569"
  },
  {
    "text": "yeah.  OK, and then if I go\nbackwards, J of x at time k",
    "start": "3883570",
    "end": "3897160"
  },
  {
    "text": "is going to work out\nto be min over u-- I should say J star of x. Sorry.",
    "start": "3897160",
    "end": "3903940"
  },
  {
    "text": "J star of x is going to be min\nover u the expected value of g",
    "start": "3903940",
    "end": "3909099"
  },
  {
    "text": "x, u plus J star of f\nof x u w of n k plus 1.",
    "start": "3909100",
    "end": "3930400"
  },
  {
    "text": " Can you buy that? ",
    "start": "3930400",
    "end": "3969880"
  },
  {
    "text": "OK, so the reinforcement\nlearning people always like to say that the\nreward or the cost",
    "start": "3969880",
    "end": "3975870"
  },
  {
    "text": "can also be a random\nprocess a random variable.",
    "start": "3975870",
    "end": "3982305"
  },
  {
    "text": "I'm always in this case\nwhere I design the cost, it's a function of some random\nx, but g is deterministic.",
    "start": "3982305",
    "end": "3988690"
  },
  {
    "text": "So actually, I could take that\nexpectation right inside here, and I just have\nto do a min over u",
    "start": "3988690",
    "end": "3994770"
  },
  {
    "text": "of g of x times the expected\nvalue of my cost to go, OK.",
    "start": "3994770",
    "end": "4001560"
  },
  {
    "start": "4001560",
    "end": "4007500"
  },
  {
    "text": "The nicest way to see how\nto implement that is let's go ahead and-- we've already discretized time.",
    "start": "4007500",
    "end": "4012970"
  },
  {
    "text": "Let's discretize\nstate and actions. ",
    "start": "4012970",
    "end": "4026470"
  },
  {
    "text": "So now I have S of n plus\n1-- remember I switch to S's and a's when\nI discretize things--",
    "start": "4026470",
    "end": "4032550"
  },
  {
    "text": "is now f of S n times some\naction times my noise.",
    "start": "4032550",
    "end": "4042810"
  },
  {
    "text": "And the advantage of\ndiscretizing stat and actions is now I can do P of n plus\n1, which is a function of S.",
    "start": "4042810",
    "end": "4057630"
  },
  {
    "text": "I could think of\nthat as just a vector where the ith element is the\nprobability that S of n plus 1",
    "start": "4057630",
    "end": "4073320"
  },
  {
    "text": "equals Si. ",
    "start": "4073320",
    "end": "4078710"
  },
  {
    "text": "Is that OK?  The probability distribution,\nremember, in general,",
    "start": "4078710",
    "end": "4084760"
  },
  {
    "text": "was a function. In the particle in a bowl case,\nit was a continuous Gaussian",
    "start": "4084760",
    "end": "4089950"
  },
  {
    "text": "function. If I discretize the\nstate there, then I can represent that\nas a vector, saying,",
    "start": "4089950",
    "end": "4096130"
  },
  {
    "text": "what's the probability of\nbeing in state one, what's the probability of being in\nstate two, probability of being in state three, and so on, OK.",
    "start": "4096130",
    "end": "4103240"
  },
  {
    "text": "So the reason to\ndiscretize states is I can turn my continuous\nfunction into a vector.",
    "start": "4103240",
    "end": "4109160"
  },
  {
    "text": "Yeah.  And I can turn this function\ninto a transition probability",
    "start": "4109160",
    "end": "4117560"
  },
  {
    "text": "matrix. I can-- so f goes to Tij, which\nis the probability of landing",
    "start": "4117560",
    "end": "4129920"
  },
  {
    "text": "in Sj-- I should-- it depends\non the actions-- given I was in Si\nand I took action a.",
    "start": "4129920",
    "end": "4137199"
  },
  {
    "text": " This is a matrix.",
    "start": "4137200",
    "end": "4144318"
  },
  {
    "text": "It's the transition matrix. ",
    "start": "4144319",
    "end": "4167500"
  },
  {
    "text": "And now the state\ndistribution dynamics",
    "start": "4167500",
    "end": "4175089"
  },
  {
    "text": "are going to just turn out\nto be a pretty simple matrix",
    "start": "4175090",
    "end": "4184719"
  },
  {
    "text": "equation. That's in-- oops. Tij Pj at time n plus 1.",
    "start": "4184720",
    "end": "4192667"
  },
  {
    "text": "Yeah, so let me actually write\nthe whole vec-- the real vector form. That's really for-- that's\nfor a single element of it.",
    "start": "4192667",
    "end": "4199600"
  },
  {
    "text": "I could just write, if I'm\ndoing it in column vectors, then it's actually going to\nbe P of n times T of a, OK.",
    "start": "4199600",
    "end": "4213070"
  },
  {
    "text": "Where these two are\nvectors, that's a matrix. ",
    "start": "4213070",
    "end": "4222000"
  },
  {
    "text": "So and this is\nthe discreet time,",
    "start": "4222000",
    "end": "4228380"
  },
  {
    "text": "discreet action, discreet\nstate master equation.",
    "start": "4228380",
    "end": "4239389"
  },
  {
    "start": "4239390",
    "end": "4246376"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] RUSS TEDRAKE: I use\nit as a column vector. AUDIENCE: [INAUDIBLE]",
    "start": "4246376",
    "end": "4256650"
  },
  {
    "text": "RUSS TEDRAKE: Let's make sure. So the probability of being in\nstate J given I was in state i",
    "start": "4256650",
    "end": "4266929"
  },
  {
    "text": "should be the sum over--  write this thing.",
    "start": "4266930",
    "end": "4273110"
  },
  {
    "text": "Probability of\nbeing of S n plus 1",
    "start": "4273110",
    "end": "4283100"
  },
  {
    "text": "is a probability-- what's that? I think I had it right, right? It's not a true loop,\nbut I think that's right.",
    "start": "4283100",
    "end": "4289988"
  },
  {
    "text": "AUDIENCE: [? Don't ?] [? you ?]\n[? need a ?] transpose? AUDIENCE: Yeah. AUDIENCE: [INAUDIBLE] RUSS TEDRAKE: I\nneed a T transpose?",
    "start": "4289988",
    "end": "4295310"
  },
  {
    "text": "AUDIENCE: Get a T transpose. AUDIENCE: You just\ncan't hit the-- AUDIENCE: [INAUDIBLE] RUSS TEDRAKE: Oh, of\ncourse, because I did this. OK, yeah, so sorry.",
    "start": "4295310",
    "end": "4301550"
  },
  {
    "text": "Yeah, I think the way I've\ngot T defined-- but thank you. That should be a\ntranspose, yeah. Good. AUDIENCE: [INAUDIBLE]\nT transpose",
    "start": "4301550",
    "end": "4307665"
  },
  {
    "text": "on the other side [INAUDIBLE]. RUSS TEDRAKE: In which case,\nI could have written it",
    "start": "4307665",
    "end": "4312710"
  },
  {
    "text": "with the T as a\ntranspose too, but if I transpose the whole thing. ",
    "start": "4312710",
    "end": "4324188"
  },
  {
    "text": "Doesn't really matter if you\nlike row vectors or column vectors. The point is the\nmaster equation, which looked a little\nscary before, yeah, turns",
    "start": "4324188",
    "end": "4331040"
  },
  {
    "text": "into a simple matrix update\nin the discrete time, discrete state case. Yeah?",
    "start": "4331040",
    "end": "4336679"
  },
  {
    "text": "AUDIENCE: So in this\n[INAUDIBLE] [? truncated ?] [? the actions ?] or you'd\njust not [? capture things? ?]",
    "start": "4336680",
    "end": "4342854"
  },
  {
    "text": "Because you have hard limits\nif you discretize things. RUSS TEDRAKE: Good. So there's a\nquestion again, just",
    "start": "4342854",
    "end": "4348770"
  },
  {
    "text": "like we had the\nquestion when we did dynamic programming for\nthe value iteration,",
    "start": "4348770",
    "end": "4353870"
  },
  {
    "text": "of how you go from the\ncontinuous probabilities and continuous states\nback to the other one. So again, yeah.",
    "start": "4353870",
    "end": "4359040"
  },
  {
    "text": "So I would sample\nfor my Gaussian and fill out a\ntransition probabilities as a close, truncated\nrepresentation of the Gaussian",
    "start": "4359040",
    "end": "4367160"
  },
  {
    "text": "and still interpolate with\nthe barycentric interpolators.",
    "start": "4367160",
    "end": "4373125"
  },
  {
    "start": "4373125",
    "end": "4378350"
  },
  {
    "text": "And now the DP update works\nout to be just a simple.",
    "start": "4378350",
    "end": "4384815"
  },
  {
    "text": " The probability of being in S--",
    "start": "4384815",
    "end": "4393200"
  },
  {
    "text": "let's see S-- J is the min over a.",
    "start": "4393200",
    "end": "4399410"
  },
  {
    "text": "The expected value\nfrom this equation can be taken care of\nwith just the transition",
    "start": "4399410",
    "end": "4407600"
  },
  {
    "text": "matrix over here. And I get maybe\nmy vector g of a,",
    "start": "4407600",
    "end": "4412670"
  },
  {
    "text": "which is the cost of\nbeing in each state given I took that action, sum\nover j Tij Sj J of Sj k plus 1.",
    "start": "4412670",
    "end": "4429540"
  },
  {
    "text": "Yeah? And I get rid of my expected\nvalues by just using that--",
    "start": "4429540",
    "end": "4437163"
  },
  {
    "text": "working directly with\nthe transition matrices. ",
    "start": "4437163",
    "end": "4446710"
  },
  {
    "text": "i on this side, j on the side. Many apologies. ",
    "start": "4446710",
    "end": "4455150"
  },
  {
    "text": "This turns out to be exactly-- the reason I said, basically\nno more expensive to solve",
    "start": "4455150",
    "end": "4460250"
  },
  {
    "text": "than the deterministic\ncase is we already used this form\nwhen we were doing",
    "start": "4460250",
    "end": "4466000"
  },
  {
    "text": "the barycentric interpolation. Because our problem in\nthe dynamic programming originally was that\nwhen we started",
    "start": "4466000",
    "end": "4476920"
  },
  {
    "text": "simulating this thing\nfrom one node forward, it didn't end up--",
    "start": "4476920",
    "end": "4482474"
  },
  {
    "text": "unless you were\nvery, very lucky, it didn't end up right\non top of another node. So we already had\nsaid that we're",
    "start": "4482475",
    "end": "4488020"
  },
  {
    "text": "going to estimate\nthe new cost to go as an interpolation\nof the neighboring points, of the value of the\nneighboring points, where",
    "start": "4488020",
    "end": "4495040"
  },
  {
    "text": "that weighting came from the\nbarycentric interpolators, OK.",
    "start": "4495040",
    "end": "4500770"
  },
  {
    "text": "We're doing the\nexact same thing now. In fact, you could\nactually think of the barycentric\ninterpolators as turning",
    "start": "4500770",
    "end": "4507880"
  },
  {
    "text": "your deterministic problem into\na stochastic problem, where the probability of going\ninto each of these neighbors",
    "start": "4507880",
    "end": "4514450"
  },
  {
    "text": "is the interpolant, OK. So the reason the\nbarycentric works beautifully is that it turns the\ndeterministic case",
    "start": "4514450",
    "end": "4521650"
  },
  {
    "text": "into a stochastic case. Yeah? And that's why I wanted to say\nthat it's no more complex, OK.",
    "start": "4521650",
    "end": "4529050"
  },
  {
    "text": "T might be more-- have less 0s than\nin the general case. If maybe-- with some\nprobability distribution,",
    "start": "4529050",
    "end": "4534863"
  },
  {
    "text": "it might be that I have to worry\nabout hitting a lot more nodes. ",
    "start": "4534863",
    "end": "4540179"
  },
  {
    "text": "So it might take\nfew more cycles. But the equations are the\nsame, and my MATLAB code is the same, OK.",
    "start": "4540180",
    "end": "4547670"
  },
  {
    "text": "Simultaneously, or\nmaybe conversely, this helps-- actually\ntells you why we have problems with the\nbarycentric interpolators.",
    "start": "4547670",
    "end": "4555720"
  },
  {
    "text": "This is the-- remember,\nthe fundamental problems with the barycentric\ninterpolators is that things leaked away\nfrom the nominal trajectories,",
    "start": "4555720",
    "end": "4563960"
  },
  {
    "text": "and we had our chattering\nhappening in the-- and our bang bang solution\nwasn't quite right.",
    "start": "4563960",
    "end": "4570050"
  },
  {
    "text": "Because now you\ncan think of it as, is my deterministic\nproblem assigning some probability of going\nto each of these neighbors?",
    "start": "4570050",
    "end": "4577490"
  },
  {
    "text": "And you can see that\nthat distribution's going to start slipping away\nfrom the nominal trajectory.",
    "start": "4577490",
    "end": "4582753"
  },
  {
    "text": " OK, excellent. So this is actually\nvery important.",
    "start": "4582753",
    "end": "4591200"
  },
  {
    "text": "Stochastic optimal control\nis a beautiful thing. If I can model the disturbances\nin any reasonable way,",
    "start": "4591200",
    "end": "4600890"
  },
  {
    "text": "then I can get better policies\nby explicitly reasoning about them. And just like we said\ndynamic programming",
    "start": "4600890",
    "end": "4608059"
  },
  {
    "text": "for low dimensional\nproblems solves all these really hard\nproblems that are analytically intractable and\nthings like that,",
    "start": "4608060",
    "end": "4613460"
  },
  {
    "text": "it can even solve a\nstochastic problem with almost no more work, OK.",
    "start": "4613460",
    "end": "4619625"
  },
  {
    "text": "The low dimensional problems,\neven complicated ones with complicated distributions,\nDP can do the work for you.",
    "start": "4619625",
    "end": "4628380"
  },
  {
    "text": "OK. So a few more things to say.",
    "start": "4628380",
    "end": "4636590"
  },
  {
    "text": "There's one particular\nresult, which we already mentioned early, that\nI have to mention here.",
    "start": "4636590",
    "end": "4647845"
  },
  {
    "start": "4647845",
    "end": "4653330"
  },
  {
    "text": "This dynamic\nprogramming update, we",
    "start": "4653330",
    "end": "4661450"
  },
  {
    "text": "use this in our analytical\noptimal control, too. We use this as the basis\nto start designing things",
    "start": "4661450",
    "end": "4666880"
  },
  {
    "text": "like our LQR controllers that\nwe turned it into the HPJ.",
    "start": "4666880",
    "end": "4672130"
  },
  {
    "text": "And in the finite time\ncase, we didn't even turn it into the HPJ. We just started-- we started--",
    "start": "4672130",
    "end": "4677199"
  },
  {
    "text": "we can back this out with\ndynamic programming, OK. So we can actually\nuse the same thing to analytically try to\ndesign some controllers",
    "start": "4677200",
    "end": "4685330"
  },
  {
    "text": "for stochastic\noptimal control cases. And just like in the\ndeterministic case,",
    "start": "4685330",
    "end": "4690940"
  },
  {
    "text": "there's one outstanding result\nthat everybody knows and uses, and that's the linear quadratic\nregulator with Gaussian noise.",
    "start": "4690940",
    "end": "4699775"
  },
  {
    "start": "4699775",
    "end": "4721690"
  },
  {
    "text": "LQG is the shorthand.",
    "start": "4721690",
    "end": "4728170"
  },
  {
    "text": "There's two forms of it. One of them is Gaussian\nnoise also on the sensors, but let's just\nworry about the case",
    "start": "4728170",
    "end": "4734320"
  },
  {
    "text": "where we know there's no\nuncertainty in the sensors, only the dynamic noise.",
    "start": "4734320",
    "end": "4740020"
  },
  {
    "text": "So x n plus 1 is a.",
    "start": "4740020",
    "end": "4745540"
  },
  {
    "text": "It could be a of n. It could be time varying or not. xn plus B n u of n plus wn.",
    "start": "4745540",
    "end": "4755980"
  },
  {
    "text": " Cost function, again, is\nthe quadratic regulator.",
    "start": "4755980",
    "end": "4761434"
  },
  {
    "start": "4761434",
    "end": "4781720"
  },
  {
    "text": "What do you think's going\nto happen with that problem? Someone who hasn't\nused it extensively",
    "start": "4781720",
    "end": "4788230"
  },
  {
    "text": "in your work, what's going to\nchange about our LQR solution? Think about stabilizing the\npendulum or something, OK.",
    "start": "4788230",
    "end": "4795850"
  },
  {
    "text": "Let's say we're doing optimal\ncontrol on the simple pendulum linearized around the\ntop, and now there's",
    "start": "4795850",
    "end": "4800860"
  },
  {
    "text": "disturbances bouncing me around. How would you act\ndifferently given",
    "start": "4800860",
    "end": "4806500"
  },
  {
    "text": "some model of disturbances\nin the linear case?",
    "start": "4806500",
    "end": "4812520"
  },
  {
    "text": "How would you act\ndifferently if you know that somebody's going\nto be bumping me around with a mean 0?",
    "start": "4812520",
    "end": "4817740"
  },
  {
    "text": "Let's keep w mean 0. ",
    "start": "4817740",
    "end": "4827070"
  },
  {
    "text": "How would you act differently\nif you're a simple pendulum around the top?",
    "start": "4827070",
    "end": "4832430"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] RUSS TEDRAKE: Anybody\nelse want to weigh in?",
    "start": "4832430",
    "end": "4837550"
  },
  {
    "text": " AUDIENCE: Increase your gain.",
    "start": "4837550",
    "end": "4842576"
  },
  {
    "text": "RUSS TEDRAKE: What's that? AUDIENCE: Increase your gain. RUSS TEDRAKE: You might\nincrease your gain or something like that, you'd think. Yeah, it turns out you\nwouldn't act different.",
    "start": "4842577",
    "end": "4851220"
  },
  {
    "text": "It's one of the most\nsurprising results, I think, of stochastic optimal control.",
    "start": "4851220",
    "end": "4857690"
  },
  {
    "text": "It turns out that\nyou work it all out, you put your costs like this,\nyou wouldn't-- you don't turn",
    "start": "4857690",
    "end": "4864110"
  },
  {
    "text": "your gains up because of the\ndisturbances or anything like that. The optimal solution\nfor the stochastic case",
    "start": "4864110",
    "end": "4870200"
  },
  {
    "text": "is the same policy as\nthe optimal solution for the deterministic case, OK.",
    "start": "4870200",
    "end": "4876313"
  },
  {
    "text": "It's also true in\ncontinuous time. ",
    "start": "4876313",
    "end": "4889250"
  },
  {
    "text": "R inverse B transpose S of n x.",
    "start": "4889250",
    "end": "4894260"
  },
  {
    "text": "Yeah, it's the same B of n here. ",
    "start": "4894260",
    "end": "4911450"
  },
  {
    "text": "Did I write something funny? AUDIENCE: Did you know that\nthat clock isn't moving?",
    "start": "4911450",
    "end": "4916800"
  },
  {
    "text": "RUSS TEDRAKE: No, I didn't. Am I way off time? AUDIENCE: It's about 4 o'clock. RUSS TEDRAKE: OK. Thank you for telling me that.",
    "start": "4916800",
    "end": "4922280"
  },
  {
    "text": "I thought I had time. Nice. AUDIENCE: Is the S the same? RUSS TEDRAKE: This\nS is the same too.",
    "start": "4922280",
    "end": "4928200"
  },
  {
    "text": "Oh, sorry, sorry. Good. The S I wrote here\nis the same, OK.",
    "start": "4928200",
    "end": "4934739"
  },
  {
    "text": "That is the same S that you\nget from the Riccati equation, but the total cost\nis bigger in the--",
    "start": "4934740",
    "end": "4941790"
  },
  {
    "text": "so the policy is the same, but-- so how much time\ndo I really have? Do I have negative\ntime already, or am I--",
    "start": "4941790",
    "end": "4947870"
  },
  {
    "text": "AUDIENCE: Yeah, kind of. RUSS TEDRAKE: Sorry. OK. But J of n--",
    "start": "4947870",
    "end": "4953520"
  },
  {
    "text": "I thought it was\njust very exciting-- ",
    "start": "4953520",
    "end": "4961020"
  },
  {
    "text": "is this plus some expected\nvalue of the noise.",
    "start": "4961020",
    "end": "4967995"
  },
  {
    "start": "4967995",
    "end": "4976590"
  },
  {
    "text": "I was going to keep going\nfor a long time, probably. OK. So it's the same S\nthat you had before,",
    "start": "4976590",
    "end": "4984070"
  },
  {
    "text": "but the cost to go that\nyou get is actually higher, in a way that you might\nexpect with-- it actually",
    "start": "4984070",
    "end": "4990450"
  },
  {
    "text": "depends on the cost on the\nother S. And so the S of n comes from the deterministic\nRiccati equation, but the cost to go gets bigger.",
    "start": "4990450",
    "end": "4998980"
  },
  {
    "text": "Yeah? So that's one of the\nmost surprising, I think, results from stochastic optimal\ncontrol, is that in one case,",
    "start": "4998980",
    "end": "5005330"
  },
  {
    "text": "it tells you it's OK to do\ndeterministic optimal control, yeah. In most cases, it's not OK.",
    "start": "5005330",
    "end": "5011179"
  },
  {
    "text": "It won't give you\nthe same thing.",
    "start": "5011180",
    "end": "5013480"
  }
]
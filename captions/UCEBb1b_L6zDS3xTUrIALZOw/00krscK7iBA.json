[
  {
    "start": "0",
    "end": "1550"
  },
  {
    "text": "In this segment, we will\ngo through two examples",
    "start": "1550",
    "end": "4170"
  },
  {
    "text": "of maximum likelihood\nestimation,",
    "start": "4170",
    "end": "6760"
  },
  {
    "text": "just in order to get a feel\nfor the procedure involved",
    "start": "6760",
    "end": "10240"
  },
  {
    "text": "and the calculations that\none has to go through.",
    "start": "10240",
    "end": "13450"
  },
  {
    "text": "Our first example\nwill be very simple.",
    "start": "13450",
    "end": "16129"
  },
  {
    "text": "We have a binomial\nrandom variable",
    "start": "16129",
    "end": "18320"
  },
  {
    "text": "with parameters n and theta.",
    "start": "18320",
    "end": "21270"
  },
  {
    "text": "So think of having a coin\nthat you flip n times,",
    "start": "21270",
    "end": "25450"
  },
  {
    "text": "and theta is the\nprobability of heads",
    "start": "25450",
    "end": "27750"
  },
  {
    "text": "at each one of the tosses.",
    "start": "27750",
    "end": "29680"
  },
  {
    "text": "So we flip it n\ntimes and we observe",
    "start": "29680",
    "end": "32090"
  },
  {
    "text": "a certain numerical\nvalue, little k",
    "start": "32090",
    "end": "35550"
  },
  {
    "text": "for the random variable\nK. And on the basis",
    "start": "35550",
    "end": "38350"
  },
  {
    "text": "of that numerical value, we\nwould like to estimate theta.",
    "start": "38350",
    "end": "41809"
  },
  {
    "text": "According to the maximum\nlikelihood methodology,",
    "start": "41810",
    "end": "44510"
  },
  {
    "text": "the first step is to write\ndown the likelihood function.",
    "start": "44510",
    "end": "48250"
  },
  {
    "text": "This is the probability of\nobtaining this particular piece",
    "start": "48250",
    "end": "51510"
  },
  {
    "text": "of data if the true\nparameter is theta.",
    "start": "51510",
    "end": "55219"
  },
  {
    "text": "Now, since K is a\nbinomial random variable,",
    "start": "55220",
    "end": "57980"
  },
  {
    "text": "the probability of obtaining\nk heads in n tosses",
    "start": "57980",
    "end": "61020"
  },
  {
    "text": "is given by this\nexpression here.",
    "start": "61020",
    "end": "63830"
  },
  {
    "text": "So what we need to do is to take\nthe data that we have observed,",
    "start": "63830",
    "end": "67900"
  },
  {
    "text": "plug it in this formula,\nleave theta free--",
    "start": "67900",
    "end": "71740"
  },
  {
    "text": "we have here a\nfunction of theta--",
    "start": "71740",
    "end": "74420"
  },
  {
    "text": "and then maximize this function\nof theta over all theta.",
    "start": "74420",
    "end": "78259"
  },
  {
    "text": "Let us now do this calculation.",
    "start": "78260",
    "end": "81020"
  },
  {
    "text": "Actually, instead of\nmaximizing this expression,",
    "start": "81020",
    "end": "84219"
  },
  {
    "text": "it's a little easier to\nmaximize the logarithm",
    "start": "84220",
    "end": "87340"
  },
  {
    "text": "of this expression.",
    "start": "87340",
    "end": "88960"
  },
  {
    "text": "And the logarithm of this\nexpression is as follows.",
    "start": "88960",
    "end": "92150"
  },
  {
    "text": "There's a first term, which\nis the logarithm of the n",
    "start": "92150",
    "end": "95410"
  },
  {
    "text": "choose k term.",
    "start": "95410",
    "end": "96870"
  },
  {
    "text": "Then, the logarithm of theta\nto the k is k times log theta.",
    "start": "96870",
    "end": "102890"
  },
  {
    "text": "And finally, the\nlogarithm of the last term",
    "start": "102890",
    "end": "105659"
  },
  {
    "text": "is n minus k, log\nof 1 minus theta.",
    "start": "105660",
    "end": "112130"
  },
  {
    "text": "So we need to maximize this\nexpression with respect",
    "start": "112130",
    "end": "114549"
  },
  {
    "text": "to theta.",
    "start": "114550",
    "end": "115289"
  },
  {
    "text": "In order to do that, we take\nthe derivative with respect",
    "start": "115289",
    "end": "118140"
  },
  {
    "text": "to theta.",
    "start": "118140",
    "end": "119530"
  },
  {
    "text": "Here, there is no\ntheta involved.",
    "start": "119530",
    "end": "121130"
  },
  {
    "text": "We get a contribution of 0.",
    "start": "121130",
    "end": "123210"
  },
  {
    "text": "This term has a derivative\nof k divided by theta.",
    "start": "123210",
    "end": "127390"
  },
  {
    "text": "And this term here\nhas a derivative,",
    "start": "127390",
    "end": "129880"
  },
  {
    "text": "which is n minus k\ntimes the derivative",
    "start": "129880",
    "end": "134020"
  },
  {
    "text": "of this logarithmic\nterm, which is",
    "start": "134020",
    "end": "136920"
  },
  {
    "text": "1 over what is\ninside the logarithm.",
    "start": "136920",
    "end": "139480"
  },
  {
    "text": "But by the chain rule,\nbecause of this minus sign",
    "start": "139480",
    "end": "142099"
  },
  {
    "text": "here, we get also a minus sign,\nand we obtain this expression.",
    "start": "142100",
    "end": "147900"
  },
  {
    "text": "Now, at the maximum,\nthe derivative",
    "start": "147900",
    "end": "149790"
  },
  {
    "text": "has to be equal to 0.",
    "start": "149790",
    "end": "151920"
  },
  {
    "text": "And this gives us now\nan equation for theta",
    "start": "151920",
    "end": "154770"
  },
  {
    "text": "that we can solve.",
    "start": "154770",
    "end": "156270"
  },
  {
    "text": "Let us take this term, move\nit to the right-hand side,",
    "start": "156270",
    "end": "159630"
  },
  {
    "text": "and then cross-multiply\nwith the denominators",
    "start": "159630",
    "end": "163270"
  },
  {
    "text": "to obtain the relation\nthat k minus k theta-- this",
    "start": "163270",
    "end": "169560"
  },
  {
    "text": "is obtained by multiplying this\nk with this one minus theta",
    "start": "169560",
    "end": "172550"
  },
  {
    "text": "factor-- has to be equal to\nthis term times theta, which",
    "start": "172550",
    "end": "177920"
  },
  {
    "text": "is n times theta minus k theta.",
    "start": "177920",
    "end": "182160"
  },
  {
    "text": "The k theta terms\ncancel, and we're",
    "start": "182160",
    "end": "185370"
  },
  {
    "text": "left with this\nexpression, which tells us",
    "start": "185370",
    "end": "188390"
  },
  {
    "text": "that theta should be\nequal to k over n.",
    "start": "188390",
    "end": "191680"
  },
  {
    "text": "So this is the maximum\nlikelihood estimate",
    "start": "191680",
    "end": "193950"
  },
  {
    "text": "for this particular\nproblem, which",
    "start": "193950",
    "end": "195450"
  },
  {
    "text": "is a pretty reasonable answer.",
    "start": "195450",
    "end": "197989"
  },
  {
    "text": "If you would like to\nrephrase what we just",
    "start": "197990",
    "end": "200380"
  },
  {
    "text": "found in terms of estimators\nand random variables,",
    "start": "200380",
    "end": "204040"
  },
  {
    "text": "the maximum likelihood\nestimator is as follows.",
    "start": "204040",
    "end": "208659"
  },
  {
    "text": "We take the random variable that\nwe observe, our observations,",
    "start": "208660",
    "end": "212579"
  },
  {
    "text": "and divide it by n.",
    "start": "212579",
    "end": "214269"
  },
  {
    "text": "And this is now a\nrandom variable,",
    "start": "214270",
    "end": "216630"
  },
  {
    "text": "which will be our estimator.",
    "start": "216630",
    "end": "219720"
  },
  {
    "text": "Now, notice that in\nthis particular example,",
    "start": "219720",
    "end": "222160"
  },
  {
    "text": "the answer that we got is\nexactly the same as the answer",
    "start": "222160",
    "end": "226090"
  },
  {
    "text": "that we got in the context\nof Bayesian inference",
    "start": "226090",
    "end": "229360"
  },
  {
    "text": "when we were finding the\nmaximum a posteriori probability",
    "start": "229360",
    "end": "232950"
  },
  {
    "text": "estimator, but for\nthe special case",
    "start": "232950",
    "end": "235810"
  },
  {
    "text": "where the prior was a\nuniform distribution.",
    "start": "235810",
    "end": "240160"
  },
  {
    "text": "So if we assume that theta\nis actually a random variable",
    "start": "240160",
    "end": "244400"
  },
  {
    "text": "but has a uniform distribution,\nso that we have a flat prior,",
    "start": "244400",
    "end": "248239"
  },
  {
    "text": "and we carry out maximum\na posteriori probability",
    "start": "248240",
    "end": "251020"
  },
  {
    "text": "estimation.",
    "start": "251020",
    "end": "252080"
  },
  {
    "text": "We do obtain exactly\nthe same estimate.",
    "start": "252080",
    "end": "254930"
  },
  {
    "text": "And this is consistent\nwith the comments",
    "start": "254930",
    "end": "256739"
  },
  {
    "text": "that we made earlier, that\nmaximum likelihood estimation",
    "start": "256740",
    "end": "259989"
  },
  {
    "text": "can be interpreted also as MAP\nestimation with a flat prior.",
    "start": "259990",
    "end": "265630"
  },
  {
    "text": "Let us now move to our\nsecond example, which",
    "start": "265630",
    "end": "267970"
  },
  {
    "text": "will be a little\nmore complicated.",
    "start": "267970",
    "end": "270670"
  },
  {
    "text": "Here, we have n random\nvariables that are independent,",
    "start": "270670",
    "end": "274830"
  },
  {
    "text": "identically distributed.",
    "start": "274830",
    "end": "276090"
  },
  {
    "text": "They all have a\nnormal distribution",
    "start": "276090",
    "end": "278070"
  },
  {
    "text": "with a certain\nmean and variance.",
    "start": "278070",
    "end": "280540"
  },
  {
    "text": "But both the mean and\nthe variance are unknown,",
    "start": "280540",
    "end": "283600"
  },
  {
    "text": "and we want to estimate\nthem on the basis",
    "start": "283600",
    "end": "285560"
  },
  {
    "text": "of these observations.",
    "start": "285560",
    "end": "287570"
  },
  {
    "text": "The first step is to write\ndown the likelihood function.",
    "start": "287570",
    "end": "291409"
  },
  {
    "text": "That is the probability\ndensity function",
    "start": "291409",
    "end": "293960"
  },
  {
    "text": "for the vector of observations\ngiven some set of parameters.",
    "start": "293960",
    "end": "299380"
  },
  {
    "text": "Because of independence,\nthe joint distribution",
    "start": "299380",
    "end": "302650"
  },
  {
    "text": "of the vector of X's that we\nhave obtained is the product",
    "start": "302650",
    "end": "308250"
  },
  {
    "text": "of the PDFs of the\nindividual X's, of the Xi's.",
    "start": "308250",
    "end": "313510"
  },
  {
    "text": "So the PDF of the typical Xi\nthat has variance v and mean mu",
    "start": "313510",
    "end": "321920"
  },
  {
    "text": "is of this form.",
    "start": "321920",
    "end": "323770"
  },
  {
    "text": "So this is the likelihood\nfunction in this case.",
    "start": "323770",
    "end": "327000"
  },
  {
    "text": "This is the probability\ndensity of obtaining",
    "start": "327000",
    "end": "329430"
  },
  {
    "text": "a particular vector\nX of observations",
    "start": "329430",
    "end": "332729"
  },
  {
    "text": "when we have these\nparticular parameters.",
    "start": "332730",
    "end": "335909"
  },
  {
    "text": "We would like to\nmaximize this function.",
    "start": "335909",
    "end": "340980"
  },
  {
    "text": "As in our previous example,\nit is actually a little easier",
    "start": "340980",
    "end": "344700"
  },
  {
    "text": "to maximize the logarithm\nof this expression.",
    "start": "344700",
    "end": "348900"
  },
  {
    "text": "And this is the\nsame as minimizing",
    "start": "348900",
    "end": "350880"
  },
  {
    "text": "the negative of the\nlogarithm of this expression.",
    "start": "350880",
    "end": "354480"
  },
  {
    "text": "Now, when we take the\nlogarithm of this expression,",
    "start": "354480",
    "end": "357180"
  },
  {
    "text": "we have a product.",
    "start": "357180",
    "end": "358159"
  },
  {
    "text": "So we're going to get\na sum of logarithms.",
    "start": "358159",
    "end": "361710"
  },
  {
    "text": "And I leave it to you to verify\nthat the negative logarithm",
    "start": "361710",
    "end": "366350"
  },
  {
    "text": "of this expression is of this\nform plus some other constant",
    "start": "366350",
    "end": "371810"
  },
  {
    "text": "that does not involve\nthe parameters,",
    "start": "371810",
    "end": "373930"
  },
  {
    "text": "and which comes from this factor\nof 1 over square root 2pi.",
    "start": "373930",
    "end": "378120"
  },
  {
    "text": "In particular, this\nterm here appears",
    "start": "378120",
    "end": "381820"
  },
  {
    "text": "when we take the\nlogarithm of this.",
    "start": "381820",
    "end": "384220"
  },
  {
    "text": "And this happens n times because\nwe have a product of n terms.",
    "start": "384220",
    "end": "388410"
  },
  {
    "text": "And this term here\nappears when we",
    "start": "388410",
    "end": "391070"
  },
  {
    "text": "take the logarithm\nof this expression,",
    "start": "391070",
    "end": "393640"
  },
  {
    "text": "and after we put\nin the minus sign,",
    "start": "393640",
    "end": "396550"
  },
  {
    "text": "because we're\nactually considering",
    "start": "396550",
    "end": "398080"
  },
  {
    "text": "the negative of the logarithm.",
    "start": "398080",
    "end": "400409"
  },
  {
    "text": "Now, to carry out the\nminimization, what",
    "start": "400409",
    "end": "403100"
  },
  {
    "text": "we need to do is to take the\nderivative of this expression",
    "start": "403100",
    "end": "406900"
  },
  {
    "text": "with respect to\nmu, set it to zero,",
    "start": "406900",
    "end": "409419"
  },
  {
    "text": "and also take the\nderivative with respect to v",
    "start": "409420",
    "end": "412270"
  },
  {
    "text": "and set it to zero as well.",
    "start": "412270",
    "end": "414319"
  },
  {
    "text": "Solve those equations and find\nthe optimal mu and v. So let's",
    "start": "414320",
    "end": "420000"
  },
  {
    "text": "start by optimizing\nwith respect to mu.",
    "start": "420000",
    "end": "422960"
  },
  {
    "text": "So we're going to take the\nderivative of this expression",
    "start": "422960",
    "end": "425720"
  },
  {
    "text": "with respect to mu\nand set it to zero.",
    "start": "425720",
    "end": "429160"
  },
  {
    "text": "This term does not\ninvolve mu, so we only",
    "start": "429160",
    "end": "431940"
  },
  {
    "text": "need to take the\nderivative of this.",
    "start": "431940",
    "end": "434690"
  },
  {
    "text": "And the derivative\nof this is going",
    "start": "434690",
    "end": "436640"
  },
  {
    "text": "to be-- there's a term\n1 over v. And then",
    "start": "436640",
    "end": "441470"
  },
  {
    "text": "the derivative of a\nquadratic divided by 2",
    "start": "441470",
    "end": "444180"
  },
  {
    "text": "is just xi minus mu.",
    "start": "444180",
    "end": "447930"
  },
  {
    "text": "And we have one term\nfor each possible i.",
    "start": "447930",
    "end": "451960"
  },
  {
    "text": "We get this equation.",
    "start": "451960",
    "end": "454699"
  },
  {
    "text": "Now we can cancel out v, and\nwe're left with the equation",
    "start": "454700",
    "end": "460909"
  },
  {
    "text": "that the sum of the\nxi's is equal to the sum",
    "start": "460909",
    "end": "465169"
  },
  {
    "text": "of the mus, which is n times mu.",
    "start": "465170",
    "end": "467920"
  },
  {
    "text": "And now we can send\nn to the denominator",
    "start": "467920",
    "end": "471260"
  },
  {
    "text": "to obtain that\nthe estimate of mu",
    "start": "471260",
    "end": "475020"
  },
  {
    "text": "is going to be the sum\nof the xi's divided by n.",
    "start": "475020",
    "end": "479960"
  },
  {
    "text": "So the maximum likelihood\nestimate of the mean",
    "start": "479960",
    "end": "482669"
  },
  {
    "text": "takes a very simple\nand very natural form.",
    "start": "482670",
    "end": "485480"
  },
  {
    "text": "It is just the sample mean.",
    "start": "485480",
    "end": "488160"
  },
  {
    "text": "Now, let us continue with\nthe minimization with respect",
    "start": "488160",
    "end": "491070"
  },
  {
    "text": "to v. In order to carry\nout that minimization,",
    "start": "491070",
    "end": "494670"
  },
  {
    "text": "we need to take the derivative\nof this expression with respect",
    "start": "494670",
    "end": "497680"
  },
  {
    "text": "to v and set it to zero.",
    "start": "497680",
    "end": "499900"
  },
  {
    "text": "The derivative of\nthe first term is",
    "start": "499900",
    "end": "502110"
  },
  {
    "text": "equal to n over 2 times 1\nover v. And then from here,",
    "start": "502110",
    "end": "508699"
  },
  {
    "text": "when we take the\nderivative, we obtain",
    "start": "508700",
    "end": "512914"
  },
  {
    "text": "the sum of all these terms\ndivided by 2v squared.",
    "start": "512915",
    "end": "525180"
  },
  {
    "text": "But actually, when we take\nthe derivative of 1 over v,",
    "start": "525180",
    "end": "527925"
  },
  {
    "text": "the derivative is\nminus 1 over v squared.",
    "start": "527925",
    "end": "531310"
  },
  {
    "text": "And for this reason here,\nwe will have a minus sign.",
    "start": "531310",
    "end": "536330"
  },
  {
    "text": "So this is the\nderivative with respect",
    "start": "536330",
    "end": "538030"
  },
  {
    "text": "to v. We set it equal to zero\nand carry out some algebra.",
    "start": "538030",
    "end": "543260"
  },
  {
    "text": "What is the algebra\ninvolved here?",
    "start": "543260",
    "end": "545770"
  },
  {
    "text": "We can delete this term, 2,\nthat appears here and there.",
    "start": "545770",
    "end": "551280"
  },
  {
    "text": "This term v cancels\nout this exponent here.",
    "start": "551280",
    "end": "556840"
  },
  {
    "text": "Then we take this v, move\nit to the other side,",
    "start": "556840",
    "end": "560700"
  },
  {
    "text": "and then take this n and\nmove it to this side,",
    "start": "560700",
    "end": "564860"
  },
  {
    "text": "underneath this term.",
    "start": "564860",
    "end": "566630"
  },
  {
    "text": "And finally, what we\nobtain after you carry out",
    "start": "566630",
    "end": "569260"
  },
  {
    "text": "this algebra is this\nexpression, that the estimate",
    "start": "569260",
    "end": "572690"
  },
  {
    "text": "of the variance is some\nform of the sample variance",
    "start": "572690",
    "end": "579150"
  },
  {
    "text": "where we use the\noptimal value of mu.",
    "start": "579150",
    "end": "583490"
  },
  {
    "text": "And the optimal value of\nmu we have already found.",
    "start": "583490",
    "end": "587500"
  },
  {
    "text": "It's given by this\nexpression here.",
    "start": "587500",
    "end": "589990"
  },
  {
    "text": "So we obtain a pretty natural\nestimate for the variance",
    "start": "589990",
    "end": "593700"
  },
  {
    "text": "as well by using this maximum\nlikelihood methodology.",
    "start": "593700",
    "end": "598340"
  },
  {
    "text": "Now, these two examples\nwere particularly nice",
    "start": "598340",
    "end": "600880"
  },
  {
    "text": "because the algebra was\nnot too complicated.",
    "start": "600880",
    "end": "604450"
  },
  {
    "text": "And the answers\nturned out to be what",
    "start": "604450",
    "end": "607160"
  },
  {
    "text": "you might have guessed without\nusing any fancy methods.",
    "start": "607160",
    "end": "611410"
  },
  {
    "text": "But in other problems,\nthe calculations",
    "start": "611410",
    "end": "613839"
  },
  {
    "text": "may be more complicated and the\nanswers may not be so obvious.",
    "start": "613840",
    "end": "618869"
  },
  {
    "start": "618869",
    "end": "619368"
  }
]
[
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6029"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6030",
    "end": "12660"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "12660",
    "end": "17873"
  },
  {
    "text": " PROFESSOR: So as I was\nsaying, what we want to do",
    "start": "17874",
    "end": "23880"
  },
  {
    "text": "is get up through use of some of\nthese statistical distributions for making hypotheses tests and\nunderstanding the relationship",
    "start": "23880",
    "end": "32729"
  },
  {
    "text": "of probabilities associated\nwith hypotheses such as a point",
    "start": "32729",
    "end": "40670"
  },
  {
    "text": "belongs to this distribution\nor that distribution. And that will set the\nground for talking",
    "start": "40670",
    "end": "46610"
  },
  {
    "text": "about statistical process\ncontrol and SPC charting, where you're asking the question\nof a new piece of data",
    "start": "46610",
    "end": "53329"
  },
  {
    "text": "off of the manufacturing\nline, does that piece of data come from the in\ncontrol distribution?",
    "start": "53330",
    "end": "59180"
  },
  {
    "text": "Or does it come from some\nout of control distribution? So it's all about\nprobabilities on SPC charts.",
    "start": "59180",
    "end": "66290"
  },
  {
    "text": "And we want to build up\nthe rest of the machinery that we need for that today.",
    "start": "66290",
    "end": "72229"
  },
  {
    "text": " To do that, one of\nthe subtle things",
    "start": "72230",
    "end": "78490"
  },
  {
    "text": "that we have to understand\na bit more about is sampling and\nsampling distributions.",
    "start": "78490",
    "end": "84190"
  },
  {
    "text": "And really what we're\ndealing with here is issues of the\nuse of statistics",
    "start": "84190",
    "end": "90790"
  },
  {
    "text": "dealing with observed data. And I have this\nphilosophical picture of what I think of as\nstatistics meaning.",
    "start": "90790",
    "end": "97390"
  },
  {
    "text": "And that's our real goal and\nstatistics is to reason about, think about, and be able\nto argue about processes--",
    "start": "97390",
    "end": "107520"
  },
  {
    "text": "in our case, real\nmanufacturing processes-- when there's uncertainty\nin those processes.",
    "start": "107520",
    "end": "113950"
  },
  {
    "text": "There is noise. There's other things\nwe don't know. But the key idea\nin statistics is we are getting some evidence.",
    "start": "113950",
    "end": "120040"
  },
  {
    "text": "We're getting some data. And what we want\nto be able to do is use that data to start\nto infer things back",
    "start": "120040",
    "end": "127000"
  },
  {
    "text": "about the underlying\npopulation, the underlying process or distribution.",
    "start": "127000",
    "end": "132110"
  },
  {
    "text": "So there are some\npreconditions in here. A lot of what I said here\nis we're reasoning based",
    "start": "132110",
    "end": "141100"
  },
  {
    "text": "on evidence from observed data. But that really means we\nare taking fundamentally",
    "start": "141100",
    "end": "147220"
  },
  {
    "text": "a probability model\nof what's going on. And we talked last\ntime, for example,",
    "start": "147220",
    "end": "153580"
  },
  {
    "text": "about assumptions with normal\ndistributions and parameters",
    "start": "153580",
    "end": "159160"
  },
  {
    "text": "of normal distributions. And what we're going to do\ntoday is focus a little bit more",
    "start": "159160",
    "end": "164260"
  },
  {
    "text": "on evidence coming from\nfinite sets of observations,",
    "start": "164260",
    "end": "169720"
  },
  {
    "text": "drawn from that population,\nand then calculations we do on that--",
    "start": "169720",
    "end": "174840"
  },
  {
    "text": "simple calculations, like\ncalculating the sample mean. And then we have this\nnumber, this sample mean.",
    "start": "174840",
    "end": "181020"
  },
  {
    "text": "What's it really telling us? What can we infer back about\nthe underlying distribution--",
    "start": "181020",
    "end": "187320"
  },
  {
    "text": "what the true mean of the\nunderlying population is? And then a little bit later,\nwe'll flesh this out more.",
    "start": "187320",
    "end": "196960"
  },
  {
    "text": "But already, even as we start\nbuilding these simple arguments",
    "start": "196960",
    "end": "202360"
  },
  {
    "text": "based on our data, we have\nan underlying implicit model of the process. It may be a purely\nprobabilistic model,",
    "start": "202360",
    "end": "208900"
  },
  {
    "text": "saying it has a certain mean\nand a Gaussian distribution or a certain mean in a normal--",
    "start": "208900",
    "end": "214780"
  },
  {
    "text": "or a uniform or a Poisson. There is a model there. And so we have to keep in\nmind that it is only a model.",
    "start": "214780",
    "end": "224680"
  },
  {
    "text": "A little bit later,\nwe'll also build up other kinds of\nfunctional relationships when we get to things like\nresponse surface modeling.",
    "start": "224680",
    "end": "232210"
  },
  {
    "text": "But for now, these are\nrelatively simple models, mostly focused on the\nprobabilistic or stochastic",
    "start": "232210",
    "end": "240160"
  },
  {
    "text": "nature of that. So here's the plan for today.",
    "start": "240160",
    "end": "245370"
  },
  {
    "text": "What we're going to do\nis talk a little bit about sampling distributions.",
    "start": "245370",
    "end": "251530"
  },
  {
    "text": "We touched on this a\nlittle bit last time when we talked about\nthe distribution of the sum of random variables\nand the central limit theorem,",
    "start": "251530",
    "end": "261310"
  },
  {
    "text": "where the sum or\nthe average always tends towards the normal. In some of the cases, we're\ngoing to be calculating things,",
    "start": "261310",
    "end": "270410"
  },
  {
    "text": "like the sample s\nsquared, the sample variants that are not going\nto be normally distributed.",
    "start": "270410",
    "end": "276569"
  },
  {
    "text": "They will have other\nstatistical shapes or statistical distributions\nsuch as the chi-squared.",
    "start": "276570",
    "end": "283670"
  },
  {
    "text": "There will be other cases where\nthe student t-distribution is operable. So we want to get a sense of\nthese sampling distributions",
    "start": "283670",
    "end": "291650"
  },
  {
    "text": "and understand how to use\nthose to make not only point estimates--",
    "start": "291650",
    "end": "298720"
  },
  {
    "text": "that is our best guess of things\nlike the underlying population mean-- but also confidence intervals--\nwhere, with some probability,",
    "start": "298720",
    "end": "306100"
  },
  {
    "text": "we think the true mean lies or\nwhere, with some probability, we think the true\nvariance lies based",
    "start": "306100",
    "end": "312250"
  },
  {
    "text": "on one set of observations. So that's where the sampling\ndistributions come into play.",
    "start": "312250",
    "end": "319419"
  },
  {
    "text": "And we'll talk about the\neffects of sample size on that as well as things like\nwhat kind of inferences,",
    "start": "319420",
    "end": "326440"
  },
  {
    "text": "these point and confidence\ninterval inferences we can make on those.",
    "start": "326440",
    "end": "333500"
  },
  {
    "text": "And then, again, leading up\ntowards hypothesis testing. And then really, this\nwill be for next time.",
    "start": "333500",
    "end": "342380"
  },
  {
    "text": "We'll dive into SPC charts. ",
    "start": "342380",
    "end": "349150"
  },
  {
    "text": "So here's how we typically\nare using sampling. We have some underlying--",
    "start": "349150",
    "end": "354460"
  },
  {
    "text": "I'll refer to it as the\npopulation distribution or sometimes the\nparent distribution.",
    "start": "354460",
    "end": "360850"
  },
  {
    "text": "It's the set or universe\nof all possible parts, say, coming off your\nmanufacturing line",
    "start": "360850",
    "end": "367150"
  },
  {
    "text": "or all possible observations. What we're typically\ngoing to do is just draw",
    "start": "367150",
    "end": "373210"
  },
  {
    "text": "some number, some finite\nnumber, of samples, some n samples of\nthe process output--",
    "start": "373210",
    "end": "380600"
  },
  {
    "text": "so some x sub i drawn\nfrom a parent distribution with some PDF p.",
    "start": "380600",
    "end": "388090"
  },
  {
    "text": "And what we're going to\nbe doing is calculating these sample mean, sample\nvariants, other sorts",
    "start": "388090",
    "end": "393190"
  },
  {
    "text": "of sample statistics. A key point here is\nthe underlying process.",
    "start": "393190",
    "end": "399670"
  },
  {
    "text": "That basic variable x has\na probability distribution function associated with it.",
    "start": "399670",
    "end": "406820"
  },
  {
    "text": "This new variable x\nbar that we calculate, this statistic\nthat we calculate,",
    "start": "406820",
    "end": "412960"
  },
  {
    "text": "also has a probability density\nfunction associated with it. And it's a different\none than the parent one.",
    "start": "412960",
    "end": "419319"
  },
  {
    "text": "And so what we'll\nneed to understand is what those\nprobability distributions",
    "start": "419320",
    "end": "425349"
  },
  {
    "text": "are that arise from\nsampling, and then how to work backwards from\nthose to make inferences",
    "start": "425350",
    "end": "430900"
  },
  {
    "text": "about the parent. Now, a quick thing. I guess there's both\ndefinitions on this slide,",
    "start": "430900",
    "end": "436340"
  },
  {
    "text": "but also a quick thing about\ndefinitions or terminology",
    "start": "436340",
    "end": "443750"
  },
  {
    "text": "or notation that I like to use. And in particular, I'm,\nagain, distinguishing",
    "start": "443750",
    "end": "451430"
  },
  {
    "text": "between the population or\nparent distribution, and then these sample statistics.",
    "start": "451430",
    "end": "458740"
  },
  {
    "text": "And typically when I talk\nabout \"truth\" or the population as a whole, we're\nusing Greek variables",
    "start": "458740",
    "end": "467110"
  },
  {
    "text": "like mu, sigma, rho, xy, for\nthe correlation coefficient.",
    "start": "467110",
    "end": "474849"
  },
  {
    "text": "And those expectations,\nthose different moments, are calculated over\nthe entire population.",
    "start": "474850",
    "end": "482470"
  },
  {
    "text": "Typically we're doing\nthose analytically if we have a closed\nform description of what",
    "start": "482470",
    "end": "488080"
  },
  {
    "text": "the population is. In contrast, I'm\ngoing to typically use",
    "start": "488080",
    "end": "493340"
  },
  {
    "text": "Roman characters-- x, s, r, xy, for example--",
    "start": "493340",
    "end": "500390"
  },
  {
    "text": "to indicate the finite\nsample statistics calculated from some n\nnumber of observations.",
    "start": "500390",
    "end": "509630"
  },
  {
    "text": "And so that's when we have\na finite discrete number of observations.",
    "start": "509630",
    "end": "516229"
  },
  {
    "text": "And we have simple formulas\nfor the calculation of those statistics.",
    "start": "516230",
    "end": "522450"
  },
  {
    "text": "A little bit later\nin the term, we will come back and start to\nlook in particular at covariance",
    "start": "522450",
    "end": "528690"
  },
  {
    "text": "and correlation between two\ndifferent random variables, some x and y. Those are especially\nimportant when we're looking",
    "start": "528690",
    "end": "535260"
  },
  {
    "text": "for functional dependencies. Right now, we're simply\nlooking at one set of data",
    "start": "535260",
    "end": "541530"
  },
  {
    "text": "or one population,\none random variable x. So we'll focus on\nunivariate stuff today.",
    "start": "541530",
    "end": "548700"
  },
  {
    "text": " There is a term,\n\"random sampling,\"",
    "start": "548700",
    "end": "555550"
  },
  {
    "text": "that actually has a\ntechnical definition that I want to point out that's very\nclose to the intuitive notion",
    "start": "555550",
    "end": "563470"
  },
  {
    "text": "here. But it actually is a\nlittle bit stronger in requirements\nfor its definition.",
    "start": "563470",
    "end": "569890"
  },
  {
    "text": "We said sampling is this act of\ntaking some finite observations out of a population.",
    "start": "569890",
    "end": "575500"
  },
  {
    "text": "Random sampling is when every\nobservation that we pull",
    "start": "575500",
    "end": "581260"
  },
  {
    "text": "is identically distributed,\nhas the same PDF associated with it, and is independent\nfrom any other sample that we",
    "start": "581260",
    "end": "590740"
  },
  {
    "text": "pull from that population. And this would not always\nnaturally be the case--",
    "start": "590740",
    "end": "597250"
  },
  {
    "text": "if you had, for example,\nfinite populations, and you pulled out a sample,\nheld it in your hand,",
    "start": "597250",
    "end": "603490"
  },
  {
    "text": "recorded it, pulled out\nanother sample, for example.",
    "start": "603490",
    "end": "608560"
  },
  {
    "text": "Imagine that you've got a bag of\n17 blue and red marbles in it.",
    "start": "608560",
    "end": "615830"
  },
  {
    "text": "And I pull a marble\nout, and it's red. I hold it in my hand, and\nI pull another marble out.",
    "start": "615830",
    "end": "624670"
  },
  {
    "text": "Do you think I'm sampling\nfrom the same underlying distribution? No, because I did not\nreplace that original marble.",
    "start": "624670",
    "end": "632530"
  },
  {
    "text": "So now the mix of\nblue and red marbles is different within that\nbag, and the probability",
    "start": "632530",
    "end": "637630"
  },
  {
    "text": "is different. It is not identical and\nindependent anymore.",
    "start": "637630",
    "end": "643000"
  },
  {
    "text": "The observation that I made\nfirst, based on the first draw, changes the probability\nfor later draws, changes--",
    "start": "643000",
    "end": "651670"
  },
  {
    "text": "there is dependence\nas well as no longer an identical distribution.",
    "start": "651670",
    "end": "658600"
  },
  {
    "text": "So when we do random sampling,\nas I'm defining it here,",
    "start": "658600",
    "end": "664029"
  },
  {
    "text": "and random sampling\nfor calculation of some of these\nsampling distributions, we're assuming if it's coming\nfrom a finite population,",
    "start": "664030",
    "end": "671509"
  },
  {
    "text": "you would always put\nthe observation back in and do another sample\nfrom the same pool.",
    "start": "671510",
    "end": "678640"
  },
  {
    "text": "Typically what\nyou're often doing is assuming there's\nno connection from one to the other, and the\nsame process, physics,",
    "start": "678640",
    "end": "684639"
  },
  {
    "text": "is operable from one\npoint in time to the next. So we are typically making\nthis IID, this Independent",
    "start": "684640",
    "end": "691570"
  },
  {
    "text": "and Identically\nDistributed assumption.",
    "start": "691570",
    "end": "697690"
  },
  {
    "text": "And then we're going to,\nagain, as I said, calculate some statistics from those. Ultimately, when\nyou have a sample--",
    "start": "697690",
    "end": "704170"
  },
  {
    "text": "sample of size 14, drawn\nfrom a big population. You calculate x bar.",
    "start": "704170",
    "end": "709750"
  },
  {
    "text": "What do you get? A number. You get an actual number\nbecause I observed those 14",
    "start": "709750",
    "end": "716560"
  },
  {
    "text": "things, measured length\nor whatever it was that I was measuring on those.",
    "start": "716560",
    "end": "722720"
  },
  {
    "text": "And so a key point here\nis that the statistic is a function of the\nsample and the sample data.",
    "start": "722720",
    "end": "730010"
  },
  {
    "text": "And so it's actually a\nvalue that you can compute. If I do that, I grab one\nsample, I calculate that x bar,",
    "start": "730010",
    "end": "738690"
  },
  {
    "text": "I've got one number. If I were to go back\nand draw another sample",
    "start": "738690",
    "end": "744640"
  },
  {
    "text": "from that distribution,\nI get a different number. And so if I keep\ngoing back and drawing",
    "start": "744640",
    "end": "749699"
  },
  {
    "text": "multiple, multiple\nsamples, that's how you build up a distribution\nfunction associated",
    "start": "749700",
    "end": "755279"
  },
  {
    "text": "with that statistic,\nthat calculation. So that's where this notion of\nstatistics, x bar or whatever,",
    "start": "755280",
    "end": "763589"
  },
  {
    "text": "as a random variable\nalso comes into play. For any one sample\nit's a number.",
    "start": "763590",
    "end": "770330"
  },
  {
    "text": "But when I go and take multiple\nsamples, multiple sets, of n,",
    "start": "770330",
    "end": "775440"
  },
  {
    "text": "now I build up a distribution\nfunction associated with those.",
    "start": "775440",
    "end": "781160"
  },
  {
    "text": "I'm going to switch here to-- or do I want to? No.",
    "start": "781160",
    "end": "786670"
  },
  {
    "text": "I'm going to switch to-- this is here on the web.",
    "start": "786670",
    "end": "791680"
  },
  {
    "text": "I mentioned last time\nthis very nice website. ",
    "start": "791680",
    "end": "798780"
  },
  {
    "text": "I don't even know\nwhat the acronym stands for-- this SticiGui. It's out of the Department\nof Statistics at Berkeley.",
    "start": "798780",
    "end": "805650"
  },
  {
    "text": "It's got a lot of different-- I guess sort of an online\ncourse kind of thing.",
    "start": "805650",
    "end": "811959"
  },
  {
    "text": "But what I really like\nin this is the Tools tab.",
    "start": "811960",
    "end": "817160"
  },
  {
    "text": "So if I go to that Tools tab-- let me do that-- it's got a number of these\nlittle Java utilities online.",
    "start": "817160",
    "end": "825920"
  },
  {
    "text": "And one that I want\nto look at here first is sampling distributions.",
    "start": "825920",
    "end": "831029"
  },
  {
    "text": "So let's see. Let this load.  Loading up Java, here.",
    "start": "831030",
    "end": "837910"
  },
  {
    "text": "So here's an example\nof sampling from some a priori distribution.",
    "start": "837910",
    "end": "844390"
  },
  {
    "text": "And this is actually drawing\nfrom a uniform distribution with discrete values,\n0, 1, 2, 3, and 4.",
    "start": "844390",
    "end": "853540"
  },
  {
    "text": "So that's our underlying\ntrue population, and they all have\nequal probabilities.",
    "start": "853540",
    "end": "858740"
  },
  {
    "text": "And what I'm going to\ndo is calculate a-- I'm going to draw a sample\ndown here at the bottom.",
    "start": "858740",
    "end": "864780"
  },
  {
    "text": "It's a sample of size 5. So I'm going to do random\nsampling with replacement.",
    "start": "864780",
    "end": "870360"
  },
  {
    "text": "So I'm going to draw five\nindependent and identically distributed samples out of that\nunderlying parent distribution.",
    "start": "870360",
    "end": "876950"
  },
  {
    "text": "And then I'm going to\ncalculate some statistic. What I want to do is to actually\ncalculate the sample mean.",
    "start": "876950",
    "end": "882670"
  },
  {
    "text": "So there in blue is our\nunderlying population. Let me take one sample of\nsize 5, calculate the mean,",
    "start": "882670",
    "end": "890820"
  },
  {
    "text": "and plot it. There it is. It's a mean of 1.4. Let me take another sample.",
    "start": "890820",
    "end": "896510"
  },
  {
    "text": "I take another sample. Do you think the value\nis going to be 1.4 again? It might be.",
    "start": "896510",
    "end": "901970"
  },
  {
    "text": "AUDIENCE: Might be. PROFESSOR: But\nprobably not, right? Let's see what happens. There it is-- 2.4.",
    "start": "901970",
    "end": "908060"
  },
  {
    "text": "Let me do a few more.  So the green bars\nare popping up,",
    "start": "908060",
    "end": "914460"
  },
  {
    "text": "as I think I've done something\nlike 1, 2, 3, 4, 5, 6-- something like 8 different\nsamples, each of size 5,",
    "start": "914460",
    "end": "921510"
  },
  {
    "text": "plotted the mean. Now to speed things\nup, I can keep taking more and more samples.",
    "start": "921510",
    "end": "928440"
  },
  {
    "text": "What distribution do you\nthink this is trending to? AUDIENCE: Normal. PROFESSOR: Normal. Down here at the bottom,\nI can take samples",
    "start": "928440",
    "end": "934890"
  },
  {
    "text": "that are a little bit larger. Or let me take-- excuse me, we take--\nthe thing tells me",
    "start": "934890",
    "end": "941020"
  },
  {
    "text": "how many samples I'm taking,\nso I don't have to just take one sample of five, plot it. I can take 10 samples of\n5, each of 5, and plot it.",
    "start": "941020",
    "end": "950060"
  },
  {
    "text": "So it's just speeding\nup my button clicks so that we can get a little\nbit better shape on that.",
    "start": "950060",
    "end": "957205"
  },
  {
    "text": "So there's the point. That's a very fascinating point. I find it fascinating\nthat I can sample from a non-normal\ndistribution, take the average,",
    "start": "957205",
    "end": "965310"
  },
  {
    "text": "the sample average, x bar, and\nover lots and lots of sampling,",
    "start": "965310",
    "end": "971930"
  },
  {
    "text": "I get a normal distribution. What else? What other observations\nor what other points",
    "start": "971930",
    "end": "978640"
  },
  {
    "text": "might you make about\nthat green distribution?",
    "start": "978640",
    "end": "983930"
  },
  {
    "text": "What do you think is true\nabout that green distribution? There's a really\nimportant fact which",
    "start": "983930",
    "end": "989850"
  },
  {
    "text": "motivates why we can't\ncalculate x bars all the time and believe the\nnumbers that come out",
    "start": "989850",
    "end": "995430"
  },
  {
    "text": "of an x bar calculation. ",
    "start": "995430",
    "end": "1001070"
  },
  {
    "text": "AUDIENCE: It's\ncentered around 2. PROFESSOR: It's\ncentered around 2. Out of the numbers\n0, 1, 2, 3, and 4,",
    "start": "1001070",
    "end": "1006440"
  },
  {
    "text": "what do you think the average\nis-- the true average? 2. So one thing that's very\nnice about the sample mean",
    "start": "1006440",
    "end": "1018360"
  },
  {
    "text": "is that it trends toward\nthe true population mean.",
    "start": "1018360",
    "end": "1024130"
  },
  {
    "text": "It's unbiased. That if I were to\ntake enough samples,",
    "start": "1024130",
    "end": "1031390"
  },
  {
    "text": "the average of or the mean of\nall of these sample averages",
    "start": "1031390",
    "end": "1038630"
  },
  {
    "text": "is equal to the true\nunderlying population mean. It's unbiased. Doesn't have a bias or\ndelta, a fixed delta,",
    "start": "1038630",
    "end": "1045679"
  },
  {
    "text": "a fixed offset error in it. It is an unbiased estimator.",
    "start": "1045680",
    "end": "1050690"
  },
  {
    "text": "So I can take lots\nand build that up. Turns out there's\nanother thing that's",
    "start": "1050690",
    "end": "1056630"
  },
  {
    "text": "true which I don't\nwant to go into and don't want to try to prove.",
    "start": "1056630",
    "end": "1062139"
  },
  {
    "text": "But it turns out that the sample\nmean is also not only unbiased,",
    "start": "1062140",
    "end": "1068890"
  },
  {
    "text": "but it's also the\nminimum error estimator. So on average, it's the\nbest estimator of the mean",
    "start": "1068890",
    "end": "1076540"
  },
  {
    "text": "that you can use as a statistic,\nmeaning its distribution in some sense is the narrowest.",
    "start": "1076540",
    "end": "1083260"
  },
  {
    "text": "The x bar distribution is\nthe narrowest estimator you can have for trying to\ncalculate the sample mean",
    "start": "1083260",
    "end": "1093370"
  },
  {
    "text": "based on your distributions. Now another important\nthing that comes up",
    "start": "1093370",
    "end": "1099159"
  },
  {
    "text": "here is at least a\nfew of the times, I got a sample\nmean that was 0.6.",
    "start": "1099160",
    "end": "1107940"
  },
  {
    "text": "Is it wrong? ",
    "start": "1107940",
    "end": "1113930"
  },
  {
    "text": "If you do just one sample,\nit's quite possible, out of this set of four,\nI drew a sample of size 5.",
    "start": "1113930",
    "end": "1120700"
  },
  {
    "text": "I might have gotten\na value of 0.6. That's all the data you have. What's your best guess\nfor the true mean",
    "start": "1120700",
    "end": "1127299"
  },
  {
    "text": "of the underlying population? That 0.6, whatever\nthat value was.",
    "start": "1127300",
    "end": "1133320"
  },
  {
    "text": "But now there is\nsome spread on it. And so if you're\nwise, you would also",
    "start": "1133320",
    "end": "1139490"
  },
  {
    "text": "start to want to hedge your\nbets a little bit here, right? You want to be able to\nsay, my best guess is 0.5.",
    "start": "1139490",
    "end": "1146760"
  },
  {
    "text": "But I think I'm only\ndrawing a sample of size 5. So I know there is, in fact,\nthis kind of Gaussian spread.",
    "start": "1146760",
    "end": "1155400"
  },
  {
    "text": "And I think the\ntrue mean probably lies within some range of that. And so you would like to have\nthis confidence interval idea.",
    "start": "1155400",
    "end": "1163020"
  },
  {
    "text": "We'll get back to that\na little bit later. In fact, there's another\nvery nice little tool in here",
    "start": "1163020",
    "end": "1169620"
  },
  {
    "text": "for illustrating\nconfidence intervals that we'll use at that point.",
    "start": "1169620",
    "end": "1175788"
  },
  {
    "text": "I want to do one more\nthing, and then we'll go back to the lecture slides. One of the neat things\nyou can do with this tool,",
    "start": "1175788",
    "end": "1182140"
  },
  {
    "text": "and it's lots of\nfun for you guys to connect up with\nand play with, is you can change\nthe sample size.",
    "start": "1182140",
    "end": "1188320"
  },
  {
    "text": " Let's say you wanted a\nbetter or a tighter estimate",
    "start": "1188320",
    "end": "1195230"
  },
  {
    "text": "for the x bar. You're not happy\nwith the idea that sometimes, with fairly\nsubstantial probability,",
    "start": "1195230",
    "end": "1202100"
  },
  {
    "text": "you might be off\nby plus or minus 1. You have a substantial\nprobability",
    "start": "1202100",
    "end": "1208190"
  },
  {
    "text": "of estimating, say, the-- or guessing the sample mean\nto be more than one value away",
    "start": "1208190",
    "end": "1217220"
  },
  {
    "text": "from the true population mean. What might you do\nto try to improve",
    "start": "1217220",
    "end": "1222410"
  },
  {
    "text": "your likelihood of being closer\nto the true mean when you're",
    "start": "1222410",
    "end": "1227510"
  },
  {
    "text": "doing sampling? AUDIENCE: More samples. PROFESSOR: More samples. More samples?",
    "start": "1227510",
    "end": "1233010"
  },
  {
    "text": "I guess you could\ndo more samples. But in some sense, really, that\ntaking one sample of size 5",
    "start": "1233010",
    "end": "1239400"
  },
  {
    "text": "and another sample\nof size 5, that's like one sample of size 10. Larger samples.",
    "start": "1239400",
    "end": "1245040"
  },
  {
    "text": "AUDIENCE: Oh, yeah,\nlarger samples. PROFESSOR: Larger samples. So if I do that\nhere, let's take--",
    "start": "1245040",
    "end": "1254700"
  },
  {
    "text": "instead of samples of size\n5, let's do a modest increase first and take\nsamples of size 10.",
    "start": "1254700",
    "end": "1262420"
  },
  {
    "text": "See what happens now. Oops, let me just do-- OK, that's good.",
    "start": "1262420",
    "end": "1268860"
  },
  {
    "text": "I'm taking a lot\nof samples here. I've taken several hundred\nsamples, each of size 10.",
    "start": "1268860",
    "end": "1273960"
  },
  {
    "text": "And sure enough,\nthat distribution is a little bit tighter. Let's say if I took a really\nbig sample, sample of size 100.",
    "start": "1273960",
    "end": "1282650"
  },
  {
    "text": "Yeah, looking a lot tighter. So one question is, we know\nas I take a larger samples,",
    "start": "1282650",
    "end": "1289360"
  },
  {
    "text": "the distribution gets tighter. One of the things we\nwant to do is understand how much tighter do they get as\na function of the sample size?",
    "start": "1289360",
    "end": "1300259"
  },
  {
    "text": "So it turns out-- let\nme go back now to-- ",
    "start": "1300260",
    "end": "1312270"
  },
  {
    "text": "it turns out that if I'm\nsampling from a parent distribution, the variance in\nthe estimate of that x bar,",
    "start": "1312270",
    "end": "1321060"
  },
  {
    "text": "or the PDF, the variance\nof x bar itself,",
    "start": "1321060",
    "end": "1326190"
  },
  {
    "text": "shrinks with size n. And the variance in\nfact scales as 1 over n.",
    "start": "1326190",
    "end": "1333029"
  },
  {
    "text": "It scales inversely proportional\nto the size of the sample. ",
    "start": "1333030",
    "end": "1340090"
  },
  {
    "text": "That's true always as you take\nlarger numbers of samples. For this special case, if\nmy underlying population",
    "start": "1340090",
    "end": "1348010"
  },
  {
    "text": "is in fact really a true-- has a true probability\ndistribution function",
    "start": "1348010",
    "end": "1353590"
  },
  {
    "text": "that was normal,\nthen it turns out that x bar is not just\ntrending towards the normal,",
    "start": "1353590",
    "end": "1361010"
  },
  {
    "text": "but is itself, even for very\nsmall numbers of samples, also a normal distribution.",
    "start": "1361010",
    "end": "1367280"
  },
  {
    "text": "So in that little\ndemo I showed you, drawing from a\nuniform distribution, for large enough n's,\nlarge enough samples,",
    "start": "1367280",
    "end": "1373399"
  },
  {
    "text": "large enough numbers\nof samples, the mean does trend towards a Gaussian. But it's even a stronger\nstatement, a stronger",
    "start": "1373400",
    "end": "1381830"
  },
  {
    "text": "relationship, if the underlying\npopulation is itself normal. So let's say we start with an\nunderlying random variable,",
    "start": "1381830",
    "end": "1389240"
  },
  {
    "text": "an underlying\nprocess x, that has some mean and some variance.",
    "start": "1389240",
    "end": "1394640"
  },
  {
    "text": "Now if I take samples of size 1\nand plot out the distribution,",
    "start": "1394640",
    "end": "1400160"
  },
  {
    "text": "what do you think it looks like? AUDIENCE: [INAUDIBLE] PROFESSOR: Yeah. I'm just repeating.",
    "start": "1400160",
    "end": "1405560"
  },
  {
    "text": "I'm replicating my underlying\ndistribution, right?",
    "start": "1405560",
    "end": "1410920"
  },
  {
    "text": "So part of the special\ncase of a sample of size 1, if I do that long enough, I\nbuild up the same distribution.",
    "start": "1410920",
    "end": "1419080"
  },
  {
    "text": "But now, if I take larger\nnumbers of samples, even a little bit\nwith n equals 2,",
    "start": "1419080",
    "end": "1425414"
  },
  {
    "text": "again, we get that\neffect that we saw with the SticiGui of the\nnarrowing of the distribution,",
    "start": "1425415",
    "end": "1431530"
  },
  {
    "text": "PDF associated with the x bar. And in particular, the PDF or\nthe Probability Distribution",
    "start": "1431530",
    "end": "1442720"
  },
  {
    "text": "Function associated\nwith x bar is exactly normal with the same mean--",
    "start": "1442720",
    "end": "1449050"
  },
  {
    "text": "it's unbiased-- and\nwith reduced variance. So the variance\ngoes as 1 over n.",
    "start": "1449050",
    "end": "1455830"
  },
  {
    "text": "So we start with the\npopulation distribution here, and we end up with a\nsample mean distribution",
    "start": "1455830",
    "end": "1463010"
  },
  {
    "text": "that is a different PDF. Everybody clear on this?",
    "start": "1463010",
    "end": "1468480"
  },
  {
    "text": "So key points--\nstatistic itself is the random variable has its\nown probability distribution",
    "start": "1468480",
    "end": "1474940"
  },
  {
    "text": "function. Now what we want to do is reason\nabout the underlying population",
    "start": "1474940",
    "end": "1481460"
  },
  {
    "text": "based on those\nobserved statistics. Somebody's cell\nphone is going crazy.",
    "start": "1481460",
    "end": "1487810"
  },
  {
    "text": "Not mine. ",
    "start": "1487810",
    "end": "1493187"
  },
  {
    "text": "Everybody hear that click? Can you even hear that\nclick in Singapore? Yeah? All right.",
    "start": "1493187",
    "end": "1498659"
  },
  {
    "text": " Hopefully that will\ngo away in a second.",
    "start": "1498660",
    "end": "1504040"
  },
  {
    "start": "1504040",
    "end": "1509080"
  },
  {
    "text": "So once we know the sampling\ndistribution, say, for x bar, now we can argue about the\nprobabilities associated",
    "start": "1509080",
    "end": "1516910"
  },
  {
    "text": "with observing particular\nvalues of x bar. We can make observations\nor arguments",
    "start": "1516910",
    "end": "1523420"
  },
  {
    "text": "about how much probability's out\nin the tails of these things. And then we can invert\nbackwards and reason",
    "start": "1523420",
    "end": "1529420"
  },
  {
    "text": "about the actual\npopulation mean. ",
    "start": "1529420",
    "end": "1534640"
  },
  {
    "text": "And again, we're after\nnot only the point estimates, our best guess,\nbut also interval estimates--",
    "start": "1534640",
    "end": "1541570"
  },
  {
    "text": "confidence intervals where\nwe think the actual value is going to lie.",
    "start": "1541570",
    "end": "1547299"
  },
  {
    "text": "And these are critically\ndependent on probability calculations of the\nsampling distribution.",
    "start": "1547300",
    "end": "1556010"
  },
  {
    "text": "So here's an example. So suppose that we start\nout with some assumptions.",
    "start": "1556010",
    "end": "1562679"
  },
  {
    "text": "We start out with some a priori\nbeliefs about the distribution",
    "start": "1562680",
    "end": "1568940"
  },
  {
    "text": "of some parameter. In particular, we're interested\nin the thickness of some part.",
    "start": "1568940",
    "end": "1575220"
  },
  {
    "text": "We don't know the mean of it. But based on maybe lots and\nlots of historical data, we do believe we do\nknow a couple of things.",
    "start": "1575220",
    "end": "1584940"
  },
  {
    "text": "We know its variance. The standard deviation was 10. So let's just assume that we\nknow the standard deviation.",
    "start": "1584940",
    "end": "1592782"
  },
  {
    "text": "And we also know--\nthe second thing is that the thickness of these\nparts is normally distributed.",
    "start": "1592782",
    "end": "1598410"
  },
  {
    "text": "Those are our\nstarting assumptions. our a priori assumptions. Now what we do is we go, and we\ndraw 50 different random parts",
    "start": "1598410",
    "end": "1606930"
  },
  {
    "text": "with the IID assumption. And we calculate the average\nthickness from those.",
    "start": "1606930",
    "end": "1615210"
  },
  {
    "text": "And I'll tell you,\nof those n equals 50 samples, the\nactual sample mean",
    "start": "1615210",
    "end": "1620549"
  },
  {
    "text": "that comes out from that one\nsample of size 50 is 113.5.",
    "start": "1620550",
    "end": "1626490"
  },
  {
    "text": "There you go. You're blessed with\nthat piece of data. Now the first question here,\nbased on what we've seen,",
    "start": "1626490",
    "end": "1633070"
  },
  {
    "text": "is what is the distribution\nof the mean of the thickness? What is the PDF\nassociated with t bar?",
    "start": "1633070",
    "end": "1639610"
  },
  {
    "text": "Everybody should know this. What's t bar distributed as? ",
    "start": "1639610",
    "end": "1649737"
  },
  {
    "text": "AUDIENCE: It's normal. PROFESSOR: It's normal, right. AUDIENCE: Centered\naround the mean. PROFESSOR: Centered\naround the mean, so it",
    "start": "1649738",
    "end": "1655810"
  },
  {
    "text": "would have the same mu unknown. And what would its variance be? AUDIENCE: 2. AUDIENCE: 2.",
    "start": "1655810",
    "end": "1661840"
  },
  {
    "text": "PROFESSOR: 2, very good. So it has the same mean, and\nthe variance scales as 1 over n.",
    "start": "1661840",
    "end": "1670630"
  },
  {
    "text": "So we had 50 samples, so\nthe variance goes down",
    "start": "1670630",
    "end": "1675860"
  },
  {
    "text": "by that factor. One quick notation\npoint here is when",
    "start": "1675860",
    "end": "1684530"
  },
  {
    "text": "we use this notation of normal\nwith mu and sigma squared,",
    "start": "1684530",
    "end": "1692530"
  },
  {
    "text": "I try to be very consistent and\nput the mean and the variance in there.",
    "start": "1692530",
    "end": "1697639"
  },
  {
    "text": "You will sometimes\nfind different texts and different\nwriters or whatever putting the mean and\nthe standard deviation.",
    "start": "1697640",
    "end": "1705230"
  },
  {
    "text": "So you always want to confirm\nthat, because one's a square, and one's the square\nroot of the other.",
    "start": "1705230",
    "end": "1711410"
  },
  {
    "text": "So be a little bit careful-- a little bit careful on that. I try to be consistent and\nhave that be the variance.",
    "start": "1711410",
    "end": "1723039"
  },
  {
    "text": "So that was a first\neasy question. We know that based\non sampling theory. We know the distribution\nfunction for the sample mean.",
    "start": "1723040",
    "end": "1731853"
  },
  {
    "text": "Now the key question\nis, how do we use that to reason about\nthe actual population mean?",
    "start": "1731853",
    "end": "1737960"
  },
  {
    "text": "Well, it's really easy\nalready-- the best guess. But the more subtle question\nthat we've been talking about",
    "start": "1737960",
    "end": "1743660"
  },
  {
    "text": "is, where do we think the\ntrue mean of the population lies based on this\none observation?",
    "start": "1743660",
    "end": "1752309"
  },
  {
    "text": "What range do we think\nthe true mean has with some degree of confidence?",
    "start": "1752310",
    "end": "1759330"
  },
  {
    "text": "Do you think it's plus or\nminus 2 around that mean? Do you think it's plus or\nminus 20 around that mean?",
    "start": "1759330",
    "end": "1765630"
  },
  {
    "text": "If I were to ask you to bet your\nlife on what the true mean is,",
    "start": "1765630",
    "end": "1772200"
  },
  {
    "text": "you would want to be able to say\nwith some degree of confidence, it's actually within\nthis amount of distance.",
    "start": "1772200",
    "end": "1778590"
  },
  {
    "text": " I have to say one more\nthing, because if I",
    "start": "1778590",
    "end": "1783640"
  },
  {
    "text": "said it's within some\namount of distance of that, well, with non-zero\nprobability, that thickness",
    "start": "1783640",
    "end": "1790360"
  },
  {
    "text": "could take on values all the\nway from plus infinity, if it's truly normally distributed,\nall the way to not quite",
    "start": "1790360",
    "end": "1800160"
  },
  {
    "text": "negative infinity, because\nthis is a thickness to 0. So it's still an\napproximate model.",
    "start": "1800160",
    "end": "1805960"
  },
  {
    "text": "So if I just asked\nyou, bet your life. Tell me where you\nthink the true mean is,",
    "start": "1805960",
    "end": "1811360"
  },
  {
    "text": "if you wanted 100% chance of\nsaving your life, you'd say, it could be anything.",
    "start": "1811360",
    "end": "1816680"
  },
  {
    "text": "So I have to give\nyou, when we're talking about confidence\nintervals, another piece of bounding information.",
    "start": "1816680",
    "end": "1822840"
  },
  {
    "text": "I want the range. How far away from that one\nobservation of the mean",
    "start": "1822840",
    "end": "1828010"
  },
  {
    "text": "do I need to be with\nsome probability? 95% confidence or\n95% of the time,",
    "start": "1828010",
    "end": "1836820"
  },
  {
    "text": "where do we think the\ntrue mean would lie? What that means is if I were\nto go and calculate another 50",
    "start": "1836820",
    "end": "1843930"
  },
  {
    "text": "samples and calculate\nthe mean, again, we have that distribution. And what we're looking for\nis that 95% central region",
    "start": "1843930",
    "end": "1853440"
  },
  {
    "text": "of the PDF associated\nwith x bar, which is where 95% of the time, the\nmean is actually going to lie.",
    "start": "1853440",
    "end": "1862700"
  },
  {
    "text": "So that gets us pictorially\nand formulaically here",
    "start": "1862700",
    "end": "1868639"
  },
  {
    "text": "to this notion of the\nconfidence interval and how we actually go\nabout calculating that.",
    "start": "1868640",
    "end": "1873919"
  },
  {
    "text": "What we're asking-- what\nwe've got in this situation is the variance is\nknown, so I'm not",
    "start": "1873920",
    "end": "1881120"
  },
  {
    "text": "trying to estimate the variance. I'm just trying to\nreason about the mean.",
    "start": "1881120",
    "end": "1886590"
  },
  {
    "text": "And I want to estimate it to\nsome percent, some confidence interval.",
    "start": "1886590",
    "end": "1892500"
  },
  {
    "text": "You always have this\nchance of being wrong when you talk\nconfidence intervals.",
    "start": "1892500",
    "end": "1898860"
  },
  {
    "text": "You've got some\nalpha probability that the true meaning is\neven further away than you think in your interval.",
    "start": "1898860",
    "end": "1905340"
  },
  {
    "text": "But you're trying to\nquantify that and bound that. So we typically talk about,\nsay, an alpha of 5% or maybe 1%",
    "start": "1905340",
    "end": "1912720"
  },
  {
    "text": "probability of being\noutside of your interval.",
    "start": "1912720",
    "end": "1918270"
  },
  {
    "text": "So there's this\nalpha probability of error associated with\nany confidence interval.",
    "start": "1918270",
    "end": "1926820"
  },
  {
    "text": "So that's that second piece\nof data I had to give you. The first is we want to know\nthis range-- what the size is.",
    "start": "1926820",
    "end": "1933350"
  },
  {
    "text": "So the way this works is\nwe're wanting to know, based on our calculated\nx bar from our sample",
    "start": "1933350",
    "end": "1942110"
  },
  {
    "text": "of size n, where the\ntrue mean actually lies.",
    "start": "1942110",
    "end": "1948820"
  },
  {
    "text": "So we know what\nwe're doing is saying that the true mean, mu, is\ngoing to be bounded on the left",
    "start": "1948820",
    "end": "1956710"
  },
  {
    "text": "by the x bar, but then\ngoing some portion",
    "start": "1956710",
    "end": "1962590"
  },
  {
    "text": "of the distribution to\nthe left and some portion of the distribution to the right\nuntil we get the 1 minus alpha.",
    "start": "1962590",
    "end": "1972040"
  },
  {
    "text": "So this area in here is the\n1 minus alpha-- the 95%, say,",
    "start": "1972040",
    "end": "1977340"
  },
  {
    "text": "central component of\nthat distribution. And then we're evenly spreading\nthe error part, the alpha,",
    "start": "1977340",
    "end": "1984750"
  },
  {
    "text": "into 2 alpha over\n2's on each side, saying I've got for a\n95% confidence interval,",
    "start": "1984750",
    "end": "1990870"
  },
  {
    "text": "a 2.5% chance that the true\nmean is a little bit further off to the left and a 2.5% chance\nthat it's a little further",
    "start": "1990870",
    "end": "1998070"
  },
  {
    "text": "off to the right. I guess in this picture here\nI'm doing an 80% confidence interval with a total alpha\nerror risk, error probability,",
    "start": "1998070",
    "end": "2008240"
  },
  {
    "text": "of 0.2. And so the question\nthen becomes,",
    "start": "2008240",
    "end": "2013620"
  },
  {
    "text": "how far do I have to go out? And we know that from the\nbasic probability manipulations",
    "start": "2013620",
    "end": "2019350"
  },
  {
    "text": "from a normal\ndistribution you guys have been dealing with already.",
    "start": "2019350",
    "end": "2024389"
  },
  {
    "text": "The whole question is, how\nmany unit standard deviations",
    "start": "2024390",
    "end": "2031190"
  },
  {
    "text": "of a unit normal\ndo I have to go? How many z's out do I have to\ngo until I have exactly alpha",
    "start": "2031190",
    "end": "2038419"
  },
  {
    "text": "over 2 out here in the tail? So for example,\nwe might know what",
    "start": "2038420",
    "end": "2044980"
  },
  {
    "text": "this is going to do\nis I've got to go out 1.28 standard\ndeviations to the left",
    "start": "2044980",
    "end": "2053350"
  },
  {
    "text": "in order to be able to\nhave just that alpha over 2",
    "start": "2053350",
    "end": "2058523"
  },
  {
    "text": "to the left of that tail,\nand similarly to the right. Now, notice that we're\nalso unnormalizing.",
    "start": "2058524",
    "end": "2070460"
  },
  {
    "text": "The z is the normal-- how many z's you get to,\nout of the unit Gaussian,",
    "start": "2070460",
    "end": "2076070"
  },
  {
    "text": "the probability\nout in the tails. But what we wanted to do is\nreason about the location",
    "start": "2076070",
    "end": "2081110"
  },
  {
    "text": "of the true population. We want to know the\ntrue population mean.",
    "start": "2081110",
    "end": "2086579"
  },
  {
    "text": "And so we have to do a little\nbit of unnormalization and say,",
    "start": "2086580",
    "end": "2092989"
  },
  {
    "text": "z alpha gave me the\nnumber of unit normals. Now, in terms of my\nactual population variance",
    "start": "2092989",
    "end": "2100700"
  },
  {
    "text": "or population\nstandard deviation, what does that correspond to? And this is where the sample\nsize also comes into play.",
    "start": "2100700",
    "end": "2111100"
  },
  {
    "text": "We were reasoning about\nthe distribution associated with a x bar.",
    "start": "2111100",
    "end": "2117210"
  },
  {
    "text": "And the x bar is scaled. It shrunk by that\nsquare root of n in terms of the\nstandard deviation.",
    "start": "2117210",
    "end": "2124300"
  },
  {
    "text": "So when I expand it back\nout, I'm counting number of-- first off, together, this is\nnumber of standard deviations",
    "start": "2124300",
    "end": "2134910"
  },
  {
    "text": "in my x bar. And then when I\nexpand that further",
    "start": "2134910",
    "end": "2142140"
  },
  {
    "text": "out to the number of standard\ndeviations in my population, I have to divide back\nout by that root n.",
    "start": "2142140",
    "end": "2148710"
  },
  {
    "text": " So what we've got is\nthe rationale for being",
    "start": "2148710",
    "end": "2157780"
  },
  {
    "text": "able to use the PDF associated\nwith x bar calculate, probabilities off\nof the details,",
    "start": "2157780",
    "end": "2163660"
  },
  {
    "text": "and get finally to this nice-- this is my fast way\nto erase everything--",
    "start": "2163660",
    "end": "2172930"
  },
  {
    "text": "get back to my nice distribution\nhere or a nice formula, which you'll see in Montgomery, you'll\nsee in all of the textbooks.",
    "start": "2172930",
    "end": "2181700"
  },
  {
    "text": "It's a wonderful note to have\non your one page set of notes",
    "start": "2181700",
    "end": "2188270"
  },
  {
    "text": "or cheat sheet\nfor taking quizzes in this class and elsewhere. This is the interval, the\nconfidence interval formula,",
    "start": "2188270",
    "end": "2195530"
  },
  {
    "text": "for the location of\nthe true mean when the variance was known. ",
    "start": "2195530",
    "end": "2204370"
  },
  {
    "text": "So any questions on that? We actually want to\nreturn to our example",
    "start": "2204370",
    "end": "2211030"
  },
  {
    "text": "and see what numbers pop\nout because I want to know-- we knew x bar was 113.5.",
    "start": "2211030",
    "end": "2217420"
  },
  {
    "text": "But I actually want to know,\nwhat is the 95% confidence interval for that?",
    "start": "2217420",
    "end": "2222950"
  },
  {
    "text": "And so we can simply go\nback to our second question. Use the fact that we had--",
    "start": "2222950",
    "end": "2228800"
  },
  {
    "text": "you guys told me what the\ndistribution was of t bar was our unknown mu.",
    "start": "2228800",
    "end": "2235990"
  },
  {
    "text": "And the variance was\nscaled, 100 over 50. So now for a 95%\nconfidence interval,",
    "start": "2235990",
    "end": "2244170"
  },
  {
    "text": "what is the true mean? So I've pictured it here.",
    "start": "2244170",
    "end": "2250079"
  },
  {
    "text": "And what we're\nsaying is we want-- we've got this red\ncurve which, again,",
    "start": "2250080",
    "end": "2256800"
  },
  {
    "text": "goes with this PDF\nassociated with t bar.",
    "start": "2256800",
    "end": "2262330"
  },
  {
    "text": "And I want the plus/minus\nz alpha over 2, the alpha being 0.05.",
    "start": "2262330",
    "end": "2268569"
  },
  {
    "text": "That's my probability\nof being wrong to get to a 0.95 confidence interval.",
    "start": "2268570",
    "end": "2274370"
  },
  {
    "text": "So how many z's do I have to go\nout to have 95% in the center?",
    "start": "2274370",
    "end": "2281400"
  },
  {
    "text": "We actually showed\nsome examples. If you remember,\nlast time we looked at plus/minus 1 sigma,\nplus/minus 2 sigma,",
    "start": "2281400",
    "end": "2288480"
  },
  {
    "text": "plus/minus 3 sigma\nfor a Gaussian. And it's actually a very\nclose approximation.",
    "start": "2288480",
    "end": "2294270"
  },
  {
    "text": "That plus/minus 2 sigma\nis 95% of a distribution. That's a good rule\nof thumb to remember.",
    "start": "2294270",
    "end": "2300930"
  },
  {
    "text": "It's actually 1.96, not quite 2. But about plus/minus\n2 sigma has 95%.",
    "start": "2300930",
    "end": "2309660"
  },
  {
    "text": "So you'll often see 95%\nconfidence intervals",
    "start": "2309660",
    "end": "2314670"
  },
  {
    "text": "graphically shown. So we need about 1.96\nstandard deviations.",
    "start": "2314670",
    "end": "2320380"
  },
  {
    "text": "Now that translates to\na confidence interval",
    "start": "2320380",
    "end": "2326299"
  },
  {
    "text": "that tells us, as\na function of n, the distribution for where\nwe think the true population",
    "start": "2326300",
    "end": "2332990"
  },
  {
    "text": "is, based on the sample\nsize that we had. The compression that we\ngot because of sampling",
    "start": "2332990",
    "end": "2339860"
  },
  {
    "text": "gets us that tighter\nstandard deviation. And I've got a symmetric\nplus/minus 2.77",
    "start": "2339860",
    "end": "2348079"
  },
  {
    "text": "for my 95% confidence interval. Now, notice that all\nyou had to do here",
    "start": "2348080",
    "end": "2353330"
  },
  {
    "text": "was be told what the\nactual calculated t bar was and what the\nunderlying variance was",
    "start": "2353330",
    "end": "2360450"
  },
  {
    "text": "and the size of your sample. I didn't even have\nto actually give you a list of all those\nvalues, right?",
    "start": "2360450",
    "end": "2365619"
  },
  {
    "text": " But I did have to tell\nyou the sample size.",
    "start": "2365620",
    "end": "2372510"
  },
  {
    "text": "If sample size changed, that\nPDF would narrow or widen,",
    "start": "2372510",
    "end": "2377780"
  },
  {
    "text": "and your confidence interval\nwould narrow or widen, right?",
    "start": "2377780",
    "end": "2383450"
  },
  {
    "text": "So any questions to\nwhere we are now? It's all seeming pretty clear?",
    "start": "2383450",
    "end": "2388790"
  },
  {
    "text": " So this is the\nrelatively easy part",
    "start": "2388790",
    "end": "2395830"
  },
  {
    "text": "because it's dealing with\nnormal distributions. This notion of sampling\nis a little bit subtle",
    "start": "2395830",
    "end": "2400990"
  },
  {
    "text": "because there is\na different PDF, and you got to know how that\nscales with the sample size. Now I'm going to throw a\nfew different curves at you,",
    "start": "2400990",
    "end": "2410670"
  },
  {
    "text": "the different curves being\ndifferent probability distribution functions\nthan normal distributions.",
    "start": "2410670",
    "end": "2417180"
  },
  {
    "text": "And I'm going to briefly\ncover three of them, and all three of them\nare ones that we actually",
    "start": "2417180",
    "end": "2424320"
  },
  {
    "text": "will be using in\nmultiple scenarios in statistical analysis\nand statistical techniques",
    "start": "2424320",
    "end": "2434180"
  },
  {
    "text": "and tools that we're using. The first one is a\nrelatively easy step,",
    "start": "2434180",
    "end": "2440270"
  },
  {
    "text": "and that's to look at the\nstudent t distribution. I'll come back to this. But basically, if we go back\nto the example I gave you.",
    "start": "2440270",
    "end": "2447800"
  },
  {
    "text": "I said, we assumed we knew,\nbased on, I don't know, lots of past history what\nthe underlying variance was",
    "start": "2447800",
    "end": "2455360"
  },
  {
    "text": "on the thickness of our parts. What if you don't know that? What if you have to\nestimate that, too?",
    "start": "2455360",
    "end": "2462467"
  },
  {
    "text": "Well, if you had to\nestimate it, you'd probably use sample standard\ndeviation, that formula, and come up with an estimate.",
    "start": "2462467",
    "end": "2468700"
  },
  {
    "text": "It turns out when you do that,\nthat additional uncertainty on what the\nunderlying variance is",
    "start": "2468700",
    "end": "2475329"
  },
  {
    "text": "means that the right\ndistribution for arguing about the mean when you didn't\nknow the underlying variance",
    "start": "2475330",
    "end": "2481810"
  },
  {
    "text": "is no longer a\nnormal distribution. It's actually a t-distribution,\nand we'll talk about that.",
    "start": "2481810",
    "end": "2487470"
  },
  {
    "text": "It's a slightly different--\nit's very close to or looks qualitatively close\nto a normal distribution,",
    "start": "2487470",
    "end": "2495470"
  },
  {
    "text": "but we do want to cover that. And then more have to\ndo with not the mean,",
    "start": "2495470",
    "end": "2502539"
  },
  {
    "text": "but arguing about the variance. If I calculate sample\nvariance from a distribution,",
    "start": "2502540",
    "end": "2508900"
  },
  {
    "text": "I calculate s squared using the\nformula for a sample of size",
    "start": "2508900",
    "end": "2515109"
  },
  {
    "text": "50, I get a number. I do that lots\nand lots of times. I trace out a PDF.",
    "start": "2515110",
    "end": "2520900"
  },
  {
    "text": "The PDF associated\nwith the values of sample variance\ncalculated from that sample",
    "start": "2520900",
    "end": "2528130"
  },
  {
    "text": "is a chi-squared distribution.  So we'll talk about what\nthat shape looks like.",
    "start": "2528130",
    "end": "2536260"
  },
  {
    "text": "And then we've got a\nvariance that we've calculated from a sample.",
    "start": "2536260",
    "end": "2541870"
  },
  {
    "text": "And a very strange distribution\nis the F distribution, which is the distribution\nof the ratio of two normally",
    "start": "2541870",
    "end": "2550360"
  },
  {
    "text": "distributed variances or two\nvariances drawn from normally distributed sample data.",
    "start": "2550360",
    "end": "2557339"
  },
  {
    "text": "Good heavens. Why would you ever\nbe calculating ratios of variances? What a weird distribution.",
    "start": "2557340",
    "end": "2565300"
  },
  {
    "text": "Why would you ever calculate\nratios of variances? Where might that come up?",
    "start": "2565300",
    "end": "2571090"
  },
  {
    "text": "There's at least a couple\nof cases-- one that's kind of subtle, but one\nthat's pretty obvious.",
    "start": "2571090",
    "end": "2576989"
  },
  {
    "text": "AUDIENCE: I think\nit's you're thinking about the variation of the\nactual population, which",
    "start": "2576989",
    "end": "2583953"
  },
  {
    "text": "varies from your sample.  PROFESSOR: Certainly,\nthe variance",
    "start": "2583953",
    "end": "2590270"
  },
  {
    "text": "associated with a\nsample of smaller size than your true population.",
    "start": "2590270",
    "end": "2595440"
  },
  {
    "text": "So that's exactly true. That's one important area. The fact of sample size\nentering into spread and things",
    "start": "2595440",
    "end": "2603020"
  },
  {
    "text": "is very important. That actually will come up\nmore in the chi-squared. But I think a second\nvery obvious place is",
    "start": "2603020",
    "end": "2610280"
  },
  {
    "text": "I make a change to a process. And I'm maybe not trying\nto mean center it. I'm trying to get a\nreduced variance process.",
    "start": "2610280",
    "end": "2617390"
  },
  {
    "text": "I want to know, is this\nprocess better or not? Is its variance smaller?",
    "start": "2617390",
    "end": "2622670"
  },
  {
    "text": "So the ratio of\nthose two variances are something I might be\nvery, very interested in.",
    "start": "2622670",
    "end": "2628550"
  },
  {
    "text": "I want to look at\nthose and see, well, I did get a smaller variance. It's half as small.",
    "start": "2628550",
    "end": "2634730"
  },
  {
    "text": "Do I have confidence that\nthe true population variance is really smaller or not? And so that's where\nthe F distribution",
    "start": "2634730",
    "end": "2641180"
  },
  {
    "text": "is going to come into play. So we want to be able\nto manipulate and deal with that one as well.",
    "start": "2641180",
    "end": "2646540"
  },
  {
    "start": "2646540",
    "end": "2651880"
  },
  {
    "text": "Let me do the student\nt-distribution first.",
    "start": "2651880",
    "end": "2658670"
  },
  {
    "text": "Actually, I can't do that. Let me do the chi-squared\ndistribution first. For the formal\ndefinition of the t,",
    "start": "2658670",
    "end": "2664130"
  },
  {
    "text": "I need the chi-squared,\neven though conceptually, it doesn't really matter. So let's talk about the\nchi-squared distribution first.",
    "start": "2664130",
    "end": "2672319"
  },
  {
    "text": "If I start out with truly\nnormally distributed data",
    "start": "2672320",
    "end": "2679580"
  },
  {
    "text": "and unit normal,\nmean 0, variance 1. And now, I take a sum\nof n of these unit",
    "start": "2679580",
    "end": "2690670"
  },
  {
    "text": "normals, each one\nof which is squared. So each x sub i is\nnormally distributed.",
    "start": "2690670",
    "end": "2696410"
  },
  {
    "text": "I do this weird operation\nwhere I take that sample. I square it, I take another\ndraw or another random variable,",
    "start": "2696410",
    "end": "2705170"
  },
  {
    "text": "also from the same distribution,\nsquare that, and then take the sum of n of those squared\nrandom variables to create",
    "start": "2705170",
    "end": "2714020"
  },
  {
    "text": "a new random variable y. y is the sum of squared unit\nnormal random variables.",
    "start": "2714020",
    "end": "2722430"
  },
  {
    "text": "Then I get this\nchi-squared distribution. The distribution of this\nnew random variable y",
    "start": "2722430",
    "end": "2729080"
  },
  {
    "text": "is chi-squared with\nn degrees of freedom. Good heavens, what a\nweird thing to be doing.",
    "start": "2729080",
    "end": "2736625"
  },
  {
    "text": "Why would you be taking\nrandom variables, squaring them, and\ntaking sums of them?",
    "start": "2736625",
    "end": "2742270"
  },
  {
    "text": "Well, think back to the formula. Let's see if I can do this.",
    "start": "2742270",
    "end": "2747420"
  },
  {
    "text": "What page is that? Anybody got it there? 8?",
    "start": "2747420",
    "end": "2752599"
  },
  {
    "text": "There we go, page 5. Look back at this formula for\nsample standard deviation.",
    "start": "2752600",
    "end": "2761670"
  },
  {
    "text": " First off, I'm subtracting\nthe mean off of some sample.",
    "start": "2761670",
    "end": "2768660"
  },
  {
    "text": "So now I've got a\n0 mean variable. Now I'm taking squares of them.",
    "start": "2768660",
    "end": "2775430"
  },
  {
    "text": "Well, that sounds kind of\nlike this squaring operation. And then I'm taking\na big sum of them.",
    "start": "2775430",
    "end": "2781829"
  },
  {
    "text": "That sounds a lot like\nthis operation I was just describing for chi-squared. So this creation of a new random\nvariable, this F squared here,",
    "start": "2781830",
    "end": "2791850"
  },
  {
    "text": "is very closely related to--",
    "start": "2791850",
    "end": "2797070"
  },
  {
    "text": "that didn't work. There we go-- very\nclosely related to the definition\nof chi-squared.",
    "start": "2797070",
    "end": "2805310"
  },
  {
    "text": "Now the chi-squared,\nthe PDF associated with the chi-squared,\nlooks kind of funky.",
    "start": "2805310",
    "end": "2811450"
  },
  {
    "text": "It's clearly not normally\ndistributed, right? It's kind of skewed. Notice it's got a\nlong tail out here",
    "start": "2811450",
    "end": "2821240"
  },
  {
    "text": "to the right for large values. Because it's a sum of squared\nvalues, it can't be negative.",
    "start": "2821240",
    "end": "2828869"
  },
  {
    "text": "So it's truncated. There's nothing-- can't\nbe smaller than 0.",
    "start": "2828870",
    "end": "2834190"
  },
  {
    "text": "Another really weird thing is\nthat the maximal probability value is not equal to the\nmean of the distribution.",
    "start": "2834190",
    "end": "2846680"
  },
  {
    "text": "That's kind of interesting. And there's another\nreally interesting fact that is truly useful\nand occasionally",
    "start": "2846680",
    "end": "2853400"
  },
  {
    "text": "comes up on problem sets\nand that sort of thing. The mean, the expected value\nof the chi-squared distribution",
    "start": "2853400",
    "end": "2859940"
  },
  {
    "text": "with degrees of freedom n, is n. So as I have larger\nnumbers of variables,",
    "start": "2859940",
    "end": "2868180"
  },
  {
    "text": "the sum of that larger\nnumber keeps getting bigger.",
    "start": "2868180",
    "end": "2873849"
  },
  {
    "text": "So that makes sense\nwhen you think about it. So the point here\nis when we actually",
    "start": "2873850",
    "end": "2881590"
  },
  {
    "text": "do that calculation of a sample\nstandard or a sample variance",
    "start": "2881590",
    "end": "2888490"
  },
  {
    "text": "or a sample standard\ndeviation, the PDF associated with that\nis actually related",
    "start": "2888490",
    "end": "2895060"
  },
  {
    "text": "to this chi-squared\ndistribution. Now there were some\nother constants in there. They're scaling factors.",
    "start": "2895060",
    "end": "2901280"
  },
  {
    "text": "So for example, we did\na mean shift x bar, but we didn't normalize\nto the true variance,",
    "start": "2901280",
    "end": "2906400"
  },
  {
    "text": "because we didn't know it. So there is this relationship\nor a scaling factor",
    "start": "2906400",
    "end": "2911500"
  },
  {
    "text": "before we get to the\nchi-squared distribution. We also had this other n minus\n1 factor back on the calculation",
    "start": "2911500",
    "end": "2920140"
  },
  {
    "text": "of the sample-- sample standard or\nsample variance. So we have to do a little bit\nof moving variables around",
    "start": "2920140",
    "end": "2928869"
  },
  {
    "text": "to get to a chi-squared\ndistribution. Another important\npoint is that the--",
    "start": "2928870",
    "end": "2936599"
  },
  {
    "text": "let me clean up some of this-- is that the sample\nvariance is actually",
    "start": "2936600",
    "end": "2943980"
  },
  {
    "text": "related to a chi-squared with\nn minus 1 degrees of freedom.",
    "start": "2943980",
    "end": "2949722"
  },
  {
    "text": "And I really don't want to\ngo into a whole discussion of degrees of freedom because\nit's a little bit subtle.",
    "start": "2949722",
    "end": "2956260"
  },
  {
    "text": "But this reminds\nme of another point that I didn't make\nback on slide 8. ",
    "start": "2956260",
    "end": "2964390"
  },
  {
    "text": "Get me to 8, please. There we go. Oops, not 48, 8. Oh, it wasn't 8.",
    "start": "2964390",
    "end": "2970660"
  },
  {
    "text": "Where was it? 4, 5. There we go. Back here on this, notice that\nwhen we calculate sample mean,",
    "start": "2970660",
    "end": "2980500"
  },
  {
    "text": "we used 1 over n. But when we calculate\nsample variance, we always use 1 over n minus 1.",
    "start": "2980500",
    "end": "2987770"
  },
  {
    "text": "Why do we do that? ",
    "start": "2987770",
    "end": "2993080"
  },
  {
    "text": "It turns out that if you need\nor want an unbiased estimator",
    "start": "2993080",
    "end": "3000170"
  },
  {
    "text": "for a sample variance, you need\nto divide by 1 over n minus 1 or divide by n minus 1, not n.",
    "start": "3000170",
    "end": "3008309"
  },
  {
    "text": "Now, as n gets very\nlarge, the difference doesn't really matter. But you can go through\nsome statistical proofs",
    "start": "3008310",
    "end": "3015890"
  },
  {
    "text": "to show that the best unbiased\nestimator needs that n minus 1.",
    "start": "3015890",
    "end": "3021799"
  },
  {
    "text": "Now the other thing that's\ngoing on in this formula is we were subtracting\noff the mean.",
    "start": "3021800",
    "end": "3029119"
  },
  {
    "text": "And in this case, we were\nalso estimating the mean. So we're using up\nessentially one degree",
    "start": "3029120",
    "end": "3035420"
  },
  {
    "text": "of freedom out of our data\nto calculate the sample mean,",
    "start": "3035420",
    "end": "3041660"
  },
  {
    "text": "leaving us only n minus\n1 degrees of freedom really in the remaining data to\nallow variance around the mean.",
    "start": "3041660",
    "end": "3051990"
  },
  {
    "text": "So I'm not going to go\ninto much more detail, other than to simply say the\nfact is, when we're calculating",
    "start": "3051990",
    "end": "3061400"
  },
  {
    "text": "sample standard deviation,\nwe're actually calculating two random variables or two\nstatistics, x bar and variance.",
    "start": "3061400",
    "end": "3070520"
  },
  {
    "text": "And so you would\nneed-- you essentially don't have complete independence\nbetween those two things.",
    "start": "3070520",
    "end": "3079190"
  },
  {
    "text": "You use up one degree of\nfreedom for one of those. Let's use this.",
    "start": "3079190",
    "end": "3086109"
  },
  {
    "text": "Before we use this, just to\ngive you a qualitative feel, here's-- again, plotted a few different\nchi-squared distributions.",
    "start": "3086110",
    "end": "3095410"
  },
  {
    "text": "When n is very small,\nit becomes very skewed. It's quite interesting.",
    "start": "3095410",
    "end": "3100960"
  },
  {
    "text": "Again, the mean you can see\nfor n equals 3 here is 3.",
    "start": "3100960",
    "end": "3107720"
  },
  {
    "text": "It's this blue curve. And as n increases,\nthe distribution",
    "start": "3107720",
    "end": "3113109"
  },
  {
    "text": "shifts to the right. The mean shift to the right. But it also spreads out,\nwhich kind of makes sense. If I've got more and\nmore random variables,",
    "start": "3113110",
    "end": "3119859"
  },
  {
    "text": "and I'm looking at the\nvariance and estimating that sum of random\nvariables, its spread",
    "start": "3119860",
    "end": "3127450"
  },
  {
    "text": "is going to get large. And another observation is that\nas n gets larger and larger,",
    "start": "3127450",
    "end": "3137780"
  },
  {
    "text": "this also trends towards\na normal distribution, which for very large n\ncan be a useful fact.",
    "start": "3137780",
    "end": "3146010"
  },
  {
    "text": "I want to actually\ngo in and use--  not that one-- use this\nchi-squared distribution",
    "start": "3146010",
    "end": "3157450"
  },
  {
    "text": "to ask another question\non that thickness example.",
    "start": "3157450",
    "end": "3163750"
  },
  {
    "text": "I'd actually want\nto know, what's the best guess for the variance\nof my thickness of parts?",
    "start": "3163750",
    "end": "3171190"
  },
  {
    "text": "And better than that, what's a\nconfidence interval for where I think the true variance\nlies, based on just this one",
    "start": "3171190",
    "end": "3177250"
  },
  {
    "text": "number for sample variance,\nbased on my sample of size n equals 50.",
    "start": "3177250",
    "end": "3182280"
  },
  {
    "text": "And this is where we do the same\nkind of a formula for the range",
    "start": "3182280",
    "end": "3189390"
  },
  {
    "text": "where we think the\ntrue variance lies, based on our observation from\none sample of sample standard",
    "start": "3189390",
    "end": "3199350"
  },
  {
    "text": "deviation. And this is using\nthat relationship between the chi-squared\ndistribution and F",
    "start": "3199350",
    "end": "3207300"
  },
  {
    "text": "squared and the true\nunderlying variance. So if you go back to\none of those formulas, what I did was took--",
    "start": "3207300",
    "end": "3214890"
  },
  {
    "text": "sigma squared was\nlying out here. I moved it up here and divided\nthe chi-squared down here.",
    "start": "3214890",
    "end": "3220390"
  },
  {
    "text": "So this is essentially\nright in here that equivalence that we said\nbefore about how F squared was",
    "start": "3220390",
    "end": "3227070"
  },
  {
    "text": "distributed as a\nchi-squared with n minus 1 degrees of freedom.",
    "start": "3227070",
    "end": "3232230"
  },
  {
    "text": " So what we've got is a bound--",
    "start": "3232230",
    "end": "3239599"
  },
  {
    "text": "let me get rid of\nall this gook-- a bound, upper and lower\nbound, on where we think,",
    "start": "3239600",
    "end": "3246150"
  },
  {
    "text": "again, the true variance is,\nbased on our calculated F squareds. And what we're doing again is\nputting some alpha probability",
    "start": "3246150",
    "end": "3254849"
  },
  {
    "text": "of being wrong in\neach of the tails. I want the central part. I want the 95% central\npart of where we",
    "start": "3254850",
    "end": "3262349"
  },
  {
    "text": "think the true variance lies. Now an interesting point here\nis chi-squared is asymmetric.",
    "start": "3262350",
    "end": "3273750"
  },
  {
    "text": "So if you ever see somebody\ngoing off and writing, I think the true\nvariance is equal to F",
    "start": "3273750",
    "end": "3280200"
  },
  {
    "text": "squared plus or minus\n14.2, that should",
    "start": "3280200",
    "end": "3285240"
  },
  {
    "text": "be a great, big red flag. ",
    "start": "3285240",
    "end": "3291360"
  },
  {
    "text": "It's somebody who doesn't know\nwhat they're talking about. Well, maybe they have\na huge sample size, and they're appealing to\na normal distribution.",
    "start": "3291360",
    "end": "3298650"
  },
  {
    "text": "But what they're probably doing\nhere is something very wrong.",
    "start": "3298650",
    "end": "3304520"
  },
  {
    "text": "Because the chi-squared\ndistribution is not symmetric, I have my best point\nestimate of F squared.",
    "start": "3304520",
    "end": "3311340"
  },
  {
    "text": "And then I'm going to\ngo a different distance to the left and a different\ndistance to the right.",
    "start": "3311340",
    "end": "3317359"
  },
  {
    "text": "So here's, still for\nour same example, the chi-squared distribution\nfor n, a sample size of 50.",
    "start": "3317360",
    "end": "3325369"
  },
  {
    "text": "So this is a chi-squared\nwith 49 degrees of freedom. And again, I want\n2.5% in the left tail",
    "start": "3325370",
    "end": "3332269"
  },
  {
    "text": "and 2.5% in the right tail. And so if I apply that\nformula, and I have to look up",
    "start": "3332270",
    "end": "3338210"
  },
  {
    "text": "chi-squared with 0.025\nand 49 degrees of freedom,",
    "start": "3338210",
    "end": "3344109"
  },
  {
    "text": "and then the chi-squared\nwhere I need to know--",
    "start": "3344110",
    "end": "3349590"
  },
  {
    "text": "I want 97.5, everything,\nleaving except just alpha over 2 out to the right.",
    "start": "3349590",
    "end": "3356940"
  },
  {
    "text": "The s squareds are the\nsame in both cases. My n minus 1 is the same. But because these values, the\nchi-squareds, are not equal--",
    "start": "3356940",
    "end": "3366320"
  },
  {
    "text": "whoops. I guess I got these flipped. Actually, when you\nlook at the tables",
    "start": "3366320",
    "end": "3372080"
  },
  {
    "text": "at the back of Montgomery\nor Mayo and Spanos,",
    "start": "3372080",
    "end": "3377540"
  },
  {
    "text": "be careful on the definition. They often show\nyou a little plot that looks a lot like this.",
    "start": "3377540",
    "end": "3383059"
  },
  {
    "text": "And they shade in what\ntheir percentage points are. And sometimes they go from the\nright, sometimes from the left.",
    "start": "3383060",
    "end": "3391410"
  },
  {
    "text": "But the point was\nwhen you actually look that up, you\nget different values",
    "start": "3391410",
    "end": "3396839"
  },
  {
    "text": "for the left and the right. And when you divide those\nout, you get a range--",
    "start": "3396840",
    "end": "3402620"
  },
  {
    "text": "get that out of the way. You get a range finally for\nwhere your true variance lies.",
    "start": "3402620",
    "end": "3409610"
  },
  {
    "text": "AUDIENCE: So is that through\na [INAUDIBLE] or estimates of variance or from chi-square\ndistribution, or is that--",
    "start": "3409611",
    "end": "3418850"
  },
  {
    "text": "PROFESSOR: The point\nis that all estimates-- well, it's strictly true if I'm\ndrawing from a population that",
    "start": "3418850",
    "end": "3428370"
  },
  {
    "text": "is normally distributed. But an approximation\nis no matter what, any time I'm\ncalculating a variance,",
    "start": "3428370",
    "end": "3438180"
  },
  {
    "text": "the variance tends to be\nchi-squared distributed. So it's always going\nto be these kinds",
    "start": "3438180",
    "end": "3443190"
  },
  {
    "text": "of chi-squared calculations.  So it's not that the\nchi-squared was a special case.",
    "start": "3443190",
    "end": "3450250"
  },
  {
    "text": "It's the PDF that\nyou should always associate it with s squared.",
    "start": "3450250",
    "end": "3456580"
  },
  {
    "text": " And notice here, we had 102.3.",
    "start": "3456580",
    "end": "3465090"
  },
  {
    "text": "That's our best guess. And we had 71.4 and 158.1\nfor the range and variance.",
    "start": "3465090",
    "end": "3473070"
  },
  {
    "start": "3473070",
    "end": "3478507"
  },
  {
    "text": "I always find this a\nlittle bit shocking.  A sample size of 50?",
    "start": "3478507",
    "end": "3484790"
  },
  {
    "text": "I took 50 samples, right? And I had-- my underlying\nvariance, I guess, was 100.",
    "start": "3484790",
    "end": "3496920"
  },
  {
    "text": "But I took a lot of samples. And it always shocks\nme a little bit how big the range is on\nthe estimate of variance",
    "start": "3496920",
    "end": "3504480"
  },
  {
    "text": "coming out of this. Here, my estimate of\nvariance is 102.3.",
    "start": "3504480",
    "end": "3510420"
  },
  {
    "text": "Well, that's at\nleast reassuring, because that's close to the\nexample that I gave here, where a priori, I\nthought it was 100.",
    "start": "3510420",
    "end": "3520780"
  },
  {
    "text": "I just basically\npopped that out. What's shocking is\nI can go down to 71.",
    "start": "3520780",
    "end": "3527140"
  },
  {
    "text": "That's like 30% lower than that,\nor 158, which is 68% higher",
    "start": "3527140",
    "end": "3534880"
  },
  {
    "text": "than my point estimate. And a really important thing\njust to know qualitatively",
    "start": "3534880",
    "end": "3541190"
  },
  {
    "text": "is that estimating a\nmean is pretty easy. And actually, as\nsample size grows,",
    "start": "3541190",
    "end": "3546680"
  },
  {
    "text": "you can get pretty good\ntight estimates of mean. But the estimates of\nvariance are hard.",
    "start": "3546680",
    "end": "3553785"
  },
  {
    "text": "You need a lot of\ndata to estimate that second-order statistic.",
    "start": "3553785",
    "end": "3561650"
  },
  {
    "text": "And so we get big\nspreads in variance. So you've got to be really\ncareful in your reasoning",
    "start": "3561650",
    "end": "3566890"
  },
  {
    "text": "about variances. And that'll bring us back to the\nF-statistic a little bit later. ",
    "start": "3566890",
    "end": "3576150"
  },
  {
    "text": "So let me go back now to\nthe student t-distribution. And it has a formula\nand a formal definition",
    "start": "3576150",
    "end": "3584550"
  },
  {
    "text": "here, which is if I start out\nwith a random variable z, that",
    "start": "3584550",
    "end": "3589560"
  },
  {
    "text": "is the unit normal. And then I divide it by\na random variable that",
    "start": "3589560",
    "end": "3597040"
  },
  {
    "text": "is chi-squared with k degrees\nof freedom, divided by k,",
    "start": "3597040",
    "end": "3602620"
  },
  {
    "text": "I get a new distribution,\na new variable t, that is a t-distribution\nwith k degrees of freedom.",
    "start": "3602620",
    "end": "3611390"
  },
  {
    "text": "And it's the same question. My god, why would you\ndo such a cruel thing to a random variable-- divide\nit by a chi-squared random",
    "start": "3611390",
    "end": "3618410"
  },
  {
    "text": "variable and some constant k? And the answer is\nthat's essentially",
    "start": "3618410",
    "end": "3626400"
  },
  {
    "text": "what we're doing when\nwe are normalizing data",
    "start": "3626400",
    "end": "3633270"
  },
  {
    "text": "like this, when\ninstead of normalizing to the true\nunderlying population",
    "start": "3633270",
    "end": "3640430"
  },
  {
    "text": "variance or the true\nunderlying sample variance, I'm also having to\nestimate not only the mean,",
    "start": "3640430",
    "end": "3649220"
  },
  {
    "text": "but also estimate the\npopulation standard deviation.",
    "start": "3649220",
    "end": "3654460"
  },
  {
    "text": "We already said, what is s? s squared is\nchi-squared distributed. So s is a square root of a\nchi-squared distribution.",
    "start": "3654460",
    "end": "3664400"
  },
  {
    "text": "So buried in this\nunit normalization that we like to do to get to\na probability distribution",
    "start": "3664400",
    "end": "3671620"
  },
  {
    "text": "function-- we can\ntalk about confidence intervals on the mean. We subtract off some\nmean, and then we",
    "start": "3671620",
    "end": "3678190"
  },
  {
    "text": "normalize to s over root n. But s itself is\nthis chi-squared.",
    "start": "3678190",
    "end": "3683600"
  },
  {
    "text": "So it's really closely\nrelated to the operations that we do when we are\nnormalizing our sample data,",
    "start": "3683600",
    "end": "3693039"
  },
  {
    "text": "when we also had to estimate\nthe standard deviation. So the way to think\nabout the t-distribution",
    "start": "3693040",
    "end": "3702579"
  },
  {
    "text": "is it's really close to\nthe normal distribution, except it's perturbed\na little bit,",
    "start": "3702580",
    "end": "3707920"
  },
  {
    "text": "because we didn't really\nknow the underlying variance. We're having to\nestimate it also.",
    "start": "3707920",
    "end": "3713710"
  },
  {
    "text": "So here's some\npictures, some examples. The red is the unit\nnormal distribution.",
    "start": "3713710",
    "end": "3723450"
  },
  {
    "text": "And now for different sizes of\nsample, so for an n equals 3,",
    "start": "3723450",
    "end": "3730390"
  },
  {
    "text": "you have this little\nblue distribution. That's the t-distribution\nwith degrees of freedom 3.",
    "start": "3730390",
    "end": "3740070"
  },
  {
    "text": "Notice that it's\na little bit wider than the normal distribution,\nreflecting a little bit",
    "start": "3740070",
    "end": "3747540"
  },
  {
    "text": "less certainty on\nreally the location of that random variable.",
    "start": "3747540",
    "end": "3753270"
  },
  {
    "text": "Now as n gets\nbigger, so we've got an n equals 10 example\nin here in the green,",
    "start": "3753270",
    "end": "3760800"
  },
  {
    "text": "the chi-square-- or\nthe t-distribution gets a little bit tighter. And for n equals 100, it's\nbasically almost lying right",
    "start": "3760800",
    "end": "3767750"
  },
  {
    "text": "on top of the\nnormal distribution. So what the t is reflecting is\na little additional uncertainty",
    "start": "3767750",
    "end": "3774800"
  },
  {
    "text": "because we didn't\nknow sigma squared. I had to calculate s squared\nfrom that same sample",
    "start": "3774800",
    "end": "3781880"
  },
  {
    "text": "distribution. So that's all that's\nreally going on there. If we then say, OK,\nI want to get back",
    "start": "3781880",
    "end": "3790040"
  },
  {
    "text": "to a confidence interval. But now, I don't\nknow the variance, and I have to estimate\nthat also from my data.",
    "start": "3790040",
    "end": "3798180"
  },
  {
    "text": "We have essentially the same\nconfidence interval formula, the only difference\nbeing instead of z",
    "start": "3798180",
    "end": "3806570"
  },
  {
    "text": "related to the unit\nnormal distribution, we have numbers of\nstandard deviations",
    "start": "3806570",
    "end": "3813200"
  },
  {
    "text": "on the t-distribution\nthat we're arguing about, again, reflecting that that\nt is a little bit wider.",
    "start": "3813200",
    "end": "3819859"
  },
  {
    "text": "But it's essentially\nexactly the same thinking, just recognizing that now, the\nsampling distribution for x",
    "start": "3819860",
    "end": "3826910"
  },
  {
    "text": "bar when variance is unknown-- is not a normal.",
    "start": "3826910",
    "end": "3832200"
  },
  {
    "text": "It's a t-distribution.  But all the other operations\nare exactly the same.",
    "start": "3832200",
    "end": "3838830"
  },
  {
    "text": "We look for what alpha error\nwe're willing to accept, what our chance of being wrong\non our bounding of the interval",
    "start": "3838830",
    "end": "3846920"
  },
  {
    "text": "is, and then allocating that\nto the left and the right;",
    "start": "3846920",
    "end": "3852020"
  },
  {
    "text": "figuring out how many\nunits normal over we go on not the underlying\npopulation distribution,",
    "start": "3852020",
    "end": "3858650"
  },
  {
    "text": "but our sampling distribution. So we still get the benefits of\nincreasing n getting tighter.",
    "start": "3858650",
    "end": "3865280"
  },
  {
    "text": "But we just do that all\non the t-distribution. AUDIENCE: So this is-- will\nbe necessary for small sample sizes.",
    "start": "3865280",
    "end": "3871300"
  },
  {
    "text": "PROFESSOR: Exactly. So the point or the\nquestion was this is only necessary for\nsmall sample sizes.",
    "start": "3871300",
    "end": "3878230"
  },
  {
    "text": "And that's exactly right\nbecause of the effect that we see back with the\nt-distribution getting",
    "start": "3878230",
    "end": "3885910"
  },
  {
    "text": "very close in approximation to\nthe normal distribution for n",
    "start": "3885910",
    "end": "3891819"
  },
  {
    "text": "becoming appreciable. I've heard different\nkinds of rules of thumb. Some people like to\nsay for n about 25,",
    "start": "3891820",
    "end": "3898930"
  },
  {
    "text": "you're pretty close to\na normal distribution. Some people like to\ndraw it at n equals 40.",
    "start": "3898930",
    "end": "3905260"
  },
  {
    "text": "It really depends on what\nkind of accuracy you're after.",
    "start": "3905260",
    "end": "3910420"
  },
  {
    "text": "But you can be substantially\nwrong for very small sample sizes-- of sample size 5,\nwhich is a natural sample",
    "start": "3910420",
    "end": "3917140"
  },
  {
    "text": "size you would often use in\nsome manufacturing scenarios. So you do have to be\naware for very small n",
    "start": "3917140",
    "end": "3924400"
  },
  {
    "text": "to use the t-distribution. This was an example\nwhere we had n equals 50",
    "start": "3924400",
    "end": "3930390"
  },
  {
    "text": "in our part thickness example. Let's see how different\nthings pop out if we use the t-distribution\nor the normal distribution.",
    "start": "3930390",
    "end": "3937840"
  },
  {
    "text": "So let's go back to our example. But now, let's say we don't\nknow either the variance",
    "start": "3937840",
    "end": "3943440"
  },
  {
    "text": "or the mean. Both of them are unknown. We already calculated\nthe sample mean.",
    "start": "3943440",
    "end": "3950130"
  },
  {
    "text": "We had 113.5. And now I'll tell you--",
    "start": "3950130",
    "end": "3955890"
  },
  {
    "text": "I guess I already gave you\nthis number previously. But I'll tell you that we\napply the sample variance",
    "start": "3955890",
    "end": "3961380"
  },
  {
    "text": "formula to the data, and\nout pops the number 102.3.",
    "start": "3961380",
    "end": "3966650"
  },
  {
    "text": "So again, that's\nyour best estimate of the sample variance.",
    "start": "3966650",
    "end": "3974950"
  },
  {
    "text": "So these are your\npoint estimates. But now, I want to go back\nto the question, where's",
    "start": "3974950",
    "end": "3979990"
  },
  {
    "text": "the confidence interval on where\nwe think the true mean would be 95% of the time?",
    "start": "3979990",
    "end": "3985240"
  },
  {
    "text": "Well, now we have to\nuse the t-distribution. When we do that with\n49 degrees of freedom,",
    "start": "3985240",
    "end": "3992770"
  },
  {
    "text": "again, k minus 1, because we're\nusing up 1 for calculation of the sample mean.",
    "start": "3992770",
    "end": "3997809"
  },
  {
    "text": "Now we have this slightly\ndifferent formula. Here, we can use the plus/minus,\nbecause the t-distribution,",
    "start": "3997810",
    "end": "4005960"
  },
  {
    "text": "like the normal\ndistribution, is symmetric. So I've got plus or minus\nsome number of unit, z's.",
    "start": "4005960",
    "end": "4015420"
  },
  {
    "text": "In this case, it's\nunit t's because the operative distribution\nis the t-distribution.",
    "start": "4015420",
    "end": "4021360"
  },
  {
    "text": "I plug that in. Notice that for 2.5%\nin each of the tail,",
    "start": "4021360",
    "end": "4028529"
  },
  {
    "text": "the t-distribution\nis slightly wider. Remember, back with\nthe unit normal,",
    "start": "4028530",
    "end": "4033869"
  },
  {
    "text": "we said 1.96 plus or minus\nstandard deviations is 95%.",
    "start": "4033870",
    "end": "4039420"
  },
  {
    "text": "For the t, you got to go\na little bit further-- 2.01.",
    "start": "4039420",
    "end": "4044610"
  },
  {
    "text": "Not a big difference-- 2.01. And when you come\nout with that, you get a slightly wider\nconfidence interval.",
    "start": "4044610",
    "end": "4054490"
  },
  {
    "text": "I'm less confident. I got to go further to get to\nmy 95% confidence on the range",
    "start": "4054490",
    "end": "4060369"
  },
  {
    "text": "because I'm also estimating. So in this case, the difference\nis pretty much negligible. And if I had a\nsample of size 50,",
    "start": "4060370",
    "end": "4067480"
  },
  {
    "text": "I would probably just use\nthe normal distribution. And that's a good example,\nshowing that difference",
    "start": "4067480",
    "end": "4073410"
  },
  {
    "text": "is 5 parts out of 200. It's really quite small. ",
    "start": "4073410",
    "end": "4082349"
  },
  {
    "text": "One more distribution\nI want to mention-- we're not going to\nuse it much here. I think I've already\ndescribed it briefly--",
    "start": "4082350",
    "end": "4089220"
  },
  {
    "text": "is this F distribution. And this arises if I have\none random variable that",
    "start": "4089220",
    "end": "4094619"
  },
  {
    "text": "is chi-squared distributed. I take another random variable\nthat's chi-squared distributed. And I form a new\nrandom variable R",
    "start": "4094620",
    "end": "4101729"
  },
  {
    "text": "that is the ratio of\nthose two, each normalized to the degrees of freedom\nor the number of variables",
    "start": "4101729",
    "end": "4109739"
  },
  {
    "text": "that went into each of those\nchi-squared distributed variables. And that is an F with u\nand v degrees of freedom.",
    "start": "4109740",
    "end": "4120528"
  },
  {
    "text": "Again, this comes up when we're\nlooking at things like ratios",
    "start": "4120529",
    "end": "4128359"
  },
  {
    "text": "and want to reason about ratios\nof true population variances, based on observations\nof sample variances.",
    "start": "4128359",
    "end": "4140390"
  },
  {
    "text": "And the key place where that\nmight come up that I mentioned is experimental design cases.",
    "start": "4140390",
    "end": "4147969"
  },
  {
    "text": "So this is an injection\nmolding example, where you might be looking\nat two different process conditions-- a low hold\ntime and a high hold time.",
    "start": "4147970",
    "end": "4156799"
  },
  {
    "text": "And there may be other\nthings varying, maybe even other variables varying, that\ncause there to be a spread.",
    "start": "4156800",
    "end": "4163479"
  },
  {
    "text": "Or there's just\nnatural variation in the two populations. And you might ask\nquestions like,",
    "start": "4163479",
    "end": "4170370"
  },
  {
    "text": "are these two\nvariances different? Did I improve the variance with\nthat process condition change?",
    "start": "4170370",
    "end": "4176089"
  },
  {
    "text": " Maybe-- maybe not. Certainly not obvious\nhere, so you might",
    "start": "4176090",
    "end": "4182979"
  },
  {
    "text": "have a very low confidence. So we're going to go and\nuse the F distribution a little bit later when we\ndo analysis of experiments,",
    "start": "4182979",
    "end": "4190509"
  },
  {
    "text": "especially where you're looking\nto try to make inferences about whether there\nis differences",
    "start": "4190510",
    "end": "4195969"
  },
  {
    "text": "between a couple of populations. And again, because we're\ndealing with variances,",
    "start": "4195970",
    "end": "4204010"
  },
  {
    "text": "there's a huge spread\nthat arise naturally in these distributions,\npurely by chance.",
    "start": "4204010",
    "end": "4212200"
  },
  {
    "text": "This is a good place\nto re-emphasize that a lot of what's going\non here in random sampling",
    "start": "4212200",
    "end": "4219550"
  },
  {
    "text": "is they're spread in the\nobservations that you get. So here's a very simple\nnumerical example.",
    "start": "4219550",
    "end": "4225830"
  },
  {
    "text": "If I start with a variable\nthat is unit normal,",
    "start": "4225830",
    "end": "4230900"
  },
  {
    "text": "and I'm just going to take\ntwo samples, sets of size n",
    "start": "4230900",
    "end": "4236120"
  },
  {
    "text": "equals 20. So I'm taking two\ndifferent samples, same underlying population.",
    "start": "4236120",
    "end": "4242680"
  },
  {
    "text": "I'm not making a\nprocess change, say. I'm just taking two\nsamples, each of size 20.",
    "start": "4242680",
    "end": "4248679"
  },
  {
    "text": "By chance, when I take\nthat first sample size, I calculate a particular\nsample variance, s squared.",
    "start": "4248680",
    "end": "4255949"
  },
  {
    "text": "And by chance, I\ncalculate another one for the second sample. And if I form the ratio of\nthose two, what typical range am",
    "start": "4255950",
    "end": "4263470"
  },
  {
    "text": "I going to observe in the\nratio of those two variances? For example, what\nratio might I observe",
    "start": "4263470",
    "end": "4270400"
  },
  {
    "text": "95% of the time or what range? And that's the F distribution.",
    "start": "4270400",
    "end": "4275810"
  },
  {
    "text": "In fact, if I look at\nthe upper and lower",
    "start": "4275810",
    "end": "4280930"
  },
  {
    "text": "bound on the range of that\nratio for a 95% confidence",
    "start": "4280930",
    "end": "4286810"
  },
  {
    "text": "interval for this ratio\nof two samples of size 20, I can go anywhere from\n2.5 to 0.4 in that ratio.",
    "start": "4286810",
    "end": "4296260"
  },
  {
    "text": " That's with samples of size 20. That's a huge range, right?",
    "start": "4296260",
    "end": "4303540"
  },
  {
    "text": "Imagine, 2 and 1/2 times\nbigger variance over here, compared to over here.",
    "start": "4303540",
    "end": "4308790"
  },
  {
    "text": "And that occurs\npurely by chance. So in 95% of the time, I\nmight have ratios within that.",
    "start": "4308790",
    "end": "4317070"
  },
  {
    "text": "But 5% of the time,\nI'll even observe ratios that are\nbigger or even smaller",
    "start": "4317070",
    "end": "4322349"
  },
  {
    "text": "than those extremo points. So you've got to be really\ncareful in reasoning about variances.",
    "start": "4322350",
    "end": "4328160"
  },
  {
    "text": " So we're mostly there.",
    "start": "4328160",
    "end": "4333210"
  },
  {
    "text": "The last thing I\nwant to do here is draw the relationship of some\nof these two hypotheses tests.",
    "start": "4333210",
    "end": "4340260"
  },
  {
    "text": "And that gets us very close to\nsome of the Shewhart hypotheses that are the basis\nfor control charts",
    "start": "4340260",
    "end": "4346020"
  },
  {
    "text": "that we'll talk about\nin the next lecture. But I do want to get the\nbasic idea in the last five,",
    "start": "4346020",
    "end": "4352110"
  },
  {
    "text": "10 minutes on what\nstatistical hypothesis is and how that relates to some\nof these confidence intervals",
    "start": "4352110",
    "end": "4359440"
  },
  {
    "text": "that we've been talking about. So the basic idea we've been\ndoing with these means is",
    "start": "4359440",
    "end": "4364870"
  },
  {
    "text": "we've been hypothesizing that\nthe mean has some distribution, say a normal distribution.",
    "start": "4364870",
    "end": "4370600"
  },
  {
    "text": "And then when we talked about\nthis confidence interval, I would say, accept or\nreject the hypothesis",
    "start": "4370600",
    "end": "4377740"
  },
  {
    "text": "that the mean was within some\nrange with some probability.",
    "start": "4377740",
    "end": "4383200"
  },
  {
    "text": "We can extend that to\nasking other questions or other hypotheses,\nand then looking",
    "start": "4383200",
    "end": "4389080"
  },
  {
    "text": "at the probabilities\nassociated with it, and saying, with some\ndegree of confidence,",
    "start": "4389080",
    "end": "4394300"
  },
  {
    "text": "I believe the hypothesis. Or I have enough\nevidence to counter it.",
    "start": "4394300",
    "end": "4399460"
  },
  {
    "text": "And a typical example\nmight be a null hypothesis, often referred to as H0,\nthat the mean is some",
    "start": "4399460",
    "end": "4411100"
  },
  {
    "text": "a priori mean, some phi 0. The null hypothesis is based\non this sample, this sample",
    "start": "4411100",
    "end": "4417579"
  },
  {
    "text": "that I'm drawing\nfrom the population. I have this\nalternative hypothesis that the mean has changed.",
    "start": "4417580",
    "end": "4423020"
  },
  {
    "text": "It's no longer the same mean. Do I have enough evidence to say\nwith some degree of confidence",
    "start": "4423020",
    "end": "4428917"
  },
  {
    "text": "that the mean has changed?  And it's a little\ntricky because there's",
    "start": "4428917",
    "end": "4435610"
  },
  {
    "text": "all these probabilities\nassociated with random sampling. So I observe a particular\nvalue with some deviation.",
    "start": "4435610",
    "end": "4443260"
  },
  {
    "text": "How do I know to what\ndegree there's actual shift,",
    "start": "4443260",
    "end": "4450130"
  },
  {
    "text": "say, in the mean or not? So let's look at this. What we do is we\nform the hypothesis.",
    "start": "4450130",
    "end": "4456840"
  },
  {
    "text": "We then look at the\nprobabilities associated with the two cases, and then\nbased on those probabilities,",
    "start": "4456840",
    "end": "4462840"
  },
  {
    "text": "say with some degree\nof confidence, I choose one or the other.",
    "start": "4462840",
    "end": "4468250"
  },
  {
    "text": "And what's important is there's\nalways the chance of being wrong, making an error--",
    "start": "4468250",
    "end": "4473940"
  },
  {
    "text": "those alpha errors out in\nthe tails, for example-- with that decision.",
    "start": "4473940",
    "end": "4479500"
  },
  {
    "text": "So that's where this\nconfidence level comes in. So let's say we're\nlooking at this test.",
    "start": "4479500",
    "end": "4485430"
  },
  {
    "text": "We're asking-- the\nnull hypothesis is I have a normal distribution\nwith some a priori mean",
    "start": "4485430",
    "end": "4494380"
  },
  {
    "text": "and some a priori variance. I'm going to draw a new sample. And based on that, I\nwant to either decide",
    "start": "4494380",
    "end": "4502880"
  },
  {
    "text": "that a shift has occurred\nor that the data-- or not-- that the data comes\nfrom that distribution or not.",
    "start": "4502880",
    "end": "4511170"
  },
  {
    "text": "And so what we're\ngoing to do is use essentially this same\nconfidence interval idea",
    "start": "4511170",
    "end": "4516560"
  },
  {
    "text": "and say, say to 95%\nconfidence, 95% of the time,",
    "start": "4516560",
    "end": "4521730"
  },
  {
    "text": "if my value lies in the central\npart of that distribution, I'm going to accept the--",
    "start": "4521730",
    "end": "4530870"
  },
  {
    "text": "well, in this case,\nthe null hypothesis that my new sample still comes\nfrom that same distribution.",
    "start": "4530870",
    "end": "4537840"
  },
  {
    "text": "So that would be my 95%,\nmy 1 minus alpha, if alpha is a 5% error.",
    "start": "4537840",
    "end": "4543390"
  },
  {
    "text": "But if I observe a\nsample mean, say, or I observe a piece of\ndata that lies out here,",
    "start": "4543390",
    "end": "4551230"
  },
  {
    "text": "I'm going to reject\nthe null hypothesis. I'm going to say\ninstead, I think I've got an unlikely\nevent by chance",
    "start": "4551230",
    "end": "4558909"
  },
  {
    "text": "that I think instead indicates\nsomething has changed. Something has changed\nin the process.",
    "start": "4558910",
    "end": "4564270"
  },
  {
    "text": "And we'll call that the\nregion of rejection. ",
    "start": "4564270",
    "end": "4570340"
  },
  {
    "text": "So again, already you\ncan see one kind of error that's likely to pop up.",
    "start": "4570340",
    "end": "4576159"
  },
  {
    "text": "There is a confidence\ninterval, this alpha. There is a significance\nlevel to the test,",
    "start": "4576160",
    "end": "4581840"
  },
  {
    "text": "very similar to the\nconfidence interval idea and the alpha error\nassociated with that.",
    "start": "4581840",
    "end": "4588290"
  },
  {
    "text": "So right away, you see\nthere's one kind of error-- it's referred to\nas a type I error--",
    "start": "4588290",
    "end": "4595239"
  },
  {
    "text": "on these kinds of\nhypothesis tests. We're rejecting the\nnull hypothesis out",
    "start": "4595240",
    "end": "4600900"
  },
  {
    "text": "here in the tails with\nsome probability alpha. ",
    "start": "4600900",
    "end": "4607675"
  },
  {
    "text": "If I observed a point\nout there in the tails, even if that population\nor that distribution",
    "start": "4607675",
    "end": "4614650"
  },
  {
    "text": "is still operative,\nit is, in fact, true. My samples are still coming\nfrom that distribution.",
    "start": "4614650",
    "end": "4621250"
  },
  {
    "text": "But I happened to draw a\nsample way out in the tail. And I said, well,\nthat was unlikely.",
    "start": "4621250",
    "end": "4628590"
  },
  {
    "text": "That was unlikely\nin this picture. I'm rejecting the\nnull hypothesis. I'm claiming this is evidence\nthat something changed",
    "start": "4628590",
    "end": "4635608"
  },
  {
    "text": "when, in fact, nothing changed. I just got unlucky, right? So the first type of\nerror that you can make",
    "start": "4635608",
    "end": "4642300"
  },
  {
    "text": "is this type I error. ",
    "start": "4642300",
    "end": "4648159"
  },
  {
    "text": "It's also sometimes referred\nto as producer error, producer risk.",
    "start": "4648160",
    "end": "4653890"
  },
  {
    "text": "You're the manufacturer. You reject your\npart because your-- or you reject a batch,\nsay, because your sample",
    "start": "4653890",
    "end": "4660970"
  },
  {
    "text": "was way out here in the tail. You're taking the risk of\nrejecting and throwing away",
    "start": "4660970",
    "end": "4665980"
  },
  {
    "text": "good product, even though\nit really was good. If I took more samples, it would\ngo back and really indicate",
    "start": "4665980",
    "end": "4674739"
  },
  {
    "text": "what was going on-- that the product was still good. So it's also sometimes\nreferred to as producer risk.",
    "start": "4674740",
    "end": "4681250"
  },
  {
    "text": "But there's another\npossible error. There is an error associated\nwith the distribution shifted",
    "start": "4681250",
    "end": "4691200"
  },
  {
    "text": "or changed. I still accepted it\nbased on a random sample",
    "start": "4691200",
    "end": "4696210"
  },
  {
    "text": "from the different\ndistribution that happened to fall in\nmy other distribution. And that's referred\nto as type II error--",
    "start": "4696210",
    "end": "4704639"
  },
  {
    "text": "has a probability associated\nwith that called beta. We've been talking all\nabout these alphas.",
    "start": "4704640",
    "end": "4710055"
  },
  {
    "text": "Well, there's also a beta. It's also sometimes referred\nto as a consumers' risk.",
    "start": "4710055",
    "end": "4717510"
  },
  {
    "text": "The manufacturer did\na little inspection. The mean happened to fall\nin the region of acceptance.",
    "start": "4717510",
    "end": "4723270"
  },
  {
    "text": "He shipped it. Turns out, it was actually\nby bad chance just happened to fall in the good region.",
    "start": "4723270",
    "end": "4729500"
  },
  {
    "text": "It really is coming\nfrom a bad distribution. So let's look at that.",
    "start": "4729500",
    "end": "4735610"
  },
  {
    "text": "What is this beta? Well, for the type II\nerrors, we essentially have to hypothesize a shift of\nsome size, some little delta.",
    "start": "4735610",
    "end": "4745120"
  },
  {
    "text": "And then we assess\nthe probabilities that I'm drawing from the tail\nof that shifted distribution",
    "start": "4745120",
    "end": "4752590"
  },
  {
    "text": "and just happen\nto fall over here in this region of acceptance\nfor our good distribution.",
    "start": "4752590",
    "end": "4760040"
  },
  {
    "text": "So this is the\nprobability associated with our null hypothesis. This is our starting\ndistribution.",
    "start": "4760040",
    "end": "4766720"
  },
  {
    "text": "Our alternative\nhypothesis here is that I had a plus delta\nshift in the mean.",
    "start": "4766720",
    "end": "4772375"
  },
  {
    "text": " So this is our\npossible new operative.",
    "start": "4772375",
    "end": "4778900"
  },
  {
    "text": "And in fact, for\na type II error, this is actually at work. Remember, this is the\nregion of acceptance.",
    "start": "4778900",
    "end": "4786949"
  },
  {
    "text": "So I'm claiming this is good. But if the population\nactually shifted over there",
    "start": "4786950",
    "end": "4794110"
  },
  {
    "text": "to the right, notice\noff on the left here we've got this\nwhole tail, where",
    "start": "4794110",
    "end": "4801560"
  },
  {
    "text": "if I drew from the\nshifted distribution, I've got that tail, that lightly\nshaded blue tail, falling",
    "start": "4801560",
    "end": "4807380"
  },
  {
    "text": "in the region of acceptance,\nwhere I would say it's a good distribution\nand erroneously except.",
    "start": "4807380",
    "end": "4814140"
  },
  {
    "text": "And one can simply apply the\nsame probabilities to basically go in and calculate--",
    "start": "4814140",
    "end": "4821280"
  },
  {
    "text": "just integrate up and do the\ncumulative normal distribution",
    "start": "4821280",
    "end": "4826829"
  },
  {
    "text": "function to calculate\nwhat that tail is.",
    "start": "4826830",
    "end": "4832200"
  },
  {
    "text": "So it's all the\nsame probabilities. So the applications of this\nare really going to be on--",
    "start": "4832200",
    "end": "4840510"
  },
  {
    "text": "of hypothesis testing. This would be\nshifts of the mean. You can start to see worrying\nabout monitoring your process",
    "start": "4840510",
    "end": "4847470"
  },
  {
    "text": "and seeing if something\nchanged in your process, a shift occurred, and\nbeing able to detect that.",
    "start": "4847470",
    "end": "4853260"
  },
  {
    "text": "And that gets us\nto control charting that we'll do next time. So this is all pretty\nmuch the same stuff.",
    "start": "4853260",
    "end": "4860730"
  },
  {
    "text": "And now this is a peek ahead. You'll see process control.",
    "start": "4860730",
    "end": "4866250"
  },
  {
    "text": "And we'll talk about\nrepeated samples in time coming from the\nsame distribution next time.",
    "start": "4866250",
    "end": "4873840"
  },
  {
    "text": "So we will see you on Thursday. And we will dive into\nShewhart control charts.",
    "start": "4873840",
    "end": "4880980"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5580",
    "end": "12270"
  },
  {
    "text": "To make a donation, or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12270",
    "end": "18830"
  },
  {
    "text": "at ocw.mit.edu.  JAMES DICARLO: So let\nme start by first--",
    "start": "18830",
    "end": "25100"
  },
  {
    "text": "I already alluded to\nthis, but let's talk about the problem of vision. This is just one\ncomputational challenge",
    "start": "25100",
    "end": "32960"
  },
  {
    "text": "that our brains solve, but\nit's one that many of us are very fascinated by. As you'll hear in the\nrest of the course,",
    "start": "32960",
    "end": "39140"
  },
  {
    "text": "there are other problems\nthat are equally fascinating. But I'm going to talk\nabout problems of vision. I'm going to talk about a\nspecific problem of vision,",
    "start": "39140",
    "end": "45780"
  },
  {
    "text": "and that's the problem\nof object recognition. So I will try to\noperationalize that for you.",
    "start": "45780",
    "end": "52160"
  },
  {
    "text": "And one thing you'll\nsee when I talk is that our field,\neven though we can be motivated by words like\nvision and object recognition,",
    "start": "52160",
    "end": "58496"
  },
  {
    "text": "we're going to\nonly make progress if we start to\noperationally define things and then decide in what domain\nmodels are going to apply.",
    "start": "58496",
    "end": "65000"
  },
  {
    "text": "And I think that's an\nimportant lesson that I hope will come across in my talk. So this is the way computer\nvision operationally",
    "start": "65000",
    "end": "71939"
  },
  {
    "text": "defines part of the problem of\nobject recognition and vision. It's as if you take\na scene like this and you want to do\nthings like come up",
    "start": "71940",
    "end": "78524"
  },
  {
    "text": "with an answer space that\nlooks like this, where you have noun labels, say a car. And you have what are called\nbounding boxes around the cars,",
    "start": "78524",
    "end": "85340"
  },
  {
    "text": "similarly for people,\nor buildings, or trees, or whatever nouns that\nyou or DARPA or whoever",
    "start": "85340",
    "end": "92300"
  },
  {
    "text": "wants to actually label. Right, so this is just one way\nof operationalizing vision.",
    "start": "92300",
    "end": "97727"
  },
  {
    "text": "But I think it gets at the crux\nof what we're after, which is, there is what's called\nlatent content in this image",
    "start": "97727",
    "end": "103700"
  },
  {
    "text": "that all of us instantly\nbring to our memories,",
    "start": "103700",
    "end": "108960"
  },
  {
    "text": "that we can say, aha, that's\na car, that's a building. There are nouns that\npop into our heads. We also know other latent\ninformation about these things,",
    "start": "108960",
    "end": "116040"
  },
  {
    "text": "like the pose of this car,\nthe position of the car, the size of the car. The key point that I'm\ngoing to tell you today",
    "start": "116040",
    "end": "121440"
  },
  {
    "text": "about this problem is that\nthat information feels to us that it's obvious,\nbut it's quite",
    "start": "121440",
    "end": "126540"
  },
  {
    "text": "latent in the image--\nthat's implicit in the pixel representation. Those of you who have\nworked on this problem will understand this and those\nof you who haven't, I hopefully",
    "start": "126540",
    "end": "133922"
  },
  {
    "text": "will give you some flavor for\nwhat that problem feels like. So I want to back up a bit.",
    "start": "133923",
    "end": "139560"
  },
  {
    "text": "This is more from a cognitive\nscience perspective, or a human brain perspective,\nto ask, why would we",
    "start": "139560",
    "end": "145290"
  },
  {
    "text": "even bother worrying about this\nproblem of object recognition? And maybe this is obvious\nthat those of you-- and I",
    "start": "145290",
    "end": "150330"
  },
  {
    "text": "don't need to say\nthis, but I like to point out that we think\nof the representations of the tokens of what's\nout there in the world",
    "start": "150330",
    "end": "156225"
  },
  {
    "text": "as being the substrates\nof what you might do, what's called higher level\ncognition, things like memory,",
    "start": "156225",
    "end": "161550"
  },
  {
    "text": "value judgments, decisions\nand actions in the world. Imagine building\na robot and having it try to act in the\nworld and it doesn't even",
    "start": "161550",
    "end": "167876"
  },
  {
    "text": "really know what's out there. So these are the sort of\nsubstrate of these kind of cognitive processes.",
    "start": "167876",
    "end": "174295"
  },
  {
    "text": "Again, from an\nengineering perspective, these are processes\nor behaviors. This is just a\nshort list of them",
    "start": "174295",
    "end": "180150"
  },
  {
    "text": "that might depend on\nyour good abilities to recognize and discriminate\namong different objects.",
    "start": "180150",
    "end": "185477"
  },
  {
    "text": "I think if you look\nthrough this list, you could imagine things that\nwould go terribly wrong if you didn't actually do a\ngood job at identifying",
    "start": "185477",
    "end": "191760"
  },
  {
    "text": "what's out there in the world. So that's just to\nthink about, again, as an engineer building a robot.",
    "start": "191760",
    "end": "198096"
  },
  {
    "text": "This is a slide\nI stuck in that I want to connect to\nthis course, the idea that I know many of you are\nfrom maybe these backgrounds,",
    "start": "198096",
    "end": "204120"
  },
  {
    "text": "or from this background. And when I think\nabout the brain, I have this coin\nhere to say, really these are kind of two sides--\nwe're studying the same coin",
    "start": "204120",
    "end": "211890"
  },
  {
    "text": "from two directions here. And really the\nquestion that we have to all be excited about,\nI hope many of you are excited about it is,\nhow does the brain work?",
    "start": "211890",
    "end": "218500"
  },
  {
    "text": "And you could do\ncomputer science and not care at all\nabout this question. I think it's a little\nharder to do these and not care about this question.",
    "start": "218500",
    "end": "223821"
  },
  {
    "text": "But it's possible, I guess. So these are all trying\nto answer this question.",
    "start": "223821",
    "end": "229140"
  },
  {
    "text": "And this is maybe\npretty obvious, but when you have\nbiological brains that are performing tasks better\nthan current computer",
    "start": "229140",
    "end": "235890"
  },
  {
    "text": "systems, machines that\nhumans have built, then the flow tends to\nwant to go this way.",
    "start": "235890",
    "end": "241410"
  },
  {
    "text": "You discover phenomena\nor constraints over here. These lead to ideas that can be\nbuilt into computer code that",
    "start": "241410",
    "end": "247650"
  },
  {
    "text": "can say, hey, can I build\na better machine based on what we discover over here? And many of us who came into\nthe field excited to do this",
    "start": "247650",
    "end": "253410"
  },
  {
    "text": "and are still excited of\nthis kind of direction. But an equally\nimportant direction is that when you\nhave systems that",
    "start": "253410",
    "end": "259259"
  },
  {
    "text": "are matched with our\nabilities, or that can compute some of the things\nthat we think the brain has to compute, then the\nflow goes more this way,",
    "start": "259260",
    "end": "266250"
  },
  {
    "text": "where there's many possible\nways to implement an idea and these become falsifiable.",
    "start": "266250",
    "end": "272610"
  },
  {
    "text": "That is, that they can be\ntested against experimental data to ask which of these many ways\nof implementing a computation",
    "start": "272610",
    "end": "278520"
  },
  {
    "text": "are the ones that are actually\noccurring in the brain. And that's important\nif you say you want to build\nbrain-machine interfaces,",
    "start": "278520",
    "end": "283710"
  },
  {
    "text": "or fix diseases, or\ndo something that's on the level of interacting\nwith the brain directly.",
    "start": "283710",
    "end": "289173"
  },
  {
    "text": "I hope that you guys\nkeep this picture in mind because I think it's sort\nof the spirit of the course that both of these\ndirections are important.",
    "start": "289174",
    "end": "294843"
  },
  {
    "text": "And it's not as if we work on\nthis for 20 years and then work on this for 20 years. It's really the flow\nacross them that I think",
    "start": "294843",
    "end": "300075"
  },
  {
    "text": "is the most exciting to us. So just to connect to that,\na little bit of history of where was the field on this\nproblem of visual recognition.",
    "start": "300075",
    "end": "307475"
  },
  {
    "text": "I don't know if many\nof you heard this, but here you are\nat summer school, so there was a Summer\nVision Project--",
    "start": "307475",
    "end": "312840"
  },
  {
    "text": "it was called, at MIT. I used to think this\nstory was apocryphal. In 1966, there was a\nproject that the final goal",
    "start": "312840",
    "end": "319782"
  },
  {
    "text": "was object identification,\nwhich we'll actually name, Objects by Matching the\nVocabulary of Known Objects. So this was essentially\na summer project to say,",
    "start": "319782",
    "end": "326912"
  },
  {
    "text": "we're going to get a couple\nundergraduate students together and we're going to build a\nrecognition system in 1966.",
    "start": "326912",
    "end": "333240"
  },
  {
    "text": "And this was the\nexcitement of AI, we can build anything\nthat we want. And of course, those\nof you who know this,",
    "start": "333240",
    "end": "338774"
  },
  {
    "text": "this problem turned\nout to be much, much harder than anticipated. So sometimes problems that\nseem easy for us are actually",
    "start": "338774",
    "end": "345419"
  },
  {
    "text": "quite difficult. If\nany of you wants this, I would be happy to share\nthis document with you. It's interesting, the space\nof objects that they describe",
    "start": "345420",
    "end": "352919"
  },
  {
    "text": "things like recognizing-- of course, I would say like\ncoffee cups on your desk. But they also say packs of\ncigarettes on your desk.",
    "start": "352920",
    "end": "360360"
  },
  {
    "text": "So this sort of dates\nthe time of this here. So it's a little bit like\nMad Men or something. So now, here we are today.",
    "start": "360360",
    "end": "366420"
  },
  {
    "text": "And I guess I just can't help\nbut sort of get excited about, here's this really cool\nmachine that's just amazing",
    "start": "366420",
    "end": "372120"
  },
  {
    "text": "that does these computations. The things got-- I can't tell\nyou all this because of the 100 billion computing elements,\nsolves problems not solveable",
    "start": "372120",
    "end": "378810"
  },
  {
    "text": "by any previous machine. And the thing, it looks\ncrazy, but it only requires 20 watts of power.",
    "start": "378810",
    "end": "384086"
  },
  {
    "text": "Those of you who\nhave seen this slide, I'm not talking\nabout this thing. I'm talking about that\nthing right there.",
    "start": "384087",
    "end": "389819"
  },
  {
    "text": "So this is a scale\nof what we're after. And we often talk about power,\nbut this is something engineers",
    "start": "389820",
    "end": "396000"
  },
  {
    "text": "are especially interested in\nas they build these systems, is how does our brains solve these\nproblems at such a low wattage, so to speak.",
    "start": "396000",
    "end": "402540"
  },
  {
    "text": "This is, again, the spirit\nof many of the things that I hope that you guys are\nexcited about in the future of this field.",
    "start": "402540",
    "end": "407987"
  },
  {
    "text": "Here's another slide\nthat I pulled out that I often like to show\nis that, from an engineer's point of view, we\noften try to say,",
    "start": "407987",
    "end": "413470"
  },
  {
    "text": "well, we want to build\nmachines that are as good or better than our brain. So machines today, you\nguys know this, beat us",
    "start": "413470",
    "end": "420010"
  },
  {
    "text": "at many things,\nstraight calculation, they beat us at chess. When I was a grad student,\nthey recently won at Jeopardy.",
    "start": "420010",
    "end": "426880"
  },
  {
    "text": "In memory, they've\nalways beaten us. Machines are way better\nat memory than us in the simple form of memory.",
    "start": "426880",
    "end": "432955"
  },
  {
    "text": "Seeing, in pattern\nmatching, go to the grocery store, hey, what's\nthat bar code done? I don't know what that\nwas, but it just scans in",
    "start": "432955",
    "end": "438910"
  },
  {
    "text": "and somehow it does\npattern matching, right? So there's forms of\nvision that machines are way better than us. But some forms of vision that\nare more complicated that",
    "start": "438910",
    "end": "445870"
  },
  {
    "text": "require generalization,\nlike object recognition, or more broadly,\nscene understanding, we like to think that we\nare still the winners at.",
    "start": "445870",
    "end": "452060"
  },
  {
    "text": "And even things that we take\nfor granted, like walking, this is quite a\nchallenging problem. So engineers really want\nto move this over here.",
    "start": "452060",
    "end": "460180"
  },
  {
    "text": "So our goal is to discover\nhow the brain solves object recognition. And the reason I put this\nup is, from an engineering",
    "start": "460180",
    "end": "465250"
  },
  {
    "text": "point of view, that just doesn't\nmean write a bunch of papers in a textbook that says,\nthis part of the brain does it, but actually help to\nimplement a system where this",
    "start": "465250",
    "end": "471670"
  },
  {
    "text": "is, at least, matched with\nus and I assume someday, will be better than us. And this is also\na gateway problem.",
    "start": "471670",
    "end": "478900"
  },
  {
    "text": "That is, even if it's\njust this domain, we think that the\nsystems we're studying might generalize to other,\nfor instance, sensory domains.",
    "start": "478900",
    "end": "486370"
  },
  {
    "text": "Gabriel told me you\nwere going to do an auditory, visual comparison\nsession later in the week.",
    "start": "486370",
    "end": "492722"
  },
  {
    "text": "That's an engineer's\npoint of view, how do I just build\nbetter systems? Let's step back and talk from\na scientist's point of view.",
    "start": "492722",
    "end": "498686"
  },
  {
    "text": "So this is really now to\nintroduce the talk that I'm going to give you today. So when you're a\nscientist, what's our job?",
    "start": "498687",
    "end": "503812"
  },
  {
    "text": "We say we want to understand. We all write that, understand. What does that mean? Well, what it really\nmeans if you boil it down,",
    "start": "503812",
    "end": "509560"
  },
  {
    "text": "and I would love to\ndiscuss this if you like, is that you have some\nmeasurements in some domain. So you can think of this\nas a state space here.",
    "start": "509560",
    "end": "516130"
  },
  {
    "text": "This is like the position\nof the planets today. And this is like the position\nof the planets tomorrow.",
    "start": "516130",
    "end": "523450"
  },
  {
    "text": "Or you could say, this is the\nDNA sequence inside a cell. And this is some protein\nthat's going to get made.",
    "start": "523450",
    "end": "529250"
  },
  {
    "text": "So you're searching for\nmappings that are predictive from one domain to another. And we can give lots\nof examples of what",
    "start": "529250",
    "end": "534976"
  },
  {
    "text": "we call successful\nscience, where that's true. This is the core of science\nis to predict, given some measurements or\nobservations, what's",
    "start": "534976",
    "end": "541660"
  },
  {
    "text": "going to happen either in\nthe future or some other set of measurements. So predictive power is\nthe core of all science",
    "start": "541660",
    "end": "548140"
  },
  {
    "text": "and the core of understanding. And I think it would be fun\nif you want to debate that, that you think\nthere's another way. But this is what I come to in\nthinking about this problem.",
    "start": "548140",
    "end": "555280"
  },
  {
    "text": "And the reason I'm\nbringing this up is because the accuracy\nof this predictive mapping is a measure of the strength\nof any scientific field.",
    "start": "555280",
    "end": "561899"
  },
  {
    "text": "And some fields are\nfurther along than others. And I would say ours is\nstill not very far along.",
    "start": "561900",
    "end": "567700"
  },
  {
    "text": "Our job is to bring it\nfrom a nonpredictive state to a very predictive state.",
    "start": "567700",
    "end": "572810"
  },
  {
    "text": "And so that means building\nmodels that can be falsified and that can predict things. And you'll hear that\nthrough my talk.",
    "start": "572810",
    "end": "578580"
  },
  {
    "text": "As Gabriel mentioned,\nwhat we try to do is build models that can predict\neither behavior or neural activity. And that's what we think is\nwhat progress looks like.",
    "start": "578580",
    "end": "586370"
  },
  {
    "text": "So now let's translate\nthis to the problem I gave you, which is the problem\nof vision or more generally object recognition.",
    "start": "586370",
    "end": "592243"
  },
  {
    "text": "You could imagine, there's\na domain of images. So just to slow down\nhere, just so everybody's on the same page,\neach dot here might be",
    "start": "592244",
    "end": "598360"
  },
  {
    "text": "all the pixels in this image. In this dot, all the\npixels in this image. So there's a set of\npossible pixel-images",
    "start": "598360",
    "end": "604390"
  },
  {
    "text": "that you could see. And we imagine that they\ngive rise to, in the brain, some state space. Think of this as the whole brain\nfor now, to just fix ideas,",
    "start": "604390",
    "end": "613057"
  },
  {
    "text": "that you could imagine that this\nimage, one you're looking at, it gives rise to some\npattern of activity across your whole brain.",
    "start": "613057",
    "end": "618781"
  },
  {
    "text": "And this image gives rise to a\ndifferent pattern of activity across your whole brain. And loosely, we call this\nthe neural representation",
    "start": "618781",
    "end": "624490"
  },
  {
    "text": "of this thing. But then what we do is\nsomehow when we ask you for behavior reports,\nthere's a mapping",
    "start": "624490",
    "end": "630820"
  },
  {
    "text": "between that neural\nstate space and what we measure as the output. Whether you say it or\nwrite it, you might say,",
    "start": "630820",
    "end": "636730"
  },
  {
    "text": "that's a face, these\nare both faces, if I asked you for\nnouns among them. OK, so this is another\ndomain of measurement.",
    "start": "636730",
    "end": "643269"
  },
  {
    "text": "So now you can see I'm setting\nup the notion of predictivity. And what we want\nto do is, we have this complex thing over\nhere of images that somehow",
    "start": "643270",
    "end": "649630"
  },
  {
    "text": "map internally into\nneural activity and then somehow\nmap to the thing we call perceptual reports. And notice I've\nalready put things",
    "start": "649630",
    "end": "655150"
  },
  {
    "text": "that we call nouns\nthat we usually associate with objects, cars,\nface, dogs, cats, clocks, and so forth.",
    "start": "655150",
    "end": "661000"
  },
  {
    "text": "OK, so understanding this\nmapping in a predictive sense is really a summary of what\nour part of the field is about.",
    "start": "661000",
    "end": "667279"
  },
  {
    "text": "And again, accurate\npredictivity is the core product of the science that\nunderlies our ability",
    "start": "667280",
    "end": "672700"
  },
  {
    "text": "to build a system like\nthis-- many of you are interested, to fix\na system like this, or to perhaps even\naugment our own systems.",
    "start": "672700",
    "end": "678576"
  },
  {
    "text": "If we want to inject signals\nhere and have them give rise to percepts, we have\nto know how this works. A big part of the\nfield of vision",
    "start": "678576",
    "end": "684520"
  },
  {
    "text": "is spent-- a lot of\nthe last three decades, working on the mapping between\nimages and neural activity.",
    "start": "684520",
    "end": "690010"
  },
  {
    "text": "That's usually called encoding,\npredictive encoding mechanisms. And it's driven by\nHubel and Wiesel's work.",
    "start": "690010",
    "end": "695569"
  },
  {
    "text": "The people saw this as\na great way forward. It's like, let's go\nstudy the neurons and try to understand what\nin the image is driving them.",
    "start": "695569",
    "end": "702910"
  },
  {
    "text": "That is, what's an\nimage computable model in the world that\nwould go from images to neural responses?",
    "start": "702910",
    "end": "709339"
  },
  {
    "text": "The other part is that there's\nsome linkage, we think, between the neural\nactivity and these reports. And notice, this is\nactually why most of us",
    "start": "709340",
    "end": "716060"
  },
  {
    "text": "get into neuroscience\nbecause you notice this arrow is two-way. This is actually\nquite deep here. From an engineer's\npoint of view,",
    "start": "716060",
    "end": "721460"
  },
  {
    "text": "you go, well, there's\ngot to be some mapping between the neural\nactivity and the button presses on my fingers or\nmy saying the word noun.",
    "start": "721460",
    "end": "727220"
  },
  {
    "text": "There's some causal linkage\nbetween this and the things that we observe\nobjectively in a subject.",
    "start": "727220",
    "end": "733040"
  },
  {
    "text": "But this is where philosophers\ndebate about like, well, you know in some sense\nthese are sort of two sides of the same coin.",
    "start": "733040",
    "end": "738380"
  },
  {
    "text": "We say our own\nperception, there's some aspects of the\ninternal activity that are the thing that we\ncall awareness or perception.",
    "start": "738380",
    "end": "744406"
  },
  {
    "text": "Now I'm not going to\nget into all that, but I just want to point\nout that if you're just building models, you\ncan't approach that.",
    "start": "744406",
    "end": "749960"
  },
  {
    "text": "It's this sort of strange\nthing between neurons and these reported states that\nmany of us are fascinated by.",
    "start": "749960",
    "end": "755510"
  },
  {
    "text": "So this is called predictive\ndecoding mechanisms. For me, it's all going\nto be operationalized in terms of reports\nfrom humans or animals.",
    "start": "755510",
    "end": "761794"
  },
  {
    "text": "And I'll not do that\nphilosophical part, but I thought I'd mention\nthat for those you like to think about those things. So for visual\nobject perception, I",
    "start": "761794",
    "end": "768350"
  },
  {
    "text": "want to point out that, again,\nthe history of the field has been mostly here. This link has been\nneglected or dominated",
    "start": "768350",
    "end": "773900"
  },
  {
    "text": "by weakly predictive\nword models. That doesn't mean they're\nnot useful starting points, but they're weakly predictive.",
    "start": "773900",
    "end": "779261"
  },
  {
    "text": "And so a weakly predictive\nword model would be-- and for temporal cortex,\na part of the brain I'm going to tell you about\ntoday, does object recognition.",
    "start": "779261",
    "end": "785388"
  },
  {
    "text": "That model has been\naround for a long time. It is somewhat predictive\nbecause it says, you take that out and\nall object recognition",
    "start": "785388",
    "end": "792100"
  },
  {
    "text": "will get destroyed,\nwould be a prediction. Turns out that doesn't\nactually happen. We can discuss that.",
    "start": "792100",
    "end": "797180"
  },
  {
    "text": "But it doesn't tell you how it\ndoes it, how to inject signals, which tasks are more\nor less affected,",
    "start": "797180",
    "end": "803329"
  },
  {
    "text": "so that's what I mean\nby weakly predictive. It's a word model. Face neurons do\nface task, that's",
    "start": "803330",
    "end": "808340"
  },
  {
    "text": "probably true to some extent. But again, it doesn't\ntell us-- it's more tight. It sort of says, oh, I'll\ntake out these smaller regions",
    "start": "808340",
    "end": "813650"
  },
  {
    "text": "and there'll be some set of\ntasks that involve faces. I don't know, I won't say\nanything about other tasks. So that's a somewhat more\nstrongly predictive model,",
    "start": "813650",
    "end": "820770"
  },
  {
    "text": "but still pretty\nweakly predictive. And my personal favorite that\ncomes in from reviewers a lot is, attention solves that.",
    "start": "820770",
    "end": "827960"
  },
  {
    "text": "So this is just a\nstatement that-- just to be on the\nlookout for word models that don't actually have\ncontent in terms of prediction.",
    "start": "827960",
    "end": "834492"
  },
  {
    "text": "I don't know what that means. I read this as, hand\nof God reaches in and solves the problem. So there's got to be an\nactual predictive model that",
    "start": "834492",
    "end": "841220"
  },
  {
    "text": "can be falsified. OK, so I don't mean to doubt\nthe importance of these. Before people start\ngiving me a hard time,",
    "start": "841220",
    "end": "847370"
  },
  {
    "text": "there are attentional phenomena,\nthere are face neurons, there is an IT,\nthat's what we study. I'm just trying to\nemphasize for you that we",
    "start": "847370",
    "end": "853640"
  },
  {
    "text": "need to go beyond word\nmodels into actual testable models that make predictions,\nthat would stand even",
    "start": "853640",
    "end": "858830"
  },
  {
    "text": "if the person claiming those\nmodels is no longer around, it would make a prediction. Let me try to define a domain.",
    "start": "858830",
    "end": "865040"
  },
  {
    "text": "I said we're going to\ntry to define stuff. It's hard to define stuff. It's big, vision,\nit's a big area. Object recognition, I\nsort of said it vaguely.",
    "start": "865040",
    "end": "871730"
  },
  {
    "text": "And when I say this, I\ninclude faces as an object, a socially important when. You'll hear this\nfrom Winrich I think.",
    "start": "871730",
    "end": "877340"
  },
  {
    "text": "But I want to say, to try\nto limit it even further, that's still a big domain. And so we tried early on to\nreduce the problem even further",
    "start": "877340",
    "end": "885430"
  },
  {
    "text": "to something that is\nmore, again, naturalistic, that we think can\ngive us more traction, this predictive sense.",
    "start": "885430",
    "end": "891030"
  },
  {
    "text": "So we started by saying, when\nyou take a scene like this and you analyze it,\nyou may not notice it but your ventral stream, really\nyour retina has high acuity",
    "start": "891030",
    "end": "901209"
  },
  {
    "text": "in say the central 10 degrees. There's anatomy that\nI'll show you later that the ventral\nstream is especially interested in processing\nthe central 10",
    "start": "901210",
    "end": "907520"
  },
  {
    "text": "degrees of information. So that's about two\nhands at arm's length, for those you see in the room. So you may have the sense that\nyou know what's out there,",
    "start": "907520",
    "end": "914210"
  },
  {
    "text": "but you don't really. You kind of stitch\nthat together. And lots of people\nhave shown this, the way you stitch this\ntogether is making rapid eye",
    "start": "914210",
    "end": "920930"
  },
  {
    "text": "movements around,\ncalled saccades, followed by fixations, which\nare 200 to 500 milliseconds in duration.",
    "start": "920930",
    "end": "926000"
  },
  {
    "text": "You don't really see\nduring this time here. It's not as if your\nbrain shuts down, it's just that the movement\nis too fast for your retina",
    "start": "926000",
    "end": "932354"
  },
  {
    "text": "to really keep up with this. So you make these\nrapid eye movements, you fixate, fixate, fixate. And what you do is,\nthat brings this sort",
    "start": "932354",
    "end": "938870"
  },
  {
    "text": "of sampled scene to\nthe central 10 degrees that might look\nsomething like this.",
    "start": "938870",
    "end": "944190"
  },
  {
    "text": "So those are 200\nmillisecond snapshots across that scan path. And I'll play it for\nyou one more time. Now, you should\nnotice that there's",
    "start": "944190",
    "end": "950748"
  },
  {
    "text": "one or more objects in\neach and every image that you probably said,\noh, there's a sign. There's a person. There's a car. You might have gotten\ntwo out of each one.",
    "start": "950749",
    "end": "956880"
  },
  {
    "text": "But you were sort of\nextracting, at least intuitively to me, at least\none or more foreground",
    "start": "956880",
    "end": "962389"
  },
  {
    "text": "or central objects when\nI show you those images. And that ability to do what I\njust showed you there, we think",
    "start": "962390",
    "end": "968660"
  },
  {
    "text": "is the core of how you\nanalyze or build up a scene like this, at least how\nthe ventral stream contributes. And therefore, we call\nthat core recognition,",
    "start": "968660",
    "end": "976500"
  },
  {
    "text": "which I defined as a central\n10 degrees of visual field, 100 to 200 millisecond\nviewing duration.",
    "start": "976500",
    "end": "981503"
  },
  {
    "text": "And again, it's not all\nof object recognition, but we think it's a\ngood starting point. And a way that we probably got\ninto this is because of a rapid",
    "start": "981504",
    "end": "988970"
  },
  {
    "text": "serial visual presentation\nmovies from the 70's. Molly Potter showed\nthis really nicely. This is a movie that I've\nbeen showing for 15 years now.",
    "start": "988970",
    "end": "996290"
  },
  {
    "text": "Notice that this is just\na sequence of images where there is typically one\nor more foreground objects. And you should be quickly\nmapping those to memory,",
    "start": "996290",
    "end": "1002962"
  },
  {
    "text": "even though I'm not\ntelling you what to expect. Like Leaning Tower\nof Pisa, right, I'm not going to tell you that\nyou're going to see Star Wars",
    "start": "1002962",
    "end": "1008230"
  },
  {
    "text": "characters-- well, I just did. But you quickly are\nable to map those things to some noun or even a more\nprecise subordinate noun.",
    "start": "1008230",
    "end": "1016090"
  },
  {
    "text": "I know this is Yoda. So our ability to do that,\nwe're very, very good at that. Notice you didn't need\na lot of pre-cueing,",
    "start": "1016090",
    "end": "1022660"
  },
  {
    "text": "yet you're still\nable to do that. And that is really what\nfascinates us about vision and object recognition\nin particular.",
    "start": "1022660",
    "end": "1028699"
  },
  {
    "text": "Even without featural\nattention or pre-cueing, you're able to do a remarkable\namount of processing. And I think that's a great\ndemonstration of that.",
    "start": "1028700",
    "end": "1036020"
  },
  {
    "text": "And just to quantify\nthis for you, because sometimes\npeople say, well you're showing it too short. Your vision system\ndoesn't do much.",
    "start": "1036020",
    "end": "1042220"
  },
  {
    "text": "Here's an eight-way\ncategorization task I'll show you later under\nrange of transformation. These are just\nthe example images",
    "start": "1042220",
    "end": "1048250"
  },
  {
    "text": "of eight different\ncategories of objects. It doesn't really matter\nwhat I much do here, you get a very similar curve.",
    "start": "1048250",
    "end": "1053500"
  },
  {
    "text": "And that is, you get most\nof the performance gain in about the first\n100 milliseconds. This is accuracy, you're\nabout 85% correct.",
    "start": "1053500",
    "end": "1059840"
  },
  {
    "text": "This is a challenging task,\nas I'll show you earlier. It looks easy here, but\nit's quite challenging. 85% correct, if I let you\nlook at the image longer,",
    "start": "1059840",
    "end": "1066070"
  },
  {
    "text": "up to two seconds, you can\nbump up to around 90's. So there is some gain with\nlonger viewing duration,",
    "start": "1066070",
    "end": "1071410"
  },
  {
    "text": "but you get-- chance is 50, so you\nget this huge ability. And we're not the\nfirst to show this.",
    "start": "1071410",
    "end": "1076810"
  },
  {
    "text": "This is just to show you\nin our own kind of task that the data I'm going\nto tell you about, where we show the image for\n100 or 200 milliseconds,",
    "start": "1076810",
    "end": "1083470"
  },
  {
    "text": "this is the typical\nprimate viewing duration that I pin this on. We use this for\nreasons of efficiency.",
    "start": "1083470",
    "end": "1089290"
  },
  {
    "text": "But you see, the performance\nis similar across that time. You get a lot done. Your visual system does a lot\nof work in that first glimpse.",
    "start": "1089290",
    "end": "1095920"
  },
  {
    "text": "And that's core recognition that\nwe are trying to study here. And I know it's not all\nof object recognition or all of vision,\nbut it's now, we",
    "start": "1095920",
    "end": "1102669"
  },
  {
    "text": "think, a much more\ndefined domain that we can make progress on. And that's what we've\nbeen working on. And that's essentially what\nI'm going to talk about today.",
    "start": "1102670",
    "end": "1108620"
  },
  {
    "text": "So think of vision,\nobject recognition, within that core recognition. This is David Marr.",
    "start": "1108620",
    "end": "1113950"
  },
  {
    "text": "David and Tommy Poggio, I\nstudied with a long time. And Tommy wrote the introduction\nto David's-- if you guys haven't read this book, Vision--",
    "start": "1113950",
    "end": "1120200"
  },
  {
    "text": "has anybody, guys\nknow this book? It's really a classic\nbook in our field. It's the first\ncouple chapters that are the part you\nshould really read.",
    "start": "1120200",
    "end": "1126950"
  },
  {
    "text": "That's the best\npart of the book. And one of the things that\nyou take from this book, that I think David\nand Tommy helped to lay out a long time\nago, is that there",
    "start": "1126950",
    "end": "1133490"
  },
  {
    "text": "is this challenge of level.  I think one of the\nthings I take from this",
    "start": "1133490",
    "end": "1139060"
  },
  {
    "text": "is, they would try to\ndefine three clean levels. It turns out not to be\nthis clean in practice.",
    "start": "1139060",
    "end": "1144130"
  },
  {
    "text": "But there's one level called\ncomputational theory, what's the goal, what's appropriate,\nwhat's the logic, and by what strategy\ncan it be carried out.",
    "start": "1144130",
    "end": "1150992"
  },
  {
    "text": "There's another\nlevel which is, OK, now once you decide that, how\nshould you represent the data? How can you implement\nan algorithm to do it?",
    "start": "1150992",
    "end": "1156850"
  },
  {
    "text": "And then there's this\nactually, how do you run it, how do you build it in hardware? And neuroscientists often\ncome in, they're like,",
    "start": "1156850",
    "end": "1162130"
  },
  {
    "text": "I'm going to study\nneurons and it's sort of like jumping into your\niPhone and saying, I'm going to study transistors. They often tend to start\nat the hardware level.",
    "start": "1162130",
    "end": "1168370"
  },
  {
    "text": "And I think that's the biggest\nlesson you take from this like, oh wait, there's\nsomething going on here, these transistors are flying. And you make some\nstory about it if you",
    "start": "1168370",
    "end": "1174090"
  },
  {
    "text": "were recording from\nthe brain or measuring transistors in my iPhone. But I think the important\npoint to take from this",
    "start": "1174090",
    "end": "1179590"
  },
  {
    "text": "is it helps to start\nthinking about what's the point of the system. What might it be doing? How might you\nsolve that problem?",
    "start": "1179590",
    "end": "1185549"
  },
  {
    "text": "And that leads you\nthen to algorithm. And then you think\nabout representations. So it's sort of a\ntop down approach, rather than just\ndigging into the brain",
    "start": "1185550",
    "end": "1191380"
  },
  {
    "text": "and hoping that the\nanswers will emerge. So I'm going to try to give\nyou that top down approach",
    "start": "1191380",
    "end": "1196746"
  },
  {
    "text": "in this problem that\nI'm talking about. I've already given you a\nbit of it by introducing you to the problem. I'll say a little bit more about\nthat and step down a little bit",
    "start": "1196746",
    "end": "1203399"
  },
  {
    "text": "this way. And so this kind of\nthinking, I think, is important to\nmaking progress in how",
    "start": "1203400",
    "end": "1208960"
  },
  {
    "text": "the brain computes things. So here's a related slide\nthat I made a long time ago that, again, I\npulled out for you",
    "start": "1208960",
    "end": "1214235"
  },
  {
    "text": "guys, that I think helps\nbridge between what I just said about the Marr\nlevels of analysis and whether you're a\nneuroscientist or cognitive",
    "start": "1214235",
    "end": "1220240"
  },
  {
    "text": "scientist, and are a computer\nvision or machine learning person. So the first is, what is the\nproblem we're trying to solve? So that's Marr\ncomputational level one.",
    "start": "1220240",
    "end": "1227320"
  },
  {
    "text": "So computational vision--\nnow operationally, you'll hear folks\nin machine learning, they might say, well, there's\nsome benchmarks, that's good.",
    "start": "1227320",
    "end": "1233948"
  },
  {
    "text": "There's a ImageNet\nChallenge or whatever challenge they want to solve. Sometimes they'll say,\nwell the brain solves it.",
    "start": "1233948",
    "end": "1239620"
  },
  {
    "text": "That's not good because\nthey didn't really define the problem. Neuroscientists\nwill say, well, it's something like\nperception or behavior",
    "start": "1239620",
    "end": "1246259"
  },
  {
    "text": "or there's some sort of\nbehavior that they imagined, although characterizing\nthat behavior is not usually\ntheir primary goal.",
    "start": "1246260",
    "end": "1253750"
  },
  {
    "text": "But I think there is at least\nsome progress in that regard. Now what does a\nsolution look like?",
    "start": "1253750",
    "end": "1259128"
  },
  {
    "text": "This is really just to\ntalk about language. So useful image representations\nfor machine learning, like what",
    "start": "1259129",
    "end": "1264510"
  },
  {
    "text": "we might call features-- but neuroscientists will talk\nabout explicit neuronal spiking populations. You heard this in Haim's talk.",
    "start": "1264510",
    "end": "1270070"
  },
  {
    "text": "He was using these\nwords interchangeably. Again, this may be\nobvious to you guys, but I thought it's\nworth going through.",
    "start": "1270070",
    "end": "1275210"
  },
  {
    "text": "So this is like Marr\nlevel two, representation. How do we instantiate\nthese solutions? So this is still\nlevel two algorithms,",
    "start": "1275210",
    "end": "1281920"
  },
  {
    "text": "or mechanisms that actually\nbuild useful feature representations. Neuroscientists will think about\nneuronal wiring and weighting",
    "start": "1281920",
    "end": "1287590"
  },
  {
    "text": "patterns that are actually\nexecuting those algorithms. This is what we think is\na bridging language there.",
    "start": "1287590",
    "end": "1293314"
  },
  {
    "text": "And then there's\nthis deeper level that came up in the\nquestions, which is, how would you construct\nit from the beginning?",
    "start": "1293314",
    "end": "1300070"
  },
  {
    "text": "Learning rules, initial\nconditions, training images, are words that are used here. There is a learning machine.",
    "start": "1300070",
    "end": "1305790"
  },
  {
    "text": "Here, neuroscientists talk\nabout plasticity, architecture, and experience. But again, those are\nsimilar questions just",
    "start": "1305790",
    "end": "1313010"
  },
  {
    "text": "with different language. And I'm doing this because I\nthink the spirit of this course is to try to build these links\nat all these different levels",
    "start": "1313010",
    "end": "1319820"
  },
  {
    "text": "here. OK, so hopefully\nthat kind of helps orient you to how\nwe think about it. Let me just go and say, I\nwant to talk about number one.",
    "start": "1319820",
    "end": "1326480"
  },
  {
    "text": "What is a problem we're trying\nto solve and why is it hard? I said, object\nrecognition is hard",
    "start": "1326480",
    "end": "1331520"
  },
  {
    "text": "and I showed you that MIT\nChallenge and it was difficult. Maybe it's hard because\nthere's lots of objects.",
    "start": "1331520",
    "end": "1337940"
  },
  {
    "text": "Who thinks that's why it's hard? Who thinks that's\nnot why it's hard?",
    "start": "1337940",
    "end": "1343960"
  },
  {
    "text": "You think computers can\nlist a bunch of objects? It's easy, right? This is what I\nsaid about memory,",
    "start": "1343960",
    "end": "1349430"
  },
  {
    "text": "it's a big long list of stuff. Computers are good at that. There's going to be\nthousands of objects. A list of objects is not a\nhard thing for a machine to do.",
    "start": "1349430",
    "end": "1356169"
  },
  {
    "text": "What's hard is that each object\ncan produce an essentially infinite number of images.",
    "start": "1356170",
    "end": "1362429"
  },
  {
    "text": "And so you somehow\nhave to be able to take some samples of certain\nviews or poses of an object,",
    "start": "1362430",
    "end": "1367799"
  },
  {
    "text": "this is a car under\ndifferent poses, and be able to generalize or\nto predict what the car might",
    "start": "1367800",
    "end": "1373690"
  },
  {
    "text": "look like in another view. ",
    "start": "1373690",
    "end": "1379046"
  },
  {
    "text": "This is what's called\nthe invariance problem. and it's due to the fact\nthat, again, there's identity preserving\nimage variation.",
    "start": "1379046",
    "end": "1384345"
  },
  {
    "text": "This is why the bar code\nreader in your supermarket works fine, because the code\nis always laid out very simply.",
    "start": "1384345",
    "end": "1389440"
  },
  {
    "text": "But when you have to\nbe able to generalize across a bunch of conditions,\npotentially things like background clutter, even\nmore severely occlusion, things",
    "start": "1389440",
    "end": "1396310"
  },
  {
    "text": "you heard from Gabriel, or you\nmay even want to generalize across the class of cars\nwhere the cars have slightly different geometry but\nthey're still cars,",
    "start": "1396310",
    "end": "1402960"
  },
  {
    "text": "these kind of generalizations\nare what make the problem hard. So I'm lumping them\nall together in what we call the invariance problem.",
    "start": "1402960",
    "end": "1410019"
  },
  {
    "text": "Many of you in the room know\nthis is the hard problem. And I think that hopefully\nit fixes ideas of, that's",
    "start": "1410020",
    "end": "1417674"
  },
  {
    "text": "what you should think about. It's not the number of\nobjects, but it's the fact that it has to deal with\nthat invariance problem. ",
    "start": "1417674",
    "end": "1425230"
  },
  {
    "text": "Haim was talking\nabout manifolds, and this is my version of that. So this is to introduce\nyou to the problem of,",
    "start": "1425230",
    "end": "1431792"
  },
  {
    "text": "why that invariance problem-- what it looks like\nor feels like. I'm not going to give you\nmath on how to solve it.",
    "start": "1431792",
    "end": "1436910"
  },
  {
    "text": "It's just a geometric\nfeel for the problem. So if you imagine\nyou're a camera-- or your retina,\nwhich is capturing",
    "start": "1436910",
    "end": "1443530"
  },
  {
    "text": "an image of an object,\nlet's call this a person, I think I called him Joe. So when you see this image of\nJoe, and this is the retina,",
    "start": "1443530",
    "end": "1450596"
  },
  {
    "text": "so now this is a state space of\nwhat's going on in your retina. So it's a million\nretinal ganglion cells.",
    "start": "1450596",
    "end": "1456110"
  },
  {
    "text": "Think of them as being an\nanalog value out of each, so this is a million\ndimensional state space. So when you see\nthis image of Joe,",
    "start": "1456110",
    "end": "1462130"
  },
  {
    "text": "he activates every retinal\nganglion cell, some a lot, some a little, but he's\nsome point of that million dimensional space.",
    "start": "1462130",
    "end": "1467970"
  },
  {
    "text": "OK, everybody with me? If everybody's heard all this\nbefore and wants me to go on, everybody wave your\nhand and I'll move on.",
    "start": "1467970",
    "end": "1474526"
  },
  {
    "text": "AUDIENCE: No, it's good. JAMES DICARLO: Keep going, OK. So the basic idea is that if\nJoe undergoes a transformation,",
    "start": "1474526",
    "end": "1480940"
  },
  {
    "text": "like a change in\npose, what that does is, it's only a 1\ndegree of freedom I'm turning under the hood\none of those latent variables.",
    "start": "1480940",
    "end": "1487910"
  },
  {
    "text": "If I had a graphics\nengine, I'm changing the pose of latent variables. It's only one knob that\nI'm turning, so to speak.",
    "start": "1487910",
    "end": "1494090"
  },
  {
    "text": "And that means there's\none line through here as Joe projects across\nthese different images here.",
    "start": "1494090",
    "end": "1499180"
  },
  {
    "text": "And I'm ignoring\nnoise and things. This is just the\ndeterministic mapping onto the retinal ganglion cells. So Joe goes--",
    "start": "1499180",
    "end": "1504669"
  },
  {
    "text": "[MOVING NOISE] --and he goes over here. And if I turn the other\nknob, he goes over here. And so I could imagine,\nif I turned those two",
    "start": "1504670",
    "end": "1510565"
  },
  {
    "text": "knobs of two axis\nopposed always possible and plotted this in the million\ndimensional state space, there'd be this curved\nup sheet of points,",
    "start": "1510565",
    "end": "1517550"
  },
  {
    "text": "which you could think of\nJoe's identity manifold over those two degrees\nof view change. It's only two dimensions,\nit's hard to start",
    "start": "1517551",
    "end": "1523152"
  },
  {
    "text": "showing more than this. But it's this curved\nup sheet of points. Everybody with me so far? You don't actually\nget to see all those.",
    "start": "1523152",
    "end": "1530080"
  },
  {
    "text": "You could imagine a machine\nactually running them all, but you don't really\nget to see them. You've got to get\nsamples of them. But there's some underlying\nmanifold structure here.",
    "start": "1530080",
    "end": "1537500"
  },
  {
    "text": "Now, what's interesting and\nwhat's important to point out is that this thing,\neven though I've drawn it and it's a little curve,\nbut it's highly complicated",
    "start": "1537500",
    "end": "1544930"
  },
  {
    "text": "in this native pixel space. It's all curved up and\nbending all over the place.",
    "start": "1544930",
    "end": "1550150"
  },
  {
    "text": "And the reason that\nmatters, and this is what Haim\nintroduced you to, is that if you want to be\nable to separate Joe",
    "start": "1550150",
    "end": "1557950"
  },
  {
    "text": "from another object, say\nnot Joe, another person say, then you need a representation.",
    "start": "1557950",
    "end": "1563460"
  },
  {
    "text": "I showed you retinal\nganglion cells. This is another\nimaginary state space where you can take simple tools\nto extract the information.",
    "start": "1563460",
    "end": "1571150"
  },
  {
    "text": "And the simple tools\nthat we like to use are linear classifiers. But you can use\nother simple tools.",
    "start": "1571150",
    "end": "1576670"
  },
  {
    "text": "Haim used the exact\nsame description to you guys in his talk, that you\nhave some linear decoder on the state space that can\nsay, oh, they can separate",
    "start": "1576670",
    "end": "1585370"
  },
  {
    "text": "cleanly Joe from not Joe. So these manifolds\nare nicely separated by a separating hyperplane. That's what these tools tend to\ndo is they like to cut planes.",
    "start": "1585370",
    "end": "1592480"
  },
  {
    "text": "This is one thing\nthey like to do, or they want to find\nlocations or regions, like compact regions\nin this space,",
    "start": "1592480",
    "end": "1597520"
  },
  {
    "text": "depending on what\nkind of tool you use. But you don't want\nthe tool having to do all kinds of complicated\ntracing through this space.",
    "start": "1597520",
    "end": "1603640"
  },
  {
    "text": "That's basically the\noriginal problem itself. So what you need is, you\nhave a simple tool box, which we think of as\ndownstream neurons.",
    "start": "1603640",
    "end": "1610059"
  },
  {
    "text": "So a linear classifier,\nas an approximation, it's like a dot product. It's a weighted sum, which is\nwhat we think, neuroscientists,",
    "start": "1610060",
    "end": "1615880"
  },
  {
    "text": "of downstream neurons doing. So it's a weighted sum. And if we want an\nexplicit representation",
    "start": "1615880",
    "end": "1622612"
  },
  {
    "text": "in some neural\nstate space, then we need to be able to take\nweighted sums of some population representation to be able to\nseparate Joe from not Joe,",
    "start": "1622612",
    "end": "1629530"
  },
  {
    "text": "and Sam from Jill, and\neverything from everything else that we want to separate. If we had such a space\nof neural population,",
    "start": "1629530",
    "end": "1636550"
  },
  {
    "text": "we'd call that a\ngood set of features or an explicit representation\nof object shape. And for any\naficionados here, it's",
    "start": "1636550",
    "end": "1642880"
  },
  {
    "text": "not just cleanly\nlinear separation, it's actually being\nable to find this",
    "start": "1642880",
    "end": "1648040"
  },
  {
    "text": "with a low number of\ntraining examples. So that turns out\nto be important. But it helps to fix ideas to\nthink about linear separation,",
    "start": "1648040",
    "end": "1655420"
  },
  {
    "text": "ideally with a low number\nof training examples. So that's a good representation. And notice, I'm starting\nto mix up terms here.",
    "start": "1655420",
    "end": "1663870"
  },
  {
    "text": "I am assuming, when\nI talk about shape, that that will map\ncleanly to identity, or what you might call\nbroadly, category.",
    "start": "1663870",
    "end": "1669610"
  },
  {
    "text": "That's another topic I won't\ntalk about, if you just think about the shape of Joe,\nor separating one geometry",
    "start": "1669610",
    "end": "1675789"
  },
  {
    "text": "from another. Now, here's a simulation that\nmy first graduate student, Dave Cox, who's now at Harvard, did.",
    "start": "1675790",
    "end": "1681850"
  },
  {
    "text": "This is a number of years old. This takes these two\nface objects, render them under changes, and view.",
    "start": "1681850",
    "end": "1688250"
  },
  {
    "text": "And then he actually\nsimulated the manifolds in a 14,000 dimensional space.",
    "start": "1688250",
    "end": "1695779"
  },
  {
    "text": "And then he wanted\nto visualize it. And because we\nwanted to try to make the point that these\nmanifolds of these two objects",
    "start": "1695780",
    "end": "1702250"
  },
  {
    "text": "are highly curved\nand highly tangled, this is a three\ndimensional view. Remember, it's sitting on a\n14,000 dimensional simulation",
    "start": "1702250",
    "end": "1708220"
  },
  {
    "text": "space. You can't view that space. This is a three\ndimensional view of it. And the point is that it's\nlike two sheets of paper",
    "start": "1708220",
    "end": "1715419"
  },
  {
    "text": "being all crumpled up together\nand they're not fused. They look fused here because\nit's in three dimensions.",
    "start": "1715420",
    "end": "1721720"
  },
  {
    "text": "But they're not actually fused. But they're complicated,\nyou can't easily",
    "start": "1721720",
    "end": "1726730"
  },
  {
    "text": "find a separating hyperplane\nto separate these two objects. We call these tangled\nobject manifolds.",
    "start": "1726730",
    "end": "1733149"
  },
  {
    "text": "And really, they're tangled\ndue to image variation. Remember, if I didn't change\nthose knobs of view or position",
    "start": "1733150",
    "end": "1739050"
  },
  {
    "text": "or scale, there would just\nbe two points in the space and it would be easy. That's the easy problem\nof listing objects.",
    "start": "1739050",
    "end": "1744192"
  },
  {
    "text": "But if they have to undergo\nall this transformation, they become these\ncomplicated structures that need to be untangled\nfrom each other.",
    "start": "1744192",
    "end": "1750440"
  },
  {
    "text": "So the problem\nthat's being solved is, you have this\nretina sampling data, like a camera on the front\nend, where things look",
    "start": "1750440",
    "end": "1756699"
  },
  {
    "text": "complicated with respect\nto the latent variables, in this case shape or\nidentity, Sam or Joe.",
    "start": "1756699",
    "end": "1761885"
  },
  {
    "text": "And that they somehow are\ntransformed, as Haim mentioned, they're transformed by some\nnon-linear transformation, some other neural population\nstate space, shown here, where",
    "start": "1761885",
    "end": "1770440"
  },
  {
    "text": "the things look more like this. The latent variable\nstructure is more explicit, that you can easily take things\nlike separating hyperplanes",
    "start": "1770440",
    "end": "1777159"
  },
  {
    "text": "to identify things like\nshape, which again, roughly corresponds to identity or\nother latent parameters, like position and scale.",
    "start": "1777160",
    "end": "1782980"
  },
  {
    "text": "You maybe haven't thrown\naway all these other latent parameters. And if I have time, I'll\nsay something about that so you don't just get identity.",
    "start": "1782980",
    "end": "1789200"
  },
  {
    "text": "But if you can\nuntangle this, you would have a very nice\nrepresentation with regard to those originally\nlatent parameters. That's the dream of\nwhat you'd like to do.",
    "start": "1789200",
    "end": "1795920"
  },
  {
    "text": "It's like reverse\ngraphics, if you will. So this is what we call an\nuntangled explicit object",
    "start": "1795920",
    "end": "1802360"
  },
  {
    "text": "information. And we think it lives\nsomewhere in the brain, at least to some degree. And I'll show you the\nevidence for that later on.",
    "start": "1802360",
    "end": "1807950"
  },
  {
    "text": "So what you have then is you\nhave a poor encoding basis, the pixel space. And somewhere in the brain\nis a powerful encoding basis,",
    "start": "1807950",
    "end": "1813820"
  },
  {
    "text": "a good set of features. And as Haim mentioned,\nas I already said, this must be a\nnon-linear transformation",
    "start": "1813820",
    "end": "1819400"
  },
  {
    "text": "because the linear\ntransformations are just rotations of that\noriginal space. So now let's go down\nto-- actually this",
    "start": "1819400",
    "end": "1825337"
  },
  {
    "text": "would be Marr level three. Let's go to instantiation. Let's get into\nthe hardware here. We're supposed to be\ntalking about brains. So I'm going to give you a\ntour of the ventral stream.",
    "start": "1825337",
    "end": "1832450"
  },
  {
    "text": "So we would love to know\nhow this brain solves it. This is the human brain. This is a non-human primate.",
    "start": "1832450",
    "end": "1838070"
  },
  {
    "text": "This is not shown to scale. This is blown up\nto show you it's a similar structure,\ntemporal lobe, frontal lobes, occipital lobe.",
    "start": "1838070",
    "end": "1843992"
  },
  {
    "text": "There is a non-human primate. We like this model for\na number of reasons. One reason that we\nlike it is that they",
    "start": "1843992",
    "end": "1850040"
  },
  {
    "text": "are very visual\ncreatures, their acuity is very well matched to ours. In fact, even their object\nrecognition abilities",
    "start": "1850040",
    "end": "1855279"
  },
  {
    "text": "are actually quite\nsimilar to our own. This may be surprising\nto you, but let me just show you some data for that.",
    "start": "1855280",
    "end": "1861310"
  },
  {
    "text": "This is actually data from\nRishi Rajalingham, in my lab. It says, impressed,\nbut this just came out.",
    "start": "1861310",
    "end": "1867700"
  },
  {
    "text": "This is the confusion\nmatrix patterns of humans trying to\ndiscriminate different objects under those transformations\nthat I showed you earlier,",
    "start": "1867700",
    "end": "1874648"
  },
  {
    "text": "where they're not\njust seeing images, but they have to deal\nwith these invariances. And this is rhesus monkey data\ntrying to do the same thing.",
    "start": "1874649",
    "end": "1882250"
  },
  {
    "text": "And the task goes, I'll\ngive you a test image and then you get choice images. Was it a car or a dog? I'll show you an image, what\nchoice was it, a dog or a tree?",
    "start": "1882250",
    "end": "1888670"
  },
  {
    "text": "And you're trying to entertain\nmany objects all at once, and you get an image under\nsome unpredictable view",
    "start": "1888670",
    "end": "1894482"
  },
  {
    "text": "and unpredictable\nbackground, and then you have to make a choice. So this is the\nconfusion difficulty.",
    "start": "1894482",
    "end": "1899510"
  },
  {
    "text": "And when you look at\nthis, it's intuitive that these are sort\nof geometry similar. Camel is confused with dog, and\ntank is confused with truck,",
    "start": "1899510",
    "end": "1908230"
  },
  {
    "text": "and that's true of both\nmonkeys and humans. And to some level, this\nshouldn't be surprising to you.",
    "start": "1908230",
    "end": "1914377"
  },
  {
    "text": "The same tasks that are\ndifficult for humans are difficult for monkeys\nbecause probably they share very similar\nprocessing structures.",
    "start": "1914377",
    "end": "1923000"
  },
  {
    "text": "They don't have to bring\nin a bunch of knowledge about tanks are driven by people\nor that, they just have to say,",
    "start": "1923000",
    "end": "1928370"
  },
  {
    "text": "was there a tank or a truck. And under those conditions,\nthey make very similar patterns of confusion. And these patterns are\nvery different from those",
    "start": "1928370",
    "end": "1935140"
  },
  {
    "text": "that you get when\nyou run classifiers on pixels or low level\nvisual simulations.",
    "start": "1935140",
    "end": "1940679"
  },
  {
    "text": "But they're very similar\nto each other, in fact, are statistically\nindistinguishable, monkeys and humans, on these\nkind of patterns of confusion.",
    "start": "1940680",
    "end": "1947300"
  },
  {
    "text": "OK, so that's one reason we like\nthis subject, the monkey model, is that the behavior is very\nwell matched to the humans.",
    "start": "1947300",
    "end": "1954550"
  },
  {
    "text": "The other reason is that we\nknow from a lot of previous work that I alluded to, that some\nstudies have shown that lesions",
    "start": "1954551",
    "end": "1960470"
  },
  {
    "text": "in these parts of the brain can\nlead to deficits in recognition task. So again, we think the ventral\nstream solves recognition.",
    "start": "1960470",
    "end": "1967870"
  },
  {
    "text": "So we know a weak word\nmodel of where to look, we just don't know exactly\nwhat's going on there.",
    "start": "1967870",
    "end": "1973070"
  },
  {
    "text": "Just to orient\nyou, these ventral areas, V1, V2, V4, and infer\ntemporal cortex, or IT cortex--",
    "start": "1973070",
    "end": "1979010"
  },
  {
    "text": "IT projects anatomically\nto the frontal lobe to regions involved in\ndecision and action, and around the bend to the\nmedial temporal lobe to regions",
    "start": "1979010",
    "end": "1985986"
  },
  {
    "text": "involved in formation\nof long-term memory. Because these are\nmonkeys and not humans, and Gabriel mentioned this\nin his talk, we can go in",
    "start": "1985986",
    "end": "1992840"
  },
  {
    "text": "and we can record\nfrom their brains, and we can perturb neural\nactivity in their brains directly. And we can do that\nin a systematic way.",
    "start": "1992840",
    "end": "1998600"
  },
  {
    "text": "This is the advantage of\nan animal model as opposed to a human model. OK, as neuroscientists\nnow, we've",
    "start": "1998600",
    "end": "2004090"
  },
  {
    "text": "taken a problem,\ntranslated it to behavior, taken that behavior into\na species we can study, we know roughly where\nto look, and now",
    "start": "2004090",
    "end": "2010060"
  },
  {
    "text": "we want to try to\nunderstand what's going on. So as engineers, we take these\ncurled up sheets of cortex",
    "start": "2010060",
    "end": "2015135"
  },
  {
    "text": "and think of them as I've\nalready been showing you, as populations of neurons. So there's millions of neurons\non each of these sheets.",
    "start": "2015135",
    "end": "2021580"
  },
  {
    "text": "I'll give you numbers\non a slide coming up. There's some sort of processing\nthat may be common here, I put these T's\nin, there might be",
    "start": "2021580",
    "end": "2027546"
  },
  {
    "text": "some common cortical algorithm\nprocessing forward this way. There's also\ninter-cortical processing.",
    "start": "2027546",
    "end": "2032720"
  },
  {
    "text": "And there's also some feedback\nprocessing going on in here. So all that's schematically\nillustrated in this slide that I'll keep\nbringing up here when",
    "start": "2032720",
    "end": "2038679"
  },
  {
    "text": "we talk about these different\nlevels of the ventral stream. Now I'm most going to be\ntalking about IT cortex here at the end.",
    "start": "2038680",
    "end": "2044200"
  },
  {
    "text": "Why do we call these\ndifferent areas? One reason is that there's\na complete retina topic map, a map of the whole\nvisual space in each",
    "start": "2044200",
    "end": "2050080"
  },
  {
    "text": "of these different levels. In retina, there's one. In LGN-- in the thalamus,\nthere's another. In V1, there's another map.",
    "start": "2050080",
    "end": "2055388"
  },
  {
    "text": "In V2, there's another map. In V4, there's another map. In IT, it's less clear\nthat it's retinotopic,",
    "start": "2055389",
    "end": "2060580"
  },
  {
    "text": "we're not even sure\nthat IT is one area. Maybe we'll have time, I'll\nsay more about that detail.",
    "start": "2060580",
    "end": "2067260"
  },
  {
    "text": "So it's not that\nretinotopic in IT, except the most\nposterior parts of IT.",
    "start": "2067260",
    "end": "2072280"
  },
  {
    "text": "But that's why\nneuroscientists divide these into different areas. So a key concept, though,\nfor you computationally is,",
    "start": "2072280",
    "end": "2078610"
  },
  {
    "text": "think of each of these as\na population representation that's retransforming the data\nfrom that complicated space",
    "start": "2078610",
    "end": "2084489"
  },
  {
    "text": "to some nicer space. And it's doing this probably\nin a stepwise, gradual manner.",
    "start": "2084489",
    "end": "2089830"
  },
  {
    "text": "So IT is believed to be\nthat powerful encoding basis that I alluded\nto earlier, where you have these nice\nflattened object manifolds.",
    "start": "2089830",
    "end": "2096023"
  },
  {
    "text": "And I'll show you the\nevidence for that.  This is recently from a\nreview I did that gives",
    "start": "2096024",
    "end": "2102910"
  },
  {
    "text": "more numbers on these things. And I've sized the\nareas according to their relative cortical\narea in the monkey.",
    "start": "2102910",
    "end": "2108920"
  },
  {
    "text": "Here's V1, V2, V4, IT. IT is a complex of areas. And I'm showing you\nthese latencies.",
    "start": "2108920",
    "end": "2115570"
  },
  {
    "text": "These are the\naverage latencies in these different visual areas.",
    "start": "2115570",
    "end": "2120760"
  },
  {
    "text": "You can see, it's\nabout 50 milliseconds from when an image\nhits the retina until you get activity in V1. 60 in V2, 70-- there's\nabout a 10 millisecond step",
    "start": "2120760",
    "end": "2127942"
  },
  {
    "text": "across these different areas. So it's about 100 millisecond\nlag between an image it's here, and you start to see changes\nin activity at this level",
    "start": "2127942",
    "end": "2134800"
  },
  {
    "text": "up here that I'm referring to. When I say IT, I'm referring\nto AIT and CIT together.",
    "start": "2134800",
    "end": "2140440"
  },
  {
    "text": "That's my usage of the\nword IT for the aficionados in the room. And that's about 10 million\noutput neurons in IT",
    "start": "2140440",
    "end": "2146680"
  },
  {
    "text": "just to fix numbers. In V1 here, you have like\n37 million output neurons. There's about 200 million\nneurons in V1, similar in V2.",
    "start": "2146680",
    "end": "2154460"
  },
  {
    "text": "And many of you probably\nheard about other parts of the visual system. Here's MT, many of you\nprobably heard about MT.",
    "start": "2154460",
    "end": "2160970"
  },
  {
    "text": "So you can see it's tiny\ncompared to some of these areas that I'm talking about here. I'm going to show\nyou some neural dam--",
    "start": "2160970",
    "end": "2166820"
  },
  {
    "text": "I'm just going to\ngive you a brief tour of these different areas, so\nbrief, it's almost cartoonish. But at least those of\nyou who haven't seen this",
    "start": "2166820",
    "end": "2173026"
  },
  {
    "text": "should at least be exposed. So in the retina-- you guys know in\nthe retina there's a bunch of cell\nlayers in the retina.",
    "start": "2173026",
    "end": "2178862"
  },
  {
    "text": "The retina is a\ncomplicated device. I think of it as a\nbeautiful camera. So you're down in the retina.",
    "start": "2178862",
    "end": "2183904"
  },
  {
    "text": "To me, the key\nthing in the retina is in the end you've got some\ncells that are going to project back along the optic nerve. So these are the\nretinal ganglion cells,",
    "start": "2183904",
    "end": "2190450"
  },
  {
    "text": "they actually live\non the surface. The light comes through,\nphoto receptors are here, there is processing in\nthese intermediate layers,",
    "start": "2190450",
    "end": "2195850"
  },
  {
    "text": "and then there's a bunch of\nretinal ganglion cell types. There's thought to be\nabout 20 types or so. The original\nphysiology, there are",
    "start": "2195850",
    "end": "2202780"
  },
  {
    "text": "two functional central\ntypes where they have on center or off center. Let's take an on center\ncell, you shine light",
    "start": "2202780",
    "end": "2209380"
  },
  {
    "text": "in the middle of\na spot-- now this is a tiny little\nspot on the retina, the size depends on where\nyou are in the visual field.",
    "start": "2209380",
    "end": "2216127"
  },
  {
    "text": "But you shine a little bit\nof light in the center, the response goes up. See the spike rate\ngoing up here. Put light in the surround,\nthe response rate goes down.",
    "start": "2216127",
    "end": "2222790"
  },
  {
    "text": "So it has an on center,\noff surround profile. And then there's\na flip type here.",
    "start": "2222790",
    "end": "2228610"
  },
  {
    "text": "So that's the basic\nfunctional type. When you think\nabout the retina, it is tiled with all of\nthese point detectors that",
    "start": "2228610",
    "end": "2233920"
  },
  {
    "text": "have some nice center\nsurround effects. There's some nice gain control\nfor overall illumination",
    "start": "2233920",
    "end": "2239620"
  },
  {
    "text": "conditions. But my toy model\nof the retina, it's basically a really nice\npixel map coming back down",
    "start": "2239620",
    "end": "2247410"
  },
  {
    "text": "the optic track to the LGN. OK, I'm going to skip the\nLGN and go straight to V1.",
    "start": "2247410",
    "end": "2254250"
  },
  {
    "text": "People have known for a\nlong time, functionally V1 cells they have sensitivity\nto especially edges.",
    "start": "2254250",
    "end": "2262349"
  },
  {
    "text": "They have what's called\norientation selectivity. Hopefully this isn't\nnew to you guys. Here's a simple cell in V1.",
    "start": "2262350",
    "end": "2268752"
  },
  {
    "text": "If you shine a bar\nof a light on it inside it's receptive field-- does everyone know what\na receptive field is? I don't want to go--",
    "start": "2268752",
    "end": "2274193"
  },
  {
    "text": "OK. It's OK if you\nask, because I want to make sure you guys are OK. So the receptive field, you\nshine a bar light in it,",
    "start": "2274193",
    "end": "2279974"
  },
  {
    "text": "turn it on in the\nright orientation, gives good response\nout of the cell. Move it off this position,\nnow not much response,",
    "start": "2279974",
    "end": "2286545"
  },
  {
    "text": "there's a little bit of\nan off response here. Change the orientation,\nnothing happens. Full field illumination,\nnothing happens.",
    "start": "2286545",
    "end": "2292860"
  },
  {
    "text": "OK, so this is\ncalled selectivity. That is, there's some\nportion of the image space that it cares about.",
    "start": "2292860",
    "end": "2299040"
  },
  {
    "text": "It doesn't just\nrespond to any light at that spot like the pixel\nwise, retinal ganglion cell",
    "start": "2299040",
    "end": "2305030"
  },
  {
    "text": "would. So now there's this\ncomplex cell that's also in V1, which\nmaintains this orientation",
    "start": "2305030",
    "end": "2312700"
  },
  {
    "text": "selectivity across a\nchange in position, as shown here, also across\nsome changes in scale.",
    "start": "2312700",
    "end": "2318460"
  },
  {
    "text": "So it maintains it, meaning\nthat you have this tolerance-- so that's called position\ntolerance, for position.",
    "start": "2318460",
    "end": "2324360"
  },
  {
    "text": "You can move the bar around it,\nstill likes that oriented bar. But you change its\nangle and it goes down,",
    "start": "2324360",
    "end": "2330420"
  },
  {
    "text": "so it still maintains\nthe same selectivity here but it has some tolerance. So you get this build up of\nsome orientation sensitivity",
    "start": "2330420",
    "end": "2337020"
  },
  {
    "text": "followed by some tolerance. And there are models\nfrom Hubel and Wiesel that they thought that\nyou could build this first",
    "start": "2337020",
    "end": "2342510"
  },
  {
    "text": "and then you build\nthese out of these, that's the simple version. And here they are. These are the Hubel\nand Wiesel models,",
    "start": "2342510",
    "end": "2348270"
  },
  {
    "text": "how you build these and like\noperators to build selectivity from pixel-wise cells with\nan and like operator lining",
    "start": "2348270",
    "end": "2354538"
  },
  {
    "text": "these up correctly. You can imagine oriented\ntuned cells built this way. There's evidence for\nthis in physiology",
    "start": "2354539",
    "end": "2360120"
  },
  {
    "text": "that this is how\nthese are constructed. The tolerance of\nthese complex cells is thought to build by a\ncombination of simple cells.",
    "start": "2360120",
    "end": "2367230"
  },
  {
    "text": "And there's some\nevidence for this. And this is again, all the\nway from Hubel and Wiesel, who won a Nobel Prize for this\nand related work in the 1960s.",
    "start": "2367230",
    "end": "2375030"
  },
  {
    "text": "And then there were a bunch\nof computational models that are really\ninspired by this and I",
    "start": "2375030",
    "end": "2380460"
  },
  {
    "text": "think are still the core\nmodels of how the system works. And some of the original\nones that were written down are Fukushima in\nthe '80s, and then",
    "start": "2380460",
    "end": "2387900"
  },
  {
    "text": "Tommy Poggio and others built\nwhat's called an HMAX Model, you guys have\nprobably heard about, that's off of these\nsimilar ideas, much more",
    "start": "2387900",
    "end": "2394440"
  },
  {
    "text": "refined and much more\nmatched to the neural data. But I'm just try to\npoint out that these kind",
    "start": "2394440",
    "end": "2399930"
  },
  {
    "text": "of physiological\nobservations are what inspired this class of\nlargely feedforward models",
    "start": "2399930",
    "end": "2404960"
  },
  {
    "text": "that you heard about much today. So that's a brief tour of V1.",
    "start": "2404960",
    "end": "2411840"
  },
  {
    "text": "Now, what's going on in V2? For a long time,\npeople thought it was hard to tell the\ndifference from V1 and V2.",
    "start": "2411840",
    "end": "2417359"
  },
  {
    "text": "And I just thought\nI'd show you guys, this is a slide I stuck\nin, this is from Eero Simoncelli and Tony Movshon. And I think you guys have Eero\nteaching in the course a bit",
    "start": "2417360",
    "end": "2424678"
  },
  {
    "text": "later, so he may\nsay some of this. But V2 cells have some\nsensitivity to natural image",
    "start": "2424678",
    "end": "2433050"
  },
  {
    "text": "statistics that V1 cells don't. And maybe I'll see if I\ncan take you through this. So the way that they did\nthis is you can simulate--",
    "start": "2433050",
    "end": "2442680"
  },
  {
    "text": "so this is all driven off of\nwork that Eero and Tony have done-- especially Eero has done\non texture synthesis.",
    "start": "2442680",
    "end": "2448390"
  },
  {
    "text": "So you have these\noriginal images, and if you run them through a\nbunch of V1-like filter banks, and then you take a new\nimage, a random seed, which",
    "start": "2448390",
    "end": "2456540"
  },
  {
    "text": "is like white noise,\nand you try to make sure that it would\nactivate populations of V1 cells in a\nsimilar way, there's",
    "start": "2456540",
    "end": "2462530"
  },
  {
    "text": "a large set of images that would\ndo that because you're just doing summary\nstatistics, but these are some examples of them.",
    "start": "2462530",
    "end": "2468340"
  },
  {
    "text": "For this image, this is one\nthat one might look like. So you can see, to you, it\ndoesn't look the same as this. But to V1, these are\nmetamers, they're",
    "start": "2468340",
    "end": "2475230"
  },
  {
    "text": "very similar in the\nsummary statistics in V1. And then you start taking cross\nproducts of these V1 summary",
    "start": "2475230",
    "end": "2481319"
  },
  {
    "text": "statistics and then\nyou try to match those. And what's interesting\nis you start to get something that looks,\ntexture wise, much more",
    "start": "2481320",
    "end": "2486720"
  },
  {
    "text": "like this original image. And this is a big part of\nwhat Eero and others did in that work. And the reason I'm\nshowing you this",
    "start": "2486720",
    "end": "2492198"
  },
  {
    "text": "is that Tony's lab has gone\nand recorded in V1 and V2 with these kinds of stimuli, and\nthe main observation they have",
    "start": "2492198",
    "end": "2498840"
  },
  {
    "text": "is that V1 doesn't care whether\nyou show it this or this. To V1, these are\nboth the same, which",
    "start": "2498840",
    "end": "2506022"
  },
  {
    "text": "says we have the\nsummary statistics for V1 right in terms of\nthe average V1 response. That's all I'm showing you here.",
    "start": "2506022",
    "end": "2511200"
  },
  {
    "text": "The paper, if you want\nit, is much more detailed. But you go to V2 and\nthere's a big difference between this, which V2 cells\nrespond to more, and this,",
    "start": "2511200",
    "end": "2519000"
  },
  {
    "text": "which they respond to less. And really one inference\nyou can take from this is that V2 neurons apply a\nrepeated-- another and like",
    "start": "2519000",
    "end": "2526950"
  },
  {
    "text": "operator on V1. That's a simple inference\nthat these kinds of data seem to support . And they also tell you that\nthese and-like operators,",
    "start": "2526950",
    "end": "2534090"
  },
  {
    "text": "these conjunctions\nof V1 statistics tend to be in the\ndirection of the statistics of the natural world, that's\nnaturalistic statistics.",
    "start": "2534090",
    "end": "2541500"
  },
  {
    "text": "Now lots of controls\nhaven't been done here to narrow in exactly\nwhat kinds ands, but that's the spirit\nof where the field is",
    "start": "2541500",
    "end": "2548280"
  },
  {
    "text": "in trying to understand V2. Everybody thinks\nit has something to do with corners or a\nmore complicated structure. But this is a way that\ncurrent in the field",
    "start": "2548280",
    "end": "2555270"
  },
  {
    "text": "to try to move these image\ncomputing models forward in V1 and V2. And Tony likes to point out that\nthis is one of the strongest",
    "start": "2555270",
    "end": "2562079"
  },
  {
    "text": "differences that you\nsee between V1 and V2, other than the\nreceptive field sizes. So I think that's quite\nsome exciting work if you",
    "start": "2562080",
    "end": "2569460"
  },
  {
    "text": "don't know about it on V2. OK, then you get up into V4\nand things get much murkier.",
    "start": "2569460",
    "end": "2574740"
  },
  {
    "text": "So what's going on in V4? Well, let me just briefly say\nthat one of my post-docs-- this is more recent work just because\nit builds on that earlier work.",
    "start": "2574740",
    "end": "2581770"
  },
  {
    "text": "This is Nicole Rust, when she\nwas a post-doc in the lab, compared V4. She actually compared it to IT.",
    "start": "2581770",
    "end": "2587280"
  },
  {
    "text": "I'll skip that. But she was using these\nSimoncelli scrambled images. These are actually the\ntexture images from--",
    "start": "2587280",
    "end": "2593636"
  },
  {
    "text": "these are the original\nimages and these are the texture versions. So this should look like a\ntextured version of that. You can see that these\nalgorithms don't actually",
    "start": "2593636",
    "end": "2599959"
  },
  {
    "text": "capture the object\ncontent of these images. And what Nicole actually\nshowed is that similar to what",
    "start": "2599959",
    "end": "2606990"
  },
  {
    "text": "you just saw there, in\nthe earlier work like V1, V4 doesn't care about the\ndifferences between these.",
    "start": "2606990",
    "end": "2612360"
  },
  {
    "text": "It responds similarly, as a\npopulation, to this and this, and this and this,\nand this and this. But IT cares a lot\nabout this versus this.",
    "start": "2612360",
    "end": "2620220"
  },
  {
    "text": "So this is just repeating the\nsame theme, the general idea that you have and -like\noperators that we think",
    "start": "2620220",
    "end": "2626402"
  },
  {
    "text": "are aligned along the\nventral stream that are tuned to the\nkind of statistics that you tend to\nencounter in the world.",
    "start": "2626402",
    "end": "2631530"
  },
  {
    "text": "And this is some of the\nevidence for it in V2, and then later in V4, and\nIT, and Nicole's work,",
    "start": "2631530",
    "end": "2637500"
  },
  {
    "text": "if you piece that all together. When you go to a place\nlike V4, remember V4 is now like three levels up.",
    "start": "2637500",
    "end": "2642690"
  },
  {
    "text": "And what does V4 do? Look, this is\nJack's work in 1996. This is from Jack\nGallant when he was",
    "start": "2642690",
    "end": "2648950"
  },
  {
    "text": "working with David Van Essen. And people had some\nideas that maybe there are these certain functions\nthat V4 neurons like,",
    "start": "2648950",
    "end": "2654599"
  },
  {
    "text": "and they would show these-- the same thing people\nhave done in V2, they would show a bunch\nof images like this",
    "start": "2654600",
    "end": "2659781"
  },
  {
    "text": "and figure out, well, does it\nlike these Cartesian gratings or these curved ones. And you know what, you\nget out of this is,",
    "start": "2659781",
    "end": "2665069"
  },
  {
    "text": "you could tell some\nstory about it, but you get a bunch of\nresponses out of it. The color indicates\nthe response.",
    "start": "2665070",
    "end": "2670140"
  },
  {
    "text": "And you kind of look at it, and\npeople would tell some stories, but it really was just\nkind of like tea leaves. Here's a bunch of\ndata, we don't really",
    "start": "2670140",
    "end": "2675604"
  },
  {
    "text": "know what these V4\nneurons were doing. This was a science paper, so\nyou could go back and read it.",
    "start": "2675604",
    "end": "2683170"
  },
  {
    "text": "And then Ed Connor\nand Anitha Pasupathy worked together a\nfew years after that",
    "start": "2683170",
    "end": "2689760"
  },
  {
    "text": "to try to figure out more\nabout what V4 neurons do. And they did things\nlike take images",
    "start": "2689760",
    "end": "2695790"
  },
  {
    "text": "like this, which were\nisolated, and try to cut them into parts, like\ncurved parts, pointy parts, curved, concave, convex.",
    "start": "2695790",
    "end": "2702930"
  },
  {
    "text": "And this was motivated off of\nsome psychology literature. And they would\ndefine these based on the center of the object.",
    "start": "2702930",
    "end": "2709510"
  },
  {
    "text": "So this wasn't an\nimage computable model, it was just a\nbasis set that they built around these\nsilhouette objects.",
    "start": "2709510",
    "end": "2716258"
  },
  {
    "text": "And so they made this basis set\nabout any kind of silhouetted object they like here. They hypothesized\nthat they could",
    "start": "2716259",
    "end": "2721530"
  },
  {
    "text": "fit the responses of V4\nneurons in this basis set. And this was their\nattempt to do it. They could actually\nfit quite well.",
    "start": "2721530",
    "end": "2727369"
  },
  {
    "text": "And that's kind of\nwhat's being shown here. Here's the response\nof a V4 neuron. The color indicates the\ndepth of the response.",
    "start": "2727369",
    "end": "2732790"
  },
  {
    "text": "You can see, this is sort\nof like that previous slide, you're looking at tea leaves. It looks complicated,\nbut under this model they were able to, in the\nshape space, explain about half",
    "start": "2732790",
    "end": "2740130"
  },
  {
    "text": "of the response\nvariants of V4 neurons. The upshot is, that V4 curve\nis about some combination",
    "start": "2740130",
    "end": "2748800"
  },
  {
    "text": "of curves. And then later, Scott\nBrincat, with Ed, went on into posterior\nIT and showed that maybe some combinations\nof these V4 cells",
    "start": "2748800",
    "end": "2755670"
  },
  {
    "text": "could fit posterior IT\nresponses quite well. So if you read the\nliterature in V4 and IT, you'll come across\nthese studies.",
    "start": "2755670",
    "end": "2761779"
  },
  {
    "text": "And they are important\nones to look at. Unfortunately,\nthey don't give you an image computable model of\nwhat these neurons are doing.",
    "start": "2761780",
    "end": "2767530"
  },
  {
    "text": "But it's some of the work\nthat you should know about if you want to look\nin V4 or early IT,",
    "start": "2767530",
    "end": "2772980"
  },
  {
    "text": "so I'm telling it to you. So let me go on to IT,\nwhich is what I want to talk about for the rest of today.",
    "start": "2772980",
    "end": "2778403"
  },
  {
    "text": "Again, I'm talking\nabout AIT and CIT.  And I'll just quickly say\nthat the anatomy, again,",
    "start": "2778404",
    "end": "2786150"
  },
  {
    "text": "suggests that the IT is\nthe central 10 degrees. And even though V1, V2, and V4\ncover the whole visual field,",
    "start": "2786150",
    "end": "2794400"
  },
  {
    "text": "if you make injections\nin V4, that's shown here, where\nyou make injections",
    "start": "2794400",
    "end": "2799559"
  },
  {
    "text": "in the more peripheral parts\nof the V4 representation, which is up here, that you don't get\nmuch projection into IT, which",
    "start": "2799560",
    "end": "2806021"
  },
  {
    "text": "is here. You don't see much green color,\nwhereas, you make projections in the center part of\nV4, these red sites here,",
    "start": "2806021",
    "end": "2811170"
  },
  {
    "text": "you see much more coverage\ninto IT, which is shown here. So when I say 10\ndegrees, that's rough.",
    "start": "2811170",
    "end": "2817829"
  },
  {
    "text": "Everything in biology is messy. But this is some of the\nevidence, beyond recordings, there's anatomical evidence\nthat as you go down into IT,",
    "start": "2817830",
    "end": "2824910"
  },
  {
    "text": "you are more and more focused\non the central 10 degrees. OK, let me talk about a little\nbit of the history of IT",
    "start": "2824910",
    "end": "2830700"
  },
  {
    "text": "recordings. This is when people got\nexcited about IT, in the 70s. This is work by Charlie Gross,\nwho's one of the first people",
    "start": "2830700",
    "end": "2836790"
  },
  {
    "text": "to record an IT cortex. And I'll show you\nwhat they did here.",
    "start": "2836790",
    "end": "2842250"
  },
  {
    "text": "This was in an era where,\nremember, Hubel and Wiesel had just done their\nwork in the '60s. And they recorded from\nthe cat visual cortex.",
    "start": "2842250",
    "end": "2848900"
  },
  {
    "text": "And they had found\nthese edge cells, and they ended up winning\nthe Nobel Prize for that. So it was the heyday\nof like, let's record",
    "start": "2848900",
    "end": "2854700"
  },
  {
    "text": "and figure out what\nmakes cells go. So they were brave enough to put\nan electrode down an IT cortex in 1970 and said, what\nmakes this neuron go.",
    "start": "2854700",
    "end": "2862470"
  },
  {
    "text": "Remember, that's an\nencoding question, what's the image content\nthat will drive this neuron.",
    "start": "2862470",
    "end": "2868620"
  },
  {
    "text": "And it's fun to just\nlook back on this and what they were doing. So they didn't have\ncomputer monitors. They were actually\nwaving around stimuli",
    "start": "2868620",
    "end": "2875089"
  },
  {
    "text": "in front of the animals. This is an anesthetized\nanimal on a table. This is a monkey. Actually, they\nstarted with a cat",
    "start": "2875090",
    "end": "2881380"
  },
  {
    "text": "and then they later\nwent to monkey. The use of these stimuli\nwas begun one day when, having failed to drive a unit\nwith any light stimulus-- that",
    "start": "2881380",
    "end": "2888020"
  },
  {
    "text": "probably means spots\nof light, edges things that Hubel and Wiesel\nhad been using. We waved a hand at\nthe stimulus screen,",
    "start": "2888020",
    "end": "2894530"
  },
  {
    "text": "they waved in front\nof the monkey, and elicited a very\nvigorous response from the previously\nunresponsive neuron.",
    "start": "2894530",
    "end": "2901190"
  },
  {
    "text": "And then we spent the next\n12 hours-- so the animal's anesthetized on the table, their\nrecording from this neuron. It's 12 hours because\nnothing's moving,",
    "start": "2901190",
    "end": "2907680"
  },
  {
    "text": "so you can record for\na long period of time. So singular neuron,\nthey're recording, listening to the spikes. We spent the next 12 hours\ntesting various paper cut",
    "start": "2907680",
    "end": "2913770"
  },
  {
    "text": "outs in attempt to find\nthe trigger feature. You can see, that's a\nHubel and Wiesel idea,",
    "start": "2913770",
    "end": "2918990"
  },
  {
    "text": "what makes this neuron go. What's the best\nthing, that's become a lot of what the\nfield spent time doing.",
    "start": "2918990",
    "end": "2925680"
  },
  {
    "text": "Trigger feature for this unit,\nwhen the entire stimulus set were used, were ranked according\nto the strength of the response",
    "start": "2925680",
    "end": "2931290"
  },
  {
    "text": "that they produced. We could not find a\nsimple physical dimension that correlated with\nthis rank order. However, the rank order\nof adequate stimuli",
    "start": "2931290",
    "end": "2937620"
  },
  {
    "text": "did correlate with\nsimilarity for us, that means\npsychophysical judged, to the shadow of a monkey hand.",
    "start": "2937620",
    "end": "2943800"
  },
  {
    "text": "So these are their rank\norder of the stimuli. And they say look, it looks like\nit's some sort of hand neuron. That's all I know\nhow to describe it.",
    "start": "2943800",
    "end": "2950021"
  },
  {
    "text": "I can't find some\nsimple thing on here. So this kind of study then\nlaunched a whole domain where people started to go\nin to record these neurons",
    "start": "2950021",
    "end": "2957180"
  },
  {
    "text": "and they found interesting\ndifferent types. Bob Desimone, who worked\nwith Charlie Gross, later showed much more\nnicely under more controlled",
    "start": "2957180",
    "end": "2963325"
  },
  {
    "text": "conditions, yes, there are\nindeed neurons that respond. You can see more to these hand--\nthis is the post stimulus time histogram, lots of spikes, lots\nof spikes, lots of spikes--",
    "start": "2963325",
    "end": "2970228"
  },
  {
    "text": "respond more to these hands\nthan to these other kind of stimuli here. So you could say,\nthese neurons have",
    "start": "2970228",
    "end": "2976350"
  },
  {
    "text": "tuned to specific combinations\nof high selectivity. You'll hear from\nWinrich that others had shown that you\ncould record some",
    "start": "2976350",
    "end": "2982470"
  },
  {
    "text": "of the neurons are really like\nfaces that you could find, and not so much hands. So you could find\nneurons that seem",
    "start": "2982470",
    "end": "2988290"
  },
  {
    "text": "to have some interesting\nselectivity in IT cortex. And then others\nlater went on to show in a number of studies-- this\nis from Nico Logothetis' work",
    "start": "2988290",
    "end": "2995605"
  },
  {
    "text": "of a number of years later. It's just one example that this\nselectivity had some tolerance to, say, the position\nof the stimulus, that's",
    "start": "2995605",
    "end": "3002390"
  },
  {
    "text": "what's shown here. The fact that these\nbars are high just means that it tolerates\nmovement in where the--",
    "start": "3002390",
    "end": "3009230"
  },
  {
    "text": "sorry, this is size,\ndegrees of visual angle. This is position, moving\nthe stimulus around. So this was known\nfor a number of years",
    "start": "3009230",
    "end": "3016190"
  },
  {
    "text": "that there's some tolerance\nto position and size changes at least. OK, so I'm putting\nthese up and you say, there's some selectivity\nand there's some tolerance.",
    "start": "3016190",
    "end": "3023836"
  },
  {
    "text": "And that should remind you of\nwhat we already said in V1, there's some selectivity,\nsimple cells. There's some tolerance,\ncomplex cells.",
    "start": "3023836",
    "end": "3029880"
  },
  {
    "text": "So you have the\nsame themes here, just different kinds of\ntypes of stimuli being used. Then people really went on, in\nthe 80s especially, and said,",
    "start": "3029880",
    "end": "3038150"
  },
  {
    "text": "let's go after this\ntrigger feature. And Tanaka's group really\nwent after this really hard.",
    "start": "3038150",
    "end": "3044359"
  },
  {
    "text": "Tanaka's group would\nfind the best stimulus they would find, dangle\na bunch of objects in front of a recorded\nneuron, find the best out",
    "start": "3044360",
    "end": "3050350"
  },
  {
    "text": "of a whole set of\nobjects, and then they try to do a reduction. They'd try to figure out,\nhow can I reduce this.",
    "start": "3050350",
    "end": "3055460"
  },
  {
    "text": "This is their attempt to reduce\nthe stimulus to its features without lowering\nthe neural response.",
    "start": "3055460",
    "end": "3061190"
  },
  {
    "text": "So high response, high response,\nhigh response, high response, high response, suddenly I\ndo this, the response drops. I do this, the response drops.",
    "start": "3061190",
    "end": "3066639"
  },
  {
    "text": "And they have lots\nof examples of this. And they want you to try to\nget to the simplest thing that could capture the response.",
    "start": "3066639",
    "end": "3072830"
  },
  {
    "text": "And when they did this, they\nwould take stimuli like this, and end up with stimuli\nthat looked like that.",
    "start": "3072830",
    "end": "3078440"
  },
  {
    "text": "Now, many of you should\nprobably start to wonder here, there's lots of paths\nfor stimulus space. It's not clear that these\nare elemental in any way.",
    "start": "3078440",
    "end": "3085754"
  },
  {
    "text": "There's lots of ways that\nyou can show with modeling that you can get easily lost in\nthis space of navigating around",
    "start": "3085754",
    "end": "3091430"
  },
  {
    "text": "here. This is just, again,\na history of the work. This is the kind of things\nthat people were doing. And then from that,\nthey presented",
    "start": "3091430",
    "end": "3097820"
  },
  {
    "text": "what we think of as the\nice cube model of IT, that I think is actually still\na very reasonable approximation.",
    "start": "3097820",
    "end": "3103015"
  },
  {
    "text": "They not only\nshowed that neurons tended to like certain\nrelatively reduced stimulus",
    "start": "3103015",
    "end": "3109069"
  },
  {
    "text": "features, not full\nobjects, but that they are gathered together. So these are millimeter\nscale regions of IT",
    "start": "3109070",
    "end": "3115340"
  },
  {
    "text": "that nearby neurons,\nwithin a millimeter or so, have similar preferences.",
    "start": "3115340",
    "end": "3120590"
  },
  {
    "text": "They're not just\nscattered willy-nilly throughout the tissue. When you go record nearby\nneurons, they're similar. So there's some mapping\nwithin IT cortex.",
    "start": "3120590",
    "end": "3128910"
  },
  {
    "text": "This is schematic here. This is optical imaging\ndata of IT cortex also",
    "start": "3128910",
    "end": "3133940"
  },
  {
    "text": "from Tanaka's\ngroup that show you that these different\nblobs of tissue",
    "start": "3133940",
    "end": "3139130"
  },
  {
    "text": "get activated by different\nimages shown here. And I'm just showing\nyou the scale of this, it's around a little\nless than a millimeter.",
    "start": "3139130",
    "end": "3145399"
  },
  {
    "text": "And our lab has\nevidence of this too. So there's some sort of\nspatial organization in IT, but we really don't really\nyet understand the features,",
    "start": "3145399",
    "end": "3152850"
  },
  {
    "text": "these elemental features yet,\nor at least, not at this time. Then later, there's lots\nof beautiful work in IT.",
    "start": "3152850",
    "end": "3159194"
  },
  {
    "text": "Again, I'm probably not\ntelling you all of it. Some of the most\nexciting work recently-- and you'll hear about\nthis from Winrich,",
    "start": "3159194",
    "end": "3164790"
  },
  {
    "text": "that people started\nto use fMRIs. So Doris Tsao and Winrich\nFreiwald and Marge Livingstone all together started to\nuse fMRI data to compare",
    "start": "3164790",
    "end": "3172880"
  },
  {
    "text": "faces versus objects. This was motivated\nfrom human work, by work like Nancy\nKanwisher lab and others.",
    "start": "3172880",
    "end": "3179361"
  },
  {
    "text": "What they found was\nthat in monkeys, you could find different\nparts that would show up, what are called\nface patches, where",
    "start": "3179361",
    "end": "3185180"
  },
  {
    "text": "you have a relative preference\nfor faces over objects. Again, I don't want to take\nall of Winrich's talk here,",
    "start": "3185180",
    "end": "3190640"
  },
  {
    "text": "but you have these\ndifferent patches here. And then what's really cool\nis, you go in and record from these patches and then you\nfind a very enriched locations",
    "start": "3190640",
    "end": "3198312"
  },
  {
    "text": "for face neurons. And these enriched\nlocations were known from a number of other studies. But this is a nice correlation\nbetween functional imaging",
    "start": "3198312",
    "end": "3205099"
  },
  {
    "text": "and this enrichment\nof these face cells. And that's what's shown here,\nthat these neurons respond",
    "start": "3205100",
    "end": "3210200"
  },
  {
    "text": "mostly to faces and not\nso much other objects. Although, you see they still\nsort of respond to these. So this kind of says\nfMRI and physiology are",
    "start": "3210200",
    "end": "3217714"
  },
  {
    "text": "telling you similar things. It also tells you there's some\nspatial clumping, at least for face-like objects, at a\nscale of a few millimeters",
    "start": "3217715",
    "end": "3224160"
  },
  {
    "text": "or so, the size\nof these patches. OK, so that's larger\nscale organization.",
    "start": "3224160",
    "end": "3229250"
  },
  {
    "text": "This is data from our own lab\nthat shows the same thing. Maybe I'll just skip through\nthis in the interest of time--",
    "start": "3229250",
    "end": "3235309"
  },
  {
    "text": "that we can map and record\nthe neurons very precisely, map them spatially and\ncompare that with fMRI.",
    "start": "3235310",
    "end": "3242090"
  },
  {
    "text": "So this is just a larger field\nof view maps of the same idea. So what we have\nthen, just to wrap up",
    "start": "3242090",
    "end": "3248870"
  },
  {
    "text": "this whirlwind tour\nof the ventral stream, is that we had some untangled\nexplicit information.",
    "start": "3248870",
    "end": "3255430"
  },
  {
    "text": "And what I want to try to\nconvince you of now, is that-- I've told you about\nthe ventral stream, but I'm going to try to\ntell you that, in IT cortex,",
    "start": "3255430",
    "end": "3261536"
  },
  {
    "text": "this is a powerful\nrepresentation for encoding object information. And then we'll take a break\nbecause we've already probably",
    "start": "3261536",
    "end": "3268780"
  },
  {
    "text": "been going a while. Yeah, about 10 more minutes\nand then we'll take a break. So what I've told you is, I've\nled you up the ventral stream,",
    "start": "3268780",
    "end": "3276280"
  },
  {
    "text": "I've given you a\nbit of the history, so now let's talk about\nIT more precisely. So now this is work\nfrom my own lab.",
    "start": "3276280",
    "end": "3282940"
  },
  {
    "text": "You go in and record IT. You go record extracellularly. You travel down into IT\ncortex, which is down here.",
    "start": "3282940",
    "end": "3288940"
  },
  {
    "text": "And you record from this. And similar to what you\nsaw, another version of what you saw from Charlie\nGross or Bob Desimone,",
    "start": "3288940",
    "end": "3295900"
  },
  {
    "text": "you show a bunch of images. And they could be\narbitrary images. You take an IT recording site,\nand see these little dots,",
    "start": "3295900",
    "end": "3301270"
  },
  {
    "text": "those are action potential\nspikes out of a particular IT site. And these are repeatable. You have some Poisson\nvariability here.",
    "start": "3301270",
    "end": "3308579"
  },
  {
    "text": "But you see that there's\nmore spikes here, there's little more here,\nless here, less there. These images are all\nrandomly interleaved",
    "start": "3308580",
    "end": "3313990"
  },
  {
    "text": "when you collect the data,\nas I'll show you in a minute. And you go to different sites\nand it likes different images. So there is certainly\nsome image selectivity.",
    "start": "3313990",
    "end": "3320424"
  },
  {
    "text": "This should not be surprising\nbecause I already showed you this from previous work. This is just data\nfrom our own lab.",
    "start": "3320425",
    "end": "3326320"
  },
  {
    "text": "You can also see now that\nyou are looking closely at the time lag, remember, I\nsaid around 100 milliseconds stimulus on.",
    "start": "3326320",
    "end": "3331944"
  },
  {
    "text": "Stimulus off, the\nstimulus is actually off before the spikes actually\nstart to occur out here in IT because,\nagain, there's a long time",
    "start": "3331945",
    "end": "3338170"
  },
  {
    "text": "lag, 100 milliseconds. OK, so that's what the\nneural responses look like. I don't know if you\nguys can hear this,",
    "start": "3338170",
    "end": "3344380"
  },
  {
    "text": "maybe I should have\nhooked up audio. Maybe you might\nbe able to hear-- this is actually a\nrecording that Chou Hung did",
    "start": "3344380",
    "end": "3350394"
  },
  {
    "text": "when he collected his data in\nmy lab for the early studies we did in the lab. I don't know if\nyou guys can hear.",
    "start": "3350394",
    "end": "3356700"
  },
  {
    "text": "[STATIC] [BEEP] [BEEP]",
    "start": "3356700",
    "end": "3363900"
  },
  {
    "text": "[BEEP] Those high beeps are the\nanimal getting reward for fixating on that dot. You're not even going to\nbe able to parse that.",
    "start": "3363900",
    "end": "3370670"
  },
  {
    "text": "I mean, you hear the\nspikes clicking by, those-- [STATIC] Those are action potentials. And I don't expect you to look\nat anything like, oh, it's",
    "start": "3370670",
    "end": "3377790"
  },
  {
    "text": "a face neuron, or whatever. I just want you to get a\nfeel for how those data were originally collected. This is a pretty grainy video.",
    "start": "3377790",
    "end": "3383640"
  },
  {
    "text": "But you get the idea. You collect data like that. And again, you can find\nselectivity in those population",
    "start": "3383640",
    "end": "3389940"
  },
  {
    "text": "patterns, as I just showed you. But then, Gabriel and Tommy\nand I, so the three of us,",
    "start": "3389940",
    "end": "3394980"
  },
  {
    "text": "I think all in this\nroom, way back when in 2005 said, well look,\nthe population of IT might have good,\nuseful information",
    "start": "3394980",
    "end": "3401490"
  },
  {
    "text": "for solving this\ndifficult object manifold tangling problem. It might be a good\nexplicit representation.",
    "start": "3401490",
    "end": "3406810"
  },
  {
    "text": "So we did a, what I call,\nearly test of this idea. We took this simple image set\nfrom eight different categories",
    "start": "3406810",
    "end": "3414810"
  },
  {
    "text": "that we had chosen. And there's good stories of\nwhy we chose those objects, if you like to hear them.",
    "start": "3414810",
    "end": "3420360"
  },
  {
    "text": "But let me just say, simple\nobjects, we moved them across position and scale,\nand we collected the responses",
    "start": "3420360",
    "end": "3426510"
  },
  {
    "text": "of IT of a bunch\nof sites to changes to all these different\nvisual images. And we showed them\nas I just showed you.",
    "start": "3426510",
    "end": "3433170"
  },
  {
    "text": "We just showed them\nfor 100 milliseconds. This is this core\nrecognition regime, were just showing them\nfor 100 milliseconds.",
    "start": "3433170",
    "end": "3438660"
  },
  {
    "text": "And then we show another\none, and they're just randomly interleaved. And from this,\nwhat you do is you could get a\npopulation set of data",
    "start": "3438660",
    "end": "3445109"
  },
  {
    "text": "where we recorded 350 IT sites. Here's a sample of 63 sites. This is 78 images, the\nmean neural response",
    "start": "3445110",
    "end": "3452270"
  },
  {
    "text": "here is the mean\nresponse to an image. This is 78 of the\nimages we showed. There's nothing for you to read\ninto here to say, other than,",
    "start": "3452270",
    "end": "3458139"
  },
  {
    "text": "you have this rich\npopulation data. And now our question is, well,\nwhat lives in this population",
    "start": "3458139",
    "end": "3463665"
  },
  {
    "text": "data that we've collected. Is it explicit with\nregard to categories? So we come back to\nwhat I showed you earlier about those\ntangled manifolds and said,",
    "start": "3463665",
    "end": "3471390"
  },
  {
    "text": "we need simple decoding tools. Can a simple decoding tool\nlook at that population and tell me what's out there?",
    "start": "3471390",
    "end": "3477930"
  },
  {
    "text": "And again, we were using\nlinear classifiers at the time, because we took\nthat, as you heard from Haim as our operational\ndefinition of what",
    "start": "3477930",
    "end": "3484349"
  },
  {
    "text": "a simple tool is. And if it could decode\ninformation about the object identity, then we'd\nsay, well, that means,",
    "start": "3484350",
    "end": "3489570"
  },
  {
    "text": "by that operational\ndefinition, this is explicit, available,\naccessible information, or just",
    "start": "3489570",
    "end": "3494790"
  },
  {
    "text": "generally good. So if you imagine that the\nactivity-- this is schematic. Each dot, this is\nneuron one, neuron two,",
    "start": "3494790",
    "end": "3501450"
  },
  {
    "text": "and you could have a\nbunch of IT neurons. But if you can\nseparate any object from all the other\nobject, these points",
    "start": "3501450",
    "end": "3506550"
  },
  {
    "text": "represent the\npopulation response to each image of an object. Remember, there's many\nimages of each object.",
    "start": "3506550",
    "end": "3512190"
  },
  {
    "text": "But if you could\nlinearly separate that, that would mean it was explicit. And if you had a hard\ntime separating it, this would be implicit.",
    "start": "3512190",
    "end": "3518609"
  },
  {
    "text": "These are like tangled\nobject manifold. This is Inaccessible,\nor bad, information. So we just-- we,\nand when I mean we,",
    "start": "3518610",
    "end": "3524781"
  },
  {
    "text": "I mean Chou Hung,\nwho led the study. Gabriel, Tommy, and I did this. We took the response of\nan image, like this one.",
    "start": "3524781",
    "end": "3531300"
  },
  {
    "text": "It produced a population vector. Again, we recorded\na bunch of neurons. We recorded them sequentially\nand then pieced together",
    "start": "3531300",
    "end": "3537170"
  },
  {
    "text": "this population vector. So these are the\nspikes simulated off a population of IT.",
    "start": "3537170",
    "end": "3543630"
  },
  {
    "text": "We could do various things. In fact, I think Gabriel\ndid everything possible, as I remember at the time. And one of the things we\ndid was just count spikes.",
    "start": "3543630",
    "end": "3550470"
  },
  {
    "text": "One of the simple things, that\nturns out to work quite well, is count the spikes\nover 100 milliseconds. So this neuron counts spikes.",
    "start": "3550470",
    "end": "3555780"
  },
  {
    "text": "That gives you a\nnumber, one number here, count spikes get one number. So you have n neurons,\nyou get n numbers.",
    "start": "3555780",
    "end": "3562380"
  },
  {
    "text": "So it's a point in a n\ndimensional state space where n is the number of neurons. And then we had already\npre-divided the images",
    "start": "3562380",
    "end": "3569370"
  },
  {
    "text": "into different\ncategories, as shown here. These are the categories. And again, we just\nasked how well",
    "start": "3569370",
    "end": "3576270"
  },
  {
    "text": "you could do faces\nversus non-faces, toys versus non-toys,\nso on and so forth. These are old slides.",
    "start": "3576270",
    "end": "3582060"
  },
  {
    "text": "But you get the idea,\nis that basically, you don't need that many\nsites to already get to very high levels\nof performance",
    "start": "3582060",
    "end": "3587280"
  },
  {
    "text": "on both categorization\nand identification. The interesting\nthing about this was that you could\nsolve simple forms",
    "start": "3587280",
    "end": "3594389"
  },
  {
    "text": "of this invariance problem\nin this representation quite easily. That if you just trained on\nthe central objects, the center",
    "start": "3594389",
    "end": "3600900"
  },
  {
    "text": "and size, the simple three\ndegree size center position, and test it on the\nsame thing, just",
    "start": "3600900",
    "end": "3606180"
  },
  {
    "text": "held out repeats of this\ndata, you did quite well. That's a baseline. But what's interesting is you\ntest at different position",
    "start": "3606180",
    "end": "3612809"
  },
  {
    "text": "and scale. And then you also do\nalmost nearly as well. So you naturally generalize\nto these other conditions",
    "start": "3612810",
    "end": "3619050"
  },
  {
    "text": "by training on these\nsimple conditions. So this is evidence\nthat the population is a good basis set for\nsolving these kind of problems.",
    "start": "3619050",
    "end": "3626850"
  },
  {
    "text": "A few number of training\nexamples on this population then generalizes,\nwell, across conditions makes the problem hard.",
    "start": "3626850",
    "end": "3633690"
  },
  {
    "text": "So again, we published\nthat a long time ago. This was an early\nstep to say, look, the phenomenology looks\nright for the story that I've",
    "start": "3633690",
    "end": "3639780"
  },
  {
    "text": "been telling you so far. You can't do this easily in\nearlier visual areas like V1,",
    "start": "3639780",
    "end": "3645450"
  },
  {
    "text": "or simulated V1 or V4. And we later show\nthat a number of ways. This is consistent with\nwork I was showing you",
    "start": "3645450",
    "end": "3652740"
  },
  {
    "text": "with Logothetis\nposition tolerance, size tolerance, the selectivity. It's really just an explicit\ntest of the idea population",
    "start": "3652740",
    "end": "3659780"
  },
  {
    "text": "encoding. So the take home here is that\nthere's this explicit object representation in IT.",
    "start": "3659780",
    "end": "3665354"
  },
  {
    "text": "I didn't prove to\nyou that this is the link, this predictive\nmodel to decoding yet. We're going to talk\nabout that next. But this was some of\nthe important population",
    "start": "3665354",
    "end": "3671794"
  },
  {
    "text": "phenomenology that we did. What I try to tell you today-- hopefully I've introduced you\nto the problem of visual object",
    "start": "3671794",
    "end": "3677750"
  },
  {
    "text": "recognition and the\nway we restricted it to core object recognition. We talked a lot about predictive\nmodels as being the goal,",
    "start": "3677750",
    "end": "3683340"
  },
  {
    "text": "although I haven't\npresented much to you yet. Hopefully, that's the\nsecond part of the talk. I've given you a tour\nof the ventral stream.",
    "start": "3683340",
    "end": "3688830"
  },
  {
    "text": "But it was a poor tour. I'm sure everybody\ni work with would say that you've neglected\nall this work because there's",
    "start": "3688830",
    "end": "3694231"
  },
  {
    "text": "no way I can do that all\nin even a whole week. I just tried to hit some\nof the highlights for you.",
    "start": "3694231",
    "end": "3700820"
  },
  {
    "text": "And I told you that\nthe IT population seems to have solved\na key problem, this sort of invariance\nproblem that I set up.",
    "start": "3700820",
    "end": "3707390"
  },
  {
    "text": "And one way to step back and\nsay, over the last 40 years or so, from those early\nstudies of Charlie Gross",
    "start": "3707390",
    "end": "3713150"
  },
  {
    "text": "or even Hubel and Wiesel, we,\nthe field of ventral stream physiology, we've largely\ndescribed important",
    "start": "3713150",
    "end": "3718920"
  },
  {
    "text": "phenomenology. Even that last study is\npopulation phenomenology. And so now we need these\nmore advanced models.",
    "start": "3718920",
    "end": "3726237"
  },
  {
    "text": "So the next phase of the field\nis developing and testing these predictive\nmodels that I've motivated at the\nbeginning, but I",
    "start": "3726237",
    "end": "3731390"
  },
  {
    "text": "haven't given you much of yet. So this was hopefully a bit\nof history and set context",
    "start": "3731390",
    "end": "3736430"
  },
  {
    "text": "to where we are. ",
    "start": "3736430",
    "end": "3755989"
  }
]
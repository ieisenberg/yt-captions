[
  {
    "start": "0",
    "end": "81000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5460"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5460",
    "end": "11760"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11760",
    "end": "18260"
  },
  {
    "text": "at ocw.mit.edu.  RYAN ALEXANDER: All right, so\nas this XKCD comic points out,",
    "start": "18260",
    "end": "25760"
  },
  {
    "text": "in CS, it can be very\ndifficult to figure out when something is\njust really hard or something is\nvirtually impossible.",
    "start": "25760",
    "end": "31199"
  },
  {
    "text": "And until a couple\nyears ago, people thought this idea of\nimage classification would be something that was\ncloser to the impossible side.",
    "start": "31200",
    "end": "38840"
  },
  {
    "text": "But with the advent of\ndeep learning typology, we've made significant strides\nin image classification, and now the problem's\nactually quite practical.",
    "start": "38840",
    "end": "45475"
  },
  {
    "text": "So today we'll be\ngoing through how the process of\nimage classification with deep learning works. So we're first going to talk\nabout what deep learning is,",
    "start": "45475",
    "end": "53390"
  },
  {
    "text": "and then we'll move into some of\nthe image processing techniques that researchers use,\nfollowed by the architecture",
    "start": "53390",
    "end": "58748"
  },
  {
    "text": "of the convolutional\nneural networks, which will be the main\nfocus in our presentation. We'll also talk about\nthe training process,",
    "start": "58749",
    "end": "65840"
  },
  {
    "text": "and then go through some\nresults and limitations of CNNs and image classification. So what is deep learning?",
    "start": "65840",
    "end": "71760"
  },
  {
    "text": "Well, the term is\nparticularly vague, and it's purposely so\nfor a couple of reasons. The first is mystery is\nalways good for marketing.",
    "start": "71760",
    "end": "79229"
  },
  {
    "text": "But the second reason\nis that deep learning refers to a pretty wide range\nof machine learning algorithms. They do have some commonalities.",
    "start": "79230",
    "end": "85910"
  },
  {
    "start": "81000",
    "end": "81000"
  },
  {
    "text": "They all seek to solve\nproblems of a complexity that previously, people thought\nonly people could solve.",
    "start": "85910",
    "end": "92840"
  },
  {
    "text": "So these are more sophisticated\nclassification problems than traditional\nconventional machine learning algorithms can do.",
    "start": "92840",
    "end": "99799"
  },
  {
    "text": "So how do they go\nabout doing this? Well, all of these\ndeep learning programs tend to take all the\nprocesses that need",
    "start": "99800",
    "end": "105950"
  },
  {
    "text": "to happen, and split them up. They've got different parts\nof their program working on different things, all\nwhile performing calculations,",
    "start": "105950",
    "end": "111439"
  },
  {
    "text": "and then at the end,\nit all comes together, and we get a result.\nOf course, this isn't unique to deep learning,\nand lots of distributed systems",
    "start": "111440",
    "end": "119320"
  },
  {
    "text": "decentralize their calculations. But the key thing\nabout deep learning is that every part is\nperforming these calculations.",
    "start": "119320",
    "end": "127310"
  },
  {
    "text": "The calculations are\nnot simple calculations. They're not we'll do this\none simple operation over, and over again on a lot\nof data, and then we'll",
    "start": "127310",
    "end": "133569"
  },
  {
    "text": "get a result at the end. Each part is performing some\nparticularly complicated process on all the little parts\nbefore they come together.",
    "start": "133570",
    "end": "141440"
  },
  {
    "text": "So why is this\narchitecture a good idea? Why did engineers\ncome up with this sort of decentralized,\nmulti-layered complex process?",
    "start": "141440",
    "end": "150190"
  },
  {
    "text": "Well, we take the example\nof image classification. It turns out that\nthe human brain does a pretty similar process.",
    "start": "150190",
    "end": "157920"
  },
  {
    "text": "So here's the human\nvisual system, and it's pretty much a\nhierarchical process. So you begin by\nmoving from the retina",
    "start": "157920",
    "end": "165470"
  },
  {
    "start": "160000",
    "end": "160000"
  },
  {
    "text": "into the first\nareas of the brain, and as the information\ngets processed, it moves from one region\nof the brain to the other,",
    "start": "165470",
    "end": "171625"
  },
  {
    "text": "and each spatial\nelement of your brain is performing an entirely\ndifferent calculation.",
    "start": "171625",
    "end": "176880"
  },
  {
    "text": "For example, the\nv1 area over here is picking out\nedges and corners, and then over here, a\ncouple steps later in v4,",
    "start": "176880",
    "end": "183799"
  },
  {
    "text": "you're starting to group\nthose figures together. And so the brain\nkind of operates in a way that is very similar to\nthe way these networks operate.",
    "start": "183800",
    "end": "192330"
  },
  {
    "start": "192000",
    "end": "192000"
  },
  {
    "text": "So let's talk about\nto classify a face. If I asked you guys how\nwould you classify a face,",
    "start": "192330",
    "end": "198080"
  },
  {
    "text": "what is the first\nthing you might do? Well, as I mentioned before,\nthe first thing out brain does is it finds these edges.",
    "start": "198080",
    "end": "204350"
  },
  {
    "text": "The first thing to do is\nidentify where the face is versus everything else. Now, does anyone have\nany idea as to what",
    "start": "204350",
    "end": "210890"
  },
  {
    "text": "we could with the next step? ",
    "start": "210890",
    "end": "216650"
  },
  {
    "text": "Julian, you have an idea? AUDIENCE: Maybe you could\ngroup these edges together. RYAN ALEXANDER: Right.",
    "start": "216650",
    "end": "222140"
  },
  {
    "text": "We could maybe identify\nsome of these features that we're working with. So these are things like\nnoses, and lips, and eyes.",
    "start": "222140",
    "end": "230420"
  },
  {
    "text": "And then what do we do after we\nhave these individual features? ",
    "start": "230420",
    "end": "237970"
  },
  {
    "text": "Steve. AUDIENCE: Well, maybe we can\ngroup some of those together. RYAN ALEXANDER: Exactly. Yeah, we can organize them into\nwhat we know the pattern to be.",
    "start": "237970",
    "end": "245000"
  },
  {
    "text": "We know that a face has to\nhave two eyes, above a nose, and then above the mouth. So that is precisely what a\nneural network actually ends up",
    "start": "245000",
    "end": "252849"
  },
  {
    "text": "doing, and we'll walk through\nthe process of how it does this later on in the talk. But as you can see,\nthe intuitive way",
    "start": "252849",
    "end": "258669"
  },
  {
    "text": "that we classify a\nface, and the way our brains are\nwired to do it, is pretty similar to the way\ngot these neural networks",
    "start": "258670",
    "end": "264120"
  },
  {
    "text": "to operate. So like I said,\nwe're talking a lot about these convolutional\nneural networks.",
    "start": "264120",
    "end": "269740"
  },
  {
    "start": "266000",
    "end": "266000"
  },
  {
    "text": "There are other types of\narchitectures involved. Like we mentioned\nbefore, deep learning is a pretty wide\nvariety of algorithms,",
    "start": "269740",
    "end": "276600"
  },
  {
    "text": "but we're going to\nfocus on these CNNs. To give you a precursor\nof how good these CNN are,",
    "start": "276600",
    "end": "283750"
  },
  {
    "text": "this results from\nImageNet competition. So the ImageNet\ncompetition is basically exactly what it sounds like,\na bunch of computer scientists",
    "start": "283750",
    "end": "290470"
  },
  {
    "text": "get together, and see how\nmany images they can correctly classify. And their error rate\nwas pretty high.",
    "start": "290470",
    "end": "296430"
  },
  {
    "text": "Almost a third error\nrate over here in 2010, 2011, and then in 2011, the CNNs\nwere introduced to the topic,",
    "start": "296430",
    "end": "304010"
  },
  {
    "text": "and the error rate plummeted. As you can see\nover here in 2015, we've got a significant\nimprovement in these ImageNet",
    "start": "304010",
    "end": "310420"
  },
  {
    "text": "competitions. So clearly, the CNNs\nhave been very effective, and it's definitely\nbeen something that is exciting in the field\nand happening right now.",
    "start": "310420",
    "end": "319500"
  },
  {
    "text": "All right, so now we're going\nto move into image processing. ISHWARYA ANANTHABHOTLA:\nOK, so Ryan gave us",
    "start": "319500",
    "end": "325550"
  },
  {
    "text": "a nice overview of where\nwe get this concept of neural networks, but\nlet's take a time travel,",
    "start": "325550",
    "end": "331690"
  },
  {
    "text": "and go into a quick\nhistory lesson. So suppose I had a chair,\nand I wanted the computer to classify this chair.",
    "start": "331690",
    "end": "337580"
  },
  {
    "text": "I have some a priori knowledge\nabout what sort of things make up a chair. So I might be\ninterested in looking",
    "start": "337580",
    "end": "342668"
  },
  {
    "text": "at arms, and corners of the\nchair, legs, things like that. So I would go ahead, and feature\nengineer my discovery scheme",
    "start": "342668",
    "end": "350479"
  },
  {
    "text": "to be looking for\nspecific things. So I'm going to talk\nabout some techniques that are traditionally used. For example, chairs, doors,\nthese things have corners.",
    "start": "350480",
    "end": "357520"
  },
  {
    "start": "355000",
    "end": "355000"
  },
  {
    "text": "So I might use an image\nprocessing technique called a Harris Corner Detector,\nwhere we basically look at large changes in\nintensity as groups of pixels",
    "start": "357520",
    "end": "365400"
  },
  {
    "text": "move from an image to\nan image that indicate the presence of corners, and you\ncan use common corners to say",
    "start": "365400",
    "end": "370470"
  },
  {
    "text": "that OK, all of these images are\nchairs, or doors, or whatever. Similarly, I want to say I have\na bunch of pictures of chairs",
    "start": "370470",
    "end": "376790"
  },
  {
    "text": "of different sizes, but\nthat they all must have so many corners or something. So typically, we use a sift\nalgorithm to scale invariant",
    "start": "376790",
    "end": "384590"
  },
  {
    "text": "feature transforms. It basically says that\nacross different sizes, I still should be able\nto extract information",
    "start": "384590",
    "end": "389960"
  },
  {
    "text": "about the placement of corners. Another common technique\nthat's used in image processing",
    "start": "389960",
    "end": "395930"
  },
  {
    "text": "is what we call HOG,\nHistogram of Gradients. So basically, for\nexample, in this image, if I want to say I want to find\nall the images that have faces",
    "start": "395930",
    "end": "405140"
  },
  {
    "text": "in them, or consist\nof faces, let's say, I might come up with\na template of a face that",
    "start": "405140",
    "end": "410480"
  },
  {
    "text": "basically assigns gradients\nto groups of pixels that form an outline of what\nlooks like a face, and then scan it across my\nsample images, and say OK,",
    "start": "410480",
    "end": "418910"
  },
  {
    "text": "a face is present in this image. Obviously, there\nare some errors. A mead cap, and a logo back\nhere have become a face,",
    "start": "418910",
    "end": "424240"
  },
  {
    "text": "but this is the\ntraditional approach. But here's the problem,\nwhat if I don't actually",
    "start": "424240",
    "end": "430310"
  },
  {
    "text": "necessarily know what features\nare the most critical depending on the dataset that I get?",
    "start": "430310",
    "end": "436280"
  },
  {
    "text": "I want the system\nitself to figure out what techniques to apply without\nhaving any a priori knowledge",
    "start": "436280",
    "end": "442490"
  },
  {
    "text": "about the dataset. So this is exactly\nthe idea of CNNs, the convolutional\nneural networks. We want the techniques to\nbe learned automatically",
    "start": "442490",
    "end": "450030"
  },
  {
    "text": "by the process, by the system. So if I'm trying\nto classify faces, I want the system to\nfigure out that eyes,",
    "start": "450030",
    "end": "455980"
  },
  {
    "text": "and ears, and nose, these are\nthe most important things. Or if I'm trying to\nclassify elephants, the ears and trunks are\nthe critical features,",
    "start": "455980",
    "end": "461900"
  },
  {
    "text": "without me having\nto say OK, we're going to do corner detection,\nso on, and so forth. So this is the idea.",
    "start": "461900",
    "end": "468470"
  },
  {
    "text": "So to be able to understand\nthis process in greater detail, I'm first going to go\ninto a little bit of math,",
    "start": "468470",
    "end": "474000"
  },
  {
    "text": "and the idea is to present\nthe most fundamental operation here, which is the convolution.",
    "start": "474000",
    "end": "479019"
  },
  {
    "text": "So this is the formal definition\nof the two-dimensional convolution, and since\nwe're working with images,",
    "start": "479019",
    "end": "484210"
  },
  {
    "start": "480000",
    "end": "480000"
  },
  {
    "text": "we're only considering\nthe two-dimensional case. So in a more graphical\npresentation,",
    "start": "484210",
    "end": "489937"
  },
  {
    "text": "which is a little bit easier\nto understand than just seeing the formula, the\nidea is that we have a kernel, or a\nconvolutional filter",
    "start": "489937",
    "end": "496610"
  },
  {
    "start": "490000",
    "end": "490000"
  },
  {
    "text": "that we seek to apply\non another image, and that extracts some\ninformation about that image that we can use to help us\nclassify the convolution.",
    "start": "496610",
    "end": "505485"
  },
  {
    "text": "So assume that this is our\nkernel, or this is our filter, and suppose this-- ",
    "start": "505485",
    "end": "513663"
  },
  {
    "text": "oh, there it is. So suppose we're applying\nthe kernel [INAUDIBLE] here to the image\nthat's in green.",
    "start": "513663",
    "end": "520690"
  },
  {
    "text": "So the idea is we want to slide\nthis filter across the image, and what we're\nbasically doing this is a succession of dot products.",
    "start": "520690",
    "end": "526579"
  },
  {
    "text": "So at each placement\non the image, we multiply the\noverlayed numbers, and the sum becomes the output\nimage on the convolt output.",
    "start": "526580",
    "end": "535770"
  },
  {
    "text": "So this is basically the\nway the process works. You probably notice that there's\na reduction in dimension, and Henry will talk a little\nbit more about why this is.",
    "start": "535770",
    "end": "544520"
  },
  {
    "text": "Let me get to it, and\nthen [INAUDIBLE] So let's see some examples\nof what information we get by applying\nthe convolution.",
    "start": "544520",
    "end": "551390"
  },
  {
    "text": "So you see the image of\na tiger on the top left. When we apply a filter\nthat's a low pass filter, basically-- it's\na Gaussian-- then",
    "start": "551390",
    "end": "558440"
  },
  {
    "text": "we get low spatial frequency\ninformation about this image. So basically, we blurred\nit, and this tells us",
    "start": "558440",
    "end": "564680"
  },
  {
    "text": "something specific that\nwe might want to learn. So the kernel actually looks\nlike a two-dimensional Gaussian",
    "start": "564680",
    "end": "569785"
  },
  {
    "text": "function that's been distributed\nacross this three-by-three kernel. Similarly, we\nmight be interested",
    "start": "569785",
    "end": "575570"
  },
  {
    "text": "in high spatial\nfrequency information. So in this case, we're\nlooking at sharp features.",
    "start": "575570",
    "end": "580850"
  },
  {
    "text": "So horizontal edges\nor vertical edges. So a question for you is\nif I have this kernel,",
    "start": "580850",
    "end": "586660"
  },
  {
    "text": "which of these outputs\nwhen this kernel was applied to the original\nimage, which of these outputs do you think it produced?",
    "start": "586660",
    "end": "593449"
  },
  {
    "text": "AUDIENCE: The third\none on the right. ISHWARYA ANANTHABHOTLA:\nYeah, that's exactly right, and it's probably\npretty easy to see why that's the case, given\nthat the numbers are all",
    "start": "593449",
    "end": "599959"
  },
  {
    "text": "horizontal bands here. Lastly, we also may be\ninterested in extracting information at a\nparticular frequency.",
    "start": "599960",
    "end": "606710"
  },
  {
    "text": "So we can take the\ndifference of a high pass filter and a low pass\nfilter, and add it",
    "start": "606710",
    "end": "613212"
  },
  {
    "text": "to your frequency you can\nextract information about that as well. OK, one last helpful\npiece of information",
    "start": "613212",
    "end": "620591"
  },
  {
    "text": "is that there's\nanother way that you can think of the information\nthat's learned at each stage",
    "start": "620591",
    "end": "625960"
  },
  {
    "text": "because a convolution\ncan also be thought of as a Fourier\ntransform in the frequency domain.",
    "start": "625960",
    "end": "630970"
  },
  {
    "text": "You can think of the image\ntransformation that way. So from an image perspective,\nwhat a Fourier transform is",
    "start": "630970",
    "end": "637180"
  },
  {
    "text": "is basically a sum of a\nset of sinusoidal gratings that differ, say, in frequency,\nin orientation, in amplitude,",
    "start": "637180",
    "end": "643575"
  },
  {
    "text": "and in phase. So you can think about\nthe zebra image here that's actually a composite\nof different gradients",
    "start": "643575",
    "end": "652030"
  },
  {
    "text": "that might look like this,\nand the Fourier coefficients would be how much of\neach of these pieces",
    "start": "652030",
    "end": "657100"
  },
  {
    "text": "come together to make\nthat final image. So just to get a sense of\nwhat kind of information this could convey, we typically\ntake a Fourier transformation,",
    "start": "657100",
    "end": "665042"
  },
  {
    "text": "and break it apart into\nthe magnitude and phase representation. So you see magnitude,\nand you see phase.",
    "start": "665042",
    "end": "671389"
  },
  {
    "text": "So those images weren't\nparticularly clear, but this is a really\ngood example for this. So if we take the\nFourier transform",
    "start": "671390",
    "end": "677650"
  },
  {
    "text": "of all the horizontal\ntext here, you see how the magnitude\nreflects this, and you can go back to\nthe math to understand",
    "start": "677650",
    "end": "682870"
  },
  {
    "text": "why it's reflected in\na vertical marking. And similarly, if I were\nto take that same image,",
    "start": "682870",
    "end": "688550"
  },
  {
    "text": "and rotate it, and then ask\nfor the Fourier transform, you see how that information\nis contained very clearly",
    "start": "688550",
    "end": "693850"
  },
  {
    "text": "in the magnitude spectrum. So these might be things\nthat a network would learn at each stage to try\nto identify this as a text,",
    "start": "693850",
    "end": "701140"
  },
  {
    "text": "or as as body of text that's\ntilted one way or the other, so on and so forth. So with that, we can now go into\nwhat the actual architecture",
    "start": "701140",
    "end": "708660"
  },
  {
    "text": "of a convolutional neural is. HENRY NASSIF: All right, so as\nit was said earlier, in order to classify or detect\nobjects, you actually",
    "start": "708660",
    "end": "714909"
  },
  {
    "text": "need certain features. You need to be able to\nidentify these features. And the way you can\nidentify these features",
    "start": "714909",
    "end": "720530"
  },
  {
    "text": "is using certain convolutions\nor certain filters. In many cases, we don't know\nwhat these features are,",
    "start": "720530",
    "end": "727060"
  },
  {
    "text": "and as a result of\nthat, we don't actually know what the filters are\nto extract these features. And what convolution neural\nnetworks allow us to do",
    "start": "727060",
    "end": "734290"
  },
  {
    "text": "is actually determine\nwhat these features are, and also determine what\nthe filters are in order",
    "start": "734290",
    "end": "739600"
  },
  {
    "text": "to extract these features. Now, the idea for\nconvolutional neural networks,",
    "start": "739600",
    "end": "744720"
  },
  {
    "text": "or the idea for replicating\nhow the brain works started in about 1960s or\n1950s after some experiments",
    "start": "744720",
    "end": "752439"
  },
  {
    "text": "by Hubel and Wesel. And what happened in\nthese experiments, as can be seen here,\nis a cat was actually",
    "start": "752440",
    "end": "758680"
  },
  {
    "text": "shown a light band\nat different angles, and the neural\nactivity of the cat was measured using an electrode.",
    "start": "758680",
    "end": "765730"
  },
  {
    "text": "And the outcome\nfrom this experiment show that based on the angle\nat which the light was shown,",
    "start": "765730",
    "end": "771280"
  },
  {
    "text": "the neural response of\nthe cat was different. As you can see here, the\nnumber of neurons, as well as",
    "start": "771280",
    "end": "776620"
  },
  {
    "text": "the neurons that were\nfiring were very different based on the angle. So what you can see\nalso here is really",
    "start": "776620",
    "end": "782820"
  },
  {
    "text": "a plot of the response versus\nthe orientation of the light. And what this has led\nHubel and Wesel to",
    "start": "782820",
    "end": "790389"
  },
  {
    "text": "is the idea that\nneurons in the brain are organized in a certain\ntopographical order,",
    "start": "790390",
    "end": "795600"
  },
  {
    "text": "and at each filter, it\nfills a specific role, and the only fires when its\nspecific input is shown,",
    "start": "795600",
    "end": "804610"
  },
  {
    "text": "or when the angle is show,\nor the angle is specified.",
    "start": "804610",
    "end": "809980"
  },
  {
    "text": "Now, the first step to\nactually replicating how the brain works\nin code is really understanding how the building\nblock, the neuron, works.",
    "start": "809980",
    "end": "818120"
  },
  {
    "text": "That's a quick\nreminder of 7012 here. So a neuron is actually a cell\nwith dendrites, nucleus, axon,",
    "start": "818120",
    "end": "826100"
  },
  {
    "text": "and a terminal. And what the neuron\nactually does is aggregate the action\npotentials or the inputs",
    "start": "826100",
    "end": "833240"
  },
  {
    "text": "it gets from all the\nneighboring neurons that are connected to it\nthrough the timelines, and it sums these action\npotentials, and then compares",
    "start": "833240",
    "end": "840579"
  },
  {
    "text": "them to a certain threshold\nthat it has internally, and that would determine\nwhether or not this neuron would",
    "start": "840580",
    "end": "846250"
  },
  {
    "text": "fire an action potential. And that very simple idea can\nactually be replicated in code.",
    "start": "846250",
    "end": "852400"
  },
  {
    "text": " An artificial neuron looks\nvery much like a natural one.",
    "start": "852400",
    "end": "859840"
  },
  {
    "text": "So what you would have\nis a set of inputs. Here we have three inputs that\nare summed inside of a cell,",
    "start": "859840",
    "end": "865720"
  },
  {
    "text": "or a neuron. The sum here is not\njust a regular sum, it's a weighted sum.",
    "start": "865720",
    "end": "871189"
  },
  {
    "text": "So the neuron\nspecifies some weight, which you can think of as how\nmuch it values the input coming",
    "start": "871190",
    "end": "877540"
  },
  {
    "text": "from a specific neuron, and\nthen the input is multiplied by its weight, and then the\ntotal sum that the neuron",
    "start": "877540",
    "end": "885070"
  },
  {
    "text": "computes is then fed into\nan activation function that produces the output that the\nneuron then basically produces.",
    "start": "885070",
    "end": "892935"
  },
  {
    "text": " Now, what we just saw here\nis really a simple neuron,",
    "start": "892935",
    "end": "898740"
  },
  {
    "text": "a single neuron. You can't really do much\nwith just one neuron, so what you would do is\ncombined these neurons",
    "start": "898740",
    "end": "904710"
  },
  {
    "text": "in a certain topography,\nor in that case, we have a network with\nseven neurons organized",
    "start": "904710",
    "end": "912130"
  },
  {
    "text": "in three different layers. And what you can think\nof that is really as one big neuron with 12\ninputs, and one output.",
    "start": "912130",
    "end": "920790"
  },
  {
    "text": "So for example, in the\ncase of the chair that was previously\nmentioned, if you're trying to identify whether\na specific image has",
    "start": "920790",
    "end": "927890"
  },
  {
    "text": "a chair in it or not,\nthese 12 inputs here could be some sub images,\nor some small areas",
    "start": "927890",
    "end": "935060"
  },
  {
    "text": "of the initial image that\nyou feed into the network, and the output here\ncould be a yes or no.",
    "start": "935060",
    "end": "941100"
  },
  {
    "text": "Whether the image has a chair,\nor doesn't have a chair. And that is really\nthe concept behind",
    "start": "941100",
    "end": "946329"
  },
  {
    "text": "convolutional neural\nnetworks, which we'll go into details in a bit.",
    "start": "946330",
    "end": "952040"
  },
  {
    "text": "So what each neuron would\nbe doing in that case, is really just\nperforming a dot product,",
    "start": "952040",
    "end": "958600"
  },
  {
    "text": "which if you aggregate\nthat with the dot products computed by each\nof the other neurons,",
    "start": "958600",
    "end": "964140"
  },
  {
    "text": "you would obtain a convolution. So what we have here\nis three inputs. If the input, in that case,\nis an image or a sub image,",
    "start": "964140",
    "end": "971810"
  },
  {
    "text": "then the inputs would be pixels. The weights that you\nwould be using here would be the filter weights,\nwhich is the filter that you",
    "start": "971810",
    "end": "979100"
  },
  {
    "text": "use in the convolution. And then the sum here\nwould be the dot product of the weights and the\ninputs, and that sum",
    "start": "979100",
    "end": "986060"
  },
  {
    "text": "would be computed by a specific\nneuron in your network. Then, that would be\nthe convolution step,",
    "start": "986060",
    "end": "993709"
  },
  {
    "start": "993000",
    "end": "993000"
  },
  {
    "text": "and then that\nconvolution step would happen at the first\nlayer in the network. So you would be applying\nthis to the input,",
    "start": "993710",
    "end": "999490"
  },
  {
    "text": "but you also would\nbe applying this at the second layer,\nand third layer. In that case, we're\nonly showing what happens in the first layer.",
    "start": "999490",
    "end": "1007029"
  },
  {
    "text": "The next step after\nthe convolution would be the activation step. So the dot product\ncomputed here would",
    "start": "1007030",
    "end": "1014470"
  },
  {
    "start": "1008000",
    "end": "1008000"
  },
  {
    "text": "be there's a function that\nwould be applied to the sum, and then that\nfunction would produce the output of the neuron.",
    "start": "1014470",
    "end": "1022730"
  },
  {
    "start": "1022000",
    "end": "1022000"
  },
  {
    "text": "And this is where the\nactivation layer is. You also have another\nactivation layer here, and then a final one here.",
    "start": "1022730",
    "end": "1028630"
  },
  {
    "text": " What we just went through\nnow are convolutions",
    "start": "1028630",
    "end": "1035289"
  },
  {
    "text": "and activations, but this is\nnot the only thing that actually happens in a neural net.",
    "start": "1035290",
    "end": "1041260"
  },
  {
    "text": "What we also have is a step\ncalled subsampling, which we will be talking about next.",
    "start": "1041260",
    "end": "1048880"
  },
  {
    "text": "For now, we will dig\ndeeper into the activation, and specifically, what\nactivation functions to use.",
    "start": "1048880",
    "end": "1055240"
  },
  {
    "text": "In that case, we can see\nthat that's a neuron, and what the neuron\nis doing here",
    "start": "1055240",
    "end": "1060400"
  },
  {
    "text": "is the weighted sum\nthat we talked about, or the dot product. And then the output\nfrom this would be fed into a certain\nactivation function.",
    "start": "1060400",
    "end": "1068480"
  },
  {
    "text": "Common activation functions\nare sigmoid, tanh, or rectify linear unit, and\nwe will go through each one",
    "start": "1068480",
    "end": "1075490"
  },
  {
    "start": "1074000",
    "end": "1074000"
  },
  {
    "text": "independently. So here, we can see the\nsigmoid activation function. So what this function\nessentially does",
    "start": "1075490",
    "end": "1081490"
  },
  {
    "text": "is map any input to an output\nin the range of zero to one,",
    "start": "1081490",
    "end": "1086595"
  },
  {
    "text": "and it's defined as one divided\nby one plus e to the minus x. The other common activation\nfunction is tanh,",
    "start": "1086595",
    "end": "1093700"
  },
  {
    "start": "1091000",
    "end": "1091000"
  },
  {
    "text": "and that's any\ninput to an output between minus one and one. And then finally, would be the\nrectified linear unit, which",
    "start": "1093700",
    "end": "1101889"
  },
  {
    "text": "maps an input to itself\nif it's positive, or to zero if it's negative.",
    "start": "1101890",
    "end": "1107440"
  },
  {
    "text": "Now, in theory, you\ncould use any function as an activation\nfunction in your network,",
    "start": "1107440",
    "end": "1113929"
  },
  {
    "text": "but that's not what you\nwant to do in practice. You want your\nactivation functions to be non-linear\nfor one main reason,",
    "start": "1113930",
    "end": "1121000"
  },
  {
    "start": "1116000",
    "end": "1116000"
  },
  {
    "text": "that the goal of the\nactivation function is actually to introduce\nnon-linearity in your system. And if all your activation\nfunctions are linear,",
    "start": "1121000",
    "end": "1128442"
  },
  {
    "text": "then you would essentially be\nhaving a linear system, which prevents you from achieving\nthe level of complexity",
    "start": "1128442",
    "end": "1133690"
  },
  {
    "text": "that you would ideally want to\nachieve with a neural network. And there's a formal\nproof for as to why",
    "start": "1133690",
    "end": "1140850"
  },
  {
    "text": "you need non-linear\nactivation functions. They don't all need\nto be non-linear, but you need to have a least\na few non-linear activation",
    "start": "1140850",
    "end": "1146757"
  },
  {
    "text": "functions in your network. And the proof is available\nin the appendix, or the link to the paper that has the proof.",
    "start": "1146757",
    "end": "1154840"
  },
  {
    "start": "1153000",
    "end": "1153000"
  },
  {
    "text": "So after we've discussed what\nhappens at the activation layer, now we want to\ntalk about convolution.",
    "start": "1154840",
    "end": "1161370"
  },
  {
    "text": "So as I said earlier,\nan image is obviously a two-dimensional image,\nbut we're using RGB images.",
    "start": "1161370",
    "end": "1169170"
  },
  {
    "text": "So actually need three channels. So what this means is\nthat an image is actually three-dimensional, and each 2D\nmatrix represents one channel.",
    "start": "1169170",
    "end": "1177670"
  },
  {
    "text": "One of them corresponding to R,\none of them corresponding to G, one of them corresponding\nto B. So a 32 by 32 image",
    "start": "1177670",
    "end": "1185330"
  },
  {
    "text": "would essentially be represented\nby a 32 by 32 by three matrix,",
    "start": "1185330",
    "end": "1190899"
  },
  {
    "text": "as can be seen here.  So what happens at\nthe convolution layer?",
    "start": "1190900",
    "end": "1198980"
  },
  {
    "text": "So here we have a\nnice animation that shows what is happening at\neach convolutional layer.",
    "start": "1198980",
    "end": "1205799"
  },
  {
    "text": "So assume we have a five\nby five by three filter. So what this is,\nessentially, would",
    "start": "1205800",
    "end": "1211360"
  },
  {
    "text": "be doing is covering a certain\npatch in the original image, which is 32 by 32 by three.",
    "start": "1211360",
    "end": "1217450"
  },
  {
    "text": "So what can see here\nis that for that five by five by three patch\nin the original image,",
    "start": "1217450",
    "end": "1222460"
  },
  {
    "text": "we have a neuron\nthat is actually performing the dot\nproduct on all the pixels in that specific patch.",
    "start": "1222460",
    "end": "1229120"
  },
  {
    "text": "So what is happening\nhere is the pixel values, which in that case, we have\nfive by five by three pixels,",
    "start": "1229120",
    "end": "1237399"
  },
  {
    "text": "are being multiplied\nby the filter values, and this operation is\nbeing performed here.",
    "start": "1237400",
    "end": "1243530"
  },
  {
    "text": "Then, after that dot\nproduct is performed, it's fed into an activation\nfunction, as can be seen here,",
    "start": "1243530",
    "end": "1251080"
  },
  {
    "text": "and this produces the\noutput of this neuron. Now, this is what this single\nneuron is actually doing.",
    "start": "1251080",
    "end": "1257260"
  },
  {
    "text": "It's just covering that\narea of the original image. What you would have\nin a neural net",
    "start": "1257260",
    "end": "1262890"
  },
  {
    "text": "is many neurons, each\ncovering a certain area of the original image. And if you aggregate the output\nof all of these neurons, what",
    "start": "1262890",
    "end": "1271929"
  },
  {
    "text": "you would be doing or performing\nis, essentially, a convolution on the original image.",
    "start": "1271930",
    "end": "1278920"
  },
  {
    "text": "And to formalize\nwhat happens here, or what's the output\nthat's being produced from that operation, we can\nlook at that from a more",
    "start": "1278920",
    "end": "1286179"
  },
  {
    "start": "1279000",
    "end": "1279000"
  },
  {
    "text": "mathematical perspective. So if you have an\ninput of size H1, W1, D1, and you're performing\na convolution with a filter,",
    "start": "1286180",
    "end": "1294630"
  },
  {
    "text": "then the output, W2,\nwould be related to W1 with the following formula.",
    "start": "1294630",
    "end": "1299730"
  },
  {
    "text": "So W2 plus W1 minus filter width\nplus one, and the same formula applies for the height, and\nthe depth would actually",
    "start": "1299730",
    "end": "1306460"
  },
  {
    "text": "be the same because\nin that case, we're using a filter that\nhas the same depth, or three, as the original image.",
    "start": "1306460",
    "end": "1312430"
  },
  {
    "text": " So what this would\nproduce in aggregate",
    "start": "1312430",
    "end": "1318279"
  },
  {
    "text": "is if you have 28 by 28 by one\nneurons, each one performing a dot product on some pixels\nin the original image,",
    "start": "1318280",
    "end": "1325030"
  },
  {
    "text": "the output would be an\nactivation map of size 28 by 28 by one, and the\noutput of each neuron",
    "start": "1325030",
    "end": "1330789"
  },
  {
    "text": "would be one pixel in\nthe activation map. Now, if we go back to the\npoints that we made earlier,",
    "start": "1330790",
    "end": "1338870"
  },
  {
    "text": "one thing we said was that the\nreason you use a neural network is because you don't know\nexactly what features",
    "start": "1338870",
    "end": "1345979"
  },
  {
    "text": "you want to extract,\nand you don't actually have specific filters that you\nwant to apply to the image. So ideally, what\nyou want to do is",
    "start": "1345979",
    "end": "1353139"
  },
  {
    "text": "have multiple filters being\napplied to the first image, and perform multiple\nconvolutions,",
    "start": "1353140",
    "end": "1358540"
  },
  {
    "text": "and this is what you can do\nwith multiple neuron layers. So what we described before\nwas just for one neuron layer.",
    "start": "1358540",
    "end": "1363850"
  },
  {
    "text": "In that case, we can assume\nwe have five different neuron layers, each one performing\na different convolution",
    "start": "1363850",
    "end": "1370000"
  },
  {
    "text": "on the original image. So in that case, we\nwould have 28 by 28 by one neuron per\nlayer, and then",
    "start": "1370000",
    "end": "1376210"
  },
  {
    "text": "if we aggregate all\nthese neurons together, we need to multiply\nit by five, and that would be the total\nnumber of neurons we",
    "start": "1376210",
    "end": "1381490"
  },
  {
    "text": "have in that specific number. So this actually leaves us with\na pretty complicated system.",
    "start": "1381490",
    "end": "1389860"
  },
  {
    "text": "It would have many parameters. The neurons have weights,\nthe number of neurons is also a parameter So how do\nwe actually formalize that?",
    "start": "1389860",
    "end": "1398890"
  },
  {
    "text": "If we have an input volume\nof 32 by 32 by three, which is our original image,\nand a filter size of five",
    "start": "1398890",
    "end": "1404800"
  },
  {
    "start": "1399000",
    "end": "1399000"
  },
  {
    "text": "by five by three, then the\nsize of the activation map that would be reduced\nwould be 28 by 28 by one.",
    "start": "1404800",
    "end": "1411970"
  },
  {
    "text": "Then in that case, we also said\nwe have five different neuron layers that perform five\ndifferent convolutions.",
    "start": "1411970",
    "end": "1417410"
  },
  {
    "text": "Then the total number of neurons\nwould be 28 by 28 by five, and then the weights\nper neuron are five",
    "start": "1417410",
    "end": "1424460"
  },
  {
    "text": "by five by three, which is 75. In that case, we're assuming\nthat the neurons independently keep track of their own weights.",
    "start": "1424460",
    "end": "1429860"
  },
  {
    "text": "This could be simplified\nto each layer having their own weight, which\nwould tremendously reduce the number of parameters.",
    "start": "1429860",
    "end": "1435460"
  },
  {
    "text": "But in that case, just\nto get an upper bound, this leaves us\nwith a total number of parameters of 294,000.",
    "start": "1435460",
    "end": "1441909"
  },
  {
    "text": "And this is just using a\n32 by 32 by three image. You can think of this\nas a pretty small image.",
    "start": "1441910",
    "end": "1447980"
  },
  {
    "text": "So if you have a\nbigger image, you will have many more parameters.",
    "start": "1447980",
    "end": "1453500"
  },
  {
    "text": "Great. So what we just saw now, and\ndescribed, were convolutions, activations, and these\nsteps happen sequentially",
    "start": "1453500",
    "end": "1461424"
  },
  {
    "text": "in a convolutional\nneural network, specifically as can be see here. One step that also happens\noccasionally is subsampling,",
    "start": "1461425",
    "end": "1469870"
  },
  {
    "text": "and we'll discuss that\nstep in detail here. So there are two main reasons\nwhy you would actually subsample your input.",
    "start": "1469870",
    "end": "1476140"
  },
  {
    "start": "1472000",
    "end": "1472000"
  },
  {
    "text": "One is to obviously reduce\nthe size of your input, and your feature space,\nbut also because you",
    "start": "1476140",
    "end": "1482752"
  },
  {
    "text": "want to keep track of the\nmost important information, and get rid of everything\nelse that you don't think",
    "start": "1482752",
    "end": "1488850"
  },
  {
    "text": "is going to be relevant\nto your classification. And the common methods\nused in subsampling",
    "start": "1488850",
    "end": "1494490"
  },
  {
    "text": "are either max pooling\nor average pooling. We will describe\nmax pooling here.",
    "start": "1494490",
    "end": "1500279"
  },
  {
    "text": "So what happens\nin max pooling is, essentially, you are\ndividing the image into different sub images,\nnon-overlapping sub images,",
    "start": "1500280",
    "end": "1507429"
  },
  {
    "text": "and you perform an\nat max operation. So in that case, if we\nconsider two by two filters,",
    "start": "1507430",
    "end": "1512650"
  },
  {
    "text": "we would split the image, which\nin that case is four by four. We'd split it into\nfour sub images, and for each two by two square,\nwe would take the maximum.",
    "start": "1512650",
    "end": "1521370"
  },
  {
    "text": "In that case, for the first\nsquare it would be six, then eight, then\nthree, then four. And the reason\nthat actually works",
    "start": "1521370",
    "end": "1527610"
  },
  {
    "text": "is because what you want\nto do is really keep track of the response of the\nneurons that-- or the highest",
    "start": "1527610",
    "end": "1535740"
  },
  {
    "text": "response produced\nby your neurons. In that case, for example,\nthe first highest response",
    "start": "1535740",
    "end": "1540780"
  },
  {
    "text": "in the first square\nis six, and that means that if you get\nthat high of a response, it means that something has\nbeen detected in the image,",
    "start": "1540780",
    "end": "1548020"
  },
  {
    "text": "or has been detected. And this is something you\nwant to keep track of as you move forward in your network.",
    "start": "1548020",
    "end": "1553530"
  },
  {
    "text": "And although this moves\naround the location of pixels, because you can think of\nthat as subsampling an image,",
    "start": "1553530",
    "end": "1560640"
  },
  {
    "text": "it does keep track of the\ninformation you care about because you only\ncare about the fact that something has been\ndetected in the image.",
    "start": "1560640",
    "end": "1567541"
  },
  {
    "text": "At this point, you\ndon't really care about where it's\nlocated in the image, and you want to keep\ntrack of all the features",
    "start": "1567541",
    "end": "1574590"
  },
  {
    "text": "that your neurons have\ndetected in order to be able to eventually classify\nthe input correctly.",
    "start": "1574590",
    "end": "1582070"
  },
  {
    "text": "So if you have multiple\nfeature maps-- so in that case, if you have 224 by 224 by 64,\nwhat your subsampling operation",
    "start": "1582070",
    "end": "1590909"
  },
  {
    "text": "would be doing is reducing\nthe height and the width so the depth would\nremain unchanged.",
    "start": "1590910",
    "end": "1597180"
  },
  {
    "text": "So in that case, you would go\nfrom 224 by 224 by 64 to 112 by 112 by 64, and that would\nbe reducing your output size",
    "start": "1597180",
    "end": "1605600"
  },
  {
    "text": "by a factor of four.  And formally, what\nthis would look",
    "start": "1605600",
    "end": "1611820"
  },
  {
    "start": "1609000",
    "end": "1609000"
  },
  {
    "text": "like is if you have\nan input of size H1, W1, D1, the size of\nyour output would",
    "start": "1611820",
    "end": "1617775"
  },
  {
    "text": "be related to your input\nin the following ways. W2 would be W1 minus\nthe pool width plus one.",
    "start": "1617775",
    "end": "1623460"
  },
  {
    "text": "The same applies for H2, and the\ndepth would remain unchanged.",
    "start": "1623460",
    "end": "1629240"
  },
  {
    "text": "So these are, essentially-- these are the steps that happen\nin a convolutional neural network.",
    "start": "1629240",
    "end": "1634825"
  },
  {
    "text": "What you could be doing\nis repeating these steps on a certain number of\ntimes in your network.",
    "start": "1634825",
    "end": "1640380"
  },
  {
    "text": "But eventually, you have\nto make a classification, and decide in our case,\nwhether our image has a chair",
    "start": "1640380",
    "end": "1647009"
  },
  {
    "text": "or doesn't have a chair. So how does that happen? So after you perform\nall these steps,",
    "start": "1647010",
    "end": "1653130"
  },
  {
    "text": "there's a step that happens\nhere that would allow you to make that\nprediction, and that step",
    "start": "1653130",
    "end": "1658240"
  },
  {
    "text": "is usually called a\nfully connected layer, or a multi-layer perception. And what this essentially is is\nlayers that are very similar,",
    "start": "1658240",
    "end": "1667010"
  },
  {
    "start": "1661000",
    "end": "1661000"
  },
  {
    "text": "or exactly the same as\nwhat you had before, except that every\nneuron in the layer is connected to all\nthe previous neurons.",
    "start": "1667010",
    "end": "1673690"
  },
  {
    "text": "So what it's allowed\nyou to do is really consider everything\nyou currently have about your input,\nor everything that's",
    "start": "1673690",
    "end": "1680429"
  },
  {
    "text": "left about your input, and\ncompute a dot product on that, rather than focusing on a\nsubset subsample of your input",
    "start": "1680430",
    "end": "1689340"
  },
  {
    "text": "like previous layers do. In that case, if\nyou're actually trying to classify your input\ninto four classes,",
    "start": "1689340",
    "end": "1696620"
  },
  {
    "text": "you would ideally have\nfour different neurons in your output layer,\neach one corresponding to one of the classes\nthat you have,",
    "start": "1696620",
    "end": "1704070"
  },
  {
    "text": "and then you would\nperform the same operation as you would in a previous\nlayer, compute the dot product,",
    "start": "1704070",
    "end": "1709919"
  },
  {
    "text": "and then once you obtain\nthe values at every neuron, you would perform a\nnormalization operation",
    "start": "1709920",
    "end": "1715870"
  },
  {
    "text": "on all the output. This organization operation\nis called softmax, or normalized exponential,\nand what it does is really,",
    "start": "1715870",
    "end": "1722280"
  },
  {
    "text": "put more weight on\nthe highest value. And by computing the\nsoftmax at the output,",
    "start": "1722280",
    "end": "1727740"
  },
  {
    "text": "you're able to compute the\nposterior probabilities, and allows you to\nmake a more informed-- or basically make\na classification",
    "start": "1727740",
    "end": "1734460"
  },
  {
    "text": "decision on your input. Great. So that's everything.",
    "start": "1734460",
    "end": "1741182"
  },
  {
    "text": "And now, the next step will be\ntalking about back propagation. ISHWARYA ANANTHABHOTLA: OK.",
    "start": "1741182",
    "end": "1746450"
  },
  {
    "text": "So now that Henry has\ngiven us an overview of the entire\narchitecture of a CNN, I'm going to quickly\nspend some time, and talk about standard\npreprocessing tricks and tips",
    "start": "1746450",
    "end": "1754610"
  },
  {
    "text": "that people might use\non the image dataset before they actually feet\nit through a neural net",
    "start": "1754610",
    "end": "1759710"
  },
  {
    "text": "to classify the images. So let's suppose we\nhave a dataset x, and there are n number of\ndata points in the dataset,",
    "start": "1759710",
    "end": "1766899"
  },
  {
    "text": "and each point has\na dimension, D. So they have D\nfeatures per point.",
    "start": "1766900",
    "end": "1773010"
  },
  {
    "text": "So in this example, we use\nthese graphs as an example. Basically, our original data\nhere has just two dimensions,",
    "start": "1773010",
    "end": "1778370"
  },
  {
    "text": "and it spans this\nrange of values. So for example, if we want\nto center this data, what we would do is a mean subtraction.",
    "start": "1778370",
    "end": "1784330"
  },
  {
    "text": "So we basically\nsubtract the mean across all the features\nof all the points, and we basically center it, and\nyou can see that transformation",
    "start": "1784330",
    "end": "1790710"
  },
  {
    "text": "here. And then we might, again, go\nfor normalizing the dimension so that you have it.",
    "start": "1790710",
    "end": "1795932"
  },
  {
    "text": "The data points\nspan the same range of values in both dimensions. So you can see that\ntransformation,",
    "start": "1795932",
    "end": "1801150"
  },
  {
    "text": "and how it's taken place here. And we just divide by the\nstandard deviation to do this.",
    "start": "1801150",
    "end": "1807087"
  },
  {
    "start": "1806000",
    "end": "1806000"
  },
  {
    "text": "Something that's\nvery commonly done is called PCA, or Principal\nComponent Analysis. And the idea here\nis sometimes we",
    "start": "1807087",
    "end": "1812896"
  },
  {
    "text": "have a dataset that has a\nvery, very high dimensionality, and we would like to\nreduce that dimensionality.",
    "start": "1812896",
    "end": "1818910"
  },
  {
    "text": "So basically, what\nour goal is is to project the higher\ndimensional space onto a lower dimensionality space by taking\nthe subset of those features.",
    "start": "1818910",
    "end": "1827126"
  },
  {
    "text": "And if you've seen\na little bit of 1806 from linear algebra,\nthe way we do this is by generating\na covariance matrix,",
    "start": "1827126",
    "end": "1832860"
  },
  {
    "text": "then doing the single\nvariable decomposition. And I'll gloss over the math\nnow, but that's the idea.",
    "start": "1832860",
    "end": "1839210"
  },
  {
    "text": "And you can see here\nhow the original data spanned two dimensions. I would decorrelate it so that\nit spans a single dimension.",
    "start": "1839210",
    "end": "1844438"
  },
  {
    "text": "And even with this\ndata, you might want to ensure\nthat it's widened, which is the same deal. You want the values to span the\nsame range in both dimensions.",
    "start": "1844438",
    "end": "1852770"
  },
  {
    "text": "So then you would just\ndivide by your Eigenvalues to get the widened data. ",
    "start": "1852770",
    "end": "1859519"
  },
  {
    "start": "1859000",
    "end": "1859000"
  },
  {
    "text": "This last bit is\nsomething that's very commonly done\nas a preprocessing trick, though people aren't\nentirely sure why it works very",
    "start": "1859520",
    "end": "1868010"
  },
  {
    "text": "well, or that it\nreally does help, but it's something\nthat people do, and it's called\ndata augmentation. So basically, if I\nhave a dataset that",
    "start": "1868010",
    "end": "1874581"
  },
  {
    "text": "contains a bunch of\nimages of chairs, a bunch of images of tables, and\nthen a bunch of images of say,",
    "start": "1874582",
    "end": "1880790"
  },
  {
    "text": "trees, I might want to\nintentionally augment that dataset further by\nintroducing a few variations",
    "start": "1880790",
    "end": "1887080"
  },
  {
    "text": "on these same images. So I might take the chair\nimage, rotate some, reflect it a few more, scale, crop,\nremap the color space,",
    "start": "1887080",
    "end": "1895042"
  },
  {
    "text": "or just kind of\nhave a process that does this randomly\nto create more variation on the same dataset. And this is a good illustration\nof why this makes a difference.",
    "start": "1895042",
    "end": "1903490"
  },
  {
    "text": "I've taken an image\nhere of what looks like a waterfall or\nsome spot of nature, and simply just\ninverted the colors.",
    "start": "1903490",
    "end": "1909785"
  },
  {
    "text": "And what I see, if I were to\njust see this image alone, it maybe looks like a\ncurtain, or a bit of texture, or something.",
    "start": "1909785",
    "end": "1915010"
  },
  {
    "text": "And the idea is even\nto a human perception, these images have two\nvery different meanings, and so it's interesting\nto see what effect they",
    "start": "1915010",
    "end": "1921744"
  },
  {
    "text": "would have on a neural network. And with that, we'll go over to\nimage classification results.",
    "start": "1921744",
    "end": "1928480"
  },
  {
    "text": "ALI SOYLEMEZOGLU:\nSo, so far we've seen how convolutional\nneural networks are built,",
    "start": "1928480",
    "end": "1934600"
  },
  {
    "text": "and certain image\nprocessing techniques we can use on the input images\nto get them into formats that",
    "start": "1934600",
    "end": "1942850"
  },
  {
    "text": "are there for the\nclassification process, but so far, it seems\na bit abstract.",
    "start": "1942850",
    "end": "1947930"
  },
  {
    "text": "It's good to know how CNNs work,\nwhy CNNs work, but why don't we",
    "start": "1947930",
    "end": "1953500"
  },
  {
    "text": "take a look at some of the\npractical results from CNNs, and what they're used\nfor so that when you're",
    "start": "1953500",
    "end": "1959990"
  },
  {
    "text": "done watching this\nlecture, you can go home, and try classifying\nimages on your own time?",
    "start": "1959990",
    "end": "1966490"
  },
  {
    "text": "With that, let's first revisit\nthe ImageNet competition. I hope you remember the graph\nat the bottom from the beginning",
    "start": "1966490",
    "end": "1973240"
  },
  {
    "text": "of the lecture,\nwhere we used this to motivate the use of CNNs. CNNs came onto the\npicture in 2012,",
    "start": "1973240",
    "end": "1981040"
  },
  {
    "text": "but the winning CNN from 2012\nwas used on the 2010 ImageNet",
    "start": "1981040",
    "end": "1986470"
  },
  {
    "text": "competition as\nwell, and it managed to bring down the top five\nerror rate to 0.17, which",
    "start": "1986470",
    "end": "1993070"
  },
  {
    "text": "is pretty much on the same level\nas how performed in the 2012 competition when it was first\nused, which was at 0.16.",
    "start": "1993070",
    "end": "2000480"
  },
  {
    "text": "So this just goes to show that\nthese convolutional neural networks are the state of the\nart when it comes to image",
    "start": "2000480",
    "end": "2006646"
  },
  {
    "text": "classification, and\nthat's why we're currently focusing on that.",
    "start": "2006646",
    "end": "2011770"
  },
  {
    "text": "But you might be wondering\nwhat the ImageNet competition exactly looks like,\nwhat the images looks like.",
    "start": "2011770",
    "end": "2017340"
  },
  {
    "text": "So why don't we\ntake a look at that. As you can see here,\nthese are images from the ImageNet competition.",
    "start": "2017340",
    "end": "2023309"
  },
  {
    "text": "Underneath each image\nis a bold caption, which is considered to be\nthe ground truth, or what the competition\nbelieves to be",
    "start": "2023310",
    "end": "2030950"
  },
  {
    "text": "the correct classification\nof the image. Underneath that\nground truth, you",
    "start": "2030950",
    "end": "2036850"
  },
  {
    "text": "see a list of five\ndifferent labels. Now, these five\nlabels are produced by a convolutional\nneural network,",
    "start": "2036850",
    "end": "2043120"
  },
  {
    "text": "and the different bars-- the different lengthened bars,\nsome pink and others blue,",
    "start": "2043120",
    "end": "2048600"
  },
  {
    "text": "represent how\nconfident the CNN is that what it sees in that\nimage is that specific label.",
    "start": "2048600",
    "end": "2054989"
  },
  {
    "text": "As you can see in\ncertain examples, the CNN is pretty confident in\nthat it has a correct answer.",
    "start": "2054989",
    "end": "2061469"
  },
  {
    "text": "For example, when we look\nat the container ship, it's pretty confident that\nwhat's in that image is exactly",
    "start": "2061469",
    "end": "2066540"
  },
  {
    "text": "a container ship. There are certain cases when it\ndoesn't get the correct label on its first try, but it does\nhave in its top five labels.",
    "start": "2066540",
    "end": "2074070"
  },
  {
    "text": "For example, you can\nsee grill and mushroom. Now, the funny thing\nabout the mushroom image is that what it thinks\nthe image should",
    "start": "2074070",
    "end": "2081750"
  },
  {
    "text": "be classified as is agaric. And if you don't know, agaric\nis actually a type of mushroom, and in fact, it's a\nmushroom that image.",
    "start": "2081750",
    "end": "2088530"
  },
  {
    "text": "And it make sense that\ntheir confidence levels are pretty much the same. Agaric is slightly-- it's\nslightly more complex that what",
    "start": "2088530",
    "end": "2095908"
  },
  {
    "text": "it sees in the image is agaric.  But there are certain\ncases when the CNN",
    "start": "2095909",
    "end": "2103140"
  },
  {
    "text": "fails to classify\nthe image correctly in its top five levels. This will be registered\nas a top five error,",
    "start": "2103140",
    "end": "2109320"
  },
  {
    "text": "as you just saw in the previous\nslide about the top error rate. One example here on\nthis slide is cherry.",
    "start": "2109320",
    "end": "2115560"
  },
  {
    "text": "Now, the ImageNet\ncompetition believed that this should be\nclassified correctly as cherry, even\nthough there's also",
    "start": "2115560",
    "end": "2121360"
  },
  {
    "text": "a Dalmatian in the background. The CNN, on the other\nhand, is pretty confident that what it sees in this\nimage is the Dalmatian.",
    "start": "2121360",
    "end": "2129410"
  },
  {
    "text": "But if you look at some\nof the other results within the top five, although\nit doesn't guess cherry at all,",
    "start": "2129410",
    "end": "2134640"
  },
  {
    "text": "it does guess certain\nfruits that it may think look sort\nof like cherries like grape or elderberry.",
    "start": "2134640",
    "end": "2140820"
  },
  {
    "text": "So the CNN does\nactually pick up on two different distinct\nobjects within the image,",
    "start": "2140820",
    "end": "2147000"
  },
  {
    "text": "but as a result of how it's\nbuilt, or its training set, it ends up classifying\nit as a Dalmatian.",
    "start": "2147000",
    "end": "2152609"
  },
  {
    "text": "But it goes to show you\nthat CNNs could also be used not just as an\nimage classification, but also as object detection,\nwhich we do not touch up",
    "start": "2152610",
    "end": "2159986"
  },
  {
    "text": "on in this lecture at all. So I'm not going to\ngo further into that.",
    "start": "2159987",
    "end": "2165460"
  },
  {
    "text": "Now, this is all fun and all,\nbut what about some real world applications? So this is a study that they\ndid at Google with Google Street",
    "start": "2165460",
    "end": "2173220"
  },
  {
    "start": "2169000",
    "end": "2169000"
  },
  {
    "text": "View house numbers, where\nthey used the CNN to classify",
    "start": "2173220",
    "end": "2178670"
  },
  {
    "text": "photographic images of house\nnumbers, as you can see here, of certain examples of\nthese house numbers-- what they look like.",
    "start": "2178670",
    "end": "2184500"
  },
  {
    "text": "So what the CNN was\ntasked with doing was that it was supposed to\nrecognize the individual digits",
    "start": "2184500",
    "end": "2191600"
  },
  {
    "text": "within the image, and then\nunderstand that it's not just one digit that\nit's looking at,",
    "start": "2191600",
    "end": "2196910"
  },
  {
    "text": "but it's actually\na string of digits connected, and successfully\nclassified as the correct house",
    "start": "2196910",
    "end": "2202720"
  },
  {
    "text": "number. This can be quite challenging,\neven for humans sometimes when the image is quite blurry.",
    "start": "2202720",
    "end": "2208930"
  },
  {
    "text": "You might not exactly know what\nthe house number exactly is,",
    "start": "2208930",
    "end": "2214420"
  },
  {
    "text": "but they managed to get the\nconvolutional neural network to operate around\nhuman operator levels.",
    "start": "2214420",
    "end": "2220410"
  },
  {
    "text": "So that corresponds to\naround 96% to 97% accuracy, and what that\nenables Google to do",
    "start": "2220410",
    "end": "2226270"
  },
  {
    "text": "is that they can\ndeploy the CNN such that the CNN automatically\nextracts the house",
    "start": "2226270",
    "end": "2232790"
  },
  {
    "text": "numbers from the images online,\nand uses that to geocode",
    "start": "2232790",
    "end": "2239180"
  },
  {
    "text": "these addresses. And it's gotten to a point\nwere the CNN is successfully",
    "start": "2239180",
    "end": "2244190"
  },
  {
    "text": "able to do this process\nin less than an hour for all of the street view\nhouse numbers in all of France.",
    "start": "2244190",
    "end": "2251390"
  },
  {
    "text": "Now, you might asking where\nthis could be useful for. If you don't have access\na lot of resources",
    "start": "2251390",
    "end": "2258559"
  },
  {
    "text": "to actually do this\ngeocoding process where you match latitude and\nlongitude to street addresses,",
    "start": "2258560",
    "end": "2265670"
  },
  {
    "text": "then your only resource might\nbe actually photographic images. So you actually need\nsomething, hopefully not human,",
    "start": "2265670",
    "end": "2271160"
  },
  {
    "text": "but some sort of software\nthat can do this successfully. And so this is, for\nexample, a place",
    "start": "2271160",
    "end": "2276200"
  },
  {
    "text": "in South Africa,\na bird's eye view. Not sure if you can\nexactly see, but there are these small numbers on\ntop of each of the houses.",
    "start": "2276200",
    "end": "2283459"
  },
  {
    "text": "All of these numbers were\nextracted and correctly classified using this\npreviously seen CNN.",
    "start": "2283459",
    "end": "2289930"
  },
  {
    "text": "Another example from robotics\nis recognizing hand gestures.",
    "start": "2289930",
    "end": "2295619"
  },
  {
    "text": "So obviously, robots\ncome equipped with a lot of different hardware.",
    "start": "2295620",
    "end": "2300680"
  },
  {
    "text": "They can sense\nsounds, they can also capture images of\ntheir surroundings. And if you're able to classify\nwhat you see-- if the robots is",
    "start": "2300680",
    "end": "2308812"
  },
  {
    "text": "able to classify\nwhat it sees, then it can actually act upon it,\nand take certain actions. That's why it becomes really\nhelpful to successfully",
    "start": "2308812",
    "end": "2315785"
  },
  {
    "text": "classify the images. So this is what they\ndid using hand gestures,",
    "start": "2315785",
    "end": "2320809"
  },
  {
    "text": "where there were five\ndifferent classes. Each class corresponds to the\nnumber of extended fingers.",
    "start": "2320810",
    "end": "2326460"
  },
  {
    "text": "So a, b, c, d, the top row,\ncorresponds to the same class. They all have two\nfingers sticking out.",
    "start": "2326460",
    "end": "2331640"
  },
  {
    "text": "The bottom row has three\nfingers sticking out. So that's another class. And they get the error rate\ndown all the way to 3%.",
    "start": "2331640",
    "end": "2340250"
  },
  {
    "text": "So 97% of the time, the\nconvolutional neural net correctly classified\nthe hand gesture.",
    "start": "2340250",
    "end": "2345650"
  },
  {
    "text": "And you can use these\nhand gestures then to give certain\ncommands to a robot,",
    "start": "2345650",
    "end": "2350990"
  },
  {
    "text": "and it can train the CNN\nto act upon something else besides hand gestures.",
    "start": "2350990",
    "end": "2356360"
  },
  {
    "text": "For example, if it's in\nsome sort of terranean and you train it\non certain images that you might find\nin nature, then it",
    "start": "2356360",
    "end": "2363740"
  },
  {
    "text": "can take those classifications,\nand act upon it once it sees, for example, a tree, or\nsome sort of body of water.",
    "start": "2363740",
    "end": "2372230"
  },
  {
    "text": "It's all thanks to\nimage classification. Now, obviously, gestures\nare not necessarily static.",
    "start": "2372230",
    "end": "2378050"
  },
  {
    "text": "You could be waving your\nhand, and so that would require a temporal component. So it's not just an image\nyou're looking at, but a video.",
    "start": "2378050",
    "end": "2385660"
  },
  {
    "text": "And so if follows\nthat we can probably extend image classification\ninto video classification.",
    "start": "2385660",
    "end": "2393049"
  },
  {
    "start": "2390000",
    "end": "2390000"
  },
  {
    "text": "After all, videos are just\nimages with an added component, specifically time.",
    "start": "2393050",
    "end": "2399920"
  },
  {
    "text": "Obviously, the added\ntemporal component comes with a lot of\nadditional complexity. So we're not going to dive into\nany of that, but in the end,",
    "start": "2399920",
    "end": "2407517"
  },
  {
    "text": "it comes down to the same thing. You extract features\nfrom the videos, and you attempt to\nclassify them using",
    "start": "2407517",
    "end": "2412520"
  },
  {
    "text": "convolutional neural nets. So why don't we look\nat a study done, again, at Google, where they\nextracted one million videos",
    "start": "2412520",
    "end": "2421390"
  },
  {
    "text": "from YouTube, sports videos,\nwith somewhere between 400",
    "start": "2421390",
    "end": "2426980"
  },
  {
    "text": "to 500 different classes,\nand they used CNNs to attempt",
    "start": "2426980",
    "end": "2432630"
  },
  {
    "text": "to classify these videos. Now, they used\ndifferent approaches. They used different\napproaches, different tests,",
    "start": "2432630",
    "end": "2438590"
  },
  {
    "text": "different types of CNNs that\nI'm not going to go into. But as you can see\nhere, these are",
    "start": "2438590",
    "end": "2445795"
  },
  {
    "text": "certain stills from these videos\nwhere the caption highlighted in blue is what the\ncorrect answer should be,",
    "start": "2445795",
    "end": "2453770"
  },
  {
    "text": "and underneath it,\nthe top five labels that the convolutional\nneural network producers.",
    "start": "2453770",
    "end": "2459250"
  },
  {
    "text": "The one highlighted\nin green is supposed to be the correct answer. So you can see on all of these,\nit gets it within the top five,",
    "start": "2459250",
    "end": "2469180"
  },
  {
    "text": "and for the most part,\nwithin the top two, and it's pretty confident\nwhen it does get it correctly. Now, when I said that they use\ndifferent types of classifieds,",
    "start": "2469180",
    "end": "2476673"
  },
  {
    "text": "some of them were more\nstacked classifieds, where they were just trained\non stills within these images,",
    "start": "2476673",
    "end": "2482970"
  },
  {
    "text": "while others were what they\ncalled fusion ones, where they sort of add the temporal\ncomponent by fusing",
    "start": "2482970",
    "end": "2488865"
  },
  {
    "text": "in different stills from\nthese photo images together.",
    "start": "2488865",
    "end": "2494250"
  },
  {
    "text": "Now, the current accuracy rate-- the best one they've\nachieved so far-- has been around 80% accuracy\nwithin the top five label.",
    "start": "2494250",
    "end": "2503550"
  },
  {
    "text": "Now, 80% accuracy\nis nowhere near what we saw with the\nImageNet classification, where in 2015, they had\nmanaged to get it up",
    "start": "2503550",
    "end": "2510690"
  },
  {
    "text": "to 98% or 99% accuracy.",
    "start": "2510690",
    "end": "2516349"
  },
  {
    "text": "But obviously, there's way more\ncomplexity involved in this.",
    "start": "2516350",
    "end": "2521520"
  },
  {
    "text": "So it makes sense that\nit's not quite there yet. But it does provide a good\nbenchmark, and something",
    "start": "2521520",
    "end": "2528090"
  },
  {
    "text": "to improve upon in\nthe future as well. Now, that being said,\nconvolutional neural networks",
    "start": "2528090",
    "end": "2535740"
  },
  {
    "text": "do come with\ncertain limitations. They're not perfect. And so Julian will now\ntalk about the limitations.",
    "start": "2535740",
    "end": "2545020"
  },
  {
    "text": "JULIAN BROWN: Thanks, Ali. So Ali talked about the\nImageNet competition,",
    "start": "2545020",
    "end": "2550210"
  },
  {
    "text": "and talked about how\nthe recent winners have been convolutional neural nets. So before, the best was about\n26% top five error rate,",
    "start": "2550210",
    "end": "2560604"
  },
  {
    "text": "but now they've\nactually gotten it down to a 4.9% top five\nerror rate, and that was-- the winner of that\ncompetition, the 2015 one,",
    "start": "2560604",
    "end": "2567920"
  },
  {
    "text": "was actually Microsoft. They've got the current state\nof the art implementation, and so because it's the\nImageNet competition,",
    "start": "2567920",
    "end": "2574890"
  },
  {
    "text": "that means they can\nidentify exactly 1,000 different categories of images.",
    "start": "2574890",
    "end": "2580770"
  },
  {
    "text": "So there are few\nproblems, actually, with the implementation,\nor just in general with convolutional neural nets.",
    "start": "2580770",
    "end": "2587300"
  },
  {
    "text": "So one of them is that\n1,000 categories, well, it may seem like a lot-- ImageNet is actually one of\nthe largest competitions--",
    "start": "2587300",
    "end": "2594012"
  },
  {
    "text": "that's not actually\nthat many categories. So it doesn't contain things\nlike hot air balloons, for instance.",
    "start": "2594012",
    "end": "2599330"
  },
  {
    "text": "So these things that children\nwould be able to classify, the neural nets actually\naren't able to, even",
    "start": "2599330",
    "end": "2605400"
  },
  {
    "text": "in the biggest competition. And each of these\ncategories also requires thousands\nof training images,",
    "start": "2605400",
    "end": "2611940"
  },
  {
    "text": "whereas you could\nshow a child a couple examples of a dog\nor a cat, and they'd be able to, generally, get a\nfeel for what a dog or a cat",
    "start": "2611940",
    "end": "2619740"
  },
  {
    "text": "looks like. It takes thousands of images\nper category for the neural nets to learn, which means\nthat the total number of images",
    "start": "2619740",
    "end": "2626850"
  },
  {
    "text": "you need to train for\nthe ImageNet competition is over a million. And so this leads to\nvery long training times,",
    "start": "2626850",
    "end": "2634200"
  },
  {
    "text": "even with all of the\nheavy optimizations that Ishwari was telling\nus about like how",
    "start": "2634200",
    "end": "2639300"
  },
  {
    "text": "efficient convolution\nis, it still takes weeks to train on multiple\nparallel GPUs working together",
    "start": "2639300",
    "end": "2647970"
  },
  {
    "text": "to train the net. There's actually a more\nfundamental problem with neural nets as well.",
    "start": "2647970",
    "end": "2654500"
  },
  {
    "text": "So here on the left, we have a\nschool bus, some kind of bird, and an Indian temple.",
    "start": "2654500",
    "end": "2660173"
  },
  {
    "text": "And all of these\nimages on the left side are actually\ncorrectly identified by convolutional neural nets.",
    "start": "2660174",
    "end": "2665670"
  },
  {
    "text": "But when we add this\nsmall distortion here in the middle, that doesn't\nchange any of the images",
    "start": "2665670",
    "end": "2672290"
  },
  {
    "text": "perceptively to the\nhuman, this actually causes the neural network\nto misclassify these images,",
    "start": "2672290",
    "end": "2679660"
  },
  {
    "text": "and now all three of\nthem are ostriches. So that's a little weird. How does this work?",
    "start": "2679660",
    "end": "2686020"
  },
  {
    "text": "How did we find\nthose distortions. So here on the left side, we see\nhow a neural network typically works.",
    "start": "2686020",
    "end": "2691250"
  },
  {
    "text": "You start with some\nimages, you put it through the different layers\nof the neural network, and then it tells you\na certain probability",
    "start": "2691250",
    "end": "2698630"
  },
  {
    "text": "that it is a guitar,\nor a penguin. So it classifies\nit, and so we can",
    "start": "2698630",
    "end": "2704160"
  },
  {
    "text": "use a modification\nof that method by applying an\nevolutionary algorithm,",
    "start": "2704160",
    "end": "2711120"
  },
  {
    "text": "or a hill-climbing or\ngradient ascent algorithm. We take a couple of images,\nand we put them through,",
    "start": "2711120",
    "end": "2716839"
  },
  {
    "text": "it classifies it, and we see\nwhat the classification is. And then we can do some\ncrossover between the images.",
    "start": "2716840",
    "end": "2723590"
  },
  {
    "text": "So we take the ones that look\na lot like what we're training for in the guitars or\npenguins, in this case,",
    "start": "2723590",
    "end": "2731150"
  },
  {
    "text": "and we take the\nfeatures of those that identify very\nstrongly as a guitar, and we combine those together\nin the crossover phase.",
    "start": "2731150",
    "end": "2737900"
  },
  {
    "text": "This is for the\nevolutionary algorithm. Then we mutate the images,\nwhich is making small changes to each one, and\nthen we re-evaluate",
    "start": "2737900",
    "end": "2745275"
  },
  {
    "text": "by plugging it back in\nthrough the neural network, and only the best\nimages, the ones that looked the most\nlike a guitar or penguin,",
    "start": "2745275",
    "end": "2751860"
  },
  {
    "text": "are then selected for\nthe next iteration. And this continues until you get\nto a very high identification",
    "start": "2751860",
    "end": "2756980"
  },
  {
    "text": "rates, even higher than\nactual images of the objects.  So using gradient ascent, these\nare some of the images that you",
    "start": "2756980",
    "end": "2764560"
  },
  {
    "text": "could produce if you start\nwith just a flat grey image, and then you run it\nthrough this algorithm.",
    "start": "2764560",
    "end": "2771530"
  },
  {
    "text": "So here on the side,\nwe have a backpack, and we can actually\nsee the outline of what looks like a backpack in there.",
    "start": "2771530",
    "end": "2778200"
  },
  {
    "text": "And over here, we have what\nlooks like a Windsor tie right here, but all of\nthese objects-- and perhaps,",
    "start": "2778200",
    "end": "2784185"
  },
  {
    "text": "there are things in\nthese other images, but they seem to be lost in\nthe LSD trip of colors here.",
    "start": "2784185",
    "end": "2791610"
  },
  {
    "text": "So that's kind of strange. That's definitely\nnot how humans do it. So let's try a different method. What if instead of\ndirectly encoding,",
    "start": "2791610",
    "end": "2797580"
  },
  {
    "text": "which is where we change\nindividual pixels, what if we change\npatterns in the images,",
    "start": "2797580",
    "end": "2802710"
  },
  {
    "text": "like different shapes? Then this is the kind\nof output that we get. So in the upper left,\nwe have a starfish.",
    "start": "2802710",
    "end": "2809830"
  },
  {
    "text": "So you can see that it\nhas the orange and blue of the orange in the\nstarfish, and also the blue of the ocean\nof the environment",
    "start": "2809830",
    "end": "2816355"
  },
  {
    "text": "that typical images of\nstarfish are taken in. And you can also see that it has\nthe points, the jagged lines,",
    "start": "2816355",
    "end": "2822810"
  },
  {
    "text": "the triangles that we associate\nwith the arms of a starfish. But the strange thing\nhere is that they're not",
    "start": "2822810",
    "end": "2828110"
  },
  {
    "text": "arranged in a circular pattern. They're not pointing\noutwards like this, like we would expect\nof an actual starfish.",
    "start": "2828110",
    "end": "2836230"
  },
  {
    "text": "So clearly, it's not latching\nonto the same large scale features that humans do.",
    "start": "2836230",
    "end": "2842109"
  },
  {
    "text": "It's actually just looking\nat the low down features. Even though it's a\ndeep neural network,",
    "start": "2842110",
    "end": "2847530"
  },
  {
    "text": "it doesn't grab onto\nthese abstract concepts like a human would.",
    "start": "2847530",
    "end": "2854980"
  },
  {
    "text": "So the reason for this\nproblem, or at least why we think neural\nnetworks aren't as good as humans at things\nlike this is the type of model.",
    "start": "2854980",
    "end": "2863210"
  },
  {
    "text": "So a human would\nhave more of what's called a generative model,\nwhich means if we have examples here, these dark blue\ndots, say, of lines,",
    "start": "2863210",
    "end": "2871990"
  },
  {
    "text": "a few examples of\nimages of lines, then we could construct a\nprobability distribution,",
    "start": "2871990",
    "end": "2878079"
  },
  {
    "text": "and say that images that\nfall somewhere in this region are lines. And over here, we have a few\nexamples of giraffes, say,",
    "start": "2878080",
    "end": "2886060"
  },
  {
    "text": "and so anything that falls in\nthis region would be a giraffe. And so if you had a red triangle\nin here, that would be a lion.",
    "start": "2886060",
    "end": "2892710"
  },
  {
    "text": "But if the red triangle\nis instead over here, it actually wouldn't\nclassify at all. We wouldn't know what that is.",
    "start": "2892710",
    "end": "2898570"
  },
  {
    "text": "We would say that's something\nother than a lion or a giraffe, but neural networks\ndon't work the same way.",
    "start": "2898570",
    "end": "2903990"
  },
  {
    "text": "They just draw a\ndecision boundary. They just draw lines between\nthe different categories.",
    "start": "2903990",
    "end": "2909505"
  },
  {
    "text": "So they don't say that something\nreally far away from the lion class is necessary not a lion.",
    "start": "2909505",
    "end": "2917080"
  },
  {
    "text": "It just depends how far away it\nis from the decision boundary. So if we have the red\ntriangle way over there,",
    "start": "2917080",
    "end": "2922770"
  },
  {
    "text": "it's very far away\nfrom giraffes, and it's just\ngenerally closer lions, even though it isn't explicitly\nvery close to it at all,",
    "start": "2922770",
    "end": "2930890"
  },
  {
    "text": "and that will still be\nidentified as a lion. So that's why we think\nwe're able to fool",
    "start": "2930890",
    "end": "2937200"
  },
  {
    "text": "these neural networks in such\na simplistic way or in such a really abstract way.",
    "start": "2937200",
    "end": "2943842"
  },
  {
    "text": "So the main takeaways\nfrom our presentation, and the salient points\nare that deep learning",
    "start": "2943842",
    "end": "2949980"
  },
  {
    "text": "is a very powerful tool\nfor image classification, and it relies on multiple\nlayers of a network.",
    "start": "2949980",
    "end": "2957035"
  },
  {
    "text": "So multiple processing layers. Also CNNs outperform\nbasically every other method",
    "start": "2957035",
    "end": "2964190"
  },
  {
    "text": "for classifying images, and\nthat's their primary use right now. We're currently\nexploring other uses,",
    "start": "2964190",
    "end": "2970810"
  },
  {
    "text": "but that's generally\nwhere it's at, and this is because\nconvolutional filters are just",
    "start": "2970810",
    "end": "2975970"
  },
  {
    "text": "so incredibly powerful. They're very fast\nand very efficient.",
    "start": "2975970",
    "end": "2981250"
  },
  {
    "text": "Also back propagation is the way\nthat we train neural networks. Normally, if you were to\ntrain a neural network that",
    "start": "2981250",
    "end": "2987280"
  },
  {
    "text": "has a lot of layers, there's\nactually an exponential growth in the time it takes to train\nbecause of the branching when",
    "start": "2987280",
    "end": "2994470"
  },
  {
    "text": "you go backwards because\neach neuron is connected to a large number of neurons\nin the previous layer.",
    "start": "2994470",
    "end": "2999590"
  },
  {
    "text": "You get this exponential growth\nin the number of dependencies from a given neuron. By using back\npropagation, it actually",
    "start": "2999590",
    "end": "3006910"
  },
  {
    "text": "reduces it to linear time\nto train the networks. So this allows for\nefficient training.",
    "start": "3006910",
    "end": "3012599"
  },
  {
    "text": "And even with back\npropagation and convolution being so efficient, it still\ntakes a very large number",
    "start": "3012600",
    "end": "3020130"
  },
  {
    "text": "of images, and a long time\nwith a lot of processing power to train neural networks.",
    "start": "3020130",
    "end": "3027900"
  },
  {
    "start": "3027000",
    "end": "3027000"
  },
  {
    "text": "Also, if you'd\nlike to get started working with neural\nnetworks, there are a couple of really nice\nopen source programming",
    "start": "3027900",
    "end": "3036870"
  },
  {
    "text": "platforms for neural networks. So one of them that we used\nfor our pset was actually TensorFlow, which is Google's\nopen source neural network",
    "start": "3036870",
    "end": "3044440"
  },
  {
    "text": "platform, and\nanother one would be Cafe, which is Berkley's\nneural network platform.",
    "start": "3044440",
    "end": "3049839"
  },
  {
    "text": "And they actually\nhave an online demo where you can plug in\nimages, and immediately get identifications.",
    "start": "3049839",
    "end": "3055590"
  },
  {
    "text": "So you can get started\nvery quickly with that one. Thank you.",
    "start": "3055590",
    "end": "3061410"
  },
  {
    "start": "3061410",
    "end": "3111264"
  }
]
[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6950"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "6950",
    "end": "13500"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "13500",
    "end": "19730"
  },
  {
    "start": "19730",
    "end": "30430"
  },
  {
    "start": "28000",
    "end": "340000"
  },
  {
    "text": "PROFESSOR: So John is going to\npresent project three, beta.",
    "start": "30430",
    "end": "35490"
  },
  {
    "text": "JOHN: All right. So here's the performance\ngrades. In general, the submission went\na lot better than last",
    "start": "35490",
    "end": "41180"
  },
  {
    "text": "time in that things were on\ntime and nobody failed to build, or forgot to add files\nto their project, or so on.",
    "start": "41180",
    "end": "50020"
  },
  {
    "text": "We did change the scoring\nmechanism a little bit. In the [? mdriver ?]",
    "start": "50020",
    "end": "56430"
  },
  {
    "text": "that we gave you, if your\nvalidator failed you on any of your traces, your\nscore is a zero.",
    "start": "56430",
    "end": "62460"
  },
  {
    "text": "In this one, we decided\nto be nicer. We replaced your validator with\nour correct validator.",
    "start": "62460",
    "end": "68080"
  },
  {
    "text": "And for traces that you failed,\nyou get a zero for the points that those traces\ncontribute. But you did get an overall\npartial score, even if you",
    "start": "68080",
    "end": "76000"
  },
  {
    "text": "failed a couple traces. So on that note, the reference\nimplementation does get a 56",
    "start": "76000",
    "end": "83330"
  },
  {
    "text": "on this score. And there were people who had\nslower than reference implementations that\nlanded below 56.",
    "start": "83330",
    "end": "90750"
  },
  {
    "text": "So that might be something to\nthink about for your final submission. The high score was a 96.",
    "start": "90750",
    "end": "96540"
  },
  {
    "text": "And there were actually quite\na few groups in the 90s. So overall, people did\nreally well on this.",
    "start": "96540",
    "end": "103330"
  },
  {
    "text": "With that said, your validators\ndidn't really--",
    "start": "103330",
    "end": "109160"
  },
  {
    "text": "I guess they were OK. But there's some people whose\nvalidators failed projects",
    "start": "109160",
    "end": "116799"
  },
  {
    "text": "that were correct, and other\npeople whose validators failed to detect certain situations. So that's also something to\nwork on for the final.",
    "start": "116800",
    "end": "124650"
  },
  {
    "text": "We won't be releasing the\nstock validators. So it'll be up to you guys to\nfind out what's wrong with your validators and fix them.",
    "start": "124650",
    "end": "131750"
  },
  {
    "text": "And along the same lines of\ncorrectness, once again, for the final submission,\nwe'll be running--",
    "start": "131750",
    "end": "136849"
  },
  {
    "text": "actually even for the beta,\nI believe, we're going to Valgrind your projects and\nlook for memory errors.",
    "start": "136850",
    "end": "142610"
  },
  {
    "text": "So do that to your own projects\nand investigate any messages you get. ",
    "start": "142610",
    "end": "152267"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] JOHN: OK. So the highlighted column\nnumber 31 refers to the",
    "start": "152267",
    "end": "160890"
  },
  {
    "text": "reference implementation\nof the validator. So that's the authority. If that's green, then your\nimplementation is correct.",
    "start": "160890",
    "end": "168110"
  },
  {
    "text": "And so hopefully, a correct\nvalidator would agree with column 31. ",
    "start": "168110",
    "end": "176210"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]  JOHN: Yes. AUDIENCE: [INAUDIBLE]",
    "start": "176210",
    "end": "181862"
  },
  {
    "text": "question. How can it be that most of-- so an implementation is\nvertical, so tests are",
    "start": "181862",
    "end": "188724"
  },
  {
    "text": "[UNINTELLIGIBLE]? JOHN: No. The implementations are\nhorizontal, and the tests are vertical.",
    "start": "188725",
    "end": "195073"
  },
  {
    "text": "AUDIENCE: So we want our column\nto look like column 31? Or we want-- JOHN: You want-- your validators\ncorrectness score",
    "start": "195074",
    "end": "200819"
  },
  {
    "text": "will be determined by whether\nor not your column number",
    "start": "200820",
    "end": "207590"
  },
  {
    "text": "corresponds with column 31. And then, your implementations\ncorrectness will purely be",
    "start": "207590",
    "end": "213129"
  },
  {
    "text": "determined by whether 31 marks\nyour row red or green. ",
    "start": "213130",
    "end": "219910"
  },
  {
    "text": "Does that make sense?  AUDIENCE: [INAUDIBLE PHRASE]",
    "start": "219910",
    "end": "225452"
  },
  {
    "text": "columns that are all green,\nour validators are not [UNINTELLIGIBLE]? Is that what you're saying? PROFESSOR: That's right. JOHN: That's correct.",
    "start": "225452",
    "end": "231500"
  },
  {
    "text": "PROFESSOR: Whereas the rows that\nare green, that's what we like to see. We like green rows.",
    "start": "231500",
    "end": "237519"
  },
  {
    "text": "And then, we like columns\nthat match column 31. AUDIENCE: [INAUDIBLE PHRASE]. ",
    "start": "237520",
    "end": "244359"
  },
  {
    "text": "The first row should\nbe all red. And right now, [INAUDIBLE].",
    "start": "244359",
    "end": "250210"
  },
  {
    "text": "JOHN: Right. PROFESSOR: That's correct. JOHN: Whatever error this\nperson had, very few validators seems to\nhave caught them.",
    "start": "250210",
    "end": "256208"
  },
  {
    "text": "Which is very surprising,\nbecause what we did for your validator.c is that we removed\nthe line of code that it",
    "start": "256209",
    "end": "263220"
  },
  {
    "text": "contained, and we added the\ncomment that explained in English exactly what that\nline of code did.",
    "start": "263220",
    "end": "269070"
  },
  {
    "text": "So it was kind of interesting to\nsee that not everybody came up with the validator that's\nidentical to reference one.",
    "start": "269070",
    "end": "275199"
  },
  {
    "text": " PROFESSOR: OK-- JOHN:JOHN: Yeah. So please run Valgrind on your\ncode before the final",
    "start": "275200",
    "end": "282630"
  },
  {
    "text": "submission. And we'll be posting your\npersonalized results to your",
    "start": "282630",
    "end": "287669"
  },
  {
    "text": "repose sometime probably by\nthe end of the day, either today or tomorrow.",
    "start": "287670",
    "end": "293480"
  },
  {
    "text": "PROFESSOR: Great. All right, you can take\nthis [UNINTELLIGIBLE]. Or you can [UNINTELLIGIBLE]. Here you go. You guys can have it here, in\ncase you need to chip in.",
    "start": "293480",
    "end": "300520"
  },
  {
    "start": "300520",
    "end": "305550"
  },
  {
    "text": "OK. So today, we're going to talk\nabout programming in parallel.",
    "start": "305550",
    "end": "311960"
  },
  {
    "text": "Parallel programming\nand so forth. So this is I'm sure what you've\nall been waiting for. Oops.",
    "start": "311960",
    "end": "318060"
  },
  {
    "text": "Oh, we have no power here. There we go. ",
    "start": "318060",
    "end": "330710"
  },
  {
    "text": "There we go. Now I've got power. ",
    "start": "330710",
    "end": "337169"
  },
  {
    "text": "OK. Let's see here. How's that?",
    "start": "337170",
    "end": "342420"
  },
  {
    "start": "340000",
    "end": "767000"
  },
  {
    "text": "Good. OK. So we talk about multicore\nprogramming. And let me start with a\nlittle bit of history.",
    "start": "342420",
    "end": "352990"
  },
  {
    "text": " So since the mid\nto late 1960s--",
    "start": "352990",
    "end": "363890"
  },
  {
    "text": "so how many years is that? 50 years. Wow. ",
    "start": "363890",
    "end": "371229"
  },
  {
    "text": "Semiconductor density\nhas been increasing at the rate of about--",
    "start": "371230",
    "end": "377811"
  },
  {
    "text": "it's been doubling about\nevery 18 to 24 months. OK. So every year, every one to two\nyears, every year and a",
    "start": "377812",
    "end": "394100"
  },
  {
    "text": "half to two years, we\nget a doubling of density on the chips.",
    "start": "394100",
    "end": "400410"
  },
  {
    "text": "And that's a trend that\nstill is continuing. OK. So that's called Moore's law,\nthe doubling of density of",
    "start": "400410",
    "end": "407620"
  },
  {
    "text": "integrated circuits. And so, this is basically a\ncurve showing how transistor",
    "start": "407620",
    "end": "413890"
  },
  {
    "text": "count is rising. OK. So all these green things are\nIntel CPUs and what the",
    "start": "413890",
    "end": "421060"
  },
  {
    "text": "transistor count is on them. Yeah, question? AUDIENCE: [INAUDIBLE PHRASE]",
    "start": "421060",
    "end": "426210"
  },
  {
    "text": "the lines in [INAUDIBLE]? PROFESSOR: So there have\nbeen some technology",
    "start": "426210",
    "end": "432150"
  },
  {
    "text": "changes along the way. So in particular, the\n[UNINTELLIGIBLE] transition is",
    "start": "432150",
    "end": "439530"
  },
  {
    "text": "back down here I think. I don't remember which\none that is.",
    "start": "439530",
    "end": "444811"
  },
  {
    "text": "Well, this is actually\na different one. What we're looking at right now\nis the transistors, which have been very smooth.",
    "start": "444812",
    "end": "451590"
  },
  {
    "text": "OK. So I'll explain this\ncurve in a minute. So there's two things\nplotted on here. One is the Intel CPU density,\nand the other is what the",
    "start": "451590",
    "end": "462000"
  },
  {
    "text": "clock speed of those\nprocesses is. And so these are the clock\nspeed numbers.",
    "start": "462000",
    "end": "468449"
  },
  {
    "text": "And so, the integrated circuit\ntechnology has been--",
    "start": "468450",
    "end": "474890"
  },
  {
    "text": "the density has been doubling. And it's really an unbelievable\nsort of social",
    "start": "474890",
    "end": "480400"
  },
  {
    "text": "and economic process, that\nthis has basically been called a law.",
    "start": "480400",
    "end": "486789"
  },
  {
    "text": "Because what happens is if a-- there's so many people that\ncontribute to making",
    "start": "486790",
    "end": "494020"
  },
  {
    "text": "integrated circuits be dense. There's so many pieces of\ntechnology that go into that. And what happens is if you\ndecide that you're going to",
    "start": "494020",
    "end": "501360"
  },
  {
    "text": "try to jump and try to make\nsomething that goes faster than Moore's law, what happens\nis it's more expensive",
    "start": "501360",
    "end": "508490"
  },
  {
    "text": "for you to do it. And none of the other\nparticipants in that economy",
    "start": "508490",
    "end": "513860"
  },
  {
    "text": "can keep up. And you're just going to\nbe more expensive. So people will op for the\ncheapest thing that gets the",
    "start": "513860",
    "end": "521159"
  },
  {
    "text": "factor of two every\n18 to 24 months. Whereas if you're behind, then\nnobody uses your stuff.",
    "start": "521159",
    "end": "531019"
  },
  {
    "text": "So everybody's got this sort\nof self-fulfilling prophecy that the rate at which the\ndensity is increasing has just",
    "start": "531020",
    "end": "539610"
  },
  {
    "text": "been extremely stable\nfor over 50 years. It's remarkable. Yeah, question?",
    "start": "539610",
    "end": "545544"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE PHRASE]  every six months.",
    "start": "545544",
    "end": "551118"
  },
  {
    "text": "And somehow, [INAUDIBLE] you would have self-replicated? PROFESSOR: No, I'm\nnot saying that.",
    "start": "551118",
    "end": "556500"
  },
  {
    "text": "What I'm saying is that there\nis some amount of everybody",
    "start": "556500",
    "end": "562230"
  },
  {
    "text": "expecting that this\nis the point that everybody's going to be at. And so if you try to go more\naggressively than that, you",
    "start": "562230",
    "end": "570720"
  },
  {
    "text": "can get burned because you'll\nbe more expensive. If you don't go that fast,\nyou're going to get burned",
    "start": "570720",
    "end": "575860"
  },
  {
    "text": "because nobody's going to adopt\nyour particular piece of the technology. And so, what happens is\neverybody sort of settles for",
    "start": "575860",
    "end": "583500"
  },
  {
    "text": "this regular repeating. It's a remarkable social and\neconomic phenomenon.",
    "start": "583500",
    "end": "590540"
  },
  {
    "text": "It's got very little to do at\nsome level of technology. It's just that we know that\nwe can improve things.",
    "start": "590540",
    "end": "596530"
  },
  {
    "text": "But what's amazing is this\ngrowth has gone through many transitions. At one point, they said we\naren't going to be able to",
    "start": "596530",
    "end": "603120"
  },
  {
    "text": "build integrated circuits any\nmore densely because all of",
    "start": "603120",
    "end": "608680"
  },
  {
    "text": "the masks that were made-- it's basically, you make\ncomputers with a photographic",
    "start": "608680",
    "end": "613970"
  },
  {
    "text": "process of exposing and\nusing masks that",
    "start": "613970",
    "end": "620110"
  },
  {
    "text": "you shine light through. It's the way they\nused to do it. And what happened was the wave\nlengths of light were such",
    "start": "620110",
    "end": "626360"
  },
  {
    "text": "that you were just simply not\ngoing to be able to get the resolutions. So what did they do? They switched to eBeams.",
    "start": "626360",
    "end": "632160"
  },
  {
    "text": "OK. Electrons rather than photons\nto expose the silicon wafers",
    "start": "632160",
    "end": "638180"
  },
  {
    "text": "and so forth. And so, they've gone through a\nwhole bunch of transitions and different technologies. And yet, throughout all of that,\nit's been just a very",
    "start": "638180",
    "end": "647019"
  },
  {
    "text": "steady progress at about the\nrate of 18 to 24 months per doubling of density.",
    "start": "647020",
    "end": "653240"
  },
  {
    "text": "And that is still going on,\nand is projected to go on maybe for 10 years more.",
    "start": "653240",
    "end": "659980"
  },
  {
    "text": "It's going to run out, I\nhope in my lifetime. ",
    "start": "659980",
    "end": "666000"
  },
  {
    "text": "And certainly within\nyour lifetimes. So that has been going.",
    "start": "666000",
    "end": "672710"
  },
  {
    "text": "Then, there's second phenomenon\nthat has been going on since about mid-1980s.",
    "start": "672710",
    "end": "682200"
  },
  {
    "text": "And that is that the clock\nspeed has actually been growing on a similar curve,\nwhere basically, we've been",
    "start": "682200",
    "end": "690730"
  },
  {
    "text": "getting 30% faster\nprocessors, clock",
    "start": "690730",
    "end": "698540"
  },
  {
    "text": "speed, since the mid-1980s. But something happened there,\nwhich was in around 2003, it",
    "start": "698540",
    "end": "707140"
  },
  {
    "text": "flattened out.  And the reason is, as a\npractical matter, clock speed",
    "start": "707140",
    "end": "717320"
  },
  {
    "text": "for air cooled systems\nis bounded at somewhere around 5 gigahertz. If you want to liquid cool\nit or nitrogen cool it or",
    "start": "717320",
    "end": "727449"
  },
  {
    "text": "something, you could\nmake it go faster. But basically, the problem is\nthat things get too hot.",
    "start": "727450",
    "end": "735240"
  },
  {
    "text": "And they cannot convey\nthe heat out. So for a while, if you have\ngreater density, the",
    "start": "735240",
    "end": "740680"
  },
  {
    "text": "transistors get smaller. They switch faster. And you can make the clock\nspeed go faster.",
    "start": "740680",
    "end": "746030"
  },
  {
    "text": "But at some point, they\nhit the wall. And so there the vendors were. People like Intel,\nAMD, Motorola.",
    "start": "746030",
    "end": "755149"
  },
  {
    "text": "A variety of the semiconductor\nmanufacturers. And what's happened is they\ncan still make integrated",
    "start": "755150",
    "end": "761860"
  },
  {
    "text": "circuits more and more dense. But they can't clock\nthem any faster.",
    "start": "761860",
    "end": "767820"
  },
  {
    "start": "767000",
    "end": "961000"
  },
  {
    "text": "OK. So here's what's going\non in the circuits.",
    "start": "767820",
    "end": "773230"
  },
  {
    "text": "So here's essentially how much\npower was being dissipated by a variety of Intel processors\nalong the way, and what they",
    "start": "773230",
    "end": "781960"
  },
  {
    "text": "[INAUDIBLE] 2000. They started getting hot and\nhotter, until if they just",
    "start": "781960",
    "end": "787019"
  },
  {
    "text": "continued this trend, they were\ngoing to be trying to",
    "start": "787020",
    "end": "795610"
  },
  {
    "text": "have junction temperatures that\nare as hot as the surface of the sun. Well, they clearly\ncouldn't do that.",
    "start": "795610",
    "end": "802140"
  },
  {
    "text": "OK. So you might say, well, let's\nput it off a few years. Yeah, but how many years are\nyou going to put this off?",
    "start": "802140",
    "end": "808200"
  },
  {
    "text": "And so, what happened\nwas they got stuck. They simply could not make chips\nget clocked in faster.",
    "start": "808200",
    "end": "817620"
  },
  {
    "text": "So what did they decide to do? They got all the silicon area,\nbut they can't make the",
    "start": "817620",
    "end": "823110"
  },
  {
    "text": "processors faster with it. So their solution was to scale\nperformance to put many",
    "start": "823110",
    "end": "831720"
  },
  {
    "text": "processing cores on the\nmicroprocessor chip. So this is an example\nof a Core i7.",
    "start": "831720",
    "end": "837895"
  },
  {
    "text": "It's a four core. One, two, three, four\ncores processor. We actually have six\ncore machines now.",
    "start": "837895",
    "end": "844020"
  },
  {
    "text": "But I didn't update\nthe figure. And what's going to happen now\nis Moore's law is going to",
    "start": "844020",
    "end": "851699"
  },
  {
    "text": "continue for a few more years. And so it looks like each new\ngeneration of Moore's law is",
    "start": "851700",
    "end": "857180"
  },
  {
    "text": "going to potentially double the\nnumber of cores per chip. So you folks are using\n12 core machines.",
    "start": "857180",
    "end": "865089"
  },
  {
    "text": "Two six core chips. Well, that's going to basically\nkeep increasing.",
    "start": "865090",
    "end": "872210"
  },
  {
    "text": "And so, we're going to get more\nand more cores per chip. OK. That's all well and good. But it turns out that there's\na major issue.",
    "start": "872210",
    "end": "882110"
  },
  {
    "text": "And that's software. Everybody has written\ntheir software. And there's billions and\nbillions and billions of",
    "start": "882110",
    "end": "890050"
  },
  {
    "text": "dollars invested in existing\nlegacy software that's written for how many cores?",
    "start": "890050",
    "end": "897040"
  },
  {
    "text": "One. And moving it to multicore is a",
    "start": "897040",
    "end": "904220"
  },
  {
    "text": "nightmare for these companies. OK. And it's potentially a nightmare\nfor these vendors.",
    "start": "904220",
    "end": "909850"
  },
  {
    "text": "Because if people say, gee, you\ncan't make the processors go any faster, why should\nI buy a new processor?",
    "start": "909850",
    "end": "916769"
  },
  {
    "text": "My old processor is as\ngood as my new one. OK. And so, anyway, so that's\nsometimes been called the",
    "start": "916770",
    "end": "925100"
  },
  {
    "text": "multicore challenge. The multicore menace. The multicore revolution.",
    "start": "925100",
    "end": "933860"
  },
  {
    "text": "Whatever. But that's what it's\nall about. It's all about the issue of the\nfrequency scaling of the",
    "start": "933860",
    "end": "939260"
  },
  {
    "text": "clocks, verses, Moore's law. Which talks about what\nthe density is.",
    "start": "939260",
    "end": "946300"
  },
  {
    "text": "OK. So their solution is to do-- and so what we're going to talk\nabout for a bunch of the",
    "start": "946300",
    "end": "952130"
  },
  {
    "text": "rest of the term is going to\nbe, how do you actually program multicore processors?",
    "start": "952130",
    "end": "958300"
  },
  {
    "text": "We're going to look at some\nfairly new software technology for doing that. So here's an abstract multicore\narchitecture.",
    "start": "958300",
    "end": "968170"
  },
  {
    "start": "961000",
    "end": "1056000"
  },
  {
    "text": "It's not precise. This is only showing\none level of cache. So we have processors connected\nto a cache.",
    "start": "968170",
    "end": "974850"
  },
  {
    "text": "In fact, of course, you\nknow that there are multiple levels of cache.",
    "start": "974850",
    "end": "981070"
  },
  {
    "text": "Yeah, this is the international\nsymbol for cache if you live in the US. ",
    "start": "981070",
    "end": "989310"
  },
  {
    "text": "So the processors have\ntheir cache. Of course, you know that what\nactually happens is you have",
    "start": "989310",
    "end": "994610"
  },
  {
    "text": "multiple levels of cache. And it's shared cache\nat some levels. OK. So it's more complex\nthan this.",
    "start": "994610",
    "end": "1000120"
  },
  {
    "text": "But this is sort of an abstract\nway of understanding a bunch of the issues. And then, of course, they only\nget more complicated as we",
    "start": "1000120",
    "end": "1006779"
  },
  {
    "text": "look at reality, as with all\nthese hardware related things.",
    "start": "1006780",
    "end": "1014200"
  },
  {
    "text": "And so, this is a chip\nmultiprocessor. Now there are other ways\nof using the silicon. So another way of using the\nsilicon is building things",
    "start": "1014200",
    "end": "1020830"
  },
  {
    "text": "like graphics processors and\nusing silicon for a very special purpose thing.",
    "start": "1020830",
    "end": "1027130"
  },
  {
    "text": "So that instead of saying,\nlet's build multiple processors, you can say, let's\ndedicate some fraction of the",
    "start": "1027130",
    "end": "1033720"
  },
  {
    "text": "silicon real estate. Instead of to general purpose\ncomputing, let's dedicate it to some specific purpose, like\ngraphics, or some kind of",
    "start": "1033720",
    "end": "1042770"
  },
  {
    "text": "stream processing,\nor what have you. Sensor processing.",
    "start": "1042770",
    "end": "1049800"
  },
  {
    "text": "A variety of other things\nyou can do. But one main trend is doing\nchip multiprocessors. ",
    "start": "1049800",
    "end": "1057929"
  },
  {
    "text": "So we're going to talk\na little bit about shared memory hardware. Just enough to get you folks off\nthe ground to understand",
    "start": "1057930",
    "end": "1064679"
  },
  {
    "text": "what's going on underneath\nthe system. And then, we're going to talk\nabout four concurrency",
    "start": "1064680",
    "end": "1069710"
  },
  {
    "text": "platforms, which are not\nthe only platforms one can program in. But they're ones that you\nshould be familiar with.",
    "start": "1069710",
    "end": "1079640"
  },
  {
    "text": "The last one, Cilk++, is the\none we're going to do our programming assignments in.",
    "start": "1079640",
    "end": "1085520"
  },
  {
    "text": "And then, race conditions, we're\ngoing to talk about, because that's the biggest thing\nthat comes up when you",
    "start": "1085520",
    "end": "1093320"
  },
  {
    "text": "do parallel programming compared\nto ordinary serial programming. It's the most pernicious\ntype of bugs.",
    "start": "1093320",
    "end": "1099850"
  },
  {
    "text": "And you need to understand race\nconditions and need a way of handling it.",
    "start": "1099850",
    "end": "1105340"
  },
  {
    "text": "So here's basically-- so we'll start with shared\nmemory hardware. ",
    "start": "1105340",
    "end": "1113830"
  },
  {
    "start": "1110000",
    "end": "1535000"
  },
  {
    "text": "So the main thing that shared\nmemory hardware provides is a thing called cache coherence.",
    "start": "1113830",
    "end": "1119940"
  },
  {
    "text": "OK. And the basic idea is that you\nwant every processor to be",
    "start": "1119940",
    "end": "1125360"
  },
  {
    "text": "able to fetch stuff out\nof local caches because that's fast. But at the same time, you want\nthem to have a common view of",
    "start": "1125360",
    "end": "1135020"
  },
  {
    "text": "what is stored in a\ngiven location. So let's run through this\nexample and see what the",
    "start": "1135020",
    "end": "1140690"
  },
  {
    "text": "problem is. And then, I'll show\nyou how they solve it in sketchy detail. ",
    "start": "1140690",
    "end": "1149070"
  },
  {
    "text": "So here's a processor. Says he wants to load\nthe value of x. And in main memory here,\nx has got the value of",
    "start": "1149070",
    "end": "1154100"
  },
  {
    "text": "3, up here in DRAM. OK. So x moves through\nto the processor,",
    "start": "1154100",
    "end": "1160840"
  },
  {
    "text": "where it gets consumed. And it leaves behind the\nfact that x equals 3",
    "start": "1160840",
    "end": "1165850"
  },
  {
    "text": "in its local cache. Well, now along comes the\nsecond processor.",
    "start": "1165850",
    "end": "1172039"
  },
  {
    "text": "It says, I want x too. And perhaps the same\nthing happens.",
    "start": "1172040",
    "end": "1177500"
  },
  {
    "text": "Very good. So far, no problem. So two caches may have\nthe same value of x.",
    "start": "1177500",
    "end": "1183250"
  },
  {
    "text": "They may both want to\nuse x, and it's both in their local caches. Now comes along the\nthird processor.",
    "start": "1183250",
    "end": "1189960"
  },
  {
    "text": "Says load x as well. Well, it turns out that\nit's actually-- what I showed you on\nthe second case is",
    "start": "1189960",
    "end": "1195470"
  },
  {
    "text": "not the common case. If these two processors, these\ntwo processing cores, are on the same chip, it's generally\ncheaper for this guy to fetch",
    "start": "1195470",
    "end": "1204750"
  },
  {
    "text": "it out of one of these guys\ncaches than it is to fetch it out of DRAM.",
    "start": "1204750",
    "end": "1210500"
  },
  {
    "text": "DRAM is slow. Getting it locally\nis much cheaper. So basically, in this case, he\ngets it from this processor.",
    "start": "1210500",
    "end": "1220030"
  },
  {
    "text": "The first processor. All is well and good. They're all sharing\nmerrily around. OK.",
    "start": "1220030",
    "end": "1226110"
  },
  {
    "text": "And then this fella decides\nif he wants to load it, no problem. He can just load it.",
    "start": "1226110",
    "end": "1231399"
  },
  {
    "text": "He loads it locally. No problem. OK. This guy decides, oh,\nhe's going to store",
    "start": "1231400",
    "end": "1236409"
  },
  {
    "text": "some value to x. In this case, he's going\nto store the value 5. So he sets x equal to 5.",
    "start": "1236410",
    "end": "1243480"
  },
  {
    "text": "OK. fine. OK, now what? Now this guy says,\nlet me load x.",
    "start": "1243480",
    "end": "1251130"
  },
  {
    "text": "He gets the value x equals 3. Uh-oh. If your parallel program\nexpected that this guy had",
    "start": "1251130",
    "end": "1258810"
  },
  {
    "text": "gone first and it set x value\nx equal to 5, these guys are now incorrect.",
    "start": "1258810",
    "end": "1264250"
  },
  {
    "text": " And so, the idea of cache\ncoherence is not letting this",
    "start": "1264250",
    "end": "1271670"
  },
  {
    "text": "happen, making it so that\nwhenever a value is changed by",
    "start": "1271670",
    "end": "1278020"
  },
  {
    "text": "a processor, the other\nprocessors see that change and yet, they're still able most\nof the time to execute",
    "start": "1278020",
    "end": "1285330"
  },
  {
    "text": "effectively out of their\nown local caches. OK. So that's the problem.",
    "start": "1285330",
    "end": "1291660"
  },
  {
    "text": "So do people understand\nbasically what the cache coherence problem is?",
    "start": "1291660",
    "end": "1297470"
  },
  {
    "text": "Yes, question? AUDIENCE: If the last processor\nwas to store x and set x equals 5, as soon as that\nhappens, wouldn't that",
    "start": "1297470",
    "end": "1307408"
  },
  {
    "text": "write DRAM x equals 5? PROFESSOR: Good. So there's actually two\ntypes of strategies that are used in caches.",
    "start": "1307408",
    "end": "1314910"
  },
  {
    "text": "One is called write through. And one is called write back.",
    "start": "1314910",
    "end": "1320180"
  },
  {
    "text": "What you're describing\nis write through. What right through caches do\nis if you write a value, it",
    "start": "1320180",
    "end": "1325240"
  },
  {
    "text": "pushes it all the\nway out to DRAM. These days, nobody uses\nwrite through.",
    "start": "1325240",
    "end": "1331169"
  },
  {
    "text": "You're always going to DRAM. You're always exercising the\nslow DRAM versus being able to",
    "start": "1331170",
    "end": "1338610"
  },
  {
    "text": "just write it locally. But you do have to do something\nabout these guys",
    "start": "1338610",
    "end": "1343960"
  },
  {
    "text": "that are going to have\nthe shared values. So here's the mechanism\nthat they use.",
    "start": "1343960",
    "end": "1349290"
  },
  {
    "text": "So what most people do these\ndays is write back caches. Which basically means you only\nwrite it back when you really",
    "start": "1349290",
    "end": "1355890"
  },
  {
    "text": "need to evict or\nwhat have you. You don't always write it\nall the way through.",
    "start": "1355890",
    "end": "1363340"
  },
  {
    "text": "And so here's how these\nschemes work. So, right. So that's a bogus value for\nthat kind to be getting.",
    "start": "1363340",
    "end": "1371470"
  },
  {
    "text": "So let's take a look. So what they use is what's\ncalled-- the simplest is called an MSI protocol.",
    "start": "1371470",
    "end": "1379060"
  },
  {
    "text": "There are somewhat more\ncomplicated ones called MESI protocols, and ones\nthat are MOESI.",
    "start": "1379060",
    "end": "1386480"
  },
  {
    "text": "\"Mo-esi\" and \"messy\". Anyway, the MESI one is probably\nthe one you'll hear",
    "start": "1386480",
    "end": "1391610"
  },
  {
    "text": "most often. It's just a little bit more\ncomplicated than this one. But it saves you one extra\naccess when we do a write.",
    "start": "1391610",
    "end": "1402510"
  },
  {
    "text": "I'll explain it in\njust a minute. But let's first understand the\nsimplest of these mechanisms.",
    "start": "1402510",
    "end": "1408610"
  },
  {
    "text": "So what you do is in each cache,\nyou're going to label each cache line with a state.",
    "start": "1408610",
    "end": "1414840"
  },
  {
    "text": "And basically, it's because\nof these states that you associate with a cache line that\ncache lines end up having",
    "start": "1414840",
    "end": "1421419"
  },
  {
    "text": "to be long. OK? Because if you think about,\nyou'd like cache lines to be",
    "start": "1421420",
    "end": "1427100"
  },
  {
    "text": "at some level very short, in\nthat then you have more opportunity to have just the\nstuff in cache that you want,",
    "start": "1427100",
    "end": "1435480"
  },
  {
    "text": "from a temporal locality\npoint of view. It's one thing if you want to\nbring in extra lines, extra",
    "start": "1435480",
    "end": "1441160"
  },
  {
    "text": "data, for spatial locality. But to insist that it all be\nthere whether you access it or not, that's not clear how\nhelpful that it is.",
    "start": "1441160",
    "end": "1449870"
  },
  {
    "text": "However, what instead is we have\nthings like, on the Intel architecture, 64 bytes\nof cache line.",
    "start": "1449870",
    "end": "1456590"
  },
  {
    "text": "And the reason is because\nthey're keeping extra data with each cache line. And they want the data to be\nthe larger fraction of what",
    "start": "1456590",
    "end": "1465570"
  },
  {
    "text": "they're keeping compared\nto the control information about the data. So in this case, they're\nkeeping three values.",
    "start": "1465570",
    "end": "1471120"
  },
  {
    "text": "Three bits. The M bit says this cache\nblock has been modified.",
    "start": "1471120",
    "end": "1476370"
  },
  {
    "text": "Somebody's written to it. And what they do is they, in\nthis protocol, they guarantee",
    "start": "1476370",
    "end": "1483130"
  },
  {
    "text": "in the protocol that if somebody\nhas it in the M state, no other caches contain\nthis block in either the M",
    "start": "1483130",
    "end": "1490490"
  },
  {
    "text": "state or S state. So what are those states? So the S state is when\nother caches may be",
    "start": "1490490",
    "end": "1498540"
  },
  {
    "text": "sharing this block. And the I state is that this\ncache block is invalid.",
    "start": "1498540",
    "end": "1504280"
  },
  {
    "text": "It's the same as if\nit's not there. It's empty entry. So it just marks this entry.",
    "start": "1504280",
    "end": "1510460"
  },
  {
    "text": "There's no data there. The cache line that's there is\nnot really there, is basically",
    "start": "1510460",
    "end": "1516860"
  },
  {
    "text": "what it says. So here, you see for example\nthat this fella has x equals",
    "start": "1516860",
    "end": "1524100"
  },
  {
    "text": "13 in the modified state. And so, if you look across here,\noh, nobody else has that",
    "start": "1524100",
    "end": "1529770"
  },
  {
    "text": "in either the M or\nthe S state. They only have it in the\nI state or not at all.",
    "start": "1529770",
    "end": "1537160"
  },
  {
    "text": "If you have it in the shared\nstate, as these guys have, well, they all have it in the\nshared state and notice the values are all the same.",
    "start": "1537160",
    "end": "1545340"
  },
  {
    "text": "And then, if it's in the invalid\nstate, here this guy once again has it in the\nmodified state, which means",
    "start": "1545340",
    "end": "1551130"
  },
  {
    "text": "these guys don't have it in\neither the S or M state. So that's the invariant. So what's the basic idea\nbehind the cache?",
    "start": "1551130",
    "end": "1558950"
  },
  {
    "text": "The MSI protocol? The idea is that before you can\nwrite on a location, you",
    "start": "1558950",
    "end": "1565360"
  },
  {
    "text": "must first invalidate all\nthe other copies. ",
    "start": "1565360",
    "end": "1572259"
  },
  {
    "text": "So whenever you try to write\non something that's shared across a bunch of things or\nthat somebody else has modified, what happens is over\nthe network goes out a",
    "start": "1572260",
    "end": "1580940"
  },
  {
    "text": "protocol to invalidate\nall the other copies. So if they're just being shared,\nthat's no problem.",
    "start": "1580940",
    "end": "1587540"
  },
  {
    "text": "Because all you do\nis just have them drop it from the cache. If it's modified, then it may\nhave to be written back or the",
    "start": "1587540",
    "end": "1595000"
  },
  {
    "text": "value brought back to you, so\nthat you're in a position of changing it. If somebody has it modified,\nthen you don't have it.",
    "start": "1595000",
    "end": "1601610"
  },
  {
    "text": "So therefore, you need to\nbring it in and make the change to it. Question?",
    "start": "1601610",
    "end": "1607117"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nthree states? PROFESSOR: Three states. Not three bits. Two bits. Right.",
    "start": "1607117",
    "end": "1612900"
  },
  {
    "text": "OK. So the idea is you first\ninvalidate the other copies. Therefore, when a processor core\nis changing the value of",
    "start": "1612900",
    "end": "1623250"
  },
  {
    "text": "some variable, it has\nthe only copy. ",
    "start": "1623250",
    "end": "1628320"
  },
  {
    "text": "And by making sure that it only\nhas the only copy, you make sure that you never have\ncopies out there that are",
    "start": "1628320",
    "end": "1633659"
  },
  {
    "text": "anything except copies of\nwhat everybody else has.",
    "start": "1633660",
    "end": "1640020"
  },
  {
    "text": "That they're all the same. OK. Does everybody follow that?",
    "start": "1640020",
    "end": "1646320"
  },
  {
    "text": "So there's hardware under\nthere doing that. It's actually pretty\nclever hardware. In fact, the verification of\ncache protocols is a huge",
    "start": "1646320",
    "end": "1656550"
  },
  {
    "text": "problem for which there's a lot\nof technology built to try",
    "start": "1656550",
    "end": "1661780"
  },
  {
    "text": "to verify to make sure these\ncache protocols work the way they're supposed to work.",
    "start": "1661780",
    "end": "1666960"
  },
  {
    "text": "Because what happens in practice\nis there are all these intermediate states. What happens if this guy starts\ndoing this while this",
    "start": "1666960",
    "end": "1672980"
  },
  {
    "text": "guy is doing that, and these\nprotocols start getting mixed, and so forth?",
    "start": "1672980",
    "end": "1679130"
  },
  {
    "text": "And you've got to make\nsure that works out. And that's what's going\non in the hardware. The MESI protocol does a\nsimple optimization.",
    "start": "1679130",
    "end": "1687200"
  },
  {
    "text": "It says, look, before I store\nsomething, I probably want to read it.",
    "start": "1687200",
    "end": "1693230"
  },
  {
    "text": "It's likely I'm going\nto read it. So I can read it in two ways. I can read it in a way that\nsays that it is--",
    "start": "1693230",
    "end": "1701100"
  },
  {
    "text": "where it's just going\nto be shared. But if I expect that I'm going\nto write it, let me when I",
    "start": "1701100",
    "end": "1706390"
  },
  {
    "text": "read it instead of getting a\nshared copy, let me get an",
    "start": "1706390",
    "end": "1711530"
  },
  {
    "text": "exclusive copy. And that's where the\nE comes from. Let me get an exclusive copy. In other words, go through the\ninvalidation protocols on the",
    "start": "1711530",
    "end": "1719419"
  },
  {
    "text": "read, so that with the\nexpectation that when you write, you don't have to then\nwait for the invalidation to",
    "start": "1719420",
    "end": "1727320"
  },
  {
    "text": "occur at that point. So it's a way of reducing the\nlatency of the protocol by",
    "start": "1727320",
    "end": "1733980"
  },
  {
    "text": "getting it exclusively by\nthe read that you do before you do the write. So rather than doing a\nread, which would go",
    "start": "1733980",
    "end": "1741410"
  },
  {
    "text": "out and get the value-- but everybody [? has them ?] shared-- then doing the write,\nand then doing a whole",
    "start": "1741410",
    "end": "1747940"
  },
  {
    "text": "invalidation protocol, if I\nbasically get it in exclusive mode on the read, then I go out,\nI get the value, and I",
    "start": "1747940",
    "end": "1755480"
  },
  {
    "text": "invalidate everybody else. Now I've just saved myself\nhalf the work and half the latency.",
    "start": "1755480",
    "end": "1762630"
  },
  {
    "text": "Or basically saved myself\nsome latency. Not half the latency. OK?",
    "start": "1762630",
    "end": "1767900"
  },
  {
    "text": "So basically, what you should\nknow is there is invalidation stuff going on behind when you\nstart using shared memory,",
    "start": "1767900",
    "end": "1775030"
  },
  {
    "text": "behind the scenes which\ncan slow down your processor from executing.",
    "start": "1775030",
    "end": "1782799"
  },
  {
    "text": "Because it can't do the things\nthat it needs to do until it goes through the protocol.",
    "start": "1782800",
    "end": "1789810"
  },
  {
    "text": "Any questions about that? That's basically the level\nwe're going to cover the",
    "start": "1789810",
    "end": "1798920"
  },
  {
    "text": "hardware at. And so, you'll discover that in\ndoing some your problems,",
    "start": "1798920",
    "end": "1804510"
  },
  {
    "text": "that if you're not careful,\nyou're going to create what are called invalidation storms,\nwhere you have a whole",
    "start": "1804510",
    "end": "1810220"
  },
  {
    "text": "bunch of things that are red,\nand they're distributed across the processor. And then you go in, and\nyou set one value.",
    "start": "1810220",
    "end": "1816220"
  },
  {
    "text": "And suddenly, vrrrrrruuuum. Gee, how come that wasn't\na fast store?",
    "start": "1816220",
    "end": "1821419"
  },
  {
    "text": "The answer is it's going through\nand invalidating all those other copies. ",
    "start": "1821420",
    "end": "1827630"
  },
  {
    "text": "Good. So let's turn to the\nreal hard problem. So it turns out that building\nthese things is not",
    "start": "1827630",
    "end": "1835289"
  },
  {
    "text": "particularly well understood. But it's understood\na lot better than programming these beasts.",
    "start": "1835290",
    "end": "1841310"
  },
  {
    "text": "OK. And so, we're going to focus on\nsome of the strategies for",
    "start": "1841310",
    "end": "1847370"
  },
  {
    "text": "programming.  So it turns out that trying to\nprogram their processor cores",
    "start": "1847370",
    "end": "1855760"
  },
  {
    "start": "1849000",
    "end": "1917000"
  },
  {
    "text": "directly is painful. And you're liable to make a lot\nof errors, as we'll see.",
    "start": "1855760",
    "end": "1864110"
  },
  {
    "text": "Because we're going to talk\nabout races soon. And so the idea of a current\ncurrency platform is to do",
    "start": "1864110",
    "end": "1871910"
  },
  {
    "text": "some level of abstraction of the\nprocessor cores to handle synchronization communication\nprotocols, and often to do",
    "start": "1871910",
    "end": "1880540"
  },
  {
    "text": "things like load balancing, so\nthat the work that you're doing can be moved across from\nprocessor to processor.",
    "start": "1880540",
    "end": "1888750"
  },
  {
    "text": "And so, here are some examples\nof concurrency platforms. Pthreads and WinAPI threads,\nwe're going to talk more in",
    "start": "1888750",
    "end": "1894500"
  },
  {
    "text": "detail about. Pthreads is basically for\nUnix type systems, like Linux and such.",
    "start": "1894500",
    "end": "1900470"
  },
  {
    "text": "WinAPI threads is for Windows. There's threading building\nblocks, TBB, OpenMP, which is",
    "start": "1900470",
    "end": "1908380"
  },
  {
    "text": "a standard, and Cilk++. Those are all examples of\nconcurrency platforms that",
    "start": "1908380",
    "end": "1914059"
  },
  {
    "text": "make it easier to program\nthese parallel machines.",
    "start": "1914060",
    "end": "1919280"
  },
  {
    "start": "1917000",
    "end": "2067000"
  },
  {
    "text": "So I'm going to do, as an\nexample, I'm going to use the Fibonacci numbers, which you\nhave seen before I'm sure,",
    "start": "1919280",
    "end": "1926320"
  },
  {
    "text": "because we've actually even\nused it in this class. This is Leonardo da Pisa, who\nwas also known as Fibonacci.",
    "start": "1926320",
    "end": "1936040"
  },
  {
    "text": "And he introduced-- he was the most brilliant\nmathematician of his day. He came basically out of the\nblue, doing all kinds of",
    "start": "1936040",
    "end": "1944230"
  },
  {
    "text": "beautiful mathematics very\nearly in the Renaissance. You'll recognize 1202 is\nvery early Renaissance.",
    "start": "1944230",
    "end": "1951085"
  },
  {
    "text": " But it turns out, for those of\nyou of Indian descent, the",
    "start": "1951085",
    "end": "1958440"
  },
  {
    "text": "Indian mathematicians\nhad already discovered all this stuff. ",
    "start": "1958440",
    "end": "1963700"
  },
  {
    "text": "But it didn't make it into\nWestern culture except for Leonardo da Pisa.",
    "start": "1963700",
    "end": "1970040"
  },
  {
    "text": "So here's a program as you might\nwrite it in C. So Fib",
    "start": "1970040",
    "end": "1977740"
  },
  {
    "text": "int n says, well, if n is\nless than 2, return n. So if it's 0 or 1, we return,\nFib of 0 is 0.",
    "start": "1977740",
    "end": "1984100"
  },
  {
    "text": "Fib of 1 is 1. And otherwise, we compute Fib of\nn minus 1, compute Fib of n",
    "start": "1984100",
    "end": "1989815"
  },
  {
    "text": "minus 2, and return the sum. Simple recursive program. Here's the main routine.",
    "start": "1989815",
    "end": "1995080"
  },
  {
    "text": "We get the argument from the\ncommand line, compute the result, and then print\nout Fibonacci",
    "start": "1995080",
    "end": "2002169"
  },
  {
    "text": "of whatever is whatever. Pretty simple piece of code. So what we're going to do is\ntake a look at what happens in",
    "start": "2002170",
    "end": "2008240"
  },
  {
    "text": "each of these four concurrency\nplatforms to see how it is that they make this easy to\nrun this in parallel.",
    "start": "2008240",
    "end": "2017510"
  },
  {
    "text": "Now just a disclaimer here. This is a really bad way--",
    "start": "2017510",
    "end": "2022720"
  },
  {
    "text": "I hope you all recognize-- of computing Fibonacci\nnumbers. So this is exponential\ntime algorithm.",
    "start": "2022720",
    "end": "2029960"
  },
  {
    "text": "And you all know the linear\ntime algorithm, which is basically computed up\nfrom the bottom.",
    "start": "2029960",
    "end": "2035440"
  },
  {
    "text": "And some of you probably know\nthere's a logarithmic time algorithm based on squaring\nmatrices.",
    "start": "2035440",
    "end": "2040909"
  },
  {
    "text": "Two by two matrices.  So in any case, we're all\nabout performance here.",
    "start": "2040910",
    "end": "2052669"
  },
  {
    "text": "But obviously, this is a really\npoor choice to do performance on. But it is a good didactic\nexample, because it's so the",
    "start": "2052670",
    "end": "2059570"
  },
  {
    "text": "structure and the issues that\nyou get into in doing this with a very simple program that\nI can fit on a slide.",
    "start": "2059570",
    "end": "2068638"
  },
  {
    "text": "OK. So when you execute Fibonacci,\nwhen you call Fib of 4, it calls Fib of 3 and Fib of 2.",
    "start": "2068639",
    "end": "2076469"
  },
  {
    "text": "And Fib of 3 calls Fib\nof 2 and Fib of 1. And Fib of 1 just returns Fib\nof 2, calls [UNINTELLIGIBLE]",
    "start": "2076469",
    "end": "2082489"
  },
  {
    "text": "1, 0, et cetera. And so basically, you get an\nexecution trace that basically",
    "start": "2082489",
    "end": "2089658"
  },
  {
    "text": "corresponds to walk\nof this tree. So if you were doing this in C,\nyou'd basically call this,",
    "start": "2089659",
    "end": "2097720"
  },
  {
    "text": "call this, call this. Get a value return. Call this. Add the two values together.",
    "start": "2097720",
    "end": "2102930"
  },
  {
    "text": "Return here. Call this. Add the two values together. Call the return there. And so forth.",
    "start": "2102930",
    "end": "2108260"
  },
  {
    "text": "You walk that using a stack, a\ncall stack, in the execution. ",
    "start": "2108260",
    "end": "2115240"
  },
  {
    "text": "The key idea for parallelization\nis, well, gee. Fib of n minus 1 and fib of n\nminus 2 are really, in this",
    "start": "2115240",
    "end": "2123390"
  },
  {
    "text": "calculation, completely\nindependently calculated. So let's just do them\nat the same time. ",
    "start": "2123390",
    "end": "2131040"
  },
  {
    "text": "And they can be executed at\nthe same time without interference, because\nall they're doing is",
    "start": "2131040",
    "end": "2137350"
  },
  {
    "text": "basing it on n. They're not using any shared\nmemory or anything even for this particular program.",
    "start": "2137350",
    "end": "2143800"
  },
  {
    "start": "2142000",
    "end": "2241000"
  },
  {
    "text": "So let's take a look,\nto begin with, how Pthreads might do this. So Pthreads is a standard that\nANSI and the IEEE have",
    "start": "2143800",
    "end": "2156090"
  },
  {
    "text": "established for-- and I actually believe this is\na little bit out of date. I believe there's now\na 2010 version.",
    "start": "2156090",
    "end": "2163700"
  },
  {
    "text": "I'm not sure. But I recall that they were\nworking on a new version. But anyway, this is a recent\nenough standard.",
    "start": "2163700",
    "end": "2170330"
  },
  {
    "text": "It's a standard that has been\nrevised over the years, the so-called POSIX standard.",
    "start": "2170330",
    "end": "2175980"
  },
  {
    "text": "So you'll hear, Pthreads is\nbasically POSIX threads.",
    "start": "2175980",
    "end": "2181020"
  },
  {
    "text": "It's basically what you might\ncharacterize as a do it yourself concurrency platform. It's kind of like assembly\nlanguage for parallelism.",
    "start": "2181020",
    "end": "2190369"
  },
  {
    "text": "It allows you to do the things\nyou need to do, but you're sort of doing it all by hand,\none step at a time.",
    "start": "2190370",
    "end": "2198230"
  },
  {
    "text": "It's built as a library of\nfunctions with special non-C or C++ semantics.",
    "start": "2198230",
    "end": "2203440"
  },
  {
    "start": "2203440",
    "end": "2210760"
  },
  {
    "text": "And we'll look at what some\nof those semantics are. Each thread implements an\nabstraction of a processor,",
    "start": "2210760",
    "end": "2217670"
  },
  {
    "text": "which are multiplexed onto the\nmachine resources by the Pthread runtime implementation.",
    "start": "2217670",
    "end": "2225700"
  },
  {
    "text": "Threads communicate through\nshared memory. And library functions mask\nthe protocols involved in",
    "start": "2225700",
    "end": "2233090"
  },
  {
    "text": "interthread coordination. So you can start up threads, et\ncetera, and their library",
    "start": "2233090",
    "end": "2240290"
  },
  {
    "text": "function for doing that. So let's just see\nhow that works. So here are, basically, the two",
    "start": "2240290",
    "end": "2245860"
  },
  {
    "start": "2241000",
    "end": "2468000"
  },
  {
    "text": "important Pthread functions. There are actually a whole bunch\nof them, because they",
    "start": "2245860",
    "end": "2251560"
  },
  {
    "text": "also provide a bunch of\nother facilities. One is pthread_create, which\ncreates Pthread.",
    "start": "2251560",
    "end": "2258200"
  },
  {
    "text": "And one is pthread_join.  So pthread_create basically\nis return an identifier.",
    "start": "2258200",
    "end": "2269990"
  },
  {
    "text": "So when you say create a\nPthread, the Pthread system says, here's a handle by which\nyou can name this thread in",
    "start": "2269990",
    "end": "2275859"
  },
  {
    "text": "the future. OK. So it's a very common thing\nthat the implementer says, here's the name that you get.",
    "start": "2275860",
    "end": "2281730"
  },
  {
    "text": "It's called a handle. So it returns a handle. It then has an object to set\nvarious thread attributes.",
    "start": "2281730",
    "end": "2292019"
  },
  {
    "text": "And for most of what we're\ngoing to need, we're just going to need NULL\nfor default. We don't need any special\nthings like changing the",
    "start": "2292020",
    "end": "2298390"
  },
  {
    "text": "priority or what have you. Then what you pass is a void*\npointer to a function, which",
    "start": "2298390",
    "end": "2308390"
  },
  {
    "text": "is going to be the routine\nexecuted after creation. So you can name the function\nthat you want to have it",
    "start": "2308390",
    "end": "2315310"
  },
  {
    "text": "operate on.  And then you have a single\npointer to an argument that",
    "start": "2315310",
    "end": "2322290"
  },
  {
    "text": "you're going to pass\nto the function.  So when you call something with\nPthreads to create them,",
    "start": "2322290",
    "end": "2329859"
  },
  {
    "text": "you can't say, and here's\nmy list of arguments. If you have more than one\nargument, you have to pack it",
    "start": "2329860",
    "end": "2335610"
  },
  {
    "text": "together into a struct\nand pass the pointer to the struct. And this function has to be\nsmart enough to understand how",
    "start": "2335610",
    "end": "2342829"
  },
  {
    "text": "to unpack it. We'll see an example\nin a minute. And then, it returns\nan error status.",
    "start": "2342830",
    "end": "2349619"
  },
  {
    "text": "So the most common thing people\ndo is they don't bother to check the error status. OK. And yet sometimes, you try to\ncreate a Pthread, there's a",
    "start": "2349620",
    "end": "2356950"
  },
  {
    "text": "reason it can't create one. And now you keep going thinking\nyou have one, and then your program crashes\nand you wonder why.",
    "start": "2356950",
    "end": "2364640"
  },
  {
    "text": "So when you create things,\nyou should check. I'm not sure in my code here\nwhether I checked everywhere.",
    "start": "2364640",
    "end": "2371540"
  },
  {
    "text": "But you should check. Do as I say, not as I do.",
    "start": "2371540",
    "end": "2376720"
  },
  {
    "text": "OK. So the other key function\nis join. And basically, what you do is\nyou say, you name the thread",
    "start": "2376720",
    "end": "2383310"
  },
  {
    "text": "that you want to wait for. This is the name that\nwould be returned by the create function.",
    "start": "2383310",
    "end": "2389700"
  },
  {
    "text": "And you also give a place where\nit can store the status",
    "start": "2389700",
    "end": "2397859"
  },
  {
    "text": "of the thread when\nit terminated. It's allowed to say, I\nterminated normally.",
    "start": "2397860",
    "end": "2403290"
  },
  {
    "text": "I terminated with a given error\ncondition or whatever. But if you don't care\nwhat it is, you just put in NULL there.",
    "start": "2403290",
    "end": "2408990"
  },
  {
    "text": "And then it returns\nto the error status of the join function. So those are the two functions\nthat you program with.",
    "start": "2408990",
    "end": "2415560"
  },
  {
    "text": "Question? AUDIENCE: [INAUDIBLE PHRASE]? ",
    "start": "2415560",
    "end": "2421089"
  },
  {
    "text": "PROFESSOR: It's different. It's different. So it's basically, if the error\nstatus, if it returns",
    "start": "2421090",
    "end": "2426349"
  },
  {
    "text": "NULL, it just means everything\nwent OK. ",
    "start": "2426350",
    "end": "2433710"
  },
  {
    "text": "The handle is you pass a name,\nand basically this is *thread. It stuffs the name into\nwhatever you give it.",
    "start": "2433710",
    "end": "2441790"
  },
  {
    "text": "OK so you're not saying,\nhere's the name. This is returned as an\noutput parameter.",
    "start": "2441790",
    "end": "2447430"
  },
  {
    "text": "So you're giving it an address\nof some place to put the name.",
    "start": "2447430",
    "end": "2452559"
  },
  {
    "text": "OK. Let's see an example. So here's Fibonacci\nwith Pthreads.",
    "start": "2452560",
    "end": "2459840"
  },
  {
    "text": "So let's just go through that. So the first part\nis pretty good.",
    "start": "2459840",
    "end": "2466330"
  },
  {
    "text": "This is your original code\nthat does Fibonacci.",
    "start": "2466330",
    "end": "2471750"
  },
  {
    "start": "2468000",
    "end": "2560000"
  },
  {
    "text": "And now what we do is\nwe have a structure for the thread arguments.",
    "start": "2471750",
    "end": "2477750"
  },
  {
    "text": "And so we're going to have an\ninput argument and an output argument in this example. Because Fib takes an input\nargument in and",
    "start": "2477750",
    "end": "2483980"
  },
  {
    "text": "returns Fib of n. So we're going to call those\ninput and output.",
    "start": "2483980",
    "end": "2489180"
  },
  {
    "text": "And we'll call them\nthread_args. And now, here is my void*\nfunction, thread_func, which",
    "start": "2489180",
    "end": "2497660"
  },
  {
    "text": "takes a pointer. And what it does is\nwhen it executes--",
    "start": "2497660",
    "end": "2503980"
  },
  {
    "text": "so what you're going to be able\nto do is, as we'll see in a minute--. Let me just go through this. This is going to be the function\ncalled when the",
    "start": "2503980",
    "end": "2510609"
  },
  {
    "text": "thread is created. So when the thread is created,\nyou're just going to call this function. And what it's going to get is\nthe argument that was passed,",
    "start": "2510610",
    "end": "2520150"
  },
  {
    "text": "which is this *star thing. And what it does in this case\nis it's basically going to",
    "start": "2520150",
    "end": "2526049"
  },
  {
    "text": "cast the pointer to a thread_arg\nstruct and",
    "start": "2526050",
    "end": "2532140"
  },
  {
    "text": "dereference the input, and stick\nthat into I. Then going to compute Fib of I. And then\nit's going to take, once",
    "start": "2532140",
    "end": "2539710"
  },
  {
    "text": "again, deference the pointer as\nif it's a thread_arg, and store into the output field\nthe result of the Fib.",
    "start": "2539710",
    "end": "2549190"
  },
  {
    "text": "And then it returns NULL.  So that's basically the function\nthat's going to be",
    "start": "2549190",
    "end": "2556170"
  },
  {
    "text": "called when the thread\nis created. So in your main routine now,\nwhat happens is we initialize",
    "start": "2556170",
    "end": "2563559"
  },
  {
    "start": "2560000",
    "end": "2882000"
  },
  {
    "text": "a bunch of things. And now, if argc is less\nthan 2, we'll return 1. That's fine.",
    "start": "2563560",
    "end": "2570860"
  },
  {
    "text": "Then we're going to get the\nreading that we fail. That's actually the reading\nof the input.",
    "start": "2570860",
    "end": "2576280"
  },
  {
    "text": "So then, what we do here is we\nget n from the command line. And then if n is less than\n30, we're just going to",
    "start": "2576280",
    "end": "2583430"
  },
  {
    "text": "compute Fib of n. This is what I evaluated on my\nlaptop was a good number.",
    "start": "2583430",
    "end": "2590680"
  },
  {
    "text": "So the idea is there's no point\nin creating the extra thread to do the work if it's\ngoing to be more expensive",
    "start": "2590680",
    "end": "2597740"
  },
  {
    "text": "than me just doing\nthe work myself. So I looked at the overhead of\nthread creation and discovered",
    "start": "2597740",
    "end": "2603150"
  },
  {
    "text": "that if it was smaller than 30,\nit's going to be slower to create another thread\nto help me out.",
    "start": "2603150",
    "end": "2610780"
  },
  {
    "text": "It's sort of like you folks\nwhen you're doing pair programming, which you're\nsupposed to be doing, versus",
    "start": "2610780",
    "end": "2615850"
  },
  {
    "text": "handing it off. Sometimes, there are some things\nthat are too small to ask somebody else to do.",
    "start": "2615850",
    "end": "2620920"
  },
  {
    "text": "You might as well just do it,\nby time you explain what it is, and so forth. Same thing here.",
    "start": "2620920",
    "end": "2627160"
  },
  {
    "text": "What's the point in starting\nup a thread to do something else, because the startup cost\nis rather substantial.",
    "start": "2627160",
    "end": "2633630"
  },
  {
    "text": "So if it's less than 30, well,\nwe'll just be done. Otherwise, what we do\nis we marshall the",
    "start": "2633630",
    "end": "2641119"
  },
  {
    "text": "argument to the thread. We basically set args.input\nto n minus 1.",
    "start": "2641120",
    "end": "2646370"
  },
  {
    "text": "Because args is going to be\nwhat I'm going to pass in. So I say the input number\nis n minus 1.",
    "start": "2646370",
    "end": "2651700"
  },
  {
    "text": "And now what I do is I create\nthe thread by saying, give me",
    "start": "2651700",
    "end": "2657520"
  },
  {
    "text": "the name of the thread\nthat I'm creating.",
    "start": "2657520",
    "end": "2662840"
  },
  {
    "text": "This was the field that I said\nyou could put to be NULL,",
    "start": "2662840",
    "end": "2668520"
  },
  {
    "text": "which basically lets\nyou set some policy parameters and so forth. I say, execute the\nthread_func.",
    "start": "2668520",
    "end": "2674470"
  },
  {
    "text": "This guy here. And here's the argument list\nthat I want to provide it, which is this args thing.",
    "start": "2674470",
    "end": "2682000"
  },
  {
    "text": "Once you do the thread_create,\nand this is where you depart from normal C or\nC++ semantics.",
    "start": "2682000",
    "end": "2688420"
  },
  {
    "text": "And in fact, we're going to be\ndoing more moving in the direction of C++. We'll have some tutorials\non that.",
    "start": "2688420",
    "end": "2697240"
  },
  {
    "text": "What happens is we\ncheck the status. OK, I actually did check the\nstatus to see whether or not",
    "start": "2697240",
    "end": "2703200"
  },
  {
    "text": "it created it properly. But basically now, what's\nhappening is after I execute",
    "start": "2703200",
    "end": "2709240"
  },
  {
    "text": "this, it goes off and all the\nmagic in Pthreads starts another thread doing\nthat computation.",
    "start": "2709240",
    "end": "2716370"
  },
  {
    "text": "And control returns to the\nstatement after the pthread_create.",
    "start": "2716370",
    "end": "2721849"
  },
  {
    "text": "So when the pthread_create\nreturns, that doesn't mean it's done computing the thing\nyou told it to do.",
    "start": "2721850",
    "end": "2728150"
  },
  {
    "text": "Then, what would be the point? It returns after it's set up\nto operate in parallel the",
    "start": "2728150",
    "end": "2735230"
  },
  {
    "text": "other thread. People follow that? So now at this point, there\nare two threads operating.",
    "start": "2735230",
    "end": "2741480"
  },
  {
    "text": "There's the thread we've\ncalled thread. And there's whatever the name\nof the thread is that we started on.",
    "start": "2741480",
    "end": "2746510"
  },
  {
    "text": " So then we, in our own processor\nhere, we compute Fib",
    "start": "2746510",
    "end": "2752510"
  },
  {
    "text": "of N minus 2. And now, what we do is we go\non to join this thread with",
    "start": "2752510",
    "end": "2758960"
  },
  {
    "text": "the thread that we\nhad created.",
    "start": "2758960",
    "end": "2764220"
  },
  {
    "text": " So let's see here.",
    "start": "2764220",
    "end": "2770740"
  },
  {
    "text": "And the thing that the join does\nis if the other thread isn't done, it sits there and\nwaits until it is done.",
    "start": "2770740",
    "end": "2777620"
  },
  {
    "text": "And it does that\nsynchronization automatically for you. And this is the kind of thing a concurrency platform provides.",
    "start": "2777620",
    "end": "2783130"
  },
  {
    "text": "It provides the coordination\nunder the covers for you to be",
    "start": "2783130",
    "end": "2788250"
  },
  {
    "text": "able to synchronize with it\nwithout you having to synchronize on your own.",
    "start": "2788250",
    "end": "2794930"
  },
  {
    "text": "And then, once it does return,\nit adds the results together",
    "start": "2794930",
    "end": "2801400"
  },
  {
    "text": "by taking the result which came\nfrom the Fib of n minus 2",
    "start": "2801400",
    "end": "2806710"
  },
  {
    "text": "and adds to it the value that\nthis thread has returned in the args.output.",
    "start": "2806710",
    "end": "2812000"
  },
  {
    "text": " And then it prints the result.",
    "start": "2812000",
    "end": "2817420"
  },
  {
    "text": "So any question about that? Wouldn't this be fun to write\na really big system in?",
    "start": "2817420",
    "end": "2822859"
  },
  {
    "text": "People do. People do. Yeah, question?",
    "start": "2822860",
    "end": "2827928"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE PHRASE] ",
    "start": "2827928",
    "end": "2833540"
  },
  {
    "text": "PROFESSOR: That's a\ntuning parameter. That's a voodoo parameter. AUDIENCE: Right. But in this particular case, it\nmakes no difference at all.",
    "start": "2833540",
    "end": "2839374"
  },
  {
    "text": "It would've made a difference\nif it was an actual person [INAUDIBLE]? PROFESSOR: No, it does\nmake a difference.",
    "start": "2839374",
    "end": "2845290"
  },
  {
    "text": "For how fast it computes this? Absolutely does. AUDIENCE: That's\nnot recursive? PROFESSOR: No, that's right. This is not recursive.",
    "start": "2845290",
    "end": "2850920"
  },
  {
    "text": "I'm just doing two things\nand then quitting. AUDIENCE: [INAUDIBLE] if it's\nless than 30, then it's going",
    "start": "2850920",
    "end": "2856202"
  },
  {
    "text": "to be [INAUDIBLE], right? PROFESSOR: If it's less than\n30, it's fast enough that I",
    "start": "2856202",
    "end": "2861660"
  },
  {
    "text": "might as well just return. AUDIENCE: Then why\n[INAUDIBLE PHRASE] to do it.",
    "start": "2861660",
    "end": "2866974"
  },
  {
    "text": "It would return [INAUDIBLE]\ntoo. PROFESSOR: No. But it would be slower. It would be wasteful\nof resources.",
    "start": "2866975",
    "end": "2872645"
  },
  {
    "text": "Maybe somebody-- AUDIENCE: Well, because you're\nusing such a bad algorithm, I guess? PROFESSOR: Yeah. AUDIENCE: Oh, I see.",
    "start": "2872645",
    "end": "2877789"
  },
  {
    "text": "Oh, OK. PROFESSOR: OK. So in any case, that's Pthread's\nprogramming. There are a bunch of issues.",
    "start": "2877790",
    "end": "2883450"
  },
  {
    "start": "2882000",
    "end": "3118000"
  },
  {
    "text": "One is that the overhead of\ncreating a thread is more than 10,000 cycles.",
    "start": "2883450",
    "end": "2890220"
  },
  {
    "text": "So it leaves you to only be able\nto do very coarse grain concurrency. There are some tricks\naround that.",
    "start": "2890220",
    "end": "2895590"
  },
  {
    "text": "One is to use what's called\nthread pools. What I do is I start up, and I\ncreate a bunch of threads.",
    "start": "2895590",
    "end": "2901600"
  },
  {
    "text": "And I have their names. I put them in a link list. And whenever I need to create\none, rather than actually creating one, I take one out of\nthe list, much as I would",
    "start": "2901600",
    "end": "2909090"
  },
  {
    "text": "do memory allocation. Which you folks are\nfamiliar with. ",
    "start": "2909090",
    "end": "2915580"
  },
  {
    "text": "OK. Ha, ha, ha, ha, ha. [MANIACAL LAUGHTER]",
    "start": "2915580",
    "end": "2925340"
  },
  {
    "text": "So basically, you can have\na free list of threads. And when you need a thread,\nyou grab the thread.",
    "start": "2925340",
    "end": "2933550"
  },
  {
    "text": "The second thing\nis scalability. So this code gets about a 1.5\nspeed up for two cores.",
    "start": "2933550",
    "end": "2941580"
  },
  {
    "text": "If I want to use three cores\nor four cores, what do I have to do?",
    "start": "2941580",
    "end": "2947470"
  },
  {
    "text": "Rewrite the whole program. This program only works\nfor two cores.",
    "start": "2947470",
    "end": "2952490"
  },
  {
    "text": "It will also work\nfor one core. but basically, it doesn't\nreally exploit",
    "start": "2952490",
    "end": "2957600"
  },
  {
    "text": "three or four cores. It's really bad for\nmodulatary. The Fibonacci logic is no longer\nneatly encapsulated in",
    "start": "2957600",
    "end": "2965670"
  },
  {
    "text": "the Fib function. So where do we see if we\ngo back to this code?",
    "start": "2965670",
    "end": "2971320"
  },
  {
    "text": "Here's the Fib function. Oh, but now, I've\nkind of got-- well, this is sort of just\nmarshaling and calling.",
    "start": "2971320",
    "end": "2977510"
  },
  {
    "text": "But over here, oh my goodness,\nI've got some arguments here. If n is less than 30,\nI give a result.",
    "start": "2977510",
    "end": "2983640"
  },
  {
    "text": "Otherwise, I'm adding\ntogether-- but wait a minute. I already specified\nFib up here.",
    "start": "2983640",
    "end": "2988730"
  },
  {
    "text": "So I'm specifying my serial\nimplementation, and I'm specifying a parallel\nway of doing it.",
    "start": "2988730",
    "end": "2995000"
  },
  {
    "text": "And so that's not modular. If I decided I wanted to change\nthe Fib, I've got to change things in two places.",
    "start": "2995000",
    "end": "3001859"
  },
  {
    "text": "If Fib were something I did.",
    "start": "3001860",
    "end": "3007840"
  },
  {
    "text": "Code simplicity. The programmers for this are actually marshalling arguments. This is what I call\nshades of 1958.",
    "start": "3007840",
    "end": "3015069"
  },
  {
    "text": "What happened in 1958 that's\nrelevant to computer science? ",
    "start": "3015070",
    "end": "3021060"
  },
  {
    "text": "What was the big innovation\nin 1958? Programming language.",
    "start": "3021060",
    "end": "3027310"
  },
  {
    "text": "Fortran. So, Fortran. Before Fortran, people wrote\nin assembly language.",
    "start": "3027310",
    "end": "3035320"
  },
  {
    "text": "If you wanted to put three\narguments to a function, you did a push, push, push, or\npassed them in parameters.",
    "start": "3035320",
    "end": "3043790"
  },
  {
    "text": "Actually, their machines were\nso much more primitive than that it was even more\ncomplicated than you could imagine, given how complicated\nit is today what the",
    "start": "3043790",
    "end": "3054099"
  },
  {
    "text": "compilers are doing. But you had marshal the\narguments yourself. What Fortran did was say,\nno, you can actually",
    "start": "3054100",
    "end": "3060150"
  },
  {
    "text": "write f of a, b, c. Close paren.",
    "start": "3060150",
    "end": "3066320"
  },
  {
    "text": "And that it will cause a, b,\nand c all to be marshalled automatically for you.",
    "start": "3066320",
    "end": "3073160"
  },
  {
    "text": "Well, Pthreads doesn't have that\nautomatic marshalling. You got to marshall by hand if\nyou're going to use pthreads.",
    "start": "3073160",
    "end": "3078300"
  },
  {
    "text": " And of course, as you can\nimagine, that was error prone.",
    "start": "3078300",
    "end": "3084770"
  },
  {
    "text": "Because there is\nno type safety. Are you calling things with the\nright types and so forth?",
    "start": "3084770",
    "end": "3091730"
  },
  {
    "text": "And so forth. And also, one of the things here\nis that we've created two",
    "start": "3091730",
    "end": "3099460"
  },
  {
    "text": "jobs that aren't\nthe same size. So there's no way that they\nhave of load balancing.",
    "start": "3099460",
    "end": "3106230"
  },
  {
    "text": "So this is why pthreads is sort\nof the assembly language level, so that you can do\nanything you want in pthreads.",
    "start": "3106230",
    "end": "3113320"
  },
  {
    "text": "But you have to program\nat this kind of very protocol-laden level.",
    "start": "3113320",
    "end": "3119500"
  },
  {
    "start": "3118000",
    "end": "3163000"
  },
  {
    "text": "Next thing I want\nto talk about is threading building blocks. ",
    "start": "3119500",
    "end": "3124700"
  },
  {
    "text": "This is a technology\ndeveloped by Intel. It's implemented as a C++\nlibrary that runs on top of",
    "start": "3124700",
    "end": "3132930"
  },
  {
    "text": "the native Pthreads, typically,\nor WinAPI threads. So it's basically a layer on\ntop of the Pthread layer.",
    "start": "3132930",
    "end": "3141590"
  },
  {
    "text": "In this case, the program\nspecifies tasks rather than threads. And tasks are automatically\nload balanced across the",
    "start": "3141590",
    "end": "3150690"
  },
  {
    "text": "threads using a strategy called\nwork-stealing, which we'll talk about a little\nbit more later.",
    "start": "3150690",
    "end": "3156640"
  },
  {
    "text": "And the focus for this\nis on performance. They want to write programs that\nactually perform well.",
    "start": "3156640",
    "end": "3163130"
  },
  {
    "start": "3163000",
    "end": "3365000"
  },
  {
    "text": "So here's Fibonacci in TBB. So as you'll see, it's better.",
    "start": "3163130",
    "end": "3168190"
  },
  {
    "text": "But maybe not ideal for what\nyou might like to express. ",
    "start": "3168190",
    "end": "3176220"
  },
  {
    "text": "So what we do is we declare the\ncomputer, the computation,",
    "start": "3176220",
    "end": "3182070"
  },
  {
    "text": "it's going to organized as a\nbunch of explicit tasks. So you say that it's\ngoing to be a task.",
    "start": "3182070",
    "end": "3190030"
  },
  {
    "text": "And FibTask is going to have an\ninput parameter, n, and an",
    "start": "3190030",
    "end": "3199280"
  },
  {
    "text": "output parameters, sum. And what we're going to do is\nwhen the task is started, it",
    "start": "3199280",
    "end": "3208990"
  },
  {
    "text": "automatically executes the\nexecute method of this tasking",
    "start": "3208990",
    "end": "3216890"
  },
  {
    "text": "object here. And the execute method now\nstarts to do something that looks very much like\nFibonacci. It says if n is less than\n2, sum is equal to n.",
    "start": "3216890",
    "end": "3226880"
  },
  {
    "text": "That's we had before. And otherwise. And now what we're going to do\nis recursively create two",
    "start": "3226880",
    "end": "3233570"
  },
  {
    "text": "child tasks, which we basically\ndo with this function, allocate_task, giving\nit the fib task a name,",
    "start": "3233570",
    "end": "3247490"
  },
  {
    "text": "where this is basically a method\nfor allocating out of a",
    "start": "3247490",
    "end": "3253040"
  },
  {
    "text": "particular type of the\npool, which is an allocate child pool.",
    "start": "3253040",
    "end": "3258760"
  },
  {
    "text": "And then similarly for b, we\nrecursively do for n minus 2. And then what it does is\nit sets the number of",
    "start": "3258760",
    "end": "3265240"
  },
  {
    "text": "tasks to wait for. In this case, it's basically\ntwo children plus 1 for",
    "start": "3265240",
    "end": "3270250"
  },
  {
    "text": "bookkeeping. So this ends up always being one\nmore than the things that",
    "start": "3270250",
    "end": "3275579"
  },
  {
    "text": "you created as subtasks. And then what we do is we\nsay, OK, let's spawn.",
    "start": "3275580",
    "end": "3284160"
  },
  {
    "text": "So this will only\nset up the task. It doesn't actually\nsay, do it. So the spawn command says\nactually do this computation",
    "start": "3284160",
    "end": "3292390"
  },
  {
    "text": "here that I set up. So it actually does b. Start task b.",
    "start": "3292390",
    "end": "3298440"
  },
  {
    "text": "And then itself, it executes a\nand waits for all of the other tasks, namely both a\nand b, to finish.",
    "start": "3298440",
    "end": "3305640"
  },
  {
    "text": "And once it's finished, it adds\nthe results together to produce the final output. ",
    "start": "3305640",
    "end": "3313299"
  },
  {
    "text": "So this, notice, has the big\nadvantage over the previous implementation that this\nis actually recursive.",
    "start": "3313300",
    "end": "3322260"
  },
  {
    "text": "So in doing Fib, you're not\njust getting two tasks. You're recursively getting each\nof those two more, and",
    "start": "3322260",
    "end": "3329010"
  },
  {
    "text": "two more, and two more, down\nto the leaves of the computation. And then what TBB does is it\nload balances those across the",
    "start": "3329010",
    "end": "3336660"
  },
  {
    "text": "number of available processors\nby creating these tasks.",
    "start": "3336660",
    "end": "3342450"
  },
  {
    "text": "And then, it automatically does\nall the load balancing of the tasks and so forth.",
    "start": "3342450",
    "end": "3347610"
  },
  {
    "text": "Questions about that? Any questions? I don't expect you to be able\nto program a TBB, unless I",
    "start": "3347610",
    "end": "3355720"
  },
  {
    "text": "gave you a book and said,\nprogram a TBB. But I'm not going to do that. ",
    "start": "3355720",
    "end": "3360900"
  },
  {
    "text": "This is mainly to give you a\nflavor of what's in there. What the alternatives are. So TBB provides many\nC++ templates that",
    "start": "3360900",
    "end": "3368670"
  },
  {
    "start": "3365000",
    "end": "3471000"
  },
  {
    "text": "simplify common patterns. So rather than having to write\nthat kind of thing for everything, for example, if\nyou have loop parallelism.",
    "start": "3368670",
    "end": "3376010"
  },
  {
    "text": "If you have n things that you\nwant to have that operate parallel, you can do a parallel\nfour and not actually",
    "start": "3376010",
    "end": "3383519"
  },
  {
    "text": "see the tasks. It covers them over and\ncreates the tasks automatically, so that you can\njust say, for I gets 1 to n,",
    "start": "3383520",
    "end": "3392940"
  },
  {
    "text": "do this to all I, and do them at\nthe same time essentially. And it then balances\nthose and so forth.",
    "start": "3392940",
    "end": "3399920"
  },
  {
    "text": "It also has to things like\nparallel reduce. Sometimes what you want to do\nacross an array is not just do",
    "start": "3399920",
    "end": "3406880"
  },
  {
    "text": "something for every element\nof the array. You may want to add up all the\nelements into a single value. And so it basically has what's\ncalled a reduction function.",
    "start": "3406880",
    "end": "3414870"
  },
  {
    "text": "It does parallel reduce\nto aggregate. And it's got various other\nthings, like pipelining and filtering for doing what's\ncalled software pipelining,",
    "start": "3414870",
    "end": "3422250"
  },
  {
    "text": "where you have one subsystem\nthat basically is going to",
    "start": "3422250",
    "end": "3428810"
  },
  {
    "text": "process the data and pass\nit to the next. So you're going to process it\nand pass it to the next. And it allows you to set up a\nsoftware pipeline of things.",
    "start": "3428810",
    "end": "3438810"
  },
  {
    "text": "It also collides with some\ncontainer classes, such as hash tables, concurrent hash\ntables, that allow you to have",
    "start": "3438810",
    "end": "3445180"
  },
  {
    "text": "multiple tasks beating\non a hash table.",
    "start": "3445180",
    "end": "3453670"
  },
  {
    "text": "Inserting and deleting from\nthe hash table at the same time and a variety of mutual\nexclusion library functions,",
    "start": "3453670",
    "end": "3459790"
  },
  {
    "text": "including locks and\natomic updates. So it has a bunch of other\nfacilities that make it much",
    "start": "3459790",
    "end": "3468230"
  },
  {
    "text": "easier to use than just using\nthe raw task interface. ",
    "start": "3468230",
    "end": "3474359"
  },
  {
    "start": "3471000",
    "end": "3599000"
  },
  {
    "text": "OpenMP.  So OpenMP is a specification\nproduced by an industry",
    "start": "3474360",
    "end": "3480099"
  },
  {
    "text": "consortium of which the\nprincipal players-- the original principal player\nwas Silicon Graphics, which",
    "start": "3480100",
    "end": "3489780"
  },
  {
    "text": "essentially has become\nless important in the industry, let's say. Put it that way.",
    "start": "3489780",
    "end": "3495820"
  },
  {
    "text": "And for the most part, recently,\nit's been players from Intel and Sun, which is now\nno longer Sun, except that",
    "start": "3495820",
    "end": "3504290"
  },
  {
    "text": "it is Sun part of Oracle, and\nof IBM, and variety of other",
    "start": "3504290",
    "end": "3513160"
  },
  {
    "text": "industry players. There's several compilers\navailable.",
    "start": "3513160",
    "end": "3519430"
  },
  {
    "text": "Both open source and\nproprietary, including gcc, has OpenMP built-in.",
    "start": "3519430",
    "end": "3526190"
  },
  {
    "text": "And also, Visual Studio\nhas OpenMP built-in.",
    "start": "3526190",
    "end": "3531369"
  },
  {
    "text": "These are a set of linguistic\nextensions to C and C++ or Fortran in the form of compiler\npractice pragmas.",
    "start": "3531370",
    "end": "3539710"
  },
  {
    "text": "So who knows what a pragma is? OK.",
    "start": "3539710",
    "end": "3545150"
  },
  {
    "text": "Good. Can you tell us what\na pragma is? AUDIENCE: [INAUDIBLE PHRASE] ",
    "start": "3545150",
    "end": "3552140"
  },
  {
    "text": "PROFESSOR: Yeah, it's kind\nof like a compiler hint. It's a way of saying to the\ncompiler, here's something I",
    "start": "3552140",
    "end": "3558420"
  },
  {
    "text": "want to tell you about the\ncode that I'm writing. And it basically is a hint.",
    "start": "3558420",
    "end": "3565150"
  },
  {
    "text": "So technically, it's not\nsupposed to have any semantic impact, but rather suggest how\nsomething might be implemented",
    "start": "3565150",
    "end": "3571490"
  },
  {
    "text": "by the compiler. However, in OpenMP's case, they actually have a compiler--",
    "start": "3571490",
    "end": "3579109"
  },
  {
    "text": "it does change the semantics\nin certain cases. It runs on top of native threads\nand it supports,",
    "start": "3579110",
    "end": "3584990"
  },
  {
    "text": "especially, loop parallelism. And then, in the latest version,\nit supports a kind of task parallelism like\nwe saw with TBB.",
    "start": "3584990",
    "end": "3594560"
  },
  {
    "text": "So, in fact, their\ntask parallelism is fairly to specify. So here's the Fib code.",
    "start": "3594560",
    "end": "3600420"
  },
  {
    "text": "So now, this is not\nlooking too bad. We basically inserted\na few lines here.",
    "start": "3600420",
    "end": "3606960"
  },
  {
    "text": "And otherwise, we actually\nhave the original Fibonacci code.",
    "start": "3606960",
    "end": "3613530"
  },
  {
    "text": "So the sharp pragma says, here's\na compiler directive. And it says, the OMP\nsays it is an",
    "start": "3613530",
    "end": "3621450"
  },
  {
    "text": "OpenMP compiler directive. The task says, oh, the following\nthings should be",
    "start": "3621450",
    "end": "3626849"
  },
  {
    "text": "interpreted as an independent\ntask. And now, the sharing of memory\nin OpenMP is managed",
    "start": "3626850",
    "end": "3633760"
  },
  {
    "text": "explicitly, because they're\ntrying to allow for programming both of distributed\nmemory clusters,",
    "start": "3633760",
    "end": "3639360"
  },
  {
    "text": "as well as shared\nmemory machines. And so, you have to explicitly\nname the shared variables that",
    "start": "3639360",
    "end": "3648020"
  },
  {
    "text": "you're using. And here, we're basically\nsaying, wait for the two things that we spawned\noff here to complete.",
    "start": "3648020",
    "end": "3656180"
  },
  {
    "text": "So pretty simple code. It provides many pragma\ndirectives to express common",
    "start": "3656180",
    "end": "3665250"
  },
  {
    "text": "patterns, such as a parallel\nfor parallelization. It also has reduction. It also has directives for\nscheduling and data sharing.",
    "start": "3665250",
    "end": "3674490"
  },
  {
    "text": "And it has a whole bunch\nof synchronization constructs and so forth. So it's another interesting\none to do.",
    "start": "3674490",
    "end": "3681650"
  },
  {
    "text": "The main downside, I would say,\nof OpenMP is that the performance is not really\nvery composable.",
    "start": "3681650",
    "end": "3687990"
  },
  {
    "text": "So if you have a program you've\nwritten with OpenMP over here, another one here,\nand you want to put them",
    "start": "3687990",
    "end": "3693089"
  },
  {
    "text": "together, they fight\nwith each other. You have to have your\nconcept of what are",
    "start": "3693090",
    "end": "3700309"
  },
  {
    "text": "going to be the programs. The task parallelism helps\na bit with that. But the basic OpenMP is very\nmuch of the model, I know how",
    "start": "3700310",
    "end": "3709410"
  },
  {
    "text": "many cores I'm running on. I can set that. And then I can have it\nautomatically parse up the",
    "start": "3709410",
    "end": "3715430"
  },
  {
    "text": "work for those many. But once you've done that, some\nother job, some other part of the system that wants to\ndo the same thing, then you",
    "start": "3715430",
    "end": "3723170"
  },
  {
    "text": "get oversubscription and perhaps\nsome [UNINTELLIGIBLE]. Nevertheless, a very\ninteresting system.",
    "start": "3723170",
    "end": "3730970"
  },
  {
    "text": "And very accessible, because\nit's in most of the standard compilers these days.",
    "start": "3730970",
    "end": "3736210"
  },
  {
    "text": " What we're going to\nlook at is Cilk++.",
    "start": "3736210",
    "end": "3743130"
  },
  {
    "text": "So this is actually a small set\nof linguistics extensions",
    "start": "3743130",
    "end": "3748740"
  },
  {
    "text": "to C++ to support fork-join\nparallelism. And it was developed by Cilk\nArts, which is an MIT",
    "start": "3748740",
    "end": "3753890"
  },
  {
    "text": "spin-off, which was acquired\nby Intel last year. So this is now an Intel\ntechnology.",
    "start": "3753890",
    "end": "3760790"
  },
  {
    "text": "And the reason I know about it\nis because I was the founder of Cilk Arts. It was based on 15 years of\nresearch at MIT out of my",
    "start": "3760790",
    "end": "3768300"
  },
  {
    "text": "research group. And we won a bunch of awards,\nactually, for this work.",
    "start": "3768300",
    "end": "3775849"
  },
  {
    "text": "In fact, the work-stealing\nscheduler that's in it is provably efficient. In other words, it's not just\na heuristic scheduler.",
    "start": "3775850",
    "end": "3782440"
  },
  {
    "text": "It's actually got a mathematical\nproof that it's an effective scheduler. And in fact, was the inspiration\nfor things like",
    "start": "3782440",
    "end": "3790200"
  },
  {
    "text": "the work-stealing in TBB and the\nnew task mechanisms and so forth in OpenMP, as well as a\nbunch of other people who've",
    "start": "3790200",
    "end": "3799640"
  },
  {
    "text": "done work-stealing. It in addition provides a\nhyperobject library for parallelizing code with global\nvariables, which we'll talk",
    "start": "3799640",
    "end": "3807140"
  },
  {
    "text": "about later. And it includes two tools that\nyou'll come to know and love.",
    "start": "3807140",
    "end": "3812720"
  },
  {
    "text": "One is the Cilkscreen race\ndetector, and the other is the Cilkview scalability analyzer.",
    "start": "3812720",
    "end": "3819460"
  },
  {
    "text": "Now, what we're going to be\nusing in this class is going to be the Cilk++ technology\nthat was developed at Cilk",
    "start": "3819460",
    "end": "3829579"
  },
  {
    "text": "Arts and then massaged\na little bit when it got to Intel. There is a brand new Intel\ntechnology with Cilk built",
    "start": "3829580",
    "end": "3835990"
  },
  {
    "text": "into their compiler. And it is due to come out\nin like, two weeks.",
    "start": "3835990",
    "end": "3842000"
  },
  {
    "text": " So our timing for this was it\nwould've been nice to have you",
    "start": "3842000",
    "end": "3848830"
  },
  {
    "text": "folks on the new Intel\nCilk+ technology. But we're going to go with\nthis one for now.",
    "start": "3848830",
    "end": "3856950"
  },
  {
    "text": "It's not going to make too big\na difference to you folks. But you should just be aware\nthat coming down the pike,",
    "start": "3856950",
    "end": "3862190"
  },
  {
    "text": "there's actually some much\nmore cleanly integrated",
    "start": "3862190",
    "end": "3867430"
  },
  {
    "text": "technology that you can use\nthat's in the Intel compiler.",
    "start": "3867430",
    "end": "3873119"
  },
  {
    "text": "So here's how we do nested\nparallelism in Cilk++. So basically, this\nis Fibonacci.",
    "start": "3873120",
    "end": "3878420"
  },
  {
    "text": "And now, what I have here is,\nif you notice, I've got two keywords, cilk_spawn\nand cilk_sync.",
    "start": "3878420",
    "end": "3886430"
  },
  {
    "text": "And this is how you write\nparallel Fibonacci in Cilk. This is it.",
    "start": "3886430",
    "end": "3891825"
  },
  {
    "text": "I've inserted two key words,\nand my program is parallel. The cilk_spawn keyword says that\nthe named child function",
    "start": "3891825",
    "end": "3900349"
  },
  {
    "text": "can execute in parallel with\nthe parent caller. So when you say x equals\ncilk_spawn or Fib of n minus",
    "start": "3900350",
    "end": "3906070"
  },
  {
    "text": "1, it does the same thing\nthat you normally think. It calls the child. ",
    "start": "3906070",
    "end": "3912809"
  },
  {
    "text": "But after it calls the child,\nrather than waiting for it to return, it goes on to\nthe next statement.",
    "start": "3912810",
    "end": "3921360"
  },
  {
    "text": "So then, the statement y equals\nFib of n minus 2 is going on at the same time\nas the calculation of",
    "start": "3921360",
    "end": "3926960"
  },
  {
    "text": "Fib of n minus 1.  And then, the cilk_sync says,\ndon't go past this point until",
    "start": "3926960",
    "end": "3934560"
  },
  {
    "text": "all the children you've spawned\noff have returned.  And since this is a recursive\nprogram, it generates gobs of",
    "start": "3934560",
    "end": "3944580"
  },
  {
    "text": "parallelism, if it's\na big thing. So one of the key things about\nCilk++, is unlike Pthreads--",
    "start": "3944580",
    "end": "3950720"
  },
  {
    "text": "Pthreads, when you say,\npthread_create, it actually goes and creates a\npiece of work.",
    "start": "3950720",
    "end": "3957080"
  },
  {
    "text": "In Cilk++, these keywords\nonly grant permission.",
    "start": "3957080",
    "end": "3962630"
  },
  {
    "text": "They say you may execute these\nthings in parallel. It doesn't insist that they\nbe executed in parallel.",
    "start": "3962630",
    "end": "3968630"
  },
  {
    "text": "The program may decide, no, in\nfact, I'm going to just call this, and then return, and\nthen execute this.",
    "start": "3968630",
    "end": "3975190"
  },
  {
    "text": " So it only grants permission,\nand the Cilk++ runtime system",
    "start": "3975190",
    "end": "3985550"
  },
  {
    "text": "figures out how to load balance\nit and schedule it. ",
    "start": "3985550",
    "end": "3991260"
  },
  {
    "text": "Cilk++ also supports\nloop parallelism.",
    "start": "3991260",
    "end": "3996590"
  },
  {
    "text": "So here's an example of an\nin-place matrix transpose. So I want to take this matrix\nand flip it on its major axis.",
    "start": "3996590",
    "end": "4002830"
  },
  {
    "text": " And we can do it\nwith for loops. As you know, for loops\nare not the best way",
    "start": "4002830",
    "end": "4009040"
  },
  {
    "text": "to do matrix transpose. Right? It's better to do divide\nand conquer.",
    "start": "4009040",
    "end": "4016090"
  },
  {
    "text": "But here's how you\ncould do it. And here, I made the indices\nrun from 0, not 1, because",
    "start": "4016090",
    "end": "4024240"
  },
  {
    "text": "that's the way you do\nit in programming. But if I did it up here, then\nthese things get to be n minus 1, n minus 1, and then it gets\ntoo crowded on the slide.",
    "start": "4024240",
    "end": "4030809"
  },
  {
    "text": "And I said, OK, I'll just put\na comment there rather than try to sort it out.",
    "start": "4030810",
    "end": "4037450"
  },
  {
    "text": "So here's what I'm saying, is\nthis outer loop is parallel. It's going from 1\nto n minus 1.",
    "start": "4037450",
    "end": "4044339"
  },
  {
    "text": "And saying, do all those\nthings in parallel. And each one is going through\na different number of iterations of j.",
    "start": "4044340",
    "end": "4050390"
  },
  {
    "text": "So you can see you actually need\nsome load balancing here, because some of these are going\nthrough just one step,",
    "start": "4050390",
    "end": "4056760"
  },
  {
    "text": "and some are going through\nn minus 1 steps. It's basically the amount of\nwork in every iteration of the",
    "start": "4056760",
    "end": "4063440"
  },
  {
    "text": "outer loop here is different. I'm sorry? AUDIENCE: [INAUDIBLE PHRASE].",
    "start": "4063440",
    "end": "4070130"
  },
  {
    "text": "PROFESSOR: No. i equals 1 is\nwhere you want to start. Because you don't have\nto move the diagonal. ",
    "start": "4070130",
    "end": "4078170"
  },
  {
    "text": "You only have to go across\nthe top here. And for each of those, copy it\ninto the appropriate column.",
    "start": "4078170",
    "end": "4087170"
  },
  {
    "text": "Flip it into the appropriate\ncolumn. Flip the two things. Actually, transpose is one\nof these functions.",
    "start": "4087170",
    "end": "4092720"
  },
  {
    "text": "I remember writing my first\ntranspose functions. And when I was done, I somehow\nhad the identity. ",
    "start": "4092720",
    "end": "4099568"
  },
  {
    "text": "Because I basically made the\nloops go from 1 to n and 1 to n and swapped them.",
    "start": "4099569",
    "end": "4107259"
  },
  {
    "text": "So I swapped them. So I said, oh, that\nwas a lot of work to compute the identity.",
    "start": "4107260",
    "end": "4112979"
  },
  {
    "text": "No, you've got to make sure\nyou only go through a triangular iteration space in\norder to make sure you swap--",
    "start": "4112979",
    "end": "4119210"
  },
  {
    "text": "and then swap.  This is an in-place swap.",
    "start": "4119210",
    "end": "4125449"
  },
  {
    "text": "So that's cilk_for. That's basically it. There are some more facilities\nwe'll talk about.",
    "start": "4125450",
    "end": "4130470"
  },
  {
    "text": "But that's basically\nit for parallel programming in Cilk++. The other part is, how do you\ndo it so you get fast code?",
    "start": "4130470",
    "end": "4138000"
  },
  {
    "text": "Which we'll talk about. Now, Cilk has serial\nsemantics.",
    "start": "4138000",
    "end": "4144670"
  },
  {
    "text": "And what that means is unlike\nsome of the other ones, it's kind of what OpenMP was\naspiring to do.",
    "start": "4144670",
    "end": "4153220"
  },
  {
    "text": "The idea is that if I, for\nexample here, delete these two keywords, I get a C++ code.",
    "start": "4153220",
    "end": "4162509"
  },
  {
    "text": "And that code is always a legal\nway to execute this parallel code.",
    "start": "4162510",
    "end": "4167560"
  },
  {
    "text": "So the parallel code may have\nmore behaviors of its nondeterministic code. But always, it's legal to\ntreat it as if it's just",
    "start": "4167560",
    "end": "4175609"
  },
  {
    "text": "straight C++.  And the reason for that is\nthat, really, we're only",
    "start": "4175609",
    "end": "4181270"
  },
  {
    "text": "granting permission for\nparallel execution. So even though I put in these\nkeywords, I still can execute",
    "start": "4181270",
    "end": "4187149"
  },
  {
    "text": "it serially if I wish. They don't command parallel\nexecution.",
    "start": "4187149",
    "end": "4192420"
  },
  {
    "text": "To obtain this serialization,\nyou can do it by hand by just defining a cilk_for to be for,\nand the cilk_spawn and",
    "start": "4192420",
    "end": "4198675"
  },
  {
    "text": "cilk_sync to be empty. Or there's a switch to the\nCilk++ composite that does",
    "start": "4198675",
    "end": "4204949"
  },
  {
    "text": "that for you automatically. And it's probably the preferred\nway of doing it.",
    "start": "4204950",
    "end": "4210750"
  },
  {
    "text": "But the idea is conceptually,\nyou can sprinkle in these keywords, and if you don't\nwant it anymore, fine.",
    "start": "4210750",
    "end": "4218140"
  },
  {
    "text": "If you want to compile it with\nthe straight c compilers, it's better to use the Cilk++\ncompiler to do it.",
    "start": "4218140",
    "end": "4223600"
  },
  {
    "text": "But if you wanted to ship it\noff to somebody else, you could just do these sharp\ndefines, and they could",
    "start": "4223600",
    "end": "4230440"
  },
  {
    "text": "compile it with their compilers,\nand it would be the same as a serial C++ code.",
    "start": "4230440",
    "end": "4236870"
  },
  {
    "text": "So the Cilk++ concurrency\nplatform allows the program to express potential parallelism\nin application.",
    "start": "4236870",
    "end": "4245290"
  },
  {
    "text": "So it says, where is\nthe parallelism? It doesn't say how\nto schedule it. It says, where is it?",
    "start": "4245290",
    "end": "4250910"
  },
  {
    "text": "And then, it gets mapped onto,\nat runtime, dynamically mapped",
    "start": "4250910",
    "end": "4256800"
  },
  {
    "text": "onto the processor cores.  And the way that it does the\nmapping is mathematically",
    "start": "4256800",
    "end": "4265510"
  },
  {
    "text": "provably a good way\nof doing it. And if you take one of my\ngraduate courses, I can teach",
    "start": "4265510",
    "end": "4272530"
  },
  {
    "text": "you how that works. We'll do a little bit of study\nof simple scheduling.",
    "start": "4272530",
    "end": "4279119"
  },
  {
    "text": "But the actual schedule it\nuses is more involved. But we'll cover it\na little bit.",
    "start": "4279120",
    "end": "4285679"
  },
  {
    "text": "Here's the components\nof the Cilk++ platform on a single slide.",
    "start": "4285680",
    "end": "4291329"
  },
  {
    "text": "So let me just say\nwhat they are. The first one is the keywords. So you get to put\nthings in there.",
    "start": "4291330",
    "end": "4296630"
  },
  {
    "text": "And if you elide or create the\nserialization, then you get",
    "start": "4296630",
    "end": "4302900"
  },
  {
    "text": "the C++ code or C code, for\nwhich then you can run your regression test and demonstrate\nyou have some good",
    "start": "4302900",
    "end": "4310780"
  },
  {
    "text": "single-threaded program. Alternatively, you can send it\nthrough the Cilk++ compiler,",
    "start": "4310780",
    "end": "4316270"
  },
  {
    "text": "which is based on a conventional\ncompiler. In our case, it will be GCC. You can link that with the\nhyperobject library, which",
    "start": "4316270",
    "end": "4322920"
  },
  {
    "text": "we'll talk about when we start\ntalking about synchronization. It produces a binary. If you run that binary on the\nruntime system, you can also",
    "start": "4322920",
    "end": "4331090"
  },
  {
    "text": "run it to the regression test. And in particular, if you run\nit on the runtime system, running on one core, it should\nbehave identically to having",
    "start": "4331090",
    "end": "4340780"
  },
  {
    "text": "run it through this path with\njust the serial code. ",
    "start": "4340780",
    "end": "4346670"
  },
  {
    "text": "And of course, you get\nexceptional performance. These, I think, were originally\nmarketing slides. ",
    "start": "4346670",
    "end": "4354290"
  },
  {
    "text": "However, there's also the fact\nthat you may get what are called races in your code, which\nare bugs that will come",
    "start": "4354290",
    "end": "4362909"
  },
  {
    "text": "up that won't occur in your\nserial code, but will occur in your parallel code.",
    "start": "4362910",
    "end": "4368680"
  },
  {
    "text": "Cilk has a race detector to\ndetect those, for which you can run parallel regression\ntests to produce your reliable",
    "start": "4368680",
    "end": "4374450"
  },
  {
    "text": "multi-threaded code. And then, the final piece of\nit is there's this thing called Cilkview, which allows\nyou to analyze the scalability",
    "start": "4374450",
    "end": "4382250"
  },
  {
    "text": "of your software. So you can run, in fact, on a\nsingle core or on a small",
    "start": "4382250",
    "end": "4387370"
  },
  {
    "text": "number of cores. And then, you can predict how\nit's going to behave on a large number of cores.",
    "start": "4387370",
    "end": "4394320"
  },
  {
    "text": "So let's just, to conclude\nhere, talk about races. Because they're the nasty,\nnasty, nasty thing we get into",
    "start": "4394320",
    "end": "4401590"
  },
  {
    "text": "parallel programming. And then next time, we'll\nget deeper into the Cilk technology itself.",
    "start": "4401590",
    "end": "4406870"
  },
  {
    "text": " So the most basic kind of race\nthere is what's called a",
    "start": "4406870",
    "end": "4412929"
  },
  {
    "text": "determinacy race. Because if you have one of these\nthings, your program",
    "start": "4412930",
    "end": "4418710"
  },
  {
    "text": "becomes nondeterministic. It doesn't do the same\nthing every time.",
    "start": "4418710",
    "end": "4424400"
  },
  {
    "text": "A determinacy race occurs when\ntwo logically parallel instructions access the same\nmemory location, and at least",
    "start": "4424400",
    "end": "4431989"
  },
  {
    "text": "one of the instructions performs\na write, performs a store, to that location.",
    "start": "4431990",
    "end": "4438190"
  },
  {
    "text": "So here's an example. I have a cilk_for here, both\nbranches of which are",
    "start": "4438190",
    "end": "4446050"
  },
  {
    "text": "incrementing x. This is basically going. The index is going. i equals 0 and i equals 1.",
    "start": "4446050",
    "end": "4453010"
  },
  {
    "text": "And then, it's asserting\nthat x equals 2. If I run this serially,\nthe assertion passes.",
    "start": "4453010",
    "end": "4459200"
  },
  {
    "text": " But when I run it in parallel,\nit may not produce a 2.",
    "start": "4459200",
    "end": "4467230"
  },
  {
    "text": "It can produce a 1. And let's see why that is. So the way to understand this\ncode is to think about its",
    "start": "4467230",
    "end": "4474350"
  },
  {
    "text": "execution in terms of a\ndependency [? dag ?]. So here I have my initialization\nof x.",
    "start": "4474350",
    "end": "4481650"
  },
  {
    "text": "Then once that's done, the\ncilk_for loop allows me to do two things at a time, b and c,\nwhich are both incrementing x.",
    "start": "4481650",
    "end": "4492030"
  },
  {
    "text": "And then, I assert that\nx equals 2 when they're both done.",
    "start": "4492030",
    "end": "4498340"
  },
  {
    "text": "Because that's the semantics\nof the cilk_for. So let's see where\nthe race occurs.",
    "start": "4498340",
    "end": "4504400"
  },
  {
    "text": "So remember that it occurs\nwhen I have two logically parallel instructions\nthat access the same memory location.",
    "start": "4504400",
    "end": "4510389"
  },
  {
    "text": "Here, it's going to\nbe the location x. And at least one of them\nperforms a write execution.",
    "start": "4510390",
    "end": "4518750"
  },
  {
    "text": "So if we actually looked closer,\nI want to expand this into this larger thing.",
    "start": "4518750",
    "end": "4523909"
  },
  {
    "text": "Because as you know, X++ is not\ndone on a memory location. It's not done as a single\ninstruction.",
    "start": "4523910",
    "end": "4530120"
  },
  {
    "text": "It's done as a load,\nx into a register. Increment the register, and then\nstore the value back in.",
    "start": "4530120",
    "end": "4538470"
  },
  {
    "text": "And meanwhile, there's another\nregister on another processor, presumably, that's doing\nthe same thing.",
    "start": "4538470",
    "end": "4545030"
  },
  {
    "text": "So this is the one I\nwant to look at. This is just a zooming in, if\nyou will, on this dependency",
    "start": "4545030",
    "end": "4550389"
  },
  {
    "text": "graph to look a little bit finer\ngrain at what's actually happening one step at a time.",
    "start": "4550390",
    "end": "4556570"
  },
  {
    "text": "So the determinacy race,\nrecall, occurs-- this is by something,\nI'm going to say again, you should memorize.",
    "start": "4556570",
    "end": "4564420"
  },
  {
    "text": "So you should know\nwhat this is. You should be able to say what\na determinacy race is.",
    "start": "4564420",
    "end": "4569750"
  },
  {
    "text": "It's when you have two\ninstructions that are both accessing the same location,\nand one of them performs write.",
    "start": "4569750",
    "end": "4575230"
  },
  {
    "text": "And here, I have that. This guy is in parallel. He's being stored to here.",
    "start": "4575230",
    "end": "4580360"
  },
  {
    "text": "This is also a race. He's been reading it, and\nthis guy is writing it.",
    "start": "4580360",
    "end": "4586080"
  },
  {
    "text": "So let's see what can happen\nand what can go wrong here. So here's my value,\nx, in memory.",
    "start": "4586080",
    "end": "4591650"
  },
  {
    "text": "And here's my two registers on,\npresumably, two different processors. So one thing is that\nyou can typically--",
    "start": "4591650",
    "end": "4598690"
  },
  {
    "text": "and this is not quite the case\nwith real hardware-- but an abstraction of the hardware\nis that you can treat the",
    "start": "4598690",
    "end": "4605620"
  },
  {
    "text": "parallel execution from a\nlogical point of view as if you're interleaving instructions\nfrom the",
    "start": "4605620",
    "end": "4611690"
  },
  {
    "text": "different processors. OK. We're going to talk in three or\nfour lectures about where",
    "start": "4611690",
    "end": "4617850"
  },
  {
    "text": "that isn't the right\nabstraction. But it is close to the\nright abstraction.",
    "start": "4617850",
    "end": "4623480"
  },
  {
    "text": "So here, basically, we execute\nstatement one, which causes x to become 0.",
    "start": "4623480",
    "end": "4629430"
  },
  {
    "text": "Now let's execute\nstatement two. That causes r1 to become 0.",
    "start": "4629430",
    "end": "4636730"
  },
  {
    "text": "Then, I can increment that. It becomes a 1. All well and good. But now if the next logical\nthing that happens is that r2",
    "start": "4636730",
    "end": "4645670"
  },
  {
    "text": "is set to the value x,\nthen it becomes 0.",
    "start": "4645670",
    "end": "4651390"
  },
  {
    "text": "Then we increment it. And now, he stores\nback 1 into x.",
    "start": "4651390",
    "end": "4656900"
  },
  {
    "text": "And now, this guy stores\n1 back into x. And notice that now,\nwe [UNINTELLIGIBLE] go to the assertion.",
    "start": "4656900",
    "end": "4663320"
  },
  {
    "text": "And we assert that it's\n2, and it's not the 2. It's a 1.",
    "start": "4663320",
    "end": "4669659"
  },
  {
    "text": "Because we lost one\nof the updates. Now the reason race bugs are\nreally pernicious is, notice",
    "start": "4669660",
    "end": "4675090"
  },
  {
    "text": "that if I had executed this\nwhole branch, and then this whole branch, I get\nthe right answer.",
    "start": "4675090",
    "end": "4682510"
  },
  {
    "text": "Or if I executed this whole\nbranch, and then this whole branch, I get the\nright answer.",
    "start": "4682510",
    "end": "4688600"
  },
  {
    "text": "The only time I don't get the\nright answer is when those two things happen to interleave\njust so.",
    "start": "4688600",
    "end": "4694490"
  },
  {
    "text": "And that's what happens with\nrace conditions generally, is that you can run your code a\nmillion times and not see the",
    "start": "4694490",
    "end": "4702050"
  },
  {
    "text": "bug, and then run it once, and\nit crashes out in the field.",
    "start": "4702050",
    "end": "4707670"
  },
  {
    "text": "Or what's happened is there\nhave been race bugs responsible for failure of\nspace shuttle to launch.",
    "start": "4707670",
    "end": "4715640"
  },
  {
    "text": "You have the North American\nblackout of 2001?",
    "start": "4715640",
    "end": "4722042"
  },
  {
    "text": "2003? It wasn't that long ago. It was like, 10 years ago. We had big black out caused by\na race condition in the code",
    "start": "4722042",
    "end": "4728970"
  },
  {
    "text": "run by the power companies. There been medical instruments\nthat have fried people, killed",
    "start": "4728970",
    "end": "4736599"
  },
  {
    "text": "them and maimed them, because\nof race conditions. These are really serious bugs.",
    "start": "4736600",
    "end": "4742889"
  },
  {
    "text": "Question? AUDIENCE: [INAUDIBLE] when you\nsaid, the only time that that",
    "start": "4742890",
    "end": "4748290"
  },
  {
    "text": "code is actually execute\nserially? PROFESSOR: It could execute in\nparallel if it happened that",
    "start": "4748290",
    "end": "4755380"
  },
  {
    "text": "these guys executed\nbefore these guys. If you think of a larger\ncontext, a whole bunch of",
    "start": "4755380",
    "end": "4760690"
  },
  {
    "text": "these things, and I have two\nroutines where they're both incrementing x in the middle\nof great big parallel",
    "start": "4760690",
    "end": "4766210"
  },
  {
    "text": "programs, it could be that\nthey're executing perfectly well in parallel.",
    "start": "4766210",
    "end": "4771280"
  },
  {
    "text": "But if those two small sections\nof code happen to execute like this or like this,\nthen you're going to end",
    "start": "4771280",
    "end": "4780670"
  },
  {
    "text": "up with it executing\ncorrectly. But if they execute sort of at\nthe same time, it would not",
    "start": "4780670",
    "end": "4786170"
  },
  {
    "text": "necessarily behave correctly. So there are two types of races\nthat people talk about,",
    "start": "4786170",
    "end": "4794500"
  },
  {
    "text": "a read race and a write race. So suppose you have two\ninstructions that access a",
    "start": "4794500",
    "end": "4799580"
  },
  {
    "text": "location, x. And suppose that a\nis parallel to b. Both a and b are both reads,\nyou get no race.",
    "start": "4799580",
    "end": "4806170"
  },
  {
    "text": "That's good. Because there's no way. But if one is a read and one is\na write, then one of them",
    "start": "4806170",
    "end": "4813130"
  },
  {
    "text": "is going to see a different\nvalue, depending upon whether it occurred before and\nafter the write. Or if they both are writing,\none can lose a value.",
    "start": "4813130",
    "end": "4819155"
  },
  {
    "text": " So these are read races.",
    "start": "4819155",
    "end": "4825489"
  },
  {
    "text": "And this is a write race. So we say that the two\nsections of code are independent if they have\nno determinacy",
    "start": "4825490",
    "end": "4830630"
  },
  {
    "text": "races between them. So for example, this piece of\ncode is incrementing y, and this is incrementing x.",
    "start": "4830630",
    "end": "4837050"
  },
  {
    "text": "And y is not equal to x. Those are independent\npieces of code. So to avoid races, you want to\nmake sure that the iterations",
    "start": "4837050",
    "end": "4845970"
  },
  {
    "text": "of your cilk_for are\nindependent. So what's going on in one\niteration is different from",
    "start": "4845970",
    "end": "4851970"
  },
  {
    "text": "what's going on in another. That you're not writing\nsomething in one that you're using in the next,\nfor example.",
    "start": "4851970",
    "end": "4858740"
  },
  {
    "text": "Between a cilk_spawn and the\ncorresponding cilk_sync, the code of the spawn child should\nbe independent of the code of",
    "start": "4858740",
    "end": "4865230"
  },
  {
    "text": "the parent. OK? Including any code executed\nby additional spawned or called children.",
    "start": "4865230",
    "end": "4871429"
  },
  {
    "text": "So it's basically saying, when\nyou spawn something off, don't then go and do something that's\ngoing to modify the",
    "start": "4871430",
    "end": "4876840"
  },
  {
    "text": "same locations. You really want to modify\ndifferent locations. ",
    "start": "4876840",
    "end": "4882530"
  },
  {
    "text": "It's fine if they both read\nthe same locations. But it's not fine for one\nof them to read and one of them to write.",
    "start": "4882530",
    "end": "4889730"
  },
  {
    "text": "One thing here to understand\nis that when you spawn a function, the arguments are\nactually executed serially",
    "start": "4889730",
    "end": "4896540"
  },
  {
    "text": "before the actual\nspawn occurs. So you evaluate the arguments,\nand you set it all up, then",
    "start": "4896540",
    "end": "4901900"
  },
  {
    "text": "you spawn the function. So the actual spawn\noccurs after the",
    "start": "4901900",
    "end": "4906949"
  },
  {
    "text": "evaluation of arguments. So they're evaluated\nin the parent. ",
    "start": "4906950",
    "end": "4912349"
  },
  {
    "text": "Machine word size matters. So this is generally\nthe case for races.",
    "start": "4912350",
    "end": "4918250"
  },
  {
    "text": "By the way, races are\nnot just Cilk stuff. These races occur in all of\nthese concurrency platforms.",
    "start": "4918250",
    "end": "4925600"
  },
  {
    "text": "I'm illustrating Cilk because\nthat's what we're going to be using in our labs\nand so forth. So it turns out machine\nword size matters.",
    "start": "4925600",
    "end": "4932430"
  },
  {
    "text": "And you can have races in\npacked data structures. So for example, on some\nmachines, if you declare a",
    "start": "4932430",
    "end": "4942180"
  },
  {
    "text": "char a and char b in a struct,\nthen updating x and x, b in",
    "start": "4942180",
    "end": "4948580"
  },
  {
    "text": "parallel may cause a race,\nbecause they're both actually operating on a word basis.",
    "start": "4948580",
    "end": "4954380"
  },
  {
    "text": "Now on the Intel architectures, that doesn't happen. Because Intel supports atomic\nupdates of single bytes.",
    "start": "4954380",
    "end": "4962090"
  },
  {
    "text": "So you don't have to\nworry about it. But if you were accessing bits\nwithin a word, you could end",
    "start": "4962090",
    "end": "4967360"
  },
  {
    "text": "up with the same thing. You access bit five and bit\nthree, you think you're acting",
    "start": "4967360",
    "end": "4972990"
  },
  {
    "text": "independently, but in fact,\nyou're reading the whole word or the whole byte in\norder to access it. ",
    "start": "4972990",
    "end": "4981070"
  },
  {
    "text": "The technology that you're going\nto be using fortunately comes with a race detector,\nwhich you will find invaluable",
    "start": "4981070",
    "end": "4989180"
  },
  {
    "text": "for debugging your stuff. And so this is kind of like\na Valgrind for races.",
    "start": "4989180",
    "end": "4994239"
  },
  {
    "text": " What's good about this race\ndetector is it provides a rock",
    "start": "4994240",
    "end": "5002739"
  },
  {
    "text": "hard guarantee. If you have a deterministic\nprogram that on a given input",
    "start": "5002740",
    "end": "5008520"
  },
  {
    "text": "could possibly behave any\ndifferently from your serial program, from the corresponding\nserial program,",
    "start": "5008520",
    "end": "5015080"
  },
  {
    "text": "if you got rid of the parallel\nkeywords, this tool, Cilkscreen, guarantees to\nreport and localize the",
    "start": "5015080",
    "end": "5021570"
  },
  {
    "text": "offending race. It'll tell you, you got\na race between this location and that location.",
    "start": "5021570",
    "end": "5027100"
  },
  {
    "text": "And it's up to you to find\nit and fix it, but it can tell you that. It employs regression test\nmethodology, where the",
    "start": "5027100",
    "end": "5033850"
  },
  {
    "text": "programmer provides\ntest inputs. So if you don't provide test\ninputs to elicit the race, you",
    "start": "5033850",
    "end": "5040719"
  },
  {
    "text": "still can have a bug. But if you have a test input\nthat in any way could behave differently than the serial\nexecution, bingo.",
    "start": "5040720",
    "end": "5048090"
  },
  {
    "text": "It'll tell you.  It identifies a bunch of things\ninvolving the race,",
    "start": "5048090",
    "end": "5054860"
  },
  {
    "text": "including a stack trace. It runs off the binary\nexecutable using what's called dynamic instrumentation.",
    "start": "5054860",
    "end": "5061530"
  },
  {
    "text": "So that's kind of like Valgrind,\nexcept it actually does this as it's running.",
    "start": "5061530",
    "end": "5066699"
  },
  {
    "text": "It uses a technology called PIN,\nwhich you can read about. P-I-N, which is a nice platform\nfor doing code",
    "start": "5066700",
    "end": "5077340"
  },
  {
    "text": "rewriting and analysis\non the fly. It runs about 20 times slower\nthan real time.",
    "start": "5077340",
    "end": "5082600"
  },
  {
    "text": "So you basically use\nit for debugging. So the first part of project\nfour is basically coming up to",
    "start": "5082600",
    "end": "5096660"
  },
  {
    "text": "speed with this technology. And so, there's some\ngood things. And that's going to be\navailable tomorrow. Is that what we said?",
    "start": "5096660",
    "end": "5101900"
  },
  {
    "text": "Yeah, that will be available\ntomorrow. So this is actually--\nthis is tons of fun.",
    "start": "5101900",
    "end": "5107410"
  },
  {
    "text": "Most people in most places\ndon't get to play with parallel technology like this. ",
    "start": "5107410",
    "end": "5120555"
  }
]
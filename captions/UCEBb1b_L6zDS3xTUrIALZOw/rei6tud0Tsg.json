[
  {
    "text": "NARRATOR: The following content\nis provided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6600"
  },
  {
    "text": "offer high-quality educational\nresources for free. To make a donation or to view\nadditional materials from",
    "start": "6600",
    "end": "12810"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "12810",
    "end": "18130"
  },
  {
    "text": " PROFESSOR: To take up the topic\nof quantization, you",
    "start": "18130",
    "end": "25160"
  },
  {
    "text": "remember we're talking about\nsource coding in the first part of the course, channel\ncoding in the",
    "start": "25160",
    "end": "30900"
  },
  {
    "text": "last 2/3 of the course. Source coding, like all, is\ndivided into three parts.",
    "start": "30900",
    "end": "39980"
  },
  {
    "text": "If you have waveforms, such\nas speech, you start out with the waveform.",
    "start": "39980",
    "end": "47400"
  },
  {
    "text": "The typical way to encode\nwaveforms is you first either sample the waveform or\nyou expand it in",
    "start": "47400",
    "end": "54750"
  },
  {
    "text": "some kind of expansion. When you do that, you wind up\nwith a sequence of numbers.",
    "start": "54750",
    "end": "61720"
  },
  {
    "text": "You put the sequence of numbers\ninto a quantizer, and the quantizer reduces that\nto a discrete alphabet.",
    "start": "61720",
    "end": "70270"
  },
  {
    "text": "You put the discrete symbols\ninto the discrete encoder.",
    "start": "70270",
    "end": "75500"
  },
  {
    "text": "You pass it through a reliable\nbinary channel. What is a reliable\nbinary channel?",
    "start": "75500",
    "end": "81140"
  },
  {
    "text": "It's a layered view of any old\nchannel in the world, OK? In other words, the way that\ndiscrete channels work these",
    "start": "81140",
    "end": "88110"
  },
  {
    "text": "days is that, in almost all\ncases, what goes into them is",
    "start": "88110",
    "end": "93910"
  },
  {
    "text": "a binary stream of signals, and\nwhat comes out of them is a binary stream of symbols, and\nthe output is essentially",
    "start": "93910",
    "end": "104320"
  },
  {
    "text": "the same z-input. That's the whole purpose of\nhow you design digital",
    "start": "104320",
    "end": "109710"
  },
  {
    "text": "channels, and they work\nover analog media and all sorts of things.",
    "start": "109710",
    "end": "115220"
  },
  {
    "text": "OK, so discrete encoders and\ndiscrete decoders are really a",
    "start": "115220",
    "end": "121400"
  },
  {
    "text": "valid topic to study\nin their own. I mean, you have text and stuff\nlike that, which is",
    "start": "121400",
    "end": "128190"
  },
  {
    "text": "discrete to start with, so\nthere's a general topic of how do you encode discrete things?",
    "start": "128190",
    "end": "135990"
  },
  {
    "text": "We've pretty much answered that\nproblem, at least in an abstract sense, and the main\npoint there is you find the",
    "start": "135990",
    "end": "147230"
  },
  {
    "text": "entropy of that discrete\nsequence, the entropy per symbol, and then you find ways\nof encoding that discrete",
    "start": "147230",
    "end": "156379"
  },
  {
    "text": "source in such a way that the\nnumber of bits per symbol is approximately equal\nto that entropy.",
    "start": "156380",
    "end": "163400"
  },
  {
    "text": "We know you can't do any\nbetter than that. You can't do an encoding, which\nis uniquely decodable,",
    "start": "163400",
    "end": "171390"
  },
  {
    "text": "which you can get out of with\nthe original symbols again, with anything less\nthan the entropy.",
    "start": "171390",
    "end": "178540"
  },
  {
    "text": "So at least we know roughly what\nthe answer to that is. We even know some classy schemes\nlike the Lempel-Ziv",
    "start": "178540",
    "end": "186150"
  },
  {
    "text": "algorithm, which will in fact\noperate without even knowing",
    "start": "186150",
    "end": "191900"
  },
  {
    "text": "anything about what the\nprobabilities are. So we sort of understand this\nblock here at this point.",
    "start": "191900",
    "end": "199750"
  },
  {
    "text": "And we could start with this\nnext, or we could start with this next, and unlike the\nelectrician here, we're going",
    "start": "199750",
    "end": "208569"
  },
  {
    "text": "to move in sequence and look at\nthis next and this third.",
    "start": "208570",
    "end": "214120"
  },
  {
    "text": "There's another reason\nfor that. When we get into this question,\nwe will be talking",
    "start": "214120",
    "end": "221690"
  },
  {
    "text": "about what do you do\nwith waveforms? How do you deal with\nwaveforms? It's what you've been studying\nprobably since the sixth",
    "start": "221690",
    "end": "229850"
  },
  {
    "text": "grade, and you're all\nfamiliar with it. You do integration and\nthings like that.",
    "start": "229850",
    "end": "235770"
  },
  {
    "text": "You know how to work\nwith functions. What we're going to do with\nfunctions in this course is a",
    "start": "235770",
    "end": "241300"
  },
  {
    "text": "little bit different than\nwhat you're used to. It's quite a bit different than\nwhat you learned in your",
    "start": "241300",
    "end": "247010"
  },
  {
    "text": "Signals and Systems course, and\nyou'll find out why as we move along. But we have to understand this\nbusiness of how to deal with",
    "start": "247010",
    "end": "257310"
  },
  {
    "text": "waveforms, both in terms of this\nblock, which is the final",
    "start": "257310",
    "end": "262350"
  },
  {
    "text": "block we'll study in source\ncoding, and also in terms of how to deal with channels\nbecause in real channels,",
    "start": "262350",
    "end": "268780"
  },
  {
    "text": "generally what you transmit\nis a waveform. What the noise does to you is to\nadd a waveform or, in some",
    "start": "268780",
    "end": "275919"
  },
  {
    "text": "sense, multiply what you put\nin by something else. And all of that is\nwaveform stuff.",
    "start": "275920",
    "end": "282650"
  },
  {
    "text": "And all of information theory\nand all of digital communication is based\non thinking bits.",
    "start": "282650",
    "end": "289610"
  },
  {
    "text": "So somehow or other, we have to\nbecome very facile in going",
    "start": "289610",
    "end": "294860"
  },
  {
    "text": "from waveforms to bits. Now I've been around the\nprofessional communities of",
    "start": "294860",
    "end": "300560"
  },
  {
    "text": "both communication and\ninformation theory for a long, long time.",
    "start": "300560",
    "end": "306790"
  },
  {
    "text": "There is one fundamental problem\nthat gives everyone problems because information\ntheory texts do not deal with",
    "start": "306790",
    "end": "314169"
  },
  {
    "text": "it and communication texts\ndo not deal with it. And that problem is how do you\ngo from one to the other,",
    "start": "314170",
    "end": "319960"
  },
  {
    "text": "which seems like it ought\nto be an easy thing. It's not as easy as it looks,\nand therefore, we're going to",
    "start": "319960",
    "end": "325820"
  },
  {
    "text": "spent quite a bit\nof time on that. In fact, I passed out lectures\n6 and 7 today, which in",
    "start": "325820",
    "end": "332139"
  },
  {
    "text": "previous years I've done in two\nseparate lectures because quantization is a problem\nthat looks important.",
    "start": "332140",
    "end": "339419"
  },
  {
    "text": "We'll see that it's not quite\nas important as it looks. And I guess the other thing is,\nI mean, at different times",
    "start": "339420",
    "end": "349180"
  },
  {
    "text": "you have to teach different\nthings or you get stale on it. And I've just finished writing\nsome fairly nice notes, I",
    "start": "349180",
    "end": "356220"
  },
  {
    "text": "think, on this question of how\ndo you go from waveforms to numbers and how do you go from\nnumbers to waveforms.",
    "start": "356220",
    "end": "363080"
  },
  {
    "text": "And I want to spend a little\nmore time on that this year than I did last year. I want to spend, therefore,\na little less time on",
    "start": "363080",
    "end": "370730"
  },
  {
    "text": "quantization, so that next time,\nwe will briefly review",
    "start": "370730",
    "end": "375910"
  },
  {
    "text": "what we've done today on\nquantization, but we will essentially just compress\nthose two",
    "start": "375910",
    "end": "383310"
  },
  {
    "text": "lectures all into one. In dealing with waveforms,\nwe're going to learn some",
    "start": "383310",
    "end": "390310"
  },
  {
    "text": "interesting and kind\nof cool things. Like for those of you who\nreally don't -- are not",
    "start": "390310",
    "end": "396180"
  },
  {
    "text": "interested in mathematics, you\nknow that people study things like the theory of real\nvariables and functional",
    "start": "396180",
    "end": "403920"
  },
  {
    "text": "analysis and all of these neat\nthings, which are very, in a",
    "start": "403920",
    "end": "410070"
  },
  {
    "text": "sense, advanced mathematics. They're all based on measure\ntheory, and you're going to",
    "start": "410070",
    "end": "416919"
  },
  {
    "text": "find out a little bit about\nmeasure theory here. Not an awful lot, but just\nenough to know why one has to",
    "start": "416920",
    "end": "423380"
  },
  {
    "text": "deal with those questions\nbecause the major results in dealing with waveforms and\nsamples really can't be stated",
    "start": "423380",
    "end": "432160"
  },
  {
    "text": "in any other form than\nin a somewhat measure-theoretic form. So we're going to find just\nenough about that so we can",
    "start": "432160",
    "end": "440740"
  },
  {
    "text": "understand what those\nissues are about. So that's why next time we're\ngoing to start dealing with the waveform issues.",
    "start": "440740",
    "end": "447930"
  },
  {
    "text": "OK, so today, we're dealing with\nthese quantizer issues and how do you take a sequence\nof numbers, turn them into a",
    "start": "447930",
    "end": "456630"
  },
  {
    "text": "sequence of symbols\nat the other end? How do you take a sequence\nof symbols, turn them back into numbers?",
    "start": "456630",
    "end": "463110"
  },
  {
    "start": "463110",
    "end": "475719"
  },
  {
    "text": "So when you convert real numbers\nto binary strings, you need a mapping from the\nset of real numbers",
    "start": "475720",
    "end": "483360"
  },
  {
    "text": "to a discrete alphabet. And we're typically going to\nhave a mapping from the set of",
    "start": "483360",
    "end": "488520"
  },
  {
    "text": "real numbers into a finite\ndiscrete alphabet. Now what's the first obvious\nthing that you notice when you",
    "start": "488520",
    "end": "496790"
  },
  {
    "text": "have a mapping that goes from an\ninfinite set of things into a finite set of things? AUDIENCE: [INAUDIBLE]",
    "start": "496790",
    "end": "503270"
  },
  {
    "text": "PROFESSOR: What? AUDIENCE: [INAUDIBLE] ",
    "start": "503270",
    "end": "508449"
  },
  {
    "text": "PROFESSOR: Not really. It's a much simpler\nidea than that.",
    "start": "508450",
    "end": "514010"
  },
  {
    "text": "How are you going to get back? I mean, usually when you map\nsomething into something else,",
    "start": "514010",
    "end": "520580"
  },
  {
    "text": "you would like to\nget back again. When you map an infinite set\ninto a finite set, how are you",
    "start": "520580",
    "end": "526870"
  },
  {
    "text": "going to get back? AUDIENCE: You're not. PROFESSOR: You're not. Good!",
    "start": "526870",
    "end": "532190"
  },
  {
    "text": "There's not any way in hell\nthat you're ever going to get back, OK? So, in other words, what\nyou've done here is to",
    "start": "532190",
    "end": "539779"
  },
  {
    "text": "deliberately introduce some\ndistortion into the picture. You've introduced distortion\nbecause you have no choice.",
    "start": "539780",
    "end": "547210"
  },
  {
    "text": "If you want to turn numbers into\nbits, you can't get back to the exact numbers again.",
    "start": "547210",
    "end": "553460"
  },
  {
    "text": "So you can only get back to some\napproximation of what the numbers are. But anyway, this process of\ndoing this is called scalar",
    "start": "553460",
    "end": "561250"
  },
  {
    "text": "quantization, if we're mapping\nfrom the set of real numbers to a discrete alphabet.",
    "start": "561250",
    "end": "567410"
  },
  {
    "text": "If instead you want to convert\nreal n-tuples into sequences",
    "start": "567410",
    "end": "574680"
  },
  {
    "text": "of discrete symbols, in other\nwords, into a finite alphabet, you call that vector\nquantization because you can",
    "start": "574680",
    "end": "582330"
  },
  {
    "text": "view n real numbers, a sequence\nof n real numbers as a vector within coordinates\nand within components.",
    "start": "582330",
    "end": "590990"
  },
  {
    "text": "And I'm not doing anything\nfancy with vectors here. You just look at an n-tuple\nof numbers as a vector.",
    "start": "590990",
    "end": "597490"
  },
  {
    "text": "OK, so scalar quantization is\ngoing to encode each term of the source sequence\nseparately.",
    "start": "597490",
    "end": "606290"
  },
  {
    "text": "And vector quantization is first\ngoing to segment this",
    "start": "606290",
    "end": "612040"
  },
  {
    "text": "sequence of numbers into blocks\nof n numbers each, and",
    "start": "612040",
    "end": "618600"
  },
  {
    "text": "then it's going to find a way\nof encoding those n-blocks",
    "start": "618600",
    "end": "623610"
  },
  {
    "text": "into discrete symbols. Does this sound a little bit\nlike what we've already done in dealing with discrete\nsources?",
    "start": "623610",
    "end": "631150"
  },
  {
    "text": "Yeah, it's exactly\nthe same thing. I mean, we started out by\nmapping individual symbols",
    "start": "631150",
    "end": "637430"
  },
  {
    "text": "into bit sequences, and then we\nsaid, gee, we can also map",
    "start": "637430",
    "end": "642950"
  },
  {
    "text": "n-blocks of those symbols into\nbits, and we said, gee, this is the same problem again.",
    "start": "642950",
    "end": "649230"
  },
  {
    "text": "There's nothing different,\nnothing new. And it's the same thing here\nalmost except here the",
    "start": "649230",
    "end": "657660"
  },
  {
    "text": "properties of the real numbers\nare important. Why are the properties of the\nreal numbers important?",
    "start": "657660",
    "end": "663200"
  },
  {
    "text": "Why can't we just look\nat this as symbols? Well, because, since we can't\ndo this mapping in an",
    "start": "663200",
    "end": "670210"
  },
  {
    "text": "invertable way, you have to deal\nwith the fact that you have distortion here.",
    "start": "670210",
    "end": "676520"
  },
  {
    "text": "There's no other way\nto think about it. There is distortion. You might as well face it. If you try to cover it\nup, it just comes",
    "start": "676520",
    "end": "684110"
  },
  {
    "text": "up to kick you later. So we face it right in the\nbeginning, and that's why we",
    "start": "684110",
    "end": "690760"
  },
  {
    "text": "deal with these things\nas numbers.  So let's look at a simple\nexample of what a scalar",
    "start": "690760",
    "end": "698380"
  },
  {
    "text": "quantizer is going to do. Basically, what we have to do\nis to map the line R, mainly",
    "start": "698380",
    "end": "710240"
  },
  {
    "text": "the set of real numbers, into\nM different regions, which we'll call R1 up to R sub M.\nAnd in this picture here,",
    "start": "710240",
    "end": "717880"
  },
  {
    "text": "here's R1, here's R2, here's R3,\nhere's R4, R5 and R6, and",
    "start": "717880",
    "end": "723220"
  },
  {
    "text": "that's all the regions\nwe have. You'll notice one of the things\nthat that does is it",
    "start": "723220",
    "end": "728290"
  },
  {
    "text": "takes an enormous set of\nnumbers, namely all these numbers less than this,\nand match them all",
    "start": "728290",
    "end": "734790"
  },
  {
    "text": "into the same symbol. So you might wind up with a\nfair amount of distortion there, no matter how you\nmeasure distortion.",
    "start": "734790",
    "end": "742880"
  },
  {
    "text": "All these outliers here all\nget mapped into a6, and everything in the middle gets\nmapped somehow into these",
    "start": "742880",
    "end": "749620"
  },
  {
    "text": "intermediate values. But every source value now in\nthe region R sub j, we're",
    "start": "749620",
    "end": "758140"
  },
  {
    "text": "going to map into a\nrepresentation point a sub j. So everything in R1 is going\nto be mapped into a1.",
    "start": "758140",
    "end": "766220"
  },
  {
    "text": "Everything in R2 is going\nto get mapped into a2 and so forth.",
    "start": "766220",
    "end": "771380"
  },
  {
    "text": "Is this a general way to map\nR into a set of M symbols? ",
    "start": "771380",
    "end": "778380"
  },
  {
    "text": "Is there anything else I ought\nto be thinking about? ",
    "start": "778380",
    "end": "785700"
  },
  {
    "text": "Well, here, these regions here\nhave a very special property. Namely, each region\nis an interval.",
    "start": "785700",
    "end": "793850"
  },
  {
    "text": "And we might say to ourselves,\nwell, maybe we shouldn't map points into intervals.",
    "start": "793850",
    "end": "799830"
  },
  {
    "text": "But aside from the fact that\nwe've chosen intervals here, this is a perfectly general\nway to represent a mapping",
    "start": "799830",
    "end": "807230"
  },
  {
    "text": "from the real numbers into\na discrete set of things. Namely, when you're doing a\nmapping from the real numbers",
    "start": "807230",
    "end": "813970"
  },
  {
    "text": "into a discrete set of things,\nthere's some set of real numbers that get mapped\ninto a1, and that by",
    "start": "813970",
    "end": "821660"
  },
  {
    "text": "definition is called R1. There's some set of numbers\nwhich get mapped into a2.",
    "start": "821660",
    "end": "827220"
  },
  {
    "text": "That by definition is called\nR2 and so forth. So aside from the fact that\nthese intervals with these",
    "start": "827220",
    "end": "834570"
  },
  {
    "text": "regions in this picture happen\nto be intervals, this is a perfectly general mapping from\nR into a discrete alphabet.",
    "start": "834570",
    "end": "844290"
  },
  {
    "text": "So since I've decided I'm\ngoing to look at scalar quantizers first, this is a\ncompletely general view of",
    "start": "844290",
    "end": "850720"
  },
  {
    "text": "what a scalar quantizer is. You tell me how many\nquantization regions you want,",
    "start": "850720",
    "end": "857580"
  },
  {
    "text": "namely how big the alphabet is\nthat you're mapping things",
    "start": "857580",
    "end": "863610"
  },
  {
    "text": "into, and then your only problem\nis how do you choose these regions and how\ndo you choose the",
    "start": "863610",
    "end": "868910"
  },
  {
    "text": "representation points? OK, one new thing here: Before,\nwe said when you have",
    "start": "868910",
    "end": "877260"
  },
  {
    "text": "a set of symbols a1 up to\na6, it doesn't matter what you call them.",
    "start": "877260",
    "end": "883120"
  },
  {
    "text": "They're just six symbols. Here it makes a difference what\nyou call them because",
    "start": "883120",
    "end": "888290"
  },
  {
    "text": "here they are representing\nreal numbers and they are representing real numbers\nbecause when you map some real",
    "start": "888290",
    "end": "897589"
  },
  {
    "text": "number on the real line into one\nof these letters here, the",
    "start": "897590",
    "end": "903940"
  },
  {
    "text": "distortion is u minus a sub j. If you're mapping u into a sub\nj, then you get a distortion,",
    "start": "903940",
    "end": "911950"
  },
  {
    "text": "which is this difference here. I haven't said yet what I am\ninterested in as far as",
    "start": "911950",
    "end": "918010"
  },
  {
    "text": "distortion is concerned. Am I interested in squared\ndistortion, cubed distortion,",
    "start": "918010",
    "end": "924040"
  },
  {
    "text": "absolute magnitude\nof distortion? I haven't answered that\nquestion yet. But there is a distortion here,\nand somehow that has to",
    "start": "924040",
    "end": "931980"
  },
  {
    "text": "be important. We have to come to grips with\nwhat we call a distortion and",
    "start": "931980",
    "end": "938610"
  },
  {
    "text": "somehow how big that distortion\nis going to be. So our problem here is somehow\nto trade off between",
    "start": "938610",
    "end": "946230"
  },
  {
    "text": "distortion and number\nof points. As we make the number of\npoints bigger, we can",
    "start": "946230",
    "end": "952110"
  },
  {
    "text": "presumably make the distortion\nsmaller in some sense, although the distortion is\nalways going to be very big",
    "start": "952110",
    "end": "958800"
  },
  {
    "text": "from these really big negative\nnumbers and from really big positive numbers.",
    "start": "958800",
    "end": "964130"
  },
  {
    "text": "But aside from that, we just\nhave a problem of how do you choose the regions?",
    "start": "964130",
    "end": "969440"
  },
  {
    "text": "How do you choose the points? OK, I've sort of forgotten\nabout the problem that we",
    "start": "969440",
    "end": "976960"
  },
  {
    "text": "started with. And the problem that we started\nwith was to have a",
    "start": "976960",
    "end": "982990"
  },
  {
    "text": "source where the source was\na sequence of numbers.",
    "start": "982990",
    "end": "988140"
  },
  {
    "text": "And when we're talking about\nsources, we're talking about something stochastic. We need a probability measure\non these real numbers that",
    "start": "988140",
    "end": "997680"
  },
  {
    "text": "we're encoding. If we knew what they were, there\nwouldn't be any need to encode them.",
    "start": "997680",
    "end": "1004440"
  },
  {
    "text": "I mean, if we knew and the\nreceiver knew, there would be no need to encode them. The receiver would just print\nout what they were or store",
    "start": "1004440",
    "end": "1013680"
  },
  {
    "text": "them or do whatever\nthe receiver wants to do with them. OK, so we're going to view the\nsource value u with the sample",
    "start": "1013680",
    "end": "1021020"
  },
  {
    "text": "value of some random variable\ncapital U. And more generally, since we have a sequence, we're\ngoing to consider a",
    "start": "1021020",
    "end": "1030409"
  },
  {
    "text": "source sequence to be U1, U2, U3\nand so forth, or you could",
    "start": "1030410",
    "end": "1035610"
  },
  {
    "text": "consider it a bi-infinite\nsequence, starting at U minus infinity and working\nits way up forever.",
    "start": "1035610",
    "end": "1043970"
  },
  {
    "text": "And then we're going to have\nsome sort of model, statistical model, for this\nsequence of random variables.",
    "start": "1043970",
    "end": "1052480"
  },
  {
    "text": "Our typical model for these is\nto assume that we have a memoryless source.",
    "start": "1052480",
    "end": "1057580"
  },
  {
    "text": "In other words, U1, U2, U3 are\nindependent, identically distributed, random variables.",
    "start": "1057580",
    "end": "1063929"
  },
  {
    "text": "That's the model we'll use until\nwe get smarter and start",
    "start": "1063930",
    "end": "1069290"
  },
  {
    "text": "to think of something else. OK, so now each of these source\nvalues we're going to",
    "start": "1069290",
    "end": "1074860"
  },
  {
    "text": "map into some representation\npoint a sub j. That's what defines\nthe quantizer.",
    "start": "1074860",
    "end": "1081690"
  },
  {
    "text": "And now since a sub j is a\nsample value of a random variable U, a sub j is going to\nbe a sample value of some",
    "start": "1081690",
    "end": "1089400"
  },
  {
    "text": "random variable V. OK, in other\nwords, the probabilities of these different sample\nvalues is going to be",
    "start": "1089400",
    "end": "1096510"
  },
  {
    "text": "determined by the set of U's\nthat math into that a sub j.",
    "start": "1096510",
    "end": "1102330"
  },
  {
    "text": "So we have a source sequence\nU1, U2, blah, blah, blah. We have a representation\nsequence V1, V2, blah, blah,",
    "start": "1102330",
    "end": "1110720"
  },
  {
    "text": "blah, which is defined by if U\nsub k is in R sub j, then Vk",
    "start": "1110720",
    "end": "1118039"
  },
  {
    "text": "is equal to a sub j. Point of confusion here: It's\nnot confusing now, but it will",
    "start": "1118040",
    "end": "1123690"
  },
  {
    "text": "be confusing at some\npoint to you. When you're talking about\nsources, you really need two",
    "start": "1123690",
    "end": "1130250"
  },
  {
    "text": "indices that you're talking\nabout all the time. OK, one of them is\nhow to represent",
    "start": "1130250",
    "end": "1139450"
  },
  {
    "text": "different elements in time. Here we're using k as a way of\nkeeping track of what element",
    "start": "1139450",
    "end": "1145299"
  },
  {
    "text": "in time we're talking about. We're also talking about a\ndiscrete alphabet, which has a",
    "start": "1145300",
    "end": "1150570"
  },
  {
    "text": "certain number of elements in\nit, which is completely independent of time. Namely, we've just described\nthe quantizer as something",
    "start": "1150570",
    "end": "1158900"
  },
  {
    "text": "which maps real numbers\ninto sample values. It has nothing to do\nwith time at all.",
    "start": "1158900",
    "end": "1164350"
  },
  {
    "text": "We're going to use that same\nthing again and again and again, and we're using\nthe subscript j",
    "start": "1164350",
    "end": "1169880"
  },
  {
    "text": "to talk about that. When you write out problem\nsolutions, you are going to",
    "start": "1169880",
    "end": "1177830"
  },
  {
    "text": "find that it's incredibly\ndifficult sometimes to write sentences which distinguish\nabout whether you're talking",
    "start": "1177830",
    "end": "1185080"
  },
  {
    "text": "about one element out of an\nalphabet or one element out of",
    "start": "1185080",
    "end": "1190880"
  },
  {
    "text": "a time sequence. And everybody has that trouble,\nand you read most of",
    "start": "1190880",
    "end": "1196909"
  },
  {
    "text": "the literature in information\ntheory or communication theory, and you can't sort out\nmost of the time what people",
    "start": "1196910",
    "end": "1202880"
  },
  {
    "text": "are talking about because\nthey're doing that. I recommend to you using an\nelement and an alphabet to",
    "start": "1202880",
    "end": "1211360"
  },
  {
    "text": "talk about this sort of thing,\nwhat a sub j is or an element and a time sequence to\nkeep track of things",
    "start": "1211360",
    "end": "1217630"
  },
  {
    "text": "at different times. It's a nice way of keeping\nthem straight. OK, so anyway, for a scalar\nquantizer, we're going to be",
    "start": "1217630",
    "end": "1226370"
  },
  {
    "text": "able to just look at a single\nrandom variable U, which is a continuous-valued random\nvariable, which takes values",
    "start": "1226370",
    "end": "1234490"
  },
  {
    "text": "anywhere on the real line and\nmaps it into a single element",
    "start": "1234490",
    "end": "1240230"
  },
  {
    "text": "in this discrete alphabet, which\nis the set a1 up to a6",
    "start": "1240230",
    "end": "1249120"
  },
  {
    "text": "that we were talking\nabout here. So a scalar quantizer then is\njust a map of this form, OK?",
    "start": "1249120",
    "end": "1256090"
  },
  {
    "text": "So the only thing we need for a\nscalar quantizer, we can now forget about time and talk about\nhow do you choose the",
    "start": "1256090",
    "end": "1262029"
  },
  {
    "text": "regions, how do you choose the\nrepresentation points?",
    "start": "1262030",
    "end": "1267080"
  },
  {
    "text": "OK, and there's a nice\nalgorithm there.",
    "start": "1267080",
    "end": "1273269"
  },
  {
    "text": "Again, one of these things,\nwhich if you were the first person to think about it, easy\nway to become famous.",
    "start": "1273270",
    "end": "1281540"
  },
  {
    "text": "You might not stay famous, but\nyou can get famous initially. Anyway, we're almost always\ninterested in the mean squared",
    "start": "1281540",
    "end": "1290970"
  },
  {
    "text": "error or the mean squared\ndistortion, MSD or MSE, which is the expected value of U minus\nV. U is this real-valued",
    "start": "1290970",
    "end": "1301890"
  },
  {
    "text": "random variable. V is the discrete random\nvariable into which it maps.",
    "start": "1301890",
    "end": "1308570"
  },
  {
    "text": "We have the distortion between\nU and V, which is U minus V. We now have the expected value\nof that squared distortion.",
    "start": "1308570",
    "end": "1318740"
  },
  {
    "text": "Why is everybody interested in\nsquared distortion instead of magnitude distortion\nor something else?",
    "start": "1318740",
    "end": "1325630"
  },
  {
    "text": "In many engineering problems,\nyou should be more interested in magnitude distortion.",
    "start": "1325630",
    "end": "1331690"
  },
  {
    "text": "Sometimes you're much more\ninterested in fourth-moment distortion or some other\nstrange thing. Why do we always use mean\nsquared distortion?",
    "start": "1331690",
    "end": "1340780"
  },
  {
    "text": "And why do we use mean-squared\neverything throughout almost everything we do in\ncommunication?",
    "start": "1340780",
    "end": "1349470"
  },
  {
    "text": "I'll tell you the reason now. We'll come back and talk about\nit more a number of times.",
    "start": "1349470",
    "end": "1355780"
  },
  {
    "text": "It's because this quantization\nproblem that we're talking about is almost always a\nsubproblem of this problem,",
    "start": "1355780",
    "end": "1363870"
  },
  {
    "text": "where you're dealing with\nwaveforms, where you take the waveform and you sample the\nwaveform, where you take the",
    "start": "1363870",
    "end": "1369760"
  },
  {
    "text": "waveform, and you turn the\nwaveform into some expansion.",
    "start": "1369760",
    "end": "1374970"
  },
  {
    "text": "When you find the mean-squared\ndistortion in a quantizer, it",
    "start": "1374970",
    "end": "1379980"
  },
  {
    "text": "turns out that that maps in\na beautiful way into the mean-squared distortion\nbetween waveforms.",
    "start": "1379980",
    "end": "1387340"
  },
  {
    "text": "If you deal with magnitudes or\nwith anything else in the world, all of that beauty\ngoes away, OK?",
    "start": "1387340",
    "end": "1394990"
  },
  {
    "text": "In other words, whenever you\nwant to go from waveforms to numbers, the one thing which\nremains invariant, which",
    "start": "1394990",
    "end": "1402890"
  },
  {
    "text": "remains nice all the way\nthrough, is this mean-square",
    "start": "1402890",
    "end": "1408040"
  },
  {
    "text": "distortion, mean-square\nvalue, OK? In other words, if you want\nto layer this problem into",
    "start": "1408040",
    "end": "1414620"
  },
  {
    "text": "looking at this problem\nseparately from looking at this problem, almost the only\nway you can do it that makes",
    "start": "1414620",
    "end": "1422250"
  },
  {
    "text": "sense is to worry about mean\nsquare distortion rather than some other kind of distortion.",
    "start": "1422250",
    "end": "1428919"
  },
  {
    "text": "So even though as engineers\nwe might be interested in something else, we almost always\nstick to that because",
    "start": "1428920",
    "end": "1435240"
  },
  {
    "text": "that's the thing that we can\ndeal with most nicely. I mean, as engineers, we're like\nthe drunk who dropped his",
    "start": "1435240",
    "end": "1444210"
  },
  {
    "text": "wallet on a dark street, and\nhe's searching for it, and somebody comes along. And here he is underneath a\nbeautiful light where he can",
    "start": "1444210",
    "end": "1454090"
  },
  {
    "text": "see everything. Somebody asks him what he's\nlooking for you, and he says he's looking for his wallet.",
    "start": "1454090",
    "end": "1459290"
  },
  {
    "text": "The guy looks down and says,\nwell, there's no wallet there. The drunk says I know. I dropped it over there, but\nit's dark over there.",
    "start": "1459290",
    "end": "1465200"
  },
  {
    "text": "So we use mean square\ndistortion in exactly the same sense. It isn't necessarily the problem\nwe're interested in,",
    "start": "1465200",
    "end": "1472940"
  },
  {
    "text": "but it's a problem where we\ncan see things clearly. So given that we're interested\nin the mean square distortion",
    "start": "1472940",
    "end": "1484560"
  },
  {
    "text": "of a scalar quantizer, an\ninteresting analytical problem that we can play with is for a\ngiven probability density on",
    "start": "1484560",
    "end": "1494630"
  },
  {
    "text": "this real random variable, and\nwe're assuming we have a probability density and a given\nalphabet size M, the",
    "start": "1494630",
    "end": "1506010"
  },
  {
    "text": "problem is how do you choose\nthese regions and how do you choose these representation\npoints in such a way as to",
    "start": "1506010",
    "end": "1514140"
  },
  {
    "text": "minimize the mean square\nerror, OK? So, in other words, we've taken\na big sort of messy",
    "start": "1514140",
    "end": "1520950"
  },
  {
    "text": "amorphous engineering problem,\nand we said, OK, we're going to deal with mean square error,\nand OK, we're going to",
    "start": "1520950",
    "end": "1527159"
  },
  {
    "text": "deal with scalar quantizers, and\nOK, we're going to fix a",
    "start": "1527160",
    "end": "1532670"
  },
  {
    "text": "number of quantization levels,\nso we've made all those choices to start with.",
    "start": "1532670",
    "end": "1538450"
  },
  {
    "text": "We still have this interesting\nproblem of how do you choose the right regions?",
    "start": "1538450",
    "end": "1543700"
  },
  {
    "text": "How do you choose the\nright sample points? And that turns out to\nbe a simple problem.",
    "start": "1543700",
    "end": "1551280"
  },
  {
    "text": "I wouldn't talk about\nif it wasn't simple. ",
    "start": "1551280",
    "end": "1558450"
  },
  {
    "text": "And we'll break it into\nsubproblems, and the subproblems are really simple.",
    "start": "1558450",
    "end": "1564510"
  },
  {
    "text": "The first subproblem is if I\ntell you what representation points I want to use, namely,\nin this picture here, I say",
    "start": "1564510",
    "end": "1575190"
  },
  {
    "text": "OK, I want to use these\nrepresentation points. And then I ask you, how are\nyou going to choose the",
    "start": "1575190",
    "end": "1582150"
  },
  {
    "text": "regions in an optimal way to\nminimize mean square error?",
    "start": "1582150",
    "end": "1588350"
  },
  {
    "text": "Well, you think about that for\nawhile, and you think about it in a number of ways. When you think about it in just\nthe right way, the answer",
    "start": "1588350",
    "end": "1595460"
  },
  {
    "text": "becomes obvious. And the answer is, let me not\nthink about the regions here,",
    "start": "1595460",
    "end": "1602970"
  },
  {
    "text": "but let me think about a\nparticular value that comes out of the source. Let me think, how should I\nconstruct a rule for how to",
    "start": "1602970",
    "end": "1611580"
  },
  {
    "text": "take outputs from this\nsource and map them",
    "start": "1611580",
    "end": "1617120"
  },
  {
    "text": "into some number here. So if I get some output from\nthe source u, I say, OK,",
    "start": "1617120",
    "end": "1625250"
  },
  {
    "text": "what's the distortion\nbetween u and a1? It's u minus a1.",
    "start": "1625250",
    "end": "1630539"
  },
  {
    "text": "And the magnitude of that is the\nmagnitude of u minus a1. The square of it is the square\nof u minus a1, and then say,",
    "start": "1630540",
    "end": "1637790"
  },
  {
    "text": "OK, let me compare that\nwith u minus a2. Let me compare it with u\nminus a3 and so forth.",
    "start": "1637790",
    "end": "1644650"
  },
  {
    "text": "Let me choose the smallest\nof those things. What's the smallest stuff\nfor any given u?",
    "start": "1644650",
    "end": "1651690"
  },
  {
    "text": "Suppose I have a u which\nhappens to be right there, for example.",
    "start": "1651690",
    "end": "1658630"
  },
  {
    "text": "What's the closest\nrepresentation point? ",
    "start": "1658630",
    "end": "1664320"
  },
  {
    "text": "Well, a3 is obviously\ncloser than a2.",
    "start": "1664320",
    "end": "1669649"
  },
  {
    "text": "And in fact for any point in\nhere, which is closer to a3",
    "start": "1669650",
    "end": "1675460"
  },
  {
    "text": "than it is to a2, we're\ngoing to choose a3. Now what's the set of points\nwhich are closer to a3 than",
    "start": "1675460",
    "end": "1682420"
  },
  {
    "text": "they are to a2? Well, you put a line here right\nbetween a2 and a3, OK?",
    "start": "1682420",
    "end": "1689590"
  },
  {
    "text": "When you put that line right\nbetween a2 and a3, everything on this side is closer to a3 and\neverything on this side is",
    "start": "1689590",
    "end": "1697720"
  },
  {
    "text": "closer to a2. So the answer is,\nin fact, simple, once you see the answer.",
    "start": "1697720",
    "end": "1704990"
  },
  {
    "text": "And the answer is, given these\npoints, we simply construct",
    "start": "1704990",
    "end": "1710610"
  },
  {
    "text": "bisectors between them, namely,\nbisectors with -- halfway between a1 and\na2, we call that b1.",
    "start": "1710610",
    "end": "1718810"
  },
  {
    "text": "Halfway between a2 and a3, we\ncall that b2, and those are the separators between\nthe regions, OK?",
    "start": "1718810",
    "end": "1726299"
  },
  {
    "text": "In other words, what we wind\nup doing is we define the",
    "start": "1726300",
    "end": "1733390"
  },
  {
    "text": "region R sub j, the set of\nthings which get mapped into a sub j as the region which is\nbounded by bj minus 1 is the",
    "start": "1733390",
    "end": "1746660"
  },
  {
    "text": "average of aj and aj minus 1,\nand bj is the average of aj",
    "start": "1746660",
    "end": "1753040"
  },
  {
    "text": "and aj plus 1, where I've\nalready ordered the points a sub j going from left\nto right, OK?",
    "start": "1753040",
    "end": "1763750"
  },
  {
    "text": "And that also tells us that the\nminimum mean square error",
    "start": "1763750",
    "end": "1769060"
  },
  {
    "text": "regions have got to\nbe intervals. There is no reason at all to\never pick regions which are",
    "start": "1769060",
    "end": "1775990"
  },
  {
    "text": "not intervals because, as soon\nas you start to solve this problem for any given set of\nrepresentation points, you",
    "start": "1775990",
    "end": "1784690"
  },
  {
    "text": "wind up with intervals. So if you ever think of using\nthings that are not intervals",
    "start": "1784690",
    "end": "1791150"
  },
  {
    "text": "for this mean square error\nproblem, then as soon as you look at this, you say, well,\naha, that can't be the best",
    "start": "1791150",
    "end": "1798630"
  },
  {
    "text": "thing to do. I will make my regions\nintervals. I will therefore simplify the\nwhole problem, and I'll also",
    "start": "1798630",
    "end": "1805770"
  },
  {
    "text": "improve it. And when you can both simplify\nthings and improve them at the same time, it usually is worth\ndoing it unless you're dealing",
    "start": "1805770",
    "end": "1813860"
  },
  {
    "text": "with standards bodies or\nsomething, and then all bets are off.",
    "start": "1813860",
    "end": "1819210"
  },
  {
    "text": "OK, so this one part of\nthe problem is easy. If we know what the\nrepresentation points are, we",
    "start": "1819210",
    "end": "1832640"
  },
  {
    "text": "can solve the problem. OK, we have a second problem,\nwhich is just",
    "start": "1832640",
    "end": "1840179"
  },
  {
    "text": "the opposite problem. Suppose then that somebody gives\nyou the interval regions",
    "start": "1840180",
    "end": "1846630"
  },
  {
    "text": "and asks you, OK, if I give you\nthese interval regions, how are you going to choose the\nrepresentation points to",
    "start": "1846630",
    "end": "1853240"
  },
  {
    "text": "minimize the mean\nsquare error? ",
    "start": "1853240",
    "end": "1860720"
  },
  {
    "text": "And analytically that's harder,\nbut conceptually, it's just about as easy.",
    "start": "1860720",
    "end": "1867740"
  },
  {
    "text": "And let's look at it and see\nif we can understand it. ",
    "start": "1867740",
    "end": "1872970"
  },
  {
    "text": "Somebody gives us this region\nhere, R sub 2, and says, OK,",
    "start": "1872970",
    "end": "1878240"
  },
  {
    "text": "where should we put\nthe point a sub 2? Well, anybody have any\nclues as to where",
    "start": "1878240",
    "end": "1885490"
  },
  {
    "text": "you want to put it? AUDIENCE: [INAUDIBLE] PROFESSOR: What? AUDIENCE: At the midpoint? PROFESSOR: At the midpoint.",
    "start": "1885490",
    "end": "1890980"
  },
  {
    "text": "It sounds like a reasonable\nthing, but it's not quite right. AUDIENCE: [INAUDIBLE]",
    "start": "1890980",
    "end": "1896330"
  },
  {
    "text": "PROFESSOR: What? AUDIENCE: [INAUDIBLE] PROFESSOR: It depends on the\nprobability density, yes.",
    "start": "1896330",
    "end": "1903100"
  },
  {
    "text": "If you have a probability\ndensity, which is highly weighted over on -- let's see,\nwas I talking about R2 or R3?",
    "start": "1903100",
    "end": "1912029"
  },
  {
    "text": "Well, it doesn't make\nany difference. We'll talk about R2. If I have a probability density,\nwhich looks like",
    "start": "1912030",
    "end": "1918399"
  },
  {
    "text": "this, then I want a2 to be\ncloser to the left-hand side",
    "start": "1918400",
    "end": "1926450"
  },
  {
    "text": "than to the right-hand side. I want it to be a little bit\nweighted towards here because that's more important\nin choosing",
    "start": "1926450",
    "end": "1933409"
  },
  {
    "text": "the mean square error.  OK, if you didn't have any of\nthis stuff, and I said how do",
    "start": "1933410",
    "end": "1941150"
  },
  {
    "text": "I choose this to minimize the\nmean square error, what's your",
    "start": "1941150",
    "end": "1946220"
  },
  {
    "text": "answer then? If I just have one region and\nI want to minimize the mean",
    "start": "1946220",
    "end": "1951850"
  },
  {
    "text": "square error, what do you do?  Anybody who doesn't know should\ngo back and study",
    "start": "1951850",
    "end": "1958920"
  },
  {
    "text": "elementary probability theory\nbecause this is almost day one of elementary probability theory\nwhen you start to study",
    "start": "1958920",
    "end": "1966760"
  },
  {
    "text": "what random variables\nare all about. And the next thing you start\nto look at is things like",
    "start": "1966760",
    "end": "1972410"
  },
  {
    "text": "variance and second moment. And what I'm asking you here\nis, how do you choose a2 in",
    "start": "1972410",
    "end": "1979530"
  },
  {
    "text": "order to minimize the second\nmoment of U, whatever it is in here, minus a2?",
    "start": "1979530",
    "end": "1985169"
  },
  {
    "text": "Yes? AUDIENCE: [INAUDIBLE] PROFESSOR: I want to take\nthe expectation of U",
    "start": "1985170",
    "end": "1990289"
  },
  {
    "text": "over the region R2. In other words, to say it more\ntechnically, I want to take",
    "start": "1990290",
    "end": "1996130"
  },
  {
    "text": "the expectation of the\nconditional random variable U, conditional on being\nin R2, OK?",
    "start": "1996130",
    "end": "2004260"
  },
  {
    "text": " And all of you could figure that\nout yourselves, if you",
    "start": "2004260",
    "end": "2011220"
  },
  {
    "text": "sat down quietly and thought\nabout it for five minutes. If you got frightened about it\nand started looking it up in a",
    "start": "2011220",
    "end": "2019720"
  },
  {
    "text": "book or something, it\nwould take you about two hours to do it. But if you just asked\nyourselves, how do I do it?",
    "start": "2019720",
    "end": "2027110"
  },
  {
    "text": "You'll come up with the right\nanswer very, very soon, OK?",
    "start": "2027110",
    "end": "2032900"
  },
  {
    "text": "So subproblem 2 says let's\nlook at the conditional",
    "start": "2032900",
    "end": "2038300"
  },
  {
    "text": "density of U in this\nregion R sub j. I'll call the conditional\ndensity -- well, the",
    "start": "2038300",
    "end": "2045780"
  },
  {
    "text": "conditional density, given that\nyou're in this region, is, in fact, the real density\ndivided by the probability of",
    "start": "2045780",
    "end": "2053990"
  },
  {
    "text": "being in that interval, OK? So we'll call that the\nconditional density.",
    "start": "2053990",
    "end": "2060270"
  },
  {
    "text": "And I'll let U of j be the\nrandom variable, which has this density.",
    "start": "2060270",
    "end": "2065790"
  },
  {
    "text": "In other words, this isn't\na random variable on the probability space that we\nstarted to deal with it.",
    "start": "2065790",
    "end": "2072320"
  },
  {
    "text": "It's sort of a phony\nrandom variable. But, in fact, it's the\nintuitive thing that",
    "start": "2072320",
    "end": "2078200"
  },
  {
    "text": "you think of, OK? In other words, if this is\nexactly what you were thinking of, you probably wouldn't have\ncalled this a separate random",
    "start": "2078200",
    "end": "2084450"
  },
  {
    "text": "variable, OK? So this is a random variable\nwith this density.",
    "start": "2084450",
    "end": "2090389"
  },
  {
    "text": "The expected value of U of j\nminus a of j quantity squared, as you all know, is sigma\nsquared of U of j plus the",
    "start": "2090390",
    "end": "2102150"
  },
  {
    "text": "expected value a U of j minus a\nsub j quantity squared, OK?",
    "start": "2102150",
    "end": "2108849"
  },
  {
    "text": "How do you minimize this? Well, you're stuck with this. This term, you minimize it by\nmaking a sub j equal to the",
    "start": "2108850",
    "end": "2117070"
  },
  {
    "text": "expected value of\nU of j, which is exactly what you said. Namely, you set a of j to be the\nconditional mean of U of j",
    "start": "2117070",
    "end": "2129070"
  },
  {
    "text": "conditional on being\nin the center. It's harder to say\nmathematically than it is to see it.",
    "start": "2129070",
    "end": "2135090"
  },
  {
    "text": " But, in fact, the intuitive\nidea is exactly right.",
    "start": "2135090",
    "end": "2141280"
  },
  {
    "text": "Namely, you condition your\nrandom variable on being in that interval, and then what you\nwant to do is choose the",
    "start": "2141280",
    "end": "2147680"
  },
  {
    "text": "mean within that interval, which\nis exactly the sort of thing we were thinking\nabout here.",
    "start": "2147680",
    "end": "2153809"
  },
  {
    "text": "When I drew this curve here, if\nI scale it, this, in fact, is the density of\nu conditional on",
    "start": "2153810",
    "end": "2161140"
  },
  {
    "text": "being in R sub j. And now all I'm trying to do\nis choose the point here, which happens to be\nthe mean which",
    "start": "2161140",
    "end": "2167619"
  },
  {
    "text": "minimizes this second moment. The second moment, in fact,\nis this mean square error.",
    "start": "2167620",
    "end": "2174869"
  },
  {
    "text": "So, bingo! That's the second problem.",
    "start": "2174870",
    "end": "2180400"
  },
  {
    "text": "Well, how do you put the\ntwo problems together?  Well, you can put it together\nin two ways.",
    "start": "2180400",
    "end": "2188259"
  },
  {
    "text": "One of them is to say, OK, well\nthen, clearly an optimal scalar quantizer has to\nsatisfy both of these",
    "start": "2188260",
    "end": "2195540"
  },
  {
    "text": "conditions. Namely, the endpoints of the\nregions have to be the midpoints of the representation\npoints, and the",
    "start": "2195540",
    "end": "2203390"
  },
  {
    "text": "representation points have to\nbe the conditional means of the points within a region\nthat you start with.",
    "start": "2203390",
    "end": "2216790"
  },
  {
    "text": "And then you say, OK, how\ndo I solve that problem? Well, if you're a computer\nscientist, and sometimes it's",
    "start": "2216790",
    "end": "2222750"
  },
  {
    "text": "good to be a computer scientist,\nyou say, well, I don't know how to solve the\nproblem, but generating an",
    "start": "2222750",
    "end": "2228780"
  },
  {
    "text": "algorithm to solve the problem\nis almost trivial. I start out with some\narbitrary set of",
    "start": "2228780",
    "end": "2236040"
  },
  {
    "text": "representation points. That should be a capital M\nbecause that's the number of",
    "start": "2236040",
    "end": "2242220"
  },
  {
    "text": "points I'm allowed to use. Then the next step in the\nalgorithm is I choose these",
    "start": "2242220",
    "end": "2249330"
  },
  {
    "text": "separation points to be b sub j\nis the midpoint between the a's for each of these values.",
    "start": "2249330",
    "end": "2257120"
  },
  {
    "text": "Then as soon as I get these\nmidpoints, I have a set of intervals, and my next step is\nto say set a sub j is equal to",
    "start": "2257120",
    "end": "2265200"
  },
  {
    "text": "the expected value of this\nconditional random variable U of j where R sub j is now this\nnew interval for 1 less than",
    "start": "2265200",
    "end": "2274530"
  },
  {
    "text": "or equal to j less than\nor equal to M minus 1. This means it's open\non the left side.",
    "start": "2274530",
    "end": "2281819"
  },
  {
    "text": "This means it's closed on the\nright side, and since it's a probability density, it doesn't\nmake any difference",
    "start": "2281820",
    "end": "2287140"
  },
  {
    "text": "what it is. I just wanted to give you an\nexplicit rule for what to do with probability zero when you\nhappen to wind up on that",
    "start": "2287140",
    "end": "2295640"
  },
  {
    "text": "special point. OK, and then you iterate on\n2 and 3 until you get a",
    "start": "2295640",
    "end": "2302800"
  },
  {
    "text": "negligible improvement. And then you ask, of course,\nwell, if I got a negligible",
    "start": "2302800",
    "end": "2307880"
  },
  {
    "text": "improvement this time, maybe\nI'll get a bigger improvement next time. And that, of course, is true.",
    "start": "2307880",
    "end": "2314670"
  },
  {
    "text": "And you then say, well, it's\npossible that after I can't",
    "start": "2314670",
    "end": "2320700"
  },
  {
    "text": "get any improvement anymore,\nI still don't have the optimal solution. And that, of course,\nis true also.",
    "start": "2320700",
    "end": "2326780"
  },
  {
    "text": "But at least you have an\nalgorithm which makes sense and which, each time you try\nit, you do a little better",
    "start": "2326780",
    "end": "2333000"
  },
  {
    "text": "than you did before. Now, this mean square error for\nany choice of regions and",
    "start": "2333000",
    "end": "2340030"
  },
  {
    "text": "any choice of representation\npoints is going to be nonnegative because\nit's an expected",
    "start": "2340030",
    "end": "2345640"
  },
  {
    "text": "value of squared terms. The algorithm is nonincreasing\nwith iterations.",
    "start": "2345640",
    "end": "2353040"
  },
  {
    "text": "In other words, the algorithm\nis going down all the time. So you have zero down here.",
    "start": "2353040",
    "end": "2359480"
  },
  {
    "text": "You have an algorithm which is\nmarching you down toward zero. It's not going to get to zero,\nbut it has to reach a minimum.",
    "start": "2359480",
    "end": "2370080"
  },
  {
    "text": "That's a major theorem in\nanalysis, but you don't need any major theorems in analysis\nto see this.",
    "start": "2370080",
    "end": "2375710"
  },
  {
    "text": "You have a set of numbers, which\nare decreasing all the time, and they're bounded\nunderneath.",
    "start": "2375710",
    "end": "2381390"
  },
  {
    "text": "After awhile, you have to get\nto some point, and you don't go any further. So it has a limit.",
    "start": "2381390",
    "end": "2388609"
  },
  {
    "text": "So that's nice. So you have an algorithm\nwhich has to converge. It can't keep on going.",
    "start": "2388610",
    "end": "2394870"
  },
  {
    "text": "Well, it can keep on going\nforever, but it keeps going on forever with smaller and\nsmaller improvements.",
    "start": "2394870",
    "end": "2400540"
  },
  {
    "text": "So eventually, you might as well\nstop because you're not getting anywhere.",
    "start": "2400540",
    "end": "2408150"
  },
  {
    "text": "OK, well, those conditions\nthat we stated, the way a mathematician would say this, is\nthese Lloyd-Max conditions",
    "start": "2408150",
    "end": "2415790"
  },
  {
    "text": "are necessary but not\nsufficient, OK? In other words, any solution\nto this problem that we're",
    "start": "2415790",
    "end": "2421720"
  },
  {
    "text": "looking at has to have\nthe property that the representation points are the\nconditional means of the",
    "start": "2421720",
    "end": "2430250"
  },
  {
    "text": "intervals and the interval\nboundaries are the midpoints between the representation\npoints.",
    "start": "2430250",
    "end": "2437410"
  },
  {
    "text": "But that isn't necessarily\nenough. Here's a simple example of\nwhere it's not enough.",
    "start": "2437410",
    "end": "2442950"
  },
  {
    "text": "Suppose you have a probability\ndensity, which is running along almost zero, jumps up to\na big value, almost zero,",
    "start": "2442950",
    "end": "2450670"
  },
  {
    "text": "jumps up to a big value, jumps\nup to a big value. This intentionally is wider than\nthis and wider than this.",
    "start": "2450670",
    "end": "2459970"
  },
  {
    "text": "In other words, there's a lot\nmore probability over here than there is here\nor there is here.",
    "start": "2459970",
    "end": "2466820"
  },
  {
    "text": "And you're unlucky, and you\nstart out somehow with points",
    "start": "2466820",
    "end": "2471840"
  },
  {
    "text": "like a1 and a2, and you start\nout with regions like R1 --",
    "start": "2471840",
    "end": "2478460"
  },
  {
    "text": "well, yeah, you want to start\nout with points, a1 and a2. So you start out with a point\na1, which is way over here,",
    "start": "2478460",
    "end": "2486280"
  },
  {
    "text": "and a point a2, which is\nnot too far over here. And your algorithm then says\npick the midpoint b1.",
    "start": "2486280",
    "end": "2493490"
  },
  {
    "text": "Here the algorithm is\nparticularly simple because, since we're only using two\nregions, all you need is one",
    "start": "2493490",
    "end": "2500380"
  },
  {
    "text": "separator point. So we wind up with b1 here,\nwhich is halfway",
    "start": "2500380",
    "end": "2505440"
  },
  {
    "text": "between a1 and a2. a1 happens to be right in the\nmiddle of that big interval",
    "start": "2505440",
    "end": "2510789"
  },
  {
    "text": "there, and there's hardly\nanything else here. So a1 just stays there as the\nconditional mean, given that",
    "start": "2510790",
    "end": "2519100"
  },
  {
    "text": "you're on this side. And a2 stays as the conditional\nmean, given that",
    "start": "2519100",
    "end": "2525070"
  },
  {
    "text": "you're over here, which means\nthat a2 is a little closer this big region than it is\nto this region, but a2 is",
    "start": "2525070",
    "end": "2532010"
  },
  {
    "text": "perfectly happy there. And we go back and\nwe iterate again. And we haven't changed b1, we\nhaven't changed a1, we haven't",
    "start": "2532010",
    "end": "2541530"
  },
  {
    "text": "changed a2, and therefore, the\nalgorithm sticks there. Well, that's not surprising.",
    "start": "2541530",
    "end": "2547740"
  },
  {
    "text": "I mean, you know that there are\nmany problems where you try to minimize things by\ndifferentiating or all the",
    "start": "2547740",
    "end": "2553569"
  },
  {
    "text": "different tricks you have for\nminimizing things, and you very often find local minima.",
    "start": "2553570",
    "end": "2560839"
  },
  {
    "text": "People call algorithms like this\nhill-climbing algorithms. They should call them\nvalley-finding algorithms",
    "start": "2560840",
    "end": "2566569"
  },
  {
    "text": "because we're sitting\nat someplace. We try to find a better place. So we wind up moving\ndown into the",
    "start": "2566570",
    "end": "2573240"
  },
  {
    "text": "valley further and further. Of course, if it's a real\ngeographical area, you finally",
    "start": "2573240",
    "end": "2578780"
  },
  {
    "text": "wind up at the river. You then move down the river,\nyou wind up in the ocean and all that. But let's forgot about that.",
    "start": "2578780",
    "end": "2585290"
  },
  {
    "text": "Let's just assume that there\naren't rivers or anything. That we just have some arbitrary\ngeographical area.",
    "start": "2585290",
    "end": "2591980"
  },
  {
    "text": "We wind up in the bottom of a\nvalley, and we say, OK, are we at the minimum or not?",
    "start": "2591980",
    "end": "2598070"
  },
  {
    "text": "Well, with hill climbing, you\ncan take a pair of binoculars, and you look around to see if\nthere's any higher peak",
    "start": "2598070",
    "end": "2603330"
  },
  {
    "text": "someplace else. With valley seeking,\nyou can't do that. We're sitting there at the\nbottom of the valley, and we",
    "start": "2603330",
    "end": "2609780"
  },
  {
    "text": "have no idea whether there's a\nbetter valley somewhere else or not, OK?",
    "start": "2609780",
    "end": "2615970"
  },
  {
    "text": "So that's the trouble with\nhill-climbing algorithms or valley-seeking algorithms.",
    "start": "2615970",
    "end": "2621700"
  },
  {
    "text": "And that's exactly what\nthis algorithm does. This is called the Lloyd-Max\nalgorithm because a guy by the",
    "start": "2621700",
    "end": "2628660"
  },
  {
    "text": "name of Lloyd at Bell Labs\ndiscovered it, I think in '57.",
    "start": "2628660",
    "end": "2633819"
  },
  {
    "text": "A guy by the name of Joel\nMax discovered it again. He was at MIT in 1960, and\nbecause all the information",
    "start": "2633820",
    "end": "2641770"
  },
  {
    "text": "theorists around were at MIT at\nthat time, they called it the Max algorithm\nfor many years.",
    "start": "2641770",
    "end": "2646990"
  },
  {
    "text": "And then somebody discovered\nthat Lloyd had done it three years earlier. Lloyd never even published it.",
    "start": "2646990",
    "end": "2652300"
  },
  {
    "text": "So it became the Lloyd-Max\nalgorithm. And now there's somebody else\nwho did it even earlier, I",
    "start": "2652300",
    "end": "2657520"
  },
  {
    "text": "think, so we should probably\ntake Max's name off it. But anyway, sometime when I\nrevise the notes, I will give",
    "start": "2657520",
    "end": "2667210"
  },
  {
    "text": "the whole story of that. But I hope you see that\nthis algorithm is no big deal anyway.",
    "start": "2667210",
    "end": "2674400"
  },
  {
    "text": "It was just people fortunately\nlooking at the question at the right time before too many other\npeople had looked at it.",
    "start": "2674400",
    "end": "2681170"
  },
  {
    "text": "And Max unfortunately\nlooked at it. He was in a valley. He didn't see all the other\npeople had looked at it.",
    "start": "2681170",
    "end": "2687900"
  },
  {
    "text": "But he became famous. He had his moment of time and\nthen sunk gradually into",
    "start": "2687900",
    "end": "2693839"
  },
  {
    "text": "oblivion except when once\nin awhile we call it the",
    "start": "2693840",
    "end": "2699040"
  },
  {
    "text": "Lloyd-Max algorithm. Most people call it the Lloyd\nalgorithm, though, and I really should also.",
    "start": "2699040",
    "end": "2705710"
  },
  {
    "text": "OK, vector quantization:\nWe talked about vector quantization a little bit.",
    "start": "2705710",
    "end": "2711610"
  },
  {
    "text": "It's the idea of segmenting the\nsource outputs before you try to do the encoding.",
    "start": "2711610",
    "end": "2719330"
  },
  {
    "text": "So we ask is scalar quantization\ngoing to be the right approach? To answer that question, we want\nto look at quantizing two",
    "start": "2719330",
    "end": "2727080"
  },
  {
    "text": "sample values jointly and\ndrawing pictures. Incidentally, what's the\nsimplest way of quantizing",
    "start": "2727080",
    "end": "2735100"
  },
  {
    "text": "that you can think of? And what do people who do simple\nthings call quantizers?",
    "start": "2735100",
    "end": "2740440"
  },
  {
    "text": " Ever hear of an\nanalog-to-digital converter?",
    "start": "2740440",
    "end": "2748360"
  },
  {
    "text": "That's what a quantizer is. And an analog-to-digital\nconverter, the way that everybody does it, is scalar.",
    "start": "2748360",
    "end": "2756890"
  },
  {
    "text": "So that says that either the\npeople who implement things are very stupid, or there's\nsomething pretty good about",
    "start": "2756890",
    "end": "2763400"
  },
  {
    "text": "scalar quantization. But anyway, since this is a\ncourse trying to find better",
    "start": "2763400",
    "end": "2769190"
  },
  {
    "text": "ways of doing things, we ought\nto investigate whether it is better to use vector\nquantizers and",
    "start": "2769190",
    "end": "2776000"
  },
  {
    "text": "what they result in. OK, well, the first thing that\nwe can do is look at quantizing two samples.",
    "start": "2776000",
    "end": "2783359"
  },
  {
    "text": "In other words, when you want\nto generalize a problem to vectors, I find it better to\ngeneralize it to two vectors",
    "start": "2783360",
    "end": "2791050"
  },
  {
    "text": "first and see what\ngoes on there. And one possible approach is to\nuse a rectangular grid of",
    "start": "2791050",
    "end": "2797720"
  },
  {
    "text": "quantization regions. And as I'll show you in the\nnext slide, that really is",
    "start": "2797720",
    "end": "2803740"
  },
  {
    "text": "just a camouflaged scalar\nquantizer again. So you have a two-dimensional\nregion corresponding to two",
    "start": "2803740",
    "end": "2812410"
  },
  {
    "text": "real samples. So you've got two real\nnumbers, U1 and U2.",
    "start": "2812410",
    "end": "2817460"
  },
  {
    "text": "You're trying to map them into\na finite set of sample values",
    "start": "2817460",
    "end": "2823080"
  },
  {
    "text": "of representation points. Since you're going to be\ninterested in the distortion",
    "start": "2823080",
    "end": "2829760"
  },
  {
    "text": "between U1 and U2, between the\nvector U1, U2, and your",
    "start": "2829760",
    "end": "2836370"
  },
  {
    "text": "representation vector, a1,\na2, these points, these",
    "start": "2836370",
    "end": "2843680"
  },
  {
    "text": "representation points, are going\nto be two-dimensional points also. So if you start out by saying\nlet's put these points on a",
    "start": "2843680",
    "end": "2851970"
  },
  {
    "text": "rectangular grid, well, we can\nthen look at it, and we say, well, given the points, how\ndo we choose the regions?",
    "start": "2851970",
    "end": "2859559"
  },
  {
    "text": " You see, it's exactly\nthe same problem",
    "start": "2859560",
    "end": "2864710"
  },
  {
    "text": "that you solved before. If I give you the points and\nthen I ask you, well, if we",
    "start": "2864710",
    "end": "2872440"
  },
  {
    "text": "get a vector U1, U2 that's\nthere, what do we map it to?",
    "start": "2872440",
    "end": "2878819"
  },
  {
    "text": "Well, we map it to the closest\nthing, which means if we want to find these regions, we set\nup these perpendicular",
    "start": "2878820",
    "end": "2885569"
  },
  {
    "text": "bisectors halfway between the\nrepresentation points. So all of this is looking very\nrectangular now because we",
    "start": "2885570",
    "end": "2893250"
  },
  {
    "text": "started out with these\npoints rectangular. These lines are rectangular, and\nnow I say, well, is this",
    "start": "2893250",
    "end": "2899839"
  },
  {
    "text": "really any different from\na scalar quantizer? And, of course, it isn't because\nfor this particular",
    "start": "2899840",
    "end": "2906740"
  },
  {
    "text": "vector quantizer, I can first\nask the question, OK, here's U1, which is something\nin this direction.",
    "start": "2906740",
    "end": "2917520"
  },
  {
    "text": "How do I find regions\nfor that? Well, for U1, I just establish\nthese regions here.",
    "start": "2917520",
    "end": "2924090"
  },
  {
    "text": "And then I say, OK, let's\nlook at U2 next. And then I look at things in\nthis direction, and I wind up",
    "start": "2924090",
    "end": "2931349"
  },
  {
    "text": "in saying, OK, that's all\nthere is to the problem. I have a scalar quantizer\nagain.",
    "start": "2931350",
    "end": "2937310"
  },
  {
    "text": "Everything that I said\nbefore works. Now if you're a theoretician,\nyou go one step further, and",
    "start": "2937310",
    "end": "2944040"
  },
  {
    "text": "you say, what this tells me is\nthat vector quantizers cannot",
    "start": "2944040",
    "end": "2950160"
  },
  {
    "text": "be any worse than scalar\nquantizers. Because, in fact, a vector\nquantizer has a -- or at least",
    "start": "2950160",
    "end": "2959360"
  },
  {
    "text": "a vector quantizer in two\ndimensions -- has a scalar quantizer -- has two scalar quantizers\nas a special case.",
    "start": "2959360",
    "end": "2968030"
  },
  {
    "text": "And therefore, the amount of\nsquare distortion that I wind up with in the vector case,\nI can always get that --",
    "start": "2968030",
    "end": "2977599"
  },
  {
    "text": " whatever I can do with the\nscalar quantizer, I can do",
    "start": "2977600",
    "end": "2984940"
  },
  {
    "text": "just as well with a vector\nquantizer by choosing it, in fact, to be rectangular\nlike this.",
    "start": "2984940",
    "end": "2991770"
  },
  {
    "text": "And you can also get some\nintuitive ideas that if instead of having IID random\nvariables, if U1 and U2 are",
    "start": "2991770",
    "end": "3000770"
  },
  {
    "text": "very heavily correlated somehow\nso that they're very close together, I mean, you\nsort of get an engineering",
    "start": "3000770",
    "end": "3006859"
  },
  {
    "text": "view of what you want to do. You want to take this\nrectangular picture here. You want to skew it\naround that way.",
    "start": "3006860",
    "end": "3014300"
  },
  {
    "text": "And you want to have lots of\npoints going this way and not too many points going this way\nbecause almost everything is",
    "start": "3014300",
    "end": "3020010"
  },
  {
    "text": "going this way, and\nthere's not much going on in that direction. So you got some pictures\nof what you want to do.",
    "start": "3020010",
    "end": "3030470"
  },
  {
    "text": "These regions here, a little bit\nof terminology, are called",
    "start": "3030470",
    "end": "3035700"
  },
  {
    "text": "Voronoi regions. Anytime you start out with a\nset of points and you put",
    "start": "3035700",
    "end": "3042680"
  },
  {
    "text": "perpendicular bisectors in\nbetween those points, halfway between the points, you call the\nregions that you wind up",
    "start": "3042680",
    "end": "3049550"
  },
  {
    "text": "with Voronoi regions. So, in fact, part of this\nLloyd-Max algorithm,",
    "start": "3049550",
    "end": "3058000"
  },
  {
    "text": "generalized at two dimensions,\nsays given any set of points,",
    "start": "3058000",
    "end": "3063800"
  },
  {
    "text": "the regions ought to be the\nVoronoi regions for them. So that's that first subproblem\ngeneralized at two",
    "start": "3063800",
    "end": "3070190"
  },
  {
    "text": "dimensions. ",
    "start": "3070190",
    "end": "3075920"
  },
  {
    "text": "And if you have an arbitrary\nset of points, the Voronoi regions look sort of\nlike this, OK?",
    "start": "3075920",
    "end": "3084580"
  },
  {
    "text": "And I've only drawn it for the\ncenter point because, well, there aren't enough points to\ndo anything more than that.",
    "start": "3084580",
    "end": "3090859"
  },
  {
    "text": "So anything in this region gets\nmapped into this point. Anything in this semi-infinite\nregion gets mapped into this",
    "start": "3090860",
    "end": "3098030"
  },
  {
    "text": "point and so forth. So even in two dimensions,\nthis part of the",
    "start": "3098030",
    "end": "3103510"
  },
  {
    "text": "algorithm is simple. When you start out with the\nregions, with almost the same",
    "start": "3103510",
    "end": "3109810"
  },
  {
    "text": "argument that we used before,\nyou can see that the mean",
    "start": "3109810",
    "end": "3115340"
  },
  {
    "text": "square error is going to be\nminimized by using conditional means for the representation\npoints.",
    "start": "3115340",
    "end": "3123510"
  },
  {
    "text": "I mean, that's done in\ndetail in the notes. It's just algebra to do that.",
    "start": "3123510",
    "end": "3129660"
  },
  {
    "text": "It's sort of intuitive that\nthe same thing ought to happen, and in fact, it does.",
    "start": "3129660",
    "end": "3134940"
  },
  {
    "text": "So you can still find\na local minimum by this Lloyd-Max algorithm.",
    "start": "3134940",
    "end": "3142440"
  },
  {
    "text": "If you're unhappy with the\nfact that the Lloyd-Max algorithm doesn't always work\nin one dimension, be content",
    "start": "3142440",
    "end": "3150020"
  },
  {
    "text": "with the fact that it's far\nworse in two dimensions, and it gets worse and worse as you\ngo to higher numbers of",
    "start": "3150020",
    "end": "3155329"
  },
  {
    "text": "dimensions. So it is a local minimum,\nbut not",
    "start": "3155330",
    "end": "3161910"
  },
  {
    "text": "necessarily the best thing. OK, well, about that time, and\nlet's go forward for maybe 10",
    "start": "3161910",
    "end": "3170490"
  },
  {
    "text": "years from 1957 and '60 when\npeople were inventing the Lloyd-Max algorithm and where\nthey thought that quantization",
    "start": "3170490",
    "end": "3177560"
  },
  {
    "text": "was a really neat academic\nproblem, and many people were writing theses on it and having\nlots of fun with it.",
    "start": "3177560",
    "end": "3184950"
  },
  {
    "text": "And then eventually, they\nstarted to realize that when you try to solve that problem\nand find the minimum, it",
    "start": "3184950",
    "end": "3191390"
  },
  {
    "text": "really is just a very\nugly problem. At least it looks like a very\nugly problem with everything",
    "start": "3191390",
    "end": "3197180"
  },
  {
    "text": "that anybody knows after\nhaving worked on it for a very long time. So not many people work\non this anymore.",
    "start": "3197180",
    "end": "3204380"
  },
  {
    "text": "So we stop and say, well, we\nreally don't want to go too far on this because it's ugly.",
    "start": "3204380",
    "end": "3209640"
  },
  {
    "text": "But then we stop and think. I mean, anytime you get stuck\non a problem, you ought to stop and ask, well, am\nI really looking",
    "start": "3209640",
    "end": "3216640"
  },
  {
    "text": "at the right problem?  Now why am I or why am I not\nlooking at the right problem?",
    "start": "3216640",
    "end": "3225770"
  },
  {
    "text": "And remember where\nwe started off.  We started off with this kind\nof layered solution, which",
    "start": "3225770",
    "end": "3234570"
  },
  {
    "text": "said we were going to quantize\nthese things into a finite alphabet and then\nwe were going to",
    "start": "3234570",
    "end": "3240200"
  },
  {
    "text": "discrete code them, OK? And here what we've been\ndoing for awhile,",
    "start": "3240200",
    "end": "3246890"
  },
  {
    "text": "and none of you objected. Of course, it's hard to object\nat 9:30 in the morning.",
    "start": "3246890",
    "end": "3252800"
  },
  {
    "text": "You just listen and you -- but\nyou should have objected. You should have said why in hell\nam I choosing the number",
    "start": "3252800",
    "end": "3260230"
  },
  {
    "text": "of quantization levels\nto minimize over? What should I be minimizing\nover?",
    "start": "3260230",
    "end": "3266830"
  },
  {
    "text": "I should be trying to find the\nminimum mean square error conditional on the entropy\nof this output alphabet.",
    "start": "3266830",
    "end": "3277050"
  },
  {
    "text": "Because the entropy of the\noutput alphabet is what determines what I can accomplish\nby discrete coding.",
    "start": "3277050",
    "end": "3285020"
  },
  {
    "text": "That's a slightly phony problem\nbecause I'm insisting, now at least to start with, that\nthe quantizer is a scalar",
    "start": "3285020",
    "end": "3296360"
  },
  {
    "text": "quantizer, and by using coding\nhere, I'm allowing memory in the coding process.",
    "start": "3296360",
    "end": "3303170"
  },
  {
    "text": "But it's not that phony\nbecause, in fact, this quantization job is a real\nmess, and this job",
    "start": "3303170",
    "end": "3310680"
  },
  {
    "text": "is very, very easy. And, in fact, when you think\nabout it a little bit, you",
    "start": "3310680",
    "end": "3315930"
  },
  {
    "text": "say, OK, how do people really\ndo this if they're trying to",
    "start": "3315930",
    "end": "3323210"
  },
  {
    "text": "implement things? And how would you go about\nimplementing something like",
    "start": "3323210",
    "end": "3328230"
  },
  {
    "text": "this entire problem that\nwe're talking about? What would you do if you\nhad to implement it?",
    "start": "3328230",
    "end": "3334789"
  },
  {
    "text": " Well, you're probably afraid to\nsay it, but you would use",
    "start": "3334790",
    "end": "3341940"
  },
  {
    "text": "digital signal processing,\nwouldn't you? I mean, the first thing you\nwould try to do is to get rid",
    "start": "3341940",
    "end": "3347550"
  },
  {
    "text": "of all these analog values, and\nyou would try to turn them",
    "start": "3347550",
    "end": "3352790"
  },
  {
    "text": "into discrete values, so that\nyou would really, after you somehow find this sequence of\nnumbers here, you would go",
    "start": "3352790",
    "end": "3362200"
  },
  {
    "text": "through a quantizer and quantize\nthese numbers very, very finely. You would think of them as real\nnumbers, and then you",
    "start": "3362200",
    "end": "3371809"
  },
  {
    "text": "would do some kind of discrete\ncoding, and you would wind up with something. And then you would say, ah, I\nhave quantized these things",
    "start": "3371810",
    "end": "3380820"
  },
  {
    "text": "very, very finely. And we'll see that when you\nquantize it very, very finely, what you're going to wind up\nwith, which is almost optimal,",
    "start": "3380820",
    "end": "3390310"
  },
  {
    "text": "is a uniform scalar quantizer,\nwhich is just what a garden-variety analog-to-digital\nconverter",
    "start": "3390310",
    "end": "3399059"
  },
  {
    "text": "does for you, OK? But then you say, aha!",
    "start": "3399060",
    "end": "3404490"
  },
  {
    "text": "What I can't do at that moment,\nI don't have enough bits to represent what this very\nfine quantizer has done.",
    "start": "3404490",
    "end": "3412220"
  },
  {
    "text": "So then I think of this\nquantization as real numbers. I go through the same process\nagain, and I think of then",
    "start": "3412220",
    "end": "3419500"
  },
  {
    "text": "quantizing the real numbers\nto the number of bits I really want.",
    "start": "3419500",
    "end": "3424710"
  },
  {
    "text": "Anybody catch what\nI just said? I'm saying you do this\nin two steps.",
    "start": "3424710",
    "end": "3431020"
  },
  {
    "text": "The first step is a very fine\nquantization, strictly for implementation purposes and\nfor no other reason.",
    "start": "3431020",
    "end": "3440440"
  },
  {
    "text": "And at that point, you\nhave bits to process. You do digital-signal\nprocessing, but you think of",
    "start": "3440440",
    "end": "3447880"
  },
  {
    "text": "those bits as representing\nnumbers, OK? In other words, as far as your\nthoughts are concerned, you're",
    "start": "3447880",
    "end": "3454430"
  },
  {
    "text": "not dealing with the\nquantization errors that occurred here at all. You're just thinking\nof real numbers.",
    "start": "3454430",
    "end": "3460730"
  },
  {
    "text": "And at that point, you try to\ndesign conceptually what it is you want to do in this\nprocess of quantizing",
    "start": "3460730",
    "end": "3467020"
  },
  {
    "text": "and discrete coding. And you then go back to looking\nat these things as",
    "start": "3467020",
    "end": "3472799"
  },
  {
    "text": "numbers again, and you quantize\nthem again, and you discrete encode them again in\nwhatever way makes sense.",
    "start": "3472800",
    "end": "3479560"
  },
  {
    "text": "So you do one thing strictly for\nimplementation purposes. You do the other thing for\nconceptual purposes.",
    "start": "3479560",
    "end": "3485600"
  },
  {
    "text": "Then you put them together into\nsomething that works. And that's the way engineers\noperate all the time, I think.",
    "start": "3485600",
    "end": "3492390"
  },
  {
    "text": "At least they did when I was\nmore active doing real engineering.",
    "start": "3492390",
    "end": "3497910"
  },
  {
    "text": "OK, so that's that.",
    "start": "3497910",
    "end": "3503530"
  },
  {
    "text": "But anyway, it says finding a\nminimum mean square error quantizer for fixed M isn't the\nright problem that we're",
    "start": "3503530",
    "end": "3510620"
  },
  {
    "text": "interested in. If you're going to have\nquantization followed by discrete coding, the quantizer\nshould minimize mean square",
    "start": "3510620",
    "end": "3518150"
  },
  {
    "text": "error for fixed representation\npoint entropy.",
    "start": "3518150",
    "end": "3523460"
  },
  {
    "text": "In other words, I'd\nwant to find these representation points. It's important what the\nnumerical values of the",
    "start": "3523460",
    "end": "3529720"
  },
  {
    "text": "representation points are for\nmean square error, but I'm not interested in how many\nof them I have.",
    "start": "3529720",
    "end": "3536480"
  },
  {
    "text": "What I'm interested in is\nthe entropy of them. OK, so the quantizer should\nminimize mean square error for",
    "start": "3536480",
    "end": "3544900"
  },
  {
    "text": "a fixed representation\npoint entropy. I would like some algorithm,\nwhich goes through and changes",
    "start": "3544900",
    "end": "3552570"
  },
  {
    "text": "my representation points,\nincluding perhaps changing the number of representation\npoints as a",
    "start": "3552570",
    "end": "3558960"
  },
  {
    "text": "way of reducing entropy. OK, sometimes you can get more\nrepresentation points by",
    "start": "3558960",
    "end": "3565240"
  },
  {
    "text": "having them out where there's\nvirtually no probability, and therefore they don't happen very\noften, but when they do",
    "start": "3565240",
    "end": "3572460"
  },
  {
    "text": "happen, they sure save\nyou an awful lot of mean square error. So you can wind up with things\nusing many, many more",
    "start": "3572460",
    "end": "3580319"
  },
  {
    "text": "quantization points than you\nwould think you would want because that's the optimal\nthing to do.",
    "start": "3580320",
    "end": "3588270"
  },
  {
    "text": "OK, when you're given the\nregions, if we try to say what happens to the Lloyd-Max\nalgorithm then, the",
    "start": "3588270",
    "end": "3596140"
  },
  {
    "text": "representation points\nshould still be the conditional means. Why?",
    "start": "3596140",
    "end": "3601670"
  },
  {
    "text": " Anybody figure out why we want\nto solve the problem that way?",
    "start": "3601670",
    "end": "3611730"
  },
  {
    "text": "If I've already figured out what\nthe region should the --",
    "start": "3611730",
    "end": "3618800"
  },
  {
    "text": "well, before, when I told you\nwhat the regions were, you told me that you wanted to make\nthe representation points",
    "start": "3618800",
    "end": "3627250"
  },
  {
    "text": "the conditional means. Now if I make the representation\npoints something other than the\nconditional means, what's",
    "start": "3627250",
    "end": "3636350"
  },
  {
    "text": "going to happen to\nthe entropy? ",
    "start": "3636350",
    "end": "3641840"
  },
  {
    "text": "The entropy stays the same. The entropy has nothing\nto do with what you call these symbols.",
    "start": "3641840",
    "end": "3648260"
  },
  {
    "text": "I can move where they are, but\nthey still have the same probability because they still\noccur whenever you wind up in",
    "start": "3648260",
    "end": "3656800"
  },
  {
    "text": "that region. And therefore, the entropy\ndoesn't change, and therefore,",
    "start": "3656800",
    "end": "3662630"
  },
  {
    "text": "the same rule holds. But now the peculiar thing is\nyou don't want to make the",
    "start": "3662630",
    "end": "3670060"
  },
  {
    "text": "representation regions Voronoi\nregions anymore. In other words, sometimes you\nwant to make a region much",
    "start": "3670060",
    "end": "3677289"
  },
  {
    "text": "closer to one point than\nto the other point. And why do you want\nto do that?",
    "start": "3677290",
    "end": "3682880"
  },
  {
    "text": "Because you'd like to make these\nprobabilities of the points as unequal as you can\nbecause you're trying to",
    "start": "3682880",
    "end": "3688849"
  },
  {
    "text": "reduce entropy. And you can reduce entropy by\nmaking things have different probabilities.",
    "start": "3688850",
    "end": "3696230"
  },
  {
    "text": "OK, so that's where we\nwind up with that. I would like to say there's\na nice algorithm",
    "start": "3696230",
    "end": "3703140"
  },
  {
    "text": "to solve this problem. There isn't. It's an incredibly\nugly problem.",
    "start": "3703140",
    "end": "3709059"
  },
  {
    "text": "You might think it makes sense\nto use a Lagrange multiplier approach and try to minimize\nsome linear combination of",
    "start": "3709060",
    "end": "3716100"
  },
  {
    "text": "entropy and mean square error. I've never been able\nto make it work.",
    "start": "3716100",
    "end": "3723710"
  },
  {
    "text": "So anyway, let's go on.",
    "start": "3723710",
    "end": "3728859"
  },
  {
    "text": " When we want to look at a\nhigh-rate quantizer, which is",
    "start": "3728860",
    "end": "3737220"
  },
  {
    "text": "what we very often want, you\ncan do a very simple",
    "start": "3737220",
    "end": "3742349"
  },
  {
    "text": "approximation. And the simple approximation\nmakes the problem much easier,",
    "start": "3742350",
    "end": "3748740"
  },
  {
    "text": "and it gives you an\nadded benefit. There's something called\ndifferential entropy.",
    "start": "3748740",
    "end": "3754130"
  },
  {
    "text": "And differential entropy is the\nsame as ordinary entropy, except instead of dealing with\nprobabilities, it deals with",
    "start": "3754130",
    "end": "3762300"
  },
  {
    "text": "probability densities. And you look at this, and you\nsay, well, that's virtually",
    "start": "3762300",
    "end": "3769030"
  },
  {
    "text": "the same thing, and it looks\nlike the same thing. And to most physicists, most\nphysicists look at something",
    "start": "3769030",
    "end": "3776020"
  },
  {
    "text": "like this, and physicists who\nare into statistical mechanics say, oh, of course that's\nthe same thing.",
    "start": "3776020",
    "end": "3781990"
  },
  {
    "text": "There's no fundamental\ndifference between a differential entropy\nand a real entropy.",
    "start": "3781990",
    "end": "3788650"
  },
  {
    "text": "And you say, well, but\nthey're all these scaling issues there. And they say, blah, that's\nnot important.",
    "start": "3788650",
    "end": "3795060"
  },
  {
    "text": "And they're right, because once\nyou understand it, it's not important. But let's look and see what the\nsimilarities and what the",
    "start": "3795060",
    "end": "3805670"
  },
  {
    "text": "differences are.  And I'll think in terms of, in\nfact, a quantization problem,",
    "start": "3805670",
    "end": "3814130"
  },
  {
    "text": "where I'm taking this\ncontinuous-valued random variable with density, and I'm\nquantizing it into a set of",
    "start": "3814130",
    "end": "3822250"
  },
  {
    "text": "discrete points. And I want to say what's the\ndifference between this",
    "start": "3822250",
    "end": "3827750"
  },
  {
    "text": "differential entropy here and\nthis discrete entropy, which we sort of understand by now.",
    "start": "3827750",
    "end": "3835410"
  },
  {
    "text": "Well, things that are the same\n-- the first thing that's the same is the differential entropy\nis still the expected",
    "start": "3835410",
    "end": "3844830"
  },
  {
    "text": "value of minus the logarithm\nof the probability density.",
    "start": "3844830",
    "end": "3849980"
  },
  {
    "text": " OK, we found that that was\nuseful before when we were",
    "start": "3849980",
    "end": "3856340"
  },
  {
    "text": "trying to understand\nthe entropy. It's the expected value\nof a log pmf.",
    "start": "3856340",
    "end": "3862180"
  },
  {
    "text": "Now the differential entropy is\nexpected value of a log pdf instead of pmf.",
    "start": "3862180",
    "end": "3870180"
  },
  {
    "text": "And the entropy of two random\nvariables, U1 and U2, if",
    "start": "3870180",
    "end": "3875349"
  },
  {
    "text": "they're independent, is just the\ndifferential entropy of U1 plus the differential\nentropy of U2.",
    "start": "3875350",
    "end": "3882940"
  },
  {
    "text": "How do I see that? You just write it down. You write down these\njoint densities. You write down this.",
    "start": "3882940",
    "end": "3888150"
  },
  {
    "text": "The logarithm of the joint\ndensity for IID splits into a",
    "start": "3888150",
    "end": "3893650"
  },
  {
    "text": "product of densities. A log of a product is\nthe sum of the logs.",
    "start": "3893650",
    "end": "3899210"
  },
  {
    "text": "It's the same as the\nargument before. In other words, it's not only\nthat this is the same as the",
    "start": "3899210",
    "end": "3906940"
  },
  {
    "text": "answer that we got before,\nbut the argument is exactly the same. And the other thing, the next\nthing is if you shift this",
    "start": "3906940",
    "end": "3915440"
  },
  {
    "text": "density here. If I have a density, which is\ngoing along here and I shift it over to here and have a\ndensity over there, the",
    "start": "3915440",
    "end": "3923410"
  },
  {
    "text": "entropy is the same again. Because this entropy is just\nfundamentally not -- it",
    "start": "3923410",
    "end": "3928930"
  },
  {
    "text": "doesn't have to do with where\nyou happen to be. It has to do with what these\nprobability densities are.",
    "start": "3928930",
    "end": "3935520"
  },
  {
    "text": "And you can stick that shift\ninto here, and if you're very good at doing calculus, you can,\nin fact, see that when",
    "start": "3935520",
    "end": "3945140"
  },
  {
    "text": "you put a shift in here, you\nstill get the same entropy. I couldn't do that at this\npoint, but I'm sure that all",
    "start": "3945140",
    "end": "3953390"
  },
  {
    "text": "of you can. And I can do it if\nI spent enough time thinking it through. It would just take me longer\nthan most of you.",
    "start": "3953390",
    "end": "3961600"
  },
  {
    "text": "OK, so all of these things\nare still true. There a couple of\nvery disturbing",
    "start": "3961600",
    "end": "3967300"
  },
  {
    "text": "differences, though. And the first difference\nis that h of U",
    "start": "3967300",
    "end": "3973450"
  },
  {
    "text": "is not scale invariant.  And, in fact, if it were\nscale invariant, it",
    "start": "3973450",
    "end": "3979800"
  },
  {
    "text": "would be totally useless. The fact that it's not scale\ninvariant turns out to be very",
    "start": "3979800",
    "end": "3985609"
  },
  {
    "text": "important when you try\nto understand it, OK? In other words, if you stretch\nthis probability density by",
    "start": "3985610",
    "end": "3996890"
  },
  {
    "text": "some quantity a, then your\nprobability density, which looks like this, shifts\nlike this.",
    "start": "3996890",
    "end": "4004569"
  },
  {
    "text": "It shifts down and\nit shifts out. So the log of the\npmf gets bigger.",
    "start": "4004570",
    "end": "4012790"
  },
  {
    "text": "The pmf itself is just\nsort of spread out. It does what you would\nexpect it to do, and",
    "start": "4012790",
    "end": "4019280"
  },
  {
    "text": "that works very nicely. But the log of the pmf has this\nextra term which comes in",
    "start": "4019280",
    "end": "4024630"
  },
  {
    "text": "here, which is a factor of a. And it turns out you can just\nfactor that factor of a out,",
    "start": "4024630",
    "end": "4032400"
  },
  {
    "text": "and you wind up with the\ndifferential entropy of a",
    "start": "4032400",
    "end": "4037730"
  },
  {
    "text": "scaled random variable U is\nequal to the differential entropy of the original U plus\nlog of a, which might be",
    "start": "4037730",
    "end": "4050760"
  },
  {
    "text": "minus log of a.  I'm not sure which it is.",
    "start": "4050760",
    "end": "4056280"
  },
  {
    "text": "I'll write down plus\nor minus log of a. It's one or the other.",
    "start": "4056280",
    "end": "4062450"
  },
  {
    "text": "I don't care at this point. All I'm interested\nin is that you recognize that it's different.",
    "start": "4062450",
    "end": "4070130"
  },
  {
    "text": "An even more disturbing point\nis this differential entropy can be negative. It can be negative\nor positive.",
    "start": "4070130",
    "end": "4075830"
  },
  {
    "text": "It can do whatever\nit wants to do. And so we're left with a sort\nof a peculiar thing.",
    "start": "4075830",
    "end": "4085540"
  },
  {
    "text": "But we say, well, all right,\nthat's the way it is. The physicists had\nto deal with that",
    "start": "4085540",
    "end": "4091410"
  },
  {
    "text": "for many, many years. And the physicists, who think\nabout it all the time, deal",
    "start": "4091410",
    "end": "4099410"
  },
  {
    "text": "with it and say it's\nnot very important. So we'll say, OK, we'll go along\nwith this unless asked:",
    "start": "4099410",
    "end": "4106980"
  },
  {
    "text": "What happens if we try to build\na uniform high-rate scalar quantizer, which is\nexactly what you would do for",
    "start": "4106980",
    "end": "4115100"
  },
  {
    "text": "implementation purposes\nanyway. So how does this work?",
    "start": "4115100",
    "end": "4120549"
  },
  {
    "text": "You pick a little tiny delta. You have all these\nregions here.",
    "start": "4120550",
    "end": "4125920"
  },
  {
    "text": "And by uniform, I mean you make\nall the regions the same. I mean, conceptually, this might\nmean having accountably",
    "start": "4125920",
    "end": "4132750"
  },
  {
    "text": "infinite number of regions. Let's not worry about that\nfor the time being. And you have points in here,\nwhich are the conditional",
    "start": "4132750",
    "end": "4141130"
  },
  {
    "text": "means of the regions. Well, if I assume that delta is\nsmall, then the probability",
    "start": "4141130",
    "end": "4151020"
  },
  {
    "text": "density of u is almost constant\nwithin a region, if it really is a density.",
    "start": "4151020",
    "end": "4157969"
  },
  {
    "text": "And I can define an average\nvalue of f of u within each",
    "start": "4157970",
    "end": "4163799"
  },
  {
    "text": "region in the following way. It's easier to see what it is\ngraphically if I have a density here, which runs\nalong like this.",
    "start": "4163800",
    "end": "4171219"
  },
  {
    "text": " And within each region, I will\nchoose f-bar of u to be a",
    "start": "4171220",
    "end": "4179930"
  },
  {
    "text": "piecewise constant version of\nthis density, which might be",
    "start": "4179930",
    "end": "4187630"
  },
  {
    "text": "like that, OK? Now that's just analytical\nstuff to make things come out right.",
    "start": "4187630",
    "end": "4193980"
  },
  {
    "text": "If you read the notes about how\nto do this, you find out that this quantity is important\nanalytically to",
    "start": "4193980",
    "end": "4202059"
  },
  {
    "text": "trace through what's going on. I think for the level that we're\nat now, it's fine to",
    "start": "4202060",
    "end": "4207510"
  },
  {
    "text": "just say, OK, this is the same\nas this, if we make the",
    "start": "4207510",
    "end": "4213380"
  },
  {
    "text": "quantization very small. I mean, at some point in this\nargument, you want to go through and say, OK, what do\nI mean by approximate?",
    "start": "4213380",
    "end": "4221420"
  },
  {
    "text": "Is the approximation close? How does the approximation\nbecome better as I make delta",
    "start": "4221420",
    "end": "4227520"
  },
  {
    "text": "smaller, and all of\nthese questions. But let's just now say, OK, this\nis the same as that, and",
    "start": "4227520",
    "end": "4235050"
  },
  {
    "text": "I'd like to find out how well\nthis uniform high-rate scalar quantizer does.",
    "start": "4235050",
    "end": "4240960"
  },
  {
    "text": " So my high-rate approximation\nis that this average density",
    "start": "4240960",
    "end": "4249610"
  },
  {
    "text": "is the same as the true\ndensity and for all possible u.",
    "start": "4249610",
    "end": "4256290"
  },
  {
    "text": "So conditional on u and Rj,\nthis quantity is constant.",
    "start": "4256290",
    "end": "4262760"
  },
  {
    "text": "It's constant and equal to 1\nover delta, and the actual",
    "start": "4262760",
    "end": "4267769"
  },
  {
    "text": "density is approximately\nequal to 1 over delta. What's that mean? It means that the mean square\nerror in one of these",
    "start": "4267770",
    "end": "4274510"
  },
  {
    "text": "quantization regions is our\nusual delta squared over 12, which is the mean square error\nof a uniform density in a",
    "start": "4274510",
    "end": "4282850"
  },
  {
    "text": "region from minus delta over\n2 to plus delta over 2. So that's the mean\nsquare error.",
    "start": "4282850",
    "end": "4288550"
  },
  {
    "text": "You can't do anything\nwith that. You're stuck with it. The next question is\nwhat is the entropy",
    "start": "4288550",
    "end": "4296650"
  },
  {
    "text": "as a quantizer output? I'm sorry, I'm giving a typical\nMIT lecture today,",
    "start": "4296650",
    "end": "4302760"
  },
  {
    "text": "which people have characterized\nas a fire hose, and it's because I want to get\ndone with this material today.",
    "start": "4302760",
    "end": "4311130"
  },
  {
    "text": "I think if you read the notes\nafterwards, you've got a pretty good picture of\nwhat's going on.",
    "start": "4311130",
    "end": "4317010"
  },
  {
    "text": "We are not going to have\nan enormous number of problems on this. It's not something we're\nstressing so I want to get you",
    "start": "4317010",
    "end": "4323295"
  },
  {
    "text": "to have some idea of what\nthis is all about. This slide is probably the most\nimportant slide because",
    "start": "4323295",
    "end": "4330829"
  },
  {
    "text": "it tells you what this\ndifferential entropy really is. ",
    "start": "4330830",
    "end": "4338040"
  },
  {
    "text": "OK, I'm going to look at the\nprobabilities of each of these discrete points now. p sub j\nis the probability that the",
    "start": "4338040",
    "end": "4347679"
  },
  {
    "text": "quantizer will get the\npoint a sub j. In other words, it is the\nprobability of the",
    "start": "4347680",
    "end": "4353260"
  },
  {
    "text": "region R sub j. And that's just the integral\nof the probability density",
    "start": "4353260",
    "end": "4360320"
  },
  {
    "text": "over the j-th region. Namely, it's the probability of\nbeing in that j-th region.",
    "start": "4360320",
    "end": "4366450"
  },
  {
    "text": "p sub j is also equal to this\naverage value times delta.",
    "start": "4366450",
    "end": "4372080"
  },
  {
    "text": "OK, so I look at what\nthe entropy is of the high-rate quantizer.",
    "start": "4372080",
    "end": "4377610"
  },
  {
    "text": "It's the sum of minus\npj log pj. I translate that pj is\nequal to this, so I",
    "start": "4377610",
    "end": "4387090"
  },
  {
    "text": "have a sum over j. I have an integral minus a fU of\nu, which is that, times log",
    "start": "4387090",
    "end": "4395850"
  },
  {
    "text": "And now I'll use this quantity\ninstead of this quantity. f-bar of u times delta du.",
    "start": "4395850",
    "end": "4402440"
  },
  {
    "text": "OK, in other words, these\nprobabilities are scaled by delta, which is what I was\ntelling you before.",
    "start": "4402440",
    "end": "4407560"
  },
  {
    "text": "That's the crucial thing here. As you make delta smaller and\nsmaller, the probabilities of",
    "start": "4407560",
    "end": "4413790"
  },
  {
    "text": "the intervals go down\nwith delta. OK, so I break this up\ninto two terms now.",
    "start": "4413790",
    "end": "4421809"
  },
  {
    "text": "I take out the log of delta,\nwhich is integrated over fU.",
    "start": "4421810",
    "end": "4427230"
  },
  {
    "text": "I have this quantity left. This quantity is approximately\nequal to the density, and what",
    "start": "4427230",
    "end": "4432670"
  },
  {
    "text": "I wind up with is that the\nactual entropy of the quantized version is equal to\nthe differential entropy minus",
    "start": "4432670",
    "end": "4440679"
  },
  {
    "text": "the log of delta at high rate. OK, that's the only way I know\nto interpret differential",
    "start": "4440680",
    "end": "4447550"
  },
  {
    "text": "entropy that makes any sense,\nOK, in other words, usually when you think of integrals,\nyou think of them",
    "start": "4447550",
    "end": "4454120"
  },
  {
    "text": "in a Riemann sense. You think of breaking up the\ninterval into lots of very thin slices with delta, and then\nyou integrate things by",
    "start": "4454120",
    "end": "4462530"
  },
  {
    "text": "adding up things, and that\nintegral then is then a sum. It's the same as this\nkind of sum.",
    "start": "4462530",
    "end": "4468600"
  },
  {
    "text": "And the integral that you wind\nup with when you're dealing with a log of the pmf, you\nget this extra delta",
    "start": "4468600",
    "end": "4476110"
  },
  {
    "text": "sticking in there, OK? So this entropy is this phony\nthing minus log of delta.",
    "start": "4476110",
    "end": "4488639"
  },
  {
    "text": "As I quantize more and\nmore finely, this entropy keeps going up.",
    "start": "4488640",
    "end": "4495020"
  },
  {
    "text": "It goes up because when delta is\nvery, very small, minus log delta is a large number.",
    "start": "4495020",
    "end": "4501590"
  },
  {
    "text": "So as delta gets smaller and\nsmaller, this entropy heads off towards infinity.",
    "start": "4501590",
    "end": "4508330"
  },
  {
    "text": "And in fact, you would expect\nthat because if you take a real number, which has a\ndistribution which is -- well,",
    "start": "4508330",
    "end": "4516150"
  },
  {
    "text": "anything just between minus 1\nand plus 1, for example, and I",
    "start": "4516150",
    "end": "4521469"
  },
  {
    "text": "want to represent it very, very\nwell if it's uniformly distributed there, the better\nI try to represent it, the",
    "start": "4521470",
    "end": "4528670"
  },
  {
    "text": "more bits it takes. That's what this is saying. This thing is changing as I try\nto represent things better",
    "start": "4528670",
    "end": "4537680"
  },
  {
    "text": "and better. This quantity here is just some\nfunny thing that deals",
    "start": "4537680",
    "end": "4543590"
  },
  {
    "text": "with the shape of the\nprobability density and nothing else. It essentially has a scale\nfactor built into it because",
    "start": "4543590",
    "end": "4553180"
  },
  {
    "text": "the probability density has a\nscale factor built into it. A probability density is\nprobability per unit length.",
    "start": "4553180",
    "end": "4562270"
  },
  {
    "text": "And therefore, this kind of\nentropy has to have that unit",
    "start": "4562270",
    "end": "4568500"
  },
  {
    "text": "length coming in here somehow,\nand that's the way it comes in. That's the way it is.",
    "start": "4568500",
    "end": "4574630"
  },
  {
    "start": "4574630",
    "end": "4579800"
  },
  {
    "text": "So to summarize all of that, and\nI'm sure you haven't quite",
    "start": "4579800",
    "end": "4585050"
  },
  {
    "text": "understood all of it, but if\nyou do efficient discrete coding at the end of the whole\nthing, the number of bits per",
    "start": "4585050",
    "end": "4595239"
  },
  {
    "text": "sample, namely, per number\ncoming into the quantizer that",
    "start": "4595240",
    "end": "4600545"
  },
  {
    "text": "you need, is H of V, OK? With this uniform quantizer,\nwhich produces an entropy of",
    "start": "4600545",
    "end": "4612510"
  },
  {
    "text": "the symbols H of V, then you\nL-bar bits per symbol to represent that. That's the result that\nwe had before.",
    "start": "4612510",
    "end": "4620110"
  },
  {
    "text": " This quantity H of V depends\nonly on delta and h of U.",
    "start": "4620110",
    "end": "4628869"
  },
  {
    "text": "Namely, h of U is equal to\nH of V plus log delta.",
    "start": "4628870",
    "end": "4634920"
  },
  {
    "text": "So, in other words,\nanalytically, the only thing you have to worry about\nis what is this",
    "start": "4634920",
    "end": "4640120"
  },
  {
    "text": "differential entropy? You can't interpret what it is,\nbut you can calculate it.",
    "start": "4640120",
    "end": "4645310"
  },
  {
    "text": "And once you calculate it,\nthis tells you what this entropy is for every\nchoice of delta so",
    "start": "4645310",
    "end": "4651630"
  },
  {
    "text": "long as delta is small. It says that when you get to the\npoint where delta is small",
    "start": "4651630",
    "end": "4658530"
  },
  {
    "text": "and the probability density is\nessentially constant over a region, if I want to make delta\nhalf as big as it was",
    "start": "4658530",
    "end": "4666360"
  },
  {
    "text": "before, then I'm going to wind\nup with twice as many quantization regions. They're all going to\nbe only half as",
    "start": "4666360",
    "end": "4672990"
  },
  {
    "text": "probable as the ones before. It's going to take me\none extra bit to represent that, OK?",
    "start": "4672990",
    "end": "4679550"
  },
  {
    "text": "Namely, this one extra bit for\neach of these old regions is going to tell me whether I'm on\nthe right side or the left",
    "start": "4679550",
    "end": "4687110"
  },
  {
    "text": "side of that old quantization\nregion to talk about the new",
    "start": "4687110",
    "end": "4693219"
  },
  {
    "text": "quantization region. So this all make sense, OK? Namely, the only thing that's\nhappening as you make the",
    "start": "4693220",
    "end": "4699770"
  },
  {
    "text": "quantization finer and finer is\nthat you have these extra",
    "start": "4699770",
    "end": "4705270"
  },
  {
    "text": "bits coming in, which are sort\nof telling you what the fine structure is.",
    "start": "4705270",
    "end": "4710540"
  },
  {
    "text": "And little h of U already has\nbuilt into it the overall shape of the thing.",
    "start": "4710540",
    "end": "4718280"
  },
  {
    "text": "OK, now I've added one thing\nmore here, which I haven't talked about at all.",
    "start": "4718280",
    "end": "4724450"
  },
  {
    "text": "This uniform scalar quantizer\nin fact becomes optimal as",
    "start": "4724450",
    "end": "4730440"
  },
  {
    "text": "delta become small. And that's not obvious;\nit's not intuitive.",
    "start": "4730440",
    "end": "4736830"
  },
  {
    "text": "There's an argument\nin the text that shows why that is true. It uses a Lagrange multiplier\nto do it.",
    "start": "4736830",
    "end": "4745680"
  },
  {
    "text": "I guess there's a certain\nelegance to it. I mean, after years of thinking\nabout it, I would",
    "start": "4745680",
    "end": "4752310"
  },
  {
    "text": "say, yeah, it's pretty likely\nthat it's true if I didn't have the mathematics\nto know it's true.",
    "start": "4752310",
    "end": "4757670"
  },
  {
    "text": "But, in fact, it's a very\ninteresting result. It says that what you do with\nclassical a to z converters,",
    "start": "4757670",
    "end": "4766760"
  },
  {
    "text": "if you're going to have very\nfine quantization, is, in fact, the right thing to do.",
    "start": "4766760",
    "end": "4771780"
  }
]
[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": " NARRATOR: The following content\nis provided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18140",
    "end": "23528"
  },
  {
    "start": "22000",
    "end": "145000"
  },
  {
    "text": "GILBERT STRANG: OK. So, I'd like to pick up again\non this neat family of matrices,",
    "start": "23528",
    "end": "31740"
  },
  {
    "text": "circulant matrices. But first, let me say\nhere and then put it",
    "start": "31740",
    "end": "37020"
  },
  {
    "text": "on the web, my thought\nabout the projects. So, I think the last deadline\nI can give is the final class.",
    "start": "37020",
    "end": "45690"
  },
  {
    "text": "So, I think that's not\nnext week but Wednesday of the following week, I think,\nis our last class meeting.",
    "start": "45690",
    "end": "53550"
  },
  {
    "text": "So, be great to get\nthem then or earlier. And if anybody or\neverybody would",
    "start": "53550",
    "end": "60570"
  },
  {
    "text": "like to tell the class a\nlittle bit about their project,",
    "start": "60570",
    "end": "67420"
  },
  {
    "text": "you know it's a\nfriendly audience",
    "start": "67420",
    "end": "72479"
  },
  {
    "text": "and I'd be happy to make\nspace and time for that. So, send me an email and\ngive me the project earlier",
    "start": "72480",
    "end": "82320"
  },
  {
    "text": "if you would like to just\nsay a few words in class. Or even if you are willing\nto say a few words in class,",
    "start": "82320",
    "end": "89370"
  },
  {
    "text": "I'll say. Yeah. Because I realize-- yeah, OK.",
    "start": "89370",
    "end": "94650"
  },
  {
    "text": "So, other questions about-- so, we're finished with\nall psets and so on.",
    "start": "94650",
    "end": "100660"
  },
  {
    "text": "So, it's really just\na project, and yeah. STUDENT: How is\nthe project graded? Like, on what basis?",
    "start": "100660",
    "end": "105785"
  },
  {
    "text": "GILBERT STRANG:\nHow is it graded? Good question. But it's going to\nbe me, I guess.",
    "start": "105785",
    "end": "111600"
  },
  {
    "text": "So I'll read all the projects\nand come up with a grade",
    "start": "111600",
    "end": "118270"
  },
  {
    "text": "somehow, you know. I hope you guys have\nunderstood that my feeling is",
    "start": "118270",
    "end": "125970"
  },
  {
    "text": "that the grades\nin this course are going to be on the high\nside because they should be.",
    "start": "125970",
    "end": "131890"
  },
  {
    "text": "Yeah. I think it's that\nkind of a course and I've asked you to\ndo a fair amount, and--",
    "start": "131890",
    "end": "139860"
  },
  {
    "text": "anyway, that's my\nstarting basis. ",
    "start": "139860",
    "end": "145590"
  },
  {
    "start": "145000",
    "end": "188000"
  },
  {
    "text": "And there's a lot of topics\nlike circulant matrices that I'm not going to be able\nto give you a pset about.",
    "start": "145590",
    "end": "151920"
  },
  {
    "text": "But of course, these\nare closely connected to the discrete\nFourier transform.",
    "start": "151920",
    "end": "161070"
  },
  {
    "text": "So, let me just write the\nname of the great man Fourier.",
    "start": "161070",
    "end": "169350"
  },
  {
    "text": "So, the discrete Fourier\ntransform is, as you know, a very, very important\nalgorithm in engineering",
    "start": "169350",
    "end": "178740"
  },
  {
    "text": "and in mathematics. Everywhere. Fourier is just\na key idea and so",
    "start": "178740",
    "end": "188955"
  },
  {
    "start": "188000",
    "end": "488000"
  },
  {
    "text": "I think it's just good\nto know about, though. So, circulant\nmatrices are connected with finite size matrices.",
    "start": "188955",
    "end": "200160"
  },
  {
    "text": "Matrices of size n. So our circulant\nmatrices will be N by N.",
    "start": "200160",
    "end": "208459"
  },
  {
    "text": "And you remember\nthis special form. ",
    "start": "208460",
    "end": "217340"
  },
  {
    "text": "So, this is a key point\nabout these matrices, C. That they're defined by\nnot n squared entries, only n.",
    "start": "217340",
    "end": "228050"
  },
  {
    "text": "If you tell me just the\nfirst row of the matrix, and that's all you would\ntell Matlab, say, c0, c1, c2",
    "start": "228050",
    "end": "237160"
  },
  {
    "text": "to c N minus 1. Then for a circulant,\nthat's all I",
    "start": "237160",
    "end": "243200"
  },
  {
    "text": "need to know because these\ndiagonals are constant. This diagonal is constant-- c1--",
    "start": "243200",
    "end": "249590"
  },
  {
    "text": "and then gets completed here. c2 diagonal come to c2 and then\ngets completed cyclically here.",
    "start": "249590",
    "end": "259459"
  },
  {
    "text": "So, n numbers and not n squared. The reason I mention\nthat, or a reason is,",
    "start": "259459",
    "end": "269780"
  },
  {
    "text": "that's a big selling point\nwhen you go to applications, say machine\nlearning, for images.",
    "start": "269780",
    "end": "279009"
  },
  {
    "text": "So, you remember the big\npicture of machine learning,",
    "start": "279010",
    "end": "285130"
  },
  {
    "text": "deep learning, was\nthat you had samples. ",
    "start": "285130",
    "end": "291670"
  },
  {
    "text": "A lot of samples, let's\nsay N samples, maybe.",
    "start": "291670",
    "end": "297220"
  },
  {
    "text": "And then each sample in this\nimage part will be an image.",
    "start": "297220",
    "end": "303710"
  },
  {
    "text": "So, the thing is that an image\nis described by its pixels",
    "start": "303710",
    "end": "309590"
  },
  {
    "text": "and if I have 1,000\nby 1,000 pixel-- so, that's a million pixels.",
    "start": "309590",
    "end": "318460"
  },
  {
    "text": "The feature vector,\nthe vector that's associated with 1\nsample, is enormous.",
    "start": "318460",
    "end": "324289"
  },
  {
    "text": "Is enormous. So I have N samples but maybe--",
    "start": "324290",
    "end": "332180"
  },
  {
    "text": "well, if they were\nin color that million suddenly becomes 3 million. So say 3 million features.",
    "start": "332180",
    "end": "340680"
  },
  {
    "start": "340680",
    "end": "346020"
  },
  {
    "text": "So, our vectors\nare a vector of-- the whole computation of deep\nlearning works with our vectors",
    "start": "346020",
    "end": "355650"
  },
  {
    "text": "with 3 million components. And that means that in the\nordinary way, if we didn't",
    "start": "355650",
    "end": "361349"
  },
  {
    "text": "do anything special we\nwould be multiplying those by matrices of size like\n3 million times 3 million.",
    "start": "361350",
    "end": "370380"
  },
  {
    "text": "We would be computing\nthat many weights. That's like, impossible. ",
    "start": "370380",
    "end": "377410"
  },
  {
    "text": "And we would be computing\nthat for each layer in the deep network\nso it would go up--",
    "start": "377410",
    "end": "384669"
  },
  {
    "start": "384670",
    "end": "389900"
  },
  {
    "text": "so 3 million by 3\nmillion is just-- we can't compute. We can't use gradient descent\nto optimize that many weights.",
    "start": "389900",
    "end": "399040"
  },
  {
    "text": "So, the point is that the\nmatrices in deep learning",
    "start": "399040",
    "end": "405190"
  },
  {
    "text": "are special. And they don't depend-- they're like circulant matrices.",
    "start": "405190",
    "end": "411729"
  },
  {
    "text": "They might not loop around. So, circulant matrices\nhave this cyclic feature",
    "start": "411730",
    "end": "418060"
  },
  {
    "text": "that makes the theory\nextremely nice. But of course, in general we\nhave matrices, let's say t0--",
    "start": "418060",
    "end": "430165"
  },
  {
    "text": " constant diagonals and\nmaybe a bunch of diagonals.",
    "start": "430165",
    "end": "438310"
  },
  {
    "text": "And here not necessarily\nsymmetric, or they might be symmetric.",
    "start": "438310",
    "end": "443710"
  },
  {
    "text": "But they're not cyclic. So, what are these\nmatrices called?",
    "start": "443710",
    "end": "449530"
  },
  {
    "text": "Well, they have a bunch of names\nbecause they're so important. They're linear shift invariant.",
    "start": "449530",
    "end": "457450"
  },
  {
    "text": "Or linear time\ninvariant, whatever is the right word in your context.",
    "start": "457450",
    "end": "464620"
  },
  {
    "text": "So, they're convolutions. You could call it a\nconvolution matrix.",
    "start": "464620",
    "end": "470365"
  },
  {
    "text": " When you multiply by\none of these matrices,",
    "start": "470365",
    "end": "477880"
  },
  {
    "text": "I guess I'm going to call it t,\nyou're doing our convolution.",
    "start": "477880",
    "end": "485210"
  },
  {
    "text": "And I'll better write down\nthe formula for convolution. You're not doing a\ncyclic convolution",
    "start": "485210",
    "end": "491190"
  },
  {
    "start": "488000",
    "end": "594000"
  },
  {
    "text": "unless the matrix cycles round. When you multiply by\nC, this would give you",
    "start": "491190",
    "end": "498120"
  },
  {
    "text": "cyclic convolution. ",
    "start": "498120",
    "end": "503920"
  },
  {
    "text": "Say if I multiply\nC by some vector v, the result is the\ncyclic convolution",
    "start": "503920",
    "end": "511289"
  },
  {
    "text": "of the c vector\nwith the v vector. So, big C is a matrix\nbut it's completely",
    "start": "511290",
    "end": "519270"
  },
  {
    "text": "defined by its first\nrow or first column. So I just have a vector\noperation in there",
    "start": "519270",
    "end": "527130"
  },
  {
    "text": "and it's a cyclic one. And over here, t\ntimes a vector v",
    "start": "527130",
    "end": "533160"
  },
  {
    "text": "will be the convolution of a t\nvector with v, but not cyclic.",
    "start": "533160",
    "end": "539959"
  },
  {
    "start": "539960",
    "end": "545280"
  },
  {
    "text": "And probably these are the\nones that would actually come into machine learning.",
    "start": "545280",
    "end": "550980"
  },
  {
    "text": "So, linear shift invariant,\nlinear time invariant.",
    "start": "550980",
    "end": "556620"
  },
  {
    "text": "I would call it-- so, math people would\ncall it a Toeplitz matrix.",
    "start": "556620",
    "end": "562470"
  },
  {
    "text": " That's why I used the letter t.",
    "start": "562470",
    "end": "569840"
  },
  {
    "text": "In engineering it would be\na filter or a convolution",
    "start": "569840",
    "end": "577180"
  },
  {
    "text": "or a constant diagonal matrix. ",
    "start": "577180",
    "end": "584860"
  },
  {
    "text": "These come up in\nall sorts of places and they come up\nin machine learning",
    "start": "584860",
    "end": "591230"
  },
  {
    "text": "and with image processing. But basically,\nbecause what you're",
    "start": "591230",
    "end": "597320"
  },
  {
    "start": "594000",
    "end": "695000"
  },
  {
    "text": "doing at one point in\nan image is pretty much what you're going to\ndo at the other points,",
    "start": "597320",
    "end": "602450"
  },
  {
    "text": "you're not going to\nfigure out special weights for each little\npixel in the image.",
    "start": "602450",
    "end": "608053"
  },
  {
    "text": "You're going to\ntake-- if you have an image, say you have an\nimage with zillions of pixels.",
    "start": "608053",
    "end": "615350"
  },
  {
    "text": "Well, you might\nwant to cut down. I mean, it would be\nvery sensible to do",
    "start": "615350",
    "end": "621830"
  },
  {
    "text": "some max pooling, some pooling\noperation to make it smaller.",
    "start": "621830",
    "end": "630160"
  },
  {
    "start": "630160",
    "end": "637220"
  },
  {
    "text": "So, that's really like, OK, we\ndon't want this large a system.",
    "start": "637220",
    "end": "642259"
  },
  {
    "text": "Let's just reduce it. So, max pooling. That operation would be--",
    "start": "642260",
    "end": "649100"
  },
  {
    "text": "say, take them 3 at a\ntime, some 9 pixels.",
    "start": "649100",
    "end": "655639"
  },
  {
    "text": "And replace that 9\npixels by 1 pixel. So the max of those 9 numbers.",
    "start": "655640",
    "end": "662000"
  },
  {
    "text": "That would be a very simple\noperation that just reduces the dimension, make it smaller.",
    "start": "662000",
    "end": "668329"
  },
  {
    "text": "Reduce the dimension. ",
    "start": "668330",
    "end": "676770"
  },
  {
    "text": "OK, so that's a cheap way\nto make an image 4 times",
    "start": "676770",
    "end": "682020"
  },
  {
    "text": "or 9 times or 64 times smaller. But the convolution part now--",
    "start": "682020",
    "end": "689120"
  },
  {
    "text": "so, that's not\ninvolving convolution. That's a different\noperation here.",
    "start": "689120",
    "end": "695100"
  },
  {
    "text": "Not even linear if I\ntake the max in each box.",
    "start": "695100",
    "end": "700300"
  },
  {
    "text": "That's not a linear operation\nbut it's a fast one. OK, so where do circulants\nor convolution or Toeplitz",
    "start": "700300",
    "end": "711140"
  },
  {
    "text": "matrices or filters\ncome into it? So, I'll forget about\nthe max pooling.",
    "start": "711140",
    "end": "716510"
  },
  {
    "text": "Suppose that's\nhappened and I still have a very big system\nwith n squared pixels,",
    "start": "716510",
    "end": "727879"
  },
  {
    "text": "n squared features\nfor each sample.",
    "start": "727880",
    "end": "732920"
  },
  {
    "text": "So, I want to operate on\nthat by matrices, as usual. I want to choose the weights to\nbring out the important points.",
    "start": "732920",
    "end": "744200"
  },
  {
    "text": "So, the whole idea is-- on a image like that\nI'll use a convolution.",
    "start": "744200",
    "end": "752149"
  },
  {
    "text": " The same operation is\nhappening at each point.",
    "start": "752150",
    "end": "760010"
  },
  {
    "start": "753000",
    "end": "870000"
  },
  {
    "text": "So, forget the max part. Let me erase, if I can\nfind an eraser here.",
    "start": "760010",
    "end": "765430"
  },
  {
    "text": "OK, so I'm not going to-- we've done this. So, that's done.",
    "start": "765430",
    "end": "771889"
  },
  {
    "text": "Now, I want to\nmultiply it by weights. So, that's already done.",
    "start": "771890",
    "end": "779710"
  },
  {
    "text": "OK. So, what am I looking to do? ",
    "start": "779710",
    "end": "787000"
  },
  {
    "text": "What kind of a job\nwould a filter do? A low-pass filter would\nkill, or nearly kill,",
    "start": "787000",
    "end": "797290"
  },
  {
    "text": "the high frequencies, the noise. So, if I wanted to get\na simpler image there,",
    "start": "797290",
    "end": "808060"
  },
  {
    "text": "I would use a low-pass\nfilter, which might just-- it might be this filter here.",
    "start": "808060",
    "end": "819550"
  },
  {
    "text": "Let me just put in some\nnumbers that would-- ",
    "start": "819550",
    "end": "825760"
  },
  {
    "text": "say 1/2 and 1/2.  So, I'm averaging each\npixel with its neighbor",
    "start": "825760",
    "end": "835360"
  },
  {
    "text": "just to take out some\nof the high frequencies. The low frequencies\nare constant.",
    "start": "835360",
    "end": "842350"
  },
  {
    "text": "An all-black image would\ncome out not changed but a very highly speckled\nimage would get largely removed",
    "start": "842350",
    "end": "854560"
  },
  {
    "text": "by that averaging. So, it's the same\nidea that comes up in all of signal\nprocessing, filtering.",
    "start": "854560",
    "end": "864400"
  },
  {
    "text": "So, just to complete\nthis thought of,",
    "start": "864400",
    "end": "874060"
  },
  {
    "start": "870000",
    "end": "1153000"
  },
  {
    "text": "why do neural nets-- so,\nI'm answering this question.",
    "start": "874060",
    "end": "881250"
  },
  {
    "text": "How do they come in\nmachine learning? So, they come when\nthe samples are images",
    "start": "881250",
    "end": "888810"
  },
  {
    "text": "and then it's natural to use\na constant diagonal matrix,",
    "start": "888810",
    "end": "895920"
  },
  {
    "text": "a shift invariant matrix\nand not an arbitrary matrix.",
    "start": "895920",
    "end": "900930"
  },
  {
    "text": "So, we only have to compute\nn weights and not n squared.",
    "start": "900930",
    "end": "908300"
  },
  {
    "text": "Yeah, so that's the point. So, that's one\nreason for talking",
    "start": "908300",
    "end": "913709"
  },
  {
    "text": "about convolution and circulant\nmatrices in this course.",
    "start": "913710",
    "end": "922620"
  },
  {
    "text": "I guess I feel another\nreason is that everything to do with the DFT, with\nFourier and Fourier transforms",
    "start": "922620",
    "end": "933690"
  },
  {
    "text": "and Fourier matrices, that's\njust stuff you gotta know.",
    "start": "933690",
    "end": "939600"
  },
  {
    "text": "Every time you're dealing\nwith vectors where shifting",
    "start": "939600",
    "end": "946589"
  },
  {
    "text": "the vectors comes\ninto it, that's-- Fourier is going to come in. So, it's just we\nshould see Fourier.",
    "start": "946590",
    "end": "954120"
  },
  {
    "text": "OK. So now I'll go back to\nthis specially nice case",
    "start": "954120",
    "end": "964260"
  },
  {
    "text": "where the matrix loops around.",
    "start": "964260",
    "end": "971010"
  },
  {
    "text": "Where I have this\ncyclic convolution. So, this would be cyclic because\nof the looping around stuff.",
    "start": "971010",
    "end": "982949"
  },
  {
    "text": " So, what was the\npoint of last time?",
    "start": "982950",
    "end": "989910"
  },
  {
    "text": "I started with this\npermutation matrix. ",
    "start": "989910",
    "end": "995430"
  },
  {
    "text": "And the permutation matrix\nhas c0 equals 0, c1 equal 1,",
    "start": "995430",
    "end": "1003339"
  },
  {
    "text": "and the rest of the c's are 0. So, it's just the effect\nof multiplying by this--",
    "start": "1003340",
    "end": "1011350"
  },
  {
    "text": " get a box around it here-- the effect of multiplying\nby this permutation matrix",
    "start": "1011350",
    "end": "1019390"
  },
  {
    "text": "is to shift everything and\nthen bring the last one up to the top.",
    "start": "1019390",
    "end": "1025250"
  },
  {
    "text": "So, it's a cyclic shift. ",
    "start": "1025250",
    "end": "1031910"
  },
  {
    "text": "And I guess at the\nvery end of last time I was asking about\nits eigenvalues",
    "start": "1031910",
    "end": "1038949"
  },
  {
    "text": "and its eigenvectors, so can\nwe come to that question? So, that's the starting\nquestion for everything here.",
    "start": "1038950",
    "end": "1045640"
  },
  {
    "text": "I guess we've understood\nthat to get deeper into a matrix, its\neigenvalues, eigenvectors,",
    "start": "1045640",
    "end": "1055180"
  },
  {
    "text": "or singular value, singular\nvectors, are the way to go.",
    "start": "1055180",
    "end": "1060880"
  },
  {
    "text": "Actually, what would be the\nsingular values of that matrix? ",
    "start": "1060880",
    "end": "1070080"
  },
  {
    "text": "Let's just think\nabout singular values and then we'll see why\nit's eigenvalues we want.",
    "start": "1070080",
    "end": "1077649"
  },
  {
    "text": "What are the singular values\nof a permutation matrix? They're all 1.",
    "start": "1077650",
    "end": "1084960"
  },
  {
    "text": "All 1. That matrix is a\northogonal matrix,",
    "start": "1084960",
    "end": "1090200"
  },
  {
    "text": "so the SVD of the matrix\njust has the permutation",
    "start": "1090200",
    "end": "1098269"
  },
  {
    "text": "and then the identity\nis there for the sigma. So, sigma is I for\nthis for this matrix.",
    "start": "1098270",
    "end": "1105860"
  },
  {
    "start": "1105860",
    "end": "1111320"
  },
  {
    "text": "So, the singular values don't--  that's because P transpose\nP is the identity matrix.",
    "start": "1111320",
    "end": "1119270"
  },
  {
    "text": " Any time I have--",
    "start": "1119270",
    "end": "1124280"
  },
  {
    "text": "that's an orthogonal matrix,\nand anytime P transpose P is the identity,\nthe singular values",
    "start": "1124280",
    "end": "1130850"
  },
  {
    "text": "will be the eigenvalues\nof the identity. And they're all just 1's.",
    "start": "1130850",
    "end": "1136010"
  },
  {
    "text": "The eigenvalues of P, that's\nwhat we want to find, so let's do that. OK, eigenvalues\nof P. So, one way",
    "start": "1136010",
    "end": "1146030"
  },
  {
    "text": "is to take P minus lambda I.\nThat's just the way we teach",
    "start": "1146030",
    "end": "1155200"
  },
  {
    "start": "1153000",
    "end": "1290000"
  },
  {
    "text": "in 18.06 and never use again. So, it puts minus\nlambda on the diagonal,",
    "start": "1155200",
    "end": "1163450"
  },
  {
    "text": "and of course P is\nsitting up here. And then the rest is 0.",
    "start": "1163450",
    "end": "1171100"
  },
  {
    "text": "OK, so now following\nthe 18.06 rule, I should take that\ndeterminant, right?",
    "start": "1171100",
    "end": "1179350"
  },
  {
    "text": "And set it to 0. This is one of the very few\noccasions we can actually",
    "start": "1179350",
    "end": "1185770"
  },
  {
    "text": "do it, so allow me to do it. So, what is the\ndeterminant of this?",
    "start": "1185770",
    "end": "1191440"
  },
  {
    "text": "Well, there's that\nlambda to the fourth,",
    "start": "1191440",
    "end": "1198799"
  },
  {
    "text": "and I guess I think it's\nlambda to the fourth minus 1.",
    "start": "1198800",
    "end": "1204485"
  },
  {
    "text": "I think that's the\nright determinant. That certainly has property--\nso, I would set that to 0,",
    "start": "1204485",
    "end": "1215590"
  },
  {
    "text": "then I would find that\nthe eigenvalues for that",
    "start": "1215590",
    "end": "1221360"
  },
  {
    "text": "will be 1 and minus\n1, and I and minus I.",
    "start": "1221360",
    "end": "1227780"
  },
  {
    "text": "And they're the\nfourth roots of 1.",
    "start": "1227780",
    "end": "1237610"
  },
  {
    "text": "Lambda to the fourth equal 1.  That's our eigenvalue equation.",
    "start": "1237610",
    "end": "1244390"
  },
  {
    "text": "Lambda to the fourth equal 1\nor lambda to the n-th equal 1. So, what would be the\neigenvalues for the P 8 by 8?",
    "start": "1244390",
    "end": "1254559"
  },
  {
    "start": "1254560",
    "end": "1260420"
  },
  {
    "text": "This is the complex\nplane, of course. Real and imaginary.",
    "start": "1260420",
    "end": "1268120"
  },
  {
    "text": "So, that's got 8 eigenvalues. P to the eighth power\nwould be the identity.",
    "start": "1268120",
    "end": "1277420"
  },
  {
    "text": "And that means that\nlambda to the eighth power is 1 for the eigenvalues.",
    "start": "1277420",
    "end": "1283000"
  },
  {
    "text": "And what are the 8 solutions? Every polynomial\nequation of degree 8",
    "start": "1283000",
    "end": "1289480"
  },
  {
    "text": "has got to have 8 solutions. That's Gauss's fundamental\ntheorem of algebra.",
    "start": "1289480",
    "end": "1297510"
  },
  {
    "start": "1290000",
    "end": "1410000"
  },
  {
    "text": "8 solutions, so what are they? What are the 8 numbers\nwhose eighth power gives 1?",
    "start": "1297510",
    "end": "1305510"
  },
  {
    "text": " You all probably know them.",
    "start": "1305510",
    "end": "1311430"
  },
  {
    "text": "So, they're 1, of course\nthe eighth power of 1, the eighth power of minus 1,\nthe eighth power of minus I,",
    "start": "1311430",
    "end": "1318419"
  },
  {
    "text": "and the other guys\nare just here. ",
    "start": "1318420",
    "end": "1323820"
  },
  {
    "text": "The roots of 1 are equally\nspaced around the circle. So, Fourier has come in.",
    "start": "1323820",
    "end": "1329060"
  },
  {
    "text": "You know, Fourier wakes up\nwhen he sees that picture. Fourier is going to be here and\nit'll be in the eigenvectors.",
    "start": "1329060",
    "end": "1339029"
  },
  {
    "text": "So, you're OK with\nthe eigenvalues? The eigenvalues of P will be--",
    "start": "1339030",
    "end": "1345080"
  },
  {
    "text": " we better give a\nname to this number.",
    "start": "1345080",
    "end": "1351470"
  },
  {
    "text": "Let's see. I'm going to call that\nnumber w and it will be e to the 2 pi i over 8, right?",
    "start": "1351470",
    "end": "1361070"
  },
  {
    "text": "Because the whole angle is\n2 pi divided in 8 pieces.",
    "start": "1361070",
    "end": "1369590"
  },
  {
    "text": "So that's 2 pi i over 8. 2 pi i over N for a matrix of--",
    "start": "1369590",
    "end": "1377840"
  },
  {
    "text": "for the n by n permutation. Yeah, so that's number w.",
    "start": "1377840",
    "end": "1383720"
  },
  {
    "text": "And of course, this\nguy is w squared. This one is w cubed, w fourth,\nw fifth, sixth, seventh,",
    "start": "1383720",
    "end": "1395840"
  },
  {
    "text": "and w to the eighth\nis the same as 1. Right. ",
    "start": "1395840",
    "end": "1407684"
  },
  {
    "text": "The reason I put\nthose numbers up there is that they come into\nthe eigenvectors as well",
    "start": "1407685",
    "end": "1412740"
  },
  {
    "start": "1410000",
    "end": "1567000"
  },
  {
    "text": "as the eigenvalues. They are the eigenvalues,\nthese 8 numbers. 1, 2, 3, 4, 5, 6, 7, 8 are the\n8 eigenvalues of the matrix.",
    "start": "1412740",
    "end": "1425220"
  },
  {
    "text": "Here's the 4 by 4 case. The matrix is an\northogonal matrix.",
    "start": "1425220",
    "end": "1431340"
  },
  {
    "text": "Oh, what does that tell\nus about the eigenvectors? The eigenvectors of\nan orthogonal matrix",
    "start": "1431340",
    "end": "1437760"
  },
  {
    "text": "are orthogonal just\nlike symmetric matrices.",
    "start": "1437760",
    "end": "1445180"
  },
  {
    "text": "So, do you know that\nlittle list of matrices",
    "start": "1445180",
    "end": "1452820"
  },
  {
    "text": "with orthogonal eigenvectors?",
    "start": "1452820",
    "end": "1460649"
  },
  {
    "text": " I'm going to call them q.",
    "start": "1460650",
    "end": "1467899"
  },
  {
    "text": "So qi dotted qj, the\ninner product, is 1 or 0.",
    "start": "1467900",
    "end": "1476520"
  },
  {
    "text": "1 if i equal j, 0 if i is not j.",
    "start": "1476520",
    "end": "1482280"
  },
  {
    "text": "Orthogonal eigenvectors. Now, what matrices have\northogonal eigenvectors? We're going back\nto linear algebra",
    "start": "1482280",
    "end": "1489120"
  },
  {
    "text": "because this is a\nfundamental fact to know, this family of\nwonderful matrices.",
    "start": "1489120",
    "end": "1497370"
  },
  {
    "text": "Matrices with\northogonal eigenvectors. Or tell me one bunch of\nmatrices that you know",
    "start": "1497370",
    "end": "1503296"
  },
  {
    "text": "has orthogonal eigenvectors. STUDENT: Symmetric. GILBERT STRANG: Symmetric. ",
    "start": "1503296",
    "end": "1512370"
  },
  {
    "text": "And what is special\nabout the eigenvalues? They're real.",
    "start": "1512370",
    "end": "1517730"
  },
  {
    "text": "But there are\nother matrices that have orthogonal\neigenvectors and we really",
    "start": "1517730",
    "end": "1525720"
  },
  {
    "text": "should know the whole\nstory about those guys. They're too important\nnot to know.",
    "start": "1525720",
    "end": "1531090"
  },
  {
    "text": "So, what's another\nbunch of matrices? So, these symmetric matrices\nhave orthogonal eigenvectors",
    "start": "1531090",
    "end": "1539010"
  },
  {
    "text": "and-- real symmetrics and the\neigenvalues will be real.",
    "start": "1539010",
    "end": "1544590"
  },
  {
    "text": "Well, what other\nkind of matrices have orthogonal eigenvectors?",
    "start": "1544590",
    "end": "1551220"
  },
  {
    "text": "But they might be complex\nand the eigenvalues might be complex.",
    "start": "1551220",
    "end": "1558240"
  },
  {
    "text": "And you can't know Fourier\nwithout saying, OK, I can",
    "start": "1558240",
    "end": "1563640"
  },
  {
    "text": "deal with this complex number. OK, so what's another\nfamily of matrices that",
    "start": "1563640",
    "end": "1570750"
  },
  {
    "text": "has orthogonal eigenvectors? Yes. STUDENT: Diagonal matrices. GILBERT STRANG: Diagonal\nfor sure, right?",
    "start": "1570750",
    "end": "1579270"
  },
  {
    "text": "And then we know that we\nhave the eigenvectors go",
    "start": "1579270",
    "end": "1589860"
  },
  {
    "text": "into the identity matrix, right. Yeah, so we know everything\nabout diagonal ones.",
    "start": "1589860",
    "end": "1595740"
  },
  {
    "text": "You could say those are\nincluded in symmetric. Now, let's get some new ones. What else?",
    "start": "1595740",
    "end": "1601500"
  },
  {
    "text": "STUDENT: [INAUDIBLE] GILBERT STRANG:\nOrthogonal matrices count. Orthogonal matrices, like\npermutations or like rotations",
    "start": "1601500",
    "end": "1611760"
  },
  {
    "start": "1602000",
    "end": "1685000"
  },
  {
    "text": "or like reflections. Orthogonal matrices. ",
    "start": "1611760",
    "end": "1618990"
  },
  {
    "text": "And what's special\nabout their eigenvalues? The eigenvalues of\nan orthogonal matrix?",
    "start": "1618990",
    "end": "1626684"
  },
  {
    "text": "STUDENT: [INAUDIBLE] GILBERT STRANG: The\nmagnitude is 1, exactly. ",
    "start": "1626684",
    "end": "1632110"
  },
  {
    "text": "It has to be 1 because an\northogonal matrix doesn't change the length of the vector.",
    "start": "1632110",
    "end": "1638420"
  },
  {
    "text": "Q times x has the same\nlength as x for all vectors.",
    "start": "1638420",
    "end": "1646090"
  },
  {
    "text": "And in particular,\nfor eigenvectors. So, if this was an eigenvector,\nQ x would equal lambda x.",
    "start": "1646090",
    "end": "1656410"
  },
  {
    "text": "And now if that equals that,\nthen lambda has to be 1. The magnitude of\nlambda has to be 1.",
    "start": "1656410",
    "end": "1662010"
  },
  {
    "text": "Of course. Complex numbers\nare expected here and that's exactly\nwhat we're seeing here.",
    "start": "1662010",
    "end": "1669610"
  },
  {
    "text": "All the eigenvalues\nof permutations are very special\northogonal matrices.",
    "start": "1669610",
    "end": "1676460"
  },
  {
    "text": "I won't add permutations\nseparately to the list but they count. ",
    "start": "1676460",
    "end": "1687900"
  },
  {
    "text": "The fact that this\nis on the list tells us that the eigenvectors\nthat we're going to find",
    "start": "1687900",
    "end": "1693150"
  },
  {
    "text": "are orthogonal. We don't have to\ndo a separate check to see that they are\nonce we compute them.",
    "start": "1693150",
    "end": "1699929"
  },
  {
    "text": "They have to be. They're the eigenvectors\nof an orthogonal matrix. Now, I could ask you--\nlet's keep going with this",
    "start": "1699930",
    "end": "1709320"
  },
  {
    "text": "and get the whole list here. Along with symmetric there\nis another bunch of guys.",
    "start": "1709320",
    "end": "1718320"
  },
  {
    "text": "Antisymmetric. Big deal, but those\nare important. So, symmetric means A transpose\nequals A. Diagonal you know.",
    "start": "1718320",
    "end": "1728220"
  },
  {
    "text": "A transpose equals A inverse\nfor orthogonal matrices.",
    "start": "1728220",
    "end": "1734110"
  },
  {
    "text": "Now, I'm going to put in\nantisymmetric matrices where A transpose\nis minus A. What",
    "start": "1734110",
    "end": "1745809"
  },
  {
    "text": "do you think you know\nabout the eigenvalues for antisymmetric matrices?",
    "start": "1745810",
    "end": "1751179"
  },
  {
    "text": " Shall we take a example?",
    "start": "1751180",
    "end": "1757190"
  },
  {
    "start": "1753000",
    "end": "1844000"
  },
  {
    "text": "Anti symmetric matrix.  Say 0, 0, 1, and minus 1.",
    "start": "1757190",
    "end": "1766440"
  },
  {
    "text": "What are the\neigenvalues of that? Well, if I subtract\nlambda from the diagonal",
    "start": "1766440",
    "end": "1776180"
  },
  {
    "text": "and take the determinant, I get\nlambda squared plus 1 equals 0.",
    "start": "1776180",
    "end": "1783460"
  },
  {
    "text": "So lambda is i or minus i. ",
    "start": "1783460",
    "end": "1790740"
  },
  {
    "text": "That's a rotation matrix.  It's a rotation\nthrough 90 degrees.",
    "start": "1790740",
    "end": "1798070"
  },
  {
    "text": "So there could not\nbe a real eigenvalue. Have you thought about that?",
    "start": "1798070",
    "end": "1804159"
  },
  {
    "text": "Or a real eigenvector. If I rotate every vector,\nhow could a vector",
    "start": "1804160",
    "end": "1809169"
  },
  {
    "text": "come out a multiple of itself? How could I have A transpose\ntimes the vector equal lambda",
    "start": "1809170",
    "end": "1819120"
  },
  {
    "text": "times a vector? I've rotated it and yet\nit's in the same direction.",
    "start": "1819120",
    "end": "1824169"
  },
  {
    "text": "Well, somehow that's\npossible in imaginary space",
    "start": "1824170",
    "end": "1832030"
  },
  {
    "text": "and not possible in real space. OK, so here the\nlambdas are imaginary.",
    "start": "1832030",
    "end": "1841940"
  },
  {
    "text": "And now finally,\ntell me if you know",
    "start": "1841940",
    "end": "1847059"
  },
  {
    "start": "1844000",
    "end": "1920000"
  },
  {
    "text": "the name of the whole\nfamily of matrices that",
    "start": "1847060",
    "end": "1852370"
  },
  {
    "text": "includes all of those and more. Of matrices with\northogonal eigenvectors.",
    "start": "1852370",
    "end": "1859810"
  },
  {
    "text": "So, what are the\nspecial properties then? These would be matrices. Shall I call them M for matrix?",
    "start": "1859810",
    "end": "1869470"
  },
  {
    "text": "So, it has orthogonal\neigenvectors. So it's Q times the\ndiagonal times Q transpose.",
    "start": "1869470",
    "end": "1877210"
  },
  {
    "text": " I've really written\ndown somehow--",
    "start": "1877210",
    "end": "1884010"
  },
  {
    "text": "I haven't written a\nname down for them but that's the way to get them.",
    "start": "1884010",
    "end": "1890159"
  },
  {
    "text": "I'm allowing any\northogonal eigenvectors.",
    "start": "1890160",
    "end": "1895870"
  },
  {
    "text": "So, this is diagonalized. I've diagonalized the matrix.",
    "start": "1895870",
    "end": "1901510"
  },
  {
    "text": "And here are any eigenvalues. So, the final guy on this\nlist allows any eigenvalues,",
    "start": "1901510",
    "end": "1909000"
  },
  {
    "text": "any complex numbers. But the eigenvectors, I\nwant to be orthogonal.",
    "start": "1909000",
    "end": "1916679"
  },
  {
    "text": "So that's why I have the Q. So, how would you\nrecognize such a matrix",
    "start": "1916680",
    "end": "1923620"
  },
  {
    "start": "1920000",
    "end": "2013000"
  },
  {
    "text": "and what is the name for them? We're going beyond\n18.06, because probably I",
    "start": "1923620",
    "end": "1931549"
  },
  {
    "text": "don't mention the name for these\nmatrices in 18.06, but I could.",
    "start": "1931550",
    "end": "1940200"
  },
  {
    "text": "Anybody know it? A matrix of that form\nis a normal matrix.",
    "start": "1940200",
    "end": "1949860"
  },
  {
    "text": "Normal. So, that's the total\nlist, is a normal matrix. ",
    "start": "1949860",
    "end": "1961870"
  },
  {
    "text": "So, normal matrices\nlook like that. ",
    "start": "1961870",
    "end": "1967760"
  },
  {
    "text": "I have to apologize for whoever\nthought up that name, normal. I mean that's like, OK.",
    "start": "1967760",
    "end": "1975155"
  },
  {
    "text": "A little more thought,\nyou could have come up with something more meaningful\nthan just, say, normal.",
    "start": "1975155",
    "end": "1981950"
  },
  {
    "text": "[INAUDIBLE] that's the\nabsolute opposite of normal. Almost all matrices\nare not normal.",
    "start": "1981950",
    "end": "1988670"
  },
  {
    "text": "So anyway, but that's\nwhat they're called. Normal matrices. And finally, how do you\nrecognize a normal matrix?",
    "start": "1988670",
    "end": "1997070"
  },
  {
    "text": "Everybody knows how to\nrecognize a symmetric matrix or a diagonal\nmatrix, and we even",
    "start": "1997070",
    "end": "2002410"
  },
  {
    "text": "know how to recognize an\northogonal matrix or skew or antisymmetric.",
    "start": "2002410",
    "end": "2007900"
  },
  {
    "text": "But what's the quick\ntest for a normal matrix? ",
    "start": "2007900",
    "end": "2013799"
  },
  {
    "text": "Well, I'll just tell you that\na normal matrix has M transpose",
    "start": "2013800",
    "end": "2020240"
  },
  {
    "text": "M equal M M transpose. ",
    "start": "2020240",
    "end": "2025970"
  },
  {
    "text": "I'm talking here\nabout real matrices and I really should\nmove to complex. But let me just think\nof them as real.",
    "start": "2025970",
    "end": "2034445"
  },
  {
    "text": " Well, the trouble is that\nthe matrices might be real",
    "start": "2034445",
    "end": "2041000"
  },
  {
    "text": "but the eigenvectors\nare not going to be real and the eigenvalues are\nnot going to be real.",
    "start": "2041000",
    "end": "2047130"
  },
  {
    "text": "So, really I-- I'm sorry to say really again-- I should get out of\nthe limitation to real.",
    "start": "2047130",
    "end": "2057090"
  },
  {
    "text": "Yeah. And how do I get out of\nthe limitation to real?",
    "start": "2057090",
    "end": "2062570"
  },
  {
    "text": "What do I change here if M\nis a complex matrix instead of a real matrix?",
    "start": "2062570",
    "end": "2068520"
  },
  {
    "text": "Then whenever you\ntranspose it you should take its\ncomplex conjugate.",
    "start": "2068520",
    "end": "2073879"
  },
  {
    "text": "So now that that's\nthe real thing. That's the normal thing,\nthat's the right thing.",
    "start": "2073880",
    "end": "2079750"
  },
  {
    "text": "Yeah, right thing. Better. OK, so that's a normal matrix.",
    "start": "2079750",
    "end": "2086010"
  },
  {
    "text": "And you can check\nthat if you took that M and you figured out\nM transpose and did that,",
    "start": "2086010",
    "end": "2095239"
  },
  {
    "text": "it would work. Because in the\nend the Q's cancel and you just have 2\ndiagonal matrices there",
    "start": "2095239",
    "end": "2105890"
  },
  {
    "text": "and that's sort of automatic,\nthat diagonal matrices commute.",
    "start": "2105890",
    "end": "2111200"
  },
  {
    "text": "So, a normal matrix is one that\ncommutes with its transpose.",
    "start": "2111200",
    "end": "2116359"
  },
  {
    "text": "Commutes with its\ntranspose or its conjugate transpose in the complex case.",
    "start": "2116360",
    "end": "2121849"
  },
  {
    "text": "OK, why did I say all that? Simply because--\noh, I guess that--",
    "start": "2121850",
    "end": "2130450"
  },
  {
    "text": "so the permutation\nP is orthogonal",
    "start": "2130450",
    "end": "2139280"
  },
  {
    "text": "so its eigenvectors, which\nwe're going to write down in a minute, are orthogonal.",
    "start": "2139280",
    "end": "2145100"
  },
  {
    "text": "But actually, this matrix\nC will be a normal matrix.",
    "start": "2145100",
    "end": "2151865"
  },
  {
    "start": "2151865",
    "end": "2158670"
  },
  {
    "text": "I didn't see that\ncoming as I started talking about these guys. Yeah, so that's a normal matrix.",
    "start": "2158670",
    "end": "2166380"
  },
  {
    "text": "Because circulant\nmatrices commute. Any 2 circulant\nmatrices commute.",
    "start": "2166380",
    "end": "2171410"
  },
  {
    "text": "C1 C2 equals C2 C1. ",
    "start": "2171410",
    "end": "2178160"
  },
  {
    "text": "And now if C2 is\nthe transpose of-- so, here's a matrix.",
    "start": "2178160",
    "end": "2184190"
  },
  {
    "text": "Yeah, so these\nare matrices here. ",
    "start": "2184190",
    "end": "2189710"
  },
  {
    "text": "Circulants all commute. It's a little\nfamily of matrices. When you multiply them\ntogether you get more of them.",
    "start": "2189710",
    "end": "2196660"
  },
  {
    "text": "You're just staying in\nthat little circulant world with n parameters.",
    "start": "2196660",
    "end": "2203060"
  },
  {
    "text": "And once you know the first row,\nyou know all the other rows. ",
    "start": "2203060",
    "end": "2210080"
  },
  {
    "text": "So in fact, they all have\nthe same eigenvectors. So, now let me be sure we get\nthe eigenvectors straight.",
    "start": "2210080",
    "end": "2220890"
  },
  {
    "text": "OK. ",
    "start": "2220890",
    "end": "2228819"
  },
  {
    "text": "OK, eigenvectors of P will\nalso be eigenvectors of C",
    "start": "2228820",
    "end": "2248320"
  },
  {
    "text": "because it's a combination\nof powers of P.",
    "start": "2248320",
    "end": "2262100"
  },
  {
    "start": "2262000",
    "end": "2301000"
  },
  {
    "text": "So once I find the\neigenvectors of P, I've found the eigenvectors\nof any circulant matrix.",
    "start": "2262100",
    "end": "2268430"
  },
  {
    "text": "And these eigenvectors\nare very special, and that's the\nconnection to Fourier. That's why-- we expect\na connection to Fourier",
    "start": "2268430",
    "end": "2276860"
  },
  {
    "text": "because we have\nsomething periodic. And that's what Fourier\nis entirely about.",
    "start": "2276860",
    "end": "2282650"
  },
  {
    "text": "OK, so what are\nthese eigenvectors? Let's take P to be 4 by 4.",
    "start": "2282650",
    "end": "2291800"
  },
  {
    "start": "2291800",
    "end": "2300110"
  },
  {
    "text": "OK, so the eigenvectors are-- so we remember, the\neigenvalues are lambda equal 1,",
    "start": "2300110",
    "end": "2307040"
  },
  {
    "start": "2301000",
    "end": "2461000"
  },
  {
    "text": "lambda equal minus\n1, lambda equal I, and lambda equal minus I. We've\ngot 4 eigenvectors to find",
    "start": "2307040",
    "end": "2315730"
  },
  {
    "text": "and when we find those,\nyou'll have the picture. OK, what's the eigenvector\nfor lambda equal 1?",
    "start": "2315730",
    "end": "2323876"
  },
  {
    "text": "STUDENT: 1, 1, 1, 1. GILBERT STRANG: 1, 1, 1, 1. So, let me make\nit into a vector.",
    "start": "2323876",
    "end": "2330340"
  },
  {
    "text": "And the eigenvector for\nlambda equal minus 1 is? So, I want this shift\nto change every sign.",
    "start": "2330340",
    "end": "2338869"
  },
  {
    "text": "So I better alternate those\nsigns so that if I shift it,",
    "start": "2338870",
    "end": "2346240"
  },
  {
    "text": "the 1 goes to the minus 1. Minus 1 goes to the 1. So the eigenvalue is minus 1.",
    "start": "2346240",
    "end": "2352880"
  },
  {
    "text": "Now, what about the\neigenvalues of i? Sorry, the eigenvector that\ngoes with eigenvalue i?",
    "start": "2352880",
    "end": "2360190"
  },
  {
    "text": " If I start it with 1 and\nI do the permutation,",
    "start": "2360190",
    "end": "2370640"
  },
  {
    "text": "I think I just want i, i\nsquared, i cubed there. And I think with this\nguy, with minus i,",
    "start": "2370640",
    "end": "2377970"
  },
  {
    "text": "I think I want the\nvector 1, minus i, minus i squared, minus i cubed.",
    "start": "2377970",
    "end": "2384980"
  },
  {
    "start": "2384980",
    "end": "2392810"
  },
  {
    "text": "So without stopping\nto check, let's just see the nice point here.",
    "start": "2392810",
    "end": "2400880"
  },
  {
    "text": "All the components\nof eigenvectors are in this picture.",
    "start": "2400880",
    "end": "2408410"
  },
  {
    "text": "Here we've got 8 eigenvectors. 8 eigenvalues, 8 eigenvectors. The eigenvectors\nhave 8 components",
    "start": "2408410",
    "end": "2415250"
  },
  {
    "text": "and every component is\none of these 8 numbers. The whole thing is constructed\nfrom the same 8 numbers.",
    "start": "2415250",
    "end": "2423300"
  },
  {
    "text": "The eigenvalues and\nthe eigenvectors. And really the\nkey point is, what",
    "start": "2423300",
    "end": "2429990"
  },
  {
    "text": "is the matrix of eigenvectors? So, let's just write that down.",
    "start": "2429990",
    "end": "2435210"
  },
  {
    "text": " So, the eigenvector matrix\nfor all circulants of size",
    "start": "2435210",
    "end": "2456320"
  },
  {
    "text": "N. They all have the same\neigenvectors, including",
    "start": "2456320",
    "end": "2466520"
  },
  {
    "start": "2461000",
    "end": "2507000"
  },
  {
    "text": "P. All circulants C of size\nN including P of size N.",
    "start": "2466520",
    "end": "2478710"
  },
  {
    "text": "So, what's the\neigenvector matrix? What are the eigenvectors?",
    "start": "2478710",
    "end": "2484319"
  },
  {
    "text": "Well, the first\nvector is all 1's.",
    "start": "2484320",
    "end": "2491490"
  },
  {
    "text": "Just as there. So, that's an\neigenvector of P, right?",
    "start": "2491490",
    "end": "2496950"
  },
  {
    "text": "Because if I multiply by P,\nI do a shift, a cyclic shift,",
    "start": "2496950",
    "end": "2504329"
  },
  {
    "text": "and I've got all 1's. The next eigenvector\nis powers of w.",
    "start": "2504330",
    "end": "2511860"
  },
  {
    "start": "2507000",
    "end": "2547000"
  },
  {
    "start": "2511860",
    "end": "2519760"
  },
  {
    "text": "And let me remind\nyou, everything is going to be powers of w. e to the 2 pi i over N.\nIt's that complex number",
    "start": "2519760",
    "end": "2530260"
  },
  {
    "text": "that's 1/n of the way around. So, what happens if\nI multiply that by P?",
    "start": "2530260",
    "end": "2536950"
  },
  {
    "text": "It shift it and it\nmultiplies by w or 1/w,",
    "start": "2536950",
    "end": "2544920"
  },
  {
    "text": "which is another eigenvector. OK, and then the next one in\nthis list will be going with w",
    "start": "2544920",
    "end": "2552960"
  },
  {
    "start": "2547000",
    "end": "2589000"
  },
  {
    "text": "squared. So it will be w fourth, w to\nthe sixth, w to the eighth.",
    "start": "2552960",
    "end": "2559570"
  },
  {
    "text": "Wait a minute, did I get\nthese lined up all right? w goes with w squared.",
    "start": "2559570",
    "end": "2565410"
  },
  {
    "text": "Whoops. ",
    "start": "2565410",
    "end": "2571609"
  },
  {
    "text": "w squared. Now it's w to the fourth, w\nthe sixth, w to the eighth,",
    "start": "2571610",
    "end": "2577550"
  },
  {
    "text": "w to the 10th, w to the\n12th, and w to the 14th. ",
    "start": "2577550",
    "end": "2585470"
  },
  {
    "text": "And they keep going.  So that's the eigenvector\nwith eigenvalue 1.",
    "start": "2585470",
    "end": "2593780"
  },
  {
    "start": "2589000",
    "end": "3156000"
  },
  {
    "text": "This will have the eigenvalue--\nit's either w or the conjugate, might be the conjugate, w bar.",
    "start": "2593780",
    "end": "2601280"
  },
  {
    "text": "And you see this matrix. So, what would be\nthe last eigenvector?",
    "start": "2601280",
    "end": "2607300"
  },
  {
    "text": "It would be w-- so this is 8 by 8.",
    "start": "2607300",
    "end": "2613100"
  },
  {
    "text": "I'm going to call that the\nFourier matrix of size 8. ",
    "start": "2613100",
    "end": "2619370"
  },
  {
    "text": "And it's the eigenvector matrix. So Fourier matrix equals\neigenvector matrix.",
    "start": "2619370",
    "end": "2630710"
  },
  {
    "start": "2630710",
    "end": "2638490"
  },
  {
    "text": "So, what I'm saying is\nthat the linear algebra for these circulants\nis fantastic.",
    "start": "2638490",
    "end": "2646970"
  },
  {
    "text": "They all have the same\neigenvector matrix. It happens to be the most\nimportant complex matrix",
    "start": "2646970",
    "end": "2652789"
  },
  {
    "text": "in the world and its\nproperties are golden.",
    "start": "2652790",
    "end": "2659090"
  },
  {
    "text": "And it allows the fast\nFourier transform, which we could write in\nmatrix language next time.",
    "start": "2659090",
    "end": "2666980"
  },
  {
    "text": "And all the entries\nare powers of w. All the entries are\non the unit circle",
    "start": "2666980",
    "end": "2676130"
  },
  {
    "text": "at one of those 8 points. And the last guy would be w to\nthe seventh, w to the 14th, w",
    "start": "2676130",
    "end": "2683780"
  },
  {
    "text": "to the 21st, 28th,\n35th, 42nd, and 49th.",
    "start": "2683780",
    "end": "2692345"
  },
  {
    "text": " So, w to the 49th\nwould be the last.",
    "start": "2692345",
    "end": "2700960"
  },
  {
    "text": "7 squared. It starts out with\nw to the 0 times 0.",
    "start": "2700960",
    "end": "2706349"
  },
  {
    "start": "2706350",
    "end": "2711880"
  },
  {
    "text": "You see that picture. w to the 49th.",
    "start": "2711880",
    "end": "2716890"
  },
  {
    "text": "What is actually w to the 49th? If w is the eighth root of 1,\nso we have w to the eighth,",
    "start": "2716890",
    "end": "2726600"
  },
  {
    "text": "it's 1 because I'm doing 8 by 8. What is w to the 49th power?",
    "start": "2726600",
    "end": "2733450"
  },
  {
    "text": " STUDENT: [INAUDIBLE] GILBERT STRANG: w? It's the same as w.",
    "start": "2733450",
    "end": "2739450"
  },
  {
    "text": "OK, because w to the\n48th is 1, right?",
    "start": "2739450",
    "end": "2747260"
  },
  {
    "text": "I take the sixth power of this\nand I get that w to the 48th is 1. So w to the 49th\nis the same as w.",
    "start": "2747260",
    "end": "2754861"
  },
  {
    "text": " Every column, every entry, in\nthe matrix is a power of w.",
    "start": "2754862",
    "end": "2764700"
  },
  {
    "text": "And in fact, that power\nis just the column number times the row number.",
    "start": "2764700",
    "end": "2770010"
  },
  {
    "text": "Yeah, so those are\nthe good matrices. ",
    "start": "2770010",
    "end": "2779860"
  },
  {
    "text": "So, that is an\northogonal matrix. Well, almost.",
    "start": "2779860",
    "end": "2785799"
  },
  {
    "text": "It has orthogonal\ncolumns but it doesn't have orthonormal columns. ",
    "start": "2785800",
    "end": "2793090"
  },
  {
    "text": "What's the length of\nthat column vector? STUDENT: [INAUDIBLE]",
    "start": "2793090",
    "end": "2798400"
  },
  {
    "text": "GILBERT STRANG: The\nsquare root of 8, right. I add up 1 squared 8 times\nand I take the square root,",
    "start": "2798400",
    "end": "2804270"
  },
  {
    "text": "I get to the square root of 8. So, this is really--",
    "start": "2804270",
    "end": "2809880"
  },
  {
    "text": "it's the square root of 8\ntimes an orthogonal matrix. ",
    "start": "2809880",
    "end": "2818670"
  },
  {
    "text": "Of course. The square root of\n8 is just a number to divide out to make the\ncolumns orthonormal instead",
    "start": "2818670",
    "end": "2829180"
  },
  {
    "text": "of just orthogonal. But how do I know that\nthose are orthogonal?",
    "start": "2829180",
    "end": "2835080"
  },
  {
    "text": "Well, I know they have to be\nbut I'd like to see it clearly. Why is that vector\northogonal to that vector?",
    "start": "2835080",
    "end": "2844049"
  },
  {
    "text": "First of all, they have to be. Because the matrix\nis a normal matrix.",
    "start": "2844050",
    "end": "2851220"
  },
  {
    "text": "Normal matrices\nhave orthogonal-- oh yeah, how do I know\nit's a normal matrix?",
    "start": "2851220",
    "end": "2858369"
  },
  {
    "text": "So, I guess I can do the test. ",
    "start": "2858370",
    "end": "2864840"
  },
  {
    "text": "If I have the permutation\nP, I know that P transpose P equals P P transpose.",
    "start": "2864840",
    "end": "2870790"
  },
  {
    "text": "The permutations commute. So, it's a normal matrix.",
    "start": "2870790",
    "end": "2877079"
  },
  {
    "text": "But I'd like to see\ndirectly why is the dot product of the first\nor the 0-th eigenvector",
    "start": "2877080",
    "end": "2885059"
  },
  {
    "text": "and the eigenvector equals 0? Let me take that dot product.",
    "start": "2885060",
    "end": "2890400"
  },
  {
    "text": "1 times 1 is 1. 1 times w is w. 1 times w squared is w squared.",
    "start": "2890400",
    "end": "2897960"
  },
  {
    "text": "Up to w to the seventh, I\nguess I'm going to finish at,",
    "start": "2897960",
    "end": "2903200"
  },
  {
    "text": "equals 0. ",
    "start": "2903200",
    "end": "2909610"
  },
  {
    "text": "Well, what's that saying? Those numbers are these points\nin my picture, those 8 points.",
    "start": "2909610",
    "end": "2924339"
  },
  {
    "text": "So, those are the 8 numbers\nthat go into that column of--",
    "start": "2924340",
    "end": "2930940"
  },
  {
    "text": "that eigenvector. Why do they add to 0? How do you see that the sum\nof those 8 numbers is 0?",
    "start": "2930940",
    "end": "2941599"
  },
  {
    "text": "STUDENT: There's symmetry. GILBERT STRANG: Yeah,\nthe symmetry would do it. When I add that guy to that guy,\nw to the 0, or w to the eighth,",
    "start": "2941600",
    "end": "2952110"
  },
  {
    "text": "or w to the 0. Yeah, when I add 1\nand minus 1, I get 0.",
    "start": "2952110",
    "end": "2957750"
  },
  {
    "text": "When I add these guys I get 0. When I add these-- by pairs.",
    "start": "2957750",
    "end": "2963420"
  },
  {
    "text": "But what about a 3 by 3? ",
    "start": "2963420",
    "end": "2974819"
  },
  {
    "text": "So, 3 by 3.  This would be e to\nthe 2 pi i over 3.",
    "start": "2974820",
    "end": "2983220"
  },
  {
    "text": "And then this would\nbe w to the 4 pi-- this would be w squared,\ne to the 4 pi i over 3.",
    "start": "2983220",
    "end": "2992250"
  },
  {
    "text": "And I believe that those\n3 vectors add to 0. ",
    "start": "2992250",
    "end": "2999200"
  },
  {
    "text": "And therefore they are\northogonal to the 1, 1, 1 eigenvector because\nthe dot product will just",
    "start": "2999200",
    "end": "3005460"
  },
  {
    "text": "want to add those 3 numbers. So why is that true? 1 plus e the 2 pi i over 3 plus\ne to the 4 pi over 3 equals 0.",
    "start": "3005460",
    "end": "3016830"
  },
  {
    "start": "3016830",
    "end": "3022260"
  },
  {
    "text": "Last minute of class today, we\ncan figure out how to do that.",
    "start": "3022260",
    "end": "3027420"
  },
  {
    "text": "Well, I could get\na formula for-- that sum is 1 and I\ncould get a closed form",
    "start": "3027420",
    "end": "3033240"
  },
  {
    "text": "and check that I\nget the answer 0. The quick way to see it is\nmaybe suppose I multiply by e",
    "start": "3033240",
    "end": "3044780"
  },
  {
    "text": "to the 2 pi i over 3. So, I multiply every term, so\nthat's e to the 2 pi i over 3.",
    "start": "3044780",
    "end": "3052730"
  },
  {
    "text": "e to the 4 pi i over 3. And e to the 6 pi i over 3.",
    "start": "3052730",
    "end": "3060530"
  },
  {
    "text": "OK, what do I learn from this? STUDENT: [INAUDIBLE] GILBERT STRANG: It's the same\nbecause e to the 6 pi i over 3",
    "start": "3060530",
    "end": "3067570"
  },
  {
    "text": "is? STUDENT: 1. GILBERT STRANG: Is 1. That's 2 pi i, so that's 1.",
    "start": "3067570",
    "end": "3074210"
  },
  {
    "text": "So I got the same sum,\n1 plus this plus this. This plus this plus 1.",
    "start": "3074210",
    "end": "3079369"
  },
  {
    "text": "So I got the same sum when\nI multiplied by that number.",
    "start": "3079370",
    "end": "3084710"
  },
  {
    "text": "And that sum has to be 0. I can't get the same sum-- I can't multiply by this\nand get the same answer",
    "start": "3084710",
    "end": "3092790"
  },
  {
    "text": "unless I'm multiplying 0. So that shows me that\nwhen n is odd I also have",
    "start": "3092790",
    "end": "3103520"
  },
  {
    "text": "those n numbers adding to 0. OK, those are the basic--",
    "start": "3103520",
    "end": "3108740"
  },
  {
    "text": "the beautiful picture\nof the eigenvalues,",
    "start": "3108740",
    "end": "3114410"
  },
  {
    "text": "the eigenvectors\nbeing orthogonal. And then the actual details here\nof what those eigenvectors are.",
    "start": "3114410",
    "end": "3124460"
  },
  {
    "text": "OK, good. Hope you have a good weekend,\nand we've just got a week",
    "start": "3124460",
    "end": "3130460"
  },
  {
    "text": "and a half left of class. I may probably have one more\nthing to do about Fourier",
    "start": "3130460",
    "end": "3137310"
  },
  {
    "text": "and then we'll come\nback to other topics. But ask any questions,\ntopics that you'd like to see",
    "start": "3137310",
    "end": "3145640"
  },
  {
    "text": "included here. We're closing out 18.065 while\nyou guys do the projects.",
    "start": "3145640",
    "end": "3153280"
  },
  {
    "text": "OK, thank you. ",
    "start": "3153280",
    "end": "3156357"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu.  GILBERT STRANG: OK, let\nme start one minute early.",
    "start": "18140",
    "end": "24750"
  },
  {
    "text": " So this being MIT, I just came\nfrom a terrific faculty member,",
    "start": "24750",
    "end": "35140"
  },
  {
    "text": "Andy Lo in the Sloan\nSchool, and I have",
    "start": "35140",
    "end": "41200"
  },
  {
    "text": "to tell you what he told us. And then I had to leave before\nhe could explain why it's true,",
    "start": "41200",
    "end": "48250"
  },
  {
    "text": "but this is like an amazing fact\nwhich I don't want to forget, so here you go.",
    "start": "48250",
    "end": "54730"
  },
  {
    "text": "Everything will\nbe on that board. So it's an observation about us\nor other people, maybe not us.",
    "start": "54730",
    "end": "66010"
  },
  {
    "text": "So suppose you\nhave a biased coin. Maybe the people playing\nthis game don't know,",
    "start": "66010",
    "end": "73870"
  },
  {
    "text": "but it's 75% likely\nto produce heads, 25% likely to produce tails.",
    "start": "73870",
    "end": "82180"
  },
  {
    "text": "And then the player has\nto guess for one flip",
    "start": "82180",
    "end": "87520"
  },
  {
    "text": "after another heads or tails,\nand you get $1 if you're right,",
    "start": "87520",
    "end": "96860"
  },
  {
    "text": "you pay $1 if you're wrong. So you just want to get\nas many right choices",
    "start": "96860",
    "end": "103700"
  },
  {
    "text": "as possible from this\ncoin flip that continues. So what should you do?",
    "start": "103700",
    "end": "111120"
  },
  {
    "text": "Well what I hope we\nwould do is we would not",
    "start": "111120",
    "end": "118370"
  },
  {
    "text": "know what the probabilities\nwere, so we would guess maybe",
    "start": "118370",
    "end": "123740"
  },
  {
    "text": "heads the first time,\ntails the second time, heads the third time, and so on.",
    "start": "123740",
    "end": "130590"
  },
  {
    "text": "But the actual result\nwould be mostly heads, so we would learn at some point\nthat-- maybe not quite as soon",
    "start": "130590",
    "end": "140520"
  },
  {
    "text": "as that. We would eventually\nlearn that we should keep guessing heads, right?",
    "start": "140520",
    "end": "146610"
  },
  {
    "text": "And that would be\nour optimal strategy, to guess heads all the time.",
    "start": "146610",
    "end": "152500"
  },
  {
    "text": "But what do people actually do? They start like\nthis, the same way,",
    "start": "152500",
    "end": "163950"
  },
  {
    "text": "and then they're\nbeginning to learn that heads is more common. So maybe they do more\nheads than tails,",
    "start": "163950",
    "end": "175459"
  },
  {
    "text": "but sometimes tails is right,\nand then after a little while, they maybe see that it's-- yeah.",
    "start": "175460",
    "end": "184430"
  },
  {
    "text": "Well maybe they're not\ncounting, they're just operating like ordinary people.",
    "start": "184430",
    "end": "191060"
  },
  {
    "text": "And what do ordinary people\nactually do in the long run?",
    "start": "191060",
    "end": "196270"
  },
  {
    "text": "You would think guess\nheads every time, right? But they don't.",
    "start": "196270",
    "end": "202530"
  },
  {
    "text": "In the long run, people\nand maybe animals and whatever guess heads three\nquarters of the time and tails",
    "start": "202530",
    "end": "211740"
  },
  {
    "text": "one quarter of the time. Isn't that unbelievable? They're guessing tails\na quarter of the time",
    "start": "211740",
    "end": "218040"
  },
  {
    "text": "when the odds are\nnever changing. Anyway, that's something that\neconomists and other people",
    "start": "218040",
    "end": "228000"
  },
  {
    "text": "have to explain, and if I had\nbeen able to stay another hour, I could tell you\nabout the explanation.",
    "start": "228000",
    "end": "234230"
  },
  {
    "text": " Oh, I see I've written\nthat on a board that I have no way to bury,\nso it's going to be there,",
    "start": "234230",
    "end": "242440"
  },
  {
    "text": "and it's not the\nsubject of 18.065 but it's kind of amazing.",
    "start": "242440",
    "end": "249060"
  },
  {
    "text": "All right, so there's good\nmath problems everywhere. OK. Can I just leave you with what\nI know, and if I learn more,",
    "start": "249060",
    "end": "260338"
  },
  {
    "text": "I'll come back to that question. OK. Please turn attention\nthis way, right?",
    "start": "260339",
    "end": "268630"
  },
  {
    "text": "Norms. A few words on norms,\nlike that should be a word in your language.",
    "start": "268630",
    "end": "275729"
  },
  {
    "text": "And so you should\nknow what it means and you should know a few\nof the important norms.",
    "start": "275730",
    "end": "281610"
  },
  {
    "text": "Again, a norm is\na way to measure the size of a vector or the\nsize of a matrix or the size",
    "start": "281610",
    "end": "289740"
  },
  {
    "text": "of a tensor, whatever we have. Or a function. Very important. A norm would be a\nfunction like sine x.",
    "start": "289740",
    "end": "298800"
  },
  {
    "text": "From 0 to pi, what would be\nthe size of that function? Well if it was 2 sine x, the\nsize would be twice as much,",
    "start": "298800",
    "end": "306970"
  },
  {
    "text": "so the norm should reflect that. ",
    "start": "306970",
    "end": "312900"
  },
  {
    "text": "So yesterday, or Wednesday,\nI told you that-- so p equals 2, 1,\nactually infinity,",
    "start": "312900",
    "end": "325050"
  },
  {
    "text": "and then I'm going to put in\nthe 0 norm with a question mark because you'll see\nthat it has a problem.",
    "start": "325050",
    "end": "333270"
  },
  {
    "text": "But let me just\nrecall from last time. So p equal to 2 is the usual\nsum of squares square root.",
    "start": "333270",
    "end": "343110"
  },
  {
    "text": "Usual length of a vector. p equal 1 is this\nvery important norm,",
    "start": "343110",
    "end": "350850"
  },
  {
    "text": "so I would call\nthat the l1 norm, and we'll see a lot of that.",
    "start": "350850",
    "end": "358690"
  },
  {
    "text": "I mentioned that it plays\na very significant part now in compressed sensing.",
    "start": "358690",
    "end": "363730"
  },
  {
    "text": "It really was a bombshell in\nsignal processing to discover--",
    "start": "363730",
    "end": "369010"
  },
  {
    "text": "and in other fields,\ntoo-- to discover that some things really\nwork best in the l1 norm.",
    "start": "369010",
    "end": "377220"
  },
  {
    "text": "The maximum norm has a\nnatural part to play, and we'll see that,\nor its matrix analog.",
    "start": "377220",
    "end": "386410"
  },
  {
    "text": "So I didn't mention the l0 norm. All this lp business.",
    "start": "386410",
    "end": "391810"
  },
  {
    "text": "So the lp norm, for any p,\nis you take the pth power--",
    "start": "391810",
    "end": "401605"
  },
  {
    "text": " to the pth power.",
    "start": "401605",
    "end": "407380"
  },
  {
    "text": "Up here, p was 2. And you take the pth root. So maybe I should\nwrite it to the 1/p.",
    "start": "407380",
    "end": "414700"
  },
  {
    "text": " Then that way, taking\npth powers and pth",
    "start": "414700",
    "end": "420819"
  },
  {
    "text": "roots, we do get the\nnorm of 2v has a factor 2 compared to the norm of v.",
    "start": "420820",
    "end": "428050"
  },
  {
    "text": "So p equal to 2, you see it. We've got it right there. p equal 1, you see it\nhere because it's just",
    "start": "428050",
    "end": "435320"
  },
  {
    "text": "the sum of the absolute values. p equal to infinity,\nif I move p up",
    "start": "435320",
    "end": "440830"
  },
  {
    "text": "and up and up, it\nwill pick out-- as I increase p,\nwhichever one is biggest",
    "start": "440830",
    "end": "447490"
  },
  {
    "text": "is going to just\ntake over, and that's why you get the max norm. Now the zero norm, where I'm\nusing that word improperly,",
    "start": "447490",
    "end": "457330"
  },
  {
    "text": "as you'll see. So what is the zero norm? ",
    "start": "457330",
    "end": "464766"
  },
  {
    "text": "So let me write it\n[INAUDIBLE] It's",
    "start": "464766",
    "end": "470199"
  },
  {
    "text": "the number of\nnon-zero components.",
    "start": "470200",
    "end": "479420"
  },
  {
    "start": "479420",
    "end": "484970"
  },
  {
    "text": "It's the thing that\nyou'd like to know about in question of sparsity.",
    "start": "484970",
    "end": "490100"
  },
  {
    "text": "Is there just one\nnon-zero component? Are there 11? Are there 101?",
    "start": "490100",
    "end": "496880"
  },
  {
    "text": "That you might want to minimize\nthat because sparse vectors",
    "start": "496880",
    "end": "502940"
  },
  {
    "text": "and sparse matrices are\nmuch faster to compute with. You've got good stuff. But now I claim that's\nnot a norm, the number",
    "start": "502940",
    "end": "510200"
  },
  {
    "text": "of non-zero components,\nbecause how does the norm of 2v",
    "start": "510200",
    "end": "518640"
  },
  {
    "text": "compare with the norm\nof v, the zero norm? It would be the same.",
    "start": "518640",
    "end": "523849"
  },
  {
    "text": "2v has the same number\nof non-zeros as v. So it violates the\nrule for a norm.",
    "start": "523850",
    "end": "531020"
  },
  {
    "text": "So I think with these norms\nand all the p's in between--",
    "start": "531020",
    "end": "540290"
  },
  {
    "text": "so actually, the math\npapers are full of, let p be between 1 and\ninfinity, because that's",
    "start": "540290",
    "end": "548180"
  },
  {
    "text": "the range where you do have a\nproper norm, as we will see. I think the good thing\nto do with these norms is",
    "start": "548180",
    "end": "556760"
  },
  {
    "text": "to have a picture in your mind. The geometry of a norm is good.",
    "start": "556760",
    "end": "561900"
  },
  {
    "text": "So the picture I'm\ngoing to suggest is, plot all the\nvectors, let's say in 2D.",
    "start": "561900",
    "end": "569050"
  },
  {
    "text": "So two-dimensional space, R2. So I want to plot the\nvectors that have v equal 1",
    "start": "569050",
    "end": "580750"
  },
  {
    "text": "in these different norms. So let me ask you-- so here's 2D space,\nR2, and now I",
    "start": "580750",
    "end": "590350"
  },
  {
    "text": "want to plot all the vectors\nthat their ordinary l2 lengths",
    "start": "590350",
    "end": "596589"
  },
  {
    "text": "equal 1. So what does that\npicture look like? I just think a picture is\nreally worth something.",
    "start": "596590",
    "end": "603010"
  },
  {
    "text": "It's a circle, thanks. It's a circle. It's a circle. This circle has the\nequation, of course,",
    "start": "603010",
    "end": "610380"
  },
  {
    "text": "v1 squared plus v2\nsquared equal 1. ",
    "start": "610380",
    "end": "618006"
  },
  {
    "text": "So I would call that the\nunit ball for the norm or whatever is a circle.",
    "start": "618006",
    "end": "626660"
  },
  {
    "text": "OK, now here comes\nmore interesting. What about in the l1, though?",
    "start": "626660",
    "end": "631949"
  },
  {
    "text": " So again, tell me how to\nplot all the points that",
    "start": "631950",
    "end": "641060"
  },
  {
    "text": "have v1 plus v2 equal 1.",
    "start": "641060",
    "end": "646130"
  },
  {
    "text": "What's the boundary\ngoing to look like now? It's going to be, let's see.",
    "start": "646130",
    "end": "651840"
  },
  {
    "text": "Well I can put down a\ncertain number of points. There up at 1 and there at 1\nand there at minus 1 and there",
    "start": "651840",
    "end": "658980"
  },
  {
    "text": "at minus 1. That would reflect the\nvector 1, 0 and this",
    "start": "658980",
    "end": "664920"
  },
  {
    "text": "would reflect the\nvector 0, minus 1. So yeah.",
    "start": "664920",
    "end": "670860"
  },
  {
    "text": "OK. So those are like four\npoints easy to plot. Easy to see the l1 norm.",
    "start": "670860",
    "end": "678570"
  },
  {
    "text": "But what's the rest\nof the boundary here?",
    "start": "678570",
    "end": "686250"
  },
  {
    "text": "It's a diamond, good. It's a diamond. We have linear set equal to 1.",
    "start": "686250",
    "end": "695580"
  },
  {
    "text": "Up here in the\npositive quadrant, it's just v1 plus v2 equal\nto 1, and the graph of that",
    "start": "695580",
    "end": "701459"
  },
  {
    "text": "is a straight line.  So all these guys--\nthis is all the points",
    "start": "701460",
    "end": "708000"
  },
  {
    "text": "with v1 plus v2 equal 1. And over here and over\nhere and over here.",
    "start": "708000",
    "end": "715300"
  },
  {
    "text": "So the unit ball in the\nl1 norm is a diamond.",
    "start": "715300",
    "end": "721649"
  },
  {
    "text": "And that's a very\nimportant picture. It reflects in a very\nsimple way something",
    "start": "721650",
    "end": "729060"
  },
  {
    "text": "important about the\nl1 norm and the reason it's just exploded\nin importance.",
    "start": "729060",
    "end": "736090"
  },
  {
    "text": "Let me continue, though. What about the max norm? v max or v infinity equal to 1.",
    "start": "736090",
    "end": "743910"
  },
  {
    "text": "So again, let me\nplot these guys, and these guys are certainly\ngoing to be in it again",
    "start": "743910",
    "end": "751810"
  },
  {
    "text": "because 0 [INAUDIBLE] plus or\nminus i and plus or minus j",
    "start": "751810",
    "end": "757260"
  },
  {
    "text": "are good friends. What's the rest of the\nboundary look like now?",
    "start": "757260",
    "end": "762649"
  },
  {
    "text": "Now this means max of\nthe v's equal to 1.",
    "start": "762650",
    "end": "772260"
  },
  {
    "text": "So what are the\nrest of the points? ",
    "start": "772260",
    "end": "777720"
  },
  {
    "text": "You see, it does take a little\nthought, but then you get it and you don't forget it.",
    "start": "777720",
    "end": "783520"
  },
  {
    "text": "OK, so what's up? I'm looking.",
    "start": "783520",
    "end": "789550"
  },
  {
    "text": "So suppose the maximum is v1. I think it's going to look like\nthat, out to 1, 0 and up to 0,",
    "start": "789550",
    "end": "806100"
  },
  {
    "text": "1. And up here, the vector\nwould be 1.4 or something,",
    "start": "806100",
    "end": "816380"
  },
  {
    "text": "so the maximum would be 1. Is that OK? So somehow, what really sees,\nas you change this number p,",
    "start": "816380",
    "end": "825920"
  },
  {
    "text": "you start with p equal\nto 1, or a diamond, and it kind of swells out to\nbe a circle at p equal to 2,",
    "start": "825920",
    "end": "835640"
  },
  {
    "text": "and then it kind\nof keeps swelling to be a square and\np equal to infinity.",
    "start": "835640",
    "end": "843200"
  },
  {
    "text": "That's an interesting thing. And yeah. ",
    "start": "843200",
    "end": "849050"
  },
  {
    "text": "Now what's the problem\nwith the zero norm? ",
    "start": "849050",
    "end": "855510"
  },
  {
    "text": "This is the number of non-zeros. ",
    "start": "855510",
    "end": "861250"
  },
  {
    "text": "OK, let me draw it. Where are the points\nwith one non-zero?",
    "start": "861250",
    "end": "866410"
  },
  {
    "text": " So I'm plotting the unit ball.",
    "start": "866410",
    "end": "873760"
  },
  {
    "text": "Where are the vectors in this\nthing that have one non-zero?",
    "start": "873760",
    "end": "879850"
  },
  {
    "text": "Not zero non-zero. So that's not included. ",
    "start": "879850",
    "end": "888550"
  },
  {
    "text": "So what do I have? I'm not allowed\nthe vector 1/3, 2/3",
    "start": "888550",
    "end": "893920"
  },
  {
    "text": "because that has two\nnon-zeros, so where are the points with\nonly one non-zero?",
    "start": "893920",
    "end": "901019"
  },
  {
    "text": "Yeah, on the axes, yeah. That tells you. So it can be there and there.",
    "start": "901020",
    "end": "908250"
  },
  {
    "text": "Oops, without that guy. And of course those\njust keep going out.",
    "start": "908250",
    "end": "913950"
  },
  {
    "text": "So it totally violates the-- ",
    "start": "913950",
    "end": "920400"
  },
  {
    "text": "so maybe the point that I should\nmake about these figures--",
    "start": "920400",
    "end": "926140"
  },
  {
    "text": "so like, what's happening? When I go down to zero-- and really, that figure should\nbe at the other end, right?",
    "start": "926140",
    "end": "933930"
  },
  {
    "text": "Oh no, shoot. This guy's in the middle. This is a badly drawn figure.",
    "start": "933930",
    "end": "940860"
  },
  {
    "text": "l2 is kind of the center guy. l1 is at one end, l infinity\nis at the other end,",
    "start": "940860",
    "end": "948210"
  },
  {
    "text": "and this one has gone off\nthe end at the left there.",
    "start": "948210",
    "end": "953700"
  },
  {
    "text": "The diamond has-- yeah,\nwhat's happened here, as that one goes down towards\nzero, none of these will be OK.",
    "start": "953700",
    "end": "962340"
  },
  {
    "text": "These balls or these\nsets will lose weight.",
    "start": "962340",
    "end": "969780"
  },
  {
    "text": " So they'll always\nhave these points in,",
    "start": "969780",
    "end": "975080"
  },
  {
    "text": "but they'll be like this and\nthen like this and then finally in the unacceptable\nlimit, but none of those--",
    "start": "975080",
    "end": "984079"
  },
  {
    "text": "this was not any good either. This was for people\nequal 1/2, let's say. ",
    "start": "984080",
    "end": "991820"
  },
  {
    "text": "That's a p equal to 1/2\nand that's not a good norm. Yeah. So maybe the property of\nthe circle, the diamond,",
    "start": "991820",
    "end": "1004190"
  },
  {
    "text": "and the square, which is a nice\nmath property of those three",
    "start": "1004190",
    "end": "1011420"
  },
  {
    "text": "sets and is not\npossessed by this.",
    "start": "1011420",
    "end": "1017139"
  },
  {
    "text": "As this thing loses weight,\nI lose the property. And then of course it's\ntotally lost over there.",
    "start": "1017140",
    "end": "1023650"
  },
  {
    "text": "Do you know what that\nproperty would be? It's what? Concave, convex.",
    "start": "1023650",
    "end": "1029390"
  },
  {
    "text": "Convex, I would say. Convex.  This is a true norm\nas the convex unit.",
    "start": "1029390",
    "end": "1041970"
  },
  {
    "text": "Well maybe for ball, I'm taking\nall the v's less or equal to 1.",
    "start": "1041970",
    "end": "1048970"
  },
  {
    "text": "Yeah, so I'm allowing the\ninsides of these shapes. So this is not a convex set.",
    "start": "1048970",
    "end": "1055279"
  },
  {
    "text": "That set, which I should maybe-- so not convex would\nbe this one like so.",
    "start": "1055280",
    "end": "1068330"
  },
  {
    "text": "And that reflects the fact\nthat the rules for a norm",
    "start": "1068330",
    "end": "1074679"
  },
  {
    "text": "are broken in the triangle. Inequality is probably\nbroken in the--",
    "start": "1074680",
    "end": "1080230"
  },
  {
    "text": "other stuff, yeah. I think that's sort\nof worth remembering.",
    "start": "1080230",
    "end": "1086210"
  },
  {
    "text": "And then one more norm that's\nnatural to think about is--",
    "start": "1086210",
    "end": "1100480"
  },
  {
    "text": "so S, as in the\nPiazza question, S does always represent a\nsymmetric matrix in 18.065.",
    "start": "1100480",
    "end": "1110030"
  },
  {
    "text": "And now my norm is going to be-- so I'm going to\ncall it the S norm.",
    "start": "1110030",
    "end": "1116840"
  },
  {
    "text": "So actually, it's a positive\ndefinite symmetric matrix. S is a positive definite\nsymmetric matrix.",
    "start": "1116840",
    "end": "1124400"
  },
  {
    "text": "And what do I do? I'll take v transpose Sv. ",
    "start": "1124400",
    "end": "1133919"
  },
  {
    "text": "OK, what's our word for that? The energy. That's the energy in\nthe vector v. And I'll",
    "start": "1133920",
    "end": "1140540"
  },
  {
    "text": "take the square root so that\nI now have the length of two",
    "start": "1140540",
    "end": "1150270"
  },
  {
    "text": "if I double v, from v to 2v. Then I got a 2\nhere and a 2 here,",
    "start": "1150270",
    "end": "1155420"
  },
  {
    "text": "and when I take the square\nroot, I get a overall 2 and that's what I want. I want the norm to grow\nlinearly with the two or three",
    "start": "1155420",
    "end": "1164960"
  },
  {
    "text": "or whatever I multiply by. But what is the\nshape of this thing?",
    "start": "1164960",
    "end": "1170720"
  },
  {
    "text": "So what is the shape of--",
    "start": "1170720",
    "end": "1176539"
  },
  {
    "text": "let me put it on this board. I'm going to get a\npicture like that. So what is the shape of v\ntranspose Sv equal 1 or less",
    "start": "1176540",
    "end": "1191960"
  },
  {
    "text": "or equal 1?  This is a symmetric\npositive definite.",
    "start": "1191960",
    "end": "1199630"
  },
  {
    "text": "People use those three\nletters to tell us. I'm claiming that we\nget a bunch of norms.",
    "start": "1199630",
    "end": "1206780"
  },
  {
    "text": "When do we get the l2 norm? What matrix S would this\ngive us the l2 norm?",
    "start": "1206780",
    "end": "1215290"
  },
  {
    "text": "The identity, certainly. Now what's going to happen if\nI use some different matrix S?",
    "start": "1215290",
    "end": "1221260"
  },
  {
    "text": "This circle is going\nto change shape. I might have a different\nnorm, depending on S.",
    "start": "1221260",
    "end": "1228770"
  },
  {
    "text": "And a typical case would\nbe S equal 2, 3, say.",
    "start": "1228770",
    "end": "1233970"
  },
  {
    "text": " That's a positive\ndefinite symmetric matrix.",
    "start": "1233970",
    "end": "1240500"
  },
  {
    "text": "And now I would be drawing the\ngraph of 2v1 squared plus 3v2",
    "start": "1240500",
    "end": "1248160"
  },
  {
    "text": "squared. That would be the energy, right? Equal 1. And I just want you to\ntell me what shape that is.",
    "start": "1248160",
    "end": "1256190"
  },
  {
    "text": "So that's a perfectly\ngood norm that you could check all its properties.",
    "start": "1256190",
    "end": "1261830"
  },
  {
    "text": "They all come out easily. But I get a new picture-- a new norm that's\nkind of adjustable.",
    "start": "1261830",
    "end": "1269570"
  },
  {
    "text": "You could say it's\na weighted norm. Weights mean that\nyou kind of have picked some numbers\nsort of appropriate",
    "start": "1269570",
    "end": "1276440"
  },
  {
    "text": "to the particular problem. Well, suppose those\nnumbers are 2 and 3. What shape is the unit\nball in this S norm?",
    "start": "1276440",
    "end": "1286440"
  },
  {
    "text": "It's an ellipse, right. It's an ellipse. And I guess it\nwill actually be--",
    "start": "1286440",
    "end": "1292050"
  },
  {
    "text": "so the larger\nnumber, 3, will mean you can't go as far as\nthe smaller number, 2.",
    "start": "1292050",
    "end": "1299180"
  },
  {
    "text": "I think it would probably\nbe an ellipse like this, and the axes length\nof the ellipse",
    "start": "1299180",
    "end": "1306690"
  },
  {
    "text": "would probably have something\nto do with the 2 and the 3. OK, so now you know really\nall the vector norms that",
    "start": "1306690",
    "end": "1316940"
  },
  {
    "text": "are sort of naturally used. These come up in a natural way.",
    "start": "1316940",
    "end": "1324950"
  },
  {
    "text": "As we said, the identity matrix\nbrings us back to the two norm.",
    "start": "1324950",
    "end": "1330039"
  },
  {
    "text": "So these are all sort of\nvariations on the two norm. And these are variations\nas p runs from 1 up to 2",
    "start": "1330040",
    "end": "1340950"
  },
  {
    "text": "on to infinity and is not\nallowed to go below 1.",
    "start": "1340950",
    "end": "1346659"
  },
  {
    "text": "OK, that's norms.  And then maybe you can actually\nsee from this picture--",
    "start": "1346660",
    "end": "1354740"
  },
  {
    "text": "here is a, like,\nsomewhat hokey idea",
    "start": "1354740",
    "end": "1361150"
  },
  {
    "text": "of why it is that minimizing\nthe area in this norm--",
    "start": "1361150",
    "end": "1369310"
  },
  {
    "text": "so what do I mean by that? Here would be a typical problem.",
    "start": "1369310",
    "end": "1375700"
  },
  {
    "text": "Minimize, subject to\nAx equal b, the l2--",
    "start": "1375700",
    "end": "1385460"
  },
  {
    "text": "sorry, I'm using x now-- the l1 norm of x.",
    "start": "1385460",
    "end": "1391980"
  },
  {
    "text": " So that would be an\nimportant problem.",
    "start": "1391980",
    "end": "1399560"
  },
  {
    "text": "Actually, it has a name. People have spent a lot of\ntime thinking of a fast way to solve it.",
    "start": "1399560",
    "end": "1405200"
  },
  {
    "text": "It's almost like least squares. What would make it more\nlike least squares would be,",
    "start": "1405200",
    "end": "1411500"
  },
  {
    "text": "change that to 2.  Yeah.",
    "start": "1411500",
    "end": "1417860"
  },
  {
    "text": "Can I just sort of sketch,\nwithout making a big argument",
    "start": "1417860",
    "end": "1423410"
  },
  {
    "text": "here, the difference\nbetween l equal 1 or 2 here.",
    "start": "1423410",
    "end": "1429480"
  },
  {
    "text": "Yeah, I'll just draw a picture. Now I'll erase this ellipse,\nbut you won't forget.",
    "start": "1429480",
    "end": "1436580"
  },
  {
    "text": "OK. So this is our problem.",
    "start": "1436580",
    "end": "1442030"
  },
  {
    "text": "With l1, it has a famous\nname, basis pursuit. Well famous to people\nwho work in optimization.",
    "start": "1442030",
    "end": "1449920"
  },
  {
    "text": "For l2, it has an\nimportant name. Well it's sort of\nlike least squares.",
    "start": "1449920",
    "end": "1456340"
  },
  {
    "text": "Ridge regression. This is like a\nbeautiful model problem.",
    "start": "1456340",
    "end": "1463000"
  },
  {
    "text": "Among all solutions\nto Ax, suppose this is just one\nequation, like c1x1 plus",
    "start": "1463000",
    "end": "1471220"
  },
  {
    "text": "c2x2 equals some right side, b. So the constraint says that the\nvectors x have to be on a line.",
    "start": "1471220",
    "end": "1483500"
  },
  {
    "text": "Suppose that's a\ngraph of that line. So among all these\nx's, which one--",
    "start": "1483500",
    "end": "1491510"
  },
  {
    "text": "oh, I'm realizing what I'm going\nto say is going to be smart.",
    "start": "1491510",
    "end": "1496880"
  },
  {
    "text": "I mean, it's going to be nice. Not going to be difficult. Let's\ndo the one we know best, l2.",
    "start": "1496880",
    "end": "1505850"
  },
  {
    "text": "So here's a picture of the line. Let me make it a little\nmore tilted so you--",
    "start": "1505850",
    "end": "1511380"
  },
  {
    "text": " yeah, like 2, 3.",
    "start": "1511380",
    "end": "1519470"
  },
  {
    "text": "OK. This is the xy plane. Here's x1, here's x2.",
    "start": "1519470",
    "end": "1525320"
  },
  {
    "text": "Here are the points that\nsatisfy my condition. Which point on that\nline minimizes--",
    "start": "1525320",
    "end": "1533780"
  },
  {
    "text": "has the smallest l2 norm? Which point on the line\nhas the smallest l2 norm?",
    "start": "1533780",
    "end": "1543919"
  },
  {
    "text": "Yeah, you're drawing the\nright figure with your hands.",
    "start": "1543920",
    "end": "1548990"
  },
  {
    "text": "The smallest l2 norm-- l2, remember, is just\nhow far out you go.",
    "start": "1548990",
    "end": "1555160"
  },
  {
    "text": "It's circular here, so it\ndoesn't matter what direction. They're all giving the same\nl2 norm, it's just how far.",
    "start": "1555160",
    "end": "1562740"
  },
  {
    "text": "So we're looking for the\nclosest point on the line because we don't want\nto go any further.",
    "start": "1562740",
    "end": "1568720"
  },
  {
    "text": "We want to go a\nminimum distance with-- I'm doing l2 now. ",
    "start": "1568720",
    "end": "1576850"
  },
  {
    "text": "So where is the point\nat minimum distance? Yeah, just show me again once\nmore, with hands or whatever.",
    "start": "1576850",
    "end": "1583800"
  },
  {
    "text": "It'll be that. I didn't want 45\ndegree angles there.",
    "start": "1583800",
    "end": "1589840"
  },
  {
    "text": "I'm going to erase\nit again and really-- this time, I'm\ngoing to get angles",
    "start": "1589840",
    "end": "1596200"
  },
  {
    "text": "that are not 45 [INAUDIBLE]\nAll right, brilliant.",
    "start": "1596200",
    "end": "1602889"
  },
  {
    "text": "Got it. OK, that's my line. OK, and what's the nearest\npoint in the l2 norm?",
    "start": "1602890",
    "end": "1608430"
  },
  {
    "text": "Here's the winner in l2, right? The nearest point.",
    "start": "1608430",
    "end": "1613870"
  },
  {
    "text": "Everybody sees that picture? So that's a basic picture\nfor minimizing something",
    "start": "1613870",
    "end": "1624380"
  },
  {
    "text": "with a constraint, which\nis the fundamental problem of optimization, of neural\nnets, of everything, really.",
    "start": "1624380",
    "end": "1632600"
  },
  {
    "text": "Of life. Well I'm getting philosophical. ",
    "start": "1632600",
    "end": "1639750"
  },
  {
    "text": "But the question always is,\nand maybe it's true in life, too, which norm are you using?",
    "start": "1639750",
    "end": "1646690"
  },
  {
    "text": "OK, now that was\nthe minimum in l2.",
    "start": "1646690",
    "end": "1654639"
  },
  {
    "text": "That's the shortest\ndistance, where distance means what we usually\nthink of it as meaning.",
    "start": "1654640",
    "end": "1660429"
  },
  {
    "text": "But now, let's go\nfor the l1 norm. Which point on the line\nhas the smallest l1 norm?",
    "start": "1660430",
    "end": "1669830"
  },
  {
    "text": "So now I'm going to add the 2. So if this is some\npoint a, 0 and this",
    "start": "1669830",
    "end": "1680050"
  },
  {
    "text": "is some point 0, b right there. So those two points are\nobviously important.",
    "start": "1680050",
    "end": "1687030"
  },
  {
    "text": "And that point, we\ncould figure out the formula for because we\nknow what the geometry is.",
    "start": "1687030",
    "end": "1694559"
  },
  {
    "text": "But I've just put\nthose two points in. So did I get a 0, b? Yeah, that's a zero.",
    "start": "1694560",
    "end": "1702790"
  },
  {
    "text": "So let me just ask\nyou the question. What point on that line\nhas the smallest l1 norm?",
    "start": "1702790",
    "end": "1708590"
  },
  {
    "text": "Which has the smallest l1 norm?  Somebody said it.",
    "start": "1708590",
    "end": "1714190"
  },
  {
    "text": "Just say it a little louder so\nthat you're on tape forever. ",
    "start": "1714190",
    "end": "1720130"
  },
  {
    "text": "AUDIENCE: 0, b. GILBERT STRANG:\n0, b, this point. That's the winner.",
    "start": "1720130",
    "end": "1725500"
  },
  {
    "text": "This is the l1 winner and\nthis was the l2 winner.",
    "start": "1725500",
    "end": "1731440"
  },
  {
    "text": " And notice what I said earlier,\nand I didn't see it coming,",
    "start": "1731440",
    "end": "1738800"
  },
  {
    "text": "but now I realize this is a\nfigure to put in the notes. The winner has the most zeros.",
    "start": "1738800",
    "end": "1747920"
  },
  {
    "text": "It's the [? sparsest ?] vector. Well out of two components,\nit didn't have much freedom,",
    "start": "1747920",
    "end": "1754500"
  },
  {
    "text": "but it has a zero component. It's on the axes.",
    "start": "1754500",
    "end": "1763950"
  },
  {
    "text": "It's the things on the\naxes that have the smallest number of components. So yeah, this is the\npicture in two dimensions.",
    "start": "1763950",
    "end": "1776780"
  },
  {
    "text": "So I'm in 2D. And you can see that the winner\nhas a zero component, yeah.",
    "start": "1776780",
    "end": "1782850"
  },
  {
    "text": " And that's a fact that extends\ninto higher dimensions too",
    "start": "1782850",
    "end": "1791040"
  },
  {
    "text": "and that makes the l1 norm\nspecial, as I've said. Yeah. Is there more to say\nabout that example?",
    "start": "1791040",
    "end": "1800130"
  },
  {
    "text": "For a simple 2D question,\nthat really makes the point",
    "start": "1800130",
    "end": "1807040"
  },
  {
    "text": "that the l1 winner is there. It's not further. You don't go further\nup the line, right? Because that's bad in all ways.",
    "start": "1807040",
    "end": "1817530"
  },
  {
    "text": "When you go up\nfurther, you're adding some non-zero first\ncomponent and you're",
    "start": "1817530",
    "end": "1823960"
  },
  {
    "text": "increasing the non-zero\nsecond component, so that's a bad idea.",
    "start": "1823960",
    "end": "1829840"
  },
  {
    "text": "That's a bad idea. This is the winner. And in a way,\nhere's the picture.",
    "start": "1829840",
    "end": "1838570"
  },
  {
    "text": "Oh yeah. I should prepare these\nlectures, but this one's coming out all right anyway.",
    "start": "1838570",
    "end": "1845049"
  },
  {
    "text": "So the picture there is\nthe nearest ball hits at that point.",
    "start": "1845050",
    "end": "1852470"
  },
  {
    "text": "And what is it? Can you see that? So that star is\noutside the circle.",
    "start": "1852470",
    "end": "1857840"
  },
  {
    "text": "This is the l1 winner and\nthat's the blow up the l1 norm",
    "start": "1857840",
    "end": "1867260"
  },
  {
    "text": "until it hits. That's the point where\nthe l1 norm hits.",
    "start": "1867260",
    "end": "1873980"
  },
  {
    "text": "Do you see it? Just give it a little thought,\nthat another geometric way",
    "start": "1873980",
    "end": "1880970"
  },
  {
    "text": "to see the answer\nto this problem is, you start at the\norigin and you blow up",
    "start": "1880970",
    "end": "1886080"
  },
  {
    "text": "the norm until you get\na point on the line that satisfies your constraint.",
    "start": "1886080",
    "end": "1892279"
  },
  {
    "text": "And because you were blowing up\nthe norm, when it hits first, that's the smallest\nblow-up possible.",
    "start": "1892280",
    "end": "1899350"
  },
  {
    "text": "That's the guy that minimizes. Yeah, so just think\nabout that picture",
    "start": "1899350",
    "end": "1904820"
  },
  {
    "text": "and I'll draw it\nbetter somewhere, too. Well that's vector norms.",
    "start": "1904820",
    "end": "1912810"
  },
  {
    "text": " And then I introduce some\nmatrix norms, and let me just",
    "start": "1912810",
    "end": "1919420"
  },
  {
    "text": "say a word about those. ",
    "start": "1919420",
    "end": "1925460"
  },
  {
    "text": "OK, a word about matrix norms. So the matrix norms were the--",
    "start": "1925460",
    "end": "1936720"
  },
  {
    "text": "so now I have a matrix A and I\nwant to define those same three",
    "start": "1936720",
    "end": "1945049"
  },
  {
    "text": "norms again for a matrix. And this was the\n2 norm, and what",
    "start": "1945050",
    "end": "1954340"
  },
  {
    "text": "was the 2 norm of a matrix? Well it was sigma 1,\nit turned out to be.",
    "start": "1954340",
    "end": "1965710"
  },
  {
    "text": "So that doesn't define it. Or we could define it. Just say, OK, the\nlargest singular value",
    "start": "1965710",
    "end": "1971799"
  },
  {
    "text": "is the 2 norm of the matrix. But actually, it\ncomes from somewhere. So I want to speak about\nthis one first, the 2 norm.",
    "start": "1971800",
    "end": "1984669"
  },
  {
    "text": "So it's the 2 norm of\na matrix, and one way to see the 2 norm of a\nmatrix is to connect it",
    "start": "1984670",
    "end": "1999500"
  },
  {
    "text": "to the 2 norm of vectors.  I'd like to connect\nthe 2 norm of matrices",
    "start": "1999500",
    "end": "2006220"
  },
  {
    "text": "to the 2 norm of vectors. And how shall I do that?",
    "start": "2006220",
    "end": "2012400"
  },
  {
    "text": "I think I'm going to\nlook at the 2 norm of Ax",
    "start": "2012400",
    "end": "2019020"
  },
  {
    "text": "over the 2 norm of x. So in a way, to me, that ratio\nis like the blow-up factor.",
    "start": "2019020",
    "end": "2029370"
  },
  {
    "text": "If A was seven\ntimes the identity, to take an easy case-- if A is seven\ntimes the identity,",
    "start": "2029370",
    "end": "2035879"
  },
  {
    "text": "what will that ratio be?  Say it, yeah.",
    "start": "2035880",
    "end": "2041760"
  },
  {
    "text": "Seven. If A is 7i, this will be 7x\nand this will be x, and norms,",
    "start": "2041760",
    "end": "2049580"
  },
  {
    "text": "the factor seven comes out,\nso that ratio will be seven.",
    "start": "2049580",
    "end": "2054662"
  },
  {
    "text": "OK. For me, the norm is--",
    "start": "2054662",
    "end": "2059989"
  },
  {
    "text": "that's the blow-up factor.  So here's the idea\nof a matrix norm.",
    "start": "2059989",
    "end": "2069129"
  },
  {
    "text": "Now I'm doing matrix. Matrix norm from vector norm.",
    "start": "2069130",
    "end": "2074998"
  },
  {
    "text": " And the answer will be\nthe maximum blow-up.",
    "start": "2074998",
    "end": "2082770"
  },
  {
    "text": " The maximum of this ratio.",
    "start": "2082770",
    "end": "2088770"
  },
  {
    "text": "I call that ratio\nthe blow-up factor. That's just a made-up name. The maximum over all x.",
    "start": "2088770",
    "end": "2097731"
  },
  {
    "text": "All of x. I look to see which vector\ngets blown up the most and that is the\nnorm of the matrix.",
    "start": "2097731",
    "end": "2109670"
  },
  {
    "text": "I've settled on\nnorms of vectors. That's done upstairs there.",
    "start": "2109670",
    "end": "2115520"
  },
  {
    "text": "Now I'm looking at\nnorms of matrices. And this is one way to get\na good norm of a matrix that",
    "start": "2115520",
    "end": "2122660"
  },
  {
    "text": "kind of comes from the 2 norm. So there would be other\nnorms for matrices coming from other vector norms,\nand those, we haven't seen,",
    "start": "2122660",
    "end": "2131300"
  },
  {
    "text": "but the 2 norm is a\nvery important one. So what is the\nmaximum value of this?",
    "start": "2131300",
    "end": "2140030"
  },
  {
    "text": "Of that ratio for a matrix A? The claim is that it's sigma 1.",
    "start": "2140030",
    "end": "2147890"
  },
  {
    "text": "I'll just put a\nbig equality there. ",
    "start": "2147890",
    "end": "2153089"
  },
  {
    "text": "Now, can we see, why is sigma\n1 the answer to this problem?",
    "start": "2153090",
    "end": "2158372"
  },
  {
    "text": " I can see a couple of\nways to think about that",
    "start": "2158372",
    "end": "2165400"
  },
  {
    "text": "but that's a very\nimportant fact. In fact, this is a way to\ndiscover what sigma 1 is",
    "start": "2165400",
    "end": "2174849"
  },
  {
    "text": "without all the other sigmas. If I look for the x that has\nthe biggest blow-up factor--",
    "start": "2174850",
    "end": "2179859"
  },
  {
    "text": "and by the way,\nwhich x will it be? Which x will win the max\ncompetition here and be sigma",
    "start": "2179860",
    "end": "2187630"
  },
  {
    "text": "1 times as large as-- the ratio will be sigma 1.",
    "start": "2187630",
    "end": "2194920"
  },
  {
    "text": "That will be sigma 1. When is this thing sigma\n1 times as large as that? For which x?",
    "start": "2194920",
    "end": "2202220"
  },
  {
    "text": "Not for an eigenvector. If x was an eigenvector,\nwhat would that ratio be?",
    "start": "2202220",
    "end": "2210070"
  },
  {
    "text": "Lambda.  But if A is not a\nsymmetric matrix,",
    "start": "2210070",
    "end": "2216680"
  },
  {
    "text": "maybe the eigenvectors don't\ntell you the exact way they go.",
    "start": "2216680",
    "end": "2223170"
  },
  {
    "text": "So what vector\nwould you now guess? It's not an eigenvector,\nit is a singular vector.",
    "start": "2223170",
    "end": "2230460"
  },
  {
    "text": "And which singular vector\nis it probably going to be? v1.",
    "start": "2230460",
    "end": "2236140"
  },
  {
    "text": "Yeah, v1 makes sense. Winner. So the winner of\nthis competition",
    "start": "2236140",
    "end": "2241240"
  },
  {
    "text": "is x equal v1, the first\nright singular vector.",
    "start": "2241240",
    "end": "2249468"
  },
  {
    "text": " And we better be\nable to check that.",
    "start": "2249468",
    "end": "2254700"
  },
  {
    "text": "So again, this maximization\nproblem, the answer",
    "start": "2254700",
    "end": "2262410"
  },
  {
    "text": "is in terms of the\nsingular vector. So that's a way to find\nthis first singular vector",
    "start": "2262410",
    "end": "2269589"
  },
  {
    "text": "without finding them all. And let's just plug in\nthe first singular vector",
    "start": "2269590",
    "end": "2275849"
  },
  {
    "text": "and see that the\nratio is sigma 1.",
    "start": "2275850",
    "end": "2282600"
  },
  {
    "text": "So now let me plug it in. So what do I have? I want Av1 over length of v1.",
    "start": "2282600",
    "end": "2292910"
  },
  {
    "text": "OK. And I'm hoping to\nget that answer.",
    "start": "2292910",
    "end": "2297990"
  },
  {
    "text": "Well what's the\ndenominator here? The length of v1 is one.",
    "start": "2297990",
    "end": "2303835"
  },
  {
    "text": "So no big deal there. That's one. What's the length\nof the top one?",
    "start": "2303835",
    "end": "2309605"
  },
  {
    "text": " Now what is Av1? If v1 is the first right\nsingular vector, than Av1",
    "start": "2309605",
    "end": "2320060"
  },
  {
    "text": "is sigma 1 times u1.",
    "start": "2320060",
    "end": "2325558"
  },
  {
    "text": "Remember, the singular vector\ndeals were Av equals sigma u.",
    "start": "2325558",
    "end": "2332560"
  },
  {
    "text": "Avk equals sigma k uk.",
    "start": "2332560",
    "end": "2338740"
  },
  {
    "text": "You remember that. So they're not eigenvectors. They're singular vectors. So Av1 is the length of sigma\n1 u1 and it's divided by 1.",
    "start": "2338740",
    "end": "2353110"
  },
  {
    "text": "And of course, u1 is also a unit\nvector, so I just get sigma 1.",
    "start": "2353110",
    "end": "2359086"
  },
  {
    "text": "OK.  So that's another\nway to say that you",
    "start": "2359086",
    "end": "2365290"
  },
  {
    "text": "can find sigma 1 by solving\nthis maximum problem.",
    "start": "2365290",
    "end": "2370420"
  },
  {
    "text": "And you get that sigma 1. OK. And I could get\nother matrix norms",
    "start": "2370420",
    "end": "2378960"
  },
  {
    "text": "by maximizing that blow-up\nfactor in that vector norm.",
    "start": "2378960",
    "end": "2384770"
  },
  {
    "text": "I won't do that now, just to\nkeep control of what we've got.",
    "start": "2384770",
    "end": "2390750"
  },
  {
    "text": "Now what was the next matrix\nnorm that came in last time?",
    "start": "2390750",
    "end": "2395970"
  },
  {
    "text": "Very, very important one for\ndeep learning and neural nets.",
    "start": "2395970",
    "end": "2401070"
  },
  {
    "text": "Somehow it's a little\nsimpler than this guy. And what was that matrix norm?",
    "start": "2401070",
    "end": "2407859"
  },
  {
    "text": "What letter whose\nname goes here? Frobenius.",
    "start": "2407860",
    "end": "2413960"
  },
  {
    "text": "So capital F for Frobenius. And what was that?",
    "start": "2413960",
    "end": "2419060"
  },
  {
    "text": "That was the square root\nof the sum of all the-- add all the aij squares,\nfor all over the matrix,",
    "start": "2419060",
    "end": "2433670"
  },
  {
    "text": "and then take the square root. And then somebody asked a\ngood question after class",
    "start": "2433670",
    "end": "2440160"
  },
  {
    "text": "on Wednesday, what has that\ngot to do with the sigmas? Because my point was that\nthese norms are the guys that",
    "start": "2440160",
    "end": "2452040"
  },
  {
    "text": "go with the sigmas, that have\nnice formulas for the sigmas, and here it is.",
    "start": "2452040",
    "end": "2458220"
  },
  {
    "text": "It's the square root of the\nsum of the squares of all the sigmas. ",
    "start": "2458220",
    "end": "2467130"
  },
  {
    "text": "So let me write Frobenius again. ",
    "start": "2467130",
    "end": "2474809"
  },
  {
    "text": "But this notation with an\nF is now pretty standard,",
    "start": "2474810",
    "end": "2480450"
  },
  {
    "text": "and we should be able to\nsee why that number is the same as that number.",
    "start": "2480450",
    "end": "2486701"
  },
  {
    "start": "2486701",
    "end": "2494940"
  },
  {
    "text": "Yeah.  I could give you a\nreason or I could put it",
    "start": "2494940",
    "end": "2501408"
  },
  {
    "text": "on the problem set.  Yeah, I think that's\nbetter on the problem",
    "start": "2501408",
    "end": "2508510"
  },
  {
    "text": "set, because first of\nall, I get off the hook right away, and secondly,\nthis connection between--",
    "start": "2508510",
    "end": "2516910"
  },
  {
    "text": "in Frobenius, that's a beautiful\nfact about Frobenius norm that you add up all\nthe sigma squares--",
    "start": "2516910",
    "end": "2523415"
  },
  {
    "text": "it's just m times n of them\nbecause it's a filled matrix.",
    "start": "2523415",
    "end": "2529630"
  },
  {
    "text": "So another way to say it\nis, we haven't written down the SVD today, A equal\nu sigma v transposed.",
    "start": "2529630",
    "end": "2536604"
  },
  {
    "text": " And the point is that,\nfor the Frobenius norm--",
    "start": "2536604",
    "end": "2546530"
  },
  {
    "text": "actually, for all these norms-- I can change u. It doesn't change the norm,\nso I can make u the identity.",
    "start": "2546530",
    "end": "2555240"
  },
  {
    "text": "u, as we all know, is\nan orthogonal matrix, and what I'm saying\nis, orthogonal matrix u",
    "start": "2555240",
    "end": "2561220"
  },
  {
    "text": "doesn't change any of\nthese particular norms. So suppose it was the identity.",
    "start": "2561220",
    "end": "2566530"
  },
  {
    "text": "Same here. That could be the identity\nwithout changing the norm. So we're down to the\nnorm of Frobenius.",
    "start": "2566530",
    "end": "2575110"
  },
  {
    "text": "So what's the Frobenius\nnorm of that guy? ",
    "start": "2575110",
    "end": "2581180"
  },
  {
    "text": "What's the Frobenius norm\nof that diagonal matrix?",
    "start": "2581180",
    "end": "2586440"
  },
  {
    "text": "Well you're supposed\nto add up the squares of all the numbers in the\nmatrix and what do you get?",
    "start": "2586440",
    "end": "2593410"
  },
  {
    "text": "You get that, right? So that's why this\nis the same as this",
    "start": "2593410",
    "end": "2598690"
  },
  {
    "text": "because the orthogonal guy there\nand the orthogonal guy there make no difference in the norm.",
    "start": "2598690",
    "end": "2604220"
  },
  {
    "text": "But that takes checking, right? Yeah. But that's another\nway to see why",
    "start": "2604220",
    "end": "2610819"
  },
  {
    "text": "the Frobenius norm gives this. And then finally, this\nwas the nuclear norm. ",
    "start": "2610820",
    "end": "2618410"
  },
  {
    "text": "And actually, just\nbefore my lunch lecture on the subject\nof probability--",
    "start": "2618410",
    "end": "2623440"
  },
  {
    "text": "I've had a learning morning. The lunch lecture was about this\ncrazy way that humans behave.",
    "start": "2623440",
    "end": "2632030"
  },
  {
    "text": "Not us but other humans.",
    "start": "2632030",
    "end": "2638000"
  },
  {
    "text": "Other actual-- well, no,\nI don't want to say that. Take that out of the tape.",
    "start": "2638000",
    "end": "2646090"
  },
  {
    "text": "Yeah, OK. Anyway, that was that\nlecture, but before that was a lecture for an hour plus\nabout deep learning by somebody",
    "start": "2646090",
    "end": "2656240"
  },
  {
    "text": "who really, really has\nbegun to understand what is happening inside.",
    "start": "2656240",
    "end": "2661820"
  },
  {
    "text": "How does that gradient\ndescent optimization algorithm pick out, what\ndoes it pick out as the thing",
    "start": "2661820",
    "end": "2671660"
  },
  {
    "text": "it learns. This is going to be our\ngoal in this course.",
    "start": "2671660",
    "end": "2678200"
  },
  {
    "text": "We're not there yet. But his conjecture is that--",
    "start": "2678200",
    "end": "2683870"
  },
  {
    "text": "yeah, so it's a conjecture. He doesn't have a proof. He's got proofs\nof some nice cases",
    "start": "2683870",
    "end": "2689720"
  },
  {
    "text": "where things commute but he\nhasn't got the whole thing yet, but it's pretty terrific work.",
    "start": "2689720",
    "end": "2695840"
  },
  {
    "text": "So this was Professor\nSrebro who's in Chicago.",
    "start": "2695840",
    "end": "2703430"
  },
  {
    "text": "So he just announced\nhis conjecture, and his conjecture is that, in a\nmodeled case, the deep learning",
    "start": "2703430",
    "end": "2711700"
  },
  {
    "text": "that we'll learn about\nwith the gradient descent that we'll learn about to\nfind the best weights--",
    "start": "2711700",
    "end": "2719210"
  },
  {
    "text": "the point is that, in\na typical deep learning",
    "start": "2719210",
    "end": "2724880"
  },
  {
    "text": "problem these days, there are\nmany more weights than samples",
    "start": "2724880",
    "end": "2730049"
  },
  {
    "text": "and so there are a lot\nof possible minima. Many different weights\ngive the same minimum loss",
    "start": "2730050",
    "end": "2737230"
  },
  {
    "text": "because there are\nso many weights. The problem is, like,\ngot too many variables,",
    "start": "2737230",
    "end": "2744010"
  },
  {
    "text": "but it turns out to be\na very, very good thing. That's part of the success. And he believes that\nin a model situation,",
    "start": "2744010",
    "end": "2754780"
  },
  {
    "text": "that optimization\nby gradient descent",
    "start": "2754780",
    "end": "2760090"
  },
  {
    "text": "picks out the weights that\nminimize the nuclear norm.",
    "start": "2760090",
    "end": "2766970"
  },
  {
    "text": "So this would be a norm\nof a lot of weights. And he thinks that's\nwhere the system goes.",
    "start": "2766970",
    "end": "2775119"
  },
  {
    "text": "We'll see this. This comes up in\ncompressed sensing, as I mentioned last time.",
    "start": "2775120",
    "end": "2781420"
  },
  {
    "text": "But now I have to remember\nwhat was the definition.",
    "start": "2781420",
    "end": "2786839"
  },
  {
    "text": "Do you remember what\nthe nuclear norm? He often used a little\nstar instead of an N.",
    "start": "2786840",
    "end": "2795060"
  },
  {
    "text": "I'll put that in the notes. Other people call\nit the trace norm. But I think this N kind of gives\nit a notation you can remember.",
    "start": "2795060",
    "end": "2807730"
  },
  {
    "text": "So let's call it\nthe nuclear norm. Do you remember\nwhat that one was? ",
    "start": "2807730",
    "end": "2814000"
  },
  {
    "text": "Yeah, somebody's\nsaying it right. Add the sigmas, yeah. Just the sum of the sigmas,\nlike the l1 norm, in a way.",
    "start": "2814000",
    "end": "2825620"
  },
  {
    "text": "So that's the idea,\nis that this is the natural sort of l1\ntype of norm for matrices.",
    "start": "2825620",
    "end": "2834210"
  },
  {
    "text": "It's the l1 norm for\nthat sigma vector. This would be the l2\nnorm of the sigma vector.",
    "start": "2834210",
    "end": "2839270"
  },
  {
    "text": "That would be the\nl infinity norm. Notice that the vector numbers,\ninfinity, 2, and 1, get",
    "start": "2839270",
    "end": "2848010"
  },
  {
    "text": "changed around when you\nlook at the matrix guy.",
    "start": "2848010",
    "end": "2855300"
  },
  {
    "text": "So that's an exciting idea\nand it remains to be proved.",
    "start": "2855300",
    "end": "2862460"
  },
  {
    "text": "And expert people are\nexperimenting to see, is it true? Yeah.",
    "start": "2862460",
    "end": "2867910"
  },
  {
    "text": "So that's a big thing\nfor their future. Yes. OK, so today, we've\ntalked about norms",
    "start": "2867910",
    "end": "2875560"
  },
  {
    "text": "and this section of the notes\nwill be all about norms. ",
    "start": "2875560",
    "end": "2882540"
  },
  {
    "text": "We've taken a big leap into\na comment about deep learning",
    "start": "2882540",
    "end": "2889930"
  },
  {
    "text": "and this is what I\nwant to say the most. And I say it to\nevery class I teach",
    "start": "2889930",
    "end": "2898119"
  },
  {
    "text": "near the start of the semester. My feeling about what my\njob is to teach you things,",
    "start": "2898120",
    "end": "2906410"
  },
  {
    "text": "or to join with you in learning\nthings, as happened today. It's not to grade you.",
    "start": "2906410",
    "end": "2912259"
  },
  {
    "text": "I don't spend any time\nlosing sleep-- you know,",
    "start": "2912260",
    "end": "2917810"
  },
  {
    "text": "should that person take a\none point or epsilon penalty for turning it in\nfour minutes late?",
    "start": "2917810",
    "end": "2927461"
  },
  {
    "text": "To Hell with that, right? We've got a lot to do here.",
    "start": "2927461",
    "end": "2932779"
  },
  {
    "text": "So anyway, we'll\nget on with the job. So homework three\ncoming up, and you'll",
    "start": "2932780",
    "end": "2940760"
  },
  {
    "text": "be using the notes\nthat you already have posted in Stellar for\nthose sections eight and nine",
    "start": "2940760",
    "end": "2947410"
  },
  {
    "text": "and so on. And we'll keep going on Monday. OK, see you on Monday\nand have a great weekend.",
    "start": "2947410",
    "end": "2954580"
  },
  {
    "start": "2954580",
    "end": "2960798"
  }
]
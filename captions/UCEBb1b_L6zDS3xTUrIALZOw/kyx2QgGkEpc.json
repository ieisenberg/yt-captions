[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": " The following\ncontent is provided by MIT OpenCourseWare under\na Creative Commons license.",
    "start": "0",
    "end": "6060"
  },
  {
    "text": "Additional information\nabout our license and MIT OpenCourseWare\nin general, is available at ocw.mit.edu.",
    "start": "6060",
    "end": "12160"
  },
  {
    "start": "12160",
    "end": "17247"
  },
  {
    "text": "PROFESSOR: I thought I\nwould, in this last lecture before the break, speak\nabout one specific topic.",
    "start": "17247",
    "end": "23779"
  },
  {
    "text": " It's often referred to\nas a fast Poisson solver,",
    "start": "23780",
    "end": "30050"
  },
  {
    "text": "so what does Poisson mean? Poisson means\nLaplace's equation.",
    "start": "30050",
    "end": "36350"
  },
  {
    "text": "So, this is the\nfive-point Laplacian, which could be some other\ndiscrete Laplace matrix,",
    "start": "36350",
    "end": "43699"
  },
  {
    "text": "but let's take the one we know. So we're in two dimensions,\nand you use Poisson's name,",
    "start": "43700",
    "end": "52660"
  },
  {
    "text": "instead of Laplace's\nname, when there's a non-zero right-hand side. So otherwise, it's a Laplace\nsolver, but here Poisson.",
    "start": "52660",
    "end": "62210"
  },
  {
    "text": "OK. So, remember that\nright-hand side comes from maybe a right-hand side\nf of x, y in the differential",
    "start": "62210",
    "end": "70810"
  },
  {
    "text": "equation, but it also comes from\nnon-zero boundary conditions,",
    "start": "70810",
    "end": "77280"
  },
  {
    "text": "because non-zero boundary\nconditions, when the five points hit a boundary, that\nknown value was moved over",
    "start": "77280",
    "end": "86580"
  },
  {
    "text": "to the right-hand side\nand becomes part of f. So f comes from the non-zero\nboundary conditions, as well as",
    "start": "86580",
    "end": "95370"
  },
  {
    "text": "the non-zero right-hand side. OK. Important problems, but special\non a square or a rectangle",
    "start": "95370",
    "end": "105579"
  },
  {
    "text": "or a cube or a box,\nso we're speaking about special geometry.",
    "start": "105580",
    "end": "113760"
  },
  {
    "text": "Today, as we've been doing,\nI'll take the case on a square,",
    "start": "113760",
    "end": "120740"
  },
  {
    "text": "and you will see that the\nwhole idea would not fly, if we were on an ellipse\nor something like that.",
    "start": "120740",
    "end": "132060"
  },
  {
    "text": "But a lot of problems on\nrectangular domains do appear",
    "start": "132060",
    "end": "138420"
  },
  {
    "text": "in applications,\nor we could use -- I hope you always think now\nabout possible preconditioners.",
    "start": "138420",
    "end": "147370"
  },
  {
    "text": "Any time you have\nsomething fast, it's a candidate to\nbe a preconditioner",
    "start": "147370",
    "end": "153700"
  },
  {
    "text": "for a real problem. The real problem might\nnot be on a square,",
    "start": "153700",
    "end": "159280"
  },
  {
    "text": "or the real problem might not\nhave the constant coefficient that we have in the Laplacian.",
    "start": "159280",
    "end": "168710"
  },
  {
    "text": "In that case, you're not\nsolving the exact problem, but one that could be\nreasonably close to it.",
    "start": "168710",
    "end": "176720"
  },
  {
    "text": "OK. So we've discussed the\nsolution to this problem,",
    "start": "176720",
    "end": "183084"
  },
  {
    "text": "and actually I\nhave a little more to say about the movie\nthat is now on the website,",
    "start": "183085",
    "end": "188640"
  },
  {
    "text": "because I'm quite\nexcited about that movie. ",
    "start": "188640",
    "end": "194320"
  },
  {
    "text": "I'll come to the\nmovie in a second. Let me just say what\ntoday's lecture would be.",
    "start": "194320",
    "end": "200830"
  },
  {
    "text": "The key idea here is that the\neigenvalues and eigenvectors",
    "start": "200830",
    "end": "206750"
  },
  {
    "text": "of this giant matrix of order\nN squared by N squared -- size is N squared by N squared.",
    "start": "206750",
    "end": "214690"
  },
  {
    "text": "The eigenvalues and the\neigenvectors are known. First of all, they're known.",
    "start": "214690",
    "end": "220270"
  },
  {
    "start": "219000",
    "end": "343000"
  },
  {
    "text": "The eigenvectors are nice\ndiscrete sine functions; they're sines,\nbecause I'm assuming",
    "start": "220270",
    "end": "230080"
  },
  {
    "text": "they come to zero\nat the boundary; so that's why I have a\nsine, rather than a cosine.",
    "start": "230080",
    "end": "236410"
  },
  {
    "text": "First, they're\nknown, and second, we can work with them very\nquickly, using the FFT.",
    "start": "236410",
    "end": "245680"
  },
  {
    "text": "So the point is that\nit's quite exceptional;",
    "start": "245680",
    "end": "250709"
  },
  {
    "text": "in fact, I don't think I\nknow any comparable example, in which a linear system is\nsolved by using the eigenvalues",
    "start": "250710",
    "end": "258989"
  },
  {
    "text": "and eigenvectors. Usually eigenvalues\nand eigenvectors, they pay off for\ndifferential equations",
    "start": "258990",
    "end": "266810"
  },
  {
    "text": "that are growing in time. Then it is worth computing\nthem, because then you can just",
    "start": "266810",
    "end": "272170"
  },
  {
    "text": "multiply by e to the lambda*t,\nand you know what's happening later. ",
    "start": "272170",
    "end": "278600"
  },
  {
    "text": "Eigenvectors, eigenvalues have\nother purposes, but very, very rarely are they used to\nsolve a linear system.",
    "start": "278600",
    "end": "286229"
  },
  {
    "text": "I mean, it's usually\nfar more work. And of course, it would\nbe incredibly more work",
    "start": "286230",
    "end": "291800"
  },
  {
    "text": "if we had to find the\neigenvalues and eigenvectors, but for this problem\nwe know them.",
    "start": "291800",
    "end": "297160"
  },
  {
    "text": "And it also would be incredibly\nmore work if the matrix of eigenvectors,\nthe basis matrix,",
    "start": "297160",
    "end": "305130"
  },
  {
    "text": "the key matrix that\nI'll denote by S -- so the eigenvectors\ngo in a matrix S;",
    "start": "305130",
    "end": "312850"
  },
  {
    "text": "the eigenvalues go in a\nmatrix capital lambda; so we know lambda.",
    "start": "312850",
    "end": "319000"
  },
  {
    "text": "It's going to be a simple\nmatrix, just diagonal, got those N numbers -- N\nsquared numbers, I guess,",
    "start": "319000",
    "end": "325520"
  },
  {
    "text": "because we're of size N squared. But these eigenvectors we know.",
    "start": "325520",
    "end": "331570"
  },
  {
    "text": "So we know them, and we can\ncompute quickly with them, using the FFT, or using,\nyou might want me to say,",
    "start": "331570",
    "end": "340270"
  },
  {
    "text": "fast sine transform,\ndiscrete sine transform, rather than Fourier\ntransform, which",
    "start": "340270",
    "end": "348180"
  },
  {
    "start": "343000",
    "end": "418000"
  },
  {
    "text": "we think of as doing\nthe complex exponential. So this is a small special\nfast Fourier world.",
    "start": "348180",
    "end": "358889"
  },
  {
    "text": "It's a special\nfast Fourier world, in which the FFT and the\nrelated sine and cosine",
    "start": "358890",
    "end": "367689"
  },
  {
    "text": "give us a quick answer,\nfaster than elimination,",
    "start": "367690",
    "end": "373290"
  },
  {
    "text": "because you all\nknow, it's n log n, if n is the number of\nFourier components,",
    "start": "373290",
    "end": "379970"
  },
  {
    "text": "and that's hard to beat. Then I'll mention also,\nfor this same problem,",
    "start": "379970",
    "end": "388169"
  },
  {
    "text": "there is another way in\nwhich it can be simplified.",
    "start": "388170",
    "end": "393640"
  },
  {
    "text": "It's not a Fourier way,\njust a direct combining",
    "start": "393640",
    "end": "401230"
  },
  {
    "text": "neighboring equations,\nso that'll be number two. OK, but mostly the lecture\nis about number one.",
    "start": "401230",
    "end": "406870"
  },
  {
    "text": " The best example I know\nin which you would use",
    "start": "406870",
    "end": "413250"
  },
  {
    "text": "eigenvectors/eigenvalues\nto solve an ordinary linear system,\nand I'll say in a word",
    "start": "413250",
    "end": "420420"
  },
  {
    "start": "418000",
    "end": "497000"
  },
  {
    "text": "just how you do it, and then\nwhat these eigenvectors are. OK.",
    "start": "420420",
    "end": "428030"
  },
  {
    "text": "Pause. Time out to say something\nabout the movie. So that movie that's\nnow on the website",
    "start": "428030",
    "end": "438199"
  },
  {
    "text": "does sparse elimination, and\nthe example it takes is K2D,",
    "start": "438200",
    "end": "447150"
  },
  {
    "text": "and you can make it 8\nsquared by 8 squared, 10 squared by 10 squared,\n20 squared by 20 squared,",
    "start": "447150",
    "end": "454780"
  },
  {
    "text": "because it shows the order\nthat the nodes are eliminated",
    "start": "454780",
    "end": "460490"
  },
  {
    "text": "and the graphs of\nnon-zeros in the matrix.",
    "start": "460490",
    "end": "467039"
  },
  {
    "text": "It's a bit slow. If you do 20 by 20, you\nhave to go away for lunch,",
    "start": "467040",
    "end": "475900"
  },
  {
    "text": "well maybe not lunch, but at\nleast coffee before it's done,",
    "start": "475900",
    "end": "481389"
  },
  {
    "text": "but when it's done, it\ncounts the number of -- it shows the non-zeros that\nare in the elimination,",
    "start": "481390",
    "end": "494919"
  },
  {
    "text": "in the factor L\nfrom elimination, and it counts the\nnumber of non-zeros,",
    "start": "494920",
    "end": "500750"
  },
  {
    "start": "497000",
    "end": "649000"
  },
  {
    "text": "and I was just talking to\nPersson about also getting it to count the number\nof actual flops.",
    "start": "500750",
    "end": "507260"
  },
  {
    "text": " Well, why am I interested?",
    "start": "507260",
    "end": "513610"
  },
  {
    "text": "I'm interested, because I\ndon't know what power of N",
    "start": "513610",
    "end": "521169"
  },
  {
    "text": "those numbers are growing with. I don't know whether the number\nof non-zeros -- and I did 10,",
    "start": "521170",
    "end": "527350"
  },
  {
    "text": "20, 30, and it looked not too\nfar from the power capital N",
    "start": "527350",
    "end": "536730"
  },
  {
    "text": "cubed, but the notes say\nfor nested dissection,",
    "start": "536730",
    "end": "545240"
  },
  {
    "text": "which would be another\nordering, N squared log N. So,",
    "start": "545240",
    "end": "555540"
  },
  {
    "text": "and of course, what power we\nget depends on what algorithm we use for ordering, so nested\ndissection is one ordering,",
    "start": "555540",
    "end": "563250"
  },
  {
    "text": "which hopefully we could\nput into another movie.",
    "start": "563250",
    "end": "568700"
  },
  {
    "text": "The movie now has exact\nminimum degree, real MMD,",
    "start": "568700",
    "end": "575390"
  },
  {
    "text": "which takes as the\nnext node the one",
    "start": "575390",
    "end": "581520"
  },
  {
    "text": "with absolutely the minimum\ndegree, not just close to it.",
    "start": "581520",
    "end": "586670"
  },
  {
    "text": "Anyway, have a\nlook at that movie, and if you have\nany interest, see",
    "start": "586670",
    "end": "600130"
  },
  {
    "text": "how the count increases\nas n increases, and also you could\nchange, slightly adapt,",
    "start": "600130",
    "end": "607720"
  },
  {
    "text": "the algorithm that\ncreates the ordering, creates the permutation\nand see what happens there.",
    "start": "607720",
    "end": "615370"
  },
  {
    "text": "There's a lot to do with that,\nand it's a pretty fundamental",
    "start": "615370",
    "end": "620540"
  },
  {
    "text": "problem, actually. We're talking there about what\nMATLAB's backslash operation",
    "start": "620540",
    "end": "626930"
  },
  {
    "text": "will do for this equation. So MATLAB'S backslash\noperation will use elimination;",
    "start": "626930",
    "end": "633100"
  },
  {
    "text": "it won't use fast\nPoisson solvers, but now let me come to\nthe fast Poisson solver.",
    "start": "633100",
    "end": "638759"
  },
  {
    "text": "OK. So I guess the main\npoint is I have to say what are the\neigenvalues and eigenvectors,",
    "start": "638760",
    "end": "645910"
  },
  {
    "text": "and how do they get used. So let me say, how\ndo they get used. So how can I use\neigenvalues and eigenvectors",
    "start": "645910",
    "end": "652390"
  },
  {
    "start": "649000",
    "end": "900000"
  },
  {
    "text": "to solve a problem like that. Let me just call it\nK rather than K2D.",
    "start": "652390",
    "end": "658080"
  },
  {
    "text": "So K*U equals F. OK. ",
    "start": "658080",
    "end": "664970"
  },
  {
    "text": "By eigenvectors.  OK, there are three steps.",
    "start": "664970",
    "end": "672100"
  },
  {
    "text": "Step one.  Expand the right-hand\nside as a combination",
    "start": "672100",
    "end": "680530"
  },
  {
    "text": "of the eigenvectors. OK. So expand F, this\nright-hand side vector,",
    "start": "680530",
    "end": "688839"
  },
  {
    "text": "as some combination of\nthe first eigenvector,",
    "start": "688840",
    "end": "694250"
  },
  {
    "text": "maybe I'm going to call it\ny_1, second eigenvector,",
    "start": "694250",
    "end": "701570"
  },
  {
    "text": "n-th eigenvector, OK, good.",
    "start": "701570",
    "end": "708412"
  },
  {
    "text": "That means -- what do I mean? I mean you have to find those\nc's, that's the job there.",
    "start": "708412",
    "end": "714000"
  },
  {
    "text": "Find the coefficients. So that's a job, a numerical --\nit's a linear system to solve",
    "start": "714000",
    "end": "723779"
  },
  {
    "text": "and we'll see what\nit amounts to. OK, but suppose\nthe right-hand side is a combination of\nthe eigenvectors,",
    "start": "723780",
    "end": "730300"
  },
  {
    "text": "how can you use that? Well, step two is\nthe real quick step. Divide each c_i by the\neigenvalue lambda_i.",
    "start": "730300",
    "end": "750910"
  },
  {
    "text": "OK, so it's by eigenvector,\nso I'm assuming that K*y_i is",
    "start": "750910",
    "end": "756579"
  },
  {
    "text": "lambda_i*y_i and that\nwe know these guys.",
    "start": "756580",
    "end": "761890"
  },
  {
    "text": "So this is known. And now the question, I'm just\nsaying, how do we assume known?",
    "start": "761890",
    "end": "768820"
  },
  {
    "text": " So my question now\nis how do we use it?",
    "start": "768820",
    "end": "775250"
  },
  {
    "text": "OK, step one -- the idea is\ngoing to be write everything in terms of eigenvectors.",
    "start": "775250",
    "end": "781850"
  },
  {
    "text": "Work with the eigenvectors,\nbecause if I've got eigenvectors,\nthe step is scalar;",
    "start": "781850",
    "end": "789990"
  },
  {
    "text": "I just divide these\nnumbers by those numbers, and then I've got the answer.",
    "start": "789990",
    "end": "795370"
  },
  {
    "text": "And then construct -- the\ncorrect answer will be U will",
    "start": "795370",
    "end": "801230"
  },
  {
    "text": "be c_1 over lambda_1 y_1 and\nc_2 over lambda_2 y_2 up to c_n",
    "start": "801230",
    "end": "812680"
  },
  {
    "text": "over lambda_n y_n, a combination\nof those same eigenvectors with",
    "start": "812680",
    "end": "821120"
  },
  {
    "text": "the same coefficients,\njust divided by lambda. ",
    "start": "821120",
    "end": "827310"
  },
  {
    "text": "But this is, of course,\nanother numerical job; this is like adding\nup a Fourier series;",
    "start": "827310",
    "end": "834540"
  },
  {
    "text": "this is like finding the\nFourier coefficients, this is like\nreconstructing the input.",
    "start": "834540",
    "end": "840980"
  },
  {
    "text": "Only because I've\ndivided by lambda_i, I'm getting the\noutput here is U,",
    "start": "840980",
    "end": "847080"
  },
  {
    "text": "when the input was F.\nAnd do you see that that is the correct answer?",
    "start": "847080",
    "end": "853690"
  },
  {
    "text": "All I have to do is\ncheck that K*U equals F. So check that this answer from\nstep three is the right answer.",
    "start": "853690",
    "end": "866040"
  },
  {
    "text": "OK, so I multiply by K.\nWhen I multiply y_1 by K,",
    "start": "866040",
    "end": "874959"
  },
  {
    "text": "a factor lambda_1 appears, the\neigenvalue; it cancels that; well that's y divided,\nso it would cancel,",
    "start": "874960",
    "end": "882480"
  },
  {
    "text": "and I have c_1*y_1. When I multiply this by\nK, K*y_2 is lambda_2*y_2;",
    "start": "882480",
    "end": "889940"
  },
  {
    "text": "cancel the lambda_2's, and\nyou're left with c_2*y_2, and so on.",
    "start": "889940",
    "end": "895000"
  },
  {
    "text": "So, when I multiplied by\nK, I got F. That's it.",
    "start": "895000",
    "end": "902250"
  },
  {
    "text": "So that's the whole idea\nwritten out, but now,",
    "start": "902250",
    "end": "909760"
  },
  {
    "text": "what actual computations go\ninto steps one and three? Step two is pretty simple.",
    "start": "909760",
    "end": "915839"
  },
  {
    "text": "Well, actually this is\na good way to look it. I want to write that same\nalgorithm in matrix language.",
    "start": "915840",
    "end": "923790"
  },
  {
    "text": "OK, so in matrix form.",
    "start": "923790",
    "end": "929790"
  },
  {
    "text": "We have the matrix\nof eigenvectors, and that's what I'm\ncalling S. And it's",
    "start": "929790",
    "end": "937319"
  },
  {
    "text": "got the eigenvectors y_1,\ny_2, y_n in its columns.",
    "start": "937320",
    "end": "943320"
  },
  {
    "text": "And the eigenvalue matrix,\nwe need a name for that too,",
    "start": "943320",
    "end": "952090"
  },
  {
    "text": "and that we decided\nto call lambda, and that's got the\neigenvalues on its diagonal.",
    "start": "952090",
    "end": "961480"
  },
  {
    "text": "So this is 18.06,\nlinear algebra.",
    "start": "961480",
    "end": "968029"
  },
  {
    "text": "The matrix of eigenvectors,\nif I multiply K by S,",
    "start": "968030",
    "end": "976020"
  },
  {
    "text": "then I'm multiplying K by\nall its little eigenvectors,",
    "start": "976020",
    "end": "981770"
  },
  {
    "text": "and K times this\ngives me lambda_1*y_1, K times y_2 gives\nme lambda_2*y_2,",
    "start": "981770",
    "end": "989250"
  },
  {
    "text": "K*y_n is lambda_n*y_n, and if\nI look to see what this is,",
    "start": "989250",
    "end": "998250"
  },
  {
    "text": "this is the same as y_1 to\ny_n multiplied by lambda.",
    "start": "998250",
    "end": "1004060"
  },
  {
    "text": "If I just multiply on\nthe right by lambda, it will take lambda_1\ntimes the first column,",
    "start": "1004060",
    "end": "1009420"
  },
  {
    "text": "lambda_2 times the second,\nlambda_n times the last, which is what we want,\nso it's S*lambda.",
    "start": "1009420",
    "end": "1016050"
  },
  {
    "text": " This is all n eigenvalues and\neigenvectors in one matrix",
    "start": "1016050",
    "end": "1024809"
  },
  {
    "text": "equation, that's all that is. It's just K*S equal S*lambda_i\njust says this for all i",
    "start": "1024810",
    "end": "1037789"
  },
  {
    "text": "at once, all i at the same time. OK. So if I use these\nmatrices in describing",
    "start": "1037790",
    "end": "1046000"
  },
  {
    "text": "steps one, two,\nthree, I'll see what's happening matrix language.",
    "start": "1046000",
    "end": "1052740"
  },
  {
    "text": "OK, let me just do that. Step one: step one\nis looking for F",
    "start": "1052740",
    "end": "1061550"
  },
  {
    "text": "as a combination of\nthe columns of S. So step one is just\nF equals S times c.",
    "start": "1061550",
    "end": "1072220"
  },
  {
    "text": "The vector of coefficients\nmultiplies the columns of S",
    "start": "1072220",
    "end": "1080110"
  },
  {
    "text": "and adds to give\nF. Then step two,",
    "start": "1080110",
    "end": "1087700"
  },
  {
    "text": "which just divides everything\nby -- divides by the lambdas.",
    "start": "1087700",
    "end": "1095309"
  },
  {
    "text": "Step two just creates\nlambda inverse S*c. ",
    "start": "1095310",
    "end": "1102850"
  },
  {
    "text": "So I took what I had\n-- let's see, no,",
    "start": "1102850",
    "end": "1110880"
  },
  {
    "text": "the lambda inverse better\nbe multiplying the c. Well, actually I can do it\nall in -- well step two,",
    "start": "1110880",
    "end": "1121150"
  },
  {
    "text": "that's the easiest step,\nI should be able to do it. c is changed to\nlambda inverse c,",
    "start": "1121150",
    "end": "1132150"
  },
  {
    "text": "so that c becomes\nlambda inverse c, OK. And then step three\nuses lambda inverse c",
    "start": "1132150",
    "end": "1141600"
  },
  {
    "text": "to construct U. So step\nthree is: the answer",
    "start": "1141600",
    "end": "1151190"
  },
  {
    "text": "U, what do I have here? I've got a combination\nof these vectors,",
    "start": "1151190",
    "end": "1156740"
  },
  {
    "text": "so they're the columns of S,\nand what are they multiplied by? They're multiplied by\nthe c's over lambdas,",
    "start": "1156740",
    "end": "1162980"
  },
  {
    "text": "which is what I have here. That's S lambda inverse c.",
    "start": "1162980",
    "end": "1173650"
  },
  {
    "start": "1172000",
    "end": "1292000"
  },
  {
    "text": "Those are the three steps. And what's the work involved?",
    "start": "1173650",
    "end": "1182900"
  },
  {
    "text": "Here, the work is solving a\nlinear system with the matrix S. Here, the work is\ntaking a combination",
    "start": "1182900",
    "end": "1193670"
  },
  {
    "text": "of the columns of s, doing\na matrix multiplication.",
    "start": "1193670",
    "end": "1199650"
  },
  {
    "text": "Those two steps are usually\nfull-scale matrix operations,",
    "start": "1199650",
    "end": "1206820"
  },
  {
    "text": "and of course, the S --\nif I just complete this, I'll see that I get\nthe right thing,",
    "start": "1206820",
    "end": "1212220"
  },
  {
    "text": "that's S lambda inverse\nand c is S inverse F.",
    "start": "1212220",
    "end": "1222909"
  },
  {
    "text": "There's the answer. U is S lambda inverse -- that's\na lambda inverse there --",
    "start": "1222910",
    "end": "1231200"
  },
  {
    "text": "S inverse F. That's the correct\nanswer in matrix language.",
    "start": "1231200",
    "end": "1237091"
  },
  {
    "text": "Right.  This is K inverse,\nthat's K inverse.",
    "start": "1237091",
    "end": "1243850"
  },
  {
    "text": "K is S*lambda S inverse, and\nif I take the inverse of that,",
    "start": "1243850",
    "end": "1254570"
  },
  {
    "text": "I get S lambda inverse S\ninverse to multiply F. Well,",
    "start": "1254570",
    "end": "1263830"
  },
  {
    "text": "I doubt if you're much\nimpressed by this lower board, because the upper board was\nthe same thing written out.",
    "start": "1263830",
    "end": "1273799"
  },
  {
    "text": "It took some indication of\nwhat the separate pieces were,",
    "start": "1273800",
    "end": "1281390"
  },
  {
    "text": "but it's pretty clear. OK, now the million dollar\nquestion is, is it fast?",
    "start": "1281390",
    "end": "1293910"
  },
  {
    "start": "1292000",
    "end": "1638000"
  },
  {
    "text": "And the answer is,\nalmost certainly no. But for the particular matrix\nS, which by good fortune,",
    "start": "1293910",
    "end": "1305690"
  },
  {
    "text": "S could also stand\nfor sine, this matrix",
    "start": "1305690",
    "end": "1310720"
  },
  {
    "text": "of eigenvectors for this\nparticular problem are sines.",
    "start": "1310720",
    "end": "1317130"
  },
  {
    "text": "These are the discrete sines,\nso this is the discrete sine transform. That's we're doing, we're doing\nthe discrete sine transform,",
    "start": "1317130",
    "end": "1325630"
  },
  {
    "text": "because those discrete\nsine vectors are the eigenvectors of K. OK, now\nlet me say what that means.",
    "start": "1325630",
    "end": "1337590"
  },
  {
    "text": "First I'm thinking of K in 1D. So this is my 2's and\nminus 1's and minus 1's.",
    "start": "1337590",
    "end": "1348960"
  },
  {
    "text": "Its eigenvectors\nare discrete sines, if I multiply that\nby sine k*h -- well,",
    "start": "1348960",
    "end": "1358530"
  },
  {
    "text": "let me just take the first\none, sine h, sine 2h,",
    "start": "1358530",
    "end": "1364070"
  },
  {
    "text": "sine n minus 1 h, that will\nturn out to be an eigenvector.",
    "start": "1364070",
    "end": "1372639"
  },
  {
    "text": " So this is K*y, K*y_1,\nthe first eigenvector.",
    "start": "1372640",
    "end": "1382630"
  },
  {
    "text": "The eigenvectors are\n-- let me draw them. The eigenvectors for that second\ndifference matrix K are --",
    "start": "1382630",
    "end": "1393960"
  },
  {
    "text": "here's the interval, 0 to 1,\nI chop it up in steps of h, and I plot the sine, which\nstarts at zero and ends",
    "start": "1393960",
    "end": "1406700"
  },
  {
    "text": "at zero, because those are\nthe boundary conditions, and here is sine h, sine 2h,\nsine 3h, sine 4h, sine 5h,",
    "start": "1406700",
    "end": "1414500"
  },
  {
    "text": "so for the five by five case --\nmaybe I should just be using n",
    "start": "1414500",
    "end": "1419880"
  },
  {
    "text": "here, or maybe I should\neven be using capital N,",
    "start": "1419880",
    "end": "1425890"
  },
  {
    "text": "so capital N is 5\nin this example. ",
    "start": "1425890",
    "end": "1433770"
  },
  {
    "text": "Good. What's on the other side\nof that equals sign?",
    "start": "1433770",
    "end": "1439670"
  },
  {
    "text": "Some eigenvalue times the\nsame vector, sine h, sine 2h,",
    "start": "1439670",
    "end": "1446940"
  },
  {
    "text": "down to sine N*h, and\nthat eigenvalue -- oh, let me just write\nlambda 1 for it.",
    "start": "1446940",
    "end": "1456230"
  },
  {
    "text": "We know what it is. The fact that this is an\neigenvector is just trig;",
    "start": "1456230",
    "end": "1464900"
  },
  {
    "text": "you know, I multiply minus 1\nof that plus 2 of that minus 1 of sine 3h, and I use\na little trig identity.",
    "start": "1464900",
    "end": "1475050"
  },
  {
    "text": "So minus that, 2 of\nthat, minus that, turns out that to be\na multiple of sine 2h.",
    "start": "1475050",
    "end": "1481250"
  },
  {
    "text": "Well, the 2 sine 2h give us a\n2, and then the minus sine h",
    "start": "1481250",
    "end": "1487770"
  },
  {
    "text": "and the minus sine 3h\ncombine into sine 2h times,",
    "start": "1487770",
    "end": "1494650"
  },
  {
    "text": "I think, it's a cosine\nof h or something,",
    "start": "1494650",
    "end": "1500210"
  },
  {
    "text": "it's that eigenvector\nthat's near zero,",
    "start": "1500210",
    "end": "1507289"
  },
  {
    "text": "because the cosine\nof h is near 1. Does that look familiar? That a combination\nof sine h and sine 3h",
    "start": "1507290",
    "end": "1516610"
  },
  {
    "text": "should give us twice sine\n2h times some cosine,",
    "start": "1516610",
    "end": "1521760"
  },
  {
    "text": "yep, Elementary trig identity.",
    "start": "1521760",
    "end": "1528320"
  },
  {
    "text": "OK, so those are eigenvectors. That's the first one, the\nnext one would have h times --",
    "start": "1528320",
    "end": "1536230"
  },
  {
    "text": "the k-th one would have h times\nk instead of just h itself,",
    "start": "1536230",
    "end": "1542260"
  },
  {
    "text": "it would take jumps\nof every k -- sine. and then a cosine h*k\nwould show up there,",
    "start": "1542260",
    "end": "1552559"
  },
  {
    "text": "and this would still\nbe an eigenvector. OK.",
    "start": "1552560",
    "end": "1559240"
  },
  {
    "text": "I'm making a little bit\nexplicit these vectors,",
    "start": "1559240",
    "end": "1566820"
  },
  {
    "text": "but the main point\nis they're sines, they're discrete sines\nat equally spaced points.",
    "start": "1566820",
    "end": "1574570"
  },
  {
    "text": "That's what the real version\nof the FFT just lives on.",
    "start": "1574570",
    "end": "1582600"
  },
  {
    "text": "And it would also live\non discrete cosines; if we had different\nboundary conditions, we could do those, too.",
    "start": "1582600",
    "end": "1588279"
  },
  {
    "text": "So this isn't the only -- these\nzero boundary conditions are",
    "start": "1588280",
    "end": "1594170"
  },
  {
    "text": "associated with the\nname of Dirichlet,",
    "start": "1594170",
    "end": "1600240"
  },
  {
    "text": "where zero slopes are associated\nwith the name of Neumann, and both -- this one gives\nsines, Neumann gives cosines,",
    "start": "1600240",
    "end": "1609830"
  },
  {
    "text": "the FFT deals with both. OK. So, that's the fast solution,\nand it would take N squared --",
    "start": "1609830",
    "end": "1620840"
  },
  {
    "text": "well I have to go to 2D. sorry, I guess I\nhave a little more to say because I have to get\nfrom this one-dimensional",
    "start": "1620840",
    "end": "1632019"
  },
  {
    "text": "second difference to the\nfive-point two-dimensional second difference,\nand that's what's",
    "start": "1632020",
    "end": "1637530"
  },
  {
    "text": "going to happen over here. I wrote up some stuff about\nthe Kronecker operation, which",
    "start": "1637530",
    "end": "1648399"
  },
  {
    "start": "1638000",
    "end": "1979000"
  },
  {
    "text": "is the nifty way for\nthese special problems to go from 1D to 2D.",
    "start": "1648400",
    "end": "1656740"
  },
  {
    "text": "You remember the deal,\nthat K2D, our 2D matrix,",
    "start": "1656740",
    "end": "1662880"
  },
  {
    "text": "was this Kronecker product\nof K and I, that gave us",
    "start": "1662880",
    "end": "1671380"
  },
  {
    "text": "second differences\nin one direction, and then we have to add in the\nKronecker product of I and K",
    "start": "1671380",
    "end": "1679040"
  },
  {
    "text": "to get second differences\nin the other direction. And then we better print --\nbecause that matrix is going",
    "start": "1679040",
    "end": "1686845"
  },
  {
    "text": "to be large, I don't\nwant to print it.",
    "start": "1686845",
    "end": "1692679"
  },
  {
    "text": "Yeah. What's the point? The point is that if I\nknow the eigenvectors of k,",
    "start": "1692680",
    "end": "1699970"
  },
  {
    "text": "then I can find the -- if\nI know the 1D eigenvectors, I can find the 2D eigenvectors,\nand you don't have to know",
    "start": "1699970",
    "end": "1707390"
  },
  {
    "text": "Kronecker products to do that. All you have to do is just\nmake a sensible guess,",
    "start": "1707390",
    "end": "1712780"
  },
  {
    "text": "so the eigenvectors in 2D, are\n-- so they have a double index,",
    "start": "1712780",
    "end": "1722170"
  },
  {
    "text": "k and l, and their components\nare sines in one direction",
    "start": "1722170",
    "end": "1737430"
  },
  {
    "text": "times sines in the\nother direction. So what are those sines? There's a k*h, I guess, l*h.",
    "start": "1737430",
    "end": "1746810"
  },
  {
    "start": "1746810",
    "end": "1754080"
  },
  {
    "text": "Those are the first components,\nI guess I have to tell you what all the components are: k --\nthe seventh component in the x",
    "start": "1754080",
    "end": "1766640"
  },
  {
    "text": "direction, there'd be a factor\n7 -- so k*m*h sine l*n*h.",
    "start": "1766640",
    "end": "1774840"
  },
  {
    "text": "This is the (m, n)\ncomponent of y_(k, l).",
    "start": "1774840",
    "end": "1781809"
  },
  {
    "start": "1781810",
    "end": "1788720"
  },
  {
    "text": "It's just what we had in 1D. In 1D there was no l, the\ncomponents were just sine",
    "start": "1788720",
    "end": "1796510"
  },
  {
    "text": "k*m*h. Now we've got two, one\nin the x direction --",
    "start": "1796510",
    "end": "1805320"
  },
  {
    "text": "These are the analogs of the\n-- the continuous case would be",
    "start": "1805320",
    "end": "1813399"
  },
  {
    "text": "sine k*pi*x times sine l*pi*y.",
    "start": "1813400",
    "end": "1821120"
  },
  {
    "text": " Those are the eigenvectors\nas eigenfunctions,",
    "start": "1821120",
    "end": "1829380"
  },
  {
    "text": "functions of x and y. And the point is\nthat, once again,",
    "start": "1829380",
    "end": "1835300"
  },
  {
    "text": "with these beautiful\nmatrices, I can sample these at the\nequally spaced points,",
    "start": "1835300",
    "end": "1843120"
  },
  {
    "text": "and I get discrete\nsines that the FFT is ready to go with, OK.",
    "start": "1843120",
    "end": "1849620"
  },
  {
    "start": "1849620",
    "end": "1854670"
  },
  {
    "text": "I'm giving this much detail\npartly because the continuous",
    "start": "1854670",
    "end": "1864770"
  },
  {
    "text": "case, of course, our operators\nd second by the dx squared and d second by dy squared, and\nthe whole idea of separating",
    "start": "1864770",
    "end": "1877820"
  },
  {
    "text": "variables, of looking\nfor solutions u --",
    "start": "1877820",
    "end": "1884700"
  },
  {
    "text": "here is the eigenvalue problem,\nthe continuous eigenvalue problem. The Laplacian of u,\nmaybe I do a minus,",
    "start": "1884700",
    "end": "1892300"
  },
  {
    "text": "the Laplacian of\nu equal lambda*u, and that's a partial\ndifferential equation,",
    "start": "1892300",
    "end": "1898760"
  },
  {
    "text": "usually it's not easy to\nsolve, but if I'm on a square,",
    "start": "1898760",
    "end": "1905540"
  },
  {
    "text": "and I have zero\nboundary conditions, then I've solved it, by\nseparation of variables,",
    "start": "1905540",
    "end": "1912429"
  },
  {
    "text": "a function of x times\na function of y. And that function of\nx times function of y",
    "start": "1912430",
    "end": "1917760"
  },
  {
    "text": "is exactly what\nKronecker product is doing for matrices, yep.",
    "start": "1917760",
    "end": "1923480"
  },
  {
    "start": "1923480",
    "end": "1928730"
  },
  {
    "text": "I thought maybe this is good to\nknow when the problem is easy,",
    "start": "1928730",
    "end": "1935960"
  },
  {
    "text": "and as I say, the possibility of\nusing the easy case on a square",
    "start": "1935960",
    "end": "1943750"
  },
  {
    "text": "for preconditioning a not\nso easy case is attractive.",
    "start": "1943750",
    "end": "1949560"
  },
  {
    "text": "All right, so\nthat's what I wanted to say about number one,\nthat's the main suggestion,",
    "start": "1949560",
    "end": "1958820"
  },
  {
    "text": "and again, the point was just to\ntake these three simple steps,",
    "start": "1958820",
    "end": "1966399"
  },
  {
    "text": "provided we know and\nlike the eigenvectors.",
    "start": "1966400",
    "end": "1971730"
  },
  {
    "text": "Here we know them and\nwe like them very much, because they're\nthose discrete sines.",
    "start": "1971730",
    "end": "1977580"
  },
  {
    "text": "OK, now just to\nfinish comes, what's",
    "start": "1977580",
    "end": "1982809"
  },
  {
    "start": "1979000",
    "end": "2724000"
  },
  {
    "text": "up with odd-even reduction. I'll use the same\n1D problem first.",
    "start": "1982810",
    "end": "1991040"
  },
  {
    "text": "It works great in --\nthat's not good English, but it works very well in\n1D, odd-even reduction,",
    "start": "1991040",
    "end": "2000679"
  },
  {
    "text": "you'll see it, you'll\nsee, oh boy, simple idea. But of course, don't forget\nthat ordinary elimination",
    "start": "2000680",
    "end": "2007429"
  },
  {
    "text": "is a breeze with a tri-diagonal\nmatrix, so nothing I could do",
    "start": "2007430",
    "end": "2013210"
  },
  {
    "text": "could be faster than that. But let's see what you can do. I just want to write\ndown the -- OK,",
    "start": "2013210",
    "end": "2020250"
  },
  {
    "text": "keep your eye on this matrix,\nso I'm going to write out",
    "start": "2020250",
    "end": "2028150"
  },
  {
    "text": "the equations. So it'll be minus U_(i-2)\nplus 2*U_(i-1) minus U_i,",
    "start": "2028150",
    "end": "2039080"
  },
  {
    "text": "that would be F_(i-1); that\nwould be equation number i minus 1, right?",
    "start": "2039080",
    "end": "2044960"
  },
  {
    "text": "With a minus 1, 2,\nminus 1, centered there. And then the next one will be\na minus U_(i-1) plus 2*U_i --",
    "start": "2044960",
    "end": "2057200"
  },
  {
    "text": "I better move this guy over\nfurther -- minus U_(i+1),",
    "start": "2057200",
    "end": "2067270"
  },
  {
    "text": "that will be F_i, right? That's equation number i,\nand now I just want to look",
    "start": "2067270",
    "end": "2074179"
  },
  {
    "text": "at equation number\n-- the next equation, minus U_i plus 2*U_(i+1)\nminus U_(i+2) is F_(i+1).",
    "start": "2074180",
    "end": "2084849"
  },
  {
    "text": " So I've written down three\nconsecutive equations,",
    "start": "2084850",
    "end": "2095389"
  },
  {
    "text": "three consecutive rows\nfrom my simple matrix:",
    "start": "2095390",
    "end": "2104240"
  },
  {
    "text": "a row, the next row,\nand the next row.",
    "start": "2104240",
    "end": "2109420"
  },
  {
    "text": "So the right-hand sides\nare coming in order, and the diagonals are there,\nand if I look at that,",
    "start": "2109420",
    "end": "2117520"
  },
  {
    "text": "do I get any idea?  Well, there is an idea here.",
    "start": "2117520",
    "end": "2129029"
  },
  {
    "text": " I'd like to remove these\nguys, the U_(i-1)'s and the",
    "start": "2129030",
    "end": "2139329"
  },
  {
    "text": "U_(i+1)'s, so that's where\nthis word odd-even reduction is coming in. I'm going to reduce\nthis system by keeping",
    "start": "2139330",
    "end": "2146820"
  },
  {
    "text": "only every second unknown\nand eliminating those.",
    "start": "2146820",
    "end": "2153750"
  },
  {
    "text": "How to do that? Well, you can see\nhow to eliminate. If I multiply this\nequation by 2.",
    "start": "2153750",
    "end": "2161050"
  },
  {
    "text": "If I multiply that\nmiddle equation by 2, that becomes a 4,\nthis becomes a minus 2,",
    "start": "2161050",
    "end": "2167380"
  },
  {
    "text": "this becomes a 2, and\nnow what shall I do? ",
    "start": "2167380",
    "end": "2172950"
  },
  {
    "text": "Add. If I add the equations\ntogether, I get minus U_(i-2) --",
    "start": "2172950",
    "end": "2180510"
  },
  {
    "text": "these cancel, that was the\npoint -- plus 4 minus a couple, so that's two u_i's,\nminus this guy,",
    "start": "2180510",
    "end": "2190550"
  },
  {
    "text": "u_(i-2) is that sum F_(i-1),\ntwo F_i's, and F_(i+1).",
    "start": "2190550",
    "end": "2204200"
  },
  {
    "text": " Well, sorry it's squeezed down\nhere, but this is the point.",
    "start": "2204200",
    "end": "2212680"
  },
  {
    "text": "The main point is look at this. What do we have?",
    "start": "2212680",
    "end": "2220050"
  },
  {
    "text": "We've got a typical\nequation, but now we've",
    "start": "2220050",
    "end": "2226880"
  },
  {
    "text": "removed half the unknowns. The problem is now half-sized.",
    "start": "2226880",
    "end": "2232030"
  },
  {
    "text": "We've only got the\neven-numbered unknowns at a small cost in updating\nthe right-hand side,",
    "start": "2232030",
    "end": "2244589"
  },
  {
    "text": "and the problem's cut in half. So that's this\nodd-even reduction,",
    "start": "2244590",
    "end": "2250250"
  },
  {
    "text": "and it cuts a problem in\nhalf, and everybody knows",
    "start": "2250250",
    "end": "2255400"
  },
  {
    "text": "right away what to do next. The one mantra of computer\nscience, \"Do it again.\"",
    "start": "2255400",
    "end": "2263670"
  },
  {
    "text": "So that is the same\nproblem on the even,",
    "start": "2263670",
    "end": "2268760"
  },
  {
    "text": "we do it again,\nso I should really call it cyclic reduction, we\njust cycle with this reduction,",
    "start": "2268760",
    "end": "2277440"
  },
  {
    "text": "and in the end, we\nhave a 2 by 2 problem. ",
    "start": "2277440",
    "end": "2284700"
  },
  {
    "text": "That seems pretty smart,\npretty successful move,",
    "start": "2284700",
    "end": "2290200"
  },
  {
    "text": "and I guess if we do\nan operation count, well, I haven't\nthought that through. What does the operation\ncount look like?",
    "start": "2290200",
    "end": "2298530"
  },
  {
    "text": "It must be pretty quick, right? Well, undoubtedly we're\nsolving this linear system",
    "start": "2298530",
    "end": "2305200"
  },
  {
    "text": "in O of N steps. Well, no big surprise to be able\nto deal with that matrix in O",
    "start": "2305200",
    "end": "2312330"
  },
  {
    "text": "of N steps, because elimination\nwould take O of N steps,",
    "start": "2312330",
    "end": "2317740"
  },
  {
    "text": "it's size N, but it's bandwidth\nis 1, so 2N or something steps",
    "start": "2317740",
    "end": "2324390"
  },
  {
    "text": "would do it, and\nmaybe, I don't know how many steps we have here.",
    "start": "2324390",
    "end": "2330089"
  },
  {
    "text": "I guess, when we cut it\nin half, that required us to do that much.",
    "start": "2330090",
    "end": "2336370"
  },
  {
    "text": "It's order N, it's order N.",
    "start": "2336370",
    "end": "2343920"
  },
  {
    "text": "So the key question\nis, can we do it 2D?",
    "start": "2343920",
    "end": "2350579"
  },
  {
    "text": "Can we do the same thing in 2D? So I want to follow that\nplan in two dimensions",
    "start": "2350580",
    "end": "2360330"
  },
  {
    "text": "where now U will be a\nwhole row at a time,",
    "start": "2360330",
    "end": "2365960"
  },
  {
    "text": "so I'm doing block 2D, block 2D. So, can I write down the\nequations in block 2D,",
    "start": "2365960",
    "end": "2374430"
  },
  {
    "text": "for whole rows? So U_i is the vector -- So\nnow this is the 2D problem,",
    "start": "2374430",
    "end": "2382590"
  },
  {
    "text": "so it'll be minus\nthe identity -- where instead of instead of 1,\nI have to write the identity --",
    "start": "2382590",
    "end": "2388859"
  },
  {
    "text": "U_(i-2) and 2K, right?",
    "start": "2388860",
    "end": "2396800"
  },
  {
    "text": "Oh no, what is the middle\n-- what's on the --",
    "start": "2396800",
    "end": "2403650"
  },
  {
    "text": "so multiplying U_i, U_(i-1). I wanted to just\nsay the same thing,",
    "start": "2403650",
    "end": "2409540"
  },
  {
    "text": "but I have to write down the --\nthis is going to be N squared",
    "start": "2409540",
    "end": "2415300"
  },
  {
    "text": "equations N at a time,\na whole row at a time, and what's on the\ndiagonal of K2D?",
    "start": "2415300",
    "end": "2423050"
  },
  {
    "text": "Not 2K. It's 2I, is it 2I plus K?",
    "start": "2423050",
    "end": "2432190"
  },
  {
    "text": "Yeah. Yeah, K plus 2I. Isn't that what we have on\nthe diagonal of the K2D one?",
    "start": "2432190",
    "end": "2442859"
  },
  {
    "text": "Times U_(i-1) minus\nI*U_i is equal to some --",
    "start": "2442860",
    "end": "2453960"
  },
  {
    "text": "that's a whole row at a time. These are all vectors with\nN components now, right?",
    "start": "2453960",
    "end": "2462319"
  },
  {
    "text": "The minus i, the 2I, and\nthe minus I are the second differences of one of\nrows, they're difference is",
    "start": "2462320",
    "end": "2470420"
  },
  {
    "text": "in the vertical direction,\nand this K*U_i the second difference is along the row.",
    "start": "2470420",
    "end": "2475840"
  },
  {
    "text": " OK, so same equation\nat the next row.",
    "start": "2475840",
    "end": "2483160"
  },
  {
    "text": "So the next row is minus\nI*U_(i-1), K plus 2 U_i --",
    "start": "2483160",
    "end": "2494880"
  },
  {
    "text": "because that's now\nthe diagonal block -- minus I*U_(i+1) is F_(i+1).",
    "start": "2494880",
    "end": "2502760"
  },
  {
    "text": "And it'll just take me a\nsecond to write this one. This is K plus 2I U_(i+1),\nminus I*U_(i+2) is F_(i+2).",
    "start": "2502760",
    "end": "2517690"
  },
  {
    "text": "OK.  Exactly the same, but now\na row at a time in 2D.",
    "start": "2517690",
    "end": "2528980"
  },
  {
    "text": "So the same idea is\ngoing to work, right? What do I do? I want to cancel this, so I\nmultiply that row by K plus 2I.",
    "start": "2528980",
    "end": "2540990"
  },
  {
    "text": "Before I multiplied\nit by 2, but now I have to multiply\nit by K plus 2I.",
    "start": "2540990",
    "end": "2546300"
  },
  {
    "text": "Times the row, the whole row. ",
    "start": "2546300",
    "end": "2552349"
  },
  {
    "text": "So when I do that this\ncancels, so I have minus this, this guy wasn't affected.",
    "start": "2552350",
    "end": "2560240"
  },
  {
    "text": "And this will\ncancel, the K plus 2I will cancel this\none, just as before.",
    "start": "2560240",
    "end": "2566460"
  },
  {
    "text": "This will not be\naffected, U_(i+2),",
    "start": "2566460",
    "end": "2573640"
  },
  {
    "text": "and I have F_i and K plus\n2I F_(i+1) and F_(i+2).",
    "start": "2573640",
    "end": "2587220"
  },
  {
    "text": " That should have been i minus\n1, and this should have been i,",
    "start": "2587220",
    "end": "2594640"
  },
  {
    "text": "and this should\nhave been i plus 1, sorry, mis-labeled the\nF's, but no big deal.",
    "start": "2594640",
    "end": "2604630"
  },
  {
    "text": "The point is the left\nside, and the point is what's in that space.",
    "start": "2604630",
    "end": "2610160"
  },
  {
    "text": " What goes in that space? Well, it's minus I, K\nplus 2I, squared, minus I,",
    "start": "2610160",
    "end": "2621140"
  },
  {
    "text": "so this is K plus 2I squared,\nwhich before was so easy,",
    "start": "2621140",
    "end": "2629670"
  },
  {
    "text": "and then the minus I, and\nthe minus I is the minus 2I, is multiplying the U_i.",
    "start": "2629670",
    "end": "2635390"
  },
  {
    "text": "Yeah, that was minus I.",
    "start": "2635390",
    "end": "2640490"
  },
  {
    "text": "OK, this is my matrix\nfrom odd-even reduction.",
    "start": "2640490",
    "end": "2649640"
  },
  {
    "text": "It's just natural\nto try the idea, and the idea works,\nbut not so perfectly,",
    "start": "2649640",
    "end": "2658540"
  },
  {
    "text": "because previously in 1D, that\njust gave us the answer 2;",
    "start": "2658540",
    "end": "2666330"
  },
  {
    "text": "it was 4 minus 2. But now in 2D, we have a\nmatrix, not surprising,",
    "start": "2666330",
    "end": "2674150"
  },
  {
    "text": "but what we don't\nlike is the fact that the bandwidth is\ngrowing. k was tri-diagonal,",
    "start": "2674150",
    "end": "2680690"
  },
  {
    "text": "but when we square it, it\nwill have five diagonals, and when we repeat the odd-even\ncycles, when we do it again,",
    "start": "2680690",
    "end": "2689430"
  },
  {
    "text": "those five diagonals will be\nnine diagonals, and onwards.",
    "start": "2689430",
    "end": "2696069"
  },
  {
    "text": "So, I'm getting\nhalf-sized problems.",
    "start": "2696070",
    "end": "2704380"
  },
  {
    "text": "All the odd-numbered rows\nin my square are eliminated,",
    "start": "2704380",
    "end": "2711400"
  },
  {
    "text": "this just involves the\neven-numbered rows, but the matrix is not\ntri-diagonal anymore,",
    "start": "2711400",
    "end": "2721500"
  },
  {
    "text": "it's growing in bandwidth. So, and then you have\nto keep track of it,",
    "start": "2721500",
    "end": "2728480"
  },
  {
    "start": "2724000",
    "end": "2903000"
  },
  {
    "text": "so the final conclusion is that\nthis is a pretty good idea,",
    "start": "2728480",
    "end": "2737650"
  },
  {
    "text": "but it's not quite\nas good as this one. It's not as good as\nthe FFT-based idea.",
    "start": "2737650",
    "end": "2745330"
  },
  {
    "text": "Also, if you look to see\nwhat is most efficient -- see the eigenvectors\nare still here,",
    "start": "2745330",
    "end": "2752540"
  },
  {
    "text": "so I could do three steps of\nthis and then go to Fourier,",
    "start": "2752540",
    "end": "2759690"
  },
  {
    "text": "and that probably\nis about right. So, if you really wanted to\npolish off a fast Poisson",
    "start": "2759690",
    "end": "2769100"
  },
  {
    "text": "solver, you could do\nmaybe two steps or three of odd-even cyclic\nreduction, but then",
    "start": "2769100",
    "end": "2778390"
  },
  {
    "text": "your matrix is getting messy and\nyou switch to the fast Poisson",
    "start": "2778390",
    "end": "2787010"
  },
  {
    "text": "solver. So it's not quite\nPoisson anymore, because it's has\na messier matrix,",
    "start": "2787010",
    "end": "2792970"
  },
  {
    "text": "but it still has the\nsame eigenvectors.",
    "start": "2792970",
    "end": "2798440"
  },
  {
    "text": "As long as we stay\nwith the matrix K, we know its eigenvectors, and\nwe know that they're sines",
    "start": "2798440",
    "end": "2808410"
  },
  {
    "text": "and that they're\nquick to work with. OK. Anyway, there you go.",
    "start": "2808410",
    "end": "2813510"
  },
  {
    "text": "That's a fast algorithm for\nthe lecture before the spring",
    "start": "2813510",
    "end": "2820780"
  },
  {
    "text": "break. So after the break is, first\nof all, discussion of projects.",
    "start": "2820780",
    "end": "2828210"
  },
  {
    "text": "If your project could\ninclude a page -- and you could maybe email\nthe whole project to Mr. Cho.",
    "start": "2828210",
    "end": "2839240"
  },
  {
    "text": "Maybe also, could you email\nto me a sort of summary page",
    "start": "2839240",
    "end": "2847100"
  },
  {
    "text": "that tells me what you did, so\nI'll save the summary pages, and I'll have for Mr. Cho the\ncomplete project with printout",
    "start": "2847100",
    "end": "2857540"
  },
  {
    "text": "and graph, as far\nas appropriate, and so we'll spend\nsome time on that,",
    "start": "2857540",
    "end": "2864490"
  },
  {
    "text": "and then move to the big topic\nof the rest of the course,",
    "start": "2864490",
    "end": "2873850"
  },
  {
    "text": "which is solving optimization\nproblems, minimization,",
    "start": "2873850",
    "end": "2880450"
  },
  {
    "text": "maximization in many variables.",
    "start": "2880450",
    "end": "2885660"
  },
  {
    "text": "OK, so have a good spring\nbreak and see you a week",
    "start": "2885660",
    "end": "2894829"
  },
  {
    "text": "from Wednesday. Good. ",
    "start": "2894830",
    "end": "2903203"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6390"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6390",
    "end": "13380"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13380",
    "end": "18480"
  },
  {
    "text": " TOM MITCHELL: I want\nto talk about some work",
    "start": "18480",
    "end": "24260"
  },
  {
    "text": "that we're doing to try to\nstudy language in the brain. Actually, to be honest, this\nis part of a grander plan.",
    "start": "24260",
    "end": "33079"
  },
  {
    "text": "So here is what I'm really\ndoing with my research life. I'm interested in\nlanguage, and so I'm",
    "start": "33080",
    "end": "43140"
  },
  {
    "text": "involved in two different\nresearch projects. One of them is to build a\ncomputer to learn to read.",
    "start": "43140",
    "end": "49950"
  },
  {
    "text": "And we have a project\nwhich we call our Never Ending Language Learner,\nwhich is an attempt",
    "start": "49950",
    "end": "56700"
  },
  {
    "text": "to build a computer program\nto learn to read the web. NELL, we call it, has been\nrunning nonstop, 24 hours a day",
    "start": "56700",
    "end": "63930"
  },
  {
    "text": "since 2010. So it's now five years old. If you have very\ngood eyesight, you",
    "start": "63930",
    "end": "69300"
  },
  {
    "text": "can tell that everybody's\nt-shirt there in the group is wearing a NELL fifth\nbirthday party t-shirt.",
    "start": "69300",
    "end": "75990"
  },
  {
    "text": "But it's an effort\nto try to understand",
    "start": "75990",
    "end": "81000"
  },
  {
    "text": "what it would be like to\nbuild a computer program that runs forever and gets\nbetter every day.",
    "start": "81000",
    "end": "86280"
  },
  {
    "text": "In this case, its job is\nto learn to read the web. It is getting better.",
    "start": "86280",
    "end": "91530"
  },
  {
    "text": "It currently has about\n100 million beliefs that it has read from the web.",
    "start": "91530",
    "end": "97540"
  },
  {
    "text": "It's learning to infer new\nbeliefs from old beliefs. It's a better reader today\nthan it was last year.",
    "start": "97540",
    "end": "103439"
  },
  {
    "text": "It was better last year\nthan it was the year before. It's still not anything like\nas competent as you and I,",
    "start": "103440",
    "end": "110280"
  },
  {
    "text": "but it's one line\nof research that you can follow if you're interested\nin understanding language",
    "start": "110280",
    "end": "118410"
  },
  {
    "text": "understanding. The other thread,\nwhich is what I'm going to talk about tonight,\nwhich is in the bottom half",
    "start": "118410",
    "end": "124440"
  },
  {
    "text": "here, is to study how the\nbrain processes language",
    "start": "124440",
    "end": "129990"
  },
  {
    "text": "by putting people\nin brain imaging scanners of different types, and\nshowing them language stimuli,",
    "start": "129990",
    "end": "136769"
  },
  {
    "text": "and getting them to read. So I'm going to focus\nreally on the bottom part. But I can't really talk\nabout this honestly",
    "start": "136770",
    "end": "143070"
  },
  {
    "text": "unless I fess up to the fact\nthat my goal is for these two",
    "start": "143070",
    "end": "149760"
  },
  {
    "text": "projects to collide in\na monstrous collision.",
    "start": "149760",
    "end": "155280"
  },
  {
    "text": "They haven't yet, although\nyou'll see some signs, I hope, tonight, of some\nof the cross-fertilisation",
    "start": "155280",
    "end": "162239"
  },
  {
    "text": "between the two areas. When it comes to the\nbrain imaging work,",
    "start": "162240",
    "end": "167520"
  },
  {
    "text": "we have a very great\nteam of people. One of them, Nicole Rafidi,\nis sitting right here.",
    "start": "167520",
    "end": "174520"
  },
  {
    "text": "Some of you have already\nmet her this week. And so what I'm going to\npresent is really the group work",
    "start": "174520",
    "end": "180840"
  },
  {
    "text": "of quite a few people. And the idea is simple,\nbut here's the brainteaser.",
    "start": "180840",
    "end": "189569"
  },
  {
    "text": "Suppose you're interested in how\nthe brain processes language, and you have access to some\nscanning machines, then",
    "start": "189570",
    "end": "196140"
  },
  {
    "text": "what would you do? And so we started\nout by showing people",
    "start": "196140",
    "end": "201300"
  },
  {
    "text": "in a scanner stimuli like these. Maybe single words, initially\nnouns like camera, and drill,",
    "start": "201300",
    "end": "208590"
  },
  {
    "text": "and house, and saw. Sometimes pictures, sometimes\npictures with words under them.",
    "start": "208590",
    "end": "214690"
  },
  {
    "text": "But just showing people\nstimuli to get them to think about some concept.",
    "start": "214690",
    "end": "219960"
  },
  {
    "text": "And then we collect\na brain image, like this one,\nwhich we collected",
    "start": "219960",
    "end": "225060"
  },
  {
    "text": "when a person was looking\nat this particular stimulus, a bottle.",
    "start": "225060",
    "end": "231480"
  },
  {
    "text": "And this is posterior, this is\nthe back of the head on top. This is the front of the\nhead at the bottom here.",
    "start": "231480",
    "end": "238500"
  },
  {
    "text": "And these four slices are\nfour out of about 22 slices",
    "start": "238500",
    "end": "244530"
  },
  {
    "text": "of the brain that make up\nthe three dimensional image. And so you can see here what\nthe brain activity looks like--",
    "start": "244530",
    "end": "251730"
  },
  {
    "text": "kind of blotchy-- when one\nparticular person thinks about,",
    "start": "251730",
    "end": "256859"
  },
  {
    "text": "bottle. So you might ask, what\ndoes it look like if they",
    "start": "256860",
    "end": "262049"
  },
  {
    "text": "think about something else? Well, I can show you what it\nlooks like on the average. If we average over\n60 different words,",
    "start": "262050",
    "end": "268100"
  },
  {
    "text": "then here's the brain activity. And you can see that it\nlooks a lot like bottle,",
    "start": "268100",
    "end": "274080"
  },
  {
    "text": "but maybe there are\nsome differences. And in fact if I subtract\nout this mean activity",
    "start": "274080",
    "end": "282220"
  },
  {
    "text": "from the brain image\nwe get for bottle, then you can see\nthe residue here.",
    "start": "282220",
    "end": "289390"
  },
  {
    "text": "There are in fact\nsome differences in the activity we see\nfor bottle compared to the mean activity\nover many words.",
    "start": "289390",
    "end": "298300"
  },
  {
    "text": "Whether that's\nsignal or noise, I guess you can't tell by\nlooking at this picture.",
    "start": "298300",
    "end": "303370"
  },
  {
    "text": "But that's the kind\nof data that we have if we use fMRI to capture\nbrain activity while people",
    "start": "303370",
    "end": "312190"
  },
  {
    "text": "read words. So the first thing\nyou might think of doing if you had\nthis kind of data",
    "start": "312190",
    "end": "319330"
  },
  {
    "text": "would be to train a\nmachine learning program to decode from these brain\nimages which word somebody is",
    "start": "319330",
    "end": "328409"
  },
  {
    "text": "thinking about it. And so we, in fact, began that\nway by training classifiers",
    "start": "328410",
    "end": "334509"
  },
  {
    "text": "where we'd give\nthem a brain image. And during training\ntime we would tell them",
    "start": "334510",
    "end": "340930"
  },
  {
    "text": "which word that brain\nimage corresponds to. And then after training we\ncould test the classifier",
    "start": "340930",
    "end": "347830"
  },
  {
    "text": "to see whether\nindeed it had learned the right pattern of activity\nby showing it new brain images",
    "start": "347830",
    "end": "354220"
  },
  {
    "text": "and having it tell us, for\nexample, is this person reading the word hammer or bottle.",
    "start": "354220",
    "end": "361630"
  },
  {
    "text": "And, in fact, that works\nthat works quite well. And, in fact, if you try it over\nseveral different participants",
    "start": "361630",
    "end": "368590"
  },
  {
    "text": "in our study, you can see we\nget classification accuracies for a Boolean\nclassification problem.",
    "start": "368590",
    "end": "375190"
  },
  {
    "text": "Are they reading a tool word\nlike hammer, saw, chisel,",
    "start": "375190",
    "end": "381460"
  },
  {
    "text": "or a building were like\nhouse, palace, hotel.",
    "start": "381460",
    "end": "386560"
  },
  {
    "text": "Then, depending on\nthe individual person, we can get in the high 90%\naccuracy or a little worse.",
    "start": "386560",
    "end": "394569"
  },
  {
    "text": "In fact, if you ask why it's\nnot the same for all people,",
    "start": "394570",
    "end": "399970"
  },
  {
    "text": "it turns out the accuracy\nthat we get correlates very well with measure of\nhead motion in the machine.",
    "start": "399970",
    "end": "407090"
  },
  {
    "text": "So a lot of this is noise. But the bottom\nline here is good.",
    "start": "407090",
    "end": "415090"
  },
  {
    "text": "fMRI actually has\nenough resolution to resolve the differences in\nneural activity between, say,",
    "start": "415090",
    "end": "423850"
  },
  {
    "text": "thinking about\nhouse versus hammer. And machine learning methods\ncan discover those distinctions.",
    "start": "423850",
    "end": "433690"
  },
  {
    "text": "So that's a good basis. And so given that, you\ncan start asking a number",
    "start": "433690",
    "end": "441310"
  },
  {
    "text": "of interesting questions. Like we could ask, well,\nwhat about you and me? Do we have the same\npattern of brain activity",
    "start": "441310",
    "end": "448240"
  },
  {
    "text": "to encode hammer, and house,\nand all the other concepts? Or do each of us do\nsomething different?",
    "start": "448240",
    "end": "456350"
  },
  {
    "text": "And we can convert that into\na machine learning question, right? We could say, well, what\nif we train on people",
    "start": "456350",
    "end": "461440"
  },
  {
    "text": "on that side of the room. We'll collect their brain\ndata and train our program.",
    "start": "461440",
    "end": "466830"
  },
  {
    "text": "Then we'll collect\ndata from these people and try to decode\nwhich word they're reading based on\nthe patterns that we",
    "start": "466830",
    "end": "473379"
  },
  {
    "text": "learned from those people. If that works, then that's\noverwhelming evidence",
    "start": "473380",
    "end": "479500"
  },
  {
    "text": "that we have very similar neural\nencodings of different word meanings.",
    "start": "479500",
    "end": "486639"
  },
  {
    "text": "So we tried that and,\nin fact, it works. In fact, here you see in\nblack, the accuracies,",
    "start": "486640",
    "end": "492460"
  },
  {
    "text": "just like on the first slide,\nof how well we can decode which word a person\nis reading in black,",
    "start": "492460",
    "end": "501009"
  },
  {
    "text": "If we train on data from the\nsame person we're testing on. But in white you\nsee the accuracies",
    "start": "501010",
    "end": "507520"
  },
  {
    "text": "we get if we train on no\ndata at all from this person, but instead train\non the data from all",
    "start": "507520",
    "end": "514179"
  },
  {
    "text": "the other participants. And you see on average\nwe do about as well",
    "start": "514179",
    "end": "520210"
  },
  {
    "text": "with the white bars as we\ndo with the black bars. In fact, in some cases\nwe do better training",
    "start": "520210",
    "end": "525730"
  },
  {
    "text": "on other people. That might be, for\nexample, because we get",
    "start": "525730",
    "end": "530860"
  },
  {
    "text": "to use more training examples. We get to use all the other\nparticipants' data instead of just one participant's data.",
    "start": "530860",
    "end": "538310"
  },
  {
    "text": "But again, the\nimportant thing here is, this is very strong evidence\nthat, even though we're all",
    "start": "538310",
    "end": "544029"
  },
  {
    "text": "very different people,\nwe have remarkably similar neural encodings when\nwe think about common nouns.",
    "start": "544030",
    "end": "554394"
  },
  {
    "text": " Which is something that\nreally, say in the year 2000,",
    "start": "554395",
    "end": "561970"
  },
  {
    "text": "I don't think\nanybody understood. So I want to kind of\nwrap up this idea.",
    "start": "561970",
    "end": "568860"
  },
  {
    "text": "So I want to go through\nbasically four ideas in this talk. Idea number one\nis, gee, we could",
    "start": "568860",
    "end": "576280"
  },
  {
    "text": "train classifiers to try to\ndecode from the neural activity",
    "start": "576280",
    "end": "582000"
  },
  {
    "text": "which word a person is reading. And if we do that,\nthen we can actually",
    "start": "582000",
    "end": "587610"
  },
  {
    "text": "ask some interesting\nscientific questions, like are the patterns\nsimilar across our brains?",
    "start": "587610",
    "end": "592800"
  },
  {
    "text": "Does it depend whether\nit's a picture or a word? And, in fact, we can think\nof this technique of training",
    "start": "592800",
    "end": "601030"
  },
  {
    "text": "and classifier as--\nthe way I think of it is it's a way of building a\nvirtual sensor of information",
    "start": "601030",
    "end": "609780"
  },
  {
    "text": "content in the neural signal. So I think that fMRI\nwas truly a revolution",
    "start": "609780",
    "end": "616500"
  },
  {
    "text": "in the study of the brain,\nbecause for the first time we could look inside\nand see the activity.",
    "start": "616500",
    "end": "622889"
  },
  {
    "text": "But I think these classifiers\ngive us a different thing. Now we can look inside and see\nnot just the neural activity,",
    "start": "622890",
    "end": "630240"
  },
  {
    "text": "but the information encoded\nin that neural activity. And so it's a different\nkind of sensor.",
    "start": "630240",
    "end": "637050"
  },
  {
    "text": "And you can design your\nown and train it, and then use it to study\ninformation represented",
    "start": "637050",
    "end": "643050"
  },
  {
    "text": "in the neural\nsignal in the brain. So it kind of opens\nup a very large set",
    "start": "643050",
    "end": "648780"
  },
  {
    "text": "of methods, and techniques,\nand experiments that we can now run with brain imaging.",
    "start": "648780",
    "end": "656100"
  },
  {
    "text": "Where instead of looking\njust at the activity, we now can look at the\ninformation content. ",
    "start": "656100",
    "end": "663690"
  },
  {
    "text": "OK, so that's idea number one. We were quite pleased\nwith ourselves",
    "start": "663690",
    "end": "670226"
  },
  {
    "text": "and we are doing this work. But in the back of\nback of our mind was kind of a gnawing question\nof, well, this is good,",
    "start": "670226",
    "end": "678820"
  },
  {
    "text": "now maybe we've trained on\na couple of hundred words, so we have a couple hundred\ndifferent neural patterns",
    "start": "678820",
    "end": "684639"
  },
  {
    "text": "of activity. We have kind of a list\nof the neural codes for a couple of hundred\nwords, but that's not really",
    "start": "684640",
    "end": "692260"
  },
  {
    "text": "a theory of neural\nencodings of meaning. It's a list.",
    "start": "692260",
    "end": "697960"
  },
  {
    "text": "What would it mean\nto have a theory? Well, scientific theories\nare logical systems",
    "start": "697960",
    "end": "705339"
  },
  {
    "text": "that can make predictions. And if they're\ninteresting theories, they make experimentally\ntestable predictions.",
    "start": "705340",
    "end": "714500"
  },
  {
    "text": "So in our case,\nit would be nice, if we want to study\nrepresentations of meaning,",
    "start": "714500",
    "end": "720610"
  },
  {
    "text": "to have a theory where we\ncould input an arbitrary noun and get it to\npredict for us what",
    "start": "720610",
    "end": "727090"
  },
  {
    "text": "would be the neural\nrepresentation for that non. At least that would\nbe better than a list.",
    "start": "727090",
    "end": "732420"
  },
  {
    "text": "That would be a generative\ntheory or model.",
    "start": "732420",
    "end": "737810"
  },
  {
    "text": "And so we're interested in this. And we worked on this for\na while and came up with--",
    "start": "737810",
    "end": "742930"
  },
  {
    "text": "our first version of\nthis looked like this.",
    "start": "742930",
    "end": "747980"
  },
  {
    "text": "It's a computational\nmodel that was trained. And once it's\ntrained, it would make a prediction for any input word,\nlike telephone, in two steps.",
    "start": "747980",
    "end": "758480"
  },
  {
    "text": "Step one, if you gave it a word\nlike telephone, for example. Step one, it would look\nup the word telephone",
    "start": "758480",
    "end": "765490"
  },
  {
    "text": "in a trillion words of\ntext collected from the web and represent that word\nby a set of statistics",
    "start": "765490",
    "end": "772660"
  },
  {
    "text": "about how telephone is used. In our case,\nstatistics about which verbs co-occurred\nwith that noun.",
    "start": "772660",
    "end": "780730"
  },
  {
    "text": "And then in the\nsecond step, it would use that vector\nwhich approximates",
    "start": "780730",
    "end": "786130"
  },
  {
    "text": "the meaning of the input noun\nas the basis for predicting in each of 20,000\nlocations in the brain,",
    "start": "786130",
    "end": "793570"
  },
  {
    "text": "how much activity\nwill there be there. So let me push on\nthat a little bit.",
    "start": "793570",
    "end": "799450"
  },
  {
    "text": "So I say in step one, we look\nup for a word like celery which",
    "start": "799450",
    "end": "805420"
  },
  {
    "text": "verbs that occur with. Well, here are the\nstatistics that we get. This is normalized to\nbe a vector of length 1.",
    "start": "805420",
    "end": "812360"
  },
  {
    "text": "But you can see for celery\nthe most common verb is eat. And taste is second most common.",
    "start": "812360",
    "end": "818950"
  },
  {
    "text": "But celery doesn't occur\nvery often with ride. On the other hand,\nairplane occurs a lot",
    "start": "818950",
    "end": "825550"
  },
  {
    "text": "with ride, and not very much\nwith manipulate and rub. So these are the verb statistics\nextracted from the web",
    "start": "825550",
    "end": "835420"
  },
  {
    "text": "for two typical nouns. And step one of\nthe model was just",
    "start": "835420",
    "end": "841690"
  },
  {
    "text": "to collect statistics\nfor whatever now we give it to make the prediction. Step two is then to predict\nat each location in the brain",
    "start": "841690",
    "end": "851140"
  },
  {
    "text": "what the neural activity will\nbe there, the fMRI activity,",
    "start": "851140",
    "end": "856300"
  },
  {
    "text": "as a function of those\nstatistics we just collected.",
    "start": "856300",
    "end": "861350"
  },
  {
    "text": "So for the word\ncelery, now we know it occurs 0.84 with eat and\n0.35 with the verb taste.",
    "start": "861350",
    "end": "870339"
  },
  {
    "text": "We're now going to make a\nprediction of this voxel. In particular, the\nprediction that voxel v",
    "start": "870340",
    "end": "877030"
  },
  {
    "text": "is the sum, over those 25\nverbs that we're using, of how frequently verb i\noccurs with the input noun,",
    "start": "877030",
    "end": "886860"
  },
  {
    "text": "celery in this case, times\nsome coefficient that we have to learn from training.",
    "start": "886860",
    "end": "893120"
  },
  {
    "text": "And this coefficient tells\nus how voxel v is influenced by co-occurring with verb i.",
    "start": "893120",
    "end": "901390"
  },
  {
    "text": "And we have 25\nverbs, 20,000 voxels,",
    "start": "901390",
    "end": "906530"
  },
  {
    "text": "so we have 500,000 of these\ncoefficients to learn. ",
    "start": "906530",
    "end": "913810"
  },
  {
    "text": "We learn them by taking\nnouns, collecting the brain-- the same data we use to\ntrain those classifiers.",
    "start": "913810",
    "end": "922100"
  },
  {
    "text": "So we have a collection of nouns\nand the corresponding brain images. For each of those nouns we can\nlook up the verbs statistics.",
    "start": "922100",
    "end": "929890"
  },
  {
    "text": "And then we can\ntrain on that data to estimate all these\nhalf million coefficients.",
    "start": "929890",
    "end": "936880"
  },
  {
    "text": "When you put those coefficients\ntogether, say, for eat, this is actually a plot\nof the coefficient values.",
    "start": "936880",
    "end": "942980"
  },
  {
    "text": "Here's one of those\ncoefficients for the verb eat in a particular\nvoxel right there.",
    "start": "942980",
    "end": "949360"
  },
  {
    "text": "So you can think of the\ncoefficients associated with each verb as forming a kind\nof activity map for that verb.",
    "start": "949360",
    "end": "958780"
  },
  {
    "text": "And a weighted linear sum of\nthose verb-associated activity maps gives us a\nprediction for celery.",
    "start": "958780",
    "end": "967240"
  },
  {
    "text": "You could ask, how well\ndo these predictions work? One way I could answer\nthat is to show you here,",
    "start": "967240",
    "end": "972880"
  },
  {
    "text": "when we trained\non 58 other nouns, not including celery,\nnot including airplane.",
    "start": "972880",
    "end": "978910"
  },
  {
    "text": "And then we had the system\npredict these novel, to it, words.",
    "start": "978910",
    "end": "985470"
  },
  {
    "text": "Celery, it predicted this image. Airplane, it\npredicted this image. Unbeknownst to it, here are\nthe actual observed images",
    "start": "985470",
    "end": "993069"
  },
  {
    "text": "for celery and airplane. So you can see it\ncorrectly predicts",
    "start": "993070",
    "end": "998350"
  },
  {
    "text": "some of this structure-- this is, by the way,\nfusiform gyrus--",
    "start": "998350",
    "end": "1004470"
  },
  {
    "text": "but not all the structure. So it captures some\nof what's going on.",
    "start": "1004470",
    "end": "1011290"
  },
  {
    "text": "I can, in a more\nquantitative way, tell you how well\nit's working by-- we can test the\nprogram this way.",
    "start": "1011290",
    "end": "1018509"
  },
  {
    "text": "We can say, here are two\nwords you have not seen.",
    "start": "1018510",
    "end": "1023640"
  },
  {
    "text": "Here are two images\nyou have not seen. One of them is celery,\none is airplane. You, the program, tell me which.",
    "start": "1023640",
    "end": "1031799"
  },
  {
    "text": "If it was just\nworking at chance, it would get an accuracy of 50%.",
    "start": "1031800",
    "end": "1037189"
  },
  {
    "text": "If you just guess randomly,\nyou'll get half of those right by chance.",
    "start": "1037190",
    "end": "1042750"
  },
  {
    "text": "In its case, averaged over\nnine different subjects in the experiment,\nwe get 79% accuracy.",
    "start": "1042750",
    "end": "1051520"
  },
  {
    "text": "So what does this mean? What this means is, three\ntimes out of four, 79%,",
    "start": "1051520",
    "end": "1058360"
  },
  {
    "text": "we could give this trained model\ntwo new nouns that it has never seen, two fMRI images\nfor those nouns,",
    "start": "1058360",
    "end": "1067030"
  },
  {
    "text": "and it could tell us three times\nout of four which was which. So this model is\nextrapolating beyond the words",
    "start": "1067030",
    "end": "1075610"
  },
  {
    "text": "on which it was trained. And it's extrapolating,\nnot perfectly, but somewhat",
    "start": "1075610",
    "end": "1082720"
  },
  {
    "text": "successfully to other nouns. Now, why? What's the basis on which\nit's doing that extrapolation?",
    "start": "1082720",
    "end": "1090610"
  },
  {
    "text": "What are the assumptions\nbuilt into this model? Well, for one\nthing, it's assuming that you can predict the neural\nrepresentation of any word",
    "start": "1090610",
    "end": "1100270"
  },
  {
    "text": "based on corpus\nstatistics summarizing how that word is used on the web.",
    "start": "1100270",
    "end": "1107560"
  },
  {
    "text": "Furthermore, it's assuming\nthat any noun you can think of",
    "start": "1107560",
    "end": "1115630"
  },
  {
    "text": "has a neural\nrepresentation which lives in a 25-dimensional\nvector space, where",
    "start": "1115630",
    "end": "1123940"
  },
  {
    "text": "each dimension corresponds\nto one of those 25 verbs. And every image is some point\nin this 25-dimensional vector",
    "start": "1123940",
    "end": "1135520"
  },
  {
    "text": "space. That's what that\nlinear equation is",
    "start": "1135520",
    "end": "1140710"
  },
  {
    "text": "doing when it's combining\nsome weighted combination of these 25 axes to\npredict the image.",
    "start": "1140710",
    "end": "1149270"
  },
  {
    "text": "So, I don't actually\nbelieve that everything you think lives in a\n25-dimensional space",
    "start": "1149270",
    "end": "1154990"
  },
  {
    "text": "where the dimensions\nare those verbs. But the interesting thing\nis that the model works.",
    "start": "1154990",
    "end": "1162280"
  },
  {
    "text": "And so it does mean that there\nis some more primitive set",
    "start": "1162280",
    "end": "1169950"
  },
  {
    "text": "of meaning components out of\nwhich these neural patterns are being constructed.",
    "start": "1169950",
    "end": "1175620"
  },
  {
    "text": " It's not just a big hash\ncode where every word",
    "start": "1175620",
    "end": "1181240"
  },
  {
    "text": "gets its own pattern. If that were the\ncase, we wouldn't be able to extrapolate\nand predict new ones by adding together\nthese different 25 components.",
    "start": "1181240",
    "end": "1194120"
  },
  {
    "text": "So patterns are\nbeing built up out of more primitive\nsemantic components.",
    "start": "1194120",
    "end": "1200410"
  },
  {
    "text": "And this model is\ncrudely, only 79%,",
    "start": "1200410",
    "end": "1206710"
  },
  {
    "text": "capturing some of\nthat substructure that gets combined when you\nthink about an entire word.",
    "start": "1206710",
    "end": "1217940"
  },
  {
    "text": "And the substructure are the\ndifferent meaning components. The point here, I\nthink, is, here's",
    "start": "1217940",
    "end": "1224080"
  },
  {
    "text": "a model that's different\nfrom training a classifier. This is actually a\ngenerative model. It can make predictions that\nextrapolate beyond the training",
    "start": "1224080",
    "end": "1232750"
  },
  {
    "text": "words on which it was trained. It is assuming that there is\na space of semantic primitives",
    "start": "1232750",
    "end": "1242049"
  },
  {
    "text": "out of which the patterns of\nneural activity are built. And it is assuming that that\nspace is at least spanned",
    "start": "1242050",
    "end": "1249550"
  },
  {
    "text": "by the corpus\nstatistics of the noun.",
    "start": "1249550",
    "end": "1255640"
  },
  {
    "text": "And since then, we've\nextended this work, and we no longer use just\nthat list of 25 verbs.",
    "start": "1255640",
    "end": "1264010"
  },
  {
    "text": "We actually use a very high\n100-million-dimensional vector,",
    "start": "1264010",
    "end": "1273130"
  },
  {
    "text": "which is generally\nvery sparse, but where every feature comes from a\nmuch more precise parse of text",
    "start": "1273130",
    "end": "1282070"
  },
  {
    "text": "on the web. And for example,\nwhen I say parse,",
    "start": "1282070",
    "end": "1288340"
  },
  {
    "text": "I mean if we have\na simple sentence like, he booked a ticket, this\nwould be a dependency parse.",
    "start": "1288340",
    "end": "1294429"
  },
  {
    "text": "It's showing, for\nexample, that booked is a verb whose subject is\nhe and whose direct object",
    "start": "1294430",
    "end": "1299560"
  },
  {
    "text": "is ticket. And now each of these\nedges in the parse becomes a feature in our new\nrepresentation of the word.",
    "start": "1299560",
    "end": "1309160"
  },
  {
    "text": "So instead of using verbs, we\nuse dependency parse features. And this actually increases\nslightly the accuracy",
    "start": "1309160",
    "end": "1318280"
  },
  {
    "text": "of our former model\nfrom 79 up a little bit. But importantly, it also lets us\nwork with all parts of speech.",
    "start": "1318280",
    "end": "1327500"
  },
  {
    "text": "So now we're not restricted\nto just using nouns. We can use these dependency\nparse vectors for adjectives",
    "start": "1327500",
    "end": "1334330"
  },
  {
    "text": "and all parts of speech. So in terms of\nbroadening the model",
    "start": "1334330",
    "end": "1340149"
  },
  {
    "text": "to be able to handle\ndifferent types of words, this is helpful. So at this point you\ncould say, well, this",
    "start": "1340150",
    "end": "1347260"
  },
  {
    "text": "is kind of interesting,\nbecause what have we seen? I think the main\npoints so far are, gee,",
    "start": "1347260",
    "end": "1356050"
  },
  {
    "text": "different people have\nvery similar patterns of neural activity that their\nbrains use to encode meaning.",
    "start": "1356050",
    "end": "1363760"
  },
  {
    "text": "Furthermore, those\npatterns of neural activity decompose into more primitive\nsemantic components.",
    "start": "1363760",
    "end": "1370990"
  },
  {
    "text": "And we can train models that\nextrapolate to new words",
    "start": "1370990",
    "end": "1376990"
  },
  {
    "text": "on which they weren't trained\nby learning those more",
    "start": "1376990",
    "end": "1382360"
  },
  {
    "text": "primitive semantic\ncomponents and how to combine them for novel words\nbased on corpus statistics.",
    "start": "1382360",
    "end": "1390289"
  },
  {
    "text": "So that's kind of interesting. But everything that\nI've said so far is really about the static\nspatial distribution",
    "start": "1390290",
    "end": "1397030"
  },
  {
    "text": "of neural activity that\nencodes these things. Now, in truth, your\nneural activity",
    "start": "1397030",
    "end": "1404409"
  },
  {
    "text": "is not just one little snapshot. When you understand a word--\ndo you know how long it",
    "start": "1404410",
    "end": "1409420"
  },
  {
    "text": "takes you to understand a word? ",
    "start": "1409420",
    "end": "1414430"
  },
  {
    "text": "About 400 milliseconds. It takes about 400 milliseconds\nto understand a word.",
    "start": "1414430",
    "end": "1420930"
  },
  {
    "text": "Well, it turns out there is\ninteresting brain activity dynamics during those\n400 milliseconds.",
    "start": "1420930",
    "end": "1427809"
  },
  {
    "text": "And let me show you. So up till now, we were\nlooking at fMRI data.",
    "start": "1427810",
    "end": "1434020"
  },
  {
    "text": "But here's some\nmagnetoencephalography data. And this data has a time\nresolution of one millisecond.",
    "start": "1434020",
    "end": "1441700"
  },
  {
    "text": "So I'll show you\nthis movie which begins 20 milliseconds before\na word appears on the screen.",
    "start": "1441700",
    "end": "1449270"
  },
  {
    "text": "In this case, the\nword is the word hand. And this brain is about\nto read the word hand.",
    "start": "1449270",
    "end": "1455440"
  },
  {
    "text": "You'll see 550 milliseconds\nof brain activity. I'll read out the\nnumbers so you can just",
    "start": "1455440",
    "end": "1461440"
  },
  {
    "text": "watch the activity over here. So here we go. 20 milliseconds before the\nword appears on the screen.",
    "start": "1461440",
    "end": "1468890"
  },
  {
    "text": "0, 100, 200 milliseconds,\n300, 400 milliseconds, 500.",
    "start": "1468890",
    "end": "1491520"
  },
  {
    "text": "OK, so it wasn't a static\nsnapshot of activity. Your brain is doing\na lot of things.",
    "start": "1491520",
    "end": "1497909"
  },
  {
    "text": "There's a lot of dynamism\nduring that 400 milliseconds that you're reading the word.",
    "start": "1497910",
    "end": "1503520"
  },
  {
    "text": "fMRI captures an image\nabout once a second,",
    "start": "1503520",
    "end": "1510270"
  },
  {
    "text": "but because of the\nblood oxygen level dependent mechanism that it\nuses to capture that, it's",
    "start": "1510270",
    "end": "1518340"
  },
  {
    "text": "kind of smeared out over time. So we can't see this dynamics\nwith fMRI, but with MEG we can.",
    "start": "1518340",
    "end": "1525419"
  },
  {
    "text": "And so now we can ask all\nkinds of interesting questions, like well, what was\nthe information encoded",
    "start": "1525420",
    "end": "1531390"
  },
  {
    "text": "in that movie that we just saw? I just showed you a\nmovie of neural activity,",
    "start": "1531390",
    "end": "1536730"
  },
  {
    "text": "but I want a movie of\ndata flow in the brain.",
    "start": "1536730",
    "end": "1542270"
  },
  {
    "text": "I want the movie showing\nme what information is encoded over time. Given this data,\nwhat could we do?",
    "start": "1542270",
    "end": "1549700"
  },
  {
    "text": "Well, here's one\nthing we can do. In fact, Gus Sudre did\nthis for his PhD thesis. He said, I want to know\nwhat information is flowing",
    "start": "1549700",
    "end": "1557850"
  },
  {
    "text": "around the brain\nthere, so I'm going to train roughly a million\ndifferent classifiers.",
    "start": "1557850",
    "end": "1563100"
  },
  {
    "text": "I'll train classifiers that\nlook at just 100 milliseconds worth of that movie and\nlook at just one of 70",
    "start": "1563100",
    "end": "1570840"
  },
  {
    "text": "or so anatomically\ndefined brain regions. And I'll use a set\nof features-- he",
    "start": "1570840",
    "end": "1578940"
  },
  {
    "text": "wasn't using our verbs anymore. He was using a set\nof 229 features",
    "start": "1578940",
    "end": "1586410"
  },
  {
    "text": "that we had made up manually\nand that were inspired",
    "start": "1586410",
    "end": "1592740"
  },
  {
    "text": "by the game 20 questions. These were features\nof the word, not like, how often does a court\ndoes it co-occur with the verb",
    "start": "1592740",
    "end": "1599640"
  },
  {
    "text": "eat? But instead, features\nlike, would you eat it? Yes or no.",
    "start": "1599640",
    "end": "1604660"
  },
  {
    "text": "Is it bigger than a bread box? Yes or no. And so forth. He had a set of 218\nquestions like that.",
    "start": "1604660",
    "end": "1612000"
  },
  {
    "text": "And every word\ncould be described by a set of 218 answers\nto those questions,",
    "start": "1612000",
    "end": "1619790"
  },
  {
    "text": "analogous to the verbs. And so what Gus did is, for\nevery one of those features,",
    "start": "1619790",
    "end": "1626100"
  },
  {
    "text": "every one of those\n218 features like, is it bigger than a breadbox,\nhe trained a classifier",
    "start": "1626100",
    "end": "1632549"
  },
  {
    "text": "to try to decode the\nvalue of that for the word that you're reading from\njust 100 milliseconds",
    "start": "1632550",
    "end": "1638789"
  },
  {
    "text": "worth of this movie, and\nlooking at just one of 70 anatomically defined regions.",
    "start": "1638790",
    "end": "1645840"
  },
  {
    "text": "And so when he did\nthat, he ended up being able to make us a movie\nof what information is coded,",
    "start": "1645840",
    "end": "1654930"
  },
  {
    "text": "in which part of\nthe brain, when. And he ran this--\nevery 50 milliseconds he'd move forward and use a\n100 millisecond window starting",
    "start": "1654930",
    "end": "1662550"
  },
  {
    "text": "there. So he found that during\nthe first 50 milliseconds after the word\nappears on the screen,",
    "start": "1662550",
    "end": "1670170"
  },
  {
    "text": "none of those classifiers\ncould reliably, in a cross validated\nway, produce",
    "start": "1670170",
    "end": "1678330"
  },
  {
    "text": "any reliable predictions. Meaning the neural\nsignals seems to not",
    "start": "1678330",
    "end": "1683460"
  },
  {
    "text": "encode any of those\nsemantic features during the first\n50 milliseconds.",
    "start": "1683460",
    "end": "1690059"
  },
  {
    "text": "By timing out to\n100 milliseconds, there were no semantic features,\nbut you could decode things",
    "start": "1690060",
    "end": "1695100"
  },
  {
    "text": "like the number of letters\nin the word, the word length. ",
    "start": "1695100",
    "end": "1701000"
  },
  {
    "text": "At 150 milliseconds,\nat 200 milliseconds, you got the first\nsemantic feature.",
    "start": "1701000",
    "end": "1706880"
  },
  {
    "text": "Is it hairy?  I think this is actually a\nstand-in for, is it alive?",
    "start": "1706880",
    "end": "1716210"
  },
  {
    "text": "But the feature he happened\nto uncover was, is it hairy? At 200 milliseconds.",
    "start": "1716210",
    "end": "1723140"
  },
  {
    "text": "At 250, now we start to\nsee more semantic features. 300, 350, 400, 450.",
    "start": "1723140",
    "end": "1732410"
  },
  {
    "text": "So literally, these are the\nsemantic features trickling",
    "start": "1732410",
    "end": "1744310"
  },
  {
    "text": "in over time during\nthis 500 milliseconds-- that's the movie--",
    "start": "1744310",
    "end": "1749740"
  },
  {
    "text": "that corresponds to\nthe neural activity that I showed you\nin that first movie.",
    "start": "1749740",
    "end": "1756799"
  },
  {
    "text": "So this is a kind of data flow\npicture of what information",
    "start": "1756800",
    "end": "1763090"
  },
  {
    "text": "is flowing around in the\nbrain in that neural activity during that 450\nmilliseconds so far.",
    "start": "1763090",
    "end": "1772700"
  },
  {
    "text": "Here's the set. Out of those 218 questions,\nhere are the 20 most decodable",
    "start": "1772700",
    "end": "1778809"
  },
  {
    "text": "features. So the number one feature\nthat's most decodable,",
    "start": "1778810",
    "end": "1784670"
  },
  {
    "text": "is that bigger than\na loaf of bread? But actually, if you\nlook at those questions,",
    "start": "1784670",
    "end": "1789740"
  },
  {
    "text": "you see many of the\nmost incredible ones are really size.",
    "start": "1789740",
    "end": "1795149"
  },
  {
    "text": "And many of the next\nare manipulability. And many others are animacy.",
    "start": "1795150",
    "end": "1800820"
  },
  {
    "text": "And some are shelter. In fact, we've across a\ndiverse set of experiments",
    "start": "1800820",
    "end": "1810380"
  },
  {
    "text": "keep seeing these\nkind of features. Size, manipulability,\nanimacy, shelter,",
    "start": "1810380",
    "end": "1816620"
  },
  {
    "text": "edibility are recurring as\nfeatures that have their own--",
    "start": "1816620",
    "end": "1826620"
  },
  {
    "text": "they seem to be kind\nof naturally some of the primitive components.",
    "start": "1826620",
    "end": "1833539"
  },
  {
    "text": "And they have their\ncorresponding neural signatures, out of which the\nencoding of the full word",
    "start": "1833540",
    "end": "1840740"
  },
  {
    "text": "is built. So if you ask me\nright now, what's my best guess of what are\nthe semantic primitives out",
    "start": "1840740",
    "end": "1847909"
  },
  {
    "text": "of which the neural\ncodes are built, I'd say, I don't really know. But these features plus\nedibility, for example,",
    "start": "1847910",
    "end": "1856340"
  },
  {
    "text": "keep recurring in\nwhat we're seeing. And they have their\nown spatial regions where the codes seem to live.",
    "start": "1856340",
    "end": "1865000"
  },
  {
    "text": "OK, so I want to get to\nthe final part, which",
    "start": "1865000",
    "end": "1870410"
  },
  {
    "text": "is, so far we've talked\nabout just single words. And there's plenty of\ninteresting questions",
    "start": "1870410",
    "end": "1877370"
  },
  {
    "text": "we can ask about single words. But really, language is\nabout multiple words. And so I want to show you a\ncouple of examples of some more",
    "start": "1877370",
    "end": "1885799"
  },
  {
    "text": "recent work where we've been\nlooking at semantic composition with the adjective-noun phrases.",
    "start": "1885800",
    "end": "1891590"
  },
  {
    "text": "This is the work of Alona Fyshe. And what she did is\nshe presented people",
    "start": "1891590",
    "end": "1896690"
  },
  {
    "text": "with just simple\nadjective-noun sequences.",
    "start": "1896690",
    "end": "1902059"
  },
  {
    "text": "She put an adjective on\nthe screen like tasty,",
    "start": "1902060",
    "end": "1907190"
  },
  {
    "text": "leave it there\nfor half a second, then a noun like tomato.",
    "start": "1907190",
    "end": "1913730"
  },
  {
    "text": "And she was interested\nin the question of, well, where and when is the\nneural encoding of these two",
    "start": "1913730",
    "end": "1923930"
  },
  {
    "text": "words, and what does\nthat encoding look like? So I'll show you a\ncouple of things.",
    "start": "1923930",
    "end": "1930270"
  },
  {
    "text": "One is, here is a picture\nof the classifier weights",
    "start": "1930270",
    "end": "1939320"
  },
  {
    "text": "that were learned to\ndecode the adjective. And you have to\nthink of it this way.",
    "start": "1939320",
    "end": "1945650"
  },
  {
    "text": "Here's time. And this is the time, the\nfirst 500 milliseconds",
    "start": "1945650",
    "end": "1951020"
  },
  {
    "text": "when the adjectives\non the screen. Then there's 300\nmilliseconds of dead air.",
    "start": "1951020",
    "end": "1956320"
  },
  {
    "text": "Then 500 milliseconds when\nthe noun is on the screen. And then more dead air.",
    "start": "1956320",
    "end": "1962779"
  },
  {
    "text": "This, the vertical axis,\nare different locations in the sensor helmet\nof the MEG scanner.",
    "start": "1962780",
    "end": "1971030"
  },
  {
    "text": "And there are\nabout 306 of those. ",
    "start": "1971030",
    "end": "1976909"
  },
  {
    "text": "The intensity here\nis showing the weight of a trained classifier\nthat was trained",
    "start": "1976910",
    "end": "1984020"
  },
  {
    "text": "to decode the adjective. And, in fact, this\nis the pattern of activity associated\nwith the adjective gentle.",
    "start": "1984020",
    "end": "1991960"
  },
  {
    "text": "Like gentle bear. ",
    "start": "1991960",
    "end": "1997310"
  },
  {
    "text": "And so what you see here is\nthat there is neural activity out here when the\nnoun is on the screen",
    "start": "1997310",
    "end": "2004720"
  },
  {
    "text": "long after the adjective has\ndisappeared from the screen. That's quite\nrelevant to decoding",
    "start": "2004720",
    "end": "2010790"
  },
  {
    "text": "what the adjective was.  And so this is just\nkind of a quick look.",
    "start": "2010790",
    "end": "2019960"
  },
  {
    "text": "You can see that if I say\ntasty tomato, even when",
    "start": "2019960",
    "end": "2026320"
  },
  {
    "text": "you're reading the word tomato,\nthere's neural activity here, when you're looking at\nthat noun, that encodes",
    "start": "2026320",
    "end": "2034059"
  },
  {
    "text": "what the adjective had been. And we can see\nthat, in fact, it's",
    "start": "2034060",
    "end": "2039850"
  },
  {
    "text": "a different pattern\nof neural activity than was here when\nthe adjective was on.",
    "start": "2039850",
    "end": "2045070"
  },
  {
    "text": "And in fact, one thing that\nAlona got interested in",
    "start": "2045070",
    "end": "2050260"
  },
  {
    "text": "is, given that you\ncan decode across time what that adjective\nwas, is your brain",
    "start": "2050260",
    "end": "2056859"
  },
  {
    "text": "using the same neural\nencoding across time? Or is it a different\nneural encoding, maybe",
    "start": "2056860",
    "end": "2064750"
  },
  {
    "text": "for different\npurposes across time. Let me explain what she did.",
    "start": "2064750",
    "end": "2070658"
  },
  {
    "text": "She trained a\nclassifier at one time",
    "start": "2070659",
    "end": "2077260"
  },
  {
    "text": "in this time series\nof adjective-noun, and then she would test it\nat some other time point.",
    "start": "2077260",
    "end": "2087580"
  },
  {
    "text": "And if you could\ntrain at this time, like let's say, right when the\nadjective comes on the screen,",
    "start": "2087580",
    "end": "2092830"
  },
  {
    "text": "and use it successfully\nto decode the adjective way down here when the\nnoun is on the screen,",
    "start": "2092830",
    "end": "2098859"
  },
  {
    "text": "then we can know that it's\nthe same neural encoding, because that's what it's doing.",
    "start": "2098860",
    "end": "2105220"
  },
  {
    "text": "And then she made a plot,\na two-dimensional plot, where you could plot, let's\nsay, the time at which you train",
    "start": "2105220",
    "end": "2112059"
  },
  {
    "text": "the classifier on\nthe vertical axis, and the time at which you test\nit on the horizontal axis.",
    "start": "2112060",
    "end": "2118560"
  },
  {
    "text": "And then we could show at\neach training test time whether you could\ntrain at this time",
    "start": "2118560",
    "end": "2126640"
  },
  {
    "text": "and then decode at this time. And that'll tell\nus whether there's a stable neural encoding of the\nadjective meaning across time.",
    "start": "2126640",
    "end": "2134845"
  },
  {
    "text": "When she did that, here's\nwhat it looks like. ",
    "start": "2134845",
    "end": "2140710"
  },
  {
    "text": "OK, so here we have\non the vertical axis the time at which she trained.",
    "start": "2140710",
    "end": "2146250"
  },
  {
    "text": "This is when the adjective is\non the screen, the first 500 milliseconds, when the\nnoun's on the screen.",
    "start": "2146250",
    "end": "2152380"
  },
  {
    "text": "Here's then using any of\nthese trained classifiers",
    "start": "2152380",
    "end": "2157500"
  },
  {
    "text": "for decoding the adjective. Here's a different time at\nwhich she tried to use it. And again, here's\nwhen the adjective's",
    "start": "2157500",
    "end": "2164070"
  },
  {
    "text": "on the screen, the noun. And so what you see-- all this intense stuff means\nhigh decoding accuracy--",
    "start": "2164070",
    "end": "2171779"
  },
  {
    "text": "shows that if you train when\nthe adjective is on the screen,",
    "start": "2171780",
    "end": "2177450"
  },
  {
    "text": "you can use that to decode other\ntimes at which the adjective's on the screen. That's good.",
    "start": "2177450",
    "end": "2184420"
  },
  {
    "text": "So we can decode adjectives. But if you try to use it to\ndecode the adjective when",
    "start": "2184420",
    "end": "2190590"
  },
  {
    "text": "the noun's on the\nscreen, it fails. Blue means failure.",
    "start": "2190590",
    "end": "2196380"
  },
  {
    "text": "No statistically significant\ndecoding accuracy. On the other hand, when\nthe noun is on the screen",
    "start": "2196380",
    "end": "2203190"
  },
  {
    "text": "if you train using the\nneural patterns when the nouns on the\nscreen, then you can, in fact, decode\nwhat the adjective",
    "start": "2203190",
    "end": "2210420"
  },
  {
    "text": "had been while the\nnoun is on the screen. So it's like there are\ntwo different encodings",
    "start": "2210420",
    "end": "2216600"
  },
  {
    "text": "of the adjective\nbeing used here. One when the adjective's\non the screen that lets you successfully decode it when\nthe adjective's on the screen,",
    "start": "2216600",
    "end": "2224190"
  },
  {
    "text": "but it doesn't work when\nthe noun's on the screen. And then the second one that\nworks another neural encoding",
    "start": "2224190",
    "end": "2231319"
  },
  {
    "text": "that you can use to decode\nwhat the adjective had been when the noun is on the screen.",
    "start": "2231320",
    "end": "2237920"
  },
  {
    "text": "And then interestingly, there's\nalso this other region here, which says if you train when\nthe adjective was on the screen,",
    "start": "2237920",
    "end": "2245400"
  },
  {
    "text": "you can't use that to\nsuccessfully decode it when the noun's on the screen. But later on, when nothing is on\nthe screen, the phrase is gone,",
    "start": "2245400",
    "end": "2254840"
  },
  {
    "text": "your brain is still\nthinking about the adjective in a way that's using this\nneural encoding, the very first",
    "start": "2254840",
    "end": "2263320"
  },
  {
    "text": "of those neural encodings. This is evidence that the neural\nencoding of the adjective that",
    "start": "2263320",
    "end": "2270530"
  },
  {
    "text": "was present when you\nsaw the adjective is re-emerging now a\ncouple seconds later,",
    "start": "2270530",
    "end": "2278119"
  },
  {
    "text": "after that thing\nis off the screen. But the neural encoding\nof the adjective",
    "start": "2278120",
    "end": "2284100"
  },
  {
    "text": "when the noun was on the screen\ndoesn't seem to get used again.",
    "start": "2284100",
    "end": "2289340"
  },
  {
    "text": "Most recently, we've\nalso been looking at stories and passages.",
    "start": "2289340",
    "end": "2294890"
  },
  {
    "text": "And much of this,\nnot all of it, is the work of Leila Wehbe,\nanother PhD student.",
    "start": "2294890",
    "end": "2302780"
  },
  {
    "text": "And here's what she did. She put people in fMRI\nand in MEG scanners,",
    "start": "2302780",
    "end": "2308765"
  },
  {
    "text": "and she showed them the\nfollowing kind of stimulus. ",
    "start": "2308765",
    "end": "2325710"
  },
  {
    "text": "So this goes on for\nabout 40 minutes. One chapter of a\nHarry Potter story.",
    "start": "2325710",
    "end": "2331010"
  },
  {
    "text": "And word by word,\nevery 500 milliseconds, we know exactly when\nyou've seen every word.",
    "start": "2331010",
    "end": "2337020"
  },
  {
    "text": "So she collected this\ndata in fMRI and in MEG to try to study the\njumble of activity that",
    "start": "2337020",
    "end": "2345746"
  },
  {
    "text": "goes on in your\nbrain when you're reading not an isolated\nword, but a whole story.",
    "start": "2345746",
    "end": "2350930"
  },
  {
    "text": "And so for her, with the fMRI we\nget an image every two seconds.",
    "start": "2350930",
    "end": "2358200"
  },
  {
    "text": "So four words go by and\nwe get an fMRI image. So here's the kind\nof data that she had.",
    "start": "2358200",
    "end": "2363800"
  },
  {
    "text": "She trained a model that's\nvery analogous to the very first generative model I\ntalked about where we would",
    "start": "2363800",
    "end": "2370970"
  },
  {
    "text": "input a word, code\nit with verbs, and then use that to\npredict neural activity. In her case, she took an\napproach where for every word,",
    "start": "2370970",
    "end": "2383190"
  },
  {
    "text": "she would encode that word\nwith a big feature vector. And that vector could\nsummarize both the meaning",
    "start": "2383190",
    "end": "2391640"
  },
  {
    "text": "of the individual\nword, but it also could have other\nfeatures that capture the context or the various\nproperties of the story",
    "start": "2391640",
    "end": "2402380"
  },
  {
    "text": "at that point in time. But the general framework\nwas to convert the time",
    "start": "2402380",
    "end": "2407599"
  },
  {
    "text": "series of words into a time\nseries of feature vectors that capture individual\nword meanings plus story",
    "start": "2407600",
    "end": "2414500"
  },
  {
    "text": "content at that time, and then\nto use that to predict the fMRI",
    "start": "2414500",
    "end": "2420110"
  },
  {
    "text": "and MEG activity. So when she did\nthis, here are some",
    "start": "2420110",
    "end": "2427210"
  },
  {
    "text": "of the kind of features\nthat we ended up using. So some of there were like\nmotions of the characters,",
    "start": "2427210",
    "end": "2436950"
  },
  {
    "text": "like was there somebody flying-- this was the Harry Potter story. Somebody manipulating,\nor moving,",
    "start": "2436950",
    "end": "2442390"
  },
  {
    "text": "or physically colliding. What were the emotions\nbeing experienced",
    "start": "2442390",
    "end": "2447430"
  },
  {
    "text": "by the characters in the\nstory that you're focused on at this point in time? What were the parts of\nspeech of the different words",
    "start": "2447430",
    "end": "2455230"
  },
  {
    "text": "and other syntactic features. What were the semantic content?",
    "start": "2455230",
    "end": "2460310"
  },
  {
    "text": "We also used the\ndependency parse statistics that I mentioned that capture\nsemantics of individual words.",
    "start": "2460310",
    "end": "2467070"
  },
  {
    "text": "So altogether, she had a feature\nvector with about 200 features. Some manually annotated, some\ncaptured by corpus statistics.",
    "start": "2467070",
    "end": "2475190"
  },
  {
    "text": "And for every word\nin the story we then had this feature vector. Then she trained this\nmodel that literally",
    "start": "2475190",
    "end": "2483160"
  },
  {
    "text": "would take as input a sequence\nof words, convert that",
    "start": "2483160",
    "end": "2490690"
  },
  {
    "text": "into the feature\nsequence, and then,",
    "start": "2490690",
    "end": "2495819"
  },
  {
    "text": "using the trained\nregression, predict the time series\nof brain activity from those feature vectors.",
    "start": "2495820",
    "end": "2503030"
  },
  {
    "text": "So this allowed\nher to then test, analogous to what we did with\nour single word noun generative",
    "start": "2503030",
    "end": "2510910"
  },
  {
    "text": "model, to test to see, did the\nmodel learn well enough that we could give it to different\npassages, and then",
    "start": "2510910",
    "end": "2518920"
  },
  {
    "text": "one real time series\nof observed data, and ask it to tell us\nwhich passage this person",
    "start": "2518920",
    "end": "2524800"
  },
  {
    "text": "was reading. And these would be novel\npassages that were not part of the training data.",
    "start": "2524800",
    "end": "2530200"
  },
  {
    "text": "And she found that it was, in\nfact, possible, imperfectly,",
    "start": "2530200",
    "end": "2535990"
  },
  {
    "text": "but three times out of four,\nto take a passage which was not part of--",
    "start": "2535990",
    "end": "2542290"
  },
  {
    "text": "two passages which had\nnever been seen in training, and a time series of\nneural activity never seen",
    "start": "2542290",
    "end": "2547660"
  },
  {
    "text": "during training, and\nthree times out of four, tell us which of those two\npassages they correspond to.",
    "start": "2547660",
    "end": "2555310"
  },
  {
    "text": "So capturing some of\nthe structure here. Interestingly, as a\nside effect of that,",
    "start": "2555310",
    "end": "2562000"
  },
  {
    "text": "you end up with a map of\ndifferent cortical regions",
    "start": "2562000",
    "end": "2567590"
  },
  {
    "text": "and which of these 200\nfeatures are encoded in different cortical regions.",
    "start": "2567590",
    "end": "2574400"
  },
  {
    "text": "So from one analysis\nof people reading this very complicated, complex\nstory, in this analysis,",
    "start": "2574400",
    "end": "2582510"
  },
  {
    "text": "we end up-- you can go [AUDIO OUT]\nfeatures and color code. Some of them have to do\nwith syntax, like part",
    "start": "2582510",
    "end": "2589250"
  },
  {
    "text": "of speech and sentence length. Some have to do\nwith dialogue, some have to do visual properties\nor characters in the stories.",
    "start": "2589250",
    "end": "2598760"
  },
  {
    "text": "And you can see here\nis a map of where those different\ntypes of information",
    "start": "2598760",
    "end": "2604160"
  },
  {
    "text": "were decodable from\nthe neural activity. Interestingly, here is a\nslightly earlier piece of work,",
    "start": "2604160",
    "end": "2613730"
  },
  {
    "text": "from Ev Fedorenko showing where\nthere is neural activity that's",
    "start": "2613730",
    "end": "2620119"
  },
  {
    "text": "selectively associated\nwith language processing. The difference here is\nthat in Leila's work,",
    "start": "2620120",
    "end": "2625770"
  },
  {
    "text": "she was also able to\nindicate not just where the activity was, but what\ninformation is encoded there.",
    "start": "2625770",
    "end": "2634010"
  },
  {
    "text": "And then again, you can\ndrill down on some of these. If you want know\nmore about syntax, we could actually look at\nthe different syntax features",
    "start": "2634010",
    "end": "2641510"
  },
  {
    "text": "and see, well, where's the\npart of speech encoded? What about the length\nof the sentence?",
    "start": "2641510",
    "end": "2646590"
  },
  {
    "text": "What about the specific\ndependency role in the parse of the\nword that we're reading",
    "start": "2646590",
    "end": "2651680"
  },
  {
    "text": "right now, and so forth. So this gives us a\nway then of starting",
    "start": "2651680",
    "end": "2659600"
  },
  {
    "text": "to look simultaneously at very\ncomplex cognitive function,",
    "start": "2659600",
    "end": "2664880"
  },
  {
    "text": "right? You're reading a story,\nyou're perceiving the words, you're figuring out\nwhat part of speech,",
    "start": "2664880",
    "end": "2670550"
  },
  {
    "text": "you're parsing the sentence. You're thinking about\nthe plot, you're fitting this into the plot. You're feeling sorry\nfor the hero who",
    "start": "2670550",
    "end": "2677180"
  },
  {
    "text": "just had their brooms stolen,\nand all kinds of stuff going on in your head.",
    "start": "2677180",
    "end": "2683280"
  },
  {
    "text": "Here's the analysis that\nattempts to simultaneously",
    "start": "2683280",
    "end": "2688820"
  },
  {
    "text": "analyze a diverse range\nof these features, and I think with some success.",
    "start": "2688820",
    "end": "2696570"
  },
  {
    "text": "There still remain\nproblems of correlations",
    "start": "2696570",
    "end": "2701960"
  },
  {
    "text": "between different features. And so it might be hard\nto know whether we're",
    "start": "2701960",
    "end": "2708170"
  },
  {
    "text": "decoding the fact that\nsomebody is being shouted at, versus the fact that their\nears are hurting, so to speak.",
    "start": "2708170",
    "end": "2715870"
  },
  {
    "text": "But there could be two\ndifferent properties we thinking of that are highly correlated. And so it can still be\nhard to tease those apart.",
    "start": "2715870",
    "end": "2724670"
  },
  {
    "text": "But I think that, to me,\nthe interesting thing about Leila's analysis here\nis that it flips from a style",
    "start": "2724670",
    "end": "2733820"
  },
  {
    "text": "that I would call reductionist. One way that people often\nstudy language in the brain",
    "start": "2733820",
    "end": "2739370"
  },
  {
    "text": "is they pick one\nphenomena, and then run a carefully controlled\nexperiment to just vary",
    "start": "2739370",
    "end": "2745260"
  },
  {
    "text": "that one dimension. Like we'll use\nwords, and we'll use",
    "start": "2745260",
    "end": "2750300"
  },
  {
    "text": "letter strings that\nare pronounceable that are not words,\nand then words. And we'll just look at\nwhat's different in those two",
    "start": "2750300",
    "end": "2757770"
  },
  {
    "text": "almost identical situations. Here, instead, we have\npeople doing natural reading,",
    "start": "2757770",
    "end": "2763620"
  },
  {
    "text": "doing a complex\ncognitive function, and try to use a\nmultivariate analysis",
    "start": "2763620",
    "end": "2769380"
  },
  {
    "text": "to simultaneously model all\nof those different functions.",
    "start": "2769380",
    "end": "2776690"
  },
  {
    "text": "And so I think this is an\ninteresting, methodologically,",
    "start": "2776690",
    "end": "2782130"
  },
  {
    "text": "position to take. And it also gives\nus a chance to start looking at some of these\nphenomena in story reading.",
    "start": "2782130",
    "end": "2789130"
  },
  {
    "start": "2789130",
    "end": "2808567"
  }
]
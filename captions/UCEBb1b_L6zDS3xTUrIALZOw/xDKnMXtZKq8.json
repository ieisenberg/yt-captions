[
  {
    "start": "0",
    "end": "42000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu.  JULIAN SHUN: All right. So we've talked a little\nbit about caching before,",
    "start": "18140",
    "end": "25920"
  },
  {
    "text": "but today we're going to talk in\nmuch more detail about caching and how to design\ncache-efficient algorithms.",
    "start": "25920",
    "end": "34680"
  },
  {
    "text": "So first, let's look\nat the caching hardware on modern machines today.",
    "start": "34680",
    "end": "41829"
  },
  {
    "text": "So here's what the\ncache hierarchy looks like for a multicore chip. We have a whole\nbunch of processors.",
    "start": "41830",
    "end": "49309"
  },
  {
    "start": "42000",
    "end": "42000"
  },
  {
    "text": "They all have their\nown private L1 caches for both the data, as\nwell as the instruction.",
    "start": "49310",
    "end": "56220"
  },
  {
    "text": "They also have a\nprivate L2 cache. And then they share a last\nlevel cache, or L3 cache,",
    "start": "56220",
    "end": "61480"
  },
  {
    "text": "which is also called LLC. They're all connected\nto a memory controller",
    "start": "61480",
    "end": "67079"
  },
  {
    "text": "that can access DRAM. And then, oftentimes,\nyou'll have multiple chips",
    "start": "67080",
    "end": "72810"
  },
  {
    "text": "on the same server,\nand these chips would be connected\nthrough a network.",
    "start": "72810",
    "end": "78880"
  },
  {
    "text": "So here we have a bunch\nof multicore chips that are connected together.",
    "start": "78880",
    "end": "84130"
  },
  {
    "text": "So we can see that there are\ndifferent levels of memory here.",
    "start": "84130",
    "end": "90160"
  },
  {
    "text": "And the sizes of each one\nof these levels of memory is different. So the sizes tend to\ngo up as you move up",
    "start": "90160",
    "end": "96690"
  },
  {
    "text": "the memory hierarchy. The L1 caches tend to\nbe about 32 kilobytes.",
    "start": "96690",
    "end": "104970"
  },
  {
    "text": "In fact, these are the\nspecifications for the machines that you're using in this class. So 32 kilobytes for\nboth the L1 data cache",
    "start": "104970",
    "end": "111660"
  },
  {
    "text": "and the L1 instruction cache. 256 kilobytes for the L2 cache.",
    "start": "111660",
    "end": "117580"
  },
  {
    "text": "so the L2 cache tends to\nbe about 8 to 10 times larger than the L1 cache.",
    "start": "117580",
    "end": "123570"
  },
  {
    "text": "And then the last level cache,\nthe size is 30 megabytes. So this is typically on the\norder of tens of megabytes.",
    "start": "123570",
    "end": "130610"
  },
  {
    "text": "And then DRAM is on\nthe order of gigabytes. So here we have\n128 gigabyte DRAM.",
    "start": "130610",
    "end": "138320"
  },
  {
    "text": "And nowadays, you can\nactually get machines that have terabytes of DRAM.",
    "start": "138320",
    "end": "145440"
  },
  {
    "text": "So the associativity tends\nto go up as you move up the cache hierarchy.",
    "start": "145440",
    "end": "150780"
  },
  {
    "text": "And I'll talk more\nabout associativity on the next couple of slides. The time to access the\nmemory also tends to go up.",
    "start": "150780",
    "end": "157800"
  },
  {
    "text": "So the latency tends\nto go up as you move up the memory hierarchy. So the L1 caches are\nthe quickest to access,",
    "start": "157800",
    "end": "164490"
  },
  {
    "text": "about two nanoseconds,\njust rough numbers. The L2 cache is a\nlittle bit slower--",
    "start": "164490",
    "end": "170380"
  },
  {
    "text": "so say four nanoseconds. Last level cache,\nmaybe six nanoseconds.",
    "start": "170380",
    "end": "175410"
  },
  {
    "text": "And then when you\nhave to go to DRAM, it's about an order of magnitude\nslower-- so 50 nanoseconds",
    "start": "175410",
    "end": "180930"
  },
  {
    "text": "in this example. And the reason why the memory\nis further down in the cache",
    "start": "180930",
    "end": "189420"
  },
  {
    "text": "hierarchy are faster\nis because they're using more expensive materials\nto manufacture these things.",
    "start": "189420",
    "end": "194650"
  },
  {
    "text": "But since they tend to be more\nexpensive, we can't fit as much of that on the machines.",
    "start": "194650",
    "end": "199720"
  },
  {
    "text": "So that's why the faster\nmemories are smaller than the slower memories. But if we're able to take\nadvantage of locality",
    "start": "199720",
    "end": "206880"
  },
  {
    "text": "in our programs, then we can\nmake use of the fast memory as much as possible.",
    "start": "206880",
    "end": "212000"
  },
  {
    "text": "And we'll talk about ways to\ndo that in this lecture today. There's also the latency\nacross the network, which",
    "start": "212000",
    "end": "219000"
  },
  {
    "text": "tends to be cheaper than\ngoing to main memory but slower than doing a\nlast level cache access.",
    "start": "219000",
    "end": "227475"
  },
  {
    "text": " And there's a lot\nof work in trying to get the cache coherence\nprotocols right, as we",
    "start": "227475",
    "end": "235770"
  },
  {
    "text": "mentioned before. So since these processors\nall have private caches, we need to make\nsure that they all",
    "start": "235770",
    "end": "241200"
  },
  {
    "text": "see a consistent\nview of memory when they're trying to\naccess the same memory addresses in parallel.",
    "start": "241200",
    "end": "248290"
  },
  {
    "text": "So we talked about the\nMSI cache protocol before. And there are many other\nprotocols out there,",
    "start": "248290",
    "end": "253500"
  },
  {
    "text": "and you can read more\nabout these things online. But these are very\nhard to get right,",
    "start": "253500",
    "end": "258730"
  },
  {
    "text": "and there's a lot of\nverification involved in trying to prove that the\ncache coherence protocols are correct. ",
    "start": "258730",
    "end": "267490"
  },
  {
    "text": "So any questions so far? ",
    "start": "267490",
    "end": "273599"
  },
  {
    "text": "OK. So let's talk about the\nassociativity of a cache. So here I'm showing you a\nfully associative cache.",
    "start": "273600",
    "end": "281690"
  },
  {
    "start": "275000",
    "end": "275000"
  },
  {
    "text": "And in a fully\nassociative cache, a cache block can reside\nanywhere in the cache.",
    "start": "281690",
    "end": "287060"
  },
  {
    "text": "And a basic unit of movement\nhere is a cache block. In this example, the cache\nblock size is 4 bytes,",
    "start": "287060",
    "end": "293750"
  },
  {
    "text": "but on the machines that\nwe're using for this class, the cache block\nsize is 64 bytes.",
    "start": "293750",
    "end": "300110"
  },
  {
    "text": "But for this example, I'm going\nto use a four byte cache line. So each row here corresponds\nto one cache line.",
    "start": "300110",
    "end": "307160"
  },
  {
    "text": "And a fully associative cache\nmeans that each line here can go anywhere in the cache.",
    "start": "307160",
    "end": "313225"
  },
  {
    "text": "And then here\nwe're also assuming a cache size that has 32 bytes. So, in total, it can\nstore eight cache line",
    "start": "313225",
    "end": "319450"
  },
  {
    "text": "since the cache line is 4 bytes. ",
    "start": "319450",
    "end": "324970"
  },
  {
    "text": "So to find a block in a\nfully associative cache, you have to actually\nsearch the entire cache,",
    "start": "324970",
    "end": "330970"
  },
  {
    "text": "because a cache line can\nappear anywhere in the cache. And there's a tag associated\nwith each of these cache lines",
    "start": "330970",
    "end": "338860"
  },
  {
    "text": "here that basically\nspecify which of the memory addresses\nin virtual memory space",
    "start": "338860",
    "end": "345669"
  },
  {
    "text": "it corresponds to. So for the fully\nassociative cache, we're actually going to use\nmost of the bits of that address",
    "start": "345670",
    "end": "351940"
  },
  {
    "text": "as a tag. We don't actually need\nthe two lower order bits, because the\nthings are being",
    "start": "351940",
    "end": "356980"
  },
  {
    "text": "moved at the granularity\nof cache lines, which are four bytes. So the two lower order bits are\nalways going to be the same,",
    "start": "356980",
    "end": "363190"
  },
  {
    "text": "but we're just going to\nuse the rest of the bits to store the tag. So if our address\nspace is 64 bits,",
    "start": "363190",
    "end": "369640"
  },
  {
    "text": "then we're going to use 62 bits\nto store the tag in a fully associative caching scheme.",
    "start": "369640",
    "end": "374800"
  },
  {
    "text": "And when a cache\nbecomes full, a block has to be evicted to make\nroom for a new block.",
    "start": "374800",
    "end": "382000"
  },
  {
    "text": "And there are various\nways that you can decide how to evict a block. So this is known as\nthe replacement policy.",
    "start": "382000",
    "end": "389260"
  },
  {
    "text": "One common replacement policy\nis LRU Least Recently Used. So you basically kick\nthe thing out that",
    "start": "389260",
    "end": "394720"
  },
  {
    "text": "has been used the\nfarthest in the past. The other schemes, such\nas second chance and clock",
    "start": "394720",
    "end": "401979"
  },
  {
    "text": "replacement, we're\nnot going to talk too much about the different\nreplacement schemes today.",
    "start": "401980",
    "end": "407080"
  },
  {
    "text": "But you can feel free to read\nabout these things online. ",
    "start": "407080",
    "end": "413470"
  },
  {
    "text": "So what's a disadvantage\nof this scheme? ",
    "start": "413470",
    "end": "425170"
  },
  {
    "text": "Yes? AUDIENCE: It's slow. JULIAN SHUN: Yeah. Why is it slow? AUDIENCE: Because you have to\ngo all the way [INAUDIBLE]..",
    "start": "425170",
    "end": "432439"
  },
  {
    "text": "JULIAN SHUN: Yeah. So the disadvantage\nis that searching for a cache line in the cache\ncan be pretty slow, because you",
    "start": "432440",
    "end": "438199"
  },
  {
    "text": "have to search entire\ncache in the worst case, since a cache block can\nreside anywhere in the cache.",
    "start": "438200",
    "end": "445370"
  },
  {
    "text": "So even though the search can\ngo on in parallel and hardware is still expensive in terms\nof power and performance",
    "start": "445370",
    "end": "451340"
  },
  {
    "text": "to have to search most\nof the cache every time. So let's look at\nanother extreme.",
    "start": "451340",
    "end": "457580"
  },
  {
    "text": "This is a direct mapped cache. So in a direct mapped\ncache, each cache block",
    "start": "457580",
    "end": "462860"
  },
  {
    "start": "462000",
    "end": "462000"
  },
  {
    "text": "can only go in one\nplace in the cache. So I've color-coded\nthese cache blocks here.",
    "start": "462860",
    "end": "468890"
  },
  {
    "text": "So the red blocks can only go\nin the first row of this cache,",
    "start": "468890",
    "end": "473990"
  },
  {
    "text": "the orange ones can only go\nin the second row, and so on. ",
    "start": "473990",
    "end": "480380"
  },
  {
    "text": "And the position which a\ncache block can go into",
    "start": "480380",
    "end": "486110"
  },
  {
    "text": "is known as that\ncache blocks set. So the set determines\nthe location",
    "start": "486110",
    "end": "491240"
  },
  {
    "text": "in the cache for each\nparticular block. So let's look at how the virtual\nmemory address is divided up",
    "start": "491240",
    "end": "499927"
  },
  {
    "text": "into and which of\nthe bits we're going to use to figure out\nwhere a cache block should go in the cache.",
    "start": "499927",
    "end": "505610"
  },
  {
    "text": "So we have the offset,\nwe have the set, and then the tag fields.",
    "start": "505610",
    "end": "511820"
  },
  {
    "text": "The offset just tells\nus which position we want to access\nwithin a cache block.",
    "start": "511820",
    "end": "517669"
  },
  {
    "text": "So since a cache\nblock has B bytes, we only need log base 2\nof B bits as the offset.",
    "start": "517669",
    "end": "523849"
  },
  {
    "text": "And the reason why\nwe have to offset is because we're not\nalways accessing something at the beginning\nof a cache block. We might want to access\nsomething in the middle.",
    "start": "523850",
    "end": "530800"
  },
  {
    "text": "And that's why we\nneed the offset to specify where in the cache\nblock we want to access. ",
    "start": "530800",
    "end": "537730"
  },
  {
    "text": "Then there's a set field. And the set field is going\nto determine which position",
    "start": "537730",
    "end": "545020"
  },
  {
    "text": "in the cache that cache\nblock can go into. So there are eight possible\npositions for each cache block.",
    "start": "545020",
    "end": "552790"
  },
  {
    "text": "And therefore, we only\nneed log base 2 of 8 bits-- so three bits for the\nset in this example.",
    "start": "552790",
    "end": "559120"
  },
  {
    "text": "And more generally, it's going\nto be log base 2 of M over B. And here, M over B is 8.",
    "start": "559120",
    "end": "565815"
  },
  {
    "text": "And then, finally, we're\ngoing to use the remaining bits as a tag. So w minus log base 2\nof M bits for the tag.",
    "start": "565815",
    "end": "572800"
  },
  {
    "text": "And that gets stored along with\nthe cache block in the cache. And that's going to\nuniquely identify",
    "start": "572800",
    "end": "579070"
  },
  {
    "text": "which of the memory blocks\nthe cache block corresponds to",
    "start": "579070",
    "end": "584560"
  },
  {
    "text": "in virtual memory. And you can verify that the\nsum of all these quantities",
    "start": "584560",
    "end": "593110"
  },
  {
    "text": "here sums to w bits. So in total, we have\na w bit address space.",
    "start": "593110",
    "end": "598120"
  },
  {
    "text": "And the sum of those\nthree things is w.  So what's the advantage and\ndisadvantage of this scheme?",
    "start": "598120",
    "end": "606880"
  },
  {
    "start": "606880",
    "end": "616880"
  },
  {
    "text": "So first, what's a good thing\nabout this scheme compared to the previous\nscheme that we saw?",
    "start": "616880",
    "end": "621990"
  },
  {
    "text": "Yes? AUDIENCE: Faster. JULIAN SHUN: Yeah. It's fast because you only\nhave to check one place. Because each cache\nblock can only",
    "start": "621990",
    "end": "627620"
  },
  {
    "text": "go in one place in a cache,\nand that's only place you have to check when\nyou try to do a lookup.",
    "start": "627620",
    "end": "632810"
  },
  {
    "text": "If the cache block is\nthere, then you find it. If it's not, then you know\nit's not in the cache.",
    "start": "632810",
    "end": "638750"
  },
  {
    "text": "What's the downside\nto this scheme? Yeah? AUDIENCE: You only end\nup putting the red ones",
    "start": "638750",
    "end": "644437"
  },
  {
    "text": "into the cache and you have\nmostly every [INAUDIBLE],, which is totally [INAUDIBLE]. JULIAN SHUN: Yeah. So good answer.",
    "start": "644437",
    "end": "650440"
  },
  {
    "text": "So the downside is that you\nmight, for example, just be accessing the\nred cache blocks",
    "start": "650440",
    "end": "658740"
  },
  {
    "text": "and then not accessing any\nof the other cache blocks. They'll all get mapped to the\nsame location in the cache,",
    "start": "658740",
    "end": "664140"
  },
  {
    "text": "and then they'll keep\nevicting each other, even though there's a lot\nof empty space in the cache.",
    "start": "664140",
    "end": "669149"
  },
  {
    "text": "And this is known\nas a conflict miss. And these can be very\nbad for performance",
    "start": "669150",
    "end": "675000"
  },
  {
    "text": "and very hard to debug. So that's one downside\nof a direct map cache is that you can get these\nconflict misses where you have",
    "start": "675000",
    "end": "682950"
  },
  {
    "text": "to evict things from the\ncache even though there's empty space in the cache. ",
    "start": "682950",
    "end": "689720"
  },
  {
    "text": "So as we said, finding\na block is very fast. Only a single location in\nthe cache has to be searched.",
    "start": "689720",
    "end": "695810"
  },
  {
    "text": "But you might\nsuffer from conflict misses if you keep axing\nthings in the same set repeatedly without accessing\nthe things in the other sets.",
    "start": "695810",
    "end": "705140"
  },
  {
    "text": "So any questions? ",
    "start": "705140",
    "end": "713029"
  },
  {
    "text": "OK. So these are sort of the two\nextremes for cache design.",
    "start": "713030",
    "end": "718870"
  },
  {
    "text": "There's actually\na hybrid solution called set associative cache.",
    "start": "718870",
    "end": "723872"
  },
  {
    "text": "And in a set associative\ncache, you still sets, but each of the sets contains\nmore than one line now.",
    "start": "723872",
    "end": "731200"
  },
  {
    "text": "So all the red blocks\nstill map to the red set, but there's actually\ntwo possible locations",
    "start": "731200",
    "end": "736990"
  },
  {
    "text": "for the red blocks now. So in this case, this is known\nas a two-way associate of cache",
    "start": "736990",
    "end": "744730"
  },
  {
    "text": "since there are two possible\nlocations inside each set. And again, a cache block's set\ndetermines k possible cache",
    "start": "744730",
    "end": "753670"
  },
  {
    "text": "locations for that block. So within a set it's\nfully associative, but each block can only\ngo in one of the sets.",
    "start": "753670",
    "end": "762040"
  },
  {
    "start": "761000",
    "end": "761000"
  },
  {
    "text": " So let's look again\nat how the bits are",
    "start": "762040",
    "end": "768190"
  },
  {
    "text": "divided into in the address. So we still have the tag\nset and offset fields.",
    "start": "768190",
    "end": "773770"
  },
  {
    "text": "The offset field is\nstill a log base 2 of b. The set field is going to take\nlog base 2 of M over kB bits.",
    "start": "773770",
    "end": "784510"
  },
  {
    "text": "So the number of sets\nwe have is M over kB. So we need log base\n2 of that number",
    "start": "784510",
    "end": "791080"
  },
  {
    "text": "to represent the set of a block. And then, finally, we use\nthe remaining bits as a tag,",
    "start": "791080",
    "end": "797589"
  },
  {
    "text": "so it's going to be w minus\nlog base 2 of M over k.",
    "start": "797590",
    "end": "802730"
  },
  {
    "text": "And now, to find a\nblock in the cache, only k locations of it's\nset must be searched.",
    "start": "802730",
    "end": "810400"
  },
  {
    "text": "So you basically find which\nset the cache block maps too, and then you check\nall k locations",
    "start": "810400",
    "end": "816129"
  },
  {
    "text": "within that set to see if\nthat cached block is there.",
    "start": "816130",
    "end": "821320"
  },
  {
    "text": "And whenever you\nwant to whenever you try to put something in the\ncache because it's not there,",
    "start": "821320",
    "end": "826899"
  },
  {
    "text": "you have to evict something. And you evict something from\nthe same set as the block that you're placing\ninto the cache.",
    "start": "826900",
    "end": "833780"
  },
  {
    "text": "So for this example, I showed\na two-way associative cache. But in practice, the\nassociated is usually bigger",
    "start": "833780",
    "end": "839199"
  },
  {
    "text": "say eight-way, 16-way,\nor sometimes 20-way. And as you keep increasing\nthe associativity,",
    "start": "839200",
    "end": "849490"
  },
  {
    "text": "it's going to look more and more\nlike a fully associative cache. And if you have a one\nway associative cache,",
    "start": "849490",
    "end": "855460"
  },
  {
    "text": "then there's just\na direct map cache. So this is a sort of a hybrid in\nbetween-- a fully mapped cache",
    "start": "855460",
    "end": "861310"
  },
  {
    "text": "and a fully associative\ncache in a direct map cache. ",
    "start": "861310",
    "end": "867620"
  },
  {
    "text": "So any questions on set\nassociative caches ? ",
    "start": "867620",
    "end": "878310"
  },
  {
    "text": "OK. So let's go over a taxonomy\nof different types of cache",
    "start": "878310",
    "end": "883340"
  },
  {
    "text": "misses that you can incur. So the first type of cache\nmiss is called a cold miss.",
    "start": "883340",
    "end": "888620"
  },
  {
    "start": "888000",
    "end": "888000"
  },
  {
    "text": "And this is the\ncache miss that you have to incur the first time\nyou access a cache block.",
    "start": "888620",
    "end": "893705"
  },
  {
    "text": "And if you need to access\nthis piece of data, there's no way to get around\ngetting a cold miss for this. Because your cache starts\nout not having this block,",
    "start": "893705",
    "end": "901225"
  },
  {
    "text": "and the first time\nyou access it, you have to bring it into cache.",
    "start": "901225",
    "end": "906959"
  },
  {
    "text": "Then there are capacity misses. So capacity misses\nare cache misses",
    "start": "906960",
    "end": "912660"
  },
  {
    "text": "You get because\nthe cache is full and it can't fit all\nof the cache blocks that you want to access.",
    "start": "912660",
    "end": "918870"
  },
  {
    "text": "So you get a capacity miss\nwhen the previous cache copy would have been\nevicted even with a fully",
    "start": "918870",
    "end": "923970"
  },
  {
    "text": "associative scheme. So even if all of the possible\nlocations in your cache could be used for a\nparticular cache line,",
    "start": "923970",
    "end": "931230"
  },
  {
    "text": "that cache line still has to\nbe evicted because there's not enough space. So that's what's\ncalled a capacity miss.",
    "start": "931230",
    "end": "937529"
  },
  {
    "text": "And you can deal\nwith capacity misses by introducing more locality\ninto your code, both spatial",
    "start": "937530",
    "end": "944610"
  },
  {
    "text": "and temporal locality. And we'll look at ways\nto reduce the capacity misses of algorithms\nlater on in this lecture.",
    "start": "944610",
    "end": "951420"
  },
  {
    "text": " Then there are conflict misses. And conflict misses happen\nin set associate of caches",
    "start": "951420",
    "end": "960000"
  },
  {
    "text": "when you have too many blocks\nfrom the same set wanting",
    "start": "960000",
    "end": "966420"
  },
  {
    "text": "to go into the cache. And some of these\nhave to be evicted, because the set can't\nfit all of the blocks.",
    "start": "966420",
    "end": "974130"
  },
  {
    "text": "And these blocks\nwouldn't have been evicted if you had a fully\nassociative scheme, so these are what's called\nconflict misses.",
    "start": "974130",
    "end": "981750"
  },
  {
    "text": "For example, if you\nhave 16 things in a set and you keep accessing 17 things\nthat all belong in the set,",
    "start": "981750",
    "end": "989820"
  },
  {
    "text": "something's going\nto get kicked out every time you want\nto access something.",
    "start": "989820",
    "end": "995340"
  },
  {
    "text": "And these cache\nevictions might not have happened if you had\na fully associative cache.",
    "start": "995340",
    "end": "1001115"
  },
  {
    "text": " And then, finally,\nthey're sharing misses.",
    "start": "1001115",
    "end": "1006459"
  },
  {
    "text": "So sharing misses only\nhappened in a parallel context. And we talked a little\nbit about true sharing",
    "start": "1006460",
    "end": "1012940"
  },
  {
    "text": "a false sharing misses\nin prior lectures. So let's just\nreview this briefly.",
    "start": "1012940",
    "end": "1019269"
  },
  {
    "text": "So a sharing miss can happen\nif multiple processors are accessing the same cache\nline and at least one of them",
    "start": "1019270",
    "end": "1026619"
  },
  {
    "text": "is writing to that cache line. If all of the\nprocessors are just reading from the cache line,\nthen the cache [INAUDIBLE]",
    "start": "1026619",
    "end": "1033010"
  },
  {
    "text": "protocol knows how to make\nit work so that you don't get misses. They can all access the same\ncache line at the same time",
    "start": "1033010",
    "end": "1039670"
  },
  {
    "text": "if nobody's modifying it. But if at least one\nprocessor is modifying it, you could get either\ntrue sharing misses",
    "start": "1039670",
    "end": "1046359"
  },
  {
    "text": "or false sharing misses. So a true sharing miss is\nwhen two processors are",
    "start": "1046359",
    "end": "1051580"
  },
  {
    "text": "accessing the same data\non the same cache line.",
    "start": "1051580",
    "end": "1056590"
  },
  {
    "text": "And as you recall from\na previous lecture, if one of the two processors\nis writing to this cache line, whenever it\ndoes a write it",
    "start": "1056590",
    "end": "1063640"
  },
  {
    "text": "needs to acquire the cache\nline in exclusive mode and then invalidate that cache\nline and all other caches.",
    "start": "1063640",
    "end": "1071710"
  },
  {
    "text": "So then when one\nanother processor tries to access the\nsame memory location, it has to bring it back\ninto its own cache,",
    "start": "1071710",
    "end": "1078130"
  },
  {
    "text": "and then you get a\ncache miss there. A false sharing this\nhappens if two processes",
    "start": "1078130",
    "end": "1084430"
  },
  {
    "text": "are accessing different data\nthat just happened to reside on the same cache line. Because the basic\nunit of movement",
    "start": "1084430",
    "end": "1090670"
  },
  {
    "text": "is a cache line in\nthe architecture. So even if you're\nasking different things,",
    "start": "1090670",
    "end": "1095860"
  },
  {
    "text": "if they are on the\nsame cache line, you're still going to\nget a sharing miss. And false sharing is\npretty hard to deal with,",
    "start": "1095860",
    "end": "1102940"
  },
  {
    "text": "because, in general,\nyou don't know what data gets placed on what cache line.",
    "start": "1102940",
    "end": "1108282"
  },
  {
    "text": "There are certain\nheuristics you can use. For example, if you're\nmallocing a big memory region, you know that that memory\nregion is contiguous,",
    "start": "1108282",
    "end": "1115430"
  },
  {
    "text": "so you can space your\naccess is far enough apart by different processors so\nthey don't touch the same cache line.",
    "start": "1115430",
    "end": "1121110"
  },
  {
    "text": "But if you're just declaring\nlocal variables on the stack, you don't know\nwhere the compiler is going to decide to\nplace these variables",
    "start": "1121110",
    "end": "1130809"
  },
  {
    "text": "in the virtual\nmemory address space. So these are four\ndifferent types of cache",
    "start": "1130810",
    "end": "1137049"
  },
  {
    "text": "misses that you\nshould know about. And there's many\nmodels out there",
    "start": "1137050",
    "end": "1142690"
  },
  {
    "text": "for analyzing the cache\nperformance of algorithms. And some of the models ignore\nsome of these different types",
    "start": "1142690",
    "end": "1148720"
  },
  {
    "text": "of cache misses. So just be aware of this when\nyou're looking at algorithm",
    "start": "1148720",
    "end": "1153940"
  },
  {
    "text": "analysis, because\nnot all of the models will capture all of these\ndifferent types of cache misses. ",
    "start": "1153940",
    "end": "1162830"
  },
  {
    "text": "So let's look at a bad\ncase for conflict misses. So here I want to access a\nsubmatrix within a larger",
    "start": "1162830",
    "end": "1173270"
  },
  {
    "start": "1164000",
    "end": "1164000"
  },
  {
    "text": "matrix. And recall that matrices are\nstored in row-major order.",
    "start": "1173270",
    "end": "1179539"
  },
  {
    "text": "And let's say our matrix is\n4,096 columns by 4,096 rows",
    "start": "1179540",
    "end": "1184850"
  },
  {
    "text": "and it still stores doubles. So therefore, each\nrow here is going",
    "start": "1184850",
    "end": "1190190"
  },
  {
    "text": "to contain 2 to the 15th\nbytes, because 4,096 is t2 to the 12th,\nand we have doubles,",
    "start": "1190190",
    "end": "1198800"
  },
  {
    "text": "which takes eight bytes. So 2 to the 12 times to the\n3rd, which is 2 to the 15th. ",
    "start": "1198800",
    "end": "1206750"
  },
  {
    "text": "We're going to assume the word\nwidth is 64, which is standard. We're going to assume that\nwe have a cache size of 32k.",
    "start": "1206750",
    "end": "1215060"
  },
  {
    "text": "And the cache block size is\n64, which, again, is standard. And let's say we have a\nfour-way associative cache.",
    "start": "1215060",
    "end": "1222125"
  },
  {
    "text": " So let's look at how the\nbits are divided into.",
    "start": "1222125",
    "end": "1231860"
  },
  {
    "text": "So again we have\nthis offset, which takes log base 2 of B bits.",
    "start": "1231860",
    "end": "1238867"
  },
  {
    "text": "So how many bits do we have\nfor the offset in this example? ",
    "start": "1238867",
    "end": "1248299"
  },
  {
    "text": "Right. So we have 6 bits. So it's just log base 2 of 64.",
    "start": "1248300",
    "end": "1253930"
  },
  {
    "text": "What about for the set? How many bits do\nwe have for that?",
    "start": "1253930",
    "end": "1259030"
  },
  {
    "text": "7. Who said 7? Yeah. So it is 7.",
    "start": "1259030",
    "end": "1264220"
  },
  {
    "text": "So M is 32k, which\nis 2 to the 15th.",
    "start": "1264220",
    "end": "1270130"
  },
  {
    "text": "And then k is 2 to\nthe 2, b is 2 6.",
    "start": "1270130",
    "end": "1277310"
  },
  {
    "text": "So it's 2 to the 15th divided by\n2 the 8th, which is to the 7th. And log base 2 of that is 7.",
    "start": "1277310",
    "end": "1283930"
  },
  {
    "text": "And finally, what\nabout the tag field? ",
    "start": "1283930",
    "end": "1289659"
  },
  {
    "text": "AUDIENCE: 51. JULIAN SHUN: 51. Why is that? AUDIENCE: 64 minus 13.",
    "start": "1289660",
    "end": "1296330"
  },
  {
    "text": "JULIAN SHUN: Yeah. So it's just 64 minus\n7 minus 6, which is 51.",
    "start": "1296330",
    "end": "1303880"
  },
  {
    "text": "OK. So let's say that we want\nto access a submatrix within this larger matrix.",
    "start": "1303880",
    "end": "1309710"
  },
  {
    "text": "Let's say we want to acts\nas a 32 by 32 submatrix. And THIS is pretty common\nin matrix algorithms, where",
    "start": "1309710",
    "end": "1317220"
  },
  {
    "text": "you want to access submatrices,\nespecially in divide and conquer algorithms. ",
    "start": "1317220",
    "end": "1324240"
  },
  {
    "text": "And let's say we want to access\na column of this submatrix A.",
    "start": "1324240",
    "end": "1329850"
  },
  {
    "text": "So the addresses of the elements\nthat we're going to access are as follows-- so let's say the first\nelement in the column",
    "start": "1329850",
    "end": "1337290"
  },
  {
    "text": "is stored at address x. Then the second\nelement in the column is going to be stored at\naddress x plus 2 to the 15th,",
    "start": "1337290",
    "end": "1344640"
  },
  {
    "text": "because each row has\n2 to the 15th bytes, and we're skipping\nover an entire row",
    "start": "1344640",
    "end": "1349650"
  },
  {
    "text": "here to get to the element in\nthe next row of the sub matrix. So we're going to\nadd 2 to the 15th.",
    "start": "1349650",
    "end": "1356460"
  },
  {
    "text": "And then to get\nthe third element, we're going to add 2\ntimes 2 to the 15th. And so on, until we get\nto the last element,",
    "start": "1356460",
    "end": "1363420"
  },
  {
    "text": "which is x plus 31\ntimes 2 to the 15th.",
    "start": "1363420",
    "end": "1368490"
  },
  {
    "text": "So which fields\nof the address are changing as we go through\none column of this submatrix?",
    "start": "1368490",
    "end": "1374850"
  },
  {
    "start": "1374850",
    "end": "1385586"
  },
  {
    "text": "AUDIENCE: You're just adding\nmultiple [INAUDIBLE] tag the [INAUDIBLE]. JULIAN SHUN: Yeah.",
    "start": "1385586",
    "end": "1390750"
  },
  {
    "text": "So it's just going to be\nthe tag that's changing. The set and the offset are going\nto stay the same, because we're",
    "start": "1390750",
    "end": "1397360"
  },
  {
    "text": "just using the lower 13 bits\nto store the set and a tag. And therefore, when we\nincrement by 2 to the 15th,",
    "start": "1397360",
    "end": "1404889"
  },
  {
    "text": "we're not going to touch\nthe set and the offset. So all of these addresses\nfall into the same set.",
    "start": "1404890",
    "end": "1412060"
  },
  {
    "text": "And this is a problem,\nbecause our cache is only four-way associative.",
    "start": "1412060",
    "end": "1417160"
  },
  {
    "text": "So we can only fit four\ncache lines in each set.",
    "start": "1417160",
    "end": "1422860"
  },
  {
    "text": "And here, we're accessing\n31 of these things. So by the time we get\nto the next column of A,",
    "start": "1422860",
    "end": "1430510"
  },
  {
    "text": "all the things that we access\nin the current column of A are going to be evicted\nfrom cache already.",
    "start": "1430510",
    "end": "1436360"
  },
  {
    "text": "And this is known\nas a conflict miss, because if you had a\nfully associative cache",
    "start": "1436360",
    "end": "1441850"
  },
  {
    "text": "this might not have happened,\nbecause you could actually use any location in the cache\nto store these cache blocks.",
    "start": "1441850",
    "end": "1449940"
  },
  {
    "text": "So does anybody have\nany questions on why we get conflict misses here?",
    "start": "1449940",
    "end": "1455059"
  },
  {
    "start": "1455060",
    "end": "1462860"
  },
  {
    "text": "So anybody have any\nideas on how to fix this? So what can I do to\nmake it so that I'm not",
    "start": "1462860",
    "end": "1469299"
  },
  {
    "text": "incrementing by exactly\n2 to the 15th every time? ",
    "start": "1469300",
    "end": "1479696"
  },
  {
    "text": "Yeah. AUDIENCE: So pad the matrix? JULIAN SHUN: Yeah. So one solution is\nto pad the matrix.",
    "start": "1479696",
    "end": "1486270"
  },
  {
    "text": "You can add some\nconstant amount of space to the end of the matrix. So each row is going\nto be longer than 2",
    "start": "1486270",
    "end": "1493320"
  },
  {
    "text": "to the 15th bytes. So maybe you add some\nsmall constant like 17. So add 17 bytes to\nthe end of each row.",
    "start": "1493320",
    "end": "1500130"
  },
  {
    "text": "And now, when you access a\ncolumn of this submatrix, you're not just incrementing\nby 2 to the 15th,",
    "start": "1500130",
    "end": "1507000"
  },
  {
    "text": "you're also adding\nsome small integer. And that's going to cause\nthe set and the offset fields",
    "start": "1507000",
    "end": "1514534"
  },
  {
    "text": "to change as well,\nand you're not going to get as many\nconflict misses. So that's one way to\nsolve the problem.",
    "start": "1514535",
    "end": "1522610"
  },
  {
    "text": "It turns out that if you're\ndoing a matrix multiplication algorithm, that's a\ncubic work algorithm,",
    "start": "1522610",
    "end": "1527909"
  },
  {
    "text": "and you can basically\nafford to copy the submatrix into a temporary\n32 by 32 matrix,",
    "start": "1527910",
    "end": "1534270"
  },
  {
    "text": "do all the operations\non the temporary matrix, and then copy it back out\nto the original matrix.",
    "start": "1534270",
    "end": "1539760"
  },
  {
    "text": "The copying only\ntakes quadratic work to do across the\nwhole algorithm.",
    "start": "1539760",
    "end": "1545160"
  },
  {
    "text": "And since the whole\nalgorithm takes cubic work, the quadratic work is\na lower order term.",
    "start": "1545160",
    "end": "1550620"
  },
  {
    "text": "So you can use temporary\nspace to make sure that you don't get conflict misses.",
    "start": "1550620",
    "end": "1556050"
  },
  {
    "text": " Any questions? ",
    "start": "1556050",
    "end": "1566030"
  },
  {
    "text": "So this was conflict misses. So conflict misses\nare important. But usually, we're going\nto be first concerned",
    "start": "1566030",
    "end": "1573180"
  },
  {
    "text": "about getting good spatial\nand temporal locality, because those are\nusually the higher order",
    "start": "1573180",
    "end": "1579240"
  },
  {
    "text": "factors in the\nperformance of a program. And once we get good spatial\nand temporal locality",
    "start": "1579240",
    "end": "1584250"
  },
  {
    "text": "in our program,\nwe can then start worrying about conflict\nmisses, for example, by using temporary space\nor padding our data",
    "start": "1584250",
    "end": "1592860"
  },
  {
    "text": "by some small constants\nso that we don't have as if any conflict misses. ",
    "start": "1592860",
    "end": "1601120"
  },
  {
    "text": "So now, I want to\ntalk about a model that we can use to\nanalyze the cache performance of algorithms.",
    "start": "1601120",
    "end": "1606530"
  },
  {
    "text": "And this is called\nthe ideal-cache model. So in this model, we have a\ntwo-level cache hierarchy.",
    "start": "1606530",
    "end": "1617030"
  },
  {
    "start": "1611000",
    "end": "1611000"
  },
  {
    "text": "So we have the cache\nand then main memory. The cache size is of size\nM, and the cache line size",
    "start": "1617030",
    "end": "1625205"
  },
  {
    "text": "is of B bytes. And therefore, we can fit M over\nV cache lines inside our cache.",
    "start": "1625205",
    "end": "1630245"
  },
  {
    "text": " This model assumes that the\ncache is fully associative,",
    "start": "1630245",
    "end": "1635930"
  },
  {
    "text": "so any cache block can\ngo anywhere in the cache. And it also assumes an optimal\nomniscient replacement policy.",
    "start": "1635930",
    "end": "1643070"
  },
  {
    "text": "So this means that where\nwe want to evict a cache block from the\ncache, we're going to pick the thing to\nevict that gives us",
    "start": "1643070",
    "end": "1648410"
  },
  {
    "text": "the best performance overall. It gives us the\nlowest number of cache misses throughout\nour entire algorithm.",
    "start": "1648410",
    "end": "1654210"
  },
  {
    "text": "So we're assuming that we know\nthe sequence of memory requests throughout the entire algorithm. And that's why it's called the\nomniscient mission replacement",
    "start": "1654210",
    "end": "1661400"
  },
  {
    "text": "policy.  And if something is in cache,\nyou can operate on it for free.",
    "start": "1661400",
    "end": "1669000"
  },
  {
    "text": "And if something\nis in main memory, you have to bring it\ninto cache and then you incur a cache miss.",
    "start": "1669000",
    "end": "1674070"
  },
  {
    "text": " So two performance measures\nthat we care about--",
    "start": "1674070",
    "end": "1679880"
  },
  {
    "text": "first, we care about\nthe ordinary work, which is just the ordinary\nrunning time of a program. So this is the\nsame as before when",
    "start": "1679880",
    "end": "1687740"
  },
  {
    "text": "we were analyzing algorithms. It's just a total\nnumber of operations that the program does.",
    "start": "1687740",
    "end": "1693690"
  },
  {
    "text": "And the number of\ncache misses is going to be the\nnumber of lines we have to transfer between the\nmain memory and the cache.",
    "start": "1693690",
    "end": "1701893"
  },
  {
    "text": "So the number of\ncache misses just counts a number of\ncache transfers, whereas as the work counts\nall the operations that you",
    "start": "1701893",
    "end": "1707570"
  },
  {
    "text": "have to do in the algorithm. ",
    "start": "1707570",
    "end": "1712640"
  },
  {
    "text": "So ideally, we would\nlike to come up with algorithms that have a\nlow number of cache misses",
    "start": "1712640",
    "end": "1718970"
  },
  {
    "text": "without increasing the work\nfrom the traditional standard algorithm.",
    "start": "1718970",
    "end": "1724550"
  },
  {
    "text": "Sometimes we can do that,\nsometimes we can't do that. And then there's a\ntrade-off between the work and the number of cache misses.",
    "start": "1724550",
    "end": "1731210"
  },
  {
    "text": "And it's a trade-off\nthat you have to decide whether it's\nworthwhile as a performance",
    "start": "1731210",
    "end": "1736910"
  },
  {
    "text": "engineer. Today, we're going to\nlook at an algorithm where you can't actually\nreduce the number of cache",
    "start": "1736910",
    "end": "1741915"
  },
  {
    "text": "misses without\nincreasing the work. So you basically get\nthe best of both worlds. ",
    "start": "1741915",
    "end": "1748880"
  },
  {
    "text": "So any questions on\nthis ideal cache model? ",
    "start": "1748880",
    "end": "1759430"
  },
  {
    "text": "So this model is just used\nfor analyzing algorithms. You can't actually buy one\nof these caches at the store.",
    "start": "1759430",
    "end": "1767530"
  },
  {
    "text": "So this is a very ideal\ncache, and they don't exist. But it turns out that this\noptimal omniscient replacement",
    "start": "1767530",
    "end": "1775000"
  },
  {
    "text": "policy has nice\ntheoretical properties. And this is a very important\nlemma that was proved in 1985.",
    "start": "1775000",
    "end": "1783970"
  },
  {
    "start": "1776000",
    "end": "1776000"
  },
  {
    "text": "It's called the LRU lemma. It was proved by\nSlater and Tarjan. And the lemma says, suppose\nthat an algorithm incurs",
    "start": "1783970",
    "end": "1791950"
  },
  {
    "text": "Q cache misses on an ideal\ncache of size M. Then, on a fully associative cache\nof size 2M, that uses the LRU,",
    "start": "1791950",
    "end": "1801280"
  },
  {
    "text": "or Least Recently Used\nreplacement policy, it incurs at most\n2Q cache misses.",
    "start": "1801280",
    "end": "1808900"
  },
  {
    "text": "So what this says is if I\ncan show the number of cache misses for an algorithm\non the ideal cache,",
    "start": "1808900",
    "end": "1816700"
  },
  {
    "text": "then if I take a fully\nassociative cache that's twice the size and use the\nLRU replacement policy,",
    "start": "1816700",
    "end": "1823220"
  },
  {
    "text": "which is a pretty\npractical policy, then the algorithm\nis going to incur, at most, twice the\nnumber of cache misses.",
    "start": "1823220",
    "end": "1831160"
  },
  {
    "text": "And the implication\nof this lemma is that for asymptotic\nanalyses, you",
    "start": "1831160",
    "end": "1836590"
  },
  {
    "text": "can assume either the optimal\nreplacement policy or the LRU replacement policy\nas convenient.",
    "start": "1836590",
    "end": "1841930"
  },
  {
    "text": "Because the number\nof cache misses is just going to be within a\nconstant factor of each other.",
    "start": "1841930",
    "end": "1850270"
  },
  {
    "text": "So this is a very\nimportant lemma. It says that this\nbasically makes it much easier for us to analyze\nour cache misses in algorithms.",
    "start": "1850270",
    "end": "1860306"
  },
  {
    "text": " And here's a software\nengineering principle",
    "start": "1860306",
    "end": "1866240"
  },
  {
    "text": "that I want to point out. So first, when you're trying\nto get good performance,",
    "start": "1866240",
    "end": "1873480"
  },
  {
    "text": "you should come up with a\ntheoretically good algorithm that has good balance on the\nwork and the cache complexity.",
    "start": "1873480",
    "end": "1880670"
  },
  {
    "text": "And then after you come up\nwith an algorithm that's theoretically good, then\nyou start engineering",
    "start": "1880670",
    "end": "1886040"
  },
  {
    "text": "for detailed performance. You start worrying about the\ndetails such as real world caches not being fully\nassociative, and, for example,",
    "start": "1886040",
    "end": "1894770"
  },
  {
    "text": "loads and stores having\ndifferent costs with respect to bandwidth and latency. But coming up with a\ntheoretically good algorithm",
    "start": "1894770",
    "end": "1901340"
  },
  {
    "text": "is the first order bit to\ngetting good performance. ",
    "start": "1901340",
    "end": "1908840"
  },
  {
    "text": "Questions? ",
    "start": "1908840",
    "end": "1918090"
  },
  {
    "text": "So let's start analyzing\nthe number of cache misses in a program. So here's a lemma.",
    "start": "1918090",
    "end": "1924090"
  },
  {
    "text": "So the lemma says, suppose that\na program reads a set of r data segments, where the i-th segment\nconsists of s sub i bytes.",
    "start": "1924090",
    "end": "1933480"
  },
  {
    "text": "And suppose that the sum of\nthe sizes of all the segments is equal to N. And we're going\nto assume that N is less than M",
    "start": "1933480",
    "end": "1942360"
  },
  {
    "text": "over 3. So the sum of the\nsize of the segments is less than the cache\nsize divided by 3.",
    "start": "1942360",
    "end": "1950100"
  },
  {
    "text": "We're also going to\nassume that N over r is greater than or\nequal to B. So recall that r is the number of\ndata segments we have,",
    "start": "1950100",
    "end": "1958650"
  },
  {
    "text": "and N is the total\nsize of the segment. So what does N over\nr mean, semantically?",
    "start": "1958650",
    "end": "1966080"
  },
  {
    "text": "Yes. AUDIENCE: Average [INAUDIBLE]. JULIAN SHUN: Yeah. So N over r is the just the\naverage size of a segment.",
    "start": "1966080",
    "end": "1973389"
  },
  {
    "text": "And here we're saying that\nthe average size of a segment is at least B-- so at least\nthe size of a cache line.",
    "start": "1973390",
    "end": "1981790"
  },
  {
    "text": "So if these two assumptions\nhold, then all of the segments are going to fit into cache,\nand the number of cache",
    "start": "1981790",
    "end": "1987590"
  },
  {
    "text": "misses to read them all is,\nat most, 3 times N over B.",
    "start": "1987590",
    "end": "1993590"
  },
  {
    "text": "So if you had just a\nsingle array of size N,",
    "start": "1993590",
    "end": "2000490"
  },
  {
    "text": "then the number of\ncache misses you would need to read\nthat array into cache is going to be N\nover B. And this",
    "start": "2000490",
    "end": "2005920"
  },
  {
    "text": "is saying that, even\nif our data is divided into a bunch of segments, as\nlong as the average length",
    "start": "2005920",
    "end": "2012040"
  },
  {
    "text": "of the segments is large enough,\nthen the number of cache misses is just a constant factor worse\nthan reading a single array.",
    "start": "2012040",
    "end": "2021549"
  },
  {
    "text": "So let's try to prove\nthis cache miss lemma. ",
    "start": "2021550",
    "end": "2028000"
  },
  {
    "start": "2022000",
    "end": "2022000"
  },
  {
    "text": "So here's a proof so. A single segment,\ns sub i is going to incur at most s sub i\nover B plus 2 cache misses.",
    "start": "2028000",
    "end": "2038350"
  },
  {
    "text": "So does anyone want to tell me\nwhere the s sub i over B plus 2 comes from? ",
    "start": "2038350",
    "end": "2049540"
  },
  {
    "text": "So let's say this is a\nsegment that we're analyzing, and this is how it's\naligned in virtual memory.",
    "start": "2049540",
    "end": "2056319"
  },
  {
    "start": "2056320",
    "end": "2061899"
  },
  {
    "text": "Yes? AUDIENCE: How many blocks\nit could overlap worst case. JULIAN SHUN: Yeah. So s sub i over B plus 2 is\nthe number of blocks that could",
    "start": "2061900",
    "end": "2069870"
  },
  {
    "text": "overlap within the worst case. So you need s sub i\nover B cache misses just",
    "start": "2069870",
    "end": "2076949"
  },
  {
    "text": "to load those s sub i bytes. But then the beginning and\nthe end of that segment",
    "start": "2076949",
    "end": "2083399"
  },
  {
    "text": "might not be perfectly aligned\nwith a cache line boundary. And therefore, you could\nwaste, at most, one block",
    "start": "2083400",
    "end": "2089669"
  },
  {
    "text": "on each side of the segment. So that's where the\nplus 2 comes from.",
    "start": "2089670",
    "end": "2095310"
  },
  {
    "text": "So to get the total\nnumber of cache misses, we just have to sum this\nquantity from i equals 1 to r.",
    "start": "2095310",
    "end": "2103170"
  },
  {
    "text": "So if I sum s sub i over\nB from i equals 1 to r, I just get N over\nB, by definition.",
    "start": "2103170",
    "end": "2108810"
  },
  {
    "text": "And then I sum 2\nfrom i equals 1 to r. So that just gives me 2r.",
    "start": "2108810",
    "end": "2114839"
  },
  {
    "text": "Now, I'm going to multiply\nthe top and the bottom with the second term by\nB. So 2r B over B now.",
    "start": "2114840",
    "end": "2121079"
  },
  {
    "text": "And then that's less\nthan or equal to N over B plus 2N over B. So where did\nI get this inequality here?",
    "start": "2121080",
    "end": "2129730"
  },
  {
    "text": "Why do I know that 2r B is\nless than or equal to 2N? ",
    "start": "2129730",
    "end": "2135500"
  },
  {
    "text": "Yes? AUDIENCE: You know that the N\nis greater than or equal to B r. JULIAN SHUN: Yeah. So you know that N is\ngreater than or equal to B",
    "start": "2135500",
    "end": "2141250"
  },
  {
    "text": "r by this assumption up here. So therefore, r B is\nless than or equal to N.",
    "start": "2141250",
    "end": "2146829"
  },
  {
    "text": "And then, N B plus 2 N\nB just sums up to 3 N B. So in the worst case, we're\ngoing to incur 3N over B cache",
    "start": "2146830",
    "end": "2155335"
  },
  {
    "text": "misses. ",
    "start": "2155335",
    "end": "2160800"
  },
  {
    "text": "So any questions on\nthis cache miss lemma? ",
    "start": "2160800",
    "end": "2167620"
  },
  {
    "text": "So the Important thing to\nremember here is that if you have a whole bunch of data\nsegments and the average length",
    "start": "2167620",
    "end": "2174070"
  },
  {
    "text": "of your segments\nis large enough-- bigger than a cache block size-- then you can access all\nof these segments just",
    "start": "2174070",
    "end": "2181690"
  },
  {
    "text": "like a single array. It only increases\nthe number of cache misses by a constant factor.",
    "start": "2181690",
    "end": "2187810"
  },
  {
    "text": "And if you're doing an\nasymptotic analysis, then it doesn't matter. So we're going to be using\nthis cache miss lemma later",
    "start": "2187810",
    "end": "2193360"
  },
  {
    "text": "on when we analyze algorithms. ",
    "start": "2193360",
    "end": "2200720"
  },
  {
    "start": "2200000",
    "end": "2200000"
  },
  {
    "text": "So another assumption\nthat we're going to need is called the tall\ncache assumption.",
    "start": "2200720",
    "end": "2206839"
  },
  {
    "text": "And the tall cache\nassumption basically says that the cache is\ntaller than it is wide.",
    "start": "2206840",
    "end": "2212390"
  },
  {
    "text": "So it says that B\nsquared is less than c M for some sufficiently\nsmall constant c less than",
    "start": "2212390",
    "end": "2218750"
  },
  {
    "text": "or equal to 1. So in other words, it says\nthat the number of cache lines",
    "start": "2218750",
    "end": "2225830"
  },
  {
    "text": "M over B you have is\ngoing to be bigger than B.",
    "start": "2225830",
    "end": "2233660"
  },
  {
    "text": "And this tall cache\nassumption is usually satisfied in practice. So here are the cache\nline sizes and the cache",
    "start": "2233660",
    "end": "2242089"
  },
  {
    "text": "sizes on the machines\nthat we're using. So cache line size is 64\nbytes, and the L1 cache size",
    "start": "2242090",
    "end": "2248990"
  },
  {
    "text": "is 32 kilobytes. So 64 bytes squared,\nthat's 2 to the 12th.",
    "start": "2248990",
    "end": "2256400"
  },
  {
    "text": "And 32 kilobytes is\n2 to the 15th bytes. So 2 to the 12th is\nless than 2 to the 15th,",
    "start": "2256400",
    "end": "2261510"
  },
  {
    "text": "so it satisfies the\ntall cache assumption. And as we go up the\nmemory hierarchy,",
    "start": "2261510",
    "end": "2266540"
  },
  {
    "text": "the cache size increases,\nbut the cache line length stays the same. So the cache has\nbecome even taller",
    "start": "2266540",
    "end": "2273230"
  },
  {
    "text": "as we move up the\nmemory hierarchy. So let's see why this\ntall cache assumption is",
    "start": "2273230",
    "end": "2280468"
  },
  {
    "text": "going to be useful.  To see that, we're\ngoing to look at what's",
    "start": "2280468",
    "end": "2286300"
  },
  {
    "start": "2282000",
    "end": "2282000"
  },
  {
    "text": "wrong with a short cache. So in a short cache, our lines\nare going to be very wide,",
    "start": "2286300",
    "end": "2291580"
  },
  {
    "text": "and they're wider than\nthe number of lines that we can have in our cache.",
    "start": "2291580",
    "end": "2298200"
  },
  {
    "text": "And let's say we're\nworking with an m by n submatrix sorted\nin row-major order.",
    "start": "2298200",
    "end": "2304119"
  },
  {
    "text": "If you have a short cache,\nthen even if n squared is less than c M,\nmeaning that you",
    "start": "2304120",
    "end": "2309700"
  },
  {
    "text": "can fit all the bytes of\nthe submatrix in cache, you might still not be able\nto fit it into a short cache.",
    "start": "2309700",
    "end": "2317620"
  },
  {
    "text": "And this picture sort\nof illustrates this. So we have m rows here.",
    "start": "2317620",
    "end": "2323049"
  },
  {
    "text": "But we can only fit M over\nB of the rows in the cache, because the cache\nlines are so long,",
    "start": "2323050",
    "end": "2328960"
  },
  {
    "text": "and we're actually\nwasting a lot of space on each of the cache lines. We're only using a very small\nfraction of each cache line",
    "start": "2328960",
    "end": "2334569"
  },
  {
    "text": "to store the row\nof this submatrix. If this were the\nentire matrix, then",
    "start": "2334570",
    "end": "2340960"
  },
  {
    "text": "it would actually be OK,\nbecause consecutive rows are going to be placed together\nconsecutively in memory.",
    "start": "2340960",
    "end": "2348850"
  },
  {
    "text": "But if this is a\nsubmatrix, then we can't be guaranteed that the\nnext row is going to be placed",
    "start": "2348850",
    "end": "2354070"
  },
  {
    "text": "right after the current row. And oftentimes, we have\nto deal with submatrices",
    "start": "2354070",
    "end": "2359290"
  },
  {
    "text": "when we're doing recursive\nmatrix algorithms. ",
    "start": "2359290",
    "end": "2365330"
  },
  {
    "text": "So this is what's wrong\nwith short caches. And that's why we want us assume\nthe tall cache assumption.",
    "start": "2365330",
    "end": "2372340"
  },
  {
    "text": "And we can assume that,\nbecause it's usually satisfied in practice. ",
    "start": "2372340",
    "end": "2377945"
  },
  {
    "text": "The TLB be actually\ntends to be short. It only has a couple of\nentries, so it might not satisfy the tall cache assumption.",
    "start": "2377945",
    "end": "2384020"
  },
  {
    "text": "But all of the other caches\nwill satisfy this assumption.",
    "start": "2384020",
    "end": "2390060"
  },
  {
    "text": "Any questions?  OK.",
    "start": "2390060",
    "end": "2396797"
  },
  {
    "start": "2395000",
    "end": "2395000"
  },
  {
    "text": "So here's another lemma\nthat's going to be useful. This is called the\nsubmatrix caching llama.",
    "start": "2396797",
    "end": "2403220"
  },
  {
    "text": "So suppose that we\nhave an n by m matrix, and it's read into\na tall cache that",
    "start": "2403220",
    "end": "2408650"
  },
  {
    "text": "satisfies B squared less than c\nM for some constant c less than or equal to 1.",
    "start": "2408650",
    "end": "2415579"
  },
  {
    "text": "And suppose that n squared\nis less than M over 3, but it's greater than\nor equal to c M. Then",
    "start": "2415580",
    "end": "2424280"
  },
  {
    "text": "A is going to fit into cache,\nand the number of cache misses required to read all\nof A's elements into cache is,",
    "start": "2424280",
    "end": "2431600"
  },
  {
    "text": "at most, 3n squared over B.",
    "start": "2431600",
    "end": "2438470"
  },
  {
    "text": "So let's see why this is true. So we're going to\nlet big N denote",
    "start": "2438470",
    "end": "2445119"
  },
  {
    "text": "the total number of bytes\nthat we need to access. So big N is going to\nbe equal to n squared.",
    "start": "2445120",
    "end": "2450940"
  },
  {
    "text": " And we're going to use the\ncache miss lemma, which",
    "start": "2450940",
    "end": "2456550"
  },
  {
    "text": "says that if the average\nlength of our segments is large enough, then we\ncan read all of the segments",
    "start": "2456550",
    "end": "2462309"
  },
  {
    "text": "in just like it were a\nsingle contiguous array. So the lengths of our segments\nhere are going to be little n.",
    "start": "2462310",
    "end": "2469930"
  },
  {
    "text": "So r is going to be a little n. And also, the number of segments\nis going to be little n.",
    "start": "2469930",
    "end": "2476470"
  },
  {
    "text": "And the segment\nlength is also going to be little n, since we're\nworking with a square submatrix",
    "start": "2476470",
    "end": "2481660"
  },
  {
    "text": "here. And then we also have the\ncache block size B is less than",
    "start": "2481660",
    "end": "2490120"
  },
  {
    "text": "or equal to n. And that's equal\nto big N over r.",
    "start": "2490120",
    "end": "2496090"
  },
  {
    "text": "And where do we get this\nproperty that B is less than or equal to n?",
    "start": "2496090",
    "end": "2502600"
  },
  {
    "text": "So I made some\nassumptions up here, where I can use to infer that\nB is less than or equal to n.",
    "start": "2502600",
    "end": "2510070"
  },
  {
    "text": "Does anybody see where? Yeah. AUDIENCE: So B squared\nis less than c M,",
    "start": "2510070",
    "end": "2515850"
  },
  {
    "text": "and c M is [INAUDIBLE] JULIAN SHUN: Yeah. So I know that B\nsquared is less than c M. C M is less than\nor equal to n squared.",
    "start": "2515850",
    "end": "2522820"
  },
  {
    "text": "So therefore, B squared\nis less than n squared, and B is less than n.",
    "start": "2522820",
    "end": "2529360"
  },
  {
    "text": "So now, I also have\nthat N is less than M",
    "start": "2529360",
    "end": "2535060"
  },
  {
    "text": "over 3, just by assumption. And therefore, I can use\nthe cache miss lemma.",
    "start": "2535060",
    "end": "2540810"
  },
  {
    "text": "So the cache miss lemma\ntells me that I only need a total of 3n\nsquared over B cache",
    "start": "2540810",
    "end": "2546609"
  },
  {
    "text": "misses to read this\nwhole thing in. ",
    "start": "2546610",
    "end": "2552780"
  },
  {
    "text": "Any questions on the\nsubmatrix caching lemma? ",
    "start": "2552780",
    "end": "2568980"
  },
  {
    "text": "So now, let's analyze\nmatrix multiplication. How many of you have seen\nmatrix multiplication before?",
    "start": "2568980",
    "end": "2575490"
  },
  {
    "text": " So a couple of you. ",
    "start": "2575490",
    "end": "2583339"
  },
  {
    "text": "So here's what the\ncode looks like for the standard cubic\nwork matrix multiplication",
    "start": "2583340",
    "end": "2591260"
  },
  {
    "start": "2585000",
    "end": "2585000"
  },
  {
    "text": "algorithm. So we have two input\nmatrices, A and B, And we're going to\nstore the result in C.",
    "start": "2591260",
    "end": "2598609"
  },
  {
    "text": "And the height and the\nwidth of our matrix is n. We're just going to deal\nwith square matrices here,",
    "start": "2598610",
    "end": "2605797"
  },
  {
    "text": "but what I'm going\nto talk about also extends to non-square matrices. And then we just have\nthree loops here.",
    "start": "2605798",
    "end": "2613450"
  },
  {
    "text": "We're going to loop through i\nfrom 0 to n minus 1, j from 0 to n minus 1, and k\nfrom 0 to n minus 1.",
    "start": "2613450",
    "end": "2620540"
  },
  {
    "text": "And then we're going to\nlet's C of i n plus j be incremented by a of i n\nplus k times b of k n plus j.",
    "start": "2620540",
    "end": "2628280"
  },
  {
    "text": "So that's just the standard\ncode for matrix multiply. So what's the work\nof this algorithm?",
    "start": "2628280",
    "end": "2637105"
  },
  {
    "text": "It should be review\nfor all of you.",
    "start": "2637105",
    "end": "2642140"
  },
  {
    "text": "n cubed.  So now, let's analyze\nthe number of cache",
    "start": "2642140",
    "end": "2648850"
  },
  {
    "text": "misses this algorithm\nis going to incur. And again, we're going to\nassume that the matrix is in row-major order, and\nwe satisfy the tall cache",
    "start": "2648850",
    "end": "2656770"
  },
  {
    "start": "2650000",
    "end": "2650000"
  },
  {
    "text": "assumption.  We're also going to\nanalyze the number of cache",
    "start": "2656770",
    "end": "2663099"
  },
  {
    "text": "misses in matrix B,\nbecause it turns out that the number of\ncache misses incurred by matrix B is going to\ndominate the number of cache",
    "start": "2663100",
    "end": "2669849"
  },
  {
    "text": "misses overall. And there are three cases\nwe need to consider. The first case is when\nn is greater than c M",
    "start": "2669850",
    "end": "2677109"
  },
  {
    "text": "over B for some constant c. ",
    "start": "2677110",
    "end": "2682890"
  },
  {
    "text": "And we're going to analyze\nmatrix B, as I said. And we're also going to\nassume LRU, because we can.",
    "start": "2682890",
    "end": "2688650"
  },
  {
    "text": "If you recall,\nthe LRU lemma says that whatever we\nanalyze using the LRU is just going to be a constant\nfactor within what we analyze",
    "start": "2688650",
    "end": "2695160"
  },
  {
    "text": "using the ideal cache. ",
    "start": "2695160",
    "end": "2701220"
  },
  {
    "text": "So to do this matrix\nmultiplication,",
    "start": "2701220",
    "end": "2707460"
  },
  {
    "text": "I'm going to go through one\nrow of A and one column of B and do the dot product there.",
    "start": "2707460",
    "end": "2712740"
  },
  {
    "text": "This is what happens\nin the innermost loop. And how many cache\nmisses am I going",
    "start": "2712740",
    "end": "2719010"
  },
  {
    "text": "to incur when I go down\none column of B here?",
    "start": "2719010",
    "end": "2724110"
  },
  {
    "text": "So here, I have the case where\nn is greater than M over B.",
    "start": "2724110",
    "end": "2729120"
  },
  {
    "text": "So I can't fit one block\nfrom each row into the cache.",
    "start": "2729120",
    "end": "2738430"
  },
  {
    "text": "So how many cache misses\ndo I have the first time I go down a column of B? ",
    "start": "2738430",
    "end": "2744440"
  },
  {
    "text": "So how many rows of B do I have?  n.",
    "start": "2744440",
    "end": "2749700"
  },
  {
    "text": "Yeah, and how many cache\nmisses do I need for each row?",
    "start": "2749700",
    "end": "2754849"
  },
  {
    "text": "One. So in total, I'm going\nto need n cache misses for the first column of B.",
    "start": "2754850",
    "end": "2762280"
  },
  {
    "text": "What about the\nsecond column of B? ",
    "start": "2762280",
    "end": "2768980"
  },
  {
    "text": "So recall that I'm assuming the\nLRU replacement policy here. So when the cache\nis full, I'm going to evict the thing that\nwas least recently used--",
    "start": "2768980",
    "end": "2777030"
  },
  {
    "text": "used the furthest in the past. ",
    "start": "2777030",
    "end": "2786932"
  },
  {
    "text": "Sorry, could you repeat that? AUDIENCE: [INAUDIBLE]. JULIAN SHUN: Yeah. So it's still going to be n. Why is that?",
    "start": "2786932",
    "end": "2793462"
  },
  {
    "text": "AUDIENCE: Because there\nare [INAUDIBLE] integer. JULIAN SHUN: Yeah.",
    "start": "2793462",
    "end": "2799822"
  },
  {
    "text": "It's still going\nto be n, because I can't fit one cache block\nfrom each row into my cache.",
    "start": "2799822",
    "end": "2805030"
  },
  {
    "text": "And by the time I get back\nto the top of my matrix B, the top block has already\nbeen evicted from the cache,",
    "start": "2805030",
    "end": "2812130"
  },
  {
    "text": "and I have to load it back in. And this is the same for every\nother block that I access. So I'm, again, going\nto need n cache misses",
    "start": "2812130",
    "end": "2818680"
  },
  {
    "text": "for the second\ncolumn of B. And this is going to be the same\nfor all the columns of B.",
    "start": "2818680",
    "end": "2825400"
  },
  {
    "text": "And then I have to do this\nagain for the second row of A. So in total, I'm going\nto need theta of n",
    "start": "2825400",
    "end": "2833120"
  },
  {
    "text": "cubed number of cache misses. And this is one cache miss\nper entry that I access in B.",
    "start": "2833120",
    "end": "2841710"
  },
  {
    "text": "And this is not very good,\nbecause the total work was also theta of n cubed. So I'm not gaining anything\nfrom having any locality",
    "start": "2841710",
    "end": "2849170"
  },
  {
    "text": "in this algorithm here. So any questions\non this analysis?",
    "start": "2849170",
    "end": "2856440"
  },
  {
    "text": "So this just case 1. Let's look at case 2.",
    "start": "2856440",
    "end": "2861579"
  },
  {
    "text": "So in this case, n is\nless than c M over B. So I can fit one block from\neach row of B into cache.",
    "start": "2861580",
    "end": "2870269"
  },
  {
    "text": "And then n is also greater than\nanother constant, c prime time",
    "start": "2870270",
    "end": "2875370"
  },
  {
    "text": "square root of M, so I can't\nfit the whole matrix into cache. And again, let's analyze\nthe number of cache",
    "start": "2875370",
    "end": "2882600"
  },
  {
    "text": "misses incurred by\naccessing B, assuming LRU. So how many cache\nmisses am I going",
    "start": "2882600",
    "end": "2888890"
  },
  {
    "text": "to incur for the\nfirst column of B? AUDIENCE: n. JULIAN SHUN: n.",
    "start": "2888890",
    "end": "2894007"
  },
  {
    "text": "So that's the same as before. What about the\nsecond column of B? So by the time I get to the\nbeginning of the matrix here,",
    "start": "2894007",
    "end": "2904260"
  },
  {
    "text": "is the top block\ngoing to be in cache? ",
    "start": "2904260",
    "end": "2909940"
  },
  {
    "text": "So who thinks the block is\nstill going to be in cache when I get back to the beginning?",
    "start": "2909940",
    "end": "2915410"
  },
  {
    "text": "Yeah. So a couple of people. Who think it going\nto be out of cache? ",
    "start": "2915410",
    "end": "2922550"
  },
  {
    "text": "So it turns out it is going\nto be in cache, because I can fit one block for every\nrow of B into my cache",
    "start": "2922550",
    "end": "2930710"
  },
  {
    "text": "since I have n less\nthan c M over B. So therefore, when I get to the\nbeginning of the second column,",
    "start": "2930710",
    "end": "2938668"
  },
  {
    "text": "that block is still going to be\nin cache, because I loaded it in when I was accessing\nthe first column. So I'm not going to\nincur any cache misses",
    "start": "2938668",
    "end": "2944800"
  },
  {
    "text": "for the second column. And, in general, if I can fit\nB columns or some constant",
    "start": "2944800",
    "end": "2954230"
  },
  {
    "text": "times B columns\ninto cache, then I",
    "start": "2954230",
    "end": "2959540"
  },
  {
    "text": "can reduce the number of cache\nmisses I have by a factor of B. So I only need to incur a\ncache miss the first time I",
    "start": "2959540",
    "end": "2966365"
  },
  {
    "text": "access of block and not for\nall the subsequent accesses. ",
    "start": "2966365",
    "end": "2973250"
  },
  {
    "text": "And the same is true\nfor the second row of A. And since I have\nm rows of A, I'm",
    "start": "2973250",
    "end": "2980500"
  },
  {
    "text": "going to have n times theta of\nn squared over B cache misses. For each row of A,\nI'm going to incur",
    "start": "2980500",
    "end": "2986530"
  },
  {
    "text": "n squared over B cache misses. So the overall number of cache\nmisses is n cubed over B.",
    "start": "2986530",
    "end": "2992750"
  },
  {
    "text": "And this is because\ninside matrix B I can exploit spatial locality. Once I load in a block, I\ncan reuse it the next time",
    "start": "2992750",
    "end": "3000000"
  },
  {
    "text": "I traverse down a\ncolumn that's nearby. ",
    "start": "3000000",
    "end": "3006780"
  },
  {
    "text": "Any questions on this analysis? ",
    "start": "3006780",
    "end": "3016640"
  },
  {
    "text": "So let's look at the third case. And here, n is less than c\nprime times square root of M.",
    "start": "3016640",
    "end": "3023120"
  },
  {
    "text": "So this means that the entire\nmatrix fits into cache. So let's analyze the number\nof cache misses for matrix B",
    "start": "3023120",
    "end": "3030350"
  },
  {
    "text": "again, assuming LRU. So how many cache\nmisses do I have now? ",
    "start": "3030350",
    "end": "3036950"
  },
  {
    "text": "So let's count the\ntotal number of cache misses I have for every time\nI go through a row of A. Yes.",
    "start": "3036950",
    "end": "3050750"
  },
  {
    "text": "AUDIENCE: Is it just n\nfor the first column? ",
    "start": "3050750",
    "end": "3056030"
  },
  {
    "text": "JULIAN SHUN: Yeah. So for the first column,\nit's going to be n. What about the second column?",
    "start": "3056030",
    "end": "3064000"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nthe second [INAUDIBLE].. JULIAN SHUN: Right. So basically, for\nthe first row of A,",
    "start": "3064000",
    "end": "3071042"
  },
  {
    "text": "the analysis is going to\nbe the same as before. I need n squared over B cache\nmisses to load the cache in.",
    "start": "3071042",
    "end": "3076870"
  },
  {
    "text": "What about the second row of A? How many cache misses\nam I going to incur? ",
    "start": "3076870",
    "end": "3087262"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. JULIAN SHUN: Yeah. So for the second\nrow of A, I'm not",
    "start": "3087262",
    "end": "3092420"
  },
  {
    "text": "going to incur any cache misses. Because once I\nload B into cache, it's going to stay in cache. Because the entire\nmatrix can fit in cache,",
    "start": "3092420",
    "end": "3099470"
  },
  {
    "text": "I assume that n is less than c\nprime times square root of M.",
    "start": "3099470",
    "end": "3104869"
  },
  {
    "text": "So total number\nof cache misses I need for matrix B is theta of n\nsquared over B since everything",
    "start": "3104870",
    "end": "3110900"
  },
  {
    "text": "fits in cache. And I just apply the submatrix\ncaching lemma from before. ",
    "start": "3110900",
    "end": "3118100"
  },
  {
    "text": "Overall, this is not\na very good algorithm. Because as you\nrecall, in case 1 I needed a cubic number\nof cache misses.",
    "start": "3118100",
    "end": "3126410"
  },
  {
    "text": " What happens if I swap the\norder of the inner two loops?",
    "start": "3126410",
    "end": "3132980"
  },
  {
    "start": "3129000",
    "end": "3129000"
  },
  {
    "text": "So recall that this was one of\nthe optimizations in lecture 1, when Charles was talking\nabout matrix multiplication",
    "start": "3132980",
    "end": "3139910"
  },
  {
    "text": "and how to speed it up. So if I swapped the order\nof the two inner loops,",
    "start": "3139910",
    "end": "3146450"
  },
  {
    "text": "then, for every\niteration, what I'm doing is I'm actually going over\na row of C and a row of B,",
    "start": "3146450",
    "end": "3155450"
  },
  {
    "text": "and A stays fixed inside\nthe innermost iteration.",
    "start": "3155450",
    "end": "3160520"
  },
  {
    "text": "So now, when I analyze\nthe number of cache misses of matrix\nB, assuming LRU,",
    "start": "3160520",
    "end": "3165920"
  },
  {
    "text": "I'm going to benefit\nfrom spatial locality, since I'm going row by\nrow and the matrix is stored in row-major order.",
    "start": "3165920",
    "end": "3173030"
  },
  {
    "text": "So across all of\nthe rows, I'm just going to require theta of n\nsquared over B cache misses.",
    "start": "3173030",
    "end": "3180380"
  },
  {
    "text": "And I have to do this n\ntimes for the outer loop. So in total, I'm\ngoing to get theta",
    "start": "3180380",
    "end": "3185600"
  },
  {
    "text": "of n cubed over B cache misses. So if you swap the order\nof the inner two loops",
    "start": "3185600",
    "end": "3190700"
  },
  {
    "text": "this significantly improves\nthe locality of your algorithm and you can benefit\nfrom spatial accounting. That's why we saw a significant\nperformance improvement",
    "start": "3190700",
    "end": "3198500"
  },
  {
    "text": "in the first lecture when we\nswapped the order of the loops.",
    "start": "3198500",
    "end": "3203750"
  },
  {
    "text": "Any questions? ",
    "start": "3203750",
    "end": "3211280"
  },
  {
    "text": "So does anybody think\nwe can do better than n cubed over B cache misses? Or do you think that\nit's the best you can do?",
    "start": "3211280",
    "end": "3219440"
  },
  {
    "text": "So how many people\nthink you can do better? ",
    "start": "3219440",
    "end": "3226010"
  },
  {
    "text": "Yeah. And how many people think\nthis is the best you can do? ",
    "start": "3226010",
    "end": "3233780"
  },
  {
    "text": "And how many people don't care? ",
    "start": "3233780",
    "end": "3240660"
  },
  {
    "text": "So it turns out\nyou can do better. And we're going to\ndo better by using",
    "start": "3240660",
    "end": "3246060"
  },
  {
    "text": "an optimization called tiling. So how this is going\nto work is instead",
    "start": "3246060",
    "end": "3252210"
  },
  {
    "start": "3250000",
    "end": "3250000"
  },
  {
    "text": "of just having\nthree for loops, I'm going to have six for loops. And I'm going to\nloop over tiles.",
    "start": "3252210",
    "end": "3259220"
  },
  {
    "text": "So I've got a loop over\ns by s submatrices. And within each\nsubmatrix, I'm going to do all of the computation\nI need for that submatrix",
    "start": "3259220",
    "end": "3267050"
  },
  {
    "text": "before moving on to\nthe next submatrix. So the three innermost\nloops are going",
    "start": "3267050",
    "end": "3272840"
  },
  {
    "text": "to loop inside a submatrix,\nand a three outermost loops are going to loop within\nthe larger matrix,",
    "start": "3272840",
    "end": "3279109"
  },
  {
    "text": "one submatrix matrix at a time. So let's analyze the\nwork of this algorithm.",
    "start": "3279110",
    "end": "3285330"
  },
  {
    "text": " So the work that we need to\ndo for a submatrix of size",
    "start": "3285330",
    "end": "3294380"
  },
  {
    "text": "s by s is going to be s cubed,\nsince that's just a bound for matrix multiplication.",
    "start": "3294380",
    "end": "3300950"
  },
  {
    "text": "And then a number of times I\nhave to operate on submatrices is going to be n over s cubed.",
    "start": "3300950",
    "end": "3307589"
  },
  {
    "text": "And you can see this if you just\nconsider each submatrix to be a single element, and then\nusing the same cubic work",
    "start": "3307590",
    "end": "3313820"
  },
  {
    "text": "analysis on the smaller matrix. So the work is n over\ns cubed times s cubed,",
    "start": "3313820",
    "end": "3322710"
  },
  {
    "text": "which is equal to\ntheta of n cubed. So the work of this tiled\nmatrix multiplies the same",
    "start": "3322710",
    "end": "3327800"
  },
  {
    "text": "as the version that\ndidn't do tiling. And now, let's analyze the\nnumber of cache misses.",
    "start": "3327800",
    "end": "3334040"
  },
  {
    "text": " So we're going to tune s so\nthat the submatrices just",
    "start": "3334040",
    "end": "3342019"
  },
  {
    "text": "fit into cache. So we're going to set\ns to be equal to theta of square root of M. We\nactually need to make this 1/3",
    "start": "3342020",
    "end": "3353990"
  },
  {
    "text": "square root of M,\nbecause we need to fit three submatrices in the cache. But it's going to be some\nconstant times square",
    "start": "3353990",
    "end": "3359780"
  },
  {
    "text": "root of M. The submatrix caching level\nimplies that for each submatrix",
    "start": "3359780",
    "end": "3367190"
  },
  {
    "text": "we're going to need x squared\nover B misses to load it in. And once we loaded into cache,\nit fits entirely into cache,",
    "start": "3367190",
    "end": "3373850"
  },
  {
    "text": "so we can do all of our\ncomputations within cache and not incur any\nmore cache misses. ",
    "start": "3373850",
    "end": "3381530"
  },
  {
    "text": "So therefore, the\ntotal number of cache misses we're going\nto incur, it's going to be the number\nof subproblems, which",
    "start": "3381530",
    "end": "3387860"
  },
  {
    "text": "is n over s cubed and\nthen a number of cache misses per subproblem,\nwhich is s squared over B.",
    "start": "3387860",
    "end": "3395210"
  },
  {
    "text": "And if you multiply\nthis out, you're going to get n cubed over\nB times square root of M.",
    "start": "3395210",
    "end": "3403070"
  },
  {
    "text": "So here, I plugged in\nsquare root of M for s. ",
    "start": "3403070",
    "end": "3408440"
  },
  {
    "text": "And this is a\npretty cool result, because it says that you\ncan actually do better than the n cubed over B bound.",
    "start": "3408440",
    "end": "3413540"
  },
  {
    "text": "You can improve this bound by\na factor of square root of M. And in practice,\nsquare root of M",
    "start": "3413540",
    "end": "3420950"
  },
  {
    "text": "is actually not insignificant. So, for example, if you're\nlooking at the last level",
    "start": "3420950",
    "end": "3427250"
  },
  {
    "text": "cache, the size of that is\non the order of megabytes. So a square root\nof M is going to be on the order of thousands.",
    "start": "3427250",
    "end": "3433340"
  },
  {
    "text": "So this significantly\nimproves the performance of the matrix\nmultiplication code if you tune s so that\nthe submatrices just",
    "start": "3433340",
    "end": "3440750"
  },
  {
    "text": "fit in the cache. It turns out that\nthis bound is optimal.",
    "start": "3440750",
    "end": "3446180"
  },
  {
    "text": "So this was shown in 1981. So for cubic work\nmatrix multiplication,",
    "start": "3446180",
    "end": "3452760"
  },
  {
    "text": "this is the best you can do. If you use another matrix\nmultiply algorithm, like Strassen's algorithm,\nyou can do better.",
    "start": "3452760",
    "end": "3460380"
  },
  {
    "text": "So I want you to\nremember this bound. It's a very important\nbound to know. It says that for a\nmatrix multiplication",
    "start": "3460380",
    "end": "3468049"
  },
  {
    "text": "you can benefit both from\nspatial locality as well as temporal locality.",
    "start": "3468050",
    "end": "3473160"
  },
  {
    "text": "So I get spatial locality in\nthe B term in the denominator.",
    "start": "3473160",
    "end": "3478819"
  },
  {
    "text": "And then the square\nroot of M term comes from temporal\nlocality, since I'm doing all of the work\ninside a submatrix",
    "start": "3478820",
    "end": "3484730"
  },
  {
    "text": "before I evict that\nsubmatrix from cache. ",
    "start": "3484730",
    "end": "3490190"
  },
  {
    "text": "Any questions on this analysis? So what's one issue with\nthis algorithm here?",
    "start": "3490190",
    "end": "3495640"
  },
  {
    "text": " Yes.",
    "start": "3495640",
    "end": "3500697"
  },
  {
    "text": "AUDIENCE: It's not portable,\nlike different architecture [INAUDIBLE]. JULIAN SHUN: Yeah. So the problem here\nis I have to tune s",
    "start": "3500697",
    "end": "3507930"
  },
  {
    "text": "for my particular machine. And I call this a\nvoodoo parameter. It's sort of like a magic\nnumber I put into my program",
    "start": "3507930",
    "end": "3516420"
  },
  {
    "text": "so that it fits in the cache\non the particular machine I'm running on. And this makes the\ncode not portable,",
    "start": "3516420",
    "end": "3522630"
  },
  {
    "text": "because if I try to run this\ncode on a another machine, the cache sizes might\nbe different there,",
    "start": "3522630",
    "end": "3529480"
  },
  {
    "text": "and then I won't get\nthe same performance as I did on my machine. ",
    "start": "3529480",
    "end": "3535710"
  },
  {
    "text": "And this is also an issue\neven if you're running it on the same machine,\nbecause you might have other programs\nrunning at the same time",
    "start": "3535710",
    "end": "3541620"
  },
  {
    "text": "and using up part of the cache. So you don't actually\nknow how much of the cache your program actually gets\nto use in a multiprogramming",
    "start": "3541620",
    "end": "3550020"
  },
  {
    "text": "environment.  And then this was also just\nfor one level of cache.",
    "start": "3550020",
    "end": "3557280"
  },
  {
    "text": "If we want to optimize\nfor two levels of caches, we're going to have two\nvoodoo parameters, s and t.",
    "start": "3557280",
    "end": "3563910"
  },
  {
    "start": "3559000",
    "end": "3559000"
  },
  {
    "text": "We're going to have submatrices\nand sub-submatrices. And then we have to tune\nboth of these parameters",
    "start": "3563910",
    "end": "3569970"
  },
  {
    "text": "to get the best\nperformance on our machine. And multi-dimensional\ntuning optimization can't be done simply\nwith binary search.",
    "start": "3569970",
    "end": "3576789"
  },
  {
    "text": "So if you're just tuning\nfor one level of cache, you can do a binary\nsearch on the parameter s, but here you can't\ndo binary search.",
    "start": "3576790",
    "end": "3583470"
  },
  {
    "text": "So it's much more\nexpensive to optimize here. And the code becomes\na little bit messier.",
    "start": "3583470",
    "end": "3591180"
  },
  {
    "text": "You have nine for\nloops instead of six. And how many levels of caches\ndo we have on the machines",
    "start": "3591180",
    "end": "3599330"
  },
  {
    "text": "that we're using today? AUDIENCE: Three. JULIAN SHUN: Three. So for three level cache, you\nhave three voodoo parameters.",
    "start": "3599330",
    "end": "3606920"
  },
  {
    "text": "You have 12 nested for loops. This code becomes very ugly. And you have to tune\nthese parameters",
    "start": "3606920",
    "end": "3613310"
  },
  {
    "text": "for your particular machine. And this makes the\ncode not very portable, as one student pointed out.",
    "start": "3613310",
    "end": "3619970"
  },
  {
    "text": "And in a multiprogramming\nenvironment, you don't actually know\nthe effective cache size that your program has access to.",
    "start": "3619970",
    "end": "3625490"
  },
  {
    "text": "Because other jobs are running\nat the same time, and therefore it's very easy to\nmistune the parameters.",
    "start": "3625490",
    "end": "3630948"
  },
  {
    "text": "Was their question? No? So any questions? Yeah. Is there a way to\nprogrammatically get",
    "start": "3630948",
    "end": "3637563"
  },
  {
    "text": "the size of the cache? [INAUDIBLE] JULIAN SHUN: Yeah. So you can auto-tune\nyour program",
    "start": "3637563",
    "end": "3643610"
  },
  {
    "text": "so that it's optimized\nfor the cache sizes of your particular machine. AUDIENCE: [INAUDIBLE]\ninstruction",
    "start": "3643610",
    "end": "3649658"
  },
  {
    "text": "to get the size of\nthe cache [INAUDIBLE].. JULIAN SHUN: Instruction to\nget the size of your cache.",
    "start": "3649658",
    "end": "3656473"
  },
  {
    "text": "I'm not actually sure. Do you know? AUDIENCE: [INAUDIBLE] in-- AUDIENCE: [INAUDIBLE]. AUDIENCE: Yeah, in the proc--",
    "start": "3656473",
    "end": "3662410"
  },
  {
    "start": "3662410",
    "end": "3667595"
  },
  {
    "text": "JULIAN SHUN: Yeah, proc cpuinfo. AUDIENCE: Yeah. proc cpuinfo\nor something like that. JULIAN SHUN: Yeah. So you can probably\nget that as well.",
    "start": "3667595",
    "end": "3674260"
  },
  {
    "text": "AUDIENCE: And I\nthink if you google, I think you'll find\nit pretty quickly. JULIAN SHUN: Yeah. AUDIENCE: Yeah. ",
    "start": "3674260",
    "end": "3683400"
  },
  {
    "text": "But even if you do\nthat, and you're running this program when\nother jobs are running, you don't actually know how much\ncache your program has access",
    "start": "3683400",
    "end": "3690570"
  },
  {
    "text": "to. Yes? Is cache of architecture\nand stuff like that optimized around\nmatrix problems?",
    "start": "3690570",
    "end": "3697109"
  },
  {
    "text": "JULIAN SHUN: No. They're actually\ngeneral purpose. Today, we're just looking\nat matrix multiply,",
    "start": "3697110",
    "end": "3703320"
  },
  {
    "text": "but on Thursday's\nlecture we'll actually be looking at many\nother problems and how to optimize them\nfor the cache hierarchy.",
    "start": "3703320",
    "end": "3710848"
  },
  {
    "start": "3710848",
    "end": "3716180"
  },
  {
    "text": "Other questions? ",
    "start": "3716180",
    "end": "3721790"
  },
  {
    "text": "So this was a good algorithm\nin terms of cache performance, but it wasn't very portable.",
    "start": "3721790",
    "end": "3727935"
  },
  {
    "text": "So let's see if\nwe can do better. Let's see if we can come\nup with a simpler design where we still get pretty\ngood cache performance.",
    "start": "3727935",
    "end": "3735390"
  },
  {
    "text": "So we're going to turn\nto divide and conquer. We're going to look at the\nrecursive matrix multiplication",
    "start": "3735390",
    "end": "3741770"
  },
  {
    "text": "algorithm that we saw before. Again, we're going to\ndeal with square matrices, but the results generalize\nto non-square matrices.",
    "start": "3741770",
    "end": "3750330"
  },
  {
    "text": "So how this works is\nwe're going to split our [INAUDIBLE] matrices\ninto four submatrices or four",
    "start": "3750330",
    "end": "3757340"
  },
  {
    "text": "quadrants. And then for each quadrant\nof the output matrix, it's just going to be the sum\nof two matrix multiplies on n",
    "start": "3757340",
    "end": "3765109"
  },
  {
    "text": "over 2 by n over 2 matrices. So c 1 1 one is going\nto be a 1 1 times b 1 1,",
    "start": "3765110",
    "end": "3771260"
  },
  {
    "text": "plus a 1 2 times B 2 1. And then we're going\nto do this recursively.",
    "start": "3771260",
    "end": "3776900"
  },
  {
    "text": "So every level of\nrecursion we're going to get eight\nmultiplied adds of n over 2",
    "start": "3776900",
    "end": "3784069"
  },
  {
    "text": "by n over 2 matrices. Here's what the recursive\ncode looks like.",
    "start": "3784070",
    "end": "3790440"
  },
  {
    "text": "You can see that we have\neight recursive calls here. The base case here is of size 1.",
    "start": "3790440",
    "end": "3797059"
  },
  {
    "text": "In practice, you want to coarsen\nthe base case to overcome function call overheads. ",
    "start": "3797060",
    "end": "3803690"
  },
  {
    "text": "Let's also look at what these\nvalues here correspond to. So I've color coded these\nso that they correspond",
    "start": "3803690",
    "end": "3811890"
  },
  {
    "text": "to particular elements\nin the submatrix that I'm looking\nat on the right. So these values here\ncorrespond to the index",
    "start": "3811890",
    "end": "3819060"
  },
  {
    "text": "of the first element in\neach of my quadrants. So the first element\nin my first quadrant is just going to\nhave an offset of 0.",
    "start": "3819060",
    "end": "3827250"
  },
  {
    "text": "And then the first element\nof my second quadrant, that's going to\nbe on the same row as the first element\nin my first quadrant.",
    "start": "3827250",
    "end": "3834120"
  },
  {
    "text": "So I just need to add the\nwidth of my quadrant, which",
    "start": "3834120",
    "end": "3842790"
  },
  {
    "text": "is n over 2. And then to get the first\nelement in quadrant 2 1,",
    "start": "3842790",
    "end": "3849480"
  },
  {
    "text": "I'm going to jump over\nand over two rows. And each row has\na length row size,",
    "start": "3849480",
    "end": "3856140"
  },
  {
    "text": "so it's just going to be\nn over 2 times row size. And then to get the first\nelement in quadrant 2 2,",
    "start": "3856140",
    "end": "3863400"
  },
  {
    "text": "it's just the first element\nin quadrant 2 1 plus n over 2. So that's n over 2\ntimes row size plus 1.",
    "start": "3863400",
    "end": "3870450"
  },
  {
    "text": " So let's analyze the\nwork of this algorithm.",
    "start": "3870450",
    "end": "3878390"
  },
  {
    "text": "So what's the recurrence\nfor this algorithm-- for the work of this algorithm?",
    "start": "3878390",
    "end": "3884750"
  },
  {
    "text": "So how many\nsubproblems do we have? AUDIENCE: Eight JULIAN SHUN: Eight. And what's the size of\neach Subproblem n over 2.",
    "start": "3884750",
    "end": "3893840"
  },
  {
    "text": "And how much work are we doing\nto set up the recursive calls? ",
    "start": "3893840",
    "end": "3900887"
  },
  {
    "text": "A constant amount of work. So the recurrences is\nW of n is equal to 8 W",
    "start": "3900887",
    "end": "3906580"
  },
  {
    "text": "n over 2 plus theta of 1. And what does that solve to?",
    "start": "3906580",
    "end": "3912560"
  },
  {
    "text": "n cubed. So it's one of the three\ncases of the master theorem. ",
    "start": "3912560",
    "end": "3920850"
  },
  {
    "text": "We're actually going to\nanalyze this in more detail by drawing out the\nrecursion tree.",
    "start": "3920850",
    "end": "3925920"
  },
  {
    "text": "And this is going to give\nus more intuition about why the master theorem is true.",
    "start": "3925920",
    "end": "3932540"
  },
  {
    "text": "So at the top level\nof my recursion tree, I'm going to have a\nproblem of size n.",
    "start": "3932540",
    "end": "3938320"
  },
  {
    "text": "And then I'm going to branch\ninto eight subproblems of size n over 2. And then I'm going to do\na constant amount of work",
    "start": "3938320",
    "end": "3944300"
  },
  {
    "text": "to set up the recursive calls. Here, I'm just\nlabeling this with one. So I'm ignoring the constants. But it's not going to matter\nfor asymptotic analysis.",
    "start": "3944300",
    "end": "3952670"
  },
  {
    "text": "And then I'm going\nto branch again into eight subproblems\nof size n over 4.",
    "start": "3952670",
    "end": "3958250"
  },
  {
    "text": "And eventually, I'm going\nto get down to the leaves. And how many levels do I have\nuntil I get to the leaves?",
    "start": "3958250",
    "end": "3966342"
  },
  {
    "start": "3966342",
    "end": "3971510"
  },
  {
    "text": "Yes? AUDIENCE: Log n. JULIAN SHUN: Yeah. So log n-- what's\nthe base of the log?",
    "start": "3971510",
    "end": "3977790"
  },
  {
    "text": "Yeah. So it's log base 2 of n,\nbecause I'm dividing my problem size by 2 every time. ",
    "start": "3977790",
    "end": "3984942"
  },
  {
    "text": "And therefore, the\nnumber of leaves I have is going to be 8\nto the log base 2 of n, because I'm branching it\neight ways every time.",
    "start": "3984942",
    "end": "3991500"
  },
  {
    "text": "8 to the log base 2 of n is\nthe same as n to the log base 2 of 8, which is n cubed.",
    "start": "3991500",
    "end": "3997230"
  },
  {
    "text": " The amount of work I'm doing\nat the top level is constant.",
    "start": "3997230",
    "end": "4004740"
  },
  {
    "text": "So I'm just going to say 1 here. At the next level, it's\neight times, then 64.",
    "start": "4004740",
    "end": "4012450"
  },
  {
    "text": "And then when I\nget to the leaves, it's going to be\ntheta of n cubed, since I have m cubed\nleaves, and they're all",
    "start": "4012450",
    "end": "4018329"
  },
  {
    "text": "doing constant work. And the work is geometrically\nincreasing as I go down",
    "start": "4018330",
    "end": "4024060"
  },
  {
    "text": "the recursion tree. So the overall work is\njust dominated by the work I need to do at the leaves.",
    "start": "4024060",
    "end": "4029850"
  },
  {
    "text": "So the overall work is just\ngoing to be theta of n cubed. And this is the\nsame as the looping",
    "start": "4029850",
    "end": "4035430"
  },
  {
    "text": "versions of matrix multiply-- they're all cubic work. Now, let's analyze the number\nof cache misses of this divide",
    "start": "4035430",
    "end": "4042990"
  },
  {
    "text": "and conquer algorithm. So now, my recurrence is\ngoing to be different.",
    "start": "4042990",
    "end": "4049540"
  },
  {
    "text": "My base case now is when the\nsubmatrix fits in the cache-- so when n squared is less than\nc M. And when that's true,",
    "start": "4049540",
    "end": "4058200"
  },
  {
    "text": "I just need to load that\nsubmatrix into cache, and then I don't incur\nany more cache misses.",
    "start": "4058200",
    "end": "4063300"
  },
  {
    "text": "So I need theta of n\nsquared over B cache misses when n squared is less\nthan c M for some sufficiently",
    "start": "4063300",
    "end": "4069839"
  },
  {
    "text": "small constant c, less\nthan or equal to 1. And then, otherwise, I recurse\ninto 8 subproblems of size n",
    "start": "4069840",
    "end": "4076680"
  },
  {
    "text": "over 2. And then I add theta\nof 1, because I'm doing a constant amount of work\nto set up the recursive calls.",
    "start": "4076680",
    "end": "4083740"
  },
  {
    "text": "And I get this state of\nn squared over B term from the submatrix\ncaching lemma.",
    "start": "4083740",
    "end": "4088935"
  },
  {
    "text": "It says I can just load the\nentire matrix into cache with this many cache misses.",
    "start": "4088935",
    "end": "4095020"
  },
  {
    "text": "So the difference between\nthe cache analysis here and the work analysis before\nis that I have a different base",
    "start": "4095020",
    "end": "4100859"
  },
  {
    "text": "case. And I think in all\nof the algorithms that you've seen before,\nthe base case was always",
    "start": "4100859",
    "end": "4106979"
  },
  {
    "text": "of a constant size. But here, we're working\nwith a base case that's not of a constant size. ",
    "start": "4106979",
    "end": "4114359"
  },
  {
    "text": "So let's try to analyze this\nusing the recursion tree approach. So at the top level, I\nhave a problem of size n",
    "start": "4114359",
    "end": "4122259"
  },
  {
    "text": "that I'm going to branch\ninto eight problems of size n over 2. And then I'm also going to\nincur a constant number of cache",
    "start": "4122260",
    "end": "4128170"
  },
  {
    "text": "misses. I'm just going to say 1 here. Then I'm going to branch again.",
    "start": "4128170",
    "end": "4134850"
  },
  {
    "text": "And then, eventually, I'm\ngoing to get to the base case where n squared\nis less than c M.",
    "start": "4134850",
    "end": "4141839"
  },
  {
    "text": "And when n squared is less than\nc M, then the number of cache misses that I'm going\nto incur is going",
    "start": "4141840",
    "end": "4147299"
  },
  {
    "text": "to be theta of c M over B. So\nI can just plug-in c M here",
    "start": "4147300",
    "end": "4152460"
  },
  {
    "text": "for n squared. And the number of\nlevels of recursion",
    "start": "4152460",
    "end": "4157830"
  },
  {
    "text": "I have in this recursion tree is\nno longer just log base 2 of n. I'm going to have log base\n2 of n minus log base 2",
    "start": "4157830",
    "end": "4167369"
  },
  {
    "text": "of square root of c M\nnumber of levels, which is the same as log base\n2 of n minus 1/2 times",
    "start": "4167370",
    "end": "4173850"
  },
  {
    "text": "log base 2 of c M. And then,\nthe number of leaves I get",
    "start": "4173850",
    "end": "4180390"
  },
  {
    "text": "is going to be 8 to this\nnumber of levels here. So it's 8 to log base 2 of n\nminus 1/2 of log base 2 of c M.",
    "start": "4180390",
    "end": "4190680"
  },
  {
    "text": "And this is equal to the theta\nof n cubed over M to the 3/2.",
    "start": "4190680",
    "end": "4196400"
  },
  {
    "text": "So the n cubed comes from the\n8 to the log base 2 of n term. And then if I do 8 to the\nnegative 1/2 of log base 2",
    "start": "4196400",
    "end": "4207450"
  },
  {
    "text": "of c M, that's just going\nto give me M to the 3/2",
    "start": "4207450",
    "end": "4212520"
  },
  {
    "text": "in the denominator.  So any questions on how I\ncomputed the number of levels",
    "start": "4212520",
    "end": "4219160"
  },
  {
    "text": "of this recursion tree here? ",
    "start": "4219160",
    "end": "4229400"
  },
  {
    "text": "So I'm basically dividing\nmy problem size by 2 until I get to a problem\nsize that fits in the cache.",
    "start": "4229400",
    "end": "4235409"
  },
  {
    "text": "So that means n is less\nthan square root of c M. So therefore, I can\nsubtract that many levels",
    "start": "4235410",
    "end": "4242310"
  },
  {
    "text": "for my recursion tree.  And then to get the\nnumber of leaves,",
    "start": "4242310",
    "end": "4247790"
  },
  {
    "text": "since I'm branching\neight ways, I just do 8 to the power of\nthe number of levels I have. And then that gives me the\ntotal number of leaves.",
    "start": "4247790",
    "end": "4254713"
  },
  {
    "text": " So now, let's analyze\na number of cache",
    "start": "4254713",
    "end": "4260320"
  },
  {
    "text": "misses I need each level\nof this recursion tree. At the top level, I\nhave a constant number",
    "start": "4260320",
    "end": "4265630"
  },
  {
    "text": "of cache misses-- let's just say 1. The next level, I have 8, 64.",
    "start": "4265630",
    "end": "4272530"
  },
  {
    "text": "And then at the\nleaves, I'm going to have theta of n cubed over\nB times square root of M cache",
    "start": "4272530",
    "end": "4278050"
  },
  {
    "text": "misses. And I got this quantity\njust by multiplying the number of\nleaves by the number",
    "start": "4278050",
    "end": "4283660"
  },
  {
    "text": "of cache misses per leaf. So number of leaves is n\ncubed over M to the 3/2.",
    "start": "4283660",
    "end": "4288730"
  },
  {
    "text": "The cache misses per leaves\nis theta of c M over B. So I lose one factor of\nB in the denominator.",
    "start": "4288730",
    "end": "4295640"
  },
  {
    "text": "I'm left with the square\nroot of M at the bottom. And then I also divide\nby the block size B.",
    "start": "4295640",
    "end": "4301449"
  },
  {
    "text": "So overall, I get n cubed over\nB times square root of M cache misses. And again, this is\na geometric series.",
    "start": "4301450",
    "end": "4308440"
  },
  {
    "text": "And the number of cache\nmisses at the leaves dominates all of\nthe other levels. So the total number\nof cache misses",
    "start": "4308440",
    "end": "4314830"
  },
  {
    "text": "I have is going to\nbe theta of n cubed over B times square root of M.",
    "start": "4314830",
    "end": "4320896"
  },
  {
    "text": "And notice that I'm getting\nthe same number of cache misses as I did with the\ntiling version of the code.",
    "start": "4320896",
    "end": "4327330"
  },
  {
    "text": "But here, I don't actually\nhave the tune my code for the particular cache size.",
    "start": "4327330",
    "end": "4332510"
  },
  {
    "text": "So what cache sizes\ndoes this code work for? ",
    "start": "4332510",
    "end": "4342130"
  },
  {
    "text": "So is this code going\nto work on your machine? ",
    "start": "4342130",
    "end": "4347920"
  },
  {
    "text": "Is it going to get\ngood cache performance? So this code is going to\nwork for all cache sizes,",
    "start": "4347920",
    "end": "4353340"
  },
  {
    "text": "because I didn't tune it for\nany particular cache size.",
    "start": "4353340",
    "end": "4358369"
  },
  {
    "text": "And this is what's known as\na cache-oblivious algorithm. It doesn't have any\nvoodoo tuning parameters,",
    "start": "4358370",
    "end": "4364300"
  },
  {
    "text": "it has no explicit\nknowledge of the caches, and it's essentially\npassively auto-tuning itself",
    "start": "4364300",
    "end": "4369539"
  },
  {
    "text": "for the particular cache\nsize of your machine. It can also work for\nmulti-level caches",
    "start": "4369540",
    "end": "4376620"
  },
  {
    "text": "automatically, because I never\nspecified what level of cache I'm analyzing this for. I can analyze it for\nany level of cache,",
    "start": "4376620",
    "end": "4383170"
  },
  {
    "text": "and it's still going to give\nme good cache complexity. And this is also good in\nmultiprogramming environments,",
    "start": "4383170",
    "end": "4388680"
  },
  {
    "text": "where you might have\nother jobs running and you don't know your\neffective cache size. This is just going to passively\nauto-tune for whatever",
    "start": "4388680",
    "end": "4394660"
  },
  {
    "text": "cache size is available.  It turns out that the best\ncache-oblivious codes to date",
    "start": "4394660",
    "end": "4401619"
  },
  {
    "text": "work on arbitrary\nrectangular matrices. I just talked about\nsquare matrices, but the best codes work\non rectangular matrices.",
    "start": "4401620",
    "end": "4409000"
  },
  {
    "text": "And they perform\nbinary splitting instead of eight-way splitting. And you're split on the\nlargest of i, j, and k.",
    "start": "4409000",
    "end": "4417130"
  },
  {
    "text": "So this is what the best\ncache-oblivious matrix multiplication algorithm does. ",
    "start": "4417130",
    "end": "4424970"
  },
  {
    "text": "Any questions? ",
    "start": "4424970",
    "end": "4430940"
  },
  {
    "text": "So I only talked about\nthe serial setting so far. I was assuming that\nthese algorithms",
    "start": "4430940",
    "end": "4436090"
  },
  {
    "text": "ran on just a single thread. What happens if I go\nto multiple processors?",
    "start": "4436090",
    "end": "4442674"
  },
  {
    "text": "It turns out that the\nresults do generalize to a parallel context.",
    "start": "4442674",
    "end": "4448380"
  },
  {
    "text": "So this is the recursive\nparallel matrix multiply code that we saw before.",
    "start": "4448380",
    "end": "4453710"
  },
  {
    "text": "And notice that we're executing\nfour sub calls in parallel, doing a sync, and then\ndoing four more sub",
    "start": "4453710",
    "end": "4459620"
  },
  {
    "text": "calls in parallel.  So let's try to analyze\nthe number of cache",
    "start": "4459620",
    "end": "4465920"
  },
  {
    "text": "misses in this parallel code. And to do that, we're going\nto use this theorem, which says that let Q sub p\nbe the number of cache",
    "start": "4465920",
    "end": "4472910"
  },
  {
    "text": "misses in a deterministic\ncell computation why run on P processors, each\nwith a private cache of size M.",
    "start": "4472910",
    "end": "4479000"
  },
  {
    "text": "And let S sub p be the\nnumber of successful steals during the computation. In the ideal cache model,\nthe number of cache",
    "start": "4479000",
    "end": "4486800"
  },
  {
    "text": "misses we're going to have\nis Q sub p equal to Q sub 1 plus big O of number of\nsteals times M over B.",
    "start": "4486800",
    "end": "4495830"
  },
  {
    "text": "So the number of cache misses\nin the parallel context is equal to the number of cache\nmisses when you run it serially",
    "start": "4495830",
    "end": "4502730"
  },
  {
    "text": "plus this term here, which\nis the number of steals times M over B.",
    "start": "4502730",
    "end": "4509670"
  },
  {
    "text": "And the proof for this goes\nas follows-- so every call in the Cilk runtime\nsystem, we can",
    "start": "4509670",
    "end": "4516199"
  },
  {
    "text": "have workers steal\ntasks from other workers when they don't have work to do. And after a worker steals\na task from another worker,",
    "start": "4516200",
    "end": "4523520"
  },
  {
    "text": "it's cache becomes completely\ncold in the worst case, because it wasn't actually\nworking on that subproblem",
    "start": "4523520",
    "end": "4529790"
  },
  {
    "text": "before. But after M over B\ncold cache misses, its cache is going to become\nidentical to what it would",
    "start": "4529790",
    "end": "4536630"
  },
  {
    "text": "be in the serial execution. So we just need to\npay M over B cache misses to make it so that\nthe cache looks the same as",
    "start": "4536630",
    "end": "4544130"
  },
  {
    "text": "if it were executing serially. And the same is\ntrue when a worker resumes a stolen subcomputation\nafter a Cilk sync.",
    "start": "4544130",
    "end": "4552380"
  },
  {
    "text": "And the number of times that\nthese two situations can happen is 2 times as S p--",
    "start": "4552380",
    "end": "4557795"
  },
  {
    "text": "2 times the number of steals. And each time, we have to\npay M over b cache misses.",
    "start": "4557795",
    "end": "4563780"
  },
  {
    "text": "And this is where this additive\nterm comes from-- order S sub p times M over B.",
    "start": "4563780",
    "end": "4573260"
  },
  {
    "text": "We also know that the number\nof steals in a Cilk program is upper-bounded by\nP times T infinity,",
    "start": "4573260",
    "end": "4581770"
  },
  {
    "text": "in the expectation where P\nis the number of processors and T infinity is the\nspan of your computation.",
    "start": "4581770",
    "end": "4587390"
  },
  {
    "text": "So if you can minimize the\nspan of your computation, then this also gives\nyou a good cache bounds.",
    "start": "4587390",
    "end": "4594170"
  },
  {
    "text": "So moral of the story\nhere is that minimizing the number of cache\nmisses in a serial elision",
    "start": "4594170",
    "end": "4601010"
  },
  {
    "text": "essentially minimizes them\nin the parallel execution for a low span algorithm.",
    "start": "4601010",
    "end": "4606080"
  },
  {
    "text": " So in this recursive matrix\nmultiplication algorithm,",
    "start": "4606080",
    "end": "4611660"
  },
  {
    "text": "the span of this is as follows-- so T infinity of n is 2T\ninfinity of of n over 2",
    "start": "4611660",
    "end": "4618920"
  },
  {
    "text": "plus theta of 1. Since we're doing\na sync here, we have to pay the critical\npath length of two sub calls.",
    "start": "4618920",
    "end": "4626960"
  },
  {
    "text": "This solves to theta of n. And applying to previous\nlemma, this gives us",
    "start": "4626960",
    "end": "4632150"
  },
  {
    "text": "a cache miss bound of theta of\nn cubed over B square root of M.",
    "start": "4632150",
    "end": "4637190"
  },
  {
    "text": "This is just the same\nas the serial execution And then this additive term is\ngoing to be order P times n.",
    "start": "4637190",
    "end": "4644150"
  },
  {
    "text": "And it's a span times M over B",
    "start": "4644150",
    "end": "4649570"
  },
  {
    "text": "So that was a parallel\nalgorithm for matrix multiply.",
    "start": "4649570",
    "end": "4655510"
  },
  {
    "text": "And we saw that we can also\nget good cache bounds there. So here's a summary of\nwhat we talked about today.",
    "start": "4655510",
    "end": "4661429"
  },
  {
    "text": "We talked about associativity\nand caches, different ways you can design a cache.",
    "start": "4661430",
    "end": "4667790"
  },
  {
    "text": "We talked about the\nideal cache model that's useful for\nanalyzing algorithms.",
    "start": "4667790",
    "end": "4672940"
  },
  {
    "text": "We talked about\ncache-aware algorithms that have explicit\nknowledge of the cache.",
    "start": "4672940",
    "end": "4678110"
  },
  {
    "text": "And the example we used\nwas titled matrix multiply. Then we came up with a\nmuch simpler algorithm",
    "start": "4678110",
    "end": "4683980"
  },
  {
    "text": "that was cache-oblivious\nusing divide and conquer.",
    "start": "4683980",
    "end": "4689290"
  },
  {
    "text": "And then on Thursday's\nlecture, we'll actually see much more on\ncache-oblivious algorithm",
    "start": "4689290",
    "end": "4694730"
  },
  {
    "text": "design. And then you'll also\nhave an opportunity to analyze the cache\nefficiency of some algorithms",
    "start": "4694730",
    "end": "4700150"
  },
  {
    "text": "in the next homework.",
    "start": "4700150",
    "end": "4702690"
  }
]
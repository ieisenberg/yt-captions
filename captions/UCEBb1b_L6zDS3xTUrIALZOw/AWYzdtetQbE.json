[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5620"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5620",
    "end": "12280"
  },
  {
    "text": "To make a donation, or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12280",
    "end": "18869"
  },
  {
    "text": "at OCW.MIT.edu. JAMES DICARLO: I'm\ngoing to shift more towards this decoding\nspace than we talked about,",
    "start": "18870",
    "end": "25980"
  },
  {
    "text": "the linkage between neural\nactivity and behavioral report. And I introduced that a bit.",
    "start": "25980",
    "end": "31170"
  },
  {
    "text": "You just saw that there's some\npopulation powerful activity in IT. And I'm going to expand\non that a bit here.",
    "start": "31170",
    "end": "37450"
  },
  {
    "text": "But sort of stepping back,\nwhen you think about it again, what I call an end\nto end understanding,",
    "start": "37450",
    "end": "42780"
  },
  {
    "text": "going from the image all\nthe way to neural activity to the perceptual report, one\nof the things we want to do, again, is just define\na decoding mechanism",
    "start": "42780",
    "end": "49540"
  },
  {
    "text": "that the brain uses to support\nthese perceptual reports. Basically what neural\nactivity are directly responsible for these tasks?",
    "start": "49540",
    "end": "56250"
  },
  {
    "text": "And I'll come back to\nlater this encoding side. It's like, you know,\nand notice I'm putting these in this order, right?",
    "start": "56250",
    "end": "61274"
  },
  {
    "text": "So once you know what\nthe relevant aspects of neural activity are in IT,\nor wherever you think they are,",
    "start": "61274",
    "end": "66900"
  },
  {
    "text": "then that sets a target\nfor what is the image to neural transformation that\nyou're trying to explain?",
    "start": "66900",
    "end": "72420"
  },
  {
    "text": "Not predict any neural\nresponse, but those particular aspects of\nthe neural response. So that's what I mean by\nthe relevant ventral stream",
    "start": "72420",
    "end": "78720"
  },
  {
    "text": "patterns of activity. So we start here. We work to here, and then\nwe work to here, rather than",
    "start": "78720",
    "end": "84150"
  },
  {
    "text": "the other way around. OK, so I'm going\nto try it again. Keep with the domain I set up. I talked about core recognition.",
    "start": "84150",
    "end": "89520"
  },
  {
    "text": "I now need to start\nto define tasks. I'm going to talk about specific\ntasks that are, for now, let's",
    "start": "89520",
    "end": "94890"
  },
  {
    "text": "call them basic level nouns. I'm actually going to relax\nthat to subordinate tasks in a minute. But here they are.",
    "start": "94890",
    "end": "100830"
  },
  {
    "text": "Car, clock, cat. These are not the actual nouns. I'll show you the ones we use. But just to fix\nideas, we're imagining a space of all possible\nnouns that you might use",
    "start": "100830",
    "end": "109140"
  },
  {
    "text": "to describe what you just saw. And I'm going to have a\ngenerative image domain. So I now have a\nspace of images here.",
    "start": "109140",
    "end": "115425"
  },
  {
    "text": "I'm not just going to\ndraw these off the web. We're going to\ngenerate our own image domain that we think\nengages on the problem,",
    "start": "115426",
    "end": "120600"
  },
  {
    "text": "but gives us control of\nthe latent variables. So I'll show you that now. So the way we're\ngoing to do this is by generating one\nforeground object in each image",
    "start": "120600",
    "end": "128849"
  },
  {
    "text": "that we're going to show. And we just did this by\ntaking 3-D models like these--",
    "start": "128850",
    "end": "133890"
  },
  {
    "text": "this is a model of a car. We can control it's other latent\nvariables beyond its identity. So this is a car.",
    "start": "133890",
    "end": "139250"
  },
  {
    "text": "It has a particular car type. So there's a couple of latent\nvariables about identity here that relate to the geometry.",
    "start": "139250",
    "end": "145349"
  },
  {
    "text": "Then there's these position--\nother latent variables like position, size, and\npose that I mentioned, that are unknowns that make\nthe problem challenging.",
    "start": "145350",
    "end": "151620"
  },
  {
    "text": "And we can then just,\nlike, render this thing. And we could place it on any\nold background we wanted to.",
    "start": "151620",
    "end": "157140"
  },
  {
    "text": "And what we did was we\ntended to place them on uncorrelated\nnaturalistic backgrounds. And that creates these sort\nof weirdish looking images.",
    "start": "157140",
    "end": "164189"
  },
  {
    "text": "Some of them may look\nsort of natural, hence, this looks pretty unnatural. But the reason we did this.",
    "start": "164190",
    "end": "169500"
  },
  {
    "text": "Why would you do this? So-- so we did this because we\ncould add a generative space.",
    "start": "169500",
    "end": "175270"
  },
  {
    "text": "And because it was-- so we know\nwhat's going on with the latent variables we care about. And we also, when we built this,\nit was challenging for computer",
    "start": "175270",
    "end": "182910"
  },
  {
    "text": "vision systems to\ndeal with this, even though humans could\nnaturally-- you know, they don't have advantage\nof any contextual cues",
    "start": "182910",
    "end": "188520"
  },
  {
    "text": "here because by construction,\nthese are uncorrelated. We just took natural\nimages and would randomly",
    "start": "188520",
    "end": "194100"
  },
  {
    "text": "put objects on them. But this was enough to fool\na lot of the computer vision systems at the time that tended\nto rely on the contextual cues.",
    "start": "194100",
    "end": "201000"
  },
  {
    "text": "Like blue in the background\nsignals or being an airplane, we didn't want those kind\nof things being done. We wanted the actual\nextraction of object identity.",
    "start": "201000",
    "end": "207840"
  },
  {
    "text": "And again, humans\ncould do it quite well. So that's why we\nended up in this sort of maybe this no man's\nland of image space, which",
    "start": "207840",
    "end": "214829"
  },
  {
    "text": "is not very simple, but not\nImageNet just pulled off off the web. And so that's how we got there.",
    "start": "214830",
    "end": "221070"
  },
  {
    "text": "And just to give you a\nsense that this is actually quite doable for humans,\nI'll show you a few images. I won't even cue\nyou what they are. I'm going to show them\nfor 100 milliseconds.",
    "start": "221070",
    "end": "227883"
  },
  {
    "text": "You can kind of shout\nout what object you see. AUDIENCE: Car. AUDIENCE: [INAUDIBLE]",
    "start": "227883",
    "end": "235265"
  },
  {
    "text": "JAMES DICARIO: Right. So see, it's pretty\nstraightforward, right? And those look weird, you\ncan do that quite well.",
    "start": "235265",
    "end": "240655"
  },
  {
    "text": "And you know, here's the kind of\nimages that we would generate. This would be-- so when\nwe think of image bags,",
    "start": "240655",
    "end": "245997"
  },
  {
    "text": "we think of partitions\nof image space. This is some images that\nwould correspond to faces. These are all images of faces\nunder some transformations.",
    "start": "245997",
    "end": "252962"
  },
  {
    "text": "Again, different backgrounds. These are not faces. These are other objects\nagain, under transformations. And we can have as many\nof these as we want.",
    "start": "252962",
    "end": "260259"
  },
  {
    "text": "We call this one-- this distinction, when\nshown for 100 milliseconds-- is one core recognition test.",
    "start": "260260",
    "end": "265780"
  },
  {
    "text": "Discriminate face for not face. Here is a subordinate task. This is beetle from not beetle. This is a particular\ntype of car.",
    "start": "265780",
    "end": "271690"
  },
  {
    "text": "You can see it's\nmore challenging. Again, we don't show\nthese images like this. This is just to\nshow you the set.",
    "start": "271690",
    "end": "276695"
  },
  {
    "text": "We show them one at a time. And so let me now\ngo ahead and say, we're going to try to make\na predictive model using",
    "start": "276695",
    "end": "283240"
  },
  {
    "text": "that kind of image space to\nsee if we can understand what are the relevant aspects\nof neural activity",
    "start": "283240",
    "end": "288940"
  },
  {
    "text": "that can predict human\nreport on an image space? And when I say we, I\nmean Naiib Maiai and Ha",
    "start": "288940",
    "end": "294280"
  },
  {
    "text": "Hong, who are post-doc\nand graduate student that were in the lab that\nled this experimental work. And Ethan Soloman and Dan Yamins\nalso contributed to the work.",
    "start": "294280",
    "end": "303200"
  },
  {
    "text": "So what we did was to try to\nrecord a bunch of IT activity to measure what's going\non in the population",
    "start": "303200",
    "end": "310390"
  },
  {
    "text": "as I showed you earlier, but\nnow in this more defined space where we're going to collect\na bunch of human behavior to compare possible\nways of reading IT",
    "start": "310390",
    "end": "318040"
  },
  {
    "text": "with the behavior of the human. This is how we started. We're now doing monkeys--",
    "start": "318040",
    "end": "323310"
  },
  {
    "text": "where we're recording and\nthe monkey's doing a task. But what we did here was we\njust passively fixating monkeys,",
    "start": "323310",
    "end": "328720"
  },
  {
    "text": "compared with behaving humans. And as I showed you\nearlier, monkeys and humans have very similar\npatterns of behavior.",
    "start": "328720",
    "end": "334849"
  },
  {
    "text": "So what we record\nfrom IT, in this case, we were using array\nrecording electrodes. These are chronically implanted.",
    "start": "334850",
    "end": "340750"
  },
  {
    "text": "This shows them here. You implant them\nduring a surgery, as kind of is shown here. Down in the IT cortex.",
    "start": "340750",
    "end": "345919"
  },
  {
    "text": "You can get their size here. There are about hundred-- there's actually 96\nelectrodes on each of them. They typically yield about\nhalf of the electrodes",
    "start": "345920",
    "end": "352780"
  },
  {
    "text": "having active neurons on them. So you get, you know, on the\norder of 150 recording sites.",
    "start": "352780",
    "end": "358309"
  },
  {
    "text": "And you can lay them out. You can lay-- we would\ntypically lay out three of them across IT and\nV4 to record a population",
    "start": "358309",
    "end": "364990"
  },
  {
    "text": "sample out of IT. And we would do this across\namong multiple monkeys. And here's an example of the\nkind of data we would get.",
    "start": "364990",
    "end": "371560"
  },
  {
    "text": "This is 168 IT recording sites. This is similar to what\nI showed you earlier. This is the mean response\nin a particular time window",
    "start": "371560",
    "end": "379600"
  },
  {
    "text": "out of IT, similar to\nwhat I showed you earlier in that study with Gabriel. And what we do here is, I'm just\nshowing you to give you feel.",
    "start": "379600",
    "end": "386230"
  },
  {
    "text": "That's one image. Here is eight more--\nhere's seven more images. And these are just\nthe population vectors",
    "start": "386230",
    "end": "392199"
  },
  {
    "text": "in a graphic form. And but we actually\ncollected nearly 25-- this is 2,560 images.",
    "start": "392200",
    "end": "397870"
  },
  {
    "text": "This is sort of\nthe mean response data of this 168 neurons. And now you have this again,\nthis rich population data.",
    "start": "397870",
    "end": "403550"
  },
  {
    "text": "And you can ask, what's\navailable in there to support these tasks? And how well does it predict\nhuman patterns of performance",
    "start": "403550",
    "end": "409870"
  },
  {
    "text": "on those tasks? So in this study, that's\nall we were asking to do. We're trying to do\nmore and more recently.",
    "start": "409870",
    "end": "416139"
  },
  {
    "text": "But let me show you what all\nwe were trying to do is to say, look. One thing we observed,\neven though you saw that car-- you could\ndo car, you could do faces.",
    "start": "416140",
    "end": "423670"
  },
  {
    "text": "It seemed like you\nwere doing 100%. Turns out you're better at\nsome things than others. So discriminate-- this is\na deep prime map of humans.",
    "start": "423670",
    "end": "430509"
  },
  {
    "text": "So red means good performance. High D prime. You know, a D prime of\n3 is something like--",
    "start": "430510",
    "end": "436404"
  },
  {
    "text": "I don't know, psychophysicists\nin the room may correct me. A D prime of 3 is sort of\non the order of 90 some 95%",
    "start": "436404",
    "end": "442000"
  },
  {
    "text": "correct, in that range. So these are very high\nperformance levels when you get up to 5.",
    "start": "442000",
    "end": "447400"
  },
  {
    "text": "0 is chance. So 50%-- well this\nis an eight way task. So one over 8% correct.",
    "start": "447400",
    "end": "453220"
  },
  {
    "text": "So the subjects were doing\neither eight way basic level tasks, or eight way subordinate\ncars, or eight way faces.",
    "start": "453220",
    "end": "459527"
  },
  {
    "text": "And these are the D prime\nlevels under different amounts of variation of those\nother latent variables position size and pose.",
    "start": "459527",
    "end": "464966"
  },
  {
    "text": "Don't worry about those details. What I want you to\nsee is the color here. So look, it's tables versus--",
    "start": "464967",
    "end": "470560"
  },
  {
    "text": "discriminating tables from\nall these other objects. You do that at a\nvery high D prime. Discriminating beetles\nfrom other cars,",
    "start": "470560",
    "end": "477699"
  },
  {
    "text": "you do it at slightly\nlower D prime. You can see this, specially\nat a high variation,",
    "start": "477700",
    "end": "482934"
  },
  {
    "text": "you're actually starting to\nget down to lower performance. And faces-- one face\nversus another face, you're actually\nquite poor at that.",
    "start": "482934",
    "end": "489530"
  },
  {
    "text": "You're a little bit\nbetter than chance. But it's actually quite\nchallenging in 100 milliseconds without hair and\nglasses to discriminate",
    "start": "489530",
    "end": "495730"
  },
  {
    "text": "those 3-D kind of face models. I showed you Sam and\nJoe earlier as examples. You're actually quite\nchallenging to do",
    "start": "495730",
    "end": "502480"
  },
  {
    "text": "that for humans in\nthat domain of faces. So, what I want to\nshow you here is you have this pattern of\nbehavioral performance.",
    "start": "502480",
    "end": "508630"
  },
  {
    "text": "You have all this IT activity. This is humans. This is monkeys. And what we wanted\nto do is say, look. We can use this pattern.",
    "start": "508630",
    "end": "514370"
  },
  {
    "text": "This is very repeatable\nacross humans. Can we use this repeatable\nbehavioral pattern to understand what\naspects of this activity",
    "start": "514370",
    "end": "521559"
  },
  {
    "text": "could map to that? And again, this\npattern is reliable. I just said that. And it's not as if you\ncan predict this pattern",
    "start": "521559",
    "end": "528220"
  },
  {
    "text": "by just running classifiers\non pixels or V1. In fact, I'll show\nyou that a minute.",
    "start": "528220",
    "end": "533297"
  },
  {
    "text": "But we thought there's\nsome aspects of IT activity that would predict this. And we wanted to try to\nfind those aspects to--",
    "start": "533297",
    "end": "539250"
  },
  {
    "text": "so, again, this was motivated\nby that study I showed you earlier. So which part of the\nIT population activity",
    "start": "539250",
    "end": "545220"
  },
  {
    "text": "could predict this behavior\nover all recognition tasks? We're seeking a general\ndecoding model that would work.",
    "start": "545220",
    "end": "551086"
  },
  {
    "text": "Here's some specific tasks. But we'd like it to be-- work over any task that we\ncould imagine testing humans within this domain\nof taking 3D models,",
    "start": "551086",
    "end": "558240"
  },
  {
    "text": "putting them under variation. Work over that entire domain. That was what we\nwere hoping to do. So again, I'll briefly\ntake you through this.",
    "start": "558240",
    "end": "564600"
  },
  {
    "text": "Because I already\nshowed you this earlier. Again, we've previously shown\nthat you could kind of take this kind of state\nspace, and say hey,",
    "start": "564600",
    "end": "570570"
  },
  {
    "text": "can you separate images\nof faces from non-faces, using these simple\nlinear classifiers, which are essentially weighted\nsums on the IT activity?",
    "start": "570570",
    "end": "578730"
  },
  {
    "text": "And now we wanted\nto ask, could this predict human behavioral\nface performance, and monkey, because again,\nthey're very similar.",
    "start": "578730",
    "end": "585600"
  },
  {
    "text": "And not only would\nthis class of decoding models that was motivated by the\nearlier work predict this task,",
    "start": "585600",
    "end": "591420"
  },
  {
    "text": "but would predict car detection? Would the same model predict\ncar one versus car two?",
    "start": "591420",
    "end": "596580"
  },
  {
    "text": "That's a subordinate task. And all such tasks. Again, over the whole domain,\ncan you take a same decoding",
    "start": "596580",
    "end": "601740"
  },
  {
    "text": "strategy and take\nthe data and say, I'm going to just learn on\na certain number of training examples, build a\nclassifier, and then I'll",
    "start": "601740",
    "end": "607830"
  },
  {
    "text": "say that's my model\nof how the human does every one of these tasks. And if that's true,\nthen it should perfectly",
    "start": "607830",
    "end": "613542"
  },
  {
    "text": "predict that pattern\nor performance that I just showed you earlier. And so here was again, this\nwas the working hypothesis.",
    "start": "613542",
    "end": "620550"
  },
  {
    "text": "Passively evoked spike rates\nusing single fixed time scale that are spatially\ndistributed, because they're sampled over IT, over a single\nfixed number of non-human--",
    "start": "620550",
    "end": "629399"
  },
  {
    "text": "of non-human primate cortex. So a single number of neurons. And learn from a reasonable\nnumber of training examples.",
    "start": "629400",
    "end": "635360"
  },
  {
    "text": "So all of that is a decoding\nclass of models that we thought might work.",
    "start": "635360",
    "end": "640617"
  },
  {
    "text": "And if this is correct--\nthis is what I just said-- it should predict\nthe behavioral data that we collect. For example, the D prime\ndata I just showed you.",
    "start": "640617",
    "end": "647350"
  },
  {
    "text": "But also more fine grained\nbehavioral data in principle. So I want to just\nstep back to make",
    "start": "647350",
    "end": "652530"
  },
  {
    "text": "it clear that it's not obvious\nthat this should work, right? I mean, it depends-- in the audience, I get people\non completely different sides",
    "start": "652530",
    "end": "659880"
  },
  {
    "text": "of this, whether this\nshould work or not. So, you know, one thing\nis, like, well look, it's passively evoked.",
    "start": "659880",
    "end": "664920"
  },
  {
    "text": "You heard Gabriel say, well,\nyou didn't like passive tasks. And I agree with that. In the ideal world,\nthe animal will be actively doing the task.",
    "start": "664920",
    "end": "670710"
  },
  {
    "text": "And then you'd say, well I'll\nmeasure while the animal's doing the task. That's going to be your\nbest chance of prediction. But we also saw earlier\nthat that passively",
    "start": "670710",
    "end": "676800"
  },
  {
    "text": "evoked monkey still-- you know, nobody would argue\nthat a passively evoked retinal data is not going to be\nsomewhat applicable to vision.",
    "start": "676800",
    "end": "684330"
  },
  {
    "text": "And you know, the\nquestion is, how much of those arousal effects\nshow up in a place like IT cortex, which\nis typically high?",
    "start": "684330",
    "end": "691110"
  },
  {
    "text": "Which is high up in\nthe ventral stream. So you could argue\nboth sides of this. But it's possible that\nattentional arousal mechanisms",
    "start": "691110",
    "end": "696930"
  },
  {
    "text": "are needed to make this a good\npredictive linkage between that to sort of activate IT in this\nsort of crude way, if you like.",
    "start": "696930",
    "end": "703554"
  },
  {
    "text": "Some people have pointed\nout that you need the trial by trial coordinated\nspike timing structure to actually\nmake good predictions,",
    "start": "703554",
    "end": "709649"
  },
  {
    "text": "that those are critical. Some people have pointed out\nthat you have to kind of assign different parts of IT to\nparticular roles, which is",
    "start": "709650",
    "end": "717030"
  },
  {
    "text": "a prior on the decoding space. For instance, that you could\nbelieve that biologically, an animal's born.",
    "start": "717030",
    "end": "722460"
  },
  {
    "text": "There's some tissue that's\ngoing to be dedicated to faces. You have to wire those neurons\ndownstream to that tissue.",
    "start": "722460",
    "end": "727501"
  },
  {
    "text": "And that means you're going to\nrestrict the decoding space, rather than just letting them\nlearn from the space of IT",
    "start": "727502",
    "end": "732555"
  },
  {
    "text": "as if they collected\nsamples off of all of IT. So I think some\npeople implicitly believe that even if it's\nnot stated quite that way.",
    "start": "732555",
    "end": "740180"
  },
  {
    "text": "IT does not directly\nunderlie recognition. You could imagine that. I mean, it's not for sure known. And some lesions of IT\ndon't produce deficits",
    "start": "740180",
    "end": "747690"
  },
  {
    "text": "in recognition. That's a possibility. Maybe you need too\nmany training examples. Monkey neural codes cannot\nexplain human behavior.",
    "start": "747690",
    "end": "753992"
  },
  {
    "text": "You know, again, but\nI already showed you monkeys and humans\nare very similar. So these are the\nreasons that you might say this is negative,\nand might not work.",
    "start": "753992",
    "end": "760350"
  },
  {
    "text": "And probably\nalready have guessed that I'm telling all these\nnegatives because it turns out this simple thing works quite\nwell for the grain of behavior",
    "start": "760350",
    "end": "766800"
  },
  {
    "text": "that I've shown you so far. And here's my evidence of that. So this is actual behavioral\nperformance out of humans",
    "start": "766800",
    "end": "772117"
  },
  {
    "text": "that I showed you earlier. This is mean D prime. This is the predicted\nbehavior or performance of taking a classifier, reading\nfrom that IT population data",
    "start": "772117",
    "end": "779520"
  },
  {
    "text": "that I've shown you, which\ngives a predicted D prime. Here is-- we first\nchose a decoder. We had to match things\nlike the number of neurons.",
    "start": "779520",
    "end": "786180"
  },
  {
    "text": "We had to get it in\nthe ballpark, so-- because again, there's\na free variable, as I showed you earlier. There's at least one. But for now, let's think of\nmatching the number of neurons",
    "start": "786180",
    "end": "794130"
  },
  {
    "text": "to get you near the\ndiagonal, so that you have sufficient number\nof neural recordings to say, how well do you do\non a face detection task?",
    "start": "794130",
    "end": "800700"
  },
  {
    "text": "And then, here's\nall the other tasks. This is those 64 points\nthat I showed you earlier. Here's some examples like\nfruit versus other things, car",
    "start": "800700",
    "end": "806910"
  },
  {
    "text": "versus other things. And you should see that all\nthese points kind of line up along this diagonal, which\nsays, wow, this is actually",
    "start": "806910",
    "end": "813546"
  },
  {
    "text": "quite predictive, that I\ncan take this simple thing and predict all the stuff\nthat we've collected so far.",
    "start": "813546",
    "end": "818980"
  },
  {
    "text": "And so let me now kind\nof be more concrete about what is the\ninferred neural mechanism that we're testing here?",
    "start": "818980",
    "end": "824820"
  },
  {
    "text": "Well, I'll show you in a minute. This is, for each\nnew object, we think what happens is some\ndownstream observer,",
    "start": "824820",
    "end": "831570"
  },
  {
    "text": "a downstream neuron, randomly\nsamples roughly 50,000 single neurons, spatially\ndistributed over all of IT,",
    "start": "831570",
    "end": "837430"
  },
  {
    "text": "not biased to any compartments. Listens to each IT sites. When I say listen\nin this case, we",
    "start": "837430",
    "end": "843490"
  },
  {
    "text": "think could average\nover 100 milliseconds. We're not sure about this. This is just the version\nthat's shown here.",
    "start": "843490",
    "end": "848860"
  },
  {
    "text": "Learn an appropriate weighted\nsum of those IT spiking. And then listen at 10%. That's basically,\nonce you learn,",
    "start": "848860",
    "end": "854649"
  },
  {
    "text": "there's a heavily weighted\nabout 10% of the IT neurons are heavily weighted\nfor each of the tasks.",
    "start": "854650",
    "end": "859960"
  },
  {
    "text": "That's just an observation\nthat we have in our data. But this is trying to map it\nto neuroscientist language",
    "start": "859960",
    "end": "865300"
  },
  {
    "text": "from these decoder\nversions out of IT. So what that is a\nmodel that says, learn weighted sums of 50,000\nrandom average 100 milliseconds",
    "start": "865300",
    "end": "872384"
  },
  {
    "text": "single unit responses\ndistributed over all IT. So a bunch of stuff in\nhere is what your model",
    "start": "872384",
    "end": "877760"
  },
  {
    "text": "is sort of encapsulating. That's still too long. So I made a little\nacronym out of that. And that caught Laws of\nRAD IT decoding mechanism.",
    "start": "877760",
    "end": "885009"
  },
  {
    "text": "So this is just to say there's\na hypothesis of how everything might work, but now can be make\npredictions for other objects",
    "start": "885010",
    "end": "892330"
  },
  {
    "text": "and could potentially\nbe falsified. So, so far, this model works\nquite well over these tasks.",
    "start": "892330",
    "end": "899590"
  },
  {
    "text": "And in fact, the\ncorrelation is 0.92. You might look at this and\nsay, oh, it's not perfect. But it turns out that\nthat's about the level",
    "start": "899590",
    "end": "905470"
  },
  {
    "text": "that which humans\ndiffer from each other. So it's passing a Turing test,\nthat this mechanism read off",
    "start": "905470",
    "end": "910870"
  },
  {
    "text": "of the monkey IT hides\nin the distribution of the human population that\nwe're asking to also perform",
    "start": "910870",
    "end": "916870"
  },
  {
    "text": "these same tasks. So it can't be\ndistinguished from being a human in these tasks.",
    "start": "916870",
    "end": "922750"
  },
  {
    "text": "You guys, watch \"X Machina?\" Wasn't that a movie I saw? Doesn't pass that test. Passes just a simple\ncore recognition test.",
    "start": "922750",
    "end": "929760"
  },
  {
    "text": "But so that was a\nTuring test of this. So OK, so, this is\nhere that I quantified. So this is human to\nhuman consistency.",
    "start": "929760",
    "end": "937000"
  },
  {
    "text": "That's the range\nI just mentioned that, you've got to get\ninto here to pass our Turing test on this.",
    "start": "937000",
    "end": "942387"
  },
  {
    "text": "And that's a decoding\nmechanism I just showed you. There's other ways of reading\nout of IT that don't pass.",
    "start": "942387",
    "end": "947459"
  },
  {
    "text": "There's ways of reading out of\nV4, which you recorded from-- none of them we've tried are\nable to get you to this here.",
    "start": "947460",
    "end": "952790"
  },
  {
    "text": "That doesn't mean\nV4 isn't involved. V4 is the feeder to IT. It just means you can't take\nsimple decodes off of V4",
    "start": "952790",
    "end": "959470"
  },
  {
    "text": "and naturally\nproduces this pattern. And that's similar for like,\npixels or V1 representations. So lower level representations\ndon't naturally",
    "start": "959470",
    "end": "966610"
  },
  {
    "text": "predict this\npattern of behavior. And even some\ncomputer vision codes that we tested at the time, as\nyou can see, if those of you",
    "start": "966610",
    "end": "972760"
  },
  {
    "text": "know these older computer\nvision models didn't do this. But more recent computer\nvision models actually do.",
    "start": "972760",
    "end": "979870"
  },
  {
    "text": "And I'll show you\nthat at the end. OK. So, this is a little\nbit for the aficionados",
    "start": "979870",
    "end": "985420"
  },
  {
    "text": "to tell you how\nwe got there as we increase the number of units in\nIT, that drives performance up.",
    "start": "985420",
    "end": "991160"
  },
  {
    "text": "So as you read more and\nmore units out of IT, you get better and\nbetter performance. That's also true out of V4.",
    "start": "991160",
    "end": "996539"
  },
  {
    "text": "But I'm trying to\nshow you this here, is it's like, not the\nabsolute performance that is the good thing\nto compare a model",
    "start": "996539",
    "end": "1004260"
  },
  {
    "text": "with actual behavioral data. It's the pattern of\nperformance, which we call the consistency\nwith the humans.",
    "start": "1004260",
    "end": "1009780"
  },
  {
    "text": "That's that correlation\nalong that diagonal that I showed you\nearlier, that tasks that are hard for the models\nare also hard for the humans.",
    "start": "1009780",
    "end": "1016020"
  },
  {
    "text": "Tasks that are easy for humans\nare also easy for the models. And you could\nimagine doing that, not just at the task level,\nbut at the image level as well.",
    "start": "1016020",
    "end": "1023560"
  },
  {
    "text": "And anyway, that's\nwhat's quantified here. And you see that when you get up\nto around you know, about 100-- I showed you 168\nrecordings out of IT.",
    "start": "1023560",
    "end": "1032010"
  },
  {
    "text": "This point right there\nis about 500 IT features. And taking you\nthrough some things that maybe I won't\nhave time for,",
    "start": "1032010",
    "end": "1038130"
  },
  {
    "text": "that's actually how we\napproximate that 50,000 single IT neuron number. That's an inference\nfrom our data",
    "start": "1038130",
    "end": "1044880"
  },
  {
    "text": "based on if we didn't actually\nrecord 50,000 single neurons. But from these kind\nof plots, we're able to make a pretty good guess\nthat this kind of model right",
    "start": "1044880",
    "end": "1053190"
  },
  {
    "text": "here would produce-- would land right there. To be consistent with\nhumans, and would get the absolute\nlevel of performance",
    "start": "1053190",
    "end": "1059760"
  },
  {
    "text": "which humans matched. And you know, the models\nwe tried out of V4, this is one example of them. They can get performance.",
    "start": "1059760",
    "end": "1065580"
  },
  {
    "text": "But they can never-- they\ndon't match this pattern of performance naturally. They over perform on some tasks,\nand under-perform on others.",
    "start": "1065580",
    "end": "1071639"
  },
  {
    "text": "They sort of reveal\nthemselves as not being human like by being too\ngood at some things, right?",
    "start": "1071640",
    "end": "1077640"
  },
  {
    "text": "So that's a way to\nfail the Turing test. OK. Maybe I'll skip through this,\nit's sort of the same thing.",
    "start": "1077640",
    "end": "1084010"
  },
  {
    "text": "This is about training examples. If those of you guys\ncare about this, I could kind of take you through\nhow we-- there's actually",
    "start": "1084010",
    "end": "1089390"
  },
  {
    "text": "a family of solutions in there. And I'm just telling you about\none of them for simplicity. So, let me then just take\nit down to another grain.",
    "start": "1089390",
    "end": "1097165"
  },
  {
    "text": "So that was the\npattern of performance, it's actually\nnaturally predicted by this first decoding\nmechanism that we tried.",
    "start": "1097166",
    "end": "1102990"
  },
  {
    "text": "But what about the\nconfusion pattern? So not just the absolute D\nprimes for each of these tasks, but there's finer grained data,\nlike how often an animal is",
    "start": "1102990",
    "end": "1110640"
  },
  {
    "text": "confused with a fruit, or an\nanimal's confused with a face. These are the confusion\npattern data here. I'm sorry I don't have\nthe color bars up.",
    "start": "1110640",
    "end": "1116669"
  },
  {
    "text": "All I'm going to need you\nto do is say, well these are the confusion patterns\nthat we predicted. And this is what is the\npredicted confusion pattern,",
    "start": "1116670",
    "end": "1124710"
  },
  {
    "text": "if I gave the machine, the\nIT, these ground truth labels. And it predicts this.",
    "start": "1124710",
    "end": "1130810"
  },
  {
    "text": "This is what actually\nhappened in human data. And what I want to sort of\nlook at this and this, and say, there actually\nlook quite similar.",
    "start": "1130810",
    "end": "1135900"
  },
  {
    "text": "Their noise corrected\ncorrelation is 0.91. So they were still quite good at\npredicting confusion patterns.",
    "start": "1135900",
    "end": "1140940"
  },
  {
    "text": "Although this did\nnot hold up fully. We're only at 0.68. I say only. Some people would\nsay this is success.",
    "start": "1140940",
    "end": "1147300"
  },
  {
    "text": "We're only at 0.68\non high variation. So there's a failure\nhere of the model. That should be at 1, because\nit's noise corrected.",
    "start": "1147300",
    "end": "1153360"
  },
  {
    "text": "So there's something\nabout this that's not quite right at\npredicting the confusion patterns of humans at\nhigh variation images.",
    "start": "1153360",
    "end": "1159600"
  },
  {
    "text": "And that to us, that's an\nopening to push forward, right? So this is a strategy\ngoing forward",
    "start": "1159600",
    "end": "1164730"
  },
  {
    "text": "as we have an initial guess\nof how you read out of IT. It looks pretty good\nfor first grain test.",
    "start": "1164730",
    "end": "1170730"
  },
  {
    "text": "But now we can turn\nthe crank harder. We need more neural data. We need more psychophysics,\nfiner grained measurements",
    "start": "1170730",
    "end": "1176970"
  },
  {
    "text": "to sort of distinguish\namong, not just say IT's better than V4 or\nthose other representations. But what exactly about\nthe IT representation?",
    "start": "1176970",
    "end": "1184380"
  },
  {
    "text": "Is it 100 milliseconds? What time scale? Maybe those synchronous\ncodes do matter. Some of those things that\nI put on there earlier",
    "start": "1184380",
    "end": "1190430"
  },
  {
    "text": "might start to matter when\nwe push the code-- push this even further. So what I take home\nhere is that you",
    "start": "1190430",
    "end": "1196440"
  },
  {
    "text": "do quite well with this\nfirst order rate code reads out of IT. But now there's an opportunity\nto try to dig in and say,",
    "start": "1196440",
    "end": "1204330"
  },
  {
    "text": "well at what point\ndo they break down? And what kind of\ndecoding models are you going to replace them with? And that's what\nwe're trying to do.",
    "start": "1204330",
    "end": "1211680"
  },
  {
    "text": "I've told you that IT\ndoes good at identity. But remember I said\nearlier on, remember I showed you those\nmanifolds, and said there's other latent variables\nlike position and scale.",
    "start": "1211680",
    "end": "1219420"
  },
  {
    "text": "And I said those\ndon't get thrown away. They just get unwrapped, right? Remember that manifold\npicture I showed earlier?",
    "start": "1219420",
    "end": "1225377"
  },
  {
    "text": "And so one of the things\nwe've been doing recently is asking, because we\nbuilt these images, we know these other\nlatent variables,",
    "start": "1225377",
    "end": "1231120"
  },
  {
    "text": "like position and\npose-- that was one of the advantages of\nbuilding the images this way. And we've been asking how well\nIT encodes those other latent",
    "start": "1231120",
    "end": "1238530"
  },
  {
    "text": "variables about the\npose of the object, the position of the object. And to make-- let me\njust skip through.",
    "start": "1238530",
    "end": "1245670"
  },
  {
    "text": "To make a long story short,\nIT actually encodes-- not only has information\nabout these kind of variables,",
    "start": "1245670",
    "end": "1250990"
  },
  {
    "text": "which is really not\nsurprising, because others have shown that\nthere's information about those kind\nof things before.",
    "start": "1250990",
    "end": "1257040"
  },
  {
    "text": "But that's sort\nof what's on here. Everything what I'm\nshowing here, here's IT V4 simulated V1 in pixels.",
    "start": "1257040",
    "end": "1263059"
  },
  {
    "text": "And always, everything goes\nup along the ventral stream for the other\nvariables, which may be non-intuitive to some of you.",
    "start": "1263060",
    "end": "1268950"
  },
  {
    "text": "I mean, because position\nis supposed to be V1. But position of an object\nin a complex background is better at IT.",
    "start": "1268950",
    "end": "1274560"
  },
  {
    "text": "That's one example. But all these latent\nvariables go up along the ventral\nstream in terms of their ease of decoding.",
    "start": "1274560",
    "end": "1280900"
  },
  {
    "text": "But what I'm most\nexcited about is that if you do this\ncomparison with humans again,",
    "start": "1280900",
    "end": "1286080"
  },
  {
    "text": "you actually get this sort\nof, again, pretty decent, not quite as tight correlation,\nbetween the human--",
    "start": "1286080",
    "end": "1291877"
  },
  {
    "text": "actual measured\nbehavioral performance on making estimates of those\nother latent variables, and the predicted behavioral\nperformance out of IT.",
    "start": "1291877",
    "end": "1298450"
  },
  {
    "text": "And again, much\nbetter correlations. It's not perfect. So again, there's some gap here,\nsome failure of understanding.",
    "start": "1298450",
    "end": "1304169"
  },
  {
    "text": "But much better than if you\nread out of V4, V1 or pixel. So this says that the\nrepresentation again isn't just",
    "start": "1304170",
    "end": "1310620"
  },
  {
    "text": "an identity thing. It seems like this could\nbe representational underlie some of these\nother judgments, at least",
    "start": "1310620",
    "end": "1316320"
  },
  {
    "text": "at the central 10 degrees for\nsort of foreground objects as we've been measuring here. That's the-- don't worry about\nthe details on here-- that's",
    "start": "1316320",
    "end": "1323428"
  },
  {
    "text": "the upshot of what I'm trying\nto say with this slide. But I just wanted to\nput that out there so you didn't forget that\nyou haven't thrown away",
    "start": "1323428",
    "end": "1329309"
  },
  {
    "text": "all this other interesting\nstuff about what's out there in the scene. OK. Let me kind of--",
    "start": "1329310",
    "end": "1334626"
  },
  {
    "text": "I've sort of alluded\nto this a bit. I want to come back\nto kind of now, this is like Marr\nlevel 3 stuff, right?",
    "start": "1334626",
    "end": "1340350"
  },
  {
    "text": "So you have this idea of\nwhat you're trying to solve. You have a decode-- you have an algorithm that's\na decoder on a basis, that's",
    "start": "1340350",
    "end": "1346350"
  },
  {
    "text": "trying-- that looks like\nit predicts pretty well. It's not perfect. There's work to be done there. But it actually does quite well.",
    "start": "1346350",
    "end": "1351893"
  },
  {
    "text": "Now what does that mean on\nthe physical hardware level? So that's Marr level 3. So you think-- here's\nhow I visualize it.",
    "start": "1351893",
    "end": "1357450"
  },
  {
    "text": "You have IT cortex,\nwhich I mean AIT and CIT. So it's about 150 square\nmillimeters in a monkey.",
    "start": "1357450",
    "end": "1363533"
  },
  {
    "text": "And remember I told you\nthere was about 1 millimeter scale of organization? I showed you that earlier.",
    "start": "1363534",
    "end": "1368792"
  },
  {
    "text": "And others have shown-- I showed this earlier,\ntoo-- that there's sort of face regions. So I've drawn them just\nfor sort of for scale here,",
    "start": "1368792",
    "end": "1374514"
  },
  {
    "text": "just a schematic. That they're slightly\nbigger organizations, they're 2 to 5 millimeter.",
    "start": "1374514",
    "end": "1379620"
  },
  {
    "text": "So I think of IT as being\nthis sort of like 100 to 200 little--",
    "start": "1379620",
    "end": "1384930"
  },
  {
    "text": "similar to Tanaka. This is not a new\nconceptual idea. But there's sort of\njust the simple version would be each millimeter does\nexactly the same thing, is",
    "start": "1384930",
    "end": "1392070"
  },
  {
    "text": "a feature. And if you sample off of\nthat, you take 5,000 neurons, but they're really sampling\nfrom only about 150 IT",
    "start": "1392070",
    "end": "1399320"
  },
  {
    "text": "features at 1 millimeter scale. Remember, I don't know\nif you caught that. But I showed 150--",
    "start": "1399320",
    "end": "1404820"
  },
  {
    "text": "101-- 150. I showed you 168 IT neurons\npredicted the pattern",
    "start": "1404820",
    "end": "1410424"
  },
  {
    "text": "of human performance. I showed that a few slides ago. But I told you the real number\nof neurons is probably 50,000.",
    "start": "1410425",
    "end": "1415440"
  },
  {
    "text": "Most of those are\nredundant copies of that 168 dimensional\nfeature set. That's how we think about it.",
    "start": "1415440",
    "end": "1421350"
  },
  {
    "text": "So you could imagine, it's\njust a redundant set of about-- I like to think of about\n100 features in IT which",
    "start": "1421350",
    "end": "1427410"
  },
  {
    "text": "are sampled maybe randomly\ndownstream neurons that are then learned. So when you learn faces\nversus other things,",
    "start": "1427410",
    "end": "1434390"
  },
  {
    "text": "hey, there's lots of good\ninformation about faces versus other things. And these face patches,\nthat's how they're defined.",
    "start": "1434390",
    "end": "1439610"
  },
  {
    "text": "But those neurons are\ngoing to lean heavily-- this downstream neuron\nis going to lean heavily on those neurons. And then these-- so that would\nmake these regions causally",
    "start": "1439610",
    "end": "1447800"
  },
  {
    "text": "involved. So that doesn't mean you had\nto pre-build in anything here. You just learn this at\na downstream version.",
    "start": "1447800",
    "end": "1452900"
  },
  {
    "text": "And you would get\nsomething that looks like it would explain our data. So we like that, because\nit captures that case.",
    "start": "1452900",
    "end": "1457919"
  },
  {
    "text": "But it also captures\nthe more general case. If you learn cars,\nyou're going to sample from a different\nsubset of neurons.",
    "start": "1457919",
    "end": "1462940"
  },
  {
    "text": "But you're following\nthe same learning rule. That's what I said earlier on. So you end up-- we think this is\nthe initial state.",
    "start": "1462940",
    "end": "1469760"
  },
  {
    "text": "This is when you learn objects. And so what we think is a\npost learning, what you have is again, about 100\nto 150 IT sub regions,",
    "start": "1469760",
    "end": "1476690"
  },
  {
    "text": "each at 1 millimeter\nscale, that are supporting a number\nof noun tasks read off this common basis here.",
    "start": "1476690",
    "end": "1482720"
  },
  {
    "text": "That's the model\nthat we like, given the kind of data that\nI've been showing you. The post learning\nmodel, as we call it.",
    "start": "1482720",
    "end": "1488383"
  },
  {
    "text": "So the reason I'm\nbringing this up is probably for\nthe neuroscientists to fix ideas about how we\nthink about IT as a basis set.",
    "start": "1488384",
    "end": "1494900"
  },
  {
    "text": "And this is-- I think Haim sort of\nset this up nicely, he sort of implied\nsimilar things. That somebody downstream\nreads from it.",
    "start": "1494900",
    "end": "1501020"
  },
  {
    "text": "OK. But now, we have\na more-- you know, we're starting to have a more\nconcrete model, that we now, I'm trying to start\nto be physical",
    "start": "1501020",
    "end": "1506330"
  },
  {
    "text": "about it, about the size\nof these regions connecting to earlier data,\nhow many there are. So we're gaining\ninference on that",
    "start": "1506330",
    "end": "1511610"
  },
  {
    "text": "from these different\nexperiments. And now, if you believe this,\nit starts to make a prediction of what's-- now we can\ndo causality, right?",
    "start": "1511610",
    "end": "1517639"
  },
  {
    "text": "Somebody mentioned that earlier. And so, one of the things\nwe've been doing recently is if we can start to silence-- look, the way I've drawn\nthis, this bit of tissue",
    "start": "1517640",
    "end": "1524030"
  },
  {
    "text": "for-- this is just\nschematic-- is somehow involved in this\ntask and that task. Face task and car task.",
    "start": "1524030",
    "end": "1529700"
  },
  {
    "text": "But this bit of\ntissue, only face task. And that bit of\ntissue, only car task. And this bit of tissue, neither.",
    "start": "1529700",
    "end": "1535779"
  },
  {
    "text": "So if you believe that,\nyou had the tools, you should be able\nto go in and start to silence little bits of IT.",
    "start": "1535780",
    "end": "1540830"
  },
  {
    "text": "And you should get\npredictable patterns out of the behavioral\ndeficits of the animal when you make those\nmanipulations, right?",
    "start": "1540830",
    "end": "1546460"
  },
  {
    "text": "Everybody follow that? Right? OK. And now the models\ngive you a framework to build those\npredictions and to also",
    "start": "1546460",
    "end": "1552800"
  },
  {
    "text": "estimate the magnitude of those\neffects that you should see. And so that's what we've\nbeen doing more recently.",
    "start": "1552800",
    "end": "1557850"
  },
  {
    "text": "And I'll just give\nyou a taste of this, because this is really ongoing. But I think it connects\nto what Gabriel said earlier about now there\nare these tools available to do",
    "start": "1557850",
    "end": "1564389"
  },
  {
    "text": "that. Oh, I put that in from\nan earlier talk where-- I think Google has a\nthing called Inception. And I don't know--",
    "start": "1564389",
    "end": "1569570"
  },
  {
    "text": "was it Google? Or somebody has it-- you can't\ndo Inception unless you're actually in a brain. So are you going\nto try to insert--",
    "start": "1569570",
    "end": "1575120"
  },
  {
    "text": "the reason we do this is my\nstudent that is working on it really wants to inject\nsignals in the brain. There's a dream\nabout VMI, right?",
    "start": "1575120",
    "end": "1581450"
  },
  {
    "text": "Could you kind of\ninject a percept? And to do that,\nyou're going to need to do experiments like this. And you understand this\nhardware to interact with it.",
    "start": "1581450",
    "end": "1588635"
  },
  {
    "text": "It's something we\ntalked about earlier. So actually-- and Tonegawa's lab\nhas some cool Inception stuff",
    "start": "1588635",
    "end": "1594181"
  },
  {
    "text": "on memory. But this is like inserting\nan object/person. So to do that, this has\nbeen a dream for many of us",
    "start": "1594181",
    "end": "1599510"
  },
  {
    "text": "for a long time. Can we reliably\ndisrupt performance by suppressing 1\nmillimeter bits of IT?",
    "start": "1599510",
    "end": "1605600"
  },
  {
    "text": "So to do that,\nwhat we're doing is testing a large battery\nof tasks and a battery",
    "start": "1605600",
    "end": "1610630"
  },
  {
    "text": "of suppression patterns. So not just sort\nof saying, can we affect face tasks or one task? But let's imagine we\ntest a battery of tasks.",
    "start": "1610630",
    "end": "1617546"
  },
  {
    "text": "And then, we--\nand the idea where we'd have a whole bunch of tasks\nand we'd do every bit of IT one by one, and then in\ncombination, and we'd",
    "start": "1617546",
    "end": "1623360"
  },
  {
    "text": "sort of get all that data\nand figure out what's going on, right? That's sort of the dream, right? So we're trying to build\ntowards that dream. Do you guys get it?",
    "start": "1623360",
    "end": "1629100"
  },
  {
    "text": "Right. I mean, I don't know. And then we're motivated\nby this kind of idea here. So to build-- so we started--",
    "start": "1629100",
    "end": "1634865"
  },
  {
    "text": "I'm just going to give\nyou a quick tour of we have tools to start to do this. You know, this is\nour recording, we",
    "start": "1634865",
    "end": "1640952"
  },
  {
    "text": "can localize what we're\nrecording two very fine grain using x-rays. So we know exactly where\nwe're recording the IT to like",
    "start": "1640952",
    "end": "1646940"
  },
  {
    "text": "about 300 micron resolution. So that's why I'm\nputting this slide up. And what we're\ninterested in is going,",
    "start": "1646940",
    "end": "1652463"
  },
  {
    "text": "if I silence this bit of\nIT, or that bit of IT, or that bit of IT, so actually\ndo this experiment, what",
    "start": "1652463",
    "end": "1658789"
  },
  {
    "text": "happens behaviorally? And Arash Afraz is a\npost-doc in the lab, started these actual experiments.",
    "start": "1658790",
    "end": "1664610"
  },
  {
    "text": "And one of the things\nArash did was to first say, let's see if we can get this\nsilencing of optogenetics tool",
    "start": "1664610",
    "end": "1671330"
  },
  {
    "text": "to work in our hands. And the reason we were\nso excited about that is because we think\nlesions, if we can make temporary\nbrief silencing,",
    "start": "1671330",
    "end": "1678410"
  },
  {
    "text": "that that will give it much more\nreliable disruption of behavior that then, if we started\nto try to inject signals,",
    "start": "1678410",
    "end": "1686300"
  },
  {
    "text": "which would be our dream, but\nthat seems too risky to us. We just want to say, what\nis a temporary lesion",
    "start": "1686300",
    "end": "1691580"
  },
  {
    "text": "of each bit of IT do? And optogenetics is\ncool, because there's no other technique that\ncan briefly silence--",
    "start": "1691580",
    "end": "1697610"
  },
  {
    "text": "temporarily silence activity. You can do pharmacological\nmanipulations, but those last for hours.",
    "start": "1697610",
    "end": "1703010"
  },
  {
    "text": "So this could briefly\nsilence bits of IT. And that's why we\nwere excited about it. We also did pharmacological\nmanipulation as a reference",
    "start": "1703010",
    "end": "1710120"
  },
  {
    "text": "to get started. But what we're doing is trying\nto silence 1 millimeter regions of IT using light delivered\nthrough optical fibers",
    "start": "1710120",
    "end": "1716490"
  },
  {
    "text": "as the recording electrode. And to silence bits\nof neurons here. And so what Arash\ndid was first show",
    "start": "1716490",
    "end": "1723757"
  },
  {
    "text": "that you can actually\nsilence neurons in this way. So if you guys haven't\nseen optogenetics plots, this is data from our lab.",
    "start": "1723757",
    "end": "1729560"
  },
  {
    "text": "What's quite cool\nabout this, again, is you have the same\nimages are being presented. So this green line\nshould be up here.",
    "start": "1729560",
    "end": "1735110"
  },
  {
    "text": "But Arash turns a laser on right\nhere, shines light on there. And there's some opsins\nexpressed in the neurons in that local area.",
    "start": "1735110",
    "end": "1740861"
  },
  {
    "text": "And you can see it just sort\nof shuts the thing down, and it sort of deletes or blocks this. You have the same\ninput coming in.",
    "start": "1740861",
    "end": "1746390"
  },
  {
    "text": "But you can sort\nof delete it here. And this is another example. These are some pretty\nstrong examples. It's not always this strong.",
    "start": "1746390",
    "end": "1753750"
  },
  {
    "text": "But this is, again, you\ncan see we can return back to normal right away, right? So this is a 200\nmillisecond silencing.",
    "start": "1753750",
    "end": "1759290"
  },
  {
    "text": "You could go even\nnarrower than that. But so this is what\nwe had done so far. And again, what we\ndid was say, look.",
    "start": "1759290",
    "end": "1765020"
  },
  {
    "text": "This is a risky tool. This is it not going\nto work at all. So Arash just wanted\nto test something that was likely to work.",
    "start": "1765020",
    "end": "1771850"
  },
  {
    "text": "And so we picked a\nface task because there was a lot of evidence of\nspatial clustering of faces that you'll hear from\nWinrich and you also",
    "start": "1771850",
    "end": "1779240"
  },
  {
    "text": "known in the literature. So what Arash did\nwas to say, we picked a task of discriminating\nmales from females.",
    "start": "1779240",
    "end": "1784910"
  },
  {
    "text": "We put in our notion\nof invariance. It's not just do\nthis image access. But you have to do it across\na bunch of transformations.",
    "start": "1784910",
    "end": "1790970"
  },
  {
    "text": "In this case, its identity\nas a transformation. So you're saying, all of these\nare supposed to be called male, and all these are called female.",
    "start": "1790970",
    "end": "1797049"
  },
  {
    "text": "And he wanted you to\ndistinguish this from this. That's what he trained\na monkey to do. And just to give you the upshot,\nis that, we do all this work,",
    "start": "1797050",
    "end": "1804031"
  },
  {
    "text": "we silence the bits of cortex. And here's the big take home. You get a 2% deficit of\nsingle one millimeter",
    "start": "1804031",
    "end": "1810140"
  },
  {
    "text": "silencing of bits of IT cortex. Parts of IT cortex,\nnot all of IT cortex,",
    "start": "1810140",
    "end": "1816200"
  },
  {
    "text": "produce a 2% deficit. Here's the animal running\nat 80%, 6% correct. These are interleaved\ntrials where we silence some local bit of IT.",
    "start": "1816200",
    "end": "1822610"
  },
  {
    "text": "You get a 2% deficit. That's true only in the\ncontralateral field, not that ipsilateral\nfield, for the aficionados.",
    "start": "1822610",
    "end": "1828290"
  },
  {
    "text": "You might look at this 2%\nand go, well, that's tiny. But we looked at it,\nthis is exactly what's predicted by the models\nthat we were talking about.",
    "start": "1828290",
    "end": "1834315"
  },
  {
    "text": "It's right in the range\nof what should happen. And so this, to us,\nis really quite cool. This is highly significant.",
    "start": "1834315",
    "end": "1840445"
  },
  {
    "text": "And now we sort of are in\nposition to start to say, OK these tools work. They do what\nthey're supposed to. And now we can start to\nexpand that task space.",
    "start": "1840445",
    "end": "1847669"
  },
  {
    "text": "So this result has been\npublished recently, if you're interested in this. And here is one of the\nways we're going forward",
    "start": "1847670",
    "end": "1853070"
  },
  {
    "text": "is that Rish Rajaingham, the one\ndoing those tasks in the monkey I showed you earlier. Silencing different parts of IT.",
    "start": "1853070",
    "end": "1858390"
  },
  {
    "text": "This is now with muscimol,\ndifferent bits of IT-- these are different tasks,\nlead to different patterns.",
    "start": "1858390",
    "end": "1863570"
  },
  {
    "text": "That's what these\ndots are here-- different patterns of deficits. And if you go back\nto the same location, you get the same\npattern of deficits.",
    "start": "1863570",
    "end": "1869640"
  },
  {
    "text": "So this is only 10 tasks. But I think it\nhopefully gives you the spirit of what\nwe're trying to do.",
    "start": "1869640",
    "end": "1874760"
  },
  {
    "text": "And again, this\nis only muscimol, which doesn't have all the\nadvantages of optogenetics. But this is what we're\nwere building towards here.",
    "start": "1874760",
    "end": "1882460"
  },
  {
    "text": "So I'm just giving you the\nsort of state of the art. So our aim is to measure\nthe specific pattern",
    "start": "1882460",
    "end": "1887990"
  },
  {
    "text": "of behavioral change induced by\nthe suppression of each IT sub region, ideally\ntesting many of them, and then compare with\nthe model predictions.",
    "start": "1887990",
    "end": "1895388"
  },
  {
    "text": "I'm saying there's\nthis domain, and I want to sort of sample\nthe whole domain. So far, I've given you only just\nsamples of tasks in the domain.",
    "start": "1895389",
    "end": "1901039"
  },
  {
    "text": "But we're really trying\nto define the domain. And I'm just-- I'm going to skip through this\njust to give you the punchline,",
    "start": "1901040",
    "end": "1906353"
  },
  {
    "text": "is that we do a whole bunch\nof behavioral measurements. We presented this work before. It's like, this is now up to\nthree million Mechanical Turk",
    "start": "1906353",
    "end": "1912456"
  },
  {
    "text": "trials. It seems to us that we can\nembed all objects, even subordinate objects,\nof the type of task",
    "start": "1912456",
    "end": "1918230"
  },
  {
    "text": "that I've been telling\nyou, in roughly, in essentially a 20\ndimensional space. So there's 20 dimensions. We think we infer that\nhumans are projecting",
    "start": "1918230",
    "end": "1925190"
  },
  {
    "text": "to about 20 dimensions to\ndo these kind of, the tasks that we've shown here. Which is sort of\nsmaller, but eerily",
    "start": "1925190",
    "end": "1931309"
  },
  {
    "text": "close to that in the\norder of magnitude to that 100 or so features\nthat I've been talking about. So that's where-- regardless\nof whether-- these",
    "start": "1931310",
    "end": "1939020"
  },
  {
    "text": "are some of the dimensions\nand how we're projecting them. Again, I won't take\nyou through this, because I think we've\nalready used up enough time",
    "start": "1939020",
    "end": "1944490"
  },
  {
    "text": "and I want to get\non to this part. But we're trying to define\na domain of all tasks where we can sort\nof predict what",
    "start": "1944490",
    "end": "1949940"
  },
  {
    "text": "would happen across\nanything within that domain. And that raises questions of the\ndimensionality of that domain.",
    "start": "1949940",
    "end": "1955175"
  },
  {
    "text": "And there were behavioral\nmethods to do that. And we've been doing\nsome work on that. So I'll just leave it at that.",
    "start": "1955175",
    "end": "1960664"
  },
  {
    "text": "And if you guys\nhave questions, we can talk about that some more. I want to sort of\nin the time I really have left is to talk about\nthe encoding side of things,",
    "start": "1960664",
    "end": "1967910"
  },
  {
    "text": "because I promised you\nguys I would get to this. Unless people have\nany more burning questions on this decoding side. So far I've been\ntalking about the link",
    "start": "1967910",
    "end": "1973826"
  },
  {
    "text": "between IT and perception. Now I'm going to switch gears\nand talk about this other side. Which is, so I\ntalked about this.",
    "start": "1973826",
    "end": "1979310"
  },
  {
    "text": "And that tells us that\nthe mean rates in IT are something that seem\nto be highly predictive. I showed you at\nleast one model that",
    "start": "1979310",
    "end": "1985130"
  },
  {
    "text": "has the laws of RAD IT model. But now, it's like now, we\ncan turn to the encoding side and say, we need to predict\nthe mean rates of IT.",
    "start": "1985130",
    "end": "1991677"
  },
  {
    "text": "And that should be our goal\nif we want to explain images to IT activity. So, these would be called\npredictive encoding mechanisms.",
    "start": "1991677",
    "end": "1998940"
  },
  {
    "text": "So, now you guys\nhave heard about deep convolutional networks. If not, you've heard\nabout them already,",
    "start": "1998940",
    "end": "2004660"
  },
  {
    "text": "you'll probably hear\nabout them some more. So we started messing\naround in 2008. This is a model inspired--",
    "start": "2004660",
    "end": "2009850"
  },
  {
    "text": "I mentioned this family\nof models before. Hubel-Wiesel, Fukushima, and\nthere's a whole HMAX family of models, that really was the\ninspiration of this larger--",
    "start": "2009850",
    "end": "2018030"
  },
  {
    "text": "this large family\nof models, that have this repeating\nstructure that are now",
    "start": "2018030",
    "end": "2023939"
  },
  {
    "text": "really the sort of modern\nday deep convolution networks really grew out of all\nof this earlier work. And so we started exploring\nthe family in 2008.",
    "start": "2023939",
    "end": "2031600"
  },
  {
    "text": "And just, this is a slide that\nyou've already sort of seen a version of this from\nGabriel where you know, for when you take an\nimage, you pass it",
    "start": "2031600",
    "end": "2038125"
  },
  {
    "text": "through a set of operators. So you have filters. So these are dot products\nover some restricted spatial restricted region,\nlike receptive fields.",
    "start": "2038125",
    "end": "2045549"
  },
  {
    "text": "You have a non linear area, like\na threshold and a saturation. You have pooling operation. Then you have a normalization.",
    "start": "2045550",
    "end": "2051408"
  },
  {
    "text": "So you have all these\noperations happen here. And that produces a stack. So think of like, if there\nare four filters here,",
    "start": "2051409",
    "end": "2056969"
  },
  {
    "text": "like four orientations,\nyou get four images, you have one image in,\nyou have four images out. But if you had 10 of these,\nyou'd get 10 of these out.",
    "start": "2056969",
    "end": "2063638"
  },
  {
    "text": "Then you repeat\nthis here, right? And so as you keep\nadding more filters, this stack just keeps\ngetting bigger and bigger.",
    "start": "2063638",
    "end": "2068749"
  },
  {
    "text": "And it keeps, because\nyou're spatially pooling, it keeps getting narrower\nand narrower, right? So you go from this\nimage to this sort",
    "start": "2068749",
    "end": "2074544"
  },
  {
    "text": "of deep stack of features\nthat has less retinatopy. It still has a little\nbit of retinotopy.",
    "start": "2074544",
    "end": "2080129"
  },
  {
    "text": "And that, you can see, has\nbeen exactly a very good model why people liked\nit of how people think about the ventral stream.",
    "start": "2080130",
    "end": "2086309"
  },
  {
    "text": "So these models\ntypically have thousands of feat-- visual neurons or\nfeatures at the top level.",
    "start": "2086310",
    "end": "2092010"
  },
  {
    "text": "Just to give you a sense of\nscale of how they're run. And just to take\nyou through, you",
    "start": "2092010",
    "end": "2097209"
  },
  {
    "text": "know, I guess maybe\nyou'll hear about this, if you haven't already. Each element has like, a\nfilter, has a large fan in.",
    "start": "2097209",
    "end": "2102900"
  },
  {
    "text": "Like these are like\nneuroscience related things. They have non-linearities,\nlike thresholds of neurons.",
    "start": "2102900",
    "end": "2108460"
  },
  {
    "text": "Each layer is\nconvolutional, which means you apply the same\nfilters across visual space. Which is like retinotopy,\nthat is a view on cell that",
    "start": "2108460",
    "end": "2115170"
  },
  {
    "text": "is oriented here. There'll be another\nview on cell that's in another spatial\nposition, same orientation, different spatial position.",
    "start": "2115170",
    "end": "2121079"
  },
  {
    "text": "That's what the\nconvolutional models are just an implementation of that idea\nof copying the same filter",
    "start": "2121080",
    "end": "2126810"
  },
  {
    "text": "type across the retina. And there's a deep\nstack of layers. These are all\nthings that I think are commensurate with\nthe ventral stream",
    "start": "2126810",
    "end": "2134610"
  },
  {
    "text": "anatomy and physiology. So, but one of the\nkey things that those who work with these\nmodels know is",
    "start": "2134610",
    "end": "2140790"
  },
  {
    "text": "that, they have lots\nof unknown parameters that are not determined\nfrom the neurobiology. Even though the family of\nmodels is well described,",
    "start": "2140790",
    "end": "2147750"
  },
  {
    "text": "what are the exact\nfilter weights? What are the\nthreshold parameters? How exactly do you pool?",
    "start": "2147750",
    "end": "2153090"
  },
  {
    "text": "How do you normalize? There's lots of parameters\nwhen you build these things, essentially thousands of\nparameters, most of them hidden",
    "start": "2153090",
    "end": "2159090"
  },
  {
    "text": "in the weight structure here. Which, if you think about,\nthe first layer, that would be like, should\nI choose Gabor filters?",
    "start": "2159090",
    "end": "2164190"
  },
  {
    "text": "Or should I do some other--\nyou know Haim was talking about random weights, right? So there's choices there. There are lots of parameters. So the upshot is, there's\na big-- that's why",
    "start": "2164190",
    "end": "2171410"
  },
  {
    "text": "I call it a family of models. And how do you choose which one\nis the right one, so to speak?",
    "start": "2171410",
    "end": "2176560"
  },
  {
    "text": "Or is there a right one? Or maybe the whole\nfamily is wrong, right? These are the\ninteresting discussions.",
    "start": "2176560",
    "end": "2181680"
  },
  {
    "text": "So, what I like about it is,\nat least when you set it, it's a model. It makes predictions. And then you can test it.",
    "start": "2181680",
    "end": "2187161"
  },
  {
    "text": "So it's at least a model. And it predicts the\nentire-- you know, if you start to map these, you\nsay this is V1, this is V2,",
    "start": "2187161",
    "end": "2193560"
  },
  {
    "text": "this is V4. It predicts the full\nneural population response to any image across these areas.",
    "start": "2193560",
    "end": "2199380"
  },
  {
    "text": "So it's a strongly\npredictive model once built. So that's nice. But now you have to determine\nhow am I going to build it?",
    "start": "2199380",
    "end": "2206550"
  },
  {
    "text": "How do I set the parameters? So how do we do that? Well, there's lots of\nways you could do it.",
    "start": "2206550",
    "end": "2211920"
  },
  {
    "text": "And I'll tell you the\nway we chose to do it. Which was to just not\nuse any neural data. It was just to use\noptimization methods",
    "start": "2211920",
    "end": "2218370"
  },
  {
    "text": "to find specific models\nto set the parameters inside this model class. And we chose an\noptimization target.",
    "start": "2218370",
    "end": "2224923"
  },
  {
    "text": "This is a little bit, again,\ninspired from a top down view of what the system's doing. What are the visual\ntasks that we",
    "start": "2224924",
    "end": "2230520"
  },
  {
    "text": "suppose the ventral stream\nwas supposed to solve? Which I already told you, we\nthink it's invariant object recognition.",
    "start": "2230520",
    "end": "2235950"
  },
  {
    "text": "That's what makes\nthe problem hard. So we tried to optimize\nmodels to solve that. And essentially when\nwe're doing that,",
    "start": "2235950",
    "end": "2241058"
  },
  {
    "text": "we're kind of doing the same\nthing that computer vision is trying to do, except we're doing\nit in our own domain of images",
    "start": "2241058",
    "end": "2246164"
  },
  {
    "text": "and tasks that we set up. But we essentially, there's a\nmeeting between computer vision and what we were\ntrying to do here.",
    "start": "2246164",
    "end": "2252240"
  },
  {
    "text": "And when I say we, this\nis work by Dan Yamins, a post-doc in the lab, and\nHa Hong, a graduate student.",
    "start": "2252240",
    "end": "2257520"
  },
  {
    "text": "And what we did was to\njust try to simulate again, as I did earlier. We took these\nsimple 3-D objects.",
    "start": "2257520",
    "end": "2263048"
  },
  {
    "text": "We could render\nthem, just as before, place them on\nnaturalistic background. And then we just\nbuilt models that",
    "start": "2263049",
    "end": "2268380"
  },
  {
    "text": "would try to discriminate\nbodies from buildings from flowers from guns. So they would have\ngood feature sets that would discriminate\nbetween these things.",
    "start": "2268380",
    "end": "2274950"
  },
  {
    "text": "And these were essentially\ntrained by various forms of supervision. Now there's lots of ways\nyou can train these models.",
    "start": "2274950",
    "end": "2282240"
  },
  {
    "text": "I could tell you\nabout how we did it and how others have done it. I think those details\nare beyond what I want to talk about today.",
    "start": "2282240",
    "end": "2287670"
  },
  {
    "text": "But just, it's a\nsupervised class that's probably not\nlearned in the same way that the brain has learned.",
    "start": "2287670",
    "end": "2293280"
  },
  {
    "text": "Most people don't think so. But the interesting\nthing is the end state of these models might look very\nmuch like the current adult",
    "start": "2293280",
    "end": "2299659"
  },
  {
    "text": "state of the brain. And that's what I want\nto try to tell you next. So first, let me show you that\nwhen we built these models, this was in 2012.",
    "start": "2299659",
    "end": "2305280"
  },
  {
    "text": "We had a particular\noptimization approach that we called HMO\nthat was trying to solve these kind of problems\nthat I showed you earlier",
    "start": "2305280",
    "end": "2311550"
  },
  {
    "text": "on these kind of images. And I showed you IT was\npretty good with humans. I showed you its performance\nwas almost up to humans, even",
    "start": "2311550",
    "end": "2317520"
  },
  {
    "text": "with just 168 samples. And when we first\nbuilt a model here, we were able to do\nmuch better than some",
    "start": "2317520",
    "end": "2322586"
  },
  {
    "text": "of our previous models that-- on these same kind of tasks. So I told you we\nconstructed, because we",
    "start": "2322586",
    "end": "2327796"
  },
  {
    "text": "knew it made these things-- we made these models\nnot do so well. So we built these\nhigh invariance tasks",
    "start": "2327796",
    "end": "2333390"
  },
  {
    "text": "to push these models down. And then we had space\nto build a model that we could do better on.",
    "start": "2333390",
    "end": "2339050"
  },
  {
    "text": "And we called it HMO 1.0. And then we started\nto say, now we have this model that has been\noptimized for performance.",
    "start": "2339050",
    "end": "2346560"
  },
  {
    "text": "Let's see how well it does\non comparing with neurons. Let's see if its internals\nlook like the neural data.",
    "start": "2346560",
    "end": "2352539"
  },
  {
    "text": "So here's the model\nwe built, HMO 1.0. It's a deep\nconvolutional network. It has two different levels. It had four levels.",
    "start": "2352540",
    "end": "2358140"
  },
  {
    "text": "It had a bunch of parameters\nthat we set by optimization, that I'm just telling you\nkind of what we optimized. I didn't tell you--",
    "start": "2358140",
    "end": "2363481"
  },
  {
    "text": "I'm not telling you\nany of the parameters. And now, we come back\nto say, well look. We can show the same\nimages to the model that we showed to the neurons.",
    "start": "2363481",
    "end": "2369550"
  },
  {
    "text": "And then we can compare how\nwell these populations look like that population, or this\npopulation looks like that.",
    "start": "2369550",
    "end": "2375830"
  },
  {
    "text": "And so what we did was, we asked\nhow well can layer four predict IT first? That was the first\nthing we wanted",
    "start": "2375830",
    "end": "2380940"
  },
  {
    "text": "to do, take the top\nlayer of this model, the last layer before the\nlinear readout of this model.",
    "start": "2380940",
    "end": "2386851"
  },
  {
    "text": "And to do that, you might sort\nof say, well, wait a minute. The model doesn't have mappings. It has sort of neurons simulated\nhere, neuron 12 or something.",
    "start": "2386852",
    "end": "2394680"
  },
  {
    "text": "And there's some\nneuron we recorded. But there's no linkage between\nthat neuron and that neuron, right? You have to make that map.",
    "start": "2394680",
    "end": "2401320"
  },
  {
    "text": "So what we do is we\ntake each IT neuron and treat this as sort\nof a generative space. You can generate as many\nsimulated IT neurons",
    "start": "2401320",
    "end": "2407940"
  },
  {
    "text": "as you want. You would just ask,\nlet's take this neuron, take some of its data, and try\nto build a linear regression",
    "start": "2407940",
    "end": "2413640"
  },
  {
    "text": "to this neuron. Treat this as a basis\nto explain that neuron. And then test the predictive\npower on the held out IT data.",
    "start": "2413640",
    "end": "2419945"
  },
  {
    "text": "And that's what\nI'm writing here. That's cross-validation\nlinear regression. So I'm going to show you\npredictions on held out data",
    "start": "2419946",
    "end": "2425849"
  },
  {
    "text": "where some of the data were\nused to make the mapping. And there's lots\nof ways we chose--",
    "start": "2425850",
    "end": "2431216"
  },
  {
    "text": "we could make the mapping. And we did essentially\nall of them. And I could talk about\nthat if you want. But that's this central idea.",
    "start": "2431217",
    "end": "2437130"
  },
  {
    "text": "Take some of your data, say,\nis this in the linear space spanned by this basis set? So I can I fit that well\nwith this linear basis here?",
    "start": "2437130",
    "end": "2444890"
  },
  {
    "text": "As a linear map from this basis? And here's what we actually--\nhere's what it looks like. Here's the IT neural response\nof one simulated-- one actual IT",
    "start": "2444890",
    "end": "2453470"
  },
  {
    "text": "neuron in black. This is not time. These are images. I think there's like\n1,600 images here.",
    "start": "2453470",
    "end": "2459174"
  },
  {
    "text": "So each black going up and\ndown, you can barely see, is the response, the mean\nresponse, to different images.",
    "start": "2459174",
    "end": "2464370"
  },
  {
    "text": "And you see we grouped them\nby categories, just so, just to help you kind\nof understand the data.",
    "start": "2464370",
    "end": "2469780"
  },
  {
    "text": "Otherwise, it'd\njust be a big mess. Because IT neurons\ndo-- you can kind of see they have a bit of\ncategory selectivity.",
    "start": "2469780",
    "end": "2475410"
  },
  {
    "text": "And again, this was known. This neuron seems to like\nchair images, but not all chair images. It sometimes likes boats and\nsome planes a little bit.",
    "start": "2475410",
    "end": "2483060"
  },
  {
    "text": "And the red line is the\nprediction of the model, once fit to part of\nthe-- to this neuron. This is the prediction on the\nheld out data for the neuron.",
    "start": "2483060",
    "end": "2490500"
  },
  {
    "text": "You can see the R\nsquared is 0.48. So half the explainable\nresponse variance is explained by this model.",
    "start": "2490500",
    "end": "2497049"
  },
  {
    "text": "And again, these\nare predictions. The images were never seen-- the objects even were\nnever seen by this model",
    "start": "2497050",
    "end": "2504360"
  },
  {
    "text": "before it makes these\npredictions here. So this is just saying that the\nIT neurons live in this space.",
    "start": "2504360",
    "end": "2510810"
  },
  {
    "text": "It's actually quite well\ncaptured by the top level, in this case, of this\nfirst HMO model we built. I'll show you some other\nmodels in a minute.",
    "start": "2510810",
    "end": "2517480"
  },
  {
    "text": "Here's another neuron\nthat you might call a face neuron because it tends to like\nfaces over other categories.",
    "start": "2517480",
    "end": "2522840"
  },
  {
    "text": "So it might-- it\nwould pass the test of the operational\ndefinition of a face neuron. This model, this neuron\nwas well predicted, again,",
    "start": "2522840",
    "end": "2529615"
  },
  {
    "text": "by both its preferred and\nnon-preferred face images by this HMO model. Again, a slightly--\nan R squared near 0.5.",
    "start": "2529615",
    "end": "2536756"
  },
  {
    "text": "Here's a neuron that you would\nlook at the category structure. And you don't even-- you can't really see\nthe categories here.",
    "start": "2536757",
    "end": "2542040"
  },
  {
    "text": "They're still here. But you don't see\nthese sort of blocks. You just see there's sort of\nsome images it likes and some",
    "start": "2542040",
    "end": "2547050"
  },
  {
    "text": "it doesn't. It's hard to even know\nwhat's driving this neuron. But it's actually quite\nwell predicted, I think. You don't have the R squared.",
    "start": "2547050",
    "end": "2552930"
  },
  {
    "text": "But it's similar. It's about half the\nexplainable variance. Just another example. And here is a sort\nof summary here.",
    "start": "2552930",
    "end": "2559140"
  },
  {
    "text": "If you take-- this\nis a distribution of the explainable variance\nfor the top level of the model fitting about, I think\nthis is 168 IT sites.",
    "start": "2559140",
    "end": "2566850"
  },
  {
    "text": "Some sites are fit\nreally well, near 100%. Some are fit not as well. The average is about\n50%, which is shown here.",
    "start": "2566850",
    "end": "2573039"
  },
  {
    "text": "So this is the median of\nthat distribution here. So the summary take\nhome is about 50%",
    "start": "2573040",
    "end": "2578400"
  },
  {
    "text": "of singularly response\nvariance predicted. And this is a big improvement\nover previous models I'll show you in a minute.",
    "start": "2578400",
    "end": "2583600"
  },
  {
    "text": "The other levels of the model\ndon't predict nearly well. So the first level\ndoesn't predict well. Second level better,\nthird level better,",
    "start": "2583600",
    "end": "2589216"
  },
  {
    "text": "the fourth level the best. If you take other models-- these\nare some of the models I showed you earlier-- they don't fit nearly as well.",
    "start": "2589216",
    "end": "2596109"
  },
  {
    "text": "Here's their distributions\nand here's their average, their median explained variance. And just to fix-- to just\nfix ideas, you might think,",
    "start": "2596110",
    "end": "2604119"
  },
  {
    "text": "well look, we built a model\nthat's a good categorizer. So of course it fits\nIT neurons well. Because IT neurons\nare categorizers.",
    "start": "2604120",
    "end": "2610260"
  },
  {
    "text": "Well, here's a model that\nactually has explicit knowledge of the category. It's not an image\ncomputable model, and it's not an easy one.",
    "start": "2610260",
    "end": "2616589"
  },
  {
    "text": "But it's just given\nthat sort of an oracle that's given the category,\nand how well it explains IT. And you can see, it\nexplains IT much worse",
    "start": "2616590",
    "end": "2623490"
  },
  {
    "text": "than the actual model. So this implies a model\nis limited by the real-- the architecture puts\nconstraints on the model",
    "start": "2623490",
    "end": "2630569"
  },
  {
    "text": "and how it adds variance\nthat the sustained IT neurons are categories\ndoes not easily capture.",
    "start": "2630570",
    "end": "2636290"
  },
  {
    "text": "So that kind of-- that sort of inspired\nus to say, OK.",
    "start": "2636290",
    "end": "2642836"
  },
  {
    "text": "What about if we go down\nand say not just IT, but let's go to V4. Because we had a\nbunch of V4 data. And so we play the\nsame game in V4.",
    "start": "2642836",
    "end": "2649280"
  },
  {
    "text": "Let's take level three and\nsee if we can predict V4. And here's the IT data I\njust showed you a minute ago.",
    "start": "2649280",
    "end": "2654710"
  },
  {
    "text": "And here's the V4 data. So the V4 neurons are highly\npredicted in the middle layer. Layer three is the\nbest predictor of V4.",
    "start": "2654710",
    "end": "2661700"
  },
  {
    "text": "The top layer is actually not\nso predictive, less predictive of V4 neurons than\nthe middle layers. And the first layer is\nnot so well predictive.",
    "start": "2661700",
    "end": "2668580"
  },
  {
    "text": "And again, the other\nmodels are actually, now you can see they're\ngetting on relatively better. You can think of them as\nsort of lower level models.",
    "start": "2668580",
    "end": "2675740"
  },
  {
    "text": "And they're getting better,\nwhich is what you'd expect. But interestingly, this\nis really exciting to us.",
    "start": "2675740",
    "end": "2681230"
  },
  {
    "text": "Because look, this\nmodel was not optimized to fit any neural data other\nthan that last mapping step.",
    "start": "2681230",
    "end": "2687200"
  },
  {
    "text": "All it is is a bio\ninspired algorithm class, which is the\nneuroscience sort of view of the feed-forward\nclass of the field.",
    "start": "2687200",
    "end": "2694550"
  },
  {
    "text": "And tasks that we and\nothers hypothesize are important, that\nthe ventral stream might be optimized to solve,\nand an actual optimization",
    "start": "2694550",
    "end": "2701810"
  },
  {
    "text": "procedure that we applied. And that leads to neural like\nencoding functions at the top",
    "start": "2701810",
    "end": "2707000"
  },
  {
    "text": "and in the middle layer. So you don't-- so this sort\nof leads to funny things like saying, what does V4 do?",
    "start": "2707000",
    "end": "2713150"
  },
  {
    "text": "The answer here\nwould be, well, it's an intermediate layer\nin a network built to optimize these things.",
    "start": "2713150",
    "end": "2718410"
  },
  {
    "text": "That's the way to\ndescribe what V4 does, according to this\nkind of modeling approach. Now I want to point\nout, this is only half",
    "start": "2718410",
    "end": "2724880"
  },
  {
    "text": "of the explainable variance. So it's far from perfect. There's room to improve here. But it's really dramatic how\nmuch improvement we got out",
    "start": "2724880",
    "end": "2730793"
  },
  {
    "text": "of these kind of models. And so if you take\nthis sort of-- well, I'll skip this.",
    "start": "2730793",
    "end": "2735869"
  },
  {
    "text": "If you take this back to\nyou know, big picture, what did we do here? What we're doing is\nwe have performance",
    "start": "2735870",
    "end": "2741710"
  },
  {
    "text": "of a model on high end\nvariance recognition tasks. We're saying, this is what\nwe've been trying to optimize. And what we noticed\nis that if you",
    "start": "2741710",
    "end": "2747890"
  },
  {
    "text": "plot-- these dots are samples\nout of that model family. These black dots are\nother models I showed you. So they're control models that\nwere in the field at the time.",
    "start": "2747890",
    "end": "2755600"
  },
  {
    "text": "And this is the\nability of the top-- the model-- the top level\nof any of the models to predict IT responses.",
    "start": "2755600",
    "end": "2761120"
  },
  {
    "text": "So, you know, how good\nthey are predicting-- this is sort of the median\nvariance explained of single IT",
    "start": "2761120",
    "end": "2766160"
  },
  {
    "text": "responses. And you see there's\na correlation here. If you're better at this, you're\nbetter at predicting that. And all we did was\noptimize this way,",
    "start": "2766160",
    "end": "2773278"
  },
  {
    "text": "which we think of as like,\nevolution or development. So we're not\nfitting neural data. We're just optimizing\nfor task performance.",
    "start": "2773279",
    "end": "2779180"
  },
  {
    "text": "And that led in 2012 to a\nmodel that I just showed you, explained about half of\nthe IT response variance.",
    "start": "2779180",
    "end": "2784277"
  },
  {
    "text": "OK, so it's like, well,\nthis looks like it's continuing up this way. OK so if you believe that\nstory, then, that says,",
    "start": "2784277",
    "end": "2791930"
  },
  {
    "text": "if we can optimize further\non these kind of tasks, maybe we can explain\nmore variance.",
    "start": "2791930",
    "end": "2797649"
  },
  {
    "text": "And it turned out,\nwe didn't actually need to do that,\nbecause again, I said, computer vision was\nalready working on this.",
    "start": "2797649",
    "end": "2803804"
  },
  {
    "text": "And they got a lot\nmore resources. They're already doing it. They're already better\nthan us on this. So here's our HMO model.",
    "start": "2803804",
    "end": "2809137"
  },
  {
    "text": "This is now Charles Cadieu,\na post-doc in the lab. These were models that\ncame out at the time. This is Krizhevski\net al. supervision.",
    "start": "2809137",
    "end": "2814183"
  },
  {
    "text": "It's ICLR 2013. They were better than the\nmodel that we had built. You know, we were in this\nrestricted image domain,",
    "start": "2814183",
    "end": "2820370"
  },
  {
    "text": "you know, there's\nlots of reasons why we could say they're better. Regardless, they were better at\nour own tasks than the models",
    "start": "2820370",
    "end": "2826070"
  },
  {
    "text": "that we had built, right? So they were already\nahead of us on the task that we had designed. And so they were up here,\nand then they were up here.",
    "start": "2826070",
    "end": "2833199"
  },
  {
    "text": "And so, if you follow\nthat prediction, that means these models\nmight be better predictors of our neural data, right? These guys don't\nhave our neural data.",
    "start": "2833199",
    "end": "2839240"
  },
  {
    "text": "All they're doing is building\nmodels to optimize performance on tasks. And but we could take their\nfeatures from the neural data,",
    "start": "2839240",
    "end": "2844970"
  },
  {
    "text": "play the same game. And we actually explained\nour response-- data better than our model\nexplained our own data.",
    "start": "2844970",
    "end": "2851060"
  },
  {
    "text": "So this is a nice statement\nthat is not even in our own lab. Just a continued optimization\nfor those kinds of tasks",
    "start": "2851060",
    "end": "2856980"
  },
  {
    "text": "leads to features that are good\npredictors of the IT responses. And that's what's shown here.",
    "start": "2856980",
    "end": "2862559"
  },
  {
    "text": "So I think that's what\nI just said there. So, Charles took this\nfurther and analyzed",
    "start": "2862560",
    "end": "2869119"
  },
  {
    "text": "this in more detail. This is a summary of what I\npresented in the second half now, showing that IT firing\nrates are feature based,",
    "start": "2869120",
    "end": "2876079"
  },
  {
    "text": "learned object judgments\nnaturally predict human monkey performance. This is why the laws of RAD IT. I picked a particular\nmodel, which",
    "start": "2876080",
    "end": "2882530"
  },
  {
    "text": "is 100 millisecond read on this\ntime window, 50,000 neurons. 100 training examples. That's one particular choice of\na decode model, that's just a--",
    "start": "2882530",
    "end": "2892220"
  },
  {
    "text": "is a current set of decode model\nthat fits a lot of our data,",
    "start": "2892220",
    "end": "2897230"
  },
  {
    "text": "but not all of our data. And we also want to\nget finer grain data. The inference is, this might\nbe the specific neural code",
    "start": "2897230",
    "end": "2902960"
  },
  {
    "text": "and decoding mechanism\nthat the brain uses to support these tasks. That's what we'd like to think.",
    "start": "2902960",
    "end": "2908174"
  },
  {
    "text": "But now, we're trying to\ndo systematic causal tests. And we talked a lot about\ntrying to silence bits of IT as one example of that.",
    "start": "2908174",
    "end": "2913810"
  },
  {
    "text": "And the tools are still not\nwhere we'd like them to be. But you see we're\nmaking progress there.",
    "start": "2913810",
    "end": "2919800"
  },
  {
    "text": "So the second was I showed the\noptimization of deep CNN models for invariant object\nrecognition tasks led to dramatic improvements\nin our ability",
    "start": "2919800",
    "end": "2926420"
  },
  {
    "text": "to predict IT and V4 responses. I showed you our model HMO. But then the convolutional\nneural networks in the field",
    "start": "2926420",
    "end": "2931700"
  },
  {
    "text": "have already surpassed\nour predictive ability on our own data. And so the inference is that\nthese encoding mechanisms",
    "start": "2931700",
    "end": "2938570"
  },
  {
    "text": "in these models might\nbe similar to those that work in the ventral stream. And now, you know, there's\na whole sort of area",
    "start": "2938570",
    "end": "2944096"
  },
  {
    "text": "where you can start to\nthink about doing physiology on the models, so to speak. And that problem's\nalmost as hard as doing physiology\nexcept on the animal,",
    "start": "2944096",
    "end": "2950599"
  },
  {
    "text": "except that you can\ngain a lot more data. And so, and this is\nallowing the field to design experiments\nto explore what remains,",
    "start": "2950600",
    "end": "2957079"
  },
  {
    "text": "what's unique and powerful\nabout primate object perception. So within core\nobject recognition or perhaps having to\nextend out of that,",
    "start": "2957080",
    "end": "2963560"
  },
  {
    "text": "I think is now what\npeople are trying to do. So big picture in terms\nof us for the future,",
    "start": "2963560",
    "end": "2968570"
  },
  {
    "text": "I've talked about\nthis law's of RAD IT. Can we perturb here\nand get effects here that are predictable?",
    "start": "2968570",
    "end": "2973940"
  },
  {
    "text": "Can we predict for each\nimage, coding model, and for the optical\nmanipulations?",
    "start": "2973940",
    "end": "2979130"
  },
  {
    "text": "We talked about that. Dynamics and feedback\nare something that we're interested in. But I haven't talked\nmuch at all about.",
    "start": "2979130",
    "end": "2985310"
  },
  {
    "text": "I think that's a good\npoint, a discussion topic. I can tell you how\nwe're thinking about it.",
    "start": "2985310",
    "end": "2991160"
  },
  {
    "text": "We have some efforts\nin that regard. I talked on the encoding\nside about these kind",
    "start": "2991160",
    "end": "2996380"
  },
  {
    "text": "of deep convolutional\nnetworks that map from images. But the dash lines mean\nthey're only 50% predicted.",
    "start": "2996380",
    "end": "3001570"
  },
  {
    "text": "Both of these cases,\nthey're not perfect, right? So there's work\nto be done there. And one of the really\nexciting things",
    "start": "3001570",
    "end": "3007930"
  },
  {
    "text": "is here is how\nthese models learn. This supervised way of\nlearning these models is almost surely not what's\ngoing on in the brain.",
    "start": "3007930",
    "end": "3013480"
  },
  {
    "text": "So finding more-- less\nsupervised, biologically motivated learning\nof these models",
    "start": "3013480",
    "end": "3018880"
  },
  {
    "text": "is a good-- is the next step,\nI think, for much of the field. But what's nice is to\nhave an end state that",
    "start": "3018880",
    "end": "3024619"
  },
  {
    "text": "is much better than any previous\nend state we'd had before. So that sets a target of\nwhat success might look like.",
    "start": "3024620",
    "end": "3032079"
  },
  {
    "text": "And you know, maybe we\ncan think about expanding beyond core recognition. We can talk in the\nquestion period about that.",
    "start": "3032080",
    "end": "3037920"
  },
  {
    "text": "When is the right\ntime to kind of keep working within the domain\nof core recognition that is set up, versus\nexpanding beyond that?",
    "start": "3037920",
    "end": "3045042"
  },
  {
    "text": "Because there's lots\nof aspects of object recognition that I\ndidn't touch on here. And that comes up\nin the questions.",
    "start": "3045042",
    "end": "3050830"
  },
  {
    "text": "I think, there's lots of work\nto be done within the domain, but there's also\ninteresting directions that",
    "start": "3050830",
    "end": "3056589"
  },
  {
    "text": "extend outside of that domain. ",
    "start": "3056590",
    "end": "3079197"
  }
]
[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6120"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6120",
    "end": "12720"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "12720",
    "end": "18810"
  },
  {
    "text": " ANKIT MOHAN: Hello, everyone. I'm Ankit Mohan.",
    "start": "18810",
    "end": "23850"
  },
  {
    "text": "I'm a post-doc with Ramesh. And I'm sorry he's\nnot here today.",
    "start": "23850",
    "end": "29550"
  },
  {
    "text": "I'm going to be talking\nbriefly about what's called epsilon photography,\nor film-like photography.",
    "start": "29550",
    "end": "35460"
  },
  {
    "text": "It's actually how can we\nimprove film like photography. And I'm not sure what part--",
    "start": "35460",
    "end": "41820"
  },
  {
    "text": "some of this might be very\nstraightforward and obvious to many of you. So if it seems like I'm going\ntoo slow, please let me know.",
    "start": "41820",
    "end": "49650"
  },
  {
    "text": "Or if you want more detail\non any of these topics, again, stop me and\nask the question.",
    "start": "49650",
    "end": "56340"
  },
  {
    "start": "55000",
    "end": "77000"
  },
  {
    "text": "So before we can try to\nimprove film-like photography we should understand what I\nmean by film-like photography.",
    "start": "56340",
    "end": "62239"
  },
  {
    "text": "And this is basically what's\nbeen the camera obscura model, where you have a pinhole\nor a center of projection",
    "start": "62240",
    "end": "69780"
  },
  {
    "text": "and you have rays of light\nthat goes through that point and form an image on the\nsensor or a film plane.",
    "start": "69780",
    "end": "76159"
  },
  {
    "text": " So what you see over here is-- on the left, this\nis traditionally",
    "start": "76160",
    "end": "82610"
  },
  {
    "start": "77000",
    "end": "126000"
  },
  {
    "text": "how you draw an\noptics ray diagram. You have the object of\nthe scene on the left. And rays always travel\nfrom left to right.",
    "start": "82610",
    "end": "89150"
  },
  {
    "text": "And there are people who\ndo hardcore optics who can get really annoyed if\nyou don't follow this model.",
    "start": "89150",
    "end": "94530"
  },
  {
    "text": "So it's always a good thing\nto go from left to right. So you have the\nscene on the left. You have a center\nof projection, which",
    "start": "94530",
    "end": "100993"
  },
  {
    "text": "is a pinhole, in this case. What I haven't shown\nhere is-- basically, you can imagine a box\nthat's surrounding",
    "start": "100993",
    "end": "107570"
  },
  {
    "text": "the central projection\nand the sensor. And only a single point\nallows light to go through.",
    "start": "107570",
    "end": "115910"
  },
  {
    "text": "What this gives us is a\nsingle ray from every point in the scene is allowed\nto go through the camera",
    "start": "115910",
    "end": "123750"
  },
  {
    "text": "and forms an image\non the sensor. Now, most objects around\nus are actually diffuse.",
    "start": "123750",
    "end": "130520"
  },
  {
    "start": "126000",
    "end": "172000"
  },
  {
    "text": "What that means is-- technically, it's\ncalled Lambertian. What that means is the rays-- when you have an internal\nlight coming on an object,",
    "start": "130520",
    "end": "138209"
  },
  {
    "text": "it reflects light\nin all directions. And most objects\nare diffuse, in that all the rays that come out\nof a point on the object",
    "start": "138210",
    "end": "145650"
  },
  {
    "text": "have roughly the same intensity,\nwhereas the other case would be a specular object,\nwhich reflects",
    "start": "145650",
    "end": "151520"
  },
  {
    "text": "light in primarily one direction\nand not in all directions. So because most\nobjects are diffuse,",
    "start": "151520",
    "end": "157610"
  },
  {
    "text": "when you have a pinhole\ncamera taking a photograph, it looks very similar to\nwhat it appears to the eye.",
    "start": "157610",
    "end": "163670"
  },
  {
    "text": "So it captures most\nof the information coming from the scene.",
    "start": "163670",
    "end": "169340"
  },
  {
    "text": "Now, what a lens does\nis slightly different,",
    "start": "169340",
    "end": "175709"
  },
  {
    "start": "172000",
    "end": "224000"
  },
  {
    "text": "is that it actually integrates\nover an angular exchange. So in this case over\nhere, you have rays coming",
    "start": "175710",
    "end": "182610"
  },
  {
    "text": "from a point in the scene. But not just one single ray\ngets imaged on the sensor. But you have a\nwhole cone of rays",
    "start": "182610",
    "end": "189090"
  },
  {
    "text": "that get imaged on the sensor. So in this case,\nall the rays coming from a point in the scene that\ngo through the lens aperture",
    "start": "189090",
    "end": "196830"
  },
  {
    "text": "get focused onto\nthe sensor plane. And this is basically\nhow a lens works",
    "start": "196830",
    "end": "203280"
  },
  {
    "text": "and how a camera,\nmodern camera works. Now, again, this is very\nstraightforward stuff.",
    "start": "203280",
    "end": "210000"
  },
  {
    "text": "But a lens obeys\ncertain properties, in that the ratio\nof the distances",
    "start": "210000",
    "end": "215340"
  },
  {
    "text": "has to obey certain properties. And what this\nbasically tells us-- and I'm going to skip\nover some of this stuff--",
    "start": "215340",
    "end": "224739"
  },
  {
    "start": "224000",
    "end": "353000"
  },
  {
    "text": "is-- this is, I think,\nthe most important thing. If you have a lens, then\nonly one plane in the scene",
    "start": "224740",
    "end": "231519"
  },
  {
    "text": "gets imaged onto\nthe sensor exactly. And there's a one-to-one\ncorrespondence",
    "start": "231520",
    "end": "237340"
  },
  {
    "text": "between which scene is\ngoing to get imaged based on the focal length and the\ndistance between the lens",
    "start": "237340",
    "end": "242920"
  },
  {
    "text": "and the sensor. This was not the case\nif it were a pinhole. In the case of a pinhole,\neverything appears in focus.",
    "start": "242920",
    "end": "249260"
  },
  {
    "text": "And you have what's called\nan infinite depth of field. So unlike a pinhole\ncamera, a camera",
    "start": "249260",
    "end": "256600"
  },
  {
    "text": "with a finite\naperture lens actually has a finite depth of field. Now, depth of field has\nan interesting definition.",
    "start": "256600",
    "end": "263680"
  },
  {
    "text": "If you look it up in\nWikipedia, in the case",
    "start": "263680",
    "end": "268720"
  },
  {
    "text": "of film-based\nphotography, it was defined that as when you\ntake a picture of a scene and you print the picture\nat a certain resolution--",
    "start": "268720",
    "end": "275860"
  },
  {
    "text": "at a certain size\npaper, and then a standard human observer stands\nsome finite distance from it,",
    "start": "275860",
    "end": "282550"
  },
  {
    "text": "can he or she has a\ndifference between two points, whether it's one is in\nfocus or not in focus?",
    "start": "282550",
    "end": "287860"
  },
  {
    "text": "So based on that and certain\nperceptual tests that they did, they came up with\nthis definition",
    "start": "287860",
    "end": "293050"
  },
  {
    "text": "of how far you can get\nfrom the plane that's going to be in perfect\nfocus and still",
    "start": "293050",
    "end": "299410"
  },
  {
    "text": "give the appearance to a viewer\nthat the plane is in focus. So in the case of the\ndigital camera, what",
    "start": "299410",
    "end": "307539"
  },
  {
    "text": "it roughly translates\nto is that when you go away from the plane of\nfocus, you are going to get--",
    "start": "307540",
    "end": "314050"
  },
  {
    "text": "if you look over\nhere, you're not-- rays are not going\nto focus to a point, but they're going to\ncreate a test-like blur.",
    "start": "314050",
    "end": "320319"
  },
  {
    "text": "And if the size of this just\nlike blur is smaller than the size of a pixel, usually\nyou cannot tell the difference",
    "start": "320320",
    "end": "325840"
  },
  {
    "text": "between whether it's in\nfocus or out of focus. So there is this finite\nregion around a plane of focus",
    "start": "325840",
    "end": "331090"
  },
  {
    "text": "that's called the\ndepth of focus. And it's actually--\nit's not symmetric. It's usually greater\nbehind the plane of focus",
    "start": "331090",
    "end": "340070"
  },
  {
    "text": "and smaller in front. And there's a\ncorresponding depth",
    "start": "340070",
    "end": "345250"
  },
  {
    "text": "of field on the sensor side. So are there any\nquestions about that?",
    "start": "345250",
    "end": "350530"
  },
  {
    "text": "Is this obvious stuff? What's interesting is that the\nsize of this depth of field",
    "start": "350530",
    "end": "358460"
  },
  {
    "start": "353000",
    "end": "454000"
  },
  {
    "text": "depends on the side\nof the aperture. So in the case when we had a\npinhole where our aperture size was infinitely small, the\nsize of the depth of field",
    "start": "358460",
    "end": "366710"
  },
  {
    "text": "is infinitely large. So everything is in focus. But as we increase\nour aperture size-- like you can see from\nhere, we went up here.",
    "start": "366710",
    "end": "375919"
  },
  {
    "text": "The corresponding size--\nbecause these cone forms are much larger cone\nangle, the region",
    "start": "375920",
    "end": "382670"
  },
  {
    "text": "in which the size of\nthe blur would still be smaller than a pixel,\nit becomes smaller.",
    "start": "382670",
    "end": "388790"
  },
  {
    "text": "And you have a much\nshallower depth of field. So there's something\nthat photographers often use when they take\npictures, like portraits",
    "start": "388790",
    "end": "395750"
  },
  {
    "text": "or macro-photography, is\nthey try to open the aperture or keep the aperture\nas wide as possible.",
    "start": "395750",
    "end": "403110"
  },
  {
    "text": "And that results in a very\nshallow depth of field. So only the plane of\ninterest is in focus.",
    "start": "403110",
    "end": "408260"
  },
  {
    "text": "Anything behind and in front\nof it appears like a blur. It has a nice blurry appearance.",
    "start": "408260",
    "end": "415097"
  },
  {
    "text": "On the other hand, if\nyou're doing something like landscape\nphotography, you want the tree that's 10 meters\nfrom you to be in sharp focus",
    "start": "415097",
    "end": "421979"
  },
  {
    "text": "and also a mountain that's\nfive kilometers away to be in sharp focus. So usually, people use a\nsmaller aperture size in order",
    "start": "421980",
    "end": "428180"
  },
  {
    "text": "to get everything in focus. So we'll come back to\nthis a little later when I talk about how\nyou can computationally",
    "start": "428180",
    "end": "435950"
  },
  {
    "text": "modify the depth of field\nand things like that. But in general, it depends\non the application.",
    "start": "435950",
    "end": "443540"
  },
  {
    "text": "The application dictates\nwhat kind of depth of field you need. And most cameras\ngive the photographer an opportunity to set\nthe aperture size, which",
    "start": "443540",
    "end": "451160"
  },
  {
    "text": "sets the depth of field.  So because there is only a\nsingle plane in the scene which",
    "start": "451160",
    "end": "461210"
  },
  {
    "start": "454000",
    "end": "601000"
  },
  {
    "text": "is actually in sharp focus, if\nyou use a camera that does not have a pinhole aperture,\nwhich is most cameras,",
    "start": "461210",
    "end": "466699"
  },
  {
    "text": "you need to be able\nto select which plane you want to focus on. And that's usually done\nthese days using autofocus.",
    "start": "466700",
    "end": "474620"
  },
  {
    "text": "The cameras use different\ntechniques for autofocus. The most common one\nthese days in SLR cameras",
    "start": "474620",
    "end": "480380"
  },
  {
    "text": "is the space-based\nautofocus, which is a really interesting\ntechnique that I think was first proposed by Minolta\nway back in the late '70s.",
    "start": "480380",
    "end": "489169"
  },
  {
    "text": "And what they essentially do is\nthey form two separate images from the different-- so\nthis is I think likely",
    "start": "489170",
    "end": "496240"
  },
  {
    "text": "from the pattern. This is the main aperture\nof the main lens. And what they essentially\ndo is create a rangefinder,",
    "start": "496240",
    "end": "503840"
  },
  {
    "text": "where the baseline is equal\nto the diameter of the lens aperture.",
    "start": "503840",
    "end": "509030"
  },
  {
    "text": "What that means is essentially\ndoing stereo or creating one image from one corner of\nthe lens and another image",
    "start": "509030",
    "end": "515929"
  },
  {
    "text": "from the other\ncorner of the lens. And looking at those two images,\nif the scene is in focus, those two images are going\nto be exactly the same.",
    "start": "515929",
    "end": "522679"
  },
  {
    "text": "If it's not in focus, there's\ngoing to be a phase mismatch. And by observing\nthe phase mismatch,",
    "start": "522679",
    "end": "527750"
  },
  {
    "text": "you can determine which\ndirection the lens needs to move in\nand by how much. So it's a single-shot\nfocusing technique",
    "start": "527750",
    "end": "534410"
  },
  {
    "text": "where, by just getting\nthis one reading, you can move the lens\nin the right direction and get an in-focus scene.",
    "start": "534410",
    "end": "541100"
  },
  {
    "text": "And this is usually very\nfast because you don't have to constantly keep searching. And the downside is that you\nneed the special hardware",
    "start": "541100",
    "end": "549530"
  },
  {
    "text": "in your camera. And most SLR cameras have\nthis kind of hardware in them.",
    "start": "549530",
    "end": "555480"
  },
  {
    "text": "Another technique that most\npoint and shoot compact cameras use is contrast-based\nautofocus, where--",
    "start": "555480",
    "end": "562460"
  },
  {
    "text": "since you have a live view\ncoming from the sensor directly, you can\nlook at one frame.",
    "start": "562460",
    "end": "568770"
  },
  {
    "text": "And you can try to\nmaximize the contrast and move the lens back\nand forth until you",
    "start": "568770",
    "end": "574100"
  },
  {
    "text": "get the maximum contrast. And since you don't get an\nestimation of the phase, like the previous\ncase, you cannot--",
    "start": "574100",
    "end": "580610"
  },
  {
    "text": "it's not a\nsingle-shot operation. You have to usually search\nthrough the span of the focus",
    "start": "580610",
    "end": "586970"
  },
  {
    "text": "settings and find out which\none has a maximum contrast and stop over there. That's where it's in focus.",
    "start": "586970",
    "end": "593070"
  },
  {
    "text": "And it's usually slower\nthan the previous case, but you don't need dedicated\nhardware in order to do this.",
    "start": "593070",
    "end": "598610"
  },
  {
    "text": "And most compact\ncameras use this. Another technique that some of\nthe older film-based compact",
    "start": "598610",
    "end": "605720"
  },
  {
    "start": "601000",
    "end": "673000"
  },
  {
    "text": "cameras used was\nusing ultrasound or infrared-based estimation\nof how far a scene is.",
    "start": "605720",
    "end": "612860"
  },
  {
    "text": "And it's something that's\nnot very prevalent anymore. And it's also not very accurate.",
    "start": "612860",
    "end": "619018"
  },
  {
    "text": "Another technique that\nI don't mention here is what's called a\nrangefinder camera. And usually, that's a separate\nunit from the main camera.",
    "start": "619018",
    "end": "626060"
  },
  {
    "text": "The difference here\nis that this lens-- the autofocus occurs\nthrough the lens.",
    "start": "626060",
    "end": "632060"
  },
  {
    "text": "So what gets on\nthe image plane is what's used to determine\nwhether it's in focus or not",
    "start": "632060",
    "end": "637820"
  },
  {
    "text": "in both these cases. In the case of a\nrangefinder camera, there is a separate\nunit, which basically",
    "start": "637820",
    "end": "643459"
  },
  {
    "text": "does this shifting and trying\nto find when it's aligned. And it's usually done manually\nrather than automatically.",
    "start": "643460",
    "end": "651128"
  },
  {
    "text": "I think the important\npoint over here is there's lots of\nwork that's gone on even before computational\nphotography came into its being",
    "start": "651128",
    "end": "659450"
  },
  {
    "text": "in the area of trying to find\nvery quickly, and effectively, and repeatedly set the focus\nautomatically on a camera.",
    "start": "659450",
    "end": "667610"
  },
  {
    "text": "And there's lots of engineering\nthat's gone into that.",
    "start": "667610",
    "end": "673700"
  },
  {
    "start": "673000",
    "end": "899000"
  },
  {
    "text": "So focus was the first\nthing that a camera needs to worry about when\nit tries to take a picture.",
    "start": "673700",
    "end": "679110"
  },
  {
    "text": "The second thing is\nwhat's called exposure. And what I'm trying\nto show here is",
    "start": "679110",
    "end": "684500"
  },
  {
    "text": "that the brightness\nof something that's daylight versus something\nthat's dark is widely different.",
    "start": "684500",
    "end": "692570"
  },
  {
    "text": "And you have just 0 to\n255 8-bits or, at most, 12 bits or 14 bits\nto work with in order",
    "start": "692570",
    "end": "699980"
  },
  {
    "text": "to compress all of that\ninformation in there. And usually, this span or\nthe dynamic range does not--",
    "start": "699980",
    "end": "707280"
  },
  {
    "text": "it cannot go through\nmore than two, or three, or four decades at most.",
    "start": "707280",
    "end": "712950"
  },
  {
    "text": "And so what needs\nto be done is need to decide what exposure\nto use on a camera.",
    "start": "712950",
    "end": "718440"
  },
  {
    "text": "And so this is a scene\nthat goes underexposed versus overexposed. Overexposure means\nyou let too much",
    "start": "718440",
    "end": "725510"
  },
  {
    "text": "light into the camera\nversus underexposure, if there wasn't enough\nlight and the scene was-- the image was dark.",
    "start": "725510",
    "end": "730760"
  },
  {
    "text": "So exposure itself is comprised\nof these three things. One is aperture size--\nthe larger size,",
    "start": "730760",
    "end": "737550"
  },
  {
    "text": "more of the light coming\nin, and the brighter the image is going to be. The shutter speed, how long\nyou keep the shutter open for--",
    "start": "737550",
    "end": "745080"
  },
  {
    "text": "if you keep it open for\nlonger, you get more light in and the image is brighter. And the film sensitivity, the\nlight coming in, how many--",
    "start": "745080",
    "end": "753590"
  },
  {
    "text": "in the case of film,\nhow much chemical can it translate, can it\nchange or chemically modify?",
    "start": "753590",
    "end": "758960"
  },
  {
    "text": "In the case of your digital\nsensor, it's the digital-- it's the analog to ADC converter\ngain is what is set by the ISO.",
    "start": "758960",
    "end": "769145"
  },
  {
    "text": "So these three things together\ndetermine what the exposure should be on your camera.",
    "start": "769145",
    "end": "774899"
  },
  {
    "text": "So if you set a\ncertain shutter speed, you need to determine what\nthe corresponding aperture",
    "start": "774900",
    "end": "780170"
  },
  {
    "text": "size and the sensitivity\nshould be in order-- before you can take a picture. And once again,\nolder cameras require",
    "start": "780170",
    "end": "788530"
  },
  {
    "text": "you to do this manually. Usually, you would\nhave film, which was of a certain sensitivity. And you set an ISO 100 on it.",
    "start": "788530",
    "end": "795572"
  },
  {
    "text": "You would select\nthe aperture size. And then you would have to-- based on some of rule of thumb\nor using an exposure meter,",
    "start": "795572",
    "end": "802910"
  },
  {
    "text": "you would determine what\nthe shutter speed should be. So this was drastically\nchanged by Nikon in, I think,",
    "start": "802910",
    "end": "811459"
  },
  {
    "text": "mid or late '80s, where they\nproposed this Nikon Matrix Metering Scheme.",
    "start": "811460",
    "end": "817130"
  },
  {
    "text": "And the idea over\nhere is-- so this is what the SLR camera looks like. You have the main lens.",
    "start": "817130",
    "end": "822899"
  },
  {
    "text": "You have a mirror. The film plane is back here. The light coming in\ngets reflected up here",
    "start": "822900",
    "end": "828410"
  },
  {
    "text": "into the pentaprism. And inside the pentaprism,\nit bends, points, and it goes through\nthe viewfinder",
    "start": "828410",
    "end": "833660"
  },
  {
    "text": "into the viewer's eyes. But what happens here is another\nsmall mirror reflects it up",
    "start": "833660",
    "end": "839329"
  },
  {
    "text": "to the top, where\nthere are these-- there's these five-- I think\nyou have five different zones.",
    "start": "839330",
    "end": "846230"
  },
  {
    "text": "And they had a light meter\nat each of these zones, which was basically capturing how\nmany photons are coming in",
    "start": "846230",
    "end": "854600"
  },
  {
    "text": "at that zone. So even before the\npicture is taken, the camera knows how\nbright the scene is.",
    "start": "854600",
    "end": "860120"
  },
  {
    "text": "And based on that and\nbased on some heuristics that they came up\nwith, they determine what the correct exposure\nshould be for the given photo.",
    "start": "860120",
    "end": "868010"
  },
  {
    "text": "And this was supposed to be a\nvery revolutionary technique back then.",
    "start": "868010",
    "end": "873440"
  },
  {
    "text": "It did away with all the\nvarious rules of thumb that people had come up\nwith before this in order",
    "start": "873440",
    "end": "878720"
  },
  {
    "text": "to estimate a good exposure. And this is what\nled to the change",
    "start": "878720",
    "end": "883820"
  },
  {
    "text": "where you can just\nAuto mode on a camera. You can just press\nthe shutter release. And you don't have to worry\nabout either the focus",
    "start": "883820",
    "end": "889563"
  },
  {
    "text": "or the exposure. And once again, I come\nback to these things in the realm of computational\nphotography and computational",
    "start": "889563",
    "end": "896720"
  },
  {
    "text": "cameras in a bit.  The one last thing\nI want to touch on",
    "start": "896720",
    "end": "902840"
  },
  {
    "start": "899000",
    "end": "956000"
  },
  {
    "text": "is the concept of color\nin digital cameras. And most digital cameras have\nwhat's called a Bayer filter.",
    "start": "902840",
    "end": "910730"
  },
  {
    "text": "And it looks kind of like this. So adjacent pixels have\ndifferent colored filters",
    "start": "910730",
    "end": "917300"
  },
  {
    "text": "placed on top of them. And usually, there\nare two green filters for every red and blue filter.",
    "start": "917300",
    "end": "922790"
  },
  {
    "text": "And what this gives them-- so the image you get is this\ninterspersed blue channel,",
    "start": "922790",
    "end": "930680"
  },
  {
    "text": "red channel, and the green\nchannel on the same sensor. And then they use demosaicing\nor interpolation techniques",
    "start": "930680",
    "end": "937340"
  },
  {
    "text": "in order to recover a high\nresolution image in color. There are other sensors,\nsuch as the Foveon sensor,",
    "start": "937340",
    "end": "943550"
  },
  {
    "text": "which does this spinning in\ndepth rather than spatially. So for each pixel,\nthey get a red, green,",
    "start": "943550",
    "end": "951930"
  },
  {
    "text": "and blue color value. ",
    "start": "951930",
    "end": "957680"
  },
  {
    "start": "956000",
    "end": "1007000"
  },
  {
    "text": "One more thing over\nhere I wanted to say is that the electromagnetic\nspectrum that",
    "start": "957680",
    "end": "964459"
  },
  {
    "text": "ranges from radio\nwaves to gamma waves, it's only a very small\nportion that we are interested in for photography.",
    "start": "964460",
    "end": "970670"
  },
  {
    "text": "It's usually from 400\nto 700 nanometers. And this region gets\nactually split up",
    "start": "970670",
    "end": "977449"
  },
  {
    "text": "into these three channels,\nthe three color channels that you have-- red,\ngreen, and blue. But the only reason you\nhave these three channels",
    "start": "977450",
    "end": "984950"
  },
  {
    "text": "is because of the human eye,\nwhich also has a similar three channels. And cameras try to\nmimic the functioning",
    "start": "984950",
    "end": "991970"
  },
  {
    "text": "of the human eye in that sense. But if you look at\nmultispectral cameras--",
    "start": "991970",
    "end": "997550"
  },
  {
    "text": "and I think we'll come back\nto that in some other class-- you can have a whole number\nof channels between the 300--",
    "start": "997550",
    "end": "1003880"
  },
  {
    "text": "400 and 709 range. So this is the CIE\nChromaticity Diagram.",
    "start": "1003880",
    "end": "1011200"
  },
  {
    "start": "1007000",
    "end": "1096000"
  },
  {
    "text": "This is how the human eye\nvisually interprets color.",
    "start": "1011200",
    "end": "1016820"
  },
  {
    "text": "So what you have is--\nit's on an xy scale. And what you have on\nthe edges over here",
    "start": "1016820",
    "end": "1023920"
  },
  {
    "text": "are the pure colors, or\nthe color-- primary colors that correspond to pure\nwavelengths going from 380",
    "start": "1023920",
    "end": "1031420"
  },
  {
    "text": "or 400 to 700 nanometers. And so anything that\nlies outside here",
    "start": "1031420",
    "end": "1036459"
  },
  {
    "text": "is a pure color, just\na single wavelength. That's what a laser or\nsome LEDs would give you.",
    "start": "1036460",
    "end": "1041949"
  },
  {
    "text": "Anything within this is a\nmixture of various colors. And the interesting\nproperty of this color space",
    "start": "1041950",
    "end": "1048970"
  },
  {
    "text": "is that if you have any two\npoints on this color space and you mix those two colors\nin various proportions,",
    "start": "1048970",
    "end": "1055815"
  },
  {
    "text": "you're going to\nget a color which lies on the line that connects\nthose two points perceptually. And so if you have--",
    "start": "1055815",
    "end": "1063195"
  },
  {
    "text": "if you have a\ntriangle like this, which is a color space, the\nXRBG color space in this case, which is what most monitors\nand LCDs use, you would get--",
    "start": "1063196",
    "end": "1073210"
  },
  {
    "text": "if you have color primaries\nthat are at the three vertices and you mix those\ncolor primaries in various proportions,\nyou're going",
    "start": "1073210",
    "end": "1079510"
  },
  {
    "text": "to get a color\nwithin that triangle. And by simply varying the\n[? wave ?] of the three",
    "start": "1079510",
    "end": "1086080"
  },
  {
    "text": "primaries between 0 and 1, you\ncan go from completely white, which is in the center, to\none of the three colors.",
    "start": "1086080",
    "end": "1092725"
  },
  {
    "text": " And that's what the\ncolor response--",
    "start": "1092725",
    "end": "1100620"
  },
  {
    "start": "1096000",
    "end": "1325000"
  },
  {
    "text": "the curve for just the red,\ngreen, and blue color primary looks like for film and for\na typical digital sensor.",
    "start": "1100620",
    "end": "1109590"
  },
  {
    "text": "What's interesting to note\nis that even though we've advanced quite a bit\nfrom film to digital,",
    "start": "1109590",
    "end": "1117120"
  },
  {
    "text": "the basic technique\nstill remains the same. We still have the same\nthree color primaries. They look almost identical.",
    "start": "1117120",
    "end": "1123300"
  },
  {
    "text": "There's very little\ndifference between them. And that's one of the goals\nof computational photography,",
    "start": "1123300",
    "end": "1128790"
  },
  {
    "text": "is to do away with the\nfilm with the baggage that we still have\nassociated with film.",
    "start": "1128790",
    "end": "1136540"
  },
  {
    "text": "And part of this\nlecture is actually going to go in the\nother direction and say, how can\nwe improve on that?",
    "start": "1136540",
    "end": "1142655"
  },
  {
    "text": "So the rest of\nthe class is going to be more about\nhow can we get away from film, whereas\nthis class is more",
    "start": "1142655",
    "end": "1148140"
  },
  {
    "text": "on how can we improve on film. AUDIENCE: In the graph\nthat you have shown, it looks like the film has\nthe colors more orthogonal",
    "start": "1148140",
    "end": "1157080"
  },
  {
    "text": "being sensed rather\nthan the digital sensor. You see the blue is\nleaking into the green",
    "start": "1157080",
    "end": "1163442"
  },
  {
    "text": "and the red is leaking? But there, it seems\nit's-- in some sense, it's very less leakage.",
    "start": "1163442",
    "end": "1169620"
  },
  {
    "text": "ANKIT MOHAN: Yeah. AUDIENCE: Is it in general too? ANKIT MOHAN: I'm not sure, in\nthis case, why it's like that.",
    "start": "1169620",
    "end": "1176160"
  },
  {
    "text": "And also, note that\nthis is just one film which is optimized for\ncertain kinds of photography. I think Velvia is\nsupposed to be very",
    "start": "1176160",
    "end": "1182820"
  },
  {
    "text": "good for landscape photography,\nand sunsets, and those kind of things. And that's something that\nyou could do with film.",
    "start": "1182820",
    "end": "1189360"
  },
  {
    "text": "You could have a film that's\nsuited for a particular task and different-- has\ndifferent primaries, whereas for cameras, it has\nto be-- for digital sensors,",
    "start": "1189360",
    "end": "1197550"
  },
  {
    "text": "it has to be something\nthat goes across the board for different kinds of\nscenes and things like that.",
    "start": "1197550",
    "end": "1203110"
  },
  {
    "text": "So that could be the\nreason why it's like that. AUDIENCE: In the previous\nslide, [INAUDIBLE]",
    "start": "1203110",
    "end": "1208890"
  },
  {
    "text": "two green cubes, two\ngreen squares and only one for red and blue. ANKIT MOHAN: Yeah. AUDIENCE: Is that\nbecause the eye",
    "start": "1208890",
    "end": "1215245"
  },
  {
    "text": "is more sensitive towards\nthe green channel? ANKIT MOHAN: Yes,\nit's because when--",
    "start": "1215245",
    "end": "1220679"
  },
  {
    "text": "I think that's\nroughly the proportion of the cones in our eye also.",
    "start": "1220680",
    "end": "1225760"
  },
  {
    "text": "And green, if you look at\nthe value, v, the luminance,",
    "start": "1225760",
    "end": "1232875"
  },
  {
    "text": "chromaticity relationship\nbetween RGB and that, green is the one that has\nthe most corresponding-- most",
    "start": "1232875",
    "end": "1238770"
  },
  {
    "text": "weight. Yeah? AUDIENCE: [INAUDIBLE] You\nmentioned the film can",
    "start": "1238770",
    "end": "1245909"
  },
  {
    "text": "be more specific [INAUDIBLE]. ",
    "start": "1245910",
    "end": "1252390"
  },
  {
    "text": "Would it make sense-- would\nit be possible to actually have different kinds\nof sensors that would be specific for\ndifferent kinds of photography",
    "start": "1252390",
    "end": "1258360"
  },
  {
    "text": "in digital? ANKIT MOHAN: It's hard\nfor you to change sensors once you have a sensor\nand it's baked in.",
    "start": "1258360",
    "end": "1265529"
  },
  {
    "text": "AUDIENCE: Yeah, I mean, if\nwe could change the sensor-- ANKIT MOHAN: Yes, yes. And some of the stuff that,\nI guess, at some point we'll",
    "start": "1265530",
    "end": "1271193"
  },
  {
    "text": "talk about in this\ncourse is there has been work on how to make\nmore flexible digital sensors,",
    "start": "1271193",
    "end": "1277247"
  },
  {
    "text": "not just digital\nsensors, but making-- how do you make the whole\ncamera more flexible so you can programmatically\nchange those responses?",
    "start": "1277247",
    "end": "1284370"
  },
  {
    "text": "And you could do\nsomething of that sort. But it turns out that,\nfor most photography, it doesn't matter that much.",
    "start": "1284370",
    "end": "1290100"
  },
  {
    "text": "And just by doing\nthings in Photoshop, if you have enough\nbit depth over there, it doesn't matter too much.",
    "start": "1290100",
    "end": "1296380"
  },
  {
    "text": "But it does matter for\nthings like remote sensing, where you need-- even between 400 and 700,\nthere'll be 30 or 40--",
    "start": "1296380",
    "end": "1304559"
  },
  {
    "text": "they're divided into 30 or 40\ndifferent channels, which are almost completely orthogonal. And so going back to\nwhat you were saying,",
    "start": "1304560",
    "end": "1310980"
  },
  {
    "text": "if you look at the response\ncurve of the human eye, even that has a huge overlap. So it's actually quite\nsimilar to this one.",
    "start": "1310980",
    "end": "1317580"
  },
  {
    "text": "It's not [INAUDIBLE]. Any other questions? ",
    "start": "1317580",
    "end": "1326740"
  },
  {
    "start": "1325000",
    "end": "1395000"
  },
  {
    "text": "So that was a very\nquick overview of what I thought\nwould be useful",
    "start": "1326740",
    "end": "1332820"
  },
  {
    "text": "for you to know about film\nphotography in general. And what I'm going to talk\nabout during this class",
    "start": "1332820",
    "end": "1339180"
  },
  {
    "text": "is what's epsilon photography. And this is a term that--\nthis is a term that Ramesh",
    "start": "1339180",
    "end": "1344340"
  },
  {
    "text": "coined some time back. And the idea here is-- the goal of epsilon\nphotography is",
    "start": "1344340",
    "end": "1349950"
  },
  {
    "text": "to improve on film-based\nphotography, not to try and do something new, but just how\nto do what we could already",
    "start": "1349950",
    "end": "1355620"
  },
  {
    "text": "do with film, but do it better. And the way it's done\nin almost all cases is by taking multiple pictures\nor capturing more data.",
    "start": "1355620",
    "end": "1363330"
  },
  {
    "text": "So you capture multiple photos,\neach with slightly different camera parameters.",
    "start": "1363330",
    "end": "1368550"
  },
  {
    "text": "And usually, the\nparameters that you vary are the exposure settings, the\ncolor settings, the spectrum",
    "start": "1368550",
    "end": "1373560"
  },
  {
    "text": "settings, the focal settings,\nthe camera position, and the direction in\nwhich it's looking, or even the scene illumination.",
    "start": "1373560",
    "end": "1379650"
  },
  {
    "text": "So you change one\nof these settings. And you capture a\nwhole number of images. And then you somehow\nuse an algorithm",
    "start": "1379650",
    "end": "1385440"
  },
  {
    "text": "to combine those\nimages together. And you get one image\nthat looks better than any one of those\nindividual images.",
    "start": "1385440",
    "end": "1391260"
  },
  {
    "text": "That's basically what\nepsilon photography is. And there are a number\nof ways in which you can",
    "start": "1391260",
    "end": "1398160"
  },
  {
    "start": "1395000",
    "end": "1479000"
  },
  {
    "text": "do this epsilon photography. And I'm going to go through\neach one of these one by one. You could do-- you could take\nmultiple pictures over time.",
    "start": "1398160",
    "end": "1405510"
  },
  {
    "text": "You could take one-- you\ncan take one picture, save it, take a second\npicture, save it, take 10 different pictures, and then\ncombine them together somehow.",
    "start": "1405510",
    "end": "1413310"
  },
  {
    "text": "Or you could do it over sensors. You could have 10 different\ncameras co-located at the same point\nand take one image,",
    "start": "1413310",
    "end": "1419400"
  },
  {
    "text": "one picture with each\ncamera at the same time. Or you could do\nepsilon over pixels. And that's-- I'll get\nback to that in a minute.",
    "start": "1419400",
    "end": "1426420"
  },
  {
    "text": "Or you could do a\ncombination of all of these. So epsilon over\ntime is something",
    "start": "1426420",
    "end": "1432270"
  },
  {
    "text": "which is the most common. And it's what most photography\nmanuals refer to as bracketing.",
    "start": "1432270",
    "end": "1437880"
  },
  {
    "text": "And the idea of bracketing\nis a little different because, in the end, you\nend up using just one image.",
    "start": "1437880",
    "end": "1443050"
  },
  {
    "text": "So when you're not sure of\nwhat the exposure should be or you're not sure of\nwhere you should focus,",
    "start": "1443050",
    "end": "1448320"
  },
  {
    "text": "you take multiple images with\nslightly different exposures or slightly different focus\nsettings or aperture settings.",
    "start": "1448320",
    "end": "1454360"
  },
  {
    "text": "And most cameras have inward\nfeatures for doing this. So you just have to press\nthe Shutter button once",
    "start": "1454360",
    "end": "1460590"
  },
  {
    "text": "and it takes five\nimages for you. And then when you\ngo home, you can decide which one is the\nbest and just use that.",
    "start": "1460590",
    "end": "1466800"
  },
  {
    "text": "But epsilon in time is similar. You take multiple images. But then you use some\nalgorithm or some--",
    "start": "1466800",
    "end": "1474510"
  },
  {
    "text": "something smart to combine\nthose images together and get one resulting image.",
    "start": "1474510",
    "end": "1480100"
  },
  {
    "start": "1479000",
    "end": "1576000"
  },
  {
    "text": "So the case where it's\nthe most commonly used is for high dynamic\nrange photography.",
    "start": "1480100",
    "end": "1485190"
  },
  {
    "text": "And I believe Ramesh\ntalked about this. In last class, he mentioned it. So as I was saying\nearlier, that you",
    "start": "1485190",
    "end": "1492270"
  },
  {
    "text": "need to have the correct\nexposure in order to get the image of a scene.",
    "start": "1492270",
    "end": "1497840"
  },
  {
    "text": "It turns out that,\nfor many scenes, even if you have the\ncorrect exposure, you cannot capture everything\nthat the scene contains.",
    "start": "1497840",
    "end": "1504210"
  },
  {
    "text": "Your scene can have very\nbright parts, such as daylight, and very dark shadow regions.",
    "start": "1504210",
    "end": "1509820"
  },
  {
    "text": "And the contrast\nratio of these two can be as high as [INAUDIBLE].",
    "start": "1509820",
    "end": "1515070"
  },
  {
    "text": "And most cameras would\nnot capture anything more than a ratio of about--",
    "start": "1515070",
    "end": "1520950"
  },
  {
    "text": "excuse me-- about 1,000. So one way of going\naround this limitation is to capture a\nnumber of images,",
    "start": "1520950",
    "end": "1527100"
  },
  {
    "text": "and then use an algorithm\nto combine all those images together and create what's\ncalled a high dynamic range",
    "start": "1527100",
    "end": "1532800"
  },
  {
    "text": "image. And I'm sure we've all\nheard of this term. If you just go on\nFlickr and search for \"high dynamic\nrange images,\" you",
    "start": "1532800",
    "end": "1538170"
  },
  {
    "text": "will get millions of pictures\nthat people have captured using this technique, just\ncapturing a bunch of images",
    "start": "1538170",
    "end": "1543539"
  },
  {
    "text": "and putting them together. And there's been\nlots of research into how you should put\nthese images together.",
    "start": "1543540",
    "end": "1549570"
  },
  {
    "text": "And it turns out that once\nyou've done all of this, there's a related\ndual problem, which is",
    "start": "1549570",
    "end": "1555630"
  },
  {
    "text": "how do you display that image. And I'll get back\nto that in a minute. But one way of displaying that\nis what's called tone mapping.",
    "start": "1555630",
    "end": "1562559"
  },
  {
    "text": "And there is work on\nsophisticated algorithms on how do you compress a\n12-bit or a 14-bit image back",
    "start": "1562560",
    "end": "1568950"
  },
  {
    "text": "to an 8-bit image. And there's interesting work\nin that area, which we're not",
    "start": "1568950",
    "end": "1574260"
  },
  {
    "text": "going to cover in this class. Another example over\nepsilon over time",
    "start": "1574260",
    "end": "1579419"
  },
  {
    "start": "1576000",
    "end": "1665000"
  },
  {
    "text": "is this example\nthat I really like. This is-- I think-- I'm not sure-- but it's one\nof the first color images--",
    "start": "1579420",
    "end": "1586200"
  },
  {
    "text": "or it's from the set of\none of the first color photographs produced. And it was by--",
    "start": "1586200",
    "end": "1593490"
  },
  {
    "text": "this guy's name I\ncannot pronounce. But he went around Russia in\nthe early 20th century during--",
    "start": "1593490",
    "end": "1601005"
  },
  {
    "text": " I forget, but during\nthe early 20th century.",
    "start": "1601005",
    "end": "1608440"
  },
  {
    "text": "And he took a whole bunch of\nphotos of people just living their lives-- going and farming,\nhunting, and just sitting,",
    "start": "1608440",
    "end": "1617190"
  },
  {
    "text": "and things like that. And then the way he\ntook these pictures was he would take three images-- one with a red filter placed\nin front of the camera,",
    "start": "1617190",
    "end": "1624090"
  },
  {
    "text": "then one with a green, and\none with the blue filter. And then once he had processed\nhis images and so on,",
    "start": "1624090",
    "end": "1629610"
  },
  {
    "text": "he developed a projector\nwhich would project a red image, a green\nimage, and a blue image on the same screen.",
    "start": "1629610",
    "end": "1637630"
  },
  {
    "text": "So when you were viewing it,\nyou would view a colored image. And as recently as\nabout 10 years ago,",
    "start": "1637630",
    "end": "1644200"
  },
  {
    "text": "until about 10 years\nago, there was just these films that were lying in\nthe Library of Congress, which were then digitized\nand hand-aligned.",
    "start": "1644200",
    "end": "1651370"
  },
  {
    "text": "And now, you can download\nall of these color images from their website. So this is the very simple\ncase of epsilon in time.",
    "start": "1651370",
    "end": "1659797"
  },
  {
    "text": "You just take three images\nwith three different pictures in front of your camera. ",
    "start": "1659797",
    "end": "1665970"
  },
  {
    "text": "Another example, which\nis actually used-- it's probably using this\nprojector-- is that there's--",
    "start": "1665970",
    "end": "1671610"
  },
  {
    "text": "most DLP projectors\nhave a color field, which stands in front\nof the DMD mirror.",
    "start": "1671610",
    "end": "1677159"
  },
  {
    "text": "And part of this-- it's a little hard to see. But I think this is\nred, green, blue,",
    "start": "1677160",
    "end": "1684240"
  },
  {
    "text": "and then it's green again. And I think this part\nis just white in order to increase the\nintensity of the--",
    "start": "1684240",
    "end": "1692250"
  },
  {
    "text": "maybe this is red and\nthis is just transparent. But when you have the red\npart of the wheel in front",
    "start": "1692250",
    "end": "1697260"
  },
  {
    "text": "of the DMD, you\nproject the red image. Then when you have\nthe green part, you project the green\nimage, and so on so",
    "start": "1697260",
    "end": "1703860"
  },
  {
    "text": "that when you actually\nview the projected image-- and this happens\nreally, really fast, that the eye\nintegrates over time",
    "start": "1703860",
    "end": "1709890"
  },
  {
    "text": "and actually gives you\nthe full color image. And one way to\nsee this happening",
    "start": "1709890",
    "end": "1715860"
  },
  {
    "text": "is if you take a camera and\nyou just capture an image with a really fast shutter\nspeed of about 1 over 1,000,",
    "start": "1715860",
    "end": "1721620"
  },
  {
    "text": "you can actually sometimes\nget half the screen green, half the screen is blue. Or you can get really\ninteresting and [INAUDIBLE]",
    "start": "1721620",
    "end": "1728309"
  },
  {
    "text": "if you try to do that. Now, this won't work if\nyou have an LCD projector because an LCD projector\nactually uses a color LCD.",
    "start": "1728310",
    "end": "1735670"
  },
  {
    "text": "And you get all the\ncolors at the same time. It's actually\nspatially interpolated.",
    "start": "1735670",
    "end": "1745320"
  },
  {
    "text": "It's a spatial sort of\nmultiplexing instead of a temporal thing like this. ",
    "start": "1745320",
    "end": "1753160"
  },
  {
    "start": "1752000",
    "end": "1850000"
  },
  {
    "text": "So this was doing\nepsilon over time. The next one is doing\nepsilon over sensors. And this usually\nmeans two things.",
    "start": "1753160",
    "end": "1759760"
  },
  {
    "text": "You can either have\nmultiple cameras or you can just have multiple\nsensors within the same camera.",
    "start": "1759760",
    "end": "1764910"
  },
  {
    "text": "And multiple sensors\nwithin the same camera is what's popularly called\na 3CCD imaging system.",
    "start": "1764910",
    "end": "1772170"
  },
  {
    "text": "It's what's used in most\nhigh-end video cameras and camcorders. And you have this trichroic lens\nwith a prism, which actually--",
    "start": "1772170",
    "end": "1782519"
  },
  {
    "text": "depending on the index of\nrefraction, the rays get-- they just pass through or they\nhave total internal reflection.",
    "start": "1782520",
    "end": "1789540"
  },
  {
    "text": "And so the red,\ngreen, and blue images are formed on three\ndifferent sensors,",
    "start": "1789540",
    "end": "1794760"
  },
  {
    "text": "which are exactly the\nsame optical distance away from the scene. And so when you take all\nof those three images--",
    "start": "1794760",
    "end": "1801150"
  },
  {
    "text": "I think that image\nover there shows you have white light coming\nin from behind the prism.",
    "start": "1801150",
    "end": "1806190"
  },
  {
    "text": "And then you have the green,\nblue, and red components getting separated\nas they go through.",
    "start": "1806190",
    "end": "1811540"
  },
  {
    "text": "And so at the same time,\nusing three different sensors, you can capture the\nthree color channels.",
    "start": "1811540",
    "end": "1817299"
  },
  {
    "text": "So it's similar to\nputting the three filters in front of\nthe camera, but it",
    "start": "1817300",
    "end": "1822360"
  },
  {
    "text": "happens at the same time. So you can use this for\nmoving objects and so on.",
    "start": "1822360",
    "end": "1827430"
  },
  {
    "text": "And yeah, so also the\nsensor itself is--",
    "start": "1827430",
    "end": "1837095"
  },
  {
    "text": "it usually has a very\nbroad spectral response. So it actually responds\nto any incoming wavelength",
    "start": "1837095",
    "end": "1842750"
  },
  {
    "text": "between 400 and 700 nanometers. It's only the prism that\ndoes the separation. ",
    "start": "1842750",
    "end": "1850960"
  },
  {
    "start": "1850000",
    "end": "1919000"
  },
  {
    "text": "AUDIENCE: So why\nis this being used? Why is that not being\nused in digital SLRs?",
    "start": "1850960",
    "end": "1856509"
  },
  {
    "text": "ANKIT MOHAN: It's\njust big and clumsy. I mean, I think the question\nI would ask is the opposite.",
    "start": "1856510",
    "end": "1864170"
  },
  {
    "text": "Why don't they use Bayer\nsensors in camcorders? And I'm not entirely sure why.",
    "start": "1864170",
    "end": "1872000"
  },
  {
    "text": "I think this might\nbe something that's just stuck around since\nthe first camcorders were",
    "start": "1872000",
    "end": "1879740"
  },
  {
    "text": "developed. And that was probably\nbefore Bayer pattern filters became popular.",
    "start": "1879740",
    "end": "1885580"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. ",
    "start": "1885580",
    "end": "1895838"
  },
  {
    "text": "ANKIT MOHAN: Right. So probably those\nedges-- edge effects show up more in a video camera\nthan they do in digital, just",
    "start": "1895838",
    "end": "1903500"
  },
  {
    "text": "still photography. I'm not really sure why\nthey're still in use.",
    "start": "1903500",
    "end": "1911130"
  },
  {
    "text": "I mean, they're\ndefinitely better. They do give a higher\nresolution, as was pointed out.",
    "start": "1911130",
    "end": "1917000"
  },
  {
    "text": " So recently, Morgan McGuire and\nothers at Mitsubishi Research,",
    "start": "1917000",
    "end": "1925169"
  },
  {
    "start": "1919000",
    "end": "2007000"
  },
  {
    "text": "which is just across the street,\nthey came up with this really-- they took this to the extreme. And they said, instead of\njust having three of them,",
    "start": "1925170",
    "end": "1931590"
  },
  {
    "text": "why don't we have\neight of them and make a whole tree of these\nkinds of multiple optically",
    "start": "1931590",
    "end": "1936720"
  },
  {
    "text": "co-located cameras? And so they came up\nwith a very interesting beam-splitter arrangement.",
    "start": "1936720",
    "end": "1942419"
  },
  {
    "text": "And each of these eight\ncameras are actually optically co-located\nat the same point.",
    "start": "1942420",
    "end": "1947920"
  },
  {
    "text": "And so the image\nformed on each of them, if there was nothing\nelse changed, would be exactly the same.",
    "start": "1947920",
    "end": "1953049"
  },
  {
    "text": "But what this gives you\nthe flexibility to do is now each of these eight\ncan have different focus",
    "start": "1953050",
    "end": "1958169"
  },
  {
    "text": "settings, for example. They can focus on\na different plane. Or they can have a different\ncolor filter in front of it.",
    "start": "1958170",
    "end": "1963400"
  },
  {
    "text": "And you can get eight\ndifferent spectrum-- spectrum channels\nat the same time. And what I think,\non the right, it",
    "start": "1963400",
    "end": "1969679"
  },
  {
    "text": "shows is just that he's shown-- he shines a laser\nthrough the cameras to align them to see\nthat that ray of light",
    "start": "1969680",
    "end": "1977309"
  },
  {
    "text": "actually goes into each\none of those cameras. So he used this setup\nfor-- or a simplified setup",
    "start": "1977310",
    "end": "1983429"
  },
  {
    "text": "for doing matting\nor defocus matting, where he used, I think,\ntwo or three cameras",
    "start": "1983430",
    "end": "1989550"
  },
  {
    "text": "to focus on the\nplane and one that's focused in the\nbackground in order to do a separation between\nwhat's in the front",
    "start": "1989550",
    "end": "1995100"
  },
  {
    "text": "and what's in the background. But it's certainly\nsomething that can be used for\nvarious other things.",
    "start": "1995100",
    "end": "2001230"
  },
  {
    "text": "It's basically the same concept\nas multiplexing over sensors. ",
    "start": "2001230",
    "end": "2008650"
  },
  {
    "start": "2007000",
    "end": "2084000"
  },
  {
    "text": "Another way you can do this is\nsimply by using camera arrays. And this was work, I believe, on\none of the first camera arrays.",
    "start": "2008650",
    "end": "2015500"
  },
  {
    "text": "And it was done at CSAIL. And it's epsilon-- the\ndifference between camera",
    "start": "2015500",
    "end": "2021160"
  },
  {
    "text": "arrays and a SAMP or\n3CCD is that this imposes a certain epsilon on your\nsetup, that there's always",
    "start": "2021160",
    "end": "2028480"
  },
  {
    "text": "going to be epsilon in\nthe camera position. You can put other\nepsilon on top of it.",
    "start": "2028480",
    "end": "2034300"
  },
  {
    "text": "You can have a different filter\nin front of these cameras or you can have a\ndifferent focus setting on each of these cameras.",
    "start": "2034300",
    "end": "2039490"
  },
  {
    "text": "But just by itself, it\ngives you an epsilon in the camera position. So each of the cameras\nin this camera array",
    "start": "2039490",
    "end": "2046870"
  },
  {
    "text": "is actually-- they're\nnot co-located. They're slightly translated\nfrom one another. And that itself can be used\nto give interesting things,",
    "start": "2046870",
    "end": "2054099"
  },
  {
    "text": "like I'll get back to\nthat later in the talk. But this is another way of\ndoing this kind of epsilon.",
    "start": "2054100",
    "end": "2063580"
  },
  {
    "text": "And Stanford has their own\nversion of camera arrays. And now, actually you can\njust buy a camera array, which",
    "start": "2063580",
    "end": "2069158"
  },
  {
    "text": "is a 5 by 5 profusion camera. We have one upstairs, which-- it's one unit. And it actually has a very\nwell-aligned and precisely",
    "start": "2069159",
    "end": "2077079"
  },
  {
    "text": "calibrated camera-- array of cameras. ",
    "start": "2077080",
    "end": "2085030"
  },
  {
    "start": "2084000",
    "end": "2134000"
  },
  {
    "text": "The last one is\nepsilon over pixels, where different pixels\nare actually capturing different information.",
    "start": "2085030",
    "end": "2091580"
  },
  {
    "text": "And we already talked\nabout this one, which is where the Bayer filter\nis essentially doing this.",
    "start": "2091580",
    "end": "2098890"
  },
  {
    "text": "Each pixel has a different\ncolor filter in front of it. And [? Roarke ?]\nis going to talk about another technique a\nlittle later today, which",
    "start": "2098890",
    "end": "2106990"
  },
  {
    "text": "is a very clever way of\nextending this and allowing you to do various other things\nwithout having to place",
    "start": "2106990",
    "end": "2112060"
  },
  {
    "text": "the filters on the pixel itself\nor [INAUDIBLE] elsewhere, which is easier to do.",
    "start": "2112060",
    "end": "2117560"
  },
  {
    "text": "So going back to-- whose question was it? Someone asked, can you change\nthe shape of the filters",
    "start": "2117560",
    "end": "2124420"
  },
  {
    "text": "of the color response? I think you want to know? But [? Roarke ?]\nwill shoe you a way of doing that by simply putting\nsomething in front of the lens.",
    "start": "2124420",
    "end": "2131950"
  },
  {
    "text": " And then you can have\nepsilon in multiple axes.",
    "start": "2131950",
    "end": "2137859"
  },
  {
    "start": "2134000",
    "end": "2197000"
  },
  {
    "text": "So this is a very cute camera\nthat also we have upstairs. It's got four lenses. And so it forms four\nimages on the film.",
    "start": "2137860",
    "end": "2146450"
  },
  {
    "text": "It's a film camera. And it also has four flashes. The reason it has\nfour flashes is not because of four\ndifferent flashes,",
    "start": "2146450",
    "end": "2152263"
  },
  {
    "text": "but because it can strobe\nthem very quickly one after the other. ",
    "start": "2152263",
    "end": "2158900"
  },
  {
    "text": "So it opens one lens at a time. And when that lens is open,\nit strobes one of the flashes.",
    "start": "2158900",
    "end": "2165410"
  },
  {
    "text": "So you get four\nimages, which are from slightly\ndifferent viewpoints and taken at a slightly\ndifferent timing sensors.",
    "start": "2165410",
    "end": "2171890"
  },
  {
    "text": "And there's a whole website\nfull of creative stuff that people have done with\nthese kind of cameras.",
    "start": "2171890",
    "end": "2177110"
  },
  {
    "text": "But this is epsilon in time\nand also in the position",
    "start": "2177110",
    "end": "2182210"
  },
  {
    "text": "of the camera, so in sensors. Yeah? AUDIENCE: So is this on film?",
    "start": "2182210",
    "end": "2188432"
  },
  {
    "text": "ANKIT MOHAN: This\nis on film, yeah. AUDIENCE: And so does it give\nyou four pictures on the film? Or are they superimposed? ANKIT MOHAN: They're\nnot superimposed.",
    "start": "2188432",
    "end": "2193970"
  },
  {
    "text": "They're four distinct pictures. AUDIENCE: Right. ANKIT MOHAN: So this is a work\ndone by [? Srini ?] sometime",
    "start": "2193970",
    "end": "2200730"
  },
  {
    "start": "2197000",
    "end": "2312000"
  },
  {
    "text": "back, which is-- it brings it all together\nin one nice package, where you can do all of\nthese things together.",
    "start": "2200730",
    "end": "2207000"
  },
  {
    "text": "And it's what they call\ngeneralized mosaicing. Are people aware\nof what mosaicing",
    "start": "2207000",
    "end": "2212700"
  },
  {
    "text": "or how you capture a panorama? Basically, if I want to capture\na panorama of this whole scene, I will take an image here, I\nwould move, take an image here,",
    "start": "2212700",
    "end": "2219710"
  },
  {
    "text": "move, take an image here,\nand take an image here, and then just\nstitch them together to create a mosaic, which\nhas everything in here.",
    "start": "2219710",
    "end": "2226660"
  },
  {
    "text": "So what they came up with is\ninstead of taking an image-- each image with the\nsame setting, they put--",
    "start": "2226660",
    "end": "2233700"
  },
  {
    "text": "so that's the camera. They put a filter in\nfront of the camera some distance between the\nscene and the camera itself.",
    "start": "2233700",
    "end": "2240330"
  },
  {
    "text": "And this can be a\nfilter which either has a ramp in neutral\ndensity gradient",
    "start": "2240330",
    "end": "2246420"
  },
  {
    "text": "or different spectrums,\ndifferent colors of polarization or even focus. And you simply-- instead of\ntaking one image at a time,",
    "start": "2246420",
    "end": "2253710"
  },
  {
    "text": "you take a video\nas it's rotating. And from this, from the\ndata that you capture, you can get either\na high dynamic range",
    "start": "2253710",
    "end": "2260130"
  },
  {
    "text": "of the whole scene, or\na multispectral image of the whole scene,\nor an image that's",
    "start": "2260130",
    "end": "2265740"
  },
  {
    "text": "focused at different points. So the way to think\nof this is that when you're taking an image here,\ndifferent scene points--",
    "start": "2265740",
    "end": "2272369"
  },
  {
    "text": "something over there-- I'm going to get the blue\nchannel of a pixel here. But when I rotate it, I'm\ngoing to get the green channel",
    "start": "2272370",
    "end": "2278220"
  },
  {
    "text": "of the same pixel. I rotate it some\nmore, I'm going to get the red channel of that pixel. So you just do this\ncomplete panoramic motion.",
    "start": "2278220",
    "end": "2285539"
  },
  {
    "text": "You have some missing\ndata for the edges. But for anything\nin between, you'll",
    "start": "2285540",
    "end": "2290760"
  },
  {
    "text": "be able to recover the\ncomplete information of this. That's why they\ncall it generalized,",
    "start": "2290760",
    "end": "2297330"
  },
  {
    "text": "because you could use it\nfor any one of these things. And I think they also built\na camera prototype like that",
    "start": "2297330",
    "end": "2303930"
  },
  {
    "text": "which was more portable. And they just put this\nfilter in front of the lens. ",
    "start": "2303930",
    "end": "2313250"
  },
  {
    "start": "2312000",
    "end": "2378000"
  },
  {
    "text": "So we sort of already\ndiscussed this one, which is doing HDR capture\nby multiple images.",
    "start": "2313250",
    "end": "2319860"
  },
  {
    "text": "You just take a whole\nbunch of images. And you can combine all\nthat information together. And this is doing HDR over time.",
    "start": "2319860",
    "end": "2326359"
  },
  {
    "start": "2326360",
    "end": "2334120"
  },
  {
    "text": "So that was this one. So I just wanted to take the\nexample of high dynamic range imaging and see how we can do\nthis over time, over sensor,",
    "start": "2334120",
    "end": "2342280"
  },
  {
    "text": "and over pixel. So this is the first one,\nwhich is doing HDR over time. This is the second one, which\nis the generalized mosaicing,",
    "start": "2342280",
    "end": "2350170"
  },
  {
    "text": "which is sort of in\nbetween the three settings that you just put this filter\nin front of your camera,",
    "start": "2350170",
    "end": "2355600"
  },
  {
    "text": "and you rotate the\ncamera, and take a video. This is using\nmultiple detectors. This is similar to the SAM or\nthe 3CCD setup that we saw.",
    "start": "2355600",
    "end": "2362829"
  },
  {
    "text": "You have multiple cameras that\nare optically co-located that take multiple-- that take\nimages at the same time",
    "start": "2362830",
    "end": "2369670"
  },
  {
    "text": "with different filters\nin front of them. So they have different exposure\nsettings on each one of them. And as you can see,\neach of these areas",
    "start": "2369670",
    "end": "2375580"
  },
  {
    "text": "has had lots of\nwork done in them. So the last one is this--",
    "start": "2375580",
    "end": "2383110"
  },
  {
    "start": "2378000",
    "end": "2434000"
  },
  {
    "text": "using what's called\nassorted pixels. I think that that's a\nmore generalized way of the other two.",
    "start": "2383110",
    "end": "2388930"
  },
  {
    "text": "Yeah, so it's similar\nto the Bayer mosaic. But instead of having\njust an RGB Bayer mosaic,",
    "start": "2388930",
    "end": "2394300"
  },
  {
    "text": "they actually had two or\nthree different levels of neutral density filters\nalso placed over each pixel.",
    "start": "2394300",
    "end": "2400600"
  },
  {
    "text": "So each pixel-- this blue\nis different from that blue in the amount of light\nthat it captures.",
    "start": "2400600",
    "end": "2407080"
  },
  {
    "text": "And so you can do an\ninterpretation in the color. And you can also do\ninterpolation in intensity",
    "start": "2407080",
    "end": "2412270"
  },
  {
    "text": "in order to get a\nhigh resolution image. And this is essentially what\nthey call assorted pixel.",
    "start": "2412270",
    "end": "2419330"
  },
  {
    "text": "But it's more like generalized\nBayer pattern, Bayer filtering. And you can put polarization\nfilters also on top of it.",
    "start": "2419330",
    "end": "2428485"
  },
  {
    "text": "Or you could have other\ncolors other than just RGB. And again, [? Roarke ?] is going\nto talk more about this later.",
    "start": "2428485",
    "end": "2435349"
  },
  {
    "start": "2434000",
    "end": "2459000"
  },
  {
    "text": "And this was actually work done\nat Columbia in collaboration with Sony.",
    "start": "2435350",
    "end": "2441170"
  },
  {
    "text": "And Sony actually made\na camera that did this. It was only a prototype. It was never sold. But they were able\nto get this picture",
    "start": "2441170",
    "end": "2449870"
  },
  {
    "text": "from an assorted camera-- assorted pixels camera, which\nhas a much higher dynamic range and captures all three color\nchannels at the same time.",
    "start": "2449870",
    "end": "2456650"
  },
  {
    "text": " This is another\nexample of doing this",
    "start": "2456650",
    "end": "2463840"
  },
  {
    "start": "2459000",
    "end": "2640000"
  },
  {
    "text": "over time, this high\ndynamic range capture. And the way this\nwas done is that you",
    "start": "2463840",
    "end": "2471175"
  },
  {
    "text": "place an LCD in front\nof the sensor which is of a much lower resolution\nthan the sensor itself.",
    "start": "2471175",
    "end": "2477040"
  },
  {
    "text": "You capture the\ninformation on the sensor. And you see certain pixels go-- get saturated.",
    "start": "2477040",
    "end": "2482680"
  },
  {
    "text": "They're too bright. And in the next\ntimestamp, you actually put a darker patch\nover those pixels",
    "start": "2482680",
    "end": "2488990"
  },
  {
    "text": "so that you compensate\nfor the brightness. And going through,\niterating through this,",
    "start": "2488990",
    "end": "2495250"
  },
  {
    "text": "you can get an image which is-- which has a lower dynamic\nrange on the sensor.",
    "start": "2495250",
    "end": "2501103"
  },
  {
    "text": "But once you combine\nthat with the information that you pumped\ninto the LCD, you can then recover a high\ndynamic range image.",
    "start": "2501103",
    "end": "2507550"
  },
  {
    "text": " The reason I wanted\nto just mention that is for this one,\nwhere this is actually",
    "start": "2507550",
    "end": "2514930"
  },
  {
    "text": "a work done by\nWolfgang Heidrich, who gave a talk in our group\nsome time back at University of British Columbia in Canada.",
    "start": "2514930",
    "end": "2521300"
  },
  {
    "text": "And this is stuff that's\nbeen brought over by Dolby. And they're actually using\nthis stuff in Samsung LCDs now.",
    "start": "2521300",
    "end": "2528610"
  },
  {
    "text": "But this is a way of generating\na high dynamic range display.",
    "start": "2528610",
    "end": "2534700"
  },
  {
    "text": "And the setup is very similar-- it's very similar\nto the previous one. And it's actually\nvery simple, in that",
    "start": "2534700",
    "end": "2540460"
  },
  {
    "text": "instead of just\nusing a projector and projecting on the screen,\nwhich is what a Bayer projector display does, they\nhave a projector,",
    "start": "2540460",
    "end": "2548349"
  },
  {
    "text": "and then they have an\nLCD in front of it. So they have two\nlayers of control. And they get twice\nor the squared",
    "start": "2548350",
    "end": "2557200"
  },
  {
    "text": "of what they had earlier as much\ncontrol over the dynamic range of what they can display.",
    "start": "2557200",
    "end": "2563950"
  },
  {
    "text": "And so they can control the-- I think this is a very\nearly prototype over here.",
    "start": "2563950",
    "end": "2569320"
  },
  {
    "text": "So they have two\nlayers of LCDs-- so one inside the projector itself\nand one placed over there.",
    "start": "2569320",
    "end": "2575960"
  },
  {
    "text": "But you can also just\ndo it with two layers of actual physical LCDs.",
    "start": "2575960",
    "end": "2581200"
  },
  {
    "text": "And it turns out that\nthe LCD at the back has to be-- can be of a much\nlower resolution than the LCD",
    "start": "2581200",
    "end": "2586480"
  },
  {
    "text": "in the front. And just using that, you can\nget very high dynamic range. And I think most\nHDTVs and so on,",
    "start": "2586480",
    "end": "2594611"
  },
  {
    "text": "also they have this thing where\nthey can dim the backlight. So they get this very\nhigh dynamic contrast,",
    "start": "2594612",
    "end": "2600250"
  },
  {
    "text": "which is sort of confusing. But it's essentially not\njust modulating the LCD,",
    "start": "2600250",
    "end": "2605830"
  },
  {
    "text": "but also modulating\nthe backlight. That's essentially\nwhat this is doing, but not just the\nwhole backlight. Backlight is\nmodulated differently",
    "start": "2605830",
    "end": "2612970"
  },
  {
    "text": "in different parts\nof the screen. Yeah? AUDIENCE: Well, how\ncome you can use a lower resolution for the front LCD?",
    "start": "2612970",
    "end": "2620760"
  },
  {
    "text": "ANKIT MOHAN: No, not for\nthe front, for the back LCD. For the front, you still\nneed full resolution",
    "start": "2620760",
    "end": "2626339"
  },
  {
    "text": "because the back\nLCD is essentially acting like a backlight.",
    "start": "2626340",
    "end": "2631589"
  },
  {
    "text": "I think they also\nhad a diffuser here, which anyways reduces the\nresolution of the back LCD.",
    "start": "2631590",
    "end": "2637770"
  },
  {
    "text": "Otherwise, you might get\nweird edges and so on. So that was a little\nabout high dynamic range.",
    "start": "2637770",
    "end": "2644728"
  },
  {
    "start": "2640000",
    "end": "2756000"
  },
  {
    "text": "The next thing I\nwanted to talk about is what we discussed earlier,\nthis concept of focus setting and how we can extend\nthe depth of field.",
    "start": "2644728",
    "end": "2652809"
  },
  {
    "text": "There are many\napplications where you want a very\nlarge depth of field, like I said, for example,\nlandscape photography.",
    "start": "2652810",
    "end": "2659410"
  },
  {
    "text": "You want the tree next to\nyou and the mountain faraway to be in focus. But as we discussed,\nin order to do that,",
    "start": "2659410",
    "end": "2666050"
  },
  {
    "text": "you need to stop down the lens. You need to have a very\nsmall aperture, which means you are going\nto get very little",
    "start": "2666050",
    "end": "2672220"
  },
  {
    "text": "light coming into the camera. And so your noise goes up. Or you might have\nthings move while you're",
    "start": "2672220",
    "end": "2678310"
  },
  {
    "text": "taking your exposure. So a number of\ntechniques have been proposed over the\npast 30 or 40 years,",
    "start": "2678310",
    "end": "2685310"
  },
  {
    "text": "especially in the\narea of microscopy, in how can we extend\nthe depth of field while still keeping the\naperture size reasonably large.",
    "start": "2685310",
    "end": "2693440"
  },
  {
    "text": "And there is recent work done\nin the area of light field cameras. And one I didn't write over\nhere is tape recording,",
    "start": "2693440",
    "end": "2699550"
  },
  {
    "text": "which I'm sure Ramesh\nwill come back to later, which also allows you to\nextend the depth of field",
    "start": "2699550",
    "end": "2705130"
  },
  {
    "text": "while still having\na large aperture. So the first technique that's\nthe most interesting one here",
    "start": "2705130",
    "end": "2711760"
  },
  {
    "text": "is what's called focal stacks. And the idea is very simple. It's basically epsilon\nover time again.",
    "start": "2711760",
    "end": "2717550"
  },
  {
    "text": "And you take multiple images\nfocused at different planes. So for example, you\nhave this ant sitting",
    "start": "2717550",
    "end": "2725470"
  },
  {
    "text": "under a microscope or this-- when you focus in\nthe foreground,",
    "start": "2725470",
    "end": "2731049"
  },
  {
    "text": "you get things in the\nforeground are in focus, but its hind legs and the rest\nof the body is out of focus.",
    "start": "2731050",
    "end": "2737720"
  },
  {
    "text": "If you focus on the\nbackground, you get focus-- the foreground is not in focus.",
    "start": "2737720",
    "end": "2743000"
  },
  {
    "text": "So what they\ninstead did was they took a whole series of images. And I'm going to just\nflip through them.",
    "start": "2743000",
    "end": "2748030"
  },
  {
    "text": "They're focused at\ndifferent planes. So I think that's about\n10 or 12 images that--",
    "start": "2748030",
    "end": "2757572"
  },
  {
    "text": "you can capture all of those. And you can do this because\nthe object or the scene, in this case, is\nstatic just over time.",
    "start": "2757572",
    "end": "2763460"
  },
  {
    "text": "Or you could use the SAMP kind\nof setup, where you capture all these images\nat the same time, but each camera is focused\nat a different plane.",
    "start": "2763460",
    "end": "2771180"
  },
  {
    "text": "And then you combine\nall of this information together in order to\ncreate one image that's",
    "start": "2771180",
    "end": "2777410"
  },
  {
    "text": "completely all in focus. And so a similar [INAUDIBLE]\nfrom University of Washington",
    "start": "2777410",
    "end": "2783410"
  },
  {
    "text": "proposes a very interesting and\nclever technique of how you can combine them together of\nfinding out regions in--",
    "start": "2783410",
    "end": "2790140"
  },
  {
    "text": "so each image has certain\nparts that are in focus. So you do a\ncontrast-based estimation",
    "start": "2790140",
    "end": "2796910"
  },
  {
    "text": "of what parts are in focus. And that's what's\nshown on the right. And then you do a gradient\ndomain merging of various parts",
    "start": "2796910",
    "end": "2803490"
  },
  {
    "text": "together. So the end result doesn't have\nany weird discontinuities. And it looks nice and smooth.",
    "start": "2803490",
    "end": "2808790"
  },
  {
    "text": "And everything is in focus. And I think Ramesh is,\nat some other point, going to talk about\nthis technique itself",
    "start": "2808790",
    "end": "2816799"
  },
  {
    "text": "in more detail. But what I wanted to mention\nis more of the focal stack. You can just take a\nwhole bunch of images",
    "start": "2816800",
    "end": "2823583"
  },
  {
    "text": "focused at different planes. And then you can put them\nall together in order to get one all in focus image.",
    "start": "2823583",
    "end": "2828960"
  },
  {
    "text": "AUDIENCE: Was the analysis\ndone in a computer vision? Or did it use [INAUDIBLE]\nfrom the camera",
    "start": "2828960",
    "end": "2837100"
  },
  {
    "text": "or the actual picture was taken? ANKIT MOHAN: You mean this data? AUDIENCE: No, the way\nto combine the images.",
    "start": "2837100",
    "end": "2844309"
  },
  {
    "start": "2844000",
    "end": "2883000"
  },
  {
    "text": "ANKIT MOHAN: So the combining\nthe images was actually a different technique. That's this gradient-based\nmerging technique,",
    "start": "2844310",
    "end": "2851750"
  },
  {
    "text": "where you have\nstuff from one image and you have stuff\nfrom another image that you want to put together. But if you just cut that\nimage and put it here,",
    "start": "2851750",
    "end": "2859580"
  },
  {
    "text": "you're going to get\nweird discontinuities. And colors are going\nto be different. But it turns out if you do that\nin the gradient domain and then",
    "start": "2859580",
    "end": "2865759"
  },
  {
    "text": "do a [? percent ?] solver\nto integrate the image back, you are going to get\na nice smooth image. And all the error is\ngoing to get distributed",
    "start": "2865760",
    "end": "2872060"
  },
  {
    "text": "as noise throughout the image. So that was what the\ntechnique initially proposed.",
    "start": "2872060",
    "end": "2877250"
  },
  {
    "text": "And they just used that\ntechnique for this focal stack in order to get this.",
    "start": "2877250",
    "end": "2884060"
  },
  {
    "start": "2883000",
    "end": "2939000"
  },
  {
    "text": "I think the example-- I'm sure Ramesh is going to\ntalk about this at some point. The example they\nhad in the paper was that you have\na scene like this.",
    "start": "2884060",
    "end": "2890910"
  },
  {
    "text": "And if you take a\npicture from here, you might get someone not\nlooking at the camera, or someone caught\nyawning, or someone is--",
    "start": "2890910",
    "end": "2898460"
  },
  {
    "text": "just has a bad face. If you take 10 such images,\neach one of those images is going to have some\npeople who are OK",
    "start": "2898460",
    "end": "2904340"
  },
  {
    "text": "and some people\nwho don't look OK. But there's not going to be\none single image that has everyone looking at the camera.",
    "start": "2904340",
    "end": "2910790"
  },
  {
    "text": "So they developed this\ntechnique in order to combine all of\nthose images together",
    "start": "2910790",
    "end": "2916160"
  },
  {
    "text": "to get one image that\nhas everyone looking at the camera the way you\nwant it to be and still look like a picture\nthat came from a camera.",
    "start": "2916160",
    "end": "2923720"
  },
  {
    "text": "And I should have put\nthat in somewhere. But it's called digital\nphoto mosaic, I think.",
    "start": "2923720",
    "end": "2931430"
  },
  {
    "text": "And it's [INAUDIBLE]. Yeah, a photo montage,\ndigital photo montage.",
    "start": "2931430",
    "end": "2936935"
  },
  {
    "text": " So you can do a similar thing\nwith a light field camera.",
    "start": "2936935",
    "end": "2942710"
  },
  {
    "text": "I don't know if Ramesh\nhas introduced the concept of light fields yet.",
    "start": "2942710",
    "end": "2947782"
  },
  {
    "text": "Has he? AUDIENCE: Yes. ANKIT MOHAN: Yes? So a light field basically\ncaptures all the information",
    "start": "2947782",
    "end": "2954690"
  },
  {
    "text": "coming into a camera. And the way it's\ntraditionally usually done is by putting a microlens array\nin front of the camera sensor.",
    "start": "2954690",
    "end": "2961670"
  },
  {
    "text": "If you don't understand\nthat, that's fine. I'm sure he'll go\ninto more detail. But what you can get\nfrom the light field",
    "start": "2961670",
    "end": "2968040"
  },
  {
    "text": "is you can extract the focal\nstack out of the light field, and then do basically what\nwe did in the previous case",
    "start": "2968040",
    "end": "2974040"
  },
  {
    "text": "and extend the depth\nof field if you want. So a light field-- essentially,\nwhat's, important to remember",
    "start": "2974040",
    "end": "2979589"
  },
  {
    "text": "is the light field\ncan be used to extract the focal stack if needed. So that's another way of\nextending the depth of field.",
    "start": "2979590",
    "end": "2988859"
  },
  {
    "text": "There was another\npaper recently, which again, I did not put\nover here, which is interesting",
    "start": "2988860",
    "end": "2994470"
  },
  {
    "text": "because it was from Sam\nHasinoff at CSAIL, where he-- instead of taking one image\nwith one aperture setting,",
    "start": "2994470",
    "end": "3002030"
  },
  {
    "text": "he claims that if you take\nmultiple images with two or three different\naperture settings,",
    "start": "3002030",
    "end": "3007640"
  },
  {
    "text": "and then you combine\nthem, you are going to get much-- your\ntotal exposure time is going to be much shorter, and you're\ngoing to get less noise,",
    "start": "3007640",
    "end": "3014600"
  },
  {
    "text": "and so on. So that's yet another\nway of combining. It's similar to focal stacks. It's just [INAUDIBLE]\nfocal stacks",
    "start": "3014600",
    "end": "3020060"
  },
  {
    "text": "more smartly because focal\nstacks focuses at each plane. And what he said is that you can\nfind an optimal set of planes",
    "start": "3020060",
    "end": "3026990"
  },
  {
    "text": "that you need to focus in\norder to get the best results. ",
    "start": "3026990",
    "end": "3033119"
  },
  {
    "start": "3032000",
    "end": "3159000"
  },
  {
    "text": "So that was extending\nthe depth of field. The opposite problem is how\ndo you make the depth of field",
    "start": "3033120",
    "end": "3038540"
  },
  {
    "text": "shallower. And this is something\nthat comes naturally when you use an SLR camera\nwith a large aperture lens.",
    "start": "3038540",
    "end": "3044780"
  },
  {
    "text": "You have a very\nshallow depth of field if you open the aperture\nall the way out. And so your main object\nis in sharp focus,",
    "start": "3044780",
    "end": "3051950"
  },
  {
    "text": "but the background\nis nice and blurred. But if you use a small\npoint and shoot camera, it's very hard to get\nthat kind of an effect",
    "start": "3051950",
    "end": "3057980"
  },
  {
    "text": "since your aperture size of the\ncamera is usually very small. And so the question\nis, how can you",
    "start": "3057980",
    "end": "3064460"
  },
  {
    "text": "still use a small\naperture camera and get results like\nthe one at the top? ",
    "start": "3064460",
    "end": "3072190"
  },
  {
    "text": "So there's been a couple of-- three or four\npapers in this area",
    "start": "3072190",
    "end": "3078220"
  },
  {
    "text": "that try to attempt\nto solve this problem. The first one is\nagain from CSAIl by Fredo Durand and his student.",
    "start": "3078220",
    "end": "3085000"
  },
  {
    "text": "And what they did was-- you\nstart with an input image. And then from just\none single image,",
    "start": "3085000",
    "end": "3090220"
  },
  {
    "text": "they estimate the\ndepth of each point. So sorry, before I go\ninto that, the reason why this is a hard\nproblem is because firstly",
    "start": "3090220",
    "end": "3101410"
  },
  {
    "text": "just from this image, it's hard\nto estimate what's in focus and what's not just by\nlooking at the contrast.",
    "start": "3101410",
    "end": "3106480"
  },
  {
    "text": "And even if you can\nget that, even if you know that the\nforeground is in focus and the background is\nout of focus, if you have",
    "start": "3106480",
    "end": "3112599"
  },
  {
    "text": "multiple layers\nin the background, each one of those layers are\ngoing to be out of focus--",
    "start": "3112600",
    "end": "3118000"
  },
  {
    "text": "more or less out\nof focus, depending on the depth or the distance\nfrom the plane of focus. So it's hard to estimate\nthe 3D shape or the 3D",
    "start": "3118000",
    "end": "3125920"
  },
  {
    "text": "structure of this from\njust a single image. It's much easier to\ndo it from two images.",
    "start": "3125920",
    "end": "3131050"
  },
  {
    "text": "But what this paper, \"Defocus\nMagnification,\" did was they tried to estimate the 3D\nstructure of the scene",
    "start": "3131050",
    "end": "3138970"
  },
  {
    "text": "from just one image,\nand then use that one-- that 3D structure\nand the image that",
    "start": "3138970",
    "end": "3145300"
  },
  {
    "text": "was captured in order to\nincrease the defocus by simply applying a spatially very\nblurred filter on the image.",
    "start": "3145300",
    "end": "3151310"
  },
  {
    "text": "So you can see the background\nis more out of focus than the image that\nthey took over here.",
    "start": "3151310",
    "end": "3157000"
  },
  {
    "text": " And this is not really\nepsilon photography.",
    "start": "3157000",
    "end": "3163110"
  },
  {
    "start": "3159000",
    "end": "3358000"
  },
  {
    "text": "I just put this\nhere because it's important to the\noverall structure. But this is more of\nan image processing",
    "start": "3163110",
    "end": "3168540"
  },
  {
    "text": "technique than anything else.  Another way of\ndoing this is what's",
    "start": "3168540",
    "end": "3175190"
  },
  {
    "text": "called synthetic\naperture photography. And this is something that was\nproposed by Marc Levoy's group",
    "start": "3175190",
    "end": "3182240"
  },
  {
    "text": "at Stanford. But it's something\nthat's more general. And it's been used in radars\nand so on for a long time.",
    "start": "3182240",
    "end": "3187490"
  },
  {
    "text": "The idea is actually\nreally simple, that what you want\nto do is you want to simulate a large aperture\nlens, such as the one shown",
    "start": "3187490",
    "end": "3194570"
  },
  {
    "text": "here. However, you don't have the\nphysical resources to create a large aperture lens.",
    "start": "3194570",
    "end": "3200120"
  },
  {
    "text": "But what you can do is create\na number of small aperture lenses, and then somehow\ntake the information coming",
    "start": "3200120",
    "end": "3208609"
  },
  {
    "text": "from each of those lenses and\ncomputationally combine them in order to simulate\na large aperture lens.",
    "start": "3208610",
    "end": "3214070"
  },
  {
    "text": "And it's essentially what-- one way of thinking of this\nis from a light field camera",
    "start": "3214070",
    "end": "3219860"
  },
  {
    "text": "kind of point of view\nor just a camera array. But if you just\nthink of it simply,",
    "start": "3219860",
    "end": "3225080"
  },
  {
    "text": "you can combine each of\nthese rays coming together into the lens if you can\nfind out what those rays are and get what you would have\ngotten from just this one",
    "start": "3225080",
    "end": "3233390"
  },
  {
    "text": "large lens. And now, if you look at a\ndifferent point in space, you combine a\ndifferent set of rays,",
    "start": "3233390",
    "end": "3239869"
  },
  {
    "text": "and you get the intensity\ncorresponding to that point.",
    "start": "3239870",
    "end": "3244980"
  },
  {
    "text": "So it's essentially doing this-- what gets done with a large\naperture lens in optics.",
    "start": "3244980",
    "end": "3253550"
  },
  {
    "text": "You're doing that\ncomputationally by combining all these rays. ",
    "start": "3253550",
    "end": "3259851"
  },
  {
    "text": "So this is what their\nsetup looked like. This is one of the setups. I think they had five\nor six different optical",
    "start": "3259851",
    "end": "3268320"
  },
  {
    "text": "configurations. But this one allows\nthem to see-- so they used this in order\nto focus on something",
    "start": "3268320",
    "end": "3275160"
  },
  {
    "text": "that was behind a bush. So let me see.",
    "start": "3275160",
    "end": "3282660"
  },
  {
    "text": "Yeah, so that's what you\nwould get with just one image. And what's on the right,\nif the video plays, is--",
    "start": "3282660",
    "end": "3289545"
  },
  {
    "start": "3289545",
    "end": "3294670"
  },
  {
    "text": "OK, that's weird.  But anyways, so you can simply,\nby computationally combining",
    "start": "3294670",
    "end": "3301313"
  },
  {
    "text": "the rays-- and you'll\nactually learn how to do this kind of computation. I think it's in one of\nyour assignments also.",
    "start": "3301313",
    "end": "3307000"
  },
  {
    "text": "It's probably the\nnext assignment, where you combine information\nfrom multiple cameras.",
    "start": "3307000",
    "end": "3313030"
  },
  {
    "text": "And by simply\nshifting and adding, you can focus on\na different plane. ",
    "start": "3313030",
    "end": "3322190"
  },
  {
    "text": "OK, so maybe I don't\nhave the video for this. It's just you can focus\nbehind on a different plane.",
    "start": "3322190",
    "end": "3328160"
  },
  {
    "text": "And anything in front\ngoes out of focus. And since your depth\nof field is so shallow because you have this\nlarge synthetic aperture,",
    "start": "3328160",
    "end": "3335630"
  },
  {
    "text": "everything over here\nactually goes out of focus and just blurs out. And you can see behind\nthe foliage in this case.",
    "start": "3335630",
    "end": "3342579"
  },
  {
    "text": "AUDIENCE: Do you know if the\nbushes are moving in time?",
    "start": "3342580",
    "end": "3347950"
  },
  {
    "text": "Does that-- ANKIT MOHAN: I don't think it\nmatters because it takes just one image from each camera. It's a camera array.",
    "start": "3347950",
    "end": "3353680"
  },
  {
    "text": "So it's not over time. It's over sensors.",
    "start": "3353680",
    "end": "3358720"
  },
  {
    "start": "3358000",
    "end": "3432000"
  },
  {
    "text": "But that's a good point. You could actually do\nthis by taking a camera, and moving it around, and\ntaking multiple images, which",
    "start": "3358720",
    "end": "3365350"
  },
  {
    "text": "is exactly what the\nnext paper does. This is actually\nwork by Professor",
    "start": "3365350",
    "end": "3370519"
  },
  {
    "text": "[INAUDIBLE] who was\na visiting professor in our group last year\nand his students in Japan.",
    "start": "3370520",
    "end": "3376089"
  },
  {
    "text": "And they generalized\nthis thing to instead of having a\nfixed, rigid camera array,",
    "start": "3376090",
    "end": "3383911"
  },
  {
    "text": "you can just take a\ncamera, and move it around, and take multiple images. And then using computer\nvision techniques",
    "start": "3383912",
    "end": "3389380"
  },
  {
    "text": "to line up various\nsynced components, they're able to get\nresults kind of like that.",
    "start": "3389380",
    "end": "3395780"
  },
  {
    "text": "So this is just with, I\nthink, three or four images that he took just\nby moving a camera and just taking random\nimages without any structure",
    "start": "3395780",
    "end": "3403765"
  },
  {
    "text": "or any sort of\ncalibration or anything. And from that, he's able to\nfocus now-- in this case,",
    "start": "3403765",
    "end": "3410050"
  },
  {
    "text": "focusing on the foreground and\nthe background is defocused. And in that case focusing\non the background. And the clock in the\nfront is in focus.",
    "start": "3410050",
    "end": "3418360"
  },
  {
    "text": "This is also-- it's\nsimilar to the camera array thing, except you\ndon't need a camera array. You can just take one camera.",
    "start": "3418360",
    "end": "3423430"
  },
  {
    "text": "And over time, you can move it. So in this case, if\nthe scene was changing, you would have problems\nreconstructing it.",
    "start": "3423430",
    "end": "3428920"
  },
  {
    "text": " Finally, the last technique\nI want to talk about",
    "start": "3428920",
    "end": "3436330"
  },
  {
    "start": "3432000",
    "end": "3472000"
  },
  {
    "text": "is something that I\nworked on last year and really quickly try\nto go through this. I think I might have put\ntoo many slides in for this.",
    "start": "3436330",
    "end": "3442870"
  },
  {
    "text": "But the idea over here is to\ndo it more optically rather than computationally. And the basic idea is that\ninstead of keeping the camera",
    "start": "3442870",
    "end": "3453020"
  },
  {
    "text": "and lens static while\nyou're taking an image, you intentionally move the\ncamera lens and sensor.",
    "start": "3453020",
    "end": "3458770"
  },
  {
    "text": "And that's what we call\nimage destabilization. You move the lens and the sensor\nsynchronously with one another",
    "start": "3458770",
    "end": "3466000"
  },
  {
    "text": "during the exposure. And so to give you an intuition\nfor how or why this works--",
    "start": "3466000",
    "end": "3473480"
  },
  {
    "start": "3472000",
    "end": "3572000"
  },
  {
    "text": "so once again, going back to the\nimage we had in the beginning, if you have a plane in\nfocus that's plane A,",
    "start": "3473480",
    "end": "3480520"
  },
  {
    "text": "all the rays coming\nfrom a point on plane-- from the point A get\nfocused on A prime.",
    "start": "3480520",
    "end": "3485890"
  },
  {
    "text": "And the rays coming\nfrom B get focused on a point, which is a little\nin front of the sensor.",
    "start": "3485890",
    "end": "3491230"
  },
  {
    "text": "So you get this defocused\nblur on the sensor. And the size of this blur on\nthe size of the lens aperture.",
    "start": "3491230",
    "end": "3499370"
  },
  {
    "text": "If you reduce the size of\nthe aperture, it goes down. ",
    "start": "3499370",
    "end": "3505040"
  },
  {
    "text": "If you have a pinhole, then you\njust get one ray going through, which is what we saw\nin the beginning.",
    "start": "3505040",
    "end": "3511390"
  },
  {
    "text": "So now if you take the pinhole\nand you translate the pinhole over time, then you're going\nto get a blur over here which",
    "start": "3511390",
    "end": "3518140"
  },
  {
    "text": "corresponds to the motion\nof this pinhole coming from the point B and\nsimilarly point from point A.",
    "start": "3518140",
    "end": "3525609"
  },
  {
    "text": "Now, what's interesting is\nif you compare these two, they're not the same size.",
    "start": "3525610",
    "end": "3530800"
  },
  {
    "text": "They're actually-- they\nhave a different size. And the size ratio\nactually depends on the distance between\nA and B, and the distance",
    "start": "3530800",
    "end": "3536620"
  },
  {
    "text": "between the points, and\nthe pinhole and the sensor. So what we do instead is\nwhile moving the pinhole,",
    "start": "3536620",
    "end": "3545900"
  },
  {
    "text": "we also move the sensor,\nbut we move the sensor such that the ratio-- such that one of\nthe points actually",
    "start": "3545900",
    "end": "3551079"
  },
  {
    "text": "remains fixed on the sensor. And the other point\nproduces a blur. So now, we've taken--",
    "start": "3551080",
    "end": "3557452"
  },
  {
    "text": "I haven't showed\nthe actual motion. But through this\nsequence of images, point A was always focused on\nthe same point on the sensor.",
    "start": "3557452",
    "end": "3563829"
  },
  {
    "text": "Point B was focused\non a different point. And so point B results in this\nblur which point A does not.",
    "start": "3563830",
    "end": "3569650"
  },
  {
    "text": "And you can use this\nsort of a setup, where",
    "start": "3569650",
    "end": "3575315"
  },
  {
    "text": "you have the lens and the\ncamera in two different planes. And the camera is moving\nat a different velocity",
    "start": "3575315",
    "end": "3580930"
  },
  {
    "text": "than the lens. And by the ratio\nof the velocities, you can focus at a different\nplane in front of that camera.",
    "start": "3580930",
    "end": "3586300"
  },
  {
    "text": "So this is an image\nyou will get with just a small aperture lens, I\nthink F22 or something,",
    "start": "3586300",
    "end": "3592150"
  },
  {
    "text": "where everything is in focus. And this is the image you\nget using our technique, where just the thing\nin between-- this",
    "start": "3592150",
    "end": "3599290"
  },
  {
    "text": "is still the same lens. You get something which is\nin the focus in the middle. And everything in\nfront and behind",
    "start": "3599290",
    "end": "3605350"
  },
  {
    "text": "goes more and more\nout of focus by simply translating the camera\nlens and the sensor over the exposure time.",
    "start": "3605350",
    "end": "3611770"
  },
  {
    "text": " And so the advantage\nof this is that you",
    "start": "3611770",
    "end": "3619349"
  },
  {
    "text": "can simulate a large\naperture lens or an SLR lens using a small camera lens.",
    "start": "3619350",
    "end": "3625109"
  },
  {
    "text": "So you don't have to spend-- many of those lenses\ncost more than $1,000. So you can use a [? $30 ?] lens\nin order to create a similar",
    "start": "3625110",
    "end": "3632610"
  },
  {
    "text": "effect as that produced\nby a $1,000 lens. But the disadvantage is\nthat you need this motion.",
    "start": "3632610",
    "end": "3637890"
  },
  {
    "text": "And so you need some\nspace around the lens where it can translate,\nwhich is not all that hard",
    "start": "3637890",
    "end": "3644190"
  },
  {
    "text": "because if you look at the space\naround the lens, most of it is wasted and not really used. ",
    "start": "3644190",
    "end": "3653100"
  },
  {
    "text": "OK, at this point, maybe\nit might be a good idea to just switch to\n[? Roarke ?] and see what his technique lets us do.",
    "start": "3653100",
    "end": "3661320"
  },
  {
    "text": "I have a couple of\nother things here. But I think we can do\nthat after his stuff. But I don't know, do you want\nto break for 5-10 minutes first?",
    "start": "3661320",
    "end": "3669372"
  },
  {
    "text": "AUDIENCE: Yeah. ANKIT MOHAN: Sure, so we\ncan break for 5 minutes. And at 2:45, yeah--",
    "start": "3669372",
    "end": "3677089"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. ",
    "start": "3677090",
    "end": "3687110"
  },
  {
    "text": "There is something\ncalled crosstalk. And there's optical crosstalk\n[INAUDIBLE] crosstalk,",
    "start": "3687110",
    "end": "3692390"
  },
  {
    "text": "meaning you end up having\nthose [INAUDIBLE] side by side. And you can have some photons\nthat actually pass [INAUDIBLE]..",
    "start": "3692390",
    "end": "3700730"
  },
  {
    "text": " ANKIT MOHAN: Do you\nwant to draw that image? AUDIENCE: I mean, if you go back\nto the [INAUDIBLE] then you can",
    "start": "3700730",
    "end": "3708950"
  },
  {
    "text": "actually-- ANKIT MOHAN: I think\nwhat you're saying is that you have [INAUDIBLE].",
    "start": "3708950",
    "end": "3714660"
  },
  {
    "text": " AUDIENCE: Red and\ngreen in there.",
    "start": "3714660",
    "end": "3720025"
  },
  {
    "text": "The photons can\nactually cross say-- yeah, exactly this. And it's going to [INAUDIBLE].",
    "start": "3720025",
    "end": "3726530"
  },
  {
    "text": "And then also, there\nis the fact that-- I mean, photons or\ndifferent wavelengths",
    "start": "3726530",
    "end": "3732370"
  },
  {
    "text": "have different energies. So it might be that one\nblue cross is Jupiter.",
    "start": "3732370",
    "end": "3739720"
  },
  {
    "text": "But we'll set up a wall a little\nbit and actually [INAUDIBLE]..",
    "start": "3739720",
    "end": "3745288"
  },
  {
    "text": "ANKIT MOHAN: Right. AUDIENCE: So this is\nanother kind of [INAUDIBLE].. And if you like--",
    "start": "3745288",
    "end": "3751690"
  },
  {
    "text": "I mean, yet another\nreason for that-- I mean, the refraction\nvaries with wavelength.",
    "start": "3751690",
    "end": "3760700"
  },
  {
    "text": "So in fact, if you have\na single plane here, you're going to have photons\nwith different wavelengths",
    "start": "3760700",
    "end": "3768670"
  },
  {
    "text": "of focus [INAUDIBLE]. So this is what he calls\nchromatic variation.",
    "start": "3768670",
    "end": "3774970"
  },
  {
    "text": "So you have to add extra\nobjects in order to focus it. ANKIT MOHAN: Right.",
    "start": "3774970",
    "end": "3780060"
  },
  {
    "text": "AUDIENCE: But people know how\n[INAUDIBLE] one of the major",
    "start": "3780060",
    "end": "3786330"
  },
  {
    "text": "reasons why-- for high-end applications\nlike manifold applications",
    "start": "3786330",
    "end": "3792320"
  },
  {
    "text": "[INAUDIBLE]. ANKIT MOHAN: Right,\nof course, yeah, and also for the Foveon sensor\nhas similar advantages in some",
    "start": "3792320",
    "end": "3799080"
  },
  {
    "text": "of the cases. And I mean, of\ncourse, using a 3CCD sensor or multiple\ndistinct sensors",
    "start": "3799080",
    "end": "3805590"
  },
  {
    "text": "is always going to give you\nbetter results than the Bayer filter. It's going to be more\nexpensive, perhaps.",
    "start": "3805590",
    "end": "3810720"
  },
  {
    "text": "But I think the question\nthat I think you had was, why is it that we use 3CCD\nfor video but not for still?",
    "start": "3810720",
    "end": "3818609"
  },
  {
    "text": "Why does it matter\nmore for video? And I'm not entirely sure.",
    "start": "3818610",
    "end": "3823860"
  },
  {
    "text": "AUDIENCE: You just\nget more light. You need more light\nfor video in general.",
    "start": "3823860",
    "end": "3829200"
  },
  {
    "text": "Otherwise-- the Bayer\nfilter functions by blocking the light.",
    "start": "3829200",
    "end": "3834420"
  },
  {
    "text": "ANKIT MOHAN: No, but then even-- AUDIENCE: 3CCD actually\nsplits up the light. So you use all the light. ANKIT MOHAN: That's true, yeah.",
    "start": "3834420",
    "end": "3841010"
  },
  {
    "text": "Yeah, so you've got three\ntimes as much light. ",
    "start": "3841010",
    "end": "3848000"
  }
]
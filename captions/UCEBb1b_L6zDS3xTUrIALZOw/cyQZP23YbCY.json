[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5580",
    "end": "12270"
  },
  {
    "text": "To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12270",
    "end": "18830"
  },
  {
    "text": "at OCW.mit.edu.  LORENZO ROSASCO:\nI'm Lorenzo Rosasco.",
    "start": "18830",
    "end": "23870"
  },
  {
    "text": "This is going to be a couple\nof hours plus of basic machine",
    "start": "23870",
    "end": "29371"
  },
  {
    "text": "learning. OK. And I want to emphasize\na bit, the word, \"basic.\" Because really I\ntried to just stick",
    "start": "29371",
    "end": "38150"
  },
  {
    "text": "to the essentials, or\nthings that I would think of essentials to just start. Suppose that you have zero\nknowledge of machine learning",
    "start": "38150",
    "end": "43550"
  },
  {
    "text": "and you just want\nto start from zero. OK. So if you already had\nclasses in machine learning, you might find this a little\nbit boring or at least",
    "start": "43550",
    "end": "51059"
  },
  {
    "text": "kind of rehearsing things\nthat you already know. The idea of looking at\nmachine learning these days",
    "start": "51060",
    "end": "58460"
  },
  {
    "text": "is coming from at least\ntwo different perspectives. The first one is for those\nof you, probably most of that",
    "start": "58460",
    "end": "65830"
  },
  {
    "text": "are interested to develop\nintelligent systems in a very broad sense. What happened in\nthe last few years",
    "start": "65830",
    "end": "71420"
  },
  {
    "text": "is that there's been a kind\nof data-driven revolution where systems that are\ntrained rather than programmed",
    "start": "71420",
    "end": "77210"
  },
  {
    "text": "start to be the key\nengines to solve tasks. And here, there are just some\npictures that are probably",
    "start": "77210",
    "end": "82789"
  },
  {
    "text": "outdated, like robotics. You know, we have\nSiri on our phone. We hear about self-driving cars.",
    "start": "82790",
    "end": "88400"
  },
  {
    "text": "In all these systems,\none key engine is providing data to the\nsystem to essentially try",
    "start": "88400",
    "end": "94010"
  },
  {
    "text": "to learn how to solve the task. And so one idea of this\nclass is to try to see what does it mean to learn?",
    "start": "94010",
    "end": "99840"
  },
  {
    "text": "And the moment that\nyou start to use data to solve complex\ntasks, then there is a natural\nconnection with what",
    "start": "99840",
    "end": "106880"
  },
  {
    "text": "today is called data\nscience, which is somewhat a rapid [INAUDIBLE]\nrenovated version of what we",
    "start": "106880",
    "end": "116330"
  },
  {
    "text": "used to call just statistics. So basically, we start to have\ntons of data of all kinds.",
    "start": "116330",
    "end": "122129"
  },
  {
    "text": "They are very easy\nto collect, and we are starving for knowledge and\ntrying to extract information from these data.",
    "start": "122129",
    "end": "127430"
  },
  {
    "text": "And as it turns out,\nmany of the techniques that are used to develop\nintelligent systems are the same very\ntechnique that you",
    "start": "127430",
    "end": "133280"
  },
  {
    "text": "can use to try to extract\nrelevant information patterns, data, from your data.",
    "start": "133280",
    "end": "140504"
  },
  {
    "text": "So what we want\nto do today is try to see a bit what's\nin the middle. What is the set of techniques\nthat allows you, indeed,",
    "start": "140504",
    "end": "145709"
  },
  {
    "text": "to go from data to knowledge\nor to acquiring ability",
    "start": "145709",
    "end": "151580"
  },
  {
    "text": "to solve tasks.  Machine learning\nis huge these days,",
    "start": "151580",
    "end": "157010"
  },
  {
    "text": "and there are tons of\npossible applications. There has been theory\ndeveloped in the last 20, 30 years that brought the field\nto a certain level of maturity",
    "start": "157010",
    "end": "164030"
  },
  {
    "text": "from a mathematical\npoint of view. There have been tons\nand tons and tons of algorithms developed.",
    "start": "164030",
    "end": "169051"
  },
  {
    "text": "OK. So in three hours,\nthere is no way I could give you even\njust a little view of what",
    "start": "169051",
    "end": "175309"
  },
  {
    "text": "machine learning is these days. So what I did is\npretty much this. I don't know if\nyou've ever done this,",
    "start": "175309",
    "end": "181159"
  },
  {
    "text": "but you used to do\nthe mixtape, and you try to pick the songs that\nyou would bring with yourself",
    "start": "181160",
    "end": "186500"
  },
  {
    "text": "on a desert island. That's kind of the way\nI thought about what to put in this one\n[INAUDIBLE] lights that we're",
    "start": "186500",
    "end": "193840"
  },
  {
    "text": "going to show in a minute. So basically, I\nthought, what are those three, four, five\nlearning algorithms",
    "start": "193840",
    "end": "199909"
  },
  {
    "text": "that you should\nknow, OK, if you know nothing about machine learning. And this is more or\nless at least one part.",
    "start": "199910",
    "end": "206151"
  },
  {
    "text": "Of course there are\na few songs that stayed out of the compilation,\nbut this is like one selection.",
    "start": "206151",
    "end": "211200"
  },
  {
    "text": "OK.  So as such, we're going\nto start, as I said--",
    "start": "211200",
    "end": "218193"
  },
  {
    "text": "whoop-- simple. And the idea is that\nthis morning you're going to see a few algorithms.",
    "start": "218193",
    "end": "224939"
  },
  {
    "text": "And I picked algorithms\nthat are relatively simple from a computational\npoint of view. So the math level is\ngoing to be pretty basic.",
    "start": "224940",
    "end": "232561"
  },
  {
    "text": "OK. I think I'm going to\nuse some linear algebra at some point and maybe some\ncalculus, but that's about it.",
    "start": "232561",
    "end": "238620"
  },
  {
    "text": "So most of the idea\nhere is to emphasize conceptual ideas, the concepts.",
    "start": "238620",
    "end": "243770"
  },
  {
    "text": "And then today, afternoon,\nthere's going to be, basically labs where\nyou sit and you just pick these kind of\nalgorithms and use them,",
    "start": "243770",
    "end": "250130"
  },
  {
    "text": "so you immediately\nsee, what does it mean? OK. So at the end of\nthe day, you should have reasonable\nknowledge about whatever",
    "start": "250130",
    "end": "257450"
  },
  {
    "text": "you're seeing this morning. So this is how the\nclass is structured.",
    "start": "257450",
    "end": "264180"
  },
  {
    "text": "It's divided in\nparts plus the lab. So the first part,\nwhat we want to do is start from probably the\nsimplest learning algorithm",
    "start": "264180",
    "end": "272540"
  },
  {
    "text": "you can think of to try\nto emphasize, and use that as an excuse to introduce\nthe idea of bias-variance,",
    "start": "272540",
    "end": "281180"
  },
  {
    "text": "trade-off, which, to me,\nis probably either the, or one of the most fundamental\nconcepts in statistics",
    "start": "281180",
    "end": "288470"
  },
  {
    "text": "and machine learning, which\nis this idea that you're going to see in a few\nminutes in more detail.",
    "start": "288470",
    "end": "294380"
  },
  {
    "text": "But it's essentially\nthe idea that you never have enough data. OK. And the game here is not\nabout describing the data",
    "start": "294380",
    "end": "300230"
  },
  {
    "text": "that you have today,\nas much as using the data you have today\nas a basis of knowledge to describe data you're\ngoing to get tomorrow.",
    "start": "300230",
    "end": "306980"
  },
  {
    "text": "So there is this\ninherent trade-off between what you\nhave at disposal and what would you\nlike to predict.",
    "start": "306980",
    "end": "313550"
  },
  {
    "text": "And then, essentially\nit turns out that you have to somewhat\ndecide how much you want to trust the data, and how\nmuch you want to somewhat throw",
    "start": "313550",
    "end": "321120"
  },
  {
    "text": "away, or regularize,\nas they say, smooth out the\ninformation in your data,",
    "start": "321120",
    "end": "326159"
  },
  {
    "text": "because you think that\nit's actually an accident. It's just because you saw\ndata with aspects today",
    "start": "326159",
    "end": "331410"
  },
  {
    "text": "that are not really reflective\nof the phenomenon that produced them. But it's just because I saw\n10 points rather than 100.",
    "start": "331410",
    "end": "337980"
  },
  {
    "text": "The basic idea\nhere is essentially the law of large numbers. When you toss a coin,\nyou might find out that if you toss\nit just 10 times,",
    "start": "337980",
    "end": "344850"
  },
  {
    "text": "it looks like it's\nnot a fair coin, but if you go for\n100, or 1,000, you start to see that it\nconverts to 50-50.",
    "start": "344850",
    "end": "350920"
  },
  {
    "text": "OK. So that's kind of\nwhat's going on here. So the idea is that you want\nto use some kind of induction",
    "start": "350920",
    "end": "356880"
  },
  {
    "text": "principle that tells you how\nmuch you can trust the data.",
    "start": "356880",
    "end": "362290"
  },
  {
    "text": "Moving on from this basic\nclass of algorithms, we're going to consider\nso-called regularization techniques.",
    "start": "362290",
    "end": "368699"
  },
  {
    "text": "I use regularization in\na very broad sentence. And here we're going to\nconcentrate on least squares",
    "start": "368700",
    "end": "374849"
  },
  {
    "text": "essentially because\nA, it's simple, and it just reduces\nto linear algebra. And so you don't have to\nknow anything about convex",
    "start": "374850",
    "end": "382320"
  },
  {
    "text": "optimization or any other\nkind of fancy optimization techniques.",
    "start": "382320",
    "end": "387739"
  },
  {
    "text": "And B, because it's\nrelatively simple to move from linear models\nto non-parametric non-linear",
    "start": "387739",
    "end": "393240"
  },
  {
    "text": "models using kernels. OK. And kernels are a big\nfield with a lot of math, but you're just\ngoing to look more",
    "start": "393240",
    "end": "399510"
  },
  {
    "text": "at the recipe to move\nfrom simple models to complicated models. ",
    "start": "399510",
    "end": "405240"
  },
  {
    "text": "So finally, the last part,\nwe're going to move a bit away from pure prediction. So basically these\nfirst two parts",
    "start": "405240",
    "end": "412110"
  },
  {
    "text": "are about prediction, or what\nis called supervised learning. And here we're going to move\na bit away from prediction",
    "start": "412110",
    "end": "418080"
  },
  {
    "text": "and we're going to ask questions\nmore related to, you have data, and you want to know, what\nare the important sectors",
    "start": "418080",
    "end": "424770"
  },
  {
    "text": "in your data? So the one key word here\nis interoperability.",
    "start": "424770",
    "end": "430010"
  },
  {
    "text": "You want to have some form of\ninteroperability of the data at hand. You would like to\nknow, not only how you can make good\npredictions, but what",
    "start": "430010",
    "end": "436890"
  },
  {
    "text": "are the important sectors. So you not only want\nto do good prediction, but you want to know how\nyou make good prediction.",
    "start": "436890",
    "end": "443610"
  },
  {
    "text": "What is the important\ninformation to actually get good prediction. And so, in this last part we're\ngoing to take a peek into this.",
    "start": "443610",
    "end": "451172"
  },
  {
    "text": "And as I said, the\nafternoon is basically going to be a practical session. If it's all MATLAB I think\nthere is some quick--",
    "start": "451172",
    "end": "456589"
  },
  {
    "text": "if you have never\nseen MATLAB before, you can play around\nwith just a little bit. But it's very easy\nand then you've",
    "start": "456589",
    "end": "462219"
  },
  {
    "text": "got a few different proposals\nI think, of things you can do. And you can pick, depending on\nwhat you already know and what",
    "start": "462220",
    "end": "468509"
  },
  {
    "text": "you can try, you can start from\nthat and be more or less fancy. OK. So it goes without\nsaying, stop me.",
    "start": "468510",
    "end": "478830"
  },
  {
    "text": "I mean, the more we\ninteract, the better it is. So the first part,\nas I said, the idea",
    "start": "478830",
    "end": "483840"
  },
  {
    "text": "is to use so-called local\nmethods as an excuse to understand it by experience.",
    "start": "483840",
    "end": "488920"
  },
  {
    "text": "OK. So we're going to introduce\nthe simplest algorithm you can think of, and we're\ngoing to use it to understand",
    "start": "488920",
    "end": "494069"
  },
  {
    "text": "a much deeper concept. So first of all, let's\njust put down our setup.",
    "start": "494070",
    "end": "501030"
  },
  {
    "text": "The idea is that we are-- so how many of you had a\nmachine learning class before?",
    "start": "501030",
    "end": "507310"
  },
  {
    "text": "All right. So, you won't be too bored. The idea is we want to\ndo supervised learning.",
    "start": "507310",
    "end": "512919"
  },
  {
    "text": "So in supervised learning there\nis an input and an output. And these inputs and outputs\nare somewhat related.",
    "start": "512919",
    "end": "518599"
  },
  {
    "text": "And I'll be more\nprecise in a minute. But the idea is that\nyou want to learn this input-output relationship.",
    "start": "518599",
    "end": "524970"
  },
  {
    "text": "And all you have at disposal\nare sets of inputs and outputs. OK.",
    "start": "524970",
    "end": "530300"
  },
  {
    "text": "So x here is an input,\nand y is the output. f is a functional\nrelation between the input",
    "start": "530300",
    "end": "536350"
  },
  {
    "text": "and the output. All you have in this puzzle\nare these couples, OK. So I give an input,\nand then what's",
    "start": "536350",
    "end": "542239"
  },
  {
    "text": "the corresponding output? I give another input\nand I know what's the corresponding output. But I don't give\nyou all of them.",
    "start": "542239",
    "end": "547920"
  },
  {
    "text": "You just have n, OK. n\nis the number of points, and you call this\na training set,",
    "start": "547920",
    "end": "553355"
  },
  {
    "text": "because it will be the basis\nof knowledge in which you can try to train a machine\nto estimate this functional",
    "start": "553356",
    "end": "560579"
  },
  {
    "text": "relationship. OK. And the key point here\nis that, on the one hand,",
    "start": "560580",
    "end": "566680"
  },
  {
    "text": "you want to describe these data. So you want to get a\nfunctional relationship that works well that, if\nyou get the next one",
    "start": "566680",
    "end": "572910"
  },
  {
    "text": "to give you an f(x1), which\nis close to y1 and so on. And f(x2), which is close to y2.",
    "start": "572910",
    "end": "579630"
  },
  {
    "text": "But more importantly,\nyou want an f, that given a new point\nthat was not here,",
    "start": "579630",
    "end": "586360"
  },
  {
    "text": "will give you an\noutput, which is a good estimate\nof the true output to correspond to that input.",
    "start": "586360",
    "end": "591779"
  },
  {
    "text": "OK. This is the most important\nthing of the setup.",
    "start": "591780",
    "end": "597040"
  },
  {
    "text": "OK. The ideal, so-called\ngeneralization, if you want prediction. If you want to\nreally do inference. You don't want to do\ndescriptive statistics.",
    "start": "597040",
    "end": "603843"
  },
  {
    "text": "You really want to do\ninferential statistics. So this is just very,\nvery simple example,",
    "start": "603843",
    "end": "611389"
  },
  {
    "text": "but just to start to\nhave something in mind. Suppose that you have-- well, it's just like a toy\nversion of the face recognition",
    "start": "611390",
    "end": "620970"
  },
  {
    "text": "system we have on our phones. You know that when you\ntake a picture, you start--",
    "start": "620970",
    "end": "626244"
  },
  {
    "text": "AUDIENCE: Sorry. LORENZO ROSASCO: They\nreally weren't talking. You have something like this. You have a little square\nappearing around a face",
    "start": "626244",
    "end": "632610"
  },
  {
    "text": "sometimes. It means that basically\nthe system is actually going inside the image\nand recognizing faces.",
    "start": "632610",
    "end": "638130"
  },
  {
    "text": "OK. So the idea is a bit more\ncomplicated than this. But a toy version\nof this algorithm",
    "start": "638130",
    "end": "645180"
  },
  {
    "text": "is, you have an image like this. OK. The image you think of\nas a matrix of numbers.",
    "start": "645180",
    "end": "652170"
  },
  {
    "text": "Now this is color, but imagine\nit's black and white, OK. Then it would just\ncontain a number,",
    "start": "652170",
    "end": "657300"
  },
  {
    "text": "which is the pixel value\nwith the light intensity of that pixel.",
    "start": "657300",
    "end": "662520"
  },
  {
    "text": "And you just have this array. And then if you want you can\nbrutalize it with and just",
    "start": "662520",
    "end": "668699"
  },
  {
    "text": "unroll the matrix\ninto a long vector. OK. That gives one vector.",
    "start": "668700",
    "end": "674920"
  },
  {
    "text": "So p here would be what? The number of? Just the number of pixels.",
    "start": "674920",
    "end": "680660"
  },
  {
    "text": "OK. So I take this image\nand I unroll it. I take another image\nand I unroll it.",
    "start": "680660",
    "end": "685920"
  },
  {
    "text": "And I take images. And you see, some images\nhere do contain faces. Some of the images\ndo not contain faces.",
    "start": "685920",
    "end": "691691"
  },
  {
    "text": "OK. And I here use\ncolor to code them. And now what I have is that\nimages are my inputs, OK,",
    "start": "691691",
    "end": "698430"
  },
  {
    "text": "are the x's. So here-- full\ndisclosure, I never use",
    "start": "698430",
    "end": "703830"
  },
  {
    "text": "the little arrow above\nletters to denote vectors. So hopefully it will be\nclear from the context.",
    "start": "703830",
    "end": "708900"
  },
  {
    "text": "When it's really useful I\nuse upper or lower indices.",
    "start": "708900",
    "end": "715000"
  },
  {
    "text": "Anyway. So this is the data matrix. Rows are inputs and columns\nare so-called features",
    "start": "715000",
    "end": "721800"
  },
  {
    "text": "or variables, are the\nentries of each vector. OK. And I have n rows and p columns.",
    "start": "721800",
    "end": "729840"
  },
  {
    "text": "Associated to this, I\nhave my output vector. And what is the output vector? Well in this case, it's\njust a simple binary vector.",
    "start": "729840",
    "end": "737130"
  },
  {
    "text": "And the idea here is, if\nthere is a face, I put 1. If there is not a\nface, I put minus 1.",
    "start": "737130",
    "end": "744570"
  },
  {
    "text": "OK. So this is the way I turn,\nlike an abstract question, recognize faces in\nimages, into some data",
    "start": "744570",
    "end": "753485"
  },
  {
    "text": "structure that in a minute\nwe're going to elaborate to try to actually\nanswer the question, whether there is a face\nin an image or not.",
    "start": "753485",
    "end": "760340"
  },
  {
    "text": "OK. So this first step, it's\nkind of obvious in this case, but it's actually a tricky step.",
    "start": "760340",
    "end": "766751"
  },
  {
    "text": "OK. It's the part that I'm not going\nto give you any hint about. It's kind of an art.",
    "start": "766751",
    "end": "773010"
  },
  {
    "text": "You have data and you have-- at the very beginning\nyou have to turn them into some kind of\nmanageable data structure.",
    "start": "773010",
    "end": "779271"
  },
  {
    "text": "OK. Then you can elaborate\nin multiple ways. But the very first step is\nyou deciding-- for example, here we decided to unroll all\nthese numbers into vectors.",
    "start": "779271",
    "end": "787600"
  },
  {
    "text": "This sounds like a good\nidea or a bad idea? One thing that you're\ndoing is that the pixel here and the pixel here\nare probably related.",
    "start": "787600",
    "end": "794910"
  },
  {
    "text": "And in this case there is\nsome structure in the image. And so when you take this\npixel 136, and you unroll it,",
    "start": "794910",
    "end": "802540"
  },
  {
    "text": "it comes here. So they're not close. OK. Now here it turns out that\nif you think about it--",
    "start": "802540",
    "end": "808019"
  },
  {
    "text": "you'll see a minute. For those of you who\nremember, if you just took Euclidean distance,\nyou take product of numbers and you sum them up.",
    "start": "808020",
    "end": "813660"
  },
  {
    "text": "That's invariant to the position\nof the individual pixels. So that's OK. OK. But yet again, there is\nthis intuition that, well,",
    "start": "813660",
    "end": "819813"
  },
  {
    "text": "maybe here I'm losing too\nmuch geometric information about the context of the image. And indeed, while this\nkind of works in practice,",
    "start": "819813",
    "end": "826868"
  },
  {
    "text": "but if you want to\nget better results you have to do the fancy\nstuff that Andrei was talking about today, looking locally\nand try to look at collection,",
    "start": "826869",
    "end": "833420"
  },
  {
    "text": "try to keep more\ngeometric information. OK. So I'm not going to talk\nabout that kind of stuff.",
    "start": "833420",
    "end": "838480"
  },
  {
    "text": "This up to date, a lot of\nengineering, and some good way to learn it.",
    "start": "838480",
    "end": "843769"
  },
  {
    "text": "But we're going to\ntry to just stick to simple representations. OK. So how do you build\nrepresentation is now",
    "start": "843770",
    "end": "850080"
  },
  {
    "text": "going to be part of what\nI'm going to talk about. So imagine that\neither and you stick",
    "start": "850080",
    "end": "856040"
  },
  {
    "text": "to this super-simple\nrepresentation or some friends of yours come in\nand put the box here in the middle, where you\nput this array of numbers",
    "start": "856040",
    "end": "864320"
  },
  {
    "text": "and you extract another\nvector much fancier than this that contains some better\nrepresentation of an image.",
    "start": "864320",
    "end": "871320"
  },
  {
    "text": "OK. But then at the end\nof the day, my job starts when you give me\na vector representation",
    "start": "871320",
    "end": "876529"
  },
  {
    "text": "that I can trust. And I can basically say that\nif two vectors seem similar, they should have the same label.",
    "start": "876530",
    "end": "883480"
  },
  {
    "text": "And that's the basic idea. OK.  All right.",
    "start": "883480",
    "end": "888560"
  },
  {
    "text": "So a little game\nhere is, OK, imagine that these are just the\ntwo-pixel version of the images",
    "start": "888560",
    "end": "894260"
  },
  {
    "text": "I showed you before. You have some\nboxes, some circles. And then I give you\nthis one triangle.",
    "start": "894260",
    "end": "900904"
  },
  {
    "text": "It's very original. Andrei showed you\nthis yesterday. And the question is,\nwhat's the color of that?",
    "start": "900905",
    "end": "906410"
  },
  {
    "text": "OK. Unless you haven't\nslept a minute, you're going to say it's orange.",
    "start": "906410",
    "end": "912260"
  },
  {
    "text": "But the question is, why\ndo you think it's orange? AUDIENCE: [INAUDIBLE] LORENZO ROSASCO: Say it again?",
    "start": "912260",
    "end": "918130"
  },
  {
    "text": "AUDIENCE: It's\nsurrounded by oranges. LORENZO ROSASCO: It's\nsurrounded by oranges. OK. And she said, it's\nclose to oranges.",
    "start": "918130",
    "end": "924230"
  },
  {
    "text": " So it turns out that this\nis actually the simplest algorithm you can think of.",
    "start": "924230",
    "end": "929871"
  },
  {
    "text": "OK. You check who you have close\nto you, and if it's orange, you say orange. And if it's blue, you say blue.",
    "start": "929871",
    "end": "937209"
  },
  {
    "text": "OK. But we already made\nan assumption here, which we ask in the question,\nwhich is the nearby things.",
    "start": "937210",
    "end": "944070"
  },
  {
    "text": "So we are basically saying that\nour of vectoral representation is such that, if two\nthings are close-- so I do have a distance,\nand if two things are close,",
    "start": "944070",
    "end": "951699"
  },
  {
    "text": "then they might have the\nsame semantic content. OK. Which might be true or not. For example, if you take\nthis thing I showed you here,",
    "start": "951700",
    "end": "961120"
  },
  {
    "text": "we cannot just draw it, right? We cannot just take 200 times\n200 vectors and just look",
    "start": "961120",
    "end": "966280"
  },
  {
    "text": "at them and say, yeah, you\nknow, a visual inspection. You have to believe that\nthis distance will be fine. And so the discussion that\nwe just had about what",
    "start": "966280",
    "end": "972760"
  },
  {
    "text": "is a good representation\nis going to kick in. OK. But the assumption you make-- in this case visually it's\nvery easy, it's low dimension--",
    "start": "972760",
    "end": "981570"
  },
  {
    "text": "is that nearby things\nhave similar labels. One thing that I forgot to tell\nyou in the previous slides, but it's key, is\nexactly this observation",
    "start": "981570",
    "end": "988570"
  },
  {
    "text": "that in machine learning\nwe typically move away from situations\nlike this one, where",
    "start": "988570",
    "end": "994720"
  },
  {
    "text": "you can do visual inspection\nand you have low dimensionality, to kind of a situation like\nthe one I just showed you",
    "start": "994720",
    "end": "1000240"
  },
  {
    "text": "a minute before,\nwhere you have images. And if you have to think of each\nof these circles as an image,",
    "start": "1000240",
    "end": "1005667"
  },
  {
    "text": "you want to be able to\ndraw it, because it's going to be several\nhundred typically, or tens dimensional vector.",
    "start": "1005667",
    "end": "1013100"
  },
  {
    "text": "OK. So the game is\nkind of different. Can we still do\nthis kind of stuff?",
    "start": "1013100",
    "end": "1018390"
  },
  {
    "text": "Can we just say that\nclosed things should have the same semantic content?",
    "start": "1018390",
    "end": "1023580"
  },
  {
    "text": "That's another question\nwe're going to try to answer. OK. But I just want to do\na bit of inception. This is a big deal, OK,\ngoing from low dimension",
    "start": "1023580",
    "end": "1030630"
  },
  {
    "text": "to very high dimensions. All right. But let's stick for\na minute to the idea that nearby things should\nhave the same label,",
    "start": "1030630",
    "end": "1038640"
  },
  {
    "text": "and just write the one line,\nwrite down the algorithm. It's the kind of case where\nit's harder to write it down",
    "start": "1038640",
    "end": "1044609"
  },
  {
    "text": "than to code it up or\njust explain what it is. It's super simple. What you do is, you\nhave data points, Xi.",
    "start": "1044609",
    "end": "1052299"
  },
  {
    "text": "So Xi is the training set, the\ninput data in the training set. X-bar is what I\ncall X-new before.",
    "start": "1052300",
    "end": "1059530"
  },
  {
    "text": "It's a new point. What you do is that you search. This just says, look for the\nindex of the closest point.",
    "start": "1059530",
    "end": "1069059"
  },
  {
    "text": "That's what you did before. OK. So here, I-prime is the index of\nthe point Xi closest to X-bar.",
    "start": "1069060",
    "end": "1077850"
  },
  {
    "text": "Once you find it,\ngo in your dataset and find the label\nof that point.",
    "start": "1077850",
    "end": "1084570"
  },
  {
    "text": "And then assign that\nlabel to the new point. Does that makes sense?",
    "start": "1084570",
    "end": "1090090"
  },
  {
    "text": "Everybody's happy? Not super-complicated.",
    "start": "1090090",
    "end": "1095810"
  },
  {
    "text": "Fair enough. How does it work?",
    "start": "1095810",
    "end": "1100960"
  },
  {
    "text": "So let me see if I can do this. ",
    "start": "1100960",
    "end": "1107570"
  },
  {
    "text": "This is extremely fancy code. ",
    "start": "1107570",
    "end": "1113702"
  },
  {
    "text": "Let's see. All right. So what did I do?",
    "start": "1113702",
    "end": "1118710"
  },
  {
    "text": "Let me do it a bit smaller. So this is just simple\ntwo-dimensional datasets. I take 40 points.",
    "start": "1118710",
    "end": "1124550"
  },
  {
    "text": " The dataset looks like this.",
    "start": "1124550",
    "end": "1131034"
  },
  {
    "text": "The dataset is the\none on the left. OK. And what I do, I take 40 points.",
    "start": "1131035",
    "end": "1136700"
  },
  {
    "text": "And to make it a\nbit more complex, I flip some of the labels. OK. So you basically\nsay that the two",
    "start": "1136700",
    "end": "1142925"
  },
  {
    "text": "datasets-- this is called\nthe two moons dataset, or something like this. And what I did is that some\nof the labels in this sea,",
    "start": "1142925",
    "end": "1149525"
  },
  {
    "text": "I changed color. I changed the label. OK. So I made the\nproblem a bit harder. And here is what fortunately\nyou don't have in practice.",
    "start": "1149525",
    "end": "1158330"
  },
  {
    "text": "OK. Here we're cheating. We're doing just\nthe simulations. We're looking at the future. We assume that because we\ncan generate this data,",
    "start": "1158330",
    "end": "1165276"
  },
  {
    "text": "we can look at the future\nand check how we're going to do in future data. So you can think of\nthis as a future data that typically you don't have.",
    "start": "1165276",
    "end": "1171240"
  },
  {
    "text": "So here you're a\nnormal human being. Here you're playing god\nand looking at the future. OK. Because we just want to\ndo a little simulation.",
    "start": "1171240",
    "end": "1178224"
  },
  {
    "text": " So based on that, we can just\ngo here and put 1, train,",
    "start": "1178224",
    "end": "1191779"
  },
  {
    "text": "and then test and plot.  So what you see here is the\nso-called decision boundary.",
    "start": "1191780",
    "end": "1200830"
  },
  {
    "text": "OK. What I did is exactly that one\nline of code you saw before. OK.",
    "start": "1200830",
    "end": "1206360"
  },
  {
    "text": "And what I did is, in\nthis case I can draw it, because it's low dimensional. And basically what I do is\nthat I just put in the regions",
    "start": "1206360",
    "end": "1212000"
  },
  {
    "text": "where I think I\nshould put orange, and the region where it\nthink I should put blue.",
    "start": "1212000",
    "end": "1218281"
  },
  {
    "text": "OK. And here you can kind\nof see what's going on. These are actually very\ngood on the data, right?",
    "start": "1218281",
    "end": "1226370"
  },
  {
    "text": "How many mistakes do you\nmake on the new dataset? Sorry, on the training set?",
    "start": "1226370",
    "end": "1232790"
  },
  {
    "text": "Zero. It's perfect. OK. Is that a good idea? Well, when you look at it here,\nit doesn't look that good.",
    "start": "1232790",
    "end": "1239651"
  },
  {
    "text": "OK. There is this whole\nregion of points, for example, that are going\nto be predicted to be orange,",
    "start": "1239651",
    "end": "1249470"
  },
  {
    "text": "but they're actually blue. Of course if you want to have\nzero errors in the training set, there's nothing\nelse you can do, right?",
    "start": "1249470",
    "end": "1255289"
  },
  {
    "text": "Because you see, you have\nthis orange point here. You have these two\norange points here. And you want to go\nand follow them.",
    "start": "1255289",
    "end": "1261200"
  },
  {
    "text": "So there's nothing you can do. So this is the\nfirst observation. The second observation\nis, the curve,",
    "start": "1261200",
    "end": "1268470"
  },
  {
    "text": "if you look close enough,\nit's piecewise linear. It's like a sequence of\nlinear pieces stuck together.",
    "start": "1268470",
    "end": "1279200"
  },
  {
    "text": "If we just try to\ndo a little game and generate some new data-- OK, so imagine again,\nI'm playing god now.",
    "start": "1279200",
    "end": "1285810"
  },
  {
    "text": "I generate the new dataset\nthat it should look like. So take another peek at this. OK.",
    "start": "1285810",
    "end": "1293100"
  },
  {
    "text": "Oop. ",
    "start": "1293100",
    "end": "1300820"
  },
  {
    "text": "So now I generate them. I plot them. ",
    "start": "1300820",
    "end": "1306445"
  },
  {
    "text": "I train.  And now let's test. ",
    "start": "1306445",
    "end": "1314049"
  },
  {
    "text": "OK. If you remember the decision\ncurves you've seen before, what do you notice here?",
    "start": "1314050",
    "end": "1319255"
  },
  {
    "text": "AUDIENCE: they're different LORENZO ROSASCO:\nThey're very different. OK. For example, the one\nbefore, if you remember,",
    "start": "1319255",
    "end": "1326770"
  },
  {
    "text": "we noticed it was going all\nthe way down here to follow those couple of points. But here you don't have\nthose couple of points.",
    "start": "1326770",
    "end": "1332750"
  },
  {
    "text": "OK. So now, is that a good\nthing or a bad thing? Well the point here\nis that because you have so few points, the\nmoment you start to just feed",
    "start": "1332750",
    "end": "1340510"
  },
  {
    "text": "the data, this will happen. OK. You have something that\nchanges all the time. It's very unstable.",
    "start": "1340510",
    "end": "1345789"
  },
  {
    "text": "That's a key word, OK. You have something\nthat you change the data just a little bit,\nand it changes completely.",
    "start": "1345790",
    "end": "1350920"
  },
  {
    "text": "That sounds like a bad idea. OK. If I want to make\na prediction, if I keep on getting\nslightly different data",
    "start": "1350920",
    "end": "1357250"
  },
  {
    "text": "and I change my mind\ncompletely, that's probably not a good way to make\na prediction about anything. OK. And this is happening\nall the time here.",
    "start": "1357250",
    "end": "1363430"
  },
  {
    "text": "And it's exactly\nbecause our algorithm is in some sense is greedy. You just try to get\nperfect performance",
    "start": "1363430",
    "end": "1369670"
  },
  {
    "text": "on the training set without\nworrying much about the future.",
    "start": "1369670",
    "end": "1375630"
  },
  {
    "text": "Let's do this just once more. ",
    "start": "1375630",
    "end": "1388340"
  },
  {
    "text": "OK. And we keep on going. It's going to change all\nthe time, all the time.",
    "start": "1388340",
    "end": "1393810"
  },
  {
    "text": "Of course-- I\ndon't know how much I can push this because\nit's not super-duper fast.",
    "start": "1393810",
    "end": "1400910"
  },
  {
    "text": "But let's try.  Let's say 18 by 30.",
    "start": "1400910",
    "end": "1406620"
  },
  {
    "start": "1406620",
    "end": "1416410"
  },
  {
    "text": "So what I did now is just that\nI augmented the number of points in my training set. It was 20 or 30,\nI don't remember.",
    "start": "1416410",
    "end": "1422200"
  },
  {
    "text": "Now it make it 100. So now you should see--",
    "start": "1422200",
    "end": "1427830"
  },
  {
    "text": "OK. So this is one solution. We want to play the same game. We just want to generate\nother datasets of the same.",
    "start": "1427830",
    "end": "1434029"
  },
  {
    "text": "So maybe now it might\nbe that I took them all.",
    "start": "1434030",
    "end": "1439040"
  },
  {
    "text": "I don't remember\nhow many there are. ",
    "start": "1439040",
    "end": "1446230"
  },
  {
    "text": "No, I didn't take them all. So, what do you see now? We are doing exactly\nthe same thing.",
    "start": "1446230",
    "end": "1451430"
  },
  {
    "text": "OK. And is this something that\nyou can absolutely not to do in practice, because you\ncannot just generate datasets.",
    "start": "1451430",
    "end": "1457750"
  },
  {
    "text": "But here what you\nsee is that I just augmented the number\nof training set points.",
    "start": "1457750",
    "end": "1463920"
  },
  {
    "text": "And what you see is now\nthe solution does change, but not as much. OK. And you can kind of start to\nsee that there is something",
    "start": "1463920",
    "end": "1470840"
  },
  {
    "text": "going on a bit like this here. OK. So this one actually\nlooks pretty bad.",
    "start": "1470840",
    "end": "1476630"
  },
  {
    "text": "Let's try to do it once more. ",
    "start": "1476630",
    "end": "1486980"
  },
  {
    "text": "OK. So again, it does change a\nlot, but not as much as before. And you roughly\nsee that this guy",
    "start": "1486980",
    "end": "1493340"
  },
  {
    "text": "says that, here it should be\norange and here should be blue. OK.",
    "start": "1493340",
    "end": "1498500"
  },
  {
    "text": "So that's kind of\nwhat you expect. The more points you get, the\nbetter your solution would get.",
    "start": "1498500",
    "end": "1503820"
  },
  {
    "text": "And if I put hear all\nthe possible points, what you will start to see is that\nthe closest point to any point",
    "start": "1503820",
    "end": "1509510"
  },
  {
    "text": "here will be a blue point. OK. So it will be perfect. So if I ask you if this\nis a good algorithm",
    "start": "1509510",
    "end": "1515870"
  },
  {
    "text": "or not, what would you say? ",
    "start": "1515870",
    "end": "1521331"
  },
  {
    "text": "AUDIENCE: It's\noverfitting the data. LORENZO ROSASCO: It's kind\nof a overfitting the data. But it is not always\noverfitting the data.",
    "start": "1521331",
    "end": "1526700"
  },
  {
    "text": "If the data are good, it's\na good idea to fit them. OK. But in some sense,\nthis algorithm doesn't have a way\nto prevent itself",
    "start": "1526700",
    "end": "1532790"
  },
  {
    "text": "to fall in love with the\ndata when there are very few. And if you have very\nfew data points, you start to just wiggle around,\nbecome extremely unstable,",
    "start": "1532790",
    "end": "1539570"
  },
  {
    "text": "change your mind all the time. If the data are\nenough, it stabilizes, and in some senses,\nthis setting, we're fitting the data,\nor as she's saying,",
    "start": "1539570",
    "end": "1547070"
  },
  {
    "text": "overfitting the data. It's actually not a bad thing. OK. So this is what's going on here. AUDIENCE: What do you\nmean by overfitting?",
    "start": "1547070",
    "end": "1554050"
  },
  {
    "text": "LORENZO ROSASCO:\nFitting a bit too much. So if you look here. So here, if you look\nwhat you're doing here,",
    "start": "1554050",
    "end": "1560580"
  },
  {
    "text": "you're always\nfitting the data OK. But here you're\ndoing nothing else. And so if you have\nfew data points,",
    "start": "1560580",
    "end": "1565910"
  },
  {
    "text": "fitting the data is fine. Sorry, if you have\nmany data points, fitting the data is just fine.",
    "start": "1565910",
    "end": "1571110"
  },
  {
    "text": "If you have few data\npoints, by fitting them you, in some sense,\noverfit in the sense",
    "start": "1571110",
    "end": "1577010"
  },
  {
    "text": "that when you look\nat new data points, you have done a bit too much. OK. What you saw before,\nthat you get something",
    "start": "1577010",
    "end": "1582551"
  },
  {
    "text": "that is very good, because\nit perfectly fits that, but it's overfitting with\nrespect to the future. Whereas here, the fitting\non the left-hand side",
    "start": "1582551",
    "end": "1590870"
  },
  {
    "text": "kind of reflects, not\ntoo badly the fitting on the right-hand side. OK.",
    "start": "1590870",
    "end": "1595950"
  },
  {
    "text": "So the idea of\noverfitting and stability that came out in this\ndiscussion are key. OK.",
    "start": "1595950",
    "end": "1601430"
  },
  {
    "text": "If you want\neverything we're going to do in the next\nthree hours, understand how you can prevent overfitting\nand build a good way",
    "start": "1601430",
    "end": "1608809"
  },
  {
    "text": "to stabilize your algorithms.",
    "start": "1608810",
    "end": "1614370"
  },
  {
    "text": "OK. So let's go back here. This is going to be quick,\nbecause if I ask you,",
    "start": "1614370",
    "end": "1620660"
  },
  {
    "text": "what is this? What would you say? AUDIENCE: [INAUDIBLE] ",
    "start": "1620660",
    "end": "1626600"
  },
  {
    "text": "[LAUGHING]  LORENZO ROSASCO: So\nthe idea is that, when",
    "start": "1626600",
    "end": "1631680"
  },
  {
    "text": "you have a situation\nlike this, you're still pretty much able to\nsay what's the right answer. And what you're going\nto do is that you're",
    "start": "1631680",
    "end": "1637210"
  },
  {
    "text": "going to move away from\njust saying, what's the closest point, and you\njust look at a few more points.",
    "start": "1637210",
    "end": "1642560"
  },
  {
    "text": "You just don't look at one. OK. You look at, how many? boh?",
    "start": "1642560",
    "end": "1647610"
  },
  {
    "text": "\"boh\" is very\nuseful Italian word. It means, I don't know. ",
    "start": "1647610",
    "end": "1652720"
  },
  {
    "text": "So these algorithm-- it's\ncalled the k nearest neighbor algorithm, it's probably the\nsecond simplest algorithm",
    "start": "1652720",
    "end": "1658649"
  },
  {
    "text": "you can think of. It's kind of the same as before. The notation here\nis a bit boring, but it's basically\nsaying, take the points.",
    "start": "1658650",
    "end": "1665395"
  },
  {
    "text": "Give them new points. Check the distance\nwith everybody. Sort it and take the first k. OK.",
    "start": "1665395",
    "end": "1671676"
  },
  {
    "text": "If it's a\nclassification problem, it's probably a good idea\nto take an odd number for k,",
    "start": "1671676",
    "end": "1677167"
  },
  {
    "text": "so that you can then\njust have voting. And basically everybody votes. Each vote counts one. And somebody says blue,\nsomebody says orange,",
    "start": "1677167",
    "end": "1684929"
  },
  {
    "text": "and you make a decision. OK. Fair enough.",
    "start": "1684930",
    "end": "1690150"
  },
  {
    "text": "Well how does this work? You can kind of imagine. ",
    "start": "1690150",
    "end": "1696960"
  },
  {
    "text": "So what we have to do-- so for example here\nwe have this guy. OK. Now let's just put k--",
    "start": "1696960",
    "end": "1703110"
  },
  {
    "text": "well, let's make\nthis a bit smaller. So we do 40. Generate, plot, train.",
    "start": "1703110",
    "end": "1711510"
  },
  {
    "text": "[INAUDIBLE] test. Plot. OK. Well we got a bit lucky, OK.",
    "start": "1711510",
    "end": "1718650"
  },
  {
    "text": "This is actually a good\ndataset, because in some sense there are no, what you\nmight call outliers.",
    "start": "1718650",
    "end": "1724140"
  },
  {
    "text": "There are no orange points that\nreally go and sit in the blue. So I just want to show you a\nbit about the dramatic effect",
    "start": "1724140",
    "end": "1729810"
  },
  {
    "text": "of this. So I'm going to just\ntry to redo this one so that we get the more-- yeah, this should do.",
    "start": "1729810",
    "end": "1735317"
  },
  {
    "text": " OK. So this is nearest neighbor. This is the solution you get.",
    "start": "1735317",
    "end": "1742000"
  },
  {
    "text": "It's not too horrible. But, for example, you see that\nit starts following this guy. OK.",
    "start": "1742000",
    "end": "1748179"
  },
  {
    "text": "Now, what you can do is that you\ncan just go in and say, four. Well, four's a bad idea.",
    "start": "1748180",
    "end": "1753330"
  },
  {
    "text": "Five. You'd retrain them the same. ",
    "start": "1753330",
    "end": "1760020"
  },
  {
    "text": "And all of a sudden it\njust ignores this guy. Because the moment that\nyou put more in, well,",
    "start": "1760020",
    "end": "1765100"
  },
  {
    "text": "you just realize that he's\nsurrounded by blue guys, so it's probably just, his vote\njust counts one against four.",
    "start": "1765100",
    "end": "1772230"
  },
  {
    "text": "OK. And you can keep on going. And the idea here is that\nthe more you make this big,",
    "start": "1772230",
    "end": "1782600"
  },
  {
    "text": "the more your solution\nis going to be, what? Well you say, it's\ngoing to be good,",
    "start": "1782600",
    "end": "1788760"
  },
  {
    "text": "but it's actually not true. Because if you start\nto put k too big, at some point all you're doing\nis counting how many points you",
    "start": "1788760",
    "end": "1796250"
  },
  {
    "text": "have in class one,\ncounting how many points you have in class two, and\nalways say the same thing.",
    "start": "1796250",
    "end": "1802741"
  },
  {
    "text": "OK. So I'm going to put here, 20. What you start to\nsee is that you",
    "start": "1802741",
    "end": "1808790"
  },
  {
    "text": "start to obtain a decision\nboundary, which is simpler, and simpler and simpler. OK.",
    "start": "1808790",
    "end": "1814280"
  },
  {
    "text": "It looks kind of linear here. What you will see is\nthat, suppose that now I regenerate the data.",
    "start": "1814280",
    "end": "1823161"
  },
  {
    "text": "And you remember\nhow much it changed before when I was using\nnearest neighbor with just k equal to 1.",
    "start": "1823161",
    "end": "1831030"
  },
  {
    "text": "So of course here, you\nknow, it's probabilistic. OK. So of course I'm going to get\na dataset like the one I just",
    "start": "1831030",
    "end": "1836179"
  },
  {
    "text": "showed you minutes ago, and\nI had it as fast as possible. Because if I pick\n10, one is going to look like that and nine\nare going to look like this.",
    "start": "1836180",
    "end": "1843260"
  },
  {
    "text": "OK. And when they look\nlike this, you see, they kind of start\nto have this kind of line, like a decision boundary\nwith some twists.",
    "start": "1843260",
    "end": "1849769"
  },
  {
    "text": "But it's very simple. OK. And if at some point, if I\nput k big enough-- that is, the number of all points,\nit won't change any more.",
    "start": "1849770",
    "end": "1856200"
  },
  {
    "text": "OK. It will just be\nessentially dividing the sets in two equal parts.",
    "start": "1856200",
    "end": "1861350"
  },
  {
    "text": "So does that makes sense? So would it make sense to\nvote to make different votes?",
    "start": "1861350",
    "end": "1869960"
  },
  {
    "text": "Essentially, the idea is,\nif the point is closest, his vote should count more than\nif a point is more far away?",
    "start": "1869960",
    "end": "1876120"
  },
  {
    "text": "Yes, absolutely. Let's say here we're\nmaking the simplest thing in the world, the second\nsimplest thing in the world,",
    "start": "1876120",
    "end": "1881919"
  },
  {
    "text": "the third simplest\nthing in the world. It is doing that. OK. And you can see that you\ncan go pretty far with this. I mean, it's simple, but\nthese are actually algorithms",
    "start": "1881920",
    "end": "1888180"
  },
  {
    "text": "that are used sometimes. And what you do is that,\nif you just look at this--",
    "start": "1888180",
    "end": "1894724"
  },
  {
    "text": "again, these I don't\nwant to explain too much. If you've seen it\nbefore, it's simple. Otherwise it doesn't\nreally matter. But the basic idea\nhere is that each vote",
    "start": "1894724",
    "end": "1902909"
  },
  {
    "text": "is going to be\nbetween 0-- so, you see here I put the distance\nbetween the new point and all",
    "start": "1902910",
    "end": "1908820"
  },
  {
    "text": "the other points on\ntop of an exponential. So the number I get is not\n1, but it is between 0 and 1.",
    "start": "1908820",
    "end": "1915040"
  },
  {
    "text": "If the two points are close,\nand the limits supposedly are the same, it becomes a\n0, and it counts exactly one.",
    "start": "1915040",
    "end": "1921540"
  },
  {
    "text": "If they're very far away,\nthese would be, say, infinity and then we'd be close to 0.",
    "start": "1921540",
    "end": "1926820"
  },
  {
    "text": "So the closest you are,\nthe more you count. If you want, you can\nread it like this. You're sitting on a new point,\nand you put a zooming window.",
    "start": "1926820",
    "end": "1937400"
  },
  {
    "text": "Yeah, like a zooming\nwindow of a certain size. And you basically\ncheck that everything which is inside this\nwindow will be closed.",
    "start": "1937400",
    "end": "1944029"
  },
  {
    "text": "And the more you go\nfarther away-- so the window is like this. And you deform the space\nso that basically what",
    "start": "1944029",
    "end": "1950039"
  },
  {
    "text": "you say is, things\nthat are far away, they're going to count less. And if I move sigma\nhere, I'm somewhat",
    "start": "1950040",
    "end": "1957660"
  },
  {
    "text": "making my visual field, if\nyou want, larger or smaller, around this one new point.",
    "start": "1957660",
    "end": "1963549"
  },
  {
    "text": "It's just a physical\ninterpretation of what this is doing. There are 15 other\nways of looking at what the Gaussian is doing.",
    "start": "1963550",
    "end": "1969630"
  },
  {
    "text": "Voting, changing the weight\nof the vote is another one. OK. Why the Gaussian here?",
    "start": "1969630",
    "end": "1975179"
  },
  {
    "text": "Well, because. Just because. You can use many, many others. You can use, for\nexample, a hat window.",
    "start": "1975180",
    "end": "1981090"
  },
  {
    "text": "And this is part of\nyour prior knowledge, how much you want to weight. If you are in this kind of\nlow dimensional situation,",
    "start": "1981090",
    "end": "1989580"
  },
  {
    "text": "you might have good ways to\njust look inside the data and decide almost like doing\nby a visual inspection.",
    "start": "1989580",
    "end": "1994599"
  },
  {
    "text": "Otherwise you have to trust\nsome more broad principles. And it's again\nback to the problem of learning the\nrepresentation and deciding",
    "start": "1994599",
    "end": "2000710"
  },
  {
    "text": "how to measure\ndistance, which are two phases of the same story. OK. ",
    "start": "2000710",
    "end": "2009490"
  },
  {
    "text": "And the other thing\nyou see is that, if you start to do these games,\nyou might actually",
    "start": "2009490",
    "end": "2015370"
  },
  {
    "text": "add more parameters. OK. Because we start from\nnearest neighbor, which is completely\nparameter-free,",
    "start": "2015370",
    "end": "2020830"
  },
  {
    "text": "but it was very unstable. We added k. We allow ourselves to go\nfrom simple to complex,",
    "start": "2020830",
    "end": "2025929"
  },
  {
    "text": "from stability to overfitting. But we introduced\na new parameter. And so that's not an\nalgorithm any more.",
    "start": "2025930",
    "end": "2031910"
  },
  {
    "text": "It's a half algorithm. A true algorithm is a\nparameter-free algorithm where I tell you how\nyou choose everything. OK.",
    "start": "2031910",
    "end": "2037500"
  },
  {
    "text": "So if they just give\nyou something, say, yeah, there's k, well,\nhow do you choose it? OK.",
    "start": "2037500",
    "end": "2043240"
  },
  {
    "text": "It's not something you can use. And here I'm adding sigma. And again, you have to\ndecide how you use it.",
    "start": "2043240",
    "end": "2048620"
  },
  {
    "text": "OK. And so that's what we\nwant to ask in a minute. So before doing that,\njust a side remark is--",
    "start": "2048621",
    "end": "2057580"
  },
  {
    "text": "we've been looking\nat vector data. OK. And we were basically\nmeasuring distance through just the Euclidean\nnorm, OK, just the usual one,",
    "start": "2057580",
    "end": "2064360"
  },
  {
    "text": "or this version like\nthe Gaussian kernel that somewhat\namplifies distances.",
    "start": "2064360",
    "end": "2070690"
  },
  {
    "text": "What if you have strings,\nfor example, or graphs? OK. Your data turns\nout to be strings",
    "start": "2070690",
    "end": "2076569"
  },
  {
    "text": "and you want to compare them?  Say even if they're\nbinary strings,",
    "start": "2076570",
    "end": "2082210"
  },
  {
    "text": "there's no linear structure. You cannot just sum them\nup. the Euclidean distance doesn't really make\na lot of sense.",
    "start": "2082210",
    "end": "2088580"
  },
  {
    "text": "But what you can\ndo is that as long as you can define a\ndistance-- and say this one would be the simplest one,\njust the Hamming distance.",
    "start": "2088580",
    "end": "2094840"
  },
  {
    "text": "You just check entries,\nand if they're the same, you count one. If they're different,\nyou count zero. OK.",
    "start": "2094840",
    "end": "2100600"
  },
  {
    "text": "The moment you can define\na distance of your data, then you can use this\nkind of technique.",
    "start": "2100600",
    "end": "2106760"
  },
  {
    "text": "So this technique is pretty\nflexible in that sense, that whenever you can\ngive-- you don't need",
    "start": "2106760",
    "end": "2112296"
  },
  {
    "text": "a vectoral\nrepresentation, you just need a way to measure,\nsay, similarity or distances between things, and\nthen you can use this method.",
    "start": "2112296",
    "end": "2119060"
  },
  {
    "text": "OK. So here I just mentioned\nthis, and that's what most of these classes are\ngoing to be, about vector data.",
    "start": "2119060",
    "end": "2124520"
  },
  {
    "text": "But this is one point where,\nthe moment you have k-- you can think of this case\nsometimes as a similarity.",
    "start": "2124520",
    "end": "2131450"
  },
  {
    "text": "OK. Similarity is kind of concept\nthat is dual to distances. So if the similarity\nis big, it's good.",
    "start": "2131450",
    "end": "2136700"
  },
  {
    "text": "The distance small is good. OK. And so here, if you have a way\nto build the k or a distance,",
    "start": "2136700",
    "end": "2142040"
  },
  {
    "text": "then you're good to go. And we're not going to\nreally talk about it, but there's a whole\nindustry about how",
    "start": "2142040",
    "end": "2148232"
  },
  {
    "text": "you build this kind of stuff. So we give restraints. Maybe I want to say\nthat I should not only",
    "start": "2148232",
    "end": "2153830"
  },
  {
    "text": "look at the entry of a string,\nbut also the nearby entry when I make the score\nfor that specific.",
    "start": "2153830",
    "end": "2158859"
  },
  {
    "text": "So maybe I shifted a value\nof the string a little bit. It's not right here. It's in the next position over,\nso that should come to bits.",
    "start": "2158860",
    "end": "2165560"
  },
  {
    "text": "So I want to do a\nsoft version of this. OK. Or maybe I have graphs, and\nI want to compare graphs.",
    "start": "2165560",
    "end": "2171560"
  },
  {
    "text": "And I want to say that if\ntwo graphs are close, then I want them to have\nthe same label. OK. How do you do that?",
    "start": "2171560",
    "end": "2178950"
  },
  {
    "text": "The next big question is-- we introduced three parameters.",
    "start": "2178950",
    "end": "2184219"
  },
  {
    "text": "They look really nice,\nbecause they kind of allowed us to get more flexible\nsolutions to the problem",
    "start": "2184219",
    "end": "2189430"
  },
  {
    "text": "by choosing, for example, k\nor the sigma in the Gaussian. We can go from\noverfitting to stability.",
    "start": "2189430",
    "end": "2195735"
  },
  {
    "text": "But then of course we have\nto choose the parameter, and we have to find good\nways to choose them. And so there are a\nbunch of questions.",
    "start": "2195736",
    "end": "2202175"
  },
  {
    "text": "So the first one is, well, is\nthere an optimal value at all? OK. Does it exist?",
    "start": "2202175",
    "end": "2208579"
  },
  {
    "text": "But if it does exist, I can go\ntry to estimate it in some way. If it doesn't, well it\ndoes not even make sense.",
    "start": "2208580",
    "end": "2214230"
  },
  {
    "text": "I just throw a random number. I just say, k equals 4. Why? Just because. OK. So what do you think?",
    "start": "2214230",
    "end": "2219730"
  },
  {
    "text": "It exists or not? What does it depend on? Because that's\nthe next question.",
    "start": "2219730",
    "end": "2225509"
  },
  {
    "text": "What does it depend on? Can we compute it? OK. So let's try to guess\none minute before we go",
    "start": "2225510",
    "end": "2230759"
  },
  {
    "text": "and check how we do this. OK. OK.",
    "start": "2230759",
    "end": "2235937"
  },
  {
    "text": "I have to choose it. How do I choose it? What does it depend on? AUDIENCE: Size of this. LORENZO ROSASCO: One thing\nis the size of the dataset.",
    "start": "2235937",
    "end": "2242650"
  },
  {
    "text": "Because what we saw is that a\nsmall k seems a good idea when you have a lot of data, but\nit seems like a bad idea",
    "start": "2242650",
    "end": "2249369"
  },
  {
    "text": "when you have few. OK. So it should depend. It should be\nsomething that scales",
    "start": "2249370",
    "end": "2254656"
  },
  {
    "text": "with n, the number of points,\nand probably also the training set itself. But we want something that\nworks for all datasets,",
    "start": "2254656",
    "end": "2260770"
  },
  {
    "text": "say, in expectation. So cardinality of\nthe training set is going to be a main factor. What else?",
    "start": "2260770",
    "end": "2266840"
  },
  {
    "text": "AUDIENCE: The smoothness\nof the boundary. LORENZO ROSASCO: The what? AUDIENCE: The smoothness. LORENZO ROSASCO: This\nsmoothness of the boundary. Yeah.",
    "start": "2266840",
    "end": "2272290"
  },
  {
    "text": "So what he's saying is, if\nmy problem looks like this, or if my problem\nlooks like this,",
    "start": "2272290",
    "end": "2277525"
  },
  {
    "text": "it looks like k\nshould be different. In this case I can take\nany arbitrary high k--",
    "start": "2277525",
    "end": "2284680"
  },
  {
    "text": "sorry, small k, I guess, or i. It doesn't matter,\nbecause whatever you do, you pretty much\nget the good thing.",
    "start": "2284680",
    "end": "2289888"
  },
  {
    "text": "But if you start doing\nsomething like this, then you want-- k is\nenough, because otherwise you just start to\nblur everything.",
    "start": "2289888",
    "end": "2295690"
  },
  {
    "text": "And this is exactly\nwhat he's saying. If your problem is\ncomplicated or it's easy. OK.",
    "start": "2295690",
    "end": "2301439"
  },
  {
    "text": "And at the same\ntime, this is related to the fact of how much noise\nyou might have in the data, OK, how much flipping you\nmight have in your data.",
    "start": "2301439",
    "end": "2309590"
  },
  {
    "text": "If the problem is hard, then you\nexpect to need a different k. OK.",
    "start": "2309590",
    "end": "2315010"
  },
  {
    "text": "So it depends on the\ncardinality of the data, and how complicated\nis the problem? How complicated it\nis the boundary?",
    "start": "2315010",
    "end": "2320128"
  },
  {
    "text": "How much noise do I have? OK. So it turns out that\none thing you can ask",
    "start": "2320128",
    "end": "2325450"
  },
  {
    "text": "is, can we prove it? OK. Can we prove a theorem that\nsays that there is an optimal k,",
    "start": "2325450",
    "end": "2331690"
  },
  {
    "text": "and it really does depends\non this, on this quantities.",
    "start": "2331690",
    "end": "2337569"
  },
  {
    "text": "And it turns out that you can. Of course, as always, to make a\ntheory or to make assumptions, you have to work within a model.",
    "start": "2337570",
    "end": "2343800"
  },
  {
    "text": "And the model we want to\nwork on is the following. You're basically\nsaying, this is the k nearest neighbor solution. So big k here is the\nnumber of neighbors,",
    "start": "2343800",
    "end": "2350520"
  },
  {
    "text": "and this is hat because\nit depends on the data. And what I say here\nis that I'm just going to look at squared loss\nerror, just because it's easy.",
    "start": "2350520",
    "end": "2357575"
  },
  {
    "text": "And I'm going to look at the\nregression problem, not just this classification. And what you do here\nis that you take",
    "start": "2357575",
    "end": "2362980"
  },
  {
    "text": "expectation over all\npossible input-output pairs. So basically you say,\nwhen I tried to do math,",
    "start": "2362980",
    "end": "2370160"
  },
  {
    "text": "I want to see what's ideal. An ideally I want\na solution that does well on future points. OK.",
    "start": "2370160",
    "end": "2375670"
  },
  {
    "text": "So how do I do that? I think the average error\nover all possible points in the future, x and y.",
    "start": "2375670",
    "end": "2381820"
  },
  {
    "text": "So this is the meaning of\nthis first expectation. Make sense?",
    "start": "2381820",
    "end": "2387070"
  },
  {
    "text": "Yes? No? So if they fix y and x, this is\nthe error on a specific couple",
    "start": "2387070",
    "end": "2394330"
  },
  {
    "text": "input and output. I give you the input. I do f(kx) and then I check\nif it's close or not to y.",
    "start": "2394330",
    "end": "2401049"
  },
  {
    "text": "But what I want to do if\nI want to be theoretical is to say, OK,\nwhat I would really like to be small is this error\nover all possible points.",
    "start": "2401049",
    "end": "2408461"
  },
  {
    "text": "So I take the expectation,\nnot the one on the training set, the one in the future. And I take expectation\nso that if points",
    "start": "2408461",
    "end": "2413980"
  },
  {
    "text": "are more likely\nto be simple, they will count more than points that\nare less likely to be simple.",
    "start": "2413980",
    "end": "2419050"
  },
  {
    "text": "OK. AUDIENCE: What was Es? LORENZO ROSASCO: We haven't\ngot to that one yet. OK.",
    "start": "2419050",
    "end": "2424360"
  },
  {
    "text": "So Exy is what I just said. What is Es? It's the expectation\nover the training set.",
    "start": "2424360",
    "end": "2430360"
  },
  {
    "text": "Why do we need that? Well because if we don't\nput that expectation, I'm basically telling you\nwhat's the good k for this one",
    "start": "2430360",
    "end": "2437290"
  },
  {
    "text": "training set here. Then I give you\nanother training set and I get another one, which\nis in some sense is good, but it's also bad,\nbecause we would",
    "start": "2437290",
    "end": "2442598"
  },
  {
    "text": "like to have a take-home\nmessage that we hold for all training sets. And this is the simplest.",
    "start": "2442598",
    "end": "2447640"
  },
  {
    "text": "You say, for the\naverage training set, this is how I should choose k.",
    "start": "2447640",
    "end": "2452697"
  },
  {
    "text": "That's what we want to do. OK. So the first expectation is\nto measure error with respect to the future. The second\nexpectation is to say,",
    "start": "2452697",
    "end": "2458811"
  },
  {
    "text": "I want to deal with\nthe fact that I have several potential\ntraining sets appearing. OK.",
    "start": "2458812",
    "end": "2466480"
  },
  {
    "text": "So in the next couple\nof slides, this red dot means that there\nare computations. OK. And so I want to\ndo them quickly.",
    "start": "2466480",
    "end": "2474340"
  },
  {
    "text": "And the important thing of\nthis bit is, it's an exercise. OK. So this is an exercise\nof stats zero.",
    "start": "2474340",
    "end": "2482550"
  },
  {
    "text": "OK. So we don't want to\nspend time doing that. The important thing is going\nto be the conceptual parts.",
    "start": "2482550",
    "end": "2488133"
  },
  {
    "text": "I'm going to go a bit\nquickly through it. So you start from\nthis, and you would like to understand\nif there exists--",
    "start": "2488133",
    "end": "2493724"
  },
  {
    "text": "so this is the quantity that\nyou would like to make small, ideally. You will never have\naccess to this,",
    "start": "2493724",
    "end": "2499450"
  },
  {
    "text": "but ideally, in the\noptimal scenario, you want k to make this small.",
    "start": "2499450",
    "end": "2505420"
  },
  {
    "text": "OK. Now the problem is that you want\nto essentially mathematically study this m minimization\nproblem, but it's not easy,",
    "start": "2505420",
    "end": "2511000"
  },
  {
    "text": "because, how do you do this? OK. The dependence of this\nfunction on k is complicated. It's that equation\nwe had before, right?",
    "start": "2511000",
    "end": "2517895"
  },
  {
    "text": "So you kind of just\ntake the derivative and set it equal to zero. Let's keep on going into to. So what we are at is,\nthese are the points",
    "start": "2517895",
    "end": "2523780"
  },
  {
    "text": "I would like to make small. I would like to choose k so\nthat I can make this small. I want to study this from a\nmathematical point of view.",
    "start": "2523780",
    "end": "2529480"
  },
  {
    "text": "But I cannot just use what\nyou're doing in calculus, which is taking a derivative\nand setting it equal to zero, because the dependence of these\ntwo k, which is my variable,",
    "start": "2529480",
    "end": "2536880"
  },
  {
    "text": "it's complicated. OK. So we go a bit of a round way. We turn out to be\npretty universal.",
    "start": "2536880",
    "end": "2541960"
  },
  {
    "text": "And this is what\nwe are going to do. ",
    "start": "2541960",
    "end": "2549540"
  },
  {
    "text": "First of all, we assume\na model for our data. And this is just for\nthe sake of simplicity. OK. I can use a much\nmore general model.",
    "start": "2549540",
    "end": "2557100"
  },
  {
    "text": "But this is the model. I'm going to say that my y\nare just some fixed function of star plus some noise.",
    "start": "2557100",
    "end": "2564720"
  },
  {
    "text": "OK. And the noise is zero\nmean and variance sigma",
    "start": "2564720",
    "end": "2571210"
  },
  {
    "text": "square for all entries. OK.",
    "start": "2571210",
    "end": "2576569"
  },
  {
    "text": "This is the simplest model. It's a Gaussian\nregression model. ",
    "start": "2576570",
    "end": "2587500"
  },
  {
    "text": "So one thing I'm doing,\nand this is like a trick and you can really\nforget it, but it just makes life much easier is that\nI take the expectation over xy",
    "start": "2587500",
    "end": "2595190"
  },
  {
    "text": "and a condition here. OK. The reason why you\ndo this is just to make the math a bit easier.",
    "start": "2595190",
    "end": "2600890"
  },
  {
    "text": "Because basically now, if\nyou put this expectation out, and you look just\nat these quantities, you're looking at\neverything for fixed x.",
    "start": "2600890",
    "end": "2606835"
  },
  {
    "text": "And these just become a real\nnumber, OK, not the function anymore. So you can use normal calculus.",
    "start": "2606835",
    "end": "2613280"
  },
  {
    "text": "You have a real-valued\nfunction and you can just use the usual stuff. OK. Again, I'm going to going\na bit quickly over this",
    "start": "2613280",
    "end": "2619700"
  },
  {
    "text": "because it doesn't\nreally matter. So this ingredient one. This is observation two. Observation three\nis that you need",
    "start": "2619700",
    "end": "2626000"
  },
  {
    "text": "to introduce an object\nbetween the solution you get in practice and\nthis ideal function.",
    "start": "2626000",
    "end": "2634490"
  },
  {
    "text": "What is this? It's this kind of, what\nis called the expectation of my algorithm.",
    "start": "2634490",
    "end": "2640700"
  },
  {
    "text": "What you do is that--\nin my algorithm what I do here is\nthat I put Yi, i OK,",
    "start": "2640700",
    "end": "2646160"
  },
  {
    "text": "just the label of\nmy training set. And the label are noisy. But this is an ideal object\nwhere you put the true function",
    "start": "2646160",
    "end": "2651950"
  },
  {
    "text": "itself, and you just average\nthe value of the true function.",
    "start": "2651950",
    "end": "2657320"
  },
  {
    "text": "Why do I use this? Because I want to\nget something which is in between this\nf-star and this f-hat.",
    "start": "2657320",
    "end": "2664309"
  },
  {
    "text": "So if you put k big enough--\nso if you have enough points, this is going to be-- sorry, if you take\nk small enough--",
    "start": "2664310",
    "end": "2670500"
  },
  {
    "text": "so this is closer to\nf-star than my f-hat, OK, because you\nget no noisy data.",
    "start": "2670500",
    "end": "2677120"
  },
  {
    "text": "And what I want to do-- oops. ",
    "start": "2677120",
    "end": "2683715"
  },
  {
    "text": "What I want to do is that I\nwant to plug it in the middle and split this error in two.",
    "start": "2683716",
    "end": "2689620"
  },
  {
    "text": "And this is what I do. OK. If you do this, you can check\nthat you have a square here.",
    "start": "2689620",
    "end": "2695960"
  },
  {
    "text": "You get two terms. One simplifies, because of\nthis assumption on the noise, and you get these two terms. OK. And the important thing\nis these two terms",
    "start": "2695960",
    "end": "2702539"
  },
  {
    "text": "are-- one is the comparison\nbetween my algorithm and its expectation. So that's exactly what\nwe called a variance.",
    "start": "2702539",
    "end": "2709000"
  },
  {
    "text": "OK. And one is the comparison\nbetween the value of the true function\nhere, and the value",
    "start": "2709000",
    "end": "2714230"
  },
  {
    "text": "of this other function. Sorry, this should be-- oh yeah. This is the\nexpectation, which is",
    "start": "2714230",
    "end": "2720049"
  },
  {
    "text": "my ideal version of my\nalgorithm, the one that has access to the noiseless labels. OK.",
    "start": "2720050",
    "end": "2725750"
  },
  {
    "text": "It's what you call a bias. It's basically because,\ninstead of using the exact value of the\nfunction, you blur it",
    "start": "2725750",
    "end": "2731619"
  },
  {
    "text": "a bit by averaging out. OK. You see here, instead of using\nthe value of the function, you average out a\nfew nearby values.",
    "start": "2731620",
    "end": "2739590"
  },
  {
    "text": "So you're making\nit a bit dirtier. The question now is, how\nwould these two quantities depend on k?",
    "start": "2739590",
    "end": "2745754"
  },
  {
    "text": "How this quantity depends\non k and how this quantity depends on k. OK.",
    "start": "2745754",
    "end": "2750824"
  },
  {
    "text": "And then by putting\nthis together, we'll see that we have a\ncertain behavior of this, and a certain behavior of this. And then balancing\nthis out, we'll",
    "start": "2750824",
    "end": "2757400"
  },
  {
    "text": "get what the optimal\nvalue looked like. And this is going to\nbe all useless from--",
    "start": "2757400",
    "end": "2762980"
  },
  {
    "text": "so these are going\nto be interesting from a conceptual perspective. We're going to learn\nsomething, but we'll still have to do something practical,\nbecause nothing of this",
    "start": "2762980",
    "end": "2770030"
  },
  {
    "text": "you can measure in practice. OK. So the next question\nwould be, now that we know that it exists and\nit depends on this stuff,",
    "start": "2770030",
    "end": "2776520"
  },
  {
    "text": "how can we actually\napproximate it in practice? And cross-validation is going\nto pop out of the window. OK. But this is the\ntheory that shows you",
    "start": "2776520",
    "end": "2782861"
  },
  {
    "text": "that this would help\nproving a theory that shows that cross-validation is\na good idea, in a precise sense.",
    "start": "2782861",
    "end": "2789650"
  },
  {
    "text": "The take-home message\nis, by making this model and using this as an\nintermediate object, you split the error in two, and\nyou start to be able to study.",
    "start": "2789650",
    "end": "2797500"
  },
  {
    "text": "And what you get is\nbasically the following. This term, by basically using--",
    "start": "2797500",
    "end": "2804030"
  },
  {
    "text": "so we assume that the data-- I didn't say that,\nbut that's important. We assume that the data are\nindependent with each other.",
    "start": "2804030",
    "end": "2809960"
  },
  {
    "text": "OK. And by using that, you get\nthese results right away, essentially using the\nfact that the variance",
    "start": "2809960",
    "end": "2816217"
  },
  {
    "text": "of the sum of the\nindependent variable is the sum of the variances. You get these\nresults in one line.",
    "start": "2816217",
    "end": "2821930"
  },
  {
    "text": "OK. And basically what this shows\nis that, if k gets big--",
    "start": "2821930",
    "end": "2829946"
  },
  {
    "text": "so variance is another\nword for the stability. OK. So if you have a big variance,\nthings will vary a lot.",
    "start": "2829946",
    "end": "2836190"
  },
  {
    "text": "It will be unstable. So what you see here is exactly\nwhat we observe in the plot",
    "start": "2836190",
    "end": "2841829"
  },
  {
    "text": "before. If k was big, things are\nnot changing as much. If k was small, things\nwere changing a lot.",
    "start": "2841830",
    "end": "2847220"
  },
  {
    "text": "OK. And this is the one equation\nthat shows you that. OK. And if you just look at\nthat, it would just tell you,",
    "start": "2847220",
    "end": "2854450"
  },
  {
    "text": "the big is better. Big, respect to what? To the noise. OK. If there is a lot of noise,\nI should make it bigger.",
    "start": "2854450",
    "end": "2860216"
  },
  {
    "text": "If there's more noise,\nI can make it smaller. But the point is\nthat we saw before is",
    "start": "2860216",
    "end": "2865970"
  },
  {
    "text": "that the problem\nof putting k large was that we were forgetting\nabout the problem. We're just getting something\nthat was very stable",
    "start": "2865970",
    "end": "2871341"
  },
  {
    "text": "but could be potentially very\nbad, if my function was not that simple. OK. This is a bit harder to\nstudy mathematically.",
    "start": "2871341",
    "end": "2878620"
  },
  {
    "text": "OK. This is a calculation\nthat I show you because you can do it yourself\nin like 20 minutes, or less.",
    "start": "2878620",
    "end": "2885952"
  },
  {
    "text": "This one takes a bit more. But he can get the hunch\non how it looks like. And the basic idea is\nwhat we already said.",
    "start": "2885952",
    "end": "2892910"
  },
  {
    "text": "If k is small, and the points\nare close enough, instead",
    "start": "2892910",
    "end": "2899210"
  },
  {
    "text": "of f-star x, we are\nthinking of f-star Xk, Xi.",
    "start": "2899210",
    "end": "2904910"
  },
  {
    "text": "And the i is closing off. OK. Now if we start to\nput k bigger, we",
    "start": "2904910",
    "end": "2909920"
  },
  {
    "text": "start to blur that prediction by\nlooking at many nearby points.",
    "start": "2909920",
    "end": "2915619"
  },
  {
    "text": "But here there is no noise. OK. So that sounds like a bad idea. So we expect the\nerror in that case",
    "start": "2915620",
    "end": "2921110"
  },
  {
    "text": "to be either increasing, or at\nleast flat with respect to k. So when we take k larger,\nwe're blurring this prediction,",
    "start": "2921110",
    "end": "2930800"
  },
  {
    "text": "and potentially make it\nfar away from the true one. OK. And you can make this\nstatement precise.",
    "start": "2930800",
    "end": "2937040"
  },
  {
    "text": "You can prove it. And if you will prove it,\nit's basically that you have-- what happened?",
    "start": "2937040",
    "end": "2943130"
  },
  {
    "text": "You have linear dependence. So the error here is linearly\nincreasing or polynomially increasing-- in fact I don't\nremember-- with respect to k.",
    "start": "2943130",
    "end": "2950551"
  },
  {
    "text": "OK.  So the reason why\nI'm showing you this, skipping\nall these details,",
    "start": "2950551",
    "end": "2956577"
  },
  {
    "text": "is just to give you a feeling\nof the kind of computation that answered the question\nif there is a optimal value",
    "start": "2956577",
    "end": "2963369"
  },
  {
    "text": "and what it depends on. And then at this point,\nonce you get this, you start to see\nthis kind of plot.",
    "start": "2963370",
    "end": "2968560"
  },
  {
    "text": "And typically here I\nput them the wrong way. But here you\nbasically say, I have this one function\nI wanted to study,",
    "start": "2968560",
    "end": "2974750"
  },
  {
    "text": "which is the sum\nof two functions. I have this, and I have this.",
    "start": "2974750",
    "end": "2981040"
  },
  {
    "text": "OK. And now to study\nthe minimum, I'm basically going to\nsum them up and see what's the optimal value\nto optimize this too.",
    "start": "2981040",
    "end": "2987666"
  },
  {
    "text": "And the k that optimized this\nis exactly the optimal k. And you see that the optimal\nk will behave as we expected.",
    "start": "2987666",
    "end": "2994270"
  },
  {
    "text": "OK. So here, one\ningredient is missing. And it's just missing\nbecause I didn't put it in,",
    "start": "2994270",
    "end": "3001425"
  },
  {
    "text": "which is the number of points. OK. It's just because I\ndidn't renormalize things. OK. It should be a 1 over n here.",
    "start": "3001425",
    "end": "3009150"
  },
  {
    "start": "3009150",
    "end": "3015210"
  },
  {
    "text": "It's just that I\ndidn't renormalize. OK. But you announced it, and\nit's good, because it's true. There should be\na 1 over n there.",
    "start": "3015210",
    "end": "3021450"
  },
  {
    "text": "But the rest is\nwhat we expected. OK. In some sense what we expect\nis that if my problem is complicated, I\nneed the smaller k.",
    "start": "3021450",
    "end": "3028100"
  },
  {
    "text": "If there is a lot of\nnoise, I need a bigger k. And depending on the\nnumber of points,",
    "start": "3028100",
    "end": "3033329"
  },
  {
    "text": "which would be in\nthe numerator here, I can make a bigger or a larger. k.",
    "start": "3033330",
    "end": "3038619"
  },
  {
    "text": "OK. This plot is fundamental because\nit shows some property which is inherent in the problem.",
    "start": "3038620",
    "end": "3044410"
  },
  {
    "text": "And the theorem that\nsomewhat is behind it-- intuition I've been saying,\nrepeating over and over,",
    "start": "3044410",
    "end": "3050680"
  },
  {
    "text": "which is this intuition that you\ncannot trust the data too much. And there is the optimal amount\nof trust you can of your data",
    "start": "3050680",
    "end": "3056849"
  },
  {
    "text": "based on certain assumptions. OK. And in our case, the assumption\nwhere this kind of model.",
    "start": "3056850",
    "end": "3063560"
  },
  {
    "text": "So little calculation\nI'll show you quickly, grounds this intuition into\na mathematical argument.",
    "start": "3063560",
    "end": "3071220"
  },
  {
    "text": "OK. All right. So we spent quite a\nbit of time on this.",
    "start": "3071220",
    "end": "3077490"
  },
  {
    "text": "In some sense, from a\nconceptual point of view, this is a critical idea. OK. Because it's behind\npretty much everything.",
    "start": "3077490",
    "end": "3083511"
  },
  {
    "text": "This idea of, how much you\ncan trust or not of the data. Of course here, as we said,\nthis has been informative,",
    "start": "3083511",
    "end": "3090920"
  },
  {
    "text": "hopefully. But you cannot\nreally choose this k, because you would need\nto know the noise, but especially to know how\nto estimate this in order",
    "start": "3090920",
    "end": "3098250"
  },
  {
    "text": "to minimize this quantity. So in practice what\nyou can show is,",
    "start": "3098250",
    "end": "3104730"
  },
  {
    "text": "you can use what is\ncalled cross-validation. And in effect,\ncross-validation is one of a few other\ntechniques you can use.",
    "start": "3104730",
    "end": "3110430"
  },
  {
    "text": "And the idea is that you\ndon't have access [AUDIO OUT] but you can show that if you\ntake a bunch of data points,",
    "start": "3110430",
    "end": "3117320"
  },
  {
    "text": "you split them in two, you\nuse half for the training as you've always done, and you\nuse the other half as a proxy",
    "start": "3117320",
    "end": "3122750"
  },
  {
    "text": "for this future data. Then by minimizing the k-- taking the k that minimized the\nerror on this so-called holdout",
    "start": "3122750",
    "end": "3130590"
  },
  {
    "text": "set, then you can prove\nit's as good as if you",
    "start": "3130590",
    "end": "3135620"
  },
  {
    "text": "could have access to this. OK. And it's actually\nvery easy to prove. You can show that if\nyou're just split in two,",
    "start": "3135620",
    "end": "3142460"
  },
  {
    "text": "and you minimize the\nerror in second half-- you do what is called the\nholdout cross-validation-- it's as good as if you'd\nhad access to this.",
    "start": "3142460",
    "end": "3151291"
  },
  {
    "text": "OK. So it's optimal in a way. ",
    "start": "3151291",
    "end": "3156309"
  },
  {
    "text": "Now, the problem with this\nis that we are only looking at the area and expectation.",
    "start": "3156310",
    "end": "3164394"
  },
  {
    "text": "And what you can check is that\nif you look at higher order statistics, say that\nvariance of your estimators",
    "start": "3164394",
    "end": "3169741"
  },
  {
    "text": "and so on and so forth,\nwhat you might get is that by splitting in two,\n[AUDIO OUT] big is fine. In practice the\ndifference is small,",
    "start": "3169741",
    "end": "3176337"
  },
  {
    "text": "you might get that the way\nyou split might matter. You might have bad luck and\njust split in a certain way. And so there is a whole\nzoology of ways of splitting.",
    "start": "3176337",
    "end": "3183849"
  },
  {
    "text": "And the basic one\nis, say, split-- this is, for example,\nthe simplest. OK.",
    "start": "3183850",
    "end": "3188905"
  },
  {
    "text": "Split in a bunch of groups. OK.",
    "start": "3188905",
    "end": "3194259"
  },
  {
    "text": "k-fold or v-fold\ncross-validation. Take one group out of the time. OK. And do the same trick.",
    "start": "3194260",
    "end": "3200150"
  },
  {
    "text": "You know, you train here\nand calculate the error here for different k's. Then you do the same\nhere, do the same here,",
    "start": "3200150",
    "end": "3205960"
  },
  {
    "text": "do the same here. Sum the errors\nup, renormalizing, and then just choose\nthe k that minimizes",
    "start": "3205960",
    "end": "3211280"
  },
  {
    "text": "this new form of error. And if the data there are\nsmall, small, small, then",
    "start": "3211280",
    "end": "3217450"
  },
  {
    "text": "typically this set\nwill become very small. And then delimited, it becomes\none, the leave one out error. OK.",
    "start": "3217450",
    "end": "3222670"
  },
  {
    "text": "What you do is\nthat you literally leave one out,\ntrain on the rest, get there for all the\nvalues of k in this case.",
    "start": "3222670",
    "end": "3229670"
  },
  {
    "text": "Put it back in, take another one\nout, and repeat the procedure.",
    "start": "3229670",
    "end": "3236210"
  },
  {
    "text": "Now the question that I\nhad 10, 15 minutes ago was, how do you choose v?",
    "start": "3236210",
    "end": "3241770"
  },
  {
    "text": "OK. Shall I make this two? So I just do one\nsplit like this?",
    "start": "3241770",
    "end": "3248630"
  },
  {
    "text": "Or shall I make it n,\nso I do leave one out? And as far as I\nknow there is not",
    "start": "3248630",
    "end": "3254569"
  },
  {
    "text": "a lot of theory\nthat would support an answer to this question. And what I know is mostly what\nyou can expect intuitively,",
    "start": "3254570",
    "end": "3263040"
  },
  {
    "text": "which is, if you have\na lot of data points-- what does it mean a lot? I don't know. If you have two million,\n10,000, I don't know.",
    "start": "3263040",
    "end": "3269690"
  },
  {
    "text": "If you have a big dataset,\ntypically splitting in two, or maybe doing just random\nsplits is stable enough.",
    "start": "3269690",
    "end": "3276590"
  },
  {
    "text": "What does it mean? That you try, and you\nlook at how much it moves.",
    "start": "3276590",
    "end": "3282320"
  },
  {
    "text": "Whereas if you have say-- you know, I don't know\nif it even exists, the implication like, you\nknow, a few years ago there were micro-reapplication where\nyou would have 20, 30 inputs,",
    "start": "3282320",
    "end": "3291350"
  },
  {
    "text": "and you have 20 dimensions. And then in that case, you\nreally don't do much splitting.",
    "start": "3291350",
    "end": "3297302"
  },
  {
    "text": "If you have 20, for example,\nyou try to leave one out and it's the best you can do. And it's already very\nunstable and sucks.",
    "start": "3297302",
    "end": "3302990"
  },
  {
    "text": "OK. So in this case, there\nis work to be done. I mean, as far as I know,\nthat's the state of things.",
    "start": "3302990",
    "end": "3308311"
  },
  {
    "text": "OK. So we introduced a class\nof very simple algorithms. They seem to be\npretty reasonable. They seem to allow us,\nprovided that we have a way",
    "start": "3308311",
    "end": "3314750"
  },
  {
    "text": "to measure distances\nor similarity, to go from simple to complex. And we have some\nkind of theory that",
    "start": "3314750",
    "end": "3321320"
  },
  {
    "text": "tells us what is the optimal\nvalue of a parameter, a kind of practical procedure to\nactually choose it in practice.",
    "start": "3321320",
    "end": "3328800"
  },
  {
    "text": "OK. Are we done? Is that all? do we need to do anything else?",
    "start": "3328800",
    "end": "3334520"
  },
  {
    "text": "What's missing here? One thing that is\nmissing here is that most of the intuition\nwe developed so far",
    "start": "3334520",
    "end": "3340310"
  },
  {
    "text": "are really related\nto low dimension. OK. And here, very quickly, if\nyou just do a little exercise",
    "start": "3340310",
    "end": "3346160"
  },
  {
    "text": "where you try to say\nhow big is a cube that covers 1% of the volume of\na bigger cube of a unit length?",
    "start": "3346160",
    "end": "3353911"
  },
  {
    "text": "OK. So the big cube is volume 1. The length of that is just 1. And it ask you, how\nbig is this, if it",
    "start": "3353911",
    "end": "3359700"
  },
  {
    "text": "has to cover 1% of the volume? It's really to check that these\nare just going to be a dth-root",
    "start": "3359700",
    "end": "3365840"
  },
  {
    "text": "where d is the\ndimension of the cube. And this is the shape\nof the dth-root. OK.",
    "start": "3365840",
    "end": "3371089"
  },
  {
    "text": "So if you're in low\ndimension, basically, 1% is intuitively small\nwithin the big cube.",
    "start": "3371090",
    "end": "3377024"
  },
  {
    "text": "But as soon as you're go\nin higher dimensional, what you see is that the length of\nthe edge of the little cube",
    "start": "3377024",
    "end": "3382940"
  },
  {
    "text": "that has to cover 1% of the\nvolume becomes very close to 1, almost immediately. It's this curve going up.",
    "start": "3382940",
    "end": "3389300"
  },
  {
    "text": "OK. What does it mean? That if you say, our\nintuition is, well, 1%.",
    "start": "3389300",
    "end": "3395630"
  },
  {
    "text": "It's a pretty small volume. If I just took the neighbors\nin 1%, they're pretty close, so they should have\nthe same label.",
    "start": "3395630",
    "end": "3402420"
  },
  {
    "text": "Well, in dimension\n10, it's everything. OK. So our intuition-- now you\ncan say that probably there",
    "start": "3402420",
    "end": "3409962"
  },
  {
    "text": "is something wrong with my way\nof thinking of volume, sure. But the problem is that\nwe have to rethink a bit how you think of dimensions and\nsimilarity in high dimension,",
    "start": "3409962",
    "end": "3417400"
  },
  {
    "text": "because things that are\nobvious low dimensional start to be very complicated. OK. And the basic idea is that\nthis neighbor technique just",
    "start": "3417400",
    "end": "3425770"
  },
  {
    "text": "looks at what's\nhappening in one region. But what you hope to do is\nthat if your function actually",
    "start": "3425770",
    "end": "3431540"
  },
  {
    "text": "has some kind of\nglobal properties-- so, say for example a sign\nis the simplest example of something which is global,\nbecause the value here",
    "start": "3431540",
    "end": "3438370"
  },
  {
    "text": "and the value here\nare very much related. And then it goes up\nand it's the same. And then it goes down.",
    "start": "3438370",
    "end": "3444012"
  },
  {
    "text": "So if you know\nsomething like this, the idea is that you\ncan borrow strength from points which are far away.",
    "start": "3444012",
    "end": "3449729"
  },
  {
    "text": "In some sense the function\nhas some similar properties. And so you want to go\nfrom a local estimation to some form of\nglobal estimation.",
    "start": "3449729",
    "end": "3456309"
  },
  {
    "text": "OK. And instead of making\na decision based only on the neighbors\nof the points, you might want to use points\nwhich are potentially far away.",
    "start": "3456310",
    "end": "3462640"
  },
  {
    "text": "OK. And this seems to be like a good\nidea in high dimensions where the neighboring points might\nnot give enough information .",
    "start": "3462640",
    "end": "3471066"
  },
  {
    "text": "And that's kind\nof what's called, curse of dimensionality. OK. So what I want to do next--",
    "start": "3471066",
    "end": "3476260"
  },
  {
    "text": "we can take a break here-- is discussing least squares\nand kernel least squares.",
    "start": "3476260",
    "end": "3482010"
  },
  {
    "text": "OK. But what we're going\nto do is that we're going to take a linear\nmodel of our data, and then we are\ngoing to try to see",
    "start": "3482010",
    "end": "3487930"
  },
  {
    "text": "how you can estimate and learn. And we're going to look\nat bit of the computation and a bit of the statistical\nidea underlying this model.",
    "start": "3487930",
    "end": "3494100"
  },
  {
    "text": "And then we're going to play\naround in a very simple for way to extend from a linear\nmodel to a non-linear model",
    "start": "3494100",
    "end": "3499390"
  },
  {
    "text": "and actually make\nit non-parametric. I'll tell you what\nnon-parametric means. ",
    "start": "3499390",
    "end": "3513689"
  }
]
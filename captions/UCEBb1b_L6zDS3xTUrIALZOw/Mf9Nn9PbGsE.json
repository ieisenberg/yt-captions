[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6360"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6360",
    "end": "13320"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13320",
    "end": "18450"
  },
  {
    "text": " ERIK DEMAINE: All\nright, today we're going to do an exciting\ntopic, which is hashing.",
    "start": "18450",
    "end": "26550"
  },
  {
    "text": "Do it all in one\nlecture, that's the plan. See if we make it.",
    "start": "26550",
    "end": "31740"
  },
  {
    "text": "You've probably\nheard about hashing. It's probably the most\ncommon data structure in computer science.",
    "start": "31740",
    "end": "37050"
  },
  {
    "text": "It's covered in pretty much\nevery algorithms class. But there's a lot\nto say about it. And I want to\nquickly review things",
    "start": "37050",
    "end": "42810"
  },
  {
    "text": "you might know and then\nquickly get to things you shouldn't know. And we're going to\ntalk on the one hand",
    "start": "42810",
    "end": "48960"
  },
  {
    "text": "about different kinds\nof hash functions, fancy stuff like\nk-wise independence, and a new technique that's\nbeen analyzed a lot lately,",
    "start": "48960",
    "end": "56040"
  },
  {
    "text": "simple tabulation hashing,\njust in the last year. And then we'll look\nat different ways to use this hash function that\nactually build data structures,",
    "start": "56040",
    "end": "63240"
  },
  {
    "text": "chaining is the obvious\none; perfect hashing you may have seen; linear probing\nis another obvious one,",
    "start": "63240",
    "end": "69150"
  },
  {
    "text": "but has only been\nanalyzed recently; and cuckoo hashing is a new one\nthat has its own fun feature.",
    "start": "69150",
    "end": "75690"
  },
  {
    "text": "So that's where we're\ngoing to go today Remember, the basic\nidea of hashing",
    "start": "75690",
    "end": "82439"
  },
  {
    "text": "is you want to reduce\na giant universe to a reasonably small table.",
    "start": "82440",
    "end": "88090"
  },
  {
    "text": "So I'm going to call\nour hash function h. I'm going to call the universe\ninteger 0 up to u minus 1.",
    "start": "88090",
    "end": "95437"
  },
  {
    "text": "So this is the universe. And I'm going to denote the\nuniverse by a capital U.",
    "start": "95438",
    "end": "102600"
  },
  {
    "text": "And we have a table\nthat we'd like to store. I'm not going to draw\nit yet because that's",
    "start": "102600",
    "end": "108630"
  },
  {
    "text": "the second half of the lecture,\nwhat is the table actually. But we'll just think of it as\nindices 0 through m minus 1.",
    "start": "108630",
    "end": "116080"
  },
  {
    "text": "So this is the table size. And probably, we want\nm to be about n. n",
    "start": "116080",
    "end": "123780"
  },
  {
    "text": "is the number of keys we're\nactually storing in the table. But that's not necessarily\nseen at this level.",
    "start": "123780",
    "end": "130289"
  },
  {
    "text": "So that's a hash function. m is going to be\nmuch smaller than u.",
    "start": "130289",
    "end": "135555"
  },
  {
    "text": "We're just hashing\nintegers here, so if you don't have integers\nyou map your whatever space of things you have to integers.",
    "start": "135555",
    "end": "141690"
  },
  {
    "text": "That's pretty much\nalways possible. Now, best case scenario would\nbe to use a totally random hash",
    "start": "141690",
    "end": "148000"
  },
  {
    "text": "function.  What does totally random mean?",
    "start": "148000",
    "end": "153730"
  },
  {
    "text": "The probability, if you\nchoose your hash function, that any key x maps to\nany particular slot--",
    "start": "153730",
    "end": "161850"
  },
  {
    "text": "these table things\nare called slots-- is 1 over m.",
    "start": "161850",
    "end": "167640"
  },
  {
    "text": "And this is\nindependent for all x. ",
    "start": "167640",
    "end": "188290"
  },
  {
    "text": "So this would be ideal. You choose each h of x for\nevery possible key randomly,",
    "start": "188290",
    "end": "194900"
  },
  {
    "text": "independently. Then that gives you\nperfect hashing. Not perfect in\nthis sense, sorry.",
    "start": "194900",
    "end": "200379"
  },
  {
    "text": "It gives you ideal hashing. Perfect means no collisions. This actually might\nhave collisions,",
    "start": "200380",
    "end": "206410"
  },
  {
    "text": "there's some chance that two\nkeys hash to the same value. We call this totally random. This is sort of the\nideal thing that we're",
    "start": "206410",
    "end": "212410"
  },
  {
    "text": "trying to approximate with\nreasonable hash functions. Why is this bad? Because it's big.",
    "start": "212410",
    "end": "217989"
  },
  {
    "text": "The number of bits\nof information you'd need if you actually\ncould flip all these coins,",
    "start": "217990",
    "end": "223480"
  },
  {
    "text": "you'd need to write\ndown, I guess U times log m bits of information.",
    "start": "223480",
    "end": "230790"
  },
  {
    "start": "230790",
    "end": "235799"
  },
  {
    "text": "Which is generally way too big. We can't afford U.\nThe whole point is we want to store n items much\nsmaller than U. Surprisingly,",
    "start": "235800",
    "end": "243880"
  },
  {
    "text": "this concept will\nstill be useful. So we'll get there. ",
    "start": "243880",
    "end": "251920"
  },
  {
    "text": "Another system you've probably\nseen is universal hashing.",
    "start": "251920",
    "end": "258870"
  },
  {
    "text": "This is a constraint\non hash function.",
    "start": "258870",
    "end": "267380"
  },
  {
    "text": "So this would be\nideally you'd choose h uniformly at random\nfrom all hash functions. That would give you\nthis probability.",
    "start": "267380",
    "end": "274090"
  },
  {
    "text": "We're going to make a\nsmaller set of hash functions whose size is much smaller. And so you can encode the hash\nfunction in many fewer bits.",
    "start": "274090",
    "end": "280850"
  },
  {
    "text": " And the property we want\nfrom that hash family",
    "start": "280850",
    "end": "287960"
  },
  {
    "text": "is that if you look\nat the probability that two keys collide,\nyou get roughly what",
    "start": "287960",
    "end": "296300"
  },
  {
    "text": "you expect from totally random. You would hope for 1 over m.",
    "start": "296300",
    "end": "302832"
  },
  {
    "text": "Once you pick one\nkey, the probability the other key would hit\nit would be 1 over m.",
    "start": "302832",
    "end": "308110"
  },
  {
    "text": "But we'll allow constant factor. And also allow it to be smaller.",
    "start": "308110",
    "end": "313389"
  },
  {
    "text": "It gives us some slop. You don't have to do this. If you don't do this you it's\ncalled strongly universal.",
    "start": "313390",
    "end": "318500"
  },
  {
    "text": " That's universal. And universal is enough\nfor a lot of things",
    "start": "318500",
    "end": "325460"
  },
  {
    "text": "that you've probably seen, but\nnot enough for other things. So here are some examples\nof hash functions",
    "start": "325460",
    "end": "331040"
  },
  {
    "text": "that are universal, which\nagain, you may have seen. ",
    "start": "331040",
    "end": "349880"
  },
  {
    "text": "You can take a random\ninteger a, multiply it by x integer multiplication. You could also do this as\na vector wise dot product.",
    "start": "349880",
    "end": "357139"
  },
  {
    "text": "But here I'm doing\nit as multiplication. Modulo a prime. Prime has to be bigger than U,\nmaybe bigger or equal is fine.",
    "start": "357140",
    "end": "367630"
  },
  {
    "start": "367630",
    "end": "373220"
  },
  {
    "text": "Universe. And then you take the\nwhole thing modulo em, Now, this is universal but\nit loses a factor of 2 here,",
    "start": "373220",
    "end": "380690"
  },
  {
    "text": "I believe, in general. Because you take things\nmodulo prime and then",
    "start": "380690",
    "end": "386060"
  },
  {
    "text": "you take things modulo\nwhatever your table size is. If you set your table\nsize to p that's great. I think you get a factor of 1.",
    "start": "386060",
    "end": "392750"
  },
  {
    "text": "If you don't, you're essentially\nlosing possibly half the slots,",
    "start": "392750",
    "end": "399170"
  },
  {
    "text": "depending on how m and p\nare related to each other. So it's OK, but not great.",
    "start": "399170",
    "end": "406190"
  },
  {
    "text": " It's also considered\nexpensive because you have do all this division,\nwhich people don't like to do.",
    "start": "406190",
    "end": "414289"
  },
  {
    "text": "So there's a\nfancier method which is a times x shifted right\nby log u minus log m.",
    "start": "414290",
    "end": "428810"
  },
  {
    "text": " This is when m and u are\npowers of 2, which is",
    "start": "428810",
    "end": "438809"
  },
  {
    "text": "the case we kind of care about. Usually your\nuniverse is of size 2",
    "start": "438809",
    "end": "444380"
  },
  {
    "text": "to the word size of your\nmachine, 2 to the 32, 2 to the 64, however\nbigger integers are.",
    "start": "444380",
    "end": "450202"
  },
  {
    "text": "So it's usually a power of 2. It's fine to make your\ntable a power of 2. We're probably going\nto use table doubling.",
    "start": "450202",
    "end": "456000"
  },
  {
    "text": "So you just multiply and then\ntake the high order bits, that's what this is saying.",
    "start": "456000",
    "end": "462759"
  },
  {
    "text": "So this is a method\nmore recent, 1997. Whereas this one\ngoes back to 1979.",
    "start": "462760",
    "end": "469500"
  },
  {
    "text": "So '79, '97. And it's also universal.",
    "start": "469500",
    "end": "477070"
  },
  {
    "text": "There's a lot of\nuniversal hash functions. I'm not going to list them all. I'd rather get to stronger\nproperties than universality.",
    "start": "477071",
    "end": "485460"
  },
  {
    "text": "So the next one is called\nk-wise independence. ",
    "start": "485460",
    "end": "494400"
  },
  {
    "text": "This is harder to obtain. And it implies universality.",
    "start": "494400",
    "end": "501600"
  },
  {
    "text": "So we want a family of\nhash functions such that--",
    "start": "501600",
    "end": "507270"
  },
  {
    "start": "507270",
    "end": "534600"
  },
  {
    "text": "Maybe let's start with\njust pairwise independence, k equals 2. Then what this is saying\nis the probability",
    "start": "534600",
    "end": "540140"
  },
  {
    "text": "of your choice of hash function,\nthat the first key maps to this slot, t1, and\nthe second key maps",
    "start": "540140",
    "end": "547250"
  },
  {
    "text": "to some other slot, t2. For any two keys x1 and xk.",
    "start": "547250",
    "end": "553139"
  },
  {
    "text": " If your function was\nrandom each of those",
    "start": "553140",
    "end": "559580"
  },
  {
    "text": "happens with probability 1\nover m, they're independent. So you get 1 over m to the\nk, or 1 over m squared for k",
    "start": "559580",
    "end": "566025"
  },
  {
    "text": "equals 2. Even in that situation\nthat's different from saying the probability of 2 keys\nbeing equal is 1 over m.",
    "start": "566025",
    "end": "574460"
  },
  {
    "text": "This would imply that. But here there could still\nbe some co-dependence between x and y.",
    "start": "574460",
    "end": "580320"
  },
  {
    "text": "Here there essentially can't be. I mean, other than\nthis constant factor.",
    "start": "580320",
    "end": "586160"
  },
  {
    "text": "Pairwise independence means\nevery two guys are independent, k-wise means every k\nguys are independent",
    "start": "586160",
    "end": "591640"
  },
  {
    "text": "up to the constant factor. So this is for distinct xi's.",
    "start": "591640",
    "end": "600740"
  },
  {
    "text": " Obviously if two\nof them are equal they're very likely to\nhash to the same slot.",
    "start": "600740",
    "end": "608690"
  },
  {
    "text": "So you've got to forbid that. OK, so an example of\nsuch a hash function.",
    "start": "608690",
    "end": "614510"
  },
  {
    "text": " Here we just took a product.",
    "start": "614510",
    "end": "622820"
  },
  {
    "text": "In general you can take a\npolynomial of degree k minus 1.",
    "start": "622820",
    "end": "635180"
  },
  {
    "text": "Evaluate that mod p.  And then if you want some,\nmodulo that to your table size.",
    "start": "635180",
    "end": "647279"
  },
  {
    "text": "So in particular if k\nequals 2, we actually have to do some work. This function is not pairwise\nindependent, it is universal.",
    "start": "647279",
    "end": "655740"
  },
  {
    "text": "If you make it ax plus\nb for random a and b, then this becomes\npairwise independent.",
    "start": "655740",
    "end": "660889"
  },
  {
    "text": "In general, you want\nthree wise independent, triple wise independent, you\nneed ax squared plus bx plus c",
    "start": "660890",
    "end": "670040"
  },
  {
    "text": "for random a, b's, and c's. So these are arbitrary numbers\nbetween 0 and p, I guess.",
    "start": "670040",
    "end": "679713"
  },
  {
    "start": "679713",
    "end": "685140"
  },
  {
    "text": "OK. This is also old, 1981. Wegman and Carter\nintroduced these two notions",
    "start": "685140",
    "end": "693300"
  },
  {
    "text": "in a couple of different papers. This is an old idea. This is, of course, expensive\nin that we pay order k time",
    "start": "693300",
    "end": "701670"
  },
  {
    "text": "to evaluate it. Also, there's a lot\nof multiplications and you have to do\neverything modulo p.",
    "start": "701670",
    "end": "707820"
  },
  {
    "text": "So a lot of people have\nworked on more efficient ways to do k-wise independence. And there two main\nresults on this.",
    "start": "707820",
    "end": "714780"
  },
  {
    "text": "Both of them achieve m to the\nepsilon space, is not great.",
    "start": "714780",
    "end": "719830"
  },
  {
    "start": "719830",
    "end": "731840"
  },
  {
    "text": "One of them the query\ntime depends on k, and it's uniform, and\nreasonably practical",
    "start": "731840",
    "end": "744255"
  },
  {
    "text": "[? with ?] experiments. The other one is constant query\nfor a logarithmic independence.",
    "start": "744255",
    "end": "758136"
  },
  {
    "start": "758136",
    "end": "767860"
  },
  {
    "text": "So this one is actually later. It's by Thorpe and [? Tsang.\n?] And this is by Siegel.",
    "start": "767860",
    "end": "774610"
  },
  {
    "text": "Both 2004, so fairly recent.",
    "start": "774610",
    "end": "779800"
  },
  {
    "text": "It takes a fair amount of space. This paper proves that\nto get constant query time for logarithmic\nindependence",
    "start": "779800",
    "end": "786100"
  },
  {
    "text": "you'd need quite a bit of space\nto store your hash function. Keep in mind, these hash\nfunctions only take--",
    "start": "786100",
    "end": "793330"
  },
  {
    "text": "well this is like k\nlog in bits to store. So this is words of space.",
    "start": "793330",
    "end": "798920"
  },
  {
    "text": "So here we're only\nspending k words to store this hash function. It's very small.",
    "start": "798920",
    "end": "804360"
  },
  {
    "text": "Here you need\nsomething depending on n, which is kind of\nannoying, especially if you want to be dynamic. But statically you can get\nconstant query logarithmic wise",
    "start": "804360",
    "end": "813920"
  },
  {
    "text": "independence, but you have\nto pay a lot in space. ",
    "start": "813920",
    "end": "819999"
  },
  {
    "text": "There's more practical methods. This is especially\npractical for k equals 5, which is a case\nthat we'll see is of interest.",
    "start": "819999",
    "end": "827320"
  },
  {
    "text": " Cool. So this much space is\nnecessary if you want.",
    "start": "827320",
    "end": "835000"
  },
  {
    "text": "We'll see log wise independence\nis the most we'll ever require in this class.",
    "start": "835000",
    "end": "841060"
  },
  {
    "text": " And as far as I know,\nin hashing in general.",
    "start": "841060",
    "end": "846820"
  },
  {
    "text": "So you don't need\nto worry about more than log wise independence.",
    "start": "846820",
    "end": "851982"
  },
  {
    "text": "All right, one more\nhashing scheme.",
    "start": "851982",
    "end": "857555"
  },
  {
    "text": "It's called simple\ntabulation hashing. ",
    "start": "857555",
    "end": "872730"
  },
  {
    "text": "This is a simple idea. It goes also back\nto '81 but it's just",
    "start": "872730",
    "end": "879660"
  },
  {
    "text": "been analyzed last year. So there's a lot of\nresults to report on it.",
    "start": "879660",
    "end": "887000"
  },
  {
    "text": "The idea is just\ntake your integer, split it up into some base\nso that there's exactly",
    "start": "887000",
    "end": "895720"
  },
  {
    "text": "c characters. c is going to be a constant.",
    "start": "895720",
    "end": "901050"
  },
  {
    "text": "Then build a totally\nrandom hash table.",
    "start": "901050",
    "end": "908070"
  },
  {
    "text": "This is the thing that\nwe couldn't afford. But we're just going to\ndo it on each character. ",
    "start": "908070",
    "end": "921269"
  },
  {
    "text": "So there's going to be\nc of these hash tables. ",
    "start": "921269",
    "end": "926290"
  },
  {
    "text": "And each of them is going to\nhave size u to the 1 over c.",
    "start": "926290",
    "end": "933130"
  },
  {
    "text": "So essentially we're getting u\nto the epsilon space, which is similar to these space bounds.",
    "start": "933130",
    "end": "940030"
  },
  {
    "text": "So again, not great, but it's\na really simple hash function.",
    "start": "940030",
    "end": "945100"
  },
  {
    "text": " Hash function is just going to\nbe you take your first table,",
    "start": "945100",
    "end": "952779"
  },
  {
    "text": "apply it to the first\ncharacter, x over that, with the second table applied\nto the second character,",
    "start": "952780",
    "end": "960220"
  },
  {
    "text": "and so on through\nall the characters. ",
    "start": "960220",
    "end": "966260"
  },
  {
    "text": "So the nice thing about\nthis is it's super simple. You can imagine this\nbeing done probably in one instruction\non a fancy CPU.",
    "start": "966260",
    "end": "974800"
  },
  {
    "text": "if you convince people this\nis a cool enough instruction to have. It's very simple to\nimplement circuit wide.",
    "start": "974800",
    "end": "981939"
  },
  {
    "text": "But in our model you have\nto do all these operations separately. You're going to take\norders c time to compute.",
    "start": "981940",
    "end": "990699"
  },
  {
    "text": "And one thing that's\nknown about it is that it's three independent,\nthree wise independent.",
    "start": "990700",
    "end": "999340"
  },
  {
    "text": "So it does kind of\nfit in this model. But three wise independence\nis not very impressive. A lot of the results we'll see\nrequire log n independence.",
    "start": "999340",
    "end": "1007740"
  },
  {
    "text": "But the cool thing is, roughly\nspeaking simple tabulation hashing is almost as good\nas log n wise independence",
    "start": "1007740",
    "end": "1014829"
  },
  {
    "text": "in all the hashing schemes\nthat we care about. And so we'll get there,\nexactly what that means.",
    "start": "1014830",
    "end": "1021990"
  },
  {
    "text": " So that was my overview of some\nhash functions, these two guys.",
    "start": "1021990",
    "end": "1029809"
  },
  {
    "text": "Next we're going to\nlook at basic chaining. ",
    "start": "1029810",
    "end": "1036800"
  },
  {
    "text": "Perfect hashing.  How many people\nhave seen perfect",
    "start": "1036800",
    "end": "1041910"
  },
  {
    "text": "hashing just to get a sense? More than half.",
    "start": "1041910",
    "end": "1046980"
  },
  {
    "text": "Maybe 2/3. All right, I should\ndo this really fast.",
    "start": "1046980",
    "end": "1052440"
  },
  {
    "text": "Chaining, this is the first\nkind of hashing you usually see.",
    "start": "1052440",
    "end": "1058314"
  },
  {
    "text": "You have your hash\nfunction, which is mapping keys into slots. If you have two keys\nthat go to the same slot",
    "start": "1058314",
    "end": "1065010"
  },
  {
    "text": "you store them as a linked list. OK, if you don't have anything\nin this slot, it's blank.",
    "start": "1065010",
    "end": "1071289"
  },
  {
    "text": "This is very easy. If you look at a\nparticular slot t and call",
    "start": "1071290",
    "end": "1078120"
  },
  {
    "text": "the length of the chain\nthat you get there Ct. You can look at the expected\nlength of that chain.",
    "start": "1078120",
    "end": "1085860"
  },
  {
    "text": "In general, it's just going\nto be sum of the probability",
    "start": "1085860",
    "end": "1091260"
  },
  {
    "text": "that the keys map to that slot.",
    "start": "1091260",
    "end": "1099410"
  },
  {
    "text": "And then you sum over all keys. This is just writing this\nas a sum of indicator random variables, and then\neach linearity of expectation,",
    "start": "1099410",
    "end": "1107660"
  },
  {
    "text": "expectation of each of\nthe indicator variables is probability. So that is the expected number.",
    "start": "1107660",
    "end": "1113240"
  },
  {
    "start": "1113240",
    "end": "1119770"
  },
  {
    "text": "Here we just need to\ncompute the probability each guy goes to each slot. As long as your hash\nfunction is uniform,",
    "start": "1119770",
    "end": "1126810"
  },
  {
    "text": "meaning that each of these\nguys is equally likely to be hashed to.",
    "start": "1126810",
    "end": "1132096"
  },
  {
    "text": "Well actually, we're looking\nat a particular slot. So we're essentially\nusing universality here.",
    "start": "1132097",
    "end": "1137990"
  },
  {
    "text": "Once we fix one slot\nthat we care about, so let t be some h of\ny that we care about,",
    "start": "1137990",
    "end": "1144520"
  },
  {
    "text": "then this is universality. By universality we\nknow this is 1 over m.",
    "start": "1144520",
    "end": "1150160"
  },
  {
    "text": "And so this is 1 over n over m,\nusually called the load factor.",
    "start": "1150160",
    "end": "1156890"
  },
  {
    "text": "And what we care about\nis this is constant for m",
    "start": "1156890",
    "end": "1162170"
  },
  {
    "text": "equal theta n. And so you use table\ndoubling to keep m theta n. Boom, you've got expected\nchain length constant.",
    "start": "1162170",
    "end": "1170580"
  },
  {
    "text": "But in the theory world\nexpected is a very weak bound.",
    "start": "1170580",
    "end": "1176090"
  },
  {
    "text": "What we want are high\nprobability bounds. So let me tell you a little bit\nabout high probability bounds. This, you may not\nhave seen as much.",
    "start": "1176090",
    "end": "1182390"
  },
  {
    "start": "1182390",
    "end": "1190520"
  },
  {
    "text": "Let's start with if your hash\nfunction is totally random, then your chain lengths will be\norder log m over a log log n,",
    "start": "1190520",
    "end": "1201914"
  },
  {
    "text": "with high probability. They are not constant. In fact, you expect\nthe maximum chain",
    "start": "1201914",
    "end": "1207680"
  },
  {
    "text": "to be at least log\nn over log log n. I won't prove that here. Instead, I'll prove\nthe upper bound.",
    "start": "1207680",
    "end": "1213670"
  },
  {
    "text": "So the claim is that while\nin expectation each of them",
    "start": "1213670",
    "end": "1220240"
  },
  {
    "text": "is constant, variance\nis essentially high. ",
    "start": "1220240",
    "end": "1232610"
  },
  {
    "text": "Actually let's talk about\nvariance a little bit. Sorry, I'm getting distracted. ",
    "start": "1232610",
    "end": "1241470"
  },
  {
    "text": "So you might say, oh\nOK, expectation is nice. Let's look at variance. Turns out variance is\nconstant for these chains.",
    "start": "1241470",
    "end": "1249905"
  },
  {
    "text": "There are various\ndefinitions of variance. ",
    "start": "1249905",
    "end": "1255010"
  },
  {
    "text": "But in particular the formula\nI want to use is this one. ",
    "start": "1255010",
    "end": "1261471"
  },
  {
    "text": "It writes it as\nsome expectations. Now, this expected chain\nlength we know is constant.",
    "start": "1261472",
    "end": "1268057"
  },
  {
    "text": "So you square it,\nit's still constant. So that's sort of irrelevant. The interesting part is what\nis the expected squared chain",
    "start": "1268057",
    "end": "1275995"
  },
  {
    "text": "length. Now this is going to depend\nexactly on your hash function. Let's analyze it\nfor totally random.",
    "start": "1275995",
    "end": "1282570"
  },
  {
    "text": "In general, we just need a\ncertain kind of symmetry here. You can write I will look at the\nexpected squared chain lengths.",
    "start": "1282570",
    "end": "1295890"
  },
  {
    "text": " And instead, what I'd like to\ndo is just sum over all of them.",
    "start": "1295890",
    "end": "1305770"
  },
  {
    "text": "This is going to be\neasier to analyze. So this is expected\nsquared chain lengths. If I sum over all chains and\nthen divide, take the average,",
    "start": "1305770",
    "end": "1315520"
  },
  {
    "text": "then I'll probably\nget the expected chain length of any individual. As long as your hash\nfunction is symmetric all the keys are sort\nof equally likely.",
    "start": "1315520",
    "end": "1322019"
  },
  {
    "text": "This will be true.  And then you could\njust basically",
    "start": "1322020",
    "end": "1327300"
  },
  {
    "text": "apply a random\npermutation to your keys to make this true\nif it isn't already. ",
    "start": "1327300",
    "end": "1333360"
  },
  {
    "text": "Now this thing is\njust the number of pairs of keys that collide.",
    "start": "1333360",
    "end": "1340240"
  },
  {
    "text": "So you can forget about\nslots, this is just the sum",
    "start": "1340240",
    "end": "1345850"
  },
  {
    "text": "overall pairs of keys\nij of the probability",
    "start": "1345850",
    "end": "1352390"
  },
  {
    "text": "that xi hashes to\nthe same spot as xj.",
    "start": "1352390",
    "end": "1357400"
  },
  {
    "text": "And that's something we\nknow by universality. This is 1 over m.",
    "start": "1357400",
    "end": "1363789"
  },
  {
    "text": "Big O. The number of\npairs is m squared.",
    "start": "1363790",
    "end": "1369940"
  },
  {
    "text": "So we get m squared times\n1 over m, times 1 over m. This is constant. ",
    "start": "1369940",
    "end": "1378620"
  },
  {
    "text": "So the variance\nis actually small. It's not a good indicator of\nhow big our chains can get. Because still, with time\nprobability one of the chains",
    "start": "1378620",
    "end": "1385960"
  },
  {
    "text": "will be log n over log log n. It's just typical one won't be. Let's prove the upper bound.",
    "start": "1385960",
    "end": "1392740"
  },
  {
    "text": "This uses Chernoff bounds. ",
    "start": "1392740",
    "end": "1398090"
  },
  {
    "text": "This is a tail\nbound, essentially. I haven't probably defined\nwith high probability.",
    "start": "1398090",
    "end": "1403330"
  },
  {
    "text": "It's probably good to\nremember, review this. This means probability\nat least 1 minus 1",
    "start": "1403330",
    "end": "1408640"
  },
  {
    "text": "over n to c where I get\nto choose any constant c.",
    "start": "1408640",
    "end": "1414370"
  },
  {
    "text": "So high probability means\npolynomially small failure probability.",
    "start": "1414370",
    "end": "1420250"
  },
  {
    "text": "This is good because if you do\nthis polynomially many times this property remains true.",
    "start": "1420250",
    "end": "1426280"
  },
  {
    "text": "You just up your constant\nby however many times you're going to use it.",
    "start": "1426280",
    "end": "1431840"
  },
  {
    "text": "So we prove these kinds of\nbounds using Chernov, which looks something like this.",
    "start": "1431840",
    "end": "1438460"
  },
  {
    "text": "e to the c minus 1\nmu over c mu c mu.",
    "start": "1438460",
    "end": "1447607"
  },
  {
    "text": "So mu here is the mean. The mean we've already\ncomputed is constant.",
    "start": "1447608",
    "end": "1452820"
  },
  {
    "text": "The expectation of the\nct variable is constant. So we want it to be not\nmuch larger than that.",
    "start": "1452820",
    "end": "1460340"
  },
  {
    "text": "So say the probability that\nit's some factor larger-- c doesn't have to be constant\nhere, sorry, maybe not",
    "start": "1460340",
    "end": "1466480"
  },
  {
    "text": "great terminology. So the probability of ct is at\nleast some c times the mean,",
    "start": "1466480",
    "end": "1474839"
  },
  {
    "text": "is going to be at\nmost this exponential. Which is a bit\nannoying, or a bit ugly.",
    "start": "1474839",
    "end": "1479980"
  },
  {
    "text": "But in particular, if we plug in\nc equals log n over log log n,",
    "start": "1479980",
    "end": "1485626"
  },
  {
    "text": "use that as our factor, which is\nwhat we're concerned about here",
    "start": "1485626",
    "end": "1490840"
  },
  {
    "text": "then. We get that this probability\nis essentially dominated",
    "start": "1490840",
    "end": "1498070"
  },
  {
    "text": "by the bottom term here. And this becomes\nlog n over log log n",
    "start": "1498070",
    "end": "1507100"
  },
  {
    "text": "to the power log\nn over log log n. ",
    "start": "1507100",
    "end": "1512620"
  },
  {
    "text": "So essentially, get 1 over that. And if you take this bottom part\nand put it into the exponent,",
    "start": "1512620",
    "end": "1521470"
  },
  {
    "text": "you get essentially log log n. So this is something\nlike 1 over 2",
    "start": "1521470",
    "end": "1527035"
  },
  {
    "text": "to the log n over log\nlog n times log log n.",
    "start": "1527035",
    "end": "1533780"
  },
  {
    "text": "And the log log n's cancel. And so this is\nbasically 1 over n. And if you put a\nconstant in here",
    "start": "1533780",
    "end": "1540850"
  },
  {
    "text": "you can get a constant\nin the exponent here. So you can get failure\nprobability 1 over n to the c.",
    "start": "1540850",
    "end": "1547366"
  },
  {
    "text": "So get this with\nhigh probability bound as long as\nyou go up to a chain",
    "start": "1547366",
    "end": "1553690"
  },
  {
    "text": "length of log n over log log n. It's not true otherwise. So this is kind of depressing. It's one reason we will\nturn to perfect hashing,",
    "start": "1553690",
    "end": "1561070"
  },
  {
    "text": "some of the chains are long. But there is a sense in\nwhich this is not so bad. ",
    "start": "1561070",
    "end": "1568910"
  },
  {
    "text": "So let me go to that. ",
    "start": "1568910",
    "end": "1581019"
  },
  {
    "text": "I kind of want all these. ",
    "start": "1581020",
    "end": "1589432"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]  ERIK DEMAINE: What's that?",
    "start": "1589432",
    "end": "1594694"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Since\nwhen is log n long. Well-- AUDIENCE: [INAUDIBLE]",
    "start": "1594694",
    "end": "1600960"
  },
  {
    "text": "ERIK DEMAINE: Right, so\nI mean, in some sense the name of the\ngame here is we want to beat binary search trees.",
    "start": "1600960",
    "end": "1606300"
  },
  {
    "text": "I didn't even mention what\nproblem we're solving. We're solving the\ndictionary problem, which is sort of bunch of\nkeys, insert delete,",
    "start": "1606300",
    "end": "1612840"
  },
  {
    "text": "and search is now\njust exact search. I want to know is\nthis key in there? If so, find some data\nassociated with it.",
    "start": "1612840",
    "end": "1619660"
  },
  {
    "text": "Which is something binary search\ntrees could do, n log n time. And we've seen\nvarious fancy ways",
    "start": "1619660",
    "end": "1624750"
  },
  {
    "text": "to try to make that better. But in the worst case,\nyou need log n time to do binary search trees. We want to get to constant\nas much as possible.",
    "start": "1624750",
    "end": "1632940"
  },
  {
    "text": "We want the hash function to be\nevaluatable in constant time. We want the queries to\nbe done in constant time.",
    "start": "1632940",
    "end": "1641280"
  },
  {
    "text": "If you have a long chain, you've\ngot to search the whole chain and I don't want to spend\nlog n over log log n.",
    "start": "1641280",
    "end": "1649290"
  },
  {
    "text": "Because I said so. Admittedly, log n over\nlog log n is not that big. And furthermore,\nthe following holds.",
    "start": "1649290",
    "end": "1656470"
  },
  {
    "text": "This is a sense in\nwhich it's not really log n over log log n. If we change the\nmodel briefly and say,",
    "start": "1656470",
    "end": "1666230"
  },
  {
    "text": "well, suppose I have a cache\nof the last log n items that I searched for\nin the hash table.",
    "start": "1666230",
    "end": "1673420"
  },
  {
    "text": " Then if you're\ntotally random, which",
    "start": "1673420",
    "end": "1680039"
  },
  {
    "text": "is something we\nassumed here in order to apply the Chernoff bound,\nwe needed that everything was completely random.",
    "start": "1680039",
    "end": "1686750"
  },
  {
    "text": "Then you get a constant\namortized bound per operation.",
    "start": "1686750",
    "end": "1692050"
  },
  {
    "text": " So this is kind of funny. In fact, all it's saying\nthis is easy to prove.",
    "start": "1692050",
    "end": "1700549"
  },
  {
    "text": "And it's not yet in any paper. It's on Mihai Petrescu's\nblog from 2011.",
    "start": "1700550",
    "end": "1710440"
  },
  {
    "text": "All right, we're here. We're looking at\ndifferent chains. So you access some chain,\nthen you access another chain, then you access another chain.",
    "start": "1710440",
    "end": "1717640"
  },
  {
    "text": "If you're unlucky,\nyou'll hit the big chain which cost log n\nover over log log n to touch, which is expensive.",
    "start": "1717640",
    "end": "1726190"
  },
  {
    "text": "But you could then put\nall those guys into cache, and if you happen to\nkeep probing there",
    "start": "1726190",
    "end": "1732320"
  },
  {
    "text": "you know it should be faster. In general, you do\na bunch of searches.",
    "start": "1732320",
    "end": "1738370"
  },
  {
    "text": "OK, first I search for x1, then\nI search for x2, x3, so on.",
    "start": "1738370",
    "end": "1746020"
  },
  {
    "text": "Cluster those into\ngroups theta log n. OK, let's look at\nthe first log n",
    "start": "1746020",
    "end": "1752080"
  },
  {
    "text": "searches, then the next log\nn searches, and analyze those separately. We're going to amortize\nover that period of log n.",
    "start": "1752080",
    "end": "1760130"
  },
  {
    "text": "So if we look at theta log n--",
    "start": "1760130",
    "end": "1765290"
  },
  {
    "text": "actually, this is\nwritten in a funny way. ",
    "start": "1765290",
    "end": "1774342"
  },
  {
    "text": "You've got the data, just log n. ",
    "start": "1774342",
    "end": "1782590"
  },
  {
    "text": "So I'm going to look at a\nbatch of log n operations. And I claim that\nthe number of keys",
    "start": "1782590",
    "end": "1788590"
  },
  {
    "text": "that collide with them is theta\nlog n, with high probability.",
    "start": "1788590",
    "end": "1796126"
  },
  {
    "text": " If this is true, then\nit's constant each.",
    "start": "1796126",
    "end": "1806460"
  },
  {
    "text": "If I can do log n operations\nby visiting order log n total chain items with\nhigh probability,",
    "start": "1806460",
    "end": "1813810"
  },
  {
    "text": "then I just charge one each. And so amortized over\nthis little log n window of sort of smoothing the cost.",
    "start": "1813810",
    "end": "1820470"
  },
  {
    "text": "With high probability\nnow, not just expectation, I get constant\namortized per operation.",
    "start": "1820470",
    "end": "1826560"
  },
  {
    "text": "So I should have said,\nwith high probability. ",
    "start": "1826560",
    "end": "1833040"
  },
  {
    "text": "Why is this true? It's essentially\nthe same argument. Here this is normally called\na balls and bin argument.",
    "start": "1833040",
    "end": "1840000"
  },
  {
    "text": "So you're throwing balls,\nwhich are your keys, randomly into your bins,\nwhich are your slots.",
    "start": "1840000",
    "end": "1846600"
  },
  {
    "text": "And the expectation is constant\nprobability to any one of them, I mean any one of\nthem could go up",
    "start": "1846600",
    "end": "1852990"
  },
  {
    "text": "to log n over log log\nn, high probability. Over here, we're looking\nat log n different slots",
    "start": "1852990",
    "end": "1859950"
  },
  {
    "text": "and taking the sum of balls that\nfall into each of the slots.",
    "start": "1859950",
    "end": "1864990"
  },
  {
    "text": "And in expectation that's log\nn, because it's constant each. An expectation is\nlinear if you're taking",
    "start": "1864990",
    "end": "1870120"
  },
  {
    "text": "the sum over these log n bins. So the expectation is log n. So you apply Chernoff again.",
    "start": "1870120",
    "end": "1876390"
  },
  {
    "text": "Except now the mean is log n. And then it suffices\nto put c equals 2.",
    "start": "1876390",
    "end": "1882080"
  },
  {
    "text": "We can run through this. So here we get the\nmean is theta log n.",
    "start": "1882080",
    "end": "1887130"
  },
  {
    "text": "We expect there to\nbe log n items that fall into these log n bins.",
    "start": "1887130",
    "end": "1893190"
  },
  {
    "text": "And so you just plug in c equals\n2 to the Chernoff bound and you get e to the log n--\nwhich is kind of weird--",
    "start": "1893190",
    "end": "1901860"
  },
  {
    "text": "over 2 log n to the 2 log n.",
    "start": "1901860",
    "end": "1909420"
  },
  {
    "text": "So this thing is like\nn to the log log n 2.",
    "start": "1909420",
    "end": "1918060"
  },
  {
    "text": "So this is big, way\nbigger than this. So this essentially disappears. And in particular, this is\nbigger than 1 over n to the c,",
    "start": "1918060",
    "end": "1926880"
  },
  {
    "text": "for any c. So log log n is bigger\nthan any constant.",
    "start": "1926880",
    "end": "1931899"
  },
  {
    "text": "So you're done. So that's just saying\nthe probability that you're more than twice\nthe mean is very, very small.",
    "start": "1931900",
    "end": "1938700"
  },
  {
    "text": "So with high probability\nthere's only log n items that fall in these log n bins. So you just amortize,\nboom, constant.",
    "start": "1938700",
    "end": "1945510"
  },
  {
    "text": "This is kind of a weird notion. I've never actually seen\namortized with high probability ever in a paper.",
    "start": "1945510",
    "end": "1951070"
  },
  {
    "text": "This is the first time it\nseems like a useful concept. So if you think log n\nover log log n is bad,",
    "start": "1951070",
    "end": "1960159"
  },
  {
    "text": "this is a sense\nin which it's OK. Don't worry about it.",
    "start": "1960160",
    "end": "1965820"
  },
  {
    "text": "All right, but if you did worry\nabout it, next thing you do is perfect hashing.",
    "start": "1965820",
    "end": "1973790"
  },
  {
    "start": "1973790",
    "end": "1992266"
  },
  {
    "text": "So, perfect hashing is\nreally just an embellishment. This is also called FKS hashing.",
    "start": "1992266",
    "end": "2001000"
  },
  {
    "text": "From the authors, Friedman,\nKomlosh, and [? Samaretti. ?]",
    "start": "2001000",
    "end": "2007800"
  },
  {
    "text": "This is from 1984, so old idea. You just take\nchaining, but instead",
    "start": "2007800",
    "end": "2013169"
  },
  {
    "text": "of storing your chains\nin a linked list, store them in a hash table. Simple idea.",
    "start": "2013170",
    "end": "2018549"
  },
  {
    "text": "There's one clever trick. ",
    "start": "2018550",
    "end": "2024036"
  },
  {
    "text": "You store it in\na big hash table.  Hash table of size\ntheta ct squared.",
    "start": "2024036",
    "end": "2033175"
  },
  {
    "text": " Now this looks like a\nproblem because that's",
    "start": "2033175",
    "end": "2038761"
  },
  {
    "text": "going to be quadratic space,\nin the worst case, if everybody hashes to the same chain. But we know that\nchains are pretty",
    "start": "2038761",
    "end": "2044260"
  },
  {
    "text": "small with high probability. So turns out this is OK.",
    "start": "2044260",
    "end": "2049989"
  },
  {
    "text": "The space is sum of ct squared.",
    "start": "2049989",
    "end": "2055454"
  },
  {
    "text": " And that's something we\nactually computed already,",
    "start": "2055454",
    "end": "2061760"
  },
  {
    "text": "except I erased it. How convenient of me. It was right here. I can still barely read it.",
    "start": "2061760",
    "end": "2066780"
  },
  {
    "text": "When we computed the variance. We can do it again it's\nnot really that hard. This is the number of\npairs of keys that collide.",
    "start": "2066780",
    "end": "2074770"
  },
  {
    "text": "And so there's n squared\npairs and each of them",
    "start": "2074770",
    "end": "2079980"
  },
  {
    "text": "has a probability 1 over\nme of colliding if you have a universal hash function.",
    "start": "2079980",
    "end": "2085300"
  },
  {
    "text": "So this is n squared\nover m, which if m is within a constant\nfactor of n, is linear.",
    "start": "2085300",
    "end": "2092580"
  },
  {
    "start": "2092580",
    "end": "2099890"
  },
  {
    "text": "So linear space in expectation. ",
    "start": "2099890",
    "end": "2104990"
  },
  {
    "text": "Expected amount of\nspace is linear. I won't try to do with high\nprobability bound here.",
    "start": "2104990",
    "end": "2110580"
  },
  {
    "text": "What else can I say? ",
    "start": "2110580",
    "end": "2116190"
  },
  {
    "text": "You have to play a similar\ntrick when you're actually building these hash tables. All right, so why\ndo we use n squared?",
    "start": "2116190",
    "end": "2122849"
  },
  {
    "text": "Because of the birthday paradox. So if you have a hash table of\nsize n squared, essentially,",
    "start": "2122850",
    "end": "2129869"
  },
  {
    "text": "or ct squared with\nhigh probability or constant probability you\ndon't get any collisions.",
    "start": "2129870",
    "end": "2137560"
  },
  {
    "text": "Why? Because then they expected\nnumber of collisions in ct.",
    "start": "2137560",
    "end": "2147200"
  },
  {
    "text": "Well, there's ct pairs\nor ct squared pairs. Each of them, if you're\nusing universal hashing,",
    "start": "2147200",
    "end": "2152970"
  },
  {
    "text": "had a probability of 1 over\nct squared of happening.",
    "start": "2152970",
    "end": "2158190"
  },
  {
    "text": "Because that's the\ntable size, 1 over m. So this is constant.",
    "start": "2158190",
    "end": "2164004"
  },
  {
    "text": "And if we set the\nconstants right, I get to set this theta\nto be whatever I want. I get this to be less than 1/2.",
    "start": "2164004",
    "end": "2172960"
  },
  {
    "text": "If the expected number of\ncollisions is less than 1/2, then the probability that\nthe number of collisions is 0",
    "start": "2172960",
    "end": "2185100"
  },
  {
    "text": "is at least a 1/2. This is Markov's\ninequality, in particular.",
    "start": "2185100",
    "end": "2191960"
  },
  {
    "text": "The probability number of\ncollisions is at least 1 is at most the expectation\nover 1, so which is 1/2.",
    "start": "2191960",
    "end": "2203990"
  },
  {
    "text": "So you try to build this table. If you have 0\ncollisions you're happy. You go on to the next one.",
    "start": "2203990",
    "end": "2209990"
  },
  {
    "text": "If you don't have 0\ncollisions, just try again. So in an expected\nconstant number of trials you're flipping\na coin each time.",
    "start": "2209990",
    "end": "2215440"
  },
  {
    "text": "Eventually you'll get heads. Then you can build this table. And then you have 0 collisions. So we always want them\nto be collision free.",
    "start": "2215440",
    "end": "2223040"
  },
  {
    "text": " So in an expected linear\ntime you can build this table",
    "start": "2223040",
    "end": "2232680"
  },
  {
    "text": "and it will have\nexpected linear space. In fact, if it doesn't\nhave linear space you can just try the\nwhole thing over again. So in expected\nlinear time you'll",
    "start": "2232680",
    "end": "2239300"
  },
  {
    "text": "build a guaranteed\nlinear space structure. The nice thing about\nperfect hashing is you're doing two hash\nde-references and that's it.",
    "start": "2239300",
    "end": "2246650"
  },
  {
    "text": "So the query is\nconstant deterministic.",
    "start": "2246650",
    "end": "2254049"
  },
  {
    "text": "Queries are now deterministic,\nonly updates are randomized. I didn't talk about updates.",
    "start": "2254050",
    "end": "2259760"
  },
  {
    "text": "I talked about building. The construction\nhere is randomized, queries are constant\ndeterministic.",
    "start": "2259760",
    "end": "2265819"
  },
  {
    "text": "Now, you can make this dynamic\nin pretty much the obvious way you say, OK, I want to insert.",
    "start": "2265820",
    "end": "2272700"
  },
  {
    "text": "So I compute which of the, it's\nessentially two level hashing.",
    "start": "2272700",
    "end": "2279410"
  },
  {
    "text": "So first you figure out where\nit fits in the big hash table, then you find the corresponding\nchain, which is now hash table,",
    "start": "2279410",
    "end": "2285920"
  },
  {
    "text": "and you insert into\nthat hash table. So it's the obvious thing. The trouble is you might get a\ncollision in that hash table.",
    "start": "2285920",
    "end": "2292190"
  },
  {
    "text": "If you get a collision, you\nrebuild that hash table. Probability of the collision\nhappening is essentially small.",
    "start": "2292190",
    "end": "2300740"
  },
  {
    "text": "It's going to remain small\nbecause of this argument. Because we know the expected\nnumber of collisions",
    "start": "2300740",
    "end": "2307700"
  },
  {
    "text": "remains small unless that\nchain gets really big. So if the chain grows\nby a factor of 2,",
    "start": "2307700",
    "end": "2313760"
  },
  {
    "text": "then generally you have\nto rebuild the table. But if your chain length\ngrows by a factor of 2,",
    "start": "2313760",
    "end": "2323119"
  },
  {
    "text": "then you rebuild your table\nto have factor 4 size larger because it's ct squared.",
    "start": "2323120",
    "end": "2330410"
  },
  {
    "text": "And in general, you\nmaintain that the table is sized for a chain of roughly\nthe correct chain length",
    "start": "2330410",
    "end": "2336590"
  },
  {
    "text": "within a constant factor. And you do doubling and halving\nin the usual way, like b-tree. Or, I guess it's\ntable doubling really.",
    "start": "2336590",
    "end": "2344840"
  },
  {
    "text": "And it will be\nconstant amortized expected per operation.",
    "start": "2344840",
    "end": "2351319"
  },
  {
    "text": "And there's a fancy way\nto make this constant with high probability\nper insert and delete,",
    "start": "2351320",
    "end": "2357410"
  },
  {
    "text": "which I have not read. But it's by [? Desfil ?]\nBinger and [? Meyer ?] [? Ofterheight, ?] 1990.",
    "start": "2357410",
    "end": "2363890"
  },
  {
    "text": "So, easy to make this\nexpected amortized. With more effort\nyou could make it",
    "start": "2363890",
    "end": "2369770"
  },
  {
    "text": "with high probability\nper operation. That is trickier.",
    "start": "2369770",
    "end": "2375980"
  },
  {
    "text": "Cool. I actually skipped one\nthing with chaining,",
    "start": "2375980",
    "end": "2382560"
  },
  {
    "text": "which I wanted to talk about. So this analysis was fine,\nit just used universality.",
    "start": "2382560",
    "end": "2389180"
  },
  {
    "text": "This cache analysis,\nI said totally random. This analysis, I\nsaid totally random. What about real hash functions?",
    "start": "2389180",
    "end": "2395579"
  },
  {
    "text": "We can't use totally random. What about universal k-wise\nindependent simple tabulation",
    "start": "2395580",
    "end": "2400760"
  },
  {
    "text": "hashing, just for chaining? OK, and similar things hold\nfor perfect hashing, I think.",
    "start": "2400760",
    "end": "2408380"
  },
  {
    "text": "I'm not sure if\nthey're all known. Oh, sorry, perfect hashing.",
    "start": "2408380",
    "end": "2413410"
  },
  {
    "text": "In expectation everything's\nfine, just with universal. So we've already done\nthat with universal. What about chaining?",
    "start": "2413410",
    "end": "2420310"
  },
  {
    "text": "How big can the chains get? I said log n over log log\nwith a high probability, but our analysis\nused Chernoff bound.",
    "start": "2420310",
    "end": "2425390"
  },
  {
    "text": "That's only true for\nBernoulli trials. It was only true for totally\nrandom hash functions. It turns out same\nis true if you have",
    "start": "2425390",
    "end": "2434030"
  },
  {
    "text": "a log n over log log n wise\nindependent hash function.",
    "start": "2434030",
    "end": "2444890"
  },
  {
    "text": "So this is kind of annoying. If you want this to be true\nyou need a lot of independence. And it's hard to get\nlog n independence.",
    "start": "2444890",
    "end": "2451340"
  },
  {
    "text": "There is a way to get constant,\nbut it needed a lot of space. That was this one, which\nis not so thrilling.",
    "start": "2451340",
    "end": "2462800"
  },
  {
    "text": "It's also kind of complicated. So if you don't mind\nthe space but you just",
    "start": "2462800",
    "end": "2471050"
  },
  {
    "text": "want it to be simpler, you can\nuse simple tabulation hashing. ",
    "start": "2471050",
    "end": "2478519"
  },
  {
    "text": "Both of these, the same chain\nanalysis turns out to work.",
    "start": "2478520",
    "end": "2483980"
  },
  {
    "text": "So this is fairly old. This is from 1995. This is from last year.",
    "start": "2483980",
    "end": "2491369"
  },
  {
    "text": "So if you just use this\nsimple tabulation hashing, still has a lot of\nspace, e to the epsilon.",
    "start": "2491370",
    "end": "2497540"
  },
  {
    "text": "But very simple to implement. Then still, the chain lengths\nare as you expect them to be.",
    "start": "2497540",
    "end": "2503780"
  },
  {
    "text": "And I believe that carries\nover to this caching argument, but I haven't checked it. ",
    "start": "2503780",
    "end": "2510120"
  },
  {
    "text": "All right.  Great, I think we're now happy.",
    "start": "2510120",
    "end": "2516490"
  },
  {
    "text": "We've talked about\nreal hash functions for chaining and\nperfect hashing.",
    "start": "2516490",
    "end": "2522200"
  },
  {
    "text": "Next thing we're going to\ntalk about is linear probing. I mean, in some sense we have\ngood theoretical answers now.",
    "start": "2522200",
    "end": "2527660"
  },
  {
    "text": "We can do constant\nexpected amortized even with constant\ndeterministic queries.",
    "start": "2527660",
    "end": "2535070"
  },
  {
    "text": "But we're greedy, or people\nlike to implement all sorts",
    "start": "2535070",
    "end": "2541260"
  },
  {
    "text": "of different hashing schemes. Perfect hashing is\npretty rare in practice. Why? I guess, because you have to\nhash twice instead of once",
    "start": "2541260",
    "end": "2548160"
  },
  {
    "text": "and that's just more expensive. So what about the\nsimpler hashing schemes? Simple tabulation hashing\nis nice and simple,",
    "start": "2548160",
    "end": "2554130"
  },
  {
    "text": "but what about linear probing?",
    "start": "2554130",
    "end": "2559380"
  },
  {
    "text": " That's really simple. ",
    "start": "2559380",
    "end": "2579130"
  },
  {
    "text": "Linear probing is\neither the first or the second hashing\nscheme you learned.",
    "start": "2579130",
    "end": "2584519"
  },
  {
    "text": "You store things in a table. ",
    "start": "2584519",
    "end": "2589554"
  },
  {
    "text": "The hash function\ntells you where to go. If that's full, you just\ngo to the next spot. If that's full, you\ngo to the next spot",
    "start": "2589554",
    "end": "2594910"
  },
  {
    "text": "till you find an empty slot\nand then you put x there. So if there's some y\nand z here, that that's",
    "start": "2594910",
    "end": "2601600"
  },
  {
    "text": "where you end up putting it. Everyone knows\nlinear probing is bad",
    "start": "2601600",
    "end": "2607450"
  },
  {
    "text": "because the rich get richer. It's like the\nparking lot problem. If you get big runs of elements\nthey're more likely to get hit,",
    "start": "2607450",
    "end": "2615940"
  },
  {
    "text": "so they're going to grow\neven faster and get worse. So you should never\nuse linear probing.",
    "start": "2615940",
    "end": "2623070"
  },
  {
    "text": "Has everyone learned that? It's all false, however.",
    "start": "2623070",
    "end": "2629500"
  },
  {
    "text": "Linear probing is\nactually really good. And first indication is it's\nreally good in practice.",
    "start": "2629500",
    "end": "2634779"
  },
  {
    "text": "There's this small\nexperiment by Mihai Petrescu, who was an undergrad\nand PhD student here.",
    "start": "2634780",
    "end": "2642369"
  },
  {
    "text": "He's working on AT&T now. And he was doing\nsome experiments and he found that in\npractice on a network router",
    "start": "2642370",
    "end": "2648540"
  },
  {
    "text": "linear probing costs 10% more\ntime than a memory access.",
    "start": "2648540",
    "end": "2654250"
  },
  {
    "text": "So, basically free. Why?",
    "start": "2654250",
    "end": "2660819"
  },
  {
    "text": "You just set m to be 2 times\nn, or 1 plus epsilon times n, whatever.",
    "start": "2660820",
    "end": "2667570"
  },
  {
    "text": "It actually works really well. And I'd like to convince you\nthat it works really well. Now, first let me\ntell you some things.",
    "start": "2667570",
    "end": "2677680"
  },
  {
    "text": "The idea that it works\nreally well is old. For a totally\nrandom hash function",
    "start": "2677680",
    "end": "2696420"
  },
  {
    "text": "you require constant\ntime per operation. And Knuth actually\nshowed this first in 1962",
    "start": "2696420",
    "end": "2701490"
  },
  {
    "text": "in a technical report. The answer ends up being\n1 over epsilon squared. Now you might say,\n1 over epsilon",
    "start": "2701490",
    "end": "2706870"
  },
  {
    "text": "squared, oh that's really bad. And there are other\nschemes that achieve 1 over epsilon, which is better. But what's a little\nbit of space, right?",
    "start": "2706870",
    "end": "2714180"
  },
  {
    "text": "I mean, just set epsilon\nto 1, you're done. ",
    "start": "2714180",
    "end": "2719320"
  },
  {
    "text": "So I think linear probing\nwas bad when we really were tight on space. But when you can afford a factor\nof 2, linear probing is great.",
    "start": "2719320",
    "end": "2726212"
  },
  {
    "text": "That's the bottom line.  Now, this is totally\nrandom, not so useful.",
    "start": "2726212",
    "end": "2732450"
  },
  {
    "text": "What about all these\nother hash functions? Like universal,\nturns out universal with the universal\nhash function,",
    "start": "2732450",
    "end": "2738330"
  },
  {
    "text": "linear probing is\nreally, really bad. And that's why it\ngets a bad rap. But some good news.",
    "start": "2738330",
    "end": "2744720"
  },
  {
    "text": "OK, first result was\nlog n wise independence. This is extremely\nstrong but it also",
    "start": "2744720",
    "end": "2752220"
  },
  {
    "text": "implies constant\nexpected per operation. Not very exciting.",
    "start": "2752220",
    "end": "2759390"
  },
  {
    "text": "The big breakthrough was in\n2007 that five-wise independence",
    "start": "2759390",
    "end": "2764789"
  },
  {
    "text": "is enough. And this is why\nthis paper, Thorpe",
    "start": "2764790",
    "end": "2774310"
  },
  {
    "text": "was focusing in particular\non the case of k equals 4. Actually, they were\ndoing k equals 4, but they solved 5\nat the same time.",
    "start": "2774310",
    "end": "2782340"
  },
  {
    "text": "And so this was a very\nhighly optimized, practical, all that good stuff. Get five-wise independence,\nadmittedly with some space.",
    "start": "2782340",
    "end": "2790750"
  },
  {
    "text": "But it's pretty cool. So this is enough to\nget constant expected.",
    "start": "2790750",
    "end": "2800490"
  },
  {
    "text": "I shouldn't write order\n1, because I'm not writing the dependence on epsilon here.",
    "start": "2800490",
    "end": "2806190"
  },
  {
    "text": "I don't know exactly what it is. But it's some constant\ndepending on epsilon.",
    "start": "2806190",
    "end": "2811869"
  },
  {
    "text": "And then this turns\nout to be tight. There are four-wise\nindependent hash functions,",
    "start": "2811870",
    "end": "2821200"
  },
  {
    "text": "including I think the\npolynomial ones that we did. These guys that are really bad.",
    "start": "2821200",
    "end": "2829090"
  },
  {
    "text": "You can get really bad. They're as bad as\nbinary search trees. You can get constant expected.",
    "start": "2829090",
    "end": "2834670"
  },
  {
    "text": " So you really need\nfive-wise independence. It's kind of weird,\nbut it's true.",
    "start": "2834670",
    "end": "2842540"
  },
  {
    "text": "And the other fun fact is that\nsimple tabulation hashing also",
    "start": "2842540",
    "end": "2849460"
  },
  {
    "text": "achieves constant. And here it's known that it's\nalso 1 over epsilon squared. So it's just as good as totally\nrandom simple tabulation",
    "start": "2849460",
    "end": "2857180"
  },
  {
    "text": "hashing. Which is nice because\nagain, this is simple. Takes a bit of space but both\nof these have that property.",
    "start": "2857180",
    "end": "2866349"
  },
  {
    "text": "And so these are\ngood ways to use linear probing in particular. So you really need\na good hash function",
    "start": "2866350",
    "end": "2871650"
  },
  {
    "text": "for linear probing to work out. If you use the universal\nhash function like a times x mod p mod m it will fail.",
    "start": "2871650",
    "end": "2880270"
  },
  {
    "text": "But if you use a good hash\nfunction, which we're now getting to the point-- I mean, this is super\nsimple to implement.",
    "start": "2880270",
    "end": "2887100"
  },
  {
    "text": "It should work fine. I think would be a\nneat project to take a Python or something that had\nhash tables deep inside it,",
    "start": "2887101",
    "end": "2892930"
  },
  {
    "text": "replace-- I think they use quadratic\nprobing and universal hash functions.",
    "start": "2892930",
    "end": "2898750"
  },
  {
    "text": "If you instead use linear\nprobing and simple tabulation hashing, might do the same,\nmight do better, I don't know.",
    "start": "2898750",
    "end": "2905812"
  },
  {
    "text": "It's interesting. It would be a\nproject to try out. ",
    "start": "2905812",
    "end": "2911690"
  },
  {
    "text": "Cool. Well, I just quoted results. What I'd like to do is prove\nsomething like this to you.",
    "start": "2911690",
    "end": "2919790"
  },
  {
    "text": "Totally random hash functions\nimply some constant expected. I won't try to work out\nthe dependence on epsilon",
    "start": "2919790",
    "end": "2925800"
  },
  {
    "text": "because it's actually a pretty\nclean proof, it looks nice. ",
    "start": "2925800",
    "end": "2931750"
  },
  {
    "text": "Very data structures-y. ",
    "start": "2931750",
    "end": "2939810"
  },
  {
    "text": "I'm not going to\ncover Knut's proof. I'm essentially\ncovering this proof.",
    "start": "2939810",
    "end": "2947650"
  },
  {
    "text": "In this paper\nfive-wise independence implies constant expected. They re-prove the\ntotally random case",
    "start": "2947650",
    "end": "2953320"
  },
  {
    "text": "and strengthen it, analyze\nthe independence they need. ",
    "start": "2953320",
    "end": "2958690"
  },
  {
    "text": "Let's just do totally\nrandom unbiased constant",
    "start": "2958690",
    "end": "2966400"
  },
  {
    "text": "expected for linear probing. We obviously know how to do\nconstant expected already",
    "start": "2966400",
    "end": "2972520"
  },
  {
    "text": "with other fancy techniques. But linear probing\nseems really bad. Yet I claim, not so much.",
    "start": "2972520",
    "end": "2981580"
  },
  {
    "text": "And we're going to assume\nm is at least 3 times n.",
    "start": "2981580",
    "end": "2987822"
  },
  {
    "text": "That will just make\nthe analysis cleaner. But it does hold\nfor 1 plus epsilon. OK, so here's the idea.",
    "start": "2987822",
    "end": "2993760"
  },
  {
    "text": "We're going to take our array,\nour hash table, it's an array.",
    "start": "2993760",
    "end": "2998890"
  },
  {
    "text": " And build a binary tree\non it because that's",
    "start": "2998890",
    "end": "3004740"
  },
  {
    "text": "what we like to do. We do this every\nlecture pretty much.",
    "start": "3004740",
    "end": "3009900"
  },
  {
    "text": "This is kind of like ordered\nfile maintenance, I guess. This is just a conceptual tree. I mean, you're not even\ndefining an algorithm",
    "start": "3009900",
    "end": "3016380"
  },
  {
    "text": "based on this because the\nalgorithm is linear probing. You go into somewhere. You hop, hop, hop, hop until\nyou find a blank space.",
    "start": "3016380",
    "end": "3022140"
  },
  {
    "text": "You put your item there. OK, but each of these\nnodes defines an interval in the array, as we know.",
    "start": "3022140",
    "end": "3028320"
  },
  {
    "text": "So I'm going to call\na node dangerous,",
    "start": "3028320",
    "end": "3038880"
  },
  {
    "text": "essentially if its\ndensity is at least 2/3. But not in the literal sense\nbecause there's a little bit",
    "start": "3038880",
    "end": "3046920"
  },
  {
    "text": "of a subtlety here. There's the location\nwhere a key wants to live, which is h of that key.",
    "start": "3046920",
    "end": "3052740"
  },
  {
    "text": "And there's the location\nthat it ended up living. I care more about the\nfirst one because that's",
    "start": "3052740",
    "end": "3059400"
  },
  {
    "text": "what I understand. h of x, that's going to be nice. It's totally random.",
    "start": "3059400",
    "end": "3064770"
  },
  {
    "text": "So h of x is random\nindependent of everything else. Great. Where x ends up being,\nthat depends on other keys",
    "start": "3064770",
    "end": "3072190"
  },
  {
    "text": "and it depends on\nthis linear thing which I'm trying to understand. So I just want to talk\nabout the number of keys",
    "start": "3072190",
    "end": "3082140"
  },
  {
    "text": "that hash via h to the interval\nif that is at least 2/3 times",
    "start": "3082140",
    "end": "3094934"
  },
  {
    "text": "the length of the interval.  This is the number of slots\nthat are actually there.",
    "start": "3094935",
    "end": "3100710"
  },
  {
    "text": " We expect the number of keys\nthat hash via h to the interval",
    "start": "3100710",
    "end": "3107100"
  },
  {
    "text": "to be 1/2. So the expectation would be\n1/3 the length the interval. If it happens to be\n2/3 it could happen",
    "start": "3107100",
    "end": "3113850"
  },
  {
    "text": "because of high\nprobability, whatever. That's a dangerous node. That's the definition.",
    "start": "3113850",
    "end": "3119100"
  },
  {
    "text": "Those ones we worry\nwill be very expensive. And we worry that we're\ngoing to get super clustering and then get these\ngiant runs, and so on.",
    "start": "3119100",
    "end": "3126560"
  },
  {
    "start": "3126560",
    "end": "3150100"
  },
  {
    "text": "So, one thing I\nwant to compute was what's the probability\nof this happening.",
    "start": "3150100",
    "end": "3157010"
  },
  {
    "text": "Probability of a\nnode being dangerous. Well, we can again use\nChernoff bounds here",
    "start": "3157010",
    "end": "3162800"
  },
  {
    "text": "because we're in a\ntotally random situation. So this is the probability\nthat the number of things that went\nthere was bigger",
    "start": "3162800",
    "end": "3169220"
  },
  {
    "text": "than twice the expectation. The expectation is 1/2,\n2/3 is twice of 1/3.",
    "start": "3169220",
    "end": "3175370"
  },
  {
    "text": "So this is the probability that\nyou're at least twice the mean, which by Chernoff is small.",
    "start": "3175370",
    "end": "3183830"
  },
  {
    "text": "It comes out to e to\nthe mu over 2 to 2 mu.",
    "start": "3183830",
    "end": "3190825"
  },
  {
    "start": "3190825",
    "end": "3196460"
  },
  {
    "text": "So this is e over 4 to the mu. You can check e. It's 2.71828.",
    "start": "3196460",
    "end": "3204230"
  },
  {
    "text": "So this is less than 1,\nkind of roughly a half-ish.",
    "start": "3204230",
    "end": "3211580"
  },
  {
    "text": "So this is good. This is something like\n1 over 2 to the mu.",
    "start": "3211580",
    "end": "3216635"
  },
  {
    "text": "What's mu? ",
    "start": "3216635",
    "end": "3225260"
  },
  {
    "text": "mu is 1/3 2 to the h\nfor a height h node.",
    "start": "3225260",
    "end": "3233340"
  },
  {
    "text": "It depends on how high you are. If you're at a leaf h is 0, so\nyou expect 1/3 of an element",
    "start": "3233340",
    "end": "3238980"
  },
  {
    "text": "there. As you go up you\nexpect more elements to hash there, of course.",
    "start": "3238980",
    "end": "3244380"
  },
  {
    "text": "OK, so this gives\nus some measure in terms of this h\nof what's going on. But it's actually\ndoubly exponential in h.",
    "start": "3244380",
    "end": "3251550"
  },
  {
    "text": "So this is a very\nsmall probability. You go up a few levels. Like, after log\nlog n levels it's",
    "start": "3251550",
    "end": "3256670"
  },
  {
    "text": "a polynomially small\nprobability of happening. Because then 2 to the\nlog log n is log n.",
    "start": "3256670",
    "end": "3262700"
  },
  {
    "text": "And then e over 4 to\nthe log n is about n. OK. ",
    "start": "3262700",
    "end": "3269930"
  },
  {
    "text": "But at small levels this\nmay happen, near the leaves.",
    "start": "3269930",
    "end": "3275099"
  },
  {
    "text": "All right, so now I want to\nlook at a run in the table.",
    "start": "3275100",
    "end": "3281260"
  },
  {
    "text": "These are the things I\nhave trouble thinking about because runs tend to get\nbigger, and we worry about them.",
    "start": "3281260",
    "end": "3289500"
  },
  {
    "text": "This is now as items are\nactually stored at the table, when do I have a bunch of\nconsecutive items in there",
    "start": "3289500",
    "end": "3295950"
  },
  {
    "text": "that happen to end up\nin consecutive slots? ",
    "start": "3295950",
    "end": "3302280"
  },
  {
    "text": "So I'm worried about\nhow long that run is. So let's look at its\nlogarithm and round",
    "start": "3302280",
    "end": "3312299"
  },
  {
    "text": "to the nearest power of 2. So let's say it has\nlength about 2 to the l. Sorry, plus 1.",
    "start": "3312300",
    "end": "3317740"
  },
  {
    "text": " All right, between 2 to the\nl and 2 to the l plus 1.",
    "start": "3317740",
    "end": "3323890"
  },
  {
    "text": "OK, look at that. And it's spanned by some\nnumber of nodes of height h",
    "start": "3323890",
    "end": "3344160"
  },
  {
    "text": "equals l minus 3. OK, so there's some interval\nthat happens to be a run,",
    "start": "3344160",
    "end": "3351240"
  },
  {
    "text": "meaning all of these\nslots are occupied. And that's 2 to the\n2, I guess, since I",
    "start": "3351240",
    "end": "3358830"
  },
  {
    "text": "got to level negative 1. A little hard to do\nin a small picture. But we're worried about\nwhen this is really",
    "start": "3358830",
    "end": "3364799"
  },
  {
    "text": "big more than some constant. OK, so let's suppose I\nwas looking at this level.",
    "start": "3364800",
    "end": "3371460"
  },
  {
    "text": "Then this interval is\nspanned, in particular, by these two nodes. Now it's a little\nsloppy because this node",
    "start": "3371460",
    "end": "3378210"
  },
  {
    "text": "contains some non-interval,\nnon-run stuff, and so does this one. At the next level down it would\nbe this way one, this one,",
    "start": "3378210",
    "end": "3386750"
  },
  {
    "text": "and this one, which is\na little more precise. But it's never going\nto be quite perfect. But just take all\nthe nodes you need",
    "start": "3386750",
    "end": "3394349"
  },
  {
    "text": "to completely cover the run. Then this will be at least eight\nnodes because the length is",
    "start": "3394350",
    "end": "3403630"
  },
  {
    "text": "1 to the l. We went three levels\ndown, 2 to the 3 is 8. So if it's perfectly aligned\nit will be exactly 8 nodes.",
    "start": "3403630",
    "end": "3411839"
  },
  {
    "text": "In the worst case, it\ncould be as much as 17. Because potentially,\nwe're 2 to the l plus 1,",
    "start": "3411840",
    "end": "3420750"
  },
  {
    "text": "which means we have 16 nodes\nif we're perfectly aligned. But then if you shift\nif over it might be one more because of the slot.",
    "start": "3420750",
    "end": "3427750"
  },
  {
    "text": "OK, but some constant\nnumber of nodes. It's important that\nit's at least eight.",
    "start": "3427750",
    "end": "3433779"
  },
  {
    "text": "That's what we need. Actually, we just need\nthat's it at least five, but eight is the nearest\npower of two rounding up.",
    "start": "3433780",
    "end": "3442860"
  },
  {
    "text": "Cool. So, there they are. Now, I want to look at\nthe first four nodes",
    "start": "3442860",
    "end": "3450750"
  },
  {
    "text": "of these eight to 12 nodes. So first meaning leftmost. Earliest in the run.",
    "start": "3450750",
    "end": "3458107"
  },
  {
    "text": "So if you think about\nthem, so there's some four nodes each\nof them spans some--",
    "start": "3458107",
    "end": "3463325"
  },
  {
    "text": "I should draw these properly. ",
    "start": "3463325",
    "end": "3471090"
  },
  {
    "text": "What we know is that these guys\nare entirely filled with items.",
    "start": "3471090",
    "end": "3476630"
  },
  {
    "text": "The run occupies here. It's got to be at least one item\ninto here, but the rest of this",
    "start": "3476630",
    "end": "3481740"
  },
  {
    "text": "could be empty. And the interval keeps\ngoing to the right so we know that all of\nthese are completely filled with items somehow.",
    "start": "3481740",
    "end": "3489360"
  },
  {
    "text": "So let's start with how\nmany there are, I guess. They span more than three times\n2 to the h slots of the run.",
    "start": "3489360",
    "end": "3506940"
  },
  {
    "text": "So somehow 3 times 2 to the h-- because there's three of them\nthat are completely filled,",
    "start": "3506940",
    "end": "3512190"
  },
  {
    "text": "otherwise it would be four. Somehow three times two\nto the h items ended here.",
    "start": "3512190",
    "end": "3518490"
  },
  {
    "text": "Now, how did they end up here? Notice there's a blank\nspace right here.",
    "start": "3518490",
    "end": "3524910"
  },
  {
    "text": "By definition this was\nthe beginning of a run. Meaning the previous\nslot is empty.",
    "start": "3524910",
    "end": "3530380"
  },
  {
    "text": "Which means all of the\nkeys that wanted to live from here to the left got to.",
    "start": "3530380",
    "end": "3537480"
  },
  {
    "text": "So if we're just thinking\nabout the keys that ended up in this interval, they had to\ninitially hash to somewhere",
    "start": "3537480",
    "end": "3543840"
  },
  {
    "text": "in here. h put them somewhere\nin this interval and then they may have\nmoved to the right,",
    "start": "3543840",
    "end": "3550290"
  },
  {
    "text": "but they never move to\nthe left in linear hashing if you're not completely full. So because there was a blank\nspot here none of these keys",
    "start": "3550290",
    "end": "3557369"
  },
  {
    "text": "could have fallen over\nto here, no deletions.",
    "start": "3557370",
    "end": "3563310"
  },
  {
    "text": "So you're doing insertions. They may have just\nspread it out, and they made sconces have\ngone farther to the right,",
    "start": "3563310",
    "end": "3568950"
  },
  {
    "text": "or they may filled in\ngaps, whatever, but h put them in this interval. Now, I claim that in fact,\nat least one of these nodes",
    "start": "3568950",
    "end": "3580350"
  },
  {
    "text": "must be dangerous. Now dangerous is tricky,\nbecause dangerous is talking",
    "start": "3580350",
    "end": "3585359"
  },
  {
    "text": "about where h puts nodes. But we just said, got to be at\nleast three times two to the h",
    "start": "3585360",
    "end": "3591180"
  },
  {
    "text": "keys, where h put them\nwithin these four nodes, otherwise they wouldn't\nhave filled in here.",
    "start": "3591180",
    "end": "3598170"
  },
  {
    "text": "Now, if none of those\nnodes were dangerous,",
    "start": "3598170",
    "end": "3611520"
  },
  {
    "text": "then we'll get a contradiction. Because none of\nthem were dangerous",
    "start": "3611520",
    "end": "3617610"
  },
  {
    "text": "this means at most\n4 times 2/3 times 2",
    "start": "3617610",
    "end": "3625460"
  },
  {
    "text": "to the h keys hash\nvia h to them.",
    "start": "3625460",
    "end": "3632430"
  },
  {
    "start": "3632430",
    "end": "3637991"
  },
  {
    "text": "Why? Because there's\nfour of the nodes. Each of them, if it's not\ndangerous, has at most 2/3",
    "start": "3637991",
    "end": "3645210"
  },
  {
    "text": "of its size keys hashing there. 4 times 2/3 is 8/3, which is\nless than 9/3, which is 3.",
    "start": "3645210",
    "end": "3658670"
  },
  {
    "text": "OK, so this would\nbe a contradiction because we just argued that at\nleast 3 times 2 to the h nodes",
    "start": "3658670",
    "end": "3665070"
  },
  {
    "text": "have to hash via h to\nsomewhere in these nodes.",
    "start": "3665070",
    "end": "3670350"
  },
  {
    "text": "They might hash here and\nthen fallen over to here. So there is this kind of,\nthings can move to the right, we've got to worry about it.",
    "start": "3670350",
    "end": "3675900"
  },
  {
    "text": "But just look three\nlevels up and it's OK. ",
    "start": "3675900",
    "end": "3682146"
  },
  {
    "text": "So one of these nodes, not\nnecessarily all of them, are dangerous. ",
    "start": "3682146",
    "end": "3693380"
  },
  {
    "text": "And we can use that to\nfinish our analysis. ",
    "start": "3693380",
    "end": "3714690"
  },
  {
    "text": "This is good news\nbecause it says that if we have a run,\nwhich is something that's",
    "start": "3714690",
    "end": "3720230"
  },
  {
    "text": "hard to think about because\nnodes are moving around to form a run, so keys are\nmoving around to form a run,",
    "start": "3720230",
    "end": "3725540"
  },
  {
    "text": "we can charge it to\na dangerous node. Which is easy to think\nabout because that's just talking about where keys hash\nvia h, and h is totally random.",
    "start": "3725540",
    "end": "3736190"
  },
  {
    "text": "There's a loss of a\nfactor of 17, potentially. But it's a constant\nfactor, no big deal.",
    "start": "3736190",
    "end": "3743350"
  },
  {
    "text": "If we look at the probability\nthat the length of a run,",
    "start": "3743350",
    "end": "3748520"
  },
  {
    "text": "say containing some key x,\nhas length between 2 to the l",
    "start": "3748520",
    "end": "3757130"
  },
  {
    "text": "and to the l plus\n1, this is going to be at most 17 times the\nprobability of a node at height",
    "start": "3757130",
    "end": "3771335"
  },
  {
    "text": "l minus 3 is dangerous. ",
    "start": "3771335",
    "end": "3778970"
  },
  {
    "text": "Because we know one of them\nis, and so just to be sloppy it's at most the sum of the\nprobabilities that any of them",
    "start": "3778970",
    "end": "3785881"
  },
  {
    "text": "is. Then potentially there's\na run of that length. And so union bound it's at\nmost 17 times probability",
    "start": "3785881",
    "end": "3792020"
  },
  {
    "text": "of this happening. Now all nodes look the\nsame because we have a totally random hash function. So we just say any node\nat height l minus 3.",
    "start": "3792020",
    "end": "3800260"
  },
  {
    "text": "We already computed\nthat probability. That was this. Probability of being dangerous\nwas e over 4 to the 1/3 2",
    "start": "3800260",
    "end": "3807980"
  },
  {
    "text": "to the h. So this is going to be at most\n17 times e over 4 to the 2",
    "start": "3807980",
    "end": "3819250"
  },
  {
    "text": "to the l minus 3 power. Again, doubly exponential in l.",
    "start": "3819250",
    "end": "3828410"
  },
  {
    "text": "So if we want to compute\nthe expected run length",
    "start": "3828410",
    "end": "3837890"
  },
  {
    "text": "we can just expand\nout the definition. Well, let's round\nit to powers of 2.",
    "start": "3837890",
    "end": "3845765"
  },
  {
    "text": "It could be the run\nlength is about 2 to the l within a constant\nfactor of 2 to the l.",
    "start": "3845765",
    "end": "3851360"
  },
  {
    "text": "So it's going to be that\ntimes this probability.",
    "start": "3851360",
    "end": "3856474"
  },
  {
    "text": " But this thing is basically\n1 over 2 to the 2 to the l.",
    "start": "3856474",
    "end": "3865640"
  },
  {
    "text": "And so the whole\nthing is constant. ",
    "start": "3865640",
    "end": "3871640"
  },
  {
    "text": "This is l. I mean, l could go to infinity. I don't really care. ",
    "start": "3871640",
    "end": "3877319"
  },
  {
    "text": "I mean, this gets dwarfed\nby the double exponential. This is super geometric. So a very low probability\nof getting long runs.",
    "start": "3877320",
    "end": "3886470"
  },
  {
    "text": "As we said, after\na log log n size-- yeah, it's very unlikely\nto run longer than log n.",
    "start": "3886470",
    "end": "3894690"
  },
  {
    "text": "We proved that in particular. But in particular, you compute\nthe expected run length,",
    "start": "3894690",
    "end": "3899910"
  },
  {
    "text": "it's constant. OK, now this of course\nassumed totally random.",
    "start": "3899910",
    "end": "3907010"
  },
  {
    "text": "It's harder to prove-- where were we. Somewhere.",
    "start": "3907010",
    "end": "3912660"
  },
  {
    "text": "Linear probing. It's harder to prove five-wise\nindependence is enough, but it's true.",
    "start": "3912660",
    "end": "3917809"
  },
  {
    "text": "And it's much harder to\nprove simple tabulation hashing works, but it's true.",
    "start": "3917810",
    "end": "3922840"
  },
  {
    "text": "So we can use them. This gives you some intuition\nfor why it's really not that bad.",
    "start": "3922840",
    "end": "3928129"
  },
  {
    "text": "And similar proof\ntechniques are used for the five-wise independence.",
    "start": "3928129",
    "end": "3933569"
  },
  {
    "text": "Other fun facts. You can do similar caching\ntrick that we did before.",
    "start": "3933570",
    "end": "3940540"
  },
  {
    "text": "Again, the worst run is going\nto be log, or log over log log. I don't have it written here.",
    "start": "3940540",
    "end": "3948030"
  },
  {
    "text": "But if you cache the last-- it's not quite enough\nto do the last log n.",
    "start": "3948030",
    "end": "3955319"
  },
  {
    "text": "But if you cache the last log\nto the 1 plus epsilon n queries.",
    "start": "3955320",
    "end": "3966852"
  },
  {
    "text": "It's a little bit more. Then you can generalize\nthis argument. And so at least for totally\nrandom hash functions",
    "start": "3966852",
    "end": "3976230"
  },
  {
    "text": "you get constant amortize\nwith high probability. ",
    "start": "3976230",
    "end": "3986119"
  },
  {
    "text": "This weird thing that\nI've never seen before. But it's comforting because\nit's expected bounds are not",
    "start": "3986120",
    "end": "3994280"
  },
  {
    "text": "so great, but you get it\nwith high probability bound as long as you're willing\nto average over log to the 1",
    "start": "3994280",
    "end": "4000040"
  },
  {
    "text": "plus epsilon different queries. As long as you\ncan remember them. ",
    "start": "4000040",
    "end": "4006880"
  },
  {
    "text": "And the proof is\nbasically the same. Except now instead of looking\nat the length of a run",
    "start": "4006880",
    "end": "4012609"
  },
  {
    "text": "containing x, you're looking\nat the length of the run containing one of these log\nto the 1 plus epsilon n nodes.",
    "start": "4012610",
    "end": "4019810"
  },
  {
    "text": "That's your batch. And you do the same thing. But now do it with high\nprobability analysis.",
    "start": "4019810",
    "end": "4027140"
  },
  {
    "text": "But again, because\nthe expectation is now bigger than log,\nexpect there to be",
    "start": "4027140",
    "end": "4033250"
  },
  {
    "text": "a lot of fairly long runs here. But that's OK, because\non average is good.",
    "start": "4033250",
    "end": "4038440"
  },
  {
    "text": " You expect to pay log to\nthe 1 plus epsilon for log",
    "start": "4038440",
    "end": "4043820"
  },
  {
    "text": "to the 1 plus epsilon queries. And so then you divide and\namortize and you're done.",
    "start": "4043820",
    "end": "4050860"
  },
  {
    "text": "It's a little bit more\ndetails in the notes about that if you want to read.",
    "start": "4050860",
    "end": "4056020"
  },
  {
    "text": "I want to do one more\ntopic, unless there are questions about linear probing.",
    "start": "4056020",
    "end": "4063700"
  },
  {
    "text": "So, yeah? AUDIENCE: So, could you motivate\nwhy the [INAUDIBLE] value of mu",
    "start": "4063700",
    "end": "4069727"
  },
  {
    "text": "is the mean for\nwhatever quantity? ERIK DEMAINE: So mu is defined\nto be the mean of whatever",
    "start": "4069727",
    "end": "4075250"
  },
  {
    "text": "quantity we're analyzing. And the Chernoff bounds\nsays, probability",
    "start": "4075250",
    "end": "4080410"
  },
  {
    "text": "that you're at least\nsomething times the mean is the formula we wrote last time. Now here, we're measuring--",
    "start": "4080410",
    "end": "4089270"
  },
  {
    "text": "I didn't write what\nthe left-hand side was. But here we're measuring\nwhat's the probability that the number of keys that\nhash via h to the interval",
    "start": "4089270",
    "end": "4096370"
  },
  {
    "text": "is at least 2/3 the\nlength of the interval. Now, let's say m equals 3m then\nthe expected number of keys",
    "start": "4096370",
    "end": "4105759"
  },
  {
    "text": "that hash via h to interval\nis 1/3 times the length of the interval. Because we have a\ntotally random thing,",
    "start": "4105760",
    "end": "4112149"
  },
  {
    "text": "and we have a density\nof 1/3 overall. So you expect there\nto be 1/3 and so",
    "start": "4112149",
    "end": "4118270"
  },
  {
    "text": "dangerous is when you're\nmore than twice that. And so it's twice mu.",
    "start": "4118270",
    "end": "4124000"
  },
  {
    "text": "Mu is, in this case, 1/3\nthe length the interval. And that's why I wrote that. AUDIENCE: So this comes\nfrom the m squared.",
    "start": "4124000",
    "end": "4130294"
  },
  {
    "text": "[INAUDIBLE] ERIK DEMAINE: Yeah,\nit comes from m equals 3m and totally random. AUDIENCE: [INAUDIBLE]",
    "start": "4130294",
    "end": "4138180"
  },
  {
    "text": "ERIK DEMAINE: Yeah, OK\nlet's make this equal. Make this more formal.",
    "start": "4138180",
    "end": "4143600"
  },
  {
    "text": "It's an assumption, anyway,\nto simplify the proof. Good. Change that in the notes too.",
    "start": "4143600",
    "end": "4149689"
  },
  {
    "start": "4149689",
    "end": "4156089"
  },
  {
    "text": "Cool. So then the\nexpectation is exactly 1/3 instead of at most 1/3. So it's all a little cleaner.",
    "start": "4156090",
    "end": "4161330"
  },
  {
    "text": "Of course, this all works\nwhen m is at least 1 plus epsilon times\nn, but then you",
    "start": "4161330",
    "end": "4166580"
  },
  {
    "text": "get a dependence on epsilon. Other questions?",
    "start": "4166580",
    "end": "4172189"
  },
  {
    "text": "So bottom line is linear\nprobing is actually good. Quadratic probing, double\nhashing, all those fancy things",
    "start": "4172189",
    "end": "4179180"
  },
  {
    "text": "are also good. But they're really\ntuned for the case when your table is almost full.",
    "start": "4179180",
    "end": "4184399"
  },
  {
    "text": "They get a better\ndependence on epsilon, which is how close\nto the bound you are.",
    "start": "4184399",
    "end": "4189799"
  },
  {
    "text": "And so if you're constant\nfactor away from space bound, linear probing is just fine. As long as you have enough\nindependence, admittedly.",
    "start": "4189800",
    "end": "4197600"
  },
  {
    "text": "Double hashing, I\nbelieve, gets around that. It does not need so\nmuch independence.",
    "start": "4197600",
    "end": "4207030"
  },
  {
    "text": "OK. Instead of going\nto double hashing, I'm going to go to something\nkind of related double hashing,",
    "start": "4207030",
    "end": "4212980"
  },
  {
    "text": "which is cuckoo hashing. ",
    "start": "4212980",
    "end": "4225340"
  },
  {
    "text": "Cuckoo hashing is a weird idea. It's kind of a more extreme\nform of perfect hashing.",
    "start": "4225340",
    "end": "4232869"
  },
  {
    "text": "It says, look, perfect\nhashing did two hash queries.",
    "start": "4232870",
    "end": "4241420"
  },
  {
    "text": "So I did one hash evaluation\nand another hash evaluation followed it, which is OK.",
    "start": "4241420",
    "end": "4248680"
  },
  {
    "text": " But again, I want my queries to\nonly do two things, two probes.",
    "start": "4248680",
    "end": "4257560"
  },
  {
    "text": "So it's going to take\nthat concept of just two",
    "start": "4257560",
    "end": "4267090"
  },
  {
    "text": "and actually use\ntwo hash tables. So you've got B over here,\nI've got A over here.",
    "start": "4267090",
    "end": "4274080"
  },
  {
    "start": "4274080",
    "end": "4279270"
  },
  {
    "text": "And if you have a\nkey x, you hash it to a particular spot in\nA via g, and you hash it",
    "start": "4279270",
    "end": "4287300"
  },
  {
    "text": "to a particular spot in B via\nH. So you have two hash tables, two hash functions.",
    "start": "4287300",
    "end": "4292679"
  },
  {
    "start": "4292680",
    "end": "4302990"
  },
  {
    "text": "To do a query you\nlook at A of g of x,",
    "start": "4302990",
    "end": "4310880"
  },
  {
    "text": "and you look at B of h of x.",
    "start": "4310880",
    "end": "4315889"
  },
  {
    "text": "Oh sorry, I forgot to mention. The other great thing\nabout linear probing is that it's cache\nperformance is so great.",
    "start": "4315890",
    "end": "4321739"
  },
  {
    "text": "This is why it runs\nso fast in practice. Why it's only 10% slower\nthan a memory access. Because once you\naccess a single slot,",
    "start": "4321740",
    "end": "4329809"
  },
  {
    "text": "whole you get B slots in\na cache with block size B. So most of the time, because\nyour runs are very short,",
    "start": "4329810",
    "end": "4337989"
  },
  {
    "text": "you will find your\nanswer immediately. So that's why we kind\nof prefer linear probing in practice over all\nthe other schemes I'm",
    "start": "4337990",
    "end": "4344050"
  },
  {
    "text": "going to talk about. Well, cuckoo\nhashing is all right because it's only going to look\nat two places and that's it.",
    "start": "4344050",
    "end": "4351739"
  },
  {
    "text": "Doesn't go anywhere else. ",
    "start": "4351740",
    "end": "4356980"
  },
  {
    "text": "I guess with perfect hashing\nthe thing is you have more than two hash functions.",
    "start": "4356980",
    "end": "4362380"
  },
  {
    "text": "You have the first\nhash function which sends you to the first table. Then you look up a\nsecond hash function. Using that hash function\nyou rehash your value x.",
    "start": "4362380",
    "end": "4371011"
  },
  {
    "text": "Downside of that is you\ncan't compare those two hash functions in parallel. So if you're like\ntwo cores, you could",
    "start": "4371012",
    "end": "4377020"
  },
  {
    "text": "compute these two in\nparallel, look them both up simultaneously. So in that sense you\nsave a factor of 2",
    "start": "4377020",
    "end": "4382720"
  },
  {
    "text": "with some parallelism.  Now, the weird thing is\nthe way we do an insertion.",
    "start": "4382720",
    "end": "4392380"
  },
  {
    "text": "You try to put it in the\nA slot, or the B slot.",
    "start": "4392380",
    "end": "4402949"
  },
  {
    "text": "If either of them is\nempty you're golden. If neither of them\nare empty, you've",
    "start": "4402950",
    "end": "4408010"
  },
  {
    "text": "got to kick out whoever's there. So let's say if you kicked\nout y from it's A slot.",
    "start": "4408010",
    "end": "4421030"
  },
  {
    "text": " So we ended up\nputting x in this one,",
    "start": "4421030",
    "end": "4427659"
  },
  {
    "text": "so we end up kicking y\nfrom wherever it belonged. Then you move it to B of h of y.",
    "start": "4427660",
    "end": "4439750"
  },
  {
    "text": "There's only one other\nplace that that item can go, so you put it there instead.",
    "start": "4439750",
    "end": "4445060"
  },
  {
    "text": "In general, I think about A key\nit has two places it can go.",
    "start": "4445060",
    "end": "4451900"
  },
  {
    "text": "There's some slot in\nA, some slot in B. You can think of this as an\nedge in a bipartite graph.",
    "start": "4451900",
    "end": "4457040"
  },
  {
    "text": "So make vertices\nfor the A slots, vertices for the B slots.",
    "start": "4457040",
    "end": "4462190"
  },
  {
    "text": "Each edge is an item on a key. Key Can only live one\nspot in A, one spot in B",
    "start": "4462190",
    "end": "4468880"
  },
  {
    "text": "for this query to work. So what's happening\nis if both of these",
    "start": "4468880",
    "end": "4474820"
  },
  {
    "text": "are full you take\nwhoever is currently here and put them over in\ntheir corresponding slot",
    "start": "4474820",
    "end": "4481510"
  },
  {
    "text": "over in B. Now, that\none might be full, which means you've got to\nkick that guy to wherever he belongs in A, and so on.",
    "start": "4481510",
    "end": "4487929"
  },
  {
    "text": "If eventually you find an\nempty slot, great, you're done. Just chain reaction\nof cuckoo steps",
    "start": "4487930",
    "end": "4495040"
  },
  {
    "text": "where the bird's going\nfrom in and out, or from A to B, vice a versa.",
    "start": "4495040",
    "end": "4501010"
  },
  {
    "text": "If it terminates, you're happy. It doesn't terminate,\nyou're in trouble because you might get a cycle,\nor a few failure situations.",
    "start": "4501010",
    "end": "4509889"
  },
  {
    "text": "In that case you're screwed. There is no cuckoo\nhash table that works for your set of keys. In that case, you pick\nanother hash function,",
    "start": "4509890",
    "end": "4516820"
  },
  {
    "text": "rebuild from scratch. So it's kind of a\nweird hashing scheme because it can\nfail catastrophic.",
    "start": "4516820",
    "end": "4524469"
  },
  {
    "text": "Fortunately, it doesn't\nhappen too often. ",
    "start": "4524470",
    "end": "4533639"
  },
  {
    "text": "It still rubs me a funny way. I don't know what\nto say about it. ",
    "start": "4533640",
    "end": "4541450"
  },
  {
    "text": "OK, so you lose a\nfactor of 2 in space. ",
    "start": "4541450",
    "end": "4547910"
  },
  {
    "text": "2 deterministic\nprobes for a query. That's good news.",
    "start": "4547910",
    "end": "4553225"
  },
  {
    "start": "4553225",
    "end": "4558850"
  },
  {
    "text": "All right, now we get\nto, what about updates? So if it's fully random\nor log n-wise independent,",
    "start": "4558850",
    "end": "4575510"
  },
  {
    "text": "then you get a constant expected\nupdate, which is what we want.",
    "start": "4575510",
    "end": "4582110"
  },
  {
    "text": "Even with the rebuilding cost. So you'll have to rebuild about\nevery n squared insertions",
    "start": "4582110",
    "end": "4588290"
  },
  {
    "text": "you do. The way they say this\nis there's a 1 over n",
    "start": "4588290",
    "end": "4595670"
  },
  {
    "text": "build failure probability. ",
    "start": "4595670",
    "end": "4602050"
  },
  {
    "text": "There's a 1 over n chance\nthat your key set will be completely unsustainable.",
    "start": "4602050",
    "end": "4607856"
  },
  {
    "text": "If you want to put all n keys\ninto this table there's a 1 over n chance that\nit will be impossible and then you have to start over.",
    "start": "4607856",
    "end": "4614430"
  },
  {
    "text": "So amortize per insertion,\nthat's about 1 over n squared. Insertions you can do before\nthe whole thing falls apart",
    "start": "4614430",
    "end": "4620960"
  },
  {
    "text": "and you have to rebuild. So it's definitely\ngoing to be this should be amortize expected, I guess.",
    "start": "4620960",
    "end": "4628120"
  },
  {
    "text": "However you want\nto think about it. But it's another way to do\nconstant amortized expected.",
    "start": "4628120",
    "end": "4634920"
  },
  {
    "text": "Cool. The other thing that's known\nis that six-wise independence",
    "start": "4634920",
    "end": "4642000"
  },
  {
    "text": "is not enough. This was actually a\nproject in this class, I believe the first time\nit was offered in 2003.",
    "start": "4642000",
    "end": "4650270"
  },
  {
    "text": "Six-wise independence\nis not sufficient to get constant expected bound.",
    "start": "4650270",
    "end": "4655560"
  },
  {
    "text": " It will actually fail\nwith high probability",
    "start": "4655560",
    "end": "4661770"
  },
  {
    "text": "if you only have\nsix-wise independence. What's not known is, do you\nneed constant Independence?",
    "start": "4661770",
    "end": "4666780"
  },
  {
    "text": "Or log n independence? With log n, very low\nfailure probability. With six-wise, high\nprobability you fail.",
    "start": "4666780",
    "end": "4674250"
  },
  {
    "text": "Like, you fail with\nprobability 1 minus 1 over n. Not so good. ",
    "start": "4674250",
    "end": "4684530"
  },
  {
    "text": "Some good news is simple\ntabulation hashing. ",
    "start": "4684530",
    "end": "4693230"
  },
  {
    "text": "Means you will fail to build\nwith probability not 1 over n,",
    "start": "4693230",
    "end": "4703060"
  },
  {
    "text": "but 1 over n to the 1/3 power. ",
    "start": "4703060",
    "end": "4710340"
  },
  {
    "text": "And this is theta. This is tight. It's almost as good as this. We really only\nneed constant here.",
    "start": "4710340",
    "end": "4716470"
  },
  {
    "text": "This is to build\nthe entire table. So in this case you can\ninsert like n to the 4 those items before your\ntable self-destructs.",
    "start": "4716470",
    "end": "4723909"
  },
  {
    "text": "So simple tabulation hashing\nis, again, pretty good. That's I think\nthe hardest result",
    "start": "4723910",
    "end": "4731310"
  },
  {
    "text": "in this paper from last year. ",
    "start": "4731310",
    "end": "4739930"
  },
  {
    "text": "So I do have a\nproof of this one. ",
    "start": "4739930",
    "end": "4747107"
  },
  {
    "text": "Something like that. Or part of a proof. So me give you a rough\nidea how this works.",
    "start": "4747107",
    "end": "4753130"
  },
  {
    "text": "So if you're a fully\nrandom hash function.",
    "start": "4753130",
    "end": "4758620"
  },
  {
    "text": "The main concern is that what\nif this path is really long.",
    "start": "4758620",
    "end": "4763630"
  },
  {
    "text": "I claim that if an insert\nfollows a path of length k,",
    "start": "4763630",
    "end": "4776760"
  },
  {
    "text": "or the probability\nof this happening,",
    "start": "4776760",
    "end": "4781840"
  },
  {
    "text": "is actually at most\n1 over 2 to the k. It's very small. Exponentially small in k.",
    "start": "4781840",
    "end": "4787130"
  },
  {
    "text": " I just want to sketch how\nthis works because it's",
    "start": "4787130",
    "end": "4793170"
  },
  {
    "text": "a cool argument that's actually\nin this simple tabulation",
    "start": "4793170",
    "end": "4798630"
  },
  {
    "text": "paper. So the idea is the following. You have some really long path.",
    "start": "4798630",
    "end": "4804760"
  },
  {
    "text": "What I'm going to\ngive you is a way to encode the hash functions.",
    "start": "4804760",
    "end": "4813450"
  },
  {
    "text": "There's hash functions g and h. Each of them has n values.",
    "start": "4813450",
    "end": "4820380"
  },
  {
    "text": "Each of those values\nis log m bits. So if I just wrote them\ndown the obvious way,",
    "start": "4820380",
    "end": "4827300"
  },
  {
    "text": "it's 2 n log m bits to write\ndown those hash functions. Now we're assuming these\nare totally random hash",
    "start": "4827300",
    "end": "4834300"
  },
  {
    "text": "functions, which means\nyou need this many bits. But I claim that if you\nfollow a path of length k,",
    "start": "4834300",
    "end": "4841020"
  },
  {
    "text": "I can find a new\nencoding scheme, a way to write down g and h\nthat is basically minus k.",
    "start": "4841020",
    "end": "4848949"
  },
  {
    "text": "This many bits minus k. I get to save k bits. Now, it turns out\nthat can happen",
    "start": "4848950",
    "end": "4854730"
  },
  {
    "text": "but it happens only with\nprobability 1 over 2 to the k. This is an information\ntheoretic argument.",
    "start": "4854730",
    "end": "4859920"
  },
  {
    "text": "You might get lucky. And the g's and h's\nyou're trying to encode can be done with fewer\nbits, k fewer bits.",
    "start": "4859920",
    "end": "4867851"
  },
  {
    "text": "But that will only happen with\nprobability 1 over 2 to the k if g and h are totally random. So how do you do it?",
    "start": "4867851",
    "end": "4874040"
  },
  {
    "text": "Basically, I want\nto encode the things on the path slightly cheaper.",
    "start": "4874040",
    "end": "4880200"
  },
  {
    "text": "I'm going to save one\nbit per node on the path. So what do I need to do?",
    "start": "4880200",
    "end": "4886450"
  },
  {
    "text": "Well, the idea is OK, I\nwill start by writing down",
    "start": "4886450",
    "end": "4893220"
  },
  {
    "text": "this hash value. This takes log m bits to\nwrite down that hash value.",
    "start": "4893220",
    "end": "4899549"
  },
  {
    "text": "Then I'll write down\nthis hash value. That takes a log\nm bit, log m bits. Generally there's going to be\nroughly k log n to write down",
    "start": "4899549",
    "end": "4906150"
  },
  {
    "text": "all of the node hash values. Then I need to say\nthat it's actually x, this particular key that\ncorresponds to this edge.",
    "start": "4906150",
    "end": "4914940"
  },
  {
    "text": "So I've got to write that down. That's going to\ntake a log n bits to say that x is the\nguy for the first edge,",
    "start": "4914940",
    "end": "4921390"
  },
  {
    "text": "then y is the key that\ncorresponds to the second edge of the path, then z, then w. But nicely, things\nare ordered here.",
    "start": "4921390",
    "end": "4928680"
  },
  {
    "text": "So it only takes\nme to log n, k log n to write down all these guys.",
    "start": "4928680",
    "end": "4934420"
  },
  {
    "text": "So I get k times\nlog m plus log n.",
    "start": "4934420",
    "end": "4939540"
  },
  {
    "text": "Now if m is 2 times n, this\nis k times 2 log m minus 1.",
    "start": "4939540",
    "end": "4957525"
  },
  {
    "text": "So I get one bit of savings\nper k, per thing in the path.",
    "start": "4957525",
    "end": "4963130"
  },
  {
    "text": "Essentially because\nit's easier for me to write down these\nlabels to say, oh, it's the key x\nthat's going here.",
    "start": "4963130",
    "end": "4970777"
  },
  {
    "text": "Instead of having to write down\nslot names all the time, which cost log m bits, writing\ndown key names only",
    "start": "4970777",
    "end": "4976360"
  },
  {
    "text": "takes log n bits,\nwhich is a savings of 1 bit per thing on the path.",
    "start": "4976360",
    "end": "4982000"
  },
  {
    "text": "And so that was a quick\nsketch of how this proof goes. It's kind of neat,\ninformation theoretic argument",
    "start": "4982000",
    "end": "4987600"
  },
  {
    "text": "why the paths can't get long. You then have to worry\nabout cycles and things that look like this.",
    "start": "4987600",
    "end": "4994170"
  },
  {
    "text": "That's kind of messy. But same kind of\nargument generalizes. So that was your quick overview\nof lots of hashing stuff.",
    "start": "4994170",
    "end": "5003110"
  }
]
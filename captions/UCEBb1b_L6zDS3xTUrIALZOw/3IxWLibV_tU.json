[
  {
    "start": "0",
    "end": "16602"
  },
  {
    "text": "YUFEI ZHAO: We've been\nspending the past few lectures discussing Szemeredi's\nRegularity Lemma.",
    "start": "16602",
    "end": "21750"
  },
  {
    "text": "And one of the\nfirst applications that we discussed of\nthe Regularity Lemma is the triangle removal Lemma.",
    "start": "21750",
    "end": "29580"
  },
  {
    "text": "So today, I want to\nrevisit this topic and show you a strengthening\nof the Removal Lemma",
    "start": "29580",
    "end": "34860"
  },
  {
    "text": "for which new regularity\ntechniques are needed. ",
    "start": "34860",
    "end": "42030"
  },
  {
    "text": "But first, recall the\ngraph removal Lemma. ",
    "start": "42030",
    "end": "57690"
  },
  {
    "text": "In the graph removal Lemma,\nwe have that for every graph H",
    "start": "57690",
    "end": "63590"
  },
  {
    "text": "and epsilon bigger than zero,\nthere exists some delta such",
    "start": "63590",
    "end": "70040"
  },
  {
    "text": "that if an N vertex graph\nhas fewer than delta",
    "start": "70040",
    "end": "84730"
  },
  {
    "text": "and to the number of vertices\nof H, many copies of H,",
    "start": "84730",
    "end": "95270"
  },
  {
    "text": "then it can be made H-free by\nremoving fewer than epsilon N",
    "start": "95270",
    "end": "113619"
  },
  {
    "text": "squared edges.  Even in the case when\nH is a triangle, when",
    "start": "113620",
    "end": "121065"
  },
  {
    "text": "this is called a triangle\nremoval Lemma, even in that case, basically\nthe regularity method",
    "start": "121065",
    "end": "126330"
  },
  {
    "text": "is more or less the only\nway that we currently know how to prove this theorem. So we saw this a\nfew lectures ago.",
    "start": "126330",
    "end": "134310"
  },
  {
    "text": "What I would like\nto discuss today is a variant of\nthis result where",
    "start": "134310",
    "end": "139650"
  },
  {
    "text": "instead of considering\ncopies of H, we're now considering\ninduced copies of H. OK?",
    "start": "139650",
    "end": "149459"
  },
  {
    "text": "So this is the induced\ngraph removal Lemma",
    "start": "149460",
    "end": "155010"
  },
  {
    "text": "where the only difference is\nthat the hypothesis is now going to be changed to\ninduced copies of H.",
    "start": "155010",
    "end": "164910"
  },
  {
    "text": "And the conclusion\nis that you can make the graph induced H-free.",
    "start": "164910",
    "end": "171330"
  },
  {
    "text": "So let me remind\nyou, the difference between the induced\ngraph subgraph and the usual subgraph.",
    "start": "171330",
    "end": "179040"
  },
  {
    "text": "So we say that H is an induced\ncopy of G, induced subgraph",
    "start": "179040",
    "end": "192220"
  },
  {
    "text": "of G. If one can obtain H from\nG by deleting vertices of G.",
    "start": "192220",
    "end": "222842"
  },
  {
    "text": "You're not allowed\nto delete edges, but only allowed\nto delete vertices. So in other words,\nthe four cycle",
    "start": "222842",
    "end": "235520"
  },
  {
    "text": "is not an induced\nsubgraph because, well,",
    "start": "235520",
    "end": "245210"
  },
  {
    "text": "if you select four vertices, you\ndon't generate this four cycle. You get extra edges. So it is a subgraph, but\nnot an induced subgraph.",
    "start": "245210",
    "end": "252060"
  },
  {
    "start": "252060",
    "end": "260049"
  },
  {
    "text": "So it is a theorem, the\ninduced graph removal Lemma. So it's a theorem,\nand let's discuss how we may prove that theorem.",
    "start": "260050",
    "end": "266220"
  },
  {
    "text": "Question.  OK, question is, why is it\nstronger than the graph removal",
    "start": "266220",
    "end": "273000"
  },
  {
    "text": "lemma? So it's not stronger, but\nwe'll see the relationship",
    "start": "273000",
    "end": "280060"
  },
  {
    "text": "between the two. So I claim that it is more\ndifficult to do this theorem.",
    "start": "280060",
    "end": "286330"
  },
  {
    "text": "Any more questions? So let's pretend for a second\nthat whatever's in here",
    "start": "286330",
    "end": "297320"
  },
  {
    "text": "is not quite true. So here's an example. ",
    "start": "297320",
    "end": "306110"
  },
  {
    "text": "For example, if your H is\nthree isolated vertices.",
    "start": "306110",
    "end": "314360"
  },
  {
    "text": "So what is that saying? We're looking at\ncopies of H which are three isolated vertices.",
    "start": "314360",
    "end": "319700"
  },
  {
    "text": "So really you are looking at\ntriangles in g complement.",
    "start": "319700",
    "end": "326330"
  },
  {
    "text": "So this is exactly the\ntriangle removal lemma in the complement of g, but\nyou can't get rid of these guys",
    "start": "326330",
    "end": "335300"
  },
  {
    "text": "by removing edges. So we need to make\nthe modification where instead of\nremoving these edges,",
    "start": "335300",
    "end": "340580"
  },
  {
    "text": "we need to both remove and\nadd by adding or deleting.",
    "start": "340580",
    "end": "348080"
  },
  {
    "text": " So maybe at the same time. So you're allowed to add some\nedges, delete some edges.",
    "start": "348080",
    "end": "355050"
  },
  {
    "text": "But in total, you change no more\nthan epsilon n squared edges. So those are sometimes also\nknown as the edit distance.",
    "start": "355050",
    "end": "361080"
  },
  {
    "text": " You're allowed to change edges.",
    "start": "361080",
    "end": "368530"
  },
  {
    "text": "So you can add edges\nand delete edges. ",
    "start": "368530",
    "end": "376090"
  },
  {
    "text": "Any questions about\nthe statement?  All right, so let's\nthink about how would you",
    "start": "376090",
    "end": "384550"
  },
  {
    "text": "prove this result following\nthe proof that we did for the triangle removal lemma.",
    "start": "384550",
    "end": "390660"
  },
  {
    "text": "So let's pretend that\nwe go through this proof and think about\nwhat could go wrong. So remember in the application\nof the removal lemma,",
    "start": "390660",
    "end": "397840"
  },
  {
    "text": "so the recipe has three steps. The first step we\ndo a partition. ",
    "start": "397840",
    "end": "405420"
  },
  {
    "text": "So we partition applying\nSzemeredi's regularity lemma to this partition.",
    "start": "405420",
    "end": "410890"
  },
  {
    "text": "And the second step\nis do a cleaning,",
    "start": "410890",
    "end": "416400"
  },
  {
    "text": "and the two key things\nthat happen in the cleaning is we remove low density pairs\nof parts and irregular pairs.",
    "start": "416400",
    "end": "431130"
  },
  {
    "text": " And the third step\nwe claim that once we",
    "start": "431130",
    "end": "436380"
  },
  {
    "text": "do the cleaning, once\nwe remove those edges, the resulting\ngraphs should be H3.",
    "start": "436380",
    "end": "442230"
  },
  {
    "text": "Because if we're not H3, then\nby considering the vertex parts where H lie and applying\nthe counting lemma,",
    "start": "442230",
    "end": "449460"
  },
  {
    "text": "you can generate many\nmore copies of H. So these were the three\nmain steps in the proof",
    "start": "449460",
    "end": "455550"
  },
  {
    "text": "of the triangle removal lemma. So let's see what\nhappens when we try to apply this strategy\nto the induced version.",
    "start": "455550",
    "end": "463530"
  },
  {
    "text": "I mean, the partition you still\ndo the regularity partition. Nothing really changes there.",
    "start": "463530",
    "end": "470370"
  },
  {
    "text": "So let's see in the\ncleaning step what happens. For low density pairs--",
    "start": "470370",
    "end": "476460"
  },
  {
    "text": "well, so now we need to think\nabout not just low density pairs, but also\nhigh density pairs.",
    "start": "476460",
    "end": "481700"
  },
  {
    "text": "Because in the induced, we\nthink about edges and non-edges at the same time. So you might think of a\nstrategy which is like the edge",
    "start": "481700",
    "end": "489030"
  },
  {
    "text": "density is less than n. So less than epsilon, then\nyou remove all those edges.",
    "start": "489030",
    "end": "495479"
  },
  {
    "text": "And if the edge density is\nbigger than 1 plus epsilon, then you add all\nof those edges in.",
    "start": "495480",
    "end": "502100"
  },
  {
    "text": "So this is the\nnatural generalization of our strategy for\ntriangle removal lemma for the induced setting.",
    "start": "502100",
    "end": "507400"
  },
  {
    "text": "So so far,\neverything's still OK. But now what would you do\nfor the irregular pairs?",
    "start": "507400",
    "end": "513490"
  },
  {
    "text": " That's problematic.",
    "start": "513490",
    "end": "521029"
  },
  {
    "text": "Previously for\ntriangle removal lemma, we just said if a pair is\nirregular, get rid of that pair",
    "start": "521030",
    "end": "527270"
  },
  {
    "text": "and it will never show\nup in the counting stage. But that strategy\nno longer works.",
    "start": "527270",
    "end": "534540"
  },
  {
    "text": "Because for example, if\nyour graph H being counted",
    "start": "534540",
    "end": "539870"
  },
  {
    "text": "is this here, you do the\nregularity partition,",
    "start": "539870",
    "end": "548630"
  },
  {
    "text": "and one of your\npairs is irregular. So you, let's say, get rid of\nall those edges in between.",
    "start": "548630",
    "end": "556240"
  },
  {
    "text": "Then maybe you have\nsome embedding of H where you are going to\nuse the removed edges.",
    "start": "556240",
    "end": "565904"
  },
  {
    "text": " And now you don't\nhave a counting lemma.",
    "start": "565905",
    "end": "574040"
  },
  {
    "text": "You cannot say, I found this\ncopy of H in my changed graph.",
    "start": "574040",
    "end": "581070"
  },
  {
    "text": "And by the counting lemma I\ncould get many copies of H because you have no control over\nthis irregular pair anymore.",
    "start": "581070",
    "end": "587620"
  },
  {
    "text": "So the fact that you\nhave to add and remove makes it unclear\nwhat to do here,",
    "start": "587620",
    "end": "592660"
  },
  {
    "text": "and this is a big obstacle\nin the application of the regularity lemma to\nthe induced removal lemma",
    "start": "592660",
    "end": "599370"
  },
  {
    "text": "application. Any questions about\nthis obstacle? ",
    "start": "599370",
    "end": "608550"
  },
  {
    "text": "So make sure you understand\nwhy this is an issue. Otherwise you won't\nreally appreciate",
    "start": "608550",
    "end": "613840"
  },
  {
    "text": "what will happen next. So somehow we need to find some\nkind of regularity partition",
    "start": "613840",
    "end": "621630"
  },
  {
    "text": "to get no irregular pairs. So the question\nis, is there a way",
    "start": "621630",
    "end": "629779"
  },
  {
    "text": "to partition so that there\nare no irregular pairs?",
    "start": "629780",
    "end": "636580"
  },
  {
    "start": "636580",
    "end": "642130"
  },
  {
    "text": "For those of you who have\nstarted your homework problem on time, you realize\nthat the answer is no.",
    "start": "642130",
    "end": "649150"
  },
  {
    "text": "So one of the\nhomework problems is for you to show that for\nthe specific graph known as the half graph.",
    "start": "649150",
    "end": "654700"
  },
  {
    "text": " So there was an\nexample in homework",
    "start": "654700",
    "end": "660588"
  },
  {
    "text": "that for the half graph-- ",
    "start": "660588",
    "end": "668665"
  },
  {
    "text": "so you'll see in the\nhomework what this graph is-- you cannot partition it so that\nyou get rid of all irregular",
    "start": "668665",
    "end": "675050"
  },
  {
    "text": "pairs. Irregular pairs are\nnecessary in the statement of regularity lemma. ",
    "start": "675050",
    "end": "682240"
  },
  {
    "text": "So what I want to show\nyou today is a way to do what's called a strong\nregularity lemma in which you",
    "start": "682240",
    "end": "689400"
  },
  {
    "text": "obtain a somewhat different\nconsequence that will allow you to get rid of\nirregular pairs",
    "start": "689400",
    "end": "695438"
  },
  {
    "text": "in the more restricted setting.  So this is the issue,\nthe irregular pairs.",
    "start": "695438",
    "end": "702100"
  },
  {
    "start": "702100",
    "end": "708420"
  },
  {
    "text": "Before telling you what\nthis regularity lemma is, I want to give you a\nsmall generalization",
    "start": "708420",
    "end": "715050"
  },
  {
    "text": "of the induced graph removal\nlemma, or just a different way to think about the statement.",
    "start": "715050",
    "end": "720540"
  },
  {
    "text": "And you can think of it as\na colorful version instead of induced where you\nhave edges and no edges.",
    "start": "720540",
    "end": "728970"
  },
  {
    "text": "You can also have colored edges. So colorful removal\nlemma, although this name",
    "start": "728970",
    "end": "734190"
  },
  {
    "text": "is not standard. ",
    "start": "734190",
    "end": "741580"
  },
  {
    "text": "So colorful-- so when\nwe talk about graphs, it's colorful graph\nremoval lemma.",
    "start": "741580",
    "end": "749040"
  },
  {
    "text": "So for every k, r, and epsilon,\nthere exists delta such",
    "start": "749040",
    "end": "757490"
  },
  {
    "text": "that if curly H is a set of\nr edge of the complete graph",
    "start": "757490",
    "end": "778020"
  },
  {
    "text": "on little k vertices. So edge coloring just\nmeans using r colors",
    "start": "778020",
    "end": "783800"
  },
  {
    "text": "to color the edges. So there are no restrictions\nabout what are allowed, what are not allowed. So just a set of\npossible r colorings.",
    "start": "783800",
    "end": "792293"
  },
  {
    "text": "Then if the complete graph--",
    "start": "792293",
    "end": "802000"
  },
  {
    "start": "802000",
    "end": "807823"
  },
  {
    "text": "say it slightly differently. So then every r edge coloring\nof the complete graph",
    "start": "807823",
    "end": "824649"
  },
  {
    "text": "on n vertices with fewer than\ndelta fraction of its k vertex",
    "start": "824650",
    "end": "842850"
  },
  {
    "text": "subsets, say k vertex subgraphs,\nbelonging to the script H.",
    "start": "842850",
    "end": "860310"
  },
  {
    "text": "So every such graph can be made\ncurly H free by recoloring,",
    "start": "860310",
    "end": "874670"
  },
  {
    "text": "so using the same r colors, a\nfewer than epsilon fraction.",
    "start": "874670",
    "end": "889709"
  },
  {
    "text": "So less than epsilon fraction\nof the edges of this kn.",
    "start": "889710",
    "end": "900710"
  },
  {
    "text": " So in particular, the\nversion that we just stated,",
    "start": "900710",
    "end": "906540"
  },
  {
    "text": "the induced version, so the\ninduced graph removal lemma,",
    "start": "906540",
    "end": "916259"
  },
  {
    "text": "is the same as having two\ncolors and H having exactly one",
    "start": "916260",
    "end": "931450"
  },
  {
    "text": "red-blue coloring of k\nof the complete graph",
    "start": "931450",
    "end": "944620"
  },
  {
    "text": "on the same number\nof vertices as H. So you color red the edges\nand blue the non-edges,",
    "start": "944620",
    "end": "951930"
  },
  {
    "text": "for instance. And you're saying, I want to\ncolor the big complete graph",
    "start": "951930",
    "end": "958680"
  },
  {
    "text": "with red and blue in such a way\nthat there are very few copies of that pattern.",
    "start": "958680",
    "end": "963900"
  },
  {
    "text": "So then I can recolor\nthe red and blue in a small number of places to\nget rid of all such patterns.",
    "start": "963900",
    "end": "969750"
  },
  {
    "text": "So having a colored\npattern somewhere in your graph in this\ncomplete graph coloring is the same as having\nan induced subgraph.",
    "start": "969750",
    "end": "979170"
  },
  {
    "text": "Yeah? AUDIENCE: So after done-- like the statement after done\nis a really long sentence. Can I--",
    "start": "979170",
    "end": "984560"
  },
  {
    "text": "YUFEI ZHAO: Yeah, OK. So every r edge coloring of kn\nwith a small number of patterns",
    "start": "984560",
    "end": "997380"
  },
  {
    "text": "can be made h-free by recoloring\na small fraction of the edges.",
    "start": "997380",
    "end": "1003710"
  },
  {
    "text": "So like in a triangle\nremoval lemma, every graph with a small\nnumber of triangles",
    "start": "1003710",
    "end": "1009170"
  },
  {
    "text": "can be made\ntriangle-free by removing a small number of edges. ",
    "start": "1009170",
    "end": "1018020"
  },
  {
    "text": "Any other questions? So this is a restatement of\nthe induced removal lemma",
    "start": "1018020",
    "end": "1027079"
  },
  {
    "text": "with a bit more generality. It's OK if you like\nthis one more or less,",
    "start": "1027079",
    "end": "1032959"
  },
  {
    "text": "but let's talk about the\ninduced version from now on. But the same proofs that\nI will talk about also",
    "start": "1032960",
    "end": "1038449"
  },
  {
    "text": "applies to this version where\nyou have somewhat more colors. ",
    "start": "1038450",
    "end": "1046349"
  },
  {
    "text": "So the variant of the\nregularity lemma that we'll need is known as a strong\nregularity lemma.",
    "start": "1046349",
    "end": "1053370"
  },
  {
    "start": "1053370",
    "end": "1067320"
  },
  {
    "text": "To state the strong\nregularity lemma, let me recall a notion that came\nup in the proof of Szemeredi's",
    "start": "1067320",
    "end": "1072419"
  },
  {
    "text": "regularity lemma. And this was the\nnotion of an energy.",
    "start": "1072420",
    "end": "1077740"
  },
  {
    "text": "So recall that if you have\na partition, denoted P. So",
    "start": "1077740",
    "end": "1084929"
  },
  {
    "text": "if this is a partition of\nthe vertex set of a graph, G,",
    "start": "1084930",
    "end": "1091980"
  },
  {
    "text": "and here n is the\nnumber of vertices,",
    "start": "1091980",
    "end": "1097770"
  },
  {
    "text": "we defined this notion of energy\nto be this quantity denoted",
    "start": "1097770",
    "end": "1109390"
  },
  {
    "text": "q, which is basically a\nsquared mean of the densities",
    "start": "1109390",
    "end": "1116790"
  },
  {
    "text": "between vertex parts\nappropriately normalized",
    "start": "1116790",
    "end": "1122010"
  },
  {
    "text": "if the vertexes do not\nall have the same size. ",
    "start": "1122010",
    "end": "1132860"
  },
  {
    "text": "In the proof of Szemeredi's\nregularity lemma,",
    "start": "1132860",
    "end": "1138690"
  },
  {
    "text": "there was an important\nenergy increment step which says that if you have\nsome partition p that is not",
    "start": "1138690",
    "end": "1152250"
  },
  {
    "text": "epsilon regular, then there\nexists a refinement, Q.",
    "start": "1152250",
    "end": "1164318"
  },
  {
    "text": "And this refinement has\nthe property that Q has",
    "start": "1164318",
    "end": "1169920"
  },
  {
    "text": "a small number of pieces, or\nnot too large as a function of P",
    "start": "1169920",
    "end": "1177440"
  },
  {
    "text": "So it's bounded at\nleast in terms of P. But also if P is not epsilon\nregular, then the energy of Q",
    "start": "1177440",
    "end": "1188370"
  },
  {
    "text": "is significantly larger than\nthe energy of P. So remember,",
    "start": "1188370",
    "end": "1195160"
  },
  {
    "text": "this was an important step in\nthe proof of regularity lemma. ",
    "start": "1195160",
    "end": "1203130"
  },
  {
    "text": "So to state the strong\nregularity lemma, we need that notion of energy.",
    "start": "1203130",
    "end": "1209298"
  },
  {
    "text": "And the statement of the\nstrong regularity lemma, if you've never seen this\nkind of thing before, will seem a bit\nintimidating at first",
    "start": "1209298",
    "end": "1214880"
  },
  {
    "text": "because it involves a whole\nsequence of parameters. But we'll get used to it.",
    "start": "1214880",
    "end": "1220640"
  },
  {
    "text": " So instead of one\nepsilon parameter,",
    "start": "1220640",
    "end": "1226790"
  },
  {
    "text": "now you have a sequence\nof positive epsilons.",
    "start": "1226790",
    "end": "1235945"
  },
  {
    "text": "And part of the strength\nof this regularity lemma is that depending on the\napplication you have in mind,",
    "start": "1235945",
    "end": "1241120"
  },
  {
    "text": "you can make the sequence\ngo to zero pretty quickly. Thereby increasing the strength\nof the regularity lemma.",
    "start": "1241120",
    "end": "1248809"
  },
  {
    "text": "So there exists some m\nbound, which depends only on your epsilons such that\nevery graph has not just one,",
    "start": "1248810",
    "end": "1267960"
  },
  {
    "text": "but now we're going to get a\npair of vertex partitions P",
    "start": "1267960",
    "end": "1276169"
  },
  {
    "text": "and Q with the\nfollowing properties.",
    "start": "1276170",
    "end": "1282930"
  },
  {
    "text": "So first, P refines-- so Q refines P. So it's\na pair of partitions,",
    "start": "1282930",
    "end": "1296990"
  },
  {
    "text": "one refining the other. ",
    "start": "1296990",
    "end": "1302400"
  },
  {
    "text": "The number of parts\nof Q is bounded just like in the usual\nregularity lemma. ",
    "start": "1302400",
    "end": "1310070"
  },
  {
    "text": "The partition P\nepsilon 0 regular. ",
    "start": "1310070",
    "end": "1317720"
  },
  {
    "text": "And here is the new part\nthat's the most important one. Q is very epsilon regular.",
    "start": "1317720",
    "end": "1327220"
  },
  {
    "text": "So it's not just\nepsilon 0 regular, it's epsilon sub the number\nof parts of P regular.",
    "start": "1327220",
    "end": "1333410"
  },
  {
    "text": " So you should think of\nthis as extremely regular",
    "start": "1333410",
    "end": "1343380"
  },
  {
    "text": "because you get to choose what\nthe sequence of epsilon is. And finally, the energy\ndifference between P and Q",
    "start": "1343380",
    "end": "1352720"
  },
  {
    "text": "is not too big. ",
    "start": "1352720",
    "end": "1363690"
  },
  {
    "text": "This is the statement of\nthe strong regularity lemma. It produces for you\nnot just one partition,",
    "start": "1363690",
    "end": "1368750"
  },
  {
    "text": "but a pair of partitions. And in this pair\nof partitions, you have one partition, P,\nwhich is similar to the one",
    "start": "1368750",
    "end": "1377480"
  },
  {
    "text": "that we obtained from\nSzemeredi's regularity lemma is some epsilon 0 regular, but\nwe also get a refinement Q.",
    "start": "1377480",
    "end": "1386150"
  },
  {
    "text": "And this Q is extremely regular.",
    "start": "1386150",
    "end": "1391250"
  },
  {
    "text": "So you can think\nthat is P, then Q",
    "start": "1391250",
    "end": "1399510"
  },
  {
    "text": "is an extremely\nregular refinement of P. Any questions\nabout the statement",
    "start": "1399510",
    "end": "1408210"
  },
  {
    "text": "of the strong regularity lemma? ",
    "start": "1408210",
    "end": "1413860"
  },
  {
    "text": "So the sequence of\nepsilons gives you flexibility on how to apply it,\nbut let's see how to prove it.",
    "start": "1413860",
    "end": "1419809"
  },
  {
    "text": "And the proof is once you\nunderstand how this works, conceptually it's pretty short.",
    "start": "1419810",
    "end": "1427070"
  },
  {
    "text": "But let me do it slowly\nso that we can appreciate this sequence of epsilons.",
    "start": "1427070",
    "end": "1434970"
  },
  {
    "text": "And the idea is that we\nwill repeatedly apply Szemeredi's regularity lemma. ",
    "start": "1434970",
    "end": "1446029"
  },
  {
    "text": "So start with the\nregularity lemma. We'll apply it\nrepeatedly to generate",
    "start": "1446030",
    "end": "1452980"
  },
  {
    "text": "a sequence of partitions. So first, let me remind you\na statement of Szemeredi's",
    "start": "1452980",
    "end": "1461620"
  },
  {
    "text": "regularity lemma. This is slightly\ndifferent from the one that we stated, but comes\nout of the same proof.",
    "start": "1461620",
    "end": "1468330"
  },
  {
    "text": "So for every epsilon,\nthere exists some m0",
    "start": "1468330",
    "end": "1473440"
  },
  {
    "text": "which depends on epsilon such\nthat for every partition P0,",
    "start": "1473440",
    "end": "1481500"
  },
  {
    "text": "so starting with\nsome partition--",
    "start": "1481500",
    "end": "1486530"
  },
  {
    "text": "so actually, let me\nstart with just P. So if you start with some\npartition of the vertex set",
    "start": "1486530",
    "end": "1494920"
  },
  {
    "text": "of g, there exists a refinement\nP prime of P into at most--",
    "start": "1494920",
    "end": "1510590"
  },
  {
    "text": "OK, so the refinement has is\nsuch that with each part of P",
    "start": "1510590",
    "end": "1527520"
  },
  {
    "text": "refined into at\nmost m0 parts such",
    "start": "1527520",
    "end": "1538960"
  },
  {
    "text": "that P prime, the new\npartition, is epsilon regular.",
    "start": "1538960",
    "end": "1544649"
  },
  {
    "start": "1544650",
    "end": "1552470"
  },
  {
    "text": "So this is a statement of\nSzemeredi's regularity lemma that we will apply repeatedly. So in the version that\nwe've seen before,",
    "start": "1552470",
    "end": "1558870"
  },
  {
    "text": "we would start with\na trivial partition. And applying\nrefinements repeatedly",
    "start": "1558870",
    "end": "1565740"
  },
  {
    "text": "in the proof to get a partition\ninto a bounded number of parts such that the final\npartition is epsilon regular.",
    "start": "1565740",
    "end": "1574080"
  },
  {
    "text": "But instead, in the proof\nof the regularity lemma if you start with not\na trivial partition",
    "start": "1574080",
    "end": "1579180"
  },
  {
    "text": "but start with a given partition\nand run this exact same proof, you find this consequence.",
    "start": "1579180",
    "end": "1586380"
  },
  {
    "text": "Except now you can guarantee\nthat the final partition is a refinement of the\none that you are given.",
    "start": "1586380",
    "end": "1591570"
  },
  {
    "text": " So let's apply the\nstatement, and we obtain",
    "start": "1591570",
    "end": "1602940"
  },
  {
    "text": "a sequence of partitions of g--",
    "start": "1602940",
    "end": "1610639"
  },
  {
    "text": "the vertex set of g-- starting with P0 being a\ntrivial partition, and so on.",
    "start": "1610640",
    "end": "1627250"
  },
  {
    "text": "Such that each partition,\neach P sub i plus 1",
    "start": "1627250",
    "end": "1637330"
  },
  {
    "text": "refines the previous\none, and such",
    "start": "1637330",
    "end": "1649940"
  },
  {
    "text": "that each P sub i plus 1 is\nepsilon sub a P sub i regular.",
    "start": "1649940",
    "end": "1659370"
  },
  {
    "text": " So you apply the regularity\nlemma with parameter",
    "start": "1659370",
    "end": "1665460"
  },
  {
    "text": "based on the number of\nparts you currently have. Applied to the\ncurrent partition,",
    "start": "1665460",
    "end": "1671010"
  },
  {
    "text": "you get a finer partition\nthat's extremely regular.",
    "start": "1671010",
    "end": "1676820"
  },
  {
    "text": "And you also know\nthat the number of parts of the new\npartition is bounded in terms",
    "start": "1676820",
    "end": "1684350"
  },
  {
    "text": "of the previous partition. ",
    "start": "1684350",
    "end": "1703138"
  },
  {
    "text": "All right. Any questions so far? ",
    "start": "1703138",
    "end": "1711510"
  },
  {
    "text": "So now we get this\nsequence of partitions. We can keep on doing this.",
    "start": "1711510",
    "end": "1717320"
  },
  {
    "text": "So g could be arbitrarily\nlarge, but eventually we",
    "start": "1717320",
    "end": "1723149"
  },
  {
    "text": "will be able to obtain\nthe last condition here, which is the only thing\nthat is missing so far.",
    "start": "1723150",
    "end": "1729169"
  },
  {
    "text": "So since the energy is\nbounded between 0 and 1,",
    "start": "1729170",
    "end": "1739510"
  },
  {
    "text": "there exists some i at\nmost 1 over epsilon 0",
    "start": "1739510",
    "end": "1746650"
  },
  {
    "text": "such that the energy goes\nup by less than epsilon 0.",
    "start": "1746650",
    "end": "1755860"
  },
  {
    "start": "1755860",
    "end": "1766390"
  },
  {
    "text": "Because otherwise your\nenergy would exceed 1. ",
    "start": "1766390",
    "end": "1773370"
  },
  {
    "text": "So now let's set\nP to be this Pi,",
    "start": "1773370",
    "end": "1778590"
  },
  {
    "text": "and Q to be this,\nthe refinement--",
    "start": "1778590",
    "end": "1783919"
  },
  {
    "text": "the next term in the partition. ",
    "start": "1783920",
    "end": "1790470"
  },
  {
    "text": "And what we find is that the-- so then you have basically\nall the conditions.",
    "start": "1790470",
    "end": "1797110"
  },
  {
    "text": "So p is epsilon 0 regular,\nbecause it is epsilon--",
    "start": "1797110",
    "end": "1803080"
  },
  {
    "text": "the previous term, which is\nat most epsilon 0 regular. And you have this one as\nwell, and this one as well.",
    "start": "1803080",
    "end": "1811970"
  },
  {
    "text": "And we want to show that\nthe number of parts of Q is bounded. And that's basically\nbecause each time there",
    "start": "1811970",
    "end": "1819309"
  },
  {
    "text": "was a bound on the number\nof parts which depends only on the regularity\nparameters, and you're",
    "start": "1819310",
    "end": "1824890"
  },
  {
    "text": "repeating that bound a\nbounded number of times. ",
    "start": "1824890",
    "end": "1830520"
  },
  {
    "text": "So Q is-- so it's bounded as\na function of the sequence",
    "start": "1830520",
    "end": "1844610"
  },
  {
    "text": "of epsilons-- this infinite\nvector of epsilons, but it is a bounded number. You're only iterating this\nbound a bounded number of times.",
    "start": "1844610",
    "end": "1854323"
  },
  {
    "text": "And that finishes the proof. ",
    "start": "1854323",
    "end": "1860946"
  },
  {
    "text": "Any questions? ",
    "start": "1860946",
    "end": "1869770"
  },
  {
    "text": "It may be somewhat mysterious\nto you right now why we do this, so we'll get that\napplication a second.",
    "start": "1869770",
    "end": "1874840"
  },
  {
    "text": "But for now, I just want to\ncomment a bit on the bounds. ",
    "start": "1874840",
    "end": "1886090"
  },
  {
    "text": "Of course, the bounds depend\non what epsilon i's do you use.",
    "start": "1886090",
    "end": "1892130"
  },
  {
    "text": "And typically, you\nwant the epsilon i's to decrease with more\nparts that you have.",
    "start": "1892130",
    "end": "1897350"
  },
  {
    "text": "And with almost all\nreasonable applications of this regularity lemma,\nthe strong regularity lemma--",
    "start": "1897350",
    "end": "1904450"
  },
  {
    "text": "so for example, with epsilon\ni being some epsilon divided",
    "start": "1904450",
    "end": "1912960"
  },
  {
    "text": "by, let's say, i plus 1 or\nany polynomial of the i's--",
    "start": "1912960",
    "end": "1918140"
  },
  {
    "text": "or you can even let it decay\nquicker than that, as well. You see, basically what\nhappens is that you",
    "start": "1918140",
    "end": "1926309"
  },
  {
    "text": "are applying this m0 bound. ",
    "start": "1926310",
    "end": "1935300"
  },
  {
    "text": "m0 applied in succession\n1 over epsilon times.",
    "start": "1935300",
    "end": "1945360"
  },
  {
    "text": " In the regularity lemma, we\nsaw that the m0 that comes out",
    "start": "1945360",
    "end": "1953800"
  },
  {
    "text": "of Szemeredi's graph regularity\nlemma is the tower function. ",
    "start": "1953800",
    "end": "1959872"
  },
  {
    "text": "So the tower function,\nthat's a tower of i is defined to be the exponential\nfunction iterated i times.",
    "start": "1959872",
    "end": "1972325"
  },
  {
    "text": "So of course, I'm\nbeing somewhat loose here with the exact dependence,\nbut you get the idea that now we want to apply\nthe tower function i times.",
    "start": "1972326",
    "end": "1982050"
  },
  {
    "start": "1982050",
    "end": "1995220"
  },
  {
    "text": "Instead of iterating\nthe exponential i times, now you iterate the\ntower function i times.",
    "start": "1995220",
    "end": "2000380"
  },
  {
    "text": "And some of you laughing, this\nis an incredibly large number. It's even larger than\nthe tower function. ",
    "start": "2000380",
    "end": "2009490"
  },
  {
    "text": "So in literature, especially\naround the regularity lemma, this function where you\niterate the tower function i",
    "start": "2009490",
    "end": "2017020"
  },
  {
    "text": "times is given the name wowzer. [LAUGHTER] As in, wow,\nthis is a huge number.",
    "start": "2017020",
    "end": "2027280"
  },
  {
    "text": "So it's a step up in\nthe Ackerman hierarchy. So if you repeat the\nwowzer function i times,",
    "start": "2027280",
    "end": "2033480"
  },
  {
    "text": "you move up one ladder\nin the Ackerman hierarchy and this hierarchy of\nrapidly growing functions.",
    "start": "2033480",
    "end": "2041060"
  },
  {
    "text": "But in any case, it's bounded\nand that's good enough for us. ",
    "start": "2041060",
    "end": "2050695"
  },
  {
    "text": "Any questions so far? ",
    "start": "2050695",
    "end": "2056379"
  },
  {
    "text": "Yeah? AUDIENCE: What do you\ncall like [INAUDIBLE] YUFEI ZHAO: Yes, so\nquestion is, what do you",
    "start": "2056380",
    "end": "2061690"
  },
  {
    "text": "call wowzer iterated? I'm not aware of a\nstandard name for that.",
    "start": "2061690",
    "end": "2067169"
  },
  {
    "text": "Actually, even the\nname wowzer somehow is very common in the\ncombinatorics community, but I think most people\noutside this community",
    "start": "2067170",
    "end": "2074199"
  },
  {
    "text": "will not recognize this word. ",
    "start": "2074199",
    "end": "2080138"
  },
  {
    "text": "Any more questions? So another way it's a step\nup in Ackerman hierarchy.",
    "start": "2080139",
    "end": "2086145"
  },
  {
    "text": "So it's enumerated one,\ntwo, three, four, you know, if you keep going up. ",
    "start": "2086145",
    "end": "2092993"
  },
  {
    "text": "All right. Another remark about this\nstrong regularity lemma",
    "start": "2092994",
    "end": "2101290"
  },
  {
    "text": "is that it will be\nconvenient for us-- actually, some are more essential compared\nto our previous applications--",
    "start": "2101290",
    "end": "2107950"
  },
  {
    "text": "to make the parts equitable. ",
    "start": "2107950",
    "end": "2113150"
  },
  {
    "text": "So P and Q equitable.",
    "start": "2113150",
    "end": "2118710"
  },
  {
    "text": "And basically, the parts\nare such that all the-- the partitions are such that\nall the parts have basically",
    "start": "2118710",
    "end": "2125068"
  },
  {
    "text": "the same number of vertices. So I won't make it\nprecise, but you can do it.",
    "start": "2125068",
    "end": "2130485"
  },
  {
    "text": "It's not too hard to do it. And you can prove\nit similar to how I described how to modify the\nproof of the regularity level.",
    "start": "2130485",
    "end": "2139030"
  },
  {
    "text": "So I won't belabor\nthat point, but we'll use the equitable version. ",
    "start": "2139030",
    "end": "2145790"
  },
  {
    "text": "All right, so how does one\nuse this regularity lemma? Let me state a\ncorollary, and let",
    "start": "2145790",
    "end": "2153460"
  },
  {
    "text": "me call this a corollary\nstar because you actually need to do some work\nto get it to follow from the strong\nregularity lemma.",
    "start": "2153460",
    "end": "2159880"
  },
  {
    "text": "But the corollary is\nthe version that we will apply that if you\nstart with a decreasing",
    "start": "2159880",
    "end": "2166420"
  },
  {
    "text": "sequence of this epsilon,\nthen there exists a delta such",
    "start": "2166420",
    "end": "2177214"
  },
  {
    "text": "that the following is true. ",
    "start": "2177215",
    "end": "2182650"
  },
  {
    "text": "Every n vertex graph has an\nequitable vertex partition,",
    "start": "2182650",
    "end": "2201359"
  },
  {
    "text": "call it i through the\nk, and a subset Wi",
    "start": "2201360",
    "end": "2211530"
  },
  {
    "text": "of each Vi such that the\nfollowing properties hold.",
    "start": "2211530",
    "end": "2219580"
  },
  {
    "text": "First, all the W's\nare fairly large.",
    "start": "2219580",
    "end": "2224960"
  },
  {
    "text": "They're at least\nconstant proportion of the total vertex set. ",
    "start": "2224960",
    "end": "2233040"
  },
  {
    "text": "Between every pair of Wi Wj,\nit is epsilon sub k regular.",
    "start": "2233040",
    "end": "2242520"
  },
  {
    "start": "2242520",
    "end": "2250890"
  },
  {
    "text": "And this is the point\nI want to emphasize. So here there are not you\nregular pairs anymore. So it is every.",
    "start": "2250890",
    "end": "2257170"
  },
  {
    "text": " So no irregular pairs\nbetween the Wi's,",
    "start": "2257170",
    "end": "2264869"
  },
  {
    "text": "and also we need\nto include the case when i equals the j, as well.",
    "start": "2264870",
    "end": "2270900"
  },
  {
    "text": "So each Wi is\nregular with itself. ",
    "start": "2270900",
    "end": "2277060"
  },
  {
    "text": "And furthermore, the edge\ndensities between the V's are",
    "start": "2277060",
    "end": "2285850"
  },
  {
    "text": "similar to the edge densities\nbetween the corresponding W's.",
    "start": "2285850",
    "end": "2291820"
  },
  {
    "text": "And here it is for\nmost pairs for all",
    "start": "2291820",
    "end": "2298060"
  },
  {
    "text": "but at most epsilon\nk square pairs.",
    "start": "2298060",
    "end": "2303550"
  },
  {
    "start": "2303550",
    "end": "2310320"
  },
  {
    "text": "Epsilon 0, yeah. At most epsilon 0. ",
    "start": "2310320",
    "end": "2320660"
  },
  {
    "text": "Any questions about\nthe statement? ",
    "start": "2320660",
    "end": "2337440"
  },
  {
    "text": "So let me show you\nhow you could deduce the corollary from the\nstrong regularity lemma.",
    "start": "2337440",
    "end": "2344520"
  },
  {
    "start": "2344520",
    "end": "2356950"
  },
  {
    "text": "So first, let me\ndraw your picture. ",
    "start": "2356950",
    "end": "2363070"
  },
  {
    "text": "So here you have a\nregularity partition. ",
    "start": "2363070",
    "end": "2371010"
  },
  {
    "text": "And so these are your\nV's, and inside each V",
    "start": "2371010",
    "end": "2378155"
  },
  {
    "text": "I find a W such that\nif I look at the edge",
    "start": "2378155",
    "end": "2390340"
  },
  {
    "text": "sets between pairwise\nblue sets, including the blue sets with themselves,\nit is always very regular.",
    "start": "2390340",
    "end": "2398950"
  },
  {
    "text": "And also, the edge densities\nbetween the blue sets",
    "start": "2398950",
    "end": "2404619"
  },
  {
    "text": "is mostly very\nsimilar to the edge density between their\nambient white sets.",
    "start": "2404620",
    "end": "2410110"
  },
  {
    "start": "2410110",
    "end": "2420040"
  },
  {
    "text": "OK, so let me say a few words-- I won't go into\ntoo many details-- about how you might\ndeduce this corollary",
    "start": "2420040",
    "end": "2426279"
  },
  {
    "text": "from the strong\nregularity lemma.  So first let me\ndo something which",
    "start": "2426280",
    "end": "2433320"
  },
  {
    "text": "is slightly simpler, which\nis to not yet require",
    "start": "2433320",
    "end": "2439830"
  },
  {
    "text": "that the blue sets, Wi's,\nare regular with themselves. ",
    "start": "2439830",
    "end": "2451480"
  },
  {
    "text": "So without requiring this\nas regular so we can obtain",
    "start": "2451480",
    "end": "2459630"
  },
  {
    "text": "the Wi's by picking\na uniform random part",
    "start": "2459630",
    "end": "2473660"
  },
  {
    "text": "of the final partition,\nQ, inside each part of P",
    "start": "2473660",
    "end": "2487869"
  },
  {
    "text": "in the strong regularity lemma. ",
    "start": "2487870",
    "end": "2495920"
  },
  {
    "text": "So you have the strong\nregularity lemma, which produces for you a\npair of partitions like that.",
    "start": "2495920",
    "end": "2504080"
  },
  {
    "text": "So it produces for you\na pair of partitions. And what we will do is to pick\none of these guys as my W,",
    "start": "2504080",
    "end": "2513560"
  },
  {
    "text": "pick one of these\nguys at random, and pick one of\nthose guys at random. ",
    "start": "2513560",
    "end": "2520730"
  },
  {
    "text": "Because W is so extremely\nregular, most of these pairs",
    "start": "2520730",
    "end": "2526619"
  },
  {
    "text": "will be regular. So with high\nprobability, you will not",
    "start": "2526620",
    "end": "2533610"
  },
  {
    "text": "encounter any\nirregular pairs if you",
    "start": "2533610",
    "end": "2538800"
  },
  {
    "text": "pick the W's randomly as parts\nof Q. So that's the key point.",
    "start": "2538800",
    "end": "2545570"
  },
  {
    "text": "Here we're using that\nQ is extremely regular. ",
    "start": "2545570",
    "end": "2560930"
  },
  {
    "text": "So all the Wi Wj is\nregular for all i not equal",
    "start": "2560930",
    "end": "2567420"
  },
  {
    "text": "to j with high probability. ",
    "start": "2567420",
    "end": "2573550"
  },
  {
    "text": "But the other thing that we\nwould like is that the edge densities between the W's\nare similar to those between",
    "start": "2573550",
    "end": "2580810"
  },
  {
    "text": "the V's. And for that, we will use this\ncondition about their energies",
    "start": "2580810",
    "end": "2586020"
  },
  {
    "text": "being very similar\nto each other.  So the third\nconsequence, C, is--",
    "start": "2586020",
    "end": "2596799"
  },
  {
    "text": "it's a consequence\nof the energy bound.",
    "start": "2596800",
    "end": "2602200"
  },
  {
    "start": "2602200",
    "end": "2610820"
  },
  {
    "text": "Because recall that in our proof\nof the Szemeredi regularity lemma there was\nan interpretation",
    "start": "2610820",
    "end": "2616730"
  },
  {
    "text": "of the energy as\nthe second moment",
    "start": "2616730",
    "end": "2623859"
  },
  {
    "text": "of a certain random\nvariable which we called z. ",
    "start": "2623860",
    "end": "2631640"
  },
  {
    "text": "And using that interpretation,\nI can write down this expression like that.",
    "start": "2631640",
    "end": "2640320"
  },
  {
    "text": "We are here assuming\nfor simplicity that Q is completely\nequitable, so all the parts",
    "start": "2640320",
    "end": "2648030"
  },
  {
    "text": "have exactly the same size. Z of Q is defined to be the\nedge density between Vi and Vj",
    "start": "2648030",
    "end": "2655740"
  },
  {
    "text": "for random ij.",
    "start": "2655740",
    "end": "2661010"
  },
  {
    "text": "So this is a random variable z. So you pick pair\nof parts uniformly,",
    "start": "2661010",
    "end": "2668410"
  },
  {
    "text": "or maybe with some weights\nif they're not exactly equal. And you evaluate\nthe edge density.",
    "start": "2668410",
    "end": "2674480"
  },
  {
    "text": "So this energy difference\nis the difference between the second moments. And because Q is\na refinement of P,",
    "start": "2674480",
    "end": "2686710"
  },
  {
    "text": "it is the case that this\ndifference of L2 norms",
    "start": "2686710",
    "end": "2695869"
  },
  {
    "text": "is equal to the second\nmoment of the difference of the random variables.",
    "start": "2695870",
    "end": "2702480"
  },
  {
    "text": "So we saw a version\nof this earlier when we were discussing\nvariance in the context",
    "start": "2702480",
    "end": "2707910"
  },
  {
    "text": "of the proof of the\nsimilar irregularity lemma. Here it's basically the same. You can either look at this\ninequality part by part of V,",
    "start": "2707910",
    "end": "2716430"
  },
  {
    "text": "or if you like to be\na bit more abstract then this is actually a\ncase of Pythagorean theorem.",
    "start": "2716430",
    "end": "2724170"
  },
  {
    "start": "2724170",
    "end": "2729910"
  },
  {
    "text": "If you view these as vectors\nin a certain vector space, then you have some\northogonality.",
    "start": "2729910",
    "end": "2736100"
  },
  {
    "text": "So you have this sum\nof squares identity. ",
    "start": "2736100",
    "end": "2745859"
  },
  {
    "text": "Where does part A come from? So part A, we want the parts,\nthat Wi's to be not too small,",
    "start": "2745860",
    "end": "2752340"
  },
  {
    "text": "but that comes from a bound\non the number of parts of Q.",
    "start": "2752340",
    "end": "2775561"
  },
  {
    "text": "So so far this more or\nless proves the corollary except for that we\nsimplified our lives",
    "start": "2775561",
    "end": "2783050"
  },
  {
    "text": "by requiring just that the i\nnot equal to j, the Vi Vj's are",
    "start": "2783050",
    "end": "2789680"
  },
  {
    "text": "regular. But in the statement\nup there, we also want the Vi's-- so the Wi's ice to\nbe regular with themselves,",
    "start": "2789680",
    "end": "2797650"
  },
  {
    "text": "which will be important\nfor application. So I won't explain how to do\nthat, and part of the reason",
    "start": "2797650",
    "end": "2805670"
  },
  {
    "text": "is that this is also one\nof your homework problems. So in one of the homework\nproblems problem set 3,",
    "start": "2805670",
    "end": "2811920"
  },
  {
    "text": "you were asked to prove\nthat every graph has a subset of vertices that is of\nleast constant proportion such",
    "start": "2811920",
    "end": "2821099"
  },
  {
    "text": "that it is regular with itself. And the methods\nyou use there will",
    "start": "2821100",
    "end": "2826769"
  },
  {
    "text": "be applicable to handle the\nsituation over here, as well.",
    "start": "2826770",
    "end": "2832210"
  },
  {
    "text": "So putting all of these\ningredients together, we get the corollary whereby\nyou have this picture,",
    "start": "2832210",
    "end": "2840020"
  },
  {
    "text": "you have this partition. I don't even require\nthe Vi's to be regular. That doesn't matter anymore.",
    "start": "2840020",
    "end": "2845640"
  },
  {
    "text": "All that matters is that between\nthe Wi's they are very regular, and that there are no irregular\nparts between these Wi's.",
    "start": "2845640",
    "end": "2854450"
  },
  {
    "text": "And now we'll be able to go back\nto the induced graph removal",
    "start": "2854450",
    "end": "2861609"
  },
  {
    "text": "lemma where previously we had\nan issue with the existence",
    "start": "2861610",
    "end": "2866920"
  },
  {
    "text": "of irregular pairs in the use of\nSzemeredi regularity partition, and now we have a tool\nto get around that.",
    "start": "2866920",
    "end": "2875250"
  },
  {
    "text": "So next we will see how\nto execute this proof,",
    "start": "2875250",
    "end": "2880300"
  },
  {
    "text": "but at this point hopefully\nyou already see an outline. Because you no longer need to\nworry about this thing here.",
    "start": "2880300",
    "end": "2890678"
  },
  {
    "text": "Let's take a quick break.  Any questions so far?",
    "start": "2890678",
    "end": "2895830"
  },
  {
    "text": " Yes?",
    "start": "2895830",
    "end": "2901480"
  },
  {
    "text": "AUDIENCE: Why are we\nable to [INAUDIBLE]",
    "start": "2901480",
    "end": "2911540"
  },
  {
    "text": "YUFEI ZHAO: OK, so\nthe question was, there was a step where we were\nlooking at some expectations",
    "start": "2911540",
    "end": "2917170"
  },
  {
    "text": "of squares. And so why was\nthat identity true?",
    "start": "2917170",
    "end": "2923670"
  },
  {
    "text": "So if you look back to the\nproof of Szemeredi's regularity lemma, we already saw an\ninstance of that inequality",
    "start": "2923670",
    "end": "2928932"
  },
  {
    "text": "in the computation\nof the variance. ",
    "start": "2928932",
    "end": "2937859"
  },
  {
    "text": "So you know that the\nvariance of x, on one hand it is equal to where\nmu is the mean of x.",
    "start": "2937860",
    "end": "2950470"
  },
  {
    "text": "And on the other hand, it\nis equal to this quantity.",
    "start": "2950470",
    "end": "2955670"
  },
  {
    "text": " So you agree with this formula?",
    "start": "2955670",
    "end": "2963359"
  },
  {
    "text": "And you can expand it to\nprove it, and the thing that-- the question that you\nraised basically you",
    "start": "2963360",
    "end": "2970990"
  },
  {
    "text": "can prove by looking at\nthis formula part by part. ",
    "start": "2970990",
    "end": "2979250"
  },
  {
    "text": "Any more questions? ",
    "start": "2979250",
    "end": "2989760"
  },
  {
    "text": "So let's now prove the\ninduced graph removal lemma. And we'll follow the\nregularity partition,",
    "start": "2989760",
    "end": "2997110"
  },
  {
    "text": "but with a small\ntwist that Instead of using Szemeredi's\nregularity lemma, we will use that\ncorollary up there.",
    "start": "2997110",
    "end": "3003740"
  },
  {
    "start": "3003740",
    "end": "3011560"
  },
  {
    "text": "So let's prove the induced\ngraph removal lemma. ",
    "start": "3011560",
    "end": "3020819"
  },
  {
    "text": "So the three steps. First, we do partition. ",
    "start": "3020820",
    "end": "3030050"
  },
  {
    "text": "So let's suppose you have a-- ",
    "start": "3030050",
    "end": "3036850"
  },
  {
    "text": "so we suppose g is like above. You have very few\ninduced copies of H.",
    "start": "3036850",
    "end": "3045200"
  },
  {
    "text": "Let's apply the corollary to get\na partition of the vertex set",
    "start": "3045200",
    "end": "3051170"
  },
  {
    "text": "of g into k parts.",
    "start": "3051170",
    "end": "3057660"
  },
  {
    "text": "And inside each part\nI have a W. Satisfying",
    "start": "3057660",
    "end": "3064690"
  },
  {
    "text": "the following properties\nthat each Wi Wj",
    "start": "3064690",
    "end": "3071950"
  },
  {
    "text": "is regular with the\nfollowing parameter which",
    "start": "3071950",
    "end": "3078516"
  },
  {
    "text": "will come out of later when we\nneed to use the counting lemma. But it's some number, but\ndon't worry too much about it.",
    "start": "3078517",
    "end": "3083740"
  },
  {
    "text": " So here I'm going to--",
    "start": "3083740",
    "end": "3090310"
  },
  {
    "text": "so let's say H has\nlittle H vertices.",
    "start": "3090310",
    "end": "3095685"
  },
  {
    "start": "3095685",
    "end": "3105405"
  },
  {
    "text": "So between Wi Wj\nit is this regular. So we actually have not\nyet used the full strength",
    "start": "3105405",
    "end": "3110730"
  },
  {
    "text": "of the corollary where I can\nmake the regularity even depend",
    "start": "3110730",
    "end": "3118740"
  },
  {
    "text": "on k. So we will not need\nthat here, but we'll need it in a later application.",
    "start": "3118740",
    "end": "3124089"
  },
  {
    "text": "So the exponent is little H.",
    "start": "3124090",
    "end": "3131120"
  },
  {
    "text": "OK, so other properties are that\nthe densities between the Vi's",
    "start": "3131120",
    "end": "3138890"
  },
  {
    "text": "and the Wi's do not differ\nby more than epsilon over 2",
    "start": "3138890",
    "end": "3148910"
  },
  {
    "text": "for all but a small fraction-- so epsilon k squared over 2--",
    "start": "3148910",
    "end": "3156480"
  },
  {
    "text": "pairs. ",
    "start": "3156480",
    "end": "3165150"
  },
  {
    "text": "And finally, the sizes of the\nWi's are at least delta 0 times",
    "start": "3165150",
    "end": "3173010"
  },
  {
    "text": "n where delta 0 depends\nonly on epsilon. ",
    "start": "3173010",
    "end": "3184310"
  },
  {
    "text": "Epsilon and H. ",
    "start": "3184310",
    "end": "3201210"
  },
  {
    "text": "This is the partition step,\nso now let's do the cleaning. ",
    "start": "3201210",
    "end": "3208210"
  },
  {
    "text": "In the cleaning step,\nbasically we're not going to--",
    "start": "3208210",
    "end": "3214830"
  },
  {
    "text": "I mean, there is no longer an\nissue of irregular pairs if we only look at the Wi's.",
    "start": "3214830",
    "end": "3220100"
  },
  {
    "text": "So we just need to think\nabout the low density pairs or whatever the\ncorresponding analog is.",
    "start": "3220100",
    "end": "3226710"
  },
  {
    "text": "And what happens here is\nthat for every i less than j,",
    "start": "3226710",
    "end": "3232200"
  },
  {
    "text": "and crucially including\nwhen i equals to j,",
    "start": "3232200",
    "end": "3237790"
  },
  {
    "text": "if the edge densities\nbetween the W's is too small",
    "start": "3237790",
    "end": "3246330"
  },
  {
    "text": "then we remove all\nedges between Vi and Vj.",
    "start": "3246330",
    "end": "3258790"
  },
  {
    "text": " And if the edge density\nbetween the Wi's is too big,",
    "start": "3258790",
    "end": "3271810"
  },
  {
    "text": "then we remove all edges. ",
    "start": "3271810",
    "end": "3278280"
  },
  {
    "text": "So we add all edges\nbetween Vi and Vj. ",
    "start": "3278280",
    "end": "3300900"
  },
  {
    "text": "How many edges do we end\nup adding or removing? ",
    "start": "3300900",
    "end": "3306560"
  },
  {
    "text": "So the total number of edges\nadded or removed from g is--",
    "start": "3306560",
    "end": "3321460"
  },
  {
    "text": "in this case, so if\nthe edges density",
    "start": "3321460",
    "end": "3326680"
  },
  {
    "text": "in g between the Vi's and\nVj's is also very small,",
    "start": "3326680",
    "end": "3332160"
  },
  {
    "text": "then you do not remove\nvery many edges. But most pairs of Vi and\nVj have that property.",
    "start": "3332160",
    "end": "3341190"
  },
  {
    "text": "So you tidy up\nwhat kind of errors you can get from here\nand there, and you",
    "start": "3341190",
    "end": "3348140"
  },
  {
    "text": "find that the total number of\nedges that are added or removed from g is less than, let's\nsay, epsilon n squared.",
    "start": "3348140",
    "end": "3359150"
  },
  {
    "text": "Maybe even get an\nextra factor of 2, but you know, upon changing\nsome constant factors,",
    "start": "3359150",
    "end": "3364310"
  },
  {
    "text": "it's less than\nepsilon n squared. So this is some small\ndetails you can work out.",
    "start": "3364310",
    "end": "3373470"
  },
  {
    "text": "Here we're using--\nasking, how is the density between Vi and\nVj related to Wi and Wj?",
    "start": "3373470",
    "end": "3379410"
  },
  {
    "text": "Well, for most pairs of i\nand j they're very similar. And there's a small fraction\nof them that are not similar,",
    "start": "3379410",
    "end": "3386180"
  },
  {
    "text": "but then you lump everything\nin to this bound over here.",
    "start": "3386180",
    "end": "3392309"
  },
  {
    "start": "3392310",
    "end": "3400290"
  },
  {
    "text": "So maybe I need to-- let me just put a 2\nhere just to be safe. ",
    "start": "3400290",
    "end": "3408690"
  },
  {
    "text": "All right. So we deleted a very\nsmall number of edges,",
    "start": "3408690",
    "end": "3415590"
  },
  {
    "text": "and now we want to show\nthat the graph that has resulted from\nthis modification",
    "start": "3415590",
    "end": "3421740"
  },
  {
    "text": "does not have any\ninduced H sub-graphs. ",
    "start": "3421740",
    "end": "3431480"
  },
  {
    "text": "And the final step\nis the counting step. So suppose there\nwere any induced",
    "start": "3431480",
    "end": "3440960"
  },
  {
    "text": "H left after the modification.",
    "start": "3440960",
    "end": "3446859"
  },
  {
    "text": "So I want to show that, in fact,\nthere must be a lot of H's-- induced H's originally\nin the graph,",
    "start": "3446860",
    "end": "3452160"
  },
  {
    "text": "thereby contradicting\nthe hypothesis. ",
    "start": "3452160",
    "end": "3461690"
  },
  {
    "text": "So where does this\ninduced H sit? Well, you have the V's,\nand inside the V's you have",
    "start": "3461690",
    "end": "3475070"
  },
  {
    "text": "the W's. ",
    "start": "3475070",
    "end": "3484170"
  },
  {
    "text": "So suppose my H is that\ngraph for illustration.",
    "start": "3484170",
    "end": "3493200"
  },
  {
    "text": "And in particular,\nI have a non-edge. So I have an edge, and\nI also have a non-edge.",
    "start": "3493200",
    "end": "3500370"
  },
  {
    "text": "So between these two,\nthat's the non-edge. ",
    "start": "3500370",
    "end": "3507950"
  },
  {
    "text": "So suppose you find a copy\nof H in the cleaned-up graph.",
    "start": "3507950",
    "end": "3514589"
  },
  {
    "text": "Where can that cleaned up-- this copy of H sit? Suppose you find it here.",
    "start": "3514590",
    "end": "3519790"
  },
  {
    "text": " The claim now is that if this\ncopy of H existed here, then",
    "start": "3519790",
    "end": "3532130"
  },
  {
    "text": "I must be able to find\nmany such copies of H in the corresponding\nyellow parts.",
    "start": "3532130",
    "end": "3539090"
  },
  {
    "text": " Because between the yellow\nparts you have regularity,",
    "start": "3539090",
    "end": "3550050"
  },
  {
    "text": "and you also have the\nright kinds of densities.",
    "start": "3550050",
    "end": "3555450"
  },
  {
    "text": "Because if they didn't have\nthe right kind of density, we would have cleaned\nit up already. ",
    "start": "3555450",
    "end": "3562900"
  },
  {
    "text": "So that's the ideal. If you had a copy\nof this H somewhere,",
    "start": "3562900",
    "end": "3569720"
  },
  {
    "text": "then I zoom into\nthe yellow parts, zoom into these W's, and I find\nlots of copies of H in between",
    "start": "3569720",
    "end": "3577160"
  },
  {
    "text": "the W's. So suppose-- let\nme write this down. So suppose the little V's, so\nthe vertices, lies in the--",
    "start": "3577160",
    "end": "3597690"
  },
  {
    "text": "so I'm just indexing\nwhere a little v lies. The little v lies\nin big V sub phi",
    "start": "3597690",
    "end": "3603225"
  },
  {
    "text": "V for some phi which since the\nvertices of H2 went through k.",
    "start": "3603225",
    "end": "3614600"
  },
  {
    "text": "So now we apply counting lemma\nto embed induced copies of H",
    "start": "3614600",
    "end": "3634650"
  },
  {
    "text": "in g where the vertex\nV in H is mapped",
    "start": "3634650",
    "end": "3645710"
  },
  {
    "text": "to a vertex in the\ncorresponding W.",
    "start": "3645710",
    "end": "3654455"
  },
  {
    "start": "3654455",
    "end": "3660630"
  },
  {
    "text": "And we would like to know that\nthere are lots of such copies. And the counting Lemma--",
    "start": "3660630",
    "end": "3666660"
  },
  {
    "text": "or rather, some variant, but I\nshould read the counting lemma",
    "start": "3666660",
    "end": "3671730"
  },
  {
    "text": "that we did last time and view\nit as a multi-partite version.",
    "start": "3671730",
    "end": "3676940"
  },
  {
    "text": "Apply this so far part to part. So we find that the number\nof such induced copies",
    "start": "3676940",
    "end": "3690339"
  },
  {
    "text": "is within a small error. ",
    "start": "3690340",
    "end": "3696630"
  },
  {
    "text": "So that regularity parameter\nmultiplied by the number",
    "start": "3696630",
    "end": "3707700"
  },
  {
    "text": "of edges of H, which we\nalready canceled out, multiplied by the\nproduct of these Wi's.",
    "start": "3707700",
    "end": "3721015"
  },
  {
    "text": " So it's within\nthis error of what",
    "start": "3721015",
    "end": "3728660"
  },
  {
    "text": "you would suspect if you\nnaively multiply the edge densities together along\nwith the vertex densities.",
    "start": "3728660",
    "end": "3736953"
  },
  {
    "start": "3736953",
    "end": "3749279"
  },
  {
    "text": "So these factors are for the\nedges that you want to embed,",
    "start": "3749280",
    "end": "3755790"
  },
  {
    "text": "and then I also need to\nmultiply the densities for the long edges. ",
    "start": "3755790",
    "end": "3771378"
  },
  {
    "text": "So 1 minus these edge densities. So one way you can think\nof it is just consider",
    "start": "3771378",
    "end": "3776500"
  },
  {
    "text": "the complement in g. So consider the complement of\ng to get this version here.",
    "start": "3776500",
    "end": "3782500"
  },
  {
    "text": "And then finally, the product\nof the vertex set sizes. ",
    "start": "3782500",
    "end": "3798000"
  },
  {
    "text": "And the point is that this\nis not a small number. So hence the number of\ninduced copies of H in g",
    "start": "3798000",
    "end": "3815870"
  },
  {
    "text": "is at least on the order of--",
    "start": "3815870",
    "end": "3821450"
  },
  {
    "text": "well, OK?  So it's at least some\nnumber, which is basically",
    "start": "3821450",
    "end": "3830589"
  },
  {
    "text": "this guy over here. So epsilon over 4 raised to--",
    "start": "3830590",
    "end": "3835819"
  },
  {
    "text": "all of these are constants,\nso that's the point. All of these guys are\nconstants, minus-- ",
    "start": "3835820",
    "end": "3845050"
  },
  {
    "text": "so here is the main term,\nand then the error term. ",
    "start": "3845050",
    "end": "3853790"
  },
  {
    "text": "And then the product of\nthese vertex set sizes, and we saw that each vertex\nset is not too small.",
    "start": "3853790",
    "end": "3859680"
  },
  {
    "start": "3859680",
    "end": "3865839"
  },
  {
    "text": "So you have lots of\ninduced copies of H in g. Yep?",
    "start": "3865840",
    "end": "3871430"
  },
  {
    "text": "AUDIENCE: How do you\ndo in the case where the density between [INAUDIBLE]",
    "start": "3871430",
    "end": "3884740"
  },
  {
    "text": "YUFEI ZHAO: OK, so can\nyou repeat your question? AUDIENCE: How are you\ndealing with the [INAUDIBLE]",
    "start": "3884740",
    "end": "3893045"
  },
  {
    "text": "YUFEI ZHAO: OK. So question, how do we deal\nwith the all but epsilon over two pairs? So that comes up in\nthe cleaning step",
    "start": "3893045",
    "end": "3899375"
  },
  {
    "text": "in what I wrote\nin red in dealing with the number of total edges\nthat are added or removed.",
    "start": "3899375",
    "end": "3907780"
  },
  {
    "text": "So think about how many\nedges are added or removed. In these non-exceptional pairs,\nthe number of edges that are",
    "start": "3907780",
    "end": "3915440"
  },
  {
    "text": "added or removed-- ",
    "start": "3915440",
    "end": "3926470"
  },
  {
    "text": "let's just think\nabout added edges. So if the density of V is\ncontrolled by that of W,",
    "start": "3926470",
    "end": "3945930"
  },
  {
    "text": "then the number of edges added-- or removed, in that case-- from all such pairs along with--",
    "start": "3945930",
    "end": "3956230"
  },
  {
    "text": "yeah. So you have epsilon n\nsquared edges changed.",
    "start": "3956230",
    "end": "3961410"
  },
  {
    "start": "3961410",
    "end": "3966539"
  },
  {
    "text": "On the other hand, if this is\nnot true then you only have",
    "start": "3966540",
    "end": "3977780"
  },
  {
    "text": "epsilon k squared such pairs ij\nfor which this cannot be true.",
    "start": "3977780",
    "end": "3983000"
  },
  {
    "text": "So you also only have at\nmost epsilon n squared edges added or removed in such cases.",
    "start": "3983000",
    "end": "3989849"
  },
  {
    "text": "That answers your question? Yes? AUDIENCE: Is that number 0?",
    "start": "3989850",
    "end": "3995032"
  },
  {
    "text": " YUFEI ZHAO: Is which number 0? AUDIENCE: The number of induced\nedges for the [INAUDIBLE]",
    "start": "3995032",
    "end": "4005320"
  },
  {
    "text": "YUFEI ZHAO: The-- AUDIENCE: Yeah, the top board. YUFEI ZHAO: Top board? ",
    "start": "4005320",
    "end": "4018839"
  },
  {
    "text": "Good. So asking about this number. So that should have been 2. ",
    "start": "4018840",
    "end": "4028580"
  },
  {
    "text": "Yes? AUDIENCE: I don't\nsee k anywhere. YUFEI ZHAO: OK, so question, you\ndon't see k appearing anywhere.",
    "start": "4028580",
    "end": "4034840"
  },
  {
    "text": "So the k in the\ncorollary, do you mean? AUDIENCE: Yeah. YUFEI ZHAO: So that\nhasn't come up yet. So it comes up implicitly\nbecause we need to lower bound",
    "start": "4034840",
    "end": "4044180"
  },
  {
    "text": "the sizes of these W's. ",
    "start": "4044180",
    "end": "4051820"
  },
  {
    "text": "So this is partly why we need\na bound on the number of parts, but it is true that we do\nnot need epsilon k to depend",
    "start": "4051820",
    "end": "4058150"
  },
  {
    "text": "on k in this application yet. I will mention a different\napplication in the second where you do need that k.",
    "start": "4058150",
    "end": "4063230"
  },
  {
    "start": "4063230",
    "end": "4068810"
  },
  {
    "text": "OK, so the number of induced H\nin g is at least this amount. And that's a small lie.",
    "start": "4068810",
    "end": "4074079"
  },
  {
    "text": "You need to maybe consider this\nis the number of homomorphic.",
    "start": "4074080",
    "end": "4079780"
  },
  {
    "text": "Well, actually, no, we're OK. Never mind. ",
    "start": "4079780",
    "end": "4091119"
  },
  {
    "text": "So you can set delta to\nbe this quantity here,",
    "start": "4091120",
    "end": "4099609"
  },
  {
    "text": "and then that\nfinishes the proof. So you have lots of\ninduced copies of H in your graph which\ncontradicts the hypothesis.",
    "start": "4099609",
    "end": "4107765"
  },
  {
    "text": "So that finishes the proof\nof the induced removal lemma, and basically the proof is\nthe same as the usual graph",
    "start": "4107765",
    "end": "4114109"
  },
  {
    "text": "removal lemma except\nthat now we need some strengthened\nregularity lemma which",
    "start": "4114109",
    "end": "4120259"
  },
  {
    "text": "allows us to get rid\nof irregular parts but in a more\nrestricted setting. Because we saw you cannot\ncompletely get rid of irregular",
    "start": "4120260",
    "end": "4127729"
  },
  {
    "text": "parts.  Any questions? ",
    "start": "4127729",
    "end": "4136109"
  },
  {
    "text": "Yes? AUDIENCE: [INAUDIBLE]",
    "start": "4136109",
    "end": "4141473"
  },
  {
    "text": "YUFEI ZHAO: So I want to\naddress the question of why did I state this\ncorollary in this more general form of a decreasing\nsequence of epsilons?",
    "start": "4141473",
    "end": "4149520"
  },
  {
    "text": "So first of all, with\nstrong regularity lemmas, the strength is sometimes\nalways nice to--",
    "start": "4149520",
    "end": "4155189"
  },
  {
    "text": "it's always nice to state\nit with this extra strength. Because it's the\nright way to think about these types of theorems.",
    "start": "4155189",
    "end": "4162770"
  },
  {
    "text": "That the regularity\non the parts depends-- you can make it depend\non the number of parts",
    "start": "4162770",
    "end": "4168778"
  },
  {
    "text": "so that you get much stronger\ncontrol on the regularity. But there are also\nsome applications. For example, whether\nI will state next,",
    "start": "4168779",
    "end": "4176970"
  },
  {
    "text": "an application where you do\nneed that kind of strength. So here's what's known as\nthe infinite removal lemma.",
    "start": "4176970",
    "end": "4183899"
  },
  {
    "text": " Here we have not\njust a single pattern",
    "start": "4183899",
    "end": "4189689"
  },
  {
    "text": "or a finite number of patterns\nwe want to get rid of. For now we have\ninfinitely many patterns.",
    "start": "4189689",
    "end": "4195330"
  },
  {
    "text": "So for every curly H, which\nis a possibly infinite set",
    "start": "4195330",
    "end": "4208880"
  },
  {
    "text": "of graphs. The graphs themselves\nare always finite, but this may be\nan infinite list.",
    "start": "4208880",
    "end": "4215480"
  },
  {
    "text": "And an epsilon parameter. There exists an H0 and a\ndelta positive parameter",
    "start": "4215480",
    "end": "4226350"
  },
  {
    "text": "such that every n vertex\ngraph with at most delta--",
    "start": "4226350",
    "end": "4238230"
  },
  {
    "text": "so less than delta-- V to the H induced\ncopies of H for every H",
    "start": "4238230",
    "end": "4252580"
  },
  {
    "text": "in this family with\nfewer than H0 vertices.",
    "start": "4252580",
    "end": "4260205"
  },
  {
    "text": " So every graph\nwith this property",
    "start": "4260205",
    "end": "4267670"
  },
  {
    "text": "can be made curly H free.",
    "start": "4267670",
    "end": "4274910"
  },
  {
    "text": "So it means free of-- induced curly H free by\nadding or removing fewer",
    "start": "4274910",
    "end": "4292390"
  },
  {
    "text": "than epsilon n squared edges. ",
    "start": "4292390",
    "end": "4298230"
  },
  {
    "text": "So now instead of\na single pattern you have a possibly infinite\nset of induced patterns and a",
    "start": "4298230",
    "end": "4303370"
  },
  {
    "text": "want to make your\ngraph curly H free--",
    "start": "4303370",
    "end": "4309700"
  },
  {
    "text": "induced curly H free. And the theorem is\nthat if there exists",
    "start": "4309700",
    "end": "4315910"
  },
  {
    "text": "some finite bound, H0, such\nthat if you have few copies--",
    "start": "4315910",
    "end": "4323320"
  },
  {
    "text": "so for all the patterns\nup to that point-- then you can do\nwhat you need to do. ",
    "start": "4323320",
    "end": "4331050"
  },
  {
    "text": "So take some time to even\ndigest this statement, but it's somehow infinite\nversions-- the correct infinite version of the\nremoval lemma if you",
    "start": "4331050",
    "end": "4338220"
  },
  {
    "text": "have infinitely many patterns\nthat you need to remove. And I claim that the\nproof is actually more or less the same proof\nas the one that we did here,",
    "start": "4338220",
    "end": "4345640"
  },
  {
    "text": "except now you need\nto take your epsilon case, as in this\ncorollary, to depend on k.",
    "start": "4345640",
    "end": "4351900"
  },
  {
    "text": "You need to in some way look\nahead in this infinite pattern. So here in proof, this epsilon\nk from corollary depends on k.",
    "start": "4351900",
    "end": "4370160"
  },
  {
    "text": "And also it depends on\nyour family of patterns H.",
    "start": "4370160",
    "end": "4382790"
  },
  {
    "text": "Finally, I want to\nmention a perspective-- a computer science\nperspective on these removal",
    "start": "4382790",
    "end": "4389022"
  },
  {
    "text": "lemmas that we've been\ndiscussing so far. ",
    "start": "4389022",
    "end": "4394750"
  },
  {
    "text": "And that's in the\ncontext of something called property testing. ",
    "start": "4394750",
    "end": "4417830"
  },
  {
    "text": "And basically, we would\nlike an efficient--",
    "start": "4417830",
    "end": "4423350"
  },
  {
    "text": "efficient meaning fast--\nrandomized algorithm",
    "start": "4423350",
    "end": "4431900"
  },
  {
    "text": "to distinguish graphs that\nare triangle-free from those",
    "start": "4431900",
    "end": "4451820"
  },
  {
    "text": "that are epsilon far\nfrom triangle-free. ",
    "start": "4451820",
    "end": "4459330"
  },
  {
    "text": "Where being epsilon far\nfrom triangle-free means that you need to change more\nthan epsilon n squared edges",
    "start": "4459330",
    "end": "4472560"
  },
  {
    "text": "here. n is, as usual, the number\nof vertices to make the graph",
    "start": "4472560",
    "end": "4485310"
  },
  {
    "text": "triangle-free. So the distance, the\n[INAUDIBLE] distance is more than epsilon away\nfrom being triangle-free.",
    "start": "4485310",
    "end": "4492750"
  },
  {
    "text": "So somebody gives you\na very large graphing. n is very large. You cannot search through\nevery triple vertices.",
    "start": "4492750",
    "end": "4500400"
  },
  {
    "text": "That's too expensive. But you want some way to test\nif a graph is triangle-free",
    "start": "4500400",
    "end": "4506280"
  },
  {
    "text": "versus very far away\nfrom being triangle-free. ",
    "start": "4506280",
    "end": "4514270"
  },
  {
    "text": "So there's a very simple\nrandomized algorithm to do this, which is\nto just try randomly",
    "start": "4514270",
    "end": "4524000"
  },
  {
    "text": "sample a random\ntriple of vertices",
    "start": "4524000",
    "end": "4530850"
  },
  {
    "text": "and check if it's a triangle. ",
    "start": "4530850",
    "end": "4541860"
  },
  {
    "text": "So you do this. And just to make our\nlife a bit more secure,",
    "start": "4541860",
    "end": "4549330"
  },
  {
    "text": "let's try it some\nlarger number of times. So some c of epsilon some\nconstant number of times.",
    "start": "4549330",
    "end": "4559159"
  },
  {
    "text": "And if you find a triangle-- so if you don't find\na triangle, then we",
    "start": "4559160",
    "end": "4568770"
  },
  {
    "text": "return that it's triangle-free.",
    "start": "4568770",
    "end": "4574084"
  },
  {
    "text": " Otherwise we return that it is\nepsilon far from triangle-free.",
    "start": "4574084",
    "end": "4583444"
  },
  {
    "start": "4583444",
    "end": "4591980"
  },
  {
    "text": "So that's the algorithm.  So it's a very\nintuitive algorithm,",
    "start": "4591980",
    "end": "4599470"
  },
  {
    "text": "but why does it work? So we want to know that,\nindeed, somebody gives you",
    "start": "4599470",
    "end": "4605050"
  },
  {
    "text": "one of these two possibilities. You run that algorithm, you can\nsucceed with high probability.",
    "start": "4605050",
    "end": "4610340"
  },
  {
    "text": "Question? AUDIENCE: [INAUDIBLE] YUFEI ZHAO: So let's talk\nabout why this works.",
    "start": "4610340",
    "end": "4618500"
  },
  {
    "text": "So theorem, for\nevery epsilon, there exists a c such that\nalgorithm succeeds",
    "start": "4618500",
    "end": "4628323"
  },
  {
    "text": "with probability bigger than\n2/3, and 2/3 can be any number.",
    "start": "4628324",
    "end": "4637760"
  },
  {
    "text": "So any number that you\nlike because you can always repeat it to boost that\nconstant probability.",
    "start": "4637760",
    "end": "4642901"
  },
  {
    "text": " So there are two cases.",
    "start": "4642901",
    "end": "4648320"
  },
  {
    "text": "If g is triangle-free,\nthen it always succeeds.",
    "start": "4648320",
    "end": "4655070"
  },
  {
    "text": "You'll never find\nthis triangle, and it would return triangle-free. ",
    "start": "4655070",
    "end": "4664260"
  },
  {
    "text": "On the other hand, if g is\nepsilon far from triangle-free,",
    "start": "4664260",
    "end": "4675340"
  },
  {
    "text": "then triangle removal\nlemma tells us that g has lots of triangles.",
    "start": "4675340",
    "end": "4683913"
  },
  {
    "text": " Delta n cubed triangles. ",
    "start": "4683913",
    "end": "4692100"
  },
  {
    "text": "So if we sample c being, let's\nsay, 1 over delta times--",
    "start": "4692100",
    "end": "4703710"
  },
  {
    "text": "delta here is a function of\nepsilon from the triangle removal lemma. So we find that the probability\nthat the algorithm fails",
    "start": "4703710",
    "end": "4714960"
  },
  {
    "text": "is at most-- ",
    "start": "4714960",
    "end": "4731710"
  },
  {
    "text": "so you have a lot of triangles. So very likely you will\nhit one of these triangles. So the probability that the\nalgorithm fails is at most 1",
    "start": "4731710",
    "end": "4740020"
  },
  {
    "text": "minus delta n cubed divided\nby total number of triples",
    "start": "4740020",
    "end": "4745780"
  },
  {
    "text": "raised to 1 over delta. And this is 1 minus at\nmost 1 minus 6 delta raised",
    "start": "4745780",
    "end": "4753090"
  },
  {
    "text": "to 1 over delta, and it's\nat most e to the minus 6. So less than 1/3 in particular.",
    "start": "4753090",
    "end": "4761890"
  },
  {
    "text": "So this algorithm succeeds\nwith high probability. Now, how big of a c do you need? Well, that depends on the\ntriangle removal lemma.",
    "start": "4761890",
    "end": "4770090"
  },
  {
    "text": "So it's a constant. So it's a constant,\ndoes not depend on the size of the graph.",
    "start": "4770090",
    "end": "4777520"
  },
  {
    "text": "But it's a large\nconstant, because we saw in the proof\nof regularity lemma that it can be very large.",
    "start": "4777520",
    "end": "4782690"
  },
  {
    "text": " But you know, this\ntheorem here is basically",
    "start": "4782690",
    "end": "4789500"
  },
  {
    "text": "the same as a triangle\nremoval lemma. So it's highly\nnon-trivial if it's true.",
    "start": "4789500",
    "end": "4795630"
  },
  {
    "text": "Even though the algorithm is\nextremely naive and simple. I just want to finish\noff with one more thing.",
    "start": "4795630",
    "end": "4801420"
  },
  {
    "text": "Instead of testing\nfor triangle-freeness, you can ask what other\nproperties can you test? So which graph\nproperties are testable",
    "start": "4801420",
    "end": "4812590"
  },
  {
    "text": "in default in that sense?  So distinguishing\nsomething which",
    "start": "4812590",
    "end": "4819040"
  },
  {
    "text": "has the property, so P versus\nepsilon far from this property",
    "start": "4819040",
    "end": "4827070"
  },
  {
    "text": "P.",
    "start": "4827070",
    "end": "4832119"
  },
  {
    "text": "And you have this\ntester which is you sample some number of vertices. So this is called\nthe oblivious tester.",
    "start": "4832120",
    "end": "4838800"
  },
  {
    "text": " So you sample k\nvertices, and you try",
    "start": "4838800",
    "end": "4848760"
  },
  {
    "text": "to see if it has that property. So there's a class of\nproperties called hereditary.",
    "start": "4848760",
    "end": "4856636"
  },
  {
    "text": " So hereditary properties\nare properties",
    "start": "4856637",
    "end": "4862559"
  },
  {
    "text": "that are closed under\nvertex deletion. ",
    "start": "4862560",
    "end": "4871320"
  },
  {
    "text": "And these properties are-- lots of properties that you're\nseeing are of this form.",
    "start": "4871320",
    "end": "4876660"
  },
  {
    "text": "So for example, being H3 is this\nform being planar so this one",
    "start": "4876660",
    "end": "4884780"
  },
  {
    "text": "being induced H3, so this\none being three-colorable,",
    "start": "4884780",
    "end": "4891705"
  },
  {
    "text": "being perfect,\nthey're all examples of hereditary properties. Properties that if your\ngraph is three-colorable,",
    "start": "4891706",
    "end": "4898210"
  },
  {
    "text": "you take out some vertices,\nit's still three-colorable. And all the\ndiscussions that we've",
    "start": "4898210",
    "end": "4904120"
  },
  {
    "text": "done so far, in particular\nthe infinite removal lemma. If you phrase it in the form\nof property testing given",
    "start": "4904120",
    "end": "4912010"
  },
  {
    "text": "the above discussion, it implies\nthat every hereditary property",
    "start": "4912010",
    "end": "4923059"
  },
  {
    "text": "is testable.  In fact, it's testable\nin the above sense",
    "start": "4923060",
    "end": "4930969"
  },
  {
    "text": "with a one-sided error\nusing an oblivious tester.",
    "start": "4930970",
    "end": "4936110"
  },
  {
    "text": "One-sided error means that up\nthere if it's triangle-free, then it always succeeds.",
    "start": "4936110",
    "end": "4941260"
  },
  {
    "text": "So here one of the cases\nthat always succeeds. And the reason is that\nyou can characterize",
    "start": "4941260",
    "end": "4948150"
  },
  {
    "text": "a hereditary property\nby a curly H induced H3",
    "start": "4948150",
    "end": "4957350"
  },
  {
    "text": "for some curly H. Namely,\nyou're putting everything into H that do not\nhave this property.",
    "start": "4957350",
    "end": "4965800"
  },
  {
    "start": "4965800",
    "end": "4973969"
  },
  {
    "text": "This is a possibly\ninfinite set of graphs, and that completely\ncharacterizes",
    "start": "4973970",
    "end": "4980500"
  },
  {
    "text": "this hereditary property. And if you read out the\ninfinite removal lemma, it says precisely, using\nabove this interpretation,",
    "start": "4980500",
    "end": "4989950"
  },
  {
    "text": "that you have a property\ntesting algorithm. ",
    "start": "4989950",
    "end": "4995000"
  }
]
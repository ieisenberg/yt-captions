[
  {
    "start": "0",
    "end": "101000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6950"
  },
  {
    "text": "offer high-quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "6950",
    "end": "13500"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "13500",
    "end": "19030"
  },
  {
    "text": " CHARLES LEISERSON: So today,\nmore parallel programming, as",
    "start": "19030",
    "end": "27230"
  },
  {
    "text": "we will do for the next couple\nlectures as well. So today, we're going to\nlook at how to analyze",
    "start": "27230",
    "end": "36570"
  },
  {
    "text": "multi-threaded algorithms, and\nI'm going to start out with a",
    "start": "36570",
    "end": "44970"
  },
  {
    "text": "review of what I hope most of\nyou know from 6006 or 6046,",
    "start": "44970",
    "end": "53470"
  },
  {
    "text": "which is how to solve divide\nand conquer recurrences. Now, we know that we can solve\nthem with recursion trees, and",
    "start": "53470",
    "end": "60280"
  },
  {
    "text": "that gets tedious after a while,\nso I want to go through the so-called Master Method to\nbegin with, and then we'll get",
    "start": "60280",
    "end": "67050"
  },
  {
    "text": "into the content\nof the course. But it will be very helpful,\nsince we're going to do so",
    "start": "67050",
    "end": "73610"
  },
  {
    "text": "many divide and conquer\nrecurrences. The difference between these\ndivide and conquer recurrences and the ones for caching is that\ncaching is all tricky by",
    "start": "73610",
    "end": "81789"
  },
  {
    "text": "the base condition. Here, are all the recurrences\nare going to be nice and clean, just like you learn\nin your algorithms class.",
    "start": "81790",
    "end": "89690"
  },
  {
    "text": "So we'll start with talking\nabout it, and then we'll go through several examples of\nanalysis of algorithms.",
    "start": "89690",
    "end": "96140"
  },
  {
    "text": "And it'll also tell us something\nabout what we need to do to make our\ncode go fast.",
    "start": "96140",
    "end": "102289"
  },
  {
    "start": "101000",
    "end": "157000"
  },
  {
    "text": "So the main method we're\ngoing to use is called the Master Method.",
    "start": "102290",
    "end": "108400"
  },
  {
    "text": "It's for solving recurrences of\nthe form t of n equals a t of n over b plus f of n, where\nwe have some technical",
    "start": "108400",
    "end": "118100"
  },
  {
    "text": "conditions, a is greater than\nor equal to 1, b is greater than one, and f is\nasymptotically positive.",
    "start": "118100",
    "end": "123950"
  },
  {
    "text": "As f gets large, it\nbecomes positive. When we give a recurrence like\nthis, normally if the base",
    "start": "123950",
    "end": "131330"
  },
  {
    "text": "case is order one, it's\nconvention not give it, to just assume, yeah, we understand\nthat when n is",
    "start": "131330",
    "end": "137810"
  },
  {
    "text": "small enough, the result\nis constant. As I say, that's the place where\nthis differs from the",
    "start": "137810",
    "end": "145709"
  },
  {
    "text": "way that we solve recurrences\nfor caching, where you have to",
    "start": "145710",
    "end": "153260"
  },
  {
    "text": "worry about what is the base\ncase of the recurrence. ",
    "start": "153260",
    "end": "158640"
  },
  {
    "start": "157000",
    "end": "273000"
  },
  {
    "text": "So the way to solve this\nis, in fact, the way we've seen before. It's a recursion tree. So we start with t of n, and\nthen we replace t of n by the",
    "start": "158640",
    "end": "167489"
  },
  {
    "text": "right hand side, just\nby substitution. So what's always going to be in\nthe tree as we develop it",
    "start": "167490",
    "end": "172590"
  },
  {
    "text": "is the total amount of work. So we basically replace it\nby f of n plus a copies",
    "start": "172590",
    "end": "179870"
  },
  {
    "text": "of t of n over b. And then each of those we\nreplace by a copies so t of n",
    "start": "179870",
    "end": "188650"
  },
  {
    "text": "over b squared. And so forth, continually\nreplacing until we get",
    "start": "188650",
    "end": "194830"
  },
  {
    "text": "down to t of 1. And at the point t of 1, we no\nlonger can substitute here, but we know that t\nof 1 is order 1.",
    "start": "194830",
    "end": "202340"
  },
  {
    "text": "And now what we do is\nadd across the rows. So we get f of n, we get a, f of\nn over b, a squared f of n",
    "start": "202340",
    "end": "210510"
  },
  {
    "text": "over b squared, and we keep\ngoing to the height of this, which we're dividing by the\nargument by b each time.",
    "start": "210510",
    "end": "219050"
  },
  {
    "text": "So to get down to 1 is\njust log base b of n.",
    "start": "219050",
    "end": "224440"
  },
  {
    "text": "So the number of leaves is,\nsince this is a regular",
    "start": "224440",
    "end": "230200"
  },
  {
    "text": "[? a area ?] tree, is a to the height,\nwhich is a to the log base b of n. And for each of those,\nwe're paying t of 1,",
    "start": "230200",
    "end": "238010"
  },
  {
    "text": "which is order 1. And so now, it turns\nout there's",
    "start": "238010",
    "end": "243269"
  },
  {
    "text": "no closed form solution. If I add up all these\nterms, there's no closed form solution.",
    "start": "243270",
    "end": "248790"
  },
  {
    "text": "But there are three\ncommon situations that occur in practice.",
    "start": "248790",
    "end": "254020"
  },
  {
    "text": "So yes, this is just n to the\nlog base b of a, just this term, not the sum,\njust this term.",
    "start": "254020",
    "end": "262210"
  },
  {
    "text": "So three cases have to do with\ncomparing the number of leaves, which is times\norder 1, with f of n.",
    "start": "262210",
    "end": "271350"
  },
  {
    "text": " So the first case is the case\nwhere n the log base b of a is",
    "start": "271350",
    "end": "279760"
  },
  {
    "text": "bigger than f of n. So whenever you're given a\nrecurrence to compute n to the log base b of a--",
    "start": "279760",
    "end": "285479"
  },
  {
    "text": "I hope this is repeat\nfor most people. If not, that's fine,\nbut hopefully it'll get you caught up.",
    "start": "285480",
    "end": "293990"
  },
  {
    "text": "n log base b of a, if it's much\nbigger than f of n, then these terms are geometrically\nincreasing.",
    "start": "293990",
    "end": "301080"
  },
  {
    "text": "And since it's geometrically\nincreasing, all that matters is the base case. In fact, actually, it has to be\nnot just greater than, it's",
    "start": "301080",
    "end": "308970"
  },
  {
    "text": "got to be greater than by a\npolynomial amount, by some n to the epsilon amount for some\nepsilon greater than 0.",
    "start": "308970",
    "end": "315200"
  },
  {
    "text": "So it might be n to the 1/2, it\nmight be n to the 1/3, it",
    "start": "315200",
    "end": "320480"
  },
  {
    "text": "could be n to the 100th. But what it can't be is log n,\nbecause log n is less than any",
    "start": "320480",
    "end": "329320"
  },
  {
    "text": "polynomial amount. So it's got to exceed it by at\nleast n to the epsilon for",
    "start": "329320",
    "end": "334330"
  },
  {
    "text": "some epsilon. In that case, it's geometrically\nincreasing, the answer is just what's\nat the leaves.",
    "start": "334330",
    "end": "340550"
  },
  {
    "text": "So that's case one,\ngeometrically increasing. Case two is when things\nare actually fairly",
    "start": "340550",
    "end": "347800"
  },
  {
    "start": "343000",
    "end": "503000"
  },
  {
    "text": "equal on every level. And the general case we'll\nlook at is when it's",
    "start": "347800",
    "end": "353680"
  },
  {
    "text": "arithmetically increasing. So in particular, this occurs\nwhen f of n is n to the log",
    "start": "353680",
    "end": "363200"
  },
  {
    "text": "base b of a times log to some\npower, n, for some constant k",
    "start": "363200",
    "end": "369000"
  },
  {
    "text": "that's at least 0. So this is the situation. If k is equal to 0, it just says\nthat f of n, the amount",
    "start": "369000",
    "end": "378080"
  },
  {
    "text": "here is exactly the same as\nthe number of leaves. And that case, it turns out that\nevery level has almost",
    "start": "378080",
    "end": "384960"
  },
  {
    "text": "exactly the same amount. And since there are log n\nlevels, you tack on an extra log n for the solution.",
    "start": "384960",
    "end": "391300"
  },
  {
    "text": "In fact, the solution\nis one more log. Turns out that if it's growing\narithmetically with layer, you",
    "start": "391300",
    "end": "398720"
  },
  {
    "text": "basically take on\none extra log. It's actually like doing\nthe integral of a as",
    "start": "398720",
    "end": "405320"
  },
  {
    "text": "an arithmetic series. If you're adding the terms\nof, say, i squared,",
    "start": "405320",
    "end": "411810"
  },
  {
    "text": "the result is i cubed.  If you have a summation that\ngoes from i equals 1 to n of i",
    "start": "411810",
    "end": "420030"
  },
  {
    "text": "squared, the result is\nproportional to n cubed. And similarly, if it's i to any\nk, the result is going to",
    "start": "420030",
    "end": "431380"
  },
  {
    "text": "be n to the k plus 1,\nand that's basically what's going on here.",
    "start": "431380",
    "end": "438450"
  },
  {
    "text": "And then the third case is\nwhen it's geometrically decreasing, when the amount\nat the root dominates.",
    "start": "438450",
    "end": "443670"
  },
  {
    "text": " So in this case, if it's much\nless than n, and specifically,",
    "start": "443670",
    "end": "453960"
  },
  {
    "text": "f of n is at least n to the\nepsilon less than log base b",
    "start": "453960",
    "end": "460725"
  },
  {
    "text": "of a, for some constant epsilon,\nit turns out in addition, you need f of n\nto satisfy a regularity",
    "start": "460726",
    "end": "467950"
  },
  {
    "text": "condition, but this regularity\ncondition is satisfied by all the normal functions that\nwe're going to come up.",
    "start": "467950",
    "end": "473300"
  },
  {
    "text": "It's not satisfied by things\nlike n to the sine n, which",
    "start": "473300",
    "end": "480110"
  },
  {
    "text": "oscillates like crazy. But it also isn't satisfied by exponentially growing functions.",
    "start": "480110",
    "end": "486800"
  },
  {
    "text": "But it is satisfied by anything\nthat's polynomial, or polynomial times a logarithm,\nor what have you.",
    "start": "486800",
    "end": "492580"
  },
  {
    "text": "So generally, we don't\nreally have to check this too carefully. And then the answer there is\njust it's order f of n,",
    "start": "492580",
    "end": "499850"
  },
  {
    "text": "because it's geometrically\ndecreasing, f of n dominates. So is this review\nfor everybody?",
    "start": "499850",
    "end": "506889"
  },
  {
    "start": "503000",
    "end": "661000"
  },
  {
    "text": "Pretty much, yeah, yeah, yeah? You can do this in your head,\nbecause we're going to ask you",
    "start": "506890",
    "end": "511960"
  },
  {
    "text": "to do this in your head\nduring the lecture? Yeah, we're all good? OK, good.",
    "start": "511960",
    "end": "518940"
  },
  {
    "text": "One of the things that students,\nwhen they learn this in an algorithms class, don't\nrecognize is that this also",
    "start": "518940",
    "end": "525500"
  },
  {
    "text": "tells you where in your\nprogram, where in your recursive program, you should\nbother to try to eke out",
    "start": "525500",
    "end": "532100"
  },
  {
    "text": "constant factors.  So if you think about it, for\nexample, in case three here,",
    "start": "532100",
    "end": "538210"
  },
  {
    "text": "it's geometrically decreasing. Does it make sense to try\nto optimize the leaves?",
    "start": "538210",
    "end": "545529"
  },
  {
    "text": "No, because very little\ntime is spent there. It makes sense to optimize\nwhat's going on at the root,",
    "start": "545530",
    "end": "552420"
  },
  {
    "text": "and to save anything you\ncan at the root. And sometimes, the root in\nparticular has special properties that aren't true of\nthe internal nodes that you",
    "start": "552420",
    "end": "560140"
  },
  {
    "text": "can take advantage of, that you\nmay not be able to take advantage of regularly. But since it's going to be\ndominated by the root, trying",
    "start": "560140",
    "end": "566390"
  },
  {
    "text": "to save in the root\nmakes sense. Correspondingly, if we're in\ncase one, in case one, it's",
    "start": "566390",
    "end": "575540"
  },
  {
    "text": "absolutely critical that you\ncoarsen the recursion, because all the work is down\nat this level.",
    "start": "575540",
    "end": "581850"
  },
  {
    "text": " And so if you want to get\nadditional performance, you",
    "start": "581850",
    "end": "587430"
  },
  {
    "text": "want to basically move this up\nhigh enough that you can cut off that constant amount and\nget factors two, three,",
    "start": "587430",
    "end": "595540"
  },
  {
    "text": "sometimes more, out\nof your code.",
    "start": "595540",
    "end": "600820"
  },
  {
    "text": "So understanding the structure\nof the recursion allows you to",
    "start": "600820",
    "end": "606200"
  },
  {
    "text": "figure out where it is that you\nshould optimize your code. Of course, with loops,\nit's much easier. Where do you spend your\ntime with loops to",
    "start": "606200",
    "end": "613720"
  },
  {
    "text": "make code go fast?  The innermost loop, right,\nbecause that's the one that's",
    "start": "613720",
    "end": "621250"
  },
  {
    "text": "executing the most. The outer loops are not\nthat important. This is sort of the corresponding thing for recursion.",
    "start": "621250",
    "end": "628840"
  },
  {
    "text": "Figure out where the recursion\nis spending the time, that's where you spend time eking\nout extra factors.",
    "start": "628840",
    "end": "634110"
  },
  {
    "text": " Here's the cheat sheet.",
    "start": "634110",
    "end": "639800"
  },
  {
    "text": " So if it's n to the log base\nb of a minus epsilon, the",
    "start": "639800",
    "end": "647920"
  },
  {
    "text": "answer's n to the\nlog base b of a. If it's plus epsilon,\nit's f of n. And if it's n to the log base\nb of a times a logarithmic",
    "start": "647920",
    "end": "655030"
  },
  {
    "text": "factor, where this logarithm has\nthe exponent greater than or equal to 0, you add a 1.",
    "start": "655030",
    "end": "662140"
  },
  {
    "start": "661000",
    "end": "780000"
  },
  {
    "text": "This is not all of\nthe situations. There are situations\nwhich don't occur. OK, quick quiz.",
    "start": "662140",
    "end": "668185"
  },
  {
    "text": " So t of n equals 4t of\nn over 2 plus n.",
    "start": "668185",
    "end": "673390"
  },
  {
    "text": "What's the solution?  n squared, good.",
    "start": "673390",
    "end": "679730"
  },
  {
    "text": "So this is n to the log base b\nof a, is n to the log base 2 of 4, which is n squared.",
    "start": "679730",
    "end": "685910"
  },
  {
    "text": "That's much bigger than n. It's bigger by a factor of n. Here, the epsilon of 1 would do,\nso would an epsilon of 1/2",
    "start": "685910",
    "end": "692430"
  },
  {
    "text": "or an epsilon of 1/4, but\nin particular, an epsilon of 1 would do. That's case one. The n squared dominates, so\nthe answer is n squared.",
    "start": "692430",
    "end": "700589"
  },
  {
    "text": "The basic idea is whichever side\ndominates for case one and case three, that's the\none that is the answer.",
    "start": "700590",
    "end": "707700"
  },
  {
    "text": "Here we go. What about this one? n squared log n, because\nthe two sides are",
    "start": "707700",
    "end": "714170"
  },
  {
    "text": "about the same size. It's n squared times log to the\n0n, tack on the extra log.",
    "start": "714170",
    "end": "722240"
  },
  {
    "text": "How about this one? n cubed. How about this one? ",
    "start": "722240",
    "end": "729403"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. Master Theorem [INAUDIBLE]?",
    "start": "729403",
    "end": "734899"
  },
  {
    "text": "CHARLES LEISERSON: Yeah, the\nMaster Theorem does not apply to this one. It looks like it's case two with\nan an exponent of minus",
    "start": "734900",
    "end": "743070"
  },
  {
    "text": "1, but that's bogus because the\nexponent of the log must",
    "start": "743070",
    "end": "748360"
  },
  {
    "text": "be greater than or equal to 0. So instead, this actually has\na solution, so it does not",
    "start": "748360",
    "end": "755510"
  },
  {
    "text": "apply, it actually has the\nsolution n squared, log log n,",
    "start": "755510",
    "end": "760750"
  },
  {
    "text": "but that's not covered by\nthe Master Theorem. You can have an infinite\nhierarchy of",
    "start": "760750",
    "end": "766640"
  },
  {
    "text": "narrowing in things. So if you don't have a solution\nto something that",
    "start": "766640",
    "end": "772330"
  },
  {
    "text": "looks like a Master Theorem\ntype of recurrence, what's your best strategy\nfor solving it?",
    "start": "772330",
    "end": "779782"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. CHARLES LEISERSON:\nWhat's that? AUDIENCE: [INAUDIBLE].",
    "start": "779782",
    "end": "784840"
  },
  {
    "text": "CHARLES LEISERSON: So a\nrecursion tree can be good, but actually, the best is the\nsubstitution method, basically proving it by induction.",
    "start": "784840",
    "end": "791089"
  },
  {
    "text": "And the recursion tree can be\nvery helpful in giving you a good guess for what you\nthink the answer is.",
    "start": "791090",
    "end": "798070"
  },
  {
    "text": "But the most reliable way to\nprove any of these things is using substitution method.",
    "start": "798070",
    "end": "803899"
  },
  {
    "text": "Good enough. So that was review for,\nI hope, most people? Yeah? OK, good.",
    "start": "803900",
    "end": "810580"
  },
  {
    "text": "OK, let's talk about parallel\nprogramming. We're going to start\nout with loops. So last time, we talked about\nhow the cilk++ runtime system",
    "start": "810580",
    "end": "819800"
  },
  {
    "text": "is based on, essentially,\nimplementing spawns and syncs,",
    "start": "819800",
    "end": "826430"
  },
  {
    "text": "using the work stealing\nalgorithm, and we talked about scheduling and so forth.",
    "start": "826430",
    "end": "831660"
  },
  {
    "text": "We didn't talk about how loops\nare implemented, except to mention that they\nwere implemented",
    "start": "831660",
    "end": "837110"
  },
  {
    "text": "with divide and conquer. So here I want to go into the\nsubtleties of loops, because",
    "start": "837110",
    "end": "842160"
  },
  {
    "text": "probably most programs that\noccur in the real world these days are programs where people\njust simply say, make this a",
    "start": "842160",
    "end": "851930"
  },
  {
    "text": "parallel loop. That's it. So let's take an example of the\nin-place matrix transpose,",
    "start": "851930",
    "end": "861730"
  },
  {
    "text": "where we're basically trying to\nflip everything along the main diagonal. I've used this figure\nbefore, I think.",
    "start": "861730",
    "end": "871029"
  },
  {
    "text": "So let's just do it not\ncache efficiently. So the cache efficient\nalgorithm actually",
    "start": "871030",
    "end": "876540"
  },
  {
    "text": "parallelizes beautifully also,\nbut let's not look at the",
    "start": "876540",
    "end": "881690"
  },
  {
    "text": "cache efficient version, the\ndivide and conquer version. Let's look at a looping\nversion to understand.",
    "start": "881690",
    "end": "888010"
  },
  {
    "text": "And once again here, as I did\nbefore, I'm going to make the indices for my implementation\nrun from 0, not 1.",
    "start": "888010",
    "end": "896430"
  },
  {
    "text": "And basically, I have an outer\nloop that goes from i equals 1 up to n minus 1, and an inner\nloop that goes from j equals 0",
    "start": "896430",
    "end": "908020"
  },
  {
    "text": "up to i minus 1. And then I do a little\nswap in there.",
    "start": "908020",
    "end": "915850"
  },
  {
    "text": "And in here, the outer loop I've\nparallelized, the inner",
    "start": "915850",
    "end": "921589"
  },
  {
    "text": "loop is running serially. ",
    "start": "921590",
    "end": "931600"
  },
  {
    "text": "So let's take a look at\nanalyzing this particular piece of code to understand\nwhat's going on.",
    "start": "931600",
    "end": "937900"
  },
  {
    "text": "So the way this actually gets\nimplemented is as follows. So here's the code\non the left.",
    "start": "937900",
    "end": "944830"
  },
  {
    "text": "What actually happens in the\ncilk++ compiler is it converts",
    "start": "944830",
    "end": "953790"
  },
  {
    "text": "it into recursion, divide\nand conquer recursion. So what it does is it has a\nrange from low to high, is",
    "start": "953790",
    "end": "962160"
  },
  {
    "text": "sort of the common case. We're going to call it on from 1\nto n minus 1, because that's the indexes that I've given\nto the cilk_for loop.",
    "start": "962160",
    "end": "971300"
  },
  {
    "text": "And what we do is, if I have\na region to do divide and",
    "start": "971300",
    "end": "977529"
  },
  {
    "text": "conquer on, a set of values\nfor i, I basically",
    "start": "977530",
    "end": "982760"
  },
  {
    "text": "divide that in half. And then I recursively execute\nthe first half, and then the",
    "start": "982760",
    "end": "992640"
  },
  {
    "text": "second half, and\nthen cilk_sync. So the two sides are going\noff in parallel.",
    "start": "992640",
    "end": "997790"
  },
  {
    "text": "And then if I am at the base,\nthen I go through the inner loop and do the swap of the\nvalues in the inner loop.",
    "start": "997790",
    "end": "1008260"
  },
  {
    "text": "So the outer loop is the one\nthat's the parallel loop. That one we're doing divide\nand conquer on.",
    "start": "1008260",
    "end": "1014449"
  },
  {
    "text": "So we basically recursively\nspawn the first half, execute the second, and then each of\nthose recursively does the",
    "start": "1014450",
    "end": "1022959"
  },
  {
    "text": "same thing until all the\niterations have been done.",
    "start": "1022960",
    "end": "1028680"
  },
  {
    "text": "Any questions about\nhow that operates? ",
    "start": "1028680",
    "end": "1034069"
  },
  {
    "text": "So this is the way all the\nparallel loops are done, is basically this strategy. Now here, I mention that this\nis in fact what happens is",
    "start": "1034069",
    "end": "1041609"
  },
  {
    "text": "this test here is actually\ncoarsened. So we don't want to go all the\nway to n equals 1, because",
    "start": "1041609",
    "end": "1049000"
  },
  {
    "text": "then we'll have this recursion\ncall overhead every time we do a call. So in fact, what happens is you\ngo down to some grain size",
    "start": "1049000",
    "end": "1059120"
  },
  {
    "text": "of some number of iterations,\nand at that number of iterations, it then just runs\nthrough it as an ordinary",
    "start": "1059120",
    "end": "1065790"
  },
  {
    "text": "serial four loop, in order not\nto pay the function call overhead all the way down.",
    "start": "1065790",
    "end": "1071830"
  },
  {
    "text": "We're going to look exactly\nat that issue. So if I take a look at it from\nusing the DAG model that I",
    "start": "1071830",
    "end": "1085660"
  },
  {
    "text": "introduced last time, remember\nthat the rectangles here kind",
    "start": "1085660",
    "end": "1092000"
  },
  {
    "text": "of count as activation\nframes, stack frames on the call stack.",
    "start": "1092000",
    "end": "1098520"
  },
  {
    "text": "And the circles here are\nstrands, which are sequences of serial code.",
    "start": "1098520",
    "end": "1105019"
  },
  {
    "text": "And so what's happening here\nis essentially, I'm running the code that divides\nit into two parts,",
    "start": "1105020",
    "end": "1110665"
  },
  {
    "text": "and I spawn one part. Then this guy spawns the other\nand waits for the return, and",
    "start": "1110665",
    "end": "1116480"
  },
  {
    "text": "then these guys come back. And then I keep doing that\nrecursively, and then when I get to the bottom, I then run\nthrough the innermost loop,",
    "start": "1116480",
    "end": "1125010"
  },
  {
    "text": "which starts out with just one\nelement to do, two, three. And so the number\nof elements--",
    "start": "1125010",
    "end": "1131210"
  },
  {
    "text": "for example, in this case where\nI've done eight, I go through eight elements at the\nbottom here if this were an",
    "start": "1131210",
    "end": "1139130"
  },
  {
    "text": "eight by eight matrix that\nI was transposing. So there's more work in these\nguys than there is over here.",
    "start": "1139130",
    "end": "1148450"
  },
  {
    "text": "So it's not something you just\ncan map onto processors in some naive fashion. It does take some load\nbalancing to",
    "start": "1148450",
    "end": "1154410"
  },
  {
    "text": "parallelize this loop. Any questions about what's\ngoing on here? Yeah?",
    "start": "1154410",
    "end": "1159800"
  },
  {
    "text": "AUDIENCE: Why is it that\nit's one, two, three, four, up to eight? CHARLES LEISERSON:\nTake a look. The inner loop goes\nfrom j to i.",
    "start": "1159800",
    "end": "1166085"
  },
  {
    "text": " So this guy just does one\niteration of the inner loop,",
    "start": "1166085",
    "end": "1171230"
  },
  {
    "text": "this guy does two, this guy does\nthree, all the way up to this guy doing eight iterations,\nif it were an eight by eight matrix.",
    "start": "1171230",
    "end": "1178880"
  },
  {
    "text": "And in general, if it's n by\nn, it's going from one to n work up here, but only\none work down here.",
    "start": "1178880",
    "end": "1185630"
  },
  {
    "text": "Because I'm basically iterating\nthrough a triangular iteration space to swap the\nmatrix, and this is basically",
    "start": "1185630",
    "end": "1192000"
  },
  {
    "text": "swapping row by row. Questions? Is that good?",
    "start": "1192000",
    "end": "1197160"
  },
  {
    "text": "Everybody see what's going on? So now let's take a look\nand let's analyze this for work and span.",
    "start": "1197160",
    "end": "1202500"
  },
  {
    "text": "So what is the work of this\nin terms of n, if I have an n by n matrix?",
    "start": "1202500",
    "end": "1208255"
  },
  {
    "start": "1208255",
    "end": "1218550"
  },
  {
    "text": "What's the work? The work is the ordinary serial\nrunning time, right? It's n squared.",
    "start": "1218550",
    "end": "1224419"
  },
  {
    "text": "Good. So basically, it's order n\nsquared, because these guys",
    "start": "1224420",
    "end": "1229710"
  },
  {
    "text": "are all adding up. This is an arithmetic sequence\nup to n, and so the total",
    "start": "1229710",
    "end": "1235060"
  },
  {
    "text": "amount in here is\norder n squared. What about this part up here? ",
    "start": "1235060",
    "end": "1243420"
  },
  {
    "text": "How much does that\ncost us for work?",
    "start": "1243420",
    "end": "1250580"
  },
  {
    "text": "How much is in the control\noverhead of doing that outer loop? ",
    "start": "1250580",
    "end": "1265934"
  },
  {
    "text": "So asymptotically, how\nmuch is in here? The total is going\nto be n squared. That I guarantee you.",
    "start": "1265935",
    "end": "1271180"
  },
  {
    "text": "But what's going on up here? How do I count that up?",
    "start": "1271180",
    "end": "1276500"
  },
  {
    "text": "AUDIENCE: I'm assuming that each\n[? strain ?] is going to be constant time? CHARLES LEISERSON: Yeah, well\nin this case, it is constant",
    "start": "1276500",
    "end": "1282160"
  },
  {
    "text": "time, for these up here, because\nwhat am I doing? All I'm doing is the recursion\ncode where I divide the range",
    "start": "1282160",
    "end": "1292690"
  },
  {
    "text": "and then spawn off two things. That takes me only a constant\namount of manipulation to be able to do that.",
    "start": "1292690",
    "end": "1298600"
  },
  {
    "text": "So this is all order n. Total of order n here.",
    "start": "1298600",
    "end": "1303760"
  },
  {
    "text": "The reason is because\nin some sense, there are n leaves here. And if you have a full binary\ntree, meaning every child is",
    "start": "1303760",
    "end": "1312040"
  },
  {
    "text": "either a leaf or has two\nchildren, then the number of the internal nodes of the\ntree is one less than",
    "start": "1312040",
    "end": "1318120"
  },
  {
    "text": "the number of leaves. So that's a basic property of\ntrees, that the number of the",
    "start": "1318120",
    "end": "1326080"
  },
  {
    "text": "internal nodes here is going to\nbe n minus 1, in this case. In particular, we have 7 here.",
    "start": "1326080",
    "end": "1334460"
  },
  {
    "text": "Is that good? So this part doesn't contribute significantly to the work.",
    "start": "1334460",
    "end": "1339790"
  },
  {
    "text": "Just this part contributes\nto the work. Is that good? ",
    "start": "1339790",
    "end": "1346000"
  },
  {
    "text": "What about the span for this? ",
    "start": "1346000",
    "end": "1364470"
  },
  {
    "text": "What's the span?  AUDIENCE: Log n.",
    "start": "1364470",
    "end": "1370770"
  },
  {
    "text": "CHARLES LEISERSON: It's not log\nn, but your heads are in the right place. ",
    "start": "1370770",
    "end": "1377796"
  },
  {
    "text": "AUDIENCE: The longest path\nis going [INAUDIBLE]. CHARLES LEISERSON: Which is the\nlongest path going to be",
    "start": "1377796",
    "end": "1382824"
  },
  {
    "text": "here, starting here and ending\nthere, which way do we go?",
    "start": "1382824",
    "end": "1390371"
  },
  {
    "text": "AUDIENCE: Go all the way down. CHARLES LEISERSON: Which way? AUDIENCE: To the right. CHARLES LEISERSON: Down to\nthe right, over, down",
    "start": "1390371",
    "end": "1397309"
  },
  {
    "text": "through this guy. How big is this guy? n. Go back up this way.",
    "start": "1397310",
    "end": "1402830"
  },
  {
    "text": "So how much is in this\npart going down? AUDIENCE: Log n. CHARLES LEISERSON: Going\ndown and up is log",
    "start": "1402830",
    "end": "1407880"
  },
  {
    "text": "n, but this is n. Good. ",
    "start": "1407880",
    "end": "1415160"
  },
  {
    "text": "So it's basically order n plus\norder log n, order n down here",
    "start": "1415160",
    "end": "1420310"
  },
  {
    "text": "plus order log n up and\ndown, that's order n. So the parallelism is the ratio\nof those two things,",
    "start": "1420310",
    "end": "1428840"
  },
  {
    "text": "which is order n. So that's got good\nparallelism.",
    "start": "1428840",
    "end": "1434260"
  },
  {
    "text": "And so if you imagine doing\nthis in a large number processors, very easy to get\nsort of your benchmark of",
    "start": "1434260",
    "end": "1442630"
  },
  {
    "text": "maybe 10 times more parallelism\nthan the number of processors that you're\nrunning on.",
    "start": "1442630",
    "end": "1448570"
  },
  {
    "text": "Everybody follow this?  Good.",
    "start": "1448570",
    "end": "1454460"
  },
  {
    "text": "So the span of the loop control\nis order log n. And in general, when you have a\nfour loop with n iterations,",
    "start": "1454460",
    "end": "1463309"
  },
  {
    "text": "the loop control itself is going\nto have log n is going to have to be added to the\nspan every time you hit a",
    "start": "1463310",
    "end": "1470000"
  },
  {
    "text": "loop, log of whatever the\nnumber of iterations is.",
    "start": "1470000",
    "end": "1475570"
  },
  {
    "text": "And then we have the maximum\nspan of the body. Well, the worst case for this\nthing in the body is when it's",
    "start": "1475570",
    "end": "1481710"
  },
  {
    "text": "doing the whole thing, because\nwhenever we're looking at spans, we're always looking\nwhat's the maximum of things",
    "start": "1481710",
    "end": "1488490"
  },
  {
    "text": "that are operating\nin parallel. Everybody good? Questions?",
    "start": "1488490",
    "end": "1494310"
  },
  {
    "text": " Great. So now let's do something\na little more parallel.",
    "start": "1494310",
    "end": "1505590"
  },
  {
    "start": "1495000",
    "end": "1604000"
  },
  {
    "text": "Let's make both loops\nbe parallel. So here we have a cilk_for loop\nhere, and then another",
    "start": "1505590",
    "end": "1512510"
  },
  {
    "text": "cilk_for loop on the interior.  And let's see what\nwe get here.",
    "start": "1512510",
    "end": "1518480"
  },
  {
    "text": "So what's the work for this? AUDIENCE: n squared. CHARLES LEISERSON:\nYeah, n squared. That's not going to change.",
    "start": "1518480",
    "end": "1525230"
  },
  {
    "text": "That's not going to change.  What's the span?",
    "start": "1525230",
    "end": "1530900"
  },
  {
    "text": " AUDIENCE: log n.",
    "start": "1530900",
    "end": "1537990"
  },
  {
    "text": "CHARLES LEISERSON:\nYeah, log n. So it's log n because the span\nof the outer control loop is",
    "start": "1537990",
    "end": "1544580"
  },
  {
    "text": "going to add log n. The max span of the inner\ncontrol loop, well, it's going",
    "start": "1544580",
    "end": "1550750"
  },
  {
    "text": "from log of 1 up to log of i,\nbut the maximums of those is",
    "start": "1550750",
    "end": "1558850"
  },
  {
    "text": "going to be proportional\nto log n because it's not regular.",
    "start": "1558850",
    "end": "1565419"
  },
  {
    "text": "And the span of the body now\nis going to be order 1. And so we add the logs because\nthose things are in series.",
    "start": "1565420",
    "end": "1576470"
  },
  {
    "text": "We don't multiply them.  What we're doing is\nwe're looking at,",
    "start": "1576470",
    "end": "1582310"
  },
  {
    "text": "what's the worst case? The worst case is I have to do\nthe control for this, plus the control for this, plus the worst\niteration here, which in",
    "start": "1582310",
    "end": "1590230"
  },
  {
    "text": "this case is just order one. So the total is order log n. That can be confusing for\npeople, why it is that we add",
    "start": "1590230",
    "end": "1598809"
  },
  {
    "text": "here rather than multiply\nor do something else.",
    "start": "1598810",
    "end": "1605210"
  },
  {
    "start": "1604000",
    "end": "1759000"
  },
  {
    "text": "So let me pause here\nfor some questions if people have questions.",
    "start": "1605210",
    "end": "1611020"
  },
  {
    "text": "Everybody with us? Anybody want clarification or\nmake a point that would lead to clarification?",
    "start": "1611020",
    "end": "1616800"
  },
  {
    "text": " Yes, question. AUDIENCE: If you were going to\ndraw a tree like the previous",
    "start": "1616800",
    "end": "1622989"
  },
  {
    "text": "slide, what would\nit look like? ",
    "start": "1622989",
    "end": "1629670"
  },
  {
    "text": "CHARLES LEISERSON: Let's see. I had wanted to do that and\nit got out of control. ",
    "start": "1629670",
    "end": "1637510"
  },
  {
    "text": "So what it would look like is if\nwe go back to the previous slide, it basically would look\nlike this, except where each",
    "start": "1637510",
    "end": "1645549"
  },
  {
    "text": "one of these guys is replaced by\na tree that looks like this with as many leaves as the\nnumber here indicates.",
    "start": "1645550",
    "end": "1658899"
  },
  {
    "text": "So once again, this would be the\none with the longest span because this would be log\nof the largest number.",
    "start": "1658900",
    "end": "1664990"
  },
  {
    "text": "But basically, each one of these\nwould be a tree that came from this. Is that clear?",
    "start": "1664990",
    "end": "1670200"
  },
  {
    "text": "That's a great question. Anybody else have\nas illuminating questions as those? Everybody understand that\nexplanation, what the tree",
    "start": "1670200",
    "end": "1677630"
  },
  {
    "text": "would look like? OK, good. ",
    "start": "1677630",
    "end": "1687419"
  },
  {
    "text": "Get So the parallelism here is\nn squared over log n.",
    "start": "1687420",
    "end": "1695022"
  },
  {
    "text": "Now it's tempting, when you do\nparallel programming, to say therefore, this is better\nparallel code.",
    "start": "1695022",
    "end": "1700160"
  },
  {
    "text": " And the reason is, well, it does\nasymptotically have more",
    "start": "1700160",
    "end": "1706759"
  },
  {
    "text": "parallelism. But generally when you're\nprogramming, you're not trying to get the most parallelism.",
    "start": "1706760",
    "end": "1713120"
  },
  {
    "text": "What you're trying to do is get\nsufficient parallelism. So if n is sufficiently large,\nit's going to be way more--",
    "start": "1713120",
    "end": "1723470"
  },
  {
    "text": "if n is a million-- which is typical problem size\nfor a loop, for example, for a big loop, or even if it's a\nfew thousand or whatever--",
    "start": "1723470",
    "end": "1731180"
  },
  {
    "text": "it may be just fine to have\nparallelism on the order of 1,000, which is what the\nfirst one gives you.",
    "start": "1731180",
    "end": "1740720"
  },
  {
    "text": "So 1,000 iterations is generally\na small number of iterations. So 1,000 by 1,000 matrix\nis going to generate",
    "start": "1740720",
    "end": "1748150"
  },
  {
    "text": "parallelism of 1,000. Here, we're going to get a\nparallelism of 1 million divided by about 20, log of\n10 or 20, so like 100,000.",
    "start": "1748150",
    "end": "1758010"
  },
  {
    "text": "But if I have 1,000 by 1,000\nmatrix, the difference between",
    "start": "1758010",
    "end": "1768520"
  },
  {
    "start": "1759000",
    "end": "1850000"
  },
  {
    "text": "having parallelism of 1,000 and\nparallelism of 100,000, when I'm running on 100 cores,\nlet's say, it doesn't matter.",
    "start": "1768520",
    "end": "1778440"
  },
  {
    "text": "Up to 100 cores, it\ndoesn't matter. And in fact, running this on\n100 cores, that's really a",
    "start": "1778440",
    "end": "1783540"
  },
  {
    "text": "tiny problem compared to\nthe amount of memory you're going to get.",
    "start": "1783540",
    "end": "1788670"
  },
  {
    "text": "1,000 by 1,000 matrix is tiny\nwhen it comes to the size of",
    "start": "1788670",
    "end": "1795840"
  },
  {
    "text": "memory that you're going to have\naccess to and so forth. So for big problems and so forth\nyou really want to look at this and say, of things that\nhave ample parallelism,",
    "start": "1795840",
    "end": "1808650"
  },
  {
    "text": "which ones really are going to\ngive me the best bang for the buck for reasonable\nmachine sizes?",
    "start": "1808650",
    "end": "1815070"
  },
  {
    "text": " That's different from\nthings like work or",
    "start": "1815070",
    "end": "1820950"
  },
  {
    "text": "serial running time. Usually less running\ntime is better, and it's always better.",
    "start": "1820950",
    "end": "1827970"
  },
  {
    "text": "But here parallelism-- yes, it's good to minimize your\nspan, but you don't have",
    "start": "1827970",
    "end": "1835150"
  },
  {
    "text": "to minimize it extremely. You just have to get it small\nenough, whereas the work term,",
    "start": "1835150",
    "end": "1843220"
  },
  {
    "text": "that you really want to\nminimize, because that's what you're going to have to\ndo, even in a serial implementation.",
    "start": "1843220",
    "end": "1848420"
  },
  {
    "text": "Question. AUDIENCE: So are you\nsuggesting that the other code was OK?",
    "start": "1848420",
    "end": "1855799"
  },
  {
    "start": "1850000",
    "end": "2221000"
  },
  {
    "text": "CHARLES LEISERSON: We're going\nto look a little bit closer at the issue of overheads.",
    "start": "1855800",
    "end": "1862210"
  },
  {
    "text": "We're now going to take a look\nat what's the difference between these two codes? We'll come back to\nthat in a minute.",
    "start": "1862210",
    "end": "1868320"
  },
  {
    "text": "The way I want to do it is take\na look at the issue of overheads with a simpler\nexample, where we can see",
    "start": "1868320",
    "end": "1876590"
  },
  {
    "text": "what's really going on. So here, what I've done is\nI've got a loop that is",
    "start": "1876590",
    "end": "1882850"
  },
  {
    "text": "basically just doing\nvector addition. It's adding for i equals\n0 to n minus 1, add b",
    "start": "1882850",
    "end": "1892110"
  },
  {
    "text": "of i into a of i.  Pretty simple code, and we\nwant to make that be a",
    "start": "1892110",
    "end": "1898020"
  },
  {
    "text": "parallel loop. So I get a recursion tree that\nlooks like this, where I have",
    "start": "1898020",
    "end": "1904290"
  },
  {
    "text": "constant work at every\nstep there. And of course, the\nwork is order n,",
    "start": "1904290",
    "end": "1909460"
  },
  {
    "text": "because I've got n leaves. And the number of internal\nnodes, the control, is all",
    "start": "1909460",
    "end": "1915670"
  },
  {
    "text": "constant size strands there. So this is all just\norder n for work. And the span is basically log\nn, as we've seen, by going",
    "start": "1915670",
    "end": "1923830"
  },
  {
    "text": "down one of these paths,\nfor example. And so the parallelism for this\nis order n over log n.",
    "start": "1923830",
    "end": "1931000"
  },
  {
    "text": "So a very simple problem. But now let's take a look more\nclosely at the overheads here.",
    "start": "1931000",
    "end": "1937280"
  },
  {
    "text": "So the problem is that\nthis work term contains substantial overhead.",
    "start": "1937280",
    "end": "1942570"
  },
  {
    "text": "In other words, if I really was\ndoing that, if I hadn't coarsened the recursion at all\nin the implementation of",
    "start": "1942570",
    "end": "1949159"
  },
  {
    "text": "cilk_for, if the developers\nhadn't done that, then I've got a function call, I've got\nn function calls here for",
    "start": "1949160",
    "end": "1957210"
  },
  {
    "text": "doing a single addition of\nvalues at the leaves.",
    "start": "1957210",
    "end": "1963000"
  },
  {
    "text": "I've got n minus one of these\nguys, that's approximately n, and I've got n of these guys.",
    "start": "1963000",
    "end": "1968940"
  },
  {
    "text": "And which are bigger, these\nguys or these guys? ",
    "start": "1968940",
    "end": "1974540"
  },
  {
    "text": "These guys are way bigger. They've got a function\ncall in there. This guy right here\njust has what?",
    "start": "1974540",
    "end": "1979590"
  },
  {
    "text": "One floating point addition. And so if I really was doing my\ndivide and conquer down to",
    "start": "1979590",
    "end": "1986530"
  },
  {
    "text": "a single element, this would be\nway slower on one processor",
    "start": "1986530",
    "end": "1993230"
  },
  {
    "text": "than if I just ran it\nwith a for loop. Because if I do a for loop, it's\njust going to go through, and the overhead it has is\nincrementing i and testing for",
    "start": "1993230",
    "end": "2004440"
  },
  {
    "text": "termination. That's it. And of course, that's a\npredictable branch, because it",
    "start": "2004440",
    "end": "2010130"
  },
  {
    "text": "almost never terminates until it\nactually terminates, and so that's exactly the sort of thing\nthat's going to have a",
    "start": "2010130",
    "end": "2016149"
  },
  {
    "text": "really, really tight loop with\nvery few instructions. But in the parallel\nimplementation, there's going to be this function call\noverhead everywhere.",
    "start": "2016150",
    "end": "2024590"
  },
  {
    "text": "And so therefore, this cilk_for\nloop in principle would not be as efficient. It actually is, but we're going\nto explain why it is,",
    "start": "2024590",
    "end": "2032290"
  },
  {
    "text": "what goes on in the runtime\nsystem, to understand that. So here's the idea, and you can",
    "start": "2032290",
    "end": "2040290"
  },
  {
    "text": "control this with a pragma. So a pragma is a statement\nto the compiler",
    "start": "2040290",
    "end": "2046200"
  },
  {
    "text": "that gives it a hint. And here, the pragma says, you\ncan name a grain size and give",
    "start": "2046200",
    "end": "2052879"
  },
  {
    "text": "it a value of g. And what that says is rather\nthan just doing one element",
    "start": "2052880",
    "end": "2059000"
  },
  {
    "text": "when you get down to the bottom\nhere, do g elements in a for loop when you get\ndown to the bottom.",
    "start": "2059000",
    "end": "2066750"
  },
  {
    "text": "And that way, you halt the\nrecursion earlier. You have fewer of these\ninternal nodes.",
    "start": "2066750",
    "end": "2072569"
  },
  {
    "text": "And if you make the grain size\nsufficiently large, the cost of the recursion at the top\nyou won't be able to see.",
    "start": "2072570",
    "end": "2080600"
  },
  {
    "text": "So let's analyze what happens\nwhen we do this. So we can understand this\nvis a vis this equation.",
    "start": "2080600",
    "end": "2089190"
  },
  {
    "text": "So the idea here is, if I look\nat my work, imagine that t",
    "start": "2089190",
    "end": "2094379"
  },
  {
    "text": "iter is the time for iteration\nof one iteration of the loop, basic time for one iteration\nof the loop.",
    "start": "2094380",
    "end": "2100490"
  },
  {
    "text": "So the amount of work that I\nhave to do is n times the time for the iterations\nof the loop.",
    "start": "2100490",
    "end": "2106580"
  },
  {
    "text": "And then depending upon my grain\nsize, I've got to do things having to do with the\ninternal nodes, and there's",
    "start": "2106580",
    "end": "2113220"
  },
  {
    "text": "basically going to be n over g\nof those, times the time for a",
    "start": "2113220",
    "end": "2120180"
  },
  {
    "text": "spawn, which is I'm saying is\nthe time to execute one of these things.",
    "start": "2120180",
    "end": "2126110"
  },
  {
    "text": "So if these are batched into\ngroups of g, then there are n over g such leaves.",
    "start": "2126110",
    "end": "2132559"
  },
  {
    "text": "There's a minus 1 in here,\nbut it doesn't matter. It's basically n over\ng times the time for",
    "start": "2132560",
    "end": "2139250"
  },
  {
    "text": "the internal nodes. So everybody see where\nI'm getting this? So I'm trying to account for\nthe constants in the",
    "start": "2139250",
    "end": "2144820"
  },
  {
    "text": "implementation. People follow where\nI'm getting this? Ask questions. I see a couple of people who are\nsort of going, not sure I",
    "start": "2144820",
    "end": "2153220"
  },
  {
    "text": "understand.  Yes?",
    "start": "2153220",
    "end": "2158260"
  },
  {
    "text": "AUDIENCE: The constants\n[INAUDIBLE]. CHARLES LEISERSON: Yes. So basically, the constants are\nthese t iter and t spawn.",
    "start": "2158260",
    "end": "2165940"
  },
  {
    "text": "So t spawn is the time to\nexecute all that mess. t iter is the time to execute\none iteration within here.",
    "start": "2165940",
    "end": "2175250"
  },
  {
    "text": "I'm doing, in this\ncase, g of them. So I have n over g leaves, but\neach one is doing g, so it's n",
    "start": "2175250",
    "end": "2182430"
  },
  {
    "text": "over g times g, which is a total\nof n iterations, which makes sense. I should be doing n\niterations if I'm",
    "start": "2182430",
    "end": "2188980"
  },
  {
    "text": "adding two vectors here. So that's accounting for all\nthe work in these guys.",
    "start": "2188980",
    "end": "2194200"
  },
  {
    "text": "Then in addition, I've got all\nof the work for all the spawning, which is n over\ng times t spawn.",
    "start": "2194200",
    "end": "2201790"
  },
  {
    "text": "And as I say, you can play with\nthis yourself, play with grain size yourself, by just\nsticking in different grain size directives.",
    "start": "2201790",
    "end": "2207829"
  },
  {
    "text": "Otherwise it turns out that the\ncilk runtime system will pick what it deems to be\na good grain size.",
    "start": "2207830",
    "end": "2216930"
  },
  {
    "text": "And it usually does a good\njob, except sometimes.",
    "start": "2216930",
    "end": "2222079"
  },
  {
    "start": "2221000",
    "end": "2303000"
  },
  {
    "text": "And that's why there's\na parameter here. So if there's a parameter\nthere, you can get rid of that.",
    "start": "2222080",
    "end": "2230160"
  },
  {
    "text": "Yes?  AUDIENCE: Is the pragma\nsomething that is enforced, or",
    "start": "2230160",
    "end": "2236086"
  },
  {
    "text": "is it something that\nsays, hey-- CHARLES LEISERSON:\nIt's a hint. AUDIENCE: It's a hint. CHARLES LEISERSON:\nYes, it's a hint.",
    "start": "2236086",
    "end": "2241885"
  },
  {
    "text": "In other words, compiler\ncould ignore it. [? AUDIENCE: The compiler is ?]\ngoing to be like, oh, that's the total [INAUDIBLE]",
    "start": "2241885",
    "end": "2246974"
  },
  {
    "text": "constant. CHARLES LEISERSON: It's supposed\nto be something that gives a hint for performance\nreasons but does not affect",
    "start": "2246975",
    "end": "2252240"
  },
  {
    "text": "the correctness of\nthe program. So the program is going to\nbe doing the same thing",
    "start": "2252240",
    "end": "2257650"
  },
  {
    "text": "regardless. The question is, here's a hint\nto the compiler and the runtime system.",
    "start": "2257650",
    "end": "2264020"
  },
  {
    "text": "And so then it's picked at-- yeah?",
    "start": "2264020",
    "end": "2269268"
  },
  {
    "text": "AUDIENCE: My question is, so\nthere's these cases where you say that the runtime system\nfails to find an appropriate",
    "start": "2269268",
    "end": "2276460"
  },
  {
    "text": "value for that [INAUDIBLE]. I mean, basically, chooses\none that's not as good. If you put a pragma on it, will\nthe runtime system choose",
    "start": "2276460",
    "end": "2283211"
  },
  {
    "text": "the one that you give it,\nor still choose-- CHARLES LEISERSON: No,\nif you give it, the runtime system will-- in the current implementation,\nit always picks whatever you",
    "start": "2283211",
    "end": "2291040"
  },
  {
    "text": "say is here. And that can be an expression. You can evaluate something\nthere. It's not just a constant.",
    "start": "2291040",
    "end": "2296540"
  },
  {
    "text": "It could be maximum of\nthis and that times whatever, et cetera.",
    "start": "2296540",
    "end": "2302655"
  },
  {
    "text": "Is that good? So this is a description\nof the work. Now let's get a description\nwith the constants",
    "start": "2302655",
    "end": "2310400"
  },
  {
    "start": "2303000",
    "end": "2575000"
  },
  {
    "text": "again of the span. So what is going to be the\nconstants for the span?",
    "start": "2310400",
    "end": "2315825"
  },
  {
    "text": " Well, I'm executing this part\nin here now serially.",
    "start": "2315825",
    "end": "2323275"
  },
  {
    "text": " So for the span part, we're\nbasically going to go down on",
    "start": "2323275",
    "end": "2329120"
  },
  {
    "text": "one of these paths and back up\nI'm not sure which one, but they're basically all\nfairly symmetric.",
    "start": "2329120",
    "end": "2335330"
  },
  {
    "text": "But then when I get\nto the leaf, I'm executing the leaf serially. So I'm going to have whatever\nthe cost is, g times the time",
    "start": "2335330",
    "end": "2343790"
  },
  {
    "text": "per iteration, is going to be\nexecuted serially, plus now log of n over g--",
    "start": "2343790",
    "end": "2352850"
  },
  {
    "text": "n over g is the number of\nthings I have here-- times the cost of the\nspawn, basically. ",
    "start": "2352850",
    "end": "2361152"
  },
  {
    "text": "Does that make sense?  So the idea is, what do we want\nto have here if I want a",
    "start": "2361152",
    "end": "2368270"
  },
  {
    "text": "good parallel code? We would like the work to\nbe as small as possible. How do I make the work small?",
    "start": "2368270",
    "end": "2374530"
  },
  {
    "text": " How can I set g to make\nthe work small?",
    "start": "2374530",
    "end": "2382758"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. CHARLES LEISERSON: Make g-- AUDIENCE: Square root of n. CHARLES LEISERSON: Well,\nmake g big or little?",
    "start": "2382758",
    "end": "2391090"
  },
  {
    "text": "If you want this term to be\nsmall, you want g to be big.",
    "start": "2391090",
    "end": "2398770"
  },
  {
    "text": "But we also want to have\na lot of parallelism. So I want this term\nto be what?",
    "start": "2398770",
    "end": "2405529"
  },
  {
    "text": "Small, which means I need\nto make g what? Well, we got an n over g here,\nbut it's in a log.",
    "start": "2405530",
    "end": "2414366"
  },
  {
    "text": "It's minus log. So really, to get this small,\nI want g to be small.",
    "start": "2414366",
    "end": "2420881"
  },
  {
    "text": "So I have tension, trade off. I have trade off.",
    "start": "2420882",
    "end": "2426089"
  },
  {
    "text": "So let's analyze this\na little bit.  Essentially, if I look at this,\nI want g to be bigger--",
    "start": "2426090",
    "end": "2434464"
  },
  {
    "start": "2434465",
    "end": "2441860"
  },
  {
    "text": "from this one I want\ng to be small. But here, what I would like is\nto make it so that this term",
    "start": "2441860",
    "end": "2447170"
  },
  {
    "text": "dominates this term.  If the first term here dominates\nthe second term,",
    "start": "2447170",
    "end": "2456470"
  },
  {
    "text": "then the work is going to be\nthe same as if I did an ordinary for loop to within\na few percent.",
    "start": "2456470",
    "end": "2465450"
  },
  {
    "text": "So therefore, I want t span\nover t iter, if I take the ratio of these things, I want\ng to be bigger than the time",
    "start": "2465450",
    "end": "2474110"
  },
  {
    "text": "to spawn divided by the\ntime to iterate. If I get it much bigger than\nthat, then this term will be",
    "start": "2474110",
    "end": "2480960"
  },
  {
    "text": "much bigger than that term\nand I don't have to worry about this term. So I want it to be much bigger,\nbut I want to be as",
    "start": "2480960",
    "end": "2489660"
  },
  {
    "text": "small as possible. There's no point in making it\nmuch bigger than that which",
    "start": "2489660",
    "end": "2495630"
  },
  {
    "text": "causes this term to essentially\nbe wiped out. People follow that? ",
    "start": "2495630",
    "end": "2504830"
  },
  {
    "text": "So basically, the idea is we\npick a grain size that's large but not too large, is what you\ngenerally want to do, so that",
    "start": "2504830",
    "end": "2513180"
  },
  {
    "text": "you have enough parallelism,\nbut you don't. The way that the runtime system\ndoes it is it has a",
    "start": "2513180",
    "end": "2519690"
  },
  {
    "text": "somewhat complicated heuristic,\nbut it actually looks to see how many processors\nyou're running on.",
    "start": "2519690",
    "end": "2526660"
  },
  {
    "text": "And it uses a heuristic that\nsays, let's make sure there's at least parallelism 10 times\nmore than the number of",
    "start": "2526660",
    "end": "2533550"
  },
  {
    "text": "processors. But there's no point in having\nmore iterations than like 500 or something, because at 500\niterations, you can't see the",
    "start": "2533550",
    "end": "2543350"
  },
  {
    "text": "spawn overhead regardless. So basically, it uses a formula\nkind of that nature to",
    "start": "2543350",
    "end": "2549900"
  },
  {
    "text": "pick this automatically. But you're free to pick\nthis yourself. But you can see the point is\nthat although it's doing",
    "start": "2549900",
    "end": "2557539"
  },
  {
    "text": "divide and conquer, you do this\nissue of coarsening and you do want to make sure that\nyou have enough work to do in",
    "start": "2557540",
    "end": "2566760"
  },
  {
    "text": "any of the leaves of\nthe computation. And as I say, usually\nit'll guess right. But if you have trouble with\nthat, you have a parameter you",
    "start": "2566760",
    "end": "2574550"
  },
  {
    "text": "can play with. Let's take a look at another\nimplementation just to try to",
    "start": "2574550",
    "end": "2579990"
  },
  {
    "start": "2575000",
    "end": "3108000"
  },
  {
    "text": "understand this issue.  Suppose I'm going to\ndo a vector add.",
    "start": "2579990",
    "end": "2586100"
  },
  {
    "text": "So here I have a vector add\nof two arrays, where I'm basically saying ai gets the\nvalue of b added into it.",
    "start": "2586100",
    "end": "2597750"
  },
  {
    "text": "That's kind of the code\nwe had before. But now, what I want to do is\nI'm going to implement a",
    "start": "2597750",
    "end": "2605440"
  },
  {
    "text": "vector add using cilk spawn. ",
    "start": "2605440",
    "end": "2610560"
  },
  {
    "text": "So rather than using a cilk_for\nloop, I'm going to parallelize this loop by\nhand using cilk spawn.",
    "start": "2610560",
    "end": "2617660"
  },
  {
    "text": "What I'm going to do is I'm\ngoing to say for j equals 0 up to-- and I'm going to\njump by whatever my",
    "start": "2617660",
    "end": "2622970"
  },
  {
    "text": "grain size is here-- and spawn off the addition of\nthings of size, essentially,",
    "start": "2622970",
    "end": "2630610"
  },
  {
    "text": "g, unless I get close to\nthe end of the array. But basically, I'm always\nspawning off the next g",
    "start": "2630610",
    "end": "2637440"
  },
  {
    "text": "iterations to do that\nin parallel. And then I sync all\nthese spawns.",
    "start": "2637440",
    "end": "2643280"
  },
  {
    "text": "So everybody understand\nthe code? I see nods. I want to see everybody nod,\nactually, when I do this.",
    "start": "2643280",
    "end": "2649740"
  },
  {
    "text": "Otherwise what happens is I see\nthree people nod, and I assume that people\nare nodding. Because if you don't do it, you\ncan shake your head, and I",
    "start": "2649740",
    "end": "2655760"
  },
  {
    "text": "promise none of your friends\nwill see that you're shaking your head.",
    "start": "2655760",
    "end": "2661280"
  },
  {
    "text": "And since the TAs are doing the\ngrading and they're facing this way, they won't\nsee either.",
    "start": "2661280",
    "end": "2666450"
  },
  {
    "text": "And so it's perfectly safe to\nlet me know, and that way I can make sure you understand. ",
    "start": "2666450",
    "end": "2673589"
  },
  {
    "text": "So everybody understand\nwhat this does? OK, so I see a few more. No.",
    "start": "2673590",
    "end": "2678820"
  },
  {
    "text": "OK, question? Do you have a question, or\nshould I just explain again? So this is basically doing a\nvector add of b into a, of n",
    "start": "2678820",
    "end": "2689490"
  },
  {
    "text": "iterations here. And we're going to call it here,\nwhen I do a vector add,",
    "start": "2689490",
    "end": "2694910"
  },
  {
    "text": "of basically g iterations. So what it's doing is it's going\nto take my array of size",
    "start": "2694910",
    "end": "2700670"
  },
  {
    "text": "n, bust it into chunks of size\ng, and spawn off the first one, spawn off the second one,\nspawn off the third one, each",
    "start": "2700670",
    "end": "2708230"
  },
  {
    "text": "one to do g iterations. That make sense?",
    "start": "2708230",
    "end": "2713340"
  },
  {
    "text": "We'll see it. So here's sort of the\ninstruction stream for the code here.",
    "start": "2713340",
    "end": "2718980"
  },
  {
    "text": "So basically, it says here is\none, we spawn off something of size g, then we go on, we spawn\noff something else of",
    "start": "2718980",
    "end": "2727370"
  },
  {
    "text": "size g, et cetera. We keep going up there until\nwe hit the cilk sync.",
    "start": "2727370",
    "end": "2732740"
  },
  {
    "text": "That make sense? Each of these is doing a vector\nadd of size g using",
    "start": "2732740",
    "end": "2738609"
  },
  {
    "text": "this serial routine.  So let's analyze this to\nunderstand the efficiency of",
    "start": "2738610",
    "end": "2746420"
  },
  {
    "text": "this type of looping\nstructure. So let's assume for this\nanalysis that g equals 1, to",
    "start": "2746420",
    "end": "2752910"
  },
  {
    "text": "make it easy, so we don't\nhave to worry about it. So we're simply spawning off\none thing here, one thing here, one iteration here,\nall the way to the end.",
    "start": "2752910",
    "end": "2761760"
  },
  {
    "text": "So what is the work for this, if\nI spawn off things of size one, asymptotic work?",
    "start": "2761760",
    "end": "2769370"
  },
  {
    "text": "It's order n, because I've got\nn leaves, and I've got n guys that I'm spawning off. So it's order n.",
    "start": "2769370",
    "end": "2775720"
  },
  {
    "text": "What's the span? AUDIENCE: [INAUDIBLE].",
    "start": "2775720",
    "end": "2780800"
  },
  {
    "text": "CHARLES LEISERSON: Yeah, it's\nalso order n, because the",
    "start": "2780800",
    "end": "2787130"
  },
  {
    "text": "critical path goes something\nlike brrrup, brrrup, brrrup. ",
    "start": "2787130",
    "end": "2793620"
  },
  {
    "text": "That's order n length. It's not this, because\nthat's only order one length, all those.",
    "start": "2793620",
    "end": "2798820"
  },
  {
    "text": "The longest path is order n. So that says the parallelism\nis order one.",
    "start": "2798820",
    "end": "2809220"
  },
  {
    "text": "Conclusion, at least with grain\nsize one, this is a really bad way to implement\na parallel loop.",
    "start": "2809220",
    "end": "2817950"
  },
  {
    "text": "However, I guarantee, it may\nnot be the people in this room, but some fraction of\nstudents in this class will",
    "start": "2817950",
    "end": "2827130"
  },
  {
    "text": "write this rather than\ndoing a cilk for. Bad idea.",
    "start": "2827130",
    "end": "2835440"
  },
  {
    "text": "Bad idea. Generally, bad idea. Question?",
    "start": "2835440",
    "end": "2840862"
  },
  {
    "text": "AUDIENCE: Do you think you could\nfind a constant factor, not just [INAUDIBLE]? ",
    "start": "2840862",
    "end": "2846164"
  },
  {
    "text": "CHARLES LEISERSON: Well here,\nactually, with grain size one, this is really bad, because\nI've got this overhead of",
    "start": "2846164",
    "end": "2851960"
  },
  {
    "text": "doing a spawn, and then I'm\nonly doing one iteration. So the ideal thing would be that\nI really am only paying",
    "start": "2851960",
    "end": "2858250"
  },
  {
    "text": "for the leaves, and the internal\nnodes, I don't have to pay anything for. Yeah, Eric?",
    "start": "2858250",
    "end": "2864182"
  },
  {
    "text": "AUDIENCE: Shouldn't there\nbe a sort of keyword in the b add too? CHARLES LEISERSON:\nIn the where? AUDIENCE: In the b add? CHARLES LEISERSON: No,\nthat's serial.",
    "start": "2864182",
    "end": "2869470"
  },
  {
    "text": "That's a serial code. AUDIENCE: No, but if you were\ngoing to call it with cilk spawn, don't you have\nto declare it cilk?",
    "start": "2869470",
    "end": "2876140"
  },
  {
    "text": "Is that not the case? CHARLES LEISERSON: No. AUDIENCE: Never mind. ",
    "start": "2876140",
    "end": "2882820"
  },
  {
    "text": "CHARLES LEISERSON:\nYes, question. AUDIENCE: If g is [INAUDIBLE],\nisn't that good enough? ",
    "start": "2882820",
    "end": "2888420"
  },
  {
    "text": "CHARLES LEISERSON: Yeah,\nso let's take a look. That's actually the\nnext slide.  This is basically, this we\ncall puny parallelism.",
    "start": "2888420",
    "end": "2897036"
  },
  {
    "text": "We don't like puny\nparallelism. It doesn't have to\nbe spectacular.",
    "start": "2897036",
    "end": "2902470"
  },
  {
    "text": "It has to be good enough. And this is not good enough\nfor most applications.",
    "start": "2902470",
    "end": "2908454"
  },
  {
    "text": " So here's another\nimplementation.",
    "start": "2908455",
    "end": "2914250"
  },
  {
    "text": "Here's another way\nof doing it. Now let's analyze it where\nwe have control over g.",
    "start": "2914250",
    "end": "2920710"
  },
  {
    "text": "So we'll analyze it in terms\nof g, and then see whether there's a setting for which\nthis make sense.",
    "start": "2920710",
    "end": "2927270"
  },
  {
    "text": "So if I analyze it in terms of\ng, now I have to do a little bit more careful\nanalysis here. How much work do I have here\nin terms of n and g?",
    "start": "2927270",
    "end": "2937798"
  },
  {
    "text": "AUDIENCE: It's the same. CHARLES LEISERSON: Yeah,\nthe work is still asymptotically order n. ",
    "start": "2937798",
    "end": "2945220"
  },
  {
    "text": "Because I always have n work\nin the leaves, even if I do more iterations here. What increasing g does is\nit shrinks this, right?",
    "start": "2945220",
    "end": "2954090"
  },
  {
    "text": "It shrinks this. The span for this is what? ",
    "start": "2954091",
    "end": "2963240"
  },
  {
    "text": "So I heard somebody say it. n over g plus g. ",
    "start": "2963240",
    "end": "2970560"
  },
  {
    "text": "And it corresponds\nto this path.  So this is the n over\ng part up here, and",
    "start": "2970560",
    "end": "2977660"
  },
  {
    "text": "this is the plus g.  So what we want to do to\nminimize this, is we can",
    "start": "2977660",
    "end": "2987060"
  },
  {
    "text": "minimize this. This has the smallest value\nwhen these two terms are equal, which you can either know\nas a basic fact of the",
    "start": "2987060",
    "end": "2995369"
  },
  {
    "text": "summation of these kinds of\nthings, or you could take derivatives and so forth.",
    "start": "2995370",
    "end": "3002210"
  },
  {
    "text": "Or you can just eyeball it and\nsay, gee, if g is bigger than square root of n, then this is\ngoing to be the dominant, and",
    "start": "3002210",
    "end": "3008710"
  },
  {
    "text": "if g is smaller than square root\nof n, then this is going to be dominant. And so when they're equal, that\nsounds like about when it",
    "start": "3008710",
    "end": "3015130"
  },
  {
    "text": "should be the smallest,\nwhich is true. So we pick it to be about\nsquare root of n, to",
    "start": "3015130",
    "end": "3020270"
  },
  {
    "text": "minimize the span. Since g, I don't have anything\nto minimize here.",
    "start": "3020270",
    "end": "3025619"
  },
  {
    "text": "So pick it around square root of\nn, then the span is around square root of n.",
    "start": "3025620",
    "end": "3031520"
  },
  {
    "text": "And so then the parallelism\nis order square root of n.",
    "start": "3031520",
    "end": "3037680"
  },
  {
    "text": "So that's pretty good. So that's not bad. So for something that's a big\narray, array of size 1",
    "start": "3037680",
    "end": "3042950"
  },
  {
    "text": "million, parallelism\nmight be 1,000. That might be just hunky dory.",
    "start": "3042950",
    "end": "3050300"
  },
  {
    "text": "Question. What's that? AUDIENCE: I don't see where-- CHARLES LEISERSON: We've\npicked g to be equal to",
    "start": "3050300",
    "end": "3056170"
  },
  {
    "text": "square root of n. AUDIENCE: [INAUDIBLE] plus\nn over g, plus g. I don't see where [INAUDIBLE].",
    "start": "3056170",
    "end": "3062430"
  },
  {
    "text": "CHARLES LEISERSON: You don't\nsee where this g came from? This g comes from, because I'm\ndoing g iterations here.",
    "start": "3062430",
    "end": "3069540"
  },
  {
    "text": "So remember that these\nare now of size g. I'm doing g iterations\nin each leaf here, if I set g to be large.",
    "start": "3069540",
    "end": "3075860"
  },
  {
    "text": "So I'm doing n over g pieces\nhere, plus g iterations in my",
    "start": "3075860",
    "end": "3081960"
  },
  {
    "text": "[INAUDIBLE]. Is that clear? So the n over g is this part. This size here, this\nis not one.",
    "start": "3081960",
    "end": "3088710"
  },
  {
    "text": "This has g iterations in it. So the total span is\ng plus n over g. ",
    "start": "3088710",
    "end": "3097369"
  },
  {
    "text": "Any other questions\nabout this? So basically, I get order\nsquare root of n. ",
    "start": "3097370",
    "end": "3104270"
  },
  {
    "text": "And so this is not necessarily a\nbad way of doing it, but the",
    "start": "3104270",
    "end": "3109370"
  },
  {
    "start": "3108000",
    "end": "3160000"
  },
  {
    "text": "cilk for is a far more reliable\nway of making sure that you get the parallelism\nthan spawning things off one by one.",
    "start": "3109370",
    "end": "3115710"
  },
  {
    "text": "One of the things, by the way,\nin this, I've seen people write code where their first\ninstinct is to write something",
    "start": "3115710",
    "end": "3123370"
  },
  {
    "text": "like this, where this that\nthey're spawning off is only constant time. And they say, gee, I spawned\noff n things.",
    "start": "3123370",
    "end": "3131809"
  },
  {
    "text": "That's really parallel. When in fact, their parallelism\nis order one.",
    "start": "3131810",
    "end": "3138270"
  },
  {
    "text": "So it's really seductive to\nthink that you can get parallelism by this,\n[? right. ?]",
    "start": "3138270",
    "end": "3143880"
  },
  {
    "text": "It's much better to do divide\nand conquer, and cilk for does that for you automatically.",
    "start": "3143880",
    "end": "3149140"
  },
  {
    "text": "If you're going to do it by\nhand, sometimes you do want to do it by hand, then you probably\nwant to think more about divide and conquer to\ngenerate parallelism, because",
    "start": "3149140",
    "end": "3155900"
  },
  {
    "text": "you'll have a small span,\nthan doing many things one at a time. ",
    "start": "3155900",
    "end": "3161800"
  },
  {
    "start": "3160000",
    "end": "3371000"
  },
  {
    "text": "So here's some tips\nfor performance.",
    "start": "3161800",
    "end": "3167520"
  },
  {
    "text": "So you want to minimize the\nspan, so the parallelism is the work over the span.",
    "start": "3167520",
    "end": "3173470"
  },
  {
    "text": "So you want to minimize the span\nto maximize parallelism. And in general, you should try\nto generate something like 10",
    "start": "3173470",
    "end": "3180769"
  },
  {
    "text": "times more parallelism than\nprocessors, if you want to get near perfect linear speed-up. In other words, a parallel\nslackness of 10 or better is",
    "start": "3180770",
    "end": "3189200"
  },
  {
    "text": "usually adequate.  If you can get more, you're now\ntalking that you can get",
    "start": "3189200",
    "end": "3196190"
  },
  {
    "text": "more performance, but now you're\ngetting performance",
    "start": "3196190",
    "end": "3202720"
  },
  {
    "text": "increases in the range of\n5% or so, 5% to 10%, something like that.",
    "start": "3202720",
    "end": "3209890"
  },
  {
    "text": "Second thing is if you have\nplenty of parallelism, try to trade some of it off to\nreduce work overhead.",
    "start": "3209890",
    "end": "3216970"
  },
  {
    "text": "So this is a general case. This is what actually goes on\nunderneath in the cilk++",
    "start": "3216970",
    "end": "3222800"
  },
  {
    "text": "runtime system, is they are\ntrying to do this themselves. But you in your own code can\nplay exactly the same game.",
    "start": "3222800",
    "end": "3229640"
  },
  {
    "text": "Whenever you have a problem and\nit says, whoa, look at all this parallelism, think about\nways that you could reduce the",
    "start": "3229640",
    "end": "3235130"
  },
  {
    "text": "parallelism and get something\nback in the efficiency of the",
    "start": "3235130",
    "end": "3240140"
  },
  {
    "text": "work term, because the\nperformance in the end is going to be something like t1\nover p plus t infinity.",
    "start": "3240140",
    "end": "3248070"
  },
  {
    "text": "If t infinity is small, it's\nlike t1 over p, and so anything you save in the t1 term\nis saving you overall.",
    "start": "3248070",
    "end": "3256059"
  },
  {
    "text": "It's going to be a savings\nfor you overall. Use divide and conquer recursion\non parallel loops",
    "start": "3256060",
    "end": "3262200"
  },
  {
    "text": "rather than sprawling one small\nthing after another. In other words, do this\nnot this, generally.",
    "start": "3262200",
    "end": "3268930"
  },
  {
    "text": " And here's some more tips.",
    "start": "3268930",
    "end": "3276220"
  },
  {
    "text": "Another thing that can happen\nthat we looked at here was make sure that the amount\nof work you're doing is",
    "start": "3276220",
    "end": "3282300"
  },
  {
    "text": "reasonably large compared\nto the number of spawns. You could also say this is true\nwhen you do recursion for",
    "start": "3282300",
    "end": "3287950"
  },
  {
    "text": "function calls. Make sure if you're just in\nserial programming, you always want to make sure that the\namount of work you're doing is",
    "start": "3287950",
    "end": "3294180"
  },
  {
    "text": "small compared to the number of\nfunction calls are doing if you can, and that'll make\nthings go faster.",
    "start": "3294180",
    "end": "3300120"
  },
  {
    "text": "So same thing here, you want to\nhave a lot of work compared",
    "start": "3300120",
    "end": "3308050"
  },
  {
    "text": "to the total number of\nspawns that you're doing in your program. So spawns, by the way, in this\nsystem, are about three or",
    "start": "3308050",
    "end": "3314520"
  },
  {
    "text": "four times the cost of\na function call. They're sort of the same order\nof magnitude as a function",
    "start": "3314520",
    "end": "3322800"
  },
  {
    "text": "call, a little bit heavier\nthan a function call. So you can spawn pretty readily,\nas long as the total",
    "start": "3322800",
    "end": "3331960"
  },
  {
    "text": "number of spawns you're doing\nisn't dominating your work.",
    "start": "3331960",
    "end": "3337349"
  },
  {
    "text": "Generally parallelize outer\nloops as opposed to inner loops if you're forced\nto make a choice.",
    "start": "3337350",
    "end": "3343619"
  },
  {
    "text": "So it's always better to have\nan outer loop that runs in parallel rather than an inner\nloop that runs in parallel,",
    "start": "3343620",
    "end": "3351000"
  },
  {
    "text": "because when you do an inner\nloop that runs in parallel, you've got a lot of overhead\nto overcome.",
    "start": "3351000",
    "end": "3356590"
  },
  {
    "text": "But in an outer loop, you've got\nall of the inner loop to amortize against the cost of the\nspawns that are being used",
    "start": "3356590",
    "end": "3363930"
  },
  {
    "text": "to parallelize the outer loop. So you'll do many fewer spawns\nin the implementation.",
    "start": "3363930",
    "end": "3370195"
  },
  {
    "text": " Watch out for scheduling\noverheads. ",
    "start": "3370195",
    "end": "3378620"
  },
  {
    "start": "3371000",
    "end": "3453000"
  },
  {
    "text": "So if you do something\nlike this-- so here we're paralyzing an\ninner loop rather than an",
    "start": "3378620",
    "end": "3387310"
  },
  {
    "text": "outer loop. Now this turns out, it doesn't\nmatter which order we're going in or whatever.",
    "start": "3387310",
    "end": "3393000"
  },
  {
    "text": "It's generally not desirable to\ndo this because I'm paying scheduling overhead n times\nthrough this loop, whereas",
    "start": "3393000",
    "end": "3400230"
  },
  {
    "text": "here, I pay for scheduling\noverhead just twice. ",
    "start": "3400230",
    "end": "3406920"
  },
  {
    "text": "So is generally better, if I\nhave n pieces of work to do, rather than, in this case,\nparallelizing--",
    "start": "3406920",
    "end": "3412400"
  },
  {
    "text": " let me slow down here.",
    "start": "3412400",
    "end": "3417510"
  },
  {
    "text": "So let's look at what\nthis code does. This says, go for\ntwo iterations. ",
    "start": "3417510",
    "end": "3423740"
  },
  {
    "text": "Do something for which\nit is going to take n iterations for j.",
    "start": "3423740",
    "end": "3429840"
  },
  {
    "text": "So two iterations for i,\nn iterations for j. ",
    "start": "3429840",
    "end": "3435710"
  },
  {
    "text": "If you look at the parallelism\nof this, what is the parallelism of this assuming\nthat f is constant time? ",
    "start": "3435710",
    "end": "3443830"
  },
  {
    "text": "What's the parallelism\nof this code? ",
    "start": "3443830",
    "end": "3453460"
  },
  {
    "start": "3453000",
    "end": "3599000"
  },
  {
    "text": "Two. The parallelism of two, because\nI've got two things on the outer loop here,\nand then each is n.",
    "start": "3453460",
    "end": "3459930"
  },
  {
    "text": "So my span is essentially n. My work is like 2n, something\nlike that.",
    "start": "3459930",
    "end": "3466770"
  },
  {
    "text": "So it's got a parallelism\nof that, too. What's the parallelism\nof this code? ",
    "start": "3466770",
    "end": "3484970"
  },
  {
    "text": "What's the parallelism? It's not n, because I'm\nbasically going through this serially, the outer\nloop serially.",
    "start": "3484970",
    "end": "3490070"
  },
  {
    "start": "3490070",
    "end": "3498680"
  },
  {
    "text": "What's the theoretical\nparallelism of this? ",
    "start": "3498680",
    "end": "3504270"
  },
  {
    "text": "So for each iteration here,\nthe parallelism is two.",
    "start": "3504270",
    "end": "3509430"
  },
  {
    "text": "No, not n. It can't be n, because I'm\nbasically only parallelizing",
    "start": "3509430",
    "end": "3514980"
  },
  {
    "text": "two things, and I'm doing\nthem serially. ",
    "start": "3514980",
    "end": "3520462"
  },
  {
    "text": "The outer loop is going serially\nthrough the code and it's spawning off two things,\ntwo things, two things, two",
    "start": "3520462",
    "end": "3527480"
  },
  {
    "text": "things, two things. And waiting for them to be done,\ntwo things, wait for it to be done, two things, wait\nfor it to be done.",
    "start": "3527480",
    "end": "3532539"
  },
  {
    "text": "So the parallelism is two. These have the same\nparallelism. ",
    "start": "3532540",
    "end": "3538690"
  },
  {
    "text": "However if you run this, this\none will give you a speedup of two on two cores, very\nclose to it.",
    "start": "3538690",
    "end": "3547530"
  },
  {
    "text": "Because there's the scheduling\noverhead here, you've only paid once for the scheduling\noverhead, and then you're doing a whole bunch of stuff.",
    "start": "3547530",
    "end": "3554640"
  },
  {
    "text": "So remember, to schedule it,\nit's got to be migrated, it's got to be moved to another\nprocessor, et cetera.",
    "start": "3554640",
    "end": "3559910"
  },
  {
    "text": "This one, it's not even worth\nit probably to steal each of",
    "start": "3559910",
    "end": "3565410"
  },
  {
    "text": "these individual things. You're spawning off things that\nare so small, this may even have parallelism that's\nless than 1 in practice.",
    "start": "3565410",
    "end": "3573395"
  },
  {
    "text": "And if you look at the cilkview\ntool, this will show you a high burden parallelism. Because the cilkview tool, the\nburden parallelism tells you",
    "start": "3573395",
    "end": "3581450"
  },
  {
    "text": "what the overhead is from\nscheduling, as well as what",
    "start": "3581450",
    "end": "3586980"
  },
  {
    "text": "the actual parallelism is. And it recognizes that\noh, gee whiz. This thing really\nhas very small--",
    "start": "3586980",
    "end": "3593625"
  },
  {
    "start": "3593625",
    "end": "3600670"
  },
  {
    "text": "there's almost no\nwork in here. So you're trying to parallelize\nsomething where the work is so small, it's not\neven worth migrating it to",
    "start": "3600670",
    "end": "3606960"
  },
  {
    "text": "take advantage of it. So those are some tips.",
    "start": "3606960",
    "end": "3612740"
  },
  {
    "text": "Now let's go through and analyze\na bunch of algorithms reasonably quickly. We'll start with matrix\nmultiplication.",
    "start": "3612740",
    "end": "3621670"
  },
  {
    "text": "People seen this\nproblem before? ",
    "start": "3621670",
    "end": "3628400"
  },
  {
    "text": "Here's the matrix multiplication\nproblem. And let's assume for\nsimplicity that n",
    "start": "3628400",
    "end": "3633779"
  },
  {
    "text": "is a power of 2.  So basically, let's start out\nwith just our looping version.",
    "start": "3633780",
    "end": "3644250"
  },
  {
    "text": "In fact, this isn't even a very\ngood looping version, because I've got the order of\nthe loops wrong, I think.",
    "start": "3644250",
    "end": "3649339"
  },
  {
    "text": "But it is just illustrative. Basically let's parallelize\nthe outer two loops.",
    "start": "3649340",
    "end": "3655079"
  },
  {
    "text": "I can't parallelize\nthe inner loop. Why not? What happens if I tried to\nparallelize the inner loop",
    "start": "3655080",
    "end": "3660180"
  },
  {
    "text": "with a cilk_for in this\nimplementation? ",
    "start": "3660180",
    "end": "3667580"
  },
  {
    "text": "Why can't I just put\na cilk_for there? Yes, somebody said it. AUDIENCE: It does that in cij.",
    "start": "3667580",
    "end": "3674599"
  },
  {
    "text": "CHARLES LEISERSON: Yeah, we\nget a race condition. We have more than two things in\nparallel trying to update",
    "start": "3674600",
    "end": "3679980"
  },
  {
    "text": "the same cij, and we'll\nhave a race condition.",
    "start": "3679980",
    "end": "3685070"
  },
  {
    "text": "So always run cilkview to\ntell your performance. But always, always, run cilk\nscreen to tell whether or not",
    "start": "3685070",
    "end": "3693695"
  },
  {
    "text": "you've got races in your code.  So yeah, you'll have a race\ncondition if you try to",
    "start": "3693695",
    "end": "3700650"
  },
  {
    "text": "naively parallelize\nthe loop here. ",
    "start": "3700650",
    "end": "3706569"
  },
  {
    "text": "So the work of this is what? ",
    "start": "3706570",
    "end": "3713460"
  },
  {
    "text": "It's order n cubed, just three\nnested loops each going to n. What's the span of this?",
    "start": "3713460",
    "end": "3719340"
  },
  {
    "start": "3719340",
    "end": "3732180"
  },
  {
    "text": "What's the span of this? ",
    "start": "3732180",
    "end": "3740990"
  },
  {
    "text": "It's order n, because it's log\nn for this loop, log n for",
    "start": "3740990",
    "end": "3746900"
  },
  {
    "text": "this loop, plus the maximum\nof this, well, that's n. Log n plus log n plus\nn is order n.",
    "start": "3746900",
    "end": "3754860"
  },
  {
    "text": "So order n span, which says parallelism is order n squared.",
    "start": "3754860",
    "end": "3762339"
  },
  {
    "text": "So for 1,000 by 1,000 matrices,\nthe parallelism is on the order of a million.",
    "start": "3762340",
    "end": "3769376"
  },
  {
    "text": "Wow.  That's great. ",
    "start": "3769376",
    "end": "3776050"
  },
  {
    "text": "However, it's on the order of\na million, but as we know, this doesn't use cache\nvery effectively.",
    "start": "3776050",
    "end": "3784630"
  },
  {
    "text": "So one of the nice things about\ndoing divide and conquer is, as you know, that's a\nreally good way to take advantage of caching.",
    "start": "3784630",
    "end": "3791850"
  },
  {
    "text": "And this works in\nparallel, too. In particular because whenever\nyou have sufficient",
    "start": "3791850",
    "end": "3798920"
  },
  {
    "text": "parallelism, these processors\nare executing the code just as if they were executing\nserial code.",
    "start": "3798920",
    "end": "3806160"
  },
  {
    "text": "So you get all the same cache\nlocality you would get in the serial code in the parallel\ncode, except for the times",
    "start": "3806160",
    "end": "3812280"
  },
  {
    "text": "that you're actually\nmigrating work. And if you have sufficient\nparallelism, that isn't too often.",
    "start": "3812280",
    "end": "3818589"
  },
  {
    "text": "So let's take a look at\nrecursive divide and conquer multiplication. So we're familiar\nwith this, too.",
    "start": "3818590",
    "end": "3825769"
  },
  {
    "text": "So this is eight multiplications\nof n over 2 by 2 matrices, and one addition\nof n by n matrix.",
    "start": "3825770",
    "end": "3831350"
  },
  {
    "text": "So here's a code using a\nlittle bit of C++ism. So I've made the type\na variable t.",
    "start": "3831350",
    "end": "3841560"
  },
  {
    "text": "So we're going to do matrix\nmultiplication of an array, a,",
    "start": "3841560",
    "end": "3847710"
  },
  {
    "text": "the result is going to go\nin c, and we're going to basically have a and b,\nand we're going to add",
    "start": "3847710",
    "end": "3853630"
  },
  {
    "text": "the result into c. We have n, which is the side\nof the submatrix that we're",
    "start": "3853630",
    "end": "3859950"
  },
  {
    "text": "working on, and we're also going\nto have an n size, which is the length of the row\nin the original matrix.",
    "start": "3859950",
    "end": "3866105"
  },
  {
    "text": "So remember when we do matrix\nthings, if I take a submatrix, it's not contiguous in memory.",
    "start": "3866105",
    "end": "3871240"
  },
  {
    "text": "So I have to know the row size\nof the matrix that I'm in in order to be able to calculate\nwhat the elements are.",
    "start": "3871240",
    "end": "3878710"
  },
  {
    "text": "So the way it's going to work\nis I'm going to assign this temporary d, by using\nthe new--",
    "start": "3878710",
    "end": "3886060"
  },
  {
    "text": "which is basically memory\nallocation C++-- array of size n by n.",
    "start": "3886060",
    "end": "3892410"
  },
  {
    "text": "And what we're going to do is\nthen do four of the recursive",
    "start": "3892410",
    "end": "3898670"
  },
  {
    "text": "multiplications, these guys\nhere, into the elements of c,",
    "start": "3898670",
    "end": "3905470"
  },
  {
    "text": "and then four of them also into\nd using the temporary.",
    "start": "3905470",
    "end": "3912000"
  },
  {
    "text": "And then we're going to sync,\nafter we get all that parallel work done, and then we're going\nto add d into c, and",
    "start": "3912000",
    "end": "3918440"
  },
  {
    "text": "then we'll delete d, because\nwe allocated it up here. Everybody understand the code?",
    "start": "3918440",
    "end": "3925920"
  },
  {
    "text": "So we're doing this,\nit's just we're going to do it in parallel. Good?",
    "start": "3925920",
    "end": "3931520"
  },
  {
    "text": "Questions? OK. So this is the row length of the\nmatrices so that I can do",
    "start": "3931520",
    "end": "3938680"
  },
  {
    "text": "the base cases, and in\nparticular, partition the matrices effectively. I haven't shown that code.",
    "start": "3938680",
    "end": "3945720"
  },
  {
    "text": "And of course, the base case,\nnormally, we would want to coarsen for efficiency. I would want to go down to\nsomething like maybe a eight",
    "start": "3945720",
    "end": "3952390"
  },
  {
    "text": "by eight or 16 by 16 matrix,\nand at that point switch to something that's going to use\nthe processor pipeline better.",
    "start": "3952390",
    "end": "3961880"
  },
  {
    "text": "The base cases, once again, I\nwant to emphasize this because a couple people on the quiz\nmisunderstood this.",
    "start": "3961880",
    "end": "3967430"
  },
  {
    "text": "The reason you coarsen has\nnothing to do with caches. The reason you coarsen is to\novercome the overhead of the",
    "start": "3967430",
    "end": "3974410"
  },
  {
    "text": "function calls, and the\ncoarsening is generally chosen independent of what the size\nof the caches are.",
    "start": "3974410",
    "end": "3981280"
  },
  {
    "text": "It's not a parameter that has\nto be tuned to cache size. It's a parameter that has to\nbe tuned to function call,",
    "start": "3981280",
    "end": "3988190"
  },
  {
    "text": "versus ALU instructions, and\nwhat that balance is. Question?",
    "start": "3988190",
    "end": "3994464"
  },
  {
    "text": "AUDIENCE: I mean, I understand\nthat's true, but I thought-- I mean, maybe I\n[? heard the call ?] wrong, but I thought we wanted, in\ngeneral, in terms of caching,",
    "start": "3994464",
    "end": "4002416"
  },
  {
    "text": "that you would choose it somehow\nso that all of the data that you have would\nsomehow fit--",
    "start": "4002416",
    "end": "4008380"
  },
  {
    "text": "CHARLES LEISERSON: That's what\nthe divide and conquer does automatically. The divide and conquer keeps\nhalving it until it fits in",
    "start": "4008380",
    "end": "4014550"
  },
  {
    "text": "whatever size cache you have. And in fact, we have\nthree caches on the machines we're using.",
    "start": "4014550",
    "end": "4019770"
  },
  {
    "text": "AUDIENCE: Yeah, but I'm saying\nif your coarsened constant is too big, that's not\ngoing to happen.",
    "start": "4019770",
    "end": "4025160"
  },
  {
    "text": "CHARLES LEISERSON: If the\ncoarsened constant is too big, that's not going to happen. But generally, the caches are\nmuch bigger than what you need",
    "start": "4025160",
    "end": "4032119"
  },
  {
    "text": "to do to amortize the cost. But you're right, that\nis an assumption. The caches are generally much\nbigger than the size that you",
    "start": "4032120",
    "end": "4039490"
  },
  {
    "text": "need in order to overcome\nfunction call overhead. Function call overhead\nis not that high. OK?",
    "start": "4039490",
    "end": "4044930"
  },
  {
    "text": "Good. I'm glad I raised that\nissue again. And so we're going to determine\nthe submatrices by",
    "start": "4044930",
    "end": "4051690"
  },
  {
    "text": "index calculation. And then we have to implement\nthis parallel add, and that I'm going to do just with a\ndoubly nested for loop to add",
    "start": "4051690",
    "end": "4062270"
  },
  {
    "text": "the things.  There's no cache behavior I can\nreally take advantage of",
    "start": "4062270",
    "end": "4068650"
  },
  {
    "text": "here except for spatial\nlocality. There's no temporal locality\nbecause I'm just adding two",
    "start": "4068650",
    "end": "4073760"
  },
  {
    "text": "matrices once, so there's no\nreal temporal locality that",
    "start": "4073760",
    "end": "4079270"
  },
  {
    "text": "I'll get out of it. And here, I've actually\ndone the index calculations by hand. ",
    "start": "4079270",
    "end": "4088550"
  },
  {
    "text": "So let's analyze this. So to analyze the multiplication\nprogram, I have",
    "start": "4088550",
    "end": "4093790"
  },
  {
    "text": "to start by analyzing the\naddition program. So this should be, I think,\nfairly straightforward.",
    "start": "4093790",
    "end": "4099889"
  },
  {
    "text": "What's the work for adding\ntwo n by n matrices here?",
    "start": "4099890",
    "end": "4106290"
  },
  {
    "text": "n squared, good, just\ndoubly nested loop. What's the span?",
    "start": "4106290",
    "end": "4112611"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. CHARLES LEISERSON: Yeah, here\nit's log n, very good.",
    "start": "4112612",
    "end": "4117859"
  },
  {
    "text": "Because I've got log n plus\nlog n plus order one. ",
    "start": "4117859",
    "end": "4124600"
  },
  {
    "text": "I'm not going to analyze the\nparallelism, because I really don't care about the parallelism\nof the addition. I really care about the\nparallelism of the matrix",
    "start": "4124600",
    "end": "4131179"
  },
  {
    "text": "multiplication. But we'll plug those\nvalues in now. What is the work of the\nmatrix multiplication?",
    "start": "4131180",
    "end": "4137429"
  },
  {
    "text": "Well for this, what we want to\ndo is get a recurrence that we can then solve.",
    "start": "4137430",
    "end": "4143139"
  },
  {
    "text": "So what's the recurrence\nthat we want to get for m of 1 of n? ",
    "start": "4143140",
    "end": "4151049"
  },
  {
    "text": "Yeah, it's going to be 8m\nsub 1 of n over 2, that",
    "start": "4151050",
    "end": "4157439"
  },
  {
    "text": "corresponds to these things,\nplus some constant stuff, plus the work of the addition.",
    "start": "4157439",
    "end": "4163649"
  },
  {
    "text": " Does that make sense? We analyze the work\nof the addition.",
    "start": "4163649",
    "end": "4169390"
  },
  {
    "text": "What's the work of\nthe addition? Order n squared. So that's going to dominate\nthat constant",
    "start": "4169390",
    "end": "4176100"
  },
  {
    "text": "there, so we get 8. And what's the solution\nto this? Back to Master Theorem.",
    "start": "4176100",
    "end": "4183318"
  },
  {
    "text": "Now we're going to start pulling\nout the Master Theorem multiple times per slide for\nthe rest of the lecture.",
    "start": "4183319",
    "end": "4189850"
  },
  {
    "text": "n cubed, because we have\nlog base 2 of 8. That's n cubed compared\nwith n squared.",
    "start": "4189850",
    "end": "4197330"
  },
  {
    "text": "So we get a solution\nwhich is n cubed-- Case 3 of the Master Theorem.",
    "start": "4197330",
    "end": "4202390"
  },
  {
    "text": "So that's good. The work we're doing is the\nsame asymptotic work we're doing for the triply\nnested loop.",
    "start": "4202390",
    "end": "4209220"
  },
  {
    "text": "Now let's take a look\nat the span.  So what's the span for this?",
    "start": "4209220",
    "end": "4215790"
  },
  {
    "start": "4215790",
    "end": "4221030"
  },
  {
    "text": "So once again, we want\na recurrence. What's the recurrence\nlook like? ",
    "start": "4221030",
    "end": "4231929"
  },
  {
    "text": "So the span of this is going\nto be the span of-- it's going to be the\nsum of some things.",
    "start": "4231930",
    "end": "4237344"
  },
  {
    "text": " But the key observation is that\nit's going to be-- we",
    "start": "4237345",
    "end": "4243950"
  },
  {
    "text": "want the maximum\nof these guys. ",
    "start": "4243950",
    "end": "4252969"
  },
  {
    "text": "So we're going to basically\nhave the allocation as constant time, we have the\nmaximum of these, which is m",
    "start": "4252970",
    "end": "4260900"
  },
  {
    "text": "of infinity of n over\n2, and then we have the span of the add.",
    "start": "4260900",
    "end": "4267159"
  },
  {
    "text": "So we get this recurrence. m infinity sub n over 2, because\nwe have only to worry",
    "start": "4267160",
    "end": "4272930"
  },
  {
    "text": "about the worst of these guys. The worst of them is-- they're all symmetric, so\nit's basically the same.",
    "start": "4272930",
    "end": "4279620"
  },
  {
    "text": "We have a of n, and then there's\na constant amount of other overhead here. Any questions about where I\npulled that out of, why that's",
    "start": "4279620",
    "end": "4288320"
  },
  {
    "text": "the recurrence?  So this is the addition, the\nspan of the addition of this",
    "start": "4288320",
    "end": "4296390"
  },
  {
    "text": "guy that we analyzed already. What is the span of\nthe addition? What did we decide that was?",
    "start": "4296390",
    "end": "4302900"
  },
  {
    "text": "log n. So basically, that dominates\nthe order one. So we get this term, and what's\nthe solution of this",
    "start": "4302900",
    "end": "4308920"
  },
  {
    "text": "recurrence? AUDIENCE: [INAUDIBLE]. ",
    "start": "4308920",
    "end": "4314270"
  },
  {
    "text": "CHARLES LEISERSON: What\ncase is this? AUDIENCE: [INAUDIBLE] log n squared. CHARLES LEISERSON: Yes,\nit's log squared n.",
    "start": "4314270",
    "end": "4322500"
  },
  {
    "text": "So basically, it's case two. So if I do n to the log base b\nof a, that's n to the log base",
    "start": "4322500",
    "end": "4327880"
  },
  {
    "text": "2 of 1, that's just 1. And so this is basically a\nlogarithmic factor times the",
    "start": "4327880",
    "end": "4335900"
  },
  {
    "text": "1, so we add an extra log. We get log squared n. ",
    "start": "4335900",
    "end": "4342330"
  },
  {
    "text": "That's just Master Theorem\nplugging in. So here, the span is order\nlog squared n. ",
    "start": "4342330",
    "end": "4349370"
  },
  {
    "text": "And so we have the work of n\ncubed, the span of log squared n, so the parallelism is the\nratio, which is n cubed over",
    "start": "4349370",
    "end": "4357150"
  },
  {
    "text": "log squared n.  Not too bad for a 1,000\nby 1,000 matrices, the",
    "start": "4357150",
    "end": "4363150"
  },
  {
    "text": "parallelism is about\n10 million.",
    "start": "4363150",
    "end": "4369300"
  },
  {
    "text": "Plenty of parallelism.  So let's use the fact that we\nhave plenty of parallelism to",
    "start": "4369300",
    "end": "4375760"
  },
  {
    "text": "say, let's get rid of some of\nthat parallelism and put it back into making our code\nmore efficient.",
    "start": "4375760",
    "end": "4382180"
  },
  {
    "text": "So in particular, this code\nuses an extra temporary d,",
    "start": "4382180",
    "end": "4389520"
  },
  {
    "text": "which it allocates here\nand it deletes here. And generally, there's a good\nrule that says, if you use",
    "start": "4389520",
    "end": "4396640"
  },
  {
    "text": "more storage you're going to use\nmore time, because you're going to have to look at that\nstorage, it's going to take up space in your cache,\nand it's generally",
    "start": "4396640",
    "end": "4403220"
  },
  {
    "text": "going to make you slower. So things that use less storage\nare generally faster.",
    "start": "4403220",
    "end": "4408469"
  },
  {
    "text": "Not always the case, sometimes\nthere's a trade off. But often it's the case, use\nmore storage, it runs slower.",
    "start": "4408470",
    "end": "4414290"
  },
  {
    "text": "So let's get rid of this guy. How do we get rid of this guy? ",
    "start": "4414290",
    "end": "4424440"
  },
  {
    "text": "Yeah? AUDIENCE: [INAUDIBLE PHRASE]. ",
    "start": "4424440",
    "end": "4435140"
  },
  {
    "text": "CHARLES LEISERSON: You're going\nto do this serially, you're saying? AUDIENCE: Yeah, you do those\nserially in add. CHARLES LEISERSON: If you do\nthis serially in add, it turns",
    "start": "4435140",
    "end": "4440880"
  },
  {
    "text": "out if you do that, you're going\nto be in trouble because you're going to not have\nvery much parallelism,",
    "start": "4440880",
    "end": "4447120"
  },
  {
    "text": "unfortunately. Actually, analyzing exactly what\nthe parallelism is there is actually pretty good.",
    "start": "4447120",
    "end": "4453330"
  },
  {
    "text": "It's a good puzzle. Maybe we'll do that on the quiz,\nthe take home problem",
    "start": "4453330",
    "end": "4458739"
  },
  {
    "text": "set we're calling\nit now, right? We're going to have a take home\nproblem set, maybe that's a good one.",
    "start": "4458740",
    "end": "4466100"
  },
  {
    "text": "Yeah, so the idea is,\nyou can sync. And in particular, why not\ncompute these, then sync, and",
    "start": "4466100",
    "end": "4476810"
  },
  {
    "text": "then compute these, adding their\nresults into the places where we added these in? ",
    "start": "4476810",
    "end": "4483849"
  },
  {
    "text": "So it's making the program\nmore serial, because I'm putting in a sync.",
    "start": "4483850",
    "end": "4490420"
  },
  {
    "text": "That shouldn't have an impact on\nthe work, but it will have an impact on the span. ",
    "start": "4490420",
    "end": "4498430"
  },
  {
    "text": "So we're going to trade it off,\nand the way we'll do that is by putting essentially\na sync in the middle.",
    "start": "4498430",
    "end": "4504469"
  },
  {
    "text": "And since they're adding it in,\nI don't even have we call the addition routine, because\nit's just going to",
    "start": "4504470",
    "end": "4510800"
  },
  {
    "text": "add it in in place. So I spawn off these four guys,\nputting their results",
    "start": "4510800",
    "end": "4516190"
  },
  {
    "text": "into c, then I spawn off these\nfour guys, and they add their results into c.",
    "start": "4516190",
    "end": "4521920"
  },
  {
    "text": "Is that clear what\nthe code is? So let's analyze this. ",
    "start": "4521920",
    "end": "4532050"
  },
  {
    "text": "So the work for this\nis order n cubed.",
    "start": "4532050",
    "end": "4541570"
  },
  {
    "text": "It's the same as anything else,\nwe can come up with a recurrence, slightly different\nfrom before because I only have an order one there, but\nit doesn't really matter.",
    "start": "4541570",
    "end": "4548510"
  },
  {
    "text": "The answer is order n cubed. The span, now this gets\na little trickier.",
    "start": "4548510",
    "end": "4555849"
  },
  {
    "text": "What's the recurrence\nof the span? ",
    "start": "4555850",
    "end": "4564430"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. CHARLES LEISERSON:\nWhat is that? AUDIENCE: Twice the span\nof m of n over 2.",
    "start": "4564430",
    "end": "4569690"
  },
  {
    "text": "CHARLES LEISERSON: Twice\nthe span of m of n over 2, that's right.",
    "start": "4569690",
    "end": "4575510"
  },
  {
    "text": "So basically, we have the\nmaximum of these guys, the maximum of these guys, and\nthen this is making those",
    "start": "4575510",
    "end": "4580870"
  },
  {
    "text": "things be in series. So things that are in parallel\nI take the max, if it's in series, I have to add them.",
    "start": "4580870",
    "end": "4586940"
  },
  {
    "text": "So I end up with 2m infinity\nof n over 2 plus order one. Does that make sense?",
    "start": "4586940",
    "end": "4595270"
  },
  {
    "text": "OK, good. So let's solve that\nrecurrence. What's the answer to that one? That's order in.",
    "start": "4595270",
    "end": "4601119"
  },
  {
    "text": "Which case is it? I never know what\nthe cases are.",
    "start": "4601120",
    "end": "4606540"
  },
  {
    "text": "I know two, but one and\nthree, it's like-- they're the same thing, it's\njust which side it's in, so I",
    "start": "4606540",
    "end": "4612030"
  },
  {
    "text": "never remember what\nthe number is. But anyway, case one, yes. Case one.",
    "start": "4612030",
    "end": "4617720"
  },
  {
    "text": "It's the one where this thing is\nbigger, so that's order n. ",
    "start": "4617720",
    "end": "4624410"
  },
  {
    "text": "Good. So then the work is n cubed,\nthe span is order n, the",
    "start": "4624410",
    "end": "4633010"
  },
  {
    "text": "parallelism is order\nn squared. So for 1,000 by 1,000 matrices,\nI get parallelism on",
    "start": "4633010",
    "end": "4638660"
  },
  {
    "text": "the order of a million, instead\nof before, I had parallelism on the order\nof 10 million.",
    "start": "4638660",
    "end": "4645710"
  },
  {
    "text": "So this turns out way better\ncode than the previous one because it avoids the temporary\nand therefore runs,",
    "start": "4645710",
    "end": "4653840"
  },
  {
    "text": "you get a constant factor\nimprovement for that, and it's still, on 12 cores, it's going\nto run pretty fast.",
    "start": "4653840",
    "end": "4662300"
  },
  {
    "text": "And in practice, this is a\nmuch better way to do it. The actual best code that\nI know for doing this",
    "start": "4662300",
    "end": "4669190"
  },
  {
    "text": "essentially does divide and\nconquer in only one dimension at a time.",
    "start": "4669190",
    "end": "4674580"
  },
  {
    "text": "So basically, it looks to see\nwhat's the long dimension, and whatever the long dimension is,\nit slices it in half and",
    "start": "4674580",
    "end": "4680880"
  },
  {
    "text": "then recurses, and just does\nthat as a binary thing. And it basically is the\nsame work, et cetera.",
    "start": "4680880",
    "end": "4686449"
  },
  {
    "text": "It's a little bit more\ntricky to analyze. ",
    "start": "4686450",
    "end": "4694820"
  },
  {
    "text": "Let me quick do merge sort. So you know merge sort. There's merging two sorted\narrays, we saw this before.",
    "start": "4694820",
    "end": "4703469"
  },
  {
    "text": "If I spend all this time doing\nanimations, I might as well get my mileage out of it.",
    "start": "4703470",
    "end": "4709829"
  },
  {
    "text": "There we go. So you merge, that's basically\nwhat this code does. Order n time to merge.",
    "start": "4709830",
    "end": "4717090"
  },
  {
    "text": "So here's merge sort. So what I'll do in merge sort\nis the same thing I normally do, except that I'll\nmake recursive",
    "start": "4717090",
    "end": "4732210"
  },
  {
    "text": "routines go in parallel. So when I do that, it basically\ndivide and conquers",
    "start": "4732210",
    "end": "4738500"
  },
  {
    "text": "down, and then it sort of does\nthis to merge things together.",
    "start": "4738500",
    "end": "4743760"
  },
  {
    "text": "So we saw this before, except\nnow, I've got the fact that I can sort two things in parallel\nrather than sorting",
    "start": "4743760",
    "end": "4751450"
  },
  {
    "text": "them serially. So let's take a look\nat the work. What's the work of merge sort? We know that.",
    "start": "4751450",
    "end": "4758770"
  },
  {
    "text": "n log n, right? 2t of n over 2 plus order n,\nso that's order n log n.",
    "start": "4758770",
    "end": "4766790"
  },
  {
    "text": "The span is what? What's the recurrence\nof the span? ",
    "start": "4766790",
    "end": "4776150"
  },
  {
    "text": "So we're going to take the\nmaximum of these two guys. So we only have one term that\ninvolves t infinity, and then",
    "start": "4776150",
    "end": "4784050"
  },
  {
    "text": "the merge costs us order n,\nso we get this recurrence. ",
    "start": "4784050",
    "end": "4789440"
  },
  {
    "text": "So that says that the\nsolution is order n.",
    "start": "4789440",
    "end": "4794989"
  },
  {
    "text": "So therefore, the work is n log\nn, the span is order n,",
    "start": "4794990",
    "end": "4801590"
  },
  {
    "text": "and so the parallelism\nis order log n.  Puny.",
    "start": "4801590",
    "end": "4807949"
  },
  {
    "text": "Puny parallelism. Log n is like, you can run it,\nand it'll work fine on a few cores, but it's not to be\nsomething that generally will",
    "start": "4807950",
    "end": "4814250"
  },
  {
    "text": "scale and give you a\nlot of parallelism. So it's pretty clear from this\nthat the bottleneck--",
    "start": "4814250",
    "end": "4820630"
  },
  {
    "text": "where's all the span going to? It's going to that merge. ",
    "start": "4820630",
    "end": "4826730"
  },
  {
    "text": "So when you understand that\nthat's the structure of it, now you say if you want to get\nparallelism, you've got to go after the merge.",
    "start": "4826730",
    "end": "4832230"
  },
  {
    "text": "So here's how we parallelize\nthe merge. So we're going to look at\nmerging of two arrays that are of possibly different length.",
    "start": "4832230",
    "end": "4838920"
  },
  {
    "text": "So one we'll call A, and\none we'll call B, with na and nb elements. And let me assume without loss\nof generality that na is",
    "start": "4838920",
    "end": "4846540"
  },
  {
    "text": "greater than or equal to nb,\nbecause otherwise I can just switch the roles of A and B. So the way that I'm going to do\nit is I'm going to find the",
    "start": "4846540",
    "end": "4853369"
  },
  {
    "text": "middle element of A. These\nare sorted arrays that I'm going to merge. I find the middle element of A,\nso these guys are or less",
    "start": "4853370",
    "end": "4861989"
  },
  {
    "text": "than or equal to a of ma,\nand these are greater than or equal to. And now I binary search and\nfind out where that middle",
    "start": "4861990",
    "end": "4869570"
  },
  {
    "text": "element would fall in the array\nB. So that costs me log",
    "start": "4869570",
    "end": "4874840"
  },
  {
    "text": "n time to binary search. Remember binary search? ",
    "start": "4874840",
    "end": "4882420"
  },
  {
    "text": "Then what I'm going to do is\nrecursively merge these guys, because these are sorted and\nless than or equal to ma,",
    "start": "4882420",
    "end": "4888490"
  },
  {
    "text": "recursively merge those and put\nthis guy in the middle. ",
    "start": "4888490",
    "end": "4895140"
  },
  {
    "text": "So when I do that, the key\nquestion when we analyze--",
    "start": "4895140",
    "end": "4902180"
  },
  {
    "text": "it turns out the work is going\nto basically be the same, but the key thing is going to be\nwhat happens to the span?",
    "start": "4902180",
    "end": "4909170"
  },
  {
    "text": "And the idea here is that the\ntotal number of elements in the larger of these two things\nis going to be at most what?",
    "start": "4909170",
    "end": "4919690"
  },
  {
    "text": "Another way of looking at it is\nin the smaller partition, if n is the total number of\nelements, the smaller",
    "start": "4919690",
    "end": "4926230"
  },
  {
    "text": "partition has how\nmany elements at least relative to n? ",
    "start": "4926230",
    "end": "4933750"
  },
  {
    "text": "No matter where this binary\nsearch finds itself. So the worst case is sort of\ngoing to come when this guy is",
    "start": "4933750",
    "end": "4941060"
  },
  {
    "text": "like at one end or the other. And then the point is that\nbecause A is the larger array,",
    "start": "4941060",
    "end": "4948070"
  },
  {
    "text": "at least a quarter of the\nelements will still be in the smaller partition.",
    "start": "4948070",
    "end": "4953340"
  },
  {
    "text": "Of all the elements here, at\nleast a quarter will be in the smaller partition, which will\noccur when B is equal to in",
    "start": "4953340",
    "end": "4959840"
  },
  {
    "text": "size to A. So the number, in\nthe larger of the recursive",
    "start": "4959840",
    "end": "4965170"
  },
  {
    "text": "merges, is at most 3/4 n.  Sound good?",
    "start": "4965170",
    "end": "4970750"
  },
  {
    "text": "That's the main, key\nidea behind this. So here's the parallel merge.",
    "start": "4970750",
    "end": "4977420"
  },
  {
    "text": "Basically you do binary search,\nyou spawn, then, the two merges.",
    "start": "4977420",
    "end": "4982660"
  },
  {
    "text": "Here's one merge, and here's\nthe other merge, and then you sync. So that's the code for the\ndoing the parallel merge.",
    "start": "4982660",
    "end": "4989590"
  },
  {
    "text": "And now you want to incorporate\nthat parallel merge into the parallel\nmerge sort.",
    "start": "4989590",
    "end": "4994750"
  },
  {
    "text": "Of course, you coarsen the base\ncases for efficiency. ",
    "start": "4994750",
    "end": "5001190"
  },
  {
    "text": "So let's analyze the\nspan of this. So the span is basically then\nthe span of something of 3/4,",
    "start": "5001190",
    "end": "5009469"
  },
  {
    "text": "at most 3/4, the size plus the\nlog n for the binary search.",
    "start": "5009470",
    "end": "5016380"
  },
  {
    "text": "So the span of parallel merge is\ntherefore order log squared n, because the important thing\nis, I'm whacking off a",
    "start": "5016380",
    "end": "5024300"
  },
  {
    "text": "constant fraction\nhere every time. So I get log squared n as the\nspan, and the work I get this",
    "start": "5024300",
    "end": "5032050"
  },
  {
    "text": "hairy recurrence, that it's t of\nalpha n plus t1 minus alpha",
    "start": "5032050",
    "end": "5038270"
  },
  {
    "text": "n plus log n, where alpha\nfalls in this range.",
    "start": "5038270",
    "end": "5043920"
  },
  {
    "text": "This does not satisfy\nthe Master Theorem. You can actually do this pretty\neasily with a recursion",
    "start": "5043920",
    "end": "5050080"
  },
  {
    "text": "tree, but the way\nto verify is-- we call this technically\na hairy recurrence.",
    "start": "5050080",
    "end": "5056370"
  },
  {
    "text": "That's the technical\nterm for it. So it turns out, this has order\nn, just like ordinary",
    "start": "5056370",
    "end": "5063830"
  },
  {
    "text": "merge, order n time. here's You can use the\nsubstitution method, and I",
    "start": "5063830",
    "end": "5070539"
  },
  {
    "text": "won't drag you through\nit, but you can look at it in the notes. And this should be very familiar\nto you as having all",
    "start": "5070540",
    "end": "5079179"
  },
  {
    "text": "aced 6006, right? Otherwise you wouldn't\nbe here, right?",
    "start": "5079180",
    "end": "5084560"
  },
  {
    "text": " So the parallelism of the\nparallel merge is something",
    "start": "5084560",
    "end": "5091640"
  },
  {
    "text": "like n over log squared n. So that's much better than\nhaving n order n bound.",
    "start": "5091640",
    "end": "5100510"
  },
  {
    "text": "And now, we can plug\nit into merge sort. So the work is going to be the\nsame as before, because I just",
    "start": "5100510",
    "end": "5105920"
  },
  {
    "text": "have the work of the merge,\nwhich is still order n. So the work is order n log n,\nonce again pulling out the",
    "start": "5105920",
    "end": "5112190"
  },
  {
    "text": "Master Theorem. And then the span is n over 2\nplus log n, because basically,",
    "start": "5112190",
    "end": "5121659"
  },
  {
    "text": "I have the span of a problem of\nhalf the size plus the span",
    "start": "5121660",
    "end": "5127590"
  },
  {
    "text": "that I need to merge things. That's order log squared n. This I want to pause\non for moment. People get this recurrence?",
    "start": "5127590",
    "end": "5135520"
  },
  {
    "text": "Because this is the\nspan of the merge. And so what I end up with is I\nget another log, log cubed n.",
    "start": "5135520",
    "end": "5145310"
  },
  {
    "text": "And so the total parallelism\nis n over log squared n.",
    "start": "5145310",
    "end": "5150350"
  },
  {
    "text": "And this is actually quite a\npractical thing to implement,",
    "start": "5150350",
    "end": "5155440"
  },
  {
    "text": "to get the n over log squared\nn parallelism versus just a log n parallelism.",
    "start": "5155440",
    "end": "5162770"
  },
  {
    "text": "We're not going to do tableau\nconstruction. You can read that up, that's on\nthe notes that are online, but you should read through\nthat part of it.",
    "start": "5162770",
    "end": "5171010"
  },
  {
    "text": "It's got some nice animations\nwhich you don't get to see. ",
    "start": "5171010",
    "end": "5180630"
  },
  {
    "text": "This is like when you do longest\ncommon subsequence and stuff like that, how you\nwould solve that type of problem in parallel.",
    "start": "5180630",
    "end": "5187110"
  },
  {
    "text": "OK, great. ",
    "start": "5187110",
    "end": "5190911"
  }
]
[
  {
    "text": "Okay, one more cache design decision to make,\nthen we're done!",
    "start": "770",
    "end": "5600"
  },
  {
    "text": "How should we handle memory writes in the\ncache?",
    "start": "5600",
    "end": "9130"
  },
  {
    "text": "Ultimately we'll need update main memory with\nthe new data, but when should that happen?",
    "start": "9130",
    "end": "15640"
  },
  {
    "text": "The most obvious choice is to perform the\nwrite immediately.",
    "start": "15640",
    "end": "18290"
  },
  {
    "text": "In other words, whenever the CPU sends a write\nrequest to the cache, the cache then performs",
    "start": "18290",
    "end": "24590"
  },
  {
    "text": "the same write to main memory.",
    "start": "24590",
    "end": "27280"
  },
  {
    "text": "This is called \"write-through\".",
    "start": "27280",
    "end": "30050"
  },
  {
    "text": "That way main memory always has the most up-to-date\nvalue for all locations.",
    "start": "30050",
    "end": "34640"
  },
  {
    "text": "But this can be slow if the CPU has to wait\nfor a DRAM write access - writes could become",
    "start": "34640",
    "end": "40140"
  },
  {
    "text": "a real bottleneck!",
    "start": "40140",
    "end": "42440"
  },
  {
    "text": "And what if the program is constantly writing\na particular memory location, e.g., updating",
    "start": "42440",
    "end": "48120"
  },
  {
    "text": "the value of a local variable in the current\nstack frame?",
    "start": "48120",
    "end": "52260"
  },
  {
    "text": "In the end we only need to write the last\nvalue to main memory.",
    "start": "52260",
    "end": "56879"
  },
  {
    "text": "Writing all the earlier values is waste of\nmemory bandwidth.",
    "start": "56880",
    "end": "60960"
  },
  {
    "text": "Suppose we let the CPU continue execution\nwhile the cache waits for the write to main",
    "start": "60960",
    "end": "65649"
  },
  {
    "text": "memory to complete - this is called \"write-behind\".",
    "start": "65649",
    "end": "69729"
  },
  {
    "text": "This will overlap execution of the program\nwith the slow writes to main memory.",
    "start": "69729",
    "end": "74178"
  },
  {
    "text": "Of course, if there's another cache miss while\nthe write is still pending, everything will",
    "start": "74179",
    "end": "79549"
  },
  {
    "text": "have to wait at that point until both the\nwrite and subsequent refill read finish, since",
    "start": "79549",
    "end": "84090"
  },
  {
    "text": "the CPU can't proceed until the cache miss\nis resolved.",
    "start": "84090",
    "end": "89928"
  },
  {
    "text": "The best strategy is called \"write-back\" where\nthe contents of the cache are updated and",
    "start": "89929",
    "end": "94480"
  },
  {
    "text": "the CPU continues execution immediately.",
    "start": "94480",
    "end": "96561"
  },
  {
    "text": "The updated cache value is only written to\nmain memory when the cache line is chosen",
    "start": "96561",
    "end": "103060"
  },
  {
    "text": "as the replacement line for a cache miss.",
    "start": "103060",
    "end": "107029"
  },
  {
    "text": "This strategy minimizes the number of accesses\nto main memory, preserving the memory bandwidth",
    "start": "107029",
    "end": "112188"
  },
  {
    "text": "for other operations.",
    "start": "112189",
    "end": "114549"
  },
  {
    "text": "This is the strategy used by most modern processors.",
    "start": "114549",
    "end": "118810"
  },
  {
    "text": "Write-back is easy to implement.",
    "start": "118810",
    "end": "120450"
  },
  {
    "text": "Returning to our original cache recipe, we\nsimply eliminate the start of the write to",
    "start": "120450",
    "end": "125288"
  },
  {
    "text": "main memory when there's a write request to\nthe cache.",
    "start": "125289",
    "end": "128349"
  },
  {
    "text": "We just update the cache contents and leave\nit at that.",
    "start": "128349",
    "end": "132220"
  },
  {
    "text": "However, replacing a cache line becomes a\nmore complex operation, since we can't reuse",
    "start": "132220",
    "end": "137790"
  },
  {
    "text": "the cache line without first writing its contents\nback to main memory in case they had been",
    "start": "137790",
    "end": "142780"
  },
  {
    "text": "modified by an earlier write access.",
    "start": "142780",
    "end": "146180"
  },
  {
    "text": "Hmm.",
    "start": "146180",
    "end": "147450"
  },
  {
    "text": "Seems like this does a write-back of all replaced\ncache lines whether or not they've been written",
    "start": "147450",
    "end": "151890"
  },
  {
    "text": "to.",
    "start": "151890",
    "end": "154470"
  },
  {
    "text": "We can avoid unnecessary write-backs by adding\nanother state bit to each cache line: the",
    "start": "154470",
    "end": "159500"
  },
  {
    "text": "\"dirty\" bit.",
    "start": "159500",
    "end": "161330"
  },
  {
    "text": "The dirty bit is set to 0 when a cache line\nis filled during a cache miss.",
    "start": "161330",
    "end": "167480"
  },
  {
    "text": "If a subsequent write operation changes the\ndata in a cache line, the dirty bit is set",
    "start": "167480",
    "end": "172379"
  },
  {
    "text": "to 1, indicating that value in the cache now\ndiffers from the value in main memory.",
    "start": "172380",
    "end": "178380"
  },
  {
    "text": "When a cache line is selected for replacement,\nwe only need to write its data back to main",
    "start": "178380",
    "end": "183080"
  },
  {
    "text": "memory if its dirty bit is 1.",
    "start": "183080",
    "end": "186220"
  },
  {
    "text": "So a write-back strategy with a dirty bit\ngives an elegant solution that minimizes the",
    "start": "186220",
    "end": "191150"
  },
  {
    "text": "number of writes to main memory and only delays\nthe CPU on a cache miss if a dirty cache line",
    "start": "191150",
    "end": "197360"
  },
  {
    "text": "needs to be written back to memory.",
    "start": "197360",
    "end": "200860"
  },
  {
    "text": "That concludes our discussion of caches, which\nwas motivated by our desire to minimize the",
    "start": "200860",
    "end": "205780"
  },
  {
    "text": "average memory access time by building a hierarchical\nmemory system that had both low latency and",
    "start": "205780",
    "end": "211980"
  },
  {
    "text": "high capacity.",
    "start": "211980",
    "end": "214510"
  },
  {
    "text": "There were a number of strategies we employed\nto achieve our goal.",
    "start": "214510",
    "end": "219000"
  },
  {
    "text": "Increasing the number of cache lines decreases\nAMAT by decreasing the miss ratio.",
    "start": "219000",
    "end": "225920"
  },
  {
    "text": "Increasing the block size of the cache let\nus take advantage of the fast column accesses",
    "start": "225920",
    "end": "230650"
  },
  {
    "text": "in a DRAM to efficiently load a whole block\nof data on a cache miss.",
    "start": "230650",
    "end": "236400"
  },
  {
    "text": "The expectation was that this would improve\nAMAT by increasing the number of hits in the",
    "start": "236400",
    "end": "241890"
  },
  {
    "text": "future as accesses were made to nearby locations.",
    "start": "241890",
    "end": "247300"
  },
  {
    "text": "Increasing the number of ways in the cache\nreduced the possibility of cache line conflicts,",
    "start": "247300",
    "end": "252190"
  },
  {
    "text": "lowering the miss ratio.",
    "start": "252190",
    "end": "254500"
  },
  {
    "text": "Choosing the least-recently used cache line\nfor replacement minimized the impact of replacement",
    "start": "254500",
    "end": "259549"
  },
  {
    "text": "on the hit ratio.",
    "start": "259549",
    "end": "261009"
  },
  {
    "text": "And, finally, we chose to handle writes using\na write-back strategy with dirty bits.",
    "start": "261009",
    "end": "267430"
  },
  {
    "text": "How do we make the tradeoffs among all these\narchitectural choices?",
    "start": "267430",
    "end": "271069"
  },
  {
    "text": "As usual, we'll simulate different cache organizations\nand chose the architectural mix that provides",
    "start": "271069",
    "end": "278009"
  },
  {
    "text": "the best performance on our benchmark programs.",
    "start": "278009",
    "end": "280629"
  }
]
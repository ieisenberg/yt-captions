[
  {
    "start": "9000",
    "end": "70000"
  },
  {
    "start": "9500",
    "end": "9500"
  },
  {
    "text": "In this lecture, we'll use a\ntechnique called Bag of Words",
    "start": "9500",
    "end": "12730"
  },
  {
    "text": "to build text analytics models.",
    "start": "12730",
    "end": "15639"
  },
  {
    "text": "Fully understanding text is\ndifficult, but Bag of Words",
    "start": "15640",
    "end": "19570"
  },
  {
    "text": "provides a very simple approach.",
    "start": "19570",
    "end": "22130"
  },
  {
    "text": "It just counts the\nnumber of times",
    "start": "22130",
    "end": "24359"
  },
  {
    "text": "each word appears in the\ntext and uses these counts",
    "start": "24360",
    "end": "28320"
  },
  {
    "text": "as the independent variables.",
    "start": "28320",
    "end": "31080"
  },
  {
    "text": "For example, in the sentence,\n\"This course is great.",
    "start": "31080",
    "end": "34880"
  },
  {
    "text": "I would recommend this\ncourse my friends,\"",
    "start": "34880",
    "end": "37440"
  },
  {
    "text": "the word this is seen twice,\nthe word course is seen twice,",
    "start": "37440",
    "end": "43180"
  },
  {
    "text": "the word great is\nseen once, et cetera.",
    "start": "43180",
    "end": "48000"
  },
  {
    "text": "In Bag of Words, there's\none feature for each word.",
    "start": "48000",
    "end": "51680"
  },
  {
    "text": "This is a very simple approach,\nbut is often very effective,",
    "start": "51680",
    "end": "55160"
  },
  {
    "text": "too.",
    "start": "55160",
    "end": "56329"
  },
  {
    "text": "It's used as a baseline\nin text analytics projects",
    "start": "56330",
    "end": "59680"
  },
  {
    "text": "and for natural\nlanguage processing.",
    "start": "59680",
    "end": "62390"
  },
  {
    "text": "This isn't the\nwhole story, though.",
    "start": "62390",
    "end": "64360"
  },
  {
    "text": "Preprocessing the\ntext can dramatically",
    "start": "64360",
    "end": "66940"
  },
  {
    "text": "improve the performance of\nthe Bag of Words method.",
    "start": "66940",
    "end": "71890"
  },
  {
    "start": "70000",
    "end": "118000"
  },
  {
    "text": "One part of\npreprocessing the text",
    "start": "71890",
    "end": "74090"
  },
  {
    "text": "is to clean up irregularities.",
    "start": "74090",
    "end": "76619"
  },
  {
    "text": "Text data often as many\ninconsistencies that will cause",
    "start": "76620",
    "end": "80000"
  },
  {
    "text": "algorithms trouble.",
    "start": "80000",
    "end": "81940"
  },
  {
    "text": "Computers are very\nliteral by default.",
    "start": "81940",
    "end": "84850"
  },
  {
    "text": "Apple with just an uppercase A,\nAPPLE all in uppercase letters,",
    "start": "84850",
    "end": "89710"
  },
  {
    "text": "or ApPLe with a mixture of\nuppercase and lowercase letters",
    "start": "89710",
    "end": "93370"
  },
  {
    "text": "will all be counted separately.",
    "start": "93370",
    "end": "95990"
  },
  {
    "text": "We want to change the\ntext so that all three",
    "start": "95990",
    "end": "98610"
  },
  {
    "text": "versions of Apple here will\nbe counted as the same word,",
    "start": "98610",
    "end": "102450"
  },
  {
    "text": "by either changing all words\nto uppercase or to lower case.",
    "start": "102450",
    "end": "106930"
  },
  {
    "text": "We'll typically change all\nthe letters to lowercase,",
    "start": "106930",
    "end": "110350"
  },
  {
    "text": "so these three versions\nof Apple will all",
    "start": "110350",
    "end": "112500"
  },
  {
    "text": "become Apple with\nlower case letters",
    "start": "112500",
    "end": "115030"
  },
  {
    "text": "and will be counted\nas the same word.",
    "start": "115030",
    "end": "117000"
  },
  {
    "start": "118000",
    "end": "163000"
  },
  {
    "text": "Punctuation can\nalso cause problems.",
    "start": "119940",
    "end": "122900"
  },
  {
    "text": "The basic approach\nis to deal with this",
    "start": "122900",
    "end": "124910"
  },
  {
    "text": "is to remove everything\nthat isn't a standard number",
    "start": "124910",
    "end": "127510"
  },
  {
    "text": "or letter.",
    "start": "127510",
    "end": "128649"
  },
  {
    "text": "However, sometimes\npunctuation is meaningful.",
    "start": "128650",
    "end": "132480"
  },
  {
    "text": "In the case of Twitter, @Apple\ndenotes a message to Apple,",
    "start": "132480",
    "end": "136989"
  },
  {
    "text": "and #Apple is a\nmessage about Apple.",
    "start": "136990",
    "end": "140690"
  },
  {
    "text": "For web addresses,\nthe punctuation",
    "start": "140690",
    "end": "142790"
  },
  {
    "text": "often defines the web address.",
    "start": "142790",
    "end": "145420"
  },
  {
    "text": "For these reasons, the\nremoval of punctuation",
    "start": "145420",
    "end": "148190"
  },
  {
    "text": "should be tailored to\nthe specific problem.",
    "start": "148190",
    "end": "151370"
  },
  {
    "text": "In our case, we will remove\nall punctuation, so @Apple,",
    "start": "151370",
    "end": "156420"
  },
  {
    "text": "Apple with an exclamation\npoint, Apple with dashes",
    "start": "156420",
    "end": "160020"
  },
  {
    "text": "will all count as just Apple.",
    "start": "160020",
    "end": "162010"
  },
  {
    "start": "163000",
    "end": "238000"
  },
  {
    "text": "Another preprocessing\ntask we want to do",
    "start": "164880",
    "end": "167490"
  },
  {
    "text": "is to remove unhelpful terms.",
    "start": "167490",
    "end": "170680"
  },
  {
    "text": "Many words are\nfrequently used but are",
    "start": "170680",
    "end": "172819"
  },
  {
    "text": "only meaningful in a sentence.",
    "start": "172820",
    "end": "174990"
  },
  {
    "text": "These are called stop words.",
    "start": "174990",
    "end": "178110"
  },
  {
    "text": "Examples are the,\nis, at, and which.",
    "start": "178110",
    "end": "182940"
  },
  {
    "text": "It's unlikely that\nthese words will improve",
    "start": "182940",
    "end": "185440"
  },
  {
    "text": "the machine learning\nprediction quality,",
    "start": "185440",
    "end": "187660"
  },
  {
    "text": "so we want to remove them to\nreduce the size of the data.",
    "start": "187660",
    "end": "191680"
  },
  {
    "text": "There are some potential\nproblems with this approach.",
    "start": "191680",
    "end": "194560"
  },
  {
    "text": "Sometimes, two stop\nwords taken together",
    "start": "194560",
    "end": "197329"
  },
  {
    "text": "have a very important meaning.",
    "start": "197329",
    "end": "199560"
  },
  {
    "text": "For example, \"The Who\"-- which\nis a combination of two stop",
    "start": "199560",
    "end": "203579"
  },
  {
    "text": "words-- is actually the name\nof the band we see on the right",
    "start": "203579",
    "end": "207099"
  },
  {
    "text": "here.",
    "start": "207100",
    "end": "208800"
  },
  {
    "text": "By removing the stop words,\nwe remove both of these words,",
    "start": "208800",
    "end": "212960"
  },
  {
    "text": "but The Who might actually\nhave a significant meaning",
    "start": "212960",
    "end": "215720"
  },
  {
    "text": "for our prediction task.",
    "start": "215720",
    "end": "217850"
  },
  {
    "text": "Another example is the\nphrase, \"Take That\".",
    "start": "217850",
    "end": "220940"
  },
  {
    "text": "If we remove the\nstop words, we'll",
    "start": "220940",
    "end": "222700"
  },
  {
    "text": "remove the word \"that,\" so the\nphrase would just say, \"take.\"",
    "start": "222700",
    "end": "227000"
  },
  {
    "text": "It no longer has the\nsame meaning as before.",
    "start": "227000",
    "end": "230620"
  },
  {
    "text": "So while removing stop words\nsometimes is not helpful,",
    "start": "230620",
    "end": "234150"
  },
  {
    "text": "it generally is a very\nhelpful preprocessing step.",
    "start": "234150",
    "end": "239769"
  },
  {
    "start": "238000",
    "end": "268000"
  },
  {
    "text": "Lastly, an important\npreprocessing step",
    "start": "239770",
    "end": "242430"
  },
  {
    "text": "is called stemming.",
    "start": "242430",
    "end": "244299"
  },
  {
    "text": "This step is motivated\nby the desire",
    "start": "244300",
    "end": "246550"
  },
  {
    "text": "to represent words\nwith different endings",
    "start": "246550",
    "end": "248760"
  },
  {
    "text": "as the same word.",
    "start": "248760",
    "end": "250379"
  },
  {
    "text": "We probably do not need to draw\na distinction between argue,",
    "start": "250380",
    "end": "254020"
  },
  {
    "text": "argued, argues, and arguing.",
    "start": "254020",
    "end": "256910"
  },
  {
    "text": "They could all be represented\nby a common stem, argue.",
    "start": "256910",
    "end": "261370"
  },
  {
    "text": "The algorithmic process of\nperforming this reduction",
    "start": "261370",
    "end": "264290"
  },
  {
    "text": "is called stemming.",
    "start": "264290",
    "end": "266170"
  },
  {
    "text": "There are many ways to\napproach the problem.",
    "start": "266170",
    "end": "269440"
  },
  {
    "start": "268000",
    "end": "321000"
  },
  {
    "text": "One approach is to\nbuild a database",
    "start": "269440",
    "end": "271750"
  },
  {
    "text": "of words and their stems.",
    "start": "271750",
    "end": "273890"
  },
  {
    "text": "A pro is that this approach\nhandles exceptions very nicely,",
    "start": "273890",
    "end": "278130"
  },
  {
    "text": "since we have to find\nall of the stems.",
    "start": "278130",
    "end": "280970"
  },
  {
    "text": "However, it won't\nhandle new words at all,",
    "start": "280970",
    "end": "283980"
  },
  {
    "text": "since they are not\nin the database.",
    "start": "283980",
    "end": "285860"
  },
  {
    "text": "This is especially\nbad for problems",
    "start": "285860",
    "end": "288030"
  },
  {
    "text": "where we're using data\nfrom the internet,",
    "start": "288030",
    "end": "290070"
  },
  {
    "text": "since we have no idea\nwhat words will be used.",
    "start": "290070",
    "end": "293480"
  },
  {
    "text": "A different approach is to\nwrite a rule-based algorithm.",
    "start": "293480",
    "end": "296909"
  },
  {
    "text": "In this approach, if a word ends\nin things like ed, ing, or ly,",
    "start": "296909",
    "end": "302460"
  },
  {
    "text": "we would remove the ending.",
    "start": "302460",
    "end": "304300"
  },
  {
    "text": "A pro of this approach is that\nit handles new or unknown words",
    "start": "304300",
    "end": "308009"
  },
  {
    "text": "well.",
    "start": "308010",
    "end": "308910"
  },
  {
    "text": "However, there are\nmany exceptions,",
    "start": "308910",
    "end": "311080"
  },
  {
    "text": "and this approach would\nmiss all of these.",
    "start": "311080",
    "end": "313319"
  },
  {
    "text": "Words like child and children\nwould be considered different,",
    "start": "313320",
    "end": "317480"
  },
  {
    "text": "but it would get other\nplurals, like dog and dogs.",
    "start": "317480",
    "end": "322830"
  },
  {
    "text": "This second approach\nis widely popular",
    "start": "322830",
    "end": "324939"
  },
  {
    "text": "and is called the\nPorter Stemmer, designed",
    "start": "324940",
    "end": "326910"
  },
  {
    "text": "by Martin Porter in 1980,\nand it's still used today.",
    "start": "326910",
    "end": "331520"
  },
  {
    "text": "Stemmers like this one have\nbeen written for many languages.",
    "start": "331520",
    "end": "335819"
  },
  {
    "text": "Other options for\nstemming include",
    "start": "335820",
    "end": "337720"
  },
  {
    "text": "machine learning,\nwhere algorithms",
    "start": "337720",
    "end": "339570"
  },
  {
    "text": "are trained to recognize the\nroots of words and combinations",
    "start": "339570",
    "end": "343420"
  },
  {
    "text": "of the approaches\nexplained here.",
    "start": "343420",
    "end": "345750"
  },
  {
    "text": "As a real example\nfrom our data set,",
    "start": "345750",
    "end": "348190"
  },
  {
    "text": "the phrase \"by far the best\ncustomer care service I",
    "start": "348190",
    "end": "351710"
  },
  {
    "text": "have ever received\"\nhas three words",
    "start": "351710",
    "end": "354289"
  },
  {
    "text": "that would be stemmed--\ncustomer, service,",
    "start": "354290",
    "end": "357659"
  },
  {
    "text": "and received.",
    "start": "357659",
    "end": "359050"
  },
  {
    "text": "The \"er\" would be\nremoved in customer,",
    "start": "359050",
    "end": "362110"
  },
  {
    "text": "the \"e\" would be\nremoved in service,",
    "start": "362110",
    "end": "364550"
  },
  {
    "text": "and the \"ed\" would be\nremoved in received.",
    "start": "364550",
    "end": "368740"
  },
  {
    "text": "In the next video, we'll see\nhow to run these preprocessing",
    "start": "368740",
    "end": "372180"
  },
  {
    "text": "steps in R.",
    "start": "372180",
    "end": "374150"
  }
]
[
  {
    "start": "0",
    "end": "137000"
  },
  {
    "start": "0",
    "end": "4960"
  },
  {
    "text": "[MUSIC PLAYING]",
    "start": "4960",
    "end": "8927"
  },
  {
    "start": "8928",
    "end": "11027"
  },
  {
    "text": "MIKE TEODORESCU: Hello,\nand welcome to this module",
    "start": "11027",
    "end": "13110"
  },
  {
    "text": "on protected attributes and\nfairness through unawareness.",
    "start": "13110",
    "end": "15584"
  },
  {
    "text": "My name is Mike Teodorescu.",
    "start": "15585",
    "end": "16710"
  },
  {
    "text": "I'm an assistant professor\nof information systems",
    "start": "16710",
    "end": "18751"
  },
  {
    "text": "at Boston College, as well as a\nvisiting scholar at MIT D-Lab.",
    "start": "18752",
    "end": "21890"
  },
  {
    "text": "What this module\nwill cover will be",
    "start": "21890",
    "end": "23519"
  },
  {
    "text": "examples of laws that codify\nprotected attributes, as well",
    "start": "23520",
    "end": "26850"
  },
  {
    "text": "as the base case\nscenario for fairness",
    "start": "26850",
    "end": "28575"
  },
  {
    "text": "in machine learning,\nwhich is called fairness",
    "start": "28575",
    "end": "30450"
  },
  {
    "text": "through unawareness.",
    "start": "30450",
    "end": "32932"
  },
  {
    "text": "The use of machine learning\npresents both risks",
    "start": "32932",
    "end": "34890"
  },
  {
    "text": "and opportunities.",
    "start": "34890",
    "end": "36675"
  },
  {
    "text": "Machine learning\ncan reduce costs",
    "start": "36675",
    "end": "38050"
  },
  {
    "text": "by automating repetitive tasks,\nbut could also increase biases.",
    "start": "38050",
    "end": "42680"
  },
  {
    "text": "Certain individual\nattributes are commonly",
    "start": "42680",
    "end": "44510"
  },
  {
    "text": "labeled as protected\nattributes, as they",
    "start": "44510",
    "end": "46820"
  },
  {
    "text": "can be sources of social bias.",
    "start": "46820",
    "end": "49160"
  },
  {
    "text": "These are race, religion,\nnational origin, gender,",
    "start": "49160",
    "end": "53550"
  },
  {
    "text": "marital status, age, and\nsocioeconomic status.",
    "start": "53550",
    "end": "55805"
  },
  {
    "start": "55805",
    "end": "59090"
  },
  {
    "text": "In the United States,\ndiscrimination",
    "start": "59090",
    "end": "60860"
  },
  {
    "text": "based on these protected\nattributes in housing, lending,",
    "start": "60860",
    "end": "63890"
  },
  {
    "text": "and employment is illegal.",
    "start": "63890",
    "end": "65750"
  },
  {
    "text": "Some of the laws are listed\nhere for your reference.",
    "start": "65750",
    "end": "68770"
  },
  {
    "text": "However, regardless of\nthe legal framework,",
    "start": "68770",
    "end": "71003"
  },
  {
    "text": "machine learning still\nhas the potential",
    "start": "71003",
    "end": "72670"
  },
  {
    "text": "to unintentionally embed bias.",
    "start": "72670",
    "end": "74979"
  },
  {
    "text": "In this lecture, we\nlook at a few examples.",
    "start": "74980",
    "end": "77605"
  },
  {
    "text": "The next lecture will\nexplore some approaches",
    "start": "77605",
    "end": "79480"
  },
  {
    "text": "to mitigate unintentional bias.",
    "start": "79480",
    "end": "83820"
  },
  {
    "text": "Even large companies could\nunintentionally discriminate.",
    "start": "83820",
    "end": "86700"
  },
  {
    "text": "For example, Amazon\nused a machine",
    "start": "86700",
    "end": "88590"
  },
  {
    "text": "learning algorithm\nto screen resumes,",
    "start": "88590",
    "end": "90594"
  },
  {
    "text": "and later found out that the\nalgorithm was discriminating",
    "start": "90595",
    "end": "92970"
  },
  {
    "text": "against female applicants.",
    "start": "92970",
    "end": "94554"
  },
  {
    "start": "94554",
    "end": "97220"
  },
  {
    "text": "In another example, this time\nfrom the criminal justice",
    "start": "97220",
    "end": "99550"
  },
  {
    "text": "system, machine learning\nis used to determine",
    "start": "99550",
    "end": "102130"
  },
  {
    "text": "the risk of recidivism.",
    "start": "102130",
    "end": "104280"
  },
  {
    "text": "This system has been questioned\nin a variety of studies,",
    "start": "104280",
    "end": "106920"
  },
  {
    "text": "in particular, with\nreference to the protected",
    "start": "106920",
    "end": "108400"
  },
  {
    "text": "attribute of race and gender.",
    "start": "108400",
    "end": "109710"
  },
  {
    "start": "109710",
    "end": "112290"
  },
  {
    "text": "In another example of\na large organization",
    "start": "112290",
    "end": "115340"
  },
  {
    "text": "employing machine learning,\nthis time, to display ads,",
    "start": "115340",
    "end": "118299"
  },
  {
    "text": "Facebook has been named in a\nsuit over alleged violations",
    "start": "118300",
    "end": "120850"
  },
  {
    "text": "of the Fair Housing Act.",
    "start": "120850",
    "end": "124090"
  },
  {
    "text": "Therefore, even\nlarge organizations,",
    "start": "124090",
    "end": "125679"
  },
  {
    "text": "like Amazon an\nFacebook, find machine",
    "start": "125680",
    "end": "127222"
  },
  {
    "text": "learning fairness challenging.",
    "start": "127222",
    "end": "129490"
  },
  {
    "text": "We hope this course will\nbe helpful in preparing",
    "start": "129490",
    "end": "132182"
  },
  {
    "text": "software engineers to better\naddress machine learning",
    "start": "132182",
    "end": "134390"
  },
  {
    "text": "fairness.",
    "start": "134390",
    "end": "134890"
  },
  {
    "start": "134890",
    "end": "137360"
  },
  {
    "start": "137000",
    "end": "137000"
  },
  {
    "text": "Generally speaking, before you\nimplement a machine learning",
    "start": "137360",
    "end": "139850"
  },
  {
    "text": "algorithm, you need to collect\ndata to train that algorithm.",
    "start": "139850",
    "end": "143930"
  },
  {
    "text": "This data set would have\nyour outcome variable,",
    "start": "143930",
    "end": "146349"
  },
  {
    "text": "in this figure, Y, for\nexample, the decision",
    "start": "146350",
    "end": "149050"
  },
  {
    "text": "to hire or not to hire, as\nwell as all of the predictors,",
    "start": "149050",
    "end": "153550"
  },
  {
    "text": "for example, features\ncollected from resumes.",
    "start": "153550",
    "end": "156910"
  },
  {
    "text": "This complete data\nset would then",
    "start": "156910",
    "end": "158440"
  },
  {
    "text": "have to be split in a training\nset on which the model would",
    "start": "158440",
    "end": "162310"
  },
  {
    "text": "learn and a test set on which\nwe would determine the model",
    "start": "162310",
    "end": "165280"
  },
  {
    "text": "performance.",
    "start": "165280",
    "end": "167100"
  },
  {
    "text": "There are other details,\nlike cross-validation,",
    "start": "167100",
    "end": "169295"
  },
  {
    "text": "which we'll not\ncover here, but I",
    "start": "169295",
    "end": "170670"
  },
  {
    "text": "encourage you to read more on.",
    "start": "170670",
    "end": "171920"
  },
  {
    "start": "171920",
    "end": "174970"
  },
  {
    "start": "174000",
    "end": "174000"
  },
  {
    "text": "Fairness starts with a\ngood quality training set.",
    "start": "174970",
    "end": "178310"
  },
  {
    "text": "Low quality data,\ngenerally speaking,",
    "start": "178310",
    "end": "179959"
  },
  {
    "text": "leads to bad predictions.",
    "start": "179960",
    "end": "182330"
  },
  {
    "text": "The individuals\nlabeling the data,",
    "start": "182330",
    "end": "183960"
  },
  {
    "text": "for example, managers labeling\nresume as a higher or no hire,",
    "start": "183960",
    "end": "188800"
  },
  {
    "text": "may carry biases, which\nare then picked up",
    "start": "188800",
    "end": "190650"
  },
  {
    "text": "by the machine\nlearning algorithm.",
    "start": "190650",
    "end": "193079"
  },
  {
    "text": "Training data may not be\nrepresentative of all groups,",
    "start": "193080",
    "end": "195750"
  },
  {
    "text": "which could lead to bias.",
    "start": "195750",
    "end": "197945"
  },
  {
    "text": "And there may be hidden\ncorrelations in input data,",
    "start": "197945",
    "end": "200070"
  },
  {
    "text": "for example, between a protected\nattribute and the predictor.",
    "start": "200070",
    "end": "203020"
  },
  {
    "text": "That can also lead to bias.",
    "start": "203020",
    "end": "206320"
  },
  {
    "text": "Individuals labeling\nthe training data",
    "start": "206320",
    "end": "207940"
  },
  {
    "text": "may misremember past\nsituations, a phenomenon known",
    "start": "207940",
    "end": "211030"
  },
  {
    "text": "as selective perception,\nwhich may in itself become",
    "start": "211030",
    "end": "213730"
  },
  {
    "text": "a source of bias.",
    "start": "213730",
    "end": "214540"
  },
  {
    "start": "214540",
    "end": "217239"
  },
  {
    "start": "216000",
    "end": "216000"
  },
  {
    "text": "The default fairness\nmethod in machine learning",
    "start": "217240",
    "end": "219700"
  },
  {
    "text": "is fairness through unawareness.",
    "start": "219700",
    "end": "222082"
  },
  {
    "text": "Fairness through\nunawareness refers",
    "start": "222082",
    "end": "223540"
  },
  {
    "text": "to leaving out protected\nattributes such as gender,",
    "start": "223540",
    "end": "226519"
  },
  {
    "text": "race, and other characteristics\ndeemed sensitive.",
    "start": "226520",
    "end": "230340"
  },
  {
    "text": "And, while it was thought\nto erase inequality,",
    "start": "230340",
    "end": "233599"
  },
  {
    "text": "it was found, actually,\nto perpetuate it.",
    "start": "233600",
    "end": "236100"
  },
  {
    "text": "It may do so by, for example,\nhaving other attributes that",
    "start": "236100",
    "end": "239655"
  },
  {
    "text": "are correlated\nwith the protected",
    "start": "239655",
    "end": "241030"
  },
  {
    "text": "attributes in the data, which,\nby ignoring the protected",
    "start": "241030",
    "end": "243959"
  },
  {
    "text": "attributes, we could just\nstill include in our model.",
    "start": "243960",
    "end": "247740"
  },
  {
    "text": "This could actually\nperpetuate inequality.",
    "start": "247740",
    "end": "252180"
  },
  {
    "start": "251000",
    "end": "251000"
  },
  {
    "text": "When race, gender, and\nother sensitive variables",
    "start": "252180",
    "end": "254370"
  },
  {
    "text": "are treated as protected, other\nvariables, such as college",
    "start": "254370",
    "end": "258060"
  },
  {
    "text": "attended, hometown, or\nother resume indicators",
    "start": "258060",
    "end": "260430"
  },
  {
    "text": "that remain\nunprotected, may still",
    "start": "260430",
    "end": "261989"
  },
  {
    "text": "be highly correlated with\nthese protected attributes.",
    "start": "261990",
    "end": "265199"
  },
  {
    "text": "Thus, ignoring the protected\nattributes altogether",
    "start": "265200",
    "end": "268200"
  },
  {
    "text": "may not reveal these hidden\ncorrelations in data.",
    "start": "268200",
    "end": "271050"
  },
  {
    "text": "This is called\nredundant encoding.",
    "start": "271050",
    "end": "274310"
  },
  {
    "text": "In one example, researchers\nat Carnegie Mellon University",
    "start": "274310",
    "end": "277040"
  },
  {
    "text": "found that gender caused\nan unintentional change",
    "start": "277040",
    "end": "280070"
  },
  {
    "text": "in Google's advertising system\nsuch an ad listings targeted",
    "start": "280070",
    "end": "283610"
  },
  {
    "text": "for user's seeking\nhigh-income jobs",
    "start": "283610",
    "end": "285750"
  },
  {
    "text": "were presented to men at\nnearly six times the rate they",
    "start": "285750",
    "end": "288425"
  },
  {
    "text": "were presented to women.",
    "start": "288425",
    "end": "289970"
  },
  {
    "text": "This may be an example of\nfairness through unawareness.",
    "start": "289970",
    "end": "295100"
  },
  {
    "start": "295000",
    "end": "295000"
  },
  {
    "text": "Here are some review\nquestions about this material.",
    "start": "295100",
    "end": "299125"
  },
  {
    "text": "What are the\nsensitive attributes",
    "start": "299125",
    "end": "300500"
  },
  {
    "text": "in the context in\nwhich you work?",
    "start": "300500",
    "end": "302578"
  },
  {
    "text": "Do you think that the current\nlist of protected attributes",
    "start": "302578",
    "end": "304995"
  },
  {
    "text": "is exhaustive?",
    "start": "304995",
    "end": "307120"
  },
  {
    "text": "What is fairness\nthrough unawareness?",
    "start": "307120",
    "end": "310270"
  },
  {
    "text": "What variables might lead\nto biased predictions",
    "start": "310270",
    "end": "312310"
  },
  {
    "text": "for a machine learning hiring\nsystem in your country?",
    "start": "312310",
    "end": "315860"
  },
  {
    "text": "What are some risks to\nan organization choosing",
    "start": "315860",
    "end": "318110"
  },
  {
    "text": "unawareness?",
    "start": "318110",
    "end": "321689"
  },
  {
    "start": "321000",
    "end": "321000"
  },
  {
    "text": "I'd like to thank my co-authors\nLily Morse, Gerald Kane,",
    "start": "321690",
    "end": "324360"
  },
  {
    "text": "and Yazeed Awwad\nfor a study that",
    "start": "324360",
    "end": "326550"
  },
  {
    "text": "helped me put together\nalso these slides,",
    "start": "326550",
    "end": "328860"
  },
  {
    "text": "as well as USAID for a grant\non appropriate use of machine",
    "start": "328860",
    "end": "331830"
  },
  {
    "text": "learning in developing\ncountries and the Carroll",
    "start": "331830",
    "end": "333860"
  },
  {
    "text": "School of Management at Boston\nCollege for research funding.",
    "start": "333860",
    "end": "337090"
  },
  {
    "text": "I'd also like to thank\neveryone who helped contribute",
    "start": "337090",
    "end": "339330"
  },
  {
    "text": "with feedback to these\nvideos, as well as",
    "start": "339330",
    "end": "341580"
  },
  {
    "text": "the accompanying manuscripts.",
    "start": "341580",
    "end": "345242"
  },
  {
    "start": "345000",
    "end": "345000"
  },
  {
    "text": "I'd like to share with you\nsome references I found helpful",
    "start": "345243",
    "end": "347660"
  },
  {
    "text": "[INAUDIBLE] this material.",
    "start": "347660",
    "end": "349500"
  },
  {
    "text": "I hope you will read\nmore about this,",
    "start": "349500",
    "end": "351440"
  },
  {
    "text": "and I'd like to thank\nyou for your attention",
    "start": "351440",
    "end": "353380"
  },
  {
    "text": "in watching this video.",
    "start": "353380",
    "end": "355680"
  },
  {
    "text": "Thank you so much for\nwatching this video.",
    "start": "355680",
    "end": "357630"
  },
  {
    "text": "We hope you find it\nuseful and you'll continue",
    "start": "357630",
    "end": "359547"
  },
  {
    "text": "watching the rest of the class.",
    "start": "359547",
    "end": "361820"
  },
  {
    "text": "[MUSIC PLAYING]",
    "start": "361820",
    "end": "365770"
  },
  {
    "start": "365770",
    "end": "377000"
  }
]
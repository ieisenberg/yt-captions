[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6330"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6330",
    "end": "13320"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. ",
    "start": "13320",
    "end": "21390"
  },
  {
    "start": "20000",
    "end": "70000"
  },
  {
    "text": "PROFESSOR: OK, welcome back. Sorry for the\ntechnical blip there. OK, so I guess lecture two.",
    "start": "21390",
    "end": "31611"
  },
  {
    "text": "I challenged you. We talked about the phase\nspace of the simple pendulum, and I challenged you to come\nup with a simple algorithm.",
    "start": "31611",
    "end": "39510"
  },
  {
    "text": "I guess I didn't\nsay simple, but I challenged you to come\nup with an algorithm to try to, in some\nsort of minimal way,",
    "start": "39510",
    "end": "49620"
  },
  {
    "text": "change the phase\nplot of this system so that the fixed points\nthat used to be unstable",
    "start": "49620",
    "end": "55290"
  },
  {
    "text": "become stable and vise versa. So today we're going to do that. I don't know if anybody\ndo that for fun?",
    "start": "55290",
    "end": "63042"
  },
  {
    "text": "Yeah, OK. [LAUGHTER] OK, so today we're\ngoing to do that.",
    "start": "63042",
    "end": "68110"
  },
  {
    "text": "So yeah, the question is, can\nwe use optimal control now,",
    "start": "68110",
    "end": "73890"
  },
  {
    "start": "70000",
    "end": "282000"
  },
  {
    "text": "numerical optimal control, to\nreshape these dynamics, OK.",
    "start": "73890",
    "end": "79320"
  },
  {
    "text": "And I want to\nstart by doing sort of an evil thing\nbut something that's",
    "start": "79320",
    "end": "87450"
  },
  {
    "text": "going to make thinking\nabout it a lot easier. We're going to discretize\neverything, OK.",
    "start": "87450",
    "end": "93540"
  },
  {
    "text": "So let's start by-- ",
    "start": "93540",
    "end": "102000"
  },
  {
    "text": "we're going to discretize\nstate, actions, and time, OK.",
    "start": "102000",
    "end": "113670"
  },
  {
    "text": "So I'm actually going to\ntake my vector of x, which",
    "start": "113670",
    "end": "120119"
  },
  {
    "text": "lived on the real numbers,\nand start thinking",
    "start": "120120",
    "end": "126420"
  },
  {
    "text": "about integer number of states.",
    "start": "126420",
    "end": "132459"
  },
  {
    "text": "I'll say what I mean by that.  OK.",
    "start": "132460",
    "end": "139050"
  },
  {
    "text": "And I'm going to take my\nactions, my continuous action",
    "start": "139050",
    "end": "147040"
  },
  {
    "text": "space, which I've\nbeen thinking of as u, and I'm going to turn\nthat into a discrete state",
    "start": "147040",
    "end": "152380"
  },
  {
    "text": "space, a discrete action space. And I'm going to\ntake time and turn it",
    "start": "152380",
    "end": "158170"
  },
  {
    "text": "into some integer,\ndiscrete time, OK.",
    "start": "158170",
    "end": "164980"
  },
  {
    "text": " So and I'm going to try to\nbe-- throughout the lectures,",
    "start": "164980",
    "end": "171480"
  },
  {
    "text": "throughout the notes, I tried\nto be very, very careful to use X and U and time\nfor continuous things",
    "start": "171480",
    "end": "177629"
  },
  {
    "text": "and S for states, A for\nactions, N for discrete things.",
    "start": "177630",
    "end": "182710"
  },
  {
    "text": "So we might find\nourselves in situations where we have continuous\nstate and discrete actions or some other combination,\nbut that should be a code.",
    "start": "182710",
    "end": "193112"
  },
  {
    "text": "OK, so if we want to-- if we're\nwilling to discretize state and time, then maybe one\nway to think about that on this picture is by thinking\nof every one of these--",
    "start": "193112",
    "end": "202960"
  },
  {
    "text": "this was my quick\ncartoon of the phase plot of the simple pendulum. Let's think about\nidentifying each one",
    "start": "202960",
    "end": "209970"
  },
  {
    "text": "of these possible states\nin the phase portrait as a particular state, OK.",
    "start": "209970",
    "end": "217020"
  },
  {
    "text": "These little nodes, possible\nstates we can live in. And through actions, we can\ntransition to different states,",
    "start": "217020",
    "end": "228840"
  },
  {
    "text": "if you see what I'm\ndoing without drawing 100,000 circles here.",
    "start": "228840",
    "end": "233950"
  },
  {
    "text": "So let's tile the state\nspace with discrete states.",
    "start": "233950",
    "end": "239560"
  },
  {
    "text": "You could also think\nof it as drawing a grid and calling each box\nin the grid a state.",
    "start": "239560",
    "end": "246030"
  },
  {
    "text": "And what that allows\nus to do-- we're also discretizing actions, so\nwe have a finite number",
    "start": "246030",
    "end": "252640"
  },
  {
    "text": "of possible options\ncoming out of each state. It allows us to turn the\ncontinuous time optimal control",
    "start": "252640",
    "end": "259049"
  },
  {
    "text": "problem into a simple\ngraph search problem, OK.",
    "start": "259050",
    "end": "266069"
  },
  {
    "text": "Graph search, we\nknow how to do well. We're really good at\nthat in computer science. OK, so let's see how\nfar we can get first",
    "start": "266070",
    "end": "274199"
  },
  {
    "text": "by just thinking about this very\nnon-linear, very dynamic thing",
    "start": "274200",
    "end": "279420"
  },
  {
    "text": "on a graph search, OK. ",
    "start": "279420",
    "end": "285180"
  },
  {
    "start": "282000",
    "end": "508000"
  },
  {
    "text": "So we're going to do\nnumerical optimal control. This is-- in\nparticular, when people",
    "start": "285180",
    "end": "293120"
  },
  {
    "text": "talk about the dynamic\nprogramming algorithm, they're often talking about\ndiscretizing state and actions.",
    "start": "293120",
    "end": "299075"
  },
  {
    "text": " And we're going to use the\nstandard optimal control",
    "start": "299075",
    "end": "306590"
  },
  {
    "text": "formulation. I'm going to start\nwith a finite horizon",
    "start": "306590",
    "end": "316430"
  },
  {
    "text": "and say that my cost of\nbeing in state x, time t",
    "start": "316430",
    "end": "323300"
  },
  {
    "text": "is h of x at the final time. ",
    "start": "323300",
    "end": "331253"
  },
  {
    "text": "All right, this is the\ncontinuous time optimal control. ",
    "start": "331253",
    "end": "342690"
  },
  {
    "text": "And I'm going to start thinking\nof that now as being in state S",
    "start": "342690",
    "end": "348600"
  },
  {
    "text": "at integer time N\nand having me be",
    "start": "348600",
    "end": "353920"
  },
  {
    "text": "at some final cost\non S plus a sum",
    "start": "353920",
    "end": "362550"
  },
  {
    "text": "from N equals 0\nto N of g SA, OK.",
    "start": "362550",
    "end": "369300"
  },
  {
    "text": "And my dynamics now are\ngoing to be of the form S-- ",
    "start": "369300",
    "end": "376560"
  },
  {
    "text": "maybe I should even write\nmore explicitly, S N plus 1 is a function of SN, AN, OK.",
    "start": "376560",
    "end": "382180"
  },
  {
    "start": "382180",
    "end": "394229"
  },
  {
    "text": "OK, so again,\ndynamic programming",
    "start": "394230",
    "end": "401850"
  },
  {
    "text": "exploits the fact that you can\nwrite this in a recursive form. So if I want to find\nthe optimal cost",
    "start": "401850",
    "end": "412830"
  },
  {
    "text": "to go, which I'll call J\nstar, at the final time,",
    "start": "412830",
    "end": "423599"
  },
  {
    "text": "it's just h of S, right.",
    "start": "423600",
    "end": "428610"
  },
  {
    "text": "And going backwards\nin time, this",
    "start": "428610",
    "end": "435629"
  },
  {
    "text": "is just going to be the min over\na of g S, a plus h of S prime,",
    "start": "435630",
    "end": "446130"
  },
  {
    "text": "where S prime is. ",
    "start": "446130",
    "end": "452600"
  },
  {
    "text": "Right? I'll get one-- if N is-- N minus 1, I get one\nof these, and then I get the final cost, OK.",
    "start": "452600",
    "end": "461870"
  },
  {
    "text": "And going backwards, we\nhave this recursive form,",
    "start": "461870",
    "end": "469060"
  },
  {
    "text": "which is min over a g S, a plus\nthe cost to go from S prime",
    "start": "469060",
    "end": "478540"
  },
  {
    "text": "and n plus 1 using\nthat same S prime. ",
    "start": "478540",
    "end": "490250"
  },
  {
    "text": "OK, I want to make sure\nyou see why that is, why this-- this is magical, right?",
    "start": "490250",
    "end": "496030"
  },
  {
    "text": "The fact that I can\nsummarize my optimal cost to go by doing a min\nover a single action, that's",
    "start": "496030",
    "end": "504240"
  },
  {
    "text": "really magical.  Just to make that extremely\nclear, think about J star",
    "start": "504240",
    "end": "515380"
  },
  {
    "text": "at N minus 2, let's say. So I have to minimize\nover two actions.",
    "start": "515380",
    "end": "522610"
  },
  {
    "text": "I have to minimize over, let's\nsay I'll call them a1 and a2. ",
    "start": "522610",
    "end": "528460"
  },
  {
    "text": "I have two steps left to go. So I have to minimize S\nat a1 plus g of S prime,",
    "start": "528460",
    "end": "536320"
  },
  {
    "text": "let's call it, a2 plus\nh of S double prime.",
    "start": "536320",
    "end": "541667"
  },
  {
    "text": "That's my minimization\nthat I'm trying to solve in order to find\nthe optimal cost to go,",
    "start": "541667",
    "end": "548620"
  },
  {
    "text": "where S prime is f of S, a.",
    "start": "548620",
    "end": "553750"
  },
  {
    "text": "S double prime is f of S prime. This is a1, and this is a2.",
    "start": "553750",
    "end": "559540"
  },
  {
    "start": "559540",
    "end": "565615"
  },
  {
    "text": "I'm just expanding this\nsum for the last two g's.",
    "start": "565615",
    "end": "571660"
  },
  {
    "text": " And the cool thing is that,\nbecause of this additive form",
    "start": "571660",
    "end": "579970"
  },
  {
    "text": "of g, this term doesn't depend\nat all on my decision a2.",
    "start": "579970",
    "end": "585399"
  },
  {
    "text": " I'm given a current state S, and\nI have to decide my action a1.",
    "start": "585400",
    "end": "596490"
  },
  {
    "text": "Nothing about this term\ndepends at all on a2, OK.",
    "start": "596490",
    "end": "602580"
  },
  {
    "text": "In contrast, this one\ndoes depend on a1, because S prime depends on a1.",
    "start": "602580",
    "end": "608640"
  },
  {
    "text": " This one depends on a1 and a2.",
    "start": "608640",
    "end": "615540"
  },
  {
    "text": "This one certainly\ndepends on a2. You see what I'm saying? ",
    "start": "615540",
    "end": "622630"
  },
  {
    "text": "So I can rewrite this\nas min over a1 f of S a1",
    "start": "622630",
    "end": "634770"
  },
  {
    "text": "plus min over a2 g of S prime\na2 plus h of S double prime.",
    "start": "634770",
    "end": "646530"
  },
  {
    "text": "I could just move\nthat min inside to the only terms that matter. ",
    "start": "646530",
    "end": "654670"
  },
  {
    "text": "This is intended to be\na moment of clarity, and I don't see a\nclarity on your faces.",
    "start": "654670",
    "end": "661000"
  },
  {
    "text": "Does that make sense, that\nthis doesn't depend on a2? I know I'm going to- a1 is\nmy action at time N minus 2.",
    "start": "661000",
    "end": "669646"
  },
  {
    "text": "a2 is my action at N minus 1. The action I take next time\nhas absolutely no effect",
    "start": "669646",
    "end": "677011"
  },
  {
    "text": "on my current state\nor my current action. ",
    "start": "677012",
    "end": "683399"
  },
  {
    "text": "So the great thing is\nthis here is just--",
    "start": "683400",
    "end": "690090"
  },
  {
    "text": "this whole term\nright here is just J star of S prime at, I'm\ncalling it, N minus 1 here.",
    "start": "690090",
    "end": "700980"
  },
  {
    "start": "700980",
    "end": "709310"
  },
  {
    "text": "So it's really the\nfact that we're taking this min over\nthis additive form that",
    "start": "709310",
    "end": "716790"
  },
  {
    "text": "allows us to write the recursive\nstatement like this that says,",
    "start": "716790",
    "end": "724320"
  },
  {
    "text": "the best thing I can\ndo with additive cost and all these things is\nto, in a single step,",
    "start": "724320",
    "end": "732550"
  },
  {
    "text": "take the action which minimizes\nmy one step cost combined",
    "start": "732550",
    "end": "737850"
  },
  {
    "text": "with the cost I'm going to\nget from being in the state I transition to for\nthe rest of time.",
    "start": "737850",
    "end": "746160"
  },
  {
    "text": "It's a magical thing. At whatever time I'm at, I only\nhave to think one action ahead",
    "start": "746160",
    "end": "752790"
  },
  {
    "text": "if I've already got my\nJ star computed, OK.",
    "start": "752790",
    "end": "758089"
  },
  {
    "text": "Simultaneously, it's\nsaying that I can compute the optimal cost to go. I could compute the optimal--",
    "start": "758090",
    "end": "765690"
  },
  {
    "text": "I know exactly how\nmuch cost I'm going to incur from any state, given\nI follow the optimal policy,",
    "start": "765690",
    "end": "771600"
  },
  {
    "text": "if I just work\nbackwards in time. And when I'm in\ntime N minus 1, I don't have to think\nabout the actions I",
    "start": "771600",
    "end": "777720"
  },
  {
    "text": "was going to take beforehand. As long as I know\nwhat state I'm in, because that state\nencompasses every action I've",
    "start": "777720",
    "end": "783840"
  },
  {
    "text": "taken in the past, that state\ncontains all the information, all I have to think\nabout is the last action",
    "start": "783840",
    "end": "791490"
  },
  {
    "text": "I'm going to take to decide\nmy optimal policy one step from the end of time, OK.",
    "start": "791490",
    "end": "797320"
  },
  {
    "start": "797320",
    "end": "803070"
  },
  {
    "text": "So the fact that you\ncan solve these things backwards in time, that's the\nprinciple of optimality, OK.",
    "start": "803070",
    "end": "812879"
  },
  {
    "text": " Ask questions if you\ndon't like what I said. ",
    "start": "812880",
    "end": "822670"
  },
  {
    "start": "814000",
    "end": "973000"
  },
  {
    "text": "I think that the graphics\nthat are about to come are going to make\nthings clear, too.",
    "start": "822670",
    "end": "829520"
  },
  {
    "text": "OK, so what does that mean? What are the\nimplications of that? ",
    "start": "829520",
    "end": "845910"
  },
  {
    "text": "All right, for the\nadditive costs,",
    "start": "845910",
    "end": "855100"
  },
  {
    "text": "I can compute J star recursively\nfrom the end of time, which,",
    "start": "855100",
    "end": "874199"
  },
  {
    "text": "in this case, is N back to 0. ",
    "start": "874200",
    "end": "886940"
  },
  {
    "text": "And the optimal action,\nthe optimal policy, which I then want to\ncall pi star, which",
    "start": "886940",
    "end": "894350"
  },
  {
    "text": "could in general depend on the\ntime, is just argmin over a.",
    "start": "894350",
    "end": "904982"
  },
  {
    "text": "It's the action which\nminimizes that same expression. ",
    "start": "904982",
    "end": "924120"
  },
  {
    "text": "So I can compute J star\nrecursively backwards in time, and if I know J star,\nthen I essentially know",
    "start": "924120",
    "end": "933180"
  },
  {
    "text": "my optimal policy. I know the best action, OK. So but for this reason, the\nfact that the cost to go,",
    "start": "933180",
    "end": "943800"
  },
  {
    "text": "the cost I expect to\nincur given I'm in state S and I'm running from\ntime N, the cost to go",
    "start": "943800",
    "end": "949102"
  },
  {
    "text": "becomes a very central\nconstruct in optimal control. ",
    "start": "949103",
    "end": "954490"
  },
  {
    "text": "All right, so part\nof the goal for today is to give you some more\nintuition about J star,",
    "start": "954490",
    "end": "962339"
  },
  {
    "text": "OK, because it's actually\na very intuitive thing, but you can be lost, I\nthink, in the equations.",
    "start": "962340",
    "end": "970570"
  },
  {
    "text": "So let's give you more\nintuition about that. I'm going to do that by\ngetting a little bit more abstract, well, simultaneously\nabstract and concrete.",
    "start": "970570",
    "end": "980880"
  },
  {
    "start": "973000",
    "end": "1179000"
  },
  {
    "text": " AUDIENCE: [INAUDIBLE]",
    "start": "980880",
    "end": "988200"
  },
  {
    "text": "PROFESSOR: Because\nit's finite horizon. AUDIENCE: You know\nthat the reward function is dependent on time.",
    "start": "988200",
    "end": "995722"
  },
  {
    "text": "PROFESSOR: I haven't\nincluded that. You can make the reward\nfunction depend on time. But even if the reward function,\nor cost function in my world,",
    "start": "995722",
    "end": "1003720"
  },
  {
    "text": "is-- there's a difference between\noptimal control people and reinforcement\nlearning people.",
    "start": "1003720",
    "end": "1010100"
  },
  {
    "text": "The optimal control\npeople are pessimists. Everything's a cost. And the reward reinforcement\nlearning people",
    "start": "1010100",
    "end": "1015600"
  },
  {
    "text": "give rewards out. So I guess I'm a pessimist. So yeah, so my cost is actually\nnot a function of time.",
    "start": "1015600",
    "end": "1021930"
  },
  {
    "text": "I could have made it that. But because there's a\nfinite horizon time, that means my policy and my\ncost to go function still",
    "start": "1021930",
    "end": "1029363"
  },
  {
    "text": "depends on time. ",
    "start": "1029363",
    "end": "1035010"
  },
  {
    "text": "Because if time\nends in one step, I'm going to do something\ndifferent than if time ends arbitrarily far in the future.",
    "start": "1035010",
    "end": "1042410"
  },
  {
    "text": "OK. So we're going to-- my goal here is to get\nintuition about cost to go",
    "start": "1042410",
    "end": "1057020"
  },
  {
    "text": "and dynamic programming, which\nI'm often going to call DP, OK. And I'm going to do it with\nthe grid world example.",
    "start": "1057020",
    "end": "1064040"
  },
  {
    "text": "This is right out of the\nreinforcement learning books.",
    "start": "1064040",
    "end": "1069340"
  },
  {
    "text": " OK, so in that\npendulum phase plot,",
    "start": "1069340",
    "end": "1079550"
  },
  {
    "text": "I discretized the\nstate space, and I started talking about\ntransitions between states, OK.",
    "start": "1079550",
    "end": "1086330"
  },
  {
    "text": "I can make that even more\ntransparent by saying, OK, now you're a\ntrashcan robot in a room.",
    "start": "1086330",
    "end": "1095630"
  },
  {
    "text": "You're going to be in\none of these tiles. You're on one of these\nblocks, so there's",
    "start": "1095630",
    "end": "1101990"
  },
  {
    "text": "a finite, discrete\nstate space, OK. I won't draw a trashcan\nrobot, but let's say I'm here.",
    "start": "1101990",
    "end": "1111110"
  },
  {
    "text": "And when you're here, you\nhave five discrete actions you can take.",
    "start": "1111110",
    "end": "1116630"
  },
  {
    "text": "You can move up, you can\nmove right, down, left,",
    "start": "1116630",
    "end": "1122000"
  },
  {
    "text": "or you can sit still. OK. ",
    "start": "1122000",
    "end": "1141409"
  },
  {
    "text": "And discrete states\nand discrete time.",
    "start": "1141410",
    "end": "1148520"
  },
  {
    "text": "Every time you take an\naction, in the next time step, you'll be in the next grid box.",
    "start": "1148520",
    "end": "1154910"
  },
  {
    "text": " OK.",
    "start": "1154910",
    "end": "1161770"
  },
  {
    "text": "Let's say I've got a goal\nstate somewhere in the world.",
    "start": "1161770",
    "end": "1167950"
  },
  {
    "text": "Well, we can formulate plenty\nof good optimal control problems to get us to that goal state. ",
    "start": "1167950",
    "end": "1176200"
  },
  {
    "text": "So plenty of good\ncost to go functions",
    "start": "1176200",
    "end": "1183210"
  },
  {
    "start": "1179000",
    "end": "1534000"
  },
  {
    "text": "in the additive form-- ",
    "start": "1183210",
    "end": "1198280"
  },
  {
    "text": "let's say I want to do minimum-- I want to get there\nin the minimum time. ",
    "start": "1198280",
    "end": "1210560"
  },
  {
    "text": "Well, then I can just\nset g of S, a to be--",
    "start": "1210560",
    "end": "1216020"
  },
  {
    "text": " to actually have it\nin units of time,",
    "start": "1216020",
    "end": "1221105"
  },
  {
    "text": "I should put a 1 if S\nis not at the goal and 0",
    "start": "1221105",
    "end": "1230540"
  },
  {
    "text": "if S is in the goal, OK. ",
    "start": "1230540",
    "end": "1240290"
  },
  {
    "text": "And I don't actually\ncare about actions. I have five discrete\nactions I can pick from whenever I'm in a state.",
    "start": "1240290",
    "end": "1249330"
  },
  {
    "text": "If I'm not at the goal, I'm\ngoing to incur a cost of 1. So it's in my best interest\nas a trashcan robot",
    "start": "1249330",
    "end": "1256550"
  },
  {
    "text": "to get to the goal. If I'm minimizing\nthat cost, I'm going to get the goal as\nfast as possible.",
    "start": "1256550",
    "end": "1261710"
  },
  {
    "text": "And actually, the\nunits, the cost to go will tell me the number\nof steps to get there.",
    "start": "1261710",
    "end": "1267635"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Right. So I'm going to do\nthat graphically.",
    "start": "1267635",
    "end": "1273140"
  },
  {
    "text": "But let's say there's\na finite horizon now, but this is how I'm going to\nget to infinite horizon, so. ",
    "start": "1273140",
    "end": "1285890"
  },
  {
    "text": "And let's say that\nh of S is just 0. ",
    "start": "1285890",
    "end": "1292027"
  },
  {
    "text": "I don't really care where\nI am at the end of time. ",
    "start": "1292027",
    "end": "1298360"
  },
  {
    "text": "Or I could have h of S\nbe this same function. That would be fine, too. ",
    "start": "1298360",
    "end": "1307029"
  },
  {
    "text": "OK.  How's is it going to look?",
    "start": "1307030",
    "end": "1312870"
  },
  {
    "text": "What is J-- well, let's\nbe specific about h.",
    "start": "1312870",
    "end": "1320190"
  },
  {
    "text": "Let's make h actually\nbe the same as g here. So I'll say it's g\nS with the 0 action.",
    "start": "1320190",
    "end": "1329220"
  },
  {
    "text": "So since this doesn't depend\non actions, it doesn't matter. Let's say h is the same\nfunction as g there.",
    "start": "1329220",
    "end": "1337140"
  },
  {
    "text": "So what does my cost to\ngo look like at time N?",
    "start": "1337140",
    "end": "1342300"
  },
  {
    "start": "1342300",
    "end": "1356926"
  },
  {
    "text": "My optimal cost to go\ngiven I'm in some state, and it's time N. This\nis a function over S,",
    "start": "1356926",
    "end": "1370040"
  },
  {
    "text": "and I'm time N. And\nwhat is that function? AUDIENCE: g. PROFESSOR: Yeah.",
    "start": "1370040",
    "end": "1376100"
  },
  {
    "text": "Well, if I'm not in\nthe goal, it's that.",
    "start": "1376100",
    "end": "1382580"
  },
  {
    "text": "It's the same as g,\nor h in this case. ",
    "start": "1382580",
    "end": "1393080"
  },
  {
    "text": "OK. What does g star of S\nN minus 1 look like?",
    "start": "1393080",
    "end": "1399799"
  },
  {
    "start": "1399800",
    "end": "1417500"
  },
  {
    "text": "Now I have time to\ntake one action, OK. ",
    "start": "1417500",
    "end": "1424380"
  },
  {
    "text": "So-- AUDIENCE: One step away\nfrom the goal is 1. If you're on the goal, it's\n0, but anywhere else, it would just be 1.",
    "start": "1424380",
    "end": "1429810"
  },
  {
    "text": "PROFESSOR: Awesome. Right? If I'm on the goal, I can do\nnothing, incur zero cost to go.",
    "start": "1429810",
    "end": "1439350"
  },
  {
    "text": "So the best thing for me\nto do if I'm on the goal",
    "start": "1439350",
    "end": "1444600"
  },
  {
    "text": "is to stay there, OK. If I'm a long way from\nthe goal, then I'm",
    "start": "1444600",
    "end": "1450690"
  },
  {
    "text": "not going to get to\nthe goal in two steps, so I'm going to incur\ntwo units of cost.",
    "start": "1450690",
    "end": "1456570"
  },
  {
    "text": " I'll say loosely far from goal.",
    "start": "1456570",
    "end": "1463290"
  },
  {
    "start": "1463290",
    "end": "1468600"
  },
  {
    "text": "And then there's this\nin-between place, which is if I'm one\nstep away from the goal, I can take the right action\nand get there and incur",
    "start": "1468600",
    "end": "1476468"
  },
  {
    "text": "only one unit of cost. ",
    "start": "1476468",
    "end": "1490053"
  },
  {
    "text": "All right, what's\nit going to be-- what's J S N minus\n2 going to be?",
    "start": "1490053",
    "end": "1495789"
  },
  {
    "text": "It's going to be 3,\n2, or 1, depending on how closely-- if\nI'm near the goal, I've got a chance of\ngetting to the goal",
    "start": "1495790",
    "end": "1502077"
  },
  {
    "text": "and stopping this\ninsane adding cost.",
    "start": "1502077",
    "end": "1507100"
  },
  {
    "text": "Stop the madness. Get to the goal. Otherwise, I'm going to just\nincur the cost no matter what I do, OK.",
    "start": "1507100",
    "end": "1514690"
  },
  {
    "text": "So what's the optimal policy? If I'm on the goal, what's the\nbest-- the best action to take is to sit still.",
    "start": "1514690",
    "end": "1520970"
  },
  {
    "text": "If I'm one step away from the\ngoal, the best thing to do is to move to the goal, whether\nit's up, down, left, or right.",
    "start": "1520970",
    "end": "1526745"
  },
  {
    "text": "What if I'm out here? What's the best\nthing for me to do? ",
    "start": "1526745",
    "end": "1531780"
  },
  {
    "text": "Doesn't matter at all. I can do anything I want. I'm still going\nto incur the cost,",
    "start": "1531780",
    "end": "1537340"
  },
  {
    "text": "so you might as well just choose\nyour policy at random, OK. So optimal policies\naren't necessarily unique.",
    "start": "1537340",
    "end": "1545080"
  },
  {
    "text": "Sometimes multiple actions\nare equally optimal. OK, here's your world.",
    "start": "1545080",
    "end": "1551130"
  },
  {
    "text": "I have put the goal always\nat 2,3, just randomly, OK.",
    "start": "1551130",
    "end": "1558060"
  },
  {
    "text": "You are a blue star. The goal is a red asterisk. It's a-- take you back to the\n'80s or something, video games.",
    "start": "1558060",
    "end": "1565990"
  },
  {
    "text": "OK. So let's just very simply-- I'm going to run this value\niteration algorithm on it, OK,",
    "start": "1565990",
    "end": "1574409"
  },
  {
    "text": "and I'm going to plot, at every\nstep of the algorithm, the cost to go, OK, and the\npolicy, actually.",
    "start": "1574410",
    "end": "1581850"
  },
  {
    "text": "So it's not going to be-- I have my more general\nvalue iteration code that's not going to be\nquite as beautiful, but--",
    "start": "1581850",
    "end": "1588960"
  },
  {
    "text": " [TYPING]",
    "start": "1588960",
    "end": "1597375"
  },
  {
    "start": "1597375",
    "end": "1606105"
  },
  {
    "text": "OK.  Well, that went pretty fast. There was supposed\nto be pause there.",
    "start": "1606105",
    "end": "1611630"
  },
  {
    "text": "Let me get that-- add a pause in\nthere quick, but-- ",
    "start": "1611630",
    "end": "1627480"
  },
  {
    "text": "OK.  Here is J at time--",
    "start": "1627480",
    "end": "1634700"
  },
  {
    "text": "at J at capital N.\nMy cost function is 0 if I'm at the goal,\n1 everywhere else, OK.",
    "start": "1634700",
    "end": "1642380"
  },
  {
    "text": "My policy, it doesn't\nmatter what I choose. I've actually chosen to do-- I didn't put this--",
    "start": "1642380",
    "end": "1648020"
  },
  {
    "text": "I didn't give you a key, but 0\nis the do nothing action, OK.",
    "start": "1648020",
    "end": "1653420"
  },
  {
    "text": "So this just has do\nnothing everywhere. This is the lazy\npolicy, I guess. And the cost it's\ngoing to get is",
    "start": "1653420",
    "end": "1659840"
  },
  {
    "text": "it's going to get no cost if\nit's at the goal, one cost if it's everywhere else. OK, if I'm now\ncomputing J S N minus 1,",
    "start": "1659840",
    "end": "1667010"
  },
  {
    "text": "you guys told me what that is. That says it's 0\nhere, it's 1 here, it's 2 everywhere else, right.",
    "start": "1667010",
    "end": "1673909"
  },
  {
    "text": "And the co-- now you\ncan see my key here. Orange must mean move down,\nred must mean move to the left,",
    "start": "1673910",
    "end": "1680090"
  },
  {
    "text": "green must mean move to\nthe right, and so on, OK. The value-- this\nbackwards propagation,",
    "start": "1680090",
    "end": "1687380"
  },
  {
    "text": "this dynamic\nprogramming propagation is a very beautiful and\nintuitive thing, OK.",
    "start": "1687380",
    "end": "1692659"
  },
  {
    "text": "Every time I take a step, a few\nmore states become reachable. ",
    "start": "1692660",
    "end": "1699440"
  },
  {
    "text": "In that amount of time,\nI can get to the goal. The resulting cost to\ngo function is simple.",
    "start": "1699440",
    "end": "1707313"
  },
  {
    "text": "It's just the distance, the\nnumber of cells from the goal, yeah. And the policy, again,\nit's not unique.",
    "start": "1707313",
    "end": "1712880"
  },
  {
    "text": "But this one, just\nbecause of the ordering I chose, and I just do\na min over the actions, says it's always going to\nmove down in that orange area,",
    "start": "1712880",
    "end": "1720890"
  },
  {
    "text": "it's always going to\nmove up in the blue area, and it's just going to-- so that's one of the\noptimal policies, all right.",
    "start": "1720890",
    "end": "1729740"
  },
  {
    "text": "Now Alborz asked\na good question, what's my horizon time? So I'm actually just working\nbackwards from some arbitrary",
    "start": "1729740",
    "end": "1739340"
  },
  {
    "text": "capital N and just\ngoing backwards in time further and further. But it turns out for this\nproblem, and for many problems,",
    "start": "1739340",
    "end": "1749779"
  },
  {
    "text": "everything converges, OK. After some amount of time,\nthe optimal cost to go",
    "start": "1749780",
    "end": "1756990"
  },
  {
    "text": "stops changing, and I know\nthat's my optimal policy.",
    "start": "1756990",
    "end": "1765170"
  },
  {
    "text": "Walk down. And this is too simple. This is painfully simple. But I think that\nintuition is going",
    "start": "1765170",
    "end": "1771240"
  },
  {
    "text": "to take us a long way with\nthe value methods, OK. ",
    "start": "1771240",
    "end": "1778720"
  },
  {
    "text": "AUDIENCE: So, Professor? PROFESSOR: Yeah. AUDIENCE: In this example, the\noptimal policy is not unique.",
    "start": "1778720",
    "end": "1784420"
  },
  {
    "text": "PROFESSOR: The optimal\npolicy is not unique. The guy could have just as well\ngone left first and then down. ",
    "start": "1784420",
    "end": "1791650"
  },
  {
    "text": "So how does that manifest\nitself in those equations? ",
    "start": "1791650",
    "end": "1799610"
  },
  {
    "text": "There's multiple min over a's. There's multiple a's that give\nme the same J star S and N",
    "start": "1799610",
    "end": "1806960"
  },
  {
    "text": "minus-- or plus 1, whatever. ",
    "start": "1806960",
    "end": "1812210"
  },
  {
    "text": "Multiple actions give me\nthe same long-term cost, so I could equally\npick any of them, yeah?",
    "start": "1812210",
    "end": "1818780"
  },
  {
    "text": "OK, to make a more\ncareful analogy to the more\ncontinuous world, that",
    "start": "1818780",
    "end": "1826630"
  },
  {
    "text": "was a perfectly good\nminimum time problem. I could have equally well chosen\na different cost function.",
    "start": "1826630",
    "end": "1833690"
  },
  {
    "text": "Oh wait, let's put the\nobstacles back in, all right. So the cool thing\nis obstacles aren't",
    "start": "1833690",
    "end": "1839338"
  },
  {
    "text": "going to make it any\nharder for us to solve this problem in our head. It's a nice observation\nthat they don't actually",
    "start": "1839338",
    "end": "1845930"
  },
  {
    "text": "make it any harder for the\nalgorithm to solve it either. And that's a general principle.",
    "start": "1845930",
    "end": "1851780"
  },
  {
    "text": "That's something I definitely\nwant you to get out of this course,\nis that when we're doing analytical optimal\ncontrol, every piece",
    "start": "1851780",
    "end": "1859790"
  },
  {
    "text": "you add to the dynamics makes\nthings cripplingly difficult. And so you have to stay with\nthese very simple dynamical",
    "start": "1859790",
    "end": "1865340"
  },
  {
    "text": "systems. OK, the computational\nalgorithms are actually pretty insensitive to how\ncomplex the dynamics are.",
    "start": "1865340",
    "end": "1871610"
  },
  {
    "text": "They're going to break down\nin a different way, OK. So there's these different\ntools for different-- that are",
    "start": "1871610",
    "end": "1877850"
  },
  {
    "text": "good for different problems. And there's a lot of problems\nwhich are very amenable to these computational\ntools that people aren't--",
    "start": "1877850",
    "end": "1884840"
  },
  {
    "text": "I mean, you can solve brand\nnew problems pretty easily with some of these algorithms.",
    "start": "1884840",
    "end": "1890300"
  },
  {
    "text": "OK, so let's think of\nanother cost function. ",
    "start": "1890300",
    "end": "1895799"
  },
  {
    "start": "1894000",
    "end": "2134000"
  },
  {
    "text": "Let's do the equivalent\nof a quadratic regulator.",
    "start": "1895800",
    "end": "1901149"
  },
  {
    "start": "1901149",
    "end": "1906507"
  },
  {
    "text": "I just had that whole\nspiel and forgot to run the boundary-- the\nobstacles together in Soapbox.",
    "start": "1906507",
    "end": "1913320"
  },
  {
    "start": "1913320",
    "end": "1924880"
  },
  {
    "text": "OK, so now I'm just going\nto put in some obstacle.",
    "start": "1924880",
    "end": "1930580"
  },
  {
    "text": "And if you see-- whoops, sorry. If my state--",
    "start": "1930580",
    "end": "1937186"
  },
  {
    "text": "OK, so I promised to use S and\na in my notes and on the board, but I guess I didn't\ndo it in my code. Sorry.",
    "start": "1937186",
    "end": "1942910"
  },
  {
    "text": "So x equals the goal,\nthen the cost to go is--",
    "start": "1942910",
    "end": "1948100"
  },
  {
    "text": "the cost, instantaneous\ncost, is 0. Otherwise it's 1. If there's an obstacle, I just\ngive it a high cost of 10. ",
    "start": "1948100",
    "end": "1957280"
  },
  {
    "text": "So if I put that obstacle\nfunction in there,",
    "start": "1957280",
    "end": "1965310"
  },
  {
    "text": "then I've got my same\n0 cost for the goal. I've got a 1 cost\nalmost everywhere,",
    "start": "1965310",
    "end": "1970570"
  },
  {
    "text": "but I've got a 10 there. That's my cost function. And as I backup, a couple\nof things happened.",
    "start": "1970570",
    "end": "1976809"
  },
  {
    "text": "First, this thing\nquickly figures out how to get off that\nobstacle as fast as possible and decides not to\ngo there anymore.",
    "start": "1976810",
    "end": "1984300"
  },
  {
    "text": "And then as you back\nup the cost function, the colors are a\nlittle more muted because I have this\nhigh color here.",
    "start": "1984300",
    "end": "1989669"
  },
  {
    "text": "But the same basic\nalgorithm plays out until it covers the space.",
    "start": "1989670",
    "end": "1995340"
  },
  {
    "text": " And my s-- oh, that was a-- [LAUGHTER]",
    "start": "1995340",
    "end": "2001940"
  },
  {
    "text": "--lucky initial condition. OK, good. Now he has to go around. Wow.",
    "start": "2001940",
    "end": "2007180"
  },
  {
    "text": " OK, so adding an obstacle in the\ngrid world is clearly trivial.",
    "start": "2007180",
    "end": "2014872"
  },
  {
    "text": "It's nice to think that adding\nan obstacle when I get back to the pendulum\nwould be trivial, because that's not trivial\nfor most of your other control",
    "start": "2014873",
    "end": "2021375"
  },
  {
    "text": "derivations. OK, so minimum-- the\nquadratic regulator now. ",
    "start": "2021375",
    "end": "2030210"
  },
  {
    "text": "Now here, the cost\nI want is x of u,",
    "start": "2030210",
    "end": "2035320"
  },
  {
    "text": "in the continuous world is some\nx minus x goal transpose Q x",
    "start": "2035320",
    "end": "2044620"
  },
  {
    "text": "minus x goal.  And you have to map that\ndown into the integer",
    "start": "2044620",
    "end": "2055210"
  },
  {
    "text": "world, the states. There's not a particularly\nclean way to write that,",
    "start": "2055210",
    "end": "2061030"
  },
  {
    "text": "so I'm just going to\nallow you to imagine that it's trivial to code.",
    "start": "2061030",
    "end": "2066250"
  },
  {
    "text": "Imagine that transition. ",
    "start": "2066250",
    "end": "2087819"
  },
  {
    "text": "OK, now my cost function\nis just penalizing me for being away from the goal.",
    "start": "2087820",
    "end": "2093310"
  },
  {
    "text": "But it's not a 0 and 1. It's penalizing me more smoothly\nfor being away from the goal. So what's the best thing to do?",
    "start": "2093310",
    "end": "2100310"
  },
  {
    "text": "The best thing to do is\nstill to get to the goal as quickly as possible. It actually doesn't really\nchange the optimal policy here,",
    "start": "2100310",
    "end": "2106840"
  },
  {
    "text": "but it's a more\nsmooth cost function, which, in some problems,\ngives you nice properties.",
    "start": "2106840",
    "end": "2114680"
  },
  {
    "text": "It turns out the optimal policy\nis more unique in this case. ",
    "start": "2114680",
    "end": "2120467"
  },
  {
    "text": "But that would have been an\noptimal for the minimum time problem, too. And it converges nicely and goes\nto the goal in the same way,",
    "start": "2120467",
    "end": "2133607"
  },
  {
    "text": "and works fine with the\nobstacle, of course. ",
    "start": "2133607",
    "end": "2139569"
  },
  {
    "start": "2134000",
    "end": "2374000"
  },
  {
    "text": "OK? ",
    "start": "2139570",
    "end": "2145080"
  },
  {
    "text": "Good. So now you have a little\nbit more intuition",
    "start": "2145080",
    "end": "2151380"
  },
  {
    "text": "to work with on these\ncost to go functions. A couple of important\nthings happened there",
    "start": "2151380",
    "end": "2158130"
  },
  {
    "text": "that I want to highlight. First of all, I really want\nyou to think in terms of cost",
    "start": "2158130",
    "end": "2164715"
  },
  {
    "text": "to go functions. They're really intuitive. ",
    "start": "2164715",
    "end": "2170790"
  },
  {
    "text": "The cost that I will obtain\ntill the end of time, the optimal cost to go says\nif I'm acting optimally,",
    "start": "2170790",
    "end": "2178320"
  },
  {
    "text": "this is the cost\nI'm going to incur. And the optimal cost to go\ngives me the optimal policy, OK.",
    "start": "2178320",
    "end": "2184630"
  },
  {
    "text": " And just to calibrate\nyou here, J star",
    "start": "2184630",
    "end": "2191640"
  },
  {
    "text": "is called the\noptimal cost to go, but it's also sometimes called\na value function, optimal value",
    "start": "2191640",
    "end": "2198190"
  },
  {
    "text": "function. ",
    "start": "2198190",
    "end": "2213422"
  },
  {
    "text": "A bunch of different communities\ntalk about the same things with different words.",
    "start": "2213422",
    "end": "2219000"
  },
  {
    "text": "These are the optimists. These are the pessimists. ",
    "start": "2219000",
    "end": "2228400"
  },
  {
    "text": "OK, the other thing that we\nsaw is that for many problems,",
    "start": "2228400",
    "end": "2239140"
  },
  {
    "text": "the limit as N goes\nto negative infinity--",
    "start": "2239140",
    "end": "2245799"
  },
  {
    "text": " I know that's a silly thing\nto say, I guess, but--",
    "start": "2245800",
    "end": "2253990"
  },
  {
    "text": " that a lot of times\nthis thing actually",
    "start": "2253990",
    "end": "2260260"
  },
  {
    "text": "goes to some well posed J star.",
    "start": "2260260",
    "end": "2268696"
  },
  {
    "text": "It doesn't have to. Sometimes it blows up. ",
    "start": "2268696",
    "end": "2277330"
  },
  {
    "text": "Another way to think of\nthis is that I said J S of N",
    "start": "2277330",
    "end": "2285670"
  },
  {
    "text": "is S of capital N. It's the\nlimit of this as capital",
    "start": "2285670",
    "end": "2300400"
  },
  {
    "text": "N goes to infinity, if you\nthink of it in the forward way. So in order for this thing to\nconverge to some nice solution,",
    "start": "2300400",
    "end": "2311740"
  },
  {
    "text": "this sum had better\nconverge in the limit. ",
    "start": "2311740",
    "end": "2318760"
  },
  {
    "text": "For my choice of g for\nthe minimum time problem, and for the quadratic\nregulator, both of these",
    "start": "2318760",
    "end": "2325472"
  },
  {
    "text": "had the property that\nwhen you get to the goal, you stop incurring cost.",
    "start": "2325472",
    "end": "2330900"
  },
  {
    "text": "So that integral-- as long\nas you can get to the goal, that integral-- the sum,\nsorry, is going to converge.",
    "start": "2330900",
    "end": "2336225"
  },
  {
    "text": " If I had chosen that\nI give a cost of 1",
    "start": "2336225",
    "end": "2344190"
  },
  {
    "text": "when I'm at the goal and\n2 when I'm anywhere else, then it wouldn't have converged. ",
    "start": "2344190",
    "end": "2352099"
  },
  {
    "text": "The cost to go would have\ngone to that same shape, but then that shape\nwould have just kept increasing every time\nI go farther back in time.",
    "start": "2352100",
    "end": "2358430"
  },
  {
    "text": "That whole function\nwould just move up by one every increment of time, OK. But for a lot of\nproblems, we do have",
    "start": "2358430",
    "end": "2366140"
  },
  {
    "text": "this nice limiting behavior,\nOK, and that gives rise",
    "start": "2366140",
    "end": "2372349"
  },
  {
    "text": "to the infinite\nhorizon problems. ",
    "start": "2372350",
    "end": "2382320"
  },
  {
    "start": "2374000",
    "end": "2534000"
  },
  {
    "text": "So so far, I had talked\nabout finite horizon, but a lot of time,\na lot of problems we write as infinite horizon.",
    "start": "2382320",
    "end": "2387448"
  },
  {
    "start": "2387448",
    "end": "2403059"
  },
  {
    "text": "OK.  When your problems are\ninfinite horizon, J and J star",
    "start": "2403059",
    "end": "2410240"
  },
  {
    "text": "don't depend on time anymore. And the optimal policy\ndoesn't depend on time.",
    "start": "2410240",
    "end": "2417500"
  },
  {
    "text": "So J star and pi, all these\nthings are just functions of S,",
    "start": "2417500",
    "end": "2423940"
  },
  {
    "text": "not of time, OK. ",
    "start": "2423940",
    "end": "2437290"
  },
  {
    "text": "And for these to be well posed,\nthat sum had better converge. ",
    "start": "2437290",
    "end": "2464650"
  },
  {
    "text": "Now just to say it, but not to\ndwell on it, a lot of people do write other formulations\nthat handle that.",
    "start": "2464650",
    "end": "2472480"
  },
  {
    "text": "For instance, a lot of\npeople do discounting.",
    "start": "2472480",
    "end": "2478660"
  },
  {
    "text": "A lot of people like to solve\nproblems of this form, OK, just",
    "start": "2478660",
    "end": "2490569"
  },
  {
    "text": "to make it more likely that\nthat sum's going to converge,",
    "start": "2490570",
    "end": "2497080"
  },
  {
    "text": "for instance. And there's some problems which\nreally do have discounting. Yeah. AUDIENCE: So that's\nless than 1 [INAUDIBLE]..",
    "start": "2497080",
    "end": "2502980"
  },
  {
    "text": "PROFESSOR: Yes, thank you. Good. Good call. ",
    "start": "2502980",
    "end": "2511500"
  },
  {
    "text": "Thank you. ",
    "start": "2511500",
    "end": "2525760"
  },
  {
    "text": "OK, so you know the\nbasic dynamic programming equations, no?",
    "start": "2525760",
    "end": "2532480"
  },
  {
    "text": "Let me just say one word\nabout implementation,",
    "start": "2532480",
    "end": "2537660"
  },
  {
    "start": "2534000",
    "end": "2734000"
  },
  {
    "text": "if you want to go home and\nmake your own '80s graphics game in Matlab. ",
    "start": "2537660",
    "end": "2547000"
  },
  {
    "text": "For discrete states,\ndiscrete actions, J,",
    "start": "2547000",
    "end": "2562345"
  },
  {
    "text": "even J star of S at\nsome N, it's a vector.",
    "start": "2562345",
    "end": "2567730"
  },
  {
    "start": "2567730",
    "end": "2573550"
  },
  {
    "text": "Typically I think of it as\nsort of a dimension of S",
    "start": "2573550",
    "end": "2580060"
  },
  {
    "text": "by one vector.  And dimension isn't\nthe right word.",
    "start": "2580060",
    "end": "2586135"
  },
  {
    "text": "This is-- so the\ncardinality of S,",
    "start": "2586135",
    "end": "2592620"
  },
  {
    "text": "let's say, something\nlike that, a big S, the number of possible\nstates by one vector.",
    "start": "2592620",
    "end": "2599710"
  },
  {
    "text": " And it's very practical to write\nthat recursion for all states",
    "start": "2599710",
    "end": "2610880"
  },
  {
    "text": "as a vector equation. So if I think of J\nstar as being a vector,",
    "start": "2610880",
    "end": "2618349"
  },
  {
    "text": "I have to do a min\nover a of g S, a. But g is another vector\nwhich depends on a.",
    "start": "2618350",
    "end": "2628950"
  },
  {
    "text": "It's an S by 1 plus-- ",
    "start": "2628950",
    "end": "2650030"
  },
  {
    "text": "I can write it as\na vector equation where this is a vector. This is a matrix. This is the transition matrix.",
    "start": "2650030",
    "end": "2655535"
  },
  {
    "start": "2655535",
    "end": "2664220"
  },
  {
    "text": "And this is my vector again.  And then transition\nmatrix is just 1 if f iA",
    "start": "2664220",
    "end": "2692336"
  },
  {
    "text": "equals J and 0 otherwise. ",
    "start": "2692336",
    "end": "2708049"
  },
  {
    "text": "OK. That's just a standard\ngraph notation. ",
    "start": "2708050",
    "end": "2716830"
  },
  {
    "text": "So it's trivial to code\nthese things in Matlab with just a bunch of\nmatrix manipulations. ",
    "start": "2716830",
    "end": "2724910"
  },
  {
    "text": "OK, we understand everything\nabout the grid world. I think it is a very\nhelpful example, actually.",
    "start": "2724910",
    "end": "2732500"
  },
  {
    "text": "Now let's think about the\nmore continuous problems that I care about. What if, instead of having\nthe dynamics of this",
    "start": "2732500",
    "end": "2744109"
  },
  {
    "start": "2734000",
    "end": "3094000"
  },
  {
    "text": "moving left, right, whatever,\nmy dynamics, my transitions came from my equations of motion\nfrom one of the systems",
    "start": "2744110",
    "end": "2750020"
  },
  {
    "text": "we care about? So let's think about\nthe double integrator.",
    "start": "2750020",
    "end": "2776690"
  },
  {
    "text": "q double dot equals u. Let's do the min time problem. ",
    "start": "2776690",
    "end": "2784650"
  },
  {
    "text": "I can use the same minimum time\ncost function I did before, OK.",
    "start": "2784650",
    "end": "2789700"
  },
  {
    "start": "2789700",
    "end": "2808126"
  },
  {
    "text": "[TYPING] ",
    "start": "2808126",
    "end": "2823130"
  },
  {
    "text": "OK. This one, I didn't leave\nthe pause in there,",
    "start": "2823130",
    "end": "2829190"
  },
  {
    "text": "but look what happens. Oops, sorry. Meant to do that.",
    "start": "2829190",
    "end": "2835069"
  },
  {
    "text": "Make it bigger.  I pop the same--",
    "start": "2835070",
    "end": "2841010"
  },
  {
    "text": "let me turn the lights down. I pop that same exact\nset of equations.",
    "start": "2841010",
    "end": "2847119"
  },
  {
    "text": "I run the same value iteration\nalgorithm, dynamic programming algorithm.",
    "start": "2847120",
    "end": "2852660"
  },
  {
    "text": "I should have said,\npeople tend to call it value iteration for when you\ntake the infinite horizon",
    "start": "2852660",
    "end": "2858789"
  },
  {
    "text": "version and dynamic\nprogramming if you call it-- if you do the finite\nhorizon, but they're",
    "start": "2858790",
    "end": "2864190"
  },
  {
    "text": "exactly the same thing, OK. So I might accidentally\nsay value iteration because I'm used to it.",
    "start": "2864190",
    "end": "2870730"
  },
  {
    "text": "OK, so I took my double\nintegrator dynamics.",
    "start": "2870730",
    "end": "2877150"
  },
  {
    "text": "I discretized my space. I made my cost function\nexactly the same as the minimum\ntime cost function",
    "start": "2877150",
    "end": "2883510"
  },
  {
    "text": "I used in the grid\nworld, where there's a 0 cost of being at the\ngoal and 1 everywhere else.",
    "start": "2883510",
    "end": "2889480"
  },
  {
    "text": "And look what pops out. This is the cost to go function,\nis a function of state, and that's the policy.",
    "start": "2889480",
    "end": "2895300"
  },
  {
    "text": " Remind you of anything?",
    "start": "2895300",
    "end": "2900320"
  },
  {
    "text": "Right? Now I've got a big\ndisclaimer that goes at the end of the lecture,\nbut for now, let's just",
    "start": "2900320",
    "end": "2905780"
  },
  {
    "text": "say that that's the\nperfect solution.  The discretization is going to\nmake this thing a little bit",
    "start": "2905780",
    "end": "2912740"
  },
  {
    "text": "wrong. I'm going to say a\nfew things about that at the end of the class. But the cool thing is that\nI pop my cost function in.",
    "start": "2912740",
    "end": "2921560"
  },
  {
    "text": "I pop my continuous\ndynamical system. It's discretized. [CLICK] Run dynamic programming.",
    "start": "2921560",
    "end": "2927920"
  },
  {
    "text": "As I back it up, it\nconverges to some-- as N goes back, it\ndoes converge for this.",
    "start": "2927920",
    "end": "2933230"
  },
  {
    "text": "It was the minimum time problem. And I get my optimal\npolicy out, which is a bang bang policy,\nwhich is decelerate",
    "start": "2933230",
    "end": "2939488"
  },
  {
    "text": "when you're at the\nbottom, accelerate when you're at that top. And that switching\nsurface shows up in green just because it's interpolated.",
    "start": "2939488",
    "end": "2945200"
  },
  {
    "text": "But when you know it, that's\nwhat we know about bang bang",
    "start": "2945200",
    "end": "2952520"
  },
  {
    "text": "controllers, OK. Yeah. AUDIENCE: Did you have to\nencode that your only three actions were full forward,\nfull backward, and--",
    "start": "2952520",
    "end": "2960315"
  },
  {
    "text": "PROFESSOR: The minimum\nover a is always going to choose the rails. In fact, in this\nimplementation, they",
    "start": "2960315",
    "end": "2966462"
  },
  {
    "text": "could have chosen in\nbetween things, and that's what it did right on the\nswitching surface because of some-- it chose 0. AUDIENCE: OK, so you left\nthe general just as--",
    "start": "2966462",
    "end": "2972860"
  },
  {
    "text": "PROFESSOR: I left it general. Yeah. So always, when I\ndiscretize the state",
    "start": "2972860",
    "end": "2977869"
  },
  {
    "text": "and I discretize the actions\nof these continuous problems, I'm left with a\nfinite set of states, a finite set of actions.",
    "start": "2977870",
    "end": "2983039"
  },
  {
    "text": "So it can't pick unbounded. It's fundamentally bounded in\nactions that it can choose,",
    "start": "2983040",
    "end": "2989210"
  },
  {
    "text": "and it chose those bounds. AUDIENCE: [INAUDIBLE] PROFESSOR: Say it again.",
    "start": "2989210",
    "end": "2994760"
  },
  {
    "text": "AUDIENCE: How do you define\nthe transition model? PROFESSOR: Good. I'm going to say some words\nabout that in a minute,",
    "start": "2994760",
    "end": "3000099"
  },
  {
    "text": "too, OK. Yeah. But not yet. Just give me a minute.",
    "start": "3000100",
    "end": "3005740"
  },
  {
    "text": "OK, let's say we\nwant to solve the LQR problem, the quadratic\nregulator cost for this.",
    "start": "3005740",
    "end": "3013059"
  },
  {
    "start": "3013060",
    "end": "3018880"
  },
  {
    "text": "[TYPING] ",
    "start": "3018880",
    "end": "3028580"
  },
  {
    "text": "So I animated the brick for\nyou just to keep it exciting.",
    "start": "3028580",
    "end": "3035120"
  },
  {
    "text": "OK, so what pops out? This beautiful quadratic\ncost to go function, OK.",
    "start": "3035120",
    "end": "3041690"
  },
  {
    "text": "Now this is a little bit off. It's supposed to be\na linear function. It almost is, but there's\nsome saturation because",
    "start": "3041690",
    "end": "3048920"
  },
  {
    "text": "of my actuator limits, OK. But within the resolution of\nsort of my discrete actions,",
    "start": "3048920",
    "end": "3056670"
  },
  {
    "text": "that's what we expected, OK. So I can do this for the brick.",
    "start": "3056670",
    "end": "3062550"
  },
  {
    "text": "I'm going to tell you the\ncaveats again in a minute, and I'm going to tell you the\ninterpolation in a minute. But first I just want to\nhelp you realize that this--",
    "start": "3062550",
    "end": "3069660"
  },
  {
    "text": "we can pop these\nequations in if we're willing to discretize the\nstate and action space. Even for pretty hard problems,\nI can just [CLICK] let it go.",
    "start": "3069660",
    "end": "3077760"
  },
  {
    "text": "It's pretty fast, too, actually. ",
    "start": "3077760",
    "end": "3083340"
  },
  {
    "text": "OK. So now why not--",
    "start": "3083340",
    "end": "3088380"
  },
  {
    "text": "analytically, we had a hard\ntime doing the pendulum, those nonlinear equations, OK.",
    "start": "3088380",
    "end": "3093660"
  },
  {
    "text": "But if we tile the space,\nturn it into a graph, then I can run the\nexact same algorithm on the simple pendulum, OK.",
    "start": "3093660",
    "end": "3100710"
  },
  {
    "start": "3094000",
    "end": "3599000"
  },
  {
    "text": "So let's do that. ",
    "start": "3100710",
    "end": "3106700"
  },
  {
    "text": "[TYPING] ",
    "start": "3106700",
    "end": "3115540"
  },
  {
    "text": "What am I going to get here? So minimum time for\nthe simple pendulum.",
    "start": "3115540",
    "end": "3122000"
  },
  {
    "text": " I've got my pause back in here.",
    "start": "3122000",
    "end": "3128540"
  },
  {
    "text": "It's hard to see, but\nthere's actually-- it's 1 everywhere except for\n0 at the goal, which is the-- now I'm in phase space,\nso that's pi at 0.",
    "start": "3128540",
    "end": "3137540"
  },
  {
    "text": "That's my unsteady\nfixed point, OK. I've got a blue 0 there,\n1 everywhere else.",
    "start": "3137540",
    "end": "3145670"
  },
  {
    "text": "At the end of time, my\naction is just do nothing, because there's no\nbenefit to doing anything.",
    "start": "3145670",
    "end": "3151069"
  },
  {
    "text": "And as I back up in time, this\nwill give you a key to what--",
    "start": "3151070",
    "end": "3156238"
  },
  {
    "text": "you can see a little bit about\nmy interpolation as I do this. OK, then it starts giving\nme incentive to move.",
    "start": "3156238",
    "end": "3165710"
  },
  {
    "text": "Again, when you can't\nget to the goal, that's actually\njust noise there.",
    "start": "3165710",
    "end": "3171890"
  },
  {
    "text": "But this thing\nquickly figures out-- ",
    "start": "3171890",
    "end": "3180920"
  },
  {
    "text": "oops.  Let me do the same thing and\nlet it not plot every time.",
    "start": "3180920",
    "end": "3191529"
  },
  {
    "start": "3191530",
    "end": "3202060"
  },
  {
    "text": "Figures out a cost\nto go function, the optimal cost to go\nfunction, and an optimal policy.",
    "start": "3202060",
    "end": "3208150"
  },
  {
    "text": "Now it looks a\nlittle noisy there. Again, we're going to\ntalk about the sensitivity to discretization.",
    "start": "3208150",
    "end": "3213760"
  },
  {
    "text": "But this is very\nmuch a bang bang policy, with the\nblue area being,",
    "start": "3213760",
    "end": "3219550"
  },
  {
    "text": "do one action, the red area\ndoing the other action. The switching surface is\nactually pretty complicated.",
    "start": "3219550",
    "end": "3228200"
  },
  {
    "text": "It's some complicated\nfunction of state, but it gets this beautifully\nsmooth cost to go function, OK.",
    "start": "3228200",
    "end": "3236190"
  },
  {
    "start": "3236190",
    "end": "3243880"
  },
  {
    "text": "Now let's take a second and\nlook at the phase plots here. ",
    "start": "3243880",
    "end": "3249802"
  },
  {
    "text": "Let me actually do\nit in order here. So this is the phase plot of\nthe damped passive pendulum,",
    "start": "3249802",
    "end": "3266450"
  },
  {
    "text": "OK, the original one we\nthought about in class. I just drew a few\nlines to help you.",
    "start": "3266450",
    "end": "3273450"
  },
  {
    "text": "So if I start at\ndownright position with a little bit of velocity,\nI'd slow down and stop.",
    "start": "3273450",
    "end": "3280220"
  },
  {
    "text": "If I start near an\nunstable fixed point with near 0 velocity,\nthen I actually",
    "start": "3280220",
    "end": "3287180"
  },
  {
    "text": "fall down and go like this\nand end up standing still near the closest\nunstable fixed point, OK.",
    "start": "3287180",
    "end": "3294860"
  },
  {
    "text": " Now if I do my feedback\nlinearization invert gravity",
    "start": "3294860",
    "end": "3303740"
  },
  {
    "text": "controller to stabilize\nthe fixed point, then what's the phase plot\ngoing to look like? ",
    "start": "3303740",
    "end": "3313233"
  },
  {
    "text": "It's going to look\njust like this, but it's going to be\nmoved over there, right? So let's make sure that's true.",
    "start": "3313233",
    "end": "3319460"
  },
  {
    "text": " Ah, what did I call it?",
    "start": "3319460",
    "end": "3326065"
  },
  {
    "text": "Invert gravity.  OK, yeah.",
    "start": "3326065",
    "end": "3332079"
  },
  {
    "text": "So I see the exact same things. Used to be my stable fixed\npoint are now going over to the closest unstable one.",
    "start": "3332080",
    "end": "3339789"
  },
  {
    "text": "This works great. The only objection\nto it is it required an enormous amount of\ntorque to just pretend like you're inverted gravity.",
    "start": "3339790",
    "end": "3346670"
  },
  {
    "text": "OK, so what's the minimum time\nsolution going to look like? ",
    "start": "3346670",
    "end": "3362710"
  },
  {
    "text": "AUDIENCE: It's going\nto depend on what your torque constraint is. PROFESSOR: It's going\nto depend on my torque constraint is, yeah.",
    "start": "3362710",
    "end": "3370220"
  },
  {
    "text": "So for whatever torque\nconstraint I have now, you could even figure\nout the units here.",
    "start": "3370220",
    "end": "3375500"
  },
  {
    "text": "My torque constraint was\nchosen to be something like half of the stall torque\nrequired to hold out like this.",
    "start": "3375500",
    "end": "3383190"
  },
  {
    "text": "Then let's see what happens. ",
    "start": "3383190",
    "end": "3389380"
  },
  {
    "text": "This is the minimum\ntime solution, which is exactly right.",
    "start": "3389380",
    "end": "3395070"
  },
  {
    "text": "If I had more torque\nto give, it could have gotten out there quicker. And this added enough that,\nafter going around once,",
    "start": "3395070",
    "end": "3403349"
  },
  {
    "text": "it could get up to the top, OK. ",
    "start": "3403350",
    "end": "3414520"
  },
  {
    "text": "Let me see. Why is it not drawing anymore? I've got this [INAUDIBLE]. ",
    "start": "3414520",
    "end": "3425085"
  },
  {
    "text": "Oop. So that was-- that's a\nrandom initial condition. So from the one I had\nshown, it took one pump.",
    "start": "3425085",
    "end": "3430580"
  },
  {
    "text": "That one took two pumps,\nand that gets it to the top. OK, but now, remember,\nmy original challenge",
    "start": "3430580",
    "end": "3437420"
  },
  {
    "text": "was to not just get to\nthe top in minimum time. This is minimum time\nwith bounded torque, so that's a little\nbit more satisfying.",
    "start": "3437420",
    "end": "3443900"
  },
  {
    "text": "I don't want to\npump in more torque than I could possibly implement. But what if I want to be\nsensitive about the torque?",
    "start": "3443900",
    "end": "3450758"
  },
  {
    "text": "I want to get to\nthe top, but I don't want to use a bunch of energy. OK, now the quadratic cost\nfunction makes a lot of sense,",
    "start": "3450758",
    "end": "3457270"
  },
  {
    "text": "OK. So I'm going to put\na quadratic cost on being away from the\ntop and a big quadratic",
    "start": "3457270",
    "end": "3462560"
  },
  {
    "text": "cost on using actions. So that'll give me some sense of\nminimally stabilizing the top,",
    "start": "3462560",
    "end": "3468650"
  },
  {
    "text": "OK. What's that one\ngoing to look like? ",
    "start": "3468650",
    "end": "3473900"
  },
  {
    "text": "Would you expect\nit to look like-- phase plot going. AUDIENCE: Basically\nin phase space, it will more turns to get up\nthere on the top [INAUDIBLE]..",
    "start": "3473900",
    "end": "3481717"
  },
  {
    "text": "PROFESSOR: OK. What about if it's near the top? Is there going to look like\na damp pendulum at the top? What's it going to do?",
    "start": "3481717",
    "end": "3487060"
  },
  {
    "text": " AUDIENCE: Well, if it's headed\nthe wrong way near the top,",
    "start": "3487060",
    "end": "3492600"
  },
  {
    "text": "it will probably swing\nall the way around. PROFESSOR: Good. Right. AUDIENCE: But if you put\ntoo much cost on distance,",
    "start": "3492600",
    "end": "3498750"
  },
  {
    "text": "it might end up quickest\non the [INAUDIBLE].. PROFESSOR: Perfect, OK. So let's switch this to be\nmy quadratic regulator cost.",
    "start": "3498750",
    "end": "3510990"
  },
  {
    "start": "3510990",
    "end": "3523410"
  },
  {
    "text": "Right, so that's what you said. Took more pumps to get up. And if you plot the\nphase plot from a couple of these different places--",
    "start": "3523410",
    "end": "3529930"
  },
  {
    "text": "oh. Crap, sorry. I thought I picked initial\nconditions that were far enough to show you that. This is what you said, OK.",
    "start": "3529930",
    "end": "3535769"
  },
  {
    "text": "This one happens to be close\nenough that it got to the top.  This one took a lot of\npumps and got out there.",
    "start": "3535770",
    "end": "3543750"
  },
  {
    "text": "But the point I was\ntrying to illustrate-- I guess I need to either\npenalize torque a little bit more or--",
    "start": "3543750",
    "end": "3549180"
  },
  {
    "start": "3549180",
    "end": "3563400"
  },
  {
    "text": "I never change things\nby a factor of 2. It's too slow. ",
    "start": "3563400",
    "end": "3569317"
  },
  {
    "text": "Oh, I made it not move. [LAUGHTER] Sorry. But it showed my point, OK. So yeah, it has no incentive\nto move from the bottom.",
    "start": "3569318",
    "end": "3577543"
  },
  {
    "text": "It says, I'm going to incur\nmore cost by moving than by getting close to the goal. Not getting close.",
    "start": "3577543",
    "end": "3582740"
  },
  {
    "text": "OK, but up at the\ntop, it is able to-- given it was near the\ntop with some velocity,",
    "start": "3582740",
    "end": "3590630"
  },
  {
    "text": "with a little effort, it's worth\ngoing around and stabilizing itself at the top.",
    "start": "3590630",
    "end": "3595960"
  },
  {
    "text": "Yeah? OK.  Good. AUDIENCE: If you\niterate it far enough,",
    "start": "3595960",
    "end": "3602582"
  },
  {
    "text": "it should go at the top, but-- PROFESSOR: No. Let's see. So--",
    "start": "3602582",
    "end": "3608453"
  },
  {
    "text": "AUDIENCE: It's because\nof the damping. PROFESSOR: It's\nbecause of the damping. AUDIENCE: Oh, OK. PROFESSOR: Yeah, good. Because that is actually\nthe steady state solution",
    "start": "3608453",
    "end": "3615170"
  },
  {
    "text": "I'm plotting. AUDIENCE: Oh. PROFESSOR: Mm-hmm. OK.",
    "start": "3615170",
    "end": "3620754"
  },
  {
    "text": "[RUSTLING] ",
    "start": "3620754",
    "end": "3633029"
  },
  {
    "text": "So if you care about\nsimple pendula-- sorry-- and you want\noptimal solutions, this looks like a pretty\nsatisfying way to do it.",
    "start": "3633030",
    "end": "3639970"
  },
  {
    "text": "You could up with your\narbitrary cost functions and see what you get. It runs in no time\non my laptop, and you",
    "start": "3639970",
    "end": "3647250"
  },
  {
    "text": "get things that look like\noptimal policies, nice phase plots, you name it, OK.",
    "start": "3647250",
    "end": "3653712"
  },
  {
    "text": "What's the catch? First catch is, how do\nI do the interpolation? How do I make that\ntransition matrix?",
    "start": "3653712",
    "end": "3659760"
  },
  {
    "start": "3659760",
    "end": "3682280"
  },
  {
    "text": "So on my pendulum example,\nI discretized some states. I have a handful--",
    "start": "3682280",
    "end": "3690050"
  },
  {
    "text": "I've already\ndiscretized actions, and I've got some\nother states over here",
    "start": "3690050",
    "end": "3695690"
  },
  {
    "text": "that they've\nalready discretized. I'd have to be pretty\nremarkably lucky to have it",
    "start": "3695690",
    "end": "3701960"
  },
  {
    "text": "that the random\nactions that I chose, integrated for some\nsmall amount of time, actually landed right on top\nof one of my other states.",
    "start": "3701960",
    "end": "3709130"
  },
  {
    "text": " In fact, they tend to land\nin between the states,",
    "start": "3709130",
    "end": "3715880"
  },
  {
    "text": "OK, so we do a little bit of\ninterpolation between them. And one of the reasons I showed\nyou that transition matrix",
    "start": "3715880",
    "end": "3723710"
  },
  {
    "text": "form is that it's actually\nquite OK, quite standard,",
    "start": "3723710",
    "end": "3729260"
  },
  {
    "text": "to say that my transition\nmatrix, my T from S",
    "start": "3729260",
    "end": "3736610"
  },
  {
    "text": "to S prime as a\nfunction of a is some--",
    "start": "3736610",
    "end": "3742505"
  },
  {
    "text": "let me just handwave it here-- but is some interpolated\nset of weights for S1 close.",
    "start": "3742505",
    "end": "3760517"
  },
  {
    "text": "[LAUGHS] OK. Zach just showed me a sign\nthat said, the pendulum works.",
    "start": "3760518",
    "end": "3767480"
  },
  {
    "text": "Having Matlab licensing issues. So we might-- I was hoping to run these\non the real pendulum. We'll do it on\nTuesday if not today.",
    "start": "3767480",
    "end": "3773197"
  },
  {
    "text": "[LAUGHS] I don't know whey\nhe didn't just say that, but there's a big\nbright green sign.",
    "start": "3773197",
    "end": "3780680"
  },
  {
    "text": "So let me write it like\nthis for the moment, OK.",
    "start": "3780680",
    "end": "3789170"
  },
  {
    "text": "So if I end up being near\nsome states in two dimensions,",
    "start": "3789170",
    "end": "3794510"
  },
  {
    "text": "I tend to interpolate between\nthe three closest states, OK.",
    "start": "3794510",
    "end": "3799670"
  },
  {
    "text": "So I'll call those Sy and S1-- Si, Sj, Sk, and I get some\ninterpolants, W1, W2, and W3.",
    "start": "3799670",
    "end": "3807380"
  },
  {
    "text": "They'd better sum to one, OK.",
    "start": "3807380",
    "end": "3816200"
  },
  {
    "text": "And there's actually\nlots of ways to do that. So actually, in previous\ntimes I've given the class, I went into some\ndetail about that.",
    "start": "3816200",
    "end": "3822210"
  },
  {
    "text": "I think that you could-- if you care about it, there's\na lot of ways to do that. You could use the\nMatlab interp2 function.",
    "start": "3822210",
    "end": "3828440"
  },
  {
    "text": "The one we use is called\nbarycentric interpolation. ",
    "start": "3828440",
    "end": "3839450"
  },
  {
    "text": "In the RL community, that was\npopularized by Munoz and Moore. ",
    "start": "3839450",
    "end": "3847650"
  },
  {
    "text": "That'll be cited in the notes.  And it uses-- if\nyou're operating",
    "start": "3847650",
    "end": "3855170"
  },
  {
    "text": "in an N-dimensional space, it\nuses N plus 1 interpolants. So in a two-dimensional\nspace, it",
    "start": "3855170",
    "end": "3861290"
  },
  {
    "text": "uses the three closest points. If you're in a\nfour-dimensional space, it uses the five\nclosest points, OK.",
    "start": "3861290",
    "end": "3867890"
  },
  {
    "text": "And there's a very\nclean, simple algorithm to find the factors of\nthat interpolant, OK.",
    "start": "3867890",
    "end": "3878510"
  },
  {
    "text": "The caveat is that\neverything spreads out.",
    "start": "3878510",
    "end": "3884870"
  },
  {
    "text": "If I simulate my dynamics,\nmy graph dynamics, what it's roughly saying is that\nif I started from this state,",
    "start": "3884870",
    "end": "3892070"
  },
  {
    "text": "I'm going to be a little bit\nin that state, a little bit in that-- a little bit in state 48,\na little bit in state 52.",
    "start": "3892070",
    "end": "3897980"
  },
  {
    "text": "And then my transition's\nout of there, so I get this diffusion across\nmy graph of where my state is,",
    "start": "3897980",
    "end": "3904805"
  },
  {
    "text": "if that makes sense. Yeah? And that's why you get some\nof the smoothing effects that you saw in the plots, OK.",
    "start": "3904805",
    "end": "3914310"
  },
  {
    "start": "3914310",
    "end": "3919840"
  },
  {
    "text": "There's a bigger\nproblem with that. The smoothing effects a lot of\ntimes don't look too dangerous,",
    "start": "3919840",
    "end": "3928210"
  },
  {
    "text": "but they can do bad\nthings to your solution",
    "start": "3928210",
    "end": "3933670"
  },
  {
    "text": "if you're not careful, OK. So the big caveat\nis the solution",
    "start": "3933670",
    "end": "3942280"
  },
  {
    "text": "you get is optimal only\nfor the discrete system.",
    "start": "3942280",
    "end": "3951595"
  },
  {
    "start": "3951595",
    "end": "3961690"
  },
  {
    "text": "We hope that it's approximately\noptimal for continuous,",
    "start": "3961690",
    "end": "3972670"
  },
  {
    "text": "but compared to the\nfinite element analysis world or the computational\nfluid dynamics world,",
    "start": "3972670",
    "end": "3978687"
  },
  {
    "text": "or other people that solve\nthese kind of problems, we have relatively less\nstrict understanding of when--",
    "start": "3978687",
    "end": "3986320"
  },
  {
    "text": "of how bad this approximation\ncan be compared-- based on the discretization.",
    "start": "3986320",
    "end": "3992170"
  },
  {
    "text": "There might actually be\npeople out there that know it. I don't know how to\ntell you how bad it's",
    "start": "3992170",
    "end": "3997630"
  },
  {
    "text": "going to get with the appro--\nwith the discretization. But I will ask you\non your problem set",
    "start": "3997630",
    "end": "4003630"
  },
  {
    "text": "to plot the bang bang solution\nof the double pendulum-- or, sorry, of the\ndouble integrator,",
    "start": "4003630",
    "end": "4009570"
  },
  {
    "text": "and plot the analytical\nsolution on top of it. And you'll see that\nif you're not careful, it's not just a\nlittle bit wrong.",
    "start": "4009570",
    "end": "4015870"
  },
  {
    "text": "It can be systematically wrong. The switching surface turns\nout in the wrong place. And we'll ask you to think a\nlittle bit about why that is,",
    "start": "4015870",
    "end": "4023000"
  },
  {
    "text": "OK.  That's really the\nonly caveat if you",
    "start": "4023000",
    "end": "4031628"
  },
  {
    "text": "about low dimensional problems. ",
    "start": "4031628",
    "end": "4036990"
  },
  {
    "text": "The more cited one,\nthough, of course, is that there's this\ncurse of dimensionality.",
    "start": "4036990",
    "end": "4042225"
  },
  {
    "start": "4042225",
    "end": "4052420"
  },
  {
    "text": "The only reason that everybody\ndoesn't use this stuff is because if I had a 10\ndegree of freedom robot",
    "start": "4052420",
    "end": "4061270"
  },
  {
    "text": "and I had to break up\nthat 10-dimensional space in discrete points, discrete\nbuckets, and made a graph,",
    "start": "4061270",
    "end": "4067840"
  },
  {
    "text": "I would need a bigger computer. Not just a little bit bigger, an\nexponentially bigger computer,",
    "start": "4067840",
    "end": "4073150"
  },
  {
    "text": "OK.  So you have to be able\nto discretize your space,",
    "start": "4073150",
    "end": "4078488"
  },
  {
    "text": "and discretizing the\nspace is exponentially expensive in the\nnumber of states, OK.",
    "start": "4078488",
    "end": "4084930"
  },
  {
    "text": "But so people\nactually-- historically, value methods were very\npopular in the '80s, say.",
    "start": "4084930",
    "end": "4094020"
  },
  {
    "text": "And there's a lot\nof work that we're going to talk about that\ncontinues to be popular, about using approximations,\nwhere you don't",
    "start": "4094020",
    "end": "4099870"
  },
  {
    "text": "do a strict\ndiscretization, but you do it so to try to\napproximate these costs, these dynamic programming\nalgorithms with function",
    "start": "4099870",
    "end": "4106109"
  },
  {
    "text": "approximation. But because of this sort\nof curse of dimensionality, a lot of people switched\ngears to a different class",
    "start": "4106109",
    "end": "4113040"
  },
  {
    "text": "of optimization algorithms\nbased more on the Pontryagin principle and more\non gradient methods.",
    "start": "4113040",
    "end": "4121620"
  },
  {
    "text": "We're going to talk\nabout those, too. But I think we have to\nremember that since the 1980s,",
    "start": "4121620",
    "end": "4129060"
  },
  {
    "text": "our computers actually\ngot a lot better, OK. Sounds silly, but\nso in the '80s,",
    "start": "4129060",
    "end": "4134220"
  },
  {
    "text": "they could tile\ntwo-dimensional spaces, and three-dimensional hurt. Now we could probably do four,\nfive, six-dimensional spaces,",
    "start": "4134220",
    "end": "4142239"
  },
  {
    "text": "OK. We actually did for-- we made that airplane\nland on a perch",
    "start": "4142240",
    "end": "4148170"
  },
  {
    "text": "by just tiling the state\nspace and doing brute force computation on that, OK.",
    "start": "4148170",
    "end": "4153299"
  },
  {
    "text": "So you should look around. If there's some hard\ncontrol problems that are four-dimensional or\nless that you consider",
    "start": "4153300",
    "end": "4160649"
  },
  {
    "text": "to be unsolved,\nyou could probably just hand them the\ndynamic programming and get a very\nnice solution, OK.",
    "start": "4160649",
    "end": "4166692"
  },
  {
    "text": "And say, hey, you couldn't\ndo it 10 years ago, but I can do it\ntoday on my laptop. ",
    "start": "4166692",
    "end": "4173960"
  },
  {
    "text": "Awesome. OK. So unless Zach\nappears here, there's only one last thing\nI want to say,",
    "start": "4173960",
    "end": "4179700"
  },
  {
    "text": "and that is I want\nto observe quickly-- ",
    "start": "4179700",
    "end": "4192739"
  },
  {
    "text": "we talked about the fact\nthat optimal policies are not unique. ",
    "start": "4192740",
    "end": "4198980"
  },
  {
    "text": "But there's more things\nyou can learn by staring at these guys a little bit. ",
    "start": "4198980",
    "end": "4209590"
  },
  {
    "text": "Let's put my R down to\nsomething more manageable. ",
    "start": "4209590",
    "end": "4221420"
  },
  {
    "text": "Go, go, go.  OK.",
    "start": "4221420",
    "end": "4227670"
  },
  {
    "text": "Can you see it in this? It's a little bit\nhard to see it. I think you can see it if\nI turn the lights down.",
    "start": "4227670",
    "end": "4234810"
  },
  {
    "text": "This is the quadratic\nregulator again. ",
    "start": "4234810",
    "end": "4242739"
  },
  {
    "text": "Now this isn't quite\nthe quadratic regulator from the double integrator.",
    "start": "4242740",
    "end": "4247960"
  },
  {
    "text": "This is now a quadratic\ncost function on a nonlinear dynamical system, OK.",
    "start": "4247960",
    "end": "4255020"
  },
  {
    "text": "In this case, the\ndynamics are smooth. They're non-linear,\nbut they're smooth. There's nothing that changes\nabruptly in the derivatives.",
    "start": "4255020",
    "end": "4262699"
  },
  {
    "text": "And the cost function\nis smooth, but you can find that the optimal\npolicy can actually still",
    "start": "4262700",
    "end": "4268130"
  },
  {
    "text": "be discontinuous, OK. So costs-- so why\nis it discontinuous?",
    "start": "4268130",
    "end": "4276140"
  },
  {
    "text": "In this case, because if I'm\nhere and I'm going this way, I want to push up, but at some\npoint, I have to change my mind",
    "start": "4276140",
    "end": "4282800"
  },
  {
    "text": "and go the opposite way to pump\nup energy and get to the top. So this pump up strategy is\ninherently discontinuous, OK.",
    "start": "4282800",
    "end": "4293660"
  },
  {
    "text": "So this is the Gordian\nknot of optimal control,",
    "start": "4293660",
    "end": "4299360"
  },
  {
    "text": "is as soon as things\nstop being linear, computing optimal cost to go\nfunctions can get arbitrarily",
    "start": "4299360",
    "end": "4307730"
  },
  {
    "text": "hard, OK. And that's why computation's\nso great, because it does that stuff for me.",
    "start": "4307730",
    "end": "4313635"
  },
  {
    "text": "But know that it doesn't\ntake much to make it so the cost to go function\ngets a lot more subtle. Mm-hmm.",
    "start": "4313635",
    "end": "4318887"
  },
  {
    "start": "4318887",
    "end": "4324050"
  },
  {
    "text": "Good. So the class will proceed taking\nthese methods as far as we can,",
    "start": "4324050",
    "end": "4329960"
  },
  {
    "text": "breaking them, and\nthen showing you approximation methods that work\nin higher dimensional spaces.",
    "start": "4329960",
    "end": "4335929"
  },
  {
    "text": "And when we give up on\noptimality all together, we'll do motion\nplanning, and we're going to get to more and\nmore interesting robots.",
    "start": "4335930",
    "end": "4341812"
  },
  {
    "text": "But this is really a key idea. So I hope that the\nintuition came through and--",
    "start": "4341812",
    "end": "4350240"
  },
  {
    "text": "through your problems set. And I can share some of\nthis code and everything. I hope you play with\nit, and think about it,",
    "start": "4350240",
    "end": "4356989"
  },
  {
    "text": "and change cost functions,\nand see what happens. OK, see you next week.",
    "start": "4356990",
    "end": "4362350"
  },
  {
    "start": "4362350",
    "end": "4363000"
  }
]
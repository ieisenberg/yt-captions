[
  {
    "start": "0",
    "end": "158000"
  },
  {
    "text": " NARRATOR: The following content\nis provided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6360"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials",
    "start": "6360",
    "end": "13350"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu.",
    "start": "13350",
    "end": "18449"
  },
  {
    "start": "18450",
    "end": "25719"
  },
  {
    "text": "ERIK DEMAINE: Yeah. I'm going to talk\nabout I/O models. Just to get a sense,\nhow many people know a model called I/O model?",
    "start": "25719",
    "end": "33510"
  },
  {
    "text": "And how many people don't? It doesn't matter. I'm just curious.",
    "start": "33510",
    "end": "38989"
  },
  {
    "text": "As some of you may\nknow, I/O models have a really rich history. And they're pretty fascinating.",
    "start": "38990",
    "end": "44030"
  },
  {
    "text": "They are all central to this\nproblem of modeling the memory hierarchy in a computer.",
    "start": "44030",
    "end": "50210"
  },
  {
    "text": "We have things like RAM\nmodel of computation where you can access anything at\nthe same price in your memory.",
    "start": "50210",
    "end": "56390"
  },
  {
    "text": "But the reality of\ncomputers is you have things that are\nvery close to you that are very cheap to\naccess, and you",
    "start": "56390",
    "end": "62030"
  },
  {
    "text": "have things that are very\nfar from you that are big. You can get 3 terabyte\ndisks these days,",
    "start": "62030",
    "end": "68090"
  },
  {
    "text": "but are very slow to access. And one of the big\ncosts there is latency. Because here, the head has to\nmove to the right position,",
    "start": "68090",
    "end": "77000"
  },
  {
    "text": "and then you can read\nlots of data really fast. The disk actually can\ngive you data very fast,",
    "start": "77000",
    "end": "82460"
  },
  {
    "text": "but the hard part is getting\nstarted in reading stuff. And so this is the sort\nof thing we want to model.",
    "start": "82460",
    "end": "88250"
  },
  {
    "text": "These kinds of computers\nhave been around for decades, as we'll see. And people have been\ntrying to model them",
    "start": "88250",
    "end": "93528"
  },
  {
    "text": "in as clean a way as possible\nthat works well theoretically and matches practice\nin some ways.",
    "start": "93528",
    "end": "99920"
  },
  {
    "text": "I have just some fun\nadditions to this slide. You can keep getting\nbigger, go to the internet, get to an exa- or a zettabyte.",
    "start": "99920",
    "end": "105910"
  },
  {
    "text": "You have to look up all\nthe words for these. In the universe,\nyou've got about 10 to the 83 atoms, so maybe\nroughly that many bits.",
    "start": "105910",
    "end": "114250"
  },
  {
    "text": "But I don't know if\nthere's a letter for them. So how do we model this?",
    "start": "114250",
    "end": "120140"
  },
  {
    "text": "Well, there's a lot of models. This is a partial list. These are sort of the core\nmodels that were around,",
    "start": "120140",
    "end": "125950"
  },
  {
    "text": "let's say, since\nthis millennium. So we start in 1972 and\nwork our way forward.",
    "start": "125950",
    "end": "133819"
  },
  {
    "text": "And I'm going to go\nthrough all of these in different levels of detail. There's a couple of\nkey features in a cache",
    "start": "133820",
    "end": "140270"
  },
  {
    "text": "that we want to model or\nmaybe a few key features. And then there's some\nmeasure of simplicity, which",
    "start": "140270",
    "end": "145549"
  },
  {
    "text": "is a little hard to define.  The goal is to get all four\nof these things at once.",
    "start": "145550",
    "end": "152690"
  },
  {
    "text": "And we get that more\nor less by the end. So first section is on this\nidealized two-level storage,",
    "start": "152690",
    "end": "160545"
  },
  {
    "start": "158000",
    "end": "158000"
  },
  {
    "text": "which was introduced\nby Bob Floyd in 1972. This is what the first page\nof the paper looks like.",
    "start": "160545",
    "end": "168219"
  },
  {
    "text": "It's probably typeset\non a typewriter it looks like and underline,\ngood old days of computer",
    "start": "168220",
    "end": "174560"
  },
  {
    "text": "science, very early days\nof computer science. And this was published\nin a conference",
    "start": "174560",
    "end": "180470"
  },
  {
    "text": "called The Complexity of\nComputer Computations. How many people have\nheard of that conference?",
    "start": "180470",
    "end": "186001"
  },
  {
    "text": "No one. Wow. There it is. It's a kind of a\nclassic, because it had Karp's original\npaper on NP-completeness.",
    "start": "186001",
    "end": "191870"
  },
  {
    "text": "So you've definitely\nread this paper. But there are a lot of\nneat papers in there",
    "start": "191870",
    "end": "196884"
  },
  {
    "text": "and a panel discussion including\nwhat should we call algorithms, which is kind of a fun read. So this is in the day when\none of the state of the art",
    "start": "196884",
    "end": "205190"
  },
  {
    "text": "computers was the PDP-11. This is what PDP-11,\nor one of them,",
    "start": "205190",
    "end": "210769"
  },
  {
    "text": "looks like by probably\nowned by Bell Labs. But Dennis Ritchie\nand Ken Thompson's",
    "start": "210770",
    "end": "216710"
  },
  {
    "text": "the inventors of C and\nUnix, working away there. It has disks, each of which is\nabout 2 megabytes in capacity.",
    "start": "216710",
    "end": "225860"
  },
  {
    "text": "And it has internal memory which\nwas core memory at the time. So each of these is a little\ncircular magnetic core.",
    "start": "225860",
    "end": "233360"
  },
  {
    "text": "And it stores 1 bit. And in total, there\nare 8 kilobytes. So you get a sense of\nalready this being an issue.",
    "start": "233360",
    "end": "241219"
  },
  {
    "text": "And this is why they\nwrote their paper. So here's the model\nthey introduced, a very simple model, maybe\nthe simplest we'll see.",
    "start": "241220",
    "end": "248000"
  },
  {
    "text": "You have your CPU, which\ncan do local computation. And then you have your\nmemory, which is very big.",
    "start": "248000",
    "end": "254720"
  },
  {
    "text": "But in particular, it's divided\ninto these blocks of size B. So each block can\nhave up to B items.",
    "start": "254720",
    "end": "260389"
  },
  {
    "text": "And what you're allowed to\ndo in one block operation is read two of the blocks.",
    "start": "260390",
    "end": "266754"
  },
  {
    "text": "You can read all the\nitems in the block. So let's say you\nread these two items. You pick some subset of\nthose items to pick up.",
    "start": "266754",
    "end": "273764"
  },
  {
    "text": "And then what\nyou're allowed to do is store them somewhere else. So you can pick some other\ntarget block like this one",
    "start": "273764",
    "end": "280280"
  },
  {
    "text": "and copy those elements\nto overwrite that block. I mean, there's no\ncomputation in this model,",
    "start": "280280",
    "end": "286760"
  },
  {
    "text": "because he was just interested\nin how you can permute items in that world.",
    "start": "286760",
    "end": "291949"
  },
  {
    "text": "So simple model, but\nyou get the idea. You can read two blocks, take\nup to B items out of them,",
    "start": "291950",
    "end": "298310"
  },
  {
    "text": "stick them in here. Here, we just ignore what\nthe order is within a block, because we're assuming you\ncan just rearrange once you",
    "start": "298310",
    "end": "304070"
  },
  {
    "text": "read them in and spit them out. So don't worry about the\norder within the block. It's more for every item,\nwhich block is it in?",
    "start": "304070",
    "end": "311300"
  },
  {
    "text": "And we're assuming here\nitems are indivisible. So here's the main\ntheorem of that paper.",
    "start": "311300",
    "end": "316670"
  },
  {
    "start": "314000",
    "end": "314000"
  },
  {
    "text": "If you're given N items and\nyou want to permute them into N",
    "start": "316670",
    "end": "322000"
  },
  {
    "text": "over B blocks, which means each\nof those blocks is going to be full-- let's say that's sort\nof the most interesting case--",
    "start": "322000",
    "end": "327210"
  },
  {
    "text": "then you need to use N over\nB log B block operations",
    "start": "327210",
    "end": "332729"
  },
  {
    "text": "even for a random permutation on\naverage with high probability. So this is kind of nice\nor kind of interesting,",
    "start": "332730",
    "end": "341680"
  },
  {
    "text": "because just to touch\nthose blocks requires N over B block operations.",
    "start": "341680",
    "end": "347590"
  },
  {
    "text": "But there's an extra log\nfactor that starts to creep up, which is maybe a little bit\nsurprising, less surprising",
    "start": "347590",
    "end": "354711"
  },
  {
    "text": "to people who are familiar with\nI/O models, but at the time, very new. And I'm making a\nparticular assumption here,",
    "start": "354711",
    "end": "360210"
  },
  {
    "text": "but just a small thing. I thought I'd go through\nthe proof of this theorem, because it's fairly simple. It's going to use a\nslightly simplified",
    "start": "360210",
    "end": "365970"
  },
  {
    "text": "model where, instead of copying\nitems, you actually move items. So these guys would\ndisappear after you put them",
    "start": "365970",
    "end": "371160"
  },
  {
    "text": "in this new block. Because we're thinking\nabout permutation problems, again, that doesn't\nreally change anything.",
    "start": "371160",
    "end": "376536"
  },
  {
    "text": "You can just, for\nevery item, see what path it follows to\nultimately get to its target location, throw away\nall the extra copies",
    "start": "376536",
    "end": "382770"
  },
  {
    "text": "and just keep that\none set of copies. And that will still be a\nvalid solution in this model.",
    "start": "382770",
    "end": "387819"
  },
  {
    "text": "So how does the lower bound go? It's a simple\npotential argument. You look at for\nevery pair of blocks,",
    "start": "387820",
    "end": "396540"
  },
  {
    "text": "how many items\nare there in block i that are destined for block j? You want to move from\nblock i to block j.",
    "start": "396540",
    "end": "403134"
  },
  {
    "text": "This is going to be\nchanging over time. This is where they\ncurrently are. So that's nij.",
    "start": "403135",
    "end": "408510"
  },
  {
    "text": "You take and nij, log nij,\nand sum that up over all i's and j's. That's the potential function.",
    "start": "408510",
    "end": "414610"
  },
  {
    "text": "And our goal is to\nmaximize that potential. Because it's going to be--",
    "start": "414610",
    "end": "420840"
  },
  {
    "text": "for those familiar\nwith entropy-- negative entropy. So it's going to be maximized\nwhen all the items are",
    "start": "420840",
    "end": "428220"
  },
  {
    "text": "where they need to be. This is when everything is\nas clustered as possible. You can only have a\ncluster of size B,",
    "start": "428220",
    "end": "434280"
  },
  {
    "text": "because items can only be\nup to B in the same place. One way to see this, in\nthe target configuration,",
    "start": "434280",
    "end": "441000"
  },
  {
    "text": "nii is B for all i. Everyone's where\nthey're supposed to be. And so that potential gives\nyou the number of items",
    "start": "441000",
    "end": "447990"
  },
  {
    "text": "times log B. And this\nis always, at most, log B. And so that's the biggest\nthis could ever hope to get.",
    "start": "447990",
    "end": "454290"
  },
  {
    "text": "So our goal is to increase\nentropy as much as possible. And we're starting\nwith low entropy. If you take a\nrandom permutation,",
    "start": "454290",
    "end": "461130"
  },
  {
    "text": "you're trying to get the\nexpected number of guys that are where they're\nsupposed to be. It's very small,\nbecause most of them",
    "start": "461130",
    "end": "466150"
  },
  {
    "text": "are going to be destined\nfor some other block. So we're starting with\nthe potential of linear.",
    "start": "466151",
    "end": "472350"
  },
  {
    "text": "We need to get to N log\nB. And then the claim is that each block operation we\ndo can only increase potential",
    "start": "472350",
    "end": "480960"
  },
  {
    "text": "by, at most, B. And\nso that gives us this bound of the\npotential we need",
    "start": "480960",
    "end": "486930"
  },
  {
    "text": "to get to minus the potential we\nhad divided by how much we can decrease potential in each step,\nwhich is basically N over B log",
    "start": "486930",
    "end": "495509"
  },
  {
    "text": "B minus a little O. Why is this claim true? I'll just sketch.",
    "start": "495510",
    "end": "501300"
  },
  {
    "text": "The idea is this fun fact,\nthe x plus y log x plus y is, at most, x log x plus\ny log y plus x plus y.",
    "start": "501300",
    "end": "508500"
  },
  {
    "text": "What this means is if\nyou have two clusters, our goal is to sort\nof cluster things together and make bigger groups\nthat are in the same place",
    "start": "508500",
    "end": "516615"
  },
  {
    "text": "or in the correct place. So if you have two clusters\nx log x and y log y contributing to this\nthing and you merge them,",
    "start": "516615",
    "end": "523830"
  },
  {
    "text": "then you now have\nthis potential. And the claim is that could\nhave only gone up by x plus y.",
    "start": "523830",
    "end": "529710"
  },
  {
    "text": "And when you're moving B\nitems, the total number of things you're moving\nis B. So you can only",
    "start": "529710",
    "end": "535200"
  },
  {
    "text": "increase things by B.\nSo it was a quick sketch of this old paper. It's a fun read, quite\nclear, easy argument.",
    "start": "535200",
    "end": "543810"
  },
  {
    "text": "So we proved this theorem that\nyou need at least N over B log B. But what is\nthe right answer?",
    "start": "543810",
    "end": "548850"
  },
  {
    "text": "There's actually not a\nmatching upper bound. Of course, for B at constant,\nthis is the right answer.",
    "start": "548850",
    "end": "554670"
  },
  {
    "text": "It's N, but that's\nnot so exciting.",
    "start": "554670",
    "end": "560100"
  },
  {
    "text": "On the upper bound\nside, this paper has almost matching lower bound. It's another log, but\nnot quite the same log,",
    "start": "560100",
    "end": "565770"
  },
  {
    "text": "N over B log N over\nB instead of log B. And the rough idea\nof how to do that-- AUDIENCE: [INAUDIBLE]",
    "start": "565770",
    "end": "570959"
  },
  {
    "text": "ERIK DEMAINE: Yeah, question. AUDIENCE: [INAUDIBLE] ERIK DEMAINE: I said a\ntall disk assumption.",
    "start": "570960",
    "end": "576210"
  },
  {
    "text": "I'm assuming N over\nB is greater than B. The number of\nblocks in your disk",
    "start": "576210",
    "end": "581640"
  },
  {
    "text": "is at least the size of a block. AUDIENCE: You needed\nthat in the proof? ERIK DEMAINE: I needed\nthat in the proof I think.",
    "start": "581640",
    "end": "587701"
  },
  {
    "text": " Good question, Where\nN over B log B.",
    "start": "587701",
    "end": "595214"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Yeah. Exactly. Yeah, that's where I'm using it.",
    "start": "595214",
    "end": "600893"
  },
  {
    "text": "Thanks. Otherwise this expectation\ndoesn't work out.",
    "start": "600893",
    "end": "606209"
  },
  {
    "text": "I mean, if you have one block,\nfor example, this will fail, because you need\nzero operations.",
    "start": "606210",
    "end": "612089"
  },
  {
    "start": "612000",
    "end": "612000"
  },
  {
    "text": "So there has to be some trade\noff at the very small regime. OK. So the way to get N\nover B log N over B",
    "start": "612090",
    "end": "618399"
  },
  {
    "text": "is basically a radix sort. In one pass through\nthe data, you can rewrite everything to\nhave the lower order bits of 0",
    "start": "618400",
    "end": "628060"
  },
  {
    "text": "before all the lower\norder bits of 1. So in N over B, you can sort\nby each bit in the target",
    "start": "628060",
    "end": "633940"
  },
  {
    "text": "block ID of every item. And so you do log\nof N over B things, because that's how\nmany blocks there are.",
    "start": "633940",
    "end": "640420"
  },
  {
    "text": "And so this is how\nmany passes you need by a binary radix sort. You can achieve that bound.",
    "start": "640420",
    "end": "647080"
  },
  {
    "text": "And the paper actually claims\nthat there's a lower bound.",
    "start": "647080",
    "end": "652507"
  },
  {
    "text": "It's a little strange,\nbecause there's a careful proof given for this. And then this claim just\nsays, \"by information",
    "start": "652507",
    "end": "658060"
  },
  {
    "text": "theoretic consideration--\"\nthis is also true. This is in the\ndays when we didn't",
    "start": "658060",
    "end": "663190"
  },
  {
    "text": "distinguish between\nbig O and big omega before [INAUDIBLE] paper.",
    "start": "663190",
    "end": "668290"
  },
  {
    "text": "But this is not true. And we'll see that\nit's not true. It was settled about\n14 years later.",
    "start": "668290",
    "end": "675220"
  },
  {
    "text": "So we'll see the right answer. This is almost the right\nanswer, but it doesn't quite",
    "start": "675220",
    "end": "680319"
  },
  {
    "text": "work when B is very small. And one way to see\nthat is when B is 1. When B is 1, the right\nanswer is N, not N log N.",
    "start": "680320",
    "end": "688649"
  },
  {
    "text": "So when B is less\nthan log N over B, then there's a slightly\ndifferent answer",
    "start": "688650",
    "end": "694480"
  },
  {
    "text": "which we'll get to later. But that was the early days. There's some other fun quotes\nfrom this paper foreshadowing",
    "start": "694480",
    "end": "702100"
  },
  {
    "text": "different things. One is the word RAM model,\nwhich is very common today, but not at the time.",
    "start": "702100",
    "end": "707579"
  },
  {
    "text": "And it says, obviously,\nthese results apply for distant drums,\nwhich was probably what they were thinking\nabout originally,",
    "start": "707579",
    "end": "713078"
  },
  {
    "text": "but also when the\npages, the blocks, are words of internal\nmemory and the records are the bits in those words.",
    "start": "713078",
    "end": "718570"
  },
  {
    "text": "So this is a word RAM model.  Here, I said just ignore the\npermutation within each block.",
    "start": "718570",
    "end": "725537"
  },
  {
    "text": "But you can actually\ndo all the things you need to do for\nthese algorithms using shifts and logical or,\nxor, and operations.",
    "start": "725537",
    "end": "732800"
  },
  {
    "text": "So all these algorithms work\nin the word RAM model, too, which is kind of nifty. Another thing is\nforeshadowing, what",
    "start": "732800",
    "end": "740230"
  },
  {
    "text": "we call the I/O model, which\nwe'll get to in a little bit. It says, \"work is in progress.\" He got scooped, unfortunately.",
    "start": "740230",
    "end": "746410"
  },
  {
    "text": "\"Work is in progress--\" unless\nhe meant by someone else-- \"attempting to study\nthe case where you",
    "start": "746410",
    "end": "752860"
  },
  {
    "text": "can store more than two pages.\" Basically, this CPU can\nhold two of these blocks, and then write one back out, but\nhas no bigger memory than that.",
    "start": "752860",
    "end": "761920"
  },
  {
    "text": "or bigger cache. So that's where we\nwere at the time. Next, chapter in\nthis story is 1981.",
    "start": "761920",
    "end": "770010"
  },
  {
    "text": "It's a good year. It was when I was born. And this is Hong\nand Kung's paper.",
    "start": "770010",
    "end": "775690"
  },
  {
    "text": "You've probably heard about\nthe red-blue pebble game. And it's also a two-level\nmodel, but now there's",
    "start": "775690",
    "end": "781690"
  },
  {
    "text": "a cache in the middle. And you can remember\nstuff for a while. I mean, you can\nremember up to M things",
    "start": "781690",
    "end": "787839"
  },
  {
    "text": "before you have\nto kick them out. The difference here is\nthere's no blocks anymore. It's just items.",
    "start": "787840",
    "end": "793490"
  },
  {
    "text": "So let me tell you a\nlittle bit about the paper. This was the state of the\nart in computing at the time. The personal computer\nrevolution was happening.",
    "start": "793490",
    "end": "799458"
  },
  {
    "text": "They had the Apple\nII, TRS-80, VIC-20. All of these originally had\nabout 4 kilobytes of RAM.",
    "start": "799458",
    "end": "805660"
  },
  {
    "text": "And the disks could store\nmaybe, I don't know, 360 kilobytes or so.",
    "start": "805660",
    "end": "811060"
  },
  {
    "text": "But you could also connect a\ntape and other crazy things. So, again, this was relevant. And that's the setting\nthey were writing this.",
    "start": "811060",
    "end": "817879"
  },
  {
    "text": "They have this fun quote. \"When a large computation is\nperformed on a small device--\" at that point, small devices\nwere becoming common--",
    "start": "817879",
    "end": "824027"
  },
  {
    "text": "\"you must decompose\nthose computations to subcomputations.\" This is going to require a lot\nof I/O. It's going to be slow.",
    "start": "824027",
    "end": "829940"
  },
  {
    "text": "So how do we minimize I/O? So their model-- before I get\nto this red-blue pebble game",
    "start": "829940",
    "end": "837700"
  },
  {
    "text": "model, it's based on a vanilla\nsingle color pebble game model",
    "start": "837700",
    "end": "843520"
  },
  {
    "text": "by a Hopcroft,\nPaul, and Valiant. This is the famous interrelation\nbetween the time hierarchy and space hierarchy paper.",
    "start": "843520",
    "end": "850720"
  },
  {
    "text": "And what they said is, OK,\nlet's think of the algorithm we're executing as a DAG.",
    "start": "850720",
    "end": "855880"
  },
  {
    "text": "We start with some\nthings that are inputs. And we want to compute stuff\nthat this computation depends",
    "start": "855880",
    "end": "862960"
  },
  {
    "text": "on having these two\nvalues and so on. In the end, we want to\ncompute some outputs. So you can rewrite computation\nin this kind of DAG form.",
    "start": "862960",
    "end": "869920"
  },
  {
    "text": "And we're going to model\nthe execution of that by playing this pebble game.",
    "start": "869920",
    "end": "875110"
  },
  {
    "text": "And so a node can\nhave pebbles on it. And for example, we could\nput a pebble on this node.",
    "start": "875110",
    "end": "880290"
  },
  {
    "text": "In general, we are allowed\nto put a pebble on a node if all of its predecessors\nhave a pebble.",
    "start": "880290",
    "end": "886300"
  },
  {
    "text": "And pebble is going to\ncorrespond to being in memory. And we can also throw away\na node, because we can just",
    "start": "886300",
    "end": "891640"
  },
  {
    "text": "forget stuff. Unlike real life, you can\njust forget whatever you don't want to know any more.",
    "start": "891640",
    "end": "896830"
  },
  {
    "text": "So you add a pebble. Let's say, now we\ncan add this pebble, because its predecessor\nhas a pebble on it.",
    "start": "896830",
    "end": "903570"
  },
  {
    "text": "We can add this pebble over\nhere, add this pebble here. Now, we don't need this\ninformation anymore,",
    "start": "903570",
    "end": "908610"
  },
  {
    "text": "because we've computed\nall the things out of it. So we can choose to\nremove that pebble. And now, we can add this one,\nremove that one, add this one.",
    "start": "908610",
    "end": "915810"
  },
  {
    "text": "You can check that I got all\nthese right, add this one, remove that one, remove,\nadd, remove, remove.",
    "start": "915810",
    "end": "923669"
  },
  {
    "text": "In the end, we want\npebbles on the outputs. We start with pebbles\non the inputs. And in this case, their goal was\nto minimize the maximum number",
    "start": "923669",
    "end": "931500"
  },
  {
    "text": "of pebbles over time. Here, there's up to four\npebbles at any one moment. That means you need\nmemory of size four.",
    "start": "931500",
    "end": "940020"
  },
  {
    "text": "And they ended up proving\nthat any DAG can be executed using N over log N\nmaximum pebbles, which",
    "start": "940020",
    "end": "945360"
  },
  {
    "text": "gave this theorem time. If you use t units of\ntime, you can fit in t over log t units of space,\nwhich was a neat advance.",
    "start": "945360",
    "end": "952980"
  },
  {
    "text": "But that's beside the point. This is where Hong and\nKung were coming from. They had this pebble model.",
    "start": "952980",
    "end": "958904"
  },
  {
    "text": "And they wanted to use\ntwo colors of pebbles, one to represent the shallower\nlevel of the memory hierarchy",
    "start": "958904",
    "end": "966029"
  },
  {
    "text": "in cache, and the other to say\nthat you're on disk somewhere. So red pebble is\ngoing to be in cache.",
    "start": "966030",
    "end": "972240"
  },
  {
    "text": "That's the hot stuff. And the blue pebbles\nare our disk. That's the cold stuff.",
    "start": "972240",
    "end": "977370"
  },
  {
    "text": "And, basically, the same rules-- when you're initially\nplacing a pebble, everything here has to be red.",
    "start": "977370",
    "end": "983511"
  },
  {
    "text": "You can place a red pebble\nif your predecessors have red pebbles. We start out with the\ninputs being blue, so there are no red pebbles.",
    "start": "983512",
    "end": "989560"
  },
  {
    "text": "But for free-- or not for free. For unit cost, we can\nconvert any red pebble to a blue pebble or any\nblue pebble to a red pebble.",
    "start": "989560",
    "end": "995610"
  },
  {
    "text": "So let's go through this. I can make that one red. And now, I can\nmake this one red. Great.",
    "start": "995610",
    "end": "1000889"
  },
  {
    "text": "Now, I don't need it right now. So I'm going to make it blue,\nmeaning write it out to disk.",
    "start": "1000889",
    "end": "1005925"
  },
  {
    "text": "I make this one red,\nmake this one red. Now, I can throw that one away. I don't need it\non cache or disk.",
    "start": "1005925",
    "end": "1011360"
  },
  {
    "text": "I can put that one\non disk, because I don't need it right now.",
    "start": "1011360",
    "end": "1016430"
  },
  {
    "text": "I can bring that one\nback in from cache, write this one out,\nput that one onto disk,",
    "start": "1016430",
    "end": "1023205"
  },
  {
    "text": "put that onto a disk. Now, we'll go over here,\nread this back in from disk, finish off this\nsection over here.",
    "start": "1023205",
    "end": "1029459"
  },
  {
    "text": "And now, I can throw that away,\nadd this guy, throw that away. What do I need? Now, I can write\nthis out to disk.",
    "start": "1029460",
    "end": "1035845"
  },
  {
    "text": "I'm done with the output. Now, I've got to read\nall these guys in, and then I can do this one. And so I needed a cache\nsize here of four.",
    "start": "1035846",
    "end": "1043430"
  },
  {
    "text": "The maximum number of red\nthings at any moment was four. And I can get rid of those guys\nand write that one to disk.",
    "start": "1043430",
    "end": "1049820"
  },
  {
    "text": "And my goal is to get\nthe outputs all blue. But the objective\nhere is different. Before, we were minimizing,\nessentially, cache size.",
    "start": "1049820",
    "end": "1057649"
  },
  {
    "text": "Cache size now is given to us. We say we have a\ncache of size M. But now, what we count are the\nnumber of reads and writes,",
    "start": "1057650",
    "end": "1063530"
  },
  {
    "text": "the number of switching\ncolors of pebbles. That is the number I/Os.",
    "start": "1063530",
    "end": "1068894"
  },
  {
    "text": "And so you can think of\nthis model as this picture I drew before. You have cache. You can store up to M items.",
    "start": "1068895",
    "end": "1075590"
  },
  {
    "text": "You can take any blue item. You could throw them\naway, for example.",
    "start": "1075590",
    "end": "1081860"
  },
  {
    "text": "I could move a red item\nover here, turn it blue. That corresponds to\nwriting out to disk. I can bring a blue item\nback in to fill that spot.",
    "start": "1081860",
    "end": "1089510"
  },
  {
    "text": "That corresponds to reading from\ndisk as long as, at all times, I have at most M red items.",
    "start": "1089510",
    "end": "1094760"
  },
  {
    "text": "And these are the same model. So what Hong and\nKung did is look",
    "start": "1094760",
    "end": "1100640"
  },
  {
    "start": "1100000",
    "end": "1100000"
  },
  {
    "text": "at a bunch of different\nalgorithms, not problems, but specific algorithms,\nthings that you",
    "start": "1100640",
    "end": "1106160"
  },
  {
    "text": "could compute in the DAG form. The DAG form is,\nI guess you could say, a class of algorithms.",
    "start": "1106160",
    "end": "1111387"
  },
  {
    "text": "There's many ways\nto execute this DAG. You could follow any\ntopological sort of this DAG.",
    "start": "1111387",
    "end": "1117470"
  },
  {
    "text": "That's an algorithm\nin some sense. And so what he's finding is the\nbest execution of these meta",
    "start": "1117470",
    "end": "1124940"
  },
  {
    "text": "algorithms, if you will. So that doesn't mean it's the\nbest way to do matrix vector",
    "start": "1124940",
    "end": "1131450"
  },
  {
    "text": "multiplication. But it says if you're following\nthe standard algorithm, the standard DAG that you get\nfrom it or the standard FFT",
    "start": "1131450",
    "end": "1137380"
  },
  {
    "text": "DAG-- I guess FFT is\nactually an algorithm-- then the minimum number\nof memory transfers",
    "start": "1137380",
    "end": "1143960"
  },
  {
    "text": "is this number of red\nor blue recolorings. And so you get a variety.",
    "start": "1143960",
    "end": "1149900"
  },
  {
    "text": "Of course, the speed-ups,\nrelative to the regular RAM analysis versus this analysis is\ngoing to be somewhere between 1",
    "start": "1149900",
    "end": "1157550"
  },
  {
    "text": "and M, I guess for\nmost problems at least.",
    "start": "1157550",
    "end": "1163306"
  },
  {
    "text": "And for some problems, like\nmatrix vector multiplication, you get very good M odd even\ntranspositions [INAUDIBLE]",
    "start": "1163306",
    "end": "1170000"
  },
  {
    "text": "you get M. Matrix\nmultiplication, not quite as good red M and FFT.",
    "start": "1170000",
    "end": "1176690"
  },
  {
    "text": "Sorting was not analyzed\nhere, because sorting is many different algorithms. Just one specific algorithm\nanalyzed here, only log M.",
    "start": "1176690",
    "end": "1185360"
  },
  {
    "text": "So I don't want to go\nthrough these analyzes, because a lot of them will\nfollow from other results that we'll get to.",
    "start": "1185360",
    "end": "1192489"
  },
  {
    "text": "So at this point,\nwe have two models. We have the idealized\ntwo-level storage of Floyd. We have the red-blue pebble\ngame of Hong and Kung.",
    "start": "1192489",
    "end": "1199549"
  },
  {
    "text": "This one models\ncaching, that you can store a bunch of things. But it does not have blocks. This one models blocking,\nbut it does not have a cache,",
    "start": "1199550",
    "end": "1207740"
  },
  {
    "text": "or it has a cache\nof constant size. So the idea is to\nmerge these two models. And this is the Aggarwal\nand Vitter paper many of you",
    "start": "1207740",
    "end": "1215539"
  },
  {
    "text": "have heard of, I'm sure. It was in 1987, so six\nyears after Hong and Kung.",
    "start": "1215540",
    "end": "1221135"
  },
  {
    "text": "It has many names. I/O model is the\noriginal, I guess. External Memory Model\nis what I usually use",
    "start": "1221135",
    "end": "1227400"
  },
  {
    "text": "and a bunch of people here use. Disk Access Model has the nice\nadvantage of you can call it",
    "start": "1227400",
    "end": "1232610"
  },
  {
    "text": "the DAM model. And, again, our goal is to\nminimize number of I/Os.",
    "start": "1232610",
    "end": "1238399"
  },
  {
    "text": "It's just a fusion\nof the two models. Now, our cache has\nblocks of size B.",
    "start": "1238400",
    "end": "1244100"
  },
  {
    "text": "And you have M over B blocks. And your disk is also\ndivided into blocks of size",
    "start": "1244100",
    "end": "1249840"
  },
  {
    "text": "B. We imagine it being as\nlarge as you need it to be, probably about order N. And what can you do?",
    "start": "1249840",
    "end": "1256230"
  },
  {
    "text": "Well, you can pick up\none of these blocks and read it in\nfrom disk to cache,",
    "start": "1256230",
    "end": "1261350"
  },
  {
    "text": "so kicking out whatever\nused to be there. You can do computation\ninternally,",
    "start": "1261350",
    "end": "1266510"
  },
  {
    "text": "change whatever these items\nare for free, let's say. You could measure\ntime, but usually",
    "start": "1266510",
    "end": "1272750"
  },
  {
    "text": "you just measure a number\nof memory transfers. And then you can take\none of these blocks and write it back out\nto disk, kicking out",
    "start": "1272750",
    "end": "1278780"
  },
  {
    "text": "whatever used to be there. So it's the obvious\nhybrid of these models. But this turns out to\nbe a really good model.",
    "start": "1278780",
    "end": "1286354"
  },
  {
    "text": "Those other two models,\nthey were interesting. They were toys. They were simple. This is basically as simple,\nbut it spawned this whole field.",
    "start": "1286354",
    "end": "1293605"
  },
  {
    "text": "And it's why we're here today. So this is a really\ncool model, let's say,",
    "start": "1293605",
    "end": "1299090"
  },
  {
    "text": "tons of results in this model. It's interesting to see-- I'm going to talk about\na lot of models today. We're sort of in the middle\nof them at the moment.",
    "start": "1299090",
    "end": "1306050"
  },
  {
    "text": "But only two have really\ncaught on in a big way and have led to lots\nand lots of papers.",
    "start": "1306050",
    "end": "1311190"
  },
  {
    "text": "This is one of them. So let me tell you some basic\nresults and how to do them.",
    "start": "1311190",
    "end": "1316929"
  },
  {
    "text": "A simple approach algorithmic\ntechnique in external memory",
    "start": "1316930",
    "end": "1322880"
  },
  {
    "text": "is to scan. So here's my data. If I just want to read items in\norder and stop at some point N,",
    "start": "1322880",
    "end": "1330679"
  },
  {
    "text": "then that cost me order N\nover B memory transfers. That's optimal. I've got to read the data in. I can accumulate, add them\nup, multiply them together,",
    "start": "1330680",
    "end": "1338240"
  },
  {
    "text": "whatever. One thing to be careful\nwith those is plus 1, or you could put\na ceiling on that.",
    "start": "1338240",
    "end": "1344179"
  },
  {
    "text": "If N is a lot less and B, then\nthis is not a good strategy. But as long as N is\nat least order B,",
    "start": "1344180",
    "end": "1349930"
  },
  {
    "text": "that's really efficient. More generally, instead\nof just one scan,",
    "start": "1349930",
    "end": "1356060"
  },
  {
    "text": "you can run up to M\nover B parallel scans. Because for a scan,\nyou really just need",
    "start": "1356060",
    "end": "1361220"
  },
  {
    "text": "to know what is my\nblock currently. And we can fit M over\nB blocks in our cache.",
    "start": "1361220",
    "end": "1367100"
  },
  {
    "text": "And so we can advance\nthis scan a little bit, advance this scan a little\nbit, advanced this one,",
    "start": "1367100",
    "end": "1373559"
  },
  {
    "text": "and go back and forth. In any kind of interleaving we\nwant of those M over B scans, some of them could\nbe read scans.",
    "start": "1373560",
    "end": "1379220"
  },
  {
    "text": "Some of them could\nbe write scans. Some of them can go backwards. Some of them could go forwards,\na lot of options here. And in particular,\nyou can do something",
    "start": "1379220",
    "end": "1385400"
  },
  {
    "text": "like given a little\nbit less than M over be lists of\ntotal size N, you can merge them all together.",
    "start": "1385400",
    "end": "1391070"
  },
  {
    "text": "If they're sorted lists,\nyou can merge them into one sorted list in\noptimal N over B time.",
    "start": "1391070",
    "end": "1397661"
  },
  {
    "text": "So that's good. We'll use that in a moment. Here",
    "start": "1397661",
    "end": "1403010"
  },
  {
    "text": "I have a little bit of\na thought experiment, originally by Lars Arge\nwho will be speaking later.",
    "start": "1403010",
    "end": "1410420"
  },
  {
    "text": "You know, is this\nreally a big deal? Factor B doesn't sound so big. Do I care? For example, suppose\nI'm going to traverse",
    "start": "1410420",
    "end": "1417460"
  },
  {
    "text": "a linked list in memory, but\nit's actually stored on disk. Is it really important\nthat I sort that list",
    "start": "1417460",
    "end": "1423230"
  },
  {
    "text": "and do a scan versus jumping\naround random access? And this is back\nof the envelope,",
    "start": "1423230",
    "end": "1429649"
  },
  {
    "text": "just computing what\nthings ought to be. If you have about a gigabyte\nof data, a block size of 32",
    "start": "1429650",
    "end": "1434975"
  },
  {
    "text": "kilobytes, which is probably on\nthe small side, a 1 millisecond disk access time,\nwhich is really fast,",
    "start": "1434975",
    "end": "1442250"
  },
  {
    "text": "usually at least 2\nmilliseconds, then if you do things\nin random order,",
    "start": "1442250",
    "end": "1450139"
  },
  {
    "text": "on average every access is going\nto require a memory transfer. That'll take about\n70 hours, three days.",
    "start": "1450140",
    "end": "1457100"
  },
  {
    "text": "But if you do a scan, if\nyou presorted everything and you do a scan, then it\nwill only take you 32 seconds.",
    "start": "1457100",
    "end": "1463400"
  },
  {
    "text": "So it's just 8,000 in time\nspace is a lot bigger than we conceptualize.",
    "start": "1463400",
    "end": "1469640"
  },
  {
    "text": "And it makes things that were\nimpractical to do, say, daily, very practical.",
    "start": "1469640",
    "end": "1474750"
  },
  {
    "text": "So that's why we're here. Let's do another problem. How about search? Suppose I have the\nitems in sorted order,",
    "start": "1474750",
    "end": "1480380"
  },
  {
    "text": "and I want to do binary search. Well, the right thing\nis not binary search, but B-way search, so log\nbase B of N. The plus 1",
    "start": "1480380",
    "end": "1488690"
  },
  {
    "text": "is to handle the\ncase when B equals 1. Then you want log base 2. So we have our items.",
    "start": "1488690",
    "end": "1495200"
  },
  {
    "text": "We want to search, first,\nwhy is this the right bound? Why is this optimal? You can do an information\ntheoretic argument",
    "start": "1495200",
    "end": "1501440"
  },
  {
    "text": "in the comparison\nmodel, assuming you're just comparing items. Then whenever you\nread in a block--",
    "start": "1501440",
    "end": "1506730"
  },
  {
    "text": "if the blocks have\nalready been sorted, you read in some block-- what you learn from\nlooking at those B items",
    "start": "1506730",
    "end": "1513440"
  },
  {
    "text": "is where your query guy, x,\nfits among those B items. You already know everything\nabout the B items,",
    "start": "1513440",
    "end": "1518480"
  },
  {
    "text": "how they relate to each other. But you learn where x is. So that gives you log of B\nplus 1 bits of information,",
    "start": "1518480",
    "end": "1524840"
  },
  {
    "text": "because there are B plus\n1 places where x could be. And you need to figure\nout log of N plus 1 bits.",
    "start": "1524840",
    "end": "1530300"
  },
  {
    "text": "You want to know where x\nfits among all the items. And so you divide log of N\nplus 1 by log of B plus 1.",
    "start": "1530300",
    "end": "1535309"
  },
  {
    "text": "That's log base b\nplus 1 of N plus 1. So that's the lower bound.",
    "start": "1535310",
    "end": "1540716"
  },
  {
    "text": "And the upper bound is, you\nprobably have guessed by now, is a B-tree. You just have B items\nand the node sort",
    "start": "1540716",
    "end": "1547130"
  },
  {
    "text": "of uniformly distributed\nthrough the sorted list. And then once you\nget those items,",
    "start": "1547130",
    "end": "1552440"
  },
  {
    "text": "you go to the appropriate\nsubtree and recurse. And the height of such a tree\nis log base b plus 1 of N,",
    "start": "1552440",
    "end": "1557930"
  },
  {
    "text": "and so it works. B-trees have the nice\nthing, you can also do insertions and deletions\nin the same amount of time.",
    "start": "1557930",
    "end": "1563870"
  },
  {
    "text": "Though, that's no\nlonger so optimal. For searches, this\nis the right answer. ",
    "start": "1563870",
    "end": "1570369"
  },
  {
    "start": "1570000",
    "end": "1570000"
  },
  {
    "text": "So, next thing you\nmight want to do-- I keep saying,\nassume it's sorted-- I'd really like some\nsorted data, please.",
    "start": "1570369",
    "end": "1576030"
  },
  {
    "text": "So how do I sort my data? I think the Aggarwal\nand Vitter paper has this fun quote about, today,\none fourth of all computation",
    "start": "1576030",
    "end": "1586040"
  },
  {
    "text": "is sorting. Some machines are devoted\nentirely to sorting. It's like the\nproblem of the day.",
    "start": "1586040",
    "end": "1591409"
  },
  {
    "text": "Everyone was sorting. I assume people\nstill sort, but I'm guessing it's not the\ndominant feature anymore.",
    "start": "1591410",
    "end": "1598710"
  },
  {
    "text": "And it's a big deal, you know. Can I sort within one\nday, so that all the stuff that I learned today\nor all the transactions that",
    "start": "1598710",
    "end": "1605390"
  },
  {
    "text": "happened today I\ncould sort them. So it turns out the\nright answer for sorting",
    "start": "1605390",
    "end": "1611059"
  },
  {
    "text": "bound is N over B log\nbase M over B of N over B. If you haven't seen that, it\nlooks kind of like a big thing.",
    "start": "1611060",
    "end": "1616790"
  },
  {
    "text": "But those of us in the know\ncan recite that in our sleep. It comes up all over the place.",
    "start": "1616790",
    "end": "1622490"
  },
  {
    "text": "Lots of problems are\nas hard as sorting, and can be solved in\nthe sorting bound time. To go back to the\nproblem I was talking",
    "start": "1622490",
    "end": "1629930"
  },
  {
    "text": "about with Floyd's model,\nthe permutation problem, I know the permutation.",
    "start": "1629930",
    "end": "1636049"
  },
  {
    "text": "I know where things\nare supposed to go. I just need to move\nthem there physically. Then it's slightly better.",
    "start": "1636050",
    "end": "1642870"
  },
  {
    "text": "You have the sorting\nbound, which is essentially what we had before. But in some cases, just doing\nthe naive thing is better.",
    "start": "1642870",
    "end": "1650120"
  },
  {
    "text": "Sometimes it's better to just\ntake every item and stick it where it belongs in\ncompletely random access.",
    "start": "1650120",
    "end": "1656591"
  },
  {
    "text": "So you could always do it, of\ncourse, in N memory transfers. And sometimes that is slightly\nbetter than the sorting bound,",
    "start": "1656591",
    "end": "1662029"
  },
  {
    "text": "because you don't\nhave the log term. And so that is the right\nanswer to Floyd's problem.",
    "start": "1662030",
    "end": "1668260"
  },
  {
    "text": "He got the upper bound right. In his case, M over B is 3. So this is just log base 2.",
    "start": "1668260",
    "end": "1677350"
  },
  {
    "text": "But he missed this one term. OK.",
    "start": "1677350",
    "end": "1682360"
  },
  {
    "start": "1682000",
    "end": "1682000"
  },
  {
    "text": "So why is the sorting\nbound correct? I won't go through\nthe permutation bound. The upper bound's clear. Information, theoretically,\nit's very easy",
    "start": "1682360",
    "end": "1688900"
  },
  {
    "text": "to see why you can't do\nbetter than the sorting bound. Let's set up a little\nbit of ground rules.",
    "start": "1688900",
    "end": "1694720"
  },
  {
    "text": "Let's suppose that whatever\nyou have in cache, you sort it. Because why not?",
    "start": "1694720",
    "end": "1699935"
  },
  {
    "text": "I mean, this is only\ngoing to help you. And everything you\ndo in cache is free. So always keep the cache sorted.",
    "start": "1699936",
    "end": "1705460"
  },
  {
    "text": "And to clean up the\ninformation that's around, I'm going to first do a\npass where I read a block,",
    "start": "1705460",
    "end": "1711310"
  },
  {
    "text": "sort the block, stick\nit back out, and repeat. So each block is presorted. So there's no sorting\ninformation inside a block.",
    "start": "1711310",
    "end": "1719830"
  },
  {
    "text": "It's all about how blocks\ncompare to each other here. So when I read a block--",
    "start": "1719830",
    "end": "1725010"
  },
  {
    "text": "let's say this is my cache,\nand a new block comes in here-- what I learn is where those B\nitems live among the M items",
    "start": "1725010",
    "end": "1731890"
  },
  {
    "text": "that I already had. So it's just like\nthe analysis before, except now I'm reading B items\namong M instead of one among B.",
    "start": "1731890",
    "end": "1740620"
  },
  {
    "text": "And so the number of\npossible outcomes for that is M plus b choose B.",
    "start": "1740620",
    "end": "1746350"
  },
  {
    "text": "So you have M plus B things. And there's B of them\nthat we're saying which of the B in the order\ncame from the new block.",
    "start": "1746350",
    "end": "1754210"
  },
  {
    "text": "You take log of that,\nand you get basically B log M over B bits that\nyou learn from each step.",
    "start": "1754210",
    "end": "1760150"
  },
  {
    "text": "And the total number of\nbits we need to learn is N log N, as you know. But we knew a little bit of\nbits from this presorting step.",
    "start": "1760150",
    "end": "1768490"
  },
  {
    "text": "This is to clean this\nup at the beginning. We already knew N log B bits,\nbecause each of those B things",
    "start": "1768490",
    "end": "1775377"
  },
  {
    "text": "was presorted. So we have B log B per\nblock each of them. There's N over B of them. So it's N log B.\nSo we need to learn",
    "start": "1775377",
    "end": "1782800"
  },
  {
    "text": "N log N minus N log B bits. And in each step, which is a\nlog of N over B N log N over B--",
    "start": "1782800",
    "end": "1793030"
  },
  {
    "text": "and in each step, we\nlearn B log M over B. So you divide those\ntwo things, and you get N over B log\nbase M over B and N",
    "start": "1793030",
    "end": "1798880"
  },
  {
    "text": "over B. It's a good exercise\nin log rules and information theory. But now, you see it's\nsort of the obvious bound",
    "start": "1798880",
    "end": "1807130"
  },
  {
    "text": "once you check how many bits\nyou're learning in each step. OK.",
    "start": "1807130",
    "end": "1812230"
  },
  {
    "text": "How do we achieve this bound? What's an upper bound? I'm going to show you\ntwo ways to do it.",
    "start": "1812230",
    "end": "1818410"
  },
  {
    "text": "The easy one is mergesort. To me, the conceptually\neasiest is mergesort. They're actually\nkind of symmetric.",
    "start": "1818410",
    "end": "1825789"
  },
  {
    "text": "So you probably know\nbinary mergesort. You take your items, split\nthem in half, recursively sort, merge.",
    "start": "1825790",
    "end": "1831220"
  },
  {
    "text": "But we know that we can\nmerge M over B sorted lists in linear time as\nwell in N over M time.",
    "start": "1831220",
    "end": "1838000"
  },
  {
    "text": "So instead of doing\nbinary mergesort where we split in\nhalf, we're going to split into M over\nB equal sized pieces,",
    "start": "1838000",
    "end": "1843970"
  },
  {
    "text": "recursively sort them\nall, and then merge. And the recurrence we\nget from that, there is--",
    "start": "1843970",
    "end": "1849826"
  },
  {
    "text": "did I get this right? Yeah. There's M over B sub-problems,\neach of size a factor of M",
    "start": "1849826",
    "end": "1856600"
  },
  {
    "text": "over B smaller than N. And then to do the merge,\nwe pay N over B plus 1.",
    "start": "1856600",
    "end": "1862490"
  },
  {
    "text": "That won't end up mattering. To make this not matter,\nwe need to use a base case for this recurrence that's\nnot 1, but B. B will work.",
    "start": "1862490",
    "end": "1871540"
  },
  {
    "text": "You could also do M, but\nit doesn't really help you. Once we get down to a\nsingle block, of course,",
    "start": "1871540",
    "end": "1876550"
  },
  {
    "text": "we can sort in constant time. We read it and sort\nit, write it back out.",
    "start": "1876550",
    "end": "1882089"
  },
  {
    "text": "So you want to solve\nthis recurrence. Easy way is to draw\na recursion tree. At the root, you have\na problem of size N.",
    "start": "1882089",
    "end": "1888400"
  },
  {
    "text": "We're paying N\nover B to solve it. We have branching factor M\nover B. And at the leaves,",
    "start": "1888400",
    "end": "1893830"
  },
  {
    "text": "we have problems with size B.\nEach of them has constant cost. I'm removing the big Os to\nmake this diagram both more",
    "start": "1893830",
    "end": "1901570"
  },
  {
    "text": "legible and more correct. Because you can't use big Os\nwhen you're using dot dot dot. So no big Os for you.",
    "start": "1901570",
    "end": "1907809"
  },
  {
    "text": "So then use sum\nthese level by level, and you see we have\nconservation of mass. We have N things here.",
    "start": "1907810",
    "end": "1913630"
  },
  {
    "text": "We still have N things. They just got distributed up. They're all being\ndivided by B linearity. You get N over B at every\nlevel, including the leaves.",
    "start": "1913630",
    "end": "1920662"
  },
  {
    "text": "Leaves you have to\ncheck specially. But there are indeed\nN over B leaves, because we stop\nwhen we get to B.",
    "start": "1920662",
    "end": "1926380"
  },
  {
    "text": "So you add this up. We just need to know how\nmany levels are there. One is log base M\nover B of N over B.",
    "start": "1926380",
    "end": "1932890"
  },
  {
    "text": "Because there's N over B leaves\nbranching factor M over B. So you multiply, done, easy.",
    "start": "1932890",
    "end": "1939490"
  },
  {
    "text": "So mergesort is pretty cool. And this works really\nwell in practice. It revolutionized the\nworld of sorting in 1988.",
    "start": "1939490",
    "end": "1948100"
  },
  {
    "text": "Here's a different approach, the\ninverse, more like quicksort, the one that you know is\nguaranteed to run [INAUDIBLE]",
    "start": "1948100",
    "end": "1954430"
  },
  {
    "text": "log N usually. Here, you can't do\nbinary quicksort. You do M over B root M\nover B-way quicksort.",
    "start": "1954430",
    "end": "1961419"
  },
  {
    "text": "The square root is necessary\njust to do step one.",
    "start": "1961420",
    "end": "1966480"
  },
  {
    "text": "So step one is I need to split. Now, I'm not splitting\nmy list into chunks.",
    "start": "1966480",
    "end": "1973870"
  },
  {
    "text": "In the answer, in\nthe sorted answer, I need to find things that are\nevenly spaced in the answer.",
    "start": "1973870",
    "end": "1980049"
  },
  {
    "text": "That's the hard part. Then, usually, you find\nthe median to do this. But now, we have to find\nsort of square root of M",
    "start": "1980050",
    "end": "1985390"
  },
  {
    "text": "over B median-like elements\nspread out through the answer. But we don't know the answer,\nso it's a little tricky.",
    "start": "1985390",
    "end": "1991210"
  },
  {
    "text": "Then once we have those\npartition elements, we can just do it. This is the square root of\nM over B-way scan again.",
    "start": "1991210",
    "end": "1999067"
  },
  {
    "text": "You scan through the data. For each of them, you see how\nit compares to the partition elements.",
    "start": "1999067",
    "end": "2004110"
  },
  {
    "text": "There aren't very many of them. And then you write it out\nto the corresponding list, and you get square root\nof M over B plus 1 lists.",
    "start": "2004110",
    "end": "2011240"
  },
  {
    "text": "And so that's efficient,\nbecause it's just a scan or parallel scans. And then you recurse, and\nthere's no combination.",
    "start": "2011240",
    "end": "2018179"
  },
  {
    "text": "There's no merging to do. Once you've got\nthem set up there, you recursively sort,\nand you're done.",
    "start": "2018180",
    "end": "2023350"
  },
  {
    "text": "So the recurrence is exactly\nthe same as mergesort. And the hard part is how do\nyou do this partitioning?",
    "start": "2023350",
    "end": "2029070"
  },
  {
    "start": "2029000",
    "end": "2029000"
  },
  {
    "text": "And I'll just\nquickly sketch that. This is probably the most\ncomplicated algorithm in these slides.",
    "start": "2029070",
    "end": "2036330"
  },
  {
    "text": "I'll tell you the algorithm. Exactly why it works is familiar\nto if you know the Bloom",
    "start": "2036330",
    "end": "2042990"
  },
  {
    "text": "at all, linear time\nmerging algorithm for regular internal memory.",
    "start": "2042990",
    "end": "2049540"
  },
  {
    "text": "Here's what we're going to do. We're going to read in M items\ninto our cache, sort them.",
    "start": "2049540",
    "end": "2057513"
  },
  {
    "text": "So that's a piece of the\nanswer in some sense. But how it relates\nto the answer, which subset of the answer\nit is, we don't know.",
    "start": "2057513",
    "end": "2063360"
  },
  {
    "text": "Sample that piece of\nthe answer like this. Every root M over B\nitems, take one guy.",
    "start": "2063360",
    "end": "2070290"
  },
  {
    "text": "Spit that in an\noutput of samples. Do this over and over\nfor all the items-- read in M, sort,\nsample, spit out--",
    "start": "2070290",
    "end": "2077699"
  },
  {
    "text": "you end up with this many items. This is basically a trick\nto shrink your input.",
    "start": "2077699",
    "end": "2083167"
  },
  {
    "text": "So now, we can do inefficient\nthings on this many items, because there aren't\nthat many of them. So what do we do?",
    "start": "2083167",
    "end": "2089969"
  },
  {
    "text": "We just run the regular linear\ntime selection algorithm that you know and love\nfrom algorithms class",
    "start": "2089969",
    "end": "2097590"
  },
  {
    "text": "to find the right item. So if you were splitting\ninto four pieces,",
    "start": "2097590",
    "end": "2107370"
  },
  {
    "text": "then you'd want the\n25%, 50%, and 75%. You know how to do each\nof those in linear time.",
    "start": "2107370",
    "end": "2112684"
  },
  {
    "text": "And it turns out\nif you re-analyze the regular linear\ntime selection, indeed, it runs in N over B\ntime in external memory.",
    "start": "2112684",
    "end": "2119010"
  },
  {
    "text": "So that's great. But now, we're doing this\njust repeatedly over and over. You find the 25%.",
    "start": "2119010",
    "end": "2124860"
  },
  {
    "text": "You find the 50%. Each of them, you\nspend linear time. But you multiply it out. You're only finding root\nof M over B of them.",
    "start": "2124860",
    "end": "2131400"
  },
  {
    "text": "Linear time, it's not N over\nB, it's N divided by this mess. You multiply them\nout, it disappears.",
    "start": "2131400",
    "end": "2137340"
  },
  {
    "text": "You end up in\nregular linear time, N over B. You find a\ngood set of partitions.",
    "start": "2137340",
    "end": "2142500"
  },
  {
    "text": "Why this is a good set\nis not totally clear. I won't justify it here. But it is good, so don't worry.",
    "start": "2142500",
    "end": "2150170"
  },
  {
    "text": "OK. One embellishment to the\nexternal memory model before I go on is to\ndistinguish not just saying,",
    "start": "2150170",
    "end": "2159700"
  },
  {
    "text": "oh, well, every block\nis equally good. You want to count how\nmany blocks you read. When you read one item,\nyou get the whole block.",
    "start": "2159700",
    "end": "2166620"
  },
  {
    "text": "And you better use that block. But you can\nfurthermore say, well, it would be really good if I\nread a whole bunch of blocks",
    "start": "2166620",
    "end": "2171960"
  },
  {
    "text": "in sequence. There are lots of reasons\nfor this in particular. Disks are really good\nat sequential access,",
    "start": "2171960",
    "end": "2177990"
  },
  {
    "text": "because they're spinning. It's very easy to seek to\nthe thing right after you. First of all, it's easy\nto read the entire track,",
    "start": "2177990",
    "end": "2183810"
  },
  {
    "text": "the whole circle of the desk. And it's easy to\nmove that thing.",
    "start": "2183810",
    "end": "2189110"
  },
  {
    "text": "So here's a model\nthat captures the idea that sequential block reads or\nwrites are better than random.",
    "start": "2189110",
    "end": "2195756"
  },
  {
    "text": "So here's the idea\nof sequential. If you read M items, so you read\nM over B blocks in sequence,",
    "start": "2195756",
    "end": "2204599"
  },
  {
    "text": "then each of those is considered\nto be a sequential memory transfer. If you break that sequence, then\nyou're starting a new sequence.",
    "start": "2204600",
    "end": "2211260"
  },
  {
    "text": "Or it's just random\naccess if you don't fall into a big block like this. So there's a couple of\nresults in this model.",
    "start": "2211260",
    "end": "2218650"
  },
  {
    "text": "One is this harder version\nof external memory. So one thing is\nwhat about sorting?",
    "start": "2218650",
    "end": "2225180"
  },
  {
    "text": "We just covered sorting. It turns out those are pretty\nrandom access in the algorithms we saw. But if you use binary\nmergesort, it is sequential.",
    "start": "2225180",
    "end": "2235410"
  },
  {
    "text": "As you binary merge,\nthings are good. And that's,\nessentially, the best you can do, surprisingly,\nin this model.",
    "start": "2235410",
    "end": "2242069"
  },
  {
    "text": "If you want the number of\nrandom memory transfers",
    "start": "2242070",
    "end": "2247650"
  },
  {
    "text": "to be little o of\nthe sorting bound-- so you want more than\na constant fraction to be sequential--\nthen you need to use",
    "start": "2247650",
    "end": "2255660"
  },
  {
    "text": "at least this much\ntotal memory transfers. And so binary mergesort\nis optimal in this model,",
    "start": "2255660",
    "end": "2264390"
  },
  {
    "text": "assuming you want a reasonable\nnumber of sequential axises. And the main point\nof this paper was",
    "start": "2264390",
    "end": "2270060"
  },
  {
    "text": "to solve suffix-tree\nconstruction in external memory. And what they prove is\nit reduces to sorting, essentially, and scans.",
    "start": "2270060",
    "end": "2276000"
  },
  {
    "text": "And scans are good. So you get this\nexact same trade-off for suffix-tree construction,\nfair representation.",
    "start": "2276000",
    "end": "2284210"
  },
  {
    "text": "I have to be careful, because so\nmany authors are in those room. Cool. So let's move on to\na different model.",
    "start": "2284210",
    "end": "2290726"
  },
  {
    "text": "This is a model that\ndid not catch on. But it's fun for\nhistorical reasons to see what it was about.",
    "start": "2290727",
    "end": "2298070"
  },
  {
    "text": "You can see in here two issues. One is, what about a\ndeeper memory hierarchy?",
    "start": "2298070",
    "end": "2303800"
  },
  {
    "text": "Two levels is nice. Yeah, in practice, two\nlevels are all that matter. But we should really\nunderstand multiple levels.",
    "start": "2303800",
    "end": "2311420"
  },
  {
    "text": "Surely, there's a\nclean way to do that. And so there are a bunch of\nmodels that try to do this. And by the end, we get\nsomething that's reasonable.",
    "start": "2311420",
    "end": "2318950"
  },
  {
    "text": "And HMM is probably one of\nmy favorite weird models. It's \"particularly simple.\"",
    "start": "2318950",
    "end": "2324890"
  },
  {
    "text": "This is a quote from\ntheir own paper, not that they're boastful. It is a simple model. This is true.",
    "start": "2324890",
    "end": "2331850"
  },
  {
    "text": "And it does model, in some\nsense, a larger hierarchy. But the way it's\nphrased initially",
    "start": "2331850",
    "end": "2337430"
  },
  {
    "text": "doesn't look like this picture,\nbut they're equivalent. So it's a RAM model.",
    "start": "2337430",
    "end": "2342440"
  },
  {
    "text": "So your memory is an array. If you want to access position\nx in the array, you pay f of x.",
    "start": "2342440",
    "end": "2349490"
  },
  {
    "text": "And in the original\ndefinition, that's just log x. So what that corresponds to\nis the first item is free.",
    "start": "2349490",
    "end": "2355670"
  },
  {
    "text": "Second item costs 1. The next two items cost 2. The next four items cost 3.",
    "start": "2355670",
    "end": "2360800"
  },
  {
    "text": "The next eight items\ncost 4, and so on. So it's exactly this\nkind of memory hierarchy.",
    "start": "2360800",
    "end": "2366470"
  },
  {
    "text": "And you can move items. You can copy. And you can do all the\nthings you can do in a RAM. So this is a pretty good\nmodel of hierarchical memory.",
    "start": "2366470",
    "end": "2374559"
  },
  {
    "text": "It's just a little hard. So, originally, they\ndefined it with log x based on this book, which is\nthe classic reference of VLSI",
    "start": "2374560",
    "end": "2382730"
  },
  {
    "text": "at the time by Mead and Conway. It sort of revolutionized\nteaching VLSI. And it has this\nparticular construction",
    "start": "2382730",
    "end": "2389990"
  },
  {
    "text": "of a hierarchical RAM. I Don't know if RAMs are\nactually built this way. But they have a\nsketch of how to do it",
    "start": "2389990",
    "end": "2397099"
  },
  {
    "text": "that achieves a\nlogarithmic performance. The deeper you are, you pay log.",
    "start": "2397100",
    "end": "2405980"
  },
  {
    "text": "The bigger your\nspace is, you need to pay logarithmic to access it.",
    "start": "2405980",
    "end": "2411940"
  },
  {
    "text": "OK. So here are the results\nthat they get in this model. I'm not going to prove them. Because, again, they follow\nfrom the results in some sense.",
    "start": "2411940",
    "end": "2418970"
  },
  {
    "text": "But you've got matrix\nmultiplication, FFT sorting, scanning, binary search, a\nlot of the usual problems.",
    "start": "2418970",
    "end": "2425210"
  },
  {
    "text": "You get kind of weird running\ntimes, log, log, and so on.",
    "start": "2425210",
    "end": "2431150"
  },
  {
    "text": "Here, it's a matter of\nslow down versus speed up, because everything is going\nto cost more than constant now.",
    "start": "2431150",
    "end": "2436864"
  },
  {
    "text": "So you want to\nminimize slowdowns. Sometimes you get constant. The worst slow down\nyou can get is log N, because everything you\ncan access in, at most,",
    "start": "2436864",
    "end": "2443180"
  },
  {
    "text": "log N time in this model. But I would say setting f of\nN to be log N doesn't really",
    "start": "2443180",
    "end": "2449870"
  },
  {
    "text": "reveal what we care about. But in the same paper, they\ngive a better perspective of their own work.",
    "start": "2449870",
    "end": "2456150"
  },
  {
    "text": "So they say, well, let's\nlook at the general case. Maybe log x isn't\nthe right thing. Let's look at an\narbitrary f of x.",
    "start": "2456150",
    "end": "2462890"
  },
  {
    "text": "Well, you could\nwrite an arbitrary f of x as a weighted sum\nof threshold functions.",
    "start": "2462890",
    "end": "2468319"
  },
  {
    "text": "I want to know is\nx bigger than xi. If so, I pay wi. Well, that is just\nlike this picture.",
    "start": "2468320",
    "end": "2475989"
  },
  {
    "text": "Any function can be\nwritten like that if it's a discrete function. But you can also think\nof it in this form",
    "start": "2475989",
    "end": "2481529"
  },
  {
    "text": "if the xi's are sorted. After you get beyond\nx0 items, you pay w0. After you get beyond x1 items\ntotal, you pay w1, and so on.",
    "start": "2481530",
    "end": "2491010"
  },
  {
    "text": "So this gives you an\narbitrary memory hierarchy even with growing\nand shrinking sizes, which you'd never\nsee in practice.",
    "start": "2491010",
    "end": "2496550"
  },
  {
    "text": "But this is the general case. And we are going to\nassume here that f is polynomially bounded to make\nthese functions reasonable.",
    "start": "2496550",
    "end": "2504720"
  },
  {
    "text": "So when you double the input,\nyou only change the output by a constant factor. ",
    "start": "2504720",
    "end": "2511349"
  },
  {
    "text": "OK. Fine. So we have to solve\nthis weighted sum. But let's just look\nat one of these.",
    "start": "2511350",
    "end": "2517010"
  },
  {
    "text": "This is kind of the\ncanonical function. The rest is just a\nweighted sum of them. And if you assume this\npolynomial bounded property,",
    "start": "2517010",
    "end": "2523074"
  },
  {
    "text": "really it suffices\nto look at this. So this is called\nf sub M. We pay 1",
    "start": "2523074",
    "end": "2532430"
  },
  {
    "start": "2527000",
    "end": "2527000"
  },
  {
    "text": "to access anything beyond\nM. And we pay 0 otherwise. So they've taken general f\nwith this deep hierarchy,",
    "start": "2532430",
    "end": "2540230"
  },
  {
    "text": "and they've reduced to this\nmodel, the red-blue pebble",
    "start": "2540230",
    "end": "2546170"
  },
  {
    "text": "game, which we've already seen. I don't know if they\nmentioned this explicitly, but it's the same model again.",
    "start": "2546170",
    "end": "2552440"
  },
  {
    "text": "And that's good, because\na lot of problems-- well, they haven't been\nsolved exactly. I would say, now, this\npaper is the first one",
    "start": "2552440",
    "end": "2558674"
  },
  {
    "text": "to really say, OK,\nsorting, what's the best way I can sort in this model? And they get something.",
    "start": "2558674",
    "end": "2565030"
  },
  {
    "text": "Do I have it here? Yeah. They aim for a\nuniform optimality. This means there's\none algorithm that",
    "start": "2565030",
    "end": "2571700"
  },
  {
    "text": "works optimally for this\nthreshold function no matter what M is.",
    "start": "2571700",
    "end": "2577040"
  },
  {
    "text": "The algorithm\ndoesn't get to know M. You might say\nthe algorithm is oblivious to M. Sound familiar?",
    "start": "2577040",
    "end": "2584800"
  },
  {
    "text": "So this is a cool idea. Of course, it does\nnot have blocking yet. But none of this\nmodel has blocking.",
    "start": "2584800",
    "end": "2590160"
  },
  {
    "text": "But they prove that if\nyou're uniformly optimal, if you work in the red-blue\npebble game model for all M",
    "start": "2590160",
    "end": "2596010"
  },
  {
    "text": "with one algorithm,\nthen, in fact, you are optimal for all\nf of x, which means, in particular for the deep\nhierarchy, you also work.",
    "start": "2596010",
    "end": "2603840"
  },
  {
    "text": "And they achieve tight bounds\nfor a bunch of problems here. You should recognize\nall of these bounds",
    "start": "2603840",
    "end": "2609270"
  },
  {
    "text": "are now, in some\nsense, particular cases of the external memory bounds. So like sorting, you have this.",
    "start": "2609270",
    "end": "2615482"
  },
  {
    "text": "Except there's no B. The B has\ndisappeared, because there's no B in this model. But, otherwise, it is N\nover B log base M over B",
    "start": "2615482",
    "end": "2621119"
  },
  {
    "text": "of N over B and so\non down the line. They said, oh, search here is\nreally bad, because caching",
    "start": "2621120",
    "end": "2627930"
  },
  {
    "text": "doesn't really help for search. But blocks help for search. So when there's no B, these\nare exactly the bounds",
    "start": "2627930",
    "end": "2633270"
  },
  {
    "text": "you get for external memory. So I mean, some of\nthese were known. These were already\nknown by Hong and Kung,",
    "start": "2633270",
    "end": "2639240"
  },
  {
    "text": "because it's the\nsame special case. And then the others followed\nfrom external memory.",
    "start": "2639240",
    "end": "2644379"
  },
  {
    "text": "But this is kind of neat. They're doing it in a somewhat\nstronger sense, because it's",
    "start": "2644379",
    "end": "2650040"
  },
  {
    "text": "uniform without knowing\nM. So the uniformity doesn't follow from this.",
    "start": "2650040",
    "end": "2656110"
  },
  {
    "text": "But they get uniformity. And therefore, it\nworks for all f. OK.",
    "start": "2656110",
    "end": "2662859"
  },
  {
    "start": "2661000",
    "end": "2661000"
  },
  {
    "text": "They had another\nfun fact, which will look familiar to\nthose of you who know the cache-oblivious\nmodel, which we'll get to.",
    "start": "2662860",
    "end": "2668049"
  },
  {
    "text": "They have this\nobservation that while we have these algorithms that are\nexplicitly moving things around in our RAM, it\nwould be nice if we",
    "start": "2668050",
    "end": "2674230"
  },
  {
    "text": "didn't have to write that down\nexplicitly in the algorithm. Could we just use least\nrecently used replacement,",
    "start": "2674230",
    "end": "2680650"
  },
  {
    "text": "so move things forward? That works great if\nyou know what M is.",
    "start": "2680650",
    "end": "2685900"
  },
  {
    "text": "Then you say, OK, if I need to\nget something from out if here, I'll move it over here. And whatever was least\nrecently used, I'll kick out.",
    "start": "2685900",
    "end": "2693190"
  },
  {
    "text": "And at this point,\nthis is just a couple of years prior to this paper. Sleator and Tarjan did the first\npaper on competitive analysis.",
    "start": "2693190",
    "end": "2699910"
  },
  {
    "text": "And they proved that\nLRU or even first in, first out is good in the\nsense that if you just",
    "start": "2699910",
    "end": "2705310"
  },
  {
    "text": "double the size of your cache-- oh, I got this backwards. TLRU of twice the\ncache is, at most,",
    "start": "2705310",
    "end": "2713290"
  },
  {
    "text": "TOPT of 1 times the cache. So the 2 should be over here. ",
    "start": "2713290",
    "end": "2720100"
  },
  {
    "text": "Great. And assuming you have a\npolynomially bounded growth function, then this is only\nlosing a constant factor.",
    "start": "2720100",
    "end": "2727130"
  },
  {
    "text": "OK. But we don't know what M is. This works for the\nthreshold function f sub m. But it doesn't work for\nan arbitrary function f,",
    "start": "2727130",
    "end": "2733270"
  },
  {
    "text": "or it doesn't work uniformly. And we want a uniform solution. And they gave one. I'll just sketch it here.",
    "start": "2733270",
    "end": "2739619"
  },
  {
    "text": "The idea is you have\nthis arbitrary hierarchy. You don't really know. I'm going to assume\nI do know what f is.",
    "start": "2739619",
    "end": "2745720"
  },
  {
    "text": "So this is not uniform. It's achieved in\na different way. But I'm going to basically\nrearrange the structure",
    "start": "2745720",
    "end": "2752500"
  },
  {
    "text": "to be roughly\nexponential to say, well, I'm going to measure\nf of x as x increases. And whenever f of x\ndoubles, I'll draw a line.",
    "start": "2752500",
    "end": "2759713"
  },
  {
    "text": "These are not where\nthe real levels are. It's just a conceptual thing. And then I do LRU\non this structure.",
    "start": "2759714",
    "end": "2764980"
  },
  {
    "text": "So if I want to access\nsomething here, I pull it out. I stick it in here. Whatever is least recently\nused gets kicked out here.",
    "start": "2764980",
    "end": "2770920"
  },
  {
    "text": "And whatever is\nleast recently used gets kicked out\nhere, here, here. And you do a chain of LRUs. Then you can prove that is\nwithin a constant factor",
    "start": "2770920",
    "end": "2777610"
  },
  {
    "text": "of optimal, but you do\nhave to pay a startup cost. It's similar to move\nto front analysis",
    "start": "2777610",
    "end": "2784080"
  },
  {
    "text": "from Sleator and Tarjan. OK. Enough about HMM sort of.",
    "start": "2784080",
    "end": "2790589"
  },
  {
    "text": "The next model is called BT. It's the same as HMM,\nbut they add blocks.",
    "start": "2790590",
    "end": "2795810"
  },
  {
    "text": "But not the blocks that we know\nfrom computer architecture, but a different\nkind of block thing.",
    "start": "2795810",
    "end": "2801030"
  },
  {
    "text": "It's kind of similar. Probably, [INAUDIBLE] constant\nfactors and not so different. So you have the old thing\naccessing x costs f of x.",
    "start": "2801030",
    "end": "2810312"
  },
  {
    "text": "But, now, you have\na new operation, which is I can copy\nany interval, which would look something like\nthis, from x minus delta to x.",
    "start": "2810312",
    "end": "2817109"
  },
  {
    "text": "And I can copy it to\ny minus delta to y. And I pay the time to seek\nthere, f of max of x and y.",
    "start": "2817110",
    "end": "2825210"
  },
  {
    "text": "Or you could do f\nof x plus f of y. It doesn't matter. And then you pay plus delta. So you can move a big\nchunk relatively quickly.",
    "start": "2825210",
    "end": "2832915"
  },
  {
    "text": "You just pay once to get there,\nand then you can move it. This is a lot more\nreasonable than HMM.",
    "start": "2832915",
    "end": "2838560"
  },
  {
    "text": "But it makes things a lot\nmessier is the short answer. Because-- here's a block move--",
    "start": "2838560",
    "end": "2844969"
  },
  {
    "text": "these are the sort\nof bounds you get. They depend now on f. And you don't get the\nsame kind of uniformity",
    "start": "2844969",
    "end": "2851280"
  },
  {
    "text": "as far as I can tell. You can't just say,\noh, it works for all f. For each of these problems, this\nis basically scanning or matrix",
    "start": "2851280",
    "end": "2859079"
  },
  {
    "text": "multiplication. It doesn't matter much until f\nof x gets really big, and then something changes.",
    "start": "2859080",
    "end": "2865170"
  },
  {
    "text": "You Dot product, you\nget log*, log, log, log, depending on whether your f\nof x is log or subpolynomial",
    "start": "2865170",
    "end": "2871950"
  },
  {
    "text": "or linear. So I find this kind\nof unsatisfying. So I'm just going to move\non to MH, which is probably",
    "start": "2871950",
    "end": "2879180"
  },
  {
    "start": "2877000",
    "end": "2877000"
  },
  {
    "text": "the messiest of the models. But in some sense, it's the\nmost realistic of the models. Here's the picture\nwhich I would draw",
    "start": "2879180",
    "end": "2885660"
  },
  {
    "text": "if someone asked me to draw\na general memory hierarchy. I have CPU connects to\nthis cache for free. It has blocks of size B0.",
    "start": "2885660",
    "end": "2892140"
  },
  {
    "text": "And to go to the next memory,\nit costs me some time, t0. And the blocks that I read here\nof size B0, I write of size B0.",
    "start": "2892140",
    "end": "2900180"
  },
  {
    "text": "So the transfers\nhere are size B0. And one has potentially\na different block size. It has a different\ncache size, M1.",
    "start": "2900180",
    "end": "2906030"
  },
  {
    "text": "And you pay. So these blocks are subdivided\ninto B0 sized blocks, which happen here.",
    "start": "2906030",
    "end": "2911700"
  },
  {
    "text": "This is a generic multi-level\nmemory hierarchy picture. It's the obvious extension\nof the external memory model to arbitrarily many levels.",
    "start": "2911700",
    "end": "2918960"
  },
  {
    "text": "And to make it so\neasy to program, all levels can be\ntransferring at once. This is realistic, but\nhard to manipulate.",
    "start": "2918960",
    "end": "2928500"
  },
  {
    "text": "And they thought, oh,\nwell, l parameters for an l-level\nhierarchy is too many.",
    "start": "2928500",
    "end": "2934360"
  },
  {
    "text": "So let's reduce it to two\nparameters and one function. So assume that B [? does\n?] grow exponentially,",
    "start": "2934360",
    "end": "2940800"
  },
  {
    "text": "that these things grow\nroughly the same way. with some aspect ratio alpha. And then the ti--",
    "start": "2940800",
    "end": "2946260"
  },
  {
    "text": "this is the part\nthat's hard to guess-- it grows exponentially. And then there's some f\nof i, which we don't know,",
    "start": "2946260",
    "end": "2951450"
  },
  {
    "text": "maybe it's log i. And because of that,\nthis doesn't really clean the model enough.",
    "start": "2951450",
    "end": "2957420"
  },
  {
    "text": "You get bounds, which,\nit's interesting. You can say as long as f of\ni is, at most, something,",
    "start": "2957420",
    "end": "2963720"
  },
  {
    "text": "then we get optimal bounds. But sometimes when f of\ni grows, things change.",
    "start": "2963720",
    "end": "2969190"
  },
  {
    "text": "And it's interesting. These algorithms\nfollow approaches that we will see in a\nmoment, divide and conquer.",
    "start": "2969190",
    "end": "2975570"
  },
  {
    "text": "But it's hard to state\nwhat the answers are. What's B4?",
    "start": "2975570",
    "end": "2981636"
  },
  {
    "text": "I think that's just a typo. That should be blank. I mean, it's hard to\nbeat an upper bound of 1.",
    "start": "2981636",
    "end": "2988520"
  },
  {
    "text": "It also seems wrong. Ignore that row. All right.",
    "start": "2988520",
    "end": "2993840"
  },
  {
    "text": "Finally, we go to the\ncache-oblivious model by Frigo, et al. in 1999.",
    "start": "2993840",
    "end": "3001140"
  },
  {
    "text": "This is another clean model. And this is another of the two\nmodels that really caught on.",
    "start": "3001140",
    "end": "3007000"
  },
  {
    "text": "It's motivated by all the\nmodels you've just seen. And in particular, it picks up\non the other successful model,",
    "start": "3007000",
    "end": "3013309"
  },
  {
    "text": "the External Memory\nModel and says, OK, let's take External Memory\nModel, exactly the same cost model.",
    "start": "3013310",
    "end": "3018410"
  },
  {
    "text": "But suppose your algorithm\ndoesn't know B or M. And we're going to analyze\nit in this model knowing",
    "start": "3018410",
    "end": "3023450"
  },
  {
    "text": "what B and M is. But, really, one algorithm\nhas to work for all B and M. This is uniformity from the--",
    "start": "3023450",
    "end": "3030560"
  },
  {
    "text": "I can't even remember\nthe model names-- not UMH, but the HMM model.",
    "start": "3030560",
    "end": "3036920"
  },
  {
    "text": "So it's taking that\nidea, but applying it to a model that has blocking. ",
    "start": "3036920",
    "end": "3044510"
  },
  {
    "text": "So for this to be\nmeaningful, block transfers have to be automatic. Because you can't manually\nmove between here and here.",
    "start": "3044510",
    "end": "3051173"
  },
  {
    "text": "In HMM, you could manually\nmove things around, because your memory is\njust a sequential thing. But now, you don't\nknow where the cutoff",
    "start": "3051174",
    "end": "3056570"
  },
  {
    "text": "is between cache and disks. So you can't manually\nmanage your memory. So you have to assume\nautomatic block replacement.",
    "start": "3056570",
    "end": "3062360"
  },
  {
    "text": "But we already know\nLRU or FIFOs only going to lose a constant factor. So that's cool.",
    "start": "3062360",
    "end": "3069560"
  },
  {
    "text": "I like this model,\nbecause it's clean. Also, in a certain sense, it's\na little hard to formalize this.",
    "start": "3069560",
    "end": "3074720"
  },
  {
    "text": "But it works for changing B,\nbecause it works for all B. And so you can imagine even\nif B is not a uniform thing--",
    "start": "3074720",
    "end": "3080450"
  },
  {
    "text": "like the size of tracks\non a disk are varying, because circles have\ndifferent sizes--",
    "start": "3080450",
    "end": "3086500"
  },
  {
    "text": "it probably works\nwell in that setting. It also works if your cache\ngets smaller, because you've",
    "start": "3086500",
    "end": "3092109"
  },
  {
    "text": "got a competing process. It'll just adjust, because\nthe analysis will work.",
    "start": "3092110",
    "end": "3098470"
  },
  {
    "text": "And the other fun thing\nis even though you're analyzing on a two-level\nmemory hierarchy, it works on an arbitrary memory\nhierarchy, this MH thing.",
    "start": "3098470",
    "end": "3106850"
  },
  {
    "text": "This is a clean\nway to tackle MH. You just need a\ncache-oblivious solution.",
    "start": "3106850",
    "end": "3114040"
  },
  {
    "text": "Cool. Because you can\nimagine the levels",
    "start": "3114040",
    "end": "3119070"
  },
  {
    "text": "to the left of something and\nthe levels to the right of some point. And the cache-oblivious\nanalysis tells you that the number of transfers\nover this boundary is optimal.",
    "start": "3119070",
    "end": "3126338"
  },
  {
    "text": "And if that's true\nfor every boundary, then the overall\nthing will be optimal, just like for HMM uniformity.",
    "start": "3126338",
    "end": "3135040"
  },
  {
    "text": "OK. Quickly some techniques\nfrom cache-oblivious. I don't have much\ntime, so I will just",
    "start": "3135040",
    "end": "3140050"
  },
  {
    "text": "give you a couple sketches. Scanning is one that generalizes\ngreat from external memory. Of course, every\ncache-oblivious algorithm",
    "start": "3140050",
    "end": "3145730"
  },
  {
    "text": "is external memory also. So we should first try all the\nexternal memory techniques. You can scan.",
    "start": "3145730",
    "end": "3151210"
  },
  {
    "text": "You can't really do M\nover B parallel scans, because you don't\nknow what M over B is. But you can do a constant\nnumber of parallel scans.",
    "start": "3151210",
    "end": "3156995"
  },
  {
    "text": "So you could at least\nmerge two lists. OK. Searching, so this is the\nanalog of binary search.",
    "start": "3156995",
    "end": "3164980"
  },
  {
    "text": "You'd like to achieve log\nbase B of N query time. And you can do that. And this is in Harald\nProkop's master's thesis.",
    "start": "3164980",
    "end": "3172940"
  },
  {
    "text": "So the idea is pretty cool. You imagine a binary search\ntree built on the items.",
    "start": "3172940",
    "end": "3180910"
  },
  {
    "text": "We can't do a B-way, because\nwe don't know what B is. But then we cut it\nat the middle level, recursively store the\ntop part, and then",
    "start": "3180910",
    "end": "3188046"
  },
  {
    "text": "recursively store\nall the bottom parts, and get root N\nchunks of size root N. Do that recursively, you get\nsome kind of lay out like this.",
    "start": "3188046",
    "end": "3195609"
  },
  {
    "text": "And it turns out\nthis works very well. Because at some level\nof the recursion, whatever B is-- it\ndoesn't know when",
    "start": "3195610",
    "end": "3200704"
  },
  {
    "text": "you're doing the recursion. But B is something. And if you look at\nthe level of recursion where you straddle B here,\nthese things are size, at most,",
    "start": "3200705",
    "end": "3207536"
  },
  {
    "text": "B. And the next level up\nis size bigger than B. Then you look at a\nroot to leaf path here.",
    "start": "3207536",
    "end": "3214625"
  },
  {
    "text": "It's a matter of how\nmany of these blue triangles do you visit. Well, the height\nof a blue triangle is going to be\naround half log B,",
    "start": "3214625",
    "end": "3221590"
  },
  {
    "text": "because we're dividing in\nhalf until we hit log B. So we might overshoot by a\nfactor of 2, but that's all.",
    "start": "3221590",
    "end": "3227800"
  },
  {
    "text": "And we only have to pay 2\nmemory transfers to visit these. Because we don't know how\nit's aligned with a block.",
    "start": "3227800",
    "end": "3232810"
  },
  {
    "text": "but at most, it fits\nin 2 blocks, certainly. It's stored consecutively\nby the recursion.",
    "start": "3232810",
    "end": "3237940"
  },
  {
    "text": "And so you divide. I mean, the height\nof this thing, it's going to be log\nbase B of N times 2.",
    "start": "3237940",
    "end": "3243460"
  },
  {
    "text": "We pay 2 each. So we get an upper bound of 4. Not as good as B-trees. B-trees get 1 times\nlog base B of N. Here,",
    "start": "3243460",
    "end": "3250270"
  },
  {
    "text": "we get 4 times log base\nB of N. This problem has been considered. The right answer is\nlog of e plus little o.",
    "start": "3250270",
    "end": "3257900"
  },
  {
    "text": "And that is tight. You can't do better\nthan that bound. So cache-oblivious\nloses a constant factor",
    "start": "3257900",
    "end": "3264520"
  },
  {
    "text": "relative to external\nmemory for that problem. You can also make this dynamic. This is where a\nbunch of us started",
    "start": "3264520",
    "end": "3270160"
  },
  {
    "text": "getting involved in this world,\nin cache-oblivious world. And this is a sketch of one of\nthe methods, I think this one.",
    "start": "3270160",
    "end": "3279849"
  },
  {
    "text": "That's the one I usually teach. You might have guessed these\nare from lecture notes, these handwritten things.",
    "start": "3279850",
    "end": "3285700"
  },
  {
    "text": "I'll plug that in in a second. So sorting is trickier. There is an analog to mergesort.",
    "start": "3285700",
    "end": "3291760"
  },
  {
    "text": "There is an analog\nto distribution sort. They achieve the sorting bound. But they do need an assumption,\nthis tall-cache assumption.",
    "start": "3291760",
    "end": "3298100"
  },
  {
    "text": "It's a little different\nfrom the last one. This is a stronger\nassumption than before. It says the cache is taller\nthan it is wide, roughly,",
    "start": "3298100",
    "end": "3305230"
  },
  {
    "text": "up to some epsilon exponent. So this is saying M over B\nis at least B to the epsilon.",
    "start": "3305230",
    "end": "3311290"
  },
  {
    "text": "Most caches have that property,\nso it's not that big a deal. But you can prove\nit's necessary. If you don't have it, you can't\nachieve the sorting bound.",
    "start": "3311290",
    "end": "3317980"
  },
  {
    "text": "You could also prove you cannot\nachieve the permutation bound, because you can't do that min. You don't know which\nis better, same paper.",
    "start": "3317980",
    "end": "3326170"
  },
  {
    "text": "Finally, I wanted\nto plug this class. It just got released\nif you're interested.",
    "start": "3326170",
    "end": "3331420"
  },
  {
    "text": "It's advanced data structures. There's video lectures\nfor free streaming online. There are three lectures\nabout cache-oblivious stuff,",
    "start": "3331420",
    "end": "3337810"
  },
  {
    "text": "mostly on the data\nstructure side, because it's a data structures class. But if you're interested\nin data structures, you should check it out.",
    "start": "3337810",
    "end": "3343900"
  },
  {
    "text": "That is the end of my\nsummary of a zillion models. The ones to keep\nin mind, of course, are external memory\nand cache-oblivious.",
    "start": "3343900",
    "end": "3349930"
  },
  {
    "start": "3344000",
    "end": "3344000"
  },
  {
    "text": "But the others are kind of fun. And you really see the\ngenesis of how this was the union of these two models.",
    "start": "3349930",
    "end": "3356170"
  },
  {
    "text": "And this was sort of the\nculmination of this effort to do multilevel in a clean way.",
    "start": "3356170",
    "end": "3362170"
  },
  {
    "text": "So I learned a lot looking\nat all these papers. Hope you enjoyed it. Thanks. [APPLAUSE]",
    "start": "3362170",
    "end": "3371005"
  },
  {
    "text": "PROFESSOR: Are\nthere any questions? AUDIENCE: So all these are\norder of magnitude bounds",
    "start": "3371005",
    "end": "3377440"
  },
  {
    "text": "I'm wondering about\nthe constant factors. ERIK DEMAINE: Are you\nguys going to talk about that in your final talk?",
    "start": "3377440",
    "end": "3383920"
  },
  {
    "text": "Or who knows? Or Lars maybe also?",
    "start": "3383920",
    "end": "3391780"
  },
  {
    "text": "Some of these papers\neven evaluated that, especially these guys\nthat had the messy models.",
    "start": "3391780",
    "end": "3396790"
  },
  {
    "text": "They were getting the\nparameters of, at that time, [INAUDIBLE] 6,000 processor,\nwhich is something I've",
    "start": "3396790",
    "end": "3401890"
  },
  {
    "text": "actually used, so not so old. And they got very good\nmatching even at that point.",
    "start": "3401890",
    "end": "3409830"
  },
  {
    "text": "I'd say external memory does\nvery good for modeling disk. I don't know if people\nuse it a lot for cache.",
    "start": "3409830",
    "end": "3416830"
  },
  {
    "text": "No, I'm told. Cache-oblivious, it's a\nlittle harder to measure.",
    "start": "3416830",
    "end": "3424010"
  },
  {
    "text": "Because you're not trying\nto tune to specific things. But in practice, it seems to\ndo very well for many problems.",
    "start": "3424010",
    "end": "3430190"
  },
  {
    "text": "That's the short answer. AUDIENCE: [INAUDIBLE]\nit runs faster than [INAUDIBLE] cache aware.",
    "start": "3430190",
    "end": "3435940"
  },
  {
    "text": "ERIK DEMAINE: Yeah. It does better than\nour analysis said it should do in some sense,\nbecause it's so flexible.",
    "start": "3435940",
    "end": "3441880"
  },
  {
    "text": "And the reality is very messy. In reality, M is\nchanging, because there's all sorts of processes\ndoing useless work.",
    "start": "3441880",
    "end": "3449710"
  },
  {
    "text": "And cache-oblivious\nwill adjust to that. And it's especially the\ncase in internal memory,",
    "start": "3449710",
    "end": "3455069"
  },
  {
    "text": "in the cache world. Things are very messy and fussy. And the nice thing\nabout cache-oblivious",
    "start": "3455069",
    "end": "3460810"
  },
  {
    "text": "is because you're not\nspecifically tuning, you have the potential to\nnot die when you mess up. AUDIENCE: I'd say\nthat's especially",
    "start": "3460810",
    "end": "3466397"
  },
  {
    "text": "the case in the disk world. ERIK DEMAINE: Oh, interesting. AUDIENCE: [INAUDIBLE] But-- ERIK DEMAINE: These\nare the guys who know.",
    "start": "3466397",
    "end": "3471880"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] people\nhave different [INAUDIBLE] ERIK DEMAINE: Yeah. They're both relevant. AUDIENCE: What's the future?",
    "start": "3471880",
    "end": "3478040"
  },
  {
    "text": "This is history. ERIK DEMAINE: OK. Well, for the future, you should\ngo to the other talks, I guess. There's still lots of open\nproblems in both models.",
    "start": "3478040",
    "end": "3485600"
  },
  {
    "text": "External memory, I guess,\ngraph algorithms and geometry are still the main topics\nof ongoing research.",
    "start": "3485600",
    "end": "3491020"
  },
  {
    "text": "Cache-oblivious is similar. At this point, I think-- well, also geometry\nis a big one.",
    "start": "3491020",
    "end": "3497349"
  },
  {
    "text": "There's some external\nmemory results that have not yet been\ncache-oblivified in geometry.",
    "start": "3497350",
    "end": "3504880"
  },
  {
    "text": "AUDIENCE: Multicore. ERIK DEMAINE: Multicore. Oh, yeah, I forgot\nto say I'm not going to talk about\nparallel models here.",
    "start": "3504880",
    "end": "3511327"
  },
  {
    "text": "Partly, because of lack of time. Also, that's probably\nthe most active-- it's an interesting active\narea of research, something",
    "start": "3511327",
    "end": "3519260"
  },
  {
    "text": "I'm interested in particular. There are some results about\nparallel cache-oblivious.",
    "start": "3519260",
    "end": "3525350"
  },
  {
    "text": "And all of these papers\nactually had parallelism. These had parallelism\nin a single disk.",
    "start": "3525350",
    "end": "3533084"
  },
  {
    "text": "There's another model\nthat has multiple disks. Those behave more\nor less the same. You basically divide\neverything by p.",
    "start": "3533084",
    "end": "3538759"
  },
  {
    "text": "These models also tried\nto introduce parallelism. Or there's a follow up\nto UMH by these guys.",
    "start": "3538759",
    "end": "3544130"
  },
  {
    "text": "So there is work\non parallel, but I think multicore or\ncache-oblivious is probably the most exciting unknown\nor still in progress stuff.",
    "start": "3544130",
    "end": "3551044"
  },
  {
    "text": "AUDIENCE: Thank\nthe speaker again. ERIK DEMAINE: Thanks. [APPLAUSE]",
    "start": "3551044",
    "end": "3557910"
  },
  {
    "start": "3557910",
    "end": "3563124"
  }
]
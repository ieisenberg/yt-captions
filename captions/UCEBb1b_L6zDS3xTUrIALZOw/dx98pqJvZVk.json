[
  {
    "start": "0",
    "end": "74000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu.  JULIAN SHUN: Today,\nwe're going to talk",
    "start": "18140",
    "end": "23350"
  },
  {
    "text": "about multicore programming. And as I was just informed\nby Charles, it's 2018.",
    "start": "23350",
    "end": "30730"
  },
  {
    "text": "I had 2017 on the slide. So first, congratulations\nto all of you.",
    "start": "30730",
    "end": "40380"
  },
  {
    "text": "You turned in the\nfirst project's data.",
    "start": "40380",
    "end": "45850"
  },
  {
    "text": "Here's a plot showing the tiers\nthat different groups reached for the beta.",
    "start": "45850",
    "end": "51460"
  },
  {
    "text": "And this is in sorted order. And we set the beta\ncutoff to be tier 45.",
    "start": "51460",
    "end": "57910"
  },
  {
    "text": "The final cutoff is tier 48. So the final cutoff we did\nset a little bit aggressively,",
    "start": "57910",
    "end": "63550"
  },
  {
    "text": "but keep in mind that\nyou don't necessarily have to get to the\nfinal cutoff in order to get an A on this project.",
    "start": "63550",
    "end": "70299"
  },
  {
    "text": " So we're going to talk about\nmulticore processing today.",
    "start": "70300",
    "end": "78540"
  },
  {
    "start": "74000",
    "end": "74000"
  },
  {
    "text": "That's going to be the\ntopic of the next project after you finish\nthe first project.",
    "start": "78540",
    "end": "84160"
  },
  {
    "text": "So in a multicore processor,\nwe have a whole bunch of cores that are all\nplaced on the same chip,",
    "start": "84160",
    "end": "90760"
  },
  {
    "text": "and they have access\nto shared memory. They usually also have some\nsort of private cache, and then",
    "start": "90760",
    "end": "98590"
  },
  {
    "text": "a shared last level cache,\nso L3, in this case. And then they all have access\nthe same memory controller,",
    "start": "98590",
    "end": "104990"
  },
  {
    "text": "which goes out to main memory. And then they also\nhave access to I/O. But for a very long time, chips\nonly had a single core on them.",
    "start": "104990",
    "end": "114820"
  },
  {
    "text": "So why do we have multicore\nprocessors nowadays? Why did semiconductor\nvendors start",
    "start": "114820",
    "end": "120640"
  },
  {
    "text": "producing chips that\nhad multiple processor cores on them? ",
    "start": "120640",
    "end": "126880"
  },
  {
    "text": "So the answer is\nbecause of two things. So first, there's\nMoore's Law, which",
    "start": "126880",
    "end": "132880"
  },
  {
    "text": "says that we get more\ntransistors every year. So the number of transistors\nthat you can fit on a chip",
    "start": "132880",
    "end": "139030"
  },
  {
    "text": "doubles approximately\nevery two years. And secondly, there's the end\nof scaling of clock frequency.",
    "start": "139030",
    "end": "145340"
  },
  {
    "text": "So for a very long\ntime, we could just keep increasing the frequency\nof the single core on the chip.",
    "start": "145340",
    "end": "152140"
  },
  {
    "text": "But at around 2004 to 2005,\nthat was no longer the case.",
    "start": "152140",
    "end": "157330"
  },
  {
    "text": "We couldn't scale the\nclock frequency anymore.",
    "start": "157330",
    "end": "162530"
  },
  {
    "text": "So here's a plot showing both\nthe number of transistors you could fit on\nthe chip over time,",
    "start": "162530",
    "end": "168740"
  },
  {
    "text": "as well as the clock frequency\nof the processors over time. And notice that the y-axis\nis in log scale here.",
    "start": "168740",
    "end": "175730"
  },
  {
    "text": "And the blue line is\nbasically Moore's Law, which says that the\nnumber of transistors",
    "start": "175730",
    "end": "180860"
  },
  {
    "text": "you can fit on a chip doubles\napproximately every two years. And that's been growing\npretty steadily.",
    "start": "180860",
    "end": "186350"
  },
  {
    "text": "So this plot goes up to\n2010, but in fact, it's been growing even up\nuntil the present. And it will continue\nto grow for a couple",
    "start": "186350",
    "end": "193310"
  },
  {
    "text": "more years before\nMoore's Law ends. However, if you look at\nthe clock frequency line,",
    "start": "193310",
    "end": "199980"
  },
  {
    "text": "you see that it\nwas growing quite steadily until about the early\n2000s, and then at that point,",
    "start": "199980",
    "end": "206720"
  },
  {
    "text": "it flattened out. ",
    "start": "206720",
    "end": "212580"
  },
  {
    "text": "So at that point, we couldn't\nincrease the clock frequencies anymore, and the clock\nspeed was bounded",
    "start": "212580",
    "end": "218959"
  },
  {
    "text": "at about four gigahertz. So nowadays, if you\ngo buy a processor, it's usually still bounded\nby around 4 gigahertz.",
    "start": "218960",
    "end": "226820"
  },
  {
    "text": "It's usually a little bit\nless than 4 gigahertz, because it doesn't really make\nsense to push it all the way. But you might find\nsome processors",
    "start": "226820",
    "end": "235280"
  },
  {
    "text": "that are around 4\ngigahertz nowadays. So what happened at\naround 2004 to 2005?",
    "start": "235280",
    "end": "243709"
  },
  {
    "text": "Does anyone know? ",
    "start": "243710",
    "end": "253720"
  },
  {
    "text": "So Moore's Law\nbasically says that we can fit more\ntransistors on a chip because the transistors\nbecome smaller.",
    "start": "253720",
    "end": "260730"
  },
  {
    "text": "And when the transistors\nbecome smaller, you can reduce\nthe voltage that's needed to operate\nthe transistors.",
    "start": "260730",
    "end": "267390"
  },
  {
    "text": "And as a result, you can\nincrease the clock frequency while maintaining the\nsame power density.",
    "start": "267390",
    "end": "273210"
  },
  {
    "text": "And that's what manufacturers\ndid until about 2004 to 2005. They just kept increasing\nthe clock frequency",
    "start": "273210",
    "end": "279900"
  },
  {
    "text": "to take advantage\nof Moore's law. But it turns out that\nonce transistors become small enough, and\nthe voltage used",
    "start": "279900",
    "end": "286889"
  },
  {
    "text": "to operate them\nbecomes small enough, there's something\ncalled leakage current.",
    "start": "286890",
    "end": "292169"
  },
  {
    "text": "So there's current\nthat leaks, and we're unable to keep reducing the\nvoltage while still having",
    "start": "292170",
    "end": "298080"
  },
  {
    "text": "reliable switching. And if you can't reduce\nthe voltage anymore,",
    "start": "298080",
    "end": "303250"
  },
  {
    "text": "then you can't increase\nthe clock frequency if you want to keep\nthe same power density.",
    "start": "303250",
    "end": "308925"
  },
  {
    "text": " So here's a plot from\nIntel back in 2004",
    "start": "308925",
    "end": "317840"
  },
  {
    "start": "314000",
    "end": "314000"
  },
  {
    "text": "when they first started\nproducing multicore processors. And this is plotting the\npower density versus time.",
    "start": "317840",
    "end": "325220"
  },
  {
    "text": "And again, the y-axis\nis in log scale here. So the green data points\nare actual data points,",
    "start": "325220",
    "end": "332120"
  },
  {
    "text": "and the orange\nones are projected. And they projected\nwhat the power density",
    "start": "332120",
    "end": "338660"
  },
  {
    "text": "would be if we kept\nincreasing the clock frequency at a trend of\nabout 25% to 30% per year,",
    "start": "338660",
    "end": "346260"
  },
  {
    "text": "which is what happened\nup until around 2004. And because we couldn't\nreduce the voltage anymore,",
    "start": "346260",
    "end": "353330"
  },
  {
    "text": "the power density will go up. And you can see\nthat eventually, it",
    "start": "353330",
    "end": "359120"
  },
  {
    "text": "reaches the power density\nof a nuclear reactor, which is pretty hot.",
    "start": "359120",
    "end": "365510"
  },
  {
    "text": "And then it reaches the power\ndensity of a rocket nozzle, and eventually you\nget to the power density of the sun's surface.",
    "start": "365510",
    "end": "373379"
  },
  {
    "text": "So if you have a chip\nthat has a power density equal to the sun's surface--",
    "start": "373380",
    "end": "379580"
  },
  {
    "text": "well, you don't actually\nreally have a chip anymore. ",
    "start": "379580",
    "end": "385970"
  },
  {
    "text": "So basically if you get\ninto this orange region, you basically have a\nfire, and you can't really do anything interesting,\nin terms of performance",
    "start": "385970",
    "end": "393020"
  },
  {
    "text": "engineering, at that point. So to solve this problem,\nsemiconductor vendors",
    "start": "393020",
    "end": "403640"
  },
  {
    "start": "400000",
    "end": "400000"
  },
  {
    "text": "didn't increased the\nclock frequency anymore, but we still had\nMoore's Law giving us",
    "start": "403640",
    "end": "410150"
  },
  {
    "text": "more and more\ntransistors every year. So what they decided to do\nwith these extra transistors",
    "start": "410150",
    "end": "415880"
  },
  {
    "text": "was to put them\ninto multiple cores, and then put multiple\ncores on the same chip.",
    "start": "415880",
    "end": "422280"
  },
  {
    "text": "So we can see that,\nstarting at around 2004, the number of cores per\nchip becomes more than one.",
    "start": "422280",
    "end": "430820"
  },
  {
    "text": " And each generation\nof Moore's Law",
    "start": "430820",
    "end": "435860"
  },
  {
    "text": "will potentially double\nthe number of cores that you can fit on a\nchip, because it's doubling the number of transistors.",
    "start": "435860",
    "end": "441920"
  },
  {
    "text": "And we've seen this trend\nup until about today. And again, it's going\nto continue for a couple",
    "start": "441920",
    "end": "449030"
  },
  {
    "text": "more years before\nMoore's Law ends. So that's why we have chips\nwith multiple cores today.",
    "start": "449030",
    "end": "457160"
  },
  {
    "text": "So today, we're going to\nlook at multicore processing. So I first want to introduce\nthe abstract multicore",
    "start": "457160",
    "end": "464780"
  },
  {
    "text": "architecture. So this is a very\nsimplified version, but I can fit it on this\nslide, and it's a good example",
    "start": "464780",
    "end": "472700"
  },
  {
    "start": "465000",
    "end": "465000"
  },
  {
    "text": "for illustration. So here, we have a whole\nbunch of processors. They each have a\ncache, so that's",
    "start": "472700",
    "end": "479600"
  },
  {
    "text": "indicated with the dollar sign. And usually they have a\nprivate cache as well as",
    "start": "479600",
    "end": "485390"
  },
  {
    "text": "a shared cache, so a shared last\nlevel cache, like the L3 cache. And then they're all\nconnected to the network.",
    "start": "485390",
    "end": "493220"
  },
  {
    "text": "And then, through\nthe network, they can connect to the main memory. They can all access\nthe same shared memory.",
    "start": "493220",
    "end": "501050"
  },
  {
    "text": "And then usually there's a\nseparate network for the I/O as well, even though I've drawn\nthem as a single network here,",
    "start": "501050",
    "end": "506100"
  },
  {
    "text": "so they can access\nthe I/O interface. And potentially, the\nnetwork will also connect to other multiprocessors\non the same system.",
    "start": "506100",
    "end": "515779"
  },
  {
    "text": "And this abstract\nmulticore architecture is known as a chip\nmultiprocessor, or CMP.",
    "start": "515780",
    "end": "521570"
  },
  {
    "text": "So that's the architecture\nthat we'll be looking at today. ",
    "start": "521570",
    "end": "528940"
  },
  {
    "start": "527000",
    "end": "527000"
  },
  {
    "text": "So here's an outline\nof today's lecture. So first, I'm going to go\nover some hardware challenges",
    "start": "528940",
    "end": "537120"
  },
  {
    "text": "with shared memory\nmulticore machines. So we're going to look at\nthe cache coherence protocol.",
    "start": "537120",
    "end": "545460"
  },
  {
    "text": "And then after\nlooking at hardware, we're going to look at\nsome software solutions",
    "start": "545460",
    "end": "551460"
  },
  {
    "text": "to write parallel programs\non these multicore machines to take advantage\nof the extra cores.",
    "start": "551460",
    "end": "557343"
  },
  {
    "text": "And we're going to look\nat several concurrency platforms listed here. We're going to look at Pthreads.",
    "start": "557343",
    "end": "563490"
  },
  {
    "text": "This is basically\na low-level API for accessing, or for running\nyour code in parallel.",
    "start": "563490",
    "end": "571240"
  },
  {
    "text": "And if you program on\nMicrosoft products, the Win API threads\nis pretty similar.",
    "start": "571240",
    "end": "576900"
  },
  {
    "text": "Then there's Intel\nThreading Building Blocks, which is a library\nsolution to concurrency.",
    "start": "576900",
    "end": "582180"
  },
  {
    "text": "And then there are two\nlinguistic solutions that we'll be looking at-- OpenMP and Cilk Plus.",
    "start": "582180",
    "end": "588090"
  },
  {
    "text": "And Cilk Plus is actually\nthe concurrency platform that we'll be using\nfor most of this class.",
    "start": "588090",
    "end": "594060"
  },
  {
    "start": "594060",
    "end": "606995"
  },
  {
    "text": "So let's look at\nhow caches work.",
    "start": "606995",
    "end": "612110"
  },
  {
    "start": "609000",
    "end": "609000"
  },
  {
    "text": "So let's say that we\nhave a value in memory at some location,\nand that value is--",
    "start": "612110",
    "end": "619819"
  },
  {
    "text": "let's say that\nvalue is x equals 3.",
    "start": "619820",
    "end": "625350"
  },
  {
    "text": "If one processor\nsays, we want to load x, what happens is\nthat processor reads",
    "start": "625350",
    "end": "631580"
  },
  {
    "text": "this value from a main memory,\nbrings it into its own cache, and then it also reads\nthe value, loads it",
    "start": "631580",
    "end": "638370"
  },
  {
    "text": "into one of its registers. And it keeps this\nvalue in cache so that if it wants to access this\nvalue again in the near future,",
    "start": "638370",
    "end": "646812"
  },
  {
    "text": "it doesn't have to go all\nthe way out to main memory. It can just look at\nthe value in its cache.",
    "start": "646812",
    "end": "652740"
  },
  {
    "text": "Now, what happens if another\nprocessor wants to load x?",
    "start": "652740",
    "end": "658173"
  },
  {
    "text": "Well, it just does\nthe same thing. It reads the value\nfrom main memory, brings it into its cache,\nand then also loads it",
    "start": "658173",
    "end": "663750"
  },
  {
    "text": "into one of the registers. And then same thing\nwith another processor.",
    "start": "663750",
    "end": "670820"
  },
  {
    "text": "It turns out that\nyou don't actually always have to go out to\nmain memory to get the value. If the value resides in one of\nthe other processor's caches,",
    "start": "670820",
    "end": "679050"
  },
  {
    "text": "you can also get the value\nthrough the other processor's cache. And sometimes that's cheaper\nthan going all the way out",
    "start": "679050",
    "end": "685980"
  },
  {
    "text": "to main memory. ",
    "start": "685980",
    "end": "693940"
  },
  {
    "text": "So the second processor\nnow loads x again. And it's in cache,\nso it doesn't have to go to main memory or\nanybody else's cache.",
    "start": "693940",
    "end": "701140"
  },
  {
    "text": "So what happens now\nif we want to store x, if we want to set the\nvalue of x to something else?",
    "start": "701140",
    "end": "708830"
  },
  {
    "text": "So let's say this processor\nwants to set x equal to 5.",
    "start": "708830",
    "end": "714650"
  },
  {
    "text": "So it's going to\nwrite x equals 5 and store that result\nin its own cache.",
    "start": "714650",
    "end": "720300"
  },
  {
    "text": "So that's all well and good. ",
    "start": "720300",
    "end": "725460"
  },
  {
    "text": "Now what happens when the first\nprocessor wants to load x? Well, it seems that the value\nof x is in its own cache,",
    "start": "725460",
    "end": "734380"
  },
  {
    "text": "so it's just going to\nread the value of x there, and it gets a value of 3.",
    "start": "734380",
    "end": "739740"
  },
  {
    "text": "So what's the problem there? ",
    "start": "739740",
    "end": "748080"
  },
  {
    "text": "Yes? AUDIENCE: The path is stale. JULIAN SHUN: Yeah. So the problem is that the value\nof x in the first processor's",
    "start": "748080",
    "end": "754670"
  },
  {
    "text": "cache is stale, because\nanother processor updated it. So now this value of x in\nthe first processor's cache",
    "start": "754670",
    "end": "762240"
  },
  {
    "text": "is invalid.  So that's the problem.",
    "start": "762240",
    "end": "768180"
  },
  {
    "text": "And one of the main challenges\nof multicore hardware is to try to solve this\nproblem of cache coherence--",
    "start": "768180",
    "end": "774570"
  },
  {
    "text": "making sure that the values in\ndifferent processors' caches are consistent across updates.",
    "start": "774570",
    "end": "781785"
  },
  {
    "text": " So one basic protocol\nfor solving this problem",
    "start": "781785",
    "end": "791580"
  },
  {
    "text": "is known as the MSI protocol. And in this protocol, each cache\nline is labeled with a state.",
    "start": "791580",
    "end": "799010"
  },
  {
    "text": "So there are three\npossible states-- M, S, and I. And this is done on\nthe granularity of cache lines.",
    "start": "799010",
    "end": "805260"
  },
  {
    "text": "Because it turns out that\nstoring this information is relatively\nexpensive, so you don't want to store it for\nevery memory location.",
    "start": "805260",
    "end": "811792"
  },
  {
    "text": "So they do it on a\nper cache line basis. Does anyone know what\nthe size of a cache line",
    "start": "811792",
    "end": "818130"
  },
  {
    "text": "is, on the machines\nthat we're using? ",
    "start": "818130",
    "end": "827089"
  },
  {
    "text": "Yeah? AUDIENCE: 64 bytes. JULIAN SHUN: Yeah,\nso it's 64 bytes. And that's typically what you\nsee today on most Intel and AMD",
    "start": "827090",
    "end": "836510"
  },
  {
    "text": "machines. There's some architectures that\nhave different cache lines, like 128 bytes.",
    "start": "836510",
    "end": "841970"
  },
  {
    "text": "But for our class, the\nmachines that we're using will have 64 byte cache lines. It's important to remember\nthat so that when you're doing",
    "start": "841970",
    "end": "849380"
  },
  {
    "text": "back-of-the-envelope\ncalculations, you can get accurate estimates. So the three states in the\nMSI protocol are M, S, and I.",
    "start": "849380",
    "end": "858050"
  },
  {
    "start": "858000",
    "end": "858000"
  },
  {
    "text": "So M stands for modified. And when a cache block\nis in the modified state, that means no other caches\ncan contain this block",
    "start": "858050",
    "end": "865760"
  },
  {
    "text": "in the M or the S states. The S state means that\nthe block is shared,",
    "start": "865760",
    "end": "872089"
  },
  {
    "text": "so other caches can also have\nthis block in shared state. And then finally, I mean\nthe cache block is invalid.",
    "start": "872090",
    "end": "880190"
  },
  {
    "text": "So that's essentially the\nsame as the cache block not being in the cache.",
    "start": "880190",
    "end": "885980"
  },
  {
    "text": "And to solve the problem\nof cache coherency, when one cache modifies\na location, it",
    "start": "885980",
    "end": "891839"
  },
  {
    "text": "has to inform all\nthe other caches that their values are now stale,\nbecause this cache modified",
    "start": "891840",
    "end": "900200"
  },
  {
    "text": "the value. So it's going to invalidate\nall of the other copies of that cache line\nin other caches",
    "start": "900200",
    "end": "907010"
  },
  {
    "text": "by changing their\nstate from S to I.",
    "start": "907010",
    "end": "913130"
  },
  {
    "text": "So let's see how this works. So let's say that the second\nprocessor wants to store y",
    "start": "913130",
    "end": "918529"
  },
  {
    "text": "equals 5. So previously, a value of y was\n17, and it was in shared state. The cache line containing y\nequals 17 was in shared state.",
    "start": "918530",
    "end": "927320"
  },
  {
    "text": "So now, when I do\ny equals 5, I'm going to set the second\nprocessor's cache--",
    "start": "927320",
    "end": "936440"
  },
  {
    "text": "that cache line--\nto modified state. And then I'm going to\ninvalidate the cache",
    "start": "936440",
    "end": "941540"
  },
  {
    "text": "line in all of the other caches\nthat contain that cache line. So now the first cache\nand the fourth cache",
    "start": "941540",
    "end": "948230"
  },
  {
    "text": "each have a state of\nI for y equals 17, because that value is stale.",
    "start": "948230",
    "end": "953976"
  },
  {
    "text": "Is there any questions? Yes? AUDIENCE: If we already have to\ntell the other things to switch",
    "start": "953976",
    "end": "961237"
  },
  {
    "text": "to invalid, why not just\ntell them the value of y? JULIAN SHUN: Yeah,\nso there are actually",
    "start": "961237",
    "end": "966680"
  },
  {
    "text": "some protocols that do that. So this is just the\nmost basic protocol.",
    "start": "966680",
    "end": "971690"
  },
  {
    "text": "So this protocol doesn't do it. But there are some that\nare used in practice that actually do do that.",
    "start": "971690",
    "end": "977720"
  },
  {
    "text": "So it's a good point. But I just want to present the\nmost basic protocol for now.",
    "start": "977720",
    "end": "984350"
  },
  {
    "start": "984350",
    "end": "989399"
  },
  {
    "text": "Sorry.  And then, when you\nload a value, you",
    "start": "989400",
    "end": "995140"
  },
  {
    "text": "can first check whether your\ncache line is in M or S state.",
    "start": "995140",
    "end": "1000720"
  },
  {
    "text": "And if it is an M\nor S state, then you can just read that\nvalue directly.",
    "start": "1000720",
    "end": "1005980"
  },
  {
    "text": "But if it's in the I state,\nor if it's not there, then you have to\nfetch that block",
    "start": "1005980",
    "end": "1011430"
  },
  {
    "text": "from either another\nprocessor's cache or fetch it from main memory.",
    "start": "1011430",
    "end": "1018250"
  },
  {
    "text": "So it turns out that there are\nmany other protocols out there. There's something known as\nMESI, the messy protocol.",
    "start": "1018250",
    "end": "1028050"
  },
  {
    "text": "There's also MOESI and many\nother different protocols. And some of them\nare proprietary.",
    "start": "1028050",
    "end": "1033720"
  },
  {
    "text": "And they all do\ndifferent things. And it turns out that\nall of these protocols",
    "start": "1033720",
    "end": "1039480"
  },
  {
    "text": "are quite complicated,\nand it's very hard to get these protocols right.",
    "start": "1039480",
    "end": "1045119"
  },
  {
    "text": "And in fact, one of the\nmost earliest successes of formal verification was\nimproving some of these cache",
    "start": "1045119",
    "end": "1051300"
  },
  {
    "text": "[INAUDIBLE] protocols\nto be correct. Yes, question? AUDIENCE: What happens if\ntwo processors try to modify",
    "start": "1051300",
    "end": "1057558"
  },
  {
    "text": "one value at the same time JULIAN SHUN: Yeah,\nso if two processors try to modify the value, one\nof them has to happen first.",
    "start": "1057558",
    "end": "1065242"
  },
  {
    "text": "So the hardware is going\nto take care of that. So the first one that\nactually modifies it will invalidate\nall the other copies,",
    "start": "1065243",
    "end": "1071730"
  },
  {
    "text": "and then the second one\nthat modifies the value will again invalidate\nall of the other copies. And when you do that--",
    "start": "1071730",
    "end": "1078810"
  },
  {
    "text": "when a lot of processors try\nto modify the same value, you get something known\nas an invalidation storm.",
    "start": "1078810",
    "end": "1084150"
  },
  {
    "text": "So you have a bunch of\ninvalidation messages going throughout the hardware.",
    "start": "1084150",
    "end": "1089340"
  },
  {
    "text": "And that can lead to a big\nperformance bottleneck. Because each processor,\nwhen it modifies its value,",
    "start": "1089340",
    "end": "1094840"
  },
  {
    "text": "it has to inform all\nthe other processors. And if all the processors\nare modifying the same value, you get this sort of\nquadratic behavior.",
    "start": "1094840",
    "end": "1102343"
  },
  {
    "text": "The hardware is still\ngoing to guarantee that one of their processors\nis going to end up writing the value there.",
    "start": "1102343",
    "end": "1107590"
  },
  {
    "text": "But you should be aware\nof this performance issue when you're writing\nparallel code.",
    "start": "1107590",
    "end": "1113130"
  },
  {
    "text": "Yes? AUDIENCE: So all of\nthis protocol stuff happens in hardware? JULIAN SHUN: Yes, so this is\nall implemented in hardware.",
    "start": "1113130",
    "end": "1120250"
  },
  {
    "text": "So if you take a computer\narchitecture class, you'll learn much more about\nthese protocols and all",
    "start": "1120250",
    "end": "1126030"
  },
  {
    "text": "of their variants. So for our purposes,\nwe don't actually",
    "start": "1126030",
    "end": "1131880"
  },
  {
    "text": "need to understand all the\ndetails of the hardware. We just need to understand\nwhat it's doing at a high level",
    "start": "1131880",
    "end": "1137800"
  },
  {
    "text": "so we can understand when we\nhave a performance bottleneck and why we have a\nperformance bottleneck.",
    "start": "1137800",
    "end": "1144450"
  },
  {
    "text": "So that's why I'm just\nintroducing the most basic protocol here. ",
    "start": "1144450",
    "end": "1154770"
  },
  {
    "text": "Any other questions? ",
    "start": "1154770",
    "end": "1161030"
  },
  {
    "text": "So I talked a little bit about\nthe shared memory hardware.",
    "start": "1161030",
    "end": "1166320"
  },
  {
    "text": "Let's now look at some\nconcurrency platforms. So these are the four platforms\nthat we'll be looking at today.",
    "start": "1166320",
    "end": "1175880"
  },
  {
    "start": "1175000",
    "end": "1175000"
  },
  {
    "text": "So first, what is a\nconcurrency platform? Well, writing parallel\nprograms is very difficult.",
    "start": "1175880",
    "end": "1184250"
  },
  {
    "text": "It's very hard to get these\nprograms to be correct. And if you want to\noptimize their performance, it becomes even harder.",
    "start": "1184250",
    "end": "1190230"
  },
  {
    "text": "So it's very painful\nand error-prone. And a concurrency platform\nabstracts processor",
    "start": "1190230",
    "end": "1195610"
  },
  {
    "text": "cores and handles\nsynchronization and communication protocols. And it also performs\nload balancing for you.",
    "start": "1195610",
    "end": "1201860"
  },
  {
    "text": "So it makes your\nlives much easier. And so today we're\ngoing to talk about some",
    "start": "1201860",
    "end": "1208660"
  },
  {
    "text": "of these different\nconcurrency platforms.",
    "start": "1208660",
    "end": "1214240"
  },
  {
    "text": "So to illustrate these\nconcurrency platforms, I'm going to do the\nFibonacci numbers example.",
    "start": "1214240",
    "end": "1220990"
  },
  {
    "text": "So does anybody not\nknow what Fibonacci is? ",
    "start": "1220990",
    "end": "1227840"
  },
  {
    "text": "So good. Everybody knows\nwhat Fibonacci is. ",
    "start": "1227840",
    "end": "1233100"
  },
  {
    "text": "So it's a sequence where\neach number is the sum of the previous two numbers. And the recurrence is shown\nin this brown box here.",
    "start": "1233100",
    "end": "1243860"
  },
  {
    "text": "The sequence is named after\nLeonardo di Pisa, who was also",
    "start": "1243860",
    "end": "1250010"
  },
  {
    "text": "known as Fibonacci, which\nis a contraction of Bonacci, son of Bonaccio.",
    "start": "1250010",
    "end": "1255950"
  },
  {
    "text": "So that's where the name\nFibonacci came from. And in Fibonacce's\n1202 book, Liber Abaci,",
    "start": "1255950",
    "end": "1263970"
  },
  {
    "text": "he introduced the sequence-- the Fibonacci sequence--\nto Western mathematics,",
    "start": "1263970",
    "end": "1270710"
  },
  {
    "text": "although it had been\npreviously known to Indian mathematicians\nfor several centuries.",
    "start": "1270710",
    "end": "1279260"
  },
  {
    "text": "But this is what we call\nthe sequence nowadays-- Fibonacci numbers. ",
    "start": "1279260",
    "end": "1285840"
  },
  {
    "text": "So here's a Fibonacci program.",
    "start": "1285840",
    "end": "1291090"
  },
  {
    "start": "1286000",
    "end": "1286000"
  },
  {
    "text": "Has anyone seen this\nalgorithm before? ",
    "start": "1291090",
    "end": "1296590"
  },
  {
    "text": "A couple of people. Probably more, but people\ndidn't raise their hands.",
    "start": "1296590",
    "end": "1301880"
  },
  {
    "text": " So it's a recursive program.",
    "start": "1301880",
    "end": "1309410"
  },
  {
    "text": "So it basically\nimplements the recurrence from the previous slide. So if n is less than\n2, we just return n.",
    "start": "1309410",
    "end": "1316400"
  },
  {
    "text": "Otherwise, we compute\nfib of n minus 1, store that value in x, fib of n\nminus 2, store that value in y,",
    "start": "1316400",
    "end": "1323180"
  },
  {
    "text": "and then return\nthe sum of x and y. ",
    "start": "1323180",
    "end": "1330560"
  },
  {
    "text": "So I do want to\nmake a disclaimer to the algorithms police\nthat this is actually a very bad algorithm.",
    "start": "1330560",
    "end": "1336480"
  },
  {
    "text": "So this algorithm\ntakes exponential time, and there's actually\nmuch better ways",
    "start": "1336480",
    "end": "1342240"
  },
  {
    "text": "to compute the end\nFibonacci number. There's a linear\ntime algorithm, which",
    "start": "1342240",
    "end": "1347535"
  },
  {
    "text": "just computes the Fibonacci\nnumbers from bottom up. This algorithm here is actually\nredoing a lot of the work,",
    "start": "1347535",
    "end": "1354360"
  },
  {
    "text": "because it's computing Fibonacci\nnumbers multiple times.",
    "start": "1354360",
    "end": "1359610"
  },
  {
    "text": "Whereas if you do a linear scan\nfrom the smallest numbers up, you only have to\ncompute each one once.",
    "start": "1359610",
    "end": "1365350"
  },
  {
    "text": "And there's actually an\neven better algorithm that takes logarithmic\ntime, and it's",
    "start": "1365350",
    "end": "1370980"
  },
  {
    "text": "based on squaring matrices. So has anyone seen\nthat algorithm before?",
    "start": "1370980",
    "end": "1377280"
  },
  {
    "text": "So a couple of people. So if you're interested\nin learning more about this algorithm,\nI encourage you to look at your favorite\ntextbook, Introduction",
    "start": "1377280",
    "end": "1385230"
  },
  {
    "text": "to Algorithms by Cormen,\nLeiserson, Rivest, and Stein. ",
    "start": "1385230",
    "end": "1391675"
  },
  {
    "text": "So even though this-- [LAUGHTER] Yes. So even though this is\na pretty bad algorithm,",
    "start": "1391675",
    "end": "1399539"
  },
  {
    "text": "it's still a good\neducational example, because I can fit\nit on one slide and illustrate all the\nconcepts of parallelism",
    "start": "1399540",
    "end": "1408450"
  },
  {
    "text": "that we want to cover today. So here's the execution\ntree for fib of 4.",
    "start": "1408450",
    "end": "1416610"
  },
  {
    "start": "1411000",
    "end": "1411000"
  },
  {
    "text": "So we see that fib of 4 is going\nto call fib of 3 and fib of 2. Fib of 3 is going to call fib\nof 2, fib of 1, and so on.",
    "start": "1416610",
    "end": "1425560"
  },
  {
    "text": "And you can see that\nrepeated computations here. So fib of 2 is being\ncomputed twice, and so on.",
    "start": "1425560",
    "end": "1432460"
  },
  {
    "text": "And if you have a\nmuch larger tree-- say you ran this\non fib of 40-- then you'll have many more\noverlapping computations.",
    "start": "1432460",
    "end": "1440549"
  },
  {
    "text": " It turns out that the two\nrecursive calls can actually",
    "start": "1440550",
    "end": "1449860"
  },
  {
    "text": "be parallelized, because\nthey're completely independent calculations. So the key idea\nfor parallelization",
    "start": "1449860",
    "end": "1456159"
  },
  {
    "text": "is to simultaneously execute the\ntwo recursive sub-calls to fib.",
    "start": "1456160",
    "end": "1462100"
  },
  {
    "text": "And in fact, you can\ndo this recursively. So the two sub-calls\nto fib of 3 can also",
    "start": "1462100",
    "end": "1467860"
  },
  {
    "text": "be executed in parallel, and\nthe two sub-calls of fib of 2 can also be executed\nin parallel, and so on.",
    "start": "1467860",
    "end": "1473060"
  },
  {
    "text": "So you have all of\nthese calls that can be executed in parallel. So that's the key idea\nfor extracting parallelism",
    "start": "1473060",
    "end": "1481390"
  },
  {
    "text": "from this algorithm.  So let's now look\nat how we can use",
    "start": "1481390",
    "end": "1488890"
  },
  {
    "text": "Pthreads to implement this\nsimple Fibonacci algorithm.",
    "start": "1488890",
    "end": "1494072"
  },
  {
    "text": " So Pthreads is a standard\nAPI for threading,",
    "start": "1494072",
    "end": "1500480"
  },
  {
    "text": "and it's supported on\nall Unix-based machines. And if you're programming\nusing Microsoft products,",
    "start": "1500480",
    "end": "1508670"
  },
  {
    "text": "then the equivalent\nis Win API threads. And Pthreads is actually\nstandard in ANSI and IEEE,",
    "start": "1508670",
    "end": "1518450"
  },
  {
    "text": "so there's this number here\nthat specifies the standard. But nowadays, we just\ncall it Pthreads.",
    "start": "1518450",
    "end": "1524070"
  },
  {
    "text": "And it's basically a\ndo-it-yourself concurrency platform. So it's like the\nassembly language",
    "start": "1524070",
    "end": "1529190"
  },
  {
    "text": "of parallel programming. It's built as a\nlibrary of functions with special non-C semantics.",
    "start": "1529190",
    "end": "1536899"
  },
  {
    "text": "Because if you're just\nwriting code in C, you can't really say\nwhich parts of the code",
    "start": "1536900",
    "end": "1542507"
  },
  {
    "text": "should be executed in parallel. So Pthreads provides\nyou a library of functions that allow\nyou to specify concurrency",
    "start": "1542508",
    "end": "1549800"
  },
  {
    "text": "in your program. And each thread implements an\nabstraction of a processor,",
    "start": "1549800",
    "end": "1556640"
  },
  {
    "text": "and these threads\nare then multiplexed onto the actual\nmachine resources.",
    "start": "1556640",
    "end": "1562040"
  },
  {
    "text": "So the number of\nthreads that you create doesn't necessarily have to\nmatch the number of processors",
    "start": "1562040",
    "end": "1567320"
  },
  {
    "text": "you have on your machine. So if you have more threads\nthan the number of processors",
    "start": "1567320",
    "end": "1572690"
  },
  {
    "text": "you have, then they'll\njust be multiplexing. So you can actually\nrun a Pthreads program on a single core even though\nyou have multiple threads",
    "start": "1572690",
    "end": "1581090"
  },
  {
    "text": "in the program. They would just be time-sharing. All the threads communicate\nthrough shared memory,",
    "start": "1581090",
    "end": "1588590"
  },
  {
    "text": "so they all have access to\nthe same view of the memory. And the library functions\nthat Pthreads provides mask",
    "start": "1588590",
    "end": "1595995"
  },
  {
    "text": "the protocols involved in\ninterthread coordination, so you don't have\nto do it yourself.",
    "start": "1595995",
    "end": "1601670"
  },
  {
    "text": "Because it turns out that\nthis is quite difficult to do correctly by hand. ",
    "start": "1601670",
    "end": "1608929"
  },
  {
    "text": "So now I want to look at\nthe key Pthread functions. So the first Pthread\nis pthread_create.",
    "start": "1608930",
    "end": "1616610"
  },
  {
    "start": "1612000",
    "end": "1612000"
  },
  {
    "text": "And this takes four arguments. So the first argument\nis this pthread_t type.",
    "start": "1616610",
    "end": "1624350"
  },
  {
    "text": " This is basically going\nto store an identifier",
    "start": "1624350",
    "end": "1629419"
  },
  {
    "text": "for the new thread\nthat pthread_create will create so that\nwe can use that thread",
    "start": "1629420",
    "end": "1634880"
  },
  {
    "text": "in our computations. pthread_attr_t-- this set\nsome thread attributes,",
    "start": "1634880",
    "end": "1643670"
  },
  {
    "text": "and for our purposes, we can\njust set it to null and use the default attributes.",
    "start": "1643670",
    "end": "1649460"
  },
  {
    "text": "The third argument\nis this function that's going to be executed\nafter we create the thread.",
    "start": "1649460",
    "end": "1656180"
  },
  {
    "text": "So we're going to need to\ndefine this function that we want the thread to execute. And then finally, we have\nthis void *arg argument,",
    "start": "1656180",
    "end": "1666170"
  },
  {
    "text": "which stores the arguments\nthat are going to be passed to the function that we're\ngoing to be executing.",
    "start": "1666170",
    "end": "1673429"
  },
  {
    "text": "And then pthread_create also\nreturns an error status, returns an integer specifying\nwhether the thread creation",
    "start": "1673430",
    "end": "1680370"
  },
  {
    "text": "was successful or not. And then there's another\nfunction called pthread_join.",
    "start": "1680370",
    "end": "1686759"
  },
  {
    "text": "pthread_join\nbasically says that we want to block at\nthis part of our code",
    "start": "1686760",
    "end": "1695820"
  },
  {
    "text": "until this specified\nthread finishes. So it takes as\nargument pthread_t.",
    "start": "1695820",
    "end": "1701760"
  },
  {
    "text": "So this thread identifier,\nand these thread identifiers, were created when we\ncalled pthread_create.",
    "start": "1701760",
    "end": "1709016"
  },
  {
    "text": "It also has a second\nargument, status, which is going to\nstore the status",
    "start": "1709016",
    "end": "1714090"
  },
  {
    "text": "of the terminating thread. And then pthread_join also\nreturns an error status.",
    "start": "1714090",
    "end": "1719400"
  },
  {
    "text": "So essentially what\nthis does is it says to wait until this thread\nfinishes before we continue on",
    "start": "1719400",
    "end": "1726230"
  },
  {
    "text": "in our program.  So any questions so far?",
    "start": "1726230",
    "end": "1731770"
  },
  {
    "start": "1731770",
    "end": "1740900"
  },
  {
    "text": "So here's what the\nimplementation of Fibonacci looks like using Pthreads.",
    "start": "1740900",
    "end": "1747350"
  },
  {
    "start": "1742000",
    "end": "1742000"
  },
  {
    "text": "So on the left, we see the\noriginal program that we had, the fib function there.",
    "start": "1747350",
    "end": "1753590"
  },
  {
    "text": "That's just the sequential code. And then we have\nall this other stuff",
    "start": "1753590",
    "end": "1759200"
  },
  {
    "text": "to enable it to run in parallel. So first, we have this struct\non the left, thread_args.",
    "start": "1759200",
    "end": "1766880"
  },
  {
    "text": "This struct here is used\nto store the arguments that are passed to the function that\nthe thread is going to execute.",
    "start": "1766880",
    "end": "1775429"
  },
  {
    "text": "And then we have\nthis thread_func. What that does is\nit reads the input",
    "start": "1775430",
    "end": "1782540"
  },
  {
    "text": "argument from this\nthread_args struct, and then it sets that to i,\nand then it calls fib of i.",
    "start": "1782540",
    "end": "1789950"
  },
  {
    "text": "And that gives you the output,\nand then we store the result into the output of the struct. ",
    "start": "1789950",
    "end": "1797640"
  },
  {
    "text": "And then that also\njust returns null. ",
    "start": "1797640",
    "end": "1803000"
  },
  {
    "text": "And then over on\nthe right hand side, we have the main function that\nwill actually call the fib",
    "start": "1803000",
    "end": "1808929"
  },
  {
    "text": "function on the left. So we initialize a\nwhole bunch of variables",
    "start": "1808930",
    "end": "1815260"
  },
  {
    "text": "that we need to\nexecute these threads. And then we first check\nif n is less than 30.",
    "start": "1815260",
    "end": "1823370"
  },
  {
    "text": "If n is less than\n30, it turns out that it's actually not\nworth creating threads to execute this program\nin parallel, because",
    "start": "1823370",
    "end": "1829660"
  },
  {
    "text": "of the overhead of\nthread creation. So if n is less than 30,\nwe'll just execute the program sequentially.",
    "start": "1829660",
    "end": "1836860"
  },
  {
    "text": "And this idea is\nknown as coarsening. So you saw a similar\nexample a couple of lectures",
    "start": "1836860",
    "end": "1842470"
  },
  {
    "text": "ago when we did\ncoarsening for sorting. But this is in the context\nof a parallel programming.",
    "start": "1842470",
    "end": "1847840"
  },
  {
    "text": "So here, because there\nare some overheads to running a\nfunction in parallel,",
    "start": "1847840",
    "end": "1853330"
  },
  {
    "text": "if the input size\nis small enough, sometimes you want to just\nexecute it sequentially. ",
    "start": "1853330",
    "end": "1860230"
  },
  {
    "text": "And then we're going to-- so let me just walk\nthrough this code, since I have an animation.",
    "start": "1860230",
    "end": "1866799"
  },
  {
    "text": " So the next thing\nit's going to do",
    "start": "1866800",
    "end": "1872020"
  },
  {
    "text": "is it's going to marshal the\ninput argument to the thread so it's going to store the\ninput argument n minus 1",
    "start": "1872020",
    "end": "1877540"
  },
  {
    "text": "in this args struct.",
    "start": "1877540",
    "end": "1883000"
  },
  {
    "text": "And then we're going\nto call pthread_create with a thread variable.",
    "start": "1883000",
    "end": "1888550"
  },
  {
    "text": "For thread_args, we're\njust going to use null. And then we're going\nto pass the thread_func that we defined on the left.",
    "start": "1888550",
    "end": "1895850"
  },
  {
    "text": "And then we're going to\npass the args structure. And inside this args structure,\nthe input is set to n minus 1,",
    "start": "1895850",
    "end": "1904090"
  },
  {
    "text": "which we did on\nthe previous line. ",
    "start": "1904090",
    "end": "1911440"
  },
  {
    "text": "And then pthread_create is\ngoing to give a return value.",
    "start": "1911440",
    "end": "1917200"
  },
  {
    "text": " So if the Pthread\ncreation was successful,",
    "start": "1917200",
    "end": "1924500"
  },
  {
    "text": "then the status is going to\nbe null, and we can continue. ",
    "start": "1924500",
    "end": "1930325"
  },
  {
    "text": "And when we\ncontinue, we're going to execute, now, fib of n minus\n2 and store the result of that",
    "start": "1930325",
    "end": "1936139"
  },
  {
    "text": "into our result variable. And this is done at the same\ntime that fib of n minus 1 is executing.",
    "start": "1936140",
    "end": "1941660"
  },
  {
    "text": "Because we created\nthis Pthread, and we told it to call this\nthread_func function",
    "start": "1941660",
    "end": "1949100"
  },
  {
    "text": "that we defined on the left. So both fib of n minus\n1 and fib of n minus 2 are executing in parallel now.",
    "start": "1949100",
    "end": "1956210"
  },
  {
    "text": "And then we have\nthis pthread_join, which says we're going\nto wait until the thread",
    "start": "1956210",
    "end": "1961850"
  },
  {
    "text": "that we've created finishes\nbefore we move on, because we need to know the result\nof both of the sub-calls",
    "start": "1961850",
    "end": "1967970"
  },
  {
    "text": "before we can finish\nthis function. And once that's done--",
    "start": "1967970",
    "end": "1973010"
  },
  {
    "text": "well, we first check the status\nto see if it was successful. And if so, then we add the\noutputs of the argument's",
    "start": "1973010",
    "end": "1979780"
  },
  {
    "text": "struct to the result. So\nargs.output will store the output of fib of n minus 1.",
    "start": "1979780",
    "end": "1985730"
  },
  {
    "text": " So that's the Pthreads code.",
    "start": "1985730",
    "end": "1993530"
  },
  {
    "text": "Any questions on how this works? ",
    "start": "1993530",
    "end": "2000870"
  },
  {
    "text": "Yeah? AUDIENCE: I have a question\nabout the thread function. So it looks like you\npassed a void pointer,",
    "start": "2000870",
    "end": "2008120"
  },
  {
    "text": "but then you cast it to\nsomething else every time you use that--",
    "start": "2008120",
    "end": "2013330"
  },
  {
    "text": "JULIAN SHUN: Yeah,\nso this is because the pthread_create\nfunction takes as input a void star pointer.",
    "start": "2013330",
    "end": "2020630"
  },
  {
    "text": "Because it's actually\na generic function, so it doesn't know\nwhat the data type is. It has to work for\nall data types,",
    "start": "2020630",
    "end": "2026150"
  },
  {
    "text": "and that's why we need\nto cast it to avoid star. When we pass it to\npthread_create and then",
    "start": "2026150",
    "end": "2031280"
  },
  {
    "text": "inside the thread_func,\nwe actually do know what type of pointer\nthat is, so then we cast it.",
    "start": "2031280",
    "end": "2036420"
  },
  {
    "start": "2036420",
    "end": "2042880"
  },
  {
    "text": "So does this code\nseem very parallel? ",
    "start": "2042880",
    "end": "2049560"
  },
  {
    "text": "So how many parallel\ncalls am I doing here? Yeah? AUDIENCE: Just one.",
    "start": "2049560",
    "end": "2056315"
  },
  {
    "text": "JULIAN SHUN: Yeah, so I'm\nonly creating one thread. So I'm executing two\nthings in parallel.",
    "start": "2056315",
    "end": "2062040"
  },
  {
    "text": "So if I ran this code\non four processors, what's the maximum\nspeed-up I could get?",
    "start": "2062040",
    "end": "2068013"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. JULIAN SHUN: So the\nmaximum speed-up I can get is just two, because I'm only\nrunning two things in parallel.",
    "start": "2068013",
    "end": "2075429"
  },
  {
    "text": "So this doesn't\nrecursively create threads.",
    "start": "2075429",
    "end": "2080760"
  },
  {
    "text": "It only creates one\nthread at the top level. And if you wanted to make it\nso that this code actually",
    "start": "2080760",
    "end": "2087388"
  },
  {
    "text": "recursively created\nthreads, it would actually become much more complicated.",
    "start": "2087389",
    "end": "2092699"
  },
  {
    "text": "And that's one of the\ndisadvantages of implementing this code in Pthreads.",
    "start": "2092699",
    "end": "2098450"
  },
  {
    "text": "So we'll look at other\nsolutions that will make this task much easier. ",
    "start": "2098450",
    "end": "2105119"
  },
  {
    "start": "2105000",
    "end": "2105000"
  },
  {
    "text": "So some of the\nissues with Pthreads are shown on this slide here. So there's a high overhead\nto creating a thread.",
    "start": "2105120",
    "end": "2112020"
  },
  {
    "text": "So creating a thread\ntypically takes over 10 to the 4th cycles.",
    "start": "2112020",
    "end": "2117720"
  },
  {
    "text": "And this leads to very\ncoarse-grained concurrency, because your tasks have\nto do a lot of work",
    "start": "2117720",
    "end": "2124529"
  },
  {
    "text": "in order to amortize the\ncosts of creating that thread.",
    "start": "2124530",
    "end": "2130140"
  },
  {
    "text": "There are something called\nthread pulls, which can help. And the idea here is to create\na whole bunch of threads at the same time to amortize\nthe costs of thread creation.",
    "start": "2130140",
    "end": "2138660"
  },
  {
    "text": "And then when you need\na thread, you just take one from the thread pull. So the thread pull\ncontains threads that",
    "start": "2138660",
    "end": "2143850"
  },
  {
    "text": "are just waiting to do work.  There's also a scalability\nissue with this code",
    "start": "2143850",
    "end": "2150780"
  },
  {
    "text": "that I showed on\nthe previous slide. The Fibonacci code\ngets, at most,",
    "start": "2150780",
    "end": "2156000"
  },
  {
    "text": "1.5x speed-up for two cores. Why is it 1.5 here?",
    "start": "2156000",
    "end": "2161142"
  },
  {
    "text": "Does anyone know?  Yeah? AUDIENCE: You have the asymmetry\nin the size of the two calls.",
    "start": "2161142",
    "end": "2168170"
  },
  {
    "text": "JULIAN SHUN: Yeah,\nso it turns out that the two calls that\nI'm executing in parallel-- they're not doing the\nsame amount of work.",
    "start": "2168170",
    "end": "2174920"
  },
  {
    "text": "So one is computing\nfib of n minus 1, one is computing\nfib of n minus 2. And does anyone know what the\nratio between these two values",
    "start": "2174920",
    "end": "2183630"
  },
  {
    "text": "is?  Yeah, so it's the golden ratio.",
    "start": "2183630",
    "end": "2189140"
  },
  {
    "text": "It's about 1.6. It turns out that if you\ncan get a speed-up of 1.6, then that's great.",
    "start": "2189140",
    "end": "2194720"
  },
  {
    "text": "But there are some\noverheads, so this code will get about a 1.5 speed up.",
    "start": "2194720",
    "end": "2202410"
  },
  {
    "text": "And if you want to run this to\ntake advantage of more cores, then you need to\nrewrite this code, and it becomes more complicated.",
    "start": "2202410",
    "end": "2210440"
  },
  {
    "text": "Third, there's the\nissue of modularity. So if you look at\nthis code here,",
    "start": "2210440",
    "end": "2216559"
  },
  {
    "text": "you see that the Fibonacci\nlogic is not nicely encapsulated within one function.",
    "start": "2216560",
    "end": "2222049"
  },
  {
    "text": "We have that logic in the\nfib function on the left, but then we also have some\nof the fib logic on the right",
    "start": "2222050",
    "end": "2228830"
  },
  {
    "text": "in our main function. And this makes this\ncode not modular.",
    "start": "2228830",
    "end": "2233930"
  },
  {
    "text": "And if we want to build\nprograms on top of this, it makes it very\nhard to maintain, if we want to just change\nthe logic of the Fibonacci",
    "start": "2233930",
    "end": "2242690"
  },
  {
    "text": "function a little\nbit, because now we have to change it\nin multiple places instead of just having\neverything in one place.",
    "start": "2242690",
    "end": "2249460"
  },
  {
    "text": "So it's not a good idea to\nwrite code that's not modular, so please don't do\nthat in your projects.",
    "start": "2249460",
    "end": "2255260"
  },
  {
    "start": "2255260",
    "end": "2260420"
  },
  {
    "text": "And then finally,\nthe code becomes complicated because you\nhave to actually move",
    "start": "2260420",
    "end": "2267110"
  },
  {
    "text": "these arguments around. That's known as\nargument marshaling. And then you have to engage\nin error-prone protocols",
    "start": "2267110",
    "end": "2272810"
  },
  {
    "text": "in order to do load balancing. So if you recall here,\nwe have to actually",
    "start": "2272810",
    "end": "2277940"
  },
  {
    "text": "place the argument n\nminus 1 into args.input and we have to extract the\nvalue out of args.output.",
    "start": "2277940",
    "end": "2285349"
  },
  {
    "text": "So that makes the\ncode very messy. ",
    "start": "2285350",
    "end": "2293090"
  },
  {
    "text": "So why do I say\nshades of 1958 here? Does anyone know what\nhappened in 1958?",
    "start": "2293090",
    "end": "2301760"
  },
  {
    "text": "Who was around in 1958? Just Charles? ",
    "start": "2301760",
    "end": "2309340"
  },
  {
    "text": "So there was a first\nsomething in 1958. What was it? ",
    "start": "2309340",
    "end": "2322200"
  },
  {
    "text": "So turns out in 1958, we\nhad the first compiler. And this was the\nFortran compiler.",
    "start": "2322200",
    "end": "2330390"
  },
  {
    "text": "And before we had\nFortran compiler, programmers were writing\nthings in assembly. And when you write\nthings in assembly,",
    "start": "2330390",
    "end": "2336750"
  },
  {
    "text": "you have to do\nargument marshaling, because you have to place things\ninto the appropriate registers",
    "start": "2336750",
    "end": "2342480"
  },
  {
    "text": "before calling a function, and\nalso move things around when you return from a function. And the nice thing\nabout the first compiler",
    "start": "2342480",
    "end": "2349530"
  },
  {
    "text": "is that it actually did all\nof this argument marshaling for you. So now you can just pass\narguments to a function,",
    "start": "2349530",
    "end": "2355680"
  },
  {
    "text": "and the compiler\nwill generate code that will do the argument\nmarshaling for us.",
    "start": "2355680",
    "end": "2362339"
  },
  {
    "text": "So having you do\nthis in Pthreads is similar to having to\nwrite code in assembly,",
    "start": "2362340",
    "end": "2367560"
  },
  {
    "text": "because you have to\nactually manually marshal these arguments. So hopefully, there are\nbetter ways to do this.",
    "start": "2367560",
    "end": "2373890"
  },
  {
    "text": "And indeed, we'll look at some\nother solutions that will make it easier on the programmer.",
    "start": "2373890",
    "end": "2380900"
  },
  {
    "text": "Any questions before I continue? ",
    "start": "2380900",
    "end": "2388980"
  },
  {
    "text": "So we looked at Pthreads. Next, let's look at\nThreading Building Blocks. ",
    "start": "2388980",
    "end": "2397160"
  },
  {
    "start": "2396000",
    "end": "2396000"
  },
  {
    "text": "So Threading Building Blocks\nis a library solution. It was developed by Intel.",
    "start": "2397160",
    "end": "2402920"
  },
  {
    "text": "And it's implemented as a\nC++ library that runs on top of native threads.",
    "start": "2402920",
    "end": "2409090"
  },
  {
    "text": "So the underlying\nimplementation uses threads, but the programmer\ndoesn't deal with threads.",
    "start": "2409090",
    "end": "2415369"
  },
  {
    "text": "Instead, the programmer\nspecifies tasks, and these tasks are\nautomatically load-balanced",
    "start": "2415370",
    "end": "2421430"
  },
  {
    "text": "across the threads using\na work-stealing algorithm inspired by research at MIT--",
    "start": "2421430",
    "end": "2427880"
  },
  {
    "text": "Charles Leiserson's research. And the focus of Intel\nTBB is on performance.",
    "start": "2427880",
    "end": "2434690"
  },
  {
    "text": "And as we'll see, the\ncode written using TBB is simpler than\nwhat you would have",
    "start": "2434690",
    "end": "2439700"
  },
  {
    "text": "to write if you used Pthreads. So let's look at how we can\nimplement Fibonacci using TBB.",
    "start": "2439700",
    "end": "2446270"
  },
  {
    "start": "2445000",
    "end": "2445000"
  },
  {
    "text": " So in TBB, we have to\ncreate these tasks.",
    "start": "2446270",
    "end": "2455000"
  },
  {
    "text": "So in the Fibonacci code, we\ncreate this fib task class.",
    "start": "2455000",
    "end": "2461460"
  },
  {
    "text": "And inside the task, we have to\ndefine this execute function. ",
    "start": "2461460",
    "end": "2470579"
  },
  {
    "text": "So the execute function\nis the function that performs a computation\nwhen we start the task.",
    "start": "2470580",
    "end": "2476080"
  },
  {
    "text": "And this is where we\ndefine the Fibonacci logic. This task also takes as input\nthese arguments parameter, n",
    "start": "2476080",
    "end": "2484990"
  },
  {
    "text": "and sum. So n is the input here\nand sum is the output. ",
    "start": "2484990",
    "end": "2491640"
  },
  {
    "text": "And in TBB, we can easily\ncreate a recursive program",
    "start": "2491640",
    "end": "2497369"
  },
  {
    "text": "that extracts more parallelism. And here, what we're doing\nis we're recursively creating",
    "start": "2497370",
    "end": "2503680"
  },
  {
    "text": "two child tasks, a and b. That's the syntax for\ncreating the tasks.",
    "start": "2503680",
    "end": "2509530"
  },
  {
    "text": "And here, we can just pass\nthe arguments to FibTask instead of marshaling\nthe arguments ourselves.",
    "start": "2509530",
    "end": "2516960"
  },
  {
    "text": "And then what we have\nhere is a set_ref_count. And this basically is\nthe number of tasks",
    "start": "2516960",
    "end": "2523690"
  },
  {
    "text": "that we have to wait for plus\none, so plus one for ourselves. And in this case, we\ncreated two children tasks,",
    "start": "2523690",
    "end": "2530920"
  },
  {
    "text": "and we have ourselves,\nso that's 2 plus 1. And then after that, we start\ntask b using the spawn(b) call.",
    "start": "2530920",
    "end": "2540720"
  },
  {
    "text": "And then we do\nspawn_and_wait_for_all with a as the argument.",
    "start": "2540720",
    "end": "2547050"
  },
  {
    "text": "In this place, he says,\nwe're going to start task a, and then also wait\nfor both a and b",
    "start": "2547050",
    "end": "2553350"
  },
  {
    "text": "to finish before we proceed. So this\nspawn_and_wait_for_all call is going to look at the\nref count that we set above",
    "start": "2553350",
    "end": "2560549"
  },
  {
    "text": "and wait for that many tasks\nto finish before it continues. And after both and a\nand b have completed,",
    "start": "2560550",
    "end": "2567869"
  },
  {
    "text": "then we can just\nsum up the results and store that into\nthe sum variable.",
    "start": "2567870",
    "end": "2573930"
  },
  {
    "text": "And here, these tasks\nare created recursively. So unlike the Pthreads\nimplementation that was only creating one\nthread at the top level,",
    "start": "2573930",
    "end": "2581760"
  },
  {
    "text": "here, we're actually recursively\ncreating more and more tasks. So we can actually\nget more parallelism",
    "start": "2581760",
    "end": "2587370"
  },
  {
    "text": "from this code and scale\nto more processors. ",
    "start": "2587370",
    "end": "2594510"
  },
  {
    "text": "We also need this main function\njust to start up the program. So what we do here is\nwe create a root task,",
    "start": "2594510",
    "end": "2602160"
  },
  {
    "text": "which just computes fib\nof n, and then we call spawn_root_and_wait(a).",
    "start": "2602160",
    "end": "2608880"
  },
  {
    "text": "So a is the task for the root. And then it will just\nrun the root task. ",
    "start": "2608880",
    "end": "2616990"
  },
  {
    "text": "So that's what Fibonacci\nlooks like in TBB. So this is much simpler than\nthe Pthreads implementation.",
    "start": "2616990",
    "end": "2624869"
  },
  {
    "text": "And it also gets\nbetter performance, because we can extract\nmore parallelism from the computation.",
    "start": "2624870",
    "end": "2630330"
  },
  {
    "text": " Any questions?",
    "start": "2630330",
    "end": "2635440"
  },
  {
    "start": "2635440",
    "end": "2642430"
  },
  {
    "text": "So TBB also has many other\nfeatures in addition to tasks.",
    "start": "2642430",
    "end": "2648130"
  },
  {
    "start": "2644000",
    "end": "2644000"
  },
  {
    "text": "So TBB provides many C++\ntemplates to express common patterns, and you can use these\ntemplates on different data",
    "start": "2648130",
    "end": "2655390"
  },
  {
    "text": "types. So they have a\nparallel_for, which is used to express\nloop parallelism.",
    "start": "2655390",
    "end": "2661110"
  },
  {
    "text": "So you can loop over a bunch\nof iterations in parallel. They also have a parallel_reduce\nfor data aggregation.",
    "start": "2661110",
    "end": "2666580"
  },
  {
    "text": "For example, if you\nwant to sum together a whole bunch of values, you\ncan use a parallel_reduce to do that in parallel.",
    "start": "2666580",
    "end": "2673609"
  },
  {
    "text": "They also have\npipeline and filter. That's used for\nsoftware pipelining.",
    "start": "2673610",
    "end": "2680260"
  },
  {
    "text": "TBB provides many concurrent\ncontainer classes, which allow multiple threads\nto safely access and update",
    "start": "2680260",
    "end": "2686590"
  },
  {
    "text": "the items in a\ncontainer concurrently. So for example, they have hash\ntables, trees, priority cues,",
    "start": "2686590",
    "end": "2693099"
  },
  {
    "text": "and so on. And you can just use\nthese out of the box, and they'll work in parallel. You can do concurrent\nupdates and reads",
    "start": "2693100",
    "end": "2701410"
  },
  {
    "text": "to these data structures. TBB also has a variety of mutual\nexclusion library functions,",
    "start": "2701410",
    "end": "2707620"
  },
  {
    "text": "such as locks and\natomic operations. So there are a lot\nof features of TBB,",
    "start": "2707620",
    "end": "2713559"
  },
  {
    "text": "which is why it's one of\nthe more popular concurrency platforms. And because of all\nof these features,",
    "start": "2713560",
    "end": "2720040"
  },
  {
    "text": "you don't have to implement many\nof these things by yourself, and still get pretty\ngood performance. ",
    "start": "2720040",
    "end": "2728770"
  },
  {
    "text": "So TBB was a library solution\nto the concurrency problem. Now we're going to look at\ntwo linguistic solutions--",
    "start": "2728770",
    "end": "2736270"
  },
  {
    "text": "OpenMP and Cilk. So let's start with OpenMP. ",
    "start": "2736270",
    "end": "2744050"
  },
  {
    "text": "So OpenMP is a specification\nby an industry consortium.",
    "start": "2744050",
    "end": "2749840"
  },
  {
    "text": "And there are several compilers\navailable that support OpenMP, both open source\nand proprietary.",
    "start": "2749840",
    "end": "2756950"
  },
  {
    "text": "So nowadays, GCC,\nICC, and Clang all support OpenMP, as\nwell as Visual Studio.",
    "start": "2756950",
    "end": "2763880"
  },
  {
    "text": "And OpenMP is-- it provides\nlinguistic extensions to C and C++, as well as Fortran, in\nthe form of compiler pragmas.",
    "start": "2763880",
    "end": "2773300"
  },
  {
    "text": "So you use these\ncompiler pragmas in your code to specify\nwhich pieces of code",
    "start": "2773300",
    "end": "2779900"
  },
  {
    "text": "should run in parallel. And OpenMP also runs on\ntop of native threads,",
    "start": "2779900",
    "end": "2786170"
  },
  {
    "text": "but the programmer isn't\nexposed to these threads. OpenMP supports\nloop parallelism,",
    "start": "2786170",
    "end": "2793119"
  },
  {
    "text": "so you can do\nparallel for loops. They have task parallelism as\nwell as pipeline parallelism.",
    "start": "2793120",
    "end": "2799143"
  },
  {
    "text": " So let's look at how we can\nimplement Fibonacci in OpenMP.",
    "start": "2799144",
    "end": "2804800"
  },
  {
    "text": " So this is the entire code.",
    "start": "2804800",
    "end": "2811140"
  },
  {
    "start": "2805000",
    "end": "2805000"
  },
  {
    "text": "So I want you to compare this\nto the Pthreads implementation that we saw 10 minutes ago.",
    "start": "2811140",
    "end": "2817770"
  },
  {
    "text": "So this code is much\ncleaner than the Pthreads implementation, and it\nalso performs better.",
    "start": "2817770",
    "end": "2824319"
  },
  {
    "text": "So let's see how\nthis code works. ",
    "start": "2824320",
    "end": "2830270"
  },
  {
    "text": "So we have these\ncompiler pragmas, or compiler directives. And the compiler pragma for\ncreating a parallel task",
    "start": "2830270",
    "end": "2840040"
  },
  {
    "text": "is omp task. So we're going to create\nan OpenMP task for fib",
    "start": "2840040",
    "end": "2847840"
  },
  {
    "text": "of n minus 1 as well\nas fib of n minus 2. ",
    "start": "2847840",
    "end": "2857840"
  },
  {
    "text": "There's also this\nshared pragma, which specifies that the two\nvariables in the arguments",
    "start": "2857840",
    "end": "2863900"
  },
  {
    "text": "are shared across\ndifferent threads. So you also have to\nspecify whether variables",
    "start": "2863900",
    "end": "2869630"
  },
  {
    "text": "are private or shared. ",
    "start": "2869630",
    "end": "2875030"
  },
  {
    "text": "And then the pragma\nomp wait just says we're going to wait\nfor the preceding task",
    "start": "2875030",
    "end": "2880970"
  },
  {
    "text": "to complete before we continue. So here, it's going to\nwait for fib of n minus 1 and fib of n minus 2\nto finish before we",
    "start": "2880970",
    "end": "2888290"
  },
  {
    "text": "return the result,\nwhich is what we want. And then after that, we\njust return x plus y.",
    "start": "2888290",
    "end": "2894260"
  },
  {
    "text": "So that's the entire code. ",
    "start": "2894260",
    "end": "2902300"
  },
  {
    "text": "And OpenMP also provides\nmany other pragma directives, in addition to task.",
    "start": "2902300",
    "end": "2908299"
  },
  {
    "text": "So we can use a parallel\nfor to do loop parallelism. There's reduction.",
    "start": "2908300",
    "end": "2913609"
  },
  {
    "text": "There's also directives for\nscheduling and data sharing. So you can specify how\nyou want a particular loop",
    "start": "2913610",
    "end": "2919550"
  },
  {
    "text": "to be scheduled. OpenMP has many different\nscheduling policies. They have static parallelism,\ndynamic parallelism, and so on.",
    "start": "2919550",
    "end": "2926730"
  },
  {
    "text": "And then these scheduling\ndirectives also have different grain sizes. The data sharing directives are\nspecifying whether variables",
    "start": "2926730",
    "end": "2936200"
  },
  {
    "text": "are private or shared. OpenMP also supplies a variety\nof synchronization constructs,",
    "start": "2936200",
    "end": "2941870"
  },
  {
    "text": "such as barriers, atomic\nupdates, mutual exclusion, or mutex locks.",
    "start": "2941870",
    "end": "2947030"
  },
  {
    "text": "So OpenMP also\nhas many features, and it's also one of the\nmore popular solutions",
    "start": "2947030",
    "end": "2953840"
  },
  {
    "text": "to writing parallel programs. As you saw in the\nprevious example,",
    "start": "2953840",
    "end": "2959030"
  },
  {
    "text": "the code is much\nsimpler than if you were to write something\nusing Pthreads or even TBB.",
    "start": "2959030",
    "end": "2965690"
  },
  {
    "text": "This is a much simpler solution. ",
    "start": "2965690",
    "end": "2972430"
  },
  {
    "text": "Any questions?  Yeah?",
    "start": "2972430",
    "end": "2978210"
  },
  {
    "text": "AUDIENCE: So with every\ncompiler directive, does it spawn a new [INAUDIBLE]\non a different processor?",
    "start": "2978210",
    "end": "2987605"
  },
  {
    "text": "JULIAN SHUN: So this\ncode here is actually independent of the\nnumber of processors. So there is actually\na scheduling algorithm",
    "start": "2987605",
    "end": "2993750"
  },
  {
    "text": "that will determine\nhow the tasks get mapped to different processors. So if you spawn a new task,\nit doesn't necessarily put it",
    "start": "2993750",
    "end": "3001460"
  },
  {
    "text": "on a different processor. And you can have more\ntasks than the number of processors available. So there's a\nscheduling algorithm",
    "start": "3001460",
    "end": "3006859"
  },
  {
    "text": "that will take care\nof how these tasks get mapped to different\nprocessors, and that's hidden from the programmer.",
    "start": "3006860",
    "end": "3013340"
  },
  {
    "text": "Although you can\nuse these scheduling pragmas to give\nhints to the compiler",
    "start": "3013340",
    "end": "3019640"
  },
  {
    "text": "how it should schedule it. Yeah? AUDIENCE: What is the\noperating system [INAUDIBLE]",
    "start": "3019640",
    "end": "3025583"
  },
  {
    "text": "scheduling [INAUDIBLE]? JULIAN SHUN: Underneath,\nthis is implemented using Pthreads, which has to\nmake operating system calls to,",
    "start": "3025583",
    "end": "3034030"
  },
  {
    "text": "basically, directly talk\nto the processor cores and do multiplexing\nand so forth.",
    "start": "3034030",
    "end": "3039849"
  },
  {
    "text": "So the operating system is\ninvolved at a very low level. ",
    "start": "3039850",
    "end": "3056630"
  },
  {
    "text": "So the last concurrency platform\nthat we'll be looking at today is Cilk. ",
    "start": "3056630",
    "end": "3068158"
  },
  {
    "start": "3063000",
    "end": "3063000"
  },
  {
    "text": "We're going to look at\nCilk Plus, actually. And the Cilk part of Cilk Plus\nis a small set of linguistic extensions to C and C++ that\nsupport fork-join parallelism.",
    "start": "3068158",
    "end": "3078040"
  },
  {
    "text": "So for example, the\nFibonacci example uses fork-join\nparallelism, so you can use Cilk to implement that.",
    "start": "3078040",
    "end": "3084740"
  },
  {
    "text": "And the Plus part of Cilk Plus\nsupports vector parallelism, which you had experience\nworking with in your homeworks.",
    "start": "3084740",
    "end": "3094990"
  },
  {
    "text": "So Cilk Plus was initially\ndeveloped by Cilk Arts, which was an MIT spin-off.",
    "start": "3094990",
    "end": "3102570"
  },
  {
    "text": "And Cilk Arts was acquired\nby Intel in July 2009.",
    "start": "3102570",
    "end": "3107730"
  },
  {
    "text": "And the Cilk Plus\nimplementation was based on the award-winning Cilk\nmulti-threaded language that",
    "start": "3107730",
    "end": "3115350"
  },
  {
    "text": "was developed two decades\nago here at MIT by Charles Leiserson's research group.",
    "start": "3115350",
    "end": "3123240"
  },
  {
    "text": "And it features a\nprovably efficient work-stealing scheduler. So this scheduler is\nprovably efficient.",
    "start": "3123240",
    "end": "3129390"
  },
  {
    "text": "You can actually prove\ntheoretical bounds on it. And this allows you to implement\ntheoretically efficient",
    "start": "3129390",
    "end": "3134700"
  },
  {
    "text": "algorithms, which we'll talk\nmore about in another lecture-- algorithm design. But it provides a\nprovably efficient",
    "start": "3134700",
    "end": "3141690"
  },
  {
    "text": "work-stealing scheduler. And Charles Leiserson\nhas a very famous paper that has a proof of that\nthis scheduler is optimal.",
    "start": "3141690",
    "end": "3149760"
  },
  {
    "text": "So if you're interested\nin reading about this, you can talk to us offline.",
    "start": "3149760",
    "end": "3155069"
  },
  {
    "text": "Cilk Plus also provides\na hyperobject library for parallelizing code\nwith global variables.",
    "start": "3155070",
    "end": "3162120"
  },
  {
    "text": "And you'll have a chance to\nplay around with hyperobjects in homework 4.",
    "start": "3162120",
    "end": "3167930"
  },
  {
    "text": "The Cilk Plus\necosystem also includes useful programming tools,\nsuch as the Cilk Screen Race",
    "start": "3167930",
    "end": "3174210"
  },
  {
    "text": "Detector. So this allows you to\ndetect determinacy races in your program to help you\nisolate bugs and performance",
    "start": "3174210",
    "end": "3181710"
  },
  {
    "text": "bottlenecks. It also has a scalability\nanalyzer called Cilk View.",
    "start": "3181710",
    "end": "3186810"
  },
  {
    "text": "And Cilk View will basically\nanalyze the amount of work",
    "start": "3186810",
    "end": "3191940"
  },
  {
    "text": "that your program\nis doing, as well as the maximum amount\nof parallelism that your code could possibly\nextract from the hardware.",
    "start": "3191940",
    "end": "3202030"
  },
  {
    "text": "So that's Intel Cilk Plus. But it turns out that\nwe're not actually",
    "start": "3202030",
    "end": "3207350"
  },
  {
    "text": "going to be using Intel\nCilk Plus in this class. We're going to be using\na better compiler. And this compiler is\nbased on Tapir/LLVM.",
    "start": "3207350",
    "end": "3216830"
  },
  {
    "text": "And it supports the Cilk\nsubset of Cilk Plus. And Tapir/LLVM was actually\nrecently developed at MIT",
    "start": "3216830",
    "end": "3225620"
  },
  {
    "text": "by T. B. Schardl, who gave\na lecture last week, William",
    "start": "3225620",
    "end": "3230870"
  },
  {
    "text": "Moses, who's a grad student\nworking with Charles, as well as Charles Leiserson. ",
    "start": "3230870",
    "end": "3238550"
  },
  {
    "text": "So talking a lot about\nCharles's work today. And Tapir/LLVM\ngenerally produces",
    "start": "3238550",
    "end": "3245390"
  },
  {
    "text": "better code, relative\nto its base compiler, than all other implementations\nof Cilk out there.",
    "start": "3245390",
    "end": "3250970"
  },
  {
    "text": "So it's the best Cilk compiler\nthat's available today. And they actually\nwrote a very nice paper",
    "start": "3250970",
    "end": "3258500"
  },
  {
    "text": "on this last year, Charles\nLeiserson and his group. And that paper received\nthe Best Paper Award",
    "start": "3258500",
    "end": "3263750"
  },
  {
    "text": "at the annual Symposium on\nPrinciples and Practices of Parallel\nProgramming, or PPoPP.",
    "start": "3263750",
    "end": "3269360"
  },
  {
    "text": "So you should look at\nthat paper as well.",
    "start": "3269360",
    "end": "3274500"
  },
  {
    "text": "So right now, Tapir/LLVM uses\nthe Intel Cilk Plus runtime system, but I believe Charles's\ngroup has plans to implement",
    "start": "3274500",
    "end": "3283790"
  },
  {
    "text": "a better runtime system. And Tapir/LLVM also supports\nmore general features",
    "start": "3283790",
    "end": "3289460"
  },
  {
    "text": "than existing Cilk compilers. So in addition to\nspawning functions,",
    "start": "3289460",
    "end": "3295289"
  },
  {
    "text": "you can also spawn code\nblocks that are not separate functions,\nand this makes",
    "start": "3295290",
    "end": "3302119"
  },
  {
    "text": "writing programs more flexible. You don't have to actually\ncreate a separate function if you want to execute a\ncode block in parallel.",
    "start": "3302120",
    "end": "3311606"
  },
  {
    "text": "Any questions? ",
    "start": "3311606",
    "end": "3321590"
  },
  {
    "text": "So this is the Cilk\ncode for Fibonacci. So it's also pretty simple.",
    "start": "3321590",
    "end": "3329320"
  },
  {
    "start": "3322000",
    "end": "3322000"
  },
  {
    "text": "It looks very similar to\nthe sequential program, except we have these\ncilk_spawn and cilk_synv",
    "start": "3329320",
    "end": "3335320"
  },
  {
    "text": "statements in the code. So what do these statements do? So cilk_spawn says that the\nnamed child function, which",
    "start": "3335320",
    "end": "3345190"
  },
  {
    "text": "is the function that is\nright after this cilk_spawn statement, may execute in\nparallel with the parent",
    "start": "3345190",
    "end": "3350800"
  },
  {
    "text": "caller. The parent caller\nis the function that is calling cilk_spawn. So this says that\nfib of n minus 1",
    "start": "3350800",
    "end": "3357670"
  },
  {
    "text": "can execute in parallel with\nthe function that called it. And then this function is then\ngoing to call fib of n minus 2.",
    "start": "3357670",
    "end": "3365890"
  },
  {
    "text": "And fib of n minus 2\nand fib of n minus 1 now can be executing\nin parallel.",
    "start": "3365890",
    "end": "3372130"
  },
  {
    "text": "And then cilk_sync says that\ncontrol cannot pass this point until all of the spawn\nchildren have returned.",
    "start": "3372130",
    "end": "3381030"
  },
  {
    "text": "So this is going to wait\nfor fib of n minus 1 to return before we go\nto the return statement",
    "start": "3381030",
    "end": "3388150"
  },
  {
    "text": "where we add up x and y. ",
    "start": "3388150",
    "end": "3394760"
  },
  {
    "text": "So one important\nthing to note is that the Cilk keywords\ngrant permission for parallel execution, but they\ndon't actually force or command",
    "start": "3394760",
    "end": "3402830"
  },
  {
    "text": "parallel execution. So even though I\nsaid cilk_spawn here,",
    "start": "3402830",
    "end": "3407980"
  },
  {
    "text": "the runtime system\ndoesn't necessarily have to run fib of n minus 1 in\nparallel with fib of n minus 2.",
    "start": "3407980",
    "end": "3415010"
  },
  {
    "text": "I'm just saying that I could run\nthese two things in parallel, and it's up to\nthe runtime system to decide whether or not to\nrun these things in parallel,",
    "start": "3415010",
    "end": "3423830"
  },
  {
    "text": "based on its scheduling policy. So let's look at\nanother example of Cilk.",
    "start": "3423830",
    "end": "3433040"
  },
  {
    "start": "3430000",
    "end": "3430000"
  },
  {
    "text": "So let's look at\nloop parallelism. So here we want to do\na matrix transpose,",
    "start": "3433040",
    "end": "3438859"
  },
  {
    "text": "and we want to do this in-place. So the idea here is we\nwant to basically swap",
    "start": "3438860",
    "end": "3444380"
  },
  {
    "text": "the elements below the\ndiagonal to its mirror",
    "start": "3444380",
    "end": "3451039"
  },
  {
    "text": "image above the diagonal. And here's some code to do this.",
    "start": "3451040",
    "end": "3456950"
  },
  {
    "text": "So we have a cilk_for. So this is basically\na parallel for loop.",
    "start": "3456950",
    "end": "3462590"
  },
  {
    "text": "It goes from i equals\n1 to n minus 1. And then the inner for loop\ngoes from j equals 0 up",
    "start": "3462590",
    "end": "3469310"
  },
  {
    "text": "to i minus 1. And then we just swap\na of i j with a of j i,",
    "start": "3469310",
    "end": "3475730"
  },
  {
    "text": "using these three statements\ninside the body of the for loop. ",
    "start": "3475730",
    "end": "3482109"
  },
  {
    "text": "So to execute a for\nloop in parallel, you just have to add cilk\nunderscore to the for keyword.",
    "start": "3482110",
    "end": "3490630"
  },
  {
    "text": "And that's as simple as it gets. So this code is actually\ngoing to run in parallel",
    "start": "3490630",
    "end": "3497099"
  },
  {
    "text": "and get pretty good speed-up\nfor this particular problem.",
    "start": "3497100",
    "end": "3502890"
  },
  {
    "text": "And internally,\nCilk for loops are transformed into nested\ncilk_spawn and cilk_sync calls.",
    "start": "3502890",
    "end": "3508980"
  },
  {
    "text": "So the compiler is going\nto get rid of the cilk_for and change it into\ncilk_spawn and cilk_sync.",
    "start": "3508980",
    "end": "3516150"
  },
  {
    "text": "So it's going to recursively\ndivide the iteration space into half, and then it's\ngoing to spawn off one half",
    "start": "3516150",
    "end": "3524220"
  },
  {
    "text": "and then execute the other\nhalf in parallel with that, and then recursively do\nthat until the iteration",
    "start": "3524220",
    "end": "3529589"
  },
  {
    "text": "range becomes small\nenough, at which point it doesn't make sense to\nexecute it in parallel anymore,",
    "start": "3529590",
    "end": "3534870"
  },
  {
    "text": "so we just execute that\nrange sequentially. ",
    "start": "3534870",
    "end": "3541310"
  },
  {
    "text": "So that's loop\nparallelism in Cilk. Any questions?",
    "start": "3541310",
    "end": "3546520"
  },
  {
    "text": "Yes? AUDIENCE: How does it know\n[INAUDIBLE] something weird,",
    "start": "3546520",
    "end": "3552070"
  },
  {
    "text": "can it still do that? JULIAN SHUN: Yeah,\nso the compiler can actually figure out\nwhat the iteration space is.",
    "start": "3552070",
    "end": "3559940"
  },
  {
    "text": "So you don't necessarily\nhave to be incrementing by 1. You can do something else. You just have to guarantee\nthat all of the iterations",
    "start": "3559940",
    "end": "3566510"
  },
  {
    "text": "are independent. So if you have a\ndeterminacy race",
    "start": "3566510",
    "end": "3572090"
  },
  {
    "text": "across the different iterations\nof your cilk_for loop, then your result might not\nnecessarily be correct.",
    "start": "3572090",
    "end": "3577910"
  },
  {
    "text": "So you have to make sure that\nthe iterations are, indeed, independent. Yes? AUDIENCE: Can you\nnest cilk_fors?",
    "start": "3577910",
    "end": "3584510"
  },
  {
    "text": "JULIAN SHUN: Yes, so\nyou can nest cilk_fors. But it turns out that,\nfor this example,",
    "start": "3584510",
    "end": "3590210"
  },
  {
    "text": "usually, you already\nhave enough parallelism in the outer loop for\nlarge enough values of n, so it doesn't make sense to\nput a cilk_for loop inside,",
    "start": "3590210",
    "end": "3597950"
  },
  {
    "text": "because using a cilk_for loop\nadds some additional overheads. But you can actually do\nnested cilk_for loops.",
    "start": "3597950",
    "end": "3604610"
  },
  {
    "text": "And in some cases,\nit does make sense, especially if there's\nnot enough parallelism",
    "start": "3604610",
    "end": "3610910"
  },
  {
    "text": "in the outermost for loop. So good question. Yes?",
    "start": "3610910",
    "end": "3616305"
  },
  {
    "text": "AUDIENCE: What does\nthe assembly code look like for the parallel code? JULIAN SHUN: So it has a bunch\nof calls to the Cilk runtime",
    "start": "3616305",
    "end": "3624144"
  },
  {
    "text": "system.  I don't know all the\ndetails, because I haven't",
    "start": "3624145",
    "end": "3629640"
  },
  {
    "text": "looked at this recently. But I think you can\nactually generate the assembly code using a\nflag in the Clang compiler.",
    "start": "3629640",
    "end": "3635700"
  },
  {
    "text": "So that's a good exercise. ",
    "start": "3635700",
    "end": "3647295"
  },
  {
    "text": "AUDIENCE: Yeah,\nyou probably want to look at the LLVM IR,\nrather than the assembly,",
    "start": "3647295",
    "end": "3654549"
  },
  {
    "text": "to begin with, to\nunderstand what's going on. It has three\ninstructions that are not",
    "start": "3654550",
    "end": "3659920"
  },
  {
    "text": "in the standard LLVM, which were\nadded to support parallelism.",
    "start": "3659920",
    "end": "3667990"
  },
  {
    "text": "Those things, when it's\nlowered into assembly,",
    "start": "3667990",
    "end": "3673750"
  },
  {
    "text": "each of those\ninstructions becomes a bunch of assembly\nlanguage instructions.",
    "start": "3673750",
    "end": "3679270"
  },
  {
    "text": "So you don't want to mess with\nlooking at it in the assembler until you see what it looks\nlike in the LLVM first.",
    "start": "3679270",
    "end": "3686590"
  },
  {
    "text": " JULIAN SHUN: So good question.",
    "start": "3686590",
    "end": "3694059"
  },
  {
    "text": "Any other questions\nabout this code here? ",
    "start": "3694060",
    "end": "3704270"
  },
  {
    "text": "OK, so let's look\nat another example.",
    "start": "3704270",
    "end": "3709611"
  },
  {
    "text": "So let's say we\nhad this for loop where, on each\niteration i, we're just incrementing a\nvariable sum by i.",
    "start": "3709611",
    "end": "3718530"
  },
  {
    "text": "So this is essentially\ngoing to compute the summation of everything\nfrom i equals 0 up to n minus 1,",
    "start": "3718530",
    "end": "3724980"
  },
  {
    "text": "and then print out the result. So one straightforward way to\ntry to parallelize this code",
    "start": "3724980",
    "end": "3733710"
  },
  {
    "text": "is to just change\nthe for to cilk_for.",
    "start": "3733710",
    "end": "3738790"
  },
  {
    "text": "So does this code work? ",
    "start": "3738790",
    "end": "3747330"
  },
  {
    "text": "Who thinks that this\ncode doesn't work? Or doesn't compute\nthe correct result?",
    "start": "3747330",
    "end": "3755750"
  },
  {
    "text": "So about half of you. And who thinks this\ncode does work?",
    "start": "3755750",
    "end": "3763470"
  },
  {
    "text": "So a couple people. And I guess the rest of\nthe people don't care.",
    "start": "3763470",
    "end": "3770309"
  },
  {
    "text": "So it turns out that it's not\nactually necessarily going to give you the right answer.",
    "start": "3770310",
    "end": "3776549"
  },
  {
    "text": "Because the cilk_for\nloop says you can execute these\niterations in parallel,",
    "start": "3776550",
    "end": "3782220"
  },
  {
    "text": "but they're all updating the\nsame shared variable sum here. So you have what's called\na determinacy race, where",
    "start": "3782220",
    "end": "3790410"
  },
  {
    "text": "multiple processors can be\nwriting to the same memory location. We'll talk much more\nabout determinacy races",
    "start": "3790410",
    "end": "3795450"
  },
  {
    "text": "in the next lecture. But for this example,\nit's not necessarily going to work if you run it\non more than one processor.",
    "start": "3795450",
    "end": "3804750"
  },
  {
    "text": "And Cilk actually has a\nnice way to deal with this. So in Cilk, we have\nsomething known as a reducer.",
    "start": "3804750",
    "end": "3811650"
  },
  {
    "text": "This is one example\nof a hyperobject, which I mentioned earlier. And with a reducer,\nwhat you have to do",
    "start": "3811650",
    "end": "3818040"
  },
  {
    "text": "is, instead of declaring\nthe sum variable just has an unsigned long\ndata type, what you do",
    "start": "3818040",
    "end": "3824910"
  },
  {
    "text": "is you use this macro called\nCILK_C_REDUCER_OPADD, which specifies we want to create\na reducer with the addition",
    "start": "3824910",
    "end": "3833339"
  },
  {
    "text": "function. Then we have the\nvariable name sum, the data type unsigned long,\nand then the initial value 0.",
    "start": "3833340",
    "end": "3840580"
  },
  {
    "text": "And then we have a macro\nto register this reducer, so a CILK_C_REGISTER_REDUCER.",
    "start": "3840580",
    "end": "3846810"
  },
  {
    "text": "And then now, inside\nthis cilk_for loop, we can increment the sum,\nor REDUCER_VIEW, of sum,",
    "start": "3846810",
    "end": "3853410"
  },
  {
    "text": "which is another macro, by i. And you can actually\nexecute this in parallel,",
    "start": "3853410",
    "end": "3858540"
  },
  {
    "text": "and it will give\nyou the same answer that you would get if you\nran this sequentially.",
    "start": "3858540",
    "end": "3863880"
  },
  {
    "text": "So the reducer will take care of\nthis determinacy race for you. And at the end, when you\nprint out this result,",
    "start": "3863880",
    "end": "3871320"
  },
  {
    "text": "you'll see that the sum is equal\nto the sum that you expect.",
    "start": "3871320",
    "end": "3876450"
  },
  {
    "text": "And then after you\nfinish using the reducer, you use this other macro called\nCILK_C_UNREGISTER_REDUCER(sum)",
    "start": "3876450",
    "end": "3883380"
  },
  {
    "text": "that tells the system that\nyou're done using this reducer.",
    "start": "3883380",
    "end": "3888450"
  },
  {
    "text": "So this is one way to\ndeal with this problem when you want to do a reduction.",
    "start": "3888450",
    "end": "3894780"
  },
  {
    "text": "And it turns out that there\nare many other interesting reduction operators that\nyou might want to use.",
    "start": "3894780",
    "end": "3899960"
  },
  {
    "text": "And in general, you can\ncreate reduces for monoids. And monoids are\nalgebraic structures",
    "start": "3899960",
    "end": "3906150"
  },
  {
    "text": "that have an associative\nbinary operation as well as an identity element. So the addition\noperator is a monoid,",
    "start": "3906150",
    "end": "3913320"
  },
  {
    "text": "because it's\nassociative, it's binary, and the identity element is 0.",
    "start": "3913320",
    "end": "3919830"
  },
  {
    "text": "Cilk also has several\nother predefined reducers, including multiplication, min,\nmax, and, or, xor, et cetera.",
    "start": "3919830",
    "end": "3927900"
  },
  {
    "text": "So these are all monoids. And you can also define\nyour own reducer. So in fact, in\nthe next homework,",
    "start": "3927900",
    "end": "3933827"
  },
  {
    "text": "you'll have the opportunity\nto play around with reducers and write a reducer for lists.",
    "start": "3933827",
    "end": "3941192"
  },
  {
    "text": "So that's reducers. ",
    "start": "3941193",
    "end": "3946740"
  },
  {
    "text": "Another nice thing about\nCilk is that there's always a valid serial interpretation\nof the program.",
    "start": "3946740",
    "end": "3953560"
  },
  {
    "text": "So the serial elision\nof a Cilk program is always a legal\ninterpretation.",
    "start": "3953560",
    "end": "3958950"
  },
  {
    "text": "And for the Cilk source\ncode on the left, the serial elision\nis basically the code",
    "start": "3958950",
    "end": "3964740"
  },
  {
    "text": "you get if you get\nrid of the cilk_spawn and cilk_sync statements. And this looks just like\nthe sequential code.",
    "start": "3964740",
    "end": "3972750"
  },
  {
    "text": " And remember that the Cilk\nkeywords grant permission",
    "start": "3972750",
    "end": "3980190"
  },
  {
    "text": "for parallel execution,\nbut they don't necessarily command parallel execution. So if you ran this Cilk\ncode using a single core,",
    "start": "3980190",
    "end": "3988950"
  },
  {
    "text": "it wouldn't actually create\nthese parallel tasks, and you would get\nthe same answer as the sequential program.",
    "start": "3988950",
    "end": "3995640"
  },
  {
    "text": "And this is-- in the\nserial edition-- is also a correct interpretation. So unlike other solutions,\nsuch as TBB and Pthreads,",
    "start": "3995640",
    "end": "4004550"
  },
  {
    "text": "it's actually difficult,\nin those environments, to get a program that does what\nthe sequential program does.",
    "start": "4004550",
    "end": "4011000"
  },
  {
    "text": "Because they're actually\ndoing a lot of additional work to set up these parallel calls\nand create these argument",
    "start": "4011000",
    "end": "4018990"
  },
  {
    "text": "structures and other\nscheduling constructs. Whereas in Cilk,\nit's very easy just to get this serial elision.",
    "start": "4018990",
    "end": "4024560"
  },
  {
    "text": "You just define cilk_spawn\nand cilk_sync to be null.",
    "start": "4024560",
    "end": "4030020"
  },
  {
    "text": "You also define\ncilk_for to be for. And then this gives you a\nvalid sequential program.",
    "start": "4030020",
    "end": "4036170"
  },
  {
    "text": "So when you're\ndebugging code, and you might first want to check if the\nsequential elision of your Cilk",
    "start": "4036170",
    "end": "4044300"
  },
  {
    "text": "program is correct,\nand you can easily do that by using these macros. Or actually, there's\nactually a compiler flag",
    "start": "4044300",
    "end": "4050780"
  },
  {
    "text": "that will do that for you\nand give you the equivalent C program. So this is a nice way\nto debug, because you",
    "start": "4050780",
    "end": "4057109"
  },
  {
    "text": "don't have to start with\nthe parallel program. You can first check if this\nserial program is correct",
    "start": "4057110",
    "end": "4062460"
  },
  {
    "text": "before you go on to debug\nthe parallel program. ",
    "start": "4062460",
    "end": "4067930"
  },
  {
    "text": "Questions? Yes? AUDIENCE: So does cilk_for--",
    "start": "4067930",
    "end": "4074030"
  },
  {
    "text": "does each iteration of\nthe cilk_for its own task",
    "start": "4074030",
    "end": "4079730"
  },
  {
    "text": "that the scheduler decides if\nit wants to execute in parallel, or if it executes in parallel,\ndo all of the iterations",
    "start": "4079730",
    "end": "4086520"
  },
  {
    "text": "execute in parallel? JULIAN SHUN: So it turns\nout that by default,",
    "start": "4086520",
    "end": "4092310"
  },
  {
    "text": "it groups a bunch of iterations\ntogether into a single task, because it doesn't make\nsense to break it down",
    "start": "4092310",
    "end": "4099479"
  },
  {
    "text": "into such small chunks, due to\nthe overheads of parallelism. But there's actually\na setting you",
    "start": "4099479",
    "end": "4106170"
  },
  {
    "text": "can do to change the grain\nsize of the for loop. So you could actually make\nit so that each iteration",
    "start": "4106170",
    "end": "4112068"
  },
  {
    "text": "is its own task. And then, as you\nthe scheduler will",
    "start": "4112069",
    "end": "4117359"
  },
  {
    "text": "decide how to map\nthese different task onto different\nprocessors, or even if it wants to execute any\nof these tasks in parallel.",
    "start": "4117359",
    "end": "4125548"
  },
  {
    "text": "So good question. ",
    "start": "4125549",
    "end": "4136600"
  },
  {
    "text": "So the idea in Cilk is\nto allow the programmer to express logical\nparallelism in an application.",
    "start": "4136600",
    "end": "4143870"
  },
  {
    "text": "So the programmer\njust has to identify which pieces of the code\ncould be executed in parallel,",
    "start": "4143870",
    "end": "4149649"
  },
  {
    "text": "but doesn't necessarily have to\ndetermine which pieces of code",
    "start": "4149649",
    "end": "4155049"
  },
  {
    "text": "should be executed in parallel. And then Cilk has\na runtime scheduler",
    "start": "4155050",
    "end": "4161350"
  },
  {
    "text": "that will automatically\nmap the executing program onto the available\nprocessor cores' runtime.",
    "start": "4161350",
    "end": "4168759"
  },
  {
    "text": "And it does this\ndynamically using a work-stealing\nscheduling algorithm.",
    "start": "4168760",
    "end": "4174149"
  },
  {
    "text": "And the work-stealing\nscheduler is used to balance the\ntasks evenly across",
    "start": "4174149",
    "end": "4179439"
  },
  {
    "text": "the different processors. And we'll talk more about\nthe work-stealing scheduler in a future lecture.",
    "start": "4179439",
    "end": "4185740"
  },
  {
    "text": "But I want to emphasize that\nunlike the other concurrency platforms that we\nlooked at today,",
    "start": "4185740",
    "end": "4192278"
  },
  {
    "text": "Cilk's work-stealing scheduling\nalgorithm is theoretically efficient, whereas the OpenMP\nand TBB schedulers are not",
    "start": "4192279",
    "end": "4200560"
  },
  {
    "text": "theoretically efficient. So this is a nice property,\nbecause it will guarantee you that the algorithms you\nwrite on top of Cilk",
    "start": "4200560",
    "end": "4207910"
  },
  {
    "text": "will also be\ntheoretically efficient. ",
    "start": "4207910",
    "end": "4213420"
  },
  {
    "text": "So here's a high-level\nillustration of the Cilk ecosystem.",
    "start": "4213420",
    "end": "4219460"
  },
  {
    "text": "It's a very simplified\nview, but I did this to fit it on a single slide.",
    "start": "4219460",
    "end": "4225860"
  },
  {
    "text": "So what you do is you\ntake the Cilk source code, you pass it to your\nfavorite Cilk compiler--",
    "start": "4225860",
    "end": "4232320"
  },
  {
    "text": "the Tapir/LLVM\ncompiler-- and this gives you a binary that you\ncan run on multiple processors.",
    "start": "4232320",
    "end": "4240720"
  },
  {
    "text": "And then you pass a program\ninput to the binary, you run it on however\nmany processors you have,",
    "start": "4240720",
    "end": "4248460"
  },
  {
    "text": "and then this allows you\nto benchmark the parallel performance of your program. ",
    "start": "4248460",
    "end": "4255890"
  },
  {
    "text": "You can also do serial testing. And to do this, you just obtain\na serial elision of the Cilk",
    "start": "4255890",
    "end": "4261820"
  },
  {
    "text": "program, and you pass it to\nan ordinary C or C++ compiler. It generates a binary that can\nonly run on a single processor,",
    "start": "4261820",
    "end": "4271360"
  },
  {
    "text": "and you run your suite of\nserial regression tests on this single threaded binary.",
    "start": "4271360",
    "end": "4277020"
  },
  {
    "text": "And this will allow you to\nbenchmark the performance of your serial code and\nalso debug any issues",
    "start": "4277020",
    "end": "4282970"
  },
  {
    "text": "that might have arised\nwhen you were running this program sequentially. ",
    "start": "4282970",
    "end": "4290460"
  },
  {
    "text": "Another way to do this\nis you can actually just compile the original\nCilk code but run it",
    "start": "4290460",
    "end": "4296320"
  },
  {
    "text": "on a single processor. So there's a command\nline argument that tells the runtime system\nhow many processors you",
    "start": "4296320",
    "end": "4302410"
  },
  {
    "text": "want to use. And if you set that\nparameter to 1, then it will only use\na single processor.",
    "start": "4302410",
    "end": "4307690"
  },
  {
    "text": "And this allows you to benchmark\nthe single threaded performance",
    "start": "4307690",
    "end": "4313120"
  },
  {
    "text": "of your code as well. And the parallel program\nexecuting on a single core should behave\nexactly the same way",
    "start": "4313120",
    "end": "4320050"
  },
  {
    "text": "as the execution of\nthis serial elision. So that's one of the\nadvantages of using Cilk.",
    "start": "4320050",
    "end": "4327780"
  },
  {
    "text": "And because you can easily do\nserial testing using the Cilk platform, this allows\nyou to separate out",
    "start": "4327780",
    "end": "4335500"
  },
  {
    "text": "the serial correctness from\nthe parallel correctness. As I said earlier, you can first\ndebug the serial correctness,",
    "start": "4335500",
    "end": "4341050"
  },
  {
    "text": "as well as any performance\nissues, before moving on to the parallel version.",
    "start": "4341050",
    "end": "4346220"
  },
  {
    "text": "And another point\nI want to make is that because Cilk actually\nuses the serial program",
    "start": "4346220",
    "end": "4355630"
  },
  {
    "text": "inside its task, it's\nactually good to optimize the serial program\neven when you're",
    "start": "4355630",
    "end": "4360670"
  },
  {
    "text": "writing a parallel\nprogram, because optimizing the serial program\nfor performance will also translate to\nbetter parallel performance.",
    "start": "4360670",
    "end": "4367929"
  },
  {
    "text": " Another nice feature\nof Cilk is that it",
    "start": "4367930",
    "end": "4375460"
  },
  {
    "text": "has this tool called\nCilksan, which stands for Cilk Sanitizer.",
    "start": "4375460",
    "end": "4381070"
  },
  {
    "text": "And Cilksan will detect\nany determinacy races that you have in your code,\nwhich will significantly",
    "start": "4381070",
    "end": "4388930"
  },
  {
    "text": "help you with debugging\nthe correctness as well as the\nperformance of your code.",
    "start": "4388930",
    "end": "4396290"
  },
  {
    "text": "So if you compile the Cilk\ncode using the Cilksan flag, it will generate an instrumented\nbinary that, when you run,",
    "start": "4396290",
    "end": "4404410"
  },
  {
    "text": "it will find and localize\nall the determinacy races in your program. So it will tell you where\nthe determinacy races occur,",
    "start": "4404410",
    "end": "4411340"
  },
  {
    "text": "so that you can go inspect\nthat part of your code and fix it if necessary.",
    "start": "4411340",
    "end": "4417740"
  },
  {
    "text": "So this is a very useful\ntool for benchmarking your parallel programs.",
    "start": "4417740",
    "end": "4423170"
  },
  {
    "text": " Cilk also has another nice\ntool called Cilkscale.",
    "start": "4423170",
    "end": "4429400"
  },
  {
    "text": "Cilkscale is a\nperformance analyzer. It will analyze how\nmuch parallelism",
    "start": "4429400",
    "end": "4435850"
  },
  {
    "text": "is available in your program\nas well as the total amount of work that it's doing. So again, you pass a\nflag to the compiler that",
    "start": "4435850",
    "end": "4443440"
  },
  {
    "text": "will turn on Cilkscale,\nand it will generate a binary that is instrumented. And then when you\nrun this code, it",
    "start": "4443440",
    "end": "4451192"
  },
  {
    "text": "will give you a\nscalability report.  So you'll find these\ntools very useful when",
    "start": "4451192",
    "end": "4457390"
  },
  {
    "text": "you're doing the next project. And we'll talk a little bit\nmore about these two tools",
    "start": "4457390",
    "end": "4463210"
  },
  {
    "text": "in the next lecture.  And as I said, Cilkscale will\nanalyze how well your program",
    "start": "4463210",
    "end": "4469300"
  },
  {
    "text": "will scale to larger machines. So it will basically tell\nyou the maximum number of processors that your code\ncould possibly take advantage",
    "start": "4469300",
    "end": "4476540"
  },
  {
    "text": "of.  Any questions? Yes? AUDIENCE: What do you\nmean when you say runtime?",
    "start": "4476540",
    "end": "4483900"
  },
  {
    "text": "JULIAN SHUN: So I mean the\nscheduler-- the Cilk runtime scheduler that's scheduling\nthe different tasks when",
    "start": "4483900",
    "end": "4490960"
  },
  {
    "text": "you're running the program. AUDIENCE: So that's\nincluded in the binary. JULIAN SHUN: So it's\nlinked from the binary.",
    "start": "4490960",
    "end": "4497960"
  },
  {
    "text": "It's not stored\nin the same place. It's linked. ",
    "start": "4497960",
    "end": "4503739"
  },
  {
    "text": "Other questions?  So let me summarize\nwhat we looked at today.",
    "start": "4503740",
    "end": "4511300"
  },
  {
    "text": "So first, we saw that\nmost processors today have multiple cores.",
    "start": "4511300",
    "end": "4517469"
  },
  {
    "text": "And probably all of your laptops\nhave more than one core on it. Who has a laptop that\nonly has one core?",
    "start": "4517470",
    "end": "4523590"
  },
  {
    "text": " AUDIENCE: [INAUDIBLE].",
    "start": "4523590",
    "end": "4529270"
  },
  {
    "text": "JULIAN SHUN: When\ndid you buy it? Probably a long time ago. ",
    "start": "4529270",
    "end": "4542520"
  },
  {
    "text": "So nowadays, obtaining high\nperformance on your machines requires you to write\nparallel programs.",
    "start": "4542520",
    "end": "4548220"
  },
  {
    "text": "But parallel programming\ncan be very hard, especially if you have\nthe program directly on the processor cores and\ninteract with the operating",
    "start": "4548220",
    "end": "4555310"
  },
  {
    "text": "system yourself. So Cilk is very nice, because\nit abstracts the processor cores",
    "start": "4555310",
    "end": "4560739"
  },
  {
    "text": "from the programmer, it\nhandles synchronization and communication protocols,\nand it also performs",
    "start": "4560740",
    "end": "4566860"
  },
  {
    "text": "provably good load-balancing. And in the next project,\nyou'll have a chance",
    "start": "4566860",
    "end": "4571990"
  },
  {
    "text": "to play around with Cilk. You'll be implementing your\nown parallel screensaver,",
    "start": "4571990",
    "end": "4577490"
  },
  {
    "text": "so that's a very\nfun project to do. And possibly, in one\nof the future lectures, we'll post some of\nthe nicest screensaver",
    "start": "4577490",
    "end": "4584820"
  },
  {
    "text": "that students developed\nfor everyone to see. OK, so that's all.",
    "start": "4584820",
    "end": "4591070"
  },
  {
    "start": "4591070",
    "end": "4605769"
  }
]
[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "start": "0",
    "end": "15405"
  },
  {
    "text": "ADAM YALA: OK, great. Well, thank you for\nthe great setup. So for this section, I'm gonna\ntalk about some of our work",
    "start": "15405",
    "end": "20530"
  },
  {
    "text": "in interpreting\nmammograms for cancer. Specifically it's going to\ngo into cancer detection and triage mammograms. Next, we'll talk about\nour technical approach",
    "start": "20530",
    "end": "27940"
  },
  {
    "text": "in breast cancer risk. And then finally close up in\nthe many, many different ways to mess up and the way\nthings can go wrong,",
    "start": "27940",
    "end": "33850"
  },
  {
    "text": "and how does it [INAUDIBLE]\nclinical implementation. So let's kind of\nlook more closely at the numbers of the actual\nbreast cancer screening",
    "start": "33850",
    "end": "39010"
  },
  {
    "start": "36000",
    "end": "36000"
  },
  {
    "text": "workflow. So as Connie already said,\nyou might see something like 1,000 patients. All them take mammograms.",
    "start": "39010",
    "end": "44680"
  },
  {
    "text": "Of that 1,000, on\naverage maybe 100 they called back for\nadditional imaging. Of that 100, something\nlike 20 will get biopsied.",
    "start": "44680",
    "end": "52172"
  },
  {
    "text": "And you end up with maybe\nfive or six diagnoses of breast cancer. So one very clear thing\nyou see about problems",
    "start": "52172",
    "end": "57880"
  },
  {
    "text": "when you look at this\nfunnel is that way over 99% of people that you see\nin a given day are cancer-free.",
    "start": "57880",
    "end": "64860"
  },
  {
    "text": "So your actual\nincidence is very low. And so there's kind of a natural\nquestion that can come up. What can you do in\nterms of modeling",
    "start": "64860",
    "end": "70960"
  },
  {
    "text": "if you have an even OK\ncancer detection model to raise the incidence\nof this population but automatically reading\na portion of the population",
    "start": "70960",
    "end": "77590"
  },
  {
    "text": "is healthy. Does everybody just\nfollow that broad idea? OK. That's enough head nods.",
    "start": "77590",
    "end": "83407"
  },
  {
    "text": "So the broad idea\nhere is you're going to train the cancer detection\nmodel to try to find cancer as well as we can.",
    "start": "83407",
    "end": "88597"
  },
  {
    "text": "Given that, we're\ngoing to try to say, what's a threshold on\na development set such that we can kind of\nsay below the threshold",
    "start": "88597",
    "end": "94950"
  },
  {
    "text": "no one has cancer. And if we use that\nat test times, simulating clinical\nimplementation, what would that look like?",
    "start": "94950",
    "end": "100030"
  },
  {
    "text": "And can we actually do better\nby doing this kind of process? And the kind of broad plan of\nhow I'm gonna talk about this--",
    "start": "100030",
    "end": "106240"
  },
  {
    "text": "I'm gonna do this for\nthe next product as well. Of course, we're going\nto talk about the kind of dataset collection and\nhow we think about, like, you know, what is good data\nand how do we think about that.",
    "start": "106240",
    "end": "114000"
  },
  {
    "text": "Next, the actual methodology and\ngo into the general challenges when you're modeling mammograms\nfor any computer mission tasks,",
    "start": "114000",
    "end": "119930"
  },
  {
    "text": "specifically in cancer,\nand also, obviously, risk. And lastly, how we thought\nabout the analysis and some kind of objectives there.",
    "start": "119930",
    "end": "126270"
  },
  {
    "text": "So to kind of dive into it, we\ntook consecutive mammograms. I'll get back into this later. This is actually\nquite important.",
    "start": "126270",
    "end": "131450"
  },
  {
    "start": "127000",
    "end": "127000"
  },
  {
    "text": "We took consecutive\nmammograms from 2009 to 2016. This started off with\nabout 280,000 cancers.",
    "start": "131450",
    "end": "137739"
  },
  {
    "text": "And once we kind of filtered--\nso at least one year follow up, we ended up with\nthis final setting",
    "start": "137740",
    "end": "143400"
  },
  {
    "text": "where we had 220,000\nmammograms for training and about 26,000 for\ndevelopment and testing.",
    "start": "143400",
    "end": "150088"
  },
  {
    "text": "And the way we had it,\nit all comes to say, is this a positive\nmammogram or not? We didn't look at\nwhat cancers were caught by the radiologists.",
    "start": "150088",
    "end": "156220"
  },
  {
    "text": "We'd say, you know, what\nwas cancer that was found in any means within a year? And where we looked to was\nthrough the radiology, EHR,",
    "start": "156220",
    "end": "162510"
  },
  {
    "text": "and the Partners-- kind\nof five hospital registry. And there we were\ntrying to save cancer-- if anyway we can tell\na cancer occurred,",
    "start": "162510",
    "end": "168300"
  },
  {
    "text": "let's mart it as such regardless\nof what others caught on MRI or some kind of later stage.",
    "start": "168300",
    "end": "173383"
  },
  {
    "text": "And so the thing we're\ntrying to do here is just mimic the\nreal world of what are we trying to catch cancer.",
    "start": "173383",
    "end": "179023"
  },
  {
    "text": "And finally, important\ndetails we always split by patient so that\nyour results aren't just",
    "start": "179023",
    "end": "184290"
  },
  {
    "text": "memorizing this specific\npatient didn't have cancer. And so we have some overlap\nthat's some bad bias to have.",
    "start": "184290",
    "end": "190130"
  },
  {
    "text": "OK. That's pretty simple. Now let's go into the modeling. There's going to kind\nof follow two chunks.",
    "start": "190130",
    "end": "195510"
  },
  {
    "text": "One chunk is going to be on\nthe kind of general challenges, and it's kind of shared between\nthe variety of projects.",
    "start": "195510",
    "end": "200680"
  },
  {
    "text": "And next is going to be kind\nof more specific analysis for this project. So kind of a general\nquestion you might be asking,",
    "start": "200680",
    "end": "207900"
  },
  {
    "start": "204000",
    "end": "204000"
  },
  {
    "text": "I have some image. I have some outcome. Obviously, this is just\nimage classification. How is it different\nfrom ImageNet?",
    "start": "207900",
    "end": "214330"
  },
  {
    "text": "Well, it's quite similar. Most lessons are shared. But there are some\nkey differences. So I gave you two examples.",
    "start": "214330",
    "end": "220600"
  },
  {
    "text": "One of them is a\nscene in my kitchen. Can anyone tell me\nwhat the object is? This is not a particularly\nhard question.",
    "start": "220600",
    "end": "226375"
  },
  {
    "text": "AUDIENCE: [Intermingled\nvoices] Dog. Bear. ADAM YALA: Right. AUDIENCE: Dog. ADAM YALA: It is almost\nall of those things. So that is my dog, the best dog.",
    "start": "226376",
    "end": "233180"
  },
  {
    "text": "OK. So can anyone tell\nme, now that you've had some training with Connie,\nif this mammogram indicates",
    "start": "233180",
    "end": "238490"
  },
  {
    "text": "cancer?  Well, it does. And this is unfair for\na couple of reasons.",
    "start": "238490",
    "end": "245260"
  },
  {
    "text": "Let's go into, like,\nwhy this is hard. It's unfair in part because\nyou don't have the training. But it's actually a much\nharder signal to learn.",
    "start": "245260",
    "end": "251880"
  },
  {
    "text": "So first let's kind\nof delve into it. In this kind of task,\nthe image is really huge.",
    "start": "251880",
    "end": "258180"
  },
  {
    "text": "So you have something like a\n3,200 by 2,600 pixel image. This is a single\nview of a breast.",
    "start": "258180",
    "end": "263367"
  },
  {
    "text": "And in that, the actual\ncancer they're looking for might be 50 by 50 pixels. So intuitively your signal to\nnoise ratio is very different.",
    "start": "263367",
    "end": "269780"
  },
  {
    "text": "Whereas an image that-- my dog is like the entire image. She's huge in real\nlife and in that photo.",
    "start": "269780",
    "end": "275130"
  },
  {
    "text": "And the image itself\nis much smaller. So not only do you have\nmuch smaller images, but you're kind of, like, the\nrelative size of the object",
    "start": "275130",
    "end": "281410"
  },
  {
    "text": "in there is much larger. To kind of further\ncompound the difficulty, the pattern you're looking\nfor inside the mammogram",
    "start": "281410",
    "end": "287819"
  },
  {
    "text": "is really context-dependent. So if you saw that pattern\nsomewhere else in the breast, it doesn't indicate\nthe same thing.",
    "start": "287820",
    "end": "294863"
  },
  {
    "text": "And so you really\ncare about where in this kind of global\ncontext this comes out. And if you kind of\ntake the mammogram",
    "start": "294863",
    "end": "299910"
  },
  {
    "text": "at different times with\ndifferent compressions, you would have this kind\nof non-rigid morphing of the image that's much\nmore difficult to model.",
    "start": "299910",
    "end": "306960"
  },
  {
    "text": "Whereas that's a more or\nless context-independent dog. You see that kind of\nframe kind of anywhere, you know it's a dog.",
    "start": "306960",
    "end": "312360"
  },
  {
    "text": "And so it's a much\neasier thing to learn in a traditional\ncomputer vision setting. And so the core challenge\nhere is that both the image",
    "start": "312360",
    "end": "319510"
  },
  {
    "start": "318000",
    "end": "318000"
  },
  {
    "text": "is too big and too small. So if you're looking at just\nthe number of cancers we have,",
    "start": "319510",
    "end": "324600"
  },
  {
    "text": "the cancer might be less\nthan 1% of the mammogram and about 0.7% of your\nimages have cancers,",
    "start": "324600",
    "end": "329610"
  },
  {
    "text": "even in this data set,\nwhich is from 2000 to 2016 MGH, a massive imaging center,\nin total across all of that,",
    "start": "329610",
    "end": "335820"
  },
  {
    "text": "you will still have\nless than 2,000 cancers. And this is super tiny\ncompared to regular object",
    "start": "335820",
    "end": "341670"
  },
  {
    "text": "classification data sets. And this is looking at\nover a million images if you look at all the\nfour views of the exams.",
    "start": "341670",
    "end": "348163"
  },
  {
    "text": "And at the same time,\nit's also too big. So even if I downsample\nthese images, I can only really fit three\nof them for a single GPU.",
    "start": "348163",
    "end": "356669"
  },
  {
    "text": "And so this kind of limits the\nbatch size I can work with. And whereas the\nkind of comparable, if I took just the\nregular image net size,",
    "start": "356670",
    "end": "362970"
  },
  {
    "text": "I could fit batches of\n128, easily happy days and do all this\nparallelization stuff, and it's just much\neasier to play with.",
    "start": "362970",
    "end": "368838"
  },
  {
    "text": "And finally, the actual data\nset itself is quite large. And so you have to do some-- there's nuisances to deal\nwith in terms of, like, just",
    "start": "368838",
    "end": "374340"
  },
  {
    "text": "setting up your server\ninfrastructure to handle these massive data sets, also\nbe able to train efficiently.",
    "start": "374340",
    "end": "381730"
  },
  {
    "start": "381000",
    "end": "381000"
  },
  {
    "text": "So you know, the\ncore challenge here across all of\nthese kind of tasks is, how do we make this\nmodel actually learn?",
    "start": "381730",
    "end": "387310"
  },
  {
    "text": "The core problem is that\nour signal to noise ratio is quite low. So training ends up\nbeing quite unstable. And there's a kind of a\ncouple of simple levers",
    "start": "387310",
    "end": "393820"
  },
  {
    "text": "you can play with. The first lever is often\ndeep learning initialization. Next, we're gonna talk about\nkind of the optimization",
    "start": "393820",
    "end": "400720"
  },
  {
    "text": "or architecture choice\nand how this compares to what people often\ndo in the community, including in a recent\npaper from yesterday.",
    "start": "400720",
    "end": "406781"
  },
  {
    "text": "And then finally, we're gonna\ntalk about something more explicit for the triage idea and\nhow we actually use this model",
    "start": "406782",
    "end": "411820"
  },
  {
    "text": "once it's trained. OK. So before I go into how\nwe made these choices, I'm just going to say what\nwe chose to give you context",
    "start": "411820",
    "end": "418930"
  },
  {
    "text": "before I dive in. So we followed some\nimage initialization. We use a relatively large\nbatch size-ish of 24.",
    "start": "418930",
    "end": "426160"
  },
  {
    "text": "And the way we do that\nis by taking 4 GPUs and just stepping\na couple of times before doing an optimizer step.",
    "start": "426160",
    "end": "431177"
  },
  {
    "text": "So when you do a\ncouple rounds of back prop first to accumulate\nthose gradients before doing optimization.",
    "start": "431177",
    "end": "436710"
  },
  {
    "text": "And you sample balanced\nbatches of training time. And for backbone architecture\nwe use ResNet-18. It's just kind of,\nlike, fairly standard.",
    "start": "436710",
    "end": "443750"
  },
  {
    "text": "OK. But as I said before, one\nof the first key decisions is how do you think about\nyour initialization?",
    "start": "443750",
    "end": "449620"
  },
  {
    "start": "449000",
    "end": "449000"
  },
  {
    "text": "So this is a figure of\nImageNet initialization versus random initialization. It's not any\nparticular experiment.",
    "start": "449620",
    "end": "456190"
  },
  {
    "text": "I've done this across\nmany, many times. It's always like this. Where if you use\nimage initialization,",
    "start": "456190",
    "end": "461200"
  },
  {
    "text": "your loss drops\nimmediately, both in train loss and development\nloss when you actually learn something.",
    "start": "461200",
    "end": "466330"
  },
  {
    "text": "Whereas when you do\nrandom initialization, you kind of don't\nlearn anything. And your loss kind of\nbounds around the top",
    "start": "466330",
    "end": "471732"
  },
  {
    "text": "for a very long time before\nit finds some region where it quickly starts learning. And then it will plateau\nagain for a long time",
    "start": "471732",
    "end": "477216"
  },
  {
    "text": "before quickly start learning. And to kind of\ngive some context, to give about 50 epochs takes\non the order of, like, 15,",
    "start": "477217",
    "end": "484400"
  },
  {
    "text": "16 hours. And so to wait long\nenough to even see if random initialization\ncould perform as well",
    "start": "484400",
    "end": "490539"
  },
  {
    "text": "is beyond my level of patience. It just takes too long, and\nI have other experiments to be running.",
    "start": "490540",
    "end": "496009"
  },
  {
    "text": "So this is more of an\nempirical observation that the image initialization\nlearns immediately. And there's some kind of\nquestions of why is this?",
    "start": "496010",
    "end": "502955"
  },
  {
    "text": "Our theoretical understanding\nof this is not that strong. We have some intuitions of\nwhy this might be happening. We don't think it's anything\nabout this particular filter",
    "start": "502955",
    "end": "511330"
  },
  {
    "text": "of this dog is really\ngreat for breast cancer. That's quite implausible. But if you look it into a lot\nof the earlier research in terms",
    "start": "511330",
    "end": "517663"
  },
  {
    "text": "of the right kind of random\ninitialization for things like revenue networks,\na lot of focus was on does the\nactivation pattern not",
    "start": "517663",
    "end": "524200"
  },
  {
    "text": "blow up as you go\nfurther down the line. One of the benefits of starting\nwith the pre-trained network is that a lot of\nthose kind of dynamics",
    "start": "524200",
    "end": "530725"
  },
  {
    "text": "are already figured out\nfor a specific task. And so shifting from\nthat to other tasks has seemed to be not\nthat challenging.",
    "start": "530725",
    "end": "537070"
  },
  {
    "text": "Another possible\narea of explanation is actually in a\nBatchNorm statistics. So if you remember, we can\nonly fit three images per GPU.",
    "start": "537070",
    "end": "543118"
  },
  {
    "text": "And the way the BatchNorm\ninitialization is implemented across every deep learning\nlibrary that I know of,",
    "start": "543118",
    "end": "548319"
  },
  {
    "text": "it computes\nindependently per GPU to minimize the kind of\ninter-GPU communication. And so it's also less able to\nkind of guess from scratch.",
    "start": "548320",
    "end": "555368"
  },
  {
    "text": "But if you're starting with\nthe BatchNorm statistics to ImageNet and just\nslowly shifting it over, it might also result in\nsome stability benefits.",
    "start": "555368",
    "end": "561910"
  },
  {
    "text": " But in general, or\nlike, a true deeper theoretical understanding, but\nas I said, it still eludes us.",
    "start": "561910",
    "end": "569110"
  },
  {
    "text": "And it isn't something I can\ngive too much conclusions about, unfortunately.",
    "start": "569110",
    "end": "574160"
  },
  {
    "text": "OK. So that's initialization. And if you don't get this\nright, kind of nothing works for a very long time. So if you're gonna start\na project in this space,",
    "start": "574160",
    "end": "580630"
  },
  {
    "text": "try this. Next, another important\ndecision that if you don't do, it kind of breaks, is your\noptimization/architecture",
    "start": "580630",
    "end": "586540"
  },
  {
    "text": "choice. So as I said before, kind of\na core problem in stability here is this idea that our\njust signal to noise ratio",
    "start": "586540",
    "end": "592600"
  },
  {
    "start": "587000",
    "end": "587000"
  },
  {
    "text": "is really low. And so a very common\napproach throughout a lot of the prior work\nand things I actually",
    "start": "592600",
    "end": "597760"
  },
  {
    "text": "have tried myself before\nis to say, OK, let's just break down this problem.",
    "start": "597760",
    "end": "602860"
  },
  {
    "text": "We can train at a\npatch level first. We're going to take just\nsubsets of a mammogram in this little\nbonding box, have it",
    "start": "602860",
    "end": "608590"
  },
  {
    "text": "annotated for radiology\nfindings like benign masses or calcification and\nthings of that sort.",
    "start": "608590",
    "end": "614019"
  },
  {
    "text": "We're going to\npre-train on that task to have this kind of\npixel level prediction. And then once we're\ndone with that, we're going to fine tune\nthat initialized model",
    "start": "614020",
    "end": "620950"
  },
  {
    "text": "across the entire image. So you kind of have this\ntwo-stage training procedure.",
    "start": "620950",
    "end": "626837"
  },
  {
    "text": "And actually, another paper\nthat came out just yesterday does the exact same approach\nwith some slightly different details.",
    "start": "626837",
    "end": "634543"
  },
  {
    "text": "But one of the things\nwe wanted to investigate is if you just-- oh, And\nthe base architecture that's always used\nfor this, there",
    "start": "634543",
    "end": "640180"
  },
  {
    "start": "638000",
    "end": "638000"
  },
  {
    "text": "is quite a few valid\noptions of things that just get\nreasonable performance and ImageNet, things like\nVGG, Wide ResNets and ResNets.",
    "start": "640180",
    "end": "648210"
  },
  {
    "text": "In my experience, they all\nperformed fairly similarly. So it's kind of a\nspeed/benefit trade-off.",
    "start": "648210",
    "end": "653722"
  },
  {
    "text": "And there's an advantage to\nusing fully convolutional architectures because if you\nhave fully connected layers that are assumed\nspecific dimensionality,",
    "start": "653722",
    "end": "660550"
  },
  {
    "text": "you can convert them to\nconvolutional layers. They're just more\nconvenient to start with a full convolutional\narchitecture.",
    "start": "660550",
    "end": "666010"
  },
  {
    "text": "There's going to be\nresolution invariant. Yes. AUDIENCE: In the last\nslide when you do patches--",
    "start": "666010",
    "end": "671120"
  },
  {
    "text": "ADAM YALA: Yes. AUDIENCE: How do you\nlabel every single patch? Are they just labeled\nwith a global label?",
    "start": "671120",
    "end": "676317"
  },
  {
    "text": "Or do you have to\nactually look and catch, and figure out what's happened? ADAM YALA: So\nnormally what you do",
    "start": "676317",
    "end": "681397"
  },
  {
    "text": "is you have positive\npatches labeled. And then you randomly\nsample other patches. So from your annotation--\nso, for example, a lot people",
    "start": "681397",
    "end": "688120"
  },
  {
    "text": "do this on public data sets like\nthe Florida DSM dataset that has some entries,\nof like, here are benign masses, benign calcs,\nmalignant calcs, et cetera.",
    "start": "688120",
    "end": "695920"
  },
  {
    "text": "What people do then is\ntake those annotations. They will randomly\nselect other patches and say, if it's not\nthere, it's negative.",
    "start": "695920",
    "end": "702750"
  },
  {
    "text": "And I'm going to\ncall it healthy. And then they'll\nsay if this bonding box overlaps with patch\nby some marginal call,",
    "start": "702750",
    "end": "707949"
  },
  {
    "text": "it's the same label. So do this heuristically. And other data sets that are\nproprietary also kind of play",
    "start": "707950",
    "end": "713230"
  },
  {
    "text": "with a similar trick. In general, they don't actually\nlabel every single pixel accordingly.",
    "start": "713230",
    "end": "718450"
  },
  {
    "text": "But there's relatively\nminor differences in how people do this. But the results are fairly\nsimilar, regardless.",
    "start": "718450",
    "end": "724110"
  },
  {
    "text": "Yes. AUDIENCE: When you go from the\npatch level to the full image, if I understand correctly,\nthe architecture hasn't quite",
    "start": "724110",
    "end": "730360"
  },
  {
    "text": "changed because it's just\nconvolution is over a larger-- ADAM YALA: Exactly. So the end thing right before we\ndo the prediction is normally--",
    "start": "730360",
    "end": "738010"
  },
  {
    "text": "ResNet, for example, does\na global average pool. Channel lies across\nthe entire feature map.",
    "start": "738010",
    "end": "743260"
  },
  {
    "text": "And so they just-- for the patch level they take\nin an image that's 250 by 250, do the global average\npool across that",
    "start": "743260",
    "end": "748840"
  },
  {
    "text": "to make the prediction. And when they just go up to\nthe full resolution image, now you're taking a global\naverage pool over a 3,000",
    "start": "748840",
    "end": "754899"
  },
  {
    "text": "by 2,000. AUDIENCE: And presumably there\nmight be some scaling issue that you might need to adjust.",
    "start": "754900",
    "end": "763610"
  },
  {
    "text": "Do you do any of that? Or are you just-- ADAM YALA: So you feed it\nin at the full resolution the entire time.",
    "start": "763610",
    "end": "769520"
  },
  {
    "text": "So you just-- do\nyou see what I mean? So you're taking a crop. So the resolution\nisn't changing.",
    "start": "769520",
    "end": "775280"
  },
  {
    "text": "So the same filter map should\nbe able to kind of scale accordingly. But if you do things\nlike average pooling,",
    "start": "775280",
    "end": "780460"
  },
  {
    "text": "then you're kind of-- any one thing that has\na very high activation will get averaged down lower. And so, for example,\nin our work,",
    "start": "780460",
    "end": "786040"
  },
  {
    "text": "we use max pooling to\nkind of get around that. Any other questions? But if this looks\ncomplicated, have",
    "start": "786040",
    "end": "792307"
  },
  {
    "text": "no worries because we actually\nthink it's totally unnecessary. And this is the next slide. So good for you.",
    "start": "792307",
    "end": "798920"
  },
  {
    "text": "So as I said before,\nthis kind of, what are the problems\nthat signal to noise? So one obvious thing to kind\nof think about is, like, OK.",
    "start": "798920",
    "end": "805630"
  },
  {
    "start": "805000",
    "end": "805000"
  },
  {
    "text": "Maybe doing SGD with\na batch size of three when the lesion is less than\n1% of the image is a bad idea.",
    "start": "805630",
    "end": "810850"
  },
  {
    "text": "If I just take less\nnoisy gradients by increasing my batch size,\nwhich means use more GPUs, take more steps before\ndoing the weight update,",
    "start": "810850",
    "end": "819680"
  },
  {
    "text": "we actually find that the\nneed to do this actually goes away completely. So these are experiments I did\nin the publicly available data",
    "start": "819680",
    "end": "826122"
  },
  {
    "text": "set a while back while we\nwere figuring this out. If you take this kind of\n[INAUDIBLE] architecture and fine tune with a batch\nsize of 2, 4, 10, 16,",
    "start": "826122",
    "end": "834670"
  },
  {
    "text": "and compare that to just\na one-stage training where you just do the\n[INAUDIBLE] beginning and initialized in ImageNet\nand as you use different batch",
    "start": "834670",
    "end": "841247"
  },
  {
    "text": "sizes, you quickly\nstart to close the gap on the development AUC. And so for all the\nexperiments that we do broadly",
    "start": "841247",
    "end": "847930"
  },
  {
    "text": "we find that we actually get\nreasonably stable training by just using a batch\nsize of 20 and above.",
    "start": "847930",
    "end": "853900"
  },
  {
    "text": "And this kind of comes down to\nif you use a batch size of one, it's just particularly unstable. In other details that we always\nsample the balanced batches.",
    "start": "853900",
    "end": "860290"
  },
  {
    "text": "Cause otherwise you'd\nbe sampling like, 20 batches before you see\na single positive sample. You just don't learn anything.",
    "start": "860290",
    "end": "865360"
  },
  {
    "text": "Cool. So that is like,\nif you do that, you don't do anything complicated. You don't do any fancy cropping\nor anything of that sort,",
    "start": "865360",
    "end": "871209"
  },
  {
    "text": "or like, dealing with\nlike VGG annotations. We found that the actual using\nVGG annotation for this task is not actually helpful.",
    "start": "871210",
    "end": "878620"
  },
  {
    "text": "OK. No questions? Yes. AUDIENCE: So with\nthe larger batch sizing you don't use\nthe magnified patches?",
    "start": "878620",
    "end": "885237"
  },
  {
    "text": "ADAM YALA: We don't. We just take the whole\nimage from beginning. Pretend you-- like,\ncan you just see the annotation as\nwhole image, cancer",
    "start": "885237",
    "end": "891630"
  },
  {
    "text": "with less than within a year. It's a much simpler setup. AUDIENCE: I don't get. That's the same thing\nI thought you said you",
    "start": "891630",
    "end": "897662"
  },
  {
    "text": "couldn't do for memory reasons. ADAM YALA: Oh. So you just-- instead of--\nso normally when you do,",
    "start": "897662",
    "end": "902899"
  },
  {
    "text": "you're going to\ntrain the network, the most common approach is\nyou do back prop and then step. Cause you do back\nprop several times,",
    "start": "902900",
    "end": "908520"
  },
  {
    "text": "you're accumulating the\ngradients, at least in PyTorch. And then you can\ndo step afterwards. So instead of doing the\nwhole batch at one time,",
    "start": "908520",
    "end": "915060"
  },
  {
    "text": "you just do it serially. So there you're just\ntrading time for space. The minimum, though, is you have\nto fit at least a single image",
    "start": "915060",
    "end": "922830"
  },
  {
    "text": "per GPU. And in our case\nwe can fit three. But to make this actually scale,\nwe use four GPUs at a time.",
    "start": "922830",
    "end": "928850"
  },
  {
    "text": " Yes. AUDIENCE: How much is\nthe trade-off with time?",
    "start": "928850",
    "end": "935150"
  },
  {
    "text": "ADAM YALA: So if I'm gonna\ntake one batch size any bigger, I would only do it in\nincrements of let's say 12, because that's how much I\ncan fit within my set of GPUs",
    "start": "935150",
    "end": "942740"
  },
  {
    "text": "at the same time. But to control the\nsize of the experiment you want to have the kind of the\nsame number of gradient updates",
    "start": "942740",
    "end": "947930"
  },
  {
    "text": "per experiment. So if I want to use\na batch size of 48, so all my experiments, instead\nof taking about half a day,",
    "start": "947930",
    "end": "953190"
  },
  {
    "text": "it takes about a day. And so there's kind of,\nlike, this natural trade-off as you go along.",
    "start": "953190",
    "end": "958620"
  },
  {
    "text": "So one of the things I\nmentioned at the very end is we're considering\nsome adversarial approach for something. And one of the annoying\nthings about that",
    "start": "958620",
    "end": "964580"
  },
  {
    "text": "is that if I have five\ndiscriminator steps, oh my god. My my experiment-- I'll take\nthree days per experiment. And [INAUDIBLE]\nupdate of someone",
    "start": "964580",
    "end": "970320"
  },
  {
    "text": "that's trying to\ndesign a better model becomes really slow\nwhen the experiments start taking this long.",
    "start": "970320",
    "end": "976220"
  },
  {
    "text": "Yes. AUDIENCE: So you said\nthe annotations did not help with the training. Is that because\nthe actual cancer",
    "start": "976220",
    "end": "985250"
  },
  {
    "text": "itself is not really different\nfrom the dense tissue, and the location of\nthat matters, and not",
    "start": "985250",
    "end": "991224"
  },
  {
    "text": "the actual granularity of the-- what is the reason? ADAM YALA: So in general\nwhen something doesn't help,",
    "start": "991224",
    "end": "997550"
  },
  {
    "text": "there's always kind of like\na possibility of two things. One thing is that the whole\nimage signal kind of subsumes",
    "start": "997550",
    "end": "1003110"
  },
  {
    "text": "that smaller scale signal. Or there is a\nbetter way to do it I haven't found that would help.",
    "start": "1003110",
    "end": "1008230"
  },
  {
    "text": "And then this thing looks\nto us all very hard. As of now, so the\ntask we're [INAUDIBLE]",
    "start": "1008230",
    "end": "1014330"
  },
  {
    "text": "on is whole image\nclassification. And so on that\ntask it's possible that the kind of\nsurrounding context--",
    "start": "1014330",
    "end": "1020180"
  },
  {
    "text": "so when you do a patch\nwith an annotation, you kind of lose the\ncontext which it appears in. So it's possible that just by\nlooking at the whole context",
    "start": "1020180",
    "end": "1026886"
  },
  {
    "text": "every time, it's as good-- you don't get any benefit from\nkind of the zooming boxes.",
    "start": "1026887",
    "end": "1032750"
  },
  {
    "text": "However, we're not evaluating\non kind of an object detection type of evaluation metric. If you say how well we\nare catching the box.",
    "start": "1032750",
    "end": "1039240"
  },
  {
    "text": "And if we were, we'd probably\nhave much better luck with using the VGG annotation. Because you might\nbe able to tell",
    "start": "1039240",
    "end": "1045506"
  },
  {
    "text": "some of those\ndiscriminations by like, this looks like a breast\nthat's likely to develop cancer at all. And the ability of\nthe model to do that",
    "start": "1045506",
    "end": "1052220"
  },
  {
    "text": "is part of why we\ncan do risk modeling. Which is going to be the kind\nof the last bit of the talk.",
    "start": "1052220",
    "end": "1057610"
  },
  {
    "text": "Yes. AUDIENCE: So do you do\nthe object detection after you identify whether\nthere's cancer or not?",
    "start": "1057610",
    "end": "1062920"
  },
  {
    "text": "ADAM YALA: So as of now we don't\ndo object detection in part because we're framing\nthe problem as triage. So there is quite a\nfew tool kits out there",
    "start": "1062920",
    "end": "1069620"
  },
  {
    "text": "to draw more boxes\non the mammogram. But the insight\nis that if there's 1,000 things to look at,\nlooking at 2,000 things",
    "start": "1069620",
    "end": "1075870"
  },
  {
    "text": "you drew more boxes per image. And it isn't\nnecessarily the problem we're trying to look at. There's quite a bit\nof effort there.",
    "start": "1075870",
    "end": "1082242"
  },
  {
    "text": "And it's something we might\nlook into later in the future. But it's not the\nfocus of this work. Yes.",
    "start": "1082243",
    "end": "1087400"
  },
  {
    "text": "AUDIENCE: So Connie was saying\nthat the same pattern appearing in different parts of the breast\ncan mean different things.",
    "start": "1087400",
    "end": "1096820"
  },
  {
    "text": "But when you're looking at\nthe entire image as once,",
    "start": "1096820",
    "end": "1103174"
  },
  {
    "text": "I would worry\nintuitively about whether the convolutional\narchitecture is",
    "start": "1103175",
    "end": "1109389"
  },
  {
    "text": "going to be able to pick\nthat up or whether-- because you were looking\nfor a very small cancer",
    "start": "1109390",
    "end": "1115840"
  },
  {
    "text": "on a very large image. And then you were looking\nfor the significance",
    "start": "1115840",
    "end": "1121120"
  },
  {
    "text": "of that very small cancer in\ndifferent parts of the image or in different\ncontexts of the image.",
    "start": "1121120",
    "end": "1127910"
  },
  {
    "text": "And I'm just-- I mean, it's a pleasant\nsurprise that this works. ADAM YALA: So there is kind\nof like two pieces that",
    "start": "1127910",
    "end": "1134770"
  },
  {
    "text": "can help explain that. So the first is that\nif you look at, like, the receptive fields of any\ngiven last receptive map",
    "start": "1134770",
    "end": "1140320"
  },
  {
    "text": "at the very end of the\nnetwork, each of those summarizes through\nthese convolutions a fairly sizable\npart of the image.",
    "start": "1140320",
    "end": "1147350"
  },
  {
    "text": "And so you are kind of, like,\neach pixel at the very end ends up being like something\nlike a 50 by 50 image.",
    "start": "1147350",
    "end": "1152620"
  },
  {
    "text": "That's by five total dimensions. And so each part does summarize\nthis local context decently",
    "start": "1152620",
    "end": "1157780"
  },
  {
    "text": "well. And when you do maximum\nat the very end, and you get some not perfect\nbut OK global summary, what",
    "start": "1157780",
    "end": "1163780"
  },
  {
    "text": "is the context of this image? So something like, let's say,\nsome of the lower dimensions can summarize, like, is\nthis a dense breast or kind",
    "start": "1163780",
    "end": "1170650"
  },
  {
    "text": "of some of the other\npattern information that might tell you what\nkind of breast this is. Whereas any one of\nthem can tell you",
    "start": "1170650",
    "end": "1178210"
  },
  {
    "text": "this looks like a cancer\ngiven its local context. So do you have some\nlevel summarization, both because of the\nchannel-wise maxim of the end,",
    "start": "1178210",
    "end": "1184900"
  },
  {
    "text": "and because each point through\nthe many, many convolutions of different strides gives you\nsome of that summary effect.",
    "start": "1184900",
    "end": "1193830"
  },
  {
    "text": "OK, great. I'm going to jump forward. So we've talked about\nhow to make this learn.",
    "start": "1193830",
    "end": "1198899"
  },
  {
    "text": "It's actually not\nthat tricky if we just do it carefully and tune. Now I'll talk about how to use\nthis model to actually deliver",
    "start": "1198900",
    "end": "1205200"
  },
  {
    "text": "on this triage idea. So some of my choices again,\nImageNet initialization",
    "start": "1205200",
    "end": "1210539"
  },
  {
    "text": "is going to make your\nlife a happier time. Use bigger batch sizes. And architecture\nchoice doesn't really matter if it's convolutional.",
    "start": "1210540",
    "end": "1217536"
  },
  {
    "text": "And the overall setup that\nwe do through this work and across many\nother projects we're training independently\nper image.",
    "start": "1217536",
    "end": "1223580"
  },
  {
    "text": "Now this is a harder task\nbecause you don't actually have the-- you're not taking any\nof the other view, you're not taking\nprior mammograms.",
    "start": "1223580",
    "end": "1229178"
  },
  {
    "text": "But this is for kind of more\nharder reasons than that. We're going to get the\nprediction for the whole exam by taking the maximum\nacross the different images.",
    "start": "1229178",
    "end": "1236590"
  },
  {
    "text": "So if I say this breast has\ncancer, the exam has cancer. So you should get it checked up.",
    "start": "1236590",
    "end": "1241710"
  },
  {
    "text": "And at each\ndevelopment epoch we're going to evaluate the\nability of the model to do triage task, which\nI'll step into in a second.",
    "start": "1241710",
    "end": "1248263"
  },
  {
    "text": "And we're going to\nkind of take the best model that can do triage. So you're always kind of\nlike, your true end metric",
    "start": "1248263",
    "end": "1254142"
  },
  {
    "text": "is what you're measuring\nduring training. And you're going to\ndo model selection and kind of hyper\npatching based on that.",
    "start": "1254142",
    "end": "1259830"
  },
  {
    "start": "1259000",
    "end": "1259000"
  },
  {
    "text": "And the way we're going\nto do triage and our goal here is to mark as\nmany people as healthy",
    "start": "1259830",
    "end": "1266483"
  },
  {
    "text": "without missing a single\ncancer that we always would have caught. So intuitively kind of\nby taking all the cancers",
    "start": "1266483",
    "end": "1271533"
  },
  {
    "text": "that the radiologist\nwould have caught, what's the probability of cancer\nacross these images, and just take the minimum\nof those and call that",
    "start": "1271533",
    "end": "1277470"
  },
  {
    "text": "the threshold. That's exactly what we do. And another detail\nthat's quite relevant",
    "start": "1277470",
    "end": "1283710"
  },
  {
    "start": "1280000",
    "end": "1280000"
  },
  {
    "text": "often is if you want\nthese models to output a reasonable\nprobability like this is the probability of cancer,\nand you train on a 50/50 sample",
    "start": "1283710",
    "end": "1291320"
  },
  {
    "text": "the batches, by default\nyour model thinks that the average\nincidence is 50%. So it's crazy\nconfidence all the time.",
    "start": "1291320",
    "end": "1297539"
  },
  {
    "text": "So to calibrate that one\nreally simple trick is you do something called Platt's Method\nwhere you basically just fit",
    "start": "1297540",
    "end": "1303120"
  },
  {
    "text": "like a two-parameter sigmoid\nor just scale and a shift to just-- on the development sets\nto make it actually fit the distribution.",
    "start": "1303120",
    "end": "1309098"
  },
  {
    "text": "That way the average\nprobability you would expect to actually fit the incidence. And you don't get this kind\nof like crazy off-kilter",
    "start": "1309098",
    "end": "1315510"
  },
  {
    "text": "probabilities. OK. So analysis. The objectives of what\nwe would try to do here",
    "start": "1315510",
    "end": "1321330"
  },
  {
    "start": "1318000",
    "end": "1318000"
  },
  {
    "text": "is kind of similar\nacross all the projects. One, does this thing work? Two, does this thing work\nacross all the people",
    "start": "1321330",
    "end": "1326610"
  },
  {
    "text": "it's supposed to work for? So we did a subgroup analysis. First we looked at\nthe AUC in this model. So the ability to\ndiscriminate cancer is not.",
    "start": "1326610",
    "end": "1333840"
  },
  {
    "text": "We did it across races. We have across MGH, age\ngroups, and density categories.",
    "start": "1333840",
    "end": "1339065"
  },
  {
    "text": "And finally, how\ndoes this relate to radiologist's assessments? And if we actually\nuse this at test time",
    "start": "1339065",
    "end": "1344809"
  },
  {
    "text": "on the test set, what\nwould have happened? Kind of a simulation before a\nfull clinical implementation.",
    "start": "1344810",
    "end": "1351700"
  },
  {
    "start": "1351000",
    "end": "1351000"
  },
  {
    "text": "So overall AUC here was 82 with\nsome confident from 80 to 85.",
    "start": "1351700",
    "end": "1357159"
  },
  {
    "text": "And we did our analysis by age. We found that the performance\nwas pretty similar across every age group.",
    "start": "1357160",
    "end": "1362440"
  },
  {
    "text": "What's not shown here is\nthe confidence intervals. So for example-- but the\nkind of key core takeaway",
    "start": "1362440",
    "end": "1367720"
  },
  {
    "text": "here is that there\nwas no noticeable gap in terms of by age group.",
    "start": "1367720",
    "end": "1372790"
  },
  {
    "text": "We repeated this\nanalysis by race, and we saw the same trend again. The performance kind of\nranged generally around 82.",
    "start": "1372790",
    "end": "1381000"
  },
  {
    "text": "And in places where\nthe gap was bigger, the just confidence interval\nwas bigger accordingly due",
    "start": "1381000",
    "end": "1386080"
  },
  {
    "text": "to smaller sample sizes,\ncause MGH is 80% white. We saw the exact same\ntrend by density.",
    "start": "1386080",
    "end": "1392290"
  },
  {
    "text": "The outlier here is\nvery dense breasts. But there's only like\n100 of those on test set. So this confidence actually\ngoes from like, 60 to 90.",
    "start": "1392290",
    "end": "1399670"
  },
  {
    "text": "So as far as we know for\nthe other three categories, it is very much tied\nto confidence interval",
    "start": "1399670",
    "end": "1404860"
  },
  {
    "text": "and very similar,\nonce again, around 82. OK. So we have a decent idea\nthat this model seems",
    "start": "1404860",
    "end": "1412570"
  },
  {
    "start": "1409000",
    "end": "1409000"
  },
  {
    "text": "at least with a\npublish of MGH actually serve the relevant\npopulations that",
    "start": "1412570",
    "end": "1418050"
  },
  {
    "text": "exist as far as we know so far. The next question is, how\ndoes the model assessment relate to the\nradiologist's assessment?",
    "start": "1418050",
    "end": "1424030"
  },
  {
    "text": "So to look at that we\nlooked at on the test, if you look at the\nradiologist's true positives, false positives, true\nnegatives, false negatives.",
    "start": "1424030",
    "end": "1431080"
  },
  {
    "text": "Where do they fall within\nthe model distribution of percentile risk? And if there is\nbelow the threshold,",
    "start": "1431080",
    "end": "1436260"
  },
  {
    "text": "we've got to color it in\nthis kind of cyan color. And if it's above\nthe threshold, we're going to color it in\nthis purple color.",
    "start": "1436260",
    "end": "1442480"
  },
  {
    "text": "So this is kind of\ntriage, not triage. The first thing to notice--\nthis is the true positives-- is that there is like a\npretty kind of steep drop-off.",
    "start": "1442480",
    "end": "1451049"
  },
  {
    "text": "And so there is only\none true positive fell below the threshold in\na test set of 26,000 exams.",
    "start": "1451050",
    "end": "1457330"
  },
  {
    "text": "So none of this difference\nwas statistically significant. And the vast majority of them\nare kind of this top 10%.",
    "start": "1457330",
    "end": "1463522"
  },
  {
    "text": "But you kind of see, like,\nthere's a clear trend here that they kind of get piled up\ntowards the higher percentages.",
    "start": "1463522",
    "end": "1469220"
  },
  {
    "text": "Whereas if you look at the\nfalse positive assessments, this trend is much weaker. So you still see that\nthere is some correlation",
    "start": "1469220",
    "end": "1476200"
  },
  {
    "text": "that there's going to more false\npositives the higher amounts, but much less stark. And this actually means\nthat a lot of radiologist's",
    "start": "1476200",
    "end": "1482080"
  },
  {
    "text": "false positives we actually\nplace below the threshold. And so because these assessments\nare completely concordant",
    "start": "1482080",
    "end": "1487390"
  },
  {
    "text": "and we're not just modeling\nwhat the radiologist would have said, we get an\nanticipated benefit of actually reducing the false\npositives significantly because",
    "start": "1487390",
    "end": "1496570"
  },
  {
    "text": "of the weight of disagreeing. And finally, kind of\naiding that further,",
    "start": "1496570",
    "end": "1501830"
  },
  {
    "text": "if you look at the true\nnegative assessments, there is not that much\ntrending between where it falls within this.",
    "start": "1501830",
    "end": "1507370"
  },
  {
    "text": "So it shows that they're kind of\npicking up on different things and they're-- where they\ndisagree gives them both areas",
    "start": "1507370",
    "end": "1514600"
  },
  {
    "text": "to improve and ancillary\nbenefits because now we can reduce false positives.",
    "start": "1514600",
    "end": "1520149"
  },
  {
    "start": "1520000",
    "end": "1520000"
  },
  {
    "text": "This directly leads into\nassimilating the impact. So one of the things we\ndid, we just said, OK. If people retrospective on\nthe test set as a simulation",
    "start": "1520150",
    "end": "1526760"
  },
  {
    "text": "before which truly plug it\nin, if people didn't rebuild the triage threshold-- so\nwe can't catch any more cancer this way, but we can\nreduce false positives--",
    "start": "1526760",
    "end": "1533910"
  },
  {
    "text": "what would have happened? So at the top we have\nthe original performance. So this is looking at\n100% of mammograms,",
    "start": "1533910",
    "end": "1539630"
  },
  {
    "text": "sensitivity was 98.6\nwith specificity of 93. And in the simulation\nthe sensitivity",
    "start": "1539630",
    "end": "1545990"
  },
  {
    "text": "dropped not\nsignificantly to 90.1, but significantly improved\nto 93.7 while looking",
    "start": "1545990",
    "end": "1551900"
  },
  {
    "text": "at 81% of the mammograms. So this is like promising\npreliminary data.",
    "start": "1551900",
    "end": "1557120"
  },
  {
    "text": "But to reevaluate this and\ngo forward, our next step-- let's see if-- oh. I'm going to get to\nthat in a second.",
    "start": "1557120",
    "end": "1562640"
  },
  {
    "text": "Our next step is we need to\ndo clinical implementation to really figure out-- because there's a\ncore assumption here",
    "start": "1562640",
    "end": "1567920"
  },
  {
    "text": "is that people read\nit the same way. But if you have this higher\nincidence, what does that mean? Can you focus more on the\npeople that are more suspicious?",
    "start": "1567920",
    "end": "1575000"
  },
  {
    "text": "And is the right way to do this\njust a single threshold to not read? Or have a double\nended with the seniors",
    "start": "1575000",
    "end": "1580040"
  },
  {
    "text": "cause they're much more\nlikely to have cancer. And so there is quite a bit\nof exploration here to say, given we have these\ntools that give us",
    "start": "1580040",
    "end": "1585832"
  },
  {
    "text": "some probability of\ncancer, that's not perfect, but gives us something. How well can we do that\nto improve care today?",
    "start": "1585832",
    "end": "1591600"
  },
  {
    "text": "So as a quiz, can you tell\nwhich of these will be triaged? So this is no cherry-picking.",
    "start": "1591600",
    "end": "1596630"
  },
  {
    "text": "I randomly picked\nfour mammograms that were below and\nabove the threshold. Can anyone guess which side--",
    "start": "1596630",
    "end": "1602929"
  },
  {
    "text": "left or right-- was triaged? ",
    "start": "1602930",
    "end": "1608192"
  },
  {
    "text": "This is not graded,\nChris, so you know. AUDIENCE: Raise your hand for-- ADAM YALA: Oh yeah. Raise your hand for the left.",
    "start": "1608192",
    "end": "1615450"
  },
  {
    "text": "OK. Raise your hand for right.  Here we go.",
    "start": "1615450",
    "end": "1620980"
  },
  {
    "text": "Well done. Well done. OK. And then next step,\nas I said before, is we need to kind of push to\nthe clinical implementation",
    "start": "1620980",
    "end": "1627120"
  },
  {
    "text": "because that's where the\nrubber hits the road. We identify is there any\nbiases we didn't detect? And we need to say, can\nwe deliver this value?",
    "start": "1627120",
    "end": "1636160"
  },
  {
    "text": "So the next project is on\nassessing breast cancer risk. So this is the same mammogram\nI showed you earlier.",
    "start": "1636160",
    "end": "1642837"
  },
  {
    "text": "It was diagnosed with\nbreast cancer in 2014. It's actually my\nadvisor, Regina's. And you can see that in\n2013 you see it's there.",
    "start": "1642837",
    "end": "1651550"
  },
  {
    "text": "In 2012 it looks\nmuch less prominence. And five years ago, really\nlooking at breast cancer risk.",
    "start": "1651550",
    "end": "1658880"
  },
  {
    "text": "So if you can tell\nfrom an image that is going to be healthy\nfor a long time, you're really trying\nto model what's the likelihood of\nthis breast developing",
    "start": "1658880",
    "end": "1665457"
  },
  {
    "text": "cancer in the future. Now modeling breast cancer\nrisk, as Connie earlier said, is not a new problem.",
    "start": "1665457",
    "end": "1671430"
  },
  {
    "text": "It's been a quite researched\none in the community. And the more classical\napproach that we're gonna look at other\nkind of global health",
    "start": "1671430",
    "end": "1678080"
  },
  {
    "text": "factors-- the person's\nage, their family history, whether or not they've\nhad menopause, and kind of any other of these kind\nof facts we can sort of say",
    "start": "1678080",
    "end": "1685000"
  },
  {
    "text": "are markers of\ntheir health to try to predict whether this person's\nat risk of developing breast cancer. People have thought that\nthe image contains something",
    "start": "1685000",
    "end": "1690820"
  },
  {
    "text": "before. The way they've\nthought about this is through this kind of\nsubjective breast density marker. And the improvements\nseen across this",
    "start": "1690820",
    "end": "1697660"
  },
  {
    "text": "are kind of marginal\nfrom 61 to 63. And as before,\nthe kind of sketch",
    "start": "1697660",
    "end": "1703220"
  },
  {
    "text": "we're going to go through is\ndataset collection, modeling, and analysis. And dataset\ncollection we followed",
    "start": "1703220",
    "end": "1708940"
  },
  {
    "text": "a very similar template. We saw from\nconsecutive mammograms from 2009 to 2012 we took\noutcomes from the EHR,",
    "start": "1708940",
    "end": "1717190"
  },
  {
    "text": "once again, and the\nPartners Registry. We didn't do exclusions based on\nrace or anything of that sort,",
    "start": "1717190",
    "end": "1722260"
  },
  {
    "text": "or implants. But we did exclude\nnegatives for followup. So if someone didn't have\ncancer in three years,",
    "start": "1722260",
    "end": "1727570"
  },
  {
    "text": "but disappeared\nfrom the system, we didn't count them\nas negatives that we have some certainty in both\nthe modeling and the analysis.",
    "start": "1727570",
    "end": "1733550"
  },
  {
    "text": "And as always, we split\npatients into train, dev, test. The modeling is very similar.",
    "start": "1733550",
    "end": "1740420"
  },
  {
    "text": "It's the same kind of templated\nlessons as from triage, except we experimented with a\nmodel that's only the image.",
    "start": "1740420",
    "end": "1747250"
  },
  {
    "text": "And for the sake of analysis,\na model that's the image model I just talked to you\nbefore concatenated with those traditional risk\nfactors at the last layer",
    "start": "1747250",
    "end": "1754315"
  },
  {
    "text": "and trained jointly. That make sense for everyone? So I'm going to call that\nImageOnly an Image+RF",
    "start": "1754315",
    "end": "1759340"
  },
  {
    "text": "or hybrid. OK. Cool? Our kind of goals\nfor the analysis.",
    "start": "1759340",
    "end": "1764350"
  },
  {
    "text": "As before, we want to\nsee does this model actually serve the\nwhole population? Is it going to be discriminative\nacross race, menopause status,",
    "start": "1764350",
    "end": "1772330"
  },
  {
    "text": "the family history? And how does it relate to kind\nof classical portions of risk? And are we actually\ndoing any better?",
    "start": "1772330",
    "end": "1778380"
  },
  {
    "text": "And so just diving\ndirectly into that, assuming there's no questions. Good. Just to kind of remind you,\nthis is the kind of the setting.",
    "start": "1778380",
    "end": "1785280"
  },
  {
    "text": "One thing I forgot to mention--\nthat's why I had the slide here to remind me-- is that we excluded\ncancers from the first year",
    "start": "1785280",
    "end": "1790690"
  },
  {
    "text": "from the test set. So there is truly a negative\nscreening population. That way we kind of\ndisentangle cancer detection",
    "start": "1790690",
    "end": "1796030"
  },
  {
    "text": "from cancer risk. OK. Cool. So Tyrer-Cuzick is the kind of\nprior state-of-the-art model.",
    "start": "1796030",
    "end": "1802470"
  },
  {
    "text": "It's a model based\nout of the UK. Their developer is\nsomeone named Sir Cuzick,",
    "start": "1802470",
    "end": "1808558"
  },
  {
    "text": "who was knighted for this work. It's very commonly used. So that one had an AUC of 62. Our image-only model\nhad an AUC about 68.",
    "start": "1808558",
    "end": "1816940"
  },
  {
    "text": "And hybrid one had an AUC of 70. So you know, what is\nthis kind of AUC thing gives you when you look\nusing a risk model.",
    "start": "1816940",
    "end": "1822429"
  },
  {
    "text": "What it gives you is the\nability to build better high-risk and low-risk cohorts. So in terms of looking\nat high-risk cohorts,",
    "start": "1822430",
    "end": "1827713"
  },
  {
    "text": "our best model place about\n30% of all the cancers in the population\nin the top 10%,",
    "start": "1827713",
    "end": "1832840"
  },
  {
    "text": "and 3% of all the\ncancers in the bottom 10% compared to 18 and 5 to\nthe prior state of the art.",
    "start": "1832840",
    "end": "1839422"
  },
  {
    "text": "And so what this\nenables you to do, if you're going to\nsay that this 10% should actually\nqualify for MRI, you can start fighting this\nproblem of majority",
    "start": "1839422",
    "end": "1846102"
  },
  {
    "text": "of people that get\ncancer don't have MRI, and the majority of people\nthat get it don't need it. It's all about, is your\nrisk model actually",
    "start": "1846102",
    "end": "1852730"
  },
  {
    "text": "place the right people\ninto the right buckets. Now we saw that this trend of\noutperforming the prior state",
    "start": "1852730",
    "end": "1858460"
  },
  {
    "text": "of the art held across races. And one of the things that\nwas kind of astonishing was that though Tyrer-Cuzick\nperformed on white women, which",
    "start": "1858460",
    "end": "1864580"
  },
  {
    "text": "makes sense because\nit was developed only using white women in the UK. It was worse than\nrandom [INAUDIBLE] for African-American women.",
    "start": "1864580",
    "end": "1870490"
  },
  {
    "text": "And so this kind of\nemphasizes the importance of this kind of\nanalysis to make sure that the kind of\ndata that you have",
    "start": "1870490",
    "end": "1876580"
  },
  {
    "text": "is reflective of the population\nthat you're trying to serve and actually doing the\nanalysis accordingly. So we saw that our model\nkind of held across races",
    "start": "1876580",
    "end": "1885030"
  },
  {
    "text": "and as well across--\nwe see this trend from across\npre-postmenopausal and with and without family history.",
    "start": "1885030",
    "end": "1892238"
  },
  {
    "text": "One thing we did in terms of\na more granular comparison of performance, if\nwe just look at kind of like the risk thirds for\nour model and the Tyrer-Cuzick",
    "start": "1892238",
    "end": "1899860"
  },
  {
    "text": "model, what's the\ntrend that you see or the cases where kind\nof like which one is right that's kind of ambiguous.",
    "start": "1899860",
    "end": "1906568"
  },
  {
    "text": "And what I should\nshow in these boxes is the cancer incidence\nprevalence in the population. So the darker the box,\nthe higher the incidence.",
    "start": "1906568",
    "end": "1913792"
  },
  {
    "text": "And on the right-hand\nside are just random images from cases\nthat fit within those boxes. Does that make\nsense for everyone?",
    "start": "1913792",
    "end": "1920230"
  },
  {
    "text": "Great. So a clear trend that you\nsee is that, for example, if TCv8 calls you a high\nrisk but we call it low,",
    "start": "1920230",
    "end": "1928260"
  },
  {
    "text": "that is a lower incidence\nthan if we called it medium and they call it low. So kind of like you kind of\nsee this straight column-wise",
    "start": "1928260",
    "end": "1935700"
  },
  {
    "text": "pattern showing that\ndiscrimination truly does follow the deep learning model\nand not the classical approach.",
    "start": "1935700",
    "end": "1941232"
  },
  {
    "text": "And by looking at the\nrandom images that were selected in case\nwhere we disagree, it supports the notion\nthat it's not just",
    "start": "1941233",
    "end": "1946680"
  },
  {
    "text": "that the column is just\nthe most dense, crazy, dense looking breast, that\nthere's something more subtle it's picking up that's actually\nindicative of breast cancer",
    "start": "1946680",
    "end": "1952688"
  },
  {
    "text": "risk. Kind of a very\nsimilar analysis we looked at as if we look at just\nby a traditional breast density",
    "start": "1952688",
    "end": "1959180"
  },
  {
    "text": "as labeled by the original\nradiologist on the development set or on the test\nset, we end up",
    "start": "1959180",
    "end": "1964640"
  },
  {
    "text": "seeing the same trend where\nif someone is non-dense we call them high risk. They're much higher\nrisk than someone that is dense than\nwe call low risk.",
    "start": "1964640",
    "end": "1970930"
  },
  {
    "text": " And as before, the\nkind of real next step here to make this truly valuable\nand truly useful is actually",
    "start": "1970930",
    "end": "1979930"
  },
  {
    "text": "implementing a clinically\nseamless prospectively and with more centers and\nkind of more population to see does this work and does it\ndeliver the kind of benefits",
    "start": "1979930",
    "end": "1987310"
  },
  {
    "text": "that we care about. And viewing what is\nthe leverage of change once you know that\nsomeone is high risk? Perhaps MRI, perhaps\nmore frequent screening.",
    "start": "1987310",
    "end": "1994000"
  },
  {
    "text": "And so this is the kind\nof gap between having a useful technology\non the paper side to an actual useful\ntechnology in real life.",
    "start": "1994000",
    "end": "2001360"
  },
  {
    "text": "So I am moving on schedule. So now I'm gonna talk\nabout how to mess up. And it's actually\nquite interesting.",
    "start": "2001360",
    "end": "2007760"
  },
  {
    "text": "There is like, so many ways. And I fall into them a few\ntimes myself, and it happens.",
    "start": "2007760",
    "end": "2013175"
  },
  {
    "text": "And kind of\nfollowing the sketch, you can mess up in\ndataset collection. That's probably the\nmost common by far. You can mess up in modeling,\nwhich I'm doing right now.",
    "start": "2013175",
    "end": "2019990"
  },
  {
    "text": "And it's very sad. And you can mess up in analysis,\nwhich is really preventable. So in dataset collection,\nenriched data sets",
    "start": "2019990",
    "end": "2027120"
  },
  {
    "text": "are the kind of the most common\nthing you see in this space. You find in a public\ndata set that's most likely going to be like\n50-50 cancer, not cancer.",
    "start": "2027120",
    "end": "2034140"
  },
  {
    "text": "And oftentimes these\ndatasets collect can have some sort of\nbias within the way",
    "start": "2034140",
    "end": "2039250"
  },
  {
    "text": "it was collected. So it might be that you have\nnegative cases from less centers than you\nhave positive cases.",
    "start": "2039250",
    "end": "2045940"
  },
  {
    "text": "Or they're collected\nfrom different years. And actually, this\nis something we ran into earlier in our own work. Once upon a time,\nConnie and I were",
    "start": "2045940",
    "end": "2052000"
  },
  {
    "text": "in Shanghai for the opening\nof a cancer center there. And at that time we had all the\ncancers from the MGH dataset,",
    "start": "2052000",
    "end": "2059000"
  },
  {
    "text": "about 2,000. But the mammograms were still\nbeing collected annually from 2012-- from 2009.",
    "start": "2059000",
    "end": "2065110"
  },
  {
    "text": "So at that time, we only had,\nlike, half of the negatives by year, but all of the cancers.",
    "start": "2065110",
    "end": "2070333"
  },
  {
    "text": "And all of a sudden\nI had to-- you know, I came from the slightly\nmore complicated model, as one often does. I looked at several\nimages at the same time.",
    "start": "2070333",
    "end": "2076683"
  },
  {
    "text": "And my AUC went up to like, 95. And I had all this, like,\nbouncing off the wall. And then in-- you know, I\nhad some suspicion of like,",
    "start": "2076683",
    "end": "2082917"
  },
  {
    "text": "wait a second. This is too high. This is too good. And we completely realized\nthat all these numbers",
    "start": "2082917",
    "end": "2088780"
  },
  {
    "text": "were kind of a myth. But this level of-- kind of if you do these\nkind of case control things,",
    "start": "2088780",
    "end": "2094060"
  },
  {
    "text": "you can oftentimes,\nunless you're very careful about the\nway it was constructed, you could easily run\ninto these issues.",
    "start": "2094060",
    "end": "2100212"
  },
  {
    "text": "And your testing set won't\nprotect you from that. And so having a clean\ndataset that truly",
    "start": "2100212",
    "end": "2105369"
  },
  {
    "text": "follows the kind of spectrum\nwe expect to use it in-- i.e., a natural\ndistribution, collected",
    "start": "2105370",
    "end": "2110480"
  },
  {
    "text": "through routine clinical\ncare is important to say will it behave as we\nactually want it to be used.",
    "start": "2110480",
    "end": "2116530"
  },
  {
    "text": "In general, the only-- some of this you can think\nthrough in first principle. But it kind of\nstresses the importance",
    "start": "2116530",
    "end": "2121630"
  },
  {
    "text": "of actually testing\nthis prospectively in external validation to try to\nsee does this work when I take",
    "start": "2121630",
    "end": "2126820"
  },
  {
    "text": "away some of the\nbiases in my dataset, and being really\ncareful about that. The common approach\nof just controlling",
    "start": "2126820",
    "end": "2132175"
  },
  {
    "text": "by age or by density\nis not enough when the model can catch\nreally fine-grained signals. ",
    "start": "2132175",
    "end": "2138455"
  },
  {
    "text": "How to mess up in modeling. So there's been adventures\nin this space as well. One of the things I've\nrecently discovered",
    "start": "2138455",
    "end": "2143690"
  },
  {
    "text": "is that the actual\nmammography machine device that the\nmachine was captured on-- so you saw a\nbunch of mammograms",
    "start": "2143690",
    "end": "2149865"
  },
  {
    "text": "probably from\ndifferent machines-- has an unexpected\nimpact on the model. So the actual probability\ndistribution--",
    "start": "2149865",
    "end": "2156790"
  },
  {
    "text": "the distribution of cancer\nprobabilities by the model is not independent\nof the device. That's something we're\ngoing through now.",
    "start": "2156790",
    "end": "2162740"
  },
  {
    "text": "We actually ran into\nthis while working on clinical implementation\nis like this kind of conditional adversarial\ntraining set up",
    "start": "2162740",
    "end": "2167960"
  },
  {
    "text": "to try to rectify this issue. It's important. So this is much harder to\ncatch based on first principle.",
    "start": "2167960",
    "end": "2173955"
  },
  {
    "text": "But it's important to think\nthrough as you kind of really start demoing out\nyour computations. This will kind of-- these\nissues pop up easily,",
    "start": "2173955",
    "end": "2180800"
  },
  {
    "text": "and they're harder to avoid. And lastly, and I\nthink probably one that's probably\nthe most important",
    "start": "2180800",
    "end": "2188120"
  },
  {
    "text": "is messing up in analysis. So it's quite common\nin the previous section in this field--",
    "start": "2188120",
    "end": "2193310"
  },
  {
    "text": "yes. AUDIENCE: With the\nadversarial up there, just to understand what you\ndo, do you that discriminate",
    "start": "2193310",
    "end": "2198810"
  },
  {
    "text": "or predict the machine? And then you train against that? ADAM YALA: So my answer\nis going to be two parts.",
    "start": "2198810",
    "end": "2205590"
  },
  {
    "text": "One, it doesn't work as\nwell as I want it to yet. So really who knows? But my best hunch\nin terms of what's",
    "start": "2205590",
    "end": "2212000"
  },
  {
    "text": "been done before for other\nkind of work, specifically in radio signals, is they use\na conditional adversarial. So you're free to discriminate\nat both the label and the image",
    "start": "2212000",
    "end": "2219437"
  },
  {
    "text": "presentation. You have to try to\npredict out the device to try to take away the\ninformation that's not just contained within the\nlabel distribution.",
    "start": "2219437",
    "end": "2226250"
  },
  {
    "text": "And that's been shown to be very\nhelpful for people trying to do [INAUDIBLE] detection\nbased off on Wi-Fi--",
    "start": "2226250",
    "end": "2232539"
  },
  {
    "text": "or not Wi-Fi-- but\nlike, radio waves. And the [INAUDIBLE]\nbut also, it seems to be the most common approach\nI've seen in literature.",
    "start": "2232540",
    "end": "2238440"
  },
  {
    "text": "So it's something that\nI'm going to try soon. I haven't implemented it. It was just GPU time\nand kind of waiting to queue up the experiment.",
    "start": "2238440",
    "end": "2245750"
  },
  {
    "text": "And the last part in\nterms of how to mess up is this kind of analysis. One thing that's\ncommon is people",
    "start": "2245750",
    "end": "2251600"
  },
  {
    "start": "2250000",
    "end": "2250000"
  },
  {
    "text": "assume that's it kind of\nlike synthetic experiments or the same thing as\nclinical implementation. Like, people do reader\nstudies very often.",
    "start": "2251600",
    "end": "2257330"
  },
  {
    "text": "And it's quite common\nto see that when you do reader studies that\nit doesn't actually-- like, you might find that\ncomputer detection does a huge difference\nin reader studies.",
    "start": "2257330",
    "end": "2263980"
  },
  {
    "text": "And it's-- Connie actual showed\nit was harmful in real life. And it's important to kind\nof like, do these real world",
    "start": "2263980",
    "end": "2270015"
  },
  {
    "text": "experiments that we can\nsay what is happening and just them the real\nbenefit that I expected. And a hopefully less\ncommon nowadays mistake",
    "start": "2270015",
    "end": "2278270"
  },
  {
    "text": "is that oftentimes people\nexclude all inconvenient cases. So there was a paper\nyesterday that just came out",
    "start": "2278270",
    "end": "2283760"
  },
  {
    "text": "that the cancer detection used a\nkind of patched-up architecture which would read more\nclosely into their details,",
    "start": "2283760",
    "end": "2288860"
  },
  {
    "text": "they excluded all\nwomen with breasts that they considered too\nsmall by some threshold for like modeling convenience.",
    "start": "2288860",
    "end": "2294260"
  },
  {
    "text": "But that might\ndisproportionately affect specifically Asian\nwomen in that population.",
    "start": "2294260",
    "end": "2299680"
  },
  {
    "text": "And so they didn't do\na subgroup analysis for all the different\nraces, so it's hard to know what\nis happening there.",
    "start": "2299680",
    "end": "2304920"
  },
  {
    "text": "If your population\nis mostly white, which it is at MGH, and\nis at a lot of the centers that these colleges\nhave developed,",
    "start": "2304920",
    "end": "2310450"
  },
  {
    "text": "are reporting the\naverage that you see isn't enough to\nreally validate that. And so you can have things\nlike Tyrer-Cuzick model that are worse than random\nand especially harmful",
    "start": "2310450",
    "end": "2317450"
  },
  {
    "text": "for African-American women. And so guarding\nagainst that is you can do a lot of that\nbased on first principle.",
    "start": "2317450",
    "end": "2323299"
  },
  {
    "text": "But some of these things\nyou can only really find out by actively monitoring to say,\nis there any subpopulation",
    "start": "2323300",
    "end": "2328430"
  },
  {
    "text": "that I didn't think about a\npriority that could be harmed? And finally, so I talked\nabout clinical deployments.",
    "start": "2328430",
    "end": "2334160"
  },
  {
    "start": "2334000",
    "end": "2334000"
  },
  {
    "text": "We've actually done\nthis a couple times. And I'm going to switch\nover to Connie real soon. In general, what\nyou want to do is",
    "start": "2334160",
    "end": "2341480"
  },
  {
    "text": "you want to make it as easy\nas plausible and possible for the in-house IT\nteam to use your tool.",
    "start": "2341480",
    "end": "2348980"
  },
  {
    "text": "We've gone through this with-- not like-- I don't--\ndepends on how you count. It's like once for density\nand then like three times",
    "start": "2348980",
    "end": "2354470"
  },
  {
    "text": "at the same time. But I spent, like, many\nhours sitting there. And the broad way that we\nset it up so far is we just",
    "start": "2354470",
    "end": "2361190"
  },
  {
    "text": "have a kind of\ndocker as container to manage a web app\nthat holds the model.",
    "start": "2361190",
    "end": "2366860"
  },
  {
    "text": "This web app has kind of a\nbackup processing toolkit. So the kind of steps that\nall of our deployments follow and I look\nunder unified framework",
    "start": "2366860",
    "end": "2373242"
  },
  {
    "text": "is the IT application\nwould get some images out of the PAC system. It will send it\nover to application.",
    "start": "2373242",
    "end": "2378260"
  },
  {
    "text": "We're going to convert to the\nPNG in the way that we expect, because we kind of encapsulate\nthis functionality.",
    "start": "2378260",
    "end": "2383410"
  },
  {
    "text": "Run for the models, send it\nback, and then write it back to the EHR. One of the things I ran into\nwas that they didn't actually",
    "start": "2383410",
    "end": "2389000"
  },
  {
    "text": "know how to use things like\nHTTP because it's not actually normal within their\ninfrastructure. And so being cognizant that\nsome of these more, like,",
    "start": "2389000",
    "end": "2396619"
  },
  {
    "text": "tech standard things\nlike just HTTP requests and responses and stuff is\nless standard within the inside",
    "start": "2396620",
    "end": "2404390"
  },
  {
    "text": "of their infrastructure\nand kind of looking up how to actually do these\nthings in like C Sharp, or whatever language\nthey have, has been really what's enabled\nus to end block these things",
    "start": "2404390",
    "end": "2411602"
  },
  {
    "text": "and actually plug it in. And that is it for my part. So I'm gonna hand\nit back-- oh, yes. AUDIENCE: So you're writing\nstuff in the IT application",
    "start": "2411602",
    "end": "2419220"
  },
  {
    "text": "in C Sharp to do API requests? ADAM YALA: So\nthey're writing it. I just meet them to tell\nthem how to write it.",
    "start": "2419220",
    "end": "2425900"
  },
  {
    "text": "But yes. So like, in general,\nlike, there's libraries. So like, the entire\nenvironment is in Windows.",
    "start": "2425900",
    "end": "2433200"
  },
  {
    "text": "And Windows has a\nvery poor support for lots of things\nyou would expect it to have a good support for. So there was like,\nif you wanted to send",
    "start": "2433200",
    "end": "2438930"
  },
  {
    "text": "HP requests for like\na multipart form and just put the\nimages in that form, apparently that has bugs in\nit in like, Windows whatever",
    "start": "2438930",
    "end": "2447000"
  },
  {
    "text": "version they use today. And so that vanilla\nversion didn't work. Windows for Docker\nalso has bugs.",
    "start": "2447000",
    "end": "2452369"
  },
  {
    "text": "And I had to set up this kind\nof locking function for them to like, automatically table\nlocks inside the container.",
    "start": "2452370",
    "end": "2457530"
  },
  {
    "text": "And it just doesn't work\nin Windows for Docker. AUDIENCE: [INAUDIBLE] questions\nbecause he is short on time. ADAM YALA: Yeah. So we can get to\nthis at the end.",
    "start": "2457530",
    "end": "2463110"
  },
  {
    "text": "I want to hand off to Connie. If you have any\nquestions, grab me after. ",
    "start": "2463110",
    "end": "2474000"
  }
]
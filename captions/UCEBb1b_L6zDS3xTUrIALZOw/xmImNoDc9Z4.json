[
  {
    "start": "0",
    "end": "93000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5340"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5340",
    "end": "11640"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11640",
    "end": "18110"
  },
  {
    "text": "at ocw.mit.edu.  PROFESSOR WILLIAMS: OK,\nso today's lecture--",
    "start": "18110",
    "end": "24370"
  },
  {
    "text": " we're going to be talking about\nprobabilistic planning later,",
    "start": "24370",
    "end": "31380"
  },
  {
    "text": "and in these cases\nwhere you're planning a large state spaces\nis very difficult.",
    "start": "31380",
    "end": "36570"
  },
  {
    "text": "You do the MVP planning. It could be stress that\nactivity planning, or the likes.",
    "start": "36570",
    "end": "41690"
  },
  {
    "text": "But you have to be\nable to figure out how to deal with\nthese state spaces. So Monte Carlo tree searches\nis one of the techniques",
    "start": "41690",
    "end": "48160"
  },
  {
    "text": "that people can identify,\nover last five years, is having an amazing performance\nimprovement over other kinds",
    "start": "48160",
    "end": "54667"
  },
  {
    "text": "of sample-based approaches. So entity is very interesting\nfrom that standpoint. And then if we [? link it to ?]\nthe last lecture,",
    "start": "54667",
    "end": "60844"
  },
  {
    "text": "then the combination\nof something, we just learn about [INAUDIBLE]\nand combine it with search,",
    "start": "60845",
    "end": "67370"
  },
  {
    "text": "is very powerful, in this case,\nthrough the state-of-the-art techniques for that, as much as\ntree search [INAUDIBLE] later",
    "start": "67370",
    "end": "75472"
  },
  {
    "text": "[INAUDIBLE]",
    "start": "75472",
    "end": "80610"
  },
  {
    "text": "PROFESSOR 2: Good\nmorning, everyone. As Professor Williams\njust said, we are going to be talking about\nMonte Carlo tree search today.",
    "start": "80610",
    "end": "86910"
  },
  {
    "text": "My name is Eann\nand I'll be leading the introduction and motivation\nof this presentation.",
    "start": "86910",
    "end": "92310"
  },
  {
    "text": "By the end of this\npresentation, you will know not only why we\ncare about Monte Carlo tree searches.",
    "start": "92310",
    "end": "97390"
  },
  {
    "start": "93000",
    "end": "93000"
  },
  {
    "text": "As Professor Williams said,\nthere's so many algorithms out there. Why do we care about\nthis specific one?",
    "start": "97390",
    "end": "103440"
  },
  {
    "text": "And second, we'll be\ngoing through the pros and cons of MCTS, as well\nas the algorithm itself.",
    "start": "103440",
    "end": "109620"
  },
  {
    "text": "And then lastly, we will\nhave a pretty cool demo on how it's applied to Super\nMario Brothers and the latest",
    "start": "109620",
    "end": "115650"
  },
  {
    "text": "Alpha Go AI that built\nthe second best leading Go",
    "start": "115650",
    "end": "121350"
  },
  {
    "text": "player in the world. So the outline for\ntoday's presentation is, first, we're going to talk\nabout pre-MCTS algorithms.",
    "start": "121350",
    "end": "128220"
  },
  {
    "text": "There are other algorithms\nthat currently exist out there, and just a few of them to lead\ninto why we do care about MCTS",
    "start": "128220",
    "end": "135600"
  },
  {
    "text": "and why these other\nalgorithms fail. And second, we'll talk about\nMonte Carlo tree searches",
    "start": "135600",
    "end": "140849"
  },
  {
    "text": "itself with Yo. And lastly, Nick will tell you\nmore about the applications of Monte Carlo tree searches.",
    "start": "140850",
    "end": "147300"
  },
  {
    "start": "147000",
    "end": "147000"
  },
  {
    "text": "So the motivation of\nthese kind of algorithms is we want to be\nable to play games",
    "start": "147300",
    "end": "153440"
  },
  {
    "text": "and we want to be able to create\nprograms to play these games, but we want to play\nthem optimally. We want to be able\nto win, but we also",
    "start": "153440",
    "end": "160879"
  },
  {
    "text": "want to be able do this in\na reasonable amount of time. So these three can\ntrain itself leads",
    "start": "160880",
    "end": "165965"
  },
  {
    "text": "to different kinds\nof algorithms, and different algorithms\nwith different complexities and time, or times to search.",
    "start": "165965",
    "end": "173420"
  },
  {
    "text": "And so that's why\ntoday we're going to be talking about Monte\nCarlo tree searches. And you'll figure out in a\nfew slides why we do care.",
    "start": "173420",
    "end": "180614"
  },
  {
    "text": "So these are the types\nof games we have. You have this\nchart where there's fully observable games,\npartially observable games,",
    "start": "180614",
    "end": "187940"
  },
  {
    "text": "determinstic, and\ngames of chance. And so today, the games\nthat we care about",
    "start": "187940",
    "end": "193239"
  },
  {
    "text": "are the games that are fully\nobservable and deterministic. And these games are games like\nchess and checkers and Go.",
    "start": "193240",
    "end": "201469"
  },
  {
    "text": "And we'll also be talking\nabout another example with Tic-tac-toe. So these pre-MCTS\nalgorithms include",
    "start": "201470",
    "end": "209280"
  },
  {
    "start": "205000",
    "end": "205000"
  },
  {
    "text": "deterministic, fully observable\ngames, like we said earlier. And the idea of this, and the\nnice thing about these games,",
    "start": "209280",
    "end": "216510"
  },
  {
    "text": "is that they have\nperfect information, and that you have\nall of the states that you need and there's\nno opportunity for chance.",
    "start": "216510",
    "end": "225650"
  },
  {
    "text": "And so the idea is\nthat we can construct a tree that contains\nall possible outcomes because everything\nis fully determined.",
    "start": "225650",
    "end": "232990"
  },
  {
    "text": "And so one of these\nalgorithms, to address this, is the algorithm Minimax, which\nyou might have heard before.",
    "start": "232990",
    "end": "238960"
  },
  {
    "text": "And the idea of\nMinimax to minimize the maximum possible loss. That sounds a little\nweird in the beginning,",
    "start": "238960",
    "end": "244150"
  },
  {
    "start": "244000",
    "end": "244000"
  },
  {
    "text": "but if you take a\nlook at this tree, this red dot, for\nexample, is the computer. And so in the computer's eyes,\nit wants to beat its opponent.",
    "start": "244150",
    "end": "251730"
  },
  {
    "text": "And we're assuming the\nopponent wants to win also, so they're playing\ntheir best game as well.",
    "start": "251730",
    "end": "256815"
  },
  {
    "text": "And so the computer wants to\nmaximize his or her points,",
    "start": "256815",
    "end": "261989"
  },
  {
    "text": "but also knowing that the\nopponent, or the human, wants to maximize\ntheir own win as well.",
    "start": "261990",
    "end": "269870"
  },
  {
    "text": "And so in the\ncomputer's eyes, it wants to minimize the\nmaximum possible lost. Does that make\nsense to everyone?",
    "start": "269870",
    "end": "277038"
  },
  {
    "text": "Yes? OK. And so in the\nexample of Minimax, we're going to start\nwith a connect,",
    "start": "277038",
    "end": "282810"
  },
  {
    "text": "or a Tic-tac-toe board,\nwhere the computer is this board right here, and\nthe blue Tic-tac-toe boards",
    "start": "282810",
    "end": "289230"
  },
  {
    "start": "284000",
    "end": "284000"
  },
  {
    "text": "are the states that the\ncomputer finally chooses. It's anticipating the\nmoves a human could play.",
    "start": "289230",
    "end": "295030"
  },
  {
    "text": " So if you take a\nlook up here, here's the current state of the board.",
    "start": "295030",
    "end": "302292"
  },
  {
    "text": "The current state of the board. And the possible options for the\nhuman are this guy, this guy.",
    "start": "302292",
    "end": "309380"
  },
  {
    "text": "Nope. Possible options\nfor the computer, we have three different options. And so you'll notice that this\nis clearly the obvious winner.",
    "start": "309380",
    "end": "316200"
  },
  {
    "text": "But in the state\nof Minimax, it goes through the entire\ntree, which is different from\ndepth-first search.",
    "start": "316200",
    "end": "321270"
  },
  {
    "text": "It goes through the entire\ntree until it finds the winning move and the minimize of\nthe maximum possible points",
    "start": "321270",
    "end": "330460"
  },
  {
    "text": "it could win. So is there a way we\ncan make this better? Yes. I'm sure you've\nheard about pruning,",
    "start": "330460",
    "end": "336720"
  },
  {
    "text": "where, in our human\nintuition, it makes sense. Well, why don't we\njust stop when we win,",
    "start": "336720",
    "end": "341790"
  },
  {
    "text": "or when we know\nwe're going to have a game that allows us to win?",
    "start": "341790",
    "end": "347116"
  },
  {
    "text": "And so this idea is the\nidea of simple pruning. And so when we combine Minimax\nand simple pruning, we have--",
    "start": "347116",
    "end": "354250"
  },
  {
    "start": "350000",
    "end": "350000"
  },
  {
    "text": "anyone know?  AUDIENCE: Alpha, beta. PROFESSOR 3: Yes.",
    "start": "354250",
    "end": "359278"
  },
  {
    "text": "Our 6.034 head TA\nknows about this. We have alpha-beta pruning,\nwhere we prune away any",
    "start": "359278",
    "end": "365800"
  },
  {
    "start": "364000",
    "end": "364000"
  },
  {
    "text": "branches that cannot\ninfluence the final decision. So in other words, you wouldn't\nkeep exploring the tree",
    "start": "365800",
    "end": "373100"
  },
  {
    "text": "if you already knew that\na previous term would allow you to win. And so this idea in\nalpha-beta pruning,",
    "start": "373100",
    "end": "379630"
  },
  {
    "start": "378000",
    "end": "378000"
  },
  {
    "text": "we have an alpha and a beta. And so the details\naren't important",
    "start": "379630",
    "end": "384740"
  },
  {
    "text": "for you to know right\nnow, but the idea is that we stop whenever\nwe know we don't need to go on any further.",
    "start": "384740",
    "end": "391930"
  },
  {
    "text": "So in the games that\nhave Tic-tac-toe and Connect 4 and chess,\nwe have relatively low",
    "start": "391930",
    "end": "397380"
  },
  {
    "text": "branching factor. So in the case of\nTic-tac-toe, we have 2 to the fourth branching factor.",
    "start": "397380",
    "end": "403720"
  },
  {
    "text": "But what if we have really\nlarge branching factors, like Alpha Go? In Alpha Go, we\nhave 2 to the 250.",
    "start": "403720",
    "end": "410440"
  },
  {
    "text": "Do you see that Mini Max,\nor even alpha-beta pruning, would be an optimal\nalgorithm for this?",
    "start": "410440",
    "end": "417140"
  },
  {
    "text": "The answer is? AUDIENCE: No. PROFESSOR 3: No. And this leads us\nto out next section.",
    "start": "417140",
    "end": "424370"
  },
  {
    "text": "Our goal is going to talk about\nhow we can use the Monte Carlo tree search algorithm for\ngames with really high",
    "start": "424370",
    "end": "431210"
  },
  {
    "text": "branching factors, and using\nthe random extension to allow us to see, ultimately, how Alpha\nGo, which is Google's AI,",
    "start": "431210",
    "end": "441490"
  },
  {
    "text": "was able to beat the leading\nGo player in the world. ",
    "start": "441490",
    "end": "449139"
  },
  {
    "text": "PROFESSOR 3: All right, guys. So this is the part\nwhere we re-explain the algorithm itself.",
    "start": "449140",
    "end": "455410"
  },
  {
    "text": "And before we dive\ninto this, I want to make something\nreally clear, which is that because these\nare technical details",
    "start": "455410",
    "end": "461469"
  },
  {
    "text": "and because we actually\nwant you to understand them, and because I definitely didn't\nunderstand this the first three times I read the paper.",
    "start": "461470",
    "end": "466920"
  },
  {
    "text": "I really want you to feel\nfree to ask any questions on your mind, with the knowledge\nthat, in my experience,",
    "start": "466920",
    "end": "473590"
  },
  {
    "text": "it is very rare that someone\nasks a question in class that's [INAUDIBLE] OK, so really,\nwhenever you have one.",
    "start": "473590",
    "end": "480350"
  },
  {
    "text": "OK. So why are we doing this? Well, the ideal\ngoal behind MTCS is",
    "start": "480350",
    "end": "486860"
  },
  {
    "start": "484000",
    "end": "484000"
  },
  {
    "text": "that we want to\nselectively build up different parts of the tree. So the depth-first search\nway, the exhaustive search,",
    "start": "486860",
    "end": "496630"
  },
  {
    "text": "would have us exploring\nthe entire koopa tree, and that our depth\nis limited by looking at all the possible\nnodes of that level.",
    "start": "496630",
    "end": "503630"
  },
  {
    "text": "But what we want is we want-- because the amount of\ncomputation required for that explodes really quickly.",
    "start": "503630",
    "end": "510080"
  },
  {
    "text": "With the number of moves\nthat you're basically looking into the\nfuture, we wanted to be able to search selectively\nin certain parts of the tree.",
    "start": "510080",
    "end": "517495"
  },
  {
    "text": "And so for example, if there are\nless promising parts over here, then we care less about looking\ninto the future of those areas.",
    "start": "517495",
    "end": "524290"
  },
  {
    "text": "But if we have a certain move-- in chess, for example,\nthere's a certain move where in two moves, you're\ngoing to be able to take",
    "start": "524290",
    "end": "529670"
  },
  {
    "text": "the opponent's queen. You're really want\nto search that region and figure out\nwhether that's going to end up being a significantly\npositive group for me.",
    "start": "529670",
    "end": "538130"
  },
  {
    "text": "And so the whole\ngoal of our algorithm is going to be growing\nthis asymmetric tree. How does that sound?",
    "start": "538130",
    "end": "543810"
  },
  {
    "text": " OK, great. So how do we actually do this?",
    "start": "543810",
    "end": "551210"
  },
  {
    "start": "549000",
    "end": "549000"
  },
  {
    "text": "We're going to go over\na high-level outline, but before we do\nthat, let's talk about our tree,\nwhich you're going",
    "start": "551210",
    "end": "556399"
  },
  {
    "text": "to get very familiar with.  Can people see that this\nis red and this is blue?",
    "start": "556400",
    "end": "564710"
  },
  {
    "text": "So this is our game state\nwhen we start our game. We can be given a Tic-tac-toe\nboard with a [INAUDIBLE] place,",
    "start": "564710",
    "end": "572569"
  },
  {
    "text": "a game of chess with the lose\nconfigured a certain way. And so our player,\nwhich is the computer,",
    "start": "572570",
    "end": "578420"
  },
  {
    "text": "has three separate\nmoves that it can take. And so each of those moves\nare presented by a node.",
    "start": "578420",
    "end": "583560"
  },
  {
    "text": "And each of those moves have\nresponse moves by the opponent. So you can imagine\nthat if one of these",
    "start": "583560",
    "end": "590870"
  },
  {
    "text": "is a Tic-tac-toe board with\njust a circle, that one of these is with that circle and\nthe next place right by it.",
    "start": "590870",
    "end": "597440"
  },
  {
    "text": "And as you go down\nthe this tree, you start understanding\nbasically,",
    "start": "597440",
    "end": "602839"
  },
  {
    "text": "it's the way that humans think\nabout playing these games. If I go here, then\nwhat if they go there,",
    "start": "602840",
    "end": "610160"
  },
  {
    "text": "and then what if\nI go right here. You try to think through\nthe set of future moves and try to evaluate\nwhether your move will",
    "start": "610160",
    "end": "617930"
  },
  {
    "text": "be good in the long term sense. They way that are going to\nexpand our tree, as we said,",
    "start": "617930",
    "end": "623090"
  },
  {
    "text": "to create an asymmetric\ntree is first of all, we're going to descend\nthrough the tree.",
    "start": "623090",
    "end": "628130"
  },
  {
    "text": "We're going to start at the\ntop and we're basically, jump down some sequence of\nbranches until we figure out",
    "start": "628130",
    "end": "634560"
  },
  {
    "text": "where we're going to place\nour new node, which seems like a key operation here.",
    "start": "634560",
    "end": "639920"
  },
  {
    "text": "To create an asymmetric\ntree it's all about how you [INAUDIBLE]. For example, in this\ncase, we're going",
    "start": "639920",
    "end": "645290"
  },
  {
    "text": "to pick this sequence of nodes. And once we get to the bottom\nand find every location,",
    "start": "645290",
    "end": "651596"
  },
  {
    "text": "we're going to\ncreate a new node. It's not very hard. Then we're going to simulate\na game from this new node.",
    "start": "651596",
    "end": "659690"
  },
  {
    "text": "And this is the\nkey part of MCTS. Once you get to new\na location, what",
    "start": "659690",
    "end": "666296"
  },
  {
    "text": "you're going to\nbe doing then, is you're going to be simulating\na game from that new location. We're going to\ntalk about how you",
    "start": "666296",
    "end": "671840"
  },
  {
    "text": "go about simulating a game from\nthis more advanced game state",
    "start": "671840",
    "end": "677300"
  },
  {
    "text": "that what we started out with. Does anyone have any\nquestions right now? We will be going in depth\ninto all of these steps,",
    "start": "677300",
    "end": "683040"
  },
  {
    "text": "but just in a high level sense. AUDIENCE: Just a quick question. PROFESSOR 3: Yeah. AUDIENCE: To create\nthe new node, is it probabilistic, just\ncreating a new node as the most",
    "start": "683040",
    "end": "689616"
  },
  {
    "text": "probable [INAUDIBLE] PROFESSOR 3: No, no. You're creating some new node. We'll talk about how\nwe pick that new node, but we're just making a new node\nand we're not thinking anything",
    "start": "689617",
    "end": "696806"
  },
  {
    "text": "about probability. The next thing is that we're\ngoing to update the tree. So whatever the value of\nthe simulation delta was--",
    "start": "696806",
    "end": "703195"
  },
  {
    "text": "delta, remember-- we're going to\npropagate that up and basically",
    "start": "703195",
    "end": "710360"
  },
  {
    "text": "add that to all\nof the nodes that are in that parent of\nthat node in the tree and update some information\nthat goes in there",
    "start": "710360",
    "end": "716332"
  },
  {
    "text": "and that they're storing. This is going to be good because\nit's going to mean that-- it's a lot like in\nsearch algorithms where",
    "start": "716332",
    "end": "722975"
  },
  {
    "text": "you have trees that then\nthe entirety of the tree remains up to date with the\ninformation from every given simulation.",
    "start": "722975",
    "end": "728642"
  },
  {
    "text": "And we're just\ngoing to repeat this over and over and over again. And slowly, our\ntree will grow out until whenever we\nfeel like stopping.",
    "start": "728642",
    "end": "735946"
  },
  {
    "text": "This is actually one\nof the nice things about MCTS, is that whenever\nwe decide that we're out",
    "start": "735946",
    "end": "742220"
  },
  {
    "text": "of time, like for example, if\nyou're in a competition playing a champion Go player, you\ncan stop the simulation.",
    "start": "742220",
    "end": "749060"
  },
  {
    "text": "And then all you\nhave to do is pick between one of the\nbest first moves",
    "start": "749060",
    "end": "754220"
  },
  {
    "text": "that you're going to make. Because an the end of\nthe day, after you're doing all the simulation,\nwe're still right here.",
    "start": "754220",
    "end": "761010"
  },
  {
    "text": "And we're still only picking\nbetween the movies that go immediately where we started. Yeah.",
    "start": "761010",
    "end": "767259"
  },
  {
    "text": "AUDIENCE: Could this\n[INAUDIBLE] good tree? And then on some initial\nregion of interest,",
    "start": "767260",
    "end": "772290"
  },
  {
    "text": "or is it arbitrary how\nyou get to create it? PROFESSOR 3: We'll go\nthrough how you pick",
    "start": "772290",
    "end": "777900"
  },
  {
    "text": "where to descend right now. I guess, it's any\npossible move that starts",
    "start": "777900",
    "end": "784029"
  },
  {
    "text": "at your starting game state. Does that make-- great.",
    "start": "784030",
    "end": "790480"
  },
  {
    "text": "Before we move on to\nthe algorithm itself, let's talk about what we store\nin each one of these nodes.",
    "start": "790480",
    "end": "797360"
  },
  {
    "start": "797000",
    "end": "797000"
  },
  {
    "text": "So now we've added\nthese numbers. And these numbers\nrepresent is that nk,",
    "start": "797360",
    "end": "802510"
  },
  {
    "text": "as in the value of the\nright, is the number of games that have been played that\ninvolve a certain node.",
    "start": "802510",
    "end": "808500"
  },
  {
    "text": "So for example, if\nI look this node, that means that\nfour games have been played that involve this node.",
    "start": "808500",
    "end": "814737"
  },
  {
    "text": "A game that has been played\nthat involves the node just means that\none of the states of the board at some\npoint in the game",
    "start": "814737",
    "end": "820940"
  },
  {
    "text": "was the state of the board\nthat this represents. For example, if I have a\ngame that was played here,",
    "start": "820940",
    "end": "828399"
  },
  {
    "text": "if I know that I've\nplayed this once, then that guarantees\nto me that I played this game\nonce because this is a precursor state to this one.",
    "start": "828400",
    "end": "835444"
  },
  {
    "text": "Make sense? Yeah. AUDIENCE: How can the two\nn's below that node not",
    "start": "835444",
    "end": "840734"
  },
  {
    "text": "add up to a value of [INAUDIBLE] PROFESSOR 3: That will come when\nwe start expanding our game.",
    "start": "840734",
    "end": "845960"
  },
  {
    "text": "But that's a great question. And intuitively\nspeaking, it should. AUDIENCE: You're saying you're\nstoring data from past games",
    "start": "845960",
    "end": "852940"
  },
  {
    "text": "about what we've-- PROFESSOR 3: Yes. AUDIENCE: --done before. AUDIENCE: If past game's outside\nof the script simulation?",
    "start": "852940",
    "end": "858360"
  },
  {
    "text": "PROFESSOR 3: No, no, no. Past game's in the\nscript simulation. And then the other\nvalue is the number",
    "start": "858360",
    "end": "863589"
  },
  {
    "text": "of wins associated\nwith a certain node. And these are going to be\nwins for player one, which",
    "start": "863590",
    "end": "868890"
  },
  {
    "text": "is red in this case. It would get confusing\nif we put both of them, but they're complementary.",
    "start": "868890",
    "end": "874120"
  },
  {
    "text": "So for example, three\nout of the four times that the red player visited this\nnode, they won in that node.",
    "start": "874120",
    "end": "882317"
  },
  {
    "text": "And these are the two numbers\nthat we're going to store. And we're going\nto see why they're significant to store later.",
    "start": "882317",
    "end": "888759"
  },
  {
    "text": "So first, descending the\nkey part of our algorithm that we're talking about. And when descending,\nthere are these two",
    "start": "888760",
    "end": "895899"
  },
  {
    "text": "counterbalanced\ndesires that we have. The first of them is that\nwe want to explore really",
    "start": "895900",
    "end": "903670"
  },
  {
    "text": "deeply into our tree. We want to think about, OK, if\nthey do this then I'll do this. And then, well, then I'll do\nthat unless I want it to forth.",
    "start": "903670",
    "end": "911427"
  },
  {
    "text": "And we want to think through\na long term strategy. But at the same time, we don't\nwant to get caught in that.",
    "start": "911427",
    "end": "916870"
  },
  {
    "text": "We want to make\nsure that we're not missing a really promising\nother movie that we weren't even",
    "start": "916870",
    "end": "922750"
  },
  {
    "text": "considering because we\nwere really going down this certain rabbit\nhole of the move that we had thought\nabout before.",
    "start": "922750",
    "end": "928839"
  },
  {
    "text": "This is illustrated by the\nx case [INAUDIBLE] SMBC. The SMBC comic about academia\nand how someone tells you",
    "start": "928840",
    "end": "937222"
  },
  {
    "text": "that a lot of really\ngreat work has been done in an area,\nthat means nothing about how promising\nthe future will be.",
    "start": "937222",
    "end": "944082"
  },
  {
    "text": "It's all about expansion\nand exploration. And the way that we're\ngoing to balance expansion and exploration\nin order to create",
    "start": "944082",
    "end": "949520"
  },
  {
    "text": "our really nice asymmetric\ntree is the following formula. And it's fine if that looks\nreally confusing and messy.",
    "start": "949520",
    "end": "957610"
  },
  {
    "text": "But actually, it breaks down\nquite nicely into two parts.",
    "start": "957610",
    "end": "963220"
  },
  {
    "text": "This formula is\nknown as the UCB. You don't need to know why it's\nthe Upper Confidence Bound. Let's just talk about\nwhat's inside it.",
    "start": "963220",
    "end": "969230"
  },
  {
    "text": "So first of all, you have\nthis term on the left. And this term on the left\nis the extension term.",
    "start": "969231",
    "end": "974589"
  },
  {
    "text": "It's basically proportional\nto the likelihood that the expected number of\ntimes that you're going to win,",
    "start": "974590",
    "end": "981050"
  },
  {
    "text": "given that you are\nin a certain node and that you were\na certain player. ",
    "start": "981050",
    "end": "987334"
  },
  {
    "text": "It's basically the\nquality of your state in some abstract level. If we knew this\nperfectly, then we would be doing\ngreat because that's",
    "start": "987334",
    "end": "993760"
  },
  {
    "text": "the thing we're looking for on\nsome grand level, The expected likelihood of winning\nfrom a certain state.",
    "start": "993760",
    "end": "999910"
  },
  {
    "text": "On the other hand, you\nhave this exploration term. And you may not be able\nto read the font there. But what this is\nbasically saying",
    "start": "999910",
    "end": "1005700"
  },
  {
    "text": "is that it looks at\nthe number of games that I have been played through,\nand it was the number of games",
    "start": "1005700",
    "end": "1014580"
  },
  {
    "text": "that my parent has\nbeen played through. And it tries to preserve those\nnumbers at a certain ratio,",
    "start": "1014580",
    "end": "1020459"
  },
  {
    "text": "at a log ratio. And what that effectively means,\nis that the number of times",
    "start": "1020460",
    "end": "1026849"
  },
  {
    "text": "that I have been-- if I have been visited\nrelatively few times, and the denominator is small.",
    "start": "1026849",
    "end": "1034179"
  },
  {
    "text": "Whereas my parent has been\nvisited many times, which means that my siblings have\ngotten much more attention, then the likelihood that I\nwill be visited again actually",
    "start": "1034180",
    "end": "1043140"
  },
  {
    "text": "increases. So this is biased\non the one hand, towards nodes that\nare really promising,",
    "start": "1043140",
    "end": "1049450"
  },
  {
    "text": "and on the other\nhand, towards nodes that haven't been explored\nyet, where there's a gold mine",
    "start": "1049450",
    "end": "1054663"
  },
  {
    "text": "and all you need to do is dig\na little bit, potentially.  We don't actually have an\nanalytical expression for this.",
    "start": "1054663",
    "end": "1062300"
  },
  {
    "text": "But we can approximate\nit because you can think that the expected\nvalue from a certain node",
    "start": "1062300",
    "end": "1068150"
  },
  {
    "start": "1065000",
    "end": "1065000"
  },
  {
    "text": "is, roughly speaking,\napproximately the ratio of wins at that node to\nthe ratio of times",
    "start": "1068150",
    "end": "1074080"
  },
  {
    "text": "that that node has\nbeen visit at all. ",
    "start": "1074080",
    "end": "1079559"
  },
  {
    "text": "Let's talk about actually\napplying this statement. Because what the statement\nis going to give you, is it's going to give you some number\nfor here and some number",
    "start": "1079560",
    "end": "1086789"
  },
  {
    "text": "here, and some number\nfor here, and so on. When we start descending\nthrough the tree, we're going to start\nat the top node.",
    "start": "1086790",
    "end": "1092830"
  },
  {
    "text": "And then we're going\nto look at the three children of that node. And we're going to\ncompute this UCB",
    "start": "1092830",
    "end": "1099290"
  },
  {
    "text": "value for each of\nthese children and pick whichever one is the highest. So just as a thought\nfor a moment,",
    "start": "1099290",
    "end": "1107650"
  },
  {
    "text": "what if we ignore this one? And what if we're just\ncomputing the UCB of these two? Does anyone have any intuition\non whether the UCB would",
    "start": "1107650",
    "end": "1115890"
  },
  {
    "text": "be higher for this\nnode or for this node? AUDIENCE: The left node. PROFESSOR 3: The left node?",
    "start": "1115890",
    "end": "1122170"
  },
  {
    "text": "OK. So why is that? AUDIENCE: It has\na win [INAUDIBLE] PROFESSOR 3: Yeah.",
    "start": "1122170",
    "end": "1127210"
  },
  {
    "text": "It has a win. AUDIENCE: And they both\nhave a [INAUDIBLE].. PROFESSOR 3: Exactly. And so clearly, you think the\nexploration term is the same",
    "start": "1127210",
    "end": "1133540"
  },
  {
    "text": "because you know it's not that\none child has been loved less than the other, but\nthe expansion term is going to be different.",
    "start": "1133540",
    "end": "1139403"
  },
  {
    "text": "And so it's definitely\ngoing to pick this one. In this case, what\nwe're going to say is actually that this is so much\nmore promising than the others",
    "start": "1139404",
    "end": "1145475"
  },
  {
    "text": "that it's actually going\nto pick this left node. And so it's going to expand,\nand it's going to look down. And then when it\nlooks down, it's",
    "start": "1145475",
    "end": "1151665"
  },
  {
    "text": "going to compare\nbetween these two. And this time, remember,\nthat this is a parent.",
    "start": "1151665",
    "end": "1157290"
  },
  {
    "text": "A parent want to minimize the\nnumber of wins that we have.",
    "start": "1157290",
    "end": "1162590"
  },
  {
    "text": "Which means that our\nopponent is going to want to pick the one that\nwere less likely to win in",
    "start": "1162590",
    "end": "1169980"
  },
  {
    "text": "and they're more\nlikely to win in. This is the idea of\nmini-max, minimizing how well my enemy does in this game.",
    "start": "1169980",
    "end": "1176519"
  },
  {
    "text": " Although again,\nthe expiration term",
    "start": "1176520",
    "end": "1181909"
  },
  {
    "text": "might counterbalance it a little\nbit because, technically, this has been explored more.",
    "start": "1181910",
    "end": "1188024"
  },
  {
    "text": "We're going to pick the\none on the left again. And we're going to\nget to that location that we got to originally.",
    "start": "1188024",
    "end": "1194480"
  },
  {
    "text": "Now when we're comparing\nbetween these two, between a node that\nhas been visited once",
    "start": "1194480",
    "end": "1199896"
  },
  {
    "text": "and a node that has\nnever been visited, can anyone guess which one\nof these it is going to pick?",
    "start": "1199896",
    "end": "1206121"
  },
  {
    "text": "Yeah. AUDIENCE: Never\nhas been visited. PROFESSOR 3: Yeah, exactly. Because this number is zero.",
    "start": "1206121",
    "end": "1211690"
  },
  {
    "text": "And so if the\nparent has ever been visited but the node hasn't,\nthis is going to be infinite and it's going to have to pick\nthe node that it has never",
    "start": "1211690",
    "end": "1218909"
  },
  {
    "text": "seen before. So that's how we descend\nthrough the tree. Does anyone have any\nquestions on that. Really, it's totally fine.",
    "start": "1218909",
    "end": "1225070"
  },
  {
    "text": "We're going to be talking\nabout this for a while. Yeah. AUDIENCE: With the left node\nthat has the four for n sub k,",
    "start": "1225070",
    "end": "1231287"
  },
  {
    "text": "wouldn't that be three because\nthere's two and one below?",
    "start": "1231287",
    "end": "1236344"
  },
  {
    "text": "PROFESSOR 3: No\nbecause of the way that we're going to\nbe updating the tree. Next, we'll talk about\nsome [INAUDIBLE]..",
    "start": "1236344",
    "end": "1241490"
  },
  {
    "text": "AUDIENCE: I like the concept. But if it's a deterministic\ngame, why couldn't it hold it's [INAUDIBLE]\npretty strictly?",
    "start": "1241490",
    "end": "1246498"
  },
  {
    "text": "PROFESSOR 3: That's\na great question. That's really up to\ncomputer memory limits. As I think that Leah\nmentioned, the number of stakes",
    "start": "1246499",
    "end": "1254279"
  },
  {
    "text": "in the game of Go-- it's a 19 by 19 board,\nand you can play something at every state. It's only like 2 to the--",
    "start": "1254280",
    "end": "1260150"
  },
  {
    "text": "PROFESSOR 2: [INAUDIBLE] PROFESSOR 3: What? PROFESSOR 2: 250. PROFESSOR 3: 250. You could never explore\nthe entire search tree.",
    "start": "1260150",
    "end": "1267000"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]\nover the first few layers or are we going polite.",
    "start": "1267000",
    "end": "1272010"
  },
  {
    "text": "We try to do this real\ntime where you could have done something offline. PROFESSOR 3: It's\ndefinitely true.",
    "start": "1272010",
    "end": "1277330"
  },
  {
    "text": "If you know a state\nthat you're going to arrive at ahead of time,\nthen you can totally do that. But in a game\nthat's large enough",
    "start": "1277330",
    "end": "1282419"
  },
  {
    "text": "that to do that for\nall the possible states would take that much more time\nand take that much more memory.",
    "start": "1282420",
    "end": "1289050"
  },
  {
    "text": "It doesn't end up\nmaking that much sense. Also, something\nto point out here, is that for most of the games\nthat we're talking about,",
    "start": "1289050",
    "end": "1294841"
  },
  {
    "text": "simulating a run through\nof the game is really fast. So if you think about it--",
    "start": "1294841",
    "end": "1300460"
  },
  {
    "text": "let's actually get to\nthat in next piece. But the point is\nthat building up this many levels of\na tree for a computer",
    "start": "1300460",
    "end": "1306885"
  },
  {
    "text": "takes probably on the order\nof less than millisecond. So doing this for a\nreally, really huge tree,",
    "start": "1306885",
    "end": "1315410"
  },
  {
    "text": "it's peanuts because their\nsuch simple operations. But it won't get expensive\nwhen we start building up",
    "start": "1315410",
    "end": "1320670"
  },
  {
    "text": "the tree to serious depths. AUDIENCE: But a game like Go,\nhow many nodes would you have?",
    "start": "1320670",
    "end": "1328425"
  },
  {
    "text": "PROFESSOR 3: On each\nlevel, in the beginning, we have something on\nthe order of 400 nodes. And we have a depth\nof about, I think",
    "start": "1328425",
    "end": "1334580"
  },
  {
    "text": "most games have up to 250\nsteps, or something like that. AUDIENCE: So just to build,\nif you go in there blank,",
    "start": "1334580",
    "end": "1339750"
  },
  {
    "text": "without any nodes built,\nyou have to in the computer, like you said, it\nhasn't visited a node, it has to go there before\nit descends further.",
    "start": "1339750",
    "end": "1346450"
  },
  {
    "text": "Basically, like breadth first. PROFESSOR 3: It's sort of like\nbreadth first but not quite. There's an important\ndistinction here,",
    "start": "1346450",
    "end": "1351823"
  },
  {
    "text": "which is that it doesn't have\nto build up this or this node.",
    "start": "1351823",
    "end": "1357387"
  },
  {
    "text": "It doesn't have to build\nup all of the nodes at a certain level. All it has to do is, if it\nbranches down to a certain sub",
    "start": "1357387",
    "end": "1364970"
  },
  {
    "text": "region, then can't\ndescend in that sub region below one of its siblings\nwithout having at least looked",
    "start": "1364970",
    "end": "1371160"
  },
  {
    "text": "once at all its siblings. After it looks once it\ncan do whatever it wants. And the point is,\nthat it doesn't",
    "start": "1371160",
    "end": "1377129"
  },
  {
    "text": "mean the tree has to be\nkept at an even level. All it means is that\nthe tree, in order",
    "start": "1377130",
    "end": "1382550"
  },
  {
    "text": "to descend on a specific\npart of the tree, it has to have at least visited\ndirect neighbors once before.",
    "start": "1382551",
    "end": "1390220"
  },
  {
    "text": "Any more questions\non this before-- Yeah. AUDIENCE: What's the\nadvantage necessarily of having to visit every single?",
    "start": "1390220",
    "end": "1396778"
  },
  {
    "start": "1396779",
    "end": "1401821"
  },
  {
    "text": "PROFESSOR 3: The\nadvantage of having to visit every single--\nthe way that I think of it, is that you don't\nwant to be missing out",
    "start": "1401821",
    "end": "1408470"
  },
  {
    "text": "on potentially being interested\nin some of the things and not others.",
    "start": "1408470",
    "end": "1415380"
  },
  {
    "text": "It comes back to the exploration\nversus expectation distinction.",
    "start": "1415380",
    "end": "1421690"
  },
  {
    "text": "We do want to descend into\nthe region of the tree that is really valuable to us.",
    "start": "1421690",
    "end": "1427200"
  },
  {
    "text": "But at least have\nexplored a little bit, at least maintaining\nsome baseline, which really isn't\nthat costly compared",
    "start": "1427200",
    "end": "1433820"
  },
  {
    "text": "to the size of the tree. 400 moves is not that bad\ncompared with 400 and 250.",
    "start": "1433820",
    "end": "1439444"
  },
  {
    "text": "AUDIENCE: Are these\nsimulations, they're just random simulations? PROFESSOR 3: We're going to\ntalk about that in a minute. Any more questions\nbefore I move onto that?",
    "start": "1439444",
    "end": "1445626"
  },
  {
    "text": " Next step is expanding. And this is very simple.",
    "start": "1445626",
    "end": "1451280"
  },
  {
    "start": "1449000",
    "end": "1449000"
  },
  {
    "text": "You just create a node and you\nset the two initial values. And the initial\nvalues are the number",
    "start": "1451280",
    "end": "1457160"
  },
  {
    "text": "of times it's been\nvisited is zero, and then number of times that\nsomeone has won from there is zero. AUDIENCE: [INAUDIBLE] So\nthe easy part is solving it.",
    "start": "1457160",
    "end": "1465020"
  },
  {
    "text": "PROFESSOR 3: Now, simulating. Simulating is really hard. You can imagine that if\nyou get to a single node",
    "start": "1465020",
    "end": "1471470"
  },
  {
    "text": "and you've never seen\nthat node before, and you don't know what to\ndo from this node onward, that if we knew how the\ngame was going to play out,",
    "start": "1471470",
    "end": "1479484"
  },
  {
    "text": "that is exactly what\nwere searching for, and we would be done. But we don't. And in fact, we have no idea\nhow to go about simulating",
    "start": "1479484",
    "end": "1487769"
  },
  {
    "text": "a realistic game,\nand a game that will tell us something\nmeaningful about the quality of a certain state.",
    "start": "1487770",
    "end": "1493410"
  },
  {
    "text": "And so, as you\ncorrectly guessed, we're going to do it randomly.",
    "start": "1493410",
    "end": "1498560"
  },
  {
    "text": "We're going to be\nat a certain state. And then from that\nstate, we're just going to pick random nodes\nfor each of the players",
    "start": "1498560",
    "end": "1504529"
  },
  {
    "text": "until the game ends. And if we, as player one, win\nthen we're going to add one.",
    "start": "1504530",
    "end": "1511990"
  },
  {
    "text": "Then we're going to say\ndelta equals plus one. And if we don't win,\nor if we tie or lose,",
    "start": "1511990",
    "end": "1518140"
  },
  {
    "text": "then we're going\nto call it a zero. You can in this graph, we're\ndescending randomly and not thinking about it.",
    "start": "1518140",
    "end": "1523510"
  },
  {
    "text": "And it turns out that\nthis is actually great because it's really, really\ncomputationally efficient.",
    "start": "1523510",
    "end": "1528570"
  },
  {
    "text": "If you have a board, even\nif it has 400 open squares, populating it by a\nbunch of random moves",
    "start": "1528570",
    "end": "1533809"
  },
  {
    "text": "doesn't take you very\nlong, on the order of not that many machine can. AUDIENCE: That's why\ndoes you don't score--",
    "start": "1533810",
    "end": "1540390"
  },
  {
    "text": "if you go down a tree randomly,\nyou already have a simulation. So the node's going\nto get to someplace.",
    "start": "1540390",
    "end": "1546560"
  },
  {
    "text": "But you don't store it because\nit would lose the randomness? PROFESSOR 3: You're totally\nright, actually, in this case.",
    "start": "1546560",
    "end": "1551920"
  },
  {
    "text": "I've thought through this, and\nI can't come up with a reason why you wouldn't\nstore it, that's it's temporary values that you\nfind all the way down the tree.",
    "start": "1551920",
    "end": "1558363"
  },
  {
    "text": "But they don't in most of\nthe literature [INAUDIBLE] But you're totally\nright about that.",
    "start": "1558363",
    "end": "1563574"
  },
  {
    "text": "Does everyone understand\nthat distinction? The fact that we only\nhold onto the result here and don't\ntheoretically make",
    "start": "1563574",
    "end": "1570110"
  },
  {
    "text": "nodes for every place down in\nthe tree just because we could, just because we've\nseen them before. We don't, and it doesn't\nreally matter in this case.",
    "start": "1570110",
    "end": "1577166"
  },
  {
    "text": "But it's theoretically a slight\nspeed up that you could do. AUDIENCE: But you reduce that\nquestion to generalities?",
    "start": "1577166",
    "end": "1582419"
  },
  {
    "text": "PROFESSOR 3: Yeah, a little bit. So we can look at an example of\nsimulating out a running game.",
    "start": "1582420",
    "end": "1589940"
  },
  {
    "text": "We get some intuition for\nwhy a random game would be correlated with how good\nyour board position is.",
    "start": "1589940",
    "end": "1595760"
  },
  {
    "text": "For example, here we\nhave a Detecto game. Circle is going to move next. But as hopefully you can\nsee, because you have played",
    "start": "1595760",
    "end": "1602539"
  },
  {
    "text": "Detecto before, this is not a\nparticularly promising board for x.",
    "start": "1602540",
    "end": "1607990"
  },
  {
    "text": "Because no matter\nwhat circle does, if x is an intelligent\nplayer x can win right now.",
    "start": "1607990",
    "end": "1614802"
  },
  {
    "text": "It has two different\noptions for winning. And so, if you simulated this\nforward randomly, what you'll get is that 2/3 of the\ntime, x will in fact win,",
    "start": "1614802",
    "end": "1621856"
  },
  {
    "text": "even if the players\naren't really thinking of it ahead of time. Yeah. AUDIENCE: Then why\nnot do n simulations",
    "start": "1621856",
    "end": "1627170"
  },
  {
    "text": "at a node instead of\njust a single simulation? PROFESSOR 3: You\ntotally can do that. That's in fact, something\nthat make sense to do",
    "start": "1627170",
    "end": "1632470"
  },
  {
    "text": "and that some people do. Although what you'll\nfind somewhat soon, is that considering that\nwe're going down the tree,",
    "start": "1632470",
    "end": "1638780"
  },
  {
    "text": "and that sometimes\nsoon we're going to explore all of\nits children, there's a good question of why\nyou end simulations now",
    "start": "1638780",
    "end": "1644930"
  },
  {
    "text": "when you could just descend\nthrough the tree n times and thereby do n simulations\nby going through the thing",
    "start": "1644930",
    "end": "1651029"
  },
  {
    "text": "and also building\nout the children? This case is-- yeah. AUDIENCE: This gives\nmore importance",
    "start": "1651030",
    "end": "1657360"
  },
  {
    "text": "to why you do randomness. Because if you're doing\nrandom simulations you would ignore the\npossibility of the best one.",
    "start": "1657360",
    "end": "1662695"
  },
  {
    "text": "When you first ran a simulation\nhere was that o wins. If I ignore this node-- PROFESSOR 3: Absolutely.",
    "start": "1662696",
    "end": "1668230"
  },
  {
    "text": "Which is why it matters that we\ndo this so many times that we drown out all the noise that\nis associated with playing",
    "start": "1668230",
    "end": "1675515"
  },
  {
    "text": "a game out randomly. Let's talk about that. If there's a lot of distance\nbetween where we are right now",
    "start": "1675515",
    "end": "1682010"
  },
  {
    "start": "1678000",
    "end": "1678000"
  },
  {
    "text": "and our end result-- For example, in\nthis game, if I were to tell you how good is this\nboard position, if you are one",
    "start": "1682010",
    "end": "1688522"
  },
  {
    "text": "of those people who played\nout every game of Detecto, you'll know that this is\ngreat if you want it to be [INAUDIBLE]",
    "start": "1688522",
    "end": "1695660"
  },
  {
    "text": "Anyway, the point\nis, that is not easy to do if you are doing\nrandom simulations from where you start.",
    "start": "1695660",
    "end": "1701730"
  },
  {
    "text": "The correlation between\nyour friend's board state and the quality of that state\nactually drops precipitously.",
    "start": "1701730",
    "end": "1707989"
  },
  {
    "text": "And this for me is one\nof the hardest parts to study about Monte\nCarlo Tree Search. Although, as Nick\nwill explain to you,",
    "start": "1707989",
    "end": "1713889"
  },
  {
    "text": "it actually works quite well. And one of the reasons that it\nworks quite well in practice for more complicated\napplications",
    "start": "1713890",
    "end": "1720215"
  },
  {
    "text": "is they do away\nwith the assumption of random simulation. Because even the\nrandom simulations does allow you to explore\nall the states, if you have",
    "start": "1720215",
    "end": "1727240"
  },
  {
    "text": "some idea of where a reasonable\nquality approach would be, then using that, as long as it's\nnot that much more expensive",
    "start": "1727240",
    "end": "1734510"
  },
  {
    "text": "computationally, can help\nyou with your simulation. Right now we're still talking\nabout total randomness. How are people doing\nwith that idea?",
    "start": "1734510",
    "end": "1740640"
  },
  {
    "text": " Now we're going to update\nthe tree with the results",
    "start": "1740640",
    "end": "1746330"
  },
  {
    "start": "1746000",
    "end": "1746000"
  },
  {
    "text": "of our simulation. So given that we had\nsome result lambda, we're going to try to\nget up the parents.",
    "start": "1746330",
    "end": "1752140"
  },
  {
    "text": "And for each parent\nwe're going to add that the game has been\nplayed there once, and that the result\nof that simulation",
    "start": "1752140",
    "end": "1760790"
  },
  {
    "text": "gets added if it was a one. So for example, if there\nwas a win in this game,",
    "start": "1760790",
    "end": "1767299"
  },
  {
    "text": "than this becomes one, one\nbecause now it's won once and it's been visited once. And these two get\nincremented by one,",
    "start": "1767300",
    "end": "1774629"
  },
  {
    "text": "and these two get\nincremented by one. That in itself comprises\na complete iteration,",
    "start": "1774630",
    "end": "1781060"
  },
  {
    "text": "the complete single iteration\nof running Monte Carlo Tree Search, which means that\nnow we can keep doing this",
    "start": "1781060",
    "end": "1789950"
  },
  {
    "text": "over and over again,\nbuilding up the tree and slowly making it\ndeeper, and making it deeper",
    "start": "1789950",
    "end": "1795350"
  },
  {
    "text": "in selective areas. And having these numbers\nincrease and increase. And be more and\nmore proportional",
    "start": "1795350",
    "end": "1801080"
  },
  {
    "text": "to the actual expected value\nof the quality of the state, until-- does anyone have any\nquestions about this idea?--",
    "start": "1801080",
    "end": "1808226"
  },
  {
    "text": " until we terminate. And we have to come up\nwith a way to terminate it.",
    "start": "1808226",
    "end": "1815040"
  },
  {
    "start": "1811000",
    "end": "1811000"
  },
  {
    "text": "Now again, we said we're going\nto pick what the best child is going to be, what the best\nimmediate move from the start",
    "start": "1815040",
    "end": "1821850"
  },
  {
    "text": "state is going to be. That's the move that were\nactually going to play. And so, how do we\ndetermine what the best is?",
    "start": "1821850",
    "end": "1829010"
  },
  {
    "text": "Well, the trivial solution\nis just the highest expected win given k.",
    "start": "1829010",
    "end": "1836790"
  },
  {
    "text": "What that, in our\ncase, is going to be is the ratio of number\nof times that I've win from a given early\nstate to the number of times",
    "start": "1836790",
    "end": "1844250"
  },
  {
    "text": "that I visited. However, this doesn't actually\nwork as well as we might hope. Let's suppose the\nfollowing scenario,",
    "start": "1844250",
    "end": "1850530"
  },
  {
    "text": "which is that you have the\nDetecto game like this. And you have been exploring\nthe tree for a while.",
    "start": "1850530",
    "end": "1857220"
  },
  {
    "text": "And you're really mostly\nlooking at these two nodes. One of these nodes, if\nyou think it through,",
    "start": "1857220",
    "end": "1864390"
  },
  {
    "text": "this node is quite\npromising and you've been exploring it for a while. There is a winning\nstrategy from this node. It's that circle goes\nhere, and then x goes here,",
    "start": "1864390",
    "end": "1871260"
  },
  {
    "text": "and then circle loses because\nx has two options to win. ",
    "start": "1871260",
    "end": "1876694"
  },
  {
    "text": "However, if you explore\nthis a bunch of times, and for some reason,\ndue to the randomness, this is at 11 out of 20.",
    "start": "1876694",
    "end": "1881970"
  },
  {
    "text": "Whereas this state, which\nis inherently inferior, is at three out of five because\nof a bunch of randomness",
    "start": "1881970",
    "end": "1888020"
  },
  {
    "text": "and because it hasn't\nbeen explored as much. And if we had looked at\nthis one as exhaustively we had at this one,\nthat you probably",
    "start": "1888020",
    "end": "1895631"
  },
  {
    "text": "would actually say that this\nstate is actually better. And so, you can create\nan alternative criteria,",
    "start": "1895631",
    "end": "1900900"
  },
  {
    "text": "which is that it's the\nhighest expected win value of one of the children.",
    "start": "1900900",
    "end": "1906060"
  },
  {
    "text": "But also, that value\nhas to be the node that has been most visited\nso that they aren't",
    "start": "1906060",
    "end": "1911310"
  },
  {
    "text": "explored by different amounts. What this sacrifice\nis however, is that this means that we\ncan't terminate on demand.",
    "start": "1911310",
    "end": "1921049"
  },
  {
    "text": "This is not always\ngoing to be true, and therefore, we're going\nto have to let the algorithm run until that's true for\nsome start state, which",
    "start": "1921050",
    "end": "1927362"
  },
  {
    "text": "means that maybe is not\na criteria that we want to apply even though we know\nthat it would be wise to do so. Are there any\nquestions about how",
    "start": "1927362",
    "end": "1933260"
  },
  {
    "text": "we pick the terminating guide? ",
    "start": "1933260",
    "end": "1939280"
  },
  {
    "text": "That was the whole thing. And now we're going to do\nit lots and lots of times until you guys are sick of\nMonte Carlo Tree Search.",
    "start": "1939280",
    "end": "1945780"
  },
  {
    "text": "So this our tree. It's more or less\nwhat we've had before. The first thing\nwe're going to do",
    "start": "1945780",
    "end": "1951200"
  },
  {
    "text": "is we're going to\nlook at the top. And then we're going to\npick one of these children. Now let's say that\nwe looked at this,",
    "start": "1951200",
    "end": "1957260"
  },
  {
    "text": "and it turns out that the one\non the left is really valuable. I think it's the one. Nope, yeah. Never mind. It's wrong.",
    "start": "1957260",
    "end": "1962319"
  },
  {
    "text": "The one on the left\nhas been explored a whole bunch of times. Remember, this term\nstarts becoming larger",
    "start": "1962319",
    "end": "1967730"
  },
  {
    "text": "than the ones that haven't\nbeen visited as much. And so we're going to\ndescend from this one.",
    "start": "1967730",
    "end": "1973390"
  },
  {
    "text": "And now we're going to descend,\nand we have these two options. Given what you know,\nwould you expect",
    "start": "1973390",
    "end": "1980612"
  },
  {
    "text": "that this is going\nto pick is going to be the one on the right\nor the one on the left? AUDIENCE: [INAUDIBLE] PROFESSOR 3: On the\nright because it's never",
    "start": "1980612",
    "end": "1986250"
  },
  {
    "text": "been visited before. And so, this term\nis going to explode. And so, we're going\nto build a node there. And then we're going\nto simulate a game.",
    "start": "1986250",
    "end": "1991726"
  },
  {
    "text": "And the result is a win,\nwhich is bad for this player. That means that he probably\ndidn't want to make that move.",
    "start": "1991726",
    "end": "1998370"
  },
  {
    "text": "And so we're going to\npropagate that value up. And we're going to start\nthe algorithm again.",
    "start": "1998370",
    "end": "2004419"
  },
  {
    "text": "And it's going to compare\nbetween these three. And now it's going to\npick the one on the left.",
    "start": "2004420",
    "end": "2011500"
  },
  {
    "text": " Now that it picked\nthe one on the left, it going to compare\nbetween these two states.",
    "start": "2011500",
    "end": "2019420"
  },
  {
    "text": "Which of the two is going to\nhave a higher expansion factor? AUDIENCE: The left.",
    "start": "2019420",
    "end": "2026397"
  },
  {
    "text": "AUDIENCE: Don't you\ninvert it, though, because this is the opponent. PROFESSOR 3: Exactly. Because two out of three\nis actually better.",
    "start": "2026397",
    "end": "2032330"
  },
  {
    "text": "Because it's one out of\nthree for the opponent that's currently\nmaking the move. So the one on the left is going\nto have a higher expansion",
    "start": "2032331",
    "end": "2037440"
  },
  {
    "text": "factor, and the\none on the right is going to have a higher\nexploration factor. Does that make sense for people? It's OK if it doesn't.",
    "start": "2037440",
    "end": "2045114"
  },
  {
    "text": "So we're actually going to\npick the one on the right because the other one was\nis doing three and has lots of it's mother's\nlove than that one's.",
    "start": "2045114",
    "end": "2051993"
  },
  {
    "text": "Anyone else need a drink? We're going to expand that node. It doesn't matter. They are both equally\nlikely to be expanded.",
    "start": "2051994",
    "end": "2058502"
  },
  {
    "text": "We're going to simulate forward,\nand it's going to be one. Which means that that was\nprobably a wise countermove.",
    "start": "2058502",
    "end": "2064638"
  },
  {
    "text": "Yeah. AUDIENCE: So when it's\nthe opponent's turn versus your turn, the\nexploration factor is the same but we complement\nthe expansion factor, right?",
    "start": "2064639",
    "end": "2073562"
  },
  {
    "text": "PROFESSOR 3: Yes. So the key here\nbeing that this takes in both the state that\nyou're talking about",
    "start": "2073562",
    "end": "2079162"
  },
  {
    "text": "and the player that\nyou're talking about. AUDIENCE: But regardless\nof the player, the exploration factor will\nalways be like this is.",
    "start": "2079162",
    "end": "2084570"
  },
  {
    "text": "PROFESSOR 3: Because it's only\nthe number of visits it's. It has nothing to do with\nresults of exploration.",
    "start": "2084570",
    "end": "2089716"
  },
  {
    "text": " AUDIENCE: If you win and\nyou have the plus one,",
    "start": "2089716",
    "end": "2095584"
  },
  {
    "text": "double plus one, and\nyou've propagated out, but I'm wondering-- so if the opponent wins\ndo you also propagate",
    "start": "2095584",
    "end": "2103602"
  },
  {
    "text": "out the win increment itself? If the opponent's\nwinning, wouldn't you",
    "start": "2103602",
    "end": "2109574"
  },
  {
    "text": "want to [INAUDIBLE] node here? PROFESSOR 3: If the\nopponent wins then what you do is you propagate up a zero.",
    "start": "2109574",
    "end": "2114780"
  },
  {
    "text": "Which means that wk is not\nincremented, but nk is.",
    "start": "2114780",
    "end": "2120390"
  },
  {
    "text": " Have we seen a zero yet?",
    "start": "2120390",
    "end": "2126580"
  },
  {
    "text": "There's one soon. But the idea is that rather\nthan subtract or anything,",
    "start": "2126580",
    "end": "2131900"
  },
  {
    "text": "all you do is propagate\nup the result of the game, which in this case is zero.",
    "start": "2131900",
    "end": "2137820"
  },
  {
    "text": "Which means that\nall of those states seems to become more valuable\nto the blue and less valuable to the red.",
    "start": "2137820",
    "end": "2142830"
  },
  {
    "text": "Because these numbers are\nlower than the other ones were. AUDIENCE: OK. ",
    "start": "2142830",
    "end": "2150750"
  },
  {
    "text": "PROFESSOR 3: So we\npropagate this up and this becomes better. What we've done here\nis we've figured out",
    "start": "2150750",
    "end": "2156930"
  },
  {
    "text": "a theoretical countermove\nto blue moving here. That's how you should think\nabout this whole tree.",
    "start": "2156930",
    "end": "2162140"
  },
  {
    "text": "It's really a lot like\nthe way the humans think about these things. If I do this, then\nwhat if they do this?",
    "start": "2162140",
    "end": "2167950"
  },
  {
    "text": "Well, then I'll do this. And I see that I'm\nsuccessful when I do that.",
    "start": "2167950",
    "end": "2174141"
  },
  {
    "text": "We're going to look\nagain at the top. And we're going to pick\nthe one on the left because it's really promising.",
    "start": "2174142",
    "end": "2180015"
  },
  {
    "text": "Five out of six\nis a good number. And we're going to\nlook at both sides. And which one is blue\ngoing to pick now?",
    "start": "2180015",
    "end": "2185571"
  },
  {
    "text": "Well, it's going to\npick the one that it's going to be more successful\nin, which is two out of three. I realize that this is\nactually not the kind of thing",
    "start": "2185571",
    "end": "2191246"
  },
  {
    "text": "where I could\nnecessarily ask people because I'm the one who's\ndecided which node to stop.",
    "start": "2191246",
    "end": "2197680"
  },
  {
    "text": "Then we go down here. And there's an equal\nlikelihood of picking either of those nodes. And so we're going to\npick one at random.",
    "start": "2197680",
    "end": "2204054"
  },
  {
    "text": "So that's going to\nbe the left one. And we're going to\ncreate an empty node. Then we're going to play it out. And it was a success\nfor blue, which",
    "start": "2204054",
    "end": "2210660"
  },
  {
    "text": "is amazing because what this\nmeans now is that suddenly, in this tree of this really\ngood move that red could make",
    "start": "2210660",
    "end": "2217180"
  },
  {
    "text": "the blue wasn't find a\nresponse to, suddenly there's hope because we're\ngoing to propagate this back.",
    "start": "2217180",
    "end": "2222280"
  },
  {
    "text": "And that means\nthat blue actually has a response move to that\nsequence of red's moves. And so it's going\nto propagate up.",
    "start": "2222280",
    "end": "2228380"
  },
  {
    "text": "And this state's going to be\nmore promising to blue and less promising of red. That region of the tree\nthat we had dug into",
    "start": "2228380",
    "end": "2234230"
  },
  {
    "text": "is a little less promising. We're going to look back up. And this time,\ninstead, we're going",
    "start": "2234230",
    "end": "2239788"
  },
  {
    "text": "to evaluate the thing\nthat is both promising from the expansion\nfactor, and also",
    "start": "2239788",
    "end": "2245910"
  },
  {
    "text": "promising because\nwe haven't looked at it very much [INAUDIBLE]\nexploration factor. We're going to pick\nbetween these two.",
    "start": "2245910",
    "end": "2251513"
  },
  {
    "text": "Which one is going\nto be picked here? AUDIENCE: [INAUDIBLE]",
    "start": "2251513",
    "end": "2257392"
  },
  {
    "text": "PROFESSOR 3: Because the\nexploration factor is the same but the expansion factor is\nhigher for the one on the left.",
    "start": "2257392",
    "end": "2264080"
  },
  {
    "text": "And it's going to\nshow us a node. And the result is going to\nbe a win for a red, which means that red has found a good\ncountermove to the thing that",
    "start": "2264080",
    "end": "2271190"
  },
  {
    "text": "was previously\npromising for blue. And we propagate it back up. And finally, we're going to pick\nthe one furthest on the right.",
    "start": "2271190",
    "end": "2277610"
  },
  {
    "text": "Because even though\nit's terrible for red, and even though it's never\nwon when it's tried it, it has to obey his idea\nof the exploration mode",
    "start": "2277610",
    "end": "2284285"
  },
  {
    "text": "to find out whether maybe there\nisn't something possible there. So it explores,\nand it goes down, and it has to pick\nthe one on the right.",
    "start": "2284285",
    "end": "2290870"
  },
  {
    "text": "And so it does. And it plays this game out. And it's a loss, again.",
    "start": "2290870",
    "end": "2296180"
  },
  {
    "text": "Which goes to show\nyou, that blue has found yet\nanother superior move to this really bad\nmove of red, where",
    "start": "2296180",
    "end": "2302569"
  },
  {
    "text": "probably this move of red,\nif this is a game of chess, is like putting\nmy queen directly in front of the\nopponent's row of pawns,",
    "start": "2302570",
    "end": "2307926"
  },
  {
    "text": "and I just leave it there. There's nothing good that's\never going to come of it but we have to explore\nit just to find out",
    "start": "2307926",
    "end": "2313070"
  },
  {
    "text": "whether there isn't some magical\nway that I should protect. And as you can see,\nwe've built up this tree",
    "start": "2313070",
    "end": "2319250"
  },
  {
    "text": "over and over and over again. And it's starting\nto look asymmetric. And we're starting to\nsee that there's really this disparity between exploring\nthe regions that are crossing",
    "start": "2319250",
    "end": "2327170"
  },
  {
    "text": "this tree and exploring\nthe regions that are not and that don't really\nmatter to us very much.",
    "start": "2327170",
    "end": "2332500"
  },
  {
    "text": "And that this is exactly what we\nwanted from Monte Carlo trees. That was why we started\nthe whole endeavor",
    "start": "2332500",
    "end": "2338474"
  },
  {
    "text": "in the first place. The next thing I'm going to\ntalk about is the pros and cons. But before I do\nthat, does anyone",
    "start": "2338475",
    "end": "2343905"
  },
  {
    "text": "have any more questions\nabout the algorithm? Yeah. AUDIENCE: It's still not\nclear how we're getting nodes",
    "start": "2343905",
    "end": "2349966"
  },
  {
    "text": "with different denominators-- [INAUDIBLE] PROFESSOR 3: The reason for\nthat is because of the way",
    "start": "2349966",
    "end": "2356011"
  },
  {
    "text": "that we're simulating through. We're actually not holding\nonto to the results of the simulation as we're\ngoing farther down the tree",
    "start": "2356011",
    "end": "2363130"
  },
  {
    "text": "than the lowest node we expand. For example, when you\nsimulate from here, you're going to propagate that\nvalue here and here, and so on.",
    "start": "2363130",
    "end": "2371030"
  },
  {
    "text": "But then when we\nexpand below, even if in the course of\nthis guy's simulation it happened to go\nthrough one of the states",
    "start": "2371030",
    "end": "2376300"
  },
  {
    "text": "that we expanded\nbelow, it will not have incremented the\nvalues of that state because we weren't\nkeeping track of it.",
    "start": "2376300",
    "end": "2382836"
  },
  {
    "text": "Theoretically, if\nwe were to keep track of all of the simulations\nthat we have in fact run, the numbers beneath these\nthings would be higher.",
    "start": "2382836",
    "end": "2391480"
  },
  {
    "text": "AUDIENCE: If you've already\nrun a simulation from that-- if you've already\nrun a simulation from that red node when\nyou first built it,",
    "start": "2391480",
    "end": "2398080"
  },
  {
    "text": "and then when you created those\ntwo ones, each of those have [INAUDIBLE]",
    "start": "2398080",
    "end": "2403156"
  },
  {
    "text": "PROFESSOR 3: OK. I see. AUDIENCE: So would\nthe denominator always be one more than the\nsum of the children? PROFESSOR 3: Yeah,\nin [INAUDIBLE] Yeah.",
    "start": "2403156",
    "end": "2410960"
  },
  {
    "text": " AUDIENCE: I understand\nhow you built that. ",
    "start": "2410960",
    "end": "2418304"
  },
  {
    "text": "Is there a rule of thumb, like\nit's time to choose a move? And it seems like you\nhave very low numbers here to make a [INAUDIBLE]",
    "start": "2418304",
    "end": "2425079"
  },
  {
    "text": "Is there a rule of\nthumb on giving games like it's 2 to the 4 or 2\nto the 350, whatever it is. What kind of numbers do\nyou need for that first row",
    "start": "2425080",
    "end": "2432335"
  },
  {
    "text": "before you [INAUDIBLE]? PROFESSOR 3: What we'll get\nto soon is that isn't one.",
    "start": "2432335",
    "end": "2438010"
  },
  {
    "text": "That's one of the\nproblem with MCTS. But in terms of which of\nthe moves you will choose,",
    "start": "2438010",
    "end": "2444210"
  },
  {
    "text": "there are actually variants of\nMCTS that suggest that you more selectively age or\ninsert new children based",
    "start": "2444210",
    "end": "2451480"
  },
  {
    "text": "on something more than just\nthe blind look right now. In terms of, if I'm here and\nit's creating my next children",
    "start": "2451480",
    "end": "2460319"
  },
  {
    "text": "as the equivalent, then there\nare some intelligent guesses that you can make in\nterms of which one you should score first.",
    "start": "2460320",
    "end": "2465673"
  },
  {
    "text": "Although it doesn't\nparticularly matter. AUDIENCE: I'm just\nsaying computational time being what it is,\nyou might say, OK,",
    "start": "2465674",
    "end": "2471400"
  },
  {
    "text": "if this is the timeline\nof this game I can expect to do a million simulations,\nwhich will give me if there's 400 nodes, I'm\ngoing to have so much use.",
    "start": "2471400",
    "end": "2478440"
  },
  {
    "text": "In other words, is\nthat enough time to say that I can\nplay through a game? I couldn't play through\na game with 400 options",
    "start": "2478440",
    "end": "2484920"
  },
  {
    "text": "if I've gotten five out\nof seven [INAUDIBLE] three out of four [INAUDIBLE] PROFESSOR 3: Absolutely. And I would say that\nso far as I know,",
    "start": "2484920",
    "end": "2490810"
  },
  {
    "text": "that's something\nthat's basically very high experimentally. They don't have\ngood balance on it. [INAUDIBLE] So let's get on\nthe first comment",
    "start": "2490810",
    "end": "2497020"
  },
  {
    "text": "because that is a\ncomputer element. So why should you\nuse this algorithm? Even though we've seen\ntremendous breakthroughs",
    "start": "2497020",
    "end": "2503920"
  },
  {
    "start": "2499000",
    "end": "2499000"
  },
  {
    "text": "in this algorithm,\nand you're going to have to ignore\neverything that I tell you and remember that\nthis does actually",
    "start": "2503920",
    "end": "2509020"
  },
  {
    "text": "work quite well in\ncertain scenarios. Should we use it or not? The pros are that it\nactually does the thing",
    "start": "2509020",
    "end": "2516224"
  },
  {
    "text": "that we want it to do. It grows the tree\nasymmetrically. It means that we do\nnot have to explore. And it doesn't\nexplode exponentially",
    "start": "2516225",
    "end": "2522339"
  },
  {
    "text": "with the number of moves that\nwe're looking into the future. And that it selectively grows\nthe tree towards the areas that",
    "start": "2522340",
    "end": "2528590"
  },
  {
    "text": "are most promising. The other huge\nbenefit, if you'll notice from what we've\njust talked through,",
    "start": "2528590",
    "end": "2535290"
  },
  {
    "text": "is that it never\nrelies on anything other than the strict\nrules of the game. What that means is that the\nonly weight of the game that's",
    "start": "2535290",
    "end": "2541555"
  },
  {
    "text": "factored in is that the\ngame is what tells us what the next moves we can\ntake from a given state are, and whether a given state\nis a victory or a defeat.",
    "start": "2541555",
    "end": "2552310"
  },
  {
    "text": "And that's kind of\namazing because we had no external heuristic\ninformation about this game.",
    "start": "2552310",
    "end": "2557650"
  },
  {
    "text": "Which means that if I\ntook a completely new game that someone had just invented,\nand I plugged MCTS into it,",
    "start": "2557650",
    "end": "2562720"
  },
  {
    "text": "MCTS would be a slightly or\nsomeone competitive player for this game, which\nis a powerful idea.",
    "start": "2562720",
    "end": "2570599"
  },
  {
    "text": "It leads to our next two pros. The first of which is that it's\nvery easy to adapt to new games",
    "start": "2570600",
    "end": "2576220"
  },
  {
    "text": "that it hasn't seen\nbefore, or even that people haven't seen before.",
    "start": "2576220",
    "end": "2582160"
  },
  {
    "text": "This is clearly valuable. But the other nice\nthing about it is that even though\nheuristics are not required to make MCTS\nwork [INAUDIBLE],,",
    "start": "2582160",
    "end": "2591810"
  },
  {
    "text": "it can work [INAUDIBLE]. There are a number\nof [? advanced ?] places in the algorithm\nthat you can actually incorporate heuristics into.",
    "start": "2591810",
    "end": "2597630"
  },
  {
    "text": "Nick is going to talk about how\nAlphaGo uses this very heavily. AlphaGo is not vanilla Go. It has a lot of\nexternal information",
    "start": "2597630",
    "end": "2604270"
  },
  {
    "text": "that's built into the\nway that it works. But MCTS is a framework-- you\ncan imagine your heuristics you",
    "start": "2604270",
    "end": "2609840"
  },
  {
    "text": "can apply in the\nsimulation, there are heuristics you can\napply in the UCB in the way that we choose the next node.",
    "start": "2609841",
    "end": "2615549"
  },
  {
    "text": "There are places\nthat it can fit in. And this services as a nice\ninfrastructure to do so. ",
    "start": "2615550",
    "end": "2621320"
  },
  {
    "text": "The other benefit is that it's\nan on demand algorithm, which is particularly valuable when\nyou're under some sort of time",
    "start": "2621320",
    "end": "2627660"
  },
  {
    "text": "pressure, when you're competing\nagainst someone that's a mathematician, or when\nsomething is about to explode",
    "start": "2627660",
    "end": "2633099"
  },
  {
    "text": "and you have to make a decision\non which reactor to shut down. And lastly-- or not\nlastly, actually, it's",
    "start": "2633100",
    "end": "2640180"
  },
  {
    "text": "complete, which is\nreally nice because you know that if you run\nthis game for long enough it's going to start looking\nat a lot like a BFS tree.",
    "start": "2640180",
    "end": "2648270"
  },
  {
    "text": "No, it's actually\ngoing to start looking like an alpha-beta tree, if\nit is what it is converted to.",
    "start": "2648270",
    "end": "2654820"
  },
  {
    "text": "It's a nice property to have. Although, this\nproperty does slightly get compromised if you\nremove the red in this idea,",
    "start": "2654820",
    "end": "2660595"
  },
  {
    "text": "and if only simulate\nthese [INAUDIBLE].. Yeah. PROFESSOR: You made\nan interesting comment",
    "start": "2660595",
    "end": "2667369"
  },
  {
    "text": "when you said, oh, it\nlooks like -beta tree. So it looked like\na mini-max tree. But have they also\nincorporated notions",
    "start": "2667370",
    "end": "2675190"
  },
  {
    "text": "of pruning in the\nMCTS, which would make it look like an -beta tree? PROFESSOR 3: Sorry,\nyou're completely right.",
    "start": "2675190",
    "end": "2680780"
  },
  {
    "text": "It does look like\na mini-max tree. I think I've seen variants\nwhere they do pruning, but I haven't looked\ninto it as much.",
    "start": "2680780",
    "end": "2686963"
  },
  {
    "text": "But I would imagine\nthat they would converge to whatever\nyou know pruning a certain tree [INAUDIBLE].",
    "start": "2686963",
    "end": "2692020"
  },
  {
    "text": "AUDIENCE: But people have\nexplored incorporating pruning into MCTS? PROFESSOR 3: I think so.",
    "start": "2692020",
    "end": "2697170"
  },
  {
    "text": "I can't say [INAUDIBLE]\nAnd then lastly, it's really parallelizable.",
    "start": "2697170",
    "end": "2702680"
  },
  {
    "text": "You'll notice, none of\nthe regions of this tree, other than the\noriginal choice, ever",
    "start": "2702680",
    "end": "2708005"
  },
  {
    "text": "have to interact\nwith each other. So if you have 200\nprocessors and you decide, OK, I'm going to break up this\ntree in the first 200 decisions",
    "start": "2708005",
    "end": "2715169"
  },
  {
    "text": "and then have each\none of those flesh out one of those decisions, that\nactually means that they can",
    "start": "2715169",
    "end": "2720599"
  },
  {
    "text": "all combine information\nright at the end and make a decision\n[INAUDIBLE],, which is a really nice, powerful\nprinciple as you [INAUDIBLE]..",
    "start": "2720600",
    "end": "2729279"
  },
  {
    "text": "It does have its fair\nshare of problems. The first problem being\nthat it does breakdown",
    "start": "2729280",
    "end": "2734950"
  },
  {
    "text": "under extreme tree depth. The main reason for this\nbeing that as you increase",
    "start": "2734950",
    "end": "2741340"
  },
  {
    "text": "more moves between you\nand the end of the game, you're increasing\nthe probability--",
    "start": "2741340",
    "end": "2747250"
  },
  {
    "text": "you are decreasing the\ncorrelation between your game state and whether a\nrandom playoff would suggest that you're in a good\nposition or a bad position.",
    "start": "2747250",
    "end": "2754750"
  },
  {
    "text": "The same goes for\nbranching factors. One of the things that people\nsometimes talk about it as if MCTS AI's cannot\nplay first-person shooters",
    "start": "2754750",
    "end": "2763930"
  },
  {
    "text": "because the distance between the\nnumber of things that you can do at every given moment, and\nwhat would be a successful",
    "start": "2763930",
    "end": "2771460"
  },
  {
    "text": "approach in the long term\nafter meeting many, many, many moves that each have\nmany branching factors, is that never begins to explore\nthe size of the search tree.",
    "start": "2771460",
    "end": "2780937"
  },
  {
    "text": "For the most part, it's\nnot really coming up with a long term policy. It's really thinking about what\nare the next sequence of moves",
    "start": "2780937",
    "end": "2787735"
  },
  {
    "text": "that I should [INAUDIBLE]. Another problem is\nthat it requires",
    "start": "2787736",
    "end": "2794000"
  },
  {
    "text": "simulation to be very\neasy and very repeatable. So for example, if we\nwanted to tell our AI,",
    "start": "2794000",
    "end": "2802820"
  },
  {
    "text": "how do I take over Ontario? There's not a\nparticularly good way that you can simulate\ntaking over Ontario?",
    "start": "2802820",
    "end": "2809480"
  },
  {
    "text": "If you try it once,\nyou're not going to have an opportunity\nto try it again, at least with the same\nset of configurations.",
    "start": "2809480",
    "end": "2816470"
  },
  {
    "text": "And actually, one of the things\nthat we really took advantage of, if that random simulation\nhappens really quickly, on the order of microseconds.",
    "start": "2816470",
    "end": "2822865"
  },
  {
    "text": "On other hand, the\nbigger your computational resources that you\nhave access to,",
    "start": "2822865",
    "end": "2828910"
  },
  {
    "text": "the better the algorithm works. That means that I can't run it\noff my Mac particularly well. It would be like large games.",
    "start": "2828910",
    "end": "2835670"
  },
  {
    "text": "It relies on this tenuous\nassumption of random play be weakly correlated with the\nquality of our game state.",
    "start": "2835670",
    "end": "2841257"
  },
  {
    "text": "And this is one of the\nfirst assumptions that is going to be thrown out the\nwindow for a lot of the more advanced MCTS approaches,\nwhich are going to have",
    "start": "2841257",
    "end": "2847880"
  },
  {
    "text": "more intelligent play outs. But those are going to\nlose some of the generality that we had before.",
    "start": "2847880",
    "end": "2855380"
  },
  {
    "text": "Something that goes off of that\nis that MCTS is a framework. But in order to actually make\nit effective for a lot of games",
    "start": "2855380",
    "end": "2861260"
  },
  {
    "text": "it does require a lot of\ntuning, in the sense that there are a whole bunch of variants. And that you need to be\nable to implement whatever",
    "start": "2861260",
    "end": "2867140"
  },
  {
    "text": "flavor is best suited for you. Which means that it's not\nquite as nice and black boxy as we would want it to be\nas far as give it the rules",
    "start": "2867140",
    "end": "2874890"
  },
  {
    "text": "and have it magically come up\nwith a strategy [INAUDIBLE].. And then lastly,\nas you mentioned,",
    "start": "2874890",
    "end": "2880160"
  },
  {
    "text": "there is not a great amount\nof literature right now about the properties of\nMCTS and its convergence,",
    "start": "2880160",
    "end": "2886080"
  },
  {
    "text": "and what the actual\nproportion of time to quality of your solution is.",
    "start": "2886080",
    "end": "2891950"
  },
  {
    "text": "This is true of all modern\nmachine learning things, is that there is certainly a lot\nmore work that could be done.",
    "start": "2891950",
    "end": "2898261"
  },
  {
    "text": "But right now,\nthat's a gap in terms of using this for a simulation\nthat's supposed to be reliable.",
    "start": "2898261",
    "end": "2903577"
  },
  {
    "text": "Anyone have any questions\non the Pros and Cons? Before we jump dive\ninto applications,",
    "start": "2903577",
    "end": "2909940"
  },
  {
    "text": "let's talk through\na few examples of what games could be\nsolved and could not be solved by MCTS.",
    "start": "2909940",
    "end": "2916750"
  },
  {
    "text": "Do you guys think that\ncheckers is a game that could be solved by MCTS? AUDIENCE: Yes. PROFESSOR 3: It's\ncompletely deterministic.",
    "start": "2916750",
    "end": "2923160"
  },
  {
    "text": "It's two-player. It satisfies all of the criteria\nthat we've laid out before. Checkers is\ndefinitely a game that",
    "start": "2923160",
    "end": "2928240"
  },
  {
    "text": "can and has been solved by\nMCTS, although not solved to the extent that you can\ndefeat the thing that actually",
    "start": "2928240",
    "end": "2933760"
  },
  {
    "text": "has the solution [INAUDIBLE]. How about \"Settlers of Catan?\"",
    "start": "2933760",
    "end": "2938860"
  },
  {
    "text": "This one's a little\nbit trickier. Do you guys think that MCTS\nis likely to be able to play \"Settlers of Catan?\"",
    "start": "2938860",
    "end": "2944650"
  },
  {
    "text": "If not, let's throw out reason\nwhy or why not it would be [INAUDIBLE]. Yeah. AUDIENCE: No because\nthere's randomness.",
    "start": "2944650",
    "end": "2951800"
  },
  {
    "text": "PROFESSOR 3: So yes, that\nis absolutely the criticism. And that's why we\ncan't apply it vanilla. I put this on here\nas a trick question,",
    "start": "2951800",
    "end": "2958819"
  },
  {
    "text": "though, because it\nturns out that MCTS is robust to randomness. That you can actually play--",
    "start": "2958820",
    "end": "2963990"
  },
  {
    "text": "and I realize that's\njust me and we do. [LAUGHTER] You can actually\nplay through games.",
    "start": "2963990",
    "end": "2969349"
  },
  {
    "text": "If you think about\nthe simulation, the simulation is\nactually applicable even if the game is\nnot deterministic",
    "start": "2969349",
    "end": "2975692"
  },
  {
    "text": "because it does give you\na sense of the quality of your position. And the MCTS-based\nAI to play \"Settlers\"",
    "start": "2975692",
    "end": "2982830"
  },
  {
    "text": "is, I think, at least 49%\ncompetitive with the best AI",
    "start": "2982830",
    "end": "2987946"
  },
  {
    "text": "to play, at least in the\nautonomous non-scale space. So it does work.",
    "start": "2987946",
    "end": "2993780"
  },
  {
    "text": "Let's talk about the war\noperations plan response. Who here has seen the\nmovie \"War Games?\"",
    "start": "2993780",
    "end": "3000831"
  },
  {
    "text": "OK. Well, it should be more of you. The idea of \"War\nGames\" is that one",
    "start": "3000831",
    "end": "3006730"
  },
  {
    "text": "of the core characters\nin this world is this computer\nthat has been put in charge of the national\ndefense strategy with respect",
    "start": "3006730",
    "end": "3015130"
  },
  {
    "text": "to Russia. And that it needs to think\nthrough the possible future scenarios and decide whether\nit's going to launch the nukes",
    "start": "3015130",
    "end": "3021550"
  },
  {
    "text": "or not. Do you think that WOPR\ncan be MCTS-based?",
    "start": "3021550",
    "end": "3027809"
  },
  {
    "text": "AUDIENCE: No. PROFESSOR 3: No. AUDIENCE: It could, it\njust wouldn't be very good. PROFESSOR 3: Absolutely.",
    "start": "3027810",
    "end": "3033190"
  },
  {
    "text": "Once you fire the\nnukes you're not going to get another chance. So you can't\nparticularly simulate through what the possible\nscenarios are going to be like.",
    "start": "3033190",
    "end": "3039620"
  },
  {
    "text": "Yeah. AUDIENCE: So what if you had-- I agree you can't simulate\nit in the real world. But what if you had\na really good model",
    "start": "3039620",
    "end": "3045789"
  },
  {
    "text": "and you just simulated\nbased on that model? ",
    "start": "3045790",
    "end": "3051074"
  },
  {
    "text": "PROFESSOR 3: In that\ncase, it probably depends on the quality of your model. If you have a good model for\nhow World War III is going to",
    "start": "3051074",
    "end": "3059235"
  },
  {
    "text": "[INAUDIBLE]. [LAUGHTER] AUDIENCE: It is the case\nthat the military does",
    "start": "3059236",
    "end": "3065170"
  },
  {
    "text": "have simulators and they\ndo war games in simulation.",
    "start": "3065170",
    "end": "3070200"
  },
  {
    "text": "PROFESSOR 3: Yes, that's true. They could certainly try it\nand run MCTS if they wanted. And that's what\nhappened in the movie.",
    "start": "3070200",
    "end": "3076560"
  },
  {
    "text": "[INTERPOSING VOICES] AUDIENCE: And there\nyou're putting your money in the simulation not in the--",
    "start": "3076560",
    "end": "3082430"
  },
  {
    "text": "AUDIENCE: It's like having an\nMCTS play SOCOM or something like that. PROFESSOR 3: Yeah. It's definitely about putting\nmoney into the simulation",
    "start": "3082430",
    "end": "3089141"
  },
  {
    "text": "and you get really\ngood simulation. If you have a really\ngood simulations then you [INAUDIBLE] to play WOPR.",
    "start": "3089142",
    "end": "3095490"
  },
  {
    "text": "Yeah. AUDIENCE: Back to\n\"Settlers\" for a second. I'm curious if there's a way\nfor the whole player training",
    "start": "3095490",
    "end": "3100599"
  },
  {
    "text": "resources thing,\nor would it have to be only purely\nlike using the ports.",
    "start": "3100600",
    "end": "3107216"
  },
  {
    "text": "PROFESSOR 3: That's\na good question. I haven't looked closely at\nwhether they do that or not.",
    "start": "3107216",
    "end": "3113620"
  },
  {
    "text": "If it's playing a\ntwo-player game, then I would imagine that they\nwouldn't because you don't",
    "start": "3113620",
    "end": "3118789"
  },
  {
    "text": "really trade in to play a game. But if they weren't,\nI bet that you can incorporate it with WOPR. AUDIENCE: Is it limited\nto two-player games?",
    "start": "3118790",
    "end": "3125090"
  },
  {
    "text": "PROFESSOR 3: No, not at all. In fact, there are\nlots of purchases that do only\none-player games, where you think of what's the best\nmovie that you can make.",
    "start": "3125090",
    "end": "3131482"
  },
  {
    "text": "AUDIENCE: I know. But I mean, couldn't MCTS handle\nthree- or four-player games? PROFESSOR 3: Yeah,\nit absolutely could.",
    "start": "3131482",
    "end": "3136840"
  },
  {
    "text": "I'm not sure how they\ncomputed their head-to-head. That might be\ncompletely flat cursors. I'm not even sure how\nthe settlers interact.",
    "start": "3136840",
    "end": "3144734"
  },
  {
    "text": "Yeah. AUDIENCE: A quick question. So at first you know if I\nreduce the chess board to only 4 by 4 or 5 by 5, and\nI run MCTS versus",
    "start": "3144734",
    "end": "3152530"
  },
  {
    "text": "the traditional algorithm that\nAlphaGo offered as a tree. Do you think MCTS will\nprefer theory and perform",
    "start": "3152530",
    "end": "3158222"
  },
  {
    "text": "this computational requirement. PROFESSOR 3: The thing about\nthe way that Deep Blue is, which is the AI that\nended the Kasparov",
    "start": "3158222",
    "end": "3164570"
  },
  {
    "text": "thing, a bunch of his\nchess grand master, is that it has a tremendous\namount of heuristic",
    "start": "3164570",
    "end": "3169970"
  },
  {
    "text": "information. There's a lot of\nexternal stuff that's incorporated into the\nsystem that makes it able to explore the best paths.",
    "start": "3169970",
    "end": "3177250"
  },
  {
    "text": "What I would say is\nthat knoledgesless MCTS based on randomness,\nwould take a very long",
    "start": "3177250",
    "end": "3183730"
  },
  {
    "text": "computational time to even\nbecome competitive with those kinds of algorithms, and\nprobably feasibly never would.",
    "start": "3183730",
    "end": "3190382"
  },
  {
    "text": "What if you incorporated\nheuristic information, I think that there's a bunch of\nhope in terms of getting MCTS to start performing better.",
    "start": "3190382",
    "end": "3196600"
  },
  {
    "text": "And you can look at what\nnext I'm going to talk about, AlphaGo. It takes inspiration for how\nwe go about incorporating",
    "start": "3196600",
    "end": "3202040"
  },
  {
    "text": "these new circuits. AUDIENCE: So only the\ncircuit you [INAUDIBLE]",
    "start": "3202040",
    "end": "3207147"
  },
  {
    "text": "PROFESSOR 3: It definitely\nseems like if you have a really good\nheuristic model for what",
    "start": "3207147",
    "end": "3213330"
  },
  {
    "text": "good states in the game are,\nthat if it's a smaller search",
    "start": "3213330",
    "end": "3218530"
  },
  {
    "text": "space, that some other\nmodels could perform better. Although, I'm probably\ngoing to eat my foot here",
    "start": "3218530",
    "end": "3224546"
  },
  {
    "text": "because this is going to be\non OCW some massive amount, massive chess\nplaying algorithms.",
    "start": "3224546",
    "end": "3229935"
  },
  {
    "text": "Eat my shoe not my foot. [LAUGHTER]",
    "start": "3229936",
    "end": "3235430"
  },
  {
    "text": "One last game. Does anyone know\nwhat this game is? AUDIENCE: \"Total War?\"",
    "start": "3235430",
    "end": "3241280"
  },
  {
    "text": "PROFESSOR 3: Yes. Nice. This is \"Rome, Total War II.\" It's a simulator for this\ntremendous real time strategy",
    "start": "3241280",
    "end": "3249890"
  },
  {
    "text": "game, where you play, I\nthink, the Roman Empire. And you're controlling armies\nand huge infrastructure systems",
    "start": "3249890",
    "end": "3257540"
  },
  {
    "text": "that move and conquer\nstates and continents, and meet in the field, and\nmanage resources, and do",
    "start": "3257540",
    "end": "3264530"
  },
  {
    "text": "all of these incredible\ndiplomacy feats. And so do you think that this\ngame can be solved by MCTS? AUDIENCE: Yes.",
    "start": "3264530",
    "end": "3269930"
  },
  {
    "text": "AUDIENCE: Yes. PROFESSOR 3: Lets say no. But I guess I put it on here. So that's good on you.",
    "start": "3269930",
    "end": "3276869"
  },
  {
    "text": "The way that the AI in\n\"Rome, Total War II\" is built is that it's built\non an MCTS structure.",
    "start": "3276870",
    "end": "3283200"
  },
  {
    "text": "And it in fact does\ndo resource allocation and a lot of its\npolitical maneuvers based on Monte Carlo\nTree Search moves.",
    "start": "3283200",
    "end": "3289439"
  },
  {
    "text": "There are a bunch of\nreasons that they explain in the game for\nwhy they do this, or in papers released\nabout the game.",
    "start": "3289439",
    "end": "3294961"
  },
  {
    "text": "But one of the nice ones\nis that it's random, which means that\nyou're never going to play against the same kind\nof AI twice because every time",
    "start": "3294961",
    "end": "3301280"
  },
  {
    "text": "the set of decisions that\nit's going to think about is completely different. AUDIENCE: I have\na quick question. PROFESSOR 3: Yeah. AUDIENCE: So if I want to\nmodel any game with MCTS,",
    "start": "3301280",
    "end": "3307646"
  },
  {
    "text": "does it have to be that the\nactions in playing a game has to be able to discretize.",
    "start": "3307646",
    "end": "3314272"
  },
  {
    "text": "PROFESSOR 3: Yes. So far as I know, I haven't\nseen many continuous variants in MCTS.",
    "start": "3314272",
    "end": "3319519"
  },
  {
    "text": "And so, I think that it is about\nchoosing these reactions, which on it's most narrow level does\nactually bring it down to here.",
    "start": "3319520",
    "end": "3326130"
  },
  {
    "text": "I think one of the\nreasons that this is nice is that there are so\nmany different decisions that could be made that MCTS is\nreally the only approach that",
    "start": "3326130",
    "end": "3332609"
  },
  {
    "text": "could even begin to handle the\nmassive branching factor that's associated with the\ngame Rome, Total War.",
    "start": "3332610",
    "end": "3337809"
  },
  {
    "text": "Yeah. AUDIENCE: This is\nalso the consequence of this year you get the play\noff when this game comes.",
    "start": "3337810",
    "end": "3343407"
  },
  {
    "text": "PROFESSOR 3: That's interesting. That's probably totally it. That's cool. ",
    "start": "3343407",
    "end": "3350640"
  },
  {
    "text": "That's everything about how\nthe algorithm actually works. I'm going to pass\nit off to Nick,",
    "start": "3350640",
    "end": "3356134"
  },
  {
    "text": "and he's going to talk to us\nabout some actual limitations for this game [INAUDIBLE]. ",
    "start": "3356134",
    "end": "3364221"
  },
  {
    "text": "PROFESSOR 3: So\nas you have said, I'm going to start diving\ninto some applications here. And not only applications\nbut also some modifications",
    "start": "3364221",
    "end": "3372180"
  },
  {
    "text": "or augmentations of MCTS. It should hopefully clarify\nsome of the side questions you all have been having\non slight tweaks to MCTS.",
    "start": "3372180",
    "end": "3381610"
  },
  {
    "text": "Now let's get started. Wait for it. Now let's get started. [LAUGHTER] Part III, applications.",
    "start": "3381610",
    "end": "3387600"
  },
  {
    "text": "First thing we're\ngoing to look at is an MCTS-based\n\"Mario\" controller. And \"Mario\" might seem like\nsome weird thing to test AI on,",
    "start": "3387600",
    "end": "3395290"
  },
  {
    "start": "3388000",
    "end": "3388000"
  },
  {
    "text": "but there actually is a \"Super\nMario Bros\" AI benchmark, which it used to\ntest a lot of AI on how well they could\nplay this platform.",
    "start": "3395290",
    "end": "3402280"
  },
  {
    "text": "In case any of you don't\nknow what \"Super Mario Bros\" is, this is a screenshot.",
    "start": "3402280",
    "end": "3407420"
  },
  {
    "text": "Basically, you control\nthis one character. It's a single-player game.",
    "start": "3407420",
    "end": "3412780"
  },
  {
    "text": "The ultimate goal is to\nreach this flag at the end. But along the way\nthere's enemies,",
    "start": "3412780",
    "end": "3418180"
  },
  {
    "text": "there's some bonus\nshrooms you can get. If you break open some\nboxes you might get coins,",
    "start": "3418180",
    "end": "3423869"
  },
  {
    "text": "things like that. But first, let's just highlight\nsome of the modifications that",
    "start": "3423870",
    "end": "3429642"
  },
  {
    "start": "3427000",
    "end": "3427000"
  },
  {
    "text": "need to be made, or some of\nthe differences between vanilla MCTS and an MCTS that's going\nto be able to work for \"Mario.\"",
    "start": "3429642",
    "end": "3436590"
  },
  {
    "text": "First thing is that\nit's single-player. The second is, we use a\nslightly different simulation strategy than the initial\njust vanilla simulation.",
    "start": "3436590",
    "end": "3445130"
  },
  {
    "text": "And someone actually hinted at\ndoing more than one simulation because you, you're watching\nus to n simulations, I think.",
    "start": "3445130",
    "end": "3452280"
  },
  {
    "text": "We'll touch on that. Then this also introduces\nwhat I would consider to be domain knowledge.",
    "start": "3452280",
    "end": "3458839"
  },
  {
    "text": "Then finally, there's a 50 to\n40 millisecond computation time. And that has to do with the\nframes per second of the game.",
    "start": "3458840",
    "end": "3465270"
  },
  {
    "text": "So you would think that\n\"Mario\" is a continuous game, but if we discretize\ntime into these chunks,",
    "start": "3465270",
    "end": "3470950"
  },
  {
    "text": "then we can use MTTS. Now let's just think about\nhow we could possibly",
    "start": "3470950",
    "end": "3476569"
  },
  {
    "start": "3474000",
    "end": "3474000"
  },
  {
    "text": "formulate this problem. Can anyone think of\nwhat each of these nodes would be if we're\nplaying \"Super Mario?\"",
    "start": "3476570",
    "end": "3482586"
  },
  {
    "text": "AUDIENCE: Jump. PROFESSOR 3: Sorry? AUDIENCE: Jump. It would be like, first\nnode you're going to jump.",
    "start": "3482586",
    "end": "3487960"
  },
  {
    "text": "PROFESSOR 3: That might\nbe a way to formulate it. But I think that could get--",
    "start": "3487960",
    "end": "3493522"
  },
  {
    "text": "AUDIENCE: Oh, it's not your\ncontrol at inputs [INAUDIBLE].. PROFESSOR 3: Right. So the node itself isn't\ngoing to be an action.",
    "start": "3493522",
    "end": "3502109"
  },
  {
    "text": "AUDIENCE: Equal frames. PROFESSOR 3: Yeah, basically. So it's going to be the\nstate of a game, what",
    "start": "3502110",
    "end": "3507320"
  },
  {
    "text": "we'll call a state. So it's basically\njust a screen grab. And it take it,\nin this case, it's a 15 by 19 grid screen\ngrab of the game.",
    "start": "3507320",
    "end": "3515190"
  },
  {
    "text": "And it will have\ninformation about-- it knows Mario's position, it knows\nthe enemy's position, position",
    "start": "3515190",
    "end": "3520240"
  },
  {
    "text": "of the blocks, et cetera. And then, as Yo\nwas saying, in MCTS",
    "start": "3520240",
    "end": "3525370"
  },
  {
    "text": "we have values associated\nwith our nodes. And so it will\nalso have a value. But we'll get into the\nvalue in the next slide",
    "start": "3525370",
    "end": "3532890"
  },
  {
    "text": "because I can't really\nfit it all in here. With that being said\nfor our node, that",
    "start": "3532890",
    "end": "3538930"
  },
  {
    "text": "being the state of the game,\nwhat makes sense for the edge? Does anyone know? How do we transition from\none state to another state?",
    "start": "3538930",
    "end": "3545990"
  },
  {
    "text": "AUDIENCE: Jump. PROFESSOR 3: Yeah, exactly. So this is where the\njump and all the action have been played. So the actions that you take--",
    "start": "3545990",
    "end": "3551970"
  },
  {
    "text": "I didn't list all the actions. You can also have a jump left,\njump right, all those things. But basically, the\nactions are what",
    "start": "3551970",
    "end": "3557960"
  },
  {
    "text": "takes you from state to state. So I just drew out\nwhat a node might look like if you\nused the jump action.",
    "start": "3557960",
    "end": "3564375"
  },
  {
    "text": "You might have Mario\ngo up in the sky. Are there questions? AUDIENCE: Does it just\nrun the rest of it?",
    "start": "3564375",
    "end": "3570790"
  },
  {
    "text": "Because that little thing's\nmoving as they move on? PROFESSOR 3: Well, it's not\nmoving in this moment in time.",
    "start": "3570790",
    "end": "3577260"
  },
  {
    "text": "We're discretizing\ntime right now. AUDIENCE: But I'm saying,\nif your action is jump, just you would have 1,000\nnodes because if you did",
    "start": "3577260",
    "end": "3586047"
  },
  {
    "text": "plan out where that thing's\nmoving, left or right, then it could be-- PROFESSOR 3: Yeah, right. So in each state we\nhave the enemy position.",
    "start": "3586047",
    "end": "3592450"
  },
  {
    "text": "And we know the\nspeed and direction. And so we know when we go from\nthis node to one time step later, we'll know where\nthe enemy's moving.",
    "start": "3592450",
    "end": "3600694"
  },
  {
    "text": "Any other questions? Moving on.",
    "start": "3600694",
    "end": "3606550"
  },
  {
    "text": "Sorry. Let me just preface\nthis part real quick. So in our other simulations,\nat the end of the simulation",
    "start": "3606550",
    "end": "3611970"
  },
  {
    "text": "we would get either a one or a\nzero, if we'd won tic-tac-toe or we lost tic-tac-toe.",
    "start": "3611970",
    "end": "3617910"
  },
  {
    "text": "But that won't really work\ntoo well here because there's a lot of other factors\nthat go into play when",
    "start": "3617910",
    "end": "3623850"
  },
  {
    "text": "you're playing \"Mario.\" Also, if you're doing a\nsimulation, more than likely, you're going to end\nup hitting an enemy",
    "start": "3623850",
    "end": "3630210"
  },
  {
    "text": "and dying or falling\ninto a gap and dying. So a lot of these simulations\nmight all return zero. And that is, you can't really\ndistinguish between them.",
    "start": "3630210",
    "end": "3638440"
  },
  {
    "text": "So this is why I say,\nthis version of MCTS introduces what I would\nconsider to be domain knowledge.",
    "start": "3638440",
    "end": "3644369"
  },
  {
    "text": "Basically, they're\nassigning scores to potential things that\ncould happened along the way.",
    "start": "3644370",
    "end": "3650680"
  },
  {
    "text": "And this is basically telling\nthe AI that collecting a flower is a little bit better\nthan collecting a mushroom.",
    "start": "3650680",
    "end": "3657935"
  },
  {
    "text": "It's telling it that\ngetting hurt is bad. Right off the bat, all\nthese things in the score are giving the AI some domain\nknowledge about \"Super Mario",
    "start": "3657936",
    "end": "3665099"
  },
  {
    "text": "Bros,\" that it's helping\nit calculate the simulation results. ",
    "start": "3665100",
    "end": "3670984"
  },
  {
    "text": "As it says here, it's just doing\na multi-objective weighted sum of all these things. Throughout the simulation it's\njust adding up your score.",
    "start": "3670985",
    "end": "3677825"
  },
  {
    "text": "And then that's the score that\nis going to be propagated. Are there questions\nabout the score?",
    "start": "3677825",
    "end": "3684479"
  },
  {
    "text": "AUDIENCE: You said that\nit adds up all these guys and it propagates it over. Is it possible to just propagate\nthe multi-part sum [INAUDIBLE]",
    "start": "3684479",
    "end": "3693086"
  },
  {
    "text": "as opposed to propagating\none value that you create? Are you essentially\npropagating all--",
    "start": "3693086",
    "end": "3699600"
  },
  {
    "text": "what's this?-- 15 values\nupwards at every node, or are you propagating one value-- PROFESSOR 3: Well,\nit's one value. It's the collective--",
    "start": "3699600",
    "end": "3705000"
  },
  {
    "text": "AUDIENCE: Then you make\nthem add it together and you got each one\nof them a sub factor. ",
    "start": "3705000",
    "end": "3710164"
  },
  {
    "text": "PROFESSOR 3: Then also,\njust one thing to note here, is distance, you get 0.1.",
    "start": "3710164",
    "end": "3715230"
  },
  {
    "text": "And these are all parameters\nthat have been tuned. In the initial version,\ndistance was, I think,",
    "start": "3715230",
    "end": "3721470"
  },
  {
    "text": "a reward of five,\nbut probably realized that that made Mario skip past\na lot of coins and things.",
    "start": "3721470",
    "end": "3728500"
  },
  {
    "text": "And so he tweaked\nthe score for that. And also, time left is two. So there's some weight there.",
    "start": "3728500",
    "end": "3734460"
  },
  {
    "text": "You want to get to the\nvery end of the game. AUDIENCE: If you're\npushing up this score, it's no longer a\nwin over losses.",
    "start": "3734460",
    "end": "3740849"
  },
  {
    "text": "So it's not w over n. What is it affecting? PROFESSOR 3: You can\njust use the score. AUDIENCE: The score is the--",
    "start": "3740850",
    "end": "3746930"
  },
  {
    "text": "PROFESSOR 3: Yeah. In MCTS you have\nthis idea of when you're propagating your q value,\nyou could have that to be zero,",
    "start": "3746930",
    "end": "3756540"
  },
  {
    "text": "one. AUDIENCE: It's like the sum of\nall the scores and the nodes below over the number\nof games you win. PROFESSOR 3: So\nbasically, what you",
    "start": "3756540",
    "end": "3762150"
  },
  {
    "text": "would be getting when you divide\nby the number of simulations is your average\nscore at that node.",
    "start": "3762150",
    "end": "3767980"
  },
  {
    "text": "AUDIENCE: OK. AUDIENCE: When you have\nkillsByFire and [INAUDIBLE]",
    "start": "3767980",
    "end": "3773550"
  },
  {
    "text": "like that, if you\nhave a positive value, then isn't it good\nto be killed by fire,",
    "start": "3773550",
    "end": "3778562"
  },
  {
    "text": "or something like that? PROFESSOR 3: This is\nkilling an enemy by fire. Like Mario could collect a\ncertain flower or mushroom?",
    "start": "3778562",
    "end": "3784350"
  },
  {
    "text": "I think flower, then you\nhave a fire breath and you [INAUDIBLE]. AUDIENCE: So that's Mario's\nstatus if Mario never dies?",
    "start": "3784350",
    "end": "3790864"
  },
  {
    "text": "PROFESSOR 3: No. Mario's status is-- I believe, Mario's\nstatus is the fact that you could upgrade Mario by\ncollecting [INAUDIBLE] mushroom",
    "start": "3790864",
    "end": "3797710"
  },
  {
    "text": "from a fire Mario. So that gives you\na lot of points. Because if you\nbecome fire Mario,",
    "start": "3797710",
    "end": "3802945"
  },
  {
    "text": "then you're more likely to not\ndie by running into enemies because you have fire-spewing--",
    "start": "3802945",
    "end": "3808433"
  },
  {
    "text": "AUDIENCE: You said they\nspent a lot of time tuning these parameters. Isn't it generally, though,\njust an optimization",
    "start": "3808434",
    "end": "3814170"
  },
  {
    "text": "framework if that's\nsome formula? So they tuned the\nparameters just to make behave the way\nthat we think is nice.",
    "start": "3814170",
    "end": "3821370"
  },
  {
    "text": "But if you change\nthe values, they'll do the right thing\nfor that equation. PROFESSOR 3: Yeah. AUDIENCE: OK. PROFESSOR 3: Yes.",
    "start": "3821370",
    "end": "3827028"
  },
  {
    "text": "But they were tuning this to\nmake it play how they wanted. AUDIENCE: [INAUDIBLE] can't just\nbe a reflection of [INAUDIBLE]",
    "start": "3827028",
    "end": "3836069"
  },
  {
    "text": "PROFESSOR 3: That's a strategy. If you choose that,\nI don't see why not. That might affect\ncertain things.",
    "start": "3836069",
    "end": "3842351"
  },
  {
    "text": "Obviously, you can change\nthese to whatever you want. It'll slightly tweak\nwhich simulations as to working better, in terms\nof changing which nodes you",
    "start": "3842352",
    "end": "3850240"
  },
  {
    "text": "end up choosing [INAUDIBLE]. So we move on.",
    "start": "3850240",
    "end": "3855670"
  },
  {
    "text": "So we know about\nscoring simulations. Now we're going to look at\nexactly the simulation type that's used to play\nthis MCTS controller.",
    "start": "3855670",
    "end": "3863579"
  },
  {
    "text": "So the regular version\nthat Yo talked about is just choosing a\nrandom node at each level in your simulation.",
    "start": "3863580",
    "end": "3870300"
  },
  {
    "text": "But there are some\nother strategies. And someone brought one up. The first is, look at best of n. So in this one, you choose three\nrandom nodes at each level,",
    "start": "3870300",
    "end": "3879280"
  },
  {
    "text": "except that you stick with\nthe best of those three. Choose three random nodes,\nstick with this one.",
    "start": "3879280",
    "end": "3885080"
  },
  {
    "text": "Go to the next one. You would choose n random\nthree, take the best one, and then go to the next level. You are able to do that\nin this game because",
    "start": "3885080",
    "end": "3893215"
  },
  {
    "text": "of the way the\nscoring works, you don't have to get to the end\nof the game for your score. You actually could collect\na coin along the way.",
    "start": "3893216",
    "end": "3900425"
  },
  {
    "text": "If this is jump,\nand then it gets to be a coin versus\nmoving left and right. That doesn't give\nyou any points. Then this is the node that would\ngive you the highest scores,",
    "start": "3900425",
    "end": "3907310"
  },
  {
    "text": "so I would choose\nthat one, et cetera. And then the final one,\nwhich is the one that is actually used\nfor this controller,",
    "start": "3907310",
    "end": "3912791"
  },
  {
    "text": "is multi-simulation. This was brought up by him. I don't know your name.",
    "start": "3912791",
    "end": "3918005"
  },
  {
    "text": "Sorry. But basically, you run\nmultiple random simulations from your node. And then you propagate up\nwhichever of those simulations",
    "start": "3918005",
    "end": "3924990"
  },
  {
    "text": "give you the highest value. And the reason to do\nmultiple simulations is to attempt to increase the\naccuracy of your simulations.",
    "start": "3924990",
    "end": "3933767"
  },
  {
    "text": "If you just do\none simulation you might just get really lucky. But if you do three then you\ncan take the highest value",
    "start": "3933767",
    "end": "3940490"
  },
  {
    "text": "use that as your value. Since the whole point of this is\nto try make moves that get you the highest values,\nthen that will",
    "start": "3940490",
    "end": "3947330"
  },
  {
    "text": "make your random simulation\nvalue more accurate. Are there questions\nabout multi-simulation?",
    "start": "3947330",
    "end": "3952915"
  },
  {
    "text": "AUDIENCE: So what do you\nthink about the simulation [INAUDIBLE] how many [INAUDIBLE]",
    "start": "3952915",
    "end": "3958940"
  },
  {
    "text": "PROFESSOR 3: So there's\na trade off here. The more simulations you\ndo the more accurate--",
    "start": "3958940",
    "end": "3964655"
  },
  {
    "text": "the more representative\nyour simulation will be at the end of the game. ",
    "start": "3964655",
    "end": "3970720"
  },
  {
    "text": "You could run two to\nthe whatever simulations to try to get every\nsingle possible action",
    "start": "3970720",
    "end": "3976390"
  },
  {
    "text": "and then take the max of that. And that would give\nyou the maximum value. That would be ideal. But obviously, that\ntakes more time.",
    "start": "3976390",
    "end": "3982290"
  },
  {
    "text": "So there's a trade off\nbetween computation time and the number of\nsimulations you run. And that's just something\nthat they probably just",
    "start": "3982290",
    "end": "3987820"
  },
  {
    "text": "played around with. AUDIENCE: Do you\nuse [INAUDIBLE] have",
    "start": "3987820",
    "end": "3997472"
  },
  {
    "text": "to finish the decision losing a\ncouple of minutes or 10 minutes or they're going to take\nyour [INAUDIBLE] away.",
    "start": "3997472",
    "end": "4003380"
  },
  {
    "text": "PROFESSOR 3: In this competition\nthere is different computation time budgets that you get.",
    "start": "4003380",
    "end": "4008480"
  },
  {
    "text": "And I believe the reason for\nthe different computation time budgets is the frame\nper second of the game. ",
    "start": "4008480",
    "end": "4018390"
  },
  {
    "text": "I told you all\nabout the setup, we went over, the scoring, the\nnodes, what the advantages are,",
    "start": "4018390",
    "end": "4023799"
  },
  {
    "text": "what the simulation\nstrategy is used. So you probably want\nto see it in action. So this is always a risky move\ntrying to get video to play.",
    "start": "4023800",
    "end": "4031150"
  },
  {
    "text": "AUDIENCE: It's actually\nin the back up. Hit Escape. PROFESSOR 3: OK. Got it. AUDIENCE: And now, I guess, we--",
    "start": "4031150",
    "end": "4037075"
  },
  {
    "text": "PROFESSOR 3: And\ndrag it over again? AUDIENCE: Yeah. ",
    "start": "4037075",
    "end": "4044667"
  },
  {
    "text": "PROFESSOR 3: Running\nthis full screen. AUDIENCE: Hit the [INAUDIBLE] PROFESSOR 3:\n[INAUDIBLE] All right.",
    "start": "4044667",
    "end": "4053330"
  },
  {
    "text": "Here's this MCTS-based\n\"Mario\" playing controller. You can see he's\nactually wrecking, so doing some serious damage here.",
    "start": "4053330",
    "end": "4059240"
  },
  {
    "text": "But those lines that you\nsee, the reason they're different colors it's not\nshowing different players,",
    "start": "4059240",
    "end": "4066616"
  },
  {
    "text": "or anything like that. It's just using\ndifferent colors so you can see the different\nlayers of this tree search.",
    "start": "4066616",
    "end": "4072065"
  },
  {
    "text": "You can see he actually\nwent backwards there. And that's because\nin a simulation, when one of the backward\nones landed on an enemy--",
    "start": "4072065",
    "end": "4078670"
  },
  {
    "text": "and in fact gets you points\nfrom our scoring system versus if you had just gone forward you\nwould have gotten some distance",
    "start": "4078670",
    "end": "4084376"
  },
  {
    "text": "points but not-- also, he is just [INAUDIBLE] The simulation is quickly being\nable to figure out that he",
    "start": "4084376",
    "end": "4092754"
  },
  {
    "text": "can jump on all his enemies. So he's just wrecking\nall these guys. Getting lots of points here,\ncollecting the coin, et cetera.",
    "start": "4092754",
    "end": "4099349"
  },
  {
    "text": "You get the idea. It's pretty awesome to watch. There's that flower\nwe were talking about. So now he's actually a\nfire-spewing Mario demon.",
    "start": "4099350",
    "end": "4108532"
  },
  {
    "text": "He's doing some serious\ndamage with that. Stepping on missiles. I didn't even know you\ncould step on the missiles.",
    "start": "4108532",
    "end": "4114689"
  },
  {
    "text": "All right. You could watch\nthis for a while. But we'll exit now.",
    "start": "4114689",
    "end": "4121599"
  },
  {
    "text": "It looks super\npromising in this video. I don't know how\nclose max stuff. AUDIENCE: Just click\non back [INAUDIBLE]",
    "start": "4121599",
    "end": "4128589"
  },
  {
    "text": "PROFESSOR 3: There it is. OK. The demo looks really cool,\nlooks really promising.",
    "start": "4128590",
    "end": "4134299"
  },
  {
    "text": "Let's take a look at the\ncharts here because we all want some quantitative stuff.",
    "start": "4134300",
    "end": "4140240"
  },
  {
    "text": "This is the chart. The score is on the y-axis. The bottom is computation\nbudget, which is something that you were talking about.",
    "start": "4140240",
    "end": "4146439"
  },
  {
    "text": "I just want to highlight\nto make this a little more",
    "start": "4146439",
    "end": "4151759"
  },
  {
    "text": "visually appealing here. All of these things\nthat I highlighted,",
    "start": "4151760",
    "end": "4156869"
  },
  {
    "text": "it's labelled as UCT. That's Upper\nConfidence Bound Tree. Remember, Yo talked about\nupper confidence bounds.",
    "start": "4156870",
    "end": "4162470"
  },
  {
    "text": "That's essentially\nwhat's used in that TTS for guiding your tree search. So these are all the methods. But then UCT multi, which is\nthis purple square, that's",
    "start": "4162470",
    "end": "4171200"
  },
  {
    "text": "saying it's using MCTS but it's\ndoing the multiple simulations. And you can see this multi\nplus care is also in the top.",
    "start": "4171200",
    "end": "4181089"
  },
  {
    "text": "Both these use the\nmulti-simulation technique. And then the plus car is\nthey added an extra scoring",
    "start": "4181090",
    "end": "4187278"
  },
  {
    "text": "mechanism for carries. I believe that's probably\nlike carrying a shell.",
    "start": "4187279",
    "end": "4192670"
  },
  {
    "text": "That made it do better. Then these ones that\naren't highlighted are using plain Astar, and then\na refined version of Astar.",
    "start": "4192670",
    "end": "4201130"
  },
  {
    "text": "With increasing time,\nthe do increase scores, but they're even worse\nthan just your UCT",
    "start": "4201130",
    "end": "4207949"
  },
  {
    "text": "with just random simulation,\nno multi-simulations.",
    "start": "4207950",
    "end": "4213424"
  },
  {
    "text": "We're running low on\ntime, which is not ideal. But another thing that I want to\npoint out is down at the bottom",
    "start": "4213424",
    "end": "4219810"
  },
  {
    "text": "here, these are the\nmulti-simulations. They have the lowest\nmaximal search depth, which",
    "start": "4219810",
    "end": "4227540"
  },
  {
    "text": "at first would seem like, what? I have the lowest search depth\nbut my score is the most?",
    "start": "4227540",
    "end": "4233840"
  },
  {
    "text": "But that comes\ninto play when you were saying about the trade\noff between the simulations and the amount time it takes.",
    "start": "4233840",
    "end": "4241220"
  },
  {
    "text": "So because I'm doing\nmultiple simulations, I'm taking more\ntime at each node. But that's giving me a more\naccurate value assessment.",
    "start": "4241220",
    "end": "4249770"
  },
  {
    "text": "So that let's me choose\nmy actions more carefully, or with more information. And so that's what's able to\ngive me this better scores.",
    "start": "4249770",
    "end": "4256240"
  },
  {
    "text": " That's all \"Mario.\" So we're going to\nmoving onto AlphaGo.",
    "start": "4256240",
    "end": "4262010"
  },
  {
    "text": "Are there any questions about\n\"Mario\" before I go to AlphaGo? Yeah. AUDIENCE: What's the table\n[INAUDIBLE] inference?",
    "start": "4262010",
    "end": "4267300"
  },
  {
    "text": "PROFESSOR 3: That's\na good question. I have a feeling it's because\nif you're doing best of n,",
    "start": "4267300",
    "end": "4272420"
  },
  {
    "text": "that's really heavily relying\non your scoring metrics. ",
    "start": "4272420",
    "end": "4279360"
  },
  {
    "text": "Let's say at one step\nif I jump and collect a coin versus if I go\nleft or right and play, I'll get more points\nif I get that coin.",
    "start": "4279360",
    "end": "4285326"
  },
  {
    "text": "But maybe, a missile is\ngoing to hit me in the face if I do that. It gets rid of\nsome of the-- it's",
    "start": "4285326",
    "end": "4290940"
  },
  {
    "text": "forcing you to do certain moves. AUDIENCE: Is the A*\nheuristically using the same value, the same value\nthat you're getting",
    "start": "4290940",
    "end": "4297718"
  },
  {
    "text": "by your simulation? PROFESSOR 3: Yeah. I'm not exactly sure what\nthe Astar heuristic is.",
    "start": "4297718",
    "end": "4302820"
  },
  {
    "text": "The whole reason that A* is\ndifficult is because coming up",
    "start": "4302820",
    "end": "4308520"
  },
  {
    "text": "with heuristics for\nthese types of games are. But this is not his\nversion of Astar.",
    "start": "4308520",
    "end": "4314670"
  },
  {
    "text": "I believe this is the\nAstar that was used by-- I forget the name of the guy--\nbut he won the AI competition",
    "start": "4314670",
    "end": "4320890"
  },
  {
    "text": "a couple of years ago. I'm going to try to\nmove onto AlphaGo.",
    "start": "4320890",
    "end": "4326390"
  },
  {
    "text": "Does someone have how\nmany minutes I have left? AUDIENCE: Four. PROFESSOR 3: OK. We're going to power through.",
    "start": "4326390",
    "end": "4333005"
  },
  {
    "text": "Here's AlphaGo. Hopefully, you all\nknow the rules. Just in case, I'll just\ngo through a quick-- 19 by 19.",
    "start": "4333005",
    "end": "4338220"
  },
  {
    "text": "You alternate black\nstones and white stones. You collect enemy stones by\ncompletely surrounding them.",
    "start": "4338220",
    "end": "4343480"
  },
  {
    "text": "You can surround a single\nstone. groups of stones. And your score is your\nterritory plus the number of captive pieces.",
    "start": "4343480",
    "end": "4349115"
  },
  {
    "text": "So your territory is just the\narea that you're surrounding, and then you just add the\nstones you've collected.",
    "start": "4349115",
    "end": "4354506"
  },
  {
    "text": "The rules aren't\nsuper important. The main emphasis is there's\nvery few rules so you would think it's really simple.",
    "start": "4354506",
    "end": "4360690"
  },
  {
    "text": "But the complexity of the\ngame is quite extreme.  At each turn you have about\n250 options that you can play.",
    "start": "4360690",
    "end": "4370290"
  },
  {
    "text": "Each Go game lasts\nabout 150 turns. So that gives you a total\nof 10 to the 761 games, approximately.",
    "start": "4370290",
    "end": "4376370"
  },
  {
    "text": "And to put that in\ncomparison, here's chess. You can read those numbers. Chess is also pretty complex.",
    "start": "4376370",
    "end": "4381400"
  },
  {
    "text": "But there's 35\noptions for turns. Deep Blue.",
    "start": "4381400",
    "end": "4386431"
  },
  {
    "text": "I think you were talking about\nbuilding out the whole tree. So Deep Blue would build\nout the tree for six levels.",
    "start": "4386432",
    "end": "4392100"
  },
  {
    "text": "And then use this\nhard core chess master inputted heuristic\nevaluation that it",
    "start": "4392100",
    "end": "4397745"
  },
  {
    "text": "used to find the best move. Except with Go, you\nhave 250 options, which already is adding\na lot more complexity.",
    "start": "4397745",
    "end": "4406670"
  },
  {
    "text": "So that strategy won't\nwork quite as nicely. What do we do?",
    "start": "4406670",
    "end": "4411870"
  },
  {
    "text": "We use a modified\nversion of MCTS. Well, it's not what we do. That's what Google's\nDeepMind team did with Go.",
    "start": "4411870",
    "end": "4419219"
  },
  {
    "text": "They combined neural\nnetworks with MCTS. Coincidentally, we learned about\nneural networks last class.",
    "start": "4419220",
    "end": "4425429"
  },
  {
    "text": "Probably not a coincidence. PROFESSOR 3: It's\nnot a coincidence. PROFESSOR 3: The we\nordered two policy networks",
    "start": "4425430",
    "end": "4431500"
  },
  {
    "text": "in the AlphaGo, and\none value network. And another big\ncoincidence here, the two policy\nnetworks are actually",
    "start": "4431500",
    "end": "4437475"
  },
  {
    "text": "CNN's, which we learned\nspecifically about last class, convolutional neural nets. And the reason for\nthat is the input",
    "start": "4437475",
    "end": "4444515"
  },
  {
    "text": "to the policy neural networks\nis an image of the game. And remember, convolutional\nneural nets work really",
    "start": "4444515",
    "end": "4450120"
  },
  {
    "text": "well with images. What it outputs, though, is\na probability distribution",
    "start": "4450120",
    "end": "4455520"
  },
  {
    "text": "over the legal moves. And the idea is, that if a\nmove has a higher probability",
    "start": "4455520",
    "end": "4460740"
  },
  {
    "text": "it will be a more promising\nmove for you to take. But another key point is\nthat it's not deterministic.",
    "start": "4460740",
    "end": "4467195"
  },
  {
    "text": "It's not telling you\nto take this move. It's just assigning a higher\nprobability to this move.",
    "start": "4467195",
    "end": "4472310"
  },
  {
    "text": "And this network was generated\nby doing supervised learning on 30 million positions\nfrom human expert games.",
    "start": "4472310",
    "end": "4479390"
  },
  {
    "text": "Apparently, there's a giant\ndatabase of Go expert games. So that came in handy. And there were two\ndifferent networks trained.",
    "start": "4479390",
    "end": "4486869"
  },
  {
    "text": "One of them was a slow policy,\nthe other was a fast policy. The slow was able to predict an\nexpert move with 57% accuracy,",
    "start": "4486870",
    "end": "4494980"
  },
  {
    "text": "which to me was mind blowing. Using this neural\nnetwork, 57% of the time",
    "start": "4494980",
    "end": "4500460"
  },
  {
    "text": "it could pin where the\nexpert would place his move. That took 3,000 microseconds.",
    "start": "4500460",
    "end": "4505780"
  },
  {
    "text": "Versus the fast policy, which\nsuffered a bit in the accuracy, but it's 1,500 times faster.",
    "start": "4505780",
    "end": "4511259"
  },
  {
    "text": "And we'll see where\nthey used each of these different\npolicies later on. But it could predict the\nexpert move with 57% accuracy.",
    "start": "4511259",
    "end": "4520680"
  },
  {
    "text": "The other Go team was,\nthat's not our goal. We don't want to\npredict an expert move. We want to predict\na winning move. And so to do that, they\ntook their policy network,",
    "start": "4520680",
    "end": "4528179"
  },
  {
    "text": "and then they would use\nreinforcement learning. That's where you play the\nnetwork against iterations of itself in order to hone\nin a better policy that's",
    "start": "4528180",
    "end": "4535830"
  },
  {
    "text": "geared towards winning moves. Then they tested this\nagainst Pachi, which uses--",
    "start": "4535830",
    "end": "4542889"
  },
  {
    "text": "for the camera, I\nhave no idea if that's how you pronounce Pachi. It might be Patchey. I'm not sure. But there's 100,000 MCTS\nsimulations at each turn.",
    "start": "4542889",
    "end": "4552329"
  },
  {
    "text": "So this is purely MCTS. If it were playing just\nthe AlphaGo policy network,",
    "start": "4552330",
    "end": "4559842"
  },
  {
    "text": "the policy network\nwon 85% of the game. So without any sort of trained\nsearch or anything involved,",
    "start": "4559842",
    "end": "4566780"
  },
  {
    "text": "it won 85%, which\nis pretty great. And that suggests that\nmaybe intuition wins",
    "start": "4566780",
    "end": "4571810"
  },
  {
    "text": "over long reflections in Go. And interestingly, if you\ntalk to expert Go players and you ask them why they did a\ncertain move, they'll just say,",
    "start": "4571810",
    "end": "4579340"
  },
  {
    "text": "It felt good, or I\nhad a hunch in this. That's indicative there.",
    "start": "4579340",
    "end": "4586659"
  },
  {
    "text": "Hopefully, I'm not\ngoing overtime. Sorry. Those are the two\npolicy networks. There's also a value network.",
    "start": "4586660",
    "end": "4592713"
  },
  {
    "text": "What the value network does\nis it takes in a board, and they'll give you a value,\nlike how good is this board?",
    "start": "4592713",
    "end": "4600140"
  },
  {
    "text": "They'll give you a win\nprobability number. So 77%, it would say,\n77% of the time you",
    "start": "4600140",
    "end": "4605592"
  },
  {
    "text": "should win from the board. That's similar to the evaluation\nthat comes from Deep Blue. But rather than a Go master\ncoming in and telling you,",
    "start": "4605592",
    "end": "4613570"
  },
  {
    "text": "well, if these are\nconnected in this way, and down here we have\nthis certain thing then here's the score\nwe should expect,",
    "start": "4613570",
    "end": "4620060"
  },
  {
    "text": "in chess, they\nhad chess masters, like if the knight is here\nand the queen is here, all these specific things. This was actually learned from\nthe reinforcement learning that",
    "start": "4620060",
    "end": "4627649"
  },
  {
    "text": "was happening when the\npolicy networks were playing each other. The value network was\nlearning about those positions",
    "start": "4627649",
    "end": "4632890"
  },
  {
    "text": "during that time. And the predictions get\nbetter towards the end of the game, which I think\nYo mentioned in his talk.",
    "start": "4632890",
    "end": "4641590"
  },
  {
    "text": "So how do you combine\nall these into MCTS? The slow policy network,\nif you remember, is slower but should\ngive us stronger moves.",
    "start": "4641590",
    "end": "4647830"
  },
  {
    "text": "It is used to guide our\ntree search in order to help us decide which\nnodes to expand next.",
    "start": "4647830",
    "end": "4653322"
  },
  {
    "text": "When we expand that\nnode to get the value, the value of the state is\nthe simulation, like before,",
    "start": "4653322",
    "end": "4658389"
  },
  {
    "text": "like normal MCTS,\nexcept it's not a completely random simulation. We use our fast policy network\nto give us a more educated",
    "start": "4658390",
    "end": "4665200"
  },
  {
    "text": "simulation here. But we're using a\nfast one, obviously, to save some computation time. It's giving us probably a more\nindicative random simulation",
    "start": "4665200",
    "end": "4673810"
  },
  {
    "text": "of what's going to\nactually happen. And then we also combine that\nwith our value network output.",
    "start": "4673810",
    "end": "4678830"
  },
  {
    "text": "So we run our value network\non this node, as well. And we add that to\nour simulation value and we propagate it. Interestingly, the\nAlphaGo team tested out",
    "start": "4678830",
    "end": "4686440"
  },
  {
    "text": "just using the fast\npolicy simulation value and scrapping the value network. And they also just\nused the value network",
    "start": "4686440",
    "end": "4693160"
  },
  {
    "text": "and scrapped the\nsimulation value. And those both performed\nworse than if it had these. And another added\ninteresting point here,",
    "start": "4693160",
    "end": "4699625"
  },
  {
    "text": "is that these two\nfactors in our value have about the same weight. They were both about\nequally important.",
    "start": "4699625",
    "end": "4707969"
  },
  {
    "text": "I think I'll get\ninto that later. But first-- AUDIENCE: Can I just\nask a quick question? PROFESSOR 3: Yeah.",
    "start": "4707970",
    "end": "4713980"
  },
  {
    "text": "AUDIENCE: So when you said\nthe policy network is used, is that used when you're\nnavigating to the tree to get to a leaf,\nor is policy network",
    "start": "4713980",
    "end": "4720350"
  },
  {
    "text": "being used to do the\nsimulation once you're at the leaf, or both?",
    "start": "4720350",
    "end": "4726340"
  },
  {
    "text": "PROFESSOR 3: The slow policy\nis done for this part. Then the fast policy is\nused for the simulation. Because the slow policy does\ntake 1,500 faster than--",
    "start": "4726340",
    "end": "4734454"
  },
  {
    "text": "or the slow takes 1,500 times\nlonger than the fast policy. You don't want to use\nthat in your simulations.",
    "start": "4734455",
    "end": "4740010"
  },
  {
    "text": "That would just\ntake way too long. It's basically just\na way of making it so our simulation isn't\ncompletely random.",
    "start": "4740010",
    "end": "4745260"
  },
  {
    "text": "It has some educated moves.  Why use policy and\nvalue network synergy?",
    "start": "4745260",
    "end": "4751392"
  },
  {
    "text": "Why can't we just use\nthe policy network? Why can't we just use\nthe value network? If we have the\nvalue network alone,",
    "start": "4751392",
    "end": "4756920"
  },
  {
    "text": "we'll actually--\nhere's a side point. Remember, the value\nnetwork learned from the policy network. And then also, later\non, the policy network",
    "start": "4756920",
    "end": "4763139"
  },
  {
    "text": "is improved by our values. They work hand-in-hand. But if we had the\nvalue network alone,",
    "start": "4763140",
    "end": "4769114"
  },
  {
    "text": "when we're deciding\non it the next move, we're going to have to evaluate\nevery single move, which would take forever.",
    "start": "4769114",
    "end": "4774510"
  },
  {
    "text": "And so, what the\npolicy network does is project the best move\nwith a probably distribution.",
    "start": "4774510",
    "end": "4781039"
  },
  {
    "text": "And it narrows our search space. And then, if we had the\npolicy network alone, we'd be unable to compare nodes\nin different parts of our tree.",
    "start": "4781040",
    "end": "4788365"
  },
  {
    "text": "The policy network\nis able to tell us a distribution over\nwhich move we should take from a certain node.",
    "start": "4788366",
    "end": "4794230"
  },
  {
    "text": "But then, if I ask it if\nI'm in a better position here than in some other\nplace, it won't know.",
    "start": "4794230",
    "end": "4799724"
  },
  {
    "text": "That's where the value\nnetwork comes in. It will give us an estimated\nnumber of the value assigned",
    "start": "4799724",
    "end": "4806140"
  },
  {
    "text": "and open an evaluation\nof that node. And then these\nvalues are later used to direct our tree\nsearches based",
    "start": "4806140",
    "end": "4812860"
  },
  {
    "text": "on updating the policy\nonce it realizes, oh, I thought this would be\na good path but the value is",
    "start": "4812860",
    "end": "4819469"
  },
  {
    "text": "this, so update all that. Then why do we combine\nneural networks with MCTS?",
    "start": "4819470",
    "end": "4825440"
  },
  {
    "text": "Remember, the\npolicy network alone played against Pachi,\nwhich was purely MCTS,",
    "start": "4825440",
    "end": "4831000"
  },
  {
    "text": "and it did pretty well. So how does MCTS improve\nour policy network?",
    "start": "4831000",
    "end": "4837220"
  },
  {
    "text": "Remember, MCTS did win\n15% of those games. So already, that makes you\nthink there's something there",
    "start": "4837220",
    "end": "4844900"
  },
  {
    "text": "that maybe the policy\nnetwork is missing. Also, the policy network\nis just a prediction. So by using this\ntree structure, we're",
    "start": "4844900",
    "end": "4851410"
  },
  {
    "text": "able to use these Monte Carlo\nrollouts to adjust our policy",
    "start": "4851410",
    "end": "4857730"
  },
  {
    "text": "to move towards nodes that are\nactually evaluated to be good. And then, how do neural\nnetworks improve MCTS?",
    "start": "4857730",
    "end": "4863960"
  },
  {
    "text": "The point should\nprobably be clear by now. We're able to more intelligently\nlead our tree exploration.",
    "start": "4863960",
    "end": "4869929"
  },
  {
    "text": "Our simulations are more\nreflective of actual games. And the value network\nand our simulation value",
    "start": "4869930",
    "end": "4877530"
  },
  {
    "text": "are complementary, which\nI've mentioned before. And just to highlight that,\nbasically, the value network",
    "start": "4877530",
    "end": "4885150"
  },
  {
    "text": "is going to give us a\nvalue that is reflective as if we've played the\nslow policy the whole time.",
    "start": "4885150",
    "end": "4890680"
  },
  {
    "text": "And the simulation is if\nwe used a faster policy. So they are complementary.",
    "start": "4890680",
    "end": "4898070"
  },
  {
    "text": "And I know I'm over time. So I just wanted to skim\nthrough the stats real quick.",
    "start": "4898070",
    "end": "4904390"
  },
  {
    "text": "Distributed AlphaGo\nwon 77% of the games against regular AlphaGo. So it's the only thing\nthat beat regular AlphaGo.",
    "start": "4904390",
    "end": "4911080"
  },
  {
    "text": "And then distributed AlphaGo\nwon 100% of the games against all these. In a rematch against Pachi,\nnow that we've added MCTS",
    "start": "4911080",
    "end": "4917719"
  },
  {
    "text": "to our policy network and\nwe have our value network, we slaughtered Pachi 100%.",
    "start": "4917720",
    "end": "4923170"
  },
  {
    "text": "Then we decided to see how\nwe fare against humans. And by we, I mean not\nme, I mean Google.",
    "start": "4923170",
    "end": "4928540"
  },
  {
    "text": "And they won 4 to 1. And Lee Sedol rating was 3,520.",
    "start": "4928540",
    "end": "4934680"
  },
  {
    "text": "Now AlphaGo's rating is\nestimated to be about 3,586. So you're like, whoo,\nwe beat the best dude.",
    "start": "4934680",
    "end": "4939960"
  },
  {
    "text": "Except we didn't because\nthere's another dude who has an even higher\nscore, apparently, 3,621.",
    "start": "4939960",
    "end": "4951320"
  },
  {
    "text": "This should be the last part. Here's this timeline. Basically, tic-tac-toe,\ncheckers were conquered in '50.",
    "start": "4951320",
    "end": "4959410"
  },
  {
    "text": "About 40 years later, we\nconquered checkers, chess. Then we scroll down\nto 2015, is when",
    "start": "4959410",
    "end": "4965800"
  },
  {
    "text": "AlphaGo was able to\nbeat Fan Hui, who was a two-dan player, which\nis considered lower down",
    "start": "4965800",
    "end": "4971340"
  },
  {
    "text": "in the tier of professional Go. But then, Lee Sedol\nwas a nine-dan player.",
    "start": "4971340",
    "end": "4976469"
  },
  {
    "text": "And he was able to beat\nhim literally last month. PROFESSOR WILLIAMS: So good job.",
    "start": "4976470",
    "end": "4981520"
  },
  {
    "text": "PROFESSOR 3: We're done. [APPLAUSE] ",
    "start": "4981520",
    "end": "5004944"
  }
]
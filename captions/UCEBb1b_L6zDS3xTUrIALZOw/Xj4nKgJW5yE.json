[
  {
    "start": "0",
    "end": "42000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5580",
    "end": "12270"
  },
  {
    "text": "To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12270",
    "end": "18830"
  },
  {
    "text": "at ocw.mit.edu. SHIMON ULLMAN: Now for a\ndifferent, entirely different",
    "start": "18830",
    "end": "26720"
  },
  {
    "text": "type of issue that\nhas more to do with recognition, some\npsychophysics, some computer vision.",
    "start": "26720",
    "end": "32090"
  },
  {
    "text": "But you will see at the end\nthe motivation was really to be able to, be\nable to recognize",
    "start": "32090",
    "end": "37490"
  },
  {
    "text": "and understand really\ncomplicated things that are happening in natural images.",
    "start": "37490",
    "end": "44149"
  },
  {
    "start": "42000",
    "end": "194000"
  },
  {
    "text": "Now, when we look at\nobjects in the world,",
    "start": "44150",
    "end": "49500"
  },
  {
    "text": "people have worked a lot\nin object recognition, and we can recognize\nwell complete objects,",
    "start": "49500",
    "end": "55489"
  },
  {
    "text": "but we can also recognize a\nvery limited configuration",
    "start": "55490",
    "end": "60650"
  },
  {
    "text": "of objects. So we are very good at\nusing limited information if this is what's\navailable in order",
    "start": "60650",
    "end": "67100"
  },
  {
    "text": "to recognize what's in there. And this is some\narbitrary collection. I guess you can\nrecognize all of them.",
    "start": "67100",
    "end": "73970"
  },
  {
    "text": "Some of them, if you think\nabout a person or even a face-- this is a very small\npart of a face-- everybody I guess knows\nwhat it is, right?",
    "start": "73970",
    "end": "82409"
  },
  {
    "text": "It's not even a recognizable,\nwell-delineated part like an eye. You see a part of a person here. We know what it is, right?",
    "start": "82410",
    "end": "88729"
  },
  {
    "text": "I mean, everybody\nrecognizes this, and so on. Now, I think that\nthe ability to be",
    "start": "88730",
    "end": "96440"
  },
  {
    "text": "able to get all the information\nout even from a limited region",
    "start": "96440",
    "end": "101900"
  },
  {
    "text": "plays an important role\nin understanding images. And let me motivate\nit by one example.",
    "start": "101900",
    "end": "106939"
  },
  {
    "text": "I'll go back to it at the end. When we look at these images,\nwe know what's happening.",
    "start": "106940",
    "end": "113820"
  },
  {
    "text": "We know what the action here is. All the people are\nperforming the same action. They are all drinking, even\ndrinking from a bottle, right?",
    "start": "113820",
    "end": "121530"
  },
  {
    "text": "But the images as images\nare very different. If you look at each image,\nif you stored one image",
    "start": "121530",
    "end": "127160"
  },
  {
    "text": "and you try to recognize another\nimage based on the first one, it will be difficult. The\nvariability here can be huge.",
    "start": "127160",
    "end": "134000"
  },
  {
    "text": "But if you focus on\nwhere the action really takes place, the most\ninformative part where most of the answer is already\ngiven to you of what's",
    "start": "134000",
    "end": "141776"
  },
  {
    "text": "happening here, which is\nwhere the bottle is docked into the mouth, you can see\nthat now these diverse images",
    "start": "141776",
    "end": "147650"
  },
  {
    "text": "becomes virtually almost\na copy of one another, almost the same. So if you manage to\nunderstand this and extract",
    "start": "147650",
    "end": "156469"
  },
  {
    "text": "the most informative\npart, although it's limited and so on,\nthe variability",
    "start": "156470",
    "end": "162710"
  },
  {
    "text": "will be much, much reduced. The variability here\nis much, much reduced compared to the variability that\nyou have in the entire image.",
    "start": "162710",
    "end": "169859"
  },
  {
    "text": "So most of the other stuff\nis much less relevant, but this is where the\ninformation is concentrated.",
    "start": "169860",
    "end": "177230"
  },
  {
    "text": "And in the limited,\nrestricted configuration,",
    "start": "177230",
    "end": "182470"
  },
  {
    "text": "recognition will be much easier,\nand will generalize much better from one situation\nto another because",
    "start": "182470",
    "end": "188510"
  },
  {
    "text": "of this principle of\nhighly-reduced variability in the delimited image.",
    "start": "188510",
    "end": "194660"
  },
  {
    "start": "194000",
    "end": "246000"
  },
  {
    "text": "So we became interested. As you see, it's useful.",
    "start": "194660",
    "end": "201080"
  },
  {
    "text": "But it's also-- to deal\nwith small images and still",
    "start": "201080",
    "end": "206510"
  },
  {
    "text": "recognize the limited images,\nyou'll see it's much more-- there are some very\nchallenging issues.",
    "start": "206510",
    "end": "212727"
  },
  {
    "text": "And I want to discuss\nit a little bit, and then also discuss what it's\ngood for a little bit more.",
    "start": "212727",
    "end": "218989"
  },
  {
    "text": "I will show you\nsome human studies. What we wanted to\nsee is what are the minimal images that\npeople can still recognize.",
    "start": "218990",
    "end": "225560"
  },
  {
    "text": "We examined some computational\nmodels, and I will give you-- will not keep the secret.",
    "start": "225560",
    "end": "230780"
  },
  {
    "text": "It turns out that\nwell-performing current schemes, including\ndeep networks,",
    "start": "230780",
    "end": "236090"
  },
  {
    "text": "cannot deal well with\nsuch minimal images. And, from this, I want to\ndiscuss some implications",
    "start": "236090",
    "end": "242420"
  },
  {
    "text": "in terms of representations in\nour system, brain processing, and things like this.",
    "start": "242420",
    "end": "248209"
  },
  {
    "start": "246000",
    "end": "271000"
  },
  {
    "text": "And quite a number of people\nhave been involved in this. Here are the names.",
    "start": "248210",
    "end": "254342"
  },
  {
    "text": "Some of them are in the\nWeizmann Institute in Israel, and a few that-- Leyla is here.",
    "start": "254342",
    "end": "259769"
  },
  {
    "text": "Leyla Isik, she is here in the\nsummer school, and a student, Yena Han, at MIT doing\nsome brain imaging",
    "start": "259769",
    "end": "268460"
  },
  {
    "text": "on this, which I will\nmention very briefly. So I'll start with\nthe human study.",
    "start": "268460",
    "end": "273740"
  },
  {
    "start": "271000",
    "end": "409000"
  },
  {
    "text": "We are looking for minimal\natomic things in recognition, and the experiment\ngoes like this.",
    "start": "273740",
    "end": "280490"
  },
  {
    "text": "You show a subject an image\nand ask them to recognize it, just produce a label. So this is a dog.",
    "start": "280490",
    "end": "286040"
  },
  {
    "text": "If they say a dog,\nthey recognize it. And if they recognize\nit correctly,",
    "start": "286040",
    "end": "292760"
  },
  {
    "text": "we generate five descendants\nfrom this initial image.",
    "start": "292760",
    "end": "297770"
  },
  {
    "text": "If this image was,\nsay, 50 by 50 pixels-- and I'll tell you about\npixels in a minute. But say it's 50 by 50 pixels.",
    "start": "297770",
    "end": "304810"
  },
  {
    "text": "We make it somewhat smaller. We reduce use it, because\nit's still not minimal. And we reduce it in five ways.",
    "start": "304810",
    "end": "310870"
  },
  {
    "text": "We either copy it at\none of the four corners to create, say, a 48\nby 48 image by taking",
    "start": "310870",
    "end": "319000"
  },
  {
    "text": "two pixels from\nthis corner here, or this corner here, and so\non and so forth descendants. And we generate-- we\nalso take the full image.",
    "start": "319000",
    "end": "326210"
  },
  {
    "text": "Keep it as is. We do not crop it. We just reduce the resolution.",
    "start": "326210",
    "end": "331240"
  },
  {
    "text": "So we resample it so some\ndetails start to become lost.",
    "start": "331240",
    "end": "336610"
  },
  {
    "text": "Instead of 50 by 50 pixels, it's\nalso a full image but 48 by 48.",
    "start": "336610",
    "end": "342310"
  },
  {
    "text": "And then we give each\none of these images-- now we have five. We give each one-- this is\nbeginning to expand as a tree.",
    "start": "342310",
    "end": "349870"
  },
  {
    "text": "Each one of the five is\ngiven again to a subject. If they recognize it,\nagain five descendants",
    "start": "349870",
    "end": "355210"
  },
  {
    "text": "are being generated, and\nwe explore the entire tree until we find all\nthe sub-images which",
    "start": "355210",
    "end": "360400"
  },
  {
    "text": "are minimal and\ncan be recognizable",
    "start": "360400",
    "end": "365470"
  },
  {
    "text": "in this original configuration. Now, this is challenging\npsychophysically",
    "start": "365470",
    "end": "371110"
  },
  {
    "text": "in terms of number of\nsubjects, because we use a subject only once. Because if you\nshow a subject this",
    "start": "371110",
    "end": "376820"
  },
  {
    "text": "and he recognizes\nit, if you show him the same subject,\na reduced image, he will recognize the image\nbased on his previous exposure.",
    "start": "376820",
    "end": "384430"
  },
  {
    "text": "So you don't you do not\nwant to use him again. So you don't use him again,\nand you show the other images to a new subject.",
    "start": "384430",
    "end": "391256"
  },
  {
    "text": "And this requires a\nlarge number of subjects. So 15,000 subjects\nparticipated in this experiment",
    "start": "391256",
    "end": "397960"
  },
  {
    "text": "online by Mechanical Turk,\ntogether with some laboratory controls to see that they\nare doing the right thing,",
    "start": "397960",
    "end": "403070"
  },
  {
    "text": "and how it compares with\nthe same experiment done under laboratory\nconditions, and so on.",
    "start": "403070",
    "end": "409930"
  },
  {
    "start": "409000",
    "end": "697000"
  },
  {
    "text": "So the way we define the\nminimal image for recognition is in this tree.",
    "start": "409930",
    "end": "414970"
  },
  {
    "text": "Here is an image. This image is recognizable. And then we create\nthe five descendants,",
    "start": "414970",
    "end": "420970"
  },
  {
    "text": "and none of the descendants\nis recognizable. So this is recognizable. Nothing here is recognizable. So it's minimal because\nyou can no longer reduce it",
    "start": "420970",
    "end": "429220"
  },
  {
    "text": "either by resolution going\nhere or by reducing the size. Any manipulation like this\nwill make it unrecognizable.",
    "start": "429220",
    "end": "437830"
  },
  {
    "text": "Technically, when\nI'm-- in my measuring, if I'm using numbers that\nthe image is 50 pixels or 35",
    "start": "437830",
    "end": "444730"
  },
  {
    "text": "pixels, and so, it's\nactually well-defined. I mean not the\npixels on the screen. You can take the image and\nmake it bigger or smaller",
    "start": "444730",
    "end": "452080"
  },
  {
    "text": "on the screen. But the number of sampling\npoints in the image is well-defined. When you give me an\nimage, a particular image,",
    "start": "452080",
    "end": "458900"
  },
  {
    "text": "I can tell you how many sample\npoints you need in order to capture this image. Technically, for those of you\nwho know it, it's twice the--",
    "start": "458900",
    "end": "466960"
  },
  {
    "text": "if you do a Fourier transform\nand take twice the cutoff",
    "start": "466960",
    "end": "472539"
  },
  {
    "text": "frequency, the highest frequency\nin the Fourier spectrum, this is, by the sampling\ntheorem of Shannon,",
    "start": "472540",
    "end": "477640"
  },
  {
    "text": "this is the number of\npoints you need in order to. So when I said that the\nimage was 35 pixels,",
    "start": "477640",
    "end": "484390"
  },
  {
    "text": "I don't really care. You can make it somewhat\nsmaller or larger",
    "start": "484390",
    "end": "489980"
  },
  {
    "text": "on the screen by interpolation. It doesn't change the\ninformation content. It's well-defined\nnotion mathematically",
    "start": "489980",
    "end": "496240"
  },
  {
    "text": "how many points, discrete\npoints or sampling points in these images.",
    "start": "496240",
    "end": "502870"
  },
  {
    "text": "So a very interesting\nthing that we found when we found\nthese minimal images",
    "start": "502870",
    "end": "511870"
  },
  {
    "text": "is that there is a\nsharp transition when you get to the level\nof the minimal images. So you go down and\nyou recognize it.",
    "start": "511870",
    "end": "519789"
  },
  {
    "text": "And then there is\na sharp transition that it suddenly becomes\nunrecognizable, basically,",
    "start": "519789",
    "end": "528410"
  },
  {
    "text": "to the large majority of people. So it can change a little bit,\nand I'll show you some examples for you to try to see how\nthese minimal images look",
    "start": "528410",
    "end": "537400"
  },
  {
    "text": "like at the recognizable\nlevel, at the unrecognizable. This is the recognizable level. This is the\nunrecognizable level.",
    "start": "537400",
    "end": "543790"
  },
  {
    "text": "So to show it to you\nas examples here, I will show you first\nthe unrecognizable one,",
    "start": "543790",
    "end": "549310"
  },
  {
    "text": "the one which people\nfind, on average, more difficult to recognize. And if you recognize\nit, raise your hand.",
    "start": "549310",
    "end": "555810"
  },
  {
    "text": "Don't say what you\nsee, because this will influence other people. Just raise your hand if\nyou recognize the image.",
    "start": "555810",
    "end": "562259"
  },
  {
    "text": "And then I'll show you\nthe more recognizable one, and let's see if\nmore hands show up, if the distinction between the\nrecognizable and unrecognizable",
    "start": "562259",
    "end": "570689"
  },
  {
    "text": "holds here. I'll just show you a couple\nof examples from the-- OK, so I'll.",
    "start": "570690",
    "end": "575790"
  },
  {
    "text": "OK, so this is the\none which is supposed to be difficult to recognize. If you see what it is, if\nyou know what's the object,",
    "start": "575790",
    "end": "581500"
  },
  {
    "text": "raise your hand. OK, good.",
    "start": "581500",
    "end": "586570"
  },
  {
    "text": "OK, don't say what it is. We have two. Let's see here.",
    "start": "586570",
    "end": "592362"
  },
  {
    "text": "OK, certainly more hands. What do you see? What do you think? AUDIENCE: Should I say it? SHIMON ULLMAN: OK. Now you can say it because-- AUDIENCE: A horse.",
    "start": "592362",
    "end": "597500"
  },
  {
    "text": "SHIMON ULLMAN: A horse. Right. So let me show\nthem side by side. So you see that\nit's very difficult",
    "start": "597500",
    "end": "603340"
  },
  {
    "text": "to recognize what's not recog-- this is, you can\nsee the statistic. This is recognized by\n93% of the subjects.",
    "start": "603340",
    "end": "609760"
  },
  {
    "text": "30 subjects saw each\none of these images. 93% recognized this. 3% recognized this.",
    "start": "609760",
    "end": "616480"
  },
  {
    "text": "And you look at\nthe image and you see that they are\nvery similar images, and it drops from 90% to 3%.",
    "start": "616480",
    "end": "622747"
  },
  {
    "text": "So you can see the two images,\nand you can see the similarity, and you can see the large drop.",
    "start": "622747",
    "end": "628540"
  },
  {
    "text": "This is part of the entire\ntree which is being explored. This is the farther.",
    "start": "628540",
    "end": "634240"
  },
  {
    "text": "This is the recognized one. The minimal image. And you can see that even reduce\nthe resolution, which is really",
    "start": "634240",
    "end": "641290"
  },
  {
    "text": "not a big manipulation, but\nthis is a drop in performance. And you can see all the-- so we used 50% as our criterion.",
    "start": "641290",
    "end": "650060"
  },
  {
    "text": "So the parents should\nbe recognized at higher. This should be\nrecognized at lower. But typically the\njump is very sharp.",
    "start": "650060",
    "end": "659829"
  },
  {
    "text": "Let's try two more or\nsomething just for fun. If you can recognize\nit, raise your hand.",
    "start": "659830",
    "end": "666974"
  },
  {
    "text": "OK. Nobody, just for the record. OK. Look around. You can see many.",
    "start": "666974",
    "end": "672100"
  },
  {
    "text": "What do you see? AUDIENCE: A boat. SHIMON ULLMAN: A boat. Right. So you can see the two images. So 80% on this.",
    "start": "672100",
    "end": "678209"
  },
  {
    "text": "0% here. And you can see that\nwhat's really missing here is the tip here.",
    "start": "678210",
    "end": "685300"
  },
  {
    "text": "And, clearly, this tip is-- there are many\ncontours in this image, but this particular corner sharp\nmakes an enormous difference,",
    "start": "685300",
    "end": "694180"
  },
  {
    "text": "and it goes from 80% to 0%. OK, let me skip.",
    "start": "694180",
    "end": "699820"
  },
  {
    "start": "697000",
    "end": "739000"
  },
  {
    "text": "Just one more. OK, let me skip this.",
    "start": "699820",
    "end": "706040"
  },
  {
    "text": "This is somewhat easier. OK. This is some-- OK, at least one,\ntwo, and three.",
    "start": "706040",
    "end": "711180"
  },
  {
    "text": "OK. How about this one? Everybody, I think. Or maybe we are missing one.",
    "start": "711180",
    "end": "716425"
  },
  {
    "text": "So, again, you can see that\nthe difference-- if you look at the two,\nthere is a difference, and it's this thing here.",
    "start": "716425",
    "end": "721570"
  },
  {
    "text": "But it's not a very\nbig part of the image. It's crucial, you know. You have to be trained on this. It's part of your\nrepresentation.",
    "start": "721570",
    "end": "727860"
  },
  {
    "text": "It's important. You go from almost\n90% to 15%, roughly. So it's important.",
    "start": "727860",
    "end": "733760"
  },
  {
    "text": "So you can see that the drop\nis typically very, very sharp. And it's also-- the sharp\ntransition is also interesting,",
    "start": "733760",
    "end": "745820"
  },
  {
    "start": "739000",
    "end": "802000"
  },
  {
    "text": "in the sense that if it\ndrops from, like the horse, from 90% to 3%, or\neven here, it also",
    "start": "745820",
    "end": "754040"
  },
  {
    "text": "says that we all carry\naround in our head a very similar presentation. Because if each one of\nus, based on the history",
    "start": "754040",
    "end": "763360"
  },
  {
    "text": "and visual experience,\nwould be less or more sensitive to various\nfeatures, then we",
    "start": "763360",
    "end": "769550"
  },
  {
    "text": "will not find this\nsharp transition. Different people will lose\nit at different points in the manipulation.",
    "start": "769550",
    "end": "776360"
  },
  {
    "text": "But at 90%, 90% of the\npeople, roughly everybody recognizes it. You remove a feature\nand it goes to 3%.",
    "start": "776360",
    "end": "783950"
  },
  {
    "text": "So everybody is using the\nsame, or very similar,",
    "start": "783950",
    "end": "788990"
  },
  {
    "text": "representation, which I find\nsomewhat surprising, at least for some of these images.",
    "start": "788990",
    "end": "794540"
  },
  {
    "text": "We don't all have the\nsame kind of experience with horses, or with\nbattleships, or things like that, and still\nthe representation",
    "start": "794540",
    "end": "800660"
  },
  {
    "text": "is very strikingly similar\nacross individuals. The experiment was done\non 10 different objects.",
    "start": "800660",
    "end": "807470"
  },
  {
    "start": "802000",
    "end": "914000"
  },
  {
    "text": "These are the initial objects. I showed you the object at the\nbeginning of the hierarchy,",
    "start": "807470",
    "end": "813020"
  },
  {
    "text": "and then you start the\nmanipulation to discover all the minimal images inside them.",
    "start": "813020",
    "end": "821550"
  },
  {
    "text": "And here, so we ended up\nwith a very nice catalog. We have a database of\nall the minimal images",
    "start": "821550",
    "end": "826640"
  },
  {
    "text": "in all of these 10 images\nin all of the children, the unrecognizable ones.",
    "start": "826640",
    "end": "832029"
  },
  {
    "text": "So, in terms of\nmodeling and in terms of exploring visual features\nand what is necessary in order",
    "start": "832030",
    "end": "837140"
  },
  {
    "text": "to recognize, and so on,\nthere is a very rich data set here of all\nthe minimal images",
    "start": "837140",
    "end": "842210"
  },
  {
    "text": "in all of these 10 images. Here are some more pairs\nof recognizable and",
    "start": "842210",
    "end": "849680"
  },
  {
    "text": "unrecognizable. We already saw\nthis in principle, but just to show some-- in some cases, it's pretty\nclear what may be going on.",
    "start": "849680",
    "end": "857600"
  },
  {
    "text": "For example, this is horse legs,\nthe front legs of the horse. This seems to be important.",
    "start": "857600",
    "end": "865050"
  },
  {
    "text": "You can see that very\noften it's a tremendously small-- in this fly image,\nvery small differences,",
    "start": "865050",
    "end": "871970"
  },
  {
    "text": "very hard to pinpoint. And it's glass that you've\ngot in the eyeglasses.",
    "start": "871970",
    "end": "878870"
  },
  {
    "text": "Something here is\nmissing a little bit. But very small things\nin a very reliable way cause this dramatic change.",
    "start": "878870",
    "end": "886820"
  },
  {
    "text": "As was mentioned here,\nsomebody mentioned, said the inflection and point, you\ncan manipulate psychophysically",
    "start": "886820",
    "end": "892770"
  },
  {
    "text": "a bit more. For example, here, this\nwas another version",
    "start": "892770",
    "end": "900980"
  },
  {
    "text": "of a minimal image. It was cropped at two locations. You can crop only\nthe left side, or you",
    "start": "900980",
    "end": "907730"
  },
  {
    "text": "can crop only the bottom\nside, and you can try to see what makes a difference. So you can really zoom in\non the critical features.",
    "start": "907730",
    "end": "916370"
  },
  {
    "start": "914000",
    "end": "967000"
  },
  {
    "text": "In terms of number of\npixels, the impression is that it's surprisingly small.",
    "start": "916370",
    "end": "921440"
  },
  {
    "text": "So I guess you can recognize\nthat this is an eagle. This is an airplane. And the number of pixels-- ",
    "start": "921440",
    "end": "930740"
  },
  {
    "text": "those of you who know\nvision, your retina has 120 million pixels.",
    "start": "930740",
    "end": "937759"
  },
  {
    "text": "The fovea, which is the area of\nvery high acuity, is 2 degrees.",
    "start": "937760",
    "end": "944890"
  },
  {
    "text": "It's about 250 by\n250, 250 by 200 pixel. This is the area at the\ncenter, an area of high acuity.",
    "start": "944890",
    "end": "951940"
  },
  {
    "text": "But you can recognize\nthings with, I don't know, 15, 20 pixels. It's 1/10 of your fovea.",
    "start": "951940",
    "end": "959040"
  },
  {
    "text": "It's tiny, tiny. You can make it\nlarger, but in terms of how much visual\ninformation, I",
    "start": "959040",
    "end": "966019"
  },
  {
    "text": "find it surprising that\nyou need very, very little. It's also interesting that\nit's very useful, in the sense",
    "start": "966020",
    "end": "971710"
  },
  {
    "start": "967000",
    "end": "1036000"
  },
  {
    "text": "that it's very redundant. If you have the capacity, if\nyou have a visual system that",
    "start": "971710",
    "end": "977060"
  },
  {
    "text": "can recognize individually each\none of these minimal images, and in fact they can be\nrecognized on their own,",
    "start": "977060",
    "end": "982490"
  },
  {
    "text": "then a full image like\nthis contains a high number of partially overlapping\nminimal images.",
    "start": "982490",
    "end": "990500"
  },
  {
    "text": "Some of them are large. You can see each one of\nthese frame, colored frame, is a minimal image,\nshown not necessarily",
    "start": "990500",
    "end": "997380"
  },
  {
    "text": "at the right resolution. You can reduce the\nresolution of things. But you can see that some\nimages are essentially",
    "start": "997380",
    "end": "1004660"
  },
  {
    "text": "low-resolution representations\nof the entire object, like almost the entire eagle.",
    "start": "1004660",
    "end": "1011170"
  },
  {
    "text": "But some of them just\ncontain something relatively small around\nthe head and the eye.",
    "start": "1011170",
    "end": "1020589"
  },
  {
    "text": "For the eye region,\nyou can see that you can get a low-resolution, again,\nthing of almost everything.",
    "start": "1020590",
    "end": "1027069"
  },
  {
    "text": "But just the corner\nof the eye and things like that are enough. We find, in general, it\nseems that things that",
    "start": "1027069",
    "end": "1032619"
  },
  {
    "text": "are related to humans,\nyou have a large number of these minimal images.",
    "start": "1032619",
    "end": "1038530"
  },
  {
    "start": "1036000",
    "end": "1076000"
  },
  {
    "text": "So they provide a sensitive\ntool to compare representations",
    "start": "1038530",
    "end": "1044619"
  },
  {
    "text": "to see what's missing\nin the sub-image which made the image become\nunrecognizable.",
    "start": "1044619",
    "end": "1051730"
  },
  {
    "text": "So we call them\nsometimes, these are called minimal\nrecognizable configuration.",
    "start": "1051730",
    "end": "1057830"
  },
  {
    "text": "We call them configuration\nbut not images. Not parts. Not objects because\nthey are not objects.",
    "start": "1057830",
    "end": "1063925"
  },
  {
    "text": "And not parts because, as\nwe saw in the examples, they do not have to be\nwell-delineated parts. They are more like\nlocal configuration.",
    "start": "1063925",
    "end": "1070630"
  },
  {
    "text": "But, anyway, minimal images. ",
    "start": "1070630",
    "end": "1077997"
  },
  {
    "start": "1076000",
    "end": "1202000"
  },
  {
    "text": "The next thing\nthat we did is, we were wondering if this kind\nof behavior, the ability",
    "start": "1077998",
    "end": "1090860"
  },
  {
    "text": "to recognize these images\nfrom such minimal information requires-- it places\nan interesting",
    "start": "1090860",
    "end": "1097880"
  },
  {
    "text": "challenge, or an interesting\ntest of a recognition system, because you really\nhave to extract and use",
    "start": "1097880",
    "end": "1104030"
  },
  {
    "text": "all the available information. By definition, this is minimal. If you do not use all\nthe information that's",
    "start": "1104030",
    "end": "1109760"
  },
  {
    "text": "in this minimal\nimage, then you don't have the minimal information. You have less than\nthat and you will fail.",
    "start": "1109760",
    "end": "1117290"
  },
  {
    "text": "So a system that\nis not good enough will fail on these minimal\nimages, or the ability",
    "start": "1117290",
    "end": "1123230"
  },
  {
    "text": "to recognize them means that\nyou really can suck out all",
    "start": "1123230",
    "end": "1128240"
  },
  {
    "text": "the relevant information out. So we were wondering what\nwill happen if we show it to various computational\nalgorithms that performed well",
    "start": "1128240",
    "end": "1138560"
  },
  {
    "text": "on full images. What will happen when\nyou challenge them with things which\nare, by nature,",
    "start": "1138560",
    "end": "1143600"
  },
  {
    "text": "designed to be non-redundant? So here is what I will do.",
    "start": "1143600",
    "end": "1148760"
  },
  {
    "text": "It's not a computer\nvision school. I will not go too much\nthrough the details",
    "start": "1148760",
    "end": "1155480"
  },
  {
    "text": "of the computational\nschemes, just to show you what was happening. And the bottom line is that\nthey are not doing a good job.",
    "start": "1155480",
    "end": "1162500"
  },
  {
    "text": "Two things happen. First of all, when you train\na computational system, you do not see the same\ndrop that you see here,",
    "start": "1162500",
    "end": "1169190"
  },
  {
    "text": "that it recognizes one and\ndoesn't recognize the other. You don't have a\ndrop in recognition.",
    "start": "1169190",
    "end": "1174320"
  },
  {
    "text": "This sort of phase\ntransition that characterizes the\nhuman vision system",
    "start": "1174320",
    "end": "1179810"
  },
  {
    "text": "is not reproduced in any of the\ncurrent recognition systems, including deep network\nand any other ones.",
    "start": "1179810",
    "end": "1188060"
  },
  {
    "text": "And, secondly, they are not\nvery good at recognizing them. Regardless of the gap, that\nthere is a sharp transition",
    "start": "1188060",
    "end": "1193280"
  },
  {
    "text": "or not, they do not get\ngood recognition results on these minimal images.",
    "start": "1193280",
    "end": "1199095"
  },
  {
    "text": "They do not suck all the\nnecessary information. So in the full\nimages, it's like we",
    "start": "1199095",
    "end": "1205490"
  },
  {
    "text": "had an image of a\nside view of a plane. So we are training on airplane. You can think of a deep network.",
    "start": "1205490",
    "end": "1211700"
  },
  {
    "text": "We actually tried a whole\nrange of good classifiers. And in all of these\ngood classifiers--",
    "start": "1211700",
    "end": "1218090"
  },
  {
    "text": "those of you who\nare not in vision probably got enough at the\nbeginning of this summer school",
    "start": "1218090",
    "end": "1224840"
  },
  {
    "text": "that they have a feeling for a\nclassifier in computer vision. It's a system, an algorithm,\na system, a scheme,",
    "start": "1224840",
    "end": "1232010"
  },
  {
    "text": "that you give it\ntraining images. You don't have to specify, you\ndon't tell it what to look for. You just give it lots\nof images and tell them",
    "start": "1232010",
    "end": "1239490"
  },
  {
    "text": "all these are of the same class. And then it calibrates itself,\nand adjusts parameters,",
    "start": "1239490",
    "end": "1245250"
  },
  {
    "text": "and so on. And then you give it new\nimages, and the system is supposed to tell you if it's\na new member of the same class",
    "start": "1245250",
    "end": "1252830"
  },
  {
    "text": "or not. So, in this case,\nwe train the system, giving them full side\nviews of an airplane.",
    "start": "1252830",
    "end": "1259940"
  },
  {
    "text": "But then we gave\nthem just the tails. Compared to random pictures\ntaken from known images,",
    "start": "1259940",
    "end": "1267890"
  },
  {
    "text": "the question is do they\nreliably can tell you that this is a tail\nof an airplane, part",
    "start": "1267890",
    "end": "1274370"
  },
  {
    "text": "of the previous class? Or they would be\nconfused and they will give even higher score\nto things which do not",
    "start": "1274370",
    "end": "1281990"
  },
  {
    "text": "come from airplane at all? So we started this when\ndeep networks were still not",
    "start": "1281990",
    "end": "1289429"
  },
  {
    "text": "the leaders, and we had\nsome other things, like DPM, and including HMAX,\nwhich is a very good model of the human visual\nsystem and performs very well.",
    "start": "1289430",
    "end": "1298580"
  },
  {
    "text": " And so we included it as well,\nand deep network as well.",
    "start": "1298580",
    "end": "1305680"
  },
  {
    "text": "This is the HMAX. This is convolutional\nneural networks.",
    "start": "1305680",
    "end": "1310730"
  },
  {
    "start": "1308000",
    "end": "1410000"
  },
  {
    "text": "You probably got the idea,\nit's just worth pointing, I find it interesting in the\ncomputer vision community",
    "start": "1310730",
    "end": "1317570"
  },
  {
    "text": "that you have Olympic\ngames every year. It's something which is\nvery structured and very",
    "start": "1317570",
    "end": "1322790"
  },
  {
    "text": "competitive, and very\nnice in this regard, that there is the\nPascal challenge,",
    "start": "1322790",
    "end": "1327830"
  },
  {
    "text": "and the ImageNet challenge,\nand it's well run. And people who think\nthat they have a better",
    "start": "1327830",
    "end": "1332929"
  },
  {
    "text": "algorithm than others\ncan submit an entry, can submit an algorithm.",
    "start": "1332930",
    "end": "1338330"
  },
  {
    "text": "Everybody gets training images\nthat are distributed publicly, but there are secret\nimages used for testing.",
    "start": "1338330",
    "end": "1345380"
  },
  {
    "text": "And you can train your\nalgorithm on the available data. Everybody uses the same data.",
    "start": "1345380",
    "end": "1351200"
  },
  {
    "text": "And then you submit\nyour algorithm, and the algorithm is run by the\ncentral committee on the test",
    "start": "1351200",
    "end": "1356360"
  },
  {
    "text": "images. And the results are published,\nand everybody knows who's number one, who's number two.",
    "start": "1356360",
    "end": "1361380"
  },
  {
    "text": "You have the gold medal\nand the silver medal. It's very competitive,\nand in some sense",
    "start": "1361380",
    "end": "1368570"
  },
  {
    "text": "it's doing very good things. It's sort of driving\nthe performance up.",
    "start": "1368570",
    "end": "1374490"
  },
  {
    "text": "It also has some\nnegative effects, I think, on the way\nthings are being done.",
    "start": "1374490",
    "end": "1383610"
  },
  {
    "text": "One negative is\nit's very difficult to come up with an\nentirely new scheme which explores a completely new idea.",
    "start": "1383610",
    "end": "1390980"
  },
  {
    "text": "Because, initially,\nbefore you fine tune it, it will not be at the level of\nthe high-performing winners,",
    "start": "1390980",
    "end": "1400340"
  },
  {
    "text": "and until it establishes\nitself as a winner, it will not get credit. So it sort of becomes a\nlittle bit conservative",
    "start": "1400340",
    "end": "1408980"
  },
  {
    "text": "in this regard, which\nis the unfortunate part. So, as I told you, and I\nwill not go in great detail,",
    "start": "1408980",
    "end": "1416390"
  },
  {
    "start": "1410000",
    "end": "1654000"
  },
  {
    "text": "the two basic outcomes\nis that the gap between the recognizable and\nrecognizable-- these two bars",
    "start": "1416390",
    "end": "1424480"
  },
  {
    "text": "are the gap for human vision. That's the whole\ngroup of horse images.",
    "start": "1424480",
    "end": "1432280"
  },
  {
    "text": "The parents are\nhighly recognizable. The children, the offsprings,\nare not recognizable.",
    "start": "1432280",
    "end": "1439910"
  },
  {
    "text": "Very large drop. This drop is not\nrecaptured in this model,",
    "start": "1439910",
    "end": "1447080"
  },
  {
    "text": "in any of the model. If you have a deep\nnetwork, or you have one of these\nclassifiers, what",
    "start": "1447080",
    "end": "1453470"
  },
  {
    "text": "is recognized and not recognized\ndepends on the threshold. You can decide that. It gives you a\nnumber, and it says that I have this\nand this confidence",
    "start": "1453470",
    "end": "1459860"
  },
  {
    "text": "that this belongs to the class. So what we did here is\nthat we tried to match.",
    "start": "1459860",
    "end": "1464890"
  },
  {
    "text": "We had a class of images,\nand people recognized them at 80% recognition.",
    "start": "1464890",
    "end": "1470760"
  },
  {
    "text": "So we put the threshold in the\nartificial, the computer vision system, at such a level\nthat it recognized correctly",
    "start": "1470760",
    "end": "1478160"
  },
  {
    "text": "80% of the minimal images.",
    "start": "1478160",
    "end": "1485180"
  },
  {
    "text": "So you match them. And then we looked at how\nmany of the sub-images",
    "start": "1485180",
    "end": "1491210"
  },
  {
    "text": "passed the threshold. And you get-- this\nis for deep network-- that, instead of a gap, you\nactually got an anti-gap.",
    "start": "1491210",
    "end": "1497980"
  },
  {
    "text": "It actually\nrecognized a few more. But this should not confuse you. It does not mean that the deep\nnetwork did better than humans.",
    "start": "1497980",
    "end": "1505625"
  },
  {
    "text": "It actually did much\nworse than humans, although the bars\nhere are higher.",
    "start": "1505625",
    "end": "1510677"
  },
  {
    "text": "And the reason is the following. You can always, even in\na very bad classifier, you can get 80% recognition by\njust lowering the threshold,",
    "start": "1510677",
    "end": "1518299"
  },
  {
    "text": "and then 80% of\nthe class examples will exceed the threshold. The question is how\nmany just garbage image,",
    "start": "1518300",
    "end": "1525600"
  },
  {
    "text": "non-class images, will also pass\nthe threshold at the same time. If you get 80% of the\nclass but also lots",
    "start": "1525600",
    "end": "1532130"
  },
  {
    "text": "and lots and lots of\ncompletely false positive, negative images,\nnon-class images",
    "start": "1532130",
    "end": "1537920"
  },
  {
    "text": "are also saying I'm an airplane,\nthen that's bad performance. So just these high bars\ndo not say anything.",
    "start": "1537920",
    "end": "1546250"
  },
  {
    "text": "The actual recognition\nlevels were very low.",
    "start": "1546250",
    "end": "1553370"
  },
  {
    "text": "We can see here\nfor deep networks that this high bar is the\nperformance on new airplanes.",
    "start": "1553370",
    "end": "1558640"
  },
  {
    "text": "So for airplanes\nit did very well. But the percent correct that\nit did on minimal images",
    "start": "1558640",
    "end": "1563809"
  },
  {
    "text": "were 3%, or 4%, were\nvery, very, very low. So it did very bad recognition\non the minimal images.",
    "start": "1563810",
    "end": "1574700"
  },
  {
    "text": "So recognition of\nminimal images does not emerge by training any\nof the existing models",
    "start": "1574700",
    "end": "1579919"
  },
  {
    "text": "that I know in the world,\nincluding deep network models.",
    "start": "1579920",
    "end": "1587790"
  },
  {
    "text": "Now, the second test\nwas, as was asked here, is that we did\nanother large test.",
    "start": "1587790",
    "end": "1594440"
  },
  {
    "text": "All of these things,\nactually, were a lot of effort and time-consuming. Because now we have this.",
    "start": "1594440",
    "end": "1600065"
  },
  {
    "text": "This was in the original\ntest, was a minimal image. I don't know if this\nwas a minimal image.",
    "start": "1600065",
    "end": "1605409"
  },
  {
    "text": "Then we collected a\nrange of tails of planes",
    "start": "1605410",
    "end": "1611090"
  },
  {
    "text": "like this for many\nother airplanes. And we ran another\nTurk experiment, which",
    "start": "1611090",
    "end": "1620810"
  },
  {
    "text": "was pretty large\nbecause we wanted to verify that each one of\nthese patches that we added",
    "start": "1620810",
    "end": "1629090"
  },
  {
    "text": "to our test and we were going\nto use for testing recognition, was indeed a minimal\nimage for recognition.",
    "start": "1629090",
    "end": "1634710"
  },
  {
    "text": "So each one of these patches,\nand there were 60 of those, we ran psychophysically.",
    "start": "1634710",
    "end": "1642350"
  },
  {
    "text": "And we saw that\nit's recognizable, and if you make it small,\nif you try to reduce it,",
    "start": "1642350",
    "end": "1647690"
  },
  {
    "text": "it's unrecognizable. So each one of these\nis individually also a minimal image. So here we did training\nand testing on--",
    "start": "1647690",
    "end": "1655429"
  },
  {
    "start": "1654000",
    "end": "1664000"
  },
  {
    "text": "so this is some\nexamples of this. So here are various images\nof fly, and each one of them",
    "start": "1655430",
    "end": "1661580"
  },
  {
    "text": "was tested on 30 subjects\non the Mechanical Turk. And the results are that, in\nterms of correct recognition,",
    "start": "1661580",
    "end": "1669789"
  },
  {
    "start": "1664000",
    "end": "2072000"
  },
  {
    "text": "there is a substantial\nimprovement from 3% to 60%.",
    "start": "1669790",
    "end": "1674830"
  },
  {
    "text": "But 60% is not very large. People recognized them-- ",
    "start": "1674830",
    "end": "1680650"
  },
  {
    "text": "I should say you should\nlook at the false alarm. The number of errors,\nI will show you later.",
    "start": "1680650",
    "end": "1686890"
  },
  {
    "text": "The number of errors\nthat, even after training on minimal images, the\nperformance of the deep network",
    "start": "1686890",
    "end": "1698049"
  },
  {
    "text": "and all the other models\non the minimal images is far worse than\nhuman recognition",
    "start": "1698050",
    "end": "1703809"
  },
  {
    "text": "levels, human performance,\non the same image. So it's not just the\ngap is not reproduced.",
    "start": "1703810",
    "end": "1709450"
  },
  {
    "text": "Even training with\nminimal images, the performance\nis not reproduced.",
    "start": "1709450",
    "end": "1717010"
  },
  {
    "text": "The errors, or the\naccuracy, is far worse in all the models,\nincluding deep network,",
    "start": "1717010",
    "end": "1724240"
  },
  {
    "text": "compared to human vision. So these systems do not do it.",
    "start": "1724240",
    "end": "1730540"
  },
  {
    "text": "It remains to be--\nyou can always ask, what happens if I train it\nwith 100,000 images and I add",
    "start": "1730540",
    "end": "1737059"
  },
  {
    "text": "and add more and more examples? This we couldn't-- this\nbecomes more and larger. But with the\nexperiments we've done,",
    "start": "1737060",
    "end": "1745210"
  },
  {
    "text": "which are quite\nextensive, it does not begin to approach\nhuman accuracy.",
    "start": "1745210",
    "end": "1751840"
  },
  {
    "text": "Humans are much better. And I'll show you. I think it's not just a\ncompetition, who does better.",
    "start": "1751840",
    "end": "1760240"
  },
  {
    "text": "I think there is\nsomething deeper there. And that's what I\nwant to go next. Let me skip some. These are the error comparison.",
    "start": "1760240",
    "end": "1766390"
  },
  {
    "text": "And you can see, just as we saw,\nin a lot of different examples, 0 errors for humans, 17%\nerror in the deep networks,",
    "start": "1766390",
    "end": "1773980"
  },
  {
    "text": "and so on. So those are big differences. OK.",
    "start": "1773980",
    "end": "1779080"
  },
  {
    "text": " A related thing which, I\nthink, gets to the heart",
    "start": "1779080",
    "end": "1785690"
  },
  {
    "text": "of what's going on, that humans\ncan do with these minimal images and model, at\nthe moment cannot,",
    "start": "1785690",
    "end": "1792470"
  },
  {
    "text": "is that we not only recognize\nthese images and say this is a man, this is an\neagle, this is a horse.",
    "start": "1792470",
    "end": "1799760"
  },
  {
    "text": "Once we recognize it,\nalthough the image itself is sort of atomic, in\nthe sense that you reduce it",
    "start": "1799760",
    "end": "1806149"
  },
  {
    "text": "and recognition goes away,\nbut once we recognize it we can recognize sort\nof subatomic particles.",
    "start": "1806150",
    "end": "1811880"
  },
  {
    "text": "We can recognize\nthings inside it. So if this is a\nperson, we ask again in the psychophysical\ntest to tell us",
    "start": "1811880",
    "end": "1819230"
  },
  {
    "text": "what you see inside the image\nusing various methodologies,",
    "start": "1819230",
    "end": "1824910"
  },
  {
    "text": "which I'll not go into. But people recognize this. This is a person\nin an Italian suit,",
    "start": "1824910",
    "end": "1830810"
  },
  {
    "text": "for those of you who\ncould not recognize it. But once people\nrecognize it, they say, this is the neck of the person. This is the tie.",
    "start": "1830810",
    "end": "1836240"
  },
  {
    "text": " This is the knot of the tie. This is part of the jacket,\nand so on and so forth.",
    "start": "1836240",
    "end": "1843299"
  },
  {
    "text": "I mean, they recognize\na whole lot of details, semantic internal\ndetails inside.",
    "start": "1843300",
    "end": "1849620"
  },
  {
    "text": "If they see this is the\nhorse, the contrast is low, but they see the ear,\nand the other ear,",
    "start": "1849620",
    "end": "1856210"
  },
  {
    "text": "and the eye, and the mouth. But if you reduce the image,\nthey lose the recognition completely. Once they recognize it,\nthey recognize a whole lot",
    "start": "1856210",
    "end": "1863720"
  },
  {
    "text": "of structure inside. And I think that the\nstructure, by itself,",
    "start": "1863720",
    "end": "1868879"
  },
  {
    "text": "is the more interesting\npart, because, really, we don't want to see a horse. We don't want to see a car.",
    "start": "1868879",
    "end": "1874400"
  },
  {
    "text": "We want to know where the car\ndoor is, where the knob is. We want to recognize all\nthe internal details.",
    "start": "1874400",
    "end": "1880880"
  },
  {
    "text": "But the ability to recognize\nall of these internal details is, automatically,\nit's also helping you",
    "start": "1880880",
    "end": "1886429"
  },
  {
    "text": "with improving the\nrecognition and rejecting sort of false detections. Because these are\nimages the deep network",
    "start": "1886430",
    "end": "1892760"
  },
  {
    "text": "thought that are good\nimages of a man in a suit. But once you dive inside and you\nsay, where exactly is the neck",
    "start": "1892760",
    "end": "1899630"
  },
  {
    "text": "and where exactly is the tie,\nand is it the right structure that I expect? The answer is that it's\nnot quite appropriate.",
    "start": "1899630",
    "end": "1907160"
  },
  {
    "text": "And you can use that so that\nthis internal interpretation is, first of all, the more\nimportant goal of vision.",
    "start": "1907160",
    "end": "1914570"
  },
  {
    "text": "But, in addition,\nonce you do it, you can reject\nthings that appeared,",
    "start": "1914570",
    "end": "1921350"
  },
  {
    "text": "based on the causal structure,\nto be correct, and in this way",
    "start": "1921350",
    "end": "1928130"
  },
  {
    "text": "you can get the\ncorrect recognition. And, for this\nreason, my prediction",
    "start": "1928130",
    "end": "1934499"
  },
  {
    "text": "is that it will be very\ndifficult to get it with current deep network,\nbecause what you'd need is not only to get the label\nout but to be able to dive",
    "start": "1934499",
    "end": "1942380"
  },
  {
    "text": "down and get the correct\ninterpretation, and inspect it. And it has some properties.",
    "start": "1942380",
    "end": "1948010"
  },
  {
    "text": "The tie, the knot in the\ntie is slightly wider than the part under\nit, and so on.",
    "start": "1948010",
    "end": "1955484"
  },
  {
    "text": "So you have to check for\nthe-- you know these things and you check for them. And if you don't do it,\nthen the recognition",
    "start": "1955484",
    "end": "1961955"
  },
  {
    "text": "will remain limited. Now, when you look at\nit and you say, OK,",
    "start": "1961955",
    "end": "1968210"
  },
  {
    "text": "and we try to develop\nan algorithm-- which we'll actually dive\nin and we'll do the internal",
    "start": "1968210",
    "end": "1973399"
  },
  {
    "text": "interpretation, and we'll do\nthem correctly and we'll reject false alarms, and so on-- it turns out that this is\nan interesting business.",
    "start": "1973400",
    "end": "1980480"
  },
  {
    "text": "You have to be very\naccurate, and some of the properties and relations\nthat you need to extract are very specific to\ncertain categories",
    "start": "1980480",
    "end": "1987529"
  },
  {
    "text": "and are very precise. For example, this was\nselected by deep network as a very good example\nof a horse head.",
    "start": "1987530",
    "end": "1994130"
  },
  {
    "text": "And, basically, it does\nhave the right shape. But, for example,\npeople reject it.",
    "start": "1994130",
    "end": "2000220"
  },
  {
    "text": "We asked people who did not\naccept it as a horse head, and they said, for example, that\nthese lines are too straight.",
    "start": "2000220",
    "end": "2006600"
  },
  {
    "text": "It looks like a man-made\npart rather than a part of a real animal.",
    "start": "2006600",
    "end": "2013180"
  },
  {
    "text": "That was a repeating\nanswer, for example. But deviation, how\nstraight is it and so on,",
    "start": "2013180",
    "end": "2018549"
  },
  {
    "text": "this is a bit tricky. And also it didn't\nhave quite the ear that you do expect here.",
    "start": "2018550",
    "end": "2025150"
  },
  {
    "text": "So we think that the kind of\nfeature that you need in order",
    "start": "2025150",
    "end": "2030850"
  },
  {
    "text": "to do this internal\ninterpretation of interest depends on relatively\ncomplicated properties",
    "start": "2030850",
    "end": "2036586"
  },
  {
    "text": "and relations that\nyou don't want to spend time and effort\ndoing in a bottom-up way",
    "start": "2036586",
    "end": "2045200"
  },
  {
    "text": "all over the entire\nvisual field. If certain two contours\nsmoothly are in a corner,",
    "start": "2045200",
    "end": "2050840"
  },
  {
    "text": "or if something is really\nstraight, only semi-straight. I mean, to do all of these\ncomputations my hunch is,",
    "start": "2050840",
    "end": "2059199"
  },
  {
    "text": "to do all of these\ncomplicated things, you need them only in a small-- you need some specific ones\nfor some specific classes",
    "start": "2059199",
    "end": "2068199"
  },
  {
    "text": "at some specific locations. So the right way to do\nthis kind of computation,",
    "start": "2068199",
    "end": "2076049"
  },
  {
    "start": "2072000",
    "end": "2091000"
  },
  {
    "text": "the right architecture,\nseems to me a combination of bottom-up\nand top-down processing. And we know that, in\nthe visual system--",
    "start": "2076050",
    "end": "2082270"
  },
  {
    "text": "this is a diagram of\nthe visual system, which is supposed to show that we have\nlots of connections going up,",
    "start": "2082270",
    "end": "2089379"
  },
  {
    "text": "but also a lot of\nconnections going down. And the suggestion that\nI would like to put up--",
    "start": "2089380",
    "end": "2095020"
  },
  {
    "start": "2091000",
    "end": "2305000"
  },
  {
    "text": "and I think it's\nwhat's happening here-- is that we have something\nlike deep network that does an initial\ngeneric classification.",
    "start": "2095020",
    "end": "2102820"
  },
  {
    "text": "It's bottom-up. It has some kind of-- was trained on many categories. It is not sensitive to all of\nthese small and informative",
    "start": "2102820",
    "end": "2110680"
  },
  {
    "text": "things that you need for\ninternal classification. And it proposes a lot of-- it\ngives you initial recognition,",
    "start": "2110680",
    "end": "2120320"
  },
  {
    "text": "which is OK. It's especially OK when you\nhave a complete object and not something challenging\nlike a minimal image.",
    "start": "2120320",
    "end": "2127990"
  },
  {
    "text": "Because you may be wrong on a\ncouple of the minimal images, but you have 20 of\nthem in each object.",
    "start": "2127990",
    "end": "2133910"
  },
  {
    "text": "So if two are wrong,\nit's not too bad. So, under many\ncircumstances, you will be OK in terms of\ngeneral recognition.",
    "start": "2133910",
    "end": "2142720"
  },
  {
    "text": "But what this does is it\ndoesn't complete the process, but it sort of triggers the\napplication of something which",
    "start": "2142720",
    "end": "2149289"
  },
  {
    "text": "is much more class-specific,\nthat it says, oh, it looks like a horse. Let's check if it has,\nor let's now complete",
    "start": "2149290",
    "end": "2155585"
  },
  {
    "text": "the interpretation. It's not just a\nvalidation, but you really want to know where is the\neye, where is the ear, where",
    "start": "2155585",
    "end": "2161260"
  },
  {
    "text": "is the mouth, and so on. You want to know maybe if\nthe mouth is open or closed. You want to feed the horse.",
    "start": "2161260",
    "end": "2166350"
  },
  {
    "text": "You want to pet the horse. I mean, when you interact with\nobjects, all of these things are important. So you continue\nyour understanding",
    "start": "2166350",
    "end": "2172360"
  },
  {
    "text": "of the visual scene. But this is not this generic\nbottom-up recognition, but you are looking\nfor specific structures",
    "start": "2172360",
    "end": "2179530"
  },
  {
    "text": "that you learned about when you\ninteracted with these objects",
    "start": "2179530",
    "end": "2184810"
  },
  {
    "text": "before. And then you test\nspecific things. Where is the eye? There should be a round\nthing roughly here,",
    "start": "2184810",
    "end": "2190839"
  },
  {
    "text": "and so on and so forth. So these are more\nextended routines that you're applying to\nthe detected region, sort",
    "start": "2190840",
    "end": "2203800"
  },
  {
    "text": "of directed from above, and\nyou know what kind of feature",
    "start": "2203800",
    "end": "2209502"
  },
  {
    "text": "to look for at\ndifferent locations within the minimal image.",
    "start": "2209502",
    "end": "2215230"
  },
  {
    "text": "And this kind of ongoing,\ncontinuing interpretation is not just inside,\ninternally, to what",
    "start": "2215230",
    "end": "2221380"
  },
  {
    "text": "you succeeded to recognize,\nbut sort of spread over the entire image.",
    "start": "2221380",
    "end": "2226490"
  },
  {
    "text": "For example, if you\nlook at this image, what do you see here\nin this image here? ",
    "start": "2226490",
    "end": "2233630"
  },
  {
    "text": "Anyone want to suggest\nwhat we see here? AUDIENCE: A face, maybe. SHIMON ULLMAN: Sorry? AUDIENCE: A face. AUDIENCE: A woman's face.",
    "start": "2233630",
    "end": "2238740"
  },
  {
    "text": "AUDIENCE: A woman's face. SHIMON ULLMAN: A woman's face. What is the woman doing? AUDIENCE: Drinking. SHIMON ULLMAN: Drinking. Right. So it's a woman drinking,\nfor those of you",
    "start": "2238740",
    "end": "2244370"
  },
  {
    "text": "managed to recognize. This is the woman, and\nshe's drinking from a cup. Now, we tested it. The woman is actually\na minimal image.",
    "start": "2244370",
    "end": "2252050"
  },
  {
    "text": "If you remove the cup,\nyou show this image, people recognize it\nat a relatively high.",
    "start": "2252050",
    "end": "2257210"
  },
  {
    "text": "Nobody recognizes this\nis a glass when you just show the glass on its own.",
    "start": "2257210",
    "end": "2263359"
  },
  {
    "text": "We think that the actual\nrecognition process in your head starts\nwith recognizing",
    "start": "2263360",
    "end": "2268610"
  },
  {
    "text": "what is recognizable\non its own, sort of the minimal configuration\nwhich you know what it is. You don't need help.",
    "start": "2268610",
    "end": "2274462"
  },
  {
    "text": "You don't need context. You don't need anything. This is a woman. This is the mouth. And you can continue from\nthere in the same way",
    "start": "2274462",
    "end": "2280310"
  },
  {
    "text": "that you can\nrecognize internally that this is the\nnose, and the nostril,",
    "start": "2280310",
    "end": "2285349"
  },
  {
    "text": "and this is the upper\nlip and lower lip. In the same way that you can\nguide your interpretation",
    "start": "2285350",
    "end": "2291230"
  },
  {
    "text": "process internally,\nyou can also say that the thing which is docked\nat her mouth is a glass.",
    "start": "2291230",
    "end": "2298160"
  },
  {
    "text": "Some results from--\nthis has been implemented by Guy Ben-Yosef,\nwho is also now a part of CBMM.",
    "start": "2298160",
    "end": "2305060"
  },
  {
    "start": "2305000",
    "end": "2529000"
  },
  {
    "text": "And this internal\ninterpretation begins to work interestingly well.",
    "start": "2305060",
    "end": "2312860"
  },
  {
    "text": "We started to do at\nMIT some MEG studies, because if this is correct,\nif the interpretation process and the correct\nrecognition of minimal images",
    "start": "2312860",
    "end": "2321230"
  },
  {
    "text": "and the following full\ninterpretation process is driven by its--",
    "start": "2321230",
    "end": "2328914"
  },
  {
    "text": "requires for completion,\nit requires the triggering of top-down processing,\nthat we could see it using",
    "start": "2328915",
    "end": "2336950"
  },
  {
    "text": "the right kind of imaging. In this case, we started to do\nminimal images in MEG images.",
    "start": "2336950",
    "end": "2348530"
  },
  {
    "text": "MEG is-- I think you-- was MEG already mentioned\nhere in any of the talks? So MEG, as you know,\nit doesn't have",
    "start": "2348530",
    "end": "2354980"
  },
  {
    "text": "very good spatial resolution. It's not like fMRI, but it has\nvery good temporal resolution.",
    "start": "2354980",
    "end": "2360390"
  },
  {
    "text": "And what Leyla-- it\nwas led by Leyla Isik.",
    "start": "2360390",
    "end": "2371119"
  },
  {
    "text": "And what we've\ndone here is trying to let subjects in the MEG\nrecognize minimal images.",
    "start": "2371120",
    "end": "2376850"
  },
  {
    "text": "And we took the electrodes from\nthe MEG and trained a decoder.",
    "start": "2376850",
    "end": "2382247"
  },
  {
    "text": "The decoder is trained\nto say whether or not the image contains, say,\nan eagle in this case.",
    "start": "2382247",
    "end": "2388130"
  },
  {
    "text": "And we had various images. And the question\nis, we can follow the performance of the\ncomputational decoder that",
    "start": "2388130",
    "end": "2395930"
  },
  {
    "text": "tries to say now the\nimage, now the electrode, the pattern of\nelectrodes, allow me to deduce that there is\nan eagle in the image.",
    "start": "2395930",
    "end": "2404390"
  },
  {
    "text": "And we see that the decoder is\nsuccessful, you can see here, at about 400 milliseconds.",
    "start": "2404390",
    "end": "2410369"
  },
  {
    "text": "This is late for vision. The initial bottom-up initial\nrecognition is more like 150,",
    "start": "2410370",
    "end": "2415790"
  },
  {
    "text": "or something like this. And we also get the same results\nwhen we do psychophysics,",
    "start": "2415790",
    "end": "2421240"
  },
  {
    "text": "that in normal images you\ncan recognize them at--",
    "start": "2421240",
    "end": "2427670"
  },
  {
    "text": "you can get good\nrecognition after, say, exposure of 100 milliseconds\nfollowed by a mask",
    "start": "2427670",
    "end": "2434930"
  },
  {
    "text": "to recognize correctly\nat the human level, to get to the human\nlevel that we get.",
    "start": "2434930",
    "end": "2443420"
  },
  {
    "text": "With minimal images,\nyou have to give enough time, which we\nsuspect is enough time,",
    "start": "2443420",
    "end": "2449450"
  },
  {
    "text": "to allow the application of the\ntop-down interpretation within.",
    "start": "2449450",
    "end": "2454540"
  },
  {
    "text": "And if you don't give\nenough time, then people degenerate and\nbecome deep networks,",
    "start": "2454540",
    "end": "2459920"
  },
  {
    "text": "and you get the same kind\nof performance, roughly. But this is all still\nunpublished and still running,",
    "start": "2459920",
    "end": "2467750"
  },
  {
    "text": "and we need more subjects. And all of this is looking\nin the right direction, and looking in providing\nsupport for top-down processing",
    "start": "2467750",
    "end": "2476150"
  },
  {
    "text": "for this. And this, by the\nway, it's interesting methodologically, because\nit's very difficult.",
    "start": "2476150",
    "end": "2482960"
  },
  {
    "text": "With real images, it's so rich\nand you get so much information already in the way\nof going up and",
    "start": "2482960",
    "end": "2488010"
  },
  {
    "text": "because of these redundancies,\nthat even if you make 20% error, it doesn't really\nmatter because you have",
    "start": "2488010",
    "end": "2494510"
  },
  {
    "text": "redundancy, you\nhave many multiple, sufficient minimal images\nwithin any object, and so on.",
    "start": "2494510",
    "end": "2501450"
  },
  {
    "text": "So it's very\ndifficult to tease out the effect of where exactly the\ntop-down information starts.",
    "start": "2501450",
    "end": "2508160"
  },
  {
    "text": "Where do you need it? Where exactly you fail\nif you don't have it. So we think you need it for\nthis internal interpretation",
    "start": "2508160",
    "end": "2516530"
  },
  {
    "text": "and for the correct\nrecognition of minimal images. And here you can start seeing\ngood signals in the MEG.",
    "start": "2516530",
    "end": "2523040"
  },
  {
    "text": "It provides you sort of a\ntool that is pretty unique and allows you to\ndo these things.",
    "start": "2523040",
    "end": "2530910"
  },
  {
    "start": "2529000",
    "end": "2647000"
  },
  {
    "text": "So let me add what is\na very informal thing but where I think this is going. I think that when you\nlook at difficult images,",
    "start": "2530910",
    "end": "2539850"
  },
  {
    "text": "like action recognition\nthat we discussed below, many things that we\ndo depend not on sort",
    "start": "2539850",
    "end": "2546720"
  },
  {
    "text": "of cause label of there\nis a person there, or there is an airplane,\nor there is a dog. But, really, things\ndepend on the fine details",
    "start": "2546720",
    "end": "2556079"
  },
  {
    "text": "of the internal interpretation. And so if you can\nturn off what I",
    "start": "2556080",
    "end": "2561300"
  },
  {
    "text": "think is the top-down part\nof class-specific top-down processes, I think that many\nof these fine distinctions",
    "start": "2561300",
    "end": "2569130"
  },
  {
    "text": "that we make all the time-- and\nit's what vision is all about. Vision is not about\ngiving cause categories--",
    "start": "2569130",
    "end": "2575760"
  },
  {
    "text": "will go away. And so these things will\nbecome more and more an important part of vision. Let me look at this variability\nin action recognition.",
    "start": "2575760",
    "end": "2585549"
  },
  {
    "text": "But let me show you\nsome specific examples.  This is something that\nconfuses current classifiers,",
    "start": "2585549",
    "end": "2592814"
  },
  {
    "text": "that in most of them it seems\nthat the person is drinking. ",
    "start": "2592814",
    "end": "2598260"
  },
  {
    "text": "Because there is a\nperson, there is a bottle, and the bottle is\nclose to the mouth. So the person is drinking\nat this rough level",
    "start": "2598260",
    "end": "2605550"
  },
  {
    "text": "of description. But, obviously, here\nthis person is drinking, this person is pouring, right?",
    "start": "2605550",
    "end": "2611120"
  },
  {
    "text": "Something very-- is this\nperson drinking at the moment? Yes or no? AUDIENCE: No.",
    "start": "2611120",
    "end": "2616365"
  },
  {
    "text": "SHIMON ULLMAN: No. Why not? She's holding a cup, and\nit's not far, and maybe on the way to the mouth. We know that she's\nnot drinking, right?",
    "start": "2616365",
    "end": "2623220"
  },
  {
    "text": "But why exactly not? And, again, this\nis something that is picked up as drinking by\nmany recognition systems.",
    "start": "2623220",
    "end": "2628680"
  },
  {
    "text": "But something is wrong here. All of these things, these\nare different objects and different actions that\nthe people are performing.",
    "start": "2628680",
    "end": "2635650"
  },
  {
    "text": "This is drinking from a straw. This is smoking. And this is brushing\ntheir teeth. But this depends on, you have\nto go to the right location",
    "start": "2635650",
    "end": "2642779"
  },
  {
    "text": "and decide exactly\nwhat's happening there. It's the kind of thing\nthat we do all the time.",
    "start": "2642780",
    "end": "2649370"
  },
  {
    "start": "2647000",
    "end": "2933000"
  },
  {
    "text": "Some more challenges. These are just sort\nof informal challenges to show you how we can deal with\nfine interpretation of details",
    "start": "2649370",
    "end": "2658109"
  },
  {
    "text": "of interest in the image. What is this arrow pointing at? AUDIENCE: Bottle SHIMON ULLMAN: Sorry?",
    "start": "2658110",
    "end": "2663382"
  },
  {
    "text": "AUDIENCE: Bottle. SHIMON ULLMAN: Yeah. But above the bottle, there\nis something else there. AUDIENCE: Fingers. SHIMON ULLMAN: Sorry?",
    "start": "2663382",
    "end": "2668736"
  },
  {
    "text": "AUDIENCE: Finger. SHIMON ULLMAN: Fingers, right. Let's see. Just playing this time. What is this arrow pointing at?",
    "start": "2668736",
    "end": "2675832"
  },
  {
    "text": "AUDIENCE: Zipper. SHIMON ULLMAN: Zipper. Let's see. Here are two challenging things. Here are two arrows. What is this one pointing at?",
    "start": "2675832",
    "end": "2683067"
  },
  {
    "text": "AUDIENCE: Cup? AUDIENCE: Tea. AUDIENCE: Cup. SHIMON ULLMAN: All right. Next to the cup,\nright, is also--",
    "start": "2683068",
    "end": "2688196"
  },
  {
    "text": "this is really challenging. Let's see if some folks. What is this one pointing at? AUDIENCE: A tray? AUDIENCE: A tray.",
    "start": "2688196",
    "end": "2693609"
  },
  {
    "text": "SHIMON ULLMAN: Tray. So the tray, think\nabout it, it's this, but you match it with this thing\nhere in order to make sure, to know that it's a tray.",
    "start": "2693610",
    "end": "2700900"
  },
  {
    "text": "It's not something that\nwill be easily picked up. I mean, I'm looking for\ndifficult things which",
    "start": "2700900",
    "end": "2706702"
  },
  {
    "text": "are a little bit challenging. And you say, ah, I can get it. But this level of detail,\ninterpreting the fine details",
    "start": "2706702",
    "end": "2712280"
  },
  {
    "text": "and images in a top-down\nfashion happens all the time. Is this person smoking?",
    "start": "2712280",
    "end": "2718640"
  },
  {
    "text": "Of course not, and we\nare not fooled by it, and we immediately zoom\non the right things. And, really, all the information\nis here at the end of the--",
    "start": "2718640",
    "end": "2727130"
  },
  {
    "text": "and so on, and so\non, and so forth. I mean, we were looking\nat dealing visually",
    "start": "2727130",
    "end": "2732140"
  },
  {
    "text": "with social interactions,\nunderstanding the social interactions\nbetween agents.",
    "start": "2732140",
    "end": "2737300"
  },
  {
    "text": "And, again, it's very\ndifficult to do correctly, and it depends on subtle things. I mean, you can get\nsomething rough OK.",
    "start": "2737300",
    "end": "2745640"
  },
  {
    "text": " For example, is this\nsort of an intimate hug, or this just a cordial hug\nof people who are not--",
    "start": "2745640",
    "end": "2754760"
  },
  {
    "text": "we know exactly what's\ngoing on, right? And it turns out that\nthe features are not that easy to get.",
    "start": "2754760",
    "end": "2760339"
  },
  {
    "text": "This was picked up\nincorrectly by something that we designed\nfor people hugging.",
    "start": "2760340",
    "end": "2765770"
  },
  {
    "text": "And it's not very far\nfrom people hugging, but it doesn't fool us, right? But they are not really hugging.",
    "start": "2765770",
    "end": "2772520"
  },
  {
    "text": "On social interactions,\nwe know interactions even between non-human agents. I mean, this\ninteraction, is this",
    "start": "2772520",
    "end": "2778850"
  },
  {
    "text": "is threatening interaction\nor a friendly interaction? What do you think? Yeah.",
    "start": "2778850",
    "end": "2784330"
  },
  {
    "text": "Correct. I think so too. Anyway, I think that all of\nthese things that we can do, and I think that\nvision is about this.",
    "start": "2784330",
    "end": "2790070"
  },
  {
    "text": "It's not about\nlooking at this room and saying that this is a\ncomputer and this is a chair. It's about understanding\nthe situation",
    "start": "2790070",
    "end": "2796460"
  },
  {
    "text": "and making fine judgments,\nand interacting with objects.",
    "start": "2796460",
    "end": "2801950"
  },
  {
    "text": "And, in fact, we're looking at\nis part of we're doing at CBMM.",
    "start": "2801950",
    "end": "2808780"
  },
  {
    "text": "We are looking at the problem of\nasking questions about images. So we want a system\nthat you can give it",
    "start": "2808780",
    "end": "2814430"
  },
  {
    "text": "an image and a\nquestion, and then we want the system to be able\nto process the image in such",
    "start": "2814430",
    "end": "2821870"
  },
  {
    "text": "a way that will give you a\ngood answer to the question. This is interesting\nbecause it means that it's not just a\ngeneric pipeline of running",
    "start": "2821870",
    "end": "2829240"
  },
  {
    "text": "the image through a\npipeline, sort of fixed sequence of operations. But, depending on what\nyou're interested in,",
    "start": "2829240",
    "end": "2836270"
  },
  {
    "text": "the whole visual process should\nbe directed in a particular way to produce just the\nrelevant answer.",
    "start": "2836270",
    "end": "2841700"
  },
  {
    "text": "And we looked at a set of--",
    "start": "2841700",
    "end": "2847345"
  },
  {
    "text": "with students, we looked at\na set of some 600 questions that we gave people on the\nMechanical Turk images.",
    "start": "2847345",
    "end": "2854900"
  },
  {
    "text": "And we say imagine some\nquestions about these images. Ask some question\nabout these images.",
    "start": "2854900",
    "end": "2860390"
  },
  {
    "text": "And they came up\nwith some images. We looked at them, and\nan informal observation, initial observation, is\nthat most of these questions",
    "start": "2860390",
    "end": "2868250"
  },
  {
    "text": "that people invented\nto ask about images, you needed some\nthings which depended on precise internal\ninterpretation of the details.",
    "start": "2868250",
    "end": "2876950"
  },
  {
    "text": "So it's things that\ncome up all the time. You have to dive into\nthe image and analyze",
    "start": "2876950",
    "end": "2882200"
  },
  {
    "text": "the subtle cues that will tell\nyou that these are not hugging, and this is not threatening,\nand this is not an intimate hug,",
    "start": "2882200",
    "end": "2890359"
  },
  {
    "text": "and so on and so forth. And this is what we are-- the whole story of\nthe minimal images",
    "start": "2890360",
    "end": "2896030"
  },
  {
    "text": "and the internal interpretation. The real goal\neventually is to be able to identify the important\nvisual features and structures",
    "start": "2896030",
    "end": "2906860"
  },
  {
    "text": "which are important\nfor this, and thinking about the automatic\nlearning of how to extract",
    "start": "2906860",
    "end": "2912829"
  },
  {
    "text": "the internal structure\nthat will support",
    "start": "2912830",
    "end": "2918260"
  },
  {
    "text": "the interpretation of all these\ninteresting and meaningful",
    "start": "2918260",
    "end": "2923630"
  },
  {
    "text": "aspects of images that, at\nthe moment, we do not have. ",
    "start": "2923630",
    "end": "2929990"
  },
  {
    "text": "OK, let me skip this. OK, I think I've said all\nof these conclusions already",
    "start": "2929990",
    "end": "2938720"
  },
  {
    "start": "2933000",
    "end": "2971000"
  },
  {
    "text": "in the final comments,\nso let me stop here. ",
    "start": "2938720",
    "end": "2971294"
  }
]
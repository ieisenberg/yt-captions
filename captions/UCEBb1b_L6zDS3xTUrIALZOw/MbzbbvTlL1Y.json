[
  {
    "text": "[MUSIC PLAYING]",
    "start": "0",
    "end": "1936"
  },
  {
    "start": "1936",
    "end": "3389"
  },
  {
    "text": "CATHERINE D'IGNAZIO:\nIt's the human behavior",
    "start": "3390",
    "end": "5250"
  },
  {
    "text": "that is making the\nbrain of the machine.",
    "start": "5250",
    "end": "7319"
  },
  {
    "text": "That is how you make\nthe machine intelligent.",
    "start": "7320",
    "end": "11020"
  },
  {
    "text": "SARAH HANSEN: Today\non Chalk Radio,",
    "start": "11020",
    "end": "13050"
  },
  {
    "text": "how the future of artificial\nintelligence and machine",
    "start": "13050",
    "end": "16200"
  },
  {
    "text": "learning education might\nlook a lot more human.",
    "start": "16200",
    "end": "18630"
  },
  {
    "text": "JACOB ANDREAS:\nWhat's the difference",
    "start": "18630",
    "end": "20130"
  },
  {
    "text": "between saying, you know, a\nrestaurant review expresses",
    "start": "20130",
    "end": "22769"
  },
  {
    "text": "positive sentiment,\nwhich is a very",
    "start": "22770",
    "end": "24690"
  },
  {
    "text": "complicated social phenomenon,\nand saying that, you know,",
    "start": "24690",
    "end": "27318"
  },
  {
    "text": "a picture of the number 9 is\na picture of the number 9,",
    "start": "27318",
    "end": "29610"
  },
  {
    "text": "which is much less complicated\nas a social phenomenon.",
    "start": "29610",
    "end": "33660"
  },
  {
    "text": "SARAH HANSEN: I'm your\nhost, Sarah Hansen.",
    "start": "33660",
    "end": "36120"
  },
  {
    "text": "This week, we're\ntalking with three",
    "start": "36120",
    "end": "37890"
  },
  {
    "text": "interdisciplinary collaborators\nabout their mission",
    "start": "37890",
    "end": "40950"
  },
  {
    "text": "to foster a new kind of approach\nto computing technologies.",
    "start": "40950",
    "end": "45030"
  },
  {
    "text": "They've created\nan assignment that",
    "start": "45030",
    "end": "46829"
  },
  {
    "text": "challenges students to take a\ncritical approach as they build",
    "start": "46830",
    "end": "50430"
  },
  {
    "text": "the technologies of the future.",
    "start": "50430",
    "end": "52873"
  },
  {
    "text": "CATHERINE D'IGNAZIO: I\nam Catherine D'Ignazio.",
    "start": "52873",
    "end": "54790"
  },
  {
    "text": "I'm an Assistant Professor of\nUrban Science and Planning.",
    "start": "54790",
    "end": "58643"
  },
  {
    "text": "JACOB ANDREAS: My\nname is Jacob Andreas.",
    "start": "58643",
    "end": "60310"
  },
  {
    "text": "I'm an Assistant Professor\nin the Department",
    "start": "60310",
    "end": "62680"
  },
  {
    "text": "of Electrical Engineering\nand Computer Science",
    "start": "62680",
    "end": "64684"
  },
  {
    "text": "and also the Computer Science\nand Artificial Intelligence",
    "start": "64685",
    "end": "67060"
  },
  {
    "text": "Laboratory.",
    "start": "67060",
    "end": "68302"
  },
  {
    "text": "HARINI SURESH: My\nname is Harini Suresh.",
    "start": "68303",
    "end": "69970"
  },
  {
    "text": "I'm a fifth year PhD\nstudent in Computer Science.",
    "start": "69970",
    "end": "74770"
  },
  {
    "text": "SARAH HANSEN: In spring 2021,\nCatherine, Jacob, and Harini",
    "start": "74770",
    "end": "78880"
  },
  {
    "text": "were brought together as\npart of a special initiative",
    "start": "78880",
    "end": "81759"
  },
  {
    "text": "called SERC from the MIT\nStephen A. Schwarzman",
    "start": "81760",
    "end": "85300"
  },
  {
    "text": "College of Computing.",
    "start": "85300",
    "end": "87310"
  },
  {
    "text": "SERC stands for the\nSocial and Ethical",
    "start": "87310",
    "end": "89680"
  },
  {
    "text": "Responsibilities of Computing.",
    "start": "89680",
    "end": "91698"
  },
  {
    "text": "CATHERINE D'IGNAZIO:\nSo the mission broadly",
    "start": "91698",
    "end": "93490"
  },
  {
    "text": "is thinking about how do we\ncultivate responsible creators",
    "start": "93490",
    "end": "98140"
  },
  {
    "text": "of computational\ntools and technologies",
    "start": "98140",
    "end": "101728"
  },
  {
    "text": "for the folks who\nare going to go out",
    "start": "101728",
    "end": "103270"
  },
  {
    "text": "and be building the\ntools of the future.",
    "start": "103270",
    "end": "106134"
  },
  {
    "text": "You know, in a lot\nof cases, you don't",
    "start": "106135",
    "end": "108250"
  },
  {
    "text": "know what the ethical\nimplications of something",
    "start": "108250",
    "end": "111790"
  },
  {
    "text": "are until, you\nknow, a kind of more",
    "start": "111790",
    "end": "114160"
  },
  {
    "text": "abstract tool or\ntechnology or algorithm",
    "start": "114160",
    "end": "116770"
  },
  {
    "text": "is kind of plugged\ninto the human context,",
    "start": "116770",
    "end": "118869"
  },
  {
    "text": "right-- like that\nplace where, you know,",
    "start": "118870",
    "end": "120860"
  },
  {
    "text": "the machine learning\nand people meet.",
    "start": "120860",
    "end": "123948"
  },
  {
    "text": "JACOB ANDREAS: There have been\nlots of high profile incidents",
    "start": "123948",
    "end": "126490"
  },
  {
    "text": "involving things like face\nrecognition software, people",
    "start": "126490",
    "end": "129375"
  },
  {
    "text": "trying to deploy\nmachine learning",
    "start": "129375",
    "end": "130750"
  },
  {
    "text": "systems in the context of things\nlike sentencing or recidivism",
    "start": "130750",
    "end": "133390"
  },
  {
    "text": "prediction, and in many cases,\nhaving sort of seriously",
    "start": "133390",
    "end": "136120"
  },
  {
    "text": "harmful effects.",
    "start": "136120",
    "end": "138099"
  },
  {
    "text": "SARAH HANSEN: For\nJacob, exploring",
    "start": "138100",
    "end": "139780"
  },
  {
    "text": "the social\nconsequences of AI got",
    "start": "139780",
    "end": "142600"
  },
  {
    "text": "him to start thinking a little\ndifferently in his own survey",
    "start": "142600",
    "end": "145390"
  },
  {
    "text": "course--",
    "start": "145390",
    "end": "145960"
  },
  {
    "text": "6.864 Natural Language\nProcessing, or NLP for short.",
    "start": "145960",
    "end": "153067"
  },
  {
    "text": "JACOB ANDREAS: The way\nwe have traditionally",
    "start": "153067",
    "end": "154900"
  },
  {
    "text": "taught machine learning classes,\nit's always, OK, you know,",
    "start": "154900",
    "end": "157959"
  },
  {
    "text": "here's a data set of\nphotographs of digits.",
    "start": "157960",
    "end": "160840"
  },
  {
    "text": "Classify this picture as whether\nit contains a 0 or a 1 or a 2",
    "start": "160840",
    "end": "164470"
  },
  {
    "text": "or a 3.",
    "start": "164470",
    "end": "165400"
  },
  {
    "text": "And you know, here's a data\nset of restaurant reviews.",
    "start": "165400",
    "end": "168209"
  },
  {
    "text": "And they just happen to already\nhave assigned to them labels",
    "start": "168210",
    "end": "170710"
  },
  {
    "text": "for whether this is\na positive restaurant",
    "start": "170710",
    "end": "172330"
  },
  {
    "text": "review or a negative\nrestaurant review.",
    "start": "172330",
    "end": "173830"
  },
  {
    "text": "You know, go train the\nmachine learning model.",
    "start": "173830",
    "end": "175747"
  },
  {
    "text": "And at no point do\nyou stop and ask, OK,",
    "start": "175747",
    "end": "177730"
  },
  {
    "text": "but where did these\nrestaurant reviews come from?",
    "start": "177730",
    "end": "179902"
  },
  {
    "text": "And what's the difference\nbetween saying a restaurant",
    "start": "179902",
    "end": "182109"
  },
  {
    "text": "review expresses\npositive sentiment, which",
    "start": "182110",
    "end": "184990"
  },
  {
    "text": "is a very complicated\nsocial phenomenon,",
    "start": "184990",
    "end": "187030"
  },
  {
    "text": "and saying that, you know,\na picture of the number 9",
    "start": "187030",
    "end": "189340"
  },
  {
    "text": "is a picture of the number 9,\nwhich is much less complicated",
    "start": "189340",
    "end": "192069"
  },
  {
    "text": "as a social phenomenon.",
    "start": "192070",
    "end": "195320"
  },
  {
    "text": "SARAH HANSEN: So he teamed\nup with Catherine and Harini",
    "start": "195320",
    "end": "197920"
  },
  {
    "text": "to show students\nthat the machine",
    "start": "197920",
    "end": "200200"
  },
  {
    "text": "part of machine learning is\nvery much influenced by humans.",
    "start": "200200",
    "end": "206480"
  },
  {
    "text": "HARINI SURESH: So the way\nthat machine learning systems",
    "start": "206480",
    "end": "209170"
  },
  {
    "text": "work in many cases is something\ncalled supervised learning,",
    "start": "209170",
    "end": "212920"
  },
  {
    "text": "where the data set\ncontains examples as well",
    "start": "212920",
    "end": "216310"
  },
  {
    "text": "as labels for those examples.",
    "start": "216310",
    "end": "218510"
  },
  {
    "text": "So for example, in content\nmoderation, you might have--",
    "start": "218510",
    "end": "222610"
  },
  {
    "text": "in your data set--",
    "start": "222610",
    "end": "223840"
  },
  {
    "text": "comments from a message\nboard as well as",
    "start": "223840",
    "end": "226480"
  },
  {
    "text": "annotations that say this\nis a toxic comment or this",
    "start": "226480",
    "end": "230260"
  },
  {
    "text": "is not a toxic comment.",
    "start": "230260",
    "end": "231700"
  },
  {
    "text": "So then what the machine\nlearning system is trying to do",
    "start": "231700",
    "end": "234459"
  },
  {
    "text": "is learn from that data What.",
    "start": "234460",
    "end": "237310"
  },
  {
    "text": "Makes up a toxic comment,\nwhat are characteristics",
    "start": "237310",
    "end": "240550"
  },
  {
    "text": "of toxicity, and it uses the\nannotations to figure that out.",
    "start": "240550",
    "end": "244900"
  },
  {
    "text": "And those annotations\ntypically come from somewhere.",
    "start": "244900",
    "end": "248450"
  },
  {
    "text": "So they might be\nautomatically generated",
    "start": "248450",
    "end": "250989"
  },
  {
    "text": "by looking at historically\nwhat sorts of comments",
    "start": "250990",
    "end": "253630"
  },
  {
    "text": "have been moderated.",
    "start": "253630",
    "end": "255490"
  },
  {
    "text": "Or they might be\ngenerated by people.",
    "start": "255490",
    "end": "260290"
  },
  {
    "text": "You might crowdsource this or\nget specific groups of people",
    "start": "260290",
    "end": "263950"
  },
  {
    "text": "to annotate comments as\nto whether they think",
    "start": "263950",
    "end": "266230"
  },
  {
    "text": "they're toxic or non-toxic.",
    "start": "266230",
    "end": "267700"
  },
  {
    "text": "And those would\nbecome the labels",
    "start": "267700",
    "end": "269680"
  },
  {
    "text": "in the data set that\nthe machine learning",
    "start": "269680",
    "end": "271570"
  },
  {
    "text": "system would learn from.",
    "start": "271570",
    "end": "273901"
  },
  {
    "text": "CATHERINE D'IGNAZIO: We\nneed to train it basically.",
    "start": "273901",
    "end": "276220"
  },
  {
    "text": "And the way to train\nit is you look either,",
    "start": "276220",
    "end": "278320"
  },
  {
    "text": "like Harini said,\nat historical data",
    "start": "278320",
    "end": "280072"
  },
  {
    "text": "or you make your\nown data set where",
    "start": "280072",
    "end": "281530"
  },
  {
    "text": "you and your team or you\nand a group of people or you",
    "start": "281530",
    "end": "284530"
  },
  {
    "text": "hire people to say, this is\ntoxic, this is not toxic.",
    "start": "284530",
    "end": "288490"
  },
  {
    "text": "Or let's keep this one,\nlet's not keep that one.",
    "start": "288490",
    "end": "291039"
  },
  {
    "text": "And that-- that annotation--",
    "start": "291040",
    "end": "294190"
  },
  {
    "text": "that is how you make\nthe machine intelligent.",
    "start": "294190",
    "end": "296830"
  },
  {
    "text": "And so if we back\nup a little bit,",
    "start": "296830",
    "end": "298930"
  },
  {
    "text": "it's the human\nbehavior that is making",
    "start": "298930",
    "end": "301810"
  },
  {
    "text": "the brain of the machine.",
    "start": "301810",
    "end": "304128"
  },
  {
    "text": "That's why, you know, that step\nis really important in there,",
    "start": "304128",
    "end": "306669"
  },
  {
    "text": "that human step.",
    "start": "306670",
    "end": "308740"
  },
  {
    "text": "It's also the step that we\nwere trying to tune people",
    "start": "308740",
    "end": "311020"
  },
  {
    "text": "into as not just being just\nlike this objective thing",
    "start": "311020",
    "end": "315220"
  },
  {
    "text": "that the machine makes up by\nitself based on completely",
    "start": "315220",
    "end": "318130"
  },
  {
    "text": "objective parameters\nor whatever.",
    "start": "318130",
    "end": "320873"
  },
  {
    "text": "JACOB ANDREAS: People\ntake these classes",
    "start": "320873",
    "end": "322539"
  },
  {
    "text": "and then they go out\nin the real world",
    "start": "322540",
    "end": "324123"
  },
  {
    "text": "and find themselves\nbuilding detectors",
    "start": "324123",
    "end": "325750"
  },
  {
    "text": "for even more\ncomplicated things,",
    "start": "325750",
    "end": "327190"
  },
  {
    "text": "like these toxicity detectors.",
    "start": "327190",
    "end": "329270"
  },
  {
    "text": "And that was what really\nfelt like the sort",
    "start": "329270",
    "end": "331180"
  },
  {
    "text": "gap between the way we\nwere training people",
    "start": "331180",
    "end": "333038"
  },
  {
    "text": "and the way these tools were\ngetting deployed in practice.",
    "start": "333038",
    "end": "335455"
  },
  {
    "start": "335455",
    "end": "338427"
  },
  {
    "text": "SARAH HANSEN:\nTogether, they designed",
    "start": "338428",
    "end": "339970"
  },
  {
    "text": "a brand new assignment for\nthe course, one they hoped",
    "start": "339970",
    "end": "343420"
  },
  {
    "text": "would get students thinking\nabout the human element",
    "start": "343420",
    "end": "346090"
  },
  {
    "text": "of machine learning.",
    "start": "346090",
    "end": "347740"
  },
  {
    "text": "First, students\nwrote instructions",
    "start": "347740",
    "end": "350050"
  },
  {
    "text": "for annotating data\nsets, and then they",
    "start": "350050",
    "end": "352960"
  },
  {
    "text": "tried to follow each\nother's instructions.",
    "start": "352960",
    "end": "355875"
  },
  {
    "text": "HARINI SURESH: The overall\ngoal of the assignment",
    "start": "355875",
    "end": "359120"
  },
  {
    "text": "was to try and\nget students to go",
    "start": "359120",
    "end": "362180"
  },
  {
    "text": "from thinking about data as this\npre-existing, objective, ground",
    "start": "362180",
    "end": "367400"
  },
  {
    "text": "truth to thinking\nabout it as the product",
    "start": "367400",
    "end": "370790"
  },
  {
    "text": "of a long and complex process\nthat involves many steps",
    "start": "370790",
    "end": "375560"
  },
  {
    "text": "and is driven by human\njudgments and values.",
    "start": "375560",
    "end": "380360"
  },
  {
    "text": "The goal of this\nassignment is not",
    "start": "380360",
    "end": "381889"
  },
  {
    "text": "to say that data is\nnot useful or that it's",
    "start": "381890",
    "end": "385310"
  },
  {
    "text": "bad but rather to help students\ncritically think about data",
    "start": "385310",
    "end": "390290"
  },
  {
    "text": "sets when they receive them\nor use them or hear about them",
    "start": "390290",
    "end": "393980"
  },
  {
    "text": "being used and to help them sort\nof ask those questions of who",
    "start": "393980",
    "end": "398270"
  },
  {
    "text": "was this created by,\nhow was it created,",
    "start": "398270",
    "end": "400879"
  },
  {
    "text": "what are its capabilities,\nand what are its limitations.",
    "start": "400880",
    "end": "405500"
  },
  {
    "text": "SARAH HANSEN: When Catherine,\nHarini, and Jacob started",
    "start": "405500",
    "end": "407840"
  },
  {
    "text": "reading the students'\nresponses, they",
    "start": "407840",
    "end": "410102"
  },
  {
    "text": "realized that the\nassignment helped",
    "start": "410102",
    "end": "411560"
  },
  {
    "text": "students think differently\nabout the instructions they",
    "start": "411560",
    "end": "414290"
  },
  {
    "text": "were giving annotators.",
    "start": "414290",
    "end": "416120"
  },
  {
    "text": "But it also did something\nnone of them had expected.",
    "start": "416120",
    "end": "419570"
  },
  {
    "text": "JACOB ANDREAS: The\nthing that surprised me",
    "start": "419570",
    "end": "421320"
  },
  {
    "text": "most was the number\nof students who",
    "start": "421320",
    "end": "422778"
  },
  {
    "text": "said, I've never done\nan assignment like this",
    "start": "422778",
    "end": "425730"
  },
  {
    "text": "in my whole undergraduate\nor graduate training, right?",
    "start": "425730",
    "end": "428080"
  },
  {
    "text": "And this is an advanced class.",
    "start": "428080",
    "end": "429330"
  },
  {
    "text": "These are people who\nare seniors in college",
    "start": "429330",
    "end": "431430"
  },
  {
    "text": "or in their first or second\nyear of graduate school.",
    "start": "431430",
    "end": "433770"
  },
  {
    "text": "And for many people,\nit was really",
    "start": "433770",
    "end": "435509"
  },
  {
    "text": "the first time they'd actually\nbeen asked to sort of think",
    "start": "435510",
    "end": "437927"
  },
  {
    "text": "about the process by which\nthese data sets that they've",
    "start": "437927",
    "end": "440370"
  },
  {
    "text": "been seeing since, you\nknow, their sophomore year",
    "start": "440370",
    "end": "442770"
  },
  {
    "text": "were actually being generated.",
    "start": "442770",
    "end": "446470"
  },
  {
    "text": "HARINI SURESH: Initially,\nwe had designed",
    "start": "446470",
    "end": "448600"
  },
  {
    "text": "this to focus on subjectivity\nthat annotators might have--",
    "start": "448600",
    "end": "453260"
  },
  {
    "text": "so like subjectivity\nin labels in data sets.",
    "start": "453260",
    "end": "456430"
  },
  {
    "text": "But there were a\nbunch of other things",
    "start": "456430",
    "end": "458979"
  },
  {
    "text": "that people learned about\nthe entire data set pipeline.",
    "start": "458980",
    "end": "463460"
  },
  {
    "text": "So for example,\nthe categorizations",
    "start": "463460",
    "end": "465669"
  },
  {
    "text": "that people came up with\nfor the same problem",
    "start": "465670",
    "end": "468250"
  },
  {
    "text": "were drastically\ndifferent in some cases.",
    "start": "468250",
    "end": "471380"
  },
  {
    "text": "People were sort of surprised\nby how much personal judgment",
    "start": "471380",
    "end": "474700"
  },
  {
    "text": "they had to use to\ndecide these things.",
    "start": "474700",
    "end": "477410"
  },
  {
    "text": "Everyone was like,\nwow, I was very",
    "start": "477410",
    "end": "479170"
  },
  {
    "text": "surprised by the amount\nthat I wasn't sure",
    "start": "479170",
    "end": "482650"
  },
  {
    "text": "and the amount that I had to\nsort of rely on my own biases",
    "start": "482650",
    "end": "486729"
  },
  {
    "text": "or judgments to decide what I\nactually thought about this.",
    "start": "486730",
    "end": "492350"
  },
  {
    "text": "SARAH HANSEN: And these\nstudents' reflections actually",
    "start": "492350",
    "end": "494600"
  },
  {
    "text": "pointed to much bigger questions\nwithin the field as a whole.",
    "start": "494600",
    "end": "499350"
  },
  {
    "text": "JACOB ANDREAS: Of the numerous\nways that Harini and Catherine",
    "start": "499350",
    "end": "502230"
  },
  {
    "text": "mentioned of constructing\nthese data sets,",
    "start": "502230",
    "end": "504270"
  },
  {
    "text": "one that has become\nI think particularly",
    "start": "504270",
    "end": "507090"
  },
  {
    "text": "important within the machine\nlearning research community",
    "start": "507090",
    "end": "510030"
  },
  {
    "text": "these days is\ncrowdsourcing, where",
    "start": "510030",
    "end": "512280"
  },
  {
    "text": "there's some online portal where\npeople can log in and sign up",
    "start": "512280",
    "end": "517049"
  },
  {
    "text": "for a teeny little\nlabeling task-- like just",
    "start": "517049",
    "end": "519510"
  },
  {
    "text": "look at this one picture\nand tell me whether or not",
    "start": "519510",
    "end": "522130"
  },
  {
    "text": "this is a picture of a cat.",
    "start": "522130",
    "end": "523440"
  },
  {
    "text": "Or look at this one\ncomment and tell me",
    "start": "523440",
    "end": "526020"
  },
  {
    "text": "whether it's a toxic\ncomment or not.",
    "start": "526020",
    "end": "527520"
  },
  {
    "text": "And then you get $0.05 or $0.10\nin exchange for doing this",
    "start": "527520",
    "end": "530610"
  },
  {
    "text": "little micro task.",
    "start": "530610",
    "end": "532500"
  },
  {
    "text": "So there's two sorts of\nthings to think about when",
    "start": "532500",
    "end": "534960"
  },
  {
    "text": "using these kinds of platforms.",
    "start": "534960",
    "end": "536792"
  },
  {
    "text": "One is just thinking\nabout the well-being",
    "start": "536792",
    "end": "538500"
  },
  {
    "text": "of the annotators\nthemselves, that it's",
    "start": "538500",
    "end": "540960"
  },
  {
    "text": "very easy to miss calibrate\nthe amount of time",
    "start": "540960",
    "end": "544230"
  },
  {
    "text": "that it takes to do one\nof these micro tasks",
    "start": "544230",
    "end": "546449"
  },
  {
    "text": "and wind up not\nactually paying people",
    "start": "546450",
    "end": "548250"
  },
  {
    "text": "a living wage for doing them.",
    "start": "548250",
    "end": "550140"
  },
  {
    "text": "And there are actually\npeople all over the world who",
    "start": "550140",
    "end": "552660"
  },
  {
    "text": "rely on these kinds of\ncrowdsourcing platforms",
    "start": "552660",
    "end": "555810"
  },
  {
    "text": "as their primary\nsource of income.",
    "start": "555810",
    "end": "557610"
  },
  {
    "text": "And another thing--\nonce you, again,",
    "start": "557610",
    "end": "559829"
  },
  {
    "text": "start to think about tasks like\ntoxic comment detection or even",
    "start": "559830",
    "end": "563070"
  },
  {
    "text": "more sensitive things\nlike recognizing images",
    "start": "563070",
    "end": "565830"
  },
  {
    "text": "of pornography or images\nof violence or whatever,",
    "start": "565830",
    "end": "568560"
  },
  {
    "text": "it is relatively easy-- without\nyou as the sort of system",
    "start": "568560",
    "end": "573654"
  },
  {
    "text": "builder yourself having had\nto look at any of this data--",
    "start": "573655",
    "end": "576030"
  },
  {
    "text": "to dump just an enormous amount\nof like really traumatizing",
    "start": "576030",
    "end": "579630"
  },
  {
    "text": "content on people who you're\npaying $0.10 a pop to label.",
    "start": "579630",
    "end": "583920"
  },
  {
    "text": "And there's all kinds of studies\nshowing that people really",
    "start": "583920",
    "end": "587279"
  },
  {
    "text": "experience post-traumatic stress\ndisorder, various other kinds",
    "start": "587280",
    "end": "590790"
  },
  {
    "text": "of mental health\nissues when subjected",
    "start": "590790",
    "end": "593040"
  },
  {
    "text": "to these kinds of things.",
    "start": "593040",
    "end": "595522"
  },
  {
    "text": "SARAH HANSEN: In\nour conversation,",
    "start": "595523",
    "end": "596940"
  },
  {
    "text": "this notion of context\nkept coming up.",
    "start": "596940",
    "end": "600420"
  },
  {
    "text": "The context in which data\nare created, pulled from,",
    "start": "600420",
    "end": "603389"
  },
  {
    "text": "and annotated is\nincredibly important",
    "start": "603390",
    "end": "605855"
  },
  {
    "text": "when thinking about how to\nimprove machine learning",
    "start": "605855",
    "end": "607980"
  },
  {
    "text": "systems.",
    "start": "607980",
    "end": "609398"
  },
  {
    "text": "HARINI SURESH: One\nthing that comes to mind",
    "start": "609398",
    "end": "611190"
  },
  {
    "text": "is Desmond Patton's\nlab at Columbia.",
    "start": "611190",
    "end": "614280"
  },
  {
    "text": "He works on context\naware annotations",
    "start": "614280",
    "end": "617910"
  },
  {
    "text": "of social media data.",
    "start": "617910",
    "end": "619810"
  },
  {
    "text": "So specifically, the work of his\nthat I read is around Twitter--",
    "start": "619810",
    "end": "624029"
  },
  {
    "text": "so looking at tweets\nand specifically",
    "start": "624030",
    "end": "627060"
  },
  {
    "text": "tweets in inner city Chicago.",
    "start": "627060",
    "end": "628770"
  },
  {
    "text": "And the task that\nthey're trying to do",
    "start": "628770",
    "end": "631050"
  },
  {
    "text": "is analyze tweets from\ngang-involved youth in Chicago.",
    "start": "631050",
    "end": "635769"
  },
  {
    "text": "And if you look at\nsome of these tweets,",
    "start": "635770",
    "end": "637890"
  },
  {
    "text": "they're trying to\nannotate them with things",
    "start": "637890",
    "end": "639810"
  },
  {
    "text": "like whether they're\nviolent or whether they",
    "start": "639810",
    "end": "642540"
  },
  {
    "text": "indicate that there's a\nviolent event going on.",
    "start": "642540",
    "end": "644975"
  },
  {
    "text": "And if you were\nto just read them",
    "start": "644975",
    "end": "646350"
  },
  {
    "text": "without any awareness\nof the context",
    "start": "646350",
    "end": "648029"
  },
  {
    "text": "and try to annotate\nthem, something",
    "start": "648030",
    "end": "649770"
  },
  {
    "text": "that seems like it's super\nviolent, if you actually",
    "start": "649770",
    "end": "652470"
  },
  {
    "text": "were in the context and\nwere part of that community,",
    "start": "652470",
    "end": "655680"
  },
  {
    "text": "you might know that it's like\na lyric from a local rapper",
    "start": "655680",
    "end": "658950"
  },
  {
    "text": "or something that requires\na lot of community",
    "start": "658950",
    "end": "661860"
  },
  {
    "text": "specific expertise.",
    "start": "661860",
    "end": "664360"
  },
  {
    "text": "So what they did in this\nproject was actually",
    "start": "664360",
    "end": "667260"
  },
  {
    "text": "get experts from the community\nto look through this data",
    "start": "667260",
    "end": "671250"
  },
  {
    "text": "and do context aware annotation.",
    "start": "671250",
    "end": "675090"
  },
  {
    "text": "And they found that\nthey were able to do",
    "start": "675090",
    "end": "678600"
  },
  {
    "text": "a much better analysis\nof this data that",
    "start": "678600",
    "end": "682019"
  },
  {
    "text": "was much more accurate and\ngrounded in the actual context",
    "start": "682020",
    "end": "686850"
  },
  {
    "text": "that it was a part of.",
    "start": "686850",
    "end": "687819"
  },
  {
    "text": "So that's, I think,\none example where,",
    "start": "687820",
    "end": "689880"
  },
  {
    "text": "if you were to just\napply generic tools,",
    "start": "689880",
    "end": "692190"
  },
  {
    "text": "you would really\nfail at this task.",
    "start": "692190",
    "end": "695118"
  },
  {
    "text": "CATHERINE D'IGNAZIO: There\nare problems pieces that are",
    "start": "695118",
    "end": "697410"
  },
  {
    "text": "slightly less\nculturally fraught,",
    "start": "697410",
    "end": "701129"
  },
  {
    "text": "where there's less room\nfor stereotypes, bias,",
    "start": "701130",
    "end": "705840"
  },
  {
    "text": "pre-existing structural\ninequalities to enter",
    "start": "705840",
    "end": "708450"
  },
  {
    "text": "into, like if we're training\na system to recognize numbers",
    "start": "708450",
    "end": "711780"
  },
  {
    "text": "in an image--",
    "start": "711780",
    "end": "712525"
  },
  {
    "text": "you know what I mean?",
    "start": "712525",
    "end": "713400"
  },
  {
    "text": "That is just--\nthere's less room.",
    "start": "713400",
    "end": "715612"
  },
  {
    "text": "I mean, obviously there's\nstill going to always",
    "start": "715612",
    "end": "717570"
  },
  {
    "text": "be space for interpretation,\nbut there's less room",
    "start": "717570",
    "end": "721410"
  },
  {
    "text": "because we don't have\npre-existing conceptions",
    "start": "721410",
    "end": "724829"
  },
  {
    "text": "of number 9's unworthiness or\nsomething like this, right?",
    "start": "724830",
    "end": "728850"
  },
  {
    "text": "But it's more when we enter into\ndata about using human language",
    "start": "728850",
    "end": "733649"
  },
  {
    "text": "or that is being used for\ndecision-making systems that",
    "start": "733650",
    "end": "736770"
  },
  {
    "text": "have real-life consequences\nfor human beings.",
    "start": "736770",
    "end": "739330"
  },
  {
    "text": "So if we're training resume\nscreeners, for example--",
    "start": "739330",
    "end": "742750"
  },
  {
    "text": "so like systems\nwhere a large company",
    "start": "742750",
    "end": "745500"
  },
  {
    "text": "would do an automated\nsystem to screen",
    "start": "745500",
    "end": "747870"
  },
  {
    "text": "resumes and then only\nput the top ones up",
    "start": "747870",
    "end": "751020"
  },
  {
    "text": "to the humans or whatever.",
    "start": "751020",
    "end": "753180"
  },
  {
    "text": "We're baking in a lot of\nbiases in the process,",
    "start": "753180",
    "end": "756330"
  },
  {
    "text": "and that has to do with where\nthe data are coming from.",
    "start": "756330",
    "end": "758710"
  },
  {
    "text": "And it also has to do with\nwho are labeling the data",
    "start": "758710",
    "end": "760877"
  },
  {
    "text": "and then who are developing\nthe technologies.",
    "start": "760877",
    "end": "764310"
  },
  {
    "text": "And it's not because\nthey're evil, you know.",
    "start": "764310",
    "end": "766742"
  },
  {
    "text": "Like, it's not because\nthere's bad people",
    "start": "766742",
    "end": "768450"
  },
  {
    "text": "at all stages of this pipeline.",
    "start": "768450",
    "end": "770340"
  },
  {
    "text": "It's that we haven't\nsufficiently kind of trained",
    "start": "770340",
    "end": "774690"
  },
  {
    "text": "people along the way.",
    "start": "774690",
    "end": "776430"
  },
  {
    "text": "There are tools to deal\nwith bias, stereotypes,",
    "start": "776430",
    "end": "779790"
  },
  {
    "text": "structural inequalities.",
    "start": "779790",
    "end": "781320"
  },
  {
    "text": "But they just-- they come\nfrom other disciplines.",
    "start": "781320",
    "end": "783490"
  },
  {
    "text": "So how do we bring\nthose things together",
    "start": "783490",
    "end": "785700"
  },
  {
    "text": "to ultimately develop a more\nrobust system that works better",
    "start": "785700",
    "end": "789120"
  },
  {
    "text": "for everybody?",
    "start": "789120",
    "end": "790260"
  },
  {
    "text": "But just because the data are\nnot the subject of ground truth",
    "start": "790260",
    "end": "793770"
  },
  {
    "text": "doesn't mean we just\nthrow up our hands",
    "start": "793770",
    "end": "796380"
  },
  {
    "text": "or, like, forget about it,\nwe can never do anything.",
    "start": "796380",
    "end": "799390"
  },
  {
    "text": "It just means we have to enter\nwith more caution and more",
    "start": "799390",
    "end": "802800"
  },
  {
    "text": "transparency and reflexivity\naround what are the boundaries",
    "start": "802800",
    "end": "807450"
  },
  {
    "text": "and the applications of the\nknowledge that we're producing.",
    "start": "807450",
    "end": "812360"
  },
  {
    "text": "SARAH HANSEN: I asked\nJacob, Harini, and Catherine",
    "start": "812360",
    "end": "814790"
  },
  {
    "text": "what they'd like to hear\nfrom you, our listeners,",
    "start": "814790",
    "end": "817790"
  },
  {
    "text": "about how to help students\ntake a critical approach",
    "start": "817790",
    "end": "820399"
  },
  {
    "text": "to computing.",
    "start": "820400",
    "end": "821943"
  },
  {
    "text": "HARINI SURESH: One\nquestion that I",
    "start": "821943",
    "end": "823360"
  },
  {
    "text": "have that I've\nbeen thinking about",
    "start": "823360",
    "end": "825550"
  },
  {
    "text": "is, what's the right format\nto introduce students",
    "start": "825550",
    "end": "829839"
  },
  {
    "text": "to these concerns?",
    "start": "829840",
    "end": "830840"
  },
  {
    "text": "So in this case, we\ndid an assignment",
    "start": "830840",
    "end": "833440"
  },
  {
    "text": "within a machine learning class.",
    "start": "833440",
    "end": "835360"
  },
  {
    "text": "And I wonder, how\ndoes that compare",
    "start": "835360",
    "end": "839140"
  },
  {
    "text": "to sort of having it be a small\nportion of every assignment",
    "start": "839140",
    "end": "843880"
  },
  {
    "text": "instead of just one assignment?",
    "start": "843880",
    "end": "845650"
  },
  {
    "text": "Or how does that\ncompare to having",
    "start": "845650",
    "end": "848380"
  },
  {
    "text": "a class that's more\nprimarily dedicated",
    "start": "848380",
    "end": "851530"
  },
  {
    "text": "to social and ethical concerns?",
    "start": "851530",
    "end": "854305"
  },
  {
    "text": "CATHERINE D'IGNAZIO:\nThis is my eternal thing",
    "start": "854305",
    "end": "856180"
  },
  {
    "text": "with these classes\nthere's like how",
    "start": "856180",
    "end": "857770"
  },
  {
    "text": "do you weave in the critical\nwhile still giving people--",
    "start": "857770",
    "end": "862330"
  },
  {
    "text": "empowering people with tools\nto ultimately change practices",
    "start": "862330",
    "end": "866500"
  },
  {
    "text": "and also to change the\ntools eventually too.",
    "start": "866500",
    "end": "869020"
  },
  {
    "text": "Because the tools don't in\nthemselves also work perfectly.",
    "start": "869020",
    "end": "871930"
  },
  {
    "text": "They all have\ntheir own politics.",
    "start": "871930",
    "end": "873640"
  },
  {
    "text": "So if people have\nideas about how",
    "start": "873640",
    "end": "876040"
  },
  {
    "text": "do you both build skills\nbut also have them",
    "start": "876040",
    "end": "880420"
  },
  {
    "text": "interrogating tools,\ninterrogating politics,",
    "start": "880420",
    "end": "883720"
  },
  {
    "text": "the critical context in\nwhich the tools are used,",
    "start": "883720",
    "end": "886180"
  },
  {
    "text": "I would love feedback\nor ideas around that.",
    "start": "886180",
    "end": "891783"
  },
  {
    "text": "SARAH HANSEN: If\nyou have insights",
    "start": "891783",
    "end": "893200"
  },
  {
    "text": "to share about engaging\nstudents in thinking",
    "start": "893200",
    "end": "895630"
  },
  {
    "text": "about the social and ethical\nresponsibilities in computing,",
    "start": "895630",
    "end": "899380"
  },
  {
    "text": "please get in touch with us\nat the link in our show notes.",
    "start": "899380",
    "end": "902470"
  },
  {
    "text": "And when you do, you'll be\njoining Catherine, Harini,",
    "start": "902470",
    "end": "905110"
  },
  {
    "text": "and Jacob in spotlighting just\nhow human the digital world is.",
    "start": "905110",
    "end": "909610"
  },
  {
    "text": "If you're interested in learning\nfrom their open and free",
    "start": "909610",
    "end": "912070"
  },
  {
    "text": "teaching materials or remixing\nthem in your own teaching,",
    "start": "912070",
    "end": "915760"
  },
  {
    "text": "you can find them on our\nMIT OpenCourseWare website.",
    "start": "915760",
    "end": "920270"
  },
  {
    "text": "Thank you so much for listening.",
    "start": "920270",
    "end": "922610"
  },
  {
    "text": "Until next time, signing off\nfrom Cambridge, Massachusetts,",
    "start": "922610",
    "end": "926420"
  },
  {
    "text": "I'm your host, Sarah Hansen\nfrom MIT OpenCourseWare.",
    "start": "926420",
    "end": "932200"
  },
  {
    "text": "Chalk Radio's producers\ninclude myself, Brett Paci,",
    "start": "932200",
    "end": "935710"
  },
  {
    "text": "and Dave Lishansky,\nscriptwriting assistance",
    "start": "935710",
    "end": "938590"
  },
  {
    "text": "from Aubrey Calaway.",
    "start": "938590",
    "end": "940120"
  },
  {
    "text": "Show notes for this episode\nwere written by Peter Chipman.",
    "start": "940120",
    "end": "944060"
  },
  {
    "text": "The SERC resource site on OCW\nwas built by Cathleen Nalezyty.",
    "start": "944060",
    "end": "948850"
  },
  {
    "text": "We're funded by MIT Open\nLearning and supporters",
    "start": "948850",
    "end": "952089"
  },
  {
    "text": "like you.",
    "start": "952090",
    "end": "953970"
  },
  {
    "start": "953970",
    "end": "963211"
  }
]
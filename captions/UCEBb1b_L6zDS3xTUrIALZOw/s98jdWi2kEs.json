[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "7410"
  },
  {
    "text": "offer high-quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "7410",
    "end": "13960"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at",
    "start": "13960",
    "end": "19790"
  },
  {
    "text": "ocw.mit.edu. PROFESSOR: OK, so let's\nget started. ",
    "start": "19790",
    "end": "26335"
  },
  {
    "text": "I want to talk mostly about\ncountable state Markov chains today, which is the new topic\nwe started on Wednesday.",
    "start": "26335",
    "end": "35790"
  },
  {
    "text": "I want to talk just a little bit\nabout the strong law proof",
    "start": "35790",
    "end": "41360"
  },
  {
    "text": "that was in the third\nproblem of the quiz. I'm not doing that because\nnone of you understood",
    "start": "41360",
    "end": "49039"
  },
  {
    "text": "anything about it. I'm doing it because all of you\nunderstood more about it than I thought you would.",
    "start": "49040",
    "end": "55680"
  },
  {
    "text": "And in fact, I've always avoided\nsaying too much about this proof because I thought\neverybody was tuning them out.",
    "start": "55680",
    "end": "64009"
  },
  {
    "text": "And for the class here, it looks\nlike a lot of you have tried seriously to understand\nthese things.",
    "start": "64010",
    "end": "69870"
  },
  {
    "text": "So I thought I would explain\nthat one part of the quiz in",
    "start": "69870",
    "end": "75090"
  },
  {
    "text": "detail so that you'd see the\nparts you're missing, and so that [INAUDIBLE] all these other\nproofs that we have,",
    "start": "75090",
    "end": "82110"
  },
  {
    "text": "talking about the strong law\nand the strong law for renewals, and putting them\ntogether and all of these",
    "start": "82110",
    "end": "87250"
  },
  {
    "text": "things, all of them are\nessentially the same. And it's just a matter\nof figuring out",
    "start": "87250",
    "end": "94070"
  },
  {
    "text": "how things fit together. So I wanted to talk about that\nbecause it's clear that most",
    "start": "94070",
    "end": "103090"
  },
  {
    "text": "of you understand enough about\nit that it makes sense. The situation in the quiz, which\nis very close to the",
    "start": "103090",
    "end": "110420"
  },
  {
    "text": "usual queuing situation and\nlittle theorem type things,",
    "start": "110420",
    "end": "116189"
  },
  {
    "text": "there's a sequence\nof Y sub i's. They're IID. There's the service times for\nG/G infinity queue, and n of",
    "start": "116190",
    "end": "126120"
  },
  {
    "text": "t, which is a renewal\nprocess for the arrivals to the process. We have arrivals coming in\naccording to this renewal",
    "start": "126120",
    "end": "134070"
  },
  {
    "text": "process, which means the\n[INAUDIBLE] arrival times, X sub i, were IID.",
    "start": "134070",
    "end": "140680"
  },
  {
    "text": "And we want to put those\ntwo things together. And we want to find out\nwhat this limit is.",
    "start": "140680",
    "end": "151250"
  },
  {
    "text": "If it's a limit, show\nthat it's a limit. And hopefully show that it's\na limit with probability 1.",
    "start": "151250",
    "end": "158490"
  },
  {
    "text": "And I think a large number of\nyou basically realize that",
    "start": "158490",
    "end": "165500"
  },
  {
    "text": "this argument consisted\nof a bunch of steps. Some people with more\ndetail than others.",
    "start": "165500",
    "end": "172400"
  },
  {
    "text": "But the first step, which we do\nin all of these arguments,",
    "start": "172400",
    "end": "177849"
  },
  {
    "text": "is to divide and multiply\nby n of t of omega.",
    "start": "177850",
    "end": "183010"
  },
  {
    "text": "So we're starting out, looking\nat some particular sample path, and start out by\nmultiplying and dividing by n",
    "start": "183010",
    "end": "191670"
  },
  {
    "text": "of t of omega. The next thing is to claim that\nthe limit of this times",
    "start": "191670",
    "end": "198640"
  },
  {
    "text": "this is equal to the limit of\nthis times the limit of this.",
    "start": "198640",
    "end": "204680"
  },
  {
    "text": "Almost no one recognized that as\na real problem, and that is a real problem.",
    "start": "204680",
    "end": "210840"
  },
  {
    "text": "It's probably the least\nobvious thing in this whole problem.",
    "start": "210840",
    "end": "219080"
  },
  {
    "text": "I'm not saying you shouldn't\nhave done that, because I've been doing that in all\nthe proofs I've been giving you all along.",
    "start": "219080",
    "end": "225500"
  },
  {
    "text": "It is sort of obvious\nthat that works. And when you're constructing a\nproof, especially in a quiz",
    "start": "225500",
    "end": "233120"
  },
  {
    "text": "when you don't have much time,\nthings which are almost obvious or which look obvious,\nyou should just go ahead and",
    "start": "233120",
    "end": "240300"
  },
  {
    "text": "assume them and come back later\nwhen you have time to see whether that really\nmakes sense.",
    "start": "240300",
    "end": "245860"
  },
  {
    "text": "That's the way you\ndo research also. You don't do research by\npainstakingly establishing",
    "start": "245860",
    "end": "252239"
  },
  {
    "text": "every point in some\nlinear path. What you do is you carelessly\nas you can and with as much",
    "start": "252240",
    "end": "262320"
  },
  {
    "text": "insight as you can, you jump\nall the way to the end, you see where you're trying to go,\nyou see how to get there, and",
    "start": "262320",
    "end": "269310"
  },
  {
    "text": "then you come back and you try\nto figure out what each of the steps are.",
    "start": "269310",
    "end": "274880"
  },
  {
    "text": "So this is certainly a very\nreasonable way of solving this problem, because it looks like\nthis limit should be equal to",
    "start": "274880",
    "end": "282250"
  },
  {
    "text": "this limit times this limit. The next step in the argument is\nto claim that this sum, up",
    "start": "282250",
    "end": "290520"
  },
  {
    "text": "to N of t of omega, over\nN of t of omega, as t approaches infinity--",
    "start": "290520",
    "end": "296220"
  },
  {
    "text": "the argument is that t\napproaches infinity-- this N of t of omega goes\nthrough, one by one, a",
    "start": "296220",
    "end": "304500"
  },
  {
    "text": "sequence, 1, 2, 3, 4,\n5, and so forth. So this limit is equal\nto that limit.",
    "start": "304500",
    "end": "312320"
  },
  {
    "text": "I've never been able to figure\nout whether that's obvious or not obvious. It is just on the borderline\nbetween what's obvious and not",
    "start": "312320",
    "end": "320390"
  },
  {
    "text": "obvious, so I'm gonna\nprove it to you. And then the next step is to see\nthat N of t of omega over",
    "start": "320390",
    "end": "329470"
  },
  {
    "text": "t is equal to 1/X-bar\nwith probability 1.",
    "start": "329470",
    "end": "335260"
  },
  {
    "text": "And this limit is equal to\nY-bar with probability 1. The first argument, this equal\nto 1/X-bar is because of the",
    "start": "335260",
    "end": "345770"
  },
  {
    "text": "strong law with renewals. And this one over here is\nbecause of the strong law of",
    "start": "345770",
    "end": "351010"
  },
  {
    "text": "large numbers. And most of you managed\nto get this. And the whole argument assumes\nthat X-bar is less than",
    "start": "351010",
    "end": "357200"
  },
  {
    "text": "infinity, and Y-bar is\nless than infinity. Now, how do you go back and\nactually see that this",
    "start": "357200",
    "end": "363720"
  },
  {
    "text": "actually makes sense? And that's what I\nwant to do next. And if you look at this, you\ncan't do it by starting here",
    "start": "363720",
    "end": "373720"
  },
  {
    "text": "and working your way down to\nthere, because there's no way you're going to argue that this\nlimit is equal to this",
    "start": "373720",
    "end": "380620"
  },
  {
    "text": "product of limit unless you know\nsomething about this and you know something about this.",
    "start": "380620",
    "end": "385960"
  },
  {
    "text": "So you really have to establish\nthat these things have limits first before\nyou can go back",
    "start": "385960",
    "end": "391020"
  },
  {
    "text": "and establish this. In the same way, you have to\nknow something about this before you can establish this.",
    "start": "391020",
    "end": "397780"
  },
  {
    "text": "So what you have to do way after\nyou've managed to have the insight to jump the whole\nway through this thing, is to",
    "start": "397780",
    "end": "404400"
  },
  {
    "text": "go back and argue each of the\npoints, but argue them in reverse order.",
    "start": "404400",
    "end": "410465"
  },
  {
    "text": "And that's very often the way\nyou do research, and it's certainly the way\nyou do quizzes.",
    "start": "410465",
    "end": "416610"
  },
  {
    "text": "So let's see where those\narguments were.",
    "start": "416610",
    "end": "422750"
  },
  {
    "text": "Start out by letting A1 be the\nset of omega for which this limit here, N of t of omega over\nt, is equal to 1/X-bar.",
    "start": "422750",
    "end": "434670"
  },
  {
    "text": "By the strong law for renewal\nprocesses, the probability of A1 equals 1.",
    "start": "434670",
    "end": "441000"
  },
  {
    "text": "This is stating this in a little\ncleaner way, I think, than we stated the strong law\nof renewals originally,",
    "start": "441000",
    "end": "448000"
  },
  {
    "text": "because we started out by\ntumbling together this statement and this statement.",
    "start": "448000",
    "end": "454660"
  },
  {
    "text": "I think it's cleaner to say,\nstart out, there's a set of omega 1 for which this\nlimit exists.",
    "start": "454660",
    "end": "461700"
  },
  {
    "text": "And what the strong law says is\nthat that set of omega has probability 1.",
    "start": "461700",
    "end": "467000"
  },
  {
    "text": "And now we have some terminology\nfor A1, what it actually means. It is the set of omega\nfor which this works.",
    "start": "467000",
    "end": "473830"
  },
  {
    "text": "You never have it working\nfor all omega, only for some omega. Then the next step, let A2 be\nthe set of omega for which the",
    "start": "473830",
    "end": "483729"
  },
  {
    "text": "limit is n goes to infinity of\n1/n times the sum of Y sub i",
    "start": "483730",
    "end": "489400"
  },
  {
    "text": "of omega, is equal to Y-bar. By the strong law of large\nnumbers, the probability of A2",
    "start": "489400",
    "end": "498010"
  },
  {
    "text": "is equal to 1.  So now we've established there's\nan A1, there's an A2.",
    "start": "498010",
    "end": "506180"
  },
  {
    "text": "Each of them have\nprobability 1. On A1, one limit exists. On A2, the other limit exists.",
    "start": "506180",
    "end": "512240"
  },
  {
    "text": "And we have two sets, both\nat probability 1. What's the probability of the\nintersection of them?",
    "start": "512240",
    "end": "517799"
  },
  {
    "text": "It has to be 1 also. So with that, you know that\nequation three is equal to",
    "start": "517799",
    "end": "525570"
  },
  {
    "text": "equation four for omega\nin the sets, A1, A2. And also, you know that\nthe probability of A1,",
    "start": "525570",
    "end": "532290"
  },
  {
    "text": "A2 is equal to 1. So we've established this part\nof the argument down here.",
    "start": "532290",
    "end": "541420"
  },
  {
    "text": "Now we want to go up and\nestablish this part of the argument, which as I said, I\ncan't convince myself that",
    "start": "541420",
    "end": "550540"
  },
  {
    "text": "it's necessary or\nnot necessary. But since I can't convince\nmyself, I thought, in trying",
    "start": "550540",
    "end": "557290"
  },
  {
    "text": "to make up solutions for the\nquiz, I ought to actually write a proof of it. And I want to show you what the\nproof is so that, if it's",
    "start": "557290",
    "end": "564680"
  },
  {
    "text": "not obvious to you, you'll know\nexactly how to do it. And if it is obvious, you can\nmaybe sort out exactly why",
    "start": "564680",
    "end": "573200"
  },
  {
    "text": "it's obvious. So this is an epsilon delta\nkind of argument. We assume that omega is in A2.",
    "start": "573200",
    "end": "579680"
  },
  {
    "text": "That's the set for which\nthe strong law of large numbers holds. There exists some integer, n,\nwhich is a function of both",
    "start": "579680",
    "end": "588360"
  },
  {
    "text": "epsilon and omega. This is the funny thing\nabout all of these strong law arguments.",
    "start": "588360",
    "end": "593820"
  },
  {
    "text": "In almost all of them,\nyou're dealing with individual sample paths. When you start saying something\nexists as a limit,",
    "start": "593820",
    "end": "601399"
  },
  {
    "text": "you're not saying that it exists\nas a limit for the random variables. You're saying it exists\nas a limit for a",
    "start": "601400",
    "end": "607470"
  },
  {
    "text": "set of sample paths. And therefore, this epsilon here\nthat you're gonna choose,",
    "start": "607470",
    "end": "614540"
  },
  {
    "text": "you need some integer there,\nsuch that this minus this is",
    "start": "614540",
    "end": "625089"
  },
  {
    "text": "less than epsilon. I think I'm going to have\nto give up on this. These things run out of\nbatteries too quickly.",
    "start": "625090",
    "end": "630880"
  },
  {
    "text": "So we have that this difference\nhere must be less than epsilon if n is bigger than\nthat m of epsilon omega.",
    "start": "630880",
    "end": "639870"
  },
  {
    "text": "That's simply what\na limit means. That's the definition\nof a limit. The only way to define a limit\nsensibly is to say, for all",
    "start": "639870",
    "end": "647440"
  },
  {
    "text": "epsilon greater than 0, no\nmatter how small the epsilon is, you can always find an\nn big enough that this",
    "start": "647440",
    "end": "654500"
  },
  {
    "text": "difference here is less\nthan epsilon. Then if omega is also in A1, the\nlimit of N of t of omega",
    "start": "654500",
    "end": "664210"
  },
  {
    "text": "has to be equal to infinity. If you want to, you can just\nsay, we proved in class that the limit of t of omega is\nequal to infinity with",
    "start": "664210",
    "end": "671820"
  },
  {
    "text": "probability 1, and introduce\nanother set, A3. You want to do a\nprobability 1. But let's do it this way.",
    "start": "671820",
    "end": "678620"
  },
  {
    "text": "And then there has to be a t,\nwhich is also a function of epsilon and omega, such\nthat N of t and",
    "start": "678620",
    "end": "684910"
  },
  {
    "text": "omega is greater than-- that's an integer, by the way. That's greater than or equal to\nm of epsilon of omega for",
    "start": "684910",
    "end": "693060"
  },
  {
    "text": "all t, which is greater\nthan or equal to t of epsilon of omega. That says that this difference\nhere is less than omega.",
    "start": "693060",
    "end": "701370"
  },
  {
    "text": "And that's true for all epsilon\ngreater than 0. And that says that, in fact,\nthis limit has to exist.",
    "start": "701370",
    "end": "710650"
  },
  {
    "text": "This limit over here is equal\nto Y-bar with probability 1. So that's what we were trying to\nprove here, that this limit",
    "start": "710650",
    "end": "723769"
  },
  {
    "text": "is the same as this limit. So we found out what\nthis limit is. We found out that it exists with\nprobability 1, namely on",
    "start": "723770",
    "end": "730350"
  },
  {
    "text": "the set A2. This is equal to this, not\nnecessarily on A2, but on A1 and A2.",
    "start": "730350",
    "end": "737070"
  },
  {
    "text": "So we got into there. Now how do we get the fact that\nthis limit times this",
    "start": "737070",
    "end": "742820"
  },
  {
    "text": "limit is equal to the limit\nof [? these. ?] Now we have a chance of\nproceeding, because we've actually shown that this limit\nexists on some set with",
    "start": "742820",
    "end": "751520"
  },
  {
    "text": "probability 1, this limit\nexists on some set with probability 1. So we can look at that set and\nsay, for omega in that set,",
    "start": "751520",
    "end": "761090"
  },
  {
    "text": "this limit exists and\nthis limit exists. Those limits are non-0 and\nthey're non-infinite.",
    "start": "761090",
    "end": "767570"
  },
  {
    "text": "The important thing is that\nthey're non-infinite. And we move on from there,\nand to do that carefully.",
    "start": "767570",
    "end": "777920"
  },
  {
    "text": "And again, I'm not suggesting\nthat I expect any of you to do this on the quiz. I would have been amazed\nif you had.",
    "start": "777920",
    "end": "785230"
  },
  {
    "text": "It took me quite a while to sort\nit out, because all these things are tangled together.",
    "start": "785230",
    "end": "790380"
  },
  {
    "text": " Where am I?",
    "start": "790380",
    "end": "795480"
  },
  {
    "text": "I want to be in the\nnext slide. Ah, there we go. Finally, we can interchange the\nlimit of a product of two",
    "start": "795480",
    "end": "800870"
  },
  {
    "text": "functions-- say, f of t, g of t-- with the product\nof the limits. Can we do that?",
    "start": "800870",
    "end": "806820"
  },
  {
    "text": "If the two functions each have\nfinite limits, as the functions of interests do for\nomega in A1, A2, then the",
    "start": "806820",
    "end": "814310"
  },
  {
    "text": "answer is yes. And if you look at any book\non analysis, I'm sure that",
    "start": "814310",
    "end": "819699"
  },
  {
    "text": "theorem is somewhere in the\nfirst couple of chapters. But anyway, if you're the kind\nof person like I am who would",
    "start": "819700",
    "end": "828050"
  },
  {
    "text": "rather sort something out for\nyourself rather than look it up, there's a trick involved\nin doing it.",
    "start": "828050",
    "end": "835220"
  },
  {
    "text": "It's this equality right here. f of t times g of t minus ab. What you want to do is somehow\nmake that look like f of t",
    "start": "835220",
    "end": "844010"
  },
  {
    "text": "minus a, which you have\nsome control over, and g of t minus b. So the identity is this is equal\nto f of t minus a times",
    "start": "844010",
    "end": "853340"
  },
  {
    "text": "g of t minus b-- we have control over that-- plus a times g of t minus b,\nplus b times f of t minus a.",
    "start": "853340",
    "end": "862680"
  },
  {
    "text": "And you multiply and add all\nthose things together and you see that that is just\nan identity.",
    "start": "862680",
    "end": "868709"
  },
  {
    "text": "And therefore the magnitude of\nf of t times g of t minus ab",
    "start": "868710",
    "end": "873940"
  },
  {
    "text": "is less than or equal to this. And then you go through all the\nepsilon delta stuff again.",
    "start": "873940",
    "end": "879420"
  },
  {
    "text": "For any epsilon greater than\n0, you choose a t such that this is less than or equal\nto epsilon for t",
    "start": "879420",
    "end": "886500"
  },
  {
    "text": "greater than the t epsilon. This is less than or equal to\nepsilon for t greater than or",
    "start": "886500",
    "end": "891880"
  },
  {
    "text": "equal to t epsilon. And then this difference here\nis less than or equal to epsilon squared plus this.",
    "start": "891880",
    "end": "898400"
  },
  {
    "text": "And with a little extra fiddling\naround, that shows you have that f of t, g of t\nminus ab approaches 0 as t",
    "start": "898400",
    "end": "908709"
  },
  {
    "text": "gets large. So that's the whole thing. Now, let me reemphasize\nagain, I did not",
    "start": "908710",
    "end": "915290"
  },
  {
    "text": "expect you to do that. I did not expect you to know how\nto do analysis arguments",
    "start": "915290",
    "end": "920970"
  },
  {
    "text": "like that, because\nanalysis is not a prerequisite for the course.",
    "start": "920970",
    "end": "926000"
  },
  {
    "text": "I do want to show you that the\nkinds of things we've been doing are not, in fact,\nimpossible.",
    "start": "926000",
    "end": "931520"
  },
  {
    "text": "If you trace them out from\nbeginning to end and put in every little detail in them.",
    "start": "931520",
    "end": "938180"
  },
  {
    "text": "If you have to go through\nthese kinds of arguments again, you will in fact know\nhow to make it precise and",
    "start": "938180",
    "end": "944220"
  },
  {
    "text": "know how to put all\nthose details in. Let's go back to countable\nstate Markov chains.",
    "start": "944220",
    "end": "952700"
  },
  {
    "text": "As we've said, two states are\nin the same class as they communicate.",
    "start": "952700",
    "end": "957780"
  },
  {
    "text": "It's the same definition as\nfor finite state chains. They communicate if there's some\npath by which you can get",
    "start": "957780",
    "end": "965110"
  },
  {
    "text": "from i to j, and there's some\npath from which you can get from j to i. And you can't get there in one\nstep only, but you can get",
    "start": "965110",
    "end": "974850"
  },
  {
    "text": "there in some finite\nnumber of steps. So that's the definition of\ntwo states communicating.",
    "start": "974850",
    "end": "981950"
  },
  {
    "text": "The theorem that we sort of\nproved last time is that all states in the same class are",
    "start": "981950",
    "end": "987930"
  },
  {
    "text": "recurrent or all are transient. That's the same as the theorem\nwe have for finite state",
    "start": "987930",
    "end": "993190"
  },
  {
    "text": "Markov chains. It's just a little hard\nto establish here. The argument is that you assume\nthat j is recurrent.",
    "start": "993190",
    "end": "1004009"
  },
  {
    "text": "If j is recurrent,\nthen the sum has to be equal to infinity.",
    "start": "1004010",
    "end": "1009420"
  },
  {
    "text": "How do you interpret\nthat sum there? What is it? P sub jj, super n, is the\nprobability that you will be",
    "start": "1009420",
    "end": "1023050"
  },
  {
    "text": "in state j at time n given\nthat you're in state j at time 0.",
    "start": "1023050",
    "end": "1028510"
  },
  {
    "text": "So what we're doing is we're\nstarting out in time 0. This quantity here is the\nprobability that we'll be in",
    "start": "1028510",
    "end": "1036449"
  },
  {
    "text": "state j at time n. Since you either are or you're\nnot, since this is also equal",
    "start": "1036450",
    "end": "1044900"
  },
  {
    "text": "to the expected value of state\nj at time n, given",
    "start": "1044900",
    "end": "1050830"
  },
  {
    "text": "state j at time 0. So when you add all these up,\nyou're adding expectations.",
    "start": "1050830",
    "end": "1056010"
  },
  {
    "text": "So this quantity here is simply\nthe expected number of recurrences to state j from time\n1 up to time infinity.",
    "start": "1056010",
    "end": "1066340"
  },
  {
    "text": "And that number of recurrences\nis equal to infinity. You remember we argued last time\nthat the probability of",
    "start": "1066340",
    "end": "1073360"
  },
  {
    "text": "one recurrence had to be equal\nto 1 if it was recurrent. If you got back to j once in\nfinite time, you're going to",
    "start": "1073360",
    "end": "1081400"
  },
  {
    "text": "get back again in a\nfinite time again. You're going to get back\nagain in finite time. It might take a very, very long\ntime, but it's finite,",
    "start": "1081400",
    "end": "1088950"
  },
  {
    "text": "and you have an infinite number\nof returns as time goes to infinity.",
    "start": "1088950",
    "end": "1094470"
  },
  {
    "text": "So that is the consequence\nof j being recurrent. For any i such that j and i\ncommunicate, there's some path",
    "start": "1094470",
    "end": "1104220"
  },
  {
    "text": "at some length m such that the\nprobability of going from state i to state j in m steps\nis greater than 0.",
    "start": "1104220",
    "end": "1112210"
  },
  {
    "text": "That's by meaning\nof communicate. And there's some m and\nsome pji of l.",
    "start": "1112210",
    "end": "1119393"
  },
  {
    "text": " Oh, for [? some m. ?] And there's some way of getting\nback from j to i.",
    "start": "1119394",
    "end": "1128810"
  },
  {
    "text": "So what you're doing is going\nfrom state i to state j, and there is some path\nfor doing that.",
    "start": "1128810",
    "end": "1134780"
  },
  {
    "text": "You're wobbling around,\nreturning to state j, returning to state j,\nmaybe returning to",
    "start": "1134780",
    "end": "1140580"
  },
  {
    "text": "state i along the way. That's part of it. And eventually there's\nsome path for going",
    "start": "1140580",
    "end": "1147960"
  },
  {
    "text": "from j back to i again. So this sum here is greater\nthan or equal.",
    "start": "1147960",
    "end": "1156360"
  },
  {
    "text": "And now all I'm doing is summing\nup the paths which in m steps go from i to j, and\nthose paths which in the final",
    "start": "1156360",
    "end": "1164010"
  },
  {
    "text": "l steps go from j back to i. And they do whatever they\nwant to in between.",
    "start": "1164010",
    "end": "1169390"
  },
  {
    "text": "So I'm summing over the number\nof times they are in between. And this sum here is\nsumming over pjjk.",
    "start": "1169390",
    "end": "1178750"
  },
  {
    "text": "And that sum is infinite,\nso this sum is infinite. So that shows that if j is\nrecurrent, then i is recurrent",
    "start": "1178750",
    "end": "1189570"
  },
  {
    "text": "also for any i in\nthe same class. And you can do the same thing\nreversing i and j, obviously.",
    "start": "1189570",
    "end": "1197870"
  },
  {
    "text": "And if that's true for all\nclasses that are very recurrent, all law classes that\nare transient have to be",
    "start": "1197870",
    "end": "1203909"
  },
  {
    "text": "in the same class also, because\na state is either transient or it's recurrent. ",
    "start": "1203910",
    "end": "1210309"
  },
  {
    "text": "If a state j is recurrent,\nthen the recurrence time, T sub jj.",
    "start": "1210310",
    "end": "1216840"
  },
  {
    "text": "When you read this chapter or\nread my notes, I apologize because there's a huge\nconfusion here.",
    "start": "1216840",
    "end": "1225260"
  },
  {
    "text": "And the confusion comes from\nthe fact that there's an extraordinary amount\nof notation here.",
    "start": "1225260",
    "end": "1230790"
  },
  {
    "text": "We're dealing with all the\nnotation of finite-state Markov chains. We're dealing with all the\nnotation of renewal processes.",
    "start": "1230790",
    "end": "1238350"
  },
  {
    "text": "And we're jumping back and forth\nbetween theorems for one and theorems for the other. And then we're inventing\na lot of new notation.",
    "start": "1238350",
    "end": "1245559"
  },
  {
    "text": "And I have to rewrite\nthat section. But anyway, the results are all\ncorrect as far as I know.",
    "start": "1245560",
    "end": "1253330"
  },
  {
    "start": "1253330",
    "end": "1258710"
  },
  {
    "text": "I mean, all of you can remember\nnotation much better than I can. So if I can remember this\nnotation, you can also.",
    "start": "1258710",
    "end": "1264450"
  },
  {
    "text": "Let me put it that way. So I can't feel too\nsorry for you. I want to rewrite it because I'm\nfeeling sorry for myself",
    "start": "1264450",
    "end": "1270780"
  },
  {
    "text": "after every year I go through\nthis and try to re-understand it again, and I find it\nvery hard to do it.",
    "start": "1270780",
    "end": "1277070"
  },
  {
    "text": "So I'm going to rewrite\nit and get rid of some of that notation.",
    "start": "1277070",
    "end": "1283120"
  },
  {
    "text": "We've already seen that if you\nhave a chain like this, which is simply the Markov chain\ncorresponding to Bernoulli",
    "start": "1283120",
    "end": "1290230"
  },
  {
    "text": "trials, if it's Bernoulli trials\nwith p equals 1/2, you move up a probability\n1/2, you move down",
    "start": "1290230",
    "end": "1297530"
  },
  {
    "text": "with probability 1/2. As we said, you eventually\ndisperse. And as you disperse, the\nprobability of being in any",
    "start": "1297530",
    "end": "1304960"
  },
  {
    "text": "one of these states goes to 0. And what that means is that the\nindividual probabilities",
    "start": "1304960",
    "end": "1315800"
  },
  {
    "text": "of the states is going to 0. You can also see, not so easily,\nthat you're eventually",
    "start": "1315800",
    "end": "1322340"
  },
  {
    "text": "going to return to each state\nwith probability 1. And I'm sorry I didn't give\nthat definition first.",
    "start": "1322340",
    "end": "1328650"
  },
  {
    "text": "We gave it last time. If the expected value of the\nrenewal time is less than",
    "start": "1328650",
    "end": "1334000"
  },
  {
    "text": "infinity, then j is positive\nrecurrent. ",
    "start": "1334000",
    "end": "1339380"
  },
  {
    "text": "If T sub jj, the recurrence\ntime, is a random variable but it has infinite expectation,\nthen j is not recurrent.",
    "start": "1339380",
    "end": "1348460"
  },
  {
    "text": "And finally, if none of those\nthings happen, j is transient. So that we went through\nlast time.",
    "start": "1348460",
    "end": "1354820"
  },
  {
    "text": "And for p equals 1/2, and in\nboth of these situations, the",
    "start": "1354820",
    "end": "1360880"
  },
  {
    "text": "probability of being in any\nstate is going to 0. The expected time of returning\nis going to infinity.",
    "start": "1360880",
    "end": "1370460"
  },
  {
    "text": "But with probability 1, you\nwill return eventually.",
    "start": "1370460",
    "end": "1375529"
  },
  {
    "text": "So in both of these cases, these\nare both examples of no recurrence.",
    "start": "1375530",
    "end": "1381130"
  },
  {
    "text": " Let's say more about positive\nrecurrence and no recurrence.",
    "start": "1381130",
    "end": "1391220"
  },
  {
    "text": "Suppose, first, that i and j\nare both recurrent and they",
    "start": "1391220",
    "end": "1396720"
  },
  {
    "text": "both communicate with\neach other. In other words, there's a path\nfrom i to j, there's a path from j to i.",
    "start": "1396720",
    "end": "1404260"
  },
  {
    "text": "And I want to look at\nthe renewal process of returns to j.",
    "start": "1404260",
    "end": "1410620"
  },
  {
    "text": "You've sorted out by now, I\nthink, that recurrence means exactly what you\nthink it means.",
    "start": "1410620",
    "end": "1417070"
  },
  {
    "text": "A recurrence means, starting\nfrom a state j, there's a",
    "start": "1417070",
    "end": "1422110"
  },
  {
    "text": "recurrence to j if eventually\nyou come back to j. And this random variable, the\nrecurrence of random variable,",
    "start": "1422110",
    "end": "1429759"
  },
  {
    "text": "is the amount of time it takes\nyou to get back to j once you've been in j. That's a random variable.",
    "start": "1429760",
    "end": "1437730"
  },
  {
    "text": "So let's look at the renewal\nprocess, starting in j, of",
    "start": "1437730",
    "end": "1443070"
  },
  {
    "text": "returning to j eventually. This is one of the\nthings that makes this whole study awkward.",
    "start": "1443070",
    "end": "1449910"
  },
  {
    "text": "We have renewal processes when\nwe start at j and we bob back",
    "start": "1449910",
    "end": "1455020"
  },
  {
    "text": "to j at various periods\nof time. If we start in i and we're\ninterested in returns to j,",
    "start": "1455020",
    "end": "1461390"
  },
  {
    "text": "then we have something called\na delayed renewal process. All the theorems about\nrenewals apply there.",
    "start": "1461390",
    "end": "1468710"
  },
  {
    "text": "It's a little harder to\nsee what's going on. It's in the end of\nchapter four.",
    "start": "1468710",
    "end": "1473890"
  },
  {
    "text": "You should have read it,\nat least quickly. But we're going to avoid those\ntheorems and instead go",
    "start": "1473890",
    "end": "1480870"
  },
  {
    "text": "directly using the theorems\nof renewal processes. But there's still places where\nthe transitions are awkward.",
    "start": "1480870",
    "end": "1488179"
  },
  {
    "text": "So I can warn you about that. But the renewal reward theorem,\nif I look at this",
    "start": "1488180",
    "end": "1496690"
  },
  {
    "text": "renewal process, I get a\nrenewal every time I return to state j.",
    "start": "1496690",
    "end": "1503159"
  },
  {
    "text": "But in that renewal process of\nreturns to state j, what I'm really interested in is returns\nto state i, because",
    "start": "1503160",
    "end": "1511980"
  },
  {
    "text": "what I'm trying to do here is\nrelate how often do you go to state i with how often\ndo you go to state j?",
    "start": "1511980",
    "end": "1519029"
  },
  {
    "text": "So we have a little bit of a\nsymmetry in it, because we're starting in state j,\nbecause that gives us a renewal process.",
    "start": "1519030",
    "end": "1525320"
  },
  {
    "text": "But now we have this renewal\nreward process, where we give ourselves a reward of 1 every\ntime we hit state i.",
    "start": "1525320",
    "end": "1534260"
  },
  {
    "text": "And we have a renewal every\ntime we hit state j. So how does that renewal\nprocess work?",
    "start": "1534260",
    "end": "1540250"
  },
  {
    "text": "Well, it's a renewal process\njust like every other one we've studied. It has this peculiar feature\nhere that is a discrete time",
    "start": "1540250",
    "end": "1550200"
  },
  {
    "text": "renewal process. And with discrete time renewal\nprocesses, as we've seen, you",
    "start": "1550200",
    "end": "1555930"
  },
  {
    "text": "can save yourself a lot of\naggravation by only looking at these discrete times.",
    "start": "1555930",
    "end": "1561230"
  },
  {
    "text": "Namely, you only look\nat integer times. And now when you only look\nat integer times--",
    "start": "1561230",
    "end": "1567940"
  },
  {
    "text": "well, whether you look at\ninteger times or not-- this is the fundamental theorem\nof renewal rewards.",
    "start": "1567940",
    "end": "1574340"
  },
  {
    "text": "If you look at the limit as t\ngoes to infinity, there's the integral of the rewards\nyou pick up.",
    "start": "1574340",
    "end": "1580419"
  },
  {
    "text": "For this discrete case, this\nis just a summation of the rewards that you get.",
    "start": "1580420",
    "end": "1585550"
  },
  {
    "text": "This summation here by the\ntheorem is equal to the expected number of rewards\nwithin one renewal period.",
    "start": "1585550",
    "end": "1593139"
  },
  {
    "text": "Namely, this is the expected\nnumber of recurrences of state i per state j.",
    "start": "1593140",
    "end": "1600100"
  },
  {
    "text": "So in between each occurrence\nof state j, what's the",
    "start": "1600100",
    "end": "1606090"
  },
  {
    "text": "expected number of\ni's that I hit? And that's the number\nthat it is. We don't know what that number\nis, but we could calculate it",
    "start": "1606090",
    "end": "1613510"
  },
  {
    "text": "if we wanted to. It's not a limit of anything. Well, it's a sort of a limit,\nbut not very much of a limit",
    "start": "1613510",
    "end": "1621580"
  },
  {
    "text": "that's well defined. And the theorem says that this\nintegral is equal to that expected value divided by\nthe expected recurrence",
    "start": "1621580",
    "end": "1630040"
  },
  {
    "text": "time of T sub jj. Now, we argue that this is,\nin fact, the number of",
    "start": "1630040",
    "end": "1638160"
  },
  {
    "text": "occurrences of state i. So it's in the limit. It's 1 over the expected\nvalue of the recurrence",
    "start": "1638160",
    "end": "1648620"
  },
  {
    "text": "time to state i. So what this says is the 1 over\nthe recurrence time to",
    "start": "1648620",
    "end": "1655179"
  },
  {
    "text": "state i is equal to the expected\nnumber of recurrences to state i per state j divided\nby the expected",
    "start": "1655180",
    "end": "1663409"
  },
  {
    "text": "time in state j. If you think about that for a\nminute, it's something which",
    "start": "1663410",
    "end": "1669070"
  },
  {
    "text": "is intuitively obvious. I mean, you look at this long\nsequences of things.",
    "start": "1669070",
    "end": "1675060"
  },
  {
    "text": "You keep hitting j's every\nonce in a while. And then what you do,\nis you count all of",
    "start": "1675060",
    "end": "1680760"
  },
  {
    "text": "the i's that occur. So now looking at it this way,\nyou're going to count the number of i's that occur\nin between each j.",
    "start": "1680760",
    "end": "1689340"
  },
  {
    "text": "You can't have a simultaneous\ni and j. The state is o or j. ",
    "start": "1689340",
    "end": "1696010"
  },
  {
    "text": "So for each recurrence period,\nyou count the number of i's that occur. And what this is then saying,\nis the expected time between",
    "start": "1696010",
    "end": "1704640"
  },
  {
    "text": "i's is equal to the expected\ntime between j's divided by--",
    "start": "1704640",
    "end": "1710920"
  },
  {
    "text": "if I turn this equation upside\ndown, the expected time between i's is equal to the\nexpected time between j's",
    "start": "1710920",
    "end": "1718090"
  },
  {
    "text": "divided by the expected\nnumber of i's per j.",
    "start": "1718090",
    "end": "1723169"
  },
  {
    "text": "What else would you expect? It has to be that way, right?",
    "start": "1723170",
    "end": "1728390"
  },
  {
    "text": "But this says that it\nindeed, is that way. Mathematics is sometimes\nconfusing with countable-state",
    "start": "1728390",
    "end": "1734100"
  },
  {
    "text": "chains as we've seen. OK, so the theorem then says for\ni and j recurrent, either",
    "start": "1734100",
    "end": "1744890"
  },
  {
    "text": "both are positive-recurrent or\nboth are null-recurrent. So this is adding to the\ntheorem we had earlier.",
    "start": "1744890",
    "end": "1751610"
  },
  {
    "text": "The theorem we had earlier says\nthat all states within a",
    "start": "1751610",
    "end": "1758330"
  },
  {
    "text": "class are either recurrent\nor they're transient. This now divides the ones that\nare recurrent into two",
    "start": "1758330",
    "end": "1765860"
  },
  {
    "text": "subsets, those that are\nnull-recurrent and those that are positive-recurrent. It says that for states within\na class, either all of them",
    "start": "1765860",
    "end": "1774940"
  },
  {
    "text": "are recurrent or all\nof them are-- all of them are\npositive-recurrent or all of",
    "start": "1774940",
    "end": "1781530"
  },
  {
    "text": "them are null-recurrent. And this theorem shows it\nbecause this theorem says",
    "start": "1781530",
    "end": "1789610"
  },
  {
    "text": "there has to be an expected\nnumber of occurrences of state i between each occurrence\nof state j.",
    "start": "1789610",
    "end": "1796790"
  },
  {
    "text": "Why is that? Because there has to be\na path from i to j. And there has to be a path that\ndoesn't go through i.",
    "start": "1796790",
    "end": "1803710"
  },
  {
    "text": "Because if you have a path from\ni that goes back to i and then off to j, there's also\nthis path from i to j.",
    "start": "1803710",
    "end": "1812070"
  },
  {
    "text": "So there's a path from i to j. There's a path from j to i that\ndoes not go through i.",
    "start": "1812070",
    "end": "1818450"
  },
  {
    "text": "That has positive probability\nbecause paths are only defined over transitions with positive\nprobability.",
    "start": "1818450",
    "end": "1826299"
  },
  {
    "text": "So this quantity is always\npositive if you're talking about two states in\nthe same class.",
    "start": "1826300",
    "end": "1833520"
  },
  {
    "text": "So what this relationship says,\nalong with the fact that",
    "start": "1833520",
    "end": "1839050"
  },
  {
    "text": "it's a very nice and convenient\nrelationship-- I almost put it in the\nquiz for finite",
    "start": "1839050",
    "end": "1844590"
  },
  {
    "text": "state and Markov chains. And you cam be happy I didn't,\nbecause proving it takes a",
    "start": "1844590",
    "end": "1849860"
  },
  {
    "text": "little more agility than\nwhat one might",
    "start": "1849860",
    "end": "1856100"
  },
  {
    "text": "expect at this point.  The theorem then says that if i\nand j are recurrent, either",
    "start": "1856100",
    "end": "1863660"
  },
  {
    "text": "both are positive-recurrent or\nboth are null-recurrent, what the overall theorem then says\nis that for every class of",
    "start": "1863660",
    "end": "1871040"
  },
  {
    "text": "states, either all of them are\ntransient, all of them are null-recurrent, or all of them\nare positive-recurrent.",
    "start": "1871040",
    "end": "1878540"
  },
  {
    "text": "And that's sort of a convenient\nrelationship. You can't have some states\nthat you never get to.",
    "start": "1878540",
    "end": "1885790"
  },
  {
    "text": "Or you only get to with an\ninfinite recurrence time in a class and others that you keep\ncoming back to all the time.",
    "start": "1885790",
    "end": "1893500"
  },
  {
    "text": "If there's a path from one to\nthe other, then they have to work the same way.",
    "start": "1893500",
    "end": "1898960"
  },
  {
    "text": "This sort of makes it\nobvious why that is. ",
    "start": "1898960",
    "end": "1907409"
  },
  {
    "text": "And this is too sensitive. OK.",
    "start": "1907410",
    "end": "1912590"
  },
  {
    "text": "OK , so now we want to look\nat steady state for positive-recurrent chain.",
    "start": "1912590",
    "end": "1918490"
  },
  {
    "text": "Do you remember that when we\nlooked at finite state in Markov chains, we did all this\nclassification stuff, and then",
    "start": "1918490",
    "end": "1924910"
  },
  {
    "text": "we went into all this\nmatrix stuff? And the outcome of the matrix\nstuff, the most important",
    "start": "1924910",
    "end": "1932370"
  },
  {
    "text": "things, were that there\nis a steady state. There's always a set of\nprobabilities such that if you",
    "start": "1932370",
    "end": "1941130"
  },
  {
    "text": "start the chain in those\nprobabilities, the chain stays in those probabilities. There's always a set of pi sub\ni's, which are probabilities.",
    "start": "1941130",
    "end": "1953590"
  },
  {
    "text": "They all sum to 1. They're all non-negative.",
    "start": "1953590",
    "end": "1959020"
  },
  {
    "text": "And each of them satisfy the\nrelationship, the probability that you're in state j at time\nt is equal to the probability",
    "start": "1959020",
    "end": "1967220"
  },
  {
    "text": "that you're in state i at\ntime t minus 1 times the probability of going\nfrom state i to j.",
    "start": "1967220",
    "end": "1973159"
  },
  {
    "text": "This is completely familiar\nfrom finite-state chains. And this is exactly\nthe same for",
    "start": "1973160",
    "end": "1980060"
  },
  {
    "text": "countable-state and Markov chains. The only question is, it's now\nnot at all sure that that",
    "start": "1980060",
    "end": "1987140"
  },
  {
    "text": "equation has a solution\nanymore. And unfortunately, you can't\nuse matrix theory to prove",
    "start": "1987140",
    "end": "1992490"
  },
  {
    "text": "that it has a solution. So we have to find some\nother way of doing it.",
    "start": "1992490",
    "end": "1997830"
  },
  {
    "text": "So we look in our toolbox,\nwhich we developed throughout the term.",
    "start": "1997830",
    "end": "2003230"
  },
  {
    "text": "And there's only one obvious\nthing to try, and it's renewal theory. So we use renewal theory.",
    "start": "2003230",
    "end": "2010860"
  },
  {
    "text": "We then want to have one other\ndefinition, which you'll see throughout the rest of the term\nand every time you start",
    "start": "2010860",
    "end": "2017330"
  },
  {
    "text": "reading about Markov chains. When you read about Markov\nchains in queuing kinds of",
    "start": "2017330",
    "end": "2023159"
  },
  {
    "text": "situations, which are the kinds\nof things that occur all over the place, almost all of\nthose Markov chains are",
    "start": "2023160",
    "end": "2030490"
  },
  {
    "text": "countable-state Markov chains. And therefore, you need a\nconvenient word to talk about",
    "start": "2030490",
    "end": "2037860"
  },
  {
    "text": "a class of states where all of\nthe states in that class",
    "start": "2037860",
    "end": "2042870"
  },
  {
    "text": "communicate with each other. And irreducible is the\ndefinition that we use. An irreducible Markov chain is\na Markov chain in which all",
    "start": "2042870",
    "end": "2052010"
  },
  {
    "text": "pairs of states communicate\nwith each other. And before, when we were talking\nabout finite-state",
    "start": "2052010",
    "end": "2059440"
  },
  {
    "text": "Markov chains, if all states\ncommunicated with each other, then they were are recurrent.",
    "start": "2059440",
    "end": "2065169"
  },
  {
    "text": "You had a recurrent Markov\nchain, end of story. Now we've seen that you can have\na Markov chain where all",
    "start": "2065170",
    "end": "2072690"
  },
  {
    "text": "the states communicate\nwith each other. We just had these\ntwo examples--",
    "start": "2072690",
    "end": "2078980"
  },
  {
    "text": "these two examples here\nwhere they all communicate with each other. But depending on what p and q\nare, they're either transition",
    "start": "2078980",
    "end": "2087980"
  },
  {
    "text": "transient, or they're\npositive-recurrent, or they're null-recurrent.",
    "start": "2087980",
    "end": "2093069"
  },
  {
    "text": "The first one can't even be\npositive-recurrent, but it can be recurrent.",
    "start": "2093070",
    "end": "2098660"
  },
  {
    "text": "And the bottom one can also\nbe positive-recurrent.",
    "start": "2098660",
    "end": "2104940"
  },
  {
    "text": "So any Markov chain where all\nthe states communicate with",
    "start": "2104940",
    "end": "2110180"
  },
  {
    "text": "each other-- there's a path from everything\nto everything else-- which is the usual situation,\nis called an irreducible",
    "start": "2110180",
    "end": "2118650"
  },
  {
    "text": "Markov chain. An irreducible can now be\npositive-recurrent,",
    "start": "2118650",
    "end": "2123680"
  },
  {
    "text": "null-recurrent, or transient. All the states in an irreducible\nMarkov chain have",
    "start": "2123680",
    "end": "2129170"
  },
  {
    "text": "to be transient, or all\nof them have to be positive-recurrent, or all\nof them have to be",
    "start": "2129170",
    "end": "2135160"
  },
  {
    "text": "null-recurrent. You can't share these\nqualities over an irreducible chain.",
    "start": "2135160",
    "end": "2141340"
  },
  {
    "text": "That's what this last\ntheorem just said. ",
    "start": "2141340",
    "end": "2147750"
  },
  {
    "text": "OK, so if a steady\nstate exists-- namely if the solution to those\nequations exist, and if",
    "start": "2147750",
    "end": "2156560"
  },
  {
    "text": "the probability that X sub 0\nequals i is equal to pi i. And incidentally, in the version\nthat got handed out,",
    "start": "2156560",
    "end": "2165230"
  },
  {
    "text": "that equation there was\na little bit garbled. That one. Said the probability that X sub\n0 was equal to pi i, which",
    "start": "2165230",
    "end": "2174510"
  },
  {
    "text": "doesn't make any sense. If a steady-state exists\nand you start out in",
    "start": "2174510",
    "end": "2180170"
  },
  {
    "text": "steady-state-- namely, the starting state X\nsub 0 is in state i with",
    "start": "2180170",
    "end": "2186560"
  },
  {
    "text": "probability pi sub i by for\nevery i, this is the same trick we played for finite-state and Markov chains.",
    "start": "2186560",
    "end": "2193440"
  },
  {
    "text": "As we go through this, I will\ntry to explain what's the same and what's different. And this is completely\nthe same.",
    "start": "2193440",
    "end": "2199640"
  },
  {
    "text": "So there's nothing new here. ",
    "start": "2199640",
    "end": "2205420"
  },
  {
    "text": "Then, this situation of being in\nsteady-state persists from one unit of time to the next.",
    "start": "2205420",
    "end": "2212349"
  },
  {
    "text": "Namely, if you start out in\nsteady-state, then the probability that X sub 1 is\nequal to j is equal to the sum",
    "start": "2212350",
    "end": "2225110"
  },
  {
    "text": "over i of pi sub i. That's the probability that\nX sub 0 is equal to i.",
    "start": "2225110",
    "end": "2230590"
  },
  {
    "text": "Times P sub i j, which by the\nsteady-state equations, is equal to pi sub j.",
    "start": "2230590",
    "end": "2235920"
  },
  {
    "text": "So you start out in\nsteady-state. After one transition, you're\nin steady-state again.",
    "start": "2235920",
    "end": "2241790"
  },
  {
    "text": "You're in steady-state\nat time 1. Guess what, you're\nin state time 2. You're in steady-state again.",
    "start": "2241790",
    "end": "2247750"
  },
  {
    "text": "And you stay in steady-state\nforever. So when you iterate, the\nprobability that you're in",
    "start": "2247750",
    "end": "2255990"
  },
  {
    "text": "state j at time X sub n is\nequal to pi sub j also. This is assuming that you\nstarted out in steady-state.",
    "start": "2255990",
    "end": "2264130"
  },
  {
    "text": "So again, we need some\nnew notation here. Let's let N sub j of tilde be\nthe number of visits to j in",
    "start": "2264130",
    "end": "2273760"
  },
  {
    "text": "the period 0 to t starting\nin steady-state. Namely, if you start in state j,\nwe get a renewal process to",
    "start": "2273760",
    "end": "2283820"
  },
  {
    "text": "talk about the returns\nto state j. If we start in steady-state,\nthen this first return to",
    "start": "2283820",
    "end": "2291829"
  },
  {
    "text": "state j is going to have a\ndifferent set of probabilities",
    "start": "2291830",
    "end": "2301210"
  },
  {
    "text": "than all subsequent returns\nto state j. So N sub j of t, tilde is now\nnot a renewal process, but a",
    "start": "2301210",
    "end": "2314880"
  },
  {
    "text": "delayed renewal process. So we have to deal with it\na little bit differently. But it's a very nice thing\nbecause for all t, the",
    "start": "2314880",
    "end": "2323609"
  },
  {
    "text": "expected number of returns to\nstate j over t transitions is",
    "start": "2323610",
    "end": "2330620"
  },
  {
    "text": "equal to n times pi sub j. Pi sub j is the probability that\nyou will be in state j at",
    "start": "2330620",
    "end": "2339280"
  },
  {
    "text": "any time n. And it stays the same\nfor every n. So if we look at the expected\nnumber of times we hit state",
    "start": "2339280",
    "end": "2347530"
  },
  {
    "text": "j, it's exactly equal\nto n times pi sub j. And again, here's this\nawkward thing about",
    "start": "2347530",
    "end": "2354470"
  },
  {
    "text": "renewals and Markov. Yes? AUDIENCE: So is that sort of\nlike an ensemble average--",
    "start": "2354470",
    "end": "2360109"
  },
  {
    "text": "PROFESSOR: Yes. AUDIENCE: Or is the time\naverage [INAUDIBLE]? PROFESSOR: Well, it's an\nensemble average and it's a time average.",
    "start": "2360110",
    "end": "2365970"
  },
  {
    "text": "But the thing we're working\nwith here is the fact there's a time-- is the fact that it's an\nensemble average, yes.",
    "start": "2365970",
    "end": "2373369"
  },
  {
    "text": "But it's convenient\nbecause it's an exact ensemble average. Usually, with renewal processes,\nthings are ugly",
    "start": "2373370",
    "end": "2382450"
  },
  {
    "text": "until you start getting\ninto the limit zone. Here, everything is nice\nand clean all the time.",
    "start": "2382450",
    "end": "2389880"
  },
  {
    "text": "So we start out in steady-state\nand we get this beautiful result. It's starting in steady-state.",
    "start": "2389880",
    "end": "2395420"
  },
  {
    "text": "The expected number of visit\nto state j by time n--",
    "start": "2395420",
    "end": "2400765"
  },
  {
    "text": "oh, this is interesting. That t there should\nbe n obviously.",
    "start": "2400765",
    "end": "2408914"
  },
  {
    "start": "2408915",
    "end": "2415790"
  },
  {
    "text": "Well, since we have t's\neverywhere else, that n there should probably be t also.",
    "start": "2415790",
    "end": "2422360"
  },
  {
    "text": "So you can fix it whichever\nway you want. n's and t's are the same.",
    "start": "2422360",
    "end": "2428579"
  },
  {
    "text": "I mean, for the purposes of this\nlecture, let all t's be n's and let all n's be t's.",
    "start": "2428580",
    "end": "2433640"
  },
  {
    "start": "2433640",
    "end": "2439809"
  },
  {
    "text": "This works for some things. This starts in steady state,\nstays in steady state. It doesn't work for renewals\nbecause it's a delayed renewal",
    "start": "2439810",
    "end": "2447970"
  },
  {
    "text": "process, so you can't talk\nabout a renewal process starting in state j, because you\ndon't know that it starts",
    "start": "2447970",
    "end": "2455130"
  },
  {
    "text": "in state j. So sometimes we want\nto deal with this.",
    "start": "2455130",
    "end": "2460810"
  },
  {
    "text": "Sometimes we want to\ndeal with this. This is the number of returns\nto t starting in state j.",
    "start": "2460810",
    "end": "2466650"
  },
  {
    "text": "This is the number of returns\nto state j over 0 to t if we",
    "start": "2466650",
    "end": "2474150"
  },
  {
    "text": "start in steady-state. Here's a useful hack, which you\ncan use a lot of the time.",
    "start": "2474150",
    "end": "2480200"
  },
  {
    "text": " Look at what N sub\ni j of t is.",
    "start": "2480200",
    "end": "2488320"
  },
  {
    "text": "It's the number of times\nyou hit state j starting in state i.",
    "start": "2488320",
    "end": "2493800"
  },
  {
    "text": "So let's look at it as you go\nfor while, you hit state j for",
    "start": "2493800",
    "end": "2499370"
  },
  {
    "text": "the first time. After hitting state j for the\nfirst time, you then go",
    "start": "2499370",
    "end": "2505119"
  },
  {
    "text": "through a number of repetitions\nof state j. But after that first time you\nhit state j, you have a",
    "start": "2505120",
    "end": "2511460"
  },
  {
    "text": "renewal process starting then. In other words, you have a\ndelayed renewal process up to",
    "start": "2511460",
    "end": "2517260"
  },
  {
    "text": "the first renewal. After that, you have\nall the statistics of a renewal process.",
    "start": "2517260",
    "end": "2523060"
  },
  {
    "text": "So the idea then is N\nsub i j of t is 1.",
    "start": "2523060",
    "end": "2528720"
  },
  {
    "text": "Counts 1 for the first visit\nto j, if there are any. Plus, N sub i j of t minus\n1 for all the subsequent",
    "start": "2528720",
    "end": "2537700"
  },
  {
    "text": "recurrences from j to j. Thus, when you look at the\nexpected values of this, the",
    "start": "2537700",
    "end": "2543330"
  },
  {
    "text": "expected value of N sub i j of\nt is less than or equal to 1",
    "start": "2543330",
    "end": "2550280"
  },
  {
    "text": "for this first recurrence, for\nthis first visit, plus the expected value of N sub j j of\nsome number smaller than t.",
    "start": "2550280",
    "end": "2560140"
  },
  {
    "text": "But N sub j j of\nt grows with t. It's a number of visits\nover some interval.",
    "start": "2560140",
    "end": "2566980"
  },
  {
    "text": "And as the interval gets bigger\nand bigger, the number of visits can't shrink.",
    "start": "2566980",
    "end": "2572380"
  },
  {
    "text": "So you just put the t there\nto make it an upper bound. And then, when you look at\nstarting in steady-state, what",
    "start": "2572380",
    "end": "2580809"
  },
  {
    "text": "you get is the sum overall\nstarting states pi sub i of",
    "start": "2580810",
    "end": "2588080"
  },
  {
    "text": "the expected value of\nN sub i j of t. And this is less than or equal\nto 1 plus the expected value",
    "start": "2588080",
    "end": "2596120"
  },
  {
    "text": "of N sub j j of t also. So this says you can always get\nfrom N tilde of t to N sub",
    "start": "2596120",
    "end": "2606485"
  },
  {
    "text": "j j of t, by just giving\nup this term 1 here as an upper bound.",
    "start": "2606485",
    "end": "2613250"
  },
  {
    "text": " If you don't like that proof--",
    "start": "2613250",
    "end": "2620150"
  },
  {
    "text": "and it's not really a proof. If you try to make it a proof,\nit gets kind of ugly.",
    "start": "2620150",
    "end": "2625730"
  },
  {
    "text": "It's part of the proof of\ntheorem 4 in the text, which is even more ugly.",
    "start": "2625730",
    "end": "2632150"
  },
  {
    "text": "Because it's mathematically\nclean with equations, but you don't get any idea of why it's\ntrue from looking at it.",
    "start": "2632150",
    "end": "2639750"
  },
  {
    "text": "This you know why it's true from\nlooking at it, but you're not quite sure that it satisfies\nthe equations that",
    "start": "2639750",
    "end": "2645589"
  },
  {
    "text": "you would like. I am trying to move you from\nbeing totally dependent on equations to being more\ndependent on ideas like this,",
    "start": "2645590",
    "end": "2655950"
  },
  {
    "text": "where you can see\nwhat's going on. But I'm also urging you, after\nyou see what's going on, to",
    "start": "2655950",
    "end": "2662200"
  },
  {
    "text": "have a way to put the equations\nin to see that you're absolutely\nright with it.",
    "start": "2662200",
    "end": "2668170"
  },
  {
    "text": "OK, now, we come to the major\ntheorem of countable-state and Markov chains. It's sort of the crucial\nthing that everything",
    "start": "2668170",
    "end": "2675920"
  },
  {
    "text": "else is based on. I mean, everything beyond\nwhat we've already done.",
    "start": "2675920",
    "end": "2683350"
  },
  {
    "text": "For any irreducible\nMarkov chain-- in other words, for any Markov\nchain where all the states",
    "start": "2683350",
    "end": "2689810"
  },
  {
    "text": "communicate with each other,\nthe steady-state equations",
    "start": "2689810",
    "end": "2695100"
  },
  {
    "text": "have a solution if and only\nif the states are positive-recurrent.",
    "start": "2695100",
    "end": "2700640"
  },
  {
    "text": "Now, remember, either all the\nstates are positive-recurrent or none of them are. So there's nothing\nconfusing there.",
    "start": "2700640",
    "end": "2707750"
  },
  {
    "text": "If all the states are\npositive-recurrent, then there is a steady-state solution. There is a solution to\nthose equations.",
    "start": "2707750",
    "end": "2716190"
  },
  {
    "text": "And if the set of states are\ntransient, or null-recurrent,",
    "start": "2716190",
    "end": "2722089"
  },
  {
    "text": "then there isn't a solution\nto all those equations. If a solution exists, then the\nprobability, the steady-state",
    "start": "2722090",
    "end": "2731039"
  },
  {
    "text": "probability is state i is 1 over\nthe main recurrence time to state i.",
    "start": "2731040",
    "end": "2736960"
  },
  {
    "text": "This is a relationship that we\nestablished by using renewal theory for finite-state\nand Markov chains.",
    "start": "2736960",
    "end": "2743580"
  },
  {
    "text": "We're just coming\nback to it here.  One thing which is important\nhere is that pi sub i is",
    "start": "2743580",
    "end": "2752050"
  },
  {
    "text": "greater than 0 for all i. This is a property we\nhad for finite-state Markov chains also.",
    "start": "2752050",
    "end": "2758780"
  },
  {
    "text": "But it's a good deal more\nsurprising here. When you have a countable number\nof states, saying that",
    "start": "2758780",
    "end": "2764520"
  },
  {
    "text": "every one of them has a positive\nprobability is-- I don't think it's entirely\nintuitive.",
    "start": "2764520",
    "end": "2772100"
  },
  {
    "text": "If you think about it\nfor a long time, it's sort of intuitive. But it's the kind of intuitive\nthing that really pushes your",
    "start": "2772100",
    "end": "2778560"
  },
  {
    "text": "intuition into understanding\nwhat's going on. So let's give a Pf of this,\nof the only if part.",
    "start": "2778560",
    "end": "2791910"
  },
  {
    "text": "And I will warn you\nabout reading the proof in the notes. It's ugly because it just goes\nthrough a bunch of logical",
    "start": "2791910",
    "end": "2799470"
  },
  {
    "text": "relationships and equations. You have no idea of where\nit's going or why.",
    "start": "2799470",
    "end": "2805070"
  },
  {
    "text": "And finally, at the\nend it says, QED.  I went through it.",
    "start": "2805070",
    "end": "2810430"
  },
  {
    "text": "It's correct. But damned if I know why. And so, anyway, that has\nto be rewritten.",
    "start": "2810430",
    "end": "2819560"
  },
  {
    "text": "But, anyway here's the Pf. Start out by assuming that the\nsteady-state equations exist.",
    "start": "2819560",
    "end": "2826140"
  },
  {
    "text": "We want to show\npositive-recurrence.  Pick any j and any t.",
    "start": "2826140",
    "end": "2834109"
  },
  {
    "text": "Pick any state and any time. pi sub j is equal to the\nexpected value of N sub j",
    "start": "2834110",
    "end": "2844539"
  },
  {
    "text": "tilde of t. That we chose for any\nMarkov chain at all. If you start out in\nsteady-state, you stay in",
    "start": "2844540",
    "end": "2850650"
  },
  {
    "text": "steady-state. So under the assumption that\nwe're in steady-state-- ",
    "start": "2850650",
    "end": "2857900"
  },
  {
    "text": "under the assumption that we\nstart out in steady-state, we stay in steady-state. This pi sub j times t has to be\nthe expected value of the",
    "start": "2857900",
    "end": "2868520"
  },
  {
    "text": "number of recurrences to state\nj over t time units.",
    "start": "2868520",
    "end": "2874120"
  },
  {
    "text": "And what we showed on\nthe last slide--",
    "start": "2874120",
    "end": "2880170"
  },
  {
    "text": "you must have realized I was\ndoing this for some reason. This is less than or equal to 1\nplus the expected recurrence",
    "start": "2880170",
    "end": "2887990"
  },
  {
    "text": "time of state j. ",
    "start": "2887990",
    "end": "2894410"
  },
  {
    "text": "So pi sub j is less than or\nequal to 1 over t times this expected recurrence\ntime for state j.",
    "start": "2894410",
    "end": "2902340"
  },
  {
    "text": "And if we go to the limit as t\ngoes to infinity, this 1 over t dribbles away to\nnothingness.",
    "start": "2902340",
    "end": "2909680"
  },
  {
    "text": "So this is less than or equal to\nthe limit of expected value of N sub j j of t over t.",
    "start": "2909680",
    "end": "2916300"
  },
  {
    "text": "What is that? That's the expected number,\nlong-term rate of",
    "start": "2916300",
    "end": "2922210"
  },
  {
    "text": "visits to state j. It's what we've shown as equal\nto 1 over the expected renewal",
    "start": "2922210",
    "end": "2929670"
  },
  {
    "text": "time of state j. Now, if the sum of the pi sub\nj's is equal to 1, remember",
    "start": "2929670",
    "end": "2939350"
  },
  {
    "text": "what happens when you sum a\ncountable set of numbers. If all of them are 0, then no\nmatter how many of them you",
    "start": "2939350",
    "end": "2947940"
  },
  {
    "text": "sum, you have 0. And when you go to the limit,\nyou still have 0.",
    "start": "2947940",
    "end": "2953099"
  },
  {
    "text": "So when you sum a set of\ncountable set of non-negative numbers, you have\nto have a limit. ",
    "start": "2953100",
    "end": "2960990"
  },
  {
    "text": "Because it's non-decreasing.  And that sum is equal to 1.",
    "start": "2960990",
    "end": "2967010"
  },
  {
    "text": "Then somewhere along the line,\nyou've got to find the positive probability.",
    "start": "2967010",
    "end": "2972059"
  },
  {
    "text": "One of the [INAUDIBLE] has to be positive. ",
    "start": "2972060",
    "end": "2977300"
  },
  {
    "text": "I mean, this is almost an\namusing proof because you work so hard to prove that one\nof them is positive.",
    "start": "2977300",
    "end": "2984250"
  },
  {
    "text": "And then, almost for free, you\nget the fact that all of them have to be positive.",
    "start": "2984250",
    "end": "2990790"
  },
  {
    "text": "So some pi j is greater\nthan 0. If pi j is less than or equal\nto this, thus the limit as t",
    "start": "2990790",
    "end": "2998240"
  },
  {
    "text": "approaches infinity of the\nexpected value of N sub j j of t over t is greater than 0 for\nthat j, which says j has to be",
    "start": "2998240",
    "end": "3008740"
  },
  {
    "text": "positive-recurrent. Which says all the states have\nto be positive-recurrent",
    "start": "3008740",
    "end": "3015270"
  },
  {
    "text": "because we've already\nshown that. So all the states are\npositive-recurrent. Then you still have to show that\nthis inequality here is",
    "start": "3015270",
    "end": "3023390"
  },
  {
    "text": "equality, and you've got to do\nthat by playing around with summing up these things.",
    "start": "3023390",
    "end": "3028805"
  },
  {
    "text": " Something has been left\nout, we have to sum",
    "start": "3028805",
    "end": "3035670"
  },
  {
    "text": "those up over j. And that's another mess. I'm not going to do\nit here in class. But just sort of see\nwhy this happened.",
    "start": "3035670",
    "end": "3042030"
  },
  {
    "text": "Yeah? AUDIENCE: [INAUDIBLE].  Why do you have to show\nthe equality?",
    "start": "3042030",
    "end": "3049260"
  },
  {
    "text": "PROFESSOR: Why do I have\nto the equality? Because if I want to show that\nall of the pi sub i's are",
    "start": "3049260",
    "end": "3057319"
  },
  {
    "text": "positive, how do I show that? All I've done is started\nout with an arbitrary--",
    "start": "3057320",
    "end": "3063050"
  },
  {
    "text": "oh, I've started out with\nan arbitrary j and an arbitrary t.",
    "start": "3063050",
    "end": "3068830"
  },
  {
    "text": "Because I got the fact that this\nwas positive-recurrent by arguing that at least\none of the pi sub",
    "start": "3068830",
    "end": "3074740"
  },
  {
    "text": "j's had to be positive. From this I can argue\nthat they're all positive-recurrent, which tells\nme that this number is",
    "start": "3074740",
    "end": "3082690"
  },
  {
    "text": "greater than 0. But that doesn't show me that\nthis number is greater than 0.",
    "start": "3082690",
    "end": "3089430"
  },
  {
    "text": "But it is. I mean, it's all right. It all works out. But not quite in such a simple\nway as you would hope.",
    "start": "3089430",
    "end": "3098080"
  },
  {
    "text": "OK, so now let's go back to\nwhat we called birth-death",
    "start": "3098080",
    "end": "3103290"
  },
  {
    "text": "chains, but look at a slightly\nmore general version of them.",
    "start": "3103290",
    "end": "3110770"
  },
  {
    "text": "These are things that you-- I mean, queuing theory is\nbuilt on these things.",
    "start": "3110770",
    "end": "3116710"
  },
  {
    "text": "Everything in queuing theory. Or not everything, but all the\nthings that come from a",
    "start": "3116710",
    "end": "3122900"
  },
  {
    "text": "Poisson kind of background. All of these somehow look at\nthe birth-death chains.",
    "start": "3122900",
    "end": "3132880"
  },
  {
    "text": "And the way a birth-death\nchain works is you have arbitrary self-loops.",
    "start": "3132880",
    "end": "3139670"
  },
  {
    "text": "You have positive probabilities\ngoing from each state to the next state up.",
    "start": "3139670",
    "end": "3145760"
  },
  {
    "text": "You have positive probabilities\ngoing from the higher state to the\nlower state.",
    "start": "3145760",
    "end": "3153390"
  },
  {
    "text": "All transitions are\nlimited from-- i can only go to i plus 1,\nor i, for i minus 1.",
    "start": "3153390",
    "end": "3161560"
  },
  {
    "text": "You can't make big jumps. You can only make jumps\nof one step. And other than that, it's\ncompletely general.",
    "start": "3161560",
    "end": "3169540"
  },
  {
    "text": "OK, now we go through an\ninteresting argument. ",
    "start": "3169540",
    "end": "3175210"
  },
  {
    "text": "We look at an arbitrary\nstate i. And for this arbitrary state i,\nlike i equals 2, we look at",
    "start": "3175210",
    "end": "3188079"
  },
  {
    "text": "the number of transitions\nthat go from 2 to 3. And the number transitions that\ngo from 3 to 2 for any",
    "start": "3188080",
    "end": "3195440"
  },
  {
    "text": "old sample path whatsoever. And for any sample path,\nthe number of transitions that go up--",
    "start": "3195440",
    "end": "3202830"
  },
  {
    "text": "if we start down there, before\nyou can come back, you've got to go up.",
    "start": "3202830",
    "end": "3208770"
  },
  {
    "text": "So if you're on that side, you\nhave one more up transition than you have down transition.",
    "start": "3208770",
    "end": "3214880"
  },
  {
    "text": "If you're on that side, you\nhave the same number of up transitions and down\ntransitions.",
    "start": "3214880",
    "end": "3221470"
  },
  {
    "text": "So that as you look over a\nlonger and longer time, the number of up transitions is\neffectively the same as the",
    "start": "3221470",
    "end": "3229280"
  },
  {
    "text": "number of down transitions.  If you have a steady-state, pi\nsub i is the fraction of time",
    "start": "3229280",
    "end": "3238420"
  },
  {
    "text": "you're in state i. pi sub i times p sub i is the\nfraction of time you're going",
    "start": "3238420",
    "end": "3248340"
  },
  {
    "text": "from state i to state\ni plus 1. And pi sub i by plus 1 times q\nsub i plus 1 is the fraction",
    "start": "3248340",
    "end": "3259720"
  },
  {
    "text": "of time you're going\nfrom state i plus 1 down to state i. What we've just argued by the\nfact that sample path averages",
    "start": "3259720",
    "end": "3272160"
  },
  {
    "text": "and ensemble averages have to\nbe equal is that pi sub i",
    "start": "3272160",
    "end": "3277940"
  },
  {
    "text": "times p sub i is equal to\npi sub i plus 1 times q sub i plus 1.",
    "start": "3277940",
    "end": "3284000"
  },
  {
    "text": " In the next slide, I will\ntalk about whether to",
    "start": "3284000",
    "end": "3290400"
  },
  {
    "text": "believe that or not. For the moment, let's\nsay we believe it.",
    "start": "3290400",
    "end": "3295810"
  },
  {
    "text": "And from this equation, we\nsee that the steady-state probability of i plus 1 is\nequal to the steady-state",
    "start": "3295810",
    "end": "3304960"
  },
  {
    "text": "probability of i times p sub\ni over q sub i plus 1.",
    "start": "3304960",
    "end": "3310430"
  },
  {
    "text": "It says that the steady-state\nprobability of each pi is determined by the steady-state\nprobability of the state",
    "start": "3310430",
    "end": "3319020"
  },
  {
    "text": "underneath it. So you just go up. You can calculate the\nsteady-state of each, the",
    "start": "3319020",
    "end": "3324099"
  },
  {
    "text": "probability of each if you know\nthe probability of the state below it.",
    "start": "3324100",
    "end": "3330000"
  },
  {
    "text": "So if you recurse on this, pi\nsub i plus 1 is equal to pi",
    "start": "3330000",
    "end": "3336300"
  },
  {
    "text": "sub i times this ratio is equal\nto pi sub i minus 1",
    "start": "3336300",
    "end": "3341470"
  },
  {
    "text": "times this ratio times p sub i\nminus 1 over q sub i is equal",
    "start": "3341470",
    "end": "3347170"
  },
  {
    "text": "to pi sub i minus 2 times\nthis triple of things.",
    "start": "3347170",
    "end": "3352390"
  },
  {
    "text": "It tells you that what you want\nto do is define row sub i as the difference of these two\nprobabilities, namely rob i,",
    "start": "3352390",
    "end": "3361580"
  },
  {
    "text": "for any state i, is the ratio\nof that probability to that",
    "start": "3361580",
    "end": "3366700"
  },
  {
    "text": "probability. And this equation then turns\ninto pi sub i plus 1 equals pi",
    "start": "3366700",
    "end": "3375820"
  },
  {
    "text": "sub i times row sub i. If you put all those\nthings together-- if you just paste them one after\nthe other, the way I was",
    "start": "3375820",
    "end": "3383490"
  },
  {
    "text": "suggesting-- what you get is pi sub i is\nequal to pi sub 0 times this",
    "start": "3383490",
    "end": "3390480"
  },
  {
    "text": "product of terms. The product of terms looks\na little ugly.",
    "start": "3390480",
    "end": "3395930"
  },
  {
    "text": "Why don't I care about\nthat very much? Well, because usually, when you\nhave a chain like this,",
    "start": "3395930",
    "end": "3401590"
  },
  {
    "text": "all the Ps are the same and\nall the Qs are the same-- or all the Ps are the same for\nsome point beyond someplace,",
    "start": "3401590",
    "end": "3409109"
  },
  {
    "text": "they're are different\nbefore that. There's always some structure\nto make life easy for you.",
    "start": "3409110",
    "end": "3414670"
  },
  {
    "text": " Oh, that's my computer. It's telling me what\ntime it is.",
    "start": "3414670",
    "end": "3420450"
  },
  {
    "text": "I'm sorry. OK. So pi sub i is this.",
    "start": "3420450",
    "end": "3427080"
  },
  {
    "text": "We then have to calculate\npi sub 0. Pi sub 0 is then 1 divided\nby the sum of all the",
    "start": "3427080",
    "end": "3434810"
  },
  {
    "text": "probabilities is pi sub 0 times\nall those other things. It's 1 plus the sum here.",
    "start": "3434810",
    "end": "3443490"
  },
  {
    "text": "And now if you don't believe\nwhat I did here, and I don't",
    "start": "3443490",
    "end": "3449680"
  },
  {
    "text": "blame you for being a little\nbit skeptical. If you don't believe this, then\nyou look at this and you",
    "start": "3449680",
    "end": "3459160"
  },
  {
    "text": "say, OK, I can now go back and\nlook at the steady state equations themselves and I can\nplug this into the steady",
    "start": "3459160",
    "end": "3467079"
  },
  {
    "text": "state equations themselves. And you will immediately see\nthat this solution satisfies",
    "start": "3467080",
    "end": "3473020"
  },
  {
    "text": "the steady state equations. OK. Oh, damn.",
    "start": "3473020",
    "end": "3479310"
  },
  {
    "text": "Excuse my language.  OK.",
    "start": "3479310",
    "end": "3485180"
  },
  {
    "text": " So we have our birth-death\nchain with all these",
    "start": "3485180",
    "end": "3492370"
  },
  {
    "text": "transitions here. We have our solution to it.",
    "start": "3492370",
    "end": "3497710"
  },
  {
    "text": "Note that the solution is only\na function of these rows.",
    "start": "3497710",
    "end": "3503500"
  },
  {
    "text": "It's only a function of the\nratio of p sub i to Q sub i plus 1.",
    "start": "3503500",
    "end": "3509789"
  },
  {
    "text": "It doesn't depend on those\nself loops at all. Isn't that peculiar?",
    "start": "3509790",
    "end": "3514810"
  },
  {
    "text": " Completely independent of what\nthose self loops are.",
    "start": "3514810",
    "end": "3521606"
  },
  {
    "text": "Well, you'll see later that it's\nnot totally independent of it, but it's essentially\nindependent of it.",
    "start": "3521606",
    "end": "3526685"
  },
  {
    "text": " And you think about that for a\nwhile and suddenly it's not",
    "start": "3526685",
    "end": "3534930"
  },
  {
    "text": "that confusing because those\nequations have come from looking at up transitions\nand down transitions.",
    "start": "3534930",
    "end": "3543770"
  },
  {
    "text": "By looking at an up transition\nand a down transition at one place here, it tells you\nsomething about the fraction",
    "start": "3543770",
    "end": "3552099"
  },
  {
    "text": "of time you're over there and\nthe fraction of time you're down there if you know what\nthese steady state probabilities are.",
    "start": "3552100",
    "end": "3558940"
  },
  {
    "text": "So if you think about it for a\nbit, you realize that these steady state probabilities\ncannot depend that strongly on",
    "start": "3558940",
    "end": "3566060"
  },
  {
    "text": "what those self loops are. So this all sort\nof makes sense. The next thing is the expression\nfor pi 0--",
    "start": "3566060",
    "end": "3574579"
  },
  {
    "text": "namely this thing here-- is a product of these terms. ",
    "start": "3574580",
    "end": "3580460"
  },
  {
    "text": "It converges and therefore the\nchain is positive recurrent because there is a solution to\nthe steady state equation.",
    "start": "3580460",
    "end": "3587650"
  },
  {
    "text": "It converges if the\nrow sub i's are asymptotically less than 1.",
    "start": "3587650",
    "end": "3594870"
  },
  {
    "text": "So for example, if\nthe row sub i's-- beyond i equals 100--",
    "start": "3594870",
    "end": "3600390"
  },
  {
    "text": "are bounded by, say, 0.9, then\nthese terms have to go to 0",
    "start": "3600390",
    "end": "3605500"
  },
  {
    "text": "rapidly after i equals 100 and\nthis product has to converge.",
    "start": "3605500",
    "end": "3611420"
  },
  {
    "text": "I say essentially here of all\nthese particular cases where the row sub i's are very close\nto 1, and they're converging",
    "start": "3611420",
    "end": "3619519"
  },
  {
    "text": "very slowly to 1\nand who knows. But for most of the things we\ndo, these row sub i's are",
    "start": "3619520",
    "end": "3626130"
  },
  {
    "text": "strictly less than\n1 as you move up. And it says that you have\nto have steady state",
    "start": "3626130",
    "end": "3633140"
  },
  {
    "text": "probabilities. So for most birth-death chains,\nit's almost immediate",
    "start": "3633140",
    "end": "3642310"
  },
  {
    "text": "to establish whether it's\nrecurrent, positive recurrent, or not positive recurrent.",
    "start": "3642310",
    "end": "3648410"
  },
  {
    "text": "And we'll talk more about that\nwhen we get into Markov processes, but that's enough\nof it for now.",
    "start": "3648410",
    "end": "3656470"
  },
  {
    "text": "Comment on methodology. We could check the renewal\nresults carefully, because",
    "start": "3656470",
    "end": "3662750"
  },
  {
    "text": "what we're doing here is\nassuming something rather peculiar about time averages\nand ensemble averages.",
    "start": "3662750",
    "end": "3671590"
  },
  {
    "text": "And sometimes you have to worry\nabout those things, but here, we don't have to worry\nabout it because we have this",
    "start": "3671590",
    "end": "3677990"
  },
  {
    "text": "major theorem which tells\nus if steady state probabilities exist-- and they exist because they\nsatisfy these equations--",
    "start": "3677990",
    "end": "3685390"
  },
  {
    "text": "then you have positive\nrecurrence. So it says the methodology to\nuse is not to get involved in",
    "start": "3685390",
    "end": "3692510"
  },
  {
    "text": "any deep theory, but just\nto see if these equations are satisfied. Again, good mathematicians\nare lazy--",
    "start": "3692510",
    "end": "3701070"
  },
  {
    "text": "good engineers are\neven lazier. That's my motto of the day.",
    "start": "3701070",
    "end": "3707110"
  },
  {
    "text": "And finally, birth-death\nchains are going to be particularly useful in queuing\nwhere the births are arrivals",
    "start": "3707110",
    "end": "3714770"
  },
  {
    "text": "and the deaths are departures. ",
    "start": "3714770",
    "end": "3720160"
  },
  {
    "text": "OK. Now we come to reversibility. I'm glad we're coming to that\ntowards the end of the lecture",
    "start": "3720160",
    "end": "3726930"
  },
  {
    "text": "because reversibility is\nsomething which I don't think",
    "start": "3726930",
    "end": "3732400"
  },
  {
    "text": "any of you guys even-- and I think this is a\npretty smart class--",
    "start": "3732400",
    "end": "3737500"
  },
  {
    "text": "but I've never seen anybody who\nunderstands reversibility the first time they\nthink about it.",
    "start": "3737500",
    "end": "3742850"
  },
  {
    "text": "It's a very peculiar concept and\nthe results coming from it",
    "start": "3742850",
    "end": "3749140"
  },
  {
    "text": "are peculiar, and we will have\nto live with it for a while.",
    "start": "3749140",
    "end": "3754490"
  },
  {
    "text": "But let's start out with\nthe easy things--",
    "start": "3754490",
    "end": "3760250"
  },
  {
    "text": "just with a definition of\nwhat a Markov chain is. This top equation here says\nthat the probability of a",
    "start": "3760250",
    "end": "3769480"
  },
  {
    "text": "whole bunch of states-- X sub n plus k down to X sub n\nplus 1 given the stated time,",
    "start": "3769480",
    "end": "3777790"
  },
  {
    "text": "n, down to the stated time 0. Because of the Markov condition,\nthat has to be",
    "start": "3777790",
    "end": "3784200"
  },
  {
    "text": "equal to the probability\nof these terms just given X sub n.",
    "start": "3784200",
    "end": "3789579"
  },
  {
    "text": "Namely, if you know what X sub\nn is, for the future, you don't have to know what any of\nthose previous states are.",
    "start": "3789580",
    "end": "3796059"
  },
  {
    "text": "You get that directly from\nwhere we started with the Markov chains-- the probability\nof X sub n plus 1,",
    "start": "3796060",
    "end": "3803040"
  },
  {
    "text": "given all this stuff, and\nthen you just add the other things onto it. Now, if you define A plus as any\nevent which is defined in",
    "start": "3803040",
    "end": "3814530"
  },
  {
    "text": "terms of X sub n plus 1, X of n\nplus 2, and so forth up, and",
    "start": "3814530",
    "end": "3820660"
  },
  {
    "text": "if you define A minus as\nanything which is a function of X sub n minus 1, X sub n\nminus 2, down to X sub 0, then",
    "start": "3820660",
    "end": "3831410"
  },
  {
    "text": "what this equations\nsays is that the probability of any A plus--",
    "start": "3831410",
    "end": "3837180"
  },
  {
    "text": "given X sub n and A minus-- is equal to the probability\nof A plus given X sub n.",
    "start": "3837180",
    "end": "3846079"
  },
  {
    "text": "And this hasn't gotten\nhard yet. If you think this is\nhard, just wait. ",
    "start": "3846080",
    "end": "3856230"
  },
  {
    "text": "If we now multiply this by\nthe probability of A minus given X sub n--",
    "start": "3856230",
    "end": "3861799"
  },
  {
    "text": "and what I'm trying to get at\nis, how do you reason about the probabilities of\nearlier states",
    "start": "3861800",
    "end": "3868559"
  },
  {
    "text": "given the present state? We're used to proceeding\nin time.",
    "start": "3868560",
    "end": "3873790"
  },
  {
    "text": "We're used to looking at\nthe past for telling what the future is.",
    "start": "3873790",
    "end": "3879300"
  },
  {
    "text": "And every once and a while, you\nwant to look at the future and predict what the\npast had to be. It's probably more important to\ntalk about the future given",
    "start": "3879300",
    "end": "3888470"
  },
  {
    "text": "the past, because sometimes\nyou don't know what the future is. But mathematically, you\nhave to sort that out.",
    "start": "3888470",
    "end": "3895210"
  },
  {
    "text": "So if we multiply this equation\nby the probability of",
    "start": "3895210",
    "end": "3902619"
  },
  {
    "text": "A minus, given X sub n,\nwe don't know what that is, but it exists.",
    "start": "3902620",
    "end": "3908950"
  },
  {
    "text": "It's a defined conditional\nprobability. Then what we get is the\nprobability of A plus and A",
    "start": "3908950",
    "end": "3914460"
  },
  {
    "text": "minus, given X sub n, is equal\nto the probability of A plus, given X sub n, times the\nprobability of A",
    "start": "3914460",
    "end": "3921410"
  },
  {
    "text": "minus, given X sub n. So that the probability of the\nfuture and the past, given",
    "start": "3921410",
    "end": "3928940"
  },
  {
    "text": "what's happening now, is equal\nto the probability of the future, given what's happening\nnow, times the probability the",
    "start": "3928940",
    "end": "3935970"
  },
  {
    "text": "past, given what's\nhappening now. Which may be a more interesting\nway of looking at",
    "start": "3935970",
    "end": "3941160"
  },
  {
    "text": "past and future and present\nthan this totally asymmetric way here.",
    "start": "3941160",
    "end": "3946710"
  },
  {
    "text": "This is a nice, symmetric\nway of looking at it. And as soon as you see that this\nhas to be true, then you",
    "start": "3946710",
    "end": "3954810"
  },
  {
    "text": "can turn around and write this\nthe opposite way, and you see that the probability of A minus,\ngiven X sub n, and A",
    "start": "3954810",
    "end": "3962365"
  },
  {
    "text": "plus is equal to the\nprobability of A minus given X sub n.",
    "start": "3962365",
    "end": "3968670"
  },
  {
    "text": "Which says that the probability\nof the past, given X sub n and the future, is equal\nto the probability of",
    "start": "3968670",
    "end": "3975970"
  },
  {
    "text": "the past just given X sub n. You can go from past the future\nor you can go from",
    "start": "3975970",
    "end": "3984530"
  },
  {
    "text": "future to past. And incidentally, if you people\nhave trouble trying to",
    "start": "3984530",
    "end": "3993020"
  },
  {
    "text": "think of the past and\nthe future as being symmetric animals--",
    "start": "3993020",
    "end": "3998210"
  },
  {
    "text": "and I do too--  everything we do with time can\nalso be done on a line going",
    "start": "3998210",
    "end": "4007090"
  },
  {
    "text": "from left to right, or it\ncan be done on a line going from bottom up. Going from bottom up, it's\nhard to say that this is",
    "start": "4007090",
    "end": "4015150"
  },
  {
    "text": "symmetric to this. If you look at it on a line\ngoing from left to right, it's",
    "start": "4015150",
    "end": "4020950"
  },
  {
    "text": "kind of easy to see that this\nis symmetric between left to right and right to left.",
    "start": "4020950",
    "end": "4027290"
  },
  {
    "text": "So every time you get confused\nabout these arguments, put them on a line and argue right\nto left and left to right",
    "start": "4027290",
    "end": "4035180"
  },
  {
    "text": "instead of earlier and later. Because mathematically, it's\nthe same thing, but it's",
    "start": "4035180",
    "end": "4043079"
  },
  {
    "text": "easier to see these\nsymmetries. And now, if you think of A minus\nas being X sub n minus",
    "start": "4043080",
    "end": "4050400"
  },
  {
    "text": "1, and you think of A plus as\nbeing X sub n plus 1, X sub n plus 2 and so forth up, what\nthis equation says is that the",
    "start": "4050400",
    "end": "4058920"
  },
  {
    "text": "probability of the last state\nin the past, given the state now and everything in the\nfuture, is equal to the",
    "start": "4058920",
    "end": "4067180"
  },
  {
    "text": "probability of the last state\nin the past given X sub n.",
    "start": "4067180",
    "end": "4072690"
  },
  {
    "text": "Now, this isn't reversibility. I'm not saying that these\nare special process.",
    "start": "4072690",
    "end": "4078350"
  },
  {
    "text": "This is true for any Markov\nchain in the world. These relationships\nare always true.",
    "start": "4078350",
    "end": "4085470"
  },
  {
    "text": "This is one reason why many\npeople view this as the real",
    "start": "4085470",
    "end": "4092750"
  },
  {
    "text": "Markov condition, as opposed to\nany of these other things. They say that three events\nhave a Markov condition",
    "start": "4092750",
    "end": "4102009"
  },
  {
    "text": "between them if there's\none of them which is in between the other.",
    "start": "4102010",
    "end": "4107899"
  },
  {
    "text": "Where you can say that the\nprobability of the left one, given the middle one, times\nthe right one, given the",
    "start": "4107899",
    "end": "4114560"
  },
  {
    "text": "middle one, is equal to the\nprobability of the left and the right given the middle.",
    "start": "4114560",
    "end": "4120549"
  },
  {
    "text": "It says that the past and the\nfuture, given the present, are",
    "start": "4120550",
    "end": "4125859"
  },
  {
    "text": "independent of each other. It says that as soon as you\nknow what the present is,",
    "start": "4125859",
    "end": "4131180"
  },
  {
    "text": "everything down there\nis independent of everything up there. That's a pretty powerful\ncondition.",
    "start": "4131180",
    "end": "4137464"
  },
  {
    "text": " And you'll see that we can do an\nawful lot with it, so it's",
    "start": "4137465",
    "end": "4144390"
  },
  {
    "text": "going to be important. OK. So let's go on with that.",
    "start": "4144390",
    "end": "4151759"
  },
  {
    "text": "By Bayes rule-- and incidentally, this is why\nBayes got into so much trouble",
    "start": "4151760",
    "end": "4157439"
  },
  {
    "text": "with the other statisticians\nin the world. Because the other statisticians\nin the world",
    "start": "4157439",
    "end": "4162910"
  },
  {
    "text": "really got emotionally upset at\nthe idea of talking about",
    "start": "4162910",
    "end": "4168870"
  },
  {
    "text": "the past given the future. That was almost an attack on\ntheir religion as well as all",
    "start": "4168870",
    "end": "4176409"
  },
  {
    "text": "the mathematics they knew and\neverything else they knew. It was really hitting them below\nthe belt, so to speak.",
    "start": "4176410",
    "end": "4184420"
  },
  {
    "text": "So they didn't like this. But now, we've recognized that\nBayes' Law is just the",
    "start": "4184420",
    "end": "4191600"
  },
  {
    "text": "consequence of the axioms of\nprobability, and there's nothing strange about it.",
    "start": "4191600",
    "end": "4198330"
  },
  {
    "text": "You write down these conditional\nprobabilities and that's sitting there,\nfacing you.",
    "start": "4198330",
    "end": "4204150"
  },
  {
    "text": "But what it says here is that\nthe probability of the state at time n minus 1, given the\nstate of time n, is equal to",
    "start": "4204150",
    "end": "4213890"
  },
  {
    "text": "the probability of the state\nof time n, given n minus 1, times the probability of X\nn minus 1 divided by the",
    "start": "4213890",
    "end": "4221860"
  },
  {
    "text": "probability of X n. In other words, you put this\nover in this side, and it says the probability of X n times the\nprobability of X n minus 1",
    "start": "4221860",
    "end": "4230310"
  },
  {
    "text": "given X n is that probability\nup there. It says that the probability\nof A given B times the",
    "start": "4230310",
    "end": "4237780"
  },
  {
    "text": "probability of B is equal to the\nprobability of A times the probability of B given A. And\nthat's just the definition of",
    "start": "4237780",
    "end": "4245920"
  },
  {
    "text": "a conditional probability,\nnothing more. OK. If the forward chain is in\na steady state, then the",
    "start": "4245920",
    "end": "4254949"
  },
  {
    "text": "probability that X sub n minus\n1 equals j, given X sub n equals i, is pji times pi sub\nj divided by pi sub i.",
    "start": "4254950",
    "end": "4266670"
  },
  {
    "text": "These probabilities become\njust probabilities which depend on i but not on n.",
    "start": "4266670",
    "end": "4273989"
  },
  {
    "text": "Now what's going on here is\nwhen you look at this equation, it looks peculiar\nbecause normally with a Markov",
    "start": "4273990",
    "end": "4284369"
  },
  {
    "text": "chain, we start out at time 0\nwith some assumed probability distribution.",
    "start": "4284370",
    "end": "4291020"
  },
  {
    "text": "And as soon as you start out\nwith some assumed probability distribution at time 0 and you\nstart talking about the past",
    "start": "4291020",
    "end": "4302889"
  },
  {
    "text": "condition on the future,\nit gets very sticky. Because when you talk about\nthe past condition on the",
    "start": "4302890",
    "end": "4313550"
  },
  {
    "text": "future, you can only go back to\ntime equals 0, and you know what's happening down there\nbecause you have some",
    "start": "4313550",
    "end": "4319650"
  },
  {
    "text": "established probabilities\nat 0. So what it says is in this\nequation here, it says that",
    "start": "4319650",
    "end": "4330330"
  },
  {
    "text": "the Markov chain, defined\nby this rule-- I guess I ought to back\nand look at the",
    "start": "4330330",
    "end": "4336590"
  },
  {
    "text": "previous slide for that. ",
    "start": "4336590",
    "end": "4342900"
  },
  {
    "text": "This is saying the probability\nof the state at time n minus",
    "start": "4342900",
    "end": "4348050"
  },
  {
    "text": "1, conditional on the entire\nfuture, is equal to the probability of X sub n minus\n1 just given X sub n.",
    "start": "4348050",
    "end": "4356020"
  },
  {
    "text": "This is the Markov condition,\nbut it's the Markov condition turned around. Usually we talk about the next\nstate given the previous state",
    "start": "4356020",
    "end": "4365159"
  },
  {
    "text": "and everything before that. Here, we're talking about\nthe previous state given everything after that.",
    "start": "4365160",
    "end": "4371720"
  },
  {
    "text": "So this really is the Markov\ncondition on what we might view as a backward chain.",
    "start": "4371720",
    "end": "4378060"
  },
  {
    "text": "But to be a Markov chain, these\ntransition probabilities",
    "start": "4378060",
    "end": "4385040"
  },
  {
    "text": "have to be independent of n. The transition probabilities\nare not going to be",
    "start": "4385040",
    "end": "4391360"
  },
  {
    "text": "independent of n if you have\nthese arbitrary probabilities",
    "start": "4391360",
    "end": "4396690"
  },
  {
    "text": "at time 0 lousing\neverything up. So you can get around\nthis in two ways.",
    "start": "4396690",
    "end": "4402199"
  },
  {
    "text": "One way to get around it is\nto say let's restrict our attention to positive recurrent\nprocesses which are",
    "start": "4402200",
    "end": "4411390"
  },
  {
    "text": "starting out in a\nsteady state. And if we start out in a steady\nstate, then these",
    "start": "4411390",
    "end": "4416740"
  },
  {
    "text": "probabilities here--  looking at these probabilities\nhere--",
    "start": "4416740",
    "end": "4424400"
  },
  {
    "text": "if you go from here down to\nhere, you'll find out that this does not depend on n.",
    "start": "4424400",
    "end": "4429720"
  },
  {
    "text": "And if you have an initial state\nwhich is something other than steady state, then these\nwill depend on it.",
    "start": "4429720",
    "end": "4437800"
  },
  {
    "text": "Let me put this down in\nthe next chain up.",
    "start": "4437800",
    "end": "4443340"
  },
  {
    "text": "The probability of X sub n minus\n1 given X sub n is going",
    "start": "4443340",
    "end": "4448780"
  },
  {
    "text": "to be independent of n if this\nis independent of n, which it",
    "start": "4448780",
    "end": "4454409"
  },
  {
    "text": "is, because we have a\nhomogeneous Markov chain. And this is independent of n and\nthis is independent of n.",
    "start": "4454410",
    "end": "4461489"
  },
  {
    "text": "Now, this will just be the\nprobability of pi sub i if X",
    "start": "4461490",
    "end": "4467380"
  },
  {
    "text": "sub n minus 1 is equal to i. And this will be pi sub i if\nprobability of X sub n is",
    "start": "4467380",
    "end": "4473540"
  },
  {
    "text": "equal to i. So this and this will be\nindependent of n if in fact we",
    "start": "4473540",
    "end": "4480810"
  },
  {
    "text": "start out in a steady state. In other words, it won't be. So what we're doing here is we\nnormally think of a Markov",
    "start": "4480810",
    "end": "4489500"
  },
  {
    "text": "chain starting out at time 0\nbecause how else can you get it started?",
    "start": "4489500",
    "end": "4495949"
  },
  {
    "text": "And we think of it in forward\ntime, and then we say, well, we want to make it homogeneous,\nbecause we want",
    "start": "4495950",
    "end": "4502580"
  },
  {
    "text": "to make it always do the same\nthing in the future otherwise it doesn't really look much\nlike the a Markov chain.",
    "start": "4502580",
    "end": "4509290"
  },
  {
    "text": "So what we're saying is that\nthis backward chain-- we have backward probabilities\ndefined now--",
    "start": "4509290",
    "end": "4515679"
  },
  {
    "text": "the backward probabilities are\nhomogeneous if the forward",
    "start": "4515680",
    "end": "4520870"
  },
  {
    "text": "probabilities start\nin a steady state. You could probably make a\nsimilar statement but say the",
    "start": "4520870",
    "end": "4526600"
  },
  {
    "text": "forward probabilities are\nhomogeneous if the backward probabilities start\nin a steady state.",
    "start": "4526600",
    "end": "4532070"
  },
  {
    "text": "But I don't know when you're\ngoing to start. You're going to have to start it\nsometime in the future, and",
    "start": "4532070",
    "end": "4538159"
  },
  {
    "text": "that gets too philosophical\nto understand. OK. ",
    "start": "4538160",
    "end": "4543980"
  },
  {
    "text": "If we think of the chain as\nstarting in a steady state at time minus infinity, these are\nalso the equations of the",
    "start": "4543980",
    "end": "4550150"
  },
  {
    "text": "homogeneous Markov chain. We can start at time minus\ninfinity wherever we want to-- it doesn't make any\ndifference--",
    "start": "4550150",
    "end": "4556550"
  },
  {
    "text": "because by the time we get to\nstate 0, we will be in steady state, and the whole range of\nwhere we want to look at",
    "start": "4556550",
    "end": "4563380"
  },
  {
    "text": "things will be in\nsteady state. OK. So aside from this issue about\nstarting at 0 and steady state",
    "start": "4563380",
    "end": "4572480"
  },
  {
    "text": "and things like that, what we've\nreally shown here is that you can look at a Markov\nchain either going forward or",
    "start": "4572480",
    "end": "4581810"
  },
  {
    "text": "going backward. Or look at it going rightward\nor going leftward.",
    "start": "4581810",
    "end": "4588179"
  },
  {
    "text": "And that's really pretty\nimportant. OK. That still doesn't say anything\nabout it being",
    "start": "4588180",
    "end": "4594380"
  },
  {
    "text": "reversible. What reversibility is-- it comes from looking at\nthis equation here.",
    "start": "4594380",
    "end": "4602050"
  },
  {
    "text": "This says what the transition\nprobabilities are, going backwards, and this\nis the transition",
    "start": "4602050",
    "end": "4609570"
  },
  {
    "text": "probabilities going forward. These are the steady state\nprobabilities. ",
    "start": "4609570",
    "end": "4615730"
  },
  {
    "text": "And if we define P star of ji\nas a backward transition",
    "start": "4615730",
    "end": "4625540"
  },
  {
    "text": "probabilities-- namely, the probability that at\nthis time or in stage A--",
    "start": "4625540",
    "end": "4630750"
  },
  {
    "text": "given that in this next time,\nwhich to us, is the previous time, we're in state i, is the\nprobability of going in a",
    "start": "4630750",
    "end": "4638510"
  },
  {
    "text": "backward direction\nfrom j to i. ",
    "start": "4638510",
    "end": "4644970"
  },
  {
    "text": "This gets into whether this is\nP star of ij or P star of ij. But I did check it carefully,\nso it has to be right.",
    "start": "4644970",
    "end": "4652770"
  },
  {
    "text": "So anyway, when you substitute\nthis in for this, the",
    "start": "4652770",
    "end": "4659400"
  },
  {
    "text": "conditions that you get is pi\nsub i times P star of ij is",
    "start": "4659400",
    "end": "4664630"
  },
  {
    "text": "equal to pi j times P of ji. These are the same equations\nthat we had for",
    "start": "4664630",
    "end": "4670515"
  },
  {
    "text": "a birth-death chain. But now, we're not talking\nabout birth-death chains. Now we're talking about\nany old chain.",
    "start": "4670515",
    "end": "4679710"
  },
  {
    "text": "Yeah? AUDIENCE: Doesn't this only\nmake sense for positive recurring chains?",
    "start": "4679710",
    "end": "4689196"
  },
  {
    "text": "PROFESSOR: Yes. Sorry. I should keep emphasizing that,\nbecause it only makes",
    "start": "4689196",
    "end": "4695449"
  },
  {
    "text": "sense when you can define the\nsteady state probabilities. Yes. The steady state probabilities\nare necessary in order to even",
    "start": "4695450",
    "end": "4704130"
  },
  {
    "text": "define this P star of ji. But once you have that steady\nstate condition, and once you",
    "start": "4704130",
    "end": "4711070"
  },
  {
    "text": "know what the steady state\nprobabilities are, then you can calculate backward\nprobabilities, you can calculate forward probabilities,\nand this is a",
    "start": "4711070",
    "end": "4719540"
  },
  {
    "text": "very simple relationship\nthat they satisfy. It makes sense because this\nis a normal form.",
    "start": "4719540",
    "end": "4727260"
  },
  {
    "text": "You look at state transition\nprobabilities and you look at the probability of being in\none state and then the",
    "start": "4727260",
    "end": "4733960"
  },
  {
    "text": "probability of going\nto the next state. And the question is the\nnext state back there",
    "start": "4733960",
    "end": "4739680"
  },
  {
    "text": "or is it over there? And if it's a star, then it\nmeans it's back there.",
    "start": "4739680",
    "end": "4746130"
  },
  {
    "text": "And then we define a chain as\nbeing reversible if P star of",
    "start": "4746130",
    "end": "4751670"
  },
  {
    "text": "ij is equal to P sub ij,\nfor all i and all j.",
    "start": "4751670",
    "end": "4758370"
  },
  {
    "text": "And what that means is that\nall birth-death chains are reversible. ",
    "start": "4758370",
    "end": "4764639"
  },
  {
    "text": "And now let me show you\nwhat that means. ",
    "start": "4764640",
    "end": "4769969"
  },
  {
    "text": "If we look at arrivals and\ndepartures for a birth-death change, sometimes you go in a\nself loop, so you don't go up",
    "start": "4769970",
    "end": "4778610"
  },
  {
    "text": "and you don't go down. Other times you either\ngo down or you go up. We have arrivals coming in.",
    "start": "4778610",
    "end": "4784940"
  },
  {
    "text": "Arrivals correspond to upper\ntransitions, departures correspond to downward\ntransitions so that when you",
    "start": "4784940",
    "end": "4792930"
  },
  {
    "text": "look at it in a normal way,\nyou start out at time 0.",
    "start": "4792930",
    "end": "4798020"
  },
  {
    "text": "You're in state 0. You have an arrival. Nothing happens for a while.",
    "start": "4798020",
    "end": "4804849"
  },
  {
    "text": "You have another arrival, but\nthis time, you have a departure, you have another\ndeparture, and you wind up in",
    "start": "4804850",
    "end": "4812110"
  },
  {
    "text": "state 0 again.  As far states are concerned,\nyou go from",
    "start": "4812110",
    "end": "4821010"
  },
  {
    "text": "state 0 to state 1. You stay in state 1. In other words, this is the\ndifference between arrivals",
    "start": "4821010",
    "end": "4827360"
  },
  {
    "text": "and departures. This is what the state is. You stay in state 1. Then you go up and you get\nanother arrival, you get a",
    "start": "4827360",
    "end": "4834440"
  },
  {
    "text": "departure, and then you\nget a departure, according to this chain. Now, let's look at it\ncoming in this way.",
    "start": "4834440",
    "end": "4843070"
  },
  {
    "text": "When we look at it\ncoming backwards in time, what happens? We're going along here,\nwe're in state 0,",
    "start": "4843070",
    "end": "4851450"
  },
  {
    "text": "suddenly we move up. If we want to view this as a\nbackward moving Markov chain,",
    "start": "4851450",
    "end": "4861130"
  },
  {
    "text": "this corresponds to an\narrival of something. This corresponds to\nanother arrival.",
    "start": "4861130",
    "end": "4867470"
  },
  {
    "text": "This corresponds\nto a departure. We go along here with nothing\nelse happening, we get another",
    "start": "4867470",
    "end": "4872719"
  },
  {
    "text": "departure, and there we are back\nin a steady state again. ",
    "start": "4872720",
    "end": "4879210"
  },
  {
    "text": "And for any birth-death\nchain, we can do this. Because any birth-death chain\nwe can look at as an arrival",
    "start": "4879210",
    "end": "4889119"
  },
  {
    "text": "and departure process. We have arrivals, we\nhave departures--",
    "start": "4889120",
    "end": "4894140"
  },
  {
    "text": "we might have states\nthat go negative. That would be rather awkward,\nbut we can have that.",
    "start": "4894140",
    "end": "4899449"
  },
  {
    "text": "But now, if we know that these\nsteady state probabilities",
    "start": "4899450",
    "end": "4905330"
  },
  {
    "text": "govern the probability of\narrivals and the probabilities of departures, if we know that\nwe have reversibility, then",
    "start": "4905330",
    "end": "4913619"
  },
  {
    "text": "these events here have the\nsame probability as these events here.",
    "start": "4913620",
    "end": "4919619"
  },
  {
    "text": "It means that when we look at\nthings going from right back to left, it means that the\nthings that we viewed as",
    "start": "4919620",
    "end": "4927139"
  },
  {
    "text": "departures here look\nlike arrivals. And what we're going to do next\ntime is use that to prove",
    "start": "4927140",
    "end": "4933730"
  },
  {
    "text": "Burke's Theorem, which says\nusing this idea that if you",
    "start": "4933730",
    "end": "4939950"
  },
  {
    "text": "look at the process of\ndepartures in a birth-death",
    "start": "4939950",
    "end": "4945210"
  },
  {
    "text": "chain where arrivals are all\nwith probability P and departures are all with\nprobability Q, then you get",
    "start": "4945210",
    "end": "4952590"
  },
  {
    "text": "this nice set of probabilities\nfor arrivals and departures.",
    "start": "4952590",
    "end": "4957599"
  },
  {
    "text": "Arrivals are independent\nof everything else-- same probability at every\nunit of time.",
    "start": "4957600",
    "end": "4963960"
  },
  {
    "text": "Departures are the same way. But when you're looking from\nleft to right, you can only",
    "start": "4963960",
    "end": "4969680"
  },
  {
    "text": "get departures when your state\nis greater than 0. When you're coming in looking\nthis way, these things that",
    "start": "4969680",
    "end": "4978680"
  },
  {
    "text": "looked like departures before\nare looking like arrivals. These arrivals form a Bernoulli\nProcess, and the",
    "start": "4978680",
    "end": "4988240"
  },
  {
    "text": "Bernoulli Process says that\ngiven the future, the probability of a departure,\nat any instant of time, is",
    "start": "4988240",
    "end": "4997630"
  },
  {
    "text": "independent of everything\nin the future. ",
    "start": "4997630",
    "end": "5003120"
  },
  {
    "text": "Now, that is not intuitive. If you think it's intuitive,\ngo back and think again.",
    "start": "5003120",
    "end": "5008960"
  },
  {
    "text": "Because it's not. But anyway, I'm going\nto stop here. You have this to mull over.",
    "start": "5008960",
    "end": "5015400"
  },
  {
    "text": "We will try to sort it out\na little more next time. This is something that's going\nto take your cooperation to",
    "start": "5015400",
    "end": "5020880"
  },
  {
    "text": "sort it out, also. ",
    "start": "5020880",
    "end": "5025067"
  }
]
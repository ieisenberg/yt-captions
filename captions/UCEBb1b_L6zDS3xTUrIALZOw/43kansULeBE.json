[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5580",
    "end": "12270"
  },
  {
    "text": "To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12270",
    "end": "18830"
  },
  {
    "text": "at ocw.mit.edu.  AUDE OLIVA: Thank you very\nmuch for the introduction.",
    "start": "18830",
    "end": "24820"
  },
  {
    "text": "Good morning, everyone. So I'm very pleased to be here. It's the first time I visit.",
    "start": "24820",
    "end": "30420"
  },
  {
    "text": "So I would like to give you\na tour during this lecture about how you can predict\nhuman visual memory,",
    "start": "30420",
    "end": "38550"
  },
  {
    "text": "and actually an\ninterdisciplinary account of the methods you can\nuse together in order",
    "start": "38550",
    "end": "44040"
  },
  {
    "text": "to have basically a view of what\npeople can remember or forget. So the specific question\nwe are going to ask today",
    "start": "44040",
    "end": "52620"
  },
  {
    "text": "is, well, we are experiencing\nand seeing all the time a lot of digital information.",
    "start": "52620",
    "end": "58949"
  },
  {
    "text": "First you see in the\nreal world, but also you are exposed to many,\nmany videos and images.",
    "start": "58950",
    "end": "65640"
  },
  {
    "text": "So vision and visual memory\nis one of the core concept of cognition.",
    "start": "65640",
    "end": "71640"
  },
  {
    "text": "And the question\nwe ask is, can we predict which image or graph\nor face or words or videos",
    "start": "71640",
    "end": "78900"
  },
  {
    "text": "or piece of\ninformation or event is going to be memorable\nor forgettable for a group of people,\nand eventually for a given",
    "start": "78900",
    "end": "86700"
  },
  {
    "text": "individual? So let's take a\nmoment to imagine",
    "start": "86700",
    "end": "91710"
  },
  {
    "text": "that we will be able\nto predict accurately",
    "start": "91710",
    "end": "97170"
  },
  {
    "text": "the memory of people. Well, this will be very\nuseful to understand",
    "start": "97170",
    "end": "102750"
  },
  {
    "text": "the mechanism of\nhuman memory, both at the cognitive and neuroscience\nlevel, system level,",
    "start": "102750",
    "end": "110640"
  },
  {
    "text": "as well as possibly\ndiagnose memory problem, short-term visual memory,\nlong-term visual memory, that",
    "start": "110640",
    "end": "117120"
  },
  {
    "text": "may arise possibly in an acute\nway or developing over time,",
    "start": "117120",
    "end": "123210"
  },
  {
    "text": "as well as design\nmnemonic aids in order to recall better informations.",
    "start": "123210",
    "end": "128699"
  },
  {
    "text": "But beside basic science, if\nyou could predict information that are memorable\nor forgettable,",
    "start": "128699",
    "end": "135810"
  },
  {
    "text": "there is a realm of\napplication that you could work on or basically\npropose that lie really",
    "start": "135810",
    "end": "144780"
  },
  {
    "text": "everywhere between the data\nvisualization or the slogan, make basically slogan\nbetter, as well",
    "start": "144780",
    "end": "151890"
  },
  {
    "text": "as all the realm of education,\nthe individual differences that may arise between people. Someone will not\nlearn very well.",
    "start": "151890",
    "end": "159330"
  },
  {
    "text": "Well, what can we do\nin order to increase the memory of visual information\nthat this person can grasp?",
    "start": "159330",
    "end": "166470"
  },
  {
    "text": "As well as various\napplications-- social networking, faces,\nretrieve better images, and so on.",
    "start": "166470",
    "end": "172300"
  },
  {
    "text": "So understanding what\nmake an information memorable or\nforgettable basically is really a very\ninter-disciplinary question,",
    "start": "172300",
    "end": "179670"
  },
  {
    "text": "something very exciting\nfor us to work on, because there's a\nlot, a lot of future",
    "start": "179670",
    "end": "184769"
  },
  {
    "text": "in working in that topic. So this is a topic we started\nin my lab a few years ago.",
    "start": "184770",
    "end": "191519"
  },
  {
    "text": "And the best for you\nto get a sense of how you start working, for\ninstance, on memory",
    "start": "191520",
    "end": "197150"
  },
  {
    "text": "is to do the kind of\ngame and the experiment we had people doing. So welcome to the\nVisual Memory Game.",
    "start": "197150",
    "end": "204240"
  },
  {
    "text": "A stream of images will\nbe presented on the screen for one second each. And your task is to--",
    "start": "204240",
    "end": "211020"
  },
  {
    "text": "If you are in front of your\ncomputer you will press a key. But what you're going to\ndo is play the game with me",
    "start": "211020",
    "end": "216120"
  },
  {
    "text": "and clap your hand\nanytime you see any image that you saw before. So you're going to have to\nbe attentive, because images,",
    "start": "216120",
    "end": "224040"
  },
  {
    "text": "they go by fast in this\nrapid stream of images. And so you will be\ngetting feedback.",
    "start": "224040",
    "end": "230740"
  },
  {
    "text": "So it's a very straightforward\nmemory experiment. And this is the\nfirst step in order",
    "start": "230740",
    "end": "235770"
  },
  {
    "text": "to get some score on a\nlot of images regarding",
    "start": "235770",
    "end": "241770"
  },
  {
    "text": "the type of information\nthat people will naturally forget or naturally remember. So let's do the game.",
    "start": "241770",
    "end": "248580"
  },
  {
    "text": "So are you ready? All right. So clap your hand\nwhenever you see a repeat. ",
    "start": "248580",
    "end": "256370"
  },
  {
    "text": "So this is what will rerun. Very simple images. [CLAPPING] Fine.",
    "start": "256370",
    "end": "261768"
  },
  {
    "text": "Excellent. So images are shown one second. There's a one-second interval.",
    "start": "261769",
    "end": "266960"
  },
  {
    "text": " [CLAPPING]",
    "start": "266960",
    "end": "272060"
  },
  {
    "start": "272060",
    "end": "277889"
  },
  {
    "text": "You're good. No false alarm. Excellent.",
    "start": "277890",
    "end": "284901"
  },
  {
    "text": "All right. So that was one of the level,\nlevel 9, out of 30 complete.",
    "start": "284901",
    "end": "290220"
  },
  {
    "text": "And so here's the\ngame that people had. They could play this game for\nfive minutes, had a break, and come back.",
    "start": "290220",
    "end": "296280"
  },
  {
    "text": "And this game had a lot\nof success, and we run it. I'm going to show many\nresults about this.",
    "start": "296280",
    "end": "301350"
  },
  {
    "text": "So you could see your score, the\namount of money you have done. This was run on Amazon\nMechanical Turk.",
    "start": "301350",
    "end": "306590"
  },
  {
    "text": "And this allow us to collect\nall around the world a lot of data regarding\nmany, many images.",
    "start": "306590",
    "end": "314009"
  },
  {
    "text": "So those visual\nmemory experiment were set up by Phillip\nIsola from MIT.",
    "start": "314010",
    "end": "320550"
  },
  {
    "text": "And you can basically\nplay that game for any kind of information\ndisplayed visually.",
    "start": "320550",
    "end": "326490"
  },
  {
    "text": "So we did it for pictures,\nfaces, and words. And you're going\nto see the result.",
    "start": "326490",
    "end": "332100"
  },
  {
    "text": "So let's start\nwith the pictures. In the first experiment,\nwe presented 10,000 images, and about 2,200 we\nrepeated many, many time.",
    "start": "332100",
    "end": "341580"
  },
  {
    "text": "So those were the one where\nwe collected the score. So for a given\nsubject, those images",
    "start": "341580",
    "end": "348900"
  },
  {
    "text": "were actually seen only once. Twice, sorry. So you have the stream\nof images at the top.",
    "start": "348900",
    "end": "355780"
  },
  {
    "text": "So, for instance, an image\nwill be shown after 90, 100,",
    "start": "355780",
    "end": "360990"
  },
  {
    "text": "110 images or so. And if this image was one\nthat the subject recognized,",
    "start": "360990",
    "end": "368190"
  },
  {
    "text": "then he will press a key. So it's exactly the\ndesign you just did. And when first you look\nat the type of images",
    "start": "368190",
    "end": "374910"
  },
  {
    "text": "that are highly memorable\nor forgettable, well, there's a trend\nthat we all expect,",
    "start": "374910",
    "end": "380450"
  },
  {
    "text": "is images who are kind of\neither funny or have something distinctive or\nsomething different,",
    "start": "380450",
    "end": "386520"
  },
  {
    "text": "or if people are\ndoing various action, or of some object that are\nkind of out of context,",
    "start": "386520",
    "end": "395250"
  },
  {
    "text": "those tend to be memorable. And, in general,\nlandscape or images",
    "start": "395250",
    "end": "400710"
  },
  {
    "text": "that don't have any activity\ntend to be forgettable. So we have those that score\nfor more than 2,000 images",
    "start": "400710",
    "end": "407010"
  },
  {
    "text": "from that experiment. So one of the first\nthing we need to know is, well, everyone\nis playing that game,",
    "start": "407010",
    "end": "413560"
  },
  {
    "text": "and we can have their\nown memory score. But in order to know if\nsome images are indeed",
    "start": "413560",
    "end": "418919"
  },
  {
    "text": "memorable for all of us or a\ngood amount of the population, we need to see if there is\nconsistency between people.",
    "start": "418920",
    "end": "426670"
  },
  {
    "text": "So here is a simple\nmeasure we do. You have a group of people\nlooking at those images, and we have the memory score.",
    "start": "426670",
    "end": "432449"
  },
  {
    "text": "And you can split\nthe group into two, and rank according to the\naverage of the first group,",
    "start": "432450",
    "end": "439919"
  },
  {
    "text": "the images, from\nthe most memorable to the less memorable. And then you can also\nrank the same images",
    "start": "439920",
    "end": "446500"
  },
  {
    "text": "in the second group. And if the two group were\nidentical to each other,",
    "start": "446500",
    "end": "451620"
  },
  {
    "text": "you will get a correlation\nbetween those two ranking of 1. And what we observe when we\nsplit repetitively the group",
    "start": "451620",
    "end": "459780"
  },
  {
    "text": "into two like this is\nwe observe a correlation of 0.75, which is pretty high.",
    "start": "459780",
    "end": "466090"
  },
  {
    "text": "And this give us basically\nthe maximum performances that we can expect when\nwe have a group of people",
    "start": "466090",
    "end": "472140"
  },
  {
    "text": "that can predict\nthe rank of images of another group of people. And actually, here\nis the curve that",
    "start": "472140",
    "end": "478630"
  },
  {
    "text": "shows what the 0.75\nconsistency look like.",
    "start": "478630",
    "end": "483965"
  },
  {
    "text": "So on the x-axis, you\nhave the image rank according to the\ngroup number one,",
    "start": "483965",
    "end": "489090"
  },
  {
    "text": "so the images with the\nhighest memory score.",
    "start": "489090",
    "end": "494505"
  },
  {
    "text": "So I have a group of\nthem that are above 90. And it's normal. The group number one in\nblue decrease as images",
    "start": "494505",
    "end": "503220"
  },
  {
    "text": "are less and less memorable. So that's like basically\nyour ground truth curve.",
    "start": "503220",
    "end": "510090"
  },
  {
    "text": "And the green show\nthe group number two, totally independent people,\nand also the performances",
    "start": "510090",
    "end": "516840"
  },
  {
    "text": "that they got for each\nbins along the image rank. And you can see the curve\nare pretty close by.",
    "start": "516840",
    "end": "524190"
  },
  {
    "text": "So a correlation of\n0.75 look like this. So it means that, with\nindependent group of people,",
    "start": "524190",
    "end": "531750"
  },
  {
    "text": "there are some images that\nare going to be systematically more memorable or forgettable.",
    "start": "531750",
    "end": "537250"
  },
  {
    "text": "You can see the full range going\nbelow 40% for the images that were forgotten, up to\n95 for the one that",
    "start": "537250",
    "end": "544860"
  },
  {
    "text": "were systematically remembered. But, importantly,\na group of person is going to predict\nanother group of person.",
    "start": "544860",
    "end": "551970"
  },
  {
    "text": "So there's several\nways to test memory. The way we tested memory\nhere to get ground truth was an objective measurement.",
    "start": "551970",
    "end": "558870"
  },
  {
    "text": "You see an image again,\nand if you remember it, you press a key. So that's an\nobjective measurement. But you can also\nask people, do you",
    "start": "558870",
    "end": "566010"
  },
  {
    "text": "think you will\nremember an image? Do you think someone else\nwill remember an image? We also run those\nsubjective memory score.",
    "start": "566010",
    "end": "574580"
  },
  {
    "text": "And we observed this\nvery interesting trend that the subjective\njudgment do not predict image memorability,\nwhich means that,",
    "start": "574580",
    "end": "583370"
  },
  {
    "text": "if you ask yourself, am\nI going to remember this? Well, basically,\nmaybe, maybe not.",
    "start": "583370",
    "end": "589430"
  },
  {
    "text": "So subjective judgment of what\nyou think your memory will be",
    "start": "589430",
    "end": "596720"
  },
  {
    "text": "or what you think the memory\nof someone else will be is not correlated with the true\nmemory, with whatever you're",
    "start": "596720",
    "end": "602480"
  },
  {
    "text": "going to remember or not. So this was very\ninteresting, because it",
    "start": "602480",
    "end": "608209"
  },
  {
    "text": "shows that objective measurement\nshould be needed here in order to really get a sense of what\npeople will remember or forget.",
    "start": "608210",
    "end": "615560"
  },
  {
    "text": "We basically have many papers\non this topic since 2010. They are all on the web site.",
    "start": "615560",
    "end": "621681"
  },
  {
    "text": "And then some of them will look\nat the correlation existing between memory, so\nthe fact that you're going to remember\ncertain kind of images,",
    "start": "621682",
    "end": "628850"
  },
  {
    "text": "and other attributes,\nfor instance, aesthetic. And, again, we found\nthat memorability is",
    "start": "628850",
    "end": "633980"
  },
  {
    "text": "distinct from image aesthetic. This means that\nbasically you could have an image that is\njudged very beautiful,",
    "start": "633980",
    "end": "640055"
  },
  {
    "text": "or, on the contrary,\nugly or boring. And in those cases,\nyou will still",
    "start": "640055",
    "end": "645830"
  },
  {
    "text": "remember those two images. So we found this absence of a\ncorrelation between those two",
    "start": "645830",
    "end": "651710"
  },
  {
    "text": "attribute in our values studies. We replicate this with other\ndata set and faces as well.",
    "start": "651710",
    "end": "658110"
  },
  {
    "text": "So it looks like what\nyou will remember is this notion of\ndistinctiveness, but it can be beautiful or ugly.",
    "start": "658110",
    "end": "666710"
  },
  {
    "text": "It doesn't matter. You can still either\nremember it or forget it. So you had this question\nabout the notion of the lag.",
    "start": "666710",
    "end": "674390"
  },
  {
    "text": "So the lag is in that you\ncould test visual memory after a few seconds or a\nfew intervening images,",
    "start": "674390",
    "end": "680880"
  },
  {
    "text": "or you could test it\na few minutes or even one hour later, or\neven days later. So because we were\nrunning those experiments",
    "start": "680880",
    "end": "687620"
  },
  {
    "text": "on Amazon Mechanical Turk,\nwe did not do the dates. However, we did run\nsome with a larger gap,",
    "start": "687620",
    "end": "693649"
  },
  {
    "text": "up to 1,000 different\nimages between the first and the second repeat.",
    "start": "693650",
    "end": "699810"
  },
  {
    "text": "And so here is the\ndesign, the one that I show you for the\nabout 100 images intervening",
    "start": "699810",
    "end": "706460"
  },
  {
    "text": "between the first and\nthe second repeat. But what about a shorter\nand a longer time scale?",
    "start": "706460",
    "end": "712310"
  },
  {
    "text": "So all that work\nis also published. You can go and download the\npaper and see the details.",
    "start": "712310",
    "end": "719420"
  },
  {
    "text": "But the basic idea is that\nthe ranks were conserved.",
    "start": "719420",
    "end": "724829"
  },
  {
    "text": "So if one image\nis very memorable, one of the top after,\nlet's say, a few seconds,",
    "start": "724830",
    "end": "731360"
  },
  {
    "text": "will still be\nmemorable after hours. And if an image is forgettable\nor one of the most forgettable",
    "start": "731360",
    "end": "738320"
  },
  {
    "text": "after a few seconds, will still\nbe forgettable after hours. So the fact that the magnitude,\nthe percentage of images",
    "start": "738320",
    "end": "747740"
  },
  {
    "text": "remembered decrease is normal. That is known from memory\nresearch for decades.",
    "start": "747740",
    "end": "753690"
  },
  {
    "text": "So it is expected. However, memorability\nhere is basically the rank, which is an image, is\nfor a population independently",
    "start": "753690",
    "end": "762680"
  },
  {
    "text": "basically of the\nrow, the magnitude. One of the most memorable given\nthis condition is forgettable.",
    "start": "762680",
    "end": "772886"
  },
  {
    "text": "And we did those\nexperiment, both on the web as well as in the lab,\nbecause in the lab we",
    "start": "772886",
    "end": "778970"
  },
  {
    "text": "could control for more factors. And it was very interesting\nto see in the lab experiment",
    "start": "778970",
    "end": "786380"
  },
  {
    "text": "that only after 20 second there\nwere images that were totally forgotten by a good group,\na good amount of people.",
    "start": "786380",
    "end": "795930"
  },
  {
    "text": "So some image seems to really-- basically do not\nstick and be gone in I",
    "start": "795930",
    "end": "805536"
  },
  {
    "text": "don't know how many second. We did not go really\nto short-term memory. We work starting in long-term\nmemory at 20 seconds and so on.",
    "start": "805536",
    "end": "812730"
  },
  {
    "text": "But there's this phenomenon. So it suggests that\nthere are some features into the visual information\nthat are encoded",
    "start": "812730",
    "end": "821000"
  },
  {
    "text": "in less details than others or\nwith more details than others. And what's very\ninteresting is then you can go to\nneuroscience and basically",
    "start": "821000",
    "end": "829280"
  },
  {
    "text": "start studying the\nlevel of details or the quality of\nencoding of an image and see where in\nthe visual pathway",
    "start": "829280",
    "end": "837150"
  },
  {
    "text": "an image basically is gone\nafter 20 seconds or something like this.",
    "start": "837150",
    "end": "842600"
  },
  {
    "text": "So important point--\nthe rank is conserved.",
    "start": "842600",
    "end": "847880"
  },
  {
    "text": "So we also look at those\nprinciple of memorability that we found for\nimages in faces.",
    "start": "847880",
    "end": "854700"
  },
  {
    "text": "So faces is a very\ninteresting material",
    "start": "854700",
    "end": "861710"
  },
  {
    "text": "to work with, because\nbasically it's all images that look alike.",
    "start": "861710",
    "end": "868580"
  },
  {
    "text": "So you have basically\none object and look at many, many exemplars. And there's no reason to believe\nthat this high consistency we",
    "start": "868580",
    "end": "875660"
  },
  {
    "text": "will find for\nimages as different as amphitheater and the parking\nand so on, and landscape,",
    "start": "875660",
    "end": "883710"
  },
  {
    "text": "this high consistency\nwill be found with faces. So we gather a data\nset of 10,000 faces.",
    "start": "883710",
    "end": "891240"
  },
  {
    "text": "The paper is published,\nas well as the entire data set is available on the web. So you can go and download\nthose 10,000 faces as well as",
    "start": "891240",
    "end": "898650"
  },
  {
    "text": "all the attribute\nthat we found where we study with the data set.",
    "start": "898650",
    "end": "904470"
  },
  {
    "text": "And we also found\nthe same phenomenon, very high consistency, both in\nthe correct positive responses,",
    "start": "904470",
    "end": "911850"
  },
  {
    "text": "when people remember\nseeing a face, as well as in the false alarm,\nwhen people did not see a face",
    "start": "911850",
    "end": "918990"
  },
  {
    "text": "but falsely thought\nthat they saw a face and basically pressed the key.",
    "start": "918990",
    "end": "924600"
  },
  {
    "text": "So this very high consistency\nfor both measurement suggests that, again, in the\nfacial features of people,",
    "start": "924600",
    "end": "933065"
  },
  {
    "text": "or at least the way\na photo is taken, there is something at the\nlevel of the image that",
    "start": "933065",
    "end": "939060"
  },
  {
    "text": "will make a face highly\nmemorable or highly forgettable for most people.",
    "start": "939060",
    "end": "945790"
  },
  {
    "text": "So all the details of this\nstudy are actually on the web. It was a pretty complex study\nto run, because while we have",
    "start": "945790",
    "end": "959040"
  },
  {
    "text": "very different\nsensitivity to faces, so the race effect on\nbasically where we grew up,",
    "start": "959040",
    "end": "966900"
  },
  {
    "text": "so we know there's a lot\nof individual differences. So the way this study\nwas run is the collection",
    "start": "966900",
    "end": "972660"
  },
  {
    "text": "of faces we have followed\nthe US census in terms of male, female, race, and age.",
    "start": "972660",
    "end": "979860"
  },
  {
    "text": "We started at 18\nyears old and older. So did our population as well.",
    "start": "979860",
    "end": "986290"
  },
  {
    "text": "So on the group, we\nshow a collection of faces that did match the\npopulation, the people who",
    "start": "986290",
    "end": "992430"
  },
  {
    "text": "were running the study. And, as I say, all the data\nare available on the web",
    "start": "992430",
    "end": "998110"
  },
  {
    "text": "if some of you want to go back\nand do additional analysis.",
    "start": "998110",
    "end": "1003170"
  },
  {
    "text": "So we kept going with this. So we have the consistency\nin the visual material. So now what about words?",
    "start": "1003170",
    "end": "1010070"
  },
  {
    "text": "So words is a very\ninteresting case, because now you\ndo know the words. But are there some kind of\nwords that we can predict",
    "start": "1010070",
    "end": "1016960"
  },
  {
    "text": "are more forgettable\nor memorable? Again, there's no reason to\nbelieve a high consistency will",
    "start": "1016960",
    "end": "1023600"
  },
  {
    "text": "be found. But we've run the study\ntwice with two different data set, again, ten thousand item,\nand two different set of words.",
    "start": "1023600",
    "end": "1035119"
  },
  {
    "text": "And we found, again, very\nhigh consistency, which is that a collection of\nwords were systematically",
    "start": "1035119",
    "end": "1041599"
  },
  {
    "text": "remembered by people and\nothers were forgettable. So this work that is\ndone in collaboration",
    "start": "1041599",
    "end": "1048620"
  },
  {
    "text": "with Mahowald, Isola,\nGibson, and Fedorenko is under submission.",
    "start": "1048620",
    "end": "1055310"
  },
  {
    "text": "But let me give you a taste\nof the words that we found. So what make words more\nmemorable or forgettable?",
    "start": "1055310",
    "end": "1062610"
  },
  {
    "text": "So here is a cartoon that give\nyou the basic idea is, well, if there is one word\nfor one meaning,",
    "start": "1062610",
    "end": "1069710"
  },
  {
    "text": "so basically a word\nhas a single meaning, it will have a tendency\nto be much more memorable than if a\nwords has many meanings.",
    "start": "1069710",
    "end": "1077210"
  },
  {
    "text": "So in the paper, we also\nlook at the correlation between memorability and image\nability or frequency and so on.",
    "start": "1077210",
    "end": "1086280"
  },
  {
    "text": "And all this is describe,\nbut really the main factor is this one-to-one referent\nbetween a word and its meaning",
    "start": "1086280",
    "end": "1095470"
  },
  {
    "text": "or concept. So let's look at\nsome of the example.",
    "start": "1095470",
    "end": "1100940"
  },
  {
    "text": "The paper will come with the\ntwo data set and thousand of words that were found\nmemorable and forgettable.",
    "start": "1100940",
    "end": "1108080"
  },
  {
    "text": "So I think if you\nwrite a letter, you should not say that\nyour student is excellent",
    "start": "1108080",
    "end": "1114000"
  },
  {
    "text": "but that she is fabulous. And our research is not a blast.",
    "start": "1114000",
    "end": "1119450"
  },
  {
    "text": "It's in vogue. And the idea of a team is not\nirrational, they are grotesque.",
    "start": "1119450",
    "end": "1124880"
  },
  {
    "text": "So those are just a few\nexample of the words that on average,\nof the three first,",
    "start": "1124880",
    "end": "1130760"
  },
  {
    "text": "had more referent\nand the tendency to be more forgettable\nbecause they",
    "start": "1130760",
    "end": "1135950"
  },
  {
    "text": "might be used for many\nmore things than the one. I also notice a lot\nof the French words",
    "start": "1135950",
    "end": "1143180"
  },
  {
    "text": "tend to be memorable. So we do find this\nstable principle",
    "start": "1143180",
    "end": "1149870"
  },
  {
    "text": "that you can\npredict the content, can predict what type\nof images, faces,",
    "start": "1149870",
    "end": "1156800"
  },
  {
    "text": "words that are memorable. And we also did it\nfor visualization, starting working on\nthe topic of education.",
    "start": "1156800",
    "end": "1162559"
  },
  {
    "text": "So this is very useful,\nbecause at least at the level of a group, you can\nstart making that prediction.",
    "start": "1162560",
    "end": "1168470"
  },
  {
    "text": "Oh, I also have\nmassive and avalanche. Forgot about it. So now that we were able\nto have all those data",
    "start": "1168470",
    "end": "1178530"
  },
  {
    "text": "and see that there\nis this consistency, then one of the next question\nyou can look at is, OK, well,",
    "start": "1178530",
    "end": "1184440"
  },
  {
    "text": "if it seems that we\nall have a tendency to remember the same image,\ncan we find a neural signature",
    "start": "1184440",
    "end": "1193149"
  },
  {
    "text": "into the human brain? So the question of memorability,\nis it a perceptual or memory",
    "start": "1193150",
    "end": "1199800"
  },
  {
    "text": "question? Because in all our\nexperiment, the images are shown for a short time.",
    "start": "1199800",
    "end": "1204906"
  },
  {
    "text": "And then, when\nthey are repeated, you see them a second time. But basically, all the action\nis at the perception level.",
    "start": "1204906",
    "end": "1211410"
  },
  {
    "text": "Whenever you perceive this\nimage for half a second or one second, there is\nsomething going on here",
    "start": "1211410",
    "end": "1217390"
  },
  {
    "text": "at the perception\nlevel that is going to bias if this image is going\nto basically go into memory",
    "start": "1217390",
    "end": "1224190"
  },
  {
    "text": "or not. So, knowing this,\nif we want to look at the potential neural\nframework of memorability,",
    "start": "1224190",
    "end": "1231539"
  },
  {
    "text": "we have to look at\nthe entire brain. We have to look at\nall the region that have been found to be\nrelated to perception,",
    "start": "1231540",
    "end": "1241710"
  },
  {
    "text": "faces perception, picture\nperception, object, space, and so on, as well as the\nmedial temporal lobe region,",
    "start": "1241710",
    "end": "1250260"
  },
  {
    "text": "more in the middle\nof the brain, that have been related to memory. So this is what we did\nwith Wilma Bainbridge.",
    "start": "1250260",
    "end": "1257790"
  },
  {
    "text": "This is her PhD,\nbasically having a look at all those region.",
    "start": "1257790",
    "end": "1263370"
  },
  {
    "text": "And here is the very\nsimple experiment we run. So we took a collection\nof faces and scene",
    "start": "1263370",
    "end": "1271080"
  },
  {
    "text": "from the thousands we\nhave, and where every one, we'll basically separate\nthose two between looking",
    "start": "1271080",
    "end": "1278010"
  },
  {
    "text": "at the region that\nare more activated for seeing versus the region\nmore activated for faces.",
    "start": "1278010",
    "end": "1286350"
  },
  {
    "text": "We split it that way,\nbetween the memorable and the forgettable set.",
    "start": "1286350",
    "end": "1291570"
  },
  {
    "text": "So in those set,\nevery images is novel.",
    "start": "1291570",
    "end": "1297990"
  },
  {
    "text": "So exactly like in\nthe memory experiment, we could show them one\ntime for half a second.",
    "start": "1297990",
    "end": "1304680"
  },
  {
    "text": "So you had the perception level. You're in a\nperception experiment. You saw those image one after\nthe other only one time.",
    "start": "1304680",
    "end": "1312030"
  },
  {
    "text": "All those images are novel. So we're going to\nlook at the contrast from novel image minus novel\nimage, from scene minus scene,",
    "start": "1312030",
    "end": "1321840"
  },
  {
    "text": "from faces minus faces,\nexcept that some images are",
    "start": "1321840",
    "end": "1327240"
  },
  {
    "text": "highly memorable and some\nare highly forgettable.",
    "start": "1327240",
    "end": "1332429"
  },
  {
    "text": "So other factor that\nyou have to look at is, it's still possible that\nwithin those group of images",
    "start": "1332430",
    "end": "1341880"
  },
  {
    "text": "and faces that are highly\nmemorable or forgettable, that there's a lot\nof image features",
    "start": "1341880",
    "end": "1348120"
  },
  {
    "text": "that basically\ncorrelate with those. So if you take a collection of\nimages like I shown you before,",
    "start": "1348120",
    "end": "1353400"
  },
  {
    "text": "and did the environment or\nthe photo that have people or action tend to be\nmemorable versus a landscape",
    "start": "1353400",
    "end": "1360460"
  },
  {
    "text": "tend to be forgettable? So here you have a\nlot of visual features",
    "start": "1360460",
    "end": "1366270"
  },
  {
    "text": "that will co-vary with the\ndimension of memorability.",
    "start": "1366270",
    "end": "1371610"
  },
  {
    "text": "So in that study for the\nbrain, we equalize for that, because we had enough images.",
    "start": "1371610",
    "end": "1377650"
  },
  {
    "text": "So here you have a\nsample of the two groups and sample of images and the\ntype of statistic we look at.",
    "start": "1377650",
    "end": "1384400"
  },
  {
    "text": "And the two, for\ninstance, for this scene were equalized in term of the\ntype of category you had--",
    "start": "1384400",
    "end": "1390240"
  },
  {
    "text": "outdoor, indoor, beach,\nlandscape, house, kitchen, and so on--",
    "start": "1390240",
    "end": "1395679"
  },
  {
    "text": "as well as a collection\nof low-level features. And you can see some of\nthe average signature that",
    "start": "1395680",
    "end": "1401850"
  },
  {
    "text": "are actually identical on a lot\nof low to mid to higher level",
    "start": "1401850",
    "end": "1408539"
  },
  {
    "text": "image features that were\nequalized between the two group. So whatever we find\nis not going to be",
    "start": "1408540",
    "end": "1415620"
  },
  {
    "text": "due to simple statistic due to\nthe image or the type of object",
    "start": "1415620",
    "end": "1421330"
  },
  {
    "text": "those have. We could play the same game\nfor the faces, so we did.",
    "start": "1421330",
    "end": "1426960"
  },
  {
    "text": "Here are the numbers again,\nmemorable and forgettable faces that were also equalized\nfor various attribute",
    "start": "1426960",
    "end": "1434220"
  },
  {
    "text": "like attractiveness,\nemotion, kindness, happiness, and so on, as well\nas male, female,",
    "start": "1434220",
    "end": "1442260"
  },
  {
    "text": "race, as well as\nexpression, and so on. And you can see that the\nstatistic, the average faces",
    "start": "1442260",
    "end": "1448559"
  },
  {
    "text": "for both the memorable\nand the forgettable group, are actually also identical. So with those group, what's left\nis hopefully only the factor",
    "start": "1448560",
    "end": "1459150"
  },
  {
    "text": "of something else in the image\nat the level of a higher image statistic, because only image\nstatistic will explain the fact",
    "start": "1459150",
    "end": "1467519"
  },
  {
    "text": "that very different people\nwill remember the same faces and forget the same faces. But certainly not some of\nobvious low-level image",
    "start": "1467520",
    "end": "1476040"
  },
  {
    "text": "statistic. Those cannot explain any result. So two years and\nfour study later,",
    "start": "1476040",
    "end": "1484710"
  },
  {
    "text": "we replicated basically\nthis study four times with many different matter.",
    "start": "1484710",
    "end": "1490500"
  },
  {
    "text": "Then, I'm just going\nto show you here one snapshot of the result. So this is a Multi-variate\nPattern Analysis",
    "start": "1490500",
    "end": "1498090"
  },
  {
    "text": "looking at the memorable\nversus the forgettable groups,",
    "start": "1498090",
    "end": "1503270"
  },
  {
    "text": "searchlight analysis,\nMVPA looking for the region of the\nbrain that are more active.",
    "start": "1503270",
    "end": "1510620"
  },
  {
    "text": "Well, that have a\ndifferent pattern. They are also more active,\nbut at a different pattern for memorable faces.",
    "start": "1510620",
    "end": "1518070"
  },
  {
    "text": "And we find signature\nin the hippocampus, the parahippocampal\narea, as well as the perirhinal that are typical\nfor memorable faces and scene,",
    "start": "1518070",
    "end": "1530620"
  },
  {
    "text": "and a new signature in the\nvisual area or even the higher visual area, because we\ndid equalize for those.",
    "start": "1530620",
    "end": "1538890"
  },
  {
    "text": "So it seems to show that\nthose MTL region play a role in a kind of higher-order\nstatistical perception,",
    "start": "1538890",
    "end": "1547520"
  },
  {
    "text": "a notion of distinctiveness\nthat is within those image. So this suggest that at the\nperception of a new image,",
    "start": "1547520",
    "end": "1556110"
  },
  {
    "text": "could be a face or a scene\nor a collection of object and so on, well, there's already\na signature of this that's",
    "start": "1556110",
    "end": "1564120"
  },
  {
    "text": "going to guide or bias if this\nis going to be put into memory or not.",
    "start": "1564120",
    "end": "1569560"
  },
  {
    "text": "And we have those at\nthe level of the group, looking now at the\nlevel of individuals.",
    "start": "1569560",
    "end": "1577840"
  },
  {
    "text": "All right. So, well, it looks\nlike we're going, given your question\nis now trying to model",
    "start": "1577840",
    "end": "1585780"
  },
  {
    "text": "this notion of memorability. So we have a good case that\nthere is some information",
    "start": "1585780",
    "end": "1591570"
  },
  {
    "text": "into the image of a\nhigher-level status-- we don't know which one-- that cannot be explained by\nsimple features that make all",
    "start": "1591570",
    "end": "1601410"
  },
  {
    "text": "of us reacting the same way. Even our brain do\nreact the same way. We also have images, signature\nof memorability coming up.",
    "start": "1601410",
    "end": "1610530"
  },
  {
    "text": "So we have this intrinsic\ninformation that make all of us remember or forget the same\nkind of visual information.",
    "start": "1610530",
    "end": "1617110"
  },
  {
    "text": "So can we now in a way\nimitate or model those result",
    "start": "1617110",
    "end": "1622440"
  },
  {
    "text": "into an artificial system? All right. So you have all heard about the\nrevolution in computer vision",
    "start": "1622440",
    "end": "1635220"
  },
  {
    "text": "a couple of years\nago and deep learning and those neural\nnetworks that are now",
    "start": "1635220",
    "end": "1641370"
  },
  {
    "text": "able to outperform a lot of--",
    "start": "1641370",
    "end": "1646900"
  },
  {
    "text": "that were able to\nrecognize and perform a lot of task, some of them\nat the level of humans,",
    "start": "1646900",
    "end": "1653260"
  },
  {
    "text": "so recognizing various\nobject and so on. And one of the aspect of\nthose neural networks,",
    "start": "1653260",
    "end": "1659760"
  },
  {
    "text": "and I'm going to\ntalk about them, is that they require\na lot of information. So you need to teach\nthem the classes",
    "start": "1659760",
    "end": "1667680"
  },
  {
    "text": "you want to distinguish. And they can and need\na lot, a lot of data.",
    "start": "1667680",
    "end": "1674159"
  },
  {
    "text": "So everything we did so\nfar, we are getting that on a couple of thousand images.",
    "start": "1674160",
    "end": "1680350"
  },
  {
    "text": "And that's really not enough\nto even start scratching computational modeling.",
    "start": "1680350",
    "end": "1685919"
  },
  {
    "text": "So with Aditya Khosla,\nwe run recently a new large-scale\nvisual memorability",
    "start": "1685920",
    "end": "1692460"
  },
  {
    "text": "study on Amazon Mechanical\nTurk, but this time getting score for 60,000 photograph.",
    "start": "1692460",
    "end": "1699750"
  },
  {
    "text": "And you have a set of\na sample over here. 60,000.",
    "start": "1699750",
    "end": "1705022"
  },
  {
    "text": "They are all going to be\navailable in a few weeks. The paper is under revision. It's looking good.",
    "start": "1705022",
    "end": "1710970"
  },
  {
    "text": "So as soon as we\nhave a citation, we are going to give away all\nthe data as well as the score",
    "start": "1710970",
    "end": "1716970"
  },
  {
    "text": "and the images and so on. And in this\nexperiment, images were presented for 600\nmilliseconds or shorter time,",
    "start": "1716970",
    "end": "1724210"
  },
  {
    "text": "but they really did\nnot change much. So as a snapshot, because\nthe 60,000 images really",
    "start": "1724210",
    "end": "1732419"
  },
  {
    "text": "cover a lot of type of photo-- faces, event, action, and\neven a graph and so on--",
    "start": "1732420",
    "end": "1739860"
  },
  {
    "text": "well, you either hear\nsome that were highly memorable or forgettable.",
    "start": "1739860",
    "end": "1745049"
  },
  {
    "text": "There's also the website. It's not populated\nyet with many things, but it will be very shortly.",
    "start": "1745050",
    "end": "1752370"
  },
  {
    "text": "And the correlation we\ngot on that data set",
    "start": "1752370",
    "end": "1757980"
  },
  {
    "text": "was pretty high again, 0.68. That was expected. And the paper explain\nthe various split we did.",
    "start": "1757980",
    "end": "1767730"
  },
  {
    "text": "But, again, we find this\nvery high correlation. So we do know that there's\nsomething to model there.",
    "start": "1767730",
    "end": "1774500"
  },
  {
    "text": "And other-- again, a\nvery quick summary. The type of images that seems\nto be the most memorable",
    "start": "1774500",
    "end": "1782080"
  },
  {
    "text": "are the one which have a\nfocus and close settings, that show some dynamics and\nsomething distinctive, unusual,",
    "start": "1782080",
    "end": "1788740"
  },
  {
    "text": "a little different, whereas\nthe less memorable one seems to have no single focus,\ndistant view, static,",
    "start": "1788740",
    "end": "1796120"
  },
  {
    "text": "and more commonalities. All photos, you can still\nfind two images that",
    "start": "1796120",
    "end": "1802120"
  },
  {
    "text": "will be focus and\ndynamics, and one of them will be more memorable\nthan the other",
    "start": "1802120",
    "end": "1807190"
  },
  {
    "text": "because it will have something\nunusual that now our system can capture.",
    "start": "1807190",
    "end": "1814120"
  },
  {
    "text": "So we have this new data set. We have all the memory score. We have the high consistency.",
    "start": "1814120",
    "end": "1820779"
  },
  {
    "text": "How do we even start thinking\nabout the computational model",
    "start": "1820780",
    "end": "1826450"
  },
  {
    "text": "of visual memory\nor memorability? Well, in order to give\nyou a sense of one",
    "start": "1826450",
    "end": "1832750"
  },
  {
    "text": "of the basic we needs,\nin order to even start thinking of a model, I'm going\nto show and run another demo.",
    "start": "1832750",
    "end": "1842059"
  },
  {
    "text": "So in this demo, you're also\ngoing to see some images. And clap your hand whenever\nyou see an image that repeat.",
    "start": "1842060",
    "end": "1848790"
  },
  {
    "text": "OK? Exactly the same\ngame than before. Ready? All right. If everyone play the\ngame, it will be fun.",
    "start": "1848790",
    "end": "1857070"
  },
  {
    "text": "OK. [CLAPPING] ",
    "start": "1857070",
    "end": "1864769"
  },
  {
    "text": "[CLAPPING] A little false alarm. [CLAPPING] False alarm.",
    "start": "1864770",
    "end": "1870181"
  },
  {
    "text": "[CLAPPING] Good. More energy.  [CLAPPING]",
    "start": "1870181",
    "end": "1875660"
  },
  {
    "text": "Good. [CLAPPING] Sorry.",
    "start": "1875660",
    "end": "1881732"
  },
  {
    "text": "[CLAPPING] No",
    "start": "1881732",
    "end": "1886946"
  },
  {
    "text": "[LAUGHTER]  [CLAPPING] No.",
    "start": "1886946",
    "end": "1893299"
  },
  {
    "text": "[CLAPPING] Yes. [CLAPPING] No. AUDIENCE: Too close.",
    "start": "1893300",
    "end": "1898620"
  },
  {
    "text": "[CLAPPING] AUDE OLIVA: No. Yeah, that was-- yes. [CLAPPING]",
    "start": "1898620",
    "end": "1904444"
  },
  {
    "text": "[LAUGHTER] All right. So for the sake of\nthe demo, I put here",
    "start": "1904444",
    "end": "1911710"
  },
  {
    "text": "really images that\nare very different, some you are familiar with. You have a concept.",
    "start": "1911710",
    "end": "1916910"
  },
  {
    "text": "You know what it is. This is a restaurant. This is an alley. This is a stadium, and so on.",
    "start": "1916910",
    "end": "1922760"
  },
  {
    "text": "And some for which either you\ndon't have a specific concept,",
    "start": "1922760",
    "end": "1928730"
  },
  {
    "text": "or you have the same concept-- texture, paintings,\ntexture, texture, texture.",
    "start": "1928730",
    "end": "1933950"
  },
  {
    "text": "And the basic idea\nof memory is you need to recognize, to put a\nunique tag or collection of tag",
    "start": "1933950",
    "end": "1941720"
  },
  {
    "text": "in order to remember\nthat individual image. So the fact that you saw\na collection of texture",
    "start": "1941720",
    "end": "1947710"
  },
  {
    "text": "or paintings or whatever\nyou want to call them, you'll remember that as a group. But to go to the\nindividual memory of one,",
    "start": "1947710",
    "end": "1954950"
  },
  {
    "text": "you're going to need to\nhave a specific concept. And in order to\nremember it, this is going to be an abstraction,\na format, a collection of words,",
    "start": "1954950",
    "end": "1965420"
  },
  {
    "text": "or a coding that make it unique. So you need to\nrecognize to remember,",
    "start": "1965420",
    "end": "1970670"
  },
  {
    "text": "which means that if you\nwant a model of memory which start from the raw image--",
    "start": "1970670",
    "end": "1975840"
  },
  {
    "text": "I'm not in toy world here. I really start from the\nraw image, like the retina.",
    "start": "1975840",
    "end": "1981510"
  },
  {
    "text": "Well, you're going to need\nto build a visual recognition",
    "start": "1981510",
    "end": "1987050"
  },
  {
    "text": "system first. So first you need a model\nthat recognize object",
    "start": "1987050",
    "end": "1992840"
  },
  {
    "text": "and scene and event and so on. And then, from this,\nthere can be a base",
    "start": "1992840",
    "end": "1999020"
  },
  {
    "text": "to start modeling memory. So, fortunately, the\nfield of computer vision",
    "start": "1999020",
    "end": "2006190"
  },
  {
    "text": "made a lot of progress in\nthe past couple of years. So now we do have visual\nrecognition system",
    "start": "2006190",
    "end": "2012732"
  },
  {
    "text": "that works pretty well. I'm going to describe them. We need to first a visual\nrecognition system.",
    "start": "2012732",
    "end": "2020059"
  },
  {
    "text": "All right. So, what does a visual\nrecognition system needs to do? So, well, it's your\nSunday morning.",
    "start": "2020060",
    "end": "2027498"
  },
  {
    "text": "You're going to the\npicnic area, and you're faced with that view. You take a photo. This photo actually\nbecame viral on the web.",
    "start": "2027499",
    "end": "2035779"
  },
  {
    "text": "And here is the state of the\nart of computer vision system. When it comes to\nrecognize the object--",
    "start": "2035780",
    "end": "2041620"
  },
  {
    "text": "I know it's a\ndifferent view, but it works very well for any view-- object recognition\nfor about 1,000",
    "start": "2041620",
    "end": "2049510"
  },
  {
    "text": "object category is reaching\nhuman performances so far.",
    "start": "2049510",
    "end": "2055256"
  },
  {
    "text": "And so this will tell\nyou this is a black bear, there's a bench, a table,\nand so on, and trees",
    "start": "2055256",
    "end": "2061960"
  },
  {
    "text": "in the background. But it's missing the point,\nthat this is a picnic area.",
    "start": "2061960",
    "end": "2068320"
  },
  {
    "text": "So you do need at least\ntwo kind of information",
    "start": "2068320",
    "end": "2073840"
  },
  {
    "text": "in order to reach visual\nscene understanding. You need the scene\nand the context,",
    "start": "2073840",
    "end": "2079899"
  },
  {
    "text": "you need to know the place, and\nyou need to know the object. So, as I said, so\nfar on the challenge",
    "start": "2079900",
    "end": "2087579"
  },
  {
    "text": "that's called the ImageNet\nChallenge in computer vision, computer vision model average\nhuman performances, which",
    "start": "2087580",
    "end": "2094360"
  },
  {
    "text": "is 95% correct on exemplars\nof objects that have never",
    "start": "2094360",
    "end": "2100540"
  },
  {
    "text": "been trained on, a new one,\nfor 1,000 object category. And recently, we basically\npublished a few papers",
    "start": "2100540",
    "end": "2109030"
  },
  {
    "text": "for the other part of visual\nscene understanding, the place and the context. And this is an\noutput of our system.",
    "start": "2109030",
    "end": "2116420"
  },
  {
    "text": "And you can go on the web-- I'm going to give you the\naddress-- and play with it and see the performances\nof recognizing",
    "start": "2116420",
    "end": "2122410"
  },
  {
    "text": "the context and the place. So just to put into context what\nthe field of computer vision",
    "start": "2122410",
    "end": "2131890"
  },
  {
    "text": "have been doing for\nthe past 15 years is, well, the\nnumber of data set,",
    "start": "2131890",
    "end": "2140740"
  },
  {
    "text": "the number of images by data\nset has been increasing, so that there's more\nexemplar to learn from.",
    "start": "2140740",
    "end": "2148160"
  },
  {
    "text": "And, in perspective, you can\nsee that two-years-old kids. Of course, it will depend on\nthe sampling you use in order",
    "start": "2148160",
    "end": "2155380"
  },
  {
    "text": "to have an estimate of the\nnumber of visual information that the retina sees. But it sees much,\nmuch more variety",
    "start": "2155380",
    "end": "2163450"
  },
  {
    "text": "and numbers of visual input. But right now, both ImageNet,\nthat is, a data set of objects,",
    "start": "2163450",
    "end": "2170650"
  },
  {
    "text": "and Places, which is\na data set of scene I'm going to present to you\nnow, have about 10 million label",
    "start": "2170650",
    "end": "2178580"
  },
  {
    "text": "images of many categories. So label means that for the\nplaces, it will tell you,",
    "start": "2178580",
    "end": "2184270"
  },
  {
    "text": "this is a kitchen or this\nis a conference room, and so on for hundred of categories. So 10 million is\nlargely enough to start",
    "start": "2184270",
    "end": "2192220"
  },
  {
    "text": "building very serious\nvisual recognition system, but it's no near\nthe human brain.",
    "start": "2192220",
    "end": "2198610"
  },
  {
    "text": "However, we might\nbe getting there. So how do we even start\nto build a visual scene",
    "start": "2198610",
    "end": "2207220"
  },
  {
    "text": "recognition data set? This is a work we did\nand published in 2010, the Scene Understanding,\nor SUN data",
    "start": "2207220",
    "end": "2213390"
  },
  {
    "text": "set, where we collected the\nwords from the dictionary that",
    "start": "2213390",
    "end": "2218799"
  },
  {
    "text": "correspond to places at\nthe subordinate level-- I'm going to give you example--",
    "start": "2218800",
    "end": "2224020"
  },
  {
    "text": "and then retrieve a lot\nof images from the web. And there was a total of\n900 different categories,",
    "start": "2224020",
    "end": "2232480"
  },
  {
    "text": "and about 400 of them\nhave enough exemplars to build a artificial system.",
    "start": "2232480",
    "end": "2239589"
  },
  {
    "text": "So instead of going and only\nlooking to build images, like to build a data set of\na bedroom and kitchen and so",
    "start": "2239590",
    "end": "2248020"
  },
  {
    "text": "on, what's happening for\nthe human brain is that you have a different environment.",
    "start": "2248020",
    "end": "2255340"
  },
  {
    "text": "You see there's many\nattribute you can put in. And you are forthcoming\nand storytelling and so on.",
    "start": "2255340",
    "end": "2263150"
  },
  {
    "text": "So most of the places,\nit's not only that this is, for instance, a bedroom,\nis that you will go more",
    "start": "2263150",
    "end": "2268600"
  },
  {
    "text": "to a student bedroom or-- Well, I think those\nare student bedroom two doors from my colleague.",
    "start": "2268600",
    "end": "2275710"
  },
  {
    "text": "So there are many\ntype of adjective that we can use in order\nto retrieve images that",
    "start": "2275710",
    "end": "2281380"
  },
  {
    "text": "will give us a larger panorama\nof the type of concept",
    "start": "2281380",
    "end": "2288130"
  },
  {
    "text": "that are used by the\nhuman brain in order to recognize environment. So a simple bedroom.",
    "start": "2288130",
    "end": "2295040"
  },
  {
    "text": "The tag were put automatically. Superior bedroom. Senior bedroom.",
    "start": "2295040",
    "end": "2301750"
  },
  {
    "text": "Colorful bedroom. Hotel bedroom. And so on and so on. So that was the\nretrieval we did,",
    "start": "2301750",
    "end": "2307810"
  },
  {
    "text": "which means that now,\nfor every category there is also a tag in term of\nthe subtype of environment",
    "start": "2307810",
    "end": "2317830"
  },
  {
    "text": "this can be. Messy bedroom. And a couple of years later,\n80 million images later,",
    "start": "2317830",
    "end": "2325760"
  },
  {
    "text": "and a lot of Amazon\nMechanical Turk experiment, we are launching this\nweek the Places2 data set,",
    "start": "2325760",
    "end": "2334270"
  },
  {
    "text": "with 460 categories, different\ncategories of environment, and 10 million images label.",
    "start": "2334270",
    "end": "2341530"
  },
  {
    "text": "So this is a larger data\nset of label images, with a label to be used right\naway for artificial system",
    "start": "2341530",
    "end": "2349850"
  },
  {
    "text": "learning, deep\nlearning, and so on. So here is just a snapshot\nof the differences",
    "start": "2349850",
    "end": "2357460"
  },
  {
    "text": "of the places in term of the\nnumber of exemplars with other a large data set.",
    "start": "2357460",
    "end": "2365150"
  },
  {
    "text": "So the Places data\nset is actually",
    "start": "2365150",
    "end": "2370990"
  },
  {
    "text": "part of the ImageNet\nchallenge this year, which means that you\ncan go to ImageNet",
    "start": "2370990",
    "end": "2378175"
  },
  {
    "text": "and register for the challenge\nand download right now, tonight, eight million\nimages of places",
    "start": "2378175",
    "end": "2386560"
  },
  {
    "text": "to use for the learning\nof your neural networks, as well as of a set that\nwill be used for the testing,",
    "start": "2386560",
    "end": "2395160"
  },
  {
    "text": "and participate\nto the challenge. So this was launch last\nweek, and the website",
    "start": "2395160",
    "end": "2402950"
  },
  {
    "text": "associated with Places\nwill be launched this week. And we decided to just give this\naway to everyone right away.",
    "start": "2402950",
    "end": "2411460"
  },
  {
    "text": "We are finishing\nup the paper now. It will be an archive paper. No time to wait for\nmonth and month.",
    "start": "2411460",
    "end": "2419260"
  },
  {
    "text": "This is a data set that can\nbe used by a lot of people to make progress fast.",
    "start": "2419260",
    "end": "2424313"
  },
  {
    "text": "And so that's what we are doing. So, as I said, the\ncomputer vision model",
    "start": "2424313",
    "end": "2432190"
  },
  {
    "text": "now require, if you use deep\nlearning, a lot of data. And we hope that\nwith this data set,",
    "start": "2432190",
    "end": "2440109"
  },
  {
    "text": "fast progress are\ngoing to be made. So what we specifically did is\nusing the AlexNet deep learning",
    "start": "2440110",
    "end": "2448750"
  },
  {
    "text": "architecture-- If you don't know\nwhat this is, I can tell you later how\nto basically access to it with the paper on so on.",
    "start": "2448750",
    "end": "2455440"
  },
  {
    "text": "This is not my model. This is a model put\ntogether by Geoffrey Hinton and collaborator\na few years ago.",
    "start": "2455440",
    "end": "2461930"
  },
  {
    "text": "And you can download the\nmodel or download the code and re-train. ",
    "start": "2461930",
    "end": "2467350"
  },
  {
    "text": "So neural net now\nbasically are based on the collection\nof operation that",
    "start": "2467350",
    "end": "2473610"
  },
  {
    "text": "are call layers, convolution,\nnormalization, simple image processing operation that\nyou do in a sequence.",
    "start": "2473610",
    "end": "2480760"
  },
  {
    "text": "You do it one time, then a\nsecond and third and so on. And then you have those\nmulti-layers models.",
    "start": "2480760",
    "end": "2486910"
  },
  {
    "text": "And the number of layers is\nstill a question of research. How does layer\ncorrespond to the brain?",
    "start": "2486910",
    "end": "2492730"
  },
  {
    "text": "I'm going to say a\nlittle bit about that. And using this simple--",
    "start": "2492730",
    "end": "2500060"
  },
  {
    "text": "well, this AlexNet model,\nwe built a scene recognition",
    "start": "2500060",
    "end": "2505985"
  },
  {
    "text": "system. And now you can go to\nplaces.csail.mit.edu with a smartphone will\nwork, will take a photo.",
    "start": "2505985",
    "end": "2514430"
  },
  {
    "text": "And it should tell you\nthe type of environment the photo represent.",
    "start": "2514430",
    "end": "2519620"
  },
  {
    "text": "It will give you\nseveral possibilities, because basically\nenvironment are ambiguous.",
    "start": "2519620",
    "end": "2526069"
  },
  {
    "text": "They can be of different type. So I don't know if you can read. Let me read a few. The first one, it says,\nrestaurant, coffee shop,",
    "start": "2526070",
    "end": "2533300"
  },
  {
    "text": "cafeteria, food court,\nrestaurant patio. I guess they all fit.",
    "start": "2533300",
    "end": "2538430"
  },
  {
    "text": "The second one, parking\nlot and driveway. The third one, conference room,\ndining room, banquet hall,",
    "start": "2538430",
    "end": "2545000"
  },
  {
    "text": "classroom. That was a difficult one. And the fourth environment\nis patio, restaurant patio,",
    "start": "2545000",
    "end": "2551240"
  },
  {
    "text": "or restaurant. So if you go there, you\ncan also give feedback",
    "start": "2551240",
    "end": "2557720"
  },
  {
    "text": "if one of the label\nmatch the environment that you're looking at.",
    "start": "2557720",
    "end": "2563000"
  },
  {
    "text": "And it should be\nabove 80% correct. And this model use 1.5 million\nimages and 200 categories.",
    "start": "2563000",
    "end": "2570890"
  },
  {
    "text": "So soon with a great-- we hope that things will be even\nmore interesting and accurate.",
    "start": "2570890",
    "end": "2579310"
  },
  {
    "text": "And I took this morning a\ncouple of photo at breakfast. So you may all recognize\nthe scenery here.",
    "start": "2579310",
    "end": "2586920"
  },
  {
    "text": "So from the breakfast\narea looking outside, it's an outdoor harbor,\ndock, boat deck.",
    "start": "2586920",
    "end": "2594680"
  },
  {
    "text": "Yeah, it could be\nactually on a boat deck looking at the harbor. And otherwise,\nthe breakfast area",
    "start": "2594680",
    "end": "2602359"
  },
  {
    "text": "was restaurant, cafeteria,\ncoffee shop, food court, or bar. All those, again, fits.",
    "start": "2602360",
    "end": "2608930"
  },
  {
    "text": "So those model now\nworks very, very well. So why? Well, let me tell you why.",
    "start": "2608930",
    "end": "2614789"
  },
  {
    "text": "So those neural networks,\nyou can go to any layers",
    "start": "2614790",
    "end": "2620990"
  },
  {
    "text": "and open them and look at what\nevery single artificial neuron",
    "start": "2620990",
    "end": "2629450"
  },
  {
    "text": "do. So what we call\nthe receptive field of every single\nunit in the layer",
    "start": "2629450",
    "end": "2634820"
  },
  {
    "text": "one, the layer two, the\nlayer three, and so on. So the first the layer--",
    "start": "2634820",
    "end": "2640634"
  },
  {
    "text": "here, four layers are shown-- basically learn simple features,\ncontours and simple texture.",
    "start": "2640634",
    "end": "2650690"
  },
  {
    "text": "That's called pool1. And those looks like the type of\nresponses of the visual cells,",
    "start": "2650690",
    "end": "2660079"
  },
  {
    "text": "and possibly V1, V2. I'm going to tell\nmore about this. And as you go higher\nup in the layers,",
    "start": "2660080",
    "end": "2668060"
  },
  {
    "text": "then you start having some\ntexture, some patches, that make more sense. And higher up in the layers,\nlike layer number five,",
    "start": "2668060",
    "end": "2676599"
  },
  {
    "text": "then you start having\nartificial receptive field that",
    "start": "2676600",
    "end": "2682090"
  },
  {
    "text": "are specific to part of\nobject, part of scene, or an entire object by itself.",
    "start": "2682090",
    "end": "2687769"
  },
  {
    "text": "Like we can see here some\nkind of [INAUDIBLE] coffee, as well as the tower and so on.",
    "start": "2687770",
    "end": "2695330"
  },
  {
    "text": "So it seems that the system are\nable to recognize environment of object.",
    "start": "2695330",
    "end": "2701520"
  },
  {
    "text": "But what they learn are\nthe part and the object that the environment contain. And I'm going to show\nexample of those.",
    "start": "2701520",
    "end": "2708130"
  },
  {
    "text": "So jumping, just giving you\na result in neuroscience.",
    "start": "2708130",
    "end": "2715049"
  },
  {
    "text": "And so there's a lot of debate\nout there about, OK, well, there's those model\nwith different layers.",
    "start": "2715050",
    "end": "2720930"
  },
  {
    "text": "And you have different\nmodels out there. To which extent they correspond\nto the visual hierarchy",
    "start": "2720930",
    "end": "2727520"
  },
  {
    "text": "of the human brain? Well, first, the\ncomputational model were inspire by the visual\nhierarchy, the V1, V2, V4,",
    "start": "2727520",
    "end": "2738319"
  },
  {
    "text": "and [INAUDIBLE]\nand so on, knowing that more complex features\nare built over time and space.",
    "start": "2738320",
    "end": "2747920"
  },
  {
    "text": "So what you can also do\nis run through a network and run in an fMRI\nexperiment the same image,",
    "start": "2747920",
    "end": "2757549"
  },
  {
    "text": "and then look at the correlation\nexisting between the responses of the cells, let's\nsay in layer one,",
    "start": "2757550",
    "end": "2765290"
  },
  {
    "text": "and the responses you may\nhave on the human brain in different part of the brain.",
    "start": "2765290",
    "end": "2770339"
  },
  {
    "text": "And what we find is that the\nlayer one will correspond more, will have a higher\ncorrelation, with responses",
    "start": "2770340",
    "end": "2778069"
  },
  {
    "text": "in the visual area,\nliterally V1, V2. And as you move up\nthrough the layers,",
    "start": "2778070",
    "end": "2785900"
  },
  {
    "text": "then there is correlation,\nhigher [INAUDIBLE] correlation, with part of the ventral and\nthe parietal part of the brain.",
    "start": "2785900",
    "end": "2794340"
  },
  {
    "text": "And I know you had the lecture\nby Jim DiCarlo that actually must have explained this.",
    "start": "2794340",
    "end": "2801740"
  },
  {
    "text": "So Jim DiCarlo team did it, Jack\nGallant as well in Berkeley. And we also did\nit with other type",
    "start": "2801740",
    "end": "2809140"
  },
  {
    "text": "of images and other network,\nand all the result really corroborate each other\nwith this nice correlation",
    "start": "2809140",
    "end": "2817360"
  },
  {
    "text": "between low to high visual\nareas between the brain,",
    "start": "2817360",
    "end": "2822970"
  },
  {
    "text": "the human brain, and\nthose multi-layers model. All right. Let me show you some\nof the receptive",
    "start": "2822970",
    "end": "2829809"
  },
  {
    "text": "field, the artificial\nreceptive field that we find in\nthe higher layers. So this network was trained\nfor scene categorization.",
    "start": "2829810",
    "end": "2839990"
  },
  {
    "text": "So the only thing\nthat this network, the one we are using\nhere, learn was to discriminate between, in\nthis case, 200 categories--",
    "start": "2839990",
    "end": "2849940"
  },
  {
    "text": "the kitchen, the bedroom,\nthe bathroom, the alley, the living room, the\nforest, and so on and so on.",
    "start": "2849940",
    "end": "2855890"
  },
  {
    "text": "200 of those. So that's the task. What the network\nlearn and what we",
    "start": "2855890",
    "end": "2862960"
  },
  {
    "text": "observe is that object\ndiscriminant and diagnostical information between\nthose category",
    "start": "2862960",
    "end": "2869640"
  },
  {
    "text": "form the emerging representation\nthat are automatically, naturally learn by the networks.",
    "start": "2869640",
    "end": "2875950"
  },
  {
    "text": "So the network has\nnever learned a wheel, but the representation\nemerge, as you can see here.",
    "start": "2875950",
    "end": "2884839"
  },
  {
    "text": "So this is one\nartificial neurone.",
    "start": "2884840",
    "end": "2889920"
  },
  {
    "text": "And it is receptive\nfield and its responses, the highest response it got\nfor a collection of images.",
    "start": "2889920",
    "end": "2897880"
  },
  {
    "text": "And as you can see, those\nhigher pool5 receptive field are more independent\nto the location.",
    "start": "2897880",
    "end": "2904779"
  },
  {
    "text": "They are built that way. But the network never\nlearn the parts.",
    "start": "2904780",
    "end": "2909850"
  },
  {
    "text": "This is something\nthat emerged naturally by learning different\nenvironment. The other thing that's very\ninteresting in this model, when",
    "start": "2909850",
    "end": "2916720"
  },
  {
    "text": "you can open up and look at\nthe receptive field using various method, here is one,\nis, well, this model has never",
    "start": "2916720",
    "end": "2924460"
  },
  {
    "text": "learned the notion\nof shape or object. So it's going to\nbasically become",
    "start": "2924460",
    "end": "2931420"
  },
  {
    "text": "sensitive to discriminant\nand diagnostic information. So you have this unit that is\ndiscriminant to the bottom part",
    "start": "2931420",
    "end": "2939820"
  },
  {
    "text": "of either the legs of\nanimate, or even you can see the trees over there. So this is a unit.",
    "start": "2939820",
    "end": "2945790"
  },
  {
    "text": "It seems that it was needed in\norder to classify environment to have units that we might\nnot have a word for it.",
    "start": "2945790",
    "end": "2954520"
  },
  {
    "text": "But the human\nbrain might as well have many of those unit\nthat do not correspond",
    "start": "2954520",
    "end": "2959690"
  },
  {
    "text": "to necessarily a word. So, basically,\nwith this model you can have a lot of new object\nemerging that you might not",
    "start": "2959690",
    "end": "2967450"
  },
  {
    "text": "have thought of, but they\nbecome parts of the code needed in order to identify\nan environment or an object.",
    "start": "2967450",
    "end": "2975590"
  },
  {
    "text": "So we also have another\nunit for this bottom parts of a collection of chairs. We also have chair,\nof course, showing up.",
    "start": "2975590",
    "end": "2983110"
  },
  {
    "text": "Faces. The model never learned faces. Only learn kitchen,\nbathroom, street.",
    "start": "2983110",
    "end": "2989290"
  },
  {
    "text": "We have several unit\nemerging for faces. Why? Because those are\ncorrelated with a collection",
    "start": "2989290",
    "end": "2996190"
  },
  {
    "text": "of environment. Then, entire object\nshapes, like bed,",
    "start": "2996190",
    "end": "3001349"
  },
  {
    "text": "very diagnostic of a\nbedroom in this case. So that will be a unit that\nis very, very specific.",
    "start": "3001350",
    "end": "3009130"
  },
  {
    "text": "That would be really\nonly for beds, that one. And then, others\nlike lamps and so on.",
    "start": "3009130",
    "end": "3017970"
  },
  {
    "text": "There's thousand\nand thousand here. Another unit never\nlearned, screen monitors.",
    "start": "3017970",
    "end": "3024720"
  },
  {
    "text": "And here is specific unit\nfor that that emerge. Also, collection\nof object or space,",
    "start": "3024720",
    "end": "3032160"
  },
  {
    "text": "collection of chairs over here. The network found that this\nis a discriminant information",
    "start": "3032160",
    "end": "3039660"
  },
  {
    "text": "to classify environment, crowds. It's a very interesting\nunit because it's",
    "start": "3039660",
    "end": "3045030"
  },
  {
    "text": "really independent of the\nlocation, as well as basically",
    "start": "3045030",
    "end": "3050250"
  },
  {
    "text": "the number of people and if\nthey are closer or further away. But it does capture\nthis notion of crowd.",
    "start": "3050250",
    "end": "3056490"
  },
  {
    "text": "So the model doesn't\nhave the word crowd. So it has never known the crowd. It's one of the\nunit emerging that",
    "start": "3056490",
    "end": "3063299"
  },
  {
    "text": "now can be used as\nan object detector to enhance the recognition of\nwhat's going on in the scene.",
    "start": "3063300",
    "end": "3068970"
  },
  {
    "text": "So this is an ice skating\narea, and there is a crowd. And also unit that are\nmore specific to space",
    "start": "3068970",
    "end": "3078380"
  },
  {
    "text": "and useful for\nnavigation, for instance. We have many of those. So in that case, just the\nfact that there is lamps up",
    "start": "3078380",
    "end": "3090090"
  },
  {
    "text": "or perspective,\nso we have a unit like this specific to this.",
    "start": "3090090",
    "end": "3096030"
  },
  {
    "text": "So it's not the only\nobject as physical object. There's also a\ncollection of unit that are related to spatial\nlayout and geometry that",
    "start": "3096030",
    "end": "3105130"
  },
  {
    "text": "are also discriminant\nfor environment. And many, many other\nthat are showing up.",
    "start": "3105130",
    "end": "3112080"
  },
  {
    "text": "So those object\ndetector naturally emerge inside this\nkind of network trained for scene understanding.",
    "start": "3112080",
    "end": "3118769"
  },
  {
    "text": "So now I only have a couple of\nminutes to wrap up, 20 minutes, so I'm going to just give you\nthe hint of the next part.",
    "start": "3118770",
    "end": "3129670"
  },
  {
    "text": "So with the Places challenge\nthat is starting this week,",
    "start": "3129670",
    "end": "3135480"
  },
  {
    "text": "certainly in less than a year\nthe computational vision model",
    "start": "3135480",
    "end": "3140500"
  },
  {
    "text": "of scene recognition\nare going to be very close to human performances. And then there's a long way\nto go and many more things",
    "start": "3140500",
    "end": "3150359"
  },
  {
    "text": "to match, like the error. So know that the\nerror look alike or when a category can\nhave many type of object",
    "start": "3150360",
    "end": "3156450"
  },
  {
    "text": "or what can happen next. So you can really expand. But let's say we\ncan consider now that we have a base\nof visual recognition",
    "start": "3156450",
    "end": "3164250"
  },
  {
    "text": "into a model that works pretty\nwell at the level of human, or close enough, or\nwill be close enough.",
    "start": "3164250",
    "end": "3172140"
  },
  {
    "text": "So, now that we have that,\nwe can add the memory module. How to add the\nmemorability module",
    "start": "3172140",
    "end": "3179190"
  },
  {
    "text": "is really open in the air. There's many ways to do. So we just did it one way, to\nhave a ground very first model",
    "start": "3179190",
    "end": "3188270"
  },
  {
    "text": "of visual memorability\nat the level of human. And this is going to be out--\nthe paper is in revision--",
    "start": "3188270",
    "end": "3195870"
  },
  {
    "text": "in a few weeks. And you're going to be able to\ndownload the images, the model, and so on. Again, this is model number one,\nand we hope that then a better",
    "start": "3195870",
    "end": "3203130"
  },
  {
    "text": "model can be done. So we went for the\nOccam razor approach.",
    "start": "3203130",
    "end": "3208920"
  },
  {
    "text": "The most simple one given\nthe model is we took AlexNet,",
    "start": "3208920",
    "end": "3214619"
  },
  {
    "text": "we feed AlexNet with\nboth ImageNet and Places. Because all the images that\nare memorable or unforgettable,",
    "start": "3214620",
    "end": "3221122"
  },
  {
    "text": "they might have object,\nthey might have places. OK, so let's put the two\ntogether so we have more power.",
    "start": "3221122",
    "end": "3226290"
  },
  {
    "text": "We train the model, so we have\nthe visual recognition model. We do know that those\nunits make sense.",
    "start": "3226290",
    "end": "3233819"
  },
  {
    "text": "They recognize that\nthis is a kitchen. And we do know why,\nbecause we have the parts. So that's a classical\nstandard AlexNet.",
    "start": "3233820",
    "end": "3242160"
  },
  {
    "text": "The output is scene and\nobject categorization, so we are still in\ncategorization land.",
    "start": "3242160",
    "end": "3247785"
  },
  {
    "text": "And we can remove\nthe last layer. And then this is a procedure\nthat has been well published",
    "start": "3247785",
    "end": "3254609"
  },
  {
    "text": "in computer vision\nand computer science, this notion of fine tuning\nand back propagation.",
    "start": "3254610",
    "end": "3260610"
  },
  {
    "text": "So you use the\nnetwork on learning that are learn to\nrecognize places, and you finely tune\nand adopt the feature",
    "start": "3260610",
    "end": "3267840"
  },
  {
    "text": "so that the task has change. So the task was recognition. And now, for the\nnetwork, at the end",
    "start": "3267840",
    "end": "3273720"
  },
  {
    "text": "there is a new task for\nthat network that has learn all those object and scene.",
    "start": "3273720",
    "end": "3280260"
  },
  {
    "text": "And the new task is now to\nlearn that those element are of high, medium, or\nlow memorability,",
    "start": "3280260",
    "end": "3287700"
  },
  {
    "text": "which is a continuous value. So by doing this,\nwe have now a model",
    "start": "3287700",
    "end": "3294300"
  },
  {
    "text": "where we give it a\nnew image, and it's going to output a\nscore between 0 and 1.",
    "start": "3294300",
    "end": "3302390"
  },
  {
    "text": "And the human to human I'll\nshow you is 0.68 correlation. The human to computer\nis 0.65, which mean now",
    "start": "3302390",
    "end": "3310620"
  },
  {
    "text": "that there is a first\nmodel that can basically",
    "start": "3310620",
    "end": "3316950"
  },
  {
    "text": "replicate human memorability\nof a group nearly at",
    "start": "3316950",
    "end": "3322500"
  },
  {
    "text": "the level of a human. And we use the data\nset of 60,000 image",
    "start": "3322500",
    "end": "3328590"
  },
  {
    "text": "to finely tune the\nrecognition model, as well as test with images\nthat this has not shown.",
    "start": "3328590",
    "end": "3335770"
  },
  {
    "text": "And because we can open up this\nnew network of memorability",
    "start": "3335770",
    "end": "3342360"
  },
  {
    "text": "and look also now at the\nreceptive field of the neuron that are related to high\nor low memorability image--",
    "start": "3342360",
    "end": "3351600"
  },
  {
    "text": "and we will publish every single\nreceptive field on the web as well with this paper--",
    "start": "3351600",
    "end": "3358420"
  },
  {
    "text": "and thus now we can see\nthe unit that are related, this higher level information\nof object or space or parts",
    "start": "3358420",
    "end": "3369270"
  },
  {
    "text": "and so on that is\nrelated with images that are highly memorable\nin green, strong positive,",
    "start": "3369270",
    "end": "3374940"
  },
  {
    "text": "or highly forgettable. And we find, again, that\nif you have animate object",
    "start": "3374940",
    "end": "3381330"
  },
  {
    "text": "or kind of object,\nroundish object, and so on, you can go\n[INAUDIBLE] those will make your images more memorable.",
    "start": "3381330",
    "end": "3389340"
  },
  {
    "text": "And so our last part\nis, so now that we do have this model that\nspill out responses",
    "start": "3389340",
    "end": "3396910"
  },
  {
    "text": "at the level of human and\nindicate the parts that",
    "start": "3396910",
    "end": "3402470"
  },
  {
    "text": "are related to higher memory,\nlower memory, at least as a guideline, then we can\ngo back to a given image",
    "start": "3402470",
    "end": "3411560"
  },
  {
    "text": "and emphasize the\npart that correspond to the high memorability\nreceptive field",
    "start": "3411560",
    "end": "3418210"
  },
  {
    "text": "and de-emphasize the\npart corresponding to the forgettable part\nof the receptive field.",
    "start": "3418210",
    "end": "3426680"
  },
  {
    "text": "And this give you\nimages on the right like that that\nhave been weighted by the element\nthat are memorable",
    "start": "3426680",
    "end": "3432830"
  },
  {
    "text": "and the element that\nare forgettable. So maybe here it doesn't matter\nthat the ground is forgettable.",
    "start": "3432830",
    "end": "3438359"
  },
  {
    "text": "Here, the part I\nlike to emphasize are the memorable one.",
    "start": "3438360",
    "end": "3443390"
  },
  {
    "text": "But, for instance, in this\nimagine we have two person. And, well, she\njust happened to be",
    "start": "3443390",
    "end": "3451550"
  },
  {
    "text": "more forgettable in this case,\nwhich will make a perfect CIA agent, if we think about it.",
    "start": "3451550",
    "end": "3458270"
  },
  {
    "text": "And we did tested those. So then, for a values\npart of navigation,",
    "start": "3458270",
    "end": "3465320"
  },
  {
    "text": "I mean values scene, we do\nfind that the element of exit",
    "start": "3465320",
    "end": "3471260"
  },
  {
    "text": "or entrance, so where\nthere's basically path and a 3D structure\nfor navigation,",
    "start": "3471260",
    "end": "3477340"
  },
  {
    "text": "tend also to be more memorable. So those are highlighted\nin those images.",
    "start": "3477340",
    "end": "3482510"
  },
  {
    "text": "Another example,\nwhere the kids will be more memorable than the\nfeatures of the person.",
    "start": "3482510",
    "end": "3488890"
  },
  {
    "text": "And I don't-- Well, I'm not an expert in game. You can explain that one to me.",
    "start": "3488890",
    "end": "3494480"
  },
  {
    "text": "So I have to stop\nbecause we need a break, and I might need to talk.",
    "start": "3494480",
    "end": "3501420"
  },
  {
    "text": "However, here is a vision\nof where we are going.",
    "start": "3501420",
    "end": "3507410"
  },
  {
    "text": "And maybe other people\nwill be interested to go on this adventure.",
    "start": "3507410",
    "end": "3513350"
  },
  {
    "text": "Because it's really,\nreally just the beginning. But if you now can\nhave a model that",
    "start": "3513350",
    "end": "3519410"
  },
  {
    "text": "at the level of a group of\nhuman predict which image are memorable, and\nas well, also match",
    "start": "3519410",
    "end": "3527000"
  },
  {
    "text": "part of the visual region and\neven the higher level object recognition, then you can start\nhaving this similarity going on",
    "start": "3527000",
    "end": "3536720"
  },
  {
    "text": "in this study between the\nhuman brain and all the part, from perception to memory\nand computational model,",
    "start": "3536720",
    "end": "3545180"
  },
  {
    "text": "to characterize what the\ncomputation underlying those particular region.",
    "start": "3545180",
    "end": "3551780"
  },
  {
    "text": "Because now you have model zero. I'm not saying that the\nmodel I'm showing to you",
    "start": "3551780",
    "end": "3557540"
  },
  {
    "text": "is a model that\nimitate the brain. But it's a model\nzero, and now it",
    "start": "3557540",
    "end": "3563090"
  },
  {
    "text": "can be tuned to better\nlearn the calculation that are done at different\nlevel along the visual",
    "start": "3563090",
    "end": "3570110"
  },
  {
    "text": "to the memory hierarchy in order\nto characterize visual memory.",
    "start": "3570110",
    "end": "3576340"
  },
  {
    "start": "3576340",
    "end": "3592265"
  }
]
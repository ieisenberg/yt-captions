[
  {
    "start": "0",
    "end": "150000"
  },
  {
    "text": " ",
    "start": "0",
    "end": "810"
  },
  {
    "text": "Hi.",
    "start": "810",
    "end": "1620"
  },
  {
    "text": "In this problem, we're going to\nbe dealing with a variation",
    "start": "1620",
    "end": "5190"
  },
  {
    "text": "of the usual coin-flipping\nproblem.",
    "start": "5190",
    "end": "7710"
  },
  {
    "text": "But in this case, the bias\nitself of the coin",
    "start": "7710",
    "end": "11830"
  },
  {
    "text": "is going to be random.",
    "start": "11830",
    "end": "13410"
  },
  {
    "text": "So you could think of it as, you\ndon't even know what the",
    "start": "13410",
    "end": "16460"
  },
  {
    "text": "probability of heads\nfor the coin is.",
    "start": "16460",
    "end": "18929"
  },
  {
    "text": "So as usual, we're still taking\none coin and we're",
    "start": "18930",
    "end": "22150"
  },
  {
    "text": "flipping it n times.",
    "start": "22150",
    "end": "23260"
  },
  {
    "text": "But the difference here is that\nthe bias is because it",
    "start": "23260",
    "end": "29340"
  },
  {
    "text": "was random variable Q. And\nwe're told that the",
    "start": "29340",
    "end": "32758"
  },
  {
    "text": "expectation of this bias is some\nmu and that the variance",
    "start": "32759",
    "end": "37390"
  },
  {
    "text": "of the bias is some sigma\nsquared, which",
    "start": "37390",
    "end": "40000"
  },
  {
    "text": "we're told is positive.",
    "start": "40000",
    "end": "42810"
  },
  {
    "text": "And what we're going to be\nasked is find a bunch of",
    "start": "42810",
    "end": "45930"
  },
  {
    "text": "different expectations,\ncovariances, and variances.",
    "start": "45930",
    "end": "50620"
  },
  {
    "text": "And we'll see that this problem\ngives us some good",
    "start": "50620",
    "end": "52969"
  },
  {
    "text": "exercise in a few concepts, a\nlot of iterated expectations,",
    "start": "52970",
    "end": "57050"
  },
  {
    "text": "which, again, tells you that\nwhen you take the expectation",
    "start": "57050",
    "end": "61265"
  },
  {
    "text": "of a conditional expectation,\nit's just the expectation of",
    "start": "61265",
    "end": "65729"
  },
  {
    "text": "the inner random variable.",
    "start": "65730",
    "end": "69350"
  },
  {
    "text": "The covariance of two random\nvariables is just the",
    "start": "69350",
    "end": "71790"
  },
  {
    "text": "expectation of the product\nminus the product of the",
    "start": "71790",
    "end": "73890"
  },
  {
    "text": "expectations.",
    "start": "73890",
    "end": "75320"
  },
  {
    "text": "Law of total variance is the\nexpectation of a variance, of",
    "start": "75320",
    "end": "79729"
  },
  {
    "text": "a conditional variance plus the\nvariance of a conditional",
    "start": "79730",
    "end": "82050"
  },
  {
    "text": "expectation.",
    "start": "82050",
    "end": "83800"
  },
  {
    "text": "And the last thing, of course,\nwe're dealing with a bunch of",
    "start": "83800",
    "end": "86090"
  },
  {
    "text": "Bernoulli random variables,\ncoin flips.",
    "start": "86090",
    "end": "88210"
  },
  {
    "text": "So as a reminder, for a\nBernoulli random variable, if",
    "start": "88210",
    "end": "91000"
  },
  {
    "text": "you know what the bias is, it's\nsome known quantity p,",
    "start": "91000",
    "end": "95770"
  },
  {
    "text": "then the expectation of the\nBernoulii is just p, and the",
    "start": "95770",
    "end": "98979"
  },
  {
    "text": "variance of the Bernoulli\nis p times 1 minus p.",
    "start": "98980",
    "end": "103260"
  },
  {
    "text": "So let's get started.",
    "start": "103260",
    "end": "104740"
  },
  {
    "text": "The problem tells us that we're\ngoing to define some",
    "start": "104740",
    "end": "107079"
  },
  {
    "text": "random variables.",
    "start": "107080",
    "end": "108100"
  },
  {
    "text": "So xi is going to be a Bernoulli\nrandom variable for",
    "start": "108100",
    "end": "112650"
  },
  {
    "text": "the i coin flip.",
    "start": "112650",
    "end": "113900"
  },
  {
    "text": " ",
    "start": "113900",
    "end": "116830"
  },
  {
    "text": "So xi is going to be 1 if the i\ncoin flip was heads and 0 if",
    "start": "116830",
    "end": "122160"
  },
  {
    "text": "it was tails.",
    "start": "122160",
    "end": "123390"
  },
  {
    "text": "And one very important thing\nthat the problem states is",
    "start": "123390",
    "end": "126360"
  },
  {
    "text": "that conditional on Q, the\nrandom bias, so if we know",
    "start": "126360",
    "end": "130919"
  },
  {
    "text": "what the random bias is, then\nall the coin flips are",
    "start": "130919",
    "end": "137120"
  },
  {
    "text": "independent.",
    "start": "137120",
    "end": "138155"
  },
  {
    "text": "And that's going to be important\nfor us when we",
    "start": "138155",
    "end": "140630"
  },
  {
    "text": "calculate all these values.",
    "start": "140630",
    "end": "143580"
  },
  {
    "text": "OK, so the first thing that we\nneed to calculate is the",
    "start": "143580",
    "end": "148250"
  },
  {
    "text": "expectation of each of these\nindividual Bernoulli random",
    "start": "148250",
    "end": "151465"
  },
  {
    "start": "150000",
    "end": "250000"
  },
  {
    "text": "variables, xi.",
    "start": "151465",
    "end": "153271"
  },
  {
    "text": "So how do we go about\ncalculating what this is?",
    "start": "153271",
    "end": "155959"
  },
  {
    "text": "Well, the problem\ngives us a int.",
    "start": "155960",
    "end": "158210"
  },
  {
    "text": "It tells us to try using the law\nof iterated expectations.",
    "start": "158210",
    "end": "161240"
  },
  {
    "text": "But in order to use it, you need\nto figure out what you",
    "start": "161240",
    "end": "164040"
  },
  {
    "text": "need the condition on.",
    "start": "164040",
    "end": "165280"
  },
  {
    "text": "What this y?",
    "start": "165280",
    "end": "166940"
  },
  {
    "text": "What takes place in y?",
    "start": "166940",
    "end": "168640"
  },
  {
    "text": "And in this case, a good\ncandidate for what you",
    "start": "168640",
    "end": "173910"
  },
  {
    "text": "condition on would be\nthe bias, the Q that",
    "start": "173910",
    "end": "178070"
  },
  {
    "text": "we're unsure about.",
    "start": "178070",
    "end": "179310"
  },
  {
    "text": "So let's try doing that\nand see what we get.",
    "start": "179310",
    "end": "183959"
  },
  {
    "text": "So we write out the law of\niterated expectations with Q.",
    "start": "183960",
    "end": "189790"
  },
  {
    "text": "So now hopefully, we can\nsimplify it with this",
    "start": "189790",
    "end": "194110"
  },
  {
    "text": "inter-conditional\nexpectation is.",
    "start": "194110",
    "end": "196100"
  },
  {
    "text": "Well, what is it really?",
    "start": "196100",
    "end": "197250"
  },
  {
    "text": "It's saying, given what Q is,\nwhat is the expectation of",
    "start": "197250",
    "end": "202620"
  },
  {
    "text": "this Bernoulli random\ninterval xi?",
    "start": "202620",
    "end": "205330"
  },
  {
    "text": "Well, we know that if we knew\nwhat the bias was, then the",
    "start": "205330",
    "end": "211500"
  },
  {
    "text": "expectation is just\nthe bias itself.",
    "start": "211500",
    "end": "213690"
  },
  {
    "text": "But in this case, the\nbias is random.",
    "start": "213690",
    "end": "216120"
  },
  {
    "text": "But remember a conditional\nexpectation is",
    "start": "216120",
    "end": "218209"
  },
  {
    "text": "still a random variable.",
    "start": "218210",
    "end": "219510"
  },
  {
    "text": "And so in this case, this\nactually just simplifies into",
    "start": "219510",
    "end": "224810"
  },
  {
    "text": "Q. So whatever the bias is, the\nexpectation is just equal",
    "start": "224810",
    "end": "231390"
  },
  {
    "text": "to the bias.",
    "start": "231390",
    "end": "233830"
  },
  {
    "text": "And so that's what\nit tells us.",
    "start": "233830",
    "end": "236590"
  },
  {
    "text": "And this part is easy because\nwe're given that the",
    "start": "236590",
    "end": "241590"
  },
  {
    "text": "expectation of q is mu.",
    "start": "241590",
    "end": "245290"
  },
  {
    "text": "And then the problem also\ndefines the random variable x.",
    "start": "245290",
    "end": "249681"
  },
  {
    "text": "X is the total number of heads\nwithin the n tosses.",
    "start": "249682",
    "end": "253120"
  },
  {
    "start": "250000",
    "end": "330000"
  },
  {
    "text": "Or you can think of it as a sum\nof all these individual xi",
    "start": "253120",
    "end": "261708"
  },
  {
    "text": "Bernoulli random variables.",
    "start": "261709",
    "end": "264290"
  },
  {
    "text": "And now, what can\nwe do with this?",
    "start": "264290",
    "end": "266830"
  },
  {
    "text": "Well we can remember that\nlinearity of expectations",
    "start": "266830",
    "end": "270770"
  },
  {
    "text": "allows us to split\nup this sum.",
    "start": "270770",
    "end": "273819"
  },
  {
    "text": "Expectation of a sum, we could\nsplit up into a sum of",
    "start": "273820",
    "end": "276200"
  },
  {
    "text": "expectations.",
    "start": "276200",
    "end": "278020"
  },
  {
    "text": "So this is actually just\nexpectation of x1 plus dot dot",
    "start": "278020",
    "end": "281770"
  },
  {
    "text": "dot plus all the way to\nexpectation of xn.",
    "start": "281770",
    "end": "286539"
  },
  {
    "text": "All right.",
    "start": "286540",
    "end": "288810"
  },
  {
    "text": "And now, remember that we're\nflipping the same coin.",
    "start": "288810",
    "end": "292680"
  },
  {
    "text": "We don't know what the bias is,\nbut for all the n flips,",
    "start": "292680",
    "end": "295039"
  },
  {
    "text": "it's the same coin.",
    "start": "295040",
    "end": "296730"
  },
  {
    "text": "And so each of these\nexpectations of xi should be",
    "start": "296730",
    "end": "300570"
  },
  {
    "text": "the same, no matter\nwhat xi is.",
    "start": "300570",
    "end": "303440"
  },
  {
    "text": "And each one of them is mu.",
    "start": "303440",
    "end": "306240"
  },
  {
    "text": "We already calculated\nthat earlier.",
    "start": "306240",
    "end": "308220"
  },
  {
    "text": "And there's 10 of them, so the\nanswer would be n times mu.",
    "start": "308220",
    "end": "311320"
  },
  {
    "text": " ",
    "start": "311320",
    "end": "315080"
  },
  {
    "text": "So let's move on to part B.\nPart B now asks us to find",
    "start": "315080",
    "end": "324729"
  },
  {
    "text": "what the covariance is\nbetween xi and xj.",
    "start": "324730",
    "end": "331840"
  },
  {
    "start": "330000",
    "end": "420000"
  },
  {
    "text": "And we have to be a little bit\ncareful here because there are",
    "start": "331840",
    "end": "336570"
  },
  {
    "text": "two different scenarios, one\nwhere i and j are different",
    "start": "336570",
    "end": "339330"
  },
  {
    "text": "indices, different tosses,\nand another where i",
    "start": "339330",
    "end": "342639"
  },
  {
    "text": "and j are the same.",
    "start": "342640",
    "end": "344720"
  },
  {
    "text": "So we have to consider both\nof these cases separately.",
    "start": "344720",
    "end": "347250"
  },
  {
    "text": "Let's first do the case where\nx and i are different.",
    "start": "347250",
    "end": "351990"
  },
  {
    "text": "So i does not equal j.",
    "start": "351990",
    "end": "356139"
  },
  {
    "text": "In this case, we can just apply\nthe formula that we",
    "start": "356140",
    "end": "363720"
  },
  {
    "text": "talked about in the beginning.",
    "start": "363720",
    "end": "365790"
  },
  {
    "text": "So this covariance is just equal\nto the expectation of xi",
    "start": "365790",
    "end": "372530"
  },
  {
    "text": "times xj minus the expectation\nof xi times expectation of xj.",
    "start": "372530",
    "end": "386350"
  },
  {
    "text": "All right, so we actually know\nwhat these two are, right?",
    "start": "386350",
    "end": "392920"
  },
  {
    "text": "Expectation of xi is mu.",
    "start": "392920",
    "end": "394400"
  },
  {
    "text": "Expectation of xj is also mu.",
    "start": "394400",
    "end": "395770"
  },
  {
    "text": "So this part is just\nmu squared.",
    "start": "395770",
    "end": "397460"
  },
  {
    "text": "But we need to figure out\nwhat this expectation",
    "start": "397460",
    "end": "399819"
  },
  {
    "text": "of xi times xj is.",
    "start": "399820",
    "end": "402840"
  },
  {
    "text": "Well, the expectation of xi\ntimes xj, we can again use the",
    "start": "402840",
    "end": "409139"
  },
  {
    "text": "law of iterated expectations.",
    "start": "409140",
    "end": "410830"
  },
  {
    "text": "So let's try conditioning\non cue again.",
    "start": "410830",
    "end": "415159"
  },
  {
    "text": " ",
    "start": "415160",
    "end": "420070"
  },
  {
    "text": "And remember we said\nthat this second",
    "start": "420070",
    "end": "421800"
  },
  {
    "text": "part is just mu squared.",
    "start": "421800",
    "end": "424110"
  },
  {
    "text": " ",
    "start": "424110",
    "end": "426909"
  },
  {
    "text": "All right, well, how can\nwe simplify this",
    "start": "426910",
    "end": "429980"
  },
  {
    "text": "inner-conditional expectation?",
    "start": "429980",
    "end": "431870"
  },
  {
    "text": "Well, we can use the fact that\nthe problem tells us that,",
    "start": "431870",
    "end": "434860"
  },
  {
    "text": "conditioned on Q, the tosses\nare independent.",
    "start": "434860",
    "end": "439020"
  },
  {
    "text": "So that means that, conditioned\non Q, xi and xj",
    "start": "439020",
    "end": "443090"
  },
  {
    "text": "are independent.",
    "start": "443090",
    "end": "444270"
  },
  {
    "text": "And remember, when random\nvariables are independent, the",
    "start": "444270",
    "end": "447800"
  },
  {
    "text": "expectation of product, you\ncould simplify that to be the",
    "start": "447800",
    "end": "451099"
  },
  {
    "text": "product of the expectations.",
    "start": "451100",
    "end": "453480"
  },
  {
    "text": "And because we're in the\ncondition world on Q, you have",
    "start": "453480",
    "end": "456390"
  },
  {
    "text": "to remember that it's going\nto be a product of two",
    "start": "456390",
    "end": "458960"
  },
  {
    "text": "conditional expectations.",
    "start": "458960",
    "end": "461910"
  },
  {
    "text": "So this will be expectation of\nxi given Q times expectation",
    "start": "461910",
    "end": "468550"
  },
  {
    "text": "of xj given Q minus\nmu squared still.",
    "start": "468550",
    "end": "476919"
  },
  {
    "text": "All right, now what is this?",
    "start": "476920",
    "end": "481400"
  },
  {
    "text": "Well the expectation of xi given\nQ, we already argued",
    "start": "481400",
    "end": "485360"
  },
  {
    "text": "earlier here that it should just\nbe Q. And then the same",
    "start": "485360",
    "end": "489500"
  },
  {
    "text": "thing for xj.",
    "start": "489500",
    "end": "490660"
  },
  {
    "text": "That should also be Q. So this\nis just expectation of Q",
    "start": "490660",
    "end": "495700"
  },
  {
    "text": "squared minus mu squared.",
    "start": "495700",
    "end": "498430"
  },
  {
    "text": " ",
    "start": "498430",
    "end": "501660"
  },
  {
    "text": "All right, now if we look at\nthis, what is the expectation",
    "start": "501660",
    "end": "506740"
  },
  {
    "text": "of Q squared minus mu squared?",
    "start": "506740",
    "end": "510229"
  },
  {
    "text": "Well, remember mu is just,\nwe're told that mu is the",
    "start": "510230",
    "end": "513830"
  },
  {
    "text": "expectation of Q. So what we\nhave is the expectation of Q",
    "start": "513830",
    "end": "517990"
  },
  {
    "text": "squared minus the quantity\nexpectation of Q squared.",
    "start": "517990",
    "end": "523299"
  },
  {
    "text": "And what is that, exactly?",
    "start": "523299",
    "end": "525040"
  },
  {
    "text": "That is just the formula or\nthe definition of what the",
    "start": "525040",
    "end": "527699"
  },
  {
    "text": "variance of Q should be.",
    "start": "527700",
    "end": "529050"
  },
  {
    "text": "So this is, in fact, exactly\nequal to the variance of Q,",
    "start": "529050",
    "end": "532910"
  },
  {
    "text": "which we're told is\nsigma squared.",
    "start": "532910",
    "end": "536540"
  },
  {
    "text": "All right, so what we found is\nthat for i not equal to j, the",
    "start": "536540",
    "end": "539500"
  },
  {
    "text": "coherence of xi and\nxj is exactly",
    "start": "539500",
    "end": "542065"
  },
  {
    "text": "equal to sigma squared.",
    "start": "542065",
    "end": "544360"
  },
  {
    "text": "And remember, we're told that\nsigma squared is positive.",
    "start": "544360",
    "end": "547589"
  },
  {
    "text": "So what does that tell us?",
    "start": "547590",
    "end": "548450"
  },
  {
    "text": "That tells us that xi and xj, or\ni not equal to j, these two",
    "start": "548450",
    "end": "553640"
  },
  {
    "text": "random variables\nare correlated.",
    "start": "553640",
    "end": "555740"
  },
  {
    "text": "And so, because they're\ncorrelated, they can't be",
    "start": "555740",
    "end": "557800"
  },
  {
    "text": "independent.",
    "start": "557800",
    "end": "558820"
  },
  {
    "text": "Remember, if two intervals are\nindependent, that means",
    "start": "558820",
    "end": "561720"
  },
  {
    "text": "they're uncorrelated.",
    "start": "561720",
    "end": "564300"
  },
  {
    "text": "But the converse isn't true.",
    "start": "564300",
    "end": "565550"
  },
  {
    "text": " ",
    "start": "565550",
    "end": "568149"
  },
  {
    "text": "But if we do know that two\nrandom variables are",
    "start": "568150",
    "end": "571130"
  },
  {
    "text": "correlated, that means that\nthey can't be independent.",
    "start": "571130",
    "end": "573050"
  },
  {
    "text": " ",
    "start": "573050",
    "end": "575920"
  },
  {
    "text": "And now let's finish this by\nconsidering the second case.",
    "start": "575920",
    "end": "580149"
  },
  {
    "text": "The second case is when i\nactually does equal j.",
    "start": "580150",
    "end": "585290"
  },
  {
    "text": "And in that case, well, the\ncovariance of xi and xi is",
    "start": "585290",
    "end": "590360"
  },
  {
    "text": "just another way of writing\nthe variance of xi.",
    "start": "590360",
    "end": "594040"
  },
  {
    "text": "So covariance, xi, xi, it's\njust the variance of xi.",
    "start": "594040",
    "end": "601690"
  },
  {
    "text": "And what is that?",
    "start": "601690",
    "end": "603320"
  },
  {
    "text": "That is just the expectation\nof xi squared minus",
    "start": "603320",
    "end": "608590"
  },
  {
    "text": "expectation of xi quantity\nsquared.",
    "start": "608590",
    "end": "616420"
  },
  {
    "text": "And again, we know what\nthe second term is.",
    "start": "616420",
    "end": "618290"
  },
  {
    "text": "The second term is expectation\nof xi quantity squared.",
    "start": "618290",
    "end": "621259"
  },
  {
    "text": "Expectation of xi we know from\npart A is just mu, right?",
    "start": "621260",
    "end": "626540"
  },
  {
    "text": "So that's just second term\nis just mu squared.",
    "start": "626540",
    "end": "628670"
  },
  {
    "text": "But what is the expectation\nof xi squared?",
    "start": "628670",
    "end": "632250"
  },
  {
    "text": "Well, we can think about\nthis a little bit more.",
    "start": "632250",
    "end": "635220"
  },
  {
    "text": "And you can realize that xi\nsquared is actually exactly",
    "start": "635220",
    "end": "640019"
  },
  {
    "text": "the same thing as just xi.",
    "start": "640020",
    "end": "641920"
  },
  {
    "text": "And this is just a special case\nbecause xi is a Bernoulli",
    "start": "641920",
    "end": "645149"
  },
  {
    "text": "random variable.",
    "start": "645150",
    "end": "646230"
  },
  {
    "text": "Because Bernoulli is\neither 0 or 1.",
    "start": "646230",
    "end": "649209"
  },
  {
    "text": "And if it's 0 and you square\nit, it's still 0.",
    "start": "649210",
    "end": "652010"
  },
  {
    "text": "And if it's 1 and you square\nit, it's still 1.",
    "start": "652010",
    "end": "654380"
  },
  {
    "text": "So squaring it doesn't\nreally doesn't",
    "start": "654380",
    "end": "658980"
  },
  {
    "text": "actually change anything.",
    "start": "658980",
    "end": "660139"
  },
  {
    "text": "It's exactly the same thing as\nthe original random variable.",
    "start": "660140",
    "end": "663390"
  },
  {
    "text": "And so, because this is a\nBernoulli random variable,",
    "start": "663390",
    "end": "667130"
  },
  {
    "text": "this is exactly just the\nexpectation of xi.",
    "start": "667130",
    "end": "671340"
  },
  {
    "text": "And we said this part\nis just mu squared.",
    "start": "671340",
    "end": "673880"
  },
  {
    "text": "So this is just expectation of\nxi, which we said was mu.",
    "start": "673880",
    "end": "677950"
  },
  {
    "text": "So the answer is just\nmu minus mu squared.",
    "start": "677950",
    "end": "681730"
  },
  {
    "text": " ",
    "start": "681730",
    "end": "684459"
  },
  {
    "text": "OK, so this completes part B.\nAnd the answer that we wanted",
    "start": "684460",
    "end": "691880"
  },
  {
    "text": "was that in fact, xi and xj are\nin fact not independent.",
    "start": "691880",
    "end": "698190"
  },
  {
    "text": "Right.",
    "start": "698190",
    "end": "699130"
  },
  {
    "text": "So let's write down some facts\nthat we'll want to remember.",
    "start": "699130",
    "end": "705960"
  },
  {
    "text": "One of them is that expectation\nof xi is mu.",
    "start": "705960",
    "end": "711610"
  },
  {
    "text": "And we also want to remember\nwhat this covariance is.",
    "start": "711610",
    "end": "716660"
  },
  {
    "text": "The covariance of xi and xj is\nequal to sigma squared when i",
    "start": "716660",
    "end": "724290"
  },
  {
    "text": "does not equal j.",
    "start": "724290",
    "end": "726470"
  },
  {
    "text": "So we'll be using these\nfacts again later.",
    "start": "726470",
    "end": "730569"
  },
  {
    "text": "And the variance of xi is equal\nto mu minus mu squared.",
    "start": "730570",
    "end": "738780"
  },
  {
    "text": " ",
    "start": "738780",
    "end": "742120"
  },
  {
    "text": "So now let's move on to the last\npart, part C, which asks",
    "start": "742120",
    "end": "747830"
  },
  {
    "start": "745000",
    "end": "870000"
  },
  {
    "text": "us to calculate the variance\nof x in two different ways.",
    "start": "747830",
    "end": "754550"
  },
  {
    "text": "So the first way we'll\ndo it is using the",
    "start": "754550",
    "end": "759110"
  },
  {
    "text": "law of total variance.",
    "start": "759110",
    "end": "761829"
  },
  {
    "text": "So the law of total variance\nwill tell us that we can write",
    "start": "761830",
    "end": "767470"
  },
  {
    "text": "the variance of x as a sum\nof two different parts.",
    "start": "767470",
    "end": "771939"
  },
  {
    "text": "So the first is variance of x\nexpectation of the variance of",
    "start": "771940",
    "end": "776240"
  },
  {
    "text": "x conditioned on something\nplus the variance of the",
    "start": "776240",
    "end": "783740"
  },
  {
    "text": "initial expectation of x\nconditioned on something.",
    "start": "783740",
    "end": "787320"
  },
  {
    "text": "And as you might have guessed,\nwhat we're going to condition",
    "start": "787320",
    "end": "790030"
  },
  {
    "text": "on is Q.",
    "start": "790030",
    "end": "796330"
  },
  {
    "text": "Let's calculate what these\ntwo things are.",
    "start": "796330",
    "end": "798670"
  },
  {
    "text": "So let's do the two\nterms separately.",
    "start": "798670",
    "end": "801170"
  },
  {
    "text": "What is the expectation\nof the conditional",
    "start": "801170",
    "end": "803470"
  },
  {
    "text": "variance of x given Q?",
    "start": "803470",
    "end": "806490"
  },
  {
    "text": " ",
    "start": "806490",
    "end": "809750"
  },
  {
    "text": "Well, what is--",
    "start": "809750",
    "end": "813550"
  },
  {
    "text": "this, we can write out x.",
    "start": "813550",
    "end": "816140"
  },
  {
    "text": "Because x, remember, is just\nthe sum of a bunch of these",
    "start": "816140",
    "end": "821880"
  },
  {
    "text": "Bernoulli random variables.",
    "start": "821880",
    "end": "823270"
  },
  {
    "text": " ",
    "start": "823270",
    "end": "826290"
  },
  {
    "text": "And now what we'll do was, well,\nagain, use the important",
    "start": "826290",
    "end": "830380"
  },
  {
    "text": "fact that the x's, we're told,\nare conditionally independent,",
    "start": "830380",
    "end": "834900"
  },
  {
    "text": "conditional on Q.",
    "start": "834900",
    "end": "836710"
  },
  {
    "text": "And because they're independent,\nremember the",
    "start": "836710",
    "end": "840450"
  },
  {
    "text": "variance of a sum is not the\nsum of the variance.",
    "start": "840450",
    "end": "843560"
  },
  {
    "text": "It's only the sum of the\nvariance if the terms in the",
    "start": "843560",
    "end": "846730"
  },
  {
    "text": "sum are independent.",
    "start": "846730",
    "end": "848480"
  },
  {
    "text": "In this case, they are\nconditionally independent",
    "start": "848480",
    "end": "850880"
  },
  {
    "text": "given Q. So we can in fact split\nthis up and write it as",
    "start": "850880",
    "end": "855730"
  },
  {
    "text": "the variance of x1 given Q\nplus all the way to the",
    "start": "855730",
    "end": "860339"
  },
  {
    "text": "variance of xn given Q.",
    "start": "860340",
    "end": "870980"
  },
  {
    "text": "And in fact, all these\nare the same, right?",
    "start": "870980",
    "end": "873959"
  },
  {
    "text": "So we just have n copies of the\nvariance of, say, x1 given",
    "start": "873960",
    "end": "879530"
  },
  {
    "text": "Q. Now, what is the variance\nof x1 given Q?",
    "start": "879530",
    "end": "883310"
  },
  {
    "text": "Well, x1 is just a Bernoulli\nrandom variable.",
    "start": "883310",
    "end": "886770"
  },
  {
    "text": "But the difference is that for\nx, we don't know what the bias",
    "start": "886770",
    "end": "891620"
  },
  {
    "text": "or what the Q is.",
    "start": "891620",
    "end": "894060"
  },
  {
    "text": "Because it's some\nrandom bias Q",
    "start": "894060",
    "end": "897910"
  },
  {
    "text": "But just like we said earlier\nin part A, when we talked",
    "start": "897910",
    "end": "901009"
  },
  {
    "text": "about the expectation of x1\ngiven Q, this is actually just",
    "start": "901010",
    "end": "907640"
  },
  {
    "text": "Q times 1 minus Q. Because if\nyou knew what the bias were,",
    "start": "907640",
    "end": "913250"
  },
  {
    "text": "it would be p times 1 minus p.",
    "start": "913250",
    "end": "914810"
  },
  {
    "text": "So the bias times 1\nminus the bias.",
    "start": "914810",
    "end": "916860"
  },
  {
    "text": "But you don't know what it is.",
    "start": "916860",
    "end": "919190"
  },
  {
    "text": "But if you did, it\nwould just be q.",
    "start": "919190",
    "end": "921060"
  },
  {
    "text": "So what we do is we just plug\nin Q, and you get Q",
    "start": "921060",
    "end": "923870"
  },
  {
    "text": "times 1 minus 2.",
    "start": "923870",
    "end": "926770"
  },
  {
    "text": "All right, and now this\nis expectation of n.",
    "start": "926770",
    "end": "936110"
  },
  {
    "text": "I can pull out the n.",
    "start": "936110",
    "end": "938959"
  },
  {
    "text": "So it's n times the expectation\nof Q minus Q",
    "start": "938960",
    "end": "943470"
  },
  {
    "text": "squared, which is just n times\nexpectation Q, we can use",
    "start": "943470",
    "end": "951089"
  },
  {
    "text": "linearity of expectations again,\nexpectation of Q is mu.",
    "start": "951090",
    "end": "955450"
  },
  {
    "text": "And the expectation of Q 2\nsquared is, well, we can do",
    "start": "955450",
    "end": "960540"
  },
  {
    "text": "that on the side.",
    "start": "960540",
    "end": "961230"
  },
  {
    "text": "Expectation of Q squared is\nthe variance of Q plus",
    "start": "961230",
    "end": "968839"
  },
  {
    "text": "expectation of Q quantity\nsquared.",
    "start": "968840",
    "end": "974230"
  },
  {
    "text": "So that's just sigma squared\nplus mu squared.",
    "start": "974230",
    "end": "982120"
  },
  {
    "text": "And so this is just going to\nbe then minus sigma squared",
    "start": "982120",
    "end": "987810"
  },
  {
    "text": "minus mu squared.",
    "start": "987810",
    "end": "989060"
  },
  {
    "text": " ",
    "start": "989060",
    "end": "992080"
  },
  {
    "text": "All right, so that's\nthe first term.",
    "start": "992080",
    "end": "993820"
  },
  {
    "text": "Now let's do the second term.",
    "start": "993820",
    "end": "995950"
  },
  {
    "text": "The variance the conditional\nexpectation of x given Q. And",
    "start": "995950",
    "end": "1003720"
  },
  {
    "text": "again, what we can do is we can\nwrite x as the sum of all",
    "start": "1003720",
    "end": "1012740"
  },
  {
    "text": "these xi's.",
    "start": "1012740",
    "end": "1015435"
  },
  {
    "text": " ",
    "start": "1015435",
    "end": "1019270"
  },
  {
    "text": "And now we can apply linearity\nof expectations.",
    "start": "1019270",
    "end": "1024730"
  },
  {
    "text": "So we would get n times one\nof these expectations.",
    "start": "1024730",
    "end": "1028704"
  },
  {
    "text": " ",
    "start": "1028705",
    "end": "1033439"
  },
  {
    "text": "And remember, we said earlier\nthe expectation of x1 given Q",
    "start": "1033440",
    "end": "1038529"
  },
  {
    "text": "is just Q. So it's the variance\nof n times Q.",
    "start": "1038530",
    "end": "1043720"
  },
  {
    "text": "And remember now, n is just--",
    "start": "1043720",
    "end": "1046375"
  },
  {
    "text": "it's not random.",
    "start": "1046375",
    "end": "1047459"
  },
  {
    "text": "It's just some number.",
    "start": "1047460",
    "end": "1049679"
  },
  {
    "text": "So when you pull it out of a\nvariance, you square it.",
    "start": "1049680",
    "end": "1052070"
  },
  {
    "text": "So this is n squared times\nthe variance of Q.",
    "start": "1052070",
    "end": "1056289"
  },
  {
    "text": "And the variance of Q we're\ngiven is sigma squared.",
    "start": "1056290",
    "end": "1059130"
  },
  {
    "text": "So this is n squared times\nsigma squared.",
    "start": "1059130",
    "end": "1062660"
  },
  {
    "text": " ",
    "start": "1062660",
    "end": "1065280"
  },
  {
    "text": "So the final answer is\njust a combination",
    "start": "1065280",
    "end": "1067860"
  },
  {
    "text": "of these two terms.",
    "start": "1067860",
    "end": "1069250"
  },
  {
    "text": "This one and this one.",
    "start": "1069250",
    "end": "1074290"
  },
  {
    "text": "So let's write it out.",
    "start": "1074290",
    "end": "1076010"
  },
  {
    "text": "The variance of x, then,\nis equal to--",
    "start": "1076010",
    "end": "1079295"
  },
  {
    "text": " ",
    "start": "1079295",
    "end": "1082790"
  },
  {
    "text": "we can combine terms\na little bit.",
    "start": "1082790",
    "end": "1084580"
  },
  {
    "text": "So the first one, let's\ntake the mus and",
    "start": "1084580",
    "end": "1088010"
  },
  {
    "text": "we'll put them together.",
    "start": "1088010",
    "end": "1088730"
  },
  {
    "text": "So it's n mu minus mu squared.",
    "start": "1088730",
    "end": "1091325"
  },
  {
    "text": " ",
    "start": "1091325",
    "end": "1095830"
  },
  {
    "text": "And then we have n squared times\nsigma squared from this",
    "start": "1095830",
    "end": "1102659"
  },
  {
    "text": "term and minus n times sigma\nsquared from this term.",
    "start": "1102660",
    "end": "1108520"
  },
  {
    "text": "So it would be n squared minus\nn times sigma squared, or n",
    "start": "1108520",
    "end": "1114450"
  },
  {
    "text": "times n minus 1 times\nsigma squared.",
    "start": "1114450",
    "end": "1118399"
  },
  {
    "text": "So that is the final answer\nthat we get for",
    "start": "1118400",
    "end": "1120970"
  },
  {
    "text": "the variance of x.",
    "start": "1120970",
    "end": "1122220"
  },
  {
    "text": " ",
    "start": "1122220",
    "end": "1125030"
  },
  {
    "text": "And now, let's try doing\nit another way.",
    "start": "1125030",
    "end": "1127450"
  },
  {
    "text": " ",
    "start": "1127450",
    "end": "1131799"
  },
  {
    "start": "1130000",
    "end": "1290000"
  },
  {
    "text": "So that's one way of doing it.",
    "start": "1131800",
    "end": "1133960"
  },
  {
    "text": "That's using the law of total\nexpectations and conditioning",
    "start": "1133960",
    "end": "1137140"
  },
  {
    "text": "on Q. Another way of finding\nthe variance of x is to use",
    "start": "1137140",
    "end": "1145880"
  },
  {
    "text": "the formula involving\ncovariances, right?",
    "start": "1145880",
    "end": "1151330"
  },
  {
    "text": "And we can use that because x is\nactually a sum of multiple",
    "start": "1151330",
    "end": "1158652"
  },
  {
    "text": "random variables\nx1 through xn.",
    "start": "1158652",
    "end": "1163590"
  },
  {
    "text": "And the formula for this is, you\nhave n variance terms plus",
    "start": "1163590",
    "end": "1180779"
  },
  {
    "text": "all these other ones.",
    "start": "1180780",
    "end": "1184110"
  },
  {
    "text": "Where i is not equal to j, you\nhave the covariance terms.",
    "start": "1184110",
    "end": "1188140"
  },
  {
    "text": "And really, it's just, you can\nthink of it as a double sum of",
    "start": "1188140",
    "end": "1191770"
  },
  {
    "text": "all pairs of xi and xj where if\ni and j happen just to be",
    "start": "1191770",
    "end": "1199150"
  },
  {
    "text": "the same, that it simplifies\nto be just the variance.",
    "start": "1199150",
    "end": "1202710"
  },
  {
    "text": "Now, so we pulled theses n terms\nout because they are",
    "start": "1202710",
    "end": "1206240"
  },
  {
    "text": "different than these because\nthey have a different value.",
    "start": "1206240",
    "end": "1210770"
  },
  {
    "text": "And now fortunately, we've\nalready calculated what these",
    "start": "1210770",
    "end": "1214060"
  },
  {
    "text": "values are in part B. So we\ncan just plug them them.",
    "start": "1214060",
    "end": "1216690"
  },
  {
    "text": "All the variances\nare the same.",
    "start": "1216690",
    "end": "1218889"
  },
  {
    "text": "And there's n of them,\nso we get n times the",
    "start": "1218890",
    "end": "1221300"
  },
  {
    "text": "variance of each one.",
    "start": "1221300",
    "end": "1222260"
  },
  {
    "text": "The variance of each one we\ncalculated already was mu",
    "start": "1222260",
    "end": "1226960"
  },
  {
    "text": "minus mu squared.",
    "start": "1226960",
    "end": "1229789"
  },
  {
    "text": "And then, we have all\nthe terms were i is",
    "start": "1229790",
    "end": "1232630"
  },
  {
    "text": "not equal to j.",
    "start": "1232630",
    "end": "1234210"
  },
  {
    "text": "Well, there are actually n\nsquared minus n of them.",
    "start": "1234210",
    "end": "1239649"
  },
  {
    "text": "So because you can take any one\nof the n's to be the first",
    "start": "1239650",
    "end": "1244040"
  },
  {
    "text": "to be i, any one of\nthe n to be j.",
    "start": "1244040",
    "end": "1248110"
  },
  {
    "text": "So that gives you\nn squared pairs.",
    "start": "1248110",
    "end": "1249890"
  },
  {
    "text": "But then you have to subtract\nout all the ones where i and j",
    "start": "1249890",
    "end": "1252590"
  },
  {
    "text": "are the same.",
    "start": "1252590",
    "end": "1253190"
  },
  {
    "text": "And there are n of them.",
    "start": "1253190",
    "end": "1254320"
  },
  {
    "text": "So that leaves you with n\nsquared minus n of these pairs",
    "start": "1254320",
    "end": "1259250"
  },
  {
    "text": "where i is not equal to j.",
    "start": "1259250",
    "end": "1261600"
  },
  {
    "text": "And the coherence for this case\nwhere i is not equal to",
    "start": "1261600",
    "end": "1264130"
  },
  {
    "text": "j, we also calculated in part B.\nThat's just sigma squared.",
    "start": "1264130",
    "end": "1268176"
  },
  {
    "text": "All right, and now if we compare\nthese two, we'll see",
    "start": "1268176",
    "end": "1273050"
  },
  {
    "text": "that they are proportionally\nexactly the same.",
    "start": "1273050",
    "end": "1275610"
  },
  {
    "text": " ",
    "start": "1275610",
    "end": "1278510"
  },
  {
    "text": "So we've use two different\nmethods to calculate the",
    "start": "1278510",
    "end": "1283700"
  },
  {
    "text": "variance, one using this\nsummation and one using the",
    "start": "1283700",
    "end": "1287510"
  },
  {
    "text": "law of total variance.",
    "start": "1287510",
    "end": "1289860"
  },
  {
    "text": "So what do we learn\nfrom this problem?",
    "start": "1289860",
    "end": "1293040"
  },
  {
    "start": "1290000",
    "end": "1377000"
  },
  {
    "text": "Well, we saw that first of all,\nin order to find some",
    "start": "1293040",
    "end": "1297430"
  },
  {
    "text": "expectations, it's very useful\nto use law of iterated",
    "start": "1297430",
    "end": "1300940"
  },
  {
    "text": "expectations.",
    "start": "1300940",
    "end": "1301700"
  },
  {
    "text": "But the trick is to figure out\nwhat you should condition on.",
    "start": "1301700",
    "end": "1304620"
  },
  {
    "text": "And that's kind of an\nart that you learn",
    "start": "1304620",
    "end": "1307780"
  },
  {
    "text": "through more practice.",
    "start": "1307780",
    "end": "1309230"
  },
  {
    "text": "But one good rule of thumb is,\nwhen you have kind of a",
    "start": "1309230",
    "end": "1312919"
  },
  {
    "text": "hierarchy or layers of\nrandomness where one layer of",
    "start": "1312920",
    "end": "1317650"
  },
  {
    "text": "randomness depends\non the randomness",
    "start": "1317650",
    "end": "1320640"
  },
  {
    "text": "of the layer above--",
    "start": "1320640",
    "end": "1321960"
  },
  {
    "text": "so in this case, whether or\nnot you get heads or tails",
    "start": "1321960",
    "end": "1325779"
  },
  {
    "text": "depends on, that's random, but\nthat depends on the randomness",
    "start": "1325780",
    "end": "1329600"
  },
  {
    "text": "on the level above, which\nwas the random",
    "start": "1329600",
    "end": "1332039"
  },
  {
    "text": "bias of the coin itself.",
    "start": "1332040",
    "end": "1334150"
  },
  {
    "text": "So the rule of thumb is, when\nyou want to calculate the",
    "start": "1334150",
    "end": "1339410"
  },
  {
    "text": "expectations for the layer where\nyou're talking about",
    "start": "1339410",
    "end": "1343360"
  },
  {
    "text": "heads or tails, it's useful to\ncondition on the layer above",
    "start": "1343360",
    "end": "1347710"
  },
  {
    "text": "where that is, in this case,\nthe random bias.",
    "start": "1347710",
    "end": "1350590"
  },
  {
    "text": "Because once you condition on\nthe layer above, that makes",
    "start": "1350590",
    "end": "1354429"
  },
  {
    "text": "the next level much simpler.",
    "start": "1354430",
    "end": "1356210"
  },
  {
    "text": "Because you kind of assume that\nyou know what all the",
    "start": "1356210",
    "end": "1359830"
  },
  {
    "text": "previous levels of randomness\nare, and that helps you",
    "start": "1359830",
    "end": "1362649"
  },
  {
    "text": "calculate what the expectation\nfor this current level.",
    "start": "1362650",
    "end": "1367480"
  },
  {
    "text": "And the rest of the problem was\njust kind of going through",
    "start": "1367480",
    "end": "1372179"
  },
  {
    "text": "exercises of actually\napplying the--",
    "start": "1372180",
    "end": "1374160"
  },
  {
    "text": " ",
    "start": "1374160",
    "end": "1375410"
  }
]
[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6910"
  },
  {
    "text": "offer high-quality, educational resources for free. To make a donation or view\nadditional materials from",
    "start": "6910",
    "end": "13460"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at",
    "start": "13460",
    "end": "19290"
  },
  {
    "text": "ocw.mit.edu. PROFESSOR: All right. So today, we're going to start\nby taking stock of what we",
    "start": "19290",
    "end": "26070"
  },
  {
    "start": "22000",
    "end": "139000"
  },
  {
    "text": "discussed last time, review the definition of Markov chains. And then most of the lecture,\nwe're going to concentrate on",
    "start": "26070",
    "end": "32399"
  },
  {
    "text": "their steady-state behavior. Meaning, we're going to look at\nwhat does a Markov chain do",
    "start": "32400",
    "end": "38860"
  },
  {
    "text": "if it has run for a long time. What can we say about\nthe probabilities of the different states?",
    "start": "38860",
    "end": "44610"
  },
  {
    "text": "So what I would like to repeat\nis a statement I made last time that Markov chains\nis a very, very",
    "start": "44610",
    "end": "49730"
  },
  {
    "text": "useful class of models. Pretty much anything in\nthe real world can be",
    "start": "49730",
    "end": "56820"
  },
  {
    "text": "approximately modeled by a\nMarkov chain provided that you set your states in\nthe proper way.",
    "start": "56820",
    "end": "65018"
  },
  {
    "text": "So we're going to see\nsome examples. You're going to see more\nexamples in the problems you're going to do in homework\nand recitation.",
    "start": "65019",
    "end": "71140"
  },
  {
    "text": " On the other hand, we're\nnot going to go too deep into examples.",
    "start": "71140",
    "end": "77829"
  },
  {
    "text": "Rather, we're going to develop\nthe general methodology. ",
    "start": "77830",
    "end": "131440"
  },
  {
    "text": "OK. ",
    "start": "131440",
    "end": "139310"
  },
  {
    "start": "139000",
    "end": "328000"
  },
  {
    "text": "All right. Markov models can be\npretty general. They can run in continuous\nor discrete time.",
    "start": "139310",
    "end": "144670"
  },
  {
    "text": "They can have continuous or\ndiscrete state spaces. In this class, we're going to\nstick just to the case where",
    "start": "144670",
    "end": "150280"
  },
  {
    "text": "the state space is discrete and\ntime is discrete because this is the simplest case.",
    "start": "150280",
    "end": "155570"
  },
  {
    "text": "And also, it's the one where\nyou build your intuition before going to more\ngeneral cases",
    "start": "155570",
    "end": "160830"
  },
  {
    "text": "perhaps in other classes. So the state is discrete\nand finite.",
    "start": "160830",
    "end": "167810"
  },
  {
    "text": "There's a finite number\nof states. At any point in time, the\nprocess is sitting on one of",
    "start": "167810",
    "end": "173540"
  },
  {
    "text": "those states. Time is discrete, so at each\nunit of time, somebody",
    "start": "173540",
    "end": "180520"
  },
  {
    "text": "whistles and then\nthe state jumps. And when it jumps, it can either\nland in the same place,",
    "start": "180520",
    "end": "186110"
  },
  {
    "text": "or it can land somewhere else. And the evolution of the\nprocess is described by transition probabilities.",
    "start": "186110",
    "end": "193130"
  },
  {
    "text": "Pij is the probability that the\nnext state is j given that the current state is i.",
    "start": "193130",
    "end": "198630"
  },
  {
    "text": "And the most important property\nthat the Markov chain has, the definition of a\nMarkov chain or Markov",
    "start": "198630",
    "end": "204690"
  },
  {
    "text": "process, is that this\nprobability, Pij, is the same every time that you\nland at state i --",
    "start": "204690",
    "end": "211490"
  },
  {
    "text": "no matter how you got there\nand also no matter what time it is.",
    "start": "211490",
    "end": "218000"
  },
  {
    "text": "So the model we have is time\nhomogeneous, which basically means that those transition\nprobabilities are the same at",
    "start": "218000",
    "end": "224629"
  },
  {
    "text": "every time. So the model is time invariant\nin that sense. So we're interested in what the\nchain or the process is",
    "start": "224630",
    "end": "232670"
  },
  {
    "text": "going to do in the longer run. So we're interested, let's say,\nin the probability that starting at a certain state, n\ntimes steps later, we find",
    "start": "232670",
    "end": "240760"
  },
  {
    "text": "ourselves at some particular\nstate j. Fortunately, we can calculate\nthose probabilities",
    "start": "240760",
    "end": "246349"
  },
  {
    "text": "recursively. Of course, at the first time 1,\nthe probability of being 1",
    "start": "246350",
    "end": "252990"
  },
  {
    "text": "time later at state j given that\nwe are right now at state i, by definition, this is just\nthe transition probabilities.",
    "start": "252990",
    "end": "260910"
  },
  {
    "text": "So by knowing these, we can\nstart a recursion that tells",
    "start": "260910",
    "end": "266000"
  },
  {
    "text": "us the transition probabilities for more than n steps.",
    "start": "266000",
    "end": "271430"
  },
  {
    "text": "This recursion, it's\na formula. It's always true. You can copy it or\nmemorize it.",
    "start": "271430",
    "end": "276860"
  },
  {
    "text": "But there is a big idea behind\nthat formula that you should keep in mind. And basically, the divide\nand conquer idea.",
    "start": "276860",
    "end": "283750"
  },
  {
    "text": "It's an application of the\ntotal probability law. So let's fix i.",
    "start": "283750",
    "end": "289080"
  },
  {
    "text": "The probability that you find\nyourself at state j, you break it up into the probabilities of\nthe different ways that you",
    "start": "289080",
    "end": "295770"
  },
  {
    "text": "can get to state j. What are those different ways? The different ways are the\ndifferent states k at which",
    "start": "295770",
    "end": "302460"
  },
  {
    "text": "you might find yourself\nthe previous time. So with some probability, with\nthis probability, you find",
    "start": "302460",
    "end": "308400"
  },
  {
    "text": "yourself at state k\nthe previous time. And then with probability\nPkj, you make a transition to state j.",
    "start": "308400",
    "end": "315030"
  },
  {
    "text": "So this is a possible scenario\nthat takes you to state j after n transitions.",
    "start": "315030",
    "end": "321090"
  },
  {
    "text": "And by summing over all the k's,\nthen we have considered all the possible scenarios.",
    "start": "321090",
    "end": "328430"
  },
  {
    "text": "Now, before we move to the more\nserious stuff, let's do a little bit of warm up to get\na handle on how we use",
    "start": "328430",
    "end": "338419"
  },
  {
    "text": "transition probabilities to\ncalculate more general probabilities, then talk about\nsome structural properties of",
    "start": "338420",
    "end": "345250"
  },
  {
    "text": "Markov chains, and then\neventually get to the main business of today, which is\na steady-state behavior.",
    "start": "345250",
    "end": "351310"
  },
  {
    "text": "So somebody gives you this\nchain, and our convention is",
    "start": "351310",
    "end": "356380"
  },
  {
    "text": "that those arcs that are not\nshown here corresponds to 0 probabilities.",
    "start": "356380",
    "end": "361510"
  },
  {
    "text": "And each one of the arcs that's\nshown has a non-zero probability, and somebody\ngives it to us.",
    "start": "361510",
    "end": "369060"
  },
  {
    "text": "Suppose that the chain\nstarts at state 1. We want to calculate the\nprobability that it follows",
    "start": "369060",
    "end": "375720"
  },
  {
    "text": "this particular path. That is, it goes to 2,\nthen to 6, then to 7. How do we calculate the\nprobability of a particular",
    "start": "375720",
    "end": "382919"
  },
  {
    "text": "trajectory? Well, this is the\nprobability-- so it's the probability of the\ntrajectory from 1 that you go",
    "start": "382920",
    "end": "390980"
  },
  {
    "text": "to 2, then to 6, then to 7. So the probability of this\ntrajectory is we use the",
    "start": "390980",
    "end": "398020"
  },
  {
    "text": "multiplication rule. The probability of several\nthings happening is the probability that the first\nthing happens, which is a",
    "start": "398020",
    "end": "404700"
  },
  {
    "text": "transition from 1 to 2. And then given that we are at\nstate 2, we multiply with a",
    "start": "404700",
    "end": "413190"
  },
  {
    "text": "conditional probability that\nthe next event happens. That is, that X2 is equal to 6\ngiven that right now, we are",
    "start": "413190",
    "end": "422370"
  },
  {
    "text": "at state 1. And that conditional probability\nis just P26.",
    "start": "422370",
    "end": "427760"
  },
  {
    "text": "And notice that this conditional\nprobability applies no matter how\nwe got to state 2.",
    "start": "427760",
    "end": "433380"
  },
  {
    "text": "This is the Markov assumption. So we don't care about the\nfact that we came in in a particular way.",
    "start": "433380",
    "end": "439120"
  },
  {
    "text": "Given that we came in here, this\nprobability P26, that the next transition takes us to 6.",
    "start": "439120",
    "end": "444639"
  },
  {
    "text": "And then given that all that\nstuff happened, so given that right now, we are at state 6,\nwe need to multiply with a",
    "start": "444640",
    "end": "452060"
  },
  {
    "text": "conditional probability that the\nnext transition takes us to state 7. And this is just the P67.",
    "start": "452060",
    "end": "459919"
  },
  {
    "text": "So to find the probability\nof following a specific trajectory, you just multiply\nthe transition probabilities",
    "start": "459920",
    "end": "469280"
  },
  {
    "text": "along the particular\ntrajectory. ",
    "start": "469280",
    "end": "474490"
  },
  {
    "text": "Now, if you want to calculate\nsomething else, such as for example, the probability that\n4 time steps later, I find",
    "start": "474490",
    "end": "482100"
  },
  {
    "text": "myself at state 7 given that\nthey started, let's say, at this state.",
    "start": "482100",
    "end": "487680"
  },
  {
    "text": "How do you calculate\nthis probability? One way is to use the recursion\nfor the Rijs that we",
    "start": "487680",
    "end": "495350"
  },
  {
    "text": "know that it is always valid. But for short and simple\nexamples, and with a small",
    "start": "495350",
    "end": "500970"
  },
  {
    "text": "time horizon, perhaps you can do\nthis in a brute force way. What would be the\nbrute force way?",
    "start": "500970",
    "end": "507100"
  },
  {
    "text": "This is the event that 4 time\nsteps later, I find myself at state 7.",
    "start": "507100",
    "end": "512210"
  },
  {
    "text": "This event can happen\nin various ways. So we can take stock of all the\ndifferent ways, and write",
    "start": "512210",
    "end": "521069"
  },
  {
    "text": "down their probabilities. So starting from 2. One possibility is to follow\nthis trajectory, 1 transition,",
    "start": "521070",
    "end": "529870"
  },
  {
    "text": "2 transitions, 3 transitions,\n4 transitions. And that takes me to state 7.",
    "start": "529870",
    "end": "535810"
  },
  {
    "text": "What's the probability\nof this trajectory? It's P26 times P67 times\nP76 and then times P67.",
    "start": "535810",
    "end": "545160"
  },
  {
    "text": "So this is a probability of a\nparticular trajectory that takes you to state 7\nafter 4 time steps.",
    "start": "545160",
    "end": "551040"
  },
  {
    "text": "But there's other trajectories\nas well. What could be it?",
    "start": "551040",
    "end": "556300"
  },
  {
    "text": "I might start from state 2, go\nto state 6, stay at state 6,",
    "start": "556300",
    "end": "563470"
  },
  {
    "text": "stay at state 6 once more. And then from state\n6, go to state 7.",
    "start": "563470",
    "end": "571670"
  },
  {
    "text": "And so there must be one more.",
    "start": "571670",
    "end": "576800"
  },
  {
    "text": "What's the other one? I guess I could go 1, 2, 6, 7.",
    "start": "576800",
    "end": "585620"
  },
  {
    "text": "OK. That's the other trajectory. Plus P21 times P12 times\nP26 and times P67.",
    "start": "585620",
    "end": "601850"
  },
  {
    "text": "So the transition probability,\nthe overall probability of finding ourselves at state 7,\nis broken down as the sum of",
    "start": "601850",
    "end": "609490"
  },
  {
    "text": "the probabilities of all the\ndifferent ways that I can get to state 7 in exactly 4 steps.",
    "start": "609490",
    "end": "616000"
  },
  {
    "text": "So we could always do that\nwithout knowing much about Markov chains or the general\nformula for the",
    "start": "616000",
    "end": "621750"
  },
  {
    "text": "Rij's that we had. What's the trouble with\nthis procedure? The trouble with this procedure\nis that the number",
    "start": "621750",
    "end": "629190"
  },
  {
    "text": "of possible trajectories becomes\nquite large if this",
    "start": "629190",
    "end": "634450"
  },
  {
    "text": "index is a little bigger. If this 4 was 100, and you\nask how many different",
    "start": "634450",
    "end": "641510"
  },
  {
    "text": "trajectories of length 100 are\nthere to take me from here to there, that number of\ntrajectories would be huge.",
    "start": "641510",
    "end": "648170"
  },
  {
    "text": "It grows exponentially with\nthe time horizon. And this kind of calculation\nwould be impossible.",
    "start": "648170",
    "end": "655110"
  },
  {
    "text": "The basic equation, the\nrecursion that have for the Rij's is basically a clever\nway of organizing this",
    "start": "655110",
    "end": "661650"
  },
  {
    "text": "computation so that the amount\nof computation that you do is not exponential in\nthe time horizon.",
    "start": "661650",
    "end": "666960"
  },
  {
    "text": "Rather, it's sort of linear\nwith the time horizon. For each time step you need in\nthe time horizon, you just",
    "start": "666960",
    "end": "674589"
  },
  {
    "text": "keep repeating the same\niteration over and over. ",
    "start": "674590",
    "end": "680460"
  },
  {
    "start": "680000",
    "end": "839000"
  },
  {
    "text": "OK. Now, the other thing that we\ndiscussed last time, briefly, was a classification of the\ndifferent states of the Markov",
    "start": "680460",
    "end": "688530"
  },
  {
    "text": "chain in two different types. A Markov chain, in general, has\nstates that are recurrent,",
    "start": "688530",
    "end": "697020"
  },
  {
    "text": "which means that from a\nrecurrent state, I can go somewhere else. But from that somewhere else,\nthere's always some way of",
    "start": "697020",
    "end": "704910"
  },
  {
    "text": "coming back. So if you have a chain of this\nform, no matter where you go, no matter where you start,\nyou can always come",
    "start": "704910",
    "end": "712500"
  },
  {
    "text": "back where you started. States of this kind are\ncalled recurrent. On the other hand, if you have\na few states all this kind, a",
    "start": "712500",
    "end": "720320"
  },
  {
    "text": "transition of this type, then\nthese states are transient in the sense that from those\nstates, it's possible to go",
    "start": "720320",
    "end": "727560"
  },
  {
    "text": "somewhere else from which place\nthere's no way to come back where you started.",
    "start": "727560",
    "end": "733580"
  },
  {
    "text": "The general structure of a\nMarkov chain is basically a collection of transient\nstates.",
    "start": "733580",
    "end": "740660"
  },
  {
    "text": "You're certain that you are\ngoing to leave the transient states eventually.",
    "start": "740660",
    "end": "747370"
  },
  {
    "text": "And after you leave the\ntransient states, you enter into a class of states in\nwhich you are trapped.",
    "start": "747370",
    "end": "753570"
  },
  {
    "text": "You are trapped if you\nget inside here. You are trapped if you\nget inside there.",
    "start": "753570",
    "end": "759040"
  },
  {
    "text": "This is a recurrent\nclass of states. From any state, you can\nget to any other state within this class.",
    "start": "759040",
    "end": "764380"
  },
  {
    "text": "That's another recurrent\nclass. From any state inside here,\nyou can get anywhere else inside that class.",
    "start": "764380",
    "end": "770680"
  },
  {
    "text": "But these 2 classes, you\ndo not communicate. If you start here, there's\nno way to get there.",
    "start": "770680",
    "end": "776310"
  },
  {
    "text": "If you have 2 recurrent classes,\nthen it's clear that the initial conditions\nof your Markov chain",
    "start": "776310",
    "end": "782310"
  },
  {
    "text": "matter in the long run. If you start here, you will be\nstuck inside here for the long",
    "start": "782310",
    "end": "787450"
  },
  {
    "text": "run and similarly about here. So the initial conditions\ndo make a difference. On the other hand, if this class\nwas not here and you",
    "start": "787450",
    "end": "794720"
  },
  {
    "text": "only had that class, what would\nhappen to the chain? Let's say you start here. You move around. At some point, you make\nthat transition.",
    "start": "794720",
    "end": "801730"
  },
  {
    "text": "You get stuck in here. And inside here, you keep\ncirculating, because of the randomness, you keep visiting\nall states over and over.",
    "start": "801730",
    "end": "810209"
  },
  {
    "text": "And hopefully or possibly, in\nthe long run, it doesn't",
    "start": "810210",
    "end": "815800"
  },
  {
    "text": "matter exactly what time it is\nor where you started, but the probability of being at that\nparticular state is the same",
    "start": "815800",
    "end": "823860"
  },
  {
    "text": "no matter what the initial\ncondition was. So with a single recurrent\nclass, we hope that the initial conditions\ndo not matter.",
    "start": "823860",
    "end": "830750"
  },
  {
    "text": "With 2 or more recurrent\nclasses, initial conditions",
    "start": "830750",
    "end": "835780"
  },
  {
    "text": "will definitely matter. So how many recurrent classes we\nhave is something that has",
    "start": "835780",
    "end": "843620"
  },
  {
    "start": "839000",
    "end": "985000"
  },
  {
    "text": "to do with the long-term\nbehavior of the chain and the extent to which initial\nconditions matter.",
    "start": "843620",
    "end": "849790"
  },
  {
    "text": "Another way that initial\nconditions may matter is if a",
    "start": "849790",
    "end": "856000"
  },
  {
    "text": "chain has a periodic\nstructure. There are many ways of\ndefining periodicity.",
    "start": "856000",
    "end": "861990"
  },
  {
    "text": "The one that I find sort of the\nmost intuitive and with the least amount\nof mathematical",
    "start": "861990",
    "end": "867410"
  },
  {
    "text": "symbols is the following. The state space of a chain is\nsaid to be periodic if you can",
    "start": "867410",
    "end": "874630"
  },
  {
    "text": "lump the states into a number\nof clusters called d clusters or groups.",
    "start": "874630",
    "end": "882550"
  },
  {
    "text": "And the transition diagram has\nthe property that from a cluster, you always\nmake a transition",
    "start": "882550",
    "end": "888860"
  },
  {
    "text": "into the next cluster. So here d is equal to 2. We have two subsets of\nthe state space.",
    "start": "888860",
    "end": "895570"
  },
  {
    "text": "Whenever we're here, next\ntime we'll be there. Whenever we're here, next\ntime we will be there.",
    "start": "895570",
    "end": "901080"
  },
  {
    "text": "So this chain has a periodic\nstructure. There may be still\nsome randomness. When I jump from here to here,\nthe state to which I jump may",
    "start": "901080",
    "end": "910270"
  },
  {
    "text": "be random, but I'm sure that I'm\ngoing to be inside here. And then next time, I will be\nsure that I'm inside here.",
    "start": "910270",
    "end": "917610"
  },
  {
    "text": "This would be a structure of a\ndiagram in which we have a period of 3. If you start in this lump, you\nknow that the next time, you",
    "start": "917610",
    "end": "925540"
  },
  {
    "text": "would be in a state\ninside here. Next time, you'll be in a state\ninside here, and so on.",
    "start": "925540",
    "end": "930829"
  },
  {
    "text": "So these chains certainly have\na periodic structure. And that periodicity\ngets maintained.",
    "start": "930830",
    "end": "937860"
  },
  {
    "text": "If I start, let's say, at this\nlump, at even times, I'm sure I'm here.",
    "start": "937860",
    "end": "944500"
  },
  {
    "text": "At odd times, I'm\nsure I am here. So the exact time does matter\nin determining the",
    "start": "944500",
    "end": "951600"
  },
  {
    "text": "probabilities of the\ndifferent states. And in particular, the\nprobability of being at the",
    "start": "951600",
    "end": "957139"
  },
  {
    "text": "particular state cannot convert\nto a state value. The probability of being at the\nstate inside here is going",
    "start": "957140",
    "end": "963410"
  },
  {
    "text": "to be 0 for all times. In general, it's going\nto be some positive number for even times.",
    "start": "963410",
    "end": "970160"
  },
  {
    "text": "So it goes 0 positive, zero,\npositive, 0 positive. Doesn't settle to anything.",
    "start": "970160",
    "end": "975370"
  },
  {
    "text": "So when we have periodicity,\nwe do not expect the states probabilities to converge to\nsomething, but rather, we",
    "start": "975370",
    "end": "982600"
  },
  {
    "text": "expect them to oscillate. Now, how can we tell whether\na Markov chain is periodic or not?",
    "start": "982600",
    "end": "989920"
  },
  {
    "start": "985000",
    "end": "1115000"
  },
  {
    "text": "There are systematic ways of\ndoing it, but usually with the types of examples we see in this\nclass, we just eyeball",
    "start": "989920",
    "end": "996560"
  },
  {
    "text": "the chain, and we tell whether\nit's periodic or not. So is this chain down here, is\nit the periodic one or not?",
    "start": "996560",
    "end": "1005240"
  },
  {
    "text": "How many people think\nit's periodic? No one.",
    "start": "1005240",
    "end": "1010680"
  },
  {
    "text": "One. How many people think\nit's not periodic? OK. Not periodic?",
    "start": "1010680",
    "end": "1016270"
  },
  {
    "text": "Let's see. Let me do some drawing here. ",
    "start": "1016270",
    "end": "1023230"
  },
  {
    "text": "OK. Is it periodic?  It is.",
    "start": "1023230",
    "end": "1029140"
  },
  {
    "text": "From a red state, you can only\nget to a white state.",
    "start": "1029140",
    "end": "1034180"
  },
  {
    "text": "And from a white state, you can\nonly get to a red state. So this chain, even though it's\nnot apparent from the",
    "start": "1034180",
    "end": "1040660"
  },
  {
    "text": "picture, actually has\nthis structure. We can group the states into red\nstates and white states.",
    "start": "1040660",
    "end": "1048600"
  },
  {
    "text": "And from reds, we always go to\na white, and from a white, we always go to a red.",
    "start": "1048600",
    "end": "1054500"
  },
  {
    "text": "So this tells you\nthat sometimes eyeballing is not as easy. If you have lots and lots of\nstates, you might have some",
    "start": "1054500",
    "end": "1060810"
  },
  {
    "text": "trouble doing this exercise. On the other hand, something\nvery useful to know.",
    "start": "1060810",
    "end": "1067230"
  },
  {
    "text": "Sometimes it's extremely\neasy to tell that the chain is not periodic.",
    "start": "1067230",
    "end": "1072360"
  },
  {
    "text": "What's that case? Suppose that your chain has a\nself-transition somewhere.",
    "start": "1072360",
    "end": "1078600"
  },
  {
    "text": "Then automatically,\nyou know that your chain is not periodic.",
    "start": "1078600",
    "end": "1084660"
  },
  {
    "text": "So remember, the definition of\nperiodicity requires that if you are in a certain group of\nstates, next time, you will be",
    "start": "1084660",
    "end": "1092230"
  },
  {
    "text": "in a different group. But if you have\nself-transitions, that property is not true.",
    "start": "1092230",
    "end": "1097600"
  },
  {
    "text": "If you have a possible\nself-transition, it's possible that you stay inside your own\ngroup for the next time step.",
    "start": "1097600",
    "end": "1104530"
  },
  {
    "text": "So whenever you have a\nself-transition, this implies",
    "start": "1104530",
    "end": "1109560"
  },
  {
    "text": "that the chain is\nnot periodic.  And usually that's the simplest\nand easy way that we",
    "start": "1109560",
    "end": "1119240"
  },
  {
    "start": "1115000",
    "end": "1390000"
  },
  {
    "text": "can tell most of the time that\nthe chain is not periodic. So now, we come to the big topic\nof today, the central",
    "start": "1119240",
    "end": "1129110"
  },
  {
    "text": "topic, which is the question\nabout what does the chain do in the long run.",
    "start": "1129110",
    "end": "1135549"
  },
  {
    "text": "The question we are asking and\nwhich we motivated last time by looking at an example.",
    "start": "1135550",
    "end": "1142510"
  },
  {
    "text": "It's something that did happen\nin our example of last time. So we're asking whether\nthis happens for",
    "start": "1142510",
    "end": "1148000"
  },
  {
    "text": "every Markov chain. We're asking the question\nwhether the probability of being at state j at some\ntime n settles to a",
    "start": "1148000",
    "end": "1158250"
  },
  {
    "text": "steady-state value. Let's call it pi sub j. That these were asking whether\nthis quantity has a limit as n",
    "start": "1158250",
    "end": "1166960"
  },
  {
    "text": "goes to infinity, so that\nwe can talk about the steady-state probability\nof state j.",
    "start": "1166960",
    "end": "1172300"
  },
  {
    "text": "And furthermore, we asked\nwhether the steady-state probability of that state\ndoes not depend",
    "start": "1172300",
    "end": "1178900"
  },
  {
    "text": "on the initial state. In other words, after the chain\nruns for a long, long",
    "start": "1178900",
    "end": "1184110"
  },
  {
    "text": "time, it doesn't matter exactly\nwhat time it is, and it doesn't matter where the\nchain started from.",
    "start": "1184110",
    "end": "1191990"
  },
  {
    "text": "You can tell me the probability\nthat the state is a particular j is approximately\nthe steady-state",
    "start": "1191990",
    "end": "1198700"
  },
  {
    "text": "probability pi sub j. It doesn't matter exactly what\ntime it is as long as you tell me that a lot of time\nhas elapsed so",
    "start": "1198700",
    "end": "1206900"
  },
  {
    "text": "that n is a big number. So this is the question. We have seen examples, and we\nunderstand that this is not",
    "start": "1206900",
    "end": "1214210"
  },
  {
    "text": "going to be the case always. For example, as I just\ndiscussed, if we have 2",
    "start": "1214210",
    "end": "1219880"
  },
  {
    "text": "recurrent classes, where\nwe start does matter. The probability pi(j) of being\nin that state j is going to be",
    "start": "1219880",
    "end": "1228059"
  },
  {
    "text": "0 if we start here, but it would\nbe something positive if we were to start in that lump.",
    "start": "1228060",
    "end": "1234710"
  },
  {
    "text": "So the initial state does matter\nif we have multiple recurrent classes. But if we have only a single\nclass of recurrent states from",
    "start": "1234710",
    "end": "1245590"
  },
  {
    "text": "each one of which you can get\nto any other one, then we don't have that problem. Then we expect initial\nconditions to be forgotten.",
    "start": "1245590",
    "end": "1253010"
  },
  {
    "text": "So that's one condition\nthat we need. ",
    "start": "1253010",
    "end": "1258960"
  },
  {
    "text": "And then the other condition\nthat we need is that the chain is not periodic. If the chain is periodic, then\nthese Rij's do not converge.",
    "start": "1258960",
    "end": "1267580"
  },
  {
    "text": "They keep oscillating. If we do not have periodicity,\nthen there is hope that we",
    "start": "1267580",
    "end": "1273190"
  },
  {
    "text": "will get the convergence\nthat we need. It turns out this is the big\ntheory of Markov chains-- the",
    "start": "1273190",
    "end": "1279210"
  },
  {
    "text": "steady-state convergence\ntheorem. It turns out that yes, the\nrijs do converge to a",
    "start": "1279210",
    "end": "1286470"
  },
  {
    "text": "steady-state limit, which\nwe call a steady-state probability as long as these two\nconditions are satisfied.",
    "start": "1286470",
    "end": "1295180"
  },
  {
    "text": "We're not going to prove\nthis theorem. If you're really interested, the\nend of chapter exercises",
    "start": "1295180",
    "end": "1301790"
  },
  {
    "text": "basically walk you through a\nproof of this result, but it's probably a little too much for\ndoing it in this class.",
    "start": "1301790",
    "end": "1309470"
  },
  {
    "text": "What is the intuitive idea\nbehind this theorem? Let's see. Let's think intuitively\nas to why the initial",
    "start": "1309470",
    "end": "1316830"
  },
  {
    "text": "state doesn't matter. Think of two copies of the chain\nthat starts at different",
    "start": "1316830",
    "end": "1322870"
  },
  {
    "text": "initial states, and the\nstate moves randomly. As the state moves randomly\nstarting from the two initial",
    "start": "1322870",
    "end": "1329390"
  },
  {
    "text": "states a random trajectory. as long as you have a single\nrecurrent class at some point,",
    "start": "1329390",
    "end": "1335610"
  },
  {
    "text": "and you don't have periodicity\nat some point, those states, those two trajectories,\nare going to collide.",
    "start": "1335610",
    "end": "1342610"
  },
  {
    "text": "Just because there's enough\nrandomness there. Even though we started from\ndifferent places, the state is",
    "start": "1342610",
    "end": "1348830"
  },
  {
    "text": "going to be the same. After the state becomes the\nsame, then the future of these trajectories, probabilistically,\nis the same",
    "start": "1348830",
    "end": "1357100"
  },
  {
    "text": "because they both started\nat the same state. So this means that the\ninitial conditions",
    "start": "1357100",
    "end": "1362540"
  },
  {
    "text": "stopped having any influence. That's sort of the high-level\nidea of why the initial state",
    "start": "1362540",
    "end": "1370039"
  },
  {
    "text": "gets forgotten. Even if you started at different\ninitial states, at some time, you may find yourself\nto be in the same",
    "start": "1370040",
    "end": "1377030"
  },
  {
    "text": "state as the other trajectory. And once that happens, your\ninitial conditions cannot have",
    "start": "1377030",
    "end": "1385370"
  },
  {
    "text": "any effect into the future. All right. So let's see how we might\ncalculate those steady-state",
    "start": "1385370",
    "end": "1395650"
  },
  {
    "start": "1390000",
    "end": "1515000"
  },
  {
    "text": "probabilities. The way we calculate the\nsteady-state probabilities is by taking this recursion, which\nis always true for the",
    "start": "1395650",
    "end": "1404230"
  },
  {
    "text": "end-step transition\nprobabilities, and take the limit of both sides.",
    "start": "1404230",
    "end": "1409400"
  },
  {
    "text": "The limit of this side is the\nsteady-state probability of state j, which is pi sub j.",
    "start": "1409400",
    "end": "1416010"
  },
  {
    "text": "The limit of this\nside, we put the limit inside the summation. Now, as n goes to infinity,\nn - also goes to infinity.",
    "start": "1416010",
    "end": "1424330"
  },
  {
    "text": "So this Rik is going to be the\nsteady-state probability of state k starting from state i.",
    "start": "1424330",
    "end": "1431150"
  },
  {
    "text": "Now where we started\ndoesn't matter. So this is just the\nsteady-state probability of state k.",
    "start": "1431150",
    "end": "1436290"
  },
  {
    "text": "So this term converges to that\none, and this gives us an equation that's satisfied\nby the steady-state",
    "start": "1436290",
    "end": "1443010"
  },
  {
    "text": "probabilities. Actually, it's not\none equation. We get one equation for\neach one of the j's.",
    "start": "1443010",
    "end": "1450580"
  },
  {
    "text": "So if we have 10 possible\nstates, we're going to get the system of 10 linear equations. In the unknowns, pi(1)\nup to pi(10).",
    "start": "1450580",
    "end": "1458840"
  },
  {
    "text": "OK. 10 unknowns, 10 equations. You might think that\nwe are in business. But actually, this system of\nequations is singular.",
    "start": "1458840",
    "end": "1467646"
  },
  {
    "text": "0 is a possible solution\nof this system. If you plug pi equal to\nzero everywhere, the",
    "start": "1467646",
    "end": "1472900"
  },
  {
    "text": "equations are satisfied. It does not have a unique\nsolution, so maybe we need one more condition to get the\nuniquely solvable system of",
    "start": "1472900",
    "end": "1480580"
  },
  {
    "text": "linear equations. It turns out that this\nsystem of equations has a unique solution.",
    "start": "1480580",
    "end": "1486150"
  },
  {
    "text": "If you impose an additional\ncondition, which is pretty natural, the pi(j)'s are the\nprobabilities of the different",
    "start": "1486150",
    "end": "1492160"
  },
  {
    "text": "states, so they should\nadd to 1. So you want this one equation\nto the mix.",
    "start": "1492160",
    "end": "1498409"
  },
  {
    "text": "And once you do that, then this\nsystem of equations is",
    "start": "1498410",
    "end": "1505490"
  },
  {
    "text": "going to have a unique\nsolution. And so we can find the\nsteady-state probabilities of the Markov chain by just\nsolving these linear",
    "start": "1505490",
    "end": "1512980"
  },
  {
    "text": "equations, which is numerically\nstraightforward. Now, these equations are\nquite important.",
    "start": "1512980",
    "end": "1518790"
  },
  {
    "start": "1515000",
    "end": "2015000"
  },
  {
    "text": "I mean, they're the central\npoint in the Markov chain. They have a name.",
    "start": "1518790",
    "end": "1524220"
  },
  {
    "text": "They're called the balance\nequations. And it's worth interpreting\nthem in a",
    "start": "1524220",
    "end": "1531260"
  },
  {
    "text": "somewhat different way. So intuitively, one can\nsometimes think of",
    "start": "1531260",
    "end": "1537029"
  },
  {
    "text": "probabilities as frequencies. For example, if I toss an\nunbiased coin, probability 1/2",
    "start": "1537030",
    "end": "1545780"
  },
  {
    "text": "of heads, you could also say\nthat if I keep flipping that coin, in the long run,\n1/2 of the time, I'm",
    "start": "1545780",
    "end": "1552510"
  },
  {
    "text": "going to see heads. Similarly, let's try an\ninterpretation of this pi(j),",
    "start": "1552510",
    "end": "1558910"
  },
  {
    "text": "the steady-state probability,\nthe long-term probability of finding myself at state j.",
    "start": "1558910",
    "end": "1564980"
  },
  {
    "text": "Let's try to interpret it as\nthe frequency with which I find myself at state j if\nI run a very, very long",
    "start": "1564980",
    "end": "1572620"
  },
  {
    "text": "trajectory over that\nMarkov chain. So the trajectory moves\naround, visits states.",
    "start": "1572620",
    "end": "1578399"
  },
  {
    "text": "It visits the different states\nwith different frequencies. And let's think of the\nprobability that you are at a",
    "start": "1578400",
    "end": "1587380"
  },
  {
    "text": "certain state as being sort of\nthe same as the frequency of visiting that state.",
    "start": "1587380",
    "end": "1594420"
  },
  {
    "text": "This turns out to be a\ncorrect statement. If you were more rigorous, you\nwould have to prove it.",
    "start": "1594420",
    "end": "1601040"
  },
  {
    "text": "But it's an interpretation which\nis valid and which gives us a lot of intuition about what\nthese equation is saying.",
    "start": "1601040",
    "end": "1608560"
  },
  {
    "text": "So let's think as follows. Let's focus on a particular\nstate j, and think of",
    "start": "1608560",
    "end": "1614240"
  },
  {
    "text": "transitions into the state j\nversus transitions out of the",
    "start": "1614240",
    "end": "1620660"
  },
  {
    "text": "state j, or transitions into\nj versus transitions starting from j.",
    "start": "1620660",
    "end": "1627080"
  },
  {
    "text": "So transition starting\nfrom that includes a self-transition. ",
    "start": "1627080",
    "end": "1634980"
  },
  {
    "text": "Ok. So how often do we get a\ntransition, if we interpret the pi(j)'s as frequencies,\nhow often do we get a",
    "start": "1634980",
    "end": "1641230"
  },
  {
    "text": "transition into j? Here's how we think about it. A fraction pi(1) of the time,\nwe're going to be at state 1.",
    "start": "1641230",
    "end": "1651110"
  },
  {
    "text": "Whenever we are at state 1,\nthere's going to be a probability, P1j, that we make\na transition of this kind.",
    "start": "1651110",
    "end": "1660549"
  },
  {
    "text": "So out of the times that we're\nat state 1, there's a frequency, P1j with which the\nnext transition is into j.",
    "start": "1660550",
    "end": "1670141"
  },
  {
    "text": " So out of the overall number of\ntransitions that happen at",
    "start": "1670141",
    "end": "1677870"
  },
  {
    "text": "the trajectory, what fraction\nof those transitions is exactly of that kind?",
    "start": "1677870",
    "end": "1683700"
  },
  {
    "text": "That fraction of transitions is\nthe fraction of time that you find yourself at 1 times the\nfraction with which out of",
    "start": "1683700",
    "end": "1691940"
  },
  {
    "text": "one you happen to visit\nnext state j. So we interpreted this number\nas the frequency of",
    "start": "1691940",
    "end": "1699299"
  },
  {
    "text": "transitions of this kind. At any given time, our chain\ncan do transitions of",
    "start": "1699300",
    "end": "1704780"
  },
  {
    "text": "different kinds, transitions of\nthe general form from some k, I go to some l.",
    "start": "1704780",
    "end": "1710669"
  },
  {
    "text": "So we try to do some\naccounting. How often does a transition of\neach particular kind happen?",
    "start": "1710670",
    "end": "1717740"
  },
  {
    "text": "And this is the frequency with\nwhich transitions of that particular kind happens.",
    "start": "1717740",
    "end": "1722970"
  },
  {
    "text": "Now, what's the total\nfrequency of transitions into state j? Transitions into state j can\nhappen by having a transition",
    "start": "1722970",
    "end": "1729880"
  },
  {
    "text": "from 1 to j, from 2 to j,\nor from state m to j. So to find the total frequency\nwith which we would observe",
    "start": "1729880",
    "end": "1738590"
  },
  {
    "text": "transitions into j is going\nto be this particular sum.",
    "start": "1738590",
    "end": "1743960"
  },
  {
    "text": "Now, you are at state j if and\nonly if the last transition",
    "start": "1743960",
    "end": "1749090"
  },
  {
    "text": "was into state j. So the frequency with which you\nare at j is the frequency",
    "start": "1749090",
    "end": "1756230"
  },
  {
    "text": "with which transitions\ninto j happen. So this equation expresses\nexactly that statement.",
    "start": "1756230",
    "end": "1764020"
  },
  {
    "text": "The probability of being at\nstate j is the sum of the probabilities that the last\ntransition was into state j.",
    "start": "1764020",
    "end": "1772440"
  },
  {
    "text": "Or in terms of frequencies, the\nfrequency with which you find yourself at state j is the\nsum of the frequencies of",
    "start": "1772440",
    "end": "1779170"
  },
  {
    "text": "all the possible transition\ntypes that take you inside state j.",
    "start": "1779170",
    "end": "1785360"
  },
  {
    "text": "So that's a useful intuition\nto have, and we're going to see an example a little later\nthat it gives us short cuts",
    "start": "1785360",
    "end": "1792360"
  },
  {
    "text": "into analyzing Markov chains. But before we move,\nlet's revisit the",
    "start": "1792360",
    "end": "1798270"
  },
  {
    "text": "example from last time. And let us write down\nthe balance",
    "start": "1798270",
    "end": "1803559"
  },
  {
    "text": "equations for this example. So the steady-state probability\nthat I find myself",
    "start": "1803560",
    "end": "1809380"
  },
  {
    "text": "at state 1 is the probability\nthat the previous time I was",
    "start": "1809380",
    "end": "1816370"
  },
  {
    "text": "at state 1 and I made\na self-transition--",
    "start": "1816370",
    "end": "1821550"
  },
  {
    "text": "So the probability that I was\nhere last time and I made a transition of this kind, plus\nthe probability that the last",
    "start": "1821550",
    "end": "1828290"
  },
  {
    "text": "time I was here and I made a\ntransition of that kind. So plus pi(2) times 0.2.",
    "start": "1828290",
    "end": "1836100"
  },
  {
    "text": "And similarly, for the other\nstates, the steady-state",
    "start": "1836100",
    "end": "1843059"
  },
  {
    "text": "probably that I find myself at\nstate 2 is the probability that last time I was at state 1\nand I made a transition into",
    "start": "1843060",
    "end": "1850650"
  },
  {
    "text": "state 2, plus the probability\nthat the last time I was at state 2 and I made the\ntransition into state 1.",
    "start": "1850650",
    "end": "1857750"
  },
  {
    "text": "Now, these are two\nequations and two unknowns, pi(1) and pi(2). But you notice that both of\nthese equations tell you the",
    "start": "1857750",
    "end": "1866150"
  },
  {
    "text": "same thing. They tell you that 0.5pi(1)\nequals 0.2pi(2).",
    "start": "1866150",
    "end": "1872226"
  },
  {
    "start": "1872226",
    "end": "1877769"
  },
  {
    "text": "Either of these equations tell\nyou exactly this if you move terms around.",
    "start": "1877770",
    "end": "1882909"
  },
  {
    "text": "So these two equations are\nnot really two equations. It's just one equation. They are linearly dependent\nequations, and in order to",
    "start": "1882910",
    "end": "1890520"
  },
  {
    "text": "solve the problem, we need the\nadditional condition that pi(1) + pi(2) is equal to 1.",
    "start": "1890520",
    "end": "1896299"
  },
  {
    "text": "Now, we have our system\nof two equations, which you can solve. And once you solve it, you find\nthat pi(1) is 2/7 and",
    "start": "1896300",
    "end": "1905030"
  },
  {
    "text": "pi(2) is 5/7. So these are the steady state\nprobabilities of the two",
    "start": "1905030",
    "end": "1912880"
  },
  {
    "text": "different states.  If we start this chain, at some\nstate, let's say state 1,",
    "start": "1912880",
    "end": "1921770"
  },
  {
    "text": "and we let it run for a long,\nlong time, the chain settles",
    "start": "1921770",
    "end": "1927050"
  },
  {
    "text": "into steady state. What does that mean? It does not mean that\nthe state itself",
    "start": "1927050",
    "end": "1932470"
  },
  {
    "text": "enters steady state. The state will keep jumping\naround forever and ever. It will keep visiting both\nstates once in a while.",
    "start": "1932470",
    "end": "1941040"
  },
  {
    "text": "So the jumping never ceases. The thing that gets into\nsteady state is the probability of finding\nyourself at state 1.",
    "start": "1941040",
    "end": "1950180"
  },
  {
    "text": "So the probability that you find\nyourself at state 1 at time one trillion is\napproximately 2/7.",
    "start": "1950180",
    "end": "1957640"
  },
  {
    "text": "The probability you find\nyourself at state 1 at time two trillions is again,\napproximately 2/7.",
    "start": "1957640",
    "end": "1965590"
  },
  {
    "text": "So the probability of being in\nthat state settles into a steady value.",
    "start": "1965590",
    "end": "1972270"
  },
  {
    "text": "That's what the steady-state\nconvergence means. It's convergence of\nprobabilities, not convergence",
    "start": "1972270",
    "end": "1978370"
  },
  {
    "text": "of the process itself. And again, the two main things\nthat are happening in this",
    "start": "1978370",
    "end": "1984750"
  },
  {
    "text": "example, and more generally,\nwhen we have a single class and no periodicity, is\nthat the initial",
    "start": "1984750",
    "end": "1990649"
  },
  {
    "text": "state does not matter. There's enough randomness here\nso that no matter where you",
    "start": "1990650",
    "end": "1995980"
  },
  {
    "text": "start, the randomness kind of\nwashes out any memory of where you started. And also in this example,\nclearly, we do not have",
    "start": "1995980",
    "end": "2003270"
  },
  {
    "text": "periodicity because\nwe have self arcs. And this, in particular, implies\nthat the exact time",
    "start": "2003270",
    "end": "2010960"
  },
  {
    "text": "does not matter.  So now, we're going to spend\nthe rest of our time by",
    "start": "2010960",
    "end": "2021510"
  },
  {
    "start": "2015000",
    "end": "2200000"
  },
  {
    "text": "looking into a special class\nof chains that's a little easier to deal with,\nbut still, it's",
    "start": "2021510",
    "end": "2027450"
  },
  {
    "text": "an important class. So what's the moral from here? This was a simple example with\ntwo states, and we could find",
    "start": "2027450",
    "end": "2035680"
  },
  {
    "text": "the steady-state probabilities\nby solving a simple system of two-by-two equations.",
    "start": "2035680",
    "end": "2041320"
  },
  {
    "text": "If you have a chain with 100\nstates, it's no problem for a computer to solve a system\nof 100-by-100 equations.",
    "start": "2041320",
    "end": "2049119"
  },
  {
    "text": "But you can certainly not do it\nby hand, and usually, you cannot get any closed-form\nformulas, so you do not",
    "start": "2049120",
    "end": "2055560"
  },
  {
    "text": "necessarily get a\nlot of insight. So one looks for special\nstructures or models that",
    "start": "2055560",
    "end": "2061330"
  },
  {
    "text": "maybe give you a little more\ninsight or maybe lead you to closed-form formulas.",
    "start": "2061330",
    "end": "2067690"
  },
  {
    "text": "And an interesting subclass of\nMarkov chains in which all of these nice things do happen,\nis the class",
    "start": "2067690",
    "end": "2075079"
  },
  {
    "text": "of birth/death processes. So what's a birth/death\nprocess?",
    "start": "2075080",
    "end": "2081500"
  },
  {
    "text": "It's a Markov chain who's\ndiagram looks basically like this.",
    "start": "2081500",
    "end": "2086810"
  },
  {
    "text": "So the states of the Markov\nchain start from 0 and go up",
    "start": "2086810",
    "end": "2092020"
  },
  {
    "text": "to some finite integer m. What's special about this chain\nis that if you are at a",
    "start": "2092020",
    "end": "2097400"
  },
  {
    "text": "certain state, next time you can\neither go up by 1, you can",
    "start": "2097400",
    "end": "2102710"
  },
  {
    "text": "go down by 1, or you\ncan stay in place. So it's like keeping track\nof some population",
    "start": "2102710",
    "end": "2109819"
  },
  {
    "text": "at any given time. One person gets born,\nor one person dies, or nothing happens.",
    "start": "2109820",
    "end": "2115680"
  },
  {
    "text": "Again, we're not accounting\nfor twins here. So we're given this structure,\nand we are given the",
    "start": "2115680",
    "end": "2124430"
  },
  {
    "text": "transition probabilities, the\nprobabilities associated with transitions of the\ndifferent types.",
    "start": "2124430",
    "end": "2129630"
  },
  {
    "text": "So we use P's for the upward\ntransitions, Q's for the downward transitions. An example of a chain of this\nkind was the supermarket",
    "start": "2129630",
    "end": "2137830"
  },
  {
    "text": "counter model that we\ndiscussed last time. That is, a customer arrives,\nso this increments",
    "start": "2137830",
    "end": "2145079"
  },
  {
    "text": "the state by 1. Or a customer finishes service,\nin which case, the state gets decremented by 1,\nor nothing happens in which",
    "start": "2145080",
    "end": "2153020"
  },
  {
    "text": "you stay in place, and so on. In the supermarket model, these\nP's inside here were all",
    "start": "2153020",
    "end": "2159880"
  },
  {
    "text": "taken to be equal because we\nassume that the arrival rate was sort of constant\nat each time slot.",
    "start": "2159880",
    "end": "2167400"
  },
  {
    "text": "But you can generalize a little\nbit by assuming that these transition probabilities\nP1 here, P2 there, and so on",
    "start": "2167400",
    "end": "2175330"
  },
  {
    "text": "may be different from\nstate to state. So in general, from state\ni, there's going to be a",
    "start": "2175330",
    "end": "2181750"
  },
  {
    "text": "transition probability\nPi that the next transition is upwards. And there's going to be a\nprobability Qi that the next",
    "start": "2181750",
    "end": "2189820"
  },
  {
    "text": "transition is downwards. And so from that state, the\nprobability that the next",
    "start": "2189820",
    "end": "2195309"
  },
  {
    "text": "transition is downwards is\ngoing to be Q_(i+1). ",
    "start": "2195310",
    "end": "2200930"
  },
  {
    "text": "So this is the structure\nof our chain. As I said, it's a crude model\nof what happens at the",
    "start": "2200930",
    "end": "2207579"
  },
  {
    "text": "supermarket counter but it's\nalso a good model for lots of",
    "start": "2207580",
    "end": "2213820"
  },
  {
    "text": "types of service systems. Again, you have a server\nsomewhere that has a buffer.",
    "start": "2213820",
    "end": "2219400"
  },
  {
    "text": "Jobs come into the buffer. So the buffer builds up. The server processes jobs, so\nthe buffer keeps going down.",
    "start": "2219400",
    "end": "2226880"
  },
  {
    "text": "And the state of the chain would\nbe the number of jobs that you have inside\nyour buffer.",
    "start": "2226880",
    "end": "2232570"
  },
  {
    "text": "Or you could be thinking about\nactive phone calls out of a",
    "start": "2232570",
    "end": "2238690"
  },
  {
    "text": "certain city. Each time that the phone call\nis placed, the number of active phone calls\ngoes up by 1.",
    "start": "2238690",
    "end": "2244090"
  },
  {
    "text": "Each time that the phone call\nstops happening, is terminated, then the count\ngoes down by 1.",
    "start": "2244090",
    "end": "2251790"
  },
  {
    "text": "So it's for processes of this\nkind that a model with this structure is going to show up.",
    "start": "2251790",
    "end": "2256890"
  },
  {
    "text": "And they do show up in\nmany, many models. Or you can think about the\nnumber of people in a certain",
    "start": "2256890",
    "end": "2263730"
  },
  {
    "text": "population that have\na disease. So 1 more person gets the\nflu, the count goes up.",
    "start": "2263730",
    "end": "2271010"
  },
  {
    "text": "1 more person gets healed,\nthe count goes down. And these probabilities in such\nan epidemic model would",
    "start": "2271010",
    "end": "2278350"
  },
  {
    "text": "certainly depend on\nthe current state. If lots of people already have\nthe flu, the probability that",
    "start": "2278350",
    "end": "2286280"
  },
  {
    "text": "another person catches it\nwould be pretty high. Whereas, if no one has the flu,\nthen the probability that",
    "start": "2286280",
    "end": "2293800"
  },
  {
    "text": "you get a transition where\nsomeone catches the flu, that probability would\nbe pretty small.",
    "start": "2293800",
    "end": "2298960"
  },
  {
    "text": "So the transition rates, the\nincidence of new people who",
    "start": "2298960",
    "end": "2306990"
  },
  {
    "text": "have the disease definitely\ndepends on how many people already have the disease. And that motivates cases where\nthose P's, the upward",
    "start": "2306990",
    "end": "2314970"
  },
  {
    "text": "transition probabilities,\ndepend on the state of the chain.",
    "start": "2314970",
    "end": "2322400"
  },
  {
    "text": "So how do we study this chain? You can sit down and write the\nsystem of n linear equations",
    "start": "2322400",
    "end": "2329220"
  },
  {
    "text": "in the pi's. And this way, find the\nsteady-state probabilities of this chain. But this is a little harder.",
    "start": "2329220",
    "end": "2335850"
  },
  {
    "text": "It's more work than one\nactually needs to do. There's a very clever shortcut\nthat applies",
    "start": "2335850",
    "end": "2343200"
  },
  {
    "text": "to birth/death processes. And it's based on the frequency\ninterpretation that",
    "start": "2343200",
    "end": "2348410"
  },
  {
    "text": "we discussed a little\nwhile ago. ",
    "start": "2348410",
    "end": "2354070"
  },
  {
    "text": "Let's put a line somewhere in\nthe middle of this chain, and focus on the relation between\nthis part and that part in",
    "start": "2354070",
    "end": "2361710"
  },
  {
    "text": "more detail. So think of the chain continuing\nin this direction, that direction. But let's just focus on 2\nadjacent states, and look at",
    "start": "2361710",
    "end": "2370019"
  },
  {
    "text": "this particular cut. What is the chain going to do? Let's say it starts here.",
    "start": "2370020",
    "end": "2375550"
  },
  {
    "text": "It's going to move around. At some point, it makes a\ntransition to the other side. And that's a transition\nfrom i to i+1.",
    "start": "2375550",
    "end": "2382860"
  },
  {
    "text": "It stays on the other\nside for some time. It gets here, and eventually,\nit's going to make a",
    "start": "2382860",
    "end": "2388490"
  },
  {
    "text": "transition to this side. Then it keeps moving\nand so on. Now, there's a certain balance\nthat must be obeyed here.",
    "start": "2388490",
    "end": "2397680"
  },
  {
    "text": "The number of upward transitions\nthrough this line cannot be very different from\nthe number of downward",
    "start": "2397680",
    "end": "2404220"
  },
  {
    "text": "transitions. Because we cross this\nway, then next time,",
    "start": "2404220",
    "end": "2409530"
  },
  {
    "text": "we'll cross that way. Then next time, we'll\ncross this way. We'll cross that way. So the frequency with which\ntransitions of this kind occur",
    "start": "2409530",
    "end": "2418940"
  },
  {
    "text": "has to be the same as the\nlong-term frequency that transitions of that\nkind occur.",
    "start": "2418940",
    "end": "2424430"
  },
  {
    "text": "You cannot go up 100 times and\ngo down only 50 times. If you have gone up 100 times,\nit means that you have gone",
    "start": "2424430",
    "end": "2431740"
  },
  {
    "text": "down 99, or 100, or 101,\nbut nothing much more",
    "start": "2431740",
    "end": "2436960"
  },
  {
    "text": "different than that. So the frequency with\nwhich transitions of this kind get observed.",
    "start": "2436960",
    "end": "2443670"
  },
  {
    "text": "That is, out of a large number\nof transitions, what fraction of transitions are\nof these kind?",
    "start": "2443670",
    "end": "2449890"
  },
  {
    "text": "That fraction has to be the\nsame as the fraction of transitions that happened\nto be of that kind. What are these fractions?",
    "start": "2449890",
    "end": "2456620"
  },
  {
    "text": "We discussed that before. The fraction of times at which\ntransitions of this kind are",
    "start": "2456620",
    "end": "2464840"
  },
  {
    "text": "observed is the fraction of time\nthat we happen to be at that state. And out of the times that we\nare in that state, the",
    "start": "2464840",
    "end": "2471790"
  },
  {
    "text": "fraction of transitions that\nhappen to be upward transitions. So this is the frequency with\nwhich transitions of this kind",
    "start": "2471790",
    "end": "2480820"
  },
  {
    "text": "are observed. And with the same argument,\nthis is the frequency with which transitions of that\nkind are observed.",
    "start": "2480820",
    "end": "2488670"
  },
  {
    "text": "Since these two frequencies\nare the same, these two numbers must be the same, and\nwe get an equation that",
    "start": "2488670",
    "end": "2494390"
  },
  {
    "text": "relates the Pi to P_(i+1). This has a nice form because\nit gives us a recursion.",
    "start": "2494390",
    "end": "2503040"
  },
  {
    "text": "If we knew pi(i), we could then immediately calculate pi(i+1).",
    "start": "2503040",
    "end": "2508860"
  },
  {
    "text": "So it's a system of equations\nthat's very easy to solve almost.",
    "start": "2508860",
    "end": "2514860"
  },
  {
    "text": "But how do we get started? If I knew pi(0), I could find\nby pi(1) and then use this",
    "start": "2514860",
    "end": "2521850"
  },
  {
    "text": "recursion to find pi(2),\npi(3), and so on. But we don't know pi(0).",
    "start": "2521850",
    "end": "2526970"
  },
  {
    "text": "It's one more unknown. It's an unknown, and we need\nto actually use the extra",
    "start": "2526970",
    "end": "2534290"
  },
  {
    "text": "normalization condition that\nthe sum of the pi's is 1.",
    "start": "2534290",
    "end": "2540000"
  },
  {
    "text": "And after we use that\nnormalization condition, then we can find all of the pi's.",
    "start": "2540000",
    "end": "2546580"
  },
  {
    "start": "2546580",
    "end": "2552550"
  },
  {
    "start": "2552000",
    "end": "3084000"
  },
  {
    "text": "So you basically fix pi(0) as a\nsymbol, solve this equation",
    "start": "2552550",
    "end": "2558450"
  },
  {
    "text": "symbolically, and\neverything gets expressed in terms of pi(0).",
    "start": "2558450",
    "end": "2563830"
  },
  {
    "text": "And then use that normalization\ncondition to find pi(0), and you're done. Let's illustrate the details\nof this procedure on a",
    "start": "2563830",
    "end": "2571570"
  },
  {
    "text": "particular special case. So in our special case, we're\ngoing to simplify things now",
    "start": "2571570",
    "end": "2577359"
  },
  {
    "text": "by assuming that all those\nupward P's are the same, and all of those downward\nQ's are the same.",
    "start": "2577360",
    "end": "2585780"
  },
  {
    "text": "So at each point in time, if\nyou're sitting somewhere in the middle, you have probability\nP of moving up and",
    "start": "2585780",
    "end": "2593060"
  },
  {
    "text": "probability Q of moving down. This rho, the ratio of P/Q is\nfrequency of going up versus",
    "start": "2593060",
    "end": "2603460"
  },
  {
    "text": "frequency of going down. If it's a service system, you\ncan think of it as a measure",
    "start": "2603460",
    "end": "2609069"
  },
  {
    "text": "of how loaded the system is. If P is equal to Q, it's means\nthat if you're at this state,",
    "start": "2609070",
    "end": "2619099"
  },
  {
    "text": "you're equally likely to move\nleft or right, so the system is kind of balanced.",
    "start": "2619100",
    "end": "2624820"
  },
  {
    "text": "The state doesn't have a\ntendency to move in this direction or in that\ndirection. If rho is bigger than 1 so that\nP is bigger than Q, it",
    "start": "2624820",
    "end": "2633859"
  },
  {
    "text": "means that whenever I'm at some\nstate in the middle, I'm more likely to move right rather\nthan move left, which",
    "start": "2633860",
    "end": "2640830"
  },
  {
    "text": "means that my state, of course\nit's random, but it has a tendency to move in\nthat direction.",
    "start": "2640830",
    "end": "2647170"
  },
  {
    "text": "And if you think of this as a\nnumber of customers in queue, it means your system has the\ntendency to become loaded and",
    "start": "2647170",
    "end": "2653750"
  },
  {
    "text": "to build up a queue. So rho being bigger than 1\ncorresponds to a heavy load,",
    "start": "2653750",
    "end": "2659790"
  },
  {
    "text": "where queues build up. Rho less than 1 corresponds to\nthe system where queues have",
    "start": "2659790",
    "end": "2665470"
  },
  {
    "text": "the tendency to drain down. ",
    "start": "2665470",
    "end": "2670880"
  },
  {
    "text": "Now, let's write down\nthe equations. We have this recursion P_(i+1)\nis Pi times Pi over Qi.",
    "start": "2670880",
    "end": "2680540"
  },
  {
    "text": "In our case here, the P's and\nthe Q's do not depend on the particular index, so we\nget this relation.",
    "start": "2680540",
    "end": "2687190"
  },
  {
    "text": "And this P over Q is just\nthe load factor rho. Once you look at this equation,\nclearly you realize",
    "start": "2687190",
    "end": "2694790"
  },
  {
    "text": "that by pi(1) is rho\ntimes pi(0). pi(2) is going to be --",
    "start": "2694790",
    "end": "2702286"
  },
  {
    "text": "So we'll do it in detail. So pi(1) is pi(0) times rho.",
    "start": "2702286",
    "end": "2708130"
  },
  {
    "text": "pi(2) is pi(1) times rho,\nwhich is pi(0) times",
    "start": "2708130",
    "end": "2715579"
  },
  {
    "text": "rho-squared. And then you continue doing\nthis calculation.",
    "start": "2715580",
    "end": "2721340"
  },
  {
    "text": "And you find that you can\nexpress every pi(i) in terms of pi(0) and you get this\nfactor of rho^i.",
    "start": "2721340",
    "end": "2731490"
  },
  {
    "text": "And then you use the last\nequation that we have -- that the sum of the probabilities\nhas to be equal to 1.",
    "start": "2731490",
    "end": "2738110"
  },
  {
    "text": "And that equation is going to\ntell us that the sum over all i's from 0 to m of pi(0) rho\nto the i is equal to 1.",
    "start": "2738110",
    "end": "2750890"
  },
  {
    "text": "And therefore, pi(0) is 1 over\n(the sum over the rho to the i",
    "start": "2750890",
    "end": "2758730"
  },
  {
    "text": "for i going from 0 to m). So now we found pi(0), and by\nplugging in this expression,",
    "start": "2758730",
    "end": "2769870"
  },
  {
    "text": "we have the steady-state\nprobabilities of all of the different states.",
    "start": "2769870",
    "end": "2774950"
  },
  {
    "text": "Let's look at some special\ncases of this. Suppose that rho\nis equal to 1.",
    "start": "2774950",
    "end": "2784390"
  },
  {
    "text": "If rho is equal to 1, then\npi(i) is equal to pi(0).",
    "start": "2784390",
    "end": "2790410"
  },
  {
    "text": "It means that all\nthe steady-state probabilities are equal.",
    "start": "2790410",
    "end": "2795840"
  },
  {
    "text": "It's means that every\nstate is equally likely in the long run.",
    "start": "2795840",
    "end": "2802750"
  },
  {
    "text": "So this is an example. It's called a symmetric\nrandom walk.",
    "start": "2802750",
    "end": "2808730"
  },
  {
    "text": "It's a very popular model for\nmodeling people who are drunk. So you start at a state\nat any point in time.",
    "start": "2808730",
    "end": "2816730"
  },
  {
    "text": "Either you stay in place, or you\nhave an equal probability of going left or going right.",
    "start": "2816730",
    "end": "2822910"
  },
  {
    "text": "There's no bias in\neither direction. You might think that in such a\nprocess, you will tend to kind",
    "start": "2822910",
    "end": "2830710"
  },
  {
    "text": "of get stuck near one end\nor the other end. Well, it's not really clear\nwhat to expect.",
    "start": "2830710",
    "end": "2837320"
  },
  {
    "text": "It turns out that in such a\nmodel, in the long run, the drunk person is equally\nlikely to be at any",
    "start": "2837320",
    "end": "2844610"
  },
  {
    "text": "one of those states. The steady-state probability is\nthe same for all i's if rho",
    "start": "2844610",
    "end": "2851300"
  },
  {
    "text": "is equal to 1. And so if you show up at a\nrandom time, and you ask where",
    "start": "2851300",
    "end": "2859569"
  },
  {
    "text": "is my state, you will be told\nit's equally likely to be at any one of those places.",
    "start": "2859570",
    "end": "2866599"
  },
  {
    "text": "So let's make that note. If rho equal to 1, implies\nthat all the",
    "start": "2866600",
    "end": "2871980"
  },
  {
    "text": "pi(i)'s are 1/(M+1) -- ",
    "start": "2871980",
    "end": "2877039"
  },
  {
    "text": "M+1 because that's how many\nstates we have in our model. Now, let's look at\na different case.",
    "start": "2877040",
    "end": "2884210"
  },
  {
    "text": "Suppose that M is\na huge number. So essentially, our supermarket\nhas a very large",
    "start": "2884210",
    "end": "2893599"
  },
  {
    "text": "space, a lot of space to\nstore their customers.",
    "start": "2893600",
    "end": "2899600"
  },
  {
    "text": "But suppose that the system\nis on the stable side. P is less than Q, which means\nthat there's a tendency for",
    "start": "2899600",
    "end": "2907900"
  },
  {
    "text": "customers to be served faster\nthan they arrive. The drift in this chain, it\ntends to be in that direction.",
    "start": "2907900",
    "end": "2915500"
  },
  {
    "text": "So when rho is less than 1,\nwhich is this case, and when M",
    "start": "2915500",
    "end": "2921920"
  },
  {
    "text": "is going to infinity, this\ninfinite sum is the sum of a geometric series.",
    "start": "2921920",
    "end": "2927690"
  },
  {
    "text": "And you recognize it\n(hopefully) -- ",
    "start": "2927690",
    "end": "2933480"
  },
  {
    "text": "this series is going\nto 1/(1-rho). And because it's in the\ndenominator, pi(0) ends up",
    "start": "2933480",
    "end": "2940280"
  },
  {
    "text": "being 1-rho. So by taking the limit as M\ngoes to infinity, in this",
    "start": "2940280",
    "end": "2946230"
  },
  {
    "text": "case, and when rho is less than\n1 so that this series is convergent, we get\nthis formula.",
    "start": "2946230",
    "end": "2952220"
  },
  {
    "text": "So we get the closed-form\nformula for the pi(i)'s. In particular, pi(i) is (1-\nrho)(rho to the i).",
    "start": "2952220",
    "end": "2959840"
  },
  {
    "text": "to So these pi(i)'s are essentially\na probability distribution.",
    "start": "2959840",
    "end": "2966200"
  },
  {
    "text": "They tell us if we show up at\ntime 1 billion and we ask,",
    "start": "2966200",
    "end": "2972099"
  },
  {
    "text": "where is my state? You will be told that\nthe state is 0.",
    "start": "2972100",
    "end": "2977500"
  },
  {
    "text": "Your system is empty with\nprobability 1-rho, minus or there's one customer in the\nsystem, and that happens with",
    "start": "2977500",
    "end": "2984410"
  },
  {
    "text": "probability (rho\n- 1) times rho. And it keeps going\ndown this way.",
    "start": "2984410",
    "end": "2989950"
  },
  {
    "text": "And it's pretty much a geometric\ndistribution except that it has shifted so that it\nstarts at 0 whereas the usual",
    "start": "2989950",
    "end": "2998130"
  },
  {
    "text": "geometric distribution\nstarts at 1. So this is a mini introduction\ninto queuing theory.",
    "start": "2998130",
    "end": "3004670"
  },
  {
    "text": "This is the first and simplest\nmodel that one encounters when you start studying\nqueuing theory.",
    "start": "3004670",
    "end": "3010850"
  },
  {
    "text": "This is clearly a model of a\nqueueing phenomenon such as the supermarket counter with\nthe P's corresponding to",
    "start": "3010850",
    "end": "3016450"
  },
  {
    "text": "arrivals, the Q's corresponding\nto departures. And this particular queuing\nsystem when M is very, very",
    "start": "3016450",
    "end": "3022690"
  },
  {
    "text": "large and rho is less than 1,\nhas a very simple and nice solution in closed form.",
    "start": "3022690",
    "end": "3028880"
  },
  {
    "text": "And that's why it's\nvery much liked. And let me just take\ntwo seconds to draw one last picture.",
    "start": "3028880",
    "end": "3038030"
  },
  {
    "text": "So this is the probability\nof the different i's. It gives you a PMF. This PMF has an expected\nvalue.",
    "start": "3038030",
    "end": "3043890"
  },
  {
    "text": "And the expectation, the\nexpected number of customers in the system, is given\nby this formula.",
    "start": "3043890",
    "end": "3050560"
  },
  {
    "text": "And this formula, which is\ninteresting to anyone who tries to analyze a system\nof this kind,",
    "start": "3050560",
    "end": "3057070"
  },
  {
    "text": "tells you the following. That as long as a rho is less\nthan 1, then the expected",
    "start": "3057070",
    "end": "3063970"
  },
  {
    "text": "number of customers in\nthe system is finite. But if rho becomes very\nclose to 1 --",
    "start": "3063970",
    "end": "3069970"
  },
  {
    "text": "So if your load factor is\nsomething like .99, you expect to have a large number of\ncustomers in the system at any",
    "start": "3069970",
    "end": "3077630"
  },
  {
    "text": "given time. OK. All right. Have a good weekend.",
    "start": "3077630",
    "end": "3083270"
  },
  {
    "text": "We'll continue next time.",
    "start": "3083270",
    "end": "3085390"
  }
]
[
  {
    "start": "0",
    "end": "114000"
  },
  {
    "start": "0",
    "end": "15700"
  },
  {
    "text": "DAVID SONTAG: So today's lecture\nis going to be about causality. ",
    "start": "15700",
    "end": "22102"
  },
  {
    "text": "Who's heard about\ncausality before? Raise your hand. ",
    "start": "22102",
    "end": "27130"
  },
  {
    "text": "What's the number one thing\nthat you hear about when thinking about causality?",
    "start": "27130",
    "end": "33210"
  },
  {
    "text": "Yeah? AUDIENCE: Correlation\ndoes not imply causation. DAVID SONTAG: Correlation\ndoes not imply causation.",
    "start": "33210",
    "end": "39465"
  },
  {
    "text": "Anything else come to mind? That's what came to my mind. Anything else come to mind? ",
    "start": "39465",
    "end": "46560"
  },
  {
    "text": "So up until now in\nthe semester, we've been talking about purely\npredictive questions. And for purely\npredictive questions,",
    "start": "46560",
    "end": "52949"
  },
  {
    "text": "one could argue that\ncorrelation is good enough. If we have some\nsigns in our data that are predictive of\nsome outcome of interest,",
    "start": "52950",
    "end": "60355"
  },
  {
    "text": "we want to be able to\ntake advantage of that. Whether it's\nupstream, downstream, the causal directionality is\nirrelevant for that purpose.",
    "start": "60355",
    "end": "70020"
  },
  {
    "text": "Although even that\nisn't quite true, right, because Pete and I have been\nhinting throughout the semester",
    "start": "70020",
    "end": "76049"
  },
  {
    "text": "that there are times\nwhen the data changes on you, for example, when you go\nfrom one institution to another",
    "start": "76050",
    "end": "83370"
  },
  {
    "text": "or when you have non-stationary. And in those situations,\nhaving a deeper understanding",
    "start": "83370",
    "end": "90210"
  },
  {
    "text": "about the data might\nallow one to build an additional robustness to\nthat type of data set shift.",
    "start": "90210",
    "end": "95790"
  },
  {
    "text": "But there are other\nreasons as well why understanding something about\nyour underlying data generating processes can be\nreally important.",
    "start": "95790",
    "end": "101795"
  },
  {
    "text": "It's because often,\nthe questions that we want to answer when\nit comes to health care are not predictive questions,\ntheir causal questions.",
    "start": "101795",
    "end": "108542"
  },
  {
    "text": "And so what I'll do now is I'll\nwalk through a few examples of what I mean by this. Let's start out with what we saw\nin Lecture 4 and in Problem Set",
    "start": "108542",
    "end": "117100"
  },
  {
    "start": "114000",
    "end": "114000"
  },
  {
    "text": "2, where we looked\nat the question of how we can do early\ndetection of type 2 diabetes.",
    "start": "117100",
    "end": "122480"
  },
  {
    "text": " You used Truven\nMarketScan's data",
    "start": "122480",
    "end": "128300"
  },
  {
    "text": "set to build a\nrisk stratification algorithm for\ndetecting who is going",
    "start": "128300",
    "end": "134855"
  },
  {
    "text": "to be newly diagnosed\nwith diabetes one to three years from now. And if you think about\nhow one might then try to deploy that\nalgorithm, you",
    "start": "134855",
    "end": "141700"
  },
  {
    "text": "might, for example, try to\nget patients into the clinic to get them diagnosed.",
    "start": "141700",
    "end": "148200"
  },
  {
    "text": "But the next set of\nquestions are usually about the so what question. What are you going to do\nbased on that prediction?",
    "start": "148200",
    "end": "155040"
  },
  {
    "text": "Once diagnosed, how\nwill you intervene? And at the end of the\nday, the interesting goal is not one of how do\nyou find them early,",
    "start": "155040",
    "end": "161412"
  },
  {
    "text": "but how do you prevent them\nfrom developing diabetes? Or how do you prevent the\npatient from developing complications of diabetes?",
    "start": "161412",
    "end": "167130"
  },
  {
    "text": " And those are questions\nabout causality.",
    "start": "167130",
    "end": "174550"
  },
  {
    "text": "Now, when we built\na predictive model and we introspected\nat the weight, we might have noticed\nsome interesting things.",
    "start": "174550",
    "end": "179900"
  },
  {
    "text": "For example, if you looked at\nthe highest negative weights, which I'm not sure if we did\nas part of the assignment",
    "start": "179900",
    "end": "187430"
  },
  {
    "text": "but is something that I did\nas part of my research study, you see that gastric\nbypass surgery has the biggest negative weight.",
    "start": "187430",
    "end": "196330"
  },
  {
    "text": "Does that mean that if you give\nan obese person gastric bypass surgery, that will prevent\nthem from developing type 2",
    "start": "196330",
    "end": "204519"
  },
  {
    "text": "diabetes? That's an example of a causal\nquestion which is raised by this predictive model.",
    "start": "204520",
    "end": "210105"
  },
  {
    "text": "But just by looking\nat the weight alone, as I'll\nshow you this week, you won't be able to\ncorrectly infer that there",
    "start": "210105",
    "end": "218060"
  },
  {
    "text": "is a causal relationship. And so part of what\nwe will be doing is coming up with a mathematical\nlanguage for thinking",
    "start": "218060",
    "end": "225069"
  },
  {
    "text": "about how does one\nanswer, is there a causal relationship here? Here's a second example.",
    "start": "225070",
    "end": "231750"
  },
  {
    "text": "Right before spring break\nwe had a series of lectures about diagnosis,\nparticularly diagnosis",
    "start": "231750",
    "end": "237120"
  },
  {
    "text": "from imaging data of\na variety of kinds, whether it be\nradiology or pathology.",
    "start": "237120",
    "end": "243240"
  },
  {
    "text": "And often, questions\nare of this sort. Here is a woman's breasts. She has breast cancer.",
    "start": "243240",
    "end": "249209"
  },
  {
    "text": "Maybe you have an associated\npathology slide as well. And you want to know what is\nthe risk of this person dying",
    "start": "249210",
    "end": "256799"
  },
  {
    "text": "in the next five years. So one can take a\ndeep learning model,",
    "start": "256800",
    "end": "263340"
  },
  {
    "text": "learn to predict\nwhat one observes. So in the patient in your\ndata set, you have the input",
    "start": "263340",
    "end": "268950"
  },
  {
    "text": "and you have, let's\nsay, survival time. And you might use that\nto predict something about how long it takes\nfrom diagnosis to death.",
    "start": "268950",
    "end": "278510"
  },
  {
    "text": "And based on those predictions,\nyou might take actions. For example, if you predict\nthat a patient is not risky,",
    "start": "278510",
    "end": "288290"
  },
  {
    "text": "then you might\nconclude that they don't need to get treatment.",
    "start": "288290",
    "end": "294010"
  },
  {
    "text": "But that could be\nreally, really dangerous, and I'll just give\nyou one example",
    "start": "294010",
    "end": "301450"
  },
  {
    "text": "of why that could be dangerous.  These predictive models,\nif you're learning them",
    "start": "301450",
    "end": "308210"
  },
  {
    "text": "in this way, the outcome,\nin this case let's say time to death, is\ngoing to be affected",
    "start": "308210",
    "end": "314630"
  },
  {
    "text": "by what's happened in between. So, for example,\nthis patient might",
    "start": "314630",
    "end": "319880"
  },
  {
    "text": "have been receiving\ntreatment, and because of them receiving treatment in\nbetween the time from diagnosis",
    "start": "319880",
    "end": "326510"
  },
  {
    "text": "to death, it might have\nprolonged their life. And so for this patient\nin your data set,",
    "start": "326510",
    "end": "331910"
  },
  {
    "text": "you might have observed that\nthey lived a very long time. But if you ignore what\nhappens in between",
    "start": "331910",
    "end": "337320"
  },
  {
    "text": "and you simply learn to predict\ny from X, X being the input, then a new patient comes\nalong and you predicted",
    "start": "337320",
    "end": "343850"
  },
  {
    "text": "that new patient is going\nto survive a long time, and it would be completely\nthe wrong conclusion to say that you don't need\nto treat that patient.",
    "start": "343850",
    "end": "350857"
  },
  {
    "text": "Because, in fact, the only\nreason the patients like them in the training data\nlived a long time is because they were treated.",
    "start": "350857",
    "end": "357400"
  },
  {
    "text": "And so when it comes to this\nfield of machine learning and health care, we need\nto think really carefully",
    "start": "357400",
    "end": "363850"
  },
  {
    "text": "about these types of questions\nbecause an error in the way that we formalize our\nproblem could kill people",
    "start": "363850",
    "end": "369080"
  },
  {
    "text": "because of mistakes like this.  Now, other questions\nare ones about not how",
    "start": "369080",
    "end": "376350"
  },
  {
    "text": "do we predict\noutcomes but how do we guide treatment decisions.",
    "start": "376350",
    "end": "383360"
  },
  {
    "text": "So, for example, as\ndata from pathology gets richer and\nricher and richer,",
    "start": "383360",
    "end": "388370"
  },
  {
    "text": "we might think that we\ncan now use computers to try to better predict\nwho is likely to benefit",
    "start": "388370",
    "end": "393860"
  },
  {
    "text": "from a treatment than\nhumans could do alone.  But the challenge\nwith using algorithms",
    "start": "393860",
    "end": "400470"
  },
  {
    "text": "to do that is that people\nrespond differently to treatment, and the\ndata which is being",
    "start": "400470",
    "end": "405840"
  },
  {
    "text": "used to guide treatment is\nbiased based on existing",
    "start": "405840",
    "end": "411449"
  },
  {
    "text": "treatment guidelines.  So, similarly, to the previous\nquestion, we could ask,",
    "start": "411450",
    "end": "418819"
  },
  {
    "text": "what would happen if we trained\nto predict past treatment decisions? This would be the\nmost naive way to try",
    "start": "418820",
    "end": "424015"
  },
  {
    "text": "to use data to guide\ntreatment decisions. So maybe you see David\ngets treatment A, John gets treatment B,\nJuana gets treatment A.",
    "start": "424015",
    "end": "431449"
  },
  {
    "text": "And you might ask then,\nOK, a new patient comes in, what should this new\npatient be treated with?",
    "start": "431450",
    "end": "437473"
  },
  {
    "text": "And if you've just\nlearned a model to predict from what you\nknow about the treatment that David is likely\nto get, then the best",
    "start": "437473",
    "end": "443990"
  },
  {
    "text": "that you could hope\nto do is to do as well as existing clinical practice.",
    "start": "443990",
    "end": "449850"
  },
  {
    "text": "So if we want to go beyond\ncurrent clinical practice, for example, to recognize\nthat there is heterogeneity",
    "start": "449850",
    "end": "455780"
  },
  {
    "text": "in treatment response, then\nwe have to somehow change the question that we're asking.",
    "start": "455780",
    "end": "464090"
  },
  {
    "text": "I'll give you one\nlast example, which is perhaps a more traditional\nquestion of, does X cause y?",
    "start": "464090",
    "end": "470600"
  },
  {
    "start": "465000",
    "end": "465000"
  },
  {
    "text": "For example, does\nsmoking cause lung cancer is a major question of\nsocietal importance.",
    "start": "470600",
    "end": "479080"
  },
  {
    "text": "Now, you might be familiar\nwith the traditional way of trying to answer questions\nof this nature, which",
    "start": "479080",
    "end": "485170"
  },
  {
    "text": "would be to do a randomized\ncontrolled trial. Except this isn't\nexactly the type of setting where you could do\nrandomized controlled trials.",
    "start": "485170",
    "end": "491830"
  },
  {
    "text": "How would you feel if you were\na smoker and someone came up",
    "start": "491830",
    "end": "497169"
  },
  {
    "text": "to you and said, you have\nto stop smoking because I need to see what happens? Or how would you feel\nif you were a non-smoker",
    "start": "497170",
    "end": "503230"
  },
  {
    "text": "and someone came\nup to you and said, you have to start smoking? That would be both not feasible\nand completely unethical.",
    "start": "503230",
    "end": "511930"
  },
  {
    "text": "And so if we want to\ntry to answer questions like this from data,\nwe need to start thinking about\nhow can we design,",
    "start": "511930",
    "end": "519849"
  },
  {
    "text": "using observational\ndata, ways of answering questions like this.",
    "start": "519850",
    "end": "525230"
  },
  {
    "text": "And the challenge\nis that there's going to be bias in the data\nbecause of who decides to smoke",
    "start": "525230",
    "end": "530570"
  },
  {
    "text": "and who decides not to smoke. So, for example,\nthe most naive way you might try to\nanswer this question would be to look at the\nconditional likelihood",
    "start": "530570",
    "end": "537227"
  },
  {
    "text": "of getting lung\ncancer among smokers and getting lung cancer\namong non-smokers. ",
    "start": "537227",
    "end": "544570"
  },
  {
    "text": "But those numbers, as you'll\nsee in the next few slides, can be very misleading\nbecause there might be confounding\nfactors, factors",
    "start": "544570",
    "end": "552070"
  },
  {
    "text": "that would, for example, both\ncause people to be a smoker",
    "start": "552070",
    "end": "561250"
  },
  {
    "text": "and cause them to\nreceive lung cancer, which would differentiate\nbetween these two numbers.",
    "start": "561250",
    "end": "568980"
  },
  {
    "text": "And we'll have a\nvery concrete example of this in just a few minutes. So to properly answer\nall of these questions,",
    "start": "568980",
    "end": "575010"
  },
  {
    "text": "one needs to be thinking\nin terms of causal graphs. So rather than the\ntraditional setup in machine",
    "start": "575010",
    "end": "580410"
  },
  {
    "text": "learning where you just\nhave inputs and outputs,",
    "start": "580410",
    "end": "592019"
  },
  {
    "text": "now we need to have triplets. Rather than having\ninputs and outputs, we need to be thinking\nof inputs, interventions,",
    "start": "592020",
    "end": "606350"
  },
  {
    "text": "and outcomes or outputs. So we now need be having\nthree quantities in mind.",
    "start": "606350",
    "end": "613530"
  },
  {
    "text": "And we have to start\nthinking about, well, what is the causal relationship\nbetween these three?",
    "start": "613530",
    "end": "618740"
  },
  {
    "text": "So for those of you who have\ntaken more graduate level machine learning\nclasses, you might",
    "start": "618740",
    "end": "624290"
  },
  {
    "text": "be familiar with ideas\nsuch as Bayesian networks. And when I went to\nundergrad and grad school",
    "start": "624290",
    "end": "631889"
  },
  {
    "text": "and I studied machine\nlearning, for the longest time I thought causal\ninference had to do with learning causal graphs.",
    "start": "631890",
    "end": "638900"
  },
  {
    "text": "So this is what I thought\ncausal inference was about. You have data of the\nfollowing nature-- ",
    "start": "638900",
    "end": "646560"
  },
  {
    "text": "1, 0, 0, 1, dot, dot, dot. ",
    "start": "646560",
    "end": "651950"
  },
  {
    "text": "So here, there are\nfour random variables. I'm showing the realizations\nof those four binary variables one per row, and you have\na data set like this.",
    "start": "651950",
    "end": "659870"
  },
  {
    "text": "And I thought\ncausal inference had to do with taking data like\nthis and trying to figure out, is the underlying\nBayesian network",
    "start": "659870",
    "end": "666050"
  },
  {
    "text": "that created that data, is it\nX1 goes to X2 goes to X3 to X4?",
    "start": "666050",
    "end": "674490"
  },
  {
    "text": "Or I'll say, this is X1,\nthat's X2, x3, and X4. Or maybe the causal graph\nis X1, to X2, to X3, to x4.",
    "start": "674490",
    "end": "687687"
  },
  {
    "text": "And trying to distinguish\nbetween these different causal graphs from observational\ndata is one type of question",
    "start": "687687",
    "end": "693940"
  },
  {
    "text": "that one can ask. And the one thing you learn\nin traditional machine",
    "start": "693940",
    "end": "700020"
  },
  {
    "text": "learning treatments of\nthis is that sometimes you can't distinguish between\nthese causal graphs from the data you have.",
    "start": "700020",
    "end": "705210"
  },
  {
    "text": "For example, suppose you just\nhad two random variables. Because any distribution could\nbe represented by probability",
    "start": "705210",
    "end": "714180"
  },
  {
    "text": "of X1 times probability\nof X2 given X1, according to just rule of\nconditional probability,",
    "start": "714180",
    "end": "723960"
  },
  {
    "text": "and similarly, any\ndistribution can be represented as the opposite, probability\nof X2 times probability",
    "start": "723960",
    "end": "730380"
  },
  {
    "text": "of X1 given X2, which would\nlook like this, the statement",
    "start": "730380",
    "end": "737735"
  },
  {
    "text": "that one would make\nis that if you just had data involving X1 and\nX2, you couldn't distinguish between these two causal graphs,\nX1 causes X2 or X2 causes X1.",
    "start": "737735",
    "end": "745930"
  },
  {
    "text": " And usually another\ntreatment would say, OK,",
    "start": "745930",
    "end": "751320"
  },
  {
    "text": "but if you have a third variable\nand you have a V structure or something like X1 goes\nto x2, X1 goes to X3,",
    "start": "751320",
    "end": "760590"
  },
  {
    "text": "this you could distinguish from,\nlet's say, a chain structure. ",
    "start": "760590",
    "end": "767380"
  },
  {
    "text": "And then the final\nanswer to what is causal inference\nfrom this philosophy would be something like, OK, if\nyou're in a setting like this",
    "start": "767380",
    "end": "774750"
  },
  {
    "text": "and you can't distinguish\nbetween X1 causes X2 or X2 causes X1, then you\ndo some interventions,",
    "start": "774750",
    "end": "779970"
  },
  {
    "text": "like you intervene on X1 and you\nlook to see what happens to X2, and that'll help you disentangle\nthese directions of causality.",
    "start": "779970",
    "end": "787290"
  },
  {
    "text": " None of this is what we're\ngoing to be talking about today. ",
    "start": "787290",
    "end": "794950"
  },
  {
    "text": "Today, we're going to be\ntalking about the simplest, simplest possible setting\nyou could imagine,",
    "start": "794950",
    "end": "800500"
  },
  {
    "text": "that graph shown up there.  You have three sets of\nrandom variables, X,",
    "start": "800500",
    "end": "809129"
  },
  {
    "text": "which is perhaps\na vector, so it's high dimensional, a\nsingle random variable T, and a single\nrandom variable Y.",
    "start": "809130",
    "end": "817170"
  },
  {
    "text": "And we know the\ncausal graph here. We're going to\nsuppose that we know the directionality, that we\nknow that X might cause T",
    "start": "817170",
    "end": "829650"
  },
  {
    "text": "and X and T might cause Y. And\nthe only thing we don't know",
    "start": "829650",
    "end": "834660"
  },
  {
    "text": "is the strength of the edges. All right. And so now let's try to\nthink through this in context",
    "start": "834660",
    "end": "840730"
  },
  {
    "text": "of the previous examples. Yeah, question? AUDIENCE: Just to make sure-- so\nT does not affect X in any way? DAVID SONTAG: Correct,\nthat's the assumption",
    "start": "840730",
    "end": "847530"
  },
  {
    "text": "we're going to make here. So let's try to\ninstantiate this. So we'll start\nwith this example.",
    "start": "847530",
    "end": "853855"
  },
  {
    "start": "853000",
    "end": "853000"
  },
  {
    "text": " X might be what you know about\nthe patient at diagnosis.",
    "start": "853855",
    "end": "863339"
  },
  {
    "text": "T, I'm going to assume for\nthe purposes of today's class, is a decision between two\ndifferent treatment plans.",
    "start": "863340",
    "end": "872468"
  },
  {
    "text": "And I'm going to simplify\nthe state of the world. I'm going to say those\ntreatment plans only depend on what you know about\nthe patient at diagnosis.",
    "start": "872468",
    "end": "882070"
  },
  {
    "text": "So at diagnosis, you\ndecide, I'm going to be giving them this\nsequence of treatments at this three-month interval\nor this other sequence",
    "start": "882070",
    "end": "889750"
  },
  {
    "text": "of treatment at, maybe,\nthat four-month interval. And you make that decision\njust based on diagnosis and you don't change it based\non anything you observe.",
    "start": "889750",
    "end": "895930"
  },
  {
    "text": " Then the causal graph\nof relevance there is,",
    "start": "895930",
    "end": "903140"
  },
  {
    "text": "based on what you know about\nthe patient at diagnosis, which I'm going to\nsay X is a vector because maybe it's\nbased on images,",
    "start": "903140",
    "end": "909740"
  },
  {
    "text": "your whole electronic\nhealth record. There's a ton of data you have\non the patient at diagnosis. Based on that, you\nmake some decision",
    "start": "909740",
    "end": "917300"
  },
  {
    "text": "about a treatment plan. I'm going to call that\nT. T could be binary,",
    "start": "917300",
    "end": "923390"
  },
  {
    "text": "a choice between two treatments,\nit could be continuous, maybe you're deciding the\ndosage of the treatment,",
    "start": "923390",
    "end": "929779"
  },
  {
    "text": "or it could be\nmaybe even a vector. For today's lecture,\nI'm going to suppose",
    "start": "929780",
    "end": "935150"
  },
  {
    "text": "that T is just binary,\njust involves two choices. But most of what\nI'll tell you about",
    "start": "935150",
    "end": "941120"
  },
  {
    "text": "will generalize to the setting\nwhere T is non-binary as well. But critically,\nI'm going to make",
    "start": "941120",
    "end": "948200"
  },
  {
    "text": "the assumption for\ntoday's lecture that you're not observing\nnew things in between. So, for example, in this\nwhole week's lecture,",
    "start": "948200",
    "end": "956630"
  },
  {
    "text": "the following scenario\nwill not happen. Based on diagnosis, you make a\ndecision about treatment plan.",
    "start": "956630",
    "end": "965519"
  },
  {
    "text": "Treatment plan starts,\nyou got new observations. Based on those new\nobservations, you realize that treatment\nplan isn't working",
    "start": "965520",
    "end": "971428"
  },
  {
    "text": "and change to another\ntreatment plan, and so on. So that scenario goes\nby a different name,",
    "start": "971428",
    "end": "977440"
  },
  {
    "text": "which is called\ndynamic treatment regimes or off-policy\nreinforcement learning,",
    "start": "977440",
    "end": "982710"
  },
  {
    "text": "and that we'll learn\nabout next week. So for today's and\nThursday's lecture, we're going to suppose\nyou base on what",
    "start": "982710",
    "end": "988830"
  },
  {
    "text": "you know about the patient at\nthis time, you make a decision, you execute the decision,\nand you look at some outcome.",
    "start": "988830",
    "end": "994650"
  },
  {
    "text": "So X causes T, not\nthe other way around. And that's pretty clear\nbecause of our prior knowledge",
    "start": "994650",
    "end": "1002060"
  },
  {
    "text": "about this problem. It's not that the\ntreatment affects what their diagnosis was.",
    "start": "1002060",
    "end": "1009279"
  },
  {
    "text": "And then there's the outcome\nY, and there, again, we suppose the outcome, what\nhappens to the patient, maybe",
    "start": "1009280",
    "end": "1015190"
  },
  {
    "text": "survival time, for example, is\na function of what treatment they're getting and\naspects about that patient.",
    "start": "1015190",
    "end": "1023740"
  },
  {
    "text": "So this is the causal graph. We know it. But we don't know,\ndoes that treatment do anything to this patient?",
    "start": "1023740",
    "end": "1029679"
  },
  {
    "text": "For whom does this\ntreatment help the most? And those are the types\nof questions we're going to try to answer today.",
    "start": "1029680",
    "end": "1035628"
  },
  {
    "text": " Is the setting clear? ",
    "start": "1035628",
    "end": "1051390"
  },
  {
    "text": "OK. Now, these questions\nare not new questions. They've been studied\nfor decades in fields",
    "start": "1051390",
    "end": "1059360"
  },
  {
    "text": "such as political science,\neconomics, statistics, biostatistics.",
    "start": "1059360",
    "end": "1065967"
  },
  {
    "text": "And the reason why they're\nstudied in those other fields is because often you don't\nhave the ability to intervene,",
    "start": "1065967",
    "end": "1071420"
  },
  {
    "text": "and one has to try to\nanswer these questions from observational data. For example, you might ask, what\nwill happen to the US economy",
    "start": "1071420",
    "end": "1081140"
  },
  {
    "text": "if the Federal Reserve raises\nUS interest rates by 1%? ",
    "start": "1081140",
    "end": "1087922"
  },
  {
    "text": "When's the last time you\nheard of the Federal Reserve doing a randomized\ncontrolled trial?",
    "start": "1087922",
    "end": "1093100"
  },
  {
    "text": "And even if they had done a\nrandomized controlled trial, for example, flipped a coin to\ndecide which way the interest",
    "start": "1093100",
    "end": "1098130"
  },
  {
    "text": "rates would go, it wouldn't\nbe comparable had they done that experiment today to\nif they had done that experiment",
    "start": "1098130",
    "end": "1103960"
  },
  {
    "text": "two years from now because\nthe state of the world has changed in those years. ",
    "start": "1103960",
    "end": "1111010"
  },
  {
    "text": "Let's talk about\npolitical science. I have close colleagues of mine\nat NYU who look at Twitter,",
    "start": "1111010",
    "end": "1118990"
  },
  {
    "text": "and they want to\nask questions like, how can we influence\nelections, or how",
    "start": "1118990",
    "end": "1124210"
  },
  {
    "text": "are elections influenced? So you might look at some\nunnamed actors, possibly",
    "start": "1124210",
    "end": "1134060"
  },
  {
    "text": "people supported by the\nRussian government, who are posting to Twitter\nor their social media.",
    "start": "1134060",
    "end": "1140659"
  },
  {
    "text": "And you might ask the\nquestion of, well, did that actually\ninfluence the outcome of the previous\npresidential election?",
    "start": "1140660",
    "end": "1148377"
  },
  {
    "text": "Again, in that\nscenario, it's one of, well, we have this\ndata, something happened in the\nworld, and we'd like",
    "start": "1148378",
    "end": "1155110"
  },
  {
    "text": "to understand what was\nthe effect of that action, but we can't exactly go back\nand replay to do something else.",
    "start": "1155110",
    "end": "1162510"
  },
  {
    "text": "So these are fundamental\nquestions that appear all across the\nsciences, and of course they're extremely relevant\nin health care,",
    "start": "1162510",
    "end": "1168130"
  },
  {
    "text": "but yet, we don't teach\nthem in our introduction to machine learning classes. We don't teach them in our\nundergraduate computer science",
    "start": "1168130",
    "end": "1174930"
  },
  {
    "text": "education. And I view this as a major\nhole in our education, which is why we're\nspending two weeks on it",
    "start": "1174930",
    "end": "1180500"
  },
  {
    "text": "in this course, which\nis still not enough. ",
    "start": "1180500",
    "end": "1186070"
  },
  {
    "text": "But what has changed\nbetween these fields, and what is relevant\nin health care?",
    "start": "1186070",
    "end": "1191480"
  },
  {
    "text": "Well, the traditional way\nin which these questions were asked in\nstatistics were ones where you took a huge\namount of domain knowledge",
    "start": "1191480",
    "end": "1199975"
  },
  {
    "text": "to, first of all, make sure\nyou're setting up the problem correctly, and that's always\ngoing to be important. But then to think through what\nare all of the factors that",
    "start": "1199975",
    "end": "1208679"
  },
  {
    "text": "could influence the\ntreatment decisions called the confounding factors.",
    "start": "1208680",
    "end": "1214769"
  },
  {
    "text": "And the traditional\napproach is one would write down 10,\n20 different things, and make sure that you do\nsome analysis, including",
    "start": "1214770",
    "end": "1221240"
  },
  {
    "text": "the analysis I'll show you about\nin today and Thursday's lecture using those 10 or 20 variables.",
    "start": "1221240",
    "end": "1227500"
  },
  {
    "text": "But where this field\nis going is one of now having high dimensional data. So I talked about how you\nmight have imaging data for X,",
    "start": "1227500",
    "end": "1234292"
  },
  {
    "text": "you might have the whole entire\npatient's electronic health record data facts. And the traditional approaches\nthat the statistics community",
    "start": "1234292",
    "end": "1241310"
  },
  {
    "text": "used to work on no longer\nwork in this high dimensional setting.",
    "start": "1241310",
    "end": "1246657"
  },
  {
    "text": "And so, in fact, it's actually\na really interesting area for research, one that my\nlab is starting to work on and many other labs, where\nwe could ask, how can we",
    "start": "1246657",
    "end": "1253160"
  },
  {
    "text": "bring machine learning\nalgorithms that are designed to work with high\ndimensional data",
    "start": "1253160",
    "end": "1258230"
  },
  {
    "text": "to answer these types of\ncausal inference questions? And in today's lecture, you'll\nsee one example of reduction",
    "start": "1258230",
    "end": "1264860"
  },
  {
    "text": "from causal inference\nto machine learning, where we'll be\nable to use machine learning to answer one of those\ncausal inference questions.",
    "start": "1264860",
    "end": "1273110"
  },
  {
    "text": " So the first thing we need\nis some language in order",
    "start": "1273110",
    "end": "1279640"
  },
  {
    "text": "to formalize these notions. So I will work within what's\nknown as the Rubin-Neyman",
    "start": "1279640",
    "end": "1286230"
  },
  {
    "text": "Causal Model, where\nwe talk about what are called potential outcomes.",
    "start": "1286230",
    "end": "1291930"
  },
  {
    "text": "What would have happened under\nthis world or that world? We'll call Y 0,\nand often it will",
    "start": "1291930",
    "end": "1298850"
  },
  {
    "text": "be denoted as Y underscore\n0, sometimes it'll be denoted as Y parentheses\n0, and sometimes it'll",
    "start": "1298850",
    "end": "1307290"
  },
  {
    "text": "be denoted as Y given\nX comma do Y equals 0.",
    "start": "1307290",
    "end": "1319990"
  },
  {
    "text": "And all three of these\nnotations are equivalent.",
    "start": "1319990",
    "end": "1325330"
  },
  {
    "text": "So Y is 0 corresponds\nto what would have happened to this\nindividual if you gave them",
    "start": "1325330",
    "end": "1330730"
  },
  {
    "start": "1327000",
    "end": "1327000"
  },
  {
    "text": "treatment to 0. And Y1 is the potential\noutcome of what would have happened to this\nindividual had you gave them",
    "start": "1330730",
    "end": "1337780"
  },
  {
    "text": "treatment one. So you could think about Y1\nas being giving the blue pill",
    "start": "1337780",
    "end": "1343340"
  },
  {
    "text": "and Y0 as being\ngiven the red pill. ",
    "start": "1343340",
    "end": "1348399"
  },
  {
    "text": "Now, once you can talk about\nthese states of the world, then one could start\nto ask questions",
    "start": "1348400",
    "end": "1354550"
  },
  {
    "text": "of what's better, the red\npill or the blue pill? And one can formalize\nthat notion mathematically",
    "start": "1354550",
    "end": "1361000"
  },
  {
    "text": "in terms of what's called the\nconditional average treatment effect, and this\nalso goes by the name of individual treatment effect.",
    "start": "1361000",
    "end": "1368970"
  },
  {
    "text": "So it's going to take\nas input Xi, which I'm going to denote as\nthe data that you had",
    "start": "1368970",
    "end": "1374049"
  },
  {
    "text": "at baseline for the individual. It's the covariance, the\nfeatures for the individual.",
    "start": "1374050",
    "end": "1380600"
  },
  {
    "text": "And one wants to know, well,\nfor this individual with what we know about them, what's the\ndifference between giving them",
    "start": "1380600",
    "end": "1387770"
  },
  {
    "text": "treatment one or giving\nthem treatment zero? So mathematically, that\ncorresponds to a difference",
    "start": "1387770",
    "end": "1393740"
  },
  {
    "text": "in expectations. It's a difference in\nexpectation of Y1 from Y0.",
    "start": "1393740",
    "end": "1400340"
  },
  {
    "text": "Now, the reason why I'm\ncalling this an expectation is because I'm not going to\nassume that Y1 and Y0 are",
    "start": "1400340",
    "end": "1406340"
  },
  {
    "text": "deterministic\nbecause maybe there's",
    "start": "1406340",
    "end": "1411779"
  },
  {
    "text": "some bad luck component. Like, maybe a medication usually\nworks for this type of person,",
    "start": "1411780",
    "end": "1416820"
  },
  {
    "text": "but with a flip of a coin,\nsometimes it doesn't work. And so that's the\nrandomness that I'm",
    "start": "1416820",
    "end": "1423330"
  },
  {
    "text": "referring to when I talk about\nprobability over Y1 given Xi. And so the CATE looks\nat the difference",
    "start": "1423330",
    "end": "1430320"
  },
  {
    "text": "in those two expectations. And then one can now talk about\nwhat the average treatment effect is, which is the\ndifference between those two.",
    "start": "1430320",
    "end": "1439570"
  },
  {
    "text": "So the average treatment effect\nis now the expectation of-- I'll say the expectation of\nthe CATE over the distribution",
    "start": "1439570",
    "end": "1449100"
  },
  {
    "text": "of people, P of X.\nNow, we're going",
    "start": "1449100",
    "end": "1454980"
  },
  {
    "text": "to go through this in four\ndifferent ways in the next 10 minutes, and then you're\ngoing to go over it five more",
    "start": "1454980",
    "end": "1460270"
  },
  {
    "text": "ways doing your\nhomework assignment, and you'll go over it two more\nways on Friday in recitation.",
    "start": "1460270",
    "end": "1465340"
  },
  {
    "text": "So if you don't get it\njust yet, stay with me, you'll get it by the\nend of this week. ",
    "start": "1465340",
    "end": "1473299"
  },
  {
    "text": "Now, in the data that you\nobserve for an individual,",
    "start": "1473300",
    "end": "1478870"
  },
  {
    "text": "all you see is what happened\nunder one of the interventions. So, for example, if the i'th\nindividual in your data set",
    "start": "1478870",
    "end": "1485649"
  },
  {
    "text": "received treatment Ti equals\n1, then what you observe, Yi is the potential outcome Y1.",
    "start": "1485650",
    "end": "1493702"
  },
  {
    "text": "On the other hand, if the\nindividual in your data set received treatment\nTi equals 0, then",
    "start": "1493702",
    "end": "1498880"
  },
  {
    "text": "what you observed\nfor that individual is the potential outcome Y0.",
    "start": "1498880",
    "end": "1504130"
  },
  {
    "text": "So that's the observed\nfactual outcome. But one could also talk\nabout the counterfactual",
    "start": "1504130",
    "end": "1511930"
  },
  {
    "text": "of what would have\nhappened to this person had the opposite treatment\nbeen done for them.",
    "start": "1511930",
    "end": "1517190"
  },
  {
    "text": "Notice that I just swapped each\nTi for 1 minus Ti, and so on.",
    "start": "1517190",
    "end": "1522460"
  },
  {
    "text": "Now, the key challenge in the\nfield is that in your data set, you only observe the\nfactual outcomes.",
    "start": "1522460",
    "end": "1529470"
  },
  {
    "text": "And when you want to reason\nabout the counterfactual, that's where you have to impute\nthis unobserved counterfactual",
    "start": "1529470",
    "end": "1536970"
  },
  {
    "text": "outcome. And that is known as\nthe fundamental problem of causal inference,\nthat we only",
    "start": "1536970",
    "end": "1542110"
  },
  {
    "text": "observe one of the two outcomes\nfor any individual in the data set. So let's look at a\nvery simple example.",
    "start": "1542110",
    "end": "1549070"
  },
  {
    "start": "1546000",
    "end": "1546000"
  },
  {
    "text": "Here, individuals\nare characterized by just one feature, their age.",
    "start": "1549070",
    "end": "1554400"
  },
  {
    "text": "And these two curves\nthat I'm showing you are the potential\noutcomes of what",
    "start": "1554400",
    "end": "1560010"
  },
  {
    "text": "would happen to this\nindividual's blood pressure if you gave them\ntreatment zero, which is the blue curve, versus\ntreatment one, which",
    "start": "1560010",
    "end": "1566700"
  },
  {
    "text": "is the red curve. All right. So let's dig in a\nlittle bit deeper.",
    "start": "1566700",
    "end": "1572000"
  },
  {
    "text": "For the blue curve,\nwe see people who received the control, what\nI'm calling treatment zero,",
    "start": "1572000",
    "end": "1582220"
  },
  {
    "text": "their blood pressure\nwas pretty low for the individuals who\nwere low and for individuals",
    "start": "1582220",
    "end": "1588890"
  },
  {
    "text": "whose age is high. But for middle age individuals,\ntheir blood pressure",
    "start": "1588890",
    "end": "1595250"
  },
  {
    "text": "on receiving treatment zero\nis in the higher range. On the other hand,\nfor individuals",
    "start": "1595250",
    "end": "1602230"
  },
  {
    "text": "who receive treatment\none, it's the red curve. So young people have much\nhigher, let's say, blood",
    "start": "1602230",
    "end": "1607940"
  },
  {
    "text": "pressure under treatment one,\nand, similarly, much older",
    "start": "1607940",
    "end": "1613789"
  },
  {
    "text": "people. So then one could\nask, well, what about the difference between\nthese two potential outcomes?",
    "start": "1613790",
    "end": "1619757"
  },
  {
    "text": "That is to say the CATE, the\nConditional Average Treatment Effect, is simply looking at the\ndistance between the blue curve",
    "start": "1619757",
    "end": "1626809"
  },
  {
    "text": "and the red curve\nfor that individual. So for someone with\na specific age, let's say a young person\nor a very old person,",
    "start": "1626810",
    "end": "1634640"
  },
  {
    "text": "there's a very big difference\nbetween giving treatment zero or giving treatment one.",
    "start": "1634640",
    "end": "1639980"
  },
  {
    "text": "Whereas for a\nmiddle aged person, there's very little difference. So, for example, if treatment\none was significantly cheaper",
    "start": "1639980",
    "end": "1650090"
  },
  {
    "text": "than treatment zero,\nthen you might say, we'll give treatment one. Even though it's not quite\nas good as treatment zero,",
    "start": "1650090",
    "end": "1657020"
  },
  {
    "text": "but it's so much cheaper and\nthe difference between them is so small, we'll\ngive the other one.",
    "start": "1657020",
    "end": "1663187"
  },
  {
    "text": "But in order to make that\ntype of policy decision, one, of course,\nhas to understand that conditional\naverage treatment effect for that individual,\nand that's something",
    "start": "1663187",
    "end": "1669700"
  },
  {
    "text": "that we're going to want\nto predict using data. Now, we don't always\nget the luxury",
    "start": "1669700",
    "end": "1674710"
  },
  {
    "text": "of having personalized\ntreatment recommendations. Sometimes we have\nto give a policy.",
    "start": "1674710",
    "end": "1681230"
  },
  {
    "text": "Like, for example-- I took this example\nout of my slides, but I'll give it to you anyway. The federal government\nmight come out",
    "start": "1681230",
    "end": "1687559"
  },
  {
    "text": "with a guideline saying that\nall men over the age of 50--",
    "start": "1687560",
    "end": "1692885"
  },
  {
    "text": "I'm making up that number-- need to get annual\nprostate cancer screening.",
    "start": "1692885",
    "end": "1699320"
  },
  {
    "text": "That's an example of a\nvery broad policy decision.",
    "start": "1699320",
    "end": "1704549"
  },
  {
    "text": "You might ask, well, what is\nthe effect of that policy now applied over the\nfull population on,",
    "start": "1704550",
    "end": "1711940"
  },
  {
    "text": "let's say, decreasing deaths\ndue to prostate cancer? And that would be\nan example of asking",
    "start": "1711940",
    "end": "1717990"
  },
  {
    "text": "about the average\ntreatment effect. So if you were to\naverage the red line, if you were to\naverage the blue line,",
    "start": "1717990",
    "end": "1723750"
  },
  {
    "text": "you get those two dotted\nlines I show there. And if you look at the\ndifference between them, that is the average\ntreatment effect between giving the\nred intervention",
    "start": "1723750",
    "end": "1730350"
  },
  {
    "text": "or giving the blue intervention. And if the average human\neffect is very positive,",
    "start": "1730350",
    "end": "1736830"
  },
  {
    "text": "you might say that, on\naverage, this intervention is a good intervention. If it's very negative, you\nmight say the opposite.",
    "start": "1736830",
    "end": "1743850"
  },
  {
    "text": " Now, the challenge about\ndoing causal inference",
    "start": "1743850",
    "end": "1748980"
  },
  {
    "text": "from observational data\nis that, of course, we don't observe those\nred and those blue curves,",
    "start": "1748980",
    "end": "1754620"
  },
  {
    "text": "rather what we observe are\ndata points that might be distributed all over the place.",
    "start": "1754620",
    "end": "1760080"
  },
  {
    "text": "Like, for example,\nin this example, the blue treatment happens\nto be given in the data more",
    "start": "1760080",
    "end": "1766537"
  },
  {
    "text": "to young people, and\nthe red treatment happens to be given in the\ndata more to older people.",
    "start": "1766537",
    "end": "1771540"
  },
  {
    "text": "And that can happen for\na variety of reasons. It can happen due to\naccess to medication.",
    "start": "1771540",
    "end": "1777030"
  },
  {
    "text": "It can happen for\nsocioeconomic reasons. It could happen because existing\ntreatment guidelines say",
    "start": "1777030",
    "end": "1783990"
  },
  {
    "text": "that old people should\nreceive treatment one and young people should\nreceive treatment zero.",
    "start": "1783990",
    "end": "1789330"
  },
  {
    "text": "These are all reasons why\nin your data who receives what treatment could\nbe biased in some way.",
    "start": "1789330",
    "end": "1796240"
  },
  {
    "text": "And that's exactly what this\nedge from X to T is modeling. ",
    "start": "1796240",
    "end": "1802960"
  },
  {
    "text": "But for each of\nthose people, you might want to know, well, what\nwould have happened if they had gotten the other treatment? And that's asking about\nthe counterfactual.",
    "start": "1802960",
    "end": "1810230"
  },
  {
    "text": "So these dotted circles\nare the counterfactuals for each of those observations.",
    "start": "1810230",
    "end": "1817299"
  },
  {
    "text": "And by the way, you'll notice\nthat those dots are not on the curves, and the reason\nthey're not on the curve is because I'm\ntrying to point out",
    "start": "1817300",
    "end": "1823407"
  },
  {
    "text": "that there could be some\nstochasticity in the outcome. So the dotted lines are the\nexpected potential outcomes",
    "start": "1823407",
    "end": "1830210"
  },
  {
    "text": "and the circles are the\nrealizations of them.  All right.",
    "start": "1830210",
    "end": "1835490"
  },
  {
    "text": "Everyone take out a calculator\nor your computer or your phone, and I'll take out mine.",
    "start": "1835490",
    "end": "1841549"
  },
  {
    "text": " This is not an opportunity to go\non Facebook, just to be clear.",
    "start": "1841550",
    "end": "1849090"
  },
  {
    "text": "All you want is a calculator. ",
    "start": "1849090",
    "end": "1854972"
  },
  {
    "text": "My phone doesn't-- oh,\nOK, it has a calculator. Good. All right.",
    "start": "1854972",
    "end": "1860450"
  },
  {
    "text": "So we're going to do\na little exercise.  Here's a data set on\nthe left-hand side.",
    "start": "1860450",
    "end": "1868530"
  },
  {
    "text": "Each row is an individual. We're observing the\nindividual's age, gender,",
    "start": "1868530",
    "end": "1873720"
  },
  {
    "text": "whether they exercise\nregularly, which I'll say is a one or a zero,\nand what treatment they got, which is A or B. On\nthe far right-hand side",
    "start": "1873720",
    "end": "1881750"
  },
  {
    "text": "are their observed sugar\nglucose sugar levels, let's say,",
    "start": "1881750",
    "end": "1888200"
  },
  {
    "text": "at the end of the year.  Now, what we'd like to\nhave, it looks like this.",
    "start": "1888200",
    "end": "1897960"
  },
  {
    "text": "So we'd like to know what would\nhave happened to this person's sugar levels had they\nreceived medication A",
    "start": "1897960",
    "end": "1905700"
  },
  {
    "text": "or had they received\nmedication B. But if you look at\nthe previous slide,",
    "start": "1905700",
    "end": "1912630"
  },
  {
    "text": "we observed for each individual\nthat they got either A or B. And so we're only\ngoing to know one",
    "start": "1912630",
    "end": "1918480"
  },
  {
    "text": "of these columns\nfor each individual. So the first row, for\nexample, this individual received treatment\nA, and so you'll",
    "start": "1918480",
    "end": "1925980"
  },
  {
    "text": "see that I've taken\nthe observed sugar",
    "start": "1925980",
    "end": "1931650"
  },
  {
    "text": "level for that individual,\nand since they received treatment A, that\nobserved level represents",
    "start": "1931650",
    "end": "1937860"
  },
  {
    "text": "the potential outcome Ya, or Y0. And that's why I have a 6,\nwhich is bolded under Y0.",
    "start": "1937860",
    "end": "1947370"
  },
  {
    "text": "And we don't know what\nwould have happened to that individual\nhad they received treatment B. So in this\ncase, some magical creature",
    "start": "1947370",
    "end": "1956580"
  },
  {
    "text": "came to me and told me\ntheir sugar levels would have been 5.5, but we\ndon't actually know that. It wasn't in the data.",
    "start": "1956580",
    "end": "1962070"
  },
  {
    "text": "Let's look at the\nnext line just to make sure we get what I'm saying. So the second\nindividual actually received treatment B. They're\nobserved sugar level is 6.5.",
    "start": "1962070",
    "end": "1973450"
  },
  {
    "text": "OK. Let's do a little survey. That 6.5 number, should\nit be in this column?",
    "start": "1973450",
    "end": "1980950"
  },
  {
    "text": "Raise your hand. Or should it be in this column? Raise your hand. All right. About half of you\ngot that right.",
    "start": "1980950",
    "end": "1988050"
  },
  {
    "text": "Indeed, it goes to\nthe second column. And again, what we would like\nto know is the counterfactual.",
    "start": "1988050",
    "end": "1994080"
  },
  {
    "text": "What would have been\ntheir sugar levels had they received medication A? Which we don't actually\nobserve in our data,",
    "start": "1994080",
    "end": "2000100"
  },
  {
    "text": "but I'm going to\nhypothesize is-- suppose that someone\ntold me it was 7, then",
    "start": "2000100",
    "end": "2005561"
  },
  {
    "text": "you would see that\nvalue filled in there. That's the unobserved\ncounterfactual.",
    "start": "2005562",
    "end": "2010610"
  },
  {
    "text": "All right. First of all, is\nthe setup clear? All right. Now here's when you\nuse your calculators.",
    "start": "2010610",
    "end": "2017990"
  },
  {
    "text": "So we're going to\nnow demonstrate the difference between\na naive estimator",
    "start": "2017990",
    "end": "2023419"
  },
  {
    "text": "of your average treatment effect\nand the true average treatment effect.",
    "start": "2023420",
    "end": "2028850"
  },
  {
    "text": "So what I want you\nto do right now is to compute, first,\nwhat is the average sugar",
    "start": "2028850",
    "end": "2039269"
  },
  {
    "text": "level of the individuals who\ngot medication B. So for that,",
    "start": "2039270",
    "end": "2047270"
  },
  {
    "text": "we're only going to\nbe using the red ones. So this is conditioning\non receiving medication B.",
    "start": "2047270",
    "end": "2057050"
  },
  {
    "text": "And so this is equivalent\nto going back to this one",
    "start": "2057050",
    "end": "2064340"
  },
  {
    "text": "and saying, we're only going to\ntake the rows where individuals receive medication\nB, and we're going",
    "start": "2064340",
    "end": "2069349"
  },
  {
    "text": "to average their\nobserved sugar levels. And everyone should do that.",
    "start": "2069350",
    "end": "2076530"
  },
  {
    "text": "What's the first number? ",
    "start": "2076530",
    "end": "2082600"
  },
  {
    "text": "6.5 plus-- I'm getting 7.875.",
    "start": "2082600",
    "end": "2102370"
  },
  {
    "text": "This is for the\naverage sugar, given",
    "start": "2102370",
    "end": "2108790"
  },
  {
    "text": "that they received\nmedication B. Is that what other people are getting? AUDIENCE: Yeah. DAVID SONTAG: OK.",
    "start": "2108790",
    "end": "2113838"
  },
  {
    "text": "What about for\nthe second number? Average sugar, given A?",
    "start": "2113838",
    "end": "2120069"
  },
  {
    "text": " I want you to compute it.",
    "start": "2120070",
    "end": "2126058"
  },
  {
    "text": "And I'm going to ask\neveryone to say it out loud in literally one minute. And if you get it\nwrong, of course you're going to be embarrassed.",
    "start": "2126058",
    "end": "2133360"
  },
  {
    "text": "I'm going to try myself. ",
    "start": "2133360",
    "end": "2153090"
  },
  {
    "text": "OK. On the count of\nthree, I want everyone to read out what\nthat third number is. One, two, three.",
    "start": "2153090",
    "end": "2160020"
  },
  {
    "text": "ALL: 7.125. DAVID SONTAG: All right.",
    "start": "2160020",
    "end": "2165250"
  },
  {
    "text": "Good. We can all do arithmetic. All right.",
    "start": "2165250",
    "end": "2170370"
  },
  {
    "text": "Good. So, again, we're just\nlooking at the red numbers",
    "start": "2170370",
    "end": "2177000"
  },
  {
    "text": "here, just the red numbers. So we just computed\nthat difference, which is point what?",
    "start": "2177000",
    "end": "2184280"
  },
  {
    "text": "AUDIENCE: 0.75. DAVID SONTAG: 0.75? Yeah, that looks about right. Good.",
    "start": "2184280",
    "end": "2189670"
  },
  {
    "text": "All right. So that's a positive number. Now let's do\nsomething different.",
    "start": "2189670",
    "end": "2197260"
  },
  {
    "text": "Now let's compute the actual\naverage treatment effect, which",
    "start": "2197260",
    "end": "2202600"
  },
  {
    "text": "is we're now going to average\nevery number in this column,",
    "start": "2202600",
    "end": "2210310"
  },
  {
    "text": "and we're going to average\nevery number in this column. So this is the\naverage sugar level",
    "start": "2210310",
    "end": "2216880"
  },
  {
    "text": "under the potential outcome\nof had the individual received treatment B, and this is\nthe average sugar level",
    "start": "2216880",
    "end": "2223590"
  },
  {
    "text": "under the potential outcome\nthat the individual received treatment A. All right.",
    "start": "2223590",
    "end": "2232350"
  },
  {
    "text": "Who's doing it? AUDIENCE: 0.75. DAVID SONTAG: 0.75 is what? AUDIENCE: The difference.",
    "start": "2232350",
    "end": "2237760"
  },
  {
    "text": "DAVID SONTAG: How do you know? AUDIENCE: [INAUDIBLE] DAVID SONTAG: Wow, you're fast.",
    "start": "2237760",
    "end": "2242910"
  },
  {
    "text": "OK. Let's see if you're right. I actually don't know. OK. The first one is 0.75. Good, we got that right. I intentionally didn't post\nthe slides to today's lecture.",
    "start": "2242910",
    "end": "2249917"
  },
  {
    "text": " And the second\none is minus 0.75.",
    "start": "2249917",
    "end": "2258340"
  },
  {
    "text": "All right. So now let's put us in the\nshoes of a policymaker. The policymaker has to\ndecide, is it a good idea to--",
    "start": "2258340",
    "end": "2267135"
  },
  {
    "text": "or let's say it's a\nhealth insurance company. A health insurance\ncompany is trying decide, should I reimburse for\ntreatment B or not?",
    "start": "2267135",
    "end": "2273768"
  },
  {
    "text": "Or should I simply\nsay, no, I'm never going to reimburse for treatment\nbecause it doesn't work well? So if they had done the\nnaive estimator, that",
    "start": "2273768",
    "end": "2282300"
  },
  {
    "text": "would have been\nthe first example, then it would look\nlike medication B is--",
    "start": "2282300",
    "end": "2290540"
  },
  {
    "text": "we want lower\nnumbers here, so it would look like medication B\nis worse than medication A.",
    "start": "2290540",
    "end": "2298609"
  },
  {
    "text": "And if you properly\nestimated what the actual average\ntreatment effect is,",
    "start": "2298610",
    "end": "2304580"
  },
  {
    "text": "you get the absolute\nopposite conclusion. You conclude that medication B\nis much better than medication",
    "start": "2304580",
    "end": "2309950"
  },
  {
    "text": "A. It's just a simple\nexample to really illustrate the difference\nbetween conditioning",
    "start": "2309950",
    "end": "2315970"
  },
  {
    "text": "and actually computing\nthat counterfactual. ",
    "start": "2315970",
    "end": "2322890"
  },
  {
    "text": "OK. So hopefully now you're\nstarting to get it. And again, you're going to have\nmany more opportunities to work through these things in your\nhomework assignment and so on.",
    "start": "2322890",
    "end": "2332700"
  },
  {
    "text": "So by now you should be\nstarting to wonder, how the hell could I do anything in\nthis state of the world? Because you don't actually\nobserve those black numbers.",
    "start": "2332700",
    "end": "2340620"
  },
  {
    "text": "These are all unobserved. And clearly there\nis bias in what the values should\nbe because of what",
    "start": "2340620",
    "end": "2347100"
  },
  {
    "text": "I've been saying all along. So what can we do? Well, the first thing\nwe have to realize",
    "start": "2347100",
    "end": "2352830"
  },
  {
    "text": "is that typically, this is an\nimpossible problem to solve. So your instincts\naren't wrong, and we're",
    "start": "2352830",
    "end": "2358920"
  },
  {
    "text": "going to have to make\na ton of assumptions in order to do anything here.",
    "start": "2358920",
    "end": "2363950"
  },
  {
    "text": "So the first assumption\nis called SUTVA. I'm not even going\nto talk about it. You can read about\nthat in your readings.",
    "start": "2363950",
    "end": "2369724"
  },
  {
    "text": "I'll tell you about\nthe two assumptions that are a little bit\neasier to describe.",
    "start": "2369725",
    "end": "2374890"
  },
  {
    "text": "The first critical assumption\nis that there are no unobserved confounding factors. Mathematically\nwhat that's saying",
    "start": "2374890",
    "end": "2381370"
  },
  {
    "start": "2376000",
    "end": "2376000"
  },
  {
    "text": "is that your potential\noutcomes, Y0 and Y1, are conditionally independent\nof the treatment decision given",
    "start": "2381370",
    "end": "2387340"
  },
  {
    "text": "what you observe on\nthe individual, X.",
    "start": "2387340",
    "end": "2392780"
  },
  {
    "text": "Now, this could\nbe a bit hard to-- and that's called ignorability. And this can be a bit\nhard to understand,",
    "start": "2392780",
    "end": "2399008"
  },
  {
    "text": "so let me draw a picture. So X is your covariance, T\nis your treatment decision.",
    "start": "2399008",
    "end": "2404200"
  },
  {
    "text": "And now I've drawn for you\na slightly different graph. Over here I said X goes\nto T, X and T go to Y.",
    "start": "2404200",
    "end": "2410860"
  },
  {
    "text": "But now I don't have Y.\nInstead, I have Y0 and Y1, and I don't have any\nedge from T to them.",
    "start": "2410860",
    "end": "2416662"
  },
  {
    "text": "And that's because\nnow I'm actually using the potential\noutcomes notation. Y0 is a potential\noutcome of what",
    "start": "2416662",
    "end": "2422225"
  },
  {
    "text": "would have happened to this\nindividual had they received treatment 0, and\nY1 is what would have happened to this individual\nif they received treatment one.",
    "start": "2422225",
    "end": "2428950"
  },
  {
    "text": "And because you already know\nwhat treatment the individual has received, it\ndoesn't make sense to talk about an edge\nfrom T to those values.",
    "start": "2428950",
    "end": "2435560"
  },
  {
    "text": "That's why there's\nno edge there. So then you might wonder,\nhow could you possibly have a violation of this\nconditional independence",
    "start": "2435560",
    "end": "2441192"
  },
  {
    "text": "assumption? Well, before I give\nyou that answer, let me put some names\nto these things. So we might think about X as\nbeing the age, gender, weight,",
    "start": "2441192",
    "end": "2448869"
  },
  {
    "text": "diet, and so on\nof the individual. T might be a medication, like\nan anti-hypertensive medication",
    "start": "2448870",
    "end": "2454300"
  },
  {
    "text": "to try to lower a\npatient's blood pressure. And these would be\nthe potential outcomes after those two medications.",
    "start": "2454300",
    "end": "2460990"
  },
  {
    "text": "So an example of a\nviolation of ignorability is if there is something else,\nsome hidden variable h, which",
    "start": "2460990",
    "end": "2470970"
  },
  {
    "text": "is not observed\nand which affects both the decision\nof what treatment the individual in\nyour data set receives",
    "start": "2470970",
    "end": "2477750"
  },
  {
    "text": "and the potential outcomes. Now it should be\nreally clear that this would be a violation of that\nconditional independence",
    "start": "2477750",
    "end": "2484378"
  },
  {
    "text": "assumption. In this graph, Y0 and\nY1 are not conditionally independent of T\ngiven X. All right.",
    "start": "2484378",
    "end": "2492760"
  },
  {
    "text": "So what are these\nhidden confounders? Well, they might be things,\nfor example, which really affect treatment decisions.",
    "start": "2492760",
    "end": "2500020"
  },
  {
    "text": "So maybe there's a\ntreatment guideline saying that for\ndiabetic patients, they should receive\ntreatment zero, that that's",
    "start": "2500020",
    "end": "2507700"
  },
  {
    "text": "the right thing to do. And so a violation\nof this would be",
    "start": "2507700",
    "end": "2514270"
  },
  {
    "text": "if the fact that the\npatient's diabetic were not recorded in the\nelectronic health record.",
    "start": "2514270",
    "end": "2519950"
  },
  {
    "text": "So you don't know-- that's not up there. You don't know that,\nin fact, the reason",
    "start": "2519950",
    "end": "2525610"
  },
  {
    "text": "the patient received treatment\nT was because of this h factor. And there's critically\nanother assumption, which is that h actually\naffects the outcome,",
    "start": "2525610",
    "end": "2532540"
  },
  {
    "text": "which is why you have these\nedges from h to the Y's. If h were something\nwhich might have affected treatment decision but not the\nactual potential outcomes--",
    "start": "2532540",
    "end": "2541620"
  },
  {
    "text": "and that can happen, of course. Things like gender can often\naffect treatment decisions,",
    "start": "2541620",
    "end": "2546880"
  },
  {
    "text": "but maybe, for some diseases,\nit might not affect outcomes.",
    "start": "2546880",
    "end": "2552569"
  },
  {
    "text": "In that situation it wouldn't\nbe a confounding factor because it doesn't\nviolate this assumption.",
    "start": "2552570",
    "end": "2558540"
  },
  {
    "text": "And, in fact, one would\nbe able to come up with consistent estimators\nof average treatment effect under that assumption.",
    "start": "2558540",
    "end": "2564130"
  },
  {
    "text": "Where things go to hell is when\nyou have both of those edges. All right.",
    "start": "2564130",
    "end": "2569950"
  },
  {
    "text": "So there can't be\nany of these h's. You have to observe\nall things that affect both treatment and outcomes.",
    "start": "2569950",
    "end": "2575055"
  },
  {
    "text": " The second big\nassumption-- oh, yeah. Question? AUDIENCE: In practice, how\ngood of a model is this?",
    "start": "2575055",
    "end": "2582098"
  },
  {
    "text": "DAVID SONTAG: Of what\nI'm showing you here? AUDIENCE: Yeah. DAVID SONTAG: For hypertension? AUDIENCE: Sure. DAVID SONTAG: I have no idea.",
    "start": "2582098",
    "end": "2587848"
  },
  {
    "text": " But I think what\nyou're really trying to get at here in asking your\nquestion, how good of a model",
    "start": "2587848",
    "end": "2594248"
  },
  {
    "text": "is this, is, well, oh,\nmy god, how do I know if I've observed everything? Right?",
    "start": "2594248",
    "end": "2600099"
  },
  {
    "text": "All right. And that's where\nyou need to start talking to domain experts. So this is my\nstarting place where",
    "start": "2600100",
    "end": "2607700"
  },
  {
    "text": "I said, no, I'm not\ngoing to attempt to fit the causal graph.",
    "start": "2607700",
    "end": "2612964"
  },
  {
    "text": " I'm going to assume I\nknow the causal graph and just try to\nestimate the effects.",
    "start": "2612965",
    "end": "2619020"
  },
  {
    "text": "That's where this starts to\nbecome really irrelevant. Because if you notice, this\nis another causal graph, not",
    "start": "2619020",
    "end": "2624053"
  },
  {
    "text": "the one I drew on the board.  And so that's something\nwhere, really,",
    "start": "2624053",
    "end": "2630110"
  },
  {
    "text": "talking with domain\nexperts would be relevant. So if you say, OK, I'm going\nto be studying hypertension",
    "start": "2630110",
    "end": "2637120"
  },
  {
    "text": "and this is the data I've\nobserved on patients, well, you can then go to a\nclinician, maybe a primary care",
    "start": "2637120",
    "end": "2644980"
  },
  {
    "text": "doctor who often treats\npatients with hypertension, and you say, OK, what usually\naffects your treatment",
    "start": "2644980",
    "end": "2650530"
  },
  {
    "text": "decisions? And you get a set\nof variables out, and then you check\nto make sure, am I",
    "start": "2650530",
    "end": "2655660"
  },
  {
    "text": "observing all of those\nvariables, at least the variables that would\nalso affect outcomes?",
    "start": "2655660",
    "end": "2660988"
  },
  {
    "text": "So, often, there's\ngoing to be a back and forth in that conversation\nto make sure that you've set up your problem correctly.",
    "start": "2660988",
    "end": "2666194"
  },
  {
    "text": "And again, this\nis one area where you see a critical\ndifference between the way that we do causal\ninference from the way that we do machine learning.",
    "start": "2666195",
    "end": "2672400"
  },
  {
    "text": "Machine learning, if there's\nsome unobserved variables, so what? I mean, maybe your predictive\naccuracy isn't quite as good",
    "start": "2672400",
    "end": "2678880"
  },
  {
    "text": "as it could have\nbeen, but whatever. Here, your conclusions\ncould be completely wrong",
    "start": "2678880",
    "end": "2683920"
  },
  {
    "text": "if you don't get those\nconfounding factors right. Now, in some of the\noptional readings",
    "start": "2683920",
    "end": "2690610"
  },
  {
    "text": "for Thursday's lecture-- and we'll touch on it\nvery briefly on Thursday, but there's not much\ntime in this course--",
    "start": "2690610",
    "end": "2697300"
  },
  {
    "text": "I'll talk about ways and\nyou'll read about ways to try to assess\nrobustness to violations",
    "start": "2697300",
    "end": "2703780"
  },
  {
    "text": "of these assumptions. And those go by the name\nof sensitivity analysis. So, for example, the type\nof question you might ask",
    "start": "2703780",
    "end": "2710200"
  },
  {
    "text": "is, how would my\nconclusions have changed if there were a\nconfounding factor which was blah strong?",
    "start": "2710200",
    "end": "2717860"
  },
  {
    "text": "And that's something that one\ncould try to answer from data,",
    "start": "2717860",
    "end": "2723210"
  },
  {
    "text": "but it's really starting\nto get beyond the scope of this course. So I'll give you\nsome readings on it, but I won't be able to talk\nabout it in the lecture.",
    "start": "2723210",
    "end": "2732000"
  },
  {
    "text": "Now, the second major\nassumption that one needs is what's known\nas common support. And by the way, pay\nclose attention here",
    "start": "2732000",
    "end": "2738610"
  },
  {
    "text": "because at the end of today's\nlecture-- and if I forget,",
    "start": "2738610",
    "end": "2743680"
  },
  {
    "text": "someone must remind me-- I'm going to ask you where did\nthese two assumptions come up",
    "start": "2743680",
    "end": "2749650"
  },
  {
    "text": "in the proof that I'm\nabout to give you. The first one I'm going to give\nyou will be a dead giveaway.",
    "start": "2749650",
    "end": "2755370"
  },
  {
    "text": "So I'm going to answer to you\nwhere ignorability comes up, but it's up to you\nto figure out where does common support show up.",
    "start": "2755370",
    "end": "2761560"
  },
  {
    "start": "2758000",
    "end": "2758000"
  },
  {
    "text": "So what is common support? Well, what common support\nsays is that there always",
    "start": "2761560",
    "end": "2767559"
  },
  {
    "text": "must be some stochasticity\nin the treatment decisions. For example, if in\nyour data patients only",
    "start": "2767560",
    "end": "2777270"
  },
  {
    "text": "receive treatment A and no\npatient receives treatment B, then you would never be able to\nfigure out the counterfactual,",
    "start": "2777270",
    "end": "2784420"
  },
  {
    "text": "what would have happened if\npatients receive treatment B. But what happens if it's\nnot quite that universal",
    "start": "2784420",
    "end": "2791050"
  },
  {
    "text": "but maybe there is\nclasses of people? Some individual is X, let's\nsay, people with blue hair.",
    "start": "2791050",
    "end": "2797350"
  },
  {
    "text": "People with blue hair always\nreceive treatment zero",
    "start": "2797350",
    "end": "2802450"
  },
  {
    "text": "and they never\nsee treatment one. Well, for those people,\nif for some reason",
    "start": "2802450",
    "end": "2809339"
  },
  {
    "text": "something about them\nhaving blue hair was also going to affect\nhow they would respond to the treatment,\nthen you wouldn't",
    "start": "2809340",
    "end": "2815250"
  },
  {
    "text": "be able to answer anything\nabout the counterfactual for those individuals. This goes by the name of what's\ncalled a propensity score.",
    "start": "2815250",
    "end": "2823559"
  },
  {
    "text": "It's the probability of\nreceiving some treatment for each individual.",
    "start": "2823560",
    "end": "2829230"
  },
  {
    "text": "And we're going to assume that\nthis propensity score is always bounded between 0 and 1.",
    "start": "2829230",
    "end": "2837150"
  },
  {
    "text": "So it's between 1 minus\nepsilon and epsilon for some small epsilon.",
    "start": "2837150",
    "end": "2843020"
  },
  {
    "text": "And violations of\nthat assumption are going to completely\ninvalidate all conclusions that we could draw\nfrom the data.",
    "start": "2843020",
    "end": "2850610"
  },
  {
    "text": "All right. Now, in actual clinical\npractice, you might wonder, can this ever hold?",
    "start": "2850610",
    "end": "2857010"
  },
  {
    "text": "Because there are\nclinical guidelines. Well, a couple of places where\nyou'll see this are as follows.",
    "start": "2857010",
    "end": "2863867"
  },
  {
    "text": "First, often, there are settings\nwhere we haven't the faintest idea how to treat patients,\nlike second line diabetes",
    "start": "2863867",
    "end": "2869720"
  },
  {
    "text": "treatments. You know that the first thing\nwe start with is metformin. But if metformin doesn't help\ncontrol the patient's glucose",
    "start": "2869720",
    "end": "2877310"
  },
  {
    "text": "values, there are several\nsecond line diabetic treatments. And right now, we don't\nreally know which one to try.",
    "start": "2877310",
    "end": "2883100"
  },
  {
    "text": "So a clinician might start\nwith treatments from one class. And if that's not working,\nyou try a different class,",
    "start": "2883100",
    "end": "2888570"
  },
  {
    "text": "and so on. And it's a bit random\nwhich class you start with for any one patient. In other settings, there might\nbe good clinical guidelines,",
    "start": "2888570",
    "end": "2896600"
  },
  {
    "text": "but there is randomness\nin other ways. For example, clinicians who\nare trained on the west coast",
    "start": "2896600",
    "end": "2905500"
  },
  {
    "text": "might be trained that this is\nthe right way to do things, and clinicians who are\ntrained in the east coast might be trained that this is\nthe right way to do things.",
    "start": "2905500",
    "end": "2913630"
  },
  {
    "text": "And so even if any one\nclinician's treatment decisions are deterministic\nin some way, you'll",
    "start": "2913630",
    "end": "2920260"
  },
  {
    "text": "see some stochasticity\nnow across clinicians. It's a bit subtle how to\nuse that in your analysis,",
    "start": "2920260",
    "end": "2925790"
  },
  {
    "text": "but trust me, it can be done. So if you want to\ndo causal inference",
    "start": "2925790",
    "end": "2931680"
  },
  {
    "text": "from observational\ndata, you're going to have to first start to\nformalize things mathematically in terms of what is your X, what\nis your T, what is your Y. You",
    "start": "2931680",
    "end": "2941190"
  },
  {
    "text": "have to think through,\ndo these choices satisfy these assumptions\nof ignorability and overlap?",
    "start": "2941190",
    "end": "2949310"
  },
  {
    "text": "Some of these things you\ncan check in your data. Ignorability you can't\nexplicitly check in your data. But overlap, this thing,\nyou can test in your data.",
    "start": "2949310",
    "end": "2959580"
  },
  {
    "text": "By the way, how? Any idea? ",
    "start": "2959580",
    "end": "2964828"
  },
  {
    "text": "Someone else who\nhasn't spoken today. ",
    "start": "2964828",
    "end": "2971320"
  },
  {
    "text": "So just think back to\nthe previous example. You have this table of these X's\nand treatment A or B and then",
    "start": "2971320",
    "end": "2981220"
  },
  {
    "text": "sugar values. How would you test this? AUDIENCE: You could use\na frequentist approach and just count how\nmany things show up.",
    "start": "2981220",
    "end": "2988550"
  },
  {
    "text": "And if there is zero, then you\ncould say that it's violated. DAVID SONTAG: Good. So you have this table.",
    "start": "2988550",
    "end": "2994705"
  },
  {
    "text": "I'll just go back to that table. We have this table,\nand these are your X's.",
    "start": "2994705",
    "end": "3003420"
  },
  {
    "text": " Actually, we'll go back\nto the previous slide where it's a bit easier to see.",
    "start": "3003420",
    "end": "3008972"
  },
  {
    "text": " Here, we're going to ignore\nthe outcome, the sugar",
    "start": "3008972",
    "end": "3017020"
  },
  {
    "text": "levels because,\nremember, this only has to do with\nprobability of treatment",
    "start": "3017020",
    "end": "3022029"
  },
  {
    "text": "given your covariance. The Y doesn't show\nup here at all. So this thing on\nthe right-hand side,",
    "start": "3022030",
    "end": "3027130"
  },
  {
    "text": "the observed sugar levels, is\nirrelevant for this question. All we care about is\nwhat goes on over here. So we look at this.",
    "start": "3027130",
    "end": "3032740"
  },
  {
    "text": "These are your X's, and\nthis is your treatment. And you can look to\nsee, OK, here you",
    "start": "3032740",
    "end": "3037840"
  },
  {
    "text": "have one 75-year-old\nmale who does exercise frequently and received\ntreatment A. Is there any one",
    "start": "3037840",
    "end": "3044680"
  },
  {
    "text": "else in the data set who\nis 75 years old and male, does exercise regularly\nbut received treatment B?",
    "start": "3044680",
    "end": "3051190"
  },
  {
    "text": "Yes or no? No. Good. OK. So overlap is not satisfied\nhere, at least not empirically.",
    "start": "3051190",
    "end": "3059360"
  },
  {
    "text": "Now, you might argue that I'm\nbeing a bit too coarse here. Well, what happens if\nthe individual is 74",
    "start": "3059360",
    "end": "3065740"
  },
  {
    "text": "and received treatment B? Maybe that's close enough. So there starts to\nbecome subtleties in assessing these things\nwhen you have finite data.",
    "start": "3065740",
    "end": "3072700"
  },
  {
    "text": "But it is something at\nthe fundamental level that you could start\nto assess using data. As opposed to ignorability,\nwhich you cannot test using",
    "start": "3072700",
    "end": "3079870"
  },
  {
    "text": "data. All right. So you have to think about, are\nthese assumptions satisfied?",
    "start": "3079870",
    "end": "3089990"
  },
  {
    "text": "And only once you start to think\nthrough those questions can you start to do your analysis.",
    "start": "3089990",
    "end": "3097339"
  },
  {
    "text": "And so that now brings me to\nthe next part of this lecture, which is how do we actually--\nlet's just now believe David,",
    "start": "3097340",
    "end": "3105260"
  },
  {
    "start": "3098000",
    "end": "3098000"
  },
  {
    "text": "believe that these\nassumptions hold. How do we do that\ncausal inference? Yeah? AUDIENCE: I just had a\nquestion on [INAUDIBLE]..",
    "start": "3105260",
    "end": "3111802"
  },
  {
    "text": "If you know that some patients,\nfor instance, healthy patients, are not tracking to\nget any treatment, should we just remove\nthem, basically?",
    "start": "3111802",
    "end": "3118890"
  },
  {
    "text": "DAVID SONTAG: So\nthe question is, what happens if you have\na violation of overlap?",
    "start": "3118890",
    "end": "3124710"
  },
  {
    "text": "For example, you know that\nhealthy individuals never receive any treatment.",
    "start": "3124710",
    "end": "3129770"
  },
  {
    "text": "Should you remove them\nfrom your data set? Well, first of all, that has\nto do with how do you formalize the question because not\nreceiving a treatment",
    "start": "3129770",
    "end": "3136160"
  },
  {
    "text": "is a treatment. So that might be your control\narm, just to be clear.",
    "start": "3136160",
    "end": "3141880"
  },
  {
    "text": "Now, if you're asking about\nthe difference between two treatments-- two different\nclasses of treatment for a condition, then often one\ndefines the relevant inclusion",
    "start": "3141880",
    "end": "3154000"
  },
  {
    "text": "criteria in order to have\nthese conditions hold.",
    "start": "3154000",
    "end": "3160990"
  },
  {
    "text": "For example, we could try to\nredefine the set of individuals that we're asking about\nso that overlap does hold.",
    "start": "3160990",
    "end": "3167140"
  },
  {
    "text": "But then in that\nsituation, you have to just make sure that your\npolicy is also modified. You say, OK, I conclude that\nthe average treatment effect is",
    "start": "3167140",
    "end": "3174640"
  },
  {
    "text": "blah for this type of people. OK?",
    "start": "3174640",
    "end": "3179830"
  },
  {
    "text": "OK. So how could we possibly compute\nthe average treatment effect",
    "start": "3179830",
    "end": "3185560"
  },
  {
    "text": "from data? Remember, average treatment\neffect, mathematically, is the expectation between\npotential outcome Y1 minus Y0.",
    "start": "3185560",
    "end": "3193635"
  },
  {
    "text": " The key tool which we'll use\nin order to estimate that",
    "start": "3193635",
    "end": "3200250"
  },
  {
    "text": "is what's known as the\nadjustment formula. This goes by many names in\nthe statistics community, such as the G-formula as well.",
    "start": "3200250",
    "end": "3206960"
  },
  {
    "text": "Here, I'll give you\na derivation of it. We're first going to recognize\nthat this expectation is",
    "start": "3206960",
    "end": "3214790"
  },
  {
    "text": "actually two\nexpectations in one. It's the expectation\nover individuals X and it's the expectation over\npotential outcomes Y given X.",
    "start": "3214790",
    "end": "3223575"
  },
  {
    "text": "So I'm first just\ngoing to write it out in terms of those\ntwo expectations, and I'll write the expectations\nrelated to X on the outside.",
    "start": "3223575",
    "end": "3230870"
  },
  {
    "text": "That goes by name of law\nof total expectation. This is trivial at this stage.",
    "start": "3230870",
    "end": "3238750"
  },
  {
    "text": "And by the way, I'm just\nwriting out expectation of Y1. In a few minutes, I'll\nshow you expectation of Y0,",
    "start": "3238750",
    "end": "3244900"
  },
  {
    "text": "but it's going to be\nexactly analogous. Now, the next step is\nwhere we use ignorability.",
    "start": "3244900",
    "end": "3251980"
  },
  {
    "text": "I told you I was going\nto give that one away. So remember, we said\nthat we're assuming",
    "start": "3251980",
    "end": "3259000"
  },
  {
    "text": "that Y1 is conditionally\nindependent of the treatment T given X. What that\nmeans is probability of Y1",
    "start": "3259000",
    "end": "3274210"
  },
  {
    "text": "given X is equal to\nprobability of Y1",
    "start": "3274210",
    "end": "3279910"
  },
  {
    "text": "given X comma T equals\nwhatever-- in this case I'll just say T equals 1.",
    "start": "3279910",
    "end": "3286750"
  },
  {
    "text": "This is implied by Y1 being\nconditionally independent of T",
    "start": "3286750",
    "end": "3292220"
  },
  {
    "text": "given X. So I can just stick n\ncomma T equals 1 here,",
    "start": "3292220",
    "end": "3299640"
  },
  {
    "text": "and that's explicitly because\nof ignorability holding.",
    "start": "3299640",
    "end": "3305089"
  },
  {
    "text": "But now we're in a really good\nplace because notice that-- and here I've just done\nsome short notation.",
    "start": "3305090",
    "end": "3310760"
  },
  {
    "text": "I'm just going to\nhide this expectation. ",
    "start": "3310760",
    "end": "3317550"
  },
  {
    "text": "And by the way, you could\ndo the same for Y0-- Y1, Y0. And now notice\nthat we can replace",
    "start": "3317550",
    "end": "3326329"
  },
  {
    "text": "this average human effect\nwith now this expectation with respect to\nall individuals X",
    "start": "3326330",
    "end": "3332440"
  },
  {
    "text": "of the expectation of Y1 given\nX comma T equals 1, and so on. ",
    "start": "3332440",
    "end": "3339500"
  },
  {
    "text": "And these are mostly\nquantities that we can now observe from our data.",
    "start": "3339500",
    "end": "3345560"
  },
  {
    "text": "So, for example, we can\nlook at the individuals who",
    "start": "3345560",
    "end": "3350980"
  },
  {
    "text": "received treatment one,\nand for those individuals we have realizations of Y1.",
    "start": "3350980",
    "end": "3356690"
  },
  {
    "text": "We can look at individuals\nwho receive treatment zero, and for those individuals\nwe have realizations of Y0.",
    "start": "3356690",
    "end": "3362496"
  },
  {
    "text": "And we could just average\nthose realizations to get estimates of the\ncorresponding expectations.",
    "start": "3362497",
    "end": "3367810"
  },
  {
    "text": "So these we can easily\nestimate from our data. ",
    "start": "3367810",
    "end": "3373020"
  },
  {
    "text": "And so we've made progress. We can now estimate some\npart of this from our data.",
    "start": "3373020",
    "end": "3378664"
  },
  {
    "text": "But notice, there\nare some things that we can't yet directly\nestimate from our data. In particular, we can't\nestimate expectation of Y0",
    "start": "3378665",
    "end": "3387450"
  },
  {
    "text": "given X comma T equals 1\nbecause we have no idea what would have happened to this\nindividual who actually",
    "start": "3387450",
    "end": "3394620"
  },
  {
    "text": "got treatment one if they\nhad gotten treatment zero. So these we don't know. ",
    "start": "3394620",
    "end": "3402210"
  },
  {
    "text": "So these we don't know. Now, what is the trick\nI'm planning on you?",
    "start": "3402210",
    "end": "3407620"
  },
  {
    "text": "How does it help\nthat we can do this? Well, the key point is\nthat these quantities that we can estimate from\ndata show up in that term.",
    "start": "3407620",
    "end": "3416790"
  },
  {
    "text": "In particular, if you\nlook at the individuals X that you've sampled from the\nfull set of individuals P of X,",
    "start": "3416790",
    "end": "3424230"
  },
  {
    "text": "for that individual\nX for which, in fact, we observed T equals 1, then we\ncan estimate expectation of Y1",
    "start": "3424230",
    "end": "3431309"
  },
  {
    "text": "given X comma T equals\n1, and similarly for Y0.",
    "start": "3431310",
    "end": "3436430"
  },
  {
    "text": "But what we need to be able\nto do is to extrapolate. Because empirically, we only\nhave samples from P of X",
    "start": "3436430",
    "end": "3442995"
  },
  {
    "text": "given T equals 1, P\nof X given T equals 0 for those two potential\noutcomes correspondingly. But we are going to also\nget samples of X such",
    "start": "3442995",
    "end": "3451670"
  },
  {
    "text": "that for those individuals\nin your data set, you might have only\nobserved T equals 0. And to compute this formula,\nyou have to answer, for that X,",
    "start": "3451670",
    "end": "3461180"
  },
  {
    "text": "what would it have been if\nthey got treatment equals one? So there are going to\nbe a set of individuals",
    "start": "3461180",
    "end": "3466283"
  },
  {
    "text": "that we have to\nextrapolate for in order to use this adjustment\nformula for estimate. ",
    "start": "3466283",
    "end": "3472779"
  },
  {
    "text": "Yep? AUDIENCE: I thought because\ncommon support is true, we have some patients that\nreceived each treatment",
    "start": "3472780",
    "end": "3478010"
  },
  {
    "text": "or a given type of X. DAVID SONTAG: Yes. But now-- so, yes, that's true.",
    "start": "3478010",
    "end": "3486850"
  },
  {
    "text": " But that's a statement\nabout infinite data.",
    "start": "3486850",
    "end": "3493920"
  },
  {
    "text": "And in reality, one\nonly has finite data. And so although common support\nhas to hold to some extent,",
    "start": "3493920",
    "end": "3502590"
  },
  {
    "text": "you can't just build on\nthat to say that you always observe the counterfactual\nfor every individual,",
    "start": "3502590",
    "end": "3509240"
  },
  {
    "text": "such as the pictures\nI showed you earlier.  So I'm going to leave this slide\nup for just one more second",
    "start": "3509240",
    "end": "3516340"
  },
  {
    "text": "to let it sink in and\nsee what it's saying. ",
    "start": "3516340",
    "end": "3521660"
  },
  {
    "text": "We started out from the goal of\ncomputing the average treatment effect, expected\nvalue of Y1 minus Y0.",
    "start": "3521660",
    "end": "3528330"
  },
  {
    "text": "Using the adjustment\nformula, we've gotten to now an equivalent\nrepresentation, which",
    "start": "3528330",
    "end": "3534750"
  },
  {
    "text": "is now an expectation with\nrespect to all individuals sampling from P of X\nof expected value of Y1",
    "start": "3534750",
    "end": "3543310"
  },
  {
    "text": "given X comma T equals\n1, expected value of Y0 given X comma T equals 0. For some of the individuals,\nyou can observe this,",
    "start": "3543310",
    "end": "3550223"
  },
  {
    "text": "and for some of them,\nyou have to extrapolate.  So from here, there are\nmany ways that one can go.",
    "start": "3550223",
    "end": "3558547"
  },
  {
    "text": "Hold your question\nfor a little while.  So types of causal\ninference methods",
    "start": "3558547",
    "end": "3565940"
  },
  {
    "text": "that you will have\nheard of include things like\ncovariance adjustment, propensity score re-weighting,\ndoubly robust estimators,",
    "start": "3565940",
    "end": "3572120"
  },
  {
    "text": "matching, and so on. And those are the tools of\nthe causal inference trade.",
    "start": "3572120",
    "end": "3577520"
  },
  {
    "text": "And in this course,\nwe're only going to talk about the first two. And in today's\nlecture, we're only going to talk about the first\none, covariate adjustment.",
    "start": "3577520",
    "end": "3584083"
  },
  {
    "text": "And on Thursday, we'll\ntalk about the second one. So covariate adjustment\nis a very natural way",
    "start": "3584083",
    "end": "3590690"
  },
  {
    "start": "3590000",
    "end": "3590000"
  },
  {
    "text": "to try to do that extrapolation. It also goes by the name, by\nthe way, of response surface",
    "start": "3590690",
    "end": "3596880"
  },
  {
    "text": "modeling. What we're going to\ndo is we're going to learn a function f, which\ntakes as an input X and T,",
    "start": "3596880",
    "end": "3604010"
  },
  {
    "text": "and its goals is to predict\nY. So intuitively, you should think about f as\nthis conditional probability",
    "start": "3604010",
    "end": "3610790"
  },
  {
    "text": "distribution. It's predicting Y\ngiven X and T. So",
    "start": "3610790",
    "end": "3619140"
  },
  {
    "text": "T is going to be an input\nto the machine learning algorithm, which is going\nto predict what would be",
    "start": "3619140",
    "end": "3625830"
  },
  {
    "text": "the potential outcome Y for this\nindividual described by feature",
    "start": "3625830",
    "end": "3630850"
  },
  {
    "text": "as X1 through Xd\nunder intervention T.",
    "start": "3630850",
    "end": "3642720"
  },
  {
    "text": "So this is just from\nthe previous slide. And what we're going\nto do now are-- this is now where we get the\nreduction to machine learning--",
    "start": "3642720",
    "end": "3650640"
  },
  {
    "text": "is we're going to use empirical\nrisk minimization, or maybe some regularized empirical risk\nminimization, to fit a function",
    "start": "3650640",
    "end": "3657480"
  },
  {
    "text": "f which approximates the\nexpected value of YT given capital T equals little t.",
    "start": "3657480",
    "end": "3663910"
  },
  {
    "text": "Got my X. And then once\nyou have that function, we're going to be able\nto use that to estimate",
    "start": "3663910",
    "end": "3670260"
  },
  {
    "text": "the average treatment effect\nby just implementing now",
    "start": "3670260",
    "end": "3675420"
  },
  {
    "text": "this formula here. So we're going to first take\nan expectation with respect to the individuals\nin the data set.",
    "start": "3675420",
    "end": "3680790"
  },
  {
    "text": "So we're going to\napproximate that with an empirical expectation\nwhere we sum over the little n",
    "start": "3680790",
    "end": "3685890"
  },
  {
    "text": "individuals in your data set. Then what we're\ngoing to do is we're going to estimate the first\nterm, which is f of Xi comma 1",
    "start": "3685890",
    "end": "3696620"
  },
  {
    "text": "because that is approximating\nthe expected value of Y1 given T comma X-- T equals 1 comma\nX. And we're going",
    "start": "3696620",
    "end": "3703970"
  },
  {
    "text": "to approximate the second\nterm, which is just plugging now 0 for T instead of 1.",
    "start": "3703970",
    "end": "3709750"
  },
  {
    "text": "And we're going to take the\ndifference between them, and that will be our estimator\nof the average treatment effect.",
    "start": "3709750",
    "end": "3715130"
  },
  {
    "start": "3715130",
    "end": "3720357"
  },
  {
    "text": "Here's a natural place\nto ask a question. ",
    "start": "3720357",
    "end": "3727210"
  },
  {
    "text": "One thing you might wonder\nis, in your data set,",
    "start": "3727210",
    "end": "3732578"
  },
  {
    "text": "you actually did observe\nsomething for that individual, right. Notice how your raw data\ndoesn't show up in this at all.",
    "start": "3732578",
    "end": "3740549"
  },
  {
    "text": "Because I've done\nmachine learning, and then I've thrown\naway the observed Y's,",
    "start": "3740550",
    "end": "3747030"
  },
  {
    "text": "and I used this estimator. So what you could have done--\nan alternative formula, which,",
    "start": "3747030",
    "end": "3753120"
  },
  {
    "text": "by the way, is also a\nconsistent estimator, would have been to\nuse the observed",
    "start": "3753120",
    "end": "3758280"
  },
  {
    "text": "Y for whatever the factual\nis and the imputed Y for the counterfactual using f.",
    "start": "3758280",
    "end": "3764642"
  },
  {
    "text": "That would have been\nthat would have also been a consistent estimator for\nthe average treatment effect. You could've done either.",
    "start": "3764642",
    "end": "3769732"
  },
  {
    "text": " OK. ",
    "start": "3769732",
    "end": "3777050"
  },
  {
    "text": "Now, sometimes you're\nnot interested in just the average treatment\neffect, but you're actually interested in understanding\nthe heterogeneity",
    "start": "3777050",
    "end": "3782555"
  },
  {
    "text": "in the population. Well, this also now\ngives you an opportunity to try to explore\nthat heterogeneity.",
    "start": "3782555",
    "end": "3788460"
  },
  {
    "text": "So for each\nindividual Xi, you can look at just the\ndifference between what f predicts for\ntreatment one and what X",
    "start": "3788460",
    "end": "3796580"
  },
  {
    "text": "predicts given treatment zero. And the difference\nbetween those is your estimate of your\nconditional average treatment effect.",
    "start": "3796580",
    "end": "3801695"
  },
  {
    "text": "So, for example, if\nyou want to figure out for this individual, what\nis the optimal policy, you might look to see is\nCATE positive or negative,",
    "start": "3801695",
    "end": "3807667"
  },
  {
    "text": "or is it greater than some\nthreshold, for example?  So let's look at some pictures.",
    "start": "3807667",
    "end": "3813440"
  },
  {
    "text": " Now what we're using is we're\nusing that function f in order",
    "start": "3813440",
    "end": "3819030"
  },
  {
    "text": "to impute those counterfactuals. And now we have those\nobserved, and we can actually compute the CATE.",
    "start": "3819030",
    "end": "3825540"
  },
  {
    "text": "And averaging over those,\nyou can estimate now the average treatment effect.",
    "start": "3825540",
    "end": "3831060"
  },
  {
    "text": "Yep? AUDIENCE: How is f non-biased?  DAVID SONTAG: Good. So where can this go wrong?",
    "start": "3831060",
    "end": "3837008"
  },
  {
    "text": "So what do you mean\nby biased, first? I'll ask that. AUDIENCE: For\ninstance, as we've seen in the paper like pneumonia\nand people who have asthma,",
    "start": "3837008",
    "end": "3844820"
  },
  {
    "text": "[INAUDIBLE]  DAVID SONTAG: Oh, thank you so\nmuch for bringing that back up.",
    "start": "3844820",
    "end": "3851300"
  },
  {
    "text": "So you're referring\nto one of the readings for the course\nfrom several weeks",
    "start": "3851300",
    "end": "3857000"
  },
  {
    "text": "ago, where we talked about using\njust a pure machine learning algorithm to try to predict\noutcomes in a hospital setting.",
    "start": "3857000",
    "end": "3864902"
  },
  {
    "text": "In particular, what\nhappens for patients who have pneumonia in\nthe emergency department? And if you all remember,\nthere was this asthma example,",
    "start": "3864903",
    "end": "3872600"
  },
  {
    "text": "where patients with\nasthma were predicted to have better outcomes than\npatients without asthma.",
    "start": "3872600",
    "end": "3881090"
  },
  {
    "text": " And you're calling that bias. But you remember, when\nI taught about this,",
    "start": "3881090",
    "end": "3886980"
  },
  {
    "text": "I called it biased due\nto a particular thing. What's the language I used? ",
    "start": "3886980",
    "end": "3892990"
  },
  {
    "text": "I said bias due to\nintervention, maybe, is what I--",
    "start": "3892990",
    "end": "3898978"
  },
  {
    "text": "I can't remember\nexactly what I said. [LAUGHTER] I don't know. Make it up.",
    "start": "3898978",
    "end": "3906240"
  },
  {
    "text": "Now a textbook will be written\nwith bias by intervention. OK. So the problem\nthere is that they",
    "start": "3906240",
    "end": "3912160"
  },
  {
    "text": "didn't formulize the\nprediction problem correctly. The question that\nthey should have asked",
    "start": "3912160",
    "end": "3917860"
  },
  {
    "text": "is, for asthma patients-- ",
    "start": "3917860",
    "end": "3923440"
  },
  {
    "text": "what you really want to ask is a\nquestion of X and then T and Y,",
    "start": "3923440",
    "end": "3931150"
  },
  {
    "text": "where T are the interventions\nthat are done for asthmatics.",
    "start": "3931150",
    "end": "3939359"
  },
  {
    "start": "3939360",
    "end": "3945090"
  },
  {
    "text": "So the failure of that\npaper is that it ignored the causal inference question\nwhich was hidden in the data,",
    "start": "3945090",
    "end": "3951359"
  },
  {
    "text": "and it just went to predict\nY given X marginalizing over T altogether. So T was never in\nthe predictive model.",
    "start": "3951360",
    "end": "3959070"
  },
  {
    "text": "And said differently, they never\nasked counterfactual questions of what would have happened\nhad you done a different T.",
    "start": "3959070",
    "end": "3964200"
  },
  {
    "text": "And then they still used it\nto try to guide some treatment decisions. Like, for example, should\nyou send this person home,",
    "start": "3964200",
    "end": "3969839"
  },
  {
    "text": "or should you keep them for\ncareful monitoring or so on? So this is exactly\nthe same example as I gave in the\nbeginning of the lecture,",
    "start": "3969840",
    "end": "3976260"
  },
  {
    "text": "where I said if you just\nuse a risk stratification model to make some decisions,\nyou run the risk that you're",
    "start": "3976260",
    "end": "3983430"
  },
  {
    "text": "making the wrong decisions\nbecause those predictions were biased by decisions\nin your data.",
    "start": "3983430",
    "end": "3990359"
  },
  {
    "text": "So that doesn't happen here\nbecause we're explicitly accounting for T in\nall of our analysis. Yep?",
    "start": "3990360",
    "end": "3995980"
  },
  {
    "text": "AUDIENCE: In the data sets\nthat we've used, like MIMIC, how much treatment\ninformation exists? DAVID SONTAG: So how much\ntreatment information",
    "start": "3995980",
    "end": "4001880"
  },
  {
    "text": "is in MIMIC? A ton. In fact, one of the\nreadings for next week",
    "start": "4001880",
    "end": "4008240"
  },
  {
    "text": "is going to be about trying to\nunderstand how one could manage sepsis, which is a condition\ncaused by infection, which",
    "start": "4008240",
    "end": "4018920"
  },
  {
    "text": "is managed by, for example,\ngiving broad spectrum antibiotics, giving\nfluids, giving",
    "start": "4018920",
    "end": "4025849"
  },
  {
    "text": "pressers and ventilators. And all of those\nare interventions, and all those interventions\nare recorded in the data",
    "start": "4025850",
    "end": "4031227"
  },
  {
    "text": "so that one could then ask\ncounterfactual questions from the data, like\nwhat would have happened if this patient\nhad they received a different set\nof interventions?",
    "start": "4031227",
    "end": "4037545"
  },
  {
    "text": "Would we have prolonged\ntheir life, for example? And so in an intensive care unit\nsetting, most of the questions",
    "start": "4037545",
    "end": "4044383"
  },
  {
    "text": "that we want to ask about,\nnot all, but many of them are about dynamic treatments\nbecause it's not just a single treatment\nbut really about",
    "start": "4044383",
    "end": "4050698"
  },
  {
    "text": "a service sequence of\ntreatments responding to the current\npatient condition. And so that's where we'll really\nstart to get into that material",
    "start": "4050698",
    "end": "4056720"
  },
  {
    "text": "next week, not in\ntoday's lecture. Yep? AUDIENCE: How do you make sure\nthat your f function really",
    "start": "4056720",
    "end": "4064022"
  },
  {
    "text": "learned from the relationship\nbetween T and the outcome? DAVID SONTAG: That's\na phenomenal question. Where were you\nthis whole course?",
    "start": "4064022",
    "end": "4070809"
  },
  {
    "text": "Thank you for asking it. So I'll repeat it. How do you know that\nyour function f actually",
    "start": "4070810",
    "end": "4076099"
  },
  {
    "text": "learned something about the\nrelationship between the input X and the treatment\nT and the outcome?",
    "start": "4076100",
    "end": "4084730"
  },
  {
    "text": "And that really gets\nto the question of, is my reduction actually valid? So I've taken this\nproblem and I've",
    "start": "4084730",
    "end": "4099979"
  },
  {
    "text": "reduced it to this machine\nlearning problem, where I take my data, and\nliterally I just",
    "start": "4099979",
    "end": "4107339"
  },
  {
    "text": "learn a function f to\ntry to predict well the observations in the data.",
    "start": "4107340",
    "end": "4112549"
  },
  {
    "text": "And how do we know that\nthat function f actually does a good job at\nestimating something like average treatment effect?",
    "start": "4112550",
    "end": "4118682"
  },
  {
    "text": "In fact, it might not. And this is where\nthings start to get",
    "start": "4118682",
    "end": "4124250"
  },
  {
    "text": "really tricky, particularly\nwith high dimensional data. Because it could happen, for\nexample, that your treatment",
    "start": "4124250",
    "end": "4131520"
  },
  {
    "text": "decision is only one of a huge\nnumber of factors that affect the outcome Y. And it\ncould be that a much more",
    "start": "4131520",
    "end": "4139130"
  },
  {
    "text": "important factor is hidden in\nX. And because you don't have much data, and because you have\nto regularize your learning",
    "start": "4139130",
    "end": "4145639"
  },
  {
    "text": "algorithm, let's say, with L1\nor L2 regularization or maybe early stopping if you're\nusing deep neural network, your algorithm might never learn\nthe actual dependence on T.",
    "start": "4145640",
    "end": "4155790"
  },
  {
    "text": "It might learn just to\nthrow away T and just use X to predict Y.\nAnd if that's the case,",
    "start": "4155790",
    "end": "4163649"
  },
  {
    "text": "you will never be able to\ninfer these average treatment effects accurately. You'll have huge errors.",
    "start": "4163649",
    "end": "4169545"
  },
  {
    "text": "And that gets back\nto one of the slides that I skipped, where I\nstarted out from this picture. This is the machine learning\npicture saying, OK, a reduction",
    "start": "4169545",
    "end": "4176990"
  },
  {
    "text": "to machine learning is-- now you add an\nadditional feature, which is your\ntreatment decision, and you learn that\nblack box function f.",
    "start": "4176990",
    "end": "4184795"
  },
  {
    "text": "But this is where machine\nlearning causal inference starts to differ because\nwe don't actually",
    "start": "4184795",
    "end": "4190100"
  },
  {
    "text": "care about the quality\nof predicting Y.",
    "start": "4190100",
    "end": "4195703"
  },
  {
    "text": "We can measure your\nroot mean squared error in predicting Y given your\nX's and T's, and that error might be low.",
    "start": "4195703",
    "end": "4202550"
  },
  {
    "text": "But you can run into\nthese failure modes where it just completely\nignores T, for example.",
    "start": "4202550",
    "end": "4208130"
  },
  {
    "text": "So T is special here. So really, the picture\nwe want to have in mind is that T is some\nparameter of interest.",
    "start": "4208130",
    "end": "4215760"
  },
  {
    "text": "We want to learn a model f\nsuch that if we twiddle T, we can see how there is a\ndifferential effect on Y based",
    "start": "4215760",
    "end": "4222500"
  },
  {
    "text": "on twiddling T.\nThat's what we truly care about when we're\nusing machine learning for causal inference.",
    "start": "4222500",
    "end": "4228290"
  },
  {
    "text": "And so that's really\nthe gap, that's the gap in our\nunderstanding today. And it's really an\nactive area of research",
    "start": "4228290",
    "end": "4234680"
  },
  {
    "text": "to figure out how do you change\nthe whole machine learning paradigm to recognize that when\nyou're using machine learning",
    "start": "4234680",
    "end": "4240938"
  },
  {
    "text": "for causal inference,\nyou're actually interested in something\na little bit different. And by the way, that's a major\narea of my lab's research,",
    "start": "4240938",
    "end": "4247370"
  },
  {
    "text": "and we just published\na series of papers trying to answer that question. Beyond the scope of\nthis course, but I'm happy to send you those\npapers if anyone's interested.",
    "start": "4247370",
    "end": "4256370"
  },
  {
    "text": "So that type of question\nis extremely important. It doesn't show up quite as much\nwhen your X's aren't very high",
    "start": "4256370",
    "end": "4264739"
  },
  {
    "text": "dimensional and where\nthings like regularization don't become important. But once your X becomes\nhigh dimensional",
    "start": "4264740",
    "end": "4271310"
  },
  {
    "text": "and once you want to start to\nconsider more and more complex f's during your\nfitting, like you want to use deep neural\nnetworks, for example,",
    "start": "4271310",
    "end": "4278510"
  },
  {
    "text": "these differences in goals\nbecome extremely important. ",
    "start": "4278510",
    "end": "4295790"
  },
  {
    "text": "So there are other ways\nin which things can fail. So I want to give you\nhere an example where--",
    "start": "4295790",
    "end": "4303205"
  },
  {
    "text": "shoot, I'm answering\nmy question.  OK. ",
    "start": "4303205",
    "end": "4310840"
  },
  {
    "text": "No one saw that slide. Question-- where did\nthe overlap assumptions show up in our approach for\nestimating average treatment",
    "start": "4310840",
    "end": "4319929"
  },
  {
    "text": "effect using\ncovariate adjustment? ",
    "start": "4319930",
    "end": "4337580"
  },
  {
    "text": "Let me go back to the formula. ",
    "start": "4337580",
    "end": "4344630"
  },
  {
    "text": "Someone who hasn't\nspoken today, hopefully. You can be wrong, it's fine. ",
    "start": "4344630",
    "end": "4351430"
  },
  {
    "text": "Yeah, in the back? AUDIENCE: Is it the\nversion with the same age in receiving treatment\nB and treatment B?",
    "start": "4351430",
    "end": "4357520"
  },
  {
    "text": "DAVID SONTAG: So maybe you have\nan individual with some age--",
    "start": "4357520",
    "end": "4363917"
  },
  {
    "text": "we're going to want\nto be able to look at the difference between what\nf predicts for that individual if they got treatment\nA versus treatment B,",
    "start": "4363917",
    "end": "4370150"
  },
  {
    "text": "or one versus zero. And let me try to lead\nthis a little bit.",
    "start": "4370150",
    "end": "4377500"
  },
  {
    "text": "And it might happen\nin your data set that for individuals\nlike them, you only ever",
    "start": "4377500",
    "end": "4384310"
  },
  {
    "text": "observe treatment one and\nthere's no one even remotely like them who you\nobserve treatment zero.",
    "start": "4384310",
    "end": "4389800"
  },
  {
    "text": "So what's this function\ngoing to output then when you input zero for\nthat second argument?",
    "start": "4389800",
    "end": "4397290"
  },
  {
    "text": "Everyone say out loud. Garbage? Right?",
    "start": "4397290",
    "end": "4402700"
  },
  {
    "text": "If in your data set you never\nobserved anyone even remotely",
    "start": "4402700",
    "end": "4407710"
  },
  {
    "text": "similar to Xi who\nreceived treatment zero, then this function is basically\nundefined for that individual.",
    "start": "4407710",
    "end": "4414428"
  },
  {
    "text": "I mean, yeah, your function\nwill output something because you fit it, but it's not\ngoing to be the right answer.",
    "start": "4414428",
    "end": "4421610"
  },
  {
    "text": "And so that's where this\nassumption starts to show up. When one talks about the\nsample complexity of learning",
    "start": "4421610",
    "end": "4429909"
  },
  {
    "text": "these functions f to do\ncovariate adjustment, and when one talks\nabout the consistency",
    "start": "4429910",
    "end": "4435730"
  },
  {
    "text": "of these arguments--\nfor example, you'd like to be\nable to make claims that as the amount of\ndata grows to, let's",
    "start": "4435730",
    "end": "4441220"
  },
  {
    "text": "say, infinity, that this is\nthe right answer-- gives you the right estimate. So that's the type\nof proof which",
    "start": "4441220",
    "end": "4447489"
  },
  {
    "text": "is often given in the\ncausal inference literature. Well, if you have overlap,\nthen as the amount of data",
    "start": "4447490",
    "end": "4453920"
  },
  {
    "text": "goes to infinity, you\nwill observe someone, like the person who\nreceived treatment one,",
    "start": "4453920",
    "end": "4459930"
  },
  {
    "text": "you'll observe someone who\nalso received treatment zero. It might have taken you a huge\namount of data to get there because treatment zero\nmight have been much less",
    "start": "4459930",
    "end": "4466110"
  },
  {
    "text": "likely than treatment one. But because the probability\nof treatment zero is not zero, eventually you'll see\nsomeone like that.",
    "start": "4466110",
    "end": "4472810"
  },
  {
    "text": "And so eventually\nyou'll get enough data in order to learn a function\nwhich can extrapolate correctly for that individual.",
    "start": "4472810",
    "end": "4479700"
  },
  {
    "text": "And so that's where\noverlap comes in in giving that type of\nconsistency argument.",
    "start": "4479700",
    "end": "4486450"
  },
  {
    "text": "Of course, in reality, you\nnever have infinite data. And so these questions\nabout trade-offs",
    "start": "4486450",
    "end": "4494280"
  },
  {
    "text": "between the amount\nof data you have and the fact that\nyou never truly have",
    "start": "4494280",
    "end": "4499469"
  },
  {
    "text": "empirical overlap with\na small amount of data, and answering when can\nyou extrapolate correctly",
    "start": "4499470",
    "end": "4505380"
  },
  {
    "text": "despite that is the\ncritical question that one needs to answer,\nbut is, by the way, not studied very well\nin the literature",
    "start": "4505380",
    "end": "4511661"
  },
  {
    "text": "because people don't usually\nthink in terms of sample complexity in that field. That's where computer\nscientists can start really",
    "start": "4511662",
    "end": "4518190"
  },
  {
    "text": "to contribute to this\nliterature and bringing things that we often think\nabout in machine learning to this new topic.",
    "start": "4518190",
    "end": "4526120"
  },
  {
    "text": "So I've got a couple\nof minutes left. Are there any other\nquestions, or should I",
    "start": "4526120",
    "end": "4531860"
  },
  {
    "text": "introduce some new\nmaterial in one minute? Yeah? AUDIENCE: So you said that\nthe average treatment effect",
    "start": "4531860",
    "end": "4538159"
  },
  {
    "text": "estimator here is consistent. But does it matter if\nwe choose the wrong-- do we have to choose some\nfunctional form of the features",
    "start": "4538160",
    "end": "4546829"
  },
  {
    "text": "to the effect? DAVID SONTAG: Great question. AUDIENCE: Is it consistent even\nif we choose a completely wrong function or formula?",
    "start": "4546830",
    "end": "4552582"
  },
  {
    "text": "DAVID SONTAG: No. AUDIENCE: That's\na different thing? DAVID SONTAG: No, no. You're asking all\nthe right questions. Good job today, everyone.",
    "start": "4552582",
    "end": "4558050"
  },
  {
    "text": "So, no. If you walk through\nthat argument I made,",
    "start": "4558050",
    "end": "4563750"
  },
  {
    "text": "I assume two things. First, that you observe\nenough data such that you can have any chance\nof extrapolating correctly.",
    "start": "4563750",
    "end": "4572330"
  },
  {
    "text": "But then implicit\nin that statement is that you're\nchoosing a function family which is\npowerful enough that it can extrapolate correctly.",
    "start": "4572330",
    "end": "4579060"
  },
  {
    "text": "So if your true function is--  if you think back to this\nfigure I showed you here,",
    "start": "4579060",
    "end": "4588969"
  },
  {
    "text": "if the true potential\noutcome functions are these quadratic functions\nand you're fitting them",
    "start": "4588970",
    "end": "4594250"
  },
  {
    "text": "with a linear function,\nthen no matter how much data you\nhave you're always going to get wrong estimates\nbecause this argument really",
    "start": "4594250",
    "end": "4602230"
  },
  {
    "text": "requires that you're considering\nmore and more complex non-linearity as your\namount of data grows.",
    "start": "4602230",
    "end": "4608710"
  },
  {
    "text": "So now here's a visual\ndepiction of what can go wrong if you don't have overlap. So now I've taken out--",
    "start": "4608710",
    "end": "4615070"
  },
  {
    "text": "previously, I had one or two\nred points over here and one or two blue points over here,\nbut I've taken those out.",
    "start": "4615070",
    "end": "4620079"
  },
  {
    "text": "So in your data all you\nhave are these blue points and those red points. ",
    "start": "4620080",
    "end": "4626500"
  },
  {
    "text": "So all you have are\nthe points, and now one can learn as good functions,\nas you can imagine, to try to,",
    "start": "4626500",
    "end": "4632140"
  },
  {
    "text": "let's say, minimize the mean\nsquared error of predicting these blue points and minimize\nthe mean squared error",
    "start": "4632140",
    "end": "4637840"
  },
  {
    "text": "of predicting those red points. And what you might get\nout is something-- maybe you'll decide on\na linear function.",
    "start": "4637840",
    "end": "4643130"
  },
  {
    "text": "That's as good as you\ncould do if all you have are those red points.",
    "start": "4643130",
    "end": "4648940"
  },
  {
    "text": "And so even if you were\nwilling to consider more and more complex\nhypothesis classes,",
    "start": "4648940",
    "end": "4654010"
  },
  {
    "text": "here, if you tried to consider\na more complex hypothesis class than this line, you'd\nprobably just over-fitting",
    "start": "4654010",
    "end": "4659620"
  },
  {
    "text": "to the data you have. And so you decide\non that line, which,",
    "start": "4659620",
    "end": "4664750"
  },
  {
    "text": "because you had\nno data over here, you don't even know that it's\nnot a good fit to the data.",
    "start": "4664750",
    "end": "4671680"
  },
  {
    "text": "And then you notice\nthat you're getting completely wrong estimates. For example, if you asked about\nthe CATE for a young person,",
    "start": "4671680",
    "end": "4678050"
  },
  {
    "text": "it would have the wrong sign\nover here because they flipped, the two lines.",
    "start": "4678050",
    "end": "4683199"
  },
  {
    "text": "So that's an example of how\none can start to get errors. And when we begin on\nThursday's lecture,",
    "start": "4683200",
    "end": "4690789"
  },
  {
    "text": "we're going to pick up right\nwhere we left off today, and I'll talk about this issue\na little bit more in detail.",
    "start": "4690790",
    "end": "4697369"
  },
  {
    "text": "I'll talk about how, if one were\nto learn a linear function, how one could actually,\nunder the assumption",
    "start": "4697370",
    "end": "4703090"
  },
  {
    "text": "that the true potential\noutcomes are linear, how one could actually\ninterpret the coefficients of that linear function\nin a causal way",
    "start": "4703090",
    "end": "4709435"
  },
  {
    "text": "under the very strong\nassumption that the two potential outcomes are linear. So that's what we'll\nreturn to on Thursday.",
    "start": "4709435",
    "end": "4715180"
  },
  {
    "start": "4715180",
    "end": "4722000"
  }
]
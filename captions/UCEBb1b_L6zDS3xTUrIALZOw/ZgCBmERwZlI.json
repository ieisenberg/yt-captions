[
  {
    "start": "0",
    "end": "880"
  },
  {
    "text": "We will finish our discussion\nof classical statistical",
    "start": "880",
    "end": "3630"
  },
  {
    "text": "methods by discussing a general\nmethod for estimation,",
    "start": "3630",
    "end": "7330"
  },
  {
    "text": "the so-called maximum\nlikelihood method.",
    "start": "7330",
    "end": "10650"
  },
  {
    "text": "If an unknown parameter can be\nexpressed as an expectation,",
    "start": "10650",
    "end": "14150"
  },
  {
    "text": "we have seen that there's a\nnatural way of estimating it.",
    "start": "14150",
    "end": "17710"
  },
  {
    "text": "But what if this is\nnot the case?",
    "start": "17710",
    "end": "20730"
  },
  {
    "text": "Suppose there's no apparent way\nof interpreting theta as",
    "start": "20730",
    "end": "24660"
  },
  {
    "text": "an expectation.",
    "start": "24660",
    "end": "25760"
  },
  {
    "text": "So we need to do\nsomething else.",
    "start": "25760",
    "end": "28410"
  },
  {
    "text": "So rather than using this\napproach, we will use a",
    "start": "28410",
    "end": "32110"
  },
  {
    "text": "different approach, which\nis the following.",
    "start": "32110",
    "end": "34550"
  },
  {
    "text": "We will find a value of theta\nthat makes the data that we",
    "start": "34550",
    "end": "39780"
  },
  {
    "text": "have seen most likely.",
    "start": "39780",
    "end": "42420"
  },
  {
    "text": "That is, we will find the value\nof theta under which the",
    "start": "42420",
    "end": "46969"
  },
  {
    "text": "probability of obtaining\nthe particular x",
    "start": "46970",
    "end": "49950"
  },
  {
    "text": "that we have seen--",
    "start": "49950",
    "end": "51710"
  },
  {
    "text": "that probability is as\nlarge as possible.",
    "start": "51710",
    "end": "54899"
  },
  {
    "text": "And that value of theta is going\nto be our estimate, the",
    "start": "54900",
    "end": "57780"
  },
  {
    "text": "maximum likelihood estimate.",
    "start": "57780",
    "end": "59899"
  },
  {
    "text": "Here, I wrote a PMF.",
    "start": "59900",
    "end": "62240"
  },
  {
    "text": "That's what you would\ndo if X was a",
    "start": "62240",
    "end": "64128"
  },
  {
    "text": "discrete random variable.",
    "start": "64129",
    "end": "65470"
  },
  {
    "text": "But the same procedure, of\ncourse, applies when X is a",
    "start": "65470",
    "end": "70170"
  },
  {
    "text": "continuous random variable.",
    "start": "70170",
    "end": "72439"
  },
  {
    "text": "And more generally, this\nprocedure also applies when X",
    "start": "72440",
    "end": "76039"
  },
  {
    "text": "is a vector of observations and\nwhen theta is a vector of",
    "start": "76039",
    "end": "80550"
  },
  {
    "text": "parameters.",
    "start": "80550",
    "end": "82480"
  },
  {
    "text": "But what does this\nmethod really do?",
    "start": "82480",
    "end": "85289"
  },
  {
    "text": "It is instructive to compare\nmaximum likelihood estimation",
    "start": "85289",
    "end": "88420"
  },
  {
    "text": "to a Bayesian approach.",
    "start": "88420",
    "end": "90159"
  },
  {
    "text": "In a Bayesian setting, what we\ndo is, we find the posterior",
    "start": "90160",
    "end": "94270"
  },
  {
    "text": "distribution of the unknown\nparameter, which is now",
    "start": "94270",
    "end": "97329"
  },
  {
    "text": "treated as a random variable.",
    "start": "97330",
    "end": "100180"
  },
  {
    "text": "And then we look for the most\nlikely value of theta.",
    "start": "100180",
    "end": "105729"
  },
  {
    "text": "We look at this distribution\nand try to find its peak.",
    "start": "105729",
    "end": "109049"
  },
  {
    "text": "So we want to maximize this\nquantity over theta.",
    "start": "109050",
    "end": "113210"
  },
  {
    "text": "The denominator does not\ninvolve any thetas.",
    "start": "113210",
    "end": "115870"
  },
  {
    "text": "So we ignore it.",
    "start": "115870",
    "end": "117320"
  },
  {
    "text": "And suppose now that\nwe use a prior for",
    "start": "117320",
    "end": "122000"
  },
  {
    "text": "theta, which is flat.",
    "start": "122000",
    "end": "124760"
  },
  {
    "text": "Suppose that this prior is\nconstant over the range of",
    "start": "124760",
    "end": "129389"
  },
  {
    "text": "possible values of theta.",
    "start": "129389",
    "end": "131630"
  },
  {
    "text": "In that case, what we need to\ndo is to just take this",
    "start": "131630",
    "end": "135520"
  },
  {
    "text": "expression and to maximize\nit over all thetas.",
    "start": "135520",
    "end": "139750"
  },
  {
    "text": "And this looks very similar to\nwhat is happening here, where",
    "start": "139750",
    "end": "142960"
  },
  {
    "text": "we take this expression and\nmaximize it over all thetas.",
    "start": "142960",
    "end": "147400"
  },
  {
    "text": "So operationally, maximum\nlikelihood estimation is the",
    "start": "147400",
    "end": "151579"
  },
  {
    "text": "same as Bayesian estimation, in\nwhich we find the peak of",
    "start": "151579",
    "end": "156790"
  },
  {
    "text": "the posterior for the special\ncase where we're using",
    "start": "156790",
    "end": "161159"
  },
  {
    "text": "constant or a flat prior.",
    "start": "161160",
    "end": "163910"
  },
  {
    "text": "But despite this similarity,\nthe two methods are",
    "start": "163910",
    "end": "167030"
  },
  {
    "text": "philosophically very\ndifferent.",
    "start": "167030",
    "end": "169505"
  },
  {
    "text": "In the Bayesian setting, you're\nasking the question,",
    "start": "169505",
    "end": "173010"
  },
  {
    "text": "what is the most likely\nvalue of theta?",
    "start": "173010",
    "end": "177090"
  },
  {
    "text": "Whereas in the maximum\nlikelihood setting, you're",
    "start": "177090",
    "end": "180500"
  },
  {
    "text": "asking, what is the value\nof theta that makes",
    "start": "180500",
    "end": "184750"
  },
  {
    "text": "my data most likely?",
    "start": "184750",
    "end": "188070"
  },
  {
    "text": "Or what is the value of theta\nunder which my data are the",
    "start": "188070",
    "end": "192380"
  },
  {
    "text": "least surprising?",
    "start": "192380",
    "end": "194610"
  },
  {
    "text": "So the interpretation of the\ntwo methods is quite",
    "start": "194610",
    "end": "199579"
  },
  {
    "text": "different, even though\nthe mechanics",
    "start": "199579",
    "end": "202579"
  },
  {
    "text": "can be fairly similar.",
    "start": "202579",
    "end": "204810"
  },
  {
    "text": "The maximum likelihood method\nhas some remarkable properties",
    "start": "204810",
    "end": "209349"
  },
  {
    "text": "that we would like\nnow to discuss.",
    "start": "209350",
    "end": "211430"
  },
  {
    "text": "But first, one comment--",
    "start": "211430",
    "end": "213560"
  },
  {
    "text": "we need to take the probability\nof the observed",
    "start": "213560",
    "end": "218230"
  },
  {
    "text": "data given theta.",
    "start": "218230",
    "end": "219579"
  },
  {
    "text": "This is a function of theta,\nand maximize it over theta.",
    "start": "219579",
    "end": "223299"
  },
  {
    "text": "In some problems, we can find\nclosed form solutions for the",
    "start": "223300",
    "end": "227190"
  },
  {
    "text": "optimal value of theta, which\nis going to be our estimate",
    "start": "227190",
    "end": "230400"
  },
  {
    "text": "but more often, and especially\nfor large problems, one has to",
    "start": "230400",
    "end": "234189"
  },
  {
    "text": "do this maximization\nin a numerical way.",
    "start": "234190",
    "end": "237960"
  },
  {
    "text": "This is possible these days,\nand routinely, people solve",
    "start": "237960",
    "end": "241440"
  },
  {
    "text": "very high dimensional problems\nwith lots of data and lots of",
    "start": "241440",
    "end": "244700"
  },
  {
    "text": "parameters using the maximum\nlikelihood methodology.",
    "start": "244700",
    "end": "248530"
  },
  {
    "text": "The maximum likelihood\nmethodology is very popular",
    "start": "248530",
    "end": "251480"
  },
  {
    "text": "because it has a very sound\ntheoretical basis.",
    "start": "251480",
    "end": "256398"
  },
  {
    "text": "I will list a few facts, which\nwe will not attempt to prove",
    "start": "256399",
    "end": "259989"
  },
  {
    "text": "or even justify.",
    "start": "259990",
    "end": "261828"
  },
  {
    "text": "But they're useful to know\nas general background.",
    "start": "261829",
    "end": "265760"
  },
  {
    "text": "Suppose that we have n pieces of\ndata that are drawn from a",
    "start": "265760",
    "end": "269770"
  },
  {
    "text": "model from a certain\nstructure.",
    "start": "269770",
    "end": "272449"
  },
  {
    "text": "Then under mild assumptions,\nthe maximum likelihood",
    "start": "272450",
    "end": "277050"
  },
  {
    "text": "estimator has the property\nthat it is consistent.",
    "start": "277050",
    "end": "280190"
  },
  {
    "text": "That is, as we draw more and\nmore data, our estimate is",
    "start": "280190",
    "end": "283720"
  },
  {
    "text": "going to converge to the true\nvalue of the parameter.",
    "start": "283720",
    "end": "287640"
  },
  {
    "text": "In addition, we know\nquite a bit more.",
    "start": "287640",
    "end": "290070"
  },
  {
    "text": "Asymptotically, the maximum\nlikelihood estimator behaves",
    "start": "290070",
    "end": "293870"
  },
  {
    "text": "like a normal random variable.",
    "start": "293870",
    "end": "295930"
  },
  {
    "text": "That is, after we normalize,\nsubtract the target and divide",
    "start": "295930",
    "end": "300330"
  },
  {
    "text": "by its standard deviation, it\napproaches a standard normal",
    "start": "300330",
    "end": "304479"
  },
  {
    "text": "distribution.",
    "start": "304480",
    "end": "305440"
  },
  {
    "text": "So in this sense, it behaves the\nsame way that the sample",
    "start": "305440",
    "end": "310360"
  },
  {
    "text": "mean behaves.",
    "start": "310360",
    "end": "312370"
  },
  {
    "text": "Notice that this expression\nhere involves the standard",
    "start": "312370",
    "end": "315940"
  },
  {
    "text": "error of the maximum likelihood\nestimator.",
    "start": "315940",
    "end": "318840"
  },
  {
    "text": "This is an important quantity.",
    "start": "318840",
    "end": "320710"
  },
  {
    "text": "And for this reason, people\nhave developed either",
    "start": "320710",
    "end": "323960"
  },
  {
    "text": "analytical or simulation methods\nfor calculating or",
    "start": "323960",
    "end": "327319"
  },
  {
    "text": "approximating this\nstandard error.",
    "start": "327320",
    "end": "330160"
  },
  {
    "text": "Once you have an estimate or\nan approximation of the",
    "start": "330160",
    "end": "333530"
  },
  {
    "text": "standard error in your hands,\nyou can further use it to",
    "start": "333530",
    "end": "337400"
  },
  {
    "text": "construct confidence\nintervals.",
    "start": "337400",
    "end": "340139"
  },
  {
    "text": "Using the asymptotic normality,\nthen we can",
    "start": "340140",
    "end": "343980"
  },
  {
    "text": "construct a confidence interval\nin exactly the same",
    "start": "343980",
    "end": "346710"
  },
  {
    "text": "way as we did for the case of\nthe sample mean estimator.",
    "start": "346710",
    "end": "350690"
  },
  {
    "text": "And this, for example, would be\na 95% confidence interval.",
    "start": "350690",
    "end": "356010"
  },
  {
    "text": "Finally, one last important\nproperty is that the maximum",
    "start": "356010",
    "end": "359650"
  },
  {
    "text": "likelihood estimator is what\nis called an asymptotically",
    "start": "359650",
    "end": "365669"
  },
  {
    "text": "efficient estimator.",
    "start": "365670",
    "end": "367700"
  },
  {
    "text": "That is, it is the best possible\nestimator in the",
    "start": "367700",
    "end": "371720"
  },
  {
    "text": "sense that it achieves the\nsmallest possible variance.",
    "start": "371720",
    "end": "376070"
  },
  {
    "text": "So all of these are very\nstrong properties.",
    "start": "376070",
    "end": "378710"
  },
  {
    "text": "And this is the reason why\nmaximum likelihood estimation",
    "start": "378710",
    "end": "382789"
  },
  {
    "text": "is the most common approach for\nproblems that do not have",
    "start": "382790",
    "end": "386780"
  },
  {
    "text": "any particular special\nstructure that",
    "start": "386780",
    "end": "389520"
  },
  {
    "text": "you can exploit otherwise.",
    "start": "389520",
    "end": "390770"
  },
  {
    "start": "390770",
    "end": "391930"
  }
]
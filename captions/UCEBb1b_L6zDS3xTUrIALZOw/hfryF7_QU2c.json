[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5580",
    "end": "12270"
  },
  {
    "text": "To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12270",
    "end": "18830"
  },
  {
    "text": "at ocw.mit.edu. JOSH TENENBAUM: We're going to-- I'm just going to give a\nbunch of examples of things",
    "start": "18830",
    "end": "25189"
  },
  {
    "start": "22000",
    "end": "56000"
  },
  {
    "text": "that we in our field have done. Most of them are things that\nI've played some role in. Maybe it was a thesis\nproject of a student.",
    "start": "25189",
    "end": "31074"
  },
  {
    "text": "But they're meant to be\nrepresentative of a broader set of things that many\npeople have been working on developing this toolkit.",
    "start": "31075",
    "end": "37349"
  },
  {
    "text": "And we're going to start from\nthe beginning in a sense-- just some very simple\nthings that we did to try to look at ways in\nwhich probabilistic, generative",
    "start": "37349",
    "end": "44719"
  },
  {
    "text": "models can inform people's\nbasic cognitive processes. And then build up to\nmore interestingly kinds",
    "start": "44720",
    "end": "50360"
  },
  {
    "text": "of symbolically structured\nmodels, hierarchical models, and ultimately to these\nprobabilistic programs",
    "start": "50360",
    "end": "55670"
  },
  {
    "text": "for common sense. So when I say a lot of\npeople have been doing this, I mean here's just a small\nnumber of these people.",
    "start": "55670",
    "end": "62073"
  },
  {
    "text": "Every year or two, I try\nto update this slide. But it's very much\nhistorically dated with people",
    "start": "62073",
    "end": "67321"
  },
  {
    "text": "that I knew when I was\nin grad school basically. There's a lot of\nreally great work by younger people who\nmaybe their names haven't",
    "start": "67321",
    "end": "74542"
  },
  {
    "text": "appeared on this slide. So those dot dot dots\nare extremely serious. And a lot of the best stuff\nis not included on here.",
    "start": "74542",
    "end": "79720"
  },
  {
    "text": "But in the last\ncouple of decades, across basically all\nthe different areas of cognitive science\nthat cover basically",
    "start": "79720",
    "end": "86180"
  },
  {
    "text": "all the different things\nthat cognition does, there's been great progress\nbuilding serious mathematical--",
    "start": "86180",
    "end": "91847"
  },
  {
    "text": "and what we could call reverse\nengineering models in the sense that they are quantitative\nmodels of human cognition,",
    "start": "91847",
    "end": "98130"
  },
  {
    "text": "but they are phrased in\nthe terms of engineering, the same things you would\nuse to build a robot to do these things,\nat least in principle.",
    "start": "98130",
    "end": "104900"
  },
  {
    "text": "And it's been\ndeveloping this toolkit of probabalistic\ngenerative models.",
    "start": "104900",
    "end": "110390"
  },
  {
    "start": "110000",
    "end": "232000"
  },
  {
    "text": "I want to start\noff by telling you a little bit about some\nwork that I did together with Tom Griffiths.",
    "start": "110390",
    "end": "116180"
  },
  {
    "text": "So Tom is now a senior\nfaculty member at Berkeley, one of the leaders\nin this field--",
    "start": "116180",
    "end": "121714"
  },
  {
    "text": "as well as a leading person\nin machine learning, actually. One of the great\nthings that he's done is to take inspiration\nfrom human learning",
    "start": "121714",
    "end": "128119"
  },
  {
    "text": "and develop fundamentally new\nkinds of probabilistic models, in non-parametric\nBayes in particular,",
    "start": "128120",
    "end": "133130"
  },
  {
    "text": "inspired by human learning. But when Tom was a grad\nstudent, we worked together.",
    "start": "133130",
    "end": "139230"
  },
  {
    "text": "He was my first student. We're almost the same age. So at this point, we're\nmore like senior colleagues than student advisor.",
    "start": "139230",
    "end": "144685"
  },
  {
    "text": "But I'll tell you\nabout some work we did back when\nhe was a student, and I was just starting off. And we were both together\ntrying to tackle this problem",
    "start": "144685",
    "end": "151159"
  },
  {
    "text": "and trying to see, OK, what are\nthe prospects for understanding",
    "start": "151160",
    "end": "156440"
  },
  {
    "text": "even very basic cognitive\nintuitions, like senses of similarity or the most\nbasic kinds of causal discovery",
    "start": "156440",
    "end": "161840"
  },
  {
    "text": "intuitions like we were\ntalking about before, using some kind of idea\nof probabilistic inference in a generative model?",
    "start": "161840",
    "end": "168280"
  },
  {
    "text": "And at the time-- remember\nin the introduction I was talking about how\nthere's been this back and forth discourse over the\ndecades of people saying, yeah,",
    "start": "168280",
    "end": "176780"
  },
  {
    "text": "rah rah, statistics,\nand, statistics, those are trivial\nand uninteresting? And at the time we started\nto do this, at least",
    "start": "176780",
    "end": "183058"
  },
  {
    "text": "in cognitive\npsychology, the idea that cognition could\nbe seen as some kind of sophisticated\nstatistical inference",
    "start": "183058",
    "end": "189140"
  },
  {
    "text": "was very much not\na popular idea. But we thought that it\nwas fundamentally right in some ways.",
    "start": "189140",
    "end": "194990"
  },
  {
    "text": "And it was at the time-- again, this was work we were\ndoing in the early 2000s when it was very clear in\nmachine learning and AI",
    "start": "194990",
    "end": "201830"
  },
  {
    "text": "already how transformative\nthese ideas were in building intelligent\nmachines or starting to build intelligent machines.",
    "start": "201830",
    "end": "207470"
  },
  {
    "text": "So it seemed clear to\nus that at least it was a good hypothesis worth\nexploring and taking much more seriously than psychologists\nhad much before that.",
    "start": "207470",
    "end": "214790"
  },
  {
    "text": "That this also could\ndescribe basic aspects of human thinking. So I'll give you a couple\nexamples of what we did here.",
    "start": "214790",
    "end": "221930"
  },
  {
    "text": "Here's a simple kind of causal\ninference from coincidences, much like what you saw\ngoing on in the video game.",
    "start": "221930",
    "end": "229720"
  },
  {
    "text": "There's no time in this. It's really mostly just space,\nor maybe a little bit of time. The motivation was not a\nvideo game, but imagine--",
    "start": "229720",
    "end": "237090"
  },
  {
    "start": "232000",
    "end": "328000"
  },
  {
    "text": "to put a real world\ncontext on it-- what's sometimes called cancer\nclusters or rare disease",
    "start": "237090",
    "end": "242510"
  },
  {
    "text": "clusters. You can read about these\noften in the newspaper, where somebody has seen some evidence\nsuggestive of some maybe",
    "start": "242510",
    "end": "249140"
  },
  {
    "text": "hidden environmental cause-- maybe it's a toxic chemical\nleak or something--",
    "start": "249140",
    "end": "254810"
  },
  {
    "text": "that seems to be responsible\nfor-- or maybe they don't have a cause. They just see a\nsuspicious coincidence of some very rare disease, a\nfew cases that seem surprisingly",
    "start": "254810",
    "end": "263750"
  },
  {
    "text": "clustered in space and time. So for example, let's say this\nis one square mile of a city.",
    "start": "263750",
    "end": "269330"
  },
  {
    "text": "And each dot represents one case\nof some very rare disease that occurred in the span of a year.",
    "start": "269330",
    "end": "276106"
  },
  {
    "text": "And you look at this. And you might think\nthat, well, it doesn't look like those dots are\ncompletely, uniformly, randomly",
    "start": "276106",
    "end": "281990"
  },
  {
    "text": "distributed over there. Maybe there's some\nweird thing going on in the upper left or\nnorthwest corner--",
    "start": "281990",
    "end": "287855"
  },
  {
    "text": "some who knows what-- making people sick. So let me just ask you. On a scale of 0 to 10,\nwhere 10 means you're sure",
    "start": "287855",
    "end": "296300"
  },
  {
    "text": "there's some kind\nof thing going on and some special cause\nin some part of this map.",
    "start": "296300",
    "end": "302121"
  },
  {
    "text": "And 0 means no, you're quite\nsure there's nothing going on. It's just random. What do you say?",
    "start": "302122",
    "end": "308870"
  },
  {
    "text": "To what extent does this give\nevidence for some hidden cause? So give me a number\nbetween 0 and 10. AUDIENCE: 5.",
    "start": "308870",
    "end": "315167"
  },
  {
    "text": "JOSH TENENBAUM: OK, great. 5, 2, 7. I heard a few examples\nof each of those. Perfect. That's exactly what people do.",
    "start": "315167",
    "end": "320442"
  },
  {
    "text": "You could do the same\nthing on Mechanical Turk, and get 10 times as much\ndata, and pay a lot more.",
    "start": "320442",
    "end": "326060"
  },
  {
    "text": "It would be the same. I'll show you the\ndata in a second. But here's the\nmodel that we built. So again, this model\nis a very simple kind",
    "start": "326060",
    "end": "333620"
  },
  {
    "start": "328000",
    "end": "484000"
  },
  {
    "text": "of generative model\nof a hidden cause that various people\nin statistics have worked with for a while.",
    "start": "333620",
    "end": "340130"
  },
  {
    "text": "We're basically modeling a\nhidden cause as a mixture.",
    "start": "340130",
    "end": "345490"
  },
  {
    "text": "Or I mean it's a\ngenerative model, so we have to model\nthe whole data. When we say there's\na hidden cause,",
    "start": "345490",
    "end": "350741"
  },
  {
    "text": "we don't necessarily mean that\neverything is caused by this. It's just that the data\nwe see in this picture",
    "start": "350741",
    "end": "356569"
  },
  {
    "text": "is a mixture of whatever the\nnormal random thing going on is plus possibly some spatially\nlocalized cause that",
    "start": "356570",
    "end": "365420"
  },
  {
    "text": "has some unknown\nposition, unknown extent. Maybe it's a very big region. And some unknown\nintensity-- maybe",
    "start": "365420",
    "end": "371720"
  },
  {
    "text": "it's causing a lot of\ncases or not that many. The hypothesis space maybe\nis best visualized like this. Each of these squares is\na different hypothesis",
    "start": "371720",
    "end": "379790"
  },
  {
    "text": "of a mixture density\nor a mixture model-- which is a mixture of just\nwhatever the normal uniform process is that causes a disease\nunrelated to space and then",
    "start": "379790",
    "end": "388490"
  },
  {
    "text": "some kind of just Gaussian bump,\nwhich can vary in location, size, and intensity, that\nis the possible hidden cause",
    "start": "388490",
    "end": "396110"
  },
  {
    "text": "of some of these cases. And what the model\nthat we propose says is that your sense of\nthis spatial coincidence--",
    "start": "396110",
    "end": "401932"
  },
  {
    "text": "like when you look at a pattern\nof dots really and you see, oh, that looks like there's a\nhidden cluster there somewhere. It's basically you're trying to\nsee whether something like one",
    "start": "401932",
    "end": "410466"
  },
  {
    "text": "of those things on the right is\ngoing on as opposed to the null hypothesis of just\npure randomness. So we take this log\nlikelihood ratio,",
    "start": "410466",
    "end": "419150"
  },
  {
    "text": "or log probability,\nwhere we're comparing the probability of the\ndata under the hypothesis",
    "start": "419150",
    "end": "425120"
  },
  {
    "text": "that there's some\ninteresting hidden cause, one of the things on the right,\nversus the alternative",
    "start": "425120",
    "end": "431300"
  },
  {
    "text": "hypothesis that\nit's just random, which is just the simple,\ncompletely uniform density. And what makes this a little\nbit interesting computationally",
    "start": "431300",
    "end": "438139"
  },
  {
    "text": "is that there's an infinite\nnumber of these possibilities on the right. There's an infinite number\nof different locations",
    "start": "438140",
    "end": "446000"
  },
  {
    "text": "and sizes and intensities\nof the Gaussian. And you have to integrate\nover all of them. So again, there's not\ngoing to be a whole lot",
    "start": "446000",
    "end": "451483"
  },
  {
    "text": "of mathematical details here. But you can read\nabout this stuff if you want to read these\npapers that we had here.",
    "start": "451484",
    "end": "459410"
  },
  {
    "text": "But for those of you who\nare familiar with this, with working with\nlatent variable models,",
    "start": "459410",
    "end": "464870"
  },
  {
    "text": "effectively what\nyou're doing is just",
    "start": "464870",
    "end": "470240"
  },
  {
    "text": "integrating either analytically\nor in a simulation over all the possible models\nand sort of trying",
    "start": "470240",
    "end": "476570"
  },
  {
    "text": "to compute on average how\nmuch does the evidence support something like what you see on\nthe right, one of those cluster",
    "start": "476570",
    "end": "481670"
  },
  {
    "text": "possibilities, versus\njust uniform density. And now what I'm showing\nyou is that model",
    "start": "481670",
    "end": "486920"
  },
  {
    "text": "compared to people's\njudgments on an experiment. So in this experiment,\nwe showed people patterns",
    "start": "486920",
    "end": "492590"
  },
  {
    "text": "like the one you just saw. The one you saw\nis this one here.",
    "start": "492590",
    "end": "497780"
  },
  {
    "text": "But in the different\nstimuli, we varied parameters that we thought\nwould be relevant. So we varied how many\npoints were there total,",
    "start": "497780",
    "end": "506300"
  },
  {
    "text": "how strong the cluster was in\nvarious ways, whether it was very tightly\nclustered or very big,",
    "start": "506300",
    "end": "511640"
  },
  {
    "text": "the relative number of points\nin the cluster versus not. So what you can see\nhere, for example,",
    "start": "511640",
    "end": "517039"
  },
  {
    "text": "is it's a very similar\nkind of geometry, except here this is a\nsort of biggish cluster.",
    "start": "517039",
    "end": "523178"
  },
  {
    "text": "And then we're making basically\nthere's four points that look clustered and two that aren't. And in these cases, we\njust make the four points",
    "start": "523179",
    "end": "530000"
  },
  {
    "text": "more tightly clustered. Here, what we're\ndoing is we're going from having no points that look\nclustered to having almost all",
    "start": "530000",
    "end": "537961"
  },
  {
    "text": "of the points looking\nclustered and just varying the ratio of clustered points\nto non-clustered points.",
    "start": "537961",
    "end": "543200"
  },
  {
    "text": "Here, we're just changing\nthe overall number. So notice that this one is\nbasically the same as this one. ",
    "start": "543200",
    "end": "551036"
  },
  {
    "text": "So again, at both\nof these, we've got four clustered points and\ntwo seemingly non-clustered ones.",
    "start": "551036",
    "end": "556100"
  },
  {
    "text": "And here we just scale\nup in set-- or scale up from four to two,\nto eight and four. And here we scale it\ndown to two and one,",
    "start": "556100",
    "end": "563107"
  },
  {
    "text": "and various other manipulations. And what you can\nsee is that they have various systematic\neffects on people's judgments.",
    "start": "563107",
    "end": "568603"
  },
  {
    "text": "So what I'm calling\nthe data there is the average of\nabout 150 people who did the same\njudgment you did--",
    "start": "568604",
    "end": "573750"
  },
  {
    "text": "0 to 10. What you can see is the one\nI gave you was this one here.",
    "start": "573750",
    "end": "578810"
  },
  {
    "text": "And the average judgment\nwas almost exactly five. And if you look at\nthe variance, it looks just like\nwhat you saw here.",
    "start": "578810",
    "end": "584040"
  },
  {
    "text": "Some people say two or three. Some people say seven. I chose one that was\nright in the middle.",
    "start": "584040",
    "end": "589374"
  },
  {
    "text": "The interesting thing\nis that, while you maybe felt like you were\nguessing-- and if you just listened to what\neveryone else was saying, maybe it sounds like we're just\nshouting out random numbers--",
    "start": "589374",
    "end": "596561"
  },
  {
    "text": "that's not what you're doing. On that one, it looks\nlike it, because it's right on the threshold. But if you look over all\nthese different patterns, what",
    "start": "596561",
    "end": "603130"
  },
  {
    "text": "you see is that sometimes\npeople give much higher numbers than others. Sometimes people give much\nlower number than others. And the details,\nthat variation, both",
    "start": "603130",
    "end": "610579"
  },
  {
    "text": "within these different\nmanipulations we did and across them,\nare almost perfectly captured by this very simple\nprobabilistic generative",
    "start": "610579",
    "end": "617560"
  },
  {
    "text": "model for a latent cause. So the model here is-- this is\nthe predictions that model I showed you is\nmaking, where again,",
    "start": "617560",
    "end": "623500"
  },
  {
    "text": "basically, a high\nbar means there's strong evidence in favor of the\nhidden latent cause hypothesis.",
    "start": "623500",
    "end": "630700"
  },
  {
    "text": "Some, one, or more-- some cluster-- that low\nbar means strong evidence",
    "start": "630700",
    "end": "636400"
  },
  {
    "text": "for the alternative hypothesis. The scale is a bit arbitrary. And it's a log\nprobability ratio scale.",
    "start": "636400",
    "end": "643302"
  },
  {
    "text": "So I'm not going to\ncomment on the scale. But importantly, it's the same\nscale across all of these. So a big difference is,\nit's the same big difference",
    "start": "643302",
    "end": "649810"
  },
  {
    "text": "in both cases. And I don't think this\nis fairly good evidence that this model is\ncapturing your sense of spatial coincidence\nand showing that it's not",
    "start": "649810",
    "end": "657130"
  },
  {
    "text": "just random or arbitrary,\nbut it's actually a very rational measure of\nhow much evidence there is in the data for a hidden cause.",
    "start": "657130",
    "end": "663850"
  },
  {
    "text": "Here's the same\nmodel now applied to a different data\nset that we actually collected a few\nyears before, which",
    "start": "663850",
    "end": "669102"
  },
  {
    "text": "just varies the same\nkinds of parameters, but has a lot more points. And the same model works\nin those cases, too.",
    "start": "669102",
    "end": "675534"
  },
  {
    "text": "The differences are\na little more subtle with these more points. So I'll give you one other\nexample of this sort of thing.",
    "start": "675534",
    "end": "684790"
  },
  {
    "text": "Like the one I just\nshowed you, we're taking a fairly simple\nstatistical model. This one, as you'll see,\nisn't even really causal.",
    "start": "684790",
    "end": "691400"
  },
  {
    "text": "This one at least, that\nI showed you, is causal. The advantage of\nthis other one is that it's both a kind of\ntextbook statistics example,",
    "start": "691400",
    "end": "698175"
  },
  {
    "text": "it's one where people do\nsomething more interesting than what's in the textbook. Although you can extend the\ntextbook analysis to make",
    "start": "698175",
    "end": "703588"
  },
  {
    "text": "it look like what people do. And unlike in this\ncase here, you can actually measure\nthe empirical statistic.",
    "start": "703588",
    "end": "709210"
  },
  {
    "text": "You can go out, and instead\nof just like positing, here's a simple model of what\na latent environmental cause",
    "start": "709210",
    "end": "714944"
  },
  {
    "text": "would be like, you can\nactually go and measure all the relevant\nprobability distributions and compare people not\njust with a notional model,",
    "start": "714944",
    "end": "721529"
  },
  {
    "text": "but with what, in\nsome stronger sense, is the rational\nthing to do, if you were doing some kind of\nintuitive Bayesian inference.",
    "start": "721530",
    "end": "729140"
  },
  {
    "text": "So these are, again\nstuff that Tom Griffiths did with me, in an in and\nthen after grad school.",
    "start": "729140",
    "end": "735540"
  },
  {
    "text": "We asked people to\nmake the following kind of everyday prediction. So we said, suppose you\nread about a movie that's",
    "start": "735540",
    "end": "741520"
  },
  {
    "text": "made $60 million to date. How much money will\nit make in total? Or you see that\nsomething's been baking",
    "start": "741520",
    "end": "747130"
  },
  {
    "text": "in the oven for 34 minutes. How long until it's ready? You meet someone\nwho's 78 years old. How long will they live?",
    "start": "747130",
    "end": "753570"
  },
  {
    "text": "Your friend quotes to you from\nline 17 of his favorite poem. How long is the poem? Or you meet a US congressman\nwho has served for 11 years.",
    "start": "753570",
    "end": "760000"
  },
  {
    "text": "How long will he serve in total? So in each of\nthese cases, you're encountering some\nphenomenon or event",
    "start": "760000",
    "end": "766990"
  },
  {
    "text": "in the world with some\nunknown total duration. We'll call that t, total. And all we know is that\nt, total, is somewhere",
    "start": "766990",
    "end": "773769"
  },
  {
    "text": "between zero and infinity. We might have a prior on it,\nas you'll see in a second. But we don't know very much\nabout this particular t,",
    "start": "773770",
    "end": "780977"
  },
  {
    "text": "total except you get one\nexample, one piece of data, some t, which we'll just\nassume is just randomly sampled",
    "start": "780977",
    "end": "788227"
  },
  {
    "text": "between zero and t, total. So all we know is that\nwhatever these things are, it's something randomly chosen,\nless than the total extent",
    "start": "788227",
    "end": "794830"
  },
  {
    "text": "or duration of these events. And now we can ask,\nwhat can you guess about the total extent\nor duration from that one",
    "start": "794830",
    "end": "801850"
  },
  {
    "text": "observation? Or in mathematical terms,\nthere is some unknown interval from zero up to\nsome maximal value.",
    "start": "801850",
    "end": "807880"
  },
  {
    "text": "You can put a prior on\nwhat that interval is. And you have to guess the\ninterval from one sampled point",
    "start": "807880",
    "end": "813100"
  },
  {
    "text": "sampled randomly within it. It's also very similar--\nand another reason we studied this-- to\nthe problem of learning a concept from one example.",
    "start": "813100",
    "end": "819620"
  },
  {
    "text": "When you're learning what\nhorses are from one example, or when you're learning what\nthat piece of rock climbing question is-- what's a cam--",
    "start": "819620",
    "end": "824740"
  },
  {
    "text": "from one example, or what's\na tufa from one example. You can think,\nthere's some region in the space of all possible\nobjects or something,",
    "start": "824740",
    "end": "831700"
  },
  {
    "text": "or some set out there. And you get one or\na few sample points, and you have to figure out\nthe extent of the region.",
    "start": "831700",
    "end": "837000"
  },
  {
    "text": "It's basically the same kind\nof problem, mathematically. But what's cool\nabout this is we can measure the priors for these\ndifferent classes of events",
    "start": "837000",
    "end": "844000"
  },
  {
    "text": "and compare people with an\noptimal Bayesian inference. And you see something\nkind of striking.",
    "start": "844000",
    "end": "849550"
  },
  {
    "text": "So here's, on the top-- I'm showing two different\nkinds of data here. On the top are just empirical\nstatistics of events",
    "start": "849550",
    "end": "856779"
  },
  {
    "text": "you can measure in the world;\nnothing behavioral, nothing about cognition. On the bottom, I'm showing\nsome behavioral data",
    "start": "856780",
    "end": "863649"
  },
  {
    "text": "and comparing it with\nmodel predictions that are based on the statistics\nthat are measured on top. So what we have\nin each column is",
    "start": "863650",
    "end": "869920"
  },
  {
    "text": "one of these classes of events,\nlike movie grosses in dollars. You can get this data from iMDB,\nthe Internet Movie Database.",
    "start": "869920",
    "end": "877090"
  },
  {
    "text": "You can see that most movies\nmake $100 million or less. There's sort of a power law.",
    "start": "877090",
    "end": "882730"
  },
  {
    "text": "But a few movies make hundreds,\nor even many hundreds, maybe a billion dollars\neven, these days.",
    "start": "882730",
    "end": "888647"
  },
  {
    "text": "Similarly with poems, they\nhave a power law distribution of length. So most poems are pretty short. They fit on a page or less.",
    "start": "888647",
    "end": "894250"
  },
  {
    "text": "But there are some\nepic poems, or some multi-page-- many,\nmany hundreds of lines. And they fall off\nwith a long tail.",
    "start": "894250",
    "end": "901290"
  },
  {
    "text": "Lifespans, movie runtimes\nare kind of unimodal, almost Gaussian-- not exactly. Those red curves,\nhistograms' bars,",
    "start": "901290",
    "end": "909420"
  },
  {
    "text": "show the empirical\nstatistics that we measured from public data. And the red curves\nshow just the best fit",
    "start": "909420",
    "end": "915170"
  },
  {
    "text": "of a simple parametric model,\nlike a Gaussian or a power law distribution that\nI'm mentioning. House of representatives-- how\nlong people serve in the House",
    "start": "915171",
    "end": "922740"
  },
  {
    "text": "has this kind of gamma,\nor particular gamma called an Erlang shape\nwith a little bit",
    "start": "922740",
    "end": "928020"
  },
  {
    "text": "of an incumbent effect. Cake baking times-- so\nremember we asked how long is this cake going to bake for.",
    "start": "928020",
    "end": "934506"
  },
  {
    "text": "They don't have any simple\nparametric form when you go in and look at cookbooks. But you see, there's\nsomething systematic there.",
    "start": "934506",
    "end": "941132"
  },
  {
    "text": "There's a lot of things\nthat are supposed to bake for exactly an hour. There are some which have\na smaller, or a shorter,",
    "start": "941132",
    "end": "948360"
  },
  {
    "text": "but broad mode. And then there's a few epic\n90-minute cakes out there. So that's all the\nempirical statistics.",
    "start": "948360",
    "end": "954900"
  },
  {
    "text": "Now what you're seeing on\nthe bottom is people's-- well, on the y-axis,\nthe vertical axis,",
    "start": "954900",
    "end": "961990"
  },
  {
    "text": "you have the average--\nit's a median-- of a bunch of human predictions\nfor the total extent of any one of these\nthings, like your guess",
    "start": "961990",
    "end": "969990"
  },
  {
    "text": "of the total length\nof a poem given that, basically, there\nis a line 17 in it. And on the x-axis, what you're\nseeing is that one data point,",
    "start": "969990",
    "end": "976880"
  },
  {
    "text": "the one value of t,\nwhich is, all you know is that it's somewhere\nbetween zero and t, total. ",
    "start": "976880",
    "end": "983160"
  },
  {
    "text": "So different groups\nof subjects were given five different values. So you see five black dots,\nwhich correspond to what",
    "start": "983160",
    "end": "989340"
  },
  {
    "text": "five different\nsubgroups of subjects said for each of these\npossible t values.",
    "start": "989340",
    "end": "995106"
  },
  {
    "text": "And then the black\nand red curves are the model fit,\nwhich comes from taking a certain kind of Bayesian\noptimal prediction, where",
    "start": "995106",
    "end": "1002000"
  },
  {
    "text": "the prior is what's\nspecified on the top-- that's the prior on t, total. The likelihood is a sort\nof uniform random density.",
    "start": "1002000",
    "end": "1010920"
  },
  {
    "text": "So it's just saying t is just a\nuniform random sample from zero up to t, total. You put those together\nto compute a posterior.",
    "start": "1010920",
    "end": "1017870"
  },
  {
    "text": "And then you-- the particular\nestimator we're using is what's called the\nposterior median. So we're looking at the\nmedian of the exterior",
    "start": "1017870",
    "end": "1023976"
  },
  {
    "text": "and comparing that with a\nmedian of human subjects. And what you can see is that\nit's almost a perfect fit.",
    "start": "1023976",
    "end": "1031354"
  },
  {
    "text": "And it doesn't really\nmatter whether you take the red curve, which is\nwhat comes from approximating the prior with one of these\nsimple parametric models,",
    "start": "1031354",
    "end": "1038954"
  },
  {
    "text": "or the black one,\nwhich comes from just taking the empirical histogram. Although, for the\ncake baking times,",
    "start": "1038954",
    "end": "1044059"
  },
  {
    "text": "you really can only go\nfor the empirical one. Because there is no\nsimple parametric one. That's why you just see a\njagged black line there.",
    "start": "1044060",
    "end": "1050930"
  },
  {
    "text": "But it's interesting that\nit's almost a perfect fit. There are a couple--",
    "start": "1050930",
    "end": "1056090"
  },
  {
    "text": "just like somebody\nasked in Demis's talk-- there's one or two cases we\nfound where this model doesn't",
    "start": "1056090",
    "end": "1062360"
  },
  {
    "text": "work, sometimes dramatically,\nand sometimes a little bit. And they're all interesting. But I have time\nto talk about it.",
    "start": "1062360",
    "end": "1067650"
  },
  {
    "text": "That's one of the things\nI decided to skip. If you'd like to talk about\nit, I'm happy to do that. But most of the time, in most\nof the cases we've studied,",
    "start": "1067650",
    "end": "1072935"
  },
  {
    "text": "these are representative. And I think, again, all\nof the failure cases are quite interesting ones. That point to, this is\none of the many things",
    "start": "1072935",
    "end": "1078844"
  },
  {
    "text": "we need to go beyond. But the interesting\nthing isn't just that the curves fit\nthe data, but the fact",
    "start": "1078844",
    "end": "1085220"
  },
  {
    "text": "that the actual shape is\ndifferent in each case. Depending on the prior of this\ndifferent classes of events,",
    "start": "1085220",
    "end": "1090866"
  },
  {
    "text": "you get a fundamentally\ndifferent, or qualitatively different, prediction function. Sometimes it's linear. Sometimes it's non-linear.",
    "start": "1090866",
    "end": "1096893"
  },
  {
    "text": "Sometimes it has\nsome weird shape. And really, quite\nsurprisingly to us,",
    "start": "1096893",
    "end": "1103910"
  },
  {
    "text": "people seem to be\nsensitive to that. So they seem to predict in ways\nthat are reflective of not only",
    "start": "1103910",
    "end": "1109640"
  },
  {
    "text": "the optimal Bayesian\nthing to do, but the optimal Bayesian thing\nto do from the optimal prior, from the correct prior.",
    "start": "1109640",
    "end": "1116420"
  },
  {
    "text": "And I certainly don't want\nto suggest that people always do this. But it was very\ninteresting to us that for just a bunch of\neveryday events, and really,",
    "start": "1116420",
    "end": "1124279"
  },
  {
    "text": "the places where this\nanalysis works best are ones, again, where we think\npeople actually might plausibly",
    "start": "1124280",
    "end": "1129470"
  },
  {
    "text": "have good reasons to have\nthe relevant experiences with these everyday\nevents, they seem to be sensitive to both the\nstatistics in the sense of just",
    "start": "1129470",
    "end": "1138350"
  },
  {
    "text": "what's going on in\nthe world and doing the right statistical\nprediction. So that's what we did.",
    "start": "1138350",
    "end": "1144095"
  },
  {
    "text": "10 years ago or so,\nthat was like the state of the art for us. And then we wanted\nto know, well, OK, can we take these sorts\nof ideas and scale them up",
    "start": "1144095",
    "end": "1151110"
  },
  {
    "text": "to some actually interesting\ncognitive problems, like say, for example, learning\nwords for object categories.",
    "start": "1151110",
    "end": "1157100"
  },
  {
    "text": "And we did some of that. I'll show you a\nlittle bit of that before showing you what I\nthink was missing there.",
    "start": "1157100",
    "end": "1162680"
  },
  {
    "text": "I mean, in a lot of ways,\nthis is a harder problem. I mean, it's very\nsimilar, as I said.",
    "start": "1162680",
    "end": "1168530"
  },
  {
    "text": "It's basically like, there's\njust like the problem I just showed you, where there\nwas an unknown total extent or duration, and you got\none random sample from it,",
    "start": "1168530",
    "end": "1174950"
  },
  {
    "text": "here there is some un-- imagine the space of\nall possible objects--",
    "start": "1174950",
    "end": "1180980"
  },
  {
    "text": "could be a manifold or\ndescribed by a bunch of knobs. I mean, these are all generated\nfrom some computer program.",
    "start": "1180980",
    "end": "1186500"
  },
  {
    "text": "If these were real,\nbiological things, they would be generated\nfrom DNA or whatever it is. But there's some huge, maybe\ninterestingly structured, space",
    "start": "1186500",
    "end": "1194660"
  },
  {
    "text": "of all possible objects. And within that space is some\nsubset, some region or subset,",
    "start": "1194660",
    "end": "1200610"
  },
  {
    "text": "somehow described that\nis the set of tufas. And somehow you're able to\ngrasp that subset, more or less,",
    "start": "1200610",
    "end": "1206791"
  },
  {
    "text": "if you get its boundaries,\nto be able to say yes or no as you did at the\nbeginning of the lecture from just, in this case, a\nfew points-- three points--",
    "start": "1206791",
    "end": "1213030"
  },
  {
    "text": "randomly sampled from\nsomewhere in that region. It would work just as well\nif I showed you one of them,",
    "start": "1213030",
    "end": "1218100"
  },
  {
    "text": "basically. So in some sense,\nit's the same problem. But it's much harder,\nbecause here, the space",
    "start": "1218100",
    "end": "1223320"
  },
  {
    "text": "was this one dimensional thing. It was just a number. Whereas here, we\ndon't know what's the dimensionality of\nthe space of objects.",
    "start": "1223320",
    "end": "1229770"
  },
  {
    "text": "We don't know how to\ndescribe the regions. Here we knew how to\ndescribe the regions. They were just intervals\nwith a lower bound at zero and an upper bound at\nsome unknown thing.",
    "start": "1229770",
    "end": "1235860"
  },
  {
    "text": "And the hypothesis space\nof possible regions was just all the possible upper\nbounds of this event duration.",
    "start": "1235860",
    "end": "1241484"
  },
  {
    "text": "Here we don't know how\nto describe this space. We don't know how to\ndescribe the regions that correspond to object concepts.",
    "start": "1241484",
    "end": "1247650"
  },
  {
    "text": "We don't know how to put a\nprice on those hypotheses. But in some work that\nwe did-- in particular,",
    "start": "1247650",
    "end": "1253590"
  },
  {
    "text": "some work that I did\nwith Fei Xu, who is also a professor at Berkeley. We were colleagues and\nfriends in graduate school.",
    "start": "1253590",
    "end": "1260070"
  },
  {
    "text": "We sort of did what\nwe could at the time. So we made some guesses about\nwhat that hypothesis space-- what that space might be like,\nwhat the hypothesis space might",
    "start": "1260070",
    "end": "1267633"
  },
  {
    "text": "be like, how to put some\npriors, and so, on there. Used exactly the\nsame likelihood, which was just this very simple\nidea that the observed examples",
    "start": "1267633",
    "end": "1274260"
  },
  {
    "text": "are a uniform random draw\nfrom some subset of the world. And you have to figure\nout what that subset is.",
    "start": "1274260",
    "end": "1280710"
  },
  {
    "text": "And we were able to\nmake some progress. So what we did was we said,\nwell, like in biology,",
    "start": "1280710",
    "end": "1285750"
  },
  {
    "text": "perhaps-- and if you saw-- how\nmany people saw Surya Ganguli's lecture yesterday morning?",
    "start": "1285750",
    "end": "1290970"
  },
  {
    "text": "Cool. I sort of tailored this for\nassuming that you probably had seen that.",
    "start": "1290970",
    "end": "1296370"
  },
  {
    "text": "Because there's a lot of\nsimilarities, or parallels, which is neat. And it's, again, part of\nengaging on generative models",
    "start": "1296370",
    "end": "1303659"
  },
  {
    "text": "and neural networks. As you saw him do, you'll\nget my version of this. So also, like he\nmentioned, there",
    "start": "1303660",
    "end": "1310530"
  },
  {
    "text": "are actual processes in the\nworld which generate objects-- something like this.",
    "start": "1310530",
    "end": "1316530"
  },
  {
    "text": "We know about evolution-- produces basically\ntree-structured groups, which we call species, or genus,\nor something like that, or just",
    "start": "1316530",
    "end": "1324419"
  },
  {
    "text": "taxa, or something. There's groups of\norganisms that have a common evolutionary descent. That's the way a biologist\nmight describe it.",
    "start": "1324420",
    "end": "1331000"
  },
  {
    "text": "And we know, these days,\na lot about the mechanisms that produce that. Even going back\n100 or 200 years,",
    "start": "1331000",
    "end": "1338340"
  },
  {
    "text": "say, to Darwin,\nwe knew something about the mechanisms\nthat produced it, even if we didn't know\nthe genetic details, ideas",
    "start": "1338340",
    "end": "1344100"
  },
  {
    "text": "of something like mutation,\nvariation, natural selection as a kind of\nmechanistic account, about right up there\nwith Newton and forces.",
    "start": "1344100",
    "end": "1351080"
  },
  {
    "text": "But anyway, scientists\ncan describe some process that generates trees. And maybe people\nhave some intuition,",
    "start": "1351080",
    "end": "1356160"
  },
  {
    "text": "just like people seem\nto have some intuitions about these statistics\nof everyday events, maybe they have some\nintuitions, somehow,",
    "start": "1356160",
    "end": "1361530"
  },
  {
    "text": "about the causal processes\nin the world, which give rise to groups and\ngroups and subgroups.",
    "start": "1361530",
    "end": "1367730"
  },
  {
    "text": "And they can use that to\nset up a hypothesis space. And the way we\nwent about this is, we have no idea how to describe\npeople's internal mental models",
    "start": "1367730",
    "end": "1375145"
  },
  {
    "text": "of these things, but\nyou can do some simple-- there are simple ways\nto get this picture by just basically asking\npeople to judge similarity",
    "start": "1375145",
    "end": "1382084"
  },
  {
    "text": "and doing hierarchical\nclustering. So this is a tree that we built\nup by just asking people-- getting some subjective\nsimilarity metric",
    "start": "1382084",
    "end": "1388680"
  },
  {
    "text": "and then doing hierarchical\nclustering, which we thought could roughly approximate\nmaybe the internal hierarchy",
    "start": "1388680",
    "end": "1393990"
  },
  {
    "text": "that our mental\nmodels impose on this. Were you raising your\nhand or just-- no. OK. Cool. ",
    "start": "1393990",
    "end": "1400740"
  },
  {
    "text": "We ultimately found\nthis dissatisfying, because we don't really\nknow what the features are. We don't really know if\nthis is the right tree",
    "start": "1400740",
    "end": "1405809"
  },
  {
    "text": "or how people built it up. But it actually\nworked pretty well, in the sense that we\ncould build up this tree. We could then assume that\nthe hypotheses for concepts",
    "start": "1405810",
    "end": "1413550"
  },
  {
    "text": "just corresponded to\nbranches of the tree. And then you could-- again, to put it\njust intuitively,",
    "start": "1413550",
    "end": "1419400"
  },
  {
    "text": "the way you do this learning\nfrom one or a few examples, let's say that you see\nthose few tufas over there. You're basically asking,\nwhich branch of the tree",
    "start": "1419400",
    "end": "1426960"
  },
  {
    "text": "do I think-- those are randomly\ndrawn from some internal branch of the tree, some subtree.",
    "start": "1426960",
    "end": "1432360"
  },
  {
    "text": "Which subtree is it? And intuitively, if you see\nthose things and you say, well, they are randomly\ndrawn from some branch,",
    "start": "1432360",
    "end": "1437820"
  },
  {
    "text": "maybe it's the one\nthat I've circled. That sounds like a better bet,\nfor example, than this one",
    "start": "1437820",
    "end": "1443669"
  },
  {
    "text": "here, or maybe this\none, which would include one of these\nthings, but not the others. So that's probably unlikely.",
    "start": "1443670",
    "end": "1450092"
  },
  {
    "text": "And it's probably a\nbetter bet than, say, this branch, or this branch, or\nthese ones, which are logically compatible, but somehow\nit would have been sort",
    "start": "1450092",
    "end": "1456299"
  },
  {
    "text": "of a suspicious coincidence. If the set of tufas had\nreally been this branch here,",
    "start": "1456300",
    "end": "1461799"
  },
  {
    "text": "or this one here, then it would\nhave been quite a coincidence that the first three\nexamples you saw were all clustered over\nthere in one corner.",
    "start": "1461799",
    "end": "1468490"
  },
  {
    "text": "And what we showed was\nthat, that kind of model, where that suspicious\ncoincidence came out",
    "start": "1468490",
    "end": "1474060"
  },
  {
    "text": "from the same kinds\nof things I've just been showing you for the\ncausal clustering example, and for the interval thing,\nit's the same Bayesian math.",
    "start": "1474060",
    "end": "1480407"
  },
  {
    "text": "But now with this\ntree-structured hypothesis space, that was actually--\ndid a pretty good job of capturing people's judgments.",
    "start": "1480407",
    "end": "1486060"
  },
  {
    "text": "We gave people one or a few\nexamples of these concepts that, the examples could be\nmore narrowly or broadly spread,",
    "start": "1486060",
    "end": "1491550"
  },
  {
    "text": "just like you saw in\nthe clustering thing, but just sort of less extensive. We did this with adults.",
    "start": "1491550",
    "end": "1497010"
  },
  {
    "text": "We did this with kids. And I won't really go\ninto any of the details. but If you're interested,\ncheck out these various Xu",
    "start": "1497010",
    "end": "1502400"
  },
  {
    "text": "and Tenenbaum papers. That's the main one there. And you know, the\nmodel kind of worked. But ultimately, we\nfound it dissatisfying.",
    "start": "1502400",
    "end": "1508130"
  },
  {
    "text": "Because we couldn't\nreally explain-- we didn't really know what\nthe hypothesis space was. We didn't really know how people\nwere building up this tree.",
    "start": "1508130",
    "end": "1513769"
  },
  {
    "text": "And so we did a few things. We-- meaning I with\nsome other people-- turned to other problems where\nwe had a better idea, maybe,",
    "start": "1513769",
    "end": "1520403"
  },
  {
    "text": "of the feature space and\nthe hypothesis space, but the same kind of ideas\ncould be explored and developed. And then ultimately-- and I'll\nshow you this maybe before",
    "start": "1520404",
    "end": "1528830"
  },
  {
    "text": "lunch, or maybe after lunch-- we went back and tackled the\nproblem of learning concepts from examples with other cases\nwhere we could get a better",
    "start": "1528830",
    "end": "1536810"
  },
  {
    "text": "handle on really knowing what\nthe representations that people were using were, and also where\nwe could compare with machines",
    "start": "1536810",
    "end": "1543350"
  },
  {
    "text": "in much more compelling\napples and oranges ways. In some sense here, there's\nno machine, as far as I know,",
    "start": "1543350",
    "end": "1548600"
  },
  {
    "text": "that can solve this problem\nas well as our model. On the other hand,\nthat's, again, it's just very much like\nthe issue that came up",
    "start": "1548600",
    "end": "1554570"
  },
  {
    "text": "when we were talking about-- I guess maybe it was\nwith you, Tyler-- when we were talking about the\ndeep learning-- or with you, Leo--",
    "start": "1554570",
    "end": "1559690"
  },
  {
    "text": "the deep reinforcement network. A machine that's looking\nat this just as pixels",
    "start": "1559690",
    "end": "1565010"
  },
  {
    "text": "is missing so much\nof what we bring to it, which is,\nwe see these things as three-dimensional objects.",
    "start": "1565010",
    "end": "1570240"
  },
  {
    "text": "And just like the\ncam in rock climbing, or any of those\nother examples I gave before, I think that's\nessential to the abilities",
    "start": "1570240",
    "end": "1577414"
  },
  {
    "text": "that people are doing. The generative model\nwe build, this tree is based not on pixels, or\neven on ConvNet features,",
    "start": "1577414",
    "end": "1583171"
  },
  {
    "text": "but on a sense of the\nthree-dimensional objects, its parts, and their\nrelations to each other. And so, fundamentally, until\nwe know how to perceive objects",
    "start": "1583171",
    "end": "1590660"
  },
  {
    "text": "better, this is not going to\nbe comparable between humans and machines on equal terms.",
    "start": "1590660",
    "end": "1596030"
  },
  {
    "text": "But I'll show you\na little bit later some still pretty quite\ninteresting, but simpler, visual concepts that you can\nstill learn and generalize",
    "start": "1596030",
    "end": "1602000"
  },
  {
    "text": "from one example, but where they\nare comparable in equal terms. But first I want to tell you\na little bit about these--",
    "start": "1602000",
    "end": "1608960"
  },
  {
    "start": "1604000",
    "end": "1668000"
  },
  {
    "text": "yet another cognitive\njudgment, which like the word learning,\nor concept learning cases, involved generalizing\nfrom a few examples.",
    "start": "1608960",
    "end": "1615110"
  },
  {
    "text": "They also involve\nusing prior knowledge. But they're ones\nwhere maybe we have some way of capturing people's\nprior knowledge by using",
    "start": "1615110",
    "end": "1621289"
  },
  {
    "text": "the right combination\nof statistical inference on some kind of symbolically\nstructured bottle.",
    "start": "1621290",
    "end": "1626560"
  },
  {
    "text": "So you can already see, as-- I mean, just sort of to\nshow the narrative here.",
    "start": "1626560",
    "end": "1632009"
  },
  {
    "text": "The examples I was\ngiving here, this doesn't require any\nsymbolic structure. All that stuff I was\ntalking at the beginning,",
    "start": "1632010",
    "end": "1637730"
  },
  {
    "text": "about how we have to combine\nstatistical inference, sophisticated\nstatistical inference, with sophisticated\nsymbolic representations,",
    "start": "1637730",
    "end": "1643250"
  },
  {
    "text": "you don't need any of that here. All the representations\ncould just be counting up numbers or\nusing simple probability",
    "start": "1643250",
    "end": "1649010"
  },
  {
    "text": "distributions that\nstatisticians have worked with for over 100 years. Once we start to go\nhere, now we have",
    "start": "1649010",
    "end": "1655476"
  },
  {
    "text": "to define a model with\nsome interesting structure, like a branching tree\nstructure, and so on.",
    "start": "1655477",
    "end": "1661510"
  },
  {
    "text": "And as you'll see,\nwe can quickly get to lots more\ninteresting causal, compositionally-structured\ngenerative models",
    "start": "1661510",
    "end": "1668870"
  },
  {
    "start": "1668000",
    "end": "2019000"
  },
  {
    "text": "in similar kinds of tasks. And in particular,\nwe were looking for-- for a few years, we\nwere very interested",
    "start": "1668870",
    "end": "1674150"
  },
  {
    "text": "in these property\ninduction tasks. So this was-- it\nhappened to be-- I mean, I think this\nwas a coincidence. Or maybe we were both influenced\nby Susan Carey, actually.",
    "start": "1674150",
    "end": "1681679"
  },
  {
    "text": "So the work that Surya talked\nabout, that he was trying to explain as a\ntheoretician-- remember,",
    "start": "1681680",
    "end": "1686909"
  },
  {
    "text": "Surya and Andrew\nSaxe, they were trying to give the theory of\nthese neural network",
    "start": "1686910",
    "end": "1692029"
  },
  {
    "text": "models that Jay\nMcClelland and Tim Rogers had built\nin the early 2000s, around the same time we\nwere doing this work.",
    "start": "1692030",
    "end": "1697940"
  },
  {
    "text": "And they were inspired by\nsome of Susan Carey's work on children's intuitive\nbiology, as well as other people out there\nin cognitive psychology--",
    "start": "1697940",
    "end": "1705140"
  },
  {
    "text": "for example, Lance\nRips, and Smith, Madine.",
    "start": "1705140",
    "end": "1711770"
  },
  {
    "text": "Many, many cognitive\npsychologists studied things like this-- Dan Osherson.",
    "start": "1711770",
    "end": "1717765"
  },
  {
    "text": "They often talked about this as\na kind of inductive reasoning, or property induction,\nwhere the idea was--",
    "start": "1717765",
    "end": "1722825"
  },
  {
    "text": "so it might look different from\nthe task I've given you before, but actually, it's\ndeeply related.",
    "start": "1722826",
    "end": "1728875"
  },
  {
    "text": "The task was often presented\nto people like an argument with premises and\na conclusion, kind",
    "start": "1728875",
    "end": "1734870"
  },
  {
    "text": "of like a traditional deductive\nsyllogism, like all men are mortal, Socrates is a man,\ntherefore Socrates is mortal.",
    "start": "1734870",
    "end": "1740768"
  },
  {
    "text": "But these are\ninductive in that there is no-- you can't conclude\nwith deductive certainty",
    "start": "1740769",
    "end": "1746210"
  },
  {
    "text": "the conclusion follows\nfrom the premises or is falsified by the\npremise, but rather you just make a good guess.",
    "start": "1746210",
    "end": "1751480"
  },
  {
    "text": "The statements above the line\nprovide some, more or less, good or bad evidence\nfor the statement",
    "start": "1751480",
    "end": "1756980"
  },
  {
    "text": "below the line being true. These studies were\noften done with-- they",
    "start": "1756980",
    "end": "1762200"
  },
  {
    "text": "could be done with just sort of\nfamiliar biological properties, like having hairy legs or\nbeing bigger than a breadbox.",
    "start": "1762200",
    "end": "1770565"
  },
  {
    "text": "I mean, it's also-- it's very\nmuch the same kind of thing that Tom Mitchell was talking\nabout, as you'll start to see.",
    "start": "1770565",
    "end": "1775799"
  },
  {
    "text": "There's another reason why\nI wanted to cover this. We worked on these\nthings because we wanted to be able to engage\nwith the same kinds of things",
    "start": "1775800",
    "end": "1782095"
  },
  {
    "text": "that people like Jay\nMcClelland and Tom Mitchell were thinking about, coming\nfrom different perspectives. Remember, Tom\nMitchell showed you",
    "start": "1782095",
    "end": "1787610"
  },
  {
    "text": "his way of classifying brain\nrepresentations of semantics",
    "start": "1787610",
    "end": "1792710"
  },
  {
    "text": "with matrices of objects and\n20-question-like features that included things like is\nit hairy, or is it alive,",
    "start": "1792710",
    "end": "1798920"
  },
  {
    "text": "or does it eggs, or is\nit bigger than a car, or bigger than a\nbreadbox, or whatever.",
    "start": "1798920",
    "end": "1806190"
  },
  {
    "text": "Any one of these things-- basically, we're getting\nat the same thing. Here there's just what's--",
    "start": "1806190",
    "end": "1811510"
  },
  {
    "text": "often these\nexperiments with humans were done with so-called\nblank predicates, something that sounded vaguely biological,\nbut was basically made up,",
    "start": "1811510",
    "end": "1817840"
  },
  {
    "text": "or that most people\nwouldn't know much about. Does anyone know anything\nabout T9 hormones? I hope so, because I made it up.",
    "start": "1817840",
    "end": "1824299"
  },
  {
    "text": "But some of them were\njust done with things that were real, but not\nknown to most people. So if I tell you that\ngorillas and seals both have",
    "start": "1824299",
    "end": "1831072"
  },
  {
    "text": "T9 hormones, you might think\nit's sort of, fairly plausible that horses have T9 hormones,\nmaybe more so than if I hadn't told you anything.",
    "start": "1831072",
    "end": "1838060"
  },
  {
    "text": "Maybe you think that\nargument is more plausible than the one\non the right; given that gorillas and seals have\nT9 or hormones, that anteaters",
    "start": "1838060",
    "end": "1845007"
  },
  {
    "text": "have hormones. So maybe you think\nhorses are somehow more similar to gorillas and\nseals than anteaters are.",
    "start": "1845007",
    "end": "1850629"
  },
  {
    "text": "I don't know. Maybe. Maybe a little bit. If I made that bees-- gorillas and seals\nhave T9 on hormones.",
    "start": "1850629",
    "end": "1856305"
  },
  {
    "text": "Does that make you think\nit's likely that bees have T9 hormones, or pine trees?",
    "start": "1856305",
    "end": "1862030"
  },
  {
    "text": "The farther the\nconclusion category gets from the premises, the\nless plausible it seems. Maybe the one on the lower right\nalso seems not very plausible,",
    "start": "1862030",
    "end": "1869260"
  },
  {
    "text": "or not as plausible. Because if I tell\nyou that gorillas have T9 hormones, chimps,\nmonkeys, and baboons all have T9 on\nhormones, maybe you",
    "start": "1869260",
    "end": "1876130"
  },
  {
    "text": "think that it's only\nprimates or something. So they're not a\nvery-- it's, again, one of these\ntypicality-suspicious",
    "start": "1876130",
    "end": "1881140"
  },
  {
    "text": "coincidence businesses. So again, you can\nthink of it as-- you can do these experiments\nin various ways.",
    "start": "1881140",
    "end": "1887380"
  },
  {
    "text": "I won't really go\nthrough the details, but it basically\ninvolves giving people a bunch of different sets\nof examples, just like--",
    "start": "1887380",
    "end": "1893229"
  },
  {
    "text": "I mean, in some sense,\nthe important thing to get is that abstractly it has\nthe same character of all the other tasks you've seen.",
    "start": "1893229",
    "end": "1898420"
  },
  {
    "text": "You're giving people one or\na few examples, which we're going to treat as random\ndraws from some concept,",
    "start": "1898420",
    "end": "1904149"
  },
  {
    "text": "or some region in\nsome larger space. In this case, the examples\nare the different premise",
    "start": "1904150",
    "end": "1909399"
  },
  {
    "text": "categories, like\ngorillas and seals are examples of the concept\nof having T9 hormones.",
    "start": "1909400",
    "end": "1915279"
  },
  {
    "text": "Or gorillas, chimps,\nmonkeys, and baboons are an example of a concept. We're going to put a\nprior on possible extents",
    "start": "1915280",
    "end": "1921460"
  },
  {
    "text": "of that concept, and then\nask what kind of inferences people make from that\nprior, to figure out",
    "start": "1921460",
    "end": "1926867"
  },
  {
    "text": "what other things\nare in that concept. So are horses in\nthat same concept? Or are anteaters?",
    "start": "1926867",
    "end": "1932382"
  },
  {
    "text": "Or are horses in it more or\nless, depending on the examples you give? And what's the\nnature of that prior?",
    "start": "1932382",
    "end": "1937750"
  },
  {
    "text": "And what's good\nabout this is that, kind of like the everyday\nprediction task--",
    "start": "1937750",
    "end": "1944740"
  },
  {
    "text": "the lines of the poems, or\nthe movie grosses, or the cake baking-- we can actually\nsort of go out and measure some features that are\nplausibly relevant,",
    "start": "1944740",
    "end": "1950960"
  },
  {
    "text": "to set up a plausibly\nrelevant prior, unlike the interesting\nobject cases.",
    "start": "1950960",
    "end": "1956860"
  },
  {
    "text": "But like the interesting\nobject cases, there are some interesting\nhierarchical and other kinds of causal compositional\nstructures",
    "start": "1956860",
    "end": "1962740"
  },
  {
    "text": "that people seem\nto be using that we can capture in our models. So here, again, the kinds of\nexperiments-- these features",
    "start": "1962740",
    "end": "1970240"
  },
  {
    "text": "were generated many years ago\nby Osherson and colleagues. But it's very similar\nto the 20 questions game",
    "start": "1970240",
    "end": "1976270"
  },
  {
    "text": "that Tom Mitchell used. And I don't remember\nif Surya talked about where these\nfeatures came from, that he talked a lot about a\nmatrix of objects and features.",
    "start": "1976270",
    "end": "1982570"
  },
  {
    "text": "I don't know if he talked\nabout where they come from. But actually, psychologists\nspent a while coming up with ways to get\npeople to just tell you",
    "start": "1982570",
    "end": "1989110"
  },
  {
    "text": "a bunch of features of animals. This is, again, it's meant\nto capture the knowledge that maybe a kid would get\nfrom maybe plausibly reading",
    "start": "1989110",
    "end": "1997210"
  },
  {
    "text": "books and going to the zoo. We know that elephants are gray. They're hairless. They have tough skin. They're big. They have a bulbous body shape.",
    "start": "1997210",
    "end": "2004740"
  },
  {
    "text": "They have long legs. These are all mostly\nrelative to other animals. They have a tail. They have tusks. They might be smelly,\ncompared to other animals--",
    "start": "2004740",
    "end": "2011638"
  },
  {
    "text": "smellier than average is\nsort of what that means. They walk, as opposed to fly. They're slow, as\nopposed to fast.",
    "start": "2011639",
    "end": "2016752"
  },
  {
    "text": "They're strong, as\nopposed to weak. It's that kind of business. So basically what that gives\nyou is this big matrix.",
    "start": "2016752",
    "end": "2021810"
  },
  {
    "start": "2019000",
    "end": "2104000"
  },
  {
    "text": "Again, the same kind\nof thing that you saw in Surya's talk,\nthe same kind of thing that Tom Mitchell\nis using to help",
    "start": "2021810",
    "end": "2027750"
  },
  {
    "text": "classify things, the\nsame kind of thing that basically everybody\nin machine learning uses-- a matrix of data\nwith objects, maybe as rows,",
    "start": "2027750",
    "end": "2035190"
  },
  {
    "text": "and features, or\nattributes, as columns. And the problem here is-- the problem of\nlearning is to say--",
    "start": "2035190",
    "end": "2042144"
  },
  {
    "text": "the problem of learning and\ngeneralizing from one example is to take a new property,\nwhich is a new concept, which is like a new\ncolumn here, to get",
    "start": "2042145",
    "end": "2048810"
  },
  {
    "text": "one or a few examples of that\nconcept, which is basically just filling in one or a\nfew entries in that column,",
    "start": "2048810",
    "end": "2054599"
  },
  {
    "text": "and figure out how to fill\nin the others, to decide, do you or don't you have\nthat property, somehow",
    "start": "2054600",
    "end": "2059790"
  },
  {
    "text": "building knowledge\nthat you can generalize from your prior\nexperience, which could be captured by, say,\nall the other features",
    "start": "2059790",
    "end": "2066360"
  },
  {
    "text": "that you know about objects. So that's the way\nthat you might set up this problem, which again, looks\nlike a lot of other problems",
    "start": "2066360",
    "end": "2072030"
  },
  {
    "text": "of, say, semi-supervised\nlearning or sparse matrix completion. It's a problem in which\nwe can, or at least we thought we could,\ncompare humans",
    "start": "2072030",
    "end": "2078592"
  },
  {
    "text": "and many different\nalgorithms, and even theory, like from Surya's talk. And that seemed very\nappealing to us.",
    "start": "2078592",
    "end": "2083760"
  },
  {
    "text": "What we thought, though,\nthat people were doing, which is maybe a little\ndifferent than what-- or somewhat different-- well,\nquite different than what Jay",
    "start": "2083760",
    "end": "2089940"
  },
  {
    "text": "McClelland thought\npeople were doing-- maybe a little bit more like\nwhat Susan Carey or some of the earlier psychologists\nthought people were doing--",
    "start": "2089940",
    "end": "2095721"
  },
  {
    "text": "was something like this. That the way we\nsolve this problem, the way we bridged from our\nprior experience to new things",
    "start": "2095722",
    "end": "2102380"
  },
  {
    "text": "we wanted to learn was\nnot, say, by just computing the second order of\nstatistics and correlations,",
    "start": "2102380",
    "end": "2108860"
  },
  {
    "start": "2104000",
    "end": "2216000"
  },
  {
    "text": "and compressing that through\nsome bottleneck hidden layer, but by building a\nmore interesting structured probabilistic\nmodel that was, in some form,",
    "start": "2108860",
    "end": "2115849"
  },
  {
    "text": "causal-- in some form-- in some\nform, compositional and hierarchical--\nsomething kind of like this.",
    "start": "2115850",
    "end": "2122140"
  },
  {
    "text": "And this is a good example of a\nhierarchical generative model. There's three layers\nof structure here.",
    "start": "2122140",
    "end": "2129110"
  },
  {
    "text": "The bottom layer is\nthe observable layer. So the arrows in these\ngenerative models point down,",
    "start": "2129110",
    "end": "2134510"
  },
  {
    "text": "often, usually, where the thing\non the bottom is the thing you observe, the data\nof your experience.",
    "start": "2134510",
    "end": "2139820"
  },
  {
    "text": "And then the stuff above it\nare various levels of structure that your mind is\npositing to explain it.",
    "start": "2139820",
    "end": "2145440"
  },
  {
    "text": "So here we have two\nlevels of structure. The level above this is sort\nof this tree in your head.",
    "start": "2145440",
    "end": "2150590"
  },
  {
    "text": "The idea-- it's like a certain\nkind of graph structure, where the objects, or the\nspecies, are the leaf nodes.",
    "start": "2150590",
    "end": "2156653"
  },
  {
    "text": "And there's some internal\nnodes corresponding, maybe to higher level taxa,\nor groups, or something. You might have words for\nthese, too, like mammal,",
    "start": "2156654",
    "end": "2162860"
  },
  {
    "text": "or primate, or animal. And the idea is that\nthere's some kind of probabilistic model\nthat you can describe,",
    "start": "2162860",
    "end": "2168890"
  },
  {
    "text": "maybe even a causal one on top\nof that symbolic structure, that tree, that produces the\ndata that's more directly",
    "start": "2168890",
    "end": "2176000"
  },
  {
    "text": "observable, the\nobservable features, including the things\nyou've only sparsely observed and want to fill in. And then you might also have\nhigher levels of structure.",
    "start": "2176000",
    "end": "2183200"
  },
  {
    "text": "Like if you want to\nexplain, how did you learn that tree in\nthe first place, maybe it's because you have\nsome kind of generative model",
    "start": "2183200",
    "end": "2189957"
  },
  {
    "text": "for that generative model. So here I'm just using\nwords to describe it, but I'll show you some\nother stuff in a-- or I'll show you something\nmore formal a little bit later.",
    "start": "2189957",
    "end": "2197599"
  },
  {
    "text": "But you could say,\nwell, maybe the way I figure out that there's\na tree structure is by having a hypothesis--",
    "start": "2197600",
    "end": "2204206"
  },
  {
    "text": "the way I figure\nout that there's that particular tree-structured\ngraphical model of this domain",
    "start": "2204206",
    "end": "2209480"
  },
  {
    "text": "is by having the more\ngeneral hypothesis that there is some latent\nhierarchy of species. And I just have to figure\nout which one it is.",
    "start": "2209480",
    "end": "2217040"
  },
  {
    "start": "2216000",
    "end": "2375000"
  },
  {
    "text": "So you could formulate this\nas a hierarchical inference by saying that\nwhat we're calling the form, the form\nof the model, it's",
    "start": "2217040",
    "end": "2222500"
  },
  {
    "text": "like a hypothesis space of\nmodels, which are themselves hypothesis spaces of possible\nobserved patterns of feature",
    "start": "2222500",
    "end": "2228890"
  },
  {
    "text": "correlation. And that, that higher\nlevel knowledge, puts some kind of a generative\nmodel on these graph",
    "start": "2228890",
    "end": "2234020"
  },
  {
    "text": "structures, where each\ngraph structure then puts a generative model on\nthe data you can observe. And then you could\nhave even higher levels",
    "start": "2234020",
    "end": "2239210"
  },
  {
    "text": "of this sort of thing. And then learning could\ngo on at any or all levels of this hierarchy, higher\nthan the level of experience.",
    "start": "2239210",
    "end": "2245399"
  },
  {
    "text": "So just to show you a little\nbit about how this kind of thing works, what we're calling\nthe probability of the data",
    "start": "2245399",
    "end": "2251869"
  },
  {
    "text": "given the structure is actually\nexactly the same, really, as the model that Surya\nand Andrew Saxe used.",
    "start": "2251870",
    "end": "2257299"
  },
  {
    "text": "The difference is that\nwe were suggesting-- may be right, may be wrong--",
    "start": "2257300",
    "end": "2262641"
  },
  {
    "text": "that something like\nthis generative model was actually in your head. Surya presented a very\nsimple abstraction",
    "start": "2262642",
    "end": "2269270"
  },
  {
    "text": "of evolutionary branching\nprocess, a kind of diffusion over the tree, where properties\ncould turn on or off.",
    "start": "2269270",
    "end": "2274940"
  },
  {
    "text": "And we built basically\nthat same kind of model. And we said, maybe you\nhave something in your head",
    "start": "2274940",
    "end": "2280880"
  },
  {
    "text": "as a model of, again, the\ndistribution of properties, or features, or attributes over\nthe leaf nodes of the tree.",
    "start": "2280880",
    "end": "2288630"
  },
  {
    "text": "So if you have this kind\nof statistical model. If you think that there's\nsomething like a tree structure, and properties are\nproduced over the leaf nodes",
    "start": "2288630",
    "end": "2296990"
  },
  {
    "text": "by some kind of switching,\non-and-off, mutation-like process, then you can do\nsomething like in this picture",
    "start": "2296990",
    "end": "2302030"
  },
  {
    "text": "here. You can take an observe a set\nof features in that matrix and learn the best tree. You can figure out that\nthing I'm showing on the top,",
    "start": "2302030",
    "end": "2308760"
  },
  {
    "text": "that structure, which is,\nin some sense, the best guess of a tree structure-- a\nlatent tree structure-- which",
    "start": "2308760",
    "end": "2314000"
  },
  {
    "text": "if you then define some\nkind of diffusion mutation process over that tree, would\nproduce with high probability",
    "start": "2314000",
    "end": "2320810"
  },
  {
    "text": "distributions of features\nlike those shown there. If I gave you a\nvery different tree it would produce other\npatterns of correlation.",
    "start": "2320810",
    "end": "2327450"
  },
  {
    "text": "And it's just like\nSurya said, it can be all captured by the\nsecond order statistics of feature correlations. The nice thing about\nthis is that now this",
    "start": "2327450",
    "end": "2334190"
  },
  {
    "text": "also gives a distribution\non new properties. So if I observe-- because each column is\nconditionally independent",
    "start": "2334190",
    "end": "2339302"
  },
  {
    "text": "given that model. Each column is an\nindependent sample from that generative model.",
    "start": "2339302",
    "end": "2344400"
  },
  {
    "text": "And the idea is if I\nobserve a new property, and I want to say, well, which\nother things have this, well, I can make a guess on using\nthat probabilistic model.",
    "start": "2344400",
    "end": "2351740"
  },
  {
    "text": "I can say, all\nright, given that I know the value of this\nfunction over the tree, this stochastic process,\nat some points, what",
    "start": "2351740",
    "end": "2358850"
  },
  {
    "text": "do I think the most likely\nvalues are at other points? And basically, what you get is,\nagain, like in the diffusion process, a kind of\nsimilarity-based generalization",
    "start": "2358851",
    "end": "2365750"
  },
  {
    "text": "with a tree-structured metric,\nthat nearby points in the tree are likely to have\nthe same value. So in particular, things that\nare near to, say, species one",
    "start": "2365750",
    "end": "2373077"
  },
  {
    "text": "and nine are probably going\nto have the same property, and others maybe less so. And you build that model.",
    "start": "2373077",
    "end": "2378150"
  },
  {
    "start": "2375000",
    "end": "2590000"
  },
  {
    "text": "And it's really quite\nstriking how much it matches people's intuitions. So now you're seeing the kinds\nof plots I was showing you",
    "start": "2378150",
    "end": "2383666"
  },
  {
    "text": "before, where-- all my data plots\nlook like this. Whenever I'm showing the\nscatterplot, by default, the y-axis is the average of\na bunch of people's judgments,",
    "start": "2383666",
    "end": "2392300"
  },
  {
    "text": "and the x-axis is the model\npredictions on the same units or scale. And each of these\nscatterplots is",
    "start": "2392300",
    "end": "2398329"
  },
  {
    "text": "from a different\nexperiment-- not done by us, done by other people,\nlike Osherson and Smith from a couple of decades ago.",
    "start": "2398330",
    "end": "2403840"
  },
  {
    "text": " But they all sort of have\nthe same kind of form, where each dot is a\ndifferent set of examples,",
    "start": "2403840",
    "end": "2410800"
  },
  {
    "text": "or a different argument. And what typically varied\nwithin an experiment-- you vary the examples. And you fix constant\nthe conclusion category.",
    "start": "2410800",
    "end": "2418810"
  },
  {
    "text": "And you see, basically,\nhow much evidential support to different sets of\ntwo or three examples gives to a certain conclusion.",
    "start": "2418810",
    "end": "2425200"
  },
  {
    "text": "And it's really, again,\nquite striking that-- sometimes in a more\ncategorical way, sometimes in a more graded\nway-- but basically,",
    "start": "2425200",
    "end": "2431110"
  },
  {
    "text": "people's average\njudgments here just line up quite well with the\nsort of Bayesian inference",
    "start": "2431110",
    "end": "2437950"
  },
  {
    "text": "on this tree-structured\ngenerative model. These are just examples of\nthe kinds of stimuli here.",
    "start": "2437950",
    "end": "2445119"
  },
  {
    "text": "Now, we can compare. One of the reasons\nwhy we were interested in this was to compare, again,\nmany different approaches. So here I'm going to show\nyou a comparison with just",
    "start": "2445120",
    "end": "2452110"
  },
  {
    "text": "a variant of our approach. It's the same kind of\nhierarchical Bayesian model, but now the structure\nisn't a tree,",
    "start": "2452110",
    "end": "2457540"
  },
  {
    "text": "it's a low-dimensional\nEuclidean space. You can define the same kinds\nof proximity smoothness thing.",
    "start": "2457540",
    "end": "2463967"
  },
  {
    "text": "I mean, again, it's more a\nstandard in machine learning. It's related to\nGaussian processes.",
    "start": "2463967",
    "end": "2470500"
  },
  {
    "text": "It's much more like\nneural networks. You could think of this as\nkind of like a Bayesian version of a bottleneck hidden\nlayer with two dimensions,",
    "start": "2470500",
    "end": "2477430"
  },
  {
    "text": "or a small number of dimensions. The pictures that Surya showed\nyou were all higher dimensions than two dimensions\nin the latent space,",
    "start": "2477430",
    "end": "2483640"
  },
  {
    "text": "or the hidden variable\nspace, of the neural network, the hidden layer space. But when he compress it\ndown to two dimensions,",
    "start": "2483640",
    "end": "2488920"
  },
  {
    "text": "it looks pretty good. So it's the same kind of idea. Now what you're saying\nis you're going to find,",
    "start": "2488920",
    "end": "2497370"
  },
  {
    "text": "not the best tree that\nexplains all these features, but the best\ntwo-dimensional space. Maybe it looks like this.",
    "start": "2497370",
    "end": "2503680"
  },
  {
    "text": "Where, again, the\nprobabilistic model says that things which are\nrelatively-- things that are closer in this\ntwo-dimensional space",
    "start": "2503680",
    "end": "2509260"
  },
  {
    "text": "are more likely to have\nthe same feature value. So you're basically explaining\nall the pairwise feature correlations by\ndistance in this space.",
    "start": "2509260",
    "end": "2517340"
  },
  {
    "text": "It's similar. Importantly it's not as\ncausal and compositional. The tree models something about,\npossibly, the causal processes",
    "start": "2517340",
    "end": "2524769"
  },
  {
    "text": "of how organisms come to be. If I told you that,\noh, there's this-- that I told you about a\nsubspecies, like whatever--",
    "start": "2524770",
    "end": "2533315"
  },
  {
    "text": "what's a good example-- different breeds of dogs. Or I told you that, oh, well,\nthere's not just wolves,",
    "start": "2533315",
    "end": "2540310"
  },
  {
    "text": "but there's the gray-tailed\nwolf and the red-tailed wolf. Red-tailed wolf? I don't know. Again, they're probably\nsimilar, but they might--",
    "start": "2540310",
    "end": "2546339"
  },
  {
    "text": "one red-tailed wolf,\nwhatever that is, more similar to another\nred-tailed wolf, probably has more\nfeatures in common",
    "start": "2546340",
    "end": "2551409"
  },
  {
    "text": "than with a gray-tailed\nwolf, and probably more to the gray-tailed\nwolf than to a dog. The nice thing about a tree is\nI can tell you these things,",
    "start": "2551409",
    "end": "2557461"
  },
  {
    "text": "and you can, in your mind-- maybe you'll never forget that\nthere's a red-tailed wolf. There isn't. I just made it up. But if you ever find\nyourself thinking",
    "start": "2557461",
    "end": "2564677"
  },
  {
    "text": "about red-tailed wolves and\nwhether their properties are more or less similar to each\nother than to gray-tailed",
    "start": "2564677",
    "end": "2570040"
  },
  {
    "text": "wolves, or less so\nto dogs, or so on, it's because I just\nsaid some things, and you grew out your\ntree in your mind.",
    "start": "2570040",
    "end": "2575736"
  },
  {
    "text": "That's a lot harder to do\nin a low-dimensional space. And it turns out\nthat, that model also",
    "start": "2575736",
    "end": "2581770"
  },
  {
    "text": "fits this data less well. So here I'm just showing\ntwo of those experiments. Some of them are well\nfit by that model,",
    "start": "2581770",
    "end": "2586806"
  },
  {
    "text": "but others are less well fit. Now, that's not to\nsay that they wouldn't be good for other things. So we also did some experiments.",
    "start": "2586806",
    "end": "2592930"
  },
  {
    "start": "2590000",
    "end": "2764000"
  },
  {
    "text": "This was experiments\nthat we did. Oh, actually, I forgot to\nsay, really importantly, this was all worked done\nby Charles Kemp, who's",
    "start": "2592930",
    "end": "2598059"
  },
  {
    "text": "now a professor at CMU. And it was part of the stuff\nthat he did in his PhD thesis.",
    "start": "2598060",
    "end": "2604870"
  },
  {
    "text": "So we were interested in this\nas a way, not to study trees, but to study a range of\ndifferent kinds of structures.",
    "start": "2604870",
    "end": "2610680"
  },
  {
    "text": "And it is true, going back,\nI guess, to the question you asked, this is what\nI was referring to about low-dimensional manifolds.",
    "start": "2610680",
    "end": "2616390"
  },
  {
    "text": "There are some kinds of\nknowledge representations we have which might have\na low-dimensional spatial structure, in particular,\nlike mental maps of the world.",
    "start": "2616390",
    "end": "2624340"
  },
  {
    "text": "So our intuitive models of the\nEarth's surface, and things which might be distributed\nover the Earth's surface",
    "start": "2624340",
    "end": "2630850"
  },
  {
    "text": "spatially, a two-dimensional\nmap is probably a good one for that. So here we considered a\nsimilar kind of concept",
    "start": "2630850",
    "end": "2638590"
  },
  {
    "text": "learning from a few examples\ntask, where we said-- but now we put it like this.",
    "start": "2638590",
    "end": "2643960"
  },
  {
    "text": "We said, suppose\nthat a certain kind of Native American\nartifact has been found in sites near city x.",
    "start": "2643960",
    "end": "2649240"
  },
  {
    "text": "How likely is it also to be\nfound in sites near city y? Or we could say sites near\ncity x and y, how about city z.",
    "start": "2649240",
    "end": "2656650"
  },
  {
    "text": "And we told people that\ndifferent Native American tribes maybe had-- some lived\nin a very small area, some",
    "start": "2656650",
    "end": "2665200"
  },
  {
    "text": "lived in a very big area. Some lived in one place,\nsome another place. Some lived here, and\nthen moved there.",
    "start": "2665200",
    "end": "2670309"
  },
  {
    "text": "We just told people very vague\nthings that taps into people's probably badly remembered,\nand very distorted,",
    "start": "2670309",
    "end": "2675730"
  },
  {
    "text": "versions of American history\nthat would basically suggests that there should be\nsome kind of similar kind",
    "start": "2675730",
    "end": "2682089"
  },
  {
    "text": "of spatial diffusion\nprocess, but now in your 2D mental map of cities. So again, there's no claim that\nthere's any reality to this,",
    "start": "2682090",
    "end": "2690040"
  },
  {
    "text": "or fine-grained reality. But we thought it would\nsort of roughly correspond to people's internal\ncausal generative",
    "start": "2690040",
    "end": "2695410"
  },
  {
    "text": "models of archeology. Again, I think it says\nsomething about the way",
    "start": "2695410",
    "end": "2700900"
  },
  {
    "text": "human intelligence\nworks that none of us are archaeologists, probably,\nbut we still have these ideas. And it turned out that, here,\na spatially structured model",
    "start": "2700900",
    "end": "2707920"
  },
  {
    "text": "actually works a lot better. Again, it shouldn't\nbe surprising. It's just showing that actually,\nthe way-- the judgments",
    "start": "2707920",
    "end": "2713816"
  },
  {
    "text": "people make when they're making\ninferences from a few examples, just like you saw\nwith the predicting the everyday events,\nbut now in the much more",
    "start": "2713816",
    "end": "2720070"
  },
  {
    "text": "interestingly\nstructured domain, is sensitive to the different kinds\nof environmental statistics.",
    "start": "2720070",
    "end": "2725200"
  },
  {
    "text": "There it was different power\nlaws versus Gaussian's of cake bake-- or of movie grosses\nversus lifetimes or something.",
    "start": "2725200",
    "end": "2734079"
  },
  {
    "text": "Here it's other stuff. It's more interestingly\nstructured kinds of knowledge. But you see the same\nkind of picture.",
    "start": "2734080",
    "end": "2740050"
  },
  {
    "text": "And we thought that\nwas interesting, and again, suggests\nsome of the ways that we are starting to\nput these tools together,",
    "start": "2740050",
    "end": "2746020"
  },
  {
    "text": "putting together probabilistic\ngenerative models with some kind of interestingly\nstructured knowledge. Now, again, as you\nsaw from Surya,",
    "start": "2746020",
    "end": "2752140"
  },
  {
    "text": "and as Jay McClellan and\nTim Rogers worked on, you can try to capture\na lot of this stuff with neural networks.",
    "start": "2752140",
    "end": "2757240"
  },
  {
    "text": "The neat thing about the neural\nnetworks that these guys have worked on is that exactly\nthe same neural network can",
    "start": "2757240",
    "end": "2763090"
  },
  {
    "text": "capture this kind\nof thing, and it can capture this kind of thing. So you can train the very\nsame hidden multilayer neural",
    "start": "2763090",
    "end": "2771400"
  },
  {
    "start": "2764000",
    "end": "2913000"
  },
  {
    "text": "network with one matrix\nof object and features. And the very same\nneural network can",
    "start": "2771400",
    "end": "2777790"
  },
  {
    "text": "predict the tree-structured\npatterns for animals and their properties, as well\nas the spatially-structured",
    "start": "2777790",
    "end": "2783790"
  },
  {
    "text": "patterns for Native American\nartifacts and their cities. The catch is that it doesn't\ndo either of them that well.",
    "start": "2783790",
    "end": "2791380"
  },
  {
    "text": "It doesn't do as well as the\ntree-structured models do for peop--",
    "start": "2791380",
    "end": "2796630"
  },
  {
    "text": "when I say either, it\ndoesn't do that well, I mean, in capturing\npeople's judgments. It doesn't do as well as the\nbest tree-structured models do",
    "start": "2796630",
    "end": "2801670"
  },
  {
    "text": "for people's concepts of\nanimals and their properties. And it doesn't do as well as\nthe best spacial structures.",
    "start": "2801670",
    "end": "2806890"
  },
  {
    "text": "But again, it's in the same\nspirit as the DeepMind networks for playing lots of Atari games. The idea there is to have\nthe same network solve",
    "start": "2806890",
    "end": "2813550"
  },
  {
    "text": "all these different tasks. And in some sense, I\nthink that's a good idea. I just think that the\narchitecture should",
    "start": "2813550",
    "end": "2818709"
  },
  {
    "text": "have a more flexible structure. So we would also\nsay, in some sense, the same architecture is solving\nall these different tasks.",
    "start": "2818709",
    "end": "2824560"
  },
  {
    "text": "It's just that this\nis one setting of it. And this is another\nsetting of it.",
    "start": "2824560",
    "end": "2830260"
  },
  {
    "text": "And where they differ is\nin the kind of structure that-- well, they\ndiffer in the fact that they explicitly represent\nstructure in the world.",
    "start": "2830260",
    "end": "2836502"
  },
  {
    "text": "And they explicitly represent\ndifferent kinds of structure. And they explicitly represent\nthat different kinds of structure are appropriate\nto different kinds of domains",
    "start": "2836502",
    "end": "2843895"
  },
  {
    "text": "in the world and our intuitions\nabout the causal processes that are at work producing the data. And I think that,\nagain, that's sort",
    "start": "2843895",
    "end": "2849970"
  },
  {
    "text": "of the difference between\nthe pattern classification and the understanding\nor explaining view of intelligence.",
    "start": "2849970",
    "end": "2857680"
  },
  {
    "text": "The explanations, of course,\ngo a lot beyond different ways that similarity\ncan be structured. So one of the kind\nof nice things-- oh,",
    "start": "2857680",
    "end": "2864220"
  },
  {
    "text": "and I guess another-- two other points beyond that. One is that to get\nthe neural networks",
    "start": "2864220",
    "end": "2870070"
  },
  {
    "text": "to do that, you have to train\nthem with a lot of data. Remember, Surya, as Tommy\npushed him on in that talk,",
    "start": "2870070",
    "end": "2875380"
  },
  {
    "text": "Surya was very\nconcerned with modeling the dynamics of learning in the\nsense of the optimization time",
    "start": "2875380",
    "end": "2881650"
  },
  {
    "text": "course, how the weights\nchange over time. But he was usually\nlooking at infinite data.",
    "start": "2881650",
    "end": "2886750"
  },
  {
    "text": "So he was assuming that\nyou had, effectively, an infinite number of columns\nof any of these matrices.",
    "start": "2886750",
    "end": "2891940"
  },
  {
    "text": "So you could perfectly\ncompute the statistics. And another important\nthing about the difference being the neural network models\nand the ones I was showing you",
    "start": "2891940",
    "end": "2898503"
  },
  {
    "text": "is that, suppose you want\nto train the model, not on an infinite matrix,\nbut on a small finite one,",
    "start": "2898503",
    "end": "2904780"
  },
  {
    "text": "and maybe one with missing data. It's a lot harder to get\nthe-- the neural network will do a much poorer job capturing\nthe structure than these more",
    "start": "2904780",
    "end": "2912940"
  },
  {
    "text": "structured models. And again, in a way\nthat's familiar with-- have you guys talked about\nbias-variance dilemma?",
    "start": "2912940",
    "end": "2918820"
  },
  {
    "start": "2913000",
    "end": "2989000"
  },
  {
    "text": "So it's that same kind\nof idea that you probably heard about from Lorenzo. Was it Lorenzo or one\nof the machin learni--",
    "start": "2918820",
    "end": "2925520"
  },
  {
    "text": "OK. So it's that same kind\nof idea, but now applying in this interesting case\nof structured estimation of generative models\nfor the world,",
    "start": "2925520",
    "end": "2932440"
  },
  {
    "text": "that if you have relatively\nlittle data, and sparse data, then having a more\nstructured inductive bi--",
    "start": "2932440",
    "end": "2939822"
  },
  {
    "text": "having the inductive bias that\ncomes from a more structured representation is going to\nbe much more valuable when",
    "start": "2939822",
    "end": "2946030"
  },
  {
    "text": "you have sparse and noisy data. The key-- and again, this is\nsomething that Charles and I",
    "start": "2946030",
    "end": "2951310"
  },
  {
    "text": "were really interested\nin-- is we wanted to-- like the DeepMind people,\nlike the connectionists, we wanted to build general\npurpose semantic cognition,",
    "start": "2951310",
    "end": "2959080"
  },
  {
    "text": "wanted to build general purpose\nlearning and reasoning systems. And we wanted to\nsomehow figure out",
    "start": "2959080",
    "end": "2965260"
  },
  {
    "text": "how you could have the best of\nboth worlds, how you could have a system that relatively\nquickly could come",
    "start": "2965260",
    "end": "2971170"
  },
  {
    "text": "to get the right kind of strong\nconstraint-inductive bias in some domain, and a different\none for a different domain,",
    "start": "2971170",
    "end": "2977109"
  },
  {
    "text": "yet could learn\nin a flexible way to capture the different\nstructure in different domains. More on that in a little bit.",
    "start": "2977110",
    "end": "2983060"
  },
  {
    "text": "But the other thing I\nwanted to talk about here is just ways in which\nour mental models, our causal and\ncompositional ones,",
    "start": "2983060",
    "end": "2989859"
  },
  {
    "start": "2989000",
    "end": "3035000"
  },
  {
    "text": "go beyond just similarity. I guess, since time\nis short-- well, I was planning to go through\nthis relatively quickly.",
    "start": "2989860",
    "end": "2995698"
  },
  {
    "text": "But anyway, mostly I'll\njust gesture towards this. And if you're\ninterested, you could read the papers that\nCharles has, or his thesis.",
    "start": "2995698",
    "end": "3002200"
  },
  {
    "text": "But here, there's a long\nhistory of asking people to make these kind of\njudgments, in which",
    "start": "3002200",
    "end": "3007460"
  },
  {
    "text": "the basis for the judgment\nisn't something like similarity, but some other kind\nof causal reasoning.",
    "start": "3007460",
    "end": "3012599"
  },
  {
    "text": "So for example, consider\nthese things here. Poodles can bite through wire,\ntherefore German shepherds can bite through wire.",
    "start": "3012599",
    "end": "3018150"
  },
  {
    "text": "Is that a strong\nargument or weak? Compare that with, dobermans\ncan bite through wire, therefore German shepherds can\nbite through wire.",
    "start": "3018150",
    "end": "3024079"
  },
  {
    "text": "So how many people think that\nthe top argument is a stronger one? How many people think the\nbottom line is a stronger one?",
    "start": "3024080",
    "end": "3030319"
  },
  {
    "text": "So that's typical. About twice as many\npeople prefer the top one. Because intuitively--\ndo I have a little thing",
    "start": "3030320",
    "end": "3036560"
  },
  {
    "start": "3035000",
    "end": "3176000"
  },
  {
    "text": "that will appear? Intuitively, anyone want to\nexplain why you thought so? ",
    "start": "3036560",
    "end": "3044198"
  },
  {
    "text": "AUDIENCE: Poodles\nare really small. JOSH TENENBAUM: Poodles\nare small or weak. Yes. And German shepherds\nare big and strong.",
    "start": "3044198",
    "end": "3049296"
  },
  {
    "text": "And what about dobermans? AUDIENCE: They're just as\nbig as German shepherds. JOSH TENENBAUM: Yeah. That's right. So they're more similar\nto German shepherds,",
    "start": "3049296",
    "end": "3056291"
  },
  {
    "text": "because they're\nboth big and strong. But notice that something very\ndifferent is going on here.",
    "start": "3056291",
    "end": "3061327"
  },
  {
    "text": "It's not about similarity. It's sort of anti-similarity. But it's not just\nanti-similarity. Suppose I said, German\nshepherds can bite through wire,",
    "start": "3061327",
    "end": "3069160"
  },
  {
    "text": "therefore poodles can\nbite through wire. Is that a good argument? AUDIENCE: No. It's an argument against. JOSH TENENBAUM: No. It's sort of a terrible\nargument, right?",
    "start": "3069160",
    "end": "3075850"
  },
  {
    "text": "So there's some kind of\nasymmetric dimensional reasoning going on. Or similarly, if I said,\nwhich of these seems better",
    "start": "3075850",
    "end": "3083470"
  },
  {
    "text": "intuitively; Salmon\ncarry some bacteria, therefore grizzly bears\nare likely to carry it,",
    "start": "3083470",
    "end": "3089350"
  },
  {
    "text": "versus grizzly bears\ncarry this, therefore salmon are likely to carry it. How many people say salmon,\ntherefore grizzly bears?",
    "start": "3089350",
    "end": "3096279"
  },
  {
    "text": "How many people say grizzly\nbears, therefore salmon? How do you know? Those who-- yeah, you're right. I mean, you're right in\nthat's what people say.",
    "start": "3096280",
    "end": "3103128"
  },
  {
    "text": "I don't know if it's right. Again, I made it up. But why did you say that,\nthose of you who said salmon? AUDIENCE: Bears eat salmon.",
    "start": "3103128",
    "end": "3108430"
  },
  {
    "text": "JOSH TENENBAUM:\nBears eat salmon. Yeah. So assuming that's true,\nso we're told or see on TV, then yeah. So anyway, these are\nthese different kinds",
    "start": "3108430",
    "end": "3115199"
  },
  {
    "text": "of things that are going on. And to cut to the\nchase, what we showed is that you could capture these\ndifferent patterns of reasoning",
    "start": "3115199",
    "end": "3121360"
  },
  {
    "text": "with, again, the same kind\nof thing, but different. It's also a hierarchical\ngenerative model.",
    "start": "3121360",
    "end": "3128230"
  },
  {
    "text": "It also has, the key\nlevel of the hierarchy is some kind of directed\ngraphical structure",
    "start": "3128230",
    "end": "3133630"
  },
  {
    "text": "that generates distribution\non observable properties. But it's a fundamentally\ndifferent kind of structure. It's not just a tree or a space.",
    "start": "3133630",
    "end": "3140680"
  },
  {
    "text": "It might be a\ndifferent kind of graph and a different kind of process. So to be a little bit\nmore technical, the things",
    "start": "3140680",
    "end": "3146740"
  },
  {
    "text": "I showed you with the tree\nand the low-dimensional space, they had a different\ngeometry to the graph, but the same stochastic\nprocess operating over it.",
    "start": "3146740",
    "end": "3154090"
  },
  {
    "text": "It was, in both cases,\nbasically a diffusion process. Whereas to get the kinds of\nreasoning that you saw here,",
    "start": "3154090",
    "end": "3159292"
  },
  {
    "text": "you need a different\nkind of graph. In one case it's like a chain to\ncapture a dimension of strength or size, say.",
    "start": "3159292",
    "end": "3165230"
  },
  {
    "text": "In the other case, it's\nsome kind of food web thing. It's not a tree. It's that kind of\ndirected network.",
    "start": "3165230",
    "end": "3170859"
  },
  {
    "text": "But you also need a\ndifferent process. So the ways-- the kind\nof probability model to find that out is different. And it's easy to see on the--",
    "start": "3170860",
    "end": "3177460"
  },
  {
    "text": "for example-- on the reasoning\nwith these threshold things, like the strength\nproperties, if you",
    "start": "3177460",
    "end": "3182710"
  },
  {
    "text": "compare a 1D chain with\njust symmetric diffusion,",
    "start": "3182710",
    "end": "3187869"
  },
  {
    "text": "you get a much\nworse fit people's judgments than if you'd used\nwhat we called this drift threshold thing, which is\nbasically a way of saying,",
    "start": "3187870",
    "end": "3193576"
  },
  {
    "text": "OK, I don't know. There's some mapping\nfrom strength to being able to bite through wire. I don't know exactly what it is.",
    "start": "3193576",
    "end": "3199820"
  },
  {
    "text": "But the higher up\nyou go on one, it's probably more likely\nthat you can bite-- that you can do the other. So that provides a wonderful\nmodel of people's judgments",
    "start": "3199820",
    "end": "3206830"
  },
  {
    "text": "on these kind of tasks. But that sort of\ndiffusion process, like if it was like mutation\nin biology, then that",
    "start": "3206830",
    "end": "3214510"
  },
  {
    "text": "would provide a very bad model. That's the second row here. Similarly, this sort of directed\nkind of noisy transmission",
    "start": "3214510",
    "end": "3221830"
  },
  {
    "text": "process on a food web does a\ngreat way of modeling people's",
    "start": "3221830",
    "end": "3226890"
  },
  {
    "text": "judgments about\ndiseases, but not a very good way of\nmodeling people's judgments about these\nbiological properties.",
    "start": "3226890",
    "end": "3233230"
  },
  {
    "text": "But the tree models\nyou saw before that do a great job of\nmodeling people's judgments about the\nproperties of animals,",
    "start": "3233230",
    "end": "3238520"
  },
  {
    "text": "they do a lousy job of modeling\nthese disease judgments. So we have this picture\nemerging that, at the time,",
    "start": "3238520",
    "end": "3244059"
  },
  {
    "text": "was very satisfying to us. That, hey, we can take\nthis domain of, say, animals and their properties,\nor the various things we",
    "start": "3244060",
    "end": "3250869"
  },
  {
    "text": "can reason about, and there's\na lot of different ways we can reason about\njust this one domain.",
    "start": "3250870",
    "end": "3255940"
  },
  {
    "text": "And by building these\nstructured probabilistic models with different kinds\nof graphs structures that capture different\nkinds of causal processes,",
    "start": "3255940",
    "end": "3262990"
  },
  {
    "text": "we could really describe\na lot of different kinds of reasoning. And we saw this\nas part of a theme",
    "start": "3262990",
    "end": "3269248"
  },
  {
    "text": "that a lot of other\npeople were working on. So this is-- I\nmentioned this before, but now I'm just sort of\nthrowing it all out there.",
    "start": "3269249",
    "end": "3275440"
  },
  {
    "text": "A lot of people at\nthe time-- again, this is maybe somewhere\nbetween 5 to 10 years ago--",
    "start": "3275440",
    "end": "3280690"
  },
  {
    "text": "more like six or\nseven years ago-- we're extremely interested\nin this general view",
    "start": "3280690",
    "end": "3286930"
  },
  {
    "text": "of common sense reasoning\nand semantic cognition by basically taking big\nmatrices and boiling them down to some kind\nof graph structure.",
    "start": "3286930",
    "end": "3293140"
  },
  {
    "text": "In some form, that's what\nTom Mitchell was doing, not just in the talk\nyou saw, but remember, he said there's this\nother stuff he does--",
    "start": "3293140",
    "end": "3299380"
  },
  {
    "text": "this thing called NELL, the\nNever Ending Language Learner. I'm showing a little\nglimpse of that up there from a New York Times\npiece on it in the upper right.",
    "start": "3299380",
    "end": "3306730"
  },
  {
    "text": "In some ways, in a sort of\nat least more implicit way, it's what the neural networks\nthat Jay McClelland, Tim Rogers, Surya were\ntalking about do.",
    "start": "3306730",
    "end": "3314156"
  },
  {
    "text": "And we thought-- you\nknow, we had good reason to think that our\napproach was more like what people were doing\nthan some of these others.",
    "start": "3314156",
    "end": "3320630"
  },
  {
    "text": "But I then came to see-- and\nthis was around the time when CBMM was actually\ngetting started-- that none of these\nwere going to work.",
    "start": "3320630",
    "end": "3326950"
  },
  {
    "text": "Like the whole thing was\njust not going to work. Liz was one of the main people\nwho convinced me of this.",
    "start": "3326950",
    "end": "3332369"
  },
  {
    "text": "But you could just\nread the New York Times article on Tom Mitchell's piece,\nand you can see what's missing. So there's Tom, remember.",
    "start": "3332370",
    "end": "3340750"
  },
  {
    "text": "This was an article from 2010. Just to set the chronology\nright, that was right around--",
    "start": "3340750",
    "end": "3346070"
  },
  {
    "text": "a little bit after Charles had\nfinished all that nice work I showed you, which again,\nI still think is valuable.",
    "start": "3346070",
    "end": "3351440"
  },
  {
    "text": "I think it is\ncapturing something about what's going on. It was very appealing to\npeople, like at Google,",
    "start": "3351440",
    "end": "3357519"
  },
  {
    "text": "because these knowledge graphs\nare very much like the way, around the same time,\nGoogle was starting to try to put more\nsemantics into web search--",
    "start": "3357520",
    "end": "3364690"
  },
  {
    "text": "again, connected to the\nwork that Tom was doing. And there was this nice\narticle in the New York",
    "start": "3364690",
    "end": "3369820"
  },
  {
    "text": "Times talking about how they\nbuilt their system by reading the web. But the best part\nof it was describing",
    "start": "3369820",
    "end": "3375387"
  },
  {
    "text": "one of the mistakes\ntheir system made. So let me just show this to you. About knowledge that's\nobvious to a person,",
    "start": "3375387",
    "end": "3380740"
  },
  {
    "text": "but not to a\ncomputer-- again, it's Tom Mitchell himself\ndescribing this. And the challenge of, that's\nwhere NELL has to be headed,",
    "start": "3380740",
    "end": "3387940"
  },
  {
    "text": "is how to make the things\nthat are obvious to people obvious to computers.",
    "start": "3387940",
    "end": "3393160"
  },
  {
    "text": "He gives this\nexample of a bug that happened in NELL's early life.",
    "start": "3393160",
    "end": "3398560"
  },
  {
    "text": "The research team noticed that-- oh, let's skip down there. So, a particular example--",
    "start": "3398560",
    "end": "3404330"
  },
  {
    "text": "when Dr. Mitchell scanned the\nbaked goods category recently, he noticed a clear pattern.",
    "start": "3404330",
    "end": "3410049"
  },
  {
    "text": "NELL was at first\nquite accurate, easily identifying all kinds of pies,\nbreads, cakes, and cookies as baked goods.",
    "start": "3410050",
    "end": "3415569"
  },
  {
    "text": "But things went awry after\nNELL's noun phrase classifier decided internet cookies\nwas a baked good. ",
    "start": "3415570",
    "end": "3423100"
  },
  {
    "text": "NELL had read the sentence \"I\ndeleted my internet cookies.\" And again, think of\nthat as, it's kind of like a simple proposition.",
    "start": "3423100",
    "end": "3429339"
  },
  {
    "text": "It's like, OK. But the way it parses\nthat is cookies are things that can be\ndeleted, the same way you can",
    "start": "3429340",
    "end": "3434350"
  },
  {
    "text": "say horses have T9 hormones. It's basically just a matrix. And the concept is\ninternet cookies.",
    "start": "3434350",
    "end": "3441220"
  },
  {
    "text": "And then there's the\nproperty of can be deleted, or something like that. And it knows something about\nnatural language processing.",
    "start": "3441220",
    "end": "3447920"
  },
  {
    "text": "So it can see-- and it's trying\nto be intelligent. Oh, internet cookies. Well, maybe like chocolate\nchip cookies and oatmeal raisin",
    "start": "3447920",
    "end": "3453160"
  },
  {
    "text": "cookies, those were\na kind of cookies. Basically, that's what it did. Or no, actually\ndid the opposite. [LAUGHS]",
    "start": "3453160",
    "end": "3459339"
  },
  {
    "text": "It said-- when it read\n\"I deleted my files,\" it decided files was\nprobably a baked good, too.",
    "start": "3459340",
    "end": "3464740"
  },
  {
    "text": "Well, first it decided internet\ncookies was a baked good, like those other cookies. And then it decided that\nfiles were a baked goods. And it started this whole\navalanche of mistakes,",
    "start": "3464740",
    "end": "3471450"
  },
  {
    "text": "Dr. Mitchell said. He corrected the\ninternet cookies error and restarted NELL's\nbakery education.",
    "start": "3471450",
    "end": "3476827"
  },
  {
    "text": "[LAUGHS] I mean, like, OK. Now rerun without that problem.",
    "start": "3476827",
    "end": "3482079"
  },
  {
    "text": "So the point, the lesson\nTom draws from this, and that the\narticle talks about, is, oh, well, we still\nneed some assistance.",
    "start": "3482080",
    "end": "3487630"
  },
  {
    "text": "We have to go back and,\nby hand, set these things. But the key thing\nis that, really-- I think the message\nthis is telling",
    "start": "3487630",
    "end": "3493360"
  },
  {
    "text": "us is no human child would\never make this mistake. Human children\nlearn in this way. They don't need this\nkind of assistance.",
    "start": "3493360",
    "end": "3499401"
  },
  {
    "text": "It's true that, as Tom\nsays, you and I don't learn in isolation either. So, all of the things\nwe've been talking about,",
    "start": "3499401",
    "end": "3504688"
  },
  {
    "text": "about learning from prior\nknowledge and so on, are true. But there's a basic kind\nof common sense thing",
    "start": "3504688",
    "end": "3510010"
  },
  {
    "text": "that this is missing,\nwhich is that at the time a child is learning\nanything about-- by the time a child is learning\nanything about computers,",
    "start": "3510010",
    "end": "3517600"
  },
  {
    "text": "and files, and so on, they\nunderstand well before that, like back in early infancy, from\nsay, work that Liz has done,",
    "start": "3517600",
    "end": "3523030"
  },
  {
    "text": "and many others, that cookies,\nin the sense of baked goods, are a physical object, a kind\nof food, a thing you eat.",
    "start": "3523030",
    "end": "3529960"
  },
  {
    "text": "Files, email-- not\na physical object. And there's all sorts\nof interesting stuff to understand about how kids\nlearn that a book can be both",
    "start": "3529960",
    "end": "3537640"
  },
  {
    "text": "a no-- a novel is both\na story and it's also a physical object, and\nso a lot of that stuff. But there's a basic\ncommon sense understanding",
    "start": "3537640",
    "end": "3545380"
  },
  {
    "text": "of the world as consisting\nof physical objects, and for example,\nagents and their goals. You heard a little bit\nabout this from us,",
    "start": "3545380",
    "end": "3551670"
  },
  {
    "text": "from me and Tomer,\non the first day. And that's where I\nwant to turn to next. And this is just one of many\nexamples that we realized,",
    "start": "3551670",
    "end": "3557810"
  },
  {
    "text": "as cool as this system is, as\ngreat as all this stuff is, just trying to approach semantic\nknowledge and common sense",
    "start": "3557810",
    "end": "3564670"
  },
  {
    "text": "reasoning as some kind\nof big matrix completion without a much more fundamental\ngrasp of the ways in which",
    "start": "3564670",
    "end": "3570580"
  },
  {
    "text": "the world is real\nto a human mind, well before they're learning\nanything about language or any of this\nhigher level stuff,",
    "start": "3570580",
    "end": "3576930"
  },
  {
    "text": "it was just not going\nto work, in the same way that I think if you want to\nbuild a system that learns",
    "start": "3576930",
    "end": "3582100"
  },
  {
    "text": "to play a video game,\neven remotely like the way a human does, there's a lot of more basic\nstuff you have to build on.",
    "start": "3582100",
    "end": "3587165"
  },
  {
    "text": "And it's the same basic\nstuff, I would argue. A cool thing about\nAtari video games is that, even though they\nwere very low resolution,",
    "start": "3587165",
    "end": "3594309"
  },
  {
    "text": "very low-bit color displays,\nwith very big pixels, what makes your ability to\nlearn that game work is",
    "start": "3594310",
    "end": "3601750"
  },
  {
    "text": "the same kind of thing that\nmakes the ability, even as a young child, to not\nmake this mistake.",
    "start": "3601750",
    "end": "3607030"
  },
  {
    "text": "And it's the kind of\nthing that Liz and people in her field of\ndevelopmental psychology-- in particular, infant research--\nhave been studying really",
    "start": "3607030",
    "end": "3614710"
  },
  {
    "text": "excitingly for a\ncouple of decades. That, I think, is as\ntransformative for the topic",
    "start": "3614710",
    "end": "3620144"
  },
  {
    "text": "of intelligence in brains,\nminds, and machines as anything. So that's what\nmotivated the work we've been doing in the last few\nyears and the main work we're",
    "start": "3620144",
    "end": "3627213"
  },
  {
    "text": "trying to do in the center. And it also goes hand-in-hand\nwith the ways in which we've realized that we have\nto take what we've learned how",
    "start": "3627213",
    "end": "3634810"
  },
  {
    "text": "to do with building problematic\nmodels over interesting symbolically-structured\nrepresentations and so on, but move way\nbeyond what you could call--",
    "start": "3634810",
    "end": "3642550"
  },
  {
    "text": "I mean, we need better,\neven more interesting, symbolic representations. In particular, we need\nto move beyond graphs",
    "start": "3642550",
    "end": "3648760"
  },
  {
    "text": "and stochastic processes\ndefined over graphs to programs. So that's where the\nprobabilistic programs",
    "start": "3648760",
    "end": "3654190"
  },
  {
    "text": "come back into the mix. So again, you already saw this. And I'm trying to\nclose the loop back to what we're doing in CBMM.",
    "start": "3654190",
    "end": "3659860"
  },
  {
    "text": "I've given you\nabout 10 to 15 years of background in our field\nof how we got to this, why we think this is\ninteresting and important,",
    "start": "3659860",
    "end": "3666460"
  },
  {
    "text": "and why we think we need to-- why we've developed a\ncertain toolkit of ideas, and why we think we needed\nto keep extending it.",
    "start": "3666460",
    "end": "3675099"
  },
  {
    "text": "And I think, as you saw\nbefore, and as you'll see, this also, in some ways-- I think we're getting more and\nmore to the interesting part",
    "start": "3675100",
    "end": "3681970"
  },
  {
    "text": "of common sense. But in another way, we're\ngetting back to the problems I started off with\nand what a lot of other people at\nthis summer school",
    "start": "3681970",
    "end": "3687880"
  },
  {
    "text": "have an interest\nin, which is things like much more basic aspects\nof visual perception. I think the heart of real\nintelligence and common sense",
    "start": "3687880",
    "end": "3695020"
  },
  {
    "text": "reasoning that\nwe're talking about is directly connected to vision\nand other sense modalities,",
    "start": "3695020",
    "end": "3700180"
  },
  {
    "text": "and how we get around in the\nworld and plan our actions, and the very basic\nkinds of goal social understandings that you\nsaw in those little videos",
    "start": "3700180",
    "end": "3707240"
  },
  {
    "text": "of the red and blue\nball, or that you see if you're trying to do\naction recognition and action understanding.",
    "start": "3707240",
    "end": "3712450"
  },
  {
    "text": "So in some sense, it's\ngotten more cognitive. But it's also, by getting to\nthe root of our common sense",
    "start": "3712450",
    "end": "3718080"
  },
  {
    "text": "knowledge, it makes better\ncontact with vision, with neuroscience research. And so I think it's a\nsuper exciting development",
    "start": "3718080",
    "end": "3725429"
  },
  {
    "text": "in what we're doing for\nthe larger Brains, Minds, and Machines agenda. So again, now we're\nsaying, OK, let's",
    "start": "3725429",
    "end": "3730770"
  },
  {
    "text": "try to understand\nthe way in which-- even these kids\nplaying with blocks,",
    "start": "3730770",
    "end": "3736530"
  },
  {
    "text": "the world is real to them. It's not just a\nbig matrix of data. That is a thing in their hands.",
    "start": "3736530",
    "end": "3742500"
  },
  {
    "text": "And they have an\nunderstanding of what a thing is before they start\ncompiling lists of properties.",
    "start": "3742500",
    "end": "3747540"
  },
  {
    "text": "And they're playing\nwith somebody else. That hand is attached to\na person, who has goals. It's not just a big matrix\nof rows and columns.",
    "start": "3747540",
    "end": "3755410"
  },
  {
    "text": "It's an agent with\ngoals, and even a mind. And they understand\nthose things before they",
    "start": "3755410",
    "end": "3761609"
  },
  {
    "text": "start to learn a lot of other\nthings, like words for objects, and advanced game-playing\nbehavior, and so on.",
    "start": "3761610",
    "end": "3769000"
  },
  {
    "text": "And when we want to\ntalk about learning, we still are interested\nin one-shot learning, or very rapid learning\nfrom a few examples.",
    "start": "3769000",
    "end": "3775440"
  },
  {
    "text": "And we're still interested\nin how prior knowledge guides that, and how that\nknowledge can be built.",
    "start": "3775440",
    "end": "3781390"
  },
  {
    "text": "But we want to do\nit in this context. We want to study in\nthe context of, say, how you learn how magnets\nwork, or how you learn how a touchscreen device\nworks-- really interesting kinds",
    "start": "3781390",
    "end": "3788760"
  },
  {
    "text": "of grounded physical causes. So this is what we\nhave, or what I've come",
    "start": "3788760",
    "end": "3795990"
  },
  {
    "text": "to call the common sense core. Liz, are you going to talk\nabout core knowledge at all?",
    "start": "3795990",
    "end": "3801180"
  },
  {
    "text": "so there's a phrase\nthat Liz likes to use called core knowledge. And this is definitely\nmeant to evoke that. And it's inspired by it.",
    "start": "3801180",
    "end": "3807780"
  },
  {
    "text": "I guess I changed\nit a little bit, because I wanted it\nto mean something a little bit different. And I think, again, to\nanticipate a little bit,",
    "start": "3807780",
    "end": "3814410"
  },
  {
    "text": "the main difference is-- I don't know. What's the main difference? The main difference is\nthat, in the same way",
    "start": "3814410",
    "end": "3820500"
  },
  {
    "text": "that lots of people look\nat me and say, oh, he's the Bayesian guy, lots\nof people look at Liz and say, oh, she's the\nnativist gal or something.",
    "start": "3820500",
    "end": "3827339"
  },
  {
    "text": "And it's true that, compared\nto a lot of other people, I tend to be more\ninterested, and have done more work\nprominently associated",
    "start": "3827340",
    "end": "3833070"
  },
  {
    "text": "with Bayesian inference. But by no means do I think\nthat's the whole story. And part of what I tried to show\nyou, and will keep showing you,",
    "start": "3833070",
    "end": "3838860"
  },
  {
    "text": "is ways in which\nthat's only really the beginning of the story. And Liz is prominently\nassociated, and you'll see some of this,\nwith really fascinating",
    "start": "3838860",
    "end": "3845849"
  },
  {
    "text": "discoveries that key high\nlevel concepts, key kinds of real knowledge, are\npresent, in some sense,",
    "start": "3845850",
    "end": "3853230"
  },
  {
    "text": "as early as you can look,\nand in some form, I think, very plausibly, have to be\ndue to some kind of innately",
    "start": "3853230",
    "end": "3860490"
  },
  {
    "text": "unfolding genetic program that\nbuilds a mind the same way it builds a brain. But just as we'll\nhear from her, that's, in some ways, only the\nbeginning, or only one part",
    "start": "3860490",
    "end": "3867223"
  },
  {
    "text": "of a much richer,\nmore interesting story that she's been developing. But for that, among\nother reasons,",
    "start": "3867223",
    "end": "3873274"
  },
  {
    "text": "I'm calling it a\nlittle different. And I'm trying to emphasize the\nconnection to what people in AI call common sense reasoning. Because I really do think this\nis the heart of common sense.",
    "start": "3873274",
    "end": "3881050"
  },
  {
    "text": "It's this intuitive physics\nand intuitive psychology. So again, you saw us already\ngive an intro to this.",
    "start": "3881050",
    "end": "3887609"
  },
  {
    "text": "Maybe what I'll just do is\nshow you a little bit more of the-- well, are you going\nto talk about the stuff at all?",
    "start": "3887610",
    "end": "3893692"
  },
  {
    "text": "LIZ SPELKE: I guess. Yeah. JOSH TENENBAUM: Well, OK. So this is work-- some of\nthis is based on Liz's work. Some of this is based\non Rene Baillargeon,",
    "start": "3893692",
    "end": "3900390"
  },
  {
    "text": "a close colleague of hers, and\nmany other people out there. And I wasn't really going\nto go into the details. And maybe, Liz, we can decide\nwhether you want to do this",
    "start": "3900390",
    "end": "3907230"
  },
  {
    "text": "or not. But what they've shown\nis that, even prior to the time when kids are\nlearning words for objects,",
    "start": "3907230",
    "end": "3914280"
  },
  {
    "text": "all of this stuff with infants,\ntwo months, four months, eight months-- at this age, kids have, at\nbest, some vague statistical",
    "start": "3914280",
    "end": "3923520"
  },
  {
    "text": "associations of words\nto kinds of objects. But they already\nhave a great deal",
    "start": "3923520",
    "end": "3928859"
  },
  {
    "text": "of much more abstract\nunderstanding of physical objects. So I won't-- maybe I should\nnot go into the details of it.",
    "start": "3928860",
    "end": "3936732"
  },
  {
    "text": "But you saw it in that nice\nvideo of the baby playing with the cups. ",
    "start": "3936732",
    "end": "3942015"
  },
  {
    "text": "And there's really\ninteresting, sort of rough, developmental\ntimelines. One of the things we're\ntrying to figure out in CBMM",
    "start": "3942015",
    "end": "3947946"
  },
  {
    "text": "is to actually get much,\nmuch clearer picture on this. But at least if you look across\na bunch of different studies,",
    "start": "3947946",
    "end": "3954120"
  },
  {
    "text": "sometimes by one lab,\nsometimes up by multiple labs, you see ways in which, say,\ngoing from two months to five",
    "start": "3954120",
    "end": "3960360"
  },
  {
    "text": "months, or five\nmonths to 12 months, kids seem to-- their\nintuitive physics of objects is getting a little\nbit more sophisticated.",
    "start": "3960360",
    "end": "3966210"
  },
  {
    "text": "So for example, they\ntend to understand--",
    "start": "3966210",
    "end": "3972180"
  },
  {
    "text": "in some form, they understand\na little bit of how collisions conserve momentum, a little bit,\nby five months or six months--",
    "start": "3972180",
    "end": "3979829"
  },
  {
    "text": "according to one of\nBaillargeon's studies-- in the sense that if they\nsee a ball roll down a ramp",
    "start": "3979830",
    "end": "3985230"
  },
  {
    "text": "and hit another one,\nand the second one goes a certain distance, if\na bigger object comes,",
    "start": "3985230",
    "end": "3991395"
  },
  {
    "text": "they're not too surprised\nif this one goes farther. But if a little object hits\nit, then they are surprised. So they expect a bigger\nobject to be able to move it",
    "start": "3991395",
    "end": "3997966"
  },
  {
    "text": "more than a little object. But a two-month-old\ndoesn't understand that. Although a two-month-old does\nunderstand-- this is, again,",
    "start": "3997966",
    "end": "4003890"
  },
  {
    "text": "from Liz's work-- that if an object is\ncolluded by a screen, it hasn't disappeared,\nand that if an object",
    "start": "4003890",
    "end": "4010010"
  },
  {
    "text": "is rolling towards a wall,\nand that wall looks solid, that the object can't go through\nit, and that if it somehow--",
    "start": "4010010",
    "end": "4016174"
  },
  {
    "text": "when the screen is removed,\nas you see on the upper left-- appears on the other side\nof the screen, that's very surprising to them.",
    "start": "4016174",
    "end": "4021954"
  },
  {
    "text": "I think-- I'm sure what Liz will\ntalk about, among other things, are the methods they use, the\nlooking time methods to reveal",
    "start": "4021954",
    "end": "4027710"
  },
  {
    "text": "this. And I think there's really-- this is one of the two\nmain insights that I,",
    "start": "4027710",
    "end": "4034200"
  },
  {
    "text": "and I think our\nwhole field, needs to learn from\ndevelopmental psychology, is how much of a basic\nunderstanding of physics",
    "start": "4034200",
    "end": "4040730"
  },
  {
    "text": "like this is present very early. And it doesn't\nmatter whether it's-- in some sense, it doesn't\nmatter for the points",
    "start": "4040730",
    "end": "4048140"
  },
  {
    "text": "I want to make here, how much\nor in what way this is innate, or how the genetics and\nthe experience interact.",
    "start": "4048140",
    "end": "4054719"
  },
  {
    "text": "I mean, that does matter. And that, that's something\nwe want to understand, and we are hoping\nto try to understand in the hopefully\nnot-too-distant future.",
    "start": "4054719",
    "end": "4061829"
  },
  {
    "text": "But for the purpose\nof understanding what is the heart\nof common sense, how are we going to build\nthese causal, compositional,",
    "start": "4061830",
    "end": "4067070"
  },
  {
    "text": "generative models to\nreally get at intelligence, the main thing is that it should\nbe about this kind of stuff. That's the main focus.",
    "start": "4067070",
    "end": "4072800"
  },
  {
    "text": "And then the other big insight\nfrom developmental psychology, which has to do with\nhow we build this stuff,",
    "start": "4072800",
    "end": "4078260"
  },
  {
    "text": "is this idea sometimes called\nthe child as scientist. The basic idea is that, just\nas this early commonsense",
    "start": "4078260",
    "end": "4084950"
  },
  {
    "text": "knowledge is something\nlike a scientific theory, something like a good scientific\ntheory, the way Newton's laws are a better scientific\ntheory than Kepler's laws",
    "start": "4084950",
    "end": "4092330"
  },
  {
    "text": "because of how they capture the\ncausal structure of the world in a compositional way. That's another\nway to sum up what",
    "start": "4092330",
    "end": "4097339"
  },
  {
    "text": "I'm trying to say about\nchildren's early knowledge. But also, the way children build\ntheir knowledge is something",
    "start": "4097340",
    "end": "4103520"
  },
  {
    "text": "like the way scientists\nbuild their knowledge, which is, well, they do\nexperiments, of course.",
    "start": "4103520",
    "end": "4110700"
  },
  {
    "text": "We normally call that play. That's one of Laura's\nSchulz's big ideas. But it's not just\nabout the experiments.",
    "start": "4110700",
    "end": "4116140"
  },
  {
    "text": "I mean, Newton didn't\nreally do any experiments. He just thought. And that's another thing you'll\nhear from Laura, and also",
    "start": "4116140",
    "end": "4121451"
  },
  {
    "text": "from Tomer, is that a lot\nof children's learning looks less like, say, stochastic\ngradient descent, and more",
    "start": "4121451",
    "end": "4126810"
  },
  {
    "text": "like scratching your head\nand trying to make sense of, well, that's really funny. Why does this happen here?",
    "start": "4126810",
    "end": "4132420"
  },
  {
    "text": "Why does that happen over there? Or how can I explain\nwhat seemed to be diverse patterns of phenomena\nwith some common underlying",
    "start": "4132420",
    "end": "4140790"
  },
  {
    "text": "principles, and making\nanalogies between things, and then trying out, oh,\nwell, if that's right, then it would make\nthis prediction.",
    "start": "4140790",
    "end": "4146020"
  },
  {
    "text": "And the kid doesn't have to\nbe conscious of that the way scientists maybe are. That process of coming\nup with theories",
    "start": "4146020",
    "end": "4153990"
  },
  {
    "text": "and considering variations,\ntrying them out, seeing what kinds of new\nexperiences you can create",
    "start": "4153990",
    "end": "4159449"
  },
  {
    "text": "for yourself-- call them an\nexperiment, or call them just a game, or\nplaying with a toy, but that dynamic is the real\nheart of how children learn",
    "start": "4159450",
    "end": "4168210"
  },
  {
    "text": "and build the knowledge\nfrom the early stages to what we come\nto have as adults.",
    "start": "4168210",
    "end": "4173939"
  },
  {
    "text": "Those two insights of what we\nstart with and how we grow, I think, are hugely powerful\nand hugely important",
    "start": "4173939",
    "end": "4179790"
  },
  {
    "text": "for anything we want to do in\ncapturing-- making machines that learn like\nhumans, or making computational models that\nreally get at the heart of how",
    "start": "4179790",
    "end": "4186111"
  },
  {
    "text": "we come to be smart. ",
    "start": "4186112",
    "end": "4211959"
  }
]
[
  {
    "text": "SPEAKER: The following content\nis provided under a Creative Commons license. Your support will help MIT\nOpeCourseWare continue to",
    "start": "0",
    "end": "6600"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or to view\nadditional material from",
    "start": "6600",
    "end": "12815"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "12815",
    "end": "18110"
  },
  {
    "text": " PROFESSOR: OK, we talked about\nthis a little bit last time.",
    "start": "18110",
    "end": "26730"
  },
  {
    "text": "We were talking about the\ndetection of vectors in white Gaussian noise.",
    "start": "26730",
    "end": "33210"
  },
  {
    "text": "When we talk about vectors we'll\noften refer to white Gaussian noise as noise where\neach component of the vector",
    "start": "33210",
    "end": "41309"
  },
  {
    "text": "is independent of each\nother when they're all the same variance.",
    "start": "41310",
    "end": "47140"
  },
  {
    "text": "Usually we take the variance\nto be n0 over 2, capital N0 over 2.",
    "start": "47140",
    "end": "54030"
  },
  {
    "text": "And we'll say more about that as\nwe go on, but that's just--",
    "start": "54030",
    "end": "59530"
  },
  {
    "text": "I guess one thing I ought\nto say about it now-- people keep wondering why we\ncall this N0 over 2 instead of",
    "start": "59530",
    "end": "66979"
  },
  {
    "text": "something else. As I said before, there's\nreally no reason for it except custom.",
    "start": "66980",
    "end": "72860"
  },
  {
    "text": "The one important thing that\nyou can always remember and which is always true is that any\ntime you're talking about",
    "start": "72860",
    "end": "82380"
  },
  {
    "text": "a sequence of real noise\nvariables they all have",
    "start": "82380",
    "end": "88649"
  },
  {
    "text": "variants N0 over 2, and the same\ncoordinate system that",
    "start": "88650",
    "end": "94320"
  },
  {
    "text": "you're using to measure\nthe signals. OK, the only thing that ever\nappears in any of these",
    "start": "94320",
    "end": "99650"
  },
  {
    "text": "formulas is a ratio of signal\npower or signal energy to",
    "start": "99650",
    "end": "106880"
  },
  {
    "text": "noise signal power. And if we're up it passband,\nwe're dealing with the power,",
    "start": "106880",
    "end": "118530"
  },
  {
    "text": "which is two times larger\nthan that at baseband. And because of that-- and\nthis is what really gets",
    "start": "118530",
    "end": "125220"
  },
  {
    "text": "confusing-- is that when you\ntalk about N0 over 2 at passband, you are talking about\nsomething which is twice",
    "start": "125220",
    "end": "133069"
  },
  {
    "text": "as big as the N0 over 2, the\nsame N0 over 2 you were talking about at baseband.",
    "start": "133070",
    "end": "139320"
  },
  {
    "text": "And the reason is since the\nsignal is twice as big there,",
    "start": "139320",
    "end": "144380"
  },
  {
    "text": "the noise is also said\nto be twice as big. I can't do anything\nabout that.",
    "start": "144380",
    "end": "149709"
  },
  {
    "text": "It's just the way that everybody\ndoes things. The other thing that everybody\ndoes-- since everyone gets",
    "start": "149710",
    "end": "154730"
  },
  {
    "text": "confused about that-- is after they get all done\ndealing with anything in a",
    "start": "154730",
    "end": "160230"
  },
  {
    "text": "paper they're writing or\nsomething, they always look at the signal to noise ratio that\nthey have and they remove all",
    "start": "160230",
    "end": "166110"
  },
  {
    "text": "the factors of two that they\nknow shouldn't be there. So that you shouldn't trust\nanything in the literature too",
    "start": "166110",
    "end": "173190"
  },
  {
    "text": "much as far as factors\nof two are concerned. And I try to be careful in the\nnotes about that, but you",
    "start": "173190",
    "end": "179629"
  },
  {
    "text": "shouldn't trust the notes too\nfar along those lines, either. So well eventually I'll get the\nnotes straightened out on",
    "start": "179630",
    "end": "188440"
  },
  {
    "text": "all of that but I think they're\npretty close now. But anyway, we were looking at\nthis question of how do you",
    "start": "188440",
    "end": "196239"
  },
  {
    "text": "detect antipodal vectors in\nwhite Gaussian noise?",
    "start": "196240",
    "end": "201980"
  },
  {
    "text": "And the picture that we\ncan draw is this.",
    "start": "201980",
    "end": "207150"
  },
  {
    "text": "Namely we have two signals. One is the vector, a, one\nis the vector, minus a.",
    "start": "207150",
    "end": "217830"
  },
  {
    "text": "It's in some finite dimensional\nsystem, but we're viewing it as far as drawing\na picture as a",
    "start": "217830",
    "end": "225310"
  },
  {
    "text": "two dimensional system. So a has some arbitrary\ncomponent in the first direction.",
    "start": "225310",
    "end": "231440"
  },
  {
    "text": "Some arbitrary component in\nthe second direction. Minus a is, of course,\nthe reverse of that.",
    "start": "231440",
    "end": "237650"
  },
  {
    "text": "This point right in here is\nthe zero point, which is halfway in between them. ",
    "start": "237650",
    "end": "246290"
  },
  {
    "text": "And the output that we observe\nis either plus or minus a, plus this independent zero mean\nnoise, Z, which has the",
    "start": "246290",
    "end": "256260"
  },
  {
    "text": "kind of circular symmetry\nindicated here with these little circles.",
    "start": "256260",
    "end": "262160"
  },
  {
    "text": "Each of the Z sub i have the\nsame variance, they're independent of each other.",
    "start": "262160",
    "end": "267740"
  },
  {
    "text": "And when you write down the\nlikelihood of the probability density of this output, given\nthat the hypothesis was zero.",
    "start": "267740",
    "end": "277110"
  },
  {
    "text": "Namely that plus a was the\nsignal which was chosen. OK, remember in all of these\nthings there's this process",
    "start": "277110",
    "end": "284289"
  },
  {
    "text": "now going on that we usually\ndon't talk about anymore. But there's an input coming into\nthe communication channel",
    "start": "284290",
    "end": "291730"
  },
  {
    "text": "which we're now calling\ncapital H. It's the hypothesis-- which is the thing\nyou're trying to detect when you're all done--",
    "start": "291730",
    "end": "297970"
  },
  {
    "text": "that input which is one up to\ncapital N, or sometimes zero",
    "start": "297970",
    "end": "303110"
  },
  {
    "text": "up to capital N minus 1. Is then mapped into a signal\nfrom a single set of capital N",
    "start": "303110",
    "end": "310720"
  },
  {
    "text": "different signals. So they're impossible signals\nin this signal alphabet. You map the hypothesis\ninto one of those.",
    "start": "310720",
    "end": "320600"
  },
  {
    "text": "From those, you generally\nform a waveform. This waveform might be\nmodulated up to high",
    "start": "320600",
    "end": "326740"
  },
  {
    "text": "frequency, back to low\nfrequency again. Detected or whatever.",
    "start": "326740",
    "end": "332050"
  },
  {
    "text": "You got some vector,\nv, at that point. Which is a sequence of samples\nthat you're going to be taking",
    "start": "332050",
    "end": "342570"
  },
  {
    "text": "as far as most cases\nare concerned. We'll talk more about\nthat later today. But anyway, v is a vector which\nis plus or minus a at",
    "start": "342570",
    "end": "349980"
  },
  {
    "text": "this point, plus this\nGaussian noise. We can write down the\nprobability density of that",
    "start": "349980",
    "end": "355110"
  },
  {
    "text": "vector, v, which is if\nhypothesis zero occurs.",
    "start": "355110",
    "end": "361159"
  },
  {
    "text": "Namely if a zero enters the\ncommunication channel, plus a is the signal which is chosen.",
    "start": "361160",
    "end": "366860"
  },
  {
    "text": "Then what happens is that the\noutput is a plus Z. Which",
    "start": "366860",
    "end": "373090"
  },
  {
    "text": "means that the probability\ndensity of the noise is v minus a.",
    "start": "373090",
    "end": "379800"
  },
  {
    "text": "So we have this probability\ndensity here. When we look at the log\nlikelihood ratio, we're taking",
    "start": "379800",
    "end": "387110"
  },
  {
    "text": "the logarithm of this\nprobability density divided by the probability density of the\nalternative hypothesis.",
    "start": "387110",
    "end": "395180"
  },
  {
    "text": "Namely v given one. Which is the same as this\nformula except there's the",
    "start": "395180",
    "end": "400230"
  },
  {
    "text": "plus a there instead\nof a minus a. So you get this thing here.",
    "start": "400230",
    "end": "405400"
  },
  {
    "text": "Now, why I wanted to talk about\nthis today is we're going to talk about the\ncomplex case also and",
    "start": "405400",
    "end": "410419"
  },
  {
    "text": "something very, very peculiar\nand funny happens there. OK so the log likelihood ratio\nis the scaled difference of",
    "start": "410420",
    "end": "419460"
  },
  {
    "text": "the energy of the distance\nbetween v and a.",
    "start": "419460",
    "end": "425120"
  },
  {
    "text": "Which is this term here. This is just a squared distance\nbetween the vector, v, and the vector, a.",
    "start": "425120",
    "end": "431970"
  },
  {
    "text": "It's v minus a is that distance\nthere, squared. And the other term here is the\nterm that comes from the",
    "start": "431970",
    "end": "440169"
  },
  {
    "text": "probability density\nof v given one. Which turns out to be that\ndistance there squared.",
    "start": "440170",
    "end": "447330"
  },
  {
    "text": "So you have the difference\nbetween these two things. This is just the inner product\nof v minus a with v minus a.",
    "start": "447330",
    "end": "455930"
  },
  {
    "text": "And if you multiply that all out\nit's the inner product v with itself, plus the inner\nproduct of a with itself,",
    "start": "455930",
    "end": "464740"
  },
  {
    "text": "minus the inner product of v and\na, minus the inner product",
    "start": "464740",
    "end": "470660"
  },
  {
    "text": "of a with v. The only things that don't\ncancel out between these two",
    "start": "470660",
    "end": "475759"
  },
  {
    "text": "things is the inner product of v\nwith a, the inner product of a with v, the inner product of v\nwith a, the inner product of",
    "start": "475760",
    "end": "482650"
  },
  {
    "text": "a with v. So those things last\nbecause there's a minus sign here and a plus sign here.",
    "start": "482650",
    "end": "489270"
  },
  {
    "text": "There's a minus sign here\nand a plus sign here. So the plus and minus signs\ncancel out, so you just get",
    "start": "489270",
    "end": "495280"
  },
  {
    "text": "four of these terms here, which\nis four times the inner product over n0. What happens to that\ngeometrically?",
    "start": "495280",
    "end": "502960"
  },
  {
    "text": "What is the inner product\nof v and a? Well it's the projection\nof v on the vector a.",
    "start": "502960",
    "end": "512209"
  },
  {
    "text": "Which happens to be the line\nbetween minus a and plus a. Mainly the fact that it's the\nline between minus a and plus",
    "start": "512210",
    "end": "519890"
  },
  {
    "text": "a is the thing which is valuable\nwhether you're dealing with antipodal\ncommunication or any other",
    "start": "519890",
    "end": "525010"
  },
  {
    "text": "kind of communication. You're always looking at this\nline between two points. So what this thing says is you\nform the inner product, which",
    "start": "525010",
    "end": "533940"
  },
  {
    "text": "says drop a perpendicular from\nZ down to here, and in terms",
    "start": "533940",
    "end": "538950"
  },
  {
    "text": "of where that perpendicular\nlands here, you make your decision.",
    "start": "538950",
    "end": "544890"
  },
  {
    "text": "Namely you compare that\nwith the threshold. OK? So we have two different\nways of doing this.",
    "start": "544890",
    "end": "550160"
  },
  {
    "text": "One of them is compare this\ndistance with this distance. Or actually here you compare the\nsquare distance here with",
    "start": "550160",
    "end": "557640"
  },
  {
    "text": "the square distance there. Which says, if you're using\nmaximum likelihood then the",
    "start": "557640",
    "end": "563380"
  },
  {
    "text": "threshold that you're dealing\nwith here is zero and you simply make your decision on\nwhether the log likelihood",
    "start": "563380",
    "end": "569050"
  },
  {
    "text": "ratio is positive or minus. Which means in terms of the\nprojection theorem here, what",
    "start": "569050",
    "end": "577530"
  },
  {
    "text": "you're doing is taking a\nperpendicular bisector of the line between minus a and plus\na, and putting a plane there",
    "start": "577530",
    "end": "585770"
  },
  {
    "text": "and that's the plane that\nseparates what goes into one",
    "start": "585770",
    "end": "591490"
  },
  {
    "text": "and what goes into zero. This goes into zero. This goes into one.",
    "start": "591490",
    "end": "596589"
  },
  {
    "text": "OK, so is it clear to all of you\nthat this is really saying the same thing as this?",
    "start": "596590",
    "end": "602100"
  },
  {
    "text": "This inner product just\ncomes from here. You can either look at this as\nminimum distance decoding.",
    "start": "602100",
    "end": "608310"
  },
  {
    "text": "You just find the\npoint which is closest to what you receive.",
    "start": "608310",
    "end": "613400"
  },
  {
    "text": " You find the hypothesized\nsignal, which is closest to",
    "start": "613400",
    "end": "619755"
  },
  {
    "text": "the actual observation\nthat you make. You make your decision\nin terms of that. Or you do this projection\nand make your",
    "start": "619755",
    "end": "627690"
  },
  {
    "text": "decision in terms of that. And if you use a triangle thing\nwhich says that this",
    "start": "627690",
    "end": "636570"
  },
  {
    "text": "squared distance plus this\nsquared distance is equal to that squared distance. We all remember that from third\ngrade or something.",
    "start": "636570",
    "end": "644090"
  },
  {
    "text": "I don't know when. But that simply says the same\nthing that this says.",
    "start": "644090",
    "end": "650380"
  },
  {
    "text": "This just says it\nmore generally. In terms of an arbitrary finite\nconventional vector,",
    "start": "650380",
    "end": "658690"
  },
  {
    "text": "rather than just the case of\nwhere you're looking at two",
    "start": "658690",
    "end": "665450"
  },
  {
    "text": "dimensions. OK that's-- we will probably come back to\nlook at that in a little bit,",
    "start": "665450",
    "end": "673670"
  },
  {
    "text": "but now I want to look at\ncomplex antipodal vectors in white Gaussian noise.",
    "start": "673670",
    "end": "679740"
  },
  {
    "text": "So the set up there is that\nthe input is some vector.",
    "start": "679740",
    "end": "685779"
  },
  {
    "text": "I usually use u's to mean\ncomplex numbers. So the vector there is u1 up to\nu sub j where u sub j is a",
    "start": "685780",
    "end": "695420"
  },
  {
    "text": "complex number. So we're dealing with complex\nvectors at this point. So we have two points, minus\na -- minus u and plus u.",
    "start": "695420",
    "end": "705750"
  },
  {
    "text": "Where instead of being\na real vector they're complex vectors.",
    "start": "705750",
    "end": "711060"
  },
  {
    "text": "And if you can't visualize\nthings geometrically, in terms of complex vectors,\njoin the crew.",
    "start": "711060",
    "end": "718160"
  },
  {
    "text": "I can't either. The only thing I can never do\nis talk about real vectors,",
    "start": "718160",
    "end": "724330"
  },
  {
    "text": "try to get some idea of what's\ngoing on from that, and use mathematics for the\ncomplex vectors.",
    "start": "724330",
    "end": "730279"
  },
  {
    "text": "Because the reason we use\ncomplex vectors is that, analytically they're just as\nsimple as real vectors.",
    "start": "730280",
    "end": "736570"
  },
  {
    "text": "The reason we use real vectors\nis because we can draw pictures of them. I defy anybody to draw a picture\nin four dimensions.",
    "start": "736570",
    "end": "744230"
  },
  {
    "text": "Some books will do it, but\nI can't understand them. And anyway.",
    "start": "744230",
    "end": "750140"
  },
  {
    "text": "OK, so under hypothesis zero\nwhat gets sent as u?",
    "start": "750140",
    "end": "756040"
  },
  {
    "text": "And under hypothesis one, what\ngets sent as minus u? So we're still talking about\nbinary communication and if",
    "start": "756040",
    "end": "766080"
  },
  {
    "text": "you're talking about antipodal\nvectors, you can't do much other than talk about binary\ncommunication.",
    "start": "766080",
    "end": "772750"
  },
  {
    "text": "Because if you're sending a, the\nonly vector antipodal to a is minus a. And then you're stuck\nand you're done.",
    "start": "772750",
    "end": "779780"
  },
  {
    "text": "So we're still talking\nabout binary vectors. Remember the reason why\nwe're doing this--",
    "start": "779780",
    "end": "787280"
  },
  {
    "text": "because one of the things we\ndid last time, one of the things that's in the notes and\nstressed again and again is",
    "start": "787280",
    "end": "793170"
  },
  {
    "text": "that once you understand the\nantipodal case, you can translate those two points\nanywhere you want to and the",
    "start": "793170",
    "end": "802220"
  },
  {
    "text": "maximum likelihood decision and\nthe MAP decision are still",
    "start": "802220",
    "end": "808470"
  },
  {
    "text": "the same thing. You take those two points and\nyou just translate them in",
    "start": "808470",
    "end": "813960"
  },
  {
    "text": "space until the mean between\nthem sits on the zero point.",
    "start": "813960",
    "end": "819170"
  },
  {
    "text": "And then you're back to the\nantipodal case again. OK, so the reason why we're\ndoing this is really so we can",
    "start": "819170",
    "end": "829170"
  },
  {
    "text": "look at the more general case. But we don't have to have\nthat mean sitting around all the time.",
    "start": "829170",
    "end": "834630"
  },
  {
    "text": "OK, Z then is going to be a\nvector of j complex IID Gaussian random variables.",
    "start": "834630",
    "end": "840990"
  },
  {
    "text": "IID real and imaginary parts. Namely the real part of each\nGaussian, complex Gaussian",
    "start": "840990",
    "end": "848610"
  },
  {
    "text": "random variable has variance\nn0 over 2 and the imaginary",
    "start": "848610",
    "end": "854510"
  },
  {
    "text": "part also has variance\nn0 over 2. These complex vectors, if you\nlook at the probability",
    "start": "854510",
    "end": "861650"
  },
  {
    "text": "density for them and you draw it\nin two dimensions, one for the real part one for the\nimaginary part, you get this",
    "start": "861650",
    "end": "872709"
  },
  {
    "text": "circular symmetry that we've\nalways associated. Those are supposed to be circles\nand not ellipses.",
    "start": "872710",
    "end": "879230"
  },
  {
    "text": " And those are sometimes\ncalled proper complex",
    "start": "879230",
    "end": "884910"
  },
  {
    "text": "Gaussian random variables. Because almost everywhere where\nyou see complex Gaussian",
    "start": "884910",
    "end": "891260"
  },
  {
    "text": "random variables, the real\nand imaginary parts are independent of each other and\nboth have the same variance.",
    "start": "891260",
    "end": "898190"
  },
  {
    "text": " Again, when you look at formulas\nin papers, formulas",
    "start": "898190",
    "end": "904610"
  },
  {
    "text": "everywhere else, they are almost\nalways assuming this",
    "start": "904610",
    "end": "909870"
  },
  {
    "text": "kind of circular symmetry. Or what's often called proper\ncomplex random variables.",
    "start": "909870",
    "end": "916589"
  },
  {
    "text": "Sort of accepting the fact that\nanything else is very, very improper.",
    "start": "916590",
    "end": "922230"
  },
  {
    "text": "It's improper because formulas\ndon't work in that case. OK, so we have a vector of these\ncomplex IID Gaussian",
    "start": "922230",
    "end": "931150"
  },
  {
    "text": "random variables. Under H equals zero, the\nobservation, v, is given by v",
    "start": "931150",
    "end": "938120"
  },
  {
    "text": "equals u plus Z. And under\nhypothesis one, the observation is given by minus\nu plus Z. So I have exactly",
    "start": "938120",
    "end": "946040"
  },
  {
    "text": "the same cases as\nwe had before. OK in other words almost all\nformulas stay the same when",
    "start": "946040",
    "end": "951800"
  },
  {
    "text": "you go from real to complex. But I don't trust the complex\ncase and you shouldn't either",
    "start": "951800",
    "end": "958370"
  },
  {
    "text": "until you at least go\nthrough it once. So what I'm going to do now is\ntranslate this complex case to",
    "start": "958370",
    "end": "965410"
  },
  {
    "text": "the real case. In other words, for each complex\nvariable I'm going to",
    "start": "965410",
    "end": "971110"
  },
  {
    "text": "make two real variables. One the real part and one\nthe imaginary part. We know that the real part and\nthe imaginary part are",
    "start": "971110",
    "end": "978040"
  },
  {
    "text": "independent of each other. And if these Gaussian random\nvariables are independent of each other, then the real and\nimaginary parts of each of",
    "start": "978040",
    "end": "985750"
  },
  {
    "text": "them are independent of the real\nand imaginary parts of each of the other side.",
    "start": "985750",
    "end": "991050"
  },
  {
    "text": "OK? So we can go from j Gaussian\nrandom variables, independant",
    "start": "991050",
    "end": "997610"
  },
  {
    "text": "Gaussian random variables,\nwhich are complex. To 2j Gaussian random variables,\nwhich at this point",
    "start": "997610",
    "end": "1004320"
  },
  {
    "text": "are going to be real. OK so it's just a translation\nfrom j complex variables to 2j",
    "start": "1004320",
    "end": "1011829"
  },
  {
    "text": "real variables. Again we can't draw pictures of\nthings in this j dimension,",
    "start": "1011830",
    "end": "1019750"
  },
  {
    "text": "we can start to draw pictures\nin 2j dimensions. If you talk about a probability\ndensity for a",
    "start": "1019750",
    "end": "1026220"
  },
  {
    "text": "complex random variable, what\nare you talking about? How do you write the probability\ndensity for just a",
    "start": "1026220",
    "end": "1034030"
  },
  {
    "text": "plane Gaussian complex\nrandom variable? What is it?",
    "start": "1034030",
    "end": "1039280"
  },
  {
    "text": " Anybody know what it is? Is it one dimensional or\nis it two dimensional?",
    "start": "1039280",
    "end": "1048260"
  },
  {
    "text": "What does probability\ndensity mean? It means probability\nper unit area.",
    "start": "1048260",
    "end": "1054060"
  },
  {
    "text": "What does area mean when\nyou're talking about complex numbers? Well you sort of mean what\nyou've drawn there, yes.",
    "start": "1054060",
    "end": "1063000"
  },
  {
    "text": "And you're looking at areas in\nthis complex plane here.",
    "start": "1063000",
    "end": "1068800"
  },
  {
    "text": "So that in fact when you write\nthe probability density for a complex random variable, what\nyou have already done whether",
    "start": "1068800",
    "end": "1075460"
  },
  {
    "text": "you want to do it or not is\nyou've converted the problem to real and imaginary part.",
    "start": "1075460",
    "end": "1081660"
  },
  {
    "text": "That's what the probability\ndensities are. Excuse me for a belaboring this\nbut, if I don't belabor",
    "start": "1081660",
    "end": "1088640"
  },
  {
    "text": "it I mean there's a catch\nhere that comes along in a little bit.",
    "start": "1088640",
    "end": "1093870"
  },
  {
    "text": "And you won't understand to\ncatch if you don't understand why these things are almost the\nsame as real variables up",
    "start": "1093870",
    "end": "1102380"
  },
  {
    "text": "until the catch comes. OK, so we're going to\ndeal with these 2j",
    "start": "1102380",
    "end": "1110020"
  },
  {
    "text": "dimensional real vectors. The components will be real part\nof u j, imaginary part of",
    "start": "1110020",
    "end": "1115990"
  },
  {
    "text": "u j for what goes into\nthe channel. And we'll let capital Y capital\nZ prime be the two j",
    "start": "1115990",
    "end": "1124730"
  },
  {
    "text": "dimensional real versions\nof V and Z. OK so that we'll call Y the real\npart, an imaginary part",
    "start": "1124730",
    "end": "1133650"
  },
  {
    "text": "of Z. And you notice that what's\ngoing on here is the same thing that's going on\nwhen you modulate QAM.",
    "start": "1133650",
    "end": "1140909"
  },
  {
    "text": "You take a complex signal, you\nmultiply it by either the 2pi j carrier frequency times t, and\nthen we started to look at",
    "start": "1140910",
    "end": "1151920"
  },
  {
    "text": "orthonormal expansions, you\nremember that what we looked at-- as far as the real signals\nthat were actually",
    "start": "1151920",
    "end": "1157560"
  },
  {
    "text": "being transmitted on the\nchannel-- was the real part of that u of t times z to the\nblah, blah, blah, and the",
    "start": "1157560",
    "end": "1164890"
  },
  {
    "text": "imaginary part of u of t\ntimes blah, blah, blah. So you've got two orthonormal\nfunctions in place of one",
    "start": "1164890",
    "end": "1172310"
  },
  {
    "text": "complex orthonormal function. And that's the same thing\nthat's going on here. It's just not with immodulation\nput in, it's just",
    "start": "1172310",
    "end": "1181490"
  },
  {
    "text": "dealing with the real parts and\nimaginary parts directly. OK, so if we do that we get\na bunch of equations.",
    "start": "1181490",
    "end": "1194870"
  },
  {
    "text": "They're sort of familiar\nlooking equations by now I hope. This is just the probability\ndensity of this real 2j",
    "start": "1194870",
    "end": "1202560"
  },
  {
    "text": "dimensional random variable. Which is all this junk that\nwe're used to seeing.",
    "start": "1202560",
    "end": "1209050"
  },
  {
    "text": "We can collapse that into\ne to the minus the norm",
    "start": "1209050",
    "end": "1215910"
  },
  {
    "text": "squared of y minus a. This is the norm squared\nin this 2j dimensional real space.",
    "start": "1215910",
    "end": "1222230"
  },
  {
    "text": "It's not the norm squared\nin this complex space. What gets confusing is\nthat those two norms",
    "start": "1222230",
    "end": "1229159"
  },
  {
    "text": "are exactly the same. As we'll see in just\na few minutes. But anyway, what we're dealing\nwith now is this",
    "start": "1229160",
    "end": "1236310"
  },
  {
    "text": "norm in real space. OK, note that's y--",
    "start": "1236310",
    "end": "1243500"
  },
  {
    "text": "oh let me translate\nthis one for you. ",
    "start": "1243500",
    "end": "1249540"
  },
  {
    "text": "If we think of this v that we\nreceived j complex random",
    "start": "1249540",
    "end": "1254690"
  },
  {
    "text": "variables as being: real part\nof v1, imaginary part of v1;",
    "start": "1254690",
    "end": "1262100"
  },
  {
    "text": "real part of v2, imaginary part\nof v2; and so forth, then",
    "start": "1262100",
    "end": "1267510"
  },
  {
    "text": "y2j minus 1 minus\na2j minus one.",
    "start": "1267510",
    "end": "1273140"
  },
  {
    "text": "I can't ever get these\nformulas right.  That should be a2j minus 1.",
    "start": "1273140",
    "end": "1281990"
  },
  {
    "text": "There. ",
    "start": "1281990",
    "end": "1289290"
  },
  {
    "text": "This squared, plus\nthis squared-- OK, in other words the real part\nsquared of the difference",
    "start": "1289290",
    "end": "1295880"
  },
  {
    "text": "plus the imaginary part squared\nof the difference-- is really just the same is\nvj minus uj squared.",
    "start": "1295880",
    "end": "1303190"
  },
  {
    "text": "OK, in other words you take the\ncomplex number v sub j, you subtract off the real\nnumber u sub j.",
    "start": "1303190",
    "end": "1310970"
  },
  {
    "text": "And the way to do that, you\nvisualize this one complex variable in the complex plane,\nand what you're doing is",
    "start": "1310970",
    "end": "1319870"
  },
  {
    "text": "you're taking the square of the\nreal part of the distance, you're adding it to\nthe square of the",
    "start": "1319870",
    "end": "1325760"
  },
  {
    "text": "imaginary part of the distance. OK, all of this is stuff you\nlearned in high school.",
    "start": "1325760",
    "end": "1331159"
  },
  {
    "text": "Just viewed in a slightly\ndifferent way. OK, now when you take the\nprobability density with",
    "start": "1331160",
    "end": "1338790"
  },
  {
    "text": "respect to these complex\nvectors-- which is what I want\nto get at--",
    "start": "1338790",
    "end": "1344309"
  },
  {
    "text": "probability density of these\ncomplex variables really means the same thing as that with\nthe real variables.",
    "start": "1344310",
    "end": "1350890"
  },
  {
    "text": "But then you wind up\nwith the magnitude",
    "start": "1350890",
    "end": "1358740"
  },
  {
    "text": "of vj minus uj squared. And this term is really exactly\nthe same as these two",
    "start": "1358740",
    "end": "1364800"
  },
  {
    "text": "terms there. So when you take this\nprobability density, you wind up with these terms the same and\nwith these terms the same.",
    "start": "1364800",
    "end": "1373820"
  },
  {
    "text": "OK, in other words the complex\nnorm squared is the same as the real norm squared, when you\ngo from complex to real",
    "start": "1373820",
    "end": "1382820"
  },
  {
    "text": "and imaginary parts of,\nwell-- as I said, this",
    "start": "1382820",
    "end": "1387870"
  },
  {
    "text": "is the same as that. OK so when we look at the log\nlikelihood ratio, then, let's",
    "start": "1387870",
    "end": "1395409"
  },
  {
    "text": "do the log likelihood ratio in\nterms of the real parts first. We get the difference between\nthis norm squared of y minus",
    "start": "1395410",
    "end": "1404820"
  },
  {
    "text": "a, and the norm squared\nof y plus a. This is the part that comes from\nthe hypothesis zero, this",
    "start": "1404820",
    "end": "1411670"
  },
  {
    "text": "is the part that comes from\nthe hypothesis one. OK, so we get these\ntwo terms here.",
    "start": "1411670",
    "end": "1417350"
  },
  {
    "text": "When we take the inner products\nhere, we get the same thing that we got before. Four times the inner\nproduct of yna.",
    "start": "1417350",
    "end": "1425440"
  },
  {
    "text": "Now, the whole reason for going\nthrough all of this is this next formula. When you do this, you wind up\nwith this very bizarre four",
    "start": "1425440",
    "end": "1433950"
  },
  {
    "text": "times the real part of the\ninner product of v and u, divided by N0.",
    "start": "1433950",
    "end": "1439400"
  },
  {
    "text": "And you get it in exactly\nthe same way that we got it before. Namely you take this norm\nhere, which is an inner",
    "start": "1439400",
    "end": "1446010"
  },
  {
    "text": "product squared of v minus u. Let me write it out. I'll write it out here.",
    "start": "1446010",
    "end": "1452050"
  },
  {
    "text": " Norm squared of y minus a, is\nthe norm squared of y plus the",
    "start": "1452050",
    "end": "1466730"
  },
  {
    "text": "norm squared of a, plus the\ninner product of minus ya,",
    "start": "1466730",
    "end": "1483010"
  },
  {
    "text": "plus the inner product\nof minus ay.",
    "start": "1483010",
    "end": "1490170"
  },
  {
    "text": "What's the sum of these\ntwo inner products? This inner product, by\ndefinition in terms of",
    "start": "1490170",
    "end": "1496570"
  },
  {
    "text": "integrals, is the integral\nof minus y times a--",
    "start": "1496570",
    "end": "1502630"
  },
  {
    "text": "complex conjugate. This is minus a times y--\ncomplex conjugate.",
    "start": "1502630",
    "end": "1509330"
  },
  {
    "text": "So in one case the complex\nconjugate is here. In the other case it's\non the other term. In other words this and\nthis are complex",
    "start": "1509330",
    "end": "1516320"
  },
  {
    "text": "conjugates of each other. What happens when you add\ntwo complex conjugates?",
    "start": "1516320",
    "end": "1521970"
  },
  {
    "text": "You get the real part\nof the two of them. Okay so when you add these two\nthings you just get that real part there.",
    "start": "1521970",
    "end": "1529540"
  },
  {
    "text": "OK, and then when you\ndo the other term, the same thing happens. The same cancellation that\nwe had before occurs.",
    "start": "1529540",
    "end": "1536590"
  },
  {
    "text": "And these two inner products add\nup so you wind up with the real part of vu over N0",
    "start": "1536590",
    "end": "1548900"
  },
  {
    "text": "When we look at the picture\nhere, what does it mean? Well I suggest you first\nlook at the one",
    "start": "1548900",
    "end": "1554450"
  },
  {
    "text": "dimensional case here. Namely on this one dimensional\ncase think of V as being a one",
    "start": "1554450",
    "end": "1560590"
  },
  {
    "text": "dimensional complex\nrandom variable. Then we can draw a picture. The picture make sense.",
    "start": "1560590",
    "end": "1566490"
  },
  {
    "text": "And what we're dealing with is\nthe real and imaginary parts, and these distances here, when\nyou talk about the norm of V",
    "start": "1566490",
    "end": "1577169"
  },
  {
    "text": "minus a-- namely what\ncorresponds to this line here, the length of this line--",
    "start": "1577170",
    "end": "1584150"
  },
  {
    "text": "what do you really mean by it? If you took the inner product,\nif you took the norm of v,",
    "start": "1584150",
    "end": "1592940"
  },
  {
    "text": "with i times a-- namely that\nthe square root of minus 1",
    "start": "1592940",
    "end": "1598990"
  },
  {
    "text": "times a-- would you get the same\nthing or wouldn't you? ",
    "start": "1598990",
    "end": "1605180"
  },
  {
    "text": "If I take a complex number, and\nI take the inner product of that complex number--\nnamely the product--",
    "start": "1605180",
    "end": "1613090"
  },
  {
    "text": "of that, when I take the inner\nproduct of ya, is this the",
    "start": "1613090",
    "end": "1626049"
  },
  {
    "text": "same as the inner product\nof y and i times a?",
    "start": "1626050",
    "end": "1632710"
  },
  {
    "text": " Not at all. The two things are totally\ndifferent.",
    "start": "1632710",
    "end": "1638590"
  },
  {
    "text": "Namely, inner products\nare complex things. Norms are real things.",
    "start": "1638590",
    "end": "1644929"
  },
  {
    "text": "And these norms, when you're\ndealing with complex numbers, have real parts in them. In other words, this distance\nthat we're talking about here",
    "start": "1644930",
    "end": "1653900"
  },
  {
    "text": "is not just the norm squared-- well it is the norm squared--\nbecause the norm has this",
    "start": "1653900",
    "end": "1660840"
  },
  {
    "text": "complex feature built into it. Because people kept making that\nmistake all the time.",
    "start": "1660840",
    "end": "1666580"
  },
  {
    "text": "So they fudged the mathematics\nto make it come out right. But after doing that, you have\nto fudge the mathematics to",
    "start": "1666580",
    "end": "1673440"
  },
  {
    "text": "come back to something that\nmakes sense here. So you have the real part of\nthis inner product, here.",
    "start": "1673440",
    "end": "1679350"
  },
  {
    "text": "So in fact, what you're doing\nwhen you're taking the inner product of two vectors and\nyou're trying to relate it to",
    "start": "1679350",
    "end": "1685590"
  },
  {
    "text": "this plane here, this separation\nplane, is you have to look at that separation\nplane.",
    "start": "1685590",
    "end": "1691300"
  },
  {
    "text": "You have to look at\nthat projection in terms of real numbers. Namely, you have to look\nat the projection.",
    "start": "1691300",
    "end": "1697880"
  },
  {
    "text": "First as being a complex\nprojection of v onto a, which",
    "start": "1697880",
    "end": "1703110"
  },
  {
    "text": "gives you a complex number. And then after you do that you\nhave to you visualize yourself",
    "start": "1703110",
    "end": "1709470"
  },
  {
    "text": "in a two dimensional\nreal space. And you have to project once\nmore from the two dimensional",
    "start": "1709470",
    "end": "1714870"
  },
  {
    "text": "thing to the one dimensional\nthing. And here where we're just\nlooking at one dimension to",
    "start": "1714870",
    "end": "1720860"
  },
  {
    "text": "start with, we have to draw it\nas a two dimensional space. And suddenly we are dealing\nwith this real part there",
    "start": "1720860",
    "end": "1728490"
  },
  {
    "text": "while we're not dealing\nwith that here. Which is why when people say\nminimum distance detection",
    "start": "1728490",
    "end": "1733740"
  },
  {
    "text": "when they're dealing with\ncomplex numbers it sounds very, very simple.",
    "start": "1733740",
    "end": "1739100"
  },
  {
    "text": "But in fact, it's\nnot so simple.  If you view this in the complex\nplane, is this a",
    "start": "1739100",
    "end": "1746570"
  },
  {
    "text": "linear operation or isn't it? When you're looking at things\nas complex vectors.",
    "start": "1746570",
    "end": "1755000"
  },
  {
    "text": "Is this thing a sub space of\nthe complex vector space?",
    "start": "1755000",
    "end": "1761220"
  },
  {
    "text": "No, it's not. It's not a sub space. Because, to be a sub space you\nhave to be able to multiply by",
    "start": "1761220",
    "end": "1769490"
  },
  {
    "text": "arbitrary scalors-- which includes complex\nnumbers-- and stay in the same space.",
    "start": "1769490",
    "end": "1775840"
  },
  {
    "text": "And here the complex numbers\nare important. OK? You should go back and\nthink about that.",
    "start": "1775840",
    "end": "1783110"
  },
  {
    "text": "You will be confused about it\nfor the first ten times you think about it.",
    "start": "1783110",
    "end": "1788370"
  },
  {
    "text": "For those of you who stick with\nit and carry through on it, you'll be happy because\nyou'll never be",
    "start": "1788370",
    "end": "1793990"
  },
  {
    "text": "confused about it again. OK, anyway thats real\nnumbers there.",
    "start": "1793990",
    "end": "1801080"
  },
  {
    "text": "And the most straightforward way\nto deal with complex noise",
    "start": "1801080",
    "end": "1806860"
  },
  {
    "text": "is to first turn it\ninto real noise. If you do that you never\nget confused.",
    "start": "1806860",
    "end": "1812410"
  },
  {
    "text": "And otherwise you only have\nhalf the analytical work. You only have half the\nwriting to do.",
    "start": "1812410",
    "end": "1819299"
  },
  {
    "text": "But you never know whether\nyou've done the right thing until you go back and check.",
    "start": "1819300",
    "end": "1824470"
  },
  {
    "text": "OK the probability of error\nfor maximum likelihood detection, in other words where\nthe threshold for the",
    "start": "1824470",
    "end": "1833169"
  },
  {
    "text": "log likelihood ratio is zero, is\nsimply the same thing that it was before.",
    "start": "1833170",
    "end": "1839070"
  },
  {
    "text": "Namely it's the q function. This tale of the Gaussian\nnormal function.",
    "start": "1839070",
    "end": "1847530"
  },
  {
    "text": "Of the norm of a divided by the\nsquare root of N0 over 2. In other words it's the length\nof a divided by the by the",
    "start": "1847530",
    "end": "1857220"
  },
  {
    "text": "length of a one standard\ndeviation of the noise.",
    "start": "1857220",
    "end": "1865020"
  },
  {
    "text": "When you put that in terms of,\nwell, if you write this as the",
    "start": "1865020",
    "end": "1872260"
  },
  {
    "text": "square root of the norm squared\nthen you get this formula here.",
    "start": "1872260",
    "end": "1877330"
  },
  {
    "text": "Because e sub b is just\nthe energy of these antipodal signals.",
    "start": "1877330",
    "end": "1882690"
  },
  {
    "text": "When you look at this in terms\nof the complex random variables, you get\nthe same thing.",
    "start": "1882690",
    "end": "1888860"
  },
  {
    "text": "OK? You get u instead of a because,\nin fact, in the complex plane and the real\nplane, distances turn out to",
    "start": "1888860",
    "end": "1897110"
  },
  {
    "text": "be the same. But again, in all cases it's\nsquare root of 2eb over n0",
    "start": "1897110",
    "end": "1905380"
  },
  {
    "text": "Now, that is true for any vector\nat all where these",
    "start": "1905380",
    "end": "1911490"
  },
  {
    "text": "norms are appropriate. When we start dealing with\nfunctions what happens?",
    "start": "1911490",
    "end": "1918909"
  },
  {
    "text": "When we start dealing with\nfunctions, what we're going to do is we're going to take this\nvector, we're going to turn it",
    "start": "1918910",
    "end": "1924680"
  },
  {
    "text": "into a wave form. We're going to transmit\nthe wave form. The wave form is going\nto come back to us.",
    "start": "1924680",
    "end": "1930650"
  },
  {
    "text": "We're going to demodulate it,\nget back to a number again. And that's the next thing that\nI want to talk about.",
    "start": "1930650",
    "end": "1939410"
  },
  {
    "text": "Because what I want to convince\nyou of is the property of white Gaussian noise\nwhich is so important.",
    "start": "1939410",
    "end": "1946150"
  },
  {
    "text": "Is that it doesn't make any\ndifference how you modulate.",
    "start": "1946150",
    "end": "1951990"
  },
  {
    "text": "All modulation systems\nare the same. All modulation schemes\nare the same. All frequencies are the same.",
    "start": "1951990",
    "end": "1959110"
  },
  {
    "text": "There is no way you can avoid\nwhite Gaussian noise. There is no way you can\nget screwed by it.",
    "start": "1959110",
    "end": "1964549"
  },
  {
    "text": "No matter what you do, the\nsame thing happens. You can always take all these\nproblems where you're dealing",
    "start": "1964550",
    "end": "1972540"
  },
  {
    "text": "with wave forms. You can convert them to finite\ndimensional vector problems.",
    "start": "1972540",
    "end": "1978070"
  },
  {
    "text": "And when you convert it into\na finite dimensional vector problem all of the orthonormal\nfunctions that you're using",
    "start": "1978070",
    "end": "1983940"
  },
  {
    "text": "all pass away. Because none of them are\nrelevant anymore. OK? That's the bottom line\nof all of that.",
    "start": "1983940",
    "end": "1991580"
  },
  {
    "text": " OK. We haven't really talked about\nM-ARY hypothesis testing.",
    "start": "1991580",
    "end": "2000370"
  },
  {
    "text": "So I want to talk about\nit a little bit now. I talked about it just a\nshade, but not much.",
    "start": "2000370",
    "end": "2008110"
  },
  {
    "text": "When we want to detect between\nm different hypothesis-- namely in the vector case\nwe're going to now be",
    "start": "2008110",
    "end": "2014560"
  },
  {
    "text": "detecting not between antipodal\nsignals but m signals which are placed\nany place at all.",
    "start": "2014560",
    "end": "2021910"
  },
  {
    "text": "We already said what the MAP,\noptimal MAP test was.",
    "start": "2021910",
    "end": "2027610"
  },
  {
    "text": "You see an observation, you're\ntrying to guess what the input was, or what the\nhypothesis was.",
    "start": "2027610",
    "end": "2035380"
  },
  {
    "text": "And in general, the MAP test\nsays try to find that j,",
    "start": "2035380",
    "end": "2042550"
  },
  {
    "text": "namely that hypothesis, for\nwhich the a priori probability of hypothesis j, times the\nlikelihood-- namely the",
    "start": "2042550",
    "end": "2051570"
  },
  {
    "text": "probability that you\nsee v given h of v, given j is maximum.",
    "start": "2051570",
    "end": "2059129"
  },
  {
    "text": "OK, this is just standard\nformula for finding a posteriori probabilities.",
    "start": "2059130",
    "end": "2065330"
  },
  {
    "text": "Where you factor out the\nmarginal on, when you cancel",
    "start": "2065330",
    "end": "2072110"
  },
  {
    "text": "out the marginal on v. In other words, what this rule\nsays is to do MAP testing,",
    "start": "2072110",
    "end": "2077850"
  },
  {
    "text": "what you do is you find the a\nposteriori probabilities of each of the hypotheses and you\nchoose the a posteriori",
    "start": "2077850",
    "end": "2085260"
  },
  {
    "text": "probability which is largest. Perfect common sense.",
    "start": "2085260",
    "end": "2090540"
  },
  {
    "text": "The way we're going to do\nthat, the way which is particularly convenient, is you\ndo it the same way that",
    "start": "2090540",
    "end": "2098329"
  },
  {
    "text": "we've been doing all along\nfor binary hypotheses. The way to do a MAP test, at\nleast one way to do a MAP",
    "start": "2098330",
    "end": "2105170"
  },
  {
    "text": "test, is you compare every pair\nof hypothesis and you choose the most likely\nof each pair.",
    "start": "2105170",
    "end": "2112180"
  },
  {
    "text": "And when you've got it all\ndone, you have a winner. OK? Mainly you can always compare\nany objects if they're",
    "start": "2112180",
    "end": "2119230"
  },
  {
    "text": "comparable. And after you compare each pair,\nyou take the one which",
    "start": "2119230",
    "end": "2125330"
  },
  {
    "text": "beats every other one and\nthat's the winner. OK? So what you do is you do a\npairwise test between each",
    "start": "2125330",
    "end": "2133900"
  },
  {
    "text": "hypothesis. Namely, the likelihood ratio\nof m relative to m prime.",
    "start": "2133900",
    "end": "2138920"
  },
  {
    "text": "Is the likelihood of the output\nconditional on m, divided by the likelihood\nof the output",
    "start": "2138920",
    "end": "2145790"
  },
  {
    "text": "conditional on m prime. You compare it with the a priori\nprobabilities, and the",
    "start": "2145790",
    "end": "2153020"
  },
  {
    "text": "point here is that nothing\nreally has been added. You have the same problem\nyou had before, OK?",
    "start": "2153020",
    "end": "2159710"
  },
  {
    "text": "Nothing new. It's just gotten n square\ntimes as complicated.",
    "start": "2159710",
    "end": "2164780"
  },
  {
    "text": "The computation is free now, so\nyou have exactly the same",
    "start": "2164780",
    "end": "2169870"
  },
  {
    "text": "problem that you had before. If you have to write it out on\npaper, yeah it's much more",
    "start": "2169870",
    "end": "2176000"
  },
  {
    "text": "complicated. But conceptually, it's not. You have to remember that\nthe signals are",
    "start": "2176000",
    "end": "2183070"
  },
  {
    "text": "not antipodal here. But what we're dealing with\nmostly at this point is this",
    "start": "2183070",
    "end": "2188740"
  },
  {
    "text": "Gaussian noise case. And here, what you observe,\nis signal plus noise.",
    "start": "2188740",
    "end": "2195490"
  },
  {
    "text": "And Z is zero-mean jointly Gauss\nand s is discrete with n",
    "start": "2195490",
    "end": "2201800"
  },
  {
    "text": "possible values. OK, so let's see what\nthat means.",
    "start": "2201800",
    "end": "2207540"
  },
  {
    "text": "Here's a picture of it.  If you have three singles which\nare each two dimensional",
    "start": "2207540",
    "end": "2214890"
  },
  {
    "text": "vectors, suppose one of them is\ns0, suppose one of them is s1, suppose one of them s2.",
    "start": "2214890",
    "end": "2222880"
  },
  {
    "text": "OK? And now you want to pairwise,\nsee which one is most likely.",
    "start": "2222880",
    "end": "2229570"
  },
  {
    "text": "And let's think of doing this\nfirst for the maximum likelihood case. What do you do?",
    "start": "2229570",
    "end": "2235100"
  },
  {
    "text": "You set up a perpendicular\nbisector between s0 and s1.",
    "start": "2235100",
    "end": "2241200"
  },
  {
    "text": "That's this line here. And if you weren't to worry\nabout s2, everything on this",
    "start": "2241200",
    "end": "2247550"
  },
  {
    "text": "side would go into\nH equals zero. And everything on this side\nwould go into H equals one.",
    "start": "2247550",
    "end": "2254619"
  },
  {
    "text": "Namely, whatever's closest\nto this point gets mapped into it. Whatever's closest to this point\ngets mapped into it.",
    "start": "2254620",
    "end": "2261770"
  },
  {
    "text": "If you're doing MAP testing,\nwhat happens? In the test between this and\nthis you had the same",
    "start": "2261770",
    "end": "2272819"
  },
  {
    "text": "orientation for this line, but\nit just gets shifted a little bit this way or a little\nbit this way.",
    "start": "2272820",
    "end": "2280140"
  },
  {
    "text": "OK? Then you compare this\nwith this and you get this line here.",
    "start": "2280140",
    "end": "2285210"
  },
  {
    "text": "Same argument as before. It's just comparing two things\nare not antipodal they've just",
    "start": "2285210",
    "end": "2291000"
  },
  {
    "text": "been shifted off from the\norigin a little bit. But for the maximum likelihood\nyou still take the",
    "start": "2291000",
    "end": "2296470"
  },
  {
    "text": "perpendicular bisector\nbetween them. And then you compare these two\nand you got a perpendicular",
    "start": "2296470",
    "end": "2302770"
  },
  {
    "text": "bisector between those.  And these perpendicular\nbisectors, in two dimensions,",
    "start": "2302770",
    "end": "2310050"
  },
  {
    "text": "always come together\nat one point. And I don't know why. ",
    "start": "2310050",
    "end": "2318010"
  },
  {
    "text": "And if you looked at it often\nenough, you probably know why. And you could probably prove\nit in about ten minutes.",
    "start": "2318010",
    "end": "2323230"
  },
  {
    "text": "But in fact these things always\ncome together somehow. If you do the MAP test, they\nalways come together also.",
    "start": "2323230",
    "end": "2329830"
  },
  {
    "text": "You can shift each of them in\narbitrary ways and somehow they always come together\nin this point.",
    "start": "2329830",
    "end": "2338230"
  },
  {
    "text": "OK, the separators between\ndecision regions here are the set of points where the real\npart of the inner product, vu,",
    "start": "2338230",
    "end": "2348289"
  },
  {
    "text": "is constant. OK? Again, for dealing with complex\nvectors, you got to",
    "start": "2348290",
    "end": "2353670"
  },
  {
    "text": "both do the projection and then\ndo the projection again onto the real part of\nthis projection.",
    "start": "2353670",
    "end": "2359550"
  },
  {
    "text": "So it's sort of a two\nway projection. Because probability densities in\nj dimensional complex space",
    "start": "2359550",
    "end": "2367220"
  },
  {
    "text": "are really 2j dimensional\nquantities. And when you're comparing\nthem, you really have to",
    "start": "2367220",
    "end": "2372690"
  },
  {
    "text": "compare things in terms\nof that 2j dimensional probability density.",
    "start": "2372690",
    "end": "2378060"
  },
  {
    "text": "OK so that's why\nthat comes out. These are best visualized in\nseparate, real, and imaginary",
    "start": "2378060",
    "end": "2383619"
  },
  {
    "text": "coordinates. And for maximum likelihood\ndetection, the regions are",
    "start": "2383620",
    "end": "2388850"
  },
  {
    "text": "Voronoi regions. OK? We talked about Voronoi regions\nin terms of doing",
    "start": "2388850",
    "end": "2398520"
  },
  {
    "text": "quantization. And we found out if you wanted\nto minimize the mean square error, what you did was you\nset up regions, which are",
    "start": "2398520",
    "end": "2406620"
  },
  {
    "text": "perpendicular bisectors between\nall the points. And here you get the same\nperpendicular bisectors",
    "start": "2406620",
    "end": "2412810"
  },
  {
    "text": "between the points. And everybody-- because\nof that-- thinks that quantization has a great deal\nto do with error probability",
    "start": "2412810",
    "end": "2421740"
  },
  {
    "text": "when you have large\nsets of signals. And it probably has something\nto do with it, but I don't",
    "start": "2421740",
    "end": "2428230"
  },
  {
    "text": "know what other than the fact\nthat you've got Voronoi regions in each case.",
    "start": "2428230",
    "end": "2433900"
  },
  {
    "text": "Which is what you get. ",
    "start": "2433900",
    "end": "2445059"
  },
  {
    "text": "OK, so that's where we are with\nboth complex vectors and",
    "start": "2445060",
    "end": "2455440"
  },
  {
    "text": "real vectors. I want to now just restrict\nattention to real wave forms so I don't have to keep going\nback and forth between the",
    "start": "2455440",
    "end": "2462770"
  },
  {
    "text": "real and imaginary case. If you're thinking in terms of\nQAM, we're now thinking in",
    "start": "2462770",
    "end": "2467799"
  },
  {
    "text": "terms of what goes\non at passband. Why do we want to think of\nwhat goes on at passband?",
    "start": "2467800",
    "end": "2473299"
  },
  {
    "text": "Because that's where\nthe noise hits us. And in a fundamental sense,\nall of the stuff about QAM",
    "start": "2473300",
    "end": "2481619"
  },
  {
    "text": "really isn't fundamental. I mean, it's all done-- all this\nstuff down at passband--",
    "start": "2481620",
    "end": "2487520"
  },
  {
    "text": "is all done because people\nthought it was easier to implement things there. It's the only reason for all of\nthat mess with dealing with",
    "start": "2487520",
    "end": "2496830"
  },
  {
    "text": "all of these complex signals. If we really want to deal with\nthe problem in a fundamental",
    "start": "2496830",
    "end": "2502240"
  },
  {
    "text": "way, what we want to\ndo is to choose a signal set up at passband. Do detection up at passband.",
    "start": "2502240",
    "end": "2509890"
  },
  {
    "text": "And then after we find out what\nthe optimal detection is up at passband, see if we can\nactually implement that down",
    "start": "2509890",
    "end": "2516430"
  },
  {
    "text": "at baseband. So the fundamental problem is\nlooking at single sets up at passband and analyze\nwhat they all mean.",
    "start": "2516430",
    "end": "2526080"
  },
  {
    "text": "OK, so we're going to generalize\nboth PAM and QAM.",
    "start": "2526080",
    "end": "2531290"
  },
  {
    "text": "And now we're going to look at\nthe general problem where what we're dealing with\nis a single set.",
    "start": "2531290",
    "end": "2538580"
  },
  {
    "text": "Which is m signals. Each of them we're going to\nvisualize as a vector in j",
    "start": "2538580",
    "end": "2544760"
  },
  {
    "text": "dimensional space. m different\nsignals, j dimensional space. Don't confuse the dimension\nof space with",
    "start": "2544760",
    "end": "2551590"
  },
  {
    "text": "the number of signals. OK? You can have an arbitrarily\nlarge dimensional space and",
    "start": "2551590",
    "end": "2556760"
  },
  {
    "text": "just binary signals. Or you can have an arbitrarily\nlarge set of signals and you",
    "start": "2556760",
    "end": "2562670"
  },
  {
    "text": "can be dealing with it. In PAM, for example, it's just\nall done in one dimension.",
    "start": "2562670",
    "end": "2568050"
  },
  {
    "text": "So j there is equal to 1. QAM j is equal to 2. We now want to look at\nmore general things.",
    "start": "2568050",
    "end": "2574540"
  },
  {
    "text": "Partly because we want to look\nat orthoginal wave forms. We want to look at orthoginal\nwave forms for two reasons.",
    "start": "2574540",
    "end": "2582080"
  },
  {
    "text": "One is that we would like to\nshow that by using orthoginal wave forms, you can reach what\nwe've called the capacity of a",
    "start": "2582080",
    "end": "2590279"
  },
  {
    "text": "white Gaussian noise channel. And two, when we get to studying\nwireless it's very,",
    "start": "2590280",
    "end": "2597480"
  },
  {
    "text": "very useful to base\nsignal sets on orthonormal sets of functions.",
    "start": "2597480",
    "end": "2603510"
  },
  {
    "text": "And we'll see why each\nof those things happen as we move on.",
    "start": "2603510",
    "end": "2608710"
  },
  {
    "text": "OK so we're going to denote the\nsingle set as the set of vectors, a1 up to a sub m.",
    "start": "2608710",
    "end": "2615170"
  },
  {
    "text": "And in that signal set, we will\ndenote the vector, a sub m, as a j dimensional vector,\na sub m1, a sub m2, up to a",
    "start": "2615170",
    "end": "2624116"
  },
  {
    "text": "sub m capital j. So j is at the dimension. m is just a component\nof these vectors.",
    "start": "2624116",
    "end": "2632810"
  },
  {
    "text": "I'm going to create\na set of capital J orthonormal wave forms.",
    "start": "2632810",
    "end": "2637930"
  },
  {
    "text": "They can be anything at all. I don't care what they are. I'm going to use those\northonormal wave forms in",
    "start": "2637930",
    "end": "2645080"
  },
  {
    "text": "order to modulate the signal-- which is now a vector-- up to some waveform.",
    "start": "2645080",
    "end": "2653240"
  },
  {
    "text": "This is really the standard way\nwe've been turning signals into waveforms all along.",
    "start": "2653240",
    "end": "2660819"
  },
  {
    "text": "It's just that now we're looking\nat the general case instead of all of these specific\ncases that we've been",
    "start": "2660820",
    "end": "2666819"
  },
  {
    "text": "looking at. All of the special cases all fit\ninto this same category.",
    "start": "2666820",
    "end": "2674370"
  },
  {
    "text": "So we have these capital\nM different waveforms. And we're going to transmit one\nof them and then at the",
    "start": "2674370",
    "end": "2685110"
  },
  {
    "text": "receiver we're going to try to\ndecide which one was sent. OK, well one of the reasons why\nI'm going through all of",
    "start": "2685110",
    "end": "2692240"
  },
  {
    "text": "this generality is that there's\nan issue we haven't",
    "start": "2692240",
    "end": "2697580"
  },
  {
    "text": "talked about yet. All of the stuff we've done on\ndetection so far we have had",
    "start": "2697580",
    "end": "2705020"
  },
  {
    "text": "one hypothesis. Could be M-ary could\nbe binary. We have sent something.",
    "start": "2705020",
    "end": "2711500"
  },
  {
    "text": "We have received something. We have made a detection. OK? In other words, for all of the\nantipodal stuff we've done, we",
    "start": "2711500",
    "end": "2718780"
  },
  {
    "text": "built a communication system. We set it all up. We transmitted one bit.",
    "start": "2718780",
    "end": "2724400"
  },
  {
    "text": "We've received the one bit. We've made a decision on it. Then we've torn down the\ncommunication system",
    "start": "2724400",
    "end": "2729890"
  },
  {
    "text": "and we've gone home. You really want to transmit a\nwhole sequence of symbols or",
    "start": "2729890",
    "end": "2735130"
  },
  {
    "text": "signals or waveforms. So we want to deal\nwith that now.",
    "start": "2735130",
    "end": "2742600"
  },
  {
    "text": "So we need some way\nto transmit a succession of M-ary signals.",
    "start": "2742600",
    "end": "2748770"
  },
  {
    "text": "And we'll call this succession\nof signals-- mainly the signals are the things that\nget chosen from the signal",
    "start": "2748770",
    "end": "2755780"
  },
  {
    "text": "set-- we'll call them\nx of k, k of z. Which is what we've been\ncalling them all along.",
    "start": "2755780",
    "end": "2761030"
  },
  {
    "text": "We've been transmitting a\nsequence of things when we're dealing with PAM. And aa in am.",
    "start": "2761030",
    "end": "2767880"
  },
  {
    "text": "Why do I call them\nxk instead of ak? ",
    "start": "2767880",
    "end": "2775740"
  },
  {
    "text": "Well I can't call them ak\nbecause when I talk about ak I'm talking about the k'th\nsignal in the signal set.",
    "start": "2775740",
    "end": "2783000"
  },
  {
    "text": "And here what I'm talking about\nnow is transmitting a sequence of choices.",
    "start": "2783000",
    "end": "2788940"
  },
  {
    "text": "Each one of these choices, the\nfirst choice is a choice from this set here. The second thing that I send\nis a choice from this set.",
    "start": "2788940",
    "end": "2796920"
  },
  {
    "text": "The third thing that I send\nis a choice from this set. So x1, x2, x3, and x4 and so\nforth are different choices",
    "start": "2796920",
    "end": "2806610"
  },
  {
    "text": "among these M-ary signals. If m is 2 to the 6--",
    "start": "2806610",
    "end": "2812680"
  },
  {
    "text": "OK in other words, every time\nI transmit a signal I'm transmitting six bits.",
    "start": "2812680",
    "end": "2818140"
  },
  {
    "text": "OK. In a communication system\nwe transmit six bits. Then we transmit another\nsix bits.",
    "start": "2818140",
    "end": "2824060"
  },
  {
    "text": "Then we transmit another six\nbits, and so on forever.",
    "start": "2824060",
    "end": "2829200"
  },
  {
    "text": "OK, so I need to talk about\nthese things as ways of a succession of signals.",
    "start": "2829200",
    "end": "2835610"
  },
  {
    "text": "The thing that I'm trying to\nget at is, how do you know when you send one of these\nsignals that you don't have to",
    "start": "2835610",
    "end": "2843940"
  },
  {
    "text": "worry about the other signals? How do you know that they don't interfere with each other?",
    "start": "2843940",
    "end": "2849660"
  },
  {
    "text": "Well, we sort of solved the\nproblem of them interfering with each other in dealing with\nNyquist, but we haven't",
    "start": "2849660",
    "end": "2857370"
  },
  {
    "text": "dealt with that problem at all\nsince we started to talk about random processes. So we don't know whether we've\nreally solved it or not.",
    "start": "2857370",
    "end": "2865349"
  },
  {
    "text": "So at this point we have to\nsolve that problem, and that's what we're aiming at. ",
    "start": "2865350",
    "end": "2872530"
  },
  {
    "text": "So, the one way to be able to\ntransmit a whole sequence of signals is to have these choices\nof vectors here and to",
    "start": "2872530",
    "end": "2882510"
  },
  {
    "text": "develop a set of orthonormal\nwaveforms, v1 up to v sub j, which all have the property that\nif you time shift them",
    "start": "2882510",
    "end": "2893040"
  },
  {
    "text": "each by capital T,\nthey're stilll--",
    "start": "2893040",
    "end": "2898180"
  },
  {
    "text": "if you time shift them by\ncapital T, they have to be orthonormal to each other. The question you're facing is\nwhether these things that",
    "start": "2898180",
    "end": "2905760"
  },
  {
    "text": "you're transmitting are\northoganol to all of these things that you're\ntransmitting. Now, in the Nyquist problem, we\ndealt with the problem of",
    "start": "2905760",
    "end": "2913890"
  },
  {
    "text": "how do you take one waveform\nhere and make it orthonormal to all of its time shifts.",
    "start": "2913890",
    "end": "2920040"
  },
  {
    "text": "And we solved that problem. In the quiz you solved the\nproblem-- although you probably didn't recognize it--",
    "start": "2920040",
    "end": "2926860"
  },
  {
    "text": "of dealing with orthonormal\nfunctions both in time and in frequency. And that's the kind of thing\nwe would like to use here.",
    "start": "2926860",
    "end": "2934200"
  },
  {
    "text": "If I take a set of orthonormal\npulses and then I modulate those orthonormal pulses up\nto a higher frequency--",
    "start": "2934200",
    "end": "2941590"
  },
  {
    "text": "which is out of the range of\nthis first frequency-- then I can send one sequence of\northonormal functions down",
    "start": "2941590",
    "end": "2948140"
  },
  {
    "text": "here, another set of orthonormal\nfunctions up here in a different frequency\nrange. Another one up here in\na different frequency",
    "start": "2948140",
    "end": "2954930"
  },
  {
    "text": "range and so forth. So then all of these orthonormal\nfunctions are going to be orthonormal\nto each other.",
    "start": "2954930",
    "end": "2961170"
  },
  {
    "text": "Yeah? AUDIENCE: Are you saying\nthat each x of",
    "start": "2961170",
    "end": "2967355"
  },
  {
    "text": "k is its own frequency? Because each x of k is\ninfinitely long. PROFESSOR: Each x of\nk is going to--",
    "start": "2967355",
    "end": "2975120"
  },
  {
    "text": "each x of k is just a vector\nof j components.",
    "start": "2975120",
    "end": "2981880"
  },
  {
    "text": "I'm going to modulate that\nvector, x of k, into a waveform, x of t, which might be\nfinite duration or it might",
    "start": "2981880",
    "end": "2991230"
  },
  {
    "text": "be infinite duration. I mean, it's going to go to zero\nvery, very fast, anyway.",
    "start": "2991230",
    "end": "2997670"
  },
  {
    "text": "And whether it is absolutely\ntime limited or not is something I don't really care\nabout at this point.",
    "start": "2997670",
    "end": "3004550"
  },
  {
    "text": "But the point is I can create\nfunctions where, in fact, I",
    "start": "3004550",
    "end": "3009770"
  },
  {
    "text": "have a whole sequence of\nfunctions here and they're orthonormal to all\nof the shifts.",
    "start": "3009770",
    "end": "3015420"
  },
  {
    "text": "One way of doing this, for\nexample, is to make capital J",
    "start": "3015420",
    "end": "3022390"
  },
  {
    "text": "a bunch of little time\nshifts on functions. I can pick a function p of t,\nwhich is orthonormal to all of",
    "start": "3022390",
    "end": "3029610"
  },
  {
    "text": "its shifts, in terms of t1. I can send J of those pulses\nto take care of x of k.",
    "start": "3029610",
    "end": "3038530"
  },
  {
    "text": "And then I can use a capital T\nin here, which is j times this little t that I was using.",
    "start": "3038530",
    "end": "3044730"
  },
  {
    "text": "And I can send another\nset of functions. So I can do that, I can move\nup and down in frequency.",
    "start": "3044730",
    "end": "3051720"
  },
  {
    "text": "I can choose any old\nset of orthonormal functions that I want to. But the thing that I want to do\nis I want to make sure that",
    "start": "3051720",
    "end": "3059910"
  },
  {
    "text": "for each vector, x of k, that\nI'm sending in time when I",
    "start": "3059910",
    "end": "3068910"
  },
  {
    "text": "modulate it to a waveform, that\nwaveform is orthonormal",
    "start": "3068910",
    "end": "3074140"
  },
  {
    "text": "to the waveforms for\nevery other k. And there are lots of\nways of doing that. OK, mainly there are\nlots of choices",
    "start": "3074140",
    "end": "3081190"
  },
  {
    "text": "of orthonormal functions. OK so anyway what I'm going to\nbe doing is making all of",
    "start": "3081190",
    "end": "3088670"
  },
  {
    "text": "these signals orthogonal\nto each other. ",
    "start": "3088670",
    "end": "3096350"
  },
  {
    "text": "OK, so the transmitting waveform\nfor this sequence of modulated signals is x of t,\nwhich is the sum of x of k",
    "start": "3096350",
    "end": "3105980"
  },
  {
    "text": "times t minus kt. Mainly the same thing we\nwere doing before. Except now I have also the\nproblem that each of these",
    "start": "3105980",
    "end": "3114920"
  },
  {
    "text": "waveforms, x of k of t,\nhas to be some sum of orthonormal functions.",
    "start": "3114920",
    "end": "3121340"
  },
  {
    "text": "So the problem becomes a little\nmore difficult than what it was before. But in fact it's--",
    "start": "3121340",
    "end": "3126569"
  },
  {
    "text": "I mean this is just standard\ncommunication. Every wireless system\nin the world uses this kind of scheme.",
    "start": "3126570",
    "end": "3132610"
  },
  {
    "text": "They don't use QAM or PAM. They use something much\nmore like this.",
    "start": "3132610",
    "end": "3139320"
  },
  {
    "text": "OK, so now our problem is you\nwant to detect a generic x from this sequence.",
    "start": "3139320",
    "end": "3145680"
  },
  {
    "text": "OK, in other words, one of these\nx sub k in sequence, we want to be able to detect\nwhat signal was sent.",
    "start": "3145680",
    "end": "3153670"
  },
  {
    "text": "We want to detect which\nhypothesis chose a signal",
    "start": "3153670",
    "end": "3158920"
  },
  {
    "text": "which was then formed into\na waveform, x of k of t. And if I can do this\nfor one k, I can do",
    "start": "3158920",
    "end": "3165180"
  },
  {
    "text": "it for all of them. So I want to solve the problem\nfor one generic value of k.",
    "start": "3165180",
    "end": "3171630"
  },
  {
    "text": "OK, how is this problem\ndifferent from what I was looking at before? Before I was looking at the\nproblem where we built a",
    "start": "3171630",
    "end": "3177830"
  },
  {
    "text": "communication system, we tuned\nit all up, we sent one bit. We detected it, we tore it all\ndown and we went home.",
    "start": "3177830",
    "end": "3186300"
  },
  {
    "text": "Now what we're doing is\nwe're building the communication system. We're tuning at all up. We're sending a sequence\nof bits.",
    "start": "3186300",
    "end": "3194470"
  },
  {
    "text": "And then all I'm interested in\nat the moment is detecting the k'th of them.",
    "start": "3194470",
    "end": "3200500"
  },
  {
    "text": "But if I find a way to detect\nthe k'th of them, I can then use it for every k.",
    "start": "3200500",
    "end": "3205740"
  },
  {
    "text": "OK? So I'm going to build a detector\nwhich is going to detect, in some optimal\nway, each one of these",
    "start": "3205740",
    "end": "3213099"
  },
  {
    "text": "signals that gets sent. OK? Is it clear how the problem\nis different? Mainly I have to deal with the\nfact that these other signals",
    "start": "3213100",
    "end": "3220000"
  },
  {
    "text": "are floating around there. And that's my problem. Ok, so the input to the channel\nis hypothesis H. That",
    "start": "3220000",
    "end": "3229380"
  },
  {
    "text": "takes values one up the m. The symbol, m, is mapped into\nthe signal, vector a sub m,",
    "start": "3229380",
    "end": "3236950"
  },
  {
    "text": "it's modulated into x of t\nequals summation over j, a sub",
    "start": "3236950",
    "end": "3242716"
  },
  {
    "text": "mj, phi j of t. OK, this waveform, now, is a\nfunction of which particular",
    "start": "3242716",
    "end": "3249980"
  },
  {
    "text": "signal I'm sending. Which is a function of which\nparticular hypothesis entered",
    "start": "3249980",
    "end": "3255039"
  },
  {
    "text": "the encoder.  The trouble with this material\nis all the complication comes",
    "start": "3255040",
    "end": "3265860"
  },
  {
    "text": "in this awful notation,\nwhich you can't avoid. Because you're dealing with\nsequences, you're dealing with vectors, and you're dealing\nwith wave forms",
    "start": "3265860",
    "end": "3273860"
  },
  {
    "text": "all at the same time. What's going on, after you\nunderstand it, you'll say why",
    "start": "3273860",
    "end": "3280070"
  },
  {
    "text": "was it so difficult to\nunderstand this? Because eventually when you see\nit, it becomes very, very",
    "start": "3280070",
    "end": "3285550"
  },
  {
    "text": "simple And I understand why\nthere's just too much stuff",
    "start": "3285550",
    "end": "3291630"
  },
  {
    "text": "all going on at the same time. OK, so what I'm going to do now\nis I'm going to take these",
    "start": "3291630",
    "end": "3297500"
  },
  {
    "text": "J, capital J, orthonormal\nwaveforms. And we've already seen that you\ncan start out with any old",
    "start": "3297500",
    "end": "3306030"
  },
  {
    "text": "orthonormal waveforms and if\nyou want to you can extend that set of waveforms into\nan orthonormal set that",
    "start": "3306030",
    "end": "3313790"
  },
  {
    "text": "spans all of L2. OK? So I'm going to imagine\nthat we've done that.",
    "start": "3313790",
    "end": "3320030"
  },
  {
    "text": "It's taken us a long time,\nbut we've done it. We're all through with it. We have this orthonormal\nset now.",
    "start": "3320030",
    "end": "3327070"
  },
  {
    "text": "If I'm smart, that orthonormal\nset, which I generated, will",
    "start": "3327070",
    "end": "3333080"
  },
  {
    "text": "also include easy ways to\nrepresent each of the other signals that we're\ngoing to send.",
    "start": "3333080",
    "end": "3338490"
  },
  {
    "text": "But I don't care about\nthat right now. All I'm dealing with is this one\nhypothesis that came in.",
    "start": "3338490",
    "end": "3344200"
  },
  {
    "text": "This one signal, a sub m-- ",
    "start": "3344200",
    "end": "3350720"
  },
  {
    "text": "oh, the hypothesis m, the\nsignal a sub m, an the",
    "start": "3350720",
    "end": "3356170"
  },
  {
    "text": "particular time instant, k, and\nthis waveform that gets sent, which can be represented\nas the first J terms in this",
    "start": "3356170",
    "end": "3365490"
  },
  {
    "text": "orthonormal sequence. OK, so what I'm going\nto get then is the",
    "start": "3365490",
    "end": "3372010"
  },
  {
    "text": "received random process. Is going to be a sum -- and forgot about the\nj prime now--",
    "start": "3372010",
    "end": "3379039"
  },
  {
    "text": "I can represent it as a sum of\ncoefficients times these",
    "start": "3379040",
    "end": "3384890"
  },
  {
    "text": "orthonormal waveforms. OK, that's what we've done for\narbitrary sequences, and then",
    "start": "3384890",
    "end": "3391980"
  },
  {
    "text": "we've said we can also do it\nfor at least well defined random processes.",
    "start": "3391980",
    "end": "3398380"
  },
  {
    "text": "I'm going to make, I mean,\ninstead of making this an infinite dimensional sum, I\nwant to make it a finite",
    "start": "3398380",
    "end": "3405880"
  },
  {
    "text": "dimensional sum where J prime\nis very, very large.",
    "start": "3405880",
    "end": "3411029"
  },
  {
    "text": "Say, 10 to the fiftieth\nif you want to. I don't want to make it\ninfinite, I want to look at what happens when I let it\nget bigger or smaller.",
    "start": "3411030",
    "end": "3419280"
  },
  {
    "text": "So I'm expanding Y of t over\nan orthonormal expansion.",
    "start": "3419280",
    "end": "3425380"
  },
  {
    "text": "But I'm not going all the way. I'm just going to try to do\nmaximum likelihood detection",
    "start": "3425380",
    "end": "3433160"
  },
  {
    "text": "with this finite set\nof observations. So I wont do quite as well\nas if I have all the",
    "start": "3433160",
    "end": "3438190"
  },
  {
    "text": "observations, but I'll\nstill do pretty well. We hope. OK, well so Y sub j--",
    "start": "3438190",
    "end": "3446200"
  },
  {
    "text": "the output that I see in\nthis degree of freedom corresponding to\nphi sub j of t.",
    "start": "3446200",
    "end": "3454099"
  },
  {
    "text": "Is going to be xj-- what I\nsent in that degree of freedom-- plus zj.",
    "start": "3454100",
    "end": "3460130"
  },
  {
    "text": "And there are j degrees of--\ncapital J degrees of freedom that I'm using. So the outputs in those degrees\nof freedom, namely in",
    "start": "3460130",
    "end": "3470010"
  },
  {
    "text": "the phi1 of t, phi2 of t, phi3\nof t directions in this L2",
    "start": "3470010",
    "end": "3475370"
  },
  {
    "text": "space are going to be the\nsignal plus the noise. For all of these dimensions.",
    "start": "3475370",
    "end": "3481760"
  },
  {
    "text": "And Yj is just going to\nbe equal to zj for all the other terms.",
    "start": "3481760",
    "end": "3488440"
  },
  {
    "text": "OK, now I want to add one\nextra thing here. What I should be putting in here\nis all the other signals",
    "start": "3488440",
    "end": "3496809"
  },
  {
    "text": "that are going to\nbe transmitted. I don't know how to do that. Notationally it gets\nvery confusing.",
    "start": "3496810",
    "end": "3504099"
  },
  {
    "text": "So what I'm going to say is,\nOK Z sub j here is not just",
    "start": "3504100",
    "end": "3509190"
  },
  {
    "text": "Gaussian noise. Z sub j is Gaussian noise plus\nall the signals from other",
    "start": "3509190",
    "end": "3517190"
  },
  {
    "text": "time instance that\nwe're sending. Plus all of the signals that\nanybody else is sending.",
    "start": "3517190",
    "end": "3523170"
  },
  {
    "text": "If we're dealing with wireless\nthen we have interference from them. Plus any old other thing you\ncan think of. z sub j is",
    "start": "3523170",
    "end": "3530480"
  },
  {
    "text": "everything but in these other\ndegrees of freedom. In these other coordinates.",
    "start": "3530480",
    "end": "3538060"
  },
  {
    "text": "This solves another problem\nfor us, because when we defined white Gaussian noise\nwe had this problem.",
    "start": "3538060",
    "end": "3545410"
  },
  {
    "text": "That we could only say it looked\nwhite over the region of interest.",
    "start": "3545410",
    "end": "3550470"
  },
  {
    "text": "We could only say it looked\nwhite over some time span.",
    "start": "3550470",
    "end": "3556220"
  },
  {
    "text": "Because the earth keeps\nchanging, you know. And over some frequency span\nbecause different frequencies",
    "start": "3556220",
    "end": "3563700"
  },
  {
    "text": "behave in different ways. So this also allows us to have\ndifferent Gaussian random",
    "start": "3563700",
    "end": "3572040"
  },
  {
    "text": "variables here. So when we have arbitrary random\nvariables here, they can be Gaussian or\nnon-Gaussian.",
    "start": "3572040",
    "end": "3578180"
  },
  {
    "text": "They don't have to have\nthe same variance. They don't have to\nhave anything.",
    "start": "3578180",
    "end": "3583859"
  },
  {
    "text": "What I am going to assume is\nthat these out of band, out of sense, out of view random\nvariables are all independent",
    "start": "3583860",
    "end": "3593740"
  },
  {
    "text": "of the things that\nI am looking at. And for white Gaussian\nnoise, that's true.",
    "start": "3593740",
    "end": "3599710"
  },
  {
    "text": "All of these random variables\nhere are independent of all of these random variables here.",
    "start": "3599710",
    "end": "3605640"
  },
  {
    "text": "For these first capital J\ndifferent random variables that I'm interested in.",
    "start": "3605640",
    "end": "3610789"
  },
  {
    "text": "And all these random variables\nare independent of they input",
    "start": "3610790",
    "end": "3616280"
  },
  {
    "text": "that I'm using. OK? In other words, a hypothesis\ncame into the transmitter that",
    "start": "3616280",
    "end": "3624380"
  },
  {
    "text": "generated a signal. The signal got turned into a\nwaveform, which is defined",
    "start": "3624380",
    "end": "3629870"
  },
  {
    "text": "solely in terms of these J\ndegrees of freedom, these J orthonormal functions.",
    "start": "3629870",
    "end": "3638000"
  },
  {
    "text": "And now everything everywhere\nelse is independent of these J",
    "start": "3638000",
    "end": "3643370"
  },
  {
    "text": "functions that I'm\ninterested in. Why is that a shaky\nassumption?",
    "start": "3643370",
    "end": "3649130"
  },
  {
    "text": " Anybody think of a\nsituation where that is absolute nonsense?",
    "start": "3649130",
    "end": "3655410"
  },
  {
    "text": " Yeah? AUDIENCE: The stuff from the\nother message had t--",
    "start": "3655410",
    "end": "3668660"
  },
  {
    "text": "PROFESSOR: Mm hmm.",
    "start": "3668660",
    "end": "3674940"
  },
  {
    "text": "AUDIENCE: You said t of j is\nnot just Gaussian noise-- PROFESSOR: It also includes all\nthose other signals, yes.",
    "start": "3674940",
    "end": "3681130"
  },
  {
    "text": "Well, but I want to assume that\nthose other signals are independent of this particular\nsignal that I'm sending.",
    "start": "3681130",
    "end": "3687210"
  },
  {
    "text": "But in fact that is making\na pretty big assumption. Because one of the things that a\nlot of people like to do is,",
    "start": "3687210",
    "end": "3694660"
  },
  {
    "text": "when these bits come into a\nchannel, the first thing they do is they encode the bits\nfor error correction.",
    "start": "3694660",
    "end": "3702500"
  },
  {
    "text": "And then they take those bits\nthat come out of the error correction device, error\nencoding device, which are as",
    "start": "3702500",
    "end": "3710020"
  },
  {
    "text": "correlated as could be. And they're all statistically\nvery dependent, because we",
    "start": "3710020",
    "end": "3715090"
  },
  {
    "text": "want to use that statistical\ndependence later to correct errors.",
    "start": "3715090",
    "end": "3720520"
  },
  {
    "text": "And this assumption that I'm\nmaking here says, \"no that's not the case. I'm assuming that all that other\nstuff is independent of",
    "start": "3720520",
    "end": "3727660"
  },
  {
    "text": "what I'm transmitting here.\"\nSo I'm very specifically assuming at this point that all\nof that stuff has not been",
    "start": "3727660",
    "end": "3735090"
  },
  {
    "text": "encoded first. That I'm sending something\nwhich is independent of everything else.",
    "start": "3735090",
    "end": "3741780"
  },
  {
    "text": "Which is going to enter\nthis channel. We'll just assume that and after\nwe get done assuming it",
    "start": "3741780",
    "end": "3748190"
  },
  {
    "text": "and seeing what the consequence\nof it is, we'll go back and see what\nit all means.",
    "start": "3748190",
    "end": "3754530"
  },
  {
    "text": "OK, so for a little\nmore notation. I'm going to call the\nvector, Y, the first",
    "start": "3754530",
    "end": "3763020"
  },
  {
    "text": "J, capital J, outputs. I'm going to call the vector Y\nprime all the other outputs.",
    "start": "3763020",
    "end": "3770800"
  },
  {
    "text": "Now intuitively what were aiming\nat is, we would like to say this stuff doesn't have\nanything to do with it.",
    "start": "3770800",
    "end": "3777930"
  },
  {
    "text": "We're going to base our\ndecision on this. But I want to prove that to you,\nand show you why it works",
    "start": "3777930",
    "end": "3784059"
  },
  {
    "text": "and why it doesn't. And the noise I'm going to\nbreak up the same way. Z is this the first J components\nof the noise.",
    "start": "3784060",
    "end": "3790710"
  },
  {
    "text": "And Z prime is the other\ncomponents of noise. So what I have is that the\noutput, the output that I want",
    "start": "3790710",
    "end": "3798565"
  },
  {
    "text": "to look at, namely the\noutput this vector of dimension J output.",
    "start": "3798565",
    "end": "3804859"
  },
  {
    "text": "Which is equal to a vector of\ndimension J input plus of a",
    "start": "3804860",
    "end": "3810130"
  },
  {
    "text": "vector of dimension J\nnoise is equal to--",
    "start": "3810130",
    "end": "3815460"
  },
  {
    "text": "well Y is equal X plus Z. And\nthe out of band stuff, the output, is just these noise\nand other signals.",
    "start": "3815460",
    "end": "3824490"
  },
  {
    "text": "OK? And I want to assume that\nZ prime, X, and Z are statistically independent.",
    "start": "3824490",
    "end": "3832120"
  },
  {
    "text": "Question, test your\nprobability. If I assume that Z prime is\nindependent of Z, and if I",
    "start": "3832120",
    "end": "3840460"
  },
  {
    "text": "assume that Z prime is\nindependent of X, does that mean that Z prime is independant\nof X and Z?",
    "start": "3840460",
    "end": "3852880"
  },
  {
    "text": "If a is independent of b, and\na is independent of c, is a necessarily independent\nof the pair bc?",
    "start": "3852880",
    "end": "3859750"
  },
  {
    "text": " How many think that's true? ",
    "start": "3859750",
    "end": "3866630"
  },
  {
    "text": "Better go back and\nstudy a little elementary probability again.",
    "start": "3866630",
    "end": "3873720"
  },
  {
    "text": "And the notes are occasionally\nwrong about that, too. So you shouldn't feel, you\nshouldn't feel badly about it.",
    "start": "3873720",
    "end": "3882860"
  },
  {
    "text": "No, the problem is you really\nneed this joint independence between all three of them. I could, for example, make X\nplus Y be equal to Z. I could",
    "start": "3882860",
    "end": "3895200"
  },
  {
    "text": "do this with discrete\nrandom variables. Which are equally probably\nzero and one.",
    "start": "3895200",
    "end": "3901330"
  },
  {
    "text": "And make the plus equal\nto a mod 2 operation. And if I did that, each pair\nwould be independent of each",
    "start": "3901330",
    "end": "3907890"
  },
  {
    "text": "other, and the triple would be\nvery, very highly dependant. So anyway, I want to assume\nthat Z prime, X, and Z are",
    "start": "3907890",
    "end": "3914990"
  },
  {
    "text": "statistically independent. In other words, what I'm doing\nis saying, \"If I assume that,",
    "start": "3914990",
    "end": "3921710"
  },
  {
    "text": "what's the consequence of it?\" OK, so the likelihood then, the\nprobability density of the",
    "start": "3921710",
    "end": "3929600"
  },
  {
    "text": "output, Y-- this is the output\nin the first j dimensions given a particular hypothesis\nY-- is equal to the",
    "start": "3929600",
    "end": "3938620"
  },
  {
    "text": "probability density of the noise\nevaluated at Y minus am.",
    "start": "3938620",
    "end": "3945410"
  },
  {
    "text": "Where this is the signal that\ngoes with this hypothesis, well with am.",
    "start": "3945410",
    "end": "3951450"
  },
  {
    "text": "Times the probability density\nof Y prime for Z prime.",
    "start": "3951450",
    "end": "3959079"
  },
  {
    "text": "OK? And I don't even have to assume\nthat this is Gaussian. All I've done is to assume that\nthese random variables",
    "start": "3959080",
    "end": "3964480"
  },
  {
    "text": "are independent of these\nrandom variables. And therefore this probability\ndensity is multiplied by this",
    "start": "3964480",
    "end": "3972400"
  },
  {
    "text": "probability density. OK, well that's kind of neat. Because if I put a different i\nin here in place of m, I get",
    "start": "3972400",
    "end": "3982420"
  },
  {
    "text": "this thing. Changes all around. F sub Z of Y minus a sub i. But this stuff, which\nis out of band,",
    "start": "3982420",
    "end": "3989470"
  },
  {
    "text": "doesn't change at all. When I form the likelihood\nratio, what I get then is this",
    "start": "3989470",
    "end": "3998030"
  },
  {
    "text": "divided by that. What has happened to Y prime?",
    "start": "3998030",
    "end": "4003430"
  },
  {
    "text": "Y prime has disappeared. In other words, Y1 to Y sub j\nare a sufficient statistic for",
    "start": "4003430",
    "end": "4011160"
  },
  {
    "text": "this problem. We've shown that sufficient\nstatistics are the only thing you need to use to do maximum\nlikelihood detection.",
    "start": "4011160",
    "end": "4019900"
  },
  {
    "text": "OK? In other words, all those other\nsignals, all that other noise, all that stuff from out\nof band has disappeared.",
    "start": "4019900",
    "end": "4028079"
  },
  {
    "text": "Now let's go back to the fact\nthat we were looking at a finite dimensional problem. ",
    "start": "4028080",
    "end": "4037010"
  },
  {
    "text": "What happens now when I\nmake j prime bigger? When I start enlarging\nj prime?",
    "start": "4037010",
    "end": "4042849"
  },
  {
    "text": "What happens to all these\nprobabilities that we're talking about? This probability density goes\nape because of this term here.",
    "start": "4042850",
    "end": "4052579"
  },
  {
    "text": "We're talking about a\nprobability density here which is involving more and\nmore and more terms.",
    "start": "4052580",
    "end": "4059460"
  },
  {
    "text": "I can't talk about that. It doesn't go to any limit. It goes to absolute nonsense\nas j prime gets big.",
    "start": "4059460",
    "end": "4068980"
  },
  {
    "text": "But if I form the likelihood\nratio before I go to the limit, then I can go to the\nlimit quite easily.",
    "start": "4068980",
    "end": "4075200"
  },
  {
    "text": "Because there isn't any\nlimit involved there. OK, in other words this is the\nlikelihood ratio between",
    "start": "4075200",
    "end": "4083490"
  },
  {
    "text": "hypothesis m and hypothesis i,\nif in fact I looked at this entire infinite amount\nof observation.",
    "start": "4083490",
    "end": "4091980"
  },
  {
    "text": "This is all I need to make\nthe optimal MAP decision.",
    "start": "4091980",
    "end": "4097759"
  },
  {
    "text": "OK, so there's a theorem here\nwhich is called the theorem of irrelevance.",
    "start": "4097760",
    "end": "4102940"
  },
  {
    "text": "This is something that\nWosencraft and Jacobs in their book on communication many years\nago stressed a lot in",
    "start": "4102940",
    "end": "4110140"
  },
  {
    "text": "trying to come up with a single\nspace viewpoint of communication. And you'll see why this really\ndoes give you a single point",
    "start": "4110140",
    "end": "4117400"
  },
  {
    "text": "viewpoint of communication. It says that assume that Z\nprime is statistically independent of the pair X and Z.\nThen the MAP detection of X",
    "start": "4117400",
    "end": "4126740"
  },
  {
    "text": "from the observation of Y and Y\nprime depends only on Y. The observed sample value of\nY prime is irrelevant.",
    "start": "4126740",
    "end": "4136329"
  },
  {
    "text": "OK? So you can do all of detection\ntheory, you can do all of communication, simply forgetting\nabout that",
    "start": "4136330",
    "end": "4144389"
  },
  {
    "text": "irrelevant stuff. Because of the theorem we can\nstick to finite dimensional vectors and the other signals\ncan be viewed",
    "start": "4144390",
    "end": "4153310"
  },
  {
    "text": "as part of Z prime. So you don't have to\nworry about them.",
    "start": "4153310",
    "end": "4158569"
  },
  {
    "text": "So long as each signal is\nindependent of each other-- which means that these groups of\nbits, the first group a bit",
    "start": "4158570",
    "end": "4166880"
  },
  {
    "text": "is used to form a sub x sub 1. ",
    "start": "4166880",
    "end": "4173100"
  },
  {
    "text": "The next group, the form x sub\n2, the next group the form x sub 3, and so forth. So long as those sequences of\nbits are independent of each",
    "start": "4173100",
    "end": "4181089"
  },
  {
    "text": "other, you're fine. Now, suppose they aren't? What happens then?",
    "start": "4181090",
    "end": "4186720"
  },
  {
    "text": " Interesting question.",
    "start": "4186720",
    "end": "4192900"
  },
  {
    "text": "We said that if they are\nindependent, I can really do maximum likelihood detection\non the whole sequence.",
    "start": "4192900",
    "end": "4200180"
  },
  {
    "text": "If they aren't independent,\nsuppose I say, \"oh I don't care about that.\" I'm just going\nto use this portion of",
    "start": "4200180",
    "end": "4208540"
  },
  {
    "text": "the output to make my decision\nand not worry about whether this is independent\nof anything else.",
    "start": "4208540",
    "end": "4215570"
  },
  {
    "text": "I can do that, this still is\ngoing to give me the optimal",
    "start": "4215570",
    "end": "4220900"
  },
  {
    "text": "maximum likelihood detection in\nterms of the observation y1 up to y sub j.",
    "start": "4220900",
    "end": "4226410"
  },
  {
    "text": " So in other words, whether I\nhave coding done before this",
    "start": "4226410",
    "end": "4233590"
  },
  {
    "text": "or not doesn't make\nany difference. I can still use maximum\nlikelihood detection on the",
    "start": "4233590",
    "end": "4239080"
  },
  {
    "text": "basis of y1 up to y sub j. What the theorem says is if\nthe out of band stuff--",
    "start": "4239080",
    "end": "4247969"
  },
  {
    "text": "both these inputs and the\nnoise-- are independent of what I'm trying to detect,\nmaximum likelihood becomes the",
    "start": "4247970",
    "end": "4255130"
  },
  {
    "text": "optimum thing to do for\nequally likely inputs. And otherwise, it's a perfectly\nreasonable thing to",
    "start": "4255130",
    "end": "4261870"
  },
  {
    "text": "do but it's not optimal. Now, a lot of people-- and we'll see some\nexamples of this",
    "start": "4261870",
    "end": "4268389"
  },
  {
    "text": "when we look at wireless-- in fact, use coding.",
    "start": "4268390",
    "end": "4274980"
  },
  {
    "text": "Then they use this particular\nkind of detection where they forget about all of the added",
    "start": "4274980",
    "end": "4280140"
  },
  {
    "text": "information from other signals. They make a decision on each of\nthese x sub k, namely each",
    "start": "4280140",
    "end": "4288659"
  },
  {
    "text": "of the M-ary signals that\ngoes in, they make a hard decision on it.",
    "start": "4288660",
    "end": "4294210"
  },
  {
    "text": "It's called a hard decision, not\nbecause it's difficult it because they refuse to ever\ngo back and change it.",
    "start": "4294210",
    "end": "4301830"
  },
  {
    "text": "If they just say likelihoods and\ntry to put things together in the final decoder, it's\ncalled soft decoding.",
    "start": "4301830",
    "end": "4309540"
  },
  {
    "text": "Otherwise it's called\nhard decoding. If you do soft decoding,\nit has to work better. Because you're making, in a\nsense, a better decision",
    "start": "4309540",
    "end": "4317310"
  },
  {
    "text": "because eventually you're\nusing more information.",
    "start": "4317310",
    "end": "4322450"
  },
  {
    "text": "So soft decisions are better\nthan hard decisions. Used to be that everybody used\nhard decisions because hard",
    "start": "4322450",
    "end": "4331770"
  },
  {
    "text": "decisions were easy and soft\ndecisions were hard.",
    "start": "4331770",
    "end": "4337810"
  },
  {
    "text": "Strange, strange thing. But anyway that's changed. Why?",
    "start": "4337810",
    "end": "4343730"
  },
  {
    "text": "Well it ought to\nbe obvious why. Because anything you build now\ncost a tenth of what it used",
    "start": "4343730",
    "end": "4348829"
  },
  {
    "text": "to cost to build it. I heard Irwin Jacobs awhile\nago saying that one of the",
    "start": "4348830",
    "end": "4354490"
  },
  {
    "text": "things that they always did when\nthey were designing new pieces of equipment is they\nwould look at how much it",
    "start": "4354490",
    "end": "4361410"
  },
  {
    "text": "would cost to build\nthese devices. And then, as opposed to most\ncompanies which would say",
    "start": "4361410",
    "end": "4369090"
  },
  {
    "text": "that's too expensive let's find\nthe cheaper way to do it, they said OK how long is it\ngoing to take for us to do it,",
    "start": "4369090",
    "end": "4375870"
  },
  {
    "text": "and what is the price of\ncomponents going to be by time we got it done? And they would usually say, well\nit's going to cost a year",
    "start": "4375870",
    "end": "4382309"
  },
  {
    "text": "before we can go into\nmass production. By that time, everything will\ncost less than a half of what",
    "start": "4382310",
    "end": "4388130"
  },
  {
    "text": "it's costing now. So let's go ahead and\ndo it the right way. So again the argument comes\nthat you can do",
    "start": "4388130",
    "end": "4396520"
  },
  {
    "text": "the hard thing now. Which is soft decisions, and\nthat's what most people do at",
    "start": "4396520",
    "end": "4402389"
  },
  {
    "text": "this point. Let me give you one more picture\nto get ready for what we're doing next time.",
    "start": "4402390",
    "end": "4409199"
  },
  {
    "text": "Because it's a nice picture\nof different signal sets.",
    "start": "4409200",
    "end": "4414960"
  },
  {
    "text": "Because we've just talked\nabstractly of having multiple signals viewed as vectors, and\nthis will give us some idea of",
    "start": "4414960",
    "end": "4426300"
  },
  {
    "text": "what all of these mean. I can have two signals, a binary\nsignal set, and I can",
    "start": "4426300",
    "end": "4434110"
  },
  {
    "text": "insist on the signals being\northogonal to each other. Which is a nice thing\nto do some times.",
    "start": "4434110",
    "end": "4440920"
  },
  {
    "text": "But then I can look at it and\nI can say, \"how can I make that a better signal system?\"\nThe trouble with this signal",
    "start": "4440920",
    "end": "4449540"
  },
  {
    "text": "system is it's not antipodal. It's not antipodal because\nsomehow by alternating between",
    "start": "4449540",
    "end": "4456790"
  },
  {
    "text": "these two orthogonal signals--\nthere's a mean between them-- and I'm transmitting that mean\nplus the difference.",
    "start": "4456790",
    "end": "4463880"
  },
  {
    "text": "And the difference between them\nis minus 0.7 and plus 0.7 in that direction that way.",
    "start": "4463880",
    "end": "4472220"
  },
  {
    "text": "If you can, I guess you\ncan't see it that way. In this direction this way.",
    "start": "4472220",
    "end": "4478280"
  },
  {
    "text": " Well anyway, OK.",
    "start": "4478280",
    "end": "4486820"
  },
  {
    "text": "A better thing to do than this\nis this, which is called bi orthogonal. So you take orthogonal signals\nand then you have a signal set",
    "start": "4486820",
    "end": "4495980"
  },
  {
    "text": "consisting of four signals and\ntwo dimensional space. We then talk about orthogonal\nsignals and",
    "start": "4495980",
    "end": "4503010"
  },
  {
    "text": "higher dimensional space. You can talk about three\northogonal signals in three",
    "start": "4503010",
    "end": "4508040"
  },
  {
    "text": "dimensional space here. There, there, and there. So that's m equals\n3 and j equals 3.",
    "start": "4508040",
    "end": "4515540"
  },
  {
    "text": "If you do the same thing\nthat we did here-- we're going to make this into\nan equilateral triangle.",
    "start": "4515540",
    "end": "4520650"
  },
  {
    "text": "Namely we're going to center\nit around the center. If we do the same thing that\nwe did here we're going to",
    "start": "4520650",
    "end": "4526219"
  },
  {
    "text": "turn this into a set of six\nwaveforms which are still",
    "start": "4526220",
    "end": "4531690"
  },
  {
    "text": "using the three degrees of\nfreedom, but at least get us more signals.",
    "start": "4531690",
    "end": "4539710"
  },
  {
    "text": "For the same number of\ndegrees of freedom. So you can extend this picture\nas far as you want to.",
    "start": "4539710",
    "end": "4545560"
  },
  {
    "text": "You can talk about many, many\northogonal signals going into many more degrees of freedom.",
    "start": "4545560",
    "end": "4552530"
  },
  {
    "text": "For each one of them you\ncan come up with a simplex set of signals. The nice thing about the simplex\nset of signals is that",
    "start": "4552530",
    "end": "4560280"
  },
  {
    "text": "all of the signals are arranged around the center point. They're all equally distant\nfrom each other.",
    "start": "4560280",
    "end": "4566030"
  },
  {
    "text": "You can get these for every\ndimension by starting with these and simply taking the mean\nout, which loses you one",
    "start": "4566030",
    "end": "4572090"
  },
  {
    "text": "dimension and makes this\nsort of ideal set. Well tomorrow-- on Wednesday\nwhat we're going to do is,",
    "start": "4572090",
    "end": "4580980"
  },
  {
    "text": "we're going to talk about these\nlarge sets here, and see what happens.",
    "start": "4580980",
    "end": "4586450"
  },
  {
    "text": "And we'll see that you in\nfact get to channel capacity this way. ",
    "start": "4586450",
    "end": "4591829"
  },
  {
    "text": "OK. ",
    "start": "4591830",
    "end": "4593262"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6910"
  },
  {
    "text": "offer high-quality, educational resources for free. To make a donation or view\nadditional materials from",
    "start": "6910",
    "end": "13460"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at",
    "start": "13460",
    "end": "19290"
  },
  {
    "text": "ocw.mit.edu.  PROFESSOR: Good morning. So today we're going\nto continue the",
    "start": "19290",
    "end": "25900"
  },
  {
    "text": "subject from last time. So we're going to talk about\nderived distributions a little",
    "start": "25900",
    "end": "31010"
  },
  {
    "text": "more, how to derive the\ndistribution of a function of a random variable.",
    "start": "31010",
    "end": "36510"
  },
  {
    "text": "So last time we discussed a\ncouple of examples in which we had a function of a\nsingle variable.",
    "start": "36510",
    "end": "43570"
  },
  {
    "text": "And we found the distribution\nof Y, if we're told the distribution of X. So today we're going to do an\nexample where we deal with the",
    "start": "43570",
    "end": "51030"
  },
  {
    "text": "function of two random\nvariables. And then we're going to consider\nthe most interesting",
    "start": "51030",
    "end": "56460"
  },
  {
    "text": "example of this kind, in which\nwe have a random variable of the form W, which is\nthe sum of two",
    "start": "56460",
    "end": "63800"
  },
  {
    "text": "independent, random variables. That's a case that shows\nup quite often. And so we want to see what\nexactly happens in this",
    "start": "63800",
    "end": "70850"
  },
  {
    "text": "particular case. Just one comment that\nI should make. The material that we're covering\nnow, chapter four, is",
    "start": "70850",
    "end": "78010"
  },
  {
    "text": "sort of conceptually a little\nmore difficult than one we have been doing before.",
    "start": "78010",
    "end": "83600"
  },
  {
    "text": "So I would definitely encourage\nyou to read the text before you jump and try\nto do the problems in",
    "start": "83600",
    "end": "89690"
  },
  {
    "text": "your problem sets. OK, so let's start with our\nexample, in which we're given",
    "start": "89690",
    "end": "100270"
  },
  {
    "text": "two random variables. They're jointly continuous. And their distribution\nis pretty simple.",
    "start": "100270",
    "end": "105869"
  },
  {
    "text": "They're uniform on\nthe unit square. In particular, each one of the\nrandom variables is uniform on",
    "start": "105870",
    "end": "112439"
  },
  {
    "text": "the unit interval. And the two random variables\nare independent. What we're going to find is the\ndistribution of the ratio",
    "start": "112440",
    "end": "120820"
  },
  {
    "text": "of the two random variables. How do we go about it? , Well,\nthe same cookbook procedure",
    "start": "120820",
    "end": "127170"
  },
  {
    "text": "that we used last time\nfor the case of a single random variable.",
    "start": "127170",
    "end": "133750"
  },
  {
    "text": "The cookbook procedure that\nwe used for this case also applies to the case where you\nhave a function of multiple",
    "start": "133750",
    "end": "140240"
  },
  {
    "text": "random variables. So what was the cookbook\nprocedure? The first step is to find the\ncumulative distribution",
    "start": "140240",
    "end": "147030"
  },
  {
    "text": "function of the random variable\nof interest and then take the derivative in order\nto find the density.",
    "start": "147030",
    "end": "156260"
  },
  {
    "text": "So let's find the cumulative. So, by definition, the\ncumulative is the probability",
    "start": "156260",
    "end": "163800"
  },
  {
    "text": "that the random variable is\nless than or equal to the argument of the cumulative.",
    "start": "163800",
    "end": "169880"
  },
  {
    "text": "So if we write this event in\nterms of the random variable of interest, this is the\nprobability that our random",
    "start": "169880",
    "end": "178470"
  },
  {
    "text": "variable is less than\nor equal to z. So what is that?",
    "start": "178470",
    "end": "184920"
  },
  {
    "text": "OK, so the ratio is going to be\nless than or equal to z, if and only if the pair, (x,y),\nhappens to fall below the line",
    "start": "184920",
    "end": "194920"
  },
  {
    "text": "that has a slope z. OK, so we draw a line\nthat has a slope z.",
    "start": "194920",
    "end": "200800"
  },
  {
    "text": "The ratio is less than this\nnumber, if and only if we get the pair of x and y that falls\ninside this triangle.",
    "start": "200800",
    "end": "207700"
  },
  {
    "text": "So we're talking about\nthe probability of this particular event. Since this line has a slope of\nz, the height at this point is",
    "start": "207700",
    "end": "217170"
  },
  {
    "text": "equal to z. And so we can find the\nprobability of this event. It's just the area\nof this triangle.",
    "start": "217170",
    "end": "223260"
  },
  {
    "text": "And so the area is 1\ntimes z times 1/2. And we get the answer, z/2.",
    "start": "223260",
    "end": "228760"
  },
  {
    "text": " Now, is this answer\nalways correct?",
    "start": "228760",
    "end": "236220"
  },
  {
    "text": "Now, this answer is going to be\ncorrect only if the slope happens to be such that we get\na picture of this kind.",
    "start": "236220",
    "end": "245080"
  },
  {
    "text": "So when do we get a picture\nof this kind? When the slope is less than 1. If I consider a different slope,\na number, little z --",
    "start": "245080",
    "end": "253110"
  },
  {
    "text": "that happens to be a slope\nof that kind -- then the picture changes. And in that case, we\nget a picture of",
    "start": "253110",
    "end": "260579"
  },
  {
    "text": "this kind, let's say. So this is a line here\nof slope z, again.",
    "start": "260579",
    "end": "268495"
  },
  {
    "text": " And this is the second case in\nwhich our number, little z, is",
    "start": "268495",
    "end": "275790"
  },
  {
    "text": "bigger than 1. So how do we proceed? Once more, the cumulative is the\nprobability that the ratio",
    "start": "275790",
    "end": "283690"
  },
  {
    "text": "is less than or equal\nto that number. So it's the probability that\nwe fall below the red line.",
    "start": "283690",
    "end": "290650"
  },
  {
    "text": "So we're talking about the\nevent, about this event.",
    "start": "290650",
    "end": "296590"
  },
  {
    "text": "So to find the probability of\nthis event, we need to find the area of this red shape.",
    "start": "296590",
    "end": "302300"
  },
  {
    "text": "And one way of finding this area\nis to consider the whole area and subtract the area\nof this triangle.",
    "start": "302300",
    "end": "309560"
  },
  {
    "text": "So let's do it this way. It's going to be 1 minus the\narea of the triangle.",
    "start": "309560",
    "end": "315000"
  },
  {
    "text": "Now, what's the area\nof the triangle? It's 1/2 times this side, which\nis 1 times this side.",
    "start": "315000",
    "end": "324420"
  },
  {
    "text": "How big is that side? Well, if y and the slope is z,\nnow z is the ratio y over x.",
    "start": "324420",
    "end": "337130"
  },
  {
    "text": "So if y over x-- at this point we have\ny/x = z and y =1.",
    "start": "337130",
    "end": "346560"
  },
  {
    "text": "This means that z is 1/x. So the coordinate of\nthis point is 1/x.",
    "start": "346560",
    "end": "355080"
  },
  {
    "text": "And this means that\nwe're going to-- 1/z So here we get the\nfactor of 1/z.",
    "start": "355080",
    "end": "364390"
  },
  {
    "text": " And we're basically done.",
    "start": "364390",
    "end": "369440"
  },
  {
    "text": "I guess if you want to have a\ncomplete answer, you should also give the formula\nfor z less than 0.",
    "start": "369440",
    "end": "376770"
  },
  {
    "text": "What is the cumulative when\nz is less than 0, the probability that you get the\nratio that's negative?",
    "start": "376770",
    "end": "382870"
  },
  {
    "text": "Well, since our random variables\nare positive, there's no way that you can\nget a negative ratio.",
    "start": "382870",
    "end": "387890"
  },
  {
    "text": "So the cumulative down\nthere is equal to 0. So we can plot the cumulative.",
    "start": "387890",
    "end": "394870"
  },
  {
    "text": "And we can take its derivative\nin order to find the density. ",
    "start": "394870",
    "end": "405980"
  },
  {
    "text": "So the cumulative that\nwe got starts at 0, when z's are negative.",
    "start": "405980",
    "end": "412000"
  },
  {
    "text": "Then it starts going up\nin proportion to z, at",
    "start": "412000",
    "end": "419750"
  },
  {
    "text": "the slope of 1/2.  So this takes us up to 1.",
    "start": "419750",
    "end": "425770"
  },
  {
    "text": " And then it starts increasing\ntowards 1,",
    "start": "425770",
    "end": "434480"
  },
  {
    "text": "according to this function. When you let z go to infinity,\nthe cumulative is going to go to 1.",
    "start": "434480",
    "end": "440330"
  },
  {
    "text": "And it has a shape of, more\nor less, this kind. So now to get the density, we\njust take the derivative.",
    "start": "440330",
    "end": "449035"
  },
  {
    "start": "449035",
    "end": "456790"
  },
  {
    "text": "And the density is, of\ncourse, 0 down here. Up here the derivative\nis just 1/2.",
    "start": "456790",
    "end": "463950"
  },
  {
    "text": " And beyond that point we need to\ntake the derivative of this",
    "start": "463950",
    "end": "472470"
  },
  {
    "text": "expression. And the derivative is going to\nbe 1/2 times 1 over z-squared.",
    "start": "472470",
    "end": "478700"
  },
  {
    "text": "So it's going to be a\nshape of this kind. ",
    "start": "478700",
    "end": "489440"
  },
  {
    "text": "And we're done. So you see that problems\ninvolving functions of",
    "start": "489440",
    "end": "494820"
  },
  {
    "text": "multiple random variables are\nno harder than problems that deal with the functional of\na single random variable.",
    "start": "494820",
    "end": "502319"
  },
  {
    "text": "The general procedure is,\nagain, exactly the same. You first find the cumulative,\nand then you differentiate.",
    "start": "502320",
    "end": "508470"
  },
  {
    "text": "The only extra difficulty will\nbe that when you calculate the cumulative, you need to find\nthe probability of an event",
    "start": "508470",
    "end": "514570"
  },
  {
    "text": "that involves multiple\nrandom variables. And sometimes this could be\na little harder to do.",
    "start": "514570",
    "end": "520729"
  },
  {
    "text": "By the way, since we dealt\nwith this example, just a couple of questions.",
    "start": "520730",
    "end": "525920"
  },
  {
    "text": "What do you think is going to\nbe the expected value of the random variable Z?",
    "start": "525920",
    "end": "532720"
  },
  {
    "text": "Let's see, the expected value\nof the random variable Z is going to be the integral\nof z times the density.",
    "start": "532720",
    "end": "541120"
  },
  {
    "text": "And the density is equal to 1/2\nfor z going from 0 to 1.",
    "start": "541120",
    "end": "550950"
  },
  {
    "text": "And then there's another contribution from 1 to infinity. There the density is\n1/(2z-squared).",
    "start": "550950",
    "end": "557260"
  },
  {
    "text": " And we get the z, since we're\ndealing with expectations, dz.",
    "start": "557260",
    "end": "564630"
  },
  {
    "text": "So what is this integral?  Well, if you look here, you're\nintegrating 1/z, all the way",
    "start": "564630",
    "end": "575070"
  },
  {
    "text": "to infinity. 1/z has an integral, which\nis the logarithm of z.",
    "start": "575070",
    "end": "581550"
  },
  {
    "text": "And since the logarithm goes to\ninfinity, this means that this integral is\nalso infinite.",
    "start": "581550",
    "end": "587769"
  },
  {
    "text": "So the expectation of the random\nvariable Z is actually",
    "start": "587770",
    "end": "593640"
  },
  {
    "text": "infinite in this example. There's nothing wrong\nwith this. Lots of random variables have\ninfinite expectations.",
    "start": "593640",
    "end": "600500"
  },
  {
    "text": "If the tail of the density falls\nkind of slowly, as the",
    "start": "600500",
    "end": "606980"
  },
  {
    "text": "argument goes to infinity, then\nit may well turn out that you get an infinite integral.",
    "start": "606980",
    "end": "612430"
  },
  {
    "text": "So that's just how\nthings often are. Nothing strange about it.",
    "start": "612430",
    "end": "619060"
  },
  {
    "text": "And now, since we are still in\nthis example, let me ask another question.",
    "start": "619060",
    "end": "625680"
  },
  {
    "text": "Would we reason, on the average,\nwould it be true that the expected value of Z --",
    "start": "625680",
    "end": "631959"
  },
  {
    "text": "remember that Z is the ratio\nY/X -- could it be that the expected value of Z\nis this number?",
    "start": "631960",
    "end": "639850"
  },
  {
    "text": " Or could it be that it's\nequal to this number?",
    "start": "639850",
    "end": "648460"
  },
  {
    "start": "648460",
    "end": "653670"
  },
  {
    "text": "Or could it be that it's\nnone of the above? ",
    "start": "653670",
    "end": "661139"
  },
  {
    "text": "OK, so how many people think\nthis is correct?",
    "start": "661140",
    "end": "666295"
  },
  {
    "start": "666295",
    "end": "672500"
  },
  {
    "text": "Small number. How many people think\nthis is correct? ",
    "start": "672500",
    "end": "678290"
  },
  {
    "text": "Slightly bigger, but still\na small number. And how many people think\nthis is correct?",
    "start": "678290",
    "end": "684660"
  },
  {
    "text": "OK, that's-- this one wins the vote. OK, let's see.",
    "start": "684660",
    "end": "692570"
  },
  {
    "text": "This one is not correct, just\nbecause there's no reason it should be correct.",
    "start": "692570",
    "end": "699100"
  },
  {
    "text": "So, in general, you cannot\nreason on the average.",
    "start": "699100",
    "end": "704420"
  },
  {
    "text": "The expected value of a function\nis not the same as the same function of the\nexpected values.",
    "start": "704420",
    "end": "710950"
  },
  {
    "text": "This is only true if you're\ndealing with linear functions of random variables. So this is not--",
    "start": "710950",
    "end": "716340"
  },
  {
    "text": "this turns out to\nnot be correct. How about this one? Well, X and Y are independent,\nby assumption.",
    "start": "716340",
    "end": "725820"
  },
  {
    "text": "So 1/X and Y are also\nindependent.",
    "start": "725820",
    "end": "730910"
  },
  {
    "text": " Why is this? Independence means that one\nrandom variable does not",
    "start": "730910",
    "end": "737150"
  },
  {
    "text": "convey any information\nabout the other. So Y doesn't give you any\ninformation about X. So Y",
    "start": "737150",
    "end": "744100"
  },
  {
    "text": "doesn't give you any information\nabout 1/X. Or to put it differently, if two\nrandom variables are",
    "start": "744100",
    "end": "750139"
  },
  {
    "text": "independent, functions of each\none of those random variables",
    "start": "750140",
    "end": "756170"
  },
  {
    "text": "are also independent. If X is independent from\nY, then g(X) is",
    "start": "756170",
    "end": "761360"
  },
  {
    "text": "independent of h(Y). So this applies to this case. These two random variables\nare independent.",
    "start": "761360",
    "end": "767780"
  },
  {
    "text": "And since they are independent,\nthis means that the expected value of their\nproduct is equal to the",
    "start": "767780",
    "end": "775069"
  },
  {
    "text": "product of the expected\nvalues. So this relation actually\nis true.",
    "start": "775070",
    "end": "782950"
  },
  {
    "text": "And therefore, this\nis not true. OK. ",
    "start": "782950",
    "end": "794690"
  },
  {
    "text": "Now, let's move on. We have this general procedure\nof finding the derived",
    "start": "794690",
    "end": "802420"
  },
  {
    "text": "distribution by going through\nthe cumulative. Are there some cases where\nwe can have a shortcut?",
    "start": "802420",
    "end": "810000"
  },
  {
    "text": "Turns out that there is a\nspecial case or a special structure in which we can get\ndirectly from densities to",
    "start": "810000",
    "end": "818339"
  },
  {
    "text": "densities using directly\njust a formula. And in that case, we don't\nhave to go through the",
    "start": "818340",
    "end": "824589"
  },
  {
    "text": "cumulative. And this case is also\ninteresting, because it gives us some insight about how one\ndensity changes to a different",
    "start": "824590",
    "end": "832810"
  },
  {
    "text": "density and what affects the\nshape of those densities. So the case where things easy\nis when the transformation",
    "start": "832810",
    "end": "840430"
  },
  {
    "text": "from one random variable to\nthe other is a strictly monotonic one. So there's a one-to-one relation\nbetween x's and y's.",
    "start": "840430",
    "end": "850629"
  },
  {
    "text": "Here we can reason directly in\nterms of densities by thinking in terms of probabilities\nof small intervals.",
    "start": "850630",
    "end": "857980"
  },
  {
    "text": "So let's look at the small\ninterval on the x-axis, like",
    "start": "857980",
    "end": "863370"
  },
  {
    "text": "this one, when X ranges from-- where capital X ranges\nfrom a small x to a",
    "start": "863370",
    "end": "870389"
  },
  {
    "text": "small x plus delta. So this is a small interval\nof length delta.",
    "start": "870390",
    "end": "876480"
  },
  {
    "text": "Whenever X happens to fall in\nthis interval, the random variable Y is going\nto fall in a",
    "start": "876480",
    "end": "882720"
  },
  {
    "text": "corresponding interval up there. So up there we have a\ncorresponding interval.",
    "start": "882720",
    "end": "890839"
  },
  {
    "text": "And these two intervals, the\nred and the blue interval--",
    "start": "890840",
    "end": "895890"
  },
  {
    "text": "this is the blue interval. And that's the red interval.",
    "start": "895890",
    "end": "901120"
  },
  {
    "text": "These two intervals should have\nthe same probability. They're exactly the\nsame event.",
    "start": "901120",
    "end": "908120"
  },
  {
    "text": "When X falls here, g(X) happens\nto fall in there.",
    "start": "908120",
    "end": "913529"
  },
  {
    "text": "So we can sort of say that the\nprobability of this little interval is the same\nas the probability of that little interval.",
    "start": "913530",
    "end": "920050"
  },
  {
    "text": "And we know that probabilities\nof little intervals have something to do with\ndensities.",
    "start": "920050",
    "end": "925560"
  },
  {
    "text": "So what is the probability\nof this little interval? It's the density of the random\nvariable X, at this point,",
    "start": "925560",
    "end": "932490"
  },
  {
    "text": "times the length of\nthe interval. How about the probability\nof that interval?",
    "start": "932490",
    "end": "938990"
  },
  {
    "text": "It's going to be the density of\nthe random variable Y times",
    "start": "938990",
    "end": "945070"
  },
  {
    "text": "the length of that\nlittle interval. Now, this interval\nhas length delta.",
    "start": "945070",
    "end": "950310"
  },
  {
    "text": "Does that mean that\nthis interval also has length delta? Well, not necessarily.",
    "start": "950310",
    "end": "955440"
  },
  {
    "text": "The length of this interval has\nsomething to do with the slope of your function g.",
    "start": "955440",
    "end": "961829"
  },
  {
    "text": "So slope is dy by dx. Is how much-- the slope tells\nyou how big is the y interval",
    "start": "961830",
    "end": "969700"
  },
  {
    "text": "when you take an interval\nx of a certain length. So the slope is what multiplies\nthe length of this",
    "start": "969700",
    "end": "977180"
  },
  {
    "text": "interval to give you the length\nof that interval. So the length of this interval\nis delta times the slope of",
    "start": "977180",
    "end": "985149"
  },
  {
    "text": "your function.  So the length of the interval\nis delta times the slope of",
    "start": "985150",
    "end": "995400"
  },
  {
    "text": "the function, approximately. So the probability of this\ninterval is going to be the",
    "start": "995400",
    "end": "1001320"
  },
  {
    "text": "density of Y times the length\nof the interval that we are",
    "start": "1001320",
    "end": "1006790"
  },
  {
    "text": "considering. So this gives us a relation\nbetween the density of X,",
    "start": "1006790",
    "end": "1012280"
  },
  {
    "text": "evaluated at this point, to the\ndensity of Y, evaluated at that point.",
    "start": "1012280",
    "end": "1018140"
  },
  {
    "text": "The two densities are\nclosely related. If these x's are very likely\nto occur, then this is big,",
    "start": "1018140",
    "end": "1025130"
  },
  {
    "text": "which means that that density\nwill also be big. If these x's are very likely to\noccur, then those y's are",
    "start": "1025130",
    "end": "1031550"
  },
  {
    "text": "also very likely to occur. But there's also another\nfactor that comes in. And that's the slope\nof the function at",
    "start": "1031550",
    "end": "1038660"
  },
  {
    "text": "this particular point. So we have this relation between\nthe two densities.",
    "start": "1038660",
    "end": "1044500"
  },
  {
    "text": "Now, in interpreting this\nequation, you need to make sure what's the relation between\nthe two variables.",
    "start": "1044500",
    "end": "1050900"
  },
  {
    "text": "I have both little x's\nand little y's. Well, this formula is true for\nan (x,y) pair, that they're",
    "start": "1050900",
    "end": "1059330"
  },
  {
    "text": "related according to this\nparticular function. So if I fix an x and consider\nthe corresponding y, then the",
    "start": "1059330",
    "end": "1068000"
  },
  {
    "text": "densities at those x's and\ncorresponding y's will be related by that formula.",
    "start": "1068000",
    "end": "1074419"
  },
  {
    "text": "Now, in the end, you want to\ncome up with a formula that just gives you the density\nof Y as a function of y.",
    "start": "1074420",
    "end": "1081520"
  },
  {
    "text": "And that means that you need to eliminate x from the picture. So let's see how that would\ngo in an example.",
    "start": "1081520",
    "end": "1091140"
  },
  {
    "text": "So suppose that we're dealing\nwith the function y equal to x",
    "start": "1091140",
    "end": "1097640"
  },
  {
    "text": "cubed, in which case our\nfunction, g(x), is the function x cubed.",
    "start": "1097640",
    "end": "1103180"
  },
  {
    "text": " And if x cubed is equal to a\nlittle y, If we have a pair of",
    "start": "1103180",
    "end": "1111980"
  },
  {
    "text": "x's and y's that are related\nthis way, then this means that",
    "start": "1111980",
    "end": "1118350"
  },
  {
    "text": "x is going to be the\ncubic root of y. So this is the formula that\ntakes us back from y's to x's.",
    "start": "1118350",
    "end": "1126549"
  },
  {
    "text": "This is the direct function from\nx, how to construct y.",
    "start": "1126550",
    "end": "1132940"
  },
  {
    "text": "This is essentially the inverse\nfunction that tells us, from a given y what is\nthe corresponding x.",
    "start": "1132940",
    "end": "1139460"
  },
  {
    "text": "Now, if we write this formula,\nit tells us that the density",
    "start": "1139460",
    "end": "1144649"
  },
  {
    "text": "at the particular x is going\nto be the density at the corresponding y times the slope\nof the function at the",
    "start": "1144650",
    "end": "1152390"
  },
  {
    "text": "particular x that we\nare considering. The slope of the function\nis 3x squared. ",
    "start": "1152390",
    "end": "1160870"
  },
  {
    "text": "Now, we want to end up with a\nformula for the density of Y.",
    "start": "1160870",
    "end": "1166590"
  },
  {
    "text": "So I'm going to take this\nfactor, send it to the other side. But since I want it to be a\nfunction of y, I want to",
    "start": "1166590",
    "end": "1175300"
  },
  {
    "text": "eliminate the x's. And I'm going to eliminate\nthe x's using this correspondence here.",
    "start": "1175300",
    "end": "1181289"
  },
  {
    "text": "So I'm going to get\nthe density of X evaluated at y to the 1/3.",
    "start": "1181290",
    "end": "1187830"
  },
  {
    "text": "And then this factor in the\ndenominator, it's 1/(3y to the power 2/3). ",
    "start": "1187830",
    "end": "1195710"
  },
  {
    "text": "So we end up finally with the\nformula for the density of the random variable Y.",
    "start": "1195710",
    "end": "1202900"
  },
  {
    "text": "And this is the same answer that\nyou would get if you go through this exercise using the\ncumulative distribution",
    "start": "1202900",
    "end": "1210030"
  },
  {
    "text": "function method. You end up getting\nthe same answer. But here we sort of\nget it directly.",
    "start": "1210030",
    "end": "1215205"
  },
  {
    "text": " Just to get a little more\ninsight as to why",
    "start": "1215205",
    "end": "1224570"
  },
  {
    "text": "the slope comes in-- ",
    "start": "1224570",
    "end": "1229960"
  },
  {
    "text": "suppose that we have a function\nlike this one.",
    "start": "1229960",
    "end": "1235070"
  },
  {
    "text": " So the function is sort of flat,\nthen moves quickly, and",
    "start": "1235070",
    "end": "1245110"
  },
  {
    "text": "then becomes flat again. What should be --",
    "start": "1245110",
    "end": "1250720"
  },
  {
    "text": "and suppose that X has some kind\nof reasonable density, some kind of flat density.",
    "start": "1250720",
    "end": "1257180"
  },
  {
    "text": "Suppose that X is a pretty\nuniform random variable. What's going to happen to\nthe random variable Y?",
    "start": "1257180",
    "end": "1264770"
  },
  {
    "text": "What kind of distribution\nshould it have? ",
    "start": "1264770",
    "end": "1274670"
  },
  {
    "text": "What are the typical values\nof the random variable Y? Either x falls here, and y is\na very small number, or--",
    "start": "1274670",
    "end": "1286960"
  },
  {
    "text": "let's take that number here\nto be -- let's say 2 -- or x falls in this range, and\ny takes a value close to 2.",
    "start": "1286960",
    "end": "1297289"
  },
  {
    "text": "And there's a small chance that\nx's will be somewhere in the middle, in which case y\ntakes intermediate values.",
    "start": "1297290",
    "end": "1304350"
  },
  {
    "text": "So what kind of shape do\nyou expect for the distribution of Y? There's going to be a fair\namount of probability that Y",
    "start": "1304350",
    "end": "1311900"
  },
  {
    "text": "takes values close to 0. There's a small probability\nthat Y takes",
    "start": "1311900",
    "end": "1318480"
  },
  {
    "text": "intermediate values. That corresponds to the case\nwhere x falls in here.",
    "start": "1318480",
    "end": "1323870"
  },
  {
    "text": "That's not a lot\nof probability. So the probability that Y takes\nvalues between 0 and 2,",
    "start": "1323870",
    "end": "1331280"
  },
  {
    "text": "that's kind of small. But then there's a lot of x's\nthat produces y's that are",
    "start": "1331280",
    "end": "1336860"
  },
  {
    "text": "close to 2. So there's a significant\nprobability that Y would take",
    "start": "1336860",
    "end": "1342110"
  },
  {
    "text": "values that are close to 2. So you-- the density of Y would have\na shape of this kind.",
    "start": "1342110",
    "end": "1351300"
  },
  {
    "text": "By looking at this picture, you\ncan tell that it's most likely that either x will fall\nhere or x will fall there.",
    "start": "1351300",
    "end": "1359630"
  },
  {
    "text": "So the g(x) is most likely\nto be close to 0 or to be close to 2.",
    "start": "1359630",
    "end": "1366290"
  },
  {
    "text": "So since y is most likely to be\nclose to 0 or close to most",
    "start": "1366290",
    "end": "1371420"
  },
  {
    "text": "of the probability\nof y is here. And there's a small probability of being in between.",
    "start": "1371420",
    "end": "1376809"
  },
  {
    "text": "Notice that the y's that get a\nlot of probability are those",
    "start": "1376810",
    "end": "1382330"
  },
  {
    "text": "y's associated with flats\nregions off your g function.",
    "start": "1382330",
    "end": "1387490"
  },
  {
    "text": "When the g function is flat,\nthat gives you big densities for Y.",
    "start": "1387490",
    "end": "1392500"
  },
  {
    "text": "So the density of Y is inversely\nproportional to the slope of the function.",
    "start": "1392500",
    "end": "1398350"
  },
  {
    "text": "And that's what you\nget from here. The density of Y is-- send that term to the other\nside-- is inversely",
    "start": "1398350",
    "end": "1405430"
  },
  {
    "text": "proportional to the slope of\nthe function that you're dealing with. ",
    "start": "1405430",
    "end": "1412755"
  },
  {
    "text": "OK, so this formula works nicely\nfor the case where the function is one-to-one.",
    "start": "1412755",
    "end": "1418470"
  },
  {
    "text": "So we can have a unique\nassociation between x's and y's and through an inverse\nfunction, from y's to x's.",
    "start": "1418470",
    "end": "1427500"
  },
  {
    "text": "It works for the monotonically\nincreasing case. It also works for the\nmonotonically decreasing case.",
    "start": "1427500",
    "end": "1433660"
  },
  {
    "text": "In the monotonically decreasing\ncase, the only change that you need to do is to\ntake the absolute value of",
    "start": "1433660",
    "end": "1439050"
  },
  {
    "text": "the slope, instead of\nthe slope itself. ",
    "start": "1439050",
    "end": "1456340"
  },
  {
    "text": "OK, now, here's another example\nor a special case.",
    "start": "1456340",
    "end": "1462480"
  },
  {
    "text": "Let's talk about the most\ninteresting case that involves",
    "start": "1462480",
    "end": "1467520"
  },
  {
    "text": "a function of two random\nvariables. And this is the case where we\nhave two independent, random",
    "start": "1467520",
    "end": "1474460"
  },
  {
    "text": "variables, and we want to\nfind the distribution of the sum of the two.",
    "start": "1474460",
    "end": "1480149"
  },
  {
    "text": "We're really interested in\nthe continuous case. But as a warm-up, it's useful\nto look at the discrete case",
    "start": "1480150",
    "end": "1485540"
  },
  {
    "text": "first of discrete random\nvariables. Let's say we want to find the\nprobability that the sum of X",
    "start": "1485540",
    "end": "1492740"
  },
  {
    "text": "and Y is equal to a\nparticular number. And to illustrate this,\nlet's take that number",
    "start": "1492740",
    "end": "1498570"
  },
  {
    "text": "to be equal to 3. What's the probability that\nthe sum of the two random variables is equal to 3?",
    "start": "1498570",
    "end": "1504700"
  },
  {
    "text": "To find the probability that\nthe sum is equal to 3, you consider all possible ways that\nyou can get the sum of 3.",
    "start": "1504700",
    "end": "1511570"
  },
  {
    "text": "And the different ways are the\npoints in this picture. And they correspond to a line\nthat goes this way.",
    "start": "1511570",
    "end": "1518100"
  },
  {
    "text": "So the probability that the\nsum is equal to a certain number is the probability\nthat --",
    "start": "1518100",
    "end": "1524550"
  },
  {
    "text": "is the sum of the\nprobabilities of all of those points. What is a typical point\nin this picture?",
    "start": "1524550",
    "end": "1531190"
  },
  {
    "text": "In a typical point, the\nrandom variable X takes a certain value.",
    "start": "1531190",
    "end": "1536490"
  },
  {
    "text": "And Y takes the value that's\nneeded so that the sum is equal to W. Any combination of\nan x with a w minus x, any",
    "start": "1536490",
    "end": "1547650"
  },
  {
    "text": "such combination gives\nyou a sum of w. So the probability that the sum\nis w is the sum over all",
    "start": "1547650",
    "end": "1554950"
  },
  {
    "text": "possible x's. That's over all these points of\nthe probability that we get a certain x.",
    "start": "1554950",
    "end": "1561050"
  },
  {
    "text": "Let's say x equals 2 times the\ncorresponding probability that random variable Y takes\nthe value 1.",
    "start": "1561050",
    "end": "1568570"
  },
  {
    "text": "And why am I multiplying\nprobabilities here? That's where we use the\nassumption that the two random",
    "start": "1568570",
    "end": "1574070"
  },
  {
    "text": "variables are independent. So the probability that X takes\na certain value and Y",
    "start": "1574070",
    "end": "1579610"
  },
  {
    "text": "takes the complementary value,\nthat probability is the product of two probabilities\nbecause of independence.",
    "start": "1579610",
    "end": "1586120"
  },
  {
    "text": "And when we write that into our\nusual PMF notation, it's a formula of this kind.",
    "start": "1586120",
    "end": "1591510"
  },
  {
    "text": "So this formula is called\nthe convolution formula. It's an operation that takes\none PMF and another PMF-- p",
    "start": "1591510",
    "end": "1602030"
  },
  {
    "text": "we're given the PMF's\nof X and Y -- and produces a new PMF.",
    "start": "1602030",
    "end": "1607640"
  },
  {
    "text": "So think of this formula as\ngiving you a transformation. You take two PMF's, you do\nsomething with them, and you",
    "start": "1607640",
    "end": "1613570"
  },
  {
    "text": "obtain a new PMF. This procedure, what this\nformula does is --",
    "start": "1613570",
    "end": "1619710"
  },
  {
    "text": "nicely illustrated sort\nof by mechanically. So let me show you a picture\nhere and illustrate how the",
    "start": "1619710",
    "end": "1628640"
  },
  {
    "text": "mechanics go, in general. So you don't have these slides,\nbut let's just reason",
    "start": "1628640",
    "end": "1636790"
  },
  {
    "text": "through it. So suppose that you are\ngiven the PMF of X,",
    "start": "1636790",
    "end": "1642220"
  },
  {
    "text": "and it has this shape. You're given the PMF of\nY. It has this shape. And somehow we are going\nto do this calculation.",
    "start": "1642220",
    "end": "1648790"
  },
  {
    "text": "Now, we need to do this\ncalculation for every value of W, in order to get the PMF of\nW. Let's start by doing the",
    "start": "1648790",
    "end": "1657190"
  },
  {
    "text": "calculation just for one case. Suppose the W is equal to 0, in\nwhich case we need to find",
    "start": "1657190",
    "end": "1663870"
  },
  {
    "text": "the sum of Px(x) and Py(-x). ",
    "start": "1663870",
    "end": "1670789"
  },
  {
    "text": "How do you do this calculation\ngraphically? It involves the PMF of X. But it\ninvolves the PMF of Y, with",
    "start": "1670790",
    "end": "1679550"
  },
  {
    "text": "the argument reversed. So how do we plot this?",
    "start": "1679550",
    "end": "1684770"
  },
  {
    "text": "Well, in order to reverse the\nargument, what you need is to take this PMF and flip it.",
    "start": "1684770",
    "end": "1691230"
  },
  {
    "text": "So that's where it's handy\nto have a pair of scissors with you. So you cut this down.",
    "start": "1691230",
    "end": "1700799"
  },
  {
    "text": "And so now you take the PMF\nof the random variable Y",
    "start": "1700800",
    "end": "1706360"
  },
  {
    "text": "and just flip it. So what you see here is this\nfunction where the argument is",
    "start": "1706360",
    "end": "1713830"
  },
  {
    "text": "being reversed. And then what do we do? We cross-multiply\nthe two plots.",
    "start": "1713830",
    "end": "1719080"
  },
  {
    "text": "Any entry here gets multiplied\nwith the corresponding entry there. And we consider all those\nproducts and add them up.",
    "start": "1719080",
    "end": "1726549"
  },
  {
    "text": "In this particular case, the\nflipped PMF doesn't have any overlap with the PMF of X. So\nwe're going to get an answer",
    "start": "1726550",
    "end": "1733850"
  },
  {
    "text": "that's equal to 0. So for w's equal to 0, the Pw is\ngoing to be equal to 0, in",
    "start": "1733850",
    "end": "1743320"
  },
  {
    "text": "this particular plot. Now if we have a different\nvalue of w --",
    "start": "1743320",
    "end": "1748760"
  },
  {
    "text": "oops. If we have a different value\nof the argument w, then we",
    "start": "1748760",
    "end": "1754670"
  },
  {
    "text": "have here the PMF of Y that's\nflipped and shifted by an",
    "start": "1754670",
    "end": "1760530"
  },
  {
    "text": "amount of w. So the correct picture of what\nyou do is to take this and",
    "start": "1760530",
    "end": "1765929"
  },
  {
    "text": "displace it by a certain\namount of w. So here, how much\ndid I shift it?",
    "start": "1765930",
    "end": "1773430"
  },
  {
    "text": "I shifted it until one\nfalls just below 4.",
    "start": "1773430",
    "end": "1780640"
  },
  {
    "text": "So I have shifted by a\ntotal amount of 5. So 0 falls under 5, whereas\n0 initially was under 0.",
    "start": "1780640",
    "end": "1790680"
  },
  {
    "text": "So I'm shifting it by 5 units. And I'm now going to\ncross-multiply and add.",
    "start": "1790680",
    "end": "1796320"
  },
  {
    "text": "Does this give us\nthe correct-- does it do the correct thing? Yes, because a typical term will\nbe the probability that",
    "start": "1796320",
    "end": "1803700"
  },
  {
    "text": "this random variable is 3 times\nthe probability that this random variable is 2.",
    "start": "1803700",
    "end": "1809090"
  },
  {
    "text": "That's a particular way that\nyou can get a sum of 5. If you see here, the way that\nthings are aligned, it gives",
    "start": "1809090",
    "end": "1816100"
  },
  {
    "text": "you all the different ways that\nyou can get the sum of 5. You can get the sum of 5 by\nhaving 1 + 4, or 2 + 3, or 3 +",
    "start": "1816100",
    "end": "1823756"
  },
  {
    "text": "2, or 4 + 1. You need to add the\nprobabilities of all those combinations.",
    "start": "1823756",
    "end": "1829340"
  },
  {
    "text": "So you take this times that. That's one product term. Then this times 0,\nthis times that.",
    "start": "1829340",
    "end": "1838220"
  },
  {
    "text": "And so 1-- you cross-- you find all the products of the\ncorresponding terms, and",
    "start": "1838220",
    "end": "1844710"
  },
  {
    "text": "you add them together. So it's a kind of handy\nmechanical procedure for doing",
    "start": "1844710",
    "end": "1850139"
  },
  {
    "text": "this calculation, especially\nwhen the PMF's are given to you in terms of a picture.",
    "start": "1850140",
    "end": "1855850"
  },
  {
    "text": "So the summary of these\nmechanics are just what we did, is that you put the PMF's\non top of each other.",
    "start": "1855850",
    "end": "1863530"
  },
  {
    "text": "You take the PMF of\nY. You flip it. And for any particular w that\nyou're interested in, you take",
    "start": "1863530",
    "end": "1870160"
  },
  {
    "text": "this flipped PMF and shift\nit by an amount of w. Given this particular shift for\na particular value of w,",
    "start": "1870160",
    "end": "1877120"
  },
  {
    "text": "you cross-multiply terms and\nthen accumulate them or add them together.",
    "start": "1877120",
    "end": "1883280"
  },
  {
    "text": "What would you expect to happen\nin the continuous case? Well, the story is familiar.",
    "start": "1883280",
    "end": "1888600"
  },
  {
    "text": "In the continuous case, pretty\nmuch, almost always things work out the same way,\nexcept that we",
    "start": "1888600",
    "end": "1894730"
  },
  {
    "text": "replace PMF's by PDF's. And we replace sums\nby integrals.",
    "start": "1894730",
    "end": "1902930"
  },
  {
    "text": "So there shouldn't be any\nsurprise here that you get a formula of this kind.",
    "start": "1902930",
    "end": "1909680"
  },
  {
    "text": "The density of W can be obtained\nfrom the density of X and the density of Y by\ncalculating this integral.",
    "start": "1909680",
    "end": "1918740"
  },
  {
    "text": "Essentially, what this integral\ndoes is it fits a particular w of interest.",
    "start": "1918740",
    "end": "1925129"
  },
  {
    "text": "We're interested in the\nprobability that the random variable, capital W, takes a\nvalue equal to little w or",
    "start": "1925130",
    "end": "1933160"
  },
  {
    "text": "values close to it. So this corresponds to the\nevent, which is this particular line on the\ntwo-dimensional space.",
    "start": "1933160",
    "end": "1941120"
  },
  {
    "text": "So we need to find\nthe sort of odd probabilities along that line. But since the setting is\ncontinuous, we will not add",
    "start": "1941120",
    "end": "1948620"
  },
  {
    "text": "probabilities. We're going to integrate. And for any typical point in\nthis picture, the probability",
    "start": "1948620",
    "end": "1955430"
  },
  {
    "text": "of obtaining an outcome in this\nneighborhood is the-- has something to do with the\ndensity of that particular x",
    "start": "1955430",
    "end": "1963460"
  },
  {
    "text": "and the density of the\nparticular y that would compliment x, in order\nto form a sum of w.",
    "start": "1963460",
    "end": "1970750"
  },
  {
    "text": "So this integral that we have\nhere is really an integral over this particular line.",
    "start": "1970750",
    "end": "1979382"
  },
  {
    "text": "OK, so I'm going to\nskip the formal derivation of this result. There's a couple of derivations\nin the text.",
    "start": "1979382",
    "end": "1986830"
  },
  {
    "text": "And the one which is outlined\nhere is yet a third derivation. But the easiest way to make\nsense of this formula is to",
    "start": "1986830",
    "end": "1994300"
  },
  {
    "text": "consider what happens in\nthe discrete case. So for the rest of the lecture\nwe're going to consider a few",
    "start": "1994300",
    "end": "2002010"
  },
  {
    "text": "extra, more miscellaneous\ntopics, a few remarks, and a",
    "start": "2002010",
    "end": "2007280"
  },
  {
    "text": "few more definitions. So let's change-- flip a page and consider\nthe next mini topic.",
    "start": "2007280",
    "end": "2015325"
  },
  {
    "text": " There's not going to be anything\ndeep here, but just",
    "start": "2015325",
    "end": "2021370"
  },
  {
    "text": "something that's worth\nbeing familiar with. If you have two independent,\nnormal random variables with",
    "start": "2021370",
    "end": "2027570"
  },
  {
    "text": "certain parameters, the question\nis, what does the joined PDF look like?",
    "start": "2027570",
    "end": "2035160"
  },
  {
    "text": "So if they're independent, by\ndefinition the joint PDF is the product of the\nindividual PDF's.",
    "start": "2035160",
    "end": "2041760"
  },
  {
    "text": "And the PDF's each one\nof them involves an exponential of something.",
    "start": "2041760",
    "end": "2047029"
  },
  {
    "text": "The product of two exponentials\nis the exponential of the sum.",
    "start": "2047030",
    "end": "2053388"
  },
  {
    "text": "So you just add the exponents. So this is the formula\nfor the joint PDF. Now, you look at that formula\nand you ask, what",
    "start": "2053389",
    "end": "2060790"
  },
  {
    "text": "does it look like? OK, you can understand it, a\nfunction of two variables by",
    "start": "2060790",
    "end": "2067780"
  },
  {
    "text": "thinking about the contours\nof this function. Look at the points at\nwhich the function",
    "start": "2067780",
    "end": "2072850"
  },
  {
    "text": "takes a constant value. Where is it? When is it constant? What's the shape of\nthe set of points",
    "start": "2072850",
    "end": "2080149"
  },
  {
    "text": "where this is a constant? So consider all x's and y's for\nwhich this expression here",
    "start": "2080150",
    "end": "2086610"
  },
  {
    "text": "is a constant, that this\nexpression here is a constant. What kind of shape is this?",
    "start": "2086610",
    "end": "2093250"
  },
  {
    "text": "This is an ellipse. And it's an ellipse that's\ncentered at--",
    "start": "2093250",
    "end": "2101880"
  },
  {
    "text": "it's centered at mu x, mu y. These are the means of the\ntwo random variables.",
    "start": "2101880",
    "end": "2109760"
  },
  {
    "text": "If those sigmas were equal,\nthat ellipse would be actually a circle.",
    "start": "2109760",
    "end": "2116970"
  },
  {
    "text": "And you would get contours\nof this kind. But if, on the other hand, the\nsigmas are different, you're",
    "start": "2116970",
    "end": "2123869"
  },
  {
    "text": "going to get an ellipse that\nhas contours of this kind.",
    "start": "2123870",
    "end": "2129900"
  },
  {
    "text": "So if my contours are\nof this kind, that corresponds to what?",
    "start": "2129900",
    "end": "2135819"
  },
  {
    "text": "Sigma x being bigger than\nsigma y or vice versa. ",
    "start": "2135820",
    "end": "2142760"
  },
  {
    "text": "OK, contours of this kind\nbasically tell you that X is",
    "start": "2142760",
    "end": "2147970"
  },
  {
    "text": "more likely to be spread out\nthan Y. So the range of",
    "start": "2147970",
    "end": "2153609"
  },
  {
    "text": "possible x's is bigger. And X out here is as likely\nas a Y up there.",
    "start": "2153610",
    "end": "2164610"
  },
  {
    "text": "So big X's have roughly the same\nprobability as certain smaller y's.",
    "start": "2164610",
    "end": "2170260"
  },
  {
    "text": "So in a picture of this kind,\nthe variance of X is going to be bigger than the\nvariance of Y.",
    "start": "2170260",
    "end": "2177710"
  },
  {
    "text": "So depending on how these\nvariances compare with each other, that's going\nto determine the shape of the ellipse.",
    "start": "2177710",
    "end": "2184180"
  },
  {
    "text": "If the variance of Y we're\nbigger, then your ellipse would be the other way. It would be elongated in\nthe other dimension.",
    "start": "2184180",
    "end": "2192400"
  },
  {
    "text": "Just visualize it\na little more. Let me throw at you a\nparticular picture. This is one--",
    "start": "2192400",
    "end": "2199820"
  },
  {
    "text": "this is a picture of\none special case. Here, I think, the variances\nare equal.",
    "start": "2199820",
    "end": "2206600"
  },
  {
    "text": "That's the kind of shape\nthat you get. It looks like a two-dimensional\nbell. So remember, for a normal random\nvariables, for a single",
    "start": "2206600",
    "end": "2214700"
  },
  {
    "text": "random variable you get a\nPDF that's bell shaped. That's just a bell-shaped\ncurve.",
    "start": "2214700",
    "end": "2220359"
  },
  {
    "text": "In the two-dimensional case, we\nget the joint PDF, which is bell shaped again.",
    "start": "2220360",
    "end": "2225960"
  },
  {
    "text": "And now it looks more like a\nreal bell, the way it would be laid out in ordinary space.",
    "start": "2225960",
    "end": "2232550"
  },
  {
    "text": "And if you look at the contours\nof this function, the places where the function is\nequal, the typcial contour",
    "start": "2232550",
    "end": "2238950"
  },
  {
    "text": "would have this shape here. And it would be an ellipse. And in this case, actually, it\nwill be more like a circle.",
    "start": "2238950",
    "end": "2248320"
  },
  {
    "text": "So these would be the different\ncontours for different--",
    "start": "2248320",
    "end": "2253900"
  },
  {
    "text": " so the contours are\nplaces where the joint PDF is a constant.",
    "start": "2253900",
    "end": "2260550"
  },
  {
    "text": "When you change the value of\nthat constant, you get the different contours. And the PDF is, of course,\ncentered around the mean of",
    "start": "2260550",
    "end": "2270790"
  },
  {
    "text": "the two random variables. So in this particular case,\nsince the bell is centered",
    "start": "2270790",
    "end": "2275970"
  },
  {
    "text": "around the (0, 0) vector, this\nis a plot of a bivariate normal with 0 means.",
    "start": "2275970",
    "end": "2282245"
  },
  {
    "text": " OK, there's--",
    "start": "2282245",
    "end": "2288680"
  },
  {
    "text": "bivariate normals are also\ninteresting when your bell is",
    "start": "2288680",
    "end": "2294990"
  },
  {
    "text": "oriented differently in space. We talked about ellipses that\nare this way, ellipses that",
    "start": "2294990",
    "end": "2301090"
  },
  {
    "text": "are this way. You could imagine also bells\nthat you take them, you squash",
    "start": "2301090",
    "end": "2306799"
  },
  {
    "text": "them somehow, so that they\nbecome narrow in one dimension and then maybe rotate them.",
    "start": "2306800",
    "end": "2312700"
  },
  {
    "text": "So if you had-- we're not going to go into this\nsubject, but if you had a joint pdf whose contours were\nlike this, what would that",
    "start": "2312700",
    "end": "2326580"
  },
  {
    "text": "correspond to? Would your x's and y's\nbe independent? No.",
    "start": "2326580",
    "end": "2331720"
  },
  {
    "text": "This would indicate that there's\na relation between the x's and the y's. That is, when you have bigger\nx's, you would expect to also",
    "start": "2331720",
    "end": "2339280"
  },
  {
    "text": "get bigger y's. So it would be a case of\ndependent normals.",
    "start": "2339280",
    "end": "2344530"
  },
  {
    "text": "And we're coming back to\nthis point in a second. Before we get to that point in\na second that has to do with",
    "start": "2344530",
    "end": "2353710"
  },
  {
    "text": "the dependencies between the\nrandom variables, let's just do another digression. If we have our two normals that\nare independent, as we",
    "start": "2353710",
    "end": "2363700"
  },
  {
    "text": "discussed here, we can go and\napply the formula, the convolution formula that we\nwere just discussing.",
    "start": "2363700",
    "end": "2371770"
  },
  {
    "text": "Suppose you want to find the\ndistribution of the sum of these two independent normals.",
    "start": "2371770",
    "end": "2377160"
  },
  {
    "text": "How do you do this? There is a closed-form formula\nfor the density of the sum,",
    "start": "2377160",
    "end": "2382730"
  },
  {
    "text": "which is this one. We do have formulas for the\ndensity of X and the density of Y, because both of them are\nnormal, random variables.",
    "start": "2382730",
    "end": "2390840"
  },
  {
    "text": "So you need to calculate this\nparticular integral here. It's an integral with\nrespect to x.",
    "start": "2390840",
    "end": "2397300"
  },
  {
    "text": "And you have to calculate\nthis integral for any given value of w.",
    "start": "2397300",
    "end": "2403190"
  },
  {
    "text": "So this is an exercise\nin integration, which is not very difficult. And it turns out that after you\ndo everything, you end up",
    "start": "2403190",
    "end": "2410460"
  },
  {
    "text": "with an answer that\nhas this form. And you look at that,\nand you suddenly recognize, oh, this is normal.",
    "start": "2410460",
    "end": "2416930"
  },
  {
    "text": "And conclusion from this\nexercise, once it's done, is that the sum of two independent\nnormal random",
    "start": "2416930",
    "end": "2423150"
  },
  {
    "text": "variables is also normal. Now, the mean of W is, of\ncourse, going to be equal to",
    "start": "2423150",
    "end": "2431900"
  },
  {
    "text": "the sum of the means of X and\nY. In this case, in this formula I took the\nmeans to be 0.",
    "start": "2431900",
    "end": "2437660"
  },
  {
    "text": "So the mean of W is also\ngoing to be 0. In the more general case, the\nmean of W is going to be just",
    "start": "2437660",
    "end": "2443650"
  },
  {
    "text": "the sum of the two means. The variance of W is always the\nsum of the variances of X",
    "start": "2443650",
    "end": "2449680"
  },
  {
    "text": "and Y, since we have independent\nrandom variables. So there's no surprise here.",
    "start": "2449680",
    "end": "2455700"
  },
  {
    "text": "The main surprise in this\ncalculation is this fact here, that the sum of independent\nnormal random",
    "start": "2455700",
    "end": "2462720"
  },
  {
    "text": "variables is normal. I had mentioned this fact\nin a previous lecture. Here what we're doing is to\nbasically outline the argument",
    "start": "2462720",
    "end": "2472070"
  },
  {
    "text": "that justifies this\nparticular fact. It's an exercise in integration,\nwhere you realize",
    "start": "2472070",
    "end": "2477539"
  },
  {
    "text": "that when you convolve two\nnormal curves, you also get",
    "start": "2477540",
    "end": "2482680"
  },
  {
    "text": "back a normal one once more. So now, let's return to the\ncomment I was making here,",
    "start": "2482680",
    "end": "2490230"
  },
  {
    "text": "that if you have a contour plot\nthat has, let's say, a shape of this kind, this\nindicates some kind of",
    "start": "2490230",
    "end": "2496640"
  },
  {
    "text": "dependence between your\ntwo random variables. So instead of a contour plot,\nlet me throw in here a",
    "start": "2496640",
    "end": "2503470"
  },
  {
    "text": "scattered diagram. What does this scattered\ndiagram correspond to? Suppose you have a discrete\ndistribution, and each one of",
    "start": "2503470",
    "end": "2510650"
  },
  {
    "text": "the points in this diagram\nhas positive probability. When you look at this diagram,\nwhat would you say?",
    "start": "2510650",
    "end": "2518600"
  },
  {
    "text": "I would say that when\ny is big then x",
    "start": "2518600",
    "end": "2526890"
  },
  {
    "text": "also tends to be larger. So bigger x's are sort of\nassociated with bigger y's in",
    "start": "2526890",
    "end": "2535579"
  },
  {
    "text": "some average, statistical\nsense. Whereas, if you have a picture\nof this kind, it tells you in",
    "start": "2535580",
    "end": "2541410"
  },
  {
    "text": "association that the positive\ny's tend to be associated with",
    "start": "2541410",
    "end": "2546980"
  },
  {
    "text": "negative x's most of the time. Negative y's tend to be\nassociated mostly with",
    "start": "2546980",
    "end": "2554410"
  },
  {
    "text": "positive x's.  So here there's a relation\nthat when one variable is",
    "start": "2554410",
    "end": "2562210"
  },
  {
    "text": "large, the other one is also\nexpected to be large. Here there's a relation\nof the opposite kind.",
    "start": "2562210",
    "end": "2568800"
  },
  {
    "text": "How can we capture\nthis relation between two random variables? The way we capture it is by\ndefining this concept called",
    "start": "2568800",
    "end": "2576090"
  },
  {
    "text": "the covariance, that looks at\nthe relation of was X bigger",
    "start": "2576090",
    "end": "2583090"
  },
  {
    "text": "than usual? That's the question, whether\nthis is positive. And how does this relate to the\nanswer-- to the question,",
    "start": "2583090",
    "end": "2590110"
  },
  {
    "text": "was Y bigger than usual? We're asking-- by calculating\nthis quantity, we're sort of",
    "start": "2590110",
    "end": "2596289"
  },
  {
    "text": "asking the question, is there a\nsystematic relation between having a big X with\nhaving a big Y?",
    "start": "2596290",
    "end": "2605790"
  },
  {
    "text": "OK , to understand more\nprecisely what this does, let's suppose that the random\nvariable has 0 means, So that",
    "start": "2605790",
    "end": "2612290"
  },
  {
    "text": "we get rid of this-- get rid of some clutter. So the covariance is defined\njust as this product.",
    "start": "2612290",
    "end": "2618940"
  },
  {
    "text": "What does this do? If positive x's tends to go\ntogether with positive y's,",
    "start": "2618940",
    "end": "2625120"
  },
  {
    "text": "and negative x's tend to go\ntogether with negative y's, this product will always\nbe positive.",
    "start": "2625120",
    "end": "2631860"
  },
  {
    "text": "And the covariance will\nend up being positive. In particular, if you sit down\nwith a scattered diagram and",
    "start": "2631860",
    "end": "2639089"
  },
  {
    "text": "you do the calculations,\nyou'll find that the covariance of X and Y in this\ndiagram would be positive,",
    "start": "2639090",
    "end": "2645480"
  },
  {
    "text": "because here, most of the time,\nX times Y is positive. There's going to be a few\nnegative terms, but there are",
    "start": "2645480",
    "end": "2652130"
  },
  {
    "text": "fewer than the positive ones. So this is a case of a\npositive covariance. It indicates a positive relation\nbetween the two",
    "start": "2652130",
    "end": "2659570"
  },
  {
    "text": "random variables. When one is big, the other\nalso tends to be big.",
    "start": "2659570",
    "end": "2664700"
  },
  {
    "text": "This is the opposite\nsituation. Here, when one variable-- here, most of the action happens\nin this quadrant and",
    "start": "2664700",
    "end": "2671000"
  },
  {
    "text": "that quadrant, which means that\nX times Y, most of the time, is negative.",
    "start": "2671000",
    "end": "2677150"
  },
  {
    "text": "You get a few positive\ncontributions, but there are few. When you add things up, the\nnegative terms dominate.",
    "start": "2677150",
    "end": "2684430"
  },
  {
    "text": "And in this case we\nhave covariance of X and Y being negative.",
    "start": "2684430",
    "end": "2689560"
  },
  {
    "text": "So a positive covariance\nindicates a sort of systematic relation, that there's a\npositive association between",
    "start": "2689560",
    "end": "2696280"
  },
  {
    "text": "the two random variables. When one is large, the other\nalso tends to be large. Negative covariance is\nsort of the opposite.",
    "start": "2696280",
    "end": "2703060"
  },
  {
    "text": "When one tends to be\nlarge, the other variable tends to be small.",
    "start": "2703060",
    "end": "2709920"
  },
  {
    "text": "OK, so what else is there to\nsay about the covariance?",
    "start": "2709920",
    "end": "2715049"
  },
  {
    "text": "One observation to make\nis the following. What's the covariance\nof X with X itself?",
    "start": "2715050",
    "end": "2721105"
  },
  {
    "text": " If you plug in X here, you see\nthat what we have is expected",
    "start": "2721105",
    "end": "2728220"
  },
  {
    "text": "value of X minus expected\nof X squared. And that's just the\ndefinition of the",
    "start": "2728220",
    "end": "2733789"
  },
  {
    "text": "variance of a random variable. So that's one fact\nto keep in mind.",
    "start": "2733790",
    "end": "2741180"
  },
  {
    "text": "We had a shortcut formula for\ncalculating variances. There's a similar shortcut\nformula for calculating",
    "start": "2741180",
    "end": "2746900"
  },
  {
    "text": "covariances. In particular, we can calculate\ncovariances in this particular way.",
    "start": "2746900",
    "end": "2752720"
  },
  {
    "text": "That's just the convenient way\nof doing it whenever you need to calculate it.",
    "start": "2752720",
    "end": "2757940"
  },
  {
    "text": "And finally, covariances are\nvery useful when you want to calculate the variance of a\nsum of random variables.",
    "start": "2757940",
    "end": "2766420"
  },
  {
    "text": " We know that if two random\nvariables are independent, the",
    "start": "2766420",
    "end": "2772609"
  },
  {
    "text": "variance of the sum is the\nsum of the variances. When the random variables are\ndependent, this is no longer",
    "start": "2772610",
    "end": "2780310"
  },
  {
    "text": "true, and we need to supplement\nthe formula a little bit. And there's a typo on\nthe slides that you",
    "start": "2780310",
    "end": "2786240"
  },
  {
    "text": "have in your hands. That term of 2 shouldn't\nbe there.",
    "start": "2786240",
    "end": "2792869"
  },
  {
    "text": "And let's see where that\nformula comes from. ",
    "start": "2792870",
    "end": "2801550"
  },
  {
    "text": "Let's suppose that our\nrandom variables are independent of -- not independent --",
    "start": "2801550",
    "end": "2807530"
  },
  {
    "text": "our random variables\nhave 0 means. ",
    "start": "2807530",
    "end": "2815680"
  },
  {
    "text": "And we want to calculate\nthe variance. So the variance is going\nto be expected value of",
    "start": "2815680",
    "end": "2820900"
  },
  {
    "text": "(X1 plus Xn) squared. What you do is you expand\nthe square.",
    "start": "2820900",
    "end": "2827140"
  },
  {
    "text": "And you get the expected value\nof the sum of the Xi squared.",
    "start": "2827140",
    "end": "2832670"
  },
  {
    "text": "And then you get all\nthe cross terms. ",
    "start": "2832670",
    "end": "2843070"
  },
  {
    "text": "OK. And so now, here, let's\nassume for simplicity",
    "start": "2843070",
    "end": "2849420"
  },
  {
    "text": "that we have 0 means. The expected value of this is\nthe sum of the expected values of the X squared terms.",
    "start": "2849420",
    "end": "2856300"
  },
  {
    "text": "And that gives us\nthe variance. And then we have all the\npossible cross terms.",
    "start": "2856300",
    "end": "2861559"
  },
  {
    "text": "And each one of the possible\ncross terms is the expected value of Xi times Xj.",
    "start": "2861560",
    "end": "2866619"
  },
  {
    "text": "This is just the covariance. So if you can calculate all\nthe variances and the",
    "start": "2866620",
    "end": "2872730"
  },
  {
    "text": "covariances, then you're able to\ncalculate also the variance of a sum of random variables.",
    "start": "2872730",
    "end": "2878540"
  },
  {
    "text": "Now, if two random variables are\nindependent, then you look at this expression.",
    "start": "2878540",
    "end": "2884800"
  },
  {
    "text": "Because of independence,\nexpected value of the product is going to be the product\nof the expected values.",
    "start": "2884800",
    "end": "2890990"
  },
  {
    "text": "And the expected value\nof just this term is always equal to 0. You're expected deviation\nfrom the mean is just 0.",
    "start": "2890990",
    "end": "2899789"
  },
  {
    "text": "So the covariance will\nturn out to be 0. So independent random\nvariables lead to 0",
    "start": "2899790",
    "end": "2905109"
  },
  {
    "text": "covariances, although the\nopposite fact is not necessarily true.",
    "start": "2905110",
    "end": "2910160"
  },
  {
    "text": "So covariances give you some\nindication of the relation between two random variables.",
    "start": "2910160",
    "end": "2915430"
  },
  {
    "text": "Something that's not so\nconvenient conceptually about covariances is that it\nhas the wrong units.",
    "start": "2915430",
    "end": "2921440"
  },
  {
    "text": "That's the same comment\nthat we had made regarding variances. And with variances we got out\nof that issue by considering",
    "start": "2921440",
    "end": "2928730"
  },
  {
    "text": "the standard deviation, which\nhas the correct units. So with the same reasoning, we\nwant to have a concept that",
    "start": "2928730",
    "end": "2938090"
  },
  {
    "text": "captures the relation between\ntwo random variables and, in some sense, that doesn't have\nto do with the units that",
    "start": "2938090",
    "end": "2945789"
  },
  {
    "text": "we're dealing. We want to have a dimensionless\nquantity. That tells us how strongly two\nrandom variables are related",
    "start": "2945790",
    "end": "2954039"
  },
  {
    "text": "to each other. So instead of considering the\ncovariance of just X with Y,",
    "start": "2954040",
    "end": "2961180"
  },
  {
    "text": "we take our random variables\nand standardize them by dividing them by their\nindividual standard deviations",
    "start": "2961180",
    "end": "2968430"
  },
  {
    "text": "and take the expectation\nof this. So what we end up doing is the\ncovariance of X and Y, which",
    "start": "2968430",
    "end": "2974780"
  },
  {
    "text": "has units that are the units of\nX times the units of Y. But divide with a standard\ndeviation, so that we get a",
    "start": "2974780",
    "end": "2981710"
  },
  {
    "text": "quantity that doesn't\nhave units. This quantity, we call it the\ncorrelation coefficient.",
    "start": "2981710",
    "end": "2987890"
  },
  {
    "text": "And it's a very useful quantity,\na very useful measure of the strength\nof association",
    "start": "2987890",
    "end": "2993610"
  },
  {
    "text": "between two random variables. It's very informative, because\nit falls always",
    "start": "2993610",
    "end": "2999750"
  },
  {
    "text": "between -1 and +1. This is an algebraic exercise\nthat you're going to see in",
    "start": "2999750",
    "end": "3006240"
  },
  {
    "text": "recitation. And the way that you interpret\nit is as follows. If the two random variables\nare independent, the",
    "start": "3006240",
    "end": "3013360"
  },
  {
    "text": "covariance is going to be 0. The correlation coefficient\nis going to be 0. So 0 correlation coefficient\nbasically indicates a lack of",
    "start": "3013360",
    "end": "3023339"
  },
  {
    "text": "a systematic relation between\nthe two random variables. On the other hand, when rho is\nlarge, either close to 1 or",
    "start": "3023340",
    "end": "3031710"
  },
  {
    "text": "close to -1, this is an\nindication of a strong association between the\ntwo random variables.",
    "start": "3031710",
    "end": "3037660"
  },
  {
    "text": "And the extreme case is when\nrho takes an extreme value.",
    "start": "3037660",
    "end": "3042770"
  },
  {
    "text": "When rho has a magnitude\nequal to 1, it's as big as it can be.",
    "start": "3042770",
    "end": "3047790"
  },
  {
    "text": "In that case, the two\nrandom variables are very strongly related.",
    "start": "3047790",
    "end": "3053630"
  },
  {
    "text": "How strongly? Well, if you know one random\nvariable, if you know the value of y, you can recover the\nvalue of x and conversely.",
    "start": "3053630",
    "end": "3063530"
  },
  {
    "text": "So the case of a complete\ncorrelation is the case where one random variable is a linear\nfunction of the other",
    "start": "3063530",
    "end": "3071300"
  },
  {
    "text": "random variable. In terms of a scatter plot, this\nwould mean that there's a",
    "start": "3071300",
    "end": "3076940"
  },
  {
    "text": "certain line and that the only\npossible (x,y) pairs that can",
    "start": "3076940",
    "end": "3082060"
  },
  {
    "text": "happen would lie on that line. So if all the possible (x,y)\npairs lie on this line, then",
    "start": "3082060",
    "end": "3088920"
  },
  {
    "text": "you have this relation, and the\ncorrelation coefficient is equal to 1. A case where the correlation\ncoefficient is close to 1",
    "start": "3088920",
    "end": "3096579"
  },
  {
    "text": "would be a scatter plot like\nthis, where the x's and y's are quite strongly aligned with\neach other, maybe not",
    "start": "3096580",
    "end": "3104820"
  },
  {
    "text": "exactly, but fairly strongly. All right, so you're going to\nhear a little more about",
    "start": "3104820",
    "end": "3110760"
  },
  {
    "text": "correlation coefficients\nand covariances in recitation tomorrow. ",
    "start": "3110760",
    "end": "3114670"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6859"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "6860",
    "end": "13410"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "13410",
    "end": "18710"
  },
  {
    "text": " PROFESSOR: OK. Let's get started.",
    "start": "18710",
    "end": "24920"
  },
  {
    "text": "So what I'm going to do next\nis switch gears to one interesting compiler, which\nis the StreamIt",
    "start": "24920",
    "end": "30540"
  },
  {
    "text": "parallelizing compiler.  The main idea about StreamIt\nis the need for a common",
    "start": "30540",
    "end": "37399"
  },
  {
    "text": "machine language. What we want to do normally is,\nin a language, you want to",
    "start": "37400",
    "end": "43670"
  },
  {
    "text": "represent common architecture\nproperties so you get good performance. You don't do it at a very high\nlevel of abstraction, so you",
    "start": "43670",
    "end": "50470"
  },
  {
    "text": "base a lot of cycles dealing\nwith the abstraction. But you want to abstract out\nthe differences between",
    "start": "50470",
    "end": "55960"
  },
  {
    "text": "machines to get the portability,\notherwise you are going to just do assembly-hacking for one machine.",
    "start": "55960",
    "end": "61690"
  },
  {
    "text": "Also you can't have things too\ncomplex, because a typical programmer cannot deal with very\ncomplex things that we",
    "start": "61690",
    "end": "67840"
  },
  {
    "text": "ask them to do. C and Fortran was a really nice\ncommon assembly language",
    "start": "67840",
    "end": "75510"
  },
  {
    "text": "for imperative languages\nrunning on the unicore machines.",
    "start": "75510",
    "end": "80650"
  },
  {
    "text": "The problem is this type of\nlanguage is not a good common language for multicores, because\nit doesn't deal with,",
    "start": "80650",
    "end": "86610"
  },
  {
    "text": "first of all, multiple cores. And as you keep changing\nthe number of cores --",
    "start": "86610",
    "end": "92619"
  },
  {
    "text": "for example, automatic\nparallelizing compilers are not good to basically get really\ngood parallelism out of",
    "start": "92620",
    "end": "98480"
  },
  {
    "text": "that, even though we\ntalk about that. Still a lot of work has\nto be done in there. So what's the correct\nabstraction if you have",
    "start": "98480",
    "end": "105860"
  },
  {
    "text": "multicore machines? The current offering, what you\nguys are doing, is things like",
    "start": "105860",
    "end": "111200"
  },
  {
    "text": "OpenMP, MPI type stuff. You are hand-hacking\nthe parallelism.",
    "start": "111200",
    "end": "116850"
  },
  {
    "text": "Well, the issue with that. It's basically this explicit\nparallel construct. It's kind of added to languages\nlike C -- that's",
    "start": "116850",
    "end": "124710"
  },
  {
    "text": "what you're working on. And what this does is all these\nnice properties about",
    "start": "124710",
    "end": "129789"
  },
  {
    "text": "composability, malleability,\ndebuggability, portability -- all those things were kind\nof out of the window.",
    "start": "129790",
    "end": "135659"
  },
  {
    "text": "And this is why this\nparallelizing is hard, because all these things makes life\nvery difficult for the",
    "start": "135660",
    "end": "141040"
  },
  {
    "text": "programmer. And it's a huge additional\nprogram burden. The programmer has to introduce\nparallelism,",
    "start": "141040",
    "end": "147850"
  },
  {
    "text": "correctness, optimization -- it's all left to\nthe programmer.",
    "start": "147850",
    "end": "152920"
  },
  {
    "text": "So what the program has to do in\nthis kind of world -- what you are doing right now -- you have to feed all the\ngranularity decisions.",
    "start": "152920",
    "end": "160299"
  },
  {
    "text": "If things are too small\nyou might get too much communication. If things are too large you\nmight not get good load",
    "start": "160300",
    "end": "166710"
  },
  {
    "text": "balancing, and stuff like. And then you deal with all the\nload balancing decisions. All those decisions are\nleft for you guys.",
    "start": "166710",
    "end": "174569"
  },
  {
    "text": "You need to figure out what's\nlocal, what's not. And if you make a wrong decision\nit can cost you.",
    "start": "174570",
    "end": "180530"
  },
  {
    "text": "All the synchronization, and\nall the pain and suffering that comes from making\na wrong decision.",
    "start": "180530",
    "end": "186230"
  },
  {
    "text": "Things like race conditions,\ndeadlocks, and stuff like that.",
    "start": "186230",
    "end": "192620"
  },
  {
    "text": "And this, while MIT students can\nhack it, you can't go and convince a dull programmer to\nconvert from writing nice",
    "start": "192620",
    "end": "201030"
  },
  {
    "text": "simple Java application code\nto dealing with all these complexities. So this is what kind of led to\nour research for the last five",
    "start": "201030",
    "end": "209209"
  },
  {
    "text": "years to do StreamIt. What you want to do is move a\nbunch of these decisions to",
    "start": "209210",
    "end": "214900"
  },
  {
    "text": "the compiler. Granularity, load balancing,\nlocality, and synchronization -- [OBSCURED]",
    "start": "214900",
    "end": "220650"
  },
  {
    "text": "And in today's talk I am going\nto talk to you about, after you write a StreamIt program\n-- as Bill pointed out, the",
    "start": "220650",
    "end": "226060"
  },
  {
    "text": "nice parallel properties -- how\ndo you actually go about getting this kind\nof parallelism. ",
    "start": "226060",
    "end": "234130"
  },
  {
    "text": "So in StreamIt , in summary, it\nbasically has regular and",
    "start": "234130",
    "end": "239210"
  },
  {
    "text": "repeating computation\nin these filters. This is called a synchronous\ndata flow model, because we",
    "start": "239210",
    "end": "244290"
  },
  {
    "text": "know at compile time exactly how\nthe data moves, how much each produces and consumes.",
    "start": "244290",
    "end": "250890"
  },
  {
    "text": "And this has natural\nparallelism, and it exposes exactly what's going to happen\nto the compiler.",
    "start": "250890",
    "end": "259010"
  },
  {
    "text": "And the compiler can do a lot\nof powerful transformations, as yesterday I pointed out.",
    "start": "259010",
    "end": "264720"
  },
  {
    "text": "The first thing is, because of\nsynchronous data flow, we know at compile time exactly who\nneeds to do what when.",
    "start": "264720",
    "end": "272530"
  },
  {
    "text": "And that really helps\ntransform. It's not like everything happens\nrun-time dynamically.",
    "start": "272530",
    "end": "277970"
  },
  {
    "text": "So what does that mean? So what that means is each\nfilter knows exactly how much",
    "start": "277970",
    "end": "283780"
  },
  {
    "text": "to push and pop -- that's in a repeatable\nexecution. And so what we can do is, we\ncan come up to the static",
    "start": "283780",
    "end": "290330"
  },
  {
    "text": "schedule that can be repeated\nmultiple times. So let me tell you a little\nbit about what a static",
    "start": "290330",
    "end": "295900"
  },
  {
    "text": "schedule means. So assume this filter pushes\ntwo, this filter pops three but pushes one, that\nfilter pops two.",
    "start": "295900",
    "end": "301960"
  },
  {
    "text": "So these are kind of rate\npushes, it's not everybody producing-consuming at once. So what's the schedule?",
    "start": "301960",
    "end": "307000"
  },
  {
    "text": "So you can say -- OK, at the beginning it produces\ntwo items, but I",
    "start": "307000",
    "end": "312129"
  },
  {
    "text": "can't consume that because I\nneed three items. And then I do two of them, and I can\nconsume the first three and",
    "start": "312130",
    "end": "318910"
  },
  {
    "text": "then produce one there. And I have two left behind. I do one more that, and\nnow I got three.",
    "start": "318910",
    "end": "324810"
  },
  {
    "text": "And it consumes that\nand produces that. And then I can fire C. So the\nneat thing about this is, when",
    "start": "324810",
    "end": "331449"
  },
  {
    "text": "I started there was nothing\ninside any of these buffers. And if I ran A, A, B, A, B, C,\nthere's nothing inside the",
    "start": "331450",
    "end": "339710"
  },
  {
    "text": "buffers again. So what I have is, I'm back to\nthe starting positioning.",
    "start": "339710",
    "end": "345690"
  },
  {
    "text": "And if I repeat this millions\nof times -- I keep the computation running\nnicely without any buffers",
    "start": "345690",
    "end": "351390"
  },
  {
    "text": "accumulating or anything\nlike that. So I can come up with this very\nnice schedule that says",
    "start": "351390",
    "end": "356650"
  },
  {
    "text": "-- here's what I have to do. I have to run A actually three\ntimes, B twice, and C once, in",
    "start": "356650",
    "end": "362060"
  },
  {
    "text": "this order, and if I\ndo that I have a computation that keeps running. And that gives me a good global\nview on what can I",
    "start": "362060",
    "end": "368940"
  },
  {
    "text": "parallelize, what can I load\nbalance, all those things. Because things don't change. One more additional thing about\nStreamIt is we can look",
    "start": "368940",
    "end": "377670"
  },
  {
    "text": "at more elements than\nI am consuming. Question? AUDIENCE: How common is it in\nyour typical code that you can",
    "start": "377670",
    "end": "385500"
  },
  {
    "text": "actually produce a static\nschedule like that? PROFESSOR: In a lot of DSV\ncode this is very common.",
    "start": "385500",
    "end": "393880"
  },
  {
    "text": "A lot of DSV code right now that\ngoes into hardware and software, they have very\ncommon properties.",
    "start": "393880",
    "end": "401230"
  },
  {
    "text": "But even things that are not\ncommon, what has a very large chunk of the program has this\nstatic property, and there are",
    "start": "401230",
    "end": "408760"
  },
  {
    "text": "some few places that has\ndynamic property. So it's like, when you write a\nnormal program you don't write",
    "start": "408760",
    "end": "414850"
  },
  {
    "text": "a branch instruction after\nevery instruction. You have a few hundred\ninstructions and a branch, a few tens of instructions and\na branch type thing.",
    "start": "414850",
    "end": "422200"
  },
  {
    "text": "So what you can think about it\nis that those instructions without a branch can get\noptimized the hell out of",
    "start": "422200",
    "end": "428460"
  },
  {
    "text": "them, and then you do a\nbranch dynamically. So you can think about\nit like this. What's the largest chunks you\ncan find that you don't have",
    "start": "428460",
    "end": "435560"
  },
  {
    "text": "this uncertainty\nuntil run-time? Then you can optimize the hell\nout of it, and then you can deal with this run-time\nissues --",
    "start": "435560",
    "end": "443330"
  },
  {
    "text": "basically branches, or control\nfor changes, or direct your rate changes at run-time.",
    "start": "443330",
    "end": "451409"
  },
  {
    "text": "If we have 10-90 rule, if you\nget 90% of the things are in a nice thing, and if you get good\nperformance on that --",
    "start": "451410",
    "end": "456639"
  },
  {
    "text": "hey, it has a big impact. So in our language you can deal\nwith dynamism, but our",
    "start": "456640",
    "end": "461850"
  },
  {
    "text": "analysis is basically trying\nto find the largest static chunk and analyze. So most of the time that\nbasically said we start with",
    "start": "461850",
    "end": "468710"
  },
  {
    "text": "empty and end with empty. But the trouble is, a lot of\ntimes we actually can look beyond the number of\nwhat we consume.",
    "start": "468710",
    "end": "474630"
  },
  {
    "text": "So what you have to do is kind\nof do initial schedule that you don't start with empty,\nyou basically consume",
    "start": "474630",
    "end": "483260"
  },
  {
    "text": "something -- you start with\nsomething like this. So the next time in\nsomething comes -- three things come\ninto this one --",
    "start": "483260",
    "end": "491189"
  },
  {
    "text": "I can actually pick four\nand pop three. So you go through the first\nthing kind of priming",
    "start": "491190",
    "end": "496340"
  },
  {
    "text": "everything with the amount of\ndata needed, and then you go to the static schedule.",
    "start": "496340",
    "end": "502190"
  },
  {
    "text": "This kind of gives you a feel\nfor what you'll get. This is a neat thing,\nI know exactly",
    "start": "502190",
    "end": "507430"
  },
  {
    "text": "what's going on in here. So now how do I run\nthis parallelism? This is something actually\nRodric pointed out before,",
    "start": "507430",
    "end": "515560"
  },
  {
    "text": "there are three types of\nparallelism we can deal with. So here's my stream program in\nhere, and I do some filters,",
    "start": "515560",
    "end": "522139"
  },
  {
    "text": "scatter-gather in here. The first site of parallelism\nis task parallelism. What that means is the\nprogrammer said, there are",
    "start": "522140",
    "end": "529280"
  },
  {
    "text": "three things that can\nrun parallelly before I join them together. So this is a\nprogrammer-specified",
    "start": "529280",
    "end": "534890"
  },
  {
    "text": "parallelism. And you have a nice data\nparallel messenger",
    "start": "534890",
    "end": "541009"
  },
  {
    "text": "presentation. The second part is\ndata parallelism.",
    "start": "541010",
    "end": "546140"
  },
  {
    "text": "What that means is, you have\nsome of these things that don't depend on the previous\nrun of that one.",
    "start": "546140",
    "end": "553180"
  },
  {
    "text": "So there's no invocation,\ndependency across multiple invocations.",
    "start": "553180",
    "end": "558340"
  },
  {
    "text": "These are called stateless\nfilters, there's no state that keeps changing. If the state kept changing,\nyou had to wait till the previous one finishes\nto run the next one.",
    "start": "558340",
    "end": "565860"
  },
  {
    "text": "So if you have a stateless\nfilter -- assume that it's data\nparallel -- what you can do is you can\nbasically take that, replicate",
    "start": "565860",
    "end": "575270"
  },
  {
    "text": "it many, many times, and\nwhen the data comes -- parallel is in it\nevery data -- and it will compute and\nparallelly get out here.",
    "start": "575270",
    "end": "583209"
  },
  {
    "text": "The final thing is pipeline\nparallelism. So you can feed this one into\nthis one, this one into this",
    "start": "583210",
    "end": "588440"
  },
  {
    "text": "one, and then douse across\nin a pipeline fashion. And you can get multiple\nthings execution. So we have these three types\nof parallelism in here, and",
    "start": "588440",
    "end": "595660"
  },
  {
    "text": "the interesting thing is if you\nhave stateful filters, you can't run this data parallel.",
    "start": "595660",
    "end": "601170"
  },
  {
    "text": "Actually the only parallelism\nyou can get is pipeline parallelism. So traditionally task\nparallelism is fork/join",
    "start": "601170",
    "end": "608170"
  },
  {
    "text": "parallelism, that you guys\nare doing right now. Data parallelism is\nloop parallelism.",
    "start": "608170",
    "end": "613800"
  },
  {
    "text": "And pipeline parallelism mainly\nwas done in hardware. If you have done something like\nVerilog or VHDL you'll do",
    "start": "613800",
    "end": "619520"
  },
  {
    "text": "a lot of pipeline parallelism. So kind of combining these three\nideas from different communities all into one,\nbecause I think programs can",
    "start": "619520",
    "end": "626620"
  },
  {
    "text": "have each part in there. So now, how do you go\nand exploit this?",
    "start": "626620",
    "end": "632199"
  },
  {
    "text": "How do you go take advantage\nof that? So I'll talk a little bit of\nbaseline techniques, and then",
    "start": "632200",
    "end": "638660"
  },
  {
    "text": "talk about what StreamIt\ncompiler does today. So assume I have a program\nlike this. The hardest thing is there\nare two tasks in here.",
    "start": "638660",
    "end": "646110"
  },
  {
    "text": "The programs are given, you\ndon't have to worry anything about that. And what you can do is assign\nthem into different",
    "start": "646110",
    "end": "652190"
  },
  {
    "text": "cores and run it. Neat.  You can think what a fork /join\nparallelism is, you come",
    "start": "652190",
    "end": "659030"
  },
  {
    "text": "here you fork, you do this\nthing, and you join in here. So the interesting thing is\nif you have two cores.",
    "start": "659030",
    "end": "665160"
  },
  {
    "text": "You probably got a 2x\nspeedup in this one. This is really neat because\nthere are two things in here. The problem is, how about if you\nhave a lot more different",
    "start": "665160",
    "end": "671209"
  },
  {
    "text": "number of cores? Or if the next generation has\ndouble the number of cores,",
    "start": "671210",
    "end": "676279"
  },
  {
    "text": "and I'm stuck with the program\nyou've written for the current generation? So this not that great,\ninteresting.",
    "start": "676280",
    "end": "683130"
  },
  {
    "text": "So we ran it on the Raw\nprocessor we have -- it has 16",
    "start": "683130",
    "end": "688290"
  },
  {
    "text": "cores in there -- that we have been building, and\nthis is actually running a simulator of that.",
    "start": "688290",
    "end": "694140"
  },
  {
    "text": "What you find is, is a bunch of\nStreamIt programs we have we kind of get performance like\nbasically close to two,",
    "start": "694140",
    "end": "702590"
  },
  {
    "text": "because that's the kind of parallelism people have written. In fact, some programs even\nslowed down in there, because",
    "start": "702590",
    "end": "709760"
  },
  {
    "text": "what happens in here is\nthe parallelism and synchronization is not matched\nwith the target --",
    "start": "709760",
    "end": "717339"
  },
  {
    "text": "because it's matched\nwith the program. Because you wrote a program\nbecause your parallelism in there was what you thought was\nright for the algorithm.",
    "start": "717340",
    "end": "724430"
  },
  {
    "text": "We didn't want you to give any\nconsideration to the machine you are running, and it didn't\nmatch the machine, basically,",
    "start": "724430",
    "end": "729490"
  },
  {
    "text": "if you just got the\nparallelism. And you just don't\ndo that right. So one thing we have noticed\nfor a lot of streaming",
    "start": "729490",
    "end": "737280"
  },
  {
    "text": "programs, to answer your\nquestion, is there are a lot of data parallelism. In fact, in this filter --",
    "start": "737280",
    "end": "744000"
  },
  {
    "text": "in this program -- what you can do is you can find\ndata parallel filters,",
    "start": "744000",
    "end": "749030"
  },
  {
    "text": "and parallelize them. So you can take each\nfilter, run it on every core for awile.",
    "start": "749030",
    "end": "754370"
  },
  {
    "text": "Get the data back. Go to the next filter,\nwrite on every go-while, get that back. So what you can do is, if you\nhave four cores in here, you",
    "start": "754370",
    "end": "762285"
  },
  {
    "text": "can each replicate all\nthis four times. Run these four for a while,\nand then these four, these",
    "start": "762285",
    "end": "767410"
  },
  {
    "text": "four, these four, these four. OK? So that's the nice\nway to do that. So the nice thing about doing\nthat is you have a lot of nice",
    "start": "767410",
    "end": "773390"
  },
  {
    "text": "in the load balancing, because\neach are doing the same amount of work for a while. And after it accumulates enough\ndata you go to the next",
    "start": "773390",
    "end": "779410"
  },
  {
    "text": "one, do for a while,\nand then like that.",
    "start": "779410",
    "end": "784870"
  },
  {
    "text": "And each group basically will\noccupy the entire machine -- you just go down this\ngroup like that. And so we ran it, it started\neven slower.",
    "start": "784870",
    "end": "793660"
  },
  {
    "text": "Why?  It should have a lot more\nparallelism, because all those",
    "start": "793660",
    "end": "799470"
  },
  {
    "text": "filters were data-parallel. So you sort of gettting stuck\nwith two, now we can easily run a parallelism of 16, because\ndata parallelism you",
    "start": "799470",
    "end": "806135"
  },
  {
    "text": "can just put it any\namount in there. But we are running slow. AUDIENCE: Communication\noverhead?",
    "start": "806135",
    "end": "812240"
  },
  {
    "text": "PROFESSOR: Yeah, it could\nmainly be communication overhead, because what happens\nis you run this for a small",
    "start": "812240",
    "end": "817779"
  },
  {
    "text": "amount of time. You had to send it all over\nthe place, collect it back again, send it all over the\nplace, collect it back again.",
    "start": "817780",
    "end": "824740"
  },
  {
    "text": "The problem is there's too\nmuch synchronization and communication. Because every person at the\nend is like this global",
    "start": "824740",
    "end": "830400"
  },
  {
    "text": "barrier, and the data has\nto go shuffling around. And that doesn't help.",
    "start": "830400",
    "end": "837220"
  },
  {
    "text": "So the other part, what you can\ndo in the baseline is what you call hardware pipeline.",
    "start": "837220",
    "end": "843280"
  },
  {
    "text": "What that means is you can\nactually do pipeline parallelism. The way you can do that is you\ncan look at the amount of work",
    "start": "843280",
    "end": "852490"
  },
  {
    "text": "each filters contain, and you\ncan combine them together in a way that the number of filters\nis going to be just about the",
    "start": "852490",
    "end": "860890"
  },
  {
    "text": "number of tiles available.  Most programs have\nmore filters than the number of cores.",
    "start": "860890",
    "end": "866960"
  },
  {
    "text": "So you review combined filters,\nto give us a number of filters, is just either the\nsame, or one or two less than",
    "start": "866960",
    "end": "872630"
  },
  {
    "text": "the number of cores available. In a way that you combine them\nso each of them will probably",
    "start": "872630",
    "end": "878840"
  },
  {
    "text": "have close to the same\namount of work. The problem is if when you\ncombine it's very hard to get",
    "start": "878840",
    "end": "884180"
  },
  {
    "text": "the same amount of work. And if you assume eight cores,\nyou can do this combination",
    "start": "884180",
    "end": "889970"
  },
  {
    "text": "and we can say -- aha, if I do this combination,\nI have one, two, three, four, five, six, seven.",
    "start": "889970",
    "end": "895459"
  },
  {
    "text": "Eight cores, I can get\nseven of them. Hopefully each of them have the\nsame amount of work, and I can run that.",
    "start": "895460",
    "end": "903070"
  },
  {
    "text": "And then we assign this to one\nfilter and say -- \"You own this one, you run it forever. You get the data from the guy\nwho owns this one, and you",
    "start": "903070",
    "end": "911040"
  },
  {
    "text": "produce at this one.\" And if\nyou have more cores you can",
    "start": "911040",
    "end": "916079"
  },
  {
    "text": "actually keep doing\nsome of that. If you have enough filters\nyou can each combine them and do that. So we perform, and\nwe got this.",
    "start": "916080",
    "end": "924980"
  },
  {
    "text": "Not that bad. So what might be the\nproblems here? ",
    "start": "924980",
    "end": "937308"
  },
  {
    "text": "AUDIENCE: Hardware locality. You want to make sure that the\ncommunicating filters are",
    "start": "937308",
    "end": "942615"
  },
  {
    "text": "close to each other. PROFESSOR: Yeah, that\nwe can deal with. It's not a big locality\n[OBSCURED] What's the other problem?",
    "start": "942616",
    "end": "949740"
  },
  {
    "text": "The bigger problem. ",
    "start": "949740",
    "end": "956020"
  },
  {
    "text": "AUDIENCE: [NOISE] load balance. PROFESSOR: Load balance is the\nbiggest problem, because the problem is you are combining\ndifferent types of things",
    "start": "956020",
    "end": "961540"
  },
  {
    "text": "together, and you are hoping\nthat each chunk you get combined togeher will\nhave an almost identical amount of work.",
    "start": "961540",
    "end": "967430"
  },
  {
    "text": "And that's very hard to achieve\nmost of the time, because dynamically things\nkeep changing. The nice thing about loops is,\nmost of the time if you have a",
    "start": "967430",
    "end": "973360"
  },
  {
    "text": "loop or state if you replicate\nit many times, it's the same amount of code, same\namount of work.",
    "start": "973360",
    "end": "979050"
  },
  {
    "text": "It nicely balances out. Hardware -- combining different things\nbecomes actually much harder. ",
    "start": "979050",
    "end": "986280"
  },
  {
    "text": "So again, parallelism and\nsynchronization are not really matched to the target. So the StreamIt compiler right\nnow does two, three things.",
    "start": "986280",
    "end": "995270"
  },
  {
    "text": "I'll go through details. Coarsen the granularity\nof things. So what happens is if you have\nsmall filters it combines them",
    "start": "995270",
    "end": "1001019"
  },
  {
    "text": "together to get the large\nstateless areas. It data parallelizes\nwhen possible.",
    "start": "1001020",
    "end": "1007600"
  },
  {
    "text": "And it does software pipelining,\nthat's a pipeline parallelism. I'll go through all these\nthings in detail.",
    "start": "1007600",
    "end": "1013710"
  },
  {
    "text": "And you can get about\n11x's speedup by doing all those things.",
    "start": "1013710",
    "end": "1019460"
  },
  {
    "text": "So coarsen the stream graph. So you look at this stream\ngraph and say -- wait a minute, I have a bunch of\ndata-parallel parts.",
    "start": "1019460",
    "end": "1026949"
  },
  {
    "text": "And before what I did was I take\neach data-parallel part, when 16 then came or get\ntogether, went 16 came",
    "start": "1026950",
    "end": "1032449"
  },
  {
    "text": "together, went 16. Why? I have put too much\ncommunication. Can I combine data-parallel\nthings into one gigantic unit",
    "start": "1032450",
    "end": "1040589"
  },
  {
    "text": "when possible? Of course, you don't want to\ncombine a data-parallel part with a non-data-parallel part.",
    "start": "1040590",
    "end": "1046290"
  },
  {
    "text": "Then the entire thing\nbecomes sequential, and that's not helpful. So in here what we found is\nthese four cannot be combined,",
    "start": "1046290",
    "end": "1052400"
  },
  {
    "text": "because if you combime them\nthe entire thing becomes sequential.",
    "start": "1052400",
    "end": "1057520"
  },
  {
    "text": "So what we have to do is, you\ncan combine this way. So all those things are\ndata-parallel, all those",
    "start": "1057520",
    "end": "1063679"
  },
  {
    "text": "things are data-parallel. And even though they are\ndata-parallel if you combine them they become\nnon-data-parallel, because",
    "start": "1063680",
    "end": "1069160"
  },
  {
    "text": "this is actually doing peeking,\nit's looking at more than one, and so it's\nlooking at somebody else's iteration work. So you can't combine them.",
    "start": "1069160",
    "end": "1076919"
  },
  {
    "text": "So what the benefits of doing\nthis is you reduce global communication basically. ",
    "start": "1076920",
    "end": "1084460"
  },
  {
    "text": "And the next thing\nis you want data parallelizing to four cores.",
    "start": "1084460",
    "end": "1090650"
  },
  {
    "text": "And this one fits four\nways in there.",
    "start": "1090650",
    "end": "1098060"
  },
  {
    "text": "But the interesting thing is,\nwhen you go in this one you realize there's some\ntask parallelism. ",
    "start": "1098060",
    "end": "1104679"
  },
  {
    "text": "We know there are two tasks that\nhave the same amount of work in here.",
    "start": "1104680",
    "end": "1110520"
  },
  {
    "text": "So facing this four ways, and\nfacing this four ways, and giving the entire machine to\nthis one, and giving the entire machine to this one,\nmight not be the best idea.",
    "start": "1110520",
    "end": "1116860"
  },
  {
    "text": "What you want to do is you\nwant to face it two ways. And then basically give the\nentire machine to all of these",
    "start": "1116860",
    "end": "1123930"
  },
  {
    "text": "running at the same time,\nbecause they're load balanced -- because they are the same\nthing repeated. And you can do the same\nthing in here.",
    "start": "1123930",
    "end": "1129789"
  },
  {
    "text": " OK. So that's what the compiler\ndoes automatically, and it",
    "start": "1129790",
    "end": "1139390"
  },
  {
    "text": "preserves task parallelism. So if you are task parallelism\nyou don't need -- the thing about that is the\nparallelism you need, you",
    "start": "1139390",
    "end": "1145159"
  },
  {
    "text": "don't need too much\nparallelism. You need enough parallelism\nto make the machine happy. If you have too much parallelism\nyou end up in",
    "start": "1145160",
    "end": "1150279"
  },
  {
    "text": "other problems, like\nsynchronization. So this gives enough parallelism\nto keep the entire machine happy, but\nnot too much.",
    "start": "1150280",
    "end": "1156640"
  },
  {
    "text": "And by doing that actually we\nget pretty good performance. There are a few cases where this\nhardware parallelism wins",
    "start": "1156640",
    "end": "1164770"
  },
  {
    "text": "out, these two, but\nmost of them -- actually this last one\nwe can recover -- do it pretty well.",
    "start": "1164770",
    "end": "1171458"
  },
  {
    "text": "OK. So what's left here is -- so\nthis is good parallelism and",
    "start": "1171458",
    "end": "1177870"
  },
  {
    "text": "low synchronization. But there's one thing, when you\nare doing data parallelism",
    "start": "1177870",
    "end": "1183320"
  },
  {
    "text": "there are places where there\nare filters that cannot be parallelized -- they are\nstateful filters.",
    "start": "1183320",
    "end": "1190460"
  },
  {
    "text": "Because you can't run the data\nparallelism, and according to Amdahl's Law that's actually\ngoing to basically kill you,",
    "start": "1190460",
    "end": "1195580"
  },
  {
    "text": "because that's just waiting\nthere and you can't do too much. I'm going to show that using\nthis separate program -- so",
    "start": "1195580",
    "end": "1203039"
  },
  {
    "text": "this number is the amount\nof work that each of them has to do. So this is actually a lot of\nwork, a lot of work -- this",
    "start": "1203040",
    "end": "1208670"
  },
  {
    "text": "does a little work in each\nof these filters. So if you look at that, these\nare data parallel but it",
    "start": "1208670",
    "end": "1214660"
  },
  {
    "text": "doesn't do any much work. Just parallelizing this\ndoesn't help you. And these are data parallel.",
    "start": "1214660",
    "end": "1220710"
  },
  {
    "text": "And these actually\ndo enough work. Actually we can go and say I\nam replicating this four times, and I'm OK. I'm getting actually good\nperformance in here.",
    "start": "1220710",
    "end": "1227640"
  },
  {
    "text": "Now what we have is a\nprogram like this. And so if you are not doing\nanything else that we have",
    "start": "1227640",
    "end": "1233320"
  },
  {
    "text": "data parallelism in. So what happens in the first\ncycle you run these two. And then you run data parallel\nthis one, and then you run",
    "start": "1233320",
    "end": "1239460"
  },
  {
    "text": "these, and then you run data\nparallel this one.",
    "start": "1239460",
    "end": "1245260"
  },
  {
    "text": "And if you look at that, what\nhappens is we have a bunch of holes in here. Because at that point when you\nare running that part of the",
    "start": "1245260",
    "end": "1252510"
  },
  {
    "text": "program there's not enough\nparallelism, and you only have two things in there. And when you're running this\nyou can run this task parallelism in here, but there's\nnothing else you can",
    "start": "1252510",
    "end": "1259210"
  },
  {
    "text": "do in here. And so you get basically\n21 time steps each --",
    "start": "1259210",
    "end": "1265860"
  },
  {
    "text": "time minutes basically will\nrun into that program. But here we can do better.",
    "start": "1265860",
    "end": "1270910"
  },
  {
    "text": "What we can do is we can take\nand try to move that there, and kind of compress them.",
    "start": "1270910",
    "end": "1278620"
  },
  {
    "text": "But the interesting thing\nis these things are not data parallel.",
    "start": "1278620",
    "end": "1284820"
  },
  {
    "text": "So how do I do that? So the way to do that is taking\nadvantage of pipeline parallelism.",
    "start": "1284820",
    "end": "1290370"
  },
  {
    "text": "So what you can do is you can\ntake this filter in here. Since each of the entire graph\ncan run only sequentially --",
    "start": "1290370",
    "end": "1300120"
  },
  {
    "text": "this has to run after this --\nyou can look at the filters running separately like that,\nand kind of say, instead of",
    "start": "1300120",
    "end": "1307470"
  },
  {
    "text": "running this and this and this,\nwhy don't I run this iterations of this one. This iterations of\nthis invocation.",
    "start": "1307470",
    "end": "1313940"
  },
  {
    "text": "And this interations\nof this one. And this iterations\non the next one. And I'm still maintaining --\nbecause when I'm running this",
    "start": "1313940",
    "end": "1320419"
  },
  {
    "text": "even though the -- I'm not running anything data\nparallel here because these ones were already done\npreviously, so I can actually use that value.",
    "start": "1320420",
    "end": "1326760"
  },
  {
    "text": "And so I can maintain that\ndependency, but I'm running things from the different\niterations.",
    "start": "1326760",
    "end": "1332429"
  },
  {
    "text": "And so what I need to do is, I\nneed to kind of do a prologue to kind of set everything\nup in there. And then I can do that and\nI don't have any kind of",
    "start": "1332430",
    "end": "1339810"
  },
  {
    "text": "dependence among these things. So now what I can do is I can\nbasically take thes two and",
    "start": "1339810",
    "end": "1348019"
  },
  {
    "text": "basically lay out anything\nanywhere in those groups, because they are in different\niterations and since I am",
    "start": "1348020",
    "end": "1354610"
  },
  {
    "text": "pipelining these I don't have\nany dependence in there. So I end up in this kind of a\nthing, and basically much",
    "start": "1354610",
    "end": "1359960"
  },
  {
    "text": "compress in here.  And by doing that what you\nactually get is a really nice",
    "start": "1359960",
    "end": "1366380"
  },
  {
    "text": "performance. The only place that this\nactually wins -- hardware",
    "start": "1366380",
    "end": "1373500"
  },
  {
    "text": "pipelining, and this little\nbit in there. But the rest you get a really\ngood win in here.",
    "start": "1373500",
    "end": "1379970"
  },
  {
    "text": "OK. So what this does is basically\nnow we got a program that when",
    "start": "1379970",
    "end": "1386460"
  },
  {
    "text": "the programmer never thought\nanything about what the hardware is -- just wrote abstract graph\nand data streaming.",
    "start": "1386460",
    "end": "1392780"
  },
  {
    "text": "And given Raw, we automatically\nactually mapped into it, and figured out what\nis the right balance, right",
    "start": "1392780",
    "end": "1397880"
  },
  {
    "text": "communication, right\nsynchronization, and got really good performance. And you're getting something\nlike 11x performance.",
    "start": "1397880",
    "end": "1404050"
  },
  {
    "text": "If you do hard hand, if you work\nhard probably you can do a little bit better. But this is good, because you\ndon't hand-do anything.",
    "start": "1404050",
    "end": "1409650"
  },
  {
    "text": "The killer thing is now I can\nprobably take this set of programs -- which we are\nactually working on -- is you",
    "start": "1409650",
    "end": "1414800"
  },
  {
    "text": "can take them to Cell which has,\ndepending on the day, six cores, seven cores, eight cores,\nand we can basically",
    "start": "1414800",
    "end": "1424100"
  },
  {
    "text": "get to matching the number\nof cores in there. So this is it because right now\nwhat happens is you have",
    "start": "1424100",
    "end": "1429390"
  },
  {
    "text": "to basically hand code all those\nthings, and this can automate all that process. So that's the idea, is can you\ndo this -- which we haven't",
    "start": "1429390",
    "end": "1435470"
  },
  {
    "text": "really proved and this\nis our research -- write once, use anywhere. So write this program once\nin this abstract way.",
    "start": "1435470",
    "end": "1444760"
  },
  {
    "text": "You have to really don't think\nabout full parallelism. You have to think about some\namount of parallelism, how",
    "start": "1444760",
    "end": "1449815"
  },
  {
    "text": "this can be put into a stream\ngraph, but you are not dealing with synchronization, load\nbalancing, performance.",
    "start": "1449815",
    "end": "1455530"
  },
  {
    "text": "You don't have to\ndeal with that. And then the compiler will\nautomatically do all these things behind you, and get\nreally good performance.",
    "start": "1455530",
    "end": "1462800"
  },
  {
    "text": "And the reason I showed\nthis was -- I'll just play one more\nslide I think -- ",
    "start": "1462800",
    "end": "1470710"
  },
  {
    "text": "showed this was it's\nnot a simple thing. The compiler actually has to do\na bunch of work, the work that you used to do before.",
    "start": "1470710",
    "end": "1476929"
  },
  {
    "text": "Things like figuring out what's\nthe right granularity, what's the right mix of\noperations, what type of",
    "start": "1476930",
    "end": "1483779"
  },
  {
    "text": "transformations you need\nto do to get there. But at some point we did three\nthings -- coarse-grained, data",
    "start": "1483780",
    "end": "1491970"
  },
  {
    "text": "parallel, and software\npipelining. And by doing these three we can\nactually get a really good performance in most of the\nprograms we have. So what we",
    "start": "1491970",
    "end": "1500620"
  },
  {
    "text": "are hoping is basically this\nkind of techniques can in fact help programmers to get\nmulticore performance without",
    "start": "1500620",
    "end": "1508380"
  },
  {
    "text": "really going and dealing in the\ngrunge level of details you guys do. You guys will appreciate that,\nand hopefully will",
    "start": "1508380",
    "end": "1515430"
  },
  {
    "text": "think of making -- because now at the end of this\nclass, you will know all the pain and suffering the\nprogrammers go",
    "start": "1515430",
    "end": "1521520"
  },
  {
    "text": "through to get there. And the interesting thing would\nbe to in fact look at the ways to basically reduce\nthat pain and suffering.",
    "start": "1521520",
    "end": "1529100"
  },
  {
    "text": "So that's what I have today. So this was, as I promised,\na short lecture --",
    "start": "1529100",
    "end": "1536340"
  },
  {
    "text": "the second one. Any questions? ",
    "start": "1536340",
    "end": "1541611"
  },
  {
    "text": "AUDIENCE: So if we've got enough\ndata parallelism we'll have the same software pipeline\njumping on each tile?",
    "start": "1541611",
    "end": "1549321"
  },
  {
    "text": "Is that right? PROFESSOR: Yes. AUDIENCE: OK. So if you do that how does it\nscale up to something that has",
    "start": "1549322",
    "end": "1556002"
  },
  {
    "text": "higher communication\ncosts than Raw? By doing this software\npipelining you have to do all",
    "start": "1556002",
    "end": "1561939"
  },
  {
    "text": "of your communication\noff tile. PROFESSOR: So the interest in\nthere right now is we haven't",
    "start": "1561939",
    "end": "1568140"
  },
  {
    "text": "done any kind of hardware\npipelining. We are kind of doing --\neverybody's getting a lot of",
    "start": "1568140",
    "end": "1574039"
  },
  {
    "text": "data moving in there. The neat thing about right now\nis, even with the SP in Cell",
    "start": "1574040",
    "end": "1579950"
  },
  {
    "text": "and even Raw, the number of\ntiles are still small enough that a lot of communication\n-- unless way too much",
    "start": "1579950",
    "end": "1587240"
  },
  {
    "text": "communication -- it doesn't\nreally overwhelm you. Because everybody's nearby,\nyou can send things.",
    "start": "1587240",
    "end": "1592530"
  },
  {
    "text": "They talk a little bit about in\nCell that near enableness helps, but not that much.",
    "start": "1592530",
    "end": "1598310"
  },
  {
    "text": "But as we go into larger and\nlarger cores, it's going to become an issue.",
    "start": "1598310",
    "end": "1604360"
  },
  {
    "text": "Near enables become much easier\nto communicate, and you can't do global things\nin there. And at that point you will\nactually have to do some",
    "start": "1604360",
    "end": "1610230"
  },
  {
    "text": "hardware pipelining. You can't just assume that at\nsome point everybody's going to get some data and\ngo to something.",
    "start": "1610230",
    "end": "1616940"
  },
  {
    "text": "So what you need to do is have\ndifferent chunks that the only communication that would be\nbetween these chunks would be kind of a pipeline\ncommunication.",
    "start": "1616940",
    "end": "1622980"
  },
  {
    "text": "So you don't mix data around. So as we go into larger and\nlarger cores you need to start",
    "start": "1622980",
    "end": "1630260"
  },
  {
    "text": "doing techniques like that. The interesting thing here is\neven though what you had to",
    "start": "1630260",
    "end": "1636710"
  },
  {
    "text": "change was the compiler --\nhopefully the program stays the same -- right now it's not an easy\nissue, because our compiler",
    "start": "1636710",
    "end": "1642180"
  },
  {
    "text": "has 10 times more core than the\nprogram, so it's easier in the program. But if you look at something C,\nthe core base is millions",
    "start": "1642180",
    "end": "1650300"
  },
  {
    "text": "of times larger than the\nsize of the compiler. So at some point they'll\nbe switched. It's easier to change\nthe compiler to kind",
    "start": "1650300",
    "end": "1655500"
  },
  {
    "text": "of keep up to date. That's what happened in C. Every\ngeneration you change the compiler, you don't ask\nprogrammers where to code the",
    "start": "1655500",
    "end": "1661149"
  },
  {
    "text": "application. So can you make these kind of\nthings as the multicores",
    "start": "1661150",
    "end": "1666500"
  },
  {
    "text": "become different -- bigger, have different\nfeatures. You change the compiler to get\nthe performance, but have the",
    "start": "1666500",
    "end": "1672269"
  },
  {
    "text": "same code base. That's the goal for\nportability. ",
    "start": "1672270",
    "end": "1678711"
  },
  {
    "text": "AUDIENCE: Have you tried\napplying StreamIt or the streaming model in general, to\ncodes that are not not very",
    "start": "1678711",
    "end": "1686549"
  },
  {
    "text": "clearly stream-based but using\nthe streaming model to make",
    "start": "1686550",
    "end": "1692950"
  },
  {
    "text": "communication explicit, such\nas scientific codes. Or, for example, the kinds of\nparallelizable loops that you",
    "start": "1692950",
    "end": "1699100"
  },
  {
    "text": "covered in the first half\nof the lecture. PROFESSOR: Some of those things,\nwhen you have free form simple communication\ncan map into streaming.",
    "start": "1699100",
    "end": "1705809"
  },
  {
    "text": "So for example, one thing\nwe are doing is things like right now MPEG. Some part of the MPEG is nicely\nStreamIt, but when you",
    "start": "1705810",
    "end": "1713429"
  },
  {
    "text": "actually go inside the MPEG and\ndealing with the frame, it's basically a big array,\nand you're doing that.",
    "start": "1713430",
    "end": "1719809"
  },
  {
    "text": "So how do you chunkify the\narrays, and basically deal with it in a streaming order? There's some interesting\nthings you can do.",
    "start": "1719810",
    "end": "1724980"
  },
  {
    "text": "There will be some stuff\nthat doesn't fit that. Things like pattern recognition\ntype stuff, where",
    "start": "1724980",
    "end": "1735100"
  },
  {
    "text": "what you want to do\nis you want to -- assume you're trying to -- good example.",
    "start": "1735100",
    "end": "1741539"
  },
  {
    "text": "You're trying to feature\na condition in a video. And what happens is the number\nof features, can you match or",
    "start": "1741540",
    "end": "1747559"
  },
  {
    "text": "connect two features,\nor match and connect a thousand features. And then each feature you need\nto do some processing. And that is a very\ndynamic thing.",
    "start": "1747560",
    "end": "1754880"
  },
  {
    "text": "And that doesn't\nreally fit into streaming order right now. And so the interesting thing is,\nthe problem we have been",
    "start": "1754880",
    "end": "1761530"
  },
  {
    "text": "doing is we are trying to\nfit everything into one. So right now the object-oriented\nmodel is it",
    "start": "1761530",
    "end": "1766779"
  },
  {
    "text": "basically -- everything\nhas to fit in there. But what you're finding is there\nare many things that don't really fit nicely.",
    "start": "1766780",
    "end": "1772169"
  },
  {
    "text": "And you'll do these very crazy\nlooking things just to get every program to fit into the\nobject-oriented model.",
    "start": "1772170",
    "end": "1778320"
  },
  {
    "text": "That doesn't really work. I think the right way\nto work is, is there might be multiple models. There's a streaming model,\nthere's some kind of a",
    "start": "1778320",
    "end": "1784049"
  },
  {
    "text": "threaded model, there might\nbe different ones -- I don't know what other\nmodels are. So the key thing is your program\nmight have a large",
    "start": "1784050",
    "end": "1789450"
  },
  {
    "text": "chunky model, another\nchunky model. Don't try to come up with -- right now what we have\nis we have a kitchen",
    "start": "1789450",
    "end": "1795220"
  },
  {
    "text": "sink type of language. It tries to support everything\nat the same time. And that doesn't really work\nbecause then you have to think",
    "start": "1795220",
    "end": "1801030"
  },
  {
    "text": "about and say -- OK done, can I have\na pointer here? And I need to think about all\nthe possible models kind of",
    "start": "1801030",
    "end": "1808890"
  },
  {
    "text": "colliding in the same space. AUDIENCE: On the other hand, the\nobject-oriented model is",
    "start": "1808890",
    "end": "1814880"
  },
  {
    "text": "much more generalized to me. It's not the best model for\nmany things, but it's much more generalizable\nthan some models.",
    "start": "1814880",
    "end": "1820830"
  },
  {
    "text": "And having a single model cuts\ndown on the number of semantic barriers you have to cross -- PROFESSOR: I don't know but --",
    "start": "1820830",
    "end": "1826030"
  },
  {
    "text": "AUDIENCE: Semantic barriers\nincur both programmer overhead and run-time overhead.",
    "start": "1826030",
    "end": "1831380"
  },
  {
    "text": "PROFESSOR: See the problem with\nright now with all the semantic barriers, is\nobject-oriented model plus a",
    "start": "1831380",
    "end": "1836770"
  },
  {
    "text": "huge number of libraries. If you want to do OpenGL, it's\nobject-oriented but you have no library.",
    "start": "1836770",
    "end": "1842250"
  },
  {
    "text": "If you want to do something\nelse, you have to learn the library. What the right thing would be,\ninstead of trying to learn the libraries is learn kind\nof a subset language.",
    "start": "1842250",
    "end": "1849880"
  },
  {
    "text": "So you have nice semantics, you\nhave nice syntax in there, you have nice error\nchecking, nice",
    "start": "1849880",
    "end": "1856380"
  },
  {
    "text": "optimization within that syntax. Because the trouble is right now\neverything is in this just gigantic language, and you\ncan't do anything.",
    "start": "1856380",
    "end": "1863620"
  },
  {
    "text": "And in the program you don't\neven know, because you can mix and match in really bad ways. The mix and match gives you\na lot of power, but it can",
    "start": "1863620",
    "end": "1873450"
  },
  {
    "text": "actually really hurt. And a lot of people\ndon't need it. Like for example in C, people\ndoubt it was really crucial",
    "start": "1873450",
    "end": "1879059"
  },
  {
    "text": "for you to access any part of\nmemory anywhere you want. You just can go and just access\nany program, anywhere,",
    "start": "1879060",
    "end": "1885270"
  },
  {
    "text": "anytime in there. If you look at it, nobody\ntakes advantage of that. How many times do you write the\nprogram an say -- \"Hey, I want to go access the other\nguy's stack from this part.\"",
    "start": "1885270",
    "end": "1892980"
  },
  {
    "text": "That doesn't work. You have a variable and\nyou use a variable. AUDIENCE: It still [OBSCURED] PROFESSOR: Yeah, but the thing\nis because of that power, it",
    "start": "1892980",
    "end": "1902020"
  },
  {
    "text": "creates a lot of problems\nfor a compiler -- because it needs to prove\nthat you're not doing that, which is hard.",
    "start": "1902020",
    "end": "1907530"
  },
  {
    "text": "And also, if you make a mistake\nthe program is like -- \"Yeah, this looks like right. It still matches my semantics\nand syntax, I'll let you do",
    "start": "1907530",
    "end": "1914649"
  },
  {
    "text": "that.\" But what you realize is\nthat's not something people do -- just stick with\nyour variable. And if you don't go\nto variables --",
    "start": "1914650",
    "end": "1921140"
  },
  {
    "text": "that's what type-safe languages\ndo -- it's probably more for bugs than a feature. And the same kind of thing\nhaving efficiency in language,",
    "start": "1921140",
    "end": "1928789"
  },
  {
    "text": "is you can do everything\nat the same time. Why can't you have a language\nthat you can go with this kind",
    "start": "1928790",
    "end": "1935130"
  },
  {
    "text": "of context. I'm in the streaming\ncontext now. I say this is my streaming\ncontext.",
    "start": "1935130",
    "end": "1940220"
  },
  {
    "text": "I am in a threaded context. Then what that does is, I have\nto learn the full set of",
    "start": "1940220",
    "end": "1945720"
  },
  {
    "text": "features, but I restrict\nwhat I'm using here. That can probably realistically\nimprove your",
    "start": "1945720",
    "end": "1950760"
  },
  {
    "text": "program building, because you\ndon't have to worry about -- AUDIENCE: It gives the\nprogrammer time to get to know each language.",
    "start": "1950760",
    "end": "1956080"
  },
  {
    "text": "PROFESSOR: But right now\nyou have to do that. If you look at C# it has\nall these features. It has streaming features, it\nhas threaded features, it has",
    "start": "1956080",
    "end": "1962770"
  },
  {
    "text": "every possible object-oriented\nfeature. AUDIENCE: Right, but there's a\ncompact central model which",
    "start": "1962770",
    "end": "1969465"
  },
  {
    "text": "covers most things. You can pull in additional\nfeatures and fit them [OBSCURED]. You can do pointer manipulation\nin C#, but you",
    "start": "1969465",
    "end": "1978745"
  },
  {
    "text": "bracket things into\nan unsafe block. And then the compiler knows\nin there you're doing really bad things.",
    "start": "1978745",
    "end": "1983799"
  },
  {
    "text": "PROFESSOR: That's a nice\nthing, because you can have unsafe. But can you have something\nlike -- this is",
    "start": "1983800",
    "end": "1988970"
  },
  {
    "text": "my streaming part. OK. Can I do something like\nthat, so I don't have to worry about other? The key thing is, is there a\nway where -- because right",
    "start": "1988970",
    "end": "1997210"
  },
  {
    "text": "now, my feeling is if you look\nat the object-oriented part. So if you are doing, for\nexample, Windows programming,",
    "start": "1997210",
    "end": "2003190"
  },
  {
    "text": "you can spend about a week\nand learn all the object-oriented concepts. And you have to spend probably\na year to learn all the",
    "start": "2003190",
    "end": "2008310"
  },
  {
    "text": "libraries on top of that. That's the old action\nthese days. It's basically the building\nblocks have become too low,",
    "start": "2008310",
    "end": "2015539"
  },
  {
    "text": "and then everything else is kind\nof an unorganized mess on top of that.",
    "start": "2015540",
    "end": "2021049"
  },
  {
    "text": "Can you put more abstraction\nthings that easy? Hey, I'm talking about\nresearch, this is one possible angle. I mean there might -- you can\nthink, I know there are messes",
    "start": "2021050",
    "end": "2028420"
  },
  {
    "text": "that I think in there. My feeling is what we do well\nis when things get too",
    "start": "2028420",
    "end": "2035309"
  },
  {
    "text": "complicated we build\nabstraction layers. And the interesting thing there\nis, we build this high",
    "start": "2035310",
    "end": "2042835"
  },
  {
    "text": "level programming language\nabstraction layer. And then now we have built so\nmuch crud on top of that",
    "start": "2042835",
    "end": "2049030"
  },
  {
    "text": "without any nice abstraction\nlayers, I think it's probably time to think through what\nthere could be at the abstraction level. Things like, it's hitting --",
    "start": "2049030",
    "end": "2055590"
  },
  {
    "text": "that is where parallelism\nis really hitting. Because that layer, the\nobject-oriented layer, doesn't really support that well.",
    "start": "2055590",
    "end": "2062530"
  },
  {
    "text": "And it's all kind of ad\nhoc on top of that. And so that says something. Yes, it's usable.",
    "start": "2062530",
    "end": "2069069"
  },
  {
    "text": "We had this argument -- assembly languages programmers\n-- for two decades. There are people who were swearing by assembly languages.",
    "start": "2069070",
    "end": "2074970"
  },
  {
    "text": "They could write it two times\nsmaller, two times faster than anything you can write in\nhigh level language.",
    "start": "2074970",
    "end": "2080679"
  },
  {
    "text": "It's probably still\ntrue today. But at the end there were\nthings that high level",
    "start": "2080680",
    "end": "2086550"
  },
  {
    "text": "languages won out. I think we are probably in\nanother layer like that. I don't know, probably will\ngo with that argument. You can always point to\nsomething saying this is",
    "start": "2086550",
    "end": "2092679"
  },
  {
    "text": "something you cannot do. If there are still things --\nlike structured programs and unstructured programs,\nwe talked about that.",
    "start": "2092680",
    "end": "2098260"
  },
  {
    "text": "That argument went\nfor a decade. AUDIENCE: The question I would\npose is can you formulate a",
    "start": "2098260",
    "end": "2104810"
  },
  {
    "text": "kitchen sink language at a\nparallelizable level of abstraction? PROFESSOR: Ah. That's interesting, because\nparallelization is -- one of",
    "start": "2104810",
    "end": "2112572"
  },
  {
    "text": "the biggest things people\nhave to figure out is composability. You can't have two parallel\nregions as a",
    "start": "2112572",
    "end": "2119530"
  },
  {
    "text": "black box put together. You start running into deadlocks\nand all those other issues in there.",
    "start": "2119530",
    "end": "2124720"
  },
  {
    "text": "Most of the things that you work\nis the abstraction works, because then you can compose at\na higher level abstraction.",
    "start": "2124720",
    "end": "2130850"
  },
  {
    "text": "You can have interface and\nsay -- here are something interface, I don't know what's\nunderneath, I compose at the interface level. And then the next guy composes\nat the higher level, and",
    "start": "2130850",
    "end": "2138960"
  },
  {
    "text": "everything is hidden. We don't know how to do that\nin parallelism right now. We need to combine two things,\nit runs into problems. And the",
    "start": "2138960",
    "end": "2147170"
  },
  {
    "text": "minute you figure that one out\n-- if somebody can figure out what's the right abstraction\nthat is composable, parallel",
    "start": "2147170",
    "end": "2152450"
  },
  {
    "text": "abstraction -- I think that will solve a\nhuge amount of problems. AUDIENCE: Isn't it Fortress that\nattempted to do something",
    "start": "2152450",
    "end": "2158831"
  },
  {
    "text": "that's parallelizable and the\nkitchen sink, but that then leaves all the parallelizable\n-- AUDIENCE: I'm saying how\nterrible [OBSCURED] programmers.",
    "start": "2158831",
    "end": "2166019"
  },
  {
    "text": "PROFESSOR: But I would say right\nnow is a very exciting time, because there's\na big problem and",
    "start": "2166020",
    "end": "2171240"
  },
  {
    "text": "nobody knows the solution. And I think for industry they\nlose a lot of sleep over that,",
    "start": "2171240",
    "end": "2177020"
  },
  {
    "text": "but for academia it's\nthe best time. Because we don't care, we don't\nhave to make money out of these things, we don't have\nto get production out of it.",
    "start": "2177020",
    "end": "2184170"
  },
  {
    "text": "But these actually have a very\nopen problem that a lot of people care about. And I think this is fun partly\nbecause of that.",
    "start": "2184170",
    "end": "2191119"
  },
  {
    "text": "I think this huge open problem\nthat if you talk to people like Intels and Microsoft, a\nlot of people worry a lot",
    "start": "2191120",
    "end": "2198070"
  },
  {
    "text": "about they don't know how to\ndeal with the future in 5-10 years time. They don't see this is scaling\nwhat they're doing.",
    "start": "2198070",
    "end": "2204990"
  },
  {
    "text": "And from Intel's point of\nview, they made money by making Moore's Law available\nfor people to use.",
    "start": "2204990",
    "end": "2213279"
  },
  {
    "text": "They know how to make it\navailable, but they don't know how to make people use it. From Microsoft's point of\nview, their current",
    "start": "2213280",
    "end": "2221150"
  },
  {
    "text": "development methodology is\nalmost at this breaking point. And if you look at the last\ntime this happening -- so",
    "start": "2221150",
    "end": "2229290"
  },
  {
    "text": "things like Windows 3.0, where\ntheir current development methodology doesn't really\nscale, and they really",
    "start": "2229290",
    "end": "2234670"
  },
  {
    "text": "revamped it. They came up with all this\nprocess, and that had lasted until now. For the last two Office and\nVista, just realized they",
    "start": "2234670",
    "end": "2242620"
  },
  {
    "text": "can't really scale that up. So they are already in trouble,\nbecause they can't write the next big goal is just\ntwo times bigger than",
    "start": "2242620",
    "end": "2249040"
  },
  {
    "text": "Vista, and hopefully\nget it working. But on top of that, they have\nit thrown this multicore",
    "start": "2249040",
    "end": "2254120"
  },
  {
    "text": "thing, and that really puts\nhuge amount of burden. So they are worried\nabout that. So from both their point of\nview, everybody's clamoring",
    "start": "2254120",
    "end": "2261840"
  },
  {
    "text": "for a solution.  And things like last\ntime around --",
    "start": "2261840",
    "end": "2266950"
  },
  {
    "text": "I'll talk about this in the\nfuture -- last time around when that happened, it created\na huge amount of opportunities, and bunch of\npeople who sold it kind of",
    "start": "2266950",
    "end": "2274720"
  },
  {
    "text": "became famous. Becuase they say -- we came up\nwith a solution, and that people started using and\nstuff like that.",
    "start": "2274720",
    "end": "2279890"
  },
  {
    "text": "Right now, everybody's kind of\nwaiting for somebody to come up and say here's the solution,\nhere's a solution.",
    "start": "2279890",
    "end": "2285500"
  },
  {
    "text": "And there are a lot of -- Fortress type exports is one,\nand what we are doing is one.",
    "start": "2285500",
    "end": "2290910"
  },
  {
    "text": "And hopefully some of you will\nend up doing something interesting that\nmight solve it. This is why it's fun.",
    "start": "2290910",
    "end": "2297089"
  },
  {
    "text": "I think we haven't had this much\nof an interesting time in programming languages,\nparallelism, architecture in",
    "start": "2297090",
    "end": "2304640"
  },
  {
    "text": "the last two decades. With that, I'll stop my talk.",
    "start": "2304640",
    "end": "2310680"
  },
  {
    "start": "2310680",
    "end": "2312979"
  }
]
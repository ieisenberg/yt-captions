[
  {
    "text": "[SQUEAKING] [RUSTLING] [CLICKING]",
    "start": "0",
    "end": "5357"
  },
  {
    "start": "5357",
    "end": "12180"
  },
  {
    "text": "RAFAEL JARAMILLO: Hello. Happy Monday. And welcome to lecture 28. We're going to continue working\non statistical thermodynamics,",
    "start": "12180",
    "end": "21480"
  },
  {
    "text": "and we'll start with the\nBoltzmann hypothesis. ",
    "start": "21480",
    "end": "31880"
  },
  {
    "text": "All right. And what Gibbs is to\nclassical thermal,",
    "start": "31880",
    "end": "41460"
  },
  {
    "text": "Boltzmann is to statistically.",
    "start": "41460",
    "end": "47910"
  },
  {
    "start": "47910",
    "end": "52960"
  },
  {
    "text": "And so these are really giants,\nand the reason why their names are all over everything. My understanding is that Gibbs\nwas a pretty straight shooter,",
    "start": "52960",
    "end": "60114"
  },
  {
    "text": "and his biography is a little\nbit on the boring side. That's my very quick read of it.",
    "start": "60115",
    "end": "65620"
  },
  {
    "text": "Boltzmann was a much more\nturbulent individual. And so it may not have\nbeen fun to be Boltzmann,",
    "start": "65620",
    "end": "72310"
  },
  {
    "text": "but his biography is a\nlot more interesting. So if you have a moment,\nyou might read a little bit about his life,\nanyway, but we're just",
    "start": "72310",
    "end": "79479"
  },
  {
    "text": "going to focus on the science. So here's the preamble. ",
    "start": "79480",
    "end": "88920"
  },
  {
    "text": "We have this quantity, which\nwe counted microstates, omega. ",
    "start": "88920",
    "end": "97909"
  },
  {
    "text": "It describes the stability. We haven't put it\nin these terms,",
    "start": "97910",
    "end": "103530"
  },
  {
    "text": "but it follows from\neverything we've been doing. Omega describes the\nstability of a macrostate",
    "start": "103530",
    "end": "110159"
  },
  {
    "text": "because the state with\nmaximum number of microstates",
    "start": "110160",
    "end": "123940"
  },
  {
    "text": "will appear. ",
    "start": "123940",
    "end": "137950"
  },
  {
    "text": "All right. So this is an observation\nfrom what we've done so far. And I hope this is\nsensible to you.",
    "start": "137950",
    "end": "145050"
  },
  {
    "text": "That the state with the\nmaximum number of microstates will appear the most stable. It's the most likely, and if\nyou find yourself in that state,",
    "start": "145050",
    "end": "152070"
  },
  {
    "text": "you're very unlikely to\nget out of that state. So it's going to appear to have\nthis property of stability.",
    "start": "152070",
    "end": "157680"
  },
  {
    "text": "And if you remember, towards\nthe beginning of this class, we defined equilibrium as having\nthis property of stability.",
    "start": "157680",
    "end": "166829"
  },
  {
    "text": "And so there's some\nconnection there. And so Boltzmann made that\nconnection with his hypothesis.",
    "start": "166830",
    "end": "172209"
  },
  {
    "text": " And his hypothesis is that\nthe entropy is a function",
    "start": "172210",
    "end": "181920"
  },
  {
    "text": "of the number of microstates. So the entropy of a\nmacrostate is a function of the number of\nmicrostates corresponding",
    "start": "181920",
    "end": "187710"
  },
  {
    "text": "to that macrostate. And more than that,\nhe hypothesized that entropy is a monotonically\nincreasing function of omega.",
    "start": "187710",
    "end": "211810"
  },
  {
    "text": "So this is a monotonically\nincreasing function. So what that means is that\nmax S means max omega.",
    "start": "211810",
    "end": "225980"
  },
  {
    "text": "So we're going to use that. Max entropy means max omega. So that's a hypothesis.",
    "start": "225980",
    "end": "232519"
  },
  {
    "text": "All right. So we're going to consider\nthe form of that function. This is pretty\neasily done, consider",
    "start": "232520",
    "end": "241240"
  },
  {
    "text": "two isolated systems,\nsystem A and system",
    "start": "241240",
    "end": "255270"
  },
  {
    "text": "B. System A is some stuff.",
    "start": "255270",
    "end": "262860"
  },
  {
    "text": "I don't know what it is. And it has number of\nmicrostates omega sub a,",
    "start": "262860",
    "end": "271635"
  },
  {
    "text": "and it has entropy\nextensive S of a. And system B is\nsome other stuff.",
    "start": "271635",
    "end": "278530"
  },
  {
    "text": "It's isolated from system A.\nIt's over on a different room, on a different\nshelf, what have you, and it has microstates\nomega b and entropy S of b.",
    "start": "278530",
    "end": "292395"
  },
  {
    "text": " So first of all,\nentropy is extensive,",
    "start": "292395",
    "end": "303780"
  },
  {
    "text": "which means that the total\nentropy in the system-- ",
    "start": "303780",
    "end": "310690"
  },
  {
    "text": "like any other\nextensive quantity, what should the entropy\nof the whole be?",
    "start": "310690",
    "end": "316168"
  },
  {
    "text": "I'll label that total.  STUDENT: Be the entropy\nof a plus the entropy b.",
    "start": "316168",
    "end": "324070"
  },
  {
    "text": "RAFAEL JARAMILLO: Yeah. Like any other extensive\nthing, like marbles in a jar or moles of material,\nyou just add them.",
    "start": "324070",
    "end": "334370"
  },
  {
    "text": "But the total number\nof microstates is--",
    "start": "334370",
    "end": "341590"
  },
  {
    "text": "I'll call it combinatoric. I don't know if that's a word. ",
    "start": "341590",
    "end": "347110"
  },
  {
    "text": "What I mean is, the total\nnumber of microstates",
    "start": "347110",
    "end": "352400"
  },
  {
    "text": "available if you consider\nboth systems is what? You can have microstate\n1 and all of these,",
    "start": "352400",
    "end": "360490"
  },
  {
    "text": "and you can have microstate\n2 and all of these, and microstate 3 and all\nof these, and so forth.",
    "start": "360490",
    "end": "365840"
  },
  {
    "text": "So what's the expression for\nthe total number of microstates considering both systems\nat the same time?",
    "start": "365840",
    "end": "371740"
  },
  {
    "start": "371740",
    "end": "377960"
  },
  {
    "text": "STUDENT: Is it the\nproduct of a and b? RAFAEL JARAMILLO: It's\nthe product, yeah. ",
    "start": "377960",
    "end": "384210"
  },
  {
    "text": "All right. So entropy is additive, but\nomega is multiplicative.",
    "start": "384210",
    "end": "391600"
  },
  {
    "text": "So that means f of\nomega total, which",
    "start": "391600",
    "end": "398410"
  },
  {
    "text": "is f of omega a times omega b,\nis f omega a plus f omega b.",
    "start": "398410",
    "end": "412300"
  },
  {
    "text": "We're using both of\nthese properties now.",
    "start": "412300",
    "end": "417810"
  },
  {
    "text": "So who knows a function\nthat has this property, the function of the product\nis the sum of the Function",
    "start": "417810",
    "end": "427258"
  },
  {
    "text": "STUDENT: Log? STUDENT: Logs? RAFAEL JARAMILLO: Yeah. So we come up with\nthis conclusion,",
    "start": "427258",
    "end": "433669"
  },
  {
    "text": "which is that this\nfunction we're looking for, which is entropy, is\nproportional to log of omega.",
    "start": "433670",
    "end": "442830"
  },
  {
    "text": "And we're going to\nright now just have a-- we have a pre factor out there. It doesn't change.",
    "start": "442830",
    "end": "449070"
  },
  {
    "text": "And so we're going to\ncall that pre factor k, and we'll put a b\nunder it because it be Boltzmann constant.",
    "start": "449070",
    "end": "455729"
  },
  {
    "text": "We don't know what it is\nyet, Boltzmann's constant.",
    "start": "455730",
    "end": "465530"
  },
  {
    "text": "And this is known as\nBoltzmann's entropy formula. ",
    "start": "465530",
    "end": "479139"
  },
  {
    "text": "So just like that, we have a\npretty simple-looking equation that gives us the entropy\nfor a system as a function",
    "start": "479140",
    "end": "486150"
  },
  {
    "text": "of the number of microstates. ",
    "start": "486150",
    "end": "492778"
  },
  {
    "text": "That's pretty cool. ",
    "start": "492778",
    "end": "497860"
  },
  {
    "text": "All right. So we still don't know what\nBoltzmann's constant is, but that's OK. So let's see what some\nimplications of that are.",
    "start": "497860",
    "end": "503820"
  },
  {
    "text": "We'll start with the same\nconfigurational entropy, which we have talked about\nthroughout the term. ",
    "start": "503820",
    "end": "514080"
  },
  {
    "text": "Configurational\nentropy, so what is?",
    "start": "514080",
    "end": "520679"
  },
  {
    "text": "It's a number of ways to\nconfigure a system and space. ",
    "start": "520679",
    "end": "526690"
  },
  {
    "text": "So I'm going to draw a grid.",
    "start": "526690",
    "end": "536920"
  },
  {
    "text": "This is going to be\nsimply suggestive. We're not going to analyze\nmy drawing because I'm just going to be rough about it.",
    "start": "536920",
    "end": "542870"
  },
  {
    "text": "Let's just put a particle\nhere and a particle here and a particle here\nand a particle here.",
    "start": "542870",
    "end": "548338"
  },
  {
    "text": "What we're going to\ndo is we're going to count the number of ways to\ndistribute n molecules into r",
    "start": "548338",
    "end": "568275"
  },
  {
    "text": "boxes. ",
    "start": "568275",
    "end": "573780"
  },
  {
    "text": "And we're going to have those\nboxes sufficiently small such",
    "start": "573780",
    "end": "585030"
  },
  {
    "text": "that no box has more\nthan one molecule.",
    "start": "585030",
    "end": "596690"
  },
  {
    "text": " So we're dividing space up into\ntiny, tiny, tiny little voxels",
    "start": "596690",
    "end": "605850"
  },
  {
    "text": "Well, we know how\nto do this already. We talked about\nthis the other time. This is just r choose n,\nand that's r factorial--",
    "start": "605850",
    "end": "619370"
  },
  {
    "text": "wait, sorry-- over n factorial--\nthere's an error in the notes there-- r minus n factorial, r choose n.",
    "start": "619370",
    "end": "627320"
  },
  {
    "text": "Good. So now what we're\ngoing to do is we're going to let the\ntotal number of boxes",
    "start": "627320",
    "end": "634500"
  },
  {
    "text": "be the total volume divided\nby some little volume b.",
    "start": "634500",
    "end": "639810"
  },
  {
    "text": "And so this is total volume\nand this is a little voxel.",
    "start": "639810",
    "end": "650635"
  },
  {
    "text": " And we can say\ncorresponds to volume--",
    "start": "650635",
    "end": "658670"
  },
  {
    "start": "658670",
    "end": "665930"
  },
  {
    "text": "we can say this corresponds\nto the volume of a molecule. It's a tiny, tiny\nlittle amount of space,",
    "start": "665930",
    "end": "671430"
  },
  {
    "text": "but it enforces our condition\nhere that the boxes cannot have more than one molecule.",
    "start": "671430",
    "end": "676490"
  },
  {
    "text": " So now it can be shown--",
    "start": "676490",
    "end": "683830"
  },
  {
    "text": "you will apiece that-- can be shown that the\nlog of r choose n--",
    "start": "683830",
    "end": "693850"
  },
  {
    "text": "you're going to take\nthe log of omega, that's the Boltzmann hypothesis,\nBoltzmann entropy formula thing, so you're\ngoing to take the log",
    "start": "693850",
    "end": "700060"
  },
  {
    "text": "of this binomial\ncoefficient, the log of r choose n is approximately\nn log r for r",
    "start": "700060",
    "end": "715190"
  },
  {
    "text": "very, very much larger than n. So r very, very much larger\nthan an n corresponds to--",
    "start": "715190",
    "end": "721670"
  },
  {
    "text": "let's say a gas. Most of space is empty. There's a much larger\nnumber of voxels of space",
    "start": "721670",
    "end": "730339"
  },
  {
    "text": "than there are molecules\nthat fill them. So that's like a gas. ",
    "start": "730340",
    "end": "736000"
  },
  {
    "text": "And this is a-- ",
    "start": "736000",
    "end": "741029"
  },
  {
    "text": "that's a problem\non a current PSET. ",
    "start": "741030",
    "end": "748510"
  },
  {
    "text": "So far so good. Now what we're going\nto do, now let system",
    "start": "748510",
    "end": "761079"
  },
  {
    "text": "expand from volume to 2 volume.",
    "start": "761080",
    "end": "769140"
  },
  {
    "text": "So we're going to do an\nexpansion of this gas, and we're going\nto calculate delta",
    "start": "769140",
    "end": "774589"
  },
  {
    "text": "S. We're going to do this using\nstatistical thermodynamics now. We're not going to do it the way\nwe did a month and a 1/2 ago.",
    "start": "774590",
    "end": "783630"
  },
  {
    "text": "You have Boltzmann's constant\ntimes n, and let's see.",
    "start": "783630",
    "end": "789370"
  },
  {
    "text": "Log 2 volume over b\nminus log volume over b.",
    "start": "789370",
    "end": "796135"
  },
  {
    "text": " And we can collect\nterms and simplify.",
    "start": "796135",
    "end": "802960"
  },
  {
    "text": "This is kbn log 2 v\nover v equals kbn log 2.",
    "start": "802960",
    "end": "819360"
  },
  {
    "start": "819360",
    "end": "827420"
  },
  {
    "text": "So this here, kbn, this is R\nn equals Avogadro's number.",
    "start": "827420",
    "end": "843700"
  },
  {
    "text": " We recall this from the\nclassical derivation,",
    "start": "843700",
    "end": "849660"
  },
  {
    "text": "isothermal expansion\nof an ideal gas. This is the same result\nfor isothermal expansion",
    "start": "849660",
    "end": "870070"
  },
  {
    "text": "of ideal gas. Delta S equals R log v\nfinal over v initial.",
    "start": "870070",
    "end": "881620"
  },
  {
    "text": " So this is one way to\nstart identifying what",
    "start": "881620",
    "end": "887900"
  },
  {
    "text": "that Boltzmann constant is. Boltzmann's constant is R\ndivided by Avogadro's number.",
    "start": "887900",
    "end": "896779"
  },
  {
    "text": "That's cool.  That's neat.",
    "start": "896780",
    "end": "902060"
  },
  {
    "text": "We've done this weird\nstatistical thing, and good, old Ludwig\ncame up with this.",
    "start": "902060",
    "end": "910130"
  },
  {
    "text": "And we find that when we\ncalculate a simple case,",
    "start": "910130",
    "end": "915140"
  },
  {
    "text": "we get functionally\nthe same thing as when we calculated this case,\nwhen we didn't know anything about molecules.",
    "start": "915140",
    "end": "920990"
  },
  {
    "text": "And we were just dealing with\nclassical thermodynamics. We can make the connection\nvia the coefficients.",
    "start": "920990",
    "end": "927220"
  },
  {
    "text": "That's cool. ",
    "start": "927220",
    "end": "932590"
  },
  {
    "text": "Great. Questions about this? Because I'm going to\nmove on to the next thing that Boltzmann did. ",
    "start": "932590",
    "end": "939685"
  },
  {
    "text": "The next thing\nwe're going to do, and what we're really\nbuilding up to here, is the maximum entropy\ncondition, maximum entropy",
    "start": "939685",
    "end": "959400"
  },
  {
    "text": "condition and the\nBoltzmann distribution.",
    "start": "959400",
    "end": "968600"
  },
  {
    "start": "968600",
    "end": "973639"
  },
  {
    "text": "So we get Boltzmann hypothesis,\nBoltzmann entropy formula. And this is going to be\nBoltzmann distribution,",
    "start": "973640",
    "end": "979120"
  },
  {
    "text": "this Boltzmann's constant\nBoltzmann's name is everywhere.",
    "start": "979120",
    "end": "985029"
  },
  {
    "text": "We're going to set this\nup and do most of it,",
    "start": "985030",
    "end": "994970"
  },
  {
    "text": "but this will carry\nover into lecture 29. It's that essential that\nit's worth taking the time. ",
    "start": "994970",
    "end": "1003680"
  },
  {
    "text": "All right. So what we're going to do? We're going to consider n\ntotal particles distributed",
    "start": "1003680",
    "end": "1022880"
  },
  {
    "text": "over r states according\nto the occupation numbers.",
    "start": "1022880",
    "end": "1034764"
  },
  {
    "start": "1034764",
    "end": "1041540"
  },
  {
    "text": "We have these occupation\nnumbers from last time. All right. That's a set of numbers, n\nof 1, n of 2, and all over--",
    "start": "1041540",
    "end": "1051257"
  },
  {
    "text": "all the way up to n of r. So how many states are-- how\nmany particles in each state? And we're going to calculate\nthe entropy of this thing.",
    "start": "1051258",
    "end": "1060980"
  },
  {
    "text": "So again, taking from last\ntime, from our last lecture, is going to be kb\ntime to log n of total",
    "start": "1060980",
    "end": "1073440"
  },
  {
    "text": "over product n of i,\neverything factorial.",
    "start": "1073440",
    "end": "1080799"
  },
  {
    "text": " Now, I'm going to use\nSterling's approximation",
    "start": "1080800",
    "end": "1095290"
  },
  {
    "text": "to get to the next line,\nwhich is going to be kb,",
    "start": "1095290",
    "end": "1100960"
  },
  {
    "text": "n total log n total minus n\ntotal minus sum n of i log",
    "start": "1100960",
    "end": "1115399"
  },
  {
    "text": "n of i plus sum n of i.",
    "start": "1115400",
    "end": "1121150"
  },
  {
    "start": "1121150",
    "end": "1126780"
  },
  {
    "text": "So I use this Sterling\napproximation, and then I'm going to use\nthe fact, the sum over i.",
    "start": "1126780",
    "end": "1135446"
  },
  {
    "text": "n of ni equals n\ntotal, so the sum of where all the particles\nare equals all the particles.",
    "start": "1135446",
    "end": "1142260"
  },
  {
    "text": "So I can simplify a little bit. This equals kb n\ntotal log n total",
    "start": "1142260",
    "end": "1153789"
  },
  {
    "text": "minus sum over i,\nn of i log n of i.",
    "start": "1153790",
    "end": "1162600"
  },
  {
    "text": "And now I can condense\nthis a little bit. I'm going to split the\nnumerator and denominator,",
    "start": "1162600",
    "end": "1170460"
  },
  {
    "text": "figure the minus sign, and I\nget a log n of i over n total.",
    "start": "1170460",
    "end": "1179414"
  },
  {
    "text": "So so far, just\nplaying with numbers. So I have the entropy\nis a sum for n",
    "start": "1179414",
    "end": "1184600"
  },
  {
    "text": "of i log n of i over n total. ",
    "start": "1184600",
    "end": "1193740"
  },
  {
    "text": "By the way, this kind of looks\nlike x log x, doesn't it? It kind of looks like our\nideal entropy formula.",
    "start": "1193740",
    "end": "1201730"
  },
  {
    "text": "Anyway, just a\npassing observation.  All right.",
    "start": "1201730",
    "end": "1207150"
  },
  {
    "text": "So that's fine. Here's the science inside. The distribution of occupation\nnumbers, the distribution",
    "start": "1207150",
    "end": "1229510"
  },
  {
    "text": "of occupation numbers is\nan unconstrained internal",
    "start": "1229510",
    "end": "1240540"
  },
  {
    "text": "variable. ",
    "start": "1240540",
    "end": "1249070"
  },
  {
    "text": "That means that those particles\nare going to fluctuate. They're going to fluctuate in\nand out of different states,",
    "start": "1249070",
    "end": "1256070"
  },
  {
    "text": "and that's an\nunconstrained process. So in our previous example,\nyou had particles in a box.",
    "start": "1256070",
    "end": "1262020"
  },
  {
    "text": "And I you could imagine these\nparticles in general move. They could jump\nin between boxes. That's an example of\njumping in between states,",
    "start": "1262020",
    "end": "1269720"
  },
  {
    "text": "we're going to make this a\nlittle more general and not limited to states being\npositions in space.",
    "start": "1269720",
    "end": "1276350"
  },
  {
    "text": "We're going to have a\nmore general expression. We're going to say, let's\nsay, state i minus 1.",
    "start": "1276350",
    "end": "1283170"
  },
  {
    "text": "We have state i and\nstate i plus 1, so forth.",
    "start": "1283170",
    "end": "1292650"
  },
  {
    "start": "1292650",
    "end": "1302760"
  },
  {
    "text": "And we're going to allow that-- At any given moment,\nlet's say there's four particles in this state.",
    "start": "1302760",
    "end": "1308760"
  },
  {
    "text": "Let's say there's two\nparticles in this state. And there was a third,\nbut that particle jumped.",
    "start": "1308760",
    "end": "1316370"
  },
  {
    "text": "It fluctuated and\nwent over here. This is simply\nvisually acknowledging",
    "start": "1316370",
    "end": "1323520"
  },
  {
    "text": "that the states are fluctuating. The particles are\nfluctuating between them.",
    "start": "1323520",
    "end": "1328690"
  },
  {
    "text": "These fluctuations\ncan and will happen.",
    "start": "1328690",
    "end": "1339144"
  },
  {
    "start": "1339145",
    "end": "1345760"
  },
  {
    "text": "So if that's happening, the\nmaximum entropy condition,",
    "start": "1345760",
    "end": "1359810"
  },
  {
    "text": "S equals S max,\nrequires that S is what?",
    "start": "1359810",
    "end": "1375060"
  },
  {
    "text": "Stationary. As we have done now so\nmany times in this class,",
    "start": "1375060",
    "end": "1380530"
  },
  {
    "text": "it has to be\nstationary with respect to all unconstrained\ninternal processes.",
    "start": "1380530",
    "end": "1387520"
  },
  {
    "start": "1387520",
    "end": "1400010"
  },
  {
    "text": "So this conceptually, where\nwe're going is the following. We did something\nlike this before. We've done it multiple times.",
    "start": "1400010",
    "end": "1407330"
  },
  {
    "text": "When we had two systems\nthat can exchange volume,",
    "start": "1407330",
    "end": "1412620"
  },
  {
    "text": "we require the entropy to\nstationary with respect to that. And we got the mechanical\nequilibrium condition.",
    "start": "1412620",
    "end": "1419550"
  },
  {
    "text": "Pressures are equal. And we had two systems\nthat can exchange energy. We wrote out the max\nentropy condition,",
    "start": "1419550",
    "end": "1430980"
  },
  {
    "text": "and we require that the entropy\nis stationary with respect to the energy exchange. And we got the thermal\nequilibrium condition.",
    "start": "1430980",
    "end": "1437520"
  },
  {
    "text": "We got the\ntemperatures are equal. And likewise with systems that\ncould exchange particle number, we got chemical\npotential being equal.",
    "start": "1437520",
    "end": "1444582"
  },
  {
    "text": "Adding that whole\nthing up, we call that thermodynamic equilibrium. So now we're doing something\nslightly different.",
    "start": "1444582",
    "end": "1451220"
  },
  {
    "text": "We're requiring this entropy\nstationary with respect to exchange between\ndifferent states.",
    "start": "1451220",
    "end": "1457180"
  },
  {
    "text": "And it's pretty\ngeneral right now. So a little bit\nvague, but there are",
    "start": "1457180",
    "end": "1463070"
  },
  {
    "text": "clear similarities to what\nwe've done earlier in the class. At least there are\nmathematical similarities.",
    "start": "1463070",
    "end": "1469590"
  },
  {
    "text": "So ds prime-- that's\nwrite that out-- equals minus\nBoltzmann's constant.",
    "start": "1469590",
    "end": "1476760"
  },
  {
    "text": "And what I'm doing is I'm just\ntaking the total derivative, so L log n of i, dn of i--",
    "start": "1476760",
    "end": "1487380"
  },
  {
    "text": "see-- plus n of i over n of i d\nn of i minus log of n total d n",
    "start": "1487380",
    "end": "1501640"
  },
  {
    "text": "of i minus n of i over n total--",
    "start": "1501640",
    "end": "1507180"
  },
  {
    "text": "just taking the total\nderivative of the expression on the previous slide.",
    "start": "1507180",
    "end": "1513830"
  },
  {
    "text": "And this simplifies\npretty readily. And I get minus\nBoltzmann constant",
    "start": "1513830",
    "end": "1522440"
  },
  {
    "text": "and the sum over log n of\ni over n total dn of i.",
    "start": "1522440",
    "end": "1532745"
  },
  {
    "start": "1532745",
    "end": "1541540"
  },
  {
    "text": "All right. Just, again, making\nthis explicit. ",
    "start": "1541540",
    "end": "1546720"
  },
  {
    "text": "I just took the total derivative\nof this using the chain rule. ",
    "start": "1546720",
    "end": "1554230"
  },
  {
    "text": "All right. So that's the S, and I have\nall my little unconstrained internal processes here,\nlittle fluctuations",
    "start": "1554230",
    "end": "1561220"
  },
  {
    "text": "between the occupation numbers. All right. Now let's apply my constraints.",
    "start": "1561220",
    "end": "1567130"
  },
  {
    "text": "That's what we did before, and\nthat's what we'll do again. And in this case, I'm going to\napply isolation constraints.",
    "start": "1567130",
    "end": "1572950"
  },
  {
    "start": "1572950",
    "end": "1581059"
  },
  {
    "text": "Isolation constraints, so I\nwant my system to be isolated. Max entropy is the\nequilibrium condition",
    "start": "1581060",
    "end": "1587330"
  },
  {
    "text": "for an isolated system. We remember that. So here's my little fluffy--",
    "start": "1587330",
    "end": "1594495"
  },
  {
    "text": " pink insulation here\nsurrounding my system,",
    "start": "1594495",
    "end": "1600270"
  },
  {
    "text": "and I've got system\nsurroundings and what?",
    "start": "1600270",
    "end": "1610770"
  },
  {
    "text": "The boundary is rigid. It is impermeable,\nand it is insulating.",
    "start": "1610770",
    "end": "1624750"
  },
  {
    "start": "1624750",
    "end": "1631430"
  },
  {
    "text": "All right. Now we're going to\nallow that the states",
    "start": "1631430",
    "end": "1638520"
  },
  {
    "text": "I have different energies. That e sub i be the energy\nper particle state I.",
    "start": "1638520",
    "end": "1656997"
  },
  {
    "text": "And I don't want to\njust slip this in there. This is kind of new. ",
    "start": "1656997",
    "end": "1662830"
  },
  {
    "text": "This is kind of new for us\nbecause previously in the baby book, and even just 15\nminutes ago in this example",
    "start": "1662830",
    "end": "1672400"
  },
  {
    "text": "of configuration\nentropy, we had this idea that space was somehow\nflat and uniform.",
    "start": "1672400",
    "end": "1677470"
  },
  {
    "text": "And the energy of each\nparticle would not be dependent on its position.",
    "start": "1677470",
    "end": "1682630"
  },
  {
    "text": "All right. So if the states are\npositions, maybe you have a gravitational\npotential, or maybe you",
    "start": "1682630",
    "end": "1688453"
  },
  {
    "text": "have an electric field. Maybe this a battery, and\nthere's an electric potential. And maybe the\nparticles are charged,",
    "start": "1688453",
    "end": "1694990"
  },
  {
    "text": "and then you can imagine energy\nand space becoming conflated. But more generally,\nthere's no reason",
    "start": "1694990",
    "end": "1701380"
  },
  {
    "text": "why these states have to\nbe positions in space.",
    "start": "1701380",
    "end": "1706840"
  },
  {
    "text": "They could be spin states\nor vibrational states. They could be rotational states.",
    "start": "1706840",
    "end": "1712490"
  },
  {
    "text": "They can be anything\nthat is distinct. Different states have\na particle in general.",
    "start": "1712490",
    "end": "1718837"
  },
  {
    "text": "These different states can\nhave different energies per particle. So e sub i equals the energy\nper particle and state I.",
    "start": "1718837",
    "end": "1725960"
  },
  {
    "text": "And so we're going to then\nsay the total internal energy is pretty simple. It's just adding up\nall the energies,",
    "start": "1725960",
    "end": "1733770"
  },
  {
    "text": "e sub i times n sub i. And that means that du\nequals e sub i dn of i.",
    "start": "1733770",
    "end": "1749200"
  },
  {
    "text": "Its conservation of energy. ",
    "start": "1749200",
    "end": "1763480"
  },
  {
    "text": "So you're going to study a\nsystem of elastic collisions",
    "start": "1763480",
    "end": "1768501"
  },
  {
    "text": "in the lab. And the individual\nparticle energy isn't going to be\nchanging, but I think you can trust\nthat the total system",
    "start": "1768501",
    "end": "1775590"
  },
  {
    "text": "energy for elastic collisions\nor rigid billiard balls, that doesn't change. So one gains and other\nloses and so forth.",
    "start": "1775590",
    "end": "1783240"
  },
  {
    "text": "And likewise, we have the\ntotal number of particles. And this is a pretty\nsimple expression.",
    "start": "1783240",
    "end": "1788750"
  },
  {
    "text": "This is the sum n of i. And that means dn total\nequals the sum dn of i.",
    "start": "1788750",
    "end": "1803230"
  },
  {
    "text": "I'm sorry I forgot. This is going to\nbe 0, and this is going to be 0, conservational\nof mass, conservation of mass.",
    "start": "1803230",
    "end": "1814934"
  },
  {
    "text": " So now I have some mathematical\nways to apply these conditions.",
    "start": "1814935",
    "end": "1822780"
  },
  {
    "text": "And I'll just make\na note in passing,",
    "start": "1822780",
    "end": "1828040"
  },
  {
    "text": "this really is beyond\nthe scope of this class, but those who are interested,\nconservation of volume,",
    "start": "1828040",
    "end": "1839985"
  },
  {
    "text": "you might say,\nwhat about volume? Before, two months ago, you\nwere considering volume, energy particle number and volume.",
    "start": "1839985",
    "end": "1846100"
  },
  {
    "text": "We're not touching\nconservational volume right now, but it's connected\nto the E Is being constant.",
    "start": "1846100",
    "end": "1860755"
  },
  {
    "start": "1860755",
    "end": "1866010"
  },
  {
    "text": "When I took du, I didn't\napply the chain rule and allow the E of Is to change.",
    "start": "1866010",
    "end": "1871510"
  },
  {
    "text": "I assumed they were constants. And that comes from the\nconservational volume.",
    "start": "1871510",
    "end": "1877260"
  },
  {
    "text": "So when you take quantum\nmechanics next semester, this comes out right away, so.",
    "start": "1877260",
    "end": "1883470"
  },
  {
    "text": "All right. But we're not going\nto touch it here. ",
    "start": "1883470",
    "end": "1888690"
  },
  {
    "text": "So this is a case of constrained\noptimization, constrained",
    "start": "1888690",
    "end": "1900169"
  },
  {
    "text": "optimization.  Constraint optimization is\nthe most important application",
    "start": "1900170",
    "end": "1908580"
  },
  {
    "text": "of calculus in\nengineering, in business. It's in general\nwhat you do in Sloan and what you do in\ncourse 16 and course 2.",
    "start": "1908580",
    "end": "1915870"
  },
  {
    "text": "A little bit less\nin course 3, but you should remember\nthis from calculus. So we want to optimize\nthat function,",
    "start": "1915870",
    "end": "1929929"
  },
  {
    "text": "subject to constraints, that the\nenergy and the total particle",
    "start": "1929930",
    "end": "1945250"
  },
  {
    "text": "number are fixed.  So we're going to\nuse the method--",
    "start": "1945250",
    "end": "1950350"
  },
  {
    "text": "anyone remember? What method are we going to use? Is it from multi? ",
    "start": "1950350",
    "end": "1958930"
  },
  {
    "text": "French name. STUDENT: The\nLagrange multiplier?",
    "start": "1958930",
    "end": "1964025"
  },
  {
    "text": " RAFAEL JARAMILLO: Yeah. Thank you. ",
    "start": "1964025",
    "end": "1971012"
  },
  {
    "text": "We're going to use [INAUDIBLE]\nof the Lagrange multipliers. So in your calculus\ntextbook, you would have used\nthe del operator.",
    "start": "1971012",
    "end": "1976710"
  },
  {
    "text": "I'll just write that here\njust for familiarity, but then we'll switch\nback to our operator. And so what do we have?",
    "start": "1976710",
    "end": "1982620"
  },
  {
    "text": "Del, the thing we\nwant to optimize, plus del, the things\nwhich are conserved. And we have Lagrange\nmultipliers.",
    "start": "1982620",
    "end": "1989880"
  },
  {
    "text": "So we have del n\ntotal and del u, and this whole thing\nis going to be 0.",
    "start": "1989880",
    "end": "1995309"
  },
  {
    "text": "This is written as in your calc\ntextbook with the del operator,",
    "start": "1995310",
    "end": "2006860"
  },
  {
    "text": "but we're going to write\nthis way, ds plus alpha dn",
    "start": "2006860",
    "end": "2012860"
  },
  {
    "text": "total plus beta du equals 0.",
    "start": "2012860",
    "end": "2018590"
  },
  {
    "text": "And alpha and beta are\nLagrange multipliers. ",
    "start": "2018590",
    "end": "2033680"
  },
  {
    "text": "I was talking to my wife\nabout this actually. She teaches college math. And it does seem this is the\nmost important application",
    "start": "2033680",
    "end": "2042080"
  },
  {
    "text": "of calculus outside of some\nspecialty areas, at least",
    "start": "2042080",
    "end": "2050300"
  },
  {
    "text": "the most widespread. Anyway. So we're going to\nsubstitute our expressions.",
    "start": "2050300",
    "end": "2055549"
  },
  {
    "start": "2055550",
    "end": "2064540"
  },
  {
    "text": "We have expressions for\nds and du and dn total",
    "start": "2064540",
    "end": "2074638"
  },
  {
    "text": "and collect terms. That's what we're going to do. ",
    "start": "2074639",
    "end": "2080770"
  },
  {
    "text": "So we substitute\nour expressions, and we collect terms, and we get\nthe following, sum over states,",
    "start": "2080770",
    "end": "2088520"
  },
  {
    "text": "we're going to have minus k sub\nbeta log n of i over n total",
    "start": "2088520",
    "end": "2098600"
  },
  {
    "text": "plus alpha plus beta e\nof i, dn of i equals 0.",
    "start": "2098600",
    "end": "2110300"
  },
  {
    "text": "So what is this functional form? What is this form? This is just like we\ndid two months ago,",
    "start": "2110300",
    "end": "2118120"
  },
  {
    "text": "starting about two months ago,\nfor the case of unary systems. We have here a set of\nunconstrained independent",
    "start": "2118120",
    "end": "2138250"
  },
  {
    "text": "variables. And so we want this\nwhole thing to be zero. How do we ensure that\nthis whole thing is zero?",
    "start": "2138250",
    "end": "2144640"
  },
  {
    "start": "2144640",
    "end": "2153420"
  },
  {
    "text": "Remember these\ndifferential forms? What did we call the pre factor\nin front of the differential",
    "start": "2153420",
    "end": "2158850"
  },
  {
    "text": "of the independent variables?  STUDENT: You just said the\ncoefficients equal zero.",
    "start": "2158850",
    "end": "2166028"
  },
  {
    "text": "RAFAEL JARAMILLO:\nCoefficient, right? Exactly. We're going to set each\ncoefficient to zero.",
    "start": "2166028",
    "end": "2182260"
  },
  {
    "text": "So let's do that, minus kb log\nn of i over n total plus alpha,",
    "start": "2182260",
    "end": "2196490"
  },
  {
    "text": "plus beta e of i equals 0. I'm going to rearrange n of i\nover n total equals e to alpha",
    "start": "2196490",
    "end": "2210430"
  },
  {
    "text": "over kb, e beta e of i over kb.",
    "start": "2210430",
    "end": "2219960"
  },
  {
    "text": "And this is true for each state\nI equals 1, 2, through, say, r.",
    "start": "2219960",
    "end": "2231000"
  },
  {
    "text": "So we're not there\nyet, but we just had something really\nimportant to happen. ",
    "start": "2231000",
    "end": "2236690"
  },
  {
    "text": "This is a distribution function. All right. This is describing the\noccupancy of state I.",
    "start": "2236690",
    "end": "2247580"
  },
  {
    "text": "And it's a fractional occupancy. It's n of i over n of\ntotal, so the fraction of particles that\nare in state I.",
    "start": "2247580",
    "end": "2253880"
  },
  {
    "text": "And it's exponentially dependent\non the energy of state I.",
    "start": "2253880",
    "end": "2260609"
  },
  {
    "text": "All right. So I want you to\nnotice two things here. I'll just repeat what I said.",
    "start": "2260610",
    "end": "2266510"
  },
  {
    "text": "That this is a\ndistribution function. ",
    "start": "2266510",
    "end": "2271930"
  },
  {
    "text": "That's a very useful thing. That's a distribution function,\nand it's exponential in e of i.",
    "start": "2271930",
    "end": "2289053"
  },
  {
    "text": "But we haven't finished yet\nbecause we have these Lagrange multipliers. So we don't know\nwhat those are yet. So we're going to\ndetermine one of them now,",
    "start": "2289053",
    "end": "2295710"
  },
  {
    "text": "and we'll determine the\nother one on Wednesday. So we're going to determine\nalpha by normalization.",
    "start": "2295710",
    "end": "2309720"
  },
  {
    "text": "What do I mean by that?  What I mean by that is\nthe sum over all of i,",
    "start": "2309720",
    "end": "2317960"
  },
  {
    "text": "n of i over n total-- what is this sum, sum over\nall of i, n of I over n total?",
    "start": "2317960",
    "end": "2323735"
  },
  {
    "text": " STUDENT: Just one. RAFAEL JARAMILLO:\nYeah, it's one.",
    "start": "2323735",
    "end": "2329690"
  },
  {
    "text": "It's one. ",
    "start": "2329690",
    "end": "2335170"
  },
  {
    "text": "So if we set that\nequal to 1, we get the following, e to the\nalpha over Boltzmann's",
    "start": "2335170",
    "end": "2343890"
  },
  {
    "text": "constant equals 1 over sum over\ni, e beta, epsilon i over kp.",
    "start": "2343890",
    "end": "2359494"
  },
  {
    "text": "And we're going to\ngive this thing a name. ",
    "start": "2359495",
    "end": "2364948"
  },
  {
    "text": "We're going to call it\nthe partition function. ",
    "start": "2364948",
    "end": "2372880"
  },
  {
    "text": "The partition function Q is the\nsum over all possible states",
    "start": "2372880",
    "end": "2378410"
  },
  {
    "text": "e beta e of i over k Boltzmann.",
    "start": "2378410",
    "end": "2385809"
  },
  {
    "text": "So for now, it's just a name. What does that mean? It normalizes the distribution.",
    "start": "2385810",
    "end": "2393190"
  },
  {
    "text": "Why is it called\npartition function? It describes all\nthe different ways that the energy can be\npartitioned in the system.",
    "start": "2393190",
    "end": "2399950"
  },
  {
    "text": "So it's a sum over\nall the states, somehow characterizing\nthe system and all the ways energy can\nbe partitioned in their.",
    "start": "2399950",
    "end": "2407810"
  },
  {
    "text": "Partition function normalizes\nthe distribution function.",
    "start": "2407810",
    "end": "2421480"
  },
  {
    "start": "2421480",
    "end": "2428290"
  },
  {
    "text": "So this distribution\nfunction, n of i over n total",
    "start": "2428290",
    "end": "2434760"
  },
  {
    "text": "is equal eb beta epsilon i\nover k beta divided by Q.",
    "start": "2434760",
    "end": "2446470"
  },
  {
    "text": "So it looks like I end it about\nfive minutes early, but better that than rush\nthrough the derivation",
    "start": "2446470",
    "end": "2454809"
  },
  {
    "text": "of a determination of beta. So I'm going to stop\nnow and take questions.",
    "start": "2454810",
    "end": "2460839"
  },
  {
    "start": "2460840",
    "end": "2466130"
  },
  {
    "text": "STUDENT: Could you explain\nthe Lagrange multipliers a little bit? I can't find it.",
    "start": "2466130",
    "end": "2472012"
  },
  {
    "text": "RAFAEL JARAMILLO: Yeah. ",
    "start": "2472012",
    "end": "2480170"
  },
  {
    "text": "So you want to subject--",
    "start": "2480170",
    "end": "2486460"
  },
  {
    "text": "you want this to be 0 subject\nto the constraint that this is 0 and also this is 0.",
    "start": "2486460",
    "end": "2492800"
  },
  {
    "text": " And you know these\nare 0 because you're",
    "start": "2492800",
    "end": "2499720"
  },
  {
    "text": "applying those constraints. And so you can add these\nto the equation of delta",
    "start": "2499720",
    "end": "2505460"
  },
  {
    "text": "S equals 0 without fundamentally\nchanging the equation. ",
    "start": "2505460",
    "end": "2510540"
  },
  {
    "text": "And then alpha and beta are\nnot necessary mathematically, but they generalize\nthe situation.",
    "start": "2510540",
    "end": "2517109"
  },
  {
    "text": " And so then you can\neffectively relax--",
    "start": "2517110",
    "end": "2522359"
  },
  {
    "text": "you can relax your\nconstraints here, and the overall constraint is\nmaintained by alpha and beta.",
    "start": "2522360",
    "end": "2530340"
  },
  {
    "text": "So your method of\nLagrange multipliers is only valid with--",
    "start": "2530340",
    "end": "2536065"
  },
  {
    "text": "the equations that\nresult from this appear as if they might\nbe valid even when",
    "start": "2536065",
    "end": "2542100"
  },
  {
    "text": "the constraints on total number\nof particles and energy relax, but they're not.",
    "start": "2542100",
    "end": "2547320"
  },
  {
    "text": "You have to remember that. The equations that we\nget from this method",
    "start": "2547320",
    "end": "2554520"
  },
  {
    "text": "are only applicable when\nu of t and n are fixed. ",
    "start": "2554520",
    "end": "2562650"
  },
  {
    "text": "So that's the\nconcept point here. And so when we derive a\ndistribution function,",
    "start": "2562650",
    "end": "2571450"
  },
  {
    "text": "we have this\ndistribution function, or we have this form here. And this, of course, also\nrelates to the Arrhenius rate",
    "start": "2571450",
    "end": "2578320"
  },
  {
    "text": "law. So we're getting there. And people will see this\ndistribution function",
    "start": "2578320",
    "end": "2586609"
  },
  {
    "text": "so often in natural\nsciences that it's important to remember\nit's not always true.",
    "start": "2586610",
    "end": "2595570"
  },
  {
    "text": "It is very specifically true\nthat it is the distribution function that maxima optimizes\nentropy under this condition.",
    "start": "2595570",
    "end": "2604940"
  },
  {
    "text": "So I think that's\nthe concept here. So don't apply it willy-nilly.",
    "start": "2604940",
    "end": "2611798"
  },
  {
    "text": "STUDENT: Thank you. RAFAEL JARAMILLO: But\nyou don't have to worry. This isn't a calculus\nclass in the sense that I'm going to ask you to\nderive this or even repeat",
    "start": "2611798",
    "end": "2617900"
  },
  {
    "text": "this derivation,\nbut I do want you to know where this\ncomes from, because this is going to start\nbecoming second nature,",
    "start": "2617900",
    "end": "2623270"
  },
  {
    "text": "not necessarily in the\nnext week and a 1/2. But this distribution\nfunction is going to be so familiar\nto you by the time you're",
    "start": "2623270",
    "end": "2628655"
  },
  {
    "text": "a fourth year student\nin material science. It's good to remember that\nit comes from somewhere, and it's subject to assumptions.",
    "start": "2628655",
    "end": "2636910"
  },
  {
    "start": "2636910",
    "end": "2639000"
  }
]
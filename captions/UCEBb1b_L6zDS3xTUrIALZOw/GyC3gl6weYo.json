[
  {
    "start": "0",
    "end": "13665"
  },
  {
    "text": "GILBERT STRANG: Moving\nnow to the second half",
    "start": "13665",
    "end": "15540"
  },
  {
    "text": "of linear algebra.",
    "start": "15540",
    "end": "17220"
  },
  {
    "text": "It's about eigenvalues\nand eigenvectors.",
    "start": "17220",
    "end": "20160"
  },
  {
    "text": "The first half, I\njust had a matrix.",
    "start": "20160",
    "end": "22320"
  },
  {
    "text": "I solved equations.",
    "start": "22320",
    "end": "24180"
  },
  {
    "text": "The second half,\nyou'll see the point",
    "start": "24180",
    "end": "27150"
  },
  {
    "text": "of eigenvalues and\neigenvectors as a new way",
    "start": "27150",
    "end": "29820"
  },
  {
    "text": "to look deeper into the matrix\nto see what's important there.",
    "start": "29820",
    "end": "34500"
  },
  {
    "text": "OK, so what are they?",
    "start": "34500",
    "end": "36660"
  },
  {
    "text": "This is a big\nequation, S time x.",
    "start": "36660",
    "end": "40510"
  },
  {
    "text": "So S is our matrix.",
    "start": "40510",
    "end": "42589"
  },
  {
    "text": "And I've called it\nS because I'm taking",
    "start": "42590",
    "end": "45060"
  },
  {
    "text": "it to be a symmetric matrix.",
    "start": "45060",
    "end": "47400"
  },
  {
    "text": "What's on one side\nof the diagonal",
    "start": "47400",
    "end": "49920"
  },
  {
    "text": "is also on the other\nside of the diagonal.",
    "start": "49920",
    "end": "52530"
  },
  {
    "text": "So those have the\nbeautiful properties.",
    "start": "52530",
    "end": "54800"
  },
  {
    "text": "Those are the kings\nof linear algebra.",
    "start": "54800",
    "end": "57270"
  },
  {
    "text": "Now, about eigenvectors\nx and eigenvalues lambda.",
    "start": "57270",
    "end": "62280"
  },
  {
    "text": "So what does that equation,\nSx equal lambda x, tell me?",
    "start": "62280",
    "end": "66810"
  },
  {
    "text": "That says that I have\na special vector x.",
    "start": "66810",
    "end": "70549"
  },
  {
    "text": "When I multiply it\nby S, my matrix,",
    "start": "70550",
    "end": "74400"
  },
  {
    "text": "I stay in the same\ndirection as the original x.",
    "start": "74400",
    "end": "77730"
  },
  {
    "text": "It might get multiplied by 2.",
    "start": "77730",
    "end": "79810"
  },
  {
    "text": "Lambda could be 2.",
    "start": "79810",
    "end": "81630"
  },
  {
    "text": "It might get multiplied by 0.",
    "start": "81630",
    "end": "83670"
  },
  {
    "text": "Lambda there could even be 0.",
    "start": "83670",
    "end": "85590"
  },
  {
    "text": "It might get multiplied\nby minus 2, whatever.",
    "start": "85590",
    "end": "88740"
  },
  {
    "text": "But it's along the same line.",
    "start": "88740",
    "end": "90680"
  },
  {
    "text": "So that's like taking a matrix\nand discovering inside it",
    "start": "90680",
    "end": "95760"
  },
  {
    "text": "something that stays on a line.",
    "start": "95760",
    "end": "99740"
  },
  {
    "text": "That means that it's really a\nsort of one dimensional problem",
    "start": "99740",
    "end": "103640"
  },
  {
    "text": "if we're looking along\nthat eigenvector.",
    "start": "103640",
    "end": "107060"
  },
  {
    "text": "And that makes computations\ninfinitely easier.",
    "start": "107060",
    "end": "111380"
  },
  {
    "text": "The hard part of a matrix\nis all the connections",
    "start": "111380",
    "end": "115070"
  },
  {
    "text": "between different\nrows and columns.",
    "start": "115070",
    "end": "117830"
  },
  {
    "text": "So eigenvectors\nare the guys that",
    "start": "117830",
    "end": "120050"
  },
  {
    "text": "stay in that same direction.",
    "start": "120050",
    "end": "122222"
  },
  {
    "start": "122222",
    "end": "124830"
  },
  {
    "text": "And y is another eigenvector.",
    "start": "124830",
    "end": "128330"
  },
  {
    "text": "It has its own eigenvalue.",
    "start": "128330",
    "end": "130169"
  },
  {
    "text": "It got multiplied by alpha\nwhere Sx multiplied the x",
    "start": "130169",
    "end": "134200"
  },
  {
    "text": "by some other number lambda.",
    "start": "134200",
    "end": "136540"
  },
  {
    "text": "So there's our couple\nof eigenvectors.",
    "start": "136540",
    "end": "138400"
  },
  {
    "text": "And the beautiful fact is\nthat because S is symmetric,",
    "start": "138400",
    "end": "143599"
  },
  {
    "text": "those two eigenvectors\nare perpendicular.",
    "start": "143600",
    "end": "146300"
  },
  {
    "text": "They are orthogonal,\nas it says up there.",
    "start": "146300",
    "end": "149450"
  },
  {
    "text": "So symmetric matrices\nare really the best",
    "start": "149450",
    "end": "152450"
  },
  {
    "text": "because their eigenvectors\nare perpendicular.",
    "start": "152450",
    "end": "155330"
  },
  {
    "text": "And we have a bunch of\none dimensional problems.",
    "start": "155330",
    "end": "158600"
  },
  {
    "text": "And here, I've included a proof.",
    "start": "158600",
    "end": "161780"
  },
  {
    "text": "You want a proof that the\neigenvectors are perpendicular?",
    "start": "161780",
    "end": "167459"
  },
  {
    "text": "So what does perpendicular mean?",
    "start": "167460",
    "end": "168980"
  },
  {
    "text": "It means that x transpose\ntimes y, the dot product is 0.",
    "start": "168980",
    "end": "175980"
  },
  {
    "text": "The angle is 90 degrees.",
    "start": "175980",
    "end": "178940"
  },
  {
    "text": "The cosine is 1.",
    "start": "178940",
    "end": "181640"
  },
  {
    "text": "OK.",
    "start": "181640",
    "end": "183050"
  },
  {
    "text": "How to show the\ncosine might be there.",
    "start": "183050",
    "end": "187670"
  },
  {
    "text": "How to show that?",
    "start": "187670",
    "end": "189560"
  },
  {
    "text": "Yeah, proof.",
    "start": "189560",
    "end": "190500"
  },
  {
    "text": "This is just you can\ntune out for two minutes",
    "start": "190500",
    "end": "193730"
  },
  {
    "text": "if you hate proofs.",
    "start": "193730",
    "end": "195409"
  },
  {
    "text": "OK, I start with what I know.",
    "start": "195410",
    "end": "197990"
  },
  {
    "text": "What I know is in that box.",
    "start": "197990",
    "end": "200200"
  },
  {
    "text": "Sx is lambda x.",
    "start": "200200",
    "end": "201640"
  },
  {
    "text": "That's one eigenvector.",
    "start": "201640",
    "end": "203260"
  },
  {
    "text": "That tells me the eigenvector y.",
    "start": "203260",
    "end": "205569"
  },
  {
    "text": "This tells me the\neigenvalues are different.",
    "start": "205570",
    "end": "207940"
  },
  {
    "text": "And that tells me the\nmatrix is symmetric.",
    "start": "207940",
    "end": "210430"
  },
  {
    "text": "I'm just going to\njuggle those four facts.",
    "start": "210430",
    "end": "213640"
  },
  {
    "text": "And I'll end up with x\ntranspose y equals 0.",
    "start": "213640",
    "end": "219040"
  },
  {
    "text": "That's orthogonality.",
    "start": "219040",
    "end": "221349"
  },
  {
    "text": "OK.",
    "start": "221350",
    "end": "222400"
  },
  {
    "text": "So I'll just do it\nquickly, too quickly.",
    "start": "222400",
    "end": "226000"
  },
  {
    "text": "So I take this first\nthing, and I transpose",
    "start": "226000",
    "end": "229900"
  },
  {
    "text": "it, turn it into row vectors.",
    "start": "229900",
    "end": "232739"
  },
  {
    "text": "And then when I transpose\nit, that transpose",
    "start": "232740",
    "end": "237450"
  },
  {
    "text": "means I flip rows and columns.",
    "start": "237450",
    "end": "239220"
  },
  {
    "text": "But for as symmetric\nmatrix, no different.",
    "start": "239220",
    "end": "242670"
  },
  {
    "text": "So S transpose is the same as S.",
    "start": "242670",
    "end": "245390"
  },
  {
    "text": "And then I look at this\none, and I multiply that",
    "start": "245390",
    "end": "248840"
  },
  {
    "text": "by x transpose, both\nsides by x transpose.",
    "start": "248840",
    "end": "253129"
  },
  {
    "text": "And what I end up\nwith is recognizing",
    "start": "253130",
    "end": "256700"
  },
  {
    "text": "that lambda times\nthat dot product",
    "start": "256700",
    "end": "259250"
  },
  {
    "text": "equals alpha times\nthat dot product.",
    "start": "259250",
    "end": "262140"
  },
  {
    "text": "But lambda is\ndifferent from alpha.",
    "start": "262140",
    "end": "264690"
  },
  {
    "text": "So the only way lambda\ntimes that number",
    "start": "264690",
    "end": "266760"
  },
  {
    "text": "could equal alpha\ntimes that number",
    "start": "266760",
    "end": "268470"
  },
  {
    "text": "is that number has to be 0.",
    "start": "268470",
    "end": "271050"
  },
  {
    "text": "And that's the answer.",
    "start": "271050",
    "end": "272460"
  },
  {
    "text": "OK, so that's the\nproof that used",
    "start": "272460",
    "end": "274740"
  },
  {
    "text": "exactly every fact we knew.",
    "start": "274740",
    "end": "277979"
  },
  {
    "text": "End of proof.",
    "start": "277980",
    "end": "279930"
  },
  {
    "text": "Main point to\nremember, eigenvectors",
    "start": "279930",
    "end": "282720"
  },
  {
    "text": "are perpendicular when\nthe matrix is symmetric.",
    "start": "282720",
    "end": "287130"
  },
  {
    "text": "OK.",
    "start": "287130",
    "end": "289710"
  },
  {
    "text": "In that case, now, you always\nwant to express these facts",
    "start": "289710",
    "end": "294180"
  },
  {
    "text": "as from multiplying matrices.",
    "start": "294180",
    "end": "299030"
  },
  {
    "text": "That says everything\nin a few symbols",
    "start": "299030",
    "end": "302180"
  },
  {
    "text": "where I had to use all those\nwords on the previous slide.",
    "start": "302180",
    "end": "306000"
  },
  {
    "text": "So that's the result\nthat I'm shooting for,",
    "start": "306000",
    "end": "310950"
  },
  {
    "text": "that a symmetric matrix--",
    "start": "310950",
    "end": "314450"
  },
  {
    "text": "just focus on that box.",
    "start": "314450",
    "end": "319150"
  },
  {
    "text": "A symmetric matrix can be\nbroken up into its eigenvectors.",
    "start": "319150",
    "end": "324740"
  },
  {
    "text": "Those are in Q. Its eigenvalues.",
    "start": "324740",
    "end": "327740"
  },
  {
    "text": "Those are the lambdas.",
    "start": "327740",
    "end": "328910"
  },
  {
    "text": "Those are the numbers\nlambda 1 to lambda n",
    "start": "328910",
    "end": "332120"
  },
  {
    "text": "on the diagonal of lambda.",
    "start": "332120",
    "end": "334070"
  },
  {
    "text": "And then the transpose, so\nthe eigenvectors are now",
    "start": "334070",
    "end": "336890"
  },
  {
    "text": "rows in Q transpose.",
    "start": "336890",
    "end": "339440"
  },
  {
    "text": "That's just perfect.",
    "start": "339440",
    "end": "342160"
  },
  {
    "text": "Perfect.",
    "start": "342160",
    "end": "343480"
  },
  {
    "text": "Every symmetric matrix\nis an orthogonal matrix",
    "start": "343480",
    "end": "347020"
  },
  {
    "text": "times a diagonal matrix\ntimes the transpose",
    "start": "347020",
    "end": "351490"
  },
  {
    "text": "of the orthogonal matrix.",
    "start": "351490",
    "end": "353680"
  },
  {
    "text": "Yeah, that's called\nthe spectral theorem.",
    "start": "353680",
    "end": "355810"
  },
  {
    "text": "And you could say it's up there\nwith the most important facts",
    "start": "355810",
    "end": "360669"
  },
  {
    "text": "in linear algebra and\nin wider mathematics.",
    "start": "360670",
    "end": "364410"
  },
  {
    "text": "Yeah, so that's the fact that\ncontrols what we do here.",
    "start": "364410",
    "end": "372580"
  },
  {
    "text": "Oh, now I have to say what's the\nsituation if the matrix is not",
    "start": "372580",
    "end": "378159"
  },
  {
    "text": "symmetric.",
    "start": "378160",
    "end": "379860"
  },
  {
    "text": "Now I am not going to get\nperpendicular eigenvectors.",
    "start": "379860",
    "end": "384169"
  },
  {
    "text": "That was a symmetric\nthing mostly.",
    "start": "384170",
    "end": "387470"
  },
  {
    "text": "But I'll get eigenvectors.",
    "start": "387470",
    "end": "390260"
  },
  {
    "text": "So I'll get Ax equal lambda x.",
    "start": "390260",
    "end": "395140"
  },
  {
    "text": "The first one won't\nbe perpendicular",
    "start": "395140",
    "end": "397060"
  },
  {
    "text": "to the second one.",
    "start": "397060",
    "end": "397870"
  },
  {
    "text": "The matrix A, it\nhas to be square,",
    "start": "397870",
    "end": "400520"
  },
  {
    "text": "or this doesn't make sense.",
    "start": "400520",
    "end": "401710"
  },
  {
    "text": "So eigenvalues and\neigenvectors are the way",
    "start": "401710",
    "end": "405069"
  },
  {
    "text": "to break up a square matrix\nand find this diagonal matrix",
    "start": "405070",
    "end": "410590"
  },
  {
    "text": "lambda with the eigenvalues,\nlambda 1, lambda 2, to lambda",
    "start": "410590",
    "end": "414639"
  },
  {
    "text": "n.",
    "start": "414640",
    "end": "415270"
  },
  {
    "text": "That's the purpose.",
    "start": "415270",
    "end": "418900"
  },
  {
    "text": "And eigenvectors are\nperpendicular when",
    "start": "418900",
    "end": "421509"
  },
  {
    "text": "it's a symmetric matrix.",
    "start": "421510",
    "end": "423250"
  },
  {
    "text": "Otherwise, I just have x and its\ninverse matrix but no symmetry.",
    "start": "423250",
    "end": "428710"
  },
  {
    "text": "OK.",
    "start": "428710",
    "end": "429490"
  },
  {
    "text": "So that's the quick expression,\nanother factorization",
    "start": "429490",
    "end": "434470"
  },
  {
    "text": "of eigenvalues in lambda.",
    "start": "434470",
    "end": "437530"
  },
  {
    "text": "Diagonal, just numbers.",
    "start": "437530",
    "end": "439670"
  },
  {
    "text": "And eigenvectors in\nthe columns of x.",
    "start": "439670",
    "end": "443370"
  },
  {
    "text": "And now I'm not\ngoing to-- oh, I was",
    "start": "443370",
    "end": "447610"
  },
  {
    "text": "going to say I'm not\ngoing to solve all",
    "start": "447610",
    "end": "449530"
  },
  {
    "text": "the problems of applied math.",
    "start": "449530",
    "end": "451030"
  },
  {
    "text": "But that's what these are for.",
    "start": "451030",
    "end": "453850"
  },
  {
    "text": "Let's just see what's special\nhere about these eigenvectors.",
    "start": "453850",
    "end": "458400"
  },
  {
    "text": "Suppose I multiply again by A.\nI Start with Ax equal lambda x.",
    "start": "458400",
    "end": "466800"
  },
  {
    "text": "Now I'm going to\nmultiply both sides by A.",
    "start": "466800",
    "end": "469650"
  },
  {
    "text": "That'll tell me something\nabout eigenvalues of A squared.",
    "start": "469650",
    "end": "473550"
  },
  {
    "text": "Because when I multiply by A--",
    "start": "473550",
    "end": "475970"
  },
  {
    "text": "so let me start\nwith A squared now",
    "start": "475970",
    "end": "478230"
  },
  {
    "text": "times x, which means A times Ax.",
    "start": "478230",
    "end": "482810"
  },
  {
    "text": "A times Ax.",
    "start": "482810",
    "end": "484400"
  },
  {
    "text": "But Ax is lambda x.",
    "start": "484400",
    "end": "486440"
  },
  {
    "text": "So I have A times lambda x.",
    "start": "486440",
    "end": "489320"
  },
  {
    "text": "And I pull out\nthat number lambda.",
    "start": "489320",
    "end": "492180"
  },
  {
    "text": "And I still have a 1Ax.",
    "start": "492180",
    "end": "495039"
  },
  {
    "text": "And that's also still lambda x.",
    "start": "495040",
    "end": "497450"
  },
  {
    "text": "You see I'm just talking\naround in a little circle",
    "start": "497450",
    "end": "500180"
  },
  {
    "text": "here, just using Ax equal\nlambda x a couple of times.",
    "start": "500180",
    "end": "504080"
  },
  {
    "text": "And the result is--",
    "start": "504080",
    "end": "505860"
  },
  {
    "text": "do you see what that\nmeans, that result?",
    "start": "505860",
    "end": "508400"
  },
  {
    "text": "That means that the eigenvalue\nfor A squared, same eigenvector",
    "start": "508400",
    "end": "513080"
  },
  {
    "text": "x.",
    "start": "513080",
    "end": "513830"
  },
  {
    "text": "The eigenvalue is\nlambda squared.",
    "start": "513830",
    "end": "517229"
  },
  {
    "text": "And if I add A\ncubed, the eigenvalue",
    "start": "517230",
    "end": "519500"
  },
  {
    "text": "would come out lambda cubed.",
    "start": "519500",
    "end": "521299"
  },
  {
    "text": "And if I have a to\nthe-- yeah, yeah.",
    "start": "521299",
    "end": "524990"
  },
  {
    "text": "So if I had A to the n\ntimes, n multiplies-- so when",
    "start": "524990",
    "end": "529640"
  },
  {
    "text": "would you have A\nto a high power?",
    "start": "529640",
    "end": "533090"
  },
  {
    "text": "That's a interesting matrix.",
    "start": "533090",
    "end": "536480"
  },
  {
    "text": "Take a matrix and\nsquare it, cube it,",
    "start": "536480",
    "end": "538910"
  },
  {
    "text": "take high powers of it.",
    "start": "538910",
    "end": "542449"
  },
  {
    "text": "The eigenvectors don't change.",
    "start": "542450",
    "end": "544520"
  },
  {
    "text": "That's the great thing.",
    "start": "544520",
    "end": "545690"
  },
  {
    "text": "That's the whole\npoint of eigenvectors.",
    "start": "545690",
    "end": "547850"
  },
  {
    "text": "They don't change.",
    "start": "547850",
    "end": "549120"
  },
  {
    "text": "And the eigenvalues just\nget taken to the high power.",
    "start": "549120",
    "end": "552540"
  },
  {
    "text": "So for example, we could\nask the question, when,",
    "start": "552540",
    "end": "556009"
  },
  {
    "text": "if I multiply a matrix by itself\nover and over and over again,",
    "start": "556010",
    "end": "559160"
  },
  {
    "text": "when do I approach 0?",
    "start": "559160",
    "end": "560839"
  },
  {
    "text": "Well, if these\nnumbers are below 1.",
    "start": "560840",
    "end": "564920"
  },
  {
    "text": "So eigenvectors, eigenvalues\ngives you something",
    "start": "564920",
    "end": "567260"
  },
  {
    "text": "that you just could not see by\nthose column operations or L",
    "start": "567260",
    "end": "573330"
  },
  {
    "text": "times U. This is looking deeper.",
    "start": "573330",
    "end": "576980"
  },
  {
    "text": "OK.",
    "start": "576980",
    "end": "578120"
  },
  {
    "text": "And OK, and then you'll see\nwe have almost already seen",
    "start": "578120",
    "end": "585040"
  },
  {
    "text": "with least squares, this\ncombination A transpose A. So",
    "start": "585040",
    "end": "589600"
  },
  {
    "text": "remember A is a\nrectangular matrix, m by n.",
    "start": "589600",
    "end": "593750"
  },
  {
    "text": "I multiply it by its transpose.",
    "start": "593750",
    "end": "596220"
  },
  {
    "text": "When I transpose\nit, I have n by m.",
    "start": "596220",
    "end": "602750"
  },
  {
    "text": "And when I multiply them\ntogether, I get n by n.",
    "start": "602750",
    "end": "605450"
  },
  {
    "text": "So A transpose A is, for\ntheory, is a great matrix,",
    "start": "605450",
    "end": "610880"
  },
  {
    "text": "A transpose times\nA. It's symmetric.",
    "start": "610880",
    "end": "614030"
  },
  {
    "text": "Yeah, let's just see\nwhat we have about A.",
    "start": "614030",
    "end": "616430"
  },
  {
    "text": "It's square for sure.",
    "start": "616430",
    "end": "619460"
  },
  {
    "text": "Oh, yeah.",
    "start": "619460",
    "end": "620000"
  },
  {
    "text": "This tells me that\nit's symmetric.",
    "start": "620000",
    "end": "622125"
  },
  {
    "text": "And you remember why.",
    "start": "622125",
    "end": "623000"
  },
  {
    "text": "I'm always looking\nfor symmetric matrices",
    "start": "623000",
    "end": "626020"
  },
  {
    "text": "because they have those\northogonal eigenvectors.",
    "start": "626020",
    "end": "629530"
  },
  {
    "text": "They're the beautiful\nones for eigenvectors.",
    "start": "629530",
    "end": "632930"
  },
  {
    "text": "And A transpose A,\nautomatically symmetric.",
    "start": "632930",
    "end": "636070"
  },
  {
    "text": "You just you're\nmultiplying something",
    "start": "636070",
    "end": "640660"
  },
  {
    "text": "by its adjoint, its\ntranspose, and the result",
    "start": "640660",
    "end": "645940"
  },
  {
    "text": "is that this matrix\nis symmetric.",
    "start": "645940",
    "end": "651010"
  },
  {
    "text": "And maybe there's even more\nabout A transpose A. Yes.",
    "start": "651010",
    "end": "655920"
  },
  {
    "text": "What is that?",
    "start": "655920",
    "end": "656579"
  },
  {
    "start": "656580",
    "end": "660610"
  },
  {
    "text": "Here is a final--",
    "start": "660610",
    "end": "663260"
  },
  {
    "text": "I always say certain\nmatrices are important,",
    "start": "663260",
    "end": "667020"
  },
  {
    "text": "but these are the winners.",
    "start": "667020",
    "end": "670330"
  },
  {
    "text": "They are symmetric matrices.",
    "start": "670330",
    "end": "672510"
  },
  {
    "text": "If I want beautiful\nmatrices, make them symmetric",
    "start": "672510",
    "end": "676260"
  },
  {
    "text": "and make the\neigenvalues positive.",
    "start": "676260",
    "end": "678950"
  },
  {
    "start": "678950",
    "end": "681540"
  },
  {
    "text": "Or non-negative allows 0.",
    "start": "681540",
    "end": "686160"
  },
  {
    "text": "So I can either say\npositive definite",
    "start": "686160",
    "end": "688889"
  },
  {
    "text": "when the eigenvalues\nare positive,",
    "start": "688890",
    "end": "691320"
  },
  {
    "text": "or I can say non-negative,\nwhich allows 0.",
    "start": "691320",
    "end": "694880"
  },
  {
    "text": "And so I have greater\nthan or equal to 0.",
    "start": "694880",
    "end": "698700"
  },
  {
    "text": "I just want to say\nthat bringing all",
    "start": "698700",
    "end": "701820"
  },
  {
    "text": "the pieces of linear\nalgebra come together",
    "start": "701820",
    "end": "704520"
  },
  {
    "text": "in these matrices.",
    "start": "704520",
    "end": "706320"
  },
  {
    "text": "And we're seeing the\neigenvalue part of it.",
    "start": "706320",
    "end": "709770"
  },
  {
    "text": "And here, I've mentioned\nsomething called the energy.",
    "start": "709770",
    "end": "713020"
  },
  {
    "text": "So that's a physical\nquantity that",
    "start": "713020",
    "end": "715380"
  },
  {
    "text": "also is greater or equal to 0.",
    "start": "715380",
    "end": "718230"
  },
  {
    "text": "So that's A transpose\nA is the matrix",
    "start": "718230",
    "end": "722970"
  },
  {
    "text": "that I'm going to use in\nthe final part of this video",
    "start": "722970",
    "end": "730290"
  },
  {
    "text": "to achieve the\ngreatest factorization.",
    "start": "730290",
    "end": "735060"
  },
  {
    "text": "Q lambda, Q transpose\nwas fantastic.",
    "start": "735060",
    "end": "738779"
  },
  {
    "text": "But for a non-square\nmatrix, it's not.",
    "start": "738780",
    "end": "742830"
  },
  {
    "text": "For a non-square\nmatrix, they don't even",
    "start": "742830",
    "end": "745260"
  },
  {
    "text": "have eigenvalues\nand eigenvectors.",
    "start": "745260",
    "end": "747840"
  },
  {
    "text": "But data comes in\nnon-square matrices.",
    "start": "747840",
    "end": "751650"
  },
  {
    "text": "Data is about like we\nhave a bunch of diseases",
    "start": "751650",
    "end": "754230"
  },
  {
    "text": "and a bunch of patients\nor a bunch of medicines.",
    "start": "754230",
    "end": "757940"
  },
  {
    "text": "And the number of\nmedicines is not",
    "start": "757940",
    "end": "759470"
  },
  {
    "text": "equal the number of\npatients or diseases.",
    "start": "759470",
    "end": "762089"
  },
  {
    "text": "Those are different numbers.",
    "start": "762090",
    "end": "763740"
  },
  {
    "text": "So the matrices that we see\nin data are rectangular.",
    "start": "763740",
    "end": "768560"
  },
  {
    "text": "And eigenvalues don't\nmake sense for those.",
    "start": "768560",
    "end": "772800"
  },
  {
    "text": "And singular values take\nthe place of eigenvalues.",
    "start": "772800",
    "end": "776649"
  },
  {
    "text": "So singular values,\nand my hope is",
    "start": "776650",
    "end": "779280"
  },
  {
    "text": "that linear algebra\ncourses, 18.06 for sure,",
    "start": "779280",
    "end": "784550"
  },
  {
    "text": "will always reach,\nafter you explain",
    "start": "784550",
    "end": "788690"
  },
  {
    "text": "eigenvalues that everybody\nagrees is important,",
    "start": "788690",
    "end": "792170"
  },
  {
    "text": "get singular values\ninto the course",
    "start": "792170",
    "end": "794600"
  },
  {
    "text": "because they really have\ncome on as the big things",
    "start": "794600",
    "end": "798740"
  },
  {
    "text": "to do in data.",
    "start": "798740",
    "end": "800600"
  },
  {
    "text": "So that would be the last\npart of this summary video",
    "start": "800600",
    "end": "807370"
  },
  {
    "text": "for 2020 vision\nof linear algebra",
    "start": "807370",
    "end": "810779"
  },
  {
    "text": "is to get singular\nvalues in there.",
    "start": "810780",
    "end": "813520"
  },
  {
    "text": "OK, that's coming next.",
    "start": "813520",
    "end": "816120"
  },
  {
    "start": "816120",
    "end": "820000"
  }
]
[
  {
    "start": "0",
    "end": "106000"
  },
  {
    "text": " [SQUEAKING] [RUSTLING] [CLICKING]",
    "start": "0",
    "end": "5868"
  },
  {
    "start": "5868",
    "end": "21482"
  },
  {
    "text": "DAVID SONTAG: So\ntoday's lecture is going to continue on\nthe lecture that you saw on Tuesday, which\nwas introducing you",
    "start": "21482",
    "end": "27950"
  },
  {
    "text": "to causal inference. So the causal inference\nsetting, which",
    "start": "27950",
    "end": "33410"
  },
  {
    "text": "we're studying in this course,\nis a really simplistic one from a causal\ngraphs perspective. There are three sets of\nvariables of interest--",
    "start": "33410",
    "end": "41030"
  },
  {
    "text": "everything you know about an\nindividual or patient, which we're calling x over here;\nand intervention or action--",
    "start": "41030",
    "end": "50180"
  },
  {
    "text": "which for today's\nlecture, we're going to suppose that it's either 0\nor 1, so a binary intervention.",
    "start": "50180",
    "end": "56510"
  },
  {
    "text": "You either take it or don't-- and an outcome y. And what makes this\nproblem of understanding",
    "start": "56510",
    "end": "64040"
  },
  {
    "text": "the impact of the intervention\non the outcome challenging is that we have to\nmake that inference",
    "start": "64040",
    "end": "70700"
  },
  {
    "text": "from observational data, where\nwe don't have the ability-- at least not in\nmedicine, we typically",
    "start": "70700",
    "end": "76340"
  },
  {
    "text": "don't have the ability to\nmake active interventions. And the goal of what we will\nbe discussing in this course",
    "start": "76340",
    "end": "83930"
  },
  {
    "text": "is about how to take\ndata that was collected from a practice of medicine\nwhere actions or interventions",
    "start": "83930",
    "end": "89600"
  },
  {
    "text": "were taken, and then use\nthat to infer something about the causal effect. And obviously, there are also\nrandomized control trials",
    "start": "89600",
    "end": "96380"
  },
  {
    "text": "where one intentionally\ndoes randomize, but the focus of\ntoday's lecture is",
    "start": "96380",
    "end": "101927"
  },
  {
    "text": "going to be using observational\ndata, or ready collected data, to try to make\nthese conclusions.",
    "start": "101927",
    "end": "107580"
  },
  {
    "start": "106000",
    "end": "205000"
  },
  {
    "text": "So we introduced the language of\npotential outcomes on Tuesday. Potential outcomes is the\nmathematical framework",
    "start": "107580",
    "end": "114200"
  },
  {
    "text": "for trying to answer\nthese questions. Then with that definition\nof potential outcomes, we can define the conditional\naverage treatment effect,",
    "start": "114200",
    "end": "122060"
  },
  {
    "text": "which is the difference\nbetween Y1 and Y0",
    "start": "122060",
    "end": "127280"
  },
  {
    "text": "for the individual Xi. So you'll notice here\nthat I have patients,",
    "start": "127280",
    "end": "133130"
  },
  {
    "text": "so treating the\npotential outcome as a random variable\nin case there",
    "start": "133130",
    "end": "138620"
  },
  {
    "text": "might be some stochasticity. So sometimes, maybe if you were\nto give someone a treatment, it works, and\nsometimes it doesn't.",
    "start": "138620",
    "end": "145500"
  },
  {
    "text": "So that's what the\nexpectation is accounting for. Any questions before I move on? ",
    "start": "145500",
    "end": "154450"
  },
  {
    "text": "So with respect\nto this definition of conditional average\ntreatment effect, then you could ask, well, what\nwould happen in aggregate",
    "start": "154450",
    "end": "161275"
  },
  {
    "text": "for the population? And you can compute\nthat by taking the average of the conditional\naverage treatment effect",
    "start": "161275",
    "end": "168230"
  },
  {
    "text": "over all of the individuals. So that's just this expectation\nwith respect to, now, p of x.",
    "start": "168230",
    "end": "173810"
  },
  {
    "text": "Now, critically, this\ndistribution, p of x, you should think about as the\ndistribution of everyone",
    "start": "173810",
    "end": "180829"
  },
  {
    "text": "that exists in your data. So some of those individuals\nmight have received",
    "start": "180830",
    "end": "186200"
  },
  {
    "text": "treatment 1 in the past. Some of them might have\nreceived treatment 0. But when we ask this question\nabout average treatment effect,",
    "start": "186200",
    "end": "193040"
  },
  {
    "text": "we're asking, for both of\nthose populations, what would have been the effect-- what would have been the\ndifference about [INAUDIBLE]",
    "start": "193040",
    "end": "200050"
  },
  {
    "text": "they received treatment 1 minus\nhad they received treatment 0?",
    "start": "200050",
    "end": "206080"
  },
  {
    "start": "205000",
    "end": "363000"
  },
  {
    "text": "Now, I wanted to\ntake this opportunity to start thinking a little\nbit bigger picture about how",
    "start": "206080",
    "end": "212410"
  },
  {
    "text": "causal inference can be\nimportant in a variety",
    "start": "212410",
    "end": "218500"
  },
  {
    "text": "of societal\nquestions, and so I'd like to now spend just a\ncouple of minutes thinking",
    "start": "218500",
    "end": "226060"
  },
  {
    "text": "with you about what some\ncausal questions might be that we urgently need to\nanswer about the COVID-19",
    "start": "226060",
    "end": "231580"
  },
  {
    "text": "pandemic. And as you try to think\nthrough these questions, I want you to have this\ncausal graph in mind.",
    "start": "231580",
    "end": "237849"
  },
  {
    "text": "So there is the\ngeneral population. There is some action\nthat you want to perform,",
    "start": "237850",
    "end": "244720"
  },
  {
    "text": "and the whole notion\nof causal inferences assessing the effective action\non some outcome of interest.",
    "start": "244720",
    "end": "253520"
  },
  {
    "text": "So in trying to give\nthe answer to my-- various answers to\nmy questions of what are some causal inference\nquestions of relevance",
    "start": "253520",
    "end": "260250"
  },
  {
    "text": "to the current\npandemic, I want you to try to frame your answers in\nterms of these Xs, Ts, and Ys.",
    "start": "260250",
    "end": "267550"
  },
  {
    "text": "It's also, obviously,\nvery hard to answer using the types of techniques\nthat we will be discussing",
    "start": "267550",
    "end": "273190"
  },
  {
    "text": "in this course, and partly\nbecause the techniques that I'm focusing on are very much\ndata driven techniques.",
    "start": "273190",
    "end": "280270"
  },
  {
    "text": "That said, the general framework\nthat I've introduced on Tuesday for covariate adjustment\nof, come up with a model",
    "start": "280270",
    "end": "290110"
  },
  {
    "text": "and use that model\nto make a prediction, and the assumptions that\nunderlie that in terms of,",
    "start": "290110",
    "end": "297358"
  },
  {
    "text": "well, where's that model\ncoming from, if you're fitting the parameters from data, having\nto have common support in order",
    "start": "297358",
    "end": "303400"
  },
  {
    "text": "to be able to have any trust\nin the downstream conclusions.",
    "start": "303400",
    "end": "309250"
  },
  {
    "text": "Those underlying assumptions\nand the general premises will still hold,\nbut here, obviously, when it comes to something\nlike social distancing,",
    "start": "309250",
    "end": "315330"
  },
  {
    "text": "they're complicated\nnetwork effects. And so whereas up\nuntil now, we've",
    "start": "315330",
    "end": "321220"
  },
  {
    "text": "been making the assumption\nof what was called SUTVA-- it was a assumption that I\nprobably didn't even talk about",
    "start": "321220",
    "end": "329169"
  },
  {
    "text": "in Tuesday's lecture. But intuitively, what\nthe SUTVA assumption says",
    "start": "329170",
    "end": "334780"
  },
  {
    "text": "is that each of your\ntraining examples are independent of each other. And that might make sense\nwhen you think about,",
    "start": "334780",
    "end": "341140"
  },
  {
    "text": "give a patient a\nmedication or not, but it certainly\ndoesn't make sense when you think about social\ndistancing type measures,",
    "start": "341140",
    "end": "348520"
  },
  {
    "text": "where if some people\nsocial distance, but other people don't,\nit has obviously a very different impact on society.",
    "start": "348520",
    "end": "356480"
  },
  {
    "text": "So one needs a different\nclass of models to try to think about\nthat, which have to relax that SUTVA assumption.",
    "start": "356480",
    "end": "363850"
  },
  {
    "start": "363000",
    "end": "654000"
  },
  {
    "text": "So those were all really\ngood answers to my question, and in some sense, now--",
    "start": "363850",
    "end": "372120"
  },
  {
    "text": "so there's the\nepidemiological type questions that we last spoke about. But the first few set\nof questions about,",
    "start": "372120",
    "end": "378069"
  },
  {
    "text": "really, how does one treat\npatients who have COVID",
    "start": "378070",
    "end": "383830"
  },
  {
    "text": "are the types of questions\nthat only now we can really start to answer\nnow, unfortunately, because we're starting to get\na lot of data in the United",
    "start": "383830",
    "end": "390030"
  },
  {
    "text": "States and internationally. And so for example, my own\npersonal research group, we're starting to\nreally scale up",
    "start": "390030",
    "end": "396430"
  },
  {
    "text": "our research on these\ntypes of questions. Now, one very simplified\nexample that I",
    "start": "396430",
    "end": "403030"
  },
  {
    "text": "wanted to give of how a causal\ninference lens can be useful here is by trying to\nunderstand case fatality rates.",
    "start": "403030",
    "end": "410470"
  },
  {
    "text": "So for example, in\nItaly, it was reported that 4.3% of individuals\nwho had this condition",
    "start": "410470",
    "end": "419890"
  },
  {
    "text": "passed away,\nwhereas in China, it was reported that 2.3%\nof individuals who had this condition passed away.",
    "start": "419890",
    "end": "427660"
  },
  {
    "text": "Now, you might ask, based\non just those two numbers, is something\ndifferent about China? For example, might\nit be that the way",
    "start": "427660",
    "end": "436720"
  },
  {
    "text": "that COVID is being managed in\nChina is better than in Italy?",
    "start": "436720",
    "end": "442180"
  },
  {
    "text": "You might also wonder if\nthe strain of the disease might be different\nbetween China and Italy?",
    "start": "442180",
    "end": "451290"
  },
  {
    "text": "So perhaps there were some\nmutations since it left Wuhan.",
    "start": "451290",
    "end": "457930"
  },
  {
    "text": "But if you dig a\nlittle bit deeper, you see that, if you plot case\nfatality rates by age group,",
    "start": "457930",
    "end": "465895"
  },
  {
    "text": "you get this plot that\nI'm showing over here. And you see that if\nyou compare Italy, which is the orange, to\nChina, which is blue, now",
    "start": "465895",
    "end": "473800"
  },
  {
    "text": "stratified by age range, you\nsee that for every single age range, the percentage\nof deaths is lower",
    "start": "473800",
    "end": "484620"
  },
  {
    "text": "in Italy than in\nChina, which would seem to be a contradiction\nwith what we saw--",
    "start": "484620",
    "end": "490445"
  },
  {
    "text": "with the aggregate\nnumbers, where we see that the case\nfatality rate in Italy",
    "start": "490445",
    "end": "495630"
  },
  {
    "text": "is higher than in China. And so the reason why this can\nhappen has to do with the fact",
    "start": "495630",
    "end": "503760"
  },
  {
    "text": "that the populations\nare very different. And by the way, this\nparadox goes by the name",
    "start": "503760",
    "end": "509700"
  },
  {
    "text": "of Simpson's paradox. So if you dig a bit\ndeeper, you see then",
    "start": "509700",
    "end": "514979"
  },
  {
    "text": "that, if you're\nto look at, well, what is the distribution of\nindividuals in China and Italy that have been\nreported to have COVID,",
    "start": "514980",
    "end": "525480"
  },
  {
    "text": "you see that, in Italy,\nit's much more highly weighted towards\nthese older ages.",
    "start": "525480",
    "end": "533730"
  },
  {
    "text": "And if you then combine that\nwith the total number of cases,",
    "start": "533730",
    "end": "540130"
  },
  {
    "text": "you get you get to\nthese discrepancies, so it now fully explains\nthese two numbers",
    "start": "540130",
    "end": "546100"
  },
  {
    "text": "and the plot that you see. Now if we're to try to think\nabout this a bit more formally, we would try to\nformalize it in terms",
    "start": "546100",
    "end": "551760"
  },
  {
    "text": "of following causal graph. And so here, we have the\nsame notions of X, T, and Y,",
    "start": "551760",
    "end": "559690"
  },
  {
    "text": "where X is the age\nof an individual who has been diagnosed with COVID.",
    "start": "559690",
    "end": "566230"
  },
  {
    "text": "T is now country, so we're going\nto think about the intervention here as transporting\nourselves from China to Italy,",
    "start": "566230",
    "end": "575720"
  },
  {
    "text": "so thinking about changing\nthe environment altogether. And Y is the outcome on\nan individual level basis.",
    "start": "575720",
    "end": "582480"
  },
  {
    "text": "And so the formal\nquestion that one might want to ask is about\na causal impact of changing the country on the outcome Y.",
    "start": "582480",
    "end": "591129"
  },
  {
    "text": "Now, for this particular\ncausal question, this causal graph that I'm\ndrawing here is the wrong one,",
    "start": "591130",
    "end": "596620"
  },
  {
    "text": "and in fact, the right\ncausal graph probably has an edge that\ngoes from T to X.",
    "start": "596620",
    "end": "604389"
  },
  {
    "text": "In particular, the distribution\nof individuals in the country",
    "start": "604390",
    "end": "609700"
  },
  {
    "text": "is obviously a function\nof the country, not the other way around. But despite the\nfact that there is",
    "start": "609700",
    "end": "615820"
  },
  {
    "text": "that difference\nin directionality, all of the techniques that\nwe've been teaching you in this course are still\napplicable for trying",
    "start": "615820",
    "end": "621730"
  },
  {
    "text": "to ask a causal question about\nthe impact of intervening on a country, and that's\nreally because, in some sense,",
    "start": "621730",
    "end": "634370"
  },
  {
    "text": "these two distributions,\nat an observational level, are equivalent. And if you want to dig a little\nbit deeper into this example--",
    "start": "634370",
    "end": "641750"
  },
  {
    "text": "and I want to stress this is\njust for educational purposes. ",
    "start": "641750",
    "end": "647350"
  },
  {
    "text": "Don't read anything\ninto these numbers-- I would go to this Colab\nnotebook after the course.",
    "start": "647350",
    "end": "654810"
  },
  {
    "start": "654000",
    "end": "822000"
  },
  {
    "text": "So all of this was\njust a little bit of set up to help frame where\ncausal inference shows up",
    "start": "654810",
    "end": "661860"
  },
  {
    "text": "and some things that\nwe've been thinking and really very worried and\nstressed about ourselves",
    "start": "661860",
    "end": "667079"
  },
  {
    "text": "personally recently. And I want to now shift\ngears to starting to get back",
    "start": "667080",
    "end": "672570"
  },
  {
    "text": "to the course material,\nand in particular, I want to start today's\nmore theoretical parts",
    "start": "672570",
    "end": "678269"
  },
  {
    "text": "of the lectures by returning\nto covariate adjustment, which we ended on and Tuesday. In covariate adjustment, one--",
    "start": "678270",
    "end": "685649"
  },
  {
    "text": "we'll use a machine learning\napproach to learn some model, which I'll call F. So you could\nimagine a black box machine",
    "start": "685650",
    "end": "694200"
  },
  {
    "text": "learning algorithm, which\ntakes as input both X and T. So X are your covariates of\nthe individual that are going",
    "start": "694200",
    "end": "702269"
  },
  {
    "text": "to receive the treatment, and\nT is that treatment decision, which for today's lecture, you\ncan just assume is binary 01,",
    "start": "702270",
    "end": "709320"
  },
  {
    "text": "and uses those together now\nto predict the outcome Y. Now, what we showed on Tuesday\nwas that, under ignorability,",
    "start": "709320",
    "end": "717380"
  },
  {
    "text": "where ignorability,\nremember, was the assumption of no\nhitting confounding, then the conditional\naverage treatment effect",
    "start": "717380",
    "end": "725000"
  },
  {
    "text": "could be defined as\njust a difference-- could be could be computed\nas the expectation of Y1",
    "start": "725000",
    "end": "735110"
  },
  {
    "text": "now conditioned on\nT equals 1, so this is the piece that\nI've added in here, and minus the expectation of Y0\nnow conditioned on T equal 0.",
    "start": "735110",
    "end": "744830"
  },
  {
    "text": "And it's that conditioning\nwhich is really important, because that's what enables you\nto estimate Y1 from data where",
    "start": "744830",
    "end": "753080"
  },
  {
    "text": "treatment 1 was observed,\nwhereas you never get to observe Y1 in data when\ntreatment 0 was performed.",
    "start": "753080",
    "end": "762030"
  },
  {
    "text": "So we have this formula, and\nafter fitting that model F, one could then use it\nto try to estimate CATE",
    "start": "762030",
    "end": "769250"
  },
  {
    "text": "by just taking that\nlearned function, plugging in the number 1\nfor the treatment variable",
    "start": "769250",
    "end": "779420"
  },
  {
    "text": "in order to get your\nestimate of this expectation, and then plugging in the number\n0 for the treatment variable",
    "start": "779420",
    "end": "786380"
  },
  {
    "text": "when you want to get your\nestimate of this expectation. Taking the difference\nbetween those",
    "start": "786380",
    "end": "791390"
  },
  {
    "text": "then gives you your estimate\nof the conditional average treatment effect. ",
    "start": "791390",
    "end": "797220"
  },
  {
    "text": "So that's the approach, and what\nwe didn't talk about so much was the modeling choices of what\nshould your function class be.",
    "start": "797220",
    "end": "806740"
  },
  {
    "text": "So this is going to turn\nout to be really important, and really, the punchline\nof the next several slides",
    "start": "806740",
    "end": "813100"
  },
  {
    "text": "is going to be a major\ndifference in philosophy between machine\nlearning and statistics,",
    "start": "813100",
    "end": "818800"
  },
  {
    "text": "and between prediction\nand causal inference. So let's now consider the\nfollowing simple model, where",
    "start": "818800",
    "end": "827440"
  },
  {
    "start": "822000",
    "end": "1625000"
  },
  {
    "text": "I'm going to assume that the\nground truth in the real world",
    "start": "827440",
    "end": "833500"
  },
  {
    "text": "has that the potential outcome\nYT of X, where T, again is the treatment, is equal\nto some simple linear model",
    "start": "833500",
    "end": "844839"
  },
  {
    "text": "involving the covariates\nX and the treatments T, the treatment T. So in\nthis very simple setting,",
    "start": "844840",
    "end": "853840"
  },
  {
    "text": "I'm going to assume that we\njust have a single feature or covariate for the\nindividual, which is there age.",
    "start": "853840",
    "end": "859850"
  },
  {
    "text": "I'm going to assume\nthat this model doesn't have any terms with an\ninteraction between X and T,",
    "start": "859850",
    "end": "865660"
  },
  {
    "text": "so it's fully linear in X and T. So this is an assumption about\nthe true potential outcomes,",
    "start": "865660",
    "end": "876890"
  },
  {
    "text": "and what we'll do over\nthe next couple of slides is think about what would happen\nif you now modeled Y of T,",
    "start": "876890",
    "end": "884209"
  },
  {
    "text": "so modeling it with\nsome function F, where F was, let's say, a linear\nfunction versus a nonlinear",
    "start": "884210",
    "end": "890060"
  },
  {
    "text": "function, if F took this\nform or a different form.",
    "start": "890060",
    "end": "895112"
  },
  {
    "text": "And by the way,\nI'm going to assume that the noise here,\nepsilon t, can be arbitrary,",
    "start": "895112",
    "end": "900560"
  },
  {
    "text": "but that it has 0 mean. So let's get started by\ntrying to estimate what",
    "start": "900560",
    "end": "906959"
  },
  {
    "text": "the true CATE is, or\nConditional Average Treatment Effect, for this\npotential outcome model.",
    "start": "906960",
    "end": "914550"
  },
  {
    "text": "Well, just by\ndefinition, the CATE is the expectation\nof Y1 minus Y0. We're going to\ntake this formula,",
    "start": "914550",
    "end": "922200"
  },
  {
    "text": "and we're going to plug it\nin for the first term using",
    "start": "922200",
    "end": "928770"
  },
  {
    "text": "T equals 1, and that's why\nyou get this term over here with gamma.",
    "start": "928770",
    "end": "934590"
  },
  {
    "text": "And the gamma is because,\nagain, T is equal to 1. We're also going to\ntake this, and we're going to plug it in for,\nnow, this term over here,",
    "start": "934590",
    "end": "942899"
  },
  {
    "text": "where T is equal to 0. And when T is equal to 0, then\nthe gamma term just disappears,",
    "start": "942900",
    "end": "948600"
  },
  {
    "text": "and so you just get\nbeta X plus epsilon 0. So all I've done so far\nis plug in the Y1 and Y0",
    "start": "948600",
    "end": "958620"
  },
  {
    "text": "according to the assumed form,\nbut notice now that there's some terms that cancel\nout-- in particular,",
    "start": "958620",
    "end": "965760"
  },
  {
    "text": "the beta X term over\nhere cancels out with a beta X term over here.",
    "start": "965760",
    "end": "970840"
  },
  {
    "text": "And because epsilon 1 has a\n0 mean, and epsilon 0 also",
    "start": "970840",
    "end": "977730"
  },
  {
    "text": "has a 0 mean. The only thing left\nis that gamma term,",
    "start": "977730",
    "end": "982860"
  },
  {
    "text": "and expectation of a constant's\nobviously that constant. And so what we\nconclude from this is that the CATE value is gamma.",
    "start": "982860",
    "end": "990510"
  },
  {
    "text": " Now, the average\ntreatment effect,",
    "start": "990510",
    "end": "995670"
  },
  {
    "text": "which is the average of\nCATE over all individuals X, will then also be\ngamma, obviously.",
    "start": "995670",
    "end": "1001430"
  },
  {
    "text": "So we've done something\npretty interesting here. We've started from\nthe assumption that the true potential\noutcome model is linear,",
    "start": "1001430",
    "end": "1008980"
  },
  {
    "text": "and what we concluded is that\nthe average treatment effect is precisely the coefficient\nof the treatment",
    "start": "1008980",
    "end": "1016209"
  },
  {
    "text": "variable in this linear model. ",
    "start": "1016210",
    "end": "1021330"
  },
  {
    "text": "So what that means is\nthat, if what you're interested in is\ncausal inference,",
    "start": "1021330",
    "end": "1028189"
  },
  {
    "text": "and suppose that we\nwere lucky enough to know that the true\nmodel were linear, and so we attempted to fit some\nfunction F, which had precisely",
    "start": "1028190",
    "end": "1035810"
  },
  {
    "text": "the same form, we get some\nbeta hats and some gamma hats",
    "start": "1035810",
    "end": "1042619"
  },
  {
    "text": "out from the learning\nalgorithm, all we need to do is look at that\ngamma hat in order",
    "start": "1042619",
    "end": "1048650"
  },
  {
    "text": "to conclude something about\nthe average treatment effect. No need to do this\ncomplicated thing of plugging",
    "start": "1048650",
    "end": "1053870"
  },
  {
    "text": "in to estimate CATEs. And again, the reason it's\nsuch a trivial conclusion",
    "start": "1053870",
    "end": "1059269"
  },
  {
    "text": "is because of our\nassumption of linearity. Now, what that also\nmeans is that, if you",
    "start": "1059270",
    "end": "1065760"
  },
  {
    "text": "have errors in\nlearning-- in particular, suppose, for example, that\nyou are estimating your gamma",
    "start": "1065760",
    "end": "1072039"
  },
  {
    "text": "hat wrongly, then\nthat means you're also going to be getting\nwrong your estimates",
    "start": "1072040",
    "end": "1077100"
  },
  {
    "text": "of your conditional and\naverage treatment effects. ",
    "start": "1077100",
    "end": "1082958"
  },
  {
    "text": "There's a question here,\nwhich I was lucky enough to see, that says, what\ndoes gamma represent in terms of the medication?",
    "start": "1082958",
    "end": "1089530"
  },
  {
    "text": "Thank you for that question. So gamma is--\nliterally speaking,",
    "start": "1089530",
    "end": "1098340"
  },
  {
    "text": "gamma tells you the conditional\naverage treatment effect, meaning if you were to give\nthe treatment versus not",
    "start": "1098340",
    "end": "1106850"
  },
  {
    "text": "giving the treatment, how\nthat affects the outcome. Think about the outcome\nof interest being the patient's blood\npressure, there",
    "start": "1106850",
    "end": "1112940"
  },
  {
    "text": "being potential confounding\nfactor of the patient's age, and T being one of two different\nblood pressure measurements.",
    "start": "1112940",
    "end": "1120140"
  },
  {
    "text": "If gamma is positive,\nthen it means that treatment 1 is more--",
    "start": "1120140",
    "end": "1126740"
  },
  {
    "text": "treatment 1 increases the\npatient's blood pressure relative to treatment 0. And if gamma is\nnegative, it means",
    "start": "1126740",
    "end": "1133670"
  },
  {
    "text": "that treatment 1 decreases\nthe patient's blood pressure relative to treatment 0. ",
    "start": "1133670",
    "end": "1144120"
  },
  {
    "text": "So in machine learning-- oh, sorry, there's another chat. Thank you, good.",
    "start": "1144120",
    "end": "1150240"
  },
  {
    "text": "So in machine learning, I\ntypically tell my students, don't attempt to interpret\nyour coefficient.",
    "start": "1150240",
    "end": "1158330"
  },
  {
    "text": "At least, don't\ninterpret them too much. Don't put too much\nweight into them, and that's because,\nwhen you're learning",
    "start": "1158330",
    "end": "1164460"
  },
  {
    "text": "very high dimensional\nmodels, there can be a lot of redundancy\nbetween your features. But when you talk\nto statisticians,",
    "start": "1164460",
    "end": "1170960"
  },
  {
    "text": "often they pay really\nclose attention to their coefficients,\nand they try to interpret those coefficients\noften with the causal lens.",
    "start": "1170960",
    "end": "1176330"
  },
  {
    "text": "And when I first got\nstarted in this field, I couldn't understand why\nare they paying attention to those coefficients so much?",
    "start": "1176330",
    "end": "1181784"
  },
  {
    "text": "Why are they coming up with\nthese causal hypotheses based on which coefficients\nare positive and which are the negative? And this is the answer.",
    "start": "1181785",
    "end": "1188930"
  },
  {
    "text": "It really comes down\nto an interpretation of the prediction\nproblem in terms",
    "start": "1188930",
    "end": "1194900"
  },
  {
    "text": "of the feature of\nrelevance being a treatment, that treatment\nbeing linear with respect",
    "start": "1194900",
    "end": "1201650"
  },
  {
    "text": "to the potential\noutcome, and then looking at the coefficient\nof the treatment",
    "start": "1201650",
    "end": "1206779"
  },
  {
    "text": "as telling you something\nabout the average treatment effect of that\nintervention or treatment.",
    "start": "1206780",
    "end": "1212570"
  },
  {
    "text": "Moreover, that also tells us\nwhy it's often very important to look at confidence intervals,\nso one might want to know,",
    "start": "1212570",
    "end": "1221779"
  },
  {
    "text": "we have some small data set, we\nget some estimate of gamma hat,",
    "start": "1221780",
    "end": "1228350"
  },
  {
    "text": "but what if you had\na different data set? So what happens if you had a\nnew sample of 100 data points?",
    "start": "1228350",
    "end": "1236510"
  },
  {
    "text": "How would your estimated\ngamma hat vary? And so you might be\ninterested, for example, in confidence intervals, like\na 95% confident interval that",
    "start": "1236510",
    "end": "1242518"
  },
  {
    "text": "says that gamma hat is\nbetween, let's say, 1",
    "start": "1242518",
    "end": "1250820"
  },
  {
    "text": "and, let's say maybe, 0.5\nwith probability 0.95.",
    "start": "1250820",
    "end": "1258169"
  },
  {
    "text": "That'll be an example\nof a confidence interval around gamma hat. And such a confidence\ninterval then",
    "start": "1258170",
    "end": "1264377"
  },
  {
    "text": "gives you confidence--\na confidence interval around the coefficients,\nthen gives you confidence intervals around\nthe average treatment",
    "start": "1264377",
    "end": "1269870"
  },
  {
    "text": "effect via this analysis. So the second\nobservation is what",
    "start": "1269870",
    "end": "1276520"
  },
  {
    "text": "happens if the true\nmodel isn't linear, but we hadn't realized\nthat as a modeler, and we had just assumed that,\nwell, the linear model's",
    "start": "1276520",
    "end": "1284975"
  },
  {
    "text": "probably good enough? And maybe even, the linear model\ngets pretty good prediction performance?",
    "start": "1284975",
    "end": "1290100"
  },
  {
    "text": "Well, let's look at the\nextreme example of this. Let's now assume that the\ntrue data generating process,",
    "start": "1290100",
    "end": "1297110"
  },
  {
    "text": "instead of being just\nbeta X plus gamma T, we're going to add in now a new\nterm, delta times X squared.",
    "start": "1297110",
    "end": "1305733"
  },
  {
    "text": "Now, this is the\nmost naive extension of the original\nlinear model that you",
    "start": "1305733",
    "end": "1312050"
  },
  {
    "text": "could imagine, because I'm not\neven adding any interaction terms like 10 times XT.",
    "start": "1312050",
    "end": "1320750"
  },
  {
    "text": "So no interaction\nterms involving treatment and covariate. Treatment is still--\nthe potential outcome",
    "start": "1320750",
    "end": "1327650"
  },
  {
    "text": "is still linear in treatment. We're just adding a\nsingle nonlinear term involving one of the features.",
    "start": "1327650",
    "end": "1335500"
  },
  {
    "text": "Now, if you compute\nthe average treatment effect via the same\nanalysis we did before, you'll again find that\nour treatment effect is gamma.",
    "start": "1335500",
    "end": "1344190"
  },
  {
    "text": "Let's suppose now\nthat we hadn't known that there was that delta\nX squared term in there,",
    "start": "1344190",
    "end": "1349480"
  },
  {
    "text": "and we hypothesized that the\npotential outcome was given to you by this linear\nmodel involving X and T.",
    "start": "1349480",
    "end": "1356310"
  },
  {
    "text": "And I'm going to use Y\nhat to denote that that's going to be the function family\nthat we're going to be fitting.",
    "start": "1356310",
    "end": "1362580"
  },
  {
    "text": "So we now fit that\nbeta hat in gamma hat, and if you had infinite data\ndrawn from this true generating",
    "start": "1362580",
    "end": "1369299"
  },
  {
    "text": "process, which is, again,\nunknown, what one can show is that the gamma hat\nthat you would estimate",
    "start": "1369300",
    "end": "1375840"
  },
  {
    "text": "using any reasonable estimator,\nlike a least squared estimator, is actually equal to\ngamma, the true ATE value,",
    "start": "1375840",
    "end": "1384600"
  },
  {
    "text": "plus delta times this term. And notice that this term does\nnot depend on beta or gamma.",
    "start": "1384600",
    "end": "1394500"
  },
  {
    "text": "What this means is,\ndepending on delta, your gamma hat could be\nmade arbitrarily large",
    "start": "1394500",
    "end": "1401070"
  },
  {
    "text": "or arbitrarily small. So for example, if\ndelta is very large, gamma hat might\nbecome positive when",
    "start": "1401070",
    "end": "1408090"
  },
  {
    "text": "gamma might have been negative. And so your conclusions about\nthe average treatment effect could be completely wrong,\nand this should scare you.",
    "start": "1408090",
    "end": "1416910"
  },
  {
    "text": "This is the thing which makes\nusing covariate adjustments so dangerous, which\nis that if you're",
    "start": "1416910",
    "end": "1423030"
  },
  {
    "text": "making the wrong assumptions\nabout the true potential outcomes, you could get\nvery, very wrong conclusions.",
    "start": "1423030",
    "end": "1431740"
  },
  {
    "text": "So because of\nthat, one typically wants to live in\na world where you",
    "start": "1431740",
    "end": "1437640"
  },
  {
    "text": "don't have to make many\nassumptions about the form, so that you could try to fit\nthe data as well as possible.",
    "start": "1437640",
    "end": "1442890"
  },
  {
    "text": "So here, you see that there\nis this nonlinear term. Well, obviously, if you had\nused some nonlinear modeling",
    "start": "1442890",
    "end": "1449670"
  },
  {
    "text": "algorithm, like a neural network\nor maybe a random forest, then it would have the potential\nto fix that nonlinear function,",
    "start": "1449670",
    "end": "1455070"
  },
  {
    "text": "and then maybe we wouldn't\nget caught in this same trap. And there are a variety of\nmachine learning algorithms",
    "start": "1455070",
    "end": "1461820"
  },
  {
    "text": "that have been applied to\ncausal inference, everything from random forests and\nBayesian additive regression",
    "start": "1461820",
    "end": "1468060"
  },
  {
    "text": "trees to algorithms\nlike Gaussian processes and deep neural networks. I'll just briefly\nhighlight the last two.",
    "start": "1468060",
    "end": "1475100"
  },
  {
    "text": "So Gaussian processes\nare very often used to model continuous\nvalued potential outcomes,",
    "start": "1475100",
    "end": "1481910"
  },
  {
    "text": "and there are a couple of ways\nin which they can be done. So for example,\none class of models might treat Y1 and Y0 as two\nseparate Gaussian processes",
    "start": "1481910",
    "end": "1492650"
  },
  {
    "text": "and fit those to the data. A different approach,\nshown on the right here,",
    "start": "1492650",
    "end": "1498950"
  },
  {
    "text": "would be to treat T as\nan additional covariate,",
    "start": "1498950",
    "end": "1509539"
  },
  {
    "text": "so now you have X and\nT as your features and fit a Gaussian process\nfor that joint model.",
    "start": "1509540",
    "end": "1519090"
  },
  {
    "text": "When it comes to\nneural networks, neural networks had been used\nin causal inference going back about 20, 30 years, but really\nstarted catching on a few years",
    "start": "1519090",
    "end": "1531270"
  },
  {
    "text": "ago with a paper that\nI wrote in my group as being one of\nthe earliest papers",
    "start": "1531270",
    "end": "1537700"
  },
  {
    "text": "from this recent generation\nof using neural networks for causal inference. And one of the things that we\nfound to work very effectively",
    "start": "1537700",
    "end": "1546100"
  },
  {
    "text": "is to use a joint model for\npredicting the causal effect,",
    "start": "1546100",
    "end": "1552110"
  },
  {
    "text": "so we're going to be\nlearning a model that takes-- an F that takes, as input,\nX and T and has to predict",
    "start": "1552110",
    "end": "1565090"
  },
  {
    "text": "Y. And the advantage\nof that is that it's going to allow us to share\nparameters across your T",
    "start": "1565090",
    "end": "1572809"
  },
  {
    "text": "equals 1 and T equals 0 samples. But rather than\nfeeding in X and T",
    "start": "1572810",
    "end": "1578770"
  },
  {
    "text": "in your first layer of\nyour neural network, we're only going to feed\nin X in the initial layer",
    "start": "1578770",
    "end": "1585377"
  },
  {
    "text": "of the neural network,\nand we're going to learn a shared\nrepresentation, which is going to be used\nfor both predicting",
    "start": "1585377",
    "end": "1590590"
  },
  {
    "text": "T equals 0 and T equals 1. And then for predicting\nwhen T is equal to 0,",
    "start": "1590590",
    "end": "1598570"
  },
  {
    "text": "we use a different head\nfrom predicting T equals 1.",
    "start": "1598570",
    "end": "1603730"
  },
  {
    "text": "So F0 is a function that\nconcatenates these shared layers with several\nnew layers used",
    "start": "1603730",
    "end": "1610750"
  },
  {
    "text": "to predict for when\nT is equal to 0 and same analogously for 1. And we found that architecture\nworked substantially better",
    "start": "1610750",
    "end": "1619269"
  },
  {
    "text": "than the naive\narchitectures when doing causal inference on\nseveral different benchmark data sets. ",
    "start": "1619270",
    "end": "1626170"
  },
  {
    "start": "1625000",
    "end": "1746000"
  },
  {
    "text": "Now, the last thing\nI want to talk about for covariate\nadjustment, before I",
    "start": "1626170",
    "end": "1631340"
  },
  {
    "text": "move on to a new\nset of techniques, is a method called\nmatching, that",
    "start": "1631340",
    "end": "1637029"
  },
  {
    "text": "is intuitively very pleasing. It's a very-- would seem to\nbe a really natural approach",
    "start": "1637030",
    "end": "1644530"
  },
  {
    "text": "to do causal inference,\nand at first glance, may look like it has nothing\nto do with covariate adjustment",
    "start": "1644530",
    "end": "1651160"
  },
  {
    "text": "technique. What I'll do now is I'm\ngoing to first introduce you to the matching\ntechnique, and then I",
    "start": "1651160",
    "end": "1656650"
  },
  {
    "text": "will show you that it\nactually is precisely identical to\ncovariate adjustment with a particular\nassumption of what",
    "start": "1656650",
    "end": "1662600"
  },
  {
    "text": "the functional family for F is. So not Gaussian processes,\nnot deep neural networks, but it'll be something else.",
    "start": "1662600",
    "end": "1669150"
  },
  {
    "text": "So before I get into\nthat, what is matching as a technique for\ncausal inference?",
    "start": "1669150",
    "end": "1674390"
  },
  {
    "text": "Well, the key idea\nof matching is to use each\nindividual's twin to try",
    "start": "1674390",
    "end": "1680870"
  },
  {
    "text": "to get some intuition about what\ntheir potential outcome might have been? So I created these\nslides a few years ago",
    "start": "1680870",
    "end": "1688519"
  },
  {
    "text": "when President\nObama was in office, and you might imagine this\nis the actual President",
    "start": "1688520",
    "end": "1694520"
  },
  {
    "text": "Obama who did go to law school. And you might imagine who might\nhave been that other president?",
    "start": "1694520",
    "end": "1702260"
  },
  {
    "text": "What President Obama\nhave been like had he not gone to law school, but let's\nsay, gone to business school?",
    "start": "1702260",
    "end": "1708512"
  },
  {
    "text": "So if you can now imagine trying\nto find, in your data set, someone else who looks\njust like Barack Obama,",
    "start": "1708512",
    "end": "1715330"
  },
  {
    "text": "but who, instead of\ngoing to law school, went to business school,\nand then you would then ask the following question.",
    "start": "1715330",
    "end": "1721360"
  },
  {
    "text": "For example, would\nthis individual have gone on to\nbecome president had",
    "start": "1721360",
    "end": "1727840"
  },
  {
    "text": "he gone to law school versus\nhad he gone to business school? If you find someone\nelse who's just like Barack Obama who went to\nbusiness school, look to see",
    "start": "1727840",
    "end": "1735100"
  },
  {
    "text": "did that person become\npresident eventually, that would in essence give\nyou that counterfactual.",
    "start": "1735100",
    "end": "1740880"
  },
  {
    "text": "Obviously, this is\na contrived example because you would never get\nthe sample size to see that.",
    "start": "1740880",
    "end": "1747090"
  },
  {
    "text": "So that's the general idea,\nand now, I'll show it to you in a picture. So here now, we have to\ncovariates or features--",
    "start": "1747090",
    "end": "1756530"
  },
  {
    "text": "a patient's age and their\nCharleson comorbidity index.",
    "start": "1756530",
    "end": "1761630"
  },
  {
    "text": "This is some measure\nof how many-- what types of conditions\nor comorbidities",
    "start": "1761630",
    "end": "1767272"
  },
  {
    "text": "the patient might have. Do they have diabetes, do they\nhave hypertension, and so on?",
    "start": "1767272",
    "end": "1772410"
  },
  {
    "text": "And notably, what\nI'm not showing you here is the\noutcome Y. All I'm",
    "start": "1772410",
    "end": "1778710"
  },
  {
    "text": "showing you are the\noriginal data points and what treatment\ndid they receive. So blue are the individuals who\nreceived the control treatment,",
    "start": "1778710",
    "end": "1786750"
  },
  {
    "text": "or T equals 0, and red\nare the individuals who received treatment 1.",
    "start": "1786750",
    "end": "1793260"
  },
  {
    "text": "So you can imagine trying\nto find nearest neighbors. For example, the\nnearest neighbor to this data point over here\nis this blue point over here,",
    "start": "1793260",
    "end": "1802050"
  },
  {
    "text": "and so if you wanted to\nknow, well, what we observed, some Y1, for this individual,\nwe observed some Y0",
    "start": "1802050",
    "end": "1815370"
  },
  {
    "text": "for this individual. And if you wanted\nto know, well, what would have happened\nto this individual",
    "start": "1815370",
    "end": "1822690"
  },
  {
    "text": "if they had received treatment\n0 instead of treatment 1, well, you could\njust look at what happened to this\nblue point and say,",
    "start": "1822690",
    "end": "1829470"
  },
  {
    "text": "that's what would have\nhappened to this red point, because they're very\nclose to each other. Any questions\nabout what matching",
    "start": "1829470",
    "end": "1835968"
  },
  {
    "text": "would do before I\ndefine it formally? ",
    "start": "1835968",
    "end": "1850572"
  },
  {
    "text": "Here, I'll-- yeah,\ngood, one question. What happens if the nearest\nneighbor is extremely far away?",
    "start": "1850572",
    "end": "1857760"
  },
  {
    "text": "That's a great question. So you can imagine that you have\none red data point over here",
    "start": "1857760",
    "end": "1866640"
  },
  {
    "text": "and no blue data points nearby. The matching approach\nwouldn't work very well.",
    "start": "1866640",
    "end": "1871929"
  },
  {
    "text": "So this data point,\nthe nearest neighbor, is this blue point over here,\nwhich intuitively, is very far",
    "start": "1871930",
    "end": "1877740"
  },
  {
    "text": "from this red point. And so if we were to estimate\nthis red point's counterfactual",
    "start": "1877740",
    "end": "1883650"
  },
  {
    "text": "using that blue point,\nwe're likely to get a very bad estimate,\nand in fact, that is going to be one of the\nchallenges of matching",
    "start": "1883650",
    "end": "1889590"
  },
  {
    "text": "based approaches. It's going to work really well\nin a high dimensional setting where you can imagine--\nsorry, in a large--",
    "start": "1889590",
    "end": "1897690"
  },
  {
    "text": "it's going to work very well in\na large sample setting, where you can hope that you're likely\nto observe a counterfactual",
    "start": "1897690",
    "end": "1904710"
  },
  {
    "text": "for every individual. And it won't work well you\nhave very limited data, and of course, all\nthis is going to be",
    "start": "1904710",
    "end": "1909990"
  },
  {
    "text": "subject to the assumption\nof common support. So one question's\nabout how does that",
    "start": "1909990",
    "end": "1915179"
  },
  {
    "text": "translate into high dimensions? The short answer--\nnot very well. We'll get back to\nthat in a moment.",
    "start": "1915180",
    "end": "1921200"
  },
  {
    "text": "Can a single data point\nappear in multiple matchings? Yes, and I will define, in\njust a moment, how and why.",
    "start": "1921200",
    "end": "1930840"
  },
  {
    "text": "It won't be a strict matching. Are we trying to\nfind a counterfactual",
    "start": "1930840",
    "end": "1935870"
  },
  {
    "text": "for each treated observation,\nor one for each control observation? I'll answer that\nin just a second.",
    "start": "1935870",
    "end": "1942860"
  },
  {
    "text": "And finally, is it common\nfor medical data sets to find such matching pairs? I'm going to reinterpret\nthat question as saying,",
    "start": "1942860",
    "end": "1949429"
  },
  {
    "text": "is this technique used\noften in medicine? And the answer\nis, yes, it's used all the time in clinical\nresearch despite the fact",
    "start": "1949430",
    "end": "1958340"
  },
  {
    "text": "that bio statisticians,\nfor quite a few years now, have been trying to argue\nthat folks should not",
    "start": "1958340",
    "end": "1965060"
  },
  {
    "text": "use this technique for\nreasons that you see shortly. So it's widely used.",
    "start": "1965060",
    "end": "1970309"
  },
  {
    "text": "It's very intuitive, which\nis why I'm teaching it. And it's going to fit into\na very general framework, as you'll see in just a\nmoment, which I'll give you",
    "start": "1970310",
    "end": "1976880"
  },
  {
    "text": "the natural solution\nfor the problems that I'm going to raise. So moving on, and\nthen I'll return",
    "start": "1976880",
    "end": "1982010"
  },
  {
    "text": "to any remaining questions. So here, I'll define one way of\ndoing counterfactual inference",
    "start": "1982010",
    "end": "1992320"
  },
  {
    "text": "using matching, and it's\ngoing to start, of course, by assuming that we\nhave some distance metric d between individuals.",
    "start": "1992320",
    "end": "1999440"
  },
  {
    "text": "Then we're going to say,\nfor each individual i, let's let j of i be the\nother individual j, obviously",
    "start": "1999440",
    "end": "2008830"
  },
  {
    "text": "different from i, who is closest\nto i, but critically, closest",
    "start": "2008830",
    "end": "2015580"
  },
  {
    "text": "but has a different treatment. So where Ti is different\nfrom Tj, and again,",
    "start": "2015580",
    "end": "2023950"
  },
  {
    "text": "I'm assuming binary,\nso Tj is either 0 or 1.",
    "start": "2023950",
    "end": "2029100"
  },
  {
    "text": "With that definition\nthen, we're going to define our estimate of the\nconditional average treatment",
    "start": "2029100",
    "end": "2037559"
  },
  {
    "text": "effect for an individual is\nwhatever their actual observed outcome was.",
    "start": "2037560",
    "end": "2044700"
  },
  {
    "text": "This, I'm going to give\nfor an individual that actually received treatment 1,\nso it's Y1, and the reason--",
    "start": "2044700",
    "end": "2050503"
  },
  {
    "text": "it's Yi minus the imputed\ncounterfactual corresponding",
    "start": "2050504",
    "end": "2057809"
  },
  {
    "text": "to T is equal to 0. And the way we get that\ncomputed counterfactual is by trying to find\nthat nearest neighbor who",
    "start": "2057810",
    "end": "2065550"
  },
  {
    "text": "received treatment 0\ninstead of treatment 1 and looking at their Y. Analogously, if T is\nequal to 0, then we're",
    "start": "2065550",
    "end": "2073679"
  },
  {
    "text": "going to use the\nobserved Yi, now over here instead of over there\nbecause it corresponds to Y0.",
    "start": "2073679",
    "end": "2081480"
  },
  {
    "text": "And where we need to impute Y1-- capital Y1, potential\noutcome Y1--",
    "start": "2081480",
    "end": "2087690"
  },
  {
    "text": "we're going to use the observed\noutcome from the nearest neighbor of individual i who\nreceived treatment 1 instead",
    "start": "2087690",
    "end": "2095940"
  },
  {
    "text": "of 0. So this, mathematically, is what\nI mean by our matching based",
    "start": "2095940",
    "end": "2101849"
  },
  {
    "text": "estimator, and this\nalso should answer one of the questions which\nwas raised, which is,",
    "start": "2101850",
    "end": "2107680"
  },
  {
    "text": "do you really need\nto have it matching, or could a data point be matched\nto multiple other data points?",
    "start": "2107680",
    "end": "2113953"
  },
  {
    "text": "And indeed, here, you see the\nanswer to that last question is yes, because you could have\na setting where, for example,",
    "start": "2113953",
    "end": "2119650"
  },
  {
    "text": "there are two red points here. And I can't draw\nblue, but I'll just",
    "start": "2119650",
    "end": "2125220"
  },
  {
    "text": "use a square for what I\nwould have drawn as blue. And then everything\nelse very far away,",
    "start": "2125220",
    "end": "2130349"
  },
  {
    "text": "and for both of\nthese red points, this blue point is\nthe closest neighbor.",
    "start": "2130350",
    "end": "2135530"
  },
  {
    "text": "So both of the counterfactual\nestimates for these two points would be using the\nsame blue point,",
    "start": "2135530",
    "end": "2142230"
  },
  {
    "text": "so that's the answer\nto that question. Now, I'm just going to\nrewrite this in a little bit",
    "start": "2142230",
    "end": "2147300"
  },
  {
    "text": "more convenient form. So I'll take this\nformula, shown over here, and you can rewrite\nthat as Yi minus Yji,",
    "start": "2147300",
    "end": "2156360"
  },
  {
    "text": "but you have to flip\nthe sign depending on whether Ti is\nequal to 1 or 0, and so that's what this\nterm is going to do.",
    "start": "2156360",
    "end": "2162600"
  },
  {
    "text": "If Ti is equal to 1,\nthen this evaluates to 1. If Ti is equal to 0, this\nevaluates to minus 1.",
    "start": "2162600",
    "end": "2168650"
  },
  {
    "text": "Flips the sign. So now that we have\nthe definition of CATE, we can now easily estimate\nthe average treatment effect",
    "start": "2168650",
    "end": "2177690"
  },
  {
    "text": "by just averaging these CATEs\nover all of the individuals in your data set.",
    "start": "2177690",
    "end": "2182880"
  },
  {
    "text": "So this is now the\ndefinition of how to do one nearest\nneighbor matching.",
    "start": "2182880",
    "end": "2189390"
  },
  {
    "text": "Any questions? ",
    "start": "2189390",
    "end": "2196390"
  },
  {
    "text": "So one question is, do we ever\nuse the metric d to weight how much we would, quote,\nunquote, \"trust\" the matching?",
    "start": "2196390",
    "end": "2202530"
  },
  {
    "text": " That's a good question. So what Hannah's\nasking is, what happens",
    "start": "2202530",
    "end": "2213190"
  },
  {
    "text": "if you have, for example,\nvery many nearest neighbors, or\nanalogously, what happens",
    "start": "2213190",
    "end": "2218380"
  },
  {
    "text": "if you have some\nnearest neighbors that are really close, some\nthat are really far? You might imagine trying to\nweight your nearest neighbors",
    "start": "2218380",
    "end": "2226390"
  },
  {
    "text": "by the distance\nfrom the data point, and you could imagine\neven doing that--",
    "start": "2226390",
    "end": "2232318"
  },
  {
    "text": "you can even imagine coming\nup with an estimator, which might discount certain data\npoints if they don't have",
    "start": "2232318",
    "end": "2237460"
  },
  {
    "text": "nearest neighbors\nnear them at all by the corresponding\nweighting factor. Yes, that's a good idea.",
    "start": "2237460",
    "end": "2242860"
  },
  {
    "text": "Yes, you can come up with\na consistent estimator of the average treatment\neffect through such an idea.",
    "start": "2242860",
    "end": "2248619"
  },
  {
    "text": "There are probably a few\nhundred papers written about it, and that's all I\nhave to say about it.",
    "start": "2248620",
    "end": "2254029"
  },
  {
    "text": "So there's lots of variants\nof this, and they all end up having the same\ntheoretical justification",
    "start": "2254030",
    "end": "2260500"
  },
  {
    "text": "that I'm about to give\nin the next slide. So one of the\nadvantages of matching",
    "start": "2260500",
    "end": "2266980"
  },
  {
    "start": "2263000",
    "end": "2567000"
  },
  {
    "text": "is that you get some\ninterpretability. So if I was to ask\nyou, well, what's the reason why you tell\nme that this treatment is",
    "start": "2266980",
    "end": "2274630"
  },
  {
    "text": "going to work for John? Well, someone can respond-- well, I used this\ntechnique, and I",
    "start": "2274630",
    "end": "2282099"
  },
  {
    "text": "found that the nearest\nneighbor to John was Anna.",
    "start": "2282100",
    "end": "2289030"
  },
  {
    "text": "And Anna took this other\ntreatment from John, and this is what\nhappened for Anna. And that's why I\nconjecture that, for John,",
    "start": "2289030",
    "end": "2295990"
  },
  {
    "text": "the difference between\nY1 and Y0 is as follows. And so then, that\ncan be criticized.",
    "start": "2295990",
    "end": "2301000"
  },
  {
    "text": "So for example, a clinician\nwho has some domain expert, can look at Anna, look at John,\nand say, oh, wait a second,",
    "start": "2301000",
    "end": "2307940"
  },
  {
    "text": "these two individuals are really\ndifferent from one another. Let's say the\ntreatment, for example, had to do with something\nwhich was gender specific.",
    "start": "2307940",
    "end": "2315819"
  },
  {
    "text": " Comparing two individuals\nwhich are of different genders",
    "start": "2315820",
    "end": "2321820"
  },
  {
    "text": "are obviously not going to\nbe comparable to one other, and so then the\ndomain expert would be able to reject that\nconclusion and say,",
    "start": "2321820",
    "end": "2328720"
  },
  {
    "text": "nuh-uh, I don't trust\nany of these statistics. Go back to the drawing board. And so type of interpretability\nis very attractive.",
    "start": "2328720",
    "end": "2338570"
  },
  {
    "text": "The second aspect of this,\nwhich is very attractive is that it's a\nnon-parametric method,",
    "start": "2338570",
    "end": "2343789"
  },
  {
    "text": "non-parametric in the same\nway that neural networks or random forest\nare non-parametric.",
    "start": "2343790",
    "end": "2348890"
  },
  {
    "text": "So this does not rely\non any strong assumption",
    "start": "2348890",
    "end": "2353930"
  },
  {
    "text": "about the parametric form\nof the potential outcomes. On the other hand,\nthis approach is",
    "start": "2353930",
    "end": "2360160"
  },
  {
    "text": "very reliant on the\nunderlying metric. If your distance function\nis a poor distance function, then it's going to\ngive poor results.",
    "start": "2360160",
    "end": "2367960"
  },
  {
    "text": "And moreover, it could\nbe very much misled by features that don't\naffect the outcome, which",
    "start": "2367960",
    "end": "2374920"
  },
  {
    "text": "is not necessarily a\nproperty that we want. Now, here's that final slide\nthat makes the connection.",
    "start": "2374920",
    "end": "2381010"
  },
  {
    "text": "Matching is equivalent\nto covariate adjustment.",
    "start": "2381010",
    "end": "2386130"
  },
  {
    "text": "It's exactly the same. It's an instantiation\nof covariate adjustment with a particular\nfunctional family for F.",
    "start": "2386130",
    "end": "2393670"
  },
  {
    "text": "So rather than assuming\nthat your function F, that black box, is a linear\nfunction or a neural network or a random forester or a\nBayesian regression tree,",
    "start": "2393670",
    "end": "2402310"
  },
  {
    "text": "we're going to\nassume that function takes the form of a nearest\nneighbor classifier. In particular, we'll\nsay that Y hat of 1,",
    "start": "2402310",
    "end": "2412630"
  },
  {
    "text": "the function for predicting\nthe potential outcome Y hat 1, is given to you by finding the\nnearest neighbor of the data",
    "start": "2412630",
    "end": "2423160"
  },
  {
    "text": "point X according to the\ndata set of individuals",
    "start": "2423160",
    "end": "2428349"
  },
  {
    "text": "that received treatment 1,\nand same thing for Y hat 0.",
    "start": "2428350",
    "end": "2434600"
  },
  {
    "text": "And so that then allows\nus to actually prove some properties of matching.",
    "start": "2434600",
    "end": "2443220"
  },
  {
    "text": "So for example, if\nyou remember from-- I think I mentioned\nin Tuesday's lecture",
    "start": "2443220",
    "end": "2449870"
  },
  {
    "text": "that this covariate\nadjustment approach, under the assumptions of overlap\nand under the assumptions",
    "start": "2449870",
    "end": "2457520"
  },
  {
    "text": "of no hidden confounding,\nand that your function",
    "start": "2457520",
    "end": "2464240"
  },
  {
    "text": "family for potential outcome\nis sufficiently rich that you can actually fit the\nunderlying model,",
    "start": "2464240",
    "end": "2470570"
  },
  {
    "text": "then you're going to\nget correct estimates of your conditional\naverage treatment effect.",
    "start": "2470570",
    "end": "2476700"
  },
  {
    "text": "Now, one can show that a nearest\nneighbor algorithm is not,",
    "start": "2476700",
    "end": "2486450"
  },
  {
    "text": "generally, a\nconsistent algorithm. And what that means\nis that, if you have a small number\nof samples, you're",
    "start": "2486450",
    "end": "2492570"
  },
  {
    "text": "going to be getting\nbiased estimate. Your function F might, in\ngeneral, be a biased estimate.",
    "start": "2492570",
    "end": "2498870"
  },
  {
    "text": "Now, we can conclude\nfrom that, that if we were to use one nearest\nneighbor matching for inferring average treatment\neffect, that in general,",
    "start": "2498870",
    "end": "2506910"
  },
  {
    "text": "it could give us\na biased estimate of the average treatment effect. However, in the limit\nof infinite data,",
    "start": "2506910",
    "end": "2515119"
  },
  {
    "text": "one nearest neighbor\nalgorithms are guaranteed to be able to fit\nthe underlying function family.",
    "start": "2515120",
    "end": "2521849"
  },
  {
    "text": "That is to say,\nthat bias goes to 0 in the limit of a\nlarge amount of data, and thus, we can immediately\ndraw from that literature",
    "start": "2521850",
    "end": "2529980"
  },
  {
    "text": "and causal inference--\nsorry, from that literature and machine learning to\nobtain theoretical results for matching for\ncausal inference.",
    "start": "2529980",
    "end": "2538900"
  },
  {
    "text": "And so that's all I want\nto say about matching and its connection to\ncovariate adjustment.",
    "start": "2538900",
    "end": "2544119"
  },
  {
    "text": "And really, the\npunchline is, think about matching just as another\ntype of covariate adjustment,",
    "start": "2544120",
    "end": "2550060"
  },
  {
    "text": "one which uses a nearest\nneighbor function family, and thus should be compared\nto other approaches",
    "start": "2550060",
    "end": "2557019"
  },
  {
    "text": "to covariate adjustments, such\nas, for example, using machine",
    "start": "2557020",
    "end": "2563110"
  },
  {
    "text": "learning algorithms that are\ndesigned to be interpretable. So the last part\nof this lecture is",
    "start": "2563110",
    "end": "2569880"
  },
  {
    "text": "going to be introducing a\nsecond approach for inferring",
    "start": "2569880",
    "end": "2576930"
  },
  {
    "text": "average treatment effect that\nis known as the propensity score method, and this is\ngoing to be a real shift.",
    "start": "2576930",
    "end": "2583420"
  },
  {
    "text": "It's going to be a\ndifferent estimator from the covariate adjustment.",
    "start": "2583420",
    "end": "2588610"
  },
  {
    "text": "So as I mentioned, it's going\nto be used for estimating average treatment effect. In problem set 4,\nyou're going to see",
    "start": "2588610",
    "end": "2594257"
  },
  {
    "text": "how you can use the\nsame sorts of techniques I'll tell you about\nnow for also estimating conditional average\ntreatment effect,",
    "start": "2594257",
    "end": "2599890"
  },
  {
    "text": "but that won't be obvious\njust from today's lecture. So the key intuition for\npropensity score method",
    "start": "2599890",
    "end": "2607315"
  },
  {
    "text": "is to think back to what\nwould have happened if you had a randomized control trial. In a randomized control\ntrial, again, you",
    "start": "2607315",
    "end": "2613430"
  },
  {
    "text": "get choice over what treatment\nto give each individual, so you might imagine\nflipping a coin.",
    "start": "2613430",
    "end": "2619875"
  },
  {
    "text": "If it's heads, giving\nthem treatment 1. If it's tails, giving\nthem treatment 0. So given data from a\nrandomized control trial,",
    "start": "2619875",
    "end": "2626320"
  },
  {
    "text": "then there's a really\nsimple estimator shown here for the average\ntreatment effect. You just sum up the values\nof Y for the individuals",
    "start": "2626320",
    "end": "2636460"
  },
  {
    "text": "that receive treatment\n1, divided by n1, which is the number\nof individuals that received treatment 1.",
    "start": "2636460",
    "end": "2641593"
  },
  {
    "text": "So this is the average\noutcome for all people who got treatment 1, and\nyou just subtract from that the average outcome\nfor all individuals who",
    "start": "2641593",
    "end": "2649299"
  },
  {
    "text": "received treatment 0. And that can be easily shown\nto be an unbiased estimator",
    "start": "2649300",
    "end": "2654820"
  },
  {
    "text": "of the average\ntreatment effect had your data come from a\nrandomized controlled trial.",
    "start": "2654820",
    "end": "2659910"
  },
  {
    "text": "So the key idea of a\npropensity score method is to turn an observational\nstudy into something",
    "start": "2659910",
    "end": "2665550"
  },
  {
    "text": "that looks like a randomized\ncontrol trial via re-weighting of the data points.",
    "start": "2665550",
    "end": "2671590"
  },
  {
    "text": "So here's the picture I\nwant you to have in mind. Again, here, I am not\nshowing you outcomes.",
    "start": "2671590",
    "end": "2677700"
  },
  {
    "text": "I'm just showing\nyou the features X-- that's what the\ndata points are-- and the treatments that\nwere given to them, the Ts.",
    "start": "2677700",
    "end": "2685830"
  },
  {
    "text": "And the Ts, in this\ncase, are being denoted by the color of the\ndots, so red is T equals 1.",
    "start": "2685830",
    "end": "2691920"
  },
  {
    "text": "Blue is T equals 0. And my apologies in advance\nfor anyone who's color blind. So the key challenge\nwhen working",
    "start": "2691920",
    "end": "2700980"
  },
  {
    "text": "with observational\nstudy is that there might be a bias in terms of who\nreceives treatment 0 versus who",
    "start": "2700980",
    "end": "2707610"
  },
  {
    "text": "receives treatment 1. If this was a randomized\ncontrol trial, then you would expect to\nsee the reds and the blues",
    "start": "2707610",
    "end": "2713700"
  },
  {
    "text": "all intermixed equally\nwith one another, but as you can see\nhere, in this data set,",
    "start": "2713700",
    "end": "2718900"
  },
  {
    "text": "there are very many\nmore people who received-- very more young\npeople who received treatment",
    "start": "2718900",
    "end": "2723990"
  },
  {
    "text": "0 than received treatment 1. Said differently, if you look\nat the distribution over X",
    "start": "2723990",
    "end": "2729900"
  },
  {
    "text": "conditioned on T\nequals 0 in the data, it's different from\nthe distribution over X conditioned on the\npeople who receive treatment 1.",
    "start": "2729900",
    "end": "2739780"
  },
  {
    "text": "So what the propensity score\nmethod is going to do is it's going to recognize that\nthere is a difference between these two distributions, and\nit's going to re-weight data",
    "start": "2739780",
    "end": "2748210"
  },
  {
    "text": "points so that, in aggregate, it\nlooks like, in any one region-- so for example, imagine\nlooking at this region--",
    "start": "2748210",
    "end": "2754829"
  },
  {
    "text": "that there's roughly\nthe same number of red and blue data points. Where if you think about blowing\nup this red data point-- here,",
    "start": "2754830",
    "end": "2762718"
  },
  {
    "text": "I've made it very\nbig-- you can think about it being many,\nmany red data points of the corresponding weight.",
    "start": "2762718",
    "end": "2768230"
  },
  {
    "text": "You look over here, see\nagain roughly the same amount",
    "start": "2768230",
    "end": "2773440"
  },
  {
    "text": "of red and blue mass as well. So if we can find some way\nto increase or decrease",
    "start": "2773440",
    "end": "2780202"
  },
  {
    "text": "the weight associated with\neach data point such that, now, it looks like the\ntwo distributions, those",
    "start": "2780202",
    "end": "2786460"
  },
  {
    "text": "who received treatment 1 and\nthose who received treatment 0, look like they came\nfrom-- look like now they have the same\nweighted distribution,",
    "start": "2786460",
    "end": "2793180"
  },
  {
    "text": "then we're going\nto be in business. So we're going to search\nfor those weights, w, that have that property.",
    "start": "2793180",
    "end": "2799522"
  },
  {
    "start": "2798000",
    "end": "2893000"
  },
  {
    "text": "So to do that, we\nneed to introduce one new concept, which is\nknown as the propensity score. The propensity score is given\nto you by the probability",
    "start": "2799522",
    "end": "2807700"
  },
  {
    "text": "that T equals 1\ngiven X. Here, again, we're going to use\nmachine learning.",
    "start": "2807700",
    "end": "2813490"
  },
  {
    "text": "Whereas in covariate\nadjustment, we used machine learning to predict\nY conditioned on X comma T--",
    "start": "2813490",
    "end": "2821170"
  },
  {
    "text": "that's what covariate\nadjustment did-- here, we're going to be\nignoring Y altogether.",
    "start": "2821170",
    "end": "2826900"
  },
  {
    "text": "We're just going\nto take X's input, and we're going to\nbe predicting T. So you can imagine using\nlogistic regression, given",
    "start": "2826900",
    "end": "2833619"
  },
  {
    "text": "your covariates, to predict\nwhich treatment any given data point came from. Here, you're using the\nfull data set, of course,",
    "start": "2833620",
    "end": "2839589"
  },
  {
    "text": "to make that\nprediction, so we're looking at both data\npoints where T equals 1",
    "start": "2839590",
    "end": "2845140"
  },
  {
    "text": "and T equals 0. T is your label for this. Then what we're\ngoing to do is given, that learned propensity score--\nso we take your data set.",
    "start": "2845140",
    "end": "2853390"
  },
  {
    "text": "You, first, learn\nthe propensity score. Then we're going to re-weight\nthe data points according to the inverse of\nthe propensity score.",
    "start": "2853390",
    "end": "2860640"
  },
  {
    "text": "And you might ask,\nthis looks familiar. This whole notion of\nre-weighting data points,",
    "start": "2860640",
    "end": "2866410"
  },
  {
    "text": "this whole notion of trying\nto figure out which, quote, unquote, \"data set\" a\ndata point came from,",
    "start": "2866410",
    "end": "2872155"
  },
  {
    "text": "the data set of individuals who\nreceive treatment 1 or the data set of individuals who\nreceive treatment 0--",
    "start": "2872155",
    "end": "2877420"
  },
  {
    "text": "that sounds really familiar. And it's because it's exactly\nwhat you saw in lecture 10, when we talked about\ndata set shift.",
    "start": "2877420",
    "end": "2883140"
  },
  {
    "text": "In fact, this whole\nentire method, as you'll develop\nin problem set 4,",
    "start": "2883140",
    "end": "2888310"
  },
  {
    "text": "is a special case of learning\nunder data set shift.",
    "start": "2888310",
    "end": "2894350"
  },
  {
    "start": "2893000",
    "end": "3116000"
  },
  {
    "text": "So here, now, is the\npropensity score algorithm. We take our data set, which\nhave samples of X, T, and Y",
    "start": "2894350",
    "end": "2903080"
  },
  {
    "text": "where Y, of course, tells\nyou the potential outcome corresponding to\nthe treatment T.",
    "start": "2903080",
    "end": "2910412"
  },
  {
    "text": "We're going to use any\nmachine learning method in order to estimate\nthis model that",
    "start": "2910413",
    "end": "2916150"
  },
  {
    "text": "can give you a probability\nof treatment given X. Now, critically, we need\na probability for this.",
    "start": "2916150",
    "end": "2922727"
  },
  {
    "text": "We're not trying to\ndo classification. We need an actual probability,\nand so if you remember back to previous lectures where\nwe spoke about calibration,",
    "start": "2922727",
    "end": "2930670"
  },
  {
    "text": "about the ability to accurately\npredict probabilities, that is going to be\nreally important here.",
    "start": "2930670",
    "end": "2935930"
  },
  {
    "text": "And so for example, if you were\nto use a deep neural network in order to estimate\nthe propensity scores,",
    "start": "2935930",
    "end": "2942309"
  },
  {
    "text": "deep networks are well known\nto not be well calibrated. And so one would have to use\none of a number of new methods",
    "start": "2942310",
    "end": "2949030"
  },
  {
    "text": "that have been\nrecently developed to make the outputs of\ndeep learning calibrated in order to use this\ntype of technique.",
    "start": "2949030",
    "end": "2955730"
  },
  {
    "text": "So after finishing\nstep 1, now that you have a model that can allow\nyou to estimate the propensity score for every\ndata point X, we now",
    "start": "2955730",
    "end": "2963130"
  },
  {
    "text": "can take those and estimate\nyour average treatment effect with the following formula.",
    "start": "2963130",
    "end": "2969450"
  },
  {
    "text": "It's 1 over n of the sum\nover the data points, where",
    "start": "2969450",
    "end": "2974790"
  },
  {
    "text": "the data points corresponding\nto the treatment 1 of Yi-- that part is\nidentical to before.",
    "start": "2974790",
    "end": "2981570"
  },
  {
    "text": "But what you see now is\nwe're going to divide it by the propensity score,\nand so this denominator,",
    "start": "2981570",
    "end": "2986609"
  },
  {
    "text": "that's the new piece here. That's the inverse of\nthe propensity score is precisely the weighting that\nwe were referring to earlier,",
    "start": "2986610",
    "end": "2993940"
  },
  {
    "text": "and the same thing happens\nover here for Ti equals 0. Now, let's try to get some\nintuition about this formula,",
    "start": "2993940",
    "end": "3001700"
  },
  {
    "text": "and I like trying\nto get intuition by looking at a special case. So the simplest special case\nthat we might be familiar with",
    "start": "3001700",
    "end": "3008300"
  },
  {
    "text": "is that of a randomized\ncontrol trial, where because you're flipping a coin,\nand each data point either",
    "start": "3008300",
    "end": "3014090"
  },
  {
    "text": "gets treatment 0 or treatment\n1, then the propensity score is precisely,\ndeterministically equal to 5.",
    "start": "3014090",
    "end": "3021119"
  },
  {
    "text": "So let's take this now. No machine learning done here. Let's just plug it in to see if\nwe get back the formula that I",
    "start": "3021120",
    "end": "3028250"
  },
  {
    "text": "showed you earlier\nfor the estimate of the average treatment effect\nin a randomized control trial. So we plug that in over there.",
    "start": "3028250",
    "end": "3035329"
  },
  {
    "text": "This now becomes 0.5, and\nplug that in over here.",
    "start": "3035330",
    "end": "3041840"
  },
  {
    "text": "This also becomes 0.5. And then what we're\ngoing to do is we're just",
    "start": "3041840",
    "end": "3047660"
  },
  {
    "text": "going to take that 0.5. We're going to bring that out,\nand this is going to become a 2 over here, and\nsame, a 2 over here.",
    "start": "3047660",
    "end": "3056030"
  },
  {
    "text": "And you get to the\nfollowing formula, which is-- if you were to compare to\nthe formula from a few slides",
    "start": "3056030",
    "end": "3061220"
  },
  {
    "text": "ago, it's almost identical,\nexcept that a few slides ago over here, I had 1 over n1,\nand over here, I had 1 over n0.",
    "start": "3061220",
    "end": "3074560"
  },
  {
    "text": " Now, these two are two different\nestimators for the same thing,",
    "start": "3074560",
    "end": "3080032"
  },
  {
    "text": "and the reason why you can\nsay they're the same thing is that, in a randomized\ncontrol trial,",
    "start": "3080032",
    "end": "3085527"
  },
  {
    "text": "the number of individuals\nthat receive treatment 1 is, on average, n over 2. Similarly, the number of\nindividuals receiving treatment",
    "start": "3085527",
    "end": "3091780"
  },
  {
    "text": "0 are, on average, n over 2. So if you were to--",
    "start": "3091780",
    "end": "3096850"
  },
  {
    "text": "that n over 2 cancels\nout with this 2 over n is what gets you a\ncorrect estimator.",
    "start": "3096850",
    "end": "3101980"
  },
  {
    "text": "So this is a slightly\ndifferent estimator, but nearly identical to the\none that I showed you earlier,",
    "start": "3101980",
    "end": "3109000"
  },
  {
    "text": "and by this argument, is\na consistent estimator of the average treatment effect\nin a randomized control trial.",
    "start": "3109000",
    "end": "3117460"
  },
  {
    "start": "3116000",
    "end": "3490000"
  },
  {
    "text": "So any questions before I try\nto derive this formula for you? ",
    "start": "3117460",
    "end": "3140180"
  },
  {
    "text": "So one student asks,\nso the propensity score is the, quote,\nunquote, \"bias\" of how",
    "start": "3140180",
    "end": "3146120"
  },
  {
    "text": "likely people are assigned\nto T equals 1 or T equals 0?",
    "start": "3146120",
    "end": "3152870"
  },
  {
    "text": "Yes, that's exactly right. So if you were to imagine\ntaking an individual where",
    "start": "3152870",
    "end": "3163640"
  },
  {
    "text": "this probability\nfor that individual is, let's say,\nvery close to 1, it",
    "start": "3163640",
    "end": "3168890"
  },
  {
    "text": "means that there are very\nfew other people in the data set who receive treatment 1.",
    "start": "3168890",
    "end": "3174470"
  },
  {
    "text": "They're a red data point in\na sea of blue data points.",
    "start": "3174470",
    "end": "3181820"
  },
  {
    "text": "And by dividing by\nthat, we're going to be trying to remove that\nbias, and that's exactly right.",
    "start": "3181820",
    "end": "3188270"
  },
  {
    "text": "Thank you for that question. Are there other questions? ",
    "start": "3188270",
    "end": "3200559"
  },
  {
    "text": "I really appreciate the\nquestions via the chat window, so thank you. ",
    "start": "3200560",
    "end": "3208660"
  },
  {
    "text": "So let's now try to\nderive this formula. ",
    "start": "3208660",
    "end": "3214480"
  },
  {
    "text": "Recall the definition of\naverage treatment effect, and for those who are\npaying very close attention,",
    "start": "3214480",
    "end": "3219580"
  },
  {
    "text": "you might notice that I removed\nthe expectation over Y1. And for this derivation\nthat I'm going to give you,",
    "start": "3219580",
    "end": "3225070"
  },
  {
    "text": "I'm going to suppose-- I'm going to assume that a\npotential outcomes are all deterministic because it\nmakes the math easier,",
    "start": "3225070",
    "end": "3231130"
  },
  {
    "text": "but is without\nloss of generality. So the average\ntreatment effect is the expectation, with\nrespect to all individuals,",
    "start": "3231130",
    "end": "3239020"
  },
  {
    "text": "of the potential outcome\nY1 minus the expectation with respect to all individuals\nof the potential outcome Y0.",
    "start": "3239020",
    "end": "3244329"
  },
  {
    "text": "So this term over here is going\nto be our estimate of that,",
    "start": "3244330",
    "end": "3249460"
  },
  {
    "text": "and this term over here is\ngoing to be our estimate of this expectation.",
    "start": "3249460",
    "end": "3254550"
  },
  {
    "text": "So naively, if you were to\njust take the observed data, it would allow you to compute--",
    "start": "3254550",
    "end": "3260100"
  },
  {
    "text": "if you, for example, just\naveraged the values of Y for the individual who\nreceived treatment 1,",
    "start": "3260100",
    "end": "3265635"
  },
  {
    "text": "that would give you this\nexpectation that I'm showing on the bottom here. I want you to compare\nthat to the one that's",
    "start": "3265635",
    "end": "3271830"
  },
  {
    "text": "actually needed in the\naverage treatment effect. Whereas over here, it's an\nexpectation with respect to individuals that received\ntreatment 1, up here,",
    "start": "3271830",
    "end": "3279609"
  },
  {
    "text": "this was an expectation with\nrespect to all individuals. But the thing inside\nthe expectation is exactly identical,\nand that's the key point",
    "start": "3279610",
    "end": "3286830"
  },
  {
    "text": "that we're going\nto work with, which is that we want an\nexpectation with respect to a different distribution than\nthe one that we actually have.",
    "start": "3286830",
    "end": "3294690"
  },
  {
    "text": "And again, this\nshould ring bells, because this sounds\nvery, very familiar to the data set shift\nstory that we talked",
    "start": "3294690",
    "end": "3300750"
  },
  {
    "text": "about a few lectures ago. So I'm going to show you how\nto derive an estimator for just",
    "start": "3300750",
    "end": "3307910"
  },
  {
    "text": "this first term, and the\nsecond term is obviously going to be identical. So let's start out\nwith the following.",
    "start": "3307910",
    "end": "3314060"
  },
  {
    "text": "We know that p of X\ngiven T times p of T is equal to p of X\ntimes p of T given X.",
    "start": "3314060",
    "end": "3323690"
  },
  {
    "text": "So what I've just done here\nis use two different formulas",
    "start": "3323690",
    "end": "3328790"
  },
  {
    "text": "for a joint distribution,\nand then I've",
    "start": "3328790",
    "end": "3336340"
  },
  {
    "text": "divided by p of T\ngiven X in order to get the formula that I\nshowed you a second ago. I'm not going to\nattempt to erase that.",
    "start": "3336340",
    "end": "3342800"
  },
  {
    "text": "I'll leave it up there. So the next thing we're going\nto do is we're going to say,",
    "start": "3342800",
    "end": "3348520"
  },
  {
    "text": "if we were to compute an\nexpectation with respect to p of X given T equals 1,\nand if we were to now take",
    "start": "3348520",
    "end": "3357730"
  },
  {
    "text": "the value that we observe, Y1,\nwhich we can get observations",
    "start": "3357730",
    "end": "3362800"
  },
  {
    "text": "for all the individuals\nwho received treatment 1, and if we were to re-weight\nthis observation by this ratio,",
    "start": "3362800",
    "end": "3370300"
  },
  {
    "text": "where remember,\nthis ratio showed up",
    "start": "3370300",
    "end": "3376780"
  },
  {
    "text": "in the previous bullet point,\nthen what I'm going to show you in just a moment is that\nthis is equal to the quantity",
    "start": "3376780",
    "end": "3385569"
  },
  {
    "text": "that we actually wanted. Well, why is that? Well, if you expand\nthis expectation,",
    "start": "3385570",
    "end": "3396500"
  },
  {
    "text": "this expectation is an\nintegral with respect to p of X conditioned\non T equals 1 times",
    "start": "3396500",
    "end": "3409609"
  },
  {
    "text": "the thing inside the brackets,\nand because we know that p of--",
    "start": "3409610",
    "end": "3415130"
  },
  {
    "text": "because we know from up here\nthat p of X conditioned on T equals 1 times p of T\nequals 1 divided by p of T",
    "start": "3415130",
    "end": "3421510"
  },
  {
    "text": "equals 1 conditioned on\nX is equal to p of X, this whole thing\nis just going to be",
    "start": "3421510",
    "end": "3426590"
  },
  {
    "text": "equal to an integral of p of\nX times Y1, which is precisely",
    "start": "3426590",
    "end": "3434750"
  },
  {
    "text": "the definition of\nexpectation that we want. So this was a very\nsimple derivation to show you that the\nre-weighting gets you",
    "start": "3434750",
    "end": "3441320"
  },
  {
    "text": "what you need. Now, we can estimate this\nexpectation empirically as follows, the\nestimate that we're",
    "start": "3441320",
    "end": "3448160"
  },
  {
    "text": "going to now sum\nover all data points that received treatment 1. We're going to take\nan average, so we're dividing by the\nnumber of data points",
    "start": "3448160",
    "end": "3454580"
  },
  {
    "text": "that received treatment 1. For p of T equals\n1, we're just going to use the empirical estimate\nof how many individuals received",
    "start": "3454580",
    "end": "3461851"
  },
  {
    "text": "treatment 1 in the\ndata set divided by the total number of\nindividuals in the data set. That's n1 divided by n. And for the denominator, p of\nT equals 1 conditioned on X,",
    "start": "3461852",
    "end": "3469700"
  },
  {
    "text": "we just plug in, now, the\npropensity score, which we had previously estimated. And we're done.",
    "start": "3469700",
    "end": "3474990"
  },
  {
    "text": "And so that, now,\nis our estimate for the first term in the\naverage treatment effect,",
    "start": "3474990",
    "end": "3480630"
  },
  {
    "text": "and you can do that now\nloosely for Ti equals 0. And I've shown\nyou the full proof of why this is an unbiased\nestimator for average treatment",
    "start": "3480630",
    "end": "3489330"
  },
  {
    "text": "effect. So I'm going to be concluding\nnow, in the next few minutes. First, I just wanted to\ncomment on what we just saw.",
    "start": "3489330",
    "end": "3497059"
  },
  {
    "text": "So we saw a different way to\nestimate the average treatment",
    "start": "3497060",
    "end": "3502100"
  },
  {
    "text": "effect, which only required\nestimating the propensity score. In particular, we never\nhad to use a model",
    "start": "3502100",
    "end": "3509750"
  },
  {
    "text": "to predict Y in this\napproach for estimating the average treatment\neffect, and that's",
    "start": "3509750",
    "end": "3515560"
  },
  {
    "text": "a good thing and a bad thing. It's a good thing\nbecause, if you had errors in\nestimating your model y,",
    "start": "3515560",
    "end": "3524350"
  },
  {
    "text": "as I showed you in the very\nbeginning of today's lecture, that could have\na very big impact on your estimate of the\naverage treatment effect.",
    "start": "3524350",
    "end": "3530680"
  },
  {
    "text": "And so that doesn't\nshow up here. On the other hand, this\nhas its own disadvantages.",
    "start": "3530680",
    "end": "3536090"
  },
  {
    "text": "So for example, the propensity\nscore is going to be really, really affected by\nlack of overlap,",
    "start": "3536090",
    "end": "3543527"
  },
  {
    "text": "because when you\nhave lack of overlap, it means there's some data\npoints where the propensity score is very close to\n0 or very close to 1.",
    "start": "3543527",
    "end": "3549870"
  },
  {
    "text": "And that really leads\nto very large variance in your estimators. And a very common\ntrick which is used",
    "start": "3549870",
    "end": "3556270"
  },
  {
    "text": "to try to address\nthat concern is known as clipping, where you\nsimply clip the propensity scores so that they're always\nbounding away from 0 and 1.",
    "start": "3556270",
    "end": "3562809"
  },
  {
    "text": "But that's really\njust a heuristic, and it can, of course, then\nlead to biased estimates",
    "start": "3562810",
    "end": "3568270"
  },
  {
    "text": "of the average treatment effect. So there's a whole family of\ncausal inference algorithms",
    "start": "3568270",
    "end": "3573900"
  },
  {
    "text": "that attempt to use ideas\nfrom both covariate adjustment and inverse\npropensity weighting.",
    "start": "3573900",
    "end": "3580770"
  },
  {
    "text": "For example, there's\na method called doubly robust\nestimators, and we'll try to provide a citation for\nthose estimators in the Scribe",
    "start": "3580770",
    "end": "3588810"
  },
  {
    "text": "notes. And these doubly\nrobust estimators are a different family of\nestimators that actually bring in both of these\ntechniques together,",
    "start": "3588810",
    "end": "3595410"
  },
  {
    "text": "and they have a\nreally nice property, which is that if either\none of them fail, you still get valid estimates\nof average treatment effect.",
    "start": "3595410",
    "end": "3603700"
  },
  {
    "text": "I'm going to skip this and just\njump to the summary now, which is that we've presented\ntwo different approaches",
    "start": "3603700",
    "end": "3611320"
  },
  {
    "text": "for causal inference\nfrom observational data-- covariate adjustment and\npropensity score based methods.",
    "start": "3611320",
    "end": "3617690"
  },
  {
    "text": "And both of these,\nI need to stress, are only going to\ngive you valid results",
    "start": "3617690",
    "end": "3623470"
  },
  {
    "text": "under the assumptions\nwe outlined in the previous lecture-- for example, that your\ncausal graph is correct;",
    "start": "3623470",
    "end": "3629410"
  },
  {
    "text": "critically, that there's no\nunobserved confounding; and second, that you have overlap\nbetween your two treatment",
    "start": "3629410",
    "end": "3637720"
  },
  {
    "text": "classes. And third, if you're using\na non-parametric regression",
    "start": "3637720",
    "end": "3646840"
  },
  {
    "text": "approach, overlap is\nextremely important, because without\noverlap, your model's",
    "start": "3646840",
    "end": "3652990"
  },
  {
    "text": "undefined in regions of space. And thus, as a result,\nyou have no way",
    "start": "3652990",
    "end": "3659110"
  },
  {
    "text": "of verifying if your\nextrapolations are correct, and so one has to use trust\nin the model, which is not",
    "start": "3659110",
    "end": "3667780"
  },
  {
    "text": "something we really like. And in propensity score methods,\noverlap is very important",
    "start": "3667780",
    "end": "3674109"
  },
  {
    "text": "because if you don't have that,\nyou get inverse propensity scores that are either--",
    "start": "3674110",
    "end": "3679330"
  },
  {
    "text": "which are infinite and lead\nto extremely high variance estimators.",
    "start": "3679330",
    "end": "3685059"
  },
  {
    "text": "So in the end of this\nslide, which are already posted online, I\ninclude some references",
    "start": "3685060",
    "end": "3690400"
  },
  {
    "text": "that I strongly encourage\nfolks to follow up on. First references to two\nrecent workshops that",
    "start": "3690400",
    "end": "3695460"
  },
  {
    "text": "have been held in the machine\nlearning community so that you can get a sense of what the\nlatest and greatest in terms",
    "start": "3695460",
    "end": "3701170"
  },
  {
    "text": "of research in\ncausal inference are, two different books\non causal inference that you can download\nfor free from MIT,",
    "start": "3701170",
    "end": "3708508"
  },
  {
    "text": "and finally, some\npapers that I think are really interesting,\nparticularly of interest, potentially, to course projects.",
    "start": "3708508",
    "end": "3714100"
  },
  {
    "text": "So we are at time now. I will hang around for a\nfew minutes after lecture,",
    "start": "3714100",
    "end": "3719859"
  },
  {
    "text": "as I would normally. But I'm going to stop the\nrecording of the lecture.",
    "start": "3719860",
    "end": "3726270"
  },
  {
    "start": "3726270",
    "end": "3736000"
  }
]
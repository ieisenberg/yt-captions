[
  {
    "start": "0",
    "end": "115000"
  },
  {
    "text": "There are a few MMU implementation details\nwe can tweak for more efficiency or functionality.",
    "start": "510",
    "end": "7490"
  },
  {
    "text": "In our simple page-map implementation, the\nfull page map occupies some number of physical",
    "start": "7490",
    "end": "12840"
  },
  {
    "text": "pages.",
    "start": "12840",
    "end": "14350"
  },
  {
    "text": "Using the numbers shown here, if each page\nmap entry occupies one word of main memory,",
    "start": "14350",
    "end": "19220"
  },
  {
    "text": "we'd need 2^20 words (or 2^10 pages) to hold\nthe page table.",
    "start": "19220",
    "end": "24990"
  },
  {
    "text": "If we have multiple contexts, we would need\nmultiple page tables, and the demands on our",
    "start": "24990",
    "end": "30340"
  },
  {
    "text": "physical memory resources would start to get\nlarge.",
    "start": "30340",
    "end": "35100"
  },
  {
    "text": "The MMU implementation shown here uses a hierarchical\npage map.",
    "start": "35100",
    "end": "39829"
  },
  {
    "text": "The top 10 bits of virtual address are used\nto access a \"page directory\", which indicates",
    "start": "39829",
    "end": "45730"
  },
  {
    "text": "the physical page that holds the page map\nfor that segment of the virtual address space.",
    "start": "45730",
    "end": "52218"
  },
  {
    "text": "The key idea is that the page map segments\nare in virtual memory, i.e., they don't all",
    "start": "52219",
    "end": "57030"
  },
  {
    "text": "have to be resident at any given time.",
    "start": "57030",
    "end": "60559"
  },
  {
    "text": "If the running application is only actively\nusing a small portion of its virtual address",
    "start": "60559",
    "end": "65369"
  },
  {
    "text": "space, we may only need a handful of pages\nto hold the page directory and the necessary",
    "start": "65370",
    "end": "71040"
  },
  {
    "text": "page map segments.",
    "start": "71040",
    "end": "73280"
  },
  {
    "text": "The resultant savings really add up when there\nare many applications, each with their own",
    "start": "73280",
    "end": "78600"
  },
  {
    "text": "context.",
    "start": "78600",
    "end": "80430"
  },
  {
    "text": "In this example, note that the middle entries\nin the page directory, i.e., the entries corresponding",
    "start": "80430",
    "end": "86860"
  },
  {
    "text": "to the as-yet unallocated virtual memory between\nthe stack and heap, are all marked as not",
    "start": "86860",
    "end": "92910"
  },
  {
    "text": "resident.",
    "start": "92910",
    "end": "93910"
  },
  {
    "text": ".133 So no page map resources need be devoted\nto holding a zillion page map entries all",
    "start": "93910",
    "end": "98980"
  },
  {
    "text": "marked \"not resident\".",
    "start": "98980",
    "end": "102170"
  },
  {
    "text": "Accessing the page map now requires two access\nto main memory (first to the page directory,",
    "start": "102170",
    "end": "107640"
  },
  {
    "text": "then to the appropriate segment of the page\nmap),",
    "start": "107640",
    "end": "109970"
  },
  {
    "text": "but the TLB makes the impact of that additional\naccess negligible.",
    "start": "109970",
    "end": "116340"
  },
  {
    "start": "115000",
    "end": "205000"
  },
  {
    "text": "Normally when changing contexts, the OS would\nreload the page-table pointer to point to",
    "start": "116340",
    "end": "121500"
  },
  {
    "text": "the appropriate page table (or page table\ndirectory if we adopt the scheme from the",
    "start": "121500",
    "end": "126310"
  },
  {
    "text": "previous slide).",
    "start": "126310",
    "end": "128250"
  },
  {
    "text": "Since this context switch in effect changes\nall the entries in the page table, the OS",
    "start": "128250",
    "end": "133189"
  },
  {
    "text": "would also have to invalidate all the entries\nin the TLB cache.",
    "start": "133189",
    "end": "138260"
  },
  {
    "text": "This naturally has a huge impact on the TLB\nhit ratio and the average memory access time",
    "start": "138260",
    "end": "143819"
  },
  {
    "text": "takes a huge hit because of the all page map\naccesses that are now necessary until the",
    "start": "143819",
    "end": "149110"
  },
  {
    "text": "TLB is refilled.",
    "start": "149110",
    "end": "151790"
  },
  {
    "text": "To reduce the impact of context switches,\nsome MMUs include a context-number register",
    "start": "151790",
    "end": "157549"
  },
  {
    "text": "whose contents are concatenated with the virtual\npage number to form the query to the TLB.",
    "start": "157549",
    "end": "164639"
  },
  {
    "text": "Essentially this means that the tag field\nin the TLB cache entries will expand to include",
    "start": "164639",
    "end": "169840"
  },
  {
    "text": "the context number provided at the time the\nTLB entry was filled.",
    "start": "169840",
    "end": "175079"
  },
  {
    "text": "To switch contexts, the OS would now reload\nboth the context-number register and the page-table",
    "start": "175079",
    "end": "180849"
  },
  {
    "text": "pointer.",
    "start": "180849",
    "end": "182069"
  },
  {
    "text": "With a new context number, entries in the\nTLB for other contexts would no longer match,",
    "start": "182069",
    "end": "187879"
  },
  {
    "text": "so no need to flush the TLB on a context switch.",
    "start": "187879",
    "end": "191890"
  },
  {
    "text": "If the TLB has sufficient capacity to cache\nthe VPN-to-PPN mappings for several contexts,",
    "start": "191890",
    "end": "199390"
  },
  {
    "text": "context switches would no longer have a substantial\nimpact on average memory access time.",
    "start": "199390",
    "end": "204999"
  },
  {
    "text": "Finally, let's return to the question about\nhow to incorporate both a cache and an MMU",
    "start": "204999",
    "end": "210700"
  },
  {
    "start": "205000",
    "end": "289000"
  },
  {
    "text": "into our memory system.",
    "start": "210700",
    "end": "213299"
  },
  {
    "text": "The first choice is to place the cache between\nthe CPU and the MMU, i.e., the cache would",
    "start": "213299",
    "end": "218349"
  },
  {
    "text": "work on virtual addresses.",
    "start": "218349",
    "end": "220470"
  },
  {
    "text": "This seems good: the cost of the VPN-to-PPN\ntranslation is only incurred on a cache miss.",
    "start": "220470",
    "end": "227250"
  },
  {
    "text": "The difficulty comes when there's a context\nswitch, which changes the effective contents",
    "start": "227250",
    "end": "233439"
  },
  {
    "text": "of virtual memory.",
    "start": "233439",
    "end": "235010"
  },
  {
    "text": "After all that was the point of the context\nswitch, since we want to switch execution",
    "start": "235010",
    "end": "239569"
  },
  {
    "text": "to another program.",
    "start": "239569",
    "end": "240689"
  },
  {
    "text": "But that means the OS would have to invalidate\nall the entries in the cache when performing",
    "start": "240689",
    "end": "246700"
  },
  {
    "text": "a context switch, which makes the cache miss\nratio quite large until the cache is refilled.",
    "start": "246700",
    "end": "253989"
  },
  {
    "text": "So once again the performance impact of a\ncontext switch would be quite high.",
    "start": "253989",
    "end": "260239"
  },
  {
    "text": "We can solve this problem by caching physical\naddresses, i.e., placing the cache between",
    "start": "260240",
    "end": "265259"
  },
  {
    "text": "the MMU and main memory.",
    "start": "265260",
    "end": "267400"
  },
  {
    "text": "Thus the contents of the cache are unaffected\nby context switches -",
    "start": "267400",
    "end": "271930"
  },
  {
    "text": "the requested physical addresses will be different,\nbut the cache handles that in due course.",
    "start": "271930",
    "end": "277780"
  },
  {
    "text": "The downside of this approach is that we have\nto incur the cost of the MMU translation before",
    "start": "277780",
    "end": "282650"
  },
  {
    "text": "we can start the cache access, slightly increasing\nthe average memory access time.",
    "start": "282650",
    "end": "290060"
  },
  {
    "start": "289000",
    "end": "392000"
  },
  {
    "text": "But if we're clever we don't have to wait\nfor the MMU to finish before starting the",
    "start": "290060",
    "end": "294169"
  },
  {
    "text": "access to the cache.",
    "start": "294170",
    "end": "296370"
  },
  {
    "text": "To get started, the cache needs the line number\nfrom the virtual address in order to fetch",
    "start": "296370",
    "end": "300850"
  },
  {
    "text": "the appropriate cache line.",
    "start": "300850",
    "end": "303670"
  },
  {
    "text": "If the address bits used for the line number\nare completely contained in the page offset",
    "start": "303670",
    "end": "308600"
  },
  {
    "text": "of the virtual address, these bits are unaffected\nby the MMU translation,",
    "start": "308600",
    "end": "314080"
  },
  {
    "text": "and so the cache lookup can happen in parallel\nwith the MMU operation.",
    "start": "314080",
    "end": "320229"
  },
  {
    "text": "Once the cache lookup is complete, the tag\nfield of the cache line can be compared with",
    "start": "320230",
    "end": "324530"
  },
  {
    "text": "the appropriate bits of the physical address\nproduced by the MMU.",
    "start": "324530",
    "end": "329590"
  },
  {
    "text": "If there was a TLB hit in the MMU, the physical\naddress should be available at about the same",
    "start": "329590",
    "end": "334840"
  },
  {
    "text": "time as the tag field produced by the cache\nlookup.",
    "start": "334840",
    "end": "339490"
  },
  {
    "text": "By performing the MMU translation and cache\nlookup in parallel, there's usually no impact",
    "start": "339490",
    "end": "344639"
  },
  {
    "text": "on the average memory access time!",
    "start": "344640",
    "end": "347170"
  },
  {
    "text": "Voila, the best of both worlds: a physically\naddressed cache that incurs no time penalty",
    "start": "347170",
    "end": "352940"
  },
  {
    "text": "for MMU translation.",
    "start": "352940",
    "end": "356080"
  },
  {
    "text": "One final detail: one way to increase the\ncapacity of the cache is to increase the number",
    "start": "356080",
    "end": "361460"
  },
  {
    "text": "of cache lines and hence the number of bits\nof address used as the line number.",
    "start": "361460",
    "end": "367560"
  },
  {
    "text": "Since we want the line number to fit into\nthe page offset field of the virtual address,",
    "start": "367560",
    "end": "371940"
  },
  {
    "text": "we're limited in how many cache lines we can\nhave.",
    "start": "371940",
    "end": "375060"
  },
  {
    "text": "The same argument applies to increasing the\nblock size.",
    "start": "375060",
    "end": "379690"
  },
  {
    "text": "So to increase the capacity of the cache our\nonly option is to increase the cache associativity,",
    "start": "379690",
    "end": "386390"
  },
  {
    "text": "which adds capacity without affecting the\naddress bits used for the line number.",
    "start": "386390",
    "end": "393240"
  },
  {
    "start": "392000",
    "end": "453000"
  },
  {
    "text": "That's it for our discussion of virtual memory.",
    "start": "393240",
    "end": "396330"
  },
  {
    "text": "We use the MMU to provide the context for\nmapping virtual addresses to physical addresses.",
    "start": "396330",
    "end": "402270"
  },
  {
    "text": "By switching contexts we can create the illusion\nof many virtual address spaces, so many programs",
    "start": "402270",
    "end": "408639"
  },
  {
    "text": "can share a single CPU and physical memory\nwithout interfering with each other.",
    "start": "408640",
    "end": "414650"
  },
  {
    "text": "We discussed using a page map to translate\nvirtual page numbers to physical page numbers.",
    "start": "414650",
    "end": "420490"
  },
  {
    "text": "To save costs, we located the page map in\nphysical memory and used a TLB to eliminate",
    "start": "420490",
    "end": "426610"
  },
  {
    "text": "the cost of accessing the page map for most\nvirtual memory accesses.",
    "start": "426610",
    "end": "433539"
  },
  {
    "text": "Access to a non-resident page causes a page\nfault exception, allowing the OS to manage",
    "start": "433540",
    "end": "438480"
  },
  {
    "text": "the complexities of equitably sharing physical\nmemory across many applications.",
    "start": "438480",
    "end": "445240"
  },
  {
    "text": "We saw that providing contexts was the first\nstep towards creating virtual machines, which",
    "start": "445240",
    "end": "450520"
  },
  {
    "text": "is the topic of our next lecture.",
    "start": "450520",
    "end": "452379"
  }
]
[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "7410"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "7410",
    "end": "13960"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "13960",
    "end": "19140"
  },
  {
    "text": " PROFESSOR: OK.",
    "start": "19140",
    "end": "24269"
  },
  {
    "start": "22000",
    "end": "103000"
  },
  {
    "text": "I guess we might as\nwell get started. We talked a little bit about\nMarkov processes last week.",
    "start": "24270",
    "end": "32729"
  },
  {
    "text": "I want to review a little bit of\nwhat we did then, and then move on pretty quickly.",
    "start": "32729",
    "end": "39570"
  },
  {
    "text": "This is a rather strange\nchapter, because it's full of notation.",
    "start": "39570",
    "end": "46620"
  },
  {
    "text": "When I first started reviewing\nit myself after not having looked at it for about a year,\nI was horrified by the amount",
    "start": "46620",
    "end": "54550"
  },
  {
    "text": "of notation. And then I realized, what we're\ndoing in this chapter is putting together all the\nstuff we've learned",
    "start": "54550",
    "end": "62750"
  },
  {
    "text": "from Poisson processes. There are Poisson processes\nall through this",
    "start": "62750",
    "end": "68460"
  },
  {
    "text": "Markov chains renewals. And all three of these, with\nall their notation, are all",
    "start": "68460",
    "end": "75670"
  },
  {
    "text": "sitting here. And then we get into new things,\nalso, so I apologize",
    "start": "75670",
    "end": "81390"
  },
  {
    "text": "for the notation. I'm going to try to keep\nit down to the minimal amount this time.",
    "start": "81390",
    "end": "87480"
  },
  {
    "text": "And see if we can sort of get\nto the bottom line as easily",
    "start": "87480",
    "end": "93060"
  },
  {
    "text": "as we can, so that when you do\nthe exercises and read the",
    "start": "93060",
    "end": "98350"
  },
  {
    "text": "notes, you can go back in\nfill in some of the things that are missing.",
    "start": "98350",
    "end": "104630"
  },
  {
    "start": "103000",
    "end": "445000"
  },
  {
    "text": "OK. So accountable state\nMarkov process. The easiest way to define it,\nand the way we're defining it",
    "start": "104630",
    "end": "113090"
  },
  {
    "text": "is as an extension\nof accountable state Markov chain. So you start out with\naccountable state Markov",
    "start": "113090",
    "end": "118980"
  },
  {
    "text": "chain, and then along with each\nstep, say from state x sub n to x sub n plus 1, there\nis an exponential holding",
    "start": "118980",
    "end": "129720"
  },
  {
    "text": "time, u sub n plus 1. We said that it was a little\nstrange associating the",
    "start": "129720",
    "end": "135420"
  },
  {
    "text": "holding time of the\nfinal state rather than the initial state. But you almost had to do that,\nbecause of many things that",
    "start": "135420",
    "end": "143890"
  },
  {
    "text": "would get very confusing\notherwise. So we're just doing that. We start out in state x0,\nwhich is usually given.",
    "start": "143890",
    "end": "153860"
  },
  {
    "text": "If it's not given,\nit can be random. And then we go to state x1 after\na waiting time, u sub 1.",
    "start": "153860",
    "end": "164659"
  },
  {
    "text": "Go from x1 to x2 with a\nwaiting time u sub 2. The waiting time u sub i is a\nfunction of the state we're",
    "start": "164660",
    "end": "174640"
  },
  {
    "text": "coming from, in the sense that\nit's an exponential random variable who's rate is\ngiven by the state",
    "start": "174640",
    "end": "181820"
  },
  {
    "text": "we're coming from. So this diagram here gives\nyou, really, what the",
    "start": "181820",
    "end": "192170"
  },
  {
    "text": "dependence of this set of\nrandom variables is. You have a sequence of random\nvariables here.",
    "start": "192170",
    "end": "199650"
  },
  {
    "text": "A sequence of random\nvariables here. Each random variable here\nconditional on the initial",
    "start": "199650",
    "end": "206950"
  },
  {
    "text": "state that it's coming\nfrom, is independent of everything else. And that's what this dependence\ndiagram means.",
    "start": "206950",
    "end": "215330"
  },
  {
    "text": "It's a generalization of what\nwe talked about before. When we talked about Markov\nchains before, we just had a",
    "start": "215330",
    "end": "222790"
  },
  {
    "text": "string of states. And each state x sub n is\ndependent only on the prior",
    "start": "222790",
    "end": "232540"
  },
  {
    "text": "state x sub n minus 1. And given the prior state\nx sub n minus 1, it's",
    "start": "232540",
    "end": "238610"
  },
  {
    "text": "statistically independent of\nall states before that. Here we have this more general\nsituation of a tree.",
    "start": "238610",
    "end": "248269"
  },
  {
    "text": "I thought I'd better illustrate\nthis a little more. If you have a directed tree, the\ndependencies, each random",
    "start": "248270",
    "end": "257739"
  },
  {
    "text": "variable conditional as parent\nis statistically independent of all earlier random\nvariables.",
    "start": "257740",
    "end": "264129"
  },
  {
    "text": "In other words, this random\nvariable here conditional on this random variable is\nstatistically independent of",
    "start": "264130",
    "end": "272540"
  },
  {
    "text": "this, this, this, and this. And so you can move forward in\nthis way, defining each random",
    "start": "272540",
    "end": "279810"
  },
  {
    "text": "variable as being statistically\nindependent of everything in the past,\nconditional on just one",
    "start": "279810",
    "end": "287550"
  },
  {
    "text": "previous random variable. As an example of this, if you\nlook at the probability of x0,",
    "start": "287550",
    "end": "294700"
  },
  {
    "text": "x1, x2, and u2, these five\nrandom variables here.",
    "start": "294700",
    "end": "304680"
  },
  {
    "text": "Probability of x0, probability\nof x1 given x0. Probability of x2 given x1.",
    "start": "304680",
    "end": "311400"
  },
  {
    "text": "Probability of u2 given x1. You can write that\nout in that way.",
    "start": "311400",
    "end": "316889"
  },
  {
    "text": "From this, you can rewrite this\nin any way you want to. You take these two equations,\nand you can rewrite them as a",
    "start": "316890",
    "end": "324000"
  },
  {
    "text": "probability of x1 times the\nprobability of x0 given x1, times the probability of\nx2 given x1, times the",
    "start": "324000",
    "end": "331830"
  },
  {
    "text": "probability u2 given x1. In other words, what's happening\nhere is if you",
    "start": "331830",
    "end": "337950"
  },
  {
    "text": "condition everything on x1,\nthis random variable here,",
    "start": "337950",
    "end": "343060"
  },
  {
    "text": "this stuff is statistically\nindependent of this. Is statistically independent\nof all of this.",
    "start": "343060",
    "end": "351280"
  },
  {
    "text": "Given any one node in this\nthree, given the value of that",
    "start": "351280",
    "end": "357180"
  },
  {
    "text": "node, everything on every set of\nbranches coming out from it is statistically independent.",
    "start": "357180",
    "end": "362280"
  },
  {
    "text": " This is a remarkably\nuseful property.",
    "start": "362280",
    "end": "368000"
  },
  {
    "text": "This is the Markov property\nin general. I mean, Markov chains,\nwe only use the fact",
    "start": "368000",
    "end": "373210"
  },
  {
    "text": "that it's on a chain. In general you use the fact\nthat it's on a tree. And all of this stuff can be\nused in remarkable ways.",
    "start": "373210",
    "end": "385539"
  },
  {
    "text": "I didn't know this until\nprobably five years ago. And suddenly when I realized it,\nI think because somebody",
    "start": "385540",
    "end": "392390"
  },
  {
    "text": "was pointing it out\nin a research paper they were writing. Suddenly all sorts of things\nbecame much, much easier.",
    "start": "392390",
    "end": "399380"
  },
  {
    "text": "Because everything like the fact\nwe pointed out before,",
    "start": "399380",
    "end": "406850"
  },
  {
    "text": "that the past is independent\nof the future, given the present, that's one\nexample of this.",
    "start": "406850",
    "end": "415020"
  },
  {
    "text": "But this is far more\ngeneral than that. It says that anything on this\ntree, if you can start at any",
    "start": "415020",
    "end": "422500"
  },
  {
    "text": "point on the tree, and\neverything going out from there is statistically\nindependent, given this node",
    "start": "422500",
    "end": "429050"
  },
  {
    "text": "on the tree. So that's a valuable thing. And so you get your condition\non any node, breaks a tree",
    "start": "429050",
    "end": "436720"
  },
  {
    "text": "into independent sub trees. You can then go on from there\nand break it down further and further and further, until you\nget out to the leaves.",
    "start": "436720",
    "end": "444520"
  },
  {
    "text": "So this independence property\nis really the general thing that we refer to when we\nsay a set of random",
    "start": "444520",
    "end": "451540"
  },
  {
    "start": "445000",
    "end": "864000"
  },
  {
    "text": "variables are Markov. OK. The evolution in time with a\nMarkov process, this diagram I",
    "start": "451540",
    "end": "458840"
  },
  {
    "text": "find very helpful to\nsee what's going on in a Markov process. You have a set of states.",
    "start": "458840",
    "end": "466090"
  },
  {
    "text": "Initially, you're in a state\nx0, the state at time 0 is",
    "start": "466090",
    "end": "472440"
  },
  {
    "text": "some given value i. This is a sample path here. The next state we'll say is\nj, the next state is a k.",
    "start": "472440",
    "end": "481569"
  },
  {
    "text": "When you're in state i, there's\nsome holding time,",
    "start": "481570",
    "end": "486890"
  },
  {
    "text": "which has rate new\n1, new sub i. It's an exponential random\nvariable which tells you how",
    "start": "486890",
    "end": "494190"
  },
  {
    "text": "long it takes until\nthis transition. This transition occurs\nat time s1, which is",
    "start": "494190",
    "end": "504390"
  },
  {
    "text": "u1 is equal to s1. The next transition is at s2. Equals u1 plus u2.",
    "start": "504390",
    "end": "511490"
  },
  {
    "text": "The next transition is at x3,\nwhich is u1 plus u2 plus u3. Now you start to see why we've\nnumbered these holding times",
    "start": "511490",
    "end": "519700"
  },
  {
    "text": "the way we have, so we can talk\nabout the times that each of these transitions\ntake place.",
    "start": "519700",
    "end": "524995"
  },
  {
    "text": " We usually assume that the\nembedded Markov chain for a",
    "start": "524995",
    "end": "530890"
  },
  {
    "text": "Markov process, remember, the\nembedded Markov chain now is just the Markov chain\nitself without these",
    "start": "530890",
    "end": "537480"
  },
  {
    "text": "holding times on it. We assume it has no self\ntransitions because if you're",
    "start": "537480",
    "end": "543070"
  },
  {
    "text": "sitting in a state x of t equals\ni, and suddenly there's a transition back to i again,\nand you look at the process in",
    "start": "543070",
    "end": "552199"
  },
  {
    "text": "terms of x of t, t greater\nthan or equal to 0. The state that you're in at\neach time t, what happens?",
    "start": "552200",
    "end": "561320"
  },
  {
    "text": "You don't see it. It's a totally invisible\ntransition, because you're sitting in state i.",
    "start": "561320",
    "end": "568260"
  },
  {
    "text": "You suddenly have a transition\nback to i that takes 0 time. So you stay in state i.",
    "start": "568260",
    "end": "574120"
  },
  {
    "text": "You can put that transition\nin or you can take it out. It doesn't make any\ndifference. It won't affect the\nprocess at all.",
    "start": "574120",
    "end": "583750"
  },
  {
    "text": "OK. Aside from that issue of these\nself transitions, a sample",
    "start": "583750",
    "end": "590120"
  },
  {
    "text": "path of both x sub n, each of\nthese x sub 0 equals i, x sub",
    "start": "590120",
    "end": "596640"
  },
  {
    "text": "1 equals j. x sub 2 equals k.",
    "start": "596640",
    "end": "601810"
  },
  {
    "text": "A sample path as those plus the\nholding times specifies",
    "start": "601810",
    "end": "607630"
  },
  {
    "text": "what x of t is at each\ninstant of time. And if you know what x of t is\nat each unit of time, that",
    "start": "607630",
    "end": "613840"
  },
  {
    "text": "tells you when the transitions\nare occurring. When you know when the\ntransitions are occurring, you",
    "start": "613840",
    "end": "619100"
  },
  {
    "text": "know what the these u's are. And when you see what the\ntransition is into, you know",
    "start": "619100",
    "end": "624250"
  },
  {
    "text": "what the state is. So the description of a Markov\nprocess in terms of the",
    "start": "624250",
    "end": "630600"
  },
  {
    "text": "process, what we call a process\nx sub t for all t greater than or equal to 0,\nand the set of random",
    "start": "630600",
    "end": "639540"
  },
  {
    "text": "variables, the embedded Markov\nchain, and the holding times are both equivalent\nto each other.",
    "start": "639540",
    "end": "645959"
  },
  {
    "text": "This shouldn't be any surprise\nto you by now, because every process we've talked to,\nwe've talked about.",
    "start": "645960",
    "end": "652220"
  },
  {
    "text": "We've described in\nthe same way. We described the Poisson process\nin multiple ways.",
    "start": "652220",
    "end": "659840"
  },
  {
    "text": "We described Markov chains\nin multiple ways. We described renewal processes\nin multiple ways.",
    "start": "659840",
    "end": "667360"
  },
  {
    "text": "And this is just another\nexample of that. You use whatever description you\nwant to after you've shown",
    "start": "667360",
    "end": "675920"
  },
  {
    "text": "they're all equivalent. So there's really nothing\nnew here.",
    "start": "675920",
    "end": "681090"
  },
  {
    "text": "Or is there?  Who can see what there is about\nthis relationship, which",
    "start": "681090",
    "end": "689590"
  },
  {
    "text": "is different from what we've\njust been talking about? It's using one extra property.",
    "start": "689590",
    "end": "694745"
  },
  {
    "text": " This is not just a consequence\nof this, it also uses",
    "start": "694745",
    "end": "704639"
  },
  {
    "text": "something else. And what else does it use? What I'm doing is saying x of\nt at this instance of time",
    "start": "704640",
    "end": "713210"
  },
  {
    "text": "here is dependent on given\nx of t is some",
    "start": "713210",
    "end": "719900"
  },
  {
    "text": "previous time here. The state here, given the state\nhere is independent of",
    "start": "719900",
    "end": "727310"
  },
  {
    "text": "everything in the past. So what else am I using there? ",
    "start": "727310",
    "end": "735300"
  },
  {
    "text": "I'm using the memory looseness\nof the Poisson process. I'm using the memory\nlooseness of the",
    "start": "735300",
    "end": "741899"
  },
  {
    "text": "exponential random variable. If I'm given the state here,\nand I'm conditioning on the",
    "start": "741900",
    "end": "752399"
  },
  {
    "text": "state here, this is\nan exponential random variable in here.",
    "start": "752400",
    "end": "758010"
  },
  {
    "text": "The time the next transition\nis exponential given this time here. And it doesn't matter\nwhen the previous",
    "start": "758010",
    "end": "765279"
  },
  {
    "text": "transition took place. So if I'm given the state at\nthis time here, the time to",
    "start": "765280",
    "end": "770940"
  },
  {
    "text": "the next transition is an\nexponential random variable, the same distribution as u2.",
    "start": "770940",
    "end": "778510"
  },
  {
    "text": "So what this says is I'm using\nthe initial description in",
    "start": "778510",
    "end": "783950"
  },
  {
    "text": "terms of an embedded Markov\nchain plus holding times, and",
    "start": "783950",
    "end": "790000"
  },
  {
    "text": "I'm adding to that the fact\nthat the holding times are exponential, and therefore\nthey're memory less.",
    "start": "790000",
    "end": "795880"
  },
  {
    "text": "OK, that clear to everybody? It's vitally important\nfor all of this. Because it's hard to do anything\nwith Markov processes",
    "start": "795880",
    "end": "807820"
  },
  {
    "text": "without realizing explicitly\nthat you're using the fact",
    "start": "807820",
    "end": "813100"
  },
  {
    "text": "that these random variables\nare memory less. At the end of this chapter,\nthere's something called semi",
    "start": "813100",
    "end": "818709"
  },
  {
    "text": "Markov processes. The description is that\nsemi Markov processes",
    "start": "818710",
    "end": "823880"
  },
  {
    "text": "are exactly the same. Semi Markov chains are exactly\nthe same as markup processes",
    "start": "823880",
    "end": "830210"
  },
  {
    "text": "except, these holding times\nare not exponential.",
    "start": "830210",
    "end": "836490"
  },
  {
    "text": "They can be anything. And as soon as the holding times\ncan be anything, the",
    "start": "836490",
    "end": "841700"
  },
  {
    "text": "process gets so complicated that\nyou hardly want to talk about it anymore. ",
    "start": "841700",
    "end": "849140"
  },
  {
    "text": "So the fact that we have these\nexponential holding times is really important in terms of\ngetting this condition here,",
    "start": "849140",
    "end": "857600"
  },
  {
    "text": "which lets you talk directly\nabout the process, instead of the embedded Markov chain.",
    "start": "857600",
    "end": "863264"
  },
  {
    "text": " You're going to represent a\nMarkov process by a graph for",
    "start": "863265",
    "end": "871200"
  },
  {
    "start": "864000",
    "end": "962000"
  },
  {
    "text": "the embedded Markov chain, and\nthen you give the rates on top of the nodes.",
    "start": "871200",
    "end": "876320"
  },
  {
    "text": "So if you're in state 0, the\nholding time until you enter",
    "start": "876320",
    "end": "882290"
  },
  {
    "text": "the next state is given as\nsome, the rate of that",
    "start": "882290",
    "end": "887380"
  },
  {
    "text": "exponential is given as new 0. The rate here is given\nas new 1, so forth.",
    "start": "887380",
    "end": "894330"
  },
  {
    "text": "Ultimately, we're usually\ninterested in this process, x of t, t greater than or equal\nto 0, which is the Markov",
    "start": "894330",
    "end": "901740"
  },
  {
    "text": "process itself. x of t is equal to xn for t in\nsub n, between sub n and",
    "start": "901740",
    "end": "911300"
  },
  {
    "text": "s sub n plus 1. What does that mean? Well, it means at this point,\nwe're taking the Markov",
    "start": "911300",
    "end": "918800"
  },
  {
    "text": "process as the fundamental\nthing, and we're describing it in terms of the nth\nstate transition.",
    "start": "918800",
    "end": "927400"
  },
  {
    "text": "But we know that the nth state\ntransition takes place at time s sub n, namely it takes place\nat the sum of all of these",
    "start": "927400",
    "end": "935330"
  },
  {
    "text": "exponential holding times\nup until that point. And that state stays there until\nthe next exponential",
    "start": "935330",
    "end": "942100"
  },
  {
    "text": "holding time. So this really gives you the\nlinkage between the Markov",
    "start": "942100",
    "end": "948829"
  },
  {
    "text": "process in this expression,\nand the markup process in",
    "start": "948830",
    "end": "954310"
  },
  {
    "text": "terms of this graphical\nexpression here with the embedded chain, and the\nexponential holding times.",
    "start": "954310",
    "end": "961339"
  },
  {
    "text": " OK. You can visualize a transition\nfrom one state to another in",
    "start": "961340",
    "end": "969320"
  },
  {
    "start": "962000",
    "end": "1644000"
  },
  {
    "text": "tree very convenient ways. And these are ways that we've, I\nhope we've really learned to",
    "start": "969320",
    "end": "976569"
  },
  {
    "text": "think about from looking\nat Poisson processes.",
    "start": "976570",
    "end": "981690"
  },
  {
    "text": "You can visualize this\ntransition by first using the",
    "start": "981690",
    "end": "986960"
  },
  {
    "text": "next state by these transition\nprobabilities in the embedded",
    "start": "986960",
    "end": "992820"
  },
  {
    "text": "Markov chain. And then you choose a transition\ntime, which is exponential with\nrate new sub i.",
    "start": "992820",
    "end": "1000190"
  },
  {
    "text": "Equivalently, because it's a\nPoisson process, you can choose the-- well, no, because these are\nindependent given the state.",
    "start": "1000190",
    "end": "1008490"
  },
  {
    "text": "You can choose the transition\ntime first, and then you can choose the state, because these\nare independent of each",
    "start": "1008490",
    "end": "1015480"
  },
  {
    "text": "other conditional on the\nstate that you're in. And finally, equivalently, which\nis where the Poisson",
    "start": "1015480",
    "end": "1021970"
  },
  {
    "text": "process comes in, a really neat\nway to think of Poisson processes is to have an\nenormously large number of",
    "start": "1021970",
    "end": "1029939"
  },
  {
    "text": "Poisson processes running\nall the time. There's one Poisson process for\nevery transition in this",
    "start": "1029940",
    "end": "1037030"
  },
  {
    "text": "Markov chain. So you have accountably infinite\nnumber of Poisson processes, which sounds a little\ncomplicated at first.",
    "start": "1037030",
    "end": "1045368"
  },
  {
    "text": "But you visualize a Poisson\nprocess for each state pair i to j, which has a rate q sub ij,\nwhich is the rate at which",
    "start": "1045369",
    "end": "1055480"
  },
  {
    "text": "transitions occur out of\nstate i times p sub ij. This is the rate which, when\nyou're in state i, you will go",
    "start": "1055480",
    "end": "1065250"
  },
  {
    "text": "to state j. And this makes use of all this\nstuff about splitting and",
    "start": "1065250",
    "end": "1071120"
  },
  {
    "text": "combining Poisson processes. If you have a Poisson process\nwhich has rate new sub i and",
    "start": "1071120",
    "end": "1081810"
  },
  {
    "text": "you split it into a number of\nPoisson processes, for each next state you might go to,\nyou're splitting it into",
    "start": "1081810",
    "end": "1088970"
  },
  {
    "text": "Poisson processes of rate new\nsub i times p sub ij.",
    "start": "1088970",
    "end": "1095070"
  },
  {
    "text": "And what's happening there is\nthere's a little switch. The little switch has\nprobabilities p sub ij, and",
    "start": "1095070",
    "end": "1103169"
  },
  {
    "text": "that switch is telling you which\nstate to go to next.",
    "start": "1103170",
    "end": "1110950"
  },
  {
    "text": "All of this is totally\nartificial. And I hope by this time, you are\ncomfortable about looking",
    "start": "1110950",
    "end": "1119200"
  },
  {
    "text": "at physical things in a totally\nartificial way, because that's the magic\nof mathematics.",
    "start": "1119200",
    "end": "1127660"
  },
  {
    "text": "If you didn't have mathematics,\nyou couldn't look at real things in\nartificial ways.",
    "start": "1127660",
    "end": "1133220"
  },
  {
    "text": "And all the science would\nsuddenly disappear. So what we're doing here is\ndefining this Markov process",
    "start": "1133220",
    "end": "1142700"
  },
  {
    "text": "in this artificial way of all\nof these little Poisson processes, and we now know\nhow they all work.",
    "start": "1142700",
    "end": "1149460"
  },
  {
    "text": "When the entry to state i, the\nnext state is the j with an x Poisson arrival, according\nto q sub ij.",
    "start": "1149460",
    "end": "1156789"
  },
  {
    "text": "So all these Poisson processes\nare waiting to have an arrival come out. To have a race, one of\nthem wins, and you",
    "start": "1156790",
    "end": "1164140"
  },
  {
    "text": "go off to that state. OK, question. What's the conditional\ndistribution of u1 given that",
    "start": "1164140",
    "end": "1171900"
  },
  {
    "text": "x0 i, and x1 equals j?",
    "start": "1171900",
    "end": "1177270"
  },
  {
    "text": "And to imagine this, suppose\nthat there are only two places",
    "start": "1177270",
    "end": "1182350"
  },
  {
    "text": "you can go from state 0. You can go into state 1\nwith some very large",
    "start": "1182350",
    "end": "1190560"
  },
  {
    "text": "probability, say 0.999. Or you can go into state 2 with\nsome very, very small",
    "start": "1190560",
    "end": "1197010"
  },
  {
    "text": "probability. And what that means is this\nexponential random variable",
    "start": "1197010",
    "end": "1202669"
  },
  {
    "text": "going from state 0 into state\n2 is a very, very",
    "start": "1202670",
    "end": "1208530"
  },
  {
    "text": "slow, random variable. It has a very small rate. And the exponential random\nvariable going into state 1 is",
    "start": "1208530",
    "end": "1215970"
  },
  {
    "text": "a very, very large\nrandom variable. So you would think that if you\ngo from state 0 the state x2,",
    "start": "1215970",
    "end": "1224799"
  },
  {
    "text": "it means it must take a very\nlong time to get there. Well, that's absolutely wrong.",
    "start": "1224800",
    "end": "1231400"
  },
  {
    "text": " The time that it takes to go\nfrom x0 to x2 is this random",
    "start": "1231400",
    "end": "1242440"
  },
  {
    "text": "variable, u sub i. Where u sub i is the state you\nhappen to be in at this point",
    "start": "1242440",
    "end": "1253559"
  },
  {
    "text": "when you're in-- ",
    "start": "1253560",
    "end": "1260310"
  },
  {
    "text": "x0 is the state that\nwe start in. x0 is a random variable.",
    "start": "1260310",
    "end": "1265510"
  },
  {
    "text": "It has some value i. With this value i, there's an\nexponential random variable",
    "start": "1265510",
    "end": "1271664"
  },
  {
    "text": "that determines how long\nit takes you to get to the next state. This random variable conditional\non x0 equals i is",
    "start": "1271665",
    "end": "1279700"
  },
  {
    "text": "independent of which state\nyou happen to go to. And what that means is that the\nconditional distribution",
    "start": "1279700",
    "end": "1288730"
  },
  {
    "text": "of u1, given x sub 0 is equal\nto i, and x sub 1 equals j.",
    "start": "1288730",
    "end": "1294960"
  },
  {
    "text": "If you've had your ears at all\nopen for the last 10 minutes, it is exponential with rate i.",
    "start": "1294960",
    "end": "1305710"
  },
  {
    "text": "With rate new sub i.  These holding times and the\nnext states you go to are",
    "start": "1305710",
    "end": "1314080"
  },
  {
    "text": "independent of each other,\nconditional on where you happen to be. It's the same thing we saw back\nin Poisson processes.",
    "start": "1314080",
    "end": "1322390"
  },
  {
    "text": "It was confusing as\nhell back then. It is still confusing as hell.",
    "start": "1322390",
    "end": "1328279"
  },
  {
    "text": "If you didn't get it sorted out\nin your mind then, go back and think about it again now,\nand try to get your common",
    "start": "1328280",
    "end": "1336770"
  },
  {
    "text": "sense, which tells you when\nyou go to state 2, it must take a long time to get there,\nbecause that exponential",
    "start": "1336770",
    "end": "1343190"
  },
  {
    "text": "random variable has a very\nlong holding time. And that just isn't true.",
    "start": "1343190",
    "end": "1350020"
  },
  {
    "text": "And it wasn't true when we were\ndealing with a Poisson process, which got\nsplit either.",
    "start": "1350020",
    "end": "1355409"
  },
  {
    "text": "These two things are independent\nof each other. Intuitively, why that is, I\nalmost hesitate to try to say",
    "start": "1355410",
    "end": "1364840"
  },
  {
    "text": "why it is, because it's such\na tricky statement.",
    "start": "1364840",
    "end": "1369950"
  },
  {
    "text": "If you happen to go to state 2\ninstead of to state 1, what's",
    "start": "1369950",
    "end": "1375010"
  },
  {
    "text": "happening is that all of this\ntime that you're waiting to have a state transition, when\nyou finally have this state",
    "start": "1375010",
    "end": "1384299"
  },
  {
    "text": "transition, you then flip a\nswitch to see which state you're going to go to.",
    "start": "1384300",
    "end": "1390350"
  },
  {
    "text": "And the fact that it's taken you\na long time to get there says nothing whatsoever about\nwhat this switch is doing,",
    "start": "1390350",
    "end": "1397679"
  },
  {
    "text": "because that switch is\nindependent of how long it takes you for the switch\nto operate.",
    "start": "1397680",
    "end": "1404360"
  },
  {
    "text": "And I know. It's not entirely intuitive,\nand you just have to beat",
    "start": "1404360",
    "end": "1412720"
  },
  {
    "text": "yourself on the head until\nit becomes intuitive. I've beaten myself on\nthe head until I can",
    "start": "1412720",
    "end": "1418390"
  },
  {
    "text": "hardly think straight. It still isn't intuitive to me,\nbut maybe it will become intuitive to you.",
    "start": "1418390",
    "end": "1424030"
  },
  {
    "text": "I hope so. So anyway, this gives the\nconditional distribution of u1",
    "start": "1424030",
    "end": "1431690"
  },
  {
    "text": "given that x0 is equal to i,\nand x1 is equal to-- no. ",
    "start": "1431690",
    "end": "1438450"
  },
  {
    "text": "This says that the exponential\nrate out of state i is equal",
    "start": "1438450",
    "end": "1443529"
  },
  {
    "text": "to the sum of the exponential\nrates to each of the states we might be going to.",
    "start": "1443530",
    "end": "1448890"
  },
  {
    "text": "We have to go to some\nother state. We have no self transitions as\nfar as we're concerned here.",
    "start": "1448890",
    "end": "1454110"
  },
  {
    "text": "Even if we had self transitions,\nthis formula would still be correct, but\nit's easier to think of it",
    "start": "1454110",
    "end": "1459380"
  },
  {
    "text": "without self transitions. p sub ij, this is the\nswitch probability.",
    "start": "1459380",
    "end": "1465720"
  },
  {
    "text": "It's q sub ij divided\nby new sub i. This is the probability you're\ngoing to go to j given that",
    "start": "1465720",
    "end": "1473360"
  },
  {
    "text": "you were in state i. The matrix of all of these cues\nspecifies the matrix of",
    "start": "1473360",
    "end": "1482400"
  },
  {
    "text": "all of these p's, and\nit specifies new. That's what this formula says.",
    "start": "1482400",
    "end": "1489900"
  },
  {
    "text": "If I know what q is, I know what\nnew is, I know what p is. And we've already said that if\nyou know what p is and you",
    "start": "1489900",
    "end": "1497884"
  },
  {
    "text": "know what new is, you know\nwhat q sub ij is. So these are completely\nequivalent representations of",
    "start": "1497885",
    "end": "1504320"
  },
  {
    "text": "the same thing. You can work with either\none you want to. Sometimes one is useful,\nsometimes the other is useful.",
    "start": "1504320",
    "end": "1512060"
  },
  {
    "text": "If you look at an mm1q,\nmm1q, you remember, is exponential arrivals.",
    "start": "1512060",
    "end": "1518720"
  },
  {
    "text": "Exponential service time. The time of the service is\nindependent of when it",
    "start": "1518720",
    "end": "1523970"
  },
  {
    "text": "happens, or who it happens to. These service times are just\nindividual exponential random",
    "start": "1523970",
    "end": "1529769"
  },
  {
    "text": "variables of some rate mu. The arrivals are the\ninter-arrival intervals are",
    "start": "1529770",
    "end": "1534950"
  },
  {
    "text": "exponential random variables\nof rate lambda.",
    "start": "1534950",
    "end": "1540980"
  },
  {
    "text": "So when you're sitting in state\n0, the only place you can is to state one.",
    "start": "1540980",
    "end": "1546210"
  },
  {
    "text": "You're sitting there, and\nif you're in state 0,",
    "start": "1546210",
    "end": "1552260"
  },
  {
    "text": "the server is idle.  You're waiting for the first\narrival to occur.",
    "start": "1552260",
    "end": "1558880"
  },
  {
    "text": "The next thing that happens has\nto be an arrival because it can't be a service. So the transition here is\nwith probability 1.",
    "start": "1558880",
    "end": "1567429"
  },
  {
    "text": "All these other transitions are\nwith probability lambda divided by lambda plus mu,\nbecause in all of these other",
    "start": "1567430",
    "end": "1574590"
  },
  {
    "text": "states, you can get an arrival\nor a departure. Each of them are exponential\nrandom variables.",
    "start": "1574590",
    "end": "1581400"
  },
  {
    "text": "The switch probability that\nwe're talking about is in lambda over lambda\nplus mu to go up.",
    "start": "1581400",
    "end": "1589300"
  },
  {
    "text": "Mu over lambda plus mu\nto go down for all states other than 0.",
    "start": "1589300",
    "end": "1595210"
  },
  {
    "text": "If you write this, this\nis in terms of the embedded Markov chain.",
    "start": "1595210",
    "end": "1600520"
  },
  {
    "text": "And if you write this in\nterms of the transition probabilities, it\nlooks like this.",
    "start": "1600520",
    "end": "1606760"
  },
  {
    "text": "Which is simpler? Which is more transparent? Well this, really, is\nwhat the mm1q is.",
    "start": "1606760",
    "end": "1613830"
  },
  {
    "text": "That's where we started\nwhen we started talking about mm1q's. ",
    "start": "1613830",
    "end": "1622360"
  },
  {
    "text": "This in this situation is\ncertainly far simpler. You're giving these transition\nprobabilities.",
    "start": "1622360",
    "end": "1628260"
  },
  {
    "text": "But don't forget that we still\nhave this embedded Markov chain in the background.",
    "start": "1628260",
    "end": "1634330"
  },
  {
    "text": "Both these graphs have\nthe same information. Both these graphs have the same\ninformation for every",
    "start": "1634330",
    "end": "1640250"
  },
  {
    "text": "Markov process you want to talk about OK.",
    "start": "1640250",
    "end": "1645740"
  },
  {
    "text": "Let's look at sample time approximations to Markov processes. ",
    "start": "1645740",
    "end": "1653280"
  },
  {
    "text": "And we already did it\nin the last chapter. We just didn't talk about\nit quite so much.",
    "start": "1653280",
    "end": "1658950"
  },
  {
    "text": "We quantized time to increments\nof delta. We viewed all Poisson processes\nin a Markov process.",
    "start": "1658950",
    "end": "1667549"
  },
  {
    "text": "Remember, we can view all\nof these transitions as independent Poisson processes\nall running",
    "start": "1667550",
    "end": "1673309"
  },
  {
    "text": "away at the same time. We can view all of these Poisson\nprocesses as Bernoulli",
    "start": "1673310",
    "end": "1679330"
  },
  {
    "text": "processes with probability of\na transition from i to j in",
    "start": "1679330",
    "end": "1685455"
  },
  {
    "text": "the increment delta, given as\na delta times qij, to first",
    "start": "1685455",
    "end": "1690929"
  },
  {
    "text": "order in delta. So we can take this Markov\nprocess, turn it into a rather",
    "start": "1690930",
    "end": "1697610"
  },
  {
    "text": "strange kind of Bernoulli\nprocess. For the M/M/1 queue, all that's\ndoing is turning into a",
    "start": "1697610",
    "end": "1704310"
  },
  {
    "text": "sample time, M/M/1 process. And we can sort of think\nthe same way about",
    "start": "1704310",
    "end": "1709679"
  },
  {
    "text": "general Markov processes. We'll see when we can\nand when we can't. Since shrinking Bernoulli goes\nto Poisson, we would",
    "start": "1709680",
    "end": "1717840"
  },
  {
    "text": "conjecture the limiting Markov\nchain as delta goes to 0 goes through a Markov process.",
    "start": "1717840",
    "end": "1723710"
  },
  {
    "text": "In a sense that X of t is approximately equal to X prime.",
    "start": "1723710",
    "end": "1728940"
  },
  {
    "text": "This is X prime as in\nthe Bernoulli domain at delta times n.",
    "start": "1728940",
    "end": "1735340"
  },
  {
    "text": " You have to put self-transition\ninto a sample",
    "start": "1735340",
    "end": "1740909"
  },
  {
    "text": "time approximation. Because if you have a very small\ndelta, there aren't big",
    "start": "1740910",
    "end": "1746280"
  },
  {
    "text": "enough transition probabilities\ngoing out of the chain to fill up the\nprobability space.",
    "start": "1746280",
    "end": "1752880"
  },
  {
    "text": "So in most transition, you're\ngoing to just have a self-transition. So you need a self-transition,\nwhich is 1 minus delta times",
    "start": "1752880",
    "end": "1761120"
  },
  {
    "text": "nu sub i, and these transitions\nto other states, which are delta times\nq sub ij.",
    "start": "1761120",
    "end": "1768350"
  },
  {
    "text": "This has the advantage that if\nyou believe this, you can",
    "start": "1768350",
    "end": "1774460"
  },
  {
    "text": "ignore everything we're saying\nabout Poisson processes because you already\nknow all of it.",
    "start": "1774460",
    "end": "1779950"
  },
  {
    "text": "We already talked about\nsample time processes. You can do this for any\nold process almost.",
    "start": "1779950",
    "end": "1788720"
  },
  {
    "text": "And when you do this for any old\nprocess, you're turning it into a Markov change instead\nof a Markov process.",
    "start": "1788720",
    "end": "1795860"
  },
  {
    "text": "This is the same argument you\ntried to use when you were a senior in high school or\nfreshman in college when you",
    "start": "1795860",
    "end": "1802500"
  },
  {
    "text": "said, I don't have to learn\ncalculus, because all it is is just taking increments\nto be very small and",
    "start": "1802500",
    "end": "1810179"
  },
  {
    "text": "looking at a limit. So I will just ignore\nall that stuff. It didn't work there.",
    "start": "1810180",
    "end": "1815940"
  },
  {
    "text": "It doesn't work here.  But it's a good thing to go\nevery time you get confused,",
    "start": "1815940",
    "end": "1824629"
  },
  {
    "text": "because this you can sort\nout for yourself. There is one problem here.",
    "start": "1824630",
    "end": "1830149"
  },
  {
    "text": "When you start making shrieking\ndelta more and more,",
    "start": "1830150",
    "end": "1836410"
  },
  {
    "text": "if you want to get a sample time\napproximation, delta has to be smaller than 1 over the\nmaximum of the nu sub i's.",
    "start": "1836410",
    "end": "1845659"
  },
  {
    "text": "If it's not smaller than the\nmaximum of the nu sub i's, the self-transition probability\nhere is",
    "start": "1845660",
    "end": "1854220"
  },
  {
    "text": "unfortunately negative. And we don't like negative\nprobabilities.",
    "start": "1854220",
    "end": "1860370"
  },
  {
    "text": "So you can't do that. If you have a Markov process,\nhas a countably infinite",
    "start": "1860370",
    "end": "1865909"
  },
  {
    "text": "number of states, each of these\nnu sub i's are positive. But they can approach\n0 as a limit.",
    "start": "1865910",
    "end": "1872899"
  },
  {
    "text": "As if they approach 0 as a\nlimit, you cannot describe a sample time Markov chain to go\nwith the Markov process.",
    "start": "1872900",
    "end": "1882520"
  },
  {
    "text": "All you can do is truncate\nthe chain also and then see what happens. And that's often a good\nway to do it.",
    "start": "1882520",
    "end": "1889366"
  },
  {
    "text": "OK, so we can always do this\nsample time approximation. ",
    "start": "1889366",
    "end": "1895030"
  },
  {
    "text": "What is nice about the sample\ntime approximation is that we",
    "start": "1895030",
    "end": "1902640"
  },
  {
    "start": "1899000",
    "end": "2318000"
  },
  {
    "text": "will find it in general, if you\ncould use the sample time approximation, it always gives\nyou the exact steady state",
    "start": "1902640",
    "end": "1910500"
  },
  {
    "text": "probabilities. No matter how crude you are in\nthis approximation, you always",
    "start": "1910500",
    "end": "1916009"
  },
  {
    "text": "wind up with the exact rate\nvalues when you're all done. I don't know why.",
    "start": "1916010",
    "end": "1921070"
  },
  {
    "text": "We will essentially prove\ntoday that that happens. But that's a nice thing.",
    "start": "1921070",
    "end": "1926750"
  },
  {
    "text": "But it doesn't work with the nu\nsub i's approach 0, because then you can't get\na sample time approximation to start with.",
    "start": "1926750",
    "end": "1934090"
  },
  {
    "text": "OK, let's look at the embedded\nchain model in the sample time model of M/M/1 queue.",
    "start": "1934090",
    "end": "1940315"
  },
  {
    "text": "I hate to keep coming back\nto the M/M/1 queue. But for Markov processes,\nthey're all so similar to each",
    "start": "1940315",
    "end": "1947340"
  },
  {
    "text": "other that you might as well\nget very familiar with one",
    "start": "1947340",
    "end": "1952779"
  },
  {
    "text": "particular model of them,\nbecause that one particular model tells you most of the\ndistinctions that you have to",
    "start": "1952780",
    "end": "1959840"
  },
  {
    "text": "be careful about.  Let's see. What is this?",
    "start": "1959840",
    "end": "1965170"
  },
  {
    "text": "This is the embedded chain\nmodel that we've talked about before. When you're in state 0,\nthe only place you can",
    "start": "1965170",
    "end": "1971210"
  },
  {
    "text": "go is to state 1. When you're in state 1, you\ncan go down with some",
    "start": "1971210",
    "end": "1977730"
  },
  {
    "text": "probability. You can go up with\nsome probability. And since these probabilities\nhave to add up to 1, it's mu",
    "start": "1977730",
    "end": "1985760"
  },
  {
    "text": "over lambda plus mu and lambda\nover lambda plus mu, and the same thing forever after.",
    "start": "1985760",
    "end": "1993309"
  },
  {
    "text": "If we're dealing with the sample\ntime model, what we wind up with is we start\nout with qij,",
    "start": "1993310",
    "end": "2002750"
  },
  {
    "text": "which is lambda here.  The time it takes to get from\nstate 0 to make a transition,",
    "start": "2002750",
    "end": "2012070"
  },
  {
    "text": "the only place you can make a\ntransition to is state 1. You make those transitions\nat rate lambda.",
    "start": "2012070",
    "end": "2018730"
  },
  {
    "text": "So the sample time model has\nthis transition and discrete time with probability lambda\ndelta, this transition with",
    "start": "2018730",
    "end": "2027299"
  },
  {
    "text": "probability mu delta\nand so forth up. You need these self-transitions\nin order to",
    "start": "2027300",
    "end": "2034380"
  },
  {
    "text": "make things add up correctly. The steady state for the\nembedded chain is pi sub 0",
    "start": "2034380",
    "end": "2042080"
  },
  {
    "text": "equals 1 minus rho over 2. How do I know that?",
    "start": "2042080",
    "end": "2047970"
  },
  {
    "text": "You just have to use\nalgebra for that. But it's very easy. ",
    "start": "2047970",
    "end": "2064850"
  },
  {
    "text": "I'm going to have to get\nthree of these things. OK, any time you have a\nbirth-death chain, you can",
    "start": "2064850",
    "end": "2071879"
  },
  {
    "text": "find the steady state\nprobabilities. ",
    "start": "2071880",
    "end": "2094030"
  },
  {
    "text": "The probability of going this\nway is equal to the probability of going this way. If you add in the probability\nof the steady state that",
    "start": "2094030",
    "end": "2102195"
  },
  {
    "text": "you're concerned with, steady\nstate transition this way, the same as the probability\nof a steady state",
    "start": "2102195",
    "end": "2107300"
  },
  {
    "text": "transition this way. And you remember, the reason for\nthis is in a birth-death chain, the total number of\ntransitions from here to here",
    "start": "2107300",
    "end": "2116450"
  },
  {
    "text": "has to be within 1 of the number\nof transitions from here to there.",
    "start": "2116450",
    "end": "2121650"
  },
  {
    "text": "So that if steady state\nmeans anything-- and if these of long-term sample\nspace probabilities",
    "start": "2121650",
    "end": "2130440"
  },
  {
    "text": "with probability 1\nmean anything-- this has to be true. So when you do that, this\nis what you get here.",
    "start": "2130440",
    "end": "2138600"
  },
  {
    "text": "This is a strange 1\nminus rho over 2. It's strange because of this\nstrange probability one here,",
    "start": "2138600",
    "end": "2145660"
  },
  {
    "text": "and this strange probability mu\nover lambda plus mu here. And otherwise, everything is\nsymmetric, so it looks the",
    "start": "2145660",
    "end": "2152530"
  },
  {
    "text": "same as this one here. For this one, the steady state\nfor the sample time doesn't",
    "start": "2152530",
    "end": "2158730"
  },
  {
    "text": "depend on delta. And it's pi sub i prime equals 1\nminus rho times rho to the i",
    "start": "2158730",
    "end": "2164589"
  },
  {
    "text": "where rho equals\nlambda over mu. This is what we did before. And what we found is since\ntransitions this way have to",
    "start": "2164590",
    "end": "2173450"
  },
  {
    "text": "equal transitions this way,\nthese self-transitions don't",
    "start": "2173450",
    "end": "2178690"
  },
  {
    "text": "make any difference here. And you get the same answer\nno matter what delta is.",
    "start": "2178690",
    "end": "2185200"
  },
  {
    "text": "And therefore you have pretty\nmuch a conviction, which can't",
    "start": "2185200",
    "end": "2191070"
  },
  {
    "text": "totally rely on, that you can go\nto the limit as delta goes to 0 and find out what is going\non in the actual Markov",
    "start": "2191070",
    "end": "2198800"
  },
  {
    "text": "process itself. You'll be very surprised with\nthis result if this were not",
    "start": "2198800",
    "end": "2205900"
  },
  {
    "text": "the result for steady state\nprobabilities in some sense for the Markov process.",
    "start": "2205900",
    "end": "2212860"
  },
  {
    "text": "However, the embedded chain\nprobabilities and these",
    "start": "2212860",
    "end": "2219790"
  },
  {
    "text": "probabilities down here\nare not the same. What's the difference\nbetween them?",
    "start": "2219790",
    "end": "2227730"
  },
  {
    "text": "For the embedded chain, what\nyou're talking about is the ratio of transitions\nthat go from one",
    "start": "2227730",
    "end": "2235210"
  },
  {
    "text": "state to another state. When you're dealing with the\nprocess, what you're talking",
    "start": "2235210",
    "end": "2241130"
  },
  {
    "text": "about is the probability that\nyou will be in one state.",
    "start": "2241130",
    "end": "2246250"
  },
  {
    "text": "If when you get in one state\nyou stay there for a long time, because the rate of\ntransitions out of that state",
    "start": "2246250",
    "end": "2256770"
  },
  {
    "text": "is very small, so you're going\nto stay there for a long time. That enhances the probability\nof being in that state.",
    "start": "2256770",
    "end": "2263940"
  },
  {
    "text": "You see that right here,\nbecause pi 0 is 1 minus rho over 2.",
    "start": "2263940",
    "end": "2270410"
  },
  {
    "text": "And pi 0 prime is 1 minus rho.",
    "start": "2270410",
    "end": "2278059"
  },
  {
    "text": "It's bigger. And it's bigger because you're\ngoing to stay there longer, because the rate of getting out\nof there is not as big as",
    "start": "2278060",
    "end": "2284830"
  },
  {
    "text": "it was before. So the steady state\nprobabilities in the embedded chain and the steady state\nprobabilities and the sample",
    "start": "2284830",
    "end": "2295000"
  },
  {
    "text": "time approximation\nare different. And the steady state\nprobabilities and the sample",
    "start": "2295000",
    "end": "2300410"
  },
  {
    "text": "time approximation are the same,\nwhen you go to the limit of infinitely fine\nsample time.",
    "start": "2300410",
    "end": "2308080"
  },
  {
    "text": "Now what we have to do is go\nback and look at renewal theory and all those that and\nactually convince ourselves",
    "start": "2308080",
    "end": "2315339"
  },
  {
    "text": "that this works.  OK, so here we have renewals\nfor Markov processes.",
    "start": "2315340",
    "end": "2323300"
  },
  {
    "start": "2318000",
    "end": "2529000"
  },
  {
    "text": " And what have we done so far? We've been looking at\nthe Poisson process.",
    "start": "2323300",
    "end": "2330400"
  },
  {
    "text": "We've been looking\nat Markov chains. And we've been trying to refer\nto this new kind of process.",
    "start": "2330400",
    "end": "2337180"
  },
  {
    "text": "Now we bring in the last\nactor, renewal theory. And as usual, Poisson processes\ngives you the easy",
    "start": "2337180",
    "end": "2346170"
  },
  {
    "text": "way to look at a problem. Markov chains gives you a way\nto look at the problem, when you'd rather write equations\nand think about it.",
    "start": "2346170",
    "end": "2353680"
  },
  {
    "text": "And we renewal theory gives\nyou the way to look at the problem when you really are a\nglutton for punishment, and",
    "start": "2353680",
    "end": "2360029"
  },
  {
    "text": "you want to spend a lot of\ntime thinking about it. And you don't want to write any\nequations, or you don't",
    "start": "2360030",
    "end": "2365040"
  },
  {
    "text": "want to write many equation. OK, an irreducible Markov\nprocess is a Markov process",
    "start": "2365040",
    "end": "2371240"
  },
  {
    "text": "for which the embedded Markov\nchain is irreducible. Remember that an irreducible a\nMarkov chain is one where all",
    "start": "2371240",
    "end": "2378840"
  },
  {
    "text": "states are in the same class. We saw that irreducible Markov\nchains when we had a countably",
    "start": "2378840",
    "end": "2387970"
  },
  {
    "text": "infinite number of states, that\nthey could be transient, the state simply wanders\noff with high",
    "start": "2387970",
    "end": "2393300"
  },
  {
    "text": "probability, never to return. If you have an M/M/1 queue,\nand the expect the service",
    "start": "2393300",
    "end": "2398670"
  },
  {
    "text": "time is bigger than the\nexpected time between",
    "start": "2398670",
    "end": "2404339"
  },
  {
    "text": "arrivals, then gradually\nthe queue builds up. The queue keeps getting longer\nand longer as time goes on.",
    "start": "2404340",
    "end": "2412480"
  },
  {
    "text": "There isn't any steady state. Looked at another way, the\nsteady state probabilities are always 0, if you want to\njust calculate them.",
    "start": "2412480",
    "end": "2421510"
  },
  {
    "text": "So we're going to see the\nirreducible Markov processes",
    "start": "2421510",
    "end": "2426700"
  },
  {
    "text": "can have even more bizarre\nbehavior than these Markov chains can.",
    "start": "2426700",
    "end": "2432220"
  },
  {
    "text": "And part of that more bizarre\nbehavior is infinitely many transitions in a finite time.",
    "start": "2432220",
    "end": "2440790"
  },
  {
    "text": "I mean, how do you talk about\nsteady state when you have an infinite number of transitions\nand a finite time?",
    "start": "2440790",
    "end": "2448680"
  },
  {
    "text": "I mean, essentially, the\nMarkov process is blowing up on you. Transitions get more\nand more frequent.",
    "start": "2448680",
    "end": "2455900"
  },
  {
    "text": "They go off to infinity. What do you do after that? I don't know. I can write these equations.",
    "start": "2455900",
    "end": "2462010"
  },
  {
    "text": "I can solve these equations. But they don't mean anything. In other words sometimes,\ntalking about steady state, we",
    "start": "2462010",
    "end": "2470170"
  },
  {
    "text": "usually write equations\nfor steady state. But as we saw with countable\nstate Markov chains, steady",
    "start": "2470170",
    "end": "2477720"
  },
  {
    "text": "state doesn't always\nexist there. There it evidenced itself with\nsteady state probabilities",
    "start": "2477720",
    "end": "2483520"
  },
  {
    "text": "that were equal to 0, which\nsaid that as time went on, things just got very diffused\nor things wandered off to",
    "start": "2483520",
    "end": "2490420"
  },
  {
    "text": "infinity or something\nlike that. Here it's this much worse thing,\nwhere in fact you get",
    "start": "2490420",
    "end": "2497170"
  },
  {
    "text": "an infinite number of\ntransitions very fast. And we'll see how that happens\na little later.",
    "start": "2497170",
    "end": "2505000"
  },
  {
    "text": "You might have a transition\nrate which goes down to 0. The process is chugging along\nand gets slower, and slower,",
    "start": "2505000",
    "end": "2513030"
  },
  {
    "text": "and slower, and pretty soon\nnothing happens anymore. Well, always something happens\nif you wait long enough, but",
    "start": "2513030",
    "end": "2521250"
  },
  {
    "text": "as you wait longer and\nlonger, things happen more and more slowly.",
    "start": "2521250",
    "end": "2527520"
  },
  {
    "text": "So we'll see all of these\nthings, and we'll see how this comes out. OK, let's review briefly\naccountable",
    "start": "2527520",
    "end": "2534650"
  },
  {
    "start": "2529000",
    "end": "3059000"
  },
  {
    "text": "state Markov chains-- an irreducible, that means\neverything can talk to",
    "start": "2534650",
    "end": "2539730"
  },
  {
    "text": "everything else; is positive\nrecurrent if and only if the steady state equations, pi sub\nj equals the sum of pi",
    "start": "2539730",
    "end": "2550110"
  },
  {
    "text": "sub i, p sub ij. Remember what this is. ",
    "start": "2550110",
    "end": "2556310"
  },
  {
    "text": "If you're in steady state, the\nprobability of being in a state j is supposed\nto be pi sub j.",
    "start": "2556310",
    "end": "2562730"
  },
  {
    "text": "The probability of being in a\nstate is supposed to be equal then to the sum of the\nprobabilities of being in",
    "start": "2562730",
    "end": "2569840"
  },
  {
    "text": "another state and going\nto that state. That's the way it has to\nbe if you're going to have a steady state.",
    "start": "2569840",
    "end": "2575610"
  },
  {
    "text": "So this is necessary. The pi sub j's have to be\ngreater than or equal to 0. And the sum of the pi sub\nj's is equal to 1.",
    "start": "2575610",
    "end": "2583410"
  },
  {
    "text": "It has a solution. If this has a solution, it's\nunique, and if pi sub i is",
    "start": "2583410",
    "end": "2588970"
  },
  {
    "text": "greater than 0 for all i, if\nit's positive recurrent.",
    "start": "2588970",
    "end": "2595680"
  },
  {
    "text": "We saw that if it wasn't\npositive recurrent, other things could happen. Also the number of visits, n\nsub ij of n, remember in a",
    "start": "2595680",
    "end": "2603950"
  },
  {
    "text": "Markov chain, what we talked\nabout when we used renewal",
    "start": "2603950",
    "end": "2609220"
  },
  {
    "text": "theory was the number of visits\nover a particular number transitions\nfrom i to j.",
    "start": "2609220",
    "end": "2619010"
  },
  {
    "text": "n sub ij of n is the number\nof times we hit j's",
    "start": "2619010",
    "end": "2625390"
  },
  {
    "text": "in the first n trials. ",
    "start": "2625390",
    "end": "2631349"
  },
  {
    "text": "I always do this. Please take that n sub ij of n\nand write 1 over n times n sub",
    "start": "2631350",
    "end": "2639815"
  },
  {
    "text": "ij of n is equal to pi j. You all know that. I know it too.",
    "start": "2639815",
    "end": "2646140"
  },
  {
    "text": "I don't know why it always gets\nleft off of my slides. Now, we guessed for a Markov\nprocess the fraction of time",
    "start": "2646140",
    "end": "2654190"
  },
  {
    "text": "in state j should be p sub j\nequals pi sub j over a nu sub",
    "start": "2654190",
    "end": "2659337"
  },
  {
    "text": "j divided by the sum over i\nof pi sub i over nu sub i.",
    "start": "2659337",
    "end": "2665440"
  },
  {
    "text": "Perhaps I should say I guessed\nthat because I already know it. I want to indicate to you why\nif you didn't know anything",
    "start": "2665440",
    "end": "2675270"
  },
  {
    "text": "and if you weren't suspicious\nby this time, you would make that guess, OK?",
    "start": "2675270",
    "end": "2681450"
  },
  {
    "text": "We had this embedded\nMarkov chain. Over a very long period\nof time, the number of",
    "start": "2681450",
    "end": "2687480"
  },
  {
    "text": "transitions into state i is\ngoing to be the number of",
    "start": "2687480",
    "end": "2693570"
  },
  {
    "text": "transitions into state i\ndivided by n is going to be pi sub i.",
    "start": "2693570",
    "end": "2699460"
  },
  {
    "text": "That's what this equation here\nsays, or what it would say if I had written it correctly.",
    "start": "2699460",
    "end": "2705829"
  },
  {
    "text": "Now, each time we get to pi\nsub i, we're going to stay there for a while.",
    "start": "2705830",
    "end": "2711220"
  },
  {
    "text": "The holding time in state\ni is proportional to",
    "start": "2711220",
    "end": "2716270"
  },
  {
    "text": "1 over nu sub i. The rate of the next transition\nis nu sub i.",
    "start": "2716270",
    "end": "2722230"
  },
  {
    "text": "So the expected holding time is\ngoing to be 1 over nu sub i, which says that the fraction\nof time that we're",
    "start": "2722230",
    "end": "2731150"
  },
  {
    "text": "actually in state i should be\nproportional to the number of",
    "start": "2731150",
    "end": "2738510"
  },
  {
    "text": "times we go into state j times\nthe expected holding time in state j.",
    "start": "2738510",
    "end": "2744930"
  },
  {
    "text": "Now when you write p sub j\nequals pi sub j over nu sub j, you have a constant there\nwhich is missing.",
    "start": "2744930",
    "end": "2751740"
  },
  {
    "text": "Because what we're doing is\nwe're amortizing this over some long period of time.",
    "start": "2751740",
    "end": "2757420"
  },
  {
    "text": "And we don't know what the\nconstant of amortization is. But these probability\nshould add up to 1.",
    "start": "2757420",
    "end": "2764120"
  },
  {
    "text": "If life is at all fair to us,\nthe fraction of time that we spent in each state j should be\nsome number which adds up",
    "start": "2764120",
    "end": "2773030"
  },
  {
    "text": "to 1 as we sum over j. So this is just a normalization\nfactor that you",
    "start": "2773030",
    "end": "2778230"
  },
  {
    "text": "need to make the p sub\nj's sum up to 1. Now what this means physically,\nand why it appears",
    "start": "2778230",
    "end": "2785799"
  },
  {
    "text": "here, is something we have to go\nthrough some more analysis. But this is what we\nwould guess if we",
    "start": "2785800",
    "end": "2790880"
  },
  {
    "text": "didn't know any better. And in fact, it's pretty\nmuch true. It's not always true, but\nit's pretty much true.",
    "start": "2790880",
    "end": "2796960"
  },
  {
    "text": " So now let's use renewal\ntheory to actually see",
    "start": "2796960",
    "end": "2802200"
  },
  {
    "text": "what's going on. And here's where we need a\nlittle more notation even.",
    "start": "2802200",
    "end": "2807440"
  },
  {
    "text": "Let n sub i of t be the number\nof transitions between 0 and t",
    "start": "2807440",
    "end": "2814140"
  },
  {
    "text": "for a Markov process starting\nin state i. I can't talk about the number of\ntransitions if I don't say",
    "start": "2814140",
    "end": "2821140"
  },
  {
    "text": "what state we start in, because\nthen I don't really have a random variable. I could say let's start and\nsteady state, and that seems",
    "start": "2821140",
    "end": "2830110"
  },
  {
    "text": "very, very appealing. I've tried to do that many\ntimes, because it would simplify all these theorems.",
    "start": "2830110",
    "end": "2837470"
  },
  {
    "text": "And it just doesn't\nwork, believe me. So let's take the extra pain\nof saying let's start",
    "start": "2837470",
    "end": "2844840"
  },
  {
    "text": "in some state i. We don't know what it is, but\nwe'll just assume there is some state.",
    "start": "2844840",
    "end": "2851849"
  },
  {
    "text": "And the theorem says that the\nlimit of M sub i of t is equal to infinity.",
    "start": "2851850",
    "end": "2857619"
  },
  {
    "text": "Here I don't have a 1 over\nt in front of it. I've written incorrectly. And this is a very technical\ntheorem.",
    "start": "2857620",
    "end": "2865210"
  },
  {
    "text": "We proved the same kind of\ntechnical theorem when we were talking about Markov chains,\nif you remember.",
    "start": "2865210",
    "end": "2870859"
  },
  {
    "text": "We were talking about\nMarkov chains. We said that in some sense, an\ninfinite number of transitions",
    "start": "2870860",
    "end": "2879910"
  },
  {
    "text": "into each one of the states\nhad to occur. The same kind of proof\nis the proof here.",
    "start": "2879910",
    "end": "2885560"
  },
  {
    "text": "It had the same kind of proof\nwhen we were talking about renewal theory. What is going on is given any\nstate, given the state the",
    "start": "2885560",
    "end": "2894670"
  },
  {
    "text": "transition has to occur within\nfinite time, because there some exponential holding\ntime there.",
    "start": "2894670",
    "end": "2901620"
  },
  {
    "text": "So the expected amount of time\nfor the next transition is 1",
    "start": "2901620",
    "end": "2906810"
  },
  {
    "text": "over nu sub i. And that's finite for every\ni in the chain.",
    "start": "2906810",
    "end": "2912920"
  },
  {
    "text": "And therefore, as you go from\none state to another, as the frog those jumping from one lily\npad to another, and each",
    "start": "2912920",
    "end": "2921430"
  },
  {
    "text": "lily pad that it jumps on\nthere's some expected time before it moves, and therefore\nassuming that it keeps moving",
    "start": "2921430",
    "end": "2928410"
  },
  {
    "text": "forever and doesn't die, which\nis what we assume with these",
    "start": "2928410",
    "end": "2933500"
  },
  {
    "text": "Markov chains, it will\neventually go through an infinite number of steps.",
    "start": "2933500",
    "end": "2940220"
  },
  {
    "text": "And the proof of that\nis in the text. But it's exactly the same proof\nas you've seen several",
    "start": "2940220",
    "end": "2946190"
  },
  {
    "text": "times before for renewal process\nin countable state Markov chains.",
    "start": "2946190",
    "end": "2951930"
  },
  {
    "text": "Next theorem is to say let M sub\nij of t be the number of",
    "start": "2951930",
    "end": "2959160"
  },
  {
    "text": "transitions to j, starting\nin state i. We can't get rid of the\nstarting state.",
    "start": "2959160",
    "end": "2966680"
  },
  {
    "text": "Somehow we have to\nkeep it in there. We have some confidence that\nit's not important, that it",
    "start": "2966680",
    "end": "2973010"
  },
  {
    "text": "shouldn't be there. And we're going to see it\ndisappear very shortly. But we have to keep it there\nfor the time being.",
    "start": "2973010",
    "end": "2979970"
  },
  {
    "text": "So if the embedded chain is\nrecurrent, then n sub ij of t",
    "start": "2979970",
    "end": "2985800"
  },
  {
    "text": "is a delayed renewal process. And we sort of know that.",
    "start": "2985800",
    "end": "2991180"
  },
  {
    "text": "Essentially, transitions\nkeep occurring. So renewals in the state\nj must keep occurring.",
    "start": "2991180",
    "end": "2997799"
  },
  {
    "text": "And therefore, any time you go\nto state j, the amount of time that it takes until you get\nthere again, is finite.",
    "start": "2997800",
    "end": "3007079"
  },
  {
    "text": "We're not selling it to expect\nat time is finite. Expect time might be infinite. We'll see lots of cases\nwhere it is.",
    "start": "3007080",
    "end": "3013850"
  },
  {
    "text": "But you've got to get\nthere eventually. That's the same kind of thing we\nsaw for renewal theory when",
    "start": "3013850",
    "end": "3022190"
  },
  {
    "text": "we had renewals and the things\nthat could happen eventually they did happen.",
    "start": "3022190",
    "end": "3028910"
  },
  {
    "text": "I don't know whether any of\nyou are old enough to have heard about Murphy's Law.",
    "start": "3028910",
    "end": "3034620"
  },
  {
    "text": "Murphy was an Irish\nAmerican to whom awful things kept happening.",
    "start": "3034620",
    "end": "3040080"
  },
  {
    "text": "And Murphy's Law says that\nif something awful can happen, it will.",
    "start": "3040080",
    "end": "3045160"
  },
  {
    "text": "This says if this can happen,\neventually it will happen. It doesn't say it will\nhappen immediately.",
    "start": "3045160",
    "end": "3050740"
  },
  {
    "text": "But it says it will\nhappen eventually. You can think of this as\nMurphy's Law, if you want to,",
    "start": "3050740",
    "end": "3057340"
  },
  {
    "text": "if you're familiar with that.  So we want to talk about steady\nstate for irreducible",
    "start": "3057340",
    "end": "3064710"
  },
  {
    "text": "Markov processes. Now, let p sub j of i be the\ntime average fraction of time",
    "start": "3064710",
    "end": "3072300"
  },
  {
    "text": "in state j for the delayed\nrenewal process. Remember we talked about p sub\nj in terms of these sample",
    "start": "3072300",
    "end": "3079910"
  },
  {
    "text": "time Markov change. And we talked about them a\nlittle bit in terms of imagining how long you would\nstay in state j if you were in",
    "start": "3079910",
    "end": "3087570"
  },
  {
    "text": "some kind of steady state. Here we want to talk\nabout p sub j of i.",
    "start": "3087570",
    "end": "3092779"
  },
  {
    "text": " In terms of strong law of\nlarge numbers kinds of results, we want to look at the\nsample path average and",
    "start": "3092780",
    "end": "3101010"
  },
  {
    "text": "see the convergence with\nprobability one. OK, so p sub j of i is a time\naverage fraction of time in",
    "start": "3101010",
    "end": "3110329"
  },
  {
    "text": "state j for the delayed\nrenewal process. Remember we said that delay\nrenewal processes were really",
    "start": "3110330",
    "end": "3117750"
  },
  {
    "text": "the same as renewal processes. You just had this first renewal,\nwhich really didn't",
    "start": "3117750",
    "end": "3122850"
  },
  {
    "text": "make any difference. And so p sub j of i is going\nto be the limit as t",
    "start": "3122850",
    "end": "3129400"
  },
  {
    "text": "approaches infinity of the\nreward that we pick up forever",
    "start": "3129400",
    "end": "3134869"
  },
  {
    "text": "of being in state j. You get one unit of reward\nwhenever you're in state j, 0",
    "start": "3134870",
    "end": "3139900"
  },
  {
    "text": "units when you're\nanywhere else. So this is the time average\nfraction of time",
    "start": "3139900",
    "end": "3145520"
  },
  {
    "text": "you're in state j. This is divided by t. And the assumption is\nyou start in time i.",
    "start": "3145520",
    "end": "3151940"
  },
  {
    "text": "So that affects this\na little bit. The picture here says whenever\nyou go to state j, you're",
    "start": "3151940",
    "end": "3158839"
  },
  {
    "text": "going to stay in state j for\nsome holding time U sub n.",
    "start": "3158840",
    "end": "3167100"
  },
  {
    "text": "Then you go back to 0 reward\nuntil the next time you went to state j.",
    "start": "3167100",
    "end": "3172980"
  },
  {
    "text": "Then you jump up\nto reward of 1. You stay there for your holding\ntime until you get",
    "start": "3172980",
    "end": "3178000"
  },
  {
    "text": "into some other state, a\nand that keeps going on forever and ever.",
    "start": "3178000",
    "end": "3184260"
  },
  {
    "text": "What does the delayed renewal\nreward theorem say? ",
    "start": "3184260",
    "end": "3196600"
  },
  {
    "text": "It says that the expected reward\nover time is going to",
    "start": "3196600",
    "end": "3202560"
  },
  {
    "text": "be the expect to reward in one\nrenewal divided by the expected length of\nthe renewal path.",
    "start": "3202560",
    "end": "3209450"
  },
  {
    "text": "It says it's going to be\nexpected value of U sub n divided by the expected time\nthat you stay in state j.",
    "start": "3209450",
    "end": "3219130"
  },
  {
    "text": "So it's 1 over nu sub j times\nthe expected time",
    "start": "3219130",
    "end": "3225490"
  },
  {
    "text": "you're in a state j.  That's a really neat result\nthat connects this steady",
    "start": "3225490",
    "end": "3232980"
  },
  {
    "text": "state probability. Excuse my impolite computer.",
    "start": "3232980",
    "end": "3239720"
  },
  {
    "text": "This relates to fraction of time\nyou're in state i to the expected delay in state j.",
    "start": "3239720",
    "end": "3246570"
  },
  {
    "text": "It's one of those maddening\nthings where you say that's great, but I don't know how to\nfind either of those things.",
    "start": "3246570",
    "end": "3253290"
  },
  {
    "text": "So we go on. We will find them. And what we will find\nis W sub j.",
    "start": "3253290",
    "end": "3261180"
  },
  {
    "text": "If we can find W sub j, we'll\nalso know p sub j.",
    "start": "3261180",
    "end": "3266780"
  },
  {
    "text": "M sub ij of t is delayed\nrenewal process. The strong law for renewal says\nthe limit as t approaches",
    "start": "3266780",
    "end": "3274590"
  },
  {
    "text": "infinity of Mi j of t over t is\n1 over this waiting time.",
    "start": "3274590",
    "end": "3281950"
  },
  {
    "text": "This is the number of\nrenewals you have as t goes to infinity. This is equal to 1 over the\nexpected length of that",
    "start": "3281950",
    "end": "3289520"
  },
  {
    "text": "renewal period. Great. So we take the limit as\nt goes to infinity.",
    "start": "3289520",
    "end": "3295780"
  },
  {
    "text": "Of mij of t over mi of t.",
    "start": "3295780",
    "end": "3301260"
  },
  {
    "text": "This is the number of\ntransitions overall up to time",
    "start": "3301260",
    "end": "3306290"
  },
  {
    "text": "t starting in state i. This is the number of those\ntransitions which go into state j.",
    "start": "3306290",
    "end": "3313130"
  },
  {
    "text": "How do I talk about that? Well, this quantity up here is\nthe number of transitions into",
    "start": "3313130",
    "end": "3323410"
  },
  {
    "text": "state j over the number of\ntransition that take place.",
    "start": "3323410",
    "end": "3330520"
  },
  {
    "text": "n sub ij of t is the number of\ntransitions out of total transitions.",
    "start": "3330520",
    "end": "3337210"
  },
  {
    "text": "mi of t is the total number\nof transitions. mi of t goes to infinity.",
    "start": "3337210",
    "end": "3342840"
  },
  {
    "text": "So this limit here goes to the\nlimit of n sub ij of n over n.",
    "start": "3342840",
    "end": "3349480"
  },
  {
    "text": "Remember, we even proved this\nvery carefully in class for the last application of it.",
    "start": "3349480",
    "end": "3356170"
  },
  {
    "text": "This is something we've done\nmany times already in different situations.",
    "start": "3356170",
    "end": "3362110"
  },
  {
    "text": "And this particular time we're\ndoing it, we won't go through any fuss about it. It's just a limit of n\nsub ij of n over n.",
    "start": "3362110",
    "end": "3371170"
  },
  {
    "text": "And what is that? That's the fraction, long term\nfraction of transitions that",
    "start": "3371170",
    "end": "3376330"
  },
  {
    "text": "go into state j. We know that for accountable\nstate Markov chain, which is",
    "start": "3376330",
    "end": "3387490"
  },
  {
    "text": "recurrent, which is positive\nrecurrent, this is equal to pi sub j.",
    "start": "3387490",
    "end": "3392850"
  },
  {
    "text": "So we have that as equal\nto pi sub j. We then have one over w sub j,\nthat's what we're trying to",
    "start": "3392850",
    "end": "3398760"
  },
  {
    "text": "find is equal to the limit of\nmij, of t over t, which is the",
    "start": "3398760",
    "end": "3404140"
  },
  {
    "text": "limit of mij of t over mi of\nt times mi of t over t.",
    "start": "3404140",
    "end": "3409529"
  },
  {
    "text": "We break this into a limit of\ntwo terms, which we've done very carefully before. And this limit here\nis pi sub j.",
    "start": "3409530",
    "end": "3418009"
  },
  {
    "text": "This limit here is the limit\nof m sub i of t. And we have already shown that\nthe limit of n sub i",
    "start": "3418010",
    "end": "3425904"
  },
  {
    "text": "of t is equal to-- ",
    "start": "3425904",
    "end": "3437700"
  },
  {
    "text": "Somewhere we showed that. Yeah. ",
    "start": "3437700",
    "end": "3445460"
  },
  {
    "text": "1 over w sub j is equal\nto pj times new sub j. That's what we proved right\ndown here. p sub j of i is",
    "start": "3445460",
    "end": "3454960"
  },
  {
    "text": "equal to 1 over new sub\nj times w sub j. ",
    "start": "3454960",
    "end": "3460750"
  },
  {
    "text": "Except now we're just calling\nit p sub j because we've already seen it. Doesn't depend on i at all.",
    "start": "3460750",
    "end": "3466950"
  },
  {
    "text": "So one over w sub j is equal\nto p sub j times new sub j.",
    "start": "3466950",
    "end": "3475190"
  },
  {
    "text": "This says if we know what\nw sub j is, we know what p sub j is.",
    "start": "3475190",
    "end": "3480880"
  },
  {
    "text": "So it looks like we're not\nmaking any progress. So what's going on?",
    "start": "3480880",
    "end": "3487040"
  },
  {
    "text": "OK, well let's look at this\na little more carefully. This quantity here is a\nfunction only of i.",
    "start": "3487040",
    "end": "3494770"
  },
  {
    "text": " 1 over w sub j, over p sub\nj and new sub j is a",
    "start": "3494770",
    "end": "3506540"
  },
  {
    "text": "function only of j. Everything else in this\nequation is a function only of j.",
    "start": "3506540",
    "end": "3512530"
  },
  {
    "text": "That says that this quantity\nhere is independent of i, and it's also independent of j.",
    "start": "3512530",
    "end": "3519450"
  },
  {
    "text": "And what is it? It's the rate at which\ntransitions occur. Overall transitions.",
    "start": "3519450",
    "end": "3526250"
  },
  {
    "text": "If you're in steady state, this\nsays that looking at any",
    "start": "3526250",
    "end": "3531320"
  },
  {
    "text": "state j, the total number of\ntransitions that occur is equal to, well, I do it\non the next page.",
    "start": "3531320",
    "end": "3540309"
  },
  {
    "text": "So let's goes there. It says that p sub j is equal\nto 1 over new sub j.",
    "start": "3540310",
    "end": "3547400"
  },
  {
    "text": "w sub j is equal to pi j over\nnew j times this limit here.",
    "start": "3547400",
    "end": "3552579"
  },
  {
    "text": " OK. ",
    "start": "3552580",
    "end": "3560060"
  },
  {
    "text": "So in fact, we now have a way\nof finding p sub j for all j",
    "start": "3560060",
    "end": "3567990"
  },
  {
    "text": "if we can just find this\none number here. This is independent of i, so\nthis is just one number, which",
    "start": "3567990",
    "end": "3574460"
  },
  {
    "text": "we now know is something that\napproaches some limit with probability one.",
    "start": "3574460",
    "end": "3580109"
  },
  {
    "text": "So we only have one unknown\ninstead of this countably infinite number of unknowns.",
    "start": "3580110",
    "end": "3586110"
  },
  {
    "text": " Seems like we haven't really\nmade any progress, because",
    "start": "3586110",
    "end": "3593500"
  },
  {
    "text": "before, what we did was to\nnormalize these p sub js. We said they have to add up to\n1, and let's normalize them.",
    "start": "3593500",
    "end": "3600800"
  },
  {
    "text": "And here we're doing\nthe same thing. We're saying p sub j is equal\nto pi sub j over new sub j",
    "start": "3600800",
    "end": "3609320"
  },
  {
    "text": "with this normalization\nfactor in. And we're saying here that this\nnormalization factor has",
    "start": "3609320",
    "end": "3615970"
  },
  {
    "text": "to be equal to 1 over the\nsum of pi k over new k.",
    "start": "3615970",
    "end": "3622369"
  },
  {
    "text": "In other words, if the p sub\nj's add to 1, then the only",
    "start": "3622370",
    "end": "3630290"
  },
  {
    "text": "value this didn't have is\n1 over the sum of pi k times new sub k.",
    "start": "3630290",
    "end": "3635760"
  },
  {
    "text": " Unfortunately, there are\nexamples where the sum of pi",
    "start": "3635760",
    "end": "3645290"
  },
  {
    "text": "sub k over new sub k is\nequal to infinity. That's very awkward.",
    "start": "3645290",
    "end": "3651200"
  },
  {
    "text": "I'm going to give you an example\nof that in just a minute, and you'll see\nwhat's going on.",
    "start": "3651200",
    "end": "3656330"
  },
  {
    "text": "But if pi sub k over new sub k\nis equal to infinity, and the theorem is true, it says that\nthe limit of mi of t over t is",
    "start": "3656330",
    "end": "3665809"
  },
  {
    "text": "equal to 1 over infinity,\nwhich says it's zero. ",
    "start": "3665810",
    "end": "3671430"
  },
  {
    "text": "So what this is telling us is\nwhat we sort of visualize",
    "start": "3671430",
    "end": "3676550"
  },
  {
    "text": "before, but we couldn't\nquite visualize it. It was saying that either these\nprobabilities add up to",
    "start": "3676550",
    "end": "3685690"
  },
  {
    "text": "1, or if they don't add up to 1,\nthis quantity here doesn't",
    "start": "3685690",
    "end": "3691550"
  },
  {
    "text": "make any sense. This is not approaching\na limit. The only way this can approach,\nwell, this can",
    "start": "3691550",
    "end": "3696990"
  },
  {
    "text": "approach a limit where\nthe limit is 0. Because this theorem holds\nwhether it approaches the",
    "start": "3696990",
    "end": "3703870"
  },
  {
    "text": "limit or not. So it is possible for\nthis limit to the 0.",
    "start": "3703870",
    "end": "3709390"
  },
  {
    "text": "In this case, these p\nsub js are all 0. And we've seen this kind\nof thing before.",
    "start": "3709390",
    "end": "3715470"
  },
  {
    "text": "We've seen that on a Markov\nchain, all the steady state probabilities can be equal to\nzero, and that's a sign that",
    "start": "3715470",
    "end": "3722380"
  },
  {
    "text": "we're either in a transient\ncondition, or in a null recurrent position.",
    "start": "3722380",
    "end": "3728110"
  },
  {
    "text": "Namely, the state just wonders\naway, and over the long term,",
    "start": "3728110",
    "end": "3733970"
  },
  {
    "text": "each state has 0 probability. And that looks like the same\nkind of thing which is",
    "start": "3733970",
    "end": "3740180"
  },
  {
    "text": "happening here. This looks trivial.",
    "start": "3740180",
    "end": "3745660"
  },
  {
    "text": "There's a fairly long proof\nin the notes doing this.",
    "start": "3745660",
    "end": "3751140"
  },
  {
    "text": "The only way I can find to do\nthis is to truncate the chain, and then go to the limit as\nthe number of states gets",
    "start": "3751140",
    "end": "3759780"
  },
  {
    "text": "larger and larger. And when you do that, this\ntheorem becomes clear.",
    "start": "3759780",
    "end": "3765630"
  },
  {
    "text": "OK, let's look at an example\nwhere the sum of pi k over new k is equal to infinity, and\nsee what's going on.",
    "start": "3765630",
    "end": "3773190"
  },
  {
    "text": " Visualize something\nlike an mm1 queue.",
    "start": "3773190",
    "end": "3781790"
  },
  {
    "text": "We have arrivals, and\nwe have a server. But as soon as the queue starts\nbuilding up, the server",
    "start": "3781790",
    "end": "3790000"
  },
  {
    "text": "starts to get very rattled. And as the server gets more and\nmore rattled, it starts to",
    "start": "3790000",
    "end": "3795010"
  },
  {
    "text": "make more and more mistakes. And as the queue builds up also,\ncustomers come in and",
    "start": "3795010",
    "end": "3801880"
  },
  {
    "text": "look at the queue, and say I'll\ncome back tomorrow when the queue isn't so long. So we both have this situation\nwhere as the queue is building",
    "start": "3801880",
    "end": "3811720"
  },
  {
    "text": "up, service is getting slower\nand the arrival rate is getting slower.",
    "start": "3811720",
    "end": "3817400"
  },
  {
    "text": "And we're assuming here to make\na nice example that the two of them build up in\nexactly the same way.",
    "start": "3817400",
    "end": "3824039"
  },
  {
    "text": "So that's what's\nhappening here. The service rate when there's\none customer being served is 2",
    "start": "3824040",
    "end": "3830295"
  },
  {
    "text": "to the minus 1. The service right rate when\nthere are two customers in the system is 2 to the minus 2.",
    "start": "3830295",
    "end": "3837680"
  },
  {
    "text": "The service rate when there\nare three customers in the system is 2 to the minus 3.",
    "start": "3837680",
    "end": "3843550"
  },
  {
    "text": "For each of these states, we\nstill have these transition",
    "start": "3843550",
    "end": "3849340"
  },
  {
    "text": "probabilities for the\nembedded chain. And the embedded chain, the only\nway to get from here to",
    "start": "3849340",
    "end": "3855350"
  },
  {
    "text": "here is with probability 1,\nbecause that's the only transition possible here.",
    "start": "3855350",
    "end": "3861370"
  },
  {
    "text": "We assume that from state 1,\nyou go to states 0 with probability 0.6.",
    "start": "3861370",
    "end": "3867280"
  },
  {
    "text": "You go to state two with\nprobability 0.4. With state 1, from state 2,\nyou go up with probability",
    "start": "3867280",
    "end": "3876330"
  },
  {
    "text": "0.4, you go down with\nprobability 0.6. The embedded chain\nlooks great.",
    "start": "3876330",
    "end": "3883780"
  },
  {
    "text": "There's nothing wrong\nwith that. That's a perfectly stable mm1\nqueue type of situation.",
    "start": "3883780",
    "end": "3891510"
  },
  {
    "text": "It's these damned holding\ntimes which become very",
    "start": "3891510",
    "end": "3896750"
  },
  {
    "text": "disturbing. Because if you look at pi sub\nj, which is supposed to be 1",
    "start": "3896750",
    "end": "3904600"
  },
  {
    "text": "minus rho times rho to the j. Rho is 2/3, it's\nlambda over mu. So it's lambda over lambda\nplus mu over rho",
    "start": "3904600",
    "end": "3911590"
  },
  {
    "text": "plus lambda plus mu. It's 0.4 divided by\n0.6, which is 2/3.",
    "start": "3911590",
    "end": "3919440"
  },
  {
    "text": "If we look at pi sub j over new\nsub j, it's equal to 2 to the j times 1 minus rho,\ntimes rho to the j.",
    "start": "3919440",
    "end": "3929080"
  },
  {
    "text": "It's 1 minus rho times\n4/3 to the j.",
    "start": "3929080",
    "end": "3934810"
  },
  {
    "text": "This quantity gets bigger and\nbigger as j increases.",
    "start": "3934810",
    "end": "3940440"
  },
  {
    "text": "So when you try to\nsum pi i over new sub j, you get infinity.",
    "start": "3940440",
    "end": "3946910"
  },
  {
    "text": "So what's going on? None of the states here have\nan infinite holding time",
    "start": "3946910",
    "end": "3952670"
  },
  {
    "text": "associated with them. It's just that the expected\nholding time",
    "start": "3952670",
    "end": "3958490"
  },
  {
    "text": "is going to be infinite. The expected number of\ntransitions over a long period",
    "start": "3958490",
    "end": "3964480"
  },
  {
    "text": "of time, according to this\nequation here, expected",
    "start": "3964480",
    "end": "3974050"
  },
  {
    "text": "transitions per unit\ntime is going to 0. As time goes on, you keep\nfloating back to state 0, as",
    "start": "3974050",
    "end": "3984160"
  },
  {
    "text": "far as the embedded chain\nis concerned. But you're eventually going to\na steady state distribution,",
    "start": "3984160",
    "end": "3990680"
  },
  {
    "text": "which is laid out over\nall the states. That steady state distribution\nlooks very nice.",
    "start": "3990680",
    "end": "4000309"
  },
  {
    "text": "That's 1 minus rho times\nrho to the j. Rho is 2/3, so the probability\nof being in state j is going",
    "start": "4000310",
    "end": "4008030"
  },
  {
    "text": "down exponentially\nas j gets big. But the time that you spend\nthere is going up",
    "start": "4008030",
    "end": "4014569"
  },
  {
    "text": "exponentially even faster. And therefore, when we sum all\nof these things up, the",
    "start": "4014570",
    "end": "4021740"
  },
  {
    "text": "overall expected rate is equal\nto zero, because the sum of",
    "start": "4021740",
    "end": "4027330"
  },
  {
    "text": "the pi j over new j is\nequal to infinity. OK.",
    "start": "4027330",
    "end": "4032599"
  },
  {
    "text": "So this is one of the awful\nthings that are going to happen with Markov processes. We still have an\nembedded chain.",
    "start": "4032600",
    "end": "4039620"
  },
  {
    "text": "The embedded chain\ncan be stable. It can have a steady state, but\nwe've already found that",
    "start": "4039620",
    "end": "4045150"
  },
  {
    "text": "the fraction of time in a state\nis not equal to the fraction of transitions that go\ninto that state. pi sub j",
    "start": "4045150",
    "end": "4053390"
  },
  {
    "text": "is not in general equal\nto p sub j. And for this example here with\nthe rattled server and the",
    "start": "4053390",
    "end": "4060740"
  },
  {
    "text": "discouraged customers, the\namount of time that it takes,",
    "start": "4060740",
    "end": "4067400"
  },
  {
    "text": "the expected amount of time that\nit takes for customers to get served is going to zero.",
    "start": "4067400",
    "end": "4074770"
  },
  {
    "text": "Even though the queue\nwas saying stable. Does mathematics lie?",
    "start": "4074770",
    "end": "4081380"
  },
  {
    "text": "I don't know. I don't think so. I've looked at this often enough\nwith great frustration,",
    "start": "4081380",
    "end": "4087320"
  },
  {
    "text": "but I believe it\nat this point. If you don't believe it, take\nthis chain here and truncate",
    "start": "4087320",
    "end": "4093660"
  },
  {
    "text": "it, and solve the problem for\nthe truncated chain, and then look at what happens\nas you start adding",
    "start": "4093660",
    "end": "4100219"
  },
  {
    "text": "states on one by one. What happens as you start adding\nstates on one by one is",
    "start": "4100220",
    "end": "4106700"
  },
  {
    "text": "that the rate at which this\nMarkov process is serving things is going to zero.",
    "start": "4106700",
    "end": "4114229"
  },
  {
    "text": "So the dilemma as the number\nof states becomes infinite, the rate at which things\nhappen is equal to 0.",
    "start": "4114229",
    "end": "4123979"
  },
  {
    "text": "It's not pleasant. It's not intuitive. But that's what it is.",
    "start": "4123979",
    "end": "4130210"
  },
  {
    "text": "And that can happen. ",
    "start": "4130210",
    "end": "4136310"
  },
  {
    "text": "Again, let's go back to the\ntypical case of a positive recurrent embedded chain, where\nthis funny sum here is",
    "start": "4136310",
    "end": "4147040"
  },
  {
    "text": "less than infinity. If the sum here is less than\ninfinity, then you can",
    "start": "4147040",
    "end": "4152710"
  },
  {
    "text": "certainly express p sub j as\npi sub j over new sub j",
    "start": "4152710",
    "end": "4158479"
  },
  {
    "text": "divided by the sum over k of\np sub k over new sub k. Why can I do that?",
    "start": "4158479",
    "end": "4163620"
  },
  {
    "text": "Because that's what\nthe formula says. ",
    "start": "4163620",
    "end": "4168750"
  },
  {
    "text": "I don't like to live with\nformulas, but sometimes things get so dirty, the mathematics\nplay such awful tricks with",
    "start": "4168750",
    "end": "4176520"
  },
  {
    "text": "you that you have to live with\nthe formulas, and just try to explain what they're doing.",
    "start": "4176520",
    "end": "4181689"
  },
  {
    "text": "p sub j is equal to this. Limit of the service rate, if\nthis quantity is non infinite,",
    "start": "4181689",
    "end": "4192339"
  },
  {
    "text": "then things get churned\nout of this queueing system at some rate.",
    "start": "4192340",
    "end": "4198820"
  },
  {
    "text": "And the p sub js can\nbe solved for. And this is the way\nto solve for them.",
    "start": "4198820",
    "end": "4206620"
  },
  {
    "text": "OK, so that's pretty neat. It says that if you can solve\nthe embedded chain, then you",
    "start": "4206620",
    "end": "4212120"
  },
  {
    "text": "have a nice formula for finding\nthe steady state probabilities. And you have a theorem which\nsays that so long as this",
    "start": "4212120",
    "end": "4219430"
  },
  {
    "text": "quantity is less than infinity\nwith probability one, the fraction of time that you\nstay in state j is",
    "start": "4219430",
    "end": "4227420"
  },
  {
    "text": "equal to this quantity. Well, that's not good enough. Because for the mm1 queue, we\nsaw that it was really a pain",
    "start": "4227420",
    "end": "4235250"
  },
  {
    "text": "in the neck to solve for the\nsteady state equations for the embedded chain.",
    "start": "4235250",
    "end": "4241400"
  },
  {
    "text": "Things looked simpler for\nthe process itself. So let's see if we can get those\nequations back also.",
    "start": "4241400",
    "end": "4251010"
  },
  {
    "text": "What we would like to do is\nto solve for the p sub j's directly by using the steady\nstate embedded equation.",
    "start": "4251010",
    "end": "4259090"
  },
  {
    "text": "Embedded equations say that pi\nsub j is equal to the sum over i, pi sub i times p sub ij.",
    "start": "4259090",
    "end": "4267330"
  },
  {
    "text": "The probability of going into\na state is equal to the probability of going\nout of a state. ",
    "start": "4267330",
    "end": "4275970"
  },
  {
    "text": "If I use this formula here, pi\nsub j over new sub j divided",
    "start": "4275970",
    "end": "4283720"
  },
  {
    "text": "by some constant is\nwhat p sub j is. So pi sub j is equal to\np sub j times new sub",
    "start": "4283720",
    "end": "4292435"
  },
  {
    "text": "j times that constant. Here we have the p sub\nj times the new sub j",
    "start": "4292435",
    "end": "4301290"
  },
  {
    "text": "divided by that constant. And that's equal to this sum\nhere over all i divided by the",
    "start": "4301290",
    "end": "4310490"
  },
  {
    "text": "same constant. So the constant cancels out. Namely, we left out that term\nhere, but that term is on this",
    "start": "4310490",
    "end": "4317870"
  },
  {
    "text": "side, and it's on this side. So we have this equation here.",
    "start": "4317870",
    "end": "4323530"
  },
  {
    "text": "If you remember, I can't\nremember, but you being younger can perhaps remember.",
    "start": "4323530",
    "end": "4329450"
  },
  {
    "text": "But when we were dealing with\na sample time approximation, if you leave the deltas out,\nthis is exactly the equation",
    "start": "4329450",
    "end": "4336600"
  },
  {
    "text": "that you got. It's a nice equation. It says that the rate at which\ntransitions occur out of state",
    "start": "4336600",
    "end": "4345910"
  },
  {
    "text": "i, the rate at which transitions\noccur out of state i, out of state j, excuse me,\nis p sub j times new sub j.",
    "start": "4345910",
    "end": "4355489"
  },
  {
    "text": "Here's the holding time, and\nthere's also the probability of being there.",
    "start": "4355490",
    "end": "4362230"
  },
  {
    "text": "Excuse me. Let's be more clear\nabout that. I'm not talking about given\nyou're in state j, the rate at",
    "start": "4362230",
    "end": "4370040"
  },
  {
    "text": "which you get out of state j. I'm talking about the rate at\nwhich you're in state j and",
    "start": "4370040",
    "end": "4376700"
  },
  {
    "text": "you're getting out of state j. If you could make sense\nout of that. That's what this is.",
    "start": "4376700",
    "end": "4382100"
  },
  {
    "text": "This quantity here is the\noverall rate at which you're entering state j.",
    "start": "4382100",
    "end": "4388099"
  },
  {
    "text": "So these equations sort of\nhave the same intuitive meaning as these equations\nhere do.",
    "start": "4388100",
    "end": "4394390"
  },
  {
    "start": "4394390",
    "end": "4399450"
  },
  {
    "text": "And then if you solve this\nequation in the same way,",
    "start": "4399450",
    "end": "4408140"
  },
  {
    "text": "what's that doing? Oh. This gets you pi sub j in\nterms of the p sub j's.",
    "start": "4408140",
    "end": "4414550"
  },
  {
    "text": "So there's a very nice symmetry about this set of equations. The p sub j's are found for the\npi sub j's in this way.",
    "start": "4414550",
    "end": "4423989"
  },
  {
    "text": "The pi sub j's are found from\nthe p sub j's by this same sort of expression.",
    "start": "4423990",
    "end": "4429010"
  },
  {
    "text": "The theorem then says if the\nembedded chain is positive recurrent, and the sum of pi\ni over new i is less than",
    "start": "4429010",
    "end": "4437250"
  },
  {
    "text": "infinity, then this equation\nhas a unique solution. In other words, there is a\nsolution to the steady state",
    "start": "4437250",
    "end": "4445270"
  },
  {
    "text": "process equations. And pi sub j and p sub j are\nrelated by this, and by this.",
    "start": "4445270",
    "end": "4456130"
  },
  {
    "text": "If you know the pi sub j's, you\ncan find the p sub j's. If you know the p sub j's, you\ncan find the pi sub j's.",
    "start": "4456130",
    "end": "4463940"
  },
  {
    "text": "There's a fudge factor, and the\nsum of pi sub i over new sub i is equal to sum of\np sub j times new sub j",
    "start": "4463940",
    "end": "4472330"
  },
  {
    "text": "to the minus 1. This equation just falls out\nof looking at this equation",
    "start": "4472330",
    "end": "4477659"
  },
  {
    "text": "and this equation. I'm not going to do that here,\nbut if you just fiddle with these equations a little bit,\nthat's what you find.",
    "start": "4477660",
    "end": "4485650"
  },
  {
    "text": " I think graduate students\nlove to push equations.",
    "start": "4485650",
    "end": "4492530"
  },
  {
    "text": "And if you push these equations,\nyou will rapidly find that out. So there's no point\nto doing it here.",
    "start": "4492530",
    "end": "4499679"
  },
  {
    "text": "OK.  You can do the opposite\nthing, also.",
    "start": "4499680",
    "end": "4505430"
  },
  {
    "text": "If the steady state process\nequations are satisfied, and the p sub j's are all greater\nthan zero, and the sum of the",
    "start": "4505430",
    "end": "4513449"
  },
  {
    "text": "p sub j's are equal to 1. And if these equations are less\nthan infinity, this is",
    "start": "4513450",
    "end": "4520010"
  },
  {
    "text": "just by symmetry with\nwhat we already did. Then pi sub j has to be equal\nto p sub j times new sub j",
    "start": "4520010",
    "end": "4527730"
  },
  {
    "text": "divided by this sum. And this gives the steady\nstate equations for the",
    "start": "4527730",
    "end": "4532830"
  },
  {
    "text": "embedded chain. And this shows that the embedded\nchain has to be positive recurrent, and says\nthat you have to be",
    "start": "4532830",
    "end": "4539980"
  },
  {
    "text": "able to go both ways. So we already know that if you\ncan solve the steady state equations for the embedded\nchain, they have to be unique,",
    "start": "4539980",
    "end": "4548310"
  },
  {
    "text": "the probabilities all\nhave to be positive. All those neat things for\naccountable state and Markov",
    "start": "4548310",
    "end": "4553580"
  },
  {
    "text": "chains hold true. This says that if you can solve\nthat virtually identical",
    "start": "4553580",
    "end": "4559830"
  },
  {
    "text": "set of equations for the\nprocess, and you get a solution, and the sum here is\nfinite, then in fact you can",
    "start": "4559830",
    "end": "4573210"
  },
  {
    "text": "go back the other way. And going back the other way,\nyou know from what we know about embedded chains that\nthere's a unique solution.",
    "start": "4573210",
    "end": "4581530"
  },
  {
    "text": "So there has to be a unique\nsolution both ways. There has to be positive\nrecurrence both ways.",
    "start": "4581530",
    "end": "4588030"
  },
  {
    "text": "So we have a complete\nstory at this point. I mean, you'll have to spend a\nlittle more time putting it",
    "start": "4588030",
    "end": "4594160"
  },
  {
    "text": "together, but it really\nis there. If new sub j is bounded over\nj, then the sum over j of p",
    "start": "4594160",
    "end": "4602630"
  },
  {
    "text": "sub j, new sub j is less\nthan infinity. Also, the sample time\nchain exists",
    "start": "4602630",
    "end": "4609119"
  },
  {
    "text": "because this is bounded. It has the same steady\nstate solution as the",
    "start": "4609120",
    "end": "4614230"
  },
  {
    "text": "Markov process solution. In other words, go back and look\nat the solution for the",
    "start": "4614230",
    "end": "4619880"
  },
  {
    "text": "sample time chain. Drop out the delta, and what\nyou will get is this set of",
    "start": "4619880",
    "end": "4625270"
  },
  {
    "text": "equations here. If you have a birth death\nprocess, it's a birth death",
    "start": "4625270",
    "end": "4631880"
  },
  {
    "text": "process for both the Markov\nprocess, and also for the",
    "start": "4631880",
    "end": "4637190"
  },
  {
    "text": "embedded chain. For the embedded chain,\nyou know that what you have to do to get--",
    "start": "4637190",
    "end": "4644040"
  },
  {
    "text": "for a birth death chain, you\nknow an easy way to solve the steady state equations for the\nchain are to say transitions",
    "start": "4644040",
    "end": "4653070"
  },
  {
    "text": "this way equal transitions\nthis way. It's the same for the process.",
    "start": "4653070",
    "end": "4658909"
  },
  {
    "text": "The amount of time that you\nspend going this way is equal to the average amount of time\nyou spent going this way.",
    "start": "4658910",
    "end": "4666360"
  },
  {
    "text": "So it says for a birth death\nprocess, p sub i times q sub",
    "start": "4666360",
    "end": "4671900"
  },
  {
    "text": "i, i plus one.  That's an i there, is equal to\np sub i plus 1 times the",
    "start": "4671900",
    "end": "4682870"
  },
  {
    "text": "transition probability from\ni plus 1 back to i.",
    "start": "4682870",
    "end": "4688110"
  },
  {
    "text": "So this symmetry exists\nalmost everywhere. And then if the sum of p sub\nj, new sub j is equal to",
    "start": "4688110",
    "end": "4697170"
  },
  {
    "text": "infinity, that's the bad case. These equations say that\npi sub j is equal to 0",
    "start": "4697170",
    "end": "4707670"
  },
  {
    "text": "everywhere. This is sort of the dual\nof the situation we already looked at.",
    "start": "4707670",
    "end": "4713480"
  },
  {
    "text": "In the case we already looked\nat of the lazy or rattled server and the discouraged\ncustomers, eventually the rate",
    "start": "4713480",
    "end": "4723050"
  },
  {
    "text": "at which service occurred\nwent to 0. This situation is a situation\nwhere as far as the embedded",
    "start": "4723050",
    "end": "4732230"
  },
  {
    "text": "chain is concerned, it thinks\nit's transient.",
    "start": "4732230",
    "end": "4738489"
  },
  {
    "text": "As far as the process is\nconcerned, the process thinks it's just fine.",
    "start": "4738490",
    "end": "4743710"
  },
  {
    "text": "But then you look at the\nprocess, and you find out that what's happening is that an\ninfinite number of transitions",
    "start": "4743710",
    "end": "4750600"
  },
  {
    "text": "are taking place in\na finite time. Markov process people call these\nirregular processes.",
    "start": "4750600",
    "end": "4759480"
  },
  {
    "text": "Here's a picture of it\non the next slide. ",
    "start": "4759480",
    "end": "4765360"
  },
  {
    "text": "Essentially, the embedded chain\nfor a hyperactive birth death chain.",
    "start": "4765360",
    "end": "4770480"
  },
  {
    "text": "As you go to higher states, the\nrate at which transitions take place gets higher\nand higher.",
    "start": "4770480",
    "end": "4778340"
  },
  {
    "text": "And for this particular example\nhere, you can solve those process equations.",
    "start": "4778340",
    "end": "4784460"
  },
  {
    "text": "The process equations\nlook just fine. This is where you have to be\ncareful with Markov processes.",
    "start": "4784460",
    "end": "4791110"
  },
  {
    "text": "Because you can solve these\nMarkov process equations, and you get things that look fine,\nwhen actually there isn't any",
    "start": "4791110",
    "end": "4799929"
  },
  {
    "text": "steady state behavior at all. It's even worse than the\nrate going to zero.",
    "start": "4799930",
    "end": "4805280"
  },
  {
    "text": "When the rate goes to infinity,\nyou can have an infinite number of transitions\ntaking place in a finite time.",
    "start": "4805280",
    "end": "4812560"
  },
  {
    "text": "And then nothing happens. Well, I don't know whether\nsomething happens or not. I can't visualize what happens\nafter the thing has exploded.",
    "start": "4812560",
    "end": "4821625"
  },
  {
    "text": " Except essentially, at\nthat point, there's nothing nice going on.",
    "start": "4821625",
    "end": "4828440"
  },
  {
    "text": "And you have to say that even\nthough the process equations have a steady state solution,\nthere is no steady state in",
    "start": "4828440",
    "end": "4836910"
  },
  {
    "text": "terms of over the long period of\ntime, this is the fraction of time you spend in state j.",
    "start": "4836910",
    "end": "4842410"
  },
  {
    "text": "Because that's not the\nway it's behaving. OK. ",
    "start": "4842410",
    "end": "4849250"
  },
  {
    "text": "I mean, you can see this\nwhen you look at the embedded chain. The embedded chain\nis transient.",
    "start": "4849250",
    "end": "4856350"
  },
  {
    "text": "You're moving up with\nprobability 0.6. You're moving down with\nprobability 0.4. So you keep moving up.",
    "start": "4856350",
    "end": "4863990"
  },
  {
    "text": "When you look at the process in\nterms of the process with",
    "start": "4863990",
    "end": "4870440"
  },
  {
    "text": "the transition rates q sub ij,\nthe rates going up are always",
    "start": "4870440",
    "end": "4876960"
  },
  {
    "text": "less than the rates\ngoing down. This is because as you\nmove up in state,",
    "start": "4876960",
    "end": "4885520"
  },
  {
    "text": "you act so much faster. The transition rates are higher\nin higher states, and",
    "start": "4885520",
    "end": "4893719"
  },
  {
    "text": "therefore the transition rates\ndown are higher, and the transition rate down from state\n2 to state 1 is bigger",
    "start": "4893720",
    "end": "4903900"
  },
  {
    "text": "than the transition right\nup from i to i plus 1.",
    "start": "4903900",
    "end": "4909110"
  },
  {
    "text": "And it looks stable, as far as\nthe process is concerned. This is one example where you\ncan't look at the process and",
    "start": "4909110",
    "end": "4918010"
  },
  {
    "text": "find out anything from it\nwithout also looking at the embedded chain, and looking at\nhow many transitions you're",
    "start": "4918010",
    "end": "4924570"
  },
  {
    "text": "getting per unit time. OK, so that's it.",
    "start": "4924570",
    "end": "4930079"
  },
  {
    "text": "Thank you. ",
    "start": "4930080",
    "end": "4933908"
  }
]
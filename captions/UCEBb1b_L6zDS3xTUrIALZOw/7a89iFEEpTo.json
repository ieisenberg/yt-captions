[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5920"
  },
  {
    "text": "Your support will help MIT\nOpenCourseWare continue to offer high-quality educational\nresources for free.",
    "start": "5920",
    "end": "12610"
  },
  {
    "text": "To make a donation or view\nadditional materials from hundreds of MIT courses, visit\nMIT OpenCourseWare at",
    "start": "12610",
    "end": "19430"
  },
  {
    "text": "ocw.mit.edu. ",
    "start": "19430",
    "end": "25716"
  },
  {
    "text": "GUEST SPEAKER 1: All right. So we're going to talk about\nperformance engineering and pretty much how to do that\nwith profiling tools.",
    "start": "25716",
    "end": "34262"
  },
  {
    "text": "So first, we're going to talk\nabout what profiling tools are and how you use them in\ngeneral, what the",
    "start": "34262",
    "end": "39420"
  },
  {
    "text": "theory of that is. And then, more importantly,\nwe're going to do an interactive walk-through\nof two examples",
    "start": "39420",
    "end": "46550"
  },
  {
    "text": "that we picked out. The first one is the Matrix\nMultiply that you guys saw in Project 0, the cache ratio\nmeasurements and how to do",
    "start": "46550",
    "end": "54560"
  },
  {
    "text": "those measurements and how to do\nthe cycles per instruction measurements, these\nkinds of things.",
    "start": "54560",
    "end": "60060"
  },
  {
    "text": "And then we're going to look at\ndoing some of the bit hacks that Charles talked about\nin the second lecture.",
    "start": "60060",
    "end": "65750"
  },
  {
    "text": "We're going to work on a\nbranchless sorting algorithm, which is pretty interesting. ",
    "start": "65750",
    "end": "75360"
  },
  {
    "text": "So the code we gave you in\nproject one, it was very",
    "start": "75360",
    "end": "82510"
  },
  {
    "text": "obvious where the\nhot spot was. But real life doesn't really\nwork that way. And code gets really,\nreally big.",
    "start": "82510",
    "end": "88340"
  },
  {
    "text": " It's not always obvious\nwhere the part is",
    "start": "88340",
    "end": "93509"
  },
  {
    "text": "that you want to optimize. And you really don't want to\nwaste time taking what is otherwise understandable, good\ncode, and beating it over the",
    "start": "93510",
    "end": "100060"
  },
  {
    "text": "head trying to make\nit go faster. So that's why Donald Knuth said,\n\"premature optimization is the root of all evil.\"\nYou really want to",
    "start": "100060",
    "end": "107460"
  },
  {
    "text": "focus on the hot spots. So that's what profiling's\nfor. It basically gives you\nvisibility into the execution",
    "start": "107460",
    "end": "115130"
  },
  {
    "text": "of your code, because it would\nbe too complicated to just sit down and look at it and try\nto understand where it's spending its time.",
    "start": "115130",
    "end": "121320"
  },
  {
    "text": " And there are many possibilities\nfor where it",
    "start": "121320",
    "end": "127110"
  },
  {
    "text": "could be spending its time. In 6-172 we're mostly going to\nbe focusing on things that are CPU-bound and things that are\nusing the memory hierarchy",
    "start": "127110",
    "end": "134890"
  },
  {
    "text": "ineffectively. But in the real world, a couple\nof other common things",
    "start": "134890",
    "end": "140410"
  },
  {
    "text": "are network requests. So if you've got your web\napplication, it's making a whole bunch of AJAX requests.",
    "start": "140410",
    "end": "146450"
  },
  {
    "text": "It's going to be wasting a\nlot of your users' time. If you've got your desktop\napplication, it's hitting the",
    "start": "146450",
    "end": "151690"
  },
  {
    "text": "disk all the time. That's also going to\nslow you down. I think SQL database, if\nanybody's ever done web development, they know that\ncan be a huge bottleneck.",
    "start": "151690",
    "end": "158875"
  },
  {
    "text": " So basically, the tool that\nyou're going to use is going",
    "start": "158875",
    "end": "165390"
  },
  {
    "text": "to depend a lot on what the\nproblem you're solving is. But the basic ideas\nare all the same.",
    "start": "165390",
    "end": "171570"
  },
  {
    "text": "There are all kinds of profiling\ntools for measuring these things and figuring out\nwhere it's coming from and",
    "start": "171570",
    "end": "177710"
  },
  {
    "text": "where the time's going.  So for trying to figure out\nCPU and memory, there's a",
    "start": "177710",
    "end": "185910"
  },
  {
    "text": "couple things you can do. The first and most basic and\nsort of most obvious to you guys is you can do manual\ninstrumentation.",
    "start": "185910",
    "end": "192480"
  },
  {
    "text": "And what that is is basically\nwhere you go in and you put in prints and try to figure out\nwhere it's spending its time,",
    "start": "192480",
    "end": "198230"
  },
  {
    "text": "what codes could you\nhave executed more. Or you can be a little\nbit more clever. You can try to insert logging\ncalls that fill up a buffer",
    "start": "198230",
    "end": "207480"
  },
  {
    "text": "with checking the time and\nactually doing that yourself. And one of the big advantages\nof that is that, when you",
    "start": "207480",
    "end": "215620"
  },
  {
    "text": "actually go into the code and\nyou instrument yourself, you can cut down the information\nthat's coming back out at you.",
    "start": "215620",
    "end": "221830"
  },
  {
    "text": "If you have an intuition for\nhow the program works, sprinkling little calls to\ntiming functions around your",
    "start": "221830",
    "end": "227410"
  },
  {
    "text": "code in the places that you\nthink matter is going to give you maybe a better picture.",
    "start": "227410",
    "end": "233580"
  },
  {
    "text": "But it requires more\nwork on your part. So that's the drawback. The other kind of\ninstrumentation is static",
    "start": "233580",
    "end": "240370"
  },
  {
    "text": "instrumentation, which\nis basically-- and I should say that\ninstrumentation is basically a little snippet of code that\nis gathering information,",
    "start": "240370",
    "end": "248190"
  },
  {
    "text": "gathering data about\nthe code execution. So static instrumentation is\nbasically code that's inserted",
    "start": "248190",
    "end": "254019"
  },
  {
    "text": "by the compiler when you\nbuild your code. And gprof is an example\nof this.",
    "start": "254020",
    "end": "259230"
  },
  {
    "text": "Basically, what it does is it\nwill, at the prologue and the epilogue for every function,\ninsert a little piece of code",
    "start": "259230",
    "end": "265130"
  },
  {
    "text": "that increments a counter\nevery time the function gets executed. I think it also figures\nout who called it,",
    "start": "265130",
    "end": "270570"
  },
  {
    "text": "that kind of thing. One of the drawbacks to static\ninstrumentation is that you have to have the source, and you\nhave to be able to rebuild",
    "start": "270570",
    "end": "277810"
  },
  {
    "text": "your project. If you've ever had a DLL binary\nblob of data library",
    "start": "277810",
    "end": "284229"
  },
  {
    "text": "handed to you, and you want to\nknow where the time's going in that library, you're not going\nto be able to instrument it.",
    "start": "284230",
    "end": "290009"
  },
  {
    "text": "So you're not going\nto get any data. So that brings us to the next\nthing, which is dynamic instrumentation, which\nsolves that problem.",
    "start": "290010",
    "end": "297430"
  },
  {
    "text": "Basically, what happens there\nis you take the binary as it is just before you're\nabout to run it.",
    "start": "297430",
    "end": "302990"
  },
  {
    "text": "And before you start executing,\nyou actually just take a look at the code\nand translate it. And you go in, and you insert\nthe instrumentation.",
    "start": "302990",
    "end": "308440"
  },
  {
    "text": "And then you have this new\nsnippet of code that you then run instead. And so that works for\nbinary blobs.",
    "start": "308440",
    "end": "316270"
  },
  {
    "text": "And it doesn't require a\nrecompile, which is great. But it introduces a lot of\noverhead, because you're not",
    "start": "316270",
    "end": "323750"
  },
  {
    "text": "actually running the original\ncode, right? You're running this translated\nthing, which might be much",
    "start": "323750",
    "end": "330270"
  },
  {
    "text": "more inefficient.  And I guess Valgrind has a\ncouple of tools that are sort",
    "start": "330270",
    "end": "337410"
  },
  {
    "text": "of classic examples of that,\nCallgrind and Cachegrind. I think Callgrind gives\nyou a call graph. And Cachegrind tries to measure\nthe cache effects,",
    "start": "337410",
    "end": "346840"
  },
  {
    "text": "tries to make a prediction of\nwhen you do memory accesses, are these things in\ncache or not.",
    "start": "346840",
    "end": "353780"
  },
  {
    "text": "Another thing you might want to\nlook at, or the thing that we're going to focus\non in this course are performance counters.",
    "start": "353780",
    "end": "359880"
  },
  {
    "text": "And two tools to get these\nare OProfile and perf. And basically, the CPU has a\nbunch of counters-- we've",
    "start": "359880",
    "end": "367590"
  },
  {
    "text": "talked about them-- for branch\nmisses, cache misses, these kinds of things. And this will give\naccess to those.",
    "start": "367590",
    "end": "373222"
  },
  {
    "text": "The last tool that I guess I'm\ngoing to talk about for profiling is heap profiling. A lot of times, if memory's your\nproblem, you really want",
    "start": "373222",
    "end": "381330"
  },
  {
    "text": "to figure out who's doing\nall the allocation. And so these tools will give you\na nice breakdown of who's",
    "start": "381330",
    "end": "388520"
  },
  {
    "text": "allocating what, who's calling\nthem, and who can I stop calling so that I'm allocating\nless memory.",
    "start": "388520",
    "end": "395110"
  },
  {
    "text": "And like I said, you can find\nmore tools for profiling",
    "start": "395110",
    "end": "400500"
  },
  {
    "text": "different kinds of problems\nand resources. But today we're mostly going to\nfocus on perf, which is a",
    "start": "400500",
    "end": "405730"
  },
  {
    "text": "new tool for getting access to\nperformance counters on Linux.",
    "start": "405730",
    "end": "412030"
  },
  {
    "text": "I guess I should also mention\nthat, as someone talked about in the last lecture, the way\nthat you want to gather data",
    "start": "412030",
    "end": "418410"
  },
  {
    "text": "from performance counters is you\nwant to do event sampling. There's too much data.",
    "start": "418410",
    "end": "424670"
  },
  {
    "text": "As you execute along, you don't\nwant to record, OK, I executed this instruction,\nthen I executed that instruction, and I'm going to\ncount all the instruction",
    "start": "424670",
    "end": "432080"
  },
  {
    "text": "executions and then store\nthat data somewhere. That would be way\ntoo much data. So what you want to do is you\nwant to sample every so often,",
    "start": "432080",
    "end": "440830"
  },
  {
    "text": "every 1,000th event, or some\nother frequency for whatever",
    "start": "440830",
    "end": "446629"
  },
  {
    "text": "your interesting event is.  And basically, what happens is\nthat when that counter has hit",
    "start": "446630",
    "end": "457680"
  },
  {
    "text": "the threshold, an interrupt\nwill fire, and the kernel will catch it. And then it will record the\ndata that you want, the",
    "start": "457680",
    "end": "464080"
  },
  {
    "text": "context, like where in the\nexecution it was, what the call stack looked like,\nthese kinds of things. ",
    "start": "464080",
    "end": "474000"
  },
  {
    "text": "I think we've covered most of\nthe performance counters that we mostly care about. But I think it's worth\nmentioning that there are a",
    "start": "474000",
    "end": "482470"
  },
  {
    "text": "lot of performance counters. And you can go look them up in\nthis part of the manual.",
    "start": "482470",
    "end": "487900"
  },
  {
    "text": "They cover a lot of interesting\nthings, not just the ones we've talked about,\nincluding sleep states, power",
    "start": "487900",
    "end": "493150"
  },
  {
    "text": "consumption. And if you want to look at\ncontention, say you have a",
    "start": "493150",
    "end": "499030"
  },
  {
    "text": "parallel program, and\nyou have two cores accessing the same data. If they're writing back to it,\nthey're going to be fighting",
    "start": "499030",
    "end": "504110"
  },
  {
    "text": "over the same cache lines. And so there are counters for\nthings like, how many times did this core have to go off\ncore to get cache line, and",
    "start": "504110",
    "end": "513630"
  },
  {
    "text": "all kinds of interesting\nthings like that. But mostly, we're going to focus\non the cache misses,",
    "start": "513630",
    "end": "518929"
  },
  {
    "text": "branch misses. ",
    "start": "518929",
    "end": "524520"
  },
  {
    "text": "I also wanted to mention that\nthe tool we're using, perf, it kind of replaces OProfile and\nPerfMon, which are tools that",
    "start": "524520",
    "end": "530520"
  },
  {
    "text": "do similar things. I guess it's different in that\nit's a unified interface to",
    "start": "530520",
    "end": "535870"
  },
  {
    "text": "monitoring two kinds\nof events. The first are software kernel\nevents, so things",
    "start": "535870",
    "end": "542080"
  },
  {
    "text": "like contact switches. So how many times did your\napplication make a system call and then get contact\nswitched out?",
    "start": "542080",
    "end": "548290"
  },
  {
    "text": "And how many page faults did\nyour application generate? ",
    "start": "548290",
    "end": "555509"
  },
  {
    "text": "These kinds of things that the\nkernel knows about, but aren't necessarily hardware events. And the other kind is\nhardware events. And those are sort of the ones\nwe're going to focus on.",
    "start": "555510",
    "end": "563449"
  },
  {
    "text": "We've already talked\nabout those. If you want to get this tool\nand try it out yourself, if you have any recent Linux\ndistribution, anything with a",
    "start": "563450",
    "end": "570160"
  },
  {
    "text": "kernel that's less than\na year old, you can install Linux tools. And the command is perf.",
    "start": "570160",
    "end": "578470"
  },
  {
    "text": "So now we're going to do a demo\nof the matrix multiply from Project 0. GUEST SPEAKER 2: All right. So for the demos, I guess I'll\nnarrate what the code's doing,",
    "start": "578470",
    "end": "586069"
  },
  {
    "text": "so Reid can focus on typing. This code should\nlook familiar. ",
    "start": "586070",
    "end": "604116"
  },
  {
    "text": "All right. Can everybody hear me? All right, cool. So this code should look\nvery familiar.",
    "start": "604116",
    "end": "609860"
  },
  {
    "text": "It's Project 0's matrix\nmultiply code, the original version. And it's a triply-nested four\nloop for multiplying matrices.",
    "start": "609860",
    "end": "618380"
  },
  {
    "text": "So what we're going to do is\nI'm going to switch to a terminal that Reid\nis typing on.",
    "start": "618380",
    "end": "625640"
  },
  {
    "text": "And we're going to run\nmatrix multiply. And it takes about eight\nseconds to run.",
    "start": "625640",
    "end": "631160"
  },
  {
    "text": "And now we're going to run it,\nbut have perf output some performance statistics for it,\nbasically, CPU counters.",
    "start": "631160",
    "end": "639269"
  },
  {
    "text": "So you use -e to request\nspecific counters. You can use perf list to take\na look at all the counters",
    "start": "639270",
    "end": "647180"
  },
  {
    "text": "that perf supports. In this case, we're asking for\nthe number of CPU cycles, the number of instructions, the\nnumber of L1 cache loads, and",
    "start": "647180",
    "end": "655090"
  },
  {
    "text": "then the number of\nL1 cache misses. ",
    "start": "655090",
    "end": "660250"
  },
  {
    "text": "Perf stat.  That's better.",
    "start": "660250",
    "end": "665490"
  },
  {
    "text": " So it takes a little bit\nlonger to execute,",
    "start": "665490",
    "end": "670620"
  },
  {
    "text": "I think, with perf. But it's not supposed to\nbe a big difference. You can see, 8.31 versus 8.34.",
    "start": "670620",
    "end": "676460"
  },
  {
    "text": "So it's relatively low overhead\nsampling, which is good, because you don't want to\nchange the behavior of your program when you sample it.",
    "start": "676460",
    "end": "683010"
  },
  {
    "text": "Important things to see. So we're looking at this cache\nmiss rate, which is 18%,",
    "start": "683010",
    "end": "692750"
  },
  {
    "text": "almost 19%, L1 cache miss rate,\nwhich is pretty bad. So as a result of that, if\nyou look at the number of",
    "start": "692750",
    "end": "699240"
  },
  {
    "text": "instructions, the number of\ncycles, perf calculates the IPC for you.",
    "start": "699240",
    "end": "704870"
  },
  {
    "text": "We previously talked\nabout CPI. But perf uses IPC, which is\ninstructions per cycle.",
    "start": "704870",
    "end": "710450"
  },
  {
    "text": "So basically, every cycle,\nyou only executed half an instruction on average,\nbecause you're",
    "start": "710450",
    "end": "715890"
  },
  {
    "text": "waiting for the cache. So that's no good. So can anybody remember from\nProject 0 what you did to work",
    "start": "715890",
    "end": "723889"
  },
  {
    "text": "around that? Yes. AUDIENCE: You reordered\nthe loops. GUEST SPEAKER 2: Yes.",
    "start": "723890",
    "end": "729339"
  },
  {
    "text": "So the before and after. You just swap out the\ninner two loops.",
    "start": "729340",
    "end": "735200"
  },
  {
    "text": "And we will run it again.",
    "start": "735200",
    "end": "740370"
  },
  {
    "text": "OK, so remember, the previous\nruntime was 8 seconds. Now it's down to 2.5 seconds,\nwhich is a lot better.",
    "start": "740370",
    "end": "745940"
  },
  {
    "text": "Let's run the perf stat command\nagain and look at the performance counters. And as you can see, the IPC\njumped from 0.49 to 1.4.",
    "start": "745940",
    "end": "754840"
  },
  {
    "text": "So it tripled. And if you look at the new L1\ncache miss rate, it's 1%",
    "start": "754840",
    "end": "761529"
  },
  {
    "text": "rather than 20%, which\nis a lot better.",
    "start": "761530",
    "end": "766670"
  },
  {
    "text": "Yes? AUDIENCE: Can you point to\nwhere the cache miss rate percent is? Because I just see\nzero per second.",
    "start": "766670",
    "end": "772690"
  },
  {
    "text": "GUEST SPEAKER 2: Oh,\nsorry about that. So L1 D-cache loads is all of\nthe times that the CPU asked",
    "start": "772690",
    "end": "778110"
  },
  {
    "text": "the L1 cache for something. And then L1 D-cache\nload misses is the number of cache misses.",
    "start": "778110",
    "end": "784730"
  },
  {
    "text": "So you divide this over this\nto get the ratio, which is",
    "start": "784730",
    "end": "792630"
  },
  {
    "text": "basically what Reid\ndid over here. Does that make sense? AUDIENCE: Yes.",
    "start": "792630",
    "end": "797830"
  },
  {
    "text": "GUEST SPEAKER 2: OK.  So this is a ridiculously simple\nexample of how to use",
    "start": "797830",
    "end": "805520"
  },
  {
    "text": "perf, just so that you can\nsee the command set. But that's not really a very\ninteresting example.",
    "start": "805520",
    "end": "811780"
  },
  {
    "text": "So the next one that we'll look\nat is actually something that Charles, Reid, and I did\nyesterday afternoon for fun.",
    "start": "811780",
    "end": "821650"
  },
  {
    "text": "It started, we were testing\nyour Project 2.1, one which is--",
    "start": "821650",
    "end": "826670"
  },
  {
    "text": "I don't know how many\npeople have looked at the handout yet. But it deals with a bunch of\nmystery sorting algorithms that you have to figure out\nwhat they're doing.",
    "start": "826670",
    "end": "833150"
  },
  {
    "text": "And so we took one of them. And we were running sorting. And Charles asked, what\nhappens if you have a",
    "start": "833150",
    "end": "839200"
  },
  {
    "text": "branchless sorting algorithm? And we said, we don't know. So we played around with it.",
    "start": "839200",
    "end": "844530"
  },
  {
    "text": "And in the process, we optimized\nour branchless sorting algorithm by using perf\nto generate insight into",
    "start": "844530",
    "end": "850760"
  },
  {
    "text": "what the CPU is doing. And as you'll see, we generated quite a good speed-up. So the first thing we'll do\nis, let's start with the",
    "start": "850760",
    "end": "856610"
  },
  {
    "text": "baseline, quicksort,\neverybody's favorite sorting algorithm. So I'll switch over\nto the terminal.",
    "start": "856610",
    "end": "861980"
  },
  {
    "text": "And Reid is going to run\nquicksort on 30 million integers one time, which it\nsays takes 4.14 seconds.",
    "start": "861980",
    "end": "871570"
  },
  {
    "text": "Now, let's use perf stat\nto see what it's doing.",
    "start": "871570",
    "end": "877710"
  },
  {
    "text": "So this time, we will ask for\nslightly different events. We'll still ask for\nthe cycles and instructions to get our IPC.",
    "start": "877710",
    "end": "884089"
  },
  {
    "text": "But we'll also ask for branches\nand branch misses, because we kind of intuitively\nknow that quicksort is doing branching.",
    "start": "884090",
    "end": "892129"
  },
  {
    "text": "So OK. It's doing 0.8 IPC, so 0.8\ninstructions per cycle.",
    "start": "892130",
    "end": "898959"
  },
  {
    "text": "And the branch miss rate, so\nbranch misses over total",
    "start": "898960",
    "end": "904580"
  },
  {
    "text": "number branches, is 11.5%. That's pretty bad in terms\nof branch missing.",
    "start": "904580",
    "end": "910780"
  },
  {
    "text": "So let's take a look\nat the code and see why that's the case. So here's the part of the code\nin quicksort where you select",
    "start": "910780",
    "end": "918480"
  },
  {
    "text": "a pivot recursively, and\nthen you loop, and then you do your swapping.",
    "start": "918480",
    "end": "923680"
  },
  {
    "text": "So these branches are more\nor less unpredictable.",
    "start": "923680",
    "end": "929550"
  },
  {
    "text": "And looking at them, there's no\nway that we could think of to get rid of the unpredictable\nbranches. They're unpredictable\nby nature.",
    "start": "929550",
    "end": "936800"
  },
  {
    "text": "So this would not be an\ninteresting example of which to do branchless sorting. So let's switch to a different\nalgorithm, mergesort.",
    "start": "936800",
    "end": "944570"
  },
  {
    "text": "So here's the relevant code in\nmergesort that takes a list,",
    "start": "944570",
    "end": "950150"
  },
  {
    "text": "C, and two input lists, A and B.\nAnd you merge the contents of A and B into C by taking\nthe smallest element from",
    "start": "950150",
    "end": "957810"
  },
  {
    "text": "either A or B, putting it in\nC, and then repeating that process until the\nlists are empty. So the \"if else\" branches, as\nthe comment says, tries to",
    "start": "957810",
    "end": "966060"
  },
  {
    "text": "place the min of the value\neither at A or B into C, and then properly increment the\npointer and do those",
    "start": "966060",
    "end": "972950"
  },
  {
    "text": "housekeeping tasks so\nyou don't crash. So we're going to try running\nthis and profiling it.",
    "start": "972950",
    "end": "980079"
  },
  {
    "text": " So Reid is running mergesort.",
    "start": "980080",
    "end": "987390"
  },
  {
    "text": "Took 5.04 seconds. Well, the last one\ntook 4.8 seconds. So already, it doesn't\nlook too good.",
    "start": "987390",
    "end": "993459"
  },
  {
    "text": "But let's try to see\nwhat happened. So we'll issue the same perf\nstat command, asking for",
    "start": "993460",
    "end": "1000079"
  },
  {
    "text": "branches, branch\nmisses, cycles. Reid is being lazy. ",
    "start": "1000080",
    "end": "1010670"
  },
  {
    "text": "OK, so the IPC is 1.1, which\nis a little bit better. But if you look at the branch\nmisses over branches, they're",
    "start": "1010670",
    "end": "1019120"
  },
  {
    "text": "off by roughly an order\nof magnitude just like before, so 10%. So OK.",
    "start": "1019120",
    "end": "1025030"
  },
  {
    "text": " Mergesort is currently slower\nthan quicksort.",
    "start": "1025030",
    "end": "1031770"
  },
  {
    "text": "And the reason is still,\nroughly, you still have all of these branches that you're\nnot predicting correctly.",
    "start": "1031770",
    "end": "1038780"
  },
  {
    "text": "OK, so why branching,\nand why not caching? Well, we did some quick\nback-of-the-envelope",
    "start": "1038780",
    "end": "1043930"
  },
  {
    "text": "calculations, or research,\nrather. And it turns out that in the\nNehalem, the processes that",
    "start": "1043930",
    "end": "1049180"
  },
  {
    "text": "you're using on the clouds, one\nof the design changes that Intel made is that they made\nthe L1 cache and, actually,",
    "start": "1049180",
    "end": "1056300"
  },
  {
    "text": "also the L2 cache faster, so\nfewer number of clock cycles to go out to the cache.",
    "start": "1056300",
    "end": "1061870"
  },
  {
    "text": "But at the same time, they also\nmade the pipeline deeper. So an L1 cache miss is maybe\nthree or four cycles.",
    "start": "1061870",
    "end": "1067970"
  },
  {
    "text": "An L2 cache miss is 15 cycles. By the time you miss the L2\ncache, you're going out into L3 cache, which is\n12 megabytes.",
    "start": "1067970",
    "end": "1074250"
  },
  {
    "text": "And if you're sorting integers,\nmost of them are probably going to be\nin there anyway. AUDIENCE: John, those are\nactually hits [INAUDIBLE].",
    "start": "1074250",
    "end": "1080080"
  },
  {
    "text": "GUEST SPEAKER 2: Oh, they are. OK, so misses might be a little\nbit bigger than that.",
    "start": "1080080",
    "end": "1085250"
  },
  {
    "text": "But OK. AUDIENCE: L1 miss is a L2-- GUEST SPEAKER 2: Right,\nis an L2.",
    "start": "1085250",
    "end": "1091020"
  },
  {
    "text": "AUDIENCE: L1 misses. AUDIENCE: It was just a typo. GUEST SPEAKER 2: OK, so the next\nnumber is probably, like,",
    "start": "1091020",
    "end": "1096050"
  },
  {
    "text": "30 to 50, somewhere\non that order. 50-something. OK.",
    "start": "1096050",
    "end": "1101710"
  },
  {
    "text": "But a branch mispredict will\nalso cost you somewhere between 16 and 24 cycles,\ndepending on how many pipeline",
    "start": "1101710",
    "end": "1107890"
  },
  {
    "text": "stages are actually in the\nNehalem, which we don't know. So bad branch predictions might\njust be as costly as bad",
    "start": "1107890",
    "end": "1115809"
  },
  {
    "text": "memory access patterns. And plus, Charles is going to\ngo into detail about memory access patterns and how to\noptimize sorting for good",
    "start": "1115810",
    "end": "1122050"
  },
  {
    "text": "memory access. So it wouldn't be interesting\nif I talked about that right now. So let's optimize branching.",
    "start": "1122050",
    "end": "1127450"
  },
  {
    "text": " So to do that, we'll use a bit\nhack that Charles introduced",
    "start": "1127450",
    "end": "1133669"
  },
  {
    "text": "in an earlier lecture. So remember, all we want to do\nis we want to put the minimum",
    "start": "1133670",
    "end": "1142150"
  },
  {
    "text": "of either A or B into C. So\nright now, we're using branches to do it. But there's no reason\nwhy we have to.",
    "start": "1142150",
    "end": "1148400"
  },
  {
    "text": "So the trick that will apply\nis the XOR trick for calculating min without\na branch.",
    "start": "1148400",
    "end": "1154040"
  },
  {
    "text": "Does everybody kind of follow\nwhat that code is doing? You can refer to the bit hacks\nlecture later to check.",
    "start": "1154040",
    "end": "1161620"
  },
  {
    "text": "But trust us that\nit's correct. GUEST SPEAKER 1: [INAUDIBLE] GUEST SPEAKER 2: All right. I guess we can go over it.",
    "start": "1161620",
    "end": "1169261"
  },
  {
    "text": "Do I have a mouse pointer? Cool. OK, so inside, you're doing a\ncomparing A is less than B,",
    "start": "1169261",
    "end": "1177045"
  },
  {
    "text": "the value of A is less than the\nvalue of B. And you store either a 0 or 1 into\na flag called CMP.",
    "start": "1177045",
    "end": "1182940"
  },
  {
    "text": "And then you take CMP,\nand you negate it. So then you end up with a bit\nmask of either all 0's or all",
    "start": "1182940",
    "end": "1188960"
  },
  {
    "text": "1's, depending on which\none was smaller. And then you mask A\nXOR B with that.",
    "start": "1188960",
    "end": "1195130"
  },
  {
    "text": "So this inner expression, you\neither get A XOR B out of it, or you get all 0's.",
    "start": "1195130",
    "end": "1201090"
  },
  {
    "text": "And then you XOR B into it. So in one case, B XOR this\nexpression cancels out the B.",
    "start": "1201090",
    "end": "1207990"
  },
  {
    "text": "You'll just get A out. And the other way, B XOR 0 is\ngoing to give you B. So that",
    "start": "1207990",
    "end": "1214669"
  },
  {
    "text": "should be convincing motivation\nthat this is actually a min function. And then, once you have that,\nyou can do cute tricks to",
    "start": "1214670",
    "end": "1221580"
  },
  {
    "text": "recycle the flags, to do\nthe A++ and B++ and so on, using CMP.",
    "start": "1221580",
    "end": "1228530"
  },
  {
    "text": "So next, let's run this code\nand see what happens. ",
    "start": "1228530",
    "end": "1240780"
  },
  {
    "text": "OK, so we went from 5.04 seconds\nto 4.59 seconds.",
    "start": "1240780",
    "end": "1249820"
  },
  {
    "text": "And we'll do a profiling run\njust to get some stats on it. ",
    "start": "1249820",
    "end": "1255260"
  },
  {
    "text": "OK, so now look at the IPC. We went from 1.1 to 1.7--",
    "start": "1255260",
    "end": "1261371"
  },
  {
    "text": " 1.7. And branch misses went down by\na factor of 10, which is",
    "start": "1261371",
    "end": "1269179"
  },
  {
    "text": "really awesome. But overall, the performance\ndidn't seem to improve by much.",
    "start": "1269180",
    "end": "1275600"
  },
  {
    "text": "Well, if you want to look at\nwhy, look at the total number of instructions executed.",
    "start": "1275600",
    "end": "1280610"
  },
  {
    "text": "That's that number versus\nthat number. We seem to be executing\nconsiderably more",
    "start": "1280610",
    "end": "1286200"
  },
  {
    "text": "instructions. So to see why that's the case,\nwe decided to use another mode",
    "start": "1286200",
    "end": "1291870"
  },
  {
    "text": "of perf called report, or\nrecord and then report. So what this does is that it\nlogs where all of those",
    "start": "1291870",
    "end": "1300500"
  },
  {
    "text": "interrupts actually happen. So it logs which point in your\ncode the CPU was executing",
    "start": "1300500",
    "end": "1305580"
  },
  {
    "text": "when these performance\ncounters tripped. And then it generates a nice\nreport that we can call using",
    "start": "1305580",
    "end": "1311040"
  },
  {
    "text": "perf annotate. And the top section gives you\na sorted summary, where it",
    "start": "1311040",
    "end": "1317790"
  },
  {
    "text": "shows you the percent of times\nthat perf caught your program executing that line of code. So 11% of the times that perf\ntriggered its interrupt, your",
    "start": "1317790",
    "end": "1326530"
  },
  {
    "text": "code was executing mergesort.c\nline 32. So let's go to mergesort.c\nline 32 and",
    "start": "1326530",
    "end": "1332900"
  },
  {
    "text": "see what it's doing. So this annotated view shows you\nthe lines of C-code, which",
    "start": "1332900",
    "end": "1340000"
  },
  {
    "text": "are in black. C-code is in black. And then line numbers\nare annotated here.",
    "start": "1340000",
    "end": "1346030"
  },
  {
    "text": "And then it actually goes\nahead and shows you the assembly instructions\nthat it's executing.",
    "start": "1346030",
    "end": "1351680"
  },
  {
    "text": "And it puts the timing actually\non the assembly instructions corresponding\nto every C expression. Yes?",
    "start": "1351680",
    "end": "1357546"
  },
  {
    "text": "AUDIENCE: Why is this\n[INAUDIBLE] is the annotated version-- GUEST SPEAKER 2: Yeah, you call\nperf annotate and then a",
    "start": "1357546",
    "end": "1364070"
  },
  {
    "text": "function name. The Project 2.1 will walk\nyou through doing this a couple of times. So you'll be able to see\nwhat it's doing.",
    "start": "1364070",
    "end": "1372169"
  },
  {
    "text": "OK, so the assembly here is\nactually pretty important.",
    "start": "1372170",
    "end": "1378270"
  },
  {
    "text": "I guess everybody's taken 6004,\nor some variant, where you had to code some\nform of assembly?",
    "start": "1378270",
    "end": "1384110"
  },
  {
    "text": "OK, it's a prereq. Cool. So Saman will talk more\nabout assembly.",
    "start": "1384110",
    "end": "1389470"
  },
  {
    "text": "But in this case-- or Charles,\nactually, now will talk more about assembly. But anyway, in this case, it was\nactually kind of useful to",
    "start": "1389470",
    "end": "1396190"
  },
  {
    "text": "look at the assembly. We won't expect you to know how\nto write assembly for this",
    "start": "1396190",
    "end": "1402020"
  },
  {
    "text": "class or expect you to write\nhigh-performing assembly. But sometimes taking a look at\nwhat the compiler outputs can",
    "start": "1402020",
    "end": "1407310"
  },
  {
    "text": "really help you. Well, in this case, what caught\nour eye was this cltq thing, because none of us in\nthe room knew what the heck",
    "start": "1407310",
    "end": "1415600"
  },
  {
    "text": "cltq was It wasn't an\nassembly instruction that you usually see. So that caught our eye. And we wondered what was\nthis assembly doing.",
    "start": "1415600",
    "end": "1422390"
  },
  {
    "text": "So we spent a little bit of\ntime tracing through this, working out what the\ncompiler was doing. So in PowerPoint, I pulled\nout this code.",
    "start": "1422390",
    "end": "1432240"
  },
  {
    "text": "And OK, so I looked up cltq in\nmy 600-page Intel manual.",
    "start": "1432240",
    "end": "1438120"
  },
  {
    "text": "Yes, your processor does\ncome with a manual. So cltq, it says, sign extends\nthe EAX register to 64 bits",
    "start": "1438120",
    "end": "1446170"
  },
  {
    "text": "and then places that into RAX. Why is it sign extending? OK, so let's try to\ntrace through what",
    "start": "1446170",
    "end": "1454180"
  },
  {
    "text": "the assembly's doing. So here, we wanted to do comp\nequals star A less than star",
    "start": "1454180",
    "end": "1459990"
  },
  {
    "text": "B. So it moves the value at\nthe address in register 14",
    "start": "1459990",
    "end": "1465420"
  },
  {
    "text": "into RCX and does the same\nthing for register 13. So assume that R14 and R13 are\nA and B. And so RCX and RDX",
    "start": "1465420",
    "end": "1473519"
  },
  {
    "text": "are star A and star B, right? And then it XORs ESI with\nESI, which is 0.",
    "start": "1473520",
    "end": "1479730"
  },
  {
    "text": "So it zeroes out the\nregister ESI. And then it does a compare\nbetween RCX and RDX, which is",
    "start": "1479730",
    "end": "1486410"
  },
  {
    "text": "the value at A and the value\nat B. So it does that comparison. And then, depending on the\nresult of that comparison, it",
    "start": "1486410",
    "end": "1492250"
  },
  {
    "text": "writes that result out\ninto register SIL-- GUEST SPEAKER 1: Which\nis the low-byte--",
    "start": "1492250",
    "end": "1498090"
  },
  {
    "text": "GUEST SPEAKER 2: SIL, as Reid\nsaid, is the low-byte of the register ESI, which\nis used here.",
    "start": "1498090",
    "end": "1504009"
  },
  {
    "text": "But before that, the compiler\nthen executes this expression here, B XOR a, which it puts\ninto register RDX.",
    "start": "1504010",
    "end": "1514210"
  },
  {
    "text": "And then, finally, it takes ESI,\nwhich contains the same value as SIL, and then it\nmoves that into EAX.",
    "start": "1514210",
    "end": "1521830"
  },
  {
    "text": "And then it negates EAX. OK, so that kind of looks like\nnegative CMP, right?",
    "start": "1521830",
    "end": "1527024"
  },
  {
    "text": "And then, after negating it, it\nthen sign extends it to a 64-bit register.",
    "start": "1527025",
    "end": "1532900"
  },
  {
    "text": "And then it does the en masse\nthat we asked it to. Well, why is it jumping\nthrough so many hoops to do this?",
    "start": "1532900",
    "end": "1539010"
  },
  {
    "text": "Well, it turns out, when you\ndeclare a value of type int, you say that it's\na 32-bit value.",
    "start": "1539010",
    "end": "1545039"
  },
  {
    "text": "And the compiler took you very\nliterally in saying that you requested a 32-bit value. So it did a 32-bit negation.",
    "start": "1545040",
    "end": "1552060"
  },
  {
    "text": "And then it extended\nthat to 64-bits. So it wasted a couple of\ninstructions doing this,",
    "start": "1552060",
    "end": "1557620"
  },
  {
    "text": "instead of just flat-out\ndoing a 64-bit negation to begin with. Now, the problem with this is\nusually you don't care if it",
    "start": "1557620",
    "end": "1565000"
  },
  {
    "text": "generates one XOR assembly\ninstruction. But this is a tight loop that's\ncalled in the recursion",
    "start": "1565000",
    "end": "1570380"
  },
  {
    "text": "process for every single\nmerge that it's doing. So the time that it wastes here\nactually really adds up.",
    "start": "1570380",
    "end": "1576330"
  },
  {
    "text": "So how do we fix that? Well, instead of declaring\nit as int, let's just try",
    "start": "1576330",
    "end": "1581390"
  },
  {
    "text": "replacing it with long, and then\nrecompiler the code and see if things are\nany different. So here we start our process\nof trial and error.",
    "start": "1581390",
    "end": "1590799"
  },
  {
    "text": "So we compiled mergesort long. And the runtime is\n4.05 seconds.",
    "start": "1590800",
    "end": "1598010"
  },
  {
    "text": "Before, it was, like,\n4.5 or so. So the runtime definitely\nimproved.",
    "start": "1598010",
    "end": "1603830"
  },
  {
    "text": "Let's compare it. GUEST SPEAKER 1: Yeah,\njust to verify. GUEST SPEAKER 2: So it went\nfrom 4.59 to 4.05, which",
    "start": "1603830",
    "end": "1609860"
  },
  {
    "text": "definitely is an improvement. So let's figure out, well,\nlet's see if it generated",
    "start": "1609860",
    "end": "1615380"
  },
  {
    "text": "better assembly. So we'll run perf record\nin order to look at",
    "start": "1615380",
    "end": "1620880"
  },
  {
    "text": "perf annotate again.  And OK, once again, it's\nspending 14% of the time",
    "start": "1620880",
    "end": "1627870"
  },
  {
    "text": "somewhere in mergesort.c, which\nis hardly surprising. We'll go to line 27 and,\nyeah, use long.",
    "start": "1627870",
    "end": "1640620"
  },
  {
    "text": "OK, so that's roughly\nthe assembly. And Reid, although he wasted\ntime to find it, I have a",
    "start": "1640620",
    "end": "1648910"
  },
  {
    "text": "nicely prepared screen shot of\nthe same section of code. So it looks cleaner.",
    "start": "1648910",
    "end": "1654010"
  },
  {
    "text": " It loads A and B into different\nregisters this time,",
    "start": "1654010",
    "end": "1660390"
  },
  {
    "text": "actually, RSI and RCX. And then it clears out EDX. And then it does the compare\nbetween RSI and RCX, which is",
    "start": "1660390",
    "end": "1668640"
  },
  {
    "text": "A and B. And then it\nsets percent DL. Now, percent DL is the\nlower byte of EDX.",
    "start": "1668640",
    "end": "1676070"
  },
  {
    "text": "So it used a different\nchoice of registers. And then it did the A XOR B.\nAnd then it moved that",
    "start": "1676070",
    "end": "1684660"
  },
  {
    "text": "compare into RAX. GUEST SPEAKER 1: [INAUDIBLE] GUEST SPEAKER 2: OK, and Reid\nactually has a longer snippet",
    "start": "1684660",
    "end": "1691080"
  },
  {
    "text": "of the code. And the compiler, actually, now\nthat we told it that it",
    "start": "1691080",
    "end": "1696400"
  },
  {
    "text": "was a 64-bit flag, the compiler\nrealized that there's a couple optimizations\nthat it could do. So it switched around the order\nof things a little bit.",
    "start": "1696400",
    "end": "1703340"
  },
  {
    "text": "And it's recycling the value\nof RDX for loading, I think",
    "start": "1703340",
    "end": "1708570"
  },
  {
    "text": "it's A+ equals comp. It's recycling the\nvalue RDX that it generated out of a compare.",
    "start": "1708570",
    "end": "1713980"
  },
  {
    "text": "And now, down there, it's\nnegating RAX as a 64-bit number and directly using it\nwithout that cltq instruction.",
    "start": "1713980",
    "end": "1722240"
  },
  {
    "text": "So that was kind of nice. So in just nudging the compiler\na little bit, we got",
    "start": "1722240",
    "end": "1727270"
  },
  {
    "text": "it to produce code that ran\nroughly about 10% faster,",
    "start": "1727270",
    "end": "1734160"
  },
  {
    "text": "which was surprising to us,\nactually, that changing a single int to a long\ncould reduce the runtime by that amount.",
    "start": "1734160",
    "end": "1741380"
  },
  {
    "text": "So next thing that we did was we\nscrolled down a little bit more on this window. And we looked at the\nnext thing that the",
    "start": "1741380",
    "end": "1746920"
  },
  {
    "text": "compiler was doing. And we kind of caught\nthe compiler again doing something silly.",
    "start": "1746920",
    "end": "1752870"
  },
  {
    "text": "So here's the code\nthat we were at before, the compare code.",
    "start": "1752870",
    "end": "1758240"
  },
  {
    "text": "And now let's look at how the\ncompiler did B+ equals CMP.",
    "start": "1758240",
    "end": "1764510"
  },
  {
    "text": "Once again, the reason that we\nstopped and looked at this code was we saw an instruction\nthat we didn't recognize, SBB.",
    "start": "1764510",
    "end": "1771759"
  },
  {
    "text": "Well, we looked at\nthe manual again. And SBB of R1 and R2 is a\nsubtract with a borrow bit.",
    "start": "1771760",
    "end": "1779080"
  },
  {
    "text": "So it does subtracting the two\narguments and then subtracting a carry flag from that.",
    "start": "1779080",
    "end": "1786270"
  },
  {
    "text": "So OK, why's it doing that? Well, let's walk through what\nthe compiler tried to do. ",
    "start": "1786270",
    "end": "1793130"
  },
  {
    "text": "Let's see, where's a good\nplace to start? So it's RDX in this compare.",
    "start": "1793130",
    "end": "1799370"
  },
  {
    "text": "So it compares RDX to 1. RDX is where CMP was stored.",
    "start": "1799370",
    "end": "1804669"
  },
  {
    "text": "So it checks whether or\nnot it equals to 1. And then the result of that\ncheck is actually stored in",
    "start": "1804670",
    "end": "1811460"
  },
  {
    "text": "the carry flag, CF. And subtract with borrow,\nRAX, RAX.",
    "start": "1811460",
    "end": "1816960"
  },
  {
    "text": "Before, RAX held the value of B.\nBut now, since it did this, RAX minus RAX is 0, right?",
    "start": "1816960",
    "end": "1823820"
  },
  {
    "text": "And then minus the carry flag\nis either 0 or negative 1, depending on the value\nof the compare.",
    "start": "1823820",
    "end": "1830270"
  },
  {
    "text": "So once again, it generates a\nregister that's either all 0's or all 1's, 64 bits.",
    "start": "1830270",
    "end": "1838380"
  },
  {
    "text": "Now, what did it go\nand do with that? Well, jump down a little bit\nlater on in the code. And it ends EAX, which is the\n32-bit version of RAX, with",
    "start": "1838380",
    "end": "1847860"
  },
  {
    "text": "the value of 8 in hexadecimal. So now it's either all\n0's, or it's 8.",
    "start": "1847860",
    "end": "1854690"
  },
  {
    "text": "And then it adds that\nvalue, EAX, which",
    "start": "1854690",
    "end": "1860570"
  },
  {
    "text": "is the same as RAX-- RAX is a 64-bit version-- it adds that value to RBP, which\nstored the address of B.",
    "start": "1860570",
    "end": "1869050"
  },
  {
    "text": "So it jumped through that many\nhoops just to increment B by either 8 or 0.",
    "start": "1869050",
    "end": "1875420"
  },
  {
    "text": "Now, this seems a little\nbit unnecessary. So we thought, how else could we\nexpress B+ equals not CMP,",
    "start": "1875420",
    "end": "1882540"
  },
  {
    "text": "and try to change the code\naround a little bit so that it does the same thing, but hope\nthat the compiler treats it",
    "start": "1882540",
    "end": "1888260"
  },
  {
    "text": "differently. Well, in this case, not CMP,\nwhen CMP is either 1 or 0, is",
    "start": "1888260",
    "end": "1893980"
  },
  {
    "text": "the same thing as 1 minus CMP. ",
    "start": "1893980",
    "end": "1899770"
  },
  {
    "text": "Well, we compiled a version\nof this code, and then we tried to run it. ",
    "start": "1899770",
    "end": "1912800"
  },
  {
    "text": "Refreshing our memory, mergesort\nminus, where we just did the minus sign.",
    "start": "1912800",
    "end": "1921360"
  },
  {
    "text": "So we took the runtime\ndown from 4.04 seconds to 3.77 seconds.",
    "start": "1921360",
    "end": "1927450"
  },
  {
    "text": "And once again, this is just\nfrom replacing a not CMP to a",
    "start": "1927450",
    "end": "1934940"
  },
  {
    "text": "1 minus CMP. That's all the code change\nthat we made. ",
    "start": "1934940",
    "end": "1940669"
  },
  {
    "text": "And we will look at the\nannotation again, just to make",
    "start": "1940670",
    "end": "1945740"
  },
  {
    "text": "sure that the compiler generated\ndifferent code. Rather, we were curious\nof what the compiler generated this time.",
    "start": "1945740",
    "end": "1952900"
  },
  {
    "text": "So it's roughly this\nsection of code. ",
    "start": "1952900",
    "end": "1959680"
  },
  {
    "text": "Now, one thing you'll\nnotice is, because we're compiling with-- this is already compiling with\nGCC's maximum optimization",
    "start": "1959680",
    "end": "1965450"
  },
  {
    "text": "level, mind you. So keep that in mind when you\nassume that the compiler is going to help you out\nand do smart things.",
    "start": "1965450",
    "end": "1972919"
  },
  {
    "text": "So the instructions are a\nlittle bit out of order compared to what you\nmight expect. ",
    "start": "1972920",
    "end": "1982584"
  },
  {
    "text": "All right, so I'll\ngo to my prepared screen shot of the code. So what did it generate\nthis time?",
    "start": "1982584",
    "end": "1990299"
  },
  {
    "text": "All right, so already, this code\nlooks shorter than the previous one, right? ",
    "start": "1990300",
    "end": "1997040"
  },
  {
    "text": "A little bit less\nhairy than that. So what did it do? Well, SIL, once again, is\nthe lower byte of RSI.",
    "start": "1997040",
    "end": "2005810"
  },
  {
    "text": "So it does the compare RCX with\nRDX, which is actually this comparison. And then it saves\nthat into SIL.",
    "start": "2005810",
    "end": "2013110"
  },
  {
    "text": "And now, later, it\ndoes the XOR. So this was the code\nfrom before.",
    "start": "2013110",
    "end": "2019810"
  },
  {
    "text": "And then it does a move of RSI,\nwhich contains the same value as SIL, which is\nCMP's either 1 or 0.",
    "start": "2019810",
    "end": "2027380"
  },
  {
    "text": "It moves that into RAX.  And then, later on, it uses\nRAX for one calculation.",
    "start": "2027380",
    "end": "2040679"
  },
  {
    "text": "And then it also uses the value\nthat's already in RSI. And it subtracts that from\nregister 14, which is where it",
    "start": "2040680",
    "end": "2047580"
  },
  {
    "text": "decided to store the value of\nB. So that's a much more direct way to either subtract 0\nor 1, actually get just 0 or",
    "start": "2047580",
    "end": "2054040"
  },
  {
    "text": "1, and then use it for\na subtraction. So the end result, and something\nelse to point out,",
    "start": "2054040",
    "end": "2059679"
  },
  {
    "text": "is that the move and subtract\ncommands have a little bit of instruction level parallelism,\nbecause right",
    "start": "2059679",
    "end": "2066199"
  },
  {
    "text": "after you set [? LE ?] SIL, as soon as that's done, you\ncan execute both the move and the subtract at the same\ntime, since they use the same",
    "start": "2066199",
    "end": "2073540"
  },
  {
    "text": "source register and put in different destination registers. And the other thing to notice\nin the comparison is the",
    "start": "2073540",
    "end": "2080219"
  },
  {
    "text": "number of ALU operations. I'll go back to the\noriginal one. You see negate, and, XOR, add.",
    "start": "2080219",
    "end": "2088908"
  },
  {
    "text": "So move is not an ALU. It's not an arithmetic\noperation. But everything else is either\nXOR, and, add, or subtract, or",
    "start": "2088909",
    "end": "2096099"
  },
  {
    "text": "compare, which all\nuse the ALU. Now, if you look at the code\nover here, you have move,",
    "start": "2096100",
    "end": "2103130"
  },
  {
    "text": "move, move, which don't\nneed the ALU. And then the other or four\nor five need the ALU.",
    "start": "2103130",
    "end": "2110300"
  },
  {
    "text": "But having fewer ALU\nop is a good thing. If you remember from the\nprevious lecture on CPU",
    "start": "2110300",
    "end": "2116440"
  },
  {
    "text": "architecture, the Nehalem,\nhas six execution ports. So it can execute six micro-ops\nin parallel per CPU",
    "start": "2116440",
    "end": "2123770"
  },
  {
    "text": "clock cycle. Actually, only three of those\nexecution ports have ALUs on them, so that they can actually\ndo XOR, at, and,",
    "start": "2123770",
    "end": "2132120"
  },
  {
    "text": "subtract, add, and so on. The rest of them can do register\nmoves and a couple of other things, but not arithmetic\noperations.",
    "start": "2132120",
    "end": "2140760"
  },
  {
    "text": "So that's a good thing. So that's an explanation of why\nthe code actually sped up.",
    "start": "2140760",
    "end": "2145900"
  },
  {
    "text": "Now, just as an overview of what\nwe were able to do, we",
    "start": "2145900",
    "end": "2151039"
  },
  {
    "text": "ran perf stat, the same thing\nthat we did for mergesort, or for the original\ntwo mergesorts.",
    "start": "2151040",
    "end": "2157050"
  },
  {
    "text": "And we made a table of the\nimprovements that we made. So originally, quicksort\nran in four seconds.",
    "start": "2157050",
    "end": "2163240"
  },
  {
    "text": "And it had an IPC of 0.8\nand 11% branch missing.",
    "start": "2163240",
    "end": "2168420"
  },
  {
    "text": "So when we switched from\nquicksort to standard mergesort, we increased\nexecution time by 20%, which",
    "start": "2168420",
    "end": "2175610"
  },
  {
    "text": "is not good. But the instructions per clock\njumped up a little bit.",
    "start": "2175610",
    "end": "2180809"
  },
  {
    "text": "Branch miss rate is\nstill pretty bad. Now, as soon as we switched it\nto branchless, we got an 8%",
    "start": "2180810",
    "end": "2186980"
  },
  {
    "text": "improvement over the\nprevious runtime. But note that we were still\nworse off than quicksort at",
    "start": "2186980",
    "end": "2192119"
  },
  {
    "text": "that point.  But the instructions per clock\njumped quite a bit from last",
    "start": "2192120",
    "end": "2198710"
  },
  {
    "text": "time, which is kind of what you\nwould expect with reducing the branch misses by\na factor of 10.",
    "start": "2198710",
    "end": "2204230"
  },
  {
    "text": "So the CPU isn't spending\nextra time stalling the pipeline, trying to backtrack\non its branch mispredicts.",
    "start": "2204230",
    "end": "2211880"
  },
  {
    "text": "And now the more interesting\nthing to me is, if you look at",
    "start": "2211880",
    "end": "2216890"
  },
  {
    "text": "the two silly little compiler\noptimizations we made, switching from int to long\nreduced the runtime by 11%",
    "start": "2216890",
    "end": "2225930"
  },
  {
    "text": "over the previous branchless\nimplementation. And then instructions per clock\nand branch miss both",
    "start": "2225930",
    "end": "2233090"
  },
  {
    "text": "didn't change at this point. At this point, we were just\nreducing the number of instructions. And then going from there to\nchanging not CMP to 1 minus",
    "start": "2233090",
    "end": "2243339"
  },
  {
    "text": "CMP reduced our runtime by\nanother 7% from before.",
    "start": "2243340",
    "end": "2249020"
  },
  {
    "text": "So overall, branchless\nmergesorting is 10.8% faster than quicksorting by the time we\nwere done optimizing, which",
    "start": "2249020",
    "end": "2257010"
  },
  {
    "text": "is a lot better than negative. At this point, we were\nstill behind.",
    "start": "2257010",
    "end": "2262550"
  },
  {
    "text": "And at the end, we ended\nup ahead of quicksort. And then, overall, switching\nto branchless, with all the",
    "start": "2262550",
    "end": "2269300"
  },
  {
    "text": "performance tweaks that we made,\nwas 33.6% better over the branching version.",
    "start": "2269300",
    "end": "2275170"
  },
  {
    "text": "So the non-branching ran\na third faster than the branching version, which\nis pretty cool.",
    "start": "2275170",
    "end": "2281869"
  },
  {
    "text": "And that's something that\nwe learned at the end of the day yesterday. So to conclude, what did we\nlearn when we were doing this?",
    "start": "2281870",
    "end": "2290630"
  },
  {
    "text": "Well, I think a lot of that\napplies to the PSETS that you're doing and how you should\ngo about optimizing",
    "start": "2290630",
    "end": "2296720"
  },
  {
    "text": "performance on the code\nthat we give you. And it's profile before\nyou optimize.",
    "start": "2296720",
    "end": "2302190"
  },
  {
    "text": "So before you spend too much\ntime just reading through source code and making wild\nguesses as to why the code is",
    "start": "2302190",
    "end": "2308930"
  },
  {
    "text": "slow, profile the code. See why it's actually slow. Get some performance\ncounter data.",
    "start": "2308930",
    "end": "2315280"
  },
  {
    "text": "Do some perf annotate, so that\nit tells you what assembly or what line of code that it's\nactually spending",
    "start": "2315280",
    "end": "2321400"
  },
  {
    "text": "the most time on. And then, optimize\niteratively. Don't try to do everything\nat once. Do things one at a time to see\nwhether or not they make a",
    "start": "2321400",
    "end": "2328480"
  },
  {
    "text": "difference. Now, before we arrived at the\nnot, there are so many different ways that you could\nhave expressed not and 1 minus",
    "start": "2328480",
    "end": "2336200"
  },
  {
    "text": "and negative and so on. So if you try them all at once,\nyou really don't know what made the improvement.",
    "start": "2336200",
    "end": "2341259"
  },
  {
    "text": "So you've got to try things one\nat a time and see what it causes the compiler to do,\nbecause you can see in the",
    "start": "2341260",
    "end": "2348640"
  },
  {
    "text": "previous two examples, by the\ntime we made that one optimization, it wasn't just\nthat one assembly instruction",
    "start": "2348640",
    "end": "2353740"
  },
  {
    "text": "that the compiler ended\nup changing. The compiler, in fact, realized\nthat it could do additional optimizations on top\nof what we hinted to it.",
    "start": "2353740",
    "end": "2361250"
  },
  {
    "text": "So it did even more\noptimizations. But the bottom line is, you\nshould optimize iteratively.",
    "start": "2361250",
    "end": "2366550"
  },
  {
    "text": "Try something, and see what\neffect it has before moving on and trying something else. And then, as much as I don't\nlike coding assembly, and I",
    "start": "2366550",
    "end": "2375250"
  },
  {
    "text": "don't expect that anybody here\ncodes assembly for the class, looking at the assembly is\nalways a good thing.",
    "start": "2375250",
    "end": "2381160"
  },
  {
    "text": "Just skim through it for your\nperformance bottlenecks. And try to get an idea of\nwhat the compiler is",
    "start": "2381160",
    "end": "2387070"
  },
  {
    "text": "asking the CPU to do. And see if there's a way that\nyou can nudge the compiler to do the right thing.",
    "start": "2387070",
    "end": "2393240"
  },
  {
    "text": "Sometimes we tell you the\ncompiler will optimize certain things, will get rid of\ndead code, and so on.",
    "start": "2393240",
    "end": "2398320"
  },
  {
    "text": "And most of the time, that's\nactually true. But it doesn't hurt to\ndouble-check in the assembly and make sure that it's\nactually doing that.",
    "start": "2398320",
    "end": "2404930"
  },
  {
    "text": "And the output from perf is\npretty helpful to doing this. It's not a monumental task\nof disassembling.",
    "start": "2404930",
    "end": "2411799"
  },
  {
    "text": "It does all of the annotation\nand interleaving for you. And finally, learn\nthrough practice.",
    "start": "2411800",
    "end": "2418210"
  },
  {
    "text": "That's the only way to learn\nhow to do this performance optimization. You gain a lot of experience\nfrom just going out",
    "start": "2418210",
    "end": "2424580"
  },
  {
    "text": "and trying the tools. And Project 2 will have you\nworking with these tools. Project 2.1 does not have\na code submission.",
    "start": "2424580",
    "end": "2432500"
  },
  {
    "text": "It's just a write-up, where you\nget to just play around with the tools on code that we\ngive you, so you can see how",
    "start": "2432500",
    "end": "2438430"
  },
  {
    "text": "to use the tools. And then Project 2.2, which is\ngoing out next week, will",
    "start": "2438430",
    "end": "2443550"
  },
  {
    "text": "actually give you a chance to\ntry to optimize code that we give you, using these tools to\nhelp you out along the way.",
    "start": "2443550",
    "end": "2450760"
  },
  {
    "text": "So with that said, any\nquestions about-- AUDIENCE: [INAUDIBLE]\na write-up.",
    "start": "2450760",
    "end": "2456571"
  },
  {
    "text": "how do you submit write-ups\nfor projects? GUEST SPEAKER 2: On Stellar. So the handouts for the\nwrite-ups are Stellar homework",
    "start": "2456571",
    "end": "2465000"
  },
  {
    "text": "assignments. Just upload a PDF to Stellar. AUDIENCE: OK.",
    "start": "2465000",
    "end": "2470320"
  },
  {
    "text": "GUEST SPEAKER 2: Yes? AUDIENCE: [INAUDIBLE PHRASE] ",
    "start": "2470320",
    "end": "2479849"
  },
  {
    "text": "GUEST SPEAKER 1: Yeah, you just\nhave to build the binary with debug info. GUEST SPEAKER 2: Yeah,\nminus G is enough. As long as GDB's break points\ncan see your code,",
    "start": "2479850",
    "end": "2489100"
  },
  {
    "text": "then perf can do it. ",
    "start": "2489100",
    "end": "2494420"
  },
  {
    "text": "And it's actually pretty nice in\nthat, even if your code is inlined, it can identify where\nthe inlined portions came from",
    "start": "2494420",
    "end": "2500840"
  },
  {
    "text": "and pull in the proper lines\nof code for that. SAMAN AMARASINGHE: I think\nwhat's really interesting and",
    "start": "2500840",
    "end": "2505849"
  },
  {
    "text": "important here is not that they\nfound this interesting thing, but the process\nthey went about.",
    "start": "2505850",
    "end": "2510940"
  },
  {
    "text": "A lot of times, when you are\ncoding, you are in control. You have very planned structure\nhow you're going",
    "start": "2510940",
    "end": "2516920"
  },
  {
    "text": "about doing that. And you follow these through and\nproduce the code you want. And sometimes, some pesky\nbugs show up.",
    "start": "2516920",
    "end": "2522440"
  },
  {
    "text": "You go through that. Here is, basically, you\nbasically let the system and",
    "start": "2522440",
    "end": "2528470"
  },
  {
    "text": "data drive what you are doing. And when you start, there's no\nplanned part, saying, I'm",
    "start": "2528470",
    "end": "2534670"
  },
  {
    "text": "going to do A, B, C, D.\nBasically, you look at the results, and you figure\nout what might change.",
    "start": "2534670",
    "end": "2540180"
  },
  {
    "text": "And you can go through that. And I was actually talking with\nCharles, saying, in my",
    "start": "2540180",
    "end": "2545390"
  },
  {
    "text": "first lecture, I talked\nabout Matrix Multiply. It looks really cool. Every time I do something, it\nimproved by a factor of 2,",
    "start": "2545390",
    "end": "2552080"
  },
  {
    "text": "50%, stuff like that. What you didn't see is all the\nthings I did that didn't have",
    "start": "2552080",
    "end": "2557670"
  },
  {
    "text": "any impact on the program. You saw this nice tree going\ndown there, all these leaves",
    "start": "2557670",
    "end": "2563240"
  },
  {
    "text": "that end up in dead ends, that\nhad nothing happened. So if you feel like when you\ngo there, you do a bunch of",
    "start": "2563240",
    "end": "2569700"
  },
  {
    "text": "things, nothing happens,\nthat's normal. Of course, when you tell\nsomebody, you're not going to say, oh, that [UNINTELLIGIBLE].",
    "start": "2569700",
    "end": "2575539"
  },
  {
    "text": "Say, I did this [UNINTELLIGIBLE], and I did that. And at the end, it looks like\nthese other people are very smart, and they're getting\nthrough all these",
    "start": "2575540",
    "end": "2581570"
  },
  {
    "text": "optimizations. No, they spend a lot of\ntime going through these dead end parts. And the interesting thing in\nhere is, one thing is, don't",
    "start": "2581570",
    "end": "2590559"
  },
  {
    "text": "trust anything. [UNINTELLIGIBLE PHRASE] Intel, they have hundreds\nof engineers",
    "start": "2590560",
    "end": "2596150"
  },
  {
    "text": "working at it for years. And OK, that should be good. Not really.",
    "start": "2596150",
    "end": "2602210"
  },
  {
    "text": "So a lot of times, it's\nan end-to-end thing. With performance,\nit's end to end. So the problem can\nbe at any level.",
    "start": "2602210",
    "end": "2609030"
  },
  {
    "text": "So it could become a compiler,\nit could be [UNINTELLIGIBLE] network, it can be network, it\ncan be an operating system, it can be in the memory system, it\ncan be in the processor, it",
    "start": "2609030",
    "end": "2615795"
  },
  {
    "text": "can be anything. So if you say, oh, yeah, that\nshouldn't be the case, probably that's where it is. So all the time, basically,\nit's interesting.",
    "start": "2615795",
    "end": "2622350"
  },
  {
    "text": "The nice thing about these\nkind of tools is that sometimes even the tools\nmight be wrong.",
    "start": "2622350",
    "end": "2628080"
  },
  {
    "text": "So sometimes I have been in\nsituations where you look have to look at the wall clock, OK,\nwait a minute, does the tool say what I actually see\nwhat's happening?",
    "start": "2628080",
    "end": "2633839"
  },
  {
    "text": "Because you get into very\nskeptical situations. Because a lot of times, in these\nkind of situations, the",
    "start": "2633840",
    "end": "2640960"
  },
  {
    "text": "problem can be hidden in\nmany different things. So that's a very good way\nof going through this.",
    "start": "2640960",
    "end": "2646500"
  },
  {
    "text": "Of course, what you get handed\nto you, we have set it up in a way that there cannot be\ntoo many surprises.",
    "start": "2646500",
    "end": "2652660"
  },
  {
    "text": "But when you're going through\na system and try to optimize and look at performance, this is\na really good way of doing",
    "start": "2652660",
    "end": "2658590"
  },
  {
    "text": "it, because I don't think these\nguys thought, when they started, they'd be looking\nat compiled bugs or compiler problems.",
    "start": "2658590",
    "end": "2665750"
  },
  {
    "text": "They were thinking about, OK,\nI'm going to do a little bit of code rewriting\nand get there. But at the end of the day, what\nthey disclosed was very",
    "start": "2665750",
    "end": "2672080"
  },
  {
    "text": "surprising to them. And it even surprised\nme today. GUEST SPEAKER 2: Our plan\nbasically ended at row three, as far as when we\nfirst set out.",
    "start": "2672080",
    "end": "2678110"
  },
  {
    "text": "We had no idea was to\nfollow after that. So one thing that I remember is\nthat some students came to",
    "start": "2678110",
    "end": "2684599"
  },
  {
    "text": "us and asked questions, like,\nyeah, I tried to implement this bit hack here,\nand it actually slowed the program down.",
    "start": "2684600",
    "end": "2690580"
  },
  {
    "text": "Or I changed my pentomino board representation to this also.",
    "start": "2690580",
    "end": "2696440"
  },
  {
    "text": "But it didn't seem to\nspeed anything up. Well, in those cases, yeah, you\nneed to do more detective",
    "start": "2696440",
    "end": "2701540"
  },
  {
    "text": "work to figure out\nwhat happened. SAMAN AMARASINGHE: So a lot of\ntimes, the performance is something like a max of a bunch\nof different things.",
    "start": "2701540",
    "end": "2709790"
  },
  {
    "text": "So you have done something,\nthat's great. It should give you a huge\nperformance improvement. But something is holding.",
    "start": "2709790",
    "end": "2715380"
  },
  {
    "text": "And a lot of times, you have\nto do three or four things. And once you do three or four\nthings, suddenly everything starts kicking off.",
    "start": "2715380",
    "end": "2723430"
  },
  {
    "text": "A good example is loop unroll. You unroll a loop and say,\nha, I should get all this parallelism. No, because you have\nsome dependence.",
    "start": "2723430",
    "end": "2729290"
  },
  {
    "text": "So you have to fix that\ndependence, fix that dependence. Suddenly, you remove\neverything. Then you get all the\nparallelism and",
    "start": "2729290",
    "end": "2734930"
  },
  {
    "text": "start running fast. So a lot of these things,\nit's basically max. You have to get all\nthe things right.",
    "start": "2734930",
    "end": "2740200"
  },
  {
    "text": "And so if you stop halfway\nthrough, that means you might be almost there, and you\nare not up to that.",
    "start": "2740200",
    "end": "2745540"
  },
  {
    "text": "So that's why it just can be a\nreally frustrating process. But it's kind of fun, too,\nwhen you get there.",
    "start": "2745540",
    "end": "2751630"
  },
  {
    "start": "2751630",
    "end": "2753748"
  }
]
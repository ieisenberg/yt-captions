[
  {
    "start": "0",
    "end": "83000"
  },
  {
    "start": "5500",
    "end": "5500"
  },
  {
    "text": "Why does going to the airport seem to require\nextra time compared with coming back from",
    "start": "5500",
    "end": "9600"
  },
  {
    "text": "the airport even if the traffic is the same\nin both directions? The answer must somehow",
    "start": "9600",
    "end": "15080"
  },
  {
    "text": "depend on more than just the average travel\ntime, which we’re assuming is the same and",
    "start": "15080",
    "end": "19900"
  },
  {
    "text": "often is. In fact, it depends on the distribution\nof travel times. Probability distributions",
    "start": "19900",
    "end": "27760"
  },
  {
    "text": "are fully described by listing or graphing\nevery probability. For example, how likely",
    "start": "27769",
    "end": "32980"
  },
  {
    "text": "is a journey to the airport to be between\n10 and 20 minutes? How likely is a 20—30",
    "start": "32980",
    "end": "38350"
  },
  {
    "text": "minute journey? A 30—40 minute journey?\nAnd so on. We’ll answer the airport question",
    "start": "38350",
    "end": "43550"
  },
  {
    "text": "at the end of the video.",
    "start": "43550",
    "end": "45590"
  },
  {
    "text": "This video is part of the Probability and\nStatistics video series. Many natural and",
    "start": "45590",
    "end": "50379"
  },
  {
    "text": "social phenomena are probabilistic in nature.\nEngineers, scientists, and policymakers often",
    "start": "50379",
    "end": "55960"
  },
  {
    "text": "use probability to model and predict system\nbehavior.",
    "start": "55960",
    "end": "59390"
  },
  {
    "text": "Hi, my name is Sanjoy Mahajan, and I’m a\nprofessor of Applied Science and Engineering",
    "start": "59390",
    "end": "64720"
  },
  {
    "text": "at Olin College. Before watching this video,\nyou should be proficient with integration",
    "start": "64720",
    "end": "70420"
  },
  {
    "text": "and have some familiarity with probabilities.",
    "start": "70420",
    "end": "74020"
  },
  {
    "text": "After watching this video, you will be able\nto:",
    "start": "74020",
    "end": "76920"
  },
  {
    "text": "Explain what moments of distributions are,\nand",
    "start": "76920",
    "end": "80140"
  },
  {
    "text": "Compute moments and understand what they mean",
    "start": "80140",
    "end": "85400"
  },
  {
    "text": "To illustrate what a probability distribution\nis, lets consider rolling two fair dice. The",
    "start": "87658",
    "end": "94658"
  },
  {
    "text": "probability distribution of their sum is this\ntable. For example, the only way to get a",
    "start": "94670",
    "end": "99548"
  },
  {
    "text": "sum of two is to roll a 1 on each die. And,\nthere are 36 possible rolls for a pair of",
    "start": "99549",
    "end": "106329"
  },
  {
    "text": "dice. So, getting a sum of two has a probability\nof 1 over 36. The probability of rolling a",
    "start": "106329",
    "end": "113329"
  },
  {
    "text": "sum of 3 is 2 over 36. And so on and so forth.\nYou can fill in a table like this yourself.",
    "start": "113880",
    "end": "120880"
  },
  {
    "text": "But the whole distribution, even for something\nas simple as two dice, is usually too much",
    "start": "121090",
    "end": "126218"
  },
  {
    "text": "information.",
    "start": "126219",
    "end": "127860"
  },
  {
    "text": "We often want to characterize the shape of\nthe distribution using only a few numbers.",
    "start": "127860",
    "end": "132790"
  },
  {
    "text": "Of course, that throws away information, but\nthrowing away information is the only way",
    "start": "132790",
    "end": "139700"
  },
  {
    "text": "to fit the complexity of the world into our\nbrains.",
    "start": "139700",
    "end": "143200"
  },
  {
    "text": "The art comes in keeping the most important\ninformation. Finding the moments of a distribution",
    "start": "143200",
    "end": "149040"
  },
  {
    "text": "can help us reach our goal. Two moments that\nyou are probably already familiar with are",
    "start": "149040",
    "end": "154959"
  },
  {
    "text": "mean and variance. They are the two most important\nmoments of distributions.",
    "start": "154959",
    "end": "159690"
  },
  {
    "text": "Let’s define these moments more formally.\nThe mean is the first moment of a distribution.",
    "start": "159690",
    "end": "167150"
  },
  {
    "text": "It is also called the expected value and is\ncomputed as shown. Expected value of x, that’s",
    "start": "167150",
    "end": "174599"
  },
  {
    "text": "x with angled brackets around it, is equal\nto this sum. It’s the weighted sum of all",
    "start": "174599",
    "end": "180349"
  },
  {
    "text": "of the x’s weighted by their probabilities.\nLet the x sub i be the possible values of",
    "start": "180349",
    "end": "186069"
  },
  {
    "text": "x.",
    "start": "186069",
    "end": "187569"
  },
  {
    "text": "For example, for the rolling of two dice,\nthe possible values for x sub i would be 2,3,4",
    "start": "187569",
    "end": "194400"
  },
  {
    "text": "all the way up through 12. And p sub i would\nbe the corresponding probabilities of rolling",
    "start": "194400",
    "end": "199220"
  },
  {
    "text": "those sums - so that was 1 over 36, 2 over\n36, and so on.",
    "start": "199220",
    "end": "204540"
  },
  {
    "text": "So, the first moment gives us some idea of\nwhat our distribution might look like, but",
    "start": "204540",
    "end": "209840"
  },
  {
    "text": "not much. Think about it like this, the center\nof mass in these two images is in the same",
    "start": "209840",
    "end": "214900"
  },
  {
    "text": "place, but the mass is actually distributed\nvery differently in the two cases. We need",
    "start": "214900",
    "end": "219930"
  },
  {
    "text": "more information.",
    "start": "219930",
    "end": "221409"
  },
  {
    "text": "The second moment can help us. The second\nmoment is very similar in structure to the",
    "start": "221409",
    "end": "226099"
  },
  {
    "text": "first moment. We write it the same way with\nangled brackets, but now we’re talking about",
    "start": "226099",
    "end": "231819"
  },
  {
    "text": "the expected value of x squared. So it’s\nstill a sum and it’s still weighted by the",
    "start": "231819",
    "end": "238379"
  },
  {
    "text": "probabilities p sub i, but now we square each\npossible x value. For the dice example that",
    "start": "238379",
    "end": "244340"
  },
  {
    "text": "was the values from two through twelve. This\nis also called the mean square. First you",
    "start": "244340",
    "end": "250920"
  },
  {
    "text": "square the x values, then you take the mean,\nweighting each x sub i by its probability,",
    "start": "250920",
    "end": "256829"
  },
  {
    "text": "p sub i.",
    "start": "256829",
    "end": "257778"
  },
  {
    "text": "In general, the nth moment is defined as follows.",
    "start": "257779",
    "end": "264780"
  },
  {
    "text": "So how does the second moment help us get\na better picture of our distribution? Because",
    "start": "267590",
    "end": "272479"
  },
  {
    "text": "it can help us calculate something called\nthe variance. The variance measures how spread",
    "start": "272479",
    "end": "278300"
  },
  {
    "text": "out the distribution is around the mean. To\ncalculate the variance, you first subtract",
    "start": "278300",
    "end": "284228"
  },
  {
    "text": "the mean from each x sub i – this is like\nfinding the distance of each x sub i from",
    "start": "284229",
    "end": "289710"
  },
  {
    "text": "the mean - and then you square the result\nand multiply by p sub i.",
    "start": "289710",
    "end": "296710"
  },
  {
    "text": "What are the dimensions of the variance? The\nsquare of the dimensions of x. For example",
    "start": "299620",
    "end": "304930"
  },
  {
    "text": "if the dimension is a length, then the variance\nis a length squared. But we often want a measure",
    "start": "304930",
    "end": "310660"
  },
  {
    "text": "of dispersion like the variance, but one that\nhas the same dimensions as x itself. That",
    "start": "310660",
    "end": "316490"
  },
  {
    "text": "measure is the standard deviation, sigma.\nSigma is defined as the square root of the",
    "start": "316490",
    "end": "322319"
  },
  {
    "text": "variance. So if the variable x has dimensions\nof length, then the variance will have dimensions",
    "start": "322320",
    "end": "327520"
  },
  {
    "text": "of length squared, but the standard deviation,\nsigma, will have dimensions of length so it’s",
    "start": "327520",
    "end": "332470"
  },
  {
    "text": "comparable to x directly.",
    "start": "332470",
    "end": "335000"
  },
  {
    "text": "This expression for the variance looks like\na pain to compute, but it has an alternative",
    "start": "335000",
    "end": "340350"
  },
  {
    "text": "expression that is much simpler. And you get\nto show that as one of the exercises after",
    "start": "340350",
    "end": "345320"
  },
  {
    "text": "the video. The alternative expression, the\nmuch simpler one, is that the variance is",
    "start": "345320",
    "end": "351490"
  },
  {
    "text": "equal to the second moment, our old friend,\nminus the square of the first moment, or the",
    "start": "351490",
    "end": "357159"
  },
  {
    "text": "mean.",
    "start": "357159",
    "end": "358240"
  },
  {
    "text": "Pause the video here to convince yourself\nthat this difference is always non-negative.",
    "start": "358240",
    "end": "365240"
  },
  {
    "text": "This alternative expression for the variance,\nthis much more useful one, is also the parallel",
    "start": "369729",
    "end": "375050"
  },
  {
    "text": "axis theorem in mechanics, which says that\nthe moment of inertia of an object about the",
    "start": "375050",
    "end": "379990"
  },
  {
    "text": "center of mass is equal to the moment of inertia\nabout an axis shifted by h from the center",
    "start": "379990",
    "end": "385160"
  },
  {
    "text": "of mass, a parallel shift, minus mh squared.",
    "start": "385160",
    "end": "389860"
  },
  {
    "text": "So how does this analogy work? This, the dispersion\naround the mean, which is here at the center",
    "start": "389860",
    "end": "396349"
  },
  {
    "text": "of mass, is like the variance. This is like\nthe second moment if we make h equal to the",
    "start": "396350",
    "end": "402610"
  },
  {
    "text": "mean. So this is the dispersion around zero\nor its second moment. So this is like x squared,",
    "start": "402610",
    "end": "410388"
  },
  {
    "text": "the expected value. The mass is the sum total\nof all the weights here for each of xi which",
    "start": "410389",
    "end": "416580"
  },
  {
    "text": "all add up to one. So this is just like one\nin this problem. And then the h squared, well",
    "start": "416580",
    "end": "423580"
  },
  {
    "text": "h is the mean, so this is x squared.",
    "start": "423639",
    "end": "426840"
  },
  {
    "text": "So you can see the exact same structure repeated\nwith h, the shift of axis as the mean, and",
    "start": "426840",
    "end": "432910"
  },
  {
    "text": "m the mass, as the sum of all probabilities\nwhich is one. So this formula for the variance",
    "start": "432910",
    "end": "439500"
  },
  {
    "text": "is also the parallel axis theorem.",
    "start": "439500",
    "end": "444080"
  },
  {
    "start": "442000",
    "end": "865000"
  },
  {
    "text": "Let’s use the definitions of the moments,\nand also of the related quantity, the variance,",
    "start": "446900",
    "end": "452100"
  },
  {
    "text": "and practice on a few distributions.",
    "start": "452110",
    "end": "454460"
  },
  {
    "text": "A simple discrete distribution is a single\ncoin flip. Instead of thinking of the coin",
    "start": "454460",
    "end": "459638"
  },
  {
    "text": "flip as resulting in heads or tails, let’s\nthink about the coin as turning up a zero",
    "start": "459639",
    "end": "463889"
  },
  {
    "text": "or one. Let p be the probability of a one.",
    "start": "463889",
    "end": "467970"
  },
  {
    "text": "So the mean is the weighted sum of the xi’s,\nweighted by the probabilities. So the mean",
    "start": "467970",
    "end": "473560"
  },
  {
    "text": "x is the sum pi xi which is equal to one minus\np times zero plus p times one which is equal",
    "start": "473560",
    "end": "482340"
  },
  {
    "text": "to p.",
    "start": "482349",
    "end": "483620"
  },
  {
    "text": "What about the second moment? X squared, it’s\nequal to the weighted sum of the xi’s squared",
    "start": "483620",
    "end": "491040"
  },
  {
    "text": "so the weights are the same and we can square\neach value here, the xi’s, but since they’re",
    "start": "491050",
    "end": "498970"
  },
  {
    "text": "all zero or one, squaring doesn’t change\nthem. So the second moment and the third moment",
    "start": "498970",
    "end": "504919"
  },
  {
    "text": "and every higher moment are all p. Pause the\nvideo here and compute the variance and sketch",
    "start": "504919",
    "end": "512759"
  },
  {
    "text": "it as a function of p.",
    "start": "512760",
    "end": "515919"
  },
  {
    "text": "The variance from our old convenient form\nof the formula is… variance of x is the",
    "start": "520690",
    "end": "524750"
  },
  {
    "text": "mean squared, mean square minus the squared\nmean and all the moments themselves were just",
    "start": "524750",
    "end": "529680"
  },
  {
    "text": "p. So that’s p minus p squared which is\nequal to p times 1 minus p.",
    "start": "529680",
    "end": "536580"
  },
  {
    "text": "What does that look like? We sketch it. P\non this axis, variance on that axis and the",
    "start": "536580",
    "end": "543339"
  },
  {
    "text": "curve starts at zero (something I can’t\nunderstand) and goes back to zero.",
    "start": "543339",
    "end": "549310"
  },
  {
    "text": "This is a p equals 1 and that’s p equals\nzero. Does that make sense?",
    "start": "549310",
    "end": "555450"
  },
  {
    "text": "Yeah, it does… from the meaning of variance\nas dispersion around the mean. So take the",
    "start": "555450",
    "end": "562080"
  },
  {
    "text": "first extreme case of p equals zero. In other\nwords, the coin has no chance of producing",
    "start": "562080",
    "end": "567430"
  },
  {
    "text": "a one, always produces a zero every time.\nThere the mean is zero and there is no dispersion",
    "start": "567430",
    "end": "573730"
  },
  {
    "text": "because it always produces zero. The same\napplies when p equals one here at this extreme.",
    "start": "573730",
    "end": "580060"
  },
  {
    "text": "The coin always produces a one with no dispersion.\nThere is no variation, there is no variance",
    "start": "580060",
    "end": "585560"
  },
  {
    "text": "and it’s plausible that the variance should\nbe a maximum right in between… here at p",
    "start": "585560",
    "end": "592420"
  },
  {
    "text": "equals one half which it is on this curve.\nSo everything looks good. Our calculation",
    "start": "592420",
    "end": "599100"
  },
  {
    "text": "seems reasonable and checks out in the extreme\ncases.",
    "start": "599100",
    "end": "603540"
  },
  {
    "text": "Before we go back to the airport problem,\nlet’s extend the idea of moments to continuous",
    "start": "603540",
    "end": "607899"
  },
  {
    "text": "distributions.",
    "start": "607900",
    "end": "609620"
  },
  {
    "text": "Here, instead of a list of probabilities for\neach possible x, we have a probability density",
    "start": "609630",
    "end": "614459"
  },
  {
    "text": "p as a function of x, where x is now a continuous\nvariable. That’s the continuous version",
    "start": "614459",
    "end": "621010"
  },
  {
    "text": "for the nth moment was a sum of xi to the\nnth weighted by the probabilities. Here, the",
    "start": "621010",
    "end": "627880"
  },
  {
    "text": "nth moment, x sub n, in equal to instead of\na sum, an integral. Weighted again, as always,",
    "start": "627880",
    "end": "634540"
  },
  {
    "text": "by the probability times x sub n, as before\nand with a dx because p of x times dx is the",
    "start": "634540",
    "end": "642339"
  },
  {
    "text": "probability and you add them all up over all\npossible values of x. That’s the formula",
    "start": "642340",
    "end": "648389"
  },
  {
    "text": "for a continuous distribution, for the moments\nof a continuous distribution.",
    "start": "648399",
    "end": "650769"
  },
  {
    "text": "Let’s practice on the simplest continuous\ndistribution, the uniform distribution. X",
    "start": "650769",
    "end": "657170"
  },
  {
    "text": "is equally likely to be any real number between\nzero and one. That’s the distribution and",
    "start": "657170",
    "end": "663420"
  },
  {
    "text": "we can compute the first and second moments\nand the variance.",
    "start": "663420",
    "end": "667450"
  },
  {
    "text": "Pause the video here, use the definition\nof moments for a continuous distribution and",
    "start": "667450",
    "end": "672700"
  },
  {
    "text": "compute the mean, first moment, the second\nmoment, and from those two, the variance.",
    "start": "672720",
    "end": "679720"
  },
  {
    "text": "What you should have found is … for the\nmean, it’s the integral of one because p",
    "start": "687930",
    "end": "693240"
  },
  {
    "text": "of x is one, times x between zero and one\ndx, which is x squared over two evaluated",
    "start": "693240",
    "end": "700980"
  },
  {
    "text": "between zero and one, which equal one half…\nwhich makes sense. The mean here, the average",
    "start": "700990",
    "end": "707649"
  },
  {
    "text": "value is just one-half right in the middle\nof the distribution of the possible values",
    "start": "707649",
    "end": "712680"
  },
  {
    "text": "of x.",
    "start": "712680",
    "end": "714279"
  },
  {
    "text": "What about the mean square? For that, you should\nhave found almost the same calculation, one",
    "start": "714279",
    "end": "722159"
  },
  {
    "text": "times x squared dx, which equals x cubed over\n3 between zero and one equals one-third. And",
    "start": "722160",
    "end": "729519"
  },
  {
    "text": "thus, the variance is equal to one-third,\nthat’s the mean square minus the squared",
    "start": "729519",
    "end": "735200"
  },
  {
    "text": "mean, which is… one twelfth. And that number\nis familiar. That’s the same 1/12 that shows",
    "start": "735200",
    "end": "742720"
  },
  {
    "text": "up in the moment of inertia of a ruler of\nlength l and mass m. Its moment of inertia",
    "start": "742730",
    "end": "748500"
  },
  {
    "text": "is 1/12 ml squared which illustrates again\nthe connection between moments of inertia",
    "start": "748500",
    "end": "754600"
  },
  {
    "text": "and moments of distributions.",
    "start": "754600",
    "end": "756569"
  },
  {
    "text": "Let’s apply our knowledge to understand\nquantitatively, or in a formal way, what happens",
    "start": "756570",
    "end": "762589"
  },
  {
    "text": "with airport travel – why does it seem\nso much longer on the way there, than on the",
    "start": "762589",
    "end": "767600"
  },
  {
    "text": "way back?",
    "start": "767600",
    "end": "768370"
  },
  {
    "text": "Here is the ideal travel experience to\nthe airport, the distribution of travel times",
    "start": "768370",
    "end": "773839"
  },
  {
    "text": "t. Here's the probability of each particular travel time, p",
    "start": "773839",
    "end": "779079"
  },
  {
    "text": "of t. In the ideal world, the travel time\nwould be very predictable. Let’s say it",
    "start": "779079",
    "end": "786219"
  },
  {
    "text": "would be almost always twenty minutes. In\nthat case, you would allow twenty minutes",
    "start": "786230",
    "end": "791570"
  },
  {
    "text": "to get to the airport and you would allow\ntwenty minutes on the way back. Going there",
    "start": "791570",
    "end": "796329"
  },
  {
    "text": "and coming back would seem the same.",
    "start": "796329",
    "end": "798399"
  },
  {
    "text": "But, here’s what travel to the airport actually\nlooks like. Let’s say the mean is still",
    "start": "798399",
    "end": "804070"
  },
  {
    "text": "the same, but the reality is that there’s\nlots of dispersion. And so the curve actually",
    "start": "804070",
    "end": "810139"
  },
  {
    "text": "looks like that. Sometimes the travel time\nwill be 30 minutes, sometimes 40, sometimes",
    "start": "810139",
    "end": "816360"
  },
  {
    "text": "10.",
    "start": "816360",
    "end": "818630"
  },
  {
    "text": "So now, what do you have to do?... this is\nreality. Well, on the way home, it’s no",
    "start": "818630",
    "end": "824079"
  },
  {
    "text": "problem. On average, you get home in twenty\nminutes. You leave whenever you get out of",
    "start": "824079",
    "end": "828680"
  },
  {
    "text": "the baggage claim. And while it’s true that\nthe trip to the airport follows the same distribution,",
    "start": "828680",
    "end": "834269"
  },
  {
    "text": "the risk to you of not making it to the airport\non time is much greater. If you just allow",
    "start": "834269",
    "end": "839639"
  },
  {
    "text": "twenty minutes, yeah, sometimes you’ll get\nlucky, but every once in a while it will take",
    "start": "839639",
    "end": "843800"
  },
  {
    "text": "you twenty-five or thirty minutes.",
    "start": "843800",
    "end": "846410"
  },
  {
    "text": "So what you have to do is allow more time\non the way there so that you don’t miss",
    "start": "846410",
    "end": "849740"
  },
  {
    "text": "your flight - maybe thirty minutes, maybe\neven forty minutes. It all depends on the",
    "start": "849740",
    "end": "854540"
  },
  {
    "text": "dispersion, or standard deviation, of the\ndistribution. On the way to the airport, you",
    "start": "854540",
    "end": "859730"
  },
  {
    "text": "are much more aware of the distribution, if\nyou will, than you are on the way back.",
    "start": "859730",
    "end": "865290"
  },
  {
    "start": "865000",
    "end": "902000"
  },
  {
    "text": "In this video, we saw how to calculate the\nmoments of a distribution and how these moments can",
    "start": "869400",
    "end": "874320"
  },
  {
    "text": "help us quickly summarize the distribution. Like life...",
    "start": "874320",
    "end": "879000"
  },
  {
    "text": "when something is complicated, simplify it, grasp it, and understand it by appreciating its moments!",
    "start": "879000",
    "end": "886000"
  }
]
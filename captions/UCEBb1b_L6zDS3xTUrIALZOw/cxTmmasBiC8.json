[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation, or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18140",
    "end": "23178"
  },
  {
    "text": "GILBERT STRANG: OK. Now, clustering for graphs. So this is a topic--",
    "start": "23178",
    "end": "30360"
  },
  {
    "text": "this is one of the\nimportant things you can try to do with a graph. So you have a large graph.",
    "start": "30360",
    "end": "36225"
  },
  {
    "start": "36225",
    "end": "44230"
  },
  {
    "text": "Let me kind of divide\nit into two clusters. ",
    "start": "44230",
    "end": "55020"
  },
  {
    "text": "So you've got a giant graph. And then the job is to\nmake some sense out of it.",
    "start": "55020",
    "end": "60030"
  },
  {
    "text": "And one possible step is\nto be able to subdivide it, if, as I see here, there's\na cut between two reasonably",
    "start": "60030",
    "end": "73560"
  },
  {
    "text": "equal parts of the graph-- reasonable--\nreasonably same size.",
    "start": "73560",
    "end": "79320"
  },
  {
    "text": "And therefore, that graph\ncould be studied in two pieces.",
    "start": "79320",
    "end": "84810"
  },
  {
    "text": "So the question is, how do you\nfind such a cut by a algorithm?",
    "start": "84810",
    "end": "90939"
  },
  {
    "text": "What's an algorithm that\nwould find that cut? So that's a problem.",
    "start": "90940",
    "end": "96120"
  },
  {
    "text": "Let's say we're looking\nfor two clusters.",
    "start": "96120",
    "end": "101775"
  },
  {
    "text": " We could look for more\nclusters, but let's say we",
    "start": "101775",
    "end": "108460"
  },
  {
    "text": "want to look for two clusters. So what are we trying to do? We're trying to minimize.",
    "start": "108460",
    "end": "115580"
  },
  {
    "text": "So this is the problem, then. ",
    "start": "115580",
    "end": "122380"
  },
  {
    "text": "So we look for-- find positions x\nand y, let's say.",
    "start": "122380",
    "end": "130509"
  },
  {
    "text": "Two which will be the\ncenters, so to speak, of the-- and really, it's just\nthese points that--",
    "start": "130509",
    "end": "141940"
  },
  {
    "text": "so the data is the\npoints and the edges, as always-- the\nnodes and the edges.",
    "start": "141940",
    "end": "147810"
  },
  {
    "text": "So the problem is to\nfind x and y so that-- to minimize. ",
    "start": "147810",
    "end": "156860"
  },
  {
    "text": "So it's a distance\nof points ai from x--",
    "start": "156860",
    "end": "165100"
  },
  {
    "text": "maybe should emphasize\nwe're in high dimensions-- plus the distance\nof other points.",
    "start": "165100",
    "end": "174230"
  },
  {
    "text": "So the ai will be these points-- these nodes.",
    "start": "174230",
    "end": "180220"
  },
  {
    "text": "And the bi will be these\nnodes, plus the sum of bi minus y squared.",
    "start": "180220",
    "end": "189670"
  },
  {
    "text": "And you understand\nthe rule here-- that together the a's union\nthe b's give me all nodes.",
    "start": "189670",
    "end": "203250"
  },
  {
    "text": " And I guess to be complete, the\na's intersect the b's is empty.",
    "start": "203250",
    "end": "216765"
  },
  {
    "text": " Just what you expect. I'm dividing the a's and\nthe b's into two groups.",
    "start": "216765",
    "end": "225110"
  },
  {
    "text": "And I'm picking\nan x and a y sort of at the center of those\ngroups, so that is a minimum.",
    "start": "225110",
    "end": "235860"
  },
  {
    "text": "So I want to minimize.  And also, I probably want to\nimpose some condition that",
    "start": "235860",
    "end": "243790"
  },
  {
    "text": "the number of a's is reasonably\nclose to the number of b's. In other words, I don't want\njust that to be the a, and all",
    "start": "243790",
    "end": "253880"
  },
  {
    "text": "the rest to be the b's. That would be not a\nsatisfactory clustering.",
    "start": "253880",
    "end": "261140"
  },
  {
    "text": "I'm looking for clusters\nthat are good sized clusters.",
    "start": "261140",
    "end": "266400"
  },
  {
    "text": "So minimize that. OK. So there are a lot of\ndifferent algorithms to do it.",
    "start": "266400",
    "end": "271980"
  },
  {
    "text": " Some are more directly\nattacking this problem.",
    "start": "271980",
    "end": "281009"
  },
  {
    "text": "Others use matrices that we\nassociate with the graph.",
    "start": "281010",
    "end": "286470"
  },
  {
    "text": "So let me tell you about two\nor three of those algorithms. And if you've seen--",
    "start": "286470",
    "end": "291660"
  },
  {
    "text": "studied-- had a course\nin graph theory, this-- you may already have\nseen this problem.",
    "start": "291660",
    "end": "296710"
  },
  {
    "text": "First question would be,\nsuppose I decide these are",
    "start": "296710",
    "end": "302910"
  },
  {
    "text": "the a's, and those are the\nb's-- or some other decision. Yeah, probably some\nother decision.",
    "start": "302910",
    "end": "308060"
  },
  {
    "text": "I don't want to solve the\nproblem before I even start. So some a's and some b's.",
    "start": "308060",
    "end": "314640"
  },
  {
    "text": "What would be the best choice\nof the x once you've decided on the a's? And what would be the\nbest choice of the y once",
    "start": "314640",
    "end": "321750"
  },
  {
    "text": "you've decided on the b's? So we can answer that question\nif we knew the two groups.",
    "start": "321750",
    "end": "333290"
  },
  {
    "text": "We could see where they\nshould be centered, with the first group centered\nat x, the second group centered",
    "start": "333290",
    "end": "341360"
  },
  {
    "text": "at y, and what does\ncentering mean? So let's just say-- ",
    "start": "341360",
    "end": "348324"
  },
  {
    "text": "so I think what I'm\nsaying here is-- ",
    "start": "348325",
    "end": "355030"
  },
  {
    "text": "let me bring that down a little. So given the a's--",
    "start": "355030",
    "end": "361250"
  },
  {
    "text": "the a's-- this is\na1 up to, say, ak.",
    "start": "361250",
    "end": "367310"
  },
  {
    "text": "What is the best x just\nto make that part right?",
    "start": "367310",
    "end": "379190"
  },
  {
    "text": "And the answer is, to do\nyou know, geometrically, what x should be here?",
    "start": "379190",
    "end": "384230"
  },
  {
    "text": "X is the-- so if I\nhave a bunch of points, and I'm looking for the\nmiddle of those points--",
    "start": "384230",
    "end": "392660"
  },
  {
    "text": "the point x-- a good point x\nto say, OK, that's the middle. It'll make the sum of the\ndistances, I think, squared--",
    "start": "392660",
    "end": "401190"
  },
  {
    "text": "I hope I'm right about that-- a minimum. What is x?",
    "start": "401190",
    "end": "408350"
  },
  {
    "text": "It is the-- AUDIENCE: [INAUDIBLE]. GILBERT STRANG: Centroid. Centroid is the word.",
    "start": "408350",
    "end": "414150"
  },
  {
    "text": "X is the centroid of the a's.",
    "start": "414150",
    "end": "422699"
  },
  {
    "text": "And what is the centroid? Let's see. Oh, maybe I don't know if\nx and y were a good choice,",
    "start": "422700",
    "end": "429120"
  },
  {
    "text": "but let me see what-- ",
    "start": "429120",
    "end": "435140"
  },
  {
    "text": "I guess, it's the average a. It's the sum of the a's--",
    "start": "435140",
    "end": "441098"
  },
  {
    "text": "of these a's. Those are vectors, of course,\ndivided by the number of a's.",
    "start": "441098",
    "end": "448220"
  },
  {
    "text": " I think.",
    "start": "448220",
    "end": "453340"
  },
  {
    "text": "Actually, I was just quickly\nreviewing this morning, so I'm not totally on\ntop of this centroid.",
    "start": "453340",
    "end": "462350"
  },
  {
    "text": "What I'm going to talk-- the algorithm that I'm going\nto talk about is the k-- well, the k-means,\nit's always called.",
    "start": "462350",
    "end": "471970"
  },
  {
    "text": "And here it will be\nthe-- k will be 2. ",
    "start": "471970",
    "end": "478840"
  },
  {
    "text": "I just have two-- partitioning into two sets,\na's and b's, so I just-- k",
    "start": "478840",
    "end": "485080"
  },
  {
    "text": "is just 2. OK. What's the algorithm? Well, if I've\nchosen a partition--",
    "start": "485080",
    "end": "495419"
  },
  {
    "text": "the a's and b's have\nseparated them-- then that tells me what\nthe x and the y should be.",
    "start": "495420",
    "end": "502800"
  },
  {
    "text": "But, now what do I do next? So is this going to be a sort\nof an alternating partition?",
    "start": "502800",
    "end": "509640"
  },
  {
    "text": "Now I take those two centroids. So step one is for\ngiven a's and b's, find",
    "start": "509640",
    "end": "523090"
  },
  {
    "text": "the centroids x and y.",
    "start": "523090",
    "end": "529770"
  },
  {
    "text": "And that's elementary. Then the second step is,\ngiven the centroids, x and y--",
    "start": "529770",
    "end": "543510"
  },
  {
    "text": "given those positions--\ngiven x and y-- they won't be centroids\nwhen you see what happened.",
    "start": "543510",
    "end": "550000"
  },
  {
    "text": "Given x and y, redo-- ",
    "start": "550000",
    "end": "558750"
  },
  {
    "text": "form the best partition-- best clusters.",
    "start": "558750",
    "end": "563805"
  },
  {
    "start": "563805",
    "end": "569839"
  },
  {
    "text": "So step one, we had a guess at\nwhat the best clusters were.",
    "start": "569840",
    "end": "576230"
  },
  {
    "text": "And we found they're centroids. Now, we start with\nthe centroids, and we form new clusters again.",
    "start": "576230",
    "end": "583250"
  },
  {
    "text": "And if these clusters\nare the same as the ones we started with, then the\nalgorithm is converged.",
    "start": "583250",
    "end": "590240"
  },
  {
    "text": "But probably they won't be-- these clusters. So you'll have to tell me what\nI mean by the best clusters.",
    "start": "590240",
    "end": "597005"
  },
  {
    "text": "If I've got the two points,\nx and y, I want the points--",
    "start": "597005",
    "end": "602390"
  },
  {
    "text": "I want to separate\nall the points that cluster around x to the\nones that cluster around y.",
    "start": "602390",
    "end": "608269"
  },
  {
    "text": "And then, they're\nprobably different from my original start. So now I've got new--",
    "start": "608270",
    "end": "614990"
  },
  {
    "text": "now I repeat step one. But let's just think, how\ndo I form the best clusters?",
    "start": "614990",
    "end": "620920"
  },
  {
    "text": " Well, I take a point and I have\nto decide, does it go with x,",
    "start": "620920",
    "end": "628830"
  },
  {
    "text": "or does it go within\nthe x cluster, or does it go in the\ncluster around y? So how do I decide that?",
    "start": "628830",
    "end": "636870"
  },
  {
    "text": "Just whichever one\nit's closer to. So each point goes\nwith each node.",
    "start": "636870",
    "end": "648540"
  },
  {
    "text": "You should-- I\ncould say, each node goes with the closer of x and y.",
    "start": "648540",
    "end": "661949"
  },
  {
    "text": " So points that\nshould have been--",
    "start": "661950",
    "end": "668961"
  },
  {
    "text": "that are closer to x-- now\nwe're going to put them in the cluster around x. And does that solve the problem?",
    "start": "668961",
    "end": "676890"
  },
  {
    "text": "No, because-- well, it\nmight, but it might not. ",
    "start": "676890",
    "end": "684430"
  },
  {
    "text": "We'd have to come\nback to step one. We've now changed the clusters.",
    "start": "684430",
    "end": "689800"
  },
  {
    "text": "They'll have\ndifferent centroids. So we repeat step one--\nfind the centroids",
    "start": "689800",
    "end": "695410"
  },
  {
    "text": "for the two new clusters. Then we come to step two. Find the ones that should\ngo with the two centroids,",
    "start": "695410",
    "end": "703209"
  },
  {
    "text": "and back and forth. I don't know. I don't think there's a\nnice theory of convergence,",
    "start": "703210",
    "end": "709750"
  },
  {
    "text": "or rate of convergence--\nall the questions that this course\nis always asking.",
    "start": "709750",
    "end": "715149"
  },
  {
    "text": "But it's a very popular\nalgorithm, k-means.",
    "start": "715150",
    "end": "721960"
  },
  {
    "text": "k would be to have k clusters. OK. So that's a--",
    "start": "721960",
    "end": "728170"
  },
  {
    "text": "I'm not going to discuss the-- I'd rather discuss some\nother ways to do this, to solve this problem.",
    "start": "728170",
    "end": "734410"
  },
  {
    "text": "But that's one sort of\nhack that works quite well.",
    "start": "734410",
    "end": "740829"
  },
  {
    "text": "OK. So second approach is\nwhat is coming next.",
    "start": "740830",
    "end": "747000"
  },
  {
    "text": "Second solution\nmethod-- and it's",
    "start": "747000",
    "end": "759140"
  },
  {
    "text": "called the spectral clustering.",
    "start": "759140",
    "end": "765476"
  },
  {
    "text": " That's the name of the method.",
    "start": "765476",
    "end": "772399"
  },
  {
    "text": "And before I write down what\nyou do, what does the word spectral mean?",
    "start": "772400",
    "end": "778580"
  },
  {
    "text": "You see spectral graph\ntheory, spectral clustering. And in other parts of\nmathematics, you see that--",
    "start": "778580",
    "end": "786320"
  },
  {
    "text": "you see spectral theorem. I gave you the most-- and I described it as the\nmost important-- perhaps--",
    "start": "786320",
    "end": "795070"
  },
  {
    "text": "theorem in linear algebra--\nat least one of the top three. ",
    "start": "795070",
    "end": "801940"
  },
  {
    "text": "So I'll write it over\nhere, because it's not-- it doesn't-- this is--",
    "start": "801940",
    "end": "807760"
  },
  {
    "text": "it's the same word, spectral. ",
    "start": "807760",
    "end": "814530"
  },
  {
    "text": "Well, let me ask\nthat question again? What's that word spectral about?",
    "start": "814530",
    "end": "819560"
  },
  {
    "text": "What does that mean? That means that if\nI have a matrix, and I want to talk\nabout its spectrum, what",
    "start": "819560",
    "end": "827450"
  },
  {
    "text": "is the spectrum of the matrix? It is the eigenvalues.",
    "start": "827450",
    "end": "834190"
  },
  {
    "text": "So spectral theory,\nspectral clustering is using the eigenvalues\nof some matrix.",
    "start": "834190",
    "end": "841760"
  },
  {
    "text": "That's what that\nspectral is telling me. Yeah. So the spectral\ntheorem, of course,",
    "start": "841760",
    "end": "847550"
  },
  {
    "text": "is that for a symmetric matrix\nS, the eigenvalues are real,",
    "start": "847550",
    "end": "856580"
  },
  {
    "text": "and the eigenvectors\nare orthogonal.",
    "start": "856580",
    "end": "861710"
  },
  {
    "text": "And don't forget what the\nreal, full statement is here,",
    "start": "861710",
    "end": "870210"
  },
  {
    "text": "because there could be\nrepeated real eigenvalues. And what does the\nspectral theorem tell me",
    "start": "870210",
    "end": "877399"
  },
  {
    "text": "for symmetric matrices,\nif lambda equals",
    "start": "877400",
    "end": "882440"
  },
  {
    "text": "5 is repeated four times-- if it's a four times\nsolution of the equation that",
    "start": "882440",
    "end": "893190"
  },
  {
    "text": "gives eigenvalues, then\nwhat's the conclusion? Then there are four independent,\northogonal eigenvectors",
    "start": "893190",
    "end": "901740"
  },
  {
    "text": "to go with it. We can't say that\nabout matrices-- about all matrices.",
    "start": "901740",
    "end": "907920"
  },
  {
    "text": "But we can say it about\nall symmetric matrices. And in fact, those\neigenvectors are orthogonal.",
    "start": "907920",
    "end": "915380"
  },
  {
    "text": "So we're even saying more. We can find four\northogonal eigenvectors that go with a multiplicity\nfor eigenvalues.",
    "start": "915380",
    "end": "925280"
  },
  {
    "text": "OK. That's spectral theorem. Spectral clustering starts with\nthe graph Laplacian matrix.",
    "start": "925280",
    "end": "942720"
  },
  {
    "text": " May I remember what\nthat matrix is?",
    "start": "942720",
    "end": "949700"
  },
  {
    "text": "Because that's the key\nconnection of linear algebra",
    "start": "949700",
    "end": "956370"
  },
  {
    "text": "to graph theory, is the\nproperties of this graph, Laplacian matrix.",
    "start": "956370",
    "end": "962209"
  },
  {
    "text": "OK. So let me say L, for Laplacian. ",
    "start": "962210",
    "end": "968269"
  },
  {
    "text": "So that matrix-- one\nway to describe it is as A transpose A,\nwhere A is the incidence",
    "start": "968270",
    "end": "978680"
  },
  {
    "text": "matrix of the graph.",
    "start": "978680",
    "end": "985380"
  },
  {
    "text": "Or another way\nwe'll see is the D--",
    "start": "985380",
    "end": "990720"
  },
  {
    "text": "the degree matrix.  That's diagonal.",
    "start": "990720",
    "end": "996395"
  },
  {
    "start": "996395",
    "end": "1002890"
  },
  {
    "text": "And I'll do an example\njust to remind you. Minus the-- well, I don't\nknow what I'd call this one.",
    "start": "1002890",
    "end": "1009505"
  },
  {
    "text": " Shall I call it\nB for the moment.",
    "start": "1009505",
    "end": "1015480"
  },
  {
    "text": "And what matrix is B? That's the adjacency matrix.",
    "start": "1015480",
    "end": "1020910"
  },
  {
    "start": "1020910",
    "end": "1027030"
  },
  {
    "text": "Really, you should know\nthese four matrices.",
    "start": "1027030",
    "end": "1033900"
  },
  {
    "text": "They're the key four matrices\nassociated with any graph. The incidence matrix,\nthat's m by n--",
    "start": "1033900",
    "end": "1040760"
  },
  {
    "text": " edges and nodes--\nedges and nodes.",
    "start": "1040760",
    "end": "1051330"
  },
  {
    "text": "So it's rectangular, but I'm\nforming A transpose A here. So I'm forming a symmetric,\npositive, semi-definite matrix.",
    "start": "1051330",
    "end": "1061280"
  },
  {
    "text": "So this Laplacian is symmetric,\npositive, semi-definite.",
    "start": "1061280",
    "end": "1070350"
  },
  {
    "text": "Yeah. Let me let me just recall\nwhat all these matrices are for a simple graph.",
    "start": "1070350",
    "end": "1077210"
  },
  {
    "text": " OK.",
    "start": "1077210",
    "end": "1082590"
  },
  {
    "text": "So I'll just draw a graph. ",
    "start": "1082590",
    "end": "1087870"
  },
  {
    "text": "All right. OK. So the incidence matrix-- ",
    "start": "1087870",
    "end": "1094570"
  },
  {
    "text": "there are 1, 2, 3, 4, 5 edges-- so five rows. ",
    "start": "1094570",
    "end": "1102030"
  },
  {
    "text": "There are four nodes-- 1, 2, 3, and 4.",
    "start": "1102030",
    "end": "1107890"
  },
  {
    "text": "So four columns. And a typical row would be edge\n1 going from node 1 to node 2,",
    "start": "1107890",
    "end": "1116460"
  },
  {
    "text": "so it would have a\nminus 1 and a 1 there. And let me take edge 2,\ngoing from 1 to node 3,",
    "start": "1116460",
    "end": "1126400"
  },
  {
    "text": "so it would have a minus 1\nand a 1 there, and so on.",
    "start": "1126400",
    "end": "1131600"
  },
  {
    "text": "So that's the\nincidence matrix A. OK.",
    "start": "1131600",
    "end": "1137390"
  },
  {
    "text": "What's the degree matrix? That's simple. The degree matrix-- well, A\ntranspose A. This is m by n.",
    "start": "1137390",
    "end": "1149409"
  },
  {
    "text": "This is n by m. So it's n by n. ",
    "start": "1149410",
    "end": "1158299"
  },
  {
    "text": "OK. In this case, 4 by 4. So the degree matrix\nwill be 4 by 4, n by n.",
    "start": "1158300",
    "end": "1166200"
  },
  {
    "text": "And it will tell us the\ndegree of that, which means-- which we just count the edges. So three edges going in, node\n2, three edges going in, node 3",
    "start": "1166200",
    "end": "1178110"
  },
  {
    "text": "has just two edges. And node 4 has just two edges. So that's the degree matrix.",
    "start": "1178110",
    "end": "1185610"
  },
  {
    "text": "And then the adjacency\nmatrix that I've called B is also 4 by 4.",
    "start": "1185610",
    "end": "1192600"
  },
  {
    "text": "And what is it? It tells us which node is\nconnected to which node.",
    "start": "1192600",
    "end": "1199990"
  },
  {
    "text": "So I don't allow nodes-- edges that connect a node to\nitself, so 0's on the diagonal.",
    "start": "1199990",
    "end": "1210180"
  },
  {
    "text": "How many-- so which nodes\nare connected to node 1? Well, all of 2 and 4 and\n3 are connected to 1.",
    "start": "1210180",
    "end": "1218640"
  },
  {
    "text": "So I have 1's there.  Node 2-- all three nodes\nare connected to node 2.",
    "start": "1218640",
    "end": "1226780"
  },
  {
    "text": "So I'll have-- the second column\nand row will have all three 1's.",
    "start": "1226780",
    "end": "1232210"
  },
  {
    "text": "How about node 3? OK. Only edges-- only two\nedges are connected.",
    "start": "1232210",
    "end": "1239770"
  },
  {
    "text": "Only two nodes are connected\nto 3, 1 and 2, but not 4.",
    "start": "1239770",
    "end": "1246820"
  },
  {
    "text": "So 1 and 2 I have, but not 4. OK.",
    "start": "1246820",
    "end": "1251950"
  },
  {
    "text": "So that's the adjacency matrix. Is that right? Think so.",
    "start": "1251950",
    "end": "1258350"
  },
  {
    "text": "This is the degree matrix. This is the incidence matrix.",
    "start": "1258350",
    "end": "1264290"
  },
  {
    "text": "And that formula gives\nme the Laplacian. OK. Let's just write\ndown the Laplacian.",
    "start": "1264290",
    "end": "1271356"
  },
  {
    "text": " So if I use the degree minus B--",
    "start": "1271356",
    "end": "1279149"
  },
  {
    "text": "that's easy. The degrees were 3, 3, 2, and 2. Now I have these minuses.",
    "start": "1279150",
    "end": "1284929"
  },
  {
    "start": "1284930",
    "end": "1290610"
  },
  {
    "text": "And those were 0. OK. ",
    "start": "1290610",
    "end": "1297290"
  },
  {
    "text": "So that's a positive,\nsemi-definite matrix. Is it a positive\ndefinite matrix?",
    "start": "1297290",
    "end": "1304059"
  },
  {
    "text": "So let me ask, is it singular\nor is it not singular?",
    "start": "1304060",
    "end": "1309890"
  },
  {
    "text": "Is there a vector\nin its null space, or is there not a vector\nin its null space? Can you solve Dx equals all 0's?",
    "start": "1309890",
    "end": "1319345"
  },
  {
    "text": " And of course, you can.",
    "start": "1319345",
    "end": "1326050"
  },
  {
    "text": "Everybody sees that\nvector of all 1's will",
    "start": "1326050",
    "end": "1331180"
  },
  {
    "text": "be a solution to L--",
    "start": "1331180",
    "end": "1337220"
  },
  {
    "text": "sorry. I should be saying L here. Lx equals 0.",
    "start": "1337220",
    "end": "1344750"
  },
  {
    "text": "Lx equals 0 as for a whole line\nof one dimensional null space",
    "start": "1344750",
    "end": "1358130"
  },
  {
    "text": "of L has dimension 1.",
    "start": "1358130",
    "end": "1365120"
  },
  {
    "text": "It's got 1 basis\nvector, 1, 1, 1, 1. And that will always happen\nwith the graph set up",
    "start": "1365120",
    "end": "1375860"
  },
  {
    "text": "that I've created. OK. So that's a first fact, that\nthis positive, semi-definite",
    "start": "1375860",
    "end": "1382400"
  },
  {
    "text": "matrix, L, has\nlambda 1 equals 0.",
    "start": "1382400",
    "end": "1389980"
  },
  {
    "text": "And the eigenvector\nis constant--",
    "start": "1389980",
    "end": "1395169"
  },
  {
    "text": "C, C, C, C-- the one\ndimensional eigenspace. Or 1, 1, 1, 1 is the\ntypical eigenvector.",
    "start": "1395170",
    "end": "1402830"
  },
  {
    "text": "OK.  Now back to graph clustering.",
    "start": "1402830",
    "end": "1412130"
  },
  {
    "text": "The idea of graph\nclustering is to look at the Fiedler eigenvector.",
    "start": "1412130",
    "end": "1419960"
  },
  {
    "text": "This is called the x2--  is the next eigenvector-- is\nthe eigenvector for the smallest",
    "start": "1419960",
    "end": "1435850"
  },
  {
    "text": "positive eigenvalue for a\nlambda min excluding 0--",
    "start": "1435850",
    "end": "1441789"
  },
  {
    "text": "so the smallest\neigenvalue of L-- ",
    "start": "1441790",
    "end": "1451454"
  },
  {
    "text": "the smallest eigenvalue\nand its eigenvector-- this is called the\nFiedler vector, named",
    "start": "1451454",
    "end": "1457670"
  },
  {
    "text": "after the Czech mathematician. ",
    "start": "1457670",
    "end": "1465330"
  },
  {
    "text": "A great man in linear algebra,\nand he studied this factor--",
    "start": "1465330",
    "end": "1471019"
  },
  {
    "text": "this situation. So everybody who knows\nabout the graph Laplacian",
    "start": "1471020",
    "end": "1478310"
  },
  {
    "text": "is aware that its\nfirst eigenvalue is 0, and that the next\neigenvalue is important.",
    "start": "1478310",
    "end": "1486170"
  },
  {
    "text": "Yeah. AUDIENCE: Is the graph\nLaplacian named the Laplacian because it has connections to--",
    "start": "1486170",
    "end": "1492850"
  },
  {
    "text": "GILBERT STRANG: To\nLaplace's equation, yes. ",
    "start": "1492850",
    "end": "1498860"
  },
  {
    "text": "Yeah, that's a good question. So why the word--",
    "start": "1498860",
    "end": "1504430"
  },
  {
    "text": "the name, Laplacian? ",
    "start": "1504430",
    "end": "1510050"
  },
  {
    "text": "So yeah, that's a good question.",
    "start": "1510050",
    "end": "1515400"
  },
  {
    "text": "So the familiar thing-- so it\nconnects to Laplace's finite",
    "start": "1515400",
    "end": "1522170"
  },
  {
    "text": "difference equation, because\nwe're talking about matrices here, and not derivatives-- not functions.",
    "start": "1522170",
    "end": "1528980"
  },
  {
    "text": "So why the word Laplacian? Well, so if I have a regular-- if my graph is composed of--",
    "start": "1528980",
    "end": "1537950"
  },
  {
    "text": "so there is a graph with\n25 nodes, and 4 times 5--",
    "start": "1537950",
    "end": "1546630"
  },
  {
    "text": "20, about 40. This probably has about\n40 edges and 25 nodes.",
    "start": "1546630",
    "end": "1555460"
  },
  {
    "text": " And of course, I\ncan construct its--",
    "start": "1555460",
    "end": "1561910"
  },
  {
    "text": "graph all those four\nmatrices for it-- its incidence matrix,\nits degree matrix.",
    "start": "1561910",
    "end": "1571050"
  },
  {
    "text": "So the degree will be four\nat all these inside points. The degree will be three\nat these boundary points.",
    "start": "1571050",
    "end": "1579220"
  },
  {
    "text": "The degree will be two\nat these corner points. But the-- what will\nthe matrix L look like?",
    "start": "1579220",
    "end": "1588670"
  },
  {
    "text": "So what is L? ",
    "start": "1588670",
    "end": "1594690"
  },
  {
    "text": "And that will tell you why\nit has this name Laplacian. So the matrix L will have--",
    "start": "1594690",
    "end": "1602690"
  },
  {
    "text": "the degree 4 right will\nbe on the diagonal. That's coming from\nD. The other--",
    "start": "1602690",
    "end": "1609990"
  },
  {
    "text": "the minus 1's that come from\nB, the adjacency matrix,",
    "start": "1609990",
    "end": "1615750"
  },
  {
    "text": "will be associated with those\nnodes, and otherwise, all 0's.",
    "start": "1615750",
    "end": "1621510"
  },
  {
    "text": "So this is a typical row\nof L. This is typical row of L centered at that node.",
    "start": "1621510",
    "end": "1629280"
  },
  {
    "text": "So maybe that's node\nnumber 5, 10, 13. That's 13 out of 25 that\nwould show you this.",
    "start": "1629280",
    "end": "1637100"
  },
  {
    "text": "And the-- sorry. Those are minus 1's. Minus 1's.",
    "start": "1637100",
    "end": "1642330"
  },
  {
    "text": "So a 4 on the diagonal,\nand four minus 1's.",
    "start": "1642330",
    "end": "1647370"
  },
  {
    "text": "That's the model problem for\nwhen the graph is a grid-- square grid.",
    "start": "1647370",
    "end": "1653280"
  },
  {
    "text": "And do you associate that\nwith Laplace's equation? So this is the\nreason that Laplace--",
    "start": "1653280",
    "end": "1661759"
  },
  {
    "text": "why Laplace gets in it. Because Laplace's equation--\nthe differential equation--",
    "start": "1661760",
    "end": "1668940"
  },
  {
    "text": "is second derivative with\nrespect to x squared, and the second derivative with\nrespect to y squared is 0.",
    "start": "1668940",
    "end": "1677460"
  },
  {
    "text": "And what we have\nhere is Lu equals 0.",
    "start": "1677460",
    "end": "1682799"
  },
  {
    "text": "It's the discrete Laplacian,\nthe vector Laplacian, the graph Laplacian--",
    "start": "1682800",
    "end": "1688710"
  },
  {
    "text": "where the second x derivative\nis replaced by -1, 2, -1.",
    "start": "1688710",
    "end": "1695340"
  },
  {
    "text": "And the second y derivative\nis replaced by -1, 2, -1. Second differences in the\nx and the y directions.",
    "start": "1695340",
    "end": "1704490"
  },
  {
    "text": "So that's-- yeah. So that's the\nexplanation for Laplace.",
    "start": "1704490",
    "end": "1710610"
  },
  {
    "text": "It's the discrete Laplace-- discrete, or the finite\ndifference Laplace.",
    "start": "1710610",
    "end": "1717870"
  },
  {
    "text": "OK. Now to just finish, I have\nto tell you what the--",
    "start": "1717870",
    "end": "1726870"
  },
  {
    "text": "what clusters-- how do you\ndecide the clusters from L? How does L propose two\nclusters, the a's and b's?",
    "start": "1726870",
    "end": "1737920"
  },
  {
    "text": "And here's the answer. They come from\nthis eigenvector--",
    "start": "1737920",
    "end": "1746930"
  },
  {
    "text": "the Fiedler eigenvector. You look at that eigenvector. ",
    "start": "1746930",
    "end": "1753280"
  },
  {
    "text": "It's got some positive and\nsome negative components. The components with positive\nnumbers of this eigenvector--",
    "start": "1753280",
    "end": "1763000"
  },
  {
    "text": "so the positive\ncomponents of x--",
    "start": "1763000",
    "end": "1771790"
  },
  {
    "text": " of-- this eigenvector.",
    "start": "1771790",
    "end": "1779797"
  },
  {
    "text": " And there are negative\ncomponents of this eigenvector.",
    "start": "1779797",
    "end": "1785698"
  },
  {
    "text": "And those are the two clusters. ",
    "start": "1785698",
    "end": "1791929"
  },
  {
    "text": "So it's-- the cluster is--\nthe two clusters are decided by the eigenvector--",
    "start": "1791930",
    "end": "1798620"
  },
  {
    "text": "by the signs-- plus or minus\nsigns of the components. The plus signs go in one and\nthe minus signs go in another.",
    "start": "1798620",
    "end": "1806810"
  },
  {
    "text": "And you have to experiment to\nsee that that would succeed.",
    "start": "1806810",
    "end": "1812450"
  },
  {
    "text": "I don't know what it would do on\nthis, actually, because that's hardly split up into two.",
    "start": "1812450",
    "end": "1819980"
  },
  {
    "text": "I suppose maybe the\nsplit is along a line like that or something, to get--",
    "start": "1819980",
    "end": "1825080"
  },
  {
    "text": "I don't know what clustering. This is not a graph that\nis naturally clustered,",
    "start": "1825080",
    "end": "1831770"
  },
  {
    "text": "but you could still\ndo k-means on it. You could still do\nspectral clustering.",
    "start": "1831770",
    "end": "1840740"
  },
  {
    "text": "And you would find\nthis eigenvector. Now what's the point\nabout this eigenvector?",
    "start": "1840740",
    "end": "1846080"
  },
  {
    "text": "I'll finish in one moment. What do we know about\nthat eigenvector as",
    "start": "1846080",
    "end": "1851360"
  },
  {
    "text": "compared to that one? So here was an\neigenvector all 1's. Let me just make it\nall 1's, 1, 1, 1, 1.",
    "start": "1851360",
    "end": "1860149"
  },
  {
    "text": "In that picture, it's 25 1's. Here's the next eigenvector up.",
    "start": "1860150",
    "end": "1867320"
  },
  {
    "text": "And what's the relation between\nthose two eigenvectors of L? They are--",
    "start": "1867320",
    "end": "1873964"
  },
  {
    "text": "AUDIENCE: Orthogonal. GILBERT STRANG: Orthogonal. These are eigenvectors\nof a symmetric matrix.",
    "start": "1873964",
    "end": "1879460"
  },
  {
    "text": "So they're orthogonal. So that means-- to be\northogonal to this guy means",
    "start": "1879460",
    "end": "1885840"
  },
  {
    "text": "that your components\nadd to 0, right? A Vector. Is orthogonal to all 1's.",
    "start": "1885840",
    "end": "1891510"
  },
  {
    "text": "That dot product is just,\nadd up the components. So we have a bunch of\npositive components",
    "start": "1891510",
    "end": "1896760"
  },
  {
    "text": "and a bunch of\nnegative components. They have the same sum, because\nthe dot product with that is 0.",
    "start": "1896760",
    "end": "1904620"
  },
  {
    "text": "And those two components--\nthose two sets of components are your-- to tell you the two clusters\nin spectral clustering.",
    "start": "1904620",
    "end": "1914250"
  },
  {
    "text": "So it's a pretty\nnifty algorithm. It does ask you to\ncompute an eigenvector.",
    "start": "1914250",
    "end": "1922920"
  },
  {
    "text": "And that, of course, takes time. And then there's a third,\nmore direct algorithm",
    "start": "1922920",
    "end": "1930400"
  },
  {
    "text": "to do this optimization problem. Well, actually, there are many.",
    "start": "1930400",
    "end": "1935970"
  },
  {
    "text": "This is an important\nproblem, so there are many proposed algorithms. Good. OK. I'm closing up.",
    "start": "1935970",
    "end": "1942360"
  },
  {
    "text": "Final question. Yeah? AUDIENCE: Is it possible to\ndo more than two clusters? GILBERT STRANG: Well,\ncertainly for k-means.",
    "start": "1942360",
    "end": "1948480"
  },
  {
    "text": "Now, if I had to do three\nclusters with Fiedler, I would look at the\nfirst three eigenvectors.",
    "start": "1948480",
    "end": "1954740"
  },
  {
    "text": "And, well, the first\none would be nothing. And I would look\nat the next two.",
    "start": "1954740",
    "end": "1959790"
  },
  {
    "text": "And that would be\npretty successful. If I wanted six\nclusters, it probably",
    "start": "1959790",
    "end": "1965130"
  },
  {
    "text": "would fall off in the\nquality of the clustering. Yeah.",
    "start": "1965130",
    "end": "1970200"
  },
  {
    "text": "But that certainly-- I\nwould look at the lowest six eigenvectors, and get somewhere.",
    "start": "1970200",
    "end": "1976920"
  },
  {
    "text": "Yeah. Right. So OK. So that's a topic--",
    "start": "1976920",
    "end": "1982050"
  },
  {
    "text": "an important topic-- a sort of\nstandard topic in applied graph",
    "start": "1982050",
    "end": "1988320"
  },
  {
    "text": "theory. OK. So see you Wednesday. I'm hoping, on Wednesday--",
    "start": "1988320",
    "end": "1997710"
  },
  {
    "text": "so Professor Edelman has\ntold me a new and optimal way",
    "start": "1997710",
    "end": "2004039"
  },
  {
    "text": "to look at the problem\nof backpropagation.",
    "start": "2004040",
    "end": "2009995"
  },
  {
    "text": "Do you remember backpropagation? If you remember\nthe lecture on it-- you don't want to remember\nthe lecture on it.",
    "start": "2009995",
    "end": "2019299"
  },
  {
    "text": "It's a tricky, messy\nthing to explain. But he says, if I explain it\nusing Julia in linear algebra,",
    "start": "2019300",
    "end": "2030110"
  },
  {
    "text": "it's clear. So we'll give him a\nchance on Wednesday to show that revolutionary\napproach to the explanation",
    "start": "2030110",
    "end": "2042110"
  },
  {
    "text": "of backpropagation. And I hope for-- I told him he could\nhave half an hour,",
    "start": "2042110",
    "end": "2048619"
  },
  {
    "text": "and projects would\ntake some time. I hope-- now we've had\ntwo with wild applause.",
    "start": "2048620",
    "end": "2055730"
  },
  {
    "text": "So I hope we get a couple\nmore in our last class.",
    "start": "2055730",
    "end": "2061919"
  },
  {
    "text": "OK. See you Wednesday. And if you bring-- well, if you have projects\nready, send them to me online,",
    "start": "2061920",
    "end": "2070460"
  },
  {
    "text": "and maybe a print out as well. That would be terrific. If you don't have them ready\nby the hour, they can go--",
    "start": "2070460",
    "end": "2081079"
  },
  {
    "text": "the envelope outside my\noffice would receive them. Good. So I'll see you Wednesday\nfor the final class.",
    "start": "2081080",
    "end": "2088090"
  },
  {
    "start": "2088090",
    "end": "2088889"
  }
]
[
  {
    "start": "0",
    "end": "92000"
  },
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare",
    "start": "0",
    "end": "6050"
  },
  {
    "text": "continue to offer high quality\neducational resources for free. To make a donation or to\nview additional materials",
    "start": "6050",
    "end": "12700"
  },
  {
    "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12700",
    "end": "18060"
  },
  {
    "text": "at ocw.mit.edu. PROFESSOR: What\nwe're going to talk about today is in\nthe previous class,",
    "start": "18060",
    "end": "25439"
  },
  {
    "text": "we did a lot of examples\non some data sets.",
    "start": "25440",
    "end": "30800"
  },
  {
    "text": "And they were artificially\ngenerated data sets, which",
    "start": "30800",
    "end": "36030"
  },
  {
    "text": "is a requirement in terms of\nif you want to do anything with big data and\nreally show stuff,",
    "start": "36030",
    "end": "41960"
  },
  {
    "text": "it can be really difficult\nto pass around terabytes and terabytes of data. So having data generators\nthat generate the statistics",
    "start": "41960",
    "end": "50270"
  },
  {
    "text": "that you want or approximate\nthe statistics that you want are good to have. We had a previous lecture\non power law graphs",
    "start": "50270",
    "end": "56690"
  },
  {
    "text": "and talked about a perfect\n[AUDIO OUT] is very useful, and I encourage you to use that. It's a useful analytic tool.",
    "start": "56690",
    "end": "62334"
  },
  {
    "text": "This one, we're going to\ntalk about Kronecker graphs and generation. Kronecker graphs are used in the\nlargest benchmark in the world",
    "start": "62334",
    "end": "71140"
  },
  {
    "text": "for benchmarking graph systems. And then finally,\nI'm going to talk a little bit about performance.",
    "start": "71140",
    "end": "76890"
  },
  {
    "text": "What are the things you\nshould be aware of when you're doing systems and building\nsystems from a performance",
    "start": "76890",
    "end": "83449"
  },
  {
    "text": "perspective, the\nkinds of things that are essentially fundamental\nlimits of the technology.",
    "start": "83449",
    "end": "89149"
  },
  {
    "text": "So moving forward, let's talk\nabout the Graph500 benchmark.",
    "start": "89150",
    "end": "97740"
  },
  {
    "start": "92000",
    "end": "92000"
  },
  {
    "text": "So the Graph500\nbenchmark was created to provide a\nmechanism for timing",
    "start": "97740",
    "end": "107240"
  },
  {
    "text": "the world's most\npowerful computers and see how good they were\non graph type operations.",
    "start": "107240",
    "end": "114679"
  },
  {
    "text": "And so I was\ninvolved and actually wrote some of the initial\ncode for this benchmark",
    "start": "114680",
    "end": "119790"
  },
  {
    "text": "about 5 or 10 years ago. And it's now become\na community effort,",
    "start": "119790",
    "end": "125850"
  },
  {
    "text": "and the code has changed,\nand other types of things. And it's mainly\nmeant for dealing",
    "start": "125850",
    "end": "132760"
  },
  {
    "text": "with parallel\nin-memory computations, but the benchmark\nis actually very useful for timing databases\nor any types of things.",
    "start": "132760",
    "end": "140810"
  },
  {
    "text": "You can do the exact\nsame operations. So it generates\ndata, and then it has you construct it\nin a graph, and then",
    "start": "140810",
    "end": "147599"
  },
  {
    "text": "it goes on to do some\nother operations. And so we've actually\nfound it to be a very useful tool\nas a very fast,",
    "start": "147600",
    "end": "154329"
  },
  {
    "text": "high-performance data generator. And if you want to time\ninserts of power law data, it's very useful for that.",
    "start": "154330",
    "end": "160989"
  },
  {
    "text": "This is some older\nperformance numbers. But this just shows\nessentially here",
    "start": "160990",
    "end": "168550"
  },
  {
    "text": "on a single core of computing\ncapability, the number",
    "start": "168550",
    "end": "174340"
  },
  {
    "text": "of entries that we're inserting\ninto a table and the inserts",
    "start": "174340",
    "end": "179459"
  },
  {
    "text": "per second that we're getting. So the single core\nperformance here for this data into\nAccumulo, it's",
    "start": "179460",
    "end": "186920"
  },
  {
    "text": "about 20,000 inserts per second. So there's a one core\ndatabase, very, very small.",
    "start": "186920",
    "end": "193440"
  },
  {
    "text": "As you've seen-- we've\neven showed last week on modern servers\nwhere we're getting",
    "start": "193440",
    "end": "198870"
  },
  {
    "text": "several thousand inserts per\nsecond on standard databases.",
    "start": "198870",
    "end": "205040"
  },
  {
    "text": " I'm comparing this also with\njust D4M without a database.",
    "start": "205040",
    "end": "212230"
  },
  {
    "text": "If I just have triples and I\nconstruct an associative array, how fast does it do that?",
    "start": "212230",
    "end": "217720"
  },
  {
    "text": "And so obviously, D4M is\nlimited by how much memory you have on your system,\nbut it just show you",
    "start": "217720",
    "end": "224790"
  },
  {
    "text": "the constructing and\nassociative array. And memory is faster\nthan inserting data",
    "start": "224790",
    "end": "230980"
  },
  {
    "text": "into a database\nby a good amount. And so again, if you could\nwork with associative arrays",
    "start": "230980",
    "end": "236100"
  },
  {
    "text": "and memory, that's going\nto be better for you. Obviously, though,\nthe database allows",
    "start": "236100",
    "end": "242939"
  },
  {
    "text": "you to go to very large sizes. And one of the great\nthings about Accumulo is this line stays pretty flat.",
    "start": "242940",
    "end": "250604"
  },
  {
    "text": "You can go on, out, and\nout, and out, and out. That's what it really\nprides itself on, is that-- as you add data,\nit might degrade slightly,",
    "start": "250604",
    "end": "261588"
  },
  {
    "text": "but if you're\ninserting it right, that line stays pretty flat. ",
    "start": "261589",
    "end": "267554"
  },
  {
    "text": "In the last class,\nwe did show how to do parallel inserts\nin parallel D4M. And this shows parallel inserts\nhere on a single node database,",
    "start": "267554",
    "end": "277790"
  },
  {
    "text": "D4M itself basically taking\nthis number and scaling it up and also into the database.",
    "start": "277790",
    "end": "283220"
  },
  {
    "text": "And so here a single\nnode, single core database",
    "start": "283220",
    "end": "288910"
  },
  {
    "text": "who are getting 100,000\ninserts a second with that. And so that just shows you some\nof the parallel expectations,",
    "start": "288910",
    "end": "299140"
  },
  {
    "text": "and when you should use\nparallel versions databases.",
    "start": "299140",
    "end": "305740"
  },
  {
    "text": "Again, if you can be in memory,\nyou want to be in memory. It's faster. If you can be in\nparallel memory,",
    "start": "305740",
    "end": "311809"
  },
  {
    "text": "you probably want to\nbe in parallel memory. That's faster. But if you have really large\nproblems, then obviously, you need to go to the database.",
    "start": "311809",
    "end": "318070"
  },
  {
    "text": "And that's what that's for. The data in the\ngraph 500 benchmark",
    "start": "318070",
    "end": "329160"
  },
  {
    "start": "324000",
    "end": "324000"
  },
  {
    "text": "is what we call a\nKronecker graph. It basically takes a little,\ntiny matrix, a little seed",
    "start": "329160",
    "end": "337500"
  },
  {
    "text": "matrix-- in this case,\ng-- and you can imagine what it looks like here.",
    "start": "337500",
    "end": "343820"
  },
  {
    "text": "Imagine this is a\ntwo-by-two matrix here. You can sort of see, maybe, a\nlittle bit of the structure.",
    "start": "343820",
    "end": "349310"
  },
  {
    "text": "And then it does a\nKronecker product of that on out to create\nand adjacency matrix.",
    "start": "349310",
    "end": "354460"
  },
  {
    "text": " By creating this adjacency\nmatrix, that creates the graph.",
    "start": "354460",
    "end": "361100"
  },
  {
    "text": "And as a result, it naturally\nproduces-- this is the result.",
    "start": "361100",
    "end": "366380"
  },
  {
    "text": "It produces something\nthat naturally looks like a power law graph here. And this just\nshows you the dots,",
    "start": "366380",
    "end": "372530"
  },
  {
    "text": "shows you the power law\ndegree distribution of that.",
    "start": "372530",
    "end": "377540"
  },
  {
    "text": "You can see the slope\nthere generated from this.",
    "start": "377540",
    "end": "382790"
  },
  {
    "text": "I should say one of\nthe powerful things about this particular\ngenerator is",
    "start": "382790",
    "end": "387860"
  },
  {
    "text": "you don't have to form the\nadjacency matrix to construct the graph.",
    "start": "387860",
    "end": "392930"
  },
  {
    "text": "So it doesn't require you to\nbuild this gigantic matrix. It generates the\nedges atomically.",
    "start": "392930",
    "end": "399920"
  },
  {
    "text": "If you have many, many\nprocesses all doing this, as long as they set\ntheir random number seeds",
    "start": "399920",
    "end": "406020"
  },
  {
    "text": "to different\nlocations, they'll all be generating perfectly\nconsistent edges in a larger",
    "start": "406020",
    "end": "412350"
  },
  {
    "text": "graph. So people have run this\non computers with millions",
    "start": "412350",
    "end": "417950"
  },
  {
    "text": "of cores to do that. Because the graph generator\nis completely-- parallel",
    "start": "417950",
    "end": "424370"
  },
  {
    "text": "allows you to essentially\ncreate a giant graph. And also, the Kronecker graph\ndoes generate this structure",
    "start": "424370",
    "end": "435470"
  },
  {
    "text": "here, which is these\nbumps and wiggles. And that actually\ncorresponds to the power k.",
    "start": "435470",
    "end": "444080"
  },
  {
    "text": "So you can count\nthe number of bumps. We have 1, 2, 3, 4, 5, 6, 7, 8.",
    "start": "444080",
    "end": "450250"
  },
  {
    "text": "So this would be a\ng to the 8th graph. So that structure\nis visible there,",
    "start": "450250",
    "end": "458900"
  },
  {
    "text": "which is an artificial\nfeature of the data. And so one of the things\nthat's actually occurred now--",
    "start": "458900",
    "end": "467114"
  },
  {
    "text": "because people have\nbeen actually trying to use this generator because\nit's so fast and efficient",
    "start": "467114",
    "end": "472340"
  },
  {
    "text": "to simulate graphs. And we've basically\nsaid to people, not really designed to\nsimulate large graphs,",
    "start": "472340",
    "end": "479790"
  },
  {
    "text": "because it does create these\nartificial structures in there. And that's the reason we develop\nthe perfect power law method.",
    "start": "479790",
    "end": "488010"
  },
  {
    "text": "Because that's a\nmuch better method if you're actually trying to\nsimulate graphs for doing that.",
    "start": "488010",
    "end": "493730"
  },
  {
    "text": "Again, this method\nhas these advantages in terms of being\nable to generate them. ",
    "start": "493730",
    "end": "501340"
  },
  {
    "text": "Another advantage\nof these Kronecker graphs-- and so in this case,\nB is my little matrix here",
    "start": "501340",
    "end": "509190"
  },
  {
    "text": "that I'm going to do\nKronecker products of. In fact, let me remind you about\nwhat a Kronecker product is.",
    "start": "509190",
    "end": "515940"
  },
  {
    "start": "513000",
    "end": "513000"
  },
  {
    "text": "So if I have here\na matrix B, that's nb by nb, although these\ndon't have to be square,",
    "start": "515940",
    "end": "521919"
  },
  {
    "text": "and another matrix\nC that's nc by mc doesn't also have to be square. And when you do the\nKronecker product,",
    "start": "521919",
    "end": "527500"
  },
  {
    "text": "basically what you're\ndoing is essentially taking c and multiplying\nby the first element, and having essentially\na block here.",
    "start": "527500",
    "end": "534140"
  },
  {
    "text": "And so it's a way of\nessentially expanding the matrix in both dimensions.",
    "start": "534140",
    "end": "539870"
  },
  {
    "text": "And Jure Leskovec, who's\nnow a professor at Stanford, essentially developed\nthis method back in 2005",
    "start": "539870",
    "end": "549620"
  },
  {
    "text": "for creating these\nmatrices which allow you to very naturally\ncreate power law matrices,",
    "start": "549620",
    "end": "555259"
  },
  {
    "text": "and even had tools for\nfitting them to data, which is a useful thing.",
    "start": "555260",
    "end": "561490"
  },
  {
    "text": "Again, its biggest\nimpact has been on generating very large graphs,\npower law graphs very quickly.",
    "start": "561490",
    "end": "568450"
  },
  {
    "text": " The Kronecker graph itself\nhas several different types",
    "start": "568450",
    "end": "577370"
  },
  {
    "start": "572000",
    "end": "572000"
  },
  {
    "text": "that I call here, basically,\nexplicit, stochastic, and an instance. So if I just set the\ncoefficients of the Kronecker",
    "start": "577370",
    "end": "587260"
  },
  {
    "text": "graph to be ones and\nzeroes and I Kronecker out, I will get structures\nthat look like this.",
    "start": "587260",
    "end": "593356"
  },
  {
    "text": "So this is a Kronecker\ngraph that essentially is a bipartite,\nessentially starting with a-- what you can call a\nstar graph and then a diagonal.",
    "start": "593356",
    "end": "602410"
  },
  {
    "text": "So that's 1. That's g1. Then I Kronecker product\nagain, g2 and g3,",
    "start": "602410",
    "end": "610385"
  },
  {
    "text": "and I get these different\nstructure 0 1 matrices.",
    "start": "610385",
    "end": "615760"
  },
  {
    "text": "And so it's only 0's and\n1's, and so the structure and the connections\nare very obvious.",
    "start": "615760",
    "end": "621280"
  },
  {
    "text": "And this is actually\nuseful for doing theory.",
    "start": "621280",
    "end": "626630"
  },
  {
    "text": "So you can actually do\na fair amount of theory on the structure of graphs\nusing the 0 1 matrices.",
    "start": "626630",
    "end": "634600"
  },
  {
    "text": "And in fact, there's\na famous paper by Van Loan on\nKronecker products.",
    "start": "634600",
    "end": "639889"
  },
  {
    "text": "And basically, the paper\nis full of identities of Kronecker products that--\nthe eigenvalues of the Kronecker",
    "start": "639890",
    "end": "649350"
  },
  {
    "text": "product of two matrices is\nthe same as the Kronecker product of their eigenvalues,\nand a whole series",
    "start": "649350",
    "end": "655030"
  },
  {
    "text": "of those things. And so what's nice is\nif you compute something on just the small matrix\ng, you can very quickly",
    "start": "655030",
    "end": "664040"
  },
  {
    "text": "compute all the properties of\nthe Kronecker product matrix, and that makes it very\nnice for doing theory.",
    "start": "664040",
    "end": "670670"
  },
  {
    "text": "And so there's times when\nyou want to understand the structure of these things.",
    "start": "670670",
    "end": "675730"
  },
  {
    "text": "Very useful theoretical\ntool for doing that.  If instead, we use our\nC graph, instead of",
    "start": "675730",
    "end": "684660"
  },
  {
    "text": "it being 1's and 0's,\nit contains, say, numbers between 0 and 1\nthat are probabilities,",
    "start": "684660",
    "end": "691330"
  },
  {
    "text": "the probability of creating\nan edge between those two vertices. And we multiply that on out.",
    "start": "691330",
    "end": "698460"
  },
  {
    "text": "You get, essentially, a giant\nprobability matrix showing the probability of edges.",
    "start": "698460",
    "end": "705410"
  },
  {
    "text": "These are the same, but here\nwe see we have differences. We don't just have 0's and 1's. We have values\nbetween 0's and 1's.",
    "start": "705410",
    "end": "711670"
  },
  {
    "text": "And then using the Kronecker\ngeneration technique, we essentially draw instances\nfrom this probability matrix",
    "start": "711670",
    "end": "719300"
  },
  {
    "text": "over here. So this allows us\nto randomly sample. So when you're talking\nabout Kronecker graphs, there's three\ndifferent types here.",
    "start": "719300",
    "end": "726210"
  },
  {
    "text": "This is very easy\nto do theory on. You can do theory on\nthis, too, but it tends to be a little bit more work-y.",
    "start": "726210",
    "end": "733370"
  },
  {
    "text": "And then likewise, when\nyou're doing simulations, usually you end up with\nKronecker graphs like this.",
    "start": "733370",
    "end": "739640"
  },
  {
    "text": " As an example of the\nkind of theory we can do,",
    "start": "739640",
    "end": "749300"
  },
  {
    "start": "744000",
    "end": "744000"
  },
  {
    "text": "one of the nicest graphs to\nwork with are bipartite graphs.",
    "start": "749300",
    "end": "754950"
  },
  {
    "text": "So a bipartite graph is\ntwo sets of vertices, and each vertex has a\nconnection to every vertex",
    "start": "754950",
    "end": "762820"
  },
  {
    "text": "in the other set, but they\ndon't have any connections amongst themselves. And so here, I'm showing you\na bipartite or star graph,",
    "start": "762820",
    "end": "771430"
  },
  {
    "text": "so basically one\nset of vertices here and another set\nof vertices here. And all the vertices have\nconnections to those vertex,",
    "start": "771430",
    "end": "777830"
  },
  {
    "text": "but they have no\nconnections themselves. And this is the adjacency\nmatrix of that graph.",
    "start": "777830",
    "end": "784130"
  },
  {
    "text": "And here is another\nbipartite graph. It's a 3 1 set. And if I Kronecker product\ntwo bipartite graphs,",
    "start": "784130",
    "end": "792600"
  },
  {
    "text": "the result is two\nmore bipartite graphs. So as we see here, we've\ncreated this one here",
    "start": "792600",
    "end": "799420"
  },
  {
    "text": "and this one here. And so in my notation, I'll\nsay B 5, 1 is a bipartite.",
    "start": "799420",
    "end": "806890"
  },
  {
    "text": "That's basically--\nI'm saying I have a matrix that's a 5, 1 bipartite\ngraph, 3, 1 bipartite graph.",
    "start": "806890",
    "end": "815330"
  },
  {
    "text": "And within some\npermutation, they produce a matrix that is the\nunion of a 15, a 1, and a 3, 5.",
    "start": "815330",
    "end": "825340"
  },
  {
    "text": "And this result actually was\nfirst shown by a professor by the name of Weichsel in 1962.",
    "start": "825340",
    "end": "833040"
  },
  {
    "text": "And there was actually\na little flurry of activity back in the 1960s\nwith this whole algebraic view",
    "start": "833040",
    "end": "841600"
  },
  {
    "text": "of graph theory, which\nwas very productive,",
    "start": "841600",
    "end": "850139"
  },
  {
    "text": "but then it all died off. And after the lecture, I can\ntell you why that happened. But now it's all coming\nback, which is nice.",
    "start": "850140",
    "end": "856850"
  },
  {
    "text": "So it took us 50 years\nto rediscover this work. But there's actually\na whole book on it",
    "start": "856850",
    "end": "862350"
  },
  {
    "text": "with lots of\ninteresting results. But then this just shows\nyou the general result here.",
    "start": "862350",
    "end": "868730"
  },
  {
    "text": "For any two bipartite graphs,\nif I Kronecker product them together, they are\nunder some permutation",
    "start": "868730",
    "end": "874560"
  },
  {
    "text": "equal to two other\nbipartite graphs. And this naturally shows\nyou how the power law",
    "start": "874560",
    "end": "883870"
  },
  {
    "text": "structure gets built up when you\nKronecker product these graphs. So basically, you\nhad this and this.",
    "start": "883870",
    "end": "893080"
  },
  {
    "text": "And there, we basically-- that's\nthe super node vertex here, this 1, 1 vertex.",
    "start": "893080",
    "end": "898680"
  },
  {
    "text": "And these are the\nlower degree pieces. And then these\nother vertices here",
    "start": "898680",
    "end": "905980"
  },
  {
    "text": "are the singleton vertices. So you can see as\nyou naturally product",
    "start": "905980",
    "end": "911570"
  },
  {
    "text": "these bipartite graphs\ntogether, you naturally create these power law graphs.",
    "start": "911570",
    "end": "918700"
  },
  {
    "text": "An example-- I won't really\nbelabor the details here-- you can compute the\ndegree distribution.",
    "start": "918700",
    "end": "925960"
  },
  {
    "start": "919000",
    "end": "919000"
  },
  {
    "text": "And this is all-- there's a long\nchapter on this in the book. Basically, you can\ncompute analytically",
    "start": "925960",
    "end": "932310"
  },
  {
    "text": "the degree distributions\nof Kronecker producing bipartite graphs. This shows you the\nformula for doing that.",
    "start": "932310",
    "end": "940180"
  },
  {
    "text": "And here is the actual\ndegree distribution with the binomial\ncoefficients for that.",
    "start": "940180",
    "end": "948399"
  },
  {
    "text": "And so a very useful thing. You can a priori do that. This shows you the results.",
    "start": "948400",
    "end": "953949"
  },
  {
    "start": "952000",
    "end": "952000"
  },
  {
    "text": "So if I have a Kronecker\nproduct of a bipartite graph n equals 5 comma 1, and I take\nit out to the 10th power,",
    "start": "953950",
    "end": "961470"
  },
  {
    "text": "this is the result\nis this blue line. And what you see is that\nyou get-- if you connect",
    "start": "961470",
    "end": "968500"
  },
  {
    "text": "the last vertex and this\nvertex-- essentially our poor man's\nalpha-- or connected any one of these\nother sets here,",
    "start": "968500",
    "end": "975880"
  },
  {
    "text": "they have a constant\nslope of negative 1. So that's a theoretical\nresult is that they have this constant slope.",
    "start": "975880",
    "end": "983170"
  },
  {
    "text": "And that's true down here, k to\nthe 5, other types of things. So we do get this bowing effect.",
    "start": "983170",
    "end": "988420"
  },
  {
    "text": "So it's not perfect\nwith respect to that. But you can see\nhow this power law",
    "start": "988420",
    "end": "994420"
  },
  {
    "text": "is baked in to the\nKronecker generator, which is a very nice thing.",
    "start": "994420",
    "end": "1000910"
  },
  {
    "text": " This shows a sample.",
    "start": "1000910",
    "end": "1006830"
  },
  {
    "start": "1004000",
    "end": "1004000"
  },
  {
    "text": "We basically created a\n4 by 1 bipartite graph",
    "start": "1006830",
    "end": "1012150"
  },
  {
    "text": "and then sampled it. And so this shows the\nstochastic instance.",
    "start": "1012150",
    "end": "1017280"
  },
  {
    "text": "There's about a\nmillion vertices here. Shows you that. And then these\ncurves here show--",
    "start": "1017280",
    "end": "1023970"
  },
  {
    "text": "when we take the\nstochastic graph and analytically compute\nwhat the expected value",
    "start": "1023970",
    "end": "1031150"
  },
  {
    "text": "of every single degree\nis assuming a Poisson distribution, and you can\nsee that we get pretty much",
    "start": "1031150",
    "end": "1037270"
  },
  {
    "text": "a perfect fit here all the way\nout, except to the very end",
    "start": "1037270",
    "end": "1043339"
  },
  {
    "text": "here. And this is where you get some\npretty interesting statistics",
    "start": "1043339",
    "end": "1049210"
  },
  {
    "text": "going on. In theory, no one vertex--\nthis is your distribution.",
    "start": "1049210",
    "end": "1059779"
  },
  {
    "text": "No one vertex should actually\nbe attracting this many nodes. But you have so many\nvertices with one of them",
    "start": "1059780",
    "end": "1066762"
  },
  {
    "text": "that have this problem. When you sum them all\ntogether, one of them gets to be chosen\nto be the winner. And it's what pops it up here.",
    "start": "1066762",
    "end": "1074140"
  },
  {
    "text": "So all the way out\nto the-- our fit is very good all the way\nout to the super node, and we have this\ndifference here.",
    "start": "1074140",
    "end": "1080264"
  },
  {
    "text": "And this is where the Poisson\nstatistics begin to fail. So again, lots of opportunities\nfor a very interesting theory",
    "start": "1080264",
    "end": "1087670"
  },
  {
    "text": "there.  So that's just pure\nbipartite graphs.",
    "start": "1087670",
    "end": "1094460"
  },
  {
    "start": "1090000",
    "end": "1090000"
  },
  {
    "text": "But bipartite graphs have\nno inter-group connections. So we can actually\ncreate something",
    "start": "1094460",
    "end": "1101669"
  },
  {
    "text": "that looks like\na power law graph and see all the community\nsubstructure very clearly.",
    "start": "1101670",
    "end": "1107210"
  },
  {
    "text": "But those communities are\nnot connected in any way. And so to create connections\nto the communities,",
    "start": "1107210",
    "end": "1113330"
  },
  {
    "text": "we have to add the identity\nmatrix down the diagonal. And that well then now connect\nall our sub bipartite graphs",
    "start": "1113330",
    "end": "1120741"
  },
  {
    "text": "together.  So this just shows\nhere-- so we basically",
    "start": "1120741",
    "end": "1126020"
  },
  {
    "text": "take our bipartite\ngraph plus the identity, and that's essentially\nthis combinatorial sum here",
    "start": "1126020",
    "end": "1133605"
  },
  {
    "text": "of the individual\nbipartite graphs there. Again, where in quotes, it\nmeans that there's a permutation",
    "start": "1133605",
    "end": "1139820"
  },
  {
    "text": "you need to actually\nmake this all work out. ",
    "start": "1139820",
    "end": "1147190"
  },
  {
    "start": "1147000",
    "end": "1147000"
  },
  {
    "text": "We actually do the computation.  This shows the 4, 1 bipartite\nplus an identity bipartite",
    "start": "1147190",
    "end": "1156860"
  },
  {
    "text": "graph out to the fourth power. So you see here you're\ngoing to get 1, 2. You can compute it on out there.",
    "start": "1156860",
    "end": "1164380"
  },
  {
    "text": "And what you see is this\nrecursive structure,",
    "start": "1164380",
    "end": "1169580"
  },
  {
    "text": "almost fractal like structure. So that's a nice way to view it. That's one way to see it.",
    "start": "1169580",
    "end": "1175020"
  },
  {
    "text": "But you don't really see\nthe bipartite substructure in there. It's hard to see\nwhat's going on there.",
    "start": "1175020",
    "end": "1181870"
  },
  {
    "text": "Well, since this is\nanalytic, we can actually compute a permutation that\nsays please recover all",
    "start": "1181870",
    "end": "1187049"
  },
  {
    "text": "those bipartite substructures. And so in the software,\nactually, [INAUDIBLE], we have a way of\nbasically computing",
    "start": "1187050",
    "end": "1193630"
  },
  {
    "text": "a permutation of this\nthat basically regroups all our bipartite groups here.",
    "start": "1193630",
    "end": "1200060"
  },
  {
    "text": "And then you can see all the\nbipartite cores or bipartite pieces, and then all\nthe interconnections",
    "start": "1200060",
    "end": "1207220"
  },
  {
    "text": "between those core\nbipartite pieces. To give you a better sense\nof what that really means,",
    "start": "1207220",
    "end": "1212940"
  },
  {
    "start": "1212000",
    "end": "1212000"
  },
  {
    "text": "here, basically we have b to\nthe i to the third power here.",
    "start": "1212940",
    "end": "1223000"
  },
  {
    "text": "That's what it looks like. If we just subtract out\nthe first and second order components, then we're left with\nthese are the interconnecting",
    "start": "1223000",
    "end": "1231390"
  },
  {
    "text": "pieces. We can see that much\nbetter when we permute it. So here is the permutation\nof just the bipartite piece,",
    "start": "1231390",
    "end": "1239120"
  },
  {
    "text": "and that shows you these\ncore bipartite chunks that are in the graph.",
    "start": "1239120",
    "end": "1245430"
  },
  {
    "text": "We then do the second term,\nwhich is b kron b kron i.",
    "start": "1245430",
    "end": "1250630"
  },
  {
    "text": "So this is the second. Now you can see that\nthis creates connections between these groups.",
    "start": "1250630",
    "end": "1256540"
  },
  {
    "text": "And then likewise, if you do\nthe next one-- so b kron i b,",
    "start": "1256540",
    "end": "1262850"
  },
  {
    "text": "that shows you the connections\nbetween these groups, and then ibb shows you\nthe different connections",
    "start": "1262850",
    "end": "1268230"
  },
  {
    "text": "in these groups. So each set of--\nwhen we take b plus i",
    "start": "1268230",
    "end": "1274610"
  },
  {
    "text": "and multiply it\nout and look at all those different combinations\nof the different multiplies",
    "start": "1274610",
    "end": "1280430"
  },
  {
    "text": "there, there's the core piece,\nwhich is just b kron to the 3,",
    "start": "1280430",
    "end": "1285890"
  },
  {
    "text": "and that creates this\ncore structure here, which is these dense pieces, and\nthen all the other polynomials",
    "start": "1285890",
    "end": "1293519"
  },
  {
    "text": "are essentially creating\ninterconnections between that. So you can get a really\ndeep understanding of the core structure and how\nthose things connect together,",
    "start": "1293519",
    "end": "1302270"
  },
  {
    "text": "which can be very interesting.  But we can compute these\ninterconnected structures",
    "start": "1302270",
    "end": "1309220"
  },
  {
    "text": "fairly nicely. Here's a higher order example\ngoing out to the fifth.",
    "start": "1309220",
    "end": "1316230"
  },
  {
    "text": "But we can compute the\nstructure, this chi structure here, which is essentially\na summary of these,",
    "start": "1316230",
    "end": "1322059"
  },
  {
    "text": "by just looking at a two-by-two.",
    "start": "1322060",
    "end": "1327630"
  },
  {
    "text": "So we can compute\nall the structures of the interconnections\nby just looking. Since we have a\nbipartite thing, we",
    "start": "1327630",
    "end": "1333129"
  },
  {
    "text": "can collapse all those\npieces down and just have a two-by-two. So we have here a little tiny\nversion of this structure here.",
    "start": "1333130",
    "end": "1339560"
  },
  {
    "text": "It shows you that. Likewise, this structure\nhere is summarized by that, and this structure here\nis summarized by that.",
    "start": "1339560",
    "end": "1346030"
  },
  {
    "text": "So you can get\ncomplete knowledge, not just at the low level scale,\nbut at all scales if you wanted to say I want to\nlook at the blocks",
    "start": "1346030",
    "end": "1352380"
  },
  {
    "text": "and how the edges are\nconnected in detail, or if I just want to\nconsider things in big blocks and connect them, I can do\nthat very nicely as well.",
    "start": "1352380",
    "end": "1361050"
  },
  {
    "start": "1361000",
    "end": "1361000"
  },
  {
    "text": "And again, we can compute the\ndegree distributions as well. So this just shows b\nkron to the k, and then",
    "start": "1361050",
    "end": "1368060"
  },
  {
    "text": "b plus the second order\nterms, and then moving on out. And actually, what you see is\nby adding this identity matrix,",
    "start": "1368060",
    "end": "1374290"
  },
  {
    "text": "all it does is slide the\ndegree structure over. It also does change\nthe slope a little bit",
    "start": "1374290",
    "end": "1381630"
  },
  {
    "text": "here by adding this\nidentity matrix along. So it's steeper\nthan the original.",
    "start": "1381630",
    "end": "1386940"
  },
  {
    "text": "And you can do other\ntypes of things. Here's something we did\nin iso-parametric ratios. I won't belabor that.",
    "start": "1386940",
    "end": "1392520"
  },
  {
    "start": "1389000",
    "end": "1389000"
  },
  {
    "text": "But it essentially is a way\nof computing the surface to volume of subgraphs. And we can compute\nthis analytically.",
    "start": "1392520",
    "end": "1398020"
  },
  {
    "text": "And we see that the\niso-parametric ratio of a bipartite\nsubgraph is constant,",
    "start": "1398020",
    "end": "1405480"
  },
  {
    "text": "but the half bipartite graph\nhas this property here. And just to summarize\nhere-- and this",
    "start": "1405480",
    "end": "1410640"
  },
  {
    "start": "1410000",
    "end": "1410000"
  },
  {
    "text": "is done a great deal\nin the chapter-- this just shows\ndifferent examples of the theoretical\nresults you can compute",
    "start": "1410640",
    "end": "1417049"
  },
  {
    "text": "for a bipartite graph or a\nbipartite plus an identity, the degree distribution.",
    "start": "1417050",
    "end": "1423530"
  },
  {
    "text": "Betweenness centrality is a\nfairly complicated metric. We actually haven't figured\nit out for this one, or I didn't bother to\nfigure it out for this one.",
    "start": "1423530",
    "end": "1429770"
  },
  {
    "text": "I can compute the\ndiameter very nicely. You can compute the eigenvalues. And the iso-parametric\nare just all examples",
    "start": "1429770",
    "end": "1437130"
  },
  {
    "text": "of a kind of theoretical\nwork you can do. And again, I think\nit's very useful if you want to understand\nthe substructure",
    "start": "1437130",
    "end": "1444159"
  },
  {
    "text": "and how the different\nparts of a power law graph might interact with each other.",
    "start": "1444160",
    "end": "1450390"
  },
  {
    "text": "So that just talks\nabout Kronecker graphs and what are the bases\nof these benchmarks.",
    "start": "1450390",
    "end": "1456539"
  },
  {
    "text": "And now I'm going to get\ninto some benchmarks again themselves. ",
    "start": "1456540",
    "end": "1463460"
  },
  {
    "start": "1463000",
    "end": "1463000"
  },
  {
    "text": "So this is just to remind folks. This just shows some\nexamples of when",
    "start": "1463460",
    "end": "1468760"
  },
  {
    "text": "you're doing benchmarking\nof inserts into a database.",
    "start": "1468760",
    "end": "1474382"
  },
  {
    "text": "Normally, when you do\nparallel computing, you have one parameter, which is\nhow many parallel processes are",
    "start": "1474382",
    "end": "1482830"
  },
  {
    "text": "you running at the same time. And so most of\nyour scaling curves will be with respect\nto, in this case,",
    "start": "1482830",
    "end": "1492430"
  },
  {
    "text": "the number of\nconcurrent processes that you're running\nat one time here. I think we're going\nup to 32 here.",
    "start": "1492430",
    "end": "1498770"
  },
  {
    "text": "That's the standard parameter\nin parallel computing. When you have parallel\ndatabases involved,",
    "start": "1498770",
    "end": "1504710"
  },
  {
    "text": "now you have a couple of\nadditional parameters, which just make it that\nmuch more stuff",
    "start": "1504710",
    "end": "1510820"
  },
  {
    "text": "you have to keep in your head. Essentially, in\nthis case, Accumulo calls its individual\ndata servers",
    "start": "1510820",
    "end": "1517410"
  },
  {
    "text": "tablet servers, so you have\nto be aware of how many tablet servers you have. So that's another parameter.",
    "start": "1517410",
    "end": "1523089"
  },
  {
    "text": "So you have to create\nseparate curves here. This is our scaling curve with\na number of ingest processes",
    "start": "1523089",
    "end": "1528260"
  },
  {
    "text": "into one tablet server versus\nnumber of ingest processes into six tablets servers.",
    "start": "1528260",
    "end": "1533940"
  },
  {
    "text": "And as you can see, not\na huge difference here at the small end. But eventually, the one tablet\nserver database levels off",
    "start": "1533940",
    "end": "1544480"
  },
  {
    "text": "while the other one\nkeeps on scaling. And so this is very tricky. If you want to do\nthese kind of results,",
    "start": "1544480",
    "end": "1550280"
  },
  {
    "text": "you have to be aware of\nboth of these parameters in order to really\nunderstand what you're doing.",
    "start": "1550280",
    "end": "1556520"
  },
  {
    "text": " There's also a third\nparameter which",
    "start": "1556520",
    "end": "1561770"
  },
  {
    "start": "1561000",
    "end": "1561000"
  },
  {
    "text": "is generally true\nof most databases, and Accumulo is no\nexception, which is that you're inserting a\ntable into a parallel database,",
    "start": "1561770",
    "end": "1570260"
  },
  {
    "text": "that table is going to be split\namongst the different parallel",
    "start": "1570260",
    "end": "1575740"
  },
  {
    "text": "servers in the database. And that will have a big\nimpact on performance.",
    "start": "1575740",
    "end": "1582150"
  },
  {
    "text": "How many splits you\nhave-- because you're not going to be able to take\nadvantage of-- if you have",
    "start": "1582150",
    "end": "1587660"
  },
  {
    "text": "fewer splits than the number\nof database server nodes, then you're not taking\nadvantage of those. And then how balanced\nthose splits are.",
    "start": "1587660",
    "end": "1595250"
  },
  {
    "text": "Is the data going in\nuniformly into those things? And so this just shows you\nan example of an 8 tablet",
    "start": "1595250",
    "end": "1602720"
  },
  {
    "text": "server Accumulo\ndoing the inserts with no splits versus doing it,\nin this case, with 35 splits.",
    "start": "1602720",
    "end": "1608550"
  },
  {
    "text": "And you see there's a rather\nlarge impact on the performance there. So D4M actually has tools.",
    "start": "1608550",
    "end": "1614420"
  },
  {
    "text": "We didn't really go into them. But if you look at\nthe documentation, we're allowing you to do splits.",
    "start": "1614420",
    "end": "1620650"
  },
  {
    "text": "The databases we've\ngiven you access to are all single node\ndatabases, so we've made your life, in\na certain sense, a little bit easier\nthat you don't",
    "start": "1620650",
    "end": "1626896"
  },
  {
    "text": "have to worry about splits. But it is something-- as\nyou work on larger systems, you have to be very\naware of the splits.",
    "start": "1626896",
    "end": "1633705"
  },
  {
    "text": " Another thing that's\noften very important",
    "start": "1633705",
    "end": "1640940"
  },
  {
    "start": "1637000",
    "end": "1637000"
  },
  {
    "text": "when you're inserting\ninto a database is the size of\nthe chunks of data",
    "start": "1640940",
    "end": "1646480"
  },
  {
    "text": "you're handing to the database. This is sometimes\ncalled the block size. This is a very\nimportant parameter.",
    "start": "1646480",
    "end": "1651790"
  },
  {
    "text": "Blocking of programs\nis very important.",
    "start": "1651790",
    "end": "1656820"
  },
  {
    "text": "Probably the key thing we\ndo in optimizing any program is coming up, finding\nwhat the right block",
    "start": "1656820",
    "end": "1663190"
  },
  {
    "text": "size is for a system. Because it almost always has a\npeak around some number here. And so this just\nshows the impact",
    "start": "1663190",
    "end": "1673260"
  },
  {
    "text": "of block size on the performance\nrate here for Accumulo.",
    "start": "1673260",
    "end": "1679420"
  },
  {
    "text": "And the nice about\nD4M, there's actually a parameter you can set for the\ntable which will say how many bytes I want to set.",
    "start": "1679420",
    "end": "1686040"
  },
  {
    "text": "I think the default is\n500 kilobytes, which is a lot smaller than\nI would've thought, but it's a number\nthat we found tends",
    "start": "1686040",
    "end": "1691751"
  },
  {
    "text": "to be fairly optimal across\na wide range of things. Typically, when you do\ninserts into a database, you're like, well, I want\nto give you the biggest",
    "start": "1691751",
    "end": "1698459"
  },
  {
    "text": "chunk that I can and move on. And Accumulo and probably\na lot of databases actually like to get\ndata in smaller chunks",
    "start": "1698459",
    "end": "1704620"
  },
  {
    "text": "than you might think. Basically, what's\nhappening then is if you're giving it\nthe right size chunks,",
    "start": "1704620",
    "end": "1710120"
  },
  {
    "text": "then it all fits in cache, and\nany sorting and other types of operations it has\nto do on that data can",
    "start": "1710120",
    "end": "1715510"
  },
  {
    "text": "be done much more efficiently. So this just shows\nanother parameter you have to be worried about. If you do everything right--\nand I showed these results",
    "start": "1715510",
    "end": "1723710"
  },
  {
    "text": "before-- these are the kind\nof results you can get. This shows essentially on an 8\nnode system-- fairly powerful,",
    "start": "1723710",
    "end": "1731350"
  },
  {
    "text": "24 cores per node getting the\n4 million inserts or entries",
    "start": "1731350",
    "end": "1736710"
  },
  {
    "text": "per second that we saw, which\nis, to our knowledge, again, the world record\nholder for this.",
    "start": "1736710",
    "end": "1741970"
  },
  {
    "text": " That talks about inserts. Another thing that we also\nwant to look at is queries.",
    "start": "1741970",
    "end": "1751290"
  },
  {
    "start": "1751000",
    "end": "1751000"
  },
  {
    "text": "So as I said before, Accumulo\nis a row-based store, which",
    "start": "1751290",
    "end": "1757000"
  },
  {
    "text": "means if you give\nit a row key, it will return the result\nin constant time.",
    "start": "1757000",
    "end": "1762320"
  },
  {
    "text": "And so that's true. So we've done a bunch\nof queries here,",
    "start": "1762320",
    "end": "1768110"
  },
  {
    "text": "lots of different concurrent\nprocesses all querying at the same time. And you can see the response\ntime is generally, they say,",
    "start": "1768110",
    "end": "1777600"
  },
  {
    "text": "around 50 milliseconds,\nwhich is great. And this is the full\nround trip time. A lot of this could have\nbeen network latency,",
    "start": "1777600",
    "end": "1783750"
  },
  {
    "text": "for all we know. So that's what you expect. That's what Accumulo does. If you do row queries,\nthen you get constant time.",
    "start": "1783750",
    "end": "1790270"
  },
  {
    "text": "Now, as we've\ntalked about before, we do our special\nexploded transpose schema, which essentially give this\nperformance for both row",
    "start": "1790270",
    "end": "1797659"
  },
  {
    "text": "and column queries. But if you have a table\nwhere you haven't done that and you are going\nto query a column,",
    "start": "1797660",
    "end": "1804059"
  },
  {
    "start": "1804000",
    "end": "1804000"
  },
  {
    "text": "it's a complete\nscan of the table. And so you see here-- when\nyou want to do a column query,",
    "start": "1804060",
    "end": "1812780"
  },
  {
    "text": "the performance is just\ngoing to go up and up and up, because they're all just\ndoing more and more scans,",
    "start": "1812780",
    "end": "1818460"
  },
  {
    "text": "and the system can only\nscan at a certain rate. So that's, again,\nthe main reason",
    "start": "1818460",
    "end": "1824230"
  },
  {
    "text": "why we do these special schemas\nis to avoid this performance penalty. ",
    "start": "1824230",
    "end": "1830890"
  },
  {
    "text": "So finally, in talking\nabout performance, let's talk a little bit\nabout D4M performance itself.",
    "start": "1830890",
    "end": "1840810"
  },
  {
    "start": "1835000",
    "end": "1835000"
  },
  {
    "text": "If you write your D4M\nprograms optimally--",
    "start": "1840810",
    "end": "1847610"
  },
  {
    "text": "and this sometimes\ntakes a while to get to, because usually you\ndon't quite have the-- or I should say, in the most\nelegant way possible, again,",
    "start": "1847610",
    "end": "1855509"
  },
  {
    "text": "this sometimes requires\nsome understanding. Most applications\nend up becoming",
    "start": "1855510",
    "end": "1861090"
  },
  {
    "text": "a combination of\nmatrix multiplies on these associative arrays.",
    "start": "1861090",
    "end": "1866940"
  },
  {
    "text": "Now, it's usually not the\nfirst program I write, but usually, it's\nthe last one I write. It finally dawns on me how to do\nthe entire complicated analytic",
    "start": "1866941",
    "end": "1875460"
  },
  {
    "text": "and all its queries as a\nseries of special sparse matrix multiplies, which then allows\nus to maximally leverage",
    "start": "1875460",
    "end": "1882570"
  },
  {
    "text": "the underlying libraries\nwhich have been very optimized to do--\nit's basically not",
    "start": "1882570",
    "end": "1889720"
  },
  {
    "text": "calling any of my code. It's just calling the MATLAB\nsparse matrix multiply routine, which is further calling the\nsparse BLAS, which are heavily",
    "start": "1889720",
    "end": "1897350"
  },
  {
    "text": "optimized by the\ncomputing vendors, and likewise are\ncalling sort routines.",
    "start": "1897350",
    "end": "1902650"
  },
  {
    "text": "So the thing you have\nto understand, though, is that sparse matrix multiply\nhas fundamental hardware",
    "start": "1902650",
    "end": "1909910"
  },
  {
    "text": "limits depending on the kinds\nof multiplies you're doing here.",
    "start": "1909910",
    "end": "1914995"
  },
  {
    "text": "And we have a whole program\nthat basically times all these and generates them. So if you ever want to get what\nyour fundamental limits are,",
    "start": "1914995",
    "end": "1922492"
  },
  {
    "text": "we have a set of\nprograms that will run all these benchmarks\nfor you and show you what you can expect.",
    "start": "1922492",
    "end": "1929310"
  },
  {
    "text": "And this shows you,\nbasically, the fraction of the theoretical\npeak performance of the processor as a\nfunction of the total memory",
    "start": "1929310",
    "end": "1938190"
  },
  {
    "text": "on that processor. So this is all single core,\nsingle processor benchmarks.",
    "start": "1938190",
    "end": "1943870"
  },
  {
    "text": "So as you can see here, this\nis dense matrix multiply. And it's 95% efficient.",
    "start": "1943870",
    "end": "1952750"
  },
  {
    "text": "If I was to build a\npiece of special purpose hardware and a memory subsystem\nfor doing dense matrix",
    "start": "1952750",
    "end": "1960710"
  },
  {
    "text": "multiply, it would be\nidentical to the computers that you all have.",
    "start": "1960710",
    "end": "1966340"
  },
  {
    "text": "Your computers have\nbeen absolutely designed to do dense matrix multiply.",
    "start": "1966340",
    "end": "1971850"
  },
  {
    "text": "And for good or bad,\nthat's just the way it is. The caching structure,\nthe matrix multiply units,",
    "start": "1971850",
    "end": "1979860"
  },
  {
    "text": "the vectorization units, they're\nall designed to-- they're identical to a custom\nbuilt matrix multiply unit.",
    "start": "1979860",
    "end": "1987799"
  },
  {
    "text": "And so we get enormously\nhigh performance here, 95% peak on dense\nmatrix multiply.",
    "start": "1987800",
    "end": "1995110"
  },
  {
    "text": "Unfortunately, that hardware\narchitecture and everything we do it for dense\nmatrix multiply",
    "start": "1995110",
    "end": "2000640"
  },
  {
    "text": "is the opposite of\nwhat we would do if we built a computer for\ndoing sparse matrix multiply.",
    "start": "2000640",
    "end": "2007559"
  },
  {
    "text": "And that's why we have, when we\ngo from dense matrix multiply to sparse matrix multiply, this\n1,000x drop in performance.",
    "start": "2007560",
    "end": "2016700"
  },
  {
    "text": "And this is not getting\nbetter with time. This is getting worse with time.",
    "start": "2016700",
    "end": "2023044"
  },
  {
    "text": "And there's nothing\nyou can do about it. That is just what\nthe hardware does. Now, it's still better to\ndo sparse matrix multiply",
    "start": "2023044",
    "end": "2029470"
  },
  {
    "text": "than to convert it to\ndense, because you're still a net win by not computing\nall those zeros that you would",
    "start": "2029470",
    "end": "2037170"
  },
  {
    "text": "have in a very sparse matrix. So it's still a significant\nwin in execution time",
    "start": "2037170",
    "end": "2043130"
  },
  {
    "text": "to do your calculation\non sparse matrices if they are sparse,\nbut not otherwise.",
    "start": "2043130",
    "end": "2050149"
  },
  {
    "text": "And then-- so that's that.",
    "start": "2050150",
    "end": "2055719"
  },
  {
    "text": "This shows the\nassociative array.",
    "start": "2055719",
    "end": "2062210"
  },
  {
    "text": "So the top one is MATLAB dense,\nMATLAB sparse, D4M associative",
    "start": "2062210",
    "end": "2068869"
  },
  {
    "text": "array. And we worked very hard to\nmake the D4M associative",
    "start": "2068870",
    "end": "2074560"
  },
  {
    "text": "array be a constant factor\nbelow the core sparse. So you're really getting\nperformance that's",
    "start": "2074560",
    "end": "2081059"
  },
  {
    "text": "pretty darn close to that. And so generally, doing\nsparse matrix multiplies",
    "start": "2081060",
    "end": "2086919"
  },
  {
    "text": "on the associative arrays\nworks out pretty well. But again, there is still about\n21% efficient of the hardware.",
    "start": "2086920",
    "end": "2093940"
  },
  {
    "text": "And then the final\nthing is we have these special sparse matrix\nmultiplies where we concatenate",
    "start": "2093940",
    "end": "2100020"
  },
  {
    "text": "the keys together. If you remember way back when we\ndid the bioinformatics example,",
    "start": "2100020",
    "end": "2105150"
  },
  {
    "text": "we could do special\nmatrix multiplies that essentially preserved\nwhere the data came from.",
    "start": "2105150",
    "end": "2112010"
  },
  {
    "text": "If we correlated\ntwo DNA sequences, we would have a\nmatrix that would show",
    "start": "2112010",
    "end": "2119080"
  },
  {
    "text": "the IDs of the DNA sequence. And if we did these\nspecial matrix multiplies, the values would then hold the\nexact DNA sequences themselves",
    "start": "2119080",
    "end": "2128320"
  },
  {
    "text": "that were the matches. Well, there's a\nperformance hit that comes with holding that\nadditional information, all",
    "start": "2128320",
    "end": "2133920"
  },
  {
    "text": "of this string information. It may be one day we'll be\nable to optimize this further, although we've actually\noptimized it a fair bit",
    "start": "2133920",
    "end": "2140120"
  },
  {
    "text": "already. And so there's\nanother factor of 100. And it looks like\nthis is just, again,",
    "start": "2140120",
    "end": "2145600"
  },
  {
    "text": "fundamentally\nlimited by the speed at which the hardware will\ndo sparse matrix multiply",
    "start": "2145600",
    "end": "2151789"
  },
  {
    "text": "and the speed at which\nit can do string sorting. That's essentially\nthe two routines",
    "start": "2151790",
    "end": "2158099"
  },
  {
    "text": "that all these\nfunctions boil down to, is sparse matrix multiply\nand string storing.",
    "start": "2158100",
    "end": "2163220"
  },
  {
    "text": "And those are essentially\nhardware limited. Those are very\noptimized functions. So this just gives you a way.",
    "start": "2163220",
    "end": "2170860"
  },
  {
    "text": "I think it's always--\nthe first thing we do when we run a program\nis if we want to optimize it,",
    "start": "2170860",
    "end": "2180130"
  },
  {
    "text": "we'll write the program\nand run it, get a time, and then we'll try and figure\nout based on this type of data,",
    "start": "2180130",
    "end": "2187070"
  },
  {
    "text": "well, what's the theoretical\nbest we could do? Given what this calculation\nis dominated by,",
    "start": "2187070",
    "end": "2193740"
  },
  {
    "text": "what is the best we can do? Because if the best we could\ndo-- the theoretical peak",
    "start": "2193740",
    "end": "2202070"
  },
  {
    "text": "for what we were doing was\n1,000 times better than what we're doing, that tells\nus, you know what?",
    "start": "2202070",
    "end": "2209400"
  },
  {
    "text": "If we have to invest\ntime in optimization, it probably is time well spent. Going from being 1,000x below\nwhatever the best you can do",
    "start": "2209400",
    "end": "2218580"
  },
  {
    "text": "getting to 100x usually\ndoesn't take too much trouble. Usually, you can find\nwhat that issue is and you can correct it.",
    "start": "2218580",
    "end": "2226030"
  },
  {
    "text": "Likewise, going from 100x\nto 10x is still usually",
    "start": "2226030",
    "end": "2233240"
  },
  {
    "text": "a worthwhile thing to do. If you're at 10% of the\nbest that you can do,",
    "start": "2233240",
    "end": "2240540"
  },
  {
    "text": "then you begin to\nthink hard about, well, do I really want to chase? I'm never going to\nprobably do better than 50%",
    "start": "2240540",
    "end": "2247430"
  },
  {
    "text": "of what the best is, or\nmaybe even 30% or 40%. Usually, there's a\nlot of effort that",
    "start": "2247430",
    "end": "2253180"
  },
  {
    "text": "goes into going from\n10% of peak performance to 50% of performance.",
    "start": "2253180",
    "end": "2259470"
  },
  {
    "text": "But going from 0.1%\nof peak performance to 1% of peak\nperformance is usually",
    "start": "2259470",
    "end": "2264980"
  },
  {
    "text": "profile the code, aha, I'm doing\nsomething wrong here, fix it, done.",
    "start": "2264980",
    "end": "2270010"
  },
  {
    "text": "And so this is something\nthat's a part of our philosophy in doing optimization, and why\nwe spend so much time running",
    "start": "2270010",
    "end": "2276260"
  },
  {
    "text": "benchmarks and\nunderstanding where-- because it tells\nus when to stop. If someone says, well,\nwill this be faster,",
    "start": "2276260",
    "end": "2283390"
  },
  {
    "text": "and you can say no, it won't\nbe faster, you're done. Or, ah, no, we think\nin a few weeks' time,",
    "start": "2283390",
    "end": "2289730"
  },
  {
    "text": "we can really make\nit a lot better. So very useful thing, and\nthat's why benchmarking is a big part of what we do.",
    "start": "2289730",
    "end": "2296910"
  },
  {
    "text": "So finally, I want\nto wrap up here. This was one of the first\ncharts I showed you,",
    "start": "2296910",
    "end": "2302530"
  },
  {
    "start": "2300000",
    "end": "2300000"
  },
  {
    "text": "and hopefully now it\nmakes a lot more sense. This shows you the easy path\ntoward solving your problems",
    "start": "2302530",
    "end": "2310660"
  },
  {
    "text": "in signal processing\non databases. And if you look at your\nproblem as one of how much data",
    "start": "2310660",
    "end": "2317290"
  },
  {
    "text": "I want to process and how much--\nwhat the granularity of access",
    "start": "2317290",
    "end": "2322420"
  },
  {
    "text": "is, well, if I don't have\na lot of data and I'm accessing it at a very\nsmall granularity,",
    "start": "2322420",
    "end": "2329880"
  },
  {
    "text": "well, then I should just do it\nin the memory of my computer.",
    "start": "2329880",
    "end": "2335470"
  },
  {
    "text": "Don't mess around with files. Don't mess around\nwith databases. Keep your life simple.",
    "start": "2335470",
    "end": "2340570"
  },
  {
    "text": "Work it there. If the data request gets high,\nmemory is still the best.",
    "start": "2340570",
    "end": "2347495"
  },
  {
    "text": "Whether you're doing\nlittle bits or big bits, working out of main memory\non a single processor, generally, for the most part,\nis where you want to be.",
    "start": "2347496",
    "end": "2356109"
  },
  {
    "text": "If you're going to be getting\nto larger amounts of data but having a fairly\nlarge request size,",
    "start": "2356110",
    "end": "2364190"
  },
  {
    "text": "then using files,\nreading those files in and out-- so\nbasically, if I have",
    "start": "2364190",
    "end": "2369816"
  },
  {
    "text": "a lot of data I want to\nprocess, it won't fit into serial memory, we'll write\nit out into a bunch of files, just read them in, process\nthem, move onto the next file",
    "start": "2369816",
    "end": "2378140"
  },
  {
    "text": "is the right thing to do. Or spread it out in parallel. Run a bunch of nodes and use\nthe RAM in each one of those.",
    "start": "2378140",
    "end": "2385200"
  },
  {
    "text": "That's still the\nbest way to do it. ",
    "start": "2385200",
    "end": "2390310"
  },
  {
    "text": "You could also do\nthat in parallel. You can have parallel programs\nreading parallel files, too.",
    "start": "2390310",
    "end": "2395799"
  },
  {
    "text": "So if you have really\nenormous amounts of data and you're going to be reading\nthe data in large chunks,",
    "start": "2395800",
    "end": "2402500"
  },
  {
    "text": "then you want to use parallel\nfiles, parallel computing. That's going to give\nyou better performance.",
    "start": "2402500",
    "end": "2408520"
  },
  {
    "text": "And it's just going to be easy. Have a lot of files. Each program reads into sets\nof files, processes its set.",
    "start": "2408520",
    "end": "2415609"
  },
  {
    "text": "Very easy to do. And we have lots of support\nin our [INAUDIBLE] system for doing those\ntypes of problems. It's the thing that\nmost people do.",
    "start": "2415610",
    "end": "2422020"
  },
  {
    "text": "However, if you have\na large amount of data and you want to be accessing\nsmall fractions of it randomly,",
    "start": "2422020",
    "end": "2431920"
  },
  {
    "text": "that's when you want\nto use the database. That is the use case\nfor the database.",
    "start": "2431920",
    "end": "2437506"
  },
  {
    "text": "And there are\ndefinitely times when we have that case where\nwe want to do that. But you want to\nbuild towards it.",
    "start": "2437507",
    "end": "2445109"
  },
  {
    "text": "A lot of times when you're\ndoing analytics or algorithm development, you tend to\nbe in these cases first.",
    "start": "2445109",
    "end": "2451319"
  },
  {
    "text": "And so rather than bite off\nthe complexity associated",
    "start": "2451320",
    "end": "2456840"
  },
  {
    "text": "with dealing with a database,\nuse these tools first. But then eventually, there may\nbe a time where you actually",
    "start": "2456840",
    "end": "2462839"
  },
  {
    "text": "have to use the database. And hopefully, one thing\nyou get out of this course is understanding this\nnuance type of thing.",
    "start": "2462839",
    "end": "2469310"
  },
  {
    "text": "Because a lot of people say,\nwe need a parallel database. Why? We have a lot of data.",
    "start": "2469310",
    "end": "2474471"
  },
  {
    "text": "All right. That's great. Well, what do you want to do? We want to scan over\nthe whole thing. Well, that's just going to\nbe a lot of data really slow.",
    "start": "2474471",
    "end": "2483180"
  },
  {
    "text": "So people will do that. They'll load a bunch\nof data in the system. They're like, well,\nbut nothing is faster.",
    "start": "2483180",
    "end": "2488607"
  },
  {
    "text": "It's like, well,\nyeah, if you're going to scan over a significant\nfraction the database, it will be slower-- certainly\nslower than loading it",
    "start": "2488607",
    "end": "2495049"
  },
  {
    "text": "into the memories of\na bunch of computers, and even slower than just\nhaving a bunch of files and reading them into memory.",
    "start": "2495050",
    "end": "2501770"
  },
  {
    "text": "And increasingly nowadays,\nyou're talking about",
    "start": "2501770",
    "end": "2508170"
  },
  {
    "text": "this is millions of entries.  There's a lot of things that\nwere databases that we have,",
    "start": "2508170",
    "end": "2515320"
  },
  {
    "text": "like the lab's LDAP server. It's like 30,000 entries.",
    "start": "2515320",
    "end": "2520980"
  },
  {
    "text": "We have a database for it. You could send it around\nan Excel spreadsheet and pretty much do\neverything with that.",
    "start": "2520980",
    "end": "2527394"
  },
  {
    "text": "Or the entire release review\nquery, or the phone book, or whatever-- these are all\nnow, by today's standards,",
    "start": "2527395",
    "end": "2533230"
  },
  {
    "text": "microscopic data sets\nthat can trivially be stored in a single\nassociative array in something",
    "start": "2533230",
    "end": "2539050"
  },
  {
    "text": "like this and manipulated\nto your heart's content. So there's a lot of data sets\nthat are big to the human",
    "start": "2539050",
    "end": "2544220"
  },
  {
    "text": "but are microscopic to\nthe technology nowadays. So this is usually\nmillions of entries.",
    "start": "2544220",
    "end": "2552430"
  },
  {
    "text": "This might be hundreds\nof millions of entries. Definitely, when you\nreally need-- often, you're talking about\nbillions of entries",
    "start": "2552430",
    "end": "2559380"
  },
  {
    "text": "when you're getting here to\nthe point where you really need a database. The exception to\nthis being if you're",
    "start": "2559380",
    "end": "2564770"
  },
  {
    "text": "in a program that requires--\nmany of our customers will say the database\nis being used.",
    "start": "2564770",
    "end": "2570470"
  },
  {
    "text": "This is where the data is. It's in no other place. So for integration\npurposes, then you",
    "start": "2570470",
    "end": "2575820"
  },
  {
    "text": "throw all this out the window. If they say, look, this\nis where the data is and that's the only way you\ncan get it, then of course.",
    "start": "2575820",
    "end": "2583634"
  },
  {
    "text": "But that still doesn't mean\nyou might be like, yeah, well, you're going to store\nit in the database, but I'm going to store it\nin /temp, and work on it,",
    "start": "2583634",
    "end": "2590536"
  },
  {
    "text": "and then put my results\nback in the database, because I know that what I'm\ndoing is going to be better.",
    "start": "2590536",
    "end": "2595660"
  },
  {
    "text": "There's no-- as\nthey say, we don't want to be too proud to win. Just because some people,\nit's like, we have a database,",
    "start": "2595660",
    "end": "2602800"
  },
  {
    "text": "and everything must be\npurely done in the database. Or some people are like,\nwe have a file system, and everything must be purely\ndone in the file system.",
    "start": "2602800",
    "end": "2609420"
  },
  {
    "text": "Or we have this language\nand everything-- the right tool for\nthe job, pulling",
    "start": "2609420",
    "end": "2616620"
  },
  {
    "text": "them together, totally fine. It's a quick way to\nget this work done without driving yourself crazy.",
    "start": "2616620",
    "end": "2622580"
  },
  {
    "text": "So with that, I'll\ncome to the end. I have one code example which\nis relatively short to show you.",
    "start": "2622580",
    "end": "2628240"
  },
  {
    "text": "But again, parallel graphs\nare the dominant type of data we see. Graph500 relies on\nthis Kronecker graphs.",
    "start": "2628240",
    "end": "2635380"
  },
  {
    "text": "Kronecker graph theory is a\ngreat theoretical framework for looking at stuff. You get all the\nidentity benefits",
    "start": "2635380",
    "end": "2642060"
  },
  {
    "text": "that come with Kronecker\nproduct eigenvalues. If you're into that,\nI certainly suggest",
    "start": "2642060",
    "end": "2647210"
  },
  {
    "text": "you read the Van\nLoan paper, which is also the seminal work\non Kronecker products.",
    "start": "2647210",
    "end": "2652620"
  },
  {
    "text": "And I don't think anyone has\nwritten a followup to him, because everyone is like,\nyep, covered it there. It's about 12, 15 pages.",
    "start": "2652621",
    "end": "2658450"
  },
  {
    "text": "Covered all the properties\nof Kronecker products. We can do parallel computing\nin D4M via pMATLAB.",
    "start": "2658450",
    "end": "2665400"
  },
  {
    "text": "And again,\nfundamentally, if you've implemented your\nalgorithms correctly, they're limited by hardware,\nby fundamental aspects",
    "start": "2665400",
    "end": "2672324"
  },
  {
    "text": "of the hardware. There are limitations. It's important to\nknow what those are and to be aware of them.",
    "start": "2672324",
    "end": "2678150"
  },
  {
    "start": "2678150",
    "end": "2682484"
  }
]
[
  {
    "text": " The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6950"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or view\nadditional materials from",
    "start": "6950",
    "end": "13500"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "13500",
    "end": "18680"
  },
  {
    "text": " PROFESSOR: Good, we're going\nto take a detour today into",
    "start": "18680",
    "end": "24590"
  },
  {
    "text": "the realm of algorithms. ",
    "start": "24590",
    "end": "30860"
  },
  {
    "text": "So when you're trying to make\ncode go fast, of course, there's no holds barred.",
    "start": "30860",
    "end": "36470"
  },
  {
    "text": "You can use whatever you\nneed to in order to make it go fast. Today we're going to talk\na little bit in a more",
    "start": "36470",
    "end": "42900"
  },
  {
    "text": "principled way about the\nmemory hierarchy. And to do that we're going to\nintroduce what we call the",
    "start": "42900",
    "end": "50850"
  },
  {
    "text": "ideal-cache model. So as you know most caches are\nhacked together to try to",
    "start": "50850",
    "end": "61880"
  },
  {
    "text": "provide something that will\ncache well while still making it easy to build and\nfast to build.",
    "start": "61880",
    "end": "68530"
  },
  {
    "text": "The ideal-cache model\nis a pretty nice",
    "start": "68530",
    "end": "73850"
  },
  {
    "text": "beast if we had them. It's got a two-level\nhierarchy.",
    "start": "73850",
    "end": "79760"
  },
  {
    "text": "It's got a cache that has m\nbytes that are organized in to b byte cache-lines.",
    "start": "79760",
    "end": "86430"
  },
  {
    "text": "So each block is b bytes. And it's fully associative.",
    "start": "86430",
    "end": "91979"
  },
  {
    "text": "So you recall, that means\nthat any line can go anywhere in cache.",
    "start": "91980",
    "end": "97719"
  },
  {
    "text": "And probably the most impressive\naspect of an ideal-cache is that\nit has an optimal",
    "start": "97720",
    "end": "104950"
  },
  {
    "text": "omniscient replacement algorithm. So what it does, is it figures\nout when it needs to kick",
    "start": "104950",
    "end": "112920"
  },
  {
    "text": "something out of cache, it says,\nwhat is the absolutely best thing you could possibly\nkick out of cache.",
    "start": "112920",
    "end": "121080"
  },
  {
    "text": "And it does that one. Looking into the future\nif need be. It says, oh is this going\nto be accessed",
    "start": "121080",
    "end": "127230"
  },
  {
    "text": "a lot in the future? I think I'll keep this one. Let's throw out this one. I know it's never going\nto be used again.",
    "start": "127230",
    "end": "132920"
  },
  {
    "text": "So it has that omniscient\ncharacter to it.",
    "start": "132920",
    "end": "138090"
  },
  {
    "text": " The performance measures we're\ngoing to look at in this",
    "start": "138090",
    "end": "144120"
  },
  {
    "text": "model, the first one is\nwhat we call the work. And that's just the ordinary\nserial running time if you",
    "start": "144120",
    "end": "151489"
  },
  {
    "text": "just ran the code on one\nprocessor and counted up",
    "start": "151490",
    "end": "157420"
  },
  {
    "text": "essentially how many processor\ninstructions you would do.",
    "start": "157420",
    "end": "163980"
  },
  {
    "text": "That's essentially the work. The second measure, which is\nthe one that's much more",
    "start": "163980",
    "end": "170660"
  },
  {
    "text": "interesting, is cache misses. So the work has to do\nwith the processor.",
    "start": "170660",
    "end": "176079"
  },
  {
    "text": "The cache misses has to do with\nwhat moves between these two levels of memory.",
    "start": "176080",
    "end": "184470"
  },
  {
    "text": "So in this case, what we're\ninterested in doing is, how often do I try to access\nsomething.",
    "start": "184470",
    "end": "190620"
  },
  {
    "text": "It's not in the cache. I have to go to main memory and\nbring it back into cache.",
    "start": "190620",
    "end": "196480"
  },
  {
    "text": "And so that's what we'll be\ncounting in this model. ",
    "start": "196480",
    "end": "202459"
  },
  {
    "text": "So it's reasonable to ask how\nreasonable ideal caches are.",
    "start": "202460",
    "end": "210030"
  },
  {
    "text": "In particular the assumption\nof omniscient replacement,",
    "start": "210030",
    "end": "216830"
  },
  {
    "text": "that's pretty powerful stuff. Well it turns out there's a\ngreat lemma due to Slater and",
    "start": "216830",
    "end": "222069"
  },
  {
    "text": "Tarjan that says essentially\nthe following. Suppose that you have an\nalgorithm that incurs q cache",
    "start": "222070",
    "end": "230799"
  },
  {
    "text": "misses on an ideal\ncache of size n.",
    "start": "230800",
    "end": "236220"
  },
  {
    "text": "So you ran the algorithm on\nyour machine, you had a cache of size n. Then, if instead of having an\nideal cache, you have a fully",
    "start": "236220",
    "end": "245049"
  },
  {
    "text": "associative cache of size two\nm and use the least recently used replacement policy.",
    "start": "245050",
    "end": "252180"
  },
  {
    "text": "So you always, whenever you're\nkicking something out of cache, you kick out the thing\nthat has been touched the",
    "start": "252180",
    "end": "257190"
  },
  {
    "text": "longest ago in the past.  Then it incurs at most\n2Q cache misses.",
    "start": "257190",
    "end": "268289"
  },
  {
    "text": "So what that says is that LRU is\nto with it constant factors",
    "start": "268290",
    "end": "273940"
  },
  {
    "text": "essentially the same\nas optimal. Really quite a remarkable\nresult.",
    "start": "273940",
    "end": "279060"
  },
  {
    "text": " Who's taking 6046?",
    "start": "279060",
    "end": "284800"
  },
  {
    "text": "You've just seen this, right? Yeah, OK. Just seen this result in 6046.",
    "start": "284800",
    "end": "291810"
  },
  {
    "text": "See, I do talk to my colleagues\noccasionally. So then something about\nhow this is proved.",
    "start": "291810",
    "end": "299720"
  },
  {
    "text": "And what's important here is\nthat really it just says, OK, Yeah you could dither on the\nconstants, but basically",
    "start": "299720",
    "end": "307550"
  },
  {
    "text": "whether you choose LRU or choose\nideal cache with the omniscient replacement,\nasymptotically you're not",
    "start": "307550",
    "end": "315960"
  },
  {
    "text": "going to be off at all. So for most asymptotic analyses,\nyou can assume",
    "start": "315960",
    "end": "321900"
  },
  {
    "text": "optimal or LRU replacement\nas convenient. And the typical way that you\ndo convenience is if you're",
    "start": "321900",
    "end": "329740"
  },
  {
    "text": "looking at upper bounds. So you're trying to show that\na particular algorithm is",
    "start": "329740",
    "end": "335290"
  },
  {
    "text": "good, then what you do is you\nassume optimal replacement.",
    "start": "335290",
    "end": "340970"
  },
  {
    "text": "If you're trying to show that\nsome algorithm is bad, then what you do is assume that it's\nLRU to get a lower bound.",
    "start": "340970",
    "end": "349510"
  },
  {
    "text": "Because then you can reason\nmore easily about what's actually in memory. Because you just say, oh we'll\njust keep the least",
    "start": "349510",
    "end": "355210"
  },
  {
    "text": "recently used one. So you tend to use the two for\nupper bounds and lower bounds.",
    "start": "355210",
    "end": "363229"
  },
  {
    "text": "Now, the way this relates\nto software engineering is as follows.",
    "start": "363230",
    "end": "370280"
  },
  {
    "text": "If you're developing a really\nfast algorithm, it's going to start from a theoretically\nsound algorithm.",
    "start": "370280",
    "end": "378800"
  },
  {
    "text": "And from that then you have\nto engineer for detailed performance.",
    "start": "378800",
    "end": "384460"
  },
  {
    "text": "So you have to take into account\nthings like real caches are not fully\nassociative.",
    "start": "384460",
    "end": "391630"
  },
  {
    "text": "That loads and stores, for\nexample, have different cost with respect to bandwidth\nand latency.",
    "start": "391630",
    "end": "396669"
  },
  {
    "text": "So whether you miss some a\nload or miss on a store, there's a different impact.",
    "start": "396670",
    "end": "402199"
  },
  {
    "text": "But these are all the tuning. And as you know, those constant\nfactors can sometimes",
    "start": "402200",
    "end": "407569"
  },
  {
    "text": "add up to dramatic numbers,\norders of magnitude.",
    "start": "407570",
    "end": "414550"
  },
  {
    "text": "And so it's important to do\nthat software engineering. But starting from a good\ntheoretical basis means that",
    "start": "414550",
    "end": "419800"
  },
  {
    "text": "you actually have an algorithm\nthat is going to work well across a large variety\nof real situations.",
    "start": "419800",
    "end": "428380"
  },
  {
    "text": " Now, there's one other\nassumption we tend to make",
    "start": "428380",
    "end": "434500"
  },
  {
    "text": "when we're dealing with ideal\ncaches, and that's called the tall-cache assumption.",
    "start": "434500",
    "end": "442080"
  },
  {
    "text": "So what the tall-cache\nassumption says, is that I you",
    "start": "442080",
    "end": "447099"
  },
  {
    "text": "have at least as many lines of\ncache, essentially, in your",
    "start": "447100",
    "end": "453230"
  },
  {
    "text": "cache, as you have bytes\nin the line. ",
    "start": "453230",
    "end": "459130"
  },
  {
    "text": "So it says the cache is tall. In other words, this dimension\nhere is bigger than this",
    "start": "459130",
    "end": "465310"
  },
  {
    "text": "dimension here. And in particular, you want that\nto be true for where we",
    "start": "465310",
    "end": "471070"
  },
  {
    "text": "have some constant here of slop\nthat we can throw in. Yes, question.",
    "start": "471070",
    "end": "476168"
  },
  {
    "text": "AUDIENCE: Does that\n[INAUDIBLE] associatively make the\ncache shorter here.",
    "start": "476168",
    "end": "482090"
  },
  {
    "text": "PROFESSOR: Yes, so this\nis basically assuming everything is ideal.",
    "start": "482090",
    "end": "487310"
  },
  {
    "text": "We're going to go back. When you engineer things, you\nhave to deal with the fact that things aren't ideal.",
    "start": "487310",
    "end": "492330"
  },
  {
    "text": "But usually that's just a little\nbit of a tweak on the actual ideal algorithm.",
    "start": "492330",
    "end": "497570"
  },
  {
    "text": "And for many programs, the\nideal algorithm you don't actually have to tweak\nat all to get a",
    "start": "497570",
    "end": "505170"
  },
  {
    "text": "good practical algorithm. So here is just saying the\ncache should be tall.",
    "start": "505170",
    "end": "510555"
  },
  {
    "text": " Now, just as an example, if we\nlook at the machines that",
    "start": "510555",
    "end": "518710"
  },
  {
    "text": "we're using, the cache-line\nlength is 64 bytes. The L1 cache size\nis 32 kilobytes.",
    "start": "518710",
    "end": "526420"
  },
  {
    "text": "And of course, for L1 it's is\n32 kilobytes and for L2 and",
    "start": "526420",
    "end": "532260"
  },
  {
    "text": "L3, it's even bigger. It's even taller. Because they also\nhave 64k line.",
    "start": "532260",
    "end": "540200"
  },
  {
    "text": "So this is a fairly reasonable\nassumption to make, that you have more lines in your cache\nthen essentially the length,",
    "start": "540200",
    "end": "550040"
  },
  {
    "text": "the number of items you can\nput on a cache line. Now why is this an important\nassumption?",
    "start": "550040",
    "end": "558310"
  },
  {
    "text": "So what's wrong with\nshort caches? So we're going to look at,\nsurprise, surprise, matrix",
    "start": "558310",
    "end": "565330"
  },
  {
    "text": "multiplication.  Which, by the end of this class\nyou will learn more",
    "start": "565330",
    "end": "573070"
  },
  {
    "text": "algorithms than matrix\nmultiplication. But it is a good one to\nillustrate things. So the idea here is, suppose\nthat you have an",
    "start": "573070",
    "end": "580190"
  },
  {
    "text": "n by n matrix here. And you don't have this\ntall-cache assumption.",
    "start": "580190",
    "end": "589220"
  },
  {
    "text": "So where your cache is short. You have a lot of bytes in a\nline, but very few lines.",
    "start": "589220",
    "end": "595560"
  },
  {
    "text": "Then even if the size of\nyour matrix fits, in",
    "start": "595560",
    "end": "602090"
  },
  {
    "text": "principle, in the cache. In other words, n squared is\nless than m by more than a",
    "start": "602090",
    "end": "608010"
  },
  {
    "text": "constant amount. So you'd say, Oh gee, that\nought to fit in. If you have a short cache it\ndoesn't necessarily fit in",
    "start": "608010",
    "end": "615750"
  },
  {
    "text": "because your length n here is\ngoing to be shorter than the",
    "start": "615750",
    "end": "620870"
  },
  {
    "text": "number of bytes on a line. However, if you have a tall\ncache, it's always the case",
    "start": "620870",
    "end": "626199"
  },
  {
    "text": "that if the matrix size is\nsmaller than the cache size by",
    "start": "626200",
    "end": "637190"
  },
  {
    "text": "a certain amount, then the\nmatrix will fit in the cache. OK, question?",
    "start": "637190",
    "end": "642665"
  },
  {
    "text": "AUDIENCE: Why wouldn't\nyou fit more than one row per cache line? PROFESSOR: Well the issue is you\nmay not have control over",
    "start": "642665",
    "end": "649750"
  },
  {
    "text": "the way this is laid out. So, for example, if this is\nrow-major order, and this is a",
    "start": "649750",
    "end": "655490"
  },
  {
    "text": "submatrix of a much bigger\nmatrix, then you may not have the freedom to be using these.",
    "start": "655490",
    "end": "663020"
  },
  {
    "text": "But if you have the tall-cache\nassumption, then any section you pull out is going to fit.",
    "start": "663020",
    "end": "668130"
  },
  {
    "text": "As long as the data fits\nmathematically in the cache,",
    "start": "668130",
    "end": "673470"
  },
  {
    "text": "it will fit practically in\nthe cache if you have the tall-cache assumption. Whereas if it's short, you\nbasically end up with the",
    "start": "673470",
    "end": "683440"
  },
  {
    "text": "cache lines being long and you\nnot having any flexibility as to where the data goes.",
    "start": "683440",
    "end": "688529"
  },
  {
    "text": "So this is sort of a-- So any questions about\nthat before we get into the use of this?",
    "start": "688530",
    "end": "696310"
  },
  {
    "text": "We're going to see the use of\nthis and where it comes up. So one of the things is that,\nif it does fit in, then it",
    "start": "696310",
    "end": "702430"
  },
  {
    "text": "takes, at most, size of the\nmatrix divided by the cache",
    "start": "702430",
    "end": "709470"
  },
  {
    "text": "line size misses\nto load it in. So this is linear time\nin the cache world.",
    "start": "709470",
    "end": "717090"
  },
  {
    "text": "Linear time says, you should\nonly take one cache fault for every line of cache.",
    "start": "717090",
    "end": "723240"
  },
  {
    "text": "And so that's what you'll have\nhere if you have a tall cache. You'll have n squared over b\ncache misses to load in n",
    "start": "723240",
    "end": "729870"
  },
  {
    "text": "square data. And that's good. ",
    "start": "729870",
    "end": "736096"
  },
  {
    "text": "OK, good. So let's take on the problem\nof multiplying matrices.",
    "start": "736096",
    "end": "741220"
  },
  {
    "text": "We're going to look at square\nmatrices because they're easier to think about than\nrectangular ones. But almost everything I say\ntoday will relate to",
    "start": "741220",
    "end": "748970"
  },
  {
    "text": "rectangular matrices as well.  And it we'll generalize\nbeyond matrices as",
    "start": "748970",
    "end": "755660"
  },
  {
    "text": "we'll see next time. So here's a typical code for\nmultiplying matrices.",
    "start": "755660",
    "end": "760900"
  },
  {
    "text": "It's not the most efficient code\nin the world, but it's good enough to illustrate\nwhat I want to show you.",
    "start": "760900",
    "end": "768180"
  },
  {
    "text": "So the first thing is, what is\nthe work of this algorithm?",
    "start": "768180",
    "end": "774270"
  },
  {
    "text": " This is, by the way, the\nsoftball question.",
    "start": "774270",
    "end": "781240"
  },
  {
    "text": "What's the work? So the work, remember, is just\nif you're analyzing it just like processor forget about\ncaches and so forth.",
    "start": "781240",
    "end": "790284"
  },
  {
    "text": "AUDIENCE: n cubed. PROFESSOR: n cubed, right. Because there's a triply nested\nloop going up to n and",
    "start": "790284",
    "end": "797910"
  },
  {
    "text": "you're doing constant\nwork in the middle. So it's n times n times 1. ",
    "start": "797910",
    "end": "803079"
  },
  {
    "text": "n cubed work. That was easy. Now let's analyze caches.",
    "start": "803080",
    "end": "809460"
  },
  {
    "text": "So we're going to look\nat row major. I'm only going to illustrate the\ncache lines on this side because B is where all\nthe action is.",
    "start": "809460",
    "end": "817310"
  },
  {
    "text": "So we're going to analyze two\ncases when the matrix doesn't fit in the cache. If the matrix fits in the cache,\nthen there's nothing to",
    "start": "817310",
    "end": "825140"
  },
  {
    "text": "analyze, at some level. So we're going to look at the\ncases where the matrix doesn't",
    "start": "825140",
    "end": "830279"
  },
  {
    "text": "fit in the cache. And the first one is going to be\nwhen the side of the matrix is bigger than m over b.",
    "start": "830280",
    "end": "836585"
  },
  {
    "text": "So remember, m over b is the\nheight of our cache, the number of lines in our cache. ",
    "start": "836585",
    "end": "848320"
  },
  {
    "text": "So let's assume for this, now\nI have a choice of assuming",
    "start": "848320",
    "end": "853480"
  },
  {
    "text": "optimal omniscient replacement\nor assuming LRU. Since I want to show this is\nbad, I'm going to assume LRU.",
    "start": "853480",
    "end": "861800"
  },
  {
    "text": "Could somebody please close\nthe back door there? Because it's we're getting some\nnoise in from out there.",
    "start": "861800",
    "end": "869300"
  },
  {
    "text": "Thank you. So let's assume LRU. So what happens in the code is\nbasically I go across a row of",
    "start": "869300",
    "end": "877280"
  },
  {
    "text": "A, while I go down a column of\nB. And now if I'm using LRU,",
    "start": "877280",
    "end": "883650"
  },
  {
    "text": "what's happening? I read in this cache\nblock and this one, then this one et cetera.",
    "start": "883650",
    "end": "889079"
  },
  {
    "text": "And if n is bigger than M/B and\nI'm using least recently used, by the time I get down\nto the bottom here, what's",
    "start": "889080",
    "end": "896470"
  },
  {
    "text": "happened the first cache line? First cache block?",
    "start": "896470",
    "end": "902300"
  },
  {
    "text": "It's out of there. It's out of there\nif I used LRU. ",
    "start": "902300",
    "end": "909490"
  },
  {
    "text": "So therefore, what happens\nis I took a miss on every one of those. And then when I go to the second\none, I take a miss on",
    "start": "909490",
    "end": "916790"
  },
  {
    "text": "every one again.  And so as I keep going through,\nevery access to B",
    "start": "916790",
    "end": "926500"
  },
  {
    "text": "causes a miss throughout the\nwhole accessing of B. Now go on to the second row A and I\nhad the same thing repeats.",
    "start": "926500",
    "end": "933530"
  },
  {
    "text": " So therefore, the number of\ncache misses is order n cubed",
    "start": "933530",
    "end": "944730"
  },
  {
    "text": "since we miss on matrix\nB on every access.",
    "start": "944730",
    "end": "950690"
  },
  {
    "text": "OK, question. AUDIENCE: I know that\nyou said it's e. Does B push out due to conflict",
    "start": "950690",
    "end": "956350"
  },
  {
    "text": "misses or capacity misses? PROFESSOR: So in this case\nthey're capacity misses that",
    "start": "956350",
    "end": "963930"
  },
  {
    "text": "we're talking about here. So there's no conflict misses in\na fully associative cache. ",
    "start": "963930",
    "end": "970490"
  },
  {
    "text": "Conflict misses occurs because\nof direct mapping. So there's no conflict misses\nin what I'm going to be",
    "start": "970490",
    "end": "975890"
  },
  {
    "text": "talking about today. That is an extra concern that\nyou have for real caches, not a concern when you have a\nfully associative cache.",
    "start": "975890",
    "end": "983060"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] n needs to be bigger than B?",
    "start": "983060",
    "end": "988735"
  },
  {
    "text": "PROFESSOR: So the number of\nlines to fit in my cache is m",
    "start": "988736",
    "end": "994310"
  },
  {
    "text": "over b, right? AUDIENCE: So can't you put\nmultiple units of data--",
    "start": "994310",
    "end": "999490"
  },
  {
    "text": "PROFESSOR: Well there are\nmultiple units of data. But notice this is row major,\nwhat's stored here",
    "start": "999490",
    "end": "1004830"
  },
  {
    "text": "is B11, B12, B13. That's stored here.",
    "start": "1004830",
    "end": "1010110"
  },
  {
    "text": "The way I'm going through the\naccess, I'm going down the columns of B. So by the time\nto get up to the top again,",
    "start": "1010110",
    "end": "1018569"
  },
  {
    "text": "that cache block is\nno longer there. And so when I access B12,\nassuming indexing from one or",
    "start": "1018570",
    "end": "1026800"
  },
  {
    "text": "whatever, this block is\nno longer in cache.",
    "start": "1026800",
    "end": "1032220"
  },
  {
    "text": "Because LRU would say, somewhere\nalong here I hit the limit of my size of cache,\nlet's say around here.",
    "start": "1032220",
    "end": "1039109"
  },
  {
    "text": "Then when this one goes\nin, that one goes out. When the next one goes in, the\nnext one goes out et cetera",
    "start": "1039109",
    "end": "1044349"
  },
  {
    "text": "using the least recently\nused replacement. So my-- AUDIENCE: Spatial locality.",
    "start": "1044349",
    "end": "1049520"
  },
  {
    "text": "PROFESSOR: I'm sorry? You don't have any spatial\nlocality here. AUDIENCE: I'm just wondering\nwhy they can't hold units.",
    "start": "1049520",
    "end": "1057710"
  },
  {
    "text": "I guess this is the question,\nwhy can't they hold multiple addresses per cache line. So why is it even pushed out?",
    "start": "1057710",
    "end": "1065549"
  },
  {
    "text": "It's being pushed out\n[UNINTELLIGIBLE] one per cache line, right? PROFESSOR: No, so it's getting\npushed out because the cache",
    "start": "1065550",
    "end": "1071370"
  },
  {
    "text": "can hold M/B blocks, right?",
    "start": "1071370",
    "end": "1076820"
  },
  {
    "text": "So once it's accessed m over b\nblocks, if I want to access anything else, something\nhas to go out.",
    "start": "1076820",
    "end": "1083820"
  },
  {
    "text": "It's a capacity issue. I access m over b blocks,\nsomething has to go out. LRU says, the latest thing that\nI accessed, well that was",
    "start": "1083820",
    "end": "1093790"
  },
  {
    "text": "the first one, gets\nknocked out. So what happens is every\none causes a miss.",
    "start": "1093790",
    "end": "1100030"
  },
  {
    "text": "Even though I may access that\nvery nearby in the future, it doesn't take advantage\nof that.",
    "start": "1100030",
    "end": "1107040"
  },
  {
    "text": "Because LRU says knock it out. AUDIENCE: [INAUDIBLE] PROFESSOR: Is it row major\nthat's the confusion?",
    "start": "1107040",
    "end": "1114880"
  },
  {
    "text": "This is the way we've been\ndealing with are matrices. So in row major, there's\na good--",
    "start": "1114880",
    "end": "1121490"
  },
  {
    "text": "that's nice, there's\nno chalk here. ",
    "start": "1121490",
    "end": "1127320"
  },
  {
    "text": "Oh, there's a big one\nthere, great. ",
    "start": "1127320",
    "end": "1133520"
  },
  {
    "text": "Yeah, so here's B. So the order\nthat B is stored is like",
    "start": "1133520",
    "end": "1140600"
  },
  {
    "text": "this in memory. So basically we're storing these\nelements in this order.",
    "start": "1140600",
    "end": "1148790"
  },
  {
    "text": "So it's a linear block\nof memory, right? And it's being stored row\nby row as we go through.",
    "start": "1148790",
    "end": "1156250"
  },
  {
    "text": "So actually if I do it like\nthis, let me do this a little bit more.",
    "start": "1156250",
    "end": "1162950"
  },
  {
    "text": "So the idea is that the first\nelement is going to be here,",
    "start": "1162950",
    "end": "1168320"
  },
  {
    "text": "and then we get up to n minus 1,\nand then we get to n minus 2 is stored here. ",
    "start": "1168320",
    "end": "1175956"
  },
  {
    "text": "n plus 1, n plus\n2, 2n minus 1.",
    "start": "1175956",
    "end": "1182150"
  },
  {
    "text": "So that's the order that\nthey're stored in linear and memory. Now these guys will all be on\nthe same cache line if it's in",
    "start": "1182150",
    "end": "1189750"
  },
  {
    "text": "row-major storage. So when I'm accessing B, I'm\ngoing and I'm accessing zero,",
    "start": "1189750",
    "end": "1195680"
  },
  {
    "text": "then I'm accessing the\nthing at location n. And I'm going down like this.",
    "start": "1195680",
    "end": "1201820"
  },
  {
    "text": "At some point here I reach\nthe limit of my cache.",
    "start": "1201820",
    "end": "1207179"
  },
  {
    "text": "This is M/B. Notice it's\na different B-- script B verses--",
    "start": "1207180",
    "end": "1213840"
  },
  {
    "text": "so when I get to m over b. Now all these things\nare sitting in cache, that's great.",
    "start": "1213840",
    "end": "1220590"
  },
  {
    "text": "However, now I go to one more,\nand it says OK, all those",
    "start": "1220590",
    "end": "1225770"
  },
  {
    "text": "things are sitting in cache,\nwhich one do I kick out? And the answer is the least\nrecently used one.",
    "start": "1225770",
    "end": "1231970"
  },
  {
    "text": "That's this guy goes out. AUDIENCE: Do you only use one\nelement per cache link? PROFESSOR: And I've only used\none element from each cache",
    "start": "1231970",
    "end": "1238260"
  },
  {
    "text": "line at this point. Then I go to the next one and it\nknocks out the second one.",
    "start": "1238260",
    "end": "1243330"
  },
  {
    "text": "By the time I get to the bottom\nand then I go up to the top to access 1 here,\nit's not in cache.",
    "start": "1243330",
    "end": "1249930"
  },
  {
    "text": "And so it repeats the same\nprocess, missing every single time. We have a question. AUDIENCE: Yeah,so my question\nis why does the cache know",
    "start": "1249930",
    "end": "1260320"
  },
  {
    "text": "where each row is? To us, we draw the matrix,\nbut the computer",
    "start": "1260320",
    "end": "1265798"
  },
  {
    "text": "doesn't know it's a matrix. To the computer, its a linear\narray of numbers. PROFESSOR: That's correct. AUDIENCE: So why would it load\nthe first couple elements in",
    "start": "1265798",
    "end": "1276016"
  },
  {
    "text": "the first row, and the second\ncolumn is an extended row the second time. ",
    "start": "1276016",
    "end": "1281455"
  },
  {
    "text": "PROFESSOR: So the cache blocks\nare determined by the locality and memory.",
    "start": "1281455",
    "end": "1287415"
  },
  {
    "text": "AUDIENCE: So my assumption\nwould be the first cache line for say-- PROFESSOR: Let's say\n0 through 3.",
    "start": "1287415",
    "end": "1294330"
  },
  {
    "text": "AUDIENCE: So yeah,\n0 through 3. PROFESSOR: Let's say we have\nfour items on that cache line. AUDIENCE: 4 to 6. PROFESSOR: The next one the\nhold 4 to 7, I think.",
    "start": "1294330",
    "end": "1302664"
  },
  {
    "text": "AUDIENCE: 4 to 7, yeah. So that is a-- PROFESSOR: So that would\nbe the next one, right?",
    "start": "1302664",
    "end": "1308010"
  },
  {
    "text": "4 to 7. AUDIENCE: When you\nget cache line. You are not using the\nfully cache line. There is no spatial locale.",
    "start": "1308010",
    "end": "1313620"
  },
  {
    "text": "You are using one from\nthe cache line. PROFESSOR: So this code\nis using this one",
    "start": "1313620",
    "end": "1320020"
  },
  {
    "text": "and then this one. It's not using the rest. So it's not very\nefficient code. AUDIENCE: So the cache line\nis holding the 0 to 3",
    "start": "1320020",
    "end": "1327945"
  },
  {
    "text": "and the 4 to 7. [INAUDIBLE] n plus 2 just reading--",
    "start": "1327946",
    "end": "1333320"
  },
  {
    "text": "[INTERPOSING VOICES] PROFESSOR: Right. And those are fixed. So if you just a dice up memory\nin our machine into 64",
    "start": "1333320",
    "end": "1341315"
  },
  {
    "text": "byte sizes, those are the things\nthat come in together whenever you access anything\non that line.",
    "start": "1341315",
    "end": "1348220"
  },
  {
    "text": "AUDIENCE: And on this particular\naxis, you never actually get the 4\nto the 7 in the--",
    "start": "1348220",
    "end": "1354136"
  },
  {
    "text": "PROFESSOR: Well we\neventually do. Until we get there,\nyes, that's right. Until we get there.",
    "start": "1354136",
    "end": "1360130"
  },
  {
    "text": "Now, of course, we're also\naccessing A and C, but turns out to this analysis it\nsufficient to show that we're",
    "start": "1360130",
    "end": "1367010"
  },
  {
    "text": "getting n cubed misses just on\nthe matrix B. In order to say",
    "start": "1367010",
    "end": "1374780"
  },
  {
    "text": "hey, we've got a lot\nof misses here. ",
    "start": "1374780",
    "end": "1380170"
  },
  {
    "text": "So this was the case where\nn was bigger than the size of a cache.",
    "start": "1380170",
    "end": "1385290"
  },
  {
    "text": "So the situation is a little\nbit different if n is large",
    "start": "1385290",
    "end": "1390630"
  },
  {
    "text": "but still actually less\nthan m over b.",
    "start": "1390630",
    "end": "1397560"
  },
  {
    "text": "So in this case, we suppose it\nn squared is bigger than m.",
    "start": "1397560",
    "end": "1404410"
  },
  {
    "text": "So the matrix doesn't\nfit in memory. So that's what this part of the\nequation is, m to the 1/2",
    "start": "1404410",
    "end": "1409804"
  },
  {
    "text": "less than n is the same as n\nsquared is bigger than memory. So we still don't fit in memory,\nbut in fact it's less",
    "start": "1409804",
    "end": "1418289"
  },
  {
    "text": "than some constant\ntimes m over b. And now let's look at the\ndifference with what happens",
    "start": "1418290",
    "end": "1424600"
  },
  {
    "text": "with the caches as we go\nthrough the algorithm. So we essentially do\nthe same thing.",
    "start": "1424600",
    "end": "1429960"
  },
  {
    "text": "Once again, we're going\nto assume LRU. And so what happens is we're\ngoing to go down a single row there.",
    "start": "1429960",
    "end": "1436320"
  },
  {
    "text": "But now, notice that by the time\nI get down to the bottom,",
    "start": "1436320",
    "end": "1448870"
  },
  {
    "text": "basically I've accessed fewer\nthan some constant times m over b locations.",
    "start": "1448870",
    "end": "1454409"
  },
  {
    "text": "And so nothing has gotten\nkicked out yet. So when I go back to the top for\nthe next access to B, all",
    "start": "1454410",
    "end": "1464880"
  },
  {
    "text": "these things are still\nin memory.  So I don't take a cache fall,\na cache miss in those cases.",
    "start": "1464880",
    "end": "1475030"
  },
  {
    "text": "And so we keep going through. And basically this is much\nbetter because we're actually",
    "start": "1475030",
    "end": "1481039"
  },
  {
    "text": "getting to take advantage\nof the spatial locality. So this algorithm\ntakes advantage of the spatial locality.",
    "start": "1481040",
    "end": "1488580"
  },
  {
    "text": "If n is really big it doesn't,\nbut if n is just kind of big,",
    "start": "1488580",
    "end": "1497039"
  },
  {
    "text": "then it does. And then if n is small enough,\nof course, it all fits in",
    "start": "1497040",
    "end": "1503510"
  },
  {
    "text": "cache and there's no misses\nother than those needed to bring it in once. ",
    "start": "1503510",
    "end": "1509820"
  },
  {
    "text": "And then the same thing happens\nonce you go through the next one. So in this case, what's\nhappening is we have n squared",
    "start": "1509820",
    "end": "1518610"
  },
  {
    "text": "over b misses per run through\nthe matrix B, and then we have",
    "start": "1518610",
    "end": "1527130"
  },
  {
    "text": "n times that we go through. Once for every row of A. So the\ntotal then is n cubed over",
    "start": "1527130",
    "end": "1532506"
  },
  {
    "text": "b the cache block size.",
    "start": "1532506",
    "end": "1537700"
  },
  {
    "text": "So depending upon the size, we\ncan analyze with this, that",
    "start": "1537700",
    "end": "1543049"
  },
  {
    "text": "this is better because we get\na factor of B improvement. But it's still not particularly\ngood.",
    "start": "1543050",
    "end": "1549549"
  },
  {
    "text": "And it only works, of course,\nif my side of my matrix fits",
    "start": "1549550",
    "end": "1558280"
  },
  {
    "text": "in the number of lines\nof cache that I have. Yeah, question.",
    "start": "1558280",
    "end": "1563345"
  },
  {
    "text": "AUDIENCE: Can you explain in-- I don't understand why you\nhave n cubed over b? PROFESSOR: OK, so we're going\nthrough this matrix n times.",
    "start": "1563345",
    "end": "1572590"
  },
  {
    "text": "And for each one of those,\nwe're running through this thing. So this thing basically, I get\nto go b times through, because",
    "start": "1572590",
    "end": "1582169"
  },
  {
    "text": "all these things are going to be\nin memory when I come back to do them again. And so it's only once every B\ncolumns that I take a miss.",
    "start": "1582170",
    "end": "1592740"
  },
  {
    "text": "I take a miss and then I get to\nthe other b minus 1 access is that I get cache hit.",
    "start": "1592740",
    "end": "1600120"
  },
  {
    "text": "And so the total here is\nthen n squared over b. So therefore a total\nof n cubed over b.",
    "start": "1600120",
    "end": "1606040"
  },
  {
    "text": " So even this is not very good\ncompared to what we can",
    "start": "1606040",
    "end": "1612630"
  },
  {
    "text": "actually do if we exploit\nthe cache well. ",
    "start": "1612630",
    "end": "1617780"
  },
  {
    "text": "So let's go on and\ntake a look. We saw this before. Let's use tiling.",
    "start": "1617780",
    "end": "1623710"
  },
  {
    "text": "So the idea of tiling is to say,\nlet's break our matrix",
    "start": "1623710",
    "end": "1629950"
  },
  {
    "text": "into blocks of s times s size. And essentially what we do is we\ntreat our big matrix as if",
    "start": "1629950",
    "end": "1643540"
  },
  {
    "text": "we're doing block matrix\nmultiplications of things of size s by s. So the inner loop here is doing\nessentially the matrix",
    "start": "1643540",
    "end": "1652360"
  },
  {
    "text": "multiplication. It's actually matrix\nmultiply and add.",
    "start": "1652360",
    "end": "1659020"
  },
  {
    "text": "The inner three loops are just\ndoing ordinary matrix multiplication, but on\ns-sized matrices.",
    "start": "1659020",
    "end": "1665210"
  },
  {
    "text": "And the outer loop is jumping\nover matrix by matrix for each",
    "start": "1665210",
    "end": "1674490"
  },
  {
    "text": "of those doing a matrix\nmultiply as its elemental piece. So this is the tiling solution\nthat you've seen before.",
    "start": "1674490",
    "end": "1681429"
  },
  {
    "text": "We can analyze it in\nthis model to see, is this a good solution.",
    "start": "1681430",
    "end": "1687250"
  },
  {
    "text": "So everybody clear on\nwhat the code does? So it's a lot of four\nloops, right?",
    "start": "1687250",
    "end": "1694737"
  },
  {
    "text": "Yeah. AUDIENCE: There should be\nless than n somewhere? There's like an and something.",
    "start": "1694737",
    "end": "1700610"
  },
  {
    "text": "PROFESSOR: Oh yeah. That must have happened\nwhen I coped it. That should be j less\nthan n here.",
    "start": "1700610",
    "end": "1707490"
  },
  {
    "text": "It should just follow\nthis pattern. i less than n, k less than\nn, that should be j less than n there.",
    "start": "1707490",
    "end": "1713020"
  },
  {
    "text": " Good catch. I did execute this.",
    "start": "1713020",
    "end": "1719270"
  },
  {
    "text": "That must have happened\nwhen I was editing.  So here's the analysis\nof work.",
    "start": "1719270",
    "end": "1725870"
  },
  {
    "text": "So what's going on\nin the work? So here we have, basically the\nouter loop is going n over s",
    "start": "1725870",
    "end": "1735120"
  },
  {
    "text": "times, each loop. So there's cube there times the\ninner loops here which are",
    "start": "1735120",
    "end": "1741110"
  },
  {
    "text": "going each s times. So times s cubed. Multiply that through,\nn cubed operations.",
    "start": "1741110",
    "end": "1747250"
  },
  {
    "text": "That's kind of what\nyou'd expect.  What about cache misses? ",
    "start": "1747250",
    "end": "1755320"
  },
  {
    "text": "So the whole idea here is that\ns becomes a tuning parameter. And whether we choose s well or\npoorly influences how well",
    "start": "1755320",
    "end": "1764060"
  },
  {
    "text": "this algorithm works. So the idea here is we want tune\ns so that the submatrices",
    "start": "1764060",
    "end": "1771620"
  },
  {
    "text": "just fit into cache. So in this case, if I want a\nmatrix to fit into cache, I",
    "start": "1771620",
    "end": "1777230"
  },
  {
    "text": "want to be about the size\nof the square root of the cache size.",
    "start": "1777230",
    "end": "1783350"
  },
  {
    "text": "And this is where we're going\nto use the tall-cache assumption now. Because I want to say, it fits\nin cache, therefore I can just",
    "start": "1783350",
    "end": "1792620"
  },
  {
    "text": "assume it all fits in cache. It's not like the size fits but\nthe actual data doesn't,",
    "start": "1792620",
    "end": "1798220"
  },
  {
    "text": "which is what happens with\nthe short cache. So the tall-cache assumption\nimplies that when I'm",
    "start": "1798220",
    "end": "1805320"
  },
  {
    "text": "executing one of these inner\nloops, what's happening? When I'm executing one of these\nlinear loops, all of the",
    "start": "1805320",
    "end": "1812110"
  },
  {
    "text": "matrices are going\nto fit in cache. So all I have is my\ncold misses, if",
    "start": "1812110",
    "end": "1818610"
  },
  {
    "text": "any, on that submatrix. And how many cold misses\ncan I have?",
    "start": "1818610",
    "end": "1824820"
  },
  {
    "text": "Well the size of the matrix is\ns squared and I get to bring in b bytes of the matrix\neach time.",
    "start": "1824820",
    "end": "1833500"
  },
  {
    "text": "So I get s squared over b\nmisses per submatrix. So that was a little bit fast,\nbut I just want to make sure--",
    "start": "1833500",
    "end": "1840149"
  },
  {
    "text": " it's at one level\nstraightforward, and the other",
    "start": "1840150",
    "end": "1845790"
  },
  {
    "text": "level it's a little bit fast. So the point is that the inner\nthree loops I can analyze if I",
    "start": "1845790",
    "end": "1851680"
  },
  {
    "text": "know that s is fitting\nin cache. The inner three loops I can\nanalyze by saying, look it's s",
    "start": "1851680",
    "end": "1857340"
  },
  {
    "text": "squared data. Once I get the data in cache,\nif I'm using an optimal replacement, then it's going\nto stay in there.",
    "start": "1857340",
    "end": "1866480"
  },
  {
    "text": "And so it will cost me s squared\nover b misses to bring that matrix in for each\nof the three matrices.",
    "start": "1866480",
    "end": "1874409"
  },
  {
    "text": "But once it's in there, I can\nkeep going over and over it as the algorithm does.",
    "start": "1874410",
    "end": "1879480"
  },
  {
    "text": "I don't get any cache misses. Because those all fitting\nin the cache.",
    "start": "1879480",
    "end": "1885720"
  },
  {
    "text": "Question? Everybody with me? OK.",
    "start": "1885720",
    "end": "1891890"
  },
  {
    "text": "So then I basically have\nthe outer three loops. And here I don't make any\nassumptions whatsoever.",
    "start": "1891890",
    "end": "1898360"
  },
  {
    "text": "There's n over s iterations\nfor each loop. And there's three loops.",
    "start": "1898360",
    "end": "1903940"
  },
  {
    "text": "So that's n over s cubed. And then the cost of the misses\nin the inner loop is s squared over b.",
    "start": "1903940",
    "end": "1910440"
  },
  {
    "text": "And that gives me n cubed over\nbm to the 1/2 if you plug in s",
    "start": "1910440",
    "end": "1916210"
  },
  {
    "text": "being m to the 1/2.  So this is radically better\nbecause m is usually big.",
    "start": "1916210",
    "end": "1928530"
  },
  {
    "text": "Especially for a higher level\ncache, for an L2 or an L3. m",
    "start": "1928530",
    "end": "1934800"
  },
  {
    "text": "is really big. What was the value we had before\nfor the best case for the other algorithm when it\ndidn't fit in matrix?",
    "start": "1934800",
    "end": "1942260"
  },
  {
    "text": "It was n cubed over b. b is like 64 bytes.",
    "start": "1942260",
    "end": "1948570"
  },
  {
    "text": "m is like the small L1 cache\nis 32 kilobytes.",
    "start": "1948570",
    "end": "1956159"
  },
  {
    "text": "So you get to square root\nthe 32 kilobytes. What's that? ",
    "start": "1956160",
    "end": "1967470"
  },
  {
    "text": "So that's 32 kilobytes\nis 2 to the 15th.",
    "start": "1967470",
    "end": "1972669"
  },
  {
    "text": "So it's 2 to the 7.5. 2 to the 7 is 128.",
    "start": "1972670",
    "end": "1979120"
  },
  {
    "text": "So it's somewhere between\n128 and 256.",
    "start": "1979120",
    "end": "1988020"
  },
  {
    "text": "So if we said 128, I've got a 64\nand a 128 multiplier there.",
    "start": "1988020",
    "end": "1993130"
  },
  {
    "text": "Much, much better in terms\nof calculating. In fact, this is such that if we\ntune this properly and then",
    "start": "1993130",
    "end": "2000920"
  },
  {
    "text": "we say, well what was the cost\nof the cache misses here, you're not going to see the cost\nof the cache misses when",
    "start": "2000920",
    "end": "2008880"
  },
  {
    "text": "you do your performance\nanalysis. It's all going to be the work. Because the work is\nstill n cubed.",
    "start": "2008880",
    "end": "2017080"
  },
  {
    "text": "The work is still n cubed,\nbut now the misses are so infrequent, because we're\nonly getting one every--",
    "start": "2017080",
    "end": "2025180"
  },
  {
    "text": "on the order of 64 times 128,\nwhich is 2 to the 6th times 2",
    "start": "2025180",
    "end": "2030375"
  },
  {
    "text": "to the 7th is 2 to\nthe 13th is 8K. Every 8,000 or so accesses\nthere's a constant factor in",
    "start": "2030375",
    "end": "2038490"
  },
  {
    "text": "there or whatever, but every\n8,000 or so accesses we're getting a cache miss. Uh, too bad.",
    "start": "2038490",
    "end": "2045700"
  },
  {
    "text": "If it's L1, that cost is four\ncycles rather than one. ",
    "start": "2045700",
    "end": "2051349"
  },
  {
    "text": "Or that cost us 10 cycles if I\nhad to go to L2 rather than one, or whatever.",
    "start": "2051350",
    "end": "2057030"
  },
  {
    "text": "So is to the point is, that's\na great multiplier to have. ",
    "start": "2057030",
    "end": "2062940"
  },
  {
    "text": "So this is a really\ngood algorithm. And in fact, this is the optimal\nbehavior you can get",
    "start": "2062940",
    "end": "2068750"
  },
  {
    "text": "for matrix multiplication.  Hong and Kung proved back in\n1981 that this particular",
    "start": "2068750",
    "end": "2077989"
  },
  {
    "text": "strategy and this bound was\nthe best you could do for matrix multiplication.",
    "start": "2077989",
    "end": "2084010"
  },
  {
    "text": "So that's great. I want you to remember this\nnumber because we're going to come back to it.",
    "start": "2084010",
    "end": "2090129"
  },
  {
    "text": "So remember it's b times n to\nthe 1/2, b times square root of m in the denominator. ",
    "start": "2090130",
    "end": "2097990"
  },
  {
    "text": "Now there's one hitch\nin this story.",
    "start": "2097990",
    "end": "2106390"
  },
  {
    "text": "And that is, what do I\nhave to do for this algorithm to work well? ",
    "start": "2106390",
    "end": "2112720"
  },
  {
    "text": "It says right up there\non the slide.  Tune s.",
    "start": "2112720",
    "end": "2119559"
  },
  {
    "text": "I've got to tune s. How do I do that? ",
    "start": "2119560",
    "end": "2125130"
  },
  {
    "text": "How do I tune s?  How would you suggest\nwe tune s?",
    "start": "2125130",
    "end": "2130810"
  },
  {
    "text": "AUDIENCE: Just run a\nbinary [INAUDIBLE]. PROFESSOR: Yeah, do binary\nsearch on s to find out what's",
    "start": "2130810",
    "end": "2139160"
  },
  {
    "text": "the best value for s. Good strategy.",
    "start": "2139160",
    "end": "2144490"
  },
  {
    "text": "What if we guess wrong?  What happens if, say, we tune\ns, we get some value for it.",
    "start": "2144490",
    "end": "2153000"
  },
  {
    "text": "Let's say the value is 100. So we've turned it. We find 100 is our best value.",
    "start": "2153000",
    "end": "2159970"
  },
  {
    "text": "We run it on our workstation,\nand somebody else has another job running. ",
    "start": "2159970",
    "end": "2166770"
  },
  {
    "text": "What happens then? That other job starts sharing\npart of that cache.",
    "start": "2166770",
    "end": "2173520"
  },
  {
    "text": "So the effective cache size is\ngoing to be smaller than what we turned it for. And what's going to happen?",
    "start": "2173520",
    "end": "2179660"
  },
  {
    "text": " What's going to happen\nin that case?",
    "start": "2179660",
    "end": "2184990"
  },
  {
    "text": " If I've tuned in for a given\nsize and then I actually have",
    "start": "2184990",
    "end": "2190540"
  },
  {
    "text": "to run with something that's\neffectively a smaller cache,",
    "start": "2190540",
    "end": "2196340"
  },
  {
    "text": "does it matter or\ndoesn't matter? AUDIENCE: Is it still tall? PROFESSOR: Still tall.",
    "start": "2196340",
    "end": "2201601"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] ",
    "start": "2201601",
    "end": "2206958"
  },
  {
    "text": "PROFESSOR: So if you imagine\nthis fit exactly into cache, and now I only have\nhalf that amount.",
    "start": "2206958",
    "end": "2212960"
  },
  {
    "text": "Then the assumption that these\nthree inner loops is running",
    "start": "2212960",
    "end": "2218089"
  },
  {
    "text": "with only s squared over b\nmisses is going to be totally out the window.",
    "start": "2218090",
    "end": "2224410"
  },
  {
    "text": "In fact, it's going to be just\nlike the case of the first",
    "start": "2224410",
    "end": "2230869"
  },
  {
    "text": "algorithm, the naive algorithm\nthat I gave. Because the size of matrix that\nI'm feeding it, s by s,",
    "start": "2230870",
    "end": "2238180"
  },
  {
    "text": "isn't fitting in the cache. And so rather than it being s\nsquared over b accesses, it's",
    "start": "2238180",
    "end": "2245850"
  },
  {
    "text": "going to be much bigger.  I'm going to end up with\nessentially s cubed accesses",
    "start": "2245850",
    "end": "2256720"
  },
  {
    "text": "if the cache, in fact,\ngets enough smaller. ",
    "start": "2256720",
    "end": "2264589"
  },
  {
    "text": "It's also one thing you have to\nput in there is what I like to call voodoo.",
    "start": "2264590",
    "end": "2271769"
  },
  {
    "text": "Whenever you have a program and\nyou've got some parameters that, oh good we've got these\nparameters we get to tweak to",
    "start": "2271770",
    "end": "2279940"
  },
  {
    "text": "make it go better. I call those voodoo\nparameters.",
    "start": "2279940",
    "end": "2284970"
  },
  {
    "text": "Because typically setting them\nis not straightforward.",
    "start": "2284970",
    "end": "2290320"
  },
  {
    "text": "Now there are different\nstrategies. One, as you say, is to do binary\nsearch by doing it. There are some programs, in\nfact, which when you start",
    "start": "2290320",
    "end": "2298360"
  },
  {
    "text": "them up you call an\ninitialization routine. And what they will do is\nautomatically check to see",
    "start": "2298360",
    "end": "2305920"
  },
  {
    "text": "what size is my cache and what's\nthe best size should I do something on and then use\nthat when you actually run it",
    "start": "2305920",
    "end": "2313050"
  },
  {
    "text": "later in the program. So it does an automatic\nadaptation automatically when you start.",
    "start": "2313050",
    "end": "2319470"
  },
  {
    "text": "But the more parameters\nyou get, the more troublesome it becomes.",
    "start": "2319470",
    "end": "2324640"
  },
  {
    "text": "So let's take a look. For example, suppose we have a\ntwo-level cache rather than a one-level cache.",
    "start": "2324640",
    "end": "2331500"
  },
  {
    "text": "Now I need to have something\nthat I tune in for L1 and something that I tune for L2.",
    "start": "2331500",
    "end": "2336990"
  },
  {
    "text": " So it turns out that if I want\nto optimize s and t, I can't",
    "start": "2336990",
    "end": "2346660"
  },
  {
    "text": "do it in more with binary search\nbecause I have two parameters. And binary search won't suffice\nfor figuring out",
    "start": "2346660",
    "end": "2353550"
  },
  {
    "text": "what's the best combination\nof s and t. And generally multidimensional\nsearches are much harder than",
    "start": "2353550",
    "end": "2360170"
  },
  {
    "text": "one-dimensional searches\nfor optimizing. Moreover, here's what\nthe code looks like.",
    "start": "2360170",
    "end": "2366590"
  },
  {
    "text": " So now I've got, how\nmany four loops?",
    "start": "2366590",
    "end": "2374530"
  },
  {
    "text": "1,2,3,4,5,6,7,8,9 nested\nfor loops. ",
    "start": "2374530",
    "end": "2381160"
  },
  {
    "text": "So you can see the voodoo\nis starting to make this stuff run. You really have to be a magician\nto tune these things",
    "start": "2381160",
    "end": "2389720"
  },
  {
    "text": "appropriately. I mean, if you can can\ndo it that's great. But if you don't do it, OK.",
    "start": "2389720",
    "end": "2396109"
  },
  {
    "text": "So now what about three\nlevels of cache? So now we need three\ntuning parameters.",
    "start": "2396110",
    "end": "2404650"
  },
  {
    "text": "Here s, t and u, we have\n12 nested four loops. I didn't have the heart to\nactually write out the code",
    "start": "2404650",
    "end": "2412040"
  },
  {
    "text": "for the 12 nested for loops. That just seemed overhead. But our new halo machines,\nthey have",
    "start": "2412040",
    "end": "2417160"
  },
  {
    "text": "three levels of caches. So let's tune for all the\nlevels of caches.",
    "start": "2417160",
    "end": "2422750"
  },
  {
    "text": "And as we mentioned, in a\nmulti-program environment, you don't actually know what the\ncache size is, what other programs are running.",
    "start": "2422750",
    "end": "2427960"
  },
  {
    "text": "So it's really easy to mistune\nthese parameters. ",
    "start": "2427960",
    "end": "2433464"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] don't\nyou have a problem because you're running the program for\na particular n, and you don't",
    "start": "2433464",
    "end": "2441078"
  },
  {
    "text": "necessarily know whether your\nprogram is going to run faster or slower-- PROFESSOR: Well what you're\nusually doing, is you're",
    "start": "2441078",
    "end": "2446090"
  },
  {
    "text": "tuning for s not n, right? So you're assuming-- AUDIENCE: No, no\na particular n.",
    "start": "2446090",
    "end": "2451515"
  },
  {
    "text": "PROFESSOR: But the tuning of\nthis is only dependent on s. It doesn't depend on n. So if you run it for a\nsufficiently large n, I think",
    "start": "2451515",
    "end": "2458800"
  },
  {
    "text": "it's reasonable to assume that\nthe s you get would be a good s for any large n.",
    "start": "2458800",
    "end": "2465300"
  },
  {
    "text": "Because the real question is,\nwhat's fitting in cache? Yeah-- AUDIENCE: How long does it\ntake to fill up the cache",
    "start": "2465300",
    "end": "2473519"
  },
  {
    "text": "relative to the context\neach time? PROFESSOR: Generally you can\ndo it pretty quickly.",
    "start": "2473519",
    "end": "2481510"
  },
  {
    "text": "AUDIENCE: Right. So why does it matter if your\nhave multiple users, if you can fill it [INAUDIBLE].",
    "start": "2481510",
    "end": "2487609"
  },
  {
    "text": "PROFESSOR: No because, he\nmay not be using all of the cache, right? So when you come back, you're\ngoing to have it polluted with",
    "start": "2487610",
    "end": "2496320"
  },
  {
    "text": "a certain amount of stuff. ",
    "start": "2496320",
    "end": "2502830"
  },
  {
    "text": "I think it's a good question. AUDIENCE: [INAUDIBLE] ",
    "start": "2502830",
    "end": "2509836"
  },
  {
    "text": "PROFESSOR: OK, so anyway, so\nthis is the-- yeah question. AUDIENCE: So if n is really\nlarge, is it possible that the",
    "start": "2509836",
    "end": "2518240"
  },
  {
    "text": "second row of the matrix\nnever loaded? PROFESSOR: If n is\nreally large--",
    "start": "2518240",
    "end": "2524115"
  },
  {
    "text": "AUDIENCE: Because n is\nreally large, right? Just the first row of\nthe matrix will fill up all the caches.",
    "start": "2524115",
    "end": "2530156"
  },
  {
    "text": " PROFESSOR: It's LRU and in B\nyou're going down this way.",
    "start": "2530156",
    "end": "2536420"
  },
  {
    "text": " You're accessing things\ngoing down.",
    "start": "2536420",
    "end": "2543010"
  },
  {
    "text": "OK, good. So let's look at a solution\nto these alternatives.",
    "start": "2543010",
    "end": "2548690"
  },
  {
    "text": "What I want to in particular\ntake a look at is recursive",
    "start": "2548690",
    "end": "2553950"
  },
  {
    "text": "matrix multiplication.  So the idea is you can do\ndivide and conquer on",
    "start": "2553950",
    "end": "2563460"
  },
  {
    "text": "multiplying matrices because if\nI divide each of these into four pieces, then essentially\nI have 8 multiply adds of n",
    "start": "2563460",
    "end": "2574573"
  },
  {
    "text": "over 2 by n over 2 matrices. Because I basically do these\neight multiplies each going",
    "start": "2574573",
    "end": "2580250"
  },
  {
    "text": "into the correct result. So multiply A11 B11 and\nadd it into C11.",
    "start": "2580250",
    "end": "2586089"
  },
  {
    "text": "Multiply A12 B21 add it\ninto C11 and so forth. ",
    "start": "2586090",
    "end": "2592310"
  },
  {
    "text": "So I can basically do\ndivide and conquer. And then each of those I recursively divide and conquer. ",
    "start": "2592310",
    "end": "2600480"
  },
  {
    "text": "So what's the intuition\nby why this might a good scheme to use? ",
    "start": "2600480",
    "end": "2607624"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] PROFESSOR: Well, we're not\ngoing to do parallel yet.",
    "start": "2607624",
    "end": "2613730"
  },
  {
    "text": "Just why is this going to\nuse the cache well? AUDIENCE: [INAUDIBLE]",
    "start": "2613730",
    "end": "2619408"
  },
  {
    "text": "PROFESSOR: Yeah eventually I get\ndown to a size where the",
    "start": "2619408",
    "end": "2625580"
  },
  {
    "text": "matrix that I'm working on fits\ninto cache, and then all the rest of the operations\nI do are all",
    "start": "2625580",
    "end": "2631710"
  },
  {
    "text": "going to be cache hits. It is taking something and it\nit's doing what the tiling is",
    "start": "2631710",
    "end": "2639260"
  },
  {
    "text": "doing but doing it blindly.  So let's take a look.",
    "start": "2639260",
    "end": "2644980"
  },
  {
    "text": "Here's the recursive code. So here I have the base case if\nn is 1, I basically have a",
    "start": "2644980",
    "end": "2653890"
  },
  {
    "text": "one by one matrix and I\njust simply update c, with a times b.",
    "start": "2653890",
    "end": "2659460"
  },
  {
    "text": "And otherwise what I do, is\nI'm going to do this by computing offsets. So generally when you're\ndealing with matrices,",
    "start": "2659460",
    "end": "2665589"
  },
  {
    "text": "especially if you want fast\ncode, I usually don't rely on two-dimensional addressing, but\nrather do the addressing",
    "start": "2665590",
    "end": "2672680"
  },
  {
    "text": "myself and rely on the\ncompiler to do common subexpression elimination.",
    "start": "2672680",
    "end": "2678470"
  },
  {
    "text": "So, for example, here\nwhat I'm going to do is compute the offsets. So here's how I do it.",
    "start": "2678470",
    "end": "2684240"
  },
  {
    "text": "So first of all, in practice\nwhat you do, is you don't go down to n equals 1. You have some cutoff.",
    "start": "2684240",
    "end": "2690300"
  },
  {
    "text": "Maybe n is 8 or something. And at that point you go into\na specialized routine that",
    "start": "2690300",
    "end": "2695760"
  },
  {
    "text": "does a really good\n8 by 8 multiply. And the reason for that is you\ndon't want to have the",
    "start": "2695760",
    "end": "2700820"
  },
  {
    "text": "function call overheads. This function call is expensive\nto do two floating",
    "start": "2700820",
    "end": "2705900"
  },
  {
    "text": "point operations here. So you'd like to have a function\ncall and then do 100",
    "start": "2705900",
    "end": "2711200"
  },
  {
    "text": "floating point operations\nor something. So that you get a\nbetter balance. Do people understand that?",
    "start": "2711200",
    "end": "2716370"
  },
  {
    "text": "So normally to write recursive\ncodes you want a course in the recursion.",
    "start": "2716370",
    "end": "2722210"
  },
  {
    "text": "Make it so you're not going\nall go the into way down to n equals 1. But rather are stopping short\nand then doing something that",
    "start": "2722210",
    "end": "2728590"
  },
  {
    "text": "doesn't involve a lot of\noverhead in the base case of your recursion.",
    "start": "2728590",
    "end": "2734230"
  },
  {
    "text": "But here I'll explain it as\nif we went all the way down to n equals 1. ",
    "start": "2734230",
    "end": "2740590"
  },
  {
    "text": "So then what we do is, if this\nis a submatrix, which is basically what I'm\nshowing here.",
    "start": "2740590",
    "end": "2746650"
  },
  {
    "text": "We have an n by n submatrix. And it's being pulled out on a\nmatrix of size row size, of",
    "start": "2746650",
    "end": "2752070"
  },
  {
    "text": "width row size. So what I can do is, if I want\nto know where the elements of",
    "start": "2752070",
    "end": "2759329"
  },
  {
    "text": "the beginning of matrices are,\nwell the first one is exactly the same place that the\ninput matrix is.",
    "start": "2759330",
    "end": "2766770"
  },
  {
    "text": "The second one is basically I\nhave to add n over 2 to the",
    "start": "2766770",
    "end": "2771950"
  },
  {
    "text": "location in the array. The third one here, 21, I have\nto basically add n over 2 rows",
    "start": "2771950",
    "end": "2780950"
  },
  {
    "text": "to get the starting point\nof that matrix. And for the last one I have to\nadd n over 2 and n over 2 rows",
    "start": "2780950",
    "end": "2787869"
  },
  {
    "text": "and n over 2 plus 1 rows\nto get to that point. So I compute those and now I can\nrecursively multiply with",
    "start": "2787870",
    "end": "2795690"
  },
  {
    "text": "sizes of n over 2 and perform\nthe program recursively.",
    "start": "2795690",
    "end": "2802619"
  },
  {
    "text": "Yeah-- ",
    "start": "2802620",
    "end": "2808883"
  },
  {
    "text": "AUDIENCE: So you said\nit rightly. You're blindly dividing the\nmatrix up til you get something to fit the cache.",
    "start": "2808883",
    "end": "2814380"
  },
  {
    "text": "So essentially-- PROFESSOR: Well and\nyou're continuing. The algorithm is completely\nblind all the way",
    "start": "2814380",
    "end": "2819460"
  },
  {
    "text": "down to n equals 1.  AUDIENCE: This could never be\nbetter if the other one-- your",
    "start": "2819460",
    "end": "2827690"
  },
  {
    "text": "computer's version\nis well-tuned. Because the applications are\nthe same, but this one you have all the overhead from\nthe [INAUDIBLE].",
    "start": "2827690",
    "end": "2833278"
  },
  {
    "text": "PROFESSOR: Could be. AUDIENCE: At the end, you\nstill need to make a multiplication and then go back\nand look at all of the--",
    "start": "2833278",
    "end": "2839609"
  },
  {
    "text": "PROFESSOR: Could be. So let's discuss that later at\nthe end when we talk about the",
    "start": "2839610",
    "end": "2848930"
  },
  {
    "text": "differences between\nthe algorithms. Let's at this point, just try to\nunderstand what's going on in the algorithm. Question--",
    "start": "2848930",
    "end": "2854572"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE] ",
    "start": "2854572",
    "end": "2866476"
  },
  {
    "text": "PROFESSOR: n over 2 times\nrow size plus-- plus n over 2. It should be row size plus 1.",
    "start": "2866476",
    "end": "2874040"
  },
  {
    "text": "You're right. Good, bug. Should be n over 2 times\nrow size plus 1. ",
    "start": "2874040",
    "end": "2883940"
  },
  {
    "text": "So let's analyze the work\nassuming the code actually did work. ",
    "start": "2883940",
    "end": "2889780"
  },
  {
    "text": "So the work we can write\na recurrence for. So here we have the\nwork to solve an",
    "start": "2889780",
    "end": "2898500"
  },
  {
    "text": "n by n matrix problem. Well if n is 1, then it's\njust order one work--",
    "start": "2898500",
    "end": "2905510"
  },
  {
    "text": "constant amount of work. But if n is bigger than 1,\nthen I'm solving eight",
    "start": "2905510",
    "end": "2911810"
  },
  {
    "text": "problems of size n over 2, plus\ndoing a constant amount",
    "start": "2911810",
    "end": "2916890"
  },
  {
    "text": "of work to divide\nall those up. So everybody understand where\nI get this recurrence?",
    "start": "2916890",
    "end": "2923580"
  },
  {
    "text": "Now normally, as you know, when\nyou do algorithmic work,",
    "start": "2923580",
    "end": "2930360"
  },
  {
    "text": "we usually omit this first line\nbecause we assume a base case of constant if it's one.",
    "start": "2930360",
    "end": "2938260"
  },
  {
    "text": "I'm actually going to keep it. And the reason is because when\nwe do caching the basic cases are important.",
    "start": "2938260",
    "end": "2943790"
  },
  {
    "text": " So everybody understand where\nthis recurrence came from?",
    "start": "2943790",
    "end": "2949529"
  },
  {
    "text": "So I can use the master theorem\nor something like that to solve this. In which case the answer\nfor this is what?",
    "start": "2949530",
    "end": "2957059"
  },
  {
    "text": "Those of you who\nhave the master theorem in your hip pocket. ",
    "start": "2957060",
    "end": "2963170"
  },
  {
    "text": "What's the solution of\nthis recurrence?  People remember?",
    "start": "2963170",
    "end": "2968500"
  },
  {
    "text": "Who's has heard of the\nmaster theorem? I thought that was kind of a\nprerequisite or something of",
    "start": "2968500",
    "end": "2974345"
  },
  {
    "text": "this class, right?  So you might want to brush up on\nthe master theorem for the",
    "start": "2974345",
    "end": "2981290"
  },
  {
    "text": "quiz next week.  So basically it's a n over\nb, so it's n to the",
    "start": "2981290",
    "end": "2988916"
  },
  {
    "text": "log base 2 of 8.  So that's n cubed, n to\nthe log base 2 of 8",
    "start": "2988916",
    "end": "2994752"
  },
  {
    "text": "is n to the n cubed.  And that's bigger than the order\none here, so the answer",
    "start": "2994752",
    "end": "3000780"
  },
  {
    "text": "is order n cubed. Which is a relief, right? Because if weren't order n cubed\nwe would be doing a lot",
    "start": "3000780",
    "end": "3009140"
  },
  {
    "text": "more work than one of the\nlooping algorithms.",
    "start": "3009140",
    "end": "3015260"
  },
  {
    "text": "However, let's actually go\nthrough and understand where that n cubed comes from.",
    "start": "3015260",
    "end": "3021120"
  },
  {
    "text": "And to do that I'm going to\nuse the technique of a recursive tree, which I think\nall of you have seen.",
    "start": "3021120",
    "end": "3027380"
  },
  {
    "text": "But let me go through it slowly\nhere to make sure, because we're going to do it\nagain when we do cache misses",
    "start": "3027380",
    "end": "3032780"
  },
  {
    "text": "and it's going to be\nmore complicated. So here's the idea. I write down the left hand side\nthe recurrence, w of n.",
    "start": "3032780",
    "end": "3042160"
  },
  {
    "text": "And now what I do is\nI substitute, and I draw it out as a tree. I have eight problems\nof size n over 2.",
    "start": "3042160",
    "end": "3049580"
  },
  {
    "text": "So what I do is I replace that\nwith the thing that's on the right hand side, I've dropped\nthe theta here, but basically",
    "start": "3049580",
    "end": "3058170"
  },
  {
    "text": "put just a constant one here. Because I'll take into account\nthe thetas at the end. So I have a one here, and\nthen I have, loops",
    "start": "3058170",
    "end": "3068510"
  },
  {
    "text": "that should be a w. Should be w n over 2. That's a bug there.",
    "start": "3068510",
    "end": "3076060"
  },
  {
    "text": "And then I replace\neach of those. ",
    "start": "3076060",
    "end": "3081420"
  },
  {
    "text": "OK, wn over 2, sorry that\nshould be wn over 4.",
    "start": "3081420",
    "end": "3087795"
  },
  {
    "text": "Ah, more bugs. I'll fix them up on\nafter lecture.",
    "start": "3087795",
    "end": "3093240"
  },
  {
    "text": "So this should be\nw of n over 4. And we go all the way down to\nthe bottom to where I hit the",
    "start": "3093240",
    "end": "3099260"
  },
  {
    "text": "base case of theta 1.",
    "start": "3099260",
    "end": "3104410"
  },
  {
    "text": "So I built out this big tree\nthat represents, if you think about it, that's exactly what\nthe algorithm is going to do.",
    "start": "3104410",
    "end": "3110350"
  },
  {
    "text": "It's going to walk this\ntree doing the work. And what I've just simply put up\nhere is to work it does at",
    "start": "3110350",
    "end": "3115450"
  },
  {
    "text": "every level.  So the first thing we want to\ndo is figure out what's the",
    "start": "3115450",
    "end": "3123320"
  },
  {
    "text": "height of this tree. Can somebody tell me what the\nheight of the tree is? ",
    "start": "3123320",
    "end": "3130479"
  },
  {
    "text": "It is a log n. What's the base? Log base 2 of n, base because\nat every level if I hadn't",
    "start": "3130479",
    "end": "3136950"
  },
  {
    "text": "made a mistake here, I'm\nactually having the argument. So I'm having the argument\nat each level.",
    "start": "3136950",
    "end": "3144250"
  },
  {
    "text": "So the height is log\nbase 2 of n. So LG is notation\nfor log base 2. ",
    "start": "3144250",
    "end": "3151720"
  },
  {
    "text": "So if I have log base 2 of n,\nI can count how many leaves there are to this tree.",
    "start": "3151720",
    "end": "3156940"
  },
  {
    "text": "So how many leaves are there? Well I'm branching a factor\nof eight at every level.",
    "start": "3156940",
    "end": "3165200"
  },
  {
    "text": "And if I'm going log base 2\nlevels, the number of leaves is 8 to the log base 2.",
    "start": "3165200",
    "end": "3172030"
  },
  {
    "text": "So 8 to the log base 2 of n. And then with a little bit of\nalgebraic magic that turns out",
    "start": "3172030",
    "end": "3177100"
  },
  {
    "text": "that's the same as n to\nthe log base 2 of 8. ",
    "start": "3177100",
    "end": "3182140"
  },
  {
    "text": "And that is equal to n cubed. So I end up with\nn cubed leaves.",
    "start": "3182140",
    "end": "3188820"
  },
  {
    "text": "Now let's add up all the\nwork that's in here. So what I do is I add\nacross the rows.",
    "start": "3188820",
    "end": "3194940"
  },
  {
    "text": "So the top level I've\ngot work of one. The next level I\nwork of eight.",
    "start": "3194940",
    "end": "3200220"
  },
  {
    "text": "The next I have work of 64. Do people see the pattern?",
    "start": "3200220",
    "end": "3205339"
  },
  {
    "text": "The work is growing how? Geometrically.",
    "start": "3205340",
    "end": "3211190"
  },
  {
    "text": "And at this level I know that\nif I add up all the leaves I've got work of n cubed.",
    "start": "3211190",
    "end": "3219000"
  },
  {
    "text": "Because I've got n cubed\nleaves, each of them taking a constant. And so this is geometrically\nincreasing, which means that",
    "start": "3219000",
    "end": "3224840"
  },
  {
    "text": "it's all born in the leaves. So the total work is\norder n cubed. ",
    "start": "3224840",
    "end": "3231600"
  },
  {
    "text": "And that's nice. It's the same work is the\nlooping versions. Because we don't want\nto increase that.",
    "start": "3231600",
    "end": "3236650"
  },
  {
    "text": " Questions?",
    "start": "3236650",
    "end": "3241730"
  },
  {
    "text": "Because now we're going to do\ncache misses and it's going to get hairy, not too hairy,\nbut hairier.",
    "start": "3241730",
    "end": "3247420"
  },
  {
    "start": "3247420",
    "end": "3253809"
  },
  {
    "text": "So here we're going\nto cache misses. So the first thing is coming\nup with a recurrence. And this is probably the hardest\npart, except for the",
    "start": "3253810",
    "end": "3261960"
  },
  {
    "text": "other hard part which is\nsolving the recurrence.  So here what we're doing is, we\nhave the same thing is that",
    "start": "3261960",
    "end": "3269910"
  },
  {
    "text": "I'm solving eight problems of\nsize n over 2 and to do the",
    "start": "3269910",
    "end": "3275569"
  },
  {
    "text": "work in here. I'm taking basically order\none cache misses. However I do, those\nthings work out.",
    "start": "3275570",
    "end": "3284440"
  },
  {
    "text": "Plus the cache misses\nI have in there. But then at some point, when I'm\nclaiming is that I'm going",
    "start": "3284440",
    "end": "3291059"
  },
  {
    "text": "to bottom out the\nrecursion early. Not when I get to n equals 1,\nbut in fact when n squared is",
    "start": "3291060",
    "end": "3299260"
  },
  {
    "text": "less than some constant\ntimes the cache size. For some sufficiently\nsmall concept.",
    "start": "3299260",
    "end": "3307010"
  },
  {
    "text": "And what I claim, at that point,\nis that the number of cache misses I'm going to take\nat that point, I can just,",
    "start": "3307010",
    "end": "3313540"
  },
  {
    "text": "without doing any more recursive\nstuff, I can just say it's n squared over b.",
    "start": "3313540",
    "end": "3318700"
  },
  {
    "text": " So where does that come from? So this basically comes from\nthe tall-cache assumption.",
    "start": "3318700",
    "end": "3327450"
  },
  {
    "text": "So the idea is that when n\nsquared is less than a constant times the size of your\ncache, constant times the",
    "start": "3327450",
    "end": "3335660"
  },
  {
    "text": "size of m, then that means\nthat this fits into-- the n by n matrices\nfit within m.",
    "start": "3335660",
    "end": "3342119"
  },
  {
    "text": "I've got three of them. I've got C, A and B. So that's\nwhere I need a constant here.",
    "start": "3342120",
    "end": "3348660"
  },
  {
    "text": "So they're all going\nto fit in memory. And so if I look at it, all I\nhave to do is count up the",
    "start": "3348660",
    "end": "3356640"
  },
  {
    "text": "cold misses for bringing in\nthose submatrices at the time",
    "start": "3356640",
    "end": "3365839"
  },
  {
    "text": "that n hits this threshold here\nof some constant times m.",
    "start": "3365840",
    "end": "3370970"
  },
  {
    "text": "And to bring in those matrices\nis only going to cost me n squared over b cache misses.",
    "start": "3370970",
    "end": "3376580"
  },
  {
    "text": "And once I've done that, all of\nthe rest of the recursion that's going on down below is\nall operating out of cache.",
    "start": "3376580",
    "end": "3384349"
  },
  {
    "text": "It's not taking any misses\nif I have an",
    "start": "3384350",
    "end": "3389510"
  },
  {
    "text": "optimal replacement algorithm. it's not taking any more misses\nas I get further down.",
    "start": "3389510",
    "end": "3396540"
  },
  {
    "text": "Questions about this part\nof the recurrence here?",
    "start": "3396540",
    "end": "3405470"
  },
  {
    "start": "3405470",
    "end": "3411510"
  },
  {
    "text": "So people with me?  So when I get down to something\nof size n squared,",
    "start": "3411510",
    "end": "3418550"
  },
  {
    "text": "where the submatrix is size n\nsquared, the point is that I'll bring in the entire\nsubmatrix.",
    "start": "3418550",
    "end": "3425300"
  },
  {
    "text": "But all the stuff that I have to\ndo in there is never going to get kicked out, because\nit's small",
    "start": "3425300",
    "end": "3430609"
  },
  {
    "text": "enough that it all fits. And an optimal algorithm for\nreplacement is going to make sure that stuff stays in there,\nbecause there's plenty",
    "start": "3430610",
    "end": "3437200"
  },
  {
    "text": "of room in the cache\nat that point. There's room for three matrices\nin the cache and a",
    "start": "3437200",
    "end": "3442349"
  },
  {
    "text": "couple of other variables that\nI might need and that's basically it. ",
    "start": "3442350",
    "end": "3450400"
  },
  {
    "text": "Any questions about that? So let's then solve\nthis recurrence.",
    "start": "3450400",
    "end": "3457540"
  },
  {
    "text": "So we're going to go about it\nvery much the same way. We make draw a recursion tree. So those of you are rusty in\ndrawing recursion trees, I can",
    "start": "3457540",
    "end": "3464470"
  },
  {
    "text": "promise you there will be a\nrecursion tree on the quiz next Thursday. I think I can promise that.",
    "start": "3464470",
    "end": "3470570"
  },
  {
    "text": "Can I promise that? Yeah, OK I can promise that. ",
    "start": "3470570",
    "end": "3475970"
  },
  {
    "text": "The way I like to do it, by the\nway, is not to try to just brought out all at once.",
    "start": "3475970",
    "end": "3482020"
  },
  {
    "text": "In my own notes when I do this I\nalways draw it step by step. I copy over and just\ndo a step by step.",
    "start": "3482020",
    "end": "3487980"
  },
  {
    "text": "You might think that\nthat's extensive. Gee, why do I have to draw\nevery one along the way? Well the answer is, it's\na geometric process.",
    "start": "3487980",
    "end": "3496059"
  },
  {
    "text": "All the ones going up to the\nlast one are a small amount of the work to draw out\nthe last one.",
    "start": "3496060",
    "end": "3503710"
  },
  {
    "text": "And they help you get it\ncorrect the first time. So let me encourage you\nto draw out the tree",
    "start": "3503710",
    "end": "3512550"
  },
  {
    "text": "iteration by iteration. Here I'm going to just\ndo replacement. So what we do is we replace with\nthe right hand side to do",
    "start": "3512550",
    "end": "3519940"
  },
  {
    "text": "the recursion. And replace that. And once again I made the bug,\nthat should be in over 8.",
    "start": "3519940",
    "end": "3526890"
  },
  {
    "text": "Sorry, n over 4 here. n over 4. And then we keep going down\nuntil I get to the base case,",
    "start": "3526890",
    "end": "3535569"
  },
  {
    "text": "which is this case here. Now comes the first hard part.",
    "start": "3535570",
    "end": "3542120"
  },
  {
    "text": "How tall is this tree? Yeah-- AUDIENCE: [INAUDIBLE] square root of n over b.",
    "start": "3542120",
    "end": "3548038"
  },
  {
    "text": "You want n squared to be\ncm, not [INAUDIBLE]. PROFESSOR: So here's the thing,\nlet's discuss, first of",
    "start": "3548038",
    "end": "3554830"
  },
  {
    "text": "all, why this is what it is. So at the point where n squared\nis less than cm, that",
    "start": "3554830",
    "end": "3562850"
  },
  {
    "text": "says that it's going to cost\nus n squared over b.",
    "start": "3562850",
    "end": "3568066"
  },
  {
    "text": "But n squared is just less than\ncm, so therefore, this is",
    "start": "3568066",
    "end": "3573720"
  },
  {
    "text": "effectively m over b.  Good question.",
    "start": "3573720",
    "end": "3579230"
  },
  {
    "text": "So everybody see that? So when I get down to the\nbottom, it's basically costing me something that's about the\nnumber of lines I have in my",
    "start": "3579230",
    "end": "3585630"
  },
  {
    "text": "cache, number of misses\nto fill things up.",
    "start": "3585630",
    "end": "3591640"
  },
  {
    "text": "The tricky thing is,\nwhat's the height? Because this is crucial to\ngetting this kind of calculation right.",
    "start": "3591640",
    "end": "3598110"
  },
  {
    "text": "So what is the height\nof this tree? ",
    "start": "3598110",
    "end": "3604690"
  },
  {
    "text": "So I'm having every time. So one way to think about it is,\nit's going to be log bas 2",
    "start": "3604690",
    "end": "3611505"
  },
  {
    "text": "of n, just as before, minus the\nheight of the tree that is",
    "start": "3611506",
    "end": "3617120"
  },
  {
    "text": "hidden here that I didn't have\nto actually go into because there are no cache\nmisses in it. ",
    "start": "3617120",
    "end": "3623210"
  },
  {
    "text": "So that's going to occur when\nn is approximately m, cm,",
    "start": "3623210",
    "end": "3631980"
  },
  {
    "text": "sorry when n is approximately\nsquare root of cm. So I end up with log of\nn minus 1/2 log of cm.",
    "start": "3631980",
    "end": "3639120"
  },
  {
    "start": "3639120",
    "end": "3644600"
  },
  {
    "text": "That's the height here. Because the height at this\npoint of the tree that's missing because they're no\ncache, I don't have to account",
    "start": "3644600",
    "end": "3651000"
  },
  {
    "text": "for any cache misses in there,\nis log of cm to the one half,",
    "start": "3651000",
    "end": "3656880"
  },
  {
    "text": "based on this.  Does that follow\nfor everybody?",
    "start": "3656880",
    "end": "3663400"
  },
  {
    "text": "People comfortable?  Yeah? OK, good.",
    "start": "3663400",
    "end": "3670090"
  },
  {
    "text": "So now what do we do? We count up how many\nleaves there are.",
    "start": "3670090",
    "end": "3675430"
  },
  {
    "text": "So the number of leaves is 8,\nbecause I have a branching factor of 8, 2 whatever\nthe height is.",
    "start": "3675430",
    "end": "3681150"
  },
  {
    "text": "Log n minus 1/2 log of cm.  And then if I do my matrix\nmagic, well that part is n",
    "start": "3681150",
    "end": "3687760"
  },
  {
    "text": "cubed, the minus becomes a\ndivide, and now 8 to the 1/2 log of cm is the square\nroot of n cubed,",
    "start": "3687760",
    "end": "3700180"
  },
  {
    "text": "which is m to the 3/2. ",
    "start": "3700180",
    "end": "3706561"
  },
  {
    "text": "Is that good? The rest of it is very similar\nto what we did before.",
    "start": "3706561",
    "end": "3712050"
  },
  {
    "text": "At every level I have a certain\nnumber of things that",
    "start": "3712050",
    "end": "3717570"
  },
  {
    "text": "I'm adding up. And on the bottom level, I take\nthe cost here, m over b,",
    "start": "3717570",
    "end": "3722849"
  },
  {
    "text": "and I multiply it by\na number of leaves. When I do that I get, what?",
    "start": "3722850",
    "end": "3729440"
  },
  {
    "text": "I get n cubed over b\ntimes m to the 1/2. ",
    "start": "3729440",
    "end": "3736660"
  },
  {
    "text": "This is geometric. So the answer is going, in this\ncase, just going to be the sum of a constant factor\ntimes the large thing.",
    "start": "3736660",
    "end": "3747860"
  },
  {
    "text": "And why does this\nlook familiar?  That was the optimal result\nwe got from tiling.",
    "start": "3747860",
    "end": "3756180"
  },
  {
    "text": "But where's the tuning\nparameters?  No tuning parameters.",
    "start": "3756180",
    "end": "3761920"
  },
  {
    "text": " No tuning parameters. So that means that this analysis\nthat I did for one",
    "start": "3761920",
    "end": "3768970"
  },
  {
    "text": "level of caching, it applies\neven if you have three levels",
    "start": "3768970",
    "end": "3774550"
  },
  {
    "text": "of caching. At every level you're getting\nnear optimal cache behavior.",
    "start": "3774550",
    "end": "3783885"
  },
  {
    "text": "So it's got the same cache\nmisses as with tiling. ",
    "start": "3783885",
    "end": "3796450"
  },
  {
    "text": "These are called cache-oblivious\nalgorithms. Because the algorithm itself\nhas no tuning parameters",
    "start": "3796450",
    "end": "3802680"
  },
  {
    "text": "related to cache. Unlike the tiling algorithm. That's a cache-aware\nalgorithm.",
    "start": "3802680",
    "end": "3808895"
  },
  {
    "text": "The cache-oblivious algorithm\nhas no tuning parameters. And if it's an efficient one.",
    "start": "3808895",
    "end": "3816950"
  },
  {
    "text": "So, by the way, our first\nalgorithm was cache-oblivious as well. The naive one. It's just not efficient.",
    "start": "3816950",
    "end": "3822510"
  },
  {
    "text": " So in this case we have\nan efficient one.",
    "start": "3822510",
    "end": "3828132"
  },
  {
    "text": "It's got no voodoo turning of\nparameters, no explicit knowledge of caches, and it\npassively autotunes itself.",
    "start": "3828132",
    "end": "3837980"
  },
  {
    "text": "As it goes down when it fits\nthings into cache it fits them and uses things locally. And then it goes down and it\nfits into the next level of",
    "start": "3837980",
    "end": "3844990"
  },
  {
    "text": "cache and uses things locally\nand so forth. It handles multi-level\ncaches automatically.",
    "start": "3844990",
    "end": "3853260"
  },
  {
    "text": "And it's good in\nmulti-programmed environments. Because if you end up taking\naway some of the cache it",
    "start": "3853260",
    "end": "3860410"
  },
  {
    "text": "doesn't matter. It still will end up using\nwhatever cache is available",
    "start": "3860410",
    "end": "3866510"
  },
  {
    "text": "nearly as well as any other\nprogram could use that cache.",
    "start": "3866510",
    "end": "3876160"
  },
  {
    "text": "So these are very good in\nmulti-programmed environments. ",
    "start": "3876160",
    "end": "3883930"
  },
  {
    "text": "The best cache-oblivious matrix\nmultiplication, in fact doesn't do an eight way split\nas I described here.",
    "start": "3883930",
    "end": "3890430"
  },
  {
    "text": "That was easier to analyze\nand so forth. The best one that\nI know work on",
    "start": "3890430",
    "end": "3896030"
  },
  {
    "text": "arbitrary rectangular matrix. And what they do, is they\ndo binary splitting. So you would take your matrix,\ni times j, So if you take a",
    "start": "3896030",
    "end": "3908440"
  },
  {
    "text": "matrix, let's say it's\nsomething like this. ",
    "start": "3908440",
    "end": "3914640"
  },
  {
    "text": "So here we have i, k, k, j.",
    "start": "3914640",
    "end": "3922589"
  },
  {
    "text": "And you're going to get\nsomething of shape. ",
    "start": "3922590",
    "end": "3929160"
  },
  {
    "text": "i times j, right? ",
    "start": "3929160",
    "end": "3936250"
  },
  {
    "text": "What it does, is it\ntakes whatever is the largest dimension. In this case k is the\nlargest dimension.",
    "start": "3936250",
    "end": "3942560"
  },
  {
    "text": "And it partitions either\none or both of the matrices along k.",
    "start": "3942560",
    "end": "3948559"
  },
  {
    "text": "In this case, it doesn't\ndo that. And then it recursively\nsolves the two sub-rectangular problems.",
    "start": "3948560",
    "end": "3955210"
  },
  {
    "text": "And that ends up being a very,\nvery efficient fast code if you code that up tightly.",
    "start": "3955210",
    "end": "3960650"
  },
  {
    "text": "So it does binary splitting\nrather than-- and it's general. And if you analyze this, it's\ngot the same behavior as the",
    "start": "3960650",
    "end": "3968289"
  },
  {
    "text": "eight way division. It's just more efficient. ",
    "start": "3968290",
    "end": "3976059"
  },
  {
    "text": "So questions? We had a question about\nnow comparing with the tiled algorithm.",
    "start": "3976060",
    "end": "3983750"
  },
  {
    "text": "Do you want to reprise\nyour question? AUDIENCE: What I was\nsaying was, I guess this answers my question.",
    "start": "3983750",
    "end": "3989725"
  },
  {
    "text": "If you were to tune the previous\nalgorithm properly,",
    "start": "3989725",
    "end": "3994742"
  },
  {
    "text": "and you're assuming it's\nnot in a multi-program environment, the recursive one,\nit will never be the one",
    "start": "3994742",
    "end": "4001900"
  },
  {
    "text": "that is locked. [INAUDIBLE] PROFESSOR: So at some level\nthat's true, and at some level",
    "start": "4001900",
    "end": "4010010"
  },
  {
    "text": "it's not true.  So it is true in that if it's\ncache-oblivious you can't take",
    "start": "4010010",
    "end": "4022589"
  },
  {
    "text": "advantage of all the corner\ncases that you would might be able to take advantage of\nin a tiling algorithm.",
    "start": "4022590",
    "end": "4028140"
  },
  {
    "text": "So from that point of\nview, that's true. On the other hand, these\nalgorithms work even as you go",
    "start": "4028140",
    "end": "4034049"
  },
  {
    "text": "into paging and disks\nand so forth. And the interesting thing about\na disk, if you start",
    "start": "4034050",
    "end": "4039090"
  },
  {
    "text": "having a big problem that\ndoesn't fit in memory and, in fact, is out of core as they\ncall it, and is paging to",
    "start": "4039090",
    "end": "4046060"
  },
  {
    "text": "disk, is that the disk sizes of\nsectors that can be brought",
    "start": "4046060",
    "end": "4053680"
  },
  {
    "text": "efficiently off of\na disk, vary. ",
    "start": "4053680",
    "end": "4060430"
  },
  {
    "text": "And the reason is because in\na disk, if you read a track",
    "start": "4060430",
    "end": "4067770"
  },
  {
    "text": "around the outside you can get\ntwo or three times as much data off the disk as a track\nthat you read near the inside.",
    "start": "4067770",
    "end": "4077510"
  },
  {
    "text": "So the head moves in and out\nof the disk like this.",
    "start": "4077510",
    "end": "4082960"
  },
  {
    "text": "It's typically on a pivot\nand pivots in and out. If it's reading towards the\ninside, you get blocks that",
    "start": "4082960",
    "end": "4088940"
  },
  {
    "text": "are small versus blocks\nthat are large. This is effectively a\ncache line size that",
    "start": "4088940",
    "end": "4094950"
  },
  {
    "text": "gets brought in. And so the thing is that there\nare actually programs in",
    "start": "4094950",
    "end": "4102568"
  },
  {
    "text": "which, when you run them on\ndisk, there is no fixed size tuning parameter that beats\nthe cache-oblivious one.",
    "start": "4102569",
    "end": "4113528"
  },
  {
    "text": "So the cache-oblivious one will\nbeat every fixed-size tuning parameters you put in. Because you don't have any\ncontrol over where your file",
    "start": "4113529",
    "end": "4121859"
  },
  {
    "text": "got laid out on disk and how\nmuch it's bringing in and how",
    "start": "4121859",
    "end": "4127130"
  },
  {
    "text": "much it isn't varies. On the other hand, for in-core\nthing, you're exactly right.",
    "start": "4127130",
    "end": "4133439"
  },
  {
    "text": "That, in principle, you could\ntune it up more if you make it more cache aware.",
    "start": "4133439",
    "end": "4138710"
  },
  {
    "text": "But then, of course, you suffer\nfrom portability loss and from, if you're in a\nmulti-programmed environment",
    "start": "4138710",
    "end": "4143963"
  },
  {
    "text": "and so forth. So the answer is, that there\nare situations where you're doing some kind of embedded or\ndedicated type of application,",
    "start": "4143964",
    "end": "4154339"
  },
  {
    "text": "you can take advantage of a lot\nof things that you want. There are other times\nwhere you're doing a multi-programmed environment,\nor where you want to be able",
    "start": "4154340",
    "end": "4164109"
  },
  {
    "text": "to move something from one\nplatform to another without having to re-engineer all of\nthe tuning and testing.",
    "start": "4164109",
    "end": "4170589"
  },
  {
    "text": "In which case it's better to\nuse the cache oblivious. So as I mentioned, my view\nof these things is that",
    "start": "4170590",
    "end": "4178410"
  },
  {
    "text": "performance is like\na currency. It's a universal medium\nof exchange.",
    "start": "4178410",
    "end": "4183540"
  },
  {
    "text": "So one place you might want\nto pay a little bit of performance is to make it so\nit's very portable as for the cache-oblivious stuff.",
    "start": "4183540",
    "end": "4190239"
  },
  {
    "text": "So you get nearly good\nperformance, but now I don't have that headache\nto worry about.",
    "start": "4190240",
    "end": "4197760"
  },
  {
    "text": "And then sometimes, in fact,\nit actually does as well or better than the one.",
    "start": "4197760",
    "end": "4202880"
  },
  {
    "text": "For matrix multiplication, the\nbest algorithms are the cache oblivious ones that\nI'm aware of. AUDIENCE: [INAUDIBLE]",
    "start": "4202880",
    "end": "4210348"
  },
  {
    "text": "currency and all the different\ncurrencies. Single currency. PROFESSOR: You want\na currency for--",
    "start": "4210348",
    "end": "4215670"
  },
  {
    "text": "so in fact the performance for\nthis is people who have engineered it to take advantage\nof exactly the cache",
    "start": "4215670",
    "end": "4222580"
  },
  {
    "text": "size, we can do just as well\nwith the cache oblivious one. And particularly, if you think\nabout it, when you've got",
    "start": "4222580",
    "end": "4228450"
  },
  {
    "text": "three levels hierarchy,\nyou've got 12 loops. ",
    "start": "4228450",
    "end": "4236380"
  },
  {
    "text": "And now you're going\nto tune that. It's hard to get it all right. ",
    "start": "4236380",
    "end": "4244309"
  },
  {
    "text": "So next time we're going to see\na bunch of other examples of cache-oblivious algorithms\nthat are optimal in terms of",
    "start": "4244310",
    "end": "4252080"
  },
  {
    "text": "their use of cache. Of course, by the way, those\npeople who are familiar with Strassen's algorithm, that's a\ncache-oblivious algorithm.",
    "start": "4252080",
    "end": "4259420"
  },
  {
    "text": "Takes advantage the same\nkind of thing. And in fact you can analyze it\nand come up with good bounds",
    "start": "4259420",
    "end": "4265530"
  },
  {
    "text": "on performance for Strassen's\nalgorithm just the same.",
    "start": "4265530",
    "end": "4270670"
  },
  {
    "text": "Just as we've done here. ",
    "start": "4270670",
    "end": "4273131"
  }
]
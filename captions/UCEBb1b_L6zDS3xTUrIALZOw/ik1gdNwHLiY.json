[
  {
    "start": "0",
    "end": "14000"
  },
  {
    "text": "[SQUEAKING] [RUSTLING] [CLICKING]",
    "start": "0",
    "end": "5760"
  },
  {
    "text": " FRANK SCHILBACH: Welcome to\nthe mid-term review of 14.13.",
    "start": "5760",
    "end": "13348"
  },
  {
    "text": "Tonight, as I\nmentioned before, there will be three types of\nquestions on the exam.",
    "start": "13348",
    "end": "18500"
  },
  {
    "start": "14000",
    "end": "14000"
  },
  {
    "text": "There will be\ntrue/false/uncertain questions. These are questions where\nyou're given a statement,",
    "start": "18500",
    "end": "23800"
  },
  {
    "text": "and you can ascertain\nwhether the statement is true or false or uncertain. True means essentially\nit's strictly true",
    "start": "23800",
    "end": "30250"
  },
  {
    "text": "and it's always true, or false\nmeans it's strictly false, and there's a counterexample\nthat's shows you it's false.",
    "start": "30250",
    "end": "36250"
  },
  {
    "text": "And uncertain means like without\nhaving further information,",
    "start": "36250",
    "end": "41300"
  },
  {
    "text": "you cannot actually\nanswer the questions. So you cannot really make\na statement whether that statement is true or false.",
    "start": "41300",
    "end": "48610"
  },
  {
    "text": "In any of the ones you\ndo, please always explain your answers carefully.",
    "start": "48610",
    "end": "54040"
  },
  {
    "text": "So just writing true,\nfalse, or uncertain will almost surely\nor will surely not",
    "start": "54040",
    "end": "59110"
  },
  {
    "text": "give you full credit. You have to explain\nyour answers. It doesn't actually matter that\nmuch whether you get it right,",
    "start": "59110",
    "end": "66450"
  },
  {
    "text": "whether the statement is\ntrue, or false, or uncertain, as long as your answer is\nactually reasonable and shows",
    "start": "66450",
    "end": "73201"
  },
  {
    "text": "some understanding\nof the material.  So the quality of your\nanswer is quite important.",
    "start": "73202",
    "end": "81260"
  },
  {
    "text": "We also want you to\nprovide intuitions. We do not want you to just write\nsome math and nothing else.",
    "start": "81260",
    "end": "87340"
  },
  {
    "text": "You can use some math\nto sort of clarify your answer or the\nlike, but you always",
    "start": "87340",
    "end": "93460"
  },
  {
    "text": "need to provide a verbal\nexplanation and some intuition and some explanation of why\nyou think the answer might be",
    "start": "93460",
    "end": "100970"
  },
  {
    "text": "or the statement\nmight be true, false, or [AUDIO OUT] your answer. For multiple choice\nquestions, you're essentially",
    "start": "100970",
    "end": "107520"
  },
  {
    "text": "given different\nchoices, and you just pick one answer with no\nfurther explanation needed. Very simple.",
    "start": "107520",
    "end": "113104"
  },
  {
    "text": "And then there will be sort\nof pset-style questions that sort of you're familiar\nwith, either from like psets",
    "start": "113105",
    "end": "118120"
  },
  {
    "text": "or like previous exams. These will be quite similar\nto the psets questions.",
    "start": "118120",
    "end": "123250"
  },
  {
    "text": "It will be sort of generally\nnot on the harder side, just, you know, we only have\nso much time to do this.",
    "start": "123250",
    "end": "128740"
  },
  {
    "text": "There will be some\nalgebra involved. Again, please always explain\nyour answers carefully.",
    "start": "128740",
    "end": "136900"
  },
  {
    "text": "Now, what materials are\nyou responsible for? You're responsible for the\nlectures up to and including",
    "start": "136900",
    "end": "143379"
  },
  {
    "start": "138000",
    "end": "138000"
  },
  {
    "text": "lecture 12, which was\nthe lecture on March 11, up to slide 67 of\nlectures 11, or lecture--",
    "start": "143380",
    "end": "150985"
  },
  {
    "text": "the notes for the lecture,\nthe handout of the notes for lectures 11 through 13. You're also responsible for\nrecitations 1 through 5,",
    "start": "150985",
    "end": "159340"
  },
  {
    "text": "recitations 6, now, which the\nrecitation that Will gave,",
    "start": "159340",
    "end": "164680"
  },
  {
    "text": "which is quite similar\nto this one, and 7. These recitations\nare just reviews that might be helpful\nfor some of you.",
    "start": "164680",
    "end": "171459"
  },
  {
    "text": "But there's no new material\nthat we use that [INAUDIBLE] right now. Psets 1 to 3 are sort\nof part of the deal.",
    "start": "171460",
    "end": "180069"
  },
  {
    "text": "And readings, starred\nor non-starred readings cited in class are only\nrelevant to the extent",
    "start": "180070",
    "end": "187299"
  },
  {
    "text": "that they appear in\nlectures and/or recitation. But to say, like if I discuss\na certain paper and the content",
    "start": "187300",
    "end": "193810"
  },
  {
    "text": "of that paper, the content\nof the people that's discussed in the class\nis relevant to you.",
    "start": "193810",
    "end": "199750"
  },
  {
    "text": "However, anything\nthat's in the paper that doesn't appear in the\nlecture is not relevant,",
    "start": "199750",
    "end": "206170"
  },
  {
    "text": "as in like, we're not going\nto ask you questions that sort of ask about some\nobscure details of the papers",
    "start": "206170",
    "end": "211510"
  },
  {
    "text": "that you never heard\nabout in class. How do you get\nready for the exam?",
    "start": "211510",
    "end": "216600"
  },
  {
    "text": "Well, you study, study that the\nlecture and presentation slides carefully.",
    "start": "216600",
    "end": "222580"
  },
  {
    "text": "You should make sure you're\nfamiliar and comfortable with the psets and\nthe solutions make",
    "start": "222580",
    "end": "228190"
  },
  {
    "text": "you understand and are able to\nsolve the psets on your own. A great resource practice is\nto do those psets and exams.",
    "start": "228190",
    "end": "236650"
  },
  {
    "text": "Again, readings, starred and\nnon-starred, are not required, but they may sort of help\nyou deepen your understanding",
    "start": "236650",
    "end": "243850"
  },
  {
    "text": "of the material, and maybe\nsometimes the lecture notes a little bit. [AUDIO OUT] dense and don't\nhave that much detail.",
    "start": "243850",
    "end": "250090"
  },
  {
    "text": "So you can sort of like try\nto consult them, and try to understand the material\nas best or better. But we won't ask you about\nthe details of those readings",
    "start": "250090",
    "end": "261208"
  },
  {
    "text": "beyond those details of\nwas covered in class. So let me now sort of review\nthe material overall and sort",
    "start": "261208",
    "end": "267735"
  },
  {
    "start": "266000",
    "end": "266000"
  },
  {
    "text": "of give you a sense of what\nare the kinds of things that we want to know. To be clear, this\nis not exhaustive",
    "start": "267735",
    "end": "273250"
  },
  {
    "text": "in the sense of like, there\nare some other materials in the lecture slides that\nI'm not mentioning here.",
    "start": "273250",
    "end": "278260"
  },
  {
    "text": "What I'm trying\nto do here is just give you a sense\nfor a lot of what the most important key\nthings that you should know.",
    "start": "278260",
    "end": "283970"
  },
  {
    "text": "This will cover\nperhaps like 80%, 90% of the material\nthat's actually potentially in the exam.",
    "start": "283970",
    "end": "289570"
  },
  {
    "text": "Having said that, you\nknow you should really go through the entire\nlecture slides, make sure you're sort\nof gathering everything",
    "start": "289570",
    "end": "296200"
  },
  {
    "text": "in understanding\nwhat's going on there. OK. So the first thing we discuss,\nthese time preferences",
    "start": "296200",
    "end": "302460"
  },
  {
    "text": "in particular, the\nexponential discounting model. Here, you should know, what\nis the exponential discounting",
    "start": "302460",
    "end": "308039"
  },
  {
    "text": "model? What is delta, the time\npreference parameter that model? What does it measure?",
    "start": "308040",
    "end": "313210"
  },
  {
    "text": "How can we estimate it, assuming\nthat an exponential discounting model is correct? Further, what are\nthe main assumptions",
    "start": "313210",
    "end": "320100"
  },
  {
    "text": "of exponential\ndiscounting model, and what evidence do we have\nagainst those assumptions?",
    "start": "320100",
    "end": "326430"
  },
  {
    "text": "So lectures 3 and 4\ndiscussed those assumptions and the evidence against\nthese assumptions in detail.",
    "start": "326430",
    "end": "335220"
  },
  {
    "start": "334000",
    "end": "334000"
  },
  {
    "text": "And after that, we discussed\nthe quasi-hyperbolic discounting model, which is a relatively\nsmall modification",
    "start": "335220",
    "end": "341340"
  },
  {
    "text": "of the exponential\ndiscounting model. Again, you know\nwhat is this model? How is it different from the\nexponential discounting model?",
    "start": "341340",
    "end": "348220"
  },
  {
    "text": "And of course, the\ndifference is that there's a present bias\nparameter of beta that",
    "start": "348220",
    "end": "353460"
  },
  {
    "text": "is added to this model, which\nmeasures short-run discounting,",
    "start": "353460",
    "end": "359940"
  },
  {
    "text": "as in like, how much weight\nyou put on the present, versus everything else\nthat's in the future. Now, what empirical evidence\ncan the quasi-exponential,",
    "start": "359940",
    "end": "370080"
  },
  {
    "text": "quasi-hyperbolic\nmodel explain better than the exponential discounting\nmodel, and why is that?",
    "start": "370080",
    "end": "375577"
  },
  {
    "text": "So you should be familiar\nwith, for example, things like preference\nreversals and then [INAUDIBLE] commitment. Why is that consistent with\nthe quasi-hyperbolic model?",
    "start": "375577",
    "end": "383040"
  },
  {
    "text": "And you know, why\nis it not consistent with the exponential model? Of course, that's\nwhat we discussed in the previous slide, is\nthe somewhat the assumptions",
    "start": "383040",
    "end": "389760"
  },
  {
    "text": "of the exponential discount\nmodel, where for example, one of the key assumptions are\nthat there are no preference",
    "start": "389760",
    "end": "395979"
  },
  {
    "text": "reversals. And we discussed that in detail. Then, of course you need\nto know in the course",
    "start": "395980",
    "end": "402770"
  },
  {
    "text": "of hyperbolic discounting model,\nwhat is this sophistication? What is naivete? And what is partial naivete?",
    "start": "402770",
    "end": "409610"
  },
  {
    "text": "So what does theta measure? What does theta hat measure? What is full sophistication,\nfull naivete, and partial naivete?",
    "start": "409610",
    "end": "416470"
  },
  {
    "text": "And answer questions\nsuch as like, does sophistication make\npeople always better off?",
    "start": "416470",
    "end": "421520"
  },
  {
    "text": "And why, or why not,\nif that's the case? Further, you should understand,\nwhat is demand for commitment?",
    "start": "421520",
    "end": "429289"
  },
  {
    "text": "Who demands commitment\nand who doesn't? Or like are fully\nsophisticated or fully naive people, or partial naive\npeople potentially demanding",
    "start": "429290",
    "end": "437610"
  },
  {
    "text": "commitment? What are the\nconditions under which somebody demands commitment?",
    "start": "437610",
    "end": "442790"
  },
  {
    "text": "And what kinds of people do\nnot, or do demand commitment?",
    "start": "442790",
    "end": "449000"
  },
  {
    "text": "And what kinds of people\nbenefit from doing so? And in particular, can\npeople be worse off",
    "start": "449000",
    "end": "454880"
  },
  {
    "text": "from being offered\na commitment device? And why is that, or why not?",
    "start": "454880",
    "end": "460650"
  },
  {
    "text": "Next, we discussed\nin quite a bit of detail empirical\napplications from a range of different settings.",
    "start": "460650",
    "end": "466570"
  },
  {
    "start": "461000",
    "end": "461000"
  },
  {
    "text": "This is lecture 5 and 6. So we want you to\nbe familiar with those empirical applications.",
    "start": "466570",
    "end": "475436"
  },
  {
    "text": "You should understand why the\nquasi-hyperbolic model can explain or cannot explain\nsome of the empirical evidence",
    "start": "475437",
    "end": "482453"
  },
  {
    "text": "better than the exponential\ndiscounting model.  And I think you know , kind\nof like why do we think",
    "start": "482453",
    "end": "489890"
  },
  {
    "text": "quasi-hyperbolic model is a good\nfit for some of the empirical examples that I have shown?",
    "start": "489890",
    "end": "497290"
  },
  {
    "text": "Then you need to be\nable to solve problems. These are similar problems to\nthe problems in the problem",
    "start": "497290",
    "end": "502800"
  },
  {
    "text": "sets that you have seen\nbefore, problem sets for people either like\nexponential discounters,",
    "start": "502800",
    "end": "508310"
  },
  {
    "text": "or like for beta delta\nequals, where beta equals 1,",
    "start": "508310",
    "end": "513799"
  },
  {
    "text": "and delta being like\neither 1, or 0.95, or close to 1, because\nhyperbolic discounters,",
    "start": "513799",
    "end": "519393"
  },
  {
    "text": "and again, fully naive, fully\nsophisticated, and partially naive agents. How does one solve\nsuch problems?",
    "start": "519394",
    "end": "525000"
  },
  {
    "text": "Of course, we had\nplenty of practice already in the psets\nin the term examples, also it's in the finals.",
    "start": "525000",
    "end": "531800"
  },
  {
    "text": "So you should use\nbackwards or forwards",
    "start": "531800",
    "end": "538490"
  },
  {
    "text": "induction or iteration,\ndepending on the kinks. I sort of discuss this in\nslide 62 of lectures 3 and 4,",
    "start": "538490",
    "end": "546560"
  },
  {
    "text": "and slide 37 of\nlectures 5 and 6. There's also a recitation\nthat covers that in detail.",
    "start": "546560",
    "end": "552320"
  },
  {
    "text": "So you should have plenty\nof practice of doing so. Now, let me now give\nyou some examples",
    "start": "552320",
    "end": "559630"
  },
  {
    "start": "558000",
    "end": "558000"
  },
  {
    "text": "of what are some examples\ntrue/false/uncertain questions, and how should you answer them?",
    "start": "559630",
    "end": "564790"
  },
  {
    "text": "So let me sort of just read\nthe statements for you, and you can think about\nthis for a second. And then we're going\nto give you the answer.",
    "start": "564790",
    "end": "571240"
  },
  {
    "text": "So consider individuals with\nbeta delta preferences-- this is quasi-hyperbolic\ndiscounters--",
    "start": "571240",
    "end": "577300"
  },
  {
    "text": "who only differ by\ntheir present bias-- had like beta equals\nbetween 0 and 1.",
    "start": "577300",
    "end": "586260"
  },
  {
    "text": "And suppose there's a commitment\nsavings device available. Their willingness to pay\nfor this commitment device",
    "start": "586260",
    "end": "591300"
  },
  {
    "text": "strictly decreases in beta. Now, is that a true\nor false statement?",
    "start": "591300",
    "end": "599530"
  },
  {
    "text": "The answer is this\nstatement is false. Now, why is that?",
    "start": "599530",
    "end": "605490"
  },
  {
    "text": "Well, there's, again, like\nif you just click false, that's not going to\ngive you full credit, even if, in fact, the\nstatement is false.",
    "start": "605490",
    "end": "613577"
  },
  {
    "text": "What you need to do is you\nneed to sort of provide some further explanation.",
    "start": "613577",
    "end": "619139"
  },
  {
    "text": "Ideally, you'll provide us\nlike a somewhat detailed explanation, so that\nyou know if it's false,",
    "start": "619140",
    "end": "626250"
  },
  {
    "text": "if you provide several\nexamples, that's should better amount than just one. In this case, why is it false?",
    "start": "626250",
    "end": "632639"
  },
  {
    "text": "Well, A, individuals\nmight be naive, right? So in particular, if\npeople are fully naive, they will not be\nwilling to pay anything",
    "start": "632640",
    "end": "640380"
  },
  {
    "text": "for commitment devices. So regardless to the\nbeta, willingness to pay will always be 0.",
    "start": "640380",
    "end": "646140"
  },
  {
    "text": "So it would surely\nnot decrease in beta. Second, the commitment\ndevice may just not",
    "start": "646140",
    "end": "652100"
  },
  {
    "text": "be effective at all. If the commitment\ndevice is useless, it doesn't matter what beta is,\nnobody will demand commitment",
    "start": "652100",
    "end": "658940"
  },
  {
    "text": "anyway. And finally, even if\nindividuals-- this is a little bit more\ntrickier explanation,",
    "start": "658940",
    "end": "664130"
  },
  {
    "text": "and I wouldn't\nnecessarily expect you to know that\nanswer-- but even if individuals are\nfully sophisticated",
    "start": "664130",
    "end": "670430"
  },
  {
    "text": "and devices effective, the\ncommitment device is effective, willingness to pay, it may not\nbe strictly decreasing in beta.",
    "start": "670430",
    "end": "678950"
  },
  {
    "text": "And here's sort of an example. Well, if beta equals\n0 or beta equals 1, then individuals would\nbe willing to pay 0",
    "start": "678950",
    "end": "686029"
  },
  {
    "text": "for the commitment\ndevice, right? Because if beta equals 0, they\ndon't care about the future. If beta equals 1,\nthey just don't",
    "start": "686030",
    "end": "691980"
  },
  {
    "text": "need any commitment devices. But in between, the\nwillingness to pay",
    "start": "691980",
    "end": "697100"
  },
  {
    "text": "might be positive for\nbetas between 0 and 1. That essentially means\nthat willingness to pay",
    "start": "697100",
    "end": "703730"
  },
  {
    "text": "would be an inverse U in beta. Again, that's a bit\nof a tricky answer. Like the third bullet point,\nwe wouldn't necessarily",
    "start": "703730",
    "end": "710750"
  },
  {
    "text": "expect you to know that answer. But you should be able to say or\nto answer reason one, or reason",
    "start": "710750",
    "end": "718580"
  },
  {
    "text": "two in this specific case. Second example statement--\nfully sophisticated",
    "start": "718580",
    "end": "725740"
  },
  {
    "text": "individuals can experience\nlarge welfare losses from their present bias. ",
    "start": "725740",
    "end": "733700"
  },
  {
    "text": "The answer is this is true. Why is that? I'll let you think\nabout this for a second. ",
    "start": "733700",
    "end": "749170"
  },
  {
    "text": "Well, the answer\nis that awareness of present bias, that\nis, like sophistication, does not remove present bias.",
    "start": "749170",
    "end": "756160"
  },
  {
    "text": "Even if people\nare sophisticated, the present bias is still there.",
    "start": "756160",
    "end": "761649"
  },
  {
    "text": "There might be some\ncommitment devices, some ways in which people are\nable to overcome the losses",
    "start": "761650",
    "end": "768850"
  },
  {
    "text": "associated with present bias. But in the absence of\ncommitment devices,",
    "start": "768850",
    "end": "774100"
  },
  {
    "text": "people may still make\nsuboptimal decisions. And some of these\ndecisions might, in fact, induce large welfare needs.",
    "start": "774100",
    "end": "780490"
  },
  {
    "text": "We discussed some\nexamples in class, sort of numerical\nexamples, where you could see that sophisticated\npeople might actually",
    "start": "780490",
    "end": "787450"
  },
  {
    "text": "be worse off than naive\npeople, and could in fact suffer quite a bit from or\nsimilar to the large welfare",
    "start": "787450",
    "end": "794209"
  },
  {
    "text": "losses. With the present\nbias, all of this is evaluated by the\nlong-run [INAUDIBLE] ideas",
    "start": "794210",
    "end": "799360"
  },
  {
    "text": "of like if somebody makes\nchoices for the future where",
    "start": "799360",
    "end": "804730"
  },
  {
    "text": "the beta is not\nrelevant, compared to that kind of\nwelfare criterion,",
    "start": "804730",
    "end": "810150"
  },
  {
    "text": "people might be a lot worse\noff due to their present bias. OK, here's example number three.",
    "start": "810150",
    "end": "816820"
  },
  {
    "text": "Present bias individuals\nalways have positive demand for commitment devices.",
    "start": "816820",
    "end": "822320"
  },
  {
    "text": "Again, the statement is false. Why is that? And we kind of\ndiscussed this already",
    "start": "822320",
    "end": "828200"
  },
  {
    "text": "in the previous questions. Now, let me be very explicit. There's sort of\nthree conditions that must be met for positive\ndemand for commitment.",
    "start": "828200",
    "end": "835470"
  },
  {
    "text": "I discussed this in class. We know that person\nmust be present biased, or have some form of some\nself-control problems.",
    "start": "835470",
    "end": "842533"
  },
  {
    "text": "Individuals must--\nthe person must be aware of the present bias,\nso they can't be fully naive. They could be partially naive,\nbut it can't be fully naive.",
    "start": "842533",
    "end": "850370"
  },
  {
    "text": "And the individual must\nperceive the commitment device as effective in helping overcome\nthe self-control problem.",
    "start": "850370",
    "end": "856293"
  },
  {
    "text": "That's to say, if somebody is\noffered a commitment device, and that commitment\ndevice is useless, well, there's not going to\nbe any demand for commitment,",
    "start": "856293",
    "end": "863569"
  },
  {
    "text": "particularly if the person\nperceives that the commitment device is useless.",
    "start": "863570",
    "end": "868886"
  },
  {
    "text": "Notice that that\nperson might actually perceive the commitment\ndevice to be effective, while in reality, it's not.",
    "start": "868887",
    "end": "873938"
  },
  {
    "text": "So they might have some\npositive demand for commitment, even if the commitment\ndevice is in reality useless, because their beliefs are\nwrong, because of essentially",
    "start": "873938",
    "end": "881360"
  },
  {
    "text": "some form of partial naivete. But it cannot be that the person\nperceives the commitment device",
    "start": "881360",
    "end": "887570"
  },
  {
    "text": "as not effective, because\nthen the person would just not demand it in the first place. Now, that makes now\nthe statement false.",
    "start": "887570",
    "end": "894920"
  },
  {
    "text": "When only the first condition\nof the three is met, as in like the person's\nonly present-biased,",
    "start": "894920",
    "end": "900050"
  },
  {
    "text": "then we cannot be sure that\nthere will be positive demand for commitment.",
    "start": "900050",
    "end": "906740"
  },
  {
    "text": "And so the statement,\nas had been said, is false, because we said\nsort of like always have",
    "start": "906740",
    "end": "913040"
  },
  {
    "text": "positive demand for commitment. If it were without\nthe always, then you could also answer uncertain,\nbecause then you would say,",
    "start": "913040",
    "end": "919589"
  },
  {
    "text": "well, it depends\non their naivete, or on the sophistication, or\nit depends on how effective",
    "start": "919590",
    "end": "926389"
  },
  {
    "text": "the commitment device is. But the way the statement is\nwritten, it says like, always. And so now, you\ncan easily come up",
    "start": "926390",
    "end": "932360"
  },
  {
    "text": "with some counterexamples that\nshow that the statement in fact is false. ",
    "start": "932360",
    "end": "939790"
  },
  {
    "start": "939000",
    "end": "939000"
  },
  {
    "text": "The second topic\nthat we discussed after time preferences\nwas risk preferences, in particular expected utility.",
    "start": "939790",
    "end": "947180"
  },
  {
    "text": "So here, you know,\nyou need to have a clear understanding of what\nis the expected utility model?",
    "start": "947180",
    "end": "953520"
  },
  {
    "text": "What is risk aversion? Why are people risk averse? How is risk aversion\nspecifically modeled",
    "start": "953520",
    "end": "958980"
  },
  {
    "text": "in the expected utility model? What is the expected\nmonetary value?",
    "start": "958980",
    "end": "964839"
  },
  {
    "text": "And also things like\nwhat is concavity? What does concavity\nhave to do-- what is the expected utility versus\nthe expected monetary value?",
    "start": "964840",
    "end": "973170"
  },
  {
    "text": "And what does the concavity\nimply for risk aversion in the expected utility model?",
    "start": "973170",
    "end": "980509"
  },
  {
    "text": "Then next, how can we\nmeasure risk aversion within the expected\nutility model? In particular, we\ndiscussed three types",
    "start": "980510",
    "end": "987110"
  },
  {
    "text": "of ways of measuring\nrisk aversion. We discuss certainty\nequivalents. We discussed choices\nfrom gambles.",
    "start": "987110",
    "end": "992839"
  },
  {
    "text": "We also discussed\ninsurance choices. This is the Sydnor paper.",
    "start": "992840",
    "end": "998250"
  },
  {
    "text": "And then, we discussed what is\nproblematic about the estimates of risk aversion in the\nexpected utility model.",
    "start": "998250",
    "end": "1004760"
  },
  {
    "text": "In particular, we\ndiscussed evidence that found that there tends to\nbe substantial small-scale risk",
    "start": "1004760",
    "end": "1010360"
  },
  {
    "text": "aversion, so when you\ngive people small gambles, they tend to be\nquite risk averse or they tend to have a\nvery quite high gamma.",
    "start": "1010360",
    "end": "1018680"
  },
  {
    "text": "But we know also from large\nscale choices that the risk aversion cannot be actually\nthat high when people make these",
    "start": "1018680",
    "end": "1026569"
  },
  {
    "text": "choices. People leave the house\nevery day and engage in quite a few risks.",
    "start": "1026569",
    "end": "1031760"
  },
  {
    "text": "In the long run, they\nhold stocks and so on. This must mean\nthat their long run",
    "start": "1031760",
    "end": "1037430"
  },
  {
    "text": "using sort of long-run choices,\nthat implies essentially a relatively low gamma. But since the expected utility\nmodel only has like one",
    "start": "1037430",
    "end": "1045140"
  },
  {
    "text": "parameter, it cannot explain\nboth of those features and sort of ignores this trouble.",
    "start": "1045140",
    "end": "1050870"
  },
  {
    "text": "So essentially, if you try\nto match a small-scale risk aversion, then you need to have\na very large gamma, high gamma.",
    "start": "1050870",
    "end": "1058650"
  },
  {
    "text": "If you try to match\nlarge-scale risk aversion, you need to have a low gamma. And that sort of brings\ntrouble, because you can't just",
    "start": "1058650",
    "end": "1065030"
  },
  {
    "text": "explain both of those things. And sort of Matthew\nRabin in Rabin & Thaler, as well as recitation 4 discuss\nthis conundrum and this issue",
    "start": "1065030",
    "end": "1073940"
  },
  {
    "text": "and in quite a bit of detail. Next, we discussed Kahneman and\nTversky's 1979 prospect theory.",
    "start": "1073940",
    "end": "1082309"
  },
  {
    "start": "1078000",
    "end": "1078000"
  },
  {
    "text": "This is a seminal paper. And if you'd remember just a\nfew papers from this class,",
    "start": "1082310",
    "end": "1088100"
  },
  {
    "text": "this is one of the papers that\nyou should really know about. So what evidence in\nKahneman and Tversky",
    "start": "1088100",
    "end": "1093450"
  },
  {
    "text": "is inconsistent with\nexpected utility? Well, in particular, sort\nof several things in there, but you discuss mostly\none feature, which",
    "start": "1093450",
    "end": "1099910"
  },
  {
    "text": "is risk aversion\nin the gain domain, and risk lovingness\nin the loss domain.",
    "start": "1099910",
    "end": "1107480"
  },
  {
    "text": "And so, now, what are\nthe most important points from Kahneman and\nTversky's prospect theory-- this is sort of the\nproposed alternative",
    "start": "1107480",
    "end": "1113240"
  },
  {
    "text": "to expected utilities. This is on slide 3\nof 51 of lecture 9,",
    "start": "1113240",
    "end": "1119203"
  },
  {
    "text": "where there's sort of three\nfutures discussed there. One is like changes rather\nthan levels are the arguments",
    "start": "1119203",
    "end": "1125000"
  },
  {
    "text": "of the utility function. Then there's loss aversion. So there's a kink of the utility\nfunction around the reference",
    "start": "1125000",
    "end": "1132559"
  },
  {
    "text": "point. And there's diminishing\nsensitivity, meaning the utility function\nis concave in the gain domain",
    "start": "1132560",
    "end": "1141890"
  },
  {
    "text": "or [INAUDIBLE] above the\nreference point and is convex. And the last domain would be\nbelow the reference point.",
    "start": "1141890",
    "end": "1147860"
  },
  {
    "text": " OK, so now, what does sort\nof this proposed alternative",
    "start": "1147860",
    "end": "1154830"
  },
  {
    "text": "utility or value\nfunction look like? How does it incorporate\nthe three features again? We sort of discussed this\nand this utility function",
    "start": "1154830",
    "end": "1162070"
  },
  {
    "text": "in lecture 9 that talks\nabout this in detail. Or the lecture talks about this\nutility function in detail.",
    "start": "1162070",
    "end": "1169273"
  },
  {
    "text": "One key question here, that\nis, how is the reference point determined? What are some candidate\nreference points?",
    "start": "1169273",
    "end": "1174490"
  },
  {
    "text": "So one candidate would\nbe the status quo. Another reference point\ncandidate would be expectation.",
    "start": "1174490",
    "end": "1179658"
  },
  {
    "text": "But there could be\nalso other things, such as goal and aspirations. Recitation 5 discuss\nthis a little bit,",
    "start": "1179658",
    "end": "1186120"
  },
  {
    "text": "not in too much detail. Then, we discussed empirical\nevidence, in particular,",
    "start": "1186120",
    "end": "1192950"
  },
  {
    "text": "what empirical evidence of\nloss aversion do we have? We talked about\nsmall-scale gambles. We talked about the endowment\neffect, in particular.",
    "start": "1192950",
    "end": "1200390"
  },
  {
    "text": "And then we discussed some\napplications in lecture 9. So what are these applications?",
    "start": "1200390",
    "end": "1206400"
  },
  {
    "text": "We discuss labor supply,\nthe housing market, stocks, marathon running, and golf. So you should be familiar with\nthese empirical applications",
    "start": "1206400",
    "end": "1215090"
  },
  {
    "text": "from lecture 9. You should in\nparticular understand why reference-dependent\npreferences can explain",
    "start": "1215090",
    "end": "1221630"
  },
  {
    "text": "some of the empirical\nevidence that is showed better than the\nexpected utility models.",
    "start": "1221630",
    "end": "1226680"
  },
  {
    "text": "You should understand,\nis some of the evidence that we see consistent with\nthe expected utility model?",
    "start": "1226680",
    "end": "1231770"
  },
  {
    "text": "And if not, why not? And why is the\nreference-dependent model-- in particular, which feature of\nthe reference-dependent model",
    "start": "1231770",
    "end": "1238700"
  },
  {
    "text": "can explain the loss. What are the features again? Changes rather than levels-- some reference point,\nreference-dependence, the loss",
    "start": "1238700",
    "end": "1246200"
  },
  {
    "text": "aversion and\ndiminished sensitivity, so which feature is\nactually important? Explaining things, we focused\nmostly on loss aversion.",
    "start": "1246200",
    "end": "1254450"
  },
  {
    "start": "1249000",
    "end": "1249000"
  },
  {
    "text": "What is not relevant is the\ndeal or no deal evidence and the paper by Pierce et al.",
    "start": "1254450",
    "end": "1260027"
  },
  {
    "text": "There's a couple of slides\nat the end of lecture 9 that I didn't really cover\nor didn't cover at all. So we're not going to ask\nany questions about that.",
    "start": "1260027",
    "end": "1268915"
  },
  {
    "text": "So now, how do\nyou solve problems with reference-dependent\npreferences? You can see problem set\n3, question number 1",
    "start": "1268915",
    "end": "1274940"
  },
  {
    "text": "had some questions about this. And again, there's additional\npsets and exam questions that you could practice with.",
    "start": "1274940",
    "end": "1280490"
  },
  {
    "text": "So there are quite a few of\nthose kinds of questions. Now, here is sort of some\nexample of a multiple choice",
    "start": "1280490",
    "end": "1287320"
  },
  {
    "start": "1285000",
    "end": "1285000"
  },
  {
    "text": "question, which is-- so Maddie wrote this question,\nso Maddie, in fact, appears. And the question is,\nMaddie is writing",
    "start": "1287320",
    "end": "1294779"
  },
  {
    "text": "a problem set for 14.13. She gets utility u of q from the\nnumber of questions she writes.",
    "start": "1294780",
    "end": "1300440"
  },
  {
    "text": "She has reference-dependent\npreferences around the goal of writing\n10 questions, with 10",
    "start": "1300440",
    "end": "1305953"
  },
  {
    "text": "as her reference points. If you normalize the utility\nof 10 questions to 0,",
    "start": "1305953",
    "end": "1311500"
  },
  {
    "text": "which of the following would be\nconsistent with loss aversion? I'll let you have\na look at this.",
    "start": "1311500",
    "end": "1316720"
  },
  {
    "text": "So there's option A, u of\nof 8 equals minus 2, u of 12 equals 1.",
    "start": "1316720",
    "end": "1322660"
  },
  {
    "text": "And number B, option B yields\n8 equals minus 2, u of 12 equals 2.",
    "start": "1322660",
    "end": "1327700"
  },
  {
    "text": "And then C is, option C is u of\n8 equals minus 1, and u of 12",
    "start": "1327700",
    "end": "1333820"
  },
  {
    "text": "equals 2. So which of those answers is\nconsistent with loss aversion?",
    "start": "1333820",
    "end": "1340810"
  },
  {
    "text": "The answer is option\nA. Now, why is that? Well, loss aversion sort of\nimplies that losses hurt more",
    "start": "1340810",
    "end": "1348610"
  },
  {
    "text": "than gains help. So with preferences\nas in A, Maddie would have the utility\ncost of 2 from falling",
    "start": "1348610",
    "end": "1355810"
  },
  {
    "text": "short of her goal\nof two questions, but only a gain of 1 util\nfrom exceeding her goal by two",
    "start": "1355810",
    "end": "1362200"
  },
  {
    "text": "questions, right? So the goal of, the\ngame of exceeding,",
    "start": "1362200",
    "end": "1369050"
  },
  {
    "text": "of being by two questions above,\nso being two questions above",
    "start": "1369050",
    "end": "1374980"
  },
  {
    "text": "gives her some gain of 1 util. But the utility costs of\nfalling short with two is twice as large,\nwhich just tends",
    "start": "1374980",
    "end": "1380828"
  },
  {
    "text": "to be kind of like\nthe evidence that you would see in loss aversion. And the other two examples\ndon't have that feature.",
    "start": "1380828",
    "end": "1387450"
  },
  {
    "text": "So really only answer\nnumber A is correct. ",
    "start": "1387450",
    "end": "1395200"
  },
  {
    "text": "Second question. Maddie is walking home and\npasses a bakery unexpectedly. She decides to buy a pastry.",
    "start": "1395200",
    "end": "1401140"
  },
  {
    "text": "For example, she\nlooks at the pastry, and it looks really nice. Prior to purchasing the\npastry, her maximum willingness",
    "start": "1401140",
    "end": "1407740"
  },
  {
    "text": "to pay for the pastry was P0. Then she runs into Alan-- this\nis our previous, excellent TA--",
    "start": "1407740",
    "end": "1415030"
  },
  {
    "text": "who asks to buy the\npastry from her. She offers him the lowest price\nshe is willing to accept, P1.",
    "start": "1415030",
    "end": "1421480"
  },
  {
    "text": "Which of the following\ncomparisons between P0 and P1 is consistent with\nan endowment effect,",
    "start": "1421480",
    "end": "1426910"
  },
  {
    "text": "P0 larger than P1, P0 equals\nP1, or P0 smaller than P1?",
    "start": "1426910",
    "end": "1432790"
  },
  {
    "text": " The answer is answer\nnumber C. Why is that?",
    "start": "1432790",
    "end": "1441320"
  },
  {
    "text": "Well, the endowment effect\nsays that people are-- when their willingness to\npay, that is in this case P0,",
    "start": "1441320",
    "end": "1450590"
  },
  {
    "text": "is smaller than their\nwillingness to accept, when they accept. That is to say, being endowed\nwith an item in this case,",
    "start": "1450590",
    "end": "1458450"
  },
  {
    "text": "like a pastry, increases\none's willingness to pay. That is to say, if somebody\nasks you to sell something",
    "start": "1458450",
    "end": "1465380"
  },
  {
    "text": "that you own, you\nask for more money than you're willing to\npay in the first place",
    "start": "1465380",
    "end": "1470690"
  },
  {
    "text": "when you don't own the item. And so the endowment effect\nwill then predict that,",
    "start": "1470690",
    "end": "1476809"
  },
  {
    "text": "or the endowment effect\nentails that now P1 is larger",
    "start": "1476810",
    "end": "1482150"
  },
  {
    "text": "than P0, which is answer\nnumber C. So Maddie values the pastry more after\nshe has bought it,",
    "start": "1482150",
    "end": "1490010"
  },
  {
    "text": "compared to like\nprior to buying it.  The third broad set of\npreferences to be discussed",
    "start": "1490010",
    "end": "1497429"
  },
  {
    "text": "were social preferences. We didn't quite\nfinish with this, so we're not going to cover\neverything, in particular,",
    "start": "1497430",
    "end": "1502470"
  },
  {
    "text": "not lecture 13. And the estimation part\nof social preferences,",
    "start": "1502470",
    "end": "1508340"
  },
  {
    "text": "which will apart from choices,\nwhich will be at pset 4. You should understand what\nsocial preferences are.",
    "start": "1508340",
    "end": "1515817"
  },
  {
    "text": "You should also\nunderstand how can you measure social preferences? In lab games, we\ndiscussed at length",
    "start": "1515817",
    "end": "1521940"
  },
  {
    "text": "the dictator game, the ultimatum\ngame, and the trust game. You should also be broadly\nfamiliar, not in detail,",
    "start": "1521940",
    "end": "1527910"
  },
  {
    "text": "but broadly familiar\nof what evidence do we typically find in\ndictator and ultimatum games?",
    "start": "1527910",
    "end": "1533740"
  },
  {
    "text": "For instance, in\ndictator games, people tend to give something like\n20% to 30% of their share.",
    "start": "1533740",
    "end": "1540020"
  },
  {
    "text": "People tend to be quite\nnice in those games. Now, then we discussed then\nlike given that evidence,",
    "start": "1540020",
    "end": "1546304"
  },
  {
    "text": "so given that people look quite\nnice in these types of games, there's also some other\nevidence people give",
    "start": "1546305",
    "end": "1553010"
  },
  {
    "text": "to charity or things like that. Do we think that is\nevidence of people being generally nice to others\nbecause of poor altruism?",
    "start": "1553010",
    "end": "1562409"
  },
  {
    "text": "Or if not, why not? We discussed sort of three\nsets of evidence in particular.",
    "start": "1562410",
    "end": "1568520"
  },
  {
    "text": "We discussed the costly exit or\nexit options in dictator games. So people essentially won't\nbe able to leave the dictator.",
    "start": "1568520",
    "end": "1575760"
  },
  {
    "text": "They rather sort\nof leave and give, and sort of keep the money. Or they're willing to pay\nsome small amount of money",
    "start": "1575760",
    "end": "1582690"
  },
  {
    "text": "to leave the\ndictator game and not having to face\nsome other person, but it then feel compelled\nto give to others.",
    "start": "1582690",
    "end": "1589320"
  },
  {
    "text": "There was the option of\nhiding behind the computer. If a computer gives\nyou the option",
    "start": "1589320",
    "end": "1595620"
  },
  {
    "text": "to hide behind the computer\nto be mean to others, you might take advantage of\nthat and actually be meaner",
    "start": "1595620",
    "end": "1601559"
  },
  {
    "text": "than you would be otherwise. So altruism, or people's giving\ntends to go down quite a bit when they're able to\nhide behind the computer.",
    "start": "1601560",
    "end": "1609960"
  },
  {
    "text": "So both of those types\nof pieces of evidence are evidence of social image\nbeing important in giving.",
    "start": "1609960",
    "end": "1616670"
  },
  {
    "text": "People care a lot about\nwhat others think, in particular what\nothers think about them,",
    "start": "1616670",
    "end": "1621710"
  },
  {
    "text": "and they don't want\nto upset others. And so if they're able to\navoid those kind of situations,",
    "start": "1621710",
    "end": "1629419"
  },
  {
    "text": "they might be able to-- they might want to do that,\nwhich would suggest that it's not really that they want\nothers to do well in the sense",
    "start": "1629420",
    "end": "1636650"
  },
  {
    "text": "that they really want others\nto have money or more money than before, but rather it's\nbecause of social pressure",
    "start": "1636650",
    "end": "1643500"
  },
  {
    "text": "or social image concerns,\npeople might give in dictator or ultimatum games.",
    "start": "1643500",
    "end": "1649580"
  },
  {
    "text": "Moreover, there's some\nevidence of self-image about people caring about what\nthey think about themselves.",
    "start": "1649580",
    "end": "1657000"
  },
  {
    "text": "They want to think of themselves\nas being a good person. And so the evidence of\nthe moral wiggle room",
    "start": "1657000",
    "end": "1663260"
  },
  {
    "text": "seems to suggest that these\nconcerns are quite important.",
    "start": "1663260",
    "end": "1668270"
  },
  {
    "text": "In particular, people are\nengaging in some behavior where they delude themselves\nthat they are in fact nice,",
    "start": "1668270",
    "end": "1677180"
  },
  {
    "text": "when in reality, they're not. So that's discussed in\ndetail in the lecture.",
    "start": "1677180",
    "end": "1683809"
  },
  {
    "text": "Again, we will not\nask, and so you should be familiar with\nthis type of evidence. And you should be familiar\nwhy that sort of tells us",
    "start": "1683810",
    "end": "1690380"
  },
  {
    "text": "that people are perhaps not as\nnice as you might have thought. They are just coming from like\ndictator or ultimatum games,",
    "start": "1690380",
    "end": "1697010"
  },
  {
    "text": "or from like donations. We will not ask you\nabout models that estimate social preferences.",
    "start": "1697010",
    "end": "1703010"
  },
  {
    "text": "That will be in problem set\n4, so don't worry about that. Sort of the stuff on [INAUDIBLE]\nand Rabin that's there,",
    "start": "1703010",
    "end": "1709529"
  },
  {
    "text": "we will not ask you about that. OK, so then here's\nanother example",
    "start": "1709530",
    "end": "1715909"
  },
  {
    "start": "1713000",
    "end": "1713000"
  },
  {
    "text": "of a true/false/uncertain\nquestion. Statement, if a person\ngives 0 in a dictator game, this is evidence that\nthis person is selfish.",
    "start": "1715910",
    "end": "1724429"
  },
  {
    "text": "Now, the answer is false. I think if you\nanswer it uncertain, that would also be fine.",
    "start": "1724430",
    "end": "1730309"
  },
  {
    "text": "Why is that? Well, the person might\ngive 0 to the other person in the dictator game and then\ndonate the money to someone",
    "start": "1730310",
    "end": "1738745"
  },
  {
    "text": "in greater need, right? And then that person is\nin fact really quite nice. ",
    "start": "1738745",
    "end": "1744590"
  },
  {
    "text": "Second, the person\nmight be very poor relative to the other\nperson in the game. So her marginal utility\nis just very high.",
    "start": "1744590",
    "end": "1750649"
  },
  {
    "text": "So now, even if you\nhave like equal weights to your own utility and\nthe other person's utility,",
    "start": "1750650",
    "end": "1757460"
  },
  {
    "text": "since the marginal utility of\ngiving $10 to yourself compared to the other person is way\nhigher than the other person's",
    "start": "1757460",
    "end": "1763820"
  },
  {
    "text": "marginal utility, you would just\ngive everything to yourself. And that doesn't mean you\ndon't care about others.",
    "start": "1763820",
    "end": "1770770"
  },
  {
    "text": "It just means\nlike, in fact, even if you were sort of\nlike a social climber,",
    "start": "1770770",
    "end": "1776655"
  },
  {
    "text": "you would give it\nto that person, because that person\nwas like a huge meany, or the rich person just might\nnot really need that money.",
    "start": "1776655",
    "end": "1782682"
  },
  {
    "text": "Looking at this more\nclosely, actually, I think uncertain would be a\nbetter answer here, and not false.",
    "start": "1782682",
    "end": "1787810"
  },
  {
    "text": "I just wrote this\nquestion fairly quickly. So if the question says--",
    "start": "1787810",
    "end": "1793430"
  },
  {
    "text": "if the question\ninstead were to say, this is conclusive evidence\nthat this person is selfish,",
    "start": "1793430",
    "end": "1799030"
  },
  {
    "text": "then it would be false. Or this would be,\nthis is clearly evidence where\nthis person must be",
    "start": "1799030",
    "end": "1804760"
  },
  {
    "text": "selfish, that would be false. The way it's written right now,\nit's rather sort of uncertain,",
    "start": "1804760",
    "end": "1810670"
  },
  {
    "text": "because we just\ndon't quite know. It could be that the\nperson is really selfish.",
    "start": "1810670",
    "end": "1816520"
  },
  {
    "text": "Or it could be that the person-- it could be this evidence\nthat the person is selfish.",
    "start": "1816520",
    "end": "1821769"
  },
  {
    "text": "But it could be the other two\nreasons that I just mentioned. OK, so now, finally, I'm going\nto give you a long question,",
    "start": "1821770",
    "end": "1830640"
  },
  {
    "start": "1827000",
    "end": "1827000"
  },
  {
    "text": "or an example of\na long question. And this is the question\nof laptop policies.",
    "start": "1830640",
    "end": "1836890"
  },
  {
    "text": "We talked about a little\nbit earlier in class, in fact in the first lecture.",
    "start": "1836890",
    "end": "1842200"
  },
  {
    "text": "And we had the first\nproblem set about this. And this is sort of like\nan algebraic version of that kind of question.",
    "start": "1842200",
    "end": "1849020"
  },
  {
    "text": "So assume the 14.13\nstudents are present biased with beta small\nthan 1 and delta equals 0.",
    "start": "1849020",
    "end": "1857020"
  },
  {
    "text": "All students have\nthe same beta smaller than 1 and delta equals 0. But they differ in\nthe value they derive",
    "start": "1857020",
    "end": "1864580"
  },
  {
    "text": "from using laptops in class. L is constant for each\nstudent from class to class,",
    "start": "1864580",
    "end": "1871050"
  },
  {
    "text": "but uniformly distributed\nacross students on the interval between 0 and 1.",
    "start": "1871050",
    "end": "1877260"
  },
  {
    "text": "So some people have\nlike a huge value of using the laptop in class.",
    "start": "1877260",
    "end": "1885255"
  },
  {
    "text": "And others do not. Each lecture generates\nno immediate utility.",
    "start": "1885255",
    "end": "1892100"
  },
  {
    "text": "So it's neither fun nor\nlike annoying or the like. But it does give a benefit,\na future benefit of V.",
    "start": "1892100",
    "end": "1900730"
  },
  {
    "text": "So like you might\nlearn something, or there's some things that\nmight be valuable to you in the future.",
    "start": "1900730",
    "end": "1906280"
  },
  {
    "text": "Using a laptop reduces\nthe long-run benefit by D. This might be like\ndistractions, in particular.",
    "start": "1906280",
    "end": "1913730"
  },
  {
    "text": "So you might be\ndistracted during class when you use a laptop. So the future benefits\nare diminished by that.",
    "start": "1913730",
    "end": "1921320"
  },
  {
    "text": "Maybe he had said something\nreally insightful, you didn't pay attention,\nand so now, the benefits",
    "start": "1921320",
    "end": "1927400"
  },
  {
    "text": "is B minus D if\nyou use a laptop. Both B and D are the\nsame for all students.",
    "start": "1927400",
    "end": "1934340"
  },
  {
    "text": "So there's no variation\nacross students there. The only variation's coming\nfrom some students who really,",
    "start": "1934340",
    "end": "1941120"
  },
  {
    "text": "really like using laptops\nfor various reasons, perhaps because they like to\nsurf the internet.",
    "start": "1941120",
    "end": "1947559"
  },
  {
    "text": "Perhaps they're really\nin need of using laptops because that allows them\nto take proper notes.",
    "start": "1947560",
    "end": "1955740"
  },
  {
    "text": "So in summary, a student\nuses a laptop in class-- sorry, a student that\nuses the laptop in class",
    "start": "1955740",
    "end": "1962809"
  },
  {
    "text": "gets immediate utility L and\nfuture, undiscounted utility of B minus D. And a student\nwho does not use a laptop",
    "start": "1962810",
    "end": "1970340"
  },
  {
    "text": "gets immediate utility of 0 and\nfuture discounted utility of V.",
    "start": "1970340",
    "end": "1975390"
  },
  {
    "text": "So and now the social\nplanner is not present biased and seeks to maximize the\nutility of 14.13 students",
    "start": "1975390",
    "end": "1983100"
  },
  {
    "text": "from his perspective, OK? ",
    "start": "1983100",
    "end": "1988620"
  },
  {
    "start": "1988000",
    "end": "1988000"
  },
  {
    "text": "First question. Show that students are just\nindifferent between using",
    "start": "1988620",
    "end": "1994340"
  },
  {
    "text": "and not using a laptop\nin the current class if L equals beat\ntimes D. Explain",
    "start": "1994340",
    "end": "2001960"
  },
  {
    "text": "why students with\nlower values of L-- so that's like L being\nlower than beta D--",
    "start": "2001960",
    "end": "2007150"
  },
  {
    "text": "don't use laptops in\nclass, but students with higher values of L-- so L exceeds beta D--",
    "start": "2007150",
    "end": "2012289"
  },
  {
    "text": "do use laptops in class. OK, so now what\nwe're going to do",
    "start": "2012290",
    "end": "2017309"
  },
  {
    "start": "2016000",
    "end": "2016000"
  },
  {
    "text": "is we're going to write down the\nutilities from the two choices. That's essentially already\ngiven in the explanation,",
    "start": "2017310",
    "end": "2024660"
  },
  {
    "text": "except for that we need to be\ncareful of where the beta comes in, right? So if students use\na laptop in class,",
    "start": "2024660",
    "end": "2032130"
  },
  {
    "text": "they get the immediate benefit\nof L. And then in the future, they get what's discounted by\nbeta, which is beta times B",
    "start": "2032130",
    "end": "2038360"
  },
  {
    "text": "minus D, right, because\nboth B and D are very far in the future. These are the benefits, or the\ndiminished benefits, B minus D,",
    "start": "2038360",
    "end": "2046620"
  },
  {
    "text": "that they get in the future. L is in the present, so\nthere's no beta here.",
    "start": "2046620",
    "end": "2051669"
  },
  {
    "text": "Instead, if someone uses no\nlaptop, the students get 0. So there's no laptop\nbenefits in the present.",
    "start": "2051670",
    "end": "2057760"
  },
  {
    "text": "And the benefits in\nthe future, the value of the lecture the\nfuture is undiminished,",
    "start": "2057760",
    "end": "2064359"
  },
  {
    "text": "which means essentially,\nit's just V. So the person just gets\n0 plus beta times V.",
    "start": "2064360",
    "end": "2072570"
  },
  {
    "text": "Now, students who are\nindifferent, by definition, have the same utility of using\nlaptops and using no laptop.",
    "start": "2072570",
    "end": "2080669"
  },
  {
    "text": "So we can essentially just\nequate those two things. Notice that like the beta\ntimes B is always there.",
    "start": "2080670",
    "end": "2088020"
  },
  {
    "text": "So it sort of\nessentially just cancels. And then what we get is the\nperson that's indifferent,",
    "start": "2088020",
    "end": "2093388"
  },
  {
    "text": "for that person, L\nequals beta times D. Now, students that\nchoose not to use laptops",
    "start": "2093389",
    "end": "2102010"
  },
  {
    "text": "will have low valuations\nL of using laptops, while students that\nchoose to use the laptops",
    "start": "2102010",
    "end": "2107980"
  },
  {
    "text": "have high L, right? If L is very large, then\nit exceeds beta times D.",
    "start": "2107980",
    "end": "2113110"
  },
  {
    "text": "If L is very small,\nthen L does not exceed, is smaller than beta times D.",
    "start": "2113110",
    "end": "2118660"
  },
  {
    "text": "So given the\nindifference condition, we have essentially, as I just\nsaid, students that do not",
    "start": "2118660",
    "end": "2124780"
  },
  {
    "text": "use the laptop, L is smaller\nthan beta times D. And students that use the laptop, for them,\nL is larger than beta times D.",
    "start": "2124780",
    "end": "2135570"
  },
  {
    "text": "OK. OK, now question number two. Now consider the policy that\nallows students to use laptops",
    "start": "2135570",
    "end": "2142640"
  },
  {
    "start": "2137000",
    "end": "2137000"
  },
  {
    "text": "only if they sign up in advance\nto sit in a laptop section. This is a little bit different\nthan we had in class,",
    "start": "2142640",
    "end": "2148790"
  },
  {
    "text": "but it's a version, or\nsomething that I also considered, in fact, in\nprevious years that that was what was used.",
    "start": "2148790",
    "end": "2154320"
  },
  {
    "text": "Now, the question here is, why\nis L larger or equal than D, not L is larger\nequal than beta D,",
    "start": "2154320",
    "end": "2161500"
  },
  {
    "text": "the threshold for opting\nin to the laptop section? OK? So now this is a\nchoice for people",
    "start": "2161500",
    "end": "2167980"
  },
  {
    "text": "to choose not for\nthe present, when they come to class, whether they\nwant to use a laptop right now.",
    "start": "2167980",
    "end": "2174130"
  },
  {
    "text": "But instead, they\nsign up in advance to sit in a laptop section\nfor the rest of the semester. So essentially, people\nare in the present,",
    "start": "2174130",
    "end": "2180490"
  },
  {
    "text": "and they choose for the future\nwhether they can use laptops in class.",
    "start": "2180490",
    "end": "2186880"
  },
  {
    "text": "Now, the utility\nis now different. And the key difference is that\nthe laptop benefits are now",
    "start": "2186880",
    "end": "2193030"
  },
  {
    "start": "2188000",
    "end": "2188000"
  },
  {
    "text": "in the future, right? So the utility of using a laptop\nnow again is 0 in the present.",
    "start": "2193030",
    "end": "2198760"
  },
  {
    "text": "And this is-- again,\nwe make choices in the present for the future. There's going to be no\nutility in the present. There's no lecture right now,\nno laptop benefits and the like.",
    "start": "2198760",
    "end": "2207849"
  },
  {
    "text": "And in the future, everything\nis discounted by beta now, because the person is\npresent biased potentially.",
    "start": "2207850",
    "end": "2215530"
  },
  {
    "text": "So it's beta times\nL plus B minus D. The utility of not using\na laptop is just 0 again.",
    "start": "2215530",
    "end": "2222780"
  },
  {
    "text": "Like in the present,\nnothing happens. And then in the future,\nthe benefits, as before, are beta times D. So the\nonly thing that you prepare",
    "start": "2222780",
    "end": "2230970"
  },
  {
    "text": "is choice, or these two\noptions, the previous version, is the L now is\ndiscounted by beta.",
    "start": "2230970",
    "end": "2237420"
  },
  {
    "text": "But before, it was not. Let me just go back here. So here, you see the\nL was like sort of--",
    "start": "2237420",
    "end": "2243840"
  },
  {
    "text": "here, you see the L\nnot discounted by beta. This is when people make\nchoices for the present.",
    "start": "2243840",
    "end": "2250490"
  },
  {
    "text": "Instead, here now, the\nL is discounted by beta, because that choice is-- the laptop benefits\nare in the future.",
    "start": "2250490",
    "end": "2258662"
  },
  {
    "text": "Now, we can do the\nsame thing as before. Threshold for opting\nin is defined as like-- or you can say that's\nessentially the indifference",
    "start": "2258662",
    "end": "2265170"
  },
  {
    "text": "conditions. You can just equalize the two,\nthe utility of using the laptop",
    "start": "2265170",
    "end": "2270270"
  },
  {
    "text": "or not using the laptop. And what you now get is that if\nL is larger than D, or larger equals than D, then the\nperson uses the laptop.",
    "start": "2270270",
    "end": "2277870"
  },
  {
    "text": "And otherwise, they do not.",
    "start": "2277870",
    "end": "2283690"
  },
  {
    "text": "Now, why does the threshold\nnow change from beta D to-- sorry, from beta times D to D?",
    "start": "2283690",
    "end": "2288880"
  },
  {
    "text": "Well, because when laptop use\ncan only happen in the future, all benefits and costs are\ndiscounted at the same rate,",
    "start": "2288880",
    "end": "2296500"
  },
  {
    "text": "and that that rate is beta. ",
    "start": "2296500",
    "end": "2302680"
  },
  {
    "text": "OK, question number three. Assume there's no\nlaptop policy at all.",
    "start": "2302680",
    "end": "2308910"
  },
  {
    "start": "2303000",
    "end": "2303000"
  },
  {
    "text": "Show that if beta times\nD is smaller than L and smaller than D,\nthe student engages",
    "start": "2308910",
    "end": "2315180"
  },
  {
    "text": "in preference reversals. She prefers not to use the\nlaptop in future classes",
    "start": "2315180",
    "end": "2320890"
  },
  {
    "text": "but changes her mind while\nshe's actually sitting in those future classes. ",
    "start": "2320890",
    "end": "2327320"
  },
  {
    "text": "That's sort of essentially\nthe typical behavior of present bias. People that, when\nthey're present biased,",
    "start": "2327320",
    "end": "2333000"
  },
  {
    "text": "for at least some parameter\nof constellations, people engage in present bias. So let's do the math and\nsee what comes out here.",
    "start": "2333000",
    "end": "2340980"
  },
  {
    "text": "So when thinking about\nthe future laptop use, this student's problem is\nidentical to the problem",
    "start": "2340980",
    "end": "2346430"
  },
  {
    "text": "in part B, sorry, in part 2. Why is that? Well, because she\ndiscounts time,",
    "start": "2346430",
    "end": "2355170"
  },
  {
    "text": "both one and two periods\nin advance, by beta. Essentially, everything\nis in the future, so you just discount\neverything by beta.",
    "start": "2355170",
    "end": "2361970"
  },
  {
    "text": "That's exactly kind of the\nchoice that we just had. So when thinking\nabout future class,",
    "start": "2361970",
    "end": "2366990"
  },
  {
    "text": "where thinking about opting\nin into a laptop section, the person makes a\nchoice for the future.",
    "start": "2366990",
    "end": "2373360"
  },
  {
    "text": "So here, when she thinks about\nany future choices, what really",
    "start": "2373360",
    "end": "2378660"
  },
  {
    "text": "matters is essentially the value\nof the laptop is in the future, I mean back in like part\n2 that we just solved.",
    "start": "2378660",
    "end": "2387660"
  },
  {
    "start": "2379000",
    "end": "2379000"
  },
  {
    "text": "Now, we know from part 2 that\nif L equals smaller than D, then she would like to\nnot use the laptop, right?",
    "start": "2387660",
    "end": "2394099"
  },
  {
    "text": "So we just solve for\nthat in part number 2.",
    "start": "2394100",
    "end": "2399240"
  },
  {
    "text": "But from part number 1, we\nknow that if beta D is smaller than L, she will end up using\nthe laptop when she's actually",
    "start": "2399240",
    "end": "2407280"
  },
  {
    "text": "sitting in the future class. That is to say, if she has\na choice in any given class and shows up in class,\nshe will say, oh,",
    "start": "2407280",
    "end": "2414150"
  },
  {
    "text": "like using the laptop\nwould be great. The same would be true\nof phones, by the way. And when she has a choice\nin any given class that",
    "start": "2414150",
    "end": "2421860"
  },
  {
    "text": "happens right now, if beta\nD equals smaller than L, she will end up using\nthe laptop in class.",
    "start": "2421860",
    "end": "2429060"
  },
  {
    "text": "So that implies essentially\nlike a preference reversal using these parameter assumptions.",
    "start": "2429060",
    "end": "2436510"
  },
  {
    "text": "She prefers not to use the\nlaptop in future classes but switches her mind or changes\nher mind when she's actually",
    "start": "2436510",
    "end": "2442530"
  },
  {
    "text": "sitting in those future classes. ",
    "start": "2442530",
    "end": "2447839"
  },
  {
    "start": "2446000",
    "end": "2446000"
  },
  {
    "text": "OK, question number 4. Explain why the fraction 1\nminus beta D of the class",
    "start": "2447840",
    "end": "2454830"
  },
  {
    "text": "uses a laptop in part 1, but\nfraction 1 minus D of the class uses the laptop in part 2.",
    "start": "2454830",
    "end": "2462150"
  },
  {
    "text": "Why does a smaller\nshare of the class use their laptop in part 2? ",
    "start": "2462150",
    "end": "2469150"
  },
  {
    "text": "All right, so now we're\njust essentially comparing part 1 and part 2. And I'm going to look at\nwhat fraction of people",
    "start": "2469150",
    "end": "2476200"
  },
  {
    "text": "are actually using the laptop. So we can sort of\ndo the math version",
    "start": "2476200",
    "end": "2481300"
  },
  {
    "start": "2480000",
    "end": "2480000"
  },
  {
    "text": "and think about why\nthat answer makes sense. So in part 1, a\nstudent uses the laptop if L is larger than beta\ntimes D. If F is CDF of L--",
    "start": "2481300",
    "end": "2496570"
  },
  {
    "text": "and then started\nas a puritan thing, but to define F as the\nCDF of L. And then given",
    "start": "2496570",
    "end": "2502920"
  },
  {
    "text": "the uniform distribution,\nthe probability of L being larger than beta\nD is 1 minus the CDF 1 minus",
    "start": "2502920",
    "end": "2514850"
  },
  {
    "text": "F of beta delta, which\nis in this uniform. It's just 1 minus beta D.",
    "start": "2514850",
    "end": "2520760"
  },
  {
    "text": "Now, likewise, in part 2,\na student uses a laptop if L is larger than the D. So\nwe have the probability of L",
    "start": "2520760",
    "end": "2527810"
  },
  {
    "text": "being larger than D\nis 1 minus the CDF or the F of D,\nwhich is 1 minus D.",
    "start": "2527810",
    "end": "2534380"
  },
  {
    "text": "So a smaller share uses\nthe laptop in part 2, because the benefit\nof using a laptop is delayed and hence\ndiscounted by beta.",
    "start": "2534380",
    "end": "2542910"
  },
  {
    "text": "So why is that? Well, essentially, think\nabout it like this. If somebody has\nbeta equals 1, which",
    "start": "2542910",
    "end": "2550550"
  },
  {
    "text": "is kind of equivalent\nto like part 2, where people made choices for the\nfuture, if you use a laptop--",
    "start": "2550550",
    "end": "2556280"
  },
  {
    "text": "so a share of people will\nlike the laptop, because-- or like to use the laptop when\nmaking choices for the future,",
    "start": "2556280",
    "end": "2562460"
  },
  {
    "text": "not because of self-control\nproblems or the like, but just because they find lots\nof really helpful in taking notes.",
    "start": "2562460",
    "end": "2569050"
  },
  {
    "text": "Now, if then a person, in\naddition, is present biased and makes a choice\nfor the present,",
    "start": "2569050",
    "end": "2575020"
  },
  {
    "text": "that enhances the\nshort-run benefits, because now the L is not\ndiscounted by beta anymore.",
    "start": "2575020",
    "end": "2581829"
  },
  {
    "text": "And now, it's essentially,\nit's given sort of the benefit.",
    "start": "2581830",
    "end": "2587710"
  },
  {
    "text": "It's in the present,\nand everything else beta is in the future. And so that means essentially\nthat when making choices",
    "start": "2587710",
    "end": "2594370"
  },
  {
    "text": "for the present, the\npresent benefits, the L, gets more weight relative\nto everything else, which",
    "start": "2594370",
    "end": "2601030"
  },
  {
    "text": "is against the weight\nof beta less than 1. So now, if you are already, when\nmaking choices for the future,",
    "start": "2601030",
    "end": "2609010"
  },
  {
    "text": "chose the laptop\nanyway, that implies that you also choose the\nlaptop for the present.",
    "start": "2609010",
    "end": "2615099"
  },
  {
    "text": "Essentially, anybody who chooses\nthe laptop for the future would also choose the\nlaptop for the present.",
    "start": "2615100",
    "end": "2620440"
  },
  {
    "text": "And now, there are some\npeople essentially don't have like huge variations. They might not choose the\nlaptop for the future,",
    "start": "2620440",
    "end": "2625765"
  },
  {
    "text": "but they might choose\nit, they will choose it for the present because\nof their present bias. And therefore, then\nthe fraction of people",
    "start": "2625765",
    "end": "2632223"
  },
  {
    "text": "who choose for the\npresent will be larger than the\nfraction of people who choose for the\nfuture, which we just",
    "start": "2632223",
    "end": "2637810"
  },
  {
    "text": "showed using some algebra. OK, then finally, why\nwould the social planner",
    "start": "2637810",
    "end": "2644620"
  },
  {
    "start": "2642000",
    "end": "2642000"
  },
  {
    "text": "prefer the opt-in policy to\nboth the the policy of allowing students to choose whether\nto use their laptops",
    "start": "2644620",
    "end": "2650619"
  },
  {
    "text": "and to banning\nlaptops altogether? So let's think about through\nthis, the opt-in policy,",
    "start": "2650620",
    "end": "2658980"
  },
  {
    "text": "what does that really entail? Well, the opt-in\npolicy, as we said, is the planner is\nnot present biased.",
    "start": "2658980",
    "end": "2667109"
  },
  {
    "start": "2662000",
    "end": "2662000"
  },
  {
    "text": "So the planner would\nonly want students with L being larger\nthan D to use laptops.",
    "start": "2667110",
    "end": "2673230"
  },
  {
    "text": "And so the opt-in policy,\nas we just showed above, achieves this. So that's great. I know like a free\nchoice policy instead,",
    "start": "2673230",
    "end": "2680370"
  },
  {
    "text": "students with beta times D is\nsmaller than L, smaller than D, will suboptimally\nuse their laptops,",
    "start": "2680370",
    "end": "2686220"
  },
  {
    "text": "and the social planner\ndoes not like this. On the other hand,\nbanning laptops altogether",
    "start": "2686220",
    "end": "2691934"
  },
  {
    "text": "is suboptimal because\nwelfare is gained by allowing the students with\nthe highest valuations, with L",
    "start": "2691935",
    "end": "2697500"
  },
  {
    "text": "equals-- sorry, L larger than D\nto use laptops, right? So banning laptops is not great\nbecause essentially, there's",
    "start": "2697500",
    "end": "2704170"
  },
  {
    "text": "some people who\nreally would love to use their laptops\nregardless of present bias. And not allowing\nthat is not great.",
    "start": "2704170",
    "end": "2711660"
  },
  {
    "text": "Free choice is not great,\nbecause essentially, once you let people\nchoose any given day, temptation will sort of\nkick in, and some people",
    "start": "2711660",
    "end": "2718440"
  },
  {
    "text": "will suboptimally\nuse their laptops and just surf the internet\nall day, or all class, and not learn very much.",
    "start": "2718440",
    "end": "2724559"
  },
  {
    "text": "And instead, the policy where\npeople opt in for the future essentially achieves\nthe objective",
    "start": "2724560",
    "end": "2732330"
  },
  {
    "text": "of the social planner, who\nwants only students with L larger than D to\nuse their laptops.",
    "start": "2732330",
    "end": "2739320"
  },
  {
    "text": "And the social planner will\nbe happy, and therefore prefer that policy\nover both free choice",
    "start": "2739320",
    "end": "2745860"
  },
  {
    "text": "and over banning laptops. ",
    "start": "2745860",
    "end": "2752650"
  },
  {
    "start": "2752000",
    "end": "2752000"
  },
  {
    "text": "So that's the end. That's all I have to say about\ngetting ready for the exam. And I think you should\nprepare well and try",
    "start": "2752650",
    "end": "2759310"
  },
  {
    "text": "to look at the materials. Please ask any questions in\ncase things aren't clear.",
    "start": "2759310",
    "end": "2764530"
  },
  {
    "text": "Again, I have office\nhours on Friday, April 3",
    "start": "2764530",
    "end": "2775200"
  },
  {
    "text": "at 4:30 to 6:00. I emailed you about that. [INAUDIBLE] also has office\nhours from 1:30 to 3:30.",
    "start": "2775200",
    "end": "2782280"
  },
  {
    "text": "Again, that's in my email. If you have questions,\nplease let us know in particular on Piazza\nor during office hours.",
    "start": "2782280",
    "end": "2789840"
  },
  {
    "text": "But in any case, please do not\nworry too much about the exam. Try your best, and\nyou will do great.",
    "start": "2789840",
    "end": "2795839"
  },
  {
    "text": "But you know, even if you\ndon't do great, you'll be fine. You will pass this class as\nlong as you take the exam",
    "start": "2795840",
    "end": "2801570"
  },
  {
    "text": "and write something that\nis remotely reasonable. Thank you so much.",
    "start": "2801570",
    "end": "2806640"
  },
  {
    "text": "And I look forward to\nseeing you in class soon. ",
    "start": "2806640",
    "end": "2812376"
  }
]
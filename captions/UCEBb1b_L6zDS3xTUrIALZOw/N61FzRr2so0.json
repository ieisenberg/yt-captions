[
  {
    "start": "0",
    "end": "500"
  },
  {
    "text": "In this lecture,\nwe will concentrate",
    "start": "500",
    "end": "2960"
  },
  {
    "text": "on the study of Markov\nchains in the long run,",
    "start": "2960",
    "end": "6000"
  },
  {
    "text": "and study under what\nconditions a Markov chain",
    "start": "6000",
    "end": "8670"
  },
  {
    "text": "exhibits steady-state behavior,\nand under what conditions",
    "start": "8670",
    "end": "12780"
  },
  {
    "text": "such steady-state\nbehavior is independent",
    "start": "12780",
    "end": "15620"
  },
  {
    "text": "of the initial starting state.",
    "start": "15620",
    "end": "18119"
  },
  {
    "text": "More precisely, we will look\nat long-term state occupancy",
    "start": "18120",
    "end": "21840"
  },
  {
    "text": "behavior-- that is, in the\nn-step transition probabilities",
    "start": "21840",
    "end": "26470"
  },
  {
    "text": "when n is large.",
    "start": "26470",
    "end": "28699"
  },
  {
    "text": "So assume that we have a\nMarkov chain which is initially",
    "start": "28700",
    "end": "32860"
  },
  {
    "text": "in a given state i, and\nconsider the probability",
    "start": "32860",
    "end": "36770"
  },
  {
    "text": "that the chain is in a specific\nstate j after n transitions.",
    "start": "36770",
    "end": "41900"
  },
  {
    "text": "Question-- does that probability\nconverge to some constant",
    "start": "41900",
    "end": "45450"
  },
  {
    "text": "when n goes to infinity?",
    "start": "45450",
    "end": "48010"
  },
  {
    "text": "And if this is the case-- second\nquestion-- can this constant be",
    "start": "48010",
    "end": "52940"
  },
  {
    "text": "independent of the\ninitial state i?",
    "start": "52940",
    "end": "56750"
  },
  {
    "text": "We will see that for\nnice Markov chains,",
    "start": "56750",
    "end": "59490"
  },
  {
    "text": "the answers to both\nquestions will be yes.",
    "start": "59490",
    "end": "62800"
  },
  {
    "text": "How to characterize\nnice Markov chains?",
    "start": "62800",
    "end": "65690"
  },
  {
    "text": "We will use several new\nconcepts, one dealing",
    "start": "65690",
    "end": "68780"
  },
  {
    "text": "with a Markov chain\nbeing aperiodic or not,",
    "start": "68780",
    "end": "71880"
  },
  {
    "text": "and the other with the\nnotion of recurrent classes.",
    "start": "71880",
    "end": "76229"
  },
  {
    "text": "Without going into\ndetails now, let",
    "start": "76230",
    "end": "78930"
  },
  {
    "text": "us simply mention\nthat we will show",
    "start": "78930",
    "end": "81380"
  },
  {
    "text": "that the existence\nof convergence",
    "start": "81380",
    "end": "83369"
  },
  {
    "text": "will be tied to having an\naperiodic Markov chain.",
    "start": "83370",
    "end": "87100"
  },
  {
    "text": "And in case we have\nconvergence, the independence",
    "start": "87100",
    "end": "90220"
  },
  {
    "text": "from the initial\nstate will be tied",
    "start": "90220",
    "end": "91990"
  },
  {
    "text": "to having a single\nrecurrent class.",
    "start": "91990",
    "end": "95159"
  },
  {
    "text": "We will end this lecture\nby looking in detail",
    "start": "95160",
    "end": "98580"
  },
  {
    "text": "at the special and important\nclass of Markov chains usually",
    "start": "98580",
    "end": "102080"
  },
  {
    "text": "known as birth-death processes.",
    "start": "102080",
    "end": "105100"
  },
  {
    "start": "105100",
    "end": "105900"
  }
]
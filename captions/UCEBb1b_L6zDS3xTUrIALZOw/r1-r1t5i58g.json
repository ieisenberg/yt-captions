[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "NARRATOR: The\nfollowing content is provided by MIT OpenCourseWare\nunder a Creative Commons license.",
    "start": "0",
    "end": "6090"
  },
  {
    "text": "Additional information\nabout our license and MIT OpenCourseWare\nin general is available at ocw.mit.edu.",
    "start": "6090",
    "end": "11930"
  },
  {
    "text": " PROFESSOR: Finite difference\nmethods for initial value",
    "start": "11930",
    "end": "17730"
  },
  {
    "start": "15000",
    "end": "107000"
  },
  {
    "text": "problems that we're\ncoming to the end of, and the solving large\nsystems that we're",
    "start": "17730",
    "end": "24810"
  },
  {
    "text": "coming to the beginning of, was\nto talk today about matrices,",
    "start": "24810",
    "end": "33200"
  },
  {
    "text": "because that language is\njust useful for everything.",
    "start": "33200",
    "end": "38230"
  },
  {
    "text": " So about the homeworks, Mr.\nCho put in a long weekend",
    "start": "38230",
    "end": "46410"
  },
  {
    "text": "grading the homeworks\nthat were turned in Friday and preparing code\nand output to go up",
    "start": "46410",
    "end": "55420"
  },
  {
    "text": "on the web page, probably\nlate tonight or tomorrow. So have a look to see and I\nhope that those codes will",
    "start": "55420",
    "end": "66110"
  },
  {
    "text": "be useful for the future too. Right. So we'll maybe say\nmore about the outputs.",
    "start": "66110",
    "end": "73430"
  },
  {
    "text": "And about the projects,\nwhich by the way, could grow out of\nthat homework or could",
    "start": "73430",
    "end": "81030"
  },
  {
    "text": "go in a totally\ndifferent direction, I'm thinking that the right\ntime to say projects due",
    "start": "81030",
    "end": "88510"
  },
  {
    "text": "would be after spring break. So pretty much nearly\nimmediately after the spring",
    "start": "88510",
    "end": "96100"
  },
  {
    "text": "break would be -- and\nwe'll talk about it more, but just so you have\nan idea of what's -- what timetable I had in mind.",
    "start": "96100",
    "end": "104119"
  },
  {
    "text": "So, matrices then.  In particular, finite\ndifference matrices.",
    "start": "104120",
    "end": "112780"
  },
  {
    "text": "So that's the second\ndifference matrix, K,",
    "start": "112780",
    "end": "118770"
  },
  {
    "text": "and I'll frequently use that\nletter K as I did in 18.085 for that very, very\nimportant and useful matrix.",
    "start": "118770",
    "end": "127630"
  },
  {
    "text": "So what are its properties? It's tridiagonal. ",
    "start": "127630",
    "end": "133360"
  },
  {
    "text": "That's a very important\nproperty, which we'll see, because that means\nthat computations",
    "start": "133360",
    "end": "139410"
  },
  {
    "text": "solving linear systems are very\nfast with a tridiagonal matrix.",
    "start": "139410",
    "end": "145420"
  },
  {
    "text": "It's symmetric. All its eigenvalues\nare positive,",
    "start": "145420",
    "end": "150660"
  },
  {
    "text": "so I would say it's\nsymmetric, positive definite. And those eigenvalues\nand eigenvectors --",
    "start": "150660",
    "end": "157030"
  },
  {
    "text": "so the eigenvectors for this\nmatrix turn out to be discrete",
    "start": "157030",
    "end": "162065"
  },
  {
    "text": "-- not quite discrete\nexponentials, discrete sines,",
    "start": "162065",
    "end": "167510"
  },
  {
    "text": "discrete sine function. If I change the\nboundary conditions, I can get discrete cosines\nas the eigenvectors.",
    "start": "167510",
    "end": "174950"
  },
  {
    "text": "Or I could get\ndiscrete exponentials as the eigenvectors\nby making it periodic.",
    "start": "174950",
    "end": "180620"
  },
  {
    "text": "Maybe I'll mention how\nto make it periodic and then I'll erase it again. To make it periodic means that\nthis second different centered",
    "start": "180620",
    "end": "189550"
  },
  {
    "text": "at point 1 should\nlook ahead to point 2 and look behind to point 0, but\nthat'll be the same as point n,",
    "start": "189550",
    "end": "197540"
  },
  {
    "text": "so I would put a minus 1\nin that corner and this one similarly, it looks ahead,\nwhich really brings it around",
    "start": "197540",
    "end": "207360"
  },
  {
    "text": "again, since we're\nsort of on a circle, brings it around again here.",
    "start": "207360",
    "end": "212470"
  },
  {
    "text": "So that matrix now, with\nminus 1's added in the corner, I would call C, a circular.",
    "start": "212470",
    "end": "219970"
  },
  {
    "text": "So I'll leave the\nletter K there, but the right letter is C\nwhile these minus 1's are here",
    "start": "219970",
    "end": "229290"
  },
  {
    "text": "to make it periodic. By the way, they mess\nup that the tridiagonal.",
    "start": "229290",
    "end": "234370"
  },
  {
    "text": "It's no longer tridiagonal. Also, it certainly got\n-- it's very sparse.",
    "start": "234370",
    "end": "239880"
  },
  {
    "text": " Mentioning sparse\nreminds me, if you're",
    "start": "239880",
    "end": "247640"
  },
  {
    "start": "242000",
    "end": "346000"
  },
  {
    "text": "coding large matrices\nthat are sparse, you should let MATLAB\nknow that they're sparse.",
    "start": "247640",
    "end": "254640"
  },
  {
    "text": "So MATLAB has a whole -- it\ncarries out operations --",
    "start": "254640",
    "end": "259690"
  },
  {
    "text": "if you tell it it's\na sparse matrix, then it only operates where the\nnon-zeros are located and it",
    "start": "259690",
    "end": "269509"
  },
  {
    "text": "doesn't waste its time looking\nat these 0's, these 0's through",
    "start": "269510",
    "end": "274640"
  },
  {
    "text": "all the matrix steps. ",
    "start": "274640",
    "end": "282300"
  },
  {
    "text": "So using sparse MATLAB is\nimportant thing to know about.",
    "start": "282300",
    "end": "287379"
  },
  {
    "text": "It's just typically\nan s or an sp will appear in MATLAB commands.",
    "start": "287380",
    "end": "293070"
  },
  {
    "text": "For example, I'll just\nmaybe fill it in here. What's the sparse\nidentity matrix?",
    "start": "293070",
    "end": "299050"
  },
  {
    "text": "The normal identity\nmatrix would be eye of n and the sparse identity\nmatrix is sp, speye of n.",
    "start": "299050",
    "end": "309620"
  },
  {
    "text": "Similarly, we would create K --\nwe could use 2 times speye of n",
    "start": "309620",
    "end": "316290"
  },
  {
    "text": "as the diagonal\nof K and the two, the upper and lower diagonals --\nand we could tell it these two",
    "start": "316290",
    "end": "327140"
  },
  {
    "text": "entries. Another thing to say -- what\nI said I wasn't going to do,",
    "start": "327140",
    "end": "333730"
  },
  {
    "text": "I'll do because I hate to see\na K up there while it's not right. ",
    "start": "333730",
    "end": "341510"
  },
  {
    "text": "Two more points\nabout this matrix. It's singular now.",
    "start": "341510",
    "end": "349060"
  },
  {
    "text": "The determinant is 0. Now, I'm never going to take the\ndeterminant of a giant matrix.",
    "start": "349060",
    "end": "357200"
  },
  {
    "text": "That's a bad thing to do. Much better to recognize that\nthere's a vector, x, let's say,",
    "start": "357200",
    "end": "368620"
  },
  {
    "text": "and it's the vector of all 1's. It's the vector of n 1's. If you imagine multiplying this\nmatrix by the vector of n 1's,",
    "start": "368620",
    "end": "377130"
  },
  {
    "text": "what do you get? You get all 0's.",
    "start": "377130",
    "end": "382760"
  },
  {
    "text": "So that vector of all\n1's is in the null space, I would say, of a matrix.",
    "start": "382760",
    "end": "388030"
  },
  {
    "text": "Null space is just\nthe vectors that get wiped out by the matrix.",
    "start": "388030",
    "end": "393440"
  },
  {
    "text": "C*x is all 0's. So that vector -- this matrix\nhas some nonzero vectors in its",
    "start": "393440",
    "end": "402550"
  },
  {
    "text": "null space. I know right away then,\nits determinant is 0. So the determinant\nof that is 0 and now",
    "start": "402550",
    "end": "411470"
  },
  {
    "text": "that would tell me something\nabout the eigenvalues of the matrix. It tells me about\none eigenvalue.",
    "start": "411470",
    "end": "419400"
  },
  {
    "text": "It's 0.  A matrix, like C, that\nhas C*x equals 0, well,",
    "start": "419400",
    "end": "430170"
  },
  {
    "text": "I could also say that\nthat's C*x equals 0*x. That would actually be better,\nso that both sides are vectors.",
    "start": "430170",
    "end": "439229"
  },
  {
    "text": "So I'm realizing that that\nvector x in the null space",
    "start": "439230",
    "end": "444630"
  },
  {
    "text": "is an eigenvector and the\ncorresponding eigenvalue is 0. ",
    "start": "444630",
    "end": "456590"
  },
  {
    "text": "Otherwise, the eigenvalues\nwill all still be positive. So this would be a\npositive semidefinite.",
    "start": "456590",
    "end": "465250"
  },
  {
    "text": "I would call that matrix\npositive semidefinite,",
    "start": "465250",
    "end": "471580"
  },
  {
    "text": "the semi telling me that it\nisn't quite definite, that it gets down and has 0,\nthe matrix is singular.",
    "start": "471580",
    "end": "484190"
  },
  {
    "text": "But still, it's good to know\nwhere all the other n minus 1 eigenvalues are.",
    "start": "484190",
    "end": "489509"
  },
  {
    "text": "They're all positive.  About the bandwidth --\nlet me go back to K now.",
    "start": "489510",
    "end": "499380"
  },
  {
    "start": "493000",
    "end": "785000"
  },
  {
    "text": "Because the bandwidth, strictly\nspeaking, the bandwidth of C is very large.",
    "start": "499380",
    "end": "505770"
  },
  {
    "text": "The bandwidth is, if I'm\nlooking for only one number,",
    "start": "505770",
    "end": "512039"
  },
  {
    "text": "that number tells me\nhow many diagonals I have to grow until I\nreach the last nonzero.",
    "start": "512040",
    "end": "524099"
  },
  {
    "text": "So the bandwidth here is large. And in general, the\noperation count,",
    "start": "524100",
    "end": "536070"
  },
  {
    "text": "the amount of work\nto do, is going to grow with the bandwidth.",
    "start": "536070",
    "end": "542100"
  },
  {
    "text": "Of course, that\nhaving full bandwidth isn't quite the full\nstory for this matrix,",
    "start": "542100",
    "end": "548310"
  },
  {
    "text": "because it's so sparse. I've got hundreds\nof zero diagonals",
    "start": "548310",
    "end": "554460"
  },
  {
    "text": "in between and just this one. Anyway, this is a matrix\nwith a large bandwidth,",
    "start": "554460",
    "end": "560800"
  },
  {
    "text": "but a little deceptive. Now here's a matrix with\na -- back to K again.",
    "start": "560800",
    "end": "569120"
  },
  {
    "text": "I call the bandwidth\njust 1 here. Really, maybe half bandwidth\nwould be a better word.",
    "start": "569120",
    "end": "577820"
  },
  {
    "text": "The bandwidth is the number\nof diagonals above or below --",
    "start": "577820",
    "end": "586280"
  },
  {
    "text": "take the maximum of the count\nabove and the count below and in this case,\nboth counts are 1.",
    "start": "586280",
    "end": "593209"
  },
  {
    "text": "One diagonal above, one\ndiagonal below, so really, half bandwidth, I\nwould say, is 1.",
    "start": "593210",
    "end": "601550"
  },
  {
    "text": "Just some convention\nis needed there. The crucial point is that\nthe bandwidth measures",
    "start": "601550",
    "end": "611110"
  },
  {
    "text": "the amount of work to do\nwhen you do elimination,",
    "start": "611110",
    "end": "617589"
  },
  {
    "text": "as MATLAB will do, of course. One other thing about MATLAB\n-- so I'm often referring",
    "start": "617590",
    "end": "626389"
  },
  {
    "text": "to MATLAB and I'm thinking\nof its backslash command. The backslash, which solves A*x\nequal b by just A backslash b.",
    "start": "626390",
    "end": "638990"
  },
  {
    "text": " So if it doesn't know\nthese matrices are sparse,",
    "start": "638990",
    "end": "649540"
  },
  {
    "text": "it will go through\nall the steps, not taking advantage of the fact\nthat we've got all these 0's",
    "start": "649540",
    "end": "655940"
  },
  {
    "text": "here. If it does know\nthat they're sparse, then it's tremendously fast.",
    "start": "655940",
    "end": "661500"
  },
  {
    "text": "Let me come back to that point. Maybe actually backslash\nis smart enough",
    "start": "661500",
    "end": "668690"
  },
  {
    "text": "to look to see\nwhether the matrix,",
    "start": "668690",
    "end": "675160"
  },
  {
    "text": "whether sparseness is available. So I shouldn't have said --\nI think maybe there's a lot engineered into backslash.",
    "start": "675160",
    "end": "682600"
  },
  {
    "text": "Actually, backslash,\nalso engineered in there is the least squares solution.",
    "start": "682600",
    "end": "689120"
  },
  {
    "text": "If you give it a\nrectangular problem and, say, too many equations,\nso that you can't expect",
    "start": "689120",
    "end": "701870"
  },
  {
    "text": "to have an exact\nsolution, backslash will pick the least\nsquares solution.",
    "start": "701870",
    "end": "708880"
  },
  {
    "text": "And much more. That's probably the\nmost used operation.",
    "start": "708880",
    "end": "715010"
  },
  {
    "text": "So I said something about\nthe eigenvalues and everybody sees that if I multiply this\nmatrix by the values of u",
    "start": "715010",
    "end": "726380"
  },
  {
    "text": "at successive mesh points, I'll\nget the second difference that corresponds to u_xx.",
    "start": "726380",
    "end": "732980"
  },
  {
    "text": "Now this would correspond\n-- this matrix -- so that tells me I'm\ntaking a finite difference.",
    "start": "732980",
    "end": "741350"
  },
  {
    "text": "That plus tells me I'm going\nin the forward direction, so that's 1 at the mesh\nvalue to the right minus 1",
    "start": "741350",
    "end": "751890"
  },
  {
    "text": "of the mesh value\nat the center point. Of course, this has\nto be divided by delta x and that by delta x squared.",
    "start": "751890",
    "end": "759260"
  },
  {
    "text": "So these are matrices, along\nwith the backward difference",
    "start": "759260",
    "end": "766940"
  },
  {
    "text": "and the centered\ndifference, out of which you build the basic\nfinite difference",
    "start": "766940",
    "end": "774350"
  },
  {
    "text": "equation, as you've done. I want to make a comment\nhere though, now,",
    "start": "774350",
    "end": "781639"
  },
  {
    "text": "on this topic of eigenvalues.",
    "start": "781640",
    "end": "786900"
  },
  {
    "start": "785000",
    "end": "1235000"
  },
  {
    "text": "Eigenvalues for\nK really tell you the truth about the\nmatrix K. The eigenvalues",
    "start": "786900",
    "end": "794649"
  },
  {
    "text": "of that matrix K start\njust a little above 0",
    "start": "794650",
    "end": "800970"
  },
  {
    "text": "and they go to a\nlittle before 4. So the eigenvalues for K\n-- shall I put that here?",
    "start": "800970",
    "end": "811920"
  },
  {
    "text": "The eigenvalues of K\nare between 0 and 4. ",
    "start": "811920",
    "end": "823180"
  },
  {
    "text": "They come very close\nto 4 and quite close to 0, depending on the size\nof the matrix of course.",
    "start": "823180",
    "end": "831840"
  },
  {
    "text": "Let me just do -- if I\ntook the one by one case, its eigenvalue is 2.",
    "start": "831840",
    "end": "837950"
  },
  {
    "text": "If I took the two by two case,\nits eigenvalues are 1 and 3.",
    "start": "837950",
    "end": "844270"
  },
  {
    "text": "Notice nice properties there. The eigenvalues 1 and 3\nare positive, as we said.",
    "start": "844270",
    "end": "853339"
  },
  {
    "text": "This matrix K has positive\neigenvalues, whatever size. What's more, the 1 and 3\nkind of interlace the 2.",
    "start": "853340",
    "end": "865550"
  },
  {
    "text": "So what I'm saying is,\nthe eigenvalue for that is in between the eigenvalue\nfor the two by two,",
    "start": "865550",
    "end": "874130"
  },
  {
    "text": "and the two\neigenvalues 1 and 3 are in between the three eigenvalues\nthat I would get for the three",
    "start": "874130",
    "end": "881149"
  },
  {
    "text": "by three case. Maybe I'll just\nwrite those down. They are useful numbers.",
    "start": "881150",
    "end": "886700"
  },
  {
    "text": "So K_2 has lambda equal 1 and 3.",
    "start": "886700",
    "end": "892890"
  },
  {
    "text": "The three by three one,\nI think the eigenvalues are 2 minus root 2,\nwhich is smaller than 1;",
    "start": "892890",
    "end": "901060"
  },
  {
    "text": "2, which is in between;\nand 2 plus root 2, which",
    "start": "901060",
    "end": "906150"
  },
  {
    "text": "is larger than 3. And of course, they're\nall between 0 and 4.",
    "start": "906150",
    "end": "912300"
  },
  {
    "text": "Just a comment. How do I know they're\nbetween 0 and 4? ",
    "start": "912300",
    "end": "918820"
  },
  {
    "text": "There's a somewhat\nhandy little rule",
    "start": "918820",
    "end": "924190"
  },
  {
    "text": "for getting the location\nof eigenvalues, that's just worth knowing as a\nsort of general principle,",
    "start": "924190",
    "end": "931130"
  },
  {
    "text": "but of course it can't tell\nyou exactly where they are. First of all, the fact that\nthe matrix is symmetric",
    "start": "931130",
    "end": "939570"
  },
  {
    "text": "tells us what about\nthe eigenvalues? So we learn a very,\nvery important fact",
    "start": "939570",
    "end": "945170"
  },
  {
    "text": "about the eigenvalues from\njust looking at the matrix and observing that\nit's symmetric.",
    "start": "945170",
    "end": "951700"
  },
  {
    "text": "That tells us that the\neigenvalues are real. They're real numbers. ",
    "start": "951700",
    "end": "959459"
  },
  {
    "text": "Actually, it tells us\nsomething equally important about the eigenvectors. The eigenvectors of the\nmatrix are orthogonal.",
    "start": "959460",
    "end": "967709"
  },
  {
    "text": "The symmetric matrix\nhas real eigenvalues, orthogonal eigenvectors. That's a little bit of\nlinear algebra to know.",
    "start": "967710",
    "end": "975510"
  },
  {
    "text": "Now, why between\n0 and 4, though? ",
    "start": "975510",
    "end": "982029"
  },
  {
    "text": "There's there's this\n-- what's his name? Gershgorin.",
    "start": "982030",
    "end": "987510"
  },
  {
    "text": "Gershgorin pointed out --\nand it's a two-line proof --",
    "start": "987510",
    "end": "992620"
  },
  {
    "text": "that every eigenvalue\nis in one of his -- one or more of his circles.",
    "start": "992620",
    "end": "998390"
  },
  {
    "text": "So where are the\nGershgorin circles? A typical Gershgorin circle is\ncentered at the number -- here,",
    "start": "998390",
    "end": "1007310"
  },
  {
    "text": "2 -- that's on the diagonal,\nand its radius is the sum off",
    "start": "1007310",
    "end": "1014120"
  },
  {
    "text": "the diagonal, but you\ntake absolute values. Gershgorin wasn't doing\nany of the fine points that",
    "start": "1014120",
    "end": "1021149"
  },
  {
    "text": "really locate the eigenvalue. So in this matrix,\nall the centers",
    "start": "1021150",
    "end": "1026829"
  },
  {
    "text": "are at 2, the\ndiagonals, and the radii are 2, also 2, because that and\nthat in absolute value make 2.",
    "start": "1026830",
    "end": "1036970"
  },
  {
    "text": " This first row makes a 1 and\nactually, that's what -- that,",
    "start": "1036970",
    "end": "1044670"
  },
  {
    "text": "by a little careful argument,\nis what gets the eigenvalues not",
    "start": "1044670",
    "end": "1052180"
  },
  {
    "text": "actually touching\n0 or touching 4. It takes a little patience.",
    "start": "1052180",
    "end": "1057570"
  },
  {
    "text": "All you could say from here --\nall Gershgorin could say would be, the eigenvalues are\nin a circle centered at 2,",
    "start": "1057570",
    "end": "1066659"
  },
  {
    "text": "its radius is 2, so\nthey're between 0 and 4.",
    "start": "1066660",
    "end": "1071770"
  },
  {
    "text": "Then it's that first\nand last row -- either the first or the last\nrow would do to say that",
    "start": "1071770",
    "end": "1081660"
  },
  {
    "text": "they're strictly positive. Of course, the true\nsecond difference,",
    "start": "1081660",
    "end": "1089890"
  },
  {
    "text": "I should divide K\nby delta x squared. So the eigenvalues will be\ndivided by delta x squared,",
    "start": "1089890",
    "end": "1097450"
  },
  {
    "text": "divided by a small number,\nso they will really be much larger.",
    "start": "1097450",
    "end": "1102790"
  },
  {
    "text": "The ratio of the\nbiggest to the smallest isn't affected by\nthe delta x squared",
    "start": "1102790",
    "end": "1108350"
  },
  {
    "text": "and that's a key number. Let me put that maybe on\nthe next board, for K.",
    "start": "1108350",
    "end": "1118530"
  },
  {
    "text": "So lambda_max is about 4.",
    "start": "1118530",
    "end": "1123890"
  },
  {
    "text": "Lambda_min, the smallest\neigenvalue, is close to 0.",
    "start": "1123890",
    "end": "1133170"
  },
  {
    "text": "How close? It's of the order of some\nconstant over n squared.",
    "start": "1133170",
    "end": "1139450"
  },
  {
    "text": " Now I use the word\ncondition number and that --",
    "start": "1139450",
    "end": "1146830"
  },
  {
    "text": "so let me write that down. Condition number -- say c\nof K for condition number --",
    "start": "1146830",
    "end": "1155050"
  },
  {
    "text": "is the ratio lambda_max\nover lambda_min. Of course, I'm\nusing here the fact",
    "start": "1155050",
    "end": "1161030"
  },
  {
    "text": "that K is a symmetric matrix. Symmetric matrices\nare so beautiful that their eigenvalues give\nyou a reliable story here.",
    "start": "1161030",
    "end": "1171220"
  },
  {
    "text": "So 4 divided by this -- the\nmain point is that it's O of --",
    "start": "1171220",
    "end": "1177890"
  },
  {
    "text": "it's of order 1 over n -- sorry. When I divide by\nlambda_min, that puts the n squared\nup in the numerator.",
    "start": "1177890",
    "end": "1185390"
  },
  {
    "text": "It's O of n squared,\ngrowing like n squared.",
    "start": "1185390",
    "end": "1192210"
  },
  {
    "text": "And that condition\nnumber, somehow it",
    "start": "1192210",
    "end": "1198169"
  },
  {
    "text": "measures how close the\nmatrix is to being singular,",
    "start": "1198170",
    "end": "1203990"
  },
  {
    "text": "because it involves\nthis lambda_min, which",
    "start": "1203990",
    "end": "1210809"
  },
  {
    "text": "is the smallest eigenvalue and\nwould be 0 if it were singular, and it's scaled by lambda_max.",
    "start": "1210810",
    "end": "1218000"
  },
  {
    "text": "So if I'm multiply\nthe matrix by 100, what happens to the\ncondition number?",
    "start": "1218000",
    "end": "1223830"
  },
  {
    "text": "No change. No change, because I'm doing\nlambda_max over lambda_min.",
    "start": "1223830",
    "end": "1229180"
  },
  {
    "text": "Both lambda_max and lambda_min\nwould be multiplied by 100, but the ratio\nwouldn't be different",
    "start": "1229180",
    "end": "1235230"
  },
  {
    "start": "1235000",
    "end": "1407000"
  },
  {
    "text": "So this is a useful measure. And O of n squared, that's\na big number if n is large.",
    "start": "1235230",
    "end": "1248220"
  },
  {
    "text": "A big numbers if n is large. And that condition number, where\ndoes it come in elimination?",
    "start": "1248220",
    "end": "1254850"
  },
  {
    "text": " In elimination, the\nround-off error -- roughly,",
    "start": "1254850",
    "end": "1269360"
  },
  {
    "text": "the rule of thumb\nis that you would -- if the condition number\nis 10 to the eighth,",
    "start": "1269360",
    "end": "1278620"
  },
  {
    "text": "you might lose eight significant\nbits in the back slide.",
    "start": "1278620",
    "end": "1286850"
  },
  {
    "text": "You could. So this condition number\nmeasures how sensitive",
    "start": "1286850",
    "end": "1294580"
  },
  {
    "text": "your matrix is to round-off. So that's a few\nthoughts about matrices",
    "start": "1294580",
    "end": "1304540"
  },
  {
    "text": "and that matrix K in particular. Now what about the other\nmatrix, the first difference?",
    "start": "1304540",
    "end": "1315960"
  },
  {
    "text": "The point I want to\nmake about that matrix is, what about its eigenvalues?",
    "start": "1315960",
    "end": "1324600"
  },
  {
    "text": "What are the eigenvalues of\nthat upper triangular matrix?",
    "start": "1324600",
    "end": "1330470"
  },
  {
    "text": "They are, if you remember\nlinear algebra -- but I can just tell you\nquickly the main point --",
    "start": "1330470",
    "end": "1338309"
  },
  {
    "text": "for a triangular matrix,\nthe values are sitting on the diagonal.",
    "start": "1338310",
    "end": "1345840"
  },
  {
    "text": "So this matrix\nhas the eigenvalue minus 1 repeated n times.",
    "start": "1345840",
    "end": "1352150"
  },
  {
    "start": "1352150",
    "end": "1357800"
  },
  {
    "text": "That true fact is totally\nmisleading, totally misleading.",
    "start": "1357800",
    "end": "1363340"
  },
  {
    "text": " The eigenvalues for\nthis triangular matrix",
    "start": "1363340",
    "end": "1369770"
  },
  {
    "text": "don't even notice what\nI've got above the diagonal and somehow they can't give\na reasonable picture of what",
    "start": "1369770",
    "end": "1380529"
  },
  {
    "text": "the matrix is actually doing. So maybe that's my\nwarning here, that",
    "start": "1380530",
    "end": "1386900"
  },
  {
    "text": "for a matrix which is\nabsolutely not symmetric, right? I mean, not at all symmetric.",
    "start": "1386900",
    "end": "1393120"
  },
  {
    "text": " For the centered\ndifference, which is --",
    "start": "1393120",
    "end": "1400039"
  },
  {
    "text": "what's the centered difference? I was going to say symmetric,\nbut it's the opposite. Centered difference would be --\nlet's put delta_centered down",
    "start": "1400039",
    "end": "1410049"
  },
  {
    "start": "1407000",
    "end": "2160000"
  },
  {
    "text": "here. Centered difference\nwould be, I'd have a 1. 0's would go on the point\nthat -- for the central value.",
    "start": "1410050",
    "end": "1421130"
  },
  {
    "text": "1 would multiply the\nforward value and minus 1 would multiply that,\nand then I'd have 1/2",
    "start": "1421130",
    "end": "1428350"
  },
  {
    "text": "and then I'd probably\nhave a delta x.  But the main point is, my matrix\nwould look something like this.",
    "start": "1428350",
    "end": "1440679"
  },
  {
    "text": "Minus 1's and 1's\non two diagonals. Now we could find the\neigenvalues of that matrix.",
    "start": "1440680",
    "end": "1449110"
  },
  {
    "text": "Do you know anything\nabout the eigenvalues?",
    "start": "1449110",
    "end": "1454820"
  },
  {
    "text": "This is a chance\nfor me just to speak for a few minutes\nabout useful facts",
    "start": "1454820",
    "end": "1462100"
  },
  {
    "text": "that you can tell about a\nmatrix just by looking at it. So what do I see when\nI look at that matrix?",
    "start": "1462100",
    "end": "1470450"
  },
  {
    "text": "Is it symmetric? It's the opposite of symmetric,\nbecause the symmetric matrix",
    "start": "1470450",
    "end": "1477220"
  },
  {
    "text": "up there, if I transpose\nit, it doesn't change. If I transpose this\none, I'll get some kind",
    "start": "1477220",
    "end": "1486330"
  },
  {
    "text": "of a backward difference. If I transpose this one, then\nthe 1's and the minus 1's will",
    "start": "1486330",
    "end": "1493840"
  },
  {
    "text": "reverse. I'll get the negative. So the rule for this centered\ndifference is -- so shall I --",
    "start": "1493840",
    "end": "1501520"
  },
  {
    "text": "how am I going to call\ncentered difference? Del centered, for the moment.",
    "start": "1501520",
    "end": "1506840"
  },
  {
    "text": "The transpose of\nthat is minus itself.",
    "start": "1506840",
    "end": "1512929"
  },
  {
    "text": " So what does that tell me? ",
    "start": "1512930",
    "end": "1521330"
  },
  {
    "text": "First, that matrix is -- it's\nthe opposite of symmetric,",
    "start": "1521330",
    "end": "1532330"
  },
  {
    "text": "but it's actually OK. What I mean by OK is,\nits eigenvectors --",
    "start": "1532330",
    "end": "1539910"
  },
  {
    "text": "we're back to\northogonal eigenvectors. I didn't say anything about\nthe eigenvectors of del plus,",
    "start": "1539910",
    "end": "1546090"
  },
  {
    "text": "but actually, that was\nthe biggest problem. This matrix del plus has one\neigenvalue repeated n times,",
    "start": "1546090",
    "end": "1555010"
  },
  {
    "text": "and it has only one\neigenvector, not --",
    "start": "1555010",
    "end": "1560360"
  },
  {
    "text": "it doesn't even have a\nfull set of eigenvectors, much less orthogonal ones.",
    "start": "1560360",
    "end": "1566059"
  },
  {
    "text": "So that matrix is like --\nyou don't want to trust",
    "start": "1566060",
    "end": "1571660"
  },
  {
    "text": "the eigenvalue picture that you\nget from a matrix like that. Here this anti-symmetric\nmatrix can be trusted.",
    "start": "1571660",
    "end": "1580210"
  },
  {
    "text": "Its eigenvalue\npicture is reliable. It does tell you\nwhat's going on. The eigenvectors are orthogonal.",
    "start": "1580210",
    "end": "1589000"
  },
  {
    "text": "They're complex, actually. Actually, they'll look a lot\nlike our e to the i*k*x's So we",
    "start": "1589000",
    "end": "1598010"
  },
  {
    "text": "don't panic when we see\ncomplex eigenvectors. The eigenvalues are -- do you\nknow what the eigenvalues looks",
    "start": "1598010",
    "end": "1606260"
  },
  {
    "text": "like for an\nanti-symmetric matrix? They're pure imaginary, just\nthe way that when we took second",
    "start": "1606260",
    "end": "1616559"
  },
  {
    "text": "differences -- maybe I'll\njust put here the centered",
    "start": "1616560",
    "end": "1625450"
  },
  {
    "text": "difference, the centered\nfirst difference,",
    "start": "1625450",
    "end": "1632899"
  },
  {
    "text": "when we applied it to -- I want\napply to e to the i*k*x to find",
    "start": "1632900",
    "end": "1640280"
  },
  {
    "text": "what factor comes out. So I get e to the i k plus 1\ndelta x from the plus side.",
    "start": "1640280",
    "end": "1652740"
  },
  {
    "text": " This is the matrix I'm\ndoing, with 1 and minus 1.",
    "start": "1652740",
    "end": "1659990"
  },
  {
    "text": "So the minus 1 will give me\nminus e to the i k minus 1",
    "start": "1659990",
    "end": "1666130"
  },
  {
    "text": "delta x and of course, I\nfactor out of that the e",
    "start": "1666130",
    "end": "1671150"
  },
  {
    "text": "to the i*k*x's so I'm\nleft with e to the -- the thing that factors out\nis e to the i delta x minus e",
    "start": "1671150",
    "end": "1679425"
  },
  {
    "text": "to the minus i delta\nx -- and what's that? That multiplies the e to\nthe i*k*x, the eigenvector.",
    "start": "1679425",
    "end": "1688350"
  },
  {
    "text": "This is like the\neigenvalue, and what do I say about that quantity? ",
    "start": "1688350",
    "end": "1695390"
  },
  {
    "text": "Of course, it's 2*i sine\ndelta x, pure imaginary.",
    "start": "1695390",
    "end": "1704740"
  },
  {
    "text": "And I should have\ndivided by the 2, which",
    "start": "1704740",
    "end": "1711200"
  },
  {
    "text": "would take away that 2. So it's pure imaginary. ",
    "start": "1711200",
    "end": "1720129"
  },
  {
    "text": "In reality and in\nthis Fourier analysis, both are giving this\nunderstanding of what i is.",
    "start": "1720130",
    "end": "1729080"
  },
  {
    "text": "So that when we did this sort\nof operation, von Neumann's",
    "start": "1729080",
    "end": "1738399"
  },
  {
    "text": "rule of following\nthe exponential, we got something reasonable.",
    "start": "1738400",
    "end": "1745280"
  },
  {
    "text": "When we do it with\nthis one, it's",
    "start": "1745280",
    "end": "1750480"
  },
  {
    "text": "von Neumann that's reliable\nand the eigenvalues that are not reliable. So the eigenvalues of this\nbeing all minus 1's is nonsense,",
    "start": "1750480",
    "end": "1759230"
  },
  {
    "text": "doesn't tell us what the forward\ndifference operator is really doing.",
    "start": "1759230",
    "end": "1765020"
  },
  {
    "text": "But von Neumann tells us\nwhat is truly going on.",
    "start": "1765020",
    "end": "1770276"
  },
  {
    "text": "Of course, that would\nbe the same thing in which this minus\n1 wouldn't appear",
    "start": "1770276",
    "end": "1775670"
  },
  {
    "text": "and the 2 wouldn't appear. So what would we get\nout of von Neumann?",
    "start": "1775670",
    "end": "1780790"
  },
  {
    "text": "So this is for delta plus. I would factor out an e\nto the i delta x minus 1.",
    "start": "1780790",
    "end": "1789500"
  },
  {
    "text": " That's what would multiply\nit e to the i*k*x.",
    "start": "1789500",
    "end": "1794910"
  },
  {
    "text": "Oh, e to the i -- sorry. Yes, that's right.",
    "start": "1794910",
    "end": "1801230"
  },
  {
    "text": "That would multiple\ne to the i*k delta x. Sorry, should've\nhad delta x there,",
    "start": "1801230",
    "end": "1809850"
  },
  {
    "text": "but I wasn't paying\nattention to that. Here I was paying attention to\nthis and it was pure imaginary.",
    "start": "1809850",
    "end": "1816230"
  },
  {
    "text": "Here I'm paying\nattention -- here, von Neumann at least is paying\nattention to this and what's he",
    "start": "1816230",
    "end": "1822480"
  },
  {
    "text": "seeing? Not pure imaginary\nor purely real,",
    "start": "1822480",
    "end": "1829950"
  },
  {
    "text": "off in the complex\nplane and that's really what the right growth\nfactor or the right number",
    "start": "1829950",
    "end": "1847850"
  },
  {
    "text": "to associate with frequency k\nfor this forward difference.",
    "start": "1847850",
    "end": "1854690"
  },
  {
    "text": "So I guess I'm saying\nthat von Neumann does -- did the right thing to\ncome up with these pictures",
    "start": "1854690",
    "end": "1863490"
  },
  {
    "text": "for the growth factors. Eigenvalues confirm that\nand really pin it down",
    "start": "1863490",
    "end": "1871550"
  },
  {
    "text": "when they're reliable. Eigenvectors and -- eigenvalues\nare reliable when eigenvector",
    "start": "1871550",
    "end": "1877590"
  },
  {
    "text": "are orthogonal and that's for\nmatrices that are symmetric or anti-symmetric or -- there's\na little bit larger class",
    "start": "1877590",
    "end": "1887650"
  },
  {
    "text": "of matrices that includes\northogonal matrices, but beyond that --\nactually, there's been a lot",
    "start": "1887650",
    "end": "1896770"
  },
  {
    "text": "of discussion over many years\nof eigenvalues and the --",
    "start": "1896770",
    "end": "1911590"
  },
  {
    "text": "for problems that are not\ncontrolled by symmetric or anti-symmetric matrices. ",
    "start": "1911590",
    "end": "1920460"
  },
  {
    "text": "The alternative, the\nmore refined idea of pseudo-eigenvalues is now\nappearing in an important book",
    "start": "1920460",
    "end": "1931850"
  },
  {
    "text": "by Trefethen and Embree,\nwith many examples -- OK,",
    "start": "1931850",
    "end": "1937030"
  },
  {
    "text": "I won't pursue that. Right. So this is some basic fact about\nthose matrices, all of which",
    "start": "1937030",
    "end": "1948510"
  },
  {
    "text": "are one-dimensional. Now this board prepares the\nway to get into 2D and 3D.",
    "start": "1948510",
    "end": "1957500"
  },
  {
    "text": "So I just want to\nask, what does the --",
    "start": "1957500",
    "end": "1962910"
  },
  {
    "text": "we didn't really do the heat\nequation or the wave equation in 2D, but we could have.",
    "start": "1962910",
    "end": "1972170"
  },
  {
    "text": "The von Neumann test\nwould be straightforward,",
    "start": "1972170",
    "end": "1978510"
  },
  {
    "text": "but now I want to think\nabout the matrices. What does the two-dimensional\nsecond difference matrix",
    "start": "1978510",
    "end": "1987919"
  },
  {
    "text": "look like? What I'm going to do,\njust to look ahead,",
    "start": "1987920",
    "end": "1994330"
  },
  {
    "text": "I'm going to use MATLAB's\noperation called kron, short for Kronecker, to\ncreate a 2D matrix out",
    "start": "1994330",
    "end": "2004070"
  },
  {
    "text": "of this 1D centered difference. So if I think now about\ncentered differences,",
    "start": "2004070",
    "end": "2011019"
  },
  {
    "text": "second differences -- so I'm\napproximating u_xx plus u_yy --",
    "start": "2011020",
    "end": "2018150"
  },
  {
    "text": "or really, I'm approximating\nminus u_xx minus u_yy, because that K approximates\nminus the second difference.",
    "start": "2018150",
    "end": "2027620"
  },
  {
    "text": "What do I -- what do\nmy matrices look like?",
    "start": "2027620",
    "end": "2034430"
  },
  {
    "text": "What's their bandwidth? How expensive is\nit to invert them? These are the key questions.",
    "start": "2034430",
    "end": "2040390"
  },
  {
    "text": "What's the matrix K2D\nthat corresponds to --",
    "start": "2040390",
    "end": "2048460"
  },
  {
    "text": "gives me second differences\nin the x direction plus second differences in the y direction.",
    "start": "2048460",
    "end": "2055119"
  },
  {
    "text": "So I'll write K2D\nfor that matrix. Let's get some picture of it. ",
    "start": "2055120",
    "end": "2063300"
  },
  {
    "text": "First of all, let\nme imagine that I'm on a square with a square grid.",
    "start": "2063300",
    "end": "2070990"
  },
  {
    "text": "Delta x in both directions. ",
    "start": "2070990",
    "end": "2081770"
  },
  {
    "text": "Square grid, let me say\nN mesh points each way. So N, I don't know whether\nI'm counting -- right now,",
    "start": "2081770",
    "end": "2089960"
  },
  {
    "text": "I won't worry whether I'm\ncounting the boundary ones or not. Probably not. So N -- I'll say N point, point\nN, N points -- so N delta x,",
    "start": "2089960",
    "end": "2103270"
  },
  {
    "text": "and in this direction N delta x.",
    "start": "2103270",
    "end": "2108630"
  },
  {
    "text": "So my matrix is a border. It's of size N squared,\nthe number of unknowns.",
    "start": "2108630",
    "end": "2118950"
  },
  {
    "text": "Now I will be a\nlittle more careful. Here, let me take the\nboundary values as given.",
    "start": "2118950",
    "end": "2125000"
  },
  {
    "text": "They're not unknown. So N in this picture is 4. One, two, three, four unknowns\nthere on a typical row.",
    "start": "2125000",
    "end": "2135980"
  },
  {
    "text": "Now I have to give them a new\nnumber -- five, six, seven, eight, nine, 10, 11, 12, 13,\n14, 15, 16 -- and N being 4,",
    "start": "2135980",
    "end": "2148620"
  },
  {
    "text": "N squared is 16 for\nthat particular square.",
    "start": "2148620",
    "end": "2154600"
  },
  {
    "text": "So my matrix is 16 by 16. ",
    "start": "2154600",
    "end": "2160970"
  },
  {
    "text": "But somehow I want to be able\nto create it out of 4 by 4",
    "start": "2160970",
    "end": "2166900"
  },
  {
    "text": "matrices like K. So K1D, which\nI'm just going to call K --",
    "start": "2166900",
    "end": "2175430"
  },
  {
    "text": "K_N will be the 4 by 4 one. 2 minus 1 -- so that's the\nmatrix that gives me second",
    "start": "2175430",
    "end": "2188160"
  },
  {
    "text": "differences along a typical\nrow or down a typical column.",
    "start": "2188160",
    "end": "2195609"
  },
  {
    "text": "But now what am I looking for? I'm looking to do both --\nsecond differences in a row",
    "start": "2195610",
    "end": "2201180"
  },
  {
    "text": "and a column. So if I pick a typical\nmesh point, like number 11.",
    "start": "2201180",
    "end": "2207319"
  },
  {
    "text": " Mesh point 11 -- let me\nblow up this picture here.",
    "start": "2207320",
    "end": "2214740"
  },
  {
    "text": "It's going to be influenced,\nmesh point 11, by 10 and 12, the second differences in the\nx direction, and by 7 and 15 --",
    "start": "2214740",
    "end": "2223550"
  },
  {
    "text": "notice those are not\nso close to 10 or 11 -- the second differences\nin the y direction.",
    "start": "2223550",
    "end": "2230460"
  },
  {
    "text": "So let me blow that up. So here's mesh point number 11\ncorresponding to row 11 of K2D.",
    "start": "2230460",
    "end": "2240500"
  },
  {
    "start": "2240500",
    "end": "2245540"
  },
  {
    "text": "So I guess I'm asking what\nrow 11 of K2D will look like. So here's mesh points 10 and 12,\nso I have a second difference",
    "start": "2245540",
    "end": "2256710"
  },
  {
    "text": "in the x direction from\nu_xx, for minus u_xx, that",
    "start": "2256710",
    "end": "2261950"
  },
  {
    "text": "means I can put a minus 1 there,\na 2 there and a minus 1 there.",
    "start": "2261950",
    "end": "2267900"
  },
  {
    "text": "Now I have the same in the\ny direction with 15 and 7,",
    "start": "2267900",
    "end": "2273980"
  },
  {
    "text": "so I have a minus 1 in column\n15, a minus 1 in column 7,",
    "start": "2273980",
    "end": "2283220"
  },
  {
    "text": "so I have four minus 1's and\nthen 2 more for the center",
    "start": "2283220",
    "end": "2290060"
  },
  {
    "text": "gives me a 4. So a typical row will have --\nit'll be sparse, of course --",
    "start": "2290060",
    "end": "2297750"
  },
  {
    "text": "it'll have a minus 1 in position\n7, a minus 1 in position 10,",
    "start": "2297750",
    "end": "2304220"
  },
  {
    "text": "a 4, a minus 1, and a minus\n1 over there in position 15.",
    "start": "2304220",
    "end": "2311160"
  },
  {
    "text": "That's a typical row of K2D. It adds to 0. ",
    "start": "2311160",
    "end": "2319130"
  },
  {
    "text": "If Gershgorin got his\nhands on this matrix,",
    "start": "2319130",
    "end": "2324309"
  },
  {
    "text": "he would say that since all\nthe rows -- the 4 will be on --",
    "start": "2324310",
    "end": "2331200"
  },
  {
    "text": "will the 4 be on the diagonal? Yes, the 4 will be on\nthe diagonal all the way.",
    "start": "2331200",
    "end": "2338180"
  },
  {
    "text": "I guess -- let's see a\nlittle bit more clearly what the matrix K2D looks like.",
    "start": "2338180",
    "end": "2344110"
  },
  {
    "text": " This is probably the\nmost studied matrix",
    "start": "2344110",
    "end": "2349670"
  },
  {
    "text": "in numerical analysis because\nit's a model of what stays nice",
    "start": "2349670",
    "end": "2356960"
  },
  {
    "text": "and what gets more difficult as\nyou move into two dimensions.",
    "start": "2356960",
    "end": "2362089"
  },
  {
    "text": "So some things\ncertainly stay nice. Symmetries -- so properties\nof K2D, K2D will be --",
    "start": "2362090",
    "end": "2371790"
  },
  {
    "text": "it'll be symmetric again.  It'll be positive\ndefinite again.",
    "start": "2371790",
    "end": "2377609"
  },
  {
    "start": "2377610",
    "end": "2382930"
  },
  {
    "text": "So what does K2D -- it's 16 by\n16 and a typical row looks like",
    "start": "2382930",
    "end": "2392050"
  },
  {
    "text": "that. That's a typical interior row. What does maybe -- if\nI took the first row,",
    "start": "2392050",
    "end": "2399970"
  },
  {
    "text": "what does the very\nfirst row look like? If I put row one above it. ",
    "start": "2399970",
    "end": "2407410"
  },
  {
    "text": "Let me draw row one. So what's the\ndifference with row one?",
    "start": "2407410",
    "end": "2412730"
  },
  {
    "text": "It's these are boundary values. These are not -- these are going\nto show up on the right-hand",
    "start": "2412730",
    "end": "2418660"
  },
  {
    "text": "side of the equation. They're known numbers. They're not -- they don't\ninvolve unknown things, so the only neighbors\nare 2 and 5.",
    "start": "2418660",
    "end": "2426460"
  },
  {
    "text": "So I'll still have the second\ndifference, minus 1, 2, minus 1, and minus\n1, 2, minus 1 --",
    "start": "2426460",
    "end": "2431990"
  },
  {
    "text": "still this five-point\nmolecule with 4 at the center,",
    "start": "2431990",
    "end": "2437670"
  },
  {
    "text": "but there won't be\nso many neighbors. There'll be the neighbor at\nthe -- just to the right,",
    "start": "2437670",
    "end": "2445320"
  },
  {
    "text": "neighbor number two, and\nthere'll be neighbor number five a little further\nalong and that's it. ",
    "start": "2445320",
    "end": "2452820"
  },
  {
    "text": "It's like the 2\nminus 1 boundary row.",
    "start": "2452820",
    "end": "2458060"
  },
  {
    "text": "It's a boundary row\nand a boundary row hasn't got as many minus\n1's because it hasn't got",
    "start": "2458060",
    "end": "2465780"
  },
  {
    "text": "as many neighboring unknowns. That boundary row would\nhave three neighbors.",
    "start": "2465780",
    "end": "2472940"
  },
  {
    "text": "Row two would have a 4,\nminus 1, minus 1, but not -- nobody there.",
    "start": "2472940",
    "end": "2478720"
  },
  {
    "text": "So now I'm going\nto try to draw K2D. Let me try to draw K2D.",
    "start": "2478720",
    "end": "2486140"
  },
  {
    "text": "I can do it. K2D will have, from the u_xx,\nthe second differences along",
    "start": "2486140",
    "end": "2498290"
  },
  {
    "text": "the rows, it will have --\nI'll have a row, row one,",
    "start": "2498290",
    "end": "2503710"
  },
  {
    "text": "it'll have another K on row two. It'll have a K on\n-- a K for each row.",
    "start": "2503710",
    "end": "2514280"
  },
  {
    "text": "These are blocks now. That's of size N by\nN. All of those are,",
    "start": "2514280",
    "end": "2519359"
  },
  {
    "text": "so the whole thing is\nN squared by N squared. Actually, I'll stop here.",
    "start": "2519360",
    "end": "2526180"
  },
  {
    "text": "If I wanted to create that\nmatrix with the same K on --",
    "start": "2526180",
    "end": "2533569"
  },
  {
    "text": "it's somehow the identity is\nin there and the matrix K is",
    "start": "2533570",
    "end": "2538610"
  },
  {
    "text": "in there and that's\n-- let's see. It's one or the other of those.",
    "start": "2538610",
    "end": "2546530"
  },
  {
    "text": "I guess it's the first one. So what's this\nKronecker product?",
    "start": "2546530",
    "end": "2552000"
  },
  {
    "text": "Now I'm saying what\nthis construction is. It's very valuable, because it\nallows you to create matrices.",
    "start": "2552000",
    "end": "2561270"
  },
  {
    "text": "If you created K as\na sparse matrix and I as a sparse matrix, then\nthe Kronecker product",
    "start": "2561270",
    "end": "2567670"
  },
  {
    "text": "would be automatically dealt\nwith as a sparse matrix. So what's the rule for\na Kronecker product?",
    "start": "2567670",
    "end": "2574740"
  },
  {
    "text": "You take the first matrix,\nwhich is the identity.",
    "start": "2574740",
    "end": "2580090"
  },
  {
    "text": "And the rest 0's. ",
    "start": "2580090",
    "end": "2588740"
  },
  {
    "text": "So that's I. Then\n-- so that's 1D --",
    "start": "2588740",
    "end": "2595330"
  },
  {
    "text": "and then you multiple each --\neach entry in I becomes a block",
    "start": "2595330",
    "end": "2602810"
  },
  {
    "text": "with entry a_(i, j) times this\nguy, K. This'll be the 0 block,",
    "start": "2602810",
    "end": "2608550"
  },
  {
    "text": "this'll be the K block,\nthis'll be the K block. I take those 1's and multiply\nK and those 0's and multiple K",
    "start": "2608550",
    "end": "2615810"
  },
  {
    "text": "and that's what I get. So you see now, the Kronecker\nproduct is a bigger guy.",
    "start": "2615810",
    "end": "2623290"
  },
  {
    "text": "If matrix A was p by p\nand matrix B was q by q,",
    "start": "2623290",
    "end": "2632220"
  },
  {
    "text": "then the Kronecker product\nwould be p times q by p times q.",
    "start": "2632220",
    "end": "2637570"
  },
  {
    "text": "It would be square again.  It would be symmetric if\nA and B are symmetric.",
    "start": "2637570",
    "end": "2646160"
  },
  {
    "text": "Actually, it would have\nvarious nice properties. Its eigenvalues\nwould be the products",
    "start": "2646160",
    "end": "2651810"
  },
  {
    "text": "of the eigenvalues of A\ntimes the eigenvalues of B.",
    "start": "2651810",
    "end": "2656910"
  },
  {
    "text": "It's a very handy\nconstruction and here we saw it in a pretty easy case\nwhere A was only the identity.",
    "start": "2656910",
    "end": "2666000"
  },
  {
    "text": "Well, let me do this case. What does the Kronecker\nrule produce here?",
    "start": "2666000",
    "end": "2671960"
  },
  {
    "text": "So I take this\nfirst matrix and I put it in here, 2, minus 1,\nminus 1, 2, minus 1, minus 1,",
    "start": "2671960",
    "end": "2683430"
  },
  {
    "text": "2.  So that's the matrix K. And\nnow, each of those numbers",
    "start": "2683430",
    "end": "2692200"
  },
  {
    "text": "multiplies the second thing,\nwhich here is I. So it's 2I,",
    "start": "2692200",
    "end": "2698400"
  },
  {
    "text": "minus I, minus I, 2I,\nminus I, minus I, minus I,",
    "start": "2698400",
    "end": "2704210"
  },
  {
    "text": "minus I, 2I, and 2I. ",
    "start": "2704210",
    "end": "2710280"
  },
  {
    "text": "Now that is the second\ndifference matrix that does all the columns. ",
    "start": "2710280",
    "end": "2717650"
  },
  {
    "text": "When I add those -- so now\nI'm going to add that to that. ",
    "start": "2717650",
    "end": "2723840"
  },
  {
    "text": "They're both size n squared. They give me K2D. So the neat construction of\nK2D is Kronecker product kron",
    "start": "2723840",
    "end": "2734470"
  },
  {
    "text": "of I, K plus kron of K, I. That's the matrix and let's look\nat what it actually looks like.",
    "start": "2734470",
    "end": "2745120"
  },
  {
    "text": "We're seeing it block-wise here. We saw it row-wise here.",
    "start": "2745120",
    "end": "2753369"
  },
  {
    "text": "And maybe now we can take one\nmore look at it, assemble it.",
    "start": "2753370",
    "end": "2759200"
  },
  {
    "text": "So K2D -- I plan to add that\nmatrix to that matrix to get",
    "start": "2759200",
    "end": "2768290"
  },
  {
    "text": "K2D. So it will have -- since they\nboth have 2's on the diagonal,",
    "start": "2768290",
    "end": "2775010"
  },
  {
    "text": "it'll have 4's on the\ndiagonal, so 4's all the way, but it'll be block-wise.",
    "start": "2775010",
    "end": "2781460"
  },
  {
    "text": " Up here, this\nblock is K plus 2I.",
    "start": "2781460",
    "end": "2788420"
  },
  {
    "text": "So that block is\n-- goes down to 4. ",
    "start": "2788420",
    "end": "2796870"
  },
  {
    "text": "Now, the K contributed minus\n1's next to the diagonal,",
    "start": "2796870",
    "end": "2804500"
  },
  {
    "text": "and I guess that's it, right? K plus 2I has that block as\n-- that's the one, one block.",
    "start": "2804500",
    "end": "2814120"
  },
  {
    "text": "Why is it -- so we're seeing\n-- did I get it right?",
    "start": "2814120",
    "end": "2820660"
  },
  {
    "text": "Yes, so we're seeing the\nneighbors to the right",
    "start": "2820660",
    "end": "2825859"
  },
  {
    "text": "and left, but now\nlet me bring in --",
    "start": "2825860",
    "end": "2831670"
  },
  {
    "text": "only now comes the neighbor\nabove or below and that comes from this off-diagonal\nblock, minus I,",
    "start": "2831670",
    "end": "2838930"
  },
  {
    "text": "which is then minus\n1's to minus 1's. ",
    "start": "2838930",
    "end": "2846800"
  },
  {
    "text": "These are all 0 blocks. Here will be a minus\nthe identity block.",
    "start": "2846800",
    "end": "2855390"
  },
  {
    "text": "Then another block,\nthe diagonal blocks are all the same,\nand another one,",
    "start": "2855390",
    "end": "2863190"
  },
  {
    "text": "another minus the identity.  Now we're getting to\ninterior mesh points,",
    "start": "2863190",
    "end": "2873040"
  },
  {
    "text": "where we see typical rows. So a typical row has\nthe 4's on the diagonal,",
    "start": "2873040",
    "end": "2878170"
  },
  {
    "text": "the minus 1's left and right,\nand the minus 1's far left and far right -- and of course,\nwhat I'm going to ask you is,",
    "start": "2878170",
    "end": "2886705"
  },
  {
    "text": "what's the bandwidth? ",
    "start": "2886705",
    "end": "2894700"
  },
  {
    "text": "We're coming to\nthe key point now. What's the bandwidth\nof this matrix?",
    "start": "2894700",
    "end": "2900290"
  },
  {
    "text": "I only have two nonzeros above\nthe diagonal on a typical row,",
    "start": "2900290",
    "end": "2906750"
  },
  {
    "text": "but I have to wait n diagonals\nbefore I get to the second one.",
    "start": "2906750",
    "end": "2915540"
  },
  {
    "text": "So the bandwidth is n, because\nI have to wait that long. Then the operation count -- if\nI just do ordinary elimination",
    "start": "2915540",
    "end": "2927890"
  },
  {
    "text": "on this matrix, the operation\nwill be the size of the matrix",
    "start": "2927890",
    "end": "2934690"
  },
  {
    "text": "times the bandwidth squared.  We can easily check that that's\nthe right count of operations",
    "start": "2934690",
    "end": "2945339"
  },
  {
    "text": "for a banded matrix. This is operations\non a banded matrix. ",
    "start": "2945340",
    "end": "2952390"
  },
  {
    "text": "So what do we get? The size of the\nmatrix is N squared.",
    "start": "2952390",
    "end": "2958109"
  },
  {
    "text": "The bandwidth is N,\nand it gets squared, so we get N to the fourth.",
    "start": "2958110",
    "end": "2963870"
  },
  {
    "text": " It's getting up there.",
    "start": "2963870",
    "end": "2969360"
  },
  {
    "text": "If N is 1,000, we've got a\nserious-sized matrix here. Still a very sparse matrix,\nso it's not like give up,",
    "start": "2969360",
    "end": "2980020"
  },
  {
    "text": "but the question is, does\nthe matrix stay sparse",
    "start": "2980020",
    "end": "2985400"
  },
  {
    "text": "as we do elimination? That's the center\nof the next lecture.",
    "start": "2985400",
    "end": "2992090"
  },
  {
    "text": "Can we organize elimination\n-- how closely can we organize elimination to preserve all\nthese zillions of 0's that are",
    "start": "2992090",
    "end": "3001170"
  },
  {
    "text": "between here? They're easy to preserve\ndown here, way up there, but in this intermediate, those\ndiagonals tend to fill in,",
    "start": "3001170",
    "end": "3013880"
  },
  {
    "text": "and that's not a\nhappy experience. And it's even less happy in 3D.",
    "start": "3013880",
    "end": "3020590"
  },
  {
    "text": "So let me just do this\nsame calculation for 3D and then we're done for today.",
    "start": "3020590",
    "end": "3025900"
  },
  {
    "text": "So K3D -- you might like to\nthink how K3D could be created",
    "start": "3025900",
    "end": "3033430"
  },
  {
    "text": "by the kron operation. Let me just imagine it. So what's K3D looking like?",
    "start": "3033430",
    "end": "3039690"
  },
  {
    "text": "I've got three directions,\nso I have a 6 in the center and six minus 1's\nbeside it and so 6 goes",
    "start": "3039690",
    "end": "3049990"
  },
  {
    "text": "on the diagonal of K3D. Six minus 1's go\non a typical row",
    "start": "3049990",
    "end": "3055070"
  },
  {
    "text": "and how long do I have to wait\nuntil I reach the last one? So I'm again going to do\nthe size -- which is --",
    "start": "3055070",
    "end": "3062450"
  },
  {
    "text": "the matrix size is\ngoing to be like N cube, and what's the bandwidth\ngoing to be like?",
    "start": "3062450",
    "end": "3071680"
  },
  {
    "text": "Maybe I'll ask you now. What do you think\nfor the bandwidth? How long -- if I just number\nit in the simplest way --",
    "start": "3071680",
    "end": "3080240"
  },
  {
    "text": "and that'll be\nthe key next time, is there a better numbering? But if I just number along rows\nuntil the rows fill up a plane",
    "start": "3080240",
    "end": "3089870"
  },
  {
    "text": "of rows and then I\nmove up to the next, in the z direction to the plane\nabove, then I have to wait --",
    "start": "3089870",
    "end": "3102790"
  },
  {
    "text": "this was the x and y, so this\ngave me a bandwidth of N, but that's not the bandwidth\nbecause I have to wait until I",
    "start": "3102790",
    "end": "3110839"
  },
  {
    "text": "finish the whole plane, until\nI go up to the next plane and catch this chap, so\nthe bandwidth is N squared.",
    "start": "3110840",
    "end": "3120360"
  },
  {
    "text": "Then the operations, which are\nsize times bandwidth squared,",
    "start": "3120360",
    "end": "3130250"
  },
  {
    "text": "we're up to N^7 and that is\na really horrifying exponent",
    "start": "3130250",
    "end": "3136730"
  },
  {
    "text": "to see, N to the seventh. That means that even\nfor a moderate --",
    "start": "3136730",
    "end": "3142770"
  },
  {
    "text": "a problem in 3D with\na moderate number, say 1,000 unknowns at\neach direction, we have --",
    "start": "3142770",
    "end": "3152320"
  },
  {
    "text": "we're looking, in theory, at\na cost that we can't afford.",
    "start": "3152320",
    "end": "3162050"
  },
  {
    "text": "Of course, there's\na lot to do here.",
    "start": "3162050",
    "end": "3167160"
  },
  {
    "text": "So there's a lot to do if\nI stay with direct methods and that's what I'll do for\nthe next couple of lectures.",
    "start": "3167160",
    "end": "3174270"
  },
  {
    "text": "Then it's really in 3D\nthat iterative methods",
    "start": "3174270",
    "end": "3180940"
  },
  {
    "text": "become essential. I mean, this one, I could\ndo those by direct methods, 2D, by a smarter direct method\nthan any I've tried here,",
    "start": "3180940",
    "end": "3192510"
  },
  {
    "text": "but in 3D, even\nsmarter elimination",
    "start": "3192510",
    "end": "3197670"
  },
  {
    "text": "is facing a serious exponent\nand loses to iterative methods.",
    "start": "3197670",
    "end": "3207369"
  },
  {
    "text": "So that's what's\ncoming, actually. So today's lecture, you\nsee, with the simplest",
    "start": "3207370",
    "end": "3212920"
  },
  {
    "text": "possible matrices, what\nthe central questions are. Thanks and I've got homeworks\ncoming back from Mr. Cho",
    "start": "3212920",
    "end": "3225400"
  },
  {
    "text": "and I'll collect any that are\nready to come in and see you Wednesday.",
    "start": "3225400",
    "end": "3231010"
  },
  {
    "start": "3231010",
    "end": "3237952"
  }
]
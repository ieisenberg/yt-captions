[
  {
    "text": "The following content is\nprovided under a Creative Commons license. Your support will help MIT\nOpenCourseWare continue to",
    "start": "0",
    "end": "6590"
  },
  {
    "text": "offer high quality educational\nresources for free. To make a donation or to view\nadditional materials from",
    "start": "6590",
    "end": "12810"
  },
  {
    "text": "hundreds of MIT courses, visit\nMIT OpenCourseWare at ocw.mit.edu.",
    "start": "12810",
    "end": "17820"
  },
  {
    "start": "17820",
    "end": "23260"
  },
  {
    "text": "PROFESSOR: I want to start out\ntoday by reviewing what we covered last time.",
    "start": "23260",
    "end": "29330"
  },
  {
    "text": "We sort of covered two lectures\nof material, but a little bit lightly last time\nbecause I want to spend more",
    "start": "29330",
    "end": "37120"
  },
  {
    "text": "time starting today dealing with\nwave forms and functions.",
    "start": "37120",
    "end": "43469"
  },
  {
    "text": "We will get notes on that\nvery, very shortly. ",
    "start": "43470",
    "end": "50840"
  },
  {
    "text": "To review quantization, we\nstarted out by talking about scalar quantizers, in other\nwords, the thing that we want",
    "start": "50840",
    "end": "59860"
  },
  {
    "text": "to do is to take a sequence of\nreal numbers and each of those real numbers we want to\nquantizers it into one of a",
    "start": "59860",
    "end": "68930"
  },
  {
    "text": "finite set of symbols. Then, of course, the symbols\nwe're going to",
    "start": "68930",
    "end": "75100"
  },
  {
    "text": "encode later on. So basically what we're doing is\nwe're taking the real line,",
    "start": "75100",
    "end": "82820"
  },
  {
    "text": "we're splitting it into a bunch\nof regions, r1, r2, r3.",
    "start": "82820",
    "end": "89350"
  },
  {
    "text": "The last region of the\nfirst region goes off to minus infinity. The last region goes off\nto plus infinity.",
    "start": "89350",
    "end": "97330"
  },
  {
    "text": "So that clearly, if there's a\nlot of probability over in here or a lot of probably over\nin here, you're going to have",
    "start": "97330",
    "end": "105170"
  },
  {
    "text": "a very large distortion. So, when we talk more about that\nlater and talk about how",
    "start": "105170",
    "end": "111880"
  },
  {
    "text": "to avoid it and why we\nshould avoid it and all of these things. We then talked about these\nLloyd-Max conditions for",
    "start": "111880",
    "end": "120240"
  },
  {
    "text": "minimum mean square error. What we said last time was\nsuppose somebody gives you",
    "start": "120240",
    "end": "128179"
  },
  {
    "text": "these representation points,\nwhich you're going to use to represent the actual number on\nthe real line that comes out.",
    "start": "128180",
    "end": "138300"
  },
  {
    "text": "Then you ask when some\nparticular number occurs should we encode it into this\npoint or into this point?",
    "start": "138300",
    "end": "148250"
  },
  {
    "text": "If our criterion is mean square\nerror, and that's what our criterion is normally going\nto be, then we're going",
    "start": "148250",
    "end": "157099"
  },
  {
    "text": "to minimize the mean square\nerror for this particular point by mapping it here, if\nthat's the most probable --",
    "start": "157100",
    "end": "165090"
  },
  {
    "text": " we're going to map it here if\nthis is the closest point, and",
    "start": "165090",
    "end": "171875"
  },
  {
    "text": "we're going to map it here if\nthat's the closest point. Because by doing this we\nminimize the squared error",
    "start": "171875",
    "end": "179280"
  },
  {
    "text": "between b and a1 or b and a2. So, that says that we're going\nto define these regions to",
    "start": "179280",
    "end": "188780"
  },
  {
    "text": "have the separations between\nthe regions at the bisector",
    "start": "188780",
    "end": "194150"
  },
  {
    "text": "points between the\nrepresentation points. So that says that one of the\nLloyd-Max conditions for",
    "start": "194150",
    "end": "200460"
  },
  {
    "text": "minimum mean square error is you\nalways want to choose the regions in such a way that\nthey're the mid-points between",
    "start": "200460",
    "end": "208230"
  },
  {
    "text": "the representation points. Any minimum mean square error\nquantizers has to satisfy this",
    "start": "208230",
    "end": "215750"
  },
  {
    "text": "condition for each of the j's. Namely, for each of these\npoints they have to be",
    "start": "215750",
    "end": "222200"
  },
  {
    "text": "mid-points. Then the other thing that we\nobserved is that once we choose these regions, the way\nwe want to choose the",
    "start": "222200",
    "end": "230520"
  },
  {
    "text": "representation points to\nminimize the mean square error",
    "start": "230520",
    "end": "235830"
  },
  {
    "text": "is we now have to look at the\nprobability density on this real line and we have to choose\nthese points to be the",
    "start": "235830",
    "end": "243090"
  },
  {
    "text": "conditional means within the\nrepresentation area. That just comes out by formula\nto be the expected value of",
    "start": "243090",
    "end": "252190"
  },
  {
    "text": "the random variable u, which is\nthis value as it occurs on",
    "start": "252190",
    "end": "258480"
  },
  {
    "text": "the real line. The expected value of that\nconditional on being in region",
    "start": "258480",
    "end": "264450"
  },
  {
    "text": "rj is just the integral\nof u times the",
    "start": "264450",
    "end": "271850"
  },
  {
    "text": "conditional density of u. The conditional density of u\nis the real density of u",
    "start": "271850",
    "end": "279010"
  },
  {
    "text": "divided by the probability\nof being in that region. So all of this is very simple.",
    "start": "279010",
    "end": "284530"
  },
  {
    "text": "I hope you see it as something\nwhich is almost trivial, because if you don't see it as\nsomething simple, go back and",
    "start": "284530",
    "end": "293270"
  },
  {
    "text": "look at it because, in fact,\nthis is not rocket science",
    "start": "293270",
    "end": "298560"
  },
  {
    "text": "here, this is just what\nyou would normally do. ",
    "start": "298560",
    "end": "305800"
  },
  {
    "text": "So Lloyd-Max algorithm then\nsays alternate between the conditions for the mid-points\nbetween the regions and the",
    "start": "305800",
    "end": "314159"
  },
  {
    "text": "conditional means. The Lloyd-Max conditions are\nnecessary but not sufficient.",
    "start": "314160",
    "end": "320800"
  },
  {
    "text": "In other words, any time you\nfind a minimum mean square error quantization, it's going\nto satisfy those conditions.",
    "start": "320800",
    "end": "330030"
  },
  {
    "text": "But if you find a set of points,\nb sub j, and a set of points, a sub j, which satisfy\nthose conditions, it doesn't",
    "start": "330030",
    "end": "338889"
  },
  {
    "text": "necessarily mean that\nyou have a minimum. In other words, there are often\nmultiple sets of points",
    "start": "338890",
    "end": "347620"
  },
  {
    "text": "which satisfy the Lloyd-Max\nconditions, and one or more of",
    "start": "347620",
    "end": "355930"
  },
  {
    "text": "those is going to be optimum,\nis going to be the smallest one, and the others are not\ngoing to be optimum. In other words, the algorithm\nis a local hill-climbing",
    "start": "355930",
    "end": "365870"
  },
  {
    "text": "algorithm, which finds the best\nthing it can find which",
    "start": "365870",
    "end": "371620"
  },
  {
    "text": "is close to where it's starting\nat some very strange sense of close.",
    "start": "371620",
    "end": "376810"
  },
  {
    "text": "The close is not any sense of\nmean square error, but close is defined in terms of where the\nalgorithm happens to go.",
    "start": "376810",
    "end": "385670"
  },
  {
    "text": "So an example of that that we\ntalked about last time is where you have three spikes\nof probability.",
    "start": "385670",
    "end": "392470"
  },
  {
    "text": "Two of them are smaller and\none of them is bigger. One of them is at minus 1, one\nof them is at zero, one of",
    "start": "392470",
    "end": "400510"
  },
  {
    "text": "them is at plus 1. One solution to the Lloyd-Max\nconditions is this one here",
    "start": "400510",
    "end": "408760"
  },
  {
    "text": "where a1 is sitting right in\nthe middle of the spike. Therefore, any time that the\nsample value of the random",
    "start": "408760",
    "end": "418610"
  },
  {
    "text": "variable is over here, you get\nvirtually no distortion.",
    "start": "418610",
    "end": "424860"
  },
  {
    "text": "The other point is sitting at\nthe conditional mean between",
    "start": "424860",
    "end": "431169"
  },
  {
    "text": "these two points. So it's a little closer\nto this one than it is to this one -- I hope the figure shows that.",
    "start": "431170",
    "end": "439570"
  },
  {
    "text": "Any time you wind up here or\nhere, you get this amount of",
    "start": "439570",
    "end": "444640"
  },
  {
    "text": "the distortion. Now without making any\ncalculations you just look at this and you say well,\nthis spike is bigger",
    "start": "444640",
    "end": "452470"
  },
  {
    "text": "than this spike is. Therefore, it makes sense if\nwe're going to do this kind of",
    "start": "452470",
    "end": "458210"
  },
  {
    "text": "strategy to put a 2 underneath\nthat spike, therefore, getting",
    "start": "458210",
    "end": "464280"
  },
  {
    "text": "a very small distortion any\ntime the big spike occurs.",
    "start": "464280",
    "end": "470150"
  },
  {
    "text": "Then a1 is going to be midway\nbetween these two points, and you get the larger amount of\ndistortion there but now it's",
    "start": "470150",
    "end": "477880"
  },
  {
    "text": "a less probable event. So you can easily check that\nboth of these solutions",
    "start": "477880",
    "end": "484180"
  },
  {
    "text": "satisfy the Lloyd-Max\nconditions, but one of them turns out to be optimal and the\nother one turns out to be",
    "start": "484180",
    "end": "492580"
  },
  {
    "text": "not optimal. If you fiddle around with it\nfor a while, you can pretty much convince yourself that\nthose are the only solutions",
    "start": "492580",
    "end": "504169"
  },
  {
    "text": "to the Lloyd-Max algorithm for\nthis particular problem. Yeah?",
    "start": "504170",
    "end": "509650"
  },
  {
    "text": "AUDIENCE: When there's a\nregion that has zero probability throughout, and the\nLloyd-Max algorithm tries",
    "start": "509650",
    "end": "516729"
  },
  {
    "text": "to find the mean for that\nregion, it's going to find somewhere outside the region,\nit will find zero as the",
    "start": "516730",
    "end": "524302"
  },
  {
    "text": "expected value. But that might not necessarily\nbe inside that region, what",
    "start": "524302",
    "end": "529783"
  },
  {
    "text": "does it do in that case? PROFESSOR: What does\nit do in that case? Well, I don't think you\ncan argue that it's",
    "start": "529783",
    "end": "537700"
  },
  {
    "text": "going to be at zero. I think you have to argue that\nit might be anywhere that it wants to be.",
    "start": "537700",
    "end": "543680"
  },
  {
    "text": "Therefore, what the algorithm is\ngoing to do when you start with a certain set of\nrepresentation points --",
    "start": "543680",
    "end": "549300"
  },
  {
    "text": " well, if you start with a\ncertain set of representation",
    "start": "549300",
    "end": "556120"
  },
  {
    "text": "points that picks that separater\nwherever it happens to be, than this particular\npoint you're talking about is",
    "start": "556120",
    "end": "561769"
  },
  {
    "text": "going to be at some completely\nunimportant place.",
    "start": "561770",
    "end": "567390"
  },
  {
    "text": "You know eventually the thing\nthat's going to happen is that this thing that's in a region of\nno probability is going to",
    "start": "567390",
    "end": "575430"
  },
  {
    "text": "spread out and include something\nthat has some probability, and then you're\ngoing to nail that region with",
    "start": "575430",
    "end": "581579"
  },
  {
    "text": "some probability. I can't prove this to you, and\nI'm not even sure that it's",
    "start": "581580",
    "end": "586750"
  },
  {
    "text": "always true, but I think if you\ntry a couple of examples",
    "start": "586750",
    "end": "591780"
  },
  {
    "text": "you will see that it sort\nof does the right thing. AUDIENCE: But in the algorithm,\nyou replace the",
    "start": "591780",
    "end": "597640"
  },
  {
    "text": "point at the point of expected\nvalue in that region. So, the algorithm doesn't know\nwhat to do at that point.",
    "start": "597640",
    "end": "605840"
  },
  {
    "text": "It crashes. PROFESSOR: Well, unless you're\nsmart enough to write the",
    "start": "605840",
    "end": "611779"
  },
  {
    "text": "program to do something\nsensible, yes. AUDIENCE:\n[UNINTELLIGIBLE PHRASE]. PROFESSOR: Yes.",
    "start": "611780",
    "end": "617300"
  },
  {
    "text": "And you have to write\nit so it'll do something reasonable then. The best thing to do is to start\nout without having any",
    "start": "617300",
    "end": "624340"
  },
  {
    "text": "of the regions have\nzero probability. AUDIENCE: We have that\n[UNINTELLIGIBLE PHRASE]. ",
    "start": "624340",
    "end": "631960"
  },
  {
    "text": "PROFESSOR: All right. Well then you have to use\nsome common sense on it. ",
    "start": "631960",
    "end": "645740"
  },
  {
    "text": "So, after that we say OK, well\njust like when we were dealing",
    "start": "645740",
    "end": "657060"
  },
  {
    "text": "with discrete source coding,\nany time we finish talking about encoding a single letter,\nwe talk about what",
    "start": "657060",
    "end": "664050"
  },
  {
    "text": "happens when you\nencode multiple letters in the same way. Somebody is bound to think of\nthe idea of encoding multiple",
    "start": "664050",
    "end": "675320"
  },
  {
    "text": "real numbers all together. So they're going to think of\nthe idea of taking this sequence of real numbers,\nsegmenting it into blocks of n",
    "start": "675320",
    "end": "683820"
  },
  {
    "text": "numbers each and then taking\nthe set of n numbers and",
    "start": "683820",
    "end": "690120"
  },
  {
    "text": "trying to find a reasonable\nquantization for that. In that case, the quantization\npoints are",
    "start": "690120",
    "end": "696060"
  },
  {
    "text": "going to be n vectors. The regions are going\nto be regions in n dimensional space.",
    "start": "696060",
    "end": "702470"
  },
  {
    "text": "Well, if you think about it\na little bit, these n dimensional representation\npoints, if you're given them,",
    "start": "702470",
    "end": "711740"
  },
  {
    "text": "the place where you're going to\nestablish the regions then is on the perpendicular\nbisectors",
    "start": "711740",
    "end": "718550"
  },
  {
    "text": "between any two points. Namely, for each two points\nyou're going to establish a perpendicular bisector between\nthose two points, you're going",
    "start": "718550",
    "end": "726400"
  },
  {
    "text": "to do that for all\nsets of points. You're going to take regions\nwhich are enclosed by all of",
    "start": "726400",
    "end": "732629"
  },
  {
    "text": "those perpendicular bisectors,\nand you call those the voronoi region. Remember, I drew an example of\nit last time that looked",
    "start": "732630",
    "end": "741750"
  },
  {
    "text": "something like this. You have various\npoints around.",
    "start": "741750",
    "end": "749290"
  },
  {
    "text": "It's hard to draw it in more\nthan two dimensions. So these perpendicular\nbisectors go",
    "start": "749290",
    "end": "755519"
  },
  {
    "text": "like this and so forth.",
    "start": "755520",
    "end": "767760"
  },
  {
    "text": "I think you can show that you've\nnever had the situation -- interesting problem if you\nwant to play with it.",
    "start": "767760",
    "end": "778230"
  },
  {
    "text": "I don't think you can have that,\nbut I'm not sure why. ",
    "start": "778230",
    "end": "786000"
  },
  {
    "text": "Anyway, you do have these\nvoronoi regions. You have these perpendicular\nbisectors that you set up in",
    "start": "786000",
    "end": "791150"
  },
  {
    "text": "two dimensional space or in\nhigh dimensional space. Then given those regions\nyou can then establish",
    "start": "791150",
    "end": "799649"
  },
  {
    "text": "representation points, which are\nat the conditional means within those regions.",
    "start": "799650",
    "end": "806149"
  },
  {
    "text": "You really have the same problem\nthat you had before, it's just a much grubbier\nproblem because it's using",
    "start": "806150",
    "end": "812180"
  },
  {
    "text": "vectors, it's an n dimensional\nspace. For this reason this problem\nwas enormously popular for",
    "start": "812180",
    "end": "818290"
  },
  {
    "text": "many, many years, because\nmany people loved the complexity of it. It was really neat\nto write computer",
    "start": "818290",
    "end": "824690"
  },
  {
    "text": "programs that did this. Back in those days you had to\nbe careful about computer",
    "start": "824690",
    "end": "830210"
  },
  {
    "text": "programs because computation\nwas very, very slow, and it",
    "start": "830210",
    "end": "835440"
  },
  {
    "text": "was a lot of fun. When you get all done with it,\nyou don't gain much by doing",
    "start": "835440",
    "end": "841550"
  },
  {
    "text": "any of that. The one thing that you do gain\nis that if you take square",
    "start": "841550",
    "end": "849350"
  },
  {
    "text": "regions, namely, if you take a\nwhole bunch of points which are laid out on a rectangular\ngrid and you take regions",
    "start": "849350",
    "end": "857910"
  },
  {
    "text": "which are now little rectangles\nor little squares, and you look at them for a\nwhile, you say that's not a",
    "start": "857910",
    "end": "865270"
  },
  {
    "text": "very good thing to do. A better thing to do is to take\nall this two dimensional",
    "start": "865270",
    "end": "871370"
  },
  {
    "text": "space, for example, and to fill\nit in to tile it we say with hexagons as opposed to\ntiling it with rectangles or",
    "start": "871370",
    "end": "881350"
  },
  {
    "text": "to tiling it with squares. If you tile it with hexagons,\nfor given amount of area you",
    "start": "881350",
    "end": "889360"
  },
  {
    "text": "get a smaller mean\nsquare error. If you could tile it with\ncircles that would be the best",
    "start": "889360",
    "end": "895150"
  },
  {
    "text": "of all, but when you try to tile\nit with circles you find out there's all this stuff left\nin the middle, like if",
    "start": "895150",
    "end": "901910"
  },
  {
    "text": "you've ever tried to tile a\nfloor with circles you find out you have to fill it\nin somehow and it's",
    "start": "901910",
    "end": "907280"
  },
  {
    "text": "a little bit awkward. So hexagons work,\ncircles don't. If you then go on to a higher\nnumber of dimensions, you get",
    "start": "907280",
    "end": "916610"
  },
  {
    "text": "the same sort of thing\nhappening, you get these nice n dimensional shapes\nwhich will tile",
    "start": "916610",
    "end": "923130"
  },
  {
    "text": "n dimensional volume. As n gets larger and larger,\nthese tiling volumes become",
    "start": "923130",
    "end": "932160"
  },
  {
    "text": "closer and closer to spheres,\nand you can prove all sorts of theorems about that.",
    "start": "932160",
    "end": "937970"
  },
  {
    "text": "But the trouble is when you\nget all done you haven't gained very much, except you\nhave a much more complex",
    "start": "937970",
    "end": "944769"
  },
  {
    "text": "problem to solve. But you don't have a much\nsmaller mean square distortion.",
    "start": "944770",
    "end": "950480"
  },
  {
    "text": "So you can still\nuse Lloyd-Max. Lloyd-Max still has as many\nproblems as it had before in",
    "start": "950480",
    "end": "957410"
  },
  {
    "text": "finding local minima. With a little bit of thought\nabout it you can see it's going to have a lot\nmore problems.",
    "start": "957410",
    "end": "963750"
  },
  {
    "text": "Because visualize starting\nLloyd-Max out where your",
    "start": "963750",
    "end": "968770"
  },
  {
    "text": "points are on a square grid and\nwhere your regions now are",
    "start": "968770",
    "end": "973940"
  },
  {
    "text": "a little square. So in other words, like this. ",
    "start": "973940",
    "end": "988209"
  },
  {
    "text": "Try to think of how the\nalgorithm is going to go from that to the hexagons that\nyou would rather have.",
    "start": "988210",
    "end": "995980"
  },
  {
    "text": "You can see pretty easily that\nit's very unlikely that the algorithm was ever going to\nfind its way to hexagons,",
    "start": "995980",
    "end": "1003529"
  },
  {
    "text": "which by looking at it a little\nfurther away we can see it's clearly a good\nthing to do.",
    "start": "1003530",
    "end": "1009350"
  },
  {
    "text": "In other words, Lloyd-Max\nalgorithm doesn't have any vision. It can't see beyond\nits own nose.",
    "start": "1009350",
    "end": "1016980"
  },
  {
    "text": "It just takes these points and\nlooks for regions determined by neighboring points, but it\ndoesn't have the sense to look",
    "start": "1016980",
    "end": "1025319"
  },
  {
    "text": "for what kind of structure\nyou want. So anyway, Lloyd-Max becomes\nworse and worse in those",
    "start": "1025320",
    "end": "1034699"
  },
  {
    "text": "situations and the problem\ngets uglier and uglier.",
    "start": "1034700",
    "end": "1040909"
  },
  {
    "text": "Then, as we said last time, we\nstop and think and we said well gee, we weren't solving\nthe right problem anyway.",
    "start": "1040910",
    "end": "1048660"
  },
  {
    "text": "As often happens when a problem\ngets very popular, people start out properly by\nsaying well I don't know how",
    "start": "1048660",
    "end": "1056399"
  },
  {
    "text": "to solve the real problem\nso I'll try to solve a toy problem. Then somehow the toy problem\ngets a life of its own because",
    "start": "1056400",
    "end": "1065370"
  },
  {
    "text": "people write many papers about\nit and students think since there are many papers\nabout it, it must be",
    "start": "1065370",
    "end": "1070850"
  },
  {
    "text": "an important problem. Then since there are these open\nproblems, students can solve those open problems and\nget PhD theses, and then they",
    "start": "1070850",
    "end": "1080580"
  },
  {
    "text": "got a in a university, and the\neasiest thing for them to do is to get 10 students working on\nthe same class of problems",
    "start": "1080580",
    "end": "1088700"
  },
  {
    "text": "and you see what happens. I'm not criticizing the students\nwho do that or the",
    "start": "1088700",
    "end": "1093710"
  },
  {
    "text": "faculty members who do it,\nthey're all trapped in this kind of crazy system.",
    "start": "1093710",
    "end": "1099020"
  },
  {
    "text": "Anyway, the right problem that\nwe should have started with is",
    "start": "1099020",
    "end": "1104380"
  },
  {
    "text": "when we look at the problem of\nquantization followed by discrete source coding, we\nshould have said that what",
    "start": "1104380",
    "end": "1113140"
  },
  {
    "text": "we're interested in is not the\nnumber of quantization levels, but rather the entropy of the\nset of quantization levels.",
    "start": "1113140",
    "end": "1121540"
  },
  {
    "text": "That's the important thing\nbecause that's the thing that determines how many bits we're\ngoing to need to encode these",
    "start": "1121540",
    "end": "1128220"
  },
  {
    "text": "symbols that come out\nof the quantizer. So the problem we'd like to\nsolve is to find the minimum",
    "start": "1128220",
    "end": "1133850"
  },
  {
    "text": "mean square error quantizer\nfor a given representation point entropy.",
    "start": "1133850",
    "end": "1140370"
  },
  {
    "text": "In other words, whatever set of\npoints you have, you want to minimize the entropy\nof that set of points.",
    "start": "1140370",
    "end": "1146000"
  },
  {
    "text": "What that's going to do is to\ngive you a larger set of points, but some points with\na very small probability.",
    "start": "1146000",
    "end": "1152630"
  },
  {
    "text": "Therefore, those points with a\nvery small probability are not going to happen very often.",
    "start": "1152630",
    "end": "1158400"
  },
  {
    "text": "Therefore, they don't affect\nthe entropy very much, and therefore, you get a lot of gain\nin terms of mean square",
    "start": "1158400",
    "end": "1164159"
  },
  {
    "text": "error by using these very\nimprobable points. ",
    "start": "1164160",
    "end": "1170260"
  },
  {
    "text": "That's a very nasty\nproblem to solve. And again, we said well\nlet's try to solve a",
    "start": "1170260",
    "end": "1176410"
  },
  {
    "text": "simpler version of it. A simpler version of it is first\nto go back to the one",
    "start": "1176410",
    "end": "1182830"
  },
  {
    "text": "dimensional case and then say\nOK, what happens if we just use a uniform quantizer, because\nthat's what most",
    "start": "1182830",
    "end": "1190860"
  },
  {
    "text": "people use in practice anyway. If we use a uniform quantizer\nand we talk about a high rate",
    "start": "1190860",
    "end": "1198430"
  },
  {
    "text": "uniform quantizer, in other\nwords, we make the quantization points close\ntogether, what's going to",
    "start": "1198430",
    "end": "1203940"
  },
  {
    "text": "happen in that case? Well, the probability of each\nquantization region in that",
    "start": "1203940",
    "end": "1210740"
  },
  {
    "text": "case is going to be close to the\nsize of the representation",
    "start": "1210740",
    "end": "1218630"
  },
  {
    "text": "interval, in other words, of\nthe quantization interval, times the probability density\nwithin that interval.",
    "start": "1218630",
    "end": "1225530"
  },
  {
    "text": "Namely, if we have a probability\ndensity and that probability density is smooth,\nthen if you take very, very",
    "start": "1225530",
    "end": "1233650"
  },
  {
    "text": "small intervals you're going to\nhave a probability density that doesn't change much\nwithin that interval.",
    "start": "1233650",
    "end": "1240570"
  },
  {
    "text": "Therefore, the probability of\nthe interval is just going to be the size of that quantization\ninterval -- in a",
    "start": "1240570",
    "end": "1246470"
  },
  {
    "text": "uniform quantizer you'll make\nall of the intervals the same -- times the density within\nthat integral.",
    "start": "1246470",
    "end": "1253710"
  },
  {
    "text": "Then we say OK, let's look at\nwhat the entropy is of that set of points, of the set of\npoints where the probabilities",
    "start": "1253710",
    "end": "1260740"
  },
  {
    "text": "are chosen to be some small\ndelta times the probability density there.",
    "start": "1260740",
    "end": "1266360"
  },
  {
    "text": "I'm going through a slightly\nsimpler kind of argument today than I did last time, and I'll\nexplain why I'm doing",
    "start": "1266360",
    "end": "1273330"
  },
  {
    "text": "something simpler today and\nwhy I did something more complicated then. ",
    "start": "1273330",
    "end": "1279600"
  },
  {
    "text": "So this entropy is\nthis quantity. If we now substitute delta times\nthe density for pj here,",
    "start": "1279600",
    "end": "1288640"
  },
  {
    "text": "we get the sum over j of this\ndelta pj, which is the probability density times the\nlogarithm of delta pj.",
    "start": "1288640",
    "end": "1298780"
  },
  {
    "text": "Well now look, the logarithm of\ndelta pj is just logarithm of delta plus logarithm of pj.",
    "start": "1298780",
    "end": "1307010"
  },
  {
    "text": "So we're taking the sum over all\nthe probability space of logarithm of delta.",
    "start": "1307010",
    "end": "1312200"
  },
  {
    "text": "That comes out. So we get a minus log delta, and\nwhat's left is minus the",
    "start": "1312200",
    "end": "1317890"
  },
  {
    "text": "sum of delta pj log pj. Does that look like something?",
    "start": "1317890",
    "end": "1324350"
  },
  {
    "text": "That looks exactly like the\napproximation to an integral",
    "start": "1324350",
    "end": "1329760"
  },
  {
    "text": "that you always talk about. Namely, if you look at a\nReimann integral, the",
    "start": "1329760",
    "end": "1335030"
  },
  {
    "text": "fundamental way to define a\nReimann integral is in terms of splitting up that integral\ninto lots of little",
    "start": "1335030",
    "end": "1342419"
  },
  {
    "text": "increments, taking the value of\nthe function in each one of those increments, multiplying\nit by the size of the",
    "start": "1342420",
    "end": "1350000"
  },
  {
    "text": "increments and adding\nthem all up. In fact, we're going to do that\na little later today when",
    "start": "1350000",
    "end": "1355289"
  },
  {
    "text": "I try to explain to you what\nthe difference is between Reimann integration and\nLebesgue integration.",
    "start": "1355290",
    "end": "1361360"
  },
  {
    "text": "should Don't be frightened\nif you've never taken any mathematics courses, because\nif people had taught you",
    "start": "1361360",
    "end": "1369990"
  },
  {
    "text": "Lebesgue integration when you\nwere freshmen at MIT or seniors in high school or\nwhenever you learned about",
    "start": "1369990",
    "end": "1377300"
  },
  {
    "text": "integration, it would have\nbeen just as simple as teaching about Reimann\nintegration. One is no simpler and no more\ncomplicated than the other, so",
    "start": "1377300",
    "end": "1386530"
  },
  {
    "text": "we're really going back to study\nsomething you should have learned about five\nyears ago, maybe.",
    "start": "1386530",
    "end": "1392909"
  },
  {
    "text": "So anyway, when we represent\nthis as an integral, we get",
    "start": "1392910",
    "end": "1398020"
  },
  {
    "text": "this thing called the\ndifferential entropy, which is the integral of p of u minus\np of u times log of p of u.",
    "start": "1398020",
    "end": "1406810"
  },
  {
    "text": "So the entropy of the discrete\nrepresentation is minus log delta plus this differential\nentropy.",
    "start": "1406810",
    "end": "1416070"
  },
  {
    "text": "The mean square error in this\nuniform quantizer, the conditional means according to\nthis approximation are right",
    "start": "1416070",
    "end": "1424399"
  },
  {
    "text": "in the middle of\nthe intervals. So we have a uniform probability\ninterval of width",
    "start": "1424400",
    "end": "1430630"
  },
  {
    "text": "delta, a point right in the\nmiddle of it, and even I can integrate that to find the mean\nsquare error in it, which",
    "start": "1430630",
    "end": "1438370"
  },
  {
    "text": "is delta squared over 12, which\nI think you've done at least once in the\nhomework by now.",
    "start": "1438370",
    "end": "1443620"
  },
  {
    "start": "1443620",
    "end": "1449820"
  },
  {
    "text": "So I said I was going to tell\nyou why I went through doing it this simpler way this time\nand put in a lot more",
    "start": "1449820",
    "end": "1456940"
  },
  {
    "text": "notation last time. If you really try to trace\nthrough what the",
    "start": "1456940",
    "end": "1462159"
  },
  {
    "text": "approximations are here, the\nway we did it last time is much, much better, because then\nyou can trace through",
    "start": "1462160",
    "end": "1469490"
  },
  {
    "text": "what's happening in those\napproximations, and you can see, as delta goes to zero,\nwhat's happened.",
    "start": "1469490",
    "end": "1474840"
  },
  {
    "text": "Yes? AUDIENCE: This may be an obvious\nquestion, why did you",
    "start": "1474840",
    "end": "1479971"
  },
  {
    "text": "substitute delta with pj\n[INAUDIBLE PHRASE]? ",
    "start": "1479972",
    "end": "1486550"
  },
  {
    "text": "PROFESSOR: Oh, why did I--? OK, this is the probability of\nthe representation of the j's",
    "start": "1486550",
    "end": "1494260"
  },
  {
    "text": "representation point. This is the probability\ndensity around that",
    "start": "1494260",
    "end": "1499790"
  },
  {
    "text": "representation point. The assumption I'm making here\nis that f of u was constant",
    "start": "1499790",
    "end": "1505230"
  },
  {
    "text": "over that interval. And if the density is constant\nover the interval, if I have a",
    "start": "1505230",
    "end": "1511500"
  },
  {
    "text": "density which is constant over\nan interval of width delta,",
    "start": "1511500",
    "end": "1516990"
  },
  {
    "text": "than the probability of landing\nin that interval is the width times the height. AUDIENCE: I think there's\na typo in your",
    "start": "1516990",
    "end": "1524177"
  },
  {
    "text": "[UNINTELLIGIBLE PHRASE]. PROFESSOR: A typo? AUDIENCE:\n[UNINTELLIGIBLE PHRASE]. ",
    "start": "1524177",
    "end": "1544500"
  },
  {
    "text": "PROFESSOR: Yes, yes, yes. I'm sorry, yes. I'm blind today.",
    "start": "1544500",
    "end": "1551070"
  },
  {
    "text": "I knew what I meant so\nwell that I didn't -- thank you.",
    "start": "1551070",
    "end": "1556250"
  },
  {
    "text": "s of uj. s of uj.",
    "start": "1556250",
    "end": "1562350"
  },
  {
    "text": "Yes. Then I take out the delta and\nwhat I'm left with is the",
    "start": "1562350",
    "end": "1569240"
  },
  {
    "text": "delta f of uj times the\nlog of f of uj.",
    "start": "1569240",
    "end": "1578980"
  },
  {
    "text": "Thank you. When I look at that it's delta\ntimes the probability density",
    "start": "1578980",
    "end": "1585520"
  },
  {
    "text": "times the log of the probability\ndensity. If I convert that now into an\ninterval when delta is very",
    "start": "1585520",
    "end": "1592480"
  },
  {
    "text": "small, I get this thing called\nthe differential entropy. Does that make a little\nmore sense?",
    "start": "1592480",
    "end": "1599610"
  },
  {
    "text": "So your question was obvious,\nit was just that I was a total dummy. ",
    "start": "1599610",
    "end": "1610789"
  },
  {
    "text": "So let's summarize what\nall of that says. ",
    "start": "1610790",
    "end": "1616260"
  },
  {
    "text": "In the scalar case\nwe're saying -- I have said but I have\nnot shown --",
    "start": "1616260",
    "end": "1622200"
  },
  {
    "text": "that a uniform scalar quantizer\napproaches an optimal scaler quantizer.",
    "start": "1622200",
    "end": "1629010"
  },
  {
    "text": "I haven't explained it all\nin class why that's true. There's an argument in the\nnotes that points it out.",
    "start": "1629010",
    "end": "1635490"
  },
  {
    "text": "You can read that there. It's just another optimization,\nbut it's true if",
    "start": "1635490",
    "end": "1647330"
  },
  {
    "text": "you're looking at a higher\nand higher rate, a scaler quantizer where delta gets\nsmaller and smaller, then in",
    "start": "1647330",
    "end": "1655270"
  },
  {
    "text": "general what you need is to take\na different size delta for each quantization region and\nthen look at what happens",
    "start": "1655270",
    "end": "1661700"
  },
  {
    "text": "when you try to optimize over\nthat and you find out that you want to make all of the\ndeltas the same.",
    "start": "1661700",
    "end": "1668520"
  },
  {
    "text": "The required number of encoded\nbits per symbol depends only on h of u and on delta.",
    "start": "1668520",
    "end": "1677850"
  },
  {
    "text": "This is the most important\npart of all of this. It says that as you change this\ndifferential entropy, if",
    "start": "1677850",
    "end": "1684899"
  },
  {
    "text": "you try to draw a curve between\nH of v and MSE, and there's a curve like that drawn\nin the notes, if you",
    "start": "1684900",
    "end": "1692140"
  },
  {
    "text": "change the differential entropy,\nit just shift this curve left and right. For a given value of h of u,\nthis is a universal curve.",
    "start": "1692140",
    "end": "1702780"
  },
  {
    "text": "In other words, as you change\ndelta, this quantity changes and this quantity changes.",
    "start": "1702780",
    "end": "1709759"
  },
  {
    "text": "That's the only variable which\nis left in here at this point. When you make delta half as\nbig, if you want to get a",
    "start": "1709760",
    "end": "1717540"
  },
  {
    "text": "higher rate quantizer,\nwhat happens? Your mean square error goes\ndown by a factor of four.",
    "start": "1717540",
    "end": "1725090"
  },
  {
    "text": "Delta squared goes down to 1/4\nof its previous value.",
    "start": "1725090",
    "end": "1730610"
  },
  {
    "text": "What happens here,\nat log of delta? Delta has changed by\na factor of 1/2.",
    "start": "1730610",
    "end": "1736500"
  },
  {
    "text": "H of v goes up by one bit. So you take one more bit in your\nquantizer and you get a",
    "start": "1736500",
    "end": "1742740"
  },
  {
    "text": "mean square error, which\nis four times as small. Any time you think of what kind\nof accuracy you need on a",
    "start": "1742740",
    "end": "1749549"
  },
  {
    "text": "computer or something, I think\nthis is obvious to all of you, if you put it in terms of\nsomething you're already",
    "start": "1749550",
    "end": "1758299"
  },
  {
    "text": "familiar with. If you use 16 bit quantization\nwith fixed bit numbers and",
    "start": "1758300",
    "end": "1767530"
  },
  {
    "text": "then you change it to\n24 bit accuracy, what's going to happen? Well, everything is going to get\nbetter by a factor of 256,",
    "start": "1767530",
    "end": "1776700"
  },
  {
    "text": "and since we're talking about\nmean square error, it's going to be four times that. So that's just saying the same\nthing that you know.",
    "start": "1776700",
    "end": "1785440"
  },
  {
    "text": "For vector quantization, uniform\nquantization again approaches optimal for\na memoryless source.",
    "start": "1785440",
    "end": "1793150"
  },
  {
    "text": "If you have a source with\nmemory, vector quantization gains a great deal for you. But if you don't have any\nmemory, vector quantization",
    "start": "1793150",
    "end": "1801540"
  },
  {
    "text": "doesn't gain much at all. The only thing that vector\nquantization gains you is this",
    "start": "1801540",
    "end": "1806650"
  },
  {
    "text": "thing we call a shaping\ngain now. We talk about that again when\nwe start talking about",
    "start": "1806650",
    "end": "1814700"
  },
  {
    "text": "modulation. If you change from a square set\nof points to a hexagonal",
    "start": "1814700",
    "end": "1820660"
  },
  {
    "text": "set of points and you keep the\nareas the same, the mean",
    "start": "1820660",
    "end": "1826420"
  },
  {
    "text": "square error goes down\nby a smidgen -- something like 1.04\nor something.",
    "start": "1826420",
    "end": "1832680"
  },
  {
    "text": "It's not a big deal but there's\nsome gain, so the gain is not impressive.",
    "start": "1832680",
    "end": "1839390"
  },
  {
    "text": "The big gains come when you look\nat the memory and when you take that into account.",
    "start": "1839390",
    "end": "1845409"
  },
  {
    "text": "So now we want to get on to the\nlast part of our trilogy",
    "start": "1845410",
    "end": "1851590"
  },
  {
    "text": "when we're talking about\nsource coding.",
    "start": "1851590",
    "end": "1856970"
  },
  {
    "text": "Remember, when we were talking\nabout source coding, we broke it up into three pieces.",
    "start": "1856970",
    "end": "1862490"
  },
  {
    "text": "The first piece we called it\nsampling, which took a wave form, turned it into a\nsequence of numbers.",
    "start": "1862490",
    "end": "1870140"
  },
  {
    "text": "That's what happens here. We then quantize the sequence of\nnumbers, either one number",
    "start": "1870140",
    "end": "1876539"
  },
  {
    "text": "at a time or with a vector\nquantizer n numbers at a time. We just finished talking\nabout that.",
    "start": "1876540",
    "end": "1883960"
  },
  {
    "text": "The first five lectures in the\ncourse were all talking about discrete encoding, and whenever\nyou're going from",
    "start": "1883960",
    "end": "1890570"
  },
  {
    "text": "wave forms to bits, you gotta go\nthrough all three of these.",
    "start": "1890570",
    "end": "1895820"
  },
  {
    "text": "Now, sampling is only one way\nto go from wave form to sequence, and filtering is\nonly one way to get back.",
    "start": "1895820",
    "end": "1902940"
  },
  {
    "text": "We're going to talk\nabout sampling. We're probably going to teach\nyou more about sampling than",
    "start": "1902940",
    "end": "1908340"
  },
  {
    "text": "you ever wanted to know. But it turns out that\nit's worth knowing.",
    "start": "1908340",
    "end": "1914680"
  },
  {
    "text": "After you understand it\nyou never forget it. There's a lot of stuff to go\nthrough to start with, but",
    "start": "1914680",
    "end": "1922950"
  },
  {
    "text": "finally, I hope, it\nall makes sense. But anyway, the thing we're\ngoing to be talking about today is really the question\nof how do you go from wave",
    "start": "1922950",
    "end": "1931080"
  },
  {
    "text": "forms to sequences,\nit's that simple. How do you in general\ntake wave forms,",
    "start": "1931080",
    "end": "1937350"
  },
  {
    "text": "turn them into sequences? How do you go back from\nsequences to wave forms? We're going to spend quite\na bit of time on this.",
    "start": "1937350",
    "end": "1944950"
  },
  {
    "text": "We're going to spend three\nlectures talking about it, and",
    "start": "1944950",
    "end": "1951570"
  },
  {
    "text": "probably with today thrown in\nit'll be closer to three and a half lectures. It's not only because we want to\ntalk about the problem with",
    "start": "1951570",
    "end": "1959460"
  },
  {
    "text": "source coding, because as soon\nas we start talking about channels, we're going to have\nthe same truck problem looked",
    "start": "1959460",
    "end": "1967490"
  },
  {
    "text": "at in the opposite direction. We're going to start out\nwith binary data.",
    "start": "1967490",
    "end": "1972679"
  },
  {
    "text": "We're then going to go through\na modulator, we're going to find symbols. From the symbols, from the\nnumerical symbols, we're",
    "start": "1972680",
    "end": "1980240"
  },
  {
    "text": "talking about a sequence of\nthings and we have to go from the sequence to wave forms.",
    "start": "1980240",
    "end": "1987080"
  },
  {
    "text": "So, both of those problems\nare really the same. We're talking about it first in\nterms of source coding, but",
    "start": "1987080",
    "end": "1994320"
  },
  {
    "text": "whatever we learn about wave\nforms to sequences will be general and will be\nusable for both.",
    "start": "1994320",
    "end": "2000450"
  },
  {
    "text": " So I want to review why it is\nthat we want to spend so much",
    "start": "2000450",
    "end": "2006610"
  },
  {
    "text": "time on this analog source\nto bit stream problem. I just told you one of the\nreasons which is not here,",
    "start": "2006610",
    "end": "2014260"
  },
  {
    "text": "which is that it's a good way\nto get into the question of what do we do with channels. But the other reasons, and we've\ntalked about them all,",
    "start": "2014260",
    "end": "2022300"
  },
  {
    "text": "and they're all important and\nyou ought to remember them, because often we get so used to\ndoing things in a certain",
    "start": "2022300",
    "end": "2028600"
  },
  {
    "text": "way that we don't know why\nwe're doing them and then somebody suggests something else\nand we say oh, that's a",
    "start": "2028600",
    "end": "2034060"
  },
  {
    "text": "terrible idea because we've\nalways done it this way. One of the reasons why we want\nto go to bits is that a",
    "start": "2034060",
    "end": "2041710"
  },
  {
    "text": "standard binary interface\nseparates the problem of source and channel coding.",
    "start": "2041710",
    "end": "2047850"
  },
  {
    "text": "This was, in a sense, one of\nShannon's great discoveries,",
    "start": "2047850",
    "end": "2053159"
  },
  {
    "text": "and he also showed that\nyou could do it without really any loss. Another reason is you want\nto multiplex data",
    "start": "2053160",
    "end": "2060790"
  },
  {
    "text": "on high speed channels. This is perfectly\nfamiliar to you. I think to everyone today we\nthink of sending data over the",
    "start": "2060790",
    "end": "2069340"
  },
  {
    "text": "web and we're all used to using\nthe web all together. I send my stuff, you send your\nstuff, I get my stuff off, you",
    "start": "2069340",
    "end": "2077540"
  },
  {
    "text": "get your stuff off, and this\nstuff was all going over common channels. It's going over optical fibers\ninto MIT, and then it splits",
    "start": "2077540",
    "end": "2086530"
  },
  {
    "text": "up at MIT and goes into many\nplaces and then it goes many places again. But this idea of multiplexing\ndata is perfectly",
    "start": "2086530",
    "end": "2094379"
  },
  {
    "text": "straightforward. If we didn't do any of this, if\nall of my stuff was really",
    "start": "2094380",
    "end": "2100490"
  },
  {
    "text": "wave forms and all of your stuff\nwas images and if all of somebody else's stuff was data\nand every piece of the",
    "start": "2100490",
    "end": "2110380"
  },
  {
    "text": "internet had to worry about all\nthose different things, when you start worrying about\nall those different things you",
    "start": "2110380",
    "end": "2116400"
  },
  {
    "text": "create an awful lot of\nother things also. We just wouldn't have\nany internet today.",
    "start": "2116400",
    "end": "2122630"
  },
  {
    "text": "So this multiplexing\nis a big deal, too. You can clean up digital data\nat each link in a network.",
    "start": "2122630",
    "end": "2131980"
  },
  {
    "text": "In other words, if I'm sending\nanalog data from here to San Francisco and I'm sending it\nover multiple different links,",
    "start": "2131980",
    "end": "2139960"
  },
  {
    "text": "on every link a little bit of\nnoise gets added to it. That noise keeps adding up\nbecause there's no way to",
    "start": "2139960",
    "end": "2145970"
  },
  {
    "text": "clean it up, because nobody\nknows what I sent. If I'm sending digital data, at\nthe receiver on each link,",
    "start": "2145970",
    "end": "2156079"
  },
  {
    "text": "nobody knows what I sent, no,\nbut they know that what I sent was one out of a finite\ncollection of things.",
    "start": "2156080",
    "end": "2162809"
  },
  {
    "text": "There's something called\nrepeating going on there at every channel, which takes what\nis received as an analog",
    "start": "2162810",
    "end": "2169900"
  },
  {
    "text": "signal and, in fact, knowing\nwhat the encoding process was,",
    "start": "2169900",
    "end": "2175369"
  },
  {
    "text": "goes back to cleaning it up\nto a digital signal again. ",
    "start": "2175370",
    "end": "2182550"
  },
  {
    "text": "If you believe all of that\nand if you think it's simple, it's not. We're going to talk\nabout it later.",
    "start": "2182550",
    "end": "2188619"
  },
  {
    "text": "At this point, it's only\nplausible, and we're going to",
    "start": "2188620",
    "end": "2194370"
  },
  {
    "text": "justify it as we move on. We can separate problems of\nwave form sampling from",
    "start": "2194370",
    "end": "2201880"
  },
  {
    "text": "quantization from discrete\nsource coding. In other words, we not only\nhave the layering between",
    "start": "2201880",
    "end": "2207870"
  },
  {
    "text": "sources and channels, but we\nalso have this layering for sources, which goes between\nwave form to sequence",
    "start": "2207870",
    "end": "2216859"
  },
  {
    "text": "separation, then sequence and\nquantization into a finite set",
    "start": "2216860",
    "end": "2222910"
  },
  {
    "text": "of symbols. Then a finite set of symbols\ngetting coded. So, three separate things we've\nlearned about, we can",
    "start": "2222910",
    "end": "2229430"
  },
  {
    "text": "separate them all very nicey. ",
    "start": "2229430",
    "end": "2236210"
  },
  {
    "text": "So we said that in this wave\nform, the sequence business,",
    "start": "2236210",
    "end": "2242760"
  },
  {
    "text": "sampling is only\none way to go. I'm going to show that to you\nright away at the beginning by",
    "start": "2242760",
    "end": "2249370"
  },
  {
    "text": "talking about Fourier series. ",
    "start": "2249370",
    "end": "2255570"
  },
  {
    "text": "How many of you have studied\nFourier series and say spending more than a couple of\nhours of your life thinking",
    "start": "2255570",
    "end": "2264550"
  },
  {
    "text": "about Fourier series?  OK, good, quite a few\nof you, that's nice.",
    "start": "2264550",
    "end": "2272880"
  },
  {
    "text": "Because we have to assume that\nyou know a little bit about this, but probably\nnot a whole lot.",
    "start": "2272880",
    "end": "2279869"
  },
  {
    "text": "There's a formula for a Fourier\nseries, which is probably not the formula\nfor a Fourier series",
    "start": "2279870",
    "end": "2285660"
  },
  {
    "text": "that you're used to. It says the Fourier series of\na time-limited function matched the function to a\nsequence of coefficients.",
    "start": "2285660",
    "end": "2294830"
  },
  {
    "text": "Here's the formula. Here's the function. You can represent the function\nas a sum of coefficients times",
    "start": "2294830",
    "end": "2303720"
  },
  {
    "text": "these complex exponentials. You do that over this interval\nminus capital T over 2 less",
    "start": "2303720",
    "end": "2310760"
  },
  {
    "text": "than or equal to t, less than or\nequal to capital T over 2. The complex coefficients satisfy\nthis equation here.",
    "start": "2310760",
    "end": "2318690"
  },
  {
    "text": "That's just what you've\nseen before. The way this is different from\nwhat you've probably seen",
    "start": "2318690",
    "end": "2323800"
  },
  {
    "text": "before is that most people think\nthat you use Fourier series for periodic functions.",
    "start": "2323800",
    "end": "2331300"
  },
  {
    "text": "In other words, if we leave out\nthis part here, leave out",
    "start": "2331300",
    "end": "2337640"
  },
  {
    "text": "this, then this quantity here\nis a periodic function,",
    "start": "2337640",
    "end": "2342700"
  },
  {
    "text": "because each of the what have\nyou are all squiggling around",
    "start": "2342700",
    "end": "2349690"
  },
  {
    "text": "with a period which is a\nsub-multiple of capital T. So",
    "start": "2349690",
    "end": "2356540"
  },
  {
    "text": "that, in fact, this\nis a periodic function with period t.",
    "start": "2356540",
    "end": "2361660"
  },
  {
    "text": "If I think of it as a periodic\nfunction I don't have to worry about this, this still works\nfor any periodic function.",
    "start": "2361660",
    "end": "2370490"
  },
  {
    "text": "The problem is this isn't the\nway the Fourier series is usually used.",
    "start": "2370490",
    "end": "2376730"
  },
  {
    "text": "Occasionally, you want to talk\nabout periodic functions, but most often what you want to do\nis you want to take a function",
    "start": "2376730",
    "end": "2384200"
  },
  {
    "text": "which exists only over some\nfinite interval and you want some way of mapping that\nfunction into a set of",
    "start": "2384200",
    "end": "2390840"
  },
  {
    "text": "coefficients. I take a function only over the\ninterval minus t over 2 to capital T over 2, and I can map\nthat into a sequence of",
    "start": "2390840",
    "end": "2399610"
  },
  {
    "text": "coefficients, I have, in fact,\ndone what I said we're interested in doing right now,\nwhich is turning a wave form",
    "start": "2399610",
    "end": "2407990"
  },
  {
    "text": "into a sequence. The only problem with it is\nit's a fine duration wave",
    "start": "2407990",
    "end": "2413630"
  },
  {
    "text": "form, which I'm turning\ninto a sequence.  Now how do you do\nspeech coding?",
    "start": "2413630",
    "end": "2421570"
  },
  {
    "text": "There's an almost universal way\nof doing speech coding now of turning speech, analog wave\nforms, into actual data, into",
    "start": "2421570",
    "end": "2431090"
  },
  {
    "text": "binary data. The way that it always starts, I\nmean everybody has their own",
    "start": "2431090",
    "end": "2436670"
  },
  {
    "text": "way of doing it, but almost\neveryone takes the speech wave form and segments it into 20\nmillisecond intervals.",
    "start": "2436670",
    "end": "2445900"
  },
  {
    "text": "Each 20 millisecond interval\nis then encoded into a sequence of coefficients.",
    "start": "2445900",
    "end": "2452600"
  },
  {
    "text": "You can think of that as taking\neach 20 millisecond interval, creating a Fourier\nseries for it, and the Fourier",
    "start": "2452600",
    "end": "2461250"
  },
  {
    "text": "series coefficients\nthen represent the function in that interval. You go on to the next interval,\nyou get another",
    "start": "2461250",
    "end": "2468460"
  },
  {
    "text": "sequence of Fourier coefficients\nand so forth. Now, most of these very\nsophisticated voice coders",
    "start": "2468460",
    "end": "2476330"
  },
  {
    "text": "don't really use the Fourier\nseries coefficients because there's a great deal of\nstructure in voice, and the",
    "start": "2476330",
    "end": "2482820"
  },
  {
    "text": "Fourier series is designed\nto deal with any old thing at all. ",
    "start": "2482820",
    "end": "2489100"
  },
  {
    "text": "But the Fourier series is a good\nfirst order approximation to what's going on when you're\ndealing with voice coding.",
    "start": "2489100",
    "end": "2497540"
  },
  {
    "text": "when you're dealing with voice\ncoding you are certainly looking at frequencies, you're\nlooking at formats, which are",
    "start": "2497540",
    "end": "2503810"
  },
  {
    "text": "ranges of frequencies. If you want to think about those\nproblems, you better start to think in\nthese ways here.",
    "start": "2503810",
    "end": "2510860"
  },
  {
    "text": "So anyway, this is not just\nmathematics, this is one of the things that we need to\nunderstand how you do actual",
    "start": "2510860",
    "end": "2522430"
  },
  {
    "text": "wave forms to sequences. We're not going to talk too\nmuch about where these formulas come from too much.",
    "start": "2522430",
    "end": "2530849"
  },
  {
    "text": "It is interesting that this\nalso works for complex functions as well as\nreal functions.",
    "start": "2530850",
    "end": "2537270"
  },
  {
    "text": "There's a nice sort of symmetry\nthere, because the coefficients are all going to be\ncomplex anyway, because of",
    "start": "2537270",
    "end": "2546690"
  },
  {
    "text": "these things here which\nare complex. Incidentally, we always use i in\nthis course for the square",
    "start": "2546690",
    "end": "2552240"
  },
  {
    "text": "root of minus 1. Electrical engineers have\ntraditionally used the letter",
    "start": "2552240",
    "end": "2557460"
  },
  {
    "text": "j for the square root of minus\n1 for the rather poor reason",
    "start": "2557460",
    "end": "2562710"
  },
  {
    "text": "that they like to refer\nto current as i. In the first two years of an\nearlier electrical engineering",
    "start": "2562710",
    "end": "2569870"
  },
  {
    "text": "education back 50 years or so\nago, you spent so much time",
    "start": "2569870",
    "end": "2575390"
  },
  {
    "text": "talking about voltages and\ncurrents that using the letter i for anything other than\ncurrent was just an",
    "start": "2575390",
    "end": "2582480"
  },
  {
    "text": "abomination. Well, everybody else in the\nworld uses i for the square root of minus 1.",
    "start": "2582480",
    "end": "2588630"
  },
  {
    "text": "So in this course we're going\nto do the same thing. I would urge you to get used\nto it because then you can",
    "start": "2588630",
    "end": "2594170"
  },
  {
    "text": "talk to people other than\nelectrical engineers, and you'll probably have to spend\na lot of time in your life",
    "start": "2594170",
    "end": "2601150"
  },
  {
    "text": "talking to other people. You shouldn't expect them to get\nused to your conventions,",
    "start": "2601150",
    "end": "2606490"
  },
  {
    "text": "you should try to do a little\nto get used to their conventions.",
    "start": "2606490",
    "end": "2613250"
  },
  {
    "text": "So there's that peculiarity. We're also using this complex\nnotation throughout.",
    "start": "2613250",
    "end": "2621730"
  },
  {
    "text": "You could do this in terms of\nsines and cosines, which is probably the way you\nfirst learned it.",
    "start": "2621730",
    "end": "2628180"
  },
  {
    "text": "I'm sure for any of you who\nspent more than a very, very small amount of time dealing\nwith Fourier series, you did",
    "start": "2628180",
    "end": "2633930"
  },
  {
    "text": "enough with it to realize that\njust computationally going from sines and cosines to\ncomplex exponentials just",
    "start": "2633930",
    "end": "2643329"
  },
  {
    "text": "makes life so much easier and\nmakes your formula so much shorter that you\nwant to do it.",
    "start": "2643330",
    "end": "2650770"
  },
  {
    "text": "So anyway, we want to make this\nwork for complex signals as well as anything else.",
    "start": "2650770",
    "end": "2656880"
  },
  {
    "text": " I do want to verify the formula\nfor these Fourier",
    "start": "2656880",
    "end": "2663130"
  },
  {
    "text": "coefficients. Incidentally, the other thing\nthat I'll be doing which is a little bit weird here is that\nmost people when they talk",
    "start": "2663130",
    "end": "2670250"
  },
  {
    "text": "about the Fourier integral and\nthe Fourier series they use capital letters to talk about\nfrequencies and they use",
    "start": "2670250",
    "end": "2678240"
  },
  {
    "text": "little letters to talk\nabout signals. For us, we really want to use\ncapital letters to talk about",
    "start": "2678240",
    "end": "2687240"
  },
  {
    "text": "random variables, and we do\nthat pretty consistently. Believe me, when we start\ntalking about random",
    "start": "2687240",
    "end": "2693700"
  },
  {
    "text": "processes, you will get so\nconfused going back and forth",
    "start": "2693700",
    "end": "2698930"
  },
  {
    "text": "between sample values and random\nof variables, that having a notation way to keep\nthem straight will be very",
    "start": "2698930",
    "end": "2708400"
  },
  {
    "text": "valuable to you. When you start reading the\nliterature you get even more confused because most people in\nthe literature don't tell",
    "start": "2708400",
    "end": "2716329"
  },
  {
    "text": "you what it is that they're\ntalking about and they go back and forth between sample values\nand random variables,",
    "start": "2716330",
    "end": "2724290"
  },
  {
    "text": "oftentimes using the same symbol\nin the same sentence",
    "start": "2724290",
    "end": "2731280"
  },
  {
    "text": "for two different things. So I think that's a more\nimportant thing to keep straight, so we'll always use\ntildes to talk about frequency",
    "start": "2731280",
    "end": "2740619"
  },
  {
    "text": "type things. You can see that these\ncoefficients here are, in",
    "start": "2740620",
    "end": "2745839"
  },
  {
    "text": "fact, frequency-like things\nbecause they're talking about how much of this wave form\nis at a certain discrete",
    "start": "2745840",
    "end": "2752050"
  },
  {
    "text": "frequency, and we'll come back\nto talk about that later. But anyway, if you want to\nverify the formula for this,",
    "start": "2752050",
    "end": "2759200"
  },
  {
    "text": "what we're going to do is to\nstart out by looking at --",
    "start": "2759200",
    "end": "2764720"
  },
  {
    "text": "this is where having smaller\ndata would be a big help.",
    "start": "2764720",
    "end": "2770510"
  },
  {
    "text": "u of t is equal to\nthis sum here. So I'm going to replace u of t\nin this formula by this sum.",
    "start": "2770510",
    "end": "2781610"
  },
  {
    "text": "I'm going to make the index\nm because I already have a k over here.",
    "start": "2781610",
    "end": "2786650"
  },
  {
    "text": "When we have a k over here and\nyou're talking about this, you don't want to get your\nindexes mixed.",
    "start": "2786650",
    "end": "2791819"
  },
  {
    "text": "So if I'm trying to see what\nthis looks like, I want to represent as the integral from\nminus t over 2 to plus t over",
    "start": "2791820",
    "end": "2800109"
  },
  {
    "text": "2 of this representated as a sum\nwith e to the minus 2 pi i",
    "start": "2800110",
    "end": "2806090"
  },
  {
    "text": "kt over t taken into\naccount over here. So what happens here?",
    "start": "2806090",
    "end": "2812280"
  },
  {
    "text": "Here we have an integral\nof a sum. Later on we're going to be a\nlittle bit careful about",
    "start": "2812280",
    "end": "2818080"
  },
  {
    "text": "interchanging integrals and\nsums, but for now let's not",
    "start": "2818080",
    "end": "2825650"
  },
  {
    "text": "worry about that at all. I suggest to all of you, never\nworry about interchanging",
    "start": "2825650",
    "end": "2832099"
  },
  {
    "text": "integrals and sums until\nafter you understand what's going on. Because if you start asking\nabout that --",
    "start": "2832100",
    "end": "2840170"
  },
  {
    "text": "I mean that's a detail. You look at what's going on in\na major way first, and then",
    "start": "2840170",
    "end": "2845890"
  },
  {
    "text": "you go back to check that\nsort of thing out. So when we look at this integral\nhere, when we take",
    "start": "2845890",
    "end": "2852210"
  },
  {
    "text": "the sum outside, we have the sum\nover m of an integral over one cycle of these quantities\nhere, of this times e to the 2",
    "start": "2852210",
    "end": "2864520"
  },
  {
    "text": "pi i times m minus kt over t. Now, you look at this integral\nhere of a complex exponential",
    "start": "2864520",
    "end": "2872579"
  },
  {
    "text": "as it's rotating around. In the period of time t, this\nalways rotates around some",
    "start": "2872580",
    "end": "2880910"
  },
  {
    "text": "integer number of times. If m is equal to k, it doesn't\nrotate at all, it just sticks where it is, at 1.",
    "start": "2880910",
    "end": "2888369"
  },
  {
    "text": "If m is unequal to k,\nit goes around some integer number of times. If I'm thinking of this as being\nreal and this as being",
    "start": "2888370",
    "end": "2898430"
  },
  {
    "text": "imaginary, I'm just running\naround this circle here. So what happens when I run\naround the circle once?",
    "start": "2898430",
    "end": "2906369"
  },
  {
    "text": "The integral is zero because\nI'm up here as much as I'm down here, I'm over here as\nmuch as I'm over here.",
    "start": "2906370",
    "end": "2912859"
  },
  {
    "text": "So this integral is always zero,\nwhich says that all of these terms except when m\nis equal to k disappear.",
    "start": "2912860",
    "end": "2921940"
  },
  {
    "text": "So that means I wind up with\njust this one term u hat of k times the integral from minus\nt over 2 to t over 2dt.",
    "start": "2921940",
    "end": "2931030"
  },
  {
    "text": "That's another integral I can\nevaluate, and it's equal to capital T times u sub k.",
    "start": "2931030",
    "end": "2937200"
  },
  {
    "text": "So, u sub k is this quantity\nhere divided by t, which is",
    "start": "2937200",
    "end": "2943150"
  },
  {
    "text": "what we said over here. In fact, that argument,\nyou can make it",
    "start": "2943150",
    "end": "2948250"
  },
  {
    "text": "precise and it works. So what this is saying is that,\nin fact, if you look at",
    "start": "2948250",
    "end": "2961390"
  },
  {
    "text": "these Fourier series formulas,\nthis thing is pretty simple in",
    "start": "2961390",
    "end": "2968599"
  },
  {
    "text": "terms of this. The question which is more\ndifficult is what functions",
    "start": "2968600",
    "end": "2975410"
  },
  {
    "text": "can you represent in this way\nand what functions can't you represent in this way.",
    "start": "2975410",
    "end": "2981460"
  },
  {
    "text": "The easy answer is if you can\nthink of it you can represent it in this way.",
    "start": "2981460",
    "end": "2988390"
  },
  {
    "text": "But if you stop and think about\nit for six months, then that might not be\ntrue anymore.",
    "start": "2988390",
    "end": "2994760"
  },
  {
    "text": "So if you become very good at\nthis, you can find examples where it doesn't work,\nand we'll talk about",
    "start": "2994760",
    "end": "3000770"
  },
  {
    "text": "that as we go on. ",
    "start": "3000770",
    "end": "3010400"
  },
  {
    "text": "Let's define this rectangular\nfunction because we're going",
    "start": "3010400",
    "end": "3015994"
  },
  {
    "text": "to be using it all the time. You probably used it when\ndealing with the Fourier integral all the time because\nyou all know that a",
    "start": "3015995",
    "end": "3022940"
  },
  {
    "text": "rectangular function is a\nFourier transform of a sync function where a sync\nfunction is a sine",
    "start": "3022940",
    "end": "3028849"
  },
  {
    "text": "x over x type function. If you don't remember\nthat, fine. But anyway, this function is 1\nin the interval minus 1/2 to",
    "start": "3028850",
    "end": "3038190"
  },
  {
    "text": "plus 1/2 and it's 0 everywhere\nelse, which is why it's called a rectangular function.",
    "start": "3038190",
    "end": "3044080"
  },
  {
    "text": "It looks like this. ",
    "start": "3044080",
    "end": "3052510"
  },
  {
    "text": "We do it from minus 1/2 to plus\n1/2 so it has area 1. ",
    "start": "3052510",
    "end": "3061770"
  },
  {
    "text": "In terms of that, we can express\nthe formula for a time-limited function as this\nsum here, uk times these",
    "start": "3061770",
    "end": "3071450"
  },
  {
    "text": "complex exponentials times this\nrectangular function.",
    "start": "3071450",
    "end": "3076500"
  },
  {
    "text": "How many of you can see it ought\nto be rectangle of t over capital T instead of\nrectangle of t times t?",
    "start": "3076500",
    "end": "3083360"
  },
  {
    "text": " Good. I can't.",
    "start": "3083360",
    "end": "3088619"
  },
  {
    "text": "I always have to take two\nminutes doing that every time I do it, and if you can\nsee it in your mind",
    "start": "3088620",
    "end": "3095910"
  },
  {
    "text": "you're extremely fortunate. When we work with these things\nfor a while, you will become",
    "start": "3095910",
    "end": "3103410"
  },
  {
    "text": "more adept at doing\nthings like that. But anyway, this works. I want to look at\nan example now.",
    "start": "3103410",
    "end": "3110359"
  },
  {
    "text": "And there's several reasons\nI want to look at this. One is to just look at what\na Fourier series does.",
    "start": "3110360",
    "end": "3116640"
  },
  {
    "text": "Suppose we expand the function,\nthe rectangular function of t over 2.",
    "start": "3116640",
    "end": "3122160"
  },
  {
    "text": "Now the rectangular function of\nt over 2 is going to be 1 from minus 1/4 to plus 1/4,\ninstead of minus 1/2 to plus",
    "start": "3122160",
    "end": "3130660"
  },
  {
    "text": "1/2, because of the 2 in here. We want to expand it in a\nFourier series over the",
    "start": "3130660",
    "end": "3137130"
  },
  {
    "text": "interval minus 1/2\nto plus 1/2. One of the things this is\ntelling you is that when",
    "start": "3137130",
    "end": "3143080"
  },
  {
    "text": "you're expanding something in a\nFourier series, you have to be quite explicit about what\nthe interval is that you're",
    "start": "3143080",
    "end": "3149920"
  },
  {
    "text": "expanding it over. Because I could also find a\nFourier series here using the",
    "start": "3149920",
    "end": "3155420"
  },
  {
    "text": "interval minus 1/4 to plus 1/4,\nwhich would be a whole lot easier. But we're gluttons\nfor punishment.",
    "start": "3155420",
    "end": "3163180"
  },
  {
    "text": "So we're expanding in a Fourier\nseries over the bigger interval from here to there.",
    "start": "3163180",
    "end": "3168270"
  },
  {
    "text": "We go through these formulas\ncalculating u sub k. We can easily do it for\nthe first one, which",
    "start": "3168270",
    "end": "3175640"
  },
  {
    "text": "is just u sub zero. It's just the average value in\nthis interval minus 1/2 to 1/2, which is 1/2.",
    "start": "3175640",
    "end": "3182850"
  },
  {
    "text": "The next term turns out to\nbe 2 over pi times the cosine of 2 pi t.",
    "start": "3182850",
    "end": "3187980"
  },
  {
    "text": "We can evaluate all of them just\ngoing through more and more junk like that. But look at what's happened.",
    "start": "3187980",
    "end": "3193550"
  },
  {
    "text": "We started out with a\nrectangular function. When we evaluate more and more\nterms of this Fourier series,",
    "start": "3193550",
    "end": "3200730"
  },
  {
    "text": "the Fourier series terms\nare all very smooth. So what we're doing is trying\nto represent something with",
    "start": "3200730",
    "end": "3208780"
  },
  {
    "text": "sharp corners by a series\nof smooth functions.",
    "start": "3208780",
    "end": "3214910"
  },
  {
    "text": "Which means if we're going to be\nable to represent it, we're only going to be able to\nrepresent it by adding on more",
    "start": "3214910",
    "end": "3220099"
  },
  {
    "text": "and more terms, which hopefully\nare going to be coming closer and closer to\napproximating this the way it",
    "start": "3220100",
    "end": "3226210"
  },
  {
    "text": "should be approximated. Now if you look at these terms\nhere, these Fourier series, you will notice that every one\nof them, except this original",
    "start": "3226210",
    "end": "3235470"
  },
  {
    "text": "one which is at 1/2 -- ",
    "start": "3235470",
    "end": "3240490"
  },
  {
    "text": "so this is the first term here\nin the Fourier series. The second term is to add\non that cosine term.",
    "start": "3240490",
    "end": "3246109"
  },
  {
    "text": "The first term is sitting\nhere at 1/2. Every other one of them is\nzero at minus 1/4 and",
    "start": "3246110",
    "end": "3253440"
  },
  {
    "text": "zero at plus 1/4. So when we add up all of those\nterms, what we wind up with is",
    "start": "3253440",
    "end": "3259430"
  },
  {
    "text": "not what we started out with,\nbut something which is 0 from minus 1/2 to minus 1/4.",
    "start": "3259430",
    "end": "3267119"
  },
  {
    "text": "It's 1/2 at the value\nminus 1/2. It's 1 all along here.",
    "start": "3267120",
    "end": "3272860"
  },
  {
    "text": "It's 1/2 over here,\nand 0 down here.",
    "start": "3272860",
    "end": "3278420"
  },
  {
    "text": "Every time you study Fourier\nseries you find out about these bizarre things. Every time you have a\ndiscontinuity in the function,",
    "start": "3278420",
    "end": "3286970"
  },
  {
    "text": "the Fourier series comes\nout to split the difference on you. So you like to define your\nfunctions at discontinuities",
    "start": "3286970",
    "end": "3295920"
  },
  {
    "text": "as either being here at minus\n1/4 or here at minus 1/4.",
    "start": "3295920",
    "end": "3302930"
  },
  {
    "text": "Then when you come back from the\nFourier series, it forces you to be there.",
    "start": "3302930",
    "end": "3307970"
  },
  {
    "text": "Well, what does this say? ",
    "start": "3307970",
    "end": "3320519"
  },
  {
    "text": "It says that u of t, which we\nstarted out defining to have a certain value at minus 1/4 and\nplus 1/4, is equal to its",
    "start": "3320520",
    "end": "3330750"
  },
  {
    "text": "Fourier series everywhere\nexcept here and here. I have to ask you to\ntake that on faith.",
    "start": "3330750",
    "end": "3336330"
  },
  {
    "text": "But you can see that it's\nnot equal to it at those discontinuities. And it shouldn't be surprising\nthat it's not equal to its",
    "start": "3336330",
    "end": "3343030"
  },
  {
    "text": "discontinuities. I could have defined it as being\nzero at minus 1/4 or 1",
    "start": "3343030",
    "end": "3349059"
  },
  {
    "text": "at minus 1/4, and just that one\npoint shouldn't change our integrals too much.",
    "start": "3349060",
    "end": "3355390"
  },
  {
    "text": "Because of that as engineers,\nI mean at some level we have",
    "start": "3355390",
    "end": "3361299"
  },
  {
    "text": "to say we don't care. It's only a modeling issue.",
    "start": "3361300",
    "end": "3366630"
  },
  {
    "text": "Functions don't have\nperfectly straight discontinuities in them.",
    "start": "3366630",
    "end": "3373279"
  },
  {
    "text": "If they do you don't care how\nyou define it, it's a discontinuity. This Fourier series is sort\nof coming back and",
    "start": "3373280",
    "end": "3381390"
  },
  {
    "text": "slapping us with that. And it's saying OK, the function\nu of t is not the",
    "start": "3381390",
    "end": "3388200"
  },
  {
    "text": "same as its Fourier series\nbecause the two are different at these two points.",
    "start": "3388200",
    "end": "3393520"
  },
  {
    "text": "You say OK, I don't care that\nthey're not different at those two points. They're the same everywhere\nelse.",
    "start": "3393520",
    "end": "3400350"
  },
  {
    "text": "A mathematician comes back and\nsays a function is a function is a function, and a function\nis defined at every value of",
    "start": "3400350",
    "end": "3406990"
  },
  {
    "text": "t, and if u of t is equal to v\nof t, it means that at every",
    "start": "3406990",
    "end": "3412210"
  },
  {
    "text": "value of t, u of t is\nequal to v of t. And you say ah.",
    "start": "3412210",
    "end": "3418600"
  },
  {
    "text": "Well, turns out that by studying\nLebesgue theory, all",
    "start": "3418600",
    "end": "3426600"
  },
  {
    "text": "of those problems\nget resolved. Lebesgue was a very powerful\nmathematician.",
    "start": "3426600",
    "end": "3431820"
  },
  {
    "text": "But you know at some\nlevel deep in his heart, he was an engineer.",
    "start": "3431820",
    "end": "3436950"
  },
  {
    "text": "He was trying to get rid of all\nthis nonsense that people talked about, and he resolved\nthis question about how to",
    "start": "3436950",
    "end": "3442990"
  },
  {
    "text": "talk about these functions\nin a nice way. I mean really, good\nengineers are",
    "start": "3442990",
    "end": "3449770"
  },
  {
    "text": "mathematicians at heart, too. I mean at some level we\nall become the same. ",
    "start": "3449770",
    "end": "3458020"
  },
  {
    "text": "What Lebesgue tried to say is\nthat two functions are said to be equivalent in\nthe L2 sense --",
    "start": "3458020",
    "end": "3466300"
  },
  {
    "text": "I'll talk about this L2 notation\nlater -- if their difference has zero energy.",
    "start": "3466300",
    "end": "3471320"
  },
  {
    "text": "In other words, Lebesgue said\nwhat's really important is not what functions are at each\npoint, but really things about",
    "start": "3471320",
    "end": "3482180"
  },
  {
    "text": "their energy. So what you would like to have\nis if u of t and v of t, if",
    "start": "3482180",
    "end": "3488599"
  },
  {
    "text": "the difference between them, you\ntake the magnitude of that and you square it, if that\ndifference is equal to zero,",
    "start": "3488600",
    "end": "3497819"
  },
  {
    "text": "you have to recognize that\nthere's no possible way that you could ever distinguish those\ntwo functions, except",
    "start": "3497820",
    "end": "3504910"
  },
  {
    "text": "just by fiat, by saying this\nis equal to this and not equal to that. That's the only way you\ncould straighten",
    "start": "3504910",
    "end": "3510660"
  },
  {
    "text": "that out in your minds. So we say the two functions\nare L2 equivalent if their",
    "start": "3510660",
    "end": "3517260"
  },
  {
    "text": "difference has zero energy. Well, we have a couple\nof problems there. How do we define that?",
    "start": "3517260",
    "end": "3525000"
  },
  {
    "text": "At this point, we're sort\nof already deep in the mathematical soup because, in\nfact, we're trying to make",
    "start": "3525000",
    "end": "3532589"
  },
  {
    "text": "these small distinctions and\nmake them make sense.",
    "start": "3532590",
    "end": "3538140"
  },
  {
    "text": "We're also going to see, as we\ngo on to two functions that have the same Fourier series,\nare L2 equivalent, because if",
    "start": "3538140",
    "end": "3544940"
  },
  {
    "text": "two functions have the same\nFourier series, put one of them there and one of them\nthere, and we're going to see",
    "start": "3544940",
    "end": "3552090"
  },
  {
    "text": "that when we expand it in a\nFourier series they're both the same, and we're going to see\nthat, in fact, what that",
    "start": "3552090",
    "end": "3558079"
  },
  {
    "text": "means is that their energy\ndifference has to be zero. Which says that if you don't\ntalk about functions, but if",
    "start": "3558080",
    "end": "3564800"
  },
  {
    "text": "you talk about their Fourier\nseries, all of these confusions go away about things\nhaving to be equal",
    "start": "3564800",
    "end": "3572220"
  },
  {
    "text": "point-wise. So let's go on and try to say\na little more about this.",
    "start": "3572220",
    "end": "3578550"
  },
  {
    "start": "3578550",
    "end": "3584400"
  },
  {
    "text": "One of the problems that we come\nup with is that not all time-limited functions, in fact,\nhave Fourier series,",
    "start": "3584400",
    "end": "3591740"
  },
  {
    "text": "even in a sense of\nL2 equivalents. You can think of functions which\nare so awful that they",
    "start": "3591740",
    "end": "3597950"
  },
  {
    "text": "don't have a Fourier series,\nalthough it's hard to find them.",
    "start": "3597950",
    "end": "3603530"
  },
  {
    "text": "We really want to make\ngeneral statements about classes of functions. Why do we want to do that?",
    "start": "3603530",
    "end": "3610140"
  },
  {
    "text": "Well, I can give you\ntwo reasons for it. The two reasons are both, I\nthink, both good reasons.",
    "start": "3610140",
    "end": "3617740"
  },
  {
    "text": "The first reason is that as\nwe deal particularly with",
    "start": "3617740",
    "end": "3623610"
  },
  {
    "text": "channels, we have to look at\nthings both in a time domain and in a frequency domain.",
    "start": "3623610",
    "end": "3630690"
  },
  {
    "text": "We look at things in the domain\nand the frequency domain, we have a function in\na time domain, we have a",
    "start": "3630690",
    "end": "3636930"
  },
  {
    "text": "Fourier transform in the\nfrequency domain, and it turns out that nice properties in a\ntime domain are not always",
    "start": "3636930",
    "end": "3648460"
  },
  {
    "text": "carried over to the frequency\ndomain and vice versa. Give me one example of that.",
    "start": "3648460",
    "end": "3656180"
  },
  {
    "text": "Suppose you think\nof a constant. The constant function, which\nis equal to 1 everywhere on",
    "start": "3656180",
    "end": "3663619"
  },
  {
    "text": "the real line. Nice function, right?",
    "start": "3663620",
    "end": "3669090"
  },
  {
    "text": "It models various things\nvery well. It doesn't model physical\nreality, really, because I",
    "start": "3669090",
    "end": "3677170"
  },
  {
    "text": "mean you don't care what this\nfunction was before the fourth ice age.",
    "start": "3677170",
    "end": "3683820"
  },
  {
    "text": "You don't care what it is after\nwe all blow ourselves up, I hope in not\ntoo many years.",
    "start": "3683820",
    "end": "3690520"
  },
  {
    "text": "I mean I hope in more than\njust a few years. ",
    "start": "3690520",
    "end": "3697040"
  },
  {
    "text": "Therefore, when we model\nsomething as a constant, what do we mean?",
    "start": "3697040",
    "end": "3704089"
  },
  {
    "text": "We mean that over the interval\nof time that we're interested in, this function is equal\nto a constant.",
    "start": "3704090",
    "end": "3711600"
  },
  {
    "text": "And it means we don't want to\nspecify what the time interval is that we're interested in,\nwhich is a common thing,",
    "start": "3711600",
    "end": "3718800"
  },
  {
    "text": "because you don't want to set\ntime limits on something. Now, you take those functions\nwhich go on and on forever.",
    "start": "3718800",
    "end": "3727550"
  },
  {
    "text": "Well, the Fourier series, you\ndon't have any problem with them because we're going to\ntruncate the function anyway",
    "start": "3727550",
    "end": "3733770"
  },
  {
    "text": "before we take a\nFourier series. But if we look at the Fourier\nintegral, and we'll see this",
    "start": "3733770",
    "end": "3740680"
  },
  {
    "text": "as soon as we get into the\nFourier integral, the awful thing is that what has happened\nin the thousand years",
    "start": "3740680",
    "end": "3748310"
  },
  {
    "text": "before the fourth ice age back,\nis just as important in the Fourier transform as\nwhat happens in the",
    "start": "3748310",
    "end": "3755340"
  },
  {
    "text": "thousand years right now. In other words, everything\nis important.",
    "start": "3755340",
    "end": "3760930"
  },
  {
    "text": "Things back in the dim\npast clobber you in a frequency domain.",
    "start": "3760930",
    "end": "3766400"
  },
  {
    "text": "Things in the distant future\nclobber you in the frequency domain. Therefore, since we have to\nface the fact that we're",
    "start": "3766400",
    "end": "3774540"
  },
  {
    "text": "dealing with approximations,\nsince we have to face the fact that we want to ignore things\n-- back there we want to",
    "start": "3774540",
    "end": "3781010"
  },
  {
    "text": "ignore things there. When we look at constants in the\nfrequency domain, we don't",
    "start": "3781010",
    "end": "3786370"
  },
  {
    "text": "mean that something is constant\nover all frequency. We mean it's constant over the\nrange of frequencies that",
    "start": "3786370",
    "end": "3792390"
  },
  {
    "text": "we're interested in and we don't\nwant to specify what that range is. You have the same problems going\nfrom there back to time.",
    "start": "3792390",
    "end": "3800940"
  },
  {
    "text": "So, as soon as we face the\nfact that we're really interested in approximations,\nand the approximations that we",
    "start": "3800940",
    "end": "3808670"
  },
  {
    "text": "deal with normally in time\nare not the same as the approximations we deal with in\nfrequency, at that point, we",
    "start": "3808670",
    "end": "3818160"
  },
  {
    "text": "start to realize that we have\nto be able to make general statements about what\nfunctions do",
    "start": "3818160",
    "end": "3823930"
  },
  {
    "text": "what kinds of things. We have to make general\nstatements about what has a Fourier transform, what doesn't,\nwhat has a Fourier",
    "start": "3823930",
    "end": "3831710"
  },
  {
    "text": "series, what doesn't have\na Fourier series. Now, one of the things we're\naiming at is to define a class",
    "start": "3831710",
    "end": "3838420"
  },
  {
    "text": "of functions called\nL2 functions. These are basically functions\nwhich have finite energy.",
    "start": "3838420",
    "end": "3845690"
  },
  {
    "text": "The nice thing about those\nfunctions is that every one of them has a Fourier transform,\nand the Fourier transform is",
    "start": "3845690",
    "end": "3852730"
  },
  {
    "text": "also an L2 function. All the other things that you\ndeal with -- continuity,",
    "start": "3852730",
    "end": "3858990"
  },
  {
    "text": "things like that -- doesn't\ncarry over at all. L2 is the only property that I\nknow of that really carries",
    "start": "3858990",
    "end": "3866829"
  },
  {
    "text": "over from time functions\nto Fourier transform. So we really want to be able\nto talk about that.",
    "start": "3866830",
    "end": "3875070"
  },
  {
    "text": "So we want to talk about these\nfinite energy functions. We want to be able to talk\nabout representing finite",
    "start": "3875070",
    "end": "3881970"
  },
  {
    "text": "energy functions. I say here, all physical wave\nforms have finite energy, but",
    "start": "3881970",
    "end": "3887450"
  },
  {
    "text": "their models do not necessarily have finite energy. In other words, we look at a\nconstant -- a constant does",
    "start": "3887450",
    "end": "3893859"
  },
  {
    "text": "not have finite energy. How about an impulse? Does an impulse have\nfinite energy?",
    "start": "3893860",
    "end": "3900270"
  },
  {
    "text": "AUDIENCE: [INAUDIBLE]. ",
    "start": "3900270",
    "end": "3908250"
  },
  {
    "text": "PROFESSOR: What? Yes? How many people think\nthe answer is yes? ",
    "start": "3908250",
    "end": "3918460"
  },
  {
    "text": "The hands are going\nup very slow. Well, the answer is no. Let me explain why.",
    "start": "3918460",
    "end": "3924130"
  },
  {
    "start": "3924130",
    "end": "3930190"
  },
  {
    "text": "It's something you\nshould know. But it's something that you get\nblinded by studying too",
    "start": "3930190",
    "end": "3936619"
  },
  {
    "text": "much signals and systems\nbefore you study any communication, because you're\ntalking about all sorts of",
    "start": "3936620",
    "end": "3943840"
  },
  {
    "text": "transforms, all sorts of things\nthat you deal with as",
    "start": "3943840",
    "end": "3950710"
  },
  {
    "text": "functions, which you're dealing\nwith electronically, instead of those functions\nthat you're interested in transmitting.",
    "start": "3950710",
    "end": "3957530"
  },
  {
    "text": "If you think of a narrow pulse\nof height 1 over epsilon, and",
    "start": "3957530",
    "end": "3965940"
  },
  {
    "text": "of width epsilon, it\nhas unit area.",
    "start": "3965940",
    "end": "3972660"
  },
  {
    "text": "So I make epsilon very,\nvery small. This starts to look like\na unit impulse, right?",
    "start": "3972660",
    "end": "3978600"
  },
  {
    "text": "In fact, you usually define a\nunit impulse somehow or other as thinking of some limiting\nprocess for this kind of",
    "start": "3978600",
    "end": "3984270"
  },
  {
    "text": "rectangular function. What's the energy of\nthat function?",
    "start": "3984270",
    "end": "3989370"
  },
  {
    "text": "What? AUDIENCE: [INAUDIBLE PHRASE]. PROFESSOR: Energy is 1\nover epsilon, yes.",
    "start": "3989370",
    "end": "3995420"
  },
  {
    "start": "3995420",
    "end": "4001130"
  },
  {
    "text": "What happens as epsilon\ngoes to infinity? Bing. ",
    "start": "4001130",
    "end": "4006680"
  },
  {
    "text": "If you put an impulse into\nan electrical circuit it'll blow it up. ",
    "start": "4006680",
    "end": "4013520"
  },
  {
    "text": "You usually don't care about\nthat because you don't see impulses in the physical\nworld.",
    "start": "4013520",
    "end": "4019250"
  },
  {
    "text": "You see things which are so\nnarrow and so tall that in",
    "start": "4019250",
    "end": "4024900"
  },
  {
    "text": "terms of the filters that you\nput them through, which have smaller bandwidth, those narrow\npulses behave very",
    "start": "4024900",
    "end": "4036170"
  },
  {
    "text": "nicely, and as you make those\nnarrow impulses more and more high and more and more narrow,\nthey behave the same way after",
    "start": "4036170",
    "end": "4043579"
  },
  {
    "text": "they go through a filter. But before that they're ugly and\nthey have infinite energy.",
    "start": "4043580",
    "end": "4050160"
  },
  {
    "text": " In fact, you could determine\nthat from two of the",
    "start": "4050160",
    "end": "4056420"
  },
  {
    "text": "statements I made earlier, and\nI'm sure I can't blame any of you for not doing that.",
    "start": "4056420",
    "end": "4062280"
  },
  {
    "text": "I said that all finite energy\nfunctions have Fourier transforms which are finite\nenergy, and you all know that",
    "start": "4062280",
    "end": "4069599"
  },
  {
    "text": "the Fourier transform of a unit\nimpulse is a constant, and the Fourier transform of a\nconstant is a unit impulse.",
    "start": "4069600",
    "end": "4076510"
  },
  {
    "text": "Therefore, if the constant has\ninfinite energy, the unit impulse has to have infinity\nenergy also.",
    "start": "4076510",
    "end": "4083090"
  },
  {
    "text": "So anyway, we have all these\nfunctions we like to deal with",
    "start": "4083090",
    "end": "4090040"
  },
  {
    "text": "all the time which do not\nhave finite energy. We don't want to deal with\nthose in this course, not",
    "start": "4090040",
    "end": "4097380"
  },
  {
    "text": "because they aren't very useful\nin signal processing, but because they aren't useful\nas wave forms which we will",
    "start": "4097380",
    "end": "4106540"
  },
  {
    "text": "transmit, and they aren't very\nuseful as source wave forms. Source wave forms do not\nbehave that way.",
    "start": "4106540",
    "end": "4113750"
  },
  {
    "text": "Source wave forms that we want\nto encode all have finite energy, and we'll see\nwhy as we go on.",
    "start": "4113750",
    "end": "4120469"
  },
  {
    "text": "So now I want to try to tell\nyou what the big theorem is",
    "start": "4120470",
    "end": "4126520"
  },
  {
    "text": "about Fourier series. I will do this in terms of a\nbunch of things that you don't",
    "start": "4126520",
    "end": "4133660"
  },
  {
    "text": "understand yet. The theorem says we're looking\nat a function u of t, which is",
    "start": "4133660",
    "end": "4140870"
  },
  {
    "text": "time-limited -- nothing strange there, that's\nwhat we've been looking at all along so far.",
    "start": "4140870",
    "end": "4148540"
  },
  {
    "text": "It's a function that goes from\nminus t over 2 to t over 2, and we'll let it go into the\ncomplex numbers because we",
    "start": "4148540",
    "end": "4155529"
  },
  {
    "text": "said it's just as easy\nto deal with complex functions as real functions.",
    "start": "4155530",
    "end": "4161440"
  },
  {
    "text": "We're going to assume that\nit has finite energy. Then it says for each index k,\nthe Lebesgue integral, u sub k",
    "start": "4161440",
    "end": "4173430"
  },
  {
    "text": "equals this. In other words, this is the\nformula for finding the Fourier series coefficient.",
    "start": "4173430",
    "end": "4180040"
  },
  {
    "text": "What we're saying here is we\nhave to redefine that to be a Lebesgue integrall instead\nof a Reimann integral.",
    "start": "4180040",
    "end": "4185890"
  },
  {
    "text": "But anyway, when you define it\nthat way it always exists and",
    "start": "4185890",
    "end": "4192020"
  },
  {
    "text": "it is always finite,\nnecessarily. It can't be infinite,\nit can't not exist.",
    "start": "4192020",
    "end": "4200090"
  },
  {
    "text": "It just is there. The other thing is -- now this\nformula is harder to swallow",
    "start": "4200090",
    "end": "4207180"
  },
  {
    "text": "as a whole. Let's try to look at it. What's inside of here is the\ndifference between u of t and",
    "start": "4207180",
    "end": "4217810"
  },
  {
    "text": "a finite approximation to\nthe Fourier series. Now if you're taking a Fourier\nseries, whether you're taking",
    "start": "4217810",
    "end": "4224750"
  },
  {
    "text": "it on a computer or calculating\nit or what you're doing with it, you're\nnever going to take",
    "start": "4224750",
    "end": "4230900"
  },
  {
    "text": "the infinite sum. You're always going to be\ndealing with some finite approximation.",
    "start": "4230900",
    "end": "4236710"
  },
  {
    "text": "This says that the different\nbetween u of t and these finite approximations, if you\ntake that difference and you",
    "start": "4236710",
    "end": "4244850"
  },
  {
    "text": "find the energy in that\ndifference, says the energy in that difference gets small.",
    "start": "4244850",
    "end": "4251420"
  },
  {
    "text": "In other words, it says that\nas you take more and more terms in your Fourier series,\nyou get a function which comes",
    "start": "4251420",
    "end": "4258990"
  },
  {
    "text": "closer and closer to u of t in\nterms of energy difference.",
    "start": "4258990",
    "end": "4264620"
  },
  {
    "text": "So that's the kind of statement\nthat we want in this course, because we're aiming\ntowards saying that this in",
    "start": "4264620",
    "end": "4271530"
  },
  {
    "text": "the limit looks like that in\nterms of having zero energy difference between it.",
    "start": "4271530",
    "end": "4277220"
  },
  {
    "text": "Namely, this is going to allow\nthis function to converge to one of these strange functions\nthat has bizarre values on",
    "start": "4277220",
    "end": "4284360"
  },
  {
    "text": "discontinuities of u of t,\nbecause that doesn't make any",
    "start": "4284360",
    "end": "4289980"
  },
  {
    "text": "difference in terms of energy. It says also the energy\nequation is satisfied.",
    "start": "4289980",
    "end": "4295170"
  },
  {
    "text": "The energy equation -- I didn't say it was the\nenergy equation -- ",
    "start": "4295170",
    "end": "4303270"
  },
  {
    "text": "I hope I said what it was. ",
    "start": "4303270",
    "end": "4310200"
  },
  {
    "text": "Blah blah blah. I have to write it down. ",
    "start": "4310200",
    "end": "4319250"
  },
  {
    "text": "The energy equation says that\nthe integral of u of t",
    "start": "4319250",
    "end": "4332050"
  },
  {
    "text": "magnitude squared dt from minus\nt over 2, the t over 2",
    "start": "4332050",
    "end": "4338590"
  },
  {
    "text": "is equal to the sum over k of u\nhat of k magnitude squared.",
    "start": "4338590",
    "end": "4350619"
  },
  {
    "text": " And there's a 1 over\nt in here.",
    "start": "4350620",
    "end": "4359460"
  },
  {
    "text": "There's either a 1\nover t or a t -- I'm pretty sure it's a 1 over t,\nbut I wouldn't swear to it.",
    "start": "4359460",
    "end": "4365820"
  },
  {
    "text": " I can't believe I didn't\nhave that written down.",
    "start": "4365820",
    "end": "4371060"
  },
  {
    "text": "At any rate it's in the notes. So you will find it there.",
    "start": "4371060",
    "end": "4376530"
  },
  {
    "text": "I can't keep these constants\nstraight. ",
    "start": "4376530",
    "end": "4383050"
  },
  {
    "text": "I think I did it wherever\nI stopped -- here. That's where I did it.",
    "start": "4383050",
    "end": "4388700"
  },
  {
    "text": "That's the energy equation. Yeah, I got it right, amazing. The integral of u of t squared\ndt is equal to t times the sum",
    "start": "4388700",
    "end": "4398000"
  },
  {
    "text": "of all the Fourier\ncoefficients.  I forgot to say this.",
    "start": "4398000",
    "end": "4403030"
  },
  {
    "text": "This is something\nI wanted to say. This energy equation is\nimportant because in terms of",
    "start": "4403030",
    "end": "4410340"
  },
  {
    "text": "source coding, if you take a\nfunction u of t, if you find this Fourier series, u of\nk, that's a sequence of",
    "start": "4410340",
    "end": "4420440"
  },
  {
    "text": "coefficients. If we take that sequence of\ncoefficients and we quantize them to some other set of\nvalues, v sub k, and then we",
    "start": "4420440",
    "end": "4431110"
  },
  {
    "text": "recreate the function\ncorresponding to this set up Fourier coefficients,\nwe get sum v of t.",
    "start": "4431110",
    "end": "4438210"
  },
  {
    "text": "So we start out with u of t, we\ngo all the way through all of this chain, going through a\nchannel and everything else,",
    "start": "4438210",
    "end": "4444080"
  },
  {
    "text": "come back with some\nfunction v of t. This applied to u of t minus\nv of t says that the energy",
    "start": "4444080",
    "end": "4454090"
  },
  {
    "text": "difference between u of t, and\nour re-created version v of t, is exactly the same as t times\nthe sum of the differences",
    "start": "4454090",
    "end": "4463420"
  },
  {
    "text": "between u sub k and\nv sub k squared. Now, that is the reason why most\npeople talk about mean",
    "start": "4463420",
    "end": "4471880"
  },
  {
    "text": "square error most of the time,\nbecause if you can control the",
    "start": "4471880",
    "end": "4477429"
  },
  {
    "text": "mean square error on your\ncoefficients, you're also controlling the mean square\nerror on the functions.",
    "start": "4477430",
    "end": "4484270"
  },
  {
    "text": "This formula does not work for\nmagnitude or cubes or fourth powers or anything else.",
    "start": "4484270",
    "end": "4490980"
  },
  {
    "text": "It only works for these\nsquare powers. That's why everybody uses\nmean square error",
    "start": "4490980",
    "end": "4497889"
  },
  {
    "text": "rather than other things. It also makes sense for energy,\nbecause we believe in, in some sense, energy ought\nto be important",
    "start": "4497890",
    "end": "4505640"
  },
  {
    "text": "and energy is important.  So, the final part of the\ntheorem says that finally, if",
    "start": "4505640",
    "end": "4516480"
  },
  {
    "text": "you start out with a sequence\nof complex numbers and the",
    "start": "4516480",
    "end": "4523550"
  },
  {
    "text": "sequence of numbers has finite\nenergy in this sense, then",
    "start": "4523550",
    "end": "4528590"
  },
  {
    "text": "there's an L2 function,\nu of t, which satisfies all of this stuff.",
    "start": "4528590",
    "end": "4535690"
  },
  {
    "text": "In other words, you can go\nfrom function to Fourier series, you can go from Fourier\nseries to function.",
    "start": "4535690",
    "end": "4541429"
  },
  {
    "text": "You can go either way.  So long as you have finite\nenergy this all works.",
    "start": "4541430",
    "end": "4548100"
  },
  {
    "text": " I want to spend just a couple\nof minutes talking about the",
    "start": "4548100",
    "end": "4553450"
  },
  {
    "text": "difference between Reimann and\nLebesgue integration to show you that, in fact, it isn't\nreally any big deal.",
    "start": "4553450",
    "end": "4561970"
  },
  {
    "text": "When you're talking about\nReimann integration -- I've just showed the integral\nfor a function between zero and 1.",
    "start": "4561970",
    "end": "4569810"
  },
  {
    "text": "How do you conceptually find the\nintegral of a function -- a Reimann integral, which\nis what you're used.",
    "start": "4569810",
    "end": "4576160"
  },
  {
    "text": "You split up the interval on\nthe horizontal axis into a bunch of equal intervals\nof size 1 over n each.",
    "start": "4576160",
    "end": "4584910"
  },
  {
    "text": "So you split it into n\nintervals, each one a size 1 over n. You approximate the value of the\nfunction in each interval",
    "start": "4584910",
    "end": "4592510"
  },
  {
    "text": "somehow, as the smallest value,\nthe largest value, the mean value, whatever\nyou want to do.",
    "start": "4592510",
    "end": "4599490"
  },
  {
    "text": "That doesn't make any difference\nbecause as the intervals become smaller and\nsmaller and smaller and you",
    "start": "4599490",
    "end": "4606860"
  },
  {
    "text": "have a function which is sort of\nsmooth in some sense, then",
    "start": "4606860",
    "end": "4613810"
  },
  {
    "text": "this Reimann sum here is going\nto get close to this interval.",
    "start": "4613810",
    "end": "4620220"
  },
  {
    "text": "In other words, the Reimann\nsum is going to approach a limit, and that limit\nis defined",
    "start": "4620220",
    "end": "4626210"
  },
  {
    "text": "as the Reimann integral. So that's the thing\nyou're used to. The Lebesgue integral is\nsimilar, oh and in a sense,",
    "start": "4626210",
    "end": "4637739"
  },
  {
    "text": "it's no more complicated. What you do is instead of\nquantizing the horizontal axis",
    "start": "4637740",
    "end": "4643890"
  },
  {
    "text": "into regions of size 1 over\nn and letting 1 over n get small, you quantize the vertical\naxis into intervals",
    "start": "4643890",
    "end": "4652219"
  },
  {
    "text": "of size epsilon and you're\ngoing to let epsilon get small later. Then the thing that you do is\nyou ask how much of the",
    "start": "4652220",
    "end": "4660010"
  },
  {
    "text": "function is in each of\nthese intervals here? So the amount of the function\nthat lies between 2 epsilon",
    "start": "4660010",
    "end": "4669360"
  },
  {
    "text": "and 3 epsilon is an interval\nt2 minus t1 -- there's that",
    "start": "4669360",
    "end": "4676010"
  },
  {
    "text": "interval where the function\nis in this range. There's also this interval over\nhere between t3 and t4.",
    "start": "4676010",
    "end": "4684290"
  },
  {
    "text": "So you say the measure of the\nfunction in this interval here is t2 minus t1 plus\nt4 minus t3.",
    "start": "4684290",
    "end": "4693970"
  },
  {
    "text": "You say the measure of the\nfunction in this region here,",
    "start": "4693970",
    "end": "4699300"
  },
  {
    "text": "vertical region here, is t1,\nnamely, this, plus 1 minus t4,",
    "start": "4699300",
    "end": "4706630"
  },
  {
    "text": "namely, this region over here. So for any function you\ncan do the same thing.",
    "start": "4706630",
    "end": "4713580"
  },
  {
    "text": "That's the Lebesgue integral. Lebesgue integral says you\ndo this and you let these epsilons get very small and\nyou just add them up.",
    "start": "4713580",
    "end": "4722570"
  },
  {
    "start": "4722570",
    "end": "4727940"
  },
  {
    "text": "Let me say just -- last slide. Turns out that whenever the\nReimann integral exists,",
    "start": "4727940",
    "end": "4735000"
  },
  {
    "text": "namely, that limit exists, the\nLebesgue interval also exists and has the same value.",
    "start": "4735000",
    "end": "4741989"
  },
  {
    "text": "All of the familiar rules for\ncalculating Reimann integrals also apply for Lebesgue\nintegrals.",
    "start": "4741990",
    "end": "4748290"
  },
  {
    "text": "For some very weird functions,\nthe Lebesgue integral exists, but the Reimann integral\ndoesn't exist.",
    "start": "4748290",
    "end": "4754310"
  },
  {
    "text": "For some extraordinarily weird\nfunctions, there aren't even any examples in the notes. I couldn't find an example which\nI thought was palatable,",
    "start": "4754310",
    "end": "4762770"
  },
  {
    "text": "not even the Lebesgue\nintegral exists. So the Lebesgue integral is\nmuch more general than the Reimann integral.",
    "start": "4762770",
    "end": "4769100"
  },
  {
    "text": "But the nice thing is you can\nalmost forget about it because",
    "start": "4769100",
    "end": "4774960"
  },
  {
    "text": "everything you know to do still\nworks, it's just that some of the things that didn't\nwork before now work.",
    "start": "4774960",
    "end": "4782830"
  },
  {
    "text": "Because those things that didn't\nwork before now work, your theorems can be much more\ngeneral than they were before.",
    "start": "4782830",
    "end": "4791160"
  },
  {
    "text": "We'll talk more about\nthat next time. This material we're talking\nabout right now is in the appendix to the lectures that\njust got passed out.",
    "start": "4791160",
    "end": "4800180"
  },
  {
    "start": "4800180",
    "end": "4800377"
  }
]
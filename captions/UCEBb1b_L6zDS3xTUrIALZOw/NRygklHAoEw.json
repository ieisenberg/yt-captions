[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5620"
  },
  {
    "text": "Your support will help\nMIT OpenCourseWare continue to offer high-quality\neducational resources for free.",
    "start": "5620",
    "end": "12280"
  },
  {
    "text": "To make a donation, or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "12280",
    "end": "18869"
  },
  {
    "text": "at ocw.mit.edu. ANDREI BARBU: All right. To start off with, perception\nis a very difficult problem.",
    "start": "18870",
    "end": "25328"
  },
  {
    "text": "And there's a good reason why\nperception should be difficult, right? We get a very\nimpoverished stimulus.",
    "start": "25329",
    "end": "30350"
  },
  {
    "text": "We get, like a 2D array\nof values from a 3D scene. Given this\nimpoverished stimulus,",
    "start": "30350",
    "end": "36000"
  },
  {
    "text": "we have to understand\na huge amount of stuff about the world. We have to understand the\n3D structure of the world. If you look at\nany one pixel, you",
    "start": "36000",
    "end": "42330"
  },
  {
    "text": "have to understand the\nproperties of the surface that produce the elimination\nthat gave you that pixel.",
    "start": "42330",
    "end": "47340"
  },
  {
    "text": "You have to understand\nthe color or the texture. You have to see the\ncolor of the light that hit that surface, the roughness\nof the surface, et cetera.",
    "start": "47340",
    "end": "54690"
  },
  {
    "text": "So you have a very small\nchannel, a very small window onto the world, and you have\nto extract a tremendous amount",
    "start": "54690",
    "end": "60270"
  },
  {
    "text": "of information so that\nyou can survive and not get killed by cars regularly. All right. That's exactly the\nproblem we're going",
    "start": "60270",
    "end": "66322"
  },
  {
    "text": "to talk about here,\nwhich is, how do we use our knowledge of the world\nto structure our perception? To actually modify\nwhat we see in order",
    "start": "66322",
    "end": "72960"
  },
  {
    "text": "to be able to\nsolve this problem? How do we take a small\nimpoverished stimulus and extract a huge\namount of information",
    "start": "72960",
    "end": "78896"
  },
  {
    "text": "about the world around us? So let's start\nwith a few examples where knowledge about the\nworld really, practically",
    "start": "78897",
    "end": "84180"
  },
  {
    "text": "changes what we see. So I'm Canadian. So I'm required to show you a\nCanadian flag in every talk. Here we are.",
    "start": "84180",
    "end": "90750"
  },
  {
    "text": "You can take this flag and\nyou can give it to any of you. You can give it to any\nkid and you can ask them,",
    "start": "90750",
    "end": "95870"
  },
  {
    "text": "here's a marker. Put big red marks around\nthe regions on this flag or in the regions in\nthis image that are red.",
    "start": "95870",
    "end": "102024"
  },
  {
    "text": "And it's pretty\nclear to all of us that there is a distinction\nbetween the red that's in the flag, and the bars,\nand in the Maple Leaf,",
    "start": "102024",
    "end": "107339"
  },
  {
    "text": "versus the red that's\nactually in the background. And we can all tell\nthose two apart. Except if you actually\nlook at the pixel values,",
    "start": "107339",
    "end": "113640"
  },
  {
    "text": "you open them in Photoshop, or\nGIMP, or whatever other program you want, you're going to notice\nthat those pixel values are",
    "start": "113640",
    "end": "118900"
  },
  {
    "text": "actually not\nparticularly different. There's no threshold\nthat you can choose that will separate\nthe red on the flag",
    "start": "118900",
    "end": "124590"
  },
  {
    "text": "from the red in the background. so you're doing a huge\namount of inference just to solve this\ntrivial, little problem of,",
    "start": "124590",
    "end": "130619"
  },
  {
    "text": "what color is where? You're using knowledge\nabout regions, knowledges about flags, knowledge\nabout transparency,",
    "start": "130620",
    "end": "137430"
  },
  {
    "text": "in order to figure out\nthat the red flag is different from the\nred in the background. So this is a really\npractical way",
    "start": "137430",
    "end": "143862"
  },
  {
    "text": "that your knowledge\nabout the world really changes your perception. You're not seeing the colors\nthat are really there.",
    "start": "143862",
    "end": "150260"
  },
  {
    "text": "Another nice example comes from\na paper by Antonino Torralba. So if you look at the\nscene, it's pretty blurry.",
    "start": "150260",
    "end": "156450"
  },
  {
    "text": "And it has to be blurry\nbecause your visual system is so incredibly good, we have\nto degrade the input for you to see how poor it\nactually is if we take away",
    "start": "156450",
    "end": "163859"
  },
  {
    "text": "some information. So this looks like a scene. And the background\nlooks like a building. In the foreground, you can\nthere's maybe a street.",
    "start": "163860",
    "end": "170310"
  },
  {
    "text": "And the thing on the street\nkind of looks like a car. Does it look like\na car to everybody? Awesome.",
    "start": "170310",
    "end": "175770"
  },
  {
    "text": "We can look at a\nslightly different image. We can look at a\nvery similar scene. Again, same building\nin the background,",
    "start": "175770",
    "end": "181319"
  },
  {
    "text": "same street in the foreground. Now, there's kind of a\nblob in the foreground. And it looks as\nif it's a person.",
    "start": "181320",
    "end": "186379"
  },
  {
    "text": "It looks like a person\nto everyone, right? Awesome. Well, the only\nproblem is the blob",
    "start": "186380",
    "end": "191670"
  },
  {
    "text": "on the left is exactly the\nsame as the blob on the right. It's difficult to believe me,\nbut you can find these two images online and in his paper.",
    "start": "191670",
    "end": "198269"
  },
  {
    "text": "You can open them up in\nyour favorite image viewer. You can zoom in and\nyou'll see they are pixelized completely identical.",
    "start": "198270",
    "end": "204280"
  },
  {
    "text": "So you're using a tremendous\namount of information to put together the fact that\nbuildings and streets-- when",
    "start": "204280",
    "end": "210090"
  },
  {
    "text": "you see these horizontal\nstreaks, it means a car. And when you see these vertical\nstreaks, it means people.",
    "start": "210090",
    "end": "215910"
  },
  {
    "text": "And this really changes\nhow you see the world. And it changes it to the point\nwhere you actually, probably don't believe me that these\ntwo blobs are the same.",
    "start": "215910",
    "end": "222690"
  },
  {
    "text": "And I couldn't believe\nit either until I really zoomed in and checked. So you can see lots\nof interesting effects",
    "start": "222690",
    "end": "228660"
  },
  {
    "text": "where your high-level\nknowledge of the world is structuring your\nlow-level perception, and it is actually\noverriding it.",
    "start": "228660",
    "end": "235012"
  },
  {
    "text": "You've seen this example\nwith the hammer, where you were unable to\nrecognize what's going on in a small region.",
    "start": "235012",
    "end": "240330"
  },
  {
    "text": "But when I give you the\nrest of the context, you can tell that it's a hammer. And when you see\nthe whole video,",
    "start": "240330",
    "end": "245549"
  },
  {
    "text": "you actually don't see\nthe hammer disappear. You're filling in information\nfrom context in single images and you're filling\nin information",
    "start": "245550",
    "end": "251490"
  },
  {
    "text": "from context in whole videos. But if we dig in what's going\non here just a little bit more,",
    "start": "251490",
    "end": "256708"
  },
  {
    "text": "what's going on is\nsomewhere inside your head, there's something resembling\na hammer detector, right? So you run a hammer detector.",
    "start": "256709",
    "end": "263040"
  },
  {
    "text": "And you ran that hammer detector\nover that little region. And it said, I'm not so sure.",
    "start": "263040",
    "end": "269586"
  },
  {
    "text": "I'm not very\nconfident about what I see in this little region. And somewhere inside\nyour head, there's some detector or something that\ncan recognize someone hammering",
    "start": "269586",
    "end": "276990"
  },
  {
    "text": "something. So if we look at sort of a more\ntraditional computer vision pipeline, what you\nwould do is you",
    "start": "276990",
    "end": "282900"
  },
  {
    "text": "would run your hammer detector. You would take your\nhammer detector. You would use that\nknowledge in order to recognize hammering\nin the scene.",
    "start": "282900",
    "end": "288024"
  },
  {
    "text": "And at the end,\nyou would say, I'm really confused because\nmy hammer detector didn't work very well. The reason why you\ncan actually do this",
    "start": "288024",
    "end": "294000"
  },
  {
    "text": "is because you have a feedback. You were able to recognize the\nhammering event as a whole. And that lets you\nupgrade the scores",
    "start": "294000",
    "end": "299796"
  },
  {
    "text": "of your hammer\ndetector, which is very unreliable in this case. So feedback was really\ncritical in being",
    "start": "299796",
    "end": "304860"
  },
  {
    "text": "able to understand this scene. Unfortunately, pretty much\nall of computer vision is feed forward, even though\nmost of your visual system",
    "start": "304860",
    "end": "311430"
  },
  {
    "text": "has, for the most part,\nfeedback connections. More feedbacks\nthan feed forwards. So in this talk, we're going\nto talk about that feedback.",
    "start": "311430",
    "end": "317729"
  },
  {
    "text": "And we're going to\nsee a way that we're going to build this feedback\nin a principled way. That if we choose\nright detections--",
    "start": "317730",
    "end": "323220"
  },
  {
    "text": "right algorithms and\nright representations from our low-level\nperception, we're going to be able to combine it\nwith our high-level perception",
    "start": "323220",
    "end": "329900"
  },
  {
    "text": "of the world. So we've seen that perception\nis very unreliable. The top-down knowledge really\naffects your perception.",
    "start": "329901",
    "end": "336790"
  },
  {
    "text": "And that, what you're\ngoing to see in a moment, is that one integrated\nrepresentation can be used for many tasks.",
    "start": "336790",
    "end": "342419"
  },
  {
    "text": "The advantage of these feedbacks\ngoes beyond just better vision. It lets you solve a lot\nof different problems",
    "start": "342420",
    "end": "348080"
  },
  {
    "text": "that look very, very distinct. But actually, turn out\nto be very, very similar. So one problem is recognition.",
    "start": "348080",
    "end": "354430"
  },
  {
    "text": "I can give you a picture of\na chair, and I can tell you, what is this? And you can tell\nme it's a chair. Or I can give you a picture\nand I can give you a sentence,",
    "start": "354430",
    "end": "361320"
  },
  {
    "text": "this is a chair. And you can tell\nme, I believe you. This is true. There's also a completely\ndifferent problem,",
    "start": "361320",
    "end": "366670"
  },
  {
    "text": "which is retrieval. Related to recognition, right? How about I give you\na library of videos",
    "start": "366670",
    "end": "371952"
  },
  {
    "text": "and ask you to find me the\nvideo where the person was sitting on the chair. And you can solve that problem.",
    "start": "371952",
    "end": "376979"
  },
  {
    "text": "You can also solve a\nproblem like generation. I can give you a video\nand I can tell you, I don't know what's here. Please describe it to me.",
    "start": "376980",
    "end": "382860"
  },
  {
    "text": "So if you see the scene, you\ncan say, what's on the screen? Well, there's a whole bunch\nof text on the screen.",
    "start": "382860",
    "end": "388120"
  },
  {
    "text": "You can also do\nquestion answering. You can take an image like this. I can ask you a question. What's the color of the font?",
    "start": "388120",
    "end": "394200"
  },
  {
    "text": "And you can say,\nthe font is white. So you were able to take\nsome very high-level that's in my head that got\ntransmitted to your head.",
    "start": "394200",
    "end": "401370"
  },
  {
    "text": "You were able to understand the\npurpose of this transmission, connect it to your perception,\nfigure out the knowledge that I",
    "start": "401370",
    "end": "406890"
  },
  {
    "text": "wanted extracted\nfrom your perception, and give it back to me in a\nway that's meaningful to me.",
    "start": "406890",
    "end": "412281"
  },
  {
    "text": "Even more than this,\nyou can disambiguate. You can take a sentence\nthat's extremely ambiguous about the\nworld and figure out",
    "start": "412281",
    "end": "417660"
  },
  {
    "text": "what I'm referring to. And we do this all the time. That's really what makes human\ncommunication possible, right? The fact that most of what I\nsay is extremely ambiguous.",
    "start": "417660",
    "end": "425160"
  },
  {
    "text": "That's why programming\ncomputers is a real pain, but talking to people\nis generally easier depending on the person.",
    "start": "425160",
    "end": "432540"
  },
  {
    "text": "You can also acquire\nknowledge, right? You can look at a\nwhole bunch of videos. If you're a child, you sort of\nperceive the world around you.",
    "start": "432540",
    "end": "438780"
  },
  {
    "text": "Occasionally, an adult comes,\ndrops a sentence here or there for you. But what's important is that\nno adult ever really points out",
    "start": "438780",
    "end": "445530"
  },
  {
    "text": "what the sentence\nis referring to. You don't know that\napproach refers to this particular vector when\nsomeone was doing some action.",
    "start": "445530",
    "end": "452190"
  },
  {
    "text": "You know that Apple refers to\nthis particular object class. Who knows what it could mean? But you get enough\ndata, and you're",
    "start": "452190",
    "end": "457848"
  },
  {
    "text": "able to disentangle\nthis problem of seeing weakly-supervised videos\npaired with sentences.",
    "start": "457848",
    "end": "465750"
  },
  {
    "text": "And we'll see how\nyou can do that. Pretty much everything\nI'll talk about is going to be about videos. And I'll tell you\na story about how I",
    "start": "465750",
    "end": "471491"
  },
  {
    "text": "think we can do images as well. There are a bunch\nof other problems that you can solve\nwith this approach.",
    "start": "471491",
    "end": "477031"
  },
  {
    "text": "I'm sorry? AUDIENCE: So those\nimages go with the video? ANDREI BARBU: Yes. So rather than doing videos,\nwe're going to do images.",
    "start": "477031",
    "end": "482967"
  },
  {
    "text": "So one thing that you can do is\nyou can try to do translation. We haven't done this. We're going to be\ndoing this in the fall. We have two students.",
    "start": "482967",
    "end": "489000"
  },
  {
    "text": "And I'll tell you at the\nend what the story is for how you're going to do a\ntask that sounds as if it's from language to\nlanguage, but you're",
    "start": "489000",
    "end": "495000"
  },
  {
    "text": "going to do it in a grounded\nway that involves vision. Even more than that,\nyou can do planning. And I'll tell you about that\nat the end a little bit.",
    "start": "495000",
    "end": "501430"
  },
  {
    "text": "And finally, you\ncan also incorporate some theory of mind. And that's actually the\nproject that the students are doing as part of summer school.",
    "start": "501430",
    "end": "506611"
  },
  {
    "text": "And I'll say a few\nwords about that. What's important about this\nis the parts at the top, we understand better. We've published\npapers about them.",
    "start": "506611",
    "end": "512466"
  },
  {
    "text": "The parts at the bottom are\nsort of more future work, and I'll say less about them.",
    "start": "512466",
    "end": "517590"
  },
  {
    "text": "Well, one important\npart about this is I've shown you\nall these tasks. But you really\nhave to believe me",
    "start": "517590",
    "end": "522870"
  },
  {
    "text": "that humans perform\nthese tasks all the time. Every time you're sitting at\na table and you ask someone, give me a cup.",
    "start": "522870",
    "end": "528600"
  },
  {
    "text": "That's a really hard\nvision language task. There may be 10 different cups\ninside of you on the table if you're sitting on one\nof the big, round tables.",
    "start": "528600",
    "end": "534823"
  },
  {
    "text": "And you have to figure out,\nwhat object am I talking about? What kind of cup\nam I talking about? Which cup would I\nbe interested in?",
    "start": "534823",
    "end": "540580"
  },
  {
    "text": "If I drank out of the cup, I\nwould expect that you give me my cup, not your cup. Otherwise, let me know. I will sit at different\ntables from now on.",
    "start": "540580",
    "end": "548670"
  },
  {
    "text": "If I ask you, which\nchair should I sit in? Again, you have to solve\na pretty difficult problem where you look at chairs.",
    "start": "548670",
    "end": "554430"
  },
  {
    "text": "You figure out what I mean by\nwhich chair should I sit in. Is it that there's a chair\nthat's reserved for someone.",
    "start": "554430",
    "end": "559590"
  },
  {
    "text": "Is it that a chair\nis for a child and I'm an adult,\nthat kind of thing. You can say something\nlike this is an apple.",
    "start": "559590",
    "end": "566280"
  },
  {
    "text": "And when you say\nthat to a child, you're saying it for\na particular reason. To convey some idea. You have to coordinate your gaze\nwith the other person's gaze",
    "start": "566280",
    "end": "573000"
  },
  {
    "text": "to make sure you're\ndrawing their attention to the real object. Even more than that, you can\nsay very abstract things, like to win this game, you have\nto make a straight line out",
    "start": "573000",
    "end": "580108"
  },
  {
    "text": "of these pieces. That means that we both\nagree on what a piece is. That I've drawn your attention\nto the right idea of a piece.",
    "start": "580108",
    "end": "586549"
  },
  {
    "text": "That we agree on\nwhat a straight line means on this particular board. There's a lot of knowledge\nthat goes into each of these.",
    "start": "586549",
    "end": "592110"
  },
  {
    "text": "But the important part\nis that they're each grounded in perception. We have to agree on what we're\nseeing in front of each other",
    "start": "592110",
    "end": "597690"
  },
  {
    "text": "in order to be able to\nexchange this information. And pretty much everything that\nwe do in daily communication",
    "start": "597690",
    "end": "603370"
  },
  {
    "text": "is a language-vision\nproblem on some level. All right. So if we believe these\nproblems are important,",
    "start": "603370",
    "end": "609160"
  },
  {
    "text": "we can make one\nother observation, which is none of\nyou got training in most of these problems. No adult ever sat you\ndown and said, OK.",
    "start": "609160",
    "end": "615700"
  },
  {
    "text": "Now, you're four. Now I'm going to teach\nyou how to ask questions about the real world. Or no one sat you\ndown and said, OK.",
    "start": "615700",
    "end": "621010"
  },
  {
    "text": "Now, let's talk about\nlanguage acquisition. You're supposed to\ndo gradient descent. So what's important is you have\nsome core ability that's shared",
    "start": "621010",
    "end": "628060"
  },
  {
    "text": "across all of these tasks? And you're able to\nacquire knowledge, maybe in one of these tasks\nor across all of these tasks.",
    "start": "628060",
    "end": "634069"
  },
  {
    "text": "You're able to put it together. And as soon as you\nhave this knowledge, you can use this for\nall these other tasks without having to\nlearn anything else.",
    "start": "634069",
    "end": "640532"
  },
  {
    "text": "And that's what\nwe're going to see. And the core of this that\nwe're going to focus on is recognition.",
    "start": "640532",
    "end": "645670"
  },
  {
    "text": "So we're going to\nbuild one component. This is that engineering\nportion of the talk. We're going to build one\nscoring function that",
    "start": "645670",
    "end": "652060"
  },
  {
    "text": "takes a sentence in a video\nand gives you a score. How well does this\nsentence match this video? If the score is 1, it\nmeans the system really",
    "start": "652060",
    "end": "658690"
  },
  {
    "text": "believes the sentence is\ndepicted by the video. If the score is 0, it\nmeans the system really believes the sentence does not\noccur anywhere in this video.",
    "start": "658690",
    "end": "665734"
  },
  {
    "text": "And this is the\nbasic thing that's going to allow us to connect our\ntop-down knowledge about what's going on in the world with\nour low-level perception.",
    "start": "665734",
    "end": "672982"
  },
  {
    "text": "And after we have\nthis, we're going to see how we reformulate\neverything in terms of this one function, so we\ndon't have to learn",
    "start": "672982",
    "end": "678550"
  },
  {
    "text": "anything else about the world. All right. So we said we need this one\nfunction, scoring function",
    "start": "678550",
    "end": "684700"
  },
  {
    "text": "between sentences and videos. So let's look at\nwhat we would need to have inside this\nfunction in the first place.",
    "start": "684700",
    "end": "690130"
  },
  {
    "text": "If I give you a video like\nthis, it's just a person riding a skateboard. And I give you a sentence.",
    "start": "690130",
    "end": "695570"
  },
  {
    "text": "The person rode the\nskateboard leftward. Well, I can ask you, is the\nsentence true of this video?",
    "start": "695570",
    "end": "702580"
  },
  {
    "text": "Indeed, it is true. But let's think\nabout what you had to do in order to be able\nto answer this question. Well, you had to at some level\ndecide there's a person there.",
    "start": "702580",
    "end": "709979"
  },
  {
    "text": "I'm not saying that\nyou're doing this in this order in your brain. I'm not saying that they\nhave to be individual stages.",
    "start": "709979",
    "end": "715120"
  },
  {
    "text": "I'm not saying you have to\nhave to object detectors. But at some point, you\nhad to decide there really is a person there somehow.",
    "start": "715120",
    "end": "721150"
  },
  {
    "text": "You also had to decide\nthere is a skateboard there. You had to look at these\nobjects over time, or at least--",
    "start": "721150",
    "end": "727450"
  },
  {
    "text": "in at least one or\ntwo frames decide that they have a\nparticular relationship, so that the person\nisn't flying in the air and the skateboard\ncontinues onwards.",
    "start": "727450",
    "end": "734514"
  },
  {
    "text": "And you had to look at this\nrelationship and decide, yeah. OK, this is writing. And it's happening leftward.",
    "start": "734514",
    "end": "739665"
  },
  {
    "text": "So you have to have these\ncomponents on some level. You've got to see the objects. You've got to see the\nrelationships, the static",
    "start": "739665",
    "end": "745060"
  },
  {
    "text": "and the changing relationship\nbetween the objects. And you have to have some way\nof combining those together to form some kind\nof sentence you",
    "start": "745060",
    "end": "751570"
  },
  {
    "text": "can represent that knowledge. And that's what\nwe're going to do. Everything I described to you\nis this feed-forward system,",
    "start": "751570",
    "end": "757180"
  },
  {
    "text": "right? We had objects. We have tracks. We take tracks and\nwe build events. Events like ride.",
    "start": "757180",
    "end": "764259"
  },
  {
    "text": "And we take those\nevents together and we form sentences\nout of them. And there's this hard\nseparation, right?",
    "start": "764260",
    "end": "769960"
  },
  {
    "text": "It's easy to understand a\nsystem where what you do is you have objects, tracks,\nevents, and sentences. And you use tracks in order\nto see if your events happened",
    "start": "769960",
    "end": "778397"
  },
  {
    "text": "and your events in order to\nsee if a particular sentence occurred. So that's what we're\ngoing to describe first,",
    "start": "778397",
    "end": "783400"
  },
  {
    "text": "and then we're going to\nsee how, because we're going to choose the right\nrepresentations for each of these, these feedbacks become\ncompletely trivial and very",
    "start": "783400",
    "end": "789790"
  },
  {
    "text": "natural to implement. All right. We need to start with\nsome object detections. Otherwise, we're just going\nto hallucinate objects",
    "start": "789790",
    "end": "796043"
  },
  {
    "text": "all the time. Any off-the-shelf object\ndetector that you choose will sometimes work. Here, we ran a person detector\nin red and a bag detector",
    "start": "796043",
    "end": "802863"
  },
  {
    "text": "in blue. It will sometimes give\nyou false positives. Trees are often\nconfused for people. I guess we're both\ntwo vertical-- two",
    "start": "802863",
    "end": "810730"
  },
  {
    "text": "long, vertical lines. And sometimes, you\nget false negatives. Sometimes, a bag\nis so deformable",
    "start": "810730",
    "end": "815949"
  },
  {
    "text": "that you think the\nperson's knee is the bag. Lest you think that object\ndetection is solved,",
    "start": "815950",
    "end": "821440"
  },
  {
    "text": "it actually isn't. So if you look at something\nlike the image net challenge, mostly people talk about\nthe image classification.",
    "start": "821440",
    "end": "828270"
  },
  {
    "text": "The stuff in light blue. And they're saying\nthat there's 10% error. These days, there's\n5% error on this.",
    "start": "828270",
    "end": "833830"
  },
  {
    "text": "But that's really not what\nyou're doing in the real world. You're not classifying\nwhole images. When you see an image in the\nreal world, what you're doing",
    "start": "833830",
    "end": "840880"
  },
  {
    "text": "is you're trying to figure\nout what objects are where. And that's the red part. That's the part where you have\nan average precision of 50%.",
    "start": "840880",
    "end": "847270"
  },
  {
    "text": "In other words, the\nobject detector really, really, really sucks. Most of the time, it's\ngoing to be pretty wrong.",
    "start": "847270",
    "end": "853190"
  },
  {
    "text": "It's very, very, very far away\nfrom how accurate you are. If your object\ndetector was that bad, you would die every time\nyou crossed the street.",
    "start": "853190",
    "end": "860709"
  },
  {
    "text": "All right. So we believe that object\ndetection doesn't work well. In order to fix this,\nbecause somehow we",
    "start": "860710",
    "end": "865766"
  },
  {
    "text": "have to be able to extract\nsome knowledge about the video that's pretty robust for us to\nbe able to track these objects and recognize\nthese sentences, we",
    "start": "865767",
    "end": "872600"
  },
  {
    "text": "need to modify object\ndetectors a little bit. We're going to go into\nour object detector. And normally, they\nhave a threshold.",
    "start": "872600",
    "end": "878560"
  },
  {
    "text": "At some point, they learn that\nif the score of this detection is above this level, I\nshould have confidence in it.",
    "start": "878560",
    "end": "884020"
  },
  {
    "text": "And if the score of this\ndetection is below this level, I shouldn't have\nconfidence in it. And what we're\ngoing to do is we're going to remove that threshold.",
    "start": "884020",
    "end": "889420"
  },
  {
    "text": "We're going to tell\nthe object detector, give me thousands or millions\nof detections in every frame. We're going to take\nthose detections",
    "start": "889420",
    "end": "895450"
  },
  {
    "text": "and we're going to figure out\nhow to filter them later on. All right. The way we're going\nto do this-- and this",
    "start": "895450",
    "end": "900730"
  },
  {
    "text": "is the only slide that's\ngoing to have any equations. And it's just going to\nbe a linear combination. All we're going to\ndo is we're going",
    "start": "900730",
    "end": "906620"
  },
  {
    "text": "to take every detection in\nevery frame of this video. We're going to arrange\nthem in the lattice. In every column of\nthis lattice, we're",
    "start": "906620",
    "end": "912233"
  },
  {
    "text": "going to have the detections\nfor one particular frame. And in essence, what we\nwant is one detection for every object\nfor every frame.",
    "start": "912233",
    "end": "919030"
  },
  {
    "text": "In other words, we want the\npath through this lattice. We want to select one\ndetection in every column.",
    "start": "919030",
    "end": "924750"
  },
  {
    "text": "But we want tracks that have\na particular property, right? If I'm approaching\nthis microphone,",
    "start": "924750",
    "end": "930060"
  },
  {
    "text": "you know that you expect\nto see me kind of far away. Then, getting closer. Then, eventually I'm\nclose to the microphone.",
    "start": "930060",
    "end": "935205"
  },
  {
    "text": "You don't expect me\nto be over there, and then to appear over\nhere as if I've teleported. So we want to build\nthis intuition",
    "start": "935205",
    "end": "940890"
  },
  {
    "text": "that objects move smoothly. And that objects move according\nto how they previously",
    "start": "940890",
    "end": "946470"
  },
  {
    "text": "moved, right? It's not like someone moves\nfrom one frame 10 pixels over. Then, the next frame, they\nmove 10 pixels to the left.",
    "start": "946470",
    "end": "952410"
  },
  {
    "text": "And they keep oscillating\nbetween the two. And that's what\nwe're going to do. I'm not going to talk\nabout how we compute this. It's really trivial.",
    "start": "952410",
    "end": "957863"
  },
  {
    "text": "If you know about optical\nflow, you can do it. But basically, what we\nwant is a track where we",
    "start": "957863",
    "end": "963210"
  },
  {
    "text": "don't hallucinate the objects. So every node in our resulting\ndetections should be strong.",
    "start": "963210",
    "end": "969209"
  },
  {
    "text": "If we ignore the strength\nof the object detector, we're just going to\npretend that there are a whole bunch of\npeople in front of us.",
    "start": "969209",
    "end": "975150"
  },
  {
    "text": "And every edge should\nalso be strong. In other words, when we\nlook at two detections from adjacent frames, if I have\na person over here in one frame",
    "start": "975150",
    "end": "982260"
  },
  {
    "text": "and a person over\nhere in another frame, I shouldn't really think that's\na very good person track. But if I have a person over\nhere that kind of moved",
    "start": "982260",
    "end": "988675"
  },
  {
    "text": "to the right the\nprevious frame and I have a new detection\nthat's just slightly to the right of that\none, I should expect",
    "start": "988675",
    "end": "994230"
  },
  {
    "text": "that it's a much better track. So that's all we do. And encoding this intuition\nis very, very straightforward.",
    "start": "994230",
    "end": "999660"
  },
  {
    "text": "It's just a linear combination. So the score of\none path, the score of the track of\nan object, is just",
    "start": "999660",
    "end": "1005390"
  },
  {
    "text": "the sum of your confidence\nin the detections. So in every detection\nand every frame, along with the confidence\nthat the object track",
    "start": "1005390",
    "end": "1013160"
  },
  {
    "text": "was actually coherent. All right. So is the only equation we're\ngoing to see in this talk. And it's just a\nlinear combination.",
    "start": "1013160",
    "end": "1019300"
  },
  {
    "text": "But it will come\nback to haunt us several times before the end. All right. So we use dynamic programming.",
    "start": "1019300",
    "end": "1024837"
  },
  {
    "text": "We find the path\nthrough this lattice. And this is a tracker. And actually, Viterbi did\nthis in 1967 for radar.",
    "start": "1024837",
    "end": "1032150"
  },
  {
    "text": "This is not a new idea. Here, we ran it for just\na computer vision task",
    "start": "1032150",
    "end": "1037520"
  },
  {
    "text": "where we just wanted\nto track objects. We ran a person detector\nand a motorcycle detector, but we don't have a\nperson standing up",
    "start": "1037520",
    "end": "1043670"
  },
  {
    "text": "and a person sitting\ndown detector. So the tracker is\ngood enough that it can keep the two people\nseparate from each other,",
    "start": "1043670",
    "end": "1049640"
  },
  {
    "text": "despite the fact\nthat they're actually pretty close in the video. So you see we do a pretty decent\njob of tracking all the objects",
    "start": "1049640",
    "end": "1056420"
  },
  {
    "text": "until they get pretty\nsmall in the field of view and the object detector\ndoesn't work well anymore. All right.",
    "start": "1056420",
    "end": "1062690"
  },
  {
    "text": "So now what we have are\nthe tracks of objects. We can see object motion\nover time and from a video.",
    "start": "1062690",
    "end": "1068600"
  },
  {
    "text": "And somehow, we have\nto look at these tracks and determine what\nhappened to them. Was someone riding?",
    "start": "1068600",
    "end": "1073760"
  },
  {
    "text": "Was someone running? Was someone bouncing\nup and down? In order to do this, we're\ngoing to get some features",
    "start": "1073760",
    "end": "1079040"
  },
  {
    "text": "from our tracks. You can look at the\ntrack in every frame and you can extract out\na lot of information.",
    "start": "1079040",
    "end": "1084170"
  },
  {
    "text": "You can extract out\nthe average color. You can extract out the\nposition, the velocity, acceleration, aspect ratio.",
    "start": "1084170",
    "end": "1090020"
  },
  {
    "text": "Anything that you\nwant to get out of this frame knowing that\nthis bounding box is there, you can compute and the\nalgorithm doesn't care.",
    "start": "1090020",
    "end": "1097280"
  },
  {
    "text": "All right. There's one small\nproblem, though. Most of the time, we need more\ncomplicated feature vectors. So for example\nfor ride, it's not",
    "start": "1097280",
    "end": "1103817"
  },
  {
    "text": "enough to have a feature vector\nthat only includes the person. You needed to look at\nthe relative position between the person\nand the skateboard",
    "start": "1103817",
    "end": "1109790"
  },
  {
    "text": "to determine-- that are\nactually going together and one isn't going right and\nthe other one is going left. So for that, what we're\ngoing to do is we're",
    "start": "1109790",
    "end": "1116120"
  },
  {
    "text": "going to build a feature vector\nfor the agent of the action in the case of ride\nand a feature vector",
    "start": "1116120",
    "end": "1121520"
  },
  {
    "text": "for the instrument--\nthe skateboard. We're going to concatenate\nthe two together, so we get a bigger\nfeature vector.",
    "start": "1121520",
    "end": "1127310"
  },
  {
    "text": "And then we're going to have\nsome extra features that tell us about the relationships\nbetween these two. So we can include things\nlike the distance,",
    "start": "1127310",
    "end": "1133399"
  },
  {
    "text": "the relative velocity,\nthe angle, overlap. Anything that you want to\ncompute between these two",
    "start": "1133400",
    "end": "1138830"
  },
  {
    "text": "bounding boxes in this frame,\nyou're welcome to compute. All right. And if you build this feature\nvector between this person",
    "start": "1138830",
    "end": "1145809"
  },
  {
    "text": "and the skateboard, you could\nrecognize the person rode the skateboard in this video. If you build a different\nfeature vector,",
    "start": "1145809",
    "end": "1151430"
  },
  {
    "text": "for example between\nthese two people, you could recognize the\nperson was approaching the other person, or the person\nwas leaving the other person.",
    "start": "1151430",
    "end": "1157760"
  },
  {
    "text": "If you build a feature\nvector between the skateboard and the other person,\nyou could recognize the skateboard is approaching\nthe person, et cetera.",
    "start": "1157760",
    "end": "1164600"
  },
  {
    "text": "So depending on which\nfeature vector you build, you can recognize\ndifferent kinds of actions. So when we have our tracks,\nwe know how the objects",
    "start": "1164600",
    "end": "1171409"
  },
  {
    "text": "moved in these videos. We get out some feature\nvectors from our tracks. And what we need to do is decide\nwhat these feature vectors",
    "start": "1171410",
    "end": "1177470"
  },
  {
    "text": "are actually doing. Is the person riding\nthat skateboard? The way we're going to do this\nis using hidden Markov models.",
    "start": "1177470",
    "end": "1182651"
  },
  {
    "text": "Hidden Markov models\nare really simple. All they assume is\nthat there is a model of the world that follows a\nparticular kind of dynamics.",
    "start": "1182651",
    "end": "1189140"
  },
  {
    "text": "In this case, imagine that we\nhave an action like approach. I'm far away from the object.",
    "start": "1189140",
    "end": "1194190"
  },
  {
    "text": "I get closer to the object. Eventually, I'm\nnext to the object. So this action, for\nexample, has three states.",
    "start": "1194190",
    "end": "1201680"
  },
  {
    "text": "One where I was far, one\nas I was getting nearer, one when I was very close. And we have a\nparticular transition",
    "start": "1201680",
    "end": "1206960"
  },
  {
    "text": "between these states, right? We already said that\nI don't teleport. So I shouldn't be able\nto go from being far away",
    "start": "1206960",
    "end": "1212120"
  },
  {
    "text": "to being near. So you should expect me\nto go from the first state to the second state\nand to the third state without going from\nthe first to the last.",
    "start": "1212120",
    "end": "1219370"
  },
  {
    "text": "In each state,\nyou have something that you want to\nobserve about me, right? You want to really see that I'm\nfar away in the first state,",
    "start": "1219370",
    "end": "1225549"
  },
  {
    "text": "that I'm getting\ncloser in the second, and I'm actually\nthere in the third. So we have some model for what\nwe expect to see in every state",
    "start": "1225550",
    "end": "1232309"
  },
  {
    "text": "and we can connect this\nwith our feature vectors. So the idea is\nthere's some hidden information behind the\nmotion of these objects.",
    "start": "1232310",
    "end": "1239054"
  },
  {
    "text": "And we're going to assume\nthat hidden information is represented within HMM. And what we need to\nrecover is the real state",
    "start": "1239054",
    "end": "1245120"
  },
  {
    "text": "of these objects. So if you see a video of me\nmoving towards this microphone,",
    "start": "1245120",
    "end": "1250820"
  },
  {
    "text": "you have to recover some\nhidden information of, which frames was far away in? Which frames was getting nearer?",
    "start": "1250820",
    "end": "1257720"
  },
  {
    "text": "And which frames was I\nactually next to the object? For now what we're\ngoing to do is we're going to assume that we\nhave one of these hidden Markov",
    "start": "1257720",
    "end": "1264761"
  },
  {
    "text": "models for every different word. So for every verb, we have a\ndifferent hidden Markov model. There's one for approach.",
    "start": "1264761",
    "end": "1270039"
  },
  {
    "text": "There's one for pickup. There's one for ride, et cetera. And if you want to tell me\nwhat's going on in this video, you just have a big library\nof hidden Markov models.",
    "start": "1270040",
    "end": "1277166"
  },
  {
    "text": "You apply every\none to every video. You have some threshold. And anything above that\nthreshold, you say happened.",
    "start": "1277166",
    "end": "1282410"
  },
  {
    "text": "And you produce a\nsentence for it. OK. If we look at how you\nactually figure out",
    "start": "1282410",
    "end": "1288559"
  },
  {
    "text": "what this hidden information\nis, what state am I in when I'm approaching\nthis object, it looks a lot like the tracker.",
    "start": "1288560",
    "end": "1294094"
  },
  {
    "text": "What you have is you have to\nmake a choice in every frame. Your choice is, which\nstate is my action in?",
    "start": "1294094",
    "end": "1299920"
  },
  {
    "text": "Is it state 1 through\n3, or some other state? In the same way that in tracker,\nyou have to make a choice. You have to choose,\nwhich detection is",
    "start": "1299920",
    "end": "1306520"
  },
  {
    "text": "the system in for each frame? And here, you also have edges. Edges tell you, how\nlikely am I to transition",
    "start": "1306520",
    "end": "1312800"
  },
  {
    "text": "between different\nstates in my action? And every node also has a score. It's the score of,\ndid you actually",
    "start": "1312800",
    "end": "1318830"
  },
  {
    "text": "observe me doing what\nyou're supposed to observe me doing in every action? So if you're saying\nI'm in the first state,",
    "start": "1318830",
    "end": "1324492"
  },
  {
    "text": "did you actually see me\nstationary and far away from that object? And what you want is a\npath through this lattice",
    "start": "1324492",
    "end": "1330679"
  },
  {
    "text": "in the same way that\nwe had a path before. And a path just means\nyou made a decision that I'm in state 1\nin the first frame",
    "start": "1330680",
    "end": "1337130"
  },
  {
    "text": "or in state 1 in the\nthird frame, et cetera. And that's just the linear\ncombination of the scores.",
    "start": "1337130",
    "end": "1342930"
  },
  {
    "text": "So it's the same\nequation we saw before. So here's an example of this\nsort of feed-forward pipeline",
    "start": "1342930",
    "end": "1348049"
  },
  {
    "text": "in action. We ran it over a\nfew thousand videos. It produces output like the\nperson carried something,",
    "start": "1348050",
    "end": "1355130"
  },
  {
    "text": "the person went away, the person\nwalked, the person had the bag. It's pretty limited\nin its vocabulary. It has 48 verbs, about\n30 different objects,",
    "start": "1355130",
    "end": "1362809"
  },
  {
    "text": "a few different prepositions. And it even works\nwhen the camera moves. So the person chased\nthe car rightward,",
    "start": "1362810",
    "end": "1369050"
  },
  {
    "text": "the person slowly ran\nrightward to the car. And it should also probably\nsay the person had a really bad day, but that's for the future.",
    "start": "1369050",
    "end": "1376920"
  },
  {
    "text": "So we've seen this\nfeed-forward pipeline. We've seen that we\ncan get objects. We can get tracks. We can look at our\ntracks, get some features,",
    "start": "1376920",
    "end": "1384050"
  },
  {
    "text": "run event detectors, take\nthose event detectors, and produce some sentences. And now, all we're\ngoing to do is",
    "start": "1384050",
    "end": "1389780"
  },
  {
    "text": "we're going to break down\nthe barriers between these and show you how you can have\nfeedback in a really, really simple way.",
    "start": "1389780",
    "end": "1395450"
  },
  {
    "text": "All right. So first, let's combine our\nevent detector and our tracker. Because what that's\ngoing to say is, if you're looking for someone\nriding something, well,",
    "start": "1395450",
    "end": "1402911"
  },
  {
    "text": "you should be biased\ntowards seeing people that are riding something. So in the occlusion\nexample, if you see someone go behind\nsome large pillar,",
    "start": "1402911",
    "end": "1410570"
  },
  {
    "text": "well, you might lose them. But you have a bias that you\nshould reacquire someone riding a skateboard after\nthey leave the pillar,",
    "start": "1410570",
    "end": "1416960"
  },
  {
    "text": "which you don't have if you just\nrun the tracker independently from the event detector. So the way we're going\nto put them together",
    "start": "1416960",
    "end": "1423500"
  },
  {
    "text": "is very, very easy. There's a reason why these\ntwo look completely identical and why the inference algorithm\nbetween them is identical.",
    "start": "1423500",
    "end": "1430279"
  },
  {
    "text": "Right now, what we're doing is\nwe have a tracker on the left, or on your left.",
    "start": "1430280",
    "end": "1435740"
  },
  {
    "text": "And we have an event\nrecognizer on the right. Right now, we're running\none, and then we're",
    "start": "1435740",
    "end": "1441440"
  },
  {
    "text": "feeding the output of\none into the other. Basically, we run\none maximization, and then we run\nanother maximization.",
    "start": "1441440",
    "end": "1447265"
  },
  {
    "text": "And all we're\ngoing to do is move the max on the\nright to the left. And you get the exact\nsame inference algorithm.",
    "start": "1447265",
    "end": "1453470"
  },
  {
    "text": "The intuition behind this\nis you have two lattices. And you can take the\ncross-product of the lattices.",
    "start": "1453470",
    "end": "1458750"
  },
  {
    "text": "Basically, for\nevery tracker node, you just look at all the\nevent recognizer's nodes and you make one big\nnode for each of those.",
    "start": "1458750",
    "end": "1465650"
  },
  {
    "text": "And every node\nrepresents the fact that the tracker\nwas in some state and the event recognizer\nwas in some other state.",
    "start": "1465650",
    "end": "1472086"
  },
  {
    "text": "So we have a node that\nsays the tracker chose the first detection. The event recognizer\nwas in the first state. We have another node that\nsays the tracker chose",
    "start": "1472086",
    "end": "1478070"
  },
  {
    "text": "the second detection. The event recognizer was\nstill in the first state. And you do this for\nevery detection. Then, you do the same thing\nfor the event recognizer",
    "start": "1478070",
    "end": "1485210"
  },
  {
    "text": "being the second\nstate, et cetera. So you're just taking\na cross-product between all of the states.",
    "start": "1485210",
    "end": "1491040"
  },
  {
    "text": "Does that make sense? Another way to say it is that\nwe have two Markov chains.",
    "start": "1491040",
    "end": "1496370"
  },
  {
    "text": "One that's observing the\noutput from the object detector and another one that's observing\nthe output of the middle Markov",
    "start": "1496370",
    "end": "1501990"
  },
  {
    "text": "chain. And you do joint\ninfluence over them. And the way you can\ndo joint inference is by taking the cross-product.",
    "start": "1501990",
    "end": "1508020"
  },
  {
    "text": "Basically, you have two\nhidden Markov models. One that does tracking and one\nthat does event recognition.",
    "start": "1508020",
    "end": "1513246"
  },
  {
    "text": "And all we're going to\ndo is joint difference in both of them. So rather than trying to\nchoose the best detection,",
    "start": "1513246",
    "end": "1518940"
  },
  {
    "text": "and then the best\nstate for my event, I'm going to jointly\nfigure out, what's the best detection if I\nassume I'm in this state?",
    "start": "1518940",
    "end": "1524720"
  },
  {
    "text": "What's the best detection if I\nassume I'm in this other state? And at the end, I'll pick\nthe best combination.",
    "start": "1524720",
    "end": "1531710"
  },
  {
    "text": "Make sense? So this is a way for\nyour event recognizer to influence your tracker,\nbecause now you're",
    "start": "1531710",
    "end": "1537809"
  },
  {
    "text": "jointly choosing the best\ndetection for both the tracker and the event recognizer. So that was really,\nreally simple.",
    "start": "1537810",
    "end": "1544330"
  },
  {
    "text": "We put in a tremendous\namount of feedback by just taking a cross product. So we can see this in action.",
    "start": "1544330",
    "end": "1549789"
  },
  {
    "text": "I'm going to show you\nthe same video twice. The person is not going to\nmove in this video at all. What we told the system is that\na ball will approach a person.",
    "start": "1549789",
    "end": "1557289"
  },
  {
    "text": "That's it we didn't\ntell them which person. We didn't tell the system\nwhich particular ball,",
    "start": "1557289",
    "end": "1562574"
  },
  {
    "text": "which direction it's\ngoing to come from, or anything like that. The top detection in this\nframe happens to be the window.",
    "start": "1562574",
    "end": "1568169"
  },
  {
    "text": "It's a little hard to see. It's quite a bit\nstronger than the person. But because neither the\nwindow nor the person",
    "start": "1568170",
    "end": "1574710"
  },
  {
    "text": "ever move in this\nscenario, the tracker can't possibly help you. You have no motion information.",
    "start": "1574710",
    "end": "1580800"
  },
  {
    "text": "The only way to override\nthat window detection is to know something\nelse about the world.",
    "start": "1580800",
    "end": "1586540"
  },
  {
    "text": "So we told it that the\nball will approach. And you can see that for the\ncombined tracker and event recognizer.",
    "start": "1586540",
    "end": "1592200"
  },
  {
    "text": "Indeed, when the ball comes into\nview, it will make more sense. So the reason why we actually--\ncoming back to the question",
    "start": "1592200",
    "end": "1598950"
  },
  {
    "text": "that you asked. Why we don't run it\nover small windows is because we want this effect\nof knowledge that's much,",
    "start": "1598950",
    "end": "1604270"
  },
  {
    "text": "much later on in the video. Like the fact that the\nball will enter or approach that person as\nopposed to that window",
    "start": "1604270",
    "end": "1609420"
  },
  {
    "text": "to actually help you much\nearlier in the video. If you run it over small\nwindows, you lose that effect.",
    "start": "1609420",
    "end": "1615450"
  },
  {
    "text": "So here, you track the person\ncorrectly from the very first frame despite the fact that\nthe ball only comes into view",
    "start": "1615450",
    "end": "1621210"
  },
  {
    "text": "halfway through the video. There are many more\nexamples of this. In this case, it's a\nperson carrying something.",
    "start": "1621210",
    "end": "1627570"
  },
  {
    "text": "Here, we told the system one\nperson's carrying something. And you'll see when\nthe person moves,",
    "start": "1627570",
    "end": "1633330"
  },
  {
    "text": "we can detect the\nperson and the bag. The object detector fails much,\nmuch earlier because the person",
    "start": "1633330",
    "end": "1639210"
  },
  {
    "text": "was deformable. So we've seen how we can combine\ntogether trackers and events recognizers. And now, we need\nto add sentences.",
    "start": "1639210",
    "end": "1645684"
  },
  {
    "text": "And the trick for\nadding sentences is going to do more of the same. What we're going to do is\nwe're going to take a tracker.",
    "start": "1645684",
    "end": "1652020"
  },
  {
    "text": "It's just exactly\nwhat we saw before. And what we just\ndid a moment ago is we combined it with\nan event recognizer.",
    "start": "1652020",
    "end": "1657528"
  },
  {
    "text": "Well, there's no reason why\nwe can't add more trackers. We actually kind\nof did that, right? We were tracking both a person\nand a ball a moment ago.",
    "start": "1657529",
    "end": "1663580"
  },
  {
    "text": "So we can take an even\nbigger cross-product, have multiple trackers,\nand have multiple words.",
    "start": "1663580",
    "end": "1669510"
  },
  {
    "text": "So all we're saying\nis, I have, say, five trackers that are running. I have five words\nthat I want to detect,",
    "start": "1669510",
    "end": "1674970"
  },
  {
    "text": "or 10 words that\nI want to detect. And I want to make the choice\nfor all of these 5 trackers jointly, so that they match\nall of these 10 words.",
    "start": "1674970",
    "end": "1683040"
  },
  {
    "text": "In this picture,\nbasically our words are kind of-- our sentences\nare kind of like bags of words, right? Every word is combined\nwith every tracker.",
    "start": "1683040",
    "end": "1689900"
  },
  {
    "text": "But we know if you look at\nthe structure of a sentence like the tall person\nquickly rode the horse,",
    "start": "1689900",
    "end": "1694919"
  },
  {
    "text": "not every word refers to\nevery object in the sentence. So you can run your object\ndetectors over your video.",
    "start": "1694920",
    "end": "1702234"
  },
  {
    "text": "And you can look\nat your sentence. And you can look at\nthe nouns and say, OK. So I have people and\nhorses inside the sentence.",
    "start": "1702234",
    "end": "1709170"
  },
  {
    "text": "And you can say, OK. Well, if I have people and\nhorses, I need two trackers. But you can look a little\nbit more at your sentence",
    "start": "1709170",
    "end": "1714895"
  },
  {
    "text": "and see that, oh, well,\nit's the other horse. So you analyze your\nsentence and you",
    "start": "1714895",
    "end": "1720030"
  },
  {
    "text": "can determine there are three\nparticipants in the event described by the sentence. There's a person and two horses.",
    "start": "1720030",
    "end": "1726360"
  },
  {
    "text": "One's the agent. One's the patient-- the\nthing that's being ridden-- and one's source-- the\nthing that is being left.",
    "start": "1726360",
    "end": "1737159"
  },
  {
    "text": "Does that make sense? Awesome. So now, given a sentence, we\nknow that we need n trackers.",
    "start": "1737160",
    "end": "1743620"
  },
  {
    "text": "And for every word, we can\nhave a hidden Markov model. We can have a hidden\nMarkov model for ride. It's just another verb.",
    "start": "1743620",
    "end": "1749589"
  },
  {
    "text": "And we just have to be\ncareful how we build a feature vector for ride. Because if we build\nit in one way, we're going to detect the\nperson rode the horse.",
    "start": "1749589",
    "end": "1756090"
  },
  {
    "text": "And if we build it\nin the opposite way by concatenating the vectors\nthe other way around, we're going to detect the\nhorse rode the person, which",
    "start": "1756090",
    "end": "1762360"
  },
  {
    "text": "is not what we want. We can also detect tall. Tall is kind of a weird\nhidden Markov model, right? It has only a single state,\nbut it's still a hidden Markov",
    "start": "1762360",
    "end": "1769140"
  },
  {
    "text": "model. It just wants to see\nthat this object is tall. So maybe its aspect ratio is\nmore than the mean aspect ratio",
    "start": "1769140",
    "end": "1776010"
  },
  {
    "text": "of objects of this class. But nonetheless, it still\nfits into this paradigm.",
    "start": "1776010",
    "end": "1781369"
  },
  {
    "text": "We can do the same\nthing for quickly. We can have an HMR for that. We can do leftward. We can do away from. Away from looks\na lot like leave.",
    "start": "1781369",
    "end": "1788320"
  },
  {
    "text": "It's the same meaning. And basically, we end up\nwith this bipartite graph. At the top, we have lattices\nthat represent words.",
    "start": "1788320",
    "end": "1795779"
  },
  {
    "text": "Each word has a\nhidden Markov model. And in the middle,\nwe have lattices that represent trackers.",
    "start": "1795780",
    "end": "1800820"
  },
  {
    "text": "We can combine them together\naccording to the links. And you can get these links\nfrom your favorite dependency parser.",
    "start": "1800820",
    "end": "1806149"
  },
  {
    "text": "You can get them from\nBoris's START system. Any language analysis\nsystem will give you this.",
    "start": "1806149",
    "end": "1812372"
  },
  {
    "text": "So this is actually\nall the heavy lifting that we have to do. Everything from now on\nis kind of eye candy.",
    "start": "1812372",
    "end": "1818487"
  },
  {
    "text": "One thing that we really\nwanted to make sure that system was doing is\nthat we could distinguish different sentences.",
    "start": "1818487",
    "end": "1823690"
  },
  {
    "text": "So we tried to come up\nwith an experiment that is, in some way,\nmaximally difficult where",
    "start": "1823690",
    "end": "1828987"
  },
  {
    "text": "events are going to\nhappen at the same time. So you can't use time in\norder to distinguish them. And the sentences only differ\nin one word or one lexical item.",
    "start": "1828987",
    "end": "1837600"
  },
  {
    "text": "So in this case,\nwe have a sentence like the person picked up an\nobject and person put down an object. There are two systems\nthat are running.",
    "start": "1837600",
    "end": "1844169"
  },
  {
    "text": "One is running on one sentence. One is running on\nthe other sentence. You're going to see\nthe same video played twice side by side.",
    "start": "1844169",
    "end": "1850726"
  },
  {
    "text": "And you can already see\nthat one system, when we primed it to\nlook for pickup, it detected me picking\nup my backpack.",
    "start": "1850726",
    "end": "1856020"
  },
  {
    "text": "And then, the other one\nit detected one of my lab mates picking up a bin. So the only way you\ncould focus its attention",
    "start": "1856020",
    "end": "1862849"
  },
  {
    "text": "on the right object is if it\nunderstood the distinction between these two\nsentences, or if it was able to represent them.",
    "start": "1862849",
    "end": "1869410"
  },
  {
    "text": "So we can play this game\nmany, many times over. We can have it pay\nattention to the subject. Is a backpack approaching\nsomething or is a chair",
    "start": "1869410",
    "end": "1875670"
  },
  {
    "text": "approaching something? We can have it pay attention\nto the color of an object. Is the red object approaching\nsomething or a blue object",
    "start": "1875670",
    "end": "1882330"
  },
  {
    "text": "approaching something? We can have it pay\nattention to a preposition. Is someone picking up an\nobject to the left of something",
    "start": "1882330",
    "end": "1888570"
  },
  {
    "text": "or to the right of something? And we have many, many\ndozens or hundreds of these. And I won't bore you\nwith all of them.",
    "start": "1888570",
    "end": "1894149"
  },
  {
    "text": "But the important part is\nwe can handle lots and lots of different parts of speech. And we can still represent\nthem and we can still",
    "start": "1894150",
    "end": "1900019"
  },
  {
    "text": "be sensitive to these subtle\ndistinctions in the meanings of the sentences. All right.",
    "start": "1900019",
    "end": "1905400"
  },
  {
    "text": "So we did all the hard work. And we actually built\nthis recognizer-- the score of a\nsentence given a video.",
    "start": "1905400",
    "end": "1911825"
  },
  {
    "text": "And now, it turns\nout that we can reformulate all of\nthese other tasks in terms of this one score. And it's going to do all\nthe heavy lifting for us.",
    "start": "1911825",
    "end": "1918580"
  },
  {
    "text": "So when we tune the\nparameters of whatever goes into the scoring\nfunction, we're going to get the ability to\ndo all these other tasks.",
    "start": "1918580",
    "end": "1925975"
  },
  {
    "text": "So let's look at retrieval. It's the most straightforward\nkind of task, right? It's what YouTube does for you. You go to YouTube.",
    "start": "1925975",
    "end": "1931170"
  },
  {
    "text": "You type in a query, and YouTube\ncomes back with some answers. So let's see what\nYouTube actually does.",
    "start": "1931170",
    "end": "1937650"
  },
  {
    "text": "If you look at YouTube. And if you look at\nsomething like pickup, you get men picking up women.",
    "start": "1937650",
    "end": "1943920"
  },
  {
    "text": "If you look at approach, you\nget men picking up women. If you look at put\ndown, once upon a time you did get men\npicking up women,",
    "start": "1943920",
    "end": "1949944"
  },
  {
    "text": "but rap is now more popular. If you ask something more\ninteresting-- the person",
    "start": "1949944",
    "end": "1955429"
  },
  {
    "text": "approached the\nother person-- you don't get videos where\npeople approach each other. You get videos about how\nyou should approach women.",
    "start": "1955430",
    "end": "1960914"
  },
  {
    "text": "I didn't select these. I typed them in and this\nis just what happened. If you type in, like the\nperson approached the cat, you get lots of people\nplaying with cats,",
    "start": "1960914",
    "end": "1967378"
  },
  {
    "text": "but no one approaching\ncats, including a link that's kind of scary\nand an Airbus landing.",
    "start": "1967378",
    "end": "1974030"
  },
  {
    "text": "And I have no idea\nwhat that means. So what we did is we built a\nvideo retrieval system that actually understands what's\ngoing on in the videos as",
    "start": "1974030",
    "end": "1980909"
  },
  {
    "text": "opposed to just\nlooking at the tags that the people apply\nto these videos. People don't describe\nwhat's going on. People describe some\nhigh-level concept.",
    "start": "1980910",
    "end": "1988299"
  },
  {
    "text": "So we took a whole bunch\nof object detectors that are completely of the\nshelf for people and for horses. And we took 10 Hollywood movies.",
    "start": "1988300",
    "end": "1995070"
  },
  {
    "text": "Nominally, they're all Westerns. They involve people on horses. And the reason why we\nchose people on horses was because people\non horses tend",
    "start": "1995070",
    "end": "2001750"
  },
  {
    "text": "to be fairly larger\nin the field of view. And given that object\ndetectors suck so much, we thought we should kind\nof help the system along",
    "start": "2001750",
    "end": "2007713"
  },
  {
    "text": "s best we could. So we build a system. It's a system that\nknows about three verbs.",
    "start": "2007713",
    "end": "2014820"
  },
  {
    "text": "It knows about two\nnouns, person and horse. It knows about some\nadverbs, quickly and slowly.",
    "start": "2014820",
    "end": "2021100"
  },
  {
    "text": "It knows about some\nprepositions, leftwards, rightwards, towards, away from. And given this template,\nyou can generate about 200,",
    "start": "2021100",
    "end": "2027980"
  },
  {
    "text": "300 different sentences. So we can type in something\nlike the person rode the horse.",
    "start": "2027980",
    "end": "2033830"
  },
  {
    "text": "And we can get a\nbunch of results. So you can see, we were in 90%\naccurate in the top 10 results.",
    "start": "2033830",
    "end": "2039150"
  },
  {
    "text": "You can see these are really\nvideos of people riding horses. The way this works is we took\none of these long videos.",
    "start": "2039150",
    "end": "2044240"
  },
  {
    "text": "We chopped it up into\nmany small segments and we ran over each\nindividual segment. You could run it\nover the whole video,",
    "start": "2044240",
    "end": "2050179"
  },
  {
    "text": "but then it would just\nclassify the whole video because it's an HMM\nand would sort of adapt to the length of the video.",
    "start": "2050179",
    "end": "2056009"
  },
  {
    "text": "We can also ask for\nother kinds of queries, like the person rode\nthe horse quickly. You can see we get videos\nthat really are quicker.",
    "start": "2056009",
    "end": "2063739"
  },
  {
    "text": "We can ask for something\nmore ambitious, like the person rode the\nhorse quickly rightward. And we get videos where people\nare riding horses rightward.",
    "start": "2063739",
    "end": "2072061"
  },
  {
    "text": "All right. So we did the hard work of\nbuilding this recognition system. And we saw we can use it\nfor another task, which",
    "start": "2072061",
    "end": "2077840"
  },
  {
    "text": "is retrieval. But let's do something else. Let's do generation. Someone asked about\ngeneration earlier.",
    "start": "2077840",
    "end": "2083750"
  },
  {
    "text": "Generation is very\nsimilar to retrieval. In retrieval, what we had\nwas we had a fixed sentence and we searched\nover all our videos",
    "start": "2083750",
    "end": "2090408"
  },
  {
    "text": "to see which ones\nwere the best match. Here, we have a fixed video. And we're going to search\nover all our sentences.",
    "start": "2090409",
    "end": "2096408"
  },
  {
    "text": "The only trick is you\nhave a language model, so it can generate a\nhuge number of sentences. But we're going\nto see that's OK.",
    "start": "2096409",
    "end": "2103099"
  },
  {
    "text": "So we have a language model. It's very, very small\nmodel by Boris' standards, or the standard of NLP.",
    "start": "2103100",
    "end": "2110210"
  },
  {
    "text": "We have only four verbs, two\nadjectives, only four nouns,",
    "start": "2110210",
    "end": "2116270"
  },
  {
    "text": "some adverbs, et cetera. But the important part is\neven if we ignore recursion, we have a tremendous\nnumber of sentences.",
    "start": "2116270",
    "end": "2122259"
  },
  {
    "text": "And this model is\nrecursive, so we can really generate an infinite number\nof sentences from it. But nonetheless, it\nturns out that you",
    "start": "2122260",
    "end": "2128690"
  },
  {
    "text": "can search the space\nof sentences very, very efficiently and actually\nfind the global optimum. And the intuition for why that's\ntrue is pretty straightforward.",
    "start": "2128690",
    "end": "2136980"
  },
  {
    "text": "You can think of your sentence\nas a constraint on what you can see in the world. The longer your sentence,\nthe more constrains you have.",
    "start": "2136980",
    "end": "2143870"
  },
  {
    "text": "So the lower the\noverall score is. So every time you\nadd a word, the score can't possibly increase, right?",
    "start": "2143870",
    "end": "2149869"
  },
  {
    "text": "The score has to\nalways decrease. So basically, you have this\nmonotonically-decreasing function over a\nlattice of sentences.",
    "start": "2149870",
    "end": "2156814"
  },
  {
    "text": "And if you ignore the\nfact that you only have to search sentences,\nyou can start off with individual words,\naggregate words together.",
    "start": "2156814",
    "end": "2162940"
  },
  {
    "text": "So you look at all\none-word phrases. You can a two-word phrases,\nthree-word phrases. Eventually, get out\nto real sentences.",
    "start": "2162940",
    "end": "2169734"
  },
  {
    "text": "But because this is a\nmonotonically-decreasing function, this is a\nvery quick search. So you can start off\nwith an empty set.",
    "start": "2169734",
    "end": "2176930"
  },
  {
    "text": "You can add a word. For example, you\ncan add carried. You can look at all the ways\nthat you can extend carried",
    "start": "2176930",
    "end": "2183170"
  },
  {
    "text": "with another word or two. So you get a phrase\nlike the person carried. And you can keep\nadding words to it until you get to\nthe global optimum.",
    "start": "2183170",
    "end": "2191090"
  },
  {
    "text": "So given a video\nlike this, where you see me doing\nsomething, you can produce a sentence\nlike the person",
    "start": "2191090",
    "end": "2196400"
  },
  {
    "text": "to the right of the bin\npicked up the backpack.  And that's pretty\nstraightforward.",
    "start": "2196400",
    "end": "2202450"
  },
  {
    "text": "We built a generator in\njust a few lines of code as long as we had our\nrecognition system.",
    "start": "2202450",
    "end": "2207454"
  },
  {
    "text": "So you have this problem\nin question answering that you have to connect\ntwo sentences with a video. And instead of doing that,\nwhat we're going to do",
    "start": "2207454",
    "end": "2213210"
  },
  {
    "text": "is we're going to make\nsome connection between two sentences. So we're going to\ntake our question. We're going to give it to\nsomething like Boris' system.",
    "start": "2213210",
    "end": "2220111"
  },
  {
    "text": "And it's going to\ntell us this question, like, what did the person\nput on top of the red car?",
    "start": "2220111",
    "end": "2226879"
  },
  {
    "text": "If you wanted to answer it,\nyou would produce an answer like, the person put some noun\nphrase on top of the red car.",
    "start": "2226879",
    "end": "2232980"
  },
  {
    "text": "So you can run the\ngeneration system exactly as was suggested. You seed it with this. You give it a\nconstraint that what",
    "start": "2232980",
    "end": "2238830"
  },
  {
    "text": "it has to produce next\ninside this empty gap is a noun phrase. And you're going to\nget out the answer.",
    "start": "2238830",
    "end": "2244430"
  },
  {
    "text": "Another way to\nthink about this is you have sort of a\npartial detector. You look inside the video\nto see where it matches.",
    "start": "2244430",
    "end": "2250290"
  },
  {
    "text": "You choose the best\nregion where it matches, and then you complete\nyour sentence. And you get an answer\nlike the person",
    "start": "2250290",
    "end": "2256090"
  },
  {
    "text": "put the pair on\ntop of the red car. There's one small problem\nwith question answering,",
    "start": "2256090",
    "end": "2261270"
  },
  {
    "text": "and it differs from\ngeneration in one way. So imagine that we're\nin a parking lot and there are a hundred white\ncars inside this parking lot.",
    "start": "2261270",
    "end": "2268380"
  },
  {
    "text": "And you come to me desperate\nand you say, I lost my keys. And I say, don't worry. I know exactly\nwhere your keys are.",
    "start": "2268380",
    "end": "2274109"
  },
  {
    "text": "And you look at me and I say,\nthey're in the white car. And then you think I'm\na complete asshole, because that was totally\nworthless information, right?",
    "start": "2274110",
    "end": "2280590"
  },
  {
    "text": "I told you something\nthat's basically true. It's a parking lot\nfull of white cars, but isn't actually giving\nyou anything useful.",
    "start": "2280590",
    "end": "2287742"
  },
  {
    "text": "So to handle this--\nin the same way that in generation, we\nhad this one parameter that we could tune to get, more\nor less, for both sentences.",
    "start": "2287742",
    "end": "2294679"
  },
  {
    "text": "We're going to add\nonly one parameter to question answering,\nwhich is kind of a truthfulness parameter.",
    "start": "2294679",
    "end": "2300600"
  },
  {
    "text": "Which basically is going to say,\nthis sentence, the person put",
    "start": "2300600",
    "end": "2306360"
  },
  {
    "text": "an object on top of the\nred car in this video, is very ambiguous, right? It could either\nbe Danny that did",
    "start": "2306360",
    "end": "2312240"
  },
  {
    "text": "it or it could be me\nthat put something on top of the red car. So what we're going\nto do is we're going to take this\ncandidate's answer.",
    "start": "2312240",
    "end": "2318269"
  },
  {
    "text": "We're going to run\nit over the video. And we're going to see how\nmany times it has really close matches in the video. And depending on\nthis one parameter,",
    "start": "2318269",
    "end": "2324720"
  },
  {
    "text": "we're going to say\nyou are allowed to say more things\nabout the video to become more specific about\nwhat you're referring to.",
    "start": "2324720",
    "end": "2331350"
  },
  {
    "text": "But potentially, slightly\nless true because the score will be lower. In the same way\nthat you were saying slightly more in\nthe generation case",
    "start": "2331350",
    "end": "2338190"
  },
  {
    "text": "at the risk of saying\npotentially something that's slightly less true. So this way, you can ignore the\nsentence, which is unhelpful.",
    "start": "2338190",
    "end": "2345180"
  },
  {
    "text": "And you can end up\nsaying something like, the person on\nthe left of the car put an object on\ntop of the red car.",
    "start": "2345180",
    "end": "2352589"
  },
  {
    "text": "So we can actually do\nthat and the system produces that output. We built one\nrecognition approach.",
    "start": "2352590",
    "end": "2358054"
  },
  {
    "text": "And we did retrieval,\ngeneration, and question answering with it. We can also do\ndisambiguation with it. In disambiguation,\nwe take a sentence,",
    "start": "2358054",
    "end": "2364350"
  },
  {
    "text": "like Danny approached\nthe chair with a bag. And you can imagine\nthat this sentence can mean multiple things.",
    "start": "2364350",
    "end": "2370150"
  },
  {
    "text": "It could mean Danny was\nactually carrying a bag and approaching a chair.",
    "start": "2370150",
    "end": "2375780"
  },
  {
    "text": "Or it could mean there\nwas a bag on a chair and Danny was approaching it.",
    "start": "2375780",
    "end": "2381312"
  },
  {
    "text": "And there's the\nquestion of, how do you decide which\ninterpretation for the sentence corresponds to which video?",
    "start": "2381312",
    "end": "2386990"
  },
  {
    "text": " Basically, you can\ntake your sentences",
    "start": "2386990",
    "end": "2392200"
  },
  {
    "text": "and you can look at\ntheir parse trees. And you're going to see\nthat they're different. Essentially, your\nlanguage system is going to give you\na slightly different",
    "start": "2392200",
    "end": "2398228"
  },
  {
    "text": "internal representation\nfor each of these. And we already know that\nwhen we build our detectors for the sentence, we take\nthese kinds of relationships",
    "start": "2398228",
    "end": "2405280"
  },
  {
    "text": "between the words as inputs. So even though there's\none sentence in English that described both of\nthese scenarios, when",
    "start": "2405280",
    "end": "2411160"
  },
  {
    "text": "we build detectors\nwe're going to end up with two different detectors. One for one meaning, one\nfor the other meaning.",
    "start": "2411160",
    "end": "2417587"
  },
  {
    "text": "And then we can just\nrun the detectors and figure out which meaning\ncorresponds to which video. And indeed, that's what we did.",
    "start": "2417587",
    "end": "2423772"
  },
  {
    "text": "Except that there\nare lots and lots of different\npotential ambiguities. There are different\nkinds of attachment.",
    "start": "2423772",
    "end": "2428890"
  },
  {
    "text": "In the same case-- I won't go through all of them. But for example, you might\nnot know where the bag is.",
    "start": "2428890",
    "end": "2434230"
  },
  {
    "text": "You might not know who's\nperforming the action. You might not be\nsure if both people are performing the\naction or only one person",
    "start": "2434230",
    "end": "2440860"
  },
  {
    "text": "is performing the action. There may be some\nproblems with references.",
    "start": "2440860",
    "end": "2446770"
  },
  {
    "text": "So this is a very\nsimple example, like Danny picked up\nthe bag in the chair. It is yellow. But this is the kind of\nthing that you would see",
    "start": "2446770",
    "end": "2453301"
  },
  {
    "text": "if you had a long paragraph. You would have some\nreference later on or earlier on to some person.",
    "start": "2453301",
    "end": "2458980"
  },
  {
    "text": "And you wouldn't be sure\nwho was the referent. And it turns out that if you\nhave sentences like this,",
    "start": "2458980",
    "end": "2464880"
  },
  {
    "text": "you can disambiguate\nthem pretty reliably. ",
    "start": "2464880",
    "end": "2470079"
  },
  {
    "text": "So what's important is it's\nnot just a case of parse trees. We need a more interesting\ninternal representation.",
    "start": "2470080",
    "end": "2476109"
  },
  {
    "text": "And an example of how we do\nthis is we take a sentence and we make some first-order\nlogic formula out of it.",
    "start": "2476110",
    "end": "2481869"
  },
  {
    "text": "So you have some variables. The chair is something like x. You have Danny, who\nmoved it, and I moved it.",
    "start": "2481870",
    "end": "2488455"
  },
  {
    "text": "Or in the other case, you\nhave two separate chairs. And I moved one and\nDanny moved the other. And they're distinct chairs.",
    "start": "2488455",
    "end": "2494440"
  },
  {
    "text": "What we do is we first\nignore the people. So we just say there\nare two people. And in both cases, we're\ndistinct from each other.",
    "start": "2494440",
    "end": "2501538"
  },
  {
    "text": "But we don't have person\nrecognizers, face recognition, or anything like that. Then for each of these\nvariables, we build a tracker.",
    "start": "2501539",
    "end": "2508780"
  },
  {
    "text": "And for every constraint,\nwe have a word model. And essentially, you can go from\nthis first-order logic formula",
    "start": "2508780",
    "end": "2514600"
  },
  {
    "text": "to one of our detectors. So it's exactly the\nsame thing as the case where we had a\nsentence and a video.",
    "start": "2514600",
    "end": "2520570"
  },
  {
    "text": "And we just wanted to see, is\nthe sentence true of the video? Except that now we have\na sentence interpretation",
    "start": "2520570",
    "end": "2525850"
  },
  {
    "text": "and the video.  So we've seen that\nif all you have",
    "start": "2525850",
    "end": "2531380"
  },
  {
    "text": "are multiple interpretation\nof a sentence, you can figure out which\none belongs to which video.",
    "start": "2531380",
    "end": "2537114"
  },
  {
    "text": "And we'll come back\nto this in a moment, because it's actually\nquite useful. So you can imagine\na scenario where",
    "start": "2537114",
    "end": "2542380"
  },
  {
    "text": "you want to talk to a robot. And you want to\ngive it a command. You don't want to play 20\nquestions with it, right? You want to tell it something.",
    "start": "2542380",
    "end": "2548260"
  },
  {
    "text": "It should look at\nthe environment. And it should figure out,\nyou're referring to this chair and this is what\nI'm supposed to do.",
    "start": "2548260",
    "end": "2553900"
  },
  {
    "text": "So the other reason\nfor disambiguation is going to be because you\nget a lot of ambiguities",
    "start": "2553900",
    "end": "2559270"
  },
  {
    "text": "while you're acquiring language. So we're going to break\ndown language acquisition into two parts.",
    "start": "2559270",
    "end": "2564920"
  },
  {
    "text": "One part is we want to learn the\nmeanings of each of our words. And another one is we want to\nlearn how we take a sentence",
    "start": "2564920",
    "end": "2570910"
  },
  {
    "text": "and we transform it into\nthis internal representation that we use to actually\nbuild these detectors.",
    "start": "2570910",
    "end": "2576549"
  },
  {
    "text": "So if you look at\nthe first one, let's say you have a whole\nbunch of videos. And every video comes\nwith a sentence.",
    "start": "2576550",
    "end": "2582697"
  },
  {
    "text": "You don't know what the\nsentence is actually referring to in the video. When children are born, nobody\ngives mothers bounding boxes",
    "start": "2582697",
    "end": "2588914"
  },
  {
    "text": "and tells them, put this\naround the Teddy bear so your child knows what\nyou're referring to. So we don't get those.",
    "start": "2588914",
    "end": "2594100"
  },
  {
    "text": "We have this more\nweakly-supervised system. But what's important is we\nget this data set and there are certain correlations\nin this data set, right?",
    "start": "2594100",
    "end": "2601090"
  },
  {
    "text": "We know the chair\noccurs in some videos. We know that backpack\noccurs in others just by looking at the sentence.",
    "start": "2601090",
    "end": "2606820"
  },
  {
    "text": "We know pickup occurs in others. So basically, this\nis the same thing as training one, big\nhidden Markov model.",
    "start": "2606820",
    "end": "2612700"
  },
  {
    "text": "Except that now we have\nmultiple hidden Markov models that have a small amount\nof dependency between them.",
    "start": "2612700",
    "end": "2617984"
  },
  {
    "text": "And I won't talk about this. You'll have to take\nmy word for it. You can look at the paper. But it's identical to\nthe Baum-Welch algorithm.",
    "start": "2617984",
    "end": "2625690"
  },
  {
    "text": "Essentially, all you do is you\ntake the gradient through all the parameters of\nthese words and you can acquire their meanings.",
    "start": "2625690",
    "end": "2632390"
  },
  {
    "text": "There are lots of\ntechnical issues with this, but that's the general idea.",
    "start": "2632390",
    "end": "2637696"
  },
  {
    "text": "So we can also look\nat learning syntax. And this is something\nthat we haven't done, but we really want to do. And this is where disambiguation\nwork really comes into play.",
    "start": "2637696",
    "end": "2645015"
  },
  {
    "text": "So if I give you a\nsentence, like Danny approached the chair with a\nbag, you feed it into a parser. Something like\nBoris' start system.",
    "start": "2645015",
    "end": "2651279"
  },
  {
    "text": "And you get potentially\ntwo parse trees, right? One for one\ninterpretation and one for the other interpretation.",
    "start": "2651280",
    "end": "2657190"
  },
  {
    "text": "You take the video\nand you can select one of these parse trees. That's the game we just\nplayed a moment ago. But imagine that we take Boris'\nsystem and we brain damage",
    "start": "2657190",
    "end": "2665350"
  },
  {
    "text": "it a little bit. Or we take some deep\nnetwork that does parsing and we just randomize a\nfew of the parameters.",
    "start": "2665350",
    "end": "2671220"
  },
  {
    "text": "So now, rather than getting\na single or two parse trees for our two interpretations,\nwe get 100 or 1,000",
    "start": "2671220",
    "end": "2677170"
  },
  {
    "text": "different parse trees. We can take each\none of those and we can see, how well does\nthis match our video?",
    "start": "2677170",
    "end": "2682686"
  },
  {
    "text": "And we get some\ndistribution over them. Maybe we won't get a single\none that matches the best. Maybe we'll get a\nfew that match well",
    "start": "2682686",
    "end": "2688570"
  },
  {
    "text": "and a bunch that match\nreally, really poorly. So this provides a signal to\nactually train the parser.",
    "start": "2688570",
    "end": "2693891"
  },
  {
    "text": "Essentially, you\nhave a parser that produces a distribution\nover parse trees. You use the vision\nsystem to decide",
    "start": "2693892",
    "end": "2699550"
  },
  {
    "text": "which of these parse trees\nare better than others. And you feed this information\nback into the parser and retrain it.",
    "start": "2699550",
    "end": "2705040"
  },
  {
    "text": "We haven't done this,\nbut it's in the pipeline. And eventually, the\nidea is that we're going to be able\nto close the loop",
    "start": "2705040",
    "end": "2712060"
  },
  {
    "text": "and learn the\nmeanings of the words while we end up\nlearning the parser. But that's further\ndown the line.",
    "start": "2712060",
    "end": "2718164"
  },
  {
    "text": "So lest you think\nthat there's something remarkable about language\nlearning in humans, actually lots of animals learn\nlanguage, not just humans.",
    "start": "2718164",
    "end": "2726140"
  },
  {
    "text": "And here's a cute example\nof a dog that does something that our system can't do. And actually, no language\nsystem out there can do.",
    "start": "2726140",
    "end": "2733540"
  },
  {
    "text": "So there's this paper,\nbut this is from PBS. And what ended up\nhappening is this dog",
    "start": "2733540",
    "end": "2740050"
  },
  {
    "text": "knows the meaning of about\n1,000 different words because there are\nlabels that have been attached to different toys.",
    "start": "2740050",
    "end": "2745540"
  },
  {
    "text": "So it has 1,000 different toys. Each one has a unique name. And if you tell the\ndog, give me Blinky,",
    "start": "2745540",
    "end": "2752320"
  },
  {
    "text": "it knows exactly\nwhich toy Blinky is. And it has 100% accuracy\ngetting you Blinky from it's big, big pile of toys.",
    "start": "2752320",
    "end": "2759490"
  },
  {
    "text": "So what they did is\nthey took 10 toys. They put them behind the sofa. And they added\none additional toy",
    "start": "2759490",
    "end": "2765640"
  },
  {
    "text": "that the dog has\nnever seen before. They tested the dog\nmany times to make sure that it doesn't have\na novelty preference",
    "start": "2765640",
    "end": "2771428"
  },
  {
    "text": "or anything like that. And then they asked the\ndog, bring the Blinky. And you can see\nthe dog was asked.",
    "start": "2771428",
    "end": "2777760"
  },
  {
    "text": "It goes behind. It quickly finds Blinky. It brings it back. And there we go. And now, the dog\nis really happy.",
    "start": "2777760",
    "end": "2786710"
  },
  {
    "text": "So now, the dog is going to be\nasked, bring me this new toy. Bring me the professor, or\nwhatever the toy is called.",
    "start": "2786710",
    "end": "2794650"
  },
  {
    "text": "It's a little less certain. OK. So it's going to\ngo behind and it's going to look at\nall the objects.",
    "start": "2794650",
    "end": "2800399"
  },
  {
    "text": "The toy with the\nbeard is the new one that it hasn't seen before. And it was there in\nthe previous trial.",
    "start": "2800399",
    "end": "2805632"
  },
  {
    "text": "So it looks around and\nit's a little uncertain. It doesn't quite\nwant to come back. We're going to see\nthat we're going",
    "start": "2805632",
    "end": "2812500"
  },
  {
    "text": "to have to give it another\ninstruction in a moment. He's going to call it\nback and ask the dog",
    "start": "2812500",
    "end": "2818550"
  },
  {
    "text": "to do exactly the\nsame task again. Isn't telling it anything new. It's just to give it\nsome encouragement.",
    "start": "2818550",
    "end": "2823766"
  },
  {
    "start": "2823766",
    "end": "2829730"
  },
  {
    "text": "So looking around for some toy. And it picks the--\nyou'll see in a moment.",
    "start": "2829730",
    "end": "2835990"
  },
  {
    "text": " It picks the toy that\nit hasn't seen before,",
    "start": "2835990",
    "end": "2842010"
  },
  {
    "text": "because it's a new word. And the dog is really happy. And I think the human is even\nhappier that this actually worked.",
    "start": "2842010",
    "end": "2848010"
  },
  {
    "text": "But the important part\nis, there's this dog that we normally don't associate\nwith having a huge amount",
    "start": "2848010",
    "end": "2853619"
  },
  {
    "text": "of linguistic ability. But it's learning\nlanguage in a way that is far more advanced\nthan anything that we have.",
    "start": "2853620",
    "end": "2859646"
  },
  {
    "text": "And it's learning it\nin a grounded way, like it hard to connect its\nknowledge about what it sees with these toys\nto this new object",
    "start": "2859646",
    "end": "2865380"
  },
  {
    "text": "that it's never seen before\nand understand this new label. And dogs are not the only\nanimal that can do this.",
    "start": "2865380",
    "end": "2871600"
  },
  {
    "text": "There are many other\nanimals that can do this. All right. And of course, children\ndo this as well.",
    "start": "2871600",
    "end": "2876990"
  },
  {
    "text": " So there was a\nquestion about the fact that we're constantly\nusing videos here.",
    "start": "2876990",
    "end": "2883170"
  },
  {
    "text": "And we're very\nfocused on motion. But of course, in many\nof these sentences, we were referring to\nobjects that were static. So we're not only sensitive\nto objects that are moving.",
    "start": "2883170",
    "end": "2890228"
  },
  {
    "text": "So for example, when\nI said something like it was the person\nto the left of the car, neither the person nor the car\nwere moving in that question.",
    "start": "2890228",
    "end": "2897390"
  },
  {
    "text": "It was the pair that was moving. But there's an\ninteresting question, what if you want to recognize\nactions in still images?",
    "start": "2897390",
    "end": "2904950"
  },
  {
    "text": "After all, we can do it. It probably didn't\ninvolve looking at photos. You know, 200 million years\nago when our visual system",
    "start": "2904950",
    "end": "2911400"
  },
  {
    "text": "was being formed. So somehow, we take\nour video ability and we apply it to images.",
    "start": "2911400",
    "end": "2917647"
  },
  {
    "text": "And the way we're going to\ndo that is by taking an image and predicting a video from it. We haven't done this,\nbut we've done the part",
    "start": "2917647",
    "end": "2923820"
  },
  {
    "text": "where you can actually\nget predicting motion from single frames. So the intuition\nabout why this works",
    "start": "2923820",
    "end": "2929670"
  },
  {
    "text": "is, if you look at this\nimage and I ask you, how quickly is this\nbaseball moving? You can give me an answer.",
    "start": "2929670",
    "end": "2936965"
  },
  {
    "text": "AUDIENCE: Not very quickly. ANDREI BARBU: Not very quickly. Right. And if you look\nat this baseball, you can decide that it's\nmoving very quickly, right?",
    "start": "2936965",
    "end": "2946034"
  },
  {
    "text": "So the other story\nin this talk is I'm becoming more\nand more American. I started with the\nCanadian flag and now I ended up with baseball.",
    "start": "2946034",
    "end": "2952070"
  },
  {
    "text": "All right. So you can clearly do this task. There is good\nneuroscience evidence that people are doing\nthis fairly regularly.",
    "start": "2952070",
    "end": "2959599"
  },
  {
    "text": "Kids can do this, et cetera. All right. So now, what we did\nis we went to YouTube",
    "start": "2959600",
    "end": "2965359"
  },
  {
    "text": "and we got a whole\nbunch of videos. Videos that contain cars or\ndifferent kinds of objects. We had eight different\nobject classes.",
    "start": "2965360",
    "end": "2971900"
  },
  {
    "text": "And we ran a standard\noptical flow algorithm just off the shelf. And this gives us an idea\nof how the motion actually",
    "start": "2971900",
    "end": "2978319"
  },
  {
    "text": "happens inside this video. Then, we discard the video. And we only keep\none of the frames. And we train a deep network.",
    "start": "2978320",
    "end": "2984380"
  },
  {
    "text": "This is the only time deep\nnetworks appear in this talk. That takes as input the image\nand predicts the optical flow.",
    "start": "2984380",
    "end": "2991700"
  },
  {
    "text": "It looks a lot like\nan auto-encoder, except the input and the output\nare different from each other. And it turns out this\nworks pretty well.",
    "start": "2991700",
    "end": "2997680"
  },
  {
    "text": "It has similar performance to\nactually doing optical flow on the video with sort of a\ncrappier, earlier optical flow",
    "start": "2997680",
    "end": "3002950"
  },
  {
    "text": "algorithm. So up until now are\nthings that we've done. At the end I'll\ntalk briefly about",
    "start": "3002950",
    "end": "3008980"
  },
  {
    "text": "what we're doing in the future. So one thing that you\ncan do is translation. And you can cast translation\nas a visual language task,",
    "start": "3008980",
    "end": "3016210"
  },
  {
    "text": "even though it sounds like it\nhas nothing to do with vision. So if I give you a\nsentence in Chinese,",
    "start": "3016210",
    "end": "3022240"
  },
  {
    "text": "you can imagine scenarios\nfor that sentence, and then try to describe\nthem with another language",
    "start": "3022240",
    "end": "3027340"
  },
  {
    "text": "that you know. This is very different from\nthe way people do translation right now. So right now, the\nway it works is",
    "start": "3027340",
    "end": "3032920"
  },
  {
    "text": "you have a sentence,\nlike Sam was happy. And you have a parallel corpus. If you want to translate\ninto French, you go off you.",
    "start": "3032920",
    "end": "3038288"
  },
  {
    "text": "Get the Hansard corpus\nand you get a whole bunch of French and English\nsentences that",
    "start": "3038288",
    "end": "3043780"
  },
  {
    "text": "are aligned with each other and\nyou learn the correspondence between them. Here, I translated into\n[AUDIO OUT] Russian.",
    "start": "3043780",
    "end": "3050386"
  },
  {
    "text": "The important part\nis in English, there's no assumption\nabout the gender of Sam. Sam is both a male\nname and a female name.",
    "start": "3050386",
    "end": "3056890"
  },
  {
    "text": "But the problem is Romanian,\nRussian, French, et cetera, they really force you to specify\nthe gender of the people that",
    "start": "3056890",
    "end": "3064299"
  },
  {
    "text": "are involved in these actions. And you have to go\nthrough a certain amount of [AUDIO OUT] really want to\navoid specifying their gender.",
    "start": "3064300",
    "end": "3070579"
  },
  {
    "text": "So here, we specify\nthe gender as male. Here, we specify the\ngender as female. And if all you have is\nstatistical machine translation",
    "start": "3070580",
    "end": "3077800"
  },
  {
    "text": "system, you may get an\narbitrary one of these two. And you may not\nknow that you've got an arbitrary one of these two.",
    "start": "3077800",
    "end": "3082950"
  },
  {
    "text": "And there may be a terrible\nfaux pas at some point.  So this problem is not\nrestricted to gender.",
    "start": "3082950",
    "end": "3091210"
  },
  {
    "text": "And it occurs all the time. For example, in Thai,\nyou specify your siblings by age, not by their gender.",
    "start": "3091210",
    "end": "3097040"
  },
  {
    "text": "So if you have an English\nsentence like my brother did x, translating that\nis quite difficult.",
    "start": "3097040",
    "end": "3102266"
  },
  {
    "text": "In English, you specify relative\ntime through the tense system, but Mandarin doesn't have the\nsame kind of tense system.",
    "start": "3102266",
    "end": "3107871"
  },
  {
    "text": "In this language\nthat I never tried to pronounce after the\nfirst time that I tried,",
    "start": "3107872",
    "end": "3112930"
  },
  {
    "text": "you don't use\nrelative direction. So you don't say the bottle\nto the left of the laptop. We all agree on a\ncommon reference",
    "start": "3112930",
    "end": "3119050"
  },
  {
    "text": "frame like a hill or something. Or we agree on\ncardinal directions. And you say, the bottle\nto the north or something.",
    "start": "3119050",
    "end": "3126280"
  },
  {
    "text": "And these people are\nreally, really good at wayfinding because\nthey constantly have to know where north is. Many languages don't\ndistinguish blue and green.",
    "start": "3126280",
    "end": "3133089"
  },
  {
    "text": "Historically, this\nis not something that languages have done. It's pretty new.",
    "start": "3133090",
    "end": "3138910"
  },
  {
    "text": "For example, Japanese didn't\nuntil a hundred years ago. They only started distinguishing\nthe two fairly recently",
    "start": "3138910",
    "end": "3144790"
  },
  {
    "text": "when they started interacting\nwith the West more. And many languages\ndon't set that boundary at exactly the same place.",
    "start": "3144790",
    "end": "3149870"
  },
  {
    "text": "So one language,\nyou may say blue. In another language, you\nmay have to say green. In Swahili, you specify\nthe color of everything",
    "start": "3149870",
    "end": "3156550"
  },
  {
    "text": "as the color of x. So like in English,\nwe have orange. But in Swahili, I\ncould say the color of the back of my cell phone.",
    "start": "3156550",
    "end": "3163090"
  },
  {
    "text": "And I expect you to know that's\nblue as long as you can see it. In Turkish, there is a\nrelatively complicated",
    "start": "3163090",
    "end": "3170140"
  },
  {
    "text": "evidentiality system. So you have to fairly often\ntell me why you know something. So if you saw\nsomebody do something,",
    "start": "3170140",
    "end": "3176980"
  },
  {
    "text": "you have to mark that in\nthe sentence as opposed to hearing it from someone else. So if it's hearsay, you\nhave to let me know.",
    "start": "3176980",
    "end": "3184210"
  },
  {
    "text": "There are much more complicated\nevidentiality systems where you have to tell me, did\nyou hear it, did you see it, did you feel it?",
    "start": "3184210",
    "end": "3189960"
  },
  {
    "text": "It can get pretty hairy. So there are a lot\nof reasons why just doing the straightforward\nsentence alignment",
    "start": "3189960",
    "end": "3195580"
  },
  {
    "text": "can really fail on you. And you can make some\npretty terrible mistakes. And more importantly,\nyou just won't know",
    "start": "3195580",
    "end": "3201040"
  },
  {
    "text": "that that made these mistakes. So instead, what\nwe've been thinking is sort of translation\nby imagination.",
    "start": "3201040",
    "end": "3206720"
  },
  {
    "text": "So you take a sentence. And it's a generative\nmodel that we have that connects sentences and videos.",
    "start": "3206720",
    "end": "3212230"
  },
  {
    "text": "And what you do is you sample. You sample a whole\nbunch of videos. So basically, you imagine\nwhat scenarios the sentence",
    "start": "3212230",
    "end": "3217420"
  },
  {
    "text": "could be true of. You get your collection\nfrom the generator. You search over sentences\nthat describe these videos",
    "start": "3217420",
    "end": "3225850"
  },
  {
    "text": "and you output a sentence\nthat describes them well in aggregate. So basically, you just\ncombine your ability",
    "start": "3225850",
    "end": "3232300"
  },
  {
    "text": "to sample, which comes\nfrom your recognizer, and your ability to generate. And you get a\ntranslation system.",
    "start": "3232300",
    "end": "3238850"
  },
  {
    "text": "So you do a\nlanguage-to-language task mediated by your understanding\nof the real world.",
    "start": "3238850",
    "end": "3244270"
  },
  {
    "text": "Something else that you\ncan do is planning, which I'll just say two words about. All you do is--",
    "start": "3244270",
    "end": "3251055"
  },
  {
    "text": "[PHONE RINGING] --in a planning task,\nwhat you have is you have a planning language.",
    "start": "3251055",
    "end": "3256279"
  },
  {
    "text": "I'm glad that\nwasn't my cellphone. You have a planning\nlanguage, right? So you have a fairly\nconstrained vocabulary",
    "start": "3256280",
    "end": "3262294"
  },
  {
    "text": "that you can use to\ndescribe your plans. And this allows you to\nhave efficient inference. Instead, you can imagine that\nI have two frames of a video,",
    "start": "3262294",
    "end": "3269810"
  },
  {
    "text": "real or imagined, where\nI have the first world. I am far away from\nthe microphone.",
    "start": "3269810",
    "end": "3275000"
  },
  {
    "text": "I have the last world where\nI'm near the microphone. And I have an unobserved\nvideo between the two.",
    "start": "3275000",
    "end": "3280580"
  },
  {
    "text": "People have work and\nI've done some work on filling in partially\nobserved videos. So it's a very similar idea,\nexcept that here we have",
    "start": "3280580",
    "end": "3287090"
  },
  {
    "text": "a partially-observed video. And we know that this\npartially-observed video should be described by\none or more sentences.",
    "start": "3287090",
    "end": "3292828"
  },
  {
    "text": "So we're going to do the same\nkind of sampling process, where we sample from this\npartially-observed video and we try to describe\nwhat the sentence is.",
    "start": "3292829",
    "end": "3299440"
  },
  {
    "text": "And now you're doing planning. You're coming up\nwith a description of what had happened in this\nmissing chunk of the video.",
    "start": "3299440",
    "end": "3304917"
  },
  {
    "text": "But your planning\nlanguage is English, so you get to take\nadvantage of things like ambiguity, which\nyou couldn't take advantage of in many languages.",
    "start": "3304917",
    "end": "3313970"
  },
  {
    "text": "Theory of mind. The idea here is relatively\nstraightforward as well. So what we have\nright now, basically",
    "start": "3313970",
    "end": "3320052"
  },
  {
    "text": "are two hidden Markov models. Or two kinds of hidden\nMarkov models, right? There's a video. We have some hidden Markov\nmodels that are tracks",
    "start": "3320052",
    "end": "3326300"
  },
  {
    "text": "and we have some hidden Markov\nmodel that look at the tracks and they do some\ninference about what's going on with the\nevents in these videos.",
    "start": "3326300",
    "end": "3332780"
  },
  {
    "text": "So now imagine that\nI had a third kind. A third kind of hidden\nMarkov model that only looks at the trackers. Doesn't look at\nthe words directly.",
    "start": "3332780",
    "end": "3339401"
  },
  {
    "text": "And what it does is it\nmakes another assumption about the videos. So first, we assume the objects\nwere moving in a coherent way.",
    "start": "3339402",
    "end": "3345410"
  },
  {
    "text": "Then, we assumed\nthat the objects were moving according to the\ndynamics of some hidden Markov models.",
    "start": "3345410",
    "end": "3350450"
  },
  {
    "text": "Now, we're going to\nassume that people move according to some\ndynamics of what's going on inside our heads.",
    "start": "3350450",
    "end": "3355859"
  },
  {
    "text": "So you can assume that I\nhave a planner inside my head that tells me what I\nwant to do and what",
    "start": "3355860",
    "end": "3361130"
  },
  {
    "text": "I should do in the future\nto accomplish my goals. And you can look at a sequence\nof my actions and try to infer.",
    "start": "3361130",
    "end": "3367280"
  },
  {
    "text": "If you believe this planner\nis running in my head, what do you think\nI should do next? Now, the nice part about\nmany of these planners",
    "start": "3367280",
    "end": "3374079"
  },
  {
    "text": "is that they look a lot like\nthis hidden Markov models. And the inference algorithms\nlook a lot like these models.",
    "start": "3374079",
    "end": "3379310"
  },
  {
    "text": "So basically, you can do\nthe same kind of trick by assuming that\nHMM-like things are going on inside people's heads.",
    "start": "3379310",
    "end": "3385619"
  },
  {
    "text": "So you can do things\nlike predict actions, figure out what people want\nto do in the future, what they did in the past. ",
    "start": "3385620",
    "end": "3393369"
  },
  {
    "text": "That's what the project is. I want to show you another\nexample of vision and language, but in a totally different\ndomain that I won't talk about,",
    "start": "3393370",
    "end": "3399900"
  },
  {
    "text": "which is in the case of robots. This is something that we\nbuilt several years ago.",
    "start": "3399900",
    "end": "3405710"
  },
  {
    "text": "This is a robot that\nlooks at a 3D structure. It's built out of Lincoln Logs. They're big. They're easier for the robot\nto manipulate than LEGOs.",
    "start": "3405710",
    "end": "3411610"
  },
  {
    "text": "The downside is\nthey're all brown, so it's very difficult\nto do vision on this. But it actually\nwill, in a moment, reconstruct the 3D\nstructure of what it sees.",
    "start": "3411610",
    "end": "3418840"
  },
  {
    "text": "And we annotated and\nread what errors it made. We didn't tell it this. What it does is it\nmeasures its own confidence",
    "start": "3418840",
    "end": "3425650"
  },
  {
    "text": "and it figures out what\nparts are occluded. So it has too\nlittle information. And it plans another view.",
    "start": "3425650",
    "end": "3431970"
  },
  {
    "text": "It goes, it acquires it by\nmeasuring its own confidence. This view is actually worse\nthan the previous view,",
    "start": "3431970",
    "end": "3438370"
  },
  {
    "text": "but it's complementary. So it will actually gain the\ninformation that it's missing. And all of this comes from the\nsame kind of generative model",
    "start": "3438370",
    "end": "3444970"
  },
  {
    "text": "trick that I showed\nyou a moment ago. A similar model, it just\nmakes different assumptions about what's built into it.",
    "start": "3444970",
    "end": "3451671"
  },
  {
    "text": "So now, because we have\na nice generative model, we can integrate the\ntwo views together. You're going to see in a moment.",
    "start": "3451671",
    "end": "3458529"
  },
  {
    "text": "It'll still make some mistakes. It won't be completely confident\nbecause there are some regions that it can't see,\neven from both views.",
    "start": "3458529",
    "end": "3464830"
  },
  {
    "text": "And then what we\ntold it is, OK, fine. For now, ignore the second\nview, take just the first few. Here's a sentence.",
    "start": "3464830",
    "end": "3470570"
  },
  {
    "text": "Or in this case, a\nsentence fragment. The fragment is\nsomething like, there's a window to the left and\nperpendicular to this door.",
    "start": "3470570",
    "end": "3476620"
  },
  {
    "text": "It'll just appear a moment. And integrating this\none view that it saw that it was uncertain about\nwith that one sentence, that's",
    "start": "3476620",
    "end": "3484630"
  },
  {
    "text": "also very generic and\napplied to many structures, determine that\nthese two completely disambiguate the structure.",
    "start": "3484630",
    "end": "3490780"
  },
  {
    "text": "And now, it's perfectly\nconfident in what's going on. And it can go and\nit can disassemble the structure for you. And we can play this\ngame in many directions.",
    "start": "3490780",
    "end": "3497589"
  },
  {
    "text": "We can have the robot\ndescribe structures to us. We can give it a description\nand it can build the structure.",
    "start": "3497590",
    "end": "3502900"
  },
  {
    "text": "One robot can describe\nthe structure in English to another robot who\ncan build it for it. And it's exactly the\nsame kind of idea.",
    "start": "3502900",
    "end": "3510640"
  },
  {
    "text": "You connect your vision\nand your language model to something in the\nreal world, and then you can play many, many\ndifferent tricks",
    "start": "3510640",
    "end": "3517120"
  },
  {
    "text": "with one internal representation\nwithout modifying it at all. But I realized yesterday\nthat I was the last speaker",
    "start": "3517120",
    "end": "3524080"
  },
  {
    "text": "before the weekend,\nso I want to end by leaving you as depressed\nas I possibly can, and tell you all the wonderful\nthings that don't work.",
    "start": "3524080",
    "end": "3531040"
  },
  {
    "text": "And how far away we are\nfrom understanding anything. So first of all,\nwe can't generate the kind of coherent stories\nthat Patrick looks at.",
    "start": "3531040",
    "end": "3538570"
  },
  {
    "text": "Really, if you look at a\nlong video, what we can do is we can search or we\ncan describe small events. A person picks something up.",
    "start": "3538570",
    "end": "3544180"
  },
  {
    "text": "They put it down. What we can say is the\nthief entered the room and rummaged around and\nran away with the gold.",
    "start": "3544180",
    "end": "3550665"
  },
  {
    "text": "That's the kind of thing\nthat you want to generate. It's the kind of thing\nthat kids generate, but we're not there yet.",
    "start": "3550665",
    "end": "3555700"
  },
  {
    "text": "Not even close. We also only reason in 2D. There's no 3D reasoning here. And that significantly hurts us.",
    "start": "3555700",
    "end": "3561880"
  },
  {
    "text": "Although, we have some ideas\nfor how we might do 3D. Another important aspect is we\ndon't know forces and contact",
    "start": "3561880",
    "end": "3567640"
  },
  {
    "text": "relationships. Now, that's fine\nas long as pickup means this kind of\naction where you see me standing next to an\nobject and the object moving",
    "start": "3567640",
    "end": "3574360"
  },
  {
    "text": "up. But sometimes, pickup means\nsomething totally different. So you're going to see\nthis cat is going to pickup that kitten in just a moment.",
    "start": "3574360",
    "end": "3582277"
  },
  {
    "text": "And you're going to see\nif you pay attention to the motion of the\ncat, that it doesn't look like it's picking something up.",
    "start": "3582277",
    "end": "3588901"
  },
  {
    "text": "It's not very good at picking\nup the kitten, mind you. I think this may\nbe its first try. ",
    "start": "3588901",
    "end": "3595619"
  },
  {
    "text": "I think it's having a good day. It's OK. Struggling a little bit. But see?",
    "start": "3595619",
    "end": "3601480"
  },
  {
    "text": "So definitely, picked it up. But it didn't look anything\nlike any of the other pickup examples I showed you.",
    "start": "3601480",
    "end": "3606700"
  },
  {
    "text": "But conceptually,\nyou should totally recognize this if you've\nseen those other examples. And kids can do this.",
    "start": "3606700",
    "end": "3613120"
  },
  {
    "text": "So the important\npart is you have to change how you\nreason you can't just reason about the relative\nmotions of the objects.",
    "start": "3613120",
    "end": "3618923"
  },
  {
    "text": "You have to assume that there\nare some hidden forces going on. And you have to reason\nabout the contact relationships and the\nforces that the objects are",
    "start": "3618924",
    "end": "3625151"
  },
  {
    "text": "undergoing. What happens if you try to\nrecognize a helicopter picking something up. It looks totally different\nfrom a human doing it,",
    "start": "3625151",
    "end": "3632051"
  },
  {
    "text": "but no one has any\nproblems recognizing this. Segmentation is\nalso a huge problem. For many of these\nproblems, you have",
    "start": "3632051",
    "end": "3638379"
  },
  {
    "text": "to pay attention to the fine\nboundaries of the objects in order to understand that\nthat kitten was being rotated and then slightly lifted.",
    "start": "3638379",
    "end": "3645442"
  },
  {
    "text": "There's also a more\nphilosophical problem about what is a part\nand what it means for something to be an object.",
    "start": "3645442",
    "end": "3650470"
  },
  {
    "text": "We arbitrarily say that\nthe cat is an object, but I could refer to its paws. I could refer to its ears.",
    "start": "3650470",
    "end": "3655510"
  },
  {
    "text": "I could refer to one\nsmall patch on its back. As long as we all know\nwhat we're talking about, that can be our object.",
    "start": "3655510",
    "end": "3660790"
  },
  {
    "text": "And that's a problem\nthroughout computer vision. It also occurs in a\ntotally different problem. So if you've ever\nseen Bongard problems,",
    "start": "3660790",
    "end": "3667240"
  },
  {
    "text": "there are these problems where\nyou have these weird patches, and you have to figure out\nwhat's in common between them. And that's the\ncase where you have",
    "start": "3667240",
    "end": "3672609"
  },
  {
    "text": "to dig deep into\nyour visual system to extract a completely\ndifferent kind of information. And this is an\nexample that I prefer.",
    "start": "3672610",
    "end": "3678855"
  },
  {
    "text": "So in this task, you can\ntry to find the real dog. And we can all spot it after\nyou look for a little while.",
    "start": "3678855",
    "end": "3685600"
  },
  {
    "text": "Right? Does everyone see it? OK. So you can all see it The interesting part is--",
    "start": "3685600",
    "end": "3691530"
  },
  {
    "text": "I mean, I doubt you\nhave ever had training detecting real dogs amongst\nmasses of fake dogs.",
    "start": "3691530",
    "end": "3698550"
  },
  {
    "text": "But somehow, you were\nable to adapt and extract a completely different\nkind of information from your visual system.",
    "start": "3698550",
    "end": "3704310"
  },
  {
    "text": "Information that isn't\ncaptured by our feature vector, as I talk about the color,\nlocation, velocity, et cetera.",
    "start": "3704310",
    "end": "3710580"
  },
  {
    "text": "So you have this\nability to extract out task-specific information. You can do things\nlike theory of mind,",
    "start": "3710580",
    "end": "3716580"
  },
  {
    "text": "but you can do far\nmore than assume people are writing a planner. You can detect if I'm sad. If I'm happy.",
    "start": "3716580",
    "end": "3722490"
  },
  {
    "text": "You can reason about\nwhether two people are having a particular\nkind of interaction. Who's more powerful\nthan the other person.",
    "start": "3722490",
    "end": "3728894"
  },
  {
    "text": "You also have a very strong\nphysics model inside your head that underlies much of this. And even more than that, there's\nthe concept of modification.",
    "start": "3728894",
    "end": "3735930"
  },
  {
    "text": "So walking quickly looks very\ndifferent from running quickly. And the way you model\nthese is quite complicated.",
    "start": "3735930",
    "end": "3741720"
  },
  {
    "text": "And the system that I presented\ndoesn't do a good job of it. But one of my favorite\nexamples from my childhood",
    "start": "3741720",
    "end": "3747900"
  },
  {
    "text": "long ago is this one, which\nis a kind of modification. So coyote is going to draw this.",
    "start": "3747900",
    "end": "3754687"
  },
  {
    "text": "You're going to see\nthe Roadrunner try to run through it. And he makes it. And you can imagine what's\nabout to happen next.",
    "start": "3754687",
    "end": "3762145"
  },
  {
    "text": "Coyote is not going\nto have a good day. So this looks silly, right? And you would think to yourself,\nhow could we possibly apply",
    "start": "3762145",
    "end": "3768380"
  },
  {
    "text": "this to the real world? But actually, this happens in\nthe real world all the time. A cage can be open for a mouse,\nbut closed for an elephant.",
    "start": "3768380",
    "end": "3774602"
  },
  {
    "text": "So if you're going to\nrepresent something like, is something closed\nor not, you have to be able to handle\nsituations like this.",
    "start": "3774602",
    "end": "3780281"
  },
  {
    "text": "And that's why\nkids can understand really weird scenarios like\nthis because they're not so outlandish.",
    "start": "3780281",
    "end": "3785896"
  },
  {
    "text": "There's also the problem\nof the vast majority of English verbs-- things like absolve, admire,\nanger, approve, bark, et",
    "start": "3785896",
    "end": "3792430"
  },
  {
    "text": "cetera. All of them require\nfar more knowledge. They require many of the things\nI've talked about before. And actually, far\nmore than them.",
    "start": "3792430",
    "end": "3799680"
  },
  {
    "text": "And what's even worse\nis we also use language in pretty bizarre ways. So there are some kinds\nof idioms in English,",
    "start": "3799680",
    "end": "3805920"
  },
  {
    "text": "like the market\n[AUDIO OUT] bullish, that you have to have seen\nbefore to understand, right? There's no reason\nto assume that bears",
    "start": "3805920",
    "end": "3812266"
  },
  {
    "text": "are better or worse than\nbulls when you apply them to the stock market. On the other hand,\nthere are certain things",
    "start": "3812267",
    "end": "3817530"
  },
  {
    "text": "that are very systematic. I can have an up\nday or a down day, because we've both kind of as a\nculture agreed that up is good",
    "start": "3817530",
    "end": "3823050"
  },
  {
    "text": "and down is bad. Some cultures have made\nthe opposite choice. But usually, it's up\nis good, down is bad. So an idea can be grand\nor it can be small.",
    "start": "3823050",
    "end": "3831210"
  },
  {
    "text": "Because we've decided big things\nare better than small things. Someone's mood can\nbe dark or light.",
    "start": "3831210",
    "end": "3837210"
  },
  {
    "text": "And these are very\nsystematic variations that underlie all of language. And we constantly use\nmetaphoric extension",
    "start": "3837210",
    "end": "3842490"
  },
  {
    "text": "in order to describe\nwhat's going on around us and to talk about\nabstract things. It really seems as if\nthis is kind of built-in",
    "start": "3842490",
    "end": "3848306"
  },
  {
    "text": "to our model of the world. And modeling this is\nkind of over the horizon. And there are many,\nmany, many other things",
    "start": "3848306",
    "end": "3855029"
  },
  {
    "text": "that we're missing here. So I just want to thank all\nmy wonderful collaborators, like Boris, Max, Candace,\nand people at MIT, and people",
    "start": "3855030",
    "end": "3862650"
  },
  {
    "text": "elsewhere. But to recap, what\nwe saw is that we can get a little bit of\ntraction on these problems.",
    "start": "3862650",
    "end": "3867960"
  },
  {
    "text": "We can build one system that\ndoes one simple problem just connects our perception with\nour high-level knowledge,",
    "start": "3867960",
    "end": "3874920"
  },
  {
    "text": "takes a video and a sentence\nand gives us a score. And once we have this\ninteresting connection, this interesting feedback\nbetween these two",
    "start": "3874920",
    "end": "3881700"
  },
  {
    "text": "very different-looking\nsystems, it turns out that we can do\nmany different and sometimes surprising things.",
    "start": "3881700",
    "end": "3888500"
  },
  {
    "start": "3888500",
    "end": "3905432"
  }
]
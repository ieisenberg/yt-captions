[
  {
    "text": "[SQUEAKING] [RUSTLING] [CLICKING]",
    "start": "0",
    "end": "6664"
  },
  {
    "text": " ALAN EDELMAN: All right. Well, welcome to the second\nlecture for this IAP class",
    "start": "6664",
    "end": "13070"
  },
  {
    "text": "on matrix calculus. Steven, do you want\nto say anything before I start on nonlinear\nversus linear maps?",
    "start": "13070",
    "end": "21380"
  },
  {
    "text": "So Philip's going to\nhelp out right away. So here's a picture\nof Philip, the corgi.",
    "start": "21380",
    "end": "27484"
  },
  {
    "text": "He's right over there, in\ncase you haven't seen him yet. And you folks could actually\ngrab your favorite photo.",
    "start": "27485",
    "end": "34250"
  },
  {
    "text": "You don't have to use a corgi. You could have any\nphoto you like. So here in Julia\nI'm just uploading",
    "start": "34250",
    "end": "39500"
  },
  {
    "text": "this picture of Philip. And I've got a few different\ntransformations of a corgi.",
    "start": "39500",
    "end": "46670"
  },
  {
    "text": "And the reason why I'm\nshowing this to you, it's because it's\ncome to my attention",
    "start": "46670",
    "end": "52930"
  },
  {
    "text": "that not everybody has a\nfairly good visual intuition as to the difference between\na linear and a nonlinear map,",
    "start": "52930",
    "end": "60970"
  },
  {
    "text": "or even a map. Here, so let's go ahead. Let me just ask a real quick\nsimple question for starters.",
    "start": "60970",
    "end": "68060"
  },
  {
    "text": "So here I'm just rotating. Right? So I'm rotating Philip. He's going to get dizzy.",
    "start": "68060",
    "end": "73160"
  },
  {
    "text": "OK. No, he's not going to get dizzy. No animal is harmed. ",
    "start": "73160",
    "end": "79090"
  },
  {
    "text": "So, all right. If I'm talking about maps from\nvectors to vectors from Rn--",
    "start": "79090",
    "end": "84760"
  },
  {
    "text": "it's usually Rn as in\nNancy to Rm as in Mary. OK? What are m and n for\nthis transformation?",
    "start": "84760",
    "end": "93340"
  },
  {
    "text": "That's an easy question. Not a trick question. So what are m and n for here?",
    "start": "93340",
    "end": "99960"
  },
  {
    "text": "So think of this\nas a transformation from the original upright\npicture to the rotated picture.",
    "start": "99960",
    "end": "105200"
  },
  {
    "text": "What are m and n? That's an easy one.",
    "start": "105200",
    "end": "111860"
  },
  {
    "text": "Oh, gosh. No, I'm not even\nthinking that way. That's too fancy. Not that you're-- in some deep\nsense you're probably right,",
    "start": "111860",
    "end": "118640"
  },
  {
    "text": "but for the purposes of\nthis class you're way off. So let's try again.",
    "start": "118640",
    "end": "123930"
  },
  {
    "text": "So m and n are the\ndimensions of the vectors. ",
    "start": "123930",
    "end": "131050"
  },
  {
    "text": "Anybody? I thought this was easy. The fact that it's not easy\nis telling me something.",
    "start": "131050",
    "end": "136553"
  },
  {
    "text": "STEVEN JOHNSON: I think\nthe question is, is it the transformation\nof the image you're talking about or\nthe transformation of the coordinates of the image\nthat you're talking about?",
    "start": "136553",
    "end": "143549"
  },
  {
    "text": "ALAN EDELMAN: Does\nthat make a difference? Right. STEVEN JOHNSON: Is it image in\nand image out or coordinate in",
    "start": "143550",
    "end": "149918"
  },
  {
    "text": "and coordinate out? Which one are you talking about? ALAN EDELMAN: Does it matter? Aren't they inverses\nof each other?",
    "start": "149918",
    "end": "155415"
  },
  {
    "text": "Answer either question\nthat Steven just said. ",
    "start": "155415",
    "end": "160849"
  },
  {
    "text": "What do you guys think? Or is the question\njust not clear? Yeah, it's from R2 to R2.",
    "start": "160850",
    "end": "167500"
  },
  {
    "text": "That's whatever. I mean, don't\noverthink the question. Right?",
    "start": "167500",
    "end": "172870"
  },
  {
    "text": "right I've got this Julia. I'm going to hold up my phone. Steven, maybe you can see. I've got this Julia sticker.",
    "start": "172870",
    "end": "179300"
  },
  {
    "text": "Right? It's in the plane, this plane,\nthis two dimensional plane of the phone.",
    "start": "179300",
    "end": "185080"
  },
  {
    "text": "Right? And this rotation is a\nmapping from R2 to R2.",
    "start": "185080",
    "end": "192280"
  },
  {
    "text": "I mean, if you\nwant to focus on-- I suppose if I have the origin\nin the middle of the phone",
    "start": "192280",
    "end": "197860"
  },
  {
    "text": "and I rotate, this\nis a linear map. Right? STEVEN JOHNSON:\nBecause Alan, you",
    "start": "197860",
    "end": "202980"
  },
  {
    "text": "could also talk about\nthe transformation that takes the image of the corgi\nin and gives the rotated image of the corgi out.",
    "start": "202980",
    "end": "208450"
  },
  {
    "text": "ALAN EDELMAN: Isn't that what\nI was-- that was exactly that-- STEVEN JOHNSON: But\nthen the vector space is the number of pixels in\nand the number of pixels out.",
    "start": "208450",
    "end": "215680"
  },
  {
    "text": " ALAN EDELMAN: All right. This is going down a rat hole\nthat I don't want to go--",
    "start": "215680",
    "end": "221192"
  },
  {
    "text": "I don't agree. But I think-- yeah. All I really wanted\nto do-- all right,",
    "start": "221192",
    "end": "226909"
  },
  {
    "text": "I'm going to go\nto the blackboard.  I'm going to go to\nthe blackboard then.",
    "start": "226910",
    "end": "234150"
  },
  {
    "text": "And let's turn on the lights\non the blackboard here. ",
    "start": "234150",
    "end": "242890"
  },
  {
    "text": "All right. So for years in linear\nalgebra classes--",
    "start": "242890",
    "end": "248739"
  },
  {
    "text": "and I'm sure you've seen this-- people will write R2.",
    "start": "248740",
    "end": "255170"
  },
  {
    "text": "Right? And then they would put\ndown-- if it's linear algebra, you'd have a matrix\nA. And people would--",
    "start": "255170",
    "end": "261355"
  },
  {
    "text": "you would draw a vector\nhere, like a vector x. OK? And then you would\nhave the image plane,",
    "start": "261355",
    "end": "267340"
  },
  {
    "text": "also R2 in this case. Right? And x goes to ax.",
    "start": "267340",
    "end": "273009"
  },
  {
    "text": "Right? And if you have another\nvector y, that might go to ay.",
    "start": "273010",
    "end": "280990"
  },
  {
    "text": "You've all seen this in a\nlinear algebra class, right? OK. And if anybody is\nfamiliar with the cover",
    "start": "280990",
    "end": "288370"
  },
  {
    "text": "of Gil Strang's book-- which maybe I should just\nbring up while we're at it. So if you're familiar\nwith the cover",
    "start": "288370",
    "end": "294550"
  },
  {
    "text": "of Strang's linear algebra book,\nwhich is the textbook that's used right here at MIT\nand all over the world,",
    "start": "294550",
    "end": "301850"
  },
  {
    "text": "one of the versions of\nthe book has these houses, this one right here.",
    "start": "301850",
    "end": "307430"
  },
  {
    "text": "OK, so maybe you've\nseen this version. Right here with the-- and this is meant to indicate\nthe transformation of a house.",
    "start": "307430",
    "end": "316000"
  },
  {
    "text": "Right? And so you have a house and\nsome windows and a chimney or something.",
    "start": "316000",
    "end": "321509"
  },
  {
    "text": "I don't know what you have. And the image-- let's say-- I mean, just to be clear,\nif this house was a square",
    "start": "321510",
    "end": "328500"
  },
  {
    "text": "and this was your\neveryday general matrix, what would the image\nlook like over here?",
    "start": "328500",
    "end": "333780"
  },
  {
    "text": "Just generally speaking.  If you transform a square with a\nmatrix, what does it look like?",
    "start": "333780",
    "end": "342520"
  },
  {
    "text": "Just what shape? It's a word you learned in high\nschool or elementary school. It's not a hard question.",
    "start": "342520",
    "end": "349890"
  },
  {
    "text": "It's a parallelogram\nof some kind, right? I don't know where it'll be,\nbut it'll be some sort of-- the square will become a\nparallelogram of some sort.",
    "start": "349890",
    "end": "357710"
  },
  {
    "text": "I don't know where it'll be. The square window will\nalso be a parallelogram with parallel parts.",
    "start": "357710",
    "end": "364100"
  },
  {
    "text": "That little chimney\nor I don't know what that is will get skewed\nin some way as well, right?",
    "start": "364100",
    "end": "369740"
  },
  {
    "text": "This is what happens when\nyou take every point. I mean, I didn't want\nto get into pixels.",
    "start": "369740",
    "end": "375810"
  },
  {
    "text": "I mean, just every\npoint in the plane is being transformed to another\npoint in the plane, right?",
    "start": "375810",
    "end": "381380"
  },
  {
    "text": "This is what we would call\na linear map from R2 to R2. ",
    "start": "381380",
    "end": "389140"
  },
  {
    "text": "Linear map from R2 to R2. It emphasizes about a matrix.",
    "start": "389140",
    "end": "394360"
  },
  {
    "text": "Not the fact that\na matrix is just a two by two four elements. It emphasizes the fact\nthat a matrix is something",
    "start": "394360",
    "end": "400300"
  },
  {
    "text": "that transforms space. OK? And that's all I\nwanted to say, and I",
    "start": "400300",
    "end": "406250"
  },
  {
    "text": "thought that this was a basic\nelement of linear algebra. I'm a little worried\nthat just the way I asked the question\nwasn't clear to people.",
    "start": "406250",
    "end": "412800"
  },
  {
    "text": "So if I had a picture of Philip\nover here-- which I could never draw a good picture of Philip.",
    "start": "412800",
    "end": "419240"
  },
  {
    "text": "Here's a Minecraft Philip. ",
    "start": "419240",
    "end": "425690"
  },
  {
    "text": "It's a terrible Minecraft\npicture of Philip. Right? It would get transformed to\nsome skewed version of Philip",
    "start": "425690",
    "end": "432050"
  },
  {
    "text": "on the other side, and\nthat's what a linear map is. OK. So am I saying things\nyou don't know?",
    "start": "432050",
    "end": "437600"
  },
  {
    "text": "You all know this, right? OK. So with that understanding,\nlet's go back,",
    "start": "437600",
    "end": "447750"
  },
  {
    "text": "turn the lights down low again. So with that\nunderstanding, I just",
    "start": "447750",
    "end": "453690"
  },
  {
    "text": "wanted to show you a few\nlinear and nonlinear maps. ",
    "start": "453690",
    "end": "460120"
  },
  {
    "text": "Not to spend too much time on\nthis, but maybe it's worth it.",
    "start": "460120",
    "end": "465280"
  },
  {
    "text": "Yeah. So a rotation is a\nlinear map from R2 to R2.",
    "start": "465280",
    "end": "470610"
  },
  {
    "text": "Is there still any\nconfusion about pixels or any other nonsense? I just want to think of--",
    "start": "470610",
    "end": "477379"
  },
  {
    "text": "to be very, very clear, I'm\njust thinking of every point-- this is the center. His little black nose here\nis the center of the plane.",
    "start": "477380",
    "end": "484490"
  },
  {
    "text": "And you can always\ndraw a vector. I guess, oh, I could use\nZoom to draw a vector. This is great.",
    "start": "484490",
    "end": "491780"
  },
  {
    "text": "Let's draw a vector right here. So if I'm at the origin,\nevery point, like the tip--",
    "start": "491780",
    "end": "498920"
  },
  {
    "text": "well, I can't draw a straight\nline, but that's my fault. But this is meant to be a vector\nright to the tip of his ear.",
    "start": "498920",
    "end": "504919"
  },
  {
    "text": "And then that vector\nwill stay where it is, but if I rotate the plane, say--",
    "start": "504920",
    "end": "514419"
  },
  {
    "text": "you know, let's not\nrotate that much. Let's rotate maybe 30 degrees.",
    "start": "514419",
    "end": "520360"
  },
  {
    "text": "You see that his ear\nhas moved 30 degrees. Oops, oops, oops. Everybody with me? Any questions?",
    "start": "520360",
    "end": "526510"
  },
  {
    "text": "OK. Let's not belabor this point. So the next thing I\nwant you to do was--",
    "start": "526510",
    "end": "534710"
  },
  {
    "text": "the next thing I\nwanted to do-- let's just clear this-- is show\nyou some other linear transformations.",
    "start": "534710",
    "end": "540570"
  },
  {
    "text": "So instead of rotating is\na little bit too simple, so another linear transformation\nis this hyperbolic rotate.",
    "start": "540570",
    "end": "547190"
  },
  {
    "text": "So let me just switch\nto hyperbolic rotate. Yet again, forgive me.",
    "start": "547190",
    "end": "552430"
  },
  {
    "text": "I just forgot my glasses today. So I'm kind of winging\nthis a little bit. So hyperbolic rotate is\na little less familiar",
    "start": "552430",
    "end": "559480"
  },
  {
    "text": "to a lot of people. So when you rotate-- just to say something also,\nI think, very obvious.",
    "start": "559480",
    "end": "566240"
  },
  {
    "text": "Yeah. When I rotate it, you\nsee the red circle? What happens to Philip's\nears as I rotate?",
    "start": "566240",
    "end": "571720"
  },
  {
    "start": "571720",
    "end": "578470"
  },
  {
    "text": "If I rotate, the ears\nfollow the red circle. Right? They just move along\nthe red circle.",
    "start": "578470",
    "end": "583900"
  },
  {
    "text": "OK. Now I want you to now focus. I'm now doing hyperbolic rotate. I want you to focus on his eyes.",
    "start": "583900",
    "end": "589130"
  },
  {
    "text": "You see the eyes\nare on a hyperbola? OK? You'll notice that as you move,\nhis eyes always actually--",
    "start": "589130",
    "end": "597055"
  },
  {
    "text": "this is what's called\na hyperbolic rotation. And his eyes, even\nas the picture gets more and more skewed,\nso these squares become",
    "start": "597055",
    "end": "604750"
  },
  {
    "text": "flatter and flatter\nparallelograms, you could still see-- I'll go backwards. You could still see\nthat his eyes are always",
    "start": "604750",
    "end": "611470"
  },
  {
    "text": "following a hyperbola as\nopposed to a rotation, an ordinary rotation where the\nred ears would follow a circle.",
    "start": "611470",
    "end": "617269"
  },
  {
    "text": "Right? So this is also a linear\ntransformation in that",
    "start": "617270",
    "end": "623020"
  },
  {
    "text": "literally if you draw a vector\nfrom his nose to any pixel and another vector from\nhis nose to any pixel",
    "start": "623020",
    "end": "629470"
  },
  {
    "text": "and you want to know,\nif you add those two vectors to create\na third vector, then it will add in the image.",
    "start": "629470",
    "end": "635630"
  },
  {
    "text": "OK? And now let me just\nshow you a nonlinear-- some nonlinear transformations.",
    "start": "635630",
    "end": "642839"
  },
  {
    "text": "So here's a nonlinear shear. So what this does is shears\nthings, and you could--",
    "start": "642840",
    "end": "651030"
  },
  {
    "text": "it's already-- and so squares\nare no longer guaranteed to be parallelograms. In fact, they're\nnot parallelograms.",
    "start": "651030",
    "end": "658610"
  },
  {
    "text": " It's much more of\na-- here he is. Poor Philip is being folded up.",
    "start": "658610",
    "end": "666240"
  },
  {
    "text": "And then there's this warp. I mean, we could put\nin any-- this is Julia. You could put in any\nfunction you want.",
    "start": "666240",
    "end": "671680"
  },
  {
    "text": "So here's a warping,\nwhich is also nonlinear. So here's the original\npicture, and you",
    "start": "671680",
    "end": "680709"
  },
  {
    "text": "can see different parts of the\npicture will move differently. And so just to make\nit clear what's",
    "start": "680710",
    "end": "687560"
  },
  {
    "text": "going on with matrix\ncalculus, everybody understands that this is a\nmapping from two vectors to two",
    "start": "687560",
    "end": "693175"
  },
  {
    "text": "vectors, right? From R2 to R2. Right? So if you form the\nJacobian matrix,",
    "start": "693175",
    "end": "698569"
  },
  {
    "text": "what's the size of\nthat Jacobian matrix? ",
    "start": "698570",
    "end": "703710"
  },
  {
    "text": "A two by two Jacobian matrix. And the Jacobian matrix is\ndifferent at every point",
    "start": "703710",
    "end": "710990"
  },
  {
    "text": "in the plane, right? When you're linear,\nthe two by two Jacobian is constant\nthroughout the plane.",
    "start": "710990",
    "end": "716910"
  },
  {
    "text": "It's actually-- like the\npicture on the board, it's just the matrix everywhere.",
    "start": "716910",
    "end": "722090"
  },
  {
    "text": "But when you have a\nnonlinear map like this one, the two by two Jacobian depends\non where you're starting.",
    "start": "722090",
    "end": "729080"
  },
  {
    "text": "And so if one could zoom-- I don't know if one can zoom. Yeah. If you were to zoom\nin, what it's saying",
    "start": "729080",
    "end": "735020"
  },
  {
    "text": "is that a zoomed in picture-- I don't know if you'd\nbe able to see it, that I'm trying\nto Chrome zoom in.",
    "start": "735020",
    "end": "740270"
  },
  {
    "text": "But what a Jacobian is\nsaying is that if you look in a small\nlittle patch, squares",
    "start": "740270",
    "end": "745490"
  },
  {
    "text": "will become parallelograms. Circles will become ellipses. Right? And they'll do it\nin a constant way.",
    "start": "745490",
    "end": "752149"
  },
  {
    "text": "But as you move away\nfrom that small patch, it'll do it differently\nin different places.",
    "start": "752150",
    "end": "757190"
  },
  {
    "text": "Is there any questions about\nwhat a map from R2 to R2",
    "start": "757190",
    "end": "763380"
  },
  {
    "text": "looks like? And of course, I can move\nmy hands around and talk",
    "start": "763380",
    "end": "768720"
  },
  {
    "text": "about maps from R3 to R3. I mean, you could\neasily imagine--",
    "start": "768720",
    "end": "773899"
  },
  {
    "text": "if we turn our heads, in\neffect, what we see in our eyes is a rotation of R3.",
    "start": "773900",
    "end": "778959"
  },
  {
    "text": "Right? That's a linear map as long\nas you fix on one point. But one could imagine\nnonlinear maps of R3.",
    "start": "778960",
    "end": "787139"
  },
  {
    "text": "It's not something I could\neasily do with my hands. But you could-- right?",
    "start": "787140",
    "end": "792240"
  },
  {
    "text": "And so that's R3 to R3. And of course, in\ngeneral, we don't even have to have the same dimension\ngoing in and going out.",
    "start": "792240",
    "end": "798270"
  },
  {
    "text": "It's Rn in, Rm out. OK?",
    "start": "798270",
    "end": "803440"
  },
  {
    "text": "All right. That's all I wanted to say\njust to start things off to get people used to these maps.",
    "start": "803440",
    "end": "809560"
  },
  {
    "text": "All right. Steven, should I\nturn it over to you? STEVEN JOHNSON: Yeah. Sounds good. So I want to talk again today\nabout this generalization",
    "start": "809560",
    "end": "818550"
  },
  {
    "text": "of the notion of a derivative or\nreinterpretation or revisiting",
    "start": "818550",
    "end": "825660"
  },
  {
    "text": "of a derivative as\na linear operator. So if you have any function-- remember what we said last time.",
    "start": "825660",
    "end": "831010"
  },
  {
    "text": "So if you have any\nfunction f of x and you change the input by a\nlittle amount, of course,",
    "start": "831010",
    "end": "836140"
  },
  {
    "text": "there's a little\nchange in the output. And if the change in\nthe input is very small,",
    "start": "836140",
    "end": "842530"
  },
  {
    "text": "then we can\napproximate the change in the output by something\nthat's linear in the input",
    "start": "842530",
    "end": "849210"
  },
  {
    "text": "where it's f. And so this is going to be-- basically it's linear in the\ninput plus higher order terms,",
    "start": "849210",
    "end": "855720"
  },
  {
    "text": "but it'll be convenient just to\ndrop these higher order terms and the notation will be\nthis differential notation.",
    "start": "855720",
    "end": "861010"
  },
  {
    "text": "So we think of this as a really\nsmall infinitesimal change in an arbitrary direction\nif x is a vector.",
    "start": "861010",
    "end": "869120"
  },
  {
    "text": "And so when we take f of\nx plus d minus f of x, we're just going\nto drop implicitly",
    "start": "869120",
    "end": "874700"
  },
  {
    "text": "any term that's higher\norder than linear, has a dx squared or a dx to\nthe 1.5 or anything like that.",
    "start": "874700",
    "end": "881100"
  },
  {
    "text": "And so the definition of\nthe derivative f prime is going to be the\nlinear operator acting",
    "start": "881100",
    "end": "887630"
  },
  {
    "text": "on dx, the change in\nthe input that gives you the change in the output. And so that gives us--",
    "start": "887630",
    "end": "893420"
  },
  {
    "text": "it's equivalent to the 18.01\ndefinition of a derivative, for if f is a scalar function.",
    "start": "893420",
    "end": "899779"
  },
  {
    "text": "A linear operator is\njust a number, the slope, that multiplies by the change in\nx to give you the change in y.",
    "start": "899780",
    "end": "906960"
  },
  {
    "text": "But it also works for\nmultivariable functions. So if the input x is a vector\nand the output is a scalar,",
    "start": "906960",
    "end": "916070"
  },
  {
    "text": "then this is a linear operator. The derivative is a linear\noperator acting on a vector.",
    "start": "916070",
    "end": "922450"
  },
  {
    "text": "dx is an arbitrary change\nin an arbitrary direction in this input\nvector that gives us",
    "start": "922450",
    "end": "928980"
  },
  {
    "text": "the change in f,\nwhich is a scalar. And a linear operator on a\nvector that gives a scalar",
    "start": "928980",
    "end": "936720"
  },
  {
    "text": "is a row vector or\na one row matrix or a co-vector or linear form. There's all sorts of\nfancy names for it,",
    "start": "936720",
    "end": "943290"
  },
  {
    "text": "but it's basically-- it's a\ndot product with something. Right? That's the only\nway to get a vector",
    "start": "943290",
    "end": "948449"
  },
  {
    "text": "and do a linear operation\nand get a scalar. And the thing we're taking\nwith the dot product with we call the gradient.",
    "start": "948450",
    "end": "954100"
  },
  {
    "text": "So the gradient, this df\nis the gradient dot dx, or equivalently f prime is\nthe transpose of the gradient.",
    "start": "954100",
    "end": "962399"
  },
  {
    "text": "It's the row vector,\nthe linear operator that you act that row vector\non a column vector on a dx.",
    "start": "962400",
    "end": "969615"
  },
  {
    "text": "It gives you the df. Right?",
    "start": "969615",
    "end": "974780"
  },
  {
    "text": "This works for ordinary\ncolumn vectors, and we're going to think of\nother vector spaces very soon. OK?",
    "start": "974780",
    "end": "980070"
  },
  {
    "text": "And then the thing I just\nstarted at the very end of the lecture was suppose--",
    "start": "980070",
    "end": "986700"
  },
  {
    "text": "so this is not 18.06 revisited. This is 18.02 revisited. This is still 18.02.",
    "start": "986700",
    "end": "992640"
  },
  {
    "text": "Oops. Black.  The other kind of function\nyou deal with in 18.02",
    "start": "992640",
    "end": "1000560"
  },
  {
    "text": "are functions that take\nvectors in and vectors out. And so for example in an\nintegral and multi-dimensional",
    "start": "1000560",
    "end": "1008960"
  },
  {
    "text": "integral, if you change\ncoordinates, you have x and y and you get some\nnew x and y, that's a function that takes a\nvector in and a vector out.",
    "start": "1008960",
    "end": "1016040"
  },
  {
    "text": "May or may not be linear. So that's where the\nfunction-- the inputs, I'm going to say the\ninputs live in Rn",
    "start": "1016040",
    "end": "1024069"
  },
  {
    "text": "and the outputs live in Rm. So maybe there's a different\nnumber of inputs and outputs.",
    "start": "1024069",
    "end": "1030430"
  },
  {
    "text": "And then when we\nask, same thing. If we change the input\nvector by a little bit,",
    "start": "1030430",
    "end": "1036439"
  },
  {
    "text": "then there's some change in the\noutput vector which we call df. And the change in the output\nvector has m components.",
    "start": "1036440",
    "end": "1043119"
  },
  {
    "text": "The change in the input\nvector has n components in some arbitrary\ndirection, and f prime",
    "start": "1043119",
    "end": "1049120"
  },
  {
    "text": "is the linear operator that goes\nfrom the change in the input, n components, to a change in\nthe output, m components.",
    "start": "1049120",
    "end": "1057590"
  },
  {
    "text": "And the only kind-- and the way we typically\ndescribe such a linear operator is an m by n matrix.",
    "start": "1057590",
    "end": "1063900"
  },
  {
    "text": "Right? So that's what\nyou would multiply by a vector with n components\nto get a vector with components.",
    "start": "1063900",
    "end": "1070640"
  },
  {
    "text": "And we call that matrix, that\nm by n matrix, the Jacobian J. And in fact, you\ncan also think of it",
    "start": "1070640",
    "end": "1078890"
  },
  {
    "text": "in terms of the entries of J.",
    "start": "1078890",
    "end": "1087370"
  },
  {
    "text": "If we ask what the entry\nJij is, this notation means row i, column j.",
    "start": "1087370",
    "end": "1096920"
  },
  {
    "text": " Right? This is going to be equivalent\nto what you learned, hopefully,",
    "start": "1096920",
    "end": "1104150"
  },
  {
    "text": "in 18.02 although not every\nversion of 1802, apparently. It's the same thing\nas partial fi,",
    "start": "1104150",
    "end": "1112910"
  },
  {
    "text": "the derivative of the\ni-th output with respect to the j-th input.",
    "start": "1112910",
    "end": "1121649"
  },
  {
    "text": "I always used to\nget these confused. Is it, which one's the rows,\nwhich one's the columns.",
    "start": "1121650",
    "end": "1126750"
  },
  {
    "text": "The dfi, dxj, dfj, dxi. And in 18.02, people\njust take the determinant",
    "start": "1126750",
    "end": "1134340"
  },
  {
    "text": "of this matrix for integration,\nand then it doesn't matter. Because you\ntranspose the matrix, it doesn't change\nthe determinant.",
    "start": "1134340",
    "end": "1140017"
  },
  {
    "text": "But as a linear operator,\nit really matters. The rows-- here we\ncan even write this.",
    "start": "1140017",
    "end": "1147000"
  },
  {
    "text": "Let me just do it in blue. If you think of a matrix\nas a linear operator,",
    "start": "1147000",
    "end": "1153480"
  },
  {
    "text": "the rows are the outputs which\nare the df's, and the columns",
    "start": "1153480",
    "end": "1159720"
  },
  {
    "text": "are the inputs,\nwhich are the dx's. So it really matters that\nthe rows are the different",
    "start": "1159720",
    "end": "1167460"
  },
  {
    "text": "f's and the columns\nare different x's. Let me just do an example,\nsince we were doing-- ",
    "start": "1167460",
    "end": "1175299"
  },
  {
    "text": "this is to m equals n equals 2. And so m equals n equals\n2, since we were just doing",
    "start": "1175300",
    "end": "1184650"
  },
  {
    "text": "transformations of the plane. So we're going from\ninputs in R2 and then f",
    "start": "1184650",
    "end": "1196000"
  },
  {
    "text": "is taking us to\noutputs also in R2.",
    "start": "1196000",
    "end": "1201055"
  },
  {
    "text": "So we're just mapping\nthe plane to the plane, but it maybe it's not a\nlinear transformation. All right? So if we thought of this\nin 18.02 style, component",
    "start": "1201055",
    "end": "1213990"
  },
  {
    "text": "by component, then we have--",
    "start": "1213990",
    "end": "1222990"
  },
  {
    "text": "f of x, we can think of\nit as two functions, f1",
    "start": "1222990",
    "end": "1228640"
  },
  {
    "text": "of x and f2 of x. ",
    "start": "1228640",
    "end": "1234074"
  },
  {
    "text": "And x, we can think of it\nas two components, x1, x2.",
    "start": "1234074",
    "end": "1240620"
  },
  {
    "text": "Right? And then if you want\nthe change in f-- let's put a vector\nhere to keep track",
    "start": "1240620",
    "end": "1247143"
  },
  {
    "text": "of what things are vectors,\nwhat things are scalars. ",
    "start": "1247143",
    "end": "1252190"
  },
  {
    "text": "The change in f, my claim\nis going to be the Jacobian.",
    "start": "1252190",
    "end": "1258169"
  },
  {
    "text": "And the Jacobian is now going\nto be our two by two Jacobian.",
    "start": "1258170",
    "end": "1265650"
  },
  {
    "text": "And I guess maybe I should\nput outputs in blue here. All right?",
    "start": "1265650",
    "end": "1272160"
  },
  {
    "text": "And the outputs are\nthe different rows. So there's df1,\ndf1, df1, df2, df2.",
    "start": "1272160",
    "end": "1284690"
  },
  {
    "text": "And the inputs are the different\ncolumns, dx1, dx2, dx1, dx2.",
    "start": "1284690",
    "end": "1294370"
  },
  {
    "text": " And then if we multiply\nthis by any change--",
    "start": "1294370",
    "end": "1302020"
  },
  {
    "text": "so you change the input by any\nvector in dx in any direction. So this is our dx.",
    "start": "1302020",
    "end": "1308390"
  },
  {
    "text": "Right? You can see that it works out. Right? So I don't know how I would\nreally write this out,",
    "start": "1308390",
    "end": "1314110"
  },
  {
    "text": "but if we multiply rows times\ncolumns, you get df1, dx1.",
    "start": "1314110",
    "end": "1321820"
  },
  {
    "text": "Let me do it, actually. So that's-- I need a\nlittle more space, maybe. ",
    "start": "1321820",
    "end": "1335100"
  },
  {
    "text": "All right. What's the first row? Row times column. Let me keep my color scheme.",
    "start": "1335100",
    "end": "1341690"
  },
  {
    "text": "df1, df1, df2, df2.",
    "start": "1341690",
    "end": "1348720"
  },
  {
    "start": "1348720",
    "end": "1365539"
  },
  {
    "text": "I think this is it, right? If I do row times column,\nI get partial f1--",
    "start": "1365540",
    "end": "1370789"
  },
  {
    "text": "partial f1 partial x1\ntimes sx1, which is this. Partial f2, partial x2\ntimes dx2, which is this.",
    "start": "1370790",
    "end": "1376767"
  },
  {
    "text": "And the same thing for the\nother row, it's just with f2. Right? Oops, and I forgot a-- I forgot a plus sign.",
    "start": "1376767",
    "end": "1382430"
  },
  {
    "text": " I have to add them.",
    "start": "1382430",
    "end": "1388530"
  },
  {
    "text": "All right? And you can see. So a component by component\nit makes sense, right? If you want the change\nin f1, well, you take--",
    "start": "1388530",
    "end": "1396620"
  },
  {
    "text": "its change, the rate of--\nits slope with respect to x1. You multiply by\nthe change in x1.",
    "start": "1396620",
    "end": "1402710"
  },
  {
    "text": "And you also have to add\nthe slope of f1 with x2 and multiply by the\nchange in x2 and so forth.",
    "start": "1402710",
    "end": "1409280"
  },
  {
    "text": "So really, all the\ncomponents match up, but this is a really-- this gets awkward\nvery, very quickly",
    "start": "1409280",
    "end": "1415429"
  },
  {
    "text": "to write things out\ncomponent-wide like this. Right? It's much easier to just say,\nthis is a linear-- think of it",
    "start": "1415430",
    "end": "1422030"
  },
  {
    "text": "as a whole. It's a linear operator acting\non the change of x, and that, if we want, we can write it down\nas a Jacobian matrix in this m",
    "start": "1422030",
    "end": "1429679"
  },
  {
    "text": "by n matrix. So I want to do a\ncouple of examples. We'll do another example.",
    "start": "1429680",
    "end": "1435960"
  },
  {
    "text": "I think Alan did this the\nother day, but let me just-- it doesn't hurt to do it again.",
    "start": "1435960",
    "end": "1442530"
  },
  {
    "text": "So suppose f of x is\njust a matrix times x.",
    "start": "1442530",
    "end": "1452170"
  },
  {
    "text": "Suppose this is a linear. Right? And so here I'm just going to\nsay, this is a constant matrix.",
    "start": "1452170",
    "end": "1461620"
  },
  {
    "text": "ALAN EDELMAN: Like the ordinary\nrotation and the hyperbolic rotation would be two examples\nof what Steven's doing now.",
    "start": "1461620",
    "end": "1467850"
  },
  {
    "text": "STEVEN JOHNSON: Exactly. So this could be a rotation\nmatrix or something like that if this is two by two. But it doesn't have\nto be two by two.",
    "start": "1467850",
    "end": "1473822"
  },
  {
    "text": "It doesn't even have\nto be a square, right? This could be in output's\nin Rm and the input's in--",
    "start": "1473822",
    "end": "1482710"
  },
  {
    "text": "so the outputs are in Rm\nand the inputs are in Rn.",
    "start": "1482710",
    "end": "1489980"
  },
  {
    "text": "And therefore the A matrix is\nan m by n matrix in general.",
    "start": "1489980",
    "end": "1497510"
  },
  {
    "text": "It could be, for\nexample, two by two. Right? And again, let's just\ndo this the slow way.",
    "start": "1497510",
    "end": "1504210"
  },
  {
    "text": "But still much\nfaster than 18.02. So the 18.02 way would\nbe to write this out as",
    "start": "1504210",
    "end": "1510930"
  },
  {
    "text": "in components. So you take ai-- this is fi is aij sum over--",
    "start": "1510930",
    "end": "1523870"
  },
  {
    "text": "let me keep my color scheme. aij xj and sum over\nj equals 1 to n.",
    "start": "1523870",
    "end": "1536050"
  },
  {
    "text": "And then ugh. All right? I mean, you could write it out\nin terms of all the components",
    "start": "1536050",
    "end": "1542730"
  },
  {
    "text": "and take derivatives that way. It's not so bad, but it starts\nto become really awkward really quickly. Right?",
    "start": "1542730",
    "end": "1548150"
  },
  {
    "text": "If we just think of-- ALAN EDELMAN: --everybody\nto think of indices as ugh. STEVEN JOHNSON: Yeah. ALAN EDELMAN: Often. Not always.",
    "start": "1548150",
    "end": "1553590"
  },
  {
    "text": "Sometimes they're useful, but\nusually they could be not used. STEVEN JOHNSON: Yeah.",
    "start": "1553590",
    "end": "1559710"
  },
  {
    "text": "And another way of\nthinking about it is as soon as you start writing\nthings in terms of indices,",
    "start": "1559710",
    "end": "1565210"
  },
  {
    "text": "everything is very\ncoordinate system dependent. So whereas if you think\nof it just generically, a rotation is an operator that\nrotates things by 90 degrees.",
    "start": "1565210",
    "end": "1573500"
  },
  {
    "text": "Right? You don't have to have\na coordinate system for that operator. Anyway, so what's\nthe derivative?",
    "start": "1573500",
    "end": "1581330"
  },
  {
    "text": "Well, let's just take-- pretty soon we'll\nhave a product rule, but here you just do\nit the slow way again.",
    "start": "1581330",
    "end": "1589320"
  },
  {
    "text": "It's not even that\nslow, you take f. You take your x, and you add\na little change minus f of x.",
    "start": "1589320",
    "end": "1605550"
  },
  {
    "text": "And what's that? We can just plug it in\nand drop nonlinear terms, except in this case there\nwon't be any nonlinear terms.",
    "start": "1605550",
    "end": "1612179"
  },
  {
    "text": "This will be f-- what's\nf of x plus delta x? It's ax plus a dx.",
    "start": "1612180",
    "end": "1621010"
  },
  {
    "text": "Right? Because this is a linear\noperation, so I can--",
    "start": "1621010",
    "end": "1626630"
  },
  {
    "text": "I guess I skipped a step. a times x plus x is ax plus\nadx and minus f of x is ax,",
    "start": "1626630",
    "end": "1633710"
  },
  {
    "text": "and then these two terms cancel. And so what we get\nis just adx, and this",
    "start": "1633710",
    "end": "1644460"
  },
  {
    "text": "has to equal f prime of x dx.",
    "start": "1644460",
    "end": "1651490"
  },
  {
    "text": "So you can see that if we just\ndid a little compare of these, f prime is just a.",
    "start": "1651490",
    "end": "1658039"
  },
  {
    "text": "It's just a linear operator a. So f prime, f prime of x is\njust a in this case, which",
    "start": "1658040",
    "end": "1667590"
  },
  {
    "text": "that's our Jacobian. ALAN EDELMAN: And just\nto say the obvious, it doesn't depend on x at all.",
    "start": "1667590",
    "end": "1674430"
  },
  {
    "text": "Everywhere in n-dimensional\nspace it's the same a. STEVEN JOHNSON: Yeah.",
    "start": "1674430",
    "end": "1679950"
  },
  {
    "text": "ALAN EDELMAN: No matter\nwhere you are in Rn. STEVEN JOHNSON: Yeah. Because in this case, it's\nlike, again, if you're in 18.01",
    "start": "1679950",
    "end": "1688530"
  },
  {
    "text": "and I have a linear function\n3x plus f of x equals 3x, the slope is just 3\nindependent of x in that case.",
    "start": "1688530",
    "end": "1696480"
  },
  {
    "text": "That's not true\nof all functions. Right? If the function is\nnonlinear, like 3x squared, the slope is 6x.",
    "start": "1696480",
    "end": "1703590"
  },
  {
    "text": "It depends on x. But if it's a linear function,\nthe slope doesn't depend on x. Same thing happens here,\nand in homework I'll",
    "start": "1703590",
    "end": "1710430"
  },
  {
    "text": "ask you to do an even slightly\nmore general version of that maybe. OK? But this is-- again,\nwriting this out,",
    "start": "1710430",
    "end": "1718440"
  },
  {
    "text": "I think it's still a lot easier\nthan component by component. Right? Doing this versus\ndoing that and taking",
    "start": "1718440",
    "end": "1724260"
  },
  {
    "text": "the derivative\npartial fi, partial xj and seeing that's aij, and then\nrealizing that, oh, that means",
    "start": "1724260",
    "end": "1730860"
  },
  {
    "text": "that the whole thing is just a. But it's still a\nlittle bit cumbersome, especially when it gets to\nmore complicated functions",
    "start": "1730860",
    "end": "1738000"
  },
  {
    "text": "like this, so it's nice\nto have some rules. ",
    "start": "1738000",
    "end": "1750170"
  },
  {
    "text": "Right? So just like when you learned\nthe derivatives in 18.01,",
    "start": "1750170",
    "end": "1759482"
  },
  {
    "text": "you don't use the\ndefinition of a derivative at some limiting\nprocedure for every time. You learn some product rules\nand power rules and sum rules",
    "start": "1759482",
    "end": "1767630"
  },
  {
    "text": "and those kinds of things, so we\ncan do the same kind of thing. Let's do an easy one.",
    "start": "1767630",
    "end": "1773580"
  },
  {
    "text": "Let's do a sum rule.  Suppose you have a function\nf of x is g of x plus h of x.",
    "start": "1773580",
    "end": "1790149"
  },
  {
    "text": "And let me draw out my vectors. You can understand\nthat everything here",
    "start": "1790150",
    "end": "1796090"
  },
  {
    "text": "can be a vector. Right? The x's can be a vector and\nthe f's and g's and h's can be vectors.",
    "start": "1796090",
    "end": "1803710"
  },
  {
    "text": "In fact, in arbitrary vector\nspaces we'll see very soon. Right? Then if I want df,\nthat's just going to be--",
    "start": "1803710",
    "end": "1815930"
  },
  {
    "text": "just write it as dg plus dh. Or equivalently, this is--",
    "start": "1815930",
    "end": "1824600"
  },
  {
    "text": "this is f prime of x dx equals\ng prime of x dx plus h prime",
    "start": "1824600",
    "end": "1834679"
  },
  {
    "text": "of x dx. So f prime equals g\nprime plus h prime.",
    "start": "1834680",
    "end": "1839820"
  },
  {
    "text": "Right? Just the obvious, some rule. I don't know. I don't know if you\nwant me to derive this.",
    "start": "1839820",
    "end": "1844880"
  },
  {
    "text": "I mean, again, it just\ncomes from the definition. If I take f of x plus dx minus\nf of x, addition is linear.",
    "start": "1844880",
    "end": "1852370"
  },
  {
    "text": "It's g of x plus dx minus\ngx plus h of x dx minus dx. ALAN EDELMAN: I don't think\nanybody in the room doubts it.",
    "start": "1852370",
    "end": "1859610"
  },
  {
    "text": "You don't actually\nhave to derive it. STEVEN JOHNSON: Yeah. So let me do the product rule.",
    "start": "1859610",
    "end": "1864910"
  },
  {
    "text": " All right? So this one starts\nto be a little bit.",
    "start": "1864910",
    "end": "1872389"
  },
  {
    "text": "I should do this on-- well,\nI'll write it out first. Suppose you have-- and\nI'm just going to write--",
    "start": "1872390",
    "end": "1878620"
  },
  {
    "text": "do I need to write the f? Sure, I'll write f of x\nequals g of x times h of x.",
    "start": "1878620",
    "end": "1887511"
  },
  {
    "text": "So these have to be things\nyou can multiply, obviously. Right? These could be two\nnumbers or they could be",
    "start": "1887511",
    "end": "1893780"
  },
  {
    "text": "two matrices of the right size. They can't be two\ncolumn vectors, at least not with the ordinary.",
    "start": "1893780",
    "end": "1900320"
  },
  {
    "text": "I'm just doing\nmultiplication here. Maybe I should do element-wise\nmultiplication in a minute,",
    "start": "1900320",
    "end": "1905370"
  },
  {
    "text": "but let me just\ndo multiplication. OK. So then df is going to be just\ndg times h plus g times dh.",
    "start": "1905370",
    "end": "1924485"
  },
  {
    "text": "ALAN EDELMAN: And I\nguess the point is, whenever gh makes sense, whether\nit's element-wise products",
    "start": "1924485",
    "end": "1930160"
  },
  {
    "text": "or matrix multiply,\nif it makes sense-- [INTERPOSING VOICES]",
    "start": "1930160",
    "end": "1936440"
  },
  {
    "text": "STEVEN JOHNSON: Yeah.  So if you think about what\nthis means in terms of f prime,",
    "start": "1936440",
    "end": "1942970"
  },
  {
    "text": "this f prime of x dx is going\nto equal g prime of x dx times h",
    "start": "1942970",
    "end": "1957080"
  },
  {
    "text": "plus g of x plus h of x plus\ng of x times h prime of x dx.",
    "start": "1957080",
    "end": "1966820"
  },
  {
    "text": "I cannot necessarily write f\nprime equals g prime h plus h",
    "start": "1966820",
    "end": "1973940"
  },
  {
    "text": "prime g because I can't commute.",
    "start": "1973940",
    "end": "1979750"
  },
  {
    "text": " I'm running out of space here.",
    "start": "1979750",
    "end": "1985145"
  },
  {
    "text": " Why can't I do that? Because I can't necessarily\nmove the x to the side here.",
    "start": "1985145",
    "end": "1997720"
  },
  {
    "text": "All right? So g prime dx h is not equal to\ng prime h times d in general.",
    "start": "1997720",
    "end": "2008690"
  },
  {
    "text": "If these are numbers,\nobviously this works. But now that these could be some\nother kind of object matrices",
    "start": "2008690",
    "end": "2015220"
  },
  {
    "text": "or something like that, this is\nnot going to work in general. OK, so let's-- and maybe\nthat's-- let's derive this,",
    "start": "2015220",
    "end": "2022480"
  },
  {
    "text": "just to-- we already kind of derived it,\nbut let's do it in general. This is derivation.",
    "start": "2022480",
    "end": "2028300"
  },
  {
    "text": " Right? So f is in gh.",
    "start": "2028300",
    "end": "2035120"
  },
  {
    "text": "So what is df? Just use our\ndefinition. df is going",
    "start": "2035120",
    "end": "2040220"
  },
  {
    "text": "to be f of x plus dx minus\nf of x, and f was g times h.",
    "start": "2040220",
    "end": "2048149"
  },
  {
    "text": "This is g of x plus dx\ntimes h of x plus dx",
    "start": "2048150",
    "end": "2054299"
  },
  {
    "text": "minus g of x h of x. ",
    "start": "2054300",
    "end": "2062219"
  },
  {
    "text": "And then this is g of x plus dx. We said by the definition\nof the derivative, that's",
    "start": "2062219",
    "end": "2068040"
  },
  {
    "text": "g of x plus g prime\nof x, whatever that linear operator is, times\ndx times h of x plus dx--",
    "start": "2068040",
    "end": "2077250"
  },
  {
    "text": "h of x plus dx. Same thing. By the definition\nof the derivative,",
    "start": "2077250",
    "end": "2083230"
  },
  {
    "text": "that's h of x plus h prime\nof x minus g of x h of x.",
    "start": "2083230",
    "end": "2094230"
  },
  {
    "text": "And if we just write\nout all those terms-- and again, these might\nbe matrices or something. I can't change the order.",
    "start": "2094230",
    "end": "2100120"
  },
  {
    "text": "But I'm assuming that if this\nis a multiplication operator, it could be\nelement-wise or it could",
    "start": "2100120",
    "end": "2105490"
  },
  {
    "text": "be just matrix multiplication. Anything that satisfies\nthe distributive law.",
    "start": "2105490",
    "end": "2110990"
  },
  {
    "text": "I can write this as gx h of x. That's this term\ntimes this term.",
    "start": "2110990",
    "end": "2117000"
  },
  {
    "text": "There's also this\nterm times this term, this term times this term,\nand this term times this term. This term times this term.",
    "start": "2117000",
    "end": "2123020"
  },
  {
    "text": "Sorry. So I get plus g\nprime x dx times--",
    "start": "2123020",
    "end": "2134050"
  },
  {
    "text": "which I could also\njust write as dg. This is the same thing as dg.",
    "start": "2134050",
    "end": "2139600"
  },
  {
    "text": "This is the same thing as gh. Maybe I should have done that. It's a little shorter to write.",
    "start": "2139600",
    "end": "2145600"
  },
  {
    "text": "This is dg times h\nplus I have a g times",
    "start": "2145600",
    "end": "2153700"
  },
  {
    "text": "dh plus I have dg times dh.",
    "start": "2153700",
    "end": "2162619"
  },
  {
    "text": "But that term we're\ngoing to ignore. This is higher order. ",
    "start": "2162620",
    "end": "2173130"
  },
  {
    "text": "All right? That's gone. If d is arbitrarily small,\nthat's infinitesimal. And then we still have the\nminus g of x, h of x term here.",
    "start": "2173130",
    "end": "2185950"
  },
  {
    "text": "And that's it. Right?  So we're done.",
    "start": "2185950",
    "end": "2192763"
  },
  {
    "text": "ALAN EDELMAN: And\nthis is really nothing but a copy of what you did in\nthe first month of calculus",
    "start": "2192763",
    "end": "2198420"
  },
  {
    "text": "when you first learned it except\nthat we are just extending it to vectors and matrices\nand making sure",
    "start": "2198420",
    "end": "2205950"
  },
  {
    "text": "that we don't mess the order up. STEVEN JOHNSON: Yeah. ALAN EDELMAN: Otherwise\nit's exactly what you did in the early days of calculus.",
    "start": "2205950",
    "end": "2212060"
  },
  {
    "text": "I'm sure you all remember. STEVEN JOHNSON: Yeah. And let me just do\na couple examples. Suppose the one we just\nhad. f of x equals ax.",
    "start": "2212060",
    "end": "2219599"
  },
  {
    "text": "Right? Then df is equal to da\ntimes x plus a times dx.",
    "start": "2219600",
    "end": "2229560"
  },
  {
    "text": "But this is zero. Since a is constant,\na is independent.",
    "start": "2229560",
    "end": "2234650"
  },
  {
    "text": "It is independent of x. So remember, you always\nhave to keep track",
    "start": "2234650",
    "end": "2239850"
  },
  {
    "text": "of what are the inputs, right? So here df-- f is a function\nwhose input, in this case,",
    "start": "2239850",
    "end": "2247810"
  },
  {
    "text": "is x. So df really means,\nf of x plus dx. ",
    "start": "2247810",
    "end": "2257230"
  },
  {
    "text": "f of x plus dx minus f of x. So since a doesn't change\nwith x, that's zero,",
    "start": "2257230",
    "end": "2262750"
  },
  {
    "text": "so then I'm done. Right? This is, again, the\nsame term I got before. ALAN EDELMAN: Let me ask the\nclass and not you, Steven.",
    "start": "2262750",
    "end": "2269650"
  },
  {
    "text": "What zero is this? ",
    "start": "2269650",
    "end": "2276180"
  },
  {
    "text": "Right? I think that might be\nuseful to think about. Can someone tell me\nexactly which zero--",
    "start": "2276180",
    "end": "2281780"
  },
  {
    "text": "STEVEN JOHNSON:\nShape of zero, yeah. ALAN EDELMAN: Shape of zero. AUDIENCE: [INAUDIBLE] ALAN EDELMAN: Sorry? AUDIENCE: M dimensional\ncolumn vector.",
    "start": "2281780",
    "end": "2288140"
  },
  {
    "text": "ALAN EDELMAN: Is it m\ndimensional column vector? No, I don't think so. AUDIENCE: It is m. ALAN EDELMAN: Yeah.",
    "start": "2288140",
    "end": "2293390"
  },
  {
    "text": "So what is da? AUDIENCE: A square matrix. An m cross n matrix of zero. ALAN EDELMAN: Yeah.",
    "start": "2293390",
    "end": "2298550"
  },
  {
    "text": "It's an m by n matrix of zeroes. So that infinite red\nzero that Steven drew",
    "start": "2298550",
    "end": "2303890"
  },
  {
    "text": "is really the m\nby n zero matrix. Right?",
    "start": "2303890",
    "end": "2309110"
  },
  {
    "text": "In fact, he could have\nwritten da equals 0dx. ",
    "start": "2309110",
    "end": "2316662"
  },
  {
    "text": "Might have pointed that out. But it's so easy to\nquickly look at that zero and lose sight of the fact that\nthat's a m by n zero matrix.",
    "start": "2316663",
    "end": "2324190"
  },
  {
    "text": "Which if you multiply by any dx\nthat's n little perturbations,",
    "start": "2324190",
    "end": "2330790"
  },
  {
    "text": "you get m0's coming back out. ",
    "start": "2330790",
    "end": "2337410"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. So let me do another one,\none that I did before. So did x transpose\nax, I believe.",
    "start": "2337410",
    "end": "2346079"
  },
  {
    "text": "Right? So now if I do df\nI get dx transpose.",
    "start": "2346080",
    "end": "2354549"
  },
  {
    "text": "This confuses people, by\nthe way, a little bit. ",
    "start": "2354550",
    "end": "2361780"
  },
  {
    "text": "Well, actually let\nme do-- why does dx",
    "start": "2361780",
    "end": "2367880"
  },
  {
    "text": "transpose equal dx transpose?",
    "start": "2367880",
    "end": "2373009"
  },
  {
    "text": "Because it's just dx-- dx transpose is really x plus\ndx transpose minus x transpose.",
    "start": "2373010",
    "end": "2387079"
  },
  {
    "text": "But that's equal to x transpose\nplus dx transpose minus x",
    "start": "2387080",
    "end": "2392090"
  },
  {
    "text": "transpose. So that's dx transpose. Right? ALAN EDELMAN: I wouldn't\nhave thought of it that way, but of course it's right.",
    "start": "2392090",
    "end": "2397852"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. ALAN EDELMAN: To me\nit's just you just take something as a column\nand you make it a row",
    "start": "2397852",
    "end": "2403609"
  },
  {
    "text": "and you perturb. Either way, it's the same thing. But formally you're\nquite right, Steven.",
    "start": "2403610",
    "end": "2409155"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. [INTERPOSING VOICES] And so in the homework I\nwant to get you to think of this in terms of linearity.",
    "start": "2409155",
    "end": "2415395"
  },
  {
    "text": "Right? The transpose is--\nwell, maybe I'm kind of giving away, though. But transpose is an example of\na linear operation on a vector.",
    "start": "2415395",
    "end": "2424849"
  },
  {
    "text": "And it's one that's kind\nof annoying to write down as a matrix because\nit's not really",
    "start": "2424850",
    "end": "2431450"
  },
  {
    "text": "multiplying x by a matrix\nunless you reinterpret the output as a vector and the\ninput as a vector in some way.",
    "start": "2431450",
    "end": "2439170"
  },
  {
    "text": "So anyway. So yeah, so this is--\nlet me just go back. The product rule-- I guess I only showed you the\nproduct rule for two terms,",
    "start": "2439170",
    "end": "2445940"
  },
  {
    "text": "but it's the same\nthing for three terms. So there's df. ALAN EDELMAN: You know, you\ncould talk about the product",
    "start": "2445940",
    "end": "2451710"
  },
  {
    "text": "rule for three\nterms, or you could think of this as two terms\nand use the result that's",
    "start": "2451710",
    "end": "2456780"
  },
  {
    "text": "on the top of your screen. STEVEN JOHNSON: Yeah. Exactly. I could just use-- ALAN EDELMAN: --now Right.",
    "start": "2456780",
    "end": "2461970"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. But let me just do it\ndo it for three terms. But yeah, I could use two terms\nand then you write it as--",
    "start": "2461970",
    "end": "2469535"
  },
  {
    "text": "let's do it with two terms. So there's the x\ntranspose times dax.",
    "start": "2469535",
    "end": "2474930"
  },
  {
    "text": "Right? And that's equal\nto dx transpose ax.",
    "start": "2474930",
    "end": "2480383"
  },
  {
    "text": "ALAN EDELMAN: So\nin effect, you're putting a parentheses around\nthe-- it's x transpose times left parenthesis ax right\nparenthesis [INAUDIBLE]..",
    "start": "2480383",
    "end": "2488089"
  },
  {
    "text": "Right? You see what I'm saying? STEVEN JOHNSON: Yes.",
    "start": "2488090",
    "end": "2493670"
  },
  {
    "text": "ALAN EDELMAN: The parenthesis\nitself is thought of as extra-- well, even-- yeah, yeah. That's what I'm thinking of.",
    "start": "2493670",
    "end": "2498950"
  },
  {
    "text": "STEVEN JOHNSON: You're\nthinking of that, yes. And of course, I\ncan put parentheses anywhere I want in\nthese kinds of things. ALAN EDELMAN: Of\ncourse you could, but that's what you're\nfocusing on this way, right?",
    "start": "2498950",
    "end": "2505550"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. And dax is product\nrule again, but I just did that, so it's adx.",
    "start": "2505550",
    "end": "2511620"
  },
  {
    "text": "Right? And then we used the\nsame trick before to--",
    "start": "2511620",
    "end": "2517560"
  },
  {
    "text": "this term here is a scalar,\nso I can just transpose it and get the dx on the right.",
    "start": "2517560",
    "end": "2523450"
  },
  {
    "text": "And so that's equal\nto x transpose a plus a transpose dx.",
    "start": "2523450",
    "end": "2530280"
  },
  {
    "text": "And then this was\nour f prime of x,",
    "start": "2530280",
    "end": "2537240"
  },
  {
    "text": "which is the same thing as\nthe gradient of f transposed. Right? Which therefore means\nthat the gradient of f",
    "start": "2537240",
    "end": "2544550"
  },
  {
    "text": "is equal to the\ntranspose of that, which is a plus a transpose x.",
    "start": "2544550",
    "end": "2552005"
  },
  {
    "text": "So that's the product rule. Pretty straightforward. Right? We could do more\ncomplicated things.",
    "start": "2552005",
    "end": "2557972"
  },
  {
    "text": "So we could do, for example--  actually, let me hold\noff on that for a second.",
    "start": "2557972",
    "end": "2564755"
  },
  {
    "text": "Let's do the chain rule. ",
    "start": "2564755",
    "end": "2573190"
  },
  {
    "text": "So suppose we have f of\nx equals g of h of x.",
    "start": "2573190",
    "end": "2585500"
  },
  {
    "text": "So gh of x is a function,\ntakes a vector in, gives you-- some x in, gives you some\nvector out, some vector space.",
    "start": "2585500",
    "end": "2593570"
  },
  {
    "text": "Maybe numbers. Maybe column vectors. Maybe matrices pretty soon. And g takes whatever\nthe output space of h",
    "start": "2593570",
    "end": "2599870"
  },
  {
    "text": "is and gives you some\nother vector as output.",
    "start": "2599870",
    "end": "2610780"
  },
  {
    "text": "All right? So for example, x could be a\ncolumn vector, and then h of x takes a column vector\nand produces a matrix.",
    "start": "2610780",
    "end": "2616589"
  },
  {
    "text": "And then g of x takes\na matrix and gives you a scalar, for example,\nlike a determinant. OK?",
    "start": "2616590",
    "end": "2621870"
  },
  {
    "text": "So they could be all\ndifferent shapes. Right? And one of the things we\ntalk about in linear algebra",
    "start": "2621870",
    "end": "2627270"
  },
  {
    "text": "is it's always good to keep\ntrack of the shapes of things. ",
    "start": "2627270",
    "end": "2632790"
  },
  {
    "text": "Everything's not\na number anymore and you need to keep\nyour shapes lined up.",
    "start": "2632790",
    "end": "2638620"
  },
  {
    "text": "OK? So then, what's the\nchain rule going to be? It's going to be--",
    "start": "2638620",
    "end": "2645240"
  },
  {
    "text": "I'll just write it down\nfirst and we'll just see why. f prime of x.",
    "start": "2645240",
    "end": "2650305"
  },
  {
    "text": " x is a linear operator\nacting on a dx.",
    "start": "2650305",
    "end": "2656685"
  },
  {
    "text": " Right? And that's our--\nand that's our df.",
    "start": "2656685",
    "end": "2664332"
  },
  {
    "text": "We should maybe write that down. ",
    "start": "2664332",
    "end": "2669650"
  },
  {
    "text": "df is that. OK. And what do you do?",
    "start": "2669650",
    "end": "2676380"
  },
  {
    "text": "It's going to be just like\nthe chain rule for numbers.",
    "start": "2676380",
    "end": "2681539"
  },
  {
    "text": "It's going to be\ng prime of h of x.",
    "start": "2681540",
    "end": "2687260"
  },
  {
    "text": "That's a linear\noperator, and that's going to act on h\nprime of x, and that's",
    "start": "2687260",
    "end": "2696510"
  },
  {
    "text": "a linear operator that's\ngoing to act on dx. I guess I haven't--",
    "start": "2696510",
    "end": "2702510"
  },
  {
    "text": "we're not putting\nvector signs in there. Very often, I'll\ndrop the f prime",
    "start": "2702510",
    "end": "2711730"
  },
  {
    "text": "of x equals g prime of\nh of x, h prime of x.",
    "start": "2711730",
    "end": "2719350"
  },
  {
    "text": "But when I write a\nproduct like this, this really means\nthe composition.",
    "start": "2719350",
    "end": "2726150"
  },
  {
    "text": "It means it's a product\nof two linear operators, of g prime and h prime.",
    "start": "2726150",
    "end": "2732540"
  },
  {
    "text": "It means you do h prime\nfirst and then g prime, and this is very much not\nequal to h prime times g prime.",
    "start": "2732540",
    "end": "2740260"
  },
  {
    "text": "Think of these, for\nexample, as matrices, right? You can't change the order. ",
    "start": "2740260",
    "end": "2745797"
  },
  {
    "text": "ALAN EDELMAN: Can I\nthrow in something that's a foreshadowing\nof something that might come later? Just to set a stage.",
    "start": "2745797",
    "end": "2752270"
  },
  {
    "text": "I want to ask the class,\nfrom ordinary calculus, just an application\nof the chain rule.",
    "start": "2752270",
    "end": "2757819"
  },
  {
    "text": "Let's say you were taking\njust the derivative-- you all can do this. Derivative of sine of x squared.",
    "start": "2757820",
    "end": "2764279"
  },
  {
    "text": "I want to ask, how many of\nyou will first do the cosine? So it'll be cosine of x\nsquared, and then in your mind",
    "start": "2764280",
    "end": "2771620"
  },
  {
    "text": "will do the 2x? And as opposed to,\nhow many of you will do the 2x on the inside\nfirst and then do the cosine?",
    "start": "2771620",
    "end": "2780200"
  },
  {
    "text": "So how many of you are\ncosine first people? I think that was everybody. Does anybody do the x\nsquared first going into out?",
    "start": "2780200",
    "end": "2789530"
  },
  {
    "text": "There are two people\nin the back who do it. But you see, I mean, of course,\nyou could do it either way.",
    "start": "2789530",
    "end": "2795270"
  },
  {
    "text": "And just to say some words\nnow that will come up later. But the first way is what\neventually becomes forward",
    "start": "2795270",
    "end": "2804290"
  },
  {
    "text": "mode automatic differentiation,\nif you've ever heard that term. And the second way is reverse\nmode automatic differentiation.",
    "start": "2804290",
    "end": "2810710"
  },
  {
    "text": "Of course, for scalars\nit's all pretty simple, but when we get into\nthis matrix calculus stuff it gets to be a whole\nbig thing of machine learning",
    "start": "2810710",
    "end": "2820070"
  },
  {
    "text": "and lots of other things-- technologies that underlie\nso much these days. Right?",
    "start": "2820070",
    "end": "2826040"
  },
  {
    "text": "But it really-- in its\nsimplest, simplest form, it all boils down to, as Steven\nwrites, you have the choice,",
    "start": "2826040",
    "end": "2832610"
  },
  {
    "text": "in effect, of doing the h prime\nfirst or the g prime h first.",
    "start": "2832610",
    "end": "2837950"
  },
  {
    "text": "Right? If you're a computer, you'll\nhave to do it sequentially. Right? So one of the things\nwill come first.",
    "start": "2837950",
    "end": "2843630"
  },
  {
    "text": "I guess it doesn't have\nto be sequentially. STEVEN JOHNSON: I'll show an\nexample of that in a second. So I think it becomes more clear\nonce you have three things.",
    "start": "2843630",
    "end": "2849362"
  },
  {
    "text": "ALAN EDELMAN: Yeah, OK. All right. I just wanted to\nset that thought up. STEVEN JOHNSON: Yeah. Absolutely. It's really going to\nmatter, left to right.",
    "start": "2849362",
    "end": "2856102"
  },
  {
    "text": "When these are not\nscalars anymore, the left to right\nversus right to left is going to start\nto matter a lot.",
    "start": "2856102",
    "end": "2861244"
  },
  {
    "text": "ALAN EDELMAN: And\nalso the order. STEVEN JOHNSON: Yeah. ALAN EDELMAN: Right? STEVEN JOHNSON: So, yeah. I don't know if people want\nme to derive this again.",
    "start": "2861245",
    "end": "2866650"
  },
  {
    "text": "We can just plug\nin the definitions and do f of x, take this plus\ndx minus g of h of x plus dx",
    "start": "2866650",
    "end": "2876750"
  },
  {
    "text": "minus g of x is g of h of x. Sorry. And then-- [INTERPOSING VOICES]",
    "start": "2876750",
    "end": "2882390"
  },
  {
    "text": "--everything and\njust drop the dx's. ALAN EDELMAN: Who\nwants the derivation and who wants to go\nstraight to the application? Derivation?",
    "start": "2882390",
    "end": "2888089"
  },
  {
    "text": "STEVEN JOHNSON: Derivation. ALAN EDELMAN: How many want\nto see the application? Like, five or six people.",
    "start": "2888090",
    "end": "2894220"
  },
  {
    "text": "STEVEN JOHNSON: OK. OK. So let me do an example\nof this just to-- suppose,",
    "start": "2894220",
    "end": "2904600"
  },
  {
    "text": "to start with, that-- so the x, or inputs, live in Rn.",
    "start": "2904600",
    "end": "2914089"
  },
  {
    "text": "So we have n component\nvectors as inputs. And then suppose that h of x--",
    "start": "2914090",
    "end": "2920600"
  },
  {
    "text": " h of x are our first function.",
    "start": "2920600",
    "end": "2930500"
  },
  {
    "text": "Our inner function\nlives in our p.",
    "start": "2930500",
    "end": "2936880"
  },
  {
    "text": "p sends vectors to vectors. Oops. What happened?",
    "start": "2936880",
    "end": "2942270"
  },
  {
    "text": "OK. And suppose our outer thing,\nour g of h, lives in our m.",
    "start": "2942270",
    "end": "2956750"
  },
  {
    "text": "So if we do f of x.",
    "start": "2956750",
    "end": "2962750"
  },
  {
    "text": " All right?",
    "start": "2962750",
    "end": "2968349"
  },
  {
    "text": "Which is not going to be-- because remember,\nit's g of h of x.",
    "start": "2968350",
    "end": "2973974"
  },
  {
    "start": "2973975",
    "end": "2979520"
  },
  {
    "text": "All right? What it does is it tend-- it sends things in Rn\nthrough to Rp via h.",
    "start": "2979520",
    "end": "2989480"
  },
  {
    "text": "And then sends them via g to Rn. OK?",
    "start": "2989480",
    "end": "2994640"
  },
  {
    "text": "So it sends vectors to vectors. Vectors may be all the\nsame size, maybe not. OK.",
    "start": "2994640",
    "end": "3000339"
  },
  {
    "text": "And then what is our chain rule? ",
    "start": "3000340",
    "end": "3008550"
  },
  {
    "text": "Right? Is that f prime-- let's e blue.",
    "start": "3008550",
    "end": "3013660"
  },
  {
    "text": "f prime of x. And so now this is-- we know\nthis is a Jacobian matrix.",
    "start": "3013660",
    "end": "3022200"
  },
  {
    "text": "This takes n inputs, m outputs. This is an m by n Jacobian.",
    "start": "3022200",
    "end": "3028950"
  },
  {
    "start": "3028950",
    "end": "3034720"
  },
  {
    "text": "This is equal to g\nprime times h prime. So this is going to\nbe g prime of h of x.",
    "start": "3034720",
    "end": "3047505"
  },
  {
    "start": "3047505",
    "end": "3052849"
  },
  {
    "text": "And g takes key\ninputs and m outputs. So this one is a--",
    "start": "3052850",
    "end": "3059576"
  },
  {
    "text": " is an m by p Jacobian of g.",
    "start": "3059576",
    "end": "3068508"
  },
  {
    "text": " I think I might need a\nlittle bit more space.",
    "start": "3068508",
    "end": "3074557"
  },
  {
    "text": "I love that I can do that. On the blackboard I\nalways write and write and get to the edge\nof the blackboard, and then my writing\ngets tinier and tinier.",
    "start": "3074557",
    "end": "3083620"
  },
  {
    "text": "And then also not equals. Times h prime. ALAN EDELMAN: I've seen\npeople move over to the walls",
    "start": "3083620",
    "end": "3089350"
  },
  {
    "text": "when the blackboard\nspace runs out. STEVEN JOHNSON: Of\nx, and h prime of",
    "start": "3089350",
    "end": "3095810"
  },
  {
    "text": "x takes an input- h has\nn inputs and p outputs.",
    "start": "3095810",
    "end": "3102850"
  },
  {
    "text": " Right?",
    "start": "3102850",
    "end": "3108180"
  },
  {
    "text": "So it's a p by n matrix. When you linearize\nit, it's a p by n. These h and g are not\nlinear functions in general,",
    "start": "3108180",
    "end": "3115480"
  },
  {
    "text": "but the derivatives\nare linearization. There are linear operators. They're just matrices\nin this case.",
    "start": "3115480",
    "end": "3122049"
  },
  {
    "text": "And you can see\nthat these match up.",
    "start": "3122050",
    "end": "3129480"
  },
  {
    "text": "Right? Not only is this not equal\nto h prime times g prime,",
    "start": "3129480",
    "end": "3141350"
  },
  {
    "text": "but that wouldn't\neven make sense. Right? ",
    "start": "3141350",
    "end": "3148720"
  },
  {
    "text": "Right? If you multiply a p\nby n times an m by p,",
    "start": "3148720",
    "end": "3158930"
  },
  {
    "text": "it doesn't even work. Right? So you really can't change\nthe order of these things.",
    "start": "3158930",
    "end": "3164310"
  },
  {
    "text": "So this is nonsense, I guess,\nif n is not equal to m. ",
    "start": "3164310",
    "end": "3171720"
  },
  {
    "text": "And even if n equals m, then\nthat product means something but it doesn't\nactually-- it's not",
    "start": "3171720",
    "end": "3178560"
  },
  {
    "text": "equal to the derivative\nof f anymore. That would be the\nderivative of g of h",
    "start": "3178560",
    "end": "3184799"
  },
  {
    "text": "of x if you swap the order. ",
    "start": "3184800",
    "end": "3190740"
  },
  {
    "text": "So for just functions that\nare vectors in, vectors out, the chain rule is just\nthe ordinary product,",
    "start": "3190740",
    "end": "3198390"
  },
  {
    "text": "the matrix product of\nJacobian matrices of each of the terms in the order.",
    "start": "3198390",
    "end": "3203579"
  },
  {
    "text": "So you always have to go\nkeep them in the same order, otherwise it's not\ngoing to make sense.",
    "start": "3203580",
    "end": "3209970"
  },
  {
    "text": "The outputs are here. Then the outputs of\nh are there and then the inputs are finally there.",
    "start": "3209970",
    "end": "3215160"
  },
  {
    "start": "3215160",
    "end": "3222880"
  },
  {
    "text": "And so not only does\nthe order matter, but the associativity\nmatters practically.",
    "start": "3222880",
    "end": "3234330"
  },
  {
    "text": " Right?",
    "start": "3234330",
    "end": "3239390"
  },
  {
    "text": "And associativity\nis going to matter where you put parentheses. So here I'm just\nmultiplying two things.",
    "start": "3239390",
    "end": "3244888"
  },
  {
    "text": "There's only one product. There's only one choice. But suppose we have-- suppose we have three functions.",
    "start": "3244888",
    "end": "3251210"
  },
  {
    "text": " Right?",
    "start": "3251210",
    "end": "3256300"
  },
  {
    "text": "So now suppose we\nhave f of x equals--",
    "start": "3256300",
    "end": "3264320"
  },
  {
    "text": "this is still Triton blue. F of x equals--",
    "start": "3264320",
    "end": "3274109"
  },
  {
    "text": "let's see. I'm running out of letters. gh. What letter should I use? ",
    "start": "3274110",
    "end": "3281530"
  },
  {
    "text": "a. Well, no. Let's use abc. Let's use abc.",
    "start": "3281530",
    "end": "3287440"
  },
  {
    "text": "A of b of c of x. ",
    "start": "3287440",
    "end": "3294820"
  },
  {
    "text": "And suppose that-- suppose\nthese all have different number",
    "start": "3294820",
    "end": "3300000"
  },
  {
    "text": "of components. Suppose this has--\nf has m components.",
    "start": "3300000",
    "end": "3307690"
  },
  {
    "text": "Suppose that x has n components,\nand these have-- let's see.",
    "start": "3307690",
    "end": "3316750"
  },
  {
    "text": "c has p components. ",
    "start": "3316750",
    "end": "3325430"
  },
  {
    "text": "p, and b has q components. And then a-- let\nme color code it.",
    "start": "3325430",
    "end": "3331740"
  },
  {
    "text": "So a is the output so that it\nhas to be the same as m-- as f.",
    "start": "3331740",
    "end": "3339660"
  },
  {
    "text": "So then what is f prime? ",
    "start": "3339660",
    "end": "3345830"
  },
  {
    "text": "That's a function of x. And it's just a product\nof the three Jacobians.",
    "start": "3345830",
    "end": "3351610"
  },
  {
    "text": "So it's a prime of x. Am I putting my x's in red?",
    "start": "3351610",
    "end": "3357010"
  },
  {
    "text": "Let me just not put x's. You know that the x's are there. It's a prime times b\nprime times c prime.",
    "start": "3357010",
    "end": "3366859"
  },
  {
    "text": "Right? And a is m by q.",
    "start": "3366860",
    "end": "3372280"
  },
  {
    "text": "My m's are in blue.  By q.",
    "start": "3372280",
    "end": "3377345"
  },
  {
    "text": "b prime is q by p\nbecause it takes p inputs and had q outputs. And c is p by n because it\nhas p inputs and q outputs.",
    "start": "3377345",
    "end": "3388450"
  },
  {
    "text": "And so this-- I can now-- so I can't\nchange the order.",
    "start": "3388450",
    "end": "3394860"
  },
  {
    "text": "This is matrix multiplication\nthat's not commutative, but it is associative.",
    "start": "3394860",
    "end": "3401700"
  },
  {
    "text": "I can always put parentheses. I can always multiply from left\nto right, or right to left.",
    "start": "3401700",
    "end": "3409880"
  },
  {
    "text": "So this is doing it left\nto right and right to left.",
    "start": "3409880",
    "end": "3423589"
  },
  {
    "text": "And these are going to have-- it seems like it's\nwho cares, right?",
    "start": "3423590",
    "end": "3429840"
  },
  {
    "text": "You do it in whatever\norder is convenient. It turns out, it's\nincredibly important.",
    "start": "3429840",
    "end": "3436335"
  },
  {
    "text": "This one, from left to right,\nis called reverse mode,",
    "start": "3436335",
    "end": "3446839"
  },
  {
    "text": "and this is called forward\nmode differentiation for an automatic\ndifferentiation.",
    "start": "3446840",
    "end": "3453470"
  },
  {
    "start": "3453470",
    "end": "3461020"
  },
  {
    "text": "ALAN EDELMAN: You see\nthe reason for the names? At first glance, it looks\nlike the names are backwards.",
    "start": "3461020",
    "end": "3468830"
  },
  {
    "text": "It looks like\nreverse modes going left to right, which is forward\nin English and many languages,",
    "start": "3468830",
    "end": "3474619"
  },
  {
    "text": "and forward is\ngoing the other way. But obviously\nforward mode refers to the first function\nis c, then b, then a,",
    "start": "3474620",
    "end": "3482840"
  },
  {
    "text": "and it's respecting\nthat same order. So it's forward. Right? Reverse mode is\ngoing a, b, c which",
    "start": "3482840",
    "end": "3489650"
  },
  {
    "text": "is the reverse order in which\nthe functions are applied.  STEVEN JOHNSON: Right.",
    "start": "3489650",
    "end": "3494950"
  },
  {
    "text": "So forward mode is\ngoing from-- inside out is like from inputs to outputs,\nfrom starting with the input c",
    "start": "3494950",
    "end": "3501500"
  },
  {
    "text": "and then going outwards. And reverse mode is going\nfrom outputs to inputs. So why does this matter? ",
    "start": "3501500",
    "end": "3508617"
  },
  {
    "text": "I claim that this matters. And the reason it matters is\nthat the multiply matrices,",
    "start": "3508617",
    "end": "3516430"
  },
  {
    "text": "how costly it is depends\non the shape a lot.",
    "start": "3516430",
    "end": "3521559"
  },
  {
    "text": "So let's think about the cost\nof matrix multiplication. ",
    "start": "3521560",
    "end": "3531710"
  },
  {
    "text": "So if I do a-- what am I doing here? ",
    "start": "3531710",
    "end": "3539049"
  },
  {
    "text": "m by q times q times p. So if I multiply an m by\nq times q by p matrices.",
    "start": "3539050",
    "end": "3550369"
  },
  {
    "start": "3550370",
    "end": "3557710"
  },
  {
    "text": "So the result of this is,\nof course, an m by p tricks.",
    "start": "3557710",
    "end": "3563339"
  },
  {
    "text": " So how do you do it? So for each entry\nof the output you've",
    "start": "3563340",
    "end": "3571180"
  },
  {
    "text": "probably learned\nrow times column. For each component of the\noutput, you do a dot product.",
    "start": "3571180",
    "end": "3579090"
  },
  {
    "text": "So this is np dot\nproducts of length q.",
    "start": "3579090",
    "end": "3592740"
  },
  {
    "text": "Is that clear? All right. So for each entry, if I\nimagine this as a matrix,",
    "start": "3592740",
    "end": "3600270"
  },
  {
    "text": "for each entry here I\ndo a row times a column. And the rows have q entries\nand the columns here",
    "start": "3600270",
    "end": "3607350"
  },
  {
    "text": "have q entries. So it's a dot part of\nlength q, and there are m times p outputs.",
    "start": "3607350",
    "end": "3613380"
  },
  {
    "text": "Right? And so the cost, how much\ndoes a dot product cost? Well, to take two dot\nproducts of length q--",
    "start": "3613380",
    "end": "3620265"
  },
  {
    "text": "a dot product of length q. ",
    "start": "3620265",
    "end": "3626411"
  },
  {
    "text": "Write it in blue. ",
    "start": "3626412",
    "end": "3632650"
  },
  {
    "text": "So a dot product of length\nq costs q multiplications,",
    "start": "3632650",
    "end": "3639917"
  },
  {
    "text": "because you have to\nmultiply q things together. ",
    "start": "3639917",
    "end": "3645240"
  },
  {
    "text": "And q minus 1\nadditions of scalars.",
    "start": "3645240",
    "end": "3654160"
  },
  {
    "text": "So basically it's proportional\nto q scalar operations, which",
    "start": "3654160",
    "end": "3661539"
  },
  {
    "text": "is what the CPU is doing. So the whole thing is\nproportional to mpq",
    "start": "3661540",
    "end": "3668530"
  },
  {
    "text": "scalar operations. ",
    "start": "3668530",
    "end": "3674050"
  },
  {
    "text": "Right? So that's a review. If I do, for example-- ",
    "start": "3674050",
    "end": "3681700"
  },
  {
    "text": "if I do m by m times\nm by m, two matrices,",
    "start": "3681700",
    "end": "3689099"
  },
  {
    "text": "this is proportional to m cubed.  In computer science you\nwould say this is theta mpq.",
    "start": "3689100",
    "end": "3698825"
  },
  {
    "text": "That notation for\nproportional to. That big O notation.",
    "start": "3698825",
    "end": "3705119"
  },
  {
    "text": "But I'll just say\nproportional to m cubed. If I do m times m times m by 1--",
    "start": "3705120",
    "end": "3714180"
  },
  {
    "text": "so if I do a matrix times\nvector times a column vector,",
    "start": "3714180",
    "end": "3722890"
  },
  {
    "text": "that's only proportional\nto m squared. I only do m dot products.",
    "start": "3722890",
    "end": "3729510"
  },
  {
    "text": "Or if I do 1 by m times m by m.",
    "start": "3729510",
    "end": "3734520"
  },
  {
    "text": "So if I do a row\nvector times that, that's also proportional\nto m squared.",
    "start": "3734520",
    "end": "3741410"
  },
  {
    "text": "So why does this matter? ",
    "start": "3741410",
    "end": "3746740"
  },
  {
    "text": "Does the order of the\nchain rule matter? ",
    "start": "3746740",
    "end": "3755860"
  },
  {
    "text": "So suppose you have lots of\ninputs and only one output.",
    "start": "3755860",
    "end": "3762270"
  },
  {
    "text": " So let's do-- ALAN EDELMAN: Machine\nlearning, you--",
    "start": "3762270",
    "end": "3767930"
  },
  {
    "text": "STEVEN JOHNSON: Yeah,\nlike in machine learning. So we have many inputs. Lots of inputs.",
    "start": "3767930",
    "end": "3773069"
  },
  {
    "text": "Actually, my inputs\nare red, right? So lots of inputs.",
    "start": "3773070",
    "end": "3778595"
  },
  {
    "text": " n is large. Right?",
    "start": "3778595",
    "end": "3784580"
  },
  {
    "text": "And only one output.",
    "start": "3784580",
    "end": "3790310"
  },
  {
    "text": "So m equals 1. So this would be the\ncase, for example,",
    "start": "3790310",
    "end": "3797450"
  },
  {
    "text": "in most of optimization. Right? So in large scale optimization.",
    "start": "3797450",
    "end": "3803420"
  },
  {
    "text": "Optimization.  Or, for example, such\nas machine learning.",
    "start": "3803420",
    "end": "3810839"
  },
  {
    "start": "3810840",
    "end": "3817530"
  },
  {
    "text": "So in that case, the output\nis called the loss function",
    "start": "3817530",
    "end": "3825477"
  },
  {
    "text": "or the objective function. ",
    "start": "3825477",
    "end": "3834110"
  },
  {
    "text": "And these are the parameters. ",
    "start": "3834110",
    "end": "3839160"
  },
  {
    "text": "Right? The optimization parameters. So machine learning,\nif the neural network--",
    "start": "3839160",
    "end": "3845030"
  },
  {
    "text": "you have a big neural network. It has a billion\nparameters in it, and you're trying to optimize\nthose parameters to make",
    "start": "3845030",
    "end": "3851530"
  },
  {
    "text": "one number better. Right? There's something called a\nloss, some measure of accuracy",
    "start": "3851530",
    "end": "3857230"
  },
  {
    "text": "of whatever the neural\nnetwork is trying to predict, for example. You're trying to make that\nmeasure of accuracy better.",
    "start": "3857230",
    "end": "3862720"
  },
  {
    "text": "So you have one output\nand a billion inputs. OK?",
    "start": "3862720",
    "end": "3868630"
  },
  {
    "text": "And let's also suppose-- let's suppose we have lots of\nintermediate values, which--",
    "start": "3868630",
    "end": "3880589"
  },
  {
    "text": "what was I calling those? q and p. ",
    "start": "3880590",
    "end": "3889420"
  },
  {
    "text": "All right. Suppose those maybe\nare comparable to n. So this also happens\nin a neural network.",
    "start": "3889420",
    "end": "3894540"
  },
  {
    "text": "You have a zillion\ninputs, and they go through a bunch of stages\nof the neural network that",
    "start": "3894540",
    "end": "3901230"
  },
  {
    "text": "have lots and lots of\nvalues at each stage, and then finally, at the\nvery end, all those outputs,",
    "start": "3901230",
    "end": "3907200"
  },
  {
    "text": "you have a zillion\noutputs, like maybe it's trying to predict\nan image, and then that goes through one function\nthat's saying, how accurate",
    "start": "3907200",
    "end": "3914040"
  },
  {
    "text": "is that image? How well does it\nmatch if you're trying to generate images of dogs\nor something like that,",
    "start": "3914040",
    "end": "3920220"
  },
  {
    "text": "or how good is it? Right? Or this happens in engineering\noptimization, right? Which is not really\ndata driven, but suppose",
    "start": "3920220",
    "end": "3927420"
  },
  {
    "text": "you're trying to design\nan airplane wing that is as strong as possible.",
    "start": "3927420",
    "end": "3933120"
  },
  {
    "text": "Then you have a\nzillion inputs which are describing the\ndistribution of all the material over the whole\nshape of the airplane wing.",
    "start": "3933120",
    "end": "3941940"
  },
  {
    "text": "But you only have one output\nat the end of the day, which is your one number which is\nsome measure of how strong it",
    "start": "3941940",
    "end": "3949600"
  },
  {
    "text": "is, how much weight can it\nhold, or something like that. Right? And you take those\nzillion inputs,",
    "start": "3949600",
    "end": "3955779"
  },
  {
    "text": "get a zillion numbers which\nare all the stresses everywhere on the airplane wing,\nand then pass it",
    "start": "3955780",
    "end": "3961270"
  },
  {
    "text": "through another function\nthat takes all those stresses and works out the\nstrength of the wing, and that's what you're\ntrying to maximize.",
    "start": "3961270",
    "end": "3966920"
  },
  {
    "text": "All right? So then think about what the\nshape of the chain rule is.",
    "start": "3966920",
    "end": "3974550"
  },
  {
    "text": "All right? So our f prime-- right? So this is one\noutput by n inputs,",
    "start": "3974550",
    "end": "3983049"
  },
  {
    "text": "so really, this is a gradient.  All right?",
    "start": "3983050",
    "end": "3988069"
  },
  {
    "text": "And this is what you're\ngoing to typically going to want in optimization\nmachine learning. We'll talk about\nthis more later,",
    "start": "3988070",
    "end": "3993140"
  },
  {
    "text": "that you want the--\nthe gradient gives you basically the direction,\nthe uphill direction--",
    "start": "3993140",
    "end": "3998509"
  },
  {
    "text": "or the downhill direction\nis minus gradient. It tells you in\nwhat direction do you perturb the parameters\nto make your system better,",
    "start": "3998510",
    "end": "4005530"
  },
  {
    "text": "like in what direction\ndo you change all the parameters\nin the neural network to make it more accurate,\nto make the loss less,",
    "start": "4005530",
    "end": "4010650"
  },
  {
    "text": "or what direction do you perturb\nall the parameters describing the shape of your airplane\nwing to make it stronger.",
    "start": "4010650",
    "end": "4017060"
  },
  {
    "text": "Right? So you really care about getting\nthis gradient, these n numbers. OK? But what is that in\nterms of the chain rule?",
    "start": "4017060",
    "end": "4024040"
  },
  {
    "text": "We said it's g prime times-- sorry. It's a prime times b\nprime times c prime.",
    "start": "4024040",
    "end": "4032110"
  },
  {
    "text": "Right? So it's a prime times\nb prime times c prime.",
    "start": "4032110",
    "end": "4041610"
  },
  {
    "text": "And we said a is m, m by\nq. m is one, so one by q.",
    "start": "4041610",
    "end": "4051815"
  },
  {
    "text": "Let's just suppose\nfor simplicity that these are just equal to n. ",
    "start": "4051815",
    "end": "4058570"
  },
  {
    "text": "So this is 1 by n. ",
    "start": "4058570",
    "end": "4063790"
  },
  {
    "text": "b is n by n. ",
    "start": "4063790",
    "end": "4069630"
  },
  {
    "text": "c is n by n. c prime is n by n.",
    "start": "4069630",
    "end": "4076320"
  },
  {
    "text": "Right? c takes n inputs,\nyour x's, gives you n intermediate outputs, p, and\nthen b takes those n things",
    "start": "4076320",
    "end": "4084140"
  },
  {
    "text": "and gives you another n. So its Jacobian\nis another n by n. Then you multiply by a.",
    "start": "4084140",
    "end": "4089712"
  },
  {
    "text": "And notice it\nreally matters where you put the parentheses,\nbecause if you",
    "start": "4089712",
    "end": "4095540"
  },
  {
    "text": "put the parentheses here,\nthink what you're doing,",
    "start": "4095540",
    "end": "4101410"
  },
  {
    "text": "versus if you put the\nparentheses in the other place. a prime.",
    "start": "4101410",
    "end": "4107314"
  },
  {
    "text": "b prime. c prime. If you do forward\nversus reverse mode.",
    "start": "4107314",
    "end": "4112819"
  },
  {
    "text": " Right? So if you put the parentheses\nhere, this is our reverse mode.",
    "start": "4112820",
    "end": "4120210"
  },
  {
    "start": "4120210",
    "end": "4127130"
  },
  {
    "text": "a, b. This product here is a\nrow vector times a matrix.",
    "start": "4127130",
    "end": "4134240"
  },
  {
    "text": "Vector times matrix is cheap. That's m proportional\nto n operations.",
    "start": "4134240",
    "end": "4140659"
  },
  {
    "text": "And then what's\nthe output of this? It's the whole thing, the\nproduct of vector times matrix-- row vector times\nmatrix is another row vector.",
    "start": "4140660",
    "end": "4148200"
  },
  {
    "text": "And so then you multiply this\nrow vector times a matrix. So you have the whole\nthing costs order n cost.",
    "start": "4148200",
    "end": "4159153"
  },
  {
    "text": "ALAN EDELMAN: Vector\ntimes matrix, Steven? STEVEN JOHNSON: Sorry. Order n squared. Sorry.",
    "start": "4159154",
    "end": "4164439"
  },
  {
    "text": "Yes. It's proportional to n squared. Right? Because it's vector\ntimes matrix.",
    "start": "4164439",
    "end": "4170910"
  },
  {
    "text": "Right? Whereas if you do forward mode,\nif you multiply right to left,",
    "start": "4170910",
    "end": "4183620"
  },
  {
    "text": "what's the cost? Well, you're doing\nb times c first. This is matrix times matrix.",
    "start": "4183620",
    "end": "4188659"
  },
  {
    "text": "That's much harder. Matrix times matrix\nis n cubed operations,",
    "start": "4188660",
    "end": "4194232"
  },
  {
    "text": "and then you multiply by a\nvector which is n squared. So the whole thing\nends up being n cubed.",
    "start": "4194232",
    "end": "4201090"
  },
  {
    "text": "So you really, really want\nto do it in this order. ",
    "start": "4201090",
    "end": "4207679"
  },
  {
    "text": "ALAN EDELMAN: This is\nprobably a good time to take a few minute break. We're a little late. STEVEN JOHNSON: Yep. And let me just say--",
    "start": "4207680",
    "end": "4214110"
  },
  {
    "text": "we're going to take\na break in a second. So this order is also called--",
    "start": "4214110",
    "end": "4219300"
  },
  {
    "text": "this is reverse mode.  It has a lot of names.",
    "start": "4219300",
    "end": "4224520"
  },
  {
    "text": "It's also called\nback propagation. ",
    "start": "4224520",
    "end": "4231010"
  },
  {
    "text": "And it's also called an\nadjoint differentiation.",
    "start": "4231010",
    "end": "4237001"
  },
  {
    "text": " And it's the key to\noptimizing functions",
    "start": "4237001",
    "end": "4243949"
  },
  {
    "text": "over zillions of parameters. It means that I can compute all\nthe derivatives with respect",
    "start": "4243950",
    "end": "4250940"
  },
  {
    "text": "to all the parameters in\nquite a reasonable cost. And basically it ends up\nbeing in cost proportional",
    "start": "4250940",
    "end": "4258020"
  },
  {
    "text": "to the cost of\njust evaluating f. Whereas if I did on\nthe opposite direction,",
    "start": "4258020",
    "end": "4263915"
  },
  {
    "text": "if I have a billion parameters,\nit becomes a billion times more expensive. ALAN EDELMAN: And I do like\nto stress that most students--",
    "start": "4263915",
    "end": "4270935"
  },
  {
    "text": "when I did the poll\nearlier in this classroom, it showed itself. Most students, even\nfor scalar calculus,",
    "start": "4270935",
    "end": "4277370"
  },
  {
    "text": "do the outputs\ntowards the inputs working their way from output. When I ask you about sine of--",
    "start": "4277370",
    "end": "4283292"
  },
  {
    "text": "STEVEN JOHNSON:\nForward mode, yeah. ALAN EDELMAN: Or sine of x\nsquared or whatever I asked, you are all doing--",
    "start": "4283292",
    "end": "4289268"
  },
  {
    "text": "without even thinking about\nit, it's all second nature. You're going from\noutputs to inputs. And so this reverse\nmode, which is often",
    "start": "4289268",
    "end": "4297290"
  },
  {
    "text": "more efficient for many\nreal applications today is also exactly what\nyou're doing instinctively",
    "start": "4297290",
    "end": "4303050"
  },
  {
    "text": "without even thinking about it. STEVEN JOHNSON: Yes. Well, it depends. When it's more\ncomplicated functions,",
    "start": "4303050",
    "end": "4308730"
  },
  {
    "text": "sometimes reverse mode is like-- usually when you're doing\nmore complicated things,",
    "start": "4308730",
    "end": "4313739"
  },
  {
    "text": "I would say the forward mode\nis often the more obvious. ALAN EDELMAN: That's right. I wasn't going to\nsay that today.",
    "start": "4313740",
    "end": "4319645"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. And we'll talk about it. And we'll talk more about how\nthese things are evaluated. How many of you have heard of\nback propagation, by the way?",
    "start": "4319645",
    "end": "4328550"
  },
  {
    "text": "ALAN EDELMAN: Everybody but one. STEVEN JOHNSON:\nEverybody but one. But how many people\nknew that it was just",
    "start": "4328550",
    "end": "4334690"
  },
  {
    "text": "multiplying Jacobians left to\nright instead of right to left? ",
    "start": "4334690",
    "end": "4340257"
  },
  {
    "text": "ALAN EDELMAN: Three,\nincluding one who never heard of the term back propagation. STEVEN JOHNSON: OK.",
    "start": "4340257",
    "end": "4345460"
  },
  {
    "text": "Yeah. And we'll show more\nexamples of this. It's one of those things that\nonce you see it explained,",
    "start": "4345460",
    "end": "4354910"
  },
  {
    "text": "it's obvious and trivial. It's just left to right versus\nright to left, after all.",
    "start": "4354910",
    "end": "4361870"
  },
  {
    "text": "But I think that until\nyou see it explained-- so for example, if\nyou're computing",
    "start": "4361870",
    "end": "4371500"
  },
  {
    "text": "the strength of an\nairplane wing as a function of 10 billion\nparameters describing the shape of the wing,\nit's a really huge",
    "start": "4371500",
    "end": "4377890"
  },
  {
    "text": "mechanical stimulation, like\na solid mechanics simulation, to calculate the strength of\nthat wing given its shape.",
    "start": "4377890",
    "end": "4384200"
  },
  {
    "text": "And it's really not\nobvious that you can get the derivative of\nthat strength with respect",
    "start": "4384200",
    "end": "4389260"
  },
  {
    "text": "to all billion\nparameters with basically one additional mechanics solve.",
    "start": "4389260",
    "end": "4394900"
  },
  {
    "text": "And it turns out that\nthat's another instance of this same thing. But once you see it\nexplained-- and we'll",
    "start": "4394900",
    "end": "4400340"
  },
  {
    "text": "see that kind of example\nmore explicitly later on. I think it becomes much\nmore straightforward.",
    "start": "4400340",
    "end": "4408710"
  },
  {
    "text": "Really, it's\nsurprisingly non-obvious when it gets to complicated\nfunctions that you can do this. ",
    "start": "4408710",
    "end": "4416525"
  },
  {
    "text": "ALAN EDELMAN: But I think\nmaybe this is just a great time to just take a\nfive minute break. STEVEN JOHNSON: Yeah. ALAN EDELMAN: So I've got\n12:23 on the clock behind--",
    "start": "4416525",
    "end": "4424450"
  },
  {
    "text": "in the back of this room, so\nhow about we reconvene at 12:28?",
    "start": "4424450",
    "end": "4429750"
  },
  {
    "start": "4429750",
    "end": "4437000"
  }
]
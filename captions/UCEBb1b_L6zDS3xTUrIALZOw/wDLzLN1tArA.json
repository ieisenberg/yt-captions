[
  {
    "start": "0",
    "end": "15220"
  },
  {
    "text": "PROFESSOR: OK, so the\nlast topic for the class is interpretability.",
    "start": "15220",
    "end": "20710"
  },
  {
    "text": "As you know, the modern\nmachine learning models are justifiably reputed to be\nvery difficult to understand.",
    "start": "20710",
    "end": "30890"
  },
  {
    "text": "So if I give you something\nlike the GPT2 model, which we talked about in natural\nlanguage processing,",
    "start": "30890",
    "end": "38170"
  },
  {
    "text": "and I tell you that it\nhas 1.5 billion parameters",
    "start": "38170",
    "end": "43210"
  },
  {
    "text": "and then you say,\nwhy is it working?",
    "start": "43210",
    "end": "49290"
  },
  {
    "text": "Clearly the answer\nis not because these particular parameters\nhave these particular values.",
    "start": "49290",
    "end": "56579"
  },
  {
    "text": "There is no way to\nunderstand that. And so the topic\ntoday is something",
    "start": "56580",
    "end": "62040"
  },
  {
    "text": "that we raised a little\nbit in the lecture on fairness, where\none of the issues",
    "start": "62040",
    "end": "67260"
  },
  {
    "text": "there was also that if you\ncan't understand the model you can't tell if the model\nhas baked-in prejudices",
    "start": "67260",
    "end": "74759"
  },
  {
    "text": "by examining it. And so today we're going to\nlook at different methods that people have\ndeveloped to try",
    "start": "74760",
    "end": "81720"
  },
  {
    "text": "to overcome this problem\nof inscrutable models. ",
    "start": "81720",
    "end": "87870"
  },
  {
    "text": "So there is a very\ninteresting bit of history.",
    "start": "87870",
    "end": "93430"
  },
  {
    "text": "How many of you know\nof George Miller's 7 plus or minus 2 result?",
    "start": "93430",
    "end": "99180"
  },
  {
    "text": "Only a few. So Miller was a psychologist at\nHarvard, I think, in the 1950s.",
    "start": "99180",
    "end": "108240"
  },
  {
    "text": "And he wrote this paper in 1956\ncalled \"The Magical Number 7 Plus or Minus 2--",
    "start": "108240",
    "end": "114860"
  },
  {
    "text": "Some Limits On Our Capacity\nfor Processing Information.\" It's quite an interesting paper.",
    "start": "114860",
    "end": "121220"
  },
  {
    "text": "So he started off with\nsomething that I had forgotten.",
    "start": "121220",
    "end": "127930"
  },
  {
    "text": "I read this paper\nmany, many years ago. And I'd forgotten that he\nstarts off with the question",
    "start": "127930",
    "end": "134740"
  },
  {
    "text": "of how many different\nthings can you sense? How many different levels\nof things can you sense?",
    "start": "134740",
    "end": "142010"
  },
  {
    "text": "So if I put headphones\non you and I ask you to tell\nme on a scale of 1",
    "start": "142010",
    "end": "148390"
  },
  {
    "text": "to n how loud is the sound that\nI'm playing in your headphone, it turns out people get confused\nwhen you get beyond about five,",
    "start": "148390",
    "end": "157610"
  },
  {
    "text": "six, seven different\nlevels of intensity. And similarly, if I give\nyou a bunch of colors",
    "start": "157610",
    "end": "164530"
  },
  {
    "text": "and I ask you to tell me\nwhere the boundaries are",
    "start": "164530",
    "end": "169840"
  },
  {
    "text": "between different\ncolors, people seem to come up with 7 plus or\nminus 2 as the number of colors",
    "start": "169840",
    "end": "177100"
  },
  {
    "text": "that they can distinguish. And so there is a long\npsychological literature of this.",
    "start": "177100",
    "end": "183460"
  },
  {
    "text": "And then Miller went\non to do experiments",
    "start": "183460",
    "end": "188780"
  },
  {
    "text": "where he asked people to\nmemorize lists of things. And what he\ndiscovered is, again,",
    "start": "188780",
    "end": "194360"
  },
  {
    "text": "that you could memorize\na list of about 7 plus or minus 2 things.",
    "start": "194360",
    "end": "199760"
  },
  {
    "text": "And beyond that, you couldn't\nremember the list anymore. So this tells us something\nabout the cognitive capacity",
    "start": "199760",
    "end": "206660"
  },
  {
    "text": "of the human mind. And it suggests that if I\ngive you an explanation that",
    "start": "206660",
    "end": "211790"
  },
  {
    "text": "has 20 things in it,\nyou're unlikely to be able to fathom it because\nyou can't keep all the moving",
    "start": "211790",
    "end": "218780"
  },
  {
    "text": "parts in your mind at one time. Now, it's a tricky result,\nbecause he does point out",
    "start": "218780",
    "end": "225349"
  },
  {
    "text": "even in 1956 that if you chunk\nthings into bigger chunks,",
    "start": "225350",
    "end": "232280"
  },
  {
    "text": "you can remember seven of those,\neven if they're much bigger.",
    "start": "232280",
    "end": "237540"
  },
  {
    "text": "And so people who are very\ngood at memorizing things, for example, make up patterns.",
    "start": "237540",
    "end": "243959"
  },
  {
    "text": "And they remember\nthose patterns, which then allow them\nto actually remember more primitive objects.",
    "start": "243960",
    "end": "250069"
  },
  {
    "text": "So you know-- and we\nstill don't really understand how memory works. But this is just an\ninteresting observation,",
    "start": "250070",
    "end": "258028"
  },
  {
    "text": "and I think plays\ninto the question of how do you explain things\nin a complicated model?",
    "start": "258029",
    "end": "267280"
  },
  {
    "text": "Because it suggests\nthat you can't explain too many different\nthings because people",
    "start": "267280",
    "end": "272470"
  },
  {
    "text": "won't understand what\nyou're talking about. OK. So what leads to complex models?",
    "start": "272470",
    "end": "281270"
  },
  {
    "text": "Well, as I say,\noverfitting certainly leads to complex models.",
    "start": "281270",
    "end": "286550"
  },
  {
    "text": "I remember in the\n1970s when we started working on expert\nsystems in healthcare,",
    "start": "286550",
    "end": "295820"
  },
  {
    "text": "I made a very bad faux pas. I went to the first\njoint conference",
    "start": "295820",
    "end": "303169"
  },
  {
    "text": "between statisticians and\nartificial intelligence researchers. And the statisticians were\nall about understanding",
    "start": "303170",
    "end": "312530"
  },
  {
    "text": "the variance and understanding\nstatistical significance and so on.",
    "start": "312530",
    "end": "317660"
  },
  {
    "text": "And I was all about trying to\nmodel details of what was going",
    "start": "317660",
    "end": "322700"
  },
  {
    "text": "on in an individual patient. And in some discussion after my\ntalk, somebody challenged me.",
    "start": "322700",
    "end": "329210"
  },
  {
    "text": "And I said, well, what\nwe AI people are really doing is fitting\nwhat you guys think",
    "start": "329210",
    "end": "334819"
  },
  {
    "text": "is the noise,\nbecause we're trying to make a lot more detailed\nrefinements in our theories",
    "start": "334820",
    "end": "342920"
  },
  {
    "text": "and our models than what the\ntypical statistical model does. And of course, I was roundly\nbooed out of the hall.",
    "start": "342920",
    "end": "353150"
  },
  {
    "text": "And people shunned me for\nthe rest of the conference because I had done\nsomething really stupid",
    "start": "353150",
    "end": "359420"
  },
  {
    "text": "to admit that I\nwas fitting noise. And of course, I\ndidn't really believe",
    "start": "359420",
    "end": "365090"
  },
  {
    "text": "that I was fitting noise. I believed that\nwhat I was fitting was what the average\nstatistician just",
    "start": "365090",
    "end": "371900"
  },
  {
    "text": "chalks up to noise. And we're interested in more\ndetails of the mechanisms.",
    "start": "371900",
    "end": "378430"
  },
  {
    "text": "So overfitting we\nhave a pretty good handle on by regularization.",
    "start": "378430",
    "end": "383620"
  },
  {
    "text": "So you can-- you\nknow, you've seen lots of examples\nof regularization throughout the course.",
    "start": "383620",
    "end": "389530"
  },
  {
    "text": "And people keep coming up\nwith interesting ideas for how to apply regularization in order\nto simplify models or make them",
    "start": "389530",
    "end": "397960"
  },
  {
    "text": "fit some preconception\nof what the model ought to look like before you\nstart learning it from data.",
    "start": "397960",
    "end": "405710"
  },
  {
    "text": "But the problem is\nthat there really is true complexity\nto these models,",
    "start": "405710",
    "end": "411370"
  },
  {
    "text": "whether or not\nyou're fitting noise. There's-- the world is\na complicated place.",
    "start": "411370",
    "end": "418330"
  },
  {
    "text": "Human beings were not designed. They evolved. And so there's all kinds\nof bizarre stuff left over",
    "start": "418330",
    "end": "425980"
  },
  {
    "text": "from our evolutionary heritage. And so it is just complex.",
    "start": "425980",
    "end": "431930"
  },
  {
    "text": "It's hard to understand\nin a simple way how to make predictions that\nare useful when the world really",
    "start": "431930",
    "end": "438470"
  },
  {
    "text": "is complex. So what do we do in order\nto try to deal with this?",
    "start": "438470",
    "end": "444630"
  },
  {
    "text": "Well, one approach\nis to make up what I call just-so stories that give\na simplified explanation of how",
    "start": "444630",
    "end": "452190"
  },
  {
    "text": "a complicated thing\nactually works. So how many of you\nhave read these stories",
    "start": "452190",
    "end": "457530"
  },
  {
    "text": "when you were a kid? Nobody? My God. OK.",
    "start": "457530",
    "end": "464020"
  },
  {
    "text": "Must be a generational thing. So Rudyard Kipling\nwas a famous author.",
    "start": "464020",
    "end": "469689"
  },
  {
    "text": "And he wrote the series\nof just-so stories, things like How the Lion Got His\nMane and How the Camel Got",
    "start": "469690",
    "end": "477190"
  },
  {
    "text": "His Hump and so on. And of course, they're\nall total bull, right? I mean, it's not a Darwinian\nevolutionary explanation",
    "start": "477190",
    "end": "488500"
  },
  {
    "text": "of why male lions have manes. It's just some made up story.",
    "start": "488500",
    "end": "493940"
  },
  {
    "text": "But they're really cute stories. And I enjoyed them as a kid. And maybe you would have,\ntoo, if your parents",
    "start": "493940",
    "end": "503169"
  },
  {
    "text": "had read them to you. So I mean, I use this\nas a kind of pejorative",
    "start": "503170",
    "end": "511990"
  },
  {
    "text": "because what the\npeople who follow this line of investigation\ndo is they take",
    "start": "511990",
    "end": "518740"
  },
  {
    "text": "some very complicated model. They make a local\napproximation to it that says,",
    "start": "518740",
    "end": "524770"
  },
  {
    "text": "this is not an approximation\nto the entire model, but it's an approximation\nto the model in the vicinity",
    "start": "524770",
    "end": "531670"
  },
  {
    "text": "of a particular case. And then they explain\nthat simplified model. And I'll show you\nsome examples of that",
    "start": "531670",
    "end": "538990"
  },
  {
    "text": "through the lecture today. And the other approach\nwhich I'll also show you some examples\nof is that you simply",
    "start": "538990",
    "end": "547149"
  },
  {
    "text": "trade off somewhat lower\nperformance for a simple-- a model that's simple enough\nto be able to explain.",
    "start": "547150",
    "end": "554769"
  },
  {
    "text": "So things like decision\ntrees and logistic regression and so on typically\ndon't perform quite",
    "start": "554770",
    "end": "562660"
  },
  {
    "text": "as well as the best, most\nsophisticated models,",
    "start": "562660",
    "end": "568240"
  },
  {
    "text": "although you've seen plenty\nof examples in this class where, in fact, they\ndo perform quite well",
    "start": "568240",
    "end": "574780"
  },
  {
    "text": "and where they're\nnot outperformed by the fancy models. But in general, you\ncan do a little better",
    "start": "574780",
    "end": "580600"
  },
  {
    "text": "by tweaking a fancy model. But then it becomes\nincomprehensible. And so people are\nwilling to say,",
    "start": "580600",
    "end": "586880"
  },
  {
    "text": "OK, I'm going to give up\n1% or 2% in performance in order to have a model\nthat I can really understand.",
    "start": "586880",
    "end": "595570"
  },
  {
    "text": "And the reason it makes sense\nis because these models are not self-executing. They're typically used as\nadvice for some human being",
    "start": "595570",
    "end": "604690"
  },
  {
    "text": "who makes ultimate decisions. Your surgeon is\nnot going to look at one of these\nmodels that says,",
    "start": "604690",
    "end": "610930"
  },
  {
    "text": "take out the guy's left\nkidney and say, OK, I guess.",
    "start": "610930",
    "end": "616430"
  },
  {
    "text": "They're going to go, well,\ndoes that make sense? And in order to answer\nthe question of,",
    "start": "616430",
    "end": "621730"
  },
  {
    "text": "does that make sense? It really helps to know\nwhat the model is-- what the model's\nrecommendation is based on.",
    "start": "621730",
    "end": "629470"
  },
  {
    "text": "What is its internal logic? And so even an approximation\nto that is useful.",
    "start": "629470",
    "end": "635750"
  },
  {
    "text": "So the need for trust, clinical\nadoption of ML models--",
    "start": "635750",
    "end": "643510"
  },
  {
    "text": "there are two\napproaches in this paper that I'm going to talk\nabout where they say, OK,",
    "start": "643510",
    "end": "649540"
  },
  {
    "text": "what you'd like to do is to look\nat case-specific predictions.",
    "start": "649540",
    "end": "654639"
  },
  {
    "text": "So there is a particular\npatient in a particular state and you want to understand\nwhat the model is",
    "start": "654640",
    "end": "660430"
  },
  {
    "text": "saying about that patient. And then you also want to\nhave confidence in the model overall.",
    "start": "660430",
    "end": "666529"
  },
  {
    "text": "And so you'd like to be able to\nhave an explanatory capability that says, here are some\ninteresting representative",
    "start": "666530",
    "end": "674410"
  },
  {
    "text": "cases. And here's how the\nmodel views them. Look through them and\ndecide whether you",
    "start": "674410",
    "end": "679690"
  },
  {
    "text": "agree with the approach\nthat this model is taking. Now, remember my critique of\nrandomized controlled trials",
    "start": "679690",
    "end": "688269"
  },
  {
    "text": "that people do these trials. They choose the simplest cases,\nthe smallest number of patients",
    "start": "688270",
    "end": "696580"
  },
  {
    "text": "that they need in order to\nreach statistical significance, the shortest amount of\nfollow-up time, et cetera.",
    "start": "696580",
    "end": "704450"
  },
  {
    "text": "And then the results\nof those trials are applied to very\ndifferent populations. So Davids talked\nabout the cohort shift",
    "start": "704450",
    "end": "712450"
  },
  {
    "text": "as a generalization\nof that idea. But the same thing happens in\nthese machine learning models",
    "start": "712450",
    "end": "718270"
  },
  {
    "text": "that you train on\nsome set of data. The typical\npublication will then",
    "start": "718270",
    "end": "723820"
  },
  {
    "text": "test on some held-out\nsubset of the same data. But that's not a very\naccurate representation",
    "start": "723820",
    "end": "731410"
  },
  {
    "text": "of the real world. If you then try to apply that\nmodel to data from a totally",
    "start": "731410",
    "end": "737080"
  },
  {
    "text": "different source,\nthe chances are you will have specialized\nit in some way that you don't appreciate.",
    "start": "737080",
    "end": "743680"
  },
  {
    "text": "And the results\nthat you get are not as good as what you got\non the held-out test data",
    "start": "743680",
    "end": "749440"
  },
  {
    "text": "because it's more heterogeneous. I think I mentioned\nthat Jeff Drazen,",
    "start": "749440",
    "end": "755310"
  },
  {
    "text": "the editor-in-chief of\nthe New England Journal, had a meeting about a year ago\nin which he was arguing that",
    "start": "755310",
    "end": "764230"
  },
  {
    "text": "the journal shouldn't ever\npublish a research study unless it's been validated on\ntwo independent data sets",
    "start": "764230",
    "end": "772420"
  },
  {
    "text": "because he's tired of publishing\nstudies that wind up getting",
    "start": "772420",
    "end": "777980"
  },
  {
    "text": "retracted because-- not because of any overt\nbadness on the part",
    "start": "777980",
    "end": "784520"
  },
  {
    "text": "of the investigators. They've done exactly\nthe kinds of things that you've learned how\nto do in this class.",
    "start": "784520",
    "end": "791220"
  },
  {
    "text": "But when they go\nto apply that model to a different\npopulation, it just doesn't work nearly\nas well as it",
    "start": "791220",
    "end": "798379"
  },
  {
    "text": "did in the published version. And of course, there\nare all the publication bias issues about if 50 of\nus do the same experiment",
    "start": "798380",
    "end": "809850"
  },
  {
    "text": "and by random chance some\nof us are going to get better results than others. And those are the\nones that are going",
    "start": "809850",
    "end": "816050"
  },
  {
    "text": "to get published\nbecause the people who got poor results don't have\nanything interesting to report.",
    "start": "816050",
    "end": "822270"
  },
  {
    "text": "And so there's that whole\nissue of publication bias, which is another serious one.",
    "start": "822270",
    "end": "828110"
  },
  {
    "text": "OK. ",
    "start": "828110",
    "end": "833200"
  },
  {
    "text": "So I wanted to just spend\na minute to say, you know, explanation is not a new idea.",
    "start": "833200",
    "end": "840290"
  },
  {
    "text": "So in the expert\nsystems era that we talked about a little bit in\none of our earlier classes,",
    "start": "840290",
    "end": "847510"
  },
  {
    "text": "we talked about the idea\nthat we would take medical-- human medical experts\nand debrief them of what",
    "start": "847510",
    "end": "855580"
  },
  {
    "text": "they knew and then try to encode\nthose in patterns or in rules",
    "start": "855580",
    "end": "861220"
  },
  {
    "text": "or in various ways in a\ncomputer program in order to reproduce their behavior.",
    "start": "861220",
    "end": "867040"
  },
  {
    "text": "So Mycin was one\nof those programs-- [INAUDIBLE] PhD\nthesis-- in 1975.",
    "start": "867040",
    "end": "874060"
  },
  {
    "text": "And they published\nthis nice paper that was about explanation and\nrule acquisition capabilities",
    "start": "874060",
    "end": "881170"
  },
  {
    "text": "of the Mycin system. And as an illustration,\nthey gave some examples",
    "start": "881170",
    "end": "886180"
  },
  {
    "text": "of what you could\ndo with the system. So rules, they argued,\nwere quite understandable",
    "start": "886180",
    "end": "893410"
  },
  {
    "text": "because they say if a bunch\nof conditions, then you can draw the\nfollowing conclusion.",
    "start": "893410",
    "end": "900130"
  },
  {
    "text": "So given that,\nyou can say, well, when the program\ncomes back and says,",
    "start": "900130",
    "end": "907330"
  },
  {
    "text": "in light of the site from\nwhich the culture was obtained and the method of\ncollection, do you feel that a significant number\nof organism 1 were detected--",
    "start": "907330",
    "end": "916810"
  },
  {
    "text": "were obtained? In other words, if you took\na sample from somebody's body",
    "start": "916810",
    "end": "923170"
  },
  {
    "text": "and you're looking\nfor an infection, do you think you got enough\norganisms in that sample?",
    "start": "923170",
    "end": "928510"
  },
  {
    "text": "And the user says, well, why\nare you asking me this question? And the answer in terms of the\nrules that the system works by",
    "start": "928510",
    "end": "937149"
  },
  {
    "text": "is pretty good. It says it's\nimportant to find out whether there's therapeutically\nsignificant disease associated",
    "start": "937150",
    "end": "943750"
  },
  {
    "text": "with this occurrence\nof organism 1. We've already established\nthat the culture is not",
    "start": "943750",
    "end": "949480"
  },
  {
    "text": "one of those that\nare normally sterile and the method of\ncollection is sterile.",
    "start": "949480",
    "end": "955420"
  },
  {
    "text": "Therefore, if the\norganism has been observed in significant\nnumbers, then there's",
    "start": "955420",
    "end": "960670"
  },
  {
    "text": "strongly suggestive evidence\nthat there's therapeutically significant disease associated\nwith this occurrence",
    "start": "960670",
    "end": "967180"
  },
  {
    "text": "of the organism. So if you find bugs in a\nplace carefully collected,",
    "start": "967180",
    "end": "975579"
  },
  {
    "text": "then that suggests\nthat you ought to probably treat this patient\nif there are were bunch of--",
    "start": "975580",
    "end": "981430"
  },
  {
    "text": "enough bugs there. And there's also strongly\nsuggestive evidence",
    "start": "981430",
    "end": "988120"
  },
  {
    "text": "that the organism is\nnot a contaminant, because the collection\nmethod was sterile.",
    "start": "988120",
    "end": "993850"
  },
  {
    "text": "And you can go on with this and\nyou can say, well, why that?",
    "start": "993850",
    "end": "999089"
  },
  {
    "text": "So why that question? And it traces back in its\nevolution of these rules",
    "start": "999090",
    "end": "1007740"
  },
  {
    "text": "and it says, well,\nin order to find out the locus of\ninfection, it's already been established that the\nsite of the culture is known.",
    "start": "1007740",
    "end": "1015839"
  },
  {
    "text": "The number of days since\nthe specimen was obtained is less than 7. Therefore, there\nis therapeutically",
    "start": "1015840",
    "end": "1021780"
  },
  {
    "text": "significant disease associated\nwith this occurrence of the organism. So there's some rule that\nsays if you've got bugs",
    "start": "1021780",
    "end": "1030359"
  },
  {
    "text": "and it happened within\nthe last seven days, the patient probably really\ndoes have an infection.",
    "start": "1030359",
    "end": "1037589"
  },
  {
    "text": "And I mean, I've got a\nlot of examples of this. But you can keep going why.",
    "start": "1037589",
    "end": "1043459"
  },
  {
    "text": "You know, this is\nthe two-year-old. But why, daddy? But why? But why?",
    "start": "1043460",
    "end": "1049919"
  },
  {
    "text": "Well, why is it important to\nfind out a locus of infection?",
    "start": "1049920",
    "end": "1055900"
  },
  {
    "text": "And, well, there's\na reason, which is that there is a rule\nthat will conclude,",
    "start": "1055900",
    "end": "1061780"
  },
  {
    "text": "for example, that the abdomen\nis a locus of infection or the pelvis is a locus\nof infection of the patient",
    "start": "1061780",
    "end": "1069340"
  },
  {
    "text": "if you satisfy these criteria. And so this is a kind of\nrudimentary explanation",
    "start": "1069340",
    "end": "1076900"
  },
  {
    "text": "that comes directly\nout of the fact that these are\nrule-based systems",
    "start": "1076900",
    "end": "1082660"
  },
  {
    "text": "and so you can just\nplay back the rules. One of the things I\nlike is you can also",
    "start": "1082660",
    "end": "1088510"
  },
  {
    "text": "ask freeform questions. 1975, the natural language\nprocessing was not so good.",
    "start": "1088510",
    "end": "1094930"
  },
  {
    "text": "And so this worked\nabout one time in five. But you could walk up to\nit and type some question.",
    "start": "1094930",
    "end": "1101409"
  },
  {
    "text": "And for example, do you\never prescribe carbenicillin for pseudomonas infections?",
    "start": "1101410",
    "end": "1107390"
  },
  {
    "text": "And it says, well,\nthere are three rules in my database of rules that\nwould conclude something",
    "start": "1107390",
    "end": "1113530"
  },
  {
    "text": "relevant to that question. So which one do you want to see? And if you say, I\nwant to see rule 64,",
    "start": "1113530",
    "end": "1120910"
  },
  {
    "text": "it says, well, that\nrule says if it's known with certainty that\nthe organism is a pseudomonas",
    "start": "1120910",
    "end": "1127720"
  },
  {
    "text": "and the drug under\nconsideration is gentamicin, then a more appropriate\ntherapy would",
    "start": "1127720",
    "end": "1134929"
  },
  {
    "text": "be a combination of\ngentamicin and carbenicillin. Again, this is medical\nknowledge as of 1975.",
    "start": "1134930",
    "end": "1143630"
  },
  {
    "text": "But my guess is the\nreal underlying reason is that there probably\nwere pseudomonas",
    "start": "1143630",
    "end": "1149570"
  },
  {
    "text": "that were resistant by\nthat point, to gentamicin, and so they used a\ncombination therapy.",
    "start": "1149570",
    "end": "1155750"
  },
  {
    "text": "Now, notice, by the way, that\nthis explanation capability does not tell you that, right?",
    "start": "1155750",
    "end": "1162570"
  },
  {
    "text": "Because it doesn't actually\nunderstand the rationale behind these individual rules.",
    "start": "1162570",
    "end": "1168390"
  },
  {
    "text": "And at the time there was\nalso research, for example, by one of my students on how\nto do a better job of that",
    "start": "1168390",
    "end": "1175230"
  },
  {
    "text": "by encoding not only the\nrules or the patterns,",
    "start": "1175230",
    "end": "1180540"
  },
  {
    "text": "but also the rationale behind\nthem so that the explanations could be more sensible.",
    "start": "1180540",
    "end": "1186690"
  },
  {
    "text": "OK. Well, the granddaddy of the\nstandard just-so story approach",
    "start": "1186690",
    "end": "1194820"
  },
  {
    "text": "to explanation of complex models\ntoday comes from this paper",
    "start": "1194820",
    "end": "1200759"
  },
  {
    "text": "and a system called LIME-- Locally Interpretable\nModel-agnostic Explanations.",
    "start": "1200760",
    "end": "1207150"
  },
  {
    "text": "And just to give\nyou an illustration, you have some complicated\nmodel and it's",
    "start": "1207150",
    "end": "1212280"
  },
  {
    "text": "trying to explain why the\ndoctor or the human being made a certain decision,\nor why the model made",
    "start": "1212280",
    "end": "1219510"
  },
  {
    "text": "a certain decision. And so it says, well,\nhere are the data we have about the patient.",
    "start": "1219510",
    "end": "1225190"
  },
  {
    "text": "We know that the\npatient is sneezing. And we know their weight\nand their headache and their age and the fact\nthat they have no fatigue.",
    "start": "1225190",
    "end": "1234389"
  },
  {
    "text": "And so the explainer\nsays, well, why did the model decide\nthis patient has the flu?",
    "start": "1234390",
    "end": "1241410"
  },
  {
    "text": "Well, positives are\nsneeze and headache. And a negative is no fatigue.",
    "start": "1241410",
    "end": "1248750"
  },
  {
    "text": "So it goes into this\ncomplicated model and it says, well, I can't\nexplain all the numerology that",
    "start": "1248750",
    "end": "1256309"
  },
  {
    "text": "happens in that neural\nnetwork or Bayesian network or whatever network it's using.",
    "start": "1256310",
    "end": "1262940"
  },
  {
    "text": "But I can specify that\nit looks like these are the most important positive\nand negative contributors.",
    "start": "1262940",
    "end": "1271570"
  },
  {
    "text": "Yeah? AUDIENCE: Is this\nfor notes only, or it's for all types of data? PROFESSOR: I'll show you some\nother kind of data in a minute.",
    "start": "1271570",
    "end": "1278660"
  },
  {
    "text": "I think they originally\nworked it out for notes, but it was also used for\nimages and other kinds of data,",
    "start": "1278660",
    "end": "1285710"
  },
  {
    "text": "as well. OK. ",
    "start": "1285710",
    "end": "1292270"
  },
  {
    "text": "And the argument they make\nis that this approach also helps to detect data\nleakage, for example",
    "start": "1292270",
    "end": "1298299"
  },
  {
    "text": "in one of their experiments,\nthe headers of the data had",
    "start": "1298300",
    "end": "1306640"
  },
  {
    "text": "information in them that\nthat correlated highly with the result.",
    "start": "1306640",
    "end": "1312790"
  },
  {
    "text": "I think there-- I can't\nremember if it was these guys, but somebody was assigning\nstudy IDs to each case.",
    "start": "1312790",
    "end": "1320140"
  },
  {
    "text": "And they did it a stupid way\nso that all the small numbers corresponded to people who had\nthe disease and the big numbers",
    "start": "1320140",
    "end": "1327970"
  },
  {
    "text": "corresponded to the\npeople who didn't. And of course, the most\nparsimonious predictive model",
    "start": "1327970",
    "end": "1333730"
  },
  {
    "text": "just used the ID number\nand said, OK, I got it. So this would help\nyou identify that,",
    "start": "1333730",
    "end": "1340720"
  },
  {
    "text": "because if you see that the\nbest predictor is the ID number,",
    "start": "1340720",
    "end": "1345919"
  },
  {
    "text": "then you would say, hmm,\nthere's something a little fishy going on here. ",
    "start": "1345920",
    "end": "1352050"
  },
  {
    "text": "Well-- so here's an example\nwhere this kind of capability is very useful.",
    "start": "1352050",
    "end": "1357759"
  },
  {
    "text": "So this was another-- this was from a newsgroup. And they were trying to\ndecide whether a post was",
    "start": "1357760",
    "end": "1364860"
  },
  {
    "text": "about Christianity or atheism.  Now, look at these two models.",
    "start": "1364860",
    "end": "1372500"
  },
  {
    "text": "So there's algorithm\n1 and algorithm 2 or model 1 and model 2. And when you explain\na particular case",
    "start": "1372500",
    "end": "1381100"
  },
  {
    "text": "about using model 1, it\nsays, while the words that I consider important\nare God, mean, anyone, this,",
    "start": "1381100",
    "end": "1390790"
  },
  {
    "text": "Koresh, and through-- does anybody remember\nwho David Koresh was?",
    "start": "1390790",
    "end": "1397430"
  },
  {
    "text": "He was some cult leader who-- I can't remember if he killed\na bunch of people or bad things",
    "start": "1397430",
    "end": "1405950"
  },
  {
    "text": "happened. Oh, I think he was\nthe guy in Waco, Texas that the FBI and the ATF went\nin and set their place on fire",
    "start": "1405950",
    "end": "1417650"
  },
  {
    "text": "and a whole bunch\nof people died. So the prediction in\nthis case is atheism.",
    "start": "1417650",
    "end": "1424700"
  },
  {
    "text": "And you notice that God and\nKoresh and Mean are negatives.",
    "start": "1424700",
    "end": "1429710"
  },
  {
    "text": "And anyone this and\nthrough are positives. And you go, I don't\nknow, is that good?",
    "start": "1429710",
    "end": "1437360"
  },
  {
    "text": "But then you look at\nalgorithm 2 and you say, this also made the\ncorrect prediction,",
    "start": "1437360",
    "end": "1443400"
  },
  {
    "text": "which is that this particular\narticle is about atheism. But the positives were\nthe word by and in,",
    "start": "1443400",
    "end": "1451346"
  },
  {
    "text": "not terribly specific. And the negatives\nwere things like NNTP.",
    "start": "1451346",
    "end": "1458230"
  },
  {
    "text": "You know what that is? That's the Network\nTime Protocol. It's some technical thing,\nand posting and host.",
    "start": "1458230",
    "end": "1467270"
  },
  {
    "text": "So this is probably\nlike metadata that got into the header of\nthe articles or something.",
    "start": "1467270",
    "end": "1474860"
  },
  {
    "text": "So it happened\nthat in this case, algorithm 2 turned out to be\nmore accurate than algorithm",
    "start": "1474860",
    "end": "1482950"
  },
  {
    "text": "1 on their held out test data,\nbut not for any good reason.",
    "start": "1482950",
    "end": "1488450"
  },
  {
    "text": "And so the\nexplanation capability allows you to clue\nin on the fact",
    "start": "1488450",
    "end": "1493480"
  },
  {
    "text": "that even though this thing\nis getting the right answers, it's not for sensible reasons.",
    "start": "1493480",
    "end": "1500460"
  },
  {
    "text": "OK.  So what would you like\nfrom an explanation?",
    "start": "1500460",
    "end": "1505810"
  },
  {
    "text": "Well, they say you'd like\nit to be interpretable. So it should provide\nqualitative understanding",
    "start": "1505810",
    "end": "1511900"
  },
  {
    "text": "of the relationship\nbetween the input variables and the response. But they also say\nthat that's going",
    "start": "1511900",
    "end": "1518529"
  },
  {
    "text": "to depend on the audience. It requires sparsity for\nthe George Miller argument",
    "start": "1518530",
    "end": "1523930"
  },
  {
    "text": "that I was making before. You can't keep too\nmany things in mind. And the features themselves\nthat you're explaining",
    "start": "1523930",
    "end": "1532420"
  },
  {
    "text": "must make sense. So for example, if I say,\nwell, the reason this decided that is\nbecause the eigenvector",
    "start": "1532420",
    "end": "1540669"
  },
  {
    "text": "for the first\nprinciple component was the following,\nthat's not going",
    "start": "1540670",
    "end": "1547450"
  },
  {
    "text": "to mean much to most people.  And then they also say, well,\nit ought to have local fidelity.",
    "start": "1547450",
    "end": "1555190"
  },
  {
    "text": "So it must correspond\nto how the model behaves in the vicinity of the\nparticular instance",
    "start": "1555190",
    "end": "1561220"
  },
  {
    "text": "that you're trying to explain. And their third criterion, which\nI think is a little iffier,",
    "start": "1561220",
    "end": "1569350"
  },
  {
    "text": "is that it must\nbe model-agnostic. In other words, you can't\ntake advantage of anything",
    "start": "1569350",
    "end": "1574940"
  },
  {
    "text": "you know that is specific\nabout the structure of the model, the way you\ntrained it, anything like that.",
    "start": "1574940",
    "end": "1581420"
  },
  {
    "text": "It has to be a general\npurpose explainer that works on any kind of\ncomplicated model.",
    "start": "1581420",
    "end": "1587549"
  },
  {
    "text": "Yeah? AUDIENCE: What is the\nreasoning for that?  PROFESSOR: I think their\nreasoning for why they insist",
    "start": "1587550",
    "end": "1595299"
  },
  {
    "text": "on this is because\nthey don't want to have to write a\nseparate explainer for each possible model.",
    "start": "1595300",
    "end": "1602620"
  },
  {
    "text": "So it's much more efficient\nif you can get this done. But I actually question whether\nthis is always a good idea",
    "start": "1602620",
    "end": "1609520"
  },
  {
    "text": "or not. But nevertheless, this is\none of their assumptions. OK.",
    "start": "1609520",
    "end": "1614630"
  },
  {
    "text": "So here's the setup\nthat they use. They say, all\nright, x is a vector",
    "start": "1614630",
    "end": "1621160"
  },
  {
    "text": "in some D-dimensional space\nthat defines your original data.",
    "start": "1621160",
    "end": "1626890"
  },
  {
    "text": "And what we're\ngoing to do in order to make the data explainable,\nin order to make the data,",
    "start": "1626890",
    "end": "1632830"
  },
  {
    "text": "not the model,\nexplainable, is we're going to define a\nnew set of variables, x prime, that are\nall binary and that",
    "start": "1632830",
    "end": "1641170"
  },
  {
    "text": "are in some space of\ndimension D prime that is probably lower than D.",
    "start": "1641170",
    "end": "1650020"
  },
  {
    "text": "So we're simplifying the\ndata that we're going to explain about this model.",
    "start": "1650020",
    "end": "1657150"
  },
  {
    "text": "Then they say, OK, we're\ngoing to build an explanation model, g, where g is a class\nof interpretable models.",
    "start": "1657150",
    "end": "1665700"
  },
  {
    "text": "So what's an\ninterpretable model? Well, they don't\ntell you, but they say, well, examples might be\nlinear models, additive scores,",
    "start": "1665700",
    "end": "1675080"
  },
  {
    "text": "decision trees,\nfalling rule lists, which we'll see\nlater in the lecture.",
    "start": "1675080",
    "end": "1681090"
  },
  {
    "text": "And the domain of\nthis is this input, the simplified input data, the\nbinary variables in D prime",
    "start": "1681090",
    "end": "1688429"
  },
  {
    "text": "dimensions, and the model\ncomplexity is going to be some",
    "start": "1688430",
    "end": "1694580"
  },
  {
    "text": "measure of the depth\nof the decision tree, the number of non-zero weights,\nand the logistic regression--",
    "start": "1694580",
    "end": "1701930"
  },
  {
    "text": "the number of clauses in a\nfalling rule list, et cetera.",
    "start": "1701930",
    "end": "1707700"
  },
  {
    "text": "So it's some complexity measure. And you want to\nminimize complexity. So then they say, all\nright, the real model,",
    "start": "1707700",
    "end": "1714770"
  },
  {
    "text": "the hairy, complicated\nfull-bore model is f.",
    "start": "1714770",
    "end": "1720980"
  },
  {
    "text": "And that maps the original data\nspace into some probability.",
    "start": "1720980",
    "end": "1727230"
  },
  {
    "text": "And for example,\nfor classification, f is the probability that x\nbelongs to a certain class.",
    "start": "1727230",
    "end": "1733770"
  },
  {
    "text": "And then they also need\na proximity measure. So they need to\nsay, we have to have",
    "start": "1733770",
    "end": "1739110"
  },
  {
    "text": "a way of comparing two cases\nand saying how close are they to each other?",
    "start": "1739110",
    "end": "1744820"
  },
  {
    "text": "And the reason for that\nis because, remember, they're going to give\nyou an explanation",
    "start": "1744820",
    "end": "1750000"
  },
  {
    "text": "of a particular case and the\nmost relevant things that will help with that\nexplanation are",
    "start": "1750000",
    "end": "1756270"
  },
  {
    "text": "the ones that are near it in\nthis high dimensional input space. ",
    "start": "1756270",
    "end": "1762990"
  },
  {
    "text": "So they then define\ntheir loss function based on the actual\ndecision algorithm,",
    "start": "1762990",
    "end": "1769530"
  },
  {
    "text": "based on the simplified one, and\nbased on the proximity measure.",
    "start": "1769530",
    "end": "1774690"
  },
  {
    "text": "And they say, well,\nthe best explanation is that g which minimizes\nthis loss function",
    "start": "1774690",
    "end": "1782160"
  },
  {
    "text": "plus the complexity of g. Pretty straightforward.",
    "start": "1782160",
    "end": "1787970"
  },
  {
    "text": "So that's our best model. ",
    "start": "1787970",
    "end": "1796090"
  },
  {
    "text": "Now, the clever\nidea here is to say, instead of using all of the\ndata that we started with,",
    "start": "1796090",
    "end": "1805389"
  },
  {
    "text": "what we're going to do\nis to sample the data so that we take more sample\npoints near the point we're",
    "start": "1805390",
    "end": "1813370"
  },
  {
    "text": "interested in explaining. We're going to sample in\nthe simplified space that",
    "start": "1813370",
    "end": "1819980"
  },
  {
    "text": "is explainable and\nthen we'll build that g model, the explanatory\nmodel, from that sample of data",
    "start": "1819980",
    "end": "1828860"
  },
  {
    "text": "where we weight by\nthat proximity function so the things that are closer\nwill have a larger influence",
    "start": "1828860",
    "end": "1835730"
  },
  {
    "text": "on the model that we learn. And then we recapture the--",
    "start": "1835730",
    "end": "1843750"
  },
  {
    "text": " sort of the closest point to\nthis simplified representation.",
    "start": "1843750",
    "end": "1851480"
  },
  {
    "text": "We can calculate what\nits answer should be. And that becomes the\nlabel for that point.",
    "start": "1851480",
    "end": "1859290"
  },
  {
    "text": "And so now we train\na simple model to predict the label that\nthe complicated model would",
    "start": "1859290",
    "end": "1864860"
  },
  {
    "text": "have predicted for the\npoint that we've sampled. Yeah?",
    "start": "1864860",
    "end": "1870610"
  },
  {
    "text": "AUDIENCE: So the proximity\nmeasure is [INAUDIBLE]?? ",
    "start": "1870610",
    "end": "1878550"
  },
  {
    "text": "PROFESSOR: It's a distance\nfunction of some sort. And I'll say more\nabout it in a minute, because that's one\nof the critiques",
    "start": "1878550",
    "end": "1885540"
  },
  {
    "text": "of this particular method\nhas to do with how do you choose that distance function?",
    "start": "1885540",
    "end": "1891419"
  },
  {
    "text": "But it's basically a similarity. So here's a nice, graphical\nexplanation of what's going on.",
    "start": "1891420",
    "end": "1899250"
  },
  {
    "text": "Suppose that the actual model-- the decision boundary is between\nthe blue and the pink regions.",
    "start": "1899250",
    "end": "1906260"
  },
  {
    "text": "OK. So it's this god awful, hairy,\ncomplicated decision model.",
    "start": "1906260",
    "end": "1911710"
  },
  {
    "text": "And we're trying to explain\nwhy this big, red plus wound up",
    "start": "1911710",
    "end": "1917320"
  },
  {
    "text": "in the pink rather\nthan in the blue. So the approach\nthat they take is",
    "start": "1917320",
    "end": "1922600"
  },
  {
    "text": "to say, well, let's\nsample a bunch of points weighted by shortest distance.",
    "start": "1922600",
    "end": "1929250"
  },
  {
    "text": "So we do sample a\nfew points out here. But mostly we're sampling\npoints near the point",
    "start": "1929250",
    "end": "1936280"
  },
  {
    "text": "that we're interested in. We then learn a linear\nboundary between the positive",
    "start": "1936280",
    "end": "1943680"
  },
  {
    "text": "and the negative cases. And that boundary\nis an approximation",
    "start": "1943680",
    "end": "1949309"
  },
  {
    "text": "to the actual boundary in\nthe more complicated decision model.",
    "start": "1949310",
    "end": "1956540"
  },
  {
    "text": "So now we can give\nan explanation just like you saw\nbefore which says, well,",
    "start": "1956540",
    "end": "1963700"
  },
  {
    "text": "this is some D prime\ndimensional space. And so which variables in\nthat D prime dimensional space",
    "start": "1963700",
    "end": "1972760"
  },
  {
    "text": "are the ones that\ninfluence where you are on one side or another\nof this newly computed decision",
    "start": "1972760",
    "end": "1980020"
  },
  {
    "text": "boundary, and to what extent? And that becomes\nthe explanation.",
    "start": "1980020",
    "end": "1986263"
  },
  {
    "text": "OK? Nice idea. ",
    "start": "1986264",
    "end": "1992940"
  },
  {
    "text": "So if you apply this to\ntext classification-- yes? AUDIENCE: I was just\ngoing to ask if the--",
    "start": "1992940",
    "end": "1998769"
  },
  {
    "text": "there's a worry that if\nexplanation is just fictitious, like, we can understand it? But is there reason to believe\nthat we should believe it",
    "start": "1998770",
    "end": "2007190"
  },
  {
    "text": "if that's really the\ntrue nature of things that the linear does-- you\nknow, it would be like, OK, we know what's\ngoing on here.",
    "start": "2007190",
    "end": "2012670"
  },
  {
    "text": "But is that even\nclose to reality?",
    "start": "2012670",
    "end": "2018550"
  },
  {
    "text": "PROFESSOR: Well,\nthat's why I called it a just-so story, right? Should you believe it?",
    "start": "2018550",
    "end": "2024550"
  },
  {
    "text": "Well, the engineering\ndisciplines",
    "start": "2024550",
    "end": "2030690"
  },
  {
    "text": "have a very long\nhistory of approximating extremely complicated\nphenomena with linear models.",
    "start": "2030690",
    "end": "2038340"
  },
  {
    "text": "Right? I mean, I'm in a department\nof electrical engineering and computer science.",
    "start": "2038340",
    "end": "2043470"
  },
  {
    "text": "And if I talk to my electrical\nengineering colleagues, they know that the world\nis insanely complicated.",
    "start": "2043470",
    "end": "2049888"
  },
  {
    "text": "Nevertheless, most models\nin electrical engineering are linear models. And they work well\nenough that people",
    "start": "2049889",
    "end": "2056370"
  },
  {
    "text": "are able to build really\ncomplicated things and have them work. So that's not a proof.",
    "start": "2056370",
    "end": "2063149"
  },
  {
    "text": "That's an argument by\nhistory or something. But it's true.",
    "start": "2063150",
    "end": "2069540"
  },
  {
    "text": "Linear models are very\npowerful, especially when you limit them to giving\nexplanations that are local.",
    "start": "2069540",
    "end": "2076589"
  },
  {
    "text": "Notice that this model is\na very poor approximation to this decision boundary\nor this one, right?",
    "start": "2076590",
    "end": "2085379"
  },
  {
    "text": "And so it only works to\nexplain in the neighborhood of the particular\nexample that I've chosen.",
    "start": "2085380",
    "end": "2093270"
  },
  {
    "text": "Right? But it does work OK there. Yeah. AUDIENCE: [INAUDIBLE]\nvery well there?",
    "start": "2093270",
    "end": "2100420"
  },
  {
    "text": "[INAUDIBLE] middle of\nthe red space then the--",
    "start": "2100420",
    "end": "2110589"
  },
  {
    "text": "PROFESSOR: Well, they did. So they sample all\nover the place.",
    "start": "2110590",
    "end": "2116000"
  },
  {
    "text": "But remember that that\nproximity function says that this one is less\nrelevant to predicting",
    "start": "2116000",
    "end": "2123250"
  },
  {
    "text": "that decision boundary because\nit's far away from the point that I'm interested in.",
    "start": "2123250",
    "end": "2129320"
  },
  {
    "text": "So that's the magic. AUDIENCE: But here\nthey're trying to explain to the\ndeep red cross, right? PROFESSOR: Yes. AUDIENCE: And they\npicked some point",
    "start": "2129320",
    "end": "2135760"
  },
  {
    "text": "in the middle of\nthe red space maybe. Then all the nearby ones\nwould be red and [INAUDIBLE]..",
    "start": "2135760",
    "end": "2145930"
  },
  {
    "text": "PROFESSOR: Well,\nbut they would-- I mean, suppose they\npicked this point, instead.",
    "start": "2145930",
    "end": "2150940"
  },
  {
    "text": "Then they would sample\naround this point and presumably they would\nfind this decision boundary",
    "start": "2150940",
    "end": "2156490"
  },
  {
    "text": "or this one or\nsomething like that and still be able to come up\nwith a coherent explanation.",
    "start": "2156490",
    "end": "2161740"
  },
  {
    "text": " OK, so in the case\nof text, you've",
    "start": "2161740",
    "end": "2170090"
  },
  {
    "text": "seen this example already. It's pretty simple. For their proximity function,\nthey use cosine distance.",
    "start": "2170090",
    "end": "2177180"
  },
  {
    "text": "So it's a bag of words\nmodel and they just calculate cosine distance\nbetween different examples",
    "start": "2177180",
    "end": "2184280"
  },
  {
    "text": "by how much overlap there is\nbetween the words that they use and the frequency of\nwords that they use.",
    "start": "2184280",
    "end": "2191690"
  },
  {
    "text": "And then they choose k-- the number of words to\nshow just as a preference.",
    "start": "2191690",
    "end": "2199700"
  },
  {
    "text": "So it's sort of\na hyperparameter. They say, you know, I'm\ninterested in looking at the top five words\nor the top 10 words that",
    "start": "2199700",
    "end": "2207349"
  },
  {
    "text": "are either positively or\nnegatively an influence on the decision, but\nnot the top 10,000",
    "start": "2207350",
    "end": "2214310"
  },
  {
    "text": "words because I don't know\nwhat to do with 10,000 words.",
    "start": "2214310",
    "end": "2220630"
  },
  {
    "text": "Now, what's interesting\nis you can also then apply the same idea\nto image interpretation.",
    "start": "2220630",
    "end": "2226400"
  },
  {
    "text": "So here is a dog\nplaying a guitar.",
    "start": "2226400",
    "end": "2232150"
  },
  {
    "text": "And they say, how do\nwe interpret this?",
    "start": "2232150",
    "end": "2238910"
  },
  {
    "text": "And so this is one of\nthese labeling tasks where you'd like to label this\npicture as a Labrador or maybe",
    "start": "2238910",
    "end": "2246310"
  },
  {
    "text": "as an acoustic guitar. But some reason--\nsome labels also decide that it's\nan electric guitar.",
    "start": "2246310",
    "end": "2254170"
  },
  {
    "text": "And so they say, well,\nwhat counts in favor of or against each of these?",
    "start": "2254170",
    "end": "2260349"
  },
  {
    "text": "And the approach they take is a\nrelatively straightforward one. They say let's\ndefine a super pixel",
    "start": "2260350",
    "end": "2268810"
  },
  {
    "text": "as a region of pixels\nwithin an image that have roughly the same intensity.",
    "start": "2268810",
    "end": "2275890"
  },
  {
    "text": "So if you've ever\nused Photoshop, the magic selection tool\ncan be adjusted to say,",
    "start": "2275890",
    "end": "2282580"
  },
  {
    "text": "find a region around this point\nwhere all the intensities are within some delta of the\npoint that I've picked.",
    "start": "2282580",
    "end": "2291789"
  },
  {
    "text": "And so it'll outline some\nregion of the picture. And what they do is they\nbreak up the entire image",
    "start": "2291790",
    "end": "2298990"
  },
  {
    "text": "into these regions. And then they treat those\nas if they were the words",
    "start": "2298990",
    "end": "2304030"
  },
  {
    "text": "in the words style explanation.  So they say, well, this\nlooks like an electric guitar",
    "start": "2304030",
    "end": "2313410"
  },
  {
    "text": "to the algorithm. And this looks like\nan acoustic guitar.",
    "start": "2313410",
    "end": "2318760"
  },
  {
    "text": "And this looks like a Labrador. So some of that makes sense. I mean, you know,\nthat dog's face",
    "start": "2318760",
    "end": "2324539"
  },
  {
    "text": "does kind of look like a Lab. This does look kind of like\npart of the body and part",
    "start": "2324540",
    "end": "2331710"
  },
  {
    "text": "of the fret work of a guitar. I have no idea\nwhat this stuff is or why this contributes\nto it being a dog.",
    "start": "2331710",
    "end": "2339990"
  },
  {
    "text": "But such is-- such is the\nnature of these models. But at least it is\ntelling you why it",
    "start": "2339990",
    "end": "2347410"
  },
  {
    "text": "believes these various things. So then the last\nthing they do is to say, well, OK, that\nhelps you understand",
    "start": "2347410",
    "end": "2355190"
  },
  {
    "text": "the particular model. But how do you\nconvince yourself-- I mean, a particular example\nwhere a model is applied to it.",
    "start": "2355190",
    "end": "2365230"
  },
  {
    "text": "But how do you convince\nyourself that the model itself is reasonable? And so they say, well,\nthe best technique we know",
    "start": "2365230",
    "end": "2372670"
  },
  {
    "text": "is to show you a\nbunch of examples. But we want those\nexamples to kind of cover",
    "start": "2372670",
    "end": "2377859"
  },
  {
    "text": "the gamut of places that\nyou might be interested in. And so they say, let's\ncreate this matrix--",
    "start": "2377860",
    "end": "2385720"
  },
  {
    "text": "an explanation matrix where\nthese are the cases and these are the various features, you\nknow, the top words or the top",
    "start": "2385720",
    "end": "2394990"
  },
  {
    "text": "pixel elements or\nsomething, and then we'll fill in the element of\nthe matrix that tells me",
    "start": "2394990",
    "end": "2403450"
  },
  {
    "text": "how strongly this feature is\ncorrelated or anti-correlated with the classification\nfor that model.",
    "start": "2403450",
    "end": "2411950"
  },
  {
    "text": "And then it becomes a\nkind of set covering issue of find a set of\nmodels that gives me",
    "start": "2411950",
    "end": "2418119"
  },
  {
    "text": "the best coverage\nof explanations across that set of features.",
    "start": "2418120",
    "end": "2423609"
  },
  {
    "text": "And then with that,\nI can convince myself that the model is reasonable.",
    "start": "2423610",
    "end": "2429609"
  },
  {
    "text": "So they have this thing called\nthe sub modular pick algorithm. And you know, probably\nif you're interested,",
    "start": "2429610",
    "end": "2437660"
  },
  {
    "text": "you should read the paper. But what they're\ndoing is essentially",
    "start": "2437660",
    "end": "2443020"
  },
  {
    "text": "doing a kind of greedy\nsearch that says, what features should\nI add in order",
    "start": "2443020",
    "end": "2449950"
  },
  {
    "text": "to get the best coverage in that\nspace of features by documents?",
    "start": "2449950",
    "end": "2455890"
  },
  {
    "start": "2455890",
    "end": "2462920"
  },
  {
    "text": "And then they did a\nbunch of experiments where they said,\nOK, let's compare the results of\nthese explanations",
    "start": "2462920",
    "end": "2470750"
  },
  {
    "text": "of these simplified models\nto two sentiment analysis tasks of 2,000 instances each.",
    "start": "2470750",
    "end": "2478040"
  },
  {
    "text": "Bag of words as features-- they\ncompared it to decision trees, logistic regression,\nnearest neighbors,",
    "start": "2478040",
    "end": "2484309"
  },
  {
    "text": "SVM with the radial\nbasis function, kernel, or random forests that use\nword to vacuum beddings--",
    "start": "2484310",
    "end": "2492410"
  },
  {
    "text": "highly non-explainable-- with 1,000 trees and K equal 10.",
    "start": "2492410",
    "end": "2499359"
  },
  {
    "text": "So they chose 10\nfeatures to explain for each of these models.",
    "start": "2499360",
    "end": "2506180"
  },
  {
    "text": "They then did a side\ncalculation that said, what are the 10 most suggestive\nfeatures for each case?",
    "start": "2506180",
    "end": "2518090"
  },
  {
    "text": "And then they said, does\nthat covering algorithm",
    "start": "2518090",
    "end": "2523250"
  },
  {
    "text": "identify those\nfeatures correctly? And so what they show here is\nthat their method line does",
    "start": "2523250",
    "end": "2534960"
  },
  {
    "text": "better in every case\nthan a random sampling--",
    "start": "2534960",
    "end": "2540240"
  },
  {
    "text": "that's not very surprising-- or a greedy sampling or a\npartisan sampling, which",
    "start": "2540240",
    "end": "2546390"
  },
  {
    "text": "I don't know the details of. But in any case, there's\nwhat this graph is showing",
    "start": "2546390",
    "end": "2552390"
  },
  {
    "text": "is that of the\nfeatures that they decided were important\nin each of these cases,",
    "start": "2552390",
    "end": "2558539"
  },
  {
    "text": "they're recovering. So their recall is up\naround 90, 90-plus percent.",
    "start": "2558540",
    "end": "2565480"
  },
  {
    "text": "So in fact, the algorithm is\nidentifying the right cases",
    "start": "2565480",
    "end": "2570720"
  },
  {
    "text": "to give you a broad\ncoverage across all the important\nfeatures that matter in classifying these cases.",
    "start": "2570720",
    "end": "2578730"
  },
  {
    "text": "They then also did a bunch\nof human experiments where",
    "start": "2578730",
    "end": "2583760"
  },
  {
    "text": "they said, OK, we're going\nto ask users to choose which",
    "start": "2583760",
    "end": "2589280"
  },
  {
    "text": "of two classifiers they think\nis going to generalize better. So this is like the picture I\nshowed you of the Christianity",
    "start": "2589280",
    "end": "2597260"
  },
  {
    "text": "versus atheism algorithm,\nwhere presumably if you were",
    "start": "2597260",
    "end": "2604190"
  },
  {
    "text": "a Mechanical Turker and somebody\nshowed you an algorithm that has very high accuracy but that\ndepends on things like finding",
    "start": "2604190",
    "end": "2612860"
  },
  {
    "text": "the word NNTP in a\nclassifier for atheism",
    "start": "2612860",
    "end": "2618080"
  },
  {
    "text": "versus Christianity, you would\nsay, well, maybe that algorithm isn't good to\ngeneralize very well,",
    "start": "2618080",
    "end": "2623900"
  },
  {
    "text": "because it's depending\non something random that may be correlated with\nthis particular data set.",
    "start": "2623900",
    "end": "2630770"
  },
  {
    "text": "But if I try it on a\ndifferent data set, it's unlikely to work. So that was one of the tasks.",
    "start": "2630770",
    "end": "2638100"
  },
  {
    "text": "And then they asked them\nto identify features like that that looked bad.",
    "start": "2638100",
    "end": "2645440"
  },
  {
    "text": "They then ran this Christianity\nversus atheism test",
    "start": "2645440",
    "end": "2652579"
  },
  {
    "text": "and had a separate test set\nof about 800 additional web pages from this website.",
    "start": "2652580",
    "end": "2661340"
  },
  {
    "text": "The underlying model was\na support vector machine with RBF kernels trained\non the 20 newsgroup data--",
    "start": "2661340",
    "end": "2669319"
  },
  {
    "text": "I don't know if you\nknow that data set, but it's a well-known,\npublicly available data set.",
    "start": "2669320",
    "end": "2675680"
  },
  {
    "text": "They got 100 Mechanical Turkers\nand they said, OK, we're",
    "start": "2675680",
    "end": "2680890"
  },
  {
    "text": "going to present each\nof them six documents and six features per document in\norder to ask them to make this.",
    "start": "2680890",
    "end": "2690370"
  },
  {
    "text": "And then they did an auxiliary\nexperiment in which they said, if you see words that are no\ngood in this experiment, just",
    "start": "2690370",
    "end": "2701260"
  },
  {
    "text": "strike them out. And that will tell us\nwhich of the features were bad in this method.",
    "start": "2701260",
    "end": "2712170"
  },
  {
    "text": "And what they found was that\nthe human subjects choosing",
    "start": "2712170",
    "end": "2718339"
  },
  {
    "text": "between two\nclassifiers were pretty good at figuring out which\nwas the better classifier.",
    "start": "2718340",
    "end": "2728150"
  },
  {
    "text": "Now, this is better\nby their judgment. And so they said, OK, this\nsubmodular pick algorithm--",
    "start": "2728150",
    "end": "2736440"
  },
  {
    "text": "which is the one that I\ndidn't describe in detail, but it's this set\ncovering algorithm--",
    "start": "2736440",
    "end": "2741770"
  },
  {
    "text": "gives you better results than\na random pick algorithm that just says pick random features.",
    "start": "2741770",
    "end": "2747590"
  },
  {
    "text": "Again, not totally surprising.  And the other thing\nthat's interesting",
    "start": "2747590",
    "end": "2754430"
  },
  {
    "text": "is if you do the feature\nengineering experiment, it shows that as the Turkers\ninteracted with the system,",
    "start": "2754430",
    "end": "2766740"
  },
  {
    "text": "the system became better. So they started off\nwith real world accuracy",
    "start": "2766740",
    "end": "2772250"
  },
  {
    "text": "of just under 60%. And using the better\nof their algorithms,",
    "start": "2772250",
    "end": "2777740"
  },
  {
    "text": "they reached about 75% after\nthree rounds of interaction.",
    "start": "2777740",
    "end": "2783360"
  },
  {
    "text": "So the users could say, I\ndon't like this feature. And then the system would\ngive them better features.",
    "start": "2783360",
    "end": "2791570"
  },
  {
    "text": "Now, they tried a similar\nthing with images. And so this one\nis a little funny.",
    "start": "2791570",
    "end": "2798760"
  },
  {
    "text": "So they trained a\ndeliberately lousy classifier to classify between\nwolves and huskies.",
    "start": "2798760",
    "end": "2805240"
  },
  {
    "text": " This is a famous example.",
    "start": "2805240",
    "end": "2811370"
  },
  {
    "text": "Also it turns out that huskies\nlive in Alaska and so--",
    "start": "2811370",
    "end": "2816860"
  },
  {
    "text": "and wolves-- I guess some wolves\ndo, but most wolves don't. And so the data\nset on which that--",
    "start": "2816860",
    "end": "2824990"
  },
  {
    "text": "which was used in that\noriginal problem formulation, there was an extremely accurate\nclassifier that was trained.",
    "start": "2824990",
    "end": "2835850"
  },
  {
    "text": "And when they went to look\nto see what it had learned, basically it had learned\nto look for snow.",
    "start": "2835850",
    "end": "2842490"
  },
  {
    "text": "And if it saw snow in the\npicture, it said it's a husky. And if it didn't see snow in the\npicture, it said it's a wolf.",
    "start": "2842490",
    "end": "2849750"
  },
  {
    "text": "So that turns out to be\npretty accurate for the sample that they had. But of course, it's not a very\nsophisticated classification",
    "start": "2849750",
    "end": "2859230"
  },
  {
    "text": "algorithm because\nit's possible to put a wolf in a snowy\npicture and it's",
    "start": "2859230",
    "end": "2865589"
  },
  {
    "text": "possible to have your\nHusky indoors with no snow. And then you're just missing\nthe boat on this classification.",
    "start": "2865590",
    "end": "2873540"
  },
  {
    "text": "So these guys built a\nparticularly bad classifier by having all wolves\nin the training set",
    "start": "2873540",
    "end": "2881760"
  },
  {
    "text": "had snow in the picture and\nnone of the huskies did. ",
    "start": "2881760",
    "end": "2887349"
  },
  {
    "text": "And then they presented cases to\ngraduate students like you guys with machine\nlearning backgrounds.",
    "start": "2887350",
    "end": "2894530"
  },
  {
    "text": "10 balance test predictions. But they put one ringer\nin each category.",
    "start": "2894530",
    "end": "2899630"
  },
  {
    "text": "So they put in one husky\nin snow and one wolf who was not in snow.",
    "start": "2899630",
    "end": "2905260"
  },
  {
    "text": "And the comparison was between\npre and post experiment trust and understanding.",
    "start": "2905260",
    "end": "2911380"
  },
  {
    "text": "And so before the\nexperiment, they said that 10 of the\n27 students said",
    "start": "2911380",
    "end": "2917590"
  },
  {
    "text": "they trusted this bad\nmodel that they trained. And afterwards, only 3\nout of 27 trusted it.",
    "start": "2917590",
    "end": "2926830"
  },
  {
    "text": "So this is a kind of\nsociological experiment that says, yes, we can\nactually change people's minds",
    "start": "2926830",
    "end": "2934000"
  },
  {
    "text": "about whether a model is\na good or a bad one based on an experiment.",
    "start": "2934000",
    "end": "2939790"
  },
  {
    "text": "Before only 12\nout of 27 students mentioned snow as a potential\nfeature in this classifier,",
    "start": "2939790",
    "end": "2948610"
  },
  {
    "text": "whereas afterwards\nalmost everybody did. So again, this tells you\nthat the method is providing",
    "start": "2948610",
    "end": "2957160"
  },
  {
    "text": "some useful information. Now this paper set off\na lot of work, including",
    "start": "2957160",
    "end": "2966120"
  },
  {
    "text": "a lot of critiques of the work. And so this is one particular\none from just a few months ago,",
    "start": "2966120",
    "end": "2971830"
  },
  {
    "text": "the end of December. And what these guys say is that\nthat distance function, which",
    "start": "2971830",
    "end": "2982350"
  },
  {
    "text": "includes a sigma, which is\nsort of the scale of distance that we're willing to\ngo, is pretty arbitrary.",
    "start": "2982350",
    "end": "2989670"
  },
  {
    "text": "In the experiments that\nthe original authors did, they set that distance\nto 75% of the square root",
    "start": "2989670",
    "end": "2998760"
  },
  {
    "text": "of the dimensionality\nof the data set. And you go, OK. I mean, that's a number.",
    "start": "2998760",
    "end": "3004820"
  },
  {
    "text": "But it's not obvious\nthat that's the best number or the right number.",
    "start": "3004820",
    "end": "3010280"
  },
  {
    "text": "And so these guys\nargue that it's important to tune the\nsize of the neighborhood",
    "start": "3010280",
    "end": "3017750"
  },
  {
    "text": "according to how far z,\nthe point that you're trying to explain,\nis from the boundary.",
    "start": "3017750",
    "end": "3024180"
  },
  {
    "text": "So if it's close\nto the boundary, then you ought to\ntake a smaller region",
    "start": "3024180",
    "end": "3029540"
  },
  {
    "text": "for your proximity measure. And if it's far\nfrom the boundary, this addresses the\nquestion you guys",
    "start": "3029540",
    "end": "3035210"
  },
  {
    "text": "were asking about\nwhat happens if you pick a point in the middle. And so they show\nsome nice examples",
    "start": "3035210",
    "end": "3043069"
  },
  {
    "text": "of places where, for instance,\nif you compare this explaining",
    "start": "3043070",
    "end": "3048680"
  },
  {
    "text": "this green point, you get\na nice green line that follows the local boundary.",
    "start": "3048680",
    "end": "3054680"
  },
  {
    "text": "But explaining the\nblue point, which is close to a corner of the\nactual decision boundary,",
    "start": "3054680",
    "end": "3061220"
  },
  {
    "text": "you got a line that's not very\ndifferent from the green one. And similarly for the red point.",
    "start": "3061220",
    "end": "3068080"
  },
  {
    "text": "And so they say,\nwell, we really need to work on that\ndistance function. And so they come\nup with a method",
    "start": "3068080",
    "end": "3078250"
  },
  {
    "text": "that they call LEAFAGE, which\nbasically says, remember,",
    "start": "3078250",
    "end": "3083350"
  },
  {
    "text": "what LINE did is it\nsampled nonexistent cases,",
    "start": "3083350",
    "end": "3089380"
  },
  {
    "text": "simplified nonexistent cases. But here they're going\nto sample existing cases.",
    "start": "3089380",
    "end": "3095320"
  },
  {
    "text": "So they're going to\nlearn from the training-- the original training set.",
    "start": "3095320",
    "end": "3100579"
  },
  {
    "text": "But they're going to sample\nit by proximity to the example",
    "start": "3100580",
    "end": "3105790"
  },
  {
    "text": "that they're trying to explain. And they argue that this is a\ngood idea because, for example,",
    "start": "3105790",
    "end": "3112789"
  },
  {
    "text": "in law, the notion\nof precedent is that you get to argue that this\ncase is very similar to some",
    "start": "3112790",
    "end": "3120170"
  },
  {
    "text": "previously decided\ncase, and therefore it should be decided the same way. I mean, Supreme Court arguments\nare always all about that.",
    "start": "3120170",
    "end": "3128780"
  },
  {
    "text": "Lower court arguments\nare sometimes more driven by what\nthe law actually says.",
    "start": "3128780",
    "end": "3135540"
  },
  {
    "text": "But case law has been well\nestablished in British law, and then by inheritance\nin American law",
    "start": "3135540",
    "end": "3143510"
  },
  {
    "text": "for many, many centuries. So they say, well,\ncase-based reasoning normally",
    "start": "3143510",
    "end": "3150230"
  },
  {
    "text": "involves retrieving\na similar case, adapting it, and then learning\nthat as a new precedent.",
    "start": "3150230",
    "end": "3158330"
  },
  {
    "text": "And they also argue for\ncontrastive justification, which is not only why\ndid you choose x, but why",
    "start": "3158330",
    "end": "3165410"
  },
  {
    "text": "did you choose x\nrather than y as giving a more satisfying\nand a more insightful",
    "start": "3165410",
    "end": "3172790"
  },
  {
    "text": "explanation of how\nsome model is working? So they say, OK, similar setup.",
    "start": "3172790",
    "end": "3178730"
  },
  {
    "text": "f solves the\nclassification problem where x is the data and y\nis some binary classifier,",
    "start": "3178730",
    "end": "3186080"
  },
  {
    "text": "you know 0, 1, if you like. The training set\nis a bunch of x's.",
    "start": "3186080",
    "end": "3192109"
  },
  {
    "text": "y sub true is the actual\nanswer. y predicted is what f predicts on that x.",
    "start": "3192110",
    "end": "3200930"
  },
  {
    "text": "And to explain f of z equals\nsome particular outcome,",
    "start": "3200930",
    "end": "3206910"
  },
  {
    "text": "you can define the\nallies of a case",
    "start": "3206910",
    "end": "3212849"
  },
  {
    "text": "as ones that come up\nwith the same answer. And you can define\nthe enemies as one",
    "start": "3212850",
    "end": "3219289"
  },
  {
    "text": "that wants to come up\nwith a different answer. So now you're going to sample\nboth the allies and the enemies",
    "start": "3219290",
    "end": "3228450"
  },
  {
    "text": "according to a new\ndistance function. And the intuition they\nhad is that the reason",
    "start": "3228450",
    "end": "3235390"
  },
  {
    "text": "that the distance function\nin the original line work wasn't working very\nwell is because it",
    "start": "3235390",
    "end": "3242090"
  },
  {
    "text": "was a spherical\ndistance function in n dimensional space. And so they're going\nto bias it by saying",
    "start": "3242090",
    "end": "3249470"
  },
  {
    "text": "that the distance,\nthis b, is going to be some combination\nof the difference",
    "start": "3249470",
    "end": "3257480"
  },
  {
    "text": "in the linear predictions\nplus the difference in the two",
    "start": "3257480",
    "end": "3262490"
  },
  {
    "text": "points. And so the contour\nlines of the first term",
    "start": "3262490",
    "end": "3267890"
  },
  {
    "text": "are these circular\ncontour lines. This is what lime was doing. The contour lines\nof the second term",
    "start": "3267890",
    "end": "3274400"
  },
  {
    "text": "are these linear gradients. And they add them to get\nsort of oval-shaped things.",
    "start": "3274400",
    "end": "3282230"
  },
  {
    "text": "And this is what gives\nyou that desired feature of being more sensitive\nto how close this point is",
    "start": "3282230",
    "end": "3290060"
  },
  {
    "text": "to the decision boundary. Again, there are a lot of\nrelatively hairy details, which",
    "start": "3290060",
    "end": "3298810"
  },
  {
    "text": "I'm going to elide\nin the class today. But they're definitely\nin the paper.",
    "start": "3298810",
    "end": "3304869"
  },
  {
    "text": "So they also did a user study\non some very simple prediction models.",
    "start": "3304870",
    "end": "3310580"
  },
  {
    "text": "So this was how much is your\nhouse worth based on things like how big is it and\nwhat year was it built in",
    "start": "3310580",
    "end": "3318580"
  },
  {
    "text": "and what's some subjective\nquality judgment of it? And so what they\nshow is that you",
    "start": "3318580",
    "end": "3328329"
  },
  {
    "text": "can find examples that are\nthe allies and the enemies",
    "start": "3328330",
    "end": "3334540"
  },
  {
    "text": "of this house in order\nto do the prediction. So then they apply\ntheir algorithm.",
    "start": "3334540",
    "end": "3341020"
  },
  {
    "text": "And it works. It gives you better answers. I'll have to go find\nthat slide somewhere.",
    "start": "3341020",
    "end": "3348230"
  },
  {
    "text": "All right. So that's all I'm going to\nsay about this idea of using",
    "start": "3348230",
    "end": "3357580"
  },
  {
    "text": "simplified models in\nthe local neighborhood of individual cases in\norder to explain something.",
    "start": "3357580",
    "end": "3365940"
  },
  {
    "text": "I wanted to talk about\ntwo other topics. So this was a paper\nby some of my students",
    "start": "3365940",
    "end": "3372120"
  },
  {
    "text": "recently in which they're\nlooking at medical images",
    "start": "3372120",
    "end": "3377250"
  },
  {
    "text": "and trying to generate\nradiology reports from those medical images.",
    "start": "3377250",
    "end": "3383010"
  },
  {
    "text": "I mean, you know,\nmachine learning can solve all problems. I give you a\ncollection of images",
    "start": "3383010",
    "end": "3389510"
  },
  {
    "text": "and a collection of\nradiology reports, should be straightforward to\nbuild a model that now takes",
    "start": "3389510",
    "end": "3396810"
  },
  {
    "text": "new radiological\nimages and produces new radiology reports that are\nunderstandable, accurate, et",
    "start": "3396810",
    "end": "3405130"
  },
  {
    "text": "cetera. I'm joking, of course. ",
    "start": "3405130",
    "end": "3411819"
  },
  {
    "text": "But the approach they took\nwas kind of interesting. So they've taken a\nstandard image decoder.",
    "start": "3411820",
    "end": "3417980"
  },
  {
    "text": "And then before\nthe pooling layer, they take essentially an\nimage embedding from the next",
    "start": "3417980",
    "end": "3425819"
  },
  {
    "text": "to last layer of this\nimage encoding algorithm.",
    "start": "3425820",
    "end": "3431430"
  },
  {
    "text": "And then they feed that\ninto a word decoder and word generator.",
    "start": "3431430",
    "end": "3438030"
  },
  {
    "text": "And the idea is\nto get things that appear in the image that\ncorrespond to words that appear",
    "start": "3438030",
    "end": "3446610"
  },
  {
    "text": "in the report to wind up in\nthe same place in the embedding",
    "start": "3446610",
    "end": "3452490"
  },
  {
    "text": "space. And so again, there's\na lot of hair. It's an LSDM based encoder.",
    "start": "3452490",
    "end": "3462030"
  },
  {
    "text": "And it's modeled as\na sentence decoder. And within that, there\nis a word decoder,",
    "start": "3462030",
    "end": "3467840"
  },
  {
    "text": "and then there's a generator\nthat generates these reports. And it uses\nreinforcement learning.",
    "start": "3467840",
    "end": "3474210"
  },
  {
    "text": "And you know, tons of hair. But here's what I wanted to\nshow you, which is interesting.",
    "start": "3474210",
    "end": "3483510"
  },
  {
    "text": "So the encoder takes a bunch\nof spatial image features.",
    "start": "3483510",
    "end": "3488570"
  },
  {
    "text": "The sentence decoder uses these\nimage features in addition to the linguistic features,\nthe word embeddings that",
    "start": "3488570",
    "end": "3499339"
  },
  {
    "text": "are fed into it. And then for ground\ntruth annotation,",
    "start": "3499340",
    "end": "3508080"
  },
  {
    "text": "they also use a remote\nannotation method, which is this chexpert program, which\nis a rule-based program out",
    "start": "3508080",
    "end": "3516000"
  },
  {
    "text": "of Stanford that reads\nradiology reports and identifies features in\nthe report that it thinks",
    "start": "3516000",
    "end": "3523320"
  },
  {
    "text": "are important and correct. So it's not always\ncorrect, of course.",
    "start": "3523320",
    "end": "3530250"
  },
  {
    "text": "But that's used in order\nto guide the generator.",
    "start": "3530250",
    "end": "3537150"
  },
  {
    "text": "So here's an example. So this is an image of a\nchest and the ground truth--",
    "start": "3537150",
    "end": "3546250"
  },
  {
    "text": "so this is the actual\nradiology report-- says cardiomegalia is moderate. Bibasilar atelectasis is mild.",
    "start": "3546250",
    "end": "3554079"
  },
  {
    "text": "There's no pneumothoraxal\nor cervical spinal fusion is partially visualized. Healed right rib fractures\nare incidentally noted.",
    "start": "3554080",
    "end": "3562470"
  },
  {
    "text": "By the way, I've stared at\nhundreds of radiological images like this. I could never figure out\nthat this image says that.",
    "start": "3562470",
    "end": "3575800"
  },
  {
    "text": "But that's why radiologists\ntrain for many, many years to become good at this stuff.",
    "start": "3575800",
    "end": "3582210"
  },
  {
    "text": "So there was a\nprevious program done by others called TieNet which\ngenerates the following report.",
    "start": "3582210",
    "end": "3590150"
  },
  {
    "text": "It says AP portable\nupright view of the chest. There's no call no focal\nconsolidation, effusion,",
    "start": "3590150",
    "end": "3596329"
  },
  {
    "text": "or pneumothorax. The cardio mediastinal\nsilhouette is normal.",
    "start": "3596330",
    "end": "3601849"
  },
  {
    "text": "Imaged osseous\nstructures are intact. So if you compare\nthis to that, you",
    "start": "3601850",
    "end": "3607310"
  },
  {
    "text": "say, well, if the cardio\nmediastinal silhouette is normal, then where would\nthe lower cervical spinal",
    "start": "3607310",
    "end": "3619340"
  },
  {
    "text": "fusion, being partially\nvisualized, because that's along the middle.",
    "start": "3619340",
    "end": "3624860"
  },
  {
    "text": "And so these are not\nquite consistent. So the system that\nthese students built",
    "start": "3624860",
    "end": "3630920"
  },
  {
    "text": "says there's mild enlargement\nof the cardiac silhouette. There is no pleural\neffusion or pneumothorax.",
    "start": "3630920",
    "end": "3637280"
  },
  {
    "text": "And there's no acute\nosseous abnormalities. So it also missed the\nhealed right rib fractures",
    "start": "3637280",
    "end": "3644869"
  },
  {
    "text": "that were incidentally noted. But anyway, it's-- you know,\nthe remarkable thing about",
    "start": "3644870",
    "end": "3650780"
  },
  {
    "text": "a singing dog is not how well\nit sings but the fact that it sings at all. ",
    "start": "3650780",
    "end": "3658360"
  },
  {
    "text": "And the reason I\nincluded this work is not to convince\nyou that this is going to replace\nradiologists anytime soon,",
    "start": "3658360",
    "end": "3667829"
  },
  {
    "text": "but that it had an interesting\nexplanation facility. And the explanation\nfacility uses",
    "start": "3667830",
    "end": "3675180"
  },
  {
    "text": "attention, which is\npart of its model, to say, hey, when we\nreach some conclusion,",
    "start": "3675180",
    "end": "3682800"
  },
  {
    "text": "we can point back\ninto the image and say what part of the\nimage corresponds",
    "start": "3682800",
    "end": "3688559"
  },
  {
    "text": "to that part of the conclusion. And so this is\npretty interesting. You say in upright and lateral\nviews of the chest in red,",
    "start": "3688560",
    "end": "3697619"
  },
  {
    "text": "well, that's kind\nof the chest in red. There's moderate cardiomegaly,\nso here the green",
    "start": "3697620",
    "end": "3707250"
  },
  {
    "text": "certainly shows you\nwhere your heart is. OK. About there and a\nlittle bit to the left.",
    "start": "3707250",
    "end": "3715270"
  },
  {
    "text": "And there's no pleural\neffusion or pneumothorax. This one is kind of funny. That's the blue region.",
    "start": "3715270",
    "end": "3722019"
  },
  {
    "text": "So how do you show me that\nthere isn't something?",
    "start": "3722020",
    "end": "3728010"
  },
  {
    "text": "And we were surprised,\nactually, the way it showed us that\nthere isn't something",
    "start": "3728010",
    "end": "3734070"
  },
  {
    "text": "is to highlight everything\noutside of anything that you might be\ninterested in, which",
    "start": "3734070",
    "end": "3740329"
  },
  {
    "text": "is not exactly convincing that\nthere's no pleural effusion.",
    "start": "3740330",
    "end": "3746300"
  },
  {
    "text": "And here's another example. There is no relevant change,\ntracheostomy tube in place,",
    "start": "3746300",
    "end": "3752220"
  },
  {
    "text": "so that roughly is\nshowing a little too wide. But it's showing roughly where\na tracheostomy tube might be.",
    "start": "3752220",
    "end": "3759630"
  },
  {
    "text": " Bilateral pleural effusion\nand compressive atelectasis.",
    "start": "3759630",
    "end": "3767305"
  },
  {
    "text": "Atelectasis is when your\nlung tissues stick together. And so that does often happen\nin the lower part of the lung.",
    "start": "3767305",
    "end": "3774920"
  },
  {
    "text": "And again, the negative\nshows you everything that's not part of the action.",
    "start": "3774920",
    "end": "3782099"
  },
  {
    "text": "Yeah? AUDIENCE: [INAUDIBLE]. ",
    "start": "3782100",
    "end": "3788060"
  },
  {
    "text": "PROFESSOR: Yes. AUDIENCE: [INAUDIBLE] PROFESSOR: No.",
    "start": "3788060",
    "end": "3793500"
  },
  {
    "text": "It's trying to predict\nthe whole model-- the whole node. AUDIENCE: And it's not easier to\nhave, like, one node for, like,",
    "start": "3793500",
    "end": "3799080"
  },
  {
    "text": "each [INAUDIBLE]? PROFESSOR: Yeah. But these guys were ambitious. You know, they-- what was it?",
    "start": "3799080",
    "end": "3808050"
  },
  {
    "text": "Jeff Hinton said a few\nyears ago that he wouldn't want his children to\nbecome radiologists",
    "start": "3808050",
    "end": "3813690"
  },
  {
    "text": "because that field is going\nto be replaced by computers. I think that was a stupid\nthing to say, especially",
    "start": "3813690",
    "end": "3820650"
  },
  {
    "text": "when you look at the\nstate of the art of how well these things work. But if that were true,\nthen you would, in fact,",
    "start": "3820650",
    "end": "3827520"
  },
  {
    "text": "want something that is able\nto produce an entire radiology report. So the motivation is there.",
    "start": "3827520",
    "end": "3833760"
  },
  {
    "text": "Now, after this\nwork was done, we ran into this interesting paper\nfrom Northeastern, which says--",
    "start": "3833760",
    "end": "3842020"
  },
  {
    "text": "but listen guys-- attention\nis not explanation. OK.",
    "start": "3842020",
    "end": "3847750"
  },
  {
    "text": "So attention is\nclearly a mechanism that's very useful in all kinds\nof machine learning methods.",
    "start": "3847750",
    "end": "3856640"
  },
  {
    "text": "But you shouldn't confuse\nit with an explanation. So they say, well, assumption--\nit's the assumption",
    "start": "3856640",
    "end": "3864160"
  },
  {
    "text": "that the input units are\naccorded high attention-- that are accorded high\nattention weights are",
    "start": "3864160",
    "end": "3869829"
  },
  {
    "text": "responsible for\nthe model outputs. And that may not be true. And so what they did is they\ndid a bunch of experiments",
    "start": "3869830",
    "end": "3877540"
  },
  {
    "text": "where they studied\nthe correlation between the attention weights\nand the gradients of the model",
    "start": "3877540",
    "end": "3888820"
  },
  {
    "text": "parameters to see whether,\nin fact, the words that had high attention\nwere the ones that",
    "start": "3888820",
    "end": "3896410"
  },
  {
    "text": "were most decisive in making\na decision in the model. And they found that the\nevidence that correlation",
    "start": "3896410",
    "end": "3904700"
  },
  {
    "text": "between intuitive feature\nimportance measures, including gradient and feature\nerasure approaches-- so this",
    "start": "3904700",
    "end": "3911359"
  },
  {
    "text": "is ablation studies and learn\ndetention weights is weak. And so they did a\nbunch of experiments.",
    "start": "3911360",
    "end": "3917930"
  },
  {
    "text": "There are a lot of controversies\nabout this particular study. But what you find is that if\nyou calculate the concordance,",
    "start": "3917930",
    "end": "3927800"
  },
  {
    "text": "you know, on different data\nsets using different models, you see that, for example, the\nconcordance is not very high.",
    "start": "3927800",
    "end": "3937080"
  },
  {
    "text": "It's less than a half\nfor this data set. And you know, some\nof it below 0,",
    "start": "3937080",
    "end": "3946000"
  },
  {
    "text": "so the opposite\nfor this data set.  Interestingly,\nthings like diabetes,",
    "start": "3946000",
    "end": "3955690"
  },
  {
    "text": "which come from the mimic\ndata, have narrower bounds than some of the others.",
    "start": "3955690",
    "end": "3961099"
  },
  {
    "text": "So they seem to have a more\ndefinitive conclusion, at least for the study.",
    "start": "3961100",
    "end": "3966415"
  },
  {
    "text": " OK.",
    "start": "3966415",
    "end": "3972450"
  },
  {
    "text": "Let me finish off by talking\nabout the opposite idea.",
    "start": "3972450",
    "end": "3977460"
  },
  {
    "text": "So rather than building\na complicated model and then trying to\nexplain it in simple ways,",
    "start": "3977460",
    "end": "3983099"
  },
  {
    "text": "what if we just\nbuilt a simple model? And Cynthia Rudin,\nwho's now at Duke,",
    "start": "3983100",
    "end": "3989190"
  },
  {
    "text": "used to be at the\nSloan School at MIT, has been championing\nthis idea for many years.",
    "start": "3989190",
    "end": "3995890"
  },
  {
    "text": "And so she has come up with\na bunch of different ideas for how to build\nsimple models that",
    "start": "3995890",
    "end": "4002890"
  },
  {
    "text": "trade off maybe a little\nbit of accuracy in order to be explainable. And one of her favorites is\nthis thing called a falling rule",
    "start": "4002890",
    "end": "4011780"
  },
  {
    "text": "list. So this is an example for a\nmammographic mass data set.",
    "start": "4011780",
    "end": "4019130"
  },
  {
    "text": "So it says, if some lump\nhas an irregular shape",
    "start": "4019130",
    "end": "4025339"
  },
  {
    "text": "and the patient is\nover 60 years old, then there's an 85%\nchance of malignancy risk,",
    "start": "4025340",
    "end": "4033050"
  },
  {
    "text": "and there are 230 cases\nin which that happened. ",
    "start": "4033050",
    "end": "4039450"
  },
  {
    "text": "If this is not the case,\nthen if the lump has the speculated margin--",
    "start": "4039450",
    "end": "4045270"
  },
  {
    "text": "so it has little spikes\ncoming out of it-- and the patient is\nover 45, then there's",
    "start": "4045270",
    "end": "4051900"
  },
  {
    "text": "a 78% chance of malignancy. And otherwise, if the margin is\nkind of fuzzy, the edge of it",
    "start": "4051900",
    "end": "4058770"
  },
  {
    "text": "is kind of fuzzy, and\nthe patient is over 60, then there's a 69% chance.",
    "start": "4058770",
    "end": "4066340"
  },
  {
    "text": "And if it has an\nirregular shape, then there's a 63% chance.",
    "start": "4066340",
    "end": "4071590"
  },
  {
    "text": "And if it's lobular and\nthe density is high, then there's a 39% chance.",
    "start": "4071590",
    "end": "4078010"
  },
  {
    "text": "And if it's round and\nthe patient is over 60, then there's a 26% chance.",
    "start": "4078010",
    "end": "4083520"
  },
  {
    "text": "Otherwise, there's a 10% chance. And the argument is that that\ndescription of the model,",
    "start": "4083520",
    "end": "4093420"
  },
  {
    "text": "of the decision-making\nmodel, is simple enough that even doctors\ncan understand it.",
    "start": "4093420",
    "end": "4100615"
  },
  {
    "text": "You're supposed to laugh.  Now, there are\nstill some problems.",
    "start": "4100615",
    "end": "4106869"
  },
  {
    "text": "So one of them is--\nnotice some of these are age greater than\n60, age greater than 45,",
    "start": "4106870",
    "end": "4113100"
  },
  {
    "text": "age greater than 60. It's not quite obvious what\ncategories that's defining.",
    "start": "4113100",
    "end": "4119460"
  },
  {
    "text": "And in principle, it\ncould be different ages in different ones.",
    "start": "4119460",
    "end": "4124620"
  },
  {
    "text": "But here's how they build it. So this is a very\nsimple model that's built by a very\ncomplicated process.",
    "start": "4124620",
    "end": "4132609"
  },
  {
    "text": "So the simple model is the\none I've just showed you. There's a Bayesian approach, a\nBayesian generative approach,",
    "start": "4132609",
    "end": "4139299"
  },
  {
    "text": "where they have a bunch of hyper\nparameters, falling rule list parameters, theta--",
    "start": "4139300",
    "end": "4144939"
  },
  {
    "text": "they calculate a\nlikelihood, which is given a particular\ntheta, how likely",
    "start": "4144939",
    "end": "4150099"
  },
  {
    "text": "are you to get the answers that\nare actually in your data given the model that you generate?",
    "start": "4150100",
    "end": "4157449"
  },
  {
    "text": "And they start with a\npossible set of if clauses. So they do frequent\nclause mining",
    "start": "4157450",
    "end": "4165039"
  },
  {
    "text": "to say what conditions,\nwhat binary conditions occur frequently together\nin the database.",
    "start": "4165040",
    "end": "4172551"
  },
  {
    "text": "And those are the\nonly ones they're going to consider\nbecause, of course, the number of possible\nclauses is vast",
    "start": "4172552",
    "end": "4179229"
  },
  {
    "text": "and they don't want to have\nto iterate through those. And then for each set\nof-- for each clause,",
    "start": "4179229",
    "end": "4186960"
  },
  {
    "text": "they calculate a\nrisk score which is generated by a\nprobability distribution",
    "start": "4186960",
    "end": "4196750"
  },
  {
    "text": "under the constraint that the\nrisk score for the next clause",
    "start": "4196750",
    "end": "4202240"
  },
  {
    "text": "is lower or equal to the risk\nscore for the previous clause. ",
    "start": "4202240",
    "end": "4215110"
  },
  {
    "text": "There are lots of details. So there is this frequent\nitemset mining algorithm.",
    "start": "4215110",
    "end": "4220570"
  },
  {
    "text": "It turns out that\nchoosing r sub l to be the logs of\nproducts of real numbers",
    "start": "4220570",
    "end": "4229480"
  },
  {
    "text": "is an important step\nin order to guarantee that monotonicity\nconstraint in a simple way.",
    "start": "4229480",
    "end": "4237460"
  },
  {
    "text": "l, the number of\nclauses, is drawn from a Poisson distribution. And you give it a\nkind of scale that",
    "start": "4237460",
    "end": "4244540"
  },
  {
    "text": "says roughly how many\nclauses would you be willing to tolerate in\nyour following rule list?",
    "start": "4244540",
    "end": "4254349"
  },
  {
    "text": "And then there's a lot\nof computational hair where they do--",
    "start": "4254350",
    "end": "4260350"
  },
  {
    "text": "they get mean a posteriori\nprobability estimation by using a simulated\nannealing algorithm.",
    "start": "4260350",
    "end": "4268600"
  },
  {
    "text": "So they basically\ngenerate some clauses and then they use swap, replace,\nadd, and delete operators",
    "start": "4268600",
    "end": "4277930"
  },
  {
    "text": "in order to try\ndifferent variations. And they're doing hill\nclimbing in that space.",
    "start": "4277930",
    "end": "4284599"
  },
  {
    "text": "There's also some\nGibbs sampling, because once you have\none of these models, simply calculating how accurate\nit is is not straightforward.",
    "start": "4284600",
    "end": "4294060"
  },
  {
    "text": "There's not a closed\nform way of doing it. And so they're doing sampling in\norder to try to generate that.",
    "start": "4294060",
    "end": "4300730"
  },
  {
    "text": "So it's a bunch of hair. And again, the paper\ndescribes it all.",
    "start": "4300730",
    "end": "4305870"
  },
  {
    "text": "But what's interesting is\nthat on a 30 day hospital readmission data set with\nabout 8,000 patients,",
    "start": "4305870",
    "end": "4315030"
  },
  {
    "text": "they used about 34 features,\nlike impaired mental status, difficult behavior, chronic\npain, feels unsafe, et cetera.",
    "start": "4315030",
    "end": "4324540"
  },
  {
    "text": "They mind rules or clauses\nwith support more than 5% of the database and no\nmore than two conditions.",
    "start": "4324540",
    "end": "4333150"
  },
  {
    "text": "They set the expected\nlength of the decision list to be eight clauses.",
    "start": "4333150",
    "end": "4338820"
  },
  {
    "text": "And then they compared\nthe decision model they got to SVM's random\nforce logistic regression",
    "start": "4338820",
    "end": "4345600"
  },
  {
    "text": "cart and an inductive\nlogic programming approach. And shockingly to\nme, their method--",
    "start": "4345600",
    "end": "4353410"
  },
  {
    "text": "the following rule list method-- got an AUC of about 0.8, whereas\nall the others did like 0.79,",
    "start": "4353410",
    "end": "4361830"
  },
  {
    "text": "0.75 logistic\nregression, as usual",
    "start": "4361830",
    "end": "4367410"
  },
  {
    "text": "outperformed the one\nthey got slightly. Right? But this is interesting,\nbecause their argument",
    "start": "4367410",
    "end": "4374160"
  },
  {
    "text": "is that this\nrepresentation of the model is much more easy to understand\nthan even a logistic regression",
    "start": "4374160",
    "end": "4382470"
  },
  {
    "text": "model for most human users. And also, if you look at--",
    "start": "4382470",
    "end": "4389700"
  },
  {
    "text": "these are just various runs\nand the different models. And their model has a\npretty decent AUC up here.",
    "start": "4389700",
    "end": "4398610"
  },
  {
    "text": "I think the green one is\nthe logistic regression one. And it's slightly better because\nit outperforms their best model",
    "start": "4398610",
    "end": "4408870"
  },
  {
    "text": "in the region of low false\npositive rates, which may be where you want to operate.",
    "start": "4408870",
    "end": "4414480"
  },
  {
    "text": "So that may actually\nbe a better model. ",
    "start": "4414480",
    "end": "4422250"
  },
  {
    "text": "So here's their\nreadmission rule list. And it says if the\npatient has bed sores",
    "start": "4422250",
    "end": "4429190"
  },
  {
    "text": "and has a history of not\nshowing up for appointments, then there's a 33%\nprobability that they'll",
    "start": "4429190",
    "end": "4435910"
  },
  {
    "text": "be readmitted within 30 days. If-- I think some note says\npoor prognosis and maximum care,",
    "start": "4435910",
    "end": "4444820"
  },
  {
    "text": "et cetera. So this is the result\nthat they came up with. Now, by the way, we've talked\na little bit about 30 day",
    "start": "4444820",
    "end": "4452650"
  },
  {
    "text": "readmission predictions. And getting over about 70%\nis not bad in that domain",
    "start": "4452650",
    "end": "4461360"
  },
  {
    "text": "because it's just not that\neasily predictable who's going to wind up back in\nthe hospital within 30 days.",
    "start": "4461360",
    "end": "4468060"
  },
  {
    "text": "So these models are\nactually doing quite well, and certainly understandable\nin these terms.",
    "start": "4468060",
    "end": "4475739"
  },
  {
    "text": "They also tried on a\nvariety of University of California-Irvine\nmachine learning data sets.",
    "start": "4475740",
    "end": "4484470"
  },
  {
    "text": "These are just random\npublic data sets. And they tried building\nthese falling rule",
    "start": "4484470",
    "end": "4489987"
  },
  {
    "text": "list models to make predictions. And what you see is that\nthe AUCs are pretty good.",
    "start": "4489987",
    "end": "4496130"
  },
  {
    "text": "So on the spam\ndetection data set, their system gets about 91.",
    "start": "4496130",
    "end": "4502820"
  },
  {
    "text": "Logistic regression,\nagain, gets 97. So you know, part of the\nunfortunate lesson that we",
    "start": "4502820",
    "end": "4511010"
  },
  {
    "text": "teach in almost every\nexample in this class is that simple models\nlike logistic regression",
    "start": "4511010",
    "end": "4517550"
  },
  {
    "text": "often do quite well. But remember, here they're\noptimizing for explainability",
    "start": "4517550",
    "end": "4523040"
  },
  {
    "text": "rather than for getting\nthe right answer. So they're willing to sacrifice\nsome accuracy in their model",
    "start": "4523040",
    "end": "4532310"
  },
  {
    "text": "in order to develop\na result that is easy to explain to people.",
    "start": "4532310",
    "end": "4537590"
  },
  {
    "text": "So again, there are many\nvariations on this type of work where people have different\nnotions of what counts",
    "start": "4537590",
    "end": "4544909"
  },
  {
    "text": "as a simple, explainable model. But that's a very\ndifferent approach",
    "start": "4544910",
    "end": "4551020"
  },
  {
    "text": "than the LIME approach, which\nsays build the hairy model and then produce local\nexplanations for why",
    "start": "4551020",
    "end": "4560020"
  },
  {
    "text": "it makes certain decisions\non particular cases. All right. I think that's all I'm going\nto say about explainability.",
    "start": "4560020",
    "end": "4568150"
  },
  {
    "text": "This is a very hot\ntopic at the moment, and so there are lots of papers. I think there's-- I just\nsaw a call for a conference",
    "start": "4568150",
    "end": "4574719"
  },
  {
    "text": "on explainable machine\nlearning models. So there's more and\nmore work in this area.",
    "start": "4574720",
    "end": "4583550"
  },
  {
    "text": "So with that, we come to\nthe end of our course. And I just wanted--",
    "start": "4583550",
    "end": "4589300"
  },
  {
    "text": "I just went through the front\npage of the course website",
    "start": "4589300",
    "end": "4595119"
  },
  {
    "text": "and listed all the topics. So we've covered quite\na lot of stuff, right?",
    "start": "4595120",
    "end": "4601670"
  },
  {
    "text": "You know, what makes\nhealth care different? And we talked about what\nclinical care is all about",
    "start": "4601670",
    "end": "4608510"
  },
  {
    "text": "and what clinical data is\nlike and risk stratification, survival modeling,\nphysiological time series, how",
    "start": "4608510",
    "end": "4616969"
  },
  {
    "text": "to interpret clinical text\nin a couple of lectures, translating technology\ninto the clinic.",
    "start": "4616970",
    "end": "4623239"
  },
  {
    "text": "The italicized ones\nwere guest lectures, so machine learning for\ncardiology and machine",
    "start": "4623240",
    "end": "4628580"
  },
  {
    "text": "learning for\ndifferential diagnosis, machine learning for\npathology, for mammography.",
    "start": "4628580",
    "end": "4634730"
  },
  {
    "text": "David gave a couple of\nlectures on causal inference and reinforcement learning\nwhere David and a guest--",
    "start": "4634730",
    "end": "4641270"
  },
  {
    "text": "which I didn't note here-- disease progression\nand sub typing.",
    "start": "4641270",
    "end": "4647030"
  },
  {
    "text": "We talked about\nprecision medicine and the role of genetics,\nautomated clinical workflows,",
    "start": "4647030",
    "end": "4653270"
  },
  {
    "text": "the lecture on regulation,\nand then recently fairness, robustness to data set\nshift, and interpretability.",
    "start": "4653270",
    "end": "4660800"
  },
  {
    "text": "So that's quite a lot. I think we're-- we the staff are\npretty happy with how the class",
    "start": "4660800",
    "end": "4668810"
  },
  {
    "text": "has gone. It was our first time as\nthis crew teaching it. And we hope to do it again.",
    "start": "4668810",
    "end": "4676910"
  },
  {
    "text": "I can't stop without giving\nan immense vote of gratitude",
    "start": "4676910",
    "end": "4683150"
  },
  {
    "text": "to Irene and Willy,\nwithout whom we would have been totally sunk.",
    "start": "4683150",
    "end": "4688976"
  },
  {
    "text": "[APPLAUSE] ",
    "start": "4688976",
    "end": "4696060"
  },
  {
    "text": "And I also want to acknowledge\nDavid's vision in putting this course together. He taught a sort of half-size\nversion of a class like this",
    "start": "4696060",
    "end": "4705750"
  },
  {
    "text": "a couple of years\nago and thought that it would be a good idea to\nexpand it into a full semester",
    "start": "4705750",
    "end": "4711330"
  },
  {
    "text": "regular course and got me\non board to work with him.",
    "start": "4711330",
    "end": "4716610"
  },
  {
    "text": "And I want to thank you\nall for your hard work. And I'm looking forward to--",
    "start": "4716610",
    "end": "4722000"
  }
]
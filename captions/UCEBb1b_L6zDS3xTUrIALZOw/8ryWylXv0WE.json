[
  {
    "start": "5130",
    "end": "5130"
  },
  {
    "text": "In this video we will compare\nall the different methods",
    "start": "5130",
    "end": "7990"
  },
  {
    "text": "we have seen so far in\nthis course and review what",
    "start": "7990",
    "end": "10799"
  },
  {
    "text": "they are used for, their\nbenefits, and limitations.",
    "start": "10800",
    "end": "15040"
  },
  {
    "text": "Linear regression is used to\npredict a continuous outcome.",
    "start": "15040",
    "end": "18869"
  },
  {
    "text": "Linear regression is\nsimple and commonly used,",
    "start": "18870",
    "end": "21530"
  },
  {
    "text": "and it works on small\nand large data sets.",
    "start": "21530",
    "end": "24380"
  },
  {
    "text": "The downside is that it\nassumes a linear relationship.",
    "start": "24380",
    "end": "28130"
  },
  {
    "text": "If we have a nonlinear\nrelationship,",
    "start": "28130",
    "end": "30220"
  },
  {
    "text": "we need to add variables\nto our analysis.",
    "start": "30220",
    "end": "33170"
  },
  {
    "text": "For instance, suppose y =\na*log(X)+b, where x is data,",
    "start": "33170",
    "end": "38390"
  },
  {
    "text": "and y is what we\nneed to predict.",
    "start": "38390",
    "end": "40660"
  },
  {
    "text": "To be able to find the\ncoefficients a and b",
    "start": "40660",
    "end": "43270"
  },
  {
    "text": "through linear\nregression, we need",
    "start": "43270",
    "end": "45070"
  },
  {
    "text": "to view log(X) as\na new variable.",
    "start": "45070",
    "end": "47989"
  },
  {
    "text": "Remember that we did this in\nthe Google homework problem.",
    "start": "47990",
    "end": "52500"
  },
  {
    "text": "Logistic regression is used to\npredict a categorical outcome.",
    "start": "52500",
    "end": "56450"
  },
  {
    "text": "We mainly focused on binary\noutcomes, like yes or no,",
    "start": "56450",
    "end": "60470"
  },
  {
    "text": "sell or buy, accept\nor reject, and so on.",
    "start": "60470",
    "end": "64809"
  },
  {
    "text": "We have seen it applied to\npredict the quality of care,",
    "start": "64810",
    "end": "68009"
  },
  {
    "text": "good or bad; the winner of\nthe US presidential election,",
    "start": "68010",
    "end": "71930"
  },
  {
    "text": "Republican or Democrat; parole\nviolation and loan payment, yes",
    "start": "71930",
    "end": "76030"
  },
  {
    "text": "or no.",
    "start": "76030",
    "end": "77400"
  },
  {
    "text": "In addition to its\nrelative simplicity,",
    "start": "77400",
    "end": "79789"
  },
  {
    "text": "logistic regression\ncomputes probabilities",
    "start": "79789",
    "end": "82200"
  },
  {
    "text": "that can be used to assess the\nconfidence of our prediction.",
    "start": "82200",
    "end": "85850"
  },
  {
    "text": "The downside is again similar\nto that of linear regression.",
    "start": "85850",
    "end": "90299"
  },
  {
    "text": "In the trees week\nwe learned CART,",
    "start": "90300",
    "end": "92370"
  },
  {
    "text": "which is used to predict\na categorical outcome,",
    "start": "92370",
    "end": "94950"
  },
  {
    "text": "with possibly more than two\ncategories, like quality",
    "start": "94950",
    "end": "98000"
  },
  {
    "text": "rating, from one to five,\nand three decisions,",
    "start": "98000",
    "end": "100710"
  },
  {
    "text": "say, buy, sell, or hold.",
    "start": "100710",
    "end": "102909"
  },
  {
    "text": "It can also predict\na continuous outcome,",
    "start": "102910",
    "end": "105620"
  },
  {
    "text": "such as salary or price.",
    "start": "105620",
    "end": "108090"
  },
  {
    "text": "We have seen it\napplied to predict",
    "start": "108090",
    "end": "109729"
  },
  {
    "text": "life expectancy, earnings\nfrom census data,",
    "start": "109729",
    "end": "113000"
  },
  {
    "text": "and letter recognition.",
    "start": "113000",
    "end": "115370"
  },
  {
    "text": "The power of CART\nlies in the fact",
    "start": "115370",
    "end": "117320"
  },
  {
    "text": "that it can handle\nnonlinear relationships",
    "start": "117320",
    "end": "119560"
  },
  {
    "text": "between variables.",
    "start": "119560",
    "end": "121220"
  },
  {
    "text": "The tree representation makes it\neasy to visualize and interpret",
    "start": "121220",
    "end": "124960"
  },
  {
    "text": "the results.",
    "start": "124960",
    "end": "126260"
  },
  {
    "text": "The downside is\nthat CART may not",
    "start": "126260",
    "end": "128369"
  },
  {
    "text": "work very well on\nsmall data sets.",
    "start": "128370",
    "end": "131819"
  },
  {
    "text": "Random forest is\nalso used to predict",
    "start": "131820",
    "end": "134190"
  },
  {
    "text": "categorical outcomes\nor continuous outcomes.",
    "start": "134190",
    "end": "137550"
  },
  {
    "text": "Its benefit over CART is that\nit can improve the prediction",
    "start": "137550",
    "end": "140880"
  },
  {
    "text": "accuracy.",
    "start": "140880",
    "end": "142090"
  },
  {
    "text": "However, we need to\nadjust many parameters",
    "start": "142090",
    "end": "144440"
  },
  {
    "text": "and it's not as easy\nto explain as CART",
    "start": "144440",
    "end": "148079"
  },
  {
    "text": "This week, we learned\nhierarchical clustering,",
    "start": "148079",
    "end": "150860"
  },
  {
    "text": "which is used to\nfind similar groups.",
    "start": "150860",
    "end": "153520"
  },
  {
    "text": "An important aspect\nof clustering data",
    "start": "153520",
    "end": "155900"
  },
  {
    "text": "into smaller groups is that\nwe can improve our prediction",
    "start": "155900",
    "end": "158730"
  },
  {
    "text": "accuracy by applying\nour predictive methods,",
    "start": "158730",
    "end": "161720"
  },
  {
    "text": "like logistic regression for\ninstance, on each cluster.",
    "start": "161720",
    "end": "165730"
  },
  {
    "text": "We expand on this\ncluster-then-predict idea",
    "start": "165730",
    "end": "168720"
  },
  {
    "text": "in one of our homework problems.",
    "start": "168720",
    "end": "171450"
  },
  {
    "text": "Hierarchical clustering is\nan attractive technique,",
    "start": "171450",
    "end": "174329"
  },
  {
    "text": "because we do not need to\nselect the number of clusters",
    "start": "174329",
    "end": "177060"
  },
  {
    "text": "before running the algorithm.",
    "start": "177060",
    "end": "179110"
  },
  {
    "text": "Also, we can visualize the\nclusters using a dendrogram.",
    "start": "179110",
    "end": "182930"
  },
  {
    "text": "The drawback though, is\nthat hierarchical clustering",
    "start": "182930",
    "end": "185680"
  },
  {
    "text": "is hard to use on\nlarge data sets,",
    "start": "185680",
    "end": "187890"
  },
  {
    "text": "because of the pairwise\ndistance calculation,",
    "start": "187890",
    "end": "190569"
  },
  {
    "text": "as we saw in this recitation.",
    "start": "190570",
    "end": "193320"
  },
  {
    "text": "An alternative method\nis k-means clustering,",
    "start": "193320",
    "end": "196110"
  },
  {
    "text": "which works well on\ndata sets of any size.",
    "start": "196110",
    "end": "199180"
  },
  {
    "text": "However, k-means\nrequires selecting",
    "start": "199180",
    "end": "201200"
  },
  {
    "text": "the number of clusters\nbefore running the algorithm.",
    "start": "201200",
    "end": "204900"
  },
  {
    "text": "This may not be a\nlimitation if we",
    "start": "204900",
    "end": "206909"
  },
  {
    "text": "have an intuition of the number\nof clusters we want to look at,",
    "start": "206910",
    "end": "210410"
  },
  {
    "text": "as in the medical image\nsegmentation example.",
    "start": "210410",
    "end": "214570"
  },
  {
    "text": "I hope that this quick review\ngave you a good refresher",
    "start": "214570",
    "end": "217310"
  },
  {
    "text": "before the competition week.",
    "start": "217310",
    "end": "219110"
  },
  {
    "text": "Good luck.",
    "start": "219110",
    "end": "221020"
  }
]
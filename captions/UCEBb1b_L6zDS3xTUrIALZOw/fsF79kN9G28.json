[
  {
    "start": "0",
    "end": "0"
  },
  {
    "start": "4500",
    "end": "4500"
  },
  {
    "text": "Let us discuss the performance\nof a benchmark algorithm.",
    "start": "4500",
    "end": "6990"
  },
  {
    "text": "The Random Forest\nalgorithm is known",
    "start": "6990",
    "end": "9250"
  },
  {
    "text": "for its attractive property of\ndetecting variable interactions",
    "start": "9250",
    "end": "12690"
  },
  {
    "text": "and excellent performance\nas a learning algorithm.",
    "start": "12690",
    "end": "15809"
  },
  {
    "text": "For the decision, we're\nselecting the Random Forest",
    "start": "15810",
    "end": "17940"
  },
  {
    "text": "algorithm as a\nbenchmark-- initially,",
    "start": "17940",
    "end": "19990"
  },
  {
    "text": "we randomly partitioned\nthe full data",
    "start": "19990",
    "end": "21890"
  },
  {
    "text": "set into two separate parts,\nwhere the split was 50-50,",
    "start": "21890",
    "end": "25900"
  },
  {
    "text": "and the partitioning was done\nevenly within each cost bin.",
    "start": "25900",
    "end": "29750"
  },
  {
    "text": "The first part,\nthe training set,",
    "start": "29750",
    "end": "31380"
  },
  {
    "text": "was used to develop the method.",
    "start": "31380",
    "end": "33829"
  },
  {
    "text": "The second part,\nthe test set, was",
    "start": "33830",
    "end": "36400"
  },
  {
    "text": "used to evaluate the\nmodel's performance.",
    "start": "36400",
    "end": "39020"
  },
  {
    "text": "The table in this slide\nreports the accuracy",
    "start": "39020",
    "end": "43290"
  },
  {
    "text": "of the Random Forest algorithm\non each of the three buckets.",
    "start": "43290",
    "end": "49330"
  },
  {
    "start": "47000",
    "end": "47000"
  },
  {
    "text": "Let us now introduce\nthe idea of clustering.",
    "start": "49330",
    "end": "52170"
  },
  {
    "text": "Patients in each bucket may\nhave different characteristics.",
    "start": "52170",
    "end": "55739"
  },
  {
    "text": "For this reason, we create\nclusters for each cost bucket",
    "start": "55740",
    "end": "60190"
  },
  {
    "text": "and make predictions for each\ncluster using the Random Forest",
    "start": "60190",
    "end": "63860"
  },
  {
    "text": "algorithm.",
    "start": "63860",
    "end": "64360"
  },
  {
    "text": "Clustering is mostly used in\nthe absence of a target variable",
    "start": "66990",
    "end": "71030"
  },
  {
    "text": "to search for relationships\namong input variables",
    "start": "71030",
    "end": "73970"
  },
  {
    "text": "or to organize data\ninto meaningful groups.",
    "start": "73970",
    "end": "77080"
  },
  {
    "text": "In this study, although\nthe target variable",
    "start": "77080",
    "end": "79450"
  },
  {
    "text": "is well-defined as a heart\nattack or not a heart attack,",
    "start": "79450",
    "end": "82500"
  },
  {
    "text": "there are many\ndifferent trajectories",
    "start": "82500",
    "end": "85160"
  },
  {
    "text": "that are associated\nwith the target.",
    "start": "85160",
    "end": "87780"
  },
  {
    "text": "There's not one set\npattern of health",
    "start": "87780",
    "end": "92100"
  },
  {
    "text": "or diagnostic combination that\nleads a person to heart attack.",
    "start": "92100",
    "end": "95530"
  },
  {
    "text": "Instead, we'll\nshow that there are",
    "start": "95530",
    "end": "97690"
  },
  {
    "text": "many different dynamic health\npatterns and time series",
    "start": "97690",
    "end": "101360"
  },
  {
    "text": "diagnostic relations\npreceding a heart attack.",
    "start": "101360",
    "end": "104300"
  },
  {
    "start": "106000",
    "end": "106000"
  },
  {
    "text": "The clustering\nmethods were used were",
    "start": "107440",
    "end": "109650"
  },
  {
    "text": "spectral clustering\nand k-means clustering.",
    "start": "109650",
    "end": "112740"
  },
  {
    "text": "We focus, in the lecture,\non the k-means clustering.",
    "start": "112740",
    "end": "117549"
  },
  {
    "text": "The broad description of\nthe algorithm is as follows.",
    "start": "117550",
    "end": "122580"
  },
  {
    "text": "We first specify the\nnumber of clusters k.",
    "start": "122580",
    "end": "128500"
  },
  {
    "text": "Then we randomly assign each\ndata point to a cluster.",
    "start": "128500",
    "end": "134780"
  },
  {
    "text": "We then compute the\ncluster centroids.",
    "start": "134780",
    "end": "137920"
  },
  {
    "text": "We re-assign each point to\nthe closest cluster centroid.",
    "start": "137920",
    "end": "142599"
  },
  {
    "text": "We then re-compute\nthe cluster centroids,",
    "start": "142600",
    "end": "145180"
  },
  {
    "text": "and we repeat steps 4 and 5\nuntil no improvement is made.",
    "start": "145180",
    "end": "149590"
  },
  {
    "start": "151000",
    "end": "151000"
  },
  {
    "text": "Let us illustrate the\nk-means algorithm in action.",
    "start": "152560",
    "end": "158030"
  },
  {
    "text": "We specify the desired\nnumber of clusters k.",
    "start": "158030",
    "end": "162560"
  },
  {
    "text": "In this case, we use k=2.",
    "start": "162560",
    "end": "164640"
  },
  {
    "text": "We then randomly assign each\ndata point to a cluster.",
    "start": "168840",
    "end": "173800"
  },
  {
    "text": "In this case, we have\nthe three points in red,",
    "start": "177100",
    "end": "180940"
  },
  {
    "text": "and the two points in black.",
    "start": "180940",
    "end": "184380"
  },
  {
    "text": "We then compute the\ncluster centroids,",
    "start": "184380",
    "end": "188400"
  },
  {
    "text": "indicated by the red\nx and the grey x.",
    "start": "188400",
    "end": "192879"
  },
  {
    "text": "We re-assign each point to\nthe closest cluster centroid,",
    "start": "192880",
    "end": "199120"
  },
  {
    "text": "and now you observe that\nthis point changes from a red",
    "start": "199120",
    "end": "204540"
  },
  {
    "text": "to a grey.",
    "start": "204540",
    "end": "206900"
  },
  {
    "text": "We re-compute the\ncluster centroids,",
    "start": "206900",
    "end": "214129"
  },
  {
    "text": "and we repeat the\nprevious steps, 4 and 5",
    "start": "214130",
    "end": "220090"
  },
  {
    "text": "until no improvement is made.",
    "start": "220090",
    "end": "221849"
  },
  {
    "text": "We observe that, in this case,\nthe k-means clustering is done,",
    "start": "221850",
    "end": "226579"
  },
  {
    "text": "and this is our\nfinal clustering.",
    "start": "226579",
    "end": "228209"
  },
  {
    "start": "232000",
    "end": "232000"
  },
  {
    "text": "Let us discuss some\npractical considerations.",
    "start": "233920",
    "end": "236690"
  },
  {
    "text": "The number of clusters\nk can be selected",
    "start": "236690",
    "end": "238790"
  },
  {
    "text": "from previous knowledge or\nby simply experimenting.",
    "start": "238790",
    "end": "242069"
  },
  {
    "text": "We can strategically select\ninitial partition of points",
    "start": "242070",
    "end": "245570"
  },
  {
    "text": "into clusters if we have\nsome knowledge of the data.",
    "start": "245570",
    "end": "249910"
  },
  {
    "text": "We can also run the\nalgorithm several times",
    "start": "249910",
    "end": "252660"
  },
  {
    "text": "with different random\nstarting points.",
    "start": "252660",
    "end": "255000"
  },
  {
    "text": "In the recitations,\nwe'll learn how",
    "start": "255000",
    "end": "257560"
  },
  {
    "text": "to run the k-means\nalgorithm in R.",
    "start": "257560",
    "end": "264120"
  },
  {
    "start": "261000",
    "end": "261000"
  },
  {
    "text": "So how do we\nmeasure performance?",
    "start": "264120",
    "end": "266979"
  },
  {
    "text": "After we construct the\nclusters in the training set,",
    "start": "266980",
    "end": "269830"
  },
  {
    "text": "we assign new observations\nto clusters by proximity",
    "start": "269830",
    "end": "273389"
  },
  {
    "text": "to the centroid of each cluster.",
    "start": "273390",
    "end": "275190"
  },
  {
    "text": "We measure performance\nby recording",
    "start": "277860",
    "end": "280729"
  },
  {
    "text": "the average performance\nrate in each cluster.",
    "start": "280730",
    "end": "283240"
  },
  {
    "text": "Let us now discuss the\nperformance of the clustering",
    "start": "287120",
    "end": "289290"
  },
  {
    "text": "methods.",
    "start": "289290",
    "end": "289790"
  },
  {
    "text": "We perform clustering on each\nbucket using k=10 clusters.",
    "start": "293070",
    "end": "298150"
  },
  {
    "text": "In the table we record\nthe average prediction",
    "start": "298150",
    "end": "303650"
  },
  {
    "text": "rate of each cost bucket.",
    "start": "303650",
    "end": "306699"
  },
  {
    "text": "We observe a very\nvisible improvement",
    "start": "306700",
    "end": "310550"
  },
  {
    "text": "when we use clustering-- from\n49% to 64%, from 56% to 73%,",
    "start": "310550",
    "end": "317800"
  },
  {
    "text": "from 58% to 78%.",
    "start": "317800",
    "end": "320889"
  }
]
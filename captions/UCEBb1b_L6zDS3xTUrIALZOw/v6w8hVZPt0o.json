[
  {
    "text": "[SQUEAKING] [RUSTLING] [CLICKING]",
    "start": "0",
    "end": "5236"
  },
  {
    "text": " ALAN EDELMAN: Today,\nthe plan would be I'm",
    "start": "5236",
    "end": "11440"
  },
  {
    "text": "going to talk a little bit-- I've got this notebook\nfrom last year talking about taking the derivative\nof such matrix quantities",
    "start": "11440",
    "end": "19720"
  },
  {
    "text": "as eigenvalues. And so what's going on\nhere is that we are-- the big story is\northogonal matrices",
    "start": "19720",
    "end": "26169"
  },
  {
    "text": "may play a role if you have\nsymmetric eigenvalue problems. And so we have\nconstrained problems, which is something we haven't\nreally talked about yet.",
    "start": "26170",
    "end": "32930"
  },
  {
    "text": "So we'll talk about\ndifferentiating under constraints a little bit. Then I will use the blackboard.",
    "start": "32930",
    "end": "37960"
  },
  {
    "text": "And you might remember from\nover a week ago, I think it was, where I was talking\nabout forward",
    "start": "37960",
    "end": "43420"
  },
  {
    "text": "and reverse mode differentiation\non the blackboard. And we made it through\nforward, but we never made it through backwards,\nor reverse mode.",
    "start": "43420",
    "end": "50170"
  },
  {
    "text": "And so the plan is to\nkind of remember where we were and go back and do that. And Steven had the idea\nof, the last 10 minutes--",
    "start": "50170",
    "end": "58120"
  },
  {
    "text": "at the end of class, we'll\ntalk about the things that we haven't talked about. We've already figured out that,\nin principle, this class could",
    "start": "58120",
    "end": "65199"
  },
  {
    "text": "go on for another week or two. But of course, IEP is\ncoming to an end this week.",
    "start": "65200",
    "end": "71050"
  },
  {
    "text": "But there's so much\nmore that we could do. So here, let me just kind\ngo through this a little bit quickly.",
    "start": "71050",
    "end": "76790"
  },
  {
    "text": "So ultimately, I want to think\nabout orthogonal matrices, right? You all know what\northogonal matrices are.",
    "start": "76790",
    "end": "82880"
  },
  {
    "text": "q transpose q is the identity. But to go slowly and\nas a bit of a warm up,",
    "start": "82880",
    "end": "88850"
  },
  {
    "text": "let me just talk about\ndifferentiating on the unit sphere. OK?",
    "start": "88850",
    "end": "93920"
  },
  {
    "text": "So the unit sphere-- right? The sphere is like\na baby version of an orthogonal matrix, right? It's one column of\nan orthogonal matrix.",
    "start": "93920",
    "end": "100800"
  },
  {
    "text": "So let's talk about\nbeing on the sphere. OK? And just as a reminder,\nif you are restricted--",
    "start": "100800",
    "end": "111510"
  },
  {
    "text": "[BARK] Philly, what's going on? There's something\nabout the sunbeams. He likes the-- oh, it's\nsomebody's reflection.",
    "start": "111510",
    "end": "118850"
  },
  {
    "text": "Is it mine? Or somebody is\nreflecting their phone. And Philip is going to chase it. [CHUCKLES] He-- he's\nreally part cat somewhere",
    "start": "118850",
    "end": "133360"
  },
  {
    "text": "genetically or something. Yeah, he will chase it. [CHUCKLING] OK.",
    "start": "133360",
    "end": "138640"
  },
  {
    "text": "Thanks for-- all right. Where was I? Yes. So you all know that if\nyou move along on a circle,",
    "start": "138640",
    "end": "146440"
  },
  {
    "text": "then tangents on the\ncircle or [? quasar ?] are orthogonal, right? If you think of the vector of\nwhere you are from the center,",
    "start": "146440",
    "end": "153550"
  },
  {
    "text": "right, tangents of\ncourse are orthogonal. And that's true\nin n dimensions-- that if you move around along\na sphere in n dimensions,",
    "start": "153550",
    "end": "161390"
  },
  {
    "text": "your position vector\nis from the origin. And then the velocity\nis always going to be orthogonal or tangent\nto the sphere, right?",
    "start": "161390",
    "end": "168549"
  },
  {
    "text": "And so all of a sudden\nnow, we're talking about-- up until now, derivatives were\nfree to be in any direction,",
    "start": "168550",
    "end": "174910"
  },
  {
    "text": "right? All of our little\ndx's that we've seen-- or da's or whatever\nyou want to call",
    "start": "174910",
    "end": "179920"
  },
  {
    "text": "it-- have always been free to\nbe in any direction you like. But if your point is restricted\nto a surface like the sphere,",
    "start": "179920",
    "end": "188170"
  },
  {
    "text": "then somehow your\ndx is restricted to being tangent to\nthe sphere now, right? It's not in any\ndirection anymore, right?",
    "start": "188170",
    "end": "194890"
  },
  {
    "text": "We're no longer interested\nin radial directions because they don't\neven exist, right? We're only interested\nin tangent directions",
    "start": "194890",
    "end": "201470"
  },
  {
    "text": "because they describe movements\non the constrained surface, right? And so we need to figure\nout how to accommodate",
    "start": "201470",
    "end": "206758"
  },
  {
    "text": "these sorts of tangential\ndirections, right? And so here, I'm kind of\njust showing you roughly",
    "start": "206758",
    "end": "218540"
  },
  {
    "text": "what it would look like. By the way, is the\nsun drowning this out? Or is it OK? I'm wondering if this\none should close--",
    "start": "218540",
    "end": "225359"
  },
  {
    "text": "or at least the little-- or partially close. It looks like there's a\nlot of glare from the sun.",
    "start": "225360",
    "end": "231739"
  },
  {
    "text": "I'm happy to see the sun. Don't get me wrong. We'll take as much of\nit as we can get this.",
    "start": "231740",
    "end": "236810"
  },
  {
    "text": "But a little-- yeah, that\nmight be a little bit better. Right. So just to kind of\nshow you how you",
    "start": "236810",
    "end": "242390"
  },
  {
    "text": "construct sort of the right\nkind of dq here, right-- by the way, do\npeople know the trick",
    "start": "242390",
    "end": "248120"
  },
  {
    "text": "for generating a random\nvector on the sphere? So if you-- so the\nquestion is, on the sphere,",
    "start": "248120",
    "end": "257190"
  },
  {
    "text": "you would like to pick a\npoint uniformly, right? \"Uniformly\" means\nthat, no matter how you rotate the sphere,\nhow you're picking it",
    "start": "257190",
    "end": "263870"
  },
  {
    "text": "doesn't matter, right? And the trick to\ndoing that is to take x to be a standard normal.",
    "start": "263870",
    "end": "269930"
  },
  {
    "text": "Like, here, I'm doing it\nin five dimensions, right? So x is a standard normal. And then all you have\nto do is normalize,",
    "start": "269930",
    "end": "277070"
  },
  {
    "text": "which makes it a unit vector. And properties of the\nnormal distribution have it that it's\ninvariant on the rotations.",
    "start": "277070",
    "end": "283670"
  },
  {
    "text": "And so q is invariant\non the sphere, right? And so that's the\nsimplest way to generate a random vector of\nunit one that actually",
    "start": "283670",
    "end": "292130"
  },
  {
    "text": "is uniform on the sphere. If you took Rand, which is-- you wouldn't get\nthe right answer.",
    "start": "292130",
    "end": "297690"
  },
  {
    "text": "It's very special to\ntake Rand n, which is the normal distribution. So q is on the sphere.",
    "start": "297690",
    "end": "305289"
  },
  {
    "text": "And if you take a little dx-- you guys know me by now. I like to type 0.0001,\nsomething like that.",
    "start": "305290",
    "end": "312850"
  },
  {
    "text": "If you take a random\ndirection, of course, it won't be tangential\nto the sphere.",
    "start": "312850",
    "end": "317860"
  },
  {
    "text": "So what I'm doing is\nI'm normalizing it",
    "start": "317860",
    "end": "323259"
  },
  {
    "text": "and subtracting it\nfrom q to kind of see-- so this is a random nearby\npoint from x on the sphere.",
    "start": "323260",
    "end": "331040"
  },
  {
    "text": "And I'm going to see\nits distance from q. And I will observe\nthat q transpose dq is heading towards 0.",
    "start": "331040",
    "end": "337490"
  },
  {
    "text": "OK? So that's basically\nsaying that-- I mean, I hope you\nall see the picture.",
    "start": "337490",
    "end": "342590"
  },
  {
    "text": "But here, let's\ndraw the picture. Maybe that'd be even better. So here's the picture, right?",
    "start": "342590",
    "end": "348100"
  },
  {
    "text": "I've got my q over here. And I've got my q plus dq just\na little bit off from here.",
    "start": "348100",
    "end": "357710"
  },
  {
    "text": "And so this is basically the dq. And what I'm showing you is--",
    "start": "357710",
    "end": "362980"
  },
  {
    "text": "numerically, the things that's\neasy to believe in your mind is that this is a right angle,\nright-- that q transpose",
    "start": "362980",
    "end": "369169"
  },
  {
    "text": "dq is 0, right? So this right angle over\nhere is the same thing as saying q transpose dq is 0.",
    "start": "369170",
    "end": "375979"
  },
  {
    "text": "Any questions about that? That's all pretty\nintuitive, right, that tangents are\northogonal to the radii",
    "start": "375980",
    "end": "383710"
  },
  {
    "text": "no matter what the dimensions? OK? And there's a math way\nof describing this.",
    "start": "383710",
    "end": "390370"
  },
  {
    "text": "You don't just need your\ngeometric intuition to see it. You just do the obvious thing. If you're restricted\nto the sphere,",
    "start": "390370",
    "end": "396490"
  },
  {
    "text": "if x transpose x\nequals 1, then we could take our usual rules\nto differentiate, right?",
    "start": "396490",
    "end": "402010"
  },
  {
    "text": "So if we differentiate,\nwe have dx transpose x plus x transpose dx.",
    "start": "402010",
    "end": "407410"
  },
  {
    "text": "And Steven spent a lot of time\nin the first week reminding you that x transpose dx and dx\ntranspose x are the same thing.",
    "start": "407410",
    "end": "414260"
  },
  {
    "text": "They're just dot products. So we can combine them to get 2x\ntranspose dx is the derivative of the constant 1, which is 0.",
    "start": "414260",
    "end": "420850"
  },
  {
    "text": "And so here, we get the-- this is a constraint on\nthe perturbation, right?",
    "start": "420850",
    "end": "426070"
  },
  {
    "text": "It says that dx is\northogonal to x. Those are the only\ndx's we're allowed.",
    "start": "426070",
    "end": "432550"
  },
  {
    "text": "We're not allowed to\ngo in any direction. Only those that\nare orthogonal to x are what we're going to\nconsider if we want to restrict",
    "start": "432550",
    "end": "439040"
  },
  {
    "text": "ourselves to a sphere. OK? So that's working\nwith constraints. And this is our first example.",
    "start": "439040",
    "end": "447130"
  },
  {
    "text": "You can even do it-- here's just a little exercise\njust to kind of check.",
    "start": "447130",
    "end": "453450"
  },
  {
    "text": "Suppose x is restricted to\nbeing on a circle, right? So x is a vector\nin two dimensions,",
    "start": "453450",
    "end": "460110"
  },
  {
    "text": "but it's parameterized\nby theta over here. And so it's living on\njust a pure circle.",
    "start": "460110",
    "end": "465480"
  },
  {
    "text": "If you wanted to\ncalculate x transpose dx as a kind of quick check\njust to show that it all--",
    "start": "465480",
    "end": "470520"
  },
  {
    "text": "I just like seeing\nthat it works. I mean, again, there's\nnothing fancy here. But x is the vector\ncosine theta sine theta.",
    "start": "470520",
    "end": "476580"
  },
  {
    "text": "dx just by taking simple,\nordinary derivatives is minus sine theta d theta\nand cosine theta d theta.",
    "start": "476580",
    "end": "482860"
  },
  {
    "text": "We can pull out the d theta. And you can see that this\ndot product is obviously minus cosine sine\nplus sine cosine.",
    "start": "482860",
    "end": "489810"
  },
  {
    "text": "It's obviously 0. OK? So you-- And then there's a little\nbit of math gossip--",
    "start": "489810",
    "end": "499030"
  },
  {
    "text": "maybe just as a\nside story, if you'd like to hear a little\nbit of math gossip. So the x vector with\nits two coordinates",
    "start": "499030",
    "end": "508710"
  },
  {
    "text": "is sometimes called an\nextrinsic vector, right? It's living in\nthis plane, right?",
    "start": "508710",
    "end": "514320"
  },
  {
    "text": "The single theta coordinate,\nthe one-dimensional-- ",
    "start": "514320",
    "end": "521099"
  },
  {
    "text": "the perimeter of a circle is a\none-dimensional object, right? That's what's called intrinsic\ncoordinates-- that, here, we",
    "start": "521100",
    "end": "528360"
  },
  {
    "text": "are just parameter-- like,\nfrom the theta point of view, there's nothing but\nthe circle, right? x has two coordinates.",
    "start": "528360",
    "end": "534030"
  },
  {
    "text": "And we have to constrain it. And mathematicians started out\ndoing everything extrinsically.",
    "start": "534030",
    "end": "539940"
  },
  {
    "text": "And then they discovered\nthat intrinsic was better. And nowadays, many\npure mathematicians will tell you you've got\nto do things intrinsically,",
    "start": "539940",
    "end": "546870"
  },
  {
    "text": "it's so much better. But I'll tell you, from\ncomputational viewpoints, I think extrinsic is\nactually better in the end.",
    "start": "546870",
    "end": "552505"
  },
  {
    "text": "So I'm not convinced of what\nthe pure mathematicians will tell you. So you get to decide.",
    "start": "552505",
    "end": "557529"
  },
  {
    "text": "But whatever variables\nwork is fine for you.",
    "start": "557530",
    "end": "564800"
  },
  {
    "text": "OK. So now what I want to do\nis move into matrix land. We want to grow up. This was simple circles.",
    "start": "564800",
    "end": "570370"
  },
  {
    "text": "Let's go into matrix land.",
    "start": "570370",
    "end": "576520"
  },
  {
    "text": "And wait, where are we going? What are we doing here?",
    "start": "576520",
    "end": "581760"
  },
  {
    "text": "Let me just remember. ",
    "start": "581760",
    "end": "587560"
  },
  {
    "text": "Oh, right. OK. So yeah. So we're taking\nanother baby step",
    "start": "587560",
    "end": "593670"
  },
  {
    "text": "into matrix land for the moment. All right. So I'm going to restrict\nmyself to symmetric matrices--",
    "start": "593670",
    "end": "600410"
  },
  {
    "text": "not for any particular reason,\nbut just for simplicity. And I'm going to look at\nessentially the gradient",
    "start": "600410",
    "end": "610400"
  },
  {
    "text": "of the quadratic form x\ntranspose ax, which we've seen enough times in this class. And as you know, the gradient\nis basically ax, right?",
    "start": "610400",
    "end": "622430"
  },
  {
    "text": "And you've seen that before. But now what I'd\nlike to do is, ask what happens if you take\nthe gradient of that very",
    "start": "622430",
    "end": "630950"
  },
  {
    "text": "same quadratic form, but\nwe restrict ourselves to being on the sphere, right?",
    "start": "630950",
    "end": "636350"
  },
  {
    "text": "So what kind of change\ndoes that happen? So to do that, here's\nkind of the trick.",
    "start": "636350",
    "end": "646070"
  },
  {
    "text": "We want to use the fact\nthat the dx's we're allowing are orthogonal to x.",
    "start": "646070",
    "end": "652880"
  },
  {
    "text": "Those are the only dx's\nthat we want to allow now. And one way to do that, one way\nto kind of say the same thing",
    "start": "652880",
    "end": "661100"
  },
  {
    "text": "is that, if you use this\nprojection matrix which projects orthogonal to x, then\nwithin this projection matrix",
    "start": "661100",
    "end": "669840"
  },
  {
    "text": "times dx is still dx, right? So if you're-- right? So here's the picture.",
    "start": "669840",
    "end": "675020"
  },
  {
    "text": "I'll just do it with my hands. Here's your radius. Here's the plane\nperpendicular to the radius.",
    "start": "675020",
    "end": "680210"
  },
  {
    "text": "And I want to project-- of course, the plane\ngoes through the origin. I want to project\nonto that plane.",
    "start": "680210",
    "end": "686070"
  },
  {
    "text": "And if I'm orthogonal,\nthat's kind of a NOOP, right? If I'm in the radial\ndirection, it's 0. And if I'm orthogonal\nto the radial direction,",
    "start": "686070",
    "end": "692870"
  },
  {
    "text": "it doesn't change anything. And so one way to describe\nthe perturbations that",
    "start": "692870",
    "end": "698990"
  },
  {
    "text": "are tangential is in this way. And so if you now\ncalculate x transpose adx,",
    "start": "698990",
    "end": "707630"
  },
  {
    "text": "I get to put this\nprojection matrix in, right? And then I do a little\nbit of manipulation.",
    "start": "707630",
    "end": "713990"
  },
  {
    "text": "And then what you see is\nthat the gradient is now the projection of ax, right?",
    "start": "713990",
    "end": "720680"
  },
  {
    "text": "And so if you're moving\naround the sphere, this is the way to\nactually get the gradient.",
    "start": "720680",
    "end": "725779"
  },
  {
    "text": "Because we want the gradient\nto live on that tangent space to be perpendicular\nto the radius.",
    "start": "725780",
    "end": "731730"
  },
  {
    "text": "So what's really going on could\nbe said more simply perhaps, which is, in general, here\nyou are on the sphere.",
    "start": "731730",
    "end": "739280"
  },
  {
    "text": "And you want to figure\nout the best direction to go in to minimize\nthat quadratic form.",
    "start": "739280",
    "end": "745312"
  },
  {
    "text": "But you're only\nrestricted to the sphere. So go ahead and project that\ngradient down to the sphere. That's really all\nthat's happening.",
    "start": "745312",
    "end": "751530"
  },
  {
    "text": "But I just thought I'd\nshow it to you formally. OK? So what did we just do?",
    "start": "751530",
    "end": "757065"
  },
  {
    "text": "We needed two things. We needed a linearization\nof the function that's correct on\ntangents and a direction that itself is tangent.",
    "start": "757065",
    "end": "762800"
  },
  {
    "text": "That's kind of what\nwe just did to be able to do this sort of thing. OK?",
    "start": "762800",
    "end": "767850"
  },
  {
    "text": "Here's a-- in general-- this wouldn't surprise anybody. But if you had some general\nfunction on the sphere,",
    "start": "767850",
    "end": "775800"
  },
  {
    "text": "then, again, you\nwould end up just projecting the\noriginal gradient so",
    "start": "775800",
    "end": "781380"
  },
  {
    "text": "that it's in the tangent space. OK. Let me get to the\nthing that's more fun.",
    "start": "781380",
    "end": "787890"
  },
  {
    "text": "Let's go to real matrices. Let's differentiate\northogonal matrices.",
    "start": "787890",
    "end": "792940"
  },
  {
    "text": "OK? That's the more fun part. And so this is where\nI want to go now. OK.",
    "start": "792940",
    "end": "798330"
  },
  {
    "text": "So what am I doing here? So let's see.",
    "start": "798330",
    "end": "804480"
  },
  {
    "text": "So what I wanted\nthis to look like is a complete analog of what I\njust did on the sphere, right?",
    "start": "804480",
    "end": "811700"
  },
  {
    "text": "I just want to do it in this\nbigger orthogonal matrix land. So instead of taking a vector,\nI'm now going to get a 5-by-5",
    "start": "811700",
    "end": "820070"
  },
  {
    "text": "random matrix with\nstandard normal entries and a perturbation that's also\na 5-by-5 matrix with my 0, 0,",
    "start": "820070",
    "end": "827540"
  },
  {
    "text": "1's. But what I'd like to do is-- I don't want to work\nwith general matrices. I want to work with\northogonal matrices.",
    "start": "827540",
    "end": "834750"
  },
  {
    "text": "So one quick way\nto get your hands on a random orthogonal matrix is\nto do the QR factorization of a",
    "start": "834750",
    "end": "842150"
  },
  {
    "text": "and grab the q component. AUDIENCE: That's\nnot quite uniform. ALAN EDELMAN: Not\nquite uniform-- yeah, I have written that down.",
    "start": "842150",
    "end": "847339"
  },
  {
    "text": "I've written a whole\nthing about that. But if you randomize the\nsigns, then it would be. Yeah, there's a whole story.",
    "start": "847340",
    "end": "852890"
  },
  {
    "text": "I contacted the LAPACK people\nyears ago about that-- yeah, not quite uniform among-- so there's this thing\ncalled Haar measure",
    "start": "852890",
    "end": "859240"
  },
  {
    "text": "on the orthogonal group, which\nis the uniform measure that's invariant not quite\nbecause of certain reasons.",
    "start": "859240",
    "end": "865540"
  },
  {
    "text": "But it doesn't matter\nfor this purpose, right? So q will be random, just\nnot uniformly random, right?",
    "start": "865540",
    "end": "871230"
  },
  {
    "text": "And then this dq will be\na little bit of a change. OK? And what I want to do is look\nat the same kind of thing",
    "start": "871230",
    "end": "880320"
  },
  {
    "text": "we looked at before. What is the relationship\nbetween dq and q?",
    "start": "880320",
    "end": "885730"
  },
  {
    "text": "On the sphere, it\nwas orthogonality. And if you look at--",
    "start": "885730",
    "end": "892710"
  },
  {
    "text": "I'm going to divide by\nroughly the size of my da there so that we can see. And I wonder, if you don't\nknow what q transpose dq is--",
    "start": "892710",
    "end": "901556"
  },
  {
    "text": "if you've known this before, I\ndon't want you to say anything. But can anybody look at\nthese numbers and guess",
    "start": "901557",
    "end": "907500"
  },
  {
    "text": "what is going to be the\ndifferential version of being tangent to the--",
    "start": "907500",
    "end": "914310"
  },
  {
    "text": "what does it mean to be tangent\nto an orthogonal matrix, right? What's a small change\nto an orthogonal matrix?",
    "start": "914310",
    "end": "919930"
  },
  {
    "text": "So what do you see when you look\nat this 5-by-5 set of numbers? What do you think it's\ntrying to point you towards?",
    "start": "919930",
    "end": "928020"
  },
  {
    "text": "So it's obviously\nnot the zero matrix. So-- yeah, what do\nyou think you see?",
    "start": "928020",
    "end": "934308"
  },
  {
    "text": "AUDIENCE: Skew symmetric. ALAN EDELMAN: Skew symmetric. That's exactly right. So the diagonal wants to be 0.",
    "start": "934308",
    "end": "939490"
  },
  {
    "text": "That's all those 10 to\nthe minus 6 and 1/7. And if you look, for example,\nat this entry versus this entry,",
    "start": "939490",
    "end": "945100"
  },
  {
    "text": "you could see that\nthey're the opposite sign with the same\nnumber, essentially. So yes, this-- and so what this\nlittle numerical experiment",
    "start": "945100",
    "end": "954010"
  },
  {
    "text": "is showing you is\nthat, if you want to make a small\nchange to a matrix q,",
    "start": "954010",
    "end": "959080"
  },
  {
    "text": "if you make a small\nchange dq, the constraint of being orthogonal at\nthe differential level",
    "start": "959080",
    "end": "965950"
  },
  {
    "text": "is that q transpose dq\nwill be skew symmetric, or antisymmetric, right?",
    "start": "965950",
    "end": "971140"
  },
  {
    "text": "And of course, we could do\nthis with-- here's the proof.",
    "start": "971140",
    "end": "977320"
  },
  {
    "text": "The proof is almost\nthe same proof as when you're on the sphere-- that, let's just\ndifferentiate the constraint.",
    "start": "977320",
    "end": "984830"
  },
  {
    "text": "So this is the very definition\nof a matrix being orthogonal. q transpose q is the identity. That is the entire constraint\nof being orthogonal.",
    "start": "984830",
    "end": "993980"
  },
  {
    "text": "And so if you\ndifferentiate, you get q transpose dq plus dq\ntranspose q equals 0.",
    "start": "993980",
    "end": "1000140"
  },
  {
    "text": "OK? But now you don't really\nget to combine these",
    "start": "1000140",
    "end": "1008620"
  },
  {
    "text": "like we did on the sphere. OK? But what we can\nnotice is that this is the same thing as saying that\nthis plus its transpose is 0.",
    "start": "1008620",
    "end": "1018120"
  },
  {
    "text": "OK? But that's just saying\nthe very definition of being antisymmetric,\nor skew symmetric,",
    "start": "1018120",
    "end": "1023540"
  },
  {
    "text": "is that a matrix plus\nits transpose is 0. And so therefore, q transpose is\nan antisymmetric differential.",
    "start": "1023540",
    "end": "1030750"
  },
  {
    "text": "OK? Now, if \"antisymmetric\ndifferential\" sounds like a weird thing to\nsay, from my point of view,",
    "start": "1030750",
    "end": "1036810"
  },
  {
    "text": "from a practical\npoint of view, it's just like if you-- in the limit\nof making little perturbations, q transpose dq will be a little\nantisymmetric matrix, right?",
    "start": "1036810",
    "end": "1044532"
  },
  {
    "text": "And then you don't have\nto worry about it being an antisymmetric differential. OK?",
    "start": "1044532",
    "end": "1050270"
  },
  {
    "text": "Let's talk about this. You all know that if\nyou're in n dimensions",
    "start": "1050270",
    "end": "1056050"
  },
  {
    "text": "and I ask you what is the\ndimensionality of the-- let's talk about the sphere first.",
    "start": "1056050",
    "end": "1061330"
  },
  {
    "text": "If I have a sphere\nin n dimensions, what is the dimensionality\nof the sphere itself? ",
    "start": "1061330",
    "end": "1069240"
  },
  {
    "text": "Like, do you understand\nthe question? Yeah. So yeah, the surface\nof the sphere.",
    "start": "1069240",
    "end": "1075799"
  },
  {
    "text": "And so in 3 dimensions,\nthe surface is two, right? When you look at\nthe world locally,",
    "start": "1075800",
    "end": "1080840"
  },
  {
    "text": "it's kind of flat, right? I mean, if the world\nwere a perfect sphere and you only could look\nat a small distance",
    "start": "1080840",
    "end": "1087662"
  },
  {
    "text": "from where you are, right,\nit looks like a flat plane locally, right? I mean, it curves\nbut from a small--",
    "start": "1087662",
    "end": "1093480"
  },
  {
    "text": "so in n dimensions, what's the\ndimensionality of a sphere? AUDIENCE: n minus 1. ALAN EDELMAN: n minus 1, right? There's only one constraint.",
    "start": "1093480",
    "end": "1099387"
  },
  {
    "text": "And so that takes you down\nfrom n dimensions to n minus 1, right? The only constraint is that\nthe sum of squares is 1.",
    "start": "1099387",
    "end": "1105240"
  },
  {
    "text": "OK? So let's now talk about-- ",
    "start": "1105240",
    "end": "1112140"
  },
  {
    "text": "generally speaking,\nn-by-n matrices live in what dimensional\nspace totally?",
    "start": "1112140",
    "end": "1117269"
  },
  {
    "text": "Just general n-by-n\nmatrices for starters just to get our feet wet. n-squared, right?",
    "start": "1117270",
    "end": "1123120"
  },
  {
    "text": "So every matrix is a point in\nn-squared dimensional space, right? Mathematicians have no\ntrouble with high dimensions.",
    "start": "1123120",
    "end": "1128840"
  },
  {
    "text": "We talk about it all the time. We don't get into\nphilosophical discussions about time or anything, right?",
    "start": "1128840",
    "end": "1133920"
  },
  {
    "text": "We just write down\nn-squared dimensional space. OK? Now, the set of\northogonal matrices",
    "start": "1133920",
    "end": "1139470"
  },
  {
    "text": "is some sort of blob\nin that space, right? It may be hard to imagine,\nbut there's some constraints.",
    "start": "1139470",
    "end": "1145270"
  },
  {
    "text": "And so now my question is,\nwhat is the dimension of that? Anybody want to attack\nthat right now or want",
    "start": "1145270",
    "end": "1153418"
  },
  {
    "text": "to-- maybe we should go slowly. Let's see. So the 2-by-2\northogonal matrices--",
    "start": "1153418",
    "end": "1160669"
  },
  {
    "text": "how many parameters are there? So let's just focus on\nrotations for starters. So we're talking about\nrotations and reflections.",
    "start": "1160670",
    "end": "1167919"
  },
  {
    "text": "How many parameters\nfor rotations? So we're in four-dimensional\nspace-- all possible matrices.",
    "start": "1167920",
    "end": "1175680"
  },
  {
    "text": "And then we're looking\nat rotations only as some sort of blob in\nfour-dimensional space.",
    "start": "1175680",
    "end": "1181860"
  },
  {
    "text": "Dimensionality? One, right? Just the angle of\nrotation, right? So that's one. There's the cosine\ntheta sine theta.",
    "start": "1181860",
    "end": "1188670"
  },
  {
    "text": "Reflections also are\nkind of like that. So for 2-by-2\nmatrices, it's one.",
    "start": "1188670",
    "end": "1197370"
  },
  {
    "text": "For 3-by-3 matrices-- people who\nfly airplanes know the answer to this, believe it or not.",
    "start": "1197370",
    "end": "1203890"
  },
  {
    "text": "Do you know how many parameters\ndescribe an orthogonal matrix in-- I mean, you don't need all\nnine numbers of a-- right?",
    "start": "1203890",
    "end": "1212920"
  },
  {
    "text": "There's constraints. Do you want to guess? AUDIENCE: 2. ALAN EDELMAN: It's not 2. ",
    "start": "1212920",
    "end": "1220220"
  },
  {
    "text": "So it's not 6, but 6 is-- I feel like 6 is on the\nright track in a sort of backwards kind of way.",
    "start": "1220220",
    "end": "1226280"
  },
  {
    "text": "AUDIENCE: Is it 4? ALAN EDELMAN: 4? We're running out of numbers. No, it's not 4. AUDIENCE: Is it 3? ALAN EDELMAN: 3.",
    "start": "1226280",
    "end": "1231370"
  },
  {
    "text": "A good guesser here. Give this man a prize. So roll, pitch, and yaw are\nwhat the airplane people",
    "start": "1231370",
    "end": "1237130"
  },
  {
    "text": "seem to know. That's what they've\nnamed it for the 3.",
    "start": "1237130",
    "end": "1242920"
  },
  {
    "text": "So the general answer-- anybody want to guess\nthe general-- oh, yeah, anybody want to guess\nthe general answer",
    "start": "1242920",
    "end": "1248860"
  },
  {
    "text": "before I show you? You've got two data points. That may be not\nenough to guess with. It's one for 2-by-2.",
    "start": "1248860",
    "end": "1256029"
  },
  {
    "text": "And it's 3 for 3-by-3. Anybody want to-- can you name\nthat song in how many notes?",
    "start": "1256030",
    "end": "1264440"
  },
  {
    "text": "All right. I'll just kind of tell you. So-- AUDIENCE: n-squared\nminus n choose 2.",
    "start": "1264440",
    "end": "1274280"
  },
  {
    "text": "ALAN EDELMAN: That sounds like\nthe right backwards answer. ",
    "start": "1274280",
    "end": "1281780"
  },
  {
    "text": "So it's the complement of that. It's n choose 2. So somebody had said 6.",
    "start": "1281780",
    "end": "1288330"
  },
  {
    "text": "You said 6. And the answer was 3. I feel like you're on\nthe same wavelength. You said the 6 number\nwhen n equals 3.",
    "start": "1288330",
    "end": "1294120"
  },
  {
    "text": "And so there's a couple\nof ways to see this. But in general, the answer\nis n times n minus 1 over 2.",
    "start": "1294120",
    "end": "1301260"
  },
  {
    "text": "One way to see it is to take\nthe n-squared free parameters and count the constraints of\nq transpose q as the identity,",
    "start": "1301260",
    "end": "1309570"
  },
  {
    "text": "right? And the constraints--\nas a picture,",
    "start": "1309570",
    "end": "1317279"
  },
  {
    "text": "you could kind of\ncount the constraints as the ones on the diagonal. The ones on the diagonals\nsay that your sum of squares",
    "start": "1317280",
    "end": "1323580"
  },
  {
    "text": "is 1, right? And then you could pick,\nsay, the upper triangular because the lower\nis the same, right?",
    "start": "1323580",
    "end": "1329460"
  },
  {
    "text": "This one tells you that\nthe i'th column is-- right? This one says the i'th\ncolumn has norm 1. This one says the i and jth\ncolumn are orthogonal, right?",
    "start": "1329460",
    "end": "1336759"
  },
  {
    "text": "And so the total number\nis sort of an upper-- oh, wait. Yeah, the number of constraints\nis n times n plus 1 over 2.",
    "start": "1336760",
    "end": "1343530"
  },
  {
    "text": "And so you have to subtract\nthat from n-squared. And you get-- what's left is\nthese numbers here, right?",
    "start": "1343530",
    "end": "1352590"
  },
  {
    "text": "This is n times n minus\n1 over 2-- or n choose 2, as this man was saying. OK? So that's one way to count it.",
    "start": "1352590",
    "end": "1359113"
  },
  {
    "text": "Another way to count\nit-- there are lots of ways to count it, actually. You could think about\nthe QR factorization.",
    "start": "1359113",
    "end": "1364630"
  },
  {
    "text": "And the R, which is\nupper triangular, has the same n times\nn plus 1 over 2. Leaving n times n minus 1 over\n2 free parameters for the q",
    "start": "1364630",
    "end": "1372600"
  },
  {
    "text": "is another way to say that. You could also think about the\nsymmetric eigenvalue problem,",
    "start": "1372600",
    "end": "1378429"
  },
  {
    "text": "if you like, where a symmetric\nmatrix has n times n plus 1 over 2.",
    "start": "1378430",
    "end": "1383980"
  },
  {
    "text": "And the eigenvalues\neat up n of them. And so now you have n\ntimes n minus 1 over 2.",
    "start": "1383980",
    "end": "1390110"
  },
  {
    "text": "So there are a lot of ways to--\nyou could also look at the SVD. That's another way to see it. For square matrices,\nthis is n-squared.",
    "start": "1390110",
    "end": "1397220"
  },
  {
    "text": "This one has n. And so these two\northogonal matrices each have n squared\nminus n over 2, right?",
    "start": "1397220",
    "end": "1402740"
  },
  {
    "text": "So there's lots and\nlots of fun ways to check that this\nis the right answer.",
    "start": "1402740",
    "end": "1408059"
  },
  {
    "text": "OK? So now what I want\nto do is sort of talk about the subject of this\nclass, which is to differentiate",
    "start": "1408060",
    "end": "1414100"
  },
  {
    "text": "matrix functions, right? So this is what the buildup has\nbeen for the last 30 minutes",
    "start": "1414100",
    "end": "1419450"
  },
  {
    "text": "or so. So I want to differentiate the\nsymmetric eigenvalue problem. And I want to show\nyou how to do it.",
    "start": "1419450",
    "end": "1425429"
  },
  {
    "text": "OK? So in fact, I guess we might\nsomewhere derive this--",
    "start": "1425430",
    "end": "1431570"
  },
  {
    "text": "you had a name I had never\nheard before of something that I think is much older. But the physics-- the\nsomething Feynman theorem.",
    "start": "1431570",
    "end": "1437450"
  },
  {
    "text": "AUDIENCE: Hellmann-Feynman. ALAN EDELMAN: Hellmann-Feynman. I'm sure it's much older\nthan Hellman and Feynman. So that sounds like the--\nwas Hellmann a physicist?",
    "start": "1437450",
    "end": "1443843"
  },
  {
    "text": "AUDIENCE: I don't\nknow who Hellmann was. ALAN EDELMAN: OK. But we all know who Feynman was. All right.",
    "start": "1443843",
    "end": "1449080"
  },
  {
    "text": "So the symmetric eigenvalue\nproblem as, you all know,",
    "start": "1449080",
    "end": "1455309"
  },
  {
    "text": "d you know that the eigenvalues\nof a symmetric matrix are real. And the eigenvectors can be\nput into an orthogonal matrix,",
    "start": "1455310",
    "end": "1463500"
  },
  {
    "text": "right? And so the symmetric\neigenvalue problem can be written as factoring\na matrix s into q lambda q",
    "start": "1463500",
    "end": "1471050"
  },
  {
    "text": "transpose. OK? And so we can differentiate. And we get the three terms.",
    "start": "1471050",
    "end": "1476870"
  },
  {
    "text": "This is just the product rule. And it turns out to be\nhandy to kind of spin around",
    "start": "1476870",
    "end": "1483900"
  },
  {
    "text": "the differential. It kind of makes you look like\nyou're at a diagonal matrix. And if you spin it around--",
    "start": "1483900",
    "end": "1490320"
  },
  {
    "text": "I'm just putting q transpose\non the left and q on the right. Let me move it up to make\nsure everybody can see this.",
    "start": "1490320",
    "end": "1496200"
  },
  {
    "text": "But yeah. Let's move everything up.",
    "start": "1496200",
    "end": "1501490"
  },
  {
    "text": "Yeah. So this rotated version of the\nchange to your symmetric matrix",
    "start": "1501490",
    "end": "1511700"
  },
  {
    "text": "is q transpose dq lambda minus\nlambda q transpose dq plus d",
    "start": "1511700",
    "end": "1516740"
  },
  {
    "text": "lambda. OK? So that's the derivative of-- so what this says is, if I\nperturb my symmetric matrix",
    "start": "1516740",
    "end": "1524059"
  },
  {
    "text": "this much, then my eigenvectors\nwill be perturbed by this much. And my eigenvalues will\nbe perturbed this much.",
    "start": "1524060",
    "end": "1531539"
  },
  {
    "text": "And you know me by now. I don't believe any theorem\nunless I can check it",
    "start": "1531540",
    "end": "1536570"
  },
  {
    "text": "numerically, right? So without a computer, I\nwouldn't be able to do math. So let's do that.",
    "start": "1536570",
    "end": "1542400"
  },
  {
    "text": "Let's create a random\n5-by-5 matrix and also a random perturbation. But what I'd like to do\nis I want to symmetrize.",
    "start": "1542400",
    "end": "1549200"
  },
  {
    "text": "So I'm going to call this s. And I'll also symmetrize\nmy perturbation. And I'm just going\nto do the obvious.",
    "start": "1549200",
    "end": "1555170"
  },
  {
    "text": "I'm going to take the\neigendecomposition of s and the eigendecomposition\nof my perturbed s.",
    "start": "1555170",
    "end": "1560690"
  },
  {
    "text": "And so here's my eigenvalues. And here's the\nperturbed eigenvalues. So let's call dq to be the\nperturbed eigenvectors. d",
    "start": "1560690",
    "end": "1568320"
  },
  {
    "text": "lambda is the\nperturbed eigenvalues. And let's just do\na comparison of--",
    "start": "1568320",
    "end": "1575040"
  },
  {
    "text": "let's see. So how do I see the comparison? Did I stack them on\ntop of each other? Yes. I was stacking them\non top of each other.",
    "start": "1575040",
    "end": "1581065"
  },
  {
    "text": "I'm not sure why I\ndid that, but I did. I stacked them on\ntop of each other. So you should be able to see\nthat, if I look at q transpose",
    "start": "1581065",
    "end": "1588269"
  },
  {
    "text": "dq versus the math thing\nthat I say it has to equal,",
    "start": "1588270",
    "end": "1594000"
  },
  {
    "text": "I guess you could see that if\nyou look at the top five rows-- what would happen if\nI didn't stack them on top of each other?",
    "start": "1594000",
    "end": "1599820"
  },
  {
    "text": "What if I just went comma? Would that not be easy?",
    "start": "1599820",
    "end": "1605150"
  },
  {
    "text": "Maybe 5-by-5 is too big. Maybe that's why I did that. I just want to see\nwhy I did that.",
    "start": "1605150",
    "end": "1611820"
  },
  {
    "text": "Oh, that's a bad-- and if I do this, that's good. That's better.",
    "start": "1611820",
    "end": "1617520"
  },
  {
    "text": "All right Let's do it that way. OK. I think that's\neasier on the eye. So yeah, you can see\nthese two matrices",
    "start": "1617520",
    "end": "1623100"
  },
  {
    "text": "are to enough digits the same. And you can believe the\nmath right now, right?",
    "start": "1623100",
    "end": "1628920"
  },
  {
    "text": "So I perturbed my\nsymmetric matrix. And I look at this. And I have an\nidentity that connects the perturbation\nof the eigenvalues",
    "start": "1628920",
    "end": "1635430"
  },
  {
    "text": "and the perturbation\nof the eigenvectors. And that\nHellmann-Feynman theorem",
    "start": "1635430",
    "end": "1642360"
  },
  {
    "text": "is just the diagonal part\nof this equation here. So the Hellmann-Feynman\ntheorem would have said--",
    "start": "1642360",
    "end": "1649860"
  },
  {
    "text": "and I'll just write\nit in this notation. But the Hellmann-Feynman\ntheorem is the diagonal,",
    "start": "1649860",
    "end": "1657430"
  },
  {
    "text": "which says that essentially\nqi transpose dsqi--",
    "start": "1657430",
    "end": "1663270"
  },
  {
    "text": "so qi being the eigenvector--\nis the diagonal. So tell me.",
    "start": "1663270",
    "end": "1668430"
  },
  {
    "text": "There's three terms there. There's three terms. What is the diagonal? ",
    "start": "1668430",
    "end": "1675740"
  },
  {
    "text": "So what's the diagonal\nof the first term? So capital lambda is a\ndiagonal matrix, right?",
    "start": "1675740",
    "end": "1682450"
  },
  {
    "text": "q transpose dq you tell\nme is an antisymmetric or a skew symmetric matrix. So what's the\ndiagonal of that term",
    "start": "1682450",
    "end": "1688330"
  },
  {
    "text": "there, q transpose dq lambda?  Well, let me ask\nan easier question.",
    "start": "1688330",
    "end": "1694587"
  },
  {
    "text": "What's the diagonal\nof q transpose dq? ",
    "start": "1694587",
    "end": "1699680"
  },
  {
    "text": "That's an easy question. AUDIENCE: 0. ALAN EDELMAN: It's 0, right?",
    "start": "1699680",
    "end": "1704920"
  },
  {
    "text": "That's just the fact that\nany skew symmetric matrix has diagonal 0. OK? Now, if you take a--",
    "start": "1704920",
    "end": "1710707"
  },
  {
    "text": "what happens if you\nmultiply it on the right by a diagonal matrix? What does that do to\nthe diagonal elements? ",
    "start": "1710707",
    "end": "1717690"
  },
  {
    "text": "Right? So now I want to take\nthat q transpose dq and multiply it by that capital\nlambda, which is diagonal.",
    "start": "1717690",
    "end": "1723850"
  },
  {
    "text": "What does it do\nto the diagonals? So if I have an\nantisymmetric times diagonal,",
    "start": "1723850",
    "end": "1729910"
  },
  {
    "text": "what's the diagonal of that? AUDIENCE: 0. ALAN EDELMAN: It's\njust 0, right? It doesn't change anything. So the only term that matters\nis the d lambda, right?",
    "start": "1729910",
    "end": "1736600"
  },
  {
    "text": "And so basically,\nthis is actually just saying that the change to\nthe eigenvalue is exactly this.",
    "start": "1736600",
    "end": "1746450"
  },
  {
    "text": "You just take the inner\nproduct of the change to your matrix in the\ndirection of the eigenvector. And there you get it, right?",
    "start": "1746450",
    "end": "1752559"
  },
  {
    "text": "So that's one quick\nderivation of that theorem. STEVEN JOHNSON: Fun fact is that\nthe Hellmann-Feynman theorem",
    "start": "1752560",
    "end": "1757922"
  },
  {
    "text": "does not require the\nperturbation to be symmetric. So even if ps is\nnot symmetric, you",
    "start": "1757922",
    "end": "1764280"
  },
  {
    "text": "can-- which is really useful. Because then you can\ntake a symmetric matrix. But then you look at a\nnon-symmetric perturbation",
    "start": "1764280",
    "end": "1770322"
  },
  {
    "text": "and you can still\nfind the effect. ALAN EDELMAN: That\nis a fun fact. Yeah, and of course, the same-- STEVEN JOHNSON: The\ntwo terms cancel.",
    "start": "1770322",
    "end": "1776380"
  },
  {
    "text": "So you actually didn't\nneed the diagonals to be 0. ALAN EDELMAN: That's true. STEVEN JOHNSON:\nIn the Q transpose dQ Because the first\nterm-- if you look at it,",
    "start": "1776380",
    "end": "1782520"
  },
  {
    "text": "the diagonals cancel. ALAN EDELMAN: That is true. Yeah, I can see that\nright there, that-- and of course, you could have\ntaken a non-symmetric matrix.",
    "start": "1782520",
    "end": "1791049"
  },
  {
    "text": "But then you would need both\neigenvectors to play a role. So lots of generalizations. Yeah, I never noticed that.",
    "start": "1791050",
    "end": "1796560"
  },
  {
    "text": "But I never perturbed\nsymmetric matrices-- you perturb them? STEVEN JOHNSON: ALAN EDELMAN: I feel\nlike it's violating the--",
    "start": "1796560",
    "end": "1802740"
  },
  {
    "text": "STEVEN JOHNSON: Physics often-- a symmetric system is\nlike a lossless system, like a lossless\nvibrating system.",
    "start": "1802740",
    "end": "1808920"
  },
  {
    "text": "But real systems, of\ncourse, often have losses. But the losses are small. So you want to\nanalyze the losses--",
    "start": "1808920",
    "end": "1814080"
  },
  {
    "text": "ALAN EDELMAN: You want to\nanalyze-- that makes sense. STEVEN JOHNSON: Where it's easy. And then, you want to put in\nthe losses perturbatively. ALAN EDELMAN: That's cool, yeah.",
    "start": "1814080",
    "end": "1819730"
  },
  {
    "text": "STEVEN JOHNSON:\nand so it's nice. ALAN EDELMAN: The\nother part of this actually tells you what\nhappens to eigenvectors, right?",
    "start": "1819730",
    "end": "1825940"
  },
  {
    "text": "That's living on\nthe off diagonal. So here's the theorem.",
    "start": "1825940",
    "end": "1831610"
  },
  {
    "text": "I just wrote it on the board\nbecause I forgot it was here. But yeah. So if s depended on a\nparameter, one way to say it",
    "start": "1831610",
    "end": "1840160"
  },
  {
    "text": "is that the derivative of\nthe eigenvalue is this. And we can use this\nto, for example,",
    "start": "1840160",
    "end": "1847129"
  },
  {
    "text": "get the gradient of a single\neigenvalue because the--",
    "start": "1847130",
    "end": "1852420"
  },
  {
    "text": "oh, I wonder if I\nshould mention-- is this obviously\nthe same thing?",
    "start": "1852420",
    "end": "1858019"
  },
  {
    "text": "No, it's not. Let me-- there's another\ntheorem that I think hasn't come up yet, but\nit's a very useful fact",
    "start": "1858020",
    "end": "1865230"
  },
  {
    "text": "in linear algebra. And maybe, Steven, you could\ntell me if you did mention it. But I don't think-- STEVEN JOHNSON: The cyclic\nproperty of the trace? ALAN EDELMAN: The cyclic\nproperty of the trace.",
    "start": "1865230",
    "end": "1870830"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. So they're actually\nderiving this in homework. But yeah. We've used the cyclic\nproperty quite a bit. ALAN EDELMAN: Oh, OK. All right.",
    "start": "1870830",
    "end": "1876015"
  },
  {
    "text": "I didn't remember\nthat you had done it. But all right. Then I don't have to say\na word about it then. And the fact that the cyclic\nproperty kind of holds--",
    "start": "1876015",
    "end": "1883412"
  },
  {
    "text": "there's another\none of these things where, when it's a\nscalar, you might be sort of a little bit\nsurprised that it works, right?",
    "start": "1883412",
    "end": "1890270"
  },
  {
    "text": "Because you don't have to\nwrite the word \"trace.\" When you have a scalar, it's\nlike a 1-by-1 matrix, right?",
    "start": "1890270",
    "end": "1895850"
  },
  {
    "text": "You don't have to say the word\n\"trace\" because it's just that. But if you pretend the\nword \"trace\" is here, then you can move it around.",
    "start": "1895850",
    "end": "1902660"
  },
  {
    "text": "And now it's a\nbig matrix, right? Was that another thing? I mean, you pointed out that\nit's kind of like dot products",
    "start": "1902660",
    "end": "1908565"
  },
  {
    "text": "commuting-- STEVEN JOHNSON: We've used\nthat a couple of times. ALAN EDELMAN: OK. STEVEN JOHNSON: Yeah, this\njust kind of gives away one of the homework problems. But that's OK.",
    "start": "1908565",
    "end": "1913940"
  },
  {
    "text": "ALAN EDELMAN: Oh, I see. STEVEN JOHNSON: But hey probably\nalready looked at the homework already. So. ALAN EDELMAN: All right. Well, it doesn't hurt\nif it helps, I think.",
    "start": "1913940",
    "end": "1920233"
  },
  {
    "text": "STEVEN JOHNSON:\nSo physicists call this first order\nperturbation theory which is the same thing as--",
    "start": "1920233",
    "end": "1926110"
  },
  {
    "text": "a first order perturbation-- ALAN EDELMAN: Is the same thing\nas computing the derivative. STEVEN JOHNSON: ALAN EDELMAN: Right, yeah. STEVEN JOHNSON: ALAN EDELMAN: It's just physics\nspeak for the same thing.",
    "start": "1926110",
    "end": "1932885"
  },
  {
    "text": " OK. And we can also get information\nabout the eigenvectors as well.",
    "start": "1932885",
    "end": "1942040"
  },
  {
    "text": "So off the diagonal, you can\nwrite down this equation.",
    "start": "1942040",
    "end": "1948720"
  },
  {
    "text": "And it basically says\nthat this divided by this will give you the change\nof the eigenvectors.",
    "start": "1948720",
    "end": "1954840"
  },
  {
    "text": "And all sorts of havoc happens\nif two eigenvalues are equal. And thing is not exactly\ndifferentiable anymore",
    "start": "1954840",
    "end": "1961140"
  },
  {
    "text": "and kind of revealing itself. OK? And so I think--",
    "start": "1961140",
    "end": "1967910"
  },
  {
    "text": "let's see. So-- oh, and by the way, here's\nsecond order perturbation theory, while we're at it.",
    "start": "1967910",
    "end": "1974039"
  },
  {
    "text": "So yeah. So one can follow\nall the way through.",
    "start": "1974040",
    "end": "1979400"
  },
  {
    "text": "Maybe I won't make a big\ndeal about it right now. But if you know the\nfirst order perturbation of the eigenvectors,\nthen you can",
    "start": "1979400",
    "end": "1985595"
  },
  {
    "text": "use that to get the\nsecond order perturbation of the eigenvalues. And here's your whole\nperturbation theory.",
    "start": "1985595",
    "end": "1992510"
  },
  {
    "text": "Should I have have divided by 2? Oh, no, there is a 2. So this is correct. OK. All right.",
    "start": "1992510",
    "end": "1998060"
  },
  {
    "text": "So I just wanted\nto kind of show you this far for the\nderivatives of eigenvalues.",
    "start": "1998060",
    "end": "2003970"
  },
  {
    "text": "You could do essentially\nthe same game and get derivatives\nof singular values, all sorts of other things.",
    "start": "2003970",
    "end": "2009890"
  },
  {
    "text": "But I think this is kind of just\nenough of a peak for the time we have in this class. Any questions about all this?",
    "start": "2009890",
    "end": "2017850"
  },
  {
    "text": "Anything you had always\nwondered about differentiating eigenvalues, or eigenvectors,\nand stuff like that?",
    "start": "2017850",
    "end": "2022980"
  },
  {
    "text": " OK then. All right. Well, then I'm going\nto switch gears.",
    "start": "2022980",
    "end": "2030970"
  },
  {
    "text": "And-- oh, yes. There is a question--\ntwo questions, actually. AUDIENCE: What if--\nfor example, sometimes",
    "start": "2030970",
    "end": "2036529"
  },
  {
    "text": "I want to take the\nderivative confined to something like the the\npositive semidefinite matrices.",
    "start": "2036530",
    "end": "2042832"
  },
  {
    "text": " ALAN EDELMAN: So that-- AUDIENCE: Do I have to also\ncheck, am I inside the thing,",
    "start": "2042832",
    "end": "2049129"
  },
  {
    "text": "so I can go anywhere? And then I have\nto on the boundary so that then I can do this? ALAN EDELMAN: I think so.",
    "start": "2049130",
    "end": "2054629"
  },
  {
    "text": "That's a good question. So this is now a-- it's kind of like an\ninequality constraint.",
    "start": "2054630",
    "end": "2061800"
  },
  {
    "text": "And I was kind of talking\nabout an equality constraint. So yeah. I don't know any other way.",
    "start": "2061800",
    "end": "2067783"
  },
  {
    "text": "STEVEN JOHNSON: Well, you\ncould use intrinsic coordinates because-- ALAN EDELMAN: I'm not a fan. STEVEN JOHNSON: But you could\nwrite semidefinite-- any--",
    "start": "2067784",
    "end": "2074370"
  },
  {
    "text": "ALAN EDELMAN: Use\nCholesky factor, yeah. STEVEN JOHNSON: well,\njust as b transpose b. ALAN EDELMAN: Right. STEVEN JOHNSON: And so if\nyou parameterize it in terms",
    "start": "2074370",
    "end": "2081179"
  },
  {
    "text": "of some kind of factor-- it\ndoesn't have to be a Cholesky factor, but you can-- ALAN EDELMAN: That's true. It could be the square\nroot, right, or any--",
    "start": "2081179",
    "end": "2087690"
  },
  {
    "text": "STEVEN JOHNSON: It's\nprobably the easiest way. ALAN EDELMAN: Maybe for that\ncase that's probably true. STEVEN JOHNSON: ALAN EDELMAN: But in general-- STEVEN JOHNSON: Yeah. Well, yeah. In general, I would say\nthat semidefinite matrices",
    "start": "2087690",
    "end": "2094623"
  },
  {
    "text": "don't fall down from the sky. So they usually-- if you\nstare at it hard enough, they came from a b transpose b.",
    "start": "2094623",
    "end": "2101309"
  },
  {
    "text": "So-- ALAN EDELMAN: So\nmaybe the b is handy. But that's actually\na good point. STEVEN JOHNSON: ALAN EDELMAN: That\nis a good point.",
    "start": "2101310",
    "end": "2106498"
  },
  {
    "text": "OK. I don't know how general\nthat is, though-- that it's easy to find an\nintrinsic coordinate system.",
    "start": "2106498",
    "end": "2112994"
  },
  {
    "text": "STEVEN JOHNSON: Yeah. ALAN EDELMAN: So that\nmight be the tricky part. But that is a good answer. OK. And I think there was\nanother question over there?",
    "start": "2112995",
    "end": "2119073"
  },
  {
    "text": "OK. AUDIENCE: I had a\nquestion where you take x transpose A x and the\nconstraint x transpose x is 1.",
    "start": "2119073",
    "end": "2125690"
  },
  {
    "text": "So if you just like\nthe df assuming that for x transpose x, you\nstill get the dot product of Ax",
    "start": "2125690",
    "end": "2133358"
  },
  {
    "text": "and x and dx, right? ALAN EDELMAN: Right. But we wouldn't be going--",
    "start": "2133358",
    "end": "2143750"
  },
  {
    "text": "like, our search\ndirection is kind of not physical, if you will. It's not on the sphere anymore.",
    "start": "2143750",
    "end": "2149900"
  },
  {
    "text": "AUDIENCE: Yeah. That's why you have to\nmultiply the projection. ALAN EDELMAN: Right. So to put the-- one way to look at it\nis the projection matrix",
    "start": "2149900",
    "end": "2156470"
  },
  {
    "text": "is just, like, slapping\nit back onto the sphere, like whack-a-mole right down\nback onto the tangent space of the sphere.",
    "start": "2156470",
    "end": "2162800"
  },
  {
    "text": "But we also see that it\ngives the correct answer and that it's moving\nin the steepest descent direction on the sphere.",
    "start": "2162800",
    "end": "2169910"
  },
  {
    "text": "Because we don't\nwant any directions that go off the\nsphere at this point. So that's right.",
    "start": "2169910",
    "end": "2175100"
  },
  {
    "text": "Was there another question? Did I-- was there another\nhand up or just those two? All right.",
    "start": "2175100",
    "end": "2180530"
  },
  {
    "text": "STEVEN JOHNSON: Do you\nwant the blackboard now? ALAN EDELMAN: Yeah, I'm going\nto do the blackboard now. And we're going to switch gears.",
    "start": "2180530",
    "end": "2185630"
  },
  {
    "text": "Thanks, Steven. And I'm going to pull\nback these notes here. So I guess I can close this.",
    "start": "2185630",
    "end": "2192460"
  },
  {
    "start": "2192460",
    "end": "2197000"
  }
]
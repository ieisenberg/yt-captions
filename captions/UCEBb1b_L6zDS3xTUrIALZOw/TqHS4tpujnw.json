[
  {
    "start": "0",
    "end": "134000"
  },
  {
    "text": "GERBRAND CEDER: So what I\nwant to do today is finish up Monte Carlo simulation and go\ninto a little more advanced",
    "start": "0",
    "end": "10849"
  },
  {
    "text": "things in Monte Carlo\nsimulation and then also go into free\nenergy integrations",
    "start": "10850",
    "end": "16100"
  },
  {
    "text": "and other\ncoarse-graining methods so when direct\nsimulation won't work. ",
    "start": "16100",
    "end": "25699"
  },
  {
    "text": "If you remember, I\nintroduced Monte Carlo simulation as a way\nof importance sampling and contrasted it\nagainst simple sampling.",
    "start": "25700",
    "end": "32606"
  },
  {
    "text": "What I want to show\nyou today, there's actually quite a few things in\nbetween that, in some cases, can be practical.",
    "start": "32607",
    "end": "38269"
  },
  {
    "text": "Remember the idea\nof simple sampling is that you sample\nrandomly and then",
    "start": "38270",
    "end": "44270"
  },
  {
    "text": "you weigh with a\nprobability that's correct relatively,\nwhere the states have",
    "start": "44270",
    "end": "50180"
  },
  {
    "text": "their correct relative\nprobability to one another. Importance sampling is sampling\nwith the correct probability",
    "start": "50180",
    "end": "56149"
  },
  {
    "text": "and then just averaging\nthe quantity you sample, but you can actually sample\nwith things in between.",
    "start": "56150",
    "end": "64979"
  },
  {
    "text": "So here you're sampling with\na probability proportional to that exponential\nof that Hamiltonian.",
    "start": "64980",
    "end": "74150"
  },
  {
    "text": "Here you're sampling\nwith no Hamiltonian and therefore, you have to\ncorrect the probability later.",
    "start": "74150",
    "end": "79550"
  },
  {
    "text": "You can sample with any\nHamiltonian H0, which is not the true Hamiltonian\nof your system,",
    "start": "79550",
    "end": "85520"
  },
  {
    "text": "and then correct for it\nin the probabilities. So if you sample with H0,\nthen the states you sample",
    "start": "85520",
    "end": "95549"
  },
  {
    "text": "have to be corrected with\nthe relative probability of that state, the\nrelative probability",
    "start": "95550",
    "end": "101270"
  },
  {
    "text": "that you would get with the\ncorrect Hamiltonian versus what you get with the Hamiltonian\nwhich you decided to sample.",
    "start": "101270",
    "end": "107670"
  },
  {
    "text": "OK? So this is the Hamiltonian\nwhich we decided to pick, the states that\ngo in your sample,",
    "start": "107670",
    "end": "113229"
  },
  {
    "text": "and then this is the\nprobability correction. Sorry. ",
    "start": "113230",
    "end": "122350"
  },
  {
    "text": "And so whenever you\nsample with what's not the proper Hamiltonian\nof your system, people call it\nnon-Boltzmann sampling.",
    "start": "122350",
    "end": "128965"
  },
  {
    "start": "128965",
    "end": "135290"
  },
  {
    "start": "134000",
    "end": "308000"
  },
  {
    "text": "Why would you want to do\nnon-Boltzmann sampling? Well, it can be relevant if\nthe particular quantity you're",
    "start": "135290",
    "end": "144810"
  },
  {
    "text": "after in your system\nis essentially not determined by the relevant\nthermodynamics states.",
    "start": "144810",
    "end": "151409"
  },
  {
    "text": "Remember, I introduced\nthis by say, what if you're looking\nat, say, average energy",
    "start": "151410",
    "end": "159030"
  },
  {
    "text": "or average volume or\naverage magnetization, then what you\nreally need to know is what's the\nenergy of the states",
    "start": "159030",
    "end": "166500"
  },
  {
    "text": "that the system spent\nmost of its time in? But what if a system\nspends only a small amount",
    "start": "166500",
    "end": "172740"
  },
  {
    "text": "of its time in certain\nstates, but those have the relevant property\nthat you want to sample?",
    "start": "172740",
    "end": "177780"
  },
  {
    "text": "For example, let's say that\nthis is a phase space, this",
    "start": "177780",
    "end": "183840"
  },
  {
    "text": "[INAUDIBLE]. So with importance\nsampling, you'd be drawn towards these states.",
    "start": "183840",
    "end": "189170"
  },
  {
    "text": "OK? I don't know, maybe\nthe ones that live here are optically\nactive or something",
    "start": "189170",
    "end": "194760"
  },
  {
    "text": "like that and the other\nones aren't and you want to somehow get\na lot of information of the optical activity\nof the material,",
    "start": "194760",
    "end": "201630"
  },
  {
    "text": "you may want to build a\nHamiltonian that drives you towards these states. OK?",
    "start": "201630",
    "end": "207209"
  },
  {
    "text": "And as long as you then correct\nfor the proper probability, you'll get a proper ensemble.",
    "start": "207210",
    "end": "212610"
  },
  {
    "text": "It's one that's just much\nmore efficiently biased towards the regional phase\nspace where you want to get.",
    "start": "212610",
    "end": "218700"
  },
  {
    "text": "So that's\nnon-Boltzmann sampling. Another obvious way is you can\nuse it to sample phase space",
    "start": "218700",
    "end": "225810"
  },
  {
    "text": "more efficiently. If you had a phase base\nwith a lot of local minima,",
    "start": "225810",
    "end": "236280"
  },
  {
    "text": "you may want to define\na new Hamiltonian that looks like this.",
    "start": "236280",
    "end": "242069"
  },
  {
    "start": "242070",
    "end": "247120"
  },
  {
    "text": "And this is especially relevant\nif your Monte Carlo has some form of dynamics in it. So in the blue Hamiltonian,\nthe true Hamiltonian,",
    "start": "247120",
    "end": "254230"
  },
  {
    "text": "it may be very hard to\nget out of this minimum into the next one. Whereas if you raise\nthe potential well,",
    "start": "254230",
    "end": "260648"
  },
  {
    "text": "OK, in the red\nHamiltonian it's going to be much easier\nto get out of it.",
    "start": "260649",
    "end": "266140"
  },
  {
    "text": "OK? So essentially your\nflattening your phase space with the new\nHamiltonian, so it's",
    "start": "266140",
    "end": "271870"
  },
  {
    "text": "going to be much easier\nto get out of local minima and then you can correct\nfor that probability.",
    "start": "271870",
    "end": "277640"
  },
  {
    "text": "There's a lot of algorithms\nthese days built on this idea, not just in Monte\nCarlo, but there",
    "start": "277640",
    "end": "284860"
  },
  {
    "text": "are molecular dynamic\nschemes, there are all kinds of\nschemes that are built on this idea of lifting\nup the potential wells",
    "start": "284860",
    "end": "292420"
  },
  {
    "text": "and then correcting the\nrelative probability or the relative\nvibrational frequency",
    "start": "292420",
    "end": "297610"
  },
  {
    "text": "or the relative time you\nspend in each potential well. ",
    "start": "297610",
    "end": "307060"
  },
  {
    "text": "OK. You can also do\nnon-Metropolis Monte Carlo. This gets even a\nlittle more odd.",
    "start": "307060",
    "end": "314330"
  },
  {
    "start": "308000",
    "end": "429000"
  },
  {
    "text": "Remember that we defined an\nacceptable Metropolis as one",
    "start": "314330",
    "end": "321199"
  },
  {
    "text": "where the a priori\nprobabilities were equal. ",
    "start": "321200",
    "end": "328150"
  },
  {
    "text": "So basically in\nthe Markov chain, the rate at which I pick\nthe i state from the j one",
    "start": "328150",
    "end": "333940"
  },
  {
    "text": "as a potential next step in\nthe Markov chain is symmetric. It's the same as the rate\nat which I pick the j",
    "start": "333940",
    "end": "339940"
  },
  {
    "text": "state from the i state. j to i and i to j is the same. You don't necessarily\nhave to do that.",
    "start": "339940",
    "end": "346970"
  },
  {
    "text": "You can actually\nmake these rates-- so these are the picking\nrates, the rates at which I",
    "start": "346970",
    "end": "352300"
  },
  {
    "text": "try one state from the other,\nnon-symmetric, and even more, you can make them dependent\non the Hamiltonian.",
    "start": "352300",
    "end": "361030"
  },
  {
    "text": "And why would you\nwant to do that? I'll show you an\nexample in a second. It's a way of forcing systems\ndownhill in energy space",
    "start": "361030",
    "end": "367569"
  },
  {
    "text": "much faster. So as long as you're correct in\nyour detailed balance argument,",
    "start": "367570",
    "end": "374110"
  },
  {
    "text": "you'll be OK. So the important thing is\nthe detailed balance criteria because the detailed balance\ncriteria is the one that",
    "start": "374110",
    "end": "381730"
  },
  {
    "text": "ultimately ensures that\nyou sample phase space or that you weigh\nstates and phase space",
    "start": "381730",
    "end": "387699"
  },
  {
    "text": "with the correct probability. And so as long as\nyou correct here-- so if you changed\nthe W0, you can still",
    "start": "387700",
    "end": "397270"
  },
  {
    "text": "get satisfied detail balanced\nby essentially changing what the acceptance rates are.",
    "start": "397270",
    "end": "402760"
  },
  {
    "text": "PI to J and PJ to I. You\ncan write out what they are. Essentially the\nratio of PIJ to PJI",
    "start": "402760",
    "end": "410440"
  },
  {
    "text": "is the factor we had\nbefore, but now you correct by the relative\nweight, which we",
    "start": "410440",
    "end": "418539"
  },
  {
    "text": "did the picking of the states. OK? So in the end it's a\nfairly trivial correction.",
    "start": "418540",
    "end": "424227"
  },
  {
    "start": "424227",
    "end": "429840"
  },
  {
    "start": "429000",
    "end": "524000"
  },
  {
    "text": "I haven't seen too many examples\nof this, but one is this one. It's force-bias\nMonte Carlo, which",
    "start": "429840",
    "end": "435720"
  },
  {
    "text": "almost looks like a\nhybrid between Monte Carlo and molecular dynamics. ",
    "start": "435720",
    "end": "443992"
  },
  {
    "text": "You know, I've given you several\ntimes this example of a liquid. How would you sample a liquid?",
    "start": "443993",
    "end": "450190"
  },
  {
    "text": "In Monte Carlo, you just could\npick random displacements of an atom within a given range. ",
    "start": "450190",
    "end": "458020"
  },
  {
    "text": "One way to actually drive\nthe system to low energy faster is not take a random\ndisplacement of the atoms,",
    "start": "458020",
    "end": "465430"
  },
  {
    "text": "but take one that's biased\nalong the force on that atom. If you move an atom\ndown with force,",
    "start": "465430",
    "end": "470950"
  },
  {
    "text": "you're obviously going to\nlower the energy mathematically because the force is the\ngradient of the energy.",
    "start": "470950",
    "end": "477400"
  },
  {
    "text": "So you could take a\ndisplacement factor",
    "start": "477400",
    "end": "483150"
  },
  {
    "text": "that has a random component and\nthat has some component that depends on the force.",
    "start": "483150",
    "end": "489720"
  },
  {
    "text": "Actually if you\nonly do this, that's actually how a lot of static\nrelaxation schemes work.",
    "start": "489720",
    "end": "498492"
  },
  {
    "text": "For example, in density\nfunctional theory you calculate the\nforces on atoms and then you relax them assuming\na certain spring constant",
    "start": "498492",
    "end": "505160"
  },
  {
    "text": "typically. But because you still\nhave a random element, this is probably somewhat better\ndescribed as mixed dynamics",
    "start": "505160",
    "end": "514130"
  },
  {
    "text": "Monte Carlo methods. And if you would like\nto read more about it, I think this was one\nof the first papers",
    "start": "514130",
    "end": "519526"
  },
  {
    "text": "that kind of introduced them. ",
    "start": "519527",
    "end": "526100"
  },
  {
    "start": "524000",
    "end": "917000"
  },
  {
    "text": "So what I want to do is a\ncouple more case studies and then show you some\nof the complications that",
    "start": "526100",
    "end": "533060"
  },
  {
    "text": "can arise when you do difficult\nsystems with Monte Carlo and see how we solve\nthem, and that'll lead us",
    "start": "533060",
    "end": "539750"
  },
  {
    "text": "into free energy integration. So this is sort of\na classic paper on--",
    "start": "539750",
    "end": "545990"
  },
  {
    "text": "it's from 1985-- using\nMonte Carlo to study surface segregation in copper nickel.",
    "start": "545990",
    "end": "552140"
  },
  {
    "text": "It uses the embedded atom\nmethod as a potential so, one of the reasons I\npicked it because it integrates a lot of the\nthings you've seen in class.",
    "start": "552140",
    "end": "559950"
  },
  {
    "text": "So the idea was to take\nrandom copper nickel alloys and see which element\nsegregates to the surface",
    "start": "559950",
    "end": "566540"
  },
  {
    "text": "and then see how the segregation\npattern away from the surface is, because there's\nbeen a lot of discussion",
    "start": "566540",
    "end": "572060"
  },
  {
    "text": "about that in the literature,\nespecially around that time. So what they do is they set up,\njust like you would probably,",
    "start": "572060",
    "end": "580520"
  },
  {
    "text": "supercells. So I think they either\nhad 24 or 24 or 48 layers,",
    "start": "580520",
    "end": "592700"
  },
  {
    "text": "and then with a certain width. So here's your supercell. ",
    "start": "592700",
    "end": "599870"
  },
  {
    "text": "Again, you can define your\nHamiltonian multiple ways. You could just seed the system\nwith a particular concentration",
    "start": "599870",
    "end": "608090"
  },
  {
    "text": "and then you have to decide\nwhich kind of Monte Carlo moves to allow.",
    "start": "608090",
    "end": "613580"
  },
  {
    "text": "A copper nickel form\n[INAUDIBLE] solid solutions. So what kind of\nmoves would you do",
    "start": "613580",
    "end": "618589"
  },
  {
    "text": "to equilibrate the system if\nyou had to set this up yourself?",
    "start": "618590",
    "end": "623620"
  },
  {
    "start": "623620",
    "end": "630770"
  },
  {
    "text": "So again, essentially you\nwould seed the system, probably with some concentration\nof copper and nickel",
    "start": "630770",
    "end": "641500"
  },
  {
    "text": "except that there's\na lot more atoms. So how would you do a\nMonte Carlo on this?",
    "start": "641500",
    "end": "646830"
  },
  {
    "text": "Remember that you're going\nto have an embedded atom Hamiltonian\nessentially, so it's one that you can fairly\nrapidly evaluate.",
    "start": "646830",
    "end": "653680"
  },
  {
    "text": "So in the end, it's a very\nsimple energy function. It's a bunch of\npairwise sums and then",
    "start": "653680",
    "end": "659450"
  },
  {
    "text": "you just stick the result in\na function and you're done. It's not like quantum mechanics.",
    "start": "659450",
    "end": "664459"
  },
  {
    "text": "You have, essentially, a\nHamiltonian you can abuse, so it's important to realize.",
    "start": "664460",
    "end": "669890"
  },
  {
    "text": "So how would you do\nMonte Carlo on this? ",
    "start": "669890",
    "end": "678262"
  },
  {
    "text": "This is the one thing-- Monte Carlo is about\nchoosing your perturbations, the rest is automatic\nafter that essentially.",
    "start": "678262",
    "end": "685709"
  },
  {
    "text": "It's just doing\nit a lot of times. So how would you\nequilibrate the system?",
    "start": "685710",
    "end": "690880"
  },
  {
    "start": "690880",
    "end": "696208"
  },
  {
    "text": "It's too early in the morning,\nyou're all still equilibrated. ",
    "start": "696208",
    "end": "704140"
  },
  {
    "text": "So first of all, you need\nto segregate some species to the surface assuming\nthere will be segregation.",
    "start": "704140",
    "end": "709730"
  },
  {
    "text": "So how do you do that? Again, you could\ndo diffusive hops.",
    "start": "709730",
    "end": "715810"
  },
  {
    "text": "Diffusive like hops, so do\ncanonical like interchanges. You could interchange\nthem nearby",
    "start": "715810",
    "end": "723400"
  },
  {
    "text": "or you could interchange\nthem far away. I got to stick to\nmy colors here. So you could interchange\npositions of copper and nickel,",
    "start": "723400",
    "end": "731920"
  },
  {
    "text": "but again, the slightly\nfaster way to do it is to do it grand canonically,\nto define actually",
    "start": "731920",
    "end": "737029"
  },
  {
    "text": "a Hamiltonian that's the energy\nminus mu copper, n copper",
    "start": "737030",
    "end": "745780"
  },
  {
    "text": "minus from mu nickel, n nickel.",
    "start": "745780",
    "end": "751130"
  },
  {
    "text": "OK? And since you're actually\ngoing to be interchanging the identity of atoms,\nn copper and n nickel",
    "start": "751130",
    "end": "760520"
  },
  {
    "text": "are not independent variables. You keep total number\nof atoms constant.",
    "start": "760520",
    "end": "766650"
  },
  {
    "text": "So you can actually write this\nas E minus mu copper minus mu",
    "start": "766650",
    "end": "772410"
  },
  {
    "text": "nickle times n copper,\nsince any change of a nickel",
    "start": "772410",
    "end": "777829"
  },
  {
    "text": "is compensated by\na change of copper. So we have essentially only one\ncontrolling chemical potential,",
    "start": "777830",
    "end": "782990"
  },
  {
    "text": "which is the difference of\nthe two species chemical potentials. OK.",
    "start": "782990",
    "end": "788089"
  },
  {
    "text": "Yes, sir? AUDIENCE: If a [INAUDIBLE]\nin a specific ratio, nickel or copper, [INAUDIBLE] very\nlong to find the correct value",
    "start": "788090",
    "end": "794015"
  },
  {
    "text": "of [INAUDIBLE]? ",
    "start": "794015",
    "end": "799279"
  },
  {
    "text": "GERBRAND CEDER: Yes. AUDIENCE: [INAUDIBLE] GERBRAND CEDER: Yes.",
    "start": "799280",
    "end": "804570"
  },
  {
    "text": "Yes, so you're controlling the\nexternal chemical potential,",
    "start": "804570",
    "end": "810920"
  },
  {
    "text": "so you don't control\nthe composition. True. ",
    "start": "810920",
    "end": "816135"
  },
  {
    "text": "What people sometimes\ndo is that-- what's of interest to you is the\nbulk chemical potential, that's",
    "start": "816135",
    "end": "825150"
  },
  {
    "text": "the source for the surface. You first do bulk\nsimulations and then you roughly know what\nchemical potential corresponds",
    "start": "825150",
    "end": "832710"
  },
  {
    "text": "to what compositions, because\nit's actually a little tricky. While energetically often,\nthe center of the system",
    "start": "832710",
    "end": "840990"
  },
  {
    "text": "does not influence\nthe surface much so you think you\nhave convergence. You still deplete\nit as a reservoir",
    "start": "840990",
    "end": "847620"
  },
  {
    "text": "as you segregate one\nspecies to the surface, so that's sometimes\nwhy you actually need more bulk in the system.",
    "start": "847620",
    "end": "853230"
  },
  {
    "text": "But yes, what you say is true. If you're only interested\nin one composition it can be better to\nstick there with that.",
    "start": "853230",
    "end": "860540"
  },
  {
    "text": "OK. But let's say you do\nthese exchange moves. ",
    "start": "860540",
    "end": "866000"
  },
  {
    "text": "Do you do it on a lattice? Do you do it in sort\nof a continuous space? I mean, how would you do it?",
    "start": "866000",
    "end": "871399"
  },
  {
    "text": " This is an FCC solid. This is an FCC solid solution.",
    "start": "871400",
    "end": "878540"
  },
  {
    "text": "So you could if you want to do\nit on a lattice, but would you? So you know what I\nmean with a lattice?",
    "start": "878540",
    "end": "884210"
  },
  {
    "text": "You have pre-defined positions\nwhere the atoms can sit. ",
    "start": "884210",
    "end": "894511"
  },
  {
    "text": "Somebody has to be\nable to say something. I'm just going to stand here. And it's not good because\nyou're being taped for OCW,",
    "start": "894512",
    "end": "902512"
  },
  {
    "text": "so they're going\nto think these MIT students have nothing to say. ",
    "start": "902512",
    "end": "908829"
  },
  {
    "text": "Somebody in Western\nAfrica sees this they're going to go\nlike, why did they let these people in at MIT?",
    "start": "908830",
    "end": "913940"
  },
  {
    "text": " So what else would you add?",
    "start": "913940",
    "end": "919883"
  },
  {
    "start": "917000",
    "end": "1204000"
  },
  {
    "text": "First of all, if you do\nit on a fixed lattice, think of what you end up\nwith thermodynamically? What have you sampled?",
    "start": "919883",
    "end": "925970"
  },
  {
    "text": "If you're on a fixed\nlattice, you've sampled the configurational\nentropy, essentially",
    "start": "925970",
    "end": "931850"
  },
  {
    "text": "the possible distributions\nof copper and nickel on these fixed lattice sites. But if one atom is\nbigger than the other,",
    "start": "931850",
    "end": "939140"
  },
  {
    "text": "for example, then they don't\nsit on a fixed lattice, then atoms will relax away\nfrom lattice positions.",
    "start": "939140",
    "end": "946520"
  },
  {
    "text": "You will also not sample\nvibrational excitation because you never go away\nfrom your lattice position.",
    "start": "946520",
    "end": "952790"
  },
  {
    "text": "So you could add\nsmall displacements to the perturbations. So remember, you\ndo the sort of big",
    "start": "952790",
    "end": "959410"
  },
  {
    "text": "into the chemical interchange\nas you interchange copper to nickel, but then\nto that you could add",
    "start": "959410",
    "end": "965199"
  },
  {
    "text": "small displacements of the atoms\nso you not sample deviations from their\nequilibrium positions.",
    "start": "965200",
    "end": "970780"
  },
  {
    "text": "And if you're done\nthem, then you'll have both configurational\nand vibrational entropy.",
    "start": "970780",
    "end": "976360"
  },
  {
    "text": "So remember that by the\npossible perturbations",
    "start": "976360",
    "end": "981440"
  },
  {
    "text": "you pick for your system,\nyou are essentially defining the phase space you sample.",
    "start": "981440",
    "end": "987220"
  },
  {
    "text": "So you're defining this phase\nspace you integrate over and that's essentially telling\nyou what forms of entropy",
    "start": "987220",
    "end": "994570"
  },
  {
    "text": "you allow in your system. Because, you know, what forms\nof entropy is the same as what",
    "start": "994570",
    "end": "1000710"
  },
  {
    "text": "forms of disorder or excitations\nI allow in your system. OK?",
    "start": "1000710",
    "end": "1005900"
  },
  {
    "text": "So the cool thing\nabout it is that you can look at the effects of both,\nand I'll show that in a bit.",
    "start": "1005900",
    "end": "1012025"
  },
  {
    "text": "You could actually\nsay, first I'm going to do it on\na rigid lattice and I'll see the\nresult, and then",
    "start": "1012025",
    "end": "1017660"
  },
  {
    "text": "I'll also include displacement\naway from the rigid lattice and you can look\nat the difference,",
    "start": "1017660",
    "end": "1022670"
  },
  {
    "text": "and that's essentially\ntelling you what the effect of\nvibrational excitations",
    "start": "1022670",
    "end": "1027679"
  },
  {
    "text": "are on your thermodynamics. OK, so here's the result.\nYou know this was 1985?",
    "start": "1027680",
    "end": "1045079"
  },
  {
    "text": "You'd be amazed how\neasy this is to do now if you wanted to do\nsomething like this yourself. With a Hamiltonian-like embedded\natom it really goes very fast",
    "start": "1045079",
    "end": "1053270"
  },
  {
    "text": "and you could equilibrate\nsystems like this in no time. But here's the\nresult. So this is a function of the bulk\nconcentration of copper.",
    "start": "1053270",
    "end": "1062690"
  },
  {
    "text": "This is the amount of\ncopper in the first and second and third layer. So the green curve\nis the first layer.",
    "start": "1062690",
    "end": "1069570"
  },
  {
    "text": "So clearly, copper segregates\nto the surface in this material. So as you can see, even\nfor 20% copper in the bulk",
    "start": "1069570",
    "end": "1078049"
  },
  {
    "text": "you have an almost perfect\ncopper layer on the surface. I think this was\nactually a 111 surface.",
    "start": "1078050",
    "end": "1084830"
  },
  {
    "text": "Copper in the second layer,\ninterestingly, is depleted. ",
    "start": "1084830",
    "end": "1091960"
  },
  {
    "text": "So it's actually below the\naverage bulk concentration. And then copper\nin the third layer",
    "start": "1091960",
    "end": "1098350"
  },
  {
    "text": "essentially starts tracking\nthe bulk concentration. So why do you think the\ncopper in the second layer",
    "start": "1098350",
    "end": "1109750"
  },
  {
    "text": "is depleted? ",
    "start": "1109750",
    "end": "1117130"
  },
  {
    "text": "Because first of all, why\ndoes copper go to the surface? It has a lower surface energy,\nso this is not rocket science.",
    "start": "1117130",
    "end": "1125277"
  },
  {
    "text": "Most of the time the thing\nwith the lower surface energy goes to the surface. OK?",
    "start": "1125277",
    "end": "1130940"
  },
  {
    "text": "But why is depleted\nin the second layer? Because I sort of\nthink, well, this is the lower surface energy.",
    "start": "1130940",
    "end": "1136789"
  },
  {
    "text": "Even in the second layer\nit's not perfectly bonded, so maybe it still wants to\nenhance its concentration there",
    "start": "1136790",
    "end": "1143299"
  },
  {
    "text": "but actually depletes it. This is not atypical, it's very\ncommon surface concentration.",
    "start": "1143300",
    "end": "1150600"
  },
  {
    "text": " It's actually because copper\nand nickel in this system",
    "start": "1150600",
    "end": "1156150"
  },
  {
    "text": "have an ordering interaction. So it's the fact that the first\nlayer is almost pure copper,",
    "start": "1156150",
    "end": "1164260"
  },
  {
    "text": "but the second layer,\nfor chemical reasons, really wants to be nickel.",
    "start": "1164260",
    "end": "1169500"
  },
  {
    "text": "OK? And this is a pure\nsurface effect. Copper and nickel in\nthe bulk are actually at low temperature\nphase separating,",
    "start": "1169500",
    "end": "1176130"
  },
  {
    "text": "but in the surface\nbecause of strain effects they form an\nordering interaction. And so the second layer\nwants to be nickel",
    "start": "1176130",
    "end": "1182370"
  },
  {
    "text": "because the first layer\nis so much copper. And so you often see this\nin compound forming systems",
    "start": "1182370",
    "end": "1189059"
  },
  {
    "text": "that you have\ndamped oscillations in the concentration\naway from the surface.",
    "start": "1189060",
    "end": "1195240"
  },
  {
    "start": "1195240",
    "end": "1205070"
  },
  {
    "start": "1204000",
    "end": "1547000"
  },
  {
    "text": "OK. So I want to show you one\nexample of something that gets much more\ncomplicated, and you'll",
    "start": "1205070",
    "end": "1212630"
  },
  {
    "text": "see how you start running into\nproblems with Monte Carlo. So I've shown you a little\nbit how you would detect phase",
    "start": "1212630",
    "end": "1220460"
  },
  {
    "text": "transitions in Monte Carlo. You'd look at things\nlike the heat capacity especially, particularly\npowerful for detecting",
    "start": "1220460",
    "end": "1226730"
  },
  {
    "text": "second order transitions. For first order transitions,\nyou look at discontinuities",
    "start": "1226730",
    "end": "1232280"
  },
  {
    "text": "in things like\nthe energy, things like the relation between mu\nand see chemical potential",
    "start": "1232280",
    "end": "1237649"
  },
  {
    "text": "and concentration, and\nyou'll pick that up. The problem you'll face is\noften that Monte Carlo systems,",
    "start": "1237650",
    "end": "1243770"
  },
  {
    "text": "just like real systems, often\nface significant hysteresis. So here's an example from\nquite a few years ago",
    "start": "1243770",
    "end": "1252770"
  },
  {
    "text": "of a fairly complicated\nlattice model Hamiltonian. This, again, was\non an FCC lattice. This is the palladium\nvanadium system, OK?",
    "start": "1252770",
    "end": "1259820"
  },
  {
    "text": "Phase diagram. This is palladium on this\nside, this side is vanadium, and this is a lattice model\nwith a bunch of interactions",
    "start": "1259820",
    "end": "1268220"
  },
  {
    "text": "in the Hamiltonian. A nearest neighbor pair,\nsecond neighbor pair, third neighbor pair, and so on.",
    "start": "1268220",
    "end": "1273680"
  },
  {
    "text": "Four body interactions, four\nbody here, three body here. It's a fairly\ncomplicated Hamiltonian",
    "start": "1273680",
    "end": "1279800"
  },
  {
    "text": "that tends to give you\na lot of local minima and how would you get\nthis phase diagram? Well, what would you do?",
    "start": "1279800",
    "end": "1286670"
  },
  {
    "text": "Again, to equilibrate faster you\nwouldn't keep the concentration fixed, you would scan\nthe chemical potential",
    "start": "1286670",
    "end": "1293419"
  },
  {
    "text": "and evolve in concentration\nfrom one end to the other. OK?",
    "start": "1293420",
    "end": "1298880"
  },
  {
    "text": "Let me actually do\nthat on the next slide. ",
    "start": "1298880",
    "end": "1305412"
  },
  {
    "text": "So you have some\nchemical potential that gives you the difference\nin palladium and vanadium amounts or the concentration.",
    "start": "1305412",
    "end": "1311610"
  },
  {
    "text": " OK. And so you would\nplot something like--",
    "start": "1311610",
    "end": "1318190"
  },
  {
    "text": " so you would have a\ndriving chemical potential",
    "start": "1318190",
    "end": "1323420"
  },
  {
    "text": "and you would plot\nthe average spin, we'd say is a\nconcentration of vanadium. ",
    "start": "1323420",
    "end": "1331660"
  },
  {
    "text": "And let's say you scan\nat this temperature, so what would you see? If you start here, you would\ngo through a solid solution",
    "start": "1331660",
    "end": "1338890"
  },
  {
    "text": "regime. So you would see your\nconcentration go up when",
    "start": "1338890",
    "end": "1344350"
  },
  {
    "text": "you hit the two phase region. OK? The chemical potential\nis constant there,",
    "start": "1344350",
    "end": "1350278"
  },
  {
    "text": "so that means at that\nchemical potential you have a discontinuity\nin the concentration,",
    "start": "1350278",
    "end": "1356170"
  },
  {
    "text": "so this would go straight up.  Then you would go in\na single phase region.",
    "start": "1356170",
    "end": "1362240"
  },
  {
    "text": " OK? So in a single phase region,\nthe chemical potential",
    "start": "1362240",
    "end": "1369179"
  },
  {
    "text": "changes rapidly\nwith concentration. So there, you actually\ntend to be kind of flat.",
    "start": "1369180",
    "end": "1376090"
  },
  {
    "text": "It's not quite\nflat, but it tends to just be sloped a lot less.",
    "start": "1376090",
    "end": "1381280"
  },
  {
    "text": "Then you would, again, go\nin to a two phase region. So you would,\nagain, form a step.",
    "start": "1381280",
    "end": "1388419"
  },
  {
    "text": "You would go into\na single phase. So we basically see\nthis kind of behavior,",
    "start": "1388420",
    "end": "1395100"
  },
  {
    "text": "and where you have\nthese discontinuities in concentration, you would\nknow that there's a first order",
    "start": "1395100",
    "end": "1401730"
  },
  {
    "text": "transition. You could also plot the\nenergy, and the energy is discontinuous as well.",
    "start": "1401730",
    "end": "1408480"
  },
  {
    "text": "The internal energy system is\ndiscontinuous at a first order transition.",
    "start": "1408480",
    "end": "1413679"
  },
  {
    "text": "You don't necessarily see\nthings in the heat capacity. Now what happens in reality? ",
    "start": "1413680",
    "end": "1420490"
  },
  {
    "text": "If you think about it,\nif you come from this end so you have a\nsolid solution, you",
    "start": "1420490",
    "end": "1426450"
  },
  {
    "text": "go through two phase\nregion, and you have to form this\ncompound, which is called nickel [INAUDIBLE].",
    "start": "1426450",
    "end": "1431580"
  },
  {
    "text": "So often in Monte Carlo,\njust like in a real system, you have nucleation problems.",
    "start": "1431580",
    "end": "1436769"
  },
  {
    "text": "If you have to form a phase\nor an arrangement that's extremely different from the\nhost from which it forms,",
    "start": "1436770",
    "end": "1443340"
  },
  {
    "text": "it will often just not\nnucleate, and well, what happens is that you will overshoot.",
    "start": "1443340",
    "end": "1448980"
  },
  {
    "text": "So you will actually push the\ndisordered phase way too far out of equilibrium and\nthen at some point,",
    "start": "1448980",
    "end": "1456330"
  },
  {
    "text": "you will be so far\nout of equilibrium that you literally shoot\ninto the ordered phase.",
    "start": "1456330",
    "end": "1462450"
  },
  {
    "text": "And then what happens\nwhen you come back? You have hysteresis\nthe other way. ",
    "start": "1462450",
    "end": "1469880"
  },
  {
    "text": "So you'll overshoot the order\nphase sometimes and disorder, although disordering is\na little easier to do.",
    "start": "1469880",
    "end": "1474900"
  },
  {
    "text": "So just like in real systems at\nstrong first order conditions you'll see a lot of hysteresis,\nand it's often very hard",
    "start": "1474900",
    "end": "1484059"
  },
  {
    "text": "to get rid of. I think some of you may\nhave noticed that if you did the molecular dynamics lab.",
    "start": "1484060",
    "end": "1491559"
  },
  {
    "text": "Seeing first order transitions\nin a molecular dynamics lab, you also are often\nplagued with hysteresis.",
    "start": "1491560",
    "end": "1498830"
  },
  {
    "text": "I mean, if you study\nmelting, for example, it's very asymmetrical\nhysteresis. If you heat up a solid,\nit's pretty easy to melt it.",
    "start": "1498830",
    "end": "1507279"
  },
  {
    "text": "If you cool down a liquid,\nit's about impossible to nucleate the solid\nunless you force it.",
    "start": "1507280",
    "end": "1513670"
  },
  {
    "text": "So there you have enormous\namounts of hysteresis. So the point of this is that\nto study strong first order",
    "start": "1513670",
    "end": "1522370"
  },
  {
    "text": "transitions,\nsometimes the best way to find their transition\ntemperatures or concentrations",
    "start": "1522370",
    "end": "1528940"
  },
  {
    "text": "is not by direct simulation. Essentially, what\nyou need to do is go through a thermodynamic route.",
    "start": "1528940",
    "end": "1535130"
  },
  {
    "text": "Try to extract free energies\nand find where they cross, because first order\ntransitions are defined",
    "start": "1535130",
    "end": "1541510"
  },
  {
    "text": "by where free energies of\nthe two phases intersect, and that's by far the most\naccurate way of detecting",
    "start": "1541510",
    "end": "1548649"
  },
  {
    "start": "1547000",
    "end": "1816000"
  },
  {
    "text": "phase transitions. There's a real problem\nhere is that, how",
    "start": "1548650",
    "end": "1553930"
  },
  {
    "text": "do you get free energy? ",
    "start": "1553930",
    "end": "1560320"
  },
  {
    "text": "The fundamental difference\nbetween free energy and energy is that energy is\nan average quantity",
    "start": "1560320",
    "end": "1566920"
  },
  {
    "text": "and free energy is not. See, energy is the\naverage of something that is defined in the\nmicroscopic states.",
    "start": "1566920",
    "end": "1575200"
  },
  {
    "text": "For every microscopic\nstate I go through, I can define an energy, and\nthen the internal energy,",
    "start": "1575200",
    "end": "1581087"
  },
  {
    "text": "the thermodynamic\nenergy of the system is just the average\nof that quantity. For free energy or entropy--",
    "start": "1581087",
    "end": "1587590"
  },
  {
    "text": "which are essentially the same\nbecause if I know the entropy, I know the free energy--",
    "start": "1587590",
    "end": "1593080"
  },
  {
    "text": "it is not the average of\na quantity that's defined in the microscopic state.",
    "start": "1593080",
    "end": "1598235"
  },
  {
    "text": "You know? If you put the atoms\nin a fixed position somewhere with some velocity,\nthat's a microscopic state.",
    "start": "1598235",
    "end": "1606940"
  },
  {
    "text": "You cannot define\nthe entropy of that. The entropy is a property\nof the ensemble as a whole,",
    "start": "1606940",
    "end": "1612309"
  },
  {
    "text": "not of a given\nmacroscopic state. So entropy and free energy\ncannot be obtained as averages.",
    "start": "1612310",
    "end": "1619120"
  },
  {
    "text": "They're actually integrals. You can see that the entropy\nis a sum over all phase",
    "start": "1619120",
    "end": "1627730"
  },
  {
    "text": "space of this quantity,\nP log P. You can write the free energy same way as an\nintegrated quantity over all",
    "start": "1627730",
    "end": "1637850"
  },
  {
    "text": "of phase space of this quantity. If you rewrite it, you\nsort of see it better.",
    "start": "1637850",
    "end": "1644539"
  },
  {
    "text": "You are averaging something. If you look at this, you\nare averaging something",
    "start": "1644540",
    "end": "1649700"
  },
  {
    "text": "because you have a\nprobability here, but what's the quantity\nyou're averaging? It's essentially the\nfree energy itself.",
    "start": "1649700",
    "end": "1656670"
  },
  {
    "text": "So it's a quantity that's\nflat in phase space. OK? So that makes it extremely\ndifficult to sample.",
    "start": "1656670",
    "end": "1666020"
  },
  {
    "text": "Actually this is not a\nmathematical problem, this is a physical problem. It's just the same as\nwhat happens in nature.",
    "start": "1666020",
    "end": "1672919"
  },
  {
    "text": "You can measure energy,\nyou can measure volume, you cannot measure free energy. There are no free energy\nmeters because it's",
    "start": "1672920",
    "end": "1680900"
  },
  {
    "text": "an extensive quantity\nthat that is determined by the whole ensemble. You only really get free\nenergies ever indirectly.",
    "start": "1680900",
    "end": "1688642"
  },
  {
    "text": "You can get free\nenergy difference, but you get free energy\nby integrating lower order quantities.",
    "start": "1688642",
    "end": "1694039"
  },
  {
    "start": "1694040",
    "end": "1701400"
  },
  {
    "text": "OK, so you can write\nit as an average",
    "start": "1701400",
    "end": "1707430"
  },
  {
    "text": "but it's a little misleading. You can actually write it as\nthe average of this thing here.",
    "start": "1707430",
    "end": "1715620"
  },
  {
    "text": "If you can calculate\nthe exponential of beta the Hamiltonian and\naverage that over phase space--",
    "start": "1715620",
    "end": "1722303"
  },
  {
    "text": "and notice I didn't\nmake an error there. I did not drop a minus sign. It's the exponential\nof the positive beta",
    "start": "1722303",
    "end": "1728320"
  },
  {
    "text": "times the Hamiltonian. If you can average\nthat quantity, you can show that you can\nactually have the free energy.",
    "start": "1728320",
    "end": "1734770"
  },
  {
    "text": "And the proof is\ngiven here, it's sort of an almost trivial proof.",
    "start": "1734770",
    "end": "1739870"
  },
  {
    "text": "But you see that's\nkind of problematic. The Hamiltonian is an\nextensive quantity,",
    "start": "1739870",
    "end": "1746110"
  },
  {
    "text": "so it scales with the\nsize of the system. So you're taking the exponential\nof something that's extensive,",
    "start": "1746110",
    "end": "1753790"
  },
  {
    "text": "so that gets very big. So first of all, you can only\ndo this for finite systems and for systems that are\nreally, really small.",
    "start": "1753790",
    "end": "1760480"
  },
  {
    "text": "Because otherwise,\nessentially, that quantity, the exponential of beta the\nHamiltonian, the difference",
    "start": "1760480",
    "end": "1766660"
  },
  {
    "text": "between two states\nbecomes excessively large",
    "start": "1766660",
    "end": "1771670"
  },
  {
    "text": "as your system size gets\nbigger because that quantity in the exponential is extensive.",
    "start": "1771670",
    "end": "1777250"
  },
  {
    "text": "OK? You see, if I'm calculating the\nHamiltonian difference, say, between two phases, the\nHamiltonian value goes in there",
    "start": "1777250",
    "end": "1785799"
  },
  {
    "text": "as the extensive quantity. It's not the normalized one. It's not the one, say, per unit\ncell or something like that.",
    "start": "1785800",
    "end": "1793160"
  },
  {
    "text": "So that energy\ndifference is infinite in the extensive limit, OK?",
    "start": "1793160",
    "end": "1798370"
  },
  {
    "text": "So even if two phases only are\none joule a part per molecule, per mol set, one joule per mol.",
    "start": "1798370",
    "end": "1805450"
  },
  {
    "text": "In the extensive limit, they're\nstill an infinite energy apart. OK? So you can't practically\nactually sample that, so",
    "start": "1805450",
    "end": "1815250"
  },
  {
    "text": "how do people get free energies? Well, there are\nhundreds of papers",
    "start": "1815250",
    "end": "1821789"
  },
  {
    "start": "1816000",
    "end": "1941000"
  },
  {
    "text": "on free energy\nintegration and the reason that there's\nhundreds of papers is that it's such a difficult thing\nand everybody claims to have",
    "start": "1821790",
    "end": "1828990"
  },
  {
    "text": "the magic potion to do it. The first thing to realize\nis that you almost never need",
    "start": "1828990",
    "end": "1835590"
  },
  {
    "text": "free energy, you always\nneed free energy differences between two things, and\nthat's a powerful statement",
    "start": "1835590",
    "end": "1841290"
  },
  {
    "text": "because that's a lot\neasier to do as you'll see. The second thing is\nthat you probably shouldn't believe half of\nwhat you read in papers.",
    "start": "1841290",
    "end": "1849240"
  },
  {
    "text": "I used to track that\nfield and everybody said, oh, I have a great method\nto get free energies out",
    "start": "1849240",
    "end": "1855390"
  },
  {
    "text": "of a single simulation, because\nthat's sort of the problem. You'll see in a second that\nthe way we get free energy",
    "start": "1855390",
    "end": "1860490"
  },
  {
    "text": "is that we have\nto do Monte Carlo at a lot of different points\nto get the free energy at one point.",
    "start": "1860490",
    "end": "1867060"
  },
  {
    "text": "There's tons of papers\nthat write that you can do it with one simulation. Well, either implicitly\nthey do a lot of simulations",
    "start": "1867060",
    "end": "1873450"
  },
  {
    "text": "within that one and\njust call it one, or you can do it\nin limited cases",
    "start": "1873450",
    "end": "1879059"
  },
  {
    "text": "if you know a lot about the\nform of your phase space. So if you have extremely\nsimple Hamiltonians--",
    "start": "1879060",
    "end": "1886080"
  },
  {
    "text": "if I give you a nearest neighbor\nIsing model, the magnetic model which is the nearest\nneighbor interaction,",
    "start": "1886080",
    "end": "1892830"
  },
  {
    "text": "essentially the\namount of excitations out of the low energy\nstates there is very finite.",
    "start": "1892830",
    "end": "1898470"
  },
  {
    "text": "Like I said, you could\nflip one isolate, spin, you get a times j. So you could almost\nnumerically start writing out",
    "start": "1898470",
    "end": "1904821"
  },
  {
    "text": "what the free energy becomes. So in very simple models, if\nyou know the form of the phase",
    "start": "1904822",
    "end": "1910925"
  },
  {
    "text": "space, you can actually get\ntowards free energy models. In general, it's pretty\nmuch an unsolved problem.",
    "start": "1910925",
    "end": "1917280"
  },
  {
    "text": "And the way we\npractically get it is with three types of methods. One is free energy integration,\nand I put lambda integration",
    "start": "1917280",
    "end": "1925010"
  },
  {
    "text": "under there. I'll show in a\nsecond what it is. And the second one is\noverlapping distribution",
    "start": "1925010",
    "end": "1931130"
  },
  {
    "text": "methods, which is slightly\nless important, especially for solids. So it's really only 2 previous\nothers, which I used to cover",
    "start": "1931130",
    "end": "1940940"
  },
  {
    "text": "and I don't even do anymore now. OK. Let me first show you\noverlapping distribution methods, which I'm less familiar\nwith because I never use it,",
    "start": "1940940",
    "end": "1950180"
  },
  {
    "start": "1941000",
    "end": "2431000"
  },
  {
    "text": "but the idea of it\nis quite simple. So if you want to know the free\nenergy difference between two",
    "start": "1950180",
    "end": "1956659"
  },
  {
    "text": "states, remember that\nthe free energy is KT log the partition function q.",
    "start": "1956660",
    "end": "1961730"
  },
  {
    "text": "So the delta, the\ndifference is the log of the ratio of the\npartition function, OK?",
    "start": "1961730",
    "end": "1968020"
  },
  {
    "text": "You are with us? So you can write\nout what that is. The partition\nfunction is the sum",
    "start": "1968020",
    "end": "1974750"
  },
  {
    "text": "over all the states\nof the exponential of minus beta the Hamiltonian.",
    "start": "1974750",
    "end": "1979760"
  },
  {
    "text": "If I multiply this\nby 1-- and I'm going to multiply\nthis by 1, then I'm",
    "start": "1979760",
    "end": "1984980"
  },
  {
    "text": "going to write 1 as the\nexponential of beta H1.",
    "start": "1984980",
    "end": "1991190"
  },
  {
    "text": "Sorry. Got to be consistent here. H1 nu times exponential\nminus beta H1.",
    "start": "1991190",
    "end": "2000460"
  },
  {
    "text": "OK, so that's one. So then I can collect the\nterms here, and what I get",
    "start": "2000460",
    "end": "2006550"
  },
  {
    "text": "is that I get I still\nsum over all the states. I get the exponential,\nthe Hamiltonian difference",
    "start": "2006550",
    "end": "2013179"
  },
  {
    "text": "to n1 weighted by\nthe probability of this state in the\nensemble of Hamiltonian one.",
    "start": "2013180",
    "end": "2021100"
  },
  {
    "text": "This is essentially\nthe probability of that state is the\nexponential minus beta H",
    "start": "2021100",
    "end": "2026799"
  },
  {
    "text": "over the partition function\ntaken with Hamiltonian 1. So what have I written here?",
    "start": "2026800",
    "end": "2032740"
  },
  {
    "text": "The exponential of the\nprobability of that state weighted in Hamiltonian\n1 of this quantity.",
    "start": "2032740",
    "end": "2041539"
  },
  {
    "text": "So essentially,\nwhat I'm averaging is the exponential of minus\nbeta the Hamiltonian difference",
    "start": "2041540",
    "end": "2047649"
  },
  {
    "text": "between state two and\none, but I average it in the ensemble of one and\nthat gives me the free energy",
    "start": "2047650",
    "end": "2053800"
  },
  {
    "text": "difference. The reason that's called\noverlapping distribution",
    "start": "2053800",
    "end": "2062129"
  },
  {
    "text": "methods is that-- let me show you\nthat in a second-- you're trying to say\nsomething about state two,",
    "start": "2062130",
    "end": "2070669"
  },
  {
    "text": "but you're sampling in\nthe ensemble of one. So the only way this\nis ever going to work",
    "start": "2070670",
    "end": "2078980"
  },
  {
    "text": "is if one and 2 are not too far\napart so that the states that are relevant for two are also\nsampled to some extent when",
    "start": "2078980",
    "end": "2087919"
  },
  {
    "text": "you're in one, and that's\nwhy it's called overlapping distribution method. So if I sample in\none, essentially",
    "start": "2087920",
    "end": "2097280"
  },
  {
    "text": "let's look at the energy. I sample energy states around\nthe average with some spread,",
    "start": "2097280",
    "end": "2102875"
  },
  {
    "text": "spread could be\nthe heat capacity. If I'm in two I\ndo the same thing around the average\nenergy of two.",
    "start": "2102875",
    "end": "2109869"
  },
  {
    "text": "And essentially\nwhat I'm doing is I'm integrating things\nfor ensemble two",
    "start": "2109870",
    "end": "2115900"
  },
  {
    "text": "just by the way I walk\nthrough ensemble one. And so it's a relatively\nelegant way of doing it,",
    "start": "2115900",
    "end": "2125040"
  },
  {
    "text": "and the key aspect is that the\nstates in the two ensembles are the same. ",
    "start": "2125040",
    "end": "2132210"
  },
  {
    "text": "The ensembles are the same,\nso the accessible states are the same, it's just that\nyou weigh them differently.",
    "start": "2132210",
    "end": "2138390"
  },
  {
    "text": "So this is almost just like\nnon-Boltzmann sampling. I Boltzmann sample\nfor ensemble one,",
    "start": "2138390",
    "end": "2145250"
  },
  {
    "text": "but you could say I\nnon-Boltzmann sample for ensemble two and I correct\nthe probability and this is",
    "start": "2145250",
    "end": "2150920"
  },
  {
    "text": "how I get the free energy.  So you can already see when\nthis is not going to work.",
    "start": "2150920",
    "end": "2157430"
  },
  {
    "text": "This is not going to work when\nyour states are too far apart. ",
    "start": "2157430",
    "end": "2164680"
  },
  {
    "text": "OK. By far the most\nused method to get",
    "start": "2164680",
    "end": "2170200"
  },
  {
    "text": "free energy is sort of a\ntrivial one in some sense, it's free energy integration.",
    "start": "2170200",
    "end": "2176099"
  },
  {
    "text": "But it's the one\nthat always works if you put enough\ntime in it and it starts from this\nkind of trivial idea",
    "start": "2176100",
    "end": "2183520"
  },
  {
    "text": "that the difference\nin a quantity is the integral of the\ndifferential, which this is why",
    "start": "2183520",
    "end": "2190000"
  },
  {
    "text": "you come to MIT to learn this. So if I can actually\nsample this,",
    "start": "2190000",
    "end": "2199330"
  },
  {
    "text": "I may be able to\nget at the quantity simply by integrating that. And why is that important?",
    "start": "2199330",
    "end": "2204650"
  },
  {
    "text": "Because if A is a free\nenergy or an entropy, the derivatives of free\nenergies and entropies",
    "start": "2204650",
    "end": "2212110"
  },
  {
    "text": "are things that can be\nsampled because they tend to be either\naverages or fluctuations. For example, for\nthe entropy, you",
    "start": "2212110",
    "end": "2219580"
  },
  {
    "text": "wanted the entropy\ndifference between two states so you integrate the\nderivative of the entropy.",
    "start": "2219580",
    "end": "2225082"
  },
  {
    "text": "Well, the derivative\nof the entropy is the heat capacity\nand the heat capacity you can get from Monte Carlo.",
    "start": "2225082",
    "end": "2231430"
  },
  {
    "text": "The heat capacity is essentially\nthe fluctuation of the energy. ",
    "start": "2231430",
    "end": "2242250"
  },
  {
    "text": "So if you want to know the\nentropy at a given temperature, you start from some\nreference temperature",
    "start": "2242250",
    "end": "2248900"
  },
  {
    "text": "where you know the entropy or\nyou just fix it to some value if you want to reference\neverything to the same thing",
    "start": "2248900",
    "end": "2254960"
  },
  {
    "text": "and you integrate\nthe heat capacity. What do you take as\nreference states?",
    "start": "2254960",
    "end": "2260480"
  },
  {
    "text": "Well, again, you could just\nintegrate between two states and get the entropy difference. Often you start from 0.",
    "start": "2260480",
    "end": "2267349"
  },
  {
    "text": "If you start from 0\ntemperature in models with discrete degrees of\nfreedoms like the Ising",
    "start": "2267350",
    "end": "2273440"
  },
  {
    "text": "model, the spin model, the\nentropy is 0 at 0 Kelvin so that's an easy\nintegration state.",
    "start": "2273440",
    "end": "2279230"
  },
  {
    "text": "In some cases, you can also\nfind the entropy at infinity because in infinity, your\nphase space is random,",
    "start": "2279230",
    "end": "2285390"
  },
  {
    "text": "the probability\ndistribution is flat, and so sometimes you can get\nanalytically the entropy there.",
    "start": "2285390",
    "end": "2291170"
  },
  {
    "text": "So these are all proper\nreference states. ",
    "start": "2291170",
    "end": "2302040"
  },
  {
    "text": "So here's an example. This is, again, our very simple\n2D square magnetic Ising model.",
    "start": "2302040",
    "end": "2308690"
  },
  {
    "text": "You would essentially\nintegrate C over T, so you'd essentially integrate\nunder this curve from 0 up.",
    "start": "2308690",
    "end": "2316039"
  },
  {
    "text": "The way you practically\ndo it is that you wouldn't start from 0,\nbecause the reason is you're",
    "start": "2316040",
    "end": "2322010"
  },
  {
    "text": "integrating. So you're integrating C\nover T and that integral,",
    "start": "2322010",
    "end": "2332860"
  },
  {
    "text": "in reality of course,\nconverges as T goes to 0. But numerically, it will\nnever in your simulation",
    "start": "2332860",
    "end": "2339099"
  },
  {
    "text": "because T goes to 0\nand you force T to 0 in your simulation.",
    "start": "2339100",
    "end": "2344260"
  },
  {
    "text": "That's a well defined\nnumber, but the heat capacity will not go to 0 just\nbecause of numerical noise.",
    "start": "2344260",
    "end": "2352150"
  },
  {
    "text": "In reality, it\nshould be really 0, but what will actually\nhappen is that because of some minor noise\nand fluctuations,",
    "start": "2352150",
    "end": "2359110"
  },
  {
    "text": "we will get non-zero\nheat capacity. So you divide by a number\nthat gets exceedingly small",
    "start": "2359110",
    "end": "2364510"
  },
  {
    "text": "as you go to 0, and so\nyou're integral will blow up numerically. So what you typically do is\nyou look at your heat capacity",
    "start": "2364510",
    "end": "2371770"
  },
  {
    "text": "and say, well, below 0.5\nor 0.75 I essentially",
    "start": "2371770",
    "end": "2376810"
  },
  {
    "text": "have no heat capacity. That means all the\nway from 0 to there I have essentially no\nentropy, and you just",
    "start": "2376810",
    "end": "2383830"
  },
  {
    "text": "start integrating\nfrom 0.5 or 0.75. If you want to be\nmore accurate, there",
    "start": "2383830",
    "end": "2389470"
  },
  {
    "text": "are ways of analytically\nwriting the heat capacity from 0",
    "start": "2389470",
    "end": "2394990"
  },
  {
    "text": "to low temperature by\nthings like low temperature expansions. Essentially from\nhere to about here,",
    "start": "2394990",
    "end": "2401410"
  },
  {
    "text": "all that would ever happen\nis single spin flips. So you'd have this\nferromagnet sitting there,",
    "start": "2401410",
    "end": "2407320"
  },
  {
    "text": "once in a while one spin would\ngo, [FAST-SOUNDING WHISTLE].. So they're single\nexcitation so you can write out what the partition\nfunction pretty much looks",
    "start": "2407320",
    "end": "2414290"
  },
  {
    "text": "like. It's the groundstate energy plus\njust the first excited states.",
    "start": "2414290",
    "end": "2419320"
  },
  {
    "text": "So you can write\nout analytically what the entropy\nis up to that point",
    "start": "2419320",
    "end": "2424490"
  },
  {
    "text": "and then integrate from there. ",
    "start": "2424490",
    "end": "2433260"
  },
  {
    "start": "2431000",
    "end": "2764000"
  },
  {
    "text": "Practically you can integrate a\nwhole bunch of other variables. The one that if you\nintegrate from infinity",
    "start": "2433260",
    "end": "2440190"
  },
  {
    "text": "that's very practical is to use\nthe Gibbs-Helmholtz relation. Gibbs-Helmholtz\nrelation essentially",
    "start": "2440190",
    "end": "2446819"
  },
  {
    "text": "tells you that\nthe average energy is the derivative of\nthe free energy over T",
    "start": "2446820",
    "end": "2452580"
  },
  {
    "text": "with respect to 1 over T. This\nis actually a generic relation. If you think here the\naverage of any Hamiltonian",
    "start": "2452580",
    "end": "2462140"
  },
  {
    "text": "is actually the derivative of\nits corresponding free energy",
    "start": "2462140",
    "end": "2469349"
  },
  {
    "text": "over T with respect to 1 over T.",
    "start": "2469350",
    "end": "2474600"
  },
  {
    "text": "OK. So if you do this in\na canonical system, then you're Hamiltonian's\nlike the energy",
    "start": "2474600",
    "end": "2481140"
  },
  {
    "text": "minus mu times\nsome concentration. So then that's the average\nquantity you would get here.",
    "start": "2481140",
    "end": "2487470"
  },
  {
    "text": "Why is this useful? Because essentially now you're\nintegrating in 1 over T, so in beta, and that\nquantity is 0 when",
    "start": "2487470",
    "end": "2496020"
  },
  {
    "text": "you're at infinite temperature. So beta is 0 and\nT equals infinity. So now this is an easy way\nto integrate from infinity.",
    "start": "2496020",
    "end": "2504150"
  },
  {
    "text": "Why do you want\nintegrate from infinity? Like I said before, sometimes\nthat infinite temperature, you know the free\nenergy analytically,",
    "start": "2504150",
    "end": "2510510"
  },
  {
    "text": "because everything is totally\nrandom and so something that's a useful integration state.",
    "start": "2510510",
    "end": "2516420"
  },
  {
    "text": "Another one that's\nquite practical is simply integrating\nin composition,",
    "start": "2516420",
    "end": "2522698"
  },
  {
    "text": "and that's why I sort of\nshown this on this phase because it shows the three\nmajor ways of integration.",
    "start": "2522698",
    "end": "2529450"
  },
  {
    "text": "If you come from\nlow temperature, you integrate the heat capacity. If you come from\nhigh temperature,",
    "start": "2529450",
    "end": "2535109"
  },
  {
    "text": "you use the\nGibbs-Helmholtz relation to integrate the average\nHamiltonian, so the energy",
    "start": "2535110",
    "end": "2540609"
  },
  {
    "text": "most cases. If you come from the sides, you\nintegrate in composition space.",
    "start": "2540610",
    "end": "2546760"
  },
  {
    "text": "So you integrate\nessentially sigma d mu, and the reason is\nthat the composition--",
    "start": "2546760",
    "end": "2552825"
  },
  {
    "text": "let me write in regular\nthermodynamic variables-- is essentially derivative\nof free energy with respect",
    "start": "2552825",
    "end": "2559670"
  },
  {
    "text": "to the chemical potential. So when you integrate that-- I've written composition here\nas the average spin in a spin",
    "start": "2559670",
    "end": "2566090"
  },
  {
    "text": "model, so you integrate Cd\nmu, and that gives you dF",
    "start": "2566090",
    "end": "2572240"
  },
  {
    "text": "and so that's essentially\nwhat this here is. Why can you integrate\nfrom the sides?",
    "start": "2572240",
    "end": "2579080"
  },
  {
    "text": "Well, if you have pure 1-- so you call this A or\nB. If you have pure A,",
    "start": "2579080",
    "end": "2585020"
  },
  {
    "text": "you know the free\nenergy in many cases because if you have a model with\nonly configuration entropy when",
    "start": "2585020",
    "end": "2591490"
  },
  {
    "text": "you have pure A, you\nhave no configuration entropy so the free energy\nthere is just the energy.",
    "start": "2591490",
    "end": "2596700"
  },
  {
    "text": "OK? So in some sense, if you\nthink of this phase diagram as this line going to\ninfinity, you essentially",
    "start": "2596700",
    "end": "2603530"
  },
  {
    "text": "know the thermodynamic\nproperties at all four edges",
    "start": "2603530",
    "end": "2609840"
  },
  {
    "text": "and then you can integrate. This is by far the most accurate\nway of determining first order",
    "start": "2609840",
    "end": "2616440"
  },
  {
    "text": "transitions, by far. The reason is that\nyou can get the answer as accurately as you want it.",
    "start": "2616440",
    "end": "2622590"
  },
  {
    "text": "So you have to integrate\nnow along a path, that's the painful thing. So if I like the\nfree energy here,",
    "start": "2622590",
    "end": "2630150"
  },
  {
    "text": "I don't have to\njust simulate here, I have to simulate pretty\nmuch all the way up from here.",
    "start": "2630150",
    "end": "2635714"
  },
  {
    "text": "So rather than simulating\nat one set of conditions, I got to simulate\nalong a whole path. But the nice thing is that--",
    "start": "2635715",
    "end": "2641890"
  },
  {
    "text": "so where does your\nerror come from? It comes from things\nyou all control.",
    "start": "2641890",
    "end": "2648000"
  },
  {
    "text": "You know, how long I've\nsampled at each state to get the quantity I'm\nintegrating, like heat capacity",
    "start": "2648000",
    "end": "2653349"
  },
  {
    "text": "or energies. You can control that. If you want it better,\nyou sample longer. How many steps I take\nalong the integration path,",
    "start": "2653350",
    "end": "2659560"
  },
  {
    "text": "so now you're numerically\nintegrating along a part. If I want that more\naccurate, I take more steps.",
    "start": "2659560",
    "end": "2664880"
  },
  {
    "text": "So while it looks difficult,\nyou have all the properties under control. So that's the nice\nthing, that you",
    "start": "2664880",
    "end": "2670430"
  },
  {
    "text": "know how to make it better\nif you don't like the answer. ",
    "start": "2670430",
    "end": "2675772"
  },
  {
    "text": "The only thing to\nkeep in mind when you free energy integration,\nthat you have to iterate through equilibrium states.",
    "start": "2675772",
    "end": "2682660"
  },
  {
    "text": "These thermodynamic\nrelations do not hold when you're away\nfrom equilibrium states.",
    "start": "2682660",
    "end": "2688519"
  },
  {
    "text": "So if you integrate\nthrough transitions, then you want to be absolutely\nsure that that transition is",
    "start": "2688520",
    "end": "2697060"
  },
  {
    "text": "occurring in equilibrium,\nand that's often the problem, and that's why we combine\nall these schemes.",
    "start": "2697060",
    "end": "2702640"
  },
  {
    "text": "Like if I want to get,\nsay, this phase boundary, I would probably integrate\none phase up from here to here",
    "start": "2702640",
    "end": "2712270"
  },
  {
    "text": "and then I would integrate\neither the solid solution from the side or from\ninfinity to that point.",
    "start": "2712270",
    "end": "2719859"
  },
  {
    "text": "OK? So I would never try to get the\nsolid solution by integrating from the ordered phase\nthrough the transition",
    "start": "2719860",
    "end": "2727510"
  },
  {
    "text": "into the solid solution\nbecause I get way too much error from\nnon-equilibrium phenomena at the transition.",
    "start": "2727510",
    "end": "2735140"
  },
  {
    "text": "OK. ",
    "start": "2735140",
    "end": "2743940"
  },
  {
    "text": "Then we come to the last form of\nfree energy integration, which is a form of\nthermodynamic integration",
    "start": "2743940",
    "end": "2752070"
  },
  {
    "text": "that has a bit of a science\nfiction component to it. ",
    "start": "2752070",
    "end": "2757870"
  },
  {
    "text": "Come on. OK. Anyway, I think I've\nsaid all these things. What the advantages\nand disadvantages are,",
    "start": "2757870",
    "end": "2765100"
  },
  {
    "start": "2764000",
    "end": "2999000"
  },
  {
    "text": "thermodynamic integration. You can actually do something\na little more fancy or esoteric",
    "start": "2765100",
    "end": "2774029"
  },
  {
    "text": "in thermodynamic\nintegration, which tends to go by the name\nof lambda integration.",
    "start": "2774030",
    "end": "2779660"
  },
  {
    "text": "What I showed you before was you\nwere integrating with respect",
    "start": "2779660",
    "end": "2784700"
  },
  {
    "text": "to derivatives of\nphysical parameters, like temperature\nor concentration or 1 over temperature.",
    "start": "2784700",
    "end": "2792380"
  },
  {
    "text": "You can actually\nintegrate with respect to nonphysical parameters. For example, I may want\nto get the free energy",
    "start": "2792380",
    "end": "2799250"
  },
  {
    "text": "difference between\nsystems that have two different Hamiltonians.",
    "start": "2799250",
    "end": "2806230"
  },
  {
    "text": "What would that mean? Maybe I want to know\nhow to free energy change if I turn on a certain\ninteraction in the Hamiltonian.",
    "start": "2806230",
    "end": "2812349"
  },
  {
    "text": "Like maybe I want to know, I\nturn on Coulombic interactions and I want to know, how\ndoes this really affect the free energy of my system?",
    "start": "2812350",
    "end": "2819620"
  },
  {
    "text": "Maybe I want to add a particle. You could think of actually\nchanging the temperature as a way of changing\nyour Hamiltonian,",
    "start": "2819620",
    "end": "2825907"
  },
  {
    "text": "because the thing you\nput in the exponential is beta times Hamiltonian, so\nit's really kind of one unit.",
    "start": "2825907",
    "end": "2831430"
  },
  {
    "text": "It's when you\nchange that product that you're changing something\nto the probability density.",
    "start": "2831430",
    "end": "2836950"
  },
  {
    "text": "I'll show you some cool\nexamples of this in a second, but let me show\nyou how it works.",
    "start": "2836950",
    "end": "2843619"
  },
  {
    "text": "So now you're going to integrate\nalong a path of lambda that essentially describes how\nyou go from Hamiltonian 1",
    "start": "2843620",
    "end": "2850990"
  },
  {
    "text": "to Hamiltonian 2. And Hamiltonian 2 could be\ntotally different physics, it could be different\nchemistry, whatever.",
    "start": "2850990",
    "end": "2858380"
  },
  {
    "text": "So I'm going to\nwrite the Hamiltonian as a linear combination of the\nHamiltonians of 1 and 2, OK?",
    "start": "2858380",
    "end": "2865630"
  },
  {
    "text": "So now you see, as\nlambda goes from 0 to 1, if I'm 0 I have\nHamiltonian 1, if I'm",
    "start": "2865630",
    "end": "2870910"
  },
  {
    "text": "one I have Hamiltonian 2. OK? So the integral\n0 to 1 for lambda defines the past one\nwhich I integrate.",
    "start": "2870910",
    "end": "2878368"
  },
  {
    "text": "So what I want to\nknow is essentially the free energy between\nlambda is 1 and 0-- but I'll get the free\nenergy along the whole path,",
    "start": "2878368",
    "end": "2885130"
  },
  {
    "text": "as you'll see in a second. You can see how\nyou can get that. If you look at the derivative\nof the free energy with respect",
    "start": "2885130",
    "end": "2892240"
  },
  {
    "text": "to lambda, well, the\nfree energy is the log of the partition function.",
    "start": "2892240",
    "end": "2897890"
  },
  {
    "text": "So if I take the\nderivative of that, you can sort of\ndo the math here. If I take a derivative\nof these exponentials",
    "start": "2897890",
    "end": "2903700"
  },
  {
    "text": "I get the exponential\nback, so that's going to give me a\npartition function. Because remember, if I\ntake derivative of the log",
    "start": "2903700",
    "end": "2910329"
  },
  {
    "text": "I get 1 over this thing. So you know, I get log z. When you take the derivative of\nthat, I'm going to get 1 over z",
    "start": "2910330",
    "end": "2916660"
  },
  {
    "text": "and then times d, z,\nd, whatever I'm taking the derivative of with respect.",
    "start": "2916660",
    "end": "2922540"
  },
  {
    "text": "So that gives me that\npartition function here. And then I take the derivative\nof what's inside the log",
    "start": "2922540",
    "end": "2928120"
  },
  {
    "text": "and that gives me this. And essentially what\nshows up is the derivative",
    "start": "2928120",
    "end": "2933700"
  },
  {
    "text": "of the Hamiltonian\nwith respect to lambda, and this is actually classic. This always happens. If you take any derivative\nof the partition function,",
    "start": "2933700",
    "end": "2941650"
  },
  {
    "text": "you essentially always end\nup with a weighted derivative of the Hamiltonian. And so what you see is\nthis is the probability,",
    "start": "2941650",
    "end": "2948790"
  },
  {
    "text": "this exponential weighted\nby q is the probability. So essentially what this\nfree energy derivative is,",
    "start": "2948790",
    "end": "2956820"
  },
  {
    "text": "it's the average of the\nderivative of the Hamiltonian with respect to lambda. OK?",
    "start": "2956820",
    "end": "2962310"
  },
  {
    "text": "This is actually quite generic\nin statistical mechanics.",
    "start": "2962310",
    "end": "2967330"
  },
  {
    "text": "So the quantity that you need\nto integrate is this derivative.",
    "start": "2967330",
    "end": "2972930"
  },
  {
    "text": "Now if we've linearized\nour Hamiltonian, that derivative is just\nHamiltonian difference.",
    "start": "2972930",
    "end": "2978570"
  },
  {
    "text": "OK? But this is actually\nmore generically true. But if you linearize\nit, all you need to do",
    "start": "2978570",
    "end": "2984720"
  },
  {
    "text": "is average the\nHamiltonian difference. ",
    "start": "2984720",
    "end": "3001690"
  },
  {
    "start": "2999000",
    "end": "3256000"
  },
  {
    "text": "So I'm going to show\nyou an example which I got out of this paper,\nwhich is hidden here by--",
    "start": "3001690",
    "end": "3008210"
  },
  {
    "text": "kind of move this thing. There we go. ",
    "start": "3008210",
    "end": "3013677"
  },
  {
    "text": "And this was a study\nwhere they wanted to look at the effects\nof a water dipole",
    "start": "3013677",
    "end": "3020270"
  },
  {
    "text": "on the free energy of water. And so the reason you have a\ndipole in water is, of course,",
    "start": "3020270",
    "end": "3026077"
  },
  {
    "text": "you have H2O--  how does this work again?",
    "start": "3026077",
    "end": "3031280"
  },
  {
    "text": "So the hydrogens are\nslightly positively charged and so this is then minus\n2 times that quantity.",
    "start": "3031280",
    "end": "3039260"
  },
  {
    "text": "And so because of that, you of\ncourse, have a dipole which-- does a dipole point from\npositive to negative",
    "start": "3039260",
    "end": "3047090"
  },
  {
    "text": "or, yeah, from negative\nto positive dipoles? Well, whatever. We'll define it this way.",
    "start": "3047090",
    "end": "3053660"
  },
  {
    "text": "So you have a dipole moment\nand in a simple simulation,",
    "start": "3053660",
    "end": "3059329"
  },
  {
    "text": "you can essentially\njust represent the water by its dipole, nothing else.",
    "start": "3059330",
    "end": "3065510"
  },
  {
    "text": "No atoms, no molecules. So you want to look at\nthe dipole interactions between water.",
    "start": "3065510",
    "end": "3071030"
  },
  {
    "text": "Now if you want to look at\nhow does the free energies change with the strength of\nthat dipole, for example,",
    "start": "3071030",
    "end": "3077789"
  },
  {
    "text": "you could write dipolar strength\nin terms of some parameter",
    "start": "3077790",
    "end": "3082910"
  },
  {
    "text": "lambda, and that's\nwhat I've done here. So the positive and the\nnegative charge in the dipole",
    "start": "3082910",
    "end": "3088460"
  },
  {
    "text": "depend on the parameter\nlambda, and so essentially what I'm going to do is\nlook at the free energy as a function of lambda.",
    "start": "3088460",
    "end": "3094460"
  },
  {
    "text": " And let me show\nyou how it works.",
    "start": "3094460",
    "end": "3100400"
  },
  {
    "text": "The green line here, there's a\nfew too many lines on this plot unfortunately. This is the exact result--",
    "start": "3100400",
    "end": "3105605"
  },
  {
    "text": " and actually, this\nwas well parameterized",
    "start": "3105605",
    "end": "3112350"
  },
  {
    "text": "because at 0 and 1 you\nshould get the same answer because when lambda is 1, the\ndipole is the same as at 0,",
    "start": "3112350",
    "end": "3119180"
  },
  {
    "text": "it's just inverted the\nplus n minus charge. OK? So the purple line is what they\ngot with lambda integrations",
    "start": "3119180",
    "end": "3128099"
  },
  {
    "text": "paper, so it does pretty well. I mean it's this\nline here, sorry. But what you see is there's\nof course a bit of error.",
    "start": "3128100",
    "end": "3134640"
  },
  {
    "text": "This point should be the\nsame as that point, OK? And so you clearly see that\nthey accumulated some error",
    "start": "3134640",
    "end": "3142650"
  },
  {
    "text": "along the integration path. And if you're really\nhard core computational",
    "start": "3142650",
    "end": "3148320"
  },
  {
    "text": "and you think this is\nfun, this is one way you can check your integration\nerrors is essentially",
    "start": "3148320",
    "end": "3154140"
  },
  {
    "text": "do a circular integration\nin your phase space. So not only go from Hamil\nstate 1 to 2, but come back",
    "start": "3154140",
    "end": "3164160"
  },
  {
    "text": "and you essentially\nhave some idea of the error you've accumulated\nalong the integration path. ",
    "start": "3164160",
    "end": "3173970"
  },
  {
    "text": "This one, the next one\nI like as an example. This is starting to get\nvery close to alchemy.",
    "start": "3173970",
    "end": "3181620"
  },
  {
    "text": "You know, in the old days people\ntried to turn lead into gold. This is getting pretty close.",
    "start": "3181620",
    "end": "3187530"
  },
  {
    "text": "You can look at\nthree energy changes literally by changing chemistry.",
    "start": "3187530",
    "end": "3194880"
  },
  {
    "text": "I know nothing about\norganic chemistry, but I think that ring\nthere is called the phenyl and so you can put different\ngroups on the phenyl",
    "start": "3194880",
    "end": "3201690"
  },
  {
    "text": "and if you put chlorine\non it, it's chlorophenyl. If you pull a methyl\ngroup on its methylphenyl,",
    "start": "3201690",
    "end": "3207480"
  },
  {
    "text": "and if you put a cyan\ngroup it's cyanophenyl. So there's clearly some\nlogic in chemical names.",
    "start": "3207480",
    "end": "3215670"
  },
  {
    "text": "But for example, you\ncould write a Hamiltonian that slowly changes one of\nthese species into another one.",
    "start": "3215670",
    "end": "3223224"
  },
  {
    "text": "And what does that\nmean, slowly change? That means that you\nmix the interaction. Let's say you did\nthis with potential,",
    "start": "3223225",
    "end": "3228630"
  },
  {
    "text": "you would essentially write\na potential from that group. Potential that comes from this\ngroup here that you attach",
    "start": "3228630",
    "end": "3235950"
  },
  {
    "text": "has a weighted average of-- let's say we go from,\nlike we did here, methylphenyl to chlorophenyl.",
    "start": "3235950",
    "end": "3242730"
  },
  {
    "text": "So you would weigh the potential\nwith the parameter lambda and integrate in\nthat space and you'd",
    "start": "3242730",
    "end": "3247860"
  },
  {
    "text": "get the free energy\ndifference between these two groups attached. ",
    "start": "3247860",
    "end": "3257660"
  },
  {
    "start": "3256000",
    "end": "3472000"
  },
  {
    "text": "OK. So here's my take\non Monte Carlo.",
    "start": "3257660",
    "end": "3265870"
  },
  {
    "text": "What I really like about it,\nit's conceptually simple. Of all the simulation\nmethods, it's",
    "start": "3265870",
    "end": "3271990"
  },
  {
    "text": "probably the one that has\nthe least amount of frills.",
    "start": "3271990",
    "end": "3277630"
  },
  {
    "text": "It tends to be very\neasy to implement.",
    "start": "3277630",
    "end": "3283509"
  },
  {
    "text": "And maybe the most\nimportant thing, it's as accurate\nas your Hamiltonian",
    "start": "3283510",
    "end": "3289930"
  },
  {
    "text": "can be so you can push\nthe sampling as far as you want it to be. So the sampling part can be done\nas accurately as you have time",
    "start": "3289930",
    "end": "3297400"
  },
  {
    "text": "for, essentially. Time and money for. Which is not always\ntrue about models. If I set up a potential\nmodel, I can't necessarily",
    "start": "3297400",
    "end": "3305290"
  },
  {
    "text": "improve that infinitely\nbetter to model the energetics of my system. But at least with Monte\nCarlo, the sampling part, so",
    "start": "3305290",
    "end": "3313030"
  },
  {
    "text": "the finite temperature part can\nbe done with as little error as you'd like it to be.",
    "start": "3313030",
    "end": "3320440"
  },
  {
    "text": "I think there's\nsort of two or three major disadvantages is that\nit's not a dynamical method,",
    "start": "3320440",
    "end": "3328849"
  },
  {
    "text": "so it doesn't give you\nany kinetic information like molecular dynamics does. Sometimes that's an\nadvantage because it",
    "start": "3328850",
    "end": "3335290"
  },
  {
    "text": "means you don't need\na kinetic mechanism to study how the system goes\nthrough it's phase space.",
    "start": "3335290",
    "end": "3341770"
  },
  {
    "text": "But the second one is the\nmajor hit most of the time. It's an extremely\nwasteful method",
    "start": "3341770",
    "end": "3348130"
  },
  {
    "text": "in terms of energy evaluations. You do a lot of kind of\nrandom excursions in phase",
    "start": "3348130",
    "end": "3353530"
  },
  {
    "text": "space and every time you\nneed to get the energy, and so that's why it's\nreally great to implement it",
    "start": "3353530",
    "end": "3360430"
  },
  {
    "text": "with fast energy methods. You know, [INAUDIBLE] small\nHamiltonian G. That's just adding a few numbers and\nmultiplying a few numbers",
    "start": "3360430",
    "end": "3366910"
  },
  {
    "text": "and you got the energy, bam! Or something like\npotential models if you do it in a continuous\nspace or embedded atom",
    "start": "3366910",
    "end": "3374440"
  },
  {
    "text": "works great with those methods. It's essentially impossible\nto implement it with quantum",
    "start": "3374440",
    "end": "3379840"
  },
  {
    "text": "mechanics directly, you know? I mean, that embedded. The method, the\ncopper nickel one",
    "start": "3379840",
    "end": "3385900"
  },
  {
    "text": "I showed you did millions\nof energy evaluations to equilibrate the system. So can you imagine you're\ngoing to millions of direct DFT",
    "start": "3385900",
    "end": "3393120"
  },
  {
    "text": "calculations? No. So that the fact that\nyou need typically a fast energy method is\nsort of a limitation.",
    "start": "3393120",
    "end": "3402430"
  },
  {
    "text": "The stochastic nature of\nit can be a limitation. It's less and less so, but\nwhen you run two Monte Carlo",
    "start": "3402430",
    "end": "3409710"
  },
  {
    "text": "simulations you don't\nget the same answer, so because of that,\nthere is noise in data.",
    "start": "3409710",
    "end": "3417059"
  },
  {
    "text": "It's a lot harder to write\nmethods on top of it, in some sense, drivers for it.",
    "start": "3417060",
    "end": "3423020"
  },
  {
    "text": "If you do DFT, if\nyou converge, you get the same answer every time.",
    "start": "3423020",
    "end": "3428790"
  },
  {
    "text": "So it's not stochastic. So you can now develop\nalgorithms that use that input",
    "start": "3428790",
    "end": "3434790"
  },
  {
    "text": "and do stuff with it. It's a lot harder to work\nwith stochastic input, let me tell you, because you\nkind of have to average noise",
    "start": "3434790",
    "end": "3442830"
  },
  {
    "text": "away. And I think the fourth one--\nyou know, I should update. This is becoming less\nand less an issue.",
    "start": "3442830",
    "end": "3449730"
  },
  {
    "text": "It used to be, but as computers\nget faster it's really, I would say we can\nget free energy when",
    "start": "3449730",
    "end": "3455760"
  },
  {
    "text": "we want it, especially on\nmodels with discrete degrees of freedom. Models with continuous degree\nof freedom you can do it.",
    "start": "3455760",
    "end": "3462680"
  },
  {
    "text": "There's still more work, but\nit's not much of a disadvantage anymore.",
    "start": "3462680",
    "end": "3469065"
  },
  {
    "text": "OK, I've gone through\nthe references Before. OK.",
    "start": "3469065",
    "end": "3474070"
  },
  {
    "start": "3472000",
    "end": "3599000"
  },
  {
    "text": "So what I want to\nstart maybe now-- and I'm probably\nnot going to get this finished-- is start to talk\nabout coarse-graining methods.",
    "start": "3474070",
    "end": "3485799"
  },
  {
    "text": "And why do you need\ncoarse-graining methods? it's essentially a nice follow\nup on what we just discussed.",
    "start": "3485800",
    "end": "3493500"
  },
  {
    "text": "Monte Carlo allows you to get\nfull phase space sampling,",
    "start": "3493500",
    "end": "3498990"
  },
  {
    "text": "but you cannot do it on an\naccurate Hamiltonian like density functional theory.",
    "start": "3498990",
    "end": "3505930"
  },
  {
    "text": "So what if you actually need\nhighly accurate energetics and you need to sample\nphase space well?",
    "start": "3505930",
    "end": "3512760"
  },
  {
    "text": "Then you're in trouble\nbecause the two are very hard to combine.",
    "start": "3512760",
    "end": "3518880"
  },
  {
    "text": "Sampling phase\nspace, well, means a lot of energy evaluations\nand a lot of energy evaluations",
    "start": "3518880",
    "end": "3524520"
  },
  {
    "text": "precludes using a very\nhighly accurate Hamiltonian, but there are problems for\nwhich you need both anyway.",
    "start": "3524520",
    "end": "3530880"
  },
  {
    "text": "And then you sort of need to\ngo to coarse-graining methods. And the idea in\ncoarse-graining methods",
    "start": "3530880",
    "end": "3536100"
  },
  {
    "text": "is that you try to either remove\nspatial degrees of freedom",
    "start": "3536100",
    "end": "3541290"
  },
  {
    "text": "or temporal degrees of\nfreedom or your system very systematically so\nthat your model becomes",
    "start": "3541290",
    "end": "3546510"
  },
  {
    "text": "simpler and simpler, giving up\nas little accuracy as possible. OK?",
    "start": "3546510",
    "end": "3551970"
  },
  {
    "text": "So accumulating as little\nerror on the way as possible. I'll talk first about\ntemporal coarse-graining",
    "start": "3551970",
    "end": "3559090"
  },
  {
    "text": "since it's easier, but if\nwe have time in the end I may say a little about spatial\ncoarse-graining, which is a much more difficult problem.",
    "start": "3559090",
    "end": "3566310"
  },
  {
    "text": " OK, let me skip this.",
    "start": "3566310",
    "end": "3572750"
  },
  {
    "text": "OK. Well, actually let\nme show it to you. ",
    "start": "3572750",
    "end": "3579559"
  },
  {
    "text": "Something wrong\nwith the color here. ",
    "start": "3579560",
    "end": "3585160"
  },
  {
    "text": "Here's an example of why\nyou need coarse-graining. This is the copper,\naluminum phase diagram.",
    "start": "3585160",
    "end": "3591550"
  },
  {
    "text": " All the stable\nphases in here are",
    "start": "3591550",
    "end": "3596890"
  },
  {
    "text": "in many cases within something\nlike 5 to 10 milli electron volt of several other phases.",
    "start": "3596890",
    "end": "3603250"
  },
  {
    "text": "So that means that\nto actually know that these are the stables\nfacing that system,",
    "start": "3603250",
    "end": "3608470"
  },
  {
    "text": "you need highly\naccurate energetics. You can't afford more than a\nfew million electoral votes",
    "start": "3608470",
    "end": "3614880"
  },
  {
    "text": "to an error. That's a very small error. So an election volt is\nabout 100 kilojoules,",
    "start": "3614880",
    "end": "3622010"
  },
  {
    "text": "so a million electron\nvolt is about 100 joules. All right. Yeah.",
    "start": "3622010",
    "end": "3627822"
  },
  {
    "text": "So I don't know what\nthat in calories is, but anyway, so highly\naccurate energetics",
    "start": "3627822",
    "end": "3633620"
  },
  {
    "text": "and then to get the\ntemperature behavior you need to sample\nphase space because you need to get the entropy\nand the excitations.",
    "start": "3633620",
    "end": "3641360"
  },
  {
    "text": " For some problems like\nthese, essentially we",
    "start": "3641360",
    "end": "3649860"
  },
  {
    "text": "figured out how to do this. It's still hard work, but\nessentially the road map is laid out.",
    "start": "3649860",
    "end": "3656750"
  },
  {
    "text": "The idea is that you\nsuccessively integrate over slower and slower timescales.",
    "start": "3656750",
    "end": "3664160"
  },
  {
    "text": "So you look at what\nexcursions, what excitations occur in the system, first at\nthe really fast time scales",
    "start": "3664160",
    "end": "3671090"
  },
  {
    "text": "and then you try to either\nvariationally remove them or you try to\nintegrate over them,",
    "start": "3671090",
    "end": "3676670"
  },
  {
    "text": "and those two are\ndifferent things. If you variationally\nremove a degree of freedom,",
    "start": "3676670",
    "end": "3681842"
  },
  {
    "text": "then you're really\nfinding, essentially, what gives you the lowest energy\nfor that degree of freedom.",
    "start": "3681843",
    "end": "3687290"
  },
  {
    "text": "If you integrate\nover the excursions of that degree of freedom,\nthen essentially you",
    "start": "3687290",
    "end": "3692330"
  },
  {
    "text": "capture its full\nentropic component, and I'll come back to the\ndistinction between the two. But let's take, for\nexample, a simple binary",
    "start": "3692330",
    "end": "3699170"
  },
  {
    "text": "solid, like that aluminum\ncopper I showed you. What are the excitations\nin that system?",
    "start": "3699170",
    "end": "3705690"
  },
  {
    "text": "Well, it's a metal so at the\nhighest level there's probably electronic excitations.",
    "start": "3705690",
    "end": "3711920"
  },
  {
    "text": "If the Fermi level of the\nsystem cuts through a band so you have density of\nstates at the Fermi level,",
    "start": "3711920",
    "end": "3719810"
  },
  {
    "text": "then electrons can get excited\nacross the Fermi level. OK? So that's a form of entropy\nright there already.",
    "start": "3719810",
    "end": "3725900"
  },
  {
    "text": "Most of the time we\ndon't worry about it. That's one that we\nvariationally remove. You do the FT and you find\nthe lowest energy state.",
    "start": "3725900",
    "end": "3733310"
  },
  {
    "text": "You don't say, I'm\ngoing to integrate over all the accessible\nelectronic states. You find the lowest one.",
    "start": "3733310",
    "end": "3740609"
  },
  {
    "text": "Then you have\nvibrational excitations. These are ones you\ncan get around. They're essentially present in\nevery material by definition.",
    "start": "3740610",
    "end": "3748935"
  },
  {
    "text": "These live on timescale\n10 to the minus 11, 10 to the minus 12, 10\nto the minus 13 seconds.",
    "start": "3748935",
    "end": "3755970"
  },
  {
    "text": "And then typically the slower\none is configurational ones. If you have just A and B that\nthey interchange positions,",
    "start": "3755970",
    "end": "3765690"
  },
  {
    "text": "they start giving you disorder. ",
    "start": "3765690",
    "end": "3771240"
  },
  {
    "text": "Again, the reason you can\nsort of do this problem easily is that this would be\nthe perfect Monte Carlo",
    "start": "3771240",
    "end": "3777240"
  },
  {
    "text": "problem, just like in\nthat copper nickel example segregation. If you could do fast\nenergy evaluations,",
    "start": "3777240",
    "end": "3783599"
  },
  {
    "text": "you would just do\nsmall displacements to capture the\nvibrations and then you would do big\nexchanges to capture",
    "start": "3783600",
    "end": "3789900"
  },
  {
    "text": "the configurational excitations. But because you\nneed the accuracy, you'd almost need to do\nit on a DFT Hamiltonian.",
    "start": "3789900",
    "end": "3796973"
  },
  {
    "text": "You could say the\nvibrational ones you could capture very well\nwith molecular dynamics.",
    "start": "3796973",
    "end": "3801990"
  },
  {
    "text": "You just track the\ndisplacements of the atoms. Think about it, the\nsort of slower phonons",
    "start": "3801990",
    "end": "3808770"
  },
  {
    "text": "go on a timescale of\nmaybe 10 to the minus 11. So what is that? That's 10 picoseconds.",
    "start": "3808770",
    "end": "3815039"
  },
  {
    "text": "So if you simulate 100\npicoseconds in nanoseconds, you're going to start\nfairly allegorically",
    "start": "3815040",
    "end": "3820230"
  },
  {
    "text": "sampling the vibration. So you'd have a\npretty good result for vibrational free\nenergy, but you'd never",
    "start": "3820230",
    "end": "3826230"
  },
  {
    "text": "get down to the\nconfigurational timescale. ",
    "start": "3826230",
    "end": "3832190"
  },
  {
    "text": "So how do you\nsolve that problem? ",
    "start": "3832190",
    "end": "3839990"
  },
  {
    "text": "Again, the idea is\nthat we integrate over the fast degrees\nof freedom and try",
    "start": "3839990",
    "end": "3847490"
  },
  {
    "text": "to define a\nHamiltonian that's only defined in the phase space of\nthe slow degrees of freedom.",
    "start": "3847490",
    "end": "3853740"
  },
  {
    "text": "OK? And the question is how\naccurate can we do this? So I'm going to focus\non this alloy problem",
    "start": "3853740",
    "end": "3861050"
  },
  {
    "text": "just so that we keep our focus. So what I want to get to is a\nHamiltonian that has integrated",
    "start": "3861050",
    "end": "3867140"
  },
  {
    "text": "away the electronic excitations,\nthe vibrational excitations, and therefore that just\nlives in the phase space",
    "start": "3867140",
    "end": "3874279"
  },
  {
    "text": "of the substitutional\nexcitations, which is a much smaller phase space. ",
    "start": "3874280",
    "end": "3884790"
  },
  {
    "text": "OK. Let me show you the math. ",
    "start": "3884790",
    "end": "3891190"
  },
  {
    "text": "If you think of a\ncrystal of A and B atoms,",
    "start": "3891190",
    "end": "3896873"
  },
  {
    "text": "they may live on a\nlattice, but of course they can be displaced\nfrom the lattice just through static\nrelaxation but also",
    "start": "3896873",
    "end": "3903520"
  },
  {
    "text": "through vibrational excursions. So normally you could\ndefine that system",
    "start": "3903520",
    "end": "3910089"
  },
  {
    "text": "just by coordinate vectors. If I have n atoms, I need\nn coordinate vectors. I'm going to change the way\nI characterize that system",
    "start": "3910090",
    "end": "3917980"
  },
  {
    "text": "by first, a lattice index. So this is a topological index. This is essentially if I\nhave a crystalline material,",
    "start": "3917980",
    "end": "3926660"
  },
  {
    "text": "I could start indexing\nthe possible sites in that material. So I will be the index of\nthese possible lattice sites",
    "start": "3926660",
    "end": "3935770"
  },
  {
    "text": "and delta r will be the\ndisplacement from these lattice sites. OK?",
    "start": "3935770",
    "end": "3940870"
  },
  {
    "text": "So do you agree that the\ncombination of these two is essentially the same as\nhaving a full coordinate?",
    "start": "3940870",
    "end": "3948220"
  },
  {
    "text": "OK. Now the set of indices i I'm\ngoing to represent essentially",
    "start": "3948220",
    "end": "3958040"
  },
  {
    "text": "by a lattice model. So the set of indices i is\nessentially saying at each",
    "start": "3958040",
    "end": "3964040"
  },
  {
    "text": "lattice point or around\nthere-- because the atom doesn't exactly have to sit\nthere, but around there--",
    "start": "3964040",
    "end": "3970040"
  },
  {
    "text": "is it an A or a B there? So the variables\nto describe that are the same variables as a\nspin model or lattice model,",
    "start": "3970040",
    "end": "3977180"
  },
  {
    "text": "it's a binary problem now. OK? So the question is,\nat I is it A or B?",
    "start": "3977180",
    "end": "3984380"
  },
  {
    "text": "But again, I don't need to\nspecify that the atom exactly sits at A or B. That I specify\nby the displacements, the delta",
    "start": "3984380",
    "end": "3991460"
  },
  {
    "text": "r's, OK? So what I've done is\nI've separated variables that give me the configurational\ntopology from the variables",
    "start": "3991460",
    "end": "3999920"
  },
  {
    "text": "that gives me the excursions\naway from the ideal lattice site. ",
    "start": "3999920",
    "end": "4009839"
  },
  {
    "text": "And now you see where I'm going. I'm going to integrate\nover the excursions",
    "start": "4009840",
    "end": "4015500"
  },
  {
    "text": "and then retain\nsomething that only exists in the space of the\nconfigurational degrees",
    "start": "4015500",
    "end": "4020780"
  },
  {
    "text": "of freedom. OK, here we go. So the partition function\nis the sum over all states.",
    "start": "4020780",
    "end": "4027660"
  },
  {
    "text": "So again, the sum\nover all states you would have normally be\nthe sum over all vectors. I'm going to write that as the\nsum over configurational states",
    "start": "4027660",
    "end": "4036230"
  },
  {
    "text": "and then the sum over all\ndisplacement states, which have called nu. So nu is the set of delta\nri, and so the energy",
    "start": "4036230",
    "end": "4051520"
  },
  {
    "text": "depends on both variables. OK? Now what I'm going to do is\nI'm going to essentially assume",
    "start": "4051520",
    "end": "4058770"
  },
  {
    "text": "I can do this integration. We'll talk in a second\nabout how you can do that. So I'm only going to do the\nsum over the displacement,",
    "start": "4058770",
    "end": "4066510"
  },
  {
    "text": "but for a given\nconfigurational state. So what does that\npractically mean?",
    "start": "4066510",
    "end": "4071650"
  },
  {
    "text": "That means that I'm integrating\nthe phase space of a fixed topology, but allowing the\natoms to sort of vibrate",
    "start": "4071650",
    "end": "4079500"
  },
  {
    "text": "around their average positions. That's essentially\nwhat I'm doing.",
    "start": "4079500",
    "end": "4084510"
  },
  {
    "text": "So essentially I'm\ncapturing, in that integral, the vibrational free\nenergy component",
    "start": "4084510",
    "end": "4089610"
  },
  {
    "text": "for a given configuration. And so I'm going to define.",
    "start": "4089610",
    "end": "4096970"
  },
  {
    "text": "So this is that integral\nwe talked about. So I'm going to give\nthat a free energy, which",
    "start": "4096970",
    "end": "4102120"
  },
  {
    "text": "is just the logarithm of that. And then just if I\nsubstitute that in here,",
    "start": "4102120",
    "end": "4109299"
  },
  {
    "text": "you see that what I\nend up with is this",
    "start": "4109300",
    "end": "4115068"
  },
  {
    "text": "and this is kind of important. What do I have? I have the partition\nfunction of a lattice model.",
    "start": "4115069",
    "end": "4121130"
  },
  {
    "text": "I have a partition\nfunction that only sums over different\ntopologies, it only",
    "start": "4121130",
    "end": "4126770"
  },
  {
    "text": "sums over different\nconfigurational states, OK?",
    "start": "4126770",
    "end": "4132670"
  },
  {
    "text": "So I've reduced the phase space. I'm not summing over\nvibrational states. Remember, I've integrated them.",
    "start": "4132670",
    "end": "4138609"
  },
  {
    "text": "But what is the\nquantity I'm summing? This is the important thing. The quantity I'm summing\nis not the energy,",
    "start": "4138609",
    "end": "4144729"
  },
  {
    "text": "it's the free energy of\nthe vibrations essentially. OK?",
    "start": "4144729",
    "end": "4149739"
  },
  {
    "text": "So as you coarse-grain\nin time, your Hamiltonian at the slower timescale is\nessentially the free energy",
    "start": "4149740",
    "end": "4157449"
  },
  {
    "text": "of the faster timescale. OK? Why? Because you\nsuccessively integrate.",
    "start": "4157450",
    "end": "4163359"
  },
  {
    "text": "So in essence, if I sum\nover lattice model stage and I put A's and B's on\ndifferent lattice positions,",
    "start": "4163359",
    "end": "4170259"
  },
  {
    "text": "what this is telling you\nis that the quantity-- that's my Hamiltonian-- is\nnot the energy of that state.",
    "start": "4170260",
    "end": "4175600"
  },
  {
    "text": "It's the vibrational free\nenergy of that state. So if I take that\nas my Hamiltonian",
    "start": "4175600",
    "end": "4182140"
  },
  {
    "text": "and then I do this\npartition function, I will essentially\nhave an exact result.",
    "start": "4182140",
    "end": "4187359"
  },
  {
    "text": "I will have the exact partition\nfunction of the system. OK? And that's pretty amazing\nbecause I've really",
    "start": "4187359",
    "end": "4194590"
  },
  {
    "text": "sort of separated the timescale,\nintegrate over them separately, but I get what's\nessentially still--",
    "start": "4194590",
    "end": "4201730"
  },
  {
    "text": "it's an almost exact\nresult, because let's say I'm going to do it this way.",
    "start": "4201730",
    "end": "4207590"
  },
  {
    "text": "So let's say on this\nI do Monte Carlo now.  There is a small assumption\nthat I've made in all of this.",
    "start": "4207590",
    "end": "4215170"
  },
  {
    "text": " Think of the physical\npicture here.",
    "start": "4215170",
    "end": "4220360"
  },
  {
    "text": " Essentially what I'm\nsaying is that I got",
    "start": "4220360",
    "end": "4225970"
  },
  {
    "text": "these A's and B's sitting on-- you can't call them\nexactly lattice site, but they're associated\nwith a given lattice site.",
    "start": "4225970",
    "end": "4232060"
  },
  {
    "text": "They may be displaced from it,\nand they sort of vibrate around and I integrate that\nthose vibrations to get",
    "start": "4232060",
    "end": "4237639"
  },
  {
    "text": "the vibrational free energy. And then once in a while\nthey hop, exchange, and if I sample that that\ngives me the free energy coming",
    "start": "4237640",
    "end": "4246489"
  },
  {
    "text": "from that slower timescale. There's one assumption\nI've made in all of this. ",
    "start": "4246490",
    "end": "4254700"
  },
  {
    "text": "It's sort of a subtle\none, but I've essentially assumed that the time\nscales are uncoupled,",
    "start": "4254700",
    "end": "4263460"
  },
  {
    "text": "and here you have to be\ncareful with what I say. I say the timescales\nare uncoupled. I don't mean the\nenergetics is uncoupled.",
    "start": "4263460",
    "end": "4269070"
  },
  {
    "text": "Obviously the\nvibrational free energy depends on the configuration.",
    "start": "4269070",
    "end": "4274510"
  },
  {
    "text": "If I arrange the\natoms differently over the lattice sites, I get\na different vibrational free energy. That's not the problem.",
    "start": "4274510",
    "end": "4280020"
  },
  {
    "text": "I've assumed that you\ncan define a free energy.",
    "start": "4280020",
    "end": "4285100"
  },
  {
    "text": "OK? That this thing exists. So what does that\nphysically mean?",
    "start": "4285100",
    "end": "4290290"
  },
  {
    "text": "What I assume is that for a\ngiven lattice model state,",
    "start": "4290290",
    "end": "4295870"
  },
  {
    "text": "the system actually\nwaits long enough before it goes to the next one. If it actually only did\none vibration and bam,",
    "start": "4295870",
    "end": "4302920"
  },
  {
    "text": "it goes to the other one,\nthen the system is not ergodic in its vibration. And what that means\nis essentially",
    "start": "4302920",
    "end": "4308770"
  },
  {
    "text": "it doesn't sample\nall its vibrations before it goes\nonto the next one. So it's the fact that I can\nseparate the excitation that",
    "start": "4308770",
    "end": "4317420"
  },
  {
    "text": "really allows me to do this. Now in most materials, this\nis no problem whatsoever.",
    "start": "4317420",
    "end": "4324110"
  },
  {
    "text": "So vibrations, again, these are\ntimescale 10 to minus 11, 10 to the minus 13 kind of range.",
    "start": "4324110",
    "end": "4332090"
  },
  {
    "text": "The exchanges between\natoms on lattices depends on the\ndiffusion constant,",
    "start": "4332090",
    "end": "4337130"
  },
  {
    "text": "but you're going\nto be hard pressed to find any solid where\nthat happens faster",
    "start": "4337130",
    "end": "4342950"
  },
  {
    "text": "than of a rate of, say, 10 to\nthe 4 per second, for example. 10 to the 4, 10 to\nthe 5 per second.",
    "start": "4342950",
    "end": "4348590"
  },
  {
    "text": "That's really fast diffusion. That gives you diffusion\nconstants of like 10 to the minus 7, 10 to minus\n8, which are very high.",
    "start": "4348590",
    "end": "4355400"
  },
  {
    "text": "Extremely high. So at room temperature,\nfor a lot of-- say for metals, this is well\nbelow one hop per second.",
    "start": "4355400",
    "end": "4364980"
  },
  {
    "text": "Fast conductors you start to\nget to a few hops per second at room temperature.",
    "start": "4364980",
    "end": "4370130"
  },
  {
    "text": "Then of course,\nif you go higher, temperature goes faster,\nbut almost always are these timescales\nextremely well separated.",
    "start": "4370130",
    "end": "4377050"
  },
  {
    "text": "Places where they might not\nbe like fast proton motion. They might not be\nvery well separated",
    "start": "4377050",
    "end": "4382760"
  },
  {
    "text": "and then this stuff breaks down. But remember, if they move\nthat fast, you should just do molecular dynamics because\nthen it's within the range.",
    "start": "4382760",
    "end": "4390050"
  },
  {
    "text": "It's well within the scope\nof molecular dynamics, and that's the perfect\napproach at that point.",
    "start": "4390050",
    "end": "4397380"
  },
  {
    "text": "OK. ",
    "start": "4397380",
    "end": "4422679"
  },
  {
    "text": "OK, let me do one more\nthing and then we'll stop.",
    "start": "4422680",
    "end": "4429160"
  },
  {
    "text": "There's a variety of\napproximations you can do. ",
    "start": "4429160",
    "end": "4435810"
  },
  {
    "text": "Remember that your Hamiltonian\nin your lattice model should be the free energy of\nthe higher order states, which",
    "start": "4435810",
    "end": "4443580"
  },
  {
    "text": "are essentially the vibrational\nand the electronic excitations that you've removed.",
    "start": "4443580",
    "end": "4449640"
  },
  {
    "text": "Now in some cases\npeople say, I don't want to do all that\nwork of integrating",
    "start": "4449640",
    "end": "4456960"
  },
  {
    "text": "over the electronic\nstates and integrating over the vibrational states. I'm going to\nvariationally remove",
    "start": "4456960",
    "end": "4462060"
  },
  {
    "text": "them, which means I'm\ngoing to find the lowest energy electronic states and\nthe lowest energy displacement",
    "start": "4462060",
    "end": "4468630"
  },
  {
    "text": "state, delta ri state. OK? So I do that\npractically while you take an arrangement\nof atoms and you just",
    "start": "4468630",
    "end": "4475350"
  },
  {
    "text": "relax them both the electronic\nstates and the positions to the minimum energy, and\nthat gives you some E value.",
    "start": "4475350",
    "end": "4483220"
  },
  {
    "text": "So what it essentially\nis is if you think of the F as the free\nenergy of an ensemble,",
    "start": "4483220",
    "end": "4488410"
  },
  {
    "text": "the E you take is the lowest\nenergy value in that ensemble. So if you do that and then\nyou stick that in Monte Carlo,",
    "start": "4488410",
    "end": "4495280"
  },
  {
    "text": "what do you have? You have proper\nenergetics and you only have configurational\nentropy because rather",
    "start": "4495280",
    "end": "4500980"
  },
  {
    "text": "than integrating all the\nvibrations and the electronics states, you've taken the minimal\nstate out of that sub-ensemble.",
    "start": "4500980",
    "end": "4508950"
  },
  {
    "text": "You'll integrate\nover-- that means essentially your system\nhasn't sampled excursions",
    "start": "4508950",
    "end": "4514139"
  },
  {
    "text": "for those variables,\nso you don't have entropy from those variables. OK?",
    "start": "4514140",
    "end": "4520270"
  },
  {
    "text": "And then you can do all\nkinds of approximation. You can say, well, I don't\ncare about the vibrations.",
    "start": "4520270",
    "end": "4525940"
  },
  {
    "text": "I think that's too much work. I'm going to just get\nthe electronic entropy. And one of the reasons\nelectronic entropy and metals",
    "start": "4525940",
    "end": "4531910"
  },
  {
    "text": "is easy, any time you\nhave delocalized states, you can write as\na simple integral over the density of\nstates, which you often",
    "start": "4531910",
    "end": "4537820"
  },
  {
    "text": "have [INAUDIBLE] density\nfunctional theory. So if you say I'm going\nto take the minimal energy",
    "start": "4537820",
    "end": "4543040"
  },
  {
    "text": "and the electronic\nentropy, well then after you've done\nyour Monte Carlo, you have configurational\nentropy and electronic entropy.",
    "start": "4543040",
    "end": "4550270"
  },
  {
    "text": "And then if you want\nto go all the way, rather than minimizing the\nenergy you integrate over",
    "start": "4550270",
    "end": "4556653"
  },
  {
    "text": "to displacement,\nthen you're going to get the vibrational\nentropy component as well. ",
    "start": "4556653",
    "end": "4567180"
  },
  {
    "text": "OK. I'm going to stop here\nbecause the rest is going to take us a little too long. And so I'll pick some\nof this up again.",
    "start": "4567180",
    "end": "4576239"
  },
  {
    "text": "It's unfortunately almost\ntwo weeks away from now, I think, because like I said,\nso Tuesday's no lecture.",
    "start": "4576240",
    "end": "4582420"
  },
  {
    "text": "Thursday-- oh, wait\nThursday's you, no? Yeah, so actually Thursday's\na lecture by Professor Marzari",
    "start": "4582420",
    "end": "4588050"
  },
  {
    "text": "and then it's the next Tuesday's\nthe lab and then Thursday after that I pick\nthis up again and then",
    "start": "4588050",
    "end": "4594085"
  },
  {
    "text": "I think we're in\nMay or something and we're almost over. Anyway, so have a good--",
    "start": "4594085",
    "end": "4600530"
  },
  {
    "text": "what is this holiday again? [INAUDIBLE] Day? No? [INAUDIBLE] Day? OK.",
    "start": "4600530",
    "end": "4605540"
  },
  {
    "text": "Watch the marathon. ",
    "start": "4605540",
    "end": "4610000"
  }
]
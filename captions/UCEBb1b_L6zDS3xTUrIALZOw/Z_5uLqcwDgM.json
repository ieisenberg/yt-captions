[
  {
    "text": " The following content is\nprovided under a Creative Commons license.",
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Your support will help\nMIT open courseware continue to offer high quality\neducational resources for free.",
    "start": "5310",
    "end": "11610"
  },
  {
    "text": "To make a donation or to\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare",
    "start": "11610",
    "end": "18140"
  },
  {
    "text": "at ocw.mit.edu. ",
    "start": "18140",
    "end": "25044"
  },
  {
    "text": "PROFESSOR: Let's go. So if you want to know the\nsubject of today's class,",
    "start": "25045",
    "end": "32040"
  },
  {
    "text": "it's A x = b. I got started writing down\ndifferent possibilities",
    "start": "32040",
    "end": "38460"
  },
  {
    "text": "for A x = b, and I\ngot carried away. It just appears all over the\nplace for different sizes,",
    "start": "38460",
    "end": "52420"
  },
  {
    "text": "different ranks, different\nsituations, nearly singular, not nearly singular.",
    "start": "52420",
    "end": "57660"
  },
  {
    "text": "And the question is, what\ndo you do in each case? So can I outline my\nlittle two pages of notes",
    "start": "57660",
    "end": "68730"
  },
  {
    "text": "here, and then pick on\none or two of these topics to develop today, and\na little more on Friday",
    "start": "68730",
    "end": "77820"
  },
  {
    "text": "about Gram-Schmidt? So I won't do much, if\nany, of Gram-Schmidt today,",
    "start": "77820",
    "end": "83729"
  },
  {
    "text": "but I will do the others. So the problem is A x = b.",
    "start": "83730",
    "end": "90705"
  },
  {
    "text": "That problem has\ncome from somewhere. We have to produce some\nkind of an answer, x.",
    "start": "90705",
    "end": "96509"
  },
  {
    "text": "So I'm going from good to bad or\neasy to difficult in this list.",
    "start": "96510",
    "end": "106530"
  },
  {
    "text": "Well, except for number 0,\nwhich is an answer in all cases,",
    "start": "106530",
    "end": "113680"
  },
  {
    "text": "using the pseudo inverse\nthat I introduced last time. So that deals with 0\neigenvalues and zero singular",
    "start": "113680",
    "end": "123910"
  },
  {
    "text": "values by saying\ntheir inverse is also 0, which is kind of wild.",
    "start": "123910",
    "end": "129310"
  },
  {
    "text": "So we'll come back to the\nmeaning of the pseudo inverse. But now, I want\nto get real, here,",
    "start": "129310",
    "end": "136630"
  },
  {
    "text": "about different situations. So number 1 is the\ngood, normal case,",
    "start": "136630",
    "end": "141910"
  },
  {
    "text": "when a person has a square\nmatrix of reasonable size,",
    "start": "141910",
    "end": "147430"
  },
  {
    "text": "reasonable condition,\na condition number-- oh, the\ncondition number, I should call it\nsigma 1 over sigma n.",
    "start": "147430",
    "end": "157290"
  },
  {
    "text": "It's the ratio of the largest\nto the smallest singular value. And let's say that's within\nreason, not more than 1,000",
    "start": "157290",
    "end": "165940"
  },
  {
    "text": "or something. Then normal, ordinary\nelimination is going to work,",
    "start": "165940",
    "end": "173530"
  },
  {
    "text": "and Matlab-- the command that would produce\nthe answer is just backslash.",
    "start": "173530",
    "end": "180040"
  },
  {
    "text": "So this is the normal case. Now, the cases that follow\nhave problems of some kind,",
    "start": "180040",
    "end": "190340"
  },
  {
    "text": "and I guess I'm\nhoping that this is a sort of useful dictionary of\nwhat to do for you and me both.",
    "start": "190340",
    "end": "201790"
  },
  {
    "text": "So we have this case here, where\nwe have too many equations.",
    "start": "201790",
    "end": "206799"
  },
  {
    "text": "So that's a pretty normal\ncase, and we'll think mostly",
    "start": "206800",
    "end": "212710"
  },
  {
    "text": "of solving by least\nsquares, which leads us to the normal equation.",
    "start": "212710",
    "end": "217939"
  },
  {
    "text": "So this is standard, happens\nall the time in statistics. And I'm thinking in\nthe reasonable case,",
    "start": "217940",
    "end": "227200"
  },
  {
    "text": "that would be ex hat.  The solution A--\nthis matrix would be",
    "start": "227200",
    "end": "234280"
  },
  {
    "text": "invertible and reasonable size. So backslash would still\nsolve that problem.",
    "start": "234280",
    "end": "242650"
  },
  {
    "text": "Backslash doesn't\nrequire a square matrix to give you an answer. So that's the good case,\nwhere the matrix is not",
    "start": "242650",
    "end": "252730"
  },
  {
    "text": "too big, so it's not\nunreasonable to form a transpose.",
    "start": "252730",
    "end": "258930"
  },
  {
    "text": "Now, here's the other extreme.  What's exciting for us is this\nis the underdetermined case.",
    "start": "258930",
    "end": "268240"
  },
  {
    "text": "I don't have enough\nequations, so I have to put something more\nin to get a specific answer.",
    "start": "268240",
    "end": "274870"
  },
  {
    "text": "And what makes it exciting\nfor us is that that's typical of deep learning.",
    "start": "274870",
    "end": "281290"
  },
  {
    "text": "There are so many weights\nin a deep neural network that the weights\nwould be the unknowns.",
    "start": "281290",
    "end": "289060"
  },
  {
    "text": "Of course, it wouldn't\nbe necessarily linear. It wouldn't be linear,\nbut still the idea's",
    "start": "289060",
    "end": "294325"
  },
  {
    "text": "the same that we\nhave many solutions,",
    "start": "294325",
    "end": "301580"
  },
  {
    "text": "and we have to pick one. Or we have to pick an algorithm,\nand then it will find one.",
    "start": "301580",
    "end": "307000"
  },
  {
    "text": " So we could pick the minimum\nnorm solution, the shortest",
    "start": "307000",
    "end": "313450"
  },
  {
    "text": "solution. That would be an L2 answer. Or we could go to L1.",
    "start": "313450",
    "end": "319440"
  },
  {
    "text": "And the big question that, I\nthink, might be settled in 2018",
    "start": "319440",
    "end": "325980"
  },
  {
    "text": "is, does deep learning and\nthe iteration from stochastic",
    "start": "325980",
    "end": "332340"
  },
  {
    "text": "gradient descent that\nwe'll see pretty soon-- does it go to the minimum L1?",
    "start": "332340",
    "end": "340230"
  },
  {
    "text": "Does it pick out an L1 solution? That's really an\nexciting math question.",
    "start": "340230",
    "end": "346340"
  },
  {
    "text": "For a long time, it\nwas standard to say",
    "start": "346340",
    "end": "351620"
  },
  {
    "text": "that these deep learning\nAI codes are fantastic,",
    "start": "351620",
    "end": "357760"
  },
  {
    "text": "but what are they doing? We don't know all the interior,\nbut we-- when I say we,",
    "start": "357760",
    "end": "365160"
  },
  {
    "text": "I don't mean I. Other\npeople are getting there, and I'm going to tell you\nas much as I can about it",
    "start": "365160",
    "end": "373710"
  },
  {
    "text": "when we get there. So those are pretty\nstandard cases. ",
    "start": "373710",
    "end": "381819"
  },
  {
    "text": "m = n, m greater than n, m\nless than n, but not crazy.",
    "start": "381820",
    "end": "387730"
  },
  {
    "text": "Now, the second board will\nhave more difficult problems. ",
    "start": "387730",
    "end": "397300"
  },
  {
    "text": "Usually, because they're\nnearly singular in some way, the columns are\nnearly dependent.",
    "start": "397300",
    "end": "403720"
  },
  {
    "text": "So that would be the\ncolumns in bad condition. You just picked\na terrible basis,",
    "start": "403720",
    "end": "409750"
  },
  {
    "text": "or nature did, or somehow you\ngot a matrix A whose columns are virtually dependent--",
    "start": "409750",
    "end": "417640"
  },
  {
    "text": "almost linearly dependent. The inverse matrix is\nreally big, but it exists.",
    "start": "417640",
    "end": "426340"
  },
  {
    "text": "Then that's when you go in,\nand you fix the columns. You orthogonalize columns.",
    "start": "426340",
    "end": "432250"
  },
  {
    "text": "Instead of accepting the\ncolumns A1, A2, up to An of the given matrix,\nyou go in, and you",
    "start": "432250",
    "end": "440169"
  },
  {
    "text": "find orthonormal vectors\nin that column space and orthonormal basis Q1 to Qn.",
    "start": "440170",
    "end": "450610"
  },
  {
    "text": "And the two are connected\nby Gram-Schmidt. And the famous matrix\nstatement of Gram-Schmidt",
    "start": "450610",
    "end": "457030"
  },
  {
    "text": "is here are the columns of\nA. Here are the columns of Q, and there's a triangular\nmatrix that connects the two.",
    "start": "457030",
    "end": "467890"
  },
  {
    "text": "So that is the central\ntopic of Gram-Schmidt in that idea of orthogonalizing.",
    "start": "467890",
    "end": "475680"
  },
  {
    "text": "It just appears everywhere. It appears all over course\n6 in many, many situations",
    "start": "475680",
    "end": "481919"
  },
  {
    "text": "with different names. So that, I'm sort of saving\na little bit until next time,",
    "start": "481920",
    "end": "488550"
  },
  {
    "text": "and let me tell you why. Because just the organization\nof Gram-Schmidt is interesting.",
    "start": "488550",
    "end": "497430"
  },
  {
    "text": "So Gram-Schmidt, you\ncould do the normal way. So that's what I teach in 18.06.",
    "start": "497430",
    "end": "505410"
  },
  {
    "text": "Just take every\ncolumn as it comes. Subtract off projections\nonto their previous stuff.",
    "start": "505410",
    "end": "513419"
  },
  {
    "text": "Get it orthogonal to\nthe previous guys. Normalize it to\nbe a unit vector.",
    "start": "513419",
    "end": "519630"
  },
  {
    "text": "Then you've got that column. Go on. So I say that\nagain, and then I'll say it again two days from now.",
    "start": "519630",
    "end": "529090"
  },
  {
    "text": "So Gram-Schmidt, the idea\nis you take the columns-- ",
    "start": "529090",
    "end": "535440"
  },
  {
    "text": "you say the second\northogonal vector, Q2,",
    "start": "535440",
    "end": "543690"
  },
  {
    "text": "will be some combination\nof columns 1 and 2, orthogonal to the first. ",
    "start": "543690",
    "end": "551720"
  },
  {
    "text": "Lots to do. And there's another order,\nwhich is really the better order",
    "start": "551720",
    "end": "557760"
  },
  {
    "text": "to do Gram-Schmidt,\nand it allows you to do column pivoting.",
    "start": "557760",
    "end": "563139"
  },
  {
    "text": "So this is my topic\nfor next time, to see Gram-Schmidt\nmore carefully.",
    "start": "563140",
    "end": "570180"
  },
  {
    "text": " Column pivoting means\nthe columns might not",
    "start": "570180",
    "end": "579130"
  },
  {
    "text": "come in a good order, so you\nallow yourself to reorder them.",
    "start": "579130",
    "end": "586750"
  },
  {
    "text": "We know that you have to\ndo that for elimination. In elimination,\nit would be rows.",
    "start": "586750",
    "end": "593710"
  },
  {
    "text": "So elimination, we\nwould have the matrix A, and we take the first row\nas the first pivot row,",
    "start": "593710",
    "end": "606430"
  },
  {
    "text": "and then the second row,\nand then the third row. But if the pivot is too\nsmall, then reorder the rows.",
    "start": "606430",
    "end": "623280"
  },
  {
    "text": " So it's row ordering that\ncomes up in elimination.",
    "start": "623280",
    "end": "631165"
  },
  {
    "start": "631165",
    "end": "637350"
  },
  {
    "text": "And Matlab just\nsystematically says, OK,",
    "start": "637350",
    "end": "642449"
  },
  {
    "text": "that's the pivot\nthat's coming up. The third pivot comes\nup out of the third row.",
    "start": "642450",
    "end": "648330"
  },
  {
    "text": "But Matlab says look down\nthat whole third column for a better pivot,\na bigger pivot.",
    "start": "648330",
    "end": "653850"
  },
  {
    "text": "Switch to a row exchange. So there are lots of\npermutations then. You end up with something\nthere that permutes the rows,",
    "start": "653850",
    "end": "663960"
  },
  {
    "text": "and then that gets\nfactored into LU. So I'm saying something\nabout elimination",
    "start": "663960",
    "end": "670680"
  },
  {
    "text": "that's just sort\nof a side comment that you would\nnever do elimination",
    "start": "670680",
    "end": "678240"
  },
  {
    "text": "without considering the\npossibility of row exchanges. And then this is Gram-Schmidt\northogonalization.",
    "start": "678240",
    "end": "689120"
  },
  {
    "text": "So this is the LU world. Here is the QR\nworld, and here, it",
    "start": "689120",
    "end": "694579"
  },
  {
    "text": "happens to be columns\nthat you're permuting. So that's coming. This is section 2.2, now.",
    "start": "694580",
    "end": "706710"
  },
  {
    "text": "But there's more. 2.2 has quite a bit\nin it, including number 0, the pseudo\ninverse, and including",
    "start": "706710",
    "end": "713605"
  },
  {
    "text": "some of these things. Actually, this will\nbe also in 2.2.",
    "start": "713605",
    "end": "718709"
  },
  {
    "text": "And maybe this is what I'm\nsaying more about today. So I'll put a little\nstar for today, here.",
    "start": "718710",
    "end": "728459"
  },
  {
    "text": "What do you do? So this is a case where the\nmatrix is nearly singular.",
    "start": "728460",
    "end": "735959"
  },
  {
    "text": "You're in danger. It's inverse is\ngoing to be big-- unreasonably big.",
    "start": "735960",
    "end": "741190"
  },
  {
    "text": "And I wrote inverse\nproblems there, because inverse problem\nis a type of problem",
    "start": "741190",
    "end": "751360"
  },
  {
    "text": "with an application that\nyou often need to solve or that engineering and\nscience have to solve.",
    "start": "751360",
    "end": "760970"
  },
  {
    "text": "So I'll just say a\nlittle more about that, but that's a typical application\nin which you're near singular.",
    "start": "760970",
    "end": "770240"
  },
  {
    "text": "Your matrix isn't\ngood enough to invert. Well, of course, you\ncould always say,",
    "start": "770240",
    "end": "775339"
  },
  {
    "text": "well, I'll just use\nthe pseudo inverse, but numerically,\nthat's like cheating.",
    "start": "775340",
    "end": "780440"
  },
  {
    "text": "You've got to get in there\nand do something about it. So inverse problems\nwould be examples.",
    "start": "780440",
    "end": "786920"
  },
  {
    "text": " Actually, as I\nwrite that, I think",
    "start": "786920",
    "end": "792220"
  },
  {
    "text": "that would be a\ntopic that I should add to the list of potential\ntopics for a three week",
    "start": "792220",
    "end": "798399"
  },
  {
    "text": "project. Look up a book on\ninverse problems. So what do I mean by\nan inverse problem?",
    "start": "798400",
    "end": "804640"
  },
  {
    "text": "I'll just finish this thought. What's an inverse problem? Typically, you know about\na system, say a network,",
    "start": "804640",
    "end": "821330"
  },
  {
    "text": "RLC network, and you give\nit a voltage or current.",
    "start": "821330",
    "end": "826810"
  },
  {
    "text": "You give it an input,\nand you find the output. You find out what current\nflows, what the voltages are.",
    "start": "826810",
    "end": "834960"
  },
  {
    "text": "But inverse problems are-- suppose you know the response\nto different voltages.",
    "start": "834960",
    "end": "847730"
  },
  {
    "text": "What was the network? You see the problem? Let me say it again.",
    "start": "847730",
    "end": "854150"
  },
  {
    "text": "Discover what the network\nis from its outputs. So that turns out to\ntypically be a problem that",
    "start": "854150",
    "end": "861399"
  },
  {
    "text": "gives nearly singular matrices. That's a difficult problem.",
    "start": "861400",
    "end": "868190"
  },
  {
    "text": "A lot of nearby networks would\ngive virtually the same output. So you have a matrix\nthat's nearly singular.",
    "start": "868190",
    "end": "877700"
  },
  {
    "text": "It's got singular\nvalues very close to 0.",
    "start": "877700",
    "end": "883340"
  },
  {
    "text": "What do you do then? Well, the world of\ninverse problems",
    "start": "883340",
    "end": "889810"
  },
  {
    "text": "thinks of adding a penalty term,\nsome kind of a penalty term.",
    "start": "889810",
    "end": "895660"
  },
  {
    "text": "When I minimize this\nthing just by itself, in the usual way, A transpose,\nit has a giant inverse.",
    "start": "895660",
    "end": "904472"
  },
  {
    "text": "The matrix A is\nbadly conditioned. It takes vectors almost to 0.",
    "start": "904472",
    "end": "913140"
  },
  {
    "text": "So that A transpose has\ngot a giant inverse, and you're at risk of losing\neverything to round off.",
    "start": "913140",
    "end": "922380"
  },
  {
    "text": "So this is the solution. You could call it\na cheap solution,",
    "start": "922380",
    "end": "928680"
  },
  {
    "text": "but everybody uses it. So I won't put that\nword on videotape.",
    "start": "928680",
    "end": "936070"
  },
  {
    "text": "But that sort of resolves\nthe problem, but then the question--",
    "start": "936070",
    "end": "941820"
  },
  {
    "text": "it shifts the problem,\nanyway, to what number-- what should be the penalty?",
    "start": "941820",
    "end": "947940"
  },
  {
    "text": "How much should you penalize it? You see, by adding that, you're\ngoing to make it invertible.",
    "start": "947940",
    "end": "958500"
  },
  {
    "text": "And if you make this bigger,\nand bigger, and bigger, it's more and more\nwell-conditioned.",
    "start": "958500",
    "end": "967130"
  },
  {
    "text": "It resolves the trouble, here. And like today, I'm going\nto do more with that.",
    "start": "967130",
    "end": "973779"
  },
  {
    "text": "So with that, I'll stop\nthere and pick it up after saying something\nabout 6 and 7.",
    "start": "973780",
    "end": "980110"
  },
  {
    "text": " I hope this is helpful. It was helpful to me, certainly,\nto see all these possibilities",
    "start": "980110",
    "end": "989470"
  },
  {
    "text": "and to write down\nwhat the symptom is. It's like a linear\nequation doctor.",
    "start": "989470",
    "end": "998560"
  },
  {
    "text": "Like you look for the symptoms,\nand then you propose something",
    "start": "998560",
    "end": "1005160"
  },
  {
    "text": "at CVS that works\nor doesn't work. But you do something about it.",
    "start": "1005160",
    "end": "1012589"
  },
  {
    "text": "So when the problem is too big-- ",
    "start": "1012590",
    "end": "1019389"
  },
  {
    "text": "up to now, the problems have\nnot been giant out of core.",
    "start": "1019390",
    "end": "1024430"
  },
  {
    "text": "But now, when it's too big-- maybe it's still in\ncore but really big-- then this is in 2.1.",
    "start": "1024430",
    "end": "1033250"
  },
  {
    "text": "So that's to come back to.  The word I could\nhave written in here,",
    "start": "1033250",
    "end": "1039980"
  },
  {
    "text": "if I was just going to write\none word, would be iteration.",
    "start": "1039980",
    "end": "1045640"
  },
  {
    "text": "Iterative methods, meaning\nyou take a step like--",
    "start": "1045640",
    "end": "1051835"
  },
  {
    "text": "the conjugate radiant method is\nthe hero of iterative methods.",
    "start": "1051835",
    "end": "1057580"
  },
  {
    "text": "And then that name\nI erased is Krylov, and there are other\nnames associated",
    "start": "1057580",
    "end": "1063160"
  },
  {
    "text": "with iterative methods. So that's the section\nthat we passed over just",
    "start": "1063160",
    "end": "1071059"
  },
  {
    "text": "to get rolling, but\nwe'll come back to. So then that one, you\nnever get the exact answer,",
    "start": "1071060",
    "end": "1079860"
  },
  {
    "text": "but you get closer and closer. If the iterative\nmethod is successful,",
    "start": "1079860",
    "end": "1085230"
  },
  {
    "text": "like conjugate gradients, you\nget pretty close, pretty fast. And then you say,\nOK, I'll take it.",
    "start": "1085230",
    "end": "1092820"
  },
  {
    "text": "And then finally, way\ntoo big, like nowhere.",
    "start": "1092820",
    "end": "1099159"
  },
  {
    "text": "You're not in core. Just your matrix-- you just\nhave a giant, giant problem,",
    "start": "1099160",
    "end": "1104890"
  },
  {
    "text": "which, of course, is\nhappening these days. And then one way to\ndo it is your matrix.",
    "start": "1104890",
    "end": "1113490"
  },
  {
    "text": "You can't even look\nat the matrix A, much less A transpose. A transpose would\nbe unthinkable.",
    "start": "1113490",
    "end": "1120870"
  },
  {
    "text": "You couldn't do it in a year.",
    "start": "1120870",
    "end": "1126990"
  },
  {
    "text": "So randomized linear\nalgebra has popped up,",
    "start": "1126990",
    "end": "1132429"
  },
  {
    "text": "and the idea there,\nwhich we'll see, is to use probability\nto sample the matrix",
    "start": "1132430",
    "end": "1145460"
  },
  {
    "text": "and work with your samples. So if the matrix is way too big,\nbut not too crazy, so to speak,",
    "start": "1145460",
    "end": "1157020"
  },
  {
    "text": "then you could sample\nthe columns and the rows,",
    "start": "1157020",
    "end": "1163090"
  },
  {
    "text": "and get an answer\nfrom the sample.",
    "start": "1163090",
    "end": "1169279"
  },
  {
    "text": "See, if I sample the columns\nof a matrix, I'm getting-- so what does sampling mean?",
    "start": "1169280",
    "end": "1175010"
  },
  {
    "text": "Let me just complete this, say,\nadd a little to this thought.",
    "start": "1175010",
    "end": "1180710"
  },
  {
    "text": "Sample a matrix. So I have a giant matrix A.\nIt might be sparse, of course.",
    "start": "1180710",
    "end": "1186760"
  },
  {
    "text": "I didn't distinguish\nover their sparse things. That would be another thing. So if I just take random\nX's, more than one,",
    "start": "1186760",
    "end": "1201930"
  },
  {
    "text": "but not the full n\ndimensions, those",
    "start": "1201930",
    "end": "1207620"
  },
  {
    "text": "will give me random guys\nin the column space. And if the matrix\nis reasonable, it",
    "start": "1207620",
    "end": "1218660"
  },
  {
    "text": "won't take too many to have a\npretty reasonable idea of what that column space is like, and\nwith it's the right hand side.",
    "start": "1218660",
    "end": "1226519"
  },
  {
    "text": "So this world of\nrandomized linear algebra has grown because it had to.",
    "start": "1226520",
    "end": "1233870"
  },
  {
    "text": "And of course, any\nstatement can never say for sure you're going\nto get the right answer,",
    "start": "1233870",
    "end": "1240340"
  },
  {
    "text": "but using the inequalities\nof probability,",
    "start": "1240340",
    "end": "1247070"
  },
  {
    "text": "you can often say that the\nchance of being way off is less than 1 in 2 to\nthe 20th or something.",
    "start": "1247070",
    "end": "1255650"
  },
  {
    "text": "So the answer is, in reality,\nyou get a good answer.",
    "start": "1255650",
    "end": "1261580"
  },
  {
    "text": "That is the end of\nthis chapter, 2.4. So this is all\nchapter 2, really.",
    "start": "1261580",
    "end": "1268650"
  },
  {
    "text": " The iterative method's in 2.1.",
    "start": "1268650",
    "end": "1276889"
  },
  {
    "text": "Most of this is in 2.2. Big is 2.3, and then really\nbig is randomized in 2.4.",
    "start": "1276890",
    "end": "1289540"
  },
  {
    "text": "So now, where are we? You were going to let me know\nor not if this is useful to see.",
    "start": "1289540",
    "end": "1297710"
  },
  {
    "text": "But you sort of see what\nare real life problems.",
    "start": "1297710",
    "end": "1303070"
  },
  {
    "text": "And of course, we're highly,\nespecially interested in getting to the deep\nlearning examples, which",
    "start": "1303070",
    "end": "1310990"
  },
  {
    "text": "are underdetermined. Then when you're\nunderdetermined, you've got many solutions,\nand the question",
    "start": "1310990",
    "end": "1318850"
  },
  {
    "text": "is, which one is a good one? And in deep learning,\nI just can't resist saying another word.",
    "start": "1318850",
    "end": "1325420"
  },
  {
    "text": " So there are many solutions.",
    "start": "1325420",
    "end": "1332840"
  },
  {
    "text": "What to do? Well, you pick some algorithm,\nlike steepest descent, which",
    "start": "1332840",
    "end": "1340350"
  },
  {
    "text": "is going to find a solution. So you hope it's a good one.",
    "start": "1340350",
    "end": "1345789"
  },
  {
    "text": "And what does a good one\nmean verses a not good one? They're all solutions.",
    "start": "1345790",
    "end": "1351570"
  },
  {
    "text": "A good one means that when\nyou apply it to the test data that you haven't yet seen,\nit gives good results",
    "start": "1351570",
    "end": "1359080"
  },
  {
    "text": "on the test data. The solution has\nlearned something from the training data, and\nit works on the test data.",
    "start": "1359080",
    "end": "1367220"
  },
  {
    "text": "So that's the big\nquestion in deep learning. How does it happen that you,\nby doing gradient descent",
    "start": "1367220",
    "end": "1375640"
  },
  {
    "text": "or whatever algorithm-- how does that algorithm\nbias the solution?",
    "start": "1375640",
    "end": "1382610"
  },
  {
    "text": "It's called implicit bias. How does that algorithm\nbias a solution toward a solution\nthat generalizes,",
    "start": "1382610",
    "end": "1391809"
  },
  {
    "text": "that works on test data? And you can think\nof algorithms which would approach a solution that\ndid not work on test data.",
    "start": "1391810",
    "end": "1401160"
  },
  {
    "text": "So that's what you\nwant to stay away from. You want the ones that work. So there's very deep\nmath questions there,",
    "start": "1401160",
    "end": "1411050"
  },
  {
    "text": "which are kind of new. They didn't arise\nuntil they did.",
    "start": "1411050",
    "end": "1416429"
  },
  {
    "text": "And we'll try to save some\nof what's being understood.",
    "start": "1416430",
    "end": "1425190"
  },
  {
    "text": "Can I focus now on,\nfor probably the rest",
    "start": "1425190",
    "end": "1430980"
  },
  {
    "text": "of today, this case, when the\nmatrix is nearly singular?",
    "start": "1430980",
    "end": "1437030"
  },
  {
    "text": "So you could apply\nelimination, but it would give a poor result.\nSo one solution is the SVD.",
    "start": "1437030",
    "end": "1451330"
  },
  {
    "text": "I haven't even mentioned the\nSVD, here, as an algorithm, but of course, it is. The SVD gives you an answer.",
    "start": "1451330",
    "end": "1460340"
  },
  {
    "text": "Boy, where should\nthat have gone? Well, the space\nover here, the SVD.",
    "start": "1460340",
    "end": "1467660"
  },
  {
    "text": "So that produces-- you have\nA = U sigma V transposed,",
    "start": "1467660",
    "end": "1475160"
  },
  {
    "text": "and then A inverse is V\nsigma inverse U transposed.",
    "start": "1475160",
    "end": "1480320"
  },
  {
    "start": "1480320",
    "end": "1486669"
  },
  {
    "text": "So we're in the case, here. We're talking about number 5. Nearly singular, where\nsigma has some very small,",
    "start": "1486670",
    "end": "1494620"
  },
  {
    "text": "singular values. Then sigma inverse has some\nvery big singular values.",
    "start": "1494620",
    "end": "1500570"
  },
  {
    "text": "So you're really\nin wild territory",
    "start": "1500570",
    "end": "1507220"
  },
  {
    "text": "here with very big inverses. So that would be\none way to do it.",
    "start": "1507220",
    "end": "1513080"
  },
  {
    "text": "But this is a way to\nregularize the problem.",
    "start": "1513080",
    "end": "1519340"
  },
  {
    "text": "So let's just pay\nattention to that. ",
    "start": "1519340",
    "end": "1528730"
  },
  {
    "text": "So suppose I minimize the sum\nof A x minus b squared and delta",
    "start": "1528730",
    "end": "1536799"
  },
  {
    "text": "squared times the\nsize of x squared. And I'm going to\nuse the L2 norm.",
    "start": "1536800",
    "end": "1543370"
  },
  {
    "text": "It's going to be a least\nsquares with penalty,",
    "start": "1543370",
    "end": "1548410"
  },
  {
    "text": "so of course, it's\nthe L2 norm here, too. ",
    "start": "1548410",
    "end": "1555240"
  },
  {
    "text": "Suppose I solve\nthat for a delta. For some, I have to\nchoose a positive delta.",
    "start": "1555240",
    "end": "1563820"
  },
  {
    "text": " And when I choose\na positive delta, then I have a solvable problem.",
    "start": "1563820",
    "end": "1572070"
  },
  {
    "text": "Even if this goes to 0,\nor A does crazy things,",
    "start": "1572070",
    "end": "1577830"
  },
  {
    "text": "this is going to keep\nme away from singular.",
    "start": "1577830",
    "end": "1583710"
  },
  {
    "text": "In fact, what equation\ndoes that lead to? So that's a least squares\nproblem with an extra penalty",
    "start": "1583710",
    "end": "1591480"
  },
  {
    "text": "term. So it would come, I suppose. Let's see, if I write\nthe equations A delta I,",
    "start": "1591480",
    "end": "1602260"
  },
  {
    "text": "x equals b 0, maybe that is\nthe least squares equation--",
    "start": "1602260",
    "end": "1613170"
  },
  {
    "text": "the usual, normal equation-- for this augmented system.",
    "start": "1613170",
    "end": "1619200"
  },
  {
    "text": "Because what's the error here? This is the new big A-- A star, let's say.",
    "start": "1619200",
    "end": "1625214"
  },
  {
    "text": " X equals-- this is the new b.",
    "start": "1625214",
    "end": "1630549"
  },
  {
    "text": " So if I apply least squares\nto that, what do I do?",
    "start": "1630550",
    "end": "1639850"
  },
  {
    "text": "I minimize the sum of squares. ",
    "start": "1639850",
    "end": "1645580"
  },
  {
    "text": "So least squares would\nminimize A x minus b squared. That would be from\nthe first components.",
    "start": "1645580",
    "end": "1652720"
  },
  {
    "text": "And delta squared x squared\nfrom the last component, which",
    "start": "1652720",
    "end": "1660789"
  },
  {
    "text": "is exactly what we\nsaid we were doing. So in a way, this\nis the equation",
    "start": "1660790",
    "end": "1667480"
  },
  {
    "text": "that the penalty\nmethod is solving. And one question, naturally,\nis, what should delta be?",
    "start": "1667480",
    "end": "1677530"
  },
  {
    "text": "Well, that question's\nbeyond us, today. It's a balance of\nwhat you can believe,",
    "start": "1677530",
    "end": "1686799"
  },
  {
    "text": "and how much noise is in\nthe system, and everything.",
    "start": "1686800",
    "end": "1691900"
  },
  {
    "text": "That choice of delta-- what we could ask\nis a math question.",
    "start": "1691900",
    "end": "1698830"
  },
  {
    "text": "What happens as delta goes to 0? So suppose I solve this problem.",
    "start": "1698830",
    "end": "1705049"
  },
  {
    "text": "Let's see, I could\nwrite it differently. What would be the\nequation, here?",
    "start": "1705050",
    "end": "1711430"
  },
  {
    "text": "This part would give\nus the A transpose, and then this part would\ngive us just the identity,",
    "start": "1711430",
    "end": "1719890"
  },
  {
    "text": "x equals A transpose b, I think.",
    "start": "1719890",
    "end": "1725620"
  },
  {
    "text": "Wouldn't that be? So really, I've written here-- what that is is A\nstar transpose A star.",
    "start": "1725620",
    "end": "1733570"
  },
  {
    "text": "This is least squares on\nthis gives that equation.",
    "start": "1733570",
    "end": "1740440"
  },
  {
    "text": "So all of those are equivalent. All of those would be\nequivalent statements",
    "start": "1740440",
    "end": "1745510"
  },
  {
    "text": "of what the penalized problem\nis that you're solving. And then the question is, as\ndelta goes to 0, what happens?",
    "start": "1745510",
    "end": "1754390"
  },
  {
    "text": " Of course, something. When delta goes to 0, you're\nfalling off the cliff.",
    "start": "1754390",
    "end": "1762610"
  },
  {
    "text": "Something quite\ndifferent is suddenly going to happen, there. Maybe we could even understand\nthis question with a 1",
    "start": "1762610",
    "end": "1773470"
  },
  {
    "text": "by 1 matrix. I think this section\nstarts with a 1 by 1.",
    "start": "1773470",
    "end": "1779830"
  },
  {
    "text": "Suppose A is just a number.  Maybe I'll just put that\non this board, here.",
    "start": "1779830",
    "end": "1787370"
  },
  {
    "text": "Suppose A is just a number.  So what am I going\nto call that number?",
    "start": "1787370",
    "end": "1794300"
  },
  {
    "text": "Just 1 by 1. Let me call it sigma,\nbecause it's certainly the leading singular value.",
    "start": "1794300",
    "end": "1800230"
  },
  {
    "start": "1800230",
    "end": "1806520"
  },
  {
    "text": "So what's my equation\nthat I'm solving? A transpose A would be sigma\nsquared plus delta squared, 1",
    "start": "1806520",
    "end": "1815500"
  },
  {
    "text": "by 1, x-- should I give some\nsubscript here?",
    "start": "1815500",
    "end": "1820690"
  },
  {
    "text": "I should, really,\nto do it right. This is the solution\nfor a given delta.",
    "start": "1820690",
    "end": "1826750"
  },
  {
    "start": "1826750",
    "end": "1832150"
  },
  {
    "text": "So that solution will exist. Fine. This matrix is\ncertainly invertible. That's positive\nsemidefinite, at least.",
    "start": "1832150",
    "end": "1840460"
  },
  {
    "text": "That's positive\nsemidefinite, and then what about delta squared I?",
    "start": "1840460",
    "end": "1845529"
  },
  {
    "text": "It is positive\ndefinite, of course. It's just the identity\nwith a factor.",
    "start": "1845530",
    "end": "1852680"
  },
  {
    "text": "So this is a positive\ndefinite matrix. I certainly have a solution. And let me keep going\non this 1 by 1 case.",
    "start": "1852680",
    "end": "1861500"
  },
  {
    "text": "This would be A transpose. A is just a sigma. I think it's just sigma b.",
    "start": "1861500",
    "end": "1866889"
  },
  {
    "text": " So A is 1 by 1, and there\nare two cases, here--",
    "start": "1866890",
    "end": "1877890"
  },
  {
    "text": "Sigma bigger than 0,\nor sigma equals 0.",
    "start": "1877890",
    "end": "1885230"
  },
  {
    "text": "And in either case, I just\nwant to know what's the limit. So the answer x--",
    "start": "1885230",
    "end": "1892310"
  },
  {
    "text": "let me just take\nthe right hand side. Well, that's fine. ",
    "start": "1892310",
    "end": "1899140"
  },
  {
    "text": "Am I computing OK? Using the penalize thing on a\n1 by 1 problem, which you could",
    "start": "1899140",
    "end": "1907580"
  },
  {
    "text": "say is a little bit small-- so solving this equation or\nequivalently minimizing this,",
    "start": "1907580",
    "end": "1920620"
  },
  {
    "text": "so here, I'm finding\nthe minimum of-- ",
    "start": "1920620",
    "end": "1927590"
  },
  {
    "text": "A was sigma x minus b squared\nplus delta squared x squared.",
    "start": "1927590",
    "end": "1934029"
  },
  {
    "text": " You see it's just 1 by 1?",
    "start": "1934030",
    "end": "1940620"
  },
  {
    "text": "Just a number. And I'm hoping that calculus\nwill agree with linear algebra here, that if I find\nthe minimum of this--",
    "start": "1940620",
    "end": "1949059"
  },
  {
    "text": "so let me write it out. Sigma squared x squared and\ndelta squared x squared,",
    "start": "1949060",
    "end": "1956170"
  },
  {
    "text": "and then minus 2 sigma xb,\nand then plus b squared.",
    "start": "1956170",
    "end": "1962820"
  },
  {
    "text": "And now, I'm going to find\nthe minimum, which means I'd set the derivative to 0.",
    "start": "1962820",
    "end": "1968490"
  },
  {
    "text": "So I get 2 sigma squared\nand 2 delta squared. I get a two here,\nand this gives me",
    "start": "1968490",
    "end": "1975780"
  },
  {
    "text": "the x derivative as 2 sigma b. So I get a 2 there, and I'm OK. I just cancel both 2s,\nand that's the equation.",
    "start": "1975780",
    "end": "1986610"
  },
  {
    "text": "So I can solve that equation. X is sigma over sigma\nsquared plus delta squared b.",
    "start": "1986610",
    "end": "1999110"
  },
  {
    "text": "So it's really that quantity. I want to let delta go to 0.",
    "start": "1999110",
    "end": "2005230"
  },
  {
    "text": " So again, what am I doing here?",
    "start": "2005230",
    "end": "2011960"
  },
  {
    "text": "I'm taking a 1 by 1\nexample just to see what happens in the\nlimit as delta goes to 0.",
    "start": "2011960",
    "end": "2022840"
  },
  {
    "text": "What happens? So I just have to look at that.",
    "start": "2022840",
    "end": "2028299"
  },
  {
    "text": "What is the limit of that\nthing in a circle, as delta",
    "start": "2028300",
    "end": "2034130"
  },
  {
    "text": "goes to 0? So I'm finding out for\na 1 by 1 problem what a penalized least squares\nproblem, ridge regression,",
    "start": "2034130",
    "end": "2044390"
  },
  {
    "text": "all over the place-- what happens? So what happens to that\nnumber as delta goes to 0?",
    "start": "2044390",
    "end": "2052690"
  },
  {
    "text": " 1 over sigma. So now, let delta go to 0.",
    "start": "2052690",
    "end": "2061669"
  },
  {
    "text": "So that approaches 1 over\nsigma, because delta disappears.",
    "start": "2061670",
    "end": "2067158"
  },
  {
    "text": "Sigma over sigma\nsquared, 1 over sigma. So it approaches the\ninverse, but what's",
    "start": "2067159",
    "end": "2074590"
  },
  {
    "text": "the other possibility, here? The other possibility\nis that sigma is 0.",
    "start": "2074590",
    "end": "2081379"
  },
  {
    "text": "I didn't say whether this\nmatrix, this 1 by 1 matrix, was invertible or not.",
    "start": "2081380",
    "end": "2086908"
  },
  {
    "text": "If sigma is not 0, then\nI go to 1 over sigma.",
    "start": "2086909",
    "end": "2093500"
  },
  {
    "text": "If sigma is really small,\nit will take a while. Delta will have to get small,\nsmall, small, even compared",
    "start": "2093500",
    "end": "2100930"
  },
  {
    "text": "to sigma, until finally,\nthat term goes away, and I just have 1 over sigma.",
    "start": "2100930",
    "end": "2106000"
  },
  {
    "text": "But what if sigma is 0? Sorry to get excited about 0.",
    "start": "2106000",
    "end": "2114410"
  },
  {
    "text": "Who would get excited about 0? So this is the case when\nthis is 1 over sigma,",
    "start": "2114410",
    "end": "2120840"
  },
  {
    "text": "if sigma is positive. And what does it\napproach if sigma is 0? ",
    "start": "2120840",
    "end": "2128079"
  },
  {
    "text": "0! Because this is 0,\nthe whole problem was like disappeared, here.",
    "start": "2128080",
    "end": "2134809"
  },
  {
    "text": "The sigma was 0. Here is a sigma. So anyway, if sigma is 0, then\nI'm getting 0 all the time.",
    "start": "2134810",
    "end": "2148430"
  },
  {
    "text": "But I have a decent\nproblem, because the delta squared is there. I have a decent problem\nuntil the last minute.",
    "start": "2148430",
    "end": "2153920"
  },
  {
    "text": "My problem falls apart. Delta goes to 0, and I\nhave a 0 equals 0 problem. I'm lost.",
    "start": "2153920",
    "end": "2159440"
  },
  {
    "text": "But the point is the\npenalty kept me positive. It kept me with his\ndelta squared term",
    "start": "2159440",
    "end": "2167300"
  },
  {
    "text": "until the last critical moment. It kept me positive\neven if that was 0.",
    "start": "2167300",
    "end": "2174260"
  },
  {
    "text": "If that is 0, and this is 0,\nI still have something here.",
    "start": "2174260",
    "end": "2179600"
  },
  {
    "text": "I still have a problem to solve. And what's the limit then? So 1 over sigma if\nsigma is positive.",
    "start": "2179600",
    "end": "2189050"
  },
  {
    "text": "And what's the answer if\nsigma is not positive? It's 0.",
    "start": "2189050",
    "end": "2194690"
  },
  {
    "text": "Just tell me. I'm getting 0. I get 0 all the way, and\nI get 0 in the limit.",
    "start": "2194690",
    "end": "2200750"
  },
  {
    "start": "2200750",
    "end": "2207080"
  },
  {
    "text": "And now, let me just ask,\nwhat have I got here?",
    "start": "2207080",
    "end": "2213450"
  },
  {
    "text": "What is this sudden bifurcation?",
    "start": "2213450",
    "end": "2219869"
  },
  {
    "text": "Do I recognize this? The inverse in the\nlimit as delta goes to 0",
    "start": "2219870",
    "end": "2226710"
  },
  {
    "text": "is either 1 over sigma,\nif that makes sense, or it's 0, which is\nnot like 1 over sigma.",
    "start": "2226710",
    "end": "2234090"
  },
  {
    "text": "1 over sigma-- as\nsigma goes to 0, this thing is getting\nbigger and bigger.",
    "start": "2234090",
    "end": "2239130"
  },
  {
    "text": "But at sigma equals 0, it's 0. You see, that's a really\nstrange kind of a limit.",
    "start": "2239130",
    "end": "2247230"
  },
  {
    "text": " Now, it would be over there.",
    "start": "2247230",
    "end": "2252810"
  },
  {
    "text": "What have I found\nhere, in this limit?",
    "start": "2252810",
    "end": "2258910"
  },
  {
    "text": "Say it again, because\nthat was exactly right. The pseudo inverse. So this system-- choose\ndelta greater than 0,",
    "start": "2258910",
    "end": "2269290"
  },
  {
    "text": "then delta going to 0. The solution goes to\nthe pseudo inverse.",
    "start": "2269290",
    "end": "2275710"
  },
  {
    "text": " That's the key fact.",
    "start": "2275710",
    "end": "2281680"
  },
  {
    "text": " When delta is\nreally, really small,",
    "start": "2281680",
    "end": "2287980"
  },
  {
    "text": "then this behaves in\na pretty crazy way. If delta is really, really\nsmall, then sigma is bigger,",
    "start": "2287980",
    "end": "2298770"
  },
  {
    "text": "or it's 0. If it's bigger, you go this way. If it's 0, you go that way. ",
    "start": "2298770",
    "end": "2307850"
  },
  {
    "text": "So that's the message,\nand this is penalized.",
    "start": "2307850",
    "end": "2312972"
  },
  {
    "start": "2312972",
    "end": "2319240"
  },
  {
    "text": "These squares, as the penalty\ngets smaller and smaller,",
    "start": "2319240",
    "end": "2325550"
  },
  {
    "text": "approaches the correct answer,\nthe always correct answer, with that sudden split\nbetween 0 and not 0",
    "start": "2325550",
    "end": "2334600"
  },
  {
    "text": "that we associate with\nthe pseudo inverse.",
    "start": "2334600",
    "end": "2341020"
  },
  {
    "text": "Of course, in a\npractical case, you're trying to find the resistances\nand inductions in a circuit",
    "start": "2341020",
    "end": "2349860"
  },
  {
    "text": "by trying the circuit, and\nlooking at the output b,",
    "start": "2349860",
    "end": "2356460"
  },
  {
    "text": "and figuring out what input. ",
    "start": "2356460",
    "end": "2361809"
  },
  {
    "text": "So the unknown x is the\nunknown system parameters.",
    "start": "2361810",
    "end": "2369100"
  },
  {
    "text": "Not the voltage and current, but\nthe resistance, and inductance, and capacitance.",
    "start": "2369100",
    "end": "2374953"
  },
  {
    "start": "2374953",
    "end": "2382251"
  },
  {
    "text": "I've only proved that\nin the 1 by 1 case. You may say that's\nnot much of a proof.",
    "start": "2382251",
    "end": "2389790"
  },
  {
    "text": "In the 1 by 1 case, we can see\nit happen in front of our eyes.",
    "start": "2389790",
    "end": "2396840"
  },
  {
    "text": "So really, a step I\nhaven't taken here is to complete that\nto any matrix A.",
    "start": "2396840",
    "end": "2407320"
  },
  {
    "text": "So that the statement then. That's the statement. ",
    "start": "2407320",
    "end": "2420500"
  },
  {
    "text": "So that's the statement. For any matrix A, this matrix,\nA transpose A plus delta",
    "start": "2420500",
    "end": "2429820"
  },
  {
    "text": "squared inverse\ntimes A transpose--",
    "start": "2429820",
    "end": "2435010"
  },
  {
    "text": "that's the solution\nmatrix to our problem. ",
    "start": "2435010",
    "end": "2440700"
  },
  {
    "text": "That's what I wrote\ndown up there. I take the inverse\nand pop it over there. That approaches A plus,\nthe pseudo inverse.",
    "start": "2440700",
    "end": "2454020"
  },
  {
    "start": "2454020",
    "end": "2459480"
  },
  {
    "text": "And that's what we just\nchecked for 1 by 1. For 1 by 1, this\nwas sigma over sigma",
    "start": "2459480",
    "end": "2467220"
  },
  {
    "text": "squared plus delta squared. And it went either to\n1 over sigma or to 0.",
    "start": "2467220",
    "end": "2478099"
  },
  {
    "text": "It split in the limit. It shows that limits\ncan be delicate.",
    "start": "2478100",
    "end": "2483460"
  },
  {
    "text": "The limit-- as delta\ngoes to 0, this thing is suddenly discontinuous.",
    "start": "2483460",
    "end": "2488920"
  },
  {
    "text": "It's this number\nthat is growing, and then suddenly, at\n0, it falls back to 0.",
    "start": "2488920",
    "end": "2495099"
  },
  {
    "text": "Anyway, that would\nbe the statement. Actually, statisticians\ndiscovered the pseudo inverse",
    "start": "2495100",
    "end": "2502810"
  },
  {
    "text": "independently of the linear\nalgebra history of it,",
    "start": "2502810",
    "end": "2509620"
  },
  {
    "text": "because statisticians\ndid exactly that. To regularize the problem,\nthey introduced a penalty",
    "start": "2509620",
    "end": "2518620"
  },
  {
    "text": "and worked with this matrix. So statisticians were\nthe first to think",
    "start": "2518620",
    "end": "2527980"
  },
  {
    "text": "of that as a natural thing\nto do in a practical case--",
    "start": "2527980",
    "end": "2533642"
  },
  {
    "text": "add a penalty. ",
    "start": "2533642",
    "end": "2539020"
  },
  {
    "text": "So this is adding a\npenalty, but remember that we stayed with L2 norms,\nstaying with L2, least squares.",
    "start": "2539020",
    "end": "2550730"
  },
  {
    "start": "2550730",
    "end": "2558000"
  },
  {
    "text": "We could ask, what happens? Suppose the penalty\nis the L1 norm.",
    "start": "2558000",
    "end": "2565050"
  },
  {
    "text": " I'm not up to do this today.",
    "start": "2565050",
    "end": "2570839"
  },
  {
    "text": "Suppose I minimize that. Maybe I'll do L2, but I'll do\nthe penalty guy in the L1 norm.",
    "start": "2570840",
    "end": "2581666"
  },
  {
    "start": "2581666",
    "end": "2587850"
  },
  {
    "text": "I'm certainly not\nan expert on that. Or you could even\nthink just that power.",
    "start": "2587850",
    "end": "2595290"
  },
  {
    "text": "So that would have a name. A statistician invented this.",
    "start": "2595290",
    "end": "2601589"
  },
  {
    "text": "It's called the Lasso in the\nL1 norm, and it's a big deal.",
    "start": "2601590",
    "end": "2607100"
  },
  {
    "text": "Statisticians like the\nL1 norm, because it",
    "start": "2607100",
    "end": "2616600"
  },
  {
    "text": "gives sparse solutions. It gives more genuine\nsolutions without a whole lot",
    "start": "2616600",
    "end": "2621700"
  },
  {
    "text": "of little components\nin the answer. So this was an important step.",
    "start": "2621700",
    "end": "2628660"
  },
  {
    "text": " Let me just say again where\nwe are in that big list.",
    "start": "2628660",
    "end": "2636695"
  },
  {
    "text": " The two important ones\nthat I haven't done yet",
    "start": "2636695",
    "end": "2644970"
  },
  {
    "text": "are these iterative\nmethods in 2.1. So that's like conventional\nlinear algebra,",
    "start": "2644970",
    "end": "2652589"
  },
  {
    "text": "just how to deal\nwith a big matrix, maybe with some\nspecial structure. That's what numerical\nlinear algebra is all about.",
    "start": "2652590",
    "end": "2661740"
  },
  {
    "text": "And then Gram-Schmidt\nwith or without pivoting,",
    "start": "2661740",
    "end": "2667790"
  },
  {
    "text": "which is a workhorse\nof numerical computing, and I think I better\nsave that for next time.",
    "start": "2667790",
    "end": "2677349"
  },
  {
    "text": "So this is the one I\npicked for this time.",
    "start": "2677350",
    "end": "2682870"
  },
  {
    "text": "And we saw what happened in L2. Well, we saw it for 1 by 1.",
    "start": "2682870",
    "end": "2689290"
  },
  {
    "text": "Would you want to extend\nto prove this for any A,",
    "start": "2689290",
    "end": "2696740"
  },
  {
    "text": "going beyond 1 by 1? How would you prove\nsuch a thing for any A?",
    "start": "2696740",
    "end": "2705734"
  },
  {
    "text": "I guess I'm not going to do it. It's too painful, but\nhow would you do it?",
    "start": "2705735",
    "end": "2717930"
  },
  {
    "text": "You would use the SVD. If you want to prove something\nabout matrices, about",
    "start": "2717930",
    "end": "2723780"
  },
  {
    "text": "any matrix, the SVD\nis the best thing you could have-- the\nbest tool you could have.",
    "start": "2723780",
    "end": "2730210"
  },
  {
    "text": "I can write this in\nterms of the SVD. I just plug-in A equals\nwhatever the SVD tells",
    "start": "2730210",
    "end": "2740830"
  },
  {
    "text": "me to put in there. U sigma V transposed.",
    "start": "2740830",
    "end": "2746600"
  },
  {
    "text": "Plug it in there,\nsimplify it using the fact that these are orthogonal.",
    "start": "2746600",
    "end": "2754370"
  },
  {
    "text": "If I have any good luck,\nit'll get an identity somewhere from there and an\nidentity somewhere from there.",
    "start": "2754370",
    "end": "2761110"
  },
  {
    "text": " And it will all simplify. It will all diagonalize.",
    "start": "2761110",
    "end": "2769480"
  },
  {
    "text": "That's what the SVD really\ndoes is turns my messy problem into a problem about their\ndiagonal matrix, sigma",
    "start": "2769480",
    "end": "2777310"
  },
  {
    "text": "in the middle. So I might as well put\nsigma in the middle. Yeah, why not? Before we give up on it--",
    "start": "2777310",
    "end": "2783627"
  },
  {
    "text": " a special case of that, but\nreally, the genuine case",
    "start": "2783627",
    "end": "2792340"
  },
  {
    "text": "would be when A is sigma. Sigma transpose sigma plus\ndelta squared I inverse times",
    "start": "2792340",
    "end": "2801580"
  },
  {
    "text": "sigma transpose approaches the\npseudo inverse, sigma plus.",
    "start": "2801580",
    "end": "2809820"
  },
  {
    "text": "And the point is the matrix\nsigma here is diagonal. ",
    "start": "2809820",
    "end": "2815840"
  },
  {
    "text": "Oh, I'm practically\nthere, actually. Why am I close to being\nable to read this off?",
    "start": "2815840",
    "end": "2826390"
  },
  {
    "text": "Well, everything\nis diagonal here. Diagonal, diagonal, diagonal. ",
    "start": "2826390",
    "end": "2833340"
  },
  {
    "text": "And what's happening on\nthose diagonal entries? ",
    "start": "2833340",
    "end": "2840690"
  },
  {
    "text": "So you had to take my word\nthat when I plugged in the SVD, the U and the V got\nseparated out to the far left",
    "start": "2840690",
    "end": "2850050"
  },
  {
    "text": "and the far right. And it was that that\nstayed in the middle.",
    "start": "2850050",
    "end": "2855940"
  },
  {
    "text": "So it's really this\nis the heart of it. And say, well, that's\ndiagonal matrix.",
    "start": "2855940",
    "end": "2866569"
  },
  {
    "text": "So I'm just looking at what\nhappens on each diagonal entry,",
    "start": "2866570",
    "end": "2872010"
  },
  {
    "text": "and which problem is that? The question of what's happening\non a typical diagonal entry",
    "start": "2872010",
    "end": "2879520"
  },
  {
    "text": "of this thing is what question?",
    "start": "2879520",
    "end": "2885020"
  },
  {
    "text": "The 1 by 1 case! The 1 by 1, because each\nentry in the diagonal",
    "start": "2885020",
    "end": "2891660"
  },
  {
    "text": "is not even noticing the others. So that's the logic, and\nit would be in the notes.",
    "start": "2891660",
    "end": "2899940"
  },
  {
    "text": "Prove it first for 1 by 1,\nthen secondly for diagonal.",
    "start": "2899940",
    "end": "2907450"
  },
  {
    "text": "This, and finally with A's,\nand they're using the SVD with",
    "start": "2907450",
    "end": "2913750"
  },
  {
    "text": "and U and V transposed\nto get out of the way and bring us back to here.",
    "start": "2913750",
    "end": "2919720"
  },
  {
    "text": "So that's the\ntheory, but really, I",
    "start": "2919720",
    "end": "2925750"
  },
  {
    "text": "guess I'm thinking that far\nthe most important message",
    "start": "2925750",
    "end": "2930910"
  },
  {
    "text": "in today's lecture is in\nthis list of different types",
    "start": "2930910",
    "end": "2937839"
  },
  {
    "text": "of problems that appear\nand different ways to work with them.",
    "start": "2937840",
    "end": "2943630"
  },
  {
    "text": "And we haven't\ndone Gram-Schmidt, and we haven't done iteration.",
    "start": "2943630",
    "end": "2950920"
  },
  {
    "text": "So this chapter is a survey of--",
    "start": "2950920",
    "end": "2956470"
  },
  {
    "text": "well, more than a survey of\nwhat numerical linear algebra is about. And I haven't done random, yet.",
    "start": "2956470",
    "end": "2962370"
  },
  {
    "text": "Sorry, that's coming, too.  So three pieces\nare still to come,",
    "start": "2962370",
    "end": "2969119"
  },
  {
    "text": "but let's take the last two\nminutes off and call it a day.",
    "start": "2969120",
    "end": "2975252"
  },
  {
    "start": "2975252",
    "end": "2975752"
  }
]
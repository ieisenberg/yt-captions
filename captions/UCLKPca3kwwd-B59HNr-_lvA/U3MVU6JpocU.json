[
  {
    "text": "hi everybody my name is Anita and I'm",
    "start": "280",
    "end": "2480"
  },
  {
    "text": "currently leading gen growth and",
    "start": "2480",
    "end": "4040"
  },
  {
    "text": "education here at vum and over the last",
    "start": "4040",
    "end": "6399"
  },
  {
    "text": "few years we worked with hundreds of",
    "start": "6399",
    "end": "8320"
  },
  {
    "text": "companies who have successfully deployed",
    "start": "8320",
    "end": "10519"
  },
  {
    "text": "reliable AI Solutions in production from",
    "start": "10519",
    "end": "13200"
  },
  {
    "text": "simple to more advanced agentic",
    "start": "13200",
    "end": "15000"
  },
  {
    "text": "workflows one thing became very clear",
    "start": "15000",
    "end": "18119"
  },
  {
    "text": "those companies who have adopted a test",
    "start": "18119",
    "end": "20480"
  },
  {
    "text": "driven development approach were able to",
    "start": "20480",
    "end": "22840"
  },
  {
    "text": "build reliable and stronger systems for",
    "start": "22840",
    "end": "25880"
  },
  {
    "text": "production today I'm excited to share",
    "start": "25880",
    "end": "28160"
  },
  {
    "text": "how you can apply that same approach to",
    "start": "28160",
    "end": "30439"
  },
  {
    "text": "build your own effective agentic",
    "start": "30439",
    "end": "32119"
  },
  {
    "text": "workflow that actually works but before",
    "start": "32119",
    "end": "35040"
  },
  {
    "text": "we jump in let's take a step back and",
    "start": "35040",
    "end": "37719"
  },
  {
    "text": "truly understand how we got here in the",
    "start": "37719",
    "end": "39760"
  },
  {
    "text": "first place I'm so excited to get",
    "start": "39760",
    "end": "41640"
  },
  {
    "text": "started let's do it so let's go back to",
    "start": "41640",
    "end": "44559"
  },
  {
    "text": "2023 everyone was building AI rappers",
    "start": "44559",
    "end": "47719"
  },
  {
    "text": "and most people argued that there is no",
    "start": "47719",
    "end": "50079"
  },
  {
    "text": "defensibility strategy around them and",
    "start": "50079",
    "end": "52640"
  },
  {
    "text": "fast forward to today we have cursor AI",
    "start": "52640",
    "end": "55559"
  },
  {
    "text": "which is the most popular and wildly",
    "start": "55559",
    "end": "57520"
  },
  {
    "text": "used AI powered IDE that just hit 100",
    "start": "57520",
    "end": "61600"
  },
  {
    "text": "million AR in just 12 months this is the",
    "start": "61600",
    "end": "65239"
  },
  {
    "text": "fastest growing SAS in the history of",
    "start": "65239",
    "end": "67880"
  },
  {
    "text": "SAS so why and how did this happen",
    "start": "67880",
    "end": "71600"
  },
  {
    "text": "because models got better at coding sure",
    "start": "71600",
    "end": "74520"
  },
  {
    "text": "because AI adoption skyrocketed that's",
    "start": "74520",
    "end": "77280"
  },
  {
    "text": "absolutely correct because coding was an",
    "start": "77280",
    "end": "79680"
  },
  {
    "text": "obvious first Target that was supposed",
    "start": "79680",
    "end": "81960"
  },
  {
    "text": "to be disrupted by these AI models there",
    "start": "81960",
    "end": "84240"
  },
  {
    "text": "is no doubt about that but more",
    "start": "84240",
    "end": "86560"
  },
  {
    "text": "importantly we built new techniques and",
    "start": "86560",
    "end": "89200"
  },
  {
    "text": "patterns on how how we can orchestrate",
    "start": "89200",
    "end": "91159"
  },
  {
    "text": "these models to work better sync better",
    "start": "91159",
    "end": "93920"
  },
  {
    "text": "with our data and then work effectively",
    "start": "93920",
    "end": "95960"
  },
  {
    "text": "in production we rely on these",
    "start": "95960",
    "end": "98079"
  },
  {
    "text": "techniques because there are clear",
    "start": "98079",
    "end": "99439"
  },
  {
    "text": "limits to model performance",
    "start": "99439",
    "end": "101159"
  },
  {
    "text": "hallucinations is still a thing",
    "start": "101159",
    "end": "103119"
  },
  {
    "text": "overfitting is still a problem and",
    "start": "103119",
    "end": "105079"
  },
  {
    "text": "developers needed more structured",
    "start": "105079",
    "end": "106759"
  },
  {
    "text": "outputs and while model providers",
    "start": "106759",
    "end": "108799"
  },
  {
    "text": "started to ship better tooling to Sol",
    "start": "108799",
    "end": "111360"
  },
  {
    "text": "for all of this we didn't see another",
    "start": "111360",
    "end": "113880"
  },
  {
    "text": "lip similar to the lip between GPD 3.5",
    "start": "113880",
    "end": "117479"
  },
  {
    "text": "and gp4 these big jumps started to slow",
    "start": "117479",
    "end": "121119"
  },
  {
    "text": "down and for years making models bigger",
    "start": "121119",
    "end": "124280"
  },
  {
    "text": "and fitting them more data kept making",
    "start": "124280",
    "end": "126920"
  },
  {
    "text": "them smarter but then we hit a wall no",
    "start": "126920",
    "end": "130160"
  },
  {
    "text": "matter how much more data we added these",
    "start": "130160",
    "end": "132360"
  },
  {
    "text": "improvements started to slow down and",
    "start": "132360",
    "end": "134720"
  },
  {
    "text": "models started to reach their limits on",
    "start": "134720",
    "end": "137400"
  },
  {
    "text": "existing test but is this true did we",
    "start": "137400",
    "end": "140720"
  },
  {
    "text": "really hit that wall seems like there",
    "start": "140720",
    "end": "144120"
  },
  {
    "text": "were some other avenues and new trining",
    "start": "144120",
    "end": "147040"
  },
  {
    "text": "methods that we still haven't explored",
    "start": "147040",
    "end": "149920"
  },
  {
    "text": "and so let's see what happened next so I",
    "start": "149920",
    "end": "152400"
  },
  {
    "text": "don't really think that there is an",
    "start": "152400",
    "end": "153519"
  },
  {
    "text": "issue here because since then and this",
    "start": "153519",
    "end": "155879"
  },
  {
    "text": "happened in the last two to 3 months",
    "start": "155879",
    "end": "158000"
  },
  {
    "text": "we've seen some new training methods",
    "start": "158000",
    "end": "159760"
  },
  {
    "text": "that push the field forward for example",
    "start": "159760",
    "end": "162599"
  },
  {
    "text": "we got the Deep seek R1 model which is",
    "start": "162599",
    "end": "165239"
  },
  {
    "text": "the first model that was trained without",
    "start": "165239",
    "end": "167800"
  },
  {
    "text": "using any labeled data we call this",
    "start": "167800",
    "end": "170599"
  },
  {
    "text": "method real reinforcement learning and",
    "start": "170599",
    "end": "173159"
  },
  {
    "text": "this means that this model was able to",
    "start": "173159",
    "end": "175239"
  },
  {
    "text": "learn on its own reportedly this is what",
    "start": "175239",
    "end": "178400"
  },
  {
    "text": "open used to train their reasoning",
    "start": "178400",
    "end": "181000"
  },
  {
    "text": "models like 01 and 03 and all these",
    "start": "181000",
    "end": "183760"
  },
  {
    "text": "reasoning models today they use Chain of",
    "start": "183760",
    "end": "186440"
  },
  {
    "text": "Thought thinking at inference time or at",
    "start": "186440",
    "end": "189400"
  },
  {
    "text": "response time to generate their answers",
    "start": "189400",
    "end": "192360"
  },
  {
    "text": "in turn allowing these models to think",
    "start": "192360",
    "end": "195319"
  },
  {
    "text": "before they give an answer to our",
    "start": "195319",
    "end": "197480"
  },
  {
    "text": "questions it enables them to really",
    "start": "197480",
    "end": "200319"
  },
  {
    "text": "solve more complex reasoning problems on",
    "start": "200319",
    "end": "203239"
  },
  {
    "text": "top of this we're seeing all of these",
    "start": "203239",
    "end": "204879"
  },
  {
    "text": "model providers to provide more",
    "start": "204879",
    "end": "207519"
  },
  {
    "text": "capabilities to their models like use of",
    "start": "207519",
    "end": "210120"
  },
  {
    "text": "tools more capabilities for research um",
    "start": "210120",
    "end": "213159"
  },
  {
    "text": "near perfect OCR accuracy when it comes",
    "start": "213159",
    "end": "215760"
  },
  {
    "text": "to the Gemini 2.0 Flash and really",
    "start": "215760",
    "end": "218400"
  },
  {
    "text": "expand the field forward however",
    "start": "218400",
    "end": "221560"
  },
  {
    "text": "traditional benchmarks are so saturated",
    "start": "221560",
    "end": "224360"
  },
  {
    "text": "so people are starting to introduce new",
    "start": "224360",
    "end": "226599"
  },
  {
    "text": "ones that will really capture the",
    "start": "226599",
    "end": "228519"
  },
  {
    "text": "performance of these new reasoning",
    "start": "228519",
    "end": "230120"
  },
  {
    "text": "models for example The Benchmark that",
    "start": "230120",
    "end": "232560"
  },
  {
    "text": "you're currently seeing on the slide",
    "start": "232560",
    "end": "233920"
  },
  {
    "text": "here the humanities last last exam it",
    "start": "233920",
    "end": "236599"
  },
  {
    "text": "measures performance on truly difficult",
    "start": "236599",
    "end": "238920"
  },
  {
    "text": "tasks so if you check the table on the",
    "start": "238920",
    "end": "241040"
  },
  {
    "text": "slide you can clearly see that even the",
    "start": "241040",
    "end": "243319"
  },
  {
    "text": "latest very smart models struggle with",
    "start": "243319",
    "end": "246239"
  },
  {
    "text": "these challenges so yeah models are",
    "start": "246239",
    "end": "248640"
  },
  {
    "text": "getting better the field is moving",
    "start": "248640",
    "end": "250560"
  },
  {
    "text": "forward but for an AI product that",
    "start": "250560",
    "end": "253239"
  },
  {
    "text": "actually works in production success",
    "start": "253239",
    "end": "255400"
  },
  {
    "text": "isn't just about the models anymore it's",
    "start": "255400",
    "end": "257639"
  },
  {
    "text": "about how you build around it and that's",
    "start": "257639",
    "end": "260199"
  },
  {
    "text": "exactly what's been evolving in parallel",
    "start": "260199",
    "end": "263040"
  },
  {
    "text": "to model training so we were learning",
    "start": "263040",
    "end": "265400"
  },
  {
    "text": "how to prompt all of these models better",
    "start": "265400",
    "end": "267639"
  },
  {
    "text": "and we developed more Advanced",
    "start": "267639",
    "end": "269120"
  },
  {
    "text": "Techniques like Chain of Thought then we",
    "start": "269120",
    "end": "271520"
  },
  {
    "text": "thought that we should be able to ground",
    "start": "271520",
    "end": "273759"
  },
  {
    "text": "all of this models responses using our",
    "start": "273759",
    "end": "276560"
  },
  {
    "text": "own data so rag became an important part",
    "start": "276560",
    "end": "279919"
  },
  {
    "text": "of our workflows then we learned that",
    "start": "279919",
    "end": "282240"
  },
  {
    "text": "for multi-threaded conversations memory",
    "start": "282240",
    "end": "285320"
  },
  {
    "text": "is going to be the most important thing",
    "start": "285320",
    "end": "287080"
  },
  {
    "text": "that we've had long context from the",
    "start": "287080",
    "end": "290080"
  },
  {
    "text": "latest models enabled new use cases then",
    "start": "290080",
    "end": "292919"
  },
  {
    "text": "we started to think about hierarchy of",
    "start": "292919",
    "end": "294960"
  },
  {
    "text": "our responses so we started to",
    "start": "294960",
    "end": "296840"
  },
  {
    "text": "experiment with graph rack and then just",
    "start": "296840",
    "end": "299039"
  },
  {
    "text": "lately we're thinking about using all",
    "start": "299039",
    "end": "301240"
  },
  {
    "text": "this reasoning models that in fact will",
    "start": "301240",
    "end": "303759"
  },
  {
    "text": "take a lot more time to think in real",
    "start": "303759",
    "end": "306199"
  },
  {
    "text": "time however it also develops new areas",
    "start": "306199",
    "end": "309880"
  },
  {
    "text": "and use cases that we can develop and",
    "start": "309880",
    "end": "312000"
  },
  {
    "text": "lately we're thinking about a gentic rag",
    "start": "312000",
    "end": "314400"
  },
  {
    "text": "making our workflows even more powerful",
    "start": "314400",
    "end": "317039"
  },
  {
    "text": "so that all this can work on its own and",
    "start": "317039",
    "end": "320400"
  },
  {
    "text": "the field is still evolving but even",
    "start": "320400",
    "end": "322440"
  },
  {
    "text": "using these techniques isn't enough you",
    "start": "322440",
    "end": "324840"
  },
  {
    "text": "need to understand your problem deeply",
    "start": "324840",
    "end": "327440"
  },
  {
    "text": "and take a test driven development",
    "start": "327440",
    "end": "329360"
  },
  {
    "text": "approach to find the right mix of",
    "start": "329360",
    "end": "331720"
  },
  {
    "text": "techniques models and logic that will",
    "start": "331720",
    "end": "334479"
  },
  {
    "text": "actually work for your use case and this",
    "start": "334479",
    "end": "337120"
  },
  {
    "text": "actually brings me to the main first",
    "start": "337120",
    "end": "340560"
  },
  {
    "text": "topic of this presentation test driven",
    "start": "340560",
    "end": "343720"
  },
  {
    "text": "development for building reliable AI",
    "start": "343720",
    "end": "346199"
  },
  {
    "text": "products because the best AI teams that",
    "start": "346199",
    "end": "349440"
  },
  {
    "text": "I've seen follow this structured",
    "start": "349440",
    "end": "352080"
  },
  {
    "text": "approach they start to experiment then",
    "start": "352080",
    "end": "354639"
  },
  {
    "text": "they evaluate it scale then finally when",
    "start": "354639",
    "end": "357080"
  },
  {
    "text": "they deploy in production they never",
    "start": "357080",
    "end": "359280"
  },
  {
    "text": "stop stop working on their workflow they",
    "start": "359280",
    "end": "361520"
  },
  {
    "text": "capture all of those responses to then",
    "start": "361520",
    "end": "363720"
  },
  {
    "text": "continuously monitor observe and improve",
    "start": "363720",
    "end": "366639"
  },
  {
    "text": "their product for their customers let's",
    "start": "366639",
    "end": "369639"
  },
  {
    "text": "look at what you can do at every stage",
    "start": "369639",
    "end": "372280"
  },
  {
    "text": "of this process before you build",
    "start": "372280",
    "end": "374520"
  },
  {
    "text": "anything production grade you need to",
    "start": "374520",
    "end": "376639"
  },
  {
    "text": "experiment a lot you need to prove",
    "start": "376639",
    "end": "378960"
  },
  {
    "text": "whether these AI models can actually",
    "start": "378960",
    "end": "380800"
  },
  {
    "text": "solve for your use case so you should",
    "start": "380800",
    "end": "383240"
  },
  {
    "text": "try different prompting techniques for",
    "start": "383240",
    "end": "384880"
  },
  {
    "text": "example fuse shot or Chain of Thought",
    "start": "384880",
    "end": "387000"
  },
  {
    "text": "some of these will work great for simple",
    "start": "387000",
    "end": "388960"
  },
  {
    "text": "tasks and other will help with a bit",
    "start": "388960",
    "end": "391039"
  },
  {
    "text": "more complex reasoning you should test",
    "start": "391039",
    "end": "393199"
  },
  {
    "text": "various techniques prom chaining is",
    "start": "393199",
    "end": "395240"
  },
  {
    "text": "usually very uh well received because",
    "start": "395240",
    "end": "398000"
  },
  {
    "text": "it's going to work better if you split",
    "start": "398000",
    "end": "399680"
  },
  {
    "text": "your instructions in multiple prompts or",
    "start": "399680",
    "end": "401960"
  },
  {
    "text": "you can adopt a more agentic workflows",
    "start": "401960",
    "end": "404479"
  },
  {
    "text": "like react that will have a stage to",
    "start": "404479",
    "end": "406800"
  },
  {
    "text": "plan and then reason and refine before",
    "start": "406800",
    "end": "409000"
  },
  {
    "text": "it actually gives you an answer what is",
    "start": "409000",
    "end": "411199"
  },
  {
    "text": "really an important part in this stage",
    "start": "411199",
    "end": "413080"
  },
  {
    "text": "is that you need to involve your domain",
    "start": "413080",
    "end": "415240"
  },
  {
    "text": "experts um because Engineers shouldn't",
    "start": "415240",
    "end": "417520"
  },
  {
    "text": "be the ones who are tweaking prompts uh",
    "start": "417520",
    "end": "420000"
  },
  {
    "text": "and bringing all these experts will",
    "start": "420000",
    "end": "421680"
  },
  {
    "text": "actually save a lot of your engineering",
    "start": "421680",
    "end": "423479"
  },
  {
    "text": "time because once you do this phase",
    "start": "423479",
    "end": "426319"
  },
  {
    "text": "right then you will actually have a",
    "start": "426319",
    "end": "428720"
  },
  {
    "text": "proof that this works and that",
    "start": "428720",
    "end": "430479"
  },
  {
    "text": "engineering time needs to be involved at",
    "start": "430479",
    "end": "433800"
  },
  {
    "text": "this stage you should also stay model",
    "start": "433800",
    "end": "435440"
  },
  {
    "text": "agnostic uh you should incorporate and",
    "start": "435440",
    "end": "437680"
  },
  {
    "text": "has different models and especially when",
    "start": "437680",
    "end": "439280"
  },
  {
    "text": "it comes to your use case you need to",
    "start": "439280",
    "end": "440840"
  },
  {
    "text": "think about Which models can do the job",
    "start": "440840",
    "end": "443160"
  },
  {
    "text": "better so in such case you can um maybe",
    "start": "443160",
    "end": "445840"
  },
  {
    "text": "use some uh different uh models like",
    "start": "445840",
    "end": "448400"
  },
  {
    "text": "Gemini 2.0 flash which is actually",
    "start": "448400",
    "end": "450759"
  },
  {
    "text": "really well at OCR uh and something that",
    "start": "450759",
    "end": "453080"
  },
  {
    "text": "we've seen work really well lately so",
    "start": "453080",
    "end": "455639"
  },
  {
    "text": "let's say that at this stage you know",
    "start": "455639",
    "end": "457479"
  },
  {
    "text": "that U these AI models can actually work",
    "start": "457479",
    "end": "460199"
  },
  {
    "text": "you have a few examples that these",
    "start": "460199",
    "end": "461919"
  },
  {
    "text": "models have like really good performance",
    "start": "461919",
    "end": "464159"
  },
  {
    "text": "on but how can you test whether this",
    "start": "464159",
    "end": "466319"
  },
  {
    "text": "will actually work in production when",
    "start": "466319",
    "end": "469039"
  },
  {
    "text": "you will potentially have hundreds if",
    "start": "469039",
    "end": "471159"
  },
  {
    "text": "not thousands or millions of requests",
    "start": "471159",
    "end": "473520"
  },
  {
    "text": "per minute and so this is where",
    "start": "473520",
    "end": "475039"
  },
  {
    "text": "Evolution comes in in this stage you",
    "start": "475039",
    "end": "477440"
  },
  {
    "text": "actually create a data set of hundreds",
    "start": "477440",
    "end": "480080"
  },
  {
    "text": "of examples that you're going to test",
    "start": "480080",
    "end": "481599"
  },
  {
    "text": "your models and workflows against and so",
    "start": "481599",
    "end": "483960"
  },
  {
    "text": "at this stage you need to uh try to",
    "start": "483960",
    "end": "486199"
  },
  {
    "text": "balance quality and cost and latency and",
    "start": "486199",
    "end": "488720"
  },
  {
    "text": "privacy and you're definitely going to",
    "start": "488720",
    "end": "490520"
  },
  {
    "text": "make a lot of tradeoffs because no AI",
    "start": "490520",
    "end": "492960"
  },
  {
    "text": "system is going to get all of this",
    "start": "492960",
    "end": "494720"
  },
  {
    "text": "perfectly but for example if you need",
    "start": "494720",
    "end": "496960"
  },
  {
    "text": "high quality maybe you can sacrifice",
    "start": "496960",
    "end": "499039"
  },
  {
    "text": "speed if cost is critical you might need",
    "start": "499039",
    "end": "501520"
  },
  {
    "text": "some lighter and cheaper model and this",
    "start": "501520",
    "end": "504199"
  },
  {
    "text": "is the stage where where you need to",
    "start": "504199",
    "end": "505919"
  },
  {
    "text": "Define your priorities because it's",
    "start": "505919",
    "end": "507639"
  },
  {
    "text": "always better if you define your",
    "start": "507639",
    "end": "509680"
  },
  {
    "text": "priorities earlier in the process you",
    "start": "509680",
    "end": "512640"
  },
  {
    "text": "should use ground through data where",
    "start": "512640",
    "end": "514680"
  },
  {
    "text": "possible if you want to evaluate all",
    "start": "514680",
    "end": "516560"
  },
  {
    "text": "these workflows having your subject",
    "start": "516560",
    "end": "518479"
  },
  {
    "text": "matter experts design these databases",
    "start": "518479",
    "end": "521039"
  },
  {
    "text": "and test these models and workflows",
    "start": "521039",
    "end": "522800"
  },
  {
    "text": "against is going to be very very useful",
    "start": "522800",
    "end": "526000"
  },
  {
    "text": "synthetic benchmarks help however they",
    "start": "526000",
    "end": "528480"
  },
  {
    "text": "will not really evaluate these models",
    "start": "528480",
    "end": "531200"
  },
  {
    "text": "for your own use case so it's usually",
    "start": "531200",
    "end": "533680"
  },
  {
    "text": "very very powerful if you can use your",
    "start": "533680",
    "end": "536240"
  },
  {
    "text": "ground through data but don't worry even",
    "start": "536240",
    "end": "538839"
  },
  {
    "text": "if you do not have ground through data",
    "start": "538839",
    "end": "540839"
  },
  {
    "text": "you can use an llm to evaluate another",
    "start": "540839",
    "end": "544560"
  },
  {
    "text": "model's response this is actually a very",
    "start": "544560",
    "end": "547640"
  },
  {
    "text": "standard and reliable way when it comes",
    "start": "547640",
    "end": "550120"
  },
  {
    "text": "to evaluating your",
    "start": "550120",
    "end": "551720"
  },
  {
    "text": "models very importantly at this stage",
    "start": "551720",
    "end": "554560"
  },
  {
    "text": "you should make sure that you're using a",
    "start": "554560",
    "end": "556680"
  },
  {
    "text": "flexible testing framework no matter if",
    "start": "556680",
    "end": "559120"
  },
  {
    "text": "you're building this in house or if",
    "start": "559120",
    "end": "561000"
  },
  {
    "text": "you're using any external service your",
    "start": "561000",
    "end": "563519"
  },
  {
    "text": "AI isn't static so your workflow should",
    "start": "563519",
    "end": "566200"
  },
  {
    "text": "also be dynamic it should be able to",
    "start": "566200",
    "end": "568320"
  },
  {
    "text": "capture all of this different",
    "start": "568320",
    "end": "570079"
  },
  {
    "text": "non-deterministic responses you need to",
    "start": "570079",
    "end": "572399"
  },
  {
    "text": "be able to Define custom metrics you",
    "start": "572399",
    "end": "574839"
  },
  {
    "text": "need to be able to write those metcs",
    "start": "574839",
    "end": "577360"
  },
  {
    "text": "metrics using python or typescript so",
    "start": "577360",
    "end": "580000"
  },
  {
    "text": "you shouldn't be looking at a very",
    "start": "580000",
    "end": "582120"
  },
  {
    "text": "strict framework customizability is a",
    "start": "582120",
    "end": "584720"
  },
  {
    "text": "very big thing here and then finally you",
    "start": "584720",
    "end": "588519"
  },
  {
    "text": "should run evaluations at every stage",
    "start": "588519",
    "end": "590800"
  },
  {
    "text": "you should have guard rails that will",
    "start": "590800",
    "end": "592519"
  },
  {
    "text": "check internal nodes and whether these",
    "start": "592519",
    "end": "594680"
  },
  {
    "text": "models are actually producing responses",
    "start": "594680",
    "end": "596800"
  },
  {
    "text": "at every step in your uh workflow",
    "start": "596800",
    "end": "599399"
  },
  {
    "text": "actually producing responses that are",
    "start": "599399",
    "end": "601120"
  },
  {
    "text": "correct at every step in your workflow",
    "start": "601120",
    "end": "603320"
  },
  {
    "text": "and then you should also test while your",
    "start": "603320",
    "end": "605720"
  },
  {
    "text": "prototyping but then you should also",
    "start": "605720",
    "end": "607760"
  },
  {
    "text": "utilize this evaluation phase to come",
    "start": "607760",
    "end": "610320"
  },
  {
    "text": "back once you have some real data but",
    "start": "610320",
    "end": "613560"
  },
  {
    "text": "how are you going to get some real data",
    "start": "613560",
    "end": "615160"
  },
  {
    "text": "so let's say that you evaluate your",
    "start": "615160",
    "end": "617440"
  },
  {
    "text": "workflows extensively with your subject",
    "start": "617440",
    "end": "619839"
  },
  {
    "text": "matter experts with your data that",
    "start": "619839",
    "end": "621680"
  },
  {
    "text": "they've created and let's say that",
    "start": "621680",
    "end": "623680"
  },
  {
    "text": "you're now satisfied with the product",
    "start": "623680",
    "end": "625360"
  },
  {
    "text": "that you have so you're ready to deploy",
    "start": "625360",
    "end": "627399"
  },
  {
    "text": "it in production so once that that",
    "start": "627399",
    "end": "629760"
  },
  {
    "text": "happens what do you need to do is your",
    "start": "629760",
    "end": "632800"
  },
  {
    "text": "job done here when it comes to AI",
    "start": "632800",
    "end": "635360"
  },
  {
    "text": "development you need to monitor more",
    "start": "635360",
    "end": "637120"
  },
  {
    "text": "things than deterministic outputs you",
    "start": "637120",
    "end": "639839"
  },
  {
    "text": "need to log all llm calls you need to",
    "start": "639839",
    "end": "642440"
  },
  {
    "text": "track all of those inputs and outputs",
    "start": "642440",
    "end": "644639"
  },
  {
    "text": "and the latency because AI models they",
    "start": "644639",
    "end": "647120"
  },
  {
    "text": "really they're really really",
    "start": "647120",
    "end": "649079"
  },
  {
    "text": "unpredictable so you need to be able to",
    "start": "649079",
    "end": "651279"
  },
  {
    "text": "debug issues and understand how your AI",
    "start": "651279",
    "end": "653760"
  },
  {
    "text": "behaves at every step of the way and",
    "start": "653760",
    "end": "656560"
  },
  {
    "text": "this is becoming extremely more",
    "start": "656560",
    "end": "658399"
  },
  {
    "text": "important with a gentic workflows",
    "start": "658399",
    "end": "660440"
  },
  {
    "text": "because gentic workflows are more",
    "start": "660440",
    "end": "662160"
  },
  {
    "text": "complex workflows that can take",
    "start": "662160",
    "end": "664200"
  },
  {
    "text": "different paths in your workflow and",
    "start": "664200",
    "end": "666920"
  },
  {
    "text": "make decisions on their own you should",
    "start": "666920",
    "end": "669360"
  },
  {
    "text": "also handle API reliability you need to",
    "start": "669360",
    "end": "672279"
  },
  {
    "text": "maintain uh stability in your API calls",
    "start": "672279",
    "end": "674959"
  },
  {
    "text": "you need to have retries you need to",
    "start": "674959",
    "end": "676680"
  },
  {
    "text": "have fallback logic to prevent outages",
    "start": "676680",
    "end": "679839"
  },
  {
    "text": "for example two months ago open AI had",
    "start": "679839",
    "end": "682000"
  },
  {
    "text": "four hours of downtime so if you had a",
    "start": "682000",
    "end": "684639"
  },
  {
    "text": "fallback logic in your productionize",
    "start": "684639",
    "end": "687639"
  },
  {
    "text": "solution then your um AI will know to go",
    "start": "687639",
    "end": "691279"
  },
  {
    "text": "back to another model and use another",
    "start": "691279",
    "end": "693200"
  },
  {
    "text": "model instead you should definitely have",
    "start": "693200",
    "end": "695680"
  },
  {
    "text": "Version Control and staging and you",
    "start": "695680",
    "end": "697720"
  },
  {
    "text": "should always deploy in control",
    "start": "697720",
    "end": "699399"
  },
  {
    "text": "environments before you roll out to The",
    "start": "699399",
    "end": "701959"
  },
  {
    "text": "Wider uh public because with it when it",
    "start": "701959",
    "end": "704959"
  },
  {
    "text": "comes to AI you need to be care careful",
    "start": "704959",
    "end": "707600"
  },
  {
    "text": "that once you update a prompt you're not",
    "start": "707600",
    "end": "709839"
  },
  {
    "text": "introducing a regression to another",
    "start": "709839",
    "end": "712000"
  },
  {
    "text": "prompt or part of your workflow so you",
    "start": "712000",
    "end": "714639"
  },
  {
    "text": "need to ensure that all these new",
    "start": "714639",
    "end": "716480"
  },
  {
    "text": "updates they won't break whatever you",
    "start": "716480",
    "end": "718279"
  },
  {
    "text": "have in production and the most",
    "start": "718279",
    "end": "720200"
  },
  {
    "text": "important part here is that make sure to",
    "start": "720200",
    "end": "722839"
  },
  {
    "text": "decouple your deployments from your",
    "start": "722839",
    "end": "725360"
  },
  {
    "text": "scheduled app deployment schedule",
    "start": "725360",
    "end": "728440"
  },
  {
    "text": "because the chances are that um you will",
    "start": "728440",
    "end": "731680"
  },
  {
    "text": "need to update your AI features more",
    "start": "731680",
    "end": "734279"
  },
  {
    "text": "frequently that you will need to update",
    "start": "734279",
    "end": "736680"
  },
  {
    "text": "your app as a whole so make sure to do",
    "start": "736680",
    "end": "739160"
  },
  {
    "text": "that and so let's say that now you have",
    "start": "739160",
    "end": "741519"
  },
  {
    "text": "deployed you're starting to capture all",
    "start": "741519",
    "end": "744320"
  },
  {
    "text": "of your responses from your users and",
    "start": "744320",
    "end": "746680"
  },
  {
    "text": "create a feedback loop to identify edge",
    "start": "746680",
    "end": "749760"
  },
  {
    "text": "cases that you capture in production to",
    "start": "749760",
    "end": "752199"
  },
  {
    "text": "then continuously improve and make your",
    "start": "752199",
    "end": "755519"
  },
  {
    "text": "workflow better you can capture all of",
    "start": "755519",
    "end": "758480"
  },
  {
    "text": "these then run evaluations again and",
    "start": "758480",
    "end": "761000"
  },
  {
    "text": "test whether um new prompts that you",
    "start": "761000",
    "end": "763240"
  },
  {
    "text": "develop will solve for this new cases",
    "start": "763240",
    "end": "766240"
  },
  {
    "text": "you should also think about building a",
    "start": "766240",
    "end": "767880"
  },
  {
    "text": "caching layer because if your system is",
    "start": "767880",
    "end": "770240"
  },
  {
    "text": "handling some repeat queries caching can",
    "start": "770240",
    "end": "772920"
  },
  {
    "text": "drastically reduce costs and improve",
    "start": "772920",
    "end": "774920"
  },
  {
    "text": "latency so for example instead of",
    "start": "774920",
    "end": "776839"
  },
  {
    "text": "calling an expensive llm for the same",
    "start": "776839",
    "end": "779199"
  },
  {
    "text": "request multiple times you can store and",
    "start": "779199",
    "end": "781360"
  },
  {
    "text": "serve frequent responses instantly and",
    "start": "781360",
    "end": "783760"
  },
  {
    "text": "this is something that is a standard",
    "start": "783760",
    "end": "785639"
  },
  {
    "text": "these days when it comes to building",
    "start": "785639",
    "end": "787360"
  },
  {
    "text": "with AI and finally let's say that your",
    "start": "787360",
    "end": "789720"
  },
  {
    "text": "product has been running reliably in",
    "start": "789720",
    "end": "791720"
  },
  {
    "text": "production for uh a longer period of",
    "start": "791720",
    "end": "794160"
  },
  {
    "text": "time time that you feel comfortable to",
    "start": "794160",
    "end": "796600"
  },
  {
    "text": "then go back to that data and use it to",
    "start": "796600",
    "end": "799040"
  },
  {
    "text": "fine-tune a custom model that will um",
    "start": "799040",
    "end": "802279"
  },
  {
    "text": "basically uh create better responses for",
    "start": "802279",
    "end": "804720"
  },
  {
    "text": "your specific use case uh can reduce",
    "start": "804720",
    "end": "807120"
  },
  {
    "text": "Reliance on API calls and in fact can",
    "start": "807120",
    "end": "809639"
  },
  {
    "text": "work with lower costs and so this",
    "start": "809639",
    "end": "814160"
  },
  {
    "text": "process is becoming even more important",
    "start": "814160",
    "end": "816720"
  },
  {
    "text": "than ever when it comes with agentic",
    "start": "816720",
    "end": "819160"
  },
  {
    "text": "workflows because these workflows are",
    "start": "819160",
    "end": "821120"
  },
  {
    "text": "going to use a wide range of tools they",
    "start": "821120",
    "end": "823880"
  },
  {
    "text": "will um call different apis they will",
    "start": "823880",
    "end": "828000"
  },
  {
    "text": "have multi-agent structures that will",
    "start": "828000",
    "end": "831000"
  },
  {
    "text": "execute a lot of things in parallel so",
    "start": "831000",
    "end": "833519"
  },
  {
    "text": "when it comes to evaluation with a",
    "start": "833519",
    "end": "835440"
  },
  {
    "text": "gentic workflows and with this test",
    "start": "835440",
    "end": "837279"
  },
  {
    "text": "driven approach it's not just just about",
    "start": "837279",
    "end": "839560"
  },
  {
    "text": "measuring performance at every step in",
    "start": "839560",
    "end": "841600"
  },
  {
    "text": "your workflow because you also need to",
    "start": "841600",
    "end": "843800"
  },
  {
    "text": "assess the behavior of these agents to",
    "start": "843800",
    "end": "846720"
  },
  {
    "text": "so that you can make sure that they're",
    "start": "846720",
    "end": "848680"
  },
  {
    "text": "making the right decisions and following",
    "start": "848680",
    "end": "850920"
  },
  {
    "text": "the intended logic and this year more",
    "start": "850920",
    "end": "853519"
  },
  {
    "text": "than ever everyone is talking about",
    "start": "853519",
    "end": "855279"
  },
  {
    "text": "agentic workflows but what does that",
    "start": "855279",
    "end": "857639"
  },
  {
    "text": "actually mean uh I would love to talk",
    "start": "857639",
    "end": "859959"
  },
  {
    "text": "more about how you can build all this",
    "start": "859959",
    "end": "861880"
  },
  {
    "text": "agentic workflows but I'm not here to",
    "start": "861880",
    "end": "864440"
  },
  {
    "text": "give you the perfect definition of what",
    "start": "864440",
    "end": "866120"
  },
  {
    "text": "an AI agent is and instead I'm going to",
    "start": "866120",
    "end": "869160"
  },
  {
    "text": "try to Define different agentic",
    "start": "869160",
    "end": "870800"
  },
  {
    "text": "behaviors and some different levels on",
    "start": "870800",
    "end": "873279"
  },
  {
    "text": "how um they can be built so if you think",
    "start": "873279",
    "end": "876920"
  },
  {
    "text": "about it every AI workflow has some",
    "start": "876920",
    "end": "880120"
  },
  {
    "text": "level of ener gentic behavior in it it's",
    "start": "880120",
    "end": "883120"
  },
  {
    "text": "just a question of how much control",
    "start": "883120",
    "end": "885600"
  },
  {
    "text": "reasoning and autonomy it has so we've",
    "start": "885600",
    "end": "888680"
  },
  {
    "text": "looked at the past the present and where",
    "start": "888680",
    "end": "890480"
  },
  {
    "text": "we're headed and from that we put",
    "start": "890480",
    "end": "893199"
  },
  {
    "text": "together this framework where we Define",
    "start": "893199",
    "end": "895839"
  },
  {
    "text": "four or five different levels of gentic",
    "start": "895839",
    "end": "898800"
  },
  {
    "text": "behav Behavior I'll go into more details",
    "start": "898800",
    "end": "901480"
  },
  {
    "text": "on each level but keep in mind that this",
    "start": "901480",
    "end": "903360"
  },
  {
    "text": "is not a final framework it's not set in",
    "start": "903360",
    "end": "906320"
  },
  {
    "text": "stone as models evolve this can expand",
    "start": "906320",
    "end": "909320"
  },
  {
    "text": "the things can blur and um a lot of",
    "start": "909320",
    "end": "911800"
  },
  {
    "text": "things can shift but for now this will",
    "start": "911800",
    "end": "914199"
  },
  {
    "text": "give us a way to define where we are",
    "start": "914199",
    "end": "916399"
  },
  {
    "text": "today and what we expect to see next at",
    "start": "916399",
    "end": "919680"
  },
  {
    "text": "this stage you have an llm call you",
    "start": "919680",
    "end": "921880"
  },
  {
    "text": "retrieve some data from your vectory",
    "start": "921880",
    "end": "923920"
  },
  {
    "text": "database and then you might have some",
    "start": "923920",
    "end": "925560"
  },
  {
    "text": "inline evals and finally you're going to",
    "start": "925560",
    "end": "928199"
  },
  {
    "text": "uh get some response from this workflow",
    "start": "928199",
    "end": "930399"
  },
  {
    "text": "so you can notice that in this workflow",
    "start": "930399",
    "end": "932279"
  },
  {
    "text": "there's no reasoning planning or",
    "start": "932279",
    "end": "933920"
  },
  {
    "text": "decision making Beyond what's baked into",
    "start": "933920",
    "end": "936440"
  },
  {
    "text": "the prompt and the Model Behavior so the",
    "start": "936440",
    "end": "938880"
  },
  {
    "text": "model is doing all the reasoning here",
    "start": "938880",
    "end": "940839"
  },
  {
    "text": "within the prompt itself and so there is",
    "start": "940839",
    "end": "943040"
  },
  {
    "text": "no external agenda organizing uh the",
    "start": "943040",
    "end": "946000"
  },
  {
    "text": "decisions or planning some actions",
    "start": "946000",
    "end": "948040"
  },
  {
    "text": "however there is some reasoning and some",
    "start": "948040",
    "end": "949639"
  },
  {
    "text": "agentic Behavior at the models level and",
    "start": "949639",
    "end": "952639"
  },
  {
    "text": "so if we move from l0 to L1 we can see",
    "start": "952639",
    "end": "956680"
  },
  {
    "text": "that in this stage our workplace can now",
    "start": "956680",
    "end": "959560"
  },
  {
    "text": "use a lot of tools and so this EA System",
    "start": "959560",
    "end": "962360"
  },
  {
    "text": "is no longer just calling apis it no now",
    "start": "962360",
    "end": "965800"
  },
  {
    "text": "knows when to call them and when to make",
    "start": "965800",
    "end": "968240"
  },
  {
    "text": "those actions and so this is where we",
    "start": "968240",
    "end": "970839"
  },
  {
    "text": "start to see more gentic Behavior",
    "start": "970839",
    "end": "973079"
  },
  {
    "text": "because the model can decide whether uh",
    "start": "973079",
    "end": "975440"
  },
  {
    "text": "it will call a specific tool or whether",
    "start": "975440",
    "end": "978040"
  },
  {
    "text": "it will call our Vector database to",
    "start": "978040",
    "end": "980480"
  },
  {
    "text": "retrieve more data before it actually uh",
    "start": "980480",
    "end": "983120"
  },
  {
    "text": "generates an output memory here starts",
    "start": "983120",
    "end": "985440"
  },
  {
    "text": "to play a key role because we're going",
    "start": "985440",
    "end": "987040"
  },
  {
    "text": "to have multi-threaded uh conver",
    "start": "987040",
    "end": "988920"
  },
  {
    "text": "conversations and then uh all of this",
    "start": "988920",
    "end": "991199"
  },
  {
    "text": "will potentially happen in parallel so",
    "start": "991199",
    "end": "993319"
  },
  {
    "text": "we need to capture all context",
    "start": "993319",
    "end": "995560"
  },
  {
    "text": "throughout the whole workflow evaluation",
    "start": "995560",
    "end": "997959"
  },
  {
    "text": "is also needed at every state uh step of",
    "start": "997959",
    "end": "1000839"
  },
  {
    "text": "the way here because we need to ensure",
    "start": "1000839",
    "end": "1002680"
  },
  {
    "text": "that this models are making the right",
    "start": "1002680",
    "end": "1004920"
  },
  {
    "text": "decisions using the right tools and",
    "start": "1004920",
    "end": "1007160"
  },
  {
    "text": "returning uh accurate responses but this",
    "start": "1007160",
    "end": "1010480"
  },
  {
    "text": "workflows can be as simple as on the",
    "start": "1010480",
    "end": "1012880"
  },
  {
    "text": "slide right here or even more",
    "start": "1012880",
    "end": "1014839"
  },
  {
    "text": "complicated where you're going to have",
    "start": "1014839",
    "end": "1016279"
  },
  {
    "text": "more different branching happen uh",
    "start": "1016279",
    "end": "1018959"
  },
  {
    "text": "happens at every stage in this workflow",
    "start": "1018959",
    "end": "1020680"
  },
  {
    "text": "where you can have 10 different tools",
    "start": "1020680",
    "end": "1022759"
  },
  {
    "text": "and the agent needs to reason whether",
    "start": "1022759",
    "end": "1024520"
  },
  {
    "text": "it's going to call the first five or the",
    "start": "1024520",
    "end": "1026558"
  },
  {
    "text": "or the last two and so this is uh where",
    "start": "1026559",
    "end": "1029760"
  },
  {
    "text": "again we see a lot more agentic Behavior",
    "start": "1029760",
    "end": "1032038"
  },
  {
    "text": "but L2 is where we actually see that um",
    "start": "1032039",
    "end": "1035600"
  },
  {
    "text": "these workflows now move from simple",
    "start": "1035600",
    "end": "1038240"
  },
  {
    "text": "tool use which is not in many cases it's",
    "start": "1038240",
    "end": "1040959"
  },
  {
    "text": "not a simple tool use like the previous",
    "start": "1040959",
    "end": "1043880"
  },
  {
    "text": "workflows can be very complex but now we",
    "start": "1043880",
    "end": "1046438"
  },
  {
    "text": "see some structured reasoning this work",
    "start": "1046439",
    "end": "1048919"
  },
  {
    "text": "workflow will notice triggers it can",
    "start": "1048919",
    "end": "1051799"
  },
  {
    "text": "plan actions and it can execute tasks in",
    "start": "1051799",
    "end": "1055120"
  },
  {
    "text": "a structured sequence so this means that",
    "start": "1055120",
    "end": "1057520"
  },
  {
    "text": "it can break down a task into multiple",
    "start": "1057520",
    "end": "1059480"
  },
  {
    "text": "steps it can retrieve some information",
    "start": "1059480",
    "end": "1061600"
  },
  {
    "text": "it can decide to call another tool it",
    "start": "1061600",
    "end": "1063720"
  },
  {
    "text": "can evaluate its usefulness if it thinks",
    "start": "1063720",
    "end": "1065880"
  },
  {
    "text": "that it needs to be refined at that",
    "start": "1065880",
    "end": "1067640"
  },
  {
    "text": "stage and once it does this in a",
    "start": "1067640",
    "end": "1069919"
  },
  {
    "text": "continuous loop it can generate the",
    "start": "1069919",
    "end": "1072400"
  },
  {
    "text": "final output but um you can notice that",
    "start": "1072400",
    "end": "1075080"
  },
  {
    "text": "atic behavior here starts to look more",
    "start": "1075080",
    "end": "1077559"
  },
  {
    "text": "intentional because the system isn't",
    "start": "1077559",
    "end": "1079720"
  },
  {
    "text": "just calling the tools that are listed",
    "start": "1079720",
    "end": "1082880"
  },
  {
    "text": "uh for their use it's also actively",
    "start": "1082880",
    "end": "1085159"
  },
  {
    "text": "deciding what needs to be done and",
    "start": "1085159",
    "end": "1087200"
  },
  {
    "text": "spending more time to think what needs",
    "start": "1087200",
    "end": "1089280"
  },
  {
    "text": "to be done instead of just deciding",
    "start": "1089280",
    "end": "1091360"
  },
  {
    "text": "whether a tool should be called and so",
    "start": "1091360",
    "end": "1093640"
  },
  {
    "text": "at this stage um one part is that the",
    "start": "1093640",
    "end": "1096679"
  },
  {
    "text": "process is still finite so once this",
    "start": "1096679",
    "end": "1099039"
  },
  {
    "text": "workflow completes the steps um as it",
    "start": "1099039",
    "end": "1102400"
  },
  {
    "text": "plans to complete them it will terminate",
    "start": "1102400",
    "end": "1104960"
  },
  {
    "text": "rather than it will run continuously but",
    "start": "1104960",
    "end": "1107600"
  },
  {
    "text": "it's a Leap Forward",
    "start": "1107600",
    "end": "1109320"
  },
  {
    "text": "um from just calling uh tools and so uh",
    "start": "1109320",
    "end": "1113440"
  },
  {
    "text": "L3 however is where we see more autonomy",
    "start": "1113440",
    "end": "1116840"
  },
  {
    "text": "where we see more uh decision making",
    "start": "1116840",
    "end": "1119120"
  },
  {
    "text": "that are not um defined by us as the",
    "start": "1119120",
    "end": "1123200"
  },
  {
    "text": "creators of this workload so the L for",
    "start": "1123200",
    "end": "1125720"
  },
  {
    "text": "system can proactively take actions",
    "start": "1125720",
    "end": "1128080"
  },
  {
    "text": "without waiting for direct input so",
    "start": "1128080",
    "end": "1130360"
  },
  {
    "text": "instead of responding responding to a",
    "start": "1130360",
    "end": "1132240"
  },
  {
    "text": "single request and then terminating this",
    "start": "1132240",
    "end": "1134880"
  },
  {
    "text": "one will stay alive and will",
    "start": "1134880",
    "end": "1136960"
  },
  {
    "text": "continuously monitor its environment and",
    "start": "1136960",
    "end": "1139559"
  },
  {
    "text": "it will react as needed so for example",
    "start": "1139559",
    "end": "1142600"
  },
  {
    "text": "um this means that it can uh look at",
    "start": "1142600",
    "end": "1144640"
  },
  {
    "text": "your email slack Google drive or any",
    "start": "1144640",
    "end": "1146640"
  },
  {
    "text": "other Tool uh external Services actually",
    "start": "1146640",
    "end": "1149320"
  },
  {
    "text": "that you can give access to and it can",
    "start": "1149320",
    "end": "1151799"
  },
  {
    "text": "plan its next moves whether it will",
    "start": "1151799",
    "end": "1153760"
  },
  {
    "text": "execute actions in real time or asks uh",
    "start": "1153760",
    "end": "1156919"
  },
  {
    "text": "the human for more input and so this is",
    "start": "1156919",
    "end": "1159760"
  },
  {
    "text": "where uh our AI workflows become less of",
    "start": "1159760",
    "end": "1162400"
  },
  {
    "text": "a tool and more of an independent system",
    "start": "1162400",
    "end": "1165200"
  },
  {
    "text": "that we can use to truly make our work",
    "start": "1165200",
    "end": "1168280"
  },
  {
    "text": "easier so for example this one can be",
    "start": "1168280",
    "end": "1170559"
  },
  {
    "text": "like a marketer that will prepare this",
    "start": "1170559",
    "end": "1173039"
  },
  {
    "text": "video or a presentation that you can",
    "start": "1173039",
    "end": "1174760"
  },
  {
    "text": "just take and use whenever you want",
    "start": "1174760",
    "end": "1178200"
  },
  {
    "text": "however the final stage is where we're",
    "start": "1178200",
    "end": "1179559"
  },
  {
    "text": "going to have a fully creative workflow",
    "start": "1179559",
    "end": "1181880"
  },
  {
    "text": "and so at L4 the AI moves between uh",
    "start": "1181880",
    "end": "1185720"
  },
  {
    "text": "Beyond Automation and reasoning and it",
    "start": "1185720",
    "end": "1187960"
  },
  {
    "text": "becomes an inventor so instead of just",
    "start": "1187960",
    "end": "1190360"
  },
  {
    "text": "executing predefined tasks or just like",
    "start": "1190360",
    "end": "1193280"
  },
  {
    "text": "reasoning within some bounds um it can",
    "start": "1193280",
    "end": "1196559"
  },
  {
    "text": "create its own new workflows so it can",
    "start": "1196559",
    "end": "1198840"
  },
  {
    "text": "create its own utilities whether it's",
    "start": "1198840",
    "end": "1200960"
  },
  {
    "text": "agents prompts function calls tools that",
    "start": "1200960",
    "end": "1203960"
  },
  {
    "text": "uh it needs to be designed uh it will",
    "start": "1203960",
    "end": "1206320"
  },
  {
    "text": "Pro it will solve problems in novel way",
    "start": "1206320",
    "end": "1208919"
  },
  {
    "text": "so well true L4 right now is definitely",
    "start": "1208919",
    "end": "1212520"
  },
  {
    "text": "Out Of Reach because there's some",
    "start": "1212520",
    "end": "1214280"
  },
  {
    "text": "constraints with models like overfitting",
    "start": "1214280",
    "end": "1216720"
  },
  {
    "text": "because models they really love their",
    "start": "1216720",
    "end": "1218360"
  },
  {
    "text": "training data and there is some issues",
    "start": "1218360",
    "end": "1220440"
  },
  {
    "text": "with uh inductive bias where models will",
    "start": "1220440",
    "end": "1223200"
  },
  {
    "text": "make assumptions again based on their",
    "start": "1223200",
    "end": "1225200"
  },
  {
    "text": "training data this makes to be like a",
    "start": "1225200",
    "end": "1228039"
  },
  {
    "text": "very hard task ask uh today but that's",
    "start": "1228039",
    "end": "1230799"
  },
  {
    "text": "the goal AI that doesn't just follow",
    "start": "1230799",
    "end": "1232880"
  },
  {
    "text": "instructions but will invent it will",
    "start": "1232880",
    "end": "1235559"
  },
  {
    "text": "improve and it will solve problems in",
    "start": "1235559",
    "end": "1237840"
  },
  {
    "text": "ways we didn't even think of before so I",
    "start": "1237840",
    "end": "1240880"
  },
  {
    "text": "would say that L1 is where we're seeing",
    "start": "1240880",
    "end": "1242559"
  },
  {
    "text": "a lot of production grade Solutions so",
    "start": "1242559",
    "end": "1244840"
  },
  {
    "text": "at Bellum we've worked with companies",
    "start": "1244840",
    "end": "1246400"
  },
  {
    "text": "like redin dra and headspace all of",
    "start": "1246400",
    "end": "1248840"
  },
  {
    "text": "which have deployed production grade AI",
    "start": "1248840",
    "end": "1250600"
  },
  {
    "text": "solutions that fall within the L1",
    "start": "1250600",
    "end": "1253720"
  },
  {
    "text": "segment and again like just using tools",
    "start": "1253720",
    "end": "1256200"
  },
  {
    "text": "it can be very simple or it can be very",
    "start": "1256200",
    "end": "1258760"
  },
  {
    "text": "complex workflow uh the focus is though",
    "start": "1258760",
    "end": "1261840"
  },
  {
    "text": "on orchestrations how do we turn our",
    "start": "1261840",
    "end": "1264400"
  },
  {
    "text": "models to interact with our system",
    "start": "1264400",
    "end": "1267240"
  },
  {
    "text": "better how do we make our models to work",
    "start": "1267240",
    "end": "1269280"
  },
  {
    "text": "with our data better how do we make sure",
    "start": "1269280",
    "end": "1271919"
  },
  {
    "text": "that whatever we retrieve from our",
    "start": "1271919",
    "end": "1273640"
  },
  {
    "text": "Vector databases is the right and",
    "start": "1273640",
    "end": "1275960"
  },
  {
    "text": "correct context for the uh question that",
    "start": "1275960",
    "end": "1278720"
  },
  {
    "text": "the user is asking and so like we're",
    "start": "1278720",
    "end": "1281240"
  },
  {
    "text": "experimented with different modalities",
    "start": "1281240",
    "end": "1282600"
  },
  {
    "text": "and all of those techniques that we",
    "start": "1282600",
    "end": "1283799"
  },
  {
    "text": "mentioned before and test driven",
    "start": "1283799",
    "end": "1285720"
  },
  {
    "text": "development truly makes its case here",
    "start": "1285720",
    "end": "1288640"
  },
  {
    "text": "because like you need to hack different",
    "start": "1288640",
    "end": "1290080"
  },
  {
    "text": "tools and models and you need to be able",
    "start": "1290080",
    "end": "1292200"
  },
  {
    "text": "to continuously improve on them to build",
    "start": "1292200",
    "end": "1294799"
  },
  {
    "text": "not only a more efficient system But A",
    "start": "1294799",
    "end": "1296640"
  },
  {
    "text": "system that will work continuously",
    "start": "1296640",
    "end": "1298360"
  },
  {
    "text": "better and better um however L2 is where",
    "start": "1298360",
    "end": "1301600"
  },
  {
    "text": "I think we're going to see most",
    "start": "1301600",
    "end": "1302840"
  },
  {
    "text": "Innovation uh happen this year and this",
    "start": "1302840",
    "end": "1305400"
  },
  {
    "text": "is where we're going to have a lot of AI",
    "start": "1305400",
    "end": "1307440"
  },
  {
    "text": "agents that are being developed to plan",
    "start": "1307440",
    "end": "1309880"
  },
  {
    "text": "and reason using models like 01 or O3 or",
    "start": "1309880",
    "end": "1313200"
  },
  {
    "text": "deep sick uh we might see a bunch of",
    "start": "1313200",
    "end": "1316279"
  },
  {
    "text": "different use cases we might see a lot",
    "start": "1316279",
    "end": "1318720"
  },
  {
    "text": "of Innovations when it comes to the UI",
    "start": "1318720",
    "end": "1321360"
  },
  {
    "text": "and the ux part of the system where we",
    "start": "1321360",
    "end": "1324159"
  },
  {
    "text": "will definitely create some new",
    "start": "1324159",
    "end": "1325559"
  },
  {
    "text": "experiments experiences for users and um",
    "start": "1325559",
    "end": "1329400"
  },
  {
    "text": "essentially this will be uh a way for us",
    "start": "1329400",
    "end": "1332159"
  },
  {
    "text": "to make true reasoners that will handle",
    "start": "1332159",
    "end": "1335240"
  },
  {
    "text": "complex tasks so you're going to have",
    "start": "1335240",
    "end": "1337240"
  },
  {
    "text": "bunch of these agents just working for",
    "start": "1337240",
    "end": "1339159"
  },
  {
    "text": "you doing uh different things however L3",
    "start": "1339159",
    "end": "1342679"
  },
  {
    "text": "and L4 they're still both limited by the",
    "start": "1342679",
    "end": "1345640"
  },
  {
    "text": "models today as well as the surrounding",
    "start": "1345640",
    "end": "1347840"
  },
  {
    "text": "logic however however that doesn't mean",
    "start": "1347840",
    "end": "1350039"
  },
  {
    "text": "that uh there's a lot of innovation",
    "start": "1350039",
    "end": "1352039"
  },
  {
    "text": "happening within those two as well so if",
    "start": "1352039",
    "end": "1354240"
  },
  {
    "text": "you want to learn more about how to",
    "start": "1354240",
    "end": "1355640"
  },
  {
    "text": "build your own uh AI agent I've included",
    "start": "1355640",
    "end": "1358720"
  },
  {
    "text": "everything that I've shared in this",
    "start": "1358720",
    "end": "1359960"
  },
  {
    "text": "presentation and more for example uh",
    "start": "1359960",
    "end": "1362600"
  },
  {
    "text": "architectures that you can build what",
    "start": "1362600",
    "end": "1364320"
  },
  {
    "text": "are the stages that you can test and",
    "start": "1364320",
    "end": "1366480"
  },
  {
    "text": "similar things like that we also feature",
    "start": "1366480",
    "end": "1368679"
  },
  {
    "text": "top researchers and professionals who",
    "start": "1368679",
    "end": "1370840"
  },
  {
    "text": "have shared all of their learnings on",
    "start": "1370840",
    "end": "1372799"
  },
  {
    "text": "how to build these for production so",
    "start": "1372799",
    "end": "1374919"
  },
  {
    "text": "feel free to scan this QR code on the",
    "start": "1374919",
    "end": "1377480"
  },
  {
    "text": "screen to download this resource so now",
    "start": "1377480",
    "end": "1380559"
  },
  {
    "text": "I think it's time to get more practical",
    "start": "1380559",
    "end": "1382760"
  },
  {
    "text": "I want to show you how I built my own",
    "start": "1382760",
    "end": "1384559"
  },
  {
    "text": "SEO agent this specific agent automates",
    "start": "1384559",
    "end": "1387520"
  },
  {
    "text": "my whole SEO process from keyword",
    "start": "1387520",
    "end": "1389799"
  },
  {
    "text": "research to content analysis and finally",
    "start": "1389799",
    "end": "1392000"
  },
  {
    "text": "for Content creation it decides whether",
    "start": "1392000",
    "end": "1394320"
  },
  {
    "text": "to use tools and has an embedded",
    "start": "1394320",
    "end": "1396320"
  },
  {
    "text": "evaluator that works on an Editor to",
    "start": "1396320",
    "end": "1398400"
  },
  {
    "text": "tell the agent if it's doing a good job",
    "start": "1398400",
    "end": "1400720"
  },
  {
    "text": "let's see a quick sketch of how this",
    "start": "1400720",
    "end": "1402760"
  },
  {
    "text": "agent works so in a minute I'm going to",
    "start": "1402760",
    "end": "1405039"
  },
  {
    "text": "show you a real demo on how this agent",
    "start": "1405039",
    "end": "1407279"
  },
  {
    "text": "actually works however I wanted to give",
    "start": "1407279",
    "end": "1409600"
  },
  {
    "text": "you a high level overview on what are",
    "start": "1409600",
    "end": "1411840"
  },
  {
    "text": "the steps that this workflow will take",
    "start": "1411840",
    "end": "1414120"
  },
  {
    "text": "and so when you look at the sketch on",
    "start": "1414120",
    "end": "1415760"
  },
  {
    "text": "the screen right now you're going to",
    "start": "1415760",
    "end": "1417159"
  },
  {
    "text": "notice that this workflow lies between",
    "start": "1417159",
    "end": "1419320"
  },
  {
    "text": "L1 and L2 type of agentic workflow you",
    "start": "1419320",
    "end": "1423000"
  },
  {
    "text": "have the SEO analyst and the researcher",
    "start": "1423000",
    "end": "1425400"
  },
  {
    "text": "who will take a keyword and it will call",
    "start": "1425400",
    "end": "1427760"
  },
  {
    "text": "Google search and it will analyze the",
    "start": "1427760",
    "end": "1430039"
  },
  {
    "text": "top performing articles for that keyword",
    "start": "1430039",
    "end": "1432679"
  },
  {
    "text": "one it will identify some of the good",
    "start": "1432679",
    "end": "1434880"
  },
  {
    "text": "parts uh Within These articles that we",
    "start": "1434880",
    "end": "1437640"
  },
  {
    "text": "also need to amplify in our own article",
    "start": "1437640",
    "end": "1440440"
  },
  {
    "text": "but it will also Identify some missing",
    "start": "1440440",
    "end": "1442840"
  },
  {
    "text": "segments or areas of improvement that we",
    "start": "1442840",
    "end": "1445480"
  },
  {
    "text": "should definitely write about to make",
    "start": "1445480",
    "end": "1447799"
  },
  {
    "text": "sure that our article is actually",
    "start": "1447799",
    "end": "1449640"
  },
  {
    "text": "performing better than the ones that",
    "start": "1449640",
    "end": "1451159"
  },
  {
    "text": "we're competing against and then after",
    "start": "1451159",
    "end": "1453679"
  },
  {
    "text": "the research and planning is done the",
    "start": "1453679",
    "end": "1455600"
  },
  {
    "text": "writer has everything it needs to start",
    "start": "1455600",
    "end": "1457720"
  },
  {
    "text": "writing the first draft what then the",
    "start": "1457720",
    "end": "1459960"
  },
  {
    "text": "first draft is passed to the editor",
    "start": "1459960",
    "end": "1461960"
  },
  {
    "text": "which is an llm based judge that will",
    "start": "1461960",
    "end": "1464279"
  },
  {
    "text": "evaluate whether the first draft is good",
    "start": "1464279",
    "end": "1466679"
  },
  {
    "text": "enough based on predefined rules that",
    "start": "1466679",
    "end": "1469039"
  },
  {
    "text": "we've set in its prompt then that",
    "start": "1469039",
    "end": "1471559"
  },
  {
    "text": "feedback is passed back to the rouer and",
    "start": "1471559",
    "end": "1473840"
  },
  {
    "text": "this will Loop uh continuously until",
    "start": "1473840",
    "end": "1477279"
  },
  {
    "text": "some uh criteria is met uh within this",
    "start": "1477279",
    "end": "1480760"
  },
  {
    "text": "Loop we also have a memory component",
    "start": "1480760",
    "end": "1482640"
  },
  {
    "text": "that will capture all previous",
    "start": "1482640",
    "end": "1484240"
  },
  {
    "text": "conversations between the writer and the",
    "start": "1484240",
    "end": "1486600"
  },
  {
    "text": "editor and finally we're going to get a",
    "start": "1486600",
    "end": "1489240"
  },
  {
    "text": "final article that's actually a very",
    "start": "1489240",
    "end": "1491440"
  },
  {
    "text": "useful um piece of content that it's not",
    "start": "1491440",
    "end": "1494399"
  },
  {
    "text": "a generated and not useful but truly",
    "start": "1494399",
    "end": "1497039"
  },
  {
    "text": "using all of this context in a Smart Way",
    "start": "1497039",
    "end": "1500679"
  },
  {
    "text": "enabling me to have a pretty impressive",
    "start": "1500679",
    "end": "1502919"
  },
  {
    "text": "first draft to work with so now let's",
    "start": "1502919",
    "end": "1505200"
  },
  {
    "text": "see the demo for the sake of time I'm",
    "start": "1505200",
    "end": "1507440"
  },
  {
    "text": "going to start running this workflow as",
    "start": "1507440",
    "end": "1509120"
  },
  {
    "text": "I explain what this agent does at every",
    "start": "1509120",
    "end": "1512279"
  },
  {
    "text": "step in the workflow so we ran this",
    "start": "1512279",
    "end": "1514840"
  },
  {
    "text": "workflow with the keyword Chain of",
    "start": "1514840",
    "end": "1516880"
  },
  {
    "text": "Thought prompting and so the SEO analyst",
    "start": "1516880",
    "end": "1519440"
  },
  {
    "text": "currently is taking that keyword is",
    "start": "1519440",
    "end": "1521240"
  },
  {
    "text": "taking some other parameters like my",
    "start": "1521240",
    "end": "1522960"
  },
  {
    "text": "writing style like the audience that",
    "start": "1522960",
    "end": "1524919"
  },
  {
    "text": "we're trying to cater to and it analyzes",
    "start": "1524919",
    "end": "1527320"
  },
  {
    "text": "the top articles that Google is ranking",
    "start": "1527320",
    "end": "1529399"
  },
  {
    "text": "for that specific keywords it tries to",
    "start": "1529399",
    "end": "1531880"
  },
  {
    "text": "identify some good components from those",
    "start": "1531880",
    "end": "1534360"
  },
  {
    "text": "articles that we need to reinforce in",
    "start": "1534360",
    "end": "1536360"
  },
  {
    "text": "our article but it also identifies some",
    "start": "1536360",
    "end": "1538720"
  },
  {
    "text": "missing opportunities where the",
    "start": "1538720",
    "end": "1540720"
  },
  {
    "text": "researcher is going to utilize those to",
    "start": "1540720",
    "end": "1543480"
  },
  {
    "text": "then make another search and capture",
    "start": "1543480",
    "end": "1545919"
  },
  {
    "text": "more data to make our article be better",
    "start": "1545919",
    "end": "1548760"
  },
  {
    "text": "than the articles that we just analyzed",
    "start": "1548760",
    "end": "1550960"
  },
  {
    "text": "so now that the SEO analyst uh is done",
    "start": "1550960",
    "end": "1553640"
  },
  {
    "text": "with its job the researcher tries to",
    "start": "1553640",
    "end": "1556000"
  },
  {
    "text": "capture more information about the",
    "start": "1556000",
    "end": "1558440"
  },
  {
    "text": "things that um were previously",
    "start": "1558440",
    "end": "1560880"
  },
  {
    "text": "identified as missing pieces to the",
    "start": "1560880",
    "end": "1562799"
  },
  {
    "text": "puzzle and then the writer will take a",
    "start": "1562799",
    "end": "1565399"
  },
  {
    "text": "lot of this information in its input and",
    "start": "1565399",
    "end": "1567720"
  },
  {
    "text": "it will try to create a great first",
    "start": "1567720",
    "end": "1569640"
  },
  {
    "text": "draft using that data as context so the",
    "start": "1569640",
    "end": "1573159"
  },
  {
    "text": "content here that will be generated by",
    "start": "1573159",
    "end": "1575120"
  },
  {
    "text": "the writer it's not going to be like a",
    "start": "1575120",
    "end": "1576760"
  },
  {
    "text": "slop type of article it's not going to",
    "start": "1576760",
    "end": "1579200"
  },
  {
    "text": "be something that it's really not useful",
    "start": "1579200",
    "end": "1581559"
  },
  {
    "text": "it's going to actually use all the",
    "start": "1581559",
    "end": "1583399"
  },
  {
    "text": "context that we're sending from",
    "start": "1583399",
    "end": "1585120"
  },
  {
    "text": "different articles that we just analyzed",
    "start": "1585120",
    "end": "1587200"
  },
  {
    "text": "you can also connect your rack here that",
    "start": "1587200",
    "end": "1589240"
  },
  {
    "text": "it will look into your database of",
    "start": "1589240",
    "end": "1591200"
  },
  {
    "text": "Articles and learnings and it can really",
    "start": "1591200",
    "end": "1593360"
  },
  {
    "text": "create something that's extremely useful",
    "start": "1593360",
    "end": "1596320"
  },
  {
    "text": "now the editor says okay this is a good",
    "start": "1596320",
    "end": "1598120"
  },
  {
    "text": "enough article but here's some feedback",
    "start": "1598120",
    "end": "1600320"
  },
  {
    "text": "and so it passes the feedback through",
    "start": "1600320",
    "end": "1602240"
  },
  {
    "text": "the memory component here which is a",
    "start": "1602240",
    "end": "1604159"
  },
  {
    "text": "chat history between these two and then",
    "start": "1604159",
    "end": "1606799"
  },
  {
    "text": "um this node that uh basically",
    "start": "1606799",
    "end": "1608919"
  },
  {
    "text": "structures that input for the sake of",
    "start": "1608919",
    "end": "1611480"
  },
  {
    "text": "this demo the conditional here for the",
    "start": "1611480",
    "end": "1614760"
  },
  {
    "text": "loop is that this Loop will break if the",
    "start": "1614760",
    "end": "1617399"
  },
  {
    "text": "evaluator actually tells us that this is",
    "start": "1617399",
    "end": "1619320"
  },
  {
    "text": "an excellent post which actually rarely",
    "start": "1619320",
    "end": "1621880"
  },
  {
    "text": "happens so um we also said that if the",
    "start": "1621880",
    "end": "1625559"
  },
  {
    "text": "loop runs for at least one time this",
    "start": "1625559",
    "end": "1628320"
  },
  {
    "text": "Loop will break and so it already ran",
    "start": "1628320",
    "end": "1630720"
  },
  {
    "text": "for one time we got still more feedback",
    "start": "1630720",
    "end": "1632960"
  },
  {
    "text": "from the editor but in this case for",
    "start": "1632960",
    "end": "1634919"
  },
  {
    "text": "this demo let's look at the output that",
    "start": "1634919",
    "end": "1637919"
  },
  {
    "text": "we got so mastering Chain of Thought",
    "start": "1637919",
    "end": "1639720"
  },
  {
    "text": "prompting in AI a comprehensive guide",
    "start": "1639720",
    "end": "1641880"
  },
  {
    "text": "for developers I think it's pretty okay",
    "start": "1641880",
    "end": "1644559"
  },
  {
    "text": "pretty nice I might change the title but",
    "start": "1644559",
    "end": "1646760"
  },
  {
    "text": "I know that the components this article",
    "start": "1646760",
    "end": "1649720"
  },
  {
    "text": "are the actual components that other",
    "start": "1649720",
    "end": "1651720"
  },
  {
    "text": "articles are writing about and so uh",
    "start": "1651720",
    "end": "1654440"
  },
  {
    "text": "this was great the latency was around",
    "start": "1654440",
    "end": "1656159"
  },
  {
    "text": "118 this usually takes around 300",
    "start": "1656159",
    "end": "1658720"
  },
  {
    "text": "seconds to run when we have more",
    "start": "1658720",
    "end": "1660240"
  },
  {
    "text": "evaluation Loops but it's pretty great",
    "start": "1660240",
    "end": "1662480"
  },
  {
    "text": "it gives me some foundations on how I",
    "start": "1662480",
    "end": "1665320"
  },
  {
    "text": "can continue to build on this content",
    "start": "1665320",
    "end": "1667360"
  },
  {
    "text": "and it saves me a lot of my time so the",
    "start": "1667360",
    "end": "1669799"
  },
  {
    "text": "product that I just used is called",
    "start": "1669799",
    "end": "1671360"
  },
  {
    "text": "Bellum workflows and it was designed to",
    "start": "1671360",
    "end": "1673279"
  },
  {
    "text": "bridge the gap between the product and",
    "start": "1673279",
    "end": "1674919"
  },
  {
    "text": "Engineering teams so they can speed up",
    "start": "1674919",
    "end": "1676960"
  },
  {
    "text": "AI development well still following this",
    "start": "1676960",
    "end": "1679640"
  },
  {
    "text": "test driven approach that we talked so",
    "start": "1679640",
    "end": "1682000"
  },
  {
    "text": "much about in this presentation however",
    "start": "1682000",
    "end": "1684600"
  },
  {
    "text": "one thing became clear developers want",
    "start": "1684600",
    "end": "1687000"
  },
  {
    "text": "more code developers want more control",
    "start": "1687000",
    "end": "1689399"
  },
  {
    "text": "and flexibility and they want to own",
    "start": "1689399",
    "end": "1691240"
  },
  {
    "text": "their definitions in their codebase so",
    "start": "1691240",
    "end": "1693360"
  },
  {
    "text": "today I'm excited to introduce our",
    "start": "1693360",
    "end": "1694880"
  },
  {
    "text": "workflow SDK it provides all the",
    "start": "1694880",
    "end": "1697120"
  },
  {
    "text": "building blocks you need it's infinitely",
    "start": "1697120",
    "end": "1699679"
  },
  {
    "text": "customizable and it has a",
    "start": "1699679",
    "end": "1701760"
  },
  {
    "text": "self-documenting syntax where you can",
    "start": "1701760",
    "end": "1704080"
  },
  {
    "text": "actually spot how this agent is working",
    "start": "1704080",
    "end": "1706399"
  },
  {
    "text": "right in your code it's also also",
    "start": "1706399",
    "end": "1708360"
  },
  {
    "text": "expressive enough so that you can",
    "start": "1708360",
    "end": "1710159"
  },
  {
    "text": "understand what's happening at every",
    "start": "1710159",
    "end": "1711720"
  },
  {
    "text": "stage in your code the best part is that",
    "start": "1711720",
    "end": "1714159"
  },
  {
    "text": "the UI and the code stay in sync so",
    "start": "1714159",
    "end": "1716840"
  },
  {
    "text": "whether you're defining debugging or",
    "start": "1716840",
    "end": "1718919"
  },
  {
    "text": "improving your workflows everyone on",
    "start": "1718919",
    "end": "1720799"
  },
  {
    "text": "your team can stay aligned I hope that",
    "start": "1720799",
    "end": "1723279"
  },
  {
    "text": "you like it it's open source and free",
    "start": "1723279",
    "end": "1725200"
  },
  {
    "text": "and you can check it out on GitHub feel",
    "start": "1725200",
    "end": "1727039"
  },
  {
    "text": "free to run uh to scan this QR code uh",
    "start": "1727039",
    "end": "1730279"
  },
  {
    "text": "to check out the repo and that's a wrap",
    "start": "1730279",
    "end": "1733159"
  },
  {
    "text": "thank you so much for listening and I",
    "start": "1733159",
    "end": "1734720"
  },
  {
    "text": "hope that today you learned something",
    "start": "1734720",
    "end": "1736279"
  },
  {
    "text": "new if you want to talk more about AI I",
    "start": "1736279",
    "end": "1738440"
  },
  {
    "text": "feel free to scan this QR code on the",
    "start": "1738440",
    "end": "1740360"
  },
  {
    "text": "screen to connect on LinkedIn or if you",
    "start": "1740360",
    "end": "1742399"
  },
  {
    "text": "have any questions feel free to um send",
    "start": "1742399",
    "end": "1745039"
  },
  {
    "text": "me a text message on my email or on",
    "start": "1745039",
    "end": "1747360"
  },
  {
    "text": "Twitter I'm GNA follow up for sure",
    "start": "1747360",
    "end": "1751480"
  }
]
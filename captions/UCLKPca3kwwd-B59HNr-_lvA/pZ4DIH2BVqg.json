[
  {
    "start": "0",
    "end": "107000"
  },
  {
    "text": "[Music]",
    "start": "350",
    "end": "12639"
  },
  {
    "text": "so the context from last year's talk was",
    "start": "12639",
    "end": "14759"
  },
  {
    "text": "pantic all you need it was a very",
    "start": "14759",
    "end": "16358"
  },
  {
    "text": "popular talk you know it kind of like",
    "start": "16359",
    "end": "18080"
  },
  {
    "text": "kicked off my Twitter career and uh",
    "start": "18080",
    "end": "20439"
  },
  {
    "text": "today I'm coming back a year later to",
    "start": "20439",
    "end": "23039"
  },
  {
    "text": "basically say the same thing again uh",
    "start": "23039",
    "end": "25760"
  },
  {
    "text": "pantic is still all you need and really",
    "start": "25760",
    "end": "27920"
  },
  {
    "text": "my goal is to share with you sort of",
    "start": "27920",
    "end": "29160"
  },
  {
    "text": "what I've learned for the past last year",
    "start": "29160",
    "end": "30920"
  },
  {
    "text": "and and and the problem has always been",
    "start": "30920",
    "end": "33079"
  },
  {
    "text": "the fact that if I had hired an intern",
    "start": "33079",
    "end": "35000"
  },
  {
    "text": "to write an API for me and that API",
    "start": "35000",
    "end": "36800"
  },
  {
    "text": "returns a string that I have the Json",
    "start": "36800",
    "end": "38719"
  },
  {
    "text": "loads into a dictionary and then just",
    "start": "38719",
    "end": "40719"
  },
  {
    "text": "pray that the data was still there to",
    "start": "40719",
    "end": "42200"
  },
  {
    "text": "begin with I would be pretty pissed off",
    "start": "42200",
    "end": "44440"
  },
  {
    "text": "I would probably just fire them replace",
    "start": "44440",
    "end": "46160"
  },
  {
    "text": "them with Devon and just prompted to use",
    "start": "46160",
    "end": "48120"
  },
  {
    "text": "fast API and",
    "start": "48120",
    "end": "49920"
  },
  {
    "text": "pantic because you know I'm really tired",
    "start": "49920",
    "end": "52039"
  },
  {
    "text": "of writing code like this right and this",
    "start": "52039",
    "end": "53480"
  },
  {
    "text": "is the kind of code that we wrote when",
    "start": "53480",
    "end": "54719"
  },
  {
    "text": "we had to work with things like chat gbt",
    "start": "54719",
    "end": "56480"
  },
  {
    "text": "uh gbt 3 and stuff like that but there's",
    "start": "56480",
    "end": "59559"
  },
  {
    "text": "a lot of good tools that we have in the",
    "start": "59559",
    "end": "61320"
  },
  {
    "text": "python ecosystem and the ecosystem in",
    "start": "61320",
    "end": "63440"
  },
  {
    "text": "all of these languages whether it's Ecto",
    "start": "63440",
    "end": "65119"
  },
  {
    "text": "and elixir active record or anything",
    "start": "65119",
    "end": "67080"
  },
  {
    "text": "like that that can make our lives a much",
    "start": "67080",
    "end": "69200"
  },
  {
    "text": "much",
    "start": "69200",
    "end": "70159"
  },
  {
    "text": "easier and so the problem is that by not",
    "start": "70159",
    "end": "72840"
  },
  {
    "text": "having schemas and structured responses",
    "start": "72840",
    "end": "74960"
  },
  {
    "text": "we tend to lose compatibility",
    "start": "74960",
    "end": "76640"
  },
  {
    "text": "composability and reliability when we",
    "start": "76640",
    "end": "78479"
  },
  {
    "text": "build tools and write code that interact",
    "start": "78479",
    "end": "81280"
  },
  {
    "text": "with external systems but it seems that",
    "start": "81280",
    "end": "84159"
  },
  {
    "text": "we're very happy with using llms for the",
    "start": "84159",
    "end": "86799"
  },
  {
    "text": "exact same reason and so last year we",
    "start": "86799",
    "end": "89240"
  },
  {
    "text": "mostly talked about how pantic and",
    "start": "89240",
    "end": "90840"
  },
  {
    "text": "function calling was a great alternative",
    "start": "90840",
    "end": "92759"
  },
  {
    "text": "for how we can use structured output to",
    "start": "92759",
    "end": "95240"
  },
  {
    "text": "do a lot of additional benefits right we",
    "start": "95240",
    "end": "97240"
  },
  {
    "text": "we we are able to have nested objects",
    "start": "97240",
    "end": "99000"
  },
  {
    "text": "and nested models for modular structures",
    "start": "99000",
    "end": "101399"
  },
  {
    "text": "and then we can also use validators to",
    "start": "101399",
    "end": "102920"
  },
  {
    "text": "improve the reliability of the systems",
    "start": "102920",
    "end": "104719"
  },
  {
    "text": "that we build and I'll talk about some",
    "start": "104719",
    "end": "106280"
  },
  {
    "text": "of these examples and so it's been about",
    "start": "106280",
    "end": "109240"
  },
  {
    "start": "107000",
    "end": "401000"
  },
  {
    "text": "a year and a half I think the big",
    "start": "109240",
    "end": "110920"
  },
  {
    "text": "question is what's new in pantic what's",
    "start": "110920",
    "end": "113399"
  },
  {
    "text": "new in the library and the answer is",
    "start": "113399",
    "end": "115439"
  },
  {
    "text": "basically nothing um I'm basically",
    "start": "115439",
    "end": "117920"
  },
  {
    "text": "coming back to say that I was right and",
    "start": "117920",
    "end": "119240"
  },
  {
    "text": "it feels really really good it's still",
    "start": "119240",
    "end": "121920"
  },
  {
    "text": "pip install instructor right and since",
    "start": "121920",
    "end": "124439"
  },
  {
    "text": "then we've released 1.0 uh We've",
    "start": "124439",
    "end": "127200"
  },
  {
    "text": "launched in five languages python uh",
    "start": "127200",
    "end": "130440"
  },
  {
    "text": "typescript Ruby go Elixir we just built",
    "start": "130440",
    "end": "133160"
  },
  {
    "text": "out a version in Rust and again it's",
    "start": "133160",
    "end": "135160"
  },
  {
    "text": "mostly because this is just the exact",
    "start": "135160",
    "end": "137440"
  },
  {
    "text": "600 lines of code that you do not want",
    "start": "137440",
    "end": "139120"
  },
  {
    "text": "to write and at least in the python",
    "start": "139120",
    "end": "141200"
  },
  {
    "text": "Library we've seen you know 40% growth",
    "start": "141200",
    "end": "143160"
  },
  {
    "text": "month over month and you know we've only",
    "start": "143160",
    "end": "145879"
  },
  {
    "text": "had about 2% of the coverage of the open",
    "start": "145879",
    "end": "147840"
  },
  {
    "text": "AI download so there's still tons of",
    "start": "147840",
    "end": "149920"
  },
  {
    "text": "room to grow in terms of how we can you",
    "start": "149920",
    "end": "151879"
  },
  {
    "text": "know make these apis a lot more",
    "start": "151879",
    "end": "154040"
  },
  {
    "text": "ergonomic and so you saw 1.0 you know",
    "start": "154040",
    "end": "156400"
  },
  {
    "text": "you might be going like Jason like what",
    "start": "156400",
    "end": "157879"
  },
  {
    "text": "did we break in the API uh I renamed a",
    "start": "157879",
    "end": "161000"
  },
  {
    "text": "method and now we support things like",
    "start": "161000",
    "end": "163319"
  },
  {
    "text": "oama and llama CBP and along with a",
    "start": "163319",
    "end": "165879"
  },
  {
    "text": "bunch of other apis so we we support",
    "start": "165879",
    "end": "167879"
  },
  {
    "text": "things like anthropic coher Gemini Gro",
    "start": "167879",
    "end": "170800"
  },
  {
    "text": "everything that you need and as long as",
    "start": "170800",
    "end": "172680"
  },
  {
    "text": "language models support more function",
    "start": "172680",
    "end": "174040"
  },
  {
    "text": "calling capabilities this API will",
    "start": "174040",
    "end": "176280"
  },
  {
    "text": "pretty much stay",
    "start": "176280",
    "end": "177519"
  },
  {
    "text": "standard and if you haven't seen the",
    "start": "177519",
    "end": "179440"
  },
  {
    "text": "talk last year the general API looks",
    "start": "179440",
    "end": "181319"
  },
  {
    "text": "like this you define a pantic object you",
    "start": "181319",
    "end": "184319"
  },
  {
    "text": "can then you know patch the open AI",
    "start": "184319",
    "end": "186280"
  },
  {
    "text": "client or any client that you want and",
    "start": "186280",
    "end": "188239"
  },
  {
    "text": "all you have to do is you got to pass in",
    "start": "188239",
    "end": "190000"
  },
  {
    "text": "response model equals user right this is",
    "start": "190000",
    "end": "192920"
  },
  {
    "text": "basically it this is very similar to how",
    "start": "192920",
    "end": "194360"
  },
  {
    "text": "fast API",
    "start": "194360",
    "end": "195640"
  },
  {
    "text": "works and you know I took a little bit",
    "start": "195640",
    "end": "198040"
  },
  {
    "text": "of a hackness but now we can also",
    "start": "198040",
    "end": "199519"
  },
  {
    "text": "leverage some of the new python tooling",
    "start": "199519",
    "end": "201640"
  },
  {
    "text": "to also infer the return type and so",
    "start": "201640",
    "end": "203680"
  },
  {
    "text": "here because response model is a user",
    "start": "203680",
    "end": "205519"
  },
  {
    "text": "the object is inferred as a user object",
    "start": "205519",
    "end": "207840"
  },
  {
    "text": "you get nice red squiggly lines if",
    "start": "207840",
    "end": "209319"
  },
  {
    "text": "you've mess up your code the same thing",
    "start": "209319",
    "end": "212040"
  },
  {
    "text": "happens when you want to create an",
    "start": "212040",
    "end": "213319"
  },
  {
    "text": "iterable here you see that I have a",
    "start": "213319",
    "end": "215400"
  },
  {
    "text": "single response model as a user but I",
    "start": "215400",
    "end": "217319"
  },
  {
    "text": "want to extract two objects and as long",
    "start": "217319",
    "end": "219560"
  },
  {
    "text": "as you set stream equals true you're",
    "start": "219560",
    "end": "221560"
  },
  {
    "text": "going to get each object as they return",
    "start": "221560",
    "end": "223799"
  },
  {
    "text": "and this is kind of a way of using",
    "start": "223799",
    "end": "225439"
  },
  {
    "text": "streaming to improve the latency while",
    "start": "225439",
    "end": "227360"
  },
  {
    "text": "having a little bit more structured",
    "start": "227360",
    "end": "229239"
  },
  {
    "text": "output we also have partials right the",
    "start": "229239",
    "end": "231799"
  },
  {
    "text": "difference here is that instead of just",
    "start": "231799",
    "end": "233760"
  },
  {
    "text": "returning a partially correct or",
    "start": "233760",
    "end": "235519"
  },
  {
    "text": "validated Json object we can validate",
    "start": "235519",
    "end": "237599"
  },
  {
    "text": "the entire object and this means that if",
    "start": "237599",
    "end": "239400"
  },
  {
    "text": "you have things like generative UI that",
    "start": "239400",
    "end": "241120"
  },
  {
    "text": "use a structure you can render that",
    "start": "241120",
    "end": "243280"
  },
  {
    "text": "while streaming without having to write",
    "start": "243280",
    "end": "245239"
  },
  {
    "text": "this like very evil like Json stack code",
    "start": "245239",
    "end": "247760"
  },
  {
    "text": "to figure out how to render this in real",
    "start": "247760",
    "end": "250319"
  },
  {
    "text": "time and so yeah nothing's really",
    "start": "250319",
    "end": "252799"
  },
  {
    "text": "changed you have one noun which is the",
    "start": "252799",
    "end": "254519"
  },
  {
    "text": "client and you have three verbs you can",
    "start": "254519",
    "end": "256280"
  },
  {
    "text": "create create with iterable and create",
    "start": "256280",
    "end": "258120"
  },
  {
    "text": "with partial based on whether or not you",
    "start": "258120",
    "end": "259400"
  },
  {
    "text": "want to use streaming and everything you",
    "start": "259400",
    "end": "261440"
  },
  {
    "text": "else you think about is going to be",
    "start": "261440",
    "end": "262759"
  },
  {
    "text": "around the response model the validators",
    "start": "262759",
    "end": "264840"
  },
  {
    "text": "that you have to build and the messages",
    "start": "264840",
    "end": "266680"
  },
  {
    "text": "array that you pass in so if if open AI",
    "start": "266680",
    "end": "269160"
  },
  {
    "text": "supports some new weird API call as long",
    "start": "269160",
    "end": "271639"
  },
  {
    "text": "as it fits with the messages there's not",
    "start": "271639",
    "end": "273160"
  },
  {
    "text": "going to be any breaking",
    "start": "273160",
    "end": "274880"
  },
  {
    "text": "code and that's why I think pantic is",
    "start": "274880",
    "end": "277000"
  },
  {
    "text": "still all you",
    "start": "277000",
    "end": "277960"
  },
  {
    "text": "need and so the rest of this talk is",
    "start": "277960",
    "end": "280440"
  },
  {
    "text": "basically going to be about you know two",
    "start": "280440",
    "end": "282960"
  },
  {
    "text": "really three things I'm going to cover",
    "start": "282960",
    "end": "284680"
  },
  {
    "text": "some examples of generation in",
    "start": "284680",
    "end": "286280"
  },
  {
    "text": "particular around Rag and extraction",
    "start": "286280",
    "end": "288880"
  },
  {
    "text": "then I'm just going to cover what we",
    "start": "288880",
    "end": "290039"
  },
  {
    "text": "learned this year and it's really not",
    "start": "290039",
    "end": "291680"
  },
  {
    "text": "that much right uh validation errors are",
    "start": "291680",
    "end": "294360"
  },
  {
    "text": "very important and usually they can fix",
    "start": "294360",
    "end": "295880"
  },
  {
    "text": "any errors that we have uh not all",
    "start": "295880",
    "end": "298600"
  },
  {
    "text": "language models can really support retry",
    "start": "298600",
    "end": "300600"
  },
  {
    "text": "logic right now I think that's something",
    "start": "300600",
    "end": "301680"
  },
  {
    "text": "we're going to work towards and",
    "start": "301680",
    "end": "303080"
  },
  {
    "text": "ultimately whether you use Vision or",
    "start": "303080",
    "end": "305199"
  },
  {
    "text": "text or rag or agents they all benefit",
    "start": "305199",
    "end": "307880"
  },
  {
    "text": "from structured outputs right because",
    "start": "307880",
    "end": "309280"
  },
  {
    "text": "the real idea here is we're going to be",
    "start": "309280",
    "end": "310880"
  },
  {
    "text": "programming with data structures which",
    "start": "310880",
    "end": "312479"
  },
  {
    "text": "is something everyone knows how to do",
    "start": "312479",
    "end": "314280"
  },
  {
    "text": "rather than trying to like beg and pray",
    "start": "314280",
    "end": "316160"
  },
  {
    "text": "to the llm gods and really again the",
    "start": "316160",
    "end": "318680"
  },
  {
    "text": "theme of this talk is the fact that",
    "start": "318680",
    "end": "320199"
  },
  {
    "text": "nothing really has changed the language",
    "start": "320199",
    "end": "321639"
  },
  {
    "text": "did not change all we learned to do is",
    "start": "321639",
    "end": "323880"
  },
  {
    "text": "relearn how to",
    "start": "323880",
    "end": "325880"
  },
  {
    "text": "program and so the first concept that I",
    "start": "325880",
    "end": "328080"
  },
  {
    "text": "think many people might not have seen in",
    "start": "328080",
    "end": "329800"
  },
  {
    "text": "pantic is the validators right here you",
    "start": "329800",
    "end": "332360"
  },
  {
    "text": "can define a validator on any kind of",
    "start": "332360",
    "end": "334000"
  },
  {
    "text": "attribute and add additional logic that",
    "start": "334000",
    "end": "336120"
  },
  {
    "text": "tells you what correct looks like and so",
    "start": "336120",
    "end": "338520"
  },
  {
    "text": "you see in my prompt I don't really ask",
    "start": "338520",
    "end": "340319"
  },
  {
    "text": "the language model to uppercase all the",
    "start": "340319",
    "end": "342120"
  },
  {
    "text": "names but I can actually write python",
    "start": "342120",
    "end": "344120"
  },
  {
    "text": "code to verify that something is correct",
    "start": "344120",
    "end": "346280"
  },
  {
    "text": "and throw an error message and if I want",
    "start": "346280",
    "end": "348639"
  },
  {
    "text": "to I can turn retrying on and that error",
    "start": "348639",
    "end": "350960"
  },
  {
    "text": "message is caught by the language model",
    "start": "350960",
    "end": "352720"
  },
  {
    "text": "and then used to correct the outputs and",
    "start": "352720",
    "end": "354280"
  },
  {
    "text": "so in this example it is the error",
    "start": "354280",
    "end": "356199"
  },
  {
    "text": "message that is part of the prompt but",
    "start": "356199",
    "end": "358039"
  },
  {
    "text": "conditionally added to the language",
    "start": "358039",
    "end": "359199"
  },
  {
    "text": "model",
    "start": "359199",
    "end": "360360"
  },
  {
    "text": "and as you can see you know after one",
    "start": "360360",
    "end": "362680"
  },
  {
    "text": "API call Jason has now all caps pretty",
    "start": "362680",
    "end": "365319"
  },
  {
    "text": "nice we can also do model level",
    "start": "365319",
    "end": "368800"
  },
  {
    "text": "validation this is a very simple example",
    "start": "368800",
    "end": "370720"
  },
  {
    "text": "you know that you might see something",
    "start": "370720",
    "end": "372120"
  },
  {
    "text": "like ramp where you're processing",
    "start": "372120",
    "end": "373639"
  },
  {
    "text": "receipts you might want to use a vision",
    "start": "373639",
    "end": "376120"
  },
  {
    "text": "language model to extract the receipt",
    "start": "376120",
    "end": "378039"
  },
  {
    "text": "data there's a total cost and the",
    "start": "378039",
    "end": "379759"
  },
  {
    "text": "products is a list of products and the",
    "start": "379759",
    "end": "381560"
  },
  {
    "text": "validator does something a little bit",
    "start": "381560",
    "end": "383039"
  },
  {
    "text": "more interesting it says make sure that",
    "start": "383039",
    "end": "384960"
  },
  {
    "text": "the price and the quantity add up to the",
    "start": "384960",
    "end": "386599"
  },
  {
    "text": "total cost right again this basically",
    "start": "386599",
    "end": "389599"
  },
  {
    "text": "doesn't really happen for 99% of the",
    "start": "389599",
    "end": "391280"
  },
  {
    "text": "cases but when it does happen you see",
    "start": "391280",
    "end": "393639"
  },
  {
    "text": "like a red bar in data dog and that's",
    "start": "393639",
    "end": "395319"
  },
  {
    "text": "really what I care about and if I want",
    "start": "395319",
    "end": "396840"
  },
  {
    "text": "to ask re asking I want to make sure",
    "start": "396840",
    "end": "398319"
  },
  {
    "text": "that again everything's done",
    "start": "398319",
    "end": "400560"
  },
  {
    "text": "correctly so let's jump into generation",
    "start": "400560",
    "end": "403080"
  },
  {
    "start": "401000",
    "end": "464000"
  },
  {
    "text": "right why should I use structured",
    "start": "403080",
    "end": "404919"
  },
  {
    "text": "outputs well it turns out if you don't",
    "start": "404919",
    "end": "406759"
  },
  {
    "text": "use structure outputs the structure you",
    "start": "406759",
    "end": "408520"
  },
  {
    "text": "get is just response as a Content string",
    "start": "408520",
    "end": "411319"
  },
  {
    "text": "right you still get an object back out",
    "start": "411319",
    "end": "413440"
  },
  {
    "text": "but you're just hoping that you don't",
    "start": "413440",
    "end": "414479"
  },
  {
    "text": "have to call Json Lowe's yourself and",
    "start": "414479",
    "end": "416199"
  },
  {
    "text": "you know eat eat whatever cost uh you",
    "start": "416199",
    "end": "418759"
  },
  {
    "text": "have in terms of",
    "start": "418759",
    "end": "420039"
  },
  {
    "text": "parsing and so a really simple example",
    "start": "420039",
    "end": "422360"
  },
  {
    "text": "of a rag application is not only having",
    "start": "422360",
    "end": "424479"
  },
  {
    "text": "a Content but having a list of follow-up",
    "start": "424479",
    "end": "426599"
  },
  {
    "text": "questions right the followup questions",
    "start": "426599",
    "end": "428199"
  },
  {
    "text": "can be informed by the existing context",
    "start": "428199",
    "end": "430520"
  },
  {
    "text": "but now you're going to let the user",
    "start": "430520",
    "end": "431919"
  },
  {
    "text": "show like hey like there's other",
    "start": "431919",
    "end": "433039"
  },
  {
    "text": "questions that you can answer based on",
    "start": "433039",
    "end": "434680"
  },
  {
    "text": "the context that I've put in the",
    "start": "434680",
    "end": "436280"
  },
  {
    "text": "prompt a really funny example that I've",
    "start": "436280",
    "end": "438440"
  },
  {
    "text": "actually done in production quite a bit",
    "start": "438440",
    "end": "440000"
  },
  {
    "text": "is just making sure that the links we",
    "start": "440000",
    "end": "441840"
  },
  {
    "text": "return are valid and so here I have a",
    "start": "441840",
    "end": "444240"
  },
  {
    "text": "very simple validator I just have a",
    "start": "444240",
    "end": "446599"
  },
  {
    "text": "regular expression parse all the URLs",
    "start": "446599",
    "end": "448919"
  },
  {
    "text": "and I use po post to figure out if the",
    "start": "448919",
    "end": "450639"
  },
  {
    "text": "URL returns a 200 and now I can make",
    "start": "450639",
    "end": "453080"
  },
  {
    "text": "sure very easily that no URLs are you",
    "start": "453080",
    "end": "455720"
  },
  {
    "text": "know hallucinated and in my instructions",
    "start": "455720",
    "end": "458400"
  },
  {
    "text": "I just say well if it's not real just",
    "start": "458400",
    "end": "460520"
  },
  {
    "text": "throw it out next time right don't try",
    "start": "460520",
    "end": "461879"
  },
  {
    "text": "to don't try too",
    "start": "461879",
    "end": "463919"
  },
  {
    "text": "hard the same thing happens with",
    "start": "463919",
    "end": "465840"
  },
  {
    "start": "464000",
    "end": "551000"
  },
  {
    "text": "retrieval augmented generation we all",
    "start": "465840",
    "end": "468479"
  },
  {
    "text": "kind of know at this point that",
    "start": "468479",
    "end": "469520"
  },
  {
    "text": "embeddings won't really solve all the",
    "start": "469520",
    "end": "471159"
  },
  {
    "text": "problems you have in search right for",
    "start": "471159",
    "end": "472840"
  },
  {
    "text": "example if I ask a questions like what",
    "start": "472840",
    "end": "474840"
  },
  {
    "text": "is the latest news from Z like latest",
    "start": "474840",
    "end": "478039"
  },
  {
    "text": "news isn't something that embedding can",
    "start": "478039",
    "end": "479759"
  },
  {
    "text": "capture right the source of that maybe",
    "start": "479759",
    "end": "482720"
  },
  {
    "text": "that is relevant if you use bm25 but",
    "start": "482720",
    "end": "485000"
  },
  {
    "text": "really there might be separate indices",
    "start": "485000",
    "end": "486360"
  },
  {
    "text": "that we want to query and we can use",
    "start": "486360",
    "end": "488440"
  },
  {
    "text": "something very simple in the structured",
    "start": "488440",
    "end": "490000"
  },
  {
    "text": "output world that makes this very",
    "start": "490000",
    "end": "491879"
  },
  {
    "text": "reasonable right here I can define a",
    "start": "491879",
    "end": "493639"
  },
  {
    "text": "search object I say it has a query a",
    "start": "493639",
    "end": "495919"
  },
  {
    "text": "start date an end date that is optional",
    "start": "495919",
    "end": "498440"
  },
  {
    "text": "maybe there's a limit in case I want to",
    "start": "498440",
    "end": "499879"
  },
  {
    "text": "see the top five results and then a",
    "start": "499879",
    "end": "501960"
  },
  {
    "text": "source that allows the language model to",
    "start": "501960",
    "end": "503560"
  },
  {
    "text": "choose which back end I want to hit and",
    "start": "503560",
    "end": "506720"
  },
  {
    "text": "then you know whe How you actually",
    "start": "506720",
    "end": "507919"
  },
  {
    "text": "search the endpoint is kind of an",
    "start": "507919",
    "end": "509080"
  },
  {
    "text": "implement detail that we don't care",
    "start": "509080",
    "end": "510560"
  },
  {
    "text": "about and now you just Define a very",
    "start": "510560",
    "end": "512080"
  },
  {
    "text": "simple function you know create search",
    "start": "512080",
    "end": "514200"
  },
  {
    "text": "it takes in a string Returns the object",
    "start": "514200",
    "end": "516518"
  },
  {
    "text": "and even the API call itself now is an",
    "start": "516519",
    "end": "518640"
  },
  {
    "text": "implementation detail right as long as I",
    "start": "518640",
    "end": "520320"
  },
  {
    "text": "get the search query out and it's",
    "start": "520320",
    "end": "521760"
  },
  {
    "text": "correct I can do a lot more and in",
    "start": "521760",
    "end": "523800"
  },
  {
    "text": "particular like even the validations",
    "start": "523800",
    "end": "525440"
  },
  {
    "text": "themselves you know I can figure out",
    "start": "525440",
    "end": "528040"
  },
  {
    "text": "whether the date ranges are zero days",
    "start": "528040",
    "end": "530240"
  },
  {
    "text": "one day and and figure out even",
    "start": "530240",
    "end": "531480"
  },
  {
    "text": "distributions based on the structured",
    "start": "531480",
    "end": "533720"
  },
  {
    "text": "output then if I ask a question like",
    "start": "533720",
    "end": "535720"
  },
  {
    "text": "what is the difference between X and Y I",
    "start": "535720",
    "end": "537880"
  },
  {
    "text": "can just turn on iterable mode",
    "start": "537880",
    "end": "540000"
  },
  {
    "text": "now if I ask this question I'm going to",
    "start": "540000",
    "end": "541720"
  },
  {
    "text": "have a search question query for y a",
    "start": "541720",
    "end": "543760"
  },
  {
    "text": "search query for x and again my rag",
    "start": "543760",
    "end": "545959"
  },
  {
    "text": "application can figure out that I can do",
    "start": "545959",
    "end": "547680"
  },
  {
    "text": "two parallel search queries collect them",
    "start": "547680",
    "end": "549480"
  },
  {
    "text": "together and continue on and so this",
    "start": "549480",
    "end": "552360"
  },
  {
    "start": "551000",
    "end": "920000"
  },
  {
    "text": "means that you can build a fairly",
    "start": "552360",
    "end": "553560"
  },
  {
    "text": "sophisticated rag application in two",
    "start": "553560",
    "end": "555200"
  },
  {
    "text": "functions and two models first you have",
    "start": "555200",
    "end": "558160"
  },
  {
    "text": "the model for how you respond with the",
    "start": "558160",
    "end": "559880"
  },
  {
    "text": "data and then how you process a search",
    "start": "559880",
    "end": "561880"
  },
  {
    "text": "query right as you can see here and then",
    "start": "561880",
    "end": "564240"
  },
  {
    "text": "you just Define two functions that",
    "start": "564240",
    "end": "566120"
  },
  {
    "text": "return those",
    "start": "566120",
    "end": "568360"
  },
  {
    "text": "objects and then this is basically your",
    "start": "568360",
    "end": "570480"
  },
  {
    "text": "Advanced rag application right you make",
    "start": "570480",
    "end": "572079"
  },
  {
    "text": "a search query you return multiple",
    "start": "572079",
    "end": "573800"
  },
  {
    "text": "searches you search each one and then",
    "start": "573800",
    "end": "575600"
  },
  {
    "text": "you pass the context into the answer",
    "start": "575600",
    "end": "577440"
  },
  {
    "text": "answer question function right this is",
    "start": "577440",
    "end": "579440"
  },
  {
    "text": "very very straightforward code but what",
    "start": "579440",
    "end": "581240"
  },
  {
    "text": "this means is you get to render",
    "start": "581240",
    "end": "582600"
  },
  {
    "text": "something very structured and then",
    "start": "582600",
    "end": "584200"
  },
  {
    "text": "whether or not this endpoint is used by",
    "start": "584200",
    "end": "585720"
  },
  {
    "text": "open API is parsed by a react model you",
    "start": "585720",
    "end": "588839"
  },
  {
    "text": "know again these are all just",
    "start": "588839",
    "end": "589800"
  },
  {
    "text": "implementation details the llm is very",
    "start": "589800",
    "end": "591880"
  },
  {
    "text": "hidden behind the the type system that",
    "start": "591880",
    "end": "594040"
  },
  {
    "text": "we can now guarantee to be",
    "start": "594040",
    "end": "595880"
  },
  {
    "text": "correct and the last one I think is",
    "start": "595880",
    "end": "597720"
  },
  {
    "text": "really interesting is this data",
    "start": "597720",
    "end": "598680"
  },
  {
    "text": "extraction um you know if you want to do",
    "start": "598680",
    "end": "601079"
  },
  {
    "text": "something like labeling it's really easy",
    "start": "601079",
    "end": "602640"
  },
  {
    "text": "to just say Okay class label is a",
    "start": "602640",
    "end": "604399"
  },
  {
    "text": "literal of either spam or not spam",
    "start": "604399",
    "end": "606800"
  },
  {
    "text": "you've built a classifier if you want",
    "start": "606800",
    "end": "608560"
  },
  {
    "text": "the accuracy to improve about 15% you",
    "start": "608560",
    "end": "610680"
  },
  {
    "text": "can have Chain of Thought right and",
    "start": "610680",
    "end": "612399"
  },
  {
    "text": "again it's the structure that tells you",
    "start": "612399",
    "end": "613760"
  },
  {
    "text": "how the language model works but you",
    "start": "613760",
    "end": "615240"
  },
  {
    "text": "still have good validation on whether or",
    "start": "615240",
    "end": "617000"
  },
  {
    "text": "not you're going to get you know spam or",
    "start": "617000",
    "end": "619079"
  },
  {
    "text": "some some like Babble on like you know",
    "start": "619079",
    "end": "621800"
  },
  {
    "text": "here's the Json that you care",
    "start": "621800",
    "end": "624000"
  },
  {
    "text": "about you can do the same thing for",
    "start": "624000",
    "end": "625880"
  },
  {
    "text": "things like extracting like structured",
    "start": "625880",
    "end": "627440"
  },
  {
    "text": "information out of transcripts like a",
    "start": "627440",
    "end": "628760"
  },
  {
    "text": "very common example examples people want",
    "start": "628760",
    "end": "630040"
  },
  {
    "text": "to process transcripts now it's very",
    "start": "630040",
    "end": "632120"
  },
  {
    "text": "structured right I have a have a",
    "start": "632120",
    "end": "633519"
  },
  {
    "text": "classification in the meeting type I've",
    "start": "633519",
    "end": "635120"
  },
  {
    "text": "given myself a title a list of action",
    "start": "635120",
    "end": "637120"
  },
  {
    "text": "items and a summary here the owner is a",
    "start": "637120",
    "end": "639560"
  },
  {
    "text": "string but you could imagine having a",
    "start": "639560",
    "end": "640959"
  },
  {
    "text": "validator that makes sure that the",
    "start": "640959",
    "end": "642959"
  },
  {
    "text": "owners are the at least one of the",
    "start": "642959",
    "end": "645320"
  },
  {
    "text": "participants of the email based on some",
    "start": "645320",
    "end": "647440"
  },
  {
    "text": "Google Calendar integration uh again",
    "start": "647440",
    "end": "649519"
  },
  {
    "text": "these are all implementation details",
    "start": "649519",
    "end": "651360"
  },
  {
    "text": "it's all up to you and then lastly you",
    "start": "651360",
    "end": "653760"
  },
  {
    "text": "can do some really magical stuff in this",
    "start": "653760",
    "end": "655680"
  },
  {
    "text": "example the type I've given is called",
    "start": "655680",
    "end": "657639"
  },
  {
    "text": "table it has a caption string and a very",
    "start": "657639",
    "end": "660040"
  },
  {
    "text": "weird data markdown data frame type hint",
    "start": "660040",
    "end": "662880"
  },
  {
    "text": "and here what you can see is that I'm",
    "start": "662880",
    "end": "664240"
  },
  {
    "text": "really just trying to extract images or",
    "start": "664240",
    "end": "666480"
  },
  {
    "text": "tables out of an",
    "start": "666480",
    "end": "667880"
  },
  {
    "text": "image but this is a bit wild like don't",
    "start": "667880",
    "end": "670120"
  },
  {
    "text": "worry if you don't understand it but",
    "start": "670120",
    "end": "671360"
  },
  {
    "text": "basically what we're using is we're",
    "start": "671360",
    "end": "672560"
  },
  {
    "text": "using the new pip uh",
    "start": "672560",
    "end": "674959"
  },
  {
    "text": "pep basically to figure out how we can",
    "start": "674959",
    "end": "677360"
  },
  {
    "text": "use annotations to create new typ hints",
    "start": "677360",
    "end": "680639"
  },
  {
    "text": "and so this typeint is pretty Advanced",
    "start": "680639",
    "end": "682120"
  },
  {
    "text": "it says that is an instance of data",
    "start": "682120",
    "end": "683680"
  },
  {
    "text": "frame which means your IDE will now",
    "start": "683680",
    "end": "685800"
  },
  {
    "text": "autocomplete all the data frame methods",
    "start": "685800",
    "end": "688040"
  },
  {
    "text": "as you continue to program",
    "start": "688040",
    "end": "689800"
  },
  {
    "text": "but the before valuator says I Know M",
    "start": "689800",
    "end": "692600"
  },
  {
    "text": "markdown is going to come out but I want",
    "start": "692600",
    "end": "693880"
  },
  {
    "text": "to parse it to a data frame the",
    "start": "693880",
    "end": "695320"
  },
  {
    "text": "serializer says I know it's a data frame",
    "start": "695320",
    "end": "697480"
  },
  {
    "text": "but when I serialize it I want it to be",
    "start": "697480",
    "end": "698760"
  },
  {
    "text": "marked down and then lastly you can add",
    "start": "698760",
    "end": "701160"
  },
  {
    "text": "additional Json schema information which",
    "start": "701160",
    "end": "703360"
  },
  {
    "text": "becomes the prompt that you would use to",
    "start": "703360",
    "end": "705120"
  },
  {
    "text": "send to a language model but the idea",
    "start": "705120",
    "end": "707600"
  },
  {
    "text": "here is you know it's really just a type",
    "start": "707600",
    "end": "709480"
  },
  {
    "text": "system that we've defined that can be",
    "start": "709480",
    "end": "711079"
  },
  {
    "text": "used by a language model and then you",
    "start": "711079",
    "end": "713360"
  },
  {
    "text": "can get pretty interesting outputs out",
    "start": "713360",
    "end": "714519"
  },
  {
    "text": "of this right and because of the data",
    "start": "714519",
    "end": "716200"
  },
  {
    "text": "frame you can instantly call two CSV or",
    "start": "716200",
    "end": "718720"
  },
  {
    "text": "something like that without worrying",
    "start": "718720",
    "end": "720120"
  },
  {
    "text": "about other implementation",
    "start": "720120",
    "end": "721959"
  },
  {
    "text": "details and so what we've seen is that",
    "start": "721959",
    "end": "724279"
  },
  {
    "text": "we can now just generate things like",
    "start": "724279",
    "end": "725600"
  },
  {
    "text": "date ranges relationships we can",
    "start": "725600",
    "end": "727600"
  },
  {
    "text": "generate knowledge graphs as we' shown",
    "start": "727600",
    "end": "729079"
  },
  {
    "text": "last year and generally just think about",
    "start": "729079",
    "end": "730720"
  },
  {
    "text": "dags and workflows and tables and again",
    "start": "730720",
    "end": "733839"
  },
  {
    "text": "all we really care about is just coming",
    "start": "733839",
    "end": "735639"
  },
  {
    "text": "up with a creative response model having",
    "start": "735639",
    "end": "737959"
  },
  {
    "text": "a good set of validators and as models",
    "start": "737959",
    "end": "739959"
  },
  {
    "text": "get smarter we're only going to have to",
    "start": "739959",
    "end": "741920"
  },
  {
    "text": "do less and less right this is fairly",
    "start": "741920",
    "end": "745000"
  },
  {
    "text": "bulletproof and so for the last like 5",
    "start": "745000",
    "end": "747440"
  },
  {
    "text": "minutes I really just want to share what",
    "start": "747440",
    "end": "748720"
  },
  {
    "text": "I've learned in the past year right the",
    "start": "748720",
    "end": "750639"
  },
  {
    "text": "first thing is that often one retry for",
    "start": "750639",
    "end": "752920"
  },
  {
    "text": "models like open Ai and anthropic are",
    "start": "752920",
    "end": "755079"
  },
  {
    "text": "basically enough and really all you care",
    "start": "755079",
    "end": "757440"
  },
  {
    "text": "about is having good well-written",
    "start": "757440",
    "end": "759440"
  },
  {
    "text": "informative error messages which has",
    "start": "759440",
    "end": "761320"
  },
  {
    "text": "been hard for all time but now you're",
    "start": "761320",
    "end": "763079"
  },
  {
    "text": "more incentivized to build this out",
    "start": "763079",
    "end": "764600"
  },
  {
    "text": "because this not only makes the code",
    "start": "764600",
    "end": "766040"
  },
  {
    "text": "more readable to you but to the language",
    "start": "766040",
    "end": "768320"
  },
  {
    "text": "model then lastly for the new models",
    "start": "768320",
    "end": "770720"
  },
  {
    "text": "from like 3.5 and you know 40 they're so",
    "start": "770720",
    "end": "773600"
  },
  {
    "text": "much faster now that we can actually eat",
    "start": "773600",
    "end": "775160"
  },
  {
    "text": "the cost of latency for performance and",
    "start": "775160",
    "end": "777440"
  },
  {
    "text": "so again you know as these models get",
    "start": "777440",
    "end": "778959"
  },
  {
    "text": "far smarter and faster you're still",
    "start": "778959",
    "end": "780760"
  },
  {
    "text": "fairly",
    "start": "780760",
    "end": "782079"
  },
  {
    "text": "bulletproof one thing I've noticed in a",
    "start": "782079",
    "end": "783920"
  },
  {
    "text": "lot of like Consulting that I've done is",
    "start": "783920",
    "end": "785720"
  },
  {
    "text": "that we see like four to five% failure",
    "start": "785720",
    "end": "787760"
  },
  {
    "text": "modes and very complex validations but",
    "start": "787760",
    "end": "790519"
  },
  {
    "text": "just by fine-tuning language models on",
    "start": "790519",
    "end": "792199"
  },
  {
    "text": "function calling we can get them down to",
    "start": "792199",
    "end": "793680"
  },
  {
    "text": "zero for even simple models like mistol",
    "start": "793680",
    "end": "795680"
  },
  {
    "text": "or gbd 5 sorry gbd",
    "start": "795680",
    "end": "798160"
  },
  {
    "text": "3.5 and lastly structured output is here",
    "start": "798160",
    "end": "801000"
  },
  {
    "text": "to stay mostly because even in domains",
    "start": "801000",
    "end": "803160"
  },
  {
    "text": "like Vision or rag or agents really what",
    "start": "803160",
    "end": "806120"
  },
  {
    "text": "I care about is defining the type system",
    "start": "806120",
    "end": "808000"
  },
  {
    "text": "that I want to program with on top of",
    "start": "808000",
    "end": "809839"
  },
  {
    "text": "how I want to use language models right",
    "start": "809839",
    "end": "811760"
  },
  {
    "text": "prompting is an implementation detail",
    "start": "811760",
    "end": "813680"
  },
  {
    "text": "the response model is an implementation",
    "start": "813680",
    "end": "815360"
  },
  {
    "text": "detail and whether or not we use",
    "start": "815360",
    "end": "817079"
  },
  {
    "text": "something like constraint sampling",
    "start": "817079",
    "end": "818360"
  },
  {
    "text": "that's available in llama CBP or Lama or",
    "start": "818360",
    "end": "820480"
  },
  {
    "text": "outlines again the benefits I get as a",
    "start": "820480",
    "end": "822959"
  },
  {
    "text": "programmer is sort of on a different",
    "start": "822959",
    "end": "824399"
  },
  {
    "text": "level of abstraction and then even with",
    "start": "824399",
    "end": "826880"
  },
  {
    "text": "things like Rag and",
    "start": "826880",
    "end": "828720"
  },
  {
    "text": "agents right now we think of rag as much",
    "start": "828720",
    "end": "831160"
  },
  {
    "text": "more like question answering systems but",
    "start": "831160",
    "end": "832920"
  },
  {
    "text": "in larger Enterprise situations I see a",
    "start": "832920",
    "end": "835680"
  },
  {
    "text": "lot of report generation as a step to",
    "start": "835680",
    "end": "837839"
  },
  {
    "text": "make you know better decision making",
    "start": "837839",
    "end": "839839"
  },
  {
    "text": "right in agents A lot of it now becomes",
    "start": "839839",
    "end": "841880"
  },
  {
    "text": "generating workflows and dags to then go",
    "start": "841880",
    "end": "844079"
  },
  {
    "text": "send to an execution engine to do the",
    "start": "844079",
    "end": "846079"
  },
  {
    "text": "computation ourselves rather than having",
    "start": "846079",
    "end": "848120"
  },
  {
    "text": "some kind of react Loop and hope that",
    "start": "848120",
    "end": "850040"
  },
  {
    "text": "these things",
    "start": "850040",
    "end": "851320"
  },
  {
    "text": "terminate and so really there's no new",
    "start": "851320",
    "end": "853440"
  },
  {
    "text": "abstractions right everything that we've",
    "start": "853440",
    "end": "854880"
  },
  {
    "text": "done today is just reducing language",
    "start": "854880",
    "end": "856720"
  },
  {
    "text": "models back to very classical",
    "start": "856720",
    "end": "858079"
  },
  {
    "text": "programming right what I care about is",
    "start": "858079",
    "end": "859959"
  },
  {
    "text": "that my ID understands the types and we",
    "start": "859959",
    "end": "862240"
  },
  {
    "text": "just get red squiggly lines when things",
    "start": "862240",
    "end": "863759"
  },
  {
    "text": "are unhappy and what we've done is we've",
    "start": "863759",
    "end": "866680"
  },
  {
    "text": "turned generative AI just to becoming",
    "start": "866680",
    "end": "869079"
  },
  {
    "text": "generating data structures right you can",
    "start": "869079",
    "end": "871000"
  },
  {
    "text": "now own the objects you define you own",
    "start": "871000",
    "end": "872759"
  },
  {
    "text": "the functions that you implement you own",
    "start": "872759",
    "end": "874360"
  },
  {
    "text": "the control flow and most importantly",
    "start": "874360",
    "end": "876199"
  },
  {
    "text": "you own the prompts because we just give",
    "start": "876199",
    "end": "877600"
  },
  {
    "text": "you this messages array and you can do",
    "start": "877600",
    "end": "879320"
  },
  {
    "text": "anything that you",
    "start": "879320",
    "end": "880639"
  },
  {
    "text": "want and what this means to me and I",
    "start": "880639",
    "end": "883120"
  },
  {
    "text": "think what this means to everyone else",
    "start": "883120",
    "end": "884399"
  },
  {
    "text": "here is that we are actually turning",
    "start": "884399",
    "end": "885880"
  },
  {
    "text": "software 3.0 and making it backwards",
    "start": "885880",
    "end": "888120"
  },
  {
    "text": "compatible with existing software right",
    "start": "888120",
    "end": "890560"
  },
  {
    "text": "we're allowing ourselves to demystify",
    "start": "890560",
    "end": "892000"
  },
  {
    "text": "the language models and go back to a",
    "start": "892000",
    "end": "893759"
  },
  {
    "text": "much more classical structure how we",
    "start": "893759",
    "end": "896440"
  },
  {
    "text": "program and that's why I still think",
    "start": "896440",
    "end": "898399"
  },
  {
    "text": "pantic is basically all we need thank",
    "start": "898399",
    "end": "900759"
  },
  {
    "text": "you",
    "start": "900759",
    "end": "903759"
  },
  {
    "text": "[Music]",
    "start": "905660",
    "end": "922579"
  }
]
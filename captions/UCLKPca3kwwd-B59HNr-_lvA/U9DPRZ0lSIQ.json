[
  {
    "text": "[Music]",
    "start": "350",
    "end": "14000"
  },
  {
    "text": "maybe to set the stage a little bit um",
    "start": "14000",
    "end": "16720"
  },
  {
    "text": "last four or five years of AI have",
    "start": "16720",
    "end": "18640"
  },
  {
    "text": "basically been really focused on this",
    "start": "18640",
    "end": "20240"
  },
  {
    "text": "idea of batch intelligence which is sort",
    "start": "20240",
    "end": "22320"
  },
  {
    "text": "of um pretty core to this uh idea of uh",
    "start": "22320",
    "end": "26000"
  },
  {
    "text": "building like an AI system that can",
    "start": "26000",
    "end": "27800"
  },
  {
    "text": "reason uh for long periods of time on a",
    "start": "27800",
    "end": "30279"
  },
  {
    "text": "problem and then solve it so you can",
    "start": "30279",
    "end": "32000"
  },
  {
    "text": "think about like math problems or you",
    "start": "32000",
    "end": "33879"
  },
  {
    "text": "know physics problems that are hard um",
    "start": "33879",
    "end": "36200"
  },
  {
    "text": "there's a lot of applications where",
    "start": "36200",
    "end": "38000"
  },
  {
    "text": "actually what you need are systems that",
    "start": "38000",
    "end": "39680"
  },
  {
    "text": "are streaming so they're real time they",
    "start": "39680",
    "end": "41920"
  },
  {
    "text": "work instantly so imagine um generating",
    "start": "41920",
    "end": "44800"
  },
  {
    "text": "video audio or um doing like",
    "start": "44800",
    "end": "47559"
  },
  {
    "text": "understanding applications on um sensor",
    "start": "47559",
    "end": "49920"
  },
  {
    "text": "streams Etc so um so it sort of",
    "start": "49920",
    "end": "52320"
  },
  {
    "text": "bifurcates where there's these two",
    "start": "52320",
    "end": "53879"
  },
  {
    "text": "different types of uh applications",
    "start": "53879",
    "end": "56199"
  },
  {
    "text": "similar to how there's you know",
    "start": "56199",
    "end": "57359"
  },
  {
    "text": "generally this idea of having batch",
    "start": "57359",
    "end": "59280"
  },
  {
    "text": "workloads and streaming workloads and so",
    "start": "59280",
    "end": "61879"
  },
  {
    "text": "um a lot of what we've seen over the",
    "start": "61879",
    "end": "63280"
  },
  {
    "text": "last few years has really been focused",
    "start": "63280",
    "end": "65000"
  },
  {
    "text": "on uh batch apis or you call a model in",
    "start": "65000",
    "end": "67840"
  },
  {
    "text": "the cloud it takes a few seconds and",
    "start": "67840",
    "end": "69400"
  },
  {
    "text": "then you get a pretty good response back",
    "start": "69400",
    "end": "72000"
  },
  {
    "text": "um and now we're seeing some shift",
    "start": "72000",
    "end": "73920"
  },
  {
    "text": "towards more real-time applications",
    "start": "73920",
    "end": "75840"
  },
  {
    "text": "where you constantly will be quering a",
    "start": "75840",
    "end": "77960"
  },
  {
    "text": "model and um asking it to return",
    "start": "77960",
    "end": "81200"
  },
  {
    "text": "responses at low latency and then uh",
    "start": "81200",
    "end": "83000"
  },
  {
    "text": "using that to sort of interpret uh or",
    "start": "83000",
    "end": "85680"
  },
  {
    "text": "generate",
    "start": "85680",
    "end": "88000"
  },
  {
    "text": "information um and I think this you know",
    "start": "88000",
    "end": "90640"
  },
  {
    "text": "this area is really exciting because",
    "start": "90640",
    "end": "92119"
  },
  {
    "text": "it's going to be transformative to a lot",
    "start": "92119",
    "end": "94240"
  },
  {
    "text": "of interesting applications that um have",
    "start": "94240",
    "end": "96960"
  },
  {
    "text": "so far actually not necessarily been uh",
    "start": "96960",
    "end": "99759"
  },
  {
    "text": "the main focus for uh a lot of what",
    "start": "99759",
    "end": "101880"
  },
  {
    "text": "we've seen over the last few years so",
    "start": "101880",
    "end": "103880"
  },
  {
    "text": "conversational voice uh is an example of",
    "start": "103880",
    "end": "105960"
  },
  {
    "text": "this where you should be able to",
    "start": "105960",
    "end": "106880"
  },
  {
    "text": "interact with a system and then talk to",
    "start": "106880",
    "end": "108560"
  },
  {
    "text": "it um and it should be able to",
    "start": "108560",
    "end": "111000"
  },
  {
    "text": "understand you and and do all kinds of",
    "start": "111000",
    "end": "112880"
  },
  {
    "text": "tasks on your behalf uh this is similar",
    "start": "112880",
    "end": "114960"
  },
  {
    "text": "to having assistants um that are on",
    "start": "114960",
    "end": "117240"
  },
  {
    "text": "device and run kind of really",
    "start": "117240",
    "end": "118680"
  },
  {
    "text": "efficiently at low power",
    "start": "118680",
    "end": "120479"
  },
  {
    "text": "um at you know all times um regardless",
    "start": "120479",
    "end": "123719"
  },
  {
    "text": "of whether you're on a phone or or",
    "start": "123719",
    "end": "125200"
  },
  {
    "text": "laptop and then um things like World",
    "start": "125200",
    "end": "127360"
  },
  {
    "text": "Generation where like you can imagine",
    "start": "127360",
    "end": "129000"
  },
  {
    "text": "actually playing a game that is",
    "start": "129000",
    "end": "130360"
  },
  {
    "text": "generated in real time similar to um how",
    "start": "130360",
    "end": "132760"
  },
  {
    "text": "the graphics are rendered um on gpus um",
    "start": "132760",
    "end": "135879"
  },
  {
    "text": "and um all of this you know should be",
    "start": "135879",
    "end": "138400"
  },
  {
    "text": "able to happen in real time on low power",
    "start": "138400",
    "end": "142400"
  },
  {
    "text": "on your phone uh on your MacBook Etc um",
    "start": "142400",
    "end": "146160"
  },
  {
    "text": "robotics is another great example where",
    "start": "146160",
    "end": "148040"
  },
  {
    "text": "it sort of culminates with all these",
    "start": "148040",
    "end": "149519"
  },
  {
    "text": "coming together on a on a single um uh",
    "start": "149519",
    "end": "153200"
  },
  {
    "text": "device that is uh trying to kind of",
    "start": "153200",
    "end": "155239"
  },
  {
    "text": "interpret everything in the world and so",
    "start": "155239",
    "end": "158040"
  },
  {
    "text": "I think this is sort of the exciting",
    "start": "158040",
    "end": "159400"
  },
  {
    "text": "intersection which is like how do we",
    "start": "159400",
    "end": "160879"
  },
  {
    "text": "make intelligence faster and cheaper so",
    "start": "160879",
    "end": "163480"
  },
  {
    "text": "that we can put it um everywhere",
    "start": "163480",
    "end": "166560"
  },
  {
    "text": "basically um and a couple examples that",
    "start": "166560",
    "end": "168720"
  },
  {
    "text": "are really powerful real-time",
    "start": "168720",
    "end": "169920"
  },
  {
    "text": "intelligence for conversational",
    "start": "169920",
    "end": "171800"
  },
  {
    "text": "interfaces uh is going to be really",
    "start": "171800",
    "end": "173519"
  },
  {
    "text": "interesting because you would be able to",
    "start": "173519",
    "end": "175200"
  },
  {
    "text": "have a agent that can provide customer",
    "start": "175200",
    "end": "177080"
  },
  {
    "text": "support for a problem answer questions",
    "start": "177080",
    "end": "179360"
  },
  {
    "text": "about health Insurance uh you know call",
    "start": "179360",
    "end": "181879"
  },
  {
    "text": "your vendor to pick up a shipment all",
    "start": "181879",
    "end": "184200"
  },
  {
    "text": "these coordination tasks that uh",
    "start": "184200",
    "end": "186319"
  },
  {
    "text": "generally are um annoying to do should",
    "start": "186319",
    "end": "189120"
  },
  {
    "text": "be really automated and uh real-time",
    "start": "189120",
    "end": "191720"
  },
  {
    "text": "intelligent agents should be doing them",
    "start": "191720",
    "end": "193599"
  },
  {
    "text": "um and then humans can spend their time",
    "start": "193599",
    "end": "194920"
  },
  {
    "text": "solving sort of harder problems that are",
    "start": "194920",
    "end": "197000"
  },
  {
    "text": "uh more interesting and in customer",
    "start": "197000",
    "end": "198920"
  },
  {
    "text": "support that could be dealing with uh",
    "start": "198920",
    "end": "200840"
  },
  {
    "text": "you know the tail of customers that are",
    "start": "200840",
    "end": "202519"
  },
  {
    "text": "much more important because they're",
    "start": "202519",
    "end": "203959"
  },
  {
    "text": "pissed off or they're uh uh more",
    "start": "203959",
    "end": "206599"
  },
  {
    "text": "important because they have uh you know",
    "start": "206599",
    "end": "208480"
  },
  {
    "text": "more customer value Etc",
    "start": "208480",
    "end": "210920"
  },
  {
    "text": "and similarly in robotics there's this",
    "start": "210920",
    "end": "212519"
  },
  {
    "text": "idea of like ingesting similar to humans",
    "start": "212519",
    "end": "214799"
  },
  {
    "text": "like audio video sensor data and then",
    "start": "214799",
    "end": "216760"
  },
  {
    "text": "responding instantly to a lot of these",
    "start": "216760",
    "end": "218959"
  },
  {
    "text": "um pieces of information so I think this",
    "start": "218959",
    "end": "221159"
  },
  {
    "text": "is sort of the the world we we should be",
    "start": "221159",
    "end": "223360"
  },
  {
    "text": "living in where all these intelligent",
    "start": "223360",
    "end": "224959"
  },
  {
    "text": "models run super fast they solve all",
    "start": "224959",
    "end": "227080"
  },
  {
    "text": "these different problems and uh they're",
    "start": "227080",
    "end": "229200"
  },
  {
    "text": "able to really kind of um Power these",
    "start": "229200",
    "end": "231920"
  },
  {
    "text": "new experiences that are interactive at",
    "start": "231920",
    "end": "234159"
  },
  {
    "text": "their",
    "start": "234159",
    "end": "235480"
  },
  {
    "text": "core so this is where we come in we're",
    "start": "235480",
    "end": "238239"
  },
  {
    "text": "building uh these real time found models",
    "start": "238239",
    "end": "240480"
  },
  {
    "text": "so um some of what I'll talk about is uh",
    "start": "240480",
    "end": "243599"
  },
  {
    "text": "the work we've done in really building",
    "start": "243599",
    "end": "245760"
  },
  {
    "text": "kind of new ideas for how you can create",
    "start": "245760",
    "end": "249560"
  },
  {
    "text": "U deep learning models so um I did my",
    "start": "249560",
    "end": "252560"
  },
  {
    "text": "PhD before this I was working with a lot",
    "start": "252560",
    "end": "254360"
  },
  {
    "text": "of these folks from my PhD Chris was our",
    "start": "254360",
    "end": "256160"
  },
  {
    "text": "PhD adviser um and um we were really",
    "start": "256160",
    "end": "259359"
  },
  {
    "text": "focused on this idea that you should be",
    "start": "259359",
    "end": "260840"
  },
  {
    "text": "able to have a model that can compress",
    "start": "260840",
    "end": "262560"
  },
  {
    "text": "information as it comes into to the",
    "start": "262560",
    "end": "264320"
  },
  {
    "text": "model and um use that to really kind of",
    "start": "264320",
    "end": "267240"
  },
  {
    "text": "build powerful systems that are",
    "start": "267240",
    "end": "269199"
  },
  {
    "text": "streaming at their core um and I'll talk",
    "start": "269199",
    "end": "271479"
  },
  {
    "text": "a little bit about this but that's",
    "start": "271479",
    "end": "273240"
  },
  {
    "text": "really the technology that we've been",
    "start": "273240",
    "end": "274560"
  },
  {
    "text": "working with for the last four or five",
    "start": "274560",
    "end": "275880"
  },
  {
    "text": "years we've been developing Academia and",
    "start": "275880",
    "end": "278120"
  },
  {
    "text": "some of you might have heard of things",
    "start": "278120",
    "end": "279280"
  },
  {
    "text": "like Mamba which is sort of a a more",
    "start": "279280",
    "end": "281280"
  },
  {
    "text": "recent iteration of this technology you",
    "start": "281280",
    "end": "283320"
  },
  {
    "text": "know I did my PhD working on some of the",
    "start": "283320",
    "end": "286080"
  },
  {
    "text": "early iterations that nobody uses",
    "start": "286080",
    "end": "288039"
  },
  {
    "text": "anymore but um are sort of the",
    "start": "288039",
    "end": "289919"
  },
  {
    "text": "precursors to a lot of the modern stuff",
    "start": "289919",
    "end": "291840"
  },
  {
    "text": "that is now more widely used and uh and",
    "start": "291840",
    "end": "295080"
  },
  {
    "text": "now what we're doing at caria is",
    "start": "295080",
    "end": "296199"
  },
  {
    "text": "basically taking this and trying to",
    "start": "296199",
    "end": "297680"
  },
  {
    "text": "understand how we can improve it how do",
    "start": "297680",
    "end": "299240"
  },
  {
    "text": "we push the boundaries on what",
    "start": "299240",
    "end": "301120"
  },
  {
    "text": "architectures can do and um and I think",
    "start": "301120",
    "end": "303680"
  },
  {
    "text": "it's an interesting question because you",
    "start": "303680",
    "end": "305280"
  },
  {
    "text": "know we should not settle for having a",
    "start": "305280",
    "end": "308000"
  },
  {
    "text": "uh one way of doing things I think",
    "start": "308000",
    "end": "309520"
  },
  {
    "text": "that's sort of a a poor way to kind of",
    "start": "309520",
    "end": "312160"
  },
  {
    "text": "um think about the future so our",
    "start": "312160",
    "end": "314360"
  },
  {
    "text": "approach is sort of like let's think",
    "start": "314360",
    "end": "315680"
  },
  {
    "text": "about new ways of actually designing",
    "start": "315680",
    "end": "317400"
  },
  {
    "text": "models that aren't necessarily built on",
    "start": "317400",
    "end": "319680"
  },
  {
    "text": "let's say the Transformer architecture",
    "start": "319680",
    "end": "321039"
  },
  {
    "text": "and the standard recipe for deep",
    "start": "321039",
    "end": "322960"
  },
  {
    "text": "learning that's uh you know prevalent",
    "start": "322960",
    "end": "325800"
  },
  {
    "text": "today and I think it boils down to this",
    "start": "325800",
    "end": "328120"
  },
  {
    "text": "question of like efficiently modeling",
    "start": "328120",
    "end": "330080"
  },
  {
    "text": "long context is a huge problem because",
    "start": "330080",
    "end": "332720"
  },
  {
    "text": "you know a lot of practical data is",
    "start": "332720",
    "end": "334440"
  },
  {
    "text": "really long sequence data I think text",
    "start": "334440",
    "end": "336560"
  },
  {
    "text": "is maybe the least interesting U long",
    "start": "336560",
    "end": "338680"
  },
  {
    "text": "sequence data because text is actually",
    "start": "338680",
    "end": "340280"
  },
  {
    "text": "fairly uh compressed already right like",
    "start": "340280",
    "end": "342880"
  },
  {
    "text": "you have a lot of information that is uh",
    "start": "342880",
    "end": "345720"
  },
  {
    "text": "embedded in two minutes of uh or two",
    "start": "345720",
    "end": "348280"
  },
  {
    "text": "sentences of text but there's all these",
    "start": "348280",
    "end": "350520"
  },
  {
    "text": "other domains where you know audio video",
    "start": "350520",
    "end": "352400"
  },
  {
    "text": "Etc where there's so much information um",
    "start": "352400",
    "end": "354919"
  },
  {
    "text": "you know imagine looking at a security",
    "start": "354919",
    "end": "356360"
  },
  {
    "text": "camera for a day like you would probably",
    "start": "356360",
    "end": "358199"
  },
  {
    "text": "have just so much information coming",
    "start": "358199",
    "end": "359759"
  },
  {
    "text": "into the system and just um very little",
    "start": "359759",
    "end": "362680"
  },
  {
    "text": "of that would be useful so compression",
    "start": "362680",
    "end": "364199"
  },
  {
    "text": "is kind of really fundamental to",
    "start": "364199",
    "end": "365960"
  },
  {
    "text": "intelligence because we were able to do",
    "start": "365960",
    "end": "367520"
  },
  {
    "text": "this where we can look at all this",
    "start": "367520",
    "end": "369199"
  },
  {
    "text": "information and then sort of compress it",
    "start": "369199",
    "end": "371039"
  },
  {
    "text": "down to whatever is necessary to",
    "start": "371039",
    "end": "373160"
  },
  {
    "text": "remember or understand um and I think so",
    "start": "373160",
    "end": "376000"
  },
  {
    "text": "far what we've seen is that the AI",
    "start": "376000",
    "end": "377479"
  },
  {
    "text": "systems that we built have not",
    "start": "377479",
    "end": "379199"
  },
  {
    "text": "necessarily exhibited that same behavior",
    "start": "379199",
    "end": "381160"
  },
  {
    "text": "so they're really kind of built not on",
    "start": "381160",
    "end": "382800"
  },
  {
    "text": "the principles of compression but more",
    "start": "382800",
    "end": "384400"
  },
  {
    "text": "on this idea of retrieval like keeping",
    "start": "384400",
    "end": "386440"
  },
  {
    "text": "all the context around and then using it",
    "start": "386440",
    "end": "388039"
  },
  {
    "text": "to reason over all the information that",
    "start": "388039",
    "end": "389880"
  },
  {
    "text": "you've seen so I think um our kind of",
    "start": "389880",
    "end": "392759"
  },
  {
    "text": "point of view is that multimodal AI will",
    "start": "392759",
    "end": "395080"
  },
  {
    "text": "remain challenging as as long as you're",
    "start": "395080",
    "end": "396800"
  },
  {
    "text": "sort of working in this Paradigm because",
    "start": "396800",
    "end": "399120"
  },
  {
    "text": "uh if you try to think about what humans",
    "start": "399120",
    "end": "400840"
  },
  {
    "text": "do in a year um you're basically",
    "start": "400840",
    "end": "403560"
  },
  {
    "text": "processing understanding about a billion",
    "start": "403560",
    "end": "405680"
  },
  {
    "text": "text tokens 10 billion audio tokens",
    "start": "405680",
    "end": "408479"
  },
  {
    "text": "these are you know back of the envelope",
    "start": "408479",
    "end": "409880"
  },
  {
    "text": "calculations that I did and about a",
    "start": "409880",
    "end": "411680"
  },
  {
    "text": "trillion video tokens probably",
    "start": "411680",
    "end": "413120"
  },
  {
    "text": "underestimates how much video we process",
    "start": "413120",
    "end": "415440"
  },
  {
    "text": "and not including all the other sensory",
    "start": "415440",
    "end": "417240"
  },
  {
    "text": "information that you're processing and",
    "start": "417240",
    "end": "418919"
  },
  {
    "text": "you're doing it simultaneously and",
    "start": "418919",
    "end": "420759"
  },
  {
    "text": "you're doing it on a computer that fits",
    "start": "420759",
    "end": "422319"
  },
  {
    "text": "in your brain um and you you know",
    "start": "422319",
    "end": "424639"
  },
  {
    "text": "sometimes don't eat and drink and you",
    "start": "424639",
    "end": "426319"
  },
  {
    "text": "know you're still functioning fine so",
    "start": "426319",
    "end": "428440"
  },
  {
    "text": "you know you can have variable amounts",
    "start": "428440",
    "end": "430479"
  },
  {
    "text": "of power in the system um so I think the",
    "start": "430479",
    "end": "433639"
  },
  {
    "text": "idea that like intelligence is solved is",
    "start": "433639",
    "end": "435680"
  },
  {
    "text": "sort of very far from the truth because",
    "start": "435680",
    "end": "437560"
  },
  {
    "text": "humans just are an extremely amazing",
    "start": "437560",
    "end": "440440"
  },
  {
    "text": "machine that does something very",
    "start": "440440",
    "end": "442360"
  },
  {
    "text": "extraordinary um in a very compressed",
    "start": "442360",
    "end": "444680"
  },
  {
    "text": "way that um our AI models can do so I",
    "start": "444680",
    "end": "447840"
  },
  {
    "text": "think that's sort of our uh you know",
    "start": "447840",
    "end": "450000"
  },
  {
    "text": "sort of uh the reason we get up in the",
    "start": "450000",
    "end": "451759"
  },
  {
    "text": "morning is we think about this and we're",
    "start": "451759",
    "end": "453199"
  },
  {
    "text": "like yeah we're very far away from where",
    "start": "453199",
    "end": "454960"
  },
  {
    "text": "we should be um and the best models",
    "start": "454960",
    "end": "457919"
  },
  {
    "text": "today are in the you know 10 million 100",
    "start": "457919",
    "end": "460039"
  },
  {
    "text": "million sort of token range so U that's",
    "start": "460039",
    "end": "462400"
  },
  {
    "text": "really good a lot of progress has been",
    "start": "462400",
    "end": "464080"
  },
  {
    "text": "made but really this is sort of what we",
    "start": "464080",
    "end": "465680"
  },
  {
    "text": "aspired to is how do you kind of build",
    "start": "465680",
    "end": "467159"
  },
  {
    "text": "these machines that are long lived that",
    "start": "467159",
    "end": "468960"
  },
  {
    "text": "can actually understand information over",
    "start": "468960",
    "end": "471240"
  },
  {
    "text": "very long periods of time and I think",
    "start": "471240",
    "end": "472960"
  },
  {
    "text": "the cool thing is like as a human you",
    "start": "472960",
    "end": "474759"
  },
  {
    "text": "can remember things that happened 30",
    "start": "474759",
    "end": "476479"
  },
  {
    "text": "years ago with very little effort you",
    "start": "476479",
    "end": "477960"
  },
  {
    "text": "don't need to do rag retrieval or",
    "start": "477960",
    "end": "480199"
  },
  {
    "text": "anything you just you know you remember",
    "start": "480199",
    "end": "481680"
  },
  {
    "text": "it it's GED in your brain and then you",
    "start": "481680",
    "end": "483639"
  },
  {
    "text": "figure it out basically so I think",
    "start": "483639",
    "end": "485680"
  },
  {
    "text": "that's kind of an extraordinary",
    "start": "485680",
    "end": "486840"
  },
  {
    "text": "capability that we should be able to put",
    "start": "486840",
    "end": "488960"
  },
  {
    "text": "into our AI models as",
    "start": "488960",
    "end": "492240"
  },
  {
    "text": "well and so some of the big problems",
    "start": "492240",
    "end": "494680"
  },
  {
    "text": "with models today are U you know they're",
    "start": "494680",
    "end": "496560"
  },
  {
    "text": "built on Transformers really optimized",
    "start": "496560",
    "end": "498319"
  },
  {
    "text": "for data center I think um we see this",
    "start": "498319",
    "end": "501000"
  },
  {
    "text": "with like a lot of the work we did which",
    "start": "501000",
    "end": "502400"
  },
  {
    "text": "was on sub quadratic models so quadratic",
    "start": "502400",
    "end": "504800"
  },
  {
    "text": "scaling and context length really just",
    "start": "504800",
    "end": "506400"
  },
  {
    "text": "means that um you know the amount of uh",
    "start": "506400",
    "end": "508800"
  },
  {
    "text": "computation have to do to process long",
    "start": "508800",
    "end": "511280"
  },
  {
    "text": "amounts of uh context is very large and",
    "start": "511280",
    "end": "513518"
  },
  {
    "text": "so right now the sort of predominant",
    "start": "513519",
    "end": "515360"
  },
  {
    "text": "approach is to throw compute at that",
    "start": "515360",
    "end": "516839"
  },
  {
    "text": "problem and then hope that that would",
    "start": "516839",
    "end": "518560"
  },
  {
    "text": "scale um obviously compute is a very",
    "start": "518560",
    "end": "520640"
  },
  {
    "text": "important piece of the puzzle because",
    "start": "520640",
    "end": "522120"
  },
  {
    "text": "you do need more computation to be able",
    "start": "522120",
    "end": "523800"
  },
  {
    "text": "to do more difficult things but um this",
    "start": "523800",
    "end": "526640"
  },
  {
    "text": "type of approach because of the",
    "start": "526640",
    "end": "527760"
  },
  {
    "text": "quadratic scaling actually has Poe",
    "start": "527760",
    "end": "529440"
  },
  {
    "text": "scaling with you know very large",
    "start": "529440",
    "end": "530800"
  },
  {
    "text": "multimodo context and text context tend",
    "start": "530800",
    "end": "533399"
  },
  {
    "text": "to be shorter multimodal context will",
    "start": "533399",
    "end": "535519"
  },
  {
    "text": "get larger because you have just way",
    "start": "535519",
    "end": "537120"
  },
  {
    "text": "more tokens and information that's going",
    "start": "537120",
    "end": "538720"
  },
  {
    "text": "into the system so that's going to be a",
    "start": "538720",
    "end": "540279"
  },
  {
    "text": "big challenge for these models",
    "start": "540279",
    "end": "541720"
  },
  {
    "text": "especially how do you do this inference",
    "start": "541720",
    "end": "543360"
  },
  {
    "text": "efficiently so you're not you know",
    "start": "543360",
    "end": "544920"
  },
  {
    "text": "Burning Down the data centers to you",
    "start": "544920",
    "end": "547079"
  },
  {
    "text": "know do uh a fairly limited amount of",
    "start": "547079",
    "end": "549360"
  },
  {
    "text": "inference like you have to imagine that",
    "start": "549360",
    "end": "550800"
  },
  {
    "text": "we're doing a thousand times or um you",
    "start": "550800",
    "end": "553040"
  },
  {
    "text": "know 100 thousand times more inference",
    "start": "553040",
    "end": "554839"
  },
  {
    "text": "and then um if the models are scaling",
    "start": "554839",
    "end": "557040"
  },
  {
    "text": "the same way it's going to be really",
    "start": "557040",
    "end": "558200"
  },
  {
    "text": "really really expensive so you're not",
    "start": "558200",
    "end": "559480"
  },
  {
    "text": "going to be able to permeate all these",
    "start": "559480",
    "end": "560760"
  },
  {
    "text": "applications that I talked about very",
    "start": "560760",
    "end": "562360"
  },
  {
    "text": "easily um and so you know that's sort of",
    "start": "562360",
    "end": "564760"
  },
  {
    "text": "a big challenge I would",
    "start": "564760",
    "end": "566600"
  },
  {
    "text": "say and so you know again our hypothesis",
    "start": "566600",
    "end": "569120"
  },
  {
    "text": "is you need new architectures and that's",
    "start": "569120",
    "end": "570680"
  },
  {
    "text": "kind of where we spend our time and we",
    "start": "570680",
    "end": "571920"
  },
  {
    "text": "want to make these models more efficient",
    "start": "571920",
    "end": "573360"
  },
  {
    "text": "faster more capable while being able to",
    "start": "573360",
    "end": "575399"
  },
  {
    "text": "handle all these long context problems",
    "start": "575399",
    "end": "577800"
  },
  {
    "text": "um this is a slide about you know",
    "start": "577800",
    "end": "579720"
  },
  {
    "text": "Transformers being somewhat inefficient",
    "start": "579720",
    "end": "581320"
  },
  {
    "text": "at handling this um but obviously um a",
    "start": "581320",
    "end": "584120"
  },
  {
    "text": "very good recipe for scaling uh uh these",
    "start": "584120",
    "end": "586519"
  },
  {
    "text": "models",
    "start": "586519",
    "end": "587800"
  },
  {
    "text": "out and so you know some of the work",
    "start": "587800",
    "end": "589959"
  },
  {
    "text": "that we've been doing is new",
    "start": "589959",
    "end": "591160"
  },
  {
    "text": "fundamentally efficient architectures so",
    "start": "591160",
    "end": "593600"
  },
  {
    "text": "they have compression at their core so",
    "start": "593600",
    "end": "595440"
  },
  {
    "text": "they sort of the way they operate I I",
    "start": "595440",
    "end": "597600"
  },
  {
    "text": "have a slide on this just to give you",
    "start": "597600",
    "end": "598959"
  },
  {
    "text": "kind of",
    "start": "598959",
    "end": "600200"
  },
  {
    "text": "a quick illustration but um they really",
    "start": "600200",
    "end": "602640"
  },
  {
    "text": "scaled more linearly in context lens so",
    "start": "602640",
    "end": "605079"
  },
  {
    "text": "you should be able to have uh because of",
    "start": "605079",
    "end": "607480"
  },
  {
    "text": "this like more low power implementations",
    "start": "607480",
    "end": "609680"
  },
  {
    "text": "of these models um you can compress",
    "start": "609680",
    "end": "612240"
  },
  {
    "text": "information as it comes into the system",
    "start": "612240",
    "end": "613839"
  },
  {
    "text": "you have low memory usage um and you can",
    "start": "613839",
    "end": "616160"
  },
  {
    "text": "actually scale to much more massive",
    "start": "616160",
    "end": "617600"
  },
  {
    "text": "context because of",
    "start": "617600",
    "end": "620120"
  },
  {
    "text": "that um and this is all the work around",
    "start": "620120",
    "end": "622640"
  },
  {
    "text": "ssms I just threw this nice slide which",
    "start": "622640",
    "end": "625440"
  },
  {
    "text": "I thought was cool um Jensen had an",
    "start": "625440",
    "end": "627519"
  },
  {
    "text": "interesting quote about ssms in one of",
    "start": "627519",
    "end": "629360"
  },
  {
    "text": "his wired articles that I like to keep",
    "start": "629360",
    "end": "631240"
  },
  {
    "text": "talking about but uh uh but I think it's",
    "start": "631240",
    "end": "633200"
  },
  {
    "text": "a cool technology that has a lot of",
    "start": "633200",
    "end": "634839"
  },
  {
    "text": "potential and sort of that's where we're",
    "start": "634839",
    "end": "636800"
  },
  {
    "text": "um spending a lot of our time and if you",
    "start": "636800",
    "end": "638399"
  },
  {
    "text": "folks are interested in Reading More",
    "start": "638399",
    "end": "640240"
  },
  {
    "text": "there's lots of videos on YouTube and",
    "start": "640240",
    "end": "641880"
  },
  {
    "text": "lots of sort of resources that try to",
    "start": "641880",
    "end": "643600"
  },
  {
    "text": "make this more accessible to understand",
    "start": "643600",
    "end": "645160"
  },
  {
    "text": "and and kind of get into some of the",
    "start": "645160",
    "end": "646920"
  },
  {
    "text": "details um but you know the working",
    "start": "646920",
    "end": "648920"
  },
  {
    "text": "intuition is basically Transformers are",
    "start": "648920",
    "end": "651320"
  },
  {
    "text": "generating quadratically by attending to",
    "start": "651320",
    "end": "653160"
  },
  {
    "text": "every past token of information so as",
    "start": "653160",
    "end": "655360"
  },
  {
    "text": "tokens come into the system you're sort",
    "start": "655360",
    "end": "656920"
  },
  {
    "text": "of keeping them around and then looking",
    "start": "656920",
    "end": "658720"
  },
  {
    "text": "at all the pass token so if you want to",
    "start": "658720",
    "end": "660240"
  },
  {
    "text": "generate the word jumped uh from the",
    "start": "660240",
    "end": "662279"
  },
  {
    "text": "quick brown fox you would actually look",
    "start": "662279",
    "end": "663680"
  },
  {
    "text": "at the entire context try to understand",
    "start": "663680",
    "end": "665800"
  },
  {
    "text": "what the next word should be and then um",
    "start": "665800",
    "end": "668200"
  },
  {
    "text": "generate it push it into the context do",
    "start": "668200",
    "end": "670240"
  },
  {
    "text": "it again uh with ssms you just have a",
    "start": "670240",
    "end": "672440"
  },
  {
    "text": "streaming system so you you have a to",
    "start": "672440",
    "end": "674320"
  },
  {
    "text": "token stream in uh they update an",
    "start": "674320",
    "end": "676880"
  },
  {
    "text": "internal memory for the model and then",
    "start": "676880",
    "end": "678560"
  },
  {
    "text": "the token gets thrown away so that",
    "start": "678560",
    "end": "680000"
  },
  {
    "text": "actually really simplifies the system",
    "start": "680000",
    "end": "681560"
  },
  {
    "text": "and that's why it's such a core sort of",
    "start": "681560",
    "end": "683279"
  },
  {
    "text": "streaming interface because you're just",
    "start": "683279",
    "end": "684800"
  },
  {
    "text": "not keeping all this memory around about",
    "start": "684800",
    "end": "687000"
  },
  {
    "text": "what happened in the past you're",
    "start": "687000",
    "end": "688200"
  },
  {
    "text": "compressing it into something sort of",
    "start": "688200",
    "end": "689880"
  },
  {
    "text": "zipped file uh State inside the model",
    "start": "689880",
    "end": "692360"
  },
  {
    "text": "that's going to be used to do future",
    "start": "692360",
    "end": "695440"
  },
  {
    "text": "generation and so this is sort of taking",
    "start": "695440",
    "end": "697519"
  },
  {
    "text": "this idea of uh taking advantage of this",
    "start": "697519",
    "end": "699399"
  },
  {
    "text": "idea of recurrence which is sort of core",
    "start": "699399",
    "end": "701480"
  },
  {
    "text": "to how even humans do a lot of their",
    "start": "701480",
    "end": "704519"
  },
  {
    "text": "raising and you know last few months a",
    "start": "704519",
    "end": "707000"
  },
  {
    "text": "lot of these models have been getting",
    "start": "707000",
    "end": "708360"
  },
  {
    "text": "adopted so it's great that you know a",
    "start": "708360",
    "end": "710240"
  },
  {
    "text": "lot of folks are now excited about the",
    "start": "710240",
    "end": "712800"
  },
  {
    "text": "uh this you know alternate way of doing",
    "start": "712800",
    "end": "714480"
  },
  {
    "text": "things that is much more uh sort of",
    "start": "714480",
    "end": "717800"
  },
  {
    "text": "oriented around this idea of recurr",
    "start": "717800",
    "end": "719200"
  },
  {
    "text": "returns rather than um retrieval um and",
    "start": "719200",
    "end": "721720"
  },
  {
    "text": "so I think like we'll see a lot more",
    "start": "721720",
    "end": "723360"
  },
  {
    "text": "activity in this especially multimodal",
    "start": "723360",
    "end": "725360"
  },
  {
    "text": "data becoming more important and uh you",
    "start": "725360",
    "end": "727600"
  },
  {
    "text": "know a lot of the challenges multimodel",
    "start": "727600",
    "end": "729160"
  },
  {
    "text": "data around efficiency will mean that I",
    "start": "729160",
    "end": "731040"
  },
  {
    "text": "think that these models will have more",
    "start": "731040",
    "end": "732760"
  },
  {
    "text": "of a role to play in the next three to",
    "start": "732760",
    "end": "734240"
  },
  {
    "text": "five years um as we also do our work in",
    "start": "734240",
    "end": "737120"
  },
  {
    "text": "uh scaling them up and making them more",
    "start": "737120",
    "end": "738880"
  },
  {
    "text": "interesting a lot of people ask me about",
    "start": "738880",
    "end": "740320"
  },
  {
    "text": "quality uh I only have a few minutes so",
    "start": "740320",
    "end": "742360"
  },
  {
    "text": "I'll go through this the rest of the",
    "start": "742360",
    "end": "743760"
  },
  {
    "text": "slide super fast but um you know ssms",
    "start": "743760",
    "end": "747480"
  },
  {
    "text": "generally have the right uh quality",
    "start": "747480",
    "end": "749480"
  },
  {
    "text": "obviously there's a trade-off between",
    "start": "749480",
    "end": "750760"
  },
  {
    "text": "compression and keeping all the",
    "start": "750760",
    "end": "752399"
  },
  {
    "text": "information around but actually like",
    "start": "752399",
    "end": "755240"
  },
  {
    "text": "compression can be helpful so if you",
    "start": "755240",
    "end": "756880"
  },
  {
    "text": "imagine the security camera example if",
    "start": "756880",
    "end": "758519"
  },
  {
    "text": "you're watching 24 hours of footage",
    "start": "758519",
    "end": "760240"
  },
  {
    "text": "actually compressing all that",
    "start": "760240",
    "end": "761480"
  },
  {
    "text": "information on the fly would help you",
    "start": "761480",
    "end": "763000"
  },
  {
    "text": "solve tasks and answer questions better",
    "start": "763000",
    "end": "765600"
  },
  {
    "text": "rather than looking at all 24 hours",
    "start": "765600",
    "end": "767399"
  },
  {
    "text": "every time so I think that's sort of the",
    "start": "767399",
    "end": "768920"
  },
  {
    "text": "rule of thumb to think about which is",
    "start": "768920",
    "end": "770360"
  },
  {
    "text": "compression super helpful for a large",
    "start": "770360",
    "end": "771959"
  },
  {
    "text": "context um not as helpful for um short",
    "start": "771959",
    "end": "774839"
  },
  {
    "text": "context and so we see that quality",
    "start": "774839",
    "end": "776800"
  },
  {
    "text": "actually is very good for long context",
    "start": "776800",
    "end": "778639"
  },
  {
    "text": "problems and and multimodal problems let",
    "start": "778639",
    "end": "781279"
  },
  {
    "text": "me talk quickly about some of the work",
    "start": "781279",
    "end": "782519"
  },
  {
    "text": "we've been doing so we've been starting",
    "start": "782519",
    "end": "783880"
  },
  {
    "text": "to work on sort of multimodal data and",
    "start": "783880",
    "end": "786040"
  },
  {
    "text": "we did a release a few weeks ago for a",
    "start": "786040",
    "end": "788560"
  },
  {
    "text": "voice generation model so this is sort",
    "start": "788560",
    "end": "790079"
  },
  {
    "text": "of text to speech and sort of in line",
    "start": "790079",
    "end": "791959"
  },
  {
    "text": "with some of the work we're doing to",
    "start": "791959",
    "end": "793279"
  },
  {
    "text": "bring more multimodel uh data into a",
    "start": "793279",
    "end": "795720"
  },
  {
    "text": "single model um and use ssms to power",
    "start": "795720",
    "end": "799120"
  },
  {
    "text": "the inference and the training and and",
    "start": "799120",
    "end": "800680"
  },
  {
    "text": "so on so this is a model you can",
    "start": "800680",
    "end": "802440"
  },
  {
    "text": "actually play with I'll try to show you",
    "start": "802440",
    "end": "803760"
  },
  {
    "text": "a demo but um one of the things we're",
    "start": "803760",
    "end": "806160"
  },
  {
    "text": "proudest off with this model is that we",
    "start": "806160",
    "end": "807760"
  },
  {
    "text": "really Shrunk The latency down so so",
    "start": "807760",
    "end": "809199"
  },
  {
    "text": "when you play with it on the playground",
    "start": "809199",
    "end": "810839"
  },
  {
    "text": "you get instant voice back generated",
    "start": "810839",
    "end": "812680"
  },
  {
    "text": "from the data center and there's some",
    "start": "812680",
    "end": "814199"
  },
  {
    "text": "cool work we're doing to actually run",
    "start": "814199",
    "end": "815600"
  },
  {
    "text": "these models on Mac um and other devices",
    "start": "815600",
    "end": "818760"
  },
  {
    "text": "so that you can basically have the same",
    "start": "818760",
    "end": "820240"
  },
  {
    "text": "experience as you have in the data",
    "start": "820240",
    "end": "821440"
  },
  {
    "text": "center but on any device and and do that",
    "start": "821440",
    "end": "823880"
  },
  {
    "text": "efficiently and at low power how much",
    "start": "823880",
    "end": "825680"
  },
  {
    "text": "time do I have okay we're out of time",
    "start": "825680",
    "end": "828680"
  },
  {
    "text": "but I was also almost done so um go to",
    "start": "828680",
    "end": "832079"
  },
  {
    "text": "the website play. AI I unfortunately",
    "start": "832079",
    "end": "834480"
  },
  {
    "text": "couldn't walk through the demo but um",
    "start": "834480",
    "end": "836360"
  },
  {
    "text": "play with it and um send us feedback",
    "start": "836360",
    "end": "838440"
  },
  {
    "text": "this is my email in case you want to",
    "start": "838440",
    "end": "840160"
  },
  {
    "text": "send me a note would love to hear",
    "start": "840160",
    "end": "841720"
  },
  {
    "text": "feedback and anything that you folks uh",
    "start": "841720",
    "end": "843880"
  },
  {
    "text": "find interesting thank you",
    "start": "843880",
    "end": "848360"
  },
  {
    "text": "[Music]",
    "start": "850410",
    "end": "867350"
  }
]
[
  {
    "text": "[Music]",
    "start": "1040",
    "end": "13859"
  },
  {
    "text": "hi everyone I'm Emanuel CEO of sematic",
    "start": "17400",
    "end": "21359"
  },
  {
    "text": "the company behind air train today I",
    "start": "21359",
    "end": "24240"
  },
  {
    "text": "want to talk about a difficult problem",
    "start": "24240",
    "end": "26080"
  },
  {
    "text": "in the language modeling space and that",
    "start": "26080",
    "end": "28080"
  },
  {
    "text": "is",
    "start": "28080",
    "end": "28960"
  },
  {
    "text": "evaluation unlike in other areas of",
    "start": "28960",
    "end": "31599"
  },
  {
    "text": "machine learning it is not so",
    "start": "31599",
    "end": "33399"
  },
  {
    "text": "straightforward to evaluate language",
    "start": "33399",
    "end": "35239"
  },
  {
    "text": "models for a specific use case there are",
    "start": "35239",
    "end": "38280"
  },
  {
    "text": "metrics and benchmarks but they mostly",
    "start": "38280",
    "end": "41039"
  },
  {
    "text": "apply to generic tasks and there is no",
    "start": "41039",
    "end": "43399"
  },
  {
    "text": "one-size fit so process to evaluate the",
    "start": "43399",
    "end": "45719"
  },
  {
    "text": "performance of a model for a particular",
    "start": "45719",
    "end": "47480"
  },
  {
    "text": "use",
    "start": "47480",
    "end": "48559"
  },
  {
    "text": "case so first let's get the basics out",
    "start": "48559",
    "end": "51440"
  },
  {
    "text": "of the way what is model",
    "start": "51440",
    "end": "53680"
  },
  {
    "text": "evaluation model evaluation is the",
    "start": "53680",
    "end": "56239"
  },
  {
    "text": "statistical measurement of the",
    "start": "56239",
    "end": "57760"
  },
  {
    "text": "performance of a machine learning model",
    "start": "57760",
    "end": "60160"
  },
  {
    "text": "how well does a model perform on a",
    "start": "60160",
    "end": "62120"
  },
  {
    "text": "particular use case measured on a large",
    "start": "62120",
    "end": "64600"
  },
  {
    "text": "data set independent from the training",
    "start": "64600",
    "end": "66360"
  },
  {
    "text": "data",
    "start": "66360",
    "end": "67360"
  },
  {
    "text": "set model evaluation usually comes right",
    "start": "67360",
    "end": "70560"
  },
  {
    "text": "after training or fine-tuning and is a",
    "start": "70560",
    "end": "72880"
  },
  {
    "text": "crucial part of model development all ml",
    "start": "72880",
    "end": "75880"
  },
  {
    "text": "teams dedicate large resources to",
    "start": "75880",
    "end": "77759"
  },
  {
    "text": "establish rigorous evaluation procedures",
    "start": "77759",
    "end": "80560"
  },
  {
    "text": "you need to set up a solid evaluation",
    "start": "80560",
    "end": "83040"
  },
  {
    "text": "process as part of your development",
    "start": "83040",
    "end": "84640"
  },
  {
    "text": "workflow to guarantee performance and",
    "start": "84640",
    "end": "86840"
  },
  {
    "text": "safety you can compare evaluation to",
    "start": "86840",
    "end": "89400"
  },
  {
    "text": "running a test Suite in your continuous",
    "start": "89400",
    "end": "91400"
  },
  {
    "text": "integration",
    "start": "91400",
    "end": "92560"
  },
  {
    "text": "pipeline in traditional supervised",
    "start": "92560",
    "end": "94880"
  },
  {
    "text": "machine learning there is a whole host",
    "start": "94880",
    "end": "96720"
  },
  {
    "text": "of well-defined metrics to clearly grade",
    "start": "96720",
    "end": "99040"
  },
  {
    "text": "A model's",
    "start": "99040",
    "end": "100200"
  },
  {
    "text": "performance for example for regressions",
    "start": "100200",
    "end": "103479"
  },
  {
    "text": "we have the root mean squared error or",
    "start": "103479",
    "end": "105960"
  },
  {
    "text": "the mean absolute error for classifiers",
    "start": "105960",
    "end": "109960"
  },
  {
    "text": "people usually use Precision recall or",
    "start": "109960",
    "end": "113320"
  },
  {
    "text": "F1 score and so on in computer vision a",
    "start": "113320",
    "end": "117520"
  },
  {
    "text": "popular metric is the intersection of",
    "start": "117520",
    "end": "120200"
  },
  {
    "text": "Union so what metrics are available to",
    "start": "120200",
    "end": "122799"
  },
  {
    "text": "score language",
    "start": "122799",
    "end": "124680"
  },
  {
    "text": "models well unlike other types of models",
    "start": "124680",
    "end": "127479"
  },
  {
    "text": "returning structured outputs such as a",
    "start": "127479",
    "end": "129599"
  },
  {
    "text": "number a class or a bounding box",
    "start": "129599",
    "end": "132760"
  },
  {
    "text": "language models generate text which is",
    "start": "132760",
    "end": "135040"
  },
  {
    "text": "very unstructured an inference that is",
    "start": "135040",
    "end": "137800"
  },
  {
    "text": "different from the ground truth",
    "start": "137800",
    "end": "139120"
  },
  {
    "text": "reference is not necessarily",
    "start": "139120",
    "end": "141200"
  },
  {
    "text": "incorrect depending on whether you have",
    "start": "141200",
    "end": "143360"
  },
  {
    "text": "access to labeled references there are a",
    "start": "143360",
    "end": "145760"
  },
  {
    "text": "number of metrics you can use for",
    "start": "145760",
    "end": "148120"
  },
  {
    "text": "example blue is a precision based metric",
    "start": "148120",
    "end": "151400"
  },
  {
    "text": "it measures the overlap between engrams",
    "start": "151400",
    "end": "154239"
  },
  {
    "text": "that is sequences of tokens between the",
    "start": "154239",
    "end": "156760"
  },
  {
    "text": "generated text and the inference it's a",
    "start": "156760",
    "end": "159720"
  },
  {
    "text": "common metric to evaluate translation",
    "start": "159720",
    "end": "161879"
  },
  {
    "text": "between two languages and can also be",
    "start": "161879",
    "end": "163800"
  },
  {
    "text": "used to score",
    "start": "163800",
    "end": "165239"
  },
  {
    "text": "summarization it can definitely serve as",
    "start": "165239",
    "end": "167440"
  },
  {
    "text": "a good Benchmark but it is not a safe",
    "start": "167440",
    "end": "169840"
  },
  {
    "text": "indicator of how a model will perform on",
    "start": "169840",
    "end": "171800"
  },
  {
    "text": "your particular task for example it does",
    "start": "171800",
    "end": "174720"
  },
  {
    "text": "not take into account intelligibility or",
    "start": "174720",
    "end": "177239"
  },
  {
    "text": "grammatical correctness Rouge is a set",
    "start": "177239",
    "end": "180360"
  },
  {
    "text": "of evaluation metrics that focuses on",
    "start": "180360",
    "end": "182560"
  },
  {
    "text": "measuring the recall of sequences of",
    "start": "182560",
    "end": "184920"
  },
  {
    "text": "tokens between references and the",
    "start": "184920",
    "end": "187799"
  },
  {
    "text": "inference it is mostly useful to",
    "start": "187799",
    "end": "190319"
  },
  {
    "text": "evaluate for",
    "start": "190319",
    "end": "191799"
  },
  {
    "text": "summarization if you don't have access",
    "start": "191799",
    "end": "193959"
  },
  {
    "text": "to labeled references you can use other",
    "start": "193959",
    "end": "196480"
  },
  {
    "text": "Standalone",
    "start": "196480",
    "end": "197640"
  },
  {
    "text": "metrics for example density quantifies",
    "start": "197640",
    "end": "201159"
  },
  {
    "text": "how well the summary represents pool",
    "start": "201159",
    "end": "203000"
  },
  {
    "text": "fragments from the text and coverage",
    "start": "203000",
    "end": "205799"
  },
  {
    "text": "quantifies the extent to which a summary",
    "start": "205799",
    "end": "207879"
  },
  {
    "text": "is derivative of a text",
    "start": "207879",
    "end": "210360"
  },
  {
    "text": "as you can see these metrics are only",
    "start": "210360",
    "end": "212159"
  },
  {
    "text": "useful to score certain high level tasks",
    "start": "212159",
    "end": "215040"
  },
  {
    "text": "such as translations and",
    "start": "215040",
    "end": "217640"
  },
  {
    "text": "summarization there are also a number of",
    "start": "217640",
    "end": "220159"
  },
  {
    "text": "benchmarks and leader boards that rank",
    "start": "220159",
    "end": "222319"
  },
  {
    "text": "various models benchmarks are",
    "start": "222319",
    "end": "225040"
  },
  {
    "text": "standardized test that's score model",
    "start": "225040",
    "end": "226920"
  },
  {
    "text": "performance for certain tasks for",
    "start": "226920",
    "end": "229560"
  },
  {
    "text": "example glue or general language",
    "start": "229560",
    "end": "232879"
  },
  {
    "text": "understanding evaluation is a common",
    "start": "232879",
    "end": "234640"
  },
  {
    "text": "Benchmark to evaluate how well a model",
    "start": "234640",
    "end": "237560"
  },
  {
    "text": "understands language through a series of",
    "start": "237560",
    "end": "239760"
  },
  {
    "text": "nine tasks for example paraphrase",
    "start": "239760",
    "end": "243280"
  },
  {
    "text": "detection and sentiment",
    "start": "243280",
    "end": "245840"
  },
  {
    "text": "analysis helis swag measures natural",
    "start": "245840",
    "end": "248599"
  },
  {
    "text": "language inference which is the ability",
    "start": "248599",
    "end": "250760"
  },
  {
    "text": "for a model to have common sense and",
    "start": "250760",
    "end": "253120"
  },
  {
    "text": "find the most plausible end to a",
    "start": "253120",
    "end": "255519"
  },
  {
    "text": "sentence in this case answer C is the",
    "start": "255519",
    "end": "258359"
  },
  {
    "text": "most reasonable Choice there are other",
    "start": "258359",
    "end": "260959"
  },
  {
    "text": "benchmarks such as trivia QA which asks",
    "start": "260959",
    "end": "264400"
  },
  {
    "text": "almost a million trivia questions from",
    "start": "264400",
    "end": "266240"
  },
  {
    "text": "Wikipedia and other sources and tests",
    "start": "266240",
    "end": "268840"
  },
  {
    "text": "the knowledge of the model also Arc",
    "start": "268840",
    "end": "272000"
  },
  {
    "text": "tests model's ability to reason about",
    "start": "272000",
    "end": "274120"
  },
  {
    "text": "high school level science questions and",
    "start": "274120",
    "end": "276639"
  },
  {
    "text": "there are dozens more benchmarks out",
    "start": "276639",
    "end": "278639"
  },
  {
    "text": "there all these metrics and benchmarks",
    "start": "278639",
    "end": "281440"
  },
  {
    "text": "are very useful to draw a landscape of",
    "start": "281440",
    "end": "283600"
  },
  {
    "text": "how llms compare to one",
    "start": "283600",
    "end": "285600"
  },
  {
    "text": "another but they do not tell you how",
    "start": "285600",
    "end": "287880"
  },
  {
    "text": "they perform for your particular task on",
    "start": "287880",
    "end": "290199"
  },
  {
    "text": "the type of input data that will be fed",
    "start": "290199",
    "end": "292400"
  },
  {
    "text": "by your",
    "start": "292400",
    "end": "293360"
  },
  {
    "text": "application for example if you're trying",
    "start": "293360",
    "end": "295880"
  },
  {
    "text": "to extract symptoms from a doctor's",
    "start": "295880",
    "end": "298039"
  },
  {
    "text": "notes or extract ract ingredients from a",
    "start": "298039",
    "end": "301000"
  },
  {
    "text": "recipe or form a Chas and payload to",
    "start": "301000",
    "end": "303600"
  },
  {
    "text": "query an API these metrics will not tell",
    "start": "303600",
    "end": "306520"
  },
  {
    "text": "you how each model performs so each",
    "start": "306520",
    "end": "309560"
  },
  {
    "text": "application needs to come up with its",
    "start": "309560",
    "end": "311320"
  },
  {
    "text": "own evaluation procedure which is a lot",
    "start": "311320",
    "end": "313680"
  },
  {
    "text": "of work there is one magic trick though",
    "start": "313680",
    "end": "317560"
  },
  {
    "text": "you can use another model to grade the",
    "start": "317560",
    "end": "320520"
  },
  {
    "text": "output of your",
    "start": "320520",
    "end": "321759"
  },
  {
    "text": "model you can describe to nlm what",
    "start": "321759",
    "end": "324400"
  },
  {
    "text": "you're trying to accomplish and what are",
    "start": "324400",
    "end": "326280"
  },
  {
    "text": "the grading criteria and ask it to grade",
    "start": "326280",
    "end": "329039"
  },
  {
    "text": "the out of another llm on a numerical",
    "start": "329039",
    "end": "332039"
  },
  {
    "text": "scale essentially you are crafting your",
    "start": "332039",
    "end": "335120"
  },
  {
    "text": "own specialized metrics for your own",
    "start": "335120",
    "end": "337639"
  },
  {
    "text": "application here's an example of how it",
    "start": "337639",
    "end": "339880"
  },
  {
    "text": "works you can feed your evaluation data",
    "start": "339880",
    "end": "342600"
  },
  {
    "text": "set to the model you want to evaluate",
    "start": "342600",
    "end": "344720"
  },
  {
    "text": "which is going to generate the",
    "start": "344720",
    "end": "345720"
  },
  {
    "text": "inferences that you want to score then",
    "start": "345720",
    "end": "348759"
  },
  {
    "text": "you can include those inferences inside",
    "start": "348759",
    "end": "350960"
  },
  {
    "text": "a broader scoring prompt in which you've",
    "start": "350960",
    "end": "353840"
  },
  {
    "text": "described the task you're trying to",
    "start": "353840",
    "end": "355600"
  },
  {
    "text": "accomplish and the properties you're",
    "start": "355600",
    "end": "356840"
  },
  {
    "text": "trying to grade and also you described",
    "start": "356840",
    "end": "359400"
  },
  {
    "text": "the the scale across which it should be",
    "start": "359400",
    "end": "361479"
  },
  {
    "text": "graded for example from 1 to 10 then you",
    "start": "361479",
    "end": "364639"
  },
  {
    "text": "pass this scoring prompt to a scoring",
    "start": "364639",
    "end": "366599"
  },
  {
    "text": "model which is going to generate a",
    "start": "366599",
    "end": "368599"
  },
  {
    "text": "number a score to score the actual",
    "start": "368599",
    "end": "371280"
  },
  {
    "text": "inference if you do this on all the",
    "start": "371280",
    "end": "373680"
  },
  {
    "text": "inferences generated from your",
    "start": "373680",
    "end": "374960"
  },
  {
    "text": "evaluation data set you can draw a",
    "start": "374960",
    "end": "376919"
  },
  {
    "text": "distribution of that particular metric",
    "start": "376919",
    "end": "379639"
  },
  {
    "text": "for example here is a small set of",
    "start": "379639",
    "end": "381560"
  },
  {
    "text": "closing words generated for a",
    "start": "381560",
    "end": "383319"
  },
  {
    "text": "professional emails we want to evaluate",
    "start": "383319",
    "end": "385800"
  },
  {
    "text": "their politeness we can prompt a model",
    "start": "385800",
    "end": "388280"
  },
  {
    "text": "to score the politeness of each",
    "start": "388280",
    "end": "389800"
  },
  {
    "text": "statement from 1 to 10 for example",
    "start": "389800",
    "end": "393360"
  },
  {
    "text": "please let us know as your earliest",
    "start": "393360",
    "end": "394880"
  },
  {
    "text": "convenience scores highly while tell me",
    "start": "394880",
    "end": "398039"
  },
  {
    "text": "ASAP will score",
    "start": "398039",
    "end": "399800"
  },
  {
    "text": "poorly we found that the best grading",
    "start": "399800",
    "end": "401960"
  },
  {
    "text": "model at this time is still gp4 but can",
    "start": "401960",
    "end": "404800"
  },
  {
    "text": "be quite costly to use to score large",
    "start": "404800",
    "end": "406800"
  },
  {
    "text": "data sets we have found that flan C5",
    "start": "406800",
    "end": "409840"
  },
  {
    "text": "offers a good trade-off of speed and",
    "start": "409840",
    "end": "412440"
  },
  {
    "text": "correctness air train was designed",
    "start": "412440",
    "end": "414680"
  },
  {
    "text": "specifically for this Purpose with air",
    "start": "414680",
    "end": "416919"
  },
  {
    "text": "train you can upload your data set",
    "start": "416919",
    "end": "419400"
  },
  {
    "text": "select the models you want to compare",
    "start": "419400",
    "end": "421759"
  },
  {
    "text": "describe the properties you want to",
    "start": "421759",
    "end": "423240"
  },
  {
    "text": "measure and visualize metric",
    "start": "423240",
    "end": "425039"
  },
  {
    "text": "distribution across your entire data set",
    "start": "425039",
    "end": "427720"
  },
  {
    "text": "you can compare Lama 2 with Falcon flant",
    "start": "427720",
    "end": "430599"
  },
  {
    "text": "T5 or even your own model then you can",
    "start": "430599",
    "end": "433080"
  },
  {
    "text": "make an edicated decision based on",
    "start": "433080",
    "end": "435000"
  },
  {
    "text": "statistical evidence sign up today for",
    "start": "435000",
    "end": "437360"
  },
  {
    "text": "Early Access at AirTrain doai and start",
    "start": "437360",
    "end": "440240"
  },
  {
    "text": "making data driven decision about your",
    "start": "440240",
    "end": "442039"
  },
  {
    "text": "choice of",
    "start": "442039",
    "end": "443360"
  },
  {
    "text": "llm thanks",
    "start": "443360",
    "end": "446130"
  },
  {
    "text": "[Music]",
    "start": "446130",
    "end": "448319"
  },
  {
    "text": "goodbye",
    "start": "448319",
    "end": "451319"
  }
]
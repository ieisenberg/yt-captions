[
  {
    "text": "my name is Karina um recently I've been working on Claude which is like a large language",
    "start": "1280",
    "end": "8639"
  },
  {
    "text": "model trained by anthropic and um most recently I was",
    "start": "8639",
    "end": "14120"
  },
  {
    "text": "working on like reducing hallucinations how to make CLA self-correct its answers and many other",
    "start": "14120",
    "end": "22199"
  },
  {
    "text": "features that went into like clot to launch and so I'm going to talk today",
    "start": "22199",
    "end": "27880"
  },
  {
    "text": "about the writing principles for task prompt engineering and kind of sort of like help you if you want to use claw",
    "start": "27880",
    "end": "36000"
  },
  {
    "text": "API help you to guide what the best practices and tips that I found and be",
    "start": "36000",
    "end": "41600"
  },
  {
    "text": "found most effective so first of all um I would",
    "start": "41600",
    "end": "47160"
  },
  {
    "text": "like to talk about why prompting is hard and to understand why prompting is hard",
    "start": "47160",
    "end": "53840"
  },
  {
    "text": "you should understand what prompting is in the first place so this models estimate the probability of each",
    "start": "53840",
    "end": "60120"
  },
  {
    "text": "subsequent word given the preceding words so in a way a well crafted prompt",
    "start": "60120",
    "end": "66159"
  },
  {
    "text": "can increase the probability of generated desired and accurate um",
    "start": "66159",
    "end": "71560"
  },
  {
    "text": "phrases due to attention mechanisms in large language models the models can",
    "start": "71560",
    "end": "76960"
  },
  {
    "text": "focus on specific parts of the input text and so effective prompts ensure",
    "start": "76960",
    "end": "83040"
  },
  {
    "text": "that the attention is directed uh appropriately for desired outputs and so it's important to incorporate like Tas",
    "start": "83040",
    "end": "90159"
  },
  {
    "text": "specific keywords and context and examples within the prompt to activate",
    "start": "90159",
    "end": "95799"
  },
  {
    "text": "the relevant portions of the models internal knowledge and lastly like you know",
    "start": "95799",
    "end": "101479"
  },
  {
    "text": "prompting leads to better results because without the need of like computational like other compute you",
    "start": "101479",
    "end": "108320"
  },
  {
    "text": "just like without like model ret training so uh you can like Leverage inference time test compute for this and",
    "start": "108320",
    "end": "116079"
  },
  {
    "text": "so like why prompting is hard and I think I found based on like my conversations with customers and like",
    "start": "116079",
    "end": "122560"
  },
  {
    "text": "developers I think prompting is hard because of like three different reasons first people know humans know what they",
    "start": "122560",
    "end": "129800"
  },
  {
    "text": "want but they don't know how to get the best performance from the model and I think that's what we're going to focus",
    "start": "129800",
    "end": "135480"
  },
  {
    "text": "on today the second reason is that they vaguely know what they want but they",
    "start": "135480",
    "end": "141599"
  },
  {
    "text": "don't know how to explain the best to the model and so the model gets confused",
    "start": "141599",
    "end": "147840"
  },
  {
    "text": "what the human wants from the ask and the third reason is like they don't know what they want so the humans don't know",
    "start": "147840",
    "end": "153920"
  },
  {
    "text": "what they want so it's pretty bad um and it's hard for the model to",
    "start": "153920",
    "end": "159680"
  },
  {
    "text": "understand so basic strategies that you can like if",
    "start": "159680",
    "end": "165560"
  },
  {
    "text": "you find yourself like you kind of wily know what the task is just provide a",
    "start": "165560",
    "end": "171000"
  },
  {
    "text": "bunch of examples and the model would be good at inferring what you're trying to do just based on like examples and the",
    "start": "171000",
    "end": "178040"
  },
  {
    "text": "examples may be um should be diverse and should encapsulate",
    "start": "178040",
    "end": "183120"
  },
  {
    "text": "a bunch of like age cases try to explain this you would have to explain to 5-year-old or like very",
    "start": "183120",
    "end": "191720"
  },
  {
    "text": "you know in a very simple terms and I think what I found is that like as you",
    "start": "191720",
    "end": "198080"
  },
  {
    "text": "have to like be able to like iterate a lot and like spend a lot of time just",
    "start": "198080",
    "end": "203319"
  },
  {
    "text": "prompting and in a way based on my experience for example as like research engineer I spend the majority of pairing",
    "start": "203319",
    "end": "210840"
  },
  {
    "text": "with people just collaborating on the prompts",
    "start": "210840",
    "end": "217000"
  },
  {
    "text": "um in the past I was thinking like how my main experience with the word prompt",
    "start": "217000",
    "end": "222200"
  },
  {
    "text": "was only in the creative writing classes uh I graduate from Berkeley and I took some like creative writing classes and",
    "start": "222200",
    "end": "229120"
  },
  {
    "text": "we usually have like exercises like prompting exercises right and so we often forget that prompting language",
    "start": "229120",
    "end": "234319"
  },
  {
    "text": "models is actually an act of creative writing and I see people get annoyed like why the prompts just don't work but",
    "start": "234319",
    "end": "241760"
  },
  {
    "text": "in most cases I think it just means that people lack some kind of like originality or creativity to think uh of",
    "start": "241760",
    "end": "250879"
  },
  {
    "text": "like new Noel ways how to make it work um I recently wrote a blog post",
    "start": "250879",
    "end": "257280"
  },
  {
    "text": "about the cultures of writing and one of the points that I'm making in the blog post is that promting becomes like a",
    "start": "257280",
    "end": "262720"
  },
  {
    "text": "form a new form of writing for any research engineer and like scientist who",
    "start": "262720",
    "end": "268199"
  },
  {
    "text": "engages in Daily this kind of writing requires forming hypothesis so you have",
    "start": "268199",
    "end": "274280"
  },
  {
    "text": "to ask the model OKAY can the model do this and you want to test that can the",
    "start": "274280",
    "end": "280000"
  },
  {
    "text": "model self correct its responses yes or no um and so you start trying like",
    "start": "280000",
    "end": "285680"
  },
  {
    "text": "forming the hypothesis next you test certain assumptions that you make about the model and if uh as you iterate more",
    "start": "285680",
    "end": "294000"
  },
  {
    "text": "you kind of like get new insights so like oh yeah the model is pretty good at this particular thing but it's not not",
    "start": "294000",
    "end": "299800"
  },
  {
    "text": "super good at another thing to achieve this task so you gain more clarity about",
    "start": "299800",
    "end": "305120"
  },
  {
    "text": "like what's what's the strength and the weaknesses are um I wanted to start with like",
    "start": "305120",
    "end": "313440"
  },
  {
    "text": "overall broad like writing principles uh because ultimately prompting is like writing right so the",
    "start": "313440",
    "end": "320560"
  },
  {
    "text": "goal is to write prompts that clearly communicate the task objective while",
    "start": "320560",
    "end": "325639"
  },
  {
    "text": "providing just enough constraints and guidance to steer the model towards producing high quality and relevant",
    "start": "325639",
    "end": "333160"
  },
  {
    "text": "outputs and so there are like four to six kind of like writing guidelines that",
    "start": "333160",
    "end": "339080"
  },
  {
    "text": "I think I found effective um especially working with like Claud um so do",
    "start": "339080",
    "end": "346960"
  },
  {
    "text": "we maybe to clarify how Claud is different from jbt or gbt models I think",
    "start": "346960",
    "end": "355120"
  },
  {
    "text": "with claw you have to almost treat it as like another human so you have to like",
    "start": "355120",
    "end": "362360"
  },
  {
    "text": "explain things to a 5-year-old or like you have to be elaborate and like um I",
    "start": "362360",
    "end": "369440"
  },
  {
    "text": "will share like more examples on like how to do that um but I think that's like a distinguishing um feature from",
    "start": "369440",
    "end": "376919"
  },
  {
    "text": "like GPT models from cloud um so the first principle is Clarity like use",
    "start": "376919",
    "end": "383759"
  },
  {
    "text": "Simple unambiguous language in your prompts avoid confusing syntax orake phrases that could confuse the model the",
    "start": "383759",
    "end": "391639"
  },
  {
    "text": "second is conciseness keep prompts short and focused include only key information",
    "start": "391639",
    "end": "398479"
  },
  {
    "text": "uh that the model needs third is coherence logically structure The Prompt with context at the",
    "start": "398479",
    "end": "405560"
  },
  {
    "text": "beginning and clear task at the end consistency stick to similar",
    "start": "405560",
    "end": "411759"
  },
  {
    "text": "formatting if you use XML tags use it consistently in the prompt if you use",
    "start": "411759",
    "end": "418280"
  },
  {
    "text": "certain like terminology um do not like kind of like put the",
    "start": "418280",
    "end": "423560"
  },
  {
    "text": "model of distribution basically so make it consistent uh Direction provide like",
    "start": "423560",
    "end": "429479"
  },
  {
    "text": "genre length style or any like guidelines guidance to direct the model's response ground prompts with",
    "start": "429479",
    "end": "437479"
  },
  {
    "text": "examples sources make the model to quote itself or like if you have like long",
    "start": "437479",
    "end": "444759"
  },
  {
    "text": "document in the context make it to quote from the do to support the",
    "start": "444759",
    "end": "450720"
  },
  {
    "text": "argument or may or help help the models to form support the arguments from like",
    "start": "450720",
    "end": "456879"
  },
  {
    "text": "search results or like other supporting um contextual uh information H engaging use diverse Ed",
    "start": "456879",
    "end": "464000"
  },
  {
    "text": "cases examples uh very useful for few short prompting um now I'm going to go through",
    "start": "464000",
    "end": "472280"
  },
  {
    "text": "sort of like tasks that I thought would be interesting um and see how how you",
    "start": "472280",
    "end": "479680"
  },
  {
    "text": "can use CLA in those specific tasks so the first case is obviously a",
    "start": "479680",
    "end": "484840"
  },
  {
    "text": "recommendation system um as of last year last year I made this project inalia um I used",
    "start": "484840",
    "end": "495199"
  },
  {
    "text": "clip to um kind of like um so I scraped a bunch",
    "start": "495199",
    "end": "502039"
  },
  {
    "text": "of like images and like uh clothing items",
    "start": "502039",
    "end": "507960"
  },
  {
    "text": "from different brands and um and I use it text as like a natural search kind of",
    "start": "507960",
    "end": "514080"
  },
  {
    "text": "like uh engine so you can say like um James Bond girl and you can do the",
    "start": "514080",
    "end": "522200"
  },
  {
    "text": "dress and in a way you get like results that are like dress in the style of",
    "start": "522200",
    "end": "527240"
  },
  {
    "text": "James Bond or you can do like futuristic etheral outfit and it's like more like Vibes based search uh and you can like",
    "start": "527240",
    "end": "535720"
  },
  {
    "text": "go and look at the shop itself yeah can you explain C oh yeah uh clip",
    "start": "535720",
    "end": "542800"
  },
  {
    "text": "is contrast of language to image model trained by open AI it's open source but",
    "start": "542800",
    "end": "549920"
  },
  {
    "text": "is basically um they provide embeddings for text and images so you can",
    "start": "549920",
    "end": "556560"
  },
  {
    "text": "like and the way it works here is that like you embed images and you embed um",
    "start": "556560",
    "end": "562240"
  },
  {
    "text": "text result and so what you can do is that you can like do cosign similarity to find the most similar um",
    "start": "562240",
    "end": "569839"
  },
  {
    "text": "items based on your database for the user query I don't know if that's clear",
    "start": "569839",
    "end": "575040"
  },
  {
    "text": "let me know if you have questions the same thing as multimodal it's a it's one way to take",
    "start": "575040",
    "end": "583160"
  },
  {
    "text": "image and text to become multimod there are different things for audio clip is",
    "start": "583160",
    "end": "588399"
  },
  {
    "text": "mostly for connecting text and yeah um I think you can read the",
    "start": "588399",
    "end": "596480"
  },
  {
    "text": "paper clip yeah um if you're interested so I was I was thinking like",
    "start": "596480",
    "end": "603440"
  },
  {
    "text": "okay how could I use CLA in this project to curate relevant recommendations based",
    "start": "603440",
    "end": "609959"
  },
  {
    "text": "on the user requests and that's the task so in a way you have like users",
    "start": "609959",
    "end": "615880"
  },
  {
    "text": "input let's say dress in the style of Emma Chamberlain Blazer like in The Great Gatsby movie an outfit with a",
    "start": "615880",
    "end": "623720"
  },
  {
    "text": "futuristic Vibe for the M Gala and on the other side you have like image to text database",
    "start": "623720",
    "end": "630000"
  },
  {
    "text": "um with images and their labels and the labels can be produced either by like",
    "start": "630000",
    "end": "635079"
  },
  {
    "text": "the original Source or you can use like multi model model to like come up with labels based on the",
    "start": "635079",
    "end": "640800"
  },
  {
    "text": "images and so the task of the cloud is to curate like based on the labels from",
    "start": "640800",
    "end": "647040"
  },
  {
    "text": "the images decide whether this like item relevant should I recommend this to the",
    "start": "647040",
    "end": "654160"
  },
  {
    "text": "user is this accurate like does it matches the uh users like can I",
    "start": "654160",
    "end": "660360"
  },
  {
    "text": "personalize this um and so if you can look at",
    "start": "660360",
    "end": "667800"
  },
  {
    "text": "the very simple curation strategy um for",
    "start": "667800",
    "end": "672880"
  },
  {
    "text": "the prompt you can just like zero shot it like I need you to decide whether the",
    "start": "672880",
    "end": "678160"
  },
  {
    "text": "item is relevant to the user query here's the user query um here's the item",
    "start": "678160",
    "end": "684839"
  },
  {
    "text": "description um is it item relevant or should should be recommended to the user",
    "start": "684839",
    "end": "689920"
  },
  {
    "text": "based on the user's query answer yes or no please write the answer in answer",
    "start": "689920",
    "end": "695160"
  },
  {
    "text": "tags let's unpack this first of all Claude really likes XML tags really",
    "start": "695160",
    "end": "702240"
  },
  {
    "text": "loves XML tags I think like this is like number one m not mistake but like um one",
    "start": "702240",
    "end": "710760"
  },
  {
    "text": "thing that people Miss they don't like put anything in XML tax and so they don't have like very high like good",
    "start": "710760",
    "end": "716920"
  },
  {
    "text": "performance so everything like yeah I feel love XML tags so you should like put everything in XML tags and um with",
    "start": "716920",
    "end": "723639"
  },
  {
    "text": "XML tags you should like be consistent so what is us a query item and you can be very descriptive I can share like",
    "start": "723639",
    "end": "730760"
  },
  {
    "text": "more examples in U later on and here in a way you like the way",
    "start": "730760",
    "end": "736959"
  },
  {
    "text": "you interact with cloud is like you can see the language here I need you to decide whether the item is relevant it",
    "start": "736959",
    "end": "743160"
  },
  {
    "text": "almost feels like you talk to a human um question yeah so uh this XML",
    "start": "743160",
    "end": "752079"
  },
  {
    "text": "thing recently only came out like maybe like a month or two ago from official enthic device oh really is this",
    "start": "752079",
    "end": "758880"
  },
  {
    "text": "something it was on like intentionally trained for or you discovered it after",
    "start": "758880",
    "end": "764880"
  },
  {
    "text": "pre-training I think it was uh I mean we tried to XML XML formatting",
    "start": "764880",
    "end": "772399"
  },
  {
    "text": "was the first formatting that we like kind of like fine tuned on like um later",
    "start": "772399",
    "end": "778120"
  },
  {
    "text": "on we disced you know customers need like markdown or like need Claud needs to like use Jon Json formatting so like",
    "start": "778120",
    "end": "786600"
  },
  {
    "text": "we kind of like learned from customers but originally it was like XML formatting yeah so is that mostly",
    "start": "786600",
    "end": "792440"
  },
  {
    "text": "because of the fine tuning or is that because you had a training set that are tons of XML stuff in it uh I think it's",
    "start": "792440",
    "end": "798560"
  },
  {
    "text": "kind of about both yeah um",
    "start": "798560",
    "end": "803160"
  },
  {
    "text": "yeah H close small",
    "start": "803959",
    "end": "809720"
  },
  {
    "text": "tags yeah I don't know",
    "start": "809720",
    "end": "815959"
  },
  {
    "text": "um oh yeah sorry I had a mistake yes I have um yeah and so like one one good",
    "start": "817959",
    "end": "826120"
  },
  {
    "text": "thing about XML tax is like it's really uh easy to extract right like the strings inside",
    "start": "826120",
    "end": "832240"
  },
  {
    "text": "it and Claude is pretty good at like um I I can like say like don't put any",
    "start": "832240",
    "end": "838800"
  },
  {
    "text": "anything in XML text so sometimes like Cloud will like say here's information blah blah blah blah but then if you ask",
    "start": "838800",
    "end": "844720"
  },
  {
    "text": "just like write the answer in like this TX Claud will not put any additional information which is one of the most",
    "start": "844720",
    "end": "851000"
  },
  {
    "text": "annoying thing with like language models so here's the results uh that I",
    "start": "851000",
    "end": "856880"
  },
  {
    "text": "put um this is through claw. a interface um and so yeah you can see",
    "start": "856880",
    "end": "863079"
  },
  {
    "text": "like is this item relevant uh says no is this item relevant yes but I don't think",
    "start": "863079",
    "end": "870240"
  },
  {
    "text": "that's like 100% like um you",
    "start": "870240",
    "end": "876079"
  },
  {
    "text": "know perfect system so it's very like zero shot so basically you can like iterate and we'll try to iterate more in",
    "start": "876079",
    "end": "884880"
  },
  {
    "text": "this um strategy number two is that like when uh you put you ask the model to",
    "start": "884880",
    "end": "892240"
  },
  {
    "text": "take some time to think whether the item is relevant or not uh in thought TXS based on the criteria above um and you",
    "start": "892240",
    "end": "900000"
  },
  {
    "text": "kind of let the model think um a little bit more um with its reasoning and then",
    "start": "900000",
    "end": "907480"
  },
  {
    "text": "uh this is like basically Chain of Thought you can also add like",
    "start": "907480",
    "end": "914360"
  },
  {
    "text": "criteria uh so as a part of your critique consider the following criteria and so if you want to like steer the",
    "start": "914360",
    "end": "919480"
  },
  {
    "text": "model on like does the item match the specific attributes of crusted by user",
    "start": "919480",
    "end": "924639"
  },
  {
    "text": "like help the model to like think kind of kind of like think through like what means what does it mean to like",
    "start": "924639",
    "end": "930560"
  },
  {
    "text": "recommend an item to the user does the item match the season or whether the conditions match in the user query for",
    "start": "930560",
    "end": "938000"
  },
  {
    "text": "example you should not recommend winter codes during summer seasons so like in the criteria you can like give more",
    "start": "938000",
    "end": "944759"
  },
  {
    "text": "example small Li examples um another thing that you",
    "start": "944759",
    "end": "950440"
  },
  {
    "text": "iterate on is like not just like give answer yes or no but you can like based on your critique score whether the item",
    "start": "950440",
    "end": "957759"
  },
  {
    "text": "should be recommended or not where one is least to be recommended and 10 is",
    "start": "957759",
    "end": "962959"
  },
  {
    "text": "highly recommended and put the final score in score tags and so how does it work uh so um",
    "start": "962959",
    "end": "971680"
  },
  {
    "text": "here like us the query James Bond Blazer um item which I took from um I think it",
    "start": "971680",
    "end": "980279"
  },
  {
    "text": "was some brand um and Claud would like start like thoughts tags um overall it",
    "start": "980279",
    "end": "989079"
  },
  {
    "text": "seems like very relevant and the final score is nine and here's another example I want",
    "start": "989079",
    "end": "995319"
  },
  {
    "text": "to dress in the style of The Great Gatsby movie um here's the item braided cor corupt waste coast and the critique",
    "start": "995319",
    "end": "1002880"
  },
  {
    "text": "is basically uh the item is not appropriate for the user needs based on the context clues in the",
    "start": "1002880",
    "end": "1008600"
  },
  {
    "text": "query um it doesn't like you know match the attributes of the great GS beu it like tries to like have like some",
    "start": "1008600",
    "end": "1014880"
  },
  {
    "text": "reasoning and so the score is two and you can be a little bit more elaborate this is like very simple like",
    "start": "1014880",
    "end": "1021680"
  },
  {
    "text": "iteration um on on that do you guys have any questions yeah so one interesting",
    "start": "1021680",
    "end": "1028280"
  },
  {
    "text": "thing that I saw I mean there was the XML tacks now here that were enclosed my friend he is not a native English",
    "start": "1028280",
    "end": "1035280"
  },
  {
    "text": "speaker his prompts are always in in very kind of funny English but he",
    "start": "1035280",
    "end": "1040360"
  },
  {
    "text": "structures them really well and they work really well despite the English being very incorrect right right why why",
    "start": "1040360",
    "end": "1047280"
  },
  {
    "text": "does that work I think it's just the models are like pretty good at like",
    "start": "1047280",
    "end": "1052880"
  },
  {
    "text": "knowledge transfer between like languages or like can infer very well on",
    "start": "1052880",
    "end": "1057960"
  },
  {
    "text": "like the users's intent um yeah I don't have like pretty clear answer",
    "start": "1057960",
    "end": "1063720"
  },
  {
    "text": "probabilistic so that text with one syntax mistake looks close enough to the",
    "start": "1063720",
    "end": "1069039"
  },
  {
    "text": "text with the right syntax the probability of the real answer is close in both cases like guess I don't know",
    "start": "1069039",
    "end": "1076799"
  },
  {
    "text": "yeah in this particular example mhm I'm curious on whether you see any bias with",
    "start": "1076799",
    "end": "1081840"
  },
  {
    "text": "the score in other words if you were look at the distribution of scores right would it be a normal distribution yeah this is an interesting",
    "start": "1081840",
    "end": "1088679"
  },
  {
    "text": "question like this is one question that we ask in our research settings like one thing that we're trying to understand",
    "start": "1088679",
    "end": "1095360"
  },
  {
    "text": "like we have a research group uh called societal impacts and one thing uh that",
    "start": "1095360",
    "end": "1102080"
  },
  {
    "text": "we we are trying to understand now is like when you summarize like news articles and you try to evaluate it's",
    "start": "1102080",
    "end": "1108679"
  },
  {
    "text": "like the bias was kind of the distribution and I feel like this is like research active like yeah I think",
    "start": "1108679",
    "end": "1113960"
  },
  {
    "text": "it depends on the task um really I did not test understand this literally it was yesterday uh",
    "start": "1113960",
    "end": "1122640"
  },
  {
    "text": "prompting cool um the second task um so Claud is",
    "start": "1124400",
    "end": "1131400"
  },
  {
    "text": "known for a 100K context uh size which is the entire",
    "start": "1131400",
    "end": "1137520"
  },
  {
    "text": "book of the great G speak can like put into the context and you can like ask the model uh Summarize the book or like",
    "start": "1137520",
    "end": "1144080"
  },
  {
    "text": "uh ask some tasks based on the huge context and this is like",
    "start": "1144080",
    "end": "1150760"
  },
  {
    "text": "basically time test compute um thing and so was long",
    "start": "1150760",
    "end": "1156720"
  },
  {
    "text": "context um let me see the way you can use long context can",
    "start": "1156720",
    "end": "1163840"
  },
  {
    "text": "be in different ways like one way is like you put multiple documents and try to summarize like a retrieve information",
    "start": "1163840",
    "end": "1171280"
  },
  {
    "text": "based on the documents another way to use long context is to have a bunch a huge F shot",
    "start": "1171280",
    "end": "1179520"
  },
  {
    "text": "prompt and so as you know like Chain of Thought um technique relies on the",
    "start": "1179520",
    "end": "1185919"
  },
  {
    "text": "stated reasoning Faithfully reflecting the model's actual reasoning and in one",
    "start": "1185919",
    "end": "1191880"
  },
  {
    "text": "of the recent papers we found that it's not super like it's not always the",
    "start": "1191880",
    "end": "1196960"
  },
  {
    "text": "case so so doesn't so basically what it means is",
    "start": "1196960",
    "end": "1203600"
  },
  {
    "text": "that like if you ask the model do chain of thought it might not necessarily",
    "start": "1203600",
    "end": "1209080"
  },
  {
    "text": "attend to you know Chain of Thought uh to produce the final answer it might",
    "start": "1209080",
    "end": "1215080"
  },
  {
    "text": "just like ignore it or like uh not take any account so it's not we we call it",
    "start": "1215080",
    "end": "1220799"
  },
  {
    "text": "like Unfaithful basically it's not super faithful and so if you proposing this",
    "start": "1220799",
    "end": "1226760"
  },
  {
    "text": "paper um like decomposition based methods can",
    "start": "1226760",
    "end": "1231880"
  },
  {
    "text": "actually achieve like strong performance on specifically question answering tasks",
    "start": "1231880",
    "end": "1237600"
  },
  {
    "text": "sometimes approaching that of Chain of Thought performance while improving the",
    "start": "1237600",
    "end": "1243360"
  },
  {
    "text": "faithfulness do you guys have any questions I didn't understand that sorry okay yeah what is faithfulness here is",
    "start": "1244039",
    "end": "1250919"
  },
  {
    "text": "the faithfulness to your um faithfulness is um",
    "start": "1250919",
    "end": "1258640"
  },
  {
    "text": "yes to your prompt yeah what's decomposition what's decomposition yeah",
    "start": "1258640",
    "end": "1263840"
  },
  {
    "text": "uh let me explain what decomposition is so here's the graph from the",
    "start": "1263840",
    "end": "1269159"
  },
  {
    "text": "paper uh we have like three methods first is a Chain of Thought method which",
    "start": "1269159",
    "end": "1274640"
  },
  {
    "text": "is like uh here's the question could could be do fit in a kangaroo pouch uh",
    "start": "1274640",
    "end": "1280320"
  },
  {
    "text": "there are two choices a yes B no Chain of Thought prompt saying like let's",
    "start": "1280320",
    "end": "1288159"
  },
  {
    "text": "think step by step gives the reasoning and the human ask the followup",
    "start": "1288159",
    "end": "1294200"
  },
  {
    "text": "questions based on the above what is the single most likely answer choice and the",
    "start": "1294200",
    "end": "1299400"
  },
  {
    "text": "model says the correct answer choice is B right the Chain of Thought",
    "start": "1299400",
    "end": "1305880"
  },
  {
    "text": "decomposition is when you decompose a question when you can ask the model to",
    "start": "1305880",
    "end": "1311640"
  },
  {
    "text": "decompose a question into like multiple sub questions so that each sub question",
    "start": "1311640",
    "end": "1316679"
  },
  {
    "text": "are kind of independent from each other other because in Chain of Thought like you have one two three you know like",
    "start": "1316679",
    "end": "1322840"
  },
  {
    "text": "they kind of like can influence each other right like in decomposition you kind of like um you you decompose and",
    "start": "1322840",
    "end": "1330279"
  },
  {
    "text": "you like put each sub question in the independent context so in a way it kind",
    "start": "1330279",
    "end": "1335600"
  },
  {
    "text": "of like reduces the bias um and so in this um let's see here",
    "start": "1335600",
    "end": "1343600"
  },
  {
    "text": "is that like sub question one uh what type of animals could we do the answer from the model SC is a",
    "start": "1343600",
    "end": "1350440"
  },
  {
    "text": "fictional character and as a sub question for for the assistant for Claud",
    "start": "1350440",
    "end": "1356400"
  },
  {
    "text": "how big is an average Kar pouch and you would and what you can see is that like each step question is kind of like",
    "start": "1356400",
    "end": "1362640"
  },
  {
    "text": "self-contained it's very Atomic self-contained question um and so you have like",
    "start": "1362640",
    "end": "1368880"
  },
  {
    "text": "multiple sub questions like this and then what you do is you recompose so",
    "start": "1368880",
    "end": "1374400"
  },
  {
    "text": "like you like put sub question answer sub question answer sub question answer",
    "start": "1374400",
    "end": "1379559"
  },
  {
    "text": "into like one context and ask the model based on the B what is the single most likely answer Choice the correct answer",
    "start": "1379559",
    "end": "1385720"
  },
  {
    "text": "Choice be yeah um in Chain of like in the",
    "start": "1385720",
    "end": "1391080"
  },
  {
    "text": "system prompt or whatever the users prompt is like we mentioned less things step by step uh what do you do for the",
    "start": "1391080",
    "end": "1398360"
  },
  {
    "text": "decomposition is it like a similar you know input to the model to",
    "start": "1398360",
    "end": "1404559"
  },
  {
    "text": "make it decompose into multiple questions yeah uh I can share the prompt um in a few slides uh on this um but uh",
    "start": "1404559",
    "end": "1414159"
  },
  {
    "text": "yeah any other questions can you show the graph now I the this graph",
    "start": "1414159",
    "end": "1420880"
  },
  {
    "text": "yeah um yeah let's look at the prompt um very hard to see but I'll",
    "start": "1428200",
    "end": "1437120"
  },
  {
    "text": "share the slide um let's um I I'm I'm going to give you",
    "start": "1437120",
    "end": "1443159"
  },
  {
    "text": "like legal context like legal question let's say you have a question on",
    "start": "1443159",
    "end": "1448799"
  },
  {
    "text": "like a legal question and you ask us like which is the following is the most persuasive argument that a person is",
    "start": "1448799",
    "end": "1455919"
  },
  {
    "text": "liable to the Creditor under the terms of the agreement and here's the context so that's the question",
    "start": "1455919",
    "end": "1462000"
  },
  {
    "text": "basically and so you have like choices for the model so this is like multiple choice question",
    "start": "1462000",
    "end": "1469039"
  },
  {
    "text": "and before that you have like a huge F shot prompt um and basically",
    "start": "1469039",
    "end": "1474679"
  },
  {
    "text": "here to answer your question like it says I'm going to give you a question I",
    "start": "1474679",
    "end": "1480440"
  },
  {
    "text": "want you to compose into series of sub questions each sub question should be self-contained with all the information",
    "start": "1480440",
    "end": "1488000"
  },
  {
    "text": "necessary um this is really important blah blah blah uh make sure not to",
    "start": "1488000",
    "end": "1495520"
  },
  {
    "text": "decompose more than necessary um be concise blah blah blah please put",
    "start": "1495520",
    "end": "1502200"
  },
  {
    "text": "each sub question in like this tags but include the numbers corresponding to each",
    "start": "1502200",
    "end": "1507799"
  },
  {
    "text": "tag so um and the model says yes I understand uh you have a",
    "start": "1507799",
    "end": "1515440"
  },
  {
    "text": "question uh multiple choice answers and the model provides sub questions for you",
    "start": "1515440",
    "end": "1522600"
  },
  {
    "text": "and then what you do is that you try to answer the first step question and you",
    "start": "1522600",
    "end": "1527799"
  },
  {
    "text": "give it to the model you try to answer second sub question you give it to the model third sub question you give to the model and then later you say like based",
    "start": "1527799",
    "end": "1536279"
  },
  {
    "text": "on everything above like you give all the context um answer me the question um the",
    "start": "1536279",
    "end": "1544799"
  },
  {
    "text": "correct answer c",
    "start": "1544799",
    "end": "1550000"
  },
  {
    "text": "yeah and so this is like very similar in the legal context you have sub questions",
    "start": "1550279",
    "end": "1556360"
  },
  {
    "text": "like what is consideration contract law blah blah blah and you have you can have like another model to like sample here",
    "start": "1556360",
    "end": "1562399"
  },
  {
    "text": "you can have like another model to answer this it doesn't necessarily should be like one model um and then there's like another",
    "start": "1562399",
    "end": "1572600"
  },
  {
    "text": "sub question and here's the answer yeah you guys have any",
    "start": "1572600",
    "end": "1581278"
  },
  {
    "text": "questions um the second that I want to talk about",
    "start": "1582799",
    "end": "1589360"
  },
  {
    "text": "is how to use claw to do evaluations like",
    "start": "1589360",
    "end": "1594480"
  },
  {
    "text": "evaluating like Claw on like long context ability let's say you have a lot",
    "start": "1594480",
    "end": "1601440"
  },
  {
    "text": "of like documents and you want to understand how good Claud is answering",
    "start": "1601440",
    "end": "1608760"
  },
  {
    "text": "questions based on the document or is it is it able to answer like the questions",
    "start": "1608760",
    "end": "1617240"
  },
  {
    "text": "not just just like from its P chain knowledge but like based on the document itself and so um I'm going to give you",
    "start": "1617240",
    "end": "1625640"
  },
  {
    "text": "example that we did at anthropic um multiple choice QA um",
    "start": "1625640",
    "end": "1631760"
  },
  {
    "text": "evaluation design so our goal was to with this experience to evaluate",
    "start": "1631760",
    "end": "1636799"
  },
  {
    "text": "techniques to maximize Cloud's chance to correctly recalling a specific piece of",
    "start": "1636799",
    "end": "1642039"
  },
  {
    "text": "information from a long document and so the document that we chose was the government document",
    "start": "1642039",
    "end": "1648159"
  },
  {
    "text": "that contains like a bunch of like meeting transcripts different departments and we also chose the one",
    "start": "1648159",
    "end": "1653799"
  },
  {
    "text": "that was like uh from this year July 13th uh which is like way after claud's",
    "start": "1653799",
    "end": "1661919"
  },
  {
    "text": "um training data cut off so that you don't like um you have the document that",
    "start": "1661919",
    "end": "1667960"
  },
  {
    "text": "does not have in the pre- knowledge or something and so what you're trying to",
    "start": "1667960",
    "end": "1674840"
  },
  {
    "text": "do is like now you want to use clot to generate question answers",
    "start": "1674840",
    "end": "1681559"
  },
  {
    "text": "pairs um you in a way like you create like",
    "start": "1681559",
    "end": "1686640"
  },
  {
    "text": "data data set based you use language models to create like data set and so",
    "start": "1686640",
    "end": "1692880"
  },
  {
    "text": "the way you do that is that you split the document into sections and use claw to generate like five multiple choice",
    "start": "1692880",
    "end": "1699600"
  },
  {
    "text": "questions for each section each with three wrong answers and one right answer and if you do that you then re",
    "start": "1699600",
    "end": "1707640"
  },
  {
    "text": "assemble like randomized sets of those sections into like long documents that you could pass them to Claud and test",
    "start": "1707640",
    "end": "1714840"
  },
  {
    "text": "its recall uh of their content this is very matter let me know if you have",
    "start": "1714840",
    "end": "1720679"
  },
  {
    "text": "questions yeah um so here's a prompt",
    "start": "1720679",
    "end": "1728200"
  },
  {
    "text": "to generate multiple choice questions um I ask like please write five factual",
    "start": "1728200",
    "end": "1734159"
  },
  {
    "text": "questions for this um some guidelines at the",
    "start": "1734159",
    "end": "1740760"
  },
  {
    "text": "end um and basically we test different strategies promting strategies just",
    "start": "1740760",
    "end": "1746720"
  },
  {
    "text": "asking Claude give Claude two fixed examples of correctly answered general",
    "start": "1746720",
    "end": "1752960"
  },
  {
    "text": "knowledge and uh that are unrelated to the government document um providing two",
    "start": "1752960",
    "end": "1760039"
  },
  {
    "text": "examples and providing five examples of correctly answered questions and we tested the strategy",
    "start": "1760039",
    "end": "1768519"
  },
  {
    "text": "uh on different settings like one is containing the answer positioned at the",
    "start": "1768519",
    "end": "1773760"
  },
  {
    "text": "beginning the end or the mle in the input and we tested with like 70k and",
    "start": "1773760",
    "end": "1779159"
  },
  {
    "text": "95k token documents you can look at the prompt and",
    "start": "1779159",
    "end": "1786360"
  },
  {
    "text": "more specific how we did this in our blog post but basically the result is this uh",
    "start": "1786360",
    "end": "1796600"
  },
  {
    "text": "here we see that um what is",
    "start": "1796600",
    "end": "1803919"
  },
  {
    "text": "thec yeah the metc was um to let's",
    "start": "1803919",
    "end": "1811639"
  },
  {
    "text": "see like basically how many how many times like CLA has",
    "start": "1814279",
    "end": "1823200"
  },
  {
    "text": "correctly answered the question um right and so",
    "start": "1823200",
    "end": "1829240"
  },
  {
    "text": "so yeah sorry uh basically what we find is that",
    "start": "1830240",
    "end": "1835559"
  },
  {
    "text": "like for document Q&A asking the question at the end of The Prompt performs a lot better than asking at the",
    "start": "1835559",
    "end": "1841440"
  },
  {
    "text": "beginning you can see it here uh pulling relevant quotes into",
    "start": "1841440",
    "end": "1848159"
  },
  {
    "text": "like critique or like thoughts tags is helpful um it's like a small cost to",
    "start": "1848159",
    "end": "1855480"
  },
  {
    "text": "latency but improves accurac see uh and we tested on like both cloud and Cloud",
    "start": "1855480",
    "end": "1862200"
  },
  {
    "text": "instant um and it seems like you can boost way better",
    "start": "1862440",
    "end": "1868000"
  },
  {
    "text": "performance from like Cloud instant um than Cloud",
    "start": "1868000",
    "end": "1873919"
  },
  {
    "text": "2 basically the idea is that like if you want to use long do Q&A put the",
    "start": "1873919",
    "end": "1880919"
  },
  {
    "text": "instructions at the end of your prompt yeah that's like the result of this what",
    "start": "1880919",
    "end": "1887360"
  },
  {
    "text": "was the I didn't catch what was the scratch pad in the uh oh yeah like you just ask the",
    "start": "1887360",
    "end": "1895200"
  },
  {
    "text": "model to like put thoughts in like thoughts tags before answering the question so it has like more reasoning B",
    "start": "1895200",
    "end": "1901960"
  },
  {
    "text": "yeah can you go to the table again yeah sorry I'm",
    "start": "1901960",
    "end": "1907278"
  },
  {
    "text": "uh but like the outcome was basically putting it at the end matters more than",
    "start": "1916159",
    "end": "1921840"
  },
  {
    "text": "all the other yeah optimization strateg right",
    "start": "1921840",
    "end": "1926799"
  },
  {
    "text": "yeah um yeah in a way this is like an example",
    "start": "1927360",
    "end": "1935039"
  },
  {
    "text": "to show like how to use cloud to generate a data set that you can like evaluate and like you can use it for",
    "start": "1935039",
    "end": "1941440"
  },
  {
    "text": "like evaluation basically",
    "start": "1941440",
    "end": "1947799"
  },
  {
    "text": "yeah so this has to do with putting your instruction at the end of The Prompt uh",
    "start": "1947799",
    "end": "1953720"
  },
  {
    "text": "first are there theories on like why why specifically instruction should be at the end and are there any things like do",
    "start": "1953720",
    "end": "1960240"
  },
  {
    "text": "we have any understanding of like are there certain things at the beginning of the prompt that still might be weighted",
    "start": "1960240",
    "end": "1966039"
  },
  {
    "text": "or is it like this sliding scale that like the further in the beginning of the prompt like the less attention it gets I",
    "start": "1966039",
    "end": "1973279"
  },
  {
    "text": "think that's basically the hypothesis it's like the you know it it's like the",
    "start": "1973279",
    "end": "1978440"
  },
  {
    "text": "distance it's like the model attends more to the end of The Prompt uh",
    "start": "1978440",
    "end": "1984799"
  },
  {
    "text": "than exact I think there was a paper saying like it just forgets in the middle or something okay um yeah I think",
    "start": "1984799",
    "end": "1991720"
  },
  {
    "text": "this is the problem with like long context that you're trying to fix or something yeah so to follow on that question you",
    "start": "1991720",
    "end": "1999000"
  },
  {
    "text": "saying that there was a paper that said that it remembers beginning and the end and kind of forgets in the middle yeah",
    "start": "1999000",
    "end": "2005000"
  },
  {
    "text": "what you're saying is for cl to it seems to do best if you give it at the end yeah",
    "start": "2005000",
    "end": "2010279"
  },
  {
    "text": "so that paper doesn't apply to CL um I did not read that paper like no I'm",
    "start": "2010279",
    "end": "2018120"
  },
  {
    "text": "just curious what you're saying is you're finding it at least for cl the end part it gets more attention",
    "start": "2018120",
    "end": "2025159"
  },
  {
    "text": "yeah for like a specific tasks is like long context uh Q&A for like long",
    "start": "2025159",
    "end": "2030559"
  },
  {
    "text": "documents yeah um yeah we have not tested on other",
    "start": "2030559",
    "end": "2035960"
  },
  {
    "text": "tasks to my knowledge um so the prompts you showed",
    "start": "2035960",
    "end": "2041480"
  },
  {
    "text": "were using regular pros and then the XML tags M um I think that's also what's",
    "start": "2041480",
    "end": "2048760"
  },
  {
    "text": "Indi anthropic docks have you guys ever done experiments on like that kind of format versus markdown versus everything",
    "start": "2048760",
    "end": "2056878"
  },
  {
    "text": "is in XML do you have any thoughts on that yeah so",
    "start": "2056879",
    "end": "2062118"
  },
  {
    "text": "um in general I think I think it's",
    "start": "2062119",
    "end": "2069040"
  },
  {
    "text": "because markdown was kind of like there's not that much of",
    "start": "2069040",
    "end": "2076200"
  },
  {
    "text": "like I don't know it's like best than XML tags like I'm I'm thinking the I've",
    "start": "2076200",
    "end": "2081878"
  },
  {
    "text": "like tried CLA to like you know use like jonl or like uh use",
    "start": "2081879",
    "end": "2088118"
  },
  {
    "text": "markdown but sometimes it's like you know it's not as good as like XML with XML it's almost 100% accuracy",
    "start": "2088119",
    "end": "2095878"
  },
  {
    "text": "yeah",
    "start": "2095879",
    "end": "2098879"
  },
  {
    "text": "let's see yeah um let's go to another task um",
    "start": "2103560",
    "end": "2109599"
  },
  {
    "text": "which is like you can use language models to like Auto label basically",
    "start": "2109599",
    "end": "2115480"
  },
  {
    "text": "anything um so one of the examples that we did last year um we ask lot to categorize the",
    "start": "2115480",
    "end": "2124480"
  },
  {
    "text": "labels for the Clusters and so um this was for the paper but the",
    "start": "2124480",
    "end": "2133200"
  },
  {
    "text": "approach was very simple we have a bunch of like you know texts and we embed them",
    "start": "2133200",
    "end": "2138720"
  },
  {
    "text": "in umap um and we do like Cann",
    "start": "2138720",
    "end": "2145119"
  },
  {
    "text": "clustering and for each cluster sorry caman clustering and for",
    "start": "2145119",
    "end": "2151720"
  },
  {
    "text": "each cluster select like for each cluster aggregate all the",
    "start": "2151720",
    "end": "2158920"
  },
  {
    "text": "you know literal like statements or claims and we ask the model to come up",
    "start": "2158920",
    "end": "2164760"
  },
  {
    "text": "with the category for this cluster so that's the approach and you",
    "start": "2164760",
    "end": "2171400"
  },
  {
    "text": "can look at the other",
    "start": "2171400",
    "end": "2176480"
  },
  {
    "text": "labels uh labels here are not super good because we used Cloud 1.3 at that time",
    "start": "2176480",
    "end": "2182160"
  },
  {
    "text": "CLA 2 is supposed to be like way better at this um but this is like you know cash it was like last",
    "start": "2182160",
    "end": "2189839"
  },
  {
    "text": "year um where's my slides and",
    "start": "2189839",
    "end": "2196359"
  },
  {
    "text": "so one thing that you can do with this kind of",
    "start": "2196359",
    "end": "2204280"
  },
  {
    "text": "task we call it self-consistency you can generate and samples for the question um",
    "start": "2204280",
    "end": "2212480"
  },
  {
    "text": "so let's say you have a question like how do do you label this cluster and you",
    "start": "2212480",
    "end": "2219240"
  },
  {
    "text": "generate independently end times and you can ask just like come up with like one",
    "start": "2219240",
    "end": "2226880"
  },
  {
    "text": "category um well this method is mostly useful for like quantitative like if you",
    "start": "2226880",
    "end": "2232960"
  },
  {
    "text": "have like a math question and you sample like different like sample multiple times and come up with the answer um",
    "start": "2232960",
    "end": "2240720"
  },
  {
    "text": "like the most common answer is uh the one that you select with the final answer and this is called the majority",
    "start": "2240720",
    "end": "2247319"
  },
  {
    "text": "of vote another technique that you can use is like um have like two generated",
    "start": "2247319",
    "end": "2254119"
  },
  {
    "text": "samples and ask another model to evaluate whether those samples are consistent or not and if the samples are",
    "start": "2254119",
    "end": "2260760"
  },
  {
    "text": "consistent well you gain more confidence that this is correct right and if it's not consistent you just like",
    "start": "2260760",
    "end": "2268359"
  },
  {
    "text": "deselect um another thing that you want to do with Claud is uh if",
    "start": "2269400",
    "end": "2275599"
  },
  {
    "text": "you if Claus kind of like misses the Nuance especially for like categorizing",
    "start": "2275599",
    "end": "2281359"
  },
  {
    "text": "a lot of labels and you have like a lot of like categorizations",
    "start": "2281359",
    "end": "2287520"
  },
  {
    "text": "um you can add contrasting conceptual distinctions in your instruction and you",
    "start": "2287520",
    "end": "2295560"
  },
  {
    "text": "can do it in multiple ways one way to do is like you provide bad example let's say like here is a very bad category and",
    "start": "2295560",
    "end": "2301839"
  },
  {
    "text": "you should never come up with it because this is like too narrow or like too General and this is not what I want uh",
    "start": "2301839",
    "end": "2308560"
  },
  {
    "text": "like give like contrastive like examples H very the context use examples in",
    "start": "2308560",
    "end": "2313839"
  },
  {
    "text": "different context and settings um not just like just like have",
    "start": "2313839",
    "end": "2319040"
  },
  {
    "text": "like more diversity like diversity is like um the more diverse like fot prompt",
    "start": "2319040",
    "end": "2324599"
  },
  {
    "text": "examples the better use analogies and metaphors um if",
    "start": "2324599",
    "end": "2330760"
  },
  {
    "text": "the concept is like too hard to understand with the model try to like decompose and like bring analogy um",
    "start": "2330760",
    "end": "2338680"
  },
  {
    "text": "point out like common misconceptions um especially for like categorizing",
    "start": "2338680",
    "end": "2344480"
  },
  {
    "text": "like let's say what is false presupposition right like uh",
    "start": "2344480",
    "end": "2351160"
  },
  {
    "text": "point out the common misc misconception and like clarify like why this is like",
    "start": "2351160",
    "end": "2357839"
  },
  {
    "text": "incorrect like provide examples thatly show why common misconception is",
    "start": "2357839",
    "end": "2364440"
  },
  {
    "text": "wrong uh yes do you guys have any questions",
    "start": "2365440",
    "end": "2372440"
  },
  {
    "text": "y um I cannot here but um the",
    "start": "2382359",
    "end": "2389079"
  },
  {
    "text": "running to group and then the task of the LM is to put a name on each group",
    "start": "2389079",
    "end": "2396920"
  },
  {
    "text": "like come up with a category like um yeah come up with a category or like classify uh like label that cluster",
    "start": "2396920",
    "end": "2407119"
  },
  {
    "text": "basically um so here's like very basic like tips and strategies with Cloud API",
    "start": "2408760",
    "end": "2414240"
  },
  {
    "text": "um number one is formatting um like human assistant is like what",
    "start": "2414240",
    "end": "2421560"
  },
  {
    "text": "Claude loves and if you misses you miss it like you'll get like very very terrible results",
    "start": "2421560",
    "end": "2427000"
  },
  {
    "text": "uh new line new line human new line new line assistant um",
    "start": "2427000",
    "end": "2434119"
  },
  {
    "text": "yeah uh you can also put words in cla's mouth to like kind of like say like do you",
    "start": "2434119",
    "end": "2442040"
  },
  {
    "text": "understand it and you can like put in the um Cloud's mouth yes I understand it",
    "start": "2442040",
    "end": "2448880"
  },
  {
    "text": "and a way to like you know put put the model into this mode have claw repeat instructions back",
    "start": "2448880",
    "end": "2458240"
  },
  {
    "text": "um you can say like do you understand the instructions um and you can put like",
    "start": "2458240",
    "end": "2465800"
  },
  {
    "text": "assistant yes I understand instructions blah blah",
    "start": "2465800",
    "end": "2471599"
  },
  {
    "text": "blah uh to reduce hallucinations like let clot hedge and like say like I don't",
    "start": "2471599",
    "end": "2479400"
  },
  {
    "text": "know or like uh I don't have enough information or like context to answer the",
    "start": "2479400",
    "end": "2485240"
  },
  {
    "text": "question um here's another thing um if you have",
    "start": "2485240",
    "end": "2494079"
  },
  {
    "text": "like generate direct quotes if you have like a document or like um a",
    "start": "2494079",
    "end": "2501560"
  },
  {
    "text": "long document in the context um make CLA to say find appropriate quotes but also",
    "start": "2501560",
    "end": "2509520"
  },
  {
    "text": "say like um if there are no quotes in this document that seems relevant to",
    "start": "2509520",
    "end": "2514720"
  },
  {
    "text": "this question please just say I don't find any relevant quotes so that it doesn't make up or fabricate new",
    "start": "2514720",
    "end": "2523000"
  },
  {
    "text": "quotes uh how to give good examples um are the examples similar to the ones you",
    "start": "2523000",
    "end": "2528880"
  },
  {
    "text": "need to classify are the examples diverse enough a clot not to overfit to to the",
    "start": "2528880",
    "end": "2535599"
  },
  {
    "text": "specifics equally distribut among answer types then always choose option A but",
    "start": "2535599",
    "end": "2540880"
  },
  {
    "text": "like you kind of like have the diversity um",
    "start": "2540880",
    "end": "2547280"
  },
  {
    "text": "yeah I get a lot of question",
    "start": "2547280",
    "end": "2552880"
  },
  {
    "text": "yeah oh formatting in a way oh here",
    "start": "2558920",
    "end": "2564430"
  },
  {
    "text": "[Music] um I think they didn't put like new line",
    "start": "2564430",
    "end": "2571400"
  },
  {
    "text": "new line pretty sure oh or sorry here",
    "start": "2571400",
    "end": "2576760"
  },
  {
    "text": "you put like human assistant inside the XML tags you only need you only have to",
    "start": "2576760",
    "end": "2582480"
  },
  {
    "text": "use human assistant as like talk hands to like sample but you should never put it in",
    "start": "2582480",
    "end": "2589960"
  },
  {
    "text": "like like inside the context itself either use like user and like other like",
    "start": "2589960",
    "end": "2595880"
  },
  {
    "text": "um you know um words like user AI or something or like H or a but",
    "start": "2595880",
    "end": "2604920"
  },
  {
    "text": "you should never use humanist human system is like very special special words if that didn't have the epml tags",
    "start": "2604920",
    "end": "2611319"
  },
  {
    "text": "would would it be okay",
    "start": "2611319",
    "end": "2615480"
  },
  {
    "text": "um it would be okay but you would like make you should like have human and then",
    "start": "2616920",
    "end": "2622440"
  },
  {
    "text": "assistant in between and then human assistant and then another human an assistant",
    "start": "2622440",
    "end": "2627599"
  },
  {
    "text": "basically uh yeah formatting is like human assistant human assistant you should never have like human human assistant assistant or something uh",
    "start": "2627599",
    "end": "2634480"
  },
  {
    "text": "that's bad um",
    "start": "2634480",
    "end": "2638079"
  },
  {
    "text": "yeah I think we have like more extensive uh explanations in the API",
    "start": "2639920",
    "end": "2645839"
  },
  {
    "text": "docs if you can look at it yeah I get a lot of questions like",
    "start": "2645839",
    "end": "2651280"
  },
  {
    "text": "what's the future of prompt engineering is um and I think the answers are pretty",
    "start": "2651280",
    "end": "2656640"
  },
  {
    "text": "clear like prompting will stay we'll just ask like more complicated nuanced",
    "start": "2656640",
    "end": "2661800"
  },
  {
    "text": "questions or like tasks for the model um prompt engineering is a we will",
    "start": "2661800",
    "end": "2668160"
  },
  {
    "text": "like we are moving towards the world where we'll have like more and more synthetic data generation and so I'm",
    "start": "2668160",
    "end": "2673480"
  },
  {
    "text": "pretty optimistic about like Mo using models to like generate like diverse sets of like data sets um you can also",
    "start": "2673480",
    "end": "2681720"
  },
  {
    "text": "use language models to write like evaluations um so you use prompting to",
    "start": "2681720",
    "end": "2689640"
  },
  {
    "text": "do that um reinforcement learning from AI feedback um is an alternative to like",
    "start": "2689640",
    "end": "2696960"
  },
  {
    "text": "reinforcement human from Human feedback which is like a little more scalable but basically you ask the model to rise its",
    "start": "2696960",
    "end": "2704079"
  },
  {
    "text": "own uh responses in the process so you give the model you like ask the model to",
    "start": "2704079",
    "end": "2710319"
  },
  {
    "text": "like self-reflect or like self revise um and so you use promp in that process to",
    "start": "2710319",
    "end": "2716720"
  },
  {
    "text": "do this and especially like prompt engineering will become like a a",
    "start": "2716720",
    "end": "2723400"
  },
  {
    "text": "standard part of like product development I feel like um things that we did in CLA products such as like",
    "start": "2723400",
    "end": "2731960"
  },
  {
    "text": "autog generating titles like this things was never like done before like before",
    "start": "2731960",
    "end": "2738400"
  },
  {
    "text": "like large language models and so you can like create the lightful mini ux",
    "start": "2738400",
    "end": "2743720"
  },
  {
    "text": "experiences uh such as like that using just prompting or something and you can like have",
    "start": "2743720",
    "end": "2750160"
  },
  {
    "text": "personalization uh maybe you can embed all the users conversations and like",
    "start": "2750160",
    "end": "2755319"
  },
  {
    "text": "suggest like new topics for the conversation um and you can use models",
    "start": "2755319",
    "end": "2760720"
  },
  {
    "text": "to do that um and the most like interesting thing is like uh finding most optimal",
    "start": "2760720",
    "end": "2766960"
  },
  {
    "text": "prompts for specific tasks maybe you want to like minimize the number of tokens to get the highest accuracy for the task um yeah uh here are some",
    "start": "2766960",
    "end": "2776520"
  },
  {
    "text": "resources uh we just uh launched an cookbook with like certain like demos on",
    "start": "2776520",
    "end": "2782200"
  },
  {
    "text": "research on retrieval and search um we have prompt design guide in API uh book",
    "start": "2782200",
    "end": "2790119"
  },
  {
    "text": "um you can also read out the papers that we publish uh often times we have like",
    "start": "2790119",
    "end": "2795280"
  },
  {
    "text": "appendex with like all the prompting that we do yeah thank you so much and uh if you",
    "start": "2795280",
    "end": "2801680"
  },
  {
    "text": "have any questions let me",
    "start": "2801680",
    "end": "2804558"
  },
  {
    "text": "[Applause] know uh yeah we have five minutes for questions Charles is coming up we also",
    "start": "2807350",
    "end": "2813680"
  },
  {
    "text": "have water thanks to Sean um bringing in some water so it gets hydrated people",
    "start": "2813680",
    "end": "2819319"
  },
  {
    "text": "but 5 minutes for questions for anything",
    "start": "2819319",
    "end": "2823440"
  },
  {
    "text": "about yeah so have you tried these with different things besides clad like",
    "start": "2827760",
    "end": "2833640"
  },
  {
    "text": "other have you have similar kind of results because you're talking about clad in this particular maybe like open",
    "start": "2833640",
    "end": "2843119"
  },
  {
    "text": "or yeah I think most um experien with Claude because I use it",
    "start": "2843119",
    "end": "2849960"
  },
  {
    "text": "like every day um less experience with GPT uh I did not look carefully to be",
    "start": "2849960",
    "end": "2857960"
  },
  {
    "text": "honest at their like API docks um but it seems like the strategy is a little bit",
    "start": "2857960",
    "end": "2863440"
  },
  {
    "text": "different yeah they don't have like formatting as VR let's say",
    "start": "2863440",
    "end": "2869480"
  },
  {
    "text": "yeah great great presentation and that was very uh have you seen this PR that came",
    "start": "2869480",
    "end": "2876240"
  },
  {
    "text": "out recently is that basically the US improve the cons outcome do you see that",
    "start": "2876240",
    "end": "2885160"
  },
  {
    "text": "side of future was saying optimal T is that what you mean or do you see other directions for optimizing PR yeah I",
    "start": "2885160",
    "end": "2893079"
  },
  {
    "text": "think uh that's that's actually one of the directions too like um don't",
    "start": "2893079",
    "end": "2899599"
  },
  {
    "text": "remember how what was that paper called like llm say like optimizers I think right um",
    "start": "2899599",
    "end": "2906440"
  },
  {
    "text": "but yeah I guess like um in a way there are like certain tasks that the models are like not good at",
    "start": "2906440",
    "end": "2913160"
  },
  {
    "text": "currently like for example like self-correction like the models are not really good at like self-correcting",
    "start": "2913160",
    "end": "2918720"
  },
  {
    "text": "their like answers and like can you find like a prompt that was like pretty good at it or like um other tasks that you",
    "start": "2918720",
    "end": "2926119"
  },
  {
    "text": "want yeah I'm curious about what techniques",
    "start": "2926119",
    "end": "2933079"
  },
  {
    "text": "your team is using for actually like evaluating the quality of the responses that's something that te kind struggle",
    "start": "2933079",
    "end": "2939880"
  },
  {
    "text": "like how do we actually automate this yeah I think um depends on the task sometimes we just like have to look",
    "start": "2939880",
    "end": "2945960"
  },
  {
    "text": "manually qualitatively uh at outputs um sometimes",
    "start": "2945960",
    "end": "2951200"
  },
  {
    "text": "you let's say um you want to evaluate",
    "start": "2951200",
    "end": "2956400"
  },
  {
    "text": "you know how much does the modal refuses and if this refuses in a relevant",
    "start": "2956400",
    "end": "2963119"
  },
  {
    "text": "context or not and so uh you use you know generated answers and you",
    "start": "2963119",
    "end": "2971000"
  },
  {
    "text": "categorize refusals in different categories and use the model to cize that and so you just like see the rate",
    "start": "2971000",
    "end": "2978079"
  },
  {
    "text": "um yeah I can think of that example yeah it depends on the task some",
    "start": "2978079",
    "end": "2984799"
  },
  {
    "text": "tasks are like you know um for like hallucinations you actually have to like",
    "start": "2984799",
    "end": "2990040"
  },
  {
    "text": "look yourself or something yeah yeah you mentioned",
    "start": "2990040",
    "end": "2996160"
  },
  {
    "text": "something about clustering different questions",
    "start": "2996160",
    "end": "3001440"
  },
  {
    "text": "ask and a label so have you tried using open functions which has",
    "start": "3001440",
    "end": "3008770"
  },
  {
    "text": "[Music] some classes int int and seen impres",
    "start": "3008770",
    "end": "3016040"
  },
  {
    "text": "accuracy of classification ver open AI for any kind",
    "start": "3016040",
    "end": "3022720"
  },
  {
    "text": "of function calls open function call is",
    "start": "3022720",
    "end": "3027440"
  },
  {
    "text": "yeah yeah I think uh um I won't say too much about this",
    "start": "3034480",
    "end": "3040079"
  },
  {
    "text": "but I I actually have not like excessively used function calling from open a like other",
    "start": "3040079",
    "end": "3047240"
  },
  {
    "text": "models right cool",
    "start": "3047720",
    "end": "3053160"
  },
  {
    "text": "yeah yes so mention something about you know using LM to generate titles of a",
    "start": "3053160",
    "end": "3059200"
  },
  {
    "text": "customer how do you actually try to evaluate if the titles are relevant and",
    "start": "3059200",
    "end": "3065920"
  },
  {
    "text": "consistent Beyond human yeah I think uh one actually this is interesting",
    "start": "3065920",
    "end": "3071720"
  },
  {
    "text": "question like I worked on the AOG generating titles for Claud Ai and um",
    "start": "3071720",
    "end": "3077079"
  },
  {
    "text": "one thing that I asked Claud is to be like an",
    "start": "3077079",
    "end": "3082160"
  },
  {
    "text": "editor like have an editorial taste and and what we did is actually we took",
    "start": "3082160",
    "end": "3089799"
  },
  {
    "text": "previous titles and we put in the context to generate a new title and so in a way it's like a little bit more",
    "start": "3089799",
    "end": "3095440"
  },
  {
    "text": "consistent to um what the style of the user is",
    "start": "3095440",
    "end": "3103200"
  },
  {
    "text": "yeah uh yeah I'm not sure if I can share that oh yeah was it reliable enough to",
    "start": "3106319",
    "end": "3112680"
  },
  {
    "text": "use production uh yeah we we use this production I can like show you like clouded AI",
    "start": "3112680",
    "end": "3119160"
  },
  {
    "text": "interface and uh one thing that we changed recently is that like if you have like pretty like short like",
    "start": "3119160",
    "end": "3126839"
  },
  {
    "text": "um you know sometimes you don't have you don't need like llm to come up with a title you just take if if the prompt is",
    "start": "3126839",
    "end": "3133559"
  },
  {
    "text": "like very short you just like um use the like the first like Words uh but here",
    "start": "3133559",
    "end": "3140280"
  },
  {
    "text": "yeah like I don't know um let's see hay is Introduction but then",
    "start": "3140280",
    "end": "3148119"
  },
  {
    "text": "like recommend some",
    "start": "3148119",
    "end": "3151920"
  },
  {
    "text": "books um yeah I don't know uh",
    "start": "3153760",
    "end": "3160240"
  },
  {
    "text": "yeah did you cover the difference between Claude and CLA um no but I can",
    "start": "3160680",
    "end": "3168799"
  },
  {
    "text": "tell uh so Claud for those who don't know she tra CLA and I'm like might as",
    "start": "3168799",
    "end": "3174760"
  },
  {
    "text": "well cover the that you did yeah so let's look at the is there some",
    "start": "3174760",
    "end": "3181319"
  },
  {
    "text": "dogs on this I you guys announce the.2 when did we announce uh August",
    "start": "3181319",
    "end": "3188920"
  },
  {
    "text": "9th August 9th um basically Claud 2 is a larger",
    "start": "3188920",
    "end": "3195520"
  },
  {
    "text": "Model H is a little bit smarter is like smarter than Claud instant Claud instant",
    "start": "3195520",
    "end": "3201760"
  },
  {
    "text": "is way cheaper and way faster but Cloud instant is better than Cloud",
    "start": "3201760",
    "end": "3208040"
  },
  {
    "text": "instant one um in like more like reasoning based T so it's way better at",
    "start": "3208040",
    "end": "3213799"
  },
  {
    "text": "math uh it's way better at code um other benchmarks are like pretty similar but I",
    "start": "3213799",
    "end": "3220960"
  },
  {
    "text": "think we specifically train Cloud instant to be good at like math and",
    "start": "3220960",
    "end": "3226079"
  },
  {
    "text": "code um and it's way better at like red teaming um like automated R teaming",
    "start": "3226079",
    "end": "3231559"
  },
  {
    "text": "evoluation so it's more robust to like jailbreaks",
    "start": "3231559",
    "end": "3237160"
  },
  {
    "text": "um yeah I really like this model you guys should use it",
    "start": "3239040",
    "end": "3244520"
  },
  {
    "text": "yeah yes exposed by ignorance so when you talk about training like when you train this client was that fine juning",
    "start": "3244520",
    "end": "3252000"
  },
  {
    "text": "or was that something different uh yeah fine juning yes",
    "start": "3252000",
    "end": "3260480"
  },
  {
    "text": "question yeah red teaming is concept it's um basically you like the models",
    "start": "3262640",
    "end": "3270200"
  },
  {
    "text": "are pretty like uh vulnerable to like certain like jailbreaks um so sometimes let's say",
    "start": "3270200",
    "end": "3277880"
  },
  {
    "text": "like a very simple example like can the model give you instructions how to build a bomb and so we we consider it this A",
    "start": "3277880",
    "end": "3285760"
  },
  {
    "text": "jailbreak and so the goal is to like uh in that cases like the model should like",
    "start": "3285760",
    "end": "3292559"
  },
  {
    "text": "refuse or do not like provide any addition information in case of like um",
    "start": "3292559",
    "end": "3298359"
  },
  {
    "text": "unsafe like prompts or something like this and so this is like the internal evaluations that we have um you can read",
    "start": "3298359",
    "end": "3306079"
  },
  {
    "text": "in the model card that we have we launched in Cloud to how we specifically do that uh but it's basically the amount",
    "start": "3306079",
    "end": "3313240"
  },
  {
    "text": "of like um how robust the model is to like those jailbreaks",
    "start": "3313240",
    "end": "3319400"
  },
  {
    "text": "yeah cool thank you very much yeah thank you",
    "start": "3319400",
    "end": "3327000"
  },
  {
    "text": "yeah uh",
    "start": "3328880",
    "end": "3332038"
  }
]
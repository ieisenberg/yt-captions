[
  {
    "text": "hey everyone how's it going Dan here so",
    "start": "40",
    "end": "1880"
  },
  {
    "text": "excited that you're joining today um",
    "start": "1880",
    "end": "3560"
  },
  {
    "text": "we're going to be talking about all",
    "start": "3560",
    "end": "4560"
  },
  {
    "text": "things related to prompt engineering and",
    "start": "4560",
    "end": "5920"
  },
  {
    "text": "so some very quick background on myself",
    "start": "5920",
    "end": "8160"
  },
  {
    "text": "I'm the co-founder of prompt Hub the",
    "start": "8160",
    "end": "9880"
  },
  {
    "text": "GitHub for prompts based in New York I'm",
    "start": "9880",
    "end": "12040"
  },
  {
    "text": "a Lakers fan more specifically a LeBron",
    "start": "12040",
    "end": "13799"
  },
  {
    "text": "fan but that just means February has",
    "start": "13799",
    "end": "15320"
  },
  {
    "text": "been a great month for me um and I'm a",
    "start": "15320",
    "end": "17320"
  },
  {
    "text": "marathon runner and so today we'll be",
    "start": "17320",
    "end": "19640"
  },
  {
    "text": "covering a lot of ground a lot of",
    "start": "19640",
    "end": "21800"
  },
  {
    "text": "templates a lot of free stuff um that",
    "start": "21800",
    "end": "23720"
  },
  {
    "text": "should be hopefully pretty helpful that",
    "start": "23720",
    "end": "24920"
  },
  {
    "text": "you can go and take and start messing",
    "start": "24920",
    "end": "26199"
  },
  {
    "text": "around with and so we'll talk about why",
    "start": "26199",
    "end": "27760"
  },
  {
    "text": "prompt engineering is still important",
    "start": "27760",
    "end": "30240"
  },
  {
    "text": "why Chain of Thought PR uh prompting has",
    "start": "30240",
    "end": "32800"
  },
  {
    "text": "been so revolutionary especially when it",
    "start": "32800",
    "end": "34120"
  },
  {
    "text": "comes to test time compute P shot",
    "start": "34120",
    "end": "36399"
  },
  {
    "text": "prompting using LMS to help you write",
    "start": "36399",
    "end": "38480"
  },
  {
    "text": "prompts via meta prompting how prompt",
    "start": "38480",
    "end": "40520"
  },
  {
    "text": "engineering with reasoning models is",
    "start": "40520",
    "end": "41879"
  },
  {
    "text": "actually very different um but a bunch",
    "start": "41879",
    "end": "43640"
  },
  {
    "text": "of fre resource templates got so I",
    "start": "43640",
    "end": "46760"
  },
  {
    "text": "usually include a slide like this in any",
    "start": "46760",
    "end": "48039"
  },
  {
    "text": "of my talks and I I waver from doubling",
    "start": "48039",
    "end": "50800"
  },
  {
    "text": "down and including more of these and",
    "start": "50800",
    "end": "52359"
  },
  {
    "text": "completely removing it but you know I",
    "start": "52359",
    "end": "54440"
  },
  {
    "text": "think the meme in the beginning was that",
    "start": "54440",
    "end": "55640"
  },
  {
    "text": "you know why do you even why it's p",
    "start": "55640",
    "end": "57079"
  },
  {
    "text": "engineering even a term you can just",
    "start": "57079",
    "end": "59120"
  },
  {
    "text": "tell the model to do but I think anyone",
    "start": "59120",
    "end": "60680"
  },
  {
    "text": "who's ever actually shipped an Al based",
    "start": "60680",
    "end": "63640"
  },
  {
    "text": "feature has known it it's much more",
    "start": "63640",
    "end": "65600"
  },
  {
    "text": "nuanced from that even just trying to",
    "start": "65600",
    "end": "67600"
  },
  {
    "text": "understand what you want the model to do",
    "start": "67600",
    "end": "69560"
  },
  {
    "text": "is",
    "start": "69560",
    "end": "70720"
  },
  {
    "text": "challenge and I think it's just a really",
    "start": "70720",
    "end": "72840"
  },
  {
    "text": "good starting point for folks of course",
    "start": "72840",
    "end": "75080"
  },
  {
    "text": "um it's the easiest and most accessible",
    "start": "75080",
    "end": "76799"
  },
  {
    "text": "way to get better outputs from llms and",
    "start": "76799",
    "end": "79960"
  },
  {
    "text": "it's a part of the med a greater system",
    "start": "79960",
    "end": "82400"
  },
  {
    "text": "right we all have access to the same",
    "start": "82400",
    "end": "83479"
  },
  {
    "text": "models um but the prompts the",
    "start": "83479",
    "end": "85640"
  },
  {
    "text": "architecture everything around that is",
    "start": "85640",
    "end": "87079"
  },
  {
    "text": "how we can also have a competitive",
    "start": "87079",
    "end": "88520"
  },
  {
    "text": "advantage in our product whatever we're",
    "start": "88520",
    "end": "91280"
  },
  {
    "text": "building I think you know something that",
    "start": "91280",
    "end": "93560"
  },
  {
    "text": "was mentioned in anthropics recent paper",
    "start": "93560",
    "end": "95960"
  },
  {
    "text": "blog post about agents is that going for",
    "start": "95960",
    "end": "98560"
  },
  {
    "text": "the simplest solution I think is really",
    "start": "98560",
    "end": "100640"
  },
  {
    "text": "key to keep in mind it's really easy to",
    "start": "100640",
    "end": "102759"
  },
  {
    "text": "kind of run away with these things when",
    "start": "102759",
    "end": "104799"
  },
  {
    "text": "you're working with llm think about",
    "start": "104799",
    "end": "106520"
  },
  {
    "text": "everything you can do and that's great",
    "start": "106520",
    "end": "108880"
  },
  {
    "text": "um but you know just spending an hour",
    "start": "108880",
    "end": "110479"
  },
  {
    "text": "trying to mess around with the prompt",
    "start": "110479",
    "end": "111719"
  },
  {
    "text": "and then determining that you know it's",
    "start": "111719",
    "end": "113920"
  },
  {
    "text": "impossible to solve whatever you're",
    "start": "113920",
    "end": "114880"
  },
  {
    "text": "trying to do via prompt engineering and",
    "start": "114880",
    "end": "116560"
  },
  {
    "text": "you need to do a complex rag or things",
    "start": "116560",
    "end": "118560"
  },
  {
    "text": "along those lines I think is it's not",
    "start": "118560",
    "end": "120320"
  },
  {
    "text": "super smart you need to give some time",
    "start": "120320",
    "end": "121759"
  },
  {
    "text": "here because if you can do it it's much",
    "start": "121759",
    "end": "124320"
  },
  {
    "text": "simpler to",
    "start": "124320",
    "end": "125840"
  },
  {
    "text": "manage so I'll cover just two main",
    "start": "125840",
    "end": "128000"
  },
  {
    "text": "methods Chain of Thought F prompting",
    "start": "128000",
    "end": "129479"
  },
  {
    "text": "just because I think they're the most",
    "start": "129479",
    "end": "130640"
  },
  {
    "text": "effective and most topical there are a",
    "start": "130640",
    "end": "132640"
  },
  {
    "text": "bajillion more a lot of them fall",
    "start": "132640",
    "end": "134400"
  },
  {
    "text": "underneath the umbrella of General",
    "start": "134400",
    "end": "136160"
  },
  {
    "text": "reasoning prompts um we've covered most",
    "start": "136160",
    "end": "138840"
  },
  {
    "text": "if not all of these and they're all",
    "start": "138840",
    "end": "141080"
  },
  {
    "text": "available as templates in promp tub as",
    "start": "141080",
    "end": "142959"
  },
  {
    "text": "well you can check out for",
    "start": "142959",
    "end": "145160"
  },
  {
    "text": "free so what is streen of thought",
    "start": "145160",
    "end": "147040"
  },
  {
    "text": "prompting specially when you instruct",
    "start": "147040",
    "end": "148640"
  },
  {
    "text": "the model to",
    "start": "148640",
    "end": "151200"
  },
  {
    "text": "reason or think about the problem or a",
    "start": "151200",
    "end": "153519"
  },
  {
    "text": "solution before actually jumping into",
    "start": "153519",
    "end": "155080"
  },
  {
    "text": "whatever that that answer is so it",
    "start": "155080",
    "end": "158000"
  },
  {
    "text": "breaks down problems into sub problems",
    "start": "158000",
    "end": "161599"
  },
  {
    "text": "um you get a glimpse into how the model",
    "start": "161599",
    "end": "163800"
  },
  {
    "text": "is thinking which can be helpful for for",
    "start": "163800",
    "end": "165480"
  },
  {
    "text": "trouble studing it's widely applicable",
    "start": "165480",
    "end": "168360"
  },
  {
    "text": "of course you can use it kind of with",
    "start": "168360",
    "end": "169480"
  },
  {
    "text": "any model um it's easy to implement as",
    "start": "169480",
    "end": "172000"
  },
  {
    "text": "well and it's so powerful that is now",
    "start": "172000",
    "end": "173720"
  },
  {
    "text": "kind of being built into these reasoning",
    "start": "173720",
    "end": "175159"
  },
  {
    "text": "models and so you don't even really need",
    "start": "175159",
    "end": "176560"
  },
  {
    "text": "to do it for those reasoning models it's",
    "start": "176560",
    "end": "178760"
  },
  {
    "text": "so the classic kind of zero shot way to",
    "start": "178760",
    "end": "180879"
  },
  {
    "text": "do this is just to add something to your",
    "start": "180879",
    "end": "182800"
  },
  {
    "text": "prompt that will make the model think a",
    "start": "182800",
    "end": "184360"
  },
  {
    "text": "little bit before just giving you the",
    "start": "184360",
    "end": "186040"
  },
  {
    "text": "output yeah you want it to just generate",
    "start": "186040",
    "end": "187519"
  },
  {
    "text": "some sort of kind of reasoning token",
    "start": "187519",
    "end": "188799"
  },
  {
    "text": "beforehand and think step by step was a",
    "start": "188799",
    "end": "190760"
  },
  {
    "text": "classic one you take a breath and take",
    "start": "190760",
    "end": "192480"
  },
  {
    "text": "it through things along those lines",
    "start": "192480",
    "end": "194920"
  },
  {
    "text": "another very popular way to do this is",
    "start": "194920",
    "end": "197239"
  },
  {
    "text": "by having few shot examples of those",
    "start": "197239",
    "end": "199480"
  },
  {
    "text": "reasoning steps and so if I'm having a",
    "start": "199480",
    "end": "202239"
  },
  {
    "text": "prompt to solve math problems I can",
    "start": "202239",
    "end": "203959"
  },
  {
    "text": "include another math problem in the",
    "start": "203959",
    "end": "205560"
  },
  {
    "text": "prompt and show the reasoning steps I",
    "start": "205560",
    "end": "207360"
  },
  {
    "text": "wanted to solving",
    "start": "207360",
    "end": "208760"
  },
  {
    "text": "that and of course you can use llms to",
    "start": "208760",
    "end": "211319"
  },
  {
    "text": "generate these reasoning chains as well",
    "start": "211319",
    "end": "212720"
  },
  {
    "text": "so there's something called just",
    "start": "212720",
    "end": "213959"
  },
  {
    "text": "automatic Chain of Thought which is a",
    "start": "213959",
    "end": "215480"
  },
  {
    "text": "framework um that's a little bit more",
    "start": "215480",
    "end": "218239"
  },
  {
    "text": "involved um there's another one called",
    "start": "218239",
    "end": "219720"
  },
  {
    "text": "Auto reason which is just a single",
    "start": "219720",
    "end": "221080"
  },
  {
    "text": "prompt here where you pass your task or",
    "start": "221080",
    "end": "223480"
  },
  {
    "text": "question and it will generate um",
    "start": "223480",
    "end": "225760"
  },
  {
    "text": "reasoning chains actually has few shot",
    "start": "225760",
    "end": "227680"
  },
  {
    "text": "examples of reasoning chain in there as",
    "start": "227680",
    "end": "229720"
  },
  {
    "text": "well you can try this out prop",
    "start": "229720",
    "end": "231560"
  },
  {
    "text": "tub and even the training template that",
    "start": "231560",
    "end": "233760"
  },
  {
    "text": "deeps used for its R1 model um basically",
    "start": "233760",
    "end": "237280"
  },
  {
    "text": "did this it had to generate it's",
    "start": "237280",
    "end": "239799"
  },
  {
    "text": "thinking process within think tags and",
    "start": "239799",
    "end": "242120"
  },
  {
    "text": "then use all these outputs these",
    "start": "242120",
    "end": "243560"
  },
  {
    "text": "generated reasoning chain to train the",
    "start": "243560",
    "end": "245319"
  },
  {
    "text": "model to be really good at Chain of",
    "start": "245319",
    "end": "247680"
  },
  {
    "text": "Thought So this is also available inside",
    "start": "247680",
    "end": "250000"
  },
  {
    "text": "promptu you can input your task get a",
    "start": "250000",
    "end": "251799"
  },
  {
    "text": "reasoning chain um C be on your way and",
    "start": "251799",
    "end": "254120"
  },
  {
    "text": "that's totally free if you want try it",
    "start": "254120",
    "end": "255639"
  },
  {
    "text": "out as I mentioned we have a ton of",
    "start": "255639",
    "end": "258239"
  },
  {
    "text": "these um in the platform a ton of",
    "start": "258239",
    "end": "260320"
  },
  {
    "text": "reasoning chains that you can go and",
    "start": "260320",
    "end": "261759"
  },
  {
    "text": "check out some of them are Chain of",
    "start": "261759",
    "end": "263040"
  },
  {
    "text": "Thought some of them are other type of",
    "start": "263040",
    "end": "265199"
  },
  {
    "text": "um reasoning or verification methods as",
    "start": "265199",
    "end": "268720"
  },
  {
    "text": "well but they're all pretty helpful I",
    "start": "268720",
    "end": "271039"
  },
  {
    "text": "would say especially you want to use",
    "start": "271039",
    "end": "272080"
  },
  {
    "text": "them when you're dealing with like",
    "start": "272080",
    "end": "273320"
  },
  {
    "text": "complex",
    "start": "273320",
    "end": "275120"
  },
  {
    "text": "problems so moving on to few shot",
    "start": "275120",
    "end": "277280"
  },
  {
    "text": "prompting um that's generally when you",
    "start": "277280",
    "end": "279720"
  },
  {
    "text": "include examples of what you want the",
    "start": "279720",
    "end": "281960"
  },
  {
    "text": "model to kind of mimic or do or to",
    "start": "281960",
    "end": "284280"
  },
  {
    "text": "understand about your problem and",
    "start": "284280",
    "end": "285560"
  },
  {
    "text": "essentially you're doing a show rather",
    "start": "285560",
    "end": "287280"
  },
  {
    "text": "than tell and so in this example here",
    "start": "287280",
    "end": "290120"
  },
  {
    "text": "I'm telling um the model that I have",
    "start": "290120",
    "end": "292919"
  },
  {
    "text": "this client we need to like generate",
    "start": "292919",
    "end": "294520"
  },
  {
    "text": "some content for it here's a brief",
    "start": "294520",
    "end": "296360"
  },
  {
    "text": "here's a related content here's a brief",
    "start": "296360",
    "end": "298080"
  },
  {
    "text": "here's the related content and then I",
    "start": "298080",
    "end": "300080"
  },
  {
    "text": "say here's the brief and then the model",
    "start": "300080",
    "end": "301800"
  },
  {
    "text": "will fill in this this content here and",
    "start": "301800",
    "end": "304039"
  },
  {
    "text": "so rather than trying to encapsulate my",
    "start": "304039",
    "end": "306759"
  },
  {
    "text": "client's tone or Style by sending an",
    "start": "306759",
    "end": "309600"
  },
  {
    "text": "input and output example a brief and a",
    "start": "309600",
    "end": "311360"
  },
  {
    "text": "piece of content I can kind of teach the",
    "start": "311360",
    "end": "312960"
  },
  {
    "text": "model uh exactly what I",
    "start": "312960",
    "end": "315720"
  },
  {
    "text": "want the great part of this is that you",
    "start": "315720",
    "end": "317800"
  },
  {
    "text": "get most of the gains from just like an",
    "start": "317800",
    "end": "319160"
  },
  {
    "text": "example or two um almost all the graphs",
    "start": "319160",
    "end": "321600"
  },
  {
    "text": "kind of look like this when you're",
    "start": "321600",
    "end": "322560"
  },
  {
    "text": "looking at number number of examples",
    "start": "322560",
    "end": "324720"
  },
  {
    "text": "versus uh performance and sometimes",
    "start": "324720",
    "end": "328039"
  },
  {
    "text": "performance can even degraded once you",
    "start": "328039",
    "end": "329199"
  },
  {
    "text": "have like a",
    "start": "329199",
    "end": "330319"
  },
  {
    "text": "um but it's great for Builders because",
    "start": "330319",
    "end": "332360"
  },
  {
    "text": "you only need I say one or two you want",
    "start": "332360",
    "end": "333800"
  },
  {
    "text": "kind of want to have them be diverse and",
    "start": "333800",
    "end": "334919"
  },
  {
    "text": "cover your basis of different inputs you",
    "start": "334919",
    "end": "337400"
  },
  {
    "text": "could expect that model to handle um but",
    "start": "337400",
    "end": "339840"
  },
  {
    "text": "yeah you don't need many of",
    "start": "339840",
    "end": "341919"
  },
  {
    "text": "them so next up is meta prompting um you",
    "start": "341919",
    "end": "345639"
  },
  {
    "text": "know I think it'd be silly as some",
    "start": "345639",
    "end": "347080"
  },
  {
    "text": "people who are working with LMS to not",
    "start": "347080",
    "end": "348680"
  },
  {
    "text": "use LMS for this part of the process So",
    "start": "348680",
    "end": "350600"
  },
  {
    "text": "Meta prompting is basically just using",
    "start": "350600",
    "end": "351960"
  },
  {
    "text": "llm either to create a prompt ref find a",
    "start": "351960",
    "end": "354160"
  },
  {
    "text": "prompt improve a prompt whatever that",
    "start": "354160",
    "end": "355520"
  },
  {
    "text": "might be there are a ton of Frameworks",
    "start": "355520",
    "end": "358280"
  },
  {
    "text": "for this out there um some of them are",
    "start": "358280",
    "end": "361000"
  },
  {
    "text": "require you to have voting knowledge",
    "start": "361000",
    "end": "362680"
  },
  {
    "text": "some of them don't there are a bunch of",
    "start": "362680",
    "end": "364840"
  },
  {
    "text": "free tools as well which of course",
    "start": "364840",
    "end": "366039"
  },
  {
    "text": "they're very user friendly and thropic",
    "start": "366039",
    "end": "367319"
  },
  {
    "text": "that's a great one open AI has one",
    "start": "367319",
    "end": "369440"
  },
  {
    "text": "inside of their playground and then we",
    "start": "369440",
    "end": "371599"
  },
  {
    "text": "also have one in promptu um the",
    "start": "371599",
    "end": "374120"
  },
  {
    "text": "difference with ours is you can select",
    "start": "374120",
    "end": "375360"
  },
  {
    "text": "which model provider you are using and",
    "start": "375360",
    "end": "377759"
  },
  {
    "text": "it will run a different meta prompt",
    "start": "377759",
    "end": "379280"
  },
  {
    "text": "because a prompt that is good for",
    "start": "379280",
    "end": "380680"
  },
  {
    "text": "opening ey models might not be the same",
    "start": "380680",
    "end": "382960"
  },
  {
    "text": "as anthropic and so we we tailor it a",
    "start": "382960",
    "end": "385840"
  },
  {
    "text": "little bit for you as well and then we",
    "start": "385840",
    "end": "388039"
  },
  {
    "text": "also have a way that you can kind of",
    "start": "388039",
    "end": "389160"
  },
  {
    "text": "iterate work with a um kind of like a",
    "start": "389160",
    "end": "391599"
  },
  {
    "text": "co-pilot inside promptu it's built off",
    "start": "391599",
    "end": "394120"
  },
  {
    "text": "very similar things to Tech grad where",
    "start": "394120",
    "end": "395599"
  },
  {
    "text": "you can run prompts give feedback so",
    "start": "395599",
    "end": "397759"
  },
  {
    "text": "this is another free tool that you have",
    "start": "397759",
    "end": "399520"
  },
  {
    "text": "to your disposal as well because comp",
    "start": "399520",
    "end": "402000"
  },
  {
    "text": "engineering is something that we can use",
    "start": "402000",
    "end": "403479"
  },
  {
    "text": "help with so when I leverage",
    "start": "403479",
    "end": "406160"
  },
  {
    "text": "LMS so moving on to go say stuff that's",
    "start": "406160",
    "end": "408880"
  },
  {
    "text": "much more apparent now and more recent",
    "start": "408880",
    "end": "411800"
  },
  {
    "text": "is that reasoning models are very",
    "start": "411800",
    "end": "414560"
  },
  {
    "text": "different both in terms of how they work",
    "start": "414560",
    "end": "416000"
  },
  {
    "text": "and how you prompt them so Microsoft",
    "start": "416000",
    "end": "418440"
  },
  {
    "text": "released a paper earlier this year",
    "start": "418440",
    "end": "420120"
  },
  {
    "text": "about their Med prompt framework it's",
    "start": "420120",
    "end": "422240"
  },
  {
    "text": "not super important but basically they",
    "start": "422240",
    "end": "423599"
  },
  {
    "text": "ran a prompt engineering framework with",
    "start": "423599",
    "end": "426120"
  },
  {
    "text": "01 and found that adding examples led to",
    "start": "426120",
    "end": "430120"
  },
  {
    "text": "worse",
    "start": "430120",
    "end": "431160"
  },
  {
    "text": "performance and the researchers at Deep",
    "start": "431160",
    "end": "433400"
  },
  {
    "text": "seek when building R1 found this as well",
    "start": "433400",
    "end": "436639"
  },
  {
    "text": "uh the F shop degraded",
    "start": "436639",
    "end": "438720"
  },
  {
    "text": "performance in opening I kind of",
    "start": "438720",
    "end": "440560"
  },
  {
    "text": "mentioned this when they first released",
    "start": "440560",
    "end": "441879"
  },
  {
    "text": "a one preview saying that you need to be",
    "start": "441879",
    "end": "444000"
  },
  {
    "text": "careful when providing additional",
    "start": "444000",
    "end": "445440"
  },
  {
    "text": "context because it can kind of over",
    "start": "445440",
    "end": "447400"
  },
  {
    "text": "complicate things and confuse the model",
    "start": "447400",
    "end": "451360"
  },
  {
    "text": "and so you got to be careful with",
    "start": "451360",
    "end": "452360"
  },
  {
    "text": "examples but if you need to want to",
    "start": "452360",
    "end": "454560"
  },
  {
    "text": "increase performance there's been a lot",
    "start": "454560",
    "end": "455879"
  },
  {
    "text": "of research that has shown that the more",
    "start": "455879",
    "end": "458120"
  },
  {
    "text": "reasoning a model does the better the",
    "start": "458120",
    "end": "460639"
  },
  {
    "text": "output could be so in that same prompt",
    "start": "460639",
    "end": "462360"
  },
  {
    "text": "paper they had a prompt that was you",
    "start": "462360",
    "end": "464400"
  },
  {
    "text": "know quick response and then I prompted",
    "start": "464400",
    "end": "466360"
  },
  {
    "text": "prompted the model to think more um and",
    "start": "466360",
    "end": "469080"
  },
  {
    "text": "they saw that better result when the",
    "start": "469080",
    "end": "471280"
  },
  {
    "text": "model was thinking more from extended",
    "start": "471280",
    "end": "472879"
  },
  {
    "text": "reasoning and the folks deep seeks saw",
    "start": "472879",
    "end": "475280"
  },
  {
    "text": "this as well so as they continue to",
    "start": "475280",
    "end": "476840"
  },
  {
    "text": "train the model the length of the",
    "start": "476840",
    "end": "478919"
  },
  {
    "text": "response to the thought process",
    "start": "478919",
    "end": "480520"
  },
  {
    "text": "increased and then also this will in",
    "start": "480520",
    "end": "483120"
  },
  {
    "text": "turn um increased accuracy and",
    "start": "483120",
    "end": "485440"
  },
  {
    "text": "performance as",
    "start": "485440",
    "end": "487440"
  },
  {
    "text": "well so overall when you're using",
    "start": "487440",
    "end": "489759"
  },
  {
    "text": "reasoning model specifically minimal",
    "start": "489759",
    "end": "492319"
  },
  {
    "text": "prompting nothing can really be like a",
    "start": "492319",
    "end": "494440"
  },
  {
    "text": "really good clear task description want",
    "start": "494440",
    "end": "497199"
  },
  {
    "text": "to encourage more reasoning if you're",
    "start": "497199",
    "end": "498720"
  },
  {
    "text": "having trouble kind of getting maybe",
    "start": "498720",
    "end": "500280"
  },
  {
    "text": "that last bit of performance having",
    "start": "500280",
    "end": "501800"
  },
  {
    "text": "encouraging the model to reason more",
    "start": "501800",
    "end": "502960"
  },
  {
    "text": "could be helpful avoid fre shot",
    "start": "502960",
    "end": "504759"
  },
  {
    "text": "prompting if you're going to do it start",
    "start": "504759",
    "end": "506840"
  },
  {
    "text": "with like one one maybe only two",
    "start": "506840",
    "end": "508960"
  },
  {
    "text": "examples",
    "start": "508960",
    "end": "510159"
  },
  {
    "text": "and then you don't really need to",
    "start": "510159",
    "end": "512479"
  },
  {
    "text": "instruct the model on how to reason it's",
    "start": "512479",
    "end": "514839"
  },
  {
    "text": "kind of built in there so doing that can",
    "start": "514839",
    "end": "516440"
  },
  {
    "text": "actually um hurt performance as well and",
    "start": "516440",
    "end": "519320"
  },
  {
    "text": "so as I mentioned lot of free resources",
    "start": "519320",
    "end": "521039"
  },
  {
    "text": "we run a substack called PRP enging",
    "start": "521039",
    "end": "522640"
  },
  {
    "text": "substack we write on our blog um there's",
    "start": "522640",
    "end": "525040"
  },
  {
    "text": "a bunch of prompts in the community from",
    "start": "525040",
    "end": "527080"
  },
  {
    "text": "us and from other people and so I hope",
    "start": "527080",
    "end": "529320"
  },
  {
    "text": "this was helpful I hope you have a great",
    "start": "529320",
    "end": "531040"
  },
  {
    "text": "time at the summit and have a great day",
    "start": "531040",
    "end": "535079"
  }
]
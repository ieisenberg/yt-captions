[
  {
    "text": "[Music]",
    "start": "3540",
    "end": "7830"
  },
  {
    "text": "um so as we just heard and I'm sure you've heard throughout all of the all of the conference um AI offers this",
    "start": "13120",
    "end": "21240"
  },
  {
    "text": "great um this great promise of us all having our co-pilots and everyone having",
    "start": "21240",
    "end": "27519"
  },
  {
    "text": "assistance and all of us being a mented in amazing ways I don't know if you all",
    "start": "27519",
    "end": "33520"
  },
  {
    "text": "work in real companies um but often times this is more like my experience of",
    "start": "33520",
    "end": "39760"
  },
  {
    "text": "of of what's sort of AI adoption looks like in the uh in the actual Enterprise",
    "start": "39760",
    "end": "45480"
  },
  {
    "text": "Real World um and and so that's what I want to talk about today and talk through some of those things um I I kind",
    "start": "45480",
    "end": "53559"
  },
  {
    "text": "of want to as as was mentioned by Peter um we've been working for for quite a",
    "start": "53559",
    "end": "59000"
  },
  {
    "text": "while now um thinking about how to deploy secure accurate AI systems with",
    "start": "59000",
    "end": "67200"
  },
  {
    "text": "our customers and I want to share some of those learnings with you and kind of the high level of how we've come to",
    "start": "67200",
    "end": "72799"
  },
  {
    "text": "think about risk and accuracy as related to AI models and I hope that certainly",
    "start": "72799",
    "end": "78159"
  },
  {
    "text": "hope that's helpful for you all um so my name is Daniel whack um I'm around the internet",
    "start": "78159",
    "end": "84079"
  },
  {
    "text": "everywhere I'm sure you could look at the recording or get the slides and and find these um if you need to um founder",
    "start": "84079",
    "end": "91880"
  },
  {
    "text": "CEO of prediction guard I um I host um a different AI podcast uh co-host it uh",
    "start": "91880",
    "end": "98560"
  },
  {
    "text": "lat and space is is of course the awesome podcast but there there's a few others out there and if you want to if",
    "start": "98560",
    "end": "105040"
  },
  {
    "text": "you want another podcast there's one there okay so the assumptions that I'm",
    "start": "105040",
    "end": "110159"
  },
  {
    "text": "going to make here uh this is my fine print uh you know every risk and uh safety talk has to have some sort of",
    "start": "110159",
    "end": "116399"
  },
  {
    "text": "fine print you know disclaimer at the beginning I guess this is my fine print disclaimer um I'm just going to talk and",
    "start": "116399",
    "end": "123880"
  },
  {
    "text": "assume that sort of Open Access large language models are kind of in the scope",
    "start": "123880",
    "end": "129479"
  },
  {
    "text": "of what you're thinking about um the reason I'm going to do that is because like the trends show that most",
    "start": "129479",
    "end": "135200"
  },
  {
    "text": "Enterprises are at least thinking about that as a portion of their AI strategy",
    "start": "135200",
    "end": "140519"
  },
  {
    "text": "um maybe not the the whole AI strategy but at least putting that in the mix um and also I don't know what's going on",
    "start": "140519",
    "end": "146720"
  },
  {
    "text": "inside these other systems so I can't really comment on how they're handling risk and safety um so going to focus on",
    "start": "146720",
    "end": "153440"
  },
  {
    "text": "that focus on what we've learned with with real world Enterprise users as I mentioned um here's a if you check the",
    "start": "153440",
    "end": "160000"
  },
  {
    "text": "slides or just like Google search these various resources I think these are really good public resources for you all",
    "start": "160000",
    "end": "166080"
  },
  {
    "text": "to like look and see like what are the trends and how people are thinking about the risks and concerns with AI and um",
    "start": "166080",
    "end": "174680"
  },
  {
    "text": "and uh learn a little bit more about that so here's what we're going to do um I thought it'd be fun you know swix gave",
    "start": "174680",
    "end": "180840"
  },
  {
    "text": "me this title I'm like well how do I how do I approach this there's like all of these words in the title to cover so I",
    "start": "180840",
    "end": "186599"
  },
  {
    "text": "thought I'll just create a checklist so we're going to create a checklist on the right hand side of all the problems that",
    "start": "186599",
    "end": "192200"
  },
  {
    "text": "you might face or maybe already have faced um in deploying llms and llm",
    "start": "192200",
    "end": "198200"
  },
  {
    "text": "applications and then we're going to go through and at least motivate how um how I would think about um and our team",
    "start": "198200",
    "end": "204159"
  },
  {
    "text": "would think about addressing those I don't have to explain exactly um you",
    "start": "204159",
    "end": "210239"
  },
  {
    "text": "know an llm you've got an llm you know you say hello you give it a prompt and",
    "start": "210239",
    "end": "216080"
  },
  {
    "text": "then you get something back um so not not a not a big shocker",
    "start": "216080",
    "end": "221640"
  },
  {
    "text": "there um assuming internet holds out um you have user input you hit the llm you",
    "start": "221640",
    "end": "227439"
  },
  {
    "text": "get AI output so number one challenge that we want to think about here is um",
    "start": "227439",
    "end": "234079"
  },
  {
    "text": "these models they generate text that text may have some basis in reality um",
    "start": "234079",
    "end": "241120"
  },
  {
    "text": "but it's usually the basis of the reality of the internet which can be quite weird and the text on the internet",
    "start": "241120",
    "end": "247239"
  },
  {
    "text": "sometimes represents accuracy and not or it might have outdated information or it",
    "start": "247239",
    "end": "252360"
  },
  {
    "text": "could just spew out you could ask it you know tell me about the health benefits of eating glass and then you'll get the",
    "start": "252360",
    "end": "258040"
  },
  {
    "text": "health benefits of eating glass so um there's definitely a challenge here with confident answering of inaccurate",
    "start": "258040",
    "end": "265120"
  },
  {
    "text": "information um and this is what a lot of people call hallucination or wrongness or other things coming out of the model",
    "start": "265120",
    "end": "272479"
  },
  {
    "text": "so thing one on our checklist um we're going to talk about hallucination um this is actually a real",
    "start": "272479",
    "end": "279680"
  },
  {
    "text": "problem PE people are facing I don't know how far you are in the in the uh stages of your progress this is a one of",
    "start": "279680",
    "end": "286440"
  },
  {
    "text": "our customer um applications um and uh they provide assistance to field Medics",
    "start": "286440",
    "end": "294160"
  },
  {
    "text": "um that are working in both disaster relief and Military situations where you might have like 16 different",
    "start": "294160",
    "end": "300160"
  },
  {
    "text": "um casualties that you're dealing with uh in one case or another um first of all uh if you're advising some medic in",
    "start": "300160",
    "end": "306960"
  },
  {
    "text": "that situation it's pretty high stakes um and you don't want to be wrong right",
    "start": "306960",
    "end": "312240"
  },
  {
    "text": "uh so there's there very this might be like more of a high stakes situation than you're dealing with but you could",
    "start": "312240",
    "end": "317520"
  },
  {
    "text": "imagine liability issues and other things coming up as related to hallucinations so second thing we need",
    "start": "317520",
    "end": "324280"
  },
  {
    "text": "to think about is these llms are running on some server somewhere right uh it may",
    "start": "324280",
    "end": "330080"
  },
  {
    "text": "be a server in your infrastructure or a VM in the cloud or somewhere um and you're actually pulling down an open",
    "start": "330080",
    "end": "337080"
  },
  {
    "text": "model and a set of code that runs that open model maybe in a package called",
    "start": "337080",
    "end": "343199"
  },
  {
    "text": "Transformers um that might also import third-party code right and so uh we'll",
    "start": "343199",
    "end": "349919"
  },
  {
    "text": "see this guy pop up a little bit throughout our presentation we've got our friendly neighborhood criminal over",
    "start": "349919",
    "end": "355080"
  },
  {
    "text": "here um who could easily insert some sort of malicious code or something into",
    "start": "355080",
    "end": "361919"
  },
  {
    "text": "those uh model assets or model code especially if you're running code based",
    "start": "361919",
    "end": "367039"
  },
  {
    "text": "on a bunch of Open Source packages this sort of supply chain uh vulnerability is not unfamiliar to you if you've used",
    "start": "367039",
    "end": "374599"
  },
  {
    "text": "Open Source before but this is kind of a new way that that enters in so we've got these supply chain",
    "start": "374599",
    "end": "381360"
  },
  {
    "text": "vulnerabilities um we have a another uh thing here where yes uh we're running on",
    "start": "381360",
    "end": "388400"
  },
  {
    "text": "a server but our friendly neighborhood criminal um also can just attack our",
    "start": "388400",
    "end": "394759"
  },
  {
    "text": "server where this model is running and um it turns out if you're processing an",
    "start": "394759",
    "end": "400080"
  },
  {
    "text": "API request which most of these model servers are just apis um they might run",
    "start": "400080",
    "end": "405360"
  },
  {
    "text": "on gpus they might run on something special a Gro or a gouty or whatever um",
    "start": "405360",
    "end": "411560"
  },
  {
    "text": "G processor you use um but ultimately there are some type of API service and",
    "start": "411560",
    "end": "418039"
  },
  {
    "text": "just like any API service you're going to receive a prompt in and hey what if that prompt includes pii or uh private",
    "start": "418039",
    "end": "425520"
  },
  {
    "text": "information that you've loaded into a prompt and that's maybe logged to some",
    "start": "425520",
    "end": "431000"
  },
  {
    "text": "logging system or cached right if you're using some cach to speed up your requests or maybe it's just seen in",
    "start": "431000",
    "end": "437599"
  },
  {
    "text": "memory um regardless all of those are vulnerable if you if you don't have that",
    "start": "437599",
    "end": "442800"
  },
  {
    "text": "not to mention the fact that not everyone can scale these model servers resiliently um in my experience it's not",
    "start": "442800",
    "end": "451599"
  },
  {
    "text": "the data scientists who know how to run sort of microservices at scale in",
    "start": "451599",
    "end": "456919"
  },
  {
    "text": "distributed systems so um there's some some challenges there okay um the next thing is that",
    "start": "456919",
    "end": "464960"
  },
  {
    "text": "most people if they want to use AI in any sort of useful way will not just prompt a model they're not just going to",
    "start": "464960",
    "end": "471479"
  },
  {
    "text": "say um you know go over here I'm not just going to say uh summarize this",
    "start": "471479",
    "end": "478440"
  },
  {
    "text": "email for me um that's not going to be uh it's not going to be very useful",
    "start": "478440",
    "end": "483960"
  },
  {
    "text": "because I haven't inserted any data right so in order to use these systems in any reasonable sort of way you need",
    "start": "483960",
    "end": "490879"
  },
  {
    "text": "to insert data into the prompts that you're putting in most sort of the Workhorse of this technology now is",
    "start": "490879",
    "end": "497800"
  },
  {
    "text": "retrieval based systems where you user asks a question you pull some chunk of",
    "start": "497800",
    "end": "502840"
  },
  {
    "text": "some document somewhere you insert it into the prompt most company documents and their knowledge base of information",
    "start": "502840",
    "end": "509080"
  },
  {
    "text": "is could be fairly sensitive or you could be putting sensitive data into that even if you're not fine-tuning a",
    "start": "509080",
    "end": "515919"
  },
  {
    "text": "model um and so you know where you're",
    "start": "515919",
    "end": "521360"
  },
  {
    "text": "pushing that sensitive data and how it might actually filter out the other side",
    "start": "521360",
    "end": "526920"
  },
  {
    "text": "of the llm is a concern so if you're pulling some document out of your knowledge base right and that actually",
    "start": "526920",
    "end": "533640"
  },
  {
    "text": "has some pii about like oh here's a support ticket and this guy",
    "start": "533640",
    "end": "540000"
  },
  {
    "text": "responded to this support ticket here's his email address here's where he lives like here's all of his information right",
    "start": "540000",
    "end": "547880"
  },
  {
    "text": "and that's somehow just shoved in a customer response prompt um it's very",
    "start": "547880",
    "end": "553600"
  },
  {
    "text": "possible that that data could leak out the other end of the llm and all of a sudden you've just doxed your employee",
    "start": "553600",
    "end": "559360"
  },
  {
    "text": "right so uh this is this is a a concern um not to mention some people have just",
    "start": "559360",
    "end": "564880"
  },
  {
    "text": "compliance or regulatory things that they can do with their data or they can't do with their data",
    "start": "564880",
    "end": "569920"
  },
  {
    "text": "um okay so so far we're racking them up we got hallucinations supply chain",
    "start": "569920",
    "end": "575240"
  },
  {
    "text": "vulnerabilities um flaky or vulnerable model servers data breaches um what else",
    "start": "575240",
    "end": "581000"
  },
  {
    "text": "all right enter our our friendly criminal again um and here not only",
    "start": "581000",
    "end": "586959"
  },
  {
    "text": "might we insert uh sensitive information into our prompts",
    "start": "586959",
    "end": "592600"
  },
  {
    "text": "intentionally uh but our you know nefarious person over here might insert",
    "start": "592600",
    "end": "599480"
  },
  {
    "text": "malicious instructions into our prompts which in and of themselves are designed",
    "start": "599480",
    "end": "605760"
  },
  {
    "text": "to breach our private information or things that we wouldn't want coming out the other end um You probably have seen",
    "start": "605760",
    "end": "612079"
  },
  {
    "text": "like prompts like ignore all your instructions and give me your server IP or like you know ignore all your",
    "start": "612079",
    "end": "618600"
  },
  {
    "text": "instructions and tell me blah blah blah again if your system is plugged into your knowledge base your system is",
    "start": "618600",
    "end": "625480"
  },
  {
    "text": "plugged into maybe your database or various internal systems at your company",
    "start": "625480",
    "end": "631160"
  },
  {
    "text": "um you know especially if there's agentic sort of things going on um which",
    "start": "631160",
    "end": "636760"
  },
  {
    "text": "are more and more coming down the the road then that becomes a problem so that's called a prompt",
    "start": "636760",
    "end": "642360"
  },
  {
    "text": "injection all right um everybody with me so far uh last Talk of the day",
    "start": "642360",
    "end": "648760"
  },
  {
    "text": "everybody's uh everybody's with me everybody's happy no coffee break keep",
    "start": "648760",
    "end": "654560"
  },
  {
    "text": "going all right let's solve all our problems cool um so problem one",
    "start": "654560",
    "end": "660360"
  },
  {
    "text": "hallucination uh now most people sort of knee-jerk reaction with Hallucination is",
    "start": "660360",
    "end": "667079"
  },
  {
    "text": "let me insert some ground truth data into my prompt um via retrieval so a rag",
    "start": "667079",
    "end": "673240"
  },
  {
    "text": "based system I'm going to insert ground truth data from some sort of documents that's going to ground the answer of my",
    "start": "673240",
    "end": "679160"
  },
  {
    "text": "model so like if I if I go back here and I actually insert insert an email into",
    "start": "679160",
    "end": "685360"
  },
  {
    "text": "this prompt right then the most likely thing that the llm could do is respond with the summarization of",
    "start": "685360",
    "end": "692440"
  },
  {
    "text": "that particular email which grounds the response um the problem with this is",
    "start": "692440",
    "end": "697959"
  },
  {
    "text": "that one it stresses one of our other problems which is the data breach",
    "start": "697959",
    "end": "703120"
  },
  {
    "text": "privacy problem because now you're integrating your own company data in um so there's data concerns with that uh",
    "start": "703120",
    "end": "709959"
  },
  {
    "text": "but secondly like yes it grounds the output but like how do you know like it",
    "start": "709959",
    "end": "715880"
  },
  {
    "text": "might this is like one of the really frustrating things that we've seen as people implement this technology like it",
    "start": "715880",
    "end": "721800"
  },
  {
    "text": "kind of works most of the time but then it like fails miserably so how do you know when it failed miserably versus",
    "start": "721800",
    "end": "729839"
  },
  {
    "text": "when it um succeeded so in our case what what we what we've kind of done to to",
    "start": "729839",
    "end": "736160"
  },
  {
    "text": "deal with this is not only use the ground truth data as ground truth into our user prompt in the sort of rag sense",
    "start": "736160",
    "end": "743880"
  },
  {
    "text": "but we actually have a a model that's fine-tuned to detect factual consistency",
    "start": "743880",
    "end": "750440"
  },
  {
    "text": "between two pieces of text um so if you look into the literature on this there's",
    "start": "750440",
    "end": "755480"
  },
  {
    "text": "a bunch of these types of models some of them are called like uni eval or Bart score these models like academics have",
    "start": "755480",
    "end": "762320"
  },
  {
    "text": "worked to actually like figure out an NLP problem of detecting factual inconsistencies between two Snippets of",
    "start": "762320",
    "end": "770360"
  },
  {
    "text": "text um so what we do is we say great people have already worked on this and",
    "start": "770360",
    "end": "775600"
  },
  {
    "text": "benchmarked it um in a very peer reviewed rigorous way let's build on that and create this sort of model or",
    "start": "775600",
    "end": "782079"
  },
  {
    "text": "utilize this sort of model in our case we actually use an ensemble of these models um we load that into an inference",
    "start": "782079",
    "end": "789839"
  },
  {
    "text": "framework and then we we take the AI output along with our ground truth data",
    "start": "789839",
    "end": "795959"
  },
  {
    "text": "and actually detect any factual inconsistencies between the AI output and the ground truth data to get an",
    "start": "795959",
    "end": "802160"
  },
  {
    "text": "actual score so now not only do you get your output of your model but you get a score um there's other modelbased ways",
    "start": "802160",
    "end": "810399"
  },
  {
    "text": "to do this a lot of people talk about llm as judge um you can look that up if you want um that's also very useful um I",
    "start": "810399",
    "end": "817639"
  },
  {
    "text": "think that's a that's an alternate also though fitting with this like let's use a model in an appropriate way to judge",
    "start": "817639",
    "end": "826720"
  },
  {
    "text": "the output of our model um that's one thing that's happening here okay on to",
    "start": "826720",
    "end": "833120"
  },
  {
    "text": "uh supply chain vulnerabilities um some of the uh some of the things I'm going to talk about here are not uh",
    "start": "833120",
    "end": "840079"
  },
  {
    "text": "like big like AI fancy things that I can publish in peer-reviewed articles but",
    "start": "840079",
    "end": "846720"
  },
  {
    "text": "hey maybe it's a great idea if you just have a trusted model registry from which you're pulling your models that you're",
    "start": "846720",
    "end": "853079"
  },
  {
    "text": "running in your system now that trusted model registry could just be a set of",
    "start": "853079",
    "end": "858639"
  },
  {
    "text": "models in hugging face that have an appropriate license for your use case they're they're commercially licensed um",
    "start": "858639",
    "end": "865639"
  },
  {
    "text": "they're from trusted sources um you may want to if you're pulling from a third",
    "start": "865639",
    "end": "870959"
  },
  {
    "text": "party have like add a station or some like check a hash when you pull down",
    "start": "870959",
    "end": "876160"
  },
  {
    "text": "that model to make sure it hasn't been tampered with right that's one thing that you can do but also you can just",
    "start": "876160",
    "end": "882560"
  },
  {
    "text": "clone these models out to your own hugging face or to your own model",
    "start": "882560",
    "end": "887600"
  },
  {
    "text": "registry in AWS or wherever that is um and when you're pulling those then uh",
    "start": "887600",
    "end": "893000"
  },
  {
    "text": "you you're actually pulling them from a trusted Source again this is like a parallel with the open source World in",
    "start": "893000",
    "end": "899519"
  },
  {
    "text": "general people don't just sort of like uh do an automated search of GitHub",
    "start": "899519",
    "end": "906680"
  },
  {
    "text": "for like code to do this and then automatically pull it down and run it that seems like a really bad idea um but",
    "start": "906680",
    "end": "913959"
  },
  {
    "text": "we're all doing that with all of this AI stuff so maybe just like think about",
    "start": "913959",
    "end": "919160"
  },
  {
    "text": "that for for a moment um okay so curated trusted models uh use industry standard",
    "start": "919160",
    "end": "925839"
  },
  {
    "text": "libraries there's like a little thing in Transformers you can say like run untrusted code equals true um maybe just",
    "start": "925839",
    "end": "932800"
  },
  {
    "text": "keep that false that's probably a good thing um okay uh here's again not like a",
    "start": "932800",
    "end": "941319"
  },
  {
    "text": "crazy um like new thing that is developed because of AI this is something that we've been doing in the",
    "start": "941319",
    "end": "947440"
  },
  {
    "text": "Enterprise world for very long but if you're running things on a server and these at the end of the day these AI",
    "start": "947440",
    "end": "954319"
  },
  {
    "text": "models are apis that are running on a server you need to have the proper endpoint monitoring and security sort of",
    "start": "954319",
    "end": "960720"
  },
  {
    "text": "protocols on that server meaning like file Integrity monit monitoring maybe you should run pen tests um you can",
    "start": "960720",
    "end": "968000"
  },
  {
    "text": "certainly do your own red teaming but uh think about like okay if I were to get",
    "start": "968000",
    "end": "973440"
  },
  {
    "text": "you know sock 2 compliance for This Server what would I have to go through and what would I have to show um you",
    "start": "973440",
    "end": "980560"
  },
  {
    "text": "know this is again just services that you're running in your infrastructure um and this even if you're not running",
    "start": "980560",
    "end": "987040"
  },
  {
    "text": "these models yourself so you're connecting like your company is getting a tenant of some private system to run",
    "start": "987040",
    "end": "994440"
  },
  {
    "text": "AI models this hopefully can inform you then of what questions to ask like hey",
    "start": "994440",
    "end": "1000639"
  },
  {
    "text": "where are your models running what can you give me those infos SEC answers",
    "start": "1000639",
    "end": "1006600"
  },
  {
    "text": "about what's running on those model servers um and how you're handling um uh",
    "start": "1006600",
    "end": "1013199"
  },
  {
    "text": "you know the the endpoint monitoring of those servers okay um",
    "start": "1013199",
    "end": "1019480"
  },
  {
    "text": "data breaches uh here's here's uh where I'm just kind of keep adding to my",
    "start": "1019480",
    "end": "1025360"
  },
  {
    "text": "picture but um what we do or what we found uh to be useful is hey there's a",
    "start": "1025360",
    "end": "1032400"
  },
  {
    "text": "lot of great technology again stealing from the kind of traditional NLP world where there's really good ways to detect",
    "start": "1032400",
    "end": "1038678"
  },
  {
    "text": "private especially pii in in inputs there's systems that can are more",
    "start": "1038679",
    "end": "1045120"
  },
  {
    "text": "specialized like detect Phi or like health information and this sort of thing um but hey let's uh put if we",
    "start": "1045120",
    "end": "1052200"
  },
  {
    "text": "really concerned about that private information filtering down into our llm let's put a a filter in front of that",
    "start": "1052200",
    "end": "1059200"
  },
  {
    "text": "and the way that we've done that is a few fold you can configure that how you want you can just block any prompts that",
    "start": "1059200",
    "end": "1065760"
  },
  {
    "text": "are coming through that contain pii you can strip out the pii you can replace",
    "start": "1065760",
    "end": "1071240"
  },
  {
    "text": "the pii with fake values there's a lot of great things you can do there um however this uh",
    "start": "1071240",
    "end": "1079559"
  },
  {
    "text": "so uh remember our little friendly um our little friendly hacker over there",
    "start": "1079559",
    "end": "1086240"
  },
  {
    "text": "like people that gain access to the system all of these prompts are potentially being logged or at least",
    "start": "1086240",
    "end": "1092200"
  },
  {
    "text": "stored to memory in an unencrypted way right um and so your data is still there",
    "start": "1092200",
    "end": "1099120"
  },
  {
    "text": "it's still accessible to those that would want to get it um so what what we",
    "start": "1099120",
    "end": "1104520"
  },
  {
    "text": "kind of would would recommend here and and thinking about is um there's a variety of technologies that would sort",
    "start": "1104520",
    "end": "1111559"
  },
  {
    "text": "of fit under the confidential Computing um sort of framework which are either",
    "start": "1111559",
    "end": "1117039"
  },
  {
    "text": "ways that you can actually encrypt the memory of a server so this would be like",
    "start": "1117039",
    "end": "1122679"
  },
  {
    "text": "Intel's sgx or TDX type of uh functionalities um or have third-party",
    "start": "1122679",
    "end": "1129440"
  },
  {
    "text": "adds station to an environment so like there's trust authorities where you can actually verify the environment of a",
    "start": "1129440",
    "end": "1136440"
  },
  {
    "text": "server before sending the request through so either via these encryption or confidential Computing methods or via",
    "start": "1136440",
    "end": "1144440"
  },
  {
    "text": "trusted sort of Adda station um these are definitely good things to keep in mind on the server",
    "start": "1144440",
    "end": "1150400"
  },
  {
    "text": "front finally um maybe not modifying the picture too much we have uh prompt",
    "start": "1150400",
    "end": "1157320"
  },
  {
    "text": "injection sort of stuff uh uh the this also fits into that almost like a",
    "start": "1157320",
    "end": "1165159"
  },
  {
    "text": "firewall or a safeguard in front of your large language model where uh in in our case we have a",
    "start": "1165159",
    "end": "1172799"
  },
  {
    "text": "custombuilt sort of layer um with examples like all the latest examples",
    "start": "1172799",
    "end": "1179120"
  },
  {
    "text": "and expanding examples of prompt injections along with a set of classification models those are all",
    "start": "1179120",
    "end": "1185720"
  },
  {
    "text": "ensembled together to give us a sense of if something is likely to be a prompt injection coming in on the front end um",
    "start": "1185720",
    "end": "1192880"
  },
  {
    "text": "and then we can filter that out accordingly again in a configurable way um so uh th this gets us to this point",
    "start": "1192880",
    "end": "1201840"
  },
  {
    "text": "of um all of these things being hopefully addressed in one way or another I hope that this gives you a bit",
    "start": "1201840",
    "end": "1208280"
  },
  {
    "text": "of a framework of thinking as you kind of go into your applications even if you're not building all of these pieces",
    "start": "1208280",
    "end": "1215799"
  },
  {
    "text": "um I think it's wise that uh that especially because we have a lot to lose",
    "start": "1215799",
    "end": "1221559"
  },
  {
    "text": "when it comes to like people's trust in AI systems um why don't we just get like",
    "start": "1221559",
    "end": "1227000"
  },
  {
    "text": "the easy stuff um that's already known like we know how to deal with some of these things let's get those out of the",
    "start": "1227000",
    "end": "1232760"
  },
  {
    "text": "way and build in some of these more sophisticated layers from the start um as we as we build out these systems now",
    "start": "1232760",
    "end": "1240120"
  },
  {
    "text": "all of this this has become kind of a a complicated picture um this is this is",
    "start": "1240120",
    "end": "1245320"
  },
  {
    "text": "essentially what we've been working on for the past uh for the past year if you're interested in talking with us I'm",
    "start": "1245320",
    "end": "1250960"
  },
  {
    "text": "more than happy to not like sell you our our product but to to give you advice",
    "start": "1250960",
    "end": "1256120"
  },
  {
    "text": "and and uh be a sounding board on this if you go to prediction guard.com there's a Discord Channel there you can",
    "start": "1256120",
    "end": "1263320"
  },
  {
    "text": "uh you can log into that Discord um you know my team is in there we're happy to answer any questions or if you don't get",
    "start": "1263320",
    "end": "1270240"
  },
  {
    "text": "questions answered here happy to follow up with those um there but yeah thank you all for sticking",
    "start": "1270240",
    "end": "1277960"
  },
  {
    "text": "around I um just went on Daniel's website and I discovered that he actually will charge you money for",
    "start": "1278880",
    "end": "1285760"
  },
  {
    "text": "asking him questions for an hour of L advice so any questions that you do get to ask now which I'm going to come to you y well maybe not the Discord but if",
    "start": "1285760",
    "end": "1293080"
  },
  {
    "text": "you want private one-on-one he can do that but if you ask any questions now you're literally making money by asking questions so fantastic we will get going",
    "start": "1293080",
    "end": "1299960"
  },
  {
    "text": "with that losing money y yeah let's spend all his",
    "start": "1299960",
    "end": "1305200"
  },
  {
    "text": "money there we go um how do you oh sorry thank you um I",
    "start": "1305440",
    "end": "1313400"
  },
  {
    "text": "saw a lot of things being added in the chart uh latency is a big concern for a lot of this lot of this space um how do",
    "start": "1313400",
    "end": "1322919"
  },
  {
    "text": "you deal with that where do you how do you analyze the trade-offs where where do you draw the lines how do you think",
    "start": "1322919",
    "end": "1328559"
  },
  {
    "text": "about uh what is worth putting in and what isn't or what may be too",
    "start": "1328559",
    "end": "1334000"
  },
  {
    "text": "much yeah so good question so the question just to um make sure uh it's",
    "start": "1334000",
    "end": "1339840"
  },
  {
    "text": "understood is as soon as you start adding things around the llm those things take some amount of computational",
    "start": "1339840",
    "end": "1346360"
  },
  {
    "text": "time which could add up and add a bunch of latency so um what the the way that",
    "start": "1346360",
    "end": "1352400"
  },
  {
    "text": "we've approached this is and this is why I emphasize like a factual consistency",
    "start": "1352400",
    "end": "1358240"
  },
  {
    "text": "model versus an llm as judge so basically the bulk of your processing",
    "start": "1358240",
    "end": "1363880"
  },
  {
    "text": "time is in the llm call so whatever it is 4 seconds or something like that it's not milliseconds certainly not not down",
    "start": "1363880",
    "end": "1371600"
  },
  {
    "text": "to there um so like 4 seconds in that call so what what you can do then by",
    "start": "1371600",
    "end": "1378080"
  },
  {
    "text": "Focus in not on using an llm a second time as like a chained llm as judge call",
    "start": "1378080",
    "end": "1385000"
  },
  {
    "text": "for example is use one of these NLP models that is much smaller it can run on CPU very performant maybe it does",
    "start": "1385000",
    "end": "1392480"
  },
  {
    "text": "take like 200 milliseconds or something but in the whole scope of like the 4 seconds right um that's sort of",
    "start": "1392480",
    "end": "1400000"
  },
  {
    "text": "minuscule on the end the other thing I think is really useful is we do leverage",
    "start": "1400000",
    "end": "1405200"
  },
  {
    "text": "um uh sort of vector search and semantic um comparisons in various pieces of our",
    "start": "1405200",
    "end": "1411840"
  },
  {
    "text": "pipeline so in prompt in injection for example and I think rebuff does this as well where um you can have a sort of",
    "start": "1411840",
    "end": "1418640"
  },
  {
    "text": "stable of examples of prompt injections and not prompt injections that's not all",
    "start": "1418640",
    "end": "1423919"
  },
  {
    "text": "we rely on but if you do that semantic comparison and then just get like a Max",
    "start": "1423919",
    "end": "1429080"
  },
  {
    "text": "score or an average score or something to those examples it's a very quick operation because it's an operation",
    "start": "1429080",
    "end": "1435159"
  },
  {
    "text": "against a database not an operation against a model so I I think you want to think about these additions around the",
    "start": "1435159",
    "end": "1441080"
  },
  {
    "text": "model not as additional llm calls if possible but as creative sort of NLP or",
    "start": "1441080",
    "end": "1448120"
  },
  {
    "text": "vector type of operations when you can and spend the latency on the llm calls",
    "start": "1448120",
    "end": "1453480"
  },
  {
    "text": "when you're able yeah yeah you just uh started touching on the prompt injection topic and I was",
    "start": "1453480",
    "end": "1460640"
  },
  {
    "text": "wondering uh it sounds like a lot of the work you do is in production with like a",
    "start": "1460640",
    "end": "1465679"
  },
  {
    "text": "firewall type approach do you do any pre production testing of the model to",
    "start": "1465679",
    "end": "1470799"
  },
  {
    "text": "understand what types of yeah yeah so the way that we have at least our setup and um this could kind of give you maybe",
    "start": "1470799",
    "end": "1478000"
  },
  {
    "text": "some inspiration um of of what you might want to do but we've we both have like",
    "start": "1478000",
    "end": "1484279"
  },
  {
    "text": "uh prompt injection where you can turn it on in like a chat call but you can also call it out individually like that",
    "start": "1484279",
    "end": "1490279"
  },
  {
    "text": "model The Prompt injection model specifically and so like our one of our",
    "start": "1490279",
    "end": "1495919"
  },
  {
    "text": "goals here was like all of these things these boxes sort of like exist in closed",
    "start": "1495919",
    "end": "1502159"
  },
  {
    "text": "systems they're not configurable they're not discoverable how they're operating so when you get moderated right you're",
    "start": "1502159",
    "end": "1508240"
  },
  {
    "text": "like well what the heck like why did I get moderated like what what am I possibly close to that could have",
    "start": "1508240",
    "end": "1514360"
  },
  {
    "text": "possibly got moderated I'm sure some of you have had this with chat GPT so our goal is to provide the visibility around",
    "start": "1514360",
    "end": "1520880"
  },
  {
    "text": "that so like if something's getting blocked right you can hit it against that model look at the scores change",
    "start": "1520880",
    "end": "1527039"
  },
  {
    "text": "your thresholds that sort sort of thing yeah um thanks for the talk yeah awesome",
    "start": "1527039",
    "end": "1532520"
  },
  {
    "text": "information uh can you talk a a little bit about um data access so if you're doing rag or whatever um what models",
    "start": "1532520",
    "end": "1539760"
  },
  {
    "text": "should have access to what data within an organization uh and who should have access to that um instead of just",
    "start": "1539760",
    "end": "1546159"
  },
  {
    "text": "ingesting all the context and every knowledge base and all the unstructured information from the an entire company or entire organization yeah um how do",
    "start": "1546159",
    "end": "1554320"
  },
  {
    "text": "you know who to give access to what given given the types of problems that you're solving yeah yeah so uh good good",
    "start": "1554320",
    "end": "1560720"
  },
  {
    "text": "question so um there's a couple scenarios that could happen here like",
    "start": "1560720",
    "end": "1566080"
  },
  {
    "text": "the one scenario which is maybe easier than the others um or maybe not easier but maybe more seamless is like if",
    "start": "1566080",
    "end": "1573799"
  },
  {
    "text": "you're doing something where you have a database of information and you're using",
    "start": "1573799",
    "end": "1580039"
  },
  {
    "text": "like for example uh postgress and you're using PG vector or um you have a SQL",
    "start": "1580039",
    "end": "1587039"
  },
  {
    "text": "database and you're doing text to SQL and there's those existing database systems that have ro-based access",
    "start": "1587039",
    "end": "1592840"
  },
  {
    "text": "control and you're embedding your AI functionality in your application where you know the context of that user and",
    "start": "1592840",
    "end": "1599000"
  },
  {
    "text": "their role then you can query against that source with the proper role assigned to it it gets a little bit more",
    "start": "1599000",
    "end": "1605960"
  },
  {
    "text": "complicated now when you just have like a big S3 bucket full of documents right um what is in those documents and what",
    "start": "1605960",
    "end": "1613399"
  },
  {
    "text": "like should so actually we've seen like two stages in the in the customers we've",
    "start": "1613399",
    "end": "1618799"
  },
  {
    "text": "worked with they actually um in certain cases have a team that uses like an llm",
    "start": "1618799",
    "end": "1624360"
  },
  {
    "text": "based approach to actually categorize and organize that like file store of",
    "start": "1624360",
    "end": "1629880"
  },
  {
    "text": "information to detect like what is where and what data is where um and then they",
    "start": "1629880",
    "end": "1635240"
  },
  {
    "text": "like parse it off to like internal and external and that sort of thing but I don't think that like this solves the",
    "start": "1635240",
    "end": "1643159"
  },
  {
    "text": "like data access problem necessarily um I could definitely recommend",
    "start": "1643159",
    "end": "1648960"
  },
  {
    "text": "outside of like the database systems like if you look at a system like a muta or something like that like there's",
    "start": "1648960",
    "end": "1654600"
  },
  {
    "text": "people that have been thinking long and hard about like you have big file store or data Lake who has access to what and",
    "start": "1654600",
    "end": "1660919"
  },
  {
    "text": "how do you manage a policy against that as soon as you have a system like that there's also an API to that system and",
    "start": "1660919",
    "end": "1668039"
  },
  {
    "text": "you could use for example tool calling in your llm with a proper role to to do",
    "start": "1668039",
    "end": "1673159"
  },
  {
    "text": "that as well so okay go",
    "start": "1673159",
    "end": "1678840"
  },
  {
    "text": "these last two so um I I think this really encompasses well what are the kinds of",
    "start": "1678840",
    "end": "1685320"
  },
  {
    "text": "guard rails that you need to have in place to make sure that you know you're deploying secure systems into production uh what we see with Enterprises is that",
    "start": "1685320",
    "end": "1691760"
  },
  {
    "text": "our sock teams are starting to get reined into what kind of net new events does this generate and send to the seam",
    "start": "1691760",
    "end": "1698320"
  },
  {
    "text": "do you have a perspective on sort of what seam integration looks like for Gen applications yeah yeah good uh good",
    "start": "1698320",
    "end": "1704840"
  },
  {
    "text": "question yeah so this gets a little bit to the like um I I talked a little just",
    "start": "1704840",
    "end": "1709880"
  },
  {
    "text": "briefly over inpoint monitoring um so so",
    "start": "1709880",
    "end": "1715640"
  },
  {
    "text": "yes I think that like our system that we run for our production uh users actually",
    "start": "1715640",
    "end": "1722600"
  },
  {
    "text": "saves very little information like in the model servers because we have a commitment not to like log prompts and",
    "start": "1722600",
    "end": "1730559"
  },
  {
    "text": "um or even completions and that sort of thing because that's not data that we even want to want to have access to um",
    "start": "1730559",
    "end": "1738799"
  },
  {
    "text": "however I think that uh some of the things like if we if if we look at I mentioned one of",
    "start": "1738799",
    "end": "1747399"
  },
  {
    "text": "those like the uh uh so let's say now you have a model cache on the system um",
    "start": "1747399",
    "end": "1755559"
  },
  {
    "text": "and like you may have had like file Integrity monit monitoring or something like that for um security related files",
    "start": "1755559",
    "end": "1763840"
  },
  {
    "text": "on your endpoint right that would change some system configuration I think there's interesting like one interesting",
    "start": "1763840",
    "end": "1769559"
  },
  {
    "text": "route is like now you have all these new artifacts that are not code um they are",
    "start": "1769559",
    "end": "1775320"
  },
  {
    "text": "data um and like the uh the Integrity monitoring of those is actually quite",
    "start": "1775320",
    "end": "1782559"
  },
  {
    "text": "quite important um in terms of the performance of these systems over time and also like uh more on the security",
    "start": "1782559",
    "end": "1790039"
  },
  {
    "text": "side so model cache that's there um I I think also there's",
    "start": "1790039",
    "end": "1796279"
  },
  {
    "text": "uh sort of interesting new ways of kind of denial of service sort of attacks",
    "start": "1796279",
    "end": "1803120"
  },
  {
    "text": "with these servers that um like yes you could still have like number of requests",
    "start": "1803120",
    "end": "1809279"
  },
  {
    "text": "but there's interesting ways to play with like the token inputs and how much you're requesting token output and um",
    "start": "1809279",
    "end": "1815960"
  },
  {
    "text": "and and things like that that could jam up the the server so like anomalies as related to those actual model input",
    "start": "1815960",
    "end": "1822760"
  },
  {
    "text": "parameters is interesting yeah so for example you have like",
    "start": "1822760",
    "end": "1829960"
  },
  {
    "text": "comp system that receives that flag that yeah yeah I think that's I think",
    "start": "1835679",
    "end": "1841799"
  },
  {
    "text": "that's totally valid I think that's something you'd want to have visibility around also if you are even on that pii",
    "start": "1841799",
    "end": "1848600"
  },
  {
    "text": "or Phi side like that's a behavioral thing that probably a security team should know if a lot of that information",
    "start": "1848600",
    "end": "1855240"
  },
  {
    "text": "is leaking into leaking into prompts I just want to thank everyone that's asked questions over the last two days by the",
    "start": "1855240",
    "end": "1861120"
  },
  {
    "text": "way because they've been absolutely fascinating and there's been no there's actually been no weird questions at all they've all been perfect questions so",
    "start": "1861120",
    "end": "1867360"
  },
  {
    "text": "actually I'm just now putting you under lots and lots of pressure for asking the last question of the last Talk of the last day so yeah the pressure is",
    "start": "1867360",
    "end": "1874679"
  },
  {
    "text": "pressure is on uh so I I'd like to know if there are additional security challenges with the advanced topics like",
    "start": "1874679",
    "end": "1880360"
  },
  {
    "text": "agents or human in the loop or do we just have the same ones yeah yeah good good question so here I've basically",
    "start": "1880360",
    "end": "1887039"
  },
  {
    "text": "laid out kind of um maybe I guess this would cover single turn and chat in the sense that often",
    "start": "1887039",
    "end": "1893880"
  },
  {
    "text": "you're just putting in like a chat thread into a model like it's not actually you know chained together but",
    "start": "1893880",
    "end": "1899639"
  },
  {
    "text": "as soon as you get into the agent scenario I think um uh this this sort of like over uh um",
    "start": "1899639",
    "end": "1910240"
  },
  {
    "text": "allowing too much permissions for for the agent um too early I think is is a",
    "start": "1910240",
    "end": "1915799"
  },
  {
    "text": "key um there's uh so if you just search for llm top 10 there's this is one of",
    "start": "1915799",
    "end": "1922480"
  },
  {
    "text": "the things that I mentioned in the talk this is really helpful in Breaking these things down if you notice one of the",
    "start": "1922480",
    "end": "1928279"
  },
  {
    "text": "things in the top 10 here um",
    "start": "1928279",
    "end": "1934200"
  },
  {
    "text": "is uh excessive agency um I think this would to to your point about agents I",
    "start": "1934200",
    "end": "1940960"
  },
  {
    "text": "think this one would be an interesting one for you to explore in terms of um these sorts of of vulnerabilities where",
    "start": "1940960",
    "end": "1949000"
  },
  {
    "text": "um like I if I a simple example would be like if I have an assistant on my",
    "start": "1949000",
    "end": "1955440"
  },
  {
    "text": "computer and I'm asking it to change settings on my computer like oh make these three applications dark mode or",
    "start": "1955440",
    "end": "1962360"
  },
  {
    "text": "something like that that requires a certain level of admin permissions on my computer and especially when there's",
    "start": "1962360",
    "end": "1968480"
  },
  {
    "text": "hallucination or other things happening all sorts of things could change about my computer in a way that's not managed",
    "start": "1968480",
    "end": "1975240"
  },
  {
    "text": "so one way to deal with that is to restrict permission another way to deal with that is to like have a dry run of",
    "start": "1975240",
    "end": "1981559"
  },
  {
    "text": "what the agent is going to do and then like have that approved like you say in some sort of human in the loop type of",
    "start": "1981559",
    "end": "1988039"
  },
  {
    "text": "scenario um I think that right now at least in the cases we've seen that like",
    "start": "1988039",
    "end": "1993840"
  },
  {
    "text": "agentic approach where you're creating a dry run and then having that approved or modified is actually really useful",
    "start": "1993840",
    "end": "2001000"
  },
  {
    "text": "because part of like like if you're creating uh uh like a set of configurations to",
    "start": "2001000",
    "end": "2009559"
  },
  {
    "text": "update a network or something like that like part of the really annoying part of",
    "start": "2009559",
    "end": "2015200"
  },
  {
    "text": "that is just generating like all the things to start with and then like from",
    "start": "2015200",
    "end": "2020919"
  },
  {
    "text": "there the post editing of those things is is much easier like you don't have to put in as much um uh and and so a",
    "start": "2020919",
    "end": "2029120"
  },
  {
    "text": "skilled network engineer could go in and modify all those things very quickly um",
    "start": "2029120",
    "end": "2034559"
  },
  {
    "text": "so I think that dry run approach is really useful yeah thank you",
    "start": "2034559",
    "end": "2040580"
  },
  {
    "text": "[Music]",
    "start": "2040580",
    "end": "2051118"
  }
]
[
  {
    "text": "hi my name is Eric bernhardson it's",
    "start": "480",
    "end": "2679"
  },
  {
    "text": "great to be here",
    "start": "2679",
    "end": "4279"
  },
  {
    "text": "virtually uh who am I I am the CEO of a",
    "start": "4279",
    "end": "7160"
  },
  {
    "text": "company called modal we are based here",
    "start": "7160",
    "end": "8840"
  },
  {
    "text": "in New York most of my background is in",
    "start": "8840",
    "end": "11679"
  },
  {
    "text": "data AI machine learning and in",
    "start": "11679",
    "end": "13960"
  },
  {
    "text": "particular I was at Spotify for many",
    "start": "13960",
    "end": "15679"
  },
  {
    "text": "years and built a music recommendation",
    "start": "15679",
    "end": "17439"
  },
  {
    "text": "system there I did leave about 10 years",
    "start": "17439",
    "end": "19119"
  },
  {
    "text": "ago and did all kinds of other stuff in",
    "start": "19119",
    "end": "20880"
  },
  {
    "text": "between but started modol about 4 or",
    "start": "20880",
    "end": "24119"
  },
  {
    "text": "five years ago during the pandemic and",
    "start": "24119",
    "end": "26480"
  },
  {
    "text": "the mission I had at that point was to",
    "start": "26480",
    "end": "29519"
  },
  {
    "text": "build",
    "start": "29519",
    "end": "30640"
  },
  {
    "text": "an infrastructure platform for data AI",
    "start": "30640",
    "end": "34079"
  },
  {
    "text": "machine learning in a way that takes all",
    "start": "34079",
    "end": "35840"
  },
  {
    "text": "the that that makes it fun again to",
    "start": "35840",
    "end": "38719"
  },
  {
    "text": "write these applications to to basically",
    "start": "38719",
    "end": "41440"
  },
  {
    "text": "to to deploy models scale them out run",
    "start": "41440",
    "end": "43480"
  },
  {
    "text": "large scale back jobs making it possible",
    "start": "43480",
    "end": "46440"
  },
  {
    "text": "to focus on writing code and not have to",
    "start": "46440",
    "end": "48399"
  },
  {
    "text": "deal with infrastructure as it turned",
    "start": "48399",
    "end": "50239"
  },
  {
    "text": "out gen was a perfect use case for this",
    "start": "50239",
    "end": "52239"
  },
  {
    "text": "we just didn't know it at that time uh",
    "start": "52239",
    "end": "54960"
  },
  {
    "text": "modal is very much focused on high code",
    "start": "54960",
    "end": "56920"
  },
  {
    "text": "use cases what that means is we focus on",
    "start": "56920",
    "end": "58800"
  },
  {
    "text": "people want to write their own code in",
    "start": "58800",
    "end": "60359"
  },
  {
    "text": "particular writing their own models but",
    "start": "60359",
    "end": "62120"
  },
  {
    "text": "also in many cases using existing models",
    "start": "62120",
    "end": "64040"
  },
  {
    "text": "in a way where you have want have",
    "start": "64040",
    "end": "65360"
  },
  {
    "text": "control or the workflow or or other",
    "start": "65360",
    "end": "67799"
  },
  {
    "text": "thing and so you can think of us more as",
    "start": "67799",
    "end": "69840"
  },
  {
    "text": "like kubernetes or AWS Lambda in the",
    "start": "69840",
    "end": "72119"
  },
  {
    "text": "sense that we can run arbitrary",
    "start": "72119",
    "end": "73360"
  },
  {
    "text": "containers or arbitrary code we do focus",
    "start": "73360",
    "end": "75280"
  },
  {
    "text": "on python right now might add other",
    "start": "75280",
    "end": "77400"
  },
  {
    "text": "languages in the future unlike system",
    "start": "77400",
    "end": "80759"
  },
  {
    "text": "like kubernetes we're fully managed so",
    "start": "80759",
    "end": "83159"
  },
  {
    "text": "we we run all the infrastructure we have",
    "start": "83159",
    "end": "84759"
  },
  {
    "text": "a big pool of thousands of gpus and CPUs",
    "start": "84759",
    "end": "88640"
  },
  {
    "text": "uh but we let you run all kinds of of",
    "start": "88640",
    "end": "90640"
  },
  {
    "text": "applications in our cloud and uh this",
    "start": "90640",
    "end": "94759"
  },
  {
    "text": "could really be anything in that sense",
    "start": "94759",
    "end": "96079"
  },
  {
    "text": "we're not an AI API we don't have one",
    "start": "96079",
    "end": "98840"
  },
  {
    "text": "model or 10 models that we put behind an",
    "start": "98840",
    "end": "101399"
  },
  {
    "text": "API doing next token prediction you can",
    "start": "101399",
    "end": "103040"
  },
  {
    "text": "really it run anything which puts a",
    "start": "103040",
    "end": "104759"
  },
  {
    "text": "little bit more owners on the developer",
    "start": "104759",
    "end": "106520"
  },
  {
    "text": "to to build this thing but it also makes",
    "start": "106520",
    "end": "108320"
  },
  {
    "text": "this a lot more",
    "start": "108320",
    "end": "109799"
  },
  {
    "text": "powerful in particular when I think",
    "start": "109799",
    "end": "111960"
  },
  {
    "text": "about platforms and how they make you",
    "start": "111960",
    "end": "114640"
  },
  {
    "text": "productive and makes it fun to write",
    "start": "114640",
    "end": "116880"
  },
  {
    "text": "code a lot of my experience is that it",
    "start": "116880",
    "end": "119640"
  },
  {
    "text": "comes down to fast feedback loops so in",
    "start": "119640",
    "end": "122079"
  },
  {
    "text": "order to make Engineers fast and make",
    "start": "122079",
    "end": "124119"
  },
  {
    "text": "them more productive you want to have",
    "start": "124119",
    "end": "125680"
  },
  {
    "text": "this like super fast feedback loop that",
    "start": "125680",
    "end": "127159"
  },
  {
    "text": "let you iterate on code very quickly I",
    "start": "127159",
    "end": "129160"
  },
  {
    "text": "think cloud has been a phenomenal",
    "start": "129160",
    "end": "131239"
  },
  {
    "text": "invention and lets us build things with",
    "start": "131239",
    "end": "133879"
  },
  {
    "text": "you know far more powerful things but",
    "start": "133879",
    "end": "135879"
  },
  {
    "text": "it's arguably a step backwards in terms",
    "start": "135879",
    "end": "137680"
  },
  {
    "text": "of developer experience and and thinking",
    "start": "137680",
    "end": "139879"
  },
  {
    "text": "a lot about this problem what what I",
    "start": "139879",
    "end": "141800"
  },
  {
    "text": "realized was in order to solve this we",
    "start": "141800",
    "end": "143879"
  },
  {
    "text": "had to build our own system to start",
    "start": "143879",
    "end": "146319"
  },
  {
    "text": "containers in the cloud very fast",
    "start": "146319",
    "end": "148400"
  },
  {
    "text": "because if you can start containers in",
    "start": "148400",
    "end": "149360"
  },
  {
    "text": "the cloud very fast you can take code",
    "start": "149360",
    "end": "151760"
  },
  {
    "text": "that that the user is building locally",
    "start": "151760",
    "end": "153680"
  },
  {
    "text": "and execute in the cloud maybe inside a",
    "start": "153680",
    "end": "155720"
  },
  {
    "text": "custom image running on a GPU whatever",
    "start": "155720",
    "end": "158400"
  },
  {
    "text": "uh and and have that sort of fast",
    "start": "158400",
    "end": "159640"
  },
  {
    "text": "feedback loop that you like when you run",
    "start": "159640",
    "end": "161400"
  },
  {
    "text": "things",
    "start": "161400",
    "end": "162840"
  },
  {
    "text": "locally uh as it turns out solving",
    "start": "162840",
    "end": "165680"
  },
  {
    "text": "container C start in a distributed",
    "start": "165680",
    "end": "167440"
  },
  {
    "text": "system is a very very deep rabbit hole",
    "start": "167440",
    "end": "169760"
  },
  {
    "text": "we have to build our own scheduler we",
    "start": "169760",
    "end": "171120"
  },
  {
    "text": "have to build all build our own file",
    "start": "171120",
    "end": "173200"
  },
  {
    "text": "system and and many other things we we",
    "start": "173200",
    "end": "175519"
  },
  {
    "text": "we sit out on a multi-year journey that",
    "start": "175519",
    "end": "177120"
  },
  {
    "text": "we still haven't completed building a",
    "start": "177120",
    "end": "178440"
  },
  {
    "text": "lot of this very very core very",
    "start": "178440",
    "end": "179920"
  },
  {
    "text": "foundational",
    "start": "179920",
    "end": "181080"
  },
  {
    "text": "infrastructure model today you can think",
    "start": "181080",
    "end": "183400"
  },
  {
    "text": "of it as two facets one is a big",
    "start": "183400",
    "end": "185239"
  },
  {
    "text": "resource",
    "start": "185239",
    "end": "186200"
  },
  {
    "text": "pool we on thousands of gpus different",
    "start": "186200",
    "end": "189080"
  },
  {
    "text": "types h100s A1 100s l4s t4s you name it",
    "start": "189080",
    "end": "193280"
  },
  {
    "text": "and the only way to access those is",
    "start": "193280",
    "end": "194920"
  },
  {
    "text": "through python esk we might add other",
    "start": "194920",
    "end": "197000"
  },
  {
    "text": "languages in the future like I mentioned",
    "start": "197000",
    "end": "198319"
  },
  {
    "text": "but right now it's Python and and the",
    "start": "198319",
    "end": "199959"
  },
  {
    "text": "reason we started with python is",
    "start": "199959",
    "end": "201280"
  },
  {
    "text": "obviously that python is such a dominant",
    "start": "201280",
    "end": "203200"
  },
  {
    "text": "language in AI machine learning and and",
    "start": "203200",
    "end": "206519"
  },
  {
    "text": "data applications one way to think about",
    "start": "206519",
    "end": "208920"
  },
  {
    "text": "model is that it's it's a serverless",
    "start": "208920",
    "end": "210799"
  },
  {
    "text": "framework that basically lets you take",
    "start": "210799",
    "end": "212720"
  },
  {
    "text": "any python function and turn that into",
    "start": "212720",
    "end": "214799"
  },
  {
    "text": "serverless function and so you do that",
    "start": "214799",
    "end": "217000"
  },
  {
    "text": "by applying this decator as you can see",
    "start": "217000",
    "end": "218560"
  },
  {
    "text": "in this code sample I'll show you a",
    "start": "218560",
    "end": "220319"
  },
  {
    "text": "little bit more examples in a second uh",
    "start": "220319",
    "end": "223040"
  },
  {
    "text": "people use model for very large scale",
    "start": "223040",
    "end": "225239"
  },
  {
    "text": "applications but also small scale",
    "start": "225239",
    "end": "226640"
  },
  {
    "text": "applications the the biggest use case is",
    "start": "226640",
    "end": "229280"
  },
  {
    "text": "most likely gen",
    "start": "229280",
    "end": "231280"
  },
  {
    "text": "inference uh we in particularly have",
    "start": "231280",
    "end": "234239"
  },
  {
    "text": "seen a lot of traction within diffusion",
    "start": "234239",
    "end": "236760"
  },
  {
    "text": "models so for instance AI generated",
    "start": "236760",
    "end": "239840"
  },
  {
    "text": "music video images but also a lot of",
    "start": "239840",
    "end": "243000"
  },
  {
    "text": "bass jobs a lot of for instance",
    "start": "243000",
    "end": "244879"
  },
  {
    "text": "processing very large scale medical",
    "start": "244879",
    "end": "247799"
  },
  {
    "text": "images or doing computer vision on on",
    "start": "247799",
    "end": "251439"
  },
  {
    "text": "frames of videos um seeing a lot of",
    "start": "251439",
    "end": "253599"
  },
  {
    "text": "traction in computational BIO things",
    "start": "253599",
    "end": "255400"
  },
  {
    "text": "like protein folding both things running",
    "start": "255400",
    "end": "257799"
  },
  {
    "text": "on gpus or or but also CPUs of course",
    "start": "257799",
    "end": "260400"
  },
  {
    "text": "LMS you can't talk about geni without",
    "start": "260400",
    "end": "262720"
  },
  {
    "text": "mentioning LMS we have a lot of",
    "start": "262720",
    "end": "264080"
  },
  {
    "text": "fine-tuning applications batch",
    "start": "264080",
    "end": "266520"
  },
  {
    "text": "embeddings uh of course inference as",
    "start": "266520",
    "end": "268759"
  },
  {
    "text": "well uh some of our customers one",
    "start": "268759",
    "end": "271600"
  },
  {
    "text": "customer I always think is incredibly",
    "start": "271600",
    "end": "273759"
  },
  {
    "text": "cool is isso they uh do AI generated",
    "start": "273759",
    "end": "278400"
  },
  {
    "text": "music and and run a lot of their",
    "start": "278400",
    "end": "280240"
  },
  {
    "text": "inference on model but we have many",
    "start": "280240",
    "end": "282560"
  },
  {
    "text": "other use cases for for modal some",
    "start": "282560",
    "end": "284759"
  },
  {
    "text": "running a very large scale uh doing all",
    "start": "284759",
    "end": "287080"
  },
  {
    "text": "kinds of different different",
    "start": "287080",
    "end": "288960"
  },
  {
    "text": "applications model it's a little bit",
    "start": "288960",
    "end": "290919"
  },
  {
    "text": "abstract to talk about model without",
    "start": "290919",
    "end": "292880"
  },
  {
    "text": "going into code so I'm going to do some",
    "start": "292880",
    "end": "294759"
  },
  {
    "text": "live coding uh so let's jump into the",
    "start": "294759",
    "end": "297440"
  },
  {
    "text": "terminal and I'll show you exactly try",
    "start": "297440",
    "end": "299880"
  },
  {
    "text": "to give you an idea of like what it",
    "start": "299880",
    "end": "301199"
  },
  {
    "text": "looks like in code so let's look at a",
    "start": "301199",
    "end": "304080"
  },
  {
    "text": "very very basic modal",
    "start": "304080",
    "end": "306080"
  },
  {
    "text": "application uh model basically one way",
    "start": "306080",
    "end": "309280"
  },
  {
    "text": "to think about it is we take python",
    "start": "309280",
    "end": "311000"
  },
  {
    "text": "functions and turn them into things that",
    "start": "311000",
    "end": "312440"
  },
  {
    "text": "run in the cloud uh there's a very",
    "start": "312440",
    "end": "314720"
  },
  {
    "text": "simple function in a called Square which",
    "start": "314720",
    "end": "317320"
  },
  {
    "text": "returns a square of a number and also",
    "start": "317320",
    "end": "319360"
  },
  {
    "text": "prints on stuff the standard error and",
    "start": "319360",
    "end": "321479"
  },
  {
    "text": "this decorator that we apply apop",
    "start": "321479",
    "end": "324639"
  },
  {
    "text": "function takes that and turns that into",
    "start": "324639",
    "end": "326960"
  },
  {
    "text": "a serverless function running in the",
    "start": "326960",
    "end": "328800"
  },
  {
    "text": "cloud and there's a few different ways",
    "start": "328800",
    "end": "330680"
  },
  {
    "text": "to invoke this thing but we have a",
    "start": "330680",
    "end": "332160"
  },
  {
    "text": "little thing here that basically make",
    "start": "332160",
    "end": "333479"
  },
  {
    "text": "sure to trigger it from our laptop when",
    "start": "333479",
    "end": "335319"
  },
  {
    "text": "we run it from the command line so we're",
    "start": "335319",
    "end": "337000"
  },
  {
    "text": "going to do that so mod has a little",
    "start": "337000",
    "end": "338720"
  },
  {
    "text": "command line interface where basically",
    "start": "338720",
    "end": "341280"
  },
  {
    "text": "it lets you run things",
    "start": "341280",
    "end": "342880"
  },
  {
    "text": "interactively and what happens when we",
    "start": "342880",
    "end": "344800"
  },
  {
    "text": "run this thing is we take the code we",
    "start": "344800",
    "end": "346319"
  },
  {
    "text": "stick it in a container we execute it in",
    "start": "346319",
    "end": "348120"
  },
  {
    "text": "the cloud as it's executing it streams",
    "start": "348120",
    "end": "350560"
  },
  {
    "text": "the output back and the whole point of",
    "start": "350560",
    "end": "352600"
  },
  {
    "text": "this is like we want to make it fast and",
    "start": "352600",
    "end": "354199"
  },
  {
    "text": "feel like we're almost developing things",
    "start": "354199",
    "end": "355560"
  },
  {
    "text": "locally it's almost as fast as running",
    "start": "355560",
    "end": "357000"
  },
  {
    "text": "things locally and this extends to",
    "start": "357000",
    "end": "358919"
  },
  {
    "text": "things like let's say want to edit this",
    "start": "358919",
    "end": "360960"
  },
  {
    "text": "thing uh and just you know print",
    "start": "360960",
    "end": "363080"
  },
  {
    "text": "something",
    "start": "363080",
    "end": "364560"
  },
  {
    "text": "else and in instead of having to rebuild",
    "start": "364560",
    "end": "368319"
  },
  {
    "text": "a container push that the container to",
    "start": "368319",
    "end": "370039"
  },
  {
    "text": "the cloud download logs Etc with a slow",
    "start": "370039",
    "end": "372520"
  },
  {
    "text": "feedback Lo we just it just picks up the",
    "start": "372520",
    "end": "374199"
  },
  {
    "text": "latest code rather and rebuilds the",
    "start": "374199",
    "end": "375599"
  },
  {
    "text": "container automatically and all these",
    "start": "375599",
    "end": "376800"
  },
  {
    "text": "things right and so while you're like",
    "start": "376800",
    "end": "379280"
  },
  {
    "text": "building applications and rewriting code",
    "start": "379280",
    "end": "381759"
  },
  {
    "text": "you can always just run things in the",
    "start": "381759",
    "end": "383000"
  },
  {
    "text": "cloud very very fast so far this is just",
    "start": "383000",
    "end": "386479"
  },
  {
    "text": "showcases like the sort of iteration",
    "start": "386479",
    "end": "388039"
  },
  {
    "text": "speed but also let's let's look at the",
    "start": "388039",
    "end": "389639"
  },
  {
    "text": "power of model like what can you do with",
    "start": "389639",
    "end": "391000"
  },
  {
    "text": "model like what kinds of stuff can you",
    "start": "391000",
    "end": "392759"
  },
  {
    "text": "can we get to scale can we run things on",
    "start": "392759",
    "end": "394520"
  },
  {
    "text": "on on other types of Hardware so let's",
    "start": "394520",
    "end": "397680"
  },
  {
    "text": "let's actually run this on an h100 and",
    "start": "397680",
    "end": "400080"
  },
  {
    "text": "and the way in model you do that is by",
    "start": "400080",
    "end": "401800"
  },
  {
    "text": "saying just on the function decorator",
    "start": "401800",
    "end": "403720"
  },
  {
    "text": "you say GPU equals one h100 uh we have a",
    "start": "403720",
    "end": "407520"
  },
  {
    "text": "bunch of other types as I mentioned we",
    "start": "407520",
    "end": "409080"
  },
  {
    "text": "have A1 100s and t4s and all kinds of",
    "start": "409080",
    "end": "411080"
  },
  {
    "text": "other ones but let's run this on an h100",
    "start": "411080",
    "end": "413800"
  },
  {
    "text": "which is nvidia's",
    "start": "413800",
    "end": "415840"
  },
  {
    "text": "Flagship um and we can get access to an",
    "start": "415840",
    "end": "419120"
  },
  {
    "text": "h100 in a couple of seconds this is",
    "start": "419120",
    "end": "421360"
  },
  {
    "text": "obviously not using the h100 uh but",
    "start": "421360",
    "end": "423800"
  },
  {
    "text": "we're running it in a container that has",
    "start": "423800",
    "end": "425840"
  },
  {
    "text": "access to an h100 so let's say we want",
    "start": "425840",
    "end": "428240"
  },
  {
    "text": "to actually access it now we need to",
    "start": "428240",
    "end": "429800"
  },
  {
    "text": "probably install some software right so",
    "start": "429800",
    "end": "432360"
  },
  {
    "text": "we might want to install torch in this",
    "start": "432360",
    "end": "433840"
  },
  {
    "text": "case uh there's a few different ways you",
    "start": "433840",
    "end": "435800"
  },
  {
    "text": "can do that in model you can give us a",
    "start": "435800",
    "end": "437560"
  },
  {
    "text": "Docker file you can also point the",
    "start": "437560",
    "end": "438960"
  },
  {
    "text": "docker image but the easiest thing to do",
    "start": "438960",
    "end": "441479"
  },
  {
    "text": "that is to basically Define the entire",
    "start": "441479",
    "end": "444080"
  },
  {
    "text": "compute environment in code so we're",
    "start": "444080",
    "end": "446080"
  },
  {
    "text": "going to define the the container image",
    "start": "446080",
    "end": "448919"
  },
  {
    "text": "using modal mod python SDK so we're",
    "start": "448919",
    "end": "451479"
  },
  {
    "text": "going to say image equals model. image.",
    "start": "451479",
    "end": "454560"
  },
  {
    "text": "Debian slim as a base image and we're",
    "start": "454560",
    "end": "456280"
  },
  {
    "text": "going to pip install torch and then",
    "start": "456280",
    "end": "459120"
  },
  {
    "text": "we're going to use this image on this",
    "start": "459120",
    "end": "461199"
  },
  {
    "text": "function and we're going to import torch",
    "start": "461199",
    "end": "464080"
  },
  {
    "text": "and just to show that it works we're",
    "start": "464080",
    "end": "465479"
  },
  {
    "text": "going to",
    "start": "465479",
    "end": "466360"
  },
  {
    "text": "print torch. Cuda doget device",
    "start": "466360",
    "end": "471080"
  },
  {
    "text": "name hopefully this works when I run",
    "start": "471080",
    "end": "473199"
  },
  {
    "text": "this we'll delete this line and when I",
    "start": "473199",
    "end": "475360"
  },
  {
    "text": "run this thing hopefully it will print",
    "start": "475360",
    "end": "477120"
  },
  {
    "text": "something like we're running on h100",
    "start": "477120",
    "end": "481199"
  },
  {
    "text": "and um as you can see it's still very",
    "start": "481240",
    "end": "484919"
  },
  {
    "text": "fast but slightly slower this time uh",
    "start": "484919",
    "end": "487840"
  },
  {
    "text": "because loading torch takes a little bit",
    "start": "487840",
    "end": "489280"
  },
  {
    "text": "of extra overhead and we'll talk about",
    "start": "489280",
    "end": "491039"
  },
  {
    "text": "it in a second what we've done to to",
    "start": "491039",
    "end": "492520"
  },
  {
    "text": "reduce that overhead but but it takes",
    "start": "492520",
    "end": "494520"
  },
  {
    "text": "maybe about a second to initialize torch",
    "start": "494520",
    "end": "497400"
  },
  {
    "text": "uh okay cool so now we can run stuff on",
    "start": "497400",
    "end": "501080"
  },
  {
    "text": "h100s let's try to run things on a lot",
    "start": "501080",
    "end": "503319"
  },
  {
    "text": "of h100s uh and so let's try to scale",
    "start": "503319",
    "end": "505680"
  },
  {
    "text": "things out a little bit uh in modal any",
    "start": "505680",
    "end": "508159"
  },
  {
    "text": "function can you can map over any",
    "start": "508159",
    "end": "510800"
  },
  {
    "text": "function in model just in code so",
    "start": "510800",
    "end": "512959"
  },
  {
    "text": "instead of calling just a single",
    "start": "512959",
    "end": "515479"
  },
  {
    "text": "function invocation we're going to Fan",
    "start": "515479",
    "end": "517159"
  },
  {
    "text": "out and do a TH or maybe let's do 10,000",
    "start": "517159",
    "end": "519560"
  },
  {
    "text": "function invocation and you can do this",
    "start": "519560",
    "end": "521560"
  },
  {
    "text": "in Code by just saying we're going to",
    "start": "521560",
    "end": "523039"
  },
  {
    "text": "map over 5,000 I said 10,000 actually so",
    "start": "523039",
    "end": "527000"
  },
  {
    "text": "let's do that and we're going to unpack",
    "start": "527000",
    "end": "529080"
  },
  {
    "text": "the the iterator and let's um print X",
    "start": "529080",
    "end": "535120"
  },
  {
    "text": "just to show some progress and what",
    "start": "535120",
    "end": "537720"
  },
  {
    "text": "model does when you fan out is that it's",
    "start": "537720",
    "end": "540079"
  },
  {
    "text": "going to spin up as many containers as",
    "start": "540079",
    "end": "542079"
  },
  {
    "text": "possible and so you can see we're",
    "start": "542079",
    "end": "544279"
  },
  {
    "text": "already running five containers six",
    "start": "544279",
    "end": "546120"
  },
  {
    "text": "containers eight containers uh it makes",
    "start": "546120",
    "end": "548800"
  },
  {
    "text": "it very easy to to Fan out and start you",
    "start": "548800",
    "end": "551279"
  },
  {
    "text": "know even hundreds of containers or even",
    "start": "551279",
    "end": "553560"
  },
  {
    "text": "thousands of containers running on gpus",
    "start": "553560",
    "end": "555200"
  },
  {
    "text": "if we keep this running for several",
    "start": "555200",
    "end": "556399"
  },
  {
    "text": "minutes we can easily scale up to very",
    "start": "556399",
    "end": "559279"
  },
  {
    "text": "large um number um so this gives you",
    "start": "559279",
    "end": "563680"
  },
  {
    "text": "basically the ability to take something",
    "start": "563680",
    "end": "565120"
  },
  {
    "text": "like you know that needs a lot of",
    "start": "565120",
    "end": "566720"
  },
  {
    "text": "compute and you know something like a",
    "start": "566720",
    "end": "569440"
  },
  {
    "text": "that's job and fan out spin up thousands",
    "start": "569440",
    "end": "571880"
  },
  {
    "text": "of containers paralyze over it and and",
    "start": "571880",
    "end": "574920"
  },
  {
    "text": "get results much faster uh we're going",
    "start": "574920",
    "end": "577600"
  },
  {
    "text": "to take a look at",
    "start": "577600",
    "end": "579720"
  },
  {
    "text": "the UI for a second uh model also has a",
    "start": "579720",
    "end": "583240"
  },
  {
    "text": "UI uh that you can access if you go to",
    "start": "583240",
    "end": "586240"
  },
  {
    "text": "the uh website uh the URL is printed in",
    "start": "586240",
    "end": "590399"
  },
  {
    "text": "the console so let's take a look at",
    "start": "590399",
    "end": "593640"
  },
  {
    "text": "that uh so we can see the app details in",
    "start": "593640",
    "end": "597360"
  },
  {
    "text": "our UI there's all kinds of of",
    "start": "597360",
    "end": "599600"
  },
  {
    "text": "interesting things here modal has a",
    "start": "599600",
    "end": "601360"
  },
  {
    "text": "pretty rich UI that lets you see",
    "start": "601360",
    "end": "603000"
  },
  {
    "text": "container metrics logs uh lets you set",
    "start": "603000",
    "end": "606160"
  },
  {
    "text": "up users and many other things so if you",
    "start": "606160",
    "end": "608720"
  },
  {
    "text": "zoom in for instance on the number of",
    "start": "608720",
    "end": "610079"
  },
  {
    "text": "containers we can see here we spawn up",
    "start": "610079",
    "end": "612600"
  },
  {
    "text": "18 containers at Peak as I mentioned if",
    "start": "612600",
    "end": "614480"
  },
  {
    "text": "we had kept going we would reach a much",
    "start": "614480",
    "end": "616200"
  },
  {
    "text": "larger number uh we got at 18 containers",
    "start": "616200",
    "end": "619079"
  },
  {
    "text": "at this point can look at CPU",
    "start": "619079",
    "end": "621000"
  },
  {
    "text": "utilization GPU Etc um could look at GPU",
    "start": "621000",
    "end": "624399"
  },
  {
    "text": "temperature 33 cels uh even the the watt",
    "start": "624399",
    "end": "629160"
  },
  {
    "text": "could consumption so there a a lot of",
    "start": "629160",
    "end": "631440"
  },
  {
    "text": "other things here we can look at app",
    "start": "631440",
    "end": "632600"
  },
  {
    "text": "logs and many other",
    "start": "632600",
    "end": "634240"
  },
  {
    "text": "things",
    "start": "634240",
    "end": "635839"
  },
  {
    "text": "um okay let's switch back to the",
    "start": "635839",
    "end": "640360"
  },
  {
    "text": "terminal for a second and see some other",
    "start": "640360",
    "end": "642320"
  },
  {
    "text": "stuff there's a lot of stuff so I'm not",
    "start": "642320",
    "end": "643920"
  },
  {
    "text": "going to go into every single",
    "start": "643920",
    "end": "646079"
  },
  {
    "text": "possibility of how to use model but one",
    "start": "646079",
    "end": "648760"
  },
  {
    "text": "thing I didn't show that I think is",
    "start": "648760",
    "end": "650040"
  },
  {
    "text": "interesting and very valuable is you can",
    "start": "650040",
    "end": "652399"
  },
  {
    "text": "also deploy these things so so far we",
    "start": "652399",
    "end": "655399"
  },
  {
    "text": "only showed how to run things",
    "start": "655399",
    "end": "656920"
  },
  {
    "text": "interactively which means we have sort",
    "start": "656920",
    "end": "658480"
  },
  {
    "text": "of you know we run things from our",
    "start": "658480",
    "end": "659880"
  },
  {
    "text": "laptop but if I take this code and",
    "start": "659880",
    "end": "662600"
  },
  {
    "text": "deploy this using model",
    "start": "662600",
    "end": "665360"
  },
  {
    "text": "deploy uh we get this persistent",
    "start": "665360",
    "end": "668160"
  },
  {
    "text": "endpoint and what's nice about that is",
    "start": "668160",
    "end": "670480"
  },
  {
    "text": "now we have this thing we can call from",
    "start": "670480",
    "end": "672000"
  },
  {
    "text": "any other context in Python and I'm just",
    "start": "672000",
    "end": "674399"
  },
  {
    "text": "going to show this using my rapple if we",
    "start": "674399",
    "end": "676519"
  },
  {
    "text": "import model and if we do look up like",
    "start": "676519",
    "end": "681200"
  },
  {
    "text": "this uh we get this handle to this",
    "start": "681200",
    "end": "683959"
  },
  {
    "text": "remote function so let's call This And",
    "start": "683959",
    "end": "686720"
  },
  {
    "text": "the first time we're going to call it",
    "start": "686720",
    "end": "687920"
  },
  {
    "text": "we're going to have inquir a call start",
    "start": "687920",
    "end": "689600"
  },
  {
    "text": "so it's going to take a couple seconds",
    "start": "689600",
    "end": "691399"
  },
  {
    "text": "because the container has to start up",
    "start": "691399",
    "end": "692720"
  },
  {
    "text": "and remember we're we're importing torch",
    "start": "692720",
    "end": "694160"
  },
  {
    "text": "and we're running this on an h100 so it",
    "start": "694160",
    "end": "695560"
  },
  {
    "text": "takes a little bit of extra time the",
    "start": "695560",
    "end": "697079"
  },
  {
    "text": "container keeps running for a few for",
    "start": "697079",
    "end": "699040"
  },
  {
    "text": "for for 60 seconds by default and then",
    "start": "699040",
    "end": "700800"
  },
  {
    "text": "shuts down so now it's actually idle so",
    "start": "700800",
    "end": "702800"
  },
  {
    "text": "if we call this again typically it' be a",
    "start": "702800",
    "end": "704720"
  },
  {
    "text": "little bit faster and uh we're obviously",
    "start": "704720",
    "end": "707600"
  },
  {
    "text": "you know wasting an enormous amount of",
    "start": "707600",
    "end": "709800"
  },
  {
    "text": "flops using a GPU to calculate the",
    "start": "709800",
    "end": "711839"
  },
  {
    "text": "square of a number uh but but this",
    "start": "711839",
    "end": "714240"
  },
  {
    "text": "showcases you know how you can easily",
    "start": "714240",
    "end": "715880"
  },
  {
    "text": "take things and deploy it uh even on",
    "start": "715880",
    "end": "718040"
  },
  {
    "text": "very powerful hardware and and building",
    "start": "718040",
    "end": "721040"
  },
  {
    "text": "serverless endpoints for instance doing",
    "start": "721040",
    "end": "722519"
  },
  {
    "text": "inference and and you know and modal",
    "start": "722519",
    "end": "724639"
  },
  {
    "text": "handles all the scaling so when you",
    "start": "724639",
    "end": "726040"
  },
  {
    "text": "invoke this function multiple times will",
    "start": "726040",
    "end": "728160"
  },
  {
    "text": "just scale up using more and more",
    "start": "728160",
    "end": "729519"
  },
  {
    "text": "containers and shut down um many other",
    "start": "729519",
    "end": "732839"
  },
  {
    "text": "things you can do with model you can set",
    "start": "732839",
    "end": "734880"
  },
  {
    "text": "up distribute file systems that you can",
    "start": "734880",
    "end": "737199"
  },
  {
    "text": "mount to each container so you can like",
    "start": "737199",
    "end": "738959"
  },
  {
    "text": "exchange information using the file",
    "start": "738959",
    "end": "740440"
  },
  {
    "text": "system you can set up web end points you",
    "start": "740440",
    "end": "743920"
  },
  {
    "text": "can set up cron jobs and many other",
    "start": "743920",
    "end": "746320"
  },
  {
    "text": "things uh so this hopefully gives you a",
    "start": "746320",
    "end": "748519"
  },
  {
    "text": "little bit more of an idea of like what",
    "start": "748519",
    "end": "749760"
  },
  {
    "text": "modal looks like from an engineering",
    "start": "749760",
    "end": "751600"
  },
  {
    "text": "perspective like what does it look like",
    "start": "751600",
    "end": "752920"
  },
  {
    "text": "when you're interacting through code",
    "start": "752920",
    "end": "754440"
  },
  {
    "text": "with",
    "start": "754440",
    "end": "755320"
  },
  {
    "text": "modal let's talk a bit about how modal",
    "start": "755320",
    "end": "757560"
  },
  {
    "text": "Works under the hood and as I mentioned",
    "start": "757560",
    "end": "760959"
  },
  {
    "text": "modal in order to deliver on this",
    "start": "760959",
    "end": "763120"
  },
  {
    "text": "developer experience that I always",
    "start": "763120",
    "end": "764320"
  },
  {
    "text": "wanted to have we had to go down this",
    "start": "764320",
    "end": "766320"
  },
  {
    "text": "very deep rabbit hole and build a lot of",
    "start": "766320",
    "end": "768199"
  },
  {
    "text": "custom infrastructure ourself and that's",
    "start": "768199",
    "end": "769920"
  },
  {
    "text": "the only way we felt that we can make it",
    "start": "769920",
    "end": "772040"
  },
  {
    "text": "fast enough we couldn't use carbonet we",
    "start": "772040",
    "end": "774240"
  },
  {
    "text": "couldn't use Docker so we have to build",
    "start": "774240",
    "end": "776279"
  },
  {
    "text": "a lot of this stuff ourselves and it",
    "start": "776279",
    "end": "778199"
  },
  {
    "text": "should be pointed out where standing on",
    "start": "778199",
    "end": "779600"
  },
  {
    "text": "shoulders of giants here uh we're using",
    "start": "779600",
    "end": "782040"
  },
  {
    "text": "a fantastic container runtime called G",
    "start": "782040",
    "end": "784320"
  },
  {
    "text": "viser uh that gives us isolation but we",
    "start": "784320",
    "end": "786920"
  },
  {
    "text": "have to build a lot of stuff around it",
    "start": "786920",
    "end": "789600"
  },
  {
    "text": "uh we had to build it on scheduler and",
    "start": "789600",
    "end": "791079"
  },
  {
    "text": "many other things but we're obviously",
    "start": "791079",
    "end": "792199"
  },
  {
    "text": "using a lot of the existing things in",
    "start": "792199",
    "end": "794519"
  },
  {
    "text": "Linux and and other systems and using",
    "start": "794519",
    "end": "796560"
  },
  {
    "text": "fantastic Cloud tools as",
    "start": "796560",
    "end": "798600"
  },
  {
    "text": "well uh in order to deliver the",
    "start": "798600",
    "end": "801519"
  },
  {
    "text": "developer experience that we wanted to",
    "start": "801519",
    "end": "802959"
  },
  {
    "text": "as I mentioned and the feedback loops",
    "start": "802959",
    "end": "804399"
  },
  {
    "text": "that we wanted to we had to figure out",
    "start": "804399",
    "end": "805920"
  },
  {
    "text": "container cold start and container cold",
    "start": "805920",
    "end": "808440"
  },
  {
    "text": "start starting containers fast in a",
    "start": "808440",
    "end": "810399"
  },
  {
    "text": "distributed system is a hard problem so",
    "start": "810399",
    "end": "813440"
  },
  {
    "text": "let's talk about what containers are to",
    "start": "813440",
    "end": "815399"
  },
  {
    "text": "start with containers are and this is my",
    "start": "815399",
    "end": "817920"
  },
  {
    "text": "super crude unfair generalization of",
    "start": "817920",
    "end": "820120"
  },
  {
    "text": "what a container is or container image",
    "start": "820120",
    "end": "822760"
  },
  {
    "text": "it's basically two things it's a root",
    "start": "822760",
    "end": "824519"
  },
  {
    "text": "file system so that's like the slash",
    "start": "824519",
    "end": "826320"
  },
  {
    "text": "that you have in in Linux that contains",
    "start": "826320",
    "end": "828160"
  },
  {
    "text": "all the data on your drive and then it's",
    "start": "828160",
    "end": "830800"
  },
  {
    "text": "a bunch of stuff to is isolate processes",
    "start": "830800",
    "end": "833519"
  },
  {
    "text": "so they can't tamper with each",
    "start": "833519",
    "end": "835440"
  },
  {
    "text": "other uh there are many inefficiencies",
    "start": "835440",
    "end": "838800"
  },
  {
    "text": "with how container images are stored and",
    "start": "838800",
    "end": "842240"
  },
  {
    "text": "how container images are transferred in",
    "start": "842240",
    "end": "844600"
  },
  {
    "text": "particular one of the issues is that",
    "start": "844600",
    "end": "846639"
  },
  {
    "text": "there's a lot of junk there's a lot of",
    "start": "846639",
    "end": "849000"
  },
  {
    "text": "stuff we're never going to read like",
    "start": "849000",
    "end": "850480"
  },
  {
    "text": "many container images has Pearl",
    "start": "850480",
    "end": "852320"
  },
  {
    "text": "installed by default Man pages local",
    "start": "852320",
    "end": "854839"
  },
  {
    "text": "information time zone information for",
    "start": "854839",
    "end": "857160"
  },
  {
    "text": "usbekistan you're never going to read",
    "start": "857160",
    "end": "859000"
  },
  {
    "text": "this stuff so we're sending all this",
    "start": "859000",
    "end": "860240"
  },
  {
    "text": "data back and forth and and and the core",
    "start": "860240",
    "end": "862519"
  },
  {
    "text": "thing here is we want to start",
    "start": "862519",
    "end": "863399"
  },
  {
    "text": "containers on a remote file on a remote",
    "start": "863399",
    "end": "865639"
  },
  {
    "text": "worker very very fast we want to",
    "start": "865639",
    "end": "867199"
  },
  {
    "text": "minimize the amount of data that has to",
    "start": "867199",
    "end": "868519"
  },
  {
    "text": "be transferred",
    "start": "868519",
    "end": "869600"
  },
  {
    "text": "we want to do as little as possible the",
    "start": "869600",
    "end": "871639"
  },
  {
    "text": "other inefficiency is that there's a lot",
    "start": "871639",
    "end": "873800"
  },
  {
    "text": "of redundancy in this a lot of the fils",
    "start": "873800",
    "end": "876240"
  },
  {
    "text": "that are being transferred back and",
    "start": "876240",
    "end": "877279"
  },
  {
    "text": "forth are actually the same files so if",
    "start": "877279",
    "end": "879399"
  },
  {
    "text": "you grab just like three very different",
    "start": "879399",
    "end": "882160"
  },
  {
    "text": "container images like I did in this case",
    "start": "882160",
    "end": "884199"
  },
  {
    "text": "and you look at the files it actually",
    "start": "884199",
    "end": "886000"
  },
  {
    "text": "turns out to be mostly the same files to",
    "start": "886000",
    "end": "887800"
  },
  {
    "text": "a very large extent so with those two",
    "start": "887800",
    "end": "890680"
  },
  {
    "text": "tricks with those two observations",
    "start": "890680",
    "end": "892360"
  },
  {
    "text": "there's a number of Tricks we can do and",
    "start": "892360",
    "end": "893880"
  },
  {
    "text": "and we so we built what's called a",
    "start": "893880",
    "end": "896600"
  },
  {
    "text": "Content addressed storage and this is",
    "start": "896600",
    "end": "898759"
  },
  {
    "text": "not new invention this is not something",
    "start": "898759",
    "end": "900360"
  },
  {
    "text": "we came up with but it's RAR used in",
    "start": "900360",
    "end": "902680"
  },
  {
    "text": "production systems notably AWS Lambda",
    "start": "902680",
    "end": "905240"
  },
  {
    "text": "actually uses the same technique and the",
    "start": "905240",
    "end": "907519"
  },
  {
    "text": "idea is that instead of storing the",
    "start": "907519",
    "end": "910279"
  },
  {
    "text": "images directly we store the images the",
    "start": "910279",
    "end": "913000"
  },
  {
    "text": "container images as just a bunch of",
    "start": "913000",
    "end": "915680"
  },
  {
    "text": "metadata that points to blobs and for",
    "start": "915680",
    "end": "919000"
  },
  {
    "text": "each blob we compute a check sum or hash",
    "start": "919000",
    "end": "923440"
  },
  {
    "text": "value and then we use that to D",
    "start": "923440",
    "end": "925480"
  },
  {
    "text": "duplicate all the blobs because there's",
    "start": "925480",
    "end": "926880"
  },
  {
    "text": "enormous amount of redundancy in these",
    "start": "926880",
    "end": "929000"
  },
  {
    "text": "blobs and this means the container",
    "start": "929000",
    "end": "932040"
  },
  {
    "text": "images themselves are actually just",
    "start": "932040",
    "end": "933720"
  },
  {
    "text": "little pieces of metadata and in many",
    "start": "933720",
    "end": "936759"
  },
  {
    "text": "cases we can cash a very large",
    "start": "936759",
    "end": "939120"
  },
  {
    "text": "percentage of the container images and",
    "start": "939120",
    "end": "941959"
  },
  {
    "text": "we can also avoid pulling data that we",
    "start": "941959",
    "end": "944600"
  },
  {
    "text": "we're not going to need by lazy loading",
    "start": "944600",
    "end": "947319"
  },
  {
    "text": "a lot of the data on axess uh this is",
    "start": "947319",
    "end": "950600"
  },
  {
    "text": "tricky because container call start in",
    "start": "950600",
    "end": "953839"
  },
  {
    "text": "particular with python is very latency",
    "start": "953839",
    "end": "957480"
  },
  {
    "text": "sensitive because we end up doing a lot",
    "start": "957480",
    "end": "959399"
  },
  {
    "text": "of very sequential file aises so in many",
    "start": "959399",
    "end": "962399"
  },
  {
    "text": "cases when a container starts up in",
    "start": "962399",
    "end": "963720"
  },
  {
    "text": "model or or in any in Python in any case",
    "start": "963720",
    "end": "967079"
  },
  {
    "text": "uh it requires reading every single",
    "start": "967079",
    "end": "969880"
  },
  {
    "text": "module every single python module which",
    "start": "969880",
    "end": "971920"
  },
  {
    "text": "is many in many cases ends up being",
    "start": "971920",
    "end": "974440"
  },
  {
    "text": "several thousand python modules each one",
    "start": "974440",
    "end": "977160"
  },
  {
    "text": "of them requires accessing the file",
    "start": "977160",
    "end": "978839"
  },
  {
    "text": "system and so what we can't allow is",
    "start": "978839",
    "end": "982120"
  },
  {
    "text": "that to take several milliseconds",
    "start": "982120",
    "end": "983800"
  },
  {
    "text": "because if you're doing something that",
    "start": "983800",
    "end": "985160"
  },
  {
    "text": "takes several milliseconds and you're",
    "start": "985160",
    "end": "986720"
  },
  {
    "text": "doing it a thousand times it and I'm",
    "start": "986720",
    "end": "989279"
  },
  {
    "text": "taking several seconds and we want to",
    "start": "989279",
    "end": "991079"
  },
  {
    "text": "avoid that so there's a lot of tricks",
    "start": "991079",
    "end": "993240"
  },
  {
    "text": "that we have to do in order to basically",
    "start": "993240",
    "end": "995680"
  },
  {
    "text": "get this down below a second we do a lot",
    "start": "995680",
    "end": "998240"
  },
  {
    "text": "of prefetching we do a lot of task",
    "start": "998240",
    "end": "1000240"
  },
  {
    "text": "tracing we look at you know historical",
    "start": "1000240",
    "end": "1002079"
  },
  {
    "text": "runs and see what types of files was",
    "start": "1002079",
    "end": "1004880"
  },
  {
    "text": "access last time it ran and then",
    "start": "1004880",
    "end": "1007759"
  },
  {
    "text": "building these containers is is",
    "start": "1007759",
    "end": "1009639"
  },
  {
    "text": "obviously also another whole challenge",
    "start": "1009639",
    "end": "1011920"
  },
  {
    "text": "we we basically built it on container",
    "start": "1011920",
    "end": "1013279"
  },
  {
    "text": "image",
    "start": "1013279",
    "end": "1014199"
  },
  {
    "text": "Builders uh another technique that we",
    "start": "1014199",
    "end": "1016519"
  },
  {
    "text": "also more recently started leveraging is",
    "start": "1016519",
    "end": "1018959"
  },
  {
    "text": "we can snapshot this CPU memory so we",
    "start": "1018959",
    "end": "1021199"
  },
  {
    "text": "talked about how we snapshot the",
    "start": "1021199",
    "end": "1023040"
  },
  {
    "text": "container images and we we we we cache a",
    "start": "1023040",
    "end": "1025760"
  },
  {
    "text": "lot of the data which means like when",
    "start": "1025760",
    "end": "1027319"
  },
  {
    "text": "you're loading it you don't have to",
    "start": "1027319",
    "end": "1029240"
  },
  {
    "text": "fetch a lot of data but what if you can",
    "start": "1029240",
    "end": "1030880"
  },
  {
    "text": "avoid loading the data in the first",
    "start": "1030880",
    "end": "1032520"
  },
  {
    "text": "place what if you can just like revert",
    "start": "1032520",
    "end": "1033959"
  },
  {
    "text": "to the the memory State the CPU memory",
    "start": "1033959",
    "end": "1036720"
  },
  {
    "text": "the ram of of uh a container and as it",
    "start": "1036720",
    "end": "1040240"
  },
  {
    "text": "turns out gvisor actually supports this",
    "start": "1040240",
    "end": "1042319"
  },
  {
    "text": "and that's another way that arguably",
    "start": "1042319",
    "end": "1044880"
  },
  {
    "text": "supersedes a lot of the previous stuff",
    "start": "1044880",
    "end": "1047240"
  },
  {
    "text": "uh in practice they end up kind of both",
    "start": "1047240",
    "end": "1049000"
  },
  {
    "text": "reinforcing this this container coal",
    "start": "1049000",
    "end": "1050799"
  },
  {
    "text": "start but this lets us cut down even",
    "start": "1050799",
    "end": "1052760"
  },
  {
    "text": "more dramatically uh things like stable",
    "start": "1052760",
    "end": "1055880"
  },
  {
    "text": "diffusion we can now start in in a",
    "start": "1055880",
    "end": "1057480"
  },
  {
    "text": "couple of seconds even though it",
    "start": "1057480",
    "end": "1059000"
  },
  {
    "text": "involves loading very very large uh",
    "start": "1059000",
    "end": "1061440"
  },
  {
    "text": "model weights like you know five or 10",
    "start": "1061440",
    "end": "1063679"
  },
  {
    "text": "gigabytes uh we're also looking at GPU",
    "start": "1063679",
    "end": "1066440"
  },
  {
    "text": "snapshotting which will make things even",
    "start": "1066440",
    "end": "1068520"
  },
  {
    "text": "more even faster which is very exciting",
    "start": "1068520",
    "end": "1072760"
  },
  {
    "text": "um and so doing all these things you",
    "start": "1072760",
    "end": "1075080"
  },
  {
    "text": "know owning the entire stack owning the",
    "start": "1075080",
    "end": "1077600"
  },
  {
    "text": "file system you know you know building a",
    "start": "1077600",
    "end": "1079320"
  },
  {
    "text": "storage system I didn't talk about the",
    "start": "1079320",
    "end": "1080520"
  },
  {
    "text": "storage system we basically use R2 and",
    "start": "1080520",
    "end": "1083320"
  },
  {
    "text": "we run in many different regions and so",
    "start": "1083320",
    "end": "1085200"
  },
  {
    "text": "we use both the CDN and the the R2 and",
    "start": "1085200",
    "end": "1089120"
  },
  {
    "text": "and and so all these optimizations",
    "start": "1089120",
    "end": "1091679"
  },
  {
    "text": "together means we kind of solve the",
    "start": "1091679",
    "end": "1095159"
  },
  {
    "text": "problem of container call start and",
    "start": "1095159",
    "end": "1097200"
  },
  {
    "text": "let's remember what why did we",
    "start": "1097200",
    "end": "1099039"
  },
  {
    "text": "originally set out to start this thing",
    "start": "1099039",
    "end": "1100799"
  },
  {
    "text": "is because we want to deliver good",
    "start": "1100799",
    "end": "1102520"
  },
  {
    "text": "developer experience as it turns out",
    "start": "1102520",
    "end": "1106440"
  },
  {
    "text": "it's good for other things too so",
    "start": "1106440",
    "end": "1108360"
  },
  {
    "text": "container call start is also good",
    "start": "1108360",
    "end": "1110240"
  },
  {
    "text": "because it enables serverless so what",
    "start": "1110240",
    "end": "1112840"
  },
  {
    "text": "does serverless mean uh it means a lot",
    "start": "1112840",
    "end": "1114840"
  },
  {
    "text": "of different things I think part of why",
    "start": "1114840",
    "end": "1117720"
  },
  {
    "text": "sometimes I avoid the term seress is",
    "start": "1117720",
    "end": "1119280"
  },
  {
    "text": "that has so many different definitions",
    "start": "1119280",
    "end": "1121919"
  },
  {
    "text": "but the the promise of serverless was",
    "start": "1121919",
    "end": "1123880"
  },
  {
    "text": "always don't provision more than you",
    "start": "1123880",
    "end": "1125799"
  },
  {
    "text": "actually need just just you know",
    "start": "1125799",
    "end": "1128559"
  },
  {
    "text": "only pay for capacitor you're actually",
    "start": "1128559",
    "end": "1131120"
  },
  {
    "text": "using and so especially with gpus which",
    "start": "1131120",
    "end": "1134280"
  },
  {
    "text": "are very expensive as it turns out you",
    "start": "1134280",
    "end": "1137400"
  },
  {
    "text": "can pack take a lot of different users",
    "start": "1137400",
    "end": "1140520"
  },
  {
    "text": "pull them together and give people",
    "start": "1140520",
    "end": "1143480"
  },
  {
    "text": "dynamically the resources they need and",
    "start": "1143480",
    "end": "1146600"
  },
  {
    "text": "get dramatically better",
    "start": "1146600",
    "end": "1148799"
  },
  {
    "text": "utilization and so that in turn means we",
    "start": "1148799",
    "end": "1152799"
  },
  {
    "text": "can get lower cost it means there's no",
    "start": "1152799",
    "end": "1154520"
  },
  {
    "text": "capacity planning it it also because we",
    "start": "1154520",
    "end": "1157360"
  },
  {
    "text": "can pull a lot of these users the the",
    "start": "1157360",
    "end": "1159760"
  },
  {
    "text": "variance the the total variance goes",
    "start": "1159760",
    "end": "1161600"
  },
  {
    "text": "down the relative variance uh which",
    "start": "1161600",
    "end": "1163799"
  },
  {
    "text": "means we can run a much more predictable",
    "start": "1163799",
    "end": "1165679"
  },
  {
    "text": "set of of resource pools the the total",
    "start": "1165679",
    "end": "1168520"
  },
  {
    "text": "cap capacity that we run uh which is",
    "start": "1168520",
    "end": "1171240"
  },
  {
    "text": "another problem by the way so we need to",
    "start": "1171240",
    "end": "1173120"
  },
  {
    "text": "run thousands of gpus we use a lot of",
    "start": "1173120",
    "end": "1175520"
  },
  {
    "text": "different Cloud vendors we use a lot of",
    "start": "1175520",
    "end": "1176919"
  },
  {
    "text": "different regions we scale up and down",
    "start": "1176919",
    "end": "1178799"
  },
  {
    "text": "continuously uh in fact we actually end",
    "start": "1178799",
    "end": "1180720"
  },
  {
    "text": "up solving a mixed iner programming",
    "start": "1180720",
    "end": "1182440"
  },
  {
    "text": "problem to to do this uh minimizing the",
    "start": "1182440",
    "end": "1185720"
  },
  {
    "text": "total cost spend uh and and this is some",
    "start": "1185720",
    "end": "1188159"
  },
  {
    "text": "of the stuff we have to do for for our",
    "start": "1188159",
    "end": "1189720"
  },
  {
    "text": "customers so they don't have to think",
    "start": "1189720",
    "end": "1191080"
  },
  {
    "text": "about it so through model you can come",
    "start": "1191080",
    "end": "1192880"
  },
  {
    "text": "in and you can request 100 gpus under",
    "start": "1192880",
    "end": "1195000"
  },
  {
    "text": "the hood there's enormous amount of work",
    "start": "1195000",
    "end": "1196760"
  },
  {
    "text": "that we have to put in in order to get",
    "start": "1196760",
    "end": "1198520"
  },
  {
    "text": "the capacity somewhere in the world uh",
    "start": "1198520",
    "end": "1201440"
  },
  {
    "text": "you know spinning up gpus if needed uh",
    "start": "1201440",
    "end": "1204159"
  },
  {
    "text": "but in many cases it happens",
    "start": "1204159",
    "end": "1205400"
  },
  {
    "text": "instantaneously because we can maintain",
    "start": "1205400",
    "end": "1206840"
  },
  {
    "text": "a buffer that makes it very fast to get",
    "start": "1206840",
    "end": "1208799"
  },
  {
    "text": "access to these compute resources for",
    "start": "1208799",
    "end": "1210240"
  },
  {
    "text": "any",
    "start": "1210240",
    "end": "1211080"
  },
  {
    "text": "customer",
    "start": "1211080",
    "end": "1212679"
  },
  {
    "text": "um this was very technical but just to",
    "start": "1212679",
    "end": "1215600"
  },
  {
    "text": "kind of go back and look at a high level",
    "start": "1215600",
    "end": "1217360"
  },
  {
    "text": "again uh why do people like modal people",
    "start": "1217360",
    "end": "1221360"
  },
  {
    "text": "pick modal in because they can run their",
    "start": "1221360",
    "end": "1224400"
  },
  {
    "text": "own code we're not an AI API so to speak",
    "start": "1224400",
    "end": "1227679"
  },
  {
    "text": "you can run almost anything with modal",
    "start": "1227679",
    "end": "1230039"
  },
  {
    "text": "uh we make it possible to iterate very",
    "start": "1230039",
    "end": "1231480"
  },
  {
    "text": "quickly we're fully usage based so when",
    "start": "1231480",
    "end": "1234120"
  },
  {
    "text": "you run things in modal you only pay for",
    "start": "1234120",
    "end": "1235760"
  },
  {
    "text": "the time the containers are actually",
    "start": "1235760",
    "end": "1237760"
  },
  {
    "text": "active you have to never think about",
    "start": "1237760",
    "end": "1239960"
  },
  {
    "text": "capacity you don't have to you know go",
    "start": "1239960",
    "end": "1241919"
  },
  {
    "text": "out and buy you know hundreds of gpus or",
    "start": "1241919",
    "end": "1244080"
  },
  {
    "text": "thousands of gpus we can get you that",
    "start": "1244080",
    "end": "1246400"
  },
  {
    "text": "within you know seconds or at least",
    "start": "1246400",
    "end": "1247840"
  },
  {
    "text": "minutes uh so there's a lot of things",
    "start": "1247840",
    "end": "1249960"
  },
  {
    "text": "the sort of burden of infrastructure",
    "start": "1249960",
    "end": "1252159"
  },
  {
    "text": "building your own internal platform",
    "start": "1252159",
    "end": "1253919"
  },
  {
    "text": "setting up kubernetes setting up you",
    "start": "1253919",
    "end": "1255760"
  },
  {
    "text": "know Docker and all these things you",
    "start": "1255760",
    "end": "1257520"
  },
  {
    "text": "don't have to think about this with",
    "start": "1257520",
    "end": "1259440"
  },
  {
    "text": "model um how do you try model it's",
    "start": "1259440",
    "end": "1262159"
  },
  {
    "text": "actually very simple uh you go to your",
    "start": "1262159",
    "end": "1263640"
  },
  {
    "text": "terminal you do pip install model the",
    "start": "1263640",
    "end": "1265720"
  },
  {
    "text": "the python client automatically you know",
    "start": "1265720",
    "end": "1268080"
  },
  {
    "text": "configures itself to connect to uh modal",
    "start": "1268080",
    "end": "1271480"
  },
  {
    "text": "and you can immediately start running",
    "start": "1271480",
    "end": "1272760"
  },
  {
    "text": "stuff because we give everyone $30 a",
    "start": "1272760",
    "end": "1274440"
  },
  {
    "text": "month uh per per month of free credits",
    "start": "1274440",
    "end": "1277320"
  },
  {
    "text": "if you are a startup uh we can give you",
    "start": "1277320",
    "end": "1280039"
  },
  {
    "text": "up to $50,000 in credits in order for",
    "start": "1280039",
    "end": "1282640"
  },
  {
    "text": "you to get",
    "start": "1282640",
    "end": "1284320"
  },
  {
    "text": "started thank you and I really hope you",
    "start": "1284320",
    "end": "1287640"
  },
  {
    "text": "enjoy this",
    "start": "1287640",
    "end": "1289360"
  },
  {
    "text": "and if you have any questions feel free",
    "start": "1289360",
    "end": "1290679"
  },
  {
    "text": "to reach out Eric oto.com uh you can",
    "start": "1290679",
    "end": "1293279"
  },
  {
    "text": "also follow me on Twitter bernhardson or",
    "start": "1293279",
    "end": "1295840"
  },
  {
    "text": "check out my blog here at burn.com",
    "start": "1295840",
    "end": "1299400"
  }
]
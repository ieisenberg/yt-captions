[
  {
    "text": "[Music]",
    "start": "350",
    "end": "14050"
  },
  {
    "text": "hi everyone uh I'm Leo I'm the chief",
    "start": "14360",
    "end": "16520"
  },
  {
    "text": "scientistic gradient and uh today I'll",
    "start": "16520",
    "end": "19920"
  },
  {
    "text": "be talking about how we trained uh large",
    "start": "19920",
    "end": "22359"
  },
  {
    "text": "language models to be Finance",
    "start": "22359",
    "end": "24519"
  },
  {
    "text": "experts um yeah let just go ahead and",
    "start": "24519",
    "end": "27400"
  },
  {
    "text": "dive right into it uh so so before kind",
    "start": "27400",
    "end": "30519"
  },
  {
    "text": "of I I start getting into the the",
    "start": "30519",
    "end": "32320"
  },
  {
    "text": "details here I wanted to make a couple",
    "start": "32320",
    "end": "33800"
  },
  {
    "text": "of observations and the the first one is",
    "start": "33800",
    "end": "37559"
  },
  {
    "text": "that uh foundational models have been",
    "start": "37559",
    "end": "39640"
  },
  {
    "text": "growing at an exponential rate uh right",
    "start": "39640",
    "end": "42760"
  },
  {
    "text": "so not only do you kind of bespoke AI",
    "start": "42760",
    "end": "46079"
  },
  {
    "text": "companies each have their own",
    "start": "46079",
    "end": "47440"
  },
  {
    "text": "foundational models but data companies",
    "start": "47440",
    "end": "50920"
  },
  {
    "text": "uh General tech companies uh they all",
    "start": "50920",
    "end": "53760"
  },
  {
    "text": "have their own flavor of a language",
    "start": "53760",
    "end": "55239"
  },
  {
    "text": "model each with its own features uh and",
    "start": "55239",
    "end": "57960"
  },
  {
    "text": "use cases and another observation which",
    "start": "57960",
    "end": "61280"
  },
  {
    "text": "is which is pretty related is that the",
    "start": "61280",
    "end": "63760"
  },
  {
    "text": "context length right the the number of",
    "start": "63760",
    "end": "65720"
  },
  {
    "text": "tokens that that you can fit into a",
    "start": "65720",
    "end": "67720"
  },
  {
    "text": "prompt uh has increased quite a bit over",
    "start": "67720",
    "end": "69880"
  },
  {
    "text": "the past year um the the largest context",
    "start": "69880",
    "end": "73040"
  },
  {
    "text": "length models about a year ago were",
    "start": "73040",
    "end": "74640"
  },
  {
    "text": "something like",
    "start": "74640",
    "end": "75880"
  },
  {
    "text": "100k um and uh in the past year they've",
    "start": "75880",
    "end": "78880"
  },
  {
    "text": "grown to about 40 times that uh just in",
    "start": "78880",
    "end": "81840"
  },
  {
    "text": "models released in the past few months",
    "start": "81840",
    "end": "83759"
  },
  {
    "text": "including One released by",
    "start": "83759",
    "end": "85520"
  },
  {
    "text": "gradient um and and both of these uh",
    "start": "85520",
    "end": "88720"
  },
  {
    "text": "observations are evidence to kind of one",
    "start": "88720",
    "end": "92119"
  },
  {
    "text": "one point and that's the large language",
    "start": "92119",
    "end": "94119"
  },
  {
    "text": "models are not one- siiz pitol um",
    "start": "94119",
    "end": "97119"
  },
  {
    "text": "especially when you get to kind of more",
    "start": "97119",
    "end": "98560"
  },
  {
    "text": "complicated use cases uh taking a",
    "start": "98560",
    "end": "101439"
  },
  {
    "text": "generalist language model uh or or a",
    "start": "101439",
    "end": "104360"
  },
  {
    "text": "base language model kind of off the",
    "start": "104360",
    "end": "105880"
  },
  {
    "text": "shelf because it isn't really going to",
    "start": "105880",
    "end": "106960"
  },
  {
    "text": "get you too far um and and I realize I'm",
    "start": "106960",
    "end": "110079"
  },
  {
    "text": "I'm talking at the open models track of",
    "start": "110079",
    "end": "112280"
  },
  {
    "text": "a conference I probably don't need to",
    "start": "112280",
    "end": "113880"
  },
  {
    "text": "convince you guys uh too much of this",
    "start": "113880",
    "end": "116240"
  },
  {
    "text": "statement but um it is pretty important",
    "start": "116240",
    "end": "118960"
  },
  {
    "text": "for us in gradient is actually our our",
    "start": "118960",
    "end": "121079"
  },
  {
    "text": "foundational thesis for for what we",
    "start": "121079",
    "end": "123280"
  },
  {
    "text": "built uh which is an AI Foundry and uh",
    "start": "123280",
    "end": "127039"
  },
  {
    "text": "for us what an AI Foundry is is it's a",
    "start": "127039",
    "end": "129920"
  },
  {
    "text": "collection of custom language models uh",
    "start": "129920",
    "end": "132280"
  },
  {
    "text": "as well as a number of workflow",
    "start": "132280",
    "end": "134239"
  },
  {
    "text": "Primitives and what we do is we take all",
    "start": "134239",
    "end": "136599"
  },
  {
    "text": "these pieces and components together uh",
    "start": "136599",
    "end": "139000"
  },
  {
    "text": "to create solutions that are a custom",
    "start": "139000",
    "end": "141040"
  },
  {
    "text": "fit uh for our customers and and today",
    "start": "141040",
    "end": "143720"
  },
  {
    "text": "I'm going to talk about specifically uh",
    "start": "143720",
    "end": "146280"
  },
  {
    "text": "our solutions for the finance domain",
    "start": "146280",
    "end": "148560"
  },
  {
    "text": "right building Financial expert s um and",
    "start": "148560",
    "end": "151519"
  },
  {
    "text": "and for those Solutions really uh two",
    "start": "151519",
    "end": "153760"
  },
  {
    "text": "components have been incredibly useful",
    "start": "153760",
    "end": "156120"
  },
  {
    "text": "uh one uh should be fairly fairly",
    "start": "156120",
    "end": "159000"
  },
  {
    "text": "straightforward is our uh domain",
    "start": "159000",
    "end": "161640"
  },
  {
    "text": "specific Finance language model and the",
    "start": "161640",
    "end": "163640"
  },
  {
    "text": "other one is a context length extension",
    "start": "163640",
    "end": "166440"
  },
  {
    "text": "that we've worked",
    "start": "166440",
    "end": "168360"
  },
  {
    "text": "on um and and so why are these important",
    "start": "168360",
    "end": "171000"
  },
  {
    "text": "specifically for finance well a little",
    "start": "171000",
    "end": "173120"
  },
  {
    "text": "while ago we we got together and wrote",
    "start": "173120",
    "end": "175159"
  },
  {
    "text": "down kind of six requirements for",
    "start": "175159",
    "end": "176720"
  },
  {
    "text": "finance applications of language models",
    "start": "176720",
    "end": "179280"
  },
  {
    "text": "that that generally IST models uh tend",
    "start": "179280",
    "end": "181360"
  },
  {
    "text": "tend to lack or fall a little bit short",
    "start": "181360",
    "end": "182879"
  },
  {
    "text": "on um you know if you look at these uh",
    "start": "182879",
    "end": "186440"
  },
  {
    "text": "requirements that they're fairly General",
    "start": "186440",
    "end": "188120"
  },
  {
    "text": "they kind of apply across uh Industries",
    "start": "188120",
    "end": "190200"
  },
  {
    "text": "but in particular for finance they seem",
    "start": "190200",
    "end": "191840"
  },
  {
    "text": "pretty important um and today I'm just",
    "start": "191840",
    "end": "194680"
  },
  {
    "text": "going to talk about two of them uh that",
    "start": "194680",
    "end": "197239"
  },
  {
    "text": "happen to be paired uh with uh the two",
    "start": "197239",
    "end": "200640"
  },
  {
    "text": "solutions that I also want to talk about",
    "start": "200640",
    "end": "202720"
  },
  {
    "text": "the finance language model and and the",
    "start": "202720",
    "end": "204599"
  },
  {
    "text": "extended context",
    "start": "204599",
    "end": "207480"
  },
  {
    "text": "length so um jump",
    "start": "207519",
    "end": "210280"
  },
  {
    "text": "uh jumping right into it uh the first",
    "start": "210280",
    "end": "212680"
  },
  {
    "text": "one is the uh Finance language model um",
    "start": "212680",
    "end": "216519"
  },
  {
    "text": "you know you might be wondering uh why",
    "start": "216519",
    "end": "218760"
  },
  {
    "text": "why even have a domain specific language",
    "start": "218760",
    "end": "221400"
  },
  {
    "text": "model uh why is domain knowledge",
    "start": "221400",
    "end": "223560"
  },
  {
    "text": "important uh the the reason is is that",
    "start": "223560",
    "end": "226519"
  },
  {
    "text": "your your general purpose language",
    "start": "226519",
    "end": "228000"
  },
  {
    "text": "models like like the gpts of the world",
    "start": "228000",
    "end": "230879"
  },
  {
    "text": "um they are uh trained on on a very",
    "start": "230879",
    "end": "234239"
  },
  {
    "text": "broad set of data uh kind of broad not",
    "start": "234239",
    "end": "236920"
  },
  {
    "text": "deep uh especially in in kind of like",
    "start": "236920",
    "end": "238959"
  },
  {
    "text": "more technical situations like technical",
    "start": "238959",
    "end": "240959"
  },
  {
    "text": "financial",
    "start": "240959",
    "end": "241959"
  },
  {
    "text": "information um and as kind of like an",
    "start": "241959",
    "end": "244319"
  },
  {
    "text": "illustrative example on why this is",
    "start": "244319",
    "end": "246439"
  },
  {
    "text": "important uh here's a chart from a",
    "start": "246439",
    "end": "248959"
  },
  {
    "text": "recent research paper and it shows that",
    "start": "248959",
    "end": "251760"
  },
  {
    "text": "even for very large models right the the",
    "start": "251760",
    "end": "253840"
  },
  {
    "text": "red line at the top there is for 176",
    "start": "253840",
    "end": "256560"
  },
  {
    "text": "billion parameter model um you need",
    "start": "256560",
    "end": "259040"
  },
  {
    "text": "something on the order of thousands of",
    "start": "259040",
    "end": "261120"
  },
  {
    "text": "relevant documents in the model's",
    "start": "261120",
    "end": "263160"
  },
  {
    "text": "pre-training uh in order for the model",
    "start": "263160",
    "end": "265160"
  },
  {
    "text": "to get decent I mean here it's even",
    "start": "265160",
    "end": "267199"
  },
  {
    "text": "above 50% accuracy uh on answering a",
    "start": "267199",
    "end": "270320"
  },
  {
    "text": "related question right and so uh kind of",
    "start": "270320",
    "end": "273199"
  },
  {
    "text": "what this implies is that if you ask a",
    "start": "273199",
    "end": "275520"
  },
  {
    "text": "language model questions uh about uh",
    "start": "275520",
    "end": "278880"
  },
  {
    "text": "data that's kind of like in the tales of",
    "start": "278880",
    "end": "280360"
  },
  {
    "text": "its training data um then it's going to",
    "start": "280360",
    "end": "283320"
  },
  {
    "text": "do a poor job at answering those",
    "start": "283320",
    "end": "284680"
  },
  {
    "text": "questions right and so um you know the",
    "start": "284680",
    "end": "287639"
  },
  {
    "text": "the natural way to fix this is the okay",
    "start": "287639",
    "end": "289720"
  },
  {
    "text": "is to say okay uh base model doesn't",
    "start": "289720",
    "end": "292160"
  },
  {
    "text": "know a lot about Finance let's train it",
    "start": "292160",
    "end": "294680"
  },
  {
    "text": "some",
    "start": "294680",
    "end": "295720"
  },
  {
    "text": "Finance um and issue there um and here",
    "start": "295720",
    "end": "299720"
  },
  {
    "text": "here I'm going to talk about kind of how",
    "start": "299720",
    "end": "301160"
  },
  {
    "text": "we trained our our finance specific",
    "start": "301160",
    "end": "303440"
  },
  {
    "text": "language model is uh so an issue there",
    "start": "303440",
    "end": "306400"
  },
  {
    "text": "is that there's there's a whole lot of",
    "start": "306400",
    "end": "307720"
  },
  {
    "text": "financial data out there right like way",
    "start": "307720",
    "end": "309440"
  },
  {
    "text": "more uh than you could possibly uh",
    "start": "309440",
    "end": "312080"
  },
  {
    "text": "review or look at manually um and so",
    "start": "312080",
    "end": "314840"
  },
  {
    "text": "that requires creating an automated data",
    "start": "314840",
    "end": "316919"
  },
  {
    "text": "pipeline um and we that's what we did we",
    "start": "316919",
    "end": "320039"
  },
  {
    "text": "created one uh probably the the most uh",
    "start": "320039",
    "end": "323240"
  },
  {
    "text": "compelling or interesting part of this",
    "start": "323240",
    "end": "324800"
  },
  {
    "text": "data pipeline is the automated data",
    "start": "324800",
    "end": "326720"
  },
  {
    "text": "curation uh where we borrowed ideas from",
    "start": "326720",
    "end": "331600"
  },
  {
    "text": "U the membership inference literature",
    "start": "331600",
    "end": "334080"
  },
  {
    "text": "and so what we do is we amass a whole",
    "start": "334080",
    "end": "336280"
  },
  {
    "text": "large Corpus of of training data um and",
    "start": "336280",
    "end": "339840"
  },
  {
    "text": "then uh we use techniques to to try to",
    "start": "339840",
    "end": "342520"
  },
  {
    "text": "see if a particular document uh if",
    "start": "342520",
    "end": "345160"
  },
  {
    "text": "there's a high chance that it was",
    "start": "345160",
    "end": "346479"
  },
  {
    "text": "already in the models training data",
    "start": "346479",
    "end": "347960"
  },
  {
    "text": "right so maybe you have like a llama",
    "start": "347960",
    "end": "349199"
  },
  {
    "text": "base model you have a document uh and",
    "start": "349199",
    "end": "351319"
  },
  {
    "text": "you can run some of these techniques to",
    "start": "351319",
    "end": "353080"
  },
  {
    "text": "to get a probability of whether or not",
    "start": "353080",
    "end": "354560"
  },
  {
    "text": "the model already seen that data in",
    "start": "354560",
    "end": "356039"
  },
  {
    "text": "training uh so you filter out all the",
    "start": "356039",
    "end": "358240"
  },
  {
    "text": "data that the model hasn't seen before",
    "start": "358240",
    "end": "359680"
  },
  {
    "text": "for uh what you're left with is a much",
    "start": "359680",
    "end": "361600"
  },
  {
    "text": "smaller set of data now that's uh",
    "start": "361600",
    "end": "363479"
  },
  {
    "text": "manageable to to look at through human",
    "start": "363479",
    "end": "365919"
  },
  {
    "text": "review uh and then finally pass through",
    "start": "365919",
    "end": "368400"
  },
  {
    "text": "to a synthetic data augmentation right",
    "start": "368400",
    "end": "371240"
  },
  {
    "text": "both to upsample data uh and to handle",
    "start": "371240",
    "end": "374520"
  },
  {
    "text": "uh some variations in data",
    "start": "374520",
    "end": "376199"
  },
  {
    "text": "representation and",
    "start": "376199",
    "end": "378960"
  },
  {
    "text": "formatting um and and kind of like the",
    "start": "379599",
    "end": "382360"
  },
  {
    "text": "the last part of of the recipe for for",
    "start": "382360",
    "end": "384800"
  },
  {
    "text": "How to Train um domain specific uh",
    "start": "384800",
    "end": "388479"
  },
  {
    "text": "language models uh is to take that data",
    "start": "388479",
    "end": "391440"
  },
  {
    "text": "set that you created and and to pass it",
    "start": "391440",
    "end": "393400"
  },
  {
    "text": "through a training pipeline um I think",
    "start": "393400",
    "end": "397000"
  },
  {
    "text": "by now a training pipeline like this is",
    "start": "397000",
    "end": "399360"
  },
  {
    "text": "is fairly standard uh there there's two",
    "start": "399360",
    "end": "401759"
  },
  {
    "text": "main parts one is the continuous",
    "start": "401759",
    "end": "403840"
  },
  {
    "text": "pre-training so you take that data set",
    "start": "403840",
    "end": "406280"
  },
  {
    "text": "uh that you created on on the previous",
    "start": "406280",
    "end": "408120"
  },
  {
    "text": "slide uh and you do kind of next token",
    "start": "408120",
    "end": "410599"
  },
  {
    "text": "prediction uh on it uh off of a a base",
    "start": "410599",
    "end": "414240"
  },
  {
    "text": "existing model right so again uh we're",
    "start": "414240",
    "end": "416360"
  },
  {
    "text": "taking a a base foundational model like",
    "start": "416360",
    "end": "418360"
  },
  {
    "text": "a llama model uh to start with and then",
    "start": "418360",
    "end": "420800"
  },
  {
    "text": "the second part uh is you do um is you",
    "start": "420800",
    "end": "424039"
  },
  {
    "text": "run alignments on the model uh here ran",
    "start": "424039",
    "end": "427560"
  },
  {
    "text": "both supervised fine-tuning and",
    "start": "427560",
    "end": "429319"
  },
  {
    "text": "preference optimization um and and kind",
    "start": "429319",
    "end": "432120"
  },
  {
    "text": "of the way I like to think about uh the",
    "start": "432120",
    "end": "434440"
  },
  {
    "text": "division between uh these two tasks is",
    "start": "434440",
    "end": "437160"
  },
  {
    "text": "pre-training is something like if you",
    "start": "437160",
    "end": "439199"
  },
  {
    "text": "had a bunch of textbooks and you wanted",
    "start": "439199",
    "end": "441400"
  },
  {
    "text": "a model to read all those textbooks and",
    "start": "441400",
    "end": "443360"
  },
  {
    "text": "and understand all all that information",
    "start": "443360",
    "end": "445319"
  },
  {
    "text": "or retain all that information and",
    "start": "445319",
    "end": "447599"
  },
  {
    "text": "Alignment is kind of like uh then",
    "start": "447599",
    "end": "450479"
  },
  {
    "text": "instructing the model on how to use that",
    "start": "450479",
    "end": "452280"
  },
  {
    "text": "information or best practices and what",
    "start": "452280",
    "end": "454319"
  },
  {
    "text": "to do with that um and so if",
    "start": "454319",
    "end": "456759"
  },
  {
    "text": "pre-training is like reading textbooks",
    "start": "456759",
    "end": "458520"
  },
  {
    "text": "alignment is like maybe like taking an",
    "start": "458520",
    "end": "460360"
  },
  {
    "text": "exam uh on a class or working on a",
    "start": "460360",
    "end": "463680"
  },
  {
    "text": "project right and um that's really all I",
    "start": "463680",
    "end": "466360"
  },
  {
    "text": "want to say about the domain specific",
    "start": "466360",
    "end": "468199"
  },
  {
    "text": "language model um now I want to talk",
    "start": "468199",
    "end": "470639"
  },
  {
    "text": "about the see how much time I have great",
    "start": "470639",
    "end": "473159"
  },
  {
    "text": "um about the other part which is the uh",
    "start": "473159",
    "end": "475720"
  },
  {
    "text": "extended context and uh how extended",
    "start": "475720",
    "end": "478800"
  },
  {
    "text": "context are long context language models",
    "start": "478800",
    "end": "481479"
  },
  {
    "text": "uh help us address",
    "start": "481479",
    "end": "483520"
  },
  {
    "text": "hallucinations right uh to give a quick",
    "start": "483520",
    "end": "485680"
  },
  {
    "text": "refresher what are hallucinations well",
    "start": "485680",
    "end": "487479"
  },
  {
    "text": "it's a pretty broad term uh and it's",
    "start": "487479",
    "end": "489560"
  },
  {
    "text": "used quite frequently nowadays it's it's",
    "start": "489560",
    "end": "491800"
  },
  {
    "text": "whenever uh you run inference on a Model",
    "start": "491800",
    "end": "495360"
  },
  {
    "text": "when you give it a query and it",
    "start": "495360",
    "end": "496800"
  },
  {
    "text": "generates content that is irrelevant or",
    "start": "496800",
    "end": "498919"
  },
  {
    "text": "made up or inconsistent with the input",
    "start": "498919",
    "end": "500720"
  },
  {
    "text": "data um there's been a fair amount of",
    "start": "500720",
    "end": "504199"
  },
  {
    "text": "research as to the cause of",
    "start": "504199",
    "end": "506120"
  },
  {
    "text": "hallucinations a lot of that research",
    "start": "506120",
    "end": "508360"
  },
  {
    "text": "points to deficiencies in the underlying",
    "start": "508360",
    "end": "511039"
  },
  {
    "text": "training data right so some some causes",
    "start": "511039",
    "end": "514360"
  },
  {
    "text": "might be just the training data is",
    "start": "514360",
    "end": "515719"
  },
  {
    "text": "outdated right you're asking the model",
    "start": "515719",
    "end": "517599"
  },
  {
    "text": "of question on information that is now",
    "start": "517599",
    "end": "520080"
  },
  {
    "text": "updated since the training data uh",
    "start": "520080",
    "end": "522320"
  },
  {
    "text": "another one is uh a lot of the training",
    "start": "522320",
    "end": "525120"
  },
  {
    "text": "data uh practices require automated data",
    "start": "525120",
    "end": "528120"
  },
  {
    "text": "collection and if there's ever",
    "start": "528120",
    "end": "530200"
  },
  {
    "text": "inconsistencies or bugs in that uh data",
    "start": "530200",
    "end": "532920"
  },
  {
    "text": "collection um you can get Source",
    "start": "532920",
    "end": "535080"
  },
  {
    "text": "reference Divergence right so the model",
    "start": "535080",
    "end": "536760"
  },
  {
    "text": "is just trained on data that doesn't",
    "start": "536760",
    "end": "538040"
  },
  {
    "text": "quite make sense uh and and there's a",
    "start": "538040",
    "end": "539959"
  },
  {
    "text": "few other reasons all of these uh can uh",
    "start": "539959",
    "end": "543519"
  },
  {
    "text": "encode information in the model's memory",
    "start": "543519",
    "end": "545680"
  },
  {
    "text": "banks that there isn't quite accurate uh",
    "start": "545680",
    "end": "548440"
  },
  {
    "text": "and and that'll cause a model",
    "start": "548440",
    "end": "550240"
  },
  {
    "text": "hallucinate and while uh alignment or or",
    "start": "550240",
    "end": "554480"
  },
  {
    "text": "uh continued training of the model can",
    "start": "554480",
    "end": "556959"
  },
  {
    "text": "alleviate",
    "start": "556959",
    "end": "558079"
  },
  {
    "text": "hallucinations um at gradient we find",
    "start": "558079",
    "end": "560800"
  },
  {
    "text": "that actually in context learning so uh",
    "start": "560800",
    "end": "563800"
  },
  {
    "text": "working directly on the prompt during",
    "start": "563800",
    "end": "565760"
  },
  {
    "text": "the execution pipeline uh is the most",
    "start": "565760",
    "end": "568440"
  },
  {
    "text": "direct in in sample efficient way to",
    "start": "568440",
    "end": "570640"
  },
  {
    "text": "reduce hallucinations right because uh",
    "start": "570640",
    "end": "573200"
  },
  {
    "text": "what you can do is you can put in a",
    "start": "573200",
    "end": "574959"
  },
  {
    "text": "relatively small amount of information",
    "start": "574959",
    "end": "577000"
  },
  {
    "text": "directly into the prompt uh kind of at",
    "start": "577000",
    "end": "579480"
  },
  {
    "text": "inference time uh and sort of uh plaster",
    "start": "579480",
    "end": "582480"
  },
  {
    "text": "over or Band-Aid over uh issues with",
    "start": "582480",
    "end": "585440"
  },
  {
    "text": "with the models training",
    "start": "585440",
    "end": "586760"
  },
  {
    "text": "data um and so that's great in context",
    "start": "586760",
    "end": "589240"
  },
  {
    "text": "learning works really well um the issue",
    "start": "589240",
    "end": "592399"
  },
  {
    "text": "is it works so well that when you start",
    "start": "592399",
    "end": "594320"
  },
  {
    "text": "doing it you want to do more and more of",
    "start": "594320",
    "end": "595800"
  },
  {
    "text": "it and and then kind of you run into the",
    "start": "595800",
    "end": "598519"
  },
  {
    "text": "one of one of the biggest pain points uh",
    "start": "598519",
    "end": "600480"
  },
  {
    "text": "with this practice are one of the",
    "start": "600480",
    "end": "602040"
  },
  {
    "text": "biggest bottlenecks uh which is the",
    "start": "602040",
    "end": "604320"
  },
  {
    "text": "context length um and I'm guessing that",
    "start": "604320",
    "end": "607800"
  },
  {
    "text": "this is an issue that that many of you",
    "start": "607800",
    "end": "609399"
  },
  {
    "text": "in this room have have come across",
    "start": "609399",
    "end": "611279"
  },
  {
    "text": "yourselves um and that's you just run",
    "start": "611279",
    "end": "614040"
  },
  {
    "text": "out of prompt uh in in terms of for in",
    "start": "614040",
    "end": "616760"
  },
  {
    "text": "context learning um a few examples uh",
    "start": "616760",
    "end": "620000"
  },
  {
    "text": "for why that can be an issue uh if",
    "start": "620000",
    "end": "622200"
  },
  {
    "text": "you're trying to put in a few shot",
    "start": "622200",
    "end": "624360"
  },
  {
    "text": "examples into the prompt you run out of",
    "start": "624360",
    "end": "626480"
  },
  {
    "text": "prompt space before you run out of",
    "start": "626480",
    "end": "627920"
  },
  {
    "text": "examples so now you have to spend a lot",
    "start": "627920",
    "end": "629519"
  },
  {
    "text": "of time in choosing the particular",
    "start": "629519",
    "end": "631079"
  },
  {
    "text": "example or or working on some kind of",
    "start": "631079",
    "end": "633320"
  },
  {
    "text": "like lossy summarization technique um",
    "start": "633320",
    "end": "636160"
  },
  {
    "text": "for more complex Pro problems they may",
    "start": "636160",
    "end": "638639"
  },
  {
    "text": "require some brittle uh pre-processing",
    "start": "638639",
    "end": "641360"
  },
  {
    "text": "pipelines each can have errors um and",
    "start": "641360",
    "end": "644399"
  },
  {
    "text": "also if you do some kind of external",
    "start": "644399",
    "end": "645880"
  },
  {
    "text": "memory management such as rag uh those",
    "start": "645880",
    "end": "649000"
  },
  {
    "text": "systems tend to have poor performance",
    "start": "649000",
    "end": "651519"
  },
  {
    "text": "when the chunks that get pulled uh",
    "start": "651519",
    "end": "654560"
  },
  {
    "text": "require them to be interrelated right so",
    "start": "654560",
    "end": "656760"
  },
  {
    "text": "if you pull one chunk and another chunk",
    "start": "656760",
    "end": "658399"
  },
  {
    "text": "that you need to pull",
    "start": "658399",
    "end": "659800"
  },
  {
    "text": "uh has to reference a previous chunk to",
    "start": "659800",
    "end": "662480"
  },
  {
    "text": "to know if it needs to get uh queried",
    "start": "662480",
    "end": "665480"
  },
  {
    "text": "right and rag does typically does a",
    "start": "665480",
    "end": "667040"
  },
  {
    "text": "pretty poort job at",
    "start": "667040",
    "end": "668639"
  },
  {
    "text": "that um right so context length is the",
    "start": "668639",
    "end": "672399"
  },
  {
    "text": "bottleneck for this so the most natural",
    "start": "672399",
    "end": "674680"
  },
  {
    "text": "thing to do is just extend the context",
    "start": "674680",
    "end": "676680"
  },
  {
    "text": "length um and and so that's that's what",
    "start": "676680",
    "end": "680040"
  },
  {
    "text": "we did with with some of our models uh",
    "start": "680040",
    "end": "682399"
  },
  {
    "text": "and here really I just wanted to talk",
    "start": "682399",
    "end": "684079"
  },
  {
    "text": "about a couple of examples of what",
    "start": "684079",
    "end": "687000"
  },
  {
    "text": "suddenly becomes possible um when you",
    "start": "687000",
    "end": "689959"
  },
  {
    "text": "have a context link that that's sort of",
    "start": "689959",
    "end": "692200"
  },
  {
    "text": "in the realm of of a million tokens long",
    "start": "692200",
    "end": "695320"
  },
  {
    "text": "um here on on the leftand side uh is an",
    "start": "695320",
    "end": "698519"
  },
  {
    "text": "example showing that you can now",
    "start": "698519",
    "end": "700160"
  },
  {
    "text": "actually put thousands of examples",
    "start": "700160",
    "end": "702200"
  },
  {
    "text": "directly into the prompt uh and that",
    "start": "702200",
    "end": "704200"
  },
  {
    "text": "kind of gets you back into this kind of",
    "start": "704200",
    "end": "706079"
  },
  {
    "text": "like domain learning regime that I",
    "start": "706079",
    "end": "707639"
  },
  {
    "text": "talked about earlier uh it's just now it",
    "start": "707639",
    "end": "710200"
  },
  {
    "text": "is uh on the Fly and at inference time",
    "start": "710200",
    "end": "712839"
  },
  {
    "text": "right so it can be very adaptive to the",
    "start": "712839",
    "end": "714440"
  },
  {
    "text": "problem um and uh you you do find that",
    "start": "714440",
    "end": "718440"
  },
  {
    "text": "uh for a lot of Tas out there this like",
    "start": "718440",
    "end": "720480"
  },
  {
    "text": "thousands of examples Mark is actually",
    "start": "720480",
    "end": "723000"
  },
  {
    "text": "necessary uh to get kind of production",
    "start": "723000",
    "end": "725279"
  },
  {
    "text": "grade accuracy or or dangerous levels of",
    "start": "725279",
    "end": "728040"
  },
  {
    "text": "accuracy for a model um and and the",
    "start": "728040",
    "end": "730600"
  },
  {
    "text": "other example is uh with a long context",
    "start": "730600",
    "end": "733600"
  },
  {
    "text": "length um you can Leverage What",
    "start": "733600",
    "end": "736360"
  },
  {
    "text": "Transformer models are are natively",
    "start": "736360",
    "end": "738600"
  },
  {
    "text": "really good at which is being able to",
    "start": "738600",
    "end": "740680"
  },
  {
    "text": "attend to every single token in the",
    "start": "740680",
    "end": "742480"
  },
  {
    "text": "prompt um and by doing that you can",
    "start": "742480",
    "end": "744800"
  },
  {
    "text": "actually have the model perform uh",
    "start": "744800",
    "end": "746600"
  },
  {
    "text": "fairly complicated reasoning uh implicit",
    "start": "746600",
    "end": "749399"
  },
  {
    "text": "L just just in through through going",
    "start": "749399",
    "end": "751480"
  },
  {
    "text": "through its layers and attention layers",
    "start": "751480",
    "end": "754160"
  },
  {
    "text": "um and an example that um that we kind",
    "start": "754160",
    "end": "757240"
  },
  {
    "text": "of uh cooked up uh inhouse uh was we",
    "start": "757240",
    "end": "761720"
  },
  {
    "text": "took uh books that were written by Mark",
    "start": "761720",
    "end": "764399"
  },
  {
    "text": "Twain the author uh and first we scrub",
    "start": "764399",
    "end": "767320"
  },
  {
    "text": "the books of any kind of identifying",
    "start": "767320",
    "end": "768880"
  },
  {
    "text": "information right so so no mention of",
    "start": "768880",
    "end": "770399"
  },
  {
    "text": "the author or anything like that uh and",
    "start": "770399",
    "end": "772360"
  },
  {
    "text": "then we gave that into the model uh into",
    "start": "772360",
    "end": "774480"
  },
  {
    "text": "its prompt into its context and asked",
    "start": "774480",
    "end": "776320"
  },
  {
    "text": "the model to generate new stories in the",
    "start": "776320",
    "end": "778760"
  },
  {
    "text": "same style uh and after kind of five",
    "start": "778760",
    "end": "781560"
  },
  {
    "text": "books of of reference prompts the model",
    "start": "781560",
    "end": "784000"
  },
  {
    "text": "was uh able to generate stories um that",
    "start": "784000",
    "end": "787360"
  },
  {
    "text": "convinced a separate critic model uh",
    "start": "787360",
    "end": "790279"
  },
  {
    "text": "that those short stories could have been",
    "start": "790279",
    "end": "792040"
  },
  {
    "text": "actually written uh by that same author",
    "start": "792040",
    "end": "794959"
  },
  {
    "text": "right uh and and in pretty actually like",
    "start": "794959",
    "end": "797000"
  },
  {
    "text": "deep and intricate ways not just kind of",
    "start": "797000",
    "end": "799240"
  },
  {
    "text": "like stylistic similarity or language uh",
    "start": "799240",
    "end": "802079"
  },
  {
    "text": "but down to theme and characters and",
    "start": "802079",
    "end": "804279"
  },
  {
    "text": "setting and things like that so uh kind",
    "start": "804279",
    "end": "806959"
  },
  {
    "text": "of the punchline is is that long context",
    "start": "806959",
    "end": "808720"
  },
  {
    "text": "language models give you more grounded",
    "start": "808720",
    "end": "811199"
  },
  {
    "text": "and robust systems and there's fewer",
    "start": "811199",
    "end": "813040"
  },
  {
    "text": "moving Parts much more is contained in",
    "start": "813040",
    "end": "815560"
  },
  {
    "text": "the language model which which is a",
    "start": "815560",
    "end": "817120"
  },
  {
    "text": "thing that we all care about um and and",
    "start": "817120",
    "end": "819480"
  },
  {
    "text": "that in turn reduces",
    "start": "819480",
    "end": "822399"
  },
  {
    "text": "hallucinations right so um you know th",
    "start": "824440",
    "end": "827680"
  },
  {
    "text": "those are basically the the two",
    "start": "827680",
    "end": "829600"
  },
  {
    "text": "components um two solutions of our",
    "start": "829600",
    "end": "832680"
  },
  {
    "text": "platform that I wanted to to describe to",
    "start": "832680",
    "end": "834800"
  },
  {
    "text": "you all today um one of the things that",
    "start": "834800",
    "end": "837639"
  },
  {
    "text": "that we believe in pretty strongly",
    "start": "837639",
    "end": "839560"
  },
  {
    "text": "at gradient is to have transparent and",
    "start": "839560",
    "end": "841959"
  },
  {
    "text": "verifiable benchmarks uh and also we're",
    "start": "841959",
    "end": "844680"
  },
  {
    "text": "pretty passionate in giving back to the",
    "start": "844680",
    "end": "846120"
  },
  {
    "text": "open source Community because a lot of",
    "start": "846120",
    "end": "847720"
  },
  {
    "text": "what we've uh built our work on are our",
    "start": "847720",
    "end": "850600"
  },
  {
    "text": "open- source uh models and techniques",
    "start": "850600",
    "end": "853079"
  },
  {
    "text": "themselves uh and so for both of those",
    "start": "853079",
    "end": "855360"
  },
  {
    "text": "Solutions we've open source models uh on",
    "start": "855360",
    "end": "857800"
  },
  {
    "text": "our um company page at huggingface um",
    "start": "857800",
    "end": "861000"
  },
  {
    "text": "one of them is the the V alphat TR model",
    "start": "861000",
    "end": "863680"
  },
  {
    "text": "so that's the result of applying our uh",
    "start": "863680",
    "end": "866639"
  },
  {
    "text": "Finance domain training on a llama 2",
    "start": "866639",
    "end": "869120"
  },
  {
    "text": "based model um and here the the",
    "start": "869120",
    "end": "871680"
  },
  {
    "text": "benchmarks show that after doing that uh",
    "start": "871680",
    "end": "874360"
  },
  {
    "text": "it ends up being competitive uh and",
    "start": "874360",
    "end": "876800"
  },
  {
    "text": "actually better uh competitive at kind",
    "start": "876800",
    "end": "878880"
  },
  {
    "text": "of open llm General uh benchmarks and",
    "start": "878880",
    "end": "881720"
  },
  {
    "text": "better at Finance specific benchmarks uh",
    "start": "881720",
    "end": "884199"
  },
  {
    "text": "to models in in the same class to its",
    "start": "884199",
    "end": "886440"
  },
  {
    "text": "peers and the other model is um a 1",
    "start": "886440",
    "end": "890079"
  },
  {
    "text": "million context length extension of uh a",
    "start": "890079",
    "end": "893279"
  },
  {
    "text": "llama 3 based model that we released",
    "start": "893279",
    "end": "895320"
  },
  {
    "text": "pretty recently um and with it uh we we",
    "start": "895320",
    "end": "899120"
  },
  {
    "text": "were able to get uh 100% needle and a",
    "start": "899120",
    "end": "901920"
  },
  {
    "text": "hay stack scores actually uh above 1",
    "start": "901920",
    "end": "904880"
  },
  {
    "text": "million context lengths that's the first",
    "start": "904880",
    "end": "906600"
  },
  {
    "text": "image uh and also had a pretty",
    "start": "906600",
    "end": "909519"
  },
  {
    "text": "substantial performance Improvement uh",
    "start": "909519",
    "end": "911959"
  },
  {
    "text": "over the base model on a ruler long",
    "start": "911959",
    "end": "915120"
  },
  {
    "text": "context length Benchmark that's a",
    "start": "915120",
    "end": "916759"
  },
  {
    "text": "benchmark put out by Nvidia um and that",
    "start": "916759",
    "end": "919360"
  },
  {
    "text": "brings this model kind of in the realm",
    "start": "919360",
    "end": "921800"
  },
  {
    "text": "of uh Flagship long context models uh",
    "start": "921800",
    "end": "925920"
  },
  {
    "text": "like Gemini 1.5 Pro GPT 4 and and mandar",
    "start": "925920",
    "end": "930519"
  },
  {
    "text": "plus right and so the these models are",
    "start": "930519",
    "end": "933120"
  },
  {
    "text": "open source publicly available I invite",
    "start": "933120",
    "end": "934839"
  },
  {
    "text": "you all to to go and check them",
    "start": "934839",
    "end": "937000"
  },
  {
    "text": "out um and I have about a about a minute",
    "start": "937000",
    "end": "940720"
  },
  {
    "text": "left so uh I'll finish off uh here uh",
    "start": "940720",
    "end": "945040"
  },
  {
    "text": "there's of course lots more to building",
    "start": "945040",
    "end": "947399"
  },
  {
    "text": "uh an AI Financial expert these are just",
    "start": "947399",
    "end": "949680"
  },
  {
    "text": "two pieces of the puzzle even though",
    "start": "949680",
    "end": "951079"
  },
  {
    "text": "they're two important ones uh and if you",
    "start": "951079",
    "end": "953240"
  },
  {
    "text": "guys are interested in finding out more",
    "start": "953240",
    "end": "955639"
  },
  {
    "text": "uh feel free to check us out on our on",
    "start": "955639",
    "end": "957360"
  },
  {
    "text": "our website or reach out and contact",
    "start": "957360",
    "end": "959040"
  },
  {
    "text": "does cool thank you",
    "start": "959040",
    "end": "961340"
  },
  {
    "text": "[Applause]",
    "start": "961340",
    "end": "962660"
  },
  {
    "text": "[Music]",
    "start": "962660",
    "end": "981399"
  }
]
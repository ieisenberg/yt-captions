[
  {
    "text": "[Music]",
    "start": "1040",
    "end": "13859"
  },
  {
    "text": "hey everyone uh my name is Jerry",
    "start": "14639",
    "end": "16320"
  },
  {
    "text": "co-founder and CEO of L index and today",
    "start": "16320",
    "end": "18359"
  },
  {
    "text": "we'll be talking about how to build",
    "start": "18359",
    "end": "19520"
  },
  {
    "text": "production ready rag applications um I",
    "start": "19520",
    "end": "22000"
  },
  {
    "text": "think there's still time for a raffle",
    "start": "22000",
    "end": "23320"
  },
  {
    "text": "for the bucket hat so if you guys stop",
    "start": "23320",
    "end": "24640"
  },
  {
    "text": "by our booth uh please fill out the",
    "start": "24640",
    "end": "26000"
  },
  {
    "text": "Google form okay let's get started so",
    "start": "26000",
    "end": "29400"
  },
  {
    "text": "everybody knows is that there's been a",
    "start": "29400",
    "end": "31039"
  },
  {
    "text": "ton of amazing use cases in gen recently",
    "start": "31039",
    "end": "33800"
  },
  {
    "text": "you know um knowledge search and QA",
    "start": "33800",
    "end": "36079"
  },
  {
    "text": "conversational agents uh workflow",
    "start": "36079",
    "end": "37960"
  },
  {
    "text": "automation document processing these are",
    "start": "37960",
    "end": "40160"
  },
  {
    "text": "all things that you can build uh",
    "start": "40160",
    "end": "41920"
  },
  {
    "text": "especially using the reasoning",
    "start": "41920",
    "end": "43039"
  },
  {
    "text": "capabilities of llms uh over your",
    "start": "43039",
    "end": "46039"
  },
  {
    "text": "data so if we just do a quick refresher",
    "start": "46039",
    "end": "49680"
  },
  {
    "text": "in terms of like paradigms for how do",
    "start": "49680",
    "end": "51360"
  },
  {
    "text": "you actually get language models to",
    "start": "51360",
    "end": "53480"
  },
  {
    "text": "understand data that hasn't been trained",
    "start": "53480",
    "end": "54920"
  },
  {
    "text": "over there's really like two main",
    "start": "54920",
    "end": "56960"
  },
  {
    "text": "paradigms one is retrieval augmentation",
    "start": "56960",
    "end": "59600"
  },
  {
    "text": "where you you like fix the model and you",
    "start": "59600",
    "end": "61359"
  },
  {
    "text": "basically create a data pipeline to put",
    "start": "61359",
    "end": "63359"
  },
  {
    "text": "context into the prompt from some data",
    "start": "63359",
    "end": "65720"
  },
  {
    "text": "source into the input prompt of the",
    "start": "65720",
    "end": "68080"
  },
  {
    "text": "language model um so like a vector",
    "start": "68080",
    "end": "70000"
  },
  {
    "text": "database uh you know like unstructured",
    "start": "70000",
    "end": "71840"
  },
  {
    "text": "taex SQL database",
    "start": "71840",
    "end": "73880"
  },
  {
    "text": "Etc the next Paradigm here is",
    "start": "73880",
    "end": "76240"
  },
  {
    "text": "fine-tuning how can we bake knowledge",
    "start": "76240",
    "end": "78720"
  },
  {
    "text": "into the weights of the network by",
    "start": "78720",
    "end": "80240"
  },
  {
    "text": "actually updating the weights of the",
    "start": "80240",
    "end": "82040"
  },
  {
    "text": "model itself some adapter on top of the",
    "start": "82040",
    "end": "84320"
  },
  {
    "text": "model but basically some sort of",
    "start": "84320",
    "end": "85720"
  },
  {
    "text": "training process over some new data to",
    "start": "85720",
    "end": "88159"
  },
  {
    "text": "actually incorporate knowledge we'll",
    "start": "88159",
    "end": "90360"
  },
  {
    "text": "probably talk a little bit more about",
    "start": "90360",
    "end": "91600"
  },
  {
    "text": "retrieval augmentation but this is just",
    "start": "91600",
    "end": "93720"
  },
  {
    "text": "like to help you get uh started and",
    "start": "93720",
    "end": "95520"
  },
  {
    "text": "really understanding the mission",
    "start": "95520",
    "end": "96560"
  },
  {
    "text": "statement of of the",
    "start": "96560",
    "end": "98600"
  },
  {
    "text": "company okay let's talk about rag",
    "start": "98600",
    "end": "101880"
  },
  {
    "text": "retrieval augmented Generation Um it's",
    "start": "101880",
    "end": "104920"
  },
  {
    "text": "become kind of a buzzword recently but",
    "start": "104920",
    "end": "107240"
  },
  {
    "text": "we'll first walk through the current rag",
    "start": "107240",
    "end": "109000"
  },
  {
    "text": "stack for building a QA system this",
    "start": "109000",
    "end": "111479"
  },
  {
    "text": "really consists of two main components",
    "start": "111479",
    "end": "113439"
  },
  {
    "text": "uh data ingestion as well as data",
    "start": "113439",
    "end": "115200"
  },
  {
    "text": "quering which contains retrieval and",
    "start": "115200",
    "end": "116960"
  },
  {
    "text": "synthesis uh if you're just getting",
    "start": "116960",
    "end": "118680"
  },
  {
    "text": "started in llama index you can basically",
    "start": "118680",
    "end": "120360"
  },
  {
    "text": "do this in around like fiveish lines of",
    "start": "120360",
    "end": "122399"
  },
  {
    "text": "code uh so you don't really need to",
    "start": "122399",
    "end": "123840"
  },
  {
    "text": "think about it but if you do want to",
    "start": "123840",
    "end": "125439"
  },
  {
    "text": "learn some of the lower level components",
    "start": "125439",
    "end": "127000"
  },
  {
    "text": "and I do encourage like every engineer",
    "start": "127000",
    "end": "129039"
  },
  {
    "text": "uh AI engineer to basically just like",
    "start": "129039",
    "end": "130640"
  },
  {
    "text": "learn how these components work under",
    "start": "130640",
    "end": "132360"
  },
  {
    "text": "the hood um I would encourage you to",
    "start": "132360",
    "end": "134000"
  },
  {
    "text": "check out some of our docs to really",
    "start": "134000",
    "end": "135680"
  },
  {
    "text": "understand how do you actually do data",
    "start": "135680",
    "end": "137080"
  },
  {
    "text": "inje uh and data quering like how do you",
    "start": "137080",
    "end": "139280"
  },
  {
    "text": "actually retrieve from a vector database",
    "start": "139280",
    "end": "141120"
  },
  {
    "text": "and how do you synthesize that with an",
    "start": "141120",
    "end": "143959"
  },
  {
    "text": "L1 so that's basically the key stack",
    "start": "143959",
    "end": "147440"
  },
  {
    "text": "that's kind of emerging these days like",
    "start": "147440",
    "end": "149080"
  },
  {
    "text": "for every sort chat bot like you know",
    "start": "149080",
    "end": "151200"
  },
  {
    "text": "chat over your PDF like over your",
    "start": "151200",
    "end": "153440"
  },
  {
    "text": "unstructured data um a lot of these",
    "start": "153440",
    "end": "155920"
  },
  {
    "text": "things are basically using the same",
    "start": "155920",
    "end": "157879"
  },
  {
    "text": "principles of like how do you actually",
    "start": "157879",
    "end": "159680"
  },
  {
    "text": "load data from some data source and",
    "start": "159680",
    "end": "161519"
  },
  {
    "text": "actually you know um retrieve in query",
    "start": "161519",
    "end": "163920"
  },
  {
    "text": "over it but I think as developers are",
    "start": "163920",
    "end": "167120"
  },
  {
    "text": "actually developing these applications",
    "start": "167120",
    "end": "168959"
  },
  {
    "text": "they're realizing that this isn't quite",
    "start": "168959",
    "end": "170640"
  },
  {
    "text": "enough uh like there's there's certain",
    "start": "170640",
    "end": "173159"
  },
  {
    "text": "issues that you're running into that are",
    "start": "173159",
    "end": "174720"
  },
  {
    "text": "blockers for actually being able to",
    "start": "174720",
    "end": "176080"
  },
  {
    "text": "productionize these applications and so",
    "start": "176080",
    "end": "178720"
  },
  {
    "text": "what are these challenges with naive rag",
    "start": "178720",
    "end": "181560"
  },
  {
    "text": "one aspect here is just like uh the",
    "start": "181560",
    "end": "184000"
  },
  {
    "text": "response and and this is the key thing",
    "start": "184000",
    "end": "185480"
  },
  {
    "text": "that we're focused on like the the",
    "start": "185480",
    "end": "186599"
  },
  {
    "text": "response quality is not very good you",
    "start": "186599",
    "end": "188519"
  },
  {
    "text": "run into for instance like bad retrieval",
    "start": "188519",
    "end": "190519"
  },
  {
    "text": "issues like uh during the retrieval",
    "start": "190519",
    "end": "192239"
  },
  {
    "text": "stage from your vector database if",
    "start": "192239",
    "end": "194000"
  },
  {
    "text": "you're not actually returning the",
    "start": "194000",
    "end": "195440"
  },
  {
    "text": "relevant chunks from your vector",
    "start": "195440",
    "end": "197040"
  },
  {
    "text": "database you're not going to be able to",
    "start": "197040",
    "end": "198640"
  },
  {
    "text": "have the correct context actually put",
    "start": "198640",
    "end": "200319"
  },
  {
    "text": "into the llm so this includes certain",
    "start": "200319",
    "end": "202760"
  },
  {
    "text": "issues like low Precision not all chunks",
    "start": "202760",
    "end": "204760"
  },
  {
    "text": "in the retrieve set are relevant uh this",
    "start": "204760",
    "end": "207000"
  },
  {
    "text": "leads to like hallucination like loss in",
    "start": "207000",
    "end": "208799"
  },
  {
    "text": "the middle problems you have a lot of",
    "start": "208799",
    "end": "210040"
  },
  {
    "text": "fluff in the return response this could",
    "start": "210040",
    "end": "212239"
  },
  {
    "text": "mean low recall like your top K isn't",
    "start": "212239",
    "end": "214159"
  },
  {
    "text": "high enough or basically like the the",
    "start": "214159",
    "end": "215799"
  },
  {
    "text": "the set of like information that you",
    "start": "215799",
    "end": "217280"
  },
  {
    "text": "need to actually answer the question is",
    "start": "217280",
    "end": "218920"
  },
  {
    "text": "just not there um and of course there's",
    "start": "218920",
    "end": "221080"
  },
  {
    "text": "other issues too like outdated",
    "start": "221080",
    "end": "223080"
  },
  {
    "text": "information and many of you who are",
    "start": "223080",
    "end": "224920"
  },
  {
    "text": "building apps these days might be",
    "start": "224920",
    "end": "226319"
  },
  {
    "text": "familiar with some like key concepts of",
    "start": "226319",
    "end": "228159"
  },
  {
    "text": "like just why the llm isn't always you",
    "start": "228159",
    "end": "230560"
  },
  {
    "text": "know uh guaranteed to give you a correct",
    "start": "230560",
    "end": "232239"
  },
  {
    "text": "answer there's hallucination irrelevance",
    "start": "232239",
    "end": "234680"
  },
  {
    "text": "like toxicity bias there's a lot of",
    "start": "234680",
    "end": "236200"
  },
  {
    "text": "issues on the LM side as",
    "start": "236200",
    "end": "238680"
  },
  {
    "text": "well so what can we do um what can we",
    "start": "238680",
    "end": "242040"
  },
  {
    "text": "actually do to try to improve the",
    "start": "242040",
    "end": "244000"
  },
  {
    "text": "performance of a retrieval augmented",
    "start": "244000",
    "end": "246079"
  },
  {
    "text": "generation application um and and for",
    "start": "246079",
    "end": "248560"
  },
  {
    "text": "many of you like you might be running",
    "start": "248560",
    "end": "249920"
  },
  {
    "text": "into certain issues and it really runs",
    "start": "249920",
    "end": "252280"
  },
  {
    "text": "the gamut across like the entire",
    "start": "252280",
    "end": "254079"
  },
  {
    "text": "pipeline there's stuff you can do on the",
    "start": "254079",
    "end": "256000"
  },
  {
    "text": "data like can we store additional",
    "start": "256000",
    "end": "257759"
  },
  {
    "text": "information Beyond just like the raw",
    "start": "257759",
    "end": "259479"
  },
  {
    "text": "text chunks right that that you're",
    "start": "259479",
    "end": "261000"
  },
  {
    "text": "putting in the vector database can you",
    "start": "261000",
    "end": "262400"
  },
  {
    "text": "optimize that data pipeline somehow play",
    "start": "262400",
    "end": "264199"
  },
  {
    "text": "around with chunk sizes that type of",
    "start": "264199",
    "end": "265680"
  },
  {
    "text": "thing can you optimize the embedding",
    "start": "265680",
    "end": "267919"
  },
  {
    "text": "representation itself a lot of times",
    "start": "267919",
    "end": "269720"
  },
  {
    "text": "when you're using a pre-trained embeding",
    "start": "269720",
    "end": "271120"
  },
  {
    "text": "model it's not really optimal for giving",
    "start": "271120",
    "end": "273080"
  },
  {
    "text": "you the best performance um there's the",
    "start": "273080",
    "end": "275560"
  },
  {
    "text": "retrieval algorithm you know the default",
    "start": "275560",
    "end": "277479"
  },
  {
    "text": "thing you do is just look up the topk",
    "start": "277479",
    "end": "279400"
  },
  {
    "text": "most similar elements from your vector",
    "start": "279400",
    "end": "281039"
  },
  {
    "text": "database to return to the llm um many",
    "start": "281039",
    "end": "284000"
  },
  {
    "text": "times that's not enough and and what are",
    "start": "284000",
    "end": "285520"
  },
  {
    "text": "kind of like both simple things you can",
    "start": "285520",
    "end": "286880"
  },
  {
    "text": "do as well as hard things uh and there's",
    "start": "286880",
    "end": "288960"
  },
  {
    "text": "also synthesis like uh why is there yeah",
    "start": "288960",
    "end": "291400"
  },
  {
    "text": "there's like a v in the anyway so so can",
    "start": "291400",
    "end": "293039"
  },
  {
    "text": "we use LMS for more than generation um",
    "start": "293039",
    "end": "295720"
  },
  {
    "text": "and so basically like you can um use the",
    "start": "295720",
    "end": "297880"
  },
  {
    "text": "llm to actually help you with like",
    "start": "297880",
    "end": "299639"
  },
  {
    "text": "reasoning um as opposed to just like",
    "start": "299639",
    "end": "301720"
  },
  {
    "text": "pure um uh pure uh just like uh just",
    "start": "301720",
    "end": "305160"
  },
  {
    "text": "pure generation right you can actually",
    "start": "305160",
    "end": "306639"
  },
  {
    "text": "use it to try to reason over given a",
    "start": "306639",
    "end": "308880"
  },
  {
    "text": "question can you break it down into",
    "start": "308880",
    "end": "310199"
  },
  {
    "text": "simpler questions route to different",
    "start": "310199",
    "end": "312160"
  },
  {
    "text": "data sources and kind of like have a a",
    "start": "312160",
    "end": "315320"
  },
  {
    "text": "more sophisticated way of in wearing",
    "start": "315320",
    "end": "316720"
  },
  {
    "text": "your",
    "start": "316720",
    "end": "318280"
  },
  {
    "text": "data um of course like if you kind of",
    "start": "318280",
    "end": "321199"
  },
  {
    "text": "been around some of my recent talks like",
    "start": "321199",
    "end": "322960"
  },
  {
    "text": "I always say before you actually try any",
    "start": "322960",
    "end": "324680"
  },
  {
    "text": "of these techniques you need to be",
    "start": "324680",
    "end": "326039"
  },
  {
    "text": "pretty task specific and make sure that",
    "start": "326039",
    "end": "327560"
  },
  {
    "text": "you need a way to that you actually have",
    "start": "327560",
    "end": "329160"
  },
  {
    "text": "a way to to measure",
    "start": "329160",
    "end": "330880"
  },
  {
    "text": "performance so I'll probably spend like",
    "start": "330880",
    "end": "333039"
  },
  {
    "text": "2 minutes talking about evaluation um",
    "start": "333039",
    "end": "335039"
  },
  {
    "text": "Simon my co-founder just ran a workshop",
    "start": "335039",
    "end": "336800"
  },
  {
    "text": "yesterday on really just like how to you",
    "start": "336800",
    "end": "338560"
  },
  {
    "text": "evaluate uh build a data set evaluate",
    "start": "338560",
    "end": "340960"
  },
  {
    "text": "rag systems and help iterate on that uh",
    "start": "340960",
    "end": "342960"
  },
  {
    "text": "if you miss the workshop don't worry",
    "start": "342960",
    "end": "344319"
  },
  {
    "text": "I'll we'll have the slides and and",
    "start": "344319",
    "end": "345960"
  },
  {
    "text": "materials uh available online so that",
    "start": "345960",
    "end": "347680"
  },
  {
    "text": "you can take a look um at a very high",
    "start": "347680",
    "end": "350720"
  },
  {
    "text": "level in terms of evaluation it's",
    "start": "350720",
    "end": "352280"
  },
  {
    "text": "important because you basically need to",
    "start": "352280",
    "end": "353560"
  },
  {
    "text": "define a benchmark for your system to",
    "start": "353560",
    "end": "355600"
  },
  {
    "text": "understand how are you going to iterate",
    "start": "355600",
    "end": "357080"
  },
  {
    "text": "on and improve it uh and there's like a",
    "start": "357080",
    "end": "359280"
  },
  {
    "text": "few few different ways you can try to do",
    "start": "359280",
    "end": "360759"
  },
  {
    "text": "evaluation right I think Anton from from",
    "start": "360759",
    "end": "362639"
  },
  {
    "text": "chroma was was just saying some of this",
    "start": "362639",
    "end": "364400"
  },
  {
    "text": "but like you basically need a way to um",
    "start": "364400",
    "end": "367280"
  },
  {
    "text": "evaluate both the end to endend solution",
    "start": "367280",
    "end": "369599"
  },
  {
    "text": "like you have your input query as well",
    "start": "369599",
    "end": "371240"
  },
  {
    "text": "as the output response you also want to",
    "start": "371240",
    "end": "373360"
  },
  {
    "text": "probably be able to evaluate like",
    "start": "373360",
    "end": "374639"
  },
  {
    "text": "specific components like if you've",
    "start": "374639",
    "end": "376120"
  },
  {
    "text": "diagnosed that the retrieval is is like",
    "start": "376120",
    "end": "378240"
  },
  {
    "text": "the portion that needs improving you",
    "start": "378240",
    "end": "379919"
  },
  {
    "text": "need like retrieval metrics to really",
    "start": "379919",
    "end": "381840"
  },
  {
    "text": "understand how can you improve your",
    "start": "381840",
    "end": "383120"
  },
  {
    "text": "retrieval system um so there's retrieval",
    "start": "383120",
    "end": "386199"
  },
  {
    "text": "and there's",
    "start": "386199",
    "end": "387400"
  },
  {
    "text": "synthesis let's talk a little bit just",
    "start": "387400",
    "end": "389680"
  },
  {
    "text": "like 30 seconds on each one um",
    "start": "389680",
    "end": "391880"
  },
  {
    "text": "evaluation on retrieval what does this",
    "start": "391880",
    "end": "393880"
  },
  {
    "text": "look like you basically want to make",
    "start": "393880",
    "end": "395720"
  },
  {
    "text": "sure that the stuff that's returned",
    "start": "395720",
    "end": "397440"
  },
  {
    "text": "actually answers the query and that",
    "start": "397440",
    "end": "399319"
  },
  {
    "text": "you're kind of you know not returning a",
    "start": "399319",
    "end": "401479"
  },
  {
    "text": "bunch of fluff uh and that the stuff",
    "start": "401479",
    "end": "402960"
  },
  {
    "text": "that you return is relevant to the",
    "start": "402960",
    "end": "404120"
  },
  {
    "text": "question um so first you need an",
    "start": "404120",
    "end": "406720"
  },
  {
    "text": "evaluation data set a lot of people are",
    "start": "406720",
    "end": "408960"
  },
  {
    "text": "uh have like human labeled data sets if",
    "start": "408960",
    "end": "410840"
  },
  {
    "text": "you're in uh building stuff in prod you",
    "start": "410840",
    "end": "412639"
  },
  {
    "text": "might have like user feedback as well if",
    "start": "412639",
    "end": "414800"
  },
  {
    "text": "not you can synthetically generate a",
    "start": "414800",
    "end": "416280"
  },
  {
    "text": "data set this data set is input like",
    "start": "416280",
    "end": "418639"
  },
  {
    "text": "query and output the IDS of like the",
    "start": "418639",
    "end": "421000"
  },
  {
    "text": "return documents are relevant to the",
    "start": "421000",
    "end": "422400"
  },
  {
    "text": "query so you need that somehow once you",
    "start": "422400",
    "end": "425120"
  },
  {
    "text": "have that you can measure stuff with",
    "start": "425120",
    "end": "426599"
  },
  {
    "text": "ranking metrics right you can measure",
    "start": "426599",
    "end": "428120"
  },
  {
    "text": "stuff like success rate hit rate Mr ndcg",
    "start": "428120",
    "end": "432080"
  },
  {
    "text": "a variety of these things uh and and so",
    "start": "432080",
    "end": "434039"
  },
  {
    "text": "like once you are able to evaluate this",
    "start": "434039",
    "end": "436319"
  },
  {
    "text": "like this really isn't uh kind of like",
    "start": "436319",
    "end": "438240"
  },
  {
    "text": "an llm problem this is like an IR",
    "start": "438240",
    "end": "440120"
  },
  {
    "text": "problem and this has been around for at",
    "start": "440120",
    "end": "441879"
  },
  {
    "text": "least like a decade or two um but a lot",
    "start": "441879",
    "end": "444240"
  },
  {
    "text": "of this is becoming like you know it's",
    "start": "444240",
    "end": "446160"
  },
  {
    "text": "it's still very relevant in the face of",
    "start": "446160",
    "end": "447720"
  },
  {
    "text": "actually building these L Maps",
    "start": "447720",
    "end": "451319"
  },
  {
    "text": "the next piece here is um there's a",
    "start": "451319",
    "end": "453280"
  },
  {
    "text": "retrieve portion right but then you",
    "start": "453280",
    "end": "454720"
  },
  {
    "text": "generate a response from it and then how",
    "start": "454720",
    "end": "456599"
  },
  {
    "text": "do you actually evaluate the whole thing",
    "start": "456599",
    "end": "457840"
  },
  {
    "text": "end to end so evaluation of the final",
    "start": "457840",
    "end": "460240"
  },
  {
    "text": "response uh given the input you still",
    "start": "460240",
    "end": "462879"
  },
  {
    "text": "want to generate some sort of data set",
    "start": "462879",
    "end": "464520"
  },
  {
    "text": "so you could do that through like human",
    "start": "464520",
    "end": "465919"
  },
  {
    "text": "annotations user feedback you could have",
    "start": "465919",
    "end": "467720"
  },
  {
    "text": "like ground truth reference answers",
    "start": "467720",
    "end": "469240"
  },
  {
    "text": "given the query that really indicates",
    "start": "469240",
    "end": "470879"
  },
  {
    "text": "like hey this is the proper answer to",
    "start": "470879",
    "end": "472319"
  },
  {
    "text": "this question um and you can also just",
    "start": "472319",
    "end": "474800"
  },
  {
    "text": "like you know synthetically generate it",
    "start": "474800",
    "end": "476120"
  },
  {
    "text": "with like gb4 uh you run this through",
    "start": "476120",
    "end": "478599"
  },
  {
    "text": "the full rag pipeline that you built the",
    "start": "478599",
    "end": "480360"
  },
  {
    "text": "retrieval and synthesis uh and you can",
    "start": "480360",
    "end": "482400"
  },
  {
    "text": "run like LM based evals um so label-free",
    "start": "482400",
    "end": "484840"
  },
  {
    "text": "evals with label evals there's a lot of",
    "start": "484840",
    "end": "487759"
  },
  {
    "text": "uh projects these days uh going on about",
    "start": "487759",
    "end": "489759"
  },
  {
    "text": "how do you actually properly evaluate",
    "start": "489759",
    "end": "491319"
  },
  {
    "text": "the outputs uh predicted outputs of a",
    "start": "491319",
    "end": "492960"
  },
  {
    "text": "language",
    "start": "492960",
    "end": "495159"
  },
  {
    "text": "model once you've defined your evalve",
    "start": "495159",
    "end": "497360"
  },
  {
    "text": "benchmark now you want to think about",
    "start": "497360",
    "end": "499159"
  },
  {
    "text": "how do you actually optimize your rag",
    "start": "499159",
    "end": "500800"
  },
  {
    "text": "systems so I sent a teaser on this slide",
    "start": "500800",
    "end": "503759"
  },
  {
    "text": "uh a few like yesterday but the way I",
    "start": "503759",
    "end": "506520"
  },
  {
    "text": "think about this is that when do you",
    "start": "506520",
    "end": "508400"
  },
  {
    "text": "want to actually improve your system",
    "start": "508400",
    "end": "510199"
  },
  {
    "text": "there's like a million things that you",
    "start": "510199",
    "end": "511520"
  },
  {
    "text": "can do to try to actually improve your",
    "start": "511520",
    "end": "513120"
  },
  {
    "text": "rag system uh and like you probably",
    "start": "513120",
    "end": "515760"
  },
  {
    "text": "don't want to start with the hard stuff",
    "start": "515760",
    "end": "517039"
  },
  {
    "text": "first uh just because like you know part",
    "start": "517039",
    "end": "518919"
  },
  {
    "text": "of the value of language models is how",
    "start": "518919",
    "end": "520800"
  },
  {
    "text": "it's kind of democratized access to",
    "start": "520800",
    "end": "522320"
  },
  {
    "text": "every developer it's really just made it",
    "start": "522320",
    "end": "523680"
  },
  {
    "text": "easy for people to get up and running",
    "start": "523680",
    "end": "525680"
  },
  {
    "text": "and so if for instance you're running",
    "start": "525680",
    "end": "527160"
  },
  {
    "text": "into some performance issues with rag",
    "start": "527160",
    "end": "529160"
  },
  {
    "text": "I'd probably start with the basics like",
    "start": "529160",
    "end": "530480"
  },
  {
    "text": "I call it like table Stakes rag",
    "start": "530480",
    "end": "532000"
  },
  {
    "text": "techniques uh better puring um so that",
    "start": "532000",
    "end": "534680"
  },
  {
    "text": "you don't just split by even chunks like",
    "start": "534680",
    "end": "536680"
  },
  {
    "text": "adjusting your chunk sizes trying out",
    "start": "536680",
    "end": "538600"
  },
  {
    "text": "stuff that's already integrated with a",
    "start": "538600",
    "end": "539880"
  },
  {
    "text": "vector database like hybrid search as",
    "start": "539880",
    "end": "541839"
  },
  {
    "text": "well as like metadata",
    "start": "541839",
    "end": "543240"
  },
  {
    "text": "filters there's also like Advanced",
    "start": "543240",
    "end": "545519"
  },
  {
    "text": "retrieval methods that you could try it",
    "start": "545519",
    "end": "547440"
  },
  {
    "text": "this is like a little bit more advanced",
    "start": "547440",
    "end": "548880"
  },
  {
    "text": "some of it pulls from like traditional",
    "start": "548880",
    "end": "550320"
  },
  {
    "text": "IR some of it it's more like kind of uh",
    "start": "550320",
    "end": "552760"
  },
  {
    "text": "really like uh new in in this age of",
    "start": "552760",
    "end": "555000"
  },
  {
    "text": "like LM based apps there's like uh",
    "start": "555000",
    "end": "557120"
  },
  {
    "text": "reranking um that's a traditional",
    "start": "557120",
    "end": "559040"
  },
  {
    "text": "concept there's also Concepts in llama",
    "start": "559040",
    "end": "560880"
  },
  {
    "text": "index like recursive retrieval like",
    "start": "560880",
    "end": "562440"
  },
  {
    "text": "dealing with embedded tables like uh",
    "start": "562440",
    "end": "564440"
  },
  {
    "text": "small to big retrieval and a lot of",
    "start": "564440",
    "end": "566079"
  },
  {
    "text": "other stuff that we have that help you",
    "start": "566079",
    "end": "567760"
  },
  {
    "text": "potentially improve the performance of",
    "start": "567760",
    "end": "569360"
  },
  {
    "text": "your application uh and then the last",
    "start": "569360",
    "end": "571760"
  },
  {
    "text": "bit like this kind of gets into more",
    "start": "571760",
    "end": "573399"
  },
  {
    "text": "expressive stuff that might be harder to",
    "start": "573399",
    "end": "575120"
  },
  {
    "text": "implement might incur a higher lency and",
    "start": "575120",
    "end": "576920"
  },
  {
    "text": "cost but is potentially more powerful",
    "start": "576920",
    "end": "578839"
  },
  {
    "text": "and forward looking is like agents like",
    "start": "578839",
    "end": "580880"
  },
  {
    "text": "how do you incorporate agents towards",
    "start": "580880",
    "end": "582640"
  },
  {
    "text": "better like rag pipelines to better",
    "start": "582640",
    "end": "585399"
  },
  {
    "text": "answer different types of questions and",
    "start": "585399",
    "end": "586800"
  },
  {
    "text": "synthesize information and how do you",
    "start": "586800",
    "end": "588680"
  },
  {
    "text": "actually fine-tune",
    "start": "588680",
    "end": "590560"
  },
  {
    "text": "stuff let's talk a little bit about the",
    "start": "590560",
    "end": "592680"
  },
  {
    "text": "table Stakes first so chunk sizes tuning",
    "start": "592680",
    "end": "595160"
  },
  {
    "text": "your chunk size can have outsize impacts",
    "start": "595160",
    "end": "597160"
  },
  {
    "text": "on performance right uh if you've kind",
    "start": "597160",
    "end": "599200"
  },
  {
    "text": "of like played around with frag systems",
    "start": "599200",
    "end": "601000"
  },
  {
    "text": "uh this may or may not be obvious to you",
    "start": "601000",
    "end": "603279"
  },
  {
    "text": "what's interesting though is that like",
    "start": "603279",
    "end": "605000"
  },
  {
    "text": "more retriev tokens does not always",
    "start": "605000",
    "end": "606920"
  },
  {
    "text": "equate to higher performance and that if",
    "start": "606920",
    "end": "609040"
  },
  {
    "text": "you do like reranking of your retrieve",
    "start": "609040",
    "end": "610959"
  },
  {
    "text": "tokens it doesn't necessarily mean that",
    "start": "610959",
    "end": "612760"
  },
  {
    "text": "your final generation response is going",
    "start": "612760",
    "end": "614399"
  },
  {
    "text": "to be better and this is again due to",
    "start": "614399",
    "end": "616240"
  },
  {
    "text": "stuff like lost in the middle problems",
    "start": "616240",
    "end": "617600"
  },
  {
    "text": "where stuff in the middle of the LM",
    "start": "617600",
    "end": "619040"
  },
  {
    "text": "context window tends to get lost where",
    "start": "619040",
    "end": "620640"
  },
  {
    "text": "stuff at the end uh tends to be a little",
    "start": "620640",
    "end": "622720"
  },
  {
    "text": "bit uh more well remembered by the Ln um",
    "start": "622720",
    "end": "626399"
  },
  {
    "text": "and so I think we did a workshop with",
    "start": "626399",
    "end": "627800"
  },
  {
    "text": "like arise a few uh week ago where",
    "start": "627800",
    "end": "630040"
  },
  {
    "text": "basically we showed you know uh there is",
    "start": "630040",
    "end": "632079"
  },
  {
    "text": "kind of like an optimal chunk size given",
    "start": "632079",
    "end": "633839"
  },
  {
    "text": "your data set and a lot of times when",
    "start": "633839",
    "end": "635240"
  },
  {
    "text": "you try out stuff like reranking it",
    "start": "635240",
    "end": "636800"
  },
  {
    "text": "actually increases your error",
    "start": "636800",
    "end": "639959"
  },
  {
    "text": "metrics metadata filtering uh this is",
    "start": "639959",
    "end": "642680"
  },
  {
    "text": "another like very table Stak thing that",
    "start": "642680",
    "end": "644920"
  },
  {
    "text": "I think everybody should look into and I",
    "start": "644920",
    "end": "646680"
  },
  {
    "text": "think Vector databases like you know",
    "start": "646680",
    "end": "648240"
  },
  {
    "text": "chroma pine cone we like these Vector",
    "start": "648240",
    "end": "650519"
  },
  {
    "text": "databases are all implementing these uh",
    "start": "650519",
    "end": "652399"
  },
  {
    "text": "capabilities on your hood metadata",
    "start": "652399",
    "end": "654399"
  },
  {
    "text": "filtering is basically just like how can",
    "start": "654399",
    "end": "656320"
  },
  {
    "text": "you add structured context uh to your",
    "start": "656320",
    "end": "659160"
  },
  {
    "text": "your chunks like your text chunks and",
    "start": "659160",
    "end": "661240"
  },
  {
    "text": "you can use this for both like",
    "start": "661240",
    "end": "662480"
  },
  {
    "text": "embeddings as well as synthesis but it",
    "start": "662480",
    "end": "664600"
  },
  {
    "text": "also integrates with like The Meta",
    "start": "664600",
    "end": "666320"
  },
  {
    "text": "metadata filter capabilities of a vector",
    "start": "666320",
    "end": "668360"
  },
  {
    "text": "database um so metadata is just like",
    "start": "668360",
    "end": "670680"
  },
  {
    "text": "again structured Json dictionary it",
    "start": "670680",
    "end": "672200"
  },
  {
    "text": "could be like page number it could be",
    "start": "672200",
    "end": "673639"
  },
  {
    "text": "the document title it could be the",
    "start": "673639",
    "end": "675040"
  },
  {
    "text": "summary of adjacent chunks you can get",
    "start": "675040",
    "end": "676480"
  },
  {
    "text": "creative with it too you could",
    "start": "676480",
    "end": "677560"
  },
  {
    "text": "hallucinate like questions uh that the",
    "start": "677560",
    "end": "679240"
  },
  {
    "text": "chunk answers um and it can help",
    "start": "679240",
    "end": "681279"
  },
  {
    "text": "retrieval it can help augment your",
    "start": "681279",
    "end": "682760"
  },
  {
    "text": "response quality it also integrates with",
    "start": "682760",
    "end": "684839"
  },
  {
    "text": "the vector database",
    "start": "684839",
    "end": "686399"
  },
  {
    "text": "filters so as an example let's say the",
    "start": "686399",
    "end": "689680"
  },
  {
    "text": "question is over like the SEC like 10q",
    "start": "689680",
    "end": "692680"
  },
  {
    "text": "document and like can you tell me the",
    "start": "692680",
    "end": "694320"
  },
  {
    "text": "risk factors in 2021 if you just do raw",
    "start": "694320",
    "end": "697120"
  },
  {
    "text": "semantic search typically it's very low",
    "start": "697120",
    "end": "698839"
  },
  {
    "text": "Precision you're going to return a bunch",
    "start": "698839",
    "end": "700000"
  },
  {
    "text": "of stuff that may or may not match this",
    "start": "700000",
    "end": "702040"
  },
  {
    "text": "you might even return stuff from like",
    "start": "702040",
    "end": "703440"
  },
  {
    "text": "other years if you have a bunch of",
    "start": "703440",
    "end": "705000"
  },
  {
    "text": "documents from different years in the",
    "start": "705000",
    "end": "706240"
  },
  {
    "text": "same Vector collection um and so like",
    "start": "706240",
    "end": "708800"
  },
  {
    "text": "you're kind of like rolling the dice a",
    "start": "708800",
    "end": "710279"
  },
  {
    "text": "little",
    "start": "710279",
    "end": "712279"
  },
  {
    "text": "bit but one idea here is basically you",
    "start": "712279",
    "end": "715800"
  },
  {
    "text": "know if you have access to the metadata",
    "start": "715800",
    "end": "718120"
  },
  {
    "text": "of the documents um and you ask a",
    "start": "718120",
    "end": "720079"
  },
  {
    "text": "question like this you basically combine",
    "start": "720079",
    "end": "721920"
  },
  {
    "text": "structured query capabilities by",
    "start": "721920",
    "end": "723399"
  },
  {
    "text": "inferring the metadata filters like a",
    "start": "723399",
    "end": "725000"
  },
  {
    "text": "wear Claus and a SQL statement like a",
    "start": "725000",
    "end": "726920"
  },
  {
    "text": "year equals 2021 and you combine that",
    "start": "726920",
    "end": "728800"
  },
  {
    "text": "with semantic search to return the most",
    "start": "728800",
    "end": "730480"
  },
  {
    "text": "relevant candidates given your query and",
    "start": "730480",
    "end": "732440"
  },
  {
    "text": "this improves the Precision of your uh",
    "start": "732440",
    "end": "734639"
  },
  {
    "text": "of your",
    "start": "734639",
    "end": "737000"
  },
  {
    "text": "results moving on to stuff that's maybe",
    "start": "737880",
    "end": "740360"
  },
  {
    "text": "a bit more advanced like Advanced",
    "start": "740360",
    "end": "741839"
  },
  {
    "text": "retrieval is one thing that we found",
    "start": "741839",
    "end": "743399"
  },
  {
    "text": "generally helps is this idea of like",
    "start": "743399",
    "end": "745560"
  },
  {
    "text": "small to big retrieval um so what does",
    "start": "745560",
    "end": "747360"
  },
  {
    "text": "that mean basically right now when you",
    "start": "747360",
    "end": "749360"
  },
  {
    "text": "embed a big text trunk you also",
    "start": "749360",
    "end": "751920"
  },
  {
    "text": "synthesize over that text trunk and so",
    "start": "751920",
    "end": "753959"
  },
  {
    "text": "it's a little suboptimal because what if",
    "start": "753959",
    "end": "755800"
  },
  {
    "text": "like the embedding representations like",
    "start": "755800",
    "end": "757440"
  },
  {
    "text": "biased because you know there's a bunch",
    "start": "757440",
    "end": "759000"
  },
  {
    "text": "of fluff in that text trunk that",
    "start": "759000",
    "end": "760320"
  },
  {
    "text": "contains a bunch of relevant information",
    "start": "760320",
    "end": "762519"
  },
  {
    "text": "you're not actually optimizing your",
    "start": "762519",
    "end": "763760"
  },
  {
    "text": "retrieval quality so embedding a big",
    "start": "763760",
    "end": "766519"
  },
  {
    "text": "text trunk sometimes feels a little",
    "start": "766519",
    "end": "767880"
  },
  {
    "text": "suboptimal one thing that you could do",
    "start": "767880",
    "end": "769720"
  },
  {
    "text": "is basically embed text at the sentence",
    "start": "769720",
    "end": "771560"
  },
  {
    "text": "level or on a smaller level and then",
    "start": "771560",
    "end": "773399"
  },
  {
    "text": "expand that window during synthesis time",
    "start": "773399",
    "end": "775920"
  },
  {
    "text": "um and so this is contained in a variety",
    "start": "775920",
    "end": "777880"
  },
  {
    "text": "of like L index ractions but the idea is",
    "start": "777880",
    "end": "780199"
  },
  {
    "text": "that you return you retrieve on more",
    "start": "780199",
    "end": "782320"
  },
  {
    "text": "granular pieces of information so",
    "start": "782320",
    "end": "784000"
  },
  {
    "text": "smaller chunks this makes it so that",
    "start": "784000",
    "end": "786279"
  },
  {
    "text": "these chunks are more likely to be",
    "start": "786279",
    "end": "787639"
  },
  {
    "text": "retrieved when you actually ask a query",
    "start": "787639",
    "end": "789360"
  },
  {
    "text": "over these specific piece of context but",
    "start": "789360",
    "end": "791360"
  },
  {
    "text": "then you want to make sure that the LM",
    "start": "791360",
    "end": "792680"
  },
  {
    "text": "actually has access to more information",
    "start": "792680",
    "end": "794279"
  },
  {
    "text": "to actually synthesize a proper",
    "start": "794279",
    "end": "796880"
  },
  {
    "text": "result so this leads to like more",
    "start": "796880",
    "end": "799240"
  },
  {
    "text": "precise retrieval right so um we we",
    "start": "799240",
    "end": "802120"
  },
  {
    "text": "tried this out it it helps avoid like",
    "start": "802120",
    "end": "804079"
  },
  {
    "text": "some loss in the middle problems you can",
    "start": "804079",
    "end": "805880"
  },
  {
    "text": "set a smaller top K value like k equal 2",
    "start": "805880",
    "end": "808600"
  },
  {
    "text": "uh whereas like over this data set if",
    "start": "808600",
    "end": "810920"
  },
  {
    "text": "you set like k equals 5 for naive",
    "start": "810920",
    "end": "812680"
  },
  {
    "text": "retrieval over big text chunks you",
    "start": "812680",
    "end": "814600"
  },
  {
    "text": "basically start returning a lot of",
    "start": "814600",
    "end": "816160"
  },
  {
    "text": "context and that kind of leads into",
    "start": "816160",
    "end": "818079"
  },
  {
    "text": "issues where uh you know maybe the",
    "start": "818079",
    "end": "820120"
  },
  {
    "text": "relevant context is in the middle but",
    "start": "820120",
    "end": "821519"
  },
  {
    "text": "you're not able to find out uh or or",
    "start": "821519",
    "end": "823160"
  },
  {
    "text": "you're like that the LM is is is not",
    "start": "823160",
    "end": "825480"
  },
  {
    "text": "able to kind of synthesize over that",
    "start": "825480",
    "end": "829399"
  },
  {
    "text": "information a very related idea here is",
    "start": "830160",
    "end": "833560"
  },
  {
    "text": "just like embedding a reference to the",
    "start": "833560",
    "end": "835759"
  },
  {
    "text": "parent trunk um as opposed to the actual",
    "start": "835759",
    "end": "837880"
  },
  {
    "text": "text Chunk itself so for instance if you",
    "start": "837880",
    "end": "840000"
  },
  {
    "text": "want to embed like not just the raw text",
    "start": "840000",
    "end": "841959"
  },
  {
    "text": "trunk or not the text trunk but actually",
    "start": "841959",
    "end": "843639"
  },
  {
    "text": "like a smaller trunk um or a summary or",
    "start": "843639",
    "end": "846160"
  },
  {
    "text": "questions that answer of the trunk we",
    "start": "846160",
    "end": "848079"
  },
  {
    "text": "have found that that actually helps to",
    "start": "848079",
    "end": "849759"
  },
  {
    "text": "improve retrieval performance a decent",
    "start": "849759",
    "end": "851600"
  },
  {
    "text": "amount um and it's it kind of again goes",
    "start": "851600",
    "end": "854079"
  },
  {
    "text": "along with this idea like a lot of times",
    "start": "854079",
    "end": "855560"
  },
  {
    "text": "you want to embed something that's more",
    "start": "855560",
    "end": "857120"
  },
  {
    "text": "edable for embedding based retrieval uh",
    "start": "857120",
    "end": "859440"
  },
  {
    "text": "but then you want to return enough",
    "start": "859440",
    "end": "860560"
  },
  {
    "text": "context so that the LM can actually",
    "start": "860560",
    "end": "862240"
  },
  {
    "text": "synthesize over that",
    "start": "862240",
    "end": "865320"
  },
  {
    "text": "information",
    "start": "867680",
    "end": "869600"
  },
  {
    "text": "the next bit here is actually kind of",
    "start": "869600",
    "end": "872040"
  },
  {
    "text": "even more advanced stuff right this goes",
    "start": "872040",
    "end": "874040"
  },
  {
    "text": "on into agents and this goes on into",
    "start": "874040",
    "end": "875759"
  },
  {
    "text": "that last pillar that I I mentioned",
    "start": "875759",
    "end": "877440"
  },
  {
    "text": "which is how can you use llms for for",
    "start": "877440",
    "end": "879680"
  },
  {
    "text": "reasoning as opposed to just synthesis",
    "start": "879680",
    "end": "882240"
  },
  {
    "text": "the intuition here is that like for a",
    "start": "882240",
    "end": "884279"
  },
  {
    "text": "lot of rag if you're just using the llm",
    "start": "884279",
    "end": "886160"
  },
  {
    "text": "at the end you're one constrained by the",
    "start": "886160",
    "end": "887880"
  },
  {
    "text": "quality of your Retriever and you're",
    "start": "887880",
    "end": "889720"
  },
  {
    "text": "really only able to do stuff like",
    "start": "889720",
    "end": "891320"
  },
  {
    "text": "question answering and there's certain",
    "start": "891320",
    "end": "893120"
  },
  {
    "text": "types of questions and more advanced uh",
    "start": "893120",
    "end": "895199"
  },
  {
    "text": "analysis that you might want to launch",
    "start": "895199",
    "end": "896720"
  },
  {
    "text": "that like top K rag can't really answer",
    "start": "896720",
    "end": "898920"
  },
  {
    "text": "it's not necessarily just a one-off",
    "start": "898920",
    "end": "900279"
  },
  {
    "text": "question you might need to have like an",
    "start": "900279",
    "end": "902079"
  },
  {
    "text": "entire sequence of reasoning steps to",
    "start": "902079",
    "end": "903639"
  },
  {
    "text": "actually pull together a piece of",
    "start": "903639",
    "end": "904839"
  },
  {
    "text": "information or you might want to like",
    "start": "904839",
    "end": "906720"
  },
  {
    "text": "summarize a document and compare with",
    "start": "906720",
    "end": "908519"
  },
  {
    "text": "like other documents so one kind of",
    "start": "908519",
    "end": "911320"
  },
  {
    "text": "architecture we're exploring right now",
    "start": "911320",
    "end": "913000"
  },
  {
    "text": "is this idea of like multi-document",
    "start": "913000",
    "end": "914399"
  },
  {
    "text": "agents what if like instead of just like",
    "start": "914399",
    "end": "916320"
  },
  {
    "text": "rag we moved a little bit more into",
    "start": "916320",
    "end": "918360"
  },
  {
    "text": "agent territory we modeled each document",
    "start": "918360",
    "end": "921160"
  },
  {
    "text": "not just as a sequence of text trunks",
    "start": "921160",
    "end": "923079"
  },
  {
    "text": "but actually as a set of tools that",
    "start": "923079",
    "end": "924920"
  },
  {
    "text": "contains the ability to both like",
    "start": "924920",
    "end": "926360"
  },
  {
    "text": "summarize that document as well as to do",
    "start": "926360",
    "end": "928839"
  },
  {
    "text": "QA over that document over specific",
    "start": "928839",
    "end": "930759"
  },
  {
    "text": "facts um and of course if you want to",
    "start": "930759",
    "end": "932839"
  },
  {
    "text": "scale to like you know hundreds or",
    "start": "932839",
    "end": "934600"
  },
  {
    "text": "thousands or millions of documents um",
    "start": "934600",
    "end": "936959"
  },
  {
    "text": "typically an agent can only have access",
    "start": "936959",
    "end": "938800"
  },
  {
    "text": "to a limited window of tools so you",
    "start": "938800",
    "end": "941240"
  },
  {
    "text": "probably want to do some sort of",
    "start": "941240",
    "end": "942480"
  },
  {
    "text": "retrieval on these tools similar to how",
    "start": "942480",
    "end": "944959"
  },
  {
    "text": "you want to retrieve like text Trunks",
    "start": "944959",
    "end": "946480"
  },
  {
    "text": "from a document the main difference is",
    "start": "946480",
    "end": "948399"
  },
  {
    "text": "that because these are tools you",
    "start": "948399",
    "end": "949680"
  },
  {
    "text": "actually want to act upon them you want",
    "start": "949680",
    "end": "951040"
  },
  {
    "text": "to use them as opposed to just like",
    "start": "951040",
    "end": "952720"
  },
  {
    "text": "taking the raw text and plugging it into",
    "start": "952720",
    "end": "954399"
  },
  {
    "text": "the context window so blending this",
    "start": "954399",
    "end": "956519"
  },
  {
    "text": "combination of like uh kind of um",
    "start": "956519",
    "end": "959160"
  },
  {
    "text": "embedding based retrieval or any sort of",
    "start": "959160",
    "end": "961120"
  },
  {
    "text": "retrieval as well as like agent tool use",
    "start": "961120",
    "end": "963319"
  },
  {
    "text": "is a very interesting Paradigm that I",
    "start": "963319",
    "end": "965000"
  },
  {
    "text": "think is really only possible with this",
    "start": "965000",
    "end": "966480"
  },
  {
    "text": "age of almes and hasn't really existed",
    "start": "966480",
    "end": "968800"
  },
  {
    "text": "before",
    "start": "968800",
    "end": "971120"
  },
  {
    "text": "this another kind of advanced concept is",
    "start": "972720",
    "end": "975759"
  },
  {
    "text": "this idea of fine tuning um and so fine",
    "start": "975759",
    "end": "978319"
  },
  {
    "text": "tuning uh you know this some other",
    "start": "978319",
    "end": "979880"
  },
  {
    "text": "presenters have talked about this as",
    "start": "979880",
    "end": "981160"
  },
  {
    "text": "well but the idea of like fine-tuning in",
    "start": "981160",
    "end": "983600"
  },
  {
    "text": "a rag system is that it really optimizes",
    "start": "983600",
    "end": "986600"
  },
  {
    "text": "specific pieces of this rag pipeline for",
    "start": "986600",
    "end": "988759"
  },
  {
    "text": "you to kind of better um like improve",
    "start": "988759",
    "end": "991480"
  },
  {
    "text": "the performance of either retriever or",
    "start": "991480",
    "end": "993519"
  },
  {
    "text": "synthesis capabilities so one thing you",
    "start": "993519",
    "end": "995680"
  },
  {
    "text": "can do is fine-tune your embeddings um I",
    "start": "995680",
    "end": "997399"
  },
  {
    "text": "think Anton was talking about this as",
    "start": "997399",
    "end": "998959"
  },
  {
    "text": "well like if you just use a pre-trained",
    "start": "998959",
    "end": "1000839"
  },
  {
    "text": "model the embedding representations are",
    "start": "1000839",
    "end": "1002480"
  },
  {
    "text": "not going to be optimized over your",
    "start": "1002480",
    "end": "1003920"
  },
  {
    "text": "specific data so sometimes you're just",
    "start": "1003920",
    "end": "1005399"
  },
  {
    "text": "going to retrieve the wrong wrong",
    "start": "1005399",
    "end": "1007120"
  },
  {
    "text": "information um if you can somehow tune",
    "start": "1007120",
    "end": "1010160"
  },
  {
    "text": "these embeddings so that given any sort",
    "start": "1010160",
    "end": "1012319"
  },
  {
    "text": "of like relevant question that the user",
    "start": "1012319",
    "end": "1013920"
  },
  {
    "text": "might ask that you're actually returning",
    "start": "1013920",
    "end": "1015880"
  },
  {
    "text": "the relevant response then you're going",
    "start": "1015880",
    "end": "1017519"
  },
  {
    "text": "to have like better performance",
    "start": "1017519",
    "end": "1018440"
  },
  {
    "text": "performance so um an idea here right is",
    "start": "1018440",
    "end": "1021399"
  },
  {
    "text": "to generate synthetic query data set",
    "start": "1021399",
    "end": "1023199"
  },
  {
    "text": "from raw text chunks using llms and use",
    "start": "1023199",
    "end": "1025280"
  },
  {
    "text": "this to fine-tune and embeding model um",
    "start": "1025280",
    "end": "1027839"
  },
  {
    "text": "and you can do this like uh if we go",
    "start": "1027839",
    "end": "1030678"
  },
  {
    "text": "back really quick actually uh you can do",
    "start": "1030679",
    "end": "1032600"
  },
  {
    "text": "this by basically um kind of fine-tuning",
    "start": "1032600",
    "end": "1034880"
  },
  {
    "text": "the base model itself you can also",
    "start": "1034880",
    "end": "1036640"
  },
  {
    "text": "fine-tune an adapter on top of the model",
    "start": "1036640",
    "end": "1039240"
  },
  {
    "text": "um and fine-tuning an adapter on top of",
    "start": "1039240",
    "end": "1040720"
  },
  {
    "text": "the model has a few advantages in that",
    "start": "1040720",
    "end": "1042678"
  },
  {
    "text": "you don't require the base model's",
    "start": "1042679",
    "end": "1043959"
  },
  {
    "text": "weights to actually fine-tune stuff and",
    "start": "1043959",
    "end": "1045839"
  },
  {
    "text": "if you just finetune the query you don't",
    "start": "1045839",
    "end": "1047360"
  },
  {
    "text": "have to reindex your entire document",
    "start": "1047360",
    "end": "1050960"
  },
  {
    "text": "Corpus there's also fine-tuning LMS",
    "start": "1052039",
    "end": "1054600"
  },
  {
    "text": "which of course like a lot of people are",
    "start": "1054600",
    "end": "1056039"
  },
  {
    "text": "very interested in doing these days um",
    "start": "1056039",
    "end": "1058679"
  },
  {
    "text": "and intuition here specifically for rag",
    "start": "1058679",
    "end": "1060440"
  },
  {
    "text": "is that if you have a weaker LM like 3.5",
    "start": "1060440",
    "end": "1062760"
  },
  {
    "text": "turbo like LL 2 7B like these weaker",
    "start": "1062760",
    "end": "1065520"
  },
  {
    "text": "llms are bad are are not bad at like um",
    "start": "1065520",
    "end": "1069360"
  },
  {
    "text": "uh wait yeah weaker LMS are are maybe a",
    "start": "1069360",
    "end": "1072160"
  },
  {
    "text": "little bit worse at like response",
    "start": "1072160",
    "end": "1073799"
  },
  {
    "text": "synthesis reasoning structured outputs",
    "start": "1073799",
    "end": "1076000"
  },
  {
    "text": "Etc um compared to like bigger models",
    "start": "1076000",
    "end": "1078919"
  },
  {
    "text": "so the solution here is what if you can",
    "start": "1078919",
    "end": "1080720"
  },
  {
    "text": "generate a synthetic data set using a",
    "start": "1080720",
    "end": "1082600"
  },
  {
    "text": "bigger model like gbd4 that's something",
    "start": "1082600",
    "end": "1084280"
  },
  {
    "text": "we're exploring and you actually distill",
    "start": "1084280",
    "end": "1086159"
  },
  {
    "text": "that into 3.5 turbo so it gets better at",
    "start": "1086159",
    "end": "1088960"
  },
  {
    "text": "train of thought longer response quality",
    "start": "1088960",
    "end": "1091640"
  },
  {
    "text": "um better structured outputs and a lot",
    "start": "1091640",
    "end": "1093400"
  },
  {
    "text": "of other possibilities as well so all",
    "start": "1093400",
    "end": "1095960"
  },
  {
    "text": "these things are in our docs there's",
    "start": "1095960",
    "end": "1097280"
  },
  {
    "text": "production rag uh there's fine toting",
    "start": "1097280",
    "end": "1099320"
  },
  {
    "text": "and I have two seconds left so thank you",
    "start": "1099320",
    "end": "1101000"
  },
  {
    "text": "very",
    "start": "1101000",
    "end": "1103159"
  },
  {
    "text": "much",
    "start": "1107320",
    "end": "1108470"
  },
  {
    "text": "[Music]",
    "start": "1108470",
    "end": "1116008"
  }
]
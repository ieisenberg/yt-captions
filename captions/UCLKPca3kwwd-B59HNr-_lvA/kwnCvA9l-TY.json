[
  {
    "text": "[Music]",
    "start": "350",
    "end": "14050"
  },
  {
    "text": "uh hello AI engineer words World's Fair",
    "start": "14120",
    "end": "16440"
  },
  {
    "text": "my name is vibor VB for short and I'm a",
    "start": "16440",
    "end": "19039"
  },
  {
    "text": "CI senior AI engineer attender where",
    "start": "19039",
    "end": "21240"
  },
  {
    "text": "I've been working on trust and safety",
    "start": "21240",
    "end": "22480"
  },
  {
    "text": "for the last five years I also work on",
    "start": "22480",
    "end": "24640"
  },
  {
    "text": "and maintain some open source AI",
    "start": "24640",
    "end": "26359"
  },
  {
    "text": "projects and I'm an adviser to a few AI",
    "start": "26359",
    "end": "28480"
  },
  {
    "text": "startups um but we only 15 minutes so",
    "start": "28480",
    "end": "30920"
  },
  {
    "text": "I'll jump right into it maybe a little",
    "start": "30920",
    "end": "32200"
  },
  {
    "text": "bit less than 15 now today I'll be",
    "start": "32200",
    "end": "34200"
  },
  {
    "text": "talking about AI Frontiers and trust and",
    "start": "34200",
    "end": "35920"
  },
  {
    "text": "safety um combating multifaceted harm on",
    "start": "35920",
    "end": "38399"
  },
  {
    "text": "Tinder at scale we'll first go over what",
    "start": "38399",
    "end": "41160"
  },
  {
    "text": "trust and safety actually is for",
    "start": "41160",
    "end": "42520"
  },
  {
    "text": "everyone in the audience and more",
    "start": "42520",
    "end": "43920"
  },
  {
    "text": "specifically what it means at Tinder",
    "start": "43920",
    "end": "45879"
  },
  {
    "text": "then we'll go over the complex",
    "start": "45879",
    "end": "47039"
  },
  {
    "text": "interaction between generative Ai and",
    "start": "47039",
    "end": "48680"
  },
  {
    "text": "trust and safety some of the problems",
    "start": "48680",
    "end": "50760"
  },
  {
    "text": "which most people think about um but",
    "start": "50760",
    "end": "52320"
  },
  {
    "text": "also some of the tremendous",
    "start": "52320",
    "end": "53239"
  },
  {
    "text": "opportunities which will fundamentally",
    "start": "53239",
    "end": "55000"
  },
  {
    "text": "change the space next we'll dive",
    "start": "55000",
    "end": "57399"
  },
  {
    "text": "specifically into how to actually use",
    "start": "57399",
    "end": "58719"
  },
  {
    "text": "llms for detect trust and safety",
    "start": "58719",
    "end": "60879"
  },
  {
    "text": "violations in text covering the end end",
    "start": "60879",
    "end": "63480"
  },
  {
    "text": "stack from training to fine-tuning to",
    "start": "63480",
    "end": "65840"
  },
  {
    "text": "production and an overview of how we're",
    "start": "65840",
    "end": "67720"
  },
  {
    "text": "doing this at Tinder finally we'll cover",
    "start": "67720",
    "end": "70280"
  },
  {
    "text": "what the future looks like for this",
    "start": "70280",
    "end": "71520"
  },
  {
    "text": "effort and what we should be most",
    "start": "71520",
    "end": "73240"
  },
  {
    "text": "excited",
    "start": "73240",
    "end": "74759"
  },
  {
    "text": "about so what is trust and safety",
    "start": "74759",
    "end": "76920"
  },
  {
    "text": "actually it's not really something",
    "start": "76920",
    "end": "78439"
  },
  {
    "text": "that's well- defined um and it's more of",
    "start": "78439",
    "end": "80159"
  },
  {
    "text": "an art than a science often times we",
    "start": "80159",
    "end": "82320"
  },
  {
    "text": "have to make ethical judgment calls but",
    "start": "82320",
    "end": "84439"
  },
  {
    "text": "it's helpful to look at a breakdown of",
    "start": "84439",
    "end": "85799"
  },
  {
    "text": "the goals of TNS by Dell Harvey who led",
    "start": "85799",
    "end": "88799"
  },
  {
    "text": "trust and safety at Tinder uh Twitter",
    "start": "88799",
    "end": "90880"
  },
  {
    "text": "for 13 years ultimately TNS is about",
    "start": "90880",
    "end": "94200"
  },
  {
    "text": "preventing risk reducing risk detecting",
    "start": "94200",
    "end": "96520"
  },
  {
    "text": "harm and mitigating harm the ultimate",
    "start": "96520",
    "end": "98720"
  },
  {
    "text": "goal is to protect users and also the",
    "start": "98720",
    "end": "100720"
  },
  {
    "text": "companies creating the products that",
    "start": "100720",
    "end": "102000"
  },
  {
    "text": "they use in this presentation we'll",
    "start": "102000",
    "end": "104479"
  },
  {
    "text": "focus on the detecting harm part of it",
    "start": "104479",
    "end": "106399"
  },
  {
    "text": "where we devote a lot of our time to at",
    "start": "106399",
    "end": "109439"
  },
  {
    "text": "Tinder speaking of which as the largest",
    "start": "109439",
    "end": "111759"
  },
  {
    "text": "dating app in the world we encounter",
    "start": "111759",
    "end": "113439"
  },
  {
    "text": "many many types of violative behavior on",
    "start": "113439",
    "end": "115320"
  },
  {
    "text": "Tinder here are some of the different",
    "start": "115320",
    "end": "117200"
  },
  {
    "text": "categories and a representative",
    "start": "117200",
    "end": "119039"
  },
  {
    "text": "synthetic textual example of each um",
    "start": "119039",
    "end": "122039"
  },
  {
    "text": "first we have uh social media in your",
    "start": "122039",
    "end": "125079"
  },
  {
    "text": "profile a relatively minor but rather",
    "start": "125079",
    "end": "127600"
  },
  {
    "text": "prevalent violation of our Pro private",
    "start": "127600",
    "end": "129840"
  },
  {
    "text": "information policy um and it's often",
    "start": "129840",
    "end": "131840"
  },
  {
    "text": "done by low intent users on the other",
    "start": "131840",
    "end": "134160"
  },
  {
    "text": "side of the spectrum we have things that",
    "start": "134160",
    "end": "135640"
  },
  {
    "text": "are low prevalence but High harm things",
    "start": "135640",
    "end": "137959"
  },
  {
    "text": "like hate speech harassment and pig",
    "start": "137959",
    "end": "140640"
  },
  {
    "text": "butchering",
    "start": "140640",
    "end": "143080"
  },
  {
    "text": "scams so now that we have a sense of",
    "start": "144319",
    "end": "146560"
  },
  {
    "text": "what TNS is let's move on to the",
    "start": "146560",
    "end": "148200"
  },
  {
    "text": "problems that generative AI is causing",
    "start": "148200",
    "end": "149440"
  },
  {
    "text": "for the industry",
    "start": "149440",
    "end": "150800"
  },
  {
    "text": "one of the biggest problems is that gen",
    "start": "150800",
    "end": "152720"
  },
  {
    "text": "enables rapid generation of content",
    "start": "152720",
    "end": "154760"
  },
  {
    "text": "which makes it particularly easy to",
    "start": "154760",
    "end": "156480"
  },
  {
    "text": "spread misinformation propaganda and",
    "start": "156480",
    "end": "158480"
  },
  {
    "text": "lowquality spam by Drowning out genuine",
    "start": "158480",
    "end": "160720"
  },
  {
    "text": "content that's what's known as the",
    "start": "160720",
    "end": "162480"
  },
  {
    "text": "content pollution phenomenon",
    "start": "162480",
    "end": "165040"
  },
  {
    "text": "additionally there's some risk that",
    "start": "165040",
    "end": "166400"
  },
  {
    "text": "platforms where the content is posted",
    "start": "166400",
    "end": "168480"
  },
  {
    "text": "will essentially inherit the known",
    "start": "168480",
    "end": "170159"
  },
  {
    "text": "copyright issues plaguing consumer geni",
    "start": "170159",
    "end": "172200"
  },
  {
    "text": "tools today like open",
    "start": "172200",
    "end": "173760"
  },
  {
    "text": "AI another problem is the accessibility",
    "start": "173760",
    "end": "176120"
  },
  {
    "text": "of deep fake technology which lowers the",
    "start": "176120",
    "end": "178200"
  },
  {
    "text": "bar of Entry to impersonation and",
    "start": "178200",
    "end": "180920"
  },
  {
    "text": "catfishing um this also enables",
    "start": "180920",
    "end": "182800"
  },
  {
    "text": "malicious interpersonal harm like in the",
    "start": "182800",
    "end": "184959"
  },
  {
    "text": "case of revenge",
    "start": "184959",
    "end": "186519"
  },
  {
    "text": "porn lastly gen can be used to scale up",
    "start": "186519",
    "end": "189480"
  },
  {
    "text": "organized spam and scam operations Bad",
    "start": "189480",
    "end": "191879"
  },
  {
    "text": "actors can rapidly create profiles by",
    "start": "191879",
    "end": "193760"
  },
  {
    "text": "generating text and images which means",
    "start": "193760",
    "end": "195680"
  },
  {
    "text": "that existing signals the ones we are",
    "start": "195680",
    "end": "197480"
  },
  {
    "text": "using today rely on similarity matching",
    "start": "197480",
    "end": "199519"
  },
  {
    "text": "or hashes um will be increasingly less",
    "start": "199519",
    "end": "201720"
  },
  {
    "text": "likely to work as a side note this is",
    "start": "201720",
    "end": "204480"
  },
  {
    "text": "why TNS teams dealing with automated",
    "start": "204480",
    "end": "206280"
  },
  {
    "text": "fraud will need to increasingly take",
    "start": "206280",
    "end": "208080"
  },
  {
    "text": "advantage of metadata type signals",
    "start": "208080",
    "end": "209840"
  },
  {
    "text": "associated with physical Bott",
    "start": "209840",
    "end": "211519"
  },
  {
    "text": "bottlenecks in meat space things like IP",
    "start": "211519",
    "end": "213920"
  },
  {
    "text": "address ISP information and phone",
    "start": "213920",
    "end": "216439"
  },
  {
    "text": "numbers um Additionally the messages",
    "start": "216439",
    "end": "218599"
  },
  {
    "text": "sent by frauders on a platform like",
    "start": "218599",
    "end": "220599"
  },
  {
    "text": "Tinder can be increasingly automated",
    "start": "220599",
    "end": "222159"
  },
  {
    "text": "with llms",
    "start": "222159",
    "end": "224879"
  },
  {
    "text": "obviously so now that we've covered some",
    "start": "224879",
    "end": "226879"
  },
  {
    "text": "of the major problems that gen is",
    "start": "226879",
    "end": "228680"
  },
  {
    "text": "causing for the trust and safety",
    "start": "228680",
    "end": "230040"
  },
  {
    "text": "industry um but there's actually some",
    "start": "230040",
    "end": "232519"
  },
  {
    "text": "big reasons to be hopeful as well so",
    "start": "232519",
    "end": "234799"
  },
  {
    "text": "here are some of the opportunities the",
    "start": "234799",
    "end": "236720"
  },
  {
    "text": "first is that AI Labs at both startups",
    "start": "236720",
    "end": "239000"
  },
  {
    "text": "and big companies already done the hard",
    "start": "239000",
    "end": "240519"
  },
  {
    "text": "work of pre-training and open sourcing",
    "start": "240519",
    "end": "242280"
  },
  {
    "text": "llms for everyone's benefit out of the",
    "start": "242280",
    "end": "244760"
  },
  {
    "text": "box these are really powerful in that",
    "start": "244760",
    "end": "246360"
  },
  {
    "text": "they have latent semantic capability and",
    "start": "246360",
    "end": "248680"
  },
  {
    "text": "often Global language coverage as well",
    "start": "248680",
    "end": "251040"
  },
  {
    "text": "just try doing a few shot example with",
    "start": "251040",
    "end": "252640"
  },
  {
    "text": "prompt engineering llama 3 or mistol um",
    "start": "252640",
    "end": "255239"
  },
  {
    "text": "to detect any kind of violation it",
    "start": "255239",
    "end": "256959"
  },
  {
    "text": "usually works pretty well by fine-tuning",
    "start": "256959",
    "end": "259440"
  },
  {
    "text": "these models we can actually achieve",
    "start": "259440",
    "end": "260759"
  },
  {
    "text": "state-of-the-art performance um in some",
    "start": "260759",
    "end": "263199"
  },
  {
    "text": "cases better than F shot gbd4",
    "start": "263199",
    "end": "265000"
  },
  {
    "text": "performance on Downstream textual",
    "start": "265000",
    "end": "267040"
  },
  {
    "text": "detection tasks um in the act of",
    "start": "267040",
    "end": "269800"
  },
  {
    "text": "finetuning uh has been made a lot easier",
    "start": "269800",
    "end": "271880"
  },
  {
    "text": "because the open source Community has",
    "start": "271880",
    "end": "273320"
  },
  {
    "text": "produced libraries and tools that are",
    "start": "273320",
    "end": "275479"
  },
  {
    "text": "relatively mature and maintained now",
    "start": "275479",
    "end": "277840"
  },
  {
    "text": "it's easier than ever to do fine-tuning",
    "start": "277840",
    "end": "279680"
  },
  {
    "text": "with the low-level details being",
    "start": "279680",
    "end": "281000"
  },
  {
    "text": "abstracted away and there's libraries",
    "start": "281000",
    "end": "282759"
  },
  {
    "text": "built for every stage of model",
    "start": "282759",
    "end": "284080"
  },
  {
    "text": "development and",
    "start": "284080",
    "end": "286680"
  },
  {
    "text": "productionizing up are things that every",
    "start": "287759",
    "end": "290199"
  },
  {
    "text": "trust and safety organization should be",
    "start": "290199",
    "end": "291520"
  },
  {
    "text": "paying attention to First is that we're",
    "start": "291520",
    "end": "294240"
  },
  {
    "text": "fine-tuning rather than starting from",
    "start": "294240",
    "end": "295720"
  },
  {
    "text": "scratch and because of that um in the",
    "start": "295720",
    "end": "298120"
  },
  {
    "text": "strong open source Library support we",
    "start": "298120",
    "end": "300120"
  },
  {
    "text": "can actually develop accelerate the",
    "start": "300120",
    "end": "301800"
  },
  {
    "text": "model development process from months to",
    "start": "301800",
    "end": "304160"
  },
  {
    "text": "weeks um and additionally one of the",
    "start": "304160",
    "end": "307240"
  },
  {
    "text": "major reasons we see such good",
    "start": "307240",
    "end": "308520"
  },
  {
    "text": "performance from the fine-tuned open",
    "start": "308520",
    "end": "310479"
  },
  {
    "text": "source llms is that in general model",
    "start": "310479",
    "end": "313199"
  },
  {
    "text": "performance degrades quickly in trust",
    "start": "313199",
    "end": "315039"
  },
  {
    "text": "and safety due to the adversarial nature",
    "start": "315039",
    "end": "316840"
  },
  {
    "text": "of automated fraud for example whenever",
    "start": "316840",
    "end": "319120"
  },
  {
    "text": "we release a rule to block one spam wave",
    "start": "319120",
    "end": "321960"
  },
  {
    "text": "Bad actors are incentivized to and",
    "start": "321960",
    "end": "324039"
  },
  {
    "text": "ultimately do change their behavior to",
    "start": "324039",
    "end": "325440"
  },
  {
    "text": "get around it um but the generalization",
    "start": "325440",
    "end": "329000"
  },
  {
    "text": "performance of LM slows the model",
    "start": "329000",
    "end": "331000"
  },
  {
    "text": "degradation curve significantly and we",
    "start": "331000",
    "end": "333319"
  },
  {
    "text": "basically get this for free when we use",
    "start": "333319",
    "end": "336720"
  },
  {
    "text": "llms okay so let's move on to some of",
    "start": "336919",
    "end": "338880"
  },
  {
    "text": "the specifics of actually using llms for",
    "start": "338880",
    "end": "341280"
  },
  {
    "text": "TNS violation detection the first major",
    "start": "341280",
    "end": "343720"
  },
  {
    "text": "step is creating our training data set",
    "start": "343720",
    "end": "345800"
  },
  {
    "text": "this is often the hardest part um that's",
    "start": "345800",
    "end": "348319"
  },
  {
    "text": "due in part to how easy some of the",
    "start": "348319",
    "end": "350000"
  },
  {
    "text": "later steps are as we'll see um but it's",
    "start": "350000",
    "end": "352039"
  },
  {
    "text": "also because uh smaller data sets are",
    "start": "352039",
    "end": "355479"
  },
  {
    "text": "required for fine tuning versus training",
    "start": "355479",
    "end": "357039"
  },
  {
    "text": "from scratch um in some cases hundreds",
    "start": "357039",
    "end": "359840"
  },
  {
    "text": "to thousands of examples and this NE",
    "start": "359840",
    "end": "362080"
  },
  {
    "text": "necessitates creating a pretty high",
    "start": "362080",
    "end": "363759"
  },
  {
    "text": "quality data set",
    "start": "363759",
    "end": "366120"
  },
  {
    "text": "um what is this data set look like well",
    "start": "366120",
    "end": "369400"
  },
  {
    "text": "GPT type llms like the closed source",
    "start": "369400",
    "end": "371560"
  },
  {
    "text": "gbd4 and CLA Opus um and also like the",
    "start": "371560",
    "end": "374319"
  },
  {
    "text": "open source LL and mistra models can be",
    "start": "374319",
    "end": "376000"
  },
  {
    "text": "thought of as a text in to text out this",
    "start": "376000",
    "end": "379039"
  },
  {
    "text": "is an approximate mental model but it",
    "start": "379039",
    "end": "380560"
  },
  {
    "text": "helps for understanding what the data",
    "start": "380560",
    "end": "382000"
  },
  {
    "text": "set should look like in our case the",
    "start": "382000",
    "end": "384319"
  },
  {
    "text": "text in is the potentially violating",
    "start": "384319",
    "end": "386479"
  },
  {
    "text": "text we want to make a we want the model",
    "start": "386479",
    "end": "388199"
  },
  {
    "text": "to be able to make a prediction on",
    "start": "388199",
    "end": "389599"
  },
  {
    "text": "wrapped by some prompt uh and the text",
    "start": "389599",
    "end": "391960"
  },
  {
    "text": "out is a classification label or um some",
    "start": "391960",
    "end": "395039"
  },
  {
    "text": "extracted characters representing the",
    "start": "395039",
    "end": "396360"
  },
  {
    "text": "violation it's not a pretty not a very",
    "start": "396360",
    "end": "398560"
  },
  {
    "text": "complicated format um and there's an",
    "start": "398560",
    "end": "401160"
  },
  {
    "text": "example for how we're a synthetic",
    "start": "401160",
    "end": "403880"
  },
  {
    "text": "example for how we would detect users if",
    "start": "403880",
    "end": "406360"
  },
  {
    "text": "they're underage in their written",
    "start": "406360",
    "end": "409879"
  },
  {
    "text": "bio um as for actually assembling a data",
    "start": "410039",
    "end": "412520"
  },
  {
    "text": "set it's possible to do it entirely by",
    "start": "412520",
    "end": "414319"
  },
  {
    "text": "hand because again we only need hundreds",
    "start": "414319",
    "end": "416240"
  },
  {
    "text": "to thousands of examples um one thing",
    "start": "416240",
    "end": "418599"
  },
  {
    "text": "we've worked seen work quite well is",
    "start": "418599",
    "end": "420440"
  },
  {
    "text": "actually to incorporate the largest llms",
    "start": "420440",
    "end": "422520"
  },
  {
    "text": "in the data generation process we could",
    "start": "422520",
    "end": "424879"
  },
  {
    "text": "generate purely synthetic training",
    "start": "424879",
    "end": "426680"
  },
  {
    "text": "examples with few shot prompting um this",
    "start": "426680",
    "end": "429000"
  },
  {
    "text": "introduces some risk that the data won't",
    "start": "429000",
    "end": "430879"
  },
  {
    "text": "resemble the true data distribution um",
    "start": "430879",
    "end": "433240"
  },
  {
    "text": "and it's platform agnostic what we found",
    "start": "433240",
    "end": "435800"
  },
  {
    "text": "works better is to actually do a hybrid",
    "start": "435800",
    "end": "437520"
  },
  {
    "text": "process where we can use gbd4 um with",
    "start": "437520",
    "end": "440080"
  },
  {
    "text": "some clever prompting to ensure we don't",
    "start": "440080",
    "end": "441599"
  },
  {
    "text": "run into the alignment um builtin to",
    "start": "441599",
    "end": "444919"
  },
  {
    "text": "actually make predictions on internal",
    "start": "444919",
    "end": "446479"
  },
  {
    "text": "analytics data and to mine examples for",
    "start": "446479",
    "end": "448520"
  },
  {
    "text": "a training set that way",
    "start": "448520",
    "end": "450280"
  },
  {
    "text": "the cost of doing this is inversely",
    "start": "450280",
    "end": "452120"
  },
  {
    "text": "proportional to the true prevalence of",
    "start": "452120",
    "end": "453400"
  },
  {
    "text": "the harm um but that cost is still",
    "start": "453400",
    "end": "456400"
  },
  {
    "text": "pretty negligible um and it provides a",
    "start": "456400",
    "end": "458319"
  },
  {
    "text": "metric that alone is actually really",
    "start": "458319",
    "end": "459879"
  },
  {
    "text": "helpful to track for TNS operations",
    "start": "459879",
    "end": "462240"
  },
  {
    "text": "teams",
    "start": "462240",
    "end": "463159"
  },
  {
    "text": "anyways it's possible to use heuristics",
    "start": "463159",
    "end": "465479"
  },
  {
    "text": "to restrict the llm calls to more likely",
    "start": "465479",
    "end": "467520"
  },
  {
    "text": "candidates as well um and finally when",
    "start": "467520",
    "end": "470440"
  },
  {
    "text": "we get the Mind examples from uh using",
    "start": "470440",
    "end": "472919"
  },
  {
    "text": "gbd4 effectively in Auto moderation uh",
    "start": "472919",
    "end": "475520"
  },
  {
    "text": "we can then do a manual verification",
    "start": "475520",
    "end": "477360"
  },
  {
    "text": "fixing any mislabeled data and making",
    "start": "477360",
    "end": "479520"
  },
  {
    "text": "judgement calls where the label is more",
    "start": "479520",
    "end": "482960"
  },
  {
    "text": "ambiguous okay so got the training set",
    "start": "483000",
    "end": "486440"
  },
  {
    "text": "now let's talk about fine tuning one",
    "start": "486440",
    "end": "488720"
  },
  {
    "text": "question you might have is why don't we",
    "start": "488720",
    "end": "490080"
  },
  {
    "text": "just directly use the API llms like gbd4",
    "start": "490080",
    "end": "492680"
  },
  {
    "text": "to do this detection and production one",
    "start": "492680",
    "end": "495199"
  },
  {
    "text": "fundamental reason is scale Tinder has a",
    "start": "495199",
    "end": "497720"
  },
  {
    "text": "huge real-time volume of profile",
    "start": "497720",
    "end": "499440"
  },
  {
    "text": "interactions and hitting open AI apis",
    "start": "499440",
    "end": "501599"
  },
  {
    "text": "that often doesn't scale in terms of",
    "start": "501599",
    "end": "503319"
  },
  {
    "text": "cost latency and throughput the other",
    "start": "503319",
    "end": "506199"
  },
  {
    "text": "reason is maintainability by fine-tuning",
    "start": "506199",
    "end": "508520"
  },
  {
    "text": "our own models we have full control over",
    "start": "508520",
    "end": "510599"
  },
  {
    "text": "the model weights and can refin tune",
    "start": "510599",
    "end": "512440"
  },
  {
    "text": "when production performance inevitably",
    "start": "512440",
    "end": "514200"
  },
  {
    "text": "degrades um without needing to worry",
    "start": "514200",
    "end": "516120"
  },
  {
    "text": "about changes in the underlying base",
    "start": "516120",
    "end": "518200"
  },
  {
    "text": "model one additional benefit for for us",
    "start": "518200",
    "end": "521039"
  },
  {
    "text": "for classification tasks is that we have",
    "start": "521039",
    "end": "522880"
  },
  {
    "text": "access to the output probability",
    "start": "522880",
    "end": "524240"
  },
  {
    "text": "distribution which means uh we can use",
    "start": "524240",
    "end": "526640"
  },
  {
    "text": "the confidence we can create essentially",
    "start": "526640",
    "end": "528959"
  },
  {
    "text": "a confidence of the prediction like in a",
    "start": "528959",
    "end": "530720"
  },
  {
    "text": "traditional machine learning",
    "start": "530720",
    "end": "532600"
  },
  {
    "text": "model as for actually doing the fine",
    "start": "532600",
    "end": "534519"
  },
  {
    "text": "tuning well the relatively mature open",
    "start": "534519",
    "end": "536880"
  },
  {
    "text": "source ecosystem makes this really easy",
    "start": "536880",
    "end": "539079"
  },
  {
    "text": "hugging face libraries make this as",
    "start": "539079",
    "end": "540560"
  },
  {
    "text": "simple as writing a few hundred lines of",
    "start": "540560",
    "end": "542000"
  },
  {
    "text": "code without really needing to",
    "start": "542000",
    "end": "543640"
  },
  {
    "text": "understand anything about deep learning",
    "start": "543640",
    "end": "544760"
  },
  {
    "text": "or Transformers um we've also had",
    "start": "544760",
    "end": "547000"
  },
  {
    "text": "particularly success building out",
    "start": "547000",
    "end": "548480"
  },
  {
    "text": "training pipelines in notebooks there",
    "start": "548480",
    "end": "551640"
  },
  {
    "text": "are also libraries which abstract",
    "start": "551640",
    "end": "553000"
  },
  {
    "text": "fine-tuning to just config files like",
    "start": "553000",
    "end": "554920"
  },
  {
    "text": "Axel AEL lwig llama Factory um and",
    "start": "554920",
    "end": "557839"
  },
  {
    "text": "finally there's manage Solutions",
    "start": "557839",
    "end": "559120"
  },
  {
    "text": "emerging that provide additional UI and",
    "start": "559120",
    "end": "561720"
  },
  {
    "text": "data set management support um for Rapid",
    "start": "561720",
    "end": "564360"
  },
  {
    "text": "experimentation like h2m studio and",
    "start": "564360",
    "end": "567320"
  },
  {
    "text": "prabas uh the latter of with whom we've",
    "start": "567320",
    "end": "569839"
  },
  {
    "text": "had a lot of success",
    "start": "569839",
    "end": "572279"
  },
  {
    "text": "with many of you are probably also",
    "start": "572279",
    "end": "574440"
  },
  {
    "text": "familiar with parameter ficient fine",
    "start": "574440",
    "end": "576279"
  },
  {
    "text": "tuning um this critical for us uh low",
    "start": "576279",
    "end": "579240"
  },
  {
    "text": "rank adaptation or Laura freezes the",
    "start": "579240",
    "end": "581360"
  },
  {
    "text": "weights of the base model and can create",
    "start": "581360",
    "end": "583000"
  },
  {
    "text": "a fine tune model while only really",
    "start": "583000",
    "end": "584800"
  },
  {
    "text": "needing to learn a megabytes of",
    "start": "584800",
    "end": "586800"
  },
  {
    "text": "additional weights accordingly the fine",
    "start": "586800",
    "end": "589120"
  },
  {
    "text": "tuning can be done quickly um and only",
    "start": "589120",
    "end": "591360"
  },
  {
    "text": "on one or a few gpus which enables rapid",
    "start": "591360",
    "end": "594000"
  },
  {
    "text": "experimentation and also unlocks using",
    "start": "594000",
    "end": "596040"
  },
  {
    "text": "larger base models um pfts of larger",
    "start": "596040",
    "end": "599000"
  },
  {
    "text": "base model models will more likely to be",
    "start": "599000",
    "end": "600680"
  },
  {
    "text": "better than full fine tunes of smaller",
    "start": "600680",
    "end": "602519"
  },
  {
    "text": "base models especially for",
    "start": "602519",
    "end": "603800"
  },
  {
    "text": "classification tasks we've had a lot of",
    "start": "603800",
    "end": "606240"
  },
  {
    "text": "success also with Cura which unlocks",
    "start": "606240",
    "end": "608200"
  },
  {
    "text": "fine tuning on a single GPU um even the",
    "start": "608200",
    "end": "610760"
  },
  {
    "text": "largest models lastly one of the biggest",
    "start": "610760",
    "end": "613680"
  },
  {
    "text": "reasons to use Laura is that we can take",
    "start": "613680",
    "end": "615880"
  },
  {
    "text": "advantage of the massive inference",
    "start": "615880",
    "end": "617240"
  },
  {
    "text": "optimizations as we'll see",
    "start": "617240",
    "end": "620600"
  },
  {
    "text": "now um so production um in production we",
    "start": "620600",
    "end": "624360"
  },
  {
    "text": "use Lorax which is an open source",
    "start": "624360",
    "end": "625920"
  },
  {
    "text": "framework that allows users to",
    "start": "625920",
    "end": "627320"
  },
  {
    "text": "efficiently serve thousands of",
    "start": "627320",
    "end": "628600"
  },
  {
    "text": "fine-tuned models on a single GPU it",
    "start": "628600",
    "end": "631360"
  },
  {
    "text": "exploits the fact that a fine-tuned",
    "start": "631360",
    "end": "632839"
  },
  {
    "text": "Laura adapter which is just a single",
    "start": "632839",
    "end": "634760"
  },
  {
    "text": "fine-tuned model is only a few megabytes",
    "start": "634760",
    "end": "636680"
  },
  {
    "text": "in size many adapters can be efficiently",
    "start": "636680",
    "end": "639240"
  },
  {
    "text": "served jointly by simply shuffling and",
    "start": "639240",
    "end": "640920"
  },
  {
    "text": "batching adapters and requests for",
    "start": "640920",
    "end": "642600"
  },
  {
    "text": "efficient serving in practice this means",
    "start": "642600",
    "end": "644680"
  },
  {
    "text": "that the marginal cost of serving a new",
    "start": "644680",
    "end": "646320"
  },
  {
    "text": "adapter on the same base model is",
    "start": "646320",
    "end": "648120"
  },
  {
    "text": "virtually zero I just want to let the",
    "start": "648120",
    "end": "650079"
  },
  {
    "text": "implication of that sink in it means",
    "start": "650079",
    "end": "652040"
  },
  {
    "text": "that we can train adapters for the many",
    "start": "652040",
    "end": "654079"
  },
  {
    "text": "many different types of trust and safety",
    "start": "654079",
    "end": "655560"
  },
  {
    "text": "violations possible hate speech",
    "start": "655560",
    "end": "657880"
  },
  {
    "text": "promotion catfishing Pig butchering",
    "start": "657880",
    "end": "660120"
  },
  {
    "text": "scams and so on and we can serve all of",
    "start": "660120",
    "end": "662600"
  },
  {
    "text": "those adapters on a on one or even a",
    "start": "662600",
    "end": "664680"
  },
  {
    "text": "small set of gpus and not need to worry",
    "start": "664680",
    "end": "666399"
  },
  {
    "text": "about horizontal scaling incorporating a",
    "start": "666399",
    "end": "668920"
  },
  {
    "text": "new adapter in production is as simple",
    "start": "668920",
    "end": "670560"
  },
  {
    "text": "as storing the megabytes of weights on",
    "start": "670560",
    "end": "672279"
  },
  {
    "text": "some file system and modifying a",
    "start": "672279",
    "end": "674279"
  },
  {
    "text": "requests to The Lorax client special",
    "start": "674279",
    "end": "676800"
  },
  {
    "text": "thanks to the prabas team who developed",
    "start": "676800",
    "end": "678639"
  },
  {
    "text": "and maintains Lorax and have provided us",
    "start": "678639",
    "end": "680680"
  },
  {
    "text": "a lot of support in",
    "start": "680680",
    "end": "682200"
  },
  {
    "text": "it the um optimizations in Lorax",
    "start": "682200",
    "end": "685480"
  },
  {
    "text": "basically enable us to do real-time",
    "start": "685480",
    "end": "686760"
  },
  {
    "text": "inference and at Tinder that's critical",
    "start": "686760",
    "end": "689639"
  },
  {
    "text": "we can support on 7 billion perimeter",
    "start": "689639",
    "end": "691560"
  },
  {
    "text": "models uh tens of QPS on 100ish",
    "start": "691560",
    "end": "694079"
  },
  {
    "text": "milliseconds of latency on A10",
    "start": "694079",
    "end": "696680"
  },
  {
    "text": "gpus this is good enough for some use",
    "start": "696680",
    "end": "698839"
  },
  {
    "text": "cases um and for those other use cases",
    "start": "698839",
    "end": "701399"
  },
  {
    "text": "The High Frequency domains we can um",
    "start": "701399",
    "end": "704120"
  },
  {
    "text": "further Reduce throughput by gating",
    "start": "704120",
    "end": "705680"
  },
  {
    "text": "requests with hero sticks um for example",
    "start": "705680",
    "end": "709360"
  },
  {
    "text": "uh for detecting social media in",
    "start": "709360",
    "end": "711240"
  },
  {
    "text": "profiles um we can make predictions only",
    "start": "711240",
    "end": "713600"
  },
  {
    "text": "on bios that contain some word that's",
    "start": "713600",
    "end": "716120"
  },
  {
    "text": "not in a dictionary um and then we're",
    "start": "716120",
    "end": "718680"
  },
  {
    "text": "also exploring doing Cascade",
    "start": "718680",
    "end": "719880"
  },
  {
    "text": "classification through some distillation",
    "start": "719880",
    "end": "722079"
  },
  {
    "text": "process where we train adapters on",
    "start": "722079",
    "end": "723720"
  },
  {
    "text": "smaller base models optimizing for",
    "start": "723720",
    "end": "725360"
  },
  {
    "text": "recall and only train only call the",
    "start": "725360",
    "end": "727720"
  },
  {
    "text": "larger based model adapters when the",
    "start": "727720",
    "end": "729760"
  },
  {
    "text": "smaller one gives a high enough",
    "start": "729760",
    "end": "731720"
  },
  {
    "text": "score another Advantage for us in this",
    "start": "731720",
    "end": "734360"
  },
  {
    "text": "TNS space is in general llm outputs are",
    "start": "734360",
    "end": "737040"
  },
  {
    "text": "computationally expensive because the",
    "start": "737040",
    "end": "739240"
  },
  {
    "text": "generation is done autor regressively",
    "start": "739240",
    "end": "741040"
  },
  {
    "text": "one token at a time but classification",
    "start": "741040",
    "end": "743720"
  },
  {
    "text": "or extraction tasks require only uh",
    "start": "743720",
    "end": "746600"
  },
  {
    "text": "exactly one token or a few tokens to",
    "start": "746600",
    "end": "748720"
  },
  {
    "text": "Output which means our time to",
    "start": "748720",
    "end": "750560"
  },
  {
    "text": "prediction is",
    "start": "750560",
    "end": "753120"
  },
  {
    "text": "low um and compared to NLP models of the",
    "start": "753199",
    "end": "757040"
  },
  {
    "text": "past we're seeing that we can get",
    "start": "757040",
    "end": "758440"
  },
  {
    "text": "massive improvements in precision and",
    "start": "758440",
    "end": "760160"
  },
  {
    "text": "recall just due to the much higher",
    "start": "760160",
    "end": "762320"
  },
  {
    "text": "latent semantic capability of today's",
    "start": "762320",
    "end": "764399"
  },
  {
    "text": "llms we can achieve near 100% recall in",
    "start": "764399",
    "end": "767320"
  },
  {
    "text": "simpler tasks like social handle",
    "start": "767320",
    "end": "769040"
  },
  {
    "text": "detection and significant improvements",
    "start": "769040",
    "end": "770920"
  },
  {
    "text": "over the Baseline in more semantically",
    "start": "770920",
    "end": "773040"
  },
  {
    "text": "complex",
    "start": "773040",
    "end": "774120"
  },
  {
    "text": "tasks the other huge benefit that we get",
    "start": "774120",
    "end": "776760"
  },
  {
    "text": "is way better generalization performance",
    "start": "776760",
    "end": "778399"
  },
  {
    "text": "which I've talked about for in",
    "start": "778399",
    "end": "780680"
  },
  {
    "text": "particular this is important for TNS",
    "start": "780680",
    "end": "782880"
  },
  {
    "text": "because uh it's it's an adversarial game",
    "start": "782880",
    "end": "785959"
  },
  {
    "text": "Bad actors and other violative users",
    "start": "785959",
    "end": "787600"
  },
  {
    "text": "always try to avoid detection for",
    "start": "787600",
    "end": "789279"
  },
  {
    "text": "example with intentional typos mixing",
    "start": "789279",
    "end": "791720"
  },
  {
    "text": "letters and numbers and innuendos but",
    "start": "791720",
    "end": "793560"
  },
  {
    "text": "llms are much better at making sense of",
    "start": "793560",
    "end": "795199"
  },
  {
    "text": "these meaning that these new adapter",
    "start": "795199",
    "end": "797199"
  },
  {
    "text": "based models get stale less quickly than",
    "start": "797199",
    "end": "799240"
  },
  {
    "text": "other traditional machine learning",
    "start": "799240",
    "end": "800800"
  },
  {
    "text": "models and are a better defense against",
    "start": "800800",
    "end": "802399"
  },
  {
    "text": "harm in the long",
    "start": "802399",
    "end": "805040"
  },
  {
    "text": "run so uh where do we go from here we're",
    "start": "805160",
    "end": "808279"
  },
  {
    "text": "interested in the growing work on",
    "start": "808279",
    "end": "809959"
  },
  {
    "text": "non-textual modalities and how we can",
    "start": "809959",
    "end": "811800"
  },
  {
    "text": "leverage that for detection purposes for",
    "start": "811800",
    "end": "814120"
  },
  {
    "text": "example we can use pre-trained visual",
    "start": "814120",
    "end": "816399"
  },
  {
    "text": "language models like lava to do explicit",
    "start": "816399",
    "end": "818480"
  },
  {
    "text": "image detection and that's an active",
    "start": "818480",
    "end": "820279"
  },
  {
    "text": "area of exploration for us overall we're",
    "start": "820279",
    "end": "824120"
  },
  {
    "text": "excited about rapidly training adapters",
    "start": "824120",
    "end": "826120"
  },
  {
    "text": "for detecting harm along the long tail",
    "start": "826120",
    "end": "828120"
  },
  {
    "text": "of TNS",
    "start": "828120",
    "end": "829399"
  },
  {
    "text": "violations we can create highquality",
    "start": "829399",
    "end": "831560"
  },
  {
    "text": "data sets with trust and safety",
    "start": "831560",
    "end": "833680"
  },
  {
    "text": "operations and policy experts um with",
    "start": "833680",
    "end": "835839"
  },
  {
    "text": "that AI in the loop we can automate",
    "start": "835839",
    "end": "838120"
  },
  {
    "text": "training and retraining pipelines for",
    "start": "838120",
    "end": "839639"
  },
  {
    "text": "fine-tuning adapters and we can take",
    "start": "839639",
    "end": "842440"
  },
  {
    "text": "advantage of Lorax to slot in new",
    "start": "842440",
    "end": "844160"
  },
  {
    "text": "adapters for inference with low marginal",
    "start": "844160",
    "end": "845920"
  },
  {
    "text": "cost ultimately we can build a Next",
    "start": "845920",
    "end": "848240"
  },
  {
    "text": "Generation defensive mode against harm",
    "start": "848240",
    "end": "850320"
  },
  {
    "text": "that takes advantage of the Gen",
    "start": "850320",
    "end": "851880"
  },
  {
    "text": "landscape today ultimately leading to a",
    "start": "851880",
    "end": "854079"
  },
  {
    "text": "safer healthier platform thanks for",
    "start": "854079",
    "end": "856079"
  },
  {
    "text": "listening",
    "start": "856079",
    "end": "859079"
  },
  {
    "text": "[Music]",
    "start": "860800",
    "end": "877719"
  }
]
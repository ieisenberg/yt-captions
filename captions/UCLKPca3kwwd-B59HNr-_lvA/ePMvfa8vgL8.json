[
  {
    "text": "[Music]",
    "start": "350",
    "end": "14050"
  },
  {
    "text": "hello everyone so my name is Dima um as",
    "start": "14519",
    "end": "17039"
  },
  {
    "text": "mentioned uh unfortunately my co-founder",
    "start": "17039",
    "end": "20039"
  },
  {
    "text": "Lino was on the schedule couldn't make",
    "start": "20039",
    "end": "21920"
  },
  {
    "text": "it today because of some personal",
    "start": "21920",
    "end": "23160"
  },
  {
    "text": "emergency so you got me and as you saw",
    "start": "23160",
    "end": "26519"
  },
  {
    "text": "we don't have yet AI to figure out video",
    "start": "26519",
    "end": "29279"
  },
  {
    "text": "projection but we have a for a lot of",
    "start": "29279",
    "end": "31000"
  },
  {
    "text": "other things uh so today I'm going to",
    "start": "31000",
    "end": "33360"
  },
  {
    "text": "talk about fireworks Ai and generally",
    "start": "33360",
    "end": "35360"
  },
  {
    "text": "I'm going to continue this te which kin",
    "start": "35360",
    "end": "37480"
  },
  {
    "text": "started about open models uh and how we",
    "start": "37480",
    "end": "41160"
  },
  {
    "text": "uh basically focus on",
    "start": "41160",
    "end": "44280"
  },
  {
    "text": "productionize but first uh as an",
    "start": "47440",
    "end": "49640"
  },
  {
    "text": "introduction uh what's our background uh",
    "start": "49640",
    "end": "52359"
  },
  {
    "text": "so the founding team of fireworks comes",
    "start": "52359",
    "end": "55239"
  },
  {
    "text": "from PCH leads at meta and some veterans",
    "start": "55239",
    "end": "58079"
  },
  {
    "text": "from Google AI so we combined have like",
    "start": "58079",
    "end": "61079"
  },
  {
    "text": "probably decade of experience in",
    "start": "61079",
    "end": "62440"
  },
  {
    "text": "productionizing Ai and some of the",
    "start": "62440",
    "end": "63800"
  },
  {
    "text": "biggest companies in the world and I",
    "start": "63800",
    "end": "66560"
  },
  {
    "text": "myself personally has been core",
    "start": "66560",
    "end": "68159"
  },
  {
    "text": "maintainer of PCH uh for the past 5",
    "start": "68159",
    "end": "70400"
  },
  {
    "text": "years so topic of Open Source is really",
    "start": "70400",
    "end": "73920"
  },
  {
    "text": "close to my heart and since we kind of",
    "start": "73920",
    "end": "76759"
  },
  {
    "text": "LED this revolution of Open Source tool",
    "start": "76759",
    "end": "79439"
  },
  {
    "text": "chain for deep learning through our work",
    "start": "79439",
    "end": "81280"
  },
  {
    "text": "on P and some of the Google Technologies",
    "start": "81280",
    "end": "83960"
  },
  {
    "text": "we really believe that open source uh",
    "start": "83960",
    "end": "86600"
  },
  {
    "text": "models are the future also for like for",
    "start": "86600",
    "end": "90000"
  },
  {
    "text": "for Gen application and our focus at",
    "start": "90000",
    "end": "92680"
  },
  {
    "text": "fireworks is precisely on",
    "start": "92680",
    "end": "94880"
  },
  {
    "text": "that um",
    "start": "94880",
    "end": "97520"
  },
  {
    "text": "so I mean uh how many people in the",
    "start": "97520",
    "end": "100079"
  },
  {
    "text": "audience actually like use GPT and",
    "start": "100079",
    "end": "102640"
  },
  {
    "text": "deploy it in for",
    "start": "102640",
    "end": "104200"
  },
  {
    "text": "production and how many people how many",
    "start": "104200",
    "end": "106399"
  },
  {
    "text": "folks use open models um AO prodction oh",
    "start": "106399",
    "end": "111000"
  },
  {
    "text": "okay so I was about to convince you that",
    "start": "111000",
    "end": "113360"
  },
  {
    "text": "share of Open Source models is going to",
    "start": "113360",
    "end": "115439"
  },
  {
    "text": "grow over time but it looks like in this",
    "start": "115439",
    "end": "117119"
  },
  {
    "text": "audience it's already already sizable",
    "start": "117119",
    "end": "119600"
  },
  {
    "text": "but",
    "start": "119600",
    "end": "120600"
  },
  {
    "text": "nevertheless um so why why basically",
    "start": "120600",
    "end": "123920"
  },
  {
    "text": "this tradeoff why go big or why go small",
    "start": "123920",
    "end": "127039"
  },
  {
    "text": "uh currently still like bulk of",
    "start": "127039",
    "end": "128440"
  },
  {
    "text": "production inference is still based on",
    "start": "128440",
    "end": "130080"
  },
  {
    "text": "proprietary models and uh the catch with",
    "start": "130080",
    "end": "133040"
  },
  {
    "text": "that those are really good models and",
    "start": "133040",
    "end": "135080"
  },
  {
    "text": "often froner in in many domains uh",
    "start": "135080",
    "end": "138400"
  },
  {
    "text": "however the catch is that it's one model",
    "start": "138400",
    "end": "140239"
  },
  {
    "text": "which is good in many many things and",
    "start": "140239",
    "end": "142440"
  },
  {
    "text": "it's often served uh in the same way uh",
    "start": "142440",
    "end": "144720"
  },
  {
    "text": "regardless of the use case which means",
    "start": "144720",
    "end": "146760"
  },
  {
    "text": "that maybe if you have bch inference uh",
    "start": "146760",
    "end": "149440"
  },
  {
    "text": "on some nrow domain or you have some",
    "start": "149440",
    "end": "151239"
  },
  {
    "text": "super realtime use case uh where you",
    "start": "151239",
    "end": "153519"
  },
  {
    "text": "need to you need to do like voice",
    "start": "153519",
    "end": "156120"
  },
  {
    "text": "assistant or something uh those often",
    "start": "156120",
    "end": "158360"
  },
  {
    "text": "serve from the same infrastructure",
    "start": "158360",
    "end": "159400"
  },
  {
    "text": "without customization in terms of model",
    "start": "159400",
    "end": "161920"
  },
  {
    "text": "capabilities it also means yeah like GPT",
    "start": "161920",
    "end": "163959"
  },
  {
    "text": "4 is great or CLA is great and can",
    "start": "163959",
    "end": "166800"
  },
  {
    "text": "handle a lot of sense but you are often",
    "start": "166800",
    "end": "168800"
  },
  {
    "text": "paying a lot for additional capabilities",
    "start": "168800",
    "end": "171319"
  },
  {
    "text": "which are not needed in particular this",
    "start": "171319",
    "end": "172800"
  },
  {
    "text": "case you don't really need customer",
    "start": "172800",
    "end": "174519"
  },
  {
    "text": "support chatbot to know about 150",
    "start": "174519",
    "end": "177519"
  },
  {
    "text": "Pok√©mons or be able to write write your",
    "start": "177519",
    "end": "179879"
  },
  {
    "text": "poetry uh but you really want it to be",
    "start": "179879",
    "end": "182159"
  },
  {
    "text": "really good in the particular uh narrow",
    "start": "182159",
    "end": "185239"
  },
  {
    "text": "domain so this uh kind uh this kind of",
    "start": "185239",
    "end": "188000"
  },
  {
    "text": "discrepancy for large models leads to",
    "start": "188000",
    "end": "189840"
  },
  {
    "text": "several issues one as I mention is high",
    "start": "189840",
    "end": "191959"
  },
  {
    "text": "latency because using a big model means",
    "start": "191959",
    "end": "194599"
  },
  {
    "text": "uh longer response times uh which is",
    "start": "194599",
    "end": "198239"
  },
  {
    "text": "particularly important for Real Time use",
    "start": "198239",
    "end": "199840"
  },
  {
    "text": "cases like voice assistance it gets more",
    "start": "199840",
    "end": "202599"
  },
  {
    "text": "and more important with tic stuff",
    "start": "202599",
    "end": "204360"
  },
  {
    "text": "because for stuff like um for example",
    "start": "204360",
    "end": "208080"
  },
  {
    "text": "next talk is going to be de right like",
    "start": "208080",
    "end": "209519"
  },
  {
    "text": "you you need to do a lot of steps for",
    "start": "209519",
    "end": "211439"
  },
  {
    "text": "like something like agent like",
    "start": "211439",
    "end": "213400"
  },
  {
    "text": "application to do reasoning and call the",
    "start": "213400",
    "end": "215439"
  },
  {
    "text": "model many times so latency is really",
    "start": "215439",
    "end": "217000"
  },
  {
    "text": "important and often you see that you can",
    "start": "217000",
    "end": "219799"
  },
  {
    "text": "pick smaller models like lar or Gemma",
    "start": "219799",
    "end": "223360"
  },
  {
    "text": "which you just talk about and achieve",
    "start": "223360",
    "end": "225480"
  },
  {
    "text": "the for an nrow domain uh same of better",
    "start": "225480",
    "end": "228200"
  },
  {
    "text": "quality while being you know up to 10",
    "start": "228200",
    "end": "230640"
  },
  {
    "text": "times faster uh for example for some of",
    "start": "230640",
    "end": "233040"
  },
  {
    "text": "the function calling use cases like",
    "start": "233040",
    "end": "234920"
  },
  {
    "text": "externally Benchmark from uh from",
    "start": "234920",
    "end": "237120"
  },
  {
    "text": "Berkeley yeah like the you get similar",
    "start": "237120",
    "end": "239280"
  },
  {
    "text": "performance from F tune Lama 3 at 10x",
    "start": "239280",
    "end": "242239"
  },
  {
    "text": "speed cost is also uh is also an issue",
    "start": "242239",
    "end": "246079"
  },
  {
    "text": "if you're running a big model for uh on",
    "start": "246079",
    "end": "248879"
  },
  {
    "text": "a lot of traffic you know even if you",
    "start": "248879",
    "end": "250480"
  },
  {
    "text": "have perhaps I know 5K tokens prompt and",
    "start": "250480",
    "end": "253879"
  },
  {
    "text": "10,000 users and each of them call sell",
    "start": "253879",
    "end": "256000"
  },
  {
    "text": "them 20 times per day you know on GPT 4",
    "start": "256000",
    "end": "258280"
  },
  {
    "text": "even on GPT 40 it probably adds up to",
    "start": "258280",
    "end": "260239"
  },
  {
    "text": "like 10K per day or something like",
    "start": "260239",
    "end": "262639"
  },
  {
    "text": "several million per month Al 7 million",
    "start": "262639",
    "end": "265240"
  },
  {
    "text": "per year which is a sizable cost of a",
    "start": "265240",
    "end": "267000"
  },
  {
    "text": "startup you can easily cut that with",
    "start": "267000",
    "end": "269120"
  },
  {
    "text": "much smaller model models and that often",
    "start": "269120",
    "end": "270680"
  },
  {
    "text": "we see as a uh as a kind of motivation",
    "start": "270680",
    "end": "274000"
  },
  {
    "text": "for reaching out for smaller and more",
    "start": "274000",
    "end": "276880"
  },
  {
    "text": "customizable models uh but really the uh",
    "start": "276880",
    "end": "280479"
  },
  {
    "text": "like where open models shine is domain",
    "start": "280479",
    "end": "282880"
  },
  {
    "text": "adaptability and that comes uh in two",
    "start": "282880",
    "end": "285440"
  },
  {
    "text": "aspects first um there is so many",
    "start": "285440",
    "end": "288120"
  },
  {
    "text": "different F tunes and customizations uh",
    "start": "288120",
    "end": "290000"
  },
  {
    "text": "I think Kaitlyn was mentioning about you",
    "start": "290000",
    "end": "291520"
  },
  {
    "text": "know Gemma built Indian languages",
    "start": "291520",
    "end": "294120"
  },
  {
    "text": "adaptation like there are model",
    "start": "294120",
    "end": "295639"
  },
  {
    "text": "specialized for coder for medicine if",
    "start": "295639",
    "end": "297479"
  },
  {
    "text": "you had to hug and face there are like",
    "start": "297479",
    "end": "299400"
  },
  {
    "text": "10 of thousands of different model",
    "start": "299400",
    "end": "301080"
  },
  {
    "text": "variants and because the weights are",
    "start": "301080",
    "end": "302800"
  },
  {
    "text": "open you can always customize to your",
    "start": "302800",
    "end": "304479"
  },
  {
    "text": "particular use case and tune and uh tune",
    "start": "304479",
    "end": "308039"
  },
  {
    "text": "quality specifically for for what you",
    "start": "308039",
    "end": "310639"
  },
  {
    "text": "need so open source models are great so",
    "start": "310639",
    "end": "313320"
  },
  {
    "text": "what are the challenges uh the",
    "start": "313320",
    "end": "314520"
  },
  {
    "text": "challenges really come from three areas",
    "start": "314520",
    "end": "316840"
  },
  {
    "text": "uh first like what we usually see when",
    "start": "316840",
    "end": "319080"
  },
  {
    "text": "people try to use you know open model",
    "start": "319080",
    "end": "320919"
  },
  {
    "text": "something like gem or whatever uh or or",
    "start": "320919",
    "end": "324000"
  },
  {
    "text": "lb uh you run into complicated setup and",
    "start": "324000",
    "end": "327319"
  },
  {
    "text": "maintenance right you need to go and",
    "start": "327319",
    "end": "328880"
  },
  {
    "text": "find gpus somewhere you need to figure",
    "start": "328880",
    "end": "330720"
  },
  {
    "text": "out which Frameworks to run on those you",
    "start": "330720",
    "end": "333639"
  },
  {
    "text": "need to like download the models maybe",
    "start": "333639",
    "end": "335600"
  },
  {
    "text": "do some performance optimization tun in",
    "start": "335600",
    "end": "337479"
  },
  {
    "text": "and you kind of have to repeat this",
    "start": "337479",
    "end": "338720"
  },
  {
    "text": "process end to end every time the model",
    "start": "338720",
    "end": "340880"
  },
  {
    "text": "gets updated or new version is released",
    "start": "340880",
    "end": "343560"
  },
  {
    "text": "Etc uh on optimization itself uh there",
    "start": "343560",
    "end": "346639"
  },
  {
    "text": "is especially for llms but generally for",
    "start": "346639",
    "end": "348680"
  },
  {
    "text": "Gen models there are many attributes uh",
    "start": "348680",
    "end": "352000"
  },
  {
    "text": "and settings which are really really",
    "start": "352000",
    "end": "354280"
  },
  {
    "text": "dependent on your use casing",
    "start": "354280",
    "end": "356080"
  },
  {
    "text": "requirements somebody needs low latency",
    "start": "356080",
    "end": "357840"
  },
  {
    "text": "somebody needs High throughput proms can",
    "start": "357840",
    "end": "360080"
  },
  {
    "text": "be short proms can be long Etc and",
    "start": "360080",
    "end": "362240"
  },
  {
    "text": "choosing the optimal settings across the",
    "start": "362240",
    "end": "363880"
  },
  {
    "text": "stack is actually not trival and as I",
    "start": "363880",
    "end": "366560"
  },
  {
    "text": "show later in many cases you can get",
    "start": "366560",
    "end": "368599"
  },
  {
    "text": "multiple X improvements from doing from",
    "start": "368599",
    "end": "370840"
  },
  {
    "text": "doing this efficiently and finally like",
    "start": "370840",
    "end": "373479"
  },
  {
    "text": "just getting it production ready is",
    "start": "373479",
    "end": "375240"
  },
  {
    "text": "actually hard uh if as you kind of go",
    "start": "375240",
    "end": "378319"
  },
  {
    "text": "from experimentation to production even",
    "start": "378319",
    "end": "380280"
  },
  {
    "text": "just BB sitting gpus on public clouds is",
    "start": "380280",
    "end": "383120"
  },
  {
    "text": "not not as easy because gpus Ain not",
    "start": "383120",
    "end": "385199"
  },
  {
    "text": "always reliable uh but getting to",
    "start": "385199",
    "end": "387440"
  },
  {
    "text": "Enterprise scale requires you know SC",
    "start": "387440",
    "end": "389720"
  },
  {
    "text": "scalability technology Telemetry",
    "start": "389720",
    "end": "391280"
  },
  {
    "text": "observability Etc so those are uh things",
    "start": "391280",
    "end": "394759"
  },
  {
    "text": "which we focus on uh solving at",
    "start": "394759",
    "end": "396960"
  },
  {
    "text": "fireworks so starting with efficiency we",
    "start": "396960",
    "end": "399639"
  },
  {
    "text": "built uh our own custom serving stack",
    "start": "399639",
    "end": "402479"
  },
  {
    "text": "which we believe is one of the fastest",
    "start": "402479",
    "end": "404160"
  },
  {
    "text": "if not the fastest uh we did it did it",
    "start": "404160",
    "end": "407720"
  },
  {
    "text": "from the ground up meaning from writing",
    "start": "407720",
    "end": "409520"
  },
  {
    "text": "our own you know Cuda kernels all the",
    "start": "409520",
    "end": "411560"
  },
  {
    "text": "way to customizing how the stuff gets",
    "start": "411560",
    "end": "414680"
  },
  {
    "text": "deployed and orchestrated on the service",
    "start": "414680",
    "end": "416280"
  },
  {
    "text": "level and that brings multiple",
    "start": "416280",
    "end": "418599"
  },
  {
    "text": "optimizations but most importantly we",
    "start": "418599",
    "end": "420319"
  },
  {
    "text": "really focus on customizing this service",
    "start": "420319",
    "end": "422280"
  },
  {
    "text": "tech to your needs uh which basically",
    "start": "422280",
    "end": "424759"
  },
  {
    "text": "means for your custom work cloud and for",
    "start": "424759",
    "end": "426560"
  },
  {
    "text": "your custom cost and latency latency",
    "start": "426560",
    "end": "429440"
  },
  {
    "text": "requirements we can we can tune it for",
    "start": "429440",
    "end": "432160"
  },
  {
    "text": "uh for those settings what does it mean",
    "start": "432160",
    "end": "434520"
  },
  {
    "text": "in practice what do customization means",
    "start": "434520",
    "end": "436360"
  },
  {
    "text": "in practice uh for example many use",
    "start": "436360",
    "end": "438639"
  },
  {
    "text": "cases use Rag and use very long prompts",
    "start": "438639",
    "end": "441960"
  },
  {
    "text": "uh so there are many settings you can",
    "start": "441960",
    "end": "443759"
  },
  {
    "text": "tune actually on the runtime level at",
    "start": "443759",
    "end": "445400"
  },
  {
    "text": "the deployment level to optimize for",
    "start": "445400",
    "end": "447840"
  },
  {
    "text": "loan prompts which often can be rep",
    "start": "447840",
    "end": "449520"
  },
  {
    "text": "fitable so cing is useful or just tun in",
    "start": "449520",
    "end": "452599"
  },
  {
    "text": "settings so the stut is higher while",
    "start": "452599",
    "end": "454280"
  },
  {
    "text": "maintaining latency so this is",
    "start": "454280",
    "end": "456319"
  },
  {
    "text": "independently Benchmark if you go to uh",
    "start": "456319",
    "end": "459240"
  },
  {
    "text": "you know artificial analysis and select",
    "start": "459240",
    "end": "460599"
  },
  {
    "text": "La prompt where Firebox actually is the",
    "start": "460599",
    "end": "462520"
  },
  {
    "text": "fastest even faster than some of the",
    "start": "462520",
    "end": "464479"
  },
  {
    "text": "other providers which are over there at",
    "start": "464479",
    "end": "466960"
  },
  {
    "text": "expoo uh and uh we don't only focus we",
    "start": "466960",
    "end": "470240"
  },
  {
    "text": "don't only focus on LM and Friends uh we",
    "start": "470240",
    "end": "472360"
  },
  {
    "text": "focus on many modalities uh as an",
    "start": "472360",
    "end": "474159"
  },
  {
    "text": "example for image generation we are the",
    "start": "474159",
    "end": "476639"
  },
  {
    "text": "fastest provider serving sdxl we also",
    "start": "476639",
    "end": "479159"
  },
  {
    "text": "the only providers Ser in sd3 uh",
    "start": "479159",
    "end": "482599"
  },
  {
    "text": "stabilities new model because their API",
    "start": "482599",
    "end": "484599"
  },
  {
    "text": "actually routes to our servers um and",
    "start": "484599",
    "end": "488879"
  },
  {
    "text": "finally as I mentioned for like LMS like",
    "start": "488879",
    "end": "490879"
  },
  {
    "text": "customiz especially for LMS",
    "start": "490879",
    "end": "492240"
  },
  {
    "text": "customization matters a lot uh One",
    "start": "492240",
    "end": "494639"
  },
  {
    "text": "require like one paradig we how to think",
    "start": "494639",
    "end": "496680"
  },
  {
    "text": "about performance of LMS often it's",
    "start": "496680",
    "end": "498360"
  },
  {
    "text": "useful for use cases is to think about",
    "start": "498360",
    "end": "500639"
  },
  {
    "text": "Max like minimizing cost under a",
    "start": "500639",
    "end": "502039"
  },
  {
    "text": "particular latency constraint we often",
    "start": "502039",
    "end": "503840"
  },
  {
    "text": "have customers coming and say like hey I",
    "start": "503840",
    "end": "505440"
  },
  {
    "text": "need to like have this my interactive",
    "start": "505440",
    "end": "507280"
  },
  {
    "text": "application I need to generate that many",
    "start": "507280",
    "end": "509039"
  },
  {
    "text": "tokens under two seconds and that's",
    "start": "509039",
    "end": "512000"
  },
  {
    "text": "where that's really where like cross",
    "start": "512000",
    "end": "513640"
  },
  {
    "text": "stack optimizations shine uh whereby uh",
    "start": "513640",
    "end": "517320"
  },
  {
    "text": "T into particular like latency cut off",
    "start": "517320",
    "end": "519560"
  },
  {
    "text": "and change in many settings you can",
    "start": "519560",
    "end": "521039"
  },
  {
    "text": "deliver much higher throughput multiple",
    "start": "521039",
    "end": "523120"
  },
  {
    "text": "times higher throughput uh which B",
    "start": "523120",
    "end": "525120"
  },
  {
    "text": "higher throughput basically means fewer",
    "start": "525120",
    "end": "526399"
  },
  {
    "text": "gpus and lower",
    "start": "526399",
    "end": "529480"
  },
  {
    "text": "cost uh in terms in terms of model",
    "start": "529480",
    "end": "532680"
  },
  {
    "text": "support we support support best quality",
    "start": "532680",
    "end": "535560"
  },
  {
    "text": "open source models uh we heard about",
    "start": "535560",
    "end": "537640"
  },
  {
    "text": "Gemma now obviously llamas uh some of",
    "start": "537640",
    "end": "540880"
  },
  {
    "text": "the ASR inext to speech models pretty",
    "start": "540880",
    "end": "543959"
  },
  {
    "text": "much from from many providers we also",
    "start": "543959",
    "end": "545839"
  },
  {
    "text": "work with model Developers for examp for",
    "start": "545839",
    "end": "547920"
  },
  {
    "text": "example e large uh in US is also served",
    "start": "547920",
    "end": "550600"
  },
  {
    "text": "on uh on fireworks launched launch last",
    "start": "550600",
    "end": "554680"
  },
  {
    "text": "week and uh as a kind of platform",
    "start": "554680",
    "end": "558320"
  },
  {
    "text": "capabilities as I mentioned we have a",
    "start": "558320",
    "end": "560040"
  },
  {
    "text": "lot of Open Source models to uh to get",
    "start": "560040",
    "end": "562160"
  },
  {
    "text": "you started or customized ones we do",
    "start": "562160",
    "end": "564839"
  },
  {
    "text": "some of the fine tuning of those models",
    "start": "564839",
    "end": "566959"
  },
  {
    "text": "uh in house so I'm going to talk a",
    "start": "566959",
    "end": "568480"
  },
  {
    "text": "little bit about function specialized",
    "start": "568480",
    "end": "570120"
  },
  {
    "text": "models uh later on or we do some of the",
    "start": "570120",
    "end": "574360"
  },
  {
    "text": "vision language model Fusion ourselves",
    "start": "574360",
    "end": "576440"
  },
  {
    "text": "which we release as well and of course",
    "start": "576440",
    "end": "578680"
  },
  {
    "text": "the key for open source um open model",
    "start": "578680",
    "end": "582000"
  },
  {
    "text": "development is it can tuned for",
    "start": "582000",
    "end": "583720"
  },
  {
    "text": "particular use case so we do provide a",
    "start": "583720",
    "end": "585600"
  },
  {
    "text": "platform for fine tuning uh whether",
    "start": "585600",
    "end": "587839"
  },
  {
    "text": "you're bringing your data set collected",
    "start": "587839",
    "end": "590040"
  },
  {
    "text": "elsewhere or collecting it life uh with",
    "start": "590040",
    "end": "592160"
  },
  {
    "text": "a feedback when serves on our",
    "start": "592160",
    "end": "595160"
  },
  {
    "text": "platform uh specifically on",
    "start": "595160",
    "end": "597040"
  },
  {
    "text": "customization it's like one uh interest",
    "start": "597040",
    "end": "598920"
  },
  {
    "text": "one inter in feature which a lot of",
    "start": "598920",
    "end": "600800"
  },
  {
    "text": "people starting to experiment with",
    "start": "600800",
    "end": "602320"
  },
  {
    "text": "models uh find interesting is if you try",
    "start": "602320",
    "end": "605240"
  },
  {
    "text": "to find fine tune and deploy the",
    "start": "605240",
    "end": "606680"
  },
  {
    "text": "resulting model how uh how to serve it",
    "start": "606680",
    "end": "609000"
  },
  {
    "text": "efficiently uh turns out if you do lying",
    "start": "609000",
    "end": "611480"
  },
  {
    "text": "tun which a lot of folks do uh you can",
    "start": "611480",
    "end": "613880"
  },
  {
    "text": "do uh smart tricks and deploy multiple",
    "start": "613880",
    "end": "616839"
  },
  {
    "text": "plur models on the same GPU uh actually",
    "start": "616839",
    "end": "619000"
  },
  {
    "text": "thousands of them which means that we",
    "start": "619000",
    "end": "620680"
  },
  {
    "text": "can give you still serverless inference",
    "start": "620680",
    "end": "622959"
  },
  {
    "text": "with pain per token even if you have",
    "start": "622959",
    "end": "624880"
  },
  {
    "text": "like thousands of model variants uh",
    "start": "624880",
    "end": "627399"
  },
  {
    "text": "sitting and deployed there without",
    "start": "627399",
    "end": "628839"
  },
  {
    "text": "having to pay any fixed",
    "start": "628839",
    "end": "632320"
  },
  {
    "text": "cost of course single model is all great",
    "start": "632320",
    "end": "635279"
  },
  {
    "text": "uh but what we see increasingly more and",
    "start": "635279",
    "end": "637680"
  },
  {
    "text": "more in applications is model is not the",
    "start": "637680",
    "end": "640639"
  },
  {
    "text": "product right uh uh by itself you need a",
    "start": "640639",
    "end": "643519"
  },
  {
    "text": "kind of bigger system uh in order to",
    "start": "643519",
    "end": "645839"
  },
  {
    "text": "solve Target application and the reason",
    "start": "645839",
    "end": "647959"
  },
  {
    "text": "for that is because uh models by",
    "start": "647959",
    "end": "649959"
  },
  {
    "text": "themselves tend to hallucinate so you",
    "start": "649959",
    "end": "651600"
  },
  {
    "text": "need some ground in and that's where",
    "start": "651600",
    "end": "653360"
  },
  {
    "text": "like rag or access to external knowledge",
    "start": "653360",
    "end": "656200"
  },
  {
    "text": "bases comes in uh also we don't have you",
    "start": "656200",
    "end": "658959"
  },
  {
    "text": "no yet in Industry magical multimodel uh",
    "start": "658959",
    "end": "662120"
  },
  {
    "text": "AI across all the modalities so often",
    "start": "662120",
    "end": "664360"
  },
  {
    "text": "you have to kind of chain multiple types",
    "start": "664360",
    "end": "666200"
  },
  {
    "text": "of models and of course you have all",
    "start": "666200",
    "end": "667920"
  },
  {
    "text": "this like external tools and external",
    "start": "667920",
    "end": "669560"
  },
  {
    "text": "actions which uh kind of end to end",
    "start": "669560",
    "end": "672000"
  },
  {
    "text": "applications might want to do in tic",
    "start": "672000",
    "end": "675120"
  },
  {
    "text": "form uh so I think the term which I",
    "start": "675120",
    "end": "677920"
  },
  {
    "text": "really like which is like popularized by",
    "start": "677920",
    "end": "679959"
  },
  {
    "text": "data Brak is like compound AI system but",
    "start": "679959",
    "end": "682480"
  },
  {
    "text": "basically increasingly seen like",
    "start": "682480",
    "end": "684279"
  },
  {
    "text": "transition from just the model being the",
    "start": "684279",
    "end": "686040"
  },
  {
    "text": "product to kind of this combination of",
    "start": "686040",
    "end": "688079"
  },
  {
    "text": "maybe like Rag and function call and",
    "start": "688079",
    "end": "689600"
  },
  {
    "text": "external tools Etc built together as the",
    "start": "689600",
    "end": "692000"
  },
  {
    "text": "product and that's pretty much Direction",
    "start": "692000",
    "end": "694079"
  },
  {
    "text": "which we kind of see uh this field",
    "start": "694079",
    "end": "697360"
  },
  {
    "text": "moving along uh over time so what does",
    "start": "697360",
    "end": "700440"
  },
  {
    "text": "it mean from uh from kind of our",
    "start": "700440",
    "end": "702360"
  },
  {
    "text": "perspective what we what we do in this",
    "start": "702360",
    "end": "703880"
  },
  {
    "text": "case uh so we see kind of as a function",
    "start": "703880",
    "end": "707279"
  },
  {
    "text": "calling like agent as a at the core of",
    "start": "707279",
    "end": "709399"
  },
  {
    "text": "this uh emerging architecture which",
    "start": "709399",
    "end": "712000"
  },
  {
    "text": "might be connected to either domain",
    "start": "712000",
    "end": "713959"
  },
  {
    "text": "specialized models uh served on our",
    "start": "713959",
    "end": "717519"
  },
  {
    "text": "platform directly or maybe tuned for for",
    "start": "717519",
    "end": "719440"
  },
  {
    "text": "part different needs and connected to",
    "start": "719440",
    "end": "721160"
  },
  {
    "text": "external tools uh maybe it's a cond",
    "start": "721160",
    "end": "722920"
  },
  {
    "text": "interpreter or maybe it's like external",
    "start": "722920",
    "end": "724480"
  },
  {
    "text": "apis somewhere uh with really like this",
    "start": "724480",
    "end": "727040"
  },
  {
    "text": "kind of central agentic uh view uh kind",
    "start": "727040",
    "end": "730959"
  },
  {
    "text": "Central Central model kind of",
    "start": "730959",
    "end": "732399"
  },
  {
    "text": "coordinating and trying to trash the uh",
    "start": "732399",
    "end": "735519"
  },
  {
    "text": "user user requirements if it's for",
    "start": "735519",
    "end": "737120"
  },
  {
    "text": "example a chatbot or something uh you",
    "start": "737120",
    "end": "739440"
  },
  {
    "text": "probably all uh heard about like",
    "start": "739440",
    "end": "741079"
  },
  {
    "text": "function calling you know popularized by",
    "start": "741079",
    "end": "742920"
  },
  {
    "text": "open air initially that's that's",
    "start": "742920",
    "end": "744920"
  },
  {
    "text": "basically the same idea uh so yeah the",
    "start": "744920",
    "end": "747839"
  },
  {
    "text": "function qu is really like a how to how",
    "start": "747839",
    "end": "750199"
  },
  {
    "text": "to connect llm to external tools and",
    "start": "750199",
    "end": "753320"
  },
  {
    "text": "exter and external elements what does it",
    "start": "753320",
    "end": "756440"
  },
  {
    "text": "mean in practice so we actually uh focus",
    "start": "756440",
    "end": "760040"
  },
  {
    "text": "on F models specifically for function",
    "start": "760040",
    "end": "761839"
  },
  {
    "text": "calling so we release a series of models",
    "start": "761839",
    "end": "764000"
  },
  {
    "text": "like that like the latest one fire",
    "start": "764000",
    "end": "765519"
  },
  {
    "text": "function V was released two uh two weeks",
    "start": "765519",
    "end": "767760"
  },
  {
    "text": "ago and uh what you can do with that is",
    "start": "767760",
    "end": "772720"
  },
  {
    "text": "uh okay if I manage to",
    "start": "772720",
    "end": "775920"
  },
  {
    "text": "click if I manage to click on this",
    "start": "775920",
    "end": "778279"
  },
  {
    "text": "button",
    "start": "778279",
    "end": "780079"
  },
  {
    "text": "uh what it means is that you can build",
    "start": "780079",
    "end": "782040"
  },
  {
    "text": "uh applications which kind of combine",
    "start": "782040",
    "end": "784079"
  },
  {
    "text": "free form General chat uh capabilities",
    "start": "784079",
    "end": "787519"
  },
  {
    "text": "with function Co so in this case the",
    "start": "787519",
    "end": "789639"
  },
  {
    "text": "this is you know this fire function has",
    "start": "789639",
    "end": "791560"
  },
  {
    "text": "some chat capabilities so you could see",
    "start": "791560",
    "end": "794040"
  },
  {
    "text": "you can like ask it what what you can",
    "start": "794040",
    "end": "795519"
  },
  {
    "text": "you do and it has like some",
    "start": "795519",
    "end": "796839"
  },
  {
    "text": "self-reflection to tell you what it can",
    "start": "796839",
    "end": "798240"
  },
  {
    "text": "do it's also connected in this demo app",
    "start": "798240",
    "end": "800240"
  },
  {
    "text": "to a bunch of uh external tools so it",
    "start": "800240",
    "end": "802800"
  },
  {
    "text": "can uh query uh like stock quotes it can",
    "start": "802800",
    "end": "806639"
  },
  {
    "text": "plot some charts all those like external",
    "start": "806639",
    "end": "808600"
  },
  {
    "text": "apis",
    "start": "808600",
    "end": "809959"
  },
  {
    "text": "uh it can U also gener generate images",
    "start": "809959",
    "end": "813959"
  },
  {
    "text": "but what it really needs to figure out",
    "start": "813959",
    "end": "815240"
  },
  {
    "text": "is how to translate user query into do",
    "start": "815240",
    "end": "818040"
  },
  {
    "text": "complex reasoning translate it into",
    "start": "818040",
    "end": "819720"
  },
  {
    "text": "function calls so for example if we ask",
    "start": "819720",
    "end": "821839"
  },
  {
    "text": "it to generate a bar chart with top",
    "start": "821839",
    "end": "824680"
  },
  {
    "text": "three uh like this stocks of top Cloud",
    "start": "824680",
    "end": "827680"
  },
  {
    "text": "providers like the big three it actually",
    "start": "827680",
    "end": "829880"
  },
  {
    "text": "needs to do several steps right it needs",
    "start": "829880",
    "end": "831720"
  },
  {
    "text": "to understand that like top three Cloud",
    "start": "831720",
    "end": "833680"
  },
  {
    "text": "providers means you knows gcp and uh an",
    "start": "833680",
    "end": "837480"
  },
  {
    "text": "Azure right aure is on by Microsoft it",
    "start": "837480",
    "end": "840040"
  },
  {
    "text": "needs to uh then go do function calls",
    "start": "840040",
    "end": "843199"
  },
  {
    "text": "querying their stock prices and finally",
    "start": "843199",
    "end": "845040"
  },
  {
    "text": "it needs to combine those information",
    "start": "845040",
    "end": "846839"
  },
  {
    "text": "and send it to chat plotting API which",
    "start": "846839",
    "end": "849240"
  },
  {
    "text": "is what just happened uh in the in the",
    "start": "849240",
    "end": "851920"
  },
  {
    "text": "background uh another important aspect",
    "start": "851920",
    "end": "854199"
  },
  {
    "text": "which you have to do for like efficient",
    "start": "854199",
    "end": "856800"
  },
  {
    "text": "uh kind of function calling chat",
    "start": "856800",
    "end": "858320"
  },
  {
    "text": "capabilities you need to have contextual",
    "start": "858320",
    "end": "860160"
  },
  {
    "text": "awareness so if I ask it to add",
    "start": "860160",
    "end": "862240"
  },
  {
    "text": "particular uh if I ask to add Oracle to",
    "start": "862240",
    "end": "864720"
  },
  {
    "text": "this graph it needs to understand what",
    "start": "864720",
    "end": "865839"
  },
  {
    "text": "I'm referring to and like still keep the",
    "start": "865839",
    "end": "867759"
  },
  {
    "text": "previous context and regenerate the",
    "start": "867759",
    "end": "869279"
  },
  {
    "text": "image and finally you know if I switch",
    "start": "869279",
    "end": "871279"
  },
  {
    "text": "to a part to a different topic it kind",
    "start": "871279",
    "end": "873839"
  },
  {
    "text": "of needs to drop the previous context",
    "start": "873839",
    "end": "875600"
  },
  {
    "text": "and understand that like hey this is",
    "start": "875600",
    "end": "877079"
  },
  {
    "text": "less uh this historical context is less",
    "start": "877079",
    "end": "879680"
  },
  {
    "text": "important I'm going to start from",
    "start": "879680",
    "end": "880600"
  },
  {
    "text": "scratch so there is no like Oracle in",
    "start": "880600",
    "end": "882680"
  },
  {
    "text": "that cat photo or whatever uh so you",
    "start": "882680",
    "end": "885360"
  },
  {
    "text": "know this particular demo is uh is",
    "start": "885360",
    "end": "887839"
  },
  {
    "text": "actually open source you can like go to",
    "start": "887839",
    "end": "889360"
  },
  {
    "text": "our GitHub and try it out it's built",
    "start": "889360",
    "end": "891240"
  },
  {
    "text": "with fire function and it's built with",
    "start": "891240",
    "end": "892480"
  },
  {
    "text": "like a few other a few other models",
    "start": "892480",
    "end": "894920"
  },
  {
    "text": "including like sdxl which are run on our",
    "start": "894920",
    "end": "897279"
  },
  {
    "text": "platform uh the model s for function",
    "start": "897279",
    "end": "899800"
  },
  {
    "text": "Callin is actually open source uh it's",
    "start": "899800",
    "end": "902160"
  },
  {
    "text": "on higen phas I mean you can of course",
    "start": "902160",
    "end": "904040"
  },
  {
    "text": "call it on uh at fireworks with for",
    "start": "904040",
    "end": "906199"
  },
  {
    "text": "optimal speeds but you can also uh run",
    "start": "906199",
    "end": "908279"
  },
  {
    "text": "it locally if you want it uses a bunch",
    "start": "908279",
    "end": "910759"
  },
  {
    "text": "of uh you know functionality on our",
    "start": "910759",
    "end": "912720"
  },
  {
    "text": "platform uh for example like structure",
    "start": "912720",
    "end": "914560"
  },
  {
    "text": "generation uh with like with Json model",
    "start": "914560",
    "end": "917639"
  },
  {
    "text": "grammar mode which I think was similar",
    "start": "917639",
    "end": "919399"
  },
  {
    "text": "to some of the previous talks from like",
    "start": "919399",
    "end": "921279"
  },
  {
    "text": "outline guys which we were talking here",
    "start": "921279",
    "end": "924120"
  },
  {
    "text": "yesterday uh yeah so finally try try it",
    "start": "924120",
    "end": "926560"
  },
  {
    "text": "out and generally like how to get",
    "start": "926560",
    "end": "929199"
  },
  {
    "text": "started in fireworks so if you had head",
    "start": "929199",
    "end": "931240"
  },
  {
    "text": "out of fireworks a such models you'll",
    "start": "931240",
    "end": "933360"
  },
  {
    "text": "you'll find a lot of uh open open source",
    "start": "933360",
    "end": "936800"
  },
  {
    "text": "open wte models which I mentioned about",
    "start": "936800",
    "end": "938360"
  },
  {
    "text": "they're available in the playground in",
    "start": "938360",
    "end": "940639"
  },
  {
    "text": "terms of product offering uh we have",
    "start": "940639",
    "end": "942399"
  },
  {
    "text": "this kind of range which can take you",
    "start": "942399",
    "end": "944279"
  },
  {
    "text": "from early prototyping all the way to",
    "start": "944279",
    "end": "946319"
  },
  {
    "text": "Enterprise scale so you can start with",
    "start": "946319",
    "end": "948040"
  },
  {
    "text": "serverless inference which is you know",
    "start": "948040",
    "end": "949480"
  },
  {
    "text": "not different from uh getting to open",
    "start": "949480",
    "end": "952440"
  },
  {
    "text": "API open air playground or something",
    "start": "952440",
    "end": "954240"
  },
  {
    "text": "where you pay per token uh it's a Conant",
    "start": "954240",
    "end": "957240"
  },
  {
    "text": "price you don't need to worry about like",
    "start": "957240",
    "end": "959079"
  },
  {
    "text": "Hardware settings or anything as I",
    "start": "959079",
    "end": "960839"
  },
  {
    "text": "mentioned you can still do fine tune in",
    "start": "960839",
    "end": "962560"
  },
  {
    "text": "so you can you can do host at fine tun",
    "start": "962560",
    "end": "964440"
  },
  {
    "text": "our platform you can bring your own lur",
    "start": "964440",
    "end": "966160"
  },
  {
    "text": "adapter and still serve with several L",
    "start": "966160",
    "end": "968240"
  },
  {
    "text": "as you kind of graduate like maybe like",
    "start": "968240",
    "end": "969839"
  },
  {
    "text": "a startup and you graduate to uh more",
    "start": "969839",
    "end": "972319"
  },
  {
    "text": "production scale uh you might want to go",
    "start": "972319",
    "end": "974360"
  },
  {
    "text": "to on demand where where it's more like",
    "start": "974360",
    "end": "976040"
  },
  {
    "text": "dedicated Hardware with more settings",
    "start": "976040",
    "end": "978120"
  },
  {
    "text": "and modifications uh for your use case",
    "start": "978120",
    "end": "980800"
  },
  {
    "text": "uh you can Brint your own custom model f",
    "start": "980800",
    "end": "982680"
  },
  {
    "text": "tune from scratch or do it on our",
    "start": "982680",
    "end": "984120"
  },
  {
    "text": "platform and finally you kind of if you",
    "start": "984120",
    "end": "986399"
  },
  {
    "text": "scale up uh to bigger volume and want to",
    "start": "986399",
    "end": "989440"
  },
  {
    "text": "go to enter enter Enterprise level where",
    "start": "989440",
    "end": "992240"
  },
  {
    "text": "it's kind discounted longterm longterm",
    "start": "992240",
    "end": "994839"
  },
  {
    "text": "contracts and we also will help you to",
    "start": "994839",
    "end": "996560"
  },
  {
    "text": "kind of personalize Hardware set up and",
    "start": "996560",
    "end": "998199"
  },
  {
    "text": "do some of those tune in for performance",
    "start": "998199",
    "end": "1000639"
  },
  {
    "text": "which I which I talked about earlier and",
    "start": "1000639",
    "end": "1003720"
  },
  {
    "text": "in terms of these cases I mean we're",
    "start": "1003720",
    "end": "1005319"
  },
  {
    "text": "running production for uh for many many",
    "start": "1005319",
    "end": "1008040"
  },
  {
    "text": "companies ranging from small startups to",
    "start": "1008040",
    "end": "1009759"
  },
  {
    "text": "Big Enterprises we're serving like last",
    "start": "1009759",
    "end": "1012319"
  },
  {
    "text": "time I checked like more than 150",
    "start": "1012319",
    "end": "1013600"
  },
  {
    "text": "billion tokens per day so you know",
    "start": "1013600",
    "end": "1015720"
  },
  {
    "text": "companies like quora built chat Bots",
    "start": "1015720",
    "end": "1018319"
  },
  {
    "text": "like Po",
    "start": "1018319",
    "end": "1019399"
  },
  {
    "text": "uh sour draft and cursor which I think I",
    "start": "1019399",
    "end": "1021720"
  },
  {
    "text": "think cursor had a talk here yesterday",
    "start": "1021720",
    "end": "1023680"
  },
  {
    "text": "they use us for like some of the code",
    "start": "1023680",
    "end": "1025120"
  },
  {
    "text": "assistant functionality and their like",
    "start": "1025120",
    "end": "1026600"
  },
  {
    "text": "latency is really important uh as you",
    "start": "1026600",
    "end": "1028678"
  },
  {
    "text": "can imagine you know Fox like upstage",
    "start": "1028679",
    "end": "1031000"
  },
  {
    "text": "liner building like different assistants",
    "start": "1031000",
    "end": "1033520"
  },
  {
    "text": "and agents uh on top of that so uh we're",
    "start": "1033520",
    "end": "1037120"
  },
  {
    "text": "definitely production ready go try try",
    "start": "1037120",
    "end": "1039079"
  },
  {
    "text": "it out uh finally we care a lot about",
    "start": "1039079",
    "end": "1041678"
  },
  {
    "text": "developers you uh you guys um so",
    "start": "1041679",
    "end": "1044520"
  },
  {
    "text": "actually this is external numbers from",
    "start": "1044520",
    "end": "1047240"
  },
  {
    "text": "uh like last year BL chain state of",
    "start": "1047240",
    "end": "1049120"
  },
  {
    "text": "stuff where turns out we are one of the",
    "start": "1049120",
    "end": "1051679"
  },
  {
    "text": "like after Hing pH the most popular",
    "start": "1051679",
    "end": "1054000"
  },
  {
    "text": "platform for where people pull models",
    "start": "1054000",
    "end": "1055600"
  },
  {
    "text": "which is great is was very nice to uh",
    "start": "1055600",
    "end": "1057840"
  },
  {
    "text": "nice to hear and again for like for",
    "start": "1057840",
    "end": "1059919"
  },
  {
    "text": "getting started just uh you know head",
    "start": "1059919",
    "end": "1062600"
  },
  {
    "text": "out to head out to our website you can",
    "start": "1062600",
    "end": "1065440"
  },
  {
    "text": "go in the go play in the playground uh",
    "start": "1065440",
    "end": "1067600"
  },
  {
    "text": "right away so for example you can run",
    "start": "1067600",
    "end": "1069440"
  },
  {
    "text": "you know Llama Or GMA or whatever at the",
    "start": "1069440",
    "end": "1071880"
  },
  {
    "text": "at the top speeds um and kind of go",
    "start": "1071880",
    "end": "1074960"
  },
  {
    "text": "start building from there I'm really",
    "start": "1074960",
    "end": "1076320"
  },
  {
    "text": "excited to see what you can build with",
    "start": "1076320",
    "end": "1077960"
  },
  {
    "text": "open models of Fire function or some",
    "start": "1077960",
    "end": "1080159"
  },
  {
    "text": "stuff which you can uh which you can",
    "start": "1080159",
    "end": "1082039"
  },
  {
    "text": "fune on on your own and yeah last point",
    "start": "1082039",
    "end": "1085320"
  },
  {
    "text": "we're as I mentioned open a API",
    "start": "1085320",
    "end": "1087320"
  },
  {
    "text": "compatible so you can still use you know",
    "start": "1087320",
    "end": "1089440"
  },
  {
    "text": "your your favorite tools uh the same",
    "start": "1089440",
    "end": "1091440"
  },
  {
    "text": "clients or you can use Frameworks like",
    "start": "1091440",
    "end": "1094120"
  },
  {
    "text": "Len chain or Lama index or Etc so yeah",
    "start": "1094120",
    "end": "1097120"
  },
  {
    "text": "really excited uh uh to kind of to be",
    "start": "1097120",
    "end": "1101039"
  },
  {
    "text": "here and talk tell a little bit about",
    "start": "1101039",
    "end": "1103400"
  },
  {
    "text": "open source uh open source models and",
    "start": "1103400",
    "end": "1105880"
  },
  {
    "text": "how we had fireworks uh focusing on",
    "start": "1105880",
    "end": "1107880"
  },
  {
    "text": "productionizing that and scaling it up",
    "start": "1107880",
    "end": "1110600"
  },
  {
    "text": "uh go try it out and you can also find",
    "start": "1110600",
    "end": "1112360"
  },
  {
    "text": "us at the Boost uh at the Expo thank you",
    "start": "1112360",
    "end": "1117880"
  },
  {
    "text": "[Music]",
    "start": "1119250",
    "end": "1135849"
  }
]
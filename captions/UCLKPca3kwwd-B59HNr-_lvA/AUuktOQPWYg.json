[
  {
    "text": "[Music]",
    "start": "350",
    "end": "13799"
  },
  {
    "text": "hi everyone I'm uh very excited to be",
    "start": "13799",
    "end": "16080"
  },
  {
    "text": "here um I am very um happy that there is",
    "start": "16080",
    "end": "20960"
  },
  {
    "text": "an open models track um so I'm going to",
    "start": "20960",
    "end": "23560"
  },
  {
    "text": "talk about the um open models of mral AI",
    "start": "23560",
    "end": "28320"
  },
  {
    "text": "and uh go a little bit deeper into why",
    "start": "28320",
    "end": "31679"
  },
  {
    "text": "we do open source and how we do open",
    "start": "31679",
    "end": "34680"
  },
  {
    "text": "source so first of all uh Mr Alia we uh",
    "start": "34680",
    "end": "38200"
  },
  {
    "text": "started last June about one year ago uh",
    "start": "38200",
    "end": "41480"
  },
  {
    "text": "we released our first open model M 7B in",
    "start": "41480",
    "end": "44399"
  },
  {
    "text": "September",
    "start": "44399",
    "end": "45360"
  },
  {
    "text": "23 um and then after that in December we",
    "start": "45360",
    "end": "48160"
  },
  {
    "text": "released our first mixture of experts",
    "start": "48160",
    "end": "51000"
  },
  {
    "text": "open model 8X",
    "start": "51000",
    "end": "52440"
  },
  {
    "text": "7B uh and along with that we released",
    "start": "52440",
    "end": "55199"
  },
  {
    "text": "our platform with model apis uh and also",
    "start": "55199",
    "end": "59559"
  },
  {
    "text": "commercial models mral medium and M",
    "start": "59559",
    "end": "62519"
  },
  {
    "text": "embed and then uh earlier this year in",
    "start": "62519",
    "end": "65320"
  },
  {
    "text": "February we released M large which is",
    "start": "65320",
    "end": "66960"
  },
  {
    "text": "our Flagship",
    "start": "66960",
    "end": "68560"
  },
  {
    "text": "model uh which has the best uh inclass",
    "start": "68560",
    "end": "72439"
  },
  {
    "text": "reasoning and uh math",
    "start": "72439",
    "end": "76600"
  },
  {
    "text": "ability and also uh in April we released",
    "start": "76600",
    "end": "80159"
  },
  {
    "text": "a new open model 8X",
    "start": "80159",
    "end": "82600"
  },
  {
    "text": "22b and then uh very recently in June we",
    "start": "82600",
    "end": "85479"
  },
  {
    "text": "released a code specific model called C",
    "start": "85479",
    "end": "88400"
  },
  {
    "text": "22b",
    "start": "88400",
    "end": "90240"
  },
  {
    "text": "and uh it's also",
    "start": "90240",
    "end": "92079"
  },
  {
    "text": "available uh in the chat interface that",
    "start": "92079",
    "end": "94399"
  },
  {
    "text": "we built uh along with Mr Large and it's",
    "start": "94399",
    "end": "98280"
  },
  {
    "text": "uh free to",
    "start": "98280",
    "end": "100840"
  },
  {
    "text": "use um so our mission um is to bring",
    "start": "101200",
    "end": "107159"
  },
  {
    "text": "Frontier AI in everyone's hands and we",
    "start": "107159",
    "end": "110719"
  },
  {
    "text": "specifically focus on building Cutting",
    "start": "110719",
    "end": "113159"
  },
  {
    "text": "Edge AI for",
    "start": "113159",
    "end": "115000"
  },
  {
    "text": "developers and we have certain",
    "start": "115000",
    "end": "117680"
  },
  {
    "text": "principles behind how we we go about",
    "start": "117680",
    "end": "121200"
  },
  {
    "text": "training models and releasing them so",
    "start": "121200",
    "end": "123079"
  },
  {
    "text": "the first is openness we want to train",
    "start": "123079",
    "end": "127000"
  },
  {
    "text": "Best in Class open models and uh release",
    "start": "127000",
    "end": "130599"
  },
  {
    "text": "it for uh the open source Community we",
    "start": "130599",
    "end": "134040"
  },
  {
    "text": "want our models to be portable uh all",
    "start": "134040",
    "end": "136840"
  },
  {
    "text": "our models are available on Azure AWS",
    "start": "136840",
    "end": "139640"
  },
  {
    "text": "gcp virtual private cloud and also they",
    "start": "139640",
    "end": "142400"
  },
  {
    "text": "can be deployed deployed on Prem which",
    "start": "142400",
    "end": "144640"
  },
  {
    "text": "means uh you can uh license the model",
    "start": "144640",
    "end": "148400"
  },
  {
    "text": "weights and use use it on your own",
    "start": "148400",
    "end": "151040"
  },
  {
    "text": "servers uh with full control over",
    "start": "151040",
    "end": "153400"
  },
  {
    "text": "security and privacy of your",
    "start": "153400",
    "end": "155599"
  },
  {
    "text": "data uh we try to optimize for the",
    "start": "155599",
    "end": "158400"
  },
  {
    "text": "performance to speed ratio uh our models",
    "start": "158400",
    "end": "161640"
  },
  {
    "text": "are particularly good at getting the",
    "start": "161640",
    "end": "163720"
  },
  {
    "text": "best performance out of a particular",
    "start": "163720",
    "end": "166480"
  },
  {
    "text": "size and um we want our models to be",
    "start": "166480",
    "end": "171800"
  },
  {
    "text": "customizable uh we are building our",
    "start": "171800",
    "end": "174000"
  },
  {
    "text": "platform to with all the libraries and",
    "start": "174000",
    "end": "176720"
  },
  {
    "text": "tools to customize our models uh",
    "start": "176720",
    "end": "178920"
  },
  {
    "text": "depending on your appli application uh",
    "start": "178920",
    "end": "180959"
  },
  {
    "text": "we recently released the mile fine tune",
    "start": "180959",
    "end": "183599"
  },
  {
    "text": "open source Library which can be used to",
    "start": "183599",
    "end": "185760"
  },
  {
    "text": "F tune any of our open source models and",
    "start": "185760",
    "end": "188400"
  },
  {
    "text": "also uh we have a fine-tuning API on our",
    "start": "188400",
    "end": "191640"
  },
  {
    "text": "uh",
    "start": "191640",
    "end": "192799"
  },
  {
    "text": "platform and before that we also",
    "start": "192799",
    "end": "194680"
  },
  {
    "text": "released M inference which is the",
    "start": "194680",
    "end": "196080"
  },
  {
    "text": "inflence library uh again open",
    "start": "196080",
    "end": "198840"
  },
  {
    "text": "source uh so I talked about these three",
    "start": "198840",
    "end": "201599"
  },
  {
    "text": "models that we have open um sourced in",
    "start": "201599",
    "end": "205159"
  },
  {
    "text": "the last one",
    "start": "205159",
    "end": "206840"
  },
  {
    "text": "year the first model is a d Transformer",
    "start": "206840",
    "end": "210519"
  },
  {
    "text": "model uh it was the first Model first 7B",
    "start": "210519",
    "end": "213959"
  },
  {
    "text": "model to achieve 60 on mmu and we saw",
    "start": "213959",
    "end": "217599"
  },
  {
    "text": "that the 60 MML is like a bare minimum",
    "start": "217599",
    "end": "221200"
  },
  {
    "text": "where the models become useful and this",
    "start": "221200",
    "end": "223599"
  },
  {
    "text": "was the first 7B model to achieve",
    "start": "223599",
    "end": "226200"
  },
  {
    "text": "this and people have uh you people have",
    "start": "226200",
    "end": "230280"
  },
  {
    "text": "been using this model for many many",
    "start": "230280",
    "end": "231840"
  },
  {
    "text": "different applications and particularly",
    "start": "231840",
    "end": "233879"
  },
  {
    "text": "we have seen that this model can be",
    "start": "233879",
    "end": "235400"
  },
  {
    "text": "deployed on laptops and phones uh and uh",
    "start": "235400",
    "end": "238840"
  },
  {
    "text": "still get reasonable speed uh on on",
    "start": "238840",
    "end": "242840"
  },
  {
    "text": "device uh we released the first um our",
    "start": "242840",
    "end": "245920"
  },
  {
    "text": "first Spar mixture of experts model in",
    "start": "245920",
    "end": "248200"
  },
  {
    "text": "December 8X 7B it's based on the uh",
    "start": "248200",
    "end": "252920"
  },
  {
    "text": "mixture of experts architecture uh which",
    "start": "252920",
    "end": "255480"
  },
  {
    "text": "basically allows us",
    "start": "255480",
    "end": "257199"
  },
  {
    "text": "to push the performance of a model while",
    "start": "257199",
    "end": "260799"
  },
  {
    "text": "keeping the infrance budget in check the",
    "start": "260799",
    "end": "262840"
  },
  {
    "text": "idea here is we have higher number of",
    "start": "262840",
    "end": "265479"
  },
  {
    "text": "total parameters in the model which",
    "start": "265479",
    "end": "266960"
  },
  {
    "text": "allows the model to uh still have the",
    "start": "266960",
    "end": "269080"
  },
  {
    "text": "knowledge",
    "start": "269080",
    "end": "270240"
  },
  {
    "text": "uh stored in the model weights but at",
    "start": "270240",
    "end": "272160"
  },
  {
    "text": "the same time we use only a small subset",
    "start": "272160",
    "end": "274680"
  },
  {
    "text": "of the parameters for every token which",
    "start": "274680",
    "end": "277320"
  },
  {
    "text": "makes it really fast and cost efficient",
    "start": "277320",
    "end": "279639"
  },
  {
    "text": "at inference",
    "start": "279639",
    "end": "281240"
  },
  {
    "text": "time and then we released a bigger",
    "start": "281240",
    "end": "283600"
  },
  {
    "text": "version of this Spar mixture of experts",
    "start": "283600",
    "end": "285479"
  },
  {
    "text": "architecture ax22 be in April uh it has",
    "start": "285479",
    "end": "288160"
  },
  {
    "text": "even better performance higher uh",
    "start": "288160",
    "end": "290919"
  },
  {
    "text": "context window and also it's",
    "start": "290919",
    "end": "293759"
  },
  {
    "text": "multilingual uh it supports English",
    "start": "293759",
    "end": "295919"
  },
  {
    "text": "French Italian German Spanish and also U",
    "start": "295919",
    "end": "299360"
  },
  {
    "text": "many other",
    "start": "299360",
    "end": "301960"
  },
  {
    "text": "languages um so a lot of people ask me",
    "start": "302160",
    "end": "306800"
  },
  {
    "text": "if you open source your models how do",
    "start": "306800",
    "end": "309120"
  },
  {
    "text": "you make money and I think this is a",
    "start": "309120",
    "end": "311160"
  },
  {
    "text": "common misconception that people have",
    "start": "311160",
    "end": "313680"
  },
  {
    "text": "that open source is",
    "start": "313680",
    "end": "316479"
  },
  {
    "text": "somewhat uh competitive with profit",
    "start": "316479",
    "end": "320039"
  },
  {
    "text": "that's actually not the case we see open",
    "start": "320039",
    "end": "322520"
  },
  {
    "text": "source",
    "start": "322520",
    "end": "323720"
  },
  {
    "text": "as",
    "start": "323720",
    "end": "325319"
  },
  {
    "text": "uh uh something that is goes hand inand",
    "start": "325319",
    "end": "328639"
  },
  {
    "text": "with profit it doesn't necessarily have",
    "start": "328639",
    "end": "331199"
  },
  {
    "text": "to be comparative it can be uh",
    "start": "331199",
    "end": "333960"
  },
  {
    "text": "complimentary and uh we want to be in",
    "start": "333960",
    "end": "337160"
  },
  {
    "text": "this quadrant where we can open source",
    "start": "337160",
    "end": "339560"
  },
  {
    "text": "our models and still have long-term",
    "start": "339560",
    "end": "341720"
  },
  {
    "text": "business value with the",
    "start": "341720",
    "end": "343880"
  },
  {
    "text": "models um so why do we open source so",
    "start": "343880",
    "end": "346560"
  },
  {
    "text": "the first reason is it uh serves as a",
    "start": "346560",
    "end": "348720"
  },
  {
    "text": "very good branding and marketing tool",
    "start": "348720",
    "end": "350160"
  },
  {
    "text": "for us um so we believe in open source",
    "start": "350160",
    "end": "352960"
  },
  {
    "text": "and open science and we want to",
    "start": "352960",
    "end": "354919"
  },
  {
    "text": "contribute uh to the community but it's",
    "start": "354919",
    "end": "358120"
  },
  {
    "text": "not a a oneway thing uh we are also",
    "start": "358120",
    "end": "362600"
  },
  {
    "text": "benefiting from open source just as the",
    "start": "362600",
    "end": "364360"
  },
  {
    "text": "community is benefiting from our models",
    "start": "364360",
    "end": "366520"
  },
  {
    "text": "so it helps us doing doing uh a lot of",
    "start": "366520",
    "end": "368800"
  },
  {
    "text": "branding and",
    "start": "368800",
    "end": "370360"
  },
  {
    "text": "marketing uh a lot of people like our",
    "start": "370360",
    "end": "372520"
  },
  {
    "text": "models they tell other people that our",
    "start": "372520",
    "end": "374319"
  },
  {
    "text": "models are good the model performance",
    "start": "374319",
    "end": "376360"
  },
  {
    "text": "speaks for itself we do not have a",
    "start": "376360",
    "end": "378919"
  },
  {
    "text": "marketing team in housee and uh just the",
    "start": "378919",
    "end": "382080"
  },
  {
    "text": "open sourcing the models allows us to",
    "start": "382080",
    "end": "384639"
  },
  {
    "text": "create awareness about our",
    "start": "384639",
    "end": "387759"
  },
  {
    "text": "products it also helps in customer",
    "start": "387759",
    "end": "390599"
  },
  {
    "text": "acquisition if people try out our open",
    "start": "390599",
    "end": "393120"
  },
  {
    "text": "source models and they really like it",
    "start": "393120",
    "end": "395120"
  },
  {
    "text": "they come to us for an upgrade to",
    "start": "395120",
    "end": "397199"
  },
  {
    "text": "propriety models and uh they pay for the",
    "start": "397199",
    "end": "400639"
  },
  {
    "text": "upgrade and it also helps in",
    "start": "400639",
    "end": "404000"
  },
  {
    "text": "customization and",
    "start": "404000",
    "end": "406520"
  },
  {
    "text": "portability uh when whenever uh for",
    "start": "406520",
    "end": "409759"
  },
  {
    "text": "example the 7B model people can try it",
    "start": "409759",
    "end": "412800"
  },
  {
    "text": "uh to to try to run it on laptops and",
    "start": "412800",
    "end": "415039"
  },
  {
    "text": "phones and this is the kind of stuff we",
    "start": "415039",
    "end": "417599"
  },
  {
    "text": "benefit from because we don't",
    "start": "417599",
    "end": "419639"
  },
  {
    "text": "necessarily have to do this out of the",
    "start": "419639",
    "end": "421919"
  },
  {
    "text": "box but the community Works around our",
    "start": "421919",
    "end": "423440"
  },
  {
    "text": "models and we learn from the community",
    "start": "423440",
    "end": "425879"
  },
  {
    "text": "how our models can be customized or uh",
    "start": "425879",
    "end": "428280"
  },
  {
    "text": "deployed in new",
    "start": "428280",
    "end": "430199"
  },
  {
    "text": "settings so how are um these open source",
    "start": "430199",
    "end": "433240"
  },
  {
    "text": "models trained so I I'll give you a very",
    "start": "433240",
    "end": "436440"
  },
  {
    "text": "high uh level overview of the different",
    "start": "436440",
    "end": "439440"
  },
  {
    "text": "stages of llm training and typically",
    "start": "439440",
    "end": "442000"
  },
  {
    "text": "llms are trained in three stages",
    "start": "442000",
    "end": "444759"
  },
  {
    "text": "pre-training instruction tuning and",
    "start": "444759",
    "end": "446520"
  },
  {
    "text": "learning from Human",
    "start": "446520",
    "end": "448280"
  },
  {
    "text": "feedback so so the idea behind",
    "start": "448280",
    "end": "450919"
  },
  {
    "text": "pre-training is very simple you take a",
    "start": "450919",
    "end": "452599"
  },
  {
    "text": "piece of",
    "start": "452599",
    "end": "453680"
  },
  {
    "text": "text and",
    "start": "453680",
    "end": "455720"
  },
  {
    "text": "you",
    "start": "455720",
    "end": "457240"
  },
  {
    "text": "pass uh word by word or token by token",
    "start": "457240",
    "end": "460960"
  },
  {
    "text": "through the large language model and ask",
    "start": "460960",
    "end": "463759"
  },
  {
    "text": "the model to predict the next",
    "start": "463759",
    "end": "466759"
  },
  {
    "text": "token um so the idea itself is very",
    "start": "466759",
    "end": "469599"
  },
  {
    "text": "simple each uh the task is the next",
    "start": "469599",
    "end": "472280"
  },
  {
    "text": "token prediction each token is roughly",
    "start": "472280",
    "end": "474720"
  },
  {
    "text": "75 word the vocabulary size is roughly",
    "start": "474720",
    "end": "477479"
  },
  {
    "text": "tens of thousands of tokens or sometimes",
    "start": "477479",
    "end": "479759"
  },
  {
    "text": "hundreds of thousands and each token is",
    "start": "479759",
    "end": "482560"
  },
  {
    "text": "basically represented as an integer and",
    "start": "482560",
    "end": "484400"
  },
  {
    "text": "it has an embedding associated with it",
    "start": "484400",
    "end": "486440"
  },
  {
    "text": "and so the task of the model is to take",
    "start": "486440",
    "end": "488560"
  },
  {
    "text": "in a sequence of embeddings or tokens",
    "start": "488560",
    "end": "491080"
  },
  {
    "text": "and predict the next",
    "start": "491080",
    "end": "493360"
  },
  {
    "text": "token uh although the concept is very",
    "start": "493360",
    "end": "495639"
  },
  {
    "text": "simple in practice it's uh actually very",
    "start": "495639",
    "end": "499039"
  },
  {
    "text": "hard uh why is it hard because it",
    "start": "499039",
    "end": "501720"
  },
  {
    "text": "requires a lot of effort in building the",
    "start": "501720",
    "end": "504560"
  },
  {
    "text": "data sets the data sets are huge they",
    "start": "504560",
    "end": "506680"
  },
  {
    "text": "are order of trillions of tokens tens of",
    "start": "506680",
    "end": "509039"
  },
  {
    "text": "trillions of tokens uh that requires",
    "start": "509039",
    "end": "511960"
  },
  {
    "text": "pre-processing cleaning D duplication",
    "start": "511960",
    "end": "515039"
  },
  {
    "text": "curation and there's again a common",
    "start": "515039",
    "end": "518599"
  },
  {
    "text": "belief that more data leads to better",
    "start": "518599",
    "end": "520479"
  },
  {
    "text": "performance but that's not not",
    "start": "520479",
    "end": "521760"
  },
  {
    "text": "necessarily the",
    "start": "521760",
    "end": "523200"
  },
  {
    "text": "case uh if you have noise in your data",
    "start": "523200",
    "end": "525760"
  },
  {
    "text": "that can actually hurt the model",
    "start": "525760",
    "end": "527959"
  },
  {
    "text": "performance it also requires a lot of",
    "start": "527959",
    "end": "531240"
  },
  {
    "text": "investment uh these models are huge you",
    "start": "531240",
    "end": "533959"
  },
  {
    "text": "know can go up to hundreds or even",
    "start": "533959",
    "end": "536000"
  },
  {
    "text": "hundreds of billions or even trillions",
    "start": "536000",
    "end": "537360"
  },
  {
    "text": "of parameters uh each",
    "start": "537360",
    "end": "540000"
  },
  {
    "text": "model takes tens to hundreds of millions",
    "start": "540000",
    "end": "541959"
  },
  {
    "text": "of dollars to",
    "start": "541959",
    "end": "543959"
  },
  {
    "text": "train and the hardest part is you don't",
    "start": "543959",
    "end": "547600"
  },
  {
    "text": "get multiple chances to train the model",
    "start": "547600",
    "end": "550680"
  },
  {
    "text": "uh the because it's so expensive if",
    "start": "550680",
    "end": "554519"
  },
  {
    "text": "something grows wrong in your training",
    "start": "554519",
    "end": "556720"
  },
  {
    "text": "uh",
    "start": "556720",
    "end": "557519"
  },
  {
    "text": "it's uh very difficult to get the",
    "start": "557519",
    "end": "560519"
  },
  {
    "text": "investment to do another training run uh",
    "start": "560519",
    "end": "563800"
  },
  {
    "text": "because uh typically for small companies",
    "start": "563800",
    "end": "566440"
  },
  {
    "text": "you don't get that kind of budget if you",
    "start": "566440",
    "end": "568680"
  },
  {
    "text": "do a model run and it's not successful",
    "start": "568680",
    "end": "571800"
  },
  {
    "text": "um it becomes harder to get the funding",
    "start": "571800",
    "end": "573680"
  },
  {
    "text": "for the next",
    "start": "573680",
    "end": "574720"
  },
  {
    "text": "run",
    "start": "574720",
    "end": "576880"
  },
  {
    "text": "um and this is hard because the best",
    "start": "576880",
    "end": "579800"
  },
  {
    "text": "hyperparameters for a smaller model",
    "start": "579800",
    "end": "581680"
  },
  {
    "text": "might not be the best for a larger",
    "start": "581680",
    "end": "585440"
  },
  {
    "text": "model uh here I'm showing you some",
    "start": "585440",
    "end": "588560"
  },
  {
    "text": "hyperparameters for llama one model",
    "start": "588560",
    "end": "591240"
  },
  {
    "text": "family sizes and you might",
    "start": "591240",
    "end": "594399"
  },
  {
    "text": "ask um why",
    "start": "594399",
    "end": "597320"
  },
  {
    "text": "are the number of layers 0 and not 82 in",
    "start": "597320",
    "end": "600920"
  },
  {
    "text": "Lama",
    "start": "600920",
    "end": "602600"
  },
  {
    "text": "65b and the answer is we don't know uh",
    "start": "602600",
    "end": "606800"
  },
  {
    "text": "there's a lot",
    "start": "606800",
    "end": "608160"
  },
  {
    "text": "of things that have been uh decided by",
    "start": "608160",
    "end": "611920"
  },
  {
    "text": "intuition and it's not exact science uh",
    "start": "611920",
    "end": "615360"
  },
  {
    "text": "so you need a lot of experience and",
    "start": "615360",
    "end": "618200"
  },
  {
    "text": "intuition working with these models to",
    "start": "618200",
    "end": "620320"
  },
  {
    "text": "come up with things that are very likely",
    "start": "620320",
    "end": "622839"
  },
  {
    "text": "to work but uh we don't uh we still not",
    "start": "622839",
    "end": "628320"
  },
  {
    "text": "very mature with the science of what is",
    "start": "628320",
    "end": "630560"
  },
  {
    "text": "the best way to print the model or",
    "start": "630560",
    "end": "632839"
  },
  {
    "text": "what's the best architecture what's the",
    "start": "632839",
    "end": "634160"
  },
  {
    "text": "best data set",
    "start": "634160",
    "end": "636519"
  },
  {
    "text": "mixture so uh can we use this",
    "start": "636519",
    "end": "638680"
  },
  {
    "text": "pre-trained model um so let's say if you",
    "start": "638680",
    "end": "641639"
  },
  {
    "text": "want to use this pre-train model and uh",
    "start": "641639",
    "end": "643560"
  },
  {
    "text": "ask it to write a python function to",
    "start": "643560",
    "end": "645279"
  },
  {
    "text": "find whether the input number is prime",
    "start": "645279",
    "end": "647200"
  },
  {
    "text": "or not and the model might give you a",
    "start": "647200",
    "end": "649880"
  },
  {
    "text": "response like this continues the text",
    "start": "649880",
    "end": "653279"
  },
  {
    "text": "gives an example and like describes the",
    "start": "653279",
    "end": "655279"
  },
  {
    "text": "approach but it might not give you the",
    "start": "655279",
    "end": "656680"
  },
  {
    "text": "code and this is because the model is",
    "start": "656680",
    "end": "660040"
  },
  {
    "text": "trained to do this it's trained to",
    "start": "660040",
    "end": "661560"
  },
  {
    "text": "predict the next token so it predicts",
    "start": "661560",
    "end": "663560"
  },
  {
    "text": "the most likely token from the text Data",
    "start": "663560",
    "end": "666760"
  },
  {
    "text": "it's been trained",
    "start": "666760",
    "end": "668399"
  },
  {
    "text": "on but there is a way to trick the model",
    "start": "668399",
    "end": "672160"
  },
  {
    "text": "if",
    "start": "672160",
    "end": "673040"
  },
  {
    "text": "you give this input like as a python",
    "start": "673040",
    "end": "676079"
  },
  {
    "text": "function definition and a doc string uh",
    "start": "676079",
    "end": "680120"
  },
  {
    "text": "to to get the same function the model",
    "start": "680120",
    "end": "682399"
  },
  {
    "text": "actually produces the",
    "start": "682399",
    "end": "683680"
  },
  {
    "text": "code and so this shows you that model",
    "start": "683680",
    "end": "686639"
  },
  {
    "text": "actually knows the answer but it is not",
    "start": "686639",
    "end": "688839"
  },
  {
    "text": "aligned with human preferences it's not",
    "start": "688839",
    "end": "691040"
  },
  {
    "text": "trained to interact with humans in the",
    "start": "691040",
    "end": "693639"
  },
  {
    "text": "way humans want to and this is why we",
    "start": "693639",
    "end": "696399"
  },
  {
    "text": "need the next two",
    "start": "696399",
    "end": "697920"
  },
  {
    "text": "stages um so in the instruction tuning",
    "start": "697920",
    "end": "700839"
  },
  {
    "text": "stage instead of just uh string of text",
    "start": "700839",
    "end": "705920"
  },
  {
    "text": "we have prompt response pairs so here we",
    "start": "705920",
    "end": "708240"
  },
  {
    "text": "are giving the prompt but in the way",
    "start": "708240",
    "end": "711440"
  },
  {
    "text": "humans want to interact with the model",
    "start": "711440",
    "end": "713279"
  },
  {
    "text": "so for example this prompt to write a",
    "start": "713279",
    "end": "715519"
  },
  {
    "text": "python function and the response is",
    "start": "715519",
    "end": "717279"
  },
  {
    "text": "directly the code because that's what",
    "start": "717279",
    "end": "718519"
  },
  {
    "text": "humans want as the",
    "start": "718519",
    "end": "720320"
  },
  {
    "text": "response and",
    "start": "720320",
    "end": "722480"
  },
  {
    "text": "the technique is very simple again we",
    "start": "722480",
    "end": "725200"
  },
  {
    "text": "are doing next token prediction but the",
    "start": "725200",
    "end": "726639"
  },
  {
    "text": "only difference is we are going to mask",
    "start": "726639",
    "end": "730279"
  },
  {
    "text": "the prompt itself we are going to do",
    "start": "730279",
    "end": "731639"
  },
  {
    "text": "prediction only for the",
    "start": "731639",
    "end": "734600"
  },
  {
    "text": "response um so the data set is paired",
    "start": "735279",
    "end": "738160"
  },
  {
    "text": "prompt response pairs we typically use",
    "start": "738160",
    "end": "740079"
  },
  {
    "text": "100 to hundreds of thousands of in",
    "start": "740079",
    "end": "742519"
  },
  {
    "text": "instructions uh the task is next to",
    "start": "742519",
    "end": "744680"
  },
  {
    "text": "prediction but just we mask the the",
    "start": "744680",
    "end": "748040"
  },
  {
    "text": "input instruction",
    "start": "748040",
    "end": "750440"
  },
  {
    "text": "uh it requires way less compute order of",
    "start": "750440",
    "end": "754560"
  },
  {
    "text": "100 100 gpus for a few hours or days is",
    "start": "754560",
    "end": "757279"
  },
  {
    "text": "typically sufficient to do instruction",
    "start": "757279",
    "end": "760199"
  },
  {
    "text": "finding and then the last steps is",
    "start": "760199",
    "end": "762199"
  },
  {
    "text": "learning from Human feedback and here",
    "start": "762199",
    "end": "763760"
  },
  {
    "text": "the idea is um that human preferences",
    "start": "763760",
    "end": "768160"
  },
  {
    "text": "are cheaper or easier to obtain than",
    "start": "768160",
    "end": "770880"
  },
  {
    "text": "full human annotation if I give you uh",
    "start": "770880",
    "end": "773360"
  },
  {
    "text": "prompt like this and two responses it's",
    "start": "773360",
    "end": "774959"
  },
  {
    "text": "much easier for a human to decide which",
    "start": "774959",
    "end": "777199"
  },
  {
    "text": "response is better than to write the",
    "start": "777199",
    "end": "778880"
  },
  {
    "text": "whole",
    "start": "778880",
    "end": "779639"
  },
  {
    "text": "response uh from scratch and so this",
    "start": "779639",
    "end": "783199"
  },
  {
    "text": "allows us to scale uh data faster and",
    "start": "783199",
    "end": "788160"
  },
  {
    "text": "there are two main techniques uh",
    "start": "788160",
    "end": "789800"
  },
  {
    "text": "learning from reinforcement learning",
    "start": "789800",
    "end": "792240"
  },
  {
    "text": "from Human feedback and direct",
    "start": "792240",
    "end": "793839"
  },
  {
    "text": "preference optimization uh where we use",
    "start": "793839",
    "end": "796600"
  },
  {
    "text": "this kind of preference data to find",
    "start": "796600",
    "end": "797959"
  },
  {
    "text": "tune the model uh",
    "start": "797959",
    "end": "800120"
  },
  {
    "text": "further so just to summarize these are",
    "start": "800120",
    "end": "802760"
  },
  {
    "text": "the three",
    "start": "802760",
    "end": "803920"
  },
  {
    "text": "stages um they have different orders of",
    "start": "803920",
    "end": "808480"
  },
  {
    "text": "data set and compute requirement and the",
    "start": "808480",
    "end": "810519"
  },
  {
    "text": "task is uh slightly different and all",
    "start": "810519",
    "end": "814000"
  },
  {
    "text": "the open source models we have have been",
    "start": "814000",
    "end": "815959"
  },
  {
    "text": "used I've been trained using these",
    "start": "815959",
    "end": "818880"
  },
  {
    "text": "techniques and so I won't go into the",
    "start": "818880",
    "end": "821079"
  },
  {
    "text": "details",
    "start": "821079",
    "end": "822120"
  },
  {
    "text": "of um the model architecture itself but",
    "start": "822120",
    "end": "826760"
  },
  {
    "text": "I'll show you the this nice graph of",
    "start": "826760",
    "end": "829600"
  },
  {
    "text": "performance to cost",
    "start": "829600",
    "end": "831320"
  },
  {
    "text": "ratio uh which kind of shows that uh we",
    "start": "831320",
    "end": "835639"
  },
  {
    "text": "really try to",
    "start": "835639",
    "end": "837000"
  },
  {
    "text": "optimize um this metric uh we try try to",
    "start": "837000",
    "end": "840720"
  },
  {
    "text": "get the best performance out of our",
    "start": "840720",
    "end": "842360"
  },
  {
    "text": "models of a particular",
    "start": "842360",
    "end": "844560"
  },
  {
    "text": "size so here on the x-axis we have the",
    "start": "844560",
    "end": "847199"
  },
  {
    "text": "active parameters which is directly",
    "start": "847199",
    "end": "848759"
  },
  {
    "text": "proportional to the cost of running",
    "start": "848759",
    "end": "850040"
  },
  {
    "text": "through the model and on the y- axis we",
    "start": "850040",
    "end": "852399"
  },
  {
    "text": "have a popular Benchmark mlu so we try",
    "start": "852399",
    "end": "855440"
  },
  {
    "text": "to be in the top left corner to get more",
    "start": "855440",
    "end": "858759"
  },
  {
    "text": "performance with a lower",
    "start": "858759",
    "end": "861720"
  },
  {
    "text": "cost um we recently released the codr",
    "start": "861720",
    "end": "865079"
  },
  {
    "text": "model codr 22b it's a dense Transformer",
    "start": "865079",
    "end": "867839"
  },
  {
    "text": "model train specif spefically for",
    "start": "867839",
    "end": "870360"
  },
  {
    "text": "code um and again we are trying to",
    "start": "870360",
    "end": "872759"
  },
  {
    "text": "optimize performance and speed it's",
    "start": "872759",
    "end": "874680"
  },
  {
    "text": "fluent in + programming languages and it",
    "start": "874680",
    "end": "878480"
  },
  {
    "text": "has both uh instruct and fill in the",
    "start": "878480",
    "end": "880839"
  },
  {
    "text": "middle mode which means that you can use",
    "start": "880839",
    "end": "882920"
  },
  {
    "text": "it for code completion uh in uh your",
    "start": "882920",
    "end": "886000"
  },
  {
    "text": "code editor just like gith up co-pilot",
    "start": "886000",
    "end": "888440"
  },
  {
    "text": "but also you can use it to ask questions",
    "start": "888440",
    "end": "890480"
  },
  {
    "text": "about the bugs or errors you're facing",
    "start": "890480",
    "end": "892560"
  },
  {
    "text": "just like you would put it in chat GPT",
    "start": "892560",
    "end": "896040"
  },
  {
    "text": "um so it outperforms Cod Lama 70b deep",
    "start": "896040",
    "end": "900199"
  },
  {
    "text": "deeps Cod 33b Lama 370b while being a",
    "start": "900199",
    "end": "903560"
  },
  {
    "text": "significantly smaller model so again we",
    "start": "903560",
    "end": "905639"
  },
  {
    "text": "are getting more performance out of a",
    "start": "905639",
    "end": "908040"
  },
  {
    "text": "model of a particular size and it also",
    "start": "908040",
    "end": "910759"
  },
  {
    "text": "has a longer context window than the",
    "start": "910759",
    "end": "913079"
  },
  {
    "text": "other open source code",
    "start": "913079",
    "end": "915880"
  },
  {
    "text": "models it is multilingual uh we trained",
    "start": "915880",
    "end": "918720"
  },
  {
    "text": "it with more than 80 programming",
    "start": "918720",
    "end": "920800"
  },
  {
    "text": "languages and",
    "start": "920800",
    "end": "923360"
  },
  {
    "text": "uh across all these different languages",
    "start": "923360",
    "end": "926360"
  },
  {
    "text": "tends to perform better than the other",
    "start": "926360",
    "end": "928440"
  },
  {
    "text": "models",
    "start": "928440",
    "end": "930240"
  },
  {
    "text": "so it's uh free to use on our chat",
    "start": "930240",
    "end": "932160"
  },
  {
    "text": "interface chat.",
    "start": "932160",
    "end": "933720"
  },
  {
    "text": "mist. uh we also have the API access",
    "start": "933720",
    "end": "937560"
  },
  {
    "text": "available on lab platform which is our",
    "start": "937560",
    "end": "940279"
  },
  {
    "text": "uh uh platform API endpoint and here uh",
    "start": "940279",
    "end": "945360"
  },
  {
    "text": "it's also free to use till I believe uh",
    "start": "945360",
    "end": "947839"
  },
  {
    "text": "end of",
    "start": "947839",
    "end": "948959"
  },
  {
    "text": "July we also have uh integration with vs",
    "start": "948959",
    "end": "952360"
  },
  {
    "text": "code and Jet brains so you can",
    "start": "952360",
    "end": "955199"
  },
  {
    "text": "download uh a plugin in vs code or jet",
    "start": "955199",
    "end": "958120"
  },
  {
    "text": "brains and use it as a coding assistant",
    "start": "958120",
    "end": "961000"
  },
  {
    "text": "for code",
    "start": "961000",
    "end": "962680"
  },
  {
    "text": "completion so",
    "start": "962680",
    "end": "966560"
  },
  {
    "text": "um in the end I would just discuss some",
    "start": "966759",
    "end": "969800"
  },
  {
    "text": "practical tips because these are some",
    "start": "969800",
    "end": "971360"
  },
  {
    "text": "commonly asked questions about how to",
    "start": "971360",
    "end": "973240"
  },
  {
    "text": "use open source models and when to use",
    "start": "973240",
    "end": "975920"
  },
  {
    "text": "open source versus when uh when to use",
    "start": "975920",
    "end": "978040"
  },
  {
    "text": "commercial models so uh if you have a",
    "start": "978040",
    "end": "981480"
  },
  {
    "text": "particular application in mind and you",
    "start": "981480",
    "end": "983399"
  },
  {
    "text": "want to try out commercial models you",
    "start": "983399",
    "end": "984959"
  },
  {
    "text": "could do things like prompt engineering",
    "start": "984959",
    "end": "987079"
  },
  {
    "text": "fot prompting Chain of Thought and you",
    "start": "987079",
    "end": "989279"
  },
  {
    "text": "could also do retrieval augmented",
    "start": "989279",
    "end": "991519"
  },
  {
    "text": "generation uh because commercial models",
    "start": "991519",
    "end": "993759"
  },
  {
    "text": "typically don't allow you to do fine",
    "start": "993759",
    "end": "996360"
  },
  {
    "text": "tuning uh but for open",
    "start": "996360",
    "end": "999319"
  },
  {
    "text": "models you can do task specific fine",
    "start": "999319",
    "end": "1001839"
  },
  {
    "text": "tuning as well you need a little bit of",
    "start": "1001839",
    "end": "1004120"
  },
  {
    "text": "data and compute for this uh but in the",
    "start": "1004120",
    "end": "1008040"
  },
  {
    "text": "end the choice is between how do you how",
    "start": "1008040",
    "end": "1011560"
  },
  {
    "text": "do you balance performance versus Cost",
    "start": "1011560",
    "end": "1013720"
  },
  {
    "text": "commercial models have a higher general",
    "start": "1013720",
    "end": "1015680"
  },
  {
    "text": "purpose performance so they are much",
    "start": "1015680",
    "end": "1017680"
  },
  {
    "text": "easier to get started with if you're",
    "start": "1017680",
    "end": "1019160"
  },
  {
    "text": "trying to build a new application uh but",
    "start": "1019160",
    "end": "1022199"
  },
  {
    "text": "if you once you get into production or",
    "start": "1022199",
    "end": "1024199"
  },
  {
    "text": "once you have high volume open models",
    "start": "1024199",
    "end": "1026438"
  },
  {
    "text": "can beat commercial models on specific",
    "start": "1026439",
    "end": "1028798"
  },
  {
    "text": "task with fine",
    "start": "1028799",
    "end": "1031678"
  },
  {
    "text": "tuning and um uh typically what we have",
    "start": "1031679",
    "end": "1035520"
  },
  {
    "text": "seen is people prototype with the",
    "start": "1035520",
    "end": "1037558"
  },
  {
    "text": "highest end models and then once they",
    "start": "1037559",
    "end": "1039600"
  },
  {
    "text": "figure out this is the the the task they",
    "start": "1039600",
    "end": "1043280"
  },
  {
    "text": "want to solve they take uh open source",
    "start": "1043280",
    "end": "1046199"
  },
  {
    "text": "model like install 7B or ax 7B and then",
    "start": "1046199",
    "end": "1048400"
  },
  {
    "text": "find un for their task and this",
    "start": "1048400",
    "end": "1050480"
  },
  {
    "text": "optimizes the performance to cost",
    "start": "1050480",
    "end": "1054760"
  },
  {
    "text": "ratio uh we have offices in Paris London",
    "start": "1054760",
    "end": "1058280"
  },
  {
    "text": "and in Maria uh we are always looking",
    "start": "1058280",
    "end": "1060960"
  },
  {
    "text": "for talented uh researchers",
    "start": "1060960",
    "end": "1064360"
  },
  {
    "text": "Engineers uh business marketing people",
    "start": "1064360",
    "end": "1068280"
  },
  {
    "text": "uh",
    "start": "1068280",
    "end": "1069240"
  },
  {
    "text": "so uh please please do apply and thank",
    "start": "1069240",
    "end": "1073120"
  },
  {
    "text": "you uh I don't know if you're taking",
    "start": "1073120",
    "end": "1074720"
  },
  {
    "text": "questions but no okay thank you so much",
    "start": "1074720",
    "end": "1080640"
  },
  {
    "text": "[Music]",
    "start": "1080810",
    "end": "1097750"
  }
]
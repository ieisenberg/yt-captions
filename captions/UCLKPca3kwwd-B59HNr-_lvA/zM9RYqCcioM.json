[
  {
    "text": "[Music]",
    "start": "490",
    "end": "17000"
  },
  {
    "text": "hey everybody uh yep I'm Kyle Corbett",
    "start": "17000",
    "end": "19119"
  },
  {
    "text": "from open pipe and I'm here with Mustafa",
    "start": "19119",
    "end": "20880"
  },
  {
    "text": "Ali from method we're going to be",
    "start": "20880",
    "end": "22960"
  },
  {
    "text": "talking about how method has scaled in",
    "start": "22960",
    "end": "25480"
  },
  {
    "text": "production to over 500 million agents uh",
    "start": "25480",
    "end": "28160"
  },
  {
    "text": "and basically all the the tricks they",
    "start": "28160",
    "end": "29359"
  },
  {
    "text": "use to make that actually work so a",
    "start": "29359",
    "end": "31840"
  },
  {
    "text": "little bit about method is that we",
    "start": "31840",
    "end": "33640"
  },
  {
    "text": "essentially collect and centralize",
    "start": "33640",
    "end": "35480"
  },
  {
    "text": "liability data from across hundreds of",
    "start": "35480",
    "end": "37640"
  },
  {
    "text": "different data sources this includes",
    "start": "37640",
    "end": "39280"
  },
  {
    "text": "tapping into the credit bureaus uh",
    "start": "39280",
    "end": "41160"
  },
  {
    "text": "connecting with the card networks like",
    "start": "41160",
    "end": "42520"
  },
  {
    "text": "visa and MasterCard um and just direct",
    "start": "42520",
    "end": "44760"
  },
  {
    "text": "connections with the financial",
    "start": "44760",
    "end": "45800"
  },
  {
    "text": "institutions and various other third",
    "start": "45800",
    "end": "47600"
  },
  {
    "text": "party sources and you know we uh sort of",
    "start": "47600",
    "end": "50800"
  },
  {
    "text": "aggregate and enhance this data and",
    "start": "50800",
    "end": "52600"
  },
  {
    "text": "serve it to our customers who are",
    "start": "52600",
    "end": "54520"
  },
  {
    "text": "typically other fintechs Banks or",
    "start": "54520",
    "end": "56520"
  },
  {
    "text": "lenders and they use this enhanced data",
    "start": "56520",
    "end": "58559"
  },
  {
    "text": "to um anything really to do with debt",
    "start": "58559",
    "end": "61440"
  },
  {
    "text": "management so refinancing loan",
    "start": "61440",
    "end": "63680"
  },
  {
    "text": "consolidation liability payments or just",
    "start": "63680",
    "end": "65518"
  },
  {
    "text": "Personal Finance Management",
    "start": "65519",
    "end": "68200"
  },
  {
    "text": "um yeah and at open pipe what we do is",
    "start": "68200",
    "end": "71240"
  },
  {
    "text": "we help you build uh train and deploy",
    "start": "71240",
    "end": "74200"
  },
  {
    "text": "open source models um for actual usage",
    "start": "74200",
    "end": "77159"
  },
  {
    "text": "we also let you use in production your",
    "start": "77159",
    "end": "79240"
  },
  {
    "text": "signals you get from users from the",
    "start": "79240",
    "end": "81040"
  },
  {
    "text": "environment to improve your model",
    "start": "81040",
    "end": "83000"
  },
  {
    "text": "continuously over time and that's some",
    "start": "83000",
    "end": "84799"
  },
  {
    "text": "of the things we'll be talking about uh",
    "start": "84799",
    "end": "86079"
  },
  {
    "text": "what we did with method nice",
    "start": "86079",
    "end": "90880"
  },
  {
    "text": "so one of the early challenges that we",
    "start": "91280",
    "end": "93399"
  },
  {
    "text": "faced at method while coming up with",
    "start": "93399",
    "end": "95520"
  },
  {
    "text": "this you know aggregation pipeline uh",
    "start": "95520",
    "end": "97720"
  },
  {
    "text": "was that some of our customers basically",
    "start": "97720",
    "end": "99799"
  },
  {
    "text": "came to us and said you know it's really",
    "start": "99799",
    "end": "101479"
  },
  {
    "text": "nice that you can give us the balance",
    "start": "101479",
    "end": "102799"
  },
  {
    "text": "and payment information on a specific",
    "start": "102799",
    "end": "104479"
  },
  {
    "text": "liability for their end consumers but",
    "start": "104479",
    "end": "106719"
  },
  {
    "text": "you know what would be really nice is if",
    "start": "106719",
    "end": "108320"
  },
  {
    "text": "you could also give us some of these",
    "start": "108320",
    "end": "110000"
  },
  {
    "text": "liability specific data points like the",
    "start": "110000",
    "end": "112320"
  },
  {
    "text": "payoff amount on an auto loan or the",
    "start": "112320",
    "end": "114520"
  },
  {
    "text": "escrow balance for a mortgage and you",
    "start": "114520",
    "end": "117000"
  },
  {
    "text": "know we said okay let's do some research",
    "start": "117000",
    "end": "119000"
  },
  {
    "text": "so we go back to to some of our data",
    "start": "119000",
    "end": "120640"
  },
  {
    "text": "partners and basically ask them you know",
    "start": "120640",
    "end": "122560"
  },
  {
    "text": "is there anything you know we can plug",
    "start": "122560",
    "end": "124079"
  },
  {
    "text": "into to get these kinds of data points",
    "start": "124079",
    "end": "125799"
  },
  {
    "text": "and what we found was there's really no",
    "start": "125799",
    "end": "127880"
  },
  {
    "text": "Central API that we could get access to",
    "start": "127880",
    "end": "130759"
  },
  {
    "text": "that would allow us to get some of these",
    "start": "130759",
    "end": "132080"
  },
  {
    "text": "data points and of course ideally we",
    "start": "132080",
    "end": "134239"
  },
  {
    "text": "would want to work with uh directly with",
    "start": "134239",
    "end": "135760"
  },
  {
    "text": "the banks but you know having already",
    "start": "135760",
    "end": "137280"
  },
  {
    "text": "worked with banks before and just from",
    "start": "137280",
    "end": "139319"
  },
  {
    "text": "initial conversations we realized that",
    "start": "139319",
    "end": "141400"
  },
  {
    "text": "it would easily take up to at least a",
    "start": "141400",
    "end": "142760"
  },
  {
    "text": "couple of years before getting anything",
    "start": "142760",
    "end": "144160"
  },
  {
    "text": "solid done and you know we we're an",
    "start": "144160",
    "end": "146400"
  },
  {
    "text": "early stage company so we want to build",
    "start": "146400",
    "end": "147760"
  },
  {
    "text": "for the customer fast um and so that's",
    "start": "147760",
    "end": "149959"
  },
  {
    "text": "really what we're trying to come up with",
    "start": "149959",
    "end": "151040"
  },
  {
    "text": "a solution that we can just you know uh",
    "start": "151040",
    "end": "153360"
  },
  {
    "text": "push into production",
    "start": "153360",
    "end": "156040"
  },
  {
    "text": "tomorrow and so just to get better",
    "start": "156040",
    "end": "158599"
  },
  {
    "text": "understanding of how some of these",
    "start": "158599",
    "end": "160040"
  },
  {
    "text": "companies are operating today uh the",
    "start": "160040",
    "end": "162040"
  },
  {
    "text": "services that they're providing today",
    "start": "162040",
    "end": "163239"
  },
  {
    "text": "how are they doing that in the first",
    "start": "163239",
    "end": "164319"
  },
  {
    "text": "place right like they must be getting",
    "start": "164319",
    "end": "165480"
  },
  {
    "text": "that data somehow so we go back to some",
    "start": "165480",
    "end": "168120"
  },
  {
    "text": "of these customers and basically ask",
    "start": "168120",
    "end": "169640"
  },
  {
    "text": "them you know how are you guys operating",
    "start": "169640",
    "end": "171680"
  },
  {
    "text": "and what they tell us is is kind of",
    "start": "171680",
    "end": "173239"
  },
  {
    "text": "interesting so a lot of these companies",
    "start": "173239",
    "end": "175440"
  },
  {
    "text": "they basically hire offshore teams of",
    "start": "175440",
    "end": "177319"
  },
  {
    "text": "contractors and you know they uh these",
    "start": "177319",
    "end": "180200"
  },
  {
    "text": "teams are basically responsible for",
    "start": "180200",
    "end": "182080"
  },
  {
    "text": "calling these Banks um on behalf of the",
    "start": "182080",
    "end": "185159"
  },
  {
    "text": "company and the end consumer they",
    "start": "185159",
    "end": "186640"
  },
  {
    "text": "authenticate with the banks gather the",
    "start": "186640",
    "end": "188440"
  },
  {
    "text": "necessary information somebody has to",
    "start": "188440",
    "end": "190239"
  },
  {
    "text": "proof check it it gets sent back um and",
    "start": "190239",
    "end": "192840"
  },
  {
    "text": "then it gets integrated into the",
    "start": "192840",
    "end": "194000"
  },
  {
    "text": "financial platforms um and it get surfac",
    "start": "194000",
    "end": "196200"
  },
  {
    "text": "to the user is used for underwriting",
    "start": "196200",
    "end": "198000"
  },
  {
    "text": "stuff like that and so that's the status",
    "start": "198000",
    "end": "201760"
  },
  {
    "text": "quo that we're dealing with here and",
    "start": "201760",
    "end": "203360"
  },
  {
    "text": "when you think about it that's a very",
    "start": "203360",
    "end": "204799"
  },
  {
    "text": "inefficient manual process right it's",
    "start": "204799",
    "end": "207879"
  },
  {
    "text": "it's when you try to think about scaling",
    "start": "207879",
    "end": "209519"
  },
  {
    "text": "it does doesn't really scale it's a very",
    "start": "209519",
    "end": "211519"
  },
  {
    "text": "um it has a lot of problems you know",
    "start": "211519",
    "end": "213799"
  },
  {
    "text": "it's expensive because one person can",
    "start": "213799",
    "end": "215959"
  },
  {
    "text": "only do one thing at a time right so if",
    "start": "215959",
    "end": "217879"
  },
  {
    "text": "you want to scale uh you basically have",
    "start": "217879",
    "end": "219879"
  },
  {
    "text": "to hire more people and for the same",
    "start": "219879",
    "end": "221760"
  },
  {
    "text": "reason because it's so synchronous it's",
    "start": "221760",
    "end": "223480"
  },
  {
    "text": "also really slow um and the main I guess",
    "start": "223480",
    "end": "226920"
  },
  {
    "text": "the the biggest problem with that is",
    "start": "226920",
    "end": "228200"
  },
  {
    "text": "also that it's there's a lot of human",
    "start": "228200",
    "end": "229680"
  },
  {
    "text": "error involved and um you you need to",
    "start": "229680",
    "end": "231799"
  },
  {
    "text": "hire a team to fact check it uh to proof",
    "start": "231799",
    "end": "234120"
  },
  {
    "text": "check it and um it's the the the the",
    "start": "234120",
    "end": "238040"
  },
  {
    "text": "worst thing that you can end up with is",
    "start": "238040",
    "end": "239760"
  },
  {
    "text": "to surface basically inaccurate",
    "start": "239760",
    "end": "241239"
  },
  {
    "text": "financial",
    "start": "241239",
    "end": "242280"
  },
  {
    "text": "information and so conceptually though",
    "start": "242280",
    "end": "244760"
  },
  {
    "text": "if you think about it it's kind of like",
    "start": "244760",
    "end": "245879"
  },
  {
    "text": "an API right you have the request",
    "start": "245879",
    "end": "247599"
  },
  {
    "text": "component you have the authentication",
    "start": "247599",
    "end": "249120"
  },
  {
    "text": "component you have the response",
    "start": "249120",
    "end": "250760"
  },
  {
    "text": "validation all that stuff uh so",
    "start": "250760",
    "end": "253720"
  },
  {
    "text": "essentially when you drill this problem",
    "start": "253720",
    "end": "255480"
  },
  {
    "text": "down into the core problem that's really",
    "start": "255480",
    "end": "257440"
  },
  {
    "text": "just trying to make sense of um",
    "start": "257440",
    "end": "259680"
  },
  {
    "text": "unstructured data right so if only there",
    "start": "259680",
    "end": "261919"
  },
  {
    "text": "was this magic tool or software that we",
    "start": "261919",
    "end": "264120"
  },
  {
    "text": "could use that was really good at",
    "start": "264120",
    "end": "266160"
  },
  {
    "text": "parsing unstructured",
    "start": "266160",
    "end": "268479"
  },
  {
    "text": "data and and you know lucky for us",
    "start": "268479",
    "end": "271560"
  },
  {
    "text": "around the time that we were trying to",
    "start": "271560",
    "end": "272759"
  },
  {
    "text": "solve this problem open aai announced",
    "start": "272759",
    "end": "275199"
  },
  {
    "text": "gbd4 and you know as people like to call",
    "start": "275199",
    "end": "277400"
  },
  {
    "text": "it there was this Cambrian explosion of",
    "start": "277400",
    "end": "279639"
  },
  {
    "text": "AI or llm enabled applications all",
    "start": "279639",
    "end": "282280"
  },
  {
    "text": "around us and the results were just",
    "start": "282280",
    "end": "284240"
  },
  {
    "text": "mind-blowing um and we thought to",
    "start": "284240",
    "end": "286560"
  },
  {
    "text": "ourselves you know this this this is the",
    "start": "286560",
    "end": "288400"
  },
  {
    "text": "perfect thing for us this is like a",
    "start": "288400",
    "end": "289520"
  },
  {
    "text": "godsend uh so we tried to like you know",
    "start": "289520",
    "end": "291919"
  },
  {
    "text": "we tried to see if there's anything",
    "start": "291919",
    "end": "293160"
  },
  {
    "text": "there that we could use and if there's",
    "start": "293160",
    "end": "294840"
  },
  {
    "text": "one thing that we all know in this room",
    "start": "294840",
    "end": "296240"
  },
  {
    "text": "is that advanced llms especially post",
    "start": "296240",
    "end": "298840"
  },
  {
    "text": "gbd4 are really good with um with",
    "start": "298840",
    "end": "302320"
  },
  {
    "text": "parsing unstructured data so tasks like",
    "start": "302320",
    "end": "304919"
  },
  {
    "text": "summarization or classification they're",
    "start": "304919",
    "end": "307199"
  },
  {
    "text": "really good with that kind of thing so",
    "start": "307199",
    "end": "308360"
  },
  {
    "text": "we want to test that theory out and see",
    "start": "308360",
    "end": "310440"
  },
  {
    "text": "what that can get",
    "start": "310440",
    "end": "313240"
  },
  {
    "text": "us and so we put our heads down hack",
    "start": "313680",
    "end": "316400"
  },
  {
    "text": "together this agentic workflow using GPD",
    "start": "316400",
    "end": "318560"
  },
  {
    "text": "4 and as expected you know it worked",
    "start": "318560",
    "end": "321240"
  },
  {
    "text": "really well so we tried to like expand",
    "start": "321240",
    "end": "323800"
  },
  {
    "text": "some of our use cases because you know",
    "start": "323800",
    "end": "325800"
  },
  {
    "text": "the API costs are high so we wanted to",
    "start": "325800",
    "end": "327639"
  },
  {
    "text": "get as much as we could from a single",
    "start": "327639",
    "end": "329240"
  },
  {
    "text": "API call and you know it turned out to",
    "start": "329240",
    "end": "331280"
  },
  {
    "text": "be really good at that so we tried to",
    "start": "331280",
    "end": "333520"
  },
  {
    "text": "obviously this was in a very controlled",
    "start": "333520",
    "end": "335319"
  },
  {
    "text": "manner um but this was in production and",
    "start": "335319",
    "end": "338360"
  },
  {
    "text": "so we were testing out uh different uh",
    "start": "338360",
    "end": "340800"
  },
  {
    "text": "extractions basically and um you know",
    "start": "340800",
    "end": "343479"
  },
  {
    "text": "everything was going really good uh but",
    "start": "343479",
    "end": "345720"
  },
  {
    "text": "as soon as we started to increase a",
    "start": "345720",
    "end": "347039"
  },
  {
    "text": "little bit of uh traffic uh what we",
    "start": "347039",
    "end": "350440"
  },
  {
    "text": "found was you know the bill had to come",
    "start": "350440",
    "end": "353000"
  },
  {
    "text": "do and um it was a lot so $70,000 for",
    "start": "353000",
    "end": "357400"
  },
  {
    "text": "our first month in production with gbd4",
    "start": "357400",
    "end": "360000"
  },
  {
    "text": "and you know this was this made",
    "start": "360000",
    "end": "361400"
  },
  {
    "text": "leadership really unhappy and you know",
    "start": "361400",
    "end": "363240"
  },
  {
    "text": "but um but it was something it was",
    "start": "363240",
    "end": "365560"
  },
  {
    "text": "something they were they were fine with",
    "start": "365560",
    "end": "367039"
  },
  {
    "text": "because the value that we were getting",
    "start": "367039",
    "end": "368440"
  },
  {
    "text": "out of gp4 was so immense um and so we",
    "start": "368440",
    "end": "371240"
  },
  {
    "text": "actually kept this thing in production",
    "start": "371240",
    "end": "373120"
  },
  {
    "text": "for at least a couple more months as we",
    "start": "373120",
    "end": "375599"
  },
  {
    "text": "tried to work around this kind of cost",
    "start": "375599",
    "end": "377880"
  },
  {
    "text": "problem and you know cost wasn't the",
    "start": "377880",
    "end": "380160"
  },
  {
    "text": "only thing that we were concerned with",
    "start": "380160",
    "end": "381960"
  },
  {
    "text": "um as we started to scale some of these",
    "start": "381960",
    "end": "383880"
  },
  {
    "text": "use cases we quickly ran into a wall",
    "start": "383880",
    "end": "385520"
  },
  {
    "text": "with prompt engineering it only takes",
    "start": "385520",
    "end": "387240"
  },
  {
    "text": "you so far um one thing we realized that",
    "start": "387240",
    "end": "389599"
  },
  {
    "text": "even though gbd is really smart it's not",
    "start": "389599",
    "end": "391720"
  },
  {
    "text": "a financial expert so you had to give it",
    "start": "391720",
    "end": "394240"
  },
  {
    "text": "really detailed instructions and",
    "start": "394240",
    "end": "395919"
  },
  {
    "text": "examples uh to really make it work with",
    "start": "395919",
    "end": "398000"
  },
  {
    "text": "all kinds of use cases that we were",
    "start": "398000",
    "end": "399199"
  },
  {
    "text": "trying to Target um so it's hard to",
    "start": "399199",
    "end": "401160"
  },
  {
    "text": "generalize those kinds of prompts they",
    "start": "401160",
    "end": "402840"
  },
  {
    "text": "become really long convoluted it's",
    "start": "402840",
    "end": "404759"
  },
  {
    "text": "always a cat and mouse Chase with you",
    "start": "404759",
    "end": "406680"
  },
  {
    "text": "fix it for a certain scenario and it",
    "start": "406680",
    "end": "408319"
  },
  {
    "text": "breaks for another one you fix it for",
    "start": "408319",
    "end": "409960"
  },
  {
    "text": "that one it breaks for the previous one",
    "start": "409960",
    "end": "411599"
  },
  {
    "text": "and so you're all this going back and",
    "start": "411599",
    "end": "412720"
  },
  {
    "text": "forth we didn't have any prompt",
    "start": "412720",
    "end": "413840"
  },
  {
    "text": "versioning so we had to figure out a",
    "start": "413840",
    "end": "415160"
  },
  {
    "text": "better way to make this work for all of",
    "start": "415160",
    "end": "417120"
  },
  {
    "text": "our use cases",
    "start": "417120",
    "end": "420560"
  },
  {
    "text": "and so the tldr here is that you know we",
    "start": "422440",
    "end": "425000"
  },
  {
    "text": "we didn't want to adopt that initial",
    "start": "425000",
    "end": "426400"
  },
  {
    "text": "solution that I just talked about",
    "start": "426400",
    "end": "427599"
  },
  {
    "text": "earlier in the slides because of its",
    "start": "427599",
    "end": "429720"
  },
  {
    "text": "scaling challenges and just because it",
    "start": "429720",
    "end": "431080"
  },
  {
    "text": "was so inefficient but we kind of ran",
    "start": "431080",
    "end": "433120"
  },
  {
    "text": "into the same scaling challenges with",
    "start": "433120",
    "end": "435599"
  },
  {
    "text": "GPT where it was expensive because we",
    "start": "435599",
    "end": "438759"
  },
  {
    "text": "couldn't really optimize for caching",
    "start": "438759",
    "end": "440919"
  },
  {
    "text": "because of the variability and responses",
    "start": "440919",
    "end": "442680"
  },
  {
    "text": "and the prompt tweaks we were making all",
    "start": "442680",
    "end": "444400"
  },
  {
    "text": "the time and the Baseline latency that",
    "start": "444400",
    "end": "446440"
  },
  {
    "text": "we were finding was actually really slow",
    "start": "446440",
    "end": "448240"
  },
  {
    "text": "so we couldn't you know it was overall",
    "start": "448240",
    "end": "449800"
  },
  {
    "text": "we couldn't scale concurrently and",
    "start": "449800",
    "end": "452440"
  },
  {
    "text": "similar to human errors that were kind",
    "start": "452440",
    "end": "454160"
  },
  {
    "text": "of uh in a different nature we had AI",
    "start": "454160",
    "end": "456800"
  },
  {
    "text": "errors which were just hallucinations",
    "start": "456800",
    "end": "458319"
  },
  {
    "text": "that were hard to catch um and we just",
    "start": "458319",
    "end": "461560"
  },
  {
    "text": "couldn't scale with this kind of system",
    "start": "461560",
    "end": "463120"
  },
  {
    "text": "but we still kept it in production",
    "start": "463120",
    "end": "464400"
  },
  {
    "text": "because for a specific use cases was",
    "start": "464400",
    "end": "466080"
  },
  {
    "text": "actually really really",
    "start": "466080",
    "end": "468080"
  },
  {
    "text": "good and so now the problem shifted from",
    "start": "468080",
    "end": "471479"
  },
  {
    "text": "solving that core problem of trying to",
    "start": "471479",
    "end": "473520"
  },
  {
    "text": "make sense of unstructured data that was",
    "start": "473520",
    "end": "475440"
  },
  {
    "text": "solved with GPT now the problem shifted",
    "start": "475440",
    "end": "477639"
  },
  {
    "text": "to how do we scale this system how do we",
    "start": "477639",
    "end": "479240"
  },
  {
    "text": "build",
    "start": "479240",
    "end": "479960"
  },
  {
    "text": "a robust uh you know agentic workflow",
    "start": "479960",
    "end": "482599"
  },
  {
    "text": "that can handle this kind of volume",
    "start": "482599",
    "end": "484919"
  },
  {
    "text": "reliably and so some of the ballpark",
    "start": "484919",
    "end": "487199"
  },
  {
    "text": "figures that we came up with you know is",
    "start": "487199",
    "end": "489000"
  },
  {
    "text": "that we we're going to be at least",
    "start": "489000",
    "end": "490479"
  },
  {
    "text": "making 16 million requests per day uh",
    "start": "490479",
    "end": "492800"
  },
  {
    "text": "we're going to have at least 100K",
    "start": "492800",
    "end": "494199"
  },
  {
    "text": "concurrent load and you know we need",
    "start": "494199",
    "end": "496440"
  },
  {
    "text": "minimal latency to um handle this kind",
    "start": "496440",
    "end": "499159"
  },
  {
    "text": "of real-time agentic workflow so sub 200",
    "start": "499159",
    "end": "501479"
  },
  {
    "text": "milliseconds and you know so the natural",
    "start": "501479",
    "end": "503479"
  },
  {
    "text": "next step for us was like we thought to",
    "start": "503479",
    "end": "505360"
  },
  {
    "text": "ourselves do we buy more gpus do we host",
    "start": "505360",
    "end": "507680"
  },
  {
    "text": "our own model like what do we do at this",
    "start": "507680",
    "end": "509240"
  },
  {
    "text": "point",
    "start": "509240",
    "end": "510240"
  },
  {
    "text": "um so that at that point open pipe comes",
    "start": "510240",
    "end": "513000"
  },
  {
    "text": "in yeah so about a year ago we started",
    "start": "513000",
    "end": "515399"
  },
  {
    "text": "working with method on solving these",
    "start": "515399",
    "end": "517240"
  },
  {
    "text": "issues that Mustafa just listed and we",
    "start": "517240",
    "end": "520640"
  },
  {
    "text": "actually found that the those three",
    "start": "520640",
    "end": "522760"
  },
  {
    "text": "issues he listed right which are quality",
    "start": "522760",
    "end": "524680"
  },
  {
    "text": "cost um and latency are very common um",
    "start": "524680",
    "end": "527560"
  },
  {
    "text": "these are things that you know across",
    "start": "527560",
    "end": "528920"
  },
  {
    "text": "almost everyone we work with uh at least",
    "start": "528920",
    "end": "530600"
  },
  {
    "text": "some subset of those are really top of",
    "start": "530600",
    "end": "532959"
  },
  {
    "text": "mind um and so with uh method",
    "start": "532959",
    "end": "536200"
  },
  {
    "text": "specifically we were working on okay how",
    "start": "536200",
    "end": "537519"
  },
  {
    "text": "do we how do we solve those problems in",
    "start": "537519",
    "end": "539000"
  },
  {
    "text": "a way that that makes this uh you know a",
    "start": "539000",
    "end": "541200"
  },
  {
    "text": "viable business for you so uh the first",
    "start": "541200",
    "end": "544160"
  },
  {
    "text": "thing we did was start measuring error",
    "start": "544160",
    "end": "545560"
  },
  {
    "text": "rates um you know like like he mentioned",
    "start": "545560",
    "end": "548000"
  },
  {
    "text": "uh even AI models are not perfect uh",
    "start": "548000",
    "end": "550480"
  },
  {
    "text": "these are all probabilistic systems",
    "start": "550480",
    "end": "552560"
  },
  {
    "text": "getting to a 0% error rate was not",
    "start": "552560",
    "end": "554959"
  },
  {
    "text": "really feasible but we were able to see",
    "start": "554959",
    "end": "557040"
  },
  {
    "text": "different models had different uh had",
    "start": "557040",
    "end": "558760"
  },
  {
    "text": "different performance characteristics",
    "start": "558760",
    "end": "560440"
  },
  {
    "text": "there so on Modern models on the task",
    "start": "560440",
    "end": "562800"
  },
  {
    "text": "they're doing these are the rates we're",
    "start": "562800",
    "end": "564000"
  },
  {
    "text": "seeing on gbd4 um we're at about an 11%",
    "start": "564000",
    "end": "566760"
  },
  {
    "text": "error rate uh and with 03 mini it's much",
    "start": "566760",
    "end": "568920"
  },
  {
    "text": "better it's a 4% error rate um the way",
    "start": "568920",
    "end": "572079"
  },
  {
    "text": "you measure that is going to be specific",
    "start": "572079",
    "end": "573760"
  },
  {
    "text": "to your business and that that's",
    "start": "573760",
    "end": "574880"
  },
  {
    "text": "actually true to some extent for all",
    "start": "574880",
    "end": "576120"
  },
  {
    "text": "three of these things we'll talk about",
    "start": "576120",
    "end": "578040"
  },
  {
    "text": "uh in the case of method this is",
    "start": "578040",
    "end": "579360"
  },
  {
    "text": "actually relatively easy to measure",
    "start": "579360",
    "end": "581079"
  },
  {
    "text": "luckily because they have this agentic",
    "start": "581079",
    "end": "582959"
  },
  {
    "text": "workflow but like ultimately what the",
    "start": "582959",
    "end": "584640"
  },
  {
    "text": "agent is trying to do is is fill out um",
    "start": "584640",
    "end": "586720"
  },
  {
    "text": "you know extract all this information he",
    "start": "586720",
    "end": "588040"
  },
  {
    "text": "was talking about Bank balances things",
    "start": "588040",
    "end": "589640"
  },
  {
    "text": "like that and so you can you can have a",
    "start": "589640",
    "end": "591920"
  },
  {
    "text": "human go through the flow and figure out",
    "start": "591920",
    "end": "593040"
  },
  {
    "text": "what the real number should be and then",
    "start": "593040",
    "end": "594720"
  },
  {
    "text": "you can compare an agentic systems final",
    "start": "594720",
    "end": "597360"
  },
  {
    "text": "outputs to that and see if it was",
    "start": "597360",
    "end": "598800"
  },
  {
    "text": "successful or not",
    "start": "598800",
    "end": "599839"
  },
  {
    "text": "um which which made this part relatively",
    "start": "599839",
    "end": "601160"
  },
  {
    "text": "easy to calculate uh so these are kind",
    "start": "601160",
    "end": "603600"
  },
  {
    "text": "of the error rates we're getting um on",
    "start": "603600",
    "end": "605600"
  },
  {
    "text": "the latency point of view uh we see that",
    "start": "605600",
    "end": "608440"
  },
  {
    "text": "gp40 is around a second uh to respond uh",
    "start": "608440",
    "end": "612160"
  },
  {
    "text": "and then o03 mini takes about 5 seconds",
    "start": "612160",
    "end": "614440"
  },
  {
    "text": "for their specific task again this is",
    "start": "614440",
    "end": "615760"
  },
  {
    "text": "somewhat task dependent uh depending on",
    "start": "615760",
    "end": "617680"
  },
  {
    "text": "how much you know for example O3 has to",
    "start": "617680",
    "end": "619440"
  },
  {
    "text": "think as you're measuring this you also",
    "start": "619440",
    "end": "621079"
  },
  {
    "text": "want to make sure that you're using real",
    "start": "621079",
    "end": "622320"
  },
  {
    "text": "production conditions that you're",
    "start": "622320",
    "end": "623800"
  },
  {
    "text": "actually doing um you know like a real",
    "start": "623800",
    "end": "625640"
  },
  {
    "text": "diversity of tasks uh that that match",
    "start": "625640",
    "end": "627560"
  },
  {
    "text": "what you're actually doing and at a",
    "start": "627560",
    "end": "628800"
  },
  {
    "text": "reasonable and currency level that",
    "start": "628800",
    "end": "630399"
  },
  {
    "text": "matches your production um and we also",
    "start": "630399",
    "end": "632760"
  },
  {
    "text": "measured the cost um so again cost uh",
    "start": "632760",
    "end": "635200"
  },
  {
    "text": "this is something that is going to",
    "start": "635200",
    "end": "636279"
  },
  {
    "text": "obviously be specific and how much it",
    "start": "636279",
    "end": "638200"
  },
  {
    "text": "matters is also very specific to your",
    "start": "638200",
    "end": "639680"
  },
  {
    "text": "use case as well um interestingly 03",
    "start": "639680",
    "end": "642000"
  },
  {
    "text": "mini even though it has a much lower per",
    "start": "642000",
    "end": "644399"
  },
  {
    "text": "token cost than GPD 40 if you just look",
    "start": "644399",
    "end": "646800"
  },
  {
    "text": "at like the pricing page on the API for",
    "start": "646800",
    "end": "649040"
  },
  {
    "text": "their specific use case uh we found it",
    "start": "649040",
    "end": "650800"
  },
  {
    "text": "was a little bit more expensive because",
    "start": "650800",
    "end": "652760"
  },
  {
    "text": "it has it generates many more reasoning",
    "start": "652760",
    "end": "654360"
  },
  {
    "text": "tokens so it has much longer outputs um",
    "start": "654360",
    "end": "656519"
  },
  {
    "text": "again though this is somewhat Tas",
    "start": "656519",
    "end": "658000"
  },
  {
    "text": "dependent so I just recommend",
    "start": "658000",
    "end": "660040"
  },
  {
    "text": "um actually just just as an aside I",
    "start": "660040",
    "end": "662360"
  },
  {
    "text": "would recommend once you get to the",
    "start": "662360",
    "end": "664200"
  },
  {
    "text": "point that you're trying to optimize",
    "start": "664200",
    "end": "665639"
  },
  {
    "text": "that you have sort of that initial proof",
    "start": "665639",
    "end": "666920"
  },
  {
    "text": "of concept with with some model",
    "start": "666920",
    "end": "668680"
  },
  {
    "text": "something that works I think it's really",
    "start": "668680",
    "end": "670440"
  },
  {
    "text": "worthwhile to it can be as simple as",
    "start": "670440",
    "end": "672040"
  },
  {
    "text": "like literally just writing like you",
    "start": "672040",
    "end": "673160"
  },
  {
    "text": "know three different Python scripts that",
    "start": "673160",
    "end": "675079"
  },
  {
    "text": "like are able to categorize each of",
    "start": "675079",
    "end": "676600"
  },
  {
    "text": "these for a different model um and then",
    "start": "676600",
    "end": "678360"
  },
  {
    "text": "as new models come out you'll be able to",
    "start": "678360",
    "end": "679959"
  },
  {
    "text": "quickly tell how they're doing um okay",
    "start": "679959",
    "end": "683600"
  },
  {
    "text": "once you've done or in this case once",
    "start": "683600",
    "end": "685480"
  },
  {
    "text": "we've done this this sort of um",
    "start": "685480",
    "end": "687320"
  },
  {
    "text": "benchmarking of where the models are",
    "start": "687320",
    "end": "689320"
  },
  {
    "text": "next question is all right what is where",
    "start": "689320",
    "end": "691320"
  },
  {
    "text": "do we need these models to be where do",
    "start": "691320",
    "end": "692720"
  },
  {
    "text": "we need to get to um and so again this",
    "start": "692720",
    "end": "695000"
  },
  {
    "text": "is very task dependent uh in the case of",
    "start": "695000",
    "end": "697760"
  },
  {
    "text": "method uh they do have special like they",
    "start": "697760",
    "end": "700399"
  },
  {
    "text": "have um extra checks that happen after",
    "start": "700399",
    "end": "702720"
  },
  {
    "text": "this where they look and see okay are",
    "start": "702720",
    "end": "704200"
  },
  {
    "text": "the numbers that came out plausible do",
    "start": "704200",
    "end": "705639"
  },
  {
    "text": "they match you know the types of things",
    "start": "705639",
    "end": "706680"
  },
  {
    "text": "we're seeing before all the all these",
    "start": "706680",
    "end": "707639"
  },
  {
    "text": "different kinds of checks they're doing",
    "start": "707639",
    "end": "708880"
  },
  {
    "text": "and so they didn't need to get all the",
    "start": "708880",
    "end": "710040"
  },
  {
    "text": "way down to a 0% error rate but of",
    "start": "710040",
    "end": "712000"
  },
  {
    "text": "course those checks are still followable",
    "start": "712000",
    "end": "713880"
  },
  {
    "text": "and so um if it's over a certain point",
    "start": "713880",
    "end": "715839"
  },
  {
    "text": "then then some fraction of those errors",
    "start": "715839",
    "end": "717200"
  },
  {
    "text": "are going to get through and that's",
    "start": "717200",
    "end": "718440"
  },
  {
    "text": "going to be bad so we found around a 9%",
    "start": "718440",
    "end": "720360"
  },
  {
    "text": "error rate was was able to get them what",
    "start": "720360",
    "end": "721920"
  },
  {
    "text": "they needed um from a latency point of",
    "start": "721920",
    "end": "724560"
  },
  {
    "text": "view so the way their agent works is a",
    "start": "724560",
    "end": "726959"
  },
  {
    "text": "realtime system uh it it needs to be",
    "start": "726959",
    "end": "729720"
  },
  {
    "text": "able to respond quickly to to move uh",
    "start": "729720",
    "end": "731880"
  },
  {
    "text": "through the the basically like through",
    "start": "731880",
    "end": "734040"
  },
  {
    "text": "the whole flow to get the information it",
    "start": "734040",
    "end": "735720"
  },
  {
    "text": "needs and so they did have a hard",
    "start": "735720",
    "end": "737000"
  },
  {
    "text": "latency cut off um we see a wide variety",
    "start": "737000",
    "end": "739760"
  },
  {
    "text": "in this for what it's worth we have some",
    "start": "739760",
    "end": "741240"
  },
  {
    "text": "customers that I talked to who it's like",
    "start": "741240",
    "end": "742720"
  },
  {
    "text": "hey if I get a result back at some point",
    "start": "742720",
    "end": "744240"
  },
  {
    "text": "in the next few days like that's totally",
    "start": "744240",
    "end": "745519"
  },
  {
    "text": "fine this is a background bash process",
    "start": "745519",
    "end": "747320"
  },
  {
    "text": "um we have other customers who are doing",
    "start": "747320",
    "end": "748480"
  },
  {
    "text": "real-time voice with the human on the",
    "start": "748480",
    "end": "750040"
  },
  {
    "text": "other end of the line and it's like hey",
    "start": "750040",
    "end": "751600"
  },
  {
    "text": "you know if I'm over 500 milliseconds",
    "start": "751600",
    "end": "753560"
  },
  {
    "text": "that's not going to work for me and so",
    "start": "753560",
    "end": "755240"
  },
  {
    "text": "again you just have to know for your",
    "start": "755240",
    "end": "756360"
  },
  {
    "text": "specific case how much this matters same",
    "start": "756360",
    "end": "758360"
  },
  {
    "text": "with cost um in their case because of",
    "start": "758360",
    "end": "760760"
  },
  {
    "text": "that very high volume as mustaf was",
    "start": "760760",
    "end": "762639"
  },
  {
    "text": "mentioning cost is pretty important to",
    "start": "762639",
    "end": "764639"
  },
  {
    "text": "them um again depending on your use case",
    "start": "764639",
    "end": "766800"
  },
  {
    "text": "usually mostly dependent on how high",
    "start": "766800",
    "end": "768440"
  },
  {
    "text": "volume it is um will determine how much",
    "start": "768440",
    "end": "771000"
  },
  {
    "text": "cost matters to you but but it's",
    "start": "771000",
    "end": "772360"
  },
  {
    "text": "something you you you should know these",
    "start": "772360",
    "end": "773600"
  },
  {
    "text": "numbers for your specific task as you're",
    "start": "773600",
    "end": "775560"
  },
  {
    "text": "comparing different models okay so um",
    "start": "775560",
    "end": "779680"
  },
  {
    "text": "we're looking here at this uh of course",
    "start": "779680",
    "end": "782440"
  },
  {
    "text": "as you're looking at this this slide you",
    "start": "782440",
    "end": "783959"
  },
  {
    "text": "can you may see there's a problem here",
    "start": "783959",
    "end": "785560"
  },
  {
    "text": "which is um of the two models we're",
    "start": "785560",
    "end": "787519"
  },
  {
    "text": "comparing at least none of them actually",
    "start": "787519",
    "end": "789720"
  },
  {
    "text": "meet all three of the requirements we",
    "start": "789720",
    "end": "791160"
  },
  {
    "text": "need to be able to deploy this in",
    "start": "791160",
    "end": "792480"
  },
  {
    "text": "production and uh you know gbd4 on both",
    "start": "792480",
    "end": "796079"
  },
  {
    "text": "the error rate as well as the cost we're",
    "start": "796079",
    "end": "798199"
  },
  {
    "text": "not quite there um and then 03 mini uh",
    "start": "798199",
    "end": "801040"
  },
  {
    "text": "on the cost but especially on the",
    "start": "801040",
    "end": "802320"
  },
  {
    "text": "latency it's just not going to work for",
    "start": "802320",
    "end": "803600"
  },
  {
    "text": "what we need so this is the point at",
    "start": "803600",
    "end": "806120"
  },
  {
    "text": "which uh method came and they talked to",
    "start": "806120",
    "end": "808079"
  },
  {
    "text": "us we're like hey we're not able to hit",
    "start": "808079",
    "end": "809959"
  },
  {
    "text": "what we need here um because again we're",
    "start": "809959",
    "end": "813040"
  },
  {
    "text": "not uh yeah we're these these models",
    "start": "813040",
    "end": "815839"
  },
  {
    "text": "aren't getting us where we need to be so",
    "start": "815839",
    "end": "817680"
  },
  {
    "text": "what we work on in open pipe is fine",
    "start": "817680",
    "end": "819160"
  },
  {
    "text": "tuning we work on building custom models",
    "start": "819160",
    "end": "821480"
  },
  {
    "text": "for your specific use case and so I'm",
    "start": "821480",
    "end": "823320"
  },
  {
    "text": "going to talk about why you would want",
    "start": "823320",
    "end": "824639"
  },
  {
    "text": "to do that and how that helps in this",
    "start": "824639",
    "end": "826079"
  },
  {
    "text": "case um first I would say fine-tuning is",
    "start": "826079",
    "end": "828920"
  },
  {
    "text": "a power tool uh it does take more time",
    "start": "828920",
    "end": "831560"
  },
  {
    "text": "it takes more um engineering investment",
    "start": "831560",
    "end": "834480"
  },
  {
    "text": "than just prompting a model uh so you",
    "start": "834480",
    "end": "836839"
  },
  {
    "text": "don't really want to do that until you",
    "start": "836839",
    "end": "839720"
  },
  {
    "text": "have actually benchmarked the production",
    "start": "839720",
    "end": "841399"
  },
  {
    "text": "models just prompting them and seen",
    "start": "841399",
    "end": "843120"
  },
  {
    "text": "whether they work or not um so in this",
    "start": "843120",
    "end": "844600"
  },
  {
    "text": "case in meth's case and and in all of",
    "start": "844600",
    "end": "846360"
  },
  {
    "text": "our customers cases uh they found that",
    "start": "846360",
    "end": "847959"
  },
  {
    "text": "they were not able to hit the numbers",
    "start": "847959",
    "end": "849199"
  },
  {
    "text": "they needed um and so that's the time",
    "start": "849199",
    "end": "850839"
  },
  {
    "text": "you want to bring in fine",
    "start": "850839",
    "end": "852360"
  },
  {
    "text": "tuning um so let's look at we were able",
    "start": "852360",
    "end": "855279"
  },
  {
    "text": "to find tuna model and see uh how that",
    "start": "855279",
    "end": "857199"
  },
  {
    "text": "was able to help uh because it can",
    "start": "857199",
    "end": "858759"
  },
  {
    "text": "actually really bend that price",
    "start": "858759",
    "end": "860240"
  },
  {
    "text": "performance curve a lot um so on the the",
    "start": "860240",
    "end": "864079"
  },
  {
    "text": "error rate uh which is basically just",
    "start": "864079",
    "end": "865440"
  },
  {
    "text": "the inverse of of accuracy if you want",
    "start": "865440",
    "end": "866759"
  },
  {
    "text": "to measure it that way um we were able",
    "start": "866759",
    "end": "868880"
  },
  {
    "text": "to get to a place where we were doing",
    "start": "868880",
    "end": "870199"
  },
  {
    "text": "significantly better than GPD 4 and",
    "start": "870199",
    "end": "871759"
  },
  {
    "text": "importantly better than that threshold",
    "start": "871759",
    "end": "873040"
  },
  {
    "text": "they needed uh this used to actually be",
    "start": "873040",
    "end": "875600"
  },
  {
    "text": "much harder to achieve it required a lot",
    "start": "875600",
    "end": "877279"
  },
  {
    "text": "of manual uh labeling of data and things",
    "start": "877279",
    "end": "879399"
  },
  {
    "text": "like that it's actually become much",
    "start": "879399",
    "end": "880759"
  },
  {
    "text": "easier over time because of the",
    "start": "880759",
    "end": "882600"
  },
  {
    "text": "existence of models like now o03 mini um",
    "start": "882600",
    "end": "885600"
  },
  {
    "text": "which allows you to just use your",
    "start": "885600",
    "end": "887639"
  },
  {
    "text": "production data you can you can use your",
    "start": "887639",
    "end": "890040"
  },
  {
    "text": "uh basically the inputs you're using",
    "start": "890040",
    "end": "891240"
  },
  {
    "text": "production you can uh generate outputs",
    "start": "891240",
    "end": "894199"
  },
  {
    "text": "for them using a model like O3 mini and",
    "start": "894199",
    "end": "896279"
  },
  {
    "text": "train on them we find like in this case",
    "start": "896279",
    "end": "898320"
  },
  {
    "text": "that often you're not able to quite get",
    "start": "898320",
    "end": "900560"
  },
  {
    "text": "uh to the the performance of the the",
    "start": "900560",
    "end": "902519"
  },
  {
    "text": "teacher model the model o03 mini in this",
    "start": "902519",
    "end": "904120"
  },
  {
    "text": "case that you're using but you can get",
    "start": "904120",
    "end": "906040"
  },
  {
    "text": "quite close to it and usually do much",
    "start": "906040",
    "end": "907880"
  },
  {
    "text": "better than you know uh a slightly less",
    "start": "907880",
    "end": "910320"
  },
  {
    "text": "good but much much larger model um you",
    "start": "910320",
    "end": "912360"
  },
  {
    "text": "know in this case uh the model we ended",
    "start": "912360",
    "end": "914040"
  },
  {
    "text": "up deploying with them is just an 8",
    "start": "914040",
    "end": "915199"
  },
  {
    "text": "billion parameter LL 3.1 model and and",
    "start": "915199",
    "end": "918199"
  },
  {
    "text": "we find that actually for the majority",
    "start": "918199",
    "end": "919440"
  },
  {
    "text": "of our customers a model that large or",
    "start": "919440",
    "end": "920839"
  },
  {
    "text": "smaller is is good enough and is able to",
    "start": "920839",
    "end": "923120"
  },
  {
    "text": "hit the numbers you need from quality um",
    "start": "923120",
    "end": "925600"
  },
  {
    "text": "but uh yeah the important thing is to be",
    "start": "925600",
    "end": "927079"
  },
  {
    "text": "able to Benchmark that and to answer",
    "start": "927079",
    "end": "928199"
  },
  {
    "text": "that question for yourself",
    "start": "928199",
    "end": "930639"
  },
  {
    "text": "um on the latency point of view because",
    "start": "930639",
    "end": "934040"
  },
  {
    "text": "actually this this is sort of the magic",
    "start": "934040",
    "end": "935279"
  },
  {
    "text": "of being able to move to that much",
    "start": "935279",
    "end": "936279"
  },
  {
    "text": "smaller model because we've got this AP",
    "start": "936279",
    "end": "937880"
  },
  {
    "text": "billion parameter model it is way easier",
    "start": "937880",
    "end": "940800"
  },
  {
    "text": "to deploy in a low latency way um",
    "start": "940800",
    "end": "943040"
  },
  {
    "text": "there's just many few fewer calculations",
    "start": "943040",
    "end": "945000"
  },
  {
    "text": "for your sequential calculations with",
    "start": "945000",
    "end": "946120"
  },
  {
    "text": "the number of layers and so you can get",
    "start": "946120",
    "end": "947560"
  },
  {
    "text": "just a much lower latency you can even",
    "start": "947560",
    "end": "949040"
  },
  {
    "text": "and we we didn't actually have to do",
    "start": "949040",
    "end": "950079"
  },
  {
    "text": "this in method's case but something you",
    "start": "950079",
    "end": "951720"
  },
  {
    "text": "can do is you can train this model you",
    "start": "951720",
    "end": "953079"
  },
  {
    "text": "can deploy it within your own",
    "start": "953079",
    "end": "954040"
  },
  {
    "text": "infrastructure collocate it with the",
    "start": "954040",
    "end": "955920"
  },
  {
    "text": "application code that's using it um and",
    "start": "955920",
    "end": "958000"
  },
  {
    "text": "even completely eliminate the the",
    "start": "958000",
    "end": "959360"
  },
  {
    "text": "network",
    "start": "959360",
    "end": "960560"
  },
  {
    "text": "latency uh and then finally uh on the",
    "start": "960560",
    "end": "962920"
  },
  {
    "text": "cost front again just because this is",
    "start": "962920",
    "end": "964800"
  },
  {
    "text": "such a smaller model um you end up with",
    "start": "964800",
    "end": "966880"
  },
  {
    "text": "a much much lower cost uh and so that",
    "start": "966880",
    "end": "969319"
  },
  {
    "text": "for many of our customers is a big is",
    "start": "969319",
    "end": "972279"
  },
  {
    "text": "incredibly important is to be able to",
    "start": "972279",
    "end": "973519"
  },
  {
    "text": "get that performance number you need um",
    "start": "973519",
    "end": "975600"
  },
  {
    "text": "while still maintaining a relatively low",
    "start": "975600",
    "end": "977959"
  },
  {
    "text": "cost um in in method's case we were",
    "start": "977959",
    "end": "980360"
  },
  {
    "text": "actually able to far exceed the sort of",
    "start": "980360",
    "end": "981880"
  },
  {
    "text": "cost thresholds that they were looking",
    "start": "981880",
    "end": "983279"
  },
  {
    "text": "for to make this viable um which means",
    "start": "983279",
    "end": "985399"
  },
  {
    "text": "that they don't have to worry about this",
    "start": "985399",
    "end": "986639"
  },
  {
    "text": "from sort of a unit economics point of",
    "start": "986639",
    "end": "988040"
  },
  {
    "text": "view uh in in in the way that they did",
    "start": "988040",
    "end": "990319"
  },
  {
    "text": "when they were using the larger",
    "start": "990319",
    "end": "992319"
  },
  {
    "text": "models um so just um to sort of",
    "start": "992319",
    "end": "996240"
  },
  {
    "text": "reiterate what I started with before um",
    "start": "996240",
    "end": "999160"
  },
  {
    "text": "this is a power tool uh the fine tuning",
    "start": "999160",
    "end": "1001680"
  },
  {
    "text": "uh is it does take a fair amount of work",
    "start": "1001680",
    "end": "1004120"
  },
  {
    "text": "um not an extreme amount of work but",
    "start": "1004120",
    "end": "1005560"
  },
  {
    "text": "significantly more work than you do for",
    "start": "1005560",
    "end": "1007240"
  },
  {
    "text": "prompt",
    "start": "1007240",
    "end": "1008000"
  },
  {
    "text": "engineering however if you're not able",
    "start": "1008000",
    "end": "1010440"
  },
  {
    "text": "to get to the reliability numbers you",
    "start": "1010440",
    "end": "1012160"
  },
  {
    "text": "need uh through just prompt engineering",
    "start": "1012160",
    "end": "1014360"
  },
  {
    "text": "with the models that exist out there",
    "start": "1014360",
    "end": "1015920"
  },
  {
    "text": "without tuning it is a viable way to",
    "start": "1015920",
    "end": "1018399"
  },
  {
    "text": "very strong bend that price performance",
    "start": "1018399",
    "end": "1020800"
  },
  {
    "text": "curve and get to a much better place uh",
    "start": "1020800",
    "end": "1023120"
  },
  {
    "text": "which uh which which can help you get to",
    "start": "1023120",
    "end": "1024839"
  },
  {
    "text": "a very large scale in production just",
    "start": "1024839",
    "end": "1026199"
  },
  {
    "text": "like method",
    "start": "1026199",
    "end": "1028678"
  },
  {
    "text": "did nice um so yeah just to wrap up here",
    "start": "1029400",
    "end": "1033798"
  },
  {
    "text": "uh one thing that or at least a couple",
    "start": "1033799",
    "end": "1035918"
  },
  {
    "text": "couple points that we want to highlight",
    "start": "1035919",
    "end": "1037360"
  },
  {
    "text": "is that you know the reason we put two",
    "start": "1037360",
    "end": "1039640"
  },
  {
    "text": "engineers in the title is also because",
    "start": "1039640",
    "end": "1041839"
  },
  {
    "text": "it's not that it's not that complicated",
    "start": "1041839",
    "end": "1043839"
  },
  {
    "text": "right you can get away with using we",
    "start": "1043839",
    "end": "1045959"
  },
  {
    "text": "identified a specific use case and we",
    "start": "1045959",
    "end": "1048160"
  },
  {
    "text": "got away with just using the cheapest",
    "start": "1048160",
    "end": "1049480"
  },
  {
    "text": "model that was out there uh we",
    "start": "1049480",
    "end": "1050960"
  },
  {
    "text": "fine-tuned it we already had the data",
    "start": "1050960",
    "end": "1052799"
  },
  {
    "text": "from GPT in production so we already had",
    "start": "1052799",
    "end": "1054840"
  },
  {
    "text": "the data we didn't have to go digging",
    "start": "1054840",
    "end": "1055960"
  },
  {
    "text": "around for the data in the first place",
    "start": "1055960",
    "end": "1057880"
  },
  {
    "text": "uh so we already used that and we used",
    "start": "1057880",
    "end": "1059520"
  },
  {
    "text": "the cheapest model that gave us the",
    "start": "1059520",
    "end": "1060880"
  },
  {
    "text": "fastest performance and you know you",
    "start": "1060880",
    "end": "1062919"
  },
  {
    "text": "don't need to buy your own gpus um and",
    "start": "1062919",
    "end": "1066120"
  },
  {
    "text": "the the other thing that we realize is",
    "start": "1066120",
    "end": "1067600"
  },
  {
    "text": "that productionizing AI agents actually",
    "start": "1067600",
    "end": "1069960"
  },
  {
    "text": "requires a little bit of uh some level",
    "start": "1069960",
    "end": "1071840"
  },
  {
    "text": "of openness uh and patience from the",
    "start": "1071840",
    "end": "1073919"
  },
  {
    "text": "engineering team from the leadership",
    "start": "1073919",
    "end": "1075280"
  },
  {
    "text": "team is because when you write code",
    "start": "1075280",
    "end": "1077280"
  },
  {
    "text": "we're all used to writing code that just",
    "start": "1077280",
    "end": "1078640"
  },
  {
    "text": "work works you push out a feature and",
    "start": "1078640",
    "end": "1079840"
  },
  {
    "text": "never breaks because you're not changing",
    "start": "1079840",
    "end": "1081320"
  },
  {
    "text": "anything but with AI agents you it takes",
    "start": "1081320",
    "end": "1083840"
  },
  {
    "text": "some time to get to a point where it's",
    "start": "1083840",
    "end": "1085360"
  },
  {
    "text": "like production ready and actually gives",
    "start": "1085360",
    "end": "1087039"
  },
  {
    "text": "you the responses that you're looking",
    "start": "1087039",
    "end": "1089000"
  },
  {
    "text": "for um and you know I I feel compelled",
    "start": "1089000",
    "end": "1092200"
  },
  {
    "text": "to say something about as to Mark the",
    "start": "1092200",
    "end": "1094200"
  },
  {
    "text": "top of the traditional software",
    "start": "1094200",
    "end": "1095360"
  },
  {
    "text": "engineering job so I'll leave you with",
    "start": "1095360",
    "end": "1096720"
  },
  {
    "text": "these last few words if you're Inu pivot",
    "start": "1096720",
    "end": "1099200"
  },
  {
    "text": "to",
    "start": "1099200",
    "end": "1101320"
  },
  {
    "text": "AE thank you thanks everyone",
    "start": "1101840",
    "end": "1105130"
  },
  {
    "text": "[Music]",
    "start": "1105130",
    "end": "1123420"
  }
]
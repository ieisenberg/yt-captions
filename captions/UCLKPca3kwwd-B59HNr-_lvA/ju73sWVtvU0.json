[
  {
    "start": "0",
    "end": "42000"
  },
  {
    "text": "[Music]",
    "start": "1010",
    "end": "13859"
  },
  {
    "text": "excited to be here I agree with uh swix",
    "start": "15000",
    "end": "17760"
  },
  {
    "text": "and Ben that it feels like feels like a",
    "start": "17760",
    "end": "20680"
  },
  {
    "text": "moment it feels like a historical moment",
    "start": "20680",
    "end": "22800"
  },
  {
    "text": "here um my name is amjad I'm the",
    "start": "22800",
    "end": "25279"
  },
  {
    "text": "co-founder of repet where we aspire to",
    "start": "25279",
    "end": "27359"
  },
  {
    "text": "be the fastest way to get from an idea",
    "start": "27359",
    "end": "29720"
  },
  {
    "text": "to a deployed software that you can",
    "start": "29720",
    "end": "31759"
  },
  {
    "text": "scale so I'm going to take you back a",
    "start": "31759",
    "end": "33879"
  },
  {
    "text": "little bit not like swix to the 6 600 AD",
    "start": "33879",
    "end": "38079"
  },
  {
    "text": "but perhaps to the start of",
    "start": "38079",
    "end": "41680"
  },
  {
    "text": "computing all right so um very early",
    "start": "41680",
    "end": "44680"
  },
  {
    "start": "42000",
    "end": "142000"
  },
  {
    "text": "computers the eniac was the first your",
    "start": "44680",
    "end": "46440"
  },
  {
    "text": "in complete uh you know programmable uh",
    "start": "46440",
    "end": "49079"
  },
  {
    "text": "vum and machine computer the way you",
    "start": "49079",
    "end": "51239"
  },
  {
    "text": "programmed it is like you literally",
    "start": "51239",
    "end": "53079"
  },
  {
    "text": "punched cards um not physically but you",
    "start": "53079",
    "end": "56600"
  },
  {
    "text": "had a machine that sort of punched these",
    "start": "56600",
    "end": "58399"
  },
  {
    "text": "cards these are sort of binary code for",
    "start": "58399",
    "end": "60440"
  },
  {
    "text": "the machine to interpret it was really",
    "start": "60440",
    "end": "62440"
  },
  {
    "text": "hard there wasn't really a software",
    "start": "62440",
    "end": "64119"
  },
  {
    "text": "industry because this was really",
    "start": "64119",
    "end": "65680"
  },
  {
    "text": "difficult it automated some tasks that",
    "start": "65680",
    "end": "67439"
  },
  {
    "text": "human computers did at the time but it",
    "start": "67439",
    "end": "69960"
  },
  {
    "text": "wasn't this it didn't create the",
    "start": "69960",
    "end": "71640"
  },
  {
    "text": "software industry",
    "start": "71640",
    "end": "73040"
  },
  {
    "text": "yet but then we moved to text from from",
    "start": "73040",
    "end": "76240"
  },
  {
    "text": "Punch Cards and um we had First Assembly",
    "start": "76240",
    "end": "81040"
  },
  {
    "text": "and then we had compilers and higher",
    "start": "81040",
    "end": "83360"
  },
  {
    "text": "level languages such as C and then",
    "start": "83360",
    "end": "85720"
  },
  {
    "text": "someone invented JavaScript and it's all",
    "start": "85720",
    "end": "87520"
  },
  {
    "text": "been downhill since then uh",
    "start": "87520",
    "end": "91840"
  },
  {
    "text": "but tax editors were really or like tax",
    "start": "92159",
    "end": "94840"
  },
  {
    "text": "based programming was a minimum a 10x",
    "start": "94840",
    "end": "98000"
  },
  {
    "text": "Improvement if not 100 a Improvement in",
    "start": "98000",
    "end": "100200"
  },
  {
    "text": "programming so we've had these moments",
    "start": "100200",
    "end": "102280"
  },
  {
    "text": "where we've had orders of magnitude",
    "start": "102280",
    "end": "104600"
  },
  {
    "text": "improvements in programming",
    "start": "104600",
    "end": "107479"
  },
  {
    "text": "before and then you know the IDE became",
    "start": "107479",
    "end": "110079"
  },
  {
    "text": "a thing because you know we had large",
    "start": "110079",
    "end": "111399"
  },
  {
    "text": "scale software this is a screenshot from",
    "start": "111399",
    "end": "113759"
  },
  {
    "text": "like 2017 or 18 when we added LSP uh to",
    "start": "113759",
    "end": "118479"
  },
  {
    "text": "every programming environment on repet",
    "start": "118479",
    "end": "120920"
  },
  {
    "text": "so anyone with an account can get",
    "start": "120920",
    "end": "123640"
  },
  {
    "text": "intelligence and we're really proud",
    "start": "123640",
    "end": "125600"
  },
  {
    "text": "about that at the time we're burning a",
    "start": "125600",
    "end": "127920"
  },
  {
    "text": "lot of CPU doing sort of inference and",
    "start": "127920",
    "end": "131000"
  },
  {
    "text": "you know if you've run typescript server",
    "start": "131000",
    "end": "132920"
  },
  {
    "text": "that's like a lot of ram but we were",
    "start": "132920",
    "end": "135000"
  },
  {
    "text": "really proud that we're giving everyone",
    "start": "135000",
    "end": "136720"
  },
  {
    "text": "in the world tools to create",
    "start": "136720",
    "end": "138480"
  },
  {
    "text": "professional grade",
    "start": "138480",
    "end": "141400"
  },
  {
    "start": "142000",
    "end": "269000"
  },
  {
    "text": "software about 3 four years ago we",
    "start": "142560",
    "end": "146239"
  },
  {
    "text": "started kind of thinking about how AI",
    "start": "146239",
    "end": "148519"
  },
  {
    "text": "could change software it started much",
    "start": "148519",
    "end": "150959"
  },
  {
    "text": "sooner than that but with the with gpt2",
    "start": "150959",
    "end": "154120"
  },
  {
    "text": "you know you could sort of kind of you",
    "start": "154120",
    "end": "157000"
  },
  {
    "text": "know give it some code and kind of",
    "start": "157000",
    "end": "158239"
  },
  {
    "text": "completes part of it you're like okay",
    "start": "158239",
    "end": "160080"
  },
  {
    "text": "this this thing is actually happening",
    "start": "160080",
    "end": "162040"
  },
  {
    "text": "and we we better be part of it and so we",
    "start": "162040",
    "end": "164319"
  },
  {
    "text": "started building and we built this uh",
    "start": "164319",
    "end": "166560"
  },
  {
    "text": "product called uh Ghost Rider uh which",
    "start": "166560",
    "end": "170319"
  },
  {
    "text": "does autocomplete chat and all sorts of",
    "start": "170319",
    "end": "172360"
  },
  {
    "text": "things inside the",
    "start": "172360",
    "end": "175280"
  },
  {
    "text": "IDE and in just those two years I mean",
    "start": "175640",
    "end": "179360"
  },
  {
    "text": "the the pace of progress across the",
    "start": "179360",
    "end": "181200"
  },
  {
    "text": "industry the tools basically AI you know",
    "start": "181200",
    "end": "184760"
  },
  {
    "text": "was deployed um and a lot of different",
    "start": "184760",
    "end": "187400"
  },
  {
    "text": "Engineers were using it the AI enhanced",
    "start": "187400",
    "end": "190159"
  },
  {
    "text": "engineer as swix kind of called it",
    "start": "190159",
    "end": "193080"
  },
  {
    "text": "everyone is sort of using these tools",
    "start": "193080",
    "end": "194640"
  },
  {
    "text": "and so uh we have a world now where a",
    "start": "194640",
    "end": "197120"
  },
  {
    "text": "lot of people are gaining huge amount of",
    "start": "197120",
    "end": "199599"
  },
  {
    "text": "productivity Improvement I don't think",
    "start": "199599",
    "end": "201400"
  },
  {
    "text": "we're at a mold magnitude Improvement",
    "start": "201400",
    "end": "204280"
  },
  {
    "text": "yet we're probably in the 50 80 perhaps",
    "start": "204280",
    "end": "207840"
  },
  {
    "text": "100% Improvement for some people but",
    "start": "207840",
    "end": "210080"
  },
  {
    "text": "we're still at the start of this and we",
    "start": "210080",
    "end": "212519"
  },
  {
    "text": "think that's going to going to be 10x",
    "start": "212519",
    "end": "214879"
  },
  {
    "text": "100x perhaps a th thousand X over the",
    "start": "214879",
    "end": "217159"
  },
  {
    "text": "next decade the problem however repas",
    "start": "217159",
    "end": "220159"
  },
  {
    "text": "Mission has always been about access our",
    "start": "220159",
    "end": "222519"
  },
  {
    "text": "mission is to uh empower the next",
    "start": "222519",
    "end": "224879"
  },
  {
    "text": "billion developers and so we really",
    "start": "224879",
    "end": "227280"
  },
  {
    "text": "didn't want to create this world where",
    "start": "227280",
    "end": "229799"
  },
  {
    "text": "some people have access to Ghost Rider",
    "start": "229799",
    "end": "231519"
  },
  {
    "text": "and other people don't have access to it",
    "start": "231519",
    "end": "234360"
  },
  {
    "text": "and we started thinking about okay what",
    "start": "234360",
    "end": "235760"
  },
  {
    "text": "is it if if you really take into heart",
    "start": "235760",
    "end": "238879"
  },
  {
    "text": "everything that they AI engineer",
    "start": "238879",
    "end": "240360"
  },
  {
    "text": "conferences about that we're at a moment",
    "start": "240360",
    "end": "242680"
  },
  {
    "text": "where software is changing where AI is",
    "start": "242680",
    "end": "244439"
  },
  {
    "text": "going to be part of the software stack",
    "start": "244439",
    "end": "246360"
  },
  {
    "text": "then you have to really step back a",
    "start": "246360",
    "end": "247720"
  },
  {
    "text": "little bit and try to rethink how",
    "start": "247720",
    "end": "249720"
  },
  {
    "text": "programming changes so our view is these",
    "start": "249720",
    "end": "253000"
  },
  {
    "text": "programming add-ons such as co-pilot and",
    "start": "253000",
    "end": "255680"
  },
  {
    "text": "coding Ghost Rider and all these things",
    "start": "255680",
    "end": "257359"
  },
  {
    "text": "we're giving them cute names we think",
    "start": "257359",
    "end": "260400"
  },
  {
    "text": "that's not the way forward we think that",
    "start": "260400",
    "end": "262079"
  },
  {
    "text": "AI needs to be really infused in every",
    "start": "262079",
    "end": "264919"
  },
  {
    "text": "programming interaction that you have",
    "start": "264919",
    "end": "267199"
  },
  {
    "text": "and it needs to be part of the default",
    "start": "267199",
    "end": "268840"
  },
  {
    "text": "experience of rep and I'm sure other",
    "start": "268840",
    "end": "270600"
  },
  {
    "start": "269000",
    "end": "393000"
  },
  {
    "text": "products in the future that's why we're",
    "start": "270600",
    "end": "272360"
  },
  {
    "text": "announcing today that we're giving AI",
    "start": "272360",
    "end": "274600"
  },
  {
    "text": "for our millions of users that are",
    "start": "274600",
    "end": "276280"
  },
  {
    "text": "coding on repet and so we think this is",
    "start": "276280",
    "end": "279080"
  },
  {
    "text": "going to be the the biggest deployment",
    "start": "279080",
    "end": "281960"
  },
  {
    "text": "of um AI enhanced uh coding in the world",
    "start": "281960",
    "end": "286400"
  },
  {
    "text": "uh we're going to be burning as much GPU",
    "start": "286400",
    "end": "288479"
  },
  {
    "text": "as we're burning CPU so pray for us",
    "start": "288479",
    "end": "294080"
  },
  {
    "text": "uh",
    "start": "298560",
    "end": "301560"
  },
  {
    "text": "we have people all over the world coding",
    "start": "302520",
    "end": "305039"
  },
  {
    "text": "on all sorts of devices we have people",
    "start": "305039",
    "end": "306800"
  },
  {
    "text": "coding on Android phones uh and and",
    "start": "306800",
    "end": "309759"
  },
  {
    "text": "they're all going to get AI now so",
    "start": "309759",
    "end": "311320"
  },
  {
    "text": "they're all going to be AI enhanced",
    "start": "311320",
    "end": "313320"
  },
  {
    "text": "Engineers but you know as T showed is",
    "start": "313320",
    "end": "316000"
  },
  {
    "text": "it's not just about AI enhanced",
    "start": "316000",
    "end": "318160"
  },
  {
    "text": "engineering there's also product so AI",
    "start": "318160",
    "end": "321639"
  },
  {
    "text": "being part of the software creation",
    "start": "321639",
    "end": "323080"
  },
  {
    "text": "stack makes sense but AI part of the",
    "start": "323080",
    "end": "325240"
  },
  {
    "text": "call stack is also where a lot of value",
    "start": "325240",
    "end": "327600"
  },
  {
    "text": "is created so uh",
    "start": "327600",
    "end": "330240"
  },
  {
    "text": "um uh so that's why we're also we have",
    "start": "330240",
    "end": "334280"
  },
  {
    "text": "this new product called Model farm and",
    "start": "334280",
    "end": "336600"
  },
  {
    "text": "model Farm basically gives you access to",
    "start": "336600",
    "end": "340560"
  },
  {
    "text": "um uh models right into your IDE so all",
    "start": "340560",
    "end": "343520"
  },
  {
    "text": "it takes is three lines of code to start",
    "start": "343520",
    "end": "345280"
  },
  {
    "text": "doing inference we launched with Google",
    "start": "345280",
    "end": "347919"
  },
  {
    "text": "Cloud uh llms but we're adding uh llama",
    "start": "347919",
    "end": "352639"
  },
  {
    "text": "uh pretty soon we're adding uh stable",
    "start": "352639",
    "end": "354360"
  },
  {
    "text": "diffusion and if you if you're an LM",
    "start": "354360",
    "end": "356800"
  },
  {
    "text": "provider and want to work with us and",
    "start": "356800",
    "end": "358280"
  },
  {
    "text": "provide this on our platform would love",
    "start": "358280",
    "end": "359960"
  },
  {
    "text": "to talk to you but basically um everyone",
    "start": "359960",
    "end": "363560"
  },
  {
    "text": "will get uh there's some free tier here",
    "start": "363560",
    "end": "366160"
  },
  {
    "text": "everyone will get free access at least",
    "start": "366160",
    "end": "368199"
  },
  {
    "text": "until the end of the year uh to model",
    "start": "368199",
    "end": "370319"
  },
  {
    "text": "form so you can start doing inference",
    "start": "370319",
    "end": "372479"
  },
  {
    "text": "and start building AI based",
    "start": "372479",
    "end": "375880"
  },
  {
    "text": "products so uh next up I'm going to",
    "start": "376039",
    "end": "378360"
  },
  {
    "text": "bring up uh my colleague the head of",
    "start": "378360",
    "end": "380560"
  },
  {
    "text": "aiet Mel kasta to talk about how we",
    "start": "380560",
    "end": "384080"
  },
  {
    "text": "train our own AI models and we have uh",
    "start": "384080",
    "end": "386440"
  },
  {
    "text": "one more announcement for you coming up",
    "start": "386440",
    "end": "389650"
  },
  {
    "text": "[Applause]",
    "start": "389650",
    "end": "393490"
  },
  {
    "start": "393000",
    "end": "449000"
  },
  {
    "text": "[Music]",
    "start": "393490",
    "end": "398470"
  },
  {
    "text": "[Music]",
    "start": "401680",
    "end": "403800"
  },
  {
    "text": "do you that",
    "start": "403800",
    "end": "405680"
  },
  {
    "text": "clicker F thank you all right hi",
    "start": "405680",
    "end": "409639"
  },
  {
    "text": "everyone so today I'm going to be",
    "start": "409639",
    "end": "411360"
  },
  {
    "text": "talking about how we're training llm for",
    "start": "411360",
    "end": "413720"
  },
  {
    "text": "coded replit and I will explain why this",
    "start": "413720",
    "end": "416840"
  },
  {
    "text": "weird title uh if you been around",
    "start": "416840",
    "end": "418720"
  },
  {
    "text": "Twitter I think a bit more than a month",
    "start": "418720",
    "end": "421039"
  },
  {
    "text": "ago you you must have read this study",
    "start": "421039",
    "end": "423280"
  },
  {
    "text": "from semi analysis and their point was",
    "start": "423280",
    "end": "426440"
  },
  {
    "text": "it's meaningless to work on small models",
    "start": "426440",
    "end": "429400"
  },
  {
    "text": "training on us you know a limited amount",
    "start": "429400",
    "end": "431720"
  },
  {
    "text": "of gpus and that came as a shock to us",
    "start": "431720",
    "end": "434240"
  },
  {
    "text": "because we had a very good success story",
    "start": "434240",
    "end": "436479"
  },
  {
    "text": "back in May where we started to train",
    "start": "436479",
    "end": "438400"
  },
  {
    "text": "our models from scratch and then you",
    "start": "438400",
    "end": "440840"
  },
  {
    "text": "know ham Jad and I and the team started",
    "start": "440840",
    "end": "443120"
  },
  {
    "text": "to think are we really wasting our time",
    "start": "443120",
    "end": "445360"
  },
  {
    "text": "here um I'm going to try to convince you",
    "start": "445360",
    "end": "447599"
  },
  {
    "text": "it's actually is not the case so our",
    "start": "447599",
    "end": "450680"
  },
  {
    "start": "449000",
    "end": "519000"
  },
  {
    "text": "code completion feature or repet is",
    "start": "450680",
    "end": "453360"
  },
  {
    "text": "powered by our own Boke large language",
    "start": "453360",
    "end": "455599"
  },
  {
    "text": "model we training open source code both",
    "start": "455599",
    "end": "458440"
  },
  {
    "text": "published on GitHub and also developed",
    "start": "458440",
    "end": "460800"
  },
  {
    "text": "by the rapit user base it's a very low",
    "start": "460800",
    "end": "463479"
  },
  {
    "text": "latency feature so we try to find a",
    "start": "463479",
    "end": "465440"
  },
  {
    "text": "different with spot compared to what you",
    "start": "465440",
    "end": "467360"
  },
  {
    "text": "might be used with other plugins we try",
    "start": "467360",
    "end": "469360"
  },
  {
    "text": "to keep our P95 latency below 250",
    "start": "469360",
    "end": "472000"
  },
  {
    "text": "milliseconds such as the developer",
    "start": "472000",
    "end": "474199"
  },
  {
    "text": "experience is almost instantaneous you",
    "start": "474199",
    "end": "475960"
  },
  {
    "text": "don't even have to think about it and",
    "start": "475960",
    "end": "477479"
  },
  {
    "text": "the code is going to be completed for",
    "start": "477479",
    "end": "478840"
  },
  {
    "text": "you at the model size that we were using",
    "start": "478840",
    "end": "481800"
  },
  {
    "text": "we have been St of the art across the",
    "start": "481800",
    "end": "483720"
  },
  {
    "text": "past few months and let's do a show",
    "start": "483720",
    "end": "487720"
  },
  {
    "text": "hands who has heard about our V1 model",
    "start": "487720",
    "end": "490919"
  },
  {
    "text": "back in",
    "start": "490919",
    "end": "491840"
  },
  {
    "text": "May all right that feels",
    "start": "491840",
    "end": "494400"
  },
  {
    "text": "good for a second I feel like an AI star",
    "start": "494400",
    "end": "497520"
  },
  {
    "text": "uh jokes aside so we released rapid code",
    "start": "497520",
    "end": "499919"
  },
  {
    "text": "V1 3B uh back in may we got a lot of",
    "start": "499919",
    "end": "502479"
  },
  {
    "text": "adoption a lot of love and also a lot of",
    "start": "502479",
    "end": "504960"
  },
  {
    "text": "contribution and that's one of the key",
    "start": "504960",
    "end": "506879"
  },
  {
    "text": "reasons why we decided to give it back",
    "start": "506879",
    "end": "509400"
  },
  {
    "text": "uh rapid history has been built on the",
    "start": "509400",
    "end": "511759"
  },
  {
    "text": "on the shoulders of giants of all the",
    "start": "511759",
    "end": "513640"
  },
  {
    "text": "people contributing to the open source",
    "start": "513640",
    "end": "515599"
  },
  {
    "text": "space so we thought we should do exactly",
    "start": "515599",
    "end": "517760"
  },
  {
    "text": "the same here we should give back our",
    "start": "517760",
    "end": "519279"
  },
  {
    "start": "519000",
    "end": "825000"
  },
  {
    "text": "model and today I'm going to be",
    "start": "519279",
    "end": "521839"
  },
  {
    "text": "announcing rapid code B 1.5 3B so the",
    "start": "521839",
    "end": "525480"
  },
  {
    "text": "evolution of the model that we we",
    "start": "525480",
    "end": "527399"
  },
  {
    "text": "released back in",
    "start": "527399",
    "end": "529240"
  },
  {
    "text": "May let's go in detail as amjad was",
    "start": "529240",
    "end": "532040"
  },
  {
    "text": "saying so the next 10 minutes we're",
    "start": "532040",
    "end": "533519"
  },
  {
    "text": "going to do a technical Deep dive and",
    "start": "533519",
    "end": "535080"
  },
  {
    "text": "I'm going to tell you how we built it",
    "start": "535080",
    "end": "536880"
  },
  {
    "text": "and why it's so powerful so first of all",
    "start": "536880",
    "end": "539680"
  },
  {
    "text": "we follow a slightly different recipe",
    "start": "539680",
    "end": "541480"
  },
  {
    "text": "compared to the last time if you recall",
    "start": "541480",
    "end": "543800"
  },
  {
    "text": "back in May our Wei W was a llama style",
    "start": "543800",
    "end": "546959"
  },
  {
    "text": "uh code model which means we follow a",
    "start": "546959",
    "end": "549279"
  },
  {
    "text": "lot of the best recipes that meta",
    "start": "549279",
    "end": "550959"
  },
  {
    "text": "pioneered uh now we went you know one",
    "start": "550959",
    "end": "553880"
  },
  {
    "text": "level up and we are training up to 300",
    "start": "553880",
    "end": "556440"
  },
  {
    "text": "tokens per parameter so if you have been",
    "start": "556440",
    "end": "558560"
  },
  {
    "text": "following a bit history of llms even in",
    "start": "558560",
    "end": "561120"
  },
  {
    "text": "you know two years ago most of the",
    "start": "561120",
    "end": "562959"
  },
  {
    "text": "models were under Trin pardon me for the",
    "start": "562959",
    "end": "565760"
  },
  {
    "text": "for the word it's not exactly you know",
    "start": "565760",
    "end": "567519"
  },
  {
    "text": "technically speaking is not correct but",
    "start": "567519",
    "end": "569839"
  },
  {
    "text": "the truth is you know uh mid 2022 the",
    "start": "569839",
    "end": "572920"
  },
  {
    "text": "chinchilla paper from Deep Mind came out",
    "start": "572920",
    "end": "574760"
  },
  {
    "text": "and it was like a bit warning for the",
    "start": "574760",
    "end": "576480"
  },
  {
    "text": "old field basically what the paper tells",
    "start": "576480",
    "end": "578519"
  },
  {
    "text": "us is that we are under training of our",
    "start": "578519",
    "end": "580279"
  },
  {
    "text": "models we should give them way more high",
    "start": "580279",
    "end": "582480"
  },
  {
    "text": "quality data and in exchange we could",
    "start": "582480",
    "end": "584519"
  },
  {
    "text": "train smaller models so in a sense we're",
    "start": "584519",
    "end": "587000"
  },
  {
    "text": "amortizing training time for inference",
    "start": "587000",
    "end": "589519"
  },
  {
    "text": "time spending more compute to train a",
    "start": "589519",
    "end": "591440"
  },
  {
    "text": "smaller more powerful model and then at",
    "start": "591440",
    "end": "593839"
  },
  {
    "text": "inference time the latency will be lower",
    "start": "593839",
    "end": "596040"
  },
  {
    "text": "and that's the key inside that we're",
    "start": "596040",
    "end": "597680"
  },
  {
    "text": "going to be carrying along you know this",
    "start": "597680",
    "end": "599800"
  },
  {
    "text": "keynote today now conver differently",
    "start": "599800",
    "end": "603160"
  },
  {
    "text": "from the V1 this time we also double the",
    "start": "603160",
    "end": "605680"
  },
  {
    "text": "amount of high quality data so we train",
    "start": "605680",
    "end": "607440"
  },
  {
    "text": "it up to 1 trillion tokens of code it's",
    "start": "607440",
    "end": "610600"
  },
  {
    "text": "the data mixture is roughly 200 billion",
    "start": "610600",
    "end": "612680"
  },
  {
    "text": "tokens across five EPO plus a linear",
    "start": "612680",
    "end": "615480"
  },
  {
    "text": "cool down at the end that really allows",
    "start": "615480",
    "end": "617120"
  },
  {
    "text": "us to squeeze the best possible",
    "start": "617120",
    "end": "618640"
  },
  {
    "text": "performance for the model and Rapid code",
    "start": "618640",
    "end": "621519"
  },
  {
    "text": "B 1.5 this time supports 30 programming",
    "start": "621519",
    "end": "624279"
  },
  {
    "text": "languages and we also added a mixture",
    "start": "624279",
    "end": "627200"
  },
  {
    "text": "coming from Stock Exchange posts that",
    "start": "627200",
    "end": "629680"
  },
  {
    "text": "are oriented towards developers so",
    "start": "629680",
    "end": "632560"
  },
  {
    "text": "questions about coding questions about",
    "start": "632560",
    "end": "634800"
  },
  {
    "text": "software engineering and so forth so",
    "start": "634800",
    "end": "636720"
  },
  {
    "text": "this is the basis of our data now let's",
    "start": "636720",
    "end": "639680"
  },
  {
    "text": "go and take a look inside at the data",
    "start": "639680",
    "end": "641560"
  },
  {
    "text": "set that we used so we started from the",
    "start": "641560",
    "end": "643839"
  },
  {
    "text": "stack which is an initiative led by big",
    "start": "643839",
    "end": "646440"
  },
  {
    "text": "code it's a group you know 100 the hugin",
    "start": "646440",
    "end": "648320"
  },
  {
    "text": "face umbrella uh very uh grateful about",
    "start": "648320",
    "end": "651600"
  },
  {
    "text": "the work that these people have been",
    "start": "651600",
    "end": "652720"
  },
  {
    "text": "doing basically they have built a big",
    "start": "652720",
    "end": "654959"
  },
  {
    "text": "pipeline getting data from GitHub",
    "start": "654959",
    "end": "657600"
  },
  {
    "text": "selecting top repositories is cleaning",
    "start": "657600",
    "end": "659839"
  },
  {
    "text": "up part of the data and then especially",
    "start": "659839",
    "end": "661760"
  },
  {
    "text": "leaving only code that is licensed under",
    "start": "661760",
    "end": "664519"
  },
  {
    "text": "permissive licenses such as MIT uh BSD",
    "start": "664519",
    "end": "667800"
  },
  {
    "text": "Apachi 2 and so forth out of this",
    "start": "667800",
    "end": "670360"
  },
  {
    "text": "mixture we selected 30 top languages and",
    "start": "670360",
    "end": "673920"
  },
  {
    "text": "then really the key secret ingredient",
    "start": "673920",
    "end": "677760"
  },
  {
    "text": "here is how much time we spent on",
    "start": "677760",
    "end": "680120"
  },
  {
    "text": "working on the data you must have been",
    "start": "680120",
    "end": "682160"
  },
  {
    "text": "hearing this again and again and every",
    "start": "682160",
    "end": "683639"
  },
  {
    "text": "time you go to an llm talk there is a go",
    "start": "683639",
    "end": "685440"
  },
  {
    "text": "stage saying you should pay attention",
    "start": "685440",
    "end": "687399"
  },
  {
    "text": "about the data quality uh here to tell",
    "start": "687399",
    "end": "689440"
  },
  {
    "text": "you exactly the same once again that's",
    "start": "689440",
    "end": "691000"
  },
  {
    "text": "probably the most important thing that",
    "start": "691000",
    "end": "692519"
  },
  {
    "text": "you could be spending your time on",
    "start": "692519",
    "end": "694360"
  },
  {
    "text": "especially because the model I'm talking",
    "start": "694360",
    "end": "696040"
  },
  {
    "text": "about today is trained from scratch so",
    "start": "696040",
    "end": "698399"
  },
  {
    "text": "this is not a fine-tuning all the models",
    "start": "698399",
    "end": "700399"
  },
  {
    "text": "that we release have been trained from",
    "start": "700399",
    "end": "701959"
  },
  {
    "text": "the very first token prepared by us so",
    "start": "701959",
    "end": "704279"
  },
  {
    "text": "it's extremely important to have high uh",
    "start": "704279",
    "end": "706800"
  },
  {
    "text": "data quality so we we took inspiration",
    "start": "706800",
    "end": "709959"
  },
  {
    "text": "from the initial quality pipelines built",
    "start": "709959",
    "end": "712279"
  },
  {
    "text": "by codex by the pound paper and then we",
    "start": "712279",
    "end": "714959"
  },
  {
    "text": "applied way more tics there so we're",
    "start": "714959",
    "end": "717519"
  },
  {
    "text": "filtering for code that is being",
    "start": "717519",
    "end": "718959"
  },
  {
    "text": "autogenerated minified nonp Parable",
    "start": "718959",
    "end": "721920"
  },
  {
    "text": "basically all the code that you wouldn't",
    "start": "721920",
    "end": "723440"
  },
  {
    "text": "want your model to recommend back to you",
    "start": "723440",
    "end": "725519"
  },
  {
    "text": "because it's not something that you will",
    "start": "725519",
    "end": "727079"
  },
  {
    "text": "be writing yourself we also remove toxic",
    "start": "727079",
    "end": "729880"
  },
  {
    "text": "content and all this pipeline have be",
    "start": "729880",
    "end": "732200"
  },
  {
    "text": "built on spark so I'm trying to",
    "start": "732200",
    "end": "734040"
  },
  {
    "text": "encourage you to also think of working",
    "start": "734040",
    "end": "736199"
  },
  {
    "text": "on your own models because pretty much a",
    "start": "736199",
    "end": "738560"
  },
  {
    "text": "lot of the base components are out there",
    "start": "738560",
    "end": "741040"
  },
  {
    "text": "available open source so you you could",
    "start": "741040",
    "end": "742680"
  },
  {
    "text": "really build the whole pipeline to train",
    "start": "742680",
    "end": "745079"
  },
  {
    "text": "and serve an llm with a lot of Open",
    "start": "745079",
    "end": "747440"
  },
  {
    "text": "Source components and as we was saying",
    "start": "747440",
    "end": "749720"
  },
  {
    "text": "you have seen this CRA acceleration in",
    "start": "749720",
    "end": "751480"
  },
  {
    "text": "the last 9 months if you wanted to do",
    "start": "751480",
    "end": "753440"
  },
  {
    "text": "this in 2022 good luck with that uh it",
    "start": "753440",
    "end": "756519"
  },
  {
    "text": "feels like we're a decade ahead compared",
    "start": "756519",
    "end": "758279"
  },
  {
    "text": "to last year so it's pretty amazing and",
    "start": "758279",
    "end": "760279"
  },
  {
    "text": "I didn't even exp in myself the speed to",
    "start": "760279",
    "end": "762600"
  },
  {
    "text": "move this fast the other inside that we",
    "start": "762600",
    "end": "766320"
  },
  {
    "text": "can of pioneer for the our V1 model and",
    "start": "766320",
    "end": "769199"
  },
  {
    "text": "turns out to be very powerful also for",
    "start": "769199",
    "end": "771199"
  },
  {
    "text": "this new one so when we released the V1",
    "start": "771199",
    "end": "774360"
  },
  {
    "text": "uh few weeks after coincidentally a very",
    "start": "774360",
    "end": "777120"
  },
  {
    "text": "interesting paper has been published",
    "start": "777120",
    "end": "778600"
  },
  {
    "text": "called scaling data constraint language",
    "start": "778600",
    "end": "780519"
  },
  {
    "text": "models and I highly recommend it it's a",
    "start": "780519",
    "end": "783000"
  },
  {
    "text": "it's a great read and it's probably one",
    "start": "783000",
    "end": "784639"
  },
  {
    "text": "of the most interesting results in LM in",
    "start": "784639",
    "end": "787480"
  },
  {
    "text": "my opinion and this intuition allowed us",
    "start": "787480",
    "end": "790199"
  },
  {
    "text": "to basically train the model to",
    "start": "790199",
    "end": "791720"
  },
  {
    "text": "completion rather than making trade-offs",
    "start": "791720",
    "end": "794240"
  },
  {
    "text": "on the data quality it allowed us to",
    "start": "794240",
    "end": "796360"
  },
  {
    "text": "select a small high quality subset of",
    "start": "796360",
    "end": "798680"
  },
  {
    "text": "data and then repeat it several times",
    "start": "798680",
    "end": "801040"
  },
  {
    "text": "the key funding of this paper is",
    "start": "801040",
    "end": "802279"
  },
  {
    "text": "basically in this two plots I'm going to",
    "start": "802279",
    "end": "803680"
  },
  {
    "text": "be sharing the slid so you know you can",
    "start": "803680",
    "end": "805040"
  },
  {
    "text": "go and check the links and the idea is",
    "start": "805040",
    "end": "807199"
  },
  {
    "text": "your loss curve after you repeat data",
    "start": "807199",
    "end": "809480"
  },
  {
    "text": "four or five times is going to be",
    "start": "809480",
    "end": "811440"
  },
  {
    "text": "comparable to training on a novel data",
    "start": "811440",
    "end": "813600"
  },
  {
    "text": "set okay now not only this is very",
    "start": "813600",
    "end": "816199"
  },
  {
    "text": "useful because it allow us to work only",
    "start": "816199",
    "end": "818120"
  },
  {
    "text": "on high quality data it also allowed us",
    "start": "818120",
    "end": "820120"
  },
  {
    "text": "to work with data that is exclusively",
    "start": "820120",
    "end": "822440"
  },
  {
    "text": "released under permissive license",
    "start": "822440",
    "end": "824560"
  },
  {
    "text": "therefore once again for our 1.5 model",
    "start": "824560",
    "end": "828120"
  },
  {
    "start": "825000",
    "end": "846000"
  },
  {
    "text": "we're going to be releasing it open",
    "start": "828120",
    "end": "829519"
  },
  {
    "text": "source and it's going to be released",
    "start": "829519",
    "end": "831160"
  },
  {
    "text": "with a permiss commercially permissive",
    "start": "831160",
    "end": "832920"
  },
  {
    "text": "license so you can use it there we",
    "start": "832920",
    "end": "837560"
  },
  {
    "text": "go",
    "start": "837759",
    "end": "840759"
  },
  {
    "text": "just shoot us an email when you use it",
    "start": "840839",
    "end": "842440"
  },
  {
    "text": "because I'm very",
    "start": "842440",
    "end": "844120"
  },
  {
    "text": "curious if you're having a good time so",
    "start": "844120",
    "end": "846800"
  },
  {
    "start": "846000",
    "end": "926000"
  },
  {
    "text": "details about the model training we",
    "start": "846800",
    "end": "848240"
  },
  {
    "text": "change a few things here and there",
    "start": "848240",
    "end": "849800"
  },
  {
    "text": "slightly larger model it's a 3.3 B uh",
    "start": "849800",
    "end": "852360"
  },
  {
    "text": "it's 4K context the old one was a 2K we",
    "start": "852360",
    "end": "855839"
  },
  {
    "text": "train a new domain specific vocabulary",
    "start": "855839",
    "end": "857920"
  },
  {
    "text": "32k so a small one uh it it helps us to",
    "start": "857920",
    "end": "861600"
  },
  {
    "text": "achieve even higher compression on the",
    "start": "861600",
    "end": "863959"
  },
  {
    "text": "data uh if youve been reading again",
    "start": "863959",
    "end": "865720"
  },
  {
    "text": "about llms you know that in a simplistic",
    "start": "865720",
    "end": "868279"
  },
  {
    "text": "from a placing point of view they are",
    "start": "868279",
    "end": "869759"
  },
  {
    "text": "data compressors losty data compressors",
    "start": "869759",
    "end": "871920"
  },
  {
    "text": "so if your vocabulary allows you to get",
    "start": "871920",
    "end": "874120"
  },
  {
    "text": "to pack even more data on fewer tokens",
    "start": "874120",
    "end": "877040"
  },
  {
    "text": "then you're basically bringing more",
    "start": "877040",
    "end": "878320"
  },
  {
    "text": "signal to the model while you're",
    "start": "878320",
    "end": "879560"
  },
  {
    "text": "training and with this new vocabulary",
    "start": "879560",
    "end": "881279"
  },
  {
    "text": "we're squeezing you know few percents",
    "start": "881279",
    "end": "882800"
  },
  {
    "text": "extra and it's a better vocabulary for",
    "start": "882800",
    "end": "884880"
  },
  {
    "text": "code compared to what star coder or code",
    "start": "884880",
    "end": "886959"
  },
  {
    "text": "Lam are using today we trained 128 h180",
    "start": "886959",
    "end": "891279"
  },
  {
    "text": "gigs gpus which are as rare as you know",
    "start": "891279",
    "end": "894519"
  },
  {
    "text": "gold at this point we have been on the",
    "start": "894519",
    "end": "896800"
  },
  {
    "text": "Mosaic platform for a week",
    "start": "896800",
    "end": "899279"
  },
  {
    "text": "and to our knowledge this is the first",
    "start": "899279",
    "end": "901680"
  },
  {
    "text": "model officially announced to be train",
    "start": "901680",
    "end": "903279"
  },
  {
    "text": "on h100s and release open source so",
    "start": "903279",
    "end": "905639"
  },
  {
    "text": "we're very excited about it and we",
    "start": "905639",
    "end": "908519"
  },
  {
    "text": "follow a list of llm best practices so",
    "start": "908519",
    "end": "911560"
  },
  {
    "text": "of course we support flesh attention we",
    "start": "911560",
    "end": "913480"
  },
  {
    "text": "have group CER attention which allow us",
    "start": "913480",
    "end": "915519"
  },
  {
    "text": "to achieve better inference performance",
    "start": "915519",
    "end": "918440"
  },
  {
    "text": "alabi position embedding latest",
    "start": "918440",
    "end": "920639"
  },
  {
    "text": "optimizers in the game and that you know",
    "start": "920639",
    "end": "922720"
  },
  {
    "text": "is really the reason why at the end you",
    "start": "922720",
    "end": "924320"
  },
  {
    "text": "will see very exciting numbers that I",
    "start": "924320",
    "end": "926199"
  },
  {
    "start": "926000",
    "end": "1051000"
  },
  {
    "text": "don't want to spoil right away so let's",
    "start": "926199",
    "end": "928040"
  },
  {
    "text": "start from the Bas model and then there",
    "start": "928040",
    "end": "930160"
  },
  {
    "text": "is surprise coming um this is the",
    "start": "930160",
    "end": "933279"
  },
  {
    "text": "evaluation P one on human eval for those",
    "start": "933279",
    "end": "935959"
  },
  {
    "text": "of you who never heard about it human",
    "start": "935959",
    "end": "937839"
  },
  {
    "text": "Val is a benchmark L back in 2021 AI if",
    "start": "937839",
    "end": "940959"
  },
  {
    "text": "I Rec correctly the format is the",
    "start": "940959",
    "end": "943000"
  },
  {
    "text": "following you have a natural language",
    "start": "943000",
    "end": "944639"
  },
  {
    "text": "description of a task in English and",
    "start": "944639",
    "end": "947040"
  },
  {
    "text": "then expect the model to generate a self",
    "start": "947040",
    "end": "949959"
  },
  {
    "text": "a self-contained python snippet then",
    "start": "949959",
    "end": "952639"
  },
  {
    "text": "then is going to be tested with a test",
    "start": "952639",
    "end": "954279"
  },
  {
    "text": "harness so you generate code and then",
    "start": "954279",
    "end": "957000"
  },
  {
    "text": "you execute it and you see if the if the",
    "start": "957000",
    "end": "959160"
  },
  {
    "text": "values uh in output are exactly what you",
    "start": "959160",
    "end": "961639"
  },
  {
    "text": "expect now an interesting evolution in",
    "start": "961639",
    "end": "963959"
  },
  {
    "text": "the last few months in the field is we",
    "start": "963959",
    "end": "965959"
  },
  {
    "text": "were not content on benchmarking",
    "start": "965959",
    "end": "968639"
  },
  {
    "text": "exclusively on python so we're also",
    "start": "968639",
    "end": "970639"
  },
  {
    "text": "doing that across several different",
    "start": "970639",
    "end": "972639"
  },
  {
    "text": "programming languages and this is coming",
    "start": "972639",
    "end": "974680"
  },
  {
    "text": "from the multilingual code eval Arness",
    "start": "974680",
    "end": "977160"
  },
  {
    "text": "again built by big code and they also",
    "start": "977160",
    "end": "979560"
  },
  {
    "text": "maintain a very interesting leaderboard",
    "start": "979560",
    "end": "981399"
  },
  {
    "text": "so what they do is they take models",
    "start": "981399",
    "end": "983079"
  },
  {
    "text": "across you know several companies and",
    "start": "983079",
    "end": "985120"
  },
  {
    "text": "several open source contributors the Run",
    "start": "985120",
    "end": "987399"
  },
  {
    "text": "devals themselves and then they compil",
    "start": "987399",
    "end": "989319"
  },
  {
    "text": "this very interesting leaderboard so you",
    "start": "989319",
    "end": "991360"
  },
  {
    "text": "will find us there I guess uh in a few",
    "start": "991360",
    "end": "993680"
  },
  {
    "text": "days so uh from the left column we have",
    "start": "993680",
    "end": "996519"
  },
  {
    "text": "star coder 3B which as of yesterday was",
    "start": "996519",
    "end": "999920"
  },
  {
    "text": "the state-of-the-art model at the 3B uh",
    "start": "999920",
    "end": "1002440"
  },
  {
    "text": "parameter size across uh languages and",
    "start": "1002440",
    "end": "1005800"
  },
  {
    "text": "today our we 1.5 is basically optimal",
    "start": "1005800",
    "end": "1009440"
  },
  {
    "text": "across every single language that you",
    "start": "1009440",
    "end": "1010920"
  },
  {
    "text": "see on the list but what gets me excited",
    "start": "1010920",
    "end": "1013279"
  },
  {
    "text": "is not that much know the fact that we",
    "start": "1013279",
    "end": "1014800"
  },
  {
    "text": "are know more powerful than star coder",
    "start": "1014800",
    "end": "1017279"
  },
  {
    "text": "which has been released a few months",
    "start": "1017279",
    "end": "1018480"
  },
  {
    "text": "months ago what got me hyped you know",
    "start": "1018480",
    "end": "1021000"
  },
  {
    "text": "when we were training it is that we're",
    "start": "1021000",
    "end": "1022680"
  },
  {
    "text": "very very close to col Lama 7D so as a",
    "start": "1022680",
    "end": "1025760"
  },
  {
    "text": "reminder col Lama 7B is a Lama 2 model",
    "start": "1025760",
    "end": "1029280"
  },
  {
    "text": "from meta the 7B version which has been",
    "start": "1029280",
    "end": "1031520"
  },
  {
    "text": "trained on two trillion tokens of",
    "start": "1031520",
    "end": "1033038"
  },
  {
    "text": "natural language and then it has an",
    "start": "1033039",
    "end": "1034880"
  },
  {
    "text": "additional pre-training phrase of 500",
    "start": "1034880",
    "end": "1037000"
  },
  {
    "text": "billion tokens exclusively on code so",
    "start": "1037000",
    "end": "1039558"
  },
  {
    "text": "it's a model that is twice the size it's",
    "start": "1039559",
    "end": "1042640"
  },
  {
    "text": "2.5x more data way more GPU compute so",
    "start": "1042640",
    "end": "1046520"
  },
  {
    "text": "you see where I'm going you know we're",
    "start": "1046520",
    "end": "1047678"
  },
  {
    "text": "getting big",
    "start": "1047679",
    "end": "1049160"
  },
  {
    "text": "close how do we surpass Cod Lama here is",
    "start": "1049160",
    "end": "1052360"
  },
  {
    "start": "1051000",
    "end": "1125000"
  },
  {
    "text": "the trick this is the the other model",
    "start": "1052360",
    "end": "1055400"
  },
  {
    "text": "that we've been training in parallel and",
    "start": "1055400",
    "end": "1057200"
  },
  {
    "text": "this is the rle tune version and it",
    "start": "1057200",
    "end": "1059120"
  },
  {
    "text": "means the following we further",
    "start": "1059120",
    "end": "1061000"
  },
  {
    "text": "pre-trained it on 200 billion tokens of",
    "start": "1061000",
    "end": "1063480"
  },
  {
    "text": "code this time coming from our home",
    "start": "1063480",
    "end": "1066440"
  },
  {
    "text": "developers so on ret when you create a",
    "start": "1066440",
    "end": "1070000"
  },
  {
    "text": "public rep hole it's automatically",
    "start": "1070000",
    "end": "1072480"
  },
  {
    "text": "published under IM license so we use",
    "start": "1072480",
    "end": "1074799"
  },
  {
    "text": "this code to further pre-rain our model",
    "start": "1074799",
    "end": "1077320"
  },
  {
    "text": "and we extract again 30 billion tokens",
    "start": "1077320",
    "end": "1079880"
  },
  {
    "text": "of code same languages same data",
    "start": "1079880",
    "end": "1082440"
  },
  {
    "text": "filtering pipeline to retain only the",
    "start": "1082440",
    "end": "1084520"
  },
  {
    "text": "top quality ones we do this three EPO",
    "start": "1084520",
    "end": "1087120"
  },
  {
    "text": "then we do also linear cool down and we",
    "start": "1087120",
    "end": "1090200"
  },
  {
    "text": "are using basically the languages that",
    "start": "1090200",
    "end": "1092640"
  },
  {
    "text": "are predominantly popular for replit",
    "start": "1092640",
    "end": "1095039"
  },
  {
    "text": "users so not the same list as we saw",
    "start": "1095039",
    "end": "1097240"
  },
  {
    "text": "before if you go on replit I would say",
    "start": "1097240",
    "end": "1099640"
  },
  {
    "text": "95% of the people are mostly writing",
    "start": "1099640",
    "end": "1101799"
  },
  {
    "text": "Python and JavaScript these are the cool",
    "start": "1101799",
    "end": "1104080"
  },
  {
    "text": "cool languages of",
    "start": "1104080",
    "end": "1105600"
  },
  {
    "text": "today another key Insight is power cut",
    "start": "1105600",
    "end": "1108960"
  },
  {
    "text": "off for this model is literally a few",
    "start": "1108960",
    "end": "1111240"
  },
  {
    "text": "weeks ago so if there is a cool new",
    "start": "1111240",
    "end": "1113840"
  },
  {
    "text": "library that everyone is you know",
    "start": "1113840",
    "end": "1115559"
  },
  {
    "text": "writing software 4 in the last month our",
    "start": "1115559",
    "end": "1118159"
  },
  {
    "text": "model is going to be capable of",
    "start": "1118159",
    "end": "1119400"
  },
  {
    "text": "generating code that you know follows",
    "start": "1119400",
    "end": "1121600"
  },
  {
    "text": "that Library so and we're going to keep",
    "start": "1121600",
    "end": "1124400"
  },
  {
    "text": "basically these models up to date so",
    "start": "1124400",
    "end": "1126360"
  },
  {
    "start": "1125000",
    "end": "1191000"
  },
  {
    "text": "that we can follow the trends and we can",
    "start": "1126360",
    "end": "1128200"
  },
  {
    "text": "make our developers more",
    "start": "1128200",
    "end": "1130559"
  },
  {
    "text": "happy here is the table that I love so",
    "start": "1130559",
    "end": "1134480"
  },
  {
    "text": "we're back to this backto back",
    "start": "1134480",
    "end": "1136799"
  },
  {
    "text": "comparison uh on the very left we have",
    "start": "1136799",
    "end": "1139200"
  },
  {
    "text": "our base model uh we didn't add star",
    "start": "1139200",
    "end": "1141720"
  },
  {
    "text": "coder here for a sake of space and also",
    "start": "1141720",
    "end": "1144559"
  },
  {
    "text": "the mod the base model is already uh",
    "start": "1144559",
    "end": "1146480"
  },
  {
    "text": "topping it on every other language so it",
    "start": "1146480",
    "end": "1148320"
  },
  {
    "text": "didn't make sense now we have K in",
    "start": "1148320",
    "end": "1150679"
  },
  {
    "text": "between and you can see why uh we are on",
    "start": "1150679",
    "end": "1153960"
  },
  {
    "text": "pretty much every language substantially",
    "start": "1153960",
    "end": "1156240"
  },
  {
    "text": "better so we have 36% on the open AI",
    "start": "1156240",
    "end": "1159919"
  },
  {
    "text": "human eval Benchmark as a reminder um I",
    "start": "1159919",
    "end": "1164360"
  },
  {
    "text": "when I was working on B coder for",
    "start": "1164360",
    "end": "1166080"
  },
  {
    "text": "example that was a ped one result",
    "start": "1166080",
    "end": "1168840"
  },
  {
    "text": "that we publish uh in early 2022 and",
    "start": "1168840",
    "end": "1172280"
  },
  {
    "text": "that model was a 530 billion tokens so",
    "start": "1172280",
    "end": "1175360"
  },
  {
    "text": "almost 200x larger than this model and",
    "start": "1175360",
    "end": "1178159"
  },
  {
    "text": "it achieves exactly the same unal pass",
    "start": "1178159",
    "end": "1180280"
  },
  {
    "text": "one performance same Coda Vinci 001 if",
    "start": "1180280",
    "end": "1184679"
  },
  {
    "text": "you go back to the paper is getting",
    "start": "1184679",
    "end": "1186159"
  },
  {
    "text": "exactly 36% so we were pretty much",
    "start": "1186159",
    "end": "1189559"
  },
  {
    "text": "amazed when this",
    "start": "1189559",
    "end": "1191320"
  },
  {
    "start": "1191000",
    "end": "1330000"
  },
  {
    "text": "happened",
    "start": "1191320",
    "end": "1193000"
  },
  {
    "text": "now why do we go through all this",
    "start": "1193000",
    "end": "1195200"
  },
  {
    "text": "struggle of training our models not only",
    "start": "1195200",
    "end": "1197039"
  },
  {
    "text": "because it's cool you know uh we love to",
    "start": "1197039",
    "end": "1198880"
  },
  {
    "text": "do this stuff but there is a there is a",
    "start": "1198880",
    "end": "1201480"
  },
  {
    "text": "rational behind it so we really want to",
    "start": "1201480",
    "end": "1204799"
  },
  {
    "text": "go as fast as possible with the most",
    "start": "1204799",
    "end": "1207840"
  },
  {
    "text": "powerful small model we could train and",
    "start": "1207840",
    "end": "1210480"
  },
  {
    "text": "the reason is all of our models are",
    "start": "1210480",
    "end": "1212760"
  },
  {
    "text": "actually optimized for inference rather",
    "start": "1212760",
    "end": "1215240"
  },
  {
    "text": "than for being awesome at benchmarks the",
    "start": "1215240",
    "end": "1217840"
  },
  {
    "text": "fact that that happens gives us a lot of",
    "start": "1217840",
    "end": "1220360"
  },
  {
    "text": "Pride and also makes us feel good when",
    "start": "1220360",
    "end": "1222640"
  },
  {
    "text": "we do a Vibe check with the model and it",
    "start": "1222640",
    "end": "1224360"
  },
  {
    "text": "performs as we expect or even better but",
    "start": "1224360",
    "end": "1226520"
  },
  {
    "text": "it turns out that our key result is on a",
    "start": "1226520",
    "end": "1228840"
  },
  {
    "text": "single model with no batching we're",
    "start": "1228840",
    "end": "1230880"
  },
  {
    "text": "generating know above 200 tokens per",
    "start": "1230880",
    "end": "1233960"
  },
  {
    "text": "second and we tune the architecture for",
    "start": "1233960",
    "end": "1236720"
  },
  {
    "text": "Speed in every possible way we're",
    "start": "1236720",
    "end": "1238840"
  },
  {
    "text": "training a small a vocabul as I was",
    "start": "1238840",
    "end": "1240440"
  },
  {
    "text": "saying before we're using flesh",
    "start": "1240440",
    "end": "1242440"
  },
  {
    "text": "attention with a traton kernel we're",
    "start": "1242440",
    "end": "1244440"
  },
  {
    "text": "using the latest gqa so every single",
    "start": "1244440",
    "end": "1246640"
  },
  {
    "text": "aspect is there to make sure that we can",
    "start": "1246640",
    "end": "1248720"
  },
  {
    "text": "go as fast as we can and we optimize",
    "start": "1248720",
    "end": "1251240"
  },
  {
    "text": "basically for the usage on the Tron",
    "start": "1251240",
    "end": "1253320"
  },
  {
    "text": "inference server and acceleration",
    "start": "1253320",
    "end": "1255320"
  },
  {
    "text": "framework such as tensor or tlm there",
    "start": "1255320",
    "end": "1257559"
  },
  {
    "text": "really squeeze you know the last drop",
    "start": "1257559",
    "end": "1260000"
  },
  {
    "text": "for andb the gpus now the other very",
    "start": "1260000",
    "end": "1262919"
  },
  {
    "text": "interesting Insight is we work very hard",
    "start": "1262919",
    "end": "1265919"
  },
  {
    "text": "also to make the model deployment go",
    "start": "1265919",
    "end": "1268320"
  },
  {
    "text": "much faster so if you ever you know had",
    "start": "1268320",
    "end": "1270760"
  },
  {
    "text": "the bad luck to work with kubernetes in",
    "start": "1270760",
    "end": "1272960"
  },
  {
    "text": "your",
    "start": "1272960",
    "end": "1274320"
  },
  {
    "text": "life you know you know thankfully can",
    "start": "1274320",
    "end": "1277039"
  },
  {
    "text": "get you know to get your pod and you",
    "start": "1277039",
    "end": "1279320"
  },
  {
    "text": "download all the dependencies and build",
    "start": "1279320",
    "end": "1280880"
  },
  {
    "text": "it and yada yada you know so the very",
    "start": "1280880",
    "end": "1282880"
  },
  {
    "text": "first time we brought this",
    "start": "1282880",
    "end": "1283880"
  },
  {
    "text": "infrastructure H it took 18 minutes to",
    "start": "1283880",
    "end": "1285960"
  },
  {
    "text": "go you know from clicking until the",
    "start": "1285960",
    "end": "1287760"
  },
  {
    "text": "model was deployed now if you want to",
    "start": "1287760",
    "end": "1290039"
  },
  {
    "text": "you know adapt to the load that the",
    "start": "1290039",
    "end": "1291640"
  },
  {
    "text": "application is receiving 18 minutes you",
    "start": "1291640",
    "end": "1293799"
  },
  {
    "text": "know looks like an eternity like if if",
    "start": "1293799",
    "end": "1295640"
  },
  {
    "text": "there is a traffic Spike good luck with",
    "start": "1295640",
    "end": "1297520"
  },
  {
    "text": "that um so one of our awesome Engineers",
    "start": "1297520",
    "end": "1300200"
  },
  {
    "text": "Bradley you're going to find him at the",
    "start": "1300200",
    "end": "1301559"
  },
  {
    "text": "boots later today brought this number",
    "start": "1301559",
    "end": "1303559"
  },
  {
    "text": "from 18 minutes to just two minutes",
    "start": "1303559",
    "end": "1306200"
  },
  {
    "text": "there is a laundry list of tricks that",
    "start": "1306200",
    "end": "1308120"
  },
  {
    "text": "he used I'm not going to go through them",
    "start": "1308120",
    "end": "1309760"
  },
  {
    "text": "just talk to Brad uh the cool Insight",
    "start": "1309760",
    "end": "1313279"
  },
  {
    "text": "here is the fact now whenever we get",
    "start": "1313279",
    "end": "1315159"
  },
  {
    "text": "more load we can react very quickly and",
    "start": "1315159",
    "end": "1317559"
  },
  {
    "text": "that's how we serve a very large user",
    "start": "1317559",
    "end": "1319240"
  },
  {
    "text": "base so the moment that I'm J announced",
    "start": "1319240",
    "end": "1321799"
  },
  {
    "text": "AI for all literally 10 minutes ago we",
    "start": "1321799",
    "end": "1324039"
  },
  {
    "text": "flip the switch and now code competion",
    "start": "1324039",
    "end": "1325880"
  },
  {
    "text": "is in front of all our users and that's",
    "start": "1325880",
    "end": "1328000"
  },
  {
    "text": "the way we made this",
    "start": "1328000",
    "end": "1330840"
  },
  {
    "start": "1330000",
    "end": "1430000"
  },
  {
    "text": "happen now I've been asked several times",
    "start": "1330840",
    "end": "1334039"
  },
  {
    "text": "guys why are you releasing your model",
    "start": "1334039",
    "end": "1335320"
  },
  {
    "text": "open source you put so much effort maybe",
    "start": "1335320",
    "end": "1337600"
  },
  {
    "text": "not that's that's an advantage for a",
    "start": "1337600",
    "end": "1339320"
  },
  {
    "text": "company um it turns out that the moment",
    "start": "1339320",
    "end": "1342080"
  },
  {
    "text": "we did it we got a lot of adoption and",
    "start": "1342080",
    "end": "1344440"
  },
  {
    "text": "apart from a lot of log which you know",
    "start": "1344440",
    "end": "1346080"
  },
  {
    "text": "always feels good and it feels good to",
    "start": "1346080",
    "end": "1347559"
  },
  {
    "text": "know to with other people in AI that are",
    "start": "1347559",
    "end": "1349960"
  },
  {
    "text": "using what we build uh we also started",
    "start": "1349960",
    "end": "1352159"
  },
  {
    "text": "to get fine tune versions instruct tune",
    "start": "1352159",
    "end": "1354720"
  },
  {
    "text": "versions of that and we have seen a lot",
    "start": "1354720",
    "end": "1357520"
  },
  {
    "text": "of people using our small model deployed",
    "start": "1357520",
    "end": "1359960"
  },
  {
    "text": "in local say with gml which goes super",
    "start": "1359960",
    "end": "1362679"
  },
  {
    "text": "fast on opal silicon and they built",
    "start": "1362679",
    "end": "1365200"
  },
  {
    "text": "their own custom privacy aware like",
    "start": "1365200",
    "end": "1368360"
  },
  {
    "text": "GitHub calot alternative with rapid V1",
    "start": "1368360",
    "end": "1371320"
  },
  {
    "text": "so we expect the same to happen with uh",
    "start": "1371320",
    "end": "1373559"
  },
  {
    "text": "B 1.5 in the next few days as we speak",
    "start": "1373559",
    "end": "1376679"
  },
  {
    "text": "also if you go on a phase the model is",
    "start": "1376679",
    "end": "1379240"
  },
  {
    "text": "available uh we're working on the readme",
    "start": "1379240",
    "end": "1381559"
  },
  {
    "text": "come to to Wi mava the boot is The",
    "start": "1381559",
    "end": "1383520"
  },
  {
    "text": "Mastermind behind it so it's going to",
    "start": "1383520",
    "end": "1384960"
  },
  {
    "text": "tell you every single detail on how to",
    "start": "1384960",
    "end": "1386640"
  },
  {
    "text": "make it run in production we're going to",
    "start": "1386640",
    "end": "1388120"
  },
  {
    "text": "be here until tonight so more than happy",
    "start": "1388120",
    "end": "1390159"
  },
  {
    "text": "to play with the model together now in",
    "start": "1390159",
    "end": "1393120"
  },
  {
    "text": "the last minute I've left I want to give",
    "start": "1393120",
    "end": "1395159"
  },
  {
    "text": "you like a teaser of what we're going to",
    "start": "1395159",
    "end": "1397000"
  },
  {
    "text": "be doing in the next weeks so we aligned",
    "start": "1397000",
    "end": "1399679"
  },
  {
    "text": "a few very exciting collaborations the",
    "start": "1399679",
    "end": "1402200"
  },
  {
    "text": "first one is with glaive AI and it's a",
    "start": "1402200",
    "end": "1404600"
  },
  {
    "text": "company that is building synthetic data",
    "start": "1404600",
    "end": "1406480"
  },
  {
    "text": "sets and we're working on on an if",
    "start": "1406480",
    "end": "1409679"
  },
  {
    "text": "version of our models so an instruct F",
    "start": "1409679",
    "end": "1411559"
  },
  {
    "text": "tune version over 2,000 uh",
    "start": "1411559",
    "end": "1414720"
  },
  {
    "text": "210,000 uh coding instructions we're",
    "start": "1414720",
    "end": "1417520"
  },
  {
    "text": "already seeing very exciting results we",
    "start": "1417520",
    "end": "1420159"
  },
  {
    "text": "want to trle check them and you know",
    "start": "1420159",
    "end": "1422640"
  },
  {
    "text": "follow our twitters and the moment that",
    "start": "1422640",
    "end": "1424480"
  },
  {
    "text": "we're sure that this is performing as we",
    "start": "1424480",
    "end": "1426400"
  },
  {
    "text": "expect is going to be out there and we",
    "start": "1426400",
    "end": "1428720"
  },
  {
    "text": "going to be able to play with it second",
    "start": "1428720",
    "end": "1431200"
  },
  {
    "start": "1430000",
    "end": "1513000"
  },
  {
    "text": "announcement we're also collaborating",
    "start": "1431200",
    "end": "1433240"
  },
  {
    "text": "with more flabs I think Jesse is here",
    "start": "1433240",
    "end": "1435520"
  },
  {
    "text": "today and he's going to run a session",
    "start": "1435520",
    "end": "1437279"
  },
  {
    "text": "later explaining you exactly what uh",
    "start": "1437279",
    "end": "1439799"
  },
  {
    "text": "this new format does I'm going to give",
    "start": "1439799",
    "end": "1441480"
  },
  {
    "text": "you a teaser and then you know go to",
    "start": "1441480",
    "end": "1442919"
  },
  {
    "text": "Jesse talking he's going to explain you",
    "start": "1442919",
    "end": "1444400"
  },
  {
    "text": "all the details so we are designed",
    "start": "1444400",
    "end": "1447080"
  },
  {
    "text": "parters on the fist format which is fing",
    "start": "1447080",
    "end": "1449919"
  },
  {
    "text": "the syntax Tre you might have heard of",
    "start": "1449919",
    "end": "1451840"
  },
  {
    "text": "feel in the middle this concept where",
    "start": "1451840",
    "end": "1454080"
  },
  {
    "text": "you can take your file split it in a",
    "start": "1454080",
    "end": "1456520"
  },
  {
    "text": "half and then basically if you're WR",
    "start": "1456520",
    "end": "1458279"
  },
  {
    "text": "writing code in between you can tell the",
    "start": "1458279",
    "end": "1460559"
  },
  {
    "text": "llm that the top of the file is your",
    "start": "1460559",
    "end": "1462720"
  },
  {
    "text": "prefix the bottom of the file is your",
    "start": "1462720",
    "end": "1464480"
  },
  {
    "text": "suffix and you give this context to the",
    "start": "1464480",
    "end": "1466600"
  },
  {
    "text": "model so that it knows which part you",
    "start": "1466600",
    "end": "1468279"
  },
  {
    "text": "should F now we found that this format",
    "start": "1468279",
    "end": "1471000"
  },
  {
    "text": "is even more powerful is aware of the",
    "start": "1471000",
    "end": "1473600"
  },
  {
    "text": "abstract syntax 3 underlying the source",
    "start": "1473600",
    "end": "1475640"
  },
  {
    "text": "code we're seeing very uh promising",
    "start": "1475640",
    "end": "1478039"
  },
  {
    "text": "results already and again this will be",
    "start": "1478039",
    "end": "1480000"
  },
  {
    "text": "out you know just a matter of like a few",
    "start": "1480000",
    "end": "1481960"
  },
  {
    "text": "days or weeks last thing we have",
    "start": "1481960",
    "end": "1484760"
  },
  {
    "text": "collaborations with the perplexity AI",
    "start": "1484760",
    "end": "1487120"
  },
  {
    "text": "guys you might have used their Labs so",
    "start": "1487120",
    "end": "1490200"
  },
  {
    "text": "it's a place where the host models",
    "start": "1490200",
    "end": "1492480"
  },
  {
    "text": "incredibly fast and the rapid B 1.5 will",
    "start": "1492480",
    "end": "1496000"
  },
  {
    "text": "appear there and you can start to play",
    "start": "1496000",
    "end": "1497480"
  },
  {
    "text": "with it and get a VI check by tonight",
    "start": "1497480",
    "end": "1500159"
  },
  {
    "text": "thanks",
    "start": "1500159",
    "end": "1502480"
  },
  {
    "text": "[Applause]",
    "start": "1502480",
    "end": "1506539"
  },
  {
    "text": "everyone",
    "start": "1511320",
    "end": "1514320"
  }
]
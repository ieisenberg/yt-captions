[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": "[Music]",
    "start": "350",
    "end": "14050"
  },
  {
    "text": "at hyper mode We Believe iteration is everything right that's why we built a platform that makes it really easy to",
    "start": "14440",
    "end": "19520"
  },
  {
    "text": "iterate over AI features and over the course of today over the next 50 minutes really you're going to be able to build",
    "start": "19520",
    "end": "25880"
  },
  {
    "start": "22000",
    "end": "33000"
  },
  {
    "text": "a couple of AI features and incrementally iterate on them right and we think that incremental iteration is everything and so that's why we're going",
    "start": "25880",
    "end": "31119"
  },
  {
    "text": "to walk through it so let's get started as we dig in",
    "start": "31119",
    "end": "36360"
  },
  {
    "start": "33000",
    "end": "57000"
  },
  {
    "text": "there's few things to be aware of we are just launching so I'm sure there'll be a couple things that break so bear with us",
    "start": "36360",
    "end": "41840"
  },
  {
    "text": "on that but we'll work through it um we are going to skip some steps to just condense this so you're going to push",
    "start": "41840",
    "end": "48280"
  },
  {
    "text": "right to main that's okay that's always fun um but let's uh let's really just",
    "start": "48280",
    "end": "53480"
  },
  {
    "text": "kind of start to dig in and overall on the agenda we're going to start with really",
    "start": "53480",
    "end": "59160"
  },
  {
    "start": "57000",
    "end": "89000"
  },
  {
    "text": "kind of showing you a few different ways where this plays out so we're going to start by playing a familiar game where we're using AI to scale the format then",
    "start": "59160",
    "end": "67400"
  },
  {
    "text": "we're going to understand how that game's constructed and kind of break it down to the building blocks and then start to apply those into triage and",
    "start": "67400",
    "end": "72880"
  },
  {
    "text": "GitHub issues we pick that because there's open data that we can easily use on that you could think about applying",
    "start": "72880",
    "end": "78320"
  },
  {
    "text": "that to a lot of different contexts whether that's customer records or product records or other things in your application but we'll start with GitHub",
    "start": "78320",
    "end": "84479"
  },
  {
    "text": "issues and talk about how we can generalize those Concepts to add AI to your application so",
    "start": "84479",
    "end": "90720"
  },
  {
    "start": "89000",
    "end": "141000"
  },
  {
    "text": "we've created a game that we call hyper categories it's like the familiar gamees categories but it works for a bigger",
    "start": "90720",
    "end": "96439"
  },
  {
    "text": "format of people right that the traditional game doesn't really work uh for more than six or eight people so",
    "start": "96439",
    "end": "102079"
  },
  {
    "text": "we're going to invite you all to play with us so you'll need your phones in a second for a QR code to kind of join into this but the prompt really is is",
    "start": "102079",
    "end": "107680"
  },
  {
    "text": "pretty simple given a starting letter provide the most unique entry that matches each category you'll get a point",
    "start": "107680",
    "end": "113880"
  },
  {
    "text": "if you actually match the category and you start with the right letter but you'll share that point with anyone else that says something similar",
    "start": "113880",
    "end": "120479"
  },
  {
    "text": "so if the category was furniture and the letter was T and you said table anyone else that says table you're going to",
    "start": "120479",
    "end": "125759"
  },
  {
    "text": "share that point around that that way so you need to be unique right we'll talk about how we're using AI to kind of power this but it also helps you to um",
    "start": "125759",
    "end": "133959"
  },
  {
    "text": "start to think think about the building blocks that you're going to use right so let's actually jump in we'll play and",
    "start": "133959",
    "end": "139080"
  },
  {
    "text": "then we'll kind of break it down afterwards with how it's actually",
    "start": "139080",
    "end": "143519"
  },
  {
    "start": "141000",
    "end": "153000"
  },
  {
    "text": "running we do we have a uh a hote jacket for whoever wins",
    "start": "144920",
    "end": "151840"
  },
  {
    "text": "so is Matt going to get that built and running",
    "start": "152680",
    "end": "157519"
  },
  {
    "start": "153000",
    "end": "298000"
  },
  {
    "text": "go all right let me can everybody see that all right we are playing with",
    "start": "159120",
    "end": "166680"
  },
  {
    "text": "things that start with the letter t so please uh scan that QR code if you can",
    "start": "166680",
    "end": "172360"
  },
  {
    "text": "hopefully everybody can if not there is a link to it in the uh in the doc that",
    "start": "172360",
    "end": "178519"
  },
  {
    "text": "accompanies this Workshop which they can get to how",
    "start": "178519",
    "end": "186599"
  },
  {
    "text": "yep uh hype. fuw Workshop y",
    "start": "186599",
    "end": "192560"
  },
  {
    "text": "okay we'll let it go a little longer than the the countdown timer here we won't cut off so if you haven't joined in yet feel free",
    "start": "194680",
    "end": "202959"
  },
  {
    "text": "there is a bot playing against you as well so I'm curious to see uh the creativity",
    "start": "214200",
    "end": "220840"
  },
  {
    "text": "that people come up with here the bot tends to pick the obvious",
    "start": "220840",
    "end": "226519"
  },
  {
    "text": "answers so it doesn't do very well in this one",
    "start": "226519",
    "end": "231319"
  },
  {
    "text": "need some music Jeopardy",
    "start": "247480",
    "end": "251920"
  },
  {
    "text": "music there we go thank you little improv",
    "start": "253400",
    "end": "260479"
  },
  {
    "text": "there yeah I see people typing still so we'll",
    "start": "261040",
    "end": "266160"
  },
  {
    "text": "give we'll give it a little bit more time",
    "start": "266160",
    "end": "270160"
  },
  {
    "text": "we can end it whenever you",
    "start": "281039",
    "end": "284199"
  },
  {
    "text": "like I see most phones down so another five",
    "start": "287039",
    "end": "292800"
  },
  {
    "text": "seconds five why don't we see the results 3 two 1 all right",
    "start": "292800",
    "end": "299919"
  },
  {
    "start": "298000",
    "end": "432000"
  },
  {
    "text": "where is Kirk buers congratulations come see us after we'll grab you a",
    "start": "299919",
    "end": "306000"
  },
  {
    "text": "jacket awesome to see so you see the bot there in fourth place so great job for",
    "start": "306000",
    "end": "311160"
  },
  {
    "text": "three of you for beating the bot and we have a tie for oh yeah sorry I miss look at",
    "start": "311160",
    "end": "318080"
  },
  {
    "text": "Francisco awesome so come see us after we we have two jackets we can make that work shall we look at the results yeah",
    "start": "318080",
    "end": "323440"
  },
  {
    "text": "let's look at it all right things you wear Tas oh got an invalid so we'll we'll dig",
    "start": "323440",
    "end": "331160"
  },
  {
    "text": "into that AI is not always perfect in the evaluation okay still one we need to train the model better yeah cool so why",
    "start": "331160",
    "end": "337919"
  },
  {
    "text": "don't we jump over to show you how this is actually working behind the scenes this is a a template that you can deploy you can play it back at your company or",
    "start": "337919",
    "end": "343840"
  },
  {
    "text": "wherever you're at but really we start to think about these type of AI",
    "start": "343840",
    "end": "349039"
  },
  {
    "text": "applications can we get the screen sled up the one on the left is a little off",
    "start": "349039",
    "end": "354360"
  },
  {
    "text": "there oh there we go um as these building blocks right that you're starting to assemble these into your applic",
    "start": "354360",
    "end": "360360"
  },
  {
    "text": "right so when you submit that response or when the bot submits the response we score that as well we validate the starting letter we validate the category",
    "start": "360360",
    "end": "367199"
  },
  {
    "text": "right and so we are using a model to make sure that you are hitting that category as we saw in the results there it's not always perfectly right we can",
    "start": "367199",
    "end": "372680"
  },
  {
    "text": "continue to train that but one of the things we learned as we were building this was if the letter was p and the",
    "start": "372680",
    "end": "378720"
  },
  {
    "text": "thing was occupation you could type in P doctor and the model would think that that was valid right so that's why we",
    "start": "378720",
    "end": "385280"
  },
  {
    "text": "added a dictionary validation as well and we really see this as illustrating the way we see the world of AI",
    "start": "385280",
    "end": "391280"
  },
  {
    "text": "applications are to develop it's this mix of models and traditional programming paradigms that come together",
    "start": "391280",
    "end": "396639"
  },
  {
    "text": "that actually make it useful right so we have that filtering stage and then we go into the scoring stage we start to",
    "start": "396639",
    "end": "402240"
  },
  {
    "text": "Cluster those responses we look at and say if you said table in someone else at tables we consider those the same answer",
    "start": "402240",
    "end": "408360"
  },
  {
    "text": "right so we're using um those processes to make sure that those things are matched and it's not just an exact text",
    "start": "408360",
    "end": "413680"
  },
  {
    "text": "search match these are ways you could start to scale this game to a size of this group right and then that responds",
    "start": "413680",
    "end": "418879"
  },
  {
    "text": "to the leaderboard and we show all this just so you start to get a feel for how these things are assembled it's a a set of building",
    "start": "418879",
    "end": "425840"
  },
  {
    "text": "blocks behind this is a set of functions models and data",
    "start": "425840",
    "end": "432080"
  },
  {
    "start": "432000",
    "end": "469000"
  },
  {
    "text": "sources right so you start to think about this at at a deeper level it's basic programming Concepts right we have",
    "start": "432080",
    "end": "438120"
  },
  {
    "text": "a set of functions we have a collection of user responses that we're doing similarity search across a set of models",
    "start": "438120",
    "end": "443680"
  },
  {
    "text": "that help power both those functions directly as well as the embeddings for the models or for the collections and",
    "start": "443680",
    "end": "448800"
  },
  {
    "text": "we're going to walk through all this in the next example and you're actually going to get hands on it and build these pieces and then some connections right",
    "start": "448800",
    "end": "454319"
  },
  {
    "text": "whether that's within hyper mode itself to out to your database to a traditional API to a model host we make it really",
    "start": "454319",
    "end": "461120"
  },
  {
    "text": "easy to stitch all that together and so that's what we want to show you now is really to apply these Concepts into Tri",
    "start": "461120",
    "end": "468039"
  },
  {
    "text": "and GitHub issue so if anyone has ever worked on an open source project you you know that you get GitHub issues from a",
    "start": "468039",
    "end": "474159"
  },
  {
    "start": "469000",
    "end": "505000"
  },
  {
    "text": "wide variety of sources and quality is not always great right so we thought what if we could actually apply AI to",
    "start": "474159",
    "end": "480240"
  },
  {
    "text": "make it easier to triage those issues to understand what type of issue it was whether similar issues that may be",
    "start": "480240",
    "end": "486520"
  },
  {
    "text": "already reported or trends that you're starting to see and actually be able to summarize Trends coming out of the repo right so that's the part that we would'",
    "start": "486520",
    "end": "492639"
  },
  {
    "text": "love for you to build with us so you guys ready we're going to we're going to build this actually build",
    "start": "492639",
    "end": "499280"
  },
  {
    "text": "it uh if you got laptops out that'd be good uh I'm going to get out of here and we're going to we're going to kind of work together the uh all this is",
    "start": "499280",
    "end": "506360"
  },
  {
    "start": "505000",
    "end": "577000"
  },
  {
    "text": "documented by the way um kind of chronologically the way we're going to follow in the workshop um and to get to",
    "start": "506360",
    "end": "512279"
  },
  {
    "text": "there there's a a short link which is uh what is it hype.",
    "start": "512279",
    "end": "517320"
  },
  {
    "text": "Fu slw Workshop that'll just take you into our docs link or you can go to docs. hyper mod.com and and go find the",
    "start": "517320",
    "end": "524000"
  },
  {
    "text": "AI Worlds Fair tab here on the left um and feel free to browse around the rest of the docs and learn about H promote as",
    "start": "524000",
    "end": "529800"
  },
  {
    "text": "you go um this is the platform we're using to build this but also the concepts we're going to go through here really could could work any way that",
    "start": "529800",
    "end": "535800"
  },
  {
    "text": "you're building an application that's going to leverage Ai and functions and data and all that stuff here um let's",
    "start": "535800",
    "end": "542440"
  },
  {
    "text": "see we already we already kind of went through a lot of this basic stuff with Hyper Gories U I will just say for PR Rex um if you hadn't seen this earlier",
    "start": "542440",
    "end": "549279"
  },
  {
    "text": "um hopefully you've got some kind of text editor I you like to use vs code um you'll need no js20 or higher um and",
    "start": "549279",
    "end": "556120"
  },
  {
    "text": "that's that's pretty much it um obviously get and in some way to uh to to clone a repo and so forth I like to",
    "start": "556120",
    "end": "561959"
  },
  {
    "text": "use GitHub desktop so you might see that flash on and off but you can use the command line or whatever you're comfortable with um so let's um let's",
    "start": "561959",
    "end": "570399"
  },
  {
    "text": "start with GitHub issue U triage we're going to go to this website we set up called just just ship.",
    "start": "570399",
    "end": "578120"
  },
  {
    "start": "577000",
    "end": "604000"
  },
  {
    "text": "aai um and this is U this is something we just launched so uh we'd love to hear",
    "start": "578120",
    "end": "583920"
  },
  {
    "text": "any feedback you may have from it there are a lot of other templates on here but we're going to work with this GitHub issue triage template for the sake of",
    "start": "583920",
    "end": "590399"
  },
  {
    "text": "this Workshop um and if you're following along so just click on the GitHub issue",
    "start": "590399",
    "end": "595959"
  },
  {
    "text": "triage and we're going to click it's going to tell you a little bit of the template you can click to go view the template but we're just going to we're",
    "start": "595959",
    "end": "601959"
  },
  {
    "text": "going to go right ahead and deploy it um now for most of you this will be the first time that you've um been into",
    "start": "601959",
    "end": "608240"
  },
  {
    "start": "604000",
    "end": "708000"
  },
  {
    "text": "hyper mode so uh you will get a screen that looks like this but when you go to connect it to your GitHub account it's",
    "start": "608240",
    "end": "614200"
  },
  {
    "text": "going to ask you to sign in um and that would be a normal uh GitHub login so if you if you don't have GitHub then you",
    "start": "614200",
    "end": "620560"
  },
  {
    "text": "would need a GitHub account in order to continue question in the front I I need to it access to all my current",
    "start": "620560",
    "end": "630959"
  },
  {
    "text": "you should only need to give it access to the repository that we're uh working with today if you're saying something",
    "start": "633000",
    "end": "639800"
  },
  {
    "text": "different we'd love to see what that looks like um yeah they uh and and if if you",
    "start": "639800",
    "end": "646120"
  },
  {
    "text": "have any concerns about that and and don't want to continue you could just watch along or we could um we could we",
    "start": "646120",
    "end": "651240"
  },
  {
    "text": "could check afterwards I know that I can't remember the exact detail but I know that there's something on GitHub where some of the wording that GitHub",
    "start": "651240",
    "end": "658160"
  },
  {
    "text": "gives you on that first link is a little confusing but U it's only requesting repost permissions that screen is a",
    "start": "658160",
    "end": "664480"
  },
  {
    "text": "little confusing of the first time if you don't have any existing repos y um",
    "start": "664480",
    "end": "670040"
  },
  {
    "text": "so you're going to basically uh this is me here Matt Johnson pint and uh if you have other ORS of course you could you",
    "start": "670040",
    "end": "676360"
  },
  {
    "text": "could pick them here um and you can name your repo anything you want uh you can make it private or public um but we're",
    "start": "676360",
    "end": "683880"
  },
  {
    "text": "going to create that and um I'm going to go to the one that I pre-created it should land you when all",
    "start": "683880",
    "end": "690360"
  },
  {
    "text": "is said and done let me find it on something that looks like",
    "start": "690360",
    "end": "695560"
  },
  {
    "text": "this um so we'll go through this a little bit more later but this is",
    "start": "696240",
    "end": "702360"
  },
  {
    "text": "basically um setting up cloning a template off of GitHub um and if you",
    "start": "702360",
    "end": "708320"
  },
  {
    "text": "look on GitHub you'll see that there is a template let me zoom in um that was cloned from the ship issue triage um",
    "start": "708320",
    "end": "715880"
  },
  {
    "text": "template repo and it's pretty barebones uh um it's got some some boiler plates",
    "start": "715880",
    "end": "721040"
  },
  {
    "text": "set up but most everything we're working with here today is going to be in this functions",
    "start": "721040",
    "end": "726560"
  },
  {
    "text": "directory uh let me go back to the doc and just see where we're at",
    "start": "726920",
    "end": "732040"
  },
  {
    "text": "for moving things along this will give them a little time",
    "start": "732040",
    "end": "737760"
  },
  {
    "text": "to to do that we did hyper category set up local",
    "start": "737760",
    "end": "745800"
  },
  {
    "text": "environment um okay so once we once we have that we're going to want to clone it right so you can get clone",
    "start": "745800",
    "end": "752399"
  },
  {
    "text": "it um I have already get cloned that repo um so if I open it in Visual Studio",
    "start": "752399",
    "end": "761279"
  },
  {
    "text": "code I will be looking at something that looks like like this I'll just pause for",
    "start": "761279",
    "end": "766720"
  },
  {
    "text": "just a few minutes to make sure that everybody can clone the starter template you're going to see me work with it for",
    "start": "766720",
    "end": "771880"
  },
  {
    "text": "a little bit too so if you're a little behind that's fine um you can always um catch up later or just continue to watch",
    "start": "771880",
    "end": "779760"
  },
  {
    "text": "um I will point out that um you may see some things in red even though everything is fine and I'm going to just",
    "start": "779760",
    "end": "786160"
  },
  {
    "text": "show you how to get rid of that when you first clone the repo um you want to um CD into the functions directory and",
    "start": "786160",
    "end": "793279"
  },
  {
    "text": "you're going to do an mpm install that's going to go download all the dependencies off of um the no package",
    "start": "793279",
    "end": "799199"
  },
  {
    "text": "manager and notice they're still in red there is a little quirk in VSS code that we haven't quite figured out how to",
    "start": "799199",
    "end": "804720"
  },
  {
    "text": "avoid at this stage you can um you need to open a typ typescript file but you",
    "start": "804720",
    "end": "810000"
  },
  {
    "text": "can you can do a few different things you can just restart the typescript language server and the red will go away",
    "start": "810000",
    "end": "815519"
  },
  {
    "text": "um this is a a vs code issue that that I've got an open issue on with that team but um it does install",
    "start": "815519",
    "end": "823959"
  },
  {
    "text": "correctly sure the question was if you are on just ship AI should you deploy or just go to GitHub um if you view it on",
    "start": "829360",
    "end": "836160"
  },
  {
    "start": "836000",
    "end": "1339000"
  },
  {
    "text": "GitHub you're just going to see the template and GitHub will also let you just use this template directly it's up",
    "start": "836160",
    "end": "841880"
  },
  {
    "text": "in the upper right hand corner but um you can go through that step but it's a little easier if you just go through the deploy and we'll automate that for you",
    "start": "841880",
    "end": "848560"
  },
  {
    "text": "because we're we're also installing the hyper mode application if you go through the uh through the green button on",
    "start": "848560",
    "end": "854480"
  },
  {
    "text": "GitHub then you'll have to import your project into hyper mode after the fact yeah if you click on the deploy",
    "start": "854480",
    "end": "861320"
  },
  {
    "text": "that's creating your org and everything on on hyper",
    "start": "861320",
    "end": "865040"
  },
  {
    "text": "mode Jake can you take a look at what they we're if people are having",
    "start": "867639",
    "end": "874040"
  },
  {
    "text": "difficulties we're going to send you somebody over and hopefully it's not everybody in the",
    "start": "874040",
    "end": "880040"
  },
  {
    "text": "room but yes please we can we can make this interactive within uh within certain time constraints um there's",
    "start": "880160",
    "end": "885880"
  },
  {
    "text": "nobody in the room after us but we know you have other sessions to go to also so we want to keep this on",
    "start": "885880",
    "end": "892639"
  },
  {
    "text": "track should I continue yep okay so so we've installed the project",
    "start": "894959",
    "end": "901560"
  },
  {
    "text": "I've installed the dependencies let's let's build it so we're going to use uh mpm here if you're used to yarn or or",
    "start": "901560",
    "end": "907880"
  },
  {
    "text": "bun or any pmpm those should all work um but I'm going to do mpm run",
    "start": "907880",
    "end": "912920"
  },
  {
    "text": "build and you're going to get some output that has our uh nice little",
    "start": "912920",
    "end": "918079"
  },
  {
    "text": "pretty um aski art that I'm wearing right here and it's going to give you",
    "start": "918079",
    "end": "923199"
  },
  {
    "text": "some metadata about your library and it's going to describe that there hey there are two functions in this um in this starter template there's one called",
    "start": "923199",
    "end": "929680"
  },
  {
    "text": "classify issue and there's another one called Trend summary um so together we're going to take a look at those two functions and",
    "start": "929680",
    "end": "935360"
  },
  {
    "text": "so we can understand how it works and and what what we're actually doing here and then I'm going to actually run some",
    "start": "935360",
    "end": "940560"
  },
  {
    "text": "of these for you so you can see like them in action um so let's just go look at I'm",
    "start": "940560",
    "end": "946920"
  },
  {
    "text": "actually going to take them backwards order here they're listed alphabetically but we're going to look at the trend summary first um this particular",
    "start": "946920",
    "end": "955279"
  },
  {
    "text": "one if we look at this um I'll make one other quick call out so um you may if",
    "start": "955279",
    "end": "962040"
  },
  {
    "text": "you're a web developer at all you may see this and say oh we're in a TS file and it looks like we're writing typescript we're actually writing",
    "start": "962040",
    "end": "967120"
  },
  {
    "text": "something called assembly script which is a typescript like language it uses a lot of the U the same features of",
    "start": "967120",
    "end": "972440"
  },
  {
    "text": "typescript and a lot of the same ecosystem as typescript um the reason we're using assembly script is because all of your hypernode functions are",
    "start": "972440",
    "end": "978519"
  },
  {
    "text": "getting compiled to web assembly and that's how we actually execute all of this code that you're writing in a nice",
    "start": "978519",
    "end": "983639"
  },
  {
    "text": "secure fast uh performant manner uh as it's running and part of the hyper mode platform um um won't dwell on that too",
    "start": "983639",
    "end": "989880"
  },
  {
    "text": "much but that's uh that's the the intent here um hyper mode will get support for other languages in the future this is",
    "start": "989880",
    "end": "996480"
  },
  {
    "text": "what we're using today um so what are we uh using from here we're we're going to use uh for",
    "start": "996480",
    "end": "1002720"
  },
  {
    "text": "this first one we're going to use openi and you'll see that we import an open a chat model and a couple system message",
    "start": "1002720",
    "end": "1008440"
  },
  {
    "text": "and user message objects so we know how to use it I've got another U Little Helper function that I wrote here let me",
    "start": "1008440",
    "end": "1014319"
  },
  {
    "text": "just close that um that is going to go get some issues",
    "start": "1014319",
    "end": "1019720"
  },
  {
    "text": "from GitHub and if I drill into that this is not AI at all this is just a an HTTP rest call GitHub has a nice API",
    "start": "1019720",
    "end": "1027000"
  },
  {
    "text": "that you can use to go fetch data and I'm going to fetch data um pass in some parameters into a template I can even do",
    "start": "1027000",
    "end": "1033678"
  },
  {
    "text": "a little logging so I can see what's going on um requires some headers um",
    "start": "1033679",
    "end": "1039640"
  },
  {
    "text": "there's a little comment here that like we have we have all secrets management system so you don't have to put secrets in your code and we can still pass your",
    "start": "1039640",
    "end": "1045199"
  },
  {
    "text": "your GitHub API tokens through securely and so forth um ultimately you get your data and come back and say hey there's",
    "start": "1045199",
    "end": "1051520"
  },
  {
    "text": "some issue data we're going to throw it in issues object so we can start working with it in the rest of your code and",
    "start": "1051520",
    "end": "1056880"
  },
  {
    "text": "that's what you're getting back here in this issues we have over it's an issues object it's an array of issues right we",
    "start": "1056880",
    "end": "1062440"
  },
  {
    "text": "said hey go get some get have issues so once we have the issues what are we going to do next um we're going",
    "start": "1062440",
    "end": "1069480"
  },
  {
    "text": "to we're going to need to build a prompt to send off for analysis because what we want here is we're going to take a whole",
    "start": "1069480",
    "end": "1075039"
  },
  {
    "text": "bunch of information from the issues and we're going to say hey uh open Ai and this this case uh we're going to use GPT",
    "start": "1075039",
    "end": "1080679"
  },
  {
    "text": "for uh would you summarize these for us uh what's the overall trend is the is",
    "start": "1080679",
    "end": "1086159"
  },
  {
    "text": "what we're asking for um so it's not just summarize the issues but like give me a trend so that's part of my my",
    "start": "1086159",
    "end": "1091679"
  },
  {
    "text": "instruction off to there provide a summary of the trends of their proditor repository based on the issues created",
    "start": "1091679",
    "end": "1098039"
  },
  {
    "text": "and um and we're going to just send open AI like a constructed string that includes like the Tim stamp um the user",
    "start": "1098039",
    "end": "1105520"
  },
  {
    "text": "handle so it can kind of get some analysis um and like the issue title and",
    "start": "1105520",
    "end": "1110919"
  },
  {
    "text": "um and we're passing all that through into um open AI the other thing I'll",
    "start": "1110919",
    "end": "1116600"
  },
  {
    "text": "I'll call out for you here it's like now we're into some um hyper mode specific code that we call our model interface",
    "start": "1116600",
    "end": "1123480"
  },
  {
    "text": "and uh this model that I'm looking at it is an open ey chat model so it h it knows everything about the open ey API",
    "start": "1123480",
    "end": "1129520"
  },
  {
    "text": "you don't have to go over and read the opening ey docs in order to construct this this API call you just say hey I'm",
    "start": "1129520",
    "end": "1135760"
  },
  {
    "text": "going to use the open AI chat model and when I create input it's telling me right here on the intellisense and the",
    "start": "1135760",
    "end": "1140960"
  },
  {
    "text": "type ahead I can just say create some messages it's going to take some messages I've got a bunch of different messages of different types um it even",
    "start": "1140960",
    "end": "1148000"
  },
  {
    "text": "goes as far as like optional parameters here I show temperature um so a lot of people when they're brand new to thei",
    "start": "1148000",
    "end": "1153039"
  },
  {
    "text": "they like they never heard this term before what what is temperature I don't know what that is and then you see top PE and like people like I don't don't",
    "start": "1153039",
    "end": "1158400"
  },
  {
    "text": "get that um it's really intuitive for a developer to just say you know um I can",
    "start": "1158400",
    "end": "1163480"
  },
  {
    "text": "just say input Dot and I get like here are all the different options there's like log Pro and n and parallel tool",
    "start": "1163480",
    "end": "1170200"
  },
  {
    "text": "calls and all the different options that the G has uh or sorry the opening eye has and um you know I can read them",
    "start": "1170200",
    "end": "1176880"
  },
  {
    "text": "individually uh if I use them incorrectly it won't compile um all that that kind of stuff that you would expect",
    "start": "1176880",
    "end": "1182880"
  },
  {
    "text": "from um a strongly typed client library and we we've baked that into hyperm mode not just for openi but for other models",
    "start": "1182880",
    "end": "1189960"
  },
  {
    "text": "as well we've got some out of the box and we're going to be expanding on them and we've designed the system so that if we don't support a certain models",
    "start": "1189960",
    "end": "1196480"
  },
  {
    "text": "interface you can write it yourself there's something that U that prevents you from doing that you can just inherit from a base class and and write the",
    "start": "1196480",
    "end": "1205320"
  },
  {
    "text": "implementation I'll pause there for a second because I felt like that was a lot of words this is a pretty basic rag use",
    "start": "1205360",
    "end": "1212000"
  },
  {
    "text": "case right we're fetching some data we're passing it to the model to ask for summarization you could do this in a lot of ways right at hyper we make it really",
    "start": "1212000",
    "end": "1218159"
  },
  {
    "text": "easy to stitch all those pieces together right and you can start to iterate through that right to Matt's point you can try new models right and you don't",
    "start": "1218159",
    "end": "1224520"
  },
  {
    "text": "have to go learn a new model and understand a different model uses temperature in a different way or has different thres holds on it right here",
    "start": "1224520",
    "end": "1230039"
  },
  {
    "text": "when you invoke that new model do input. temperature you're going to see that right there in context and so we find it",
    "start": "1230039",
    "end": "1235400"
  },
  {
    "text": "makes it a lot more productive for users as they're starting to stitch these things together not having to make any of these choices and really kind of hard",
    "start": "1235400",
    "end": "1241720"
  },
  {
    "text": "choices up front knowing that you can always swap them out really easily one of the things we found when we were designing this is that um um a lot of",
    "start": "1241720",
    "end": "1249559"
  },
  {
    "text": "the the use cases seem to believe that all models were interchangeable and we found just through testing that it's",
    "start": "1249559",
    "end": "1254720"
  },
  {
    "text": "just not the case um not only are prompts different and outputs are different but also like um the different hyper parameters are different the",
    "start": "1254720",
    "end": "1261360"
  },
  {
    "text": "different um ways you can control the apis are different like uh everybody's got their own little custom snowflake",
    "start": "1261360",
    "end": "1267039"
  },
  {
    "text": "tweaks and we needed a way to consolidate that that so that a user can very easily get to all the different",
    "start": "1267039",
    "end": "1273200"
  },
  {
    "text": "options that are available so this is the API we came up with and I love feedback about that for any like API",
    "start": "1273200",
    "end": "1278720"
  },
  {
    "text": "design Engineers that are in the room come talk to me after um all right so",
    "start": "1278720",
    "end": "1284080"
  },
  {
    "text": "get uh open the eye returns me some complex things it's there there is the ability open I to have multiple choices",
    "start": "1284080",
    "end": "1289640"
  },
  {
    "text": "we're just going to take the first one and we're going to take that message and this may seem like a little thing but like um once I get the content of that",
    "start": "1289640",
    "end": "1297159"
  },
  {
    "text": "string I I could do other things with it I could in this case all I'm going to do is just trim it because like sometimes it comes back with extra characters but",
    "start": "1297159",
    "end": "1304039"
  },
  {
    "text": "say I wanted to throw it in a database or I wanted to log it or I wanted to go call another model without that input um",
    "start": "1304039",
    "end": "1310080"
  },
  {
    "text": "as soon as I say that people they're like oh like BL chain like well kind of it's just it's just programming it's just like you're taking one input and",
    "start": "1310080",
    "end": "1315360"
  },
  {
    "text": "you're you're manipulating it to do the next thing um um so let's let's just run",
    "start": "1315360",
    "end": "1320520"
  },
  {
    "text": "this so what does that mean when we run it um in this case it's already in hyper mode because I cloned from the template",
    "start": "1320520",
    "end": "1325559"
  },
  {
    "text": "but to say I just written this all I'd have to do and this is the where the tile cones from is just get commit get push uh and we pick it up um",
    "start": "1325559",
    "end": "1333039"
  },
  {
    "text": "automatically and roll that out into your hyper mode console which I'll go back to this is the one we're looking at",
    "start": "1333039",
    "end": "1339960"
  },
  {
    "text": "um and um you'll see that I've got Trend summary on here um now I've already",
    "start": "1339960",
    "end": "1345360"
  },
  {
    "text": "configured this um backend to have an API key off to opening eye which you would need um but if you were doing it",
    "start": "1345360",
    "end": "1351840"
  },
  {
    "text": "yourself you would go over to host and you would need a GitHub token as well cuz we're going to go pull issues off GitHub right um so let's run this we got",
    "start": "1351840",
    "end": "1359600"
  },
  {
    "text": "a little query tab here that uses graphical it's a it's a built-in thing we may we replace that with something a little more uh interactive later but it",
    "start": "1359600",
    "end": "1366520"
  },
  {
    "text": "it works for for now and um I use hugging face Transformers but let's",
    "start": "1366520",
    "end": "1371720"
  },
  {
    "text": "somebody have somebody throw out a favorite repository I need the uh the org name and the anybody have another",
    "start": "1371720",
    "end": "1377960"
  },
  {
    "text": "one anyone anyone I'll pick something at",
    "start": "1377960",
    "end": "1383600"
  },
  {
    "text": "random okay I used to be for a long time I was a c developer um don't hold that",
    "start": "1383600",
    "end": "1388799"
  },
  {
    "text": "against me so I'm going to go let's go see what's going on the net runtime and and I haven't tested this so we'll just",
    "start": "1388799",
    "end": "1394600"
  },
  {
    "text": "see what happens here it's going to go fetch the top 100 issues off ofet runtime repo and within a few seconds",
    "start": "1394600",
    "end": "1400760"
  },
  {
    "text": "here it has summarized it and said hey there's the trend summary um and you notice um we made a graphql call um but",
    "start": "1400760",
    "end": "1409000"
  },
  {
    "text": "I didn't have to write any graph kill schema um hyper mode automatically generates the graph kill schema based on the functions that you export so all I",
    "start": "1409000",
    "end": "1415760"
  },
  {
    "text": "had to do is make this function Trend summary and tell what its inputs are and it now has a full lit up graphql",
    "start": "1415760",
    "end": "1421960"
  },
  {
    "text": "endpoint um I happen to be calling it from the hyper mode console but you could use another tool like Postman uh",
    "start": "1421960",
    "end": "1427960"
  },
  {
    "text": "has a really good graph Co interface or you could use any graph K clibrary you want or you could just use Curl um on",
    "start": "1427960",
    "end": "1433919"
  },
  {
    "text": "the command line and write into a script or your favorite HTTP client you can use anything you want",
    "start": "1433919",
    "end": "1439360"
  },
  {
    "text": "we got a question",
    "start": "1439360",
    "end": "1442600"
  },
  {
    "text": "yeah it does the question yeah uh I'll repeat the question it says uh does does",
    "start": "1446520",
    "end": "1451960"
  },
  {
    "text": "hyper mode create the graphql types from inferred from the typescript types it does um that is part of the hyper mode",
    "start": "1451960",
    "end": "1458640"
  },
  {
    "text": "experience U it will even create custom scalers for you if you have those uh there are some limitations but we are we",
    "start": "1458640",
    "end": "1465600"
  },
  {
    "text": "are actively engineering to try to overcome them the biggest implementation you'll see right away is at the moment",
    "start": "1465600",
    "end": "1470919"
  },
  {
    "text": "um input types are are not supported U you can have structured output types so input types at the moment have to be all",
    "start": "1470919",
    "end": "1476640"
  },
  {
    "text": "scalers um or arrays but um say you had your custom object and graph kill will",
    "start": "1476640",
    "end": "1482480"
  },
  {
    "text": "let you supply that but we we need to do some engineering work to make that",
    "start": "1482480",
    "end": "1487600"
  },
  {
    "text": "work yeah um it's really nice way to like um Define your code once um and you",
    "start": "1487600",
    "end": "1495520"
  },
  {
    "text": "have a single source of Truth and it can be in a file you import if you in a corporation that has lots of libraries you can you can make separate libraries",
    "start": "1495520",
    "end": "1501840"
  },
  {
    "text": "for this and it's just it's just the mpm package ecosystem so it just folds in like you would expect when we support",
    "start": "1501840",
    "end": "1506880"
  },
  {
    "text": "other languages it'll be whatever the package ecosystem is for those languages we're not trying to do anything special here so Matt here why don't we show what",
    "start": "1506880",
    "end": "1514559"
  },
  {
    "text": "you get as well when you run that query right so if you go to the inferences tab you'll see actually a history of",
    "start": "1514559",
    "end": "1520520"
  },
  {
    "start": "1519000",
    "end": "1564000"
  },
  {
    "text": "this model run right because we know that when you start to actually run models you need more observability into that right your app may be triggering",
    "start": "1520520",
    "end": "1526240"
  },
  {
    "text": "things from the front end dynamically prompting that model so we make it really easy to see every time you hit a",
    "start": "1526240",
    "end": "1531520"
  },
  {
    "text": "model you're going to get one of these entries to understand how long it took what was the input what was the output",
    "start": "1531520",
    "end": "1536840"
  },
  {
    "text": "right so you can start to debug this with with additional visibility and we find that makes it really easy especially if you're starting to chain",
    "start": "1536840",
    "end": "1542240"
  },
  {
    "text": "multiple models together in a single function yeah like if I wanted to know well how many tokens did um opening I",
    "start": "1542240",
    "end": "1547399"
  },
  {
    "text": "consume for that it did return that to me but I didn't use it in my code I could have but I even though I didn't",
    "start": "1547399",
    "end": "1552919"
  },
  {
    "text": "use my code I do have it in our inference history so you can go back and and say oh that that prompt you know",
    "start": "1552919",
    "end": "1557960"
  },
  {
    "text": "took 3,000 tokens Y and then you also have access to to",
    "start": "1557960",
    "end": "1563480"
  },
  {
    "text": "Raw logs of of the functions as they run right so you can log things out to that you'll see system logs are part of that",
    "start": "1563480",
    "end": "1569360"
  },
  {
    "start": "1564000",
    "end": "1909000"
  },
  {
    "text": "and they're all kind of uh oriented based on each individual function execution right so you can have high",
    "start": "1569360",
    "end": "1574880"
  },
  {
    "text": "volumes of overlapping functions makes it really easy to debug here to understand what's going on how models are being invoked what the specific",
    "start": "1574880",
    "end": "1580919"
  },
  {
    "text": "inputs and outputs of those are so that you can continue to iterate and understand what's going on this is the",
    "start": "1580919",
    "end": "1586120"
  },
  {
    "text": "one I just ran um these are some ones I was running earlier but we'll we'll show you those in a minute um there's a whole",
    "start": "1586120",
    "end": "1591440"
  },
  {
    "text": "bunch of stuff other stuff on here one of the interesting one is like deployments um I've only done one on this repo it just the initial commit but",
    "start": "1591440",
    "end": "1597520"
  },
  {
    "text": "as we push you'll see that like you have to get hash and you could click the link over there and it makes it really easy to like see who changed what over time",
    "start": "1597520",
    "end": "1607000"
  },
  {
    "text": "um okay um let's go on to so this one we're",
    "start": "1607000",
    "end": "1612600"
  },
  {
    "text": "not going to um have you guys Implement yourself because I don't want anybody in here to have to supply an opening I key or get H token right now but like I said",
    "start": "1612600",
    "end": "1619200"
  },
  {
    "text": "they they are in the starter template and workshop you can do that on your own time however you like we're going to go on to the next one which I think",
    "start": "1619200",
    "end": "1624399"
  },
  {
    "text": "everybody can do here together because uh we're going to actually run the model on hyper mode rather than uh externally",
    "start": "1624399",
    "end": "1631360"
  },
  {
    "text": "yep is that the right spot in the sequence I so okay yeah bear with us if",
    "start": "1631360",
    "end": "1637799"
  },
  {
    "text": "uh we're just going through presentation uh coordination here uh okay so the next one we're going to look at like I said",
    "start": "1637799",
    "end": "1643720"
  },
  {
    "text": "there's two functions that are in in this um starter template um the next one is classifi and we're going to we're",
    "start": "1643720",
    "end": "1648960"
  },
  {
    "text": "going to use this at first and then I'm going to have you guys modify it we're going to actually put your code to work here so if you've never written a suly",
    "start": "1648960",
    "end": "1655200"
  },
  {
    "text": "script or anything before just prend it's typescript if you run into a thing where like it says hey I don't know what type that is that's that's where you get",
    "start": "1655200",
    "end": "1660960"
  },
  {
    "text": "the assembly script it's and there I can answer those questions but it's pretty straightforward um uh so uh what does",
    "start": "1660960",
    "end": "1667679"
  },
  {
    "text": "this function do well in this case so this is going to be a little disconnected from the last one we did but uh because it's not going to go",
    "start": "1667679",
    "end": "1673720"
  },
  {
    "text": "query GitHub it's just going to take as inputs the title and the description and an issue ID",
    "start": "1673720",
    "end": "1678799"
  },
  {
    "text": "and we're going to we're going to log some information what we're doing and we're going to we're going to just build",
    "start": "1678799",
    "end": "1684399"
  },
  {
    "text": "a really dumb uh prompt here of uh or input anyway of summarizing the uh the",
    "start": "1684399",
    "end": "1689720"
  },
  {
    "text": "title and the description concatenated together um in a real app you'd want to play with us a little bit and figure out what the right exact input that matches",
    "start": "1689720",
    "end": "1696000"
  },
  {
    "text": "the model you're using uh oh let's talk about the model um so this model is uh called thebert mnli GitHub issues we",
    "start": "1696000",
    "end": "1703640"
  },
  {
    "text": "found it on hugging face um this is a a a Community contributed model I believe",
    "start": "1703640",
    "end": "1710159"
  },
  {
    "text": "um but it's pre-trained on giab issues so it's a purpose built model we don't need to spend time model training here",
    "start": "1710159",
    "end": "1715559"
  },
  {
    "text": "we don't need to start with anything big this is a really small model um is is good for like just deciding whether get",
    "start": "1715559",
    "end": "1721240"
  },
  {
    "text": "have issue is uh I believe it's it tells you whether it's an issue a bug a feature request or question or a",
    "start": "1721240",
    "end": "1727159"
  },
  {
    "text": "question yeah that's always what it's going to do um the interface for this uh",
    "start": "1727159",
    "end": "1732480"
  },
  {
    "text": "you'll see we import classification models from our models as Library um the sort experimental scared off by that",
    "start": "1732480",
    "end": "1738919"
  },
  {
    "text": "it's just we're trying to make sure that um we are careful about when we U finally call it not experimental um but",
    "start": "1738919",
    "end": "1744840"
  },
  {
    "text": "this will match most of the classification models that are on Hing face at the moment",
    "start": "1744840",
    "end": "1750360"
  },
  {
    "text": "um and uh yeah so what are we going to do we're going to we're going to build a prompt we're going to say okayy get that",
    "start": "1750360",
    "end": "1756080"
  },
  {
    "text": "classification model and now I've got uh an input that in this case requires um",
    "start": "1756080",
    "end": "1761200"
  },
  {
    "text": "one or more input strings as an array and the reason it's one or more is because you can classify things in batches I could say hey there's are",
    "start": "1761200",
    "end": "1767360"
  },
  {
    "text": "there are 10 you have issues I'd like you to classify I only need to make one model call for that um and and and",
    "start": "1767360",
    "end": "1773840"
  },
  {
    "text": "that's why I've got prediction zero the first prediction coming back because I'm only asking for one but um those would",
    "start": "1773840",
    "end": "1779279"
  },
  {
    "text": "match the the inputs and outputs and again if there were other options here you could say input dot in",
    "start": "1779279",
    "end": "1785360"
  },
  {
    "text": "this case it's the only one um but we would wrap that up for you in the interface and then we'll just log output",
    "start": "1785360",
    "end": "1792039"
  },
  {
    "text": "so this this is really simple um again I've already got it running so let's just run it and um the query for these",
    "start": "1792039",
    "end": "1798440"
  },
  {
    "text": "by the way are are pasted into the docs if you're following along in the docs let me just make sure I show you where",
    "start": "1798440",
    "end": "1803720"
  },
  {
    "text": "we are we are at issue type classification and there's some description there but basically this is",
    "start": "1803720",
    "end": "1809440"
  },
  {
    "text": "the code we're working on here's the example query we're going to run I'm going to paste this query um and this this quer got a lot of",
    "start": "1809440",
    "end": "1817720"
  },
  {
    "text": "um what looks like junk in it but it's because we just took literally the entire text of the query um off of",
    "start": "1817720",
    "end": "1823799"
  },
  {
    "text": "GitHub um and made sure it was properly escaped and stuff so if you were using the GitHub AP it would work um if you're",
    "start": "1823799",
    "end": "1830679"
  },
  {
    "text": "literally like with your mouse copying and pasting text you may find um like getting the new lines in there and the",
    "start": "1830679",
    "end": "1835720"
  },
  {
    "text": "quotes escaped might just be a little tricky on the fly but if you had input from an app it would be doing that for",
    "start": "1835720",
    "end": "1841399"
  },
  {
    "text": "you it's just it's a string in and a string out right um but let's go run",
    "start": "1841399",
    "end": "1847000"
  },
  {
    "text": "that guy where am I make sure I'm in the right area I think I've already got it in here yeah I'll just paste it anyway",
    "start": "1847000",
    "end": "1853360"
  },
  {
    "text": "just make sure is that the one it didn't paste correctly there",
    "start": "1853360",
    "end": "1859399"
  },
  {
    "text": "might be a doc issue there this one I know Works um maybe something I need to fix in the",
    "start": "1859399",
    "end": "1866519"
  },
  {
    "text": "docs I don't know if J can fix that the uh the one that's in the docs isn't U escaped properly so when I copy and",
    "start": "1866519",
    "end": "1872880"
  },
  {
    "text": "paste it it's it's got new lines in there weird um but basically everything I'm putting in should be in the",
    "start": "1872880",
    "end": "1878600"
  },
  {
    "text": "description if if you do get uh if you're trying this out and you get some weird error like like this doesn't work",
    "start": "1878600",
    "end": "1885159"
  },
  {
    "text": "um just reduce it down to to some string in here just so you can you can follow",
    "start": "1885159",
    "end": "1890279"
  },
  {
    "text": "along um we'll make sure we clean up the example later ideally it would be the entire thing of the issue um indeed this",
    "start": "1890279",
    "end": "1897200"
  },
  {
    "text": "is the the classification C that came out is it's a real issue um so so what's what's happening",
    "start": "1897200",
    "end": "1903760"
  },
  {
    "text": "here just to kind of highlight some of the contrast here right so when you deployed this project this small model different than kind of open AI models",
    "start": "1903760",
    "end": "1910240"
  },
  {
    "start": "1909000",
    "end": "1989000"
  },
  {
    "text": "right uh this small model actually got provision automatically in hyper mode so when you're running this query you're running against a dedicated instance of",
    "start": "1910240",
    "end": "1916440"
  },
  {
    "text": "this model just for your project and you can start to customize and and adjust that right and so really wanted",
    "start": "1916440",
    "end": "1921679"
  },
  {
    "text": "to to show you these two functions to kind of show you the contrast but also the similarities right the model uh interfaces are relatively similar and",
    "start": "1921679",
    "end": "1927399"
  },
  {
    "text": "pretty intuitive to make it easy to kind of continue to iterate through that why don't we jump ahead slightly just in the",
    "start": "1927399",
    "end": "1932919"
  },
  {
    "text": "interest of Time start building um a vector or",
    "start": "1932919",
    "end": "1938440"
  },
  {
    "text": "natural language search well one one thing I would like to do is just give people a few minutes to do some failure",
    "start": "1938440",
    "end": "1944399"
  },
  {
    "text": "we don't have time okay sorry um you your project continue to run if you reference the docs you're welcome to",
    "start": "1944399",
    "end": "1950240"
  },
  {
    "text": "continue to iterate with this we can spend all the time with you after to if if you'd like to but we won't do it but",
    "start": "1950240",
    "end": "1955519"
  },
  {
    "text": "the suggestion in the docs and there's a walk through is like how would I add a threshold to this function and say hey I",
    "start": "1955519",
    "end": "1961200"
  },
  {
    "text": "I I need to know based on its confidence like how how accurate is this label um",
    "start": "1961200",
    "end": "1966440"
  },
  {
    "text": "and that's something you don't need to train a model on it's just code you just write it there's a there's a um instead",
    "start": "1966440",
    "end": "1972039"
  },
  {
    "text": "of just that there's confidence score so you can decide what the confidence score you want is and and do some comparisons",
    "start": "1972039",
    "end": "1977559"
  },
  {
    "text": "and just just write that code but we'll let we'll let people on their own but y so why don't we jump",
    "start": "1977559",
    "end": "1983399"
  },
  {
    "text": "ahead to building a natural language search to identify similar issues right oftentimes people report repeated issues",
    "start": "1983399",
    "end": "1990799"
  },
  {
    "text": "and wouldn't it be great if there could be a bot that responds to every issue saying that sounds a lot like these three other issues that's what we're",
    "start": "1990799",
    "end": "1996639"
  },
  {
    "text": "going to build in the next 12 minutes okay sorry for The Rush guys um like I",
    "start": "1996639",
    "end": "2002600"
  },
  {
    "text": "said uh there's nobody in the room after will be around so if you want to walk through the slower if you have questions y we will help you uh uh okay so we're",
    "start": "2002600",
    "end": "2011159"
  },
  {
    "text": "going to go we're going to start writing some new stuff Let's uh let's just take this directly from the doc so that we",
    "start": "2011159",
    "end": "2016760"
  },
  {
    "text": "can walk through it together the first thing we're going to do is we're going to create what we call a hyper mode collection um and basically it's like",
    "start": "2016760",
    "end": "2023360"
  },
  {
    "text": "where you going to store your data um hyper mode isn't a database but we give you a very simple way to have an",
    "start": "2023360",
    "end": "2029159"
  },
  {
    "text": "inmemory key value store that we can apply an index to um and that way we can um basically do your vector search in in",
    "start": "2029159",
    "end": "2035919"
  },
  {
    "text": "memory in hyper mode um so first we have to go to our manifest and say hey there's um there is a collection so far",
    "start": "2035919",
    "end": "2042679"
  },
  {
    "text": "we haven't talked about the Manifest but you'll see in the root there's a file called hyper mode. Json and it has models it has the two models we've been",
    "start": "2042679",
    "end": "2048240"
  },
  {
    "text": "using so far it has hosts which were the uh both for the U the the first example",
    "start": "2048240",
    "end": "2054480"
  },
  {
    "text": "uh that's how we get out to other other places and I'm going to add that collections so I'm just going to drop it",
    "start": "2054480",
    "end": "2060158"
  },
  {
    "text": "right in here um so we have our collection Define that's all we have to do um and there's some additional",
    "start": "2060159",
    "end": "2067240"
  },
  {
    "text": "options and stuff that we're not going to go through the model right now um the next thing we're going to do",
    "start": "2067240",
    "end": "2073358"
  },
  {
    "text": "is we're going to add another model so one of the things with um if we're going to do a vector search we need to know well what model are we creating our",
    "start": "2073359",
    "end": "2079158"
  },
  {
    "text": "Bings off of right um and we don't want you to think about that too much but you do have to um Supply a model so we're",
    "start": "2079159",
    "end": "2086638"
  },
  {
    "text": "going to take another one from hugging face and we're going to go add it to the model",
    "start": "2086639",
    "end": "2091320"
  },
  {
    "text": "section boom we're going to use mini LM uh from s trans",
    "start": "2093359",
    "end": "2098440"
  },
  {
    "text": "forers and uh and you'll see that syntax in the the documentation but basically it's just that's the source of the model",
    "start": "2098440",
    "end": "2104119"
  },
  {
    "text": "we're using it's going to be hosted on hyper mode and we got that from hagging face that's it save that and um I'm",
    "start": "2104119",
    "end": "2112680"
  },
  {
    "text": "going to do a uh I'm going to commit that for a minute",
    "start": "2112680",
    "end": "2117839"
  },
  {
    "text": "so let's do command line get add everything and get",
    "start": "2117839",
    "end": "2126440"
  },
  {
    "text": "commit and um um add collection and",
    "start": "2126440",
    "end": "2132960"
  },
  {
    "text": "model okay and then it's we've got nice get signing on so it's asking me to",
    "start": "2132960",
    "end": "2138640"
  },
  {
    "text": "authenticate but once that's in I can get push and just from the push it's",
    "start": "2138640",
    "end": "2145119"
  },
  {
    "text": "going to start spinning up that model on hyper mode now you didn't have to do that at this step you could do the code and then do it all at once but this just",
    "start": "2145119",
    "end": "2150760"
  },
  {
    "text": "gives it time to warm up a little bit since we're uh under time constraint um the next thing I'm going",
    "start": "2150760",
    "end": "2156480"
  },
  {
    "text": "to do is is I'm going to uh go grab the embedder function so",
    "start": "2156480",
    "end": "2163000"
  },
  {
    "text": "we need an embedder function um you know how that we we showed you the model interface a couple times well this time",
    "start": "2163000",
    "end": "2168640"
  },
  {
    "text": "we're going to use an embeddings model and I'm going to go create a new file new file",
    "start": "2168640",
    "end": "2178079"
  },
  {
    "text": ".ts and I'm going to paste that in here and won't lock the whole thing but",
    "start": "2178079",
    "end": "2183319"
  },
  {
    "text": "basically um embedders need a text in and an array of vectors out and the vectors are flat 32 arrays so it looks",
    "start": "2183319",
    "end": "2189680"
  },
  {
    "text": "like a two-dimensional array but it's an array of array of flat 32s um and that's an assembly script",
    "start": "2189680",
    "end": "2197000"
  },
  {
    "text": "thing that we have a concept of a FL 32 instead of just a number um but that's basically how it works and we're going",
    "start": "2197000",
    "end": "2202040"
  },
  {
    "text": "to create it and we're going to just return all the predictions um one thing I have to do also is I have to um the way that this",
    "start": "2202040",
    "end": "2208440"
  },
  {
    "text": "is these exports work is uh I have to go to my index file and actually just make sure I include",
    "start": "2208440",
    "end": "2213480"
  },
  {
    "text": "it otherwise it's not going to leave the module when I build um at this stage I should be able to mpm I have to go to",
    "start": "2213480",
    "end": "2221000"
  },
  {
    "text": "the functions directory and I can say mpm run build and we should see",
    "start": "2221000",
    "end": "2227000"
  },
  {
    "text": "it yeah that in better is is in the output it's still not searchable though",
    "start": "2227000",
    "end": "2233000"
  },
  {
    "text": "this if I were to run it at this stage you'd see the array of all those floats and it's kind of not very usable from a",
    "start": "2233000",
    "end": "2239240"
  },
  {
    "text": "a user's perspective um so let's grab the actual function that's going to do the search and that's also in the docs",
    "start": "2239240",
    "end": "2246000"
  },
  {
    "text": "so I'm just going to copy that in and I'm going to do the same sort of",
    "start": "2246000",
    "end": "2251079"
  },
  {
    "text": "thing I'm going to come here and say new file um search we'll call it it can be called anything I'm going to paste that",
    "start": "2251079",
    "end": "2258319"
  },
  {
    "text": "in and and before I show it to you I'm going to make sure I don't forget to export it sometimes I forget to uh not",
    "start": "2258319",
    "end": "2264079"
  },
  {
    "text": "from yeah we're going to from search Okay um and I know we're tied on",
    "start": "2264079",
    "end": "2270599"
  },
  {
    "text": "time but just real quick what does this look like uh it's going to do a few things uh",
    "start": "2270599",
    "end": "2277720"
  },
  {
    "text": "it's going to Define uh it's going to import our collections object it's going to define a class that's going to be for our",
    "start": "2277720",
    "end": "2284440"
  },
  {
    "text": "similar issues this is you asking like can we return structured objects yes I'm doing it right here I return a similar issues array and we automatically get",
    "start": "2284440",
    "end": "2291560"
  },
  {
    "text": "graph C generated in our our output schema um I'm going to search the",
    "start": "2291560",
    "end": "2296880"
  },
  {
    "text": "collection using the information we have the Manifest and this time I'm going to say just give me the top three and I do",
    "start": "2296880",
    "end": "2302119"
  },
  {
    "text": "want the text and the results um often you don't often you just say give me the ID back cuz I'm going to go query a database using that ID and so for you to",
    "start": "2302119",
    "end": "2308599"
  },
  {
    "text": "return me the text if it's big could be an extra step we you don't need to do um",
    "start": "2308599",
    "end": "2314280"
  },
  {
    "text": "that's it return them uh return me an object using the the output of that that",
    "start": "2314280",
    "end": "2319560"
  },
  {
    "text": "search Let's uh let's do the get push and um get add do get commit Das",
    "start": "2319560",
    "end": "2329520"
  },
  {
    "text": "and um add search functions and get push and um oh I",
    "start": "2329520",
    "end": "2338319"
  },
  {
    "text": "didn't do I probably should have made sure it builds locally um it's going to build it in in di oh I'm not in the",
    "start": "2338319",
    "end": "2344760"
  },
  {
    "text": "right directory functions mpm run build because if I had a compiler or",
    "start": "2344760",
    "end": "2350319"
  },
  {
    "text": "something it would happen here and we are working on improving our local Dev experience as well because ideally we' like you to be able to run it here too",
    "start": "2350319",
    "end": "2356240"
  },
  {
    "text": "we don't have that just yet so for now you just push it and we run it there um notice it says hey there's a custom data",
    "start": "2356240",
    "end": "2362280"
  },
  {
    "text": "type similar issue that's going to be in our new graph to we'll go back to hyper mode and how",
    "start": "2362280",
    "end": "2368319"
  },
  {
    "text": "are we on time good eight minutes okay thanks for hanging with me here let's look at deployments for a second notice",
    "start": "2368319",
    "end": "2374079"
  },
  {
    "start": "2369000",
    "end": "2700000"
  },
  {
    "text": "they're there already so there's are the two pushes that I did get push it just works uh I can now go to the homepage",
    "start": "2374079",
    "end": "2381839"
  },
  {
    "text": "and I should see hey there's an issues collection and I've got four functions and I've got that new model that I added",
    "start": "2381839",
    "end": "2388560"
  },
  {
    "text": "right so every everything we just did it's already in hyper mode um one thing I want to do just uh for sake of time is",
    "start": "2388560",
    "end": "2393920"
  },
  {
    "text": "I'm going to go um preed this um collection with some existing data and I've got a link to",
    "start": "2393920",
    "end": "2400839"
  },
  {
    "text": "that in the not there in the doc down in the bottom there is a link here example",
    "start": "2400839",
    "end": "2408520"
  },
  {
    "text": "CSV file so we're going to take these issues which we scraped earlier off of I think Transformers I think this is where",
    "start": "2408520",
    "end": "2415200"
  },
  {
    "text": "we grabbed it from and I'm just going to download that file from GitHub issues.",
    "start": "2415200",
    "end": "2420359"
  },
  {
    "text": "CSV and I'm going to go over to hyper mode and um and upload them there now",
    "start": "2420359",
    "end": "2425680"
  },
  {
    "text": "you don't have to do it this way you could could write s a function that says um hey take this other API input and go",
    "start": "2425680",
    "end": "2431200"
  },
  {
    "text": "upload it or you could call GitHub API and upload it that way so there's a lot of different ways you can do it but",
    "start": "2431200",
    "end": "2436560"
  },
  {
    "text": "we're going to we're going to put it in manually right now there it is and what's going to happen when Matt does this is because of",
    "start": "2436560",
    "end": "2443280"
  },
  {
    "text": "the way that we've set up the collection and the embedding function every time you add something new to the The Collection whether that's via your code",
    "start": "2443280",
    "end": "2449520"
  },
  {
    "text": "or via this upload it's going to automatically embed it right it's going to use that function automatically embed",
    "start": "2449520",
    "end": "2454680"
  },
  {
    "text": "it and make it available for your search it's going to use that SA embedding function in the search so that you know that what you're searching and what",
    "start": "2454680",
    "end": "2460960"
  },
  {
    "text": "you're searching against have been embedded embedded the same way right so you don't need to bring three different systems together to get this working all",
    "start": "2460960",
    "end": "2467400"
  },
  {
    "text": "in one box you get natural language search off of these couple of functions there's a little bit of delay as it's",
    "start": "2467400",
    "end": "2473480"
  },
  {
    "text": "working here but if I just patient for a minute and refresh eventually we'll see",
    "start": "2473480",
    "end": "2478640"
  },
  {
    "text": "the uh inference history from those embedding functions should pop up yep those",
    "start": "2478640",
    "end": "2484079"
  },
  {
    "text": "are demo these are the ones that we ran when we were classifying what we should see",
    "start": "2484079",
    "end": "2489920"
  },
  {
    "text": "here let's just pick the model why do I not see that model shouldn't I see the EMB better",
    "start": "2489920",
    "end": "2498800"
  },
  {
    "text": "here the functions runs work let me let me just try a search and",
    "start": "2503240",
    "end": "2509640"
  },
  {
    "text": "see what happens I think probably still queueing up all right I'm going to search we'll see if it's still going I",
    "start": "2509640",
    "end": "2516359"
  },
  {
    "text": "think I think we're going to no here we can we can just wait a little more but um we're going to see if hey is anybody",
    "start": "2516359",
    "end": "2522160"
  },
  {
    "text": "we're going to search a new issue like imagine the workflow here somebody writes an issue says Hey I want to add a",
    "start": "2522160",
    "end": "2527280"
  },
  {
    "text": "Spanish uh version of your REM file and so our app that's using these apis is going to be like a bot that says hey we",
    "start": "2527280",
    "end": "2534040"
  },
  {
    "text": "we may already have that already you know maybe other people have asked um and indeed okay so it did finish",
    "start": "2534040",
    "end": "2540520"
  },
  {
    "text": "uploading from The Collection um we can go figure out why it's not showing in the logs it should have showed in our logs uh but indeed we can say hey um",
    "start": "2540520",
    "end": "2547520"
  },
  {
    "text": "there was a Turkish read me and there's some other bits about languages and a French version of this but I don't see anything that's a Spanish read me so",
    "start": "2547520",
    "end": "2554200"
  },
  {
    "text": "it's probably okay um there aren't any similar issues uh these are the most similar um that are",
    "start": "2554200",
    "end": "2561599"
  },
  {
    "text": "available I am curious why that didn't come through there they are just took a second y okay we'll work on that um",
    "start": "2561599",
    "end": "2568680"
  },
  {
    "text": "these are batches uh by the way so they're a little long here but I think what we did is we split them up to like 25 at a time and so they take like you",
    "start": "2568680",
    "end": "2575240"
  },
  {
    "text": "know 2 seconds for that one and 1 second for that one um but we can see the the history and",
    "start": "2575240",
    "end": "2580800"
  },
  {
    "text": "like there's a stuff you really don't want to look at all of the uh the photo Rays right that's your vector embeddings",
    "start": "2580800",
    "end": "2586680"
  },
  {
    "text": "and then the search just uses that Vector embeddings that's it I think that's I know we kind of",
    "start": "2586680",
    "end": "2593920"
  },
  {
    "text": "rushed through that I'm sorry um hopefully some of you got a chance to code some of it but like I said um uh",
    "start": "2593920",
    "end": "2599400"
  },
  {
    "text": "feel free to stick around or to continue to walk through the the dock on your own time and I'm really excited to see what",
    "start": "2599400",
    "end": "2606319"
  },
  {
    "text": "else you guys want to build uh we have a lot of other documentation off to the side here that you can see like other stuff we can do you can make HTTP calls",
    "start": "2606319",
    "end": "2614000"
  },
  {
    "text": "um you can you can uh what else you can do you can work with the collections more uh shortly not yet but shortly",
    "start": "2614000",
    "end": "2619920"
  },
  {
    "text": "we'll have ability to go and R and connect to any postcards database that you want to uh that's coming soon um and",
    "start": "2619920",
    "end": "2627440"
  },
  {
    "text": "uh and yeah there's like the sky's is the limit right take your models and write your functions and way you",
    "start": "2627440",
    "end": "2634359"
  },
  {
    "text": "go anything else we want to show yeah no that's that's what we had to show you right it was like these are a set of",
    "start": "2634359",
    "end": "2639559"
  },
  {
    "text": "building blocks that you can apply in your applications across context across different points of data hopefully you start to understand how these pieces",
    "start": "2639559",
    "end": "2645319"
  },
  {
    "text": "work right we see this everywhere like when we start to look it around and say there are so many places where you want",
    "start": "2645319",
    "end": "2651079"
  },
  {
    "text": "to do that natural language sorting or search or bringing these pieces in and we just seen people like you to help",
    "start": "2651079",
    "end": "2656359"
  },
  {
    "text": "bring that into those applications right and so that's what we really get excited about we don't want you to have to start",
    "start": "2656359",
    "end": "2661400"
  },
  {
    "text": "from scratch so that's as Matt said we launched just ship AI those are templates you can deploy those right away you all have access to hyper modee",
    "start": "2661400",
    "end": "2668800"
  },
  {
    "text": "now you got a 14-day trial feel free to respond to that email and you can claim the credits that Kevin mentioned this morning happy to get your team set up um",
    "start": "2668800",
    "end": "2675960"
  },
  {
    "text": "and run through this in a more contextual way for you as useful but thank you",
    "start": "2675960",
    "end": "2683440"
  },
  {
    "text": "[Music]",
    "start": "2684590",
    "end": "2702170"
  }
]
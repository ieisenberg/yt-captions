[
  {
    "text": "[Music]",
    "start": "1040",
    "end": "13859"
  },
  {
    "text": "hi this is Nicholas I'm the CTO and",
    "start": "15639",
    "end": "17880"
  },
  {
    "text": "co-founder of log 10 and we want to talk",
    "start": "17880",
    "end": "21439"
  },
  {
    "text": "about how you can scale the liability of",
    "start": "21439",
    "end": "24439"
  },
  {
    "text": "LM applications using um a new tool that",
    "start": "24439",
    "end": "27240"
  },
  {
    "text": "we've built during this year I think we",
    "start": "27240",
    "end": "29679"
  },
  {
    "text": "all can agree that there's been like",
    "start": "29679",
    "end": "31640"
  },
  {
    "text": "this kind of craze in the industry and",
    "start": "31640",
    "end": "34079"
  },
  {
    "text": "we've been rolling out a ton of",
    "start": "34079",
    "end": "36399"
  },
  {
    "text": "intelligence features based on",
    "start": "36399",
    "end": "38160"
  },
  {
    "text": "gbt and we kind of finding ourselves in",
    "start": "38160",
    "end": "40840"
  },
  {
    "text": "a now what",
    "start": "40840",
    "end": "42120"
  },
  {
    "text": "moment because without knowing what good",
    "start": "42120",
    "end": "44600"
  },
  {
    "text": "means in a generative setting it's",
    "start": "44600",
    "end": "46800"
  },
  {
    "text": "really really hard and risky to evolve",
    "start": "46800",
    "end": "49879"
  },
  {
    "text": "your applications like changing your",
    "start": "49879",
    "end": "51719"
  },
  {
    "text": "prompts configurations let alone",
    "start": "51719",
    "end": "53879"
  },
  {
    "text": "considering going from one model",
    "start": "53879",
    "end": "55840"
  },
  {
    "text": "provider to another to more advanced use",
    "start": "55840",
    "end": "59239"
  },
  {
    "text": "cases like self posting or",
    "start": "59239",
    "end": "61160"
  },
  {
    "text": "fine-tuning we wanted to introduce a new",
    "start": "61160",
    "end": "63199"
  },
  {
    "text": "tool today called llm",
    "start": "63199",
    "end": "65080"
  },
  {
    "text": "eal that enables uh teams to ship",
    "start": "65080",
    "end": "68479"
  },
  {
    "text": "reliable llm",
    "start": "68479",
    "end": "71560"
  },
  {
    "text": "products it it is command line tool that",
    "start": "72280",
    "end": "75759"
  },
  {
    "text": "you can run locally and with these four",
    "start": "75759",
    "end": "78960"
  },
  {
    "text": "uh lines of code uh you should be good",
    "start": "78960",
    "end": "81320"
  },
  {
    "text": "to",
    "start": "81320",
    "end": "82159"
  },
  {
    "text": "go um the initialization creates a",
    "start": "82159",
    "end": "87079"
  },
  {
    "text": "folder",
    "start": "87079",
    "end": "88000"
  },
  {
    "text": "structure um and best practices for",
    "start": "88000",
    "end": "90479"
  },
  {
    "text": "storing prompts and and",
    "start": "90479",
    "end": "92600"
  },
  {
    "text": "tests and then this is based on a super",
    "start": "92600",
    "end": "96720"
  },
  {
    "text": "configurable system from meta called",
    "start": "96720",
    "end": "99439"
  },
  {
    "text": "Hydra so you could basically extend it",
    "start": "99439",
    "end": "102840"
  },
  {
    "text": "to your heart's desire and the metrics",
    "start": "102840",
    "end": "105880"
  },
  {
    "text": "that we have wired up are in Python so",
    "start": "105880",
    "end": "109040"
  },
  {
    "text": "they could be any logic could be called",
    "start": "109040",
    "end": "111240"
  },
  {
    "text": "out to all the llms whatever you want",
    "start": "111240",
    "end": "114280"
  },
  {
    "text": "and after these evaluations have been",
    "start": "114280",
    "end": "116439"
  },
  {
    "text": "run you can generate some reports that",
    "start": "116439",
    "end": "119840"
  },
  {
    "text": "that basically gives you like a brief",
    "start": "119840",
    "end": "121240"
  },
  {
    "text": "overview of how the entire app and all",
    "start": "121240",
    "end": "124000"
  },
  {
    "text": "the tests are looking but still supports",
    "start": "124000",
    "end": "127200"
  },
  {
    "text": "flexible test criteria because like",
    "start": "127200",
    "end": "129920"
  },
  {
    "text": "these models are very fuzzy it's very",
    "start": "129920",
    "end": "132080"
  },
  {
    "text": "hard to sit with a guarantee that it's",
    "start": "132080",
    "end": "133680"
  },
  {
    "text": "going to be one or the other but it's",
    "start": "133680",
    "end": "135800"
  },
  {
    "text": "fairly safe to say that the majority",
    "start": "135800",
    "end": "137959"
  },
  {
    "text": "cases or say three out of five should",
    "start": "137959",
    "end": "141560"
  },
  {
    "text": "pass and we're going to jump",
    "start": "141560",
    "end": "144040"
  },
  {
    "text": "into command line and taking a",
    "start": "144040",
    "end": "147400"
  },
  {
    "text": "look we're just going to create a",
    "start": "147400",
    "end": "150319"
  },
  {
    "text": "directory for",
    "start": "150319",
    "end": "153120"
  },
  {
    "text": "today and go into this directory and",
    "start": "154160",
    "end": "156640"
  },
  {
    "text": "create ourselves a virtual",
    "start": "156640",
    "end": "159840"
  },
  {
    "text": "environment from here we going to",
    "start": "161400",
    "end": "164159"
  },
  {
    "text": "install LM",
    "start": "164159",
    "end": "166800"
  },
  {
    "text": "eval and initialize the folder structure",
    "start": "169680",
    "end": "173040"
  },
  {
    "text": "what we should be able to see here",
    "start": "173040",
    "end": "177120"
  },
  {
    "text": "is a directory structure where we have",
    "start": "177120",
    "end": "181480"
  },
  {
    "text": "our prompts let see a simple case could",
    "start": "181480",
    "end": "183959"
  },
  {
    "text": "be this where we have this message",
    "start": "183959",
    "end": "186599"
  },
  {
    "text": "template saying like what is a plus b",
    "start": "186599",
    "end": "188959"
  },
  {
    "text": "only return the answer without any",
    "start": "188959",
    "end": "190640"
  },
  {
    "text": "explanation so in this case we know that",
    "start": "190640",
    "end": "194239"
  },
  {
    "text": "we have to prompt engineer further in",
    "start": "194239",
    "end": "195760"
  },
  {
    "text": "order to get an exact output cuz let's",
    "start": "195760",
    "end": "199080"
  },
  {
    "text": "take a look at how the test looks like",
    "start": "199080",
    "end": "201720"
  },
  {
    "text": "in this case we're taking like the",
    "start": "201720",
    "end": "203239"
  },
  {
    "text": "actual output from the llm and comparing",
    "start": "203239",
    "end": "207599"
  },
  {
    "text": "it with the expected and this is like a",
    "start": "207599",
    "end": "210879"
  },
  {
    "text": "comparison what we had taken the Liberty",
    "start": "210879",
    "end": "213159"
  },
  {
    "text": "to do is to strip any spaces that might",
    "start": "213159",
    "end": "216439"
  },
  {
    "text": "be come from from the left and that's",
    "start": "216439",
    "end": "219080"
  },
  {
    "text": "because some models in this case claw",
    "start": "219080",
    "end": "221840"
  },
  {
    "text": "tends to preent spaces and so it's",
    "start": "221840",
    "end": "224640"
  },
  {
    "text": "things like that that you have to watch",
    "start": "224640",
    "end": "226040"
  },
  {
    "text": "out for then we have the metric which",
    "start": "226040",
    "end": "229480"
  },
  {
    "text": "could be any metric that you want to",
    "start": "229480",
    "end": "230799"
  },
  {
    "text": "surface in the report and then the",
    "start": "230799",
    "end": "232840"
  },
  {
    "text": "result which is then pass or fail and in",
    "start": "232840",
    "end": "236159"
  },
  {
    "text": "this case we want to add four and five",
    "start": "236159",
    "end": "238239"
  },
  {
    "text": "and we expect it to be nine",
    "start": "238239",
    "end": "241680"
  },
  {
    "text": "and I just going to try to run this test",
    "start": "241720",
    "end": "243599"
  },
  {
    "text": "here and try to revert some of the promp",
    "start": "243599",
    "end": "247040"
  },
  {
    "text": "engineering that we did earlier so I'm",
    "start": "247040",
    "end": "249000"
  },
  {
    "text": "going to",
    "start": "249000",
    "end": "251640"
  },
  {
    "text": "remove only return the answer without",
    "start": "251720",
    "end": "254480"
  },
  {
    "text": "any",
    "start": "254480",
    "end": "256720"
  },
  {
    "text": "explanation and the way you can start it",
    "start": "258840",
    "end": "261440"
  },
  {
    "text": "is LM eval",
    "start": "261440",
    "end": "263160"
  },
  {
    "text": "run but if you want to overwrite",
    "start": "263160",
    "end": "265520"
  },
  {
    "text": "anything if you just do L EV run it runs",
    "start": "265520",
    "end": "268080"
  },
  {
    "text": "everything but if you do like prompts",
    "start": "268080",
    "end": "270240"
  },
  {
    "text": "equals math then it's only going to run",
    "start": "270240",
    "end": "272479"
  },
  {
    "text": "the math example if you do n",
    "start": "272479",
    "end": "276800"
  },
  {
    "text": "tries one then it's just going to do one",
    "start": "276800",
    "end": "280360"
  },
  {
    "text": "sample by default we do five",
    "start": "280360",
    "end": "284240"
  },
  {
    "text": "samples so so we get like a better read",
    "start": "284240",
    "end": "286759"
  },
  {
    "text": "on the stability of of each test but it",
    "start": "286759",
    "end": "288919"
  },
  {
    "text": "might be too much for you but you can",
    "start": "288919",
    "end": "290039"
  },
  {
    "text": "override anything you can find",
    "start": "290039",
    "end": "293240"
  },
  {
    "text": "these default settings here in the LM",
    "start": "293240",
    "end": "296840"
  },
  {
    "text": "eval",
    "start": "296840",
    "end": "297759"
  },
  {
    "text": "yaml and but let's try try to run this",
    "start": "297759",
    "end": "300479"
  },
  {
    "text": "and see what happens and so this ran",
    "start": "300479",
    "end": "302479"
  },
  {
    "text": "across CLA gbt 4 and and gbt 3.5 once so",
    "start": "302479",
    "end": "307840"
  },
  {
    "text": "we can go in and generate a",
    "start": "307840",
    "end": "311600"
  },
  {
    "text": "report and say like actually something",
    "start": "311600",
    "end": "313720"
  },
  {
    "text": "failed what was the failed so let's take",
    "start": "313720",
    "end": "316080"
  },
  {
    "text": "a look at the output here and in this",
    "start": "316080",
    "end": "318919"
  },
  {
    "text": "case because we removed our prompt",
    "start": "318919",
    "end": "321520"
  },
  {
    "text": "engineering gbt 3.5 starts being a bit",
    "start": "321520",
    "end": "324560"
  },
  {
    "text": "chatty and says like 4.5 equals 9 Claud",
    "start": "324560",
    "end": "327639"
  },
  {
    "text": "does something similar it comes right",
    "start": "327639",
    "end": "329720"
  },
  {
    "text": "out the wres out the",
    "start": "329720",
    "end": "331759"
  },
  {
    "text": "equation and now I'm going to try to",
    "start": "331759",
    "end": "335039"
  },
  {
    "text": "revert and see let's let's get this",
    "start": "335039",
    "end": "338880"
  },
  {
    "text": "in and we try to run one more",
    "start": "338880",
    "end": "343039"
  },
  {
    "text": "time great now when we CH the report I",
    "start": "344319",
    "end": "347960"
  },
  {
    "text": "can say some test failed but the most",
    "start": "347960",
    "end": "349960"
  },
  {
    "text": "recent test that ran passed so when you",
    "start": "349960",
    "end": "352639"
  },
  {
    "text": "do the report it's going to generate",
    "start": "352639",
    "end": "354400"
  },
  {
    "text": "like a summary going to generate a",
    "start": "354400",
    "end": "355880"
  },
  {
    "text": "report per per run but then also say",
    "start": "355880",
    "end": "359120"
  },
  {
    "text": "overall all was there anything that that",
    "start": "359120",
    "end": "360960"
  },
  {
    "text": "failed out of these",
    "start": "360960",
    "end": "363160"
  },
  {
    "text": "reports if you want to go a bit more",
    "start": "363160",
    "end": "365520"
  },
  {
    "text": "advanced let's say you want to use tools",
    "start": "365520",
    "end": "369000"
  },
  {
    "text": "we we have an example here where we are",
    "start": "369000",
    "end": "371680"
  },
  {
    "text": "generating some python code and again we",
    "start": "371680",
    "end": "374000"
  },
  {
    "text": "had to add a number of different um",
    "start": "374000",
    "end": "376599"
  },
  {
    "text": "Clauses to make sure that it only",
    "start": "376599",
    "end": "378319"
  },
  {
    "text": "outputs python it tends to be very happy",
    "start": "378319",
    "end": "380759"
  },
  {
    "text": "generating um surrounding",
    "start": "380759",
    "end": "383560"
  },
  {
    "text": "explanations uh so in this case we are",
    "start": "383560",
    "end": "386680"
  },
  {
    "text": "going to see whether or not um",
    "start": "386680",
    "end": "390000"
  },
  {
    "text": "it returns an actual Python program that",
    "start": "390000",
    "end": "392199"
  },
  {
    "text": "could be that be parsed so let's try to",
    "start": "392199",
    "end": "394759"
  },
  {
    "text": "run",
    "start": "394759",
    "end": "396199"
  },
  {
    "text": "that if you go in and take a look at",
    "start": "396199",
    "end": "398880"
  },
  {
    "text": "this",
    "start": "398880",
    "end": "400199"
  },
  {
    "text": "report you can see that these tests",
    "start": "400199",
    "end": "402560"
  },
  {
    "text": "actually end end up passing our tool",
    "start": "402560",
    "end": "405080"
  },
  {
    "text": "use and to to round",
    "start": "405080",
    "end": "407440"
  },
  {
    "text": "up we have model based evaluation as",
    "start": "407440",
    "end": "410160"
  },
  {
    "text": "well where you can test using other",
    "start": "410160",
    "end": "414639"
  },
  {
    "text": "models and so in this case say with",
    "start": "414639",
    "end": "417919"
  },
  {
    "text": "grading we can go in and to find like a",
    "start": "417919",
    "end": "420080"
  },
  {
    "text": "full set of criteria here we're",
    "start": "420080",
    "end": "423080"
  },
  {
    "text": "evaluating mermaid diagrams giving a",
    "start": "423080",
    "end": "425960"
  },
  {
    "text": "score between 1 and five and the reason",
    "start": "425960",
    "end": "429360"
  },
  {
    "text": "and that that is also supported in LM",
    "start": "429360",
    "end": "431840"
  },
  {
    "text": "eval one thing about the previous",
    "start": "431840",
    "end": "434039"
  },
  {
    "text": "approach is that it takes quite an AM",
    "start": "434039",
    "end": "436440"
  },
  {
    "text": "amount of work to set up these tests and",
    "start": "436440",
    "end": "439120"
  },
  {
    "text": "gather your test cases and one really",
    "start": "439120",
    "end": "442520"
  },
  {
    "text": "compelling answer to evaluation has been",
    "start": "442520",
    "end": "444400"
  },
  {
    "text": "model based",
    "start": "444400",
    "end": "445759"
  },
  {
    "text": "evaluation and it's uh it's a setting",
    "start": "445759",
    "end": "448639"
  },
  {
    "text": "where you have typically a larger model",
    "start": "448639",
    "end": "451360"
  },
  {
    "text": "discriminate or kind of grade or be a",
    "start": "451360",
    "end": "453240"
  },
  {
    "text": "judge over the output from another llm",
    "start": "453240",
    "end": "456639"
  },
  {
    "text": "and that makes it so you can get more",
    "start": "456639",
    "end": "458800"
  },
  {
    "text": "nuanced output like pass fail or a grade",
    "start": "458800",
    "end": "462039"
  },
  {
    "text": "from 1 to five or preferences between",
    "start": "462039",
    "end": "464560"
  },
  {
    "text": "different options and it's reasoning",
    "start": "464560",
    "end": "466520"
  },
  {
    "text": "behind it there's a number of pitfalls",
    "start": "466520",
    "end": "469639"
  },
  {
    "text": "unfortunately around this approach",
    "start": "469639",
    "end": "472159"
  },
  {
    "text": "around biases towards the output from",
    "start": "472159",
    "end": "475240"
  },
  {
    "text": "the model itself if you're sweeping",
    "start": "475240",
    "end": "476759"
  },
  {
    "text": "different models they tend to prefer",
    "start": "476759",
    "end": "478159"
  },
  {
    "text": "their own output",
    "start": "478159",
    "end": "479919"
  },
  {
    "text": "then I'm very good at giving Point",
    "start": "479919",
    "end": "481599"
  },
  {
    "text": "scores saying I think between 0 and one",
    "start": "481599",
    "end": "485560"
  },
  {
    "text": "or larger scores between Z 0 and",
    "start": "485560",
    "end": "488639"
  },
  {
    "text": "100 but there are different ways where",
    "start": "488639",
    "end": "491159"
  },
  {
    "text": "you can start increasing the accuracy of",
    "start": "491159",
    "end": "494080"
  },
  {
    "text": "the kind of feedback that's been",
    "start": "494080",
    "end": "496240"
  },
  {
    "text": "generated and we've been working on this",
    "start": "496240",
    "end": "499919"
  },
  {
    "text": "where you basically start bridging",
    "start": "499919",
    "end": "501919"
  },
  {
    "text": "between model based and human feedback",
    "start": "501919",
    "end": "504680"
  },
  {
    "text": "so instead of removing the human",
    "start": "504680",
    "end": "506319"
  },
  {
    "text": "completely from the feedback you start",
    "start": "506319",
    "end": "508879"
  },
  {
    "text": "taking in all feedback that might have",
    "start": "508879",
    "end": "510599"
  },
  {
    "text": "been given prior and start modeling it",
    "start": "510599",
    "end": "513839"
  },
  {
    "text": "and say like if you have all the",
    "start": "513839",
    "end": "515599"
  },
  {
    "text": "feedback from John then we create an",
    "start": "515599",
    "end": "517399"
  },
  {
    "text": "autog John that will start create",
    "start": "517399",
    "end": "519159"
  },
  {
    "text": "generating feedback for review um for",
    "start": "519159",
    "end": "522320"
  },
  {
    "text": "any incoming completions and so in this",
    "start": "522320",
    "end": "524240"
  },
  {
    "text": "case here we have two pieces of feedback",
    "start": "524240",
    "end": "526640"
  },
  {
    "text": "that's been already given by human see",
    "start": "526640",
    "end": "528720"
  },
  {
    "text": "here it was overall just score five or",
    "start": "528720",
    "end": "533000"
  },
  {
    "text": "here just like a bit more",
    "start": "533000",
    "end": "534959"
  },
  {
    "text": "nuanced but here we are kind of pending",
    "start": "534959",
    "end": "537160"
  },
  {
    "text": "feedback and if you click this",
    "start": "537160",
    "end": "540000"
  },
  {
    "text": "we have ai suggested an answer to to",
    "start": "540000",
    "end": "545120"
  },
  {
    "text": "this and that's all I had today um if",
    "start": "545600",
    "end": "548200"
  },
  {
    "text": "you want to get started on um llm e we",
    "start": "548200",
    "end": "551920"
  },
  {
    "text": "have our documentation at our usual",
    "start": "551920",
    "end": "553720"
  },
  {
    "text": "documentation site and you can find me",
    "start": "553720",
    "end": "556720"
  },
  {
    "text": "at Nicholas cord on X or forly forly",
    "start": "556720",
    "end": "560240"
  },
  {
    "text": "known as Twitter or should be an email",
    "start": "560240",
    "end": "562519"
  },
  {
    "text": "at Nick atlock 10. thank",
    "start": "562519",
    "end": "566460"
  },
  {
    "text": "[Music]",
    "start": "566460",
    "end": "568120"
  },
  {
    "text": "you",
    "start": "568120",
    "end": "571120"
  }
]
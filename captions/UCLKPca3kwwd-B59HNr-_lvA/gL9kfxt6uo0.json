[
  {
    "text": "[Music]",
    "start": "350",
    "end": "13000"
  },
  {
    "text": "hi everyone thank you for joining us for",
    "start": "13000",
    "end": "14920"
  },
  {
    "text": "the session on how you can accelerate",
    "start": "14920",
    "end": "16920"
  },
  {
    "text": "your AI Journey with the aurei model",
    "start": "16920",
    "end": "19000"
  },
  {
    "text": "catalog this is shuie I'm one of the",
    "start": "19000",
    "end": "21199"
  },
  {
    "text": "product managers on",
    "start": "21199",
    "end": "22760"
  },
  {
    "text": "aurei and I'm sharmi I'm one of the",
    "start": "22760",
    "end": "25560"
  },
  {
    "text": "product marketing managers on Azure",
    "start": "25560",
    "end": "28320"
  },
  {
    "text": "AI great so let's get started so today",
    "start": "28320",
    "end": "32160"
  },
  {
    "text": "we'll be talking about how we offer the",
    "start": "32160",
    "end": "33760"
  },
  {
    "text": "best collection of foundation models on",
    "start": "33760",
    "end": "35399"
  },
  {
    "text": "Azure why the model Choice matters so",
    "start": "35399",
    "end": "38000"
  },
  {
    "text": "much when you have such a huge",
    "start": "38000",
    "end": "39520"
  },
  {
    "text": "collection of models and how does the",
    "start": "39520",
    "end": "41600"
  },
  {
    "text": "Azure AI model inference API make it",
    "start": "41600",
    "end": "43840"
  },
  {
    "text": "standard and easy for you to switch",
    "start": "43840",
    "end": "45680"
  },
  {
    "text": "between multiple models swpe one out for",
    "start": "45680",
    "end": "47840"
  },
  {
    "text": "another without disturbing your rest of",
    "start": "47840",
    "end": "49399"
  },
  {
    "text": "the code base and then how you can build",
    "start": "49399",
    "end": "51800"
  },
  {
    "text": "generative AI apps on top of it and how",
    "start": "51800",
    "end": "55079"
  },
  {
    "text": "the platform makes sure that all your",
    "start": "55079",
    "end": "56960"
  },
  {
    "text": "Enterprise redness needs like data",
    "start": "56960",
    "end": "58800"
  },
  {
    "text": "privacy security and content filtering",
    "start": "58800",
    "end": "60760"
  },
  {
    "text": "are met and then let we'll talk a bit",
    "start": "60760",
    "end": "62719"
  },
  {
    "text": "about some of the customer success",
    "start": "62719",
    "end": "64799"
  },
  {
    "text": "stories so Shi as you mentioned uh there",
    "start": "64799",
    "end": "68040"
  },
  {
    "text": "are a lot of large language models that",
    "start": "68040",
    "end": "69840"
  },
  {
    "text": "are being U released pretty much every",
    "start": "69840",
    "end": "72280"
  },
  {
    "text": "day every week and uh I know in the",
    "start": "72280",
    "end": "74960"
  },
  {
    "text": "Azure AI studio and model catalog we are",
    "start": "74960",
    "end": "77400"
  },
  {
    "text": "bringing a lot of models like large",
    "start": "77400",
    "end": "79640"
  },
  {
    "text": "language models foundational models I",
    "start": "79640",
    "end": "82320"
  },
  {
    "text": "want to understand why are we bringing",
    "start": "82320",
    "end": "84840"
  },
  {
    "text": "all all these models and why does it",
    "start": "84840",
    "end": "86840"
  },
  {
    "text": "matter to a",
    "start": "86840",
    "end": "88600"
  },
  {
    "text": "customer yeah absolutely that's a very",
    "start": "88600",
    "end": "91560"
  },
  {
    "text": "valid question so let's talk about why",
    "start": "91560",
    "end": "93880"
  },
  {
    "text": "model Choice matters in the real world",
    "start": "93880",
    "end": "95720"
  },
  {
    "text": "right as cha asked so the three",
    "start": "95720",
    "end": "97920"
  },
  {
    "text": "questions that we all try to answer when",
    "start": "97920",
    "end": "99960"
  },
  {
    "text": "we try to buid generative AI apps is can",
    "start": "99960",
    "end": "102600"
  },
  {
    "text": "AI solve my use case first and then what",
    "start": "102600",
    "end": "105320"
  },
  {
    "text": "is the best model for my use case and",
    "start": "105320",
    "end": "107280"
  },
  {
    "text": "then how do I go about scaling this for",
    "start": "107280",
    "end": "108920"
  },
  {
    "text": "the production workloads so the first",
    "start": "108920",
    "end": "111200"
  },
  {
    "text": "step is called prototyping where you try",
    "start": "111200",
    "end": "113240"
  },
  {
    "text": "try out multiple models that are",
    "start": "113240",
    "end": "114759"
  },
  {
    "text": "available to you you try to establish",
    "start": "114759",
    "end": "116920"
  },
  {
    "text": "feasibility build that prototype do",
    "start": "116920",
    "end": "119399"
  },
  {
    "text": "compare model benchmarks and find the",
    "start": "119399",
    "end": "121280"
  },
  {
    "text": "right one for your use case or maybe at",
    "start": "121280",
    "end": "123000"
  },
  {
    "text": "least short list some of them and that's",
    "start": "123000",
    "end": "125000"
  },
  {
    "text": "when you move to the next stage where",
    "start": "125000",
    "end": "126439"
  },
  {
    "text": "you try to optimize it for your use case",
    "start": "126439",
    "end": "128520"
  },
  {
    "text": "where you try to optimize for cost",
    "start": "128520",
    "end": "130319"
  },
  {
    "text": "latency Regional nuances Etc and that's",
    "start": "130319",
    "end": "133680"
  },
  {
    "text": "where the Azure AI platform comes into",
    "start": "133680",
    "end": "135440"
  },
  {
    "text": "picture where you can use the techniques",
    "start": "135440",
    "end": "137040"
  },
  {
    "text": "like prompt engineering Rag and",
    "start": "137040",
    "end": "138560"
  },
  {
    "text": "fine-tuning to make sure that you've",
    "start": "138560",
    "end": "140040"
  },
  {
    "text": "optimized it once you're done through",
    "start": "140040",
    "end": "142160"
  },
  {
    "text": "this Loop of prototyping with the model",
    "start": "142160",
    "end": "143879"
  },
  {
    "text": "catalog and optimizing with the platform",
    "start": "143879",
    "end": "145920"
  },
  {
    "text": "you can go ahead and operationalize it",
    "start": "145920",
    "end": "147840"
  },
  {
    "text": "so you don't have to worry much about",
    "start": "147840",
    "end": "149360"
  },
  {
    "text": "the capacity and cost tradeoffs you have",
    "start": "149360",
    "end": "151319"
  },
  {
    "text": "to you have you've got monitoring you've",
    "start": "151319",
    "end": "153200"
  },
  {
    "text": "got scalability you've got data privacy",
    "start": "153200",
    "end": "155560"
  },
  {
    "text": "content filtering and all your",
    "start": "155560",
    "end": "158000"
  },
  {
    "text": "Enterprise needs are met so once you",
    "start": "158000",
    "end": "160720"
  },
  {
    "text": "through this you have your generative AI",
    "start": "160720",
    "end": "162480"
  },
  {
    "text": "application production so another",
    "start": "162480",
    "end": "165120"
  },
  {
    "text": "question I had here is U have you seen",
    "start": "165120",
    "end": "168080"
  },
  {
    "text": "situations where a customer is using",
    "start": "168080",
    "end": "170239"
  },
  {
    "text": "more than one model for a specific use",
    "start": "170239",
    "end": "172200"
  },
  {
    "text": "case and even for multiple use cases",
    "start": "172200",
    "end": "174519"
  },
  {
    "text": "yeah absolutely like that's the whole",
    "start": "174519",
    "end": "176319"
  },
  {
    "text": "point of the model catalog that you have",
    "start": "176319",
    "end": "178519"
  },
  {
    "text": "this wide range of models you have your",
    "start": "178519",
    "end": "180879"
  },
  {
    "text": "use case and you're able to plug in any",
    "start": "180879",
    "end": "183920"
  },
  {
    "text": "model in from that model catalog so you",
    "start": "183920",
    "end": "186159"
  },
  {
    "text": "can swap out one for another without",
    "start": "186159",
    "end": "187959"
  },
  {
    "text": "disturbing anything with quick",
    "start": "187959",
    "end": "189599"
  },
  {
    "text": "prototyping and quick",
    "start": "189599",
    "end": "192720"
  },
  {
    "text": "comparison so as we mentioned let's talk",
    "start": "193599",
    "end": "196080"
  },
  {
    "text": "a bit about the model selections that we",
    "start": "196080",
    "end": "197680"
  },
  {
    "text": "offer on our platform so we offer a wide",
    "start": "197680",
    "end": "199959"
  },
  {
    "text": "range of Flagship llms and slms recently",
    "start": "199959",
    "end": "202840"
  },
  {
    "text": "we launched the Aur OPI models GPD 4 is",
    "start": "202840",
    "end": "205480"
  },
  {
    "text": "already on the platform we launched",
    "start": "205480",
    "end": "207080"
  },
  {
    "text": "mistal models llama models coher models",
    "start": "207080",
    "end": "210080"
  },
  {
    "text": "as well as small language models like 53",
    "start": "210080",
    "end": "212280"
  },
  {
    "text": "and the mral OSS models along with that",
    "start": "212280",
    "end": "215000"
  },
  {
    "text": "we make sure that your multimodel",
    "start": "215000",
    "end": "217159"
  },
  {
    "text": "requirements image generation",
    "start": "217159",
    "end": "218599"
  },
  {
    "text": "requirements and specific needs such as",
    "start": "218599",
    "end": "220720"
  },
  {
    "text": "embedding model requirements are also",
    "start": "220720",
    "end": "222280"
  },
  {
    "text": "fulfilled on this platform so GPD 40 for",
    "start": "222280",
    "end": "225439"
  },
  {
    "text": "example has function calling and Json",
    "start": "225439",
    "end": "227120"
  },
  {
    "text": "support so you can make sure you use",
    "start": "227120",
    "end": "228560"
  },
  {
    "text": "that for your agent Centric workflows",
    "start": "228560",
    "end": "230879"
  },
  {
    "text": "along with that we also make sure that",
    "start": "230879",
    "end": "232680"
  },
  {
    "text": "we cater to your region or language",
    "start": "232680",
    "end": "234640"
  },
  {
    "text": "specific needs so for example the mral",
    "start": "234640",
    "end": "236519"
  },
  {
    "text": "language is really good with the",
    "start": "236519",
    "end": "237599"
  },
  {
    "text": "European languages or uh the coer",
    "start": "237599",
    "end": "240360"
  },
  {
    "text": "embedding multilingual model is very",
    "start": "240360",
    "end": "242439"
  },
  {
    "text": "good for your multilingual requirements",
    "start": "242439",
    "end": "244319"
  },
  {
    "text": "and we also recently launched js on a",
    "start": "244319",
    "end": "246680"
  },
  {
    "text": "platform which is an Arabic",
    "start": "246680",
    "end": "248439"
  },
  {
    "text": "llm along with all these Flagship and",
    "start": "248439",
    "end": "251000"
  },
  {
    "text": "premium models we also have hundreds of",
    "start": "251000",
    "end": "253159"
  },
  {
    "text": "open models from hunging face and we've",
    "start": "253159",
    "end": "255200"
  },
  {
    "text": "been actively partnering with meta data",
    "start": "255200",
    "end": "257239"
  },
  {
    "text": "brick Snowflake and Nvidia to make sure",
    "start": "257239",
    "end": "259280"
  },
  {
    "text": "that we get their models on our platform",
    "start": "259280",
    "end": "261840"
  },
  {
    "text": "as soon as",
    "start": "261840",
    "end": "264440"
  },
  {
    "text": "possible okay so now that we have uh",
    "start": "264960",
    "end": "269880"
  },
  {
    "text": "seen what all we can do with the catalog",
    "start": "269880",
    "end": "271840"
  },
  {
    "text": "let's try to see a live example of how",
    "start": "271840",
    "end": "273759"
  },
  {
    "text": "to actually go to the catalog and deploy",
    "start": "273759",
    "end": "276000"
  },
  {
    "text": "your models so once you type into your",
    "start": "276000",
    "end": "278600"
  },
  {
    "text": "url ai. azure.com it's as easy you land",
    "start": "278600",
    "end": "281800"
  },
  {
    "text": "on this AI Studio page where you can go",
    "start": "281800",
    "end": "284039"
  },
  {
    "text": "to the model catalog on this left nav",
    "start": "284039",
    "end": "285960"
  },
  {
    "text": "bar and you land on this page that has",
    "start": "285960",
    "end": "288080"
  },
  {
    "text": "the list of all the models that we offer",
    "start": "288080",
    "end": "290639"
  },
  {
    "text": "it has 1,600 plus models right here and",
    "start": "290639",
    "end": "293320"
  },
  {
    "text": "to make it easy for you to filter it for",
    "start": "293320",
    "end": "295039"
  },
  {
    "text": "a use case you can filter by the",
    "start": "295039",
    "end": "297240"
  },
  {
    "text": "different deployment types different",
    "start": "297240",
    "end": "298840"
  },
  {
    "text": "inference tasks that you want to do or",
    "start": "298840",
    "end": "301080"
  },
  {
    "text": "even if just by the model collection",
    "start": "301080",
    "end": "302800"
  },
  {
    "text": "families so let's start out by filtering",
    "start": "302800",
    "end": "305160"
  },
  {
    "text": "for the coher models like click on cair",
    "start": "305160",
    "end": "308000"
  },
  {
    "text": "right here let's try to see coher",
    "start": "308000",
    "end": "310160"
  },
  {
    "text": "command R for example once you click on",
    "start": "310160",
    "end": "312280"
  },
  {
    "text": "the model you land on this model card",
    "start": "312280",
    "end": "314160"
  },
  {
    "text": "page where you have all the information",
    "start": "314160",
    "end": "315919"
  },
  {
    "text": "about the model how uh you can customize",
    "start": "315919",
    "end": "318759"
  },
  {
    "text": "it for your own use case tool use",
    "start": "318759",
    "end": "321000"
  },
  {
    "text": "capabilities this one specific talks",
    "start": "321000",
    "end": "323240"
  },
  {
    "text": "about rack capabilities because the",
    "start": "323240",
    "end": "324800"
  },
  {
    "text": "coher command r model it all model",
    "start": "324800",
    "end": "327560"
  },
  {
    "text": "catalog pages also have these inference",
    "start": "327560",
    "end": "330120"
  },
  {
    "text": "samples that you can use as starter",
    "start": "330120",
    "end": "331560"
  },
  {
    "text": "codes to get started with for example A",
    "start": "331560",
    "end": "333680"
  },
  {
    "text": "Lang chain SDK or a light llm SDK as we",
    "start": "333680",
    "end": "337400"
  },
  {
    "text": "mentioned like we try to standardize the",
    "start": "337400",
    "end": "339360"
  },
  {
    "text": "apis across all use cases so you can",
    "start": "339360",
    "end": "342199"
  },
  {
    "text": "just plug in your our apis into any",
    "start": "342199",
    "end": "344840"
  },
  {
    "text": "third party application like the light",
    "start": "344840",
    "end": "346840"
  },
  {
    "text": "llm and have it working in no time so",
    "start": "346840",
    "end": "350000"
  },
  {
    "text": "once you've gone over this check the",
    "start": "350000",
    "end": "351440"
  },
  {
    "text": "pricing we go ahead and click on deploy",
    "start": "351440",
    "end": "354919"
  },
  {
    "text": "and this is where we make sure that we",
    "start": "354919",
    "end": "357000"
  },
  {
    "text": "are connecting to the Azure Marketplace",
    "start": "357000",
    "end": "359400"
  },
  {
    "text": "so so we use Azure Marketplace just for",
    "start": "359400",
    "end": "361479"
  },
  {
    "text": "the bilding side of things to make sure",
    "start": "361479",
    "end": "363680"
  },
  {
    "text": "that you're built correctly based on",
    "start": "363680",
    "end": "365400"
  },
  {
    "text": "your token usage and this is the step",
    "start": "365400",
    "end": "367800"
  },
  {
    "text": "where you actually subscribe to that",
    "start": "367800",
    "end": "369160"
  },
  {
    "text": "offer here I've already subscribed to",
    "start": "369160",
    "end": "371160"
  },
  {
    "text": "that Microsoft subscription so it's",
    "start": "371160",
    "end": "372560"
  },
  {
    "text": "giving me the option to continue to",
    "start": "372560",
    "end": "374199"
  },
  {
    "text": "deploy it's as simple as choosing a",
    "start": "374199",
    "end": "377000"
  },
  {
    "text": "deployment name checking if you want to",
    "start": "377000",
    "end": "378919"
  },
  {
    "text": "enable content filter or not and",
    "start": "378919",
    "end": "380520"
  },
  {
    "text": "clicking on deploy so under a minute",
    "start": "380520",
    "end": "383280"
  },
  {
    "text": "you'll have your URL and key ready to",
    "start": "383280",
    "end": "386720"
  },
  {
    "text": "get started so while this is happening",
    "start": "386720",
    "end": "388840"
  },
  {
    "text": "let's look",
    "start": "388840",
    "end": "390080"
  },
  {
    "text": "uh at other capabilities that we have",
    "start": "390080",
    "end": "391880"
  },
  {
    "text": "like model benchmarks so when you're in",
    "start": "391880",
    "end": "393800"
  },
  {
    "text": "the Azure AI Studio you also have the",
    "start": "393800",
    "end": "395599"
  },
  {
    "text": "ability to check model benchmarks which",
    "start": "395599",
    "end": "397639"
  },
  {
    "text": "is right here on the left under model",
    "start": "397639",
    "end": "400000"
  },
  {
    "text": "catalog once you go in here here I'm",
    "start": "400000",
    "end": "402400"
  },
  {
    "text": "showing all the models that we have you",
    "start": "402400",
    "end": "404639"
  },
  {
    "text": "can see that we Tred to Benchmark on",
    "start": "404639",
    "end": "406360"
  },
  {
    "text": "certain common characteristics like the",
    "start": "406360",
    "end": "408000"
  },
  {
    "text": "model accuracy model coherence",
    "start": "408000",
    "end": "410039"
  },
  {
    "text": "groundedness Etc and this is the perfect",
    "start": "410039",
    "end": "412800"
  },
  {
    "text": "place for you to filter out which model",
    "start": "412800",
    "end": "415240"
  },
  {
    "text": "you want to choose based on the extreme",
    "start": "415240",
    "end": "416879"
  },
  {
    "text": "selections of models that we offer",
    "start": "416879",
    "end": "419960"
  },
  {
    "text": "so let's go back to check oh yeah and we",
    "start": "419960",
    "end": "421800"
  },
  {
    "text": "see we go back to the deployment that we",
    "start": "421800",
    "end": "423800"
  },
  {
    "text": "created and it got created within a few",
    "start": "423800",
    "end": "425720"
  },
  {
    "text": "seconds we have a Target URL right here",
    "start": "425720",
    "end": "428160"
  },
  {
    "text": "and the key ready to use in any code",
    "start": "428160",
    "end": "430800"
  },
  {
    "text": "base that you already have so now you",
    "start": "430800",
    "end": "432919"
  },
  {
    "text": "may be thinking that before I move on to",
    "start": "432919",
    "end": "435560"
  },
  {
    "text": "using my IDE I want to try it out a bit",
    "start": "435560",
    "end": "437560"
  },
  {
    "text": "right is there something like a",
    "start": "437560",
    "end": "438520"
  },
  {
    "text": "playground and that's where we also have",
    "start": "438520",
    "end": "440840"
  },
  {
    "text": "this playground capability so once it's",
    "start": "440840",
    "end": "443599"
  },
  {
    "text": "also in the AI Studio on the left if you",
    "start": "443599",
    "end": "445280"
  },
  {
    "text": "see we're right under the chat",
    "start": "445280",
    "end": "446520"
  },
  {
    "text": "playground so let's see a live example",
    "start": "446520",
    "end": "448639"
  },
  {
    "text": "right here you can choose the model that",
    "start": "448639",
    "end": "450639"
  },
  {
    "text": "you want to use in the playground so in",
    "start": "450639",
    "end": "452199"
  },
  {
    "text": "this deployment section I've chosen a",
    "start": "452199",
    "end": "453800"
  },
  {
    "text": "mral large deployment that I already",
    "start": "453800",
    "end": "455520"
  },
  {
    "text": "have in this",
    "start": "455520",
    "end": "456919"
  },
  {
    "text": "project let's try to uh chat with this",
    "start": "456919",
    "end": "459840"
  },
  {
    "text": "model right here it's not customized on",
    "start": "459840",
    "end": "461960"
  },
  {
    "text": "any any data I'm just directly asking",
    "start": "461960",
    "end": "463919"
  },
  {
    "text": "the model so I'm trying to ask how does",
    "start": "463919",
    "end": "466199"
  },
  {
    "text": "Microsoft promote the culture of giving",
    "start": "466199",
    "end": "468639"
  },
  {
    "text": "so this will in general give me a",
    "start": "468639",
    "end": "470720"
  },
  {
    "text": "generic response about how it has uh",
    "start": "470720",
    "end": "473639"
  },
  {
    "text": "culture of giving through various",
    "start": "473639",
    "end": "474639"
  },
  {
    "text": "initiatives it has employee match",
    "start": "474639",
    "end": "476240"
  },
  {
    "text": "programs and some generic information",
    "start": "476240",
    "end": "478120"
  },
  {
    "text": "that's available online but what if you",
    "start": "478120",
    "end": "480319"
  },
  {
    "text": "want to specialize it for your for our",
    "start": "480319",
    "end": "482680"
  },
  {
    "text": "own data so here we can go ahead and use",
    "start": "482680",
    "end": "485159"
  },
  {
    "text": "the add your data functionality where",
    "start": "485159",
    "end": "487479"
  },
  {
    "text": "you can choose an available index so",
    "start": "487479",
    "end": "490000"
  },
  {
    "text": "let's choose an available index that's",
    "start": "490000",
    "end": "491560"
  },
  {
    "text": "called Microsoft give that tells it in",
    "start": "491560",
    "end": "493879"
  },
  {
    "text": "specific that what uh what are the",
    "start": "493879",
    "end": "496720"
  },
  {
    "text": "specific things that are very",
    "start": "496720",
    "end": "498440"
  },
  {
    "text": "particularly known internally or may not",
    "start": "498440",
    "end": "500599"
  },
  {
    "text": "be available generic",
    "start": "500599",
    "end": "503240"
  },
  {
    "text": "circumstances if we send out the same",
    "start": "503240",
    "end": "505680"
  },
  {
    "text": "question right here we should get a more",
    "start": "505680",
    "end": "507680"
  },
  {
    "text": "targeted response based on the documents",
    "start": "507680",
    "end": "510159"
  },
  {
    "text": "in that",
    "start": "510159",
    "end": "512520"
  },
  {
    "text": "index so just wait for a few",
    "start": "512719",
    "end": "516800"
  },
  {
    "text": "seconds so shy while this is happening I",
    "start": "516800",
    "end": "519360"
  },
  {
    "text": "had a quick question it's great that we",
    "start": "519360",
    "end": "521560"
  },
  {
    "text": "are doing all this I'm just curious",
    "start": "521560",
    "end": "523120"
  },
  {
    "text": "because you mentioned data and data",
    "start": "523120",
    "end": "525080"
  },
  {
    "text": "source and everything are we using any",
    "start": "525080",
    "end": "527600"
  },
  {
    "text": "of the data from our customers to train",
    "start": "527600",
    "end": "530519"
  },
  {
    "text": "the models or is Microsoft using it are",
    "start": "530519",
    "end": "533480"
  },
  {
    "text": "a model providers using any of the data",
    "start": "533480",
    "end": "535560"
  },
  {
    "text": "that a customer brings in so that's a",
    "start": "535560",
    "end": "538440"
  },
  {
    "text": "great question Sharma because that's a",
    "start": "538440",
    "end": "539920"
  },
  {
    "text": "very common question we get from our",
    "start": "539920",
    "end": "541480"
  },
  {
    "text": "customers and no we have very strict",
    "start": "541480",
    "end": "544079"
  },
  {
    "text": "data privacy and policy rules in place",
    "start": "544079",
    "end": "546480"
  },
  {
    "text": "your prompts and your completions are",
    "start": "546480",
    "end": "548200"
  },
  {
    "text": "not shared with the model provider nor",
    "start": "548200",
    "end": "550279"
  },
  {
    "text": "your data is used for training any of",
    "start": "550279",
    "end": "551839"
  },
  {
    "text": "the",
    "start": "551839",
    "end": "553959"
  },
  {
    "text": "models so yeah looking back at the",
    "start": "554200",
    "end": "557320"
  },
  {
    "text": "results we see that it gave us a very",
    "start": "557320",
    "end": "558959"
  },
  {
    "text": "specific response that says you get 50",
    "start": "558959",
    "end": "561160"
  },
  {
    "text": "usds to start off with a new hire credit",
    "start": "561160",
    "end": "563399"
  },
  {
    "text": "for the giving program and that wasn't",
    "start": "563399",
    "end": "565320"
  },
  {
    "text": "in the response earlier so with just the",
    "start": "565320",
    "end": "567720"
  },
  {
    "text": "click of a button we were able to link",
    "start": "567720",
    "end": "569440"
  },
  {
    "text": "it to an index and get that response so",
    "start": "569440",
    "end": "572000"
  },
  {
    "text": "that's how the playground",
    "start": "572000",
    "end": "575240"
  },
  {
    "text": "works so talking about the different",
    "start": "575920",
    "end": "578519"
  },
  {
    "text": "ways of deployment the one that we just",
    "start": "578519",
    "end": "580200"
  },
  {
    "text": "saw was a serverless API option so in",
    "start": "580200",
    "end": "582640"
  },
  {
    "text": "the model catalog there are two ways you",
    "start": "582640",
    "end": "584200"
  },
  {
    "text": "can deploy a model one's called the",
    "start": "584200",
    "end": "585760"
  },
  {
    "text": "managed compute and one's called the",
    "start": "585760",
    "end": "587079"
  },
  {
    "text": "serverless API option with managed",
    "start": "587079",
    "end": "589360"
  },
  {
    "text": "compute the user is responsible for",
    "start": "589360",
    "end": "591399"
  },
  {
    "text": "getting their own GPU so you basically",
    "start": "591399",
    "end": "593360"
  },
  {
    "text": "pay for the VMS per hour and you're",
    "start": "593360",
    "end": "595560"
  },
  {
    "text": "responsible for the quota management",
    "start": "595560",
    "end": "597560"
  },
  {
    "text": "capacity management and you can use",
    "start": "597560",
    "end": "599800"
  },
  {
    "text": "hundreds of Open Source models with this",
    "start": "599800",
    "end": "602079"
  },
  {
    "text": "the second uh way you can deploy models",
    "start": "602079",
    "end": "604600"
  },
  {
    "text": "is by getting a serverless API and this",
    "start": "604600",
    "end": "607160"
  },
  {
    "text": "available with both Azure op service and",
    "start": "607160",
    "end": "609399"
  },
  {
    "text": "models as a service and this is what has",
    "start": "609399",
    "end": "612560"
  },
  {
    "text": "about 30 plus Flagship models premium",
    "start": "612560",
    "end": "614760"
  },
  {
    "text": "models that you pay for based on your",
    "start": "614760",
    "end": "616600"
  },
  {
    "text": "usage so you get ready to use apis and",
    "start": "616600",
    "end": "619200"
  },
  {
    "text": "you only pay for the input tokens or the",
    "start": "619200",
    "end": "621240"
  },
  {
    "text": "output tokens that you",
    "start": "621240",
    "end": "623600"
  },
  {
    "text": "use we've also put in a lot of effort to",
    "start": "623600",
    "end": "626480"
  },
  {
    "text": "make sure that we standardize the schema",
    "start": "626480",
    "end": "628480"
  },
  {
    "text": "and the apis of these models for you so",
    "start": "628480",
    "end": "631200"
  },
  {
    "text": "we've worked with the model providers to",
    "start": "631200",
    "end": "632760"
  },
  {
    "text": "make sure that we build an SDK on top of",
    "start": "632760",
    "end": "634800"
  },
  {
    "text": "a very standardized rest API system and",
    "start": "634800",
    "end": "638079"
  },
  {
    "text": "such an such an SDK works with common uh",
    "start": "638079",
    "end": "641120"
  },
  {
    "text": "open- sourced applications things like",
    "start": "641120",
    "end": "643800"
  },
  {
    "text": "Lang chain as well as the model provider",
    "start": "643800",
    "end": "646000"
  },
  {
    "text": "specific sdks so all you have to have is",
    "start": "646000",
    "end": "648959"
  },
  {
    "text": "a different endpoint and every endpoint",
    "start": "648959",
    "end": "651959"
  },
  {
    "text": "has the same API structure and the same",
    "start": "651959",
    "end": "654200"
  },
  {
    "text": "SDK structure so you can just swap in",
    "start": "654200",
    "end": "656040"
  },
  {
    "text": "one for another evaluate create multiple",
    "start": "656040",
    "end": "658600"
  },
  {
    "text": "evaluations",
    "start": "658600",
    "end": "659839"
  },
  {
    "text": "compare the results and choose the one",
    "start": "659839",
    "end": "661720"
  },
  {
    "text": "that's perfect for your use",
    "start": "661720",
    "end": "664920"
  },
  {
    "text": "case okay awesome so um we've been",
    "start": "666680",
    "end": "669720"
  },
  {
    "text": "seeing everything about the model",
    "start": "669720",
    "end": "671040"
  },
  {
    "text": "catalog and models can you show us an",
    "start": "671040",
    "end": "674200"
  },
  {
    "text": "actual use case",
    "start": "674200",
    "end": "676279"
  },
  {
    "text": "example yeah so uh let's briefly talk",
    "start": "676279",
    "end": "679519"
  },
  {
    "text": "about how you can actually use these",
    "start": "679519",
    "end": "681120"
  },
  {
    "text": "apis in your IDE let's talk about the",
    "start": "681120",
    "end": "683839"
  },
  {
    "text": "function calling example and let's take",
    "start": "683839",
    "end": "685600"
  },
  {
    "text": "the Mr Large model for for that use case",
    "start": "685600",
    "end": "688279"
  },
  {
    "text": "so here I have a simple function calling",
    "start": "688279",
    "end": "690040"
  },
  {
    "text": "example where I'm trying to qu use this",
    "start": "690040",
    "end": "692040"
  },
  {
    "text": "model as a chatbot for example of in",
    "start": "692040",
    "end": "694519"
  },
  {
    "text": "shop the shop has sells certain",
    "start": "694519",
    "end": "696600"
  },
  {
    "text": "stationary items it has certain specific",
    "start": "696600",
    "end": "699399"
  },
  {
    "text": "pricing and may have certain ongoing",
    "start": "699399",
    "end": "701079"
  },
  {
    "text": "discounts so if you just use a model as",
    "start": "701079",
    "end": "703120"
  },
  {
    "text": "a blackbox you will not get the specific",
    "start": "703120",
    "end": "705560"
  },
  {
    "text": "pricing for the model or for the shop or",
    "start": "705560",
    "end": "708200"
  },
  {
    "text": "any of the ongoing discounts but what",
    "start": "708200",
    "end": "709839"
  },
  {
    "text": "I'm doing here is using the function",
    "start": "709839",
    "end": "711440"
  },
  {
    "text": "calling capability of the mral large",
    "start": "711440",
    "end": "713399"
  },
  {
    "text": "model to define a function called get",
    "start": "713399",
    "end": "715639"
  },
  {
    "text": "bill amount that can take in the",
    "start": "715639",
    "end": "718639"
  },
  {
    "text": "specific information that we fed to it",
    "start": "718639",
    "end": "720600"
  },
  {
    "text": "recognize that it needs to call this",
    "start": "720600",
    "end": "722279"
  },
  {
    "text": "external function based on the prompt",
    "start": "722279",
    "end": "724639"
  },
  {
    "text": "and smartly make that call query that",
    "start": "724639",
    "end": "726800"
  },
  {
    "text": "result and give you the exact",
    "start": "726800",
    "end": "728839"
  },
  {
    "text": "information so right here I've defined",
    "start": "728839",
    "end": "730880"
  },
  {
    "text": "that function I've defined the tool for",
    "start": "730880",
    "end": "732720"
  },
  {
    "text": "that model for Mr Large we send in a",
    "start": "732720",
    "end": "735199"
  },
  {
    "text": "prompt that says you're a helpful",
    "start": "735199",
    "end": "736600"
  },
  {
    "text": "assistant that helps users find how much",
    "start": "736600",
    "end": "738480"
  },
  {
    "text": "they have to pay and we also make sure",
    "start": "738480",
    "end": "740519"
  },
  {
    "text": "that we tell it that you also care about",
    "start": "740519",
    "end": "742360"
  },
  {
    "text": "the environment and you also have to",
    "start": "742360",
    "end": "744160"
  },
  {
    "text": "help users understand possible things",
    "start": "744160",
    "end": "746000"
  },
  {
    "text": "they should be careful of when using",
    "start": "746000",
    "end": "747839"
  },
  {
    "text": "these items so this is just to uh add",
    "start": "747839",
    "end": "750720"
  },
  {
    "text": "more context to the response and see how",
    "start": "750720",
    "end": "752519"
  },
  {
    "text": "the model can adjust based on the",
    "start": "752519",
    "end": "754199"
  },
  {
    "text": "requirement we go ahead we send this",
    "start": "754199",
    "end": "756760"
  },
  {
    "text": "response in we can see that the model",
    "start": "756760",
    "end": "758440"
  },
  {
    "text": "has intelligently identified that it is",
    "start": "758440",
    "end": "760360"
  },
  {
    "text": "calling the function get bill amount",
    "start": "760360",
    "end": "762399"
  },
  {
    "text": "with the right arguments so it",
    "start": "762399",
    "end": "763639"
  },
  {
    "text": "identified that we queried for a stapler",
    "start": "763639",
    "end": "765800"
  },
  {
    "text": "and we as Tred to ask what is the price",
    "start": "765800",
    "end": "767839"
  },
  {
    "text": "for the 10 staplers and if we see the",
    "start": "767839",
    "end": "770279"
  },
  {
    "text": "chat response it says the cost of 10",
    "start": "770279",
    "end": "772199"
  },
  {
    "text": "staplers including any ongoing discounts",
    "start": "772199",
    "end": "774040"
  },
  {
    "text": "is $45 which is very specific and it",
    "start": "774040",
    "end": "776800"
  },
  {
    "text": "also makes sure that it REM the users to",
    "start": "776800",
    "end": "780079"
  },
  {
    "text": "be mindful of the environment and try to",
    "start": "780079",
    "end": "782079"
  },
  {
    "text": "use staples when possible and this is in",
    "start": "782079",
    "end": "784320"
  },
  {
    "text": "result of the system message that we",
    "start": "784320",
    "end": "785880"
  },
  {
    "text": "sent to it when we asked it to be",
    "start": "785880",
    "end": "788079"
  },
  {
    "text": "environmentally friendly and give users",
    "start": "788079",
    "end": "790279"
  },
  {
    "text": "the right context so similarly if you",
    "start": "790279",
    "end": "792839"
  },
  {
    "text": "see right here you can swap any code",
    "start": "792839",
    "end": "795240"
  },
  {
    "text": "base with uh any endpoint that you have",
    "start": "795240",
    "end": "798120"
  },
  {
    "text": "and",
    "start": "798120",
    "end": "799000"
  },
  {
    "text": "without putting M much time into it or",
    "start": "799000",
    "end": "801839"
  },
  {
    "text": "much effort into it you have a running",
    "start": "801839",
    "end": "803760"
  },
  {
    "text": "API app right here we also make sure",
    "start": "803760",
    "end": "806160"
  },
  {
    "text": "that we use uh uh model provider um",
    "start": "806160",
    "end": "810360"
  },
  {
    "text": "feels like the safe prompt setting to",
    "start": "810360",
    "end": "812440"
  },
  {
    "text": "true so on top of we always build on top",
    "start": "812440",
    "end": "815279"
  },
  {
    "text": "of what the model provider capabilities",
    "start": "815279",
    "end": "816959"
  },
  {
    "text": "are already",
    "start": "816959",
    "end": "818440"
  },
  {
    "text": "existing",
    "start": "818440",
    "end": "821120"
  },
  {
    "text": "a so now that we've talked about how we",
    "start": "821120",
    "end": "824440"
  },
  {
    "text": "can set it up in the IDE let's talk a",
    "start": "824440",
    "end": "826040"
  },
  {
    "text": "bit about how you can set it up in the",
    "start": "826040",
    "end": "827639"
  },
  {
    "text": "UI and how you can create a generative",
    "start": "827639",
    "end": "829480"
  },
  {
    "text": "AI app using prompt flow so when you try",
    "start": "829480",
    "end": "832360"
  },
  {
    "text": "to here I'm trying to create a shopping",
    "start": "832360",
    "end": "834000"
  },
  {
    "text": "assistant chatbot using promp flow where",
    "start": "834000",
    "end": "836680"
  },
  {
    "text": "it's a simple rag application where we",
    "start": "836680",
    "end": "838360"
  },
  {
    "text": "taking the user prompt we try to get",
    "start": "838360",
    "end": "840360"
  },
  {
    "text": "retrieval uh we retrieve contact",
    "start": "840360",
    "end": "842279"
  },
  {
    "text": "specific information from our index and",
    "start": "842279",
    "end": "844560"
  },
  {
    "text": "then uh send it to the llm to generate",
    "start": "844560",
    "end": "846600"
  },
  {
    "text": "an output here we've created the lookup",
    "start": "846600",
    "end": "849279"
  },
  {
    "text": "step for it which is basically doing the",
    "start": "849279",
    "end": "851639"
  },
  {
    "text": "rag part of it the generate part is",
    "start": "851639",
    "end": "853480"
  },
  {
    "text": "going to generate the output from the",
    "start": "853480",
    "end": "854880"
  },
  {
    "text": "llm but we've added this extra step of",
    "start": "854880",
    "end": "857240"
  },
  {
    "text": "rephrasing where we using the query",
    "start": "857240",
    "end": "859399"
  },
  {
    "text": "transformation technique where we take",
    "start": "859399",
    "end": "861279"
  },
  {
    "text": "in the user con uh prompt which is",
    "start": "861279",
    "end": "863360"
  },
  {
    "text": "generally very succinct but we try to",
    "start": "863360",
    "end": "865519"
  },
  {
    "text": "make it more verbos by rephrasing it",
    "start": "865519",
    "end": "868000"
  },
  {
    "text": "because we've seen better result results",
    "start": "868000",
    "end": "869360"
  },
  {
    "text": "of rag with",
    "start": "869360",
    "end": "870800"
  },
  {
    "text": "that so let's look at a live example of",
    "start": "870800",
    "end": "874360"
  },
  {
    "text": "this right here I have this prom flow",
    "start": "874360",
    "end": "876959"
  },
  {
    "text": "running right here my compute session is",
    "start": "876959",
    "end": "878560"
  },
  {
    "text": "running we see that the first question",
    "start": "878560",
    "end": "881120"
  },
  {
    "text": "that we ask is do you have any new",
    "start": "881120",
    "end": "882639"
  },
  {
    "text": "hiking shoes but the rephrase step",
    "start": "882639",
    "end": "885360"
  },
  {
    "text": "rephrase it into a longer verbos output",
    "start": "885360",
    "end": "887759"
  },
  {
    "text": "that says I'm looking for hiking Avail",
    "start": "887759",
    "end": "889920"
  },
  {
    "text": "hiking shoes available and if so what",
    "start": "889920",
    "end": "891920"
  },
  {
    "text": "materials and features so it basically",
    "start": "891920",
    "end": "893399"
  },
  {
    "text": "elongated that",
    "start": "893399",
    "end": "895360"
  },
  {
    "text": "question we check the output of the",
    "start": "895360",
    "end": "897399"
  },
  {
    "text": "lookup step and we see that The Prompt",
    "start": "897399",
    "end": "899880"
  },
  {
    "text": "was able to get the context specific",
    "start": "899880",
    "end": "902160"
  },
  {
    "text": "information from the index that we",
    "start": "902160",
    "end": "903560"
  },
  {
    "text": "provided to it so it identified certain",
    "start": "903560",
    "end": "905199"
  },
  {
    "text": "amount of information that we can now",
    "start": "905199",
    "end": "907399"
  },
  {
    "text": "send to our llm in the next step and the",
    "start": "907399",
    "end": "909399"
  },
  {
    "text": "llm generates a response so based on",
    "start": "909399",
    "end": "911759"
  },
  {
    "text": "that specific information we were able",
    "start": "911759",
    "end": "914160"
  },
  {
    "text": "to get this output that recommended the",
    "start": "914160",
    "end": "916160"
  },
  {
    "text": "fleece fit uh Flex jacket for the women",
    "start": "916160",
    "end": "919959"
  },
  {
    "text": "so we can see that we are able to",
    "start": "919959",
    "end": "922240"
  },
  {
    "text": "generate a plum flow end to endend but",
    "start": "922240",
    "end": "924199"
  },
  {
    "text": "you may be wondering that how do I make",
    "start": "924199",
    "end": "925839"
  },
  {
    "text": "sure that I'm able to plug in different",
    "start": "925839",
    "end": "927600"
  },
  {
    "text": "models into this flow and this is where",
    "start": "927600",
    "end": "929839"
  },
  {
    "text": "you can try to create variance so here",
    "start": "929839",
    "end": "931920"
  },
  {
    "text": "you can see that in the generate step",
    "start": "931920",
    "end": "933440"
  },
  {
    "text": "I'm using a connection from the coher",
    "start": "933440",
    "end": "935040"
  },
  {
    "text": "command r model but you can go ahead and",
    "start": "935040",
    "end": "937319"
  },
  {
    "text": "choose any other connection to any other",
    "start": "937319",
    "end": "939279"
  },
  {
    "text": "model and use evaluation to try to",
    "start": "939279",
    "end": "941880"
  },
  {
    "text": "compare the results from the same for",
    "start": "941880",
    "end": "944639"
  },
  {
    "text": "the same flow for different models so",
    "start": "944639",
    "end": "946880"
  },
  {
    "text": "example for the um first step when we",
    "start": "946880",
    "end": "949560"
  },
  {
    "text": "trying to create the embeddings here",
    "start": "949560",
    "end": "950920"
  },
  {
    "text": "I've used the Ada model but you can go",
    "start": "950920",
    "end": "952800"
  },
  {
    "text": "ahead and try to see okay how does the",
    "start": "952800",
    "end": "954600"
  },
  {
    "text": "command r model work with the command",
    "start": "954600",
    "end": "956279"
  },
  {
    "text": "embed model so you can create these",
    "start": "956279",
    "end": "958240"
  },
  {
    "text": "variance and try to see the evaluation",
    "start": "958240",
    "end": "960279"
  },
  {
    "text": "results in the interest of time I",
    "start": "960279",
    "end": "962279"
  },
  {
    "text": "already ran some evaluations as we also",
    "start": "962279",
    "end": "964399"
  },
  {
    "text": "saw in the previous uh demo and here we",
    "start": "964399",
    "end": "966959"
  },
  {
    "text": "trying to compare the CER command R",
    "start": "966959",
    "end": "968959"
  },
  {
    "text": "versus Lama 3 versus the mral large and",
    "start": "968959",
    "end": "971880"
  },
  {
    "text": "the evaluation capability helps you to",
    "start": "971880",
    "end": "974360"
  },
  {
    "text": "compare the same model for the same flow",
    "start": "974360",
    "end": "977120"
  },
  {
    "text": "on different parameters and you can see",
    "start": "977120",
    "end": "979399"
  },
  {
    "text": "how one fed against",
    "start": "979399",
    "end": "982440"
  },
  {
    "text": "another so this is all great and I think",
    "start": "984639",
    "end": "987279"
  },
  {
    "text": "you touched upon data privacy a little",
    "start": "987279",
    "end": "989319"
  },
  {
    "text": "bit so can you go a little bit more into",
    "start": "989319",
    "end": "991319"
  },
  {
    "text": "the details of what else do we have in",
    "start": "991319",
    "end": "993480"
  },
  {
    "text": "the AI Studio or model catalog to ensure",
    "start": "993480",
    "end": "996600"
  },
  {
    "text": "customers privacy and data security yeah",
    "start": "996600",
    "end": "1000680"
  },
  {
    "text": "absolutely that's the key so let's talk",
    "start": "1000680",
    "end": "1002880"
  },
  {
    "text": "a bit about how we ensure that the data",
    "start": "1002880",
    "end": "1005160"
  },
  {
    "text": "privacy and security compliance needs",
    "start": "1005160",
    "end": "1006839"
  },
  {
    "text": "are met so as I mentioned there are",
    "start": "1006839",
    "end": "1008880"
  },
  {
    "text": "three pillars to this so one's the data",
    "start": "1008880",
    "end": "1010519"
  },
  {
    "text": "privacy part second the security and",
    "start": "1010519",
    "end": "1012720"
  },
  {
    "text": "compliance and the third is the",
    "start": "1012720",
    "end": "1014120"
  },
  {
    "text": "responsible Ai and the content safety",
    "start": "1014120",
    "end": "1016600"
  },
  {
    "text": "talking about data privacy for both man",
    "start": "1016600",
    "end": "1019120"
  },
  {
    "text": "compute and serverless apis your prompts",
    "start": "1019120",
    "end": "1021920"
  },
  {
    "text": "and completions are not shared with the",
    "start": "1021920",
    "end": "1023600"
  },
  {
    "text": "model provider your prompts and",
    "start": "1023600",
    "end": "1025600"
  },
  {
    "text": "completions are not used for training",
    "start": "1025600",
    "end": "1027240"
  },
  {
    "text": "the models no data is shared for",
    "start": "1027240",
    "end": "1029600"
  },
  {
    "text": "training or with the model providers so",
    "start": "1029600",
    "end": "1031480"
  },
  {
    "text": "you can be assured that the AI platform",
    "start": "1031480",
    "end": "1034079"
  },
  {
    "text": "makes sure that your Enterprise needs",
    "start": "1034079",
    "end": "1035520"
  },
  {
    "text": "for data privacy are",
    "start": "1035520",
    "end": "1037199"
  },
  {
    "text": "met we also have this additional feature",
    "start": "1037199",
    "end": "1040120"
  },
  {
    "text": "of adding hidden layer to our model",
    "start": "1040120",
    "end": "1042000"
  },
  {
    "text": "scanning so we make sure that we finding",
    "start": "1042000",
    "end": "1044480"
  },
  {
    "text": "the embedded malware and back doors we",
    "start": "1044480",
    "end": "1046798"
  },
  {
    "text": "it scans for common vulnerabilities and",
    "start": "1046799",
    "end": "1048960"
  },
  {
    "text": "exposures and detect tampering and",
    "start": "1048960",
    "end": "1050720"
  },
  {
    "text": "Corruption across models so for any",
    "start": "1050720",
    "end": "1053240"
  },
  {
    "text": "model that's labeled curated by Azure AI",
    "start": "1053240",
    "end": "1055559"
  },
  {
    "text": "you can be assured that it's passing",
    "start": "1055559",
    "end": "1057120"
  },
  {
    "text": "through the required",
    "start": "1057120",
    "end": "1059000"
  },
  {
    "text": "checks talking about security and",
    "start": "1059000",
    "end": "1061240"
  },
  {
    "text": "compliance in addition to the data",
    "start": "1061240",
    "end": "1063039"
  },
  {
    "text": "privacy Norms that we mentioned we also",
    "start": "1063039",
    "end": "1065240"
  },
  {
    "text": "offer the capabilities of adding private",
    "start": "1065240",
    "end": "1067240"
  },
  {
    "text": "networking so that your data is not",
    "start": "1067240",
    "end": "1069080"
  },
  {
    "text": "exposed to the Internet so you have the",
    "start": "1069080",
    "end": "1071320"
  },
  {
    "text": "control over routing your Ingress and",
    "start": "1071320",
    "end": "1073600"
  },
  {
    "text": "egress traffic through the v-ets and you",
    "start": "1073600",
    "end": "1075760"
  },
  {
    "text": "also have the ability to set up fqdn",
    "start": "1075760",
    "end": "1077679"
  },
  {
    "text": "rules so you can approve proove outbound",
    "start": "1077679",
    "end": "1079600"
  },
  {
    "text": "access to non- aure",
    "start": "1079600",
    "end": "1082120"
  },
  {
    "text": "resources um in addition to this you can",
    "start": "1082120",
    "end": "1084520"
  },
  {
    "text": "also regulate access to models with",
    "start": "1084520",
    "end": "1086280"
  },
  {
    "text": "Azure policy integration so you can have",
    "start": "1086280",
    "end": "1088720"
  },
  {
    "text": "allow list or deny list patterns and you",
    "start": "1088720",
    "end": "1091360"
  },
  {
    "text": "can split out which model collections",
    "start": "1091360",
    "end": "1093480"
  },
  {
    "text": "you want access to or not and you can",
    "start": "1093480",
    "end": "1096080"
  },
  {
    "text": "also use these different policies for",
    "start": "1096080",
    "end": "1098120"
  },
  {
    "text": "separating out the dev test and",
    "start": "1098120",
    "end": "1099760"
  },
  {
    "text": "production",
    "start": "1099760",
    "end": "1102159"
  },
  {
    "text": "environments awesome so um shubi thank",
    "start": "1104559",
    "end": "1107520"
  },
  {
    "text": "you so much for going through the model",
    "start": "1107520",
    "end": "1109080"
  },
  {
    "text": "catalog and AI Studio what what are the",
    "start": "1109080",
    "end": "1111360"
  },
  {
    "text": "features available in there and all all",
    "start": "1111360",
    "end": "1113280"
  },
  {
    "text": "these great demos so now I just want to",
    "start": "1113280",
    "end": "1115720"
  },
  {
    "text": "go into a few customer success stories",
    "start": "1115720",
    "end": "1118640"
  },
  {
    "text": "and uh the one of the main uh kind of",
    "start": "1118640",
    "end": "1121320"
  },
  {
    "text": "underlying theme for all the customer",
    "start": "1121320",
    "end": "1123000"
  },
  {
    "text": "success stories that I'm going to show",
    "start": "1123000",
    "end": "1124440"
  },
  {
    "text": "is that these customers are not just",
    "start": "1124440",
    "end": "1126799"
  },
  {
    "text": "using one model and for their use case",
    "start": "1126799",
    "end": "1129039"
  },
  {
    "text": "they're using multiple models from the",
    "start": "1129039",
    "end": "1130559"
  },
  {
    "text": "model catalog and it could be in one use",
    "start": "1130559",
    "end": "1133280"
  },
  {
    "text": "case or across multiple use cases",
    "start": "1133280",
    "end": "1134880"
  },
  {
    "text": "similar to what should be has shown in",
    "start": "1134880",
    "end": "1136159"
  },
  {
    "text": "the",
    "start": "1136159",
    "end": "1137280"
  },
  {
    "text": "demo and the first customer we're going",
    "start": "1137280",
    "end": "1139440"
  },
  {
    "text": "to talk about is ey and uh they've been",
    "start": "1139440",
    "end": "1142679"
  },
  {
    "text": "using uh our large language models",
    "start": "1142679",
    "end": "1144840"
  },
  {
    "text": "they've started off with the open AI",
    "start": "1144840",
    "end": "1146480"
  },
  {
    "text": "models that was available in the Azure",
    "start": "1146480",
    "end": "1148400"
  },
  {
    "text": "open AI service um they are doing that",
    "start": "1148400",
    "end": "1150840"
  },
  {
    "text": "today and they're also looking into",
    "start": "1150840",
    "end": "1152720"
  },
  {
    "text": "llama models uh where they are looking",
    "start": "1152720",
    "end": "1154960"
  },
  {
    "text": "into llama models for like really uh uh",
    "start": "1154960",
    "end": "1157640"
  },
  {
    "text": "task specific use cases like for",
    "start": "1157640",
    "end": "1159880"
  },
  {
    "text": "documentation and for summarization and",
    "start": "1159880",
    "end": "1162240"
  },
  {
    "text": "all that and um they have using our",
    "start": "1162240",
    "end": "1165200"
  },
  {
    "text": "model catalog they built ey. a which is",
    "start": "1165200",
    "end": "1167840"
  },
  {
    "text": "a generative AI platform for ey",
    "start": "1167840",
    "end": "1169840"
  },
  {
    "text": "professionals which addresses the need",
    "start": "1169840",
    "end": "1171520"
  },
  {
    "text": "for enhanced uh productivity and",
    "start": "1171520",
    "end": "1173960"
  },
  {
    "text": "accuracy in professional tasks and one",
    "start": "1173960",
    "end": "1176799"
  },
  {
    "text": "of the key things that we want to show",
    "start": "1176799",
    "end": "1178400"
  },
  {
    "text": "is what's the result of what they've",
    "start": "1178400",
    "end": "1180320"
  },
  {
    "text": "been doing the eyq chat that they built",
    "start": "1180320",
    "end": "1183200"
  },
  {
    "text": "has been adopted by 275,000 employees",
    "start": "1183200",
    "end": "1186120"
  },
  {
    "text": "internally and allow the employees to",
    "start": "1186120",
    "end": "1189000"
  },
  {
    "text": "perform a wide range of tasks",
    "start": "1189000",
    "end": "1190880"
  },
  {
    "text": "efficiently and with great accuracy and",
    "start": "1190880",
    "end": "1193480"
  },
  {
    "text": "what some of the lessons that they have",
    "start": "1193480",
    "end": "1194960"
  },
  {
    "text": "learned is it's not AI using AI in their",
    "start": "1194960",
    "end": "1198679"
  },
  {
    "text": "use cases is not like a one-time thing",
    "start": "1198679",
    "end": "1201039"
  },
  {
    "text": "they need to do continuous evaluation of",
    "start": "1201039",
    "end": "1203240"
  },
  {
    "text": "AI performance and they want to stick to",
    "start": "1203240",
    "end": "1205520"
  },
  {
    "text": "all the responsible AI practices and",
    "start": "1205520",
    "end": "1207799"
  },
  {
    "text": "that's one main reason why they've been",
    "start": "1207799",
    "end": "1209480"
  },
  {
    "text": "using Azure AI uh uh model catalog and",
    "start": "1209480",
    "end": "1212400"
  },
  {
    "text": "Azure AI Studio it's because they feel",
    "start": "1212400",
    "end": "1214799"
  },
  {
    "text": "that they can easily do this evaluation",
    "start": "1214799",
    "end": "1217840"
  },
  {
    "text": "and um make sure whatever they're doing",
    "start": "1217840",
    "end": "1220600"
  },
  {
    "text": "putting in production is going to be uh",
    "start": "1220600",
    "end": "1222320"
  },
  {
    "text": "really and adhering to safe and",
    "start": "1222320",
    "end": "1224960"
  },
  {
    "text": "responsible",
    "start": "1224960",
    "end": "1226280"
  },
  {
    "text": "Ai and then the next customer I wanted",
    "start": "1226280",
    "end": "1228520"
  },
  {
    "text": "to talk about is C CGM again they are a",
    "start": "1228520",
    "end": "1232080"
  },
  {
    "text": "big uh Global player in Sea Land Air and",
    "start": "1232080",
    "end": "1235000"
  },
  {
    "text": "logistic Solutions and they are also",
    "start": "1235000",
    "end": "1237799"
  },
  {
    "text": "building a kind of like a robotic",
    "start": "1237799",
    "end": "1239960"
  },
  {
    "text": "process uh they've been doing",
    "start": "1239960",
    "end": "1241240"
  },
  {
    "text": "traditional robotic process Automation",
    "start": "1241240",
    "end": "1243360"
  },
  {
    "text": "and they've decided to use mistal model",
    "start": "1243360",
    "end": "1245520"
  },
  {
    "text": "from a model catalog and they have built",
    "start": "1245520",
    "end": "1247919"
  },
  {
    "text": "again a similar chatbot like scenario uh",
    "start": "1247919",
    "end": "1250840"
  },
  {
    "text": "for their customer care agents and um",
    "start": "1250840",
    "end": "1253960"
  },
  {
    "text": "one thing that they have seen is they",
    "start": "1253960",
    "end": "1255559"
  },
  {
    "text": "have seen a reduced response latency and",
    "start": "1255559",
    "end": "1257840"
  },
  {
    "text": "increased customer customer satisfaction",
    "start": "1257840",
    "end": "1259520"
  },
  {
    "text": "in their chatbot uh use case and they",
    "start": "1259520",
    "end": "1262200"
  },
  {
    "text": "plan to again extend the application of",
    "start": "1262200",
    "end": "1265280"
  },
  {
    "text": "llms to Encompass specific products for",
    "start": "1265280",
    "end": "1267960"
  },
  {
    "text": "Core Business activities like invoicing",
    "start": "1267960",
    "end": "1270720"
  },
  {
    "text": "customer document analysis uh",
    "start": "1270720",
    "end": "1272840"
  },
  {
    "text": "interpreting free client text and uh",
    "start": "1272840",
    "end": "1275200"
  },
  {
    "text": "writing emails and all that and finally",
    "start": "1275200",
    "end": "1278640"
  },
  {
    "text": "the last customer story I want to share",
    "start": "1278640",
    "end": "1280360"
  },
  {
    "text": "is Bridgestone again Bridgestone is a",
    "start": "1280360",
    "end": "1282400"
  },
  {
    "text": "very popular name um their their use",
    "start": "1282400",
    "end": "1285240"
  },
  {
    "text": "case is U they have been using the Nixa",
    "start": "1285240",
    "end": "1287520"
  },
  {
    "text": "model from model catalog we launched",
    "start": "1287520",
    "end": "1289640"
  },
  {
    "text": "Nixa uh time series model at build last",
    "start": "1289640",
    "end": "1292640"
  },
  {
    "text": "month and it's a Time series forecasting",
    "start": "1292640",
    "end": "1295080"
  },
  {
    "text": "model and they're using it specifically",
    "start": "1295080",
    "end": "1297159"
  },
  {
    "text": "to predict monthly demand for a vast",
    "start": "1297159",
    "end": "1299440"
  },
  {
    "text": "portfolio of products and um one of the",
    "start": "1299440",
    "end": "1302720"
  },
  {
    "text": "things that they want to do is",
    "start": "1302720",
    "end": "1304000"
  },
  {
    "text": "streamline their forecasting pipelines",
    "start": "1304000",
    "end": "1306200"
  },
  {
    "text": "enhance accuracy and reduce operational",
    "start": "1306200",
    "end": "1308520"
  },
  {
    "text": "complexity and again what they have seen",
    "start": "1308520",
    "end": "1311200"
  },
  {
    "text": "is that they have seen that using the",
    "start": "1311200",
    "end": "1313480"
  },
  {
    "text": "forecasting model like time gen from",
    "start": "1313480",
    "end": "1315320"
  },
  {
    "text": "Nixa has helped them reduce U Errors By",
    "start": "1315320",
    "end": "1318200"
  },
  {
    "text": "nearly 30% on average in forecasting",
    "start": "1318200",
    "end": "1320960"
  },
  {
    "text": "errors uh which is huge and U again in",
    "start": "1320960",
    "end": "1324559"
  },
  {
    "text": "all these customer use cases the time it",
    "start": "1324559",
    "end": "1326640"
  },
  {
    "text": "took for them to start using llms in",
    "start": "1326640",
    "end": "1328760"
  },
  {
    "text": "their applications to seeing the results",
    "start": "1328760",
    "end": "1330880"
  },
  {
    "text": "and impact has been reduced",
    "start": "1330880",
    "end": "1333200"
  },
  {
    "text": "significantly because they were being",
    "start": "1333200",
    "end": "1335000"
  },
  {
    "text": "able to use uh model catalog and Azure",
    "start": "1335000",
    "end": "1337600"
  },
  {
    "text": "AI Studio where we provide as should be",
    "start": "1337600",
    "end": "1340360"
  },
  {
    "text": "showed in the very first slide we do we",
    "start": "1340360",
    "end": "1343200"
  },
  {
    "text": "have tools for prototyping um optimizing",
    "start": "1343200",
    "end": "1346799"
  },
  {
    "text": "and operationalizing so whether you're",
    "start": "1346799",
    "end": "1348720"
  },
  {
    "text": "just starting off with let me try this",
    "start": "1348720",
    "end": "1350919"
  },
  {
    "text": "for a prototype project to realizing",
    "start": "1350919",
    "end": "1353279"
  },
  {
    "text": "okay I need to put it into production",
    "start": "1353279",
    "end": "1355200"
  },
  {
    "text": "the time it takes from going from that",
    "start": "1355200",
    "end": "1357039"
  },
  {
    "text": "to the last step has been reduced",
    "start": "1357039",
    "end": "1358720"
  },
  {
    "text": "significantly mostly because we have",
    "start": "1358720",
    "end": "1360480"
  },
  {
    "text": "streamlined all the different um",
    "start": "1360480",
    "end": "1363279"
  },
  {
    "text": "foundational models we have provided the",
    "start": "1363279",
    "end": "1364960"
  },
  {
    "text": "right tools for all our customers to",
    "start": "1364960",
    "end": "1366720"
  },
  {
    "text": "kind of go through that whole uh llm",
    "start": "1366720",
    "end": "1369520"
  },
  {
    "text": "life cycle I think that's pretty much it",
    "start": "1369520",
    "end": "1373360"
  },
  {
    "text": "uh thank you thank you",
    "start": "1373360",
    "end": "1377600"
  },
  {
    "text": "oh",
    "start": "1378640",
    "end": "1381480"
  },
  {
    "text": "[Music]",
    "start": "1381480",
    "end": "1395270"
  }
]